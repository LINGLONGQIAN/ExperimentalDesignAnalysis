2024-05-22 11:55:01 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 11:55:02 [INFO]: Using the given device: cuda:0
2024-05-22 11:55:02 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240522_T115502
2024-05-22 11:55:02 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240522_T115502/tensorboard
2024-05-22 11:55:02 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 11:55:05 [INFO]: Epoch 001 - training loss: 1.2264, validation loss: 0.2753
2024-05-22 11:55:05 [INFO]: Epoch 002 - training loss: 0.9106, validation loss: 0.1269
2024-05-22 11:55:06 [INFO]: Epoch 003 - training loss: 0.8254, validation loss: 0.1002
2024-05-22 11:55:06 [INFO]: Epoch 004 - training loss: 0.7486, validation loss: 0.0945
2024-05-22 11:55:07 [INFO]: Epoch 005 - training loss: 0.7110, validation loss: 0.0842
2024-05-22 11:55:07 [INFO]: Epoch 006 - training loss: 0.6720, validation loss: 0.0755
2024-05-22 11:55:08 [INFO]: Epoch 007 - training loss: 0.6634, validation loss: 0.0688
2024-05-22 11:55:08 [INFO]: Epoch 008 - training loss: 0.6406, validation loss: 0.0736
2024-05-22 11:55:09 [INFO]: Epoch 009 - training loss: 0.6247, validation loss: 0.0570
2024-05-22 11:55:09 [INFO]: Epoch 010 - training loss: 0.6106, validation loss: 0.0727
2024-05-22 11:55:10 [INFO]: Epoch 011 - training loss: 0.6071, validation loss: 0.0843
2024-05-22 11:55:10 [INFO]: Epoch 012 - training loss: 0.6041, validation loss: 0.0661
2024-05-22 11:55:11 [INFO]: Epoch 013 - training loss: 0.6045, validation loss: 0.0611
2024-05-22 11:55:11 [INFO]: Epoch 014 - training loss: 0.5719, validation loss: 0.0502
2024-05-22 11:55:12 [INFO]: Epoch 015 - training loss: 0.5605, validation loss: 0.0596
2024-05-22 11:55:12 [INFO]: Epoch 016 - training loss: 0.5605, validation loss: 0.0562
2024-05-22 11:55:13 [INFO]: Epoch 017 - training loss: 0.5672, validation loss: 0.0587
2024-05-22 11:55:13 [INFO]: Epoch 018 - training loss: 0.5452, validation loss: 0.0457
2024-05-22 11:55:14 [INFO]: Epoch 019 - training loss: 0.5365, validation loss: 0.0648
2024-05-22 11:55:14 [INFO]: Epoch 020 - training loss: 0.5442, validation loss: 0.0513
2024-05-22 11:55:15 [INFO]: Epoch 021 - training loss: 0.5371, validation loss: 0.0417
2024-05-22 11:55:15 [INFO]: Epoch 022 - training loss: 0.5210, validation loss: 0.0420
2024-05-22 11:55:16 [INFO]: Epoch 023 - training loss: 0.5194, validation loss: 0.1362
2024-05-22 11:55:16 [INFO]: Epoch 024 - training loss: 0.5415, validation loss: 0.0399
2024-05-22 11:55:17 [INFO]: Epoch 025 - training loss: 0.5115, validation loss: 0.0610
2024-05-22 11:55:17 [INFO]: Epoch 026 - training loss: 0.4889, validation loss: 0.0382
2024-05-22 11:55:18 [INFO]: Epoch 027 - training loss: 0.4851, validation loss: 0.0441
2024-05-22 11:55:19 [INFO]: Epoch 028 - training loss: 0.4798, validation loss: 0.0462
2024-05-22 11:55:19 [INFO]: Epoch 029 - training loss: 0.4795, validation loss: 0.0426
2024-05-22 11:55:20 [INFO]: Epoch 030 - training loss: 0.4677, validation loss: 0.0610
2024-05-22 11:55:20 [INFO]: Epoch 031 - training loss: 0.4642, validation loss: 0.0452
2024-05-22 11:55:21 [INFO]: Epoch 032 - training loss: 0.4506, validation loss: 0.0524
2024-05-22 11:55:21 [INFO]: Epoch 033 - training loss: 0.4542, validation loss: 0.0422
2024-05-22 11:55:22 [INFO]: Epoch 034 - training loss: 0.4465, validation loss: 0.0457
2024-05-22 11:55:22 [INFO]: Epoch 035 - training loss: 0.4333, validation loss: 0.0409
2024-05-22 11:55:23 [INFO]: Epoch 036 - training loss: 0.4529, validation loss: 0.0569
2024-05-22 11:55:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:55:23 [INFO]: Finished training. The best model is from epoch#26.
2024-05-22 11:55:23 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_ettm1/20240522_T115502/SAITS.pypots
2024-05-22 11:55:23 [INFO]: SAITS on ETTm1: MAE=0.2008, MSE=0.0807
2024-05-22 11:55:23 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-22 11:55:23 [INFO]: Using the given device: cuda:0
2024-05-22 11:55:23 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240522_T115523
2024-05-22 11:55:23 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240522_T115523/tensorboard
2024-05-22 11:55:23 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 11:55:23 [INFO]: Epoch 001 - training loss: 1.1668, validation loss: 0.3330
2024-05-22 11:55:24 [INFO]: Epoch 002 - training loss: 0.7162, validation loss: 0.1449
2024-05-22 11:55:24 [INFO]: Epoch 003 - training loss: 0.5839, validation loss: 0.1086
2024-05-22 11:55:24 [INFO]: Epoch 004 - training loss: 0.5208, validation loss: 0.0829
2024-05-22 11:55:24 [INFO]: Epoch 005 - training loss: 0.4822, validation loss: 0.0731
2024-05-22 11:55:25 [INFO]: Epoch 006 - training loss: 0.4640, validation loss: 0.0717
2024-05-22 11:55:25 [INFO]: Epoch 007 - training loss: 0.4420, validation loss: 0.0668
2024-05-22 11:55:25 [INFO]: Epoch 008 - training loss: 0.4171, validation loss: 0.0626
2024-05-22 11:55:25 [INFO]: Epoch 009 - training loss: 0.4035, validation loss: 0.0669
2024-05-22 11:55:25 [INFO]: Epoch 010 - training loss: 0.3989, validation loss: 0.0642
2024-05-22 11:55:26 [INFO]: Epoch 011 - training loss: 0.3905, validation loss: 0.0717
2024-05-22 11:55:26 [INFO]: Epoch 012 - training loss: 0.3785, validation loss: 0.0518
2024-05-22 11:55:26 [INFO]: Epoch 013 - training loss: 0.3622, validation loss: 0.0467
2024-05-22 11:55:26 [INFO]: Epoch 014 - training loss: 0.3599, validation loss: 0.0486
2024-05-22 11:55:26 [INFO]: Epoch 015 - training loss: 0.3520, validation loss: 0.0483
2024-05-22 11:55:27 [INFO]: Epoch 016 - training loss: 0.3459, validation loss: 0.0464
2024-05-22 11:55:27 [INFO]: Epoch 017 - training loss: 0.3388, validation loss: 0.0453
2024-05-22 11:55:27 [INFO]: Epoch 018 - training loss: 0.3350, validation loss: 0.0460
2024-05-22 11:55:27 [INFO]: Epoch 019 - training loss: 0.3279, validation loss: 0.0436
2024-05-22 11:55:28 [INFO]: Epoch 020 - training loss: 0.3228, validation loss: 0.0383
2024-05-22 11:55:28 [INFO]: Epoch 021 - training loss: 0.3184, validation loss: 0.0419
2024-05-22 11:55:28 [INFO]: Epoch 022 - training loss: 0.3193, validation loss: 0.0361
2024-05-22 11:55:28 [INFO]: Epoch 023 - training loss: 0.3151, validation loss: 0.0396
2024-05-22 11:55:28 [INFO]: Epoch 024 - training loss: 0.3110, validation loss: 0.0346
2024-05-22 11:55:29 [INFO]: Epoch 025 - training loss: 0.3023, validation loss: 0.0425
2024-05-22 11:55:29 [INFO]: Epoch 026 - training loss: 0.3033, validation loss: 0.0422
2024-05-22 11:55:29 [INFO]: Epoch 027 - training loss: 0.2969, validation loss: 0.0395
2024-05-22 11:55:29 [INFO]: Epoch 028 - training loss: 0.2940, validation loss: 0.0339
2024-05-22 11:55:30 [INFO]: Epoch 029 - training loss: 0.2902, validation loss: 0.0378
2024-05-22 11:55:30 [INFO]: Epoch 030 - training loss: 0.2886, validation loss: 0.0370
2024-05-22 11:55:30 [INFO]: Epoch 031 - training loss: 0.2887, validation loss: 0.0353
2024-05-22 11:55:30 [INFO]: Epoch 032 - training loss: 0.2800, validation loss: 0.0321
2024-05-22 11:55:30 [INFO]: Epoch 033 - training loss: 0.2741, validation loss: 0.0339
2024-05-22 11:55:31 [INFO]: Epoch 034 - training loss: 0.2788, validation loss: 0.0345
2024-05-22 11:55:31 [INFO]: Epoch 035 - training loss: 0.2754, validation loss: 0.0328
2024-05-22 11:55:31 [INFO]: Epoch 036 - training loss: 0.2705, validation loss: 0.0307
2024-05-22 11:55:31 [INFO]: Epoch 037 - training loss: 0.2671, validation loss: 0.0344
2024-05-22 11:55:32 [INFO]: Epoch 038 - training loss: 0.2634, validation loss: 0.0328
2024-05-22 11:55:32 [INFO]: Epoch 039 - training loss: 0.2583, validation loss: 0.0299
2024-05-22 11:55:32 [INFO]: Epoch 040 - training loss: 0.2549, validation loss: 0.0283
2024-05-22 11:55:32 [INFO]: Epoch 041 - training loss: 0.2568, validation loss: 0.0354
2024-05-22 11:55:32 [INFO]: Epoch 042 - training loss: 0.2553, validation loss: 0.0311
2024-05-22 11:55:33 [INFO]: Epoch 043 - training loss: 0.2466, validation loss: 0.0381
2024-05-22 11:55:33 [INFO]: Epoch 044 - training loss: 0.2572, validation loss: 0.0350
2024-05-22 11:55:33 [INFO]: Epoch 045 - training loss: 0.2499, validation loss: 0.0262
2024-05-22 11:55:33 [INFO]: Epoch 046 - training loss: 0.2433, validation loss: 0.0308
2024-05-22 11:55:34 [INFO]: Epoch 047 - training loss: 0.2525, validation loss: 0.0410
2024-05-22 11:55:34 [INFO]: Epoch 048 - training loss: 0.2596, validation loss: 0.0299
2024-05-22 11:55:34 [INFO]: Epoch 049 - training loss: 0.2386, validation loss: 0.0313
2024-05-22 11:55:34 [INFO]: Epoch 050 - training loss: 0.2392, validation loss: 0.0287
2024-05-22 11:55:34 [INFO]: Epoch 051 - training loss: 0.2321, validation loss: 0.0279
2024-05-22 11:55:35 [INFO]: Epoch 052 - training loss: 0.2337, validation loss: 0.0279
2024-05-22 11:55:35 [INFO]: Epoch 053 - training loss: 0.2383, validation loss: 0.0309
2024-05-22 11:55:35 [INFO]: Epoch 054 - training loss: 0.2454, validation loss: 0.0324
2024-05-22 11:55:35 [INFO]: Epoch 055 - training loss: 0.2346, validation loss: 0.0335
2024-05-22 11:55:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:55:35 [INFO]: Finished training. The best model is from epoch#45.
2024-05-22 11:55:35 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_ettm1/20240522_T115523/Transformer.pypots
2024-05-22 11:55:35 [INFO]: Transformer on ETTm1: MAE=0.1666, MSE=0.0482
2024-05-22 11:55:35 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-22 11:55:35 [INFO]: Using the given device: cuda:0
2024-05-22 11:55:35 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240522_T115535
2024-05-22 11:55:35 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240522_T115535/tensorboard
2024-05-22 11:55:36 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 11:55:42 [INFO]: Epoch 001 - training loss: 0.1516, validation loss: 0.0501
2024-05-22 11:55:42 [INFO]: Epoch 002 - training loss: 0.0683, validation loss: 0.0425
2024-05-22 11:55:42 [INFO]: Epoch 003 - training loss: 0.0551, validation loss: 0.0380
2024-05-22 11:55:42 [INFO]: Epoch 004 - training loss: 0.0504, validation loss: 0.0368
2024-05-22 11:55:43 [INFO]: Epoch 005 - training loss: 0.0496, validation loss: 0.0360
2024-05-22 11:55:43 [INFO]: Epoch 006 - training loss: 0.0518, validation loss: 0.0384
2024-05-22 11:55:43 [INFO]: Epoch 007 - training loss: 0.0591, validation loss: 0.0407
2024-05-22 11:55:43 [INFO]: Epoch 008 - training loss: 0.0557, validation loss: 0.0370
2024-05-22 11:55:43 [INFO]: Epoch 009 - training loss: 0.0495, validation loss: 0.0362
2024-05-22 11:55:44 [INFO]: Epoch 010 - training loss: 0.0437, validation loss: 0.0325
2024-05-22 11:55:44 [INFO]: Epoch 011 - training loss: 0.0441, validation loss: 0.0319
2024-05-22 11:55:44 [INFO]: Epoch 012 - training loss: 0.0456, validation loss: 0.0332
2024-05-22 11:55:44 [INFO]: Epoch 013 - training loss: 0.0439, validation loss: 0.0331
2024-05-22 11:55:45 [INFO]: Epoch 014 - training loss: 0.0462, validation loss: 0.0346
2024-05-22 11:55:45 [INFO]: Epoch 015 - training loss: 0.0456, validation loss: 0.0337
2024-05-22 11:55:45 [INFO]: Epoch 016 - training loss: 0.0445, validation loss: 0.0307
2024-05-22 11:55:45 [INFO]: Epoch 017 - training loss: 0.0426, validation loss: 0.0297
2024-05-22 11:55:46 [INFO]: Epoch 018 - training loss: 0.0437, validation loss: 0.0309
2024-05-22 11:55:46 [INFO]: Epoch 019 - training loss: 0.0422, validation loss: 0.0300
2024-05-22 11:55:46 [INFO]: Epoch 020 - training loss: 0.0487, validation loss: 0.0314
2024-05-22 11:55:46 [INFO]: Epoch 021 - training loss: 0.0440, validation loss: 0.0282
2024-05-22 11:55:46 [INFO]: Epoch 022 - training loss: 0.0423, validation loss: 0.0278
2024-05-22 11:55:47 [INFO]: Epoch 023 - training loss: 0.0387, validation loss: 0.0282
2024-05-22 11:55:47 [INFO]: Epoch 024 - training loss: 0.0397, validation loss: 0.0292
2024-05-22 11:55:47 [INFO]: Epoch 025 - training loss: 0.0395, validation loss: 0.0283
2024-05-22 11:55:47 [INFO]: Epoch 026 - training loss: 0.0393, validation loss: 0.0276
2024-05-22 11:55:48 [INFO]: Epoch 027 - training loss: 0.0383, validation loss: 0.0290
2024-05-22 11:55:48 [INFO]: Epoch 028 - training loss: 0.0361, validation loss: 0.0289
2024-05-22 11:55:48 [INFO]: Epoch 029 - training loss: 0.0381, validation loss: 0.0286
2024-05-22 11:55:48 [INFO]: Epoch 030 - training loss: 0.0395, validation loss: 0.0300
2024-05-22 11:55:48 [INFO]: Epoch 031 - training loss: 0.0418, validation loss: 0.0324
2024-05-22 11:55:49 [INFO]: Epoch 032 - training loss: 0.0399, validation loss: 0.0266
2024-05-22 11:55:49 [INFO]: Epoch 033 - training loss: 0.0373, validation loss: 0.0259
2024-05-22 11:55:49 [INFO]: Epoch 034 - training loss: 0.0360, validation loss: 0.0269
2024-05-22 11:55:49 [INFO]: Epoch 035 - training loss: 0.0369, validation loss: 0.0274
2024-05-22 11:55:49 [INFO]: Epoch 036 - training loss: 0.0387, validation loss: 0.0267
2024-05-22 11:55:50 [INFO]: Epoch 037 - training loss: 0.0409, validation loss: 0.0272
2024-05-22 11:55:50 [INFO]: Epoch 038 - training loss: 0.0381, validation loss: 0.0253
2024-05-22 11:55:50 [INFO]: Epoch 039 - training loss: 0.0351, validation loss: 0.0266
2024-05-22 11:55:50 [INFO]: Epoch 040 - training loss: 0.0349, validation loss: 0.0258
2024-05-22 11:55:51 [INFO]: Epoch 041 - training loss: 0.0344, validation loss: 0.0260
2024-05-22 11:55:51 [INFO]: Epoch 042 - training loss: 0.0377, validation loss: 0.0275
2024-05-22 11:55:51 [INFO]: Epoch 043 - training loss: 0.0371, validation loss: 0.0263
2024-05-22 11:55:51 [INFO]: Epoch 044 - training loss: 0.0347, validation loss: 0.0268
2024-05-22 11:55:51 [INFO]: Epoch 045 - training loss: 0.0361, validation loss: 0.0266
2024-05-22 11:55:52 [INFO]: Epoch 046 - training loss: 0.0337, validation loss: 0.0243
2024-05-22 11:55:52 [INFO]: Epoch 047 - training loss: 0.0342, validation loss: 0.0250
2024-05-22 11:55:52 [INFO]: Epoch 048 - training loss: 0.0368, validation loss: 0.0270
2024-05-22 11:55:52 [INFO]: Epoch 049 - training loss: 0.0343, validation loss: 0.0263
2024-05-22 11:55:53 [INFO]: Epoch 050 - training loss: 0.0333, validation loss: 0.0253
2024-05-22 11:55:53 [INFO]: Epoch 051 - training loss: 0.0328, validation loss: 0.0249
2024-05-22 11:55:53 [INFO]: Epoch 052 - training loss: 0.0342, validation loss: 0.0250
2024-05-22 11:55:53 [INFO]: Epoch 053 - training loss: 0.0335, validation loss: 0.0250
2024-05-22 11:55:53 [INFO]: Epoch 054 - training loss: 0.0333, validation loss: 0.0242
2024-05-22 11:55:54 [INFO]: Epoch 055 - training loss: 0.0326, validation loss: 0.0254
2024-05-22 11:55:54 [INFO]: Epoch 056 - training loss: 0.0325, validation loss: 0.0247
2024-05-22 11:55:54 [INFO]: Epoch 057 - training loss: 0.0326, validation loss: 0.0244
2024-05-22 11:55:54 [INFO]: Epoch 058 - training loss: 0.0325, validation loss: 0.0280
2024-05-22 11:55:54 [INFO]: Epoch 059 - training loss: 0.0405, validation loss: 0.0329
2024-05-22 11:55:55 [INFO]: Epoch 060 - training loss: 0.0498, validation loss: 0.0288
2024-05-22 11:55:55 [INFO]: Epoch 061 - training loss: 0.0451, validation loss: 0.0292
2024-05-22 11:55:55 [INFO]: Epoch 062 - training loss: 0.0358, validation loss: 0.0242
2024-05-22 11:55:55 [INFO]: Epoch 063 - training loss: 0.0329, validation loss: 0.0238
2024-05-22 11:55:56 [INFO]: Epoch 064 - training loss: 0.0337, validation loss: 0.0236
2024-05-22 11:55:56 [INFO]: Epoch 065 - training loss: 0.0317, validation loss: 0.0235
2024-05-22 11:55:56 [INFO]: Epoch 066 - training loss: 0.0335, validation loss: 0.0235
2024-05-22 11:55:56 [INFO]: Epoch 067 - training loss: 0.0329, validation loss: 0.0239
2024-05-22 11:55:56 [INFO]: Epoch 068 - training loss: 0.0322, validation loss: 0.0238
2024-05-22 11:55:57 [INFO]: Epoch 069 - training loss: 0.0319, validation loss: 0.0239
2024-05-22 11:55:57 [INFO]: Epoch 070 - training loss: 0.0344, validation loss: 0.0243
2024-05-22 11:55:57 [INFO]: Epoch 071 - training loss: 0.0319, validation loss: 0.0233
2024-05-22 11:55:57 [INFO]: Epoch 072 - training loss: 0.0315, validation loss: 0.0234
2024-05-22 11:55:58 [INFO]: Epoch 073 - training loss: 0.0322, validation loss: 0.0245
2024-05-22 11:55:58 [INFO]: Epoch 074 - training loss: 0.0335, validation loss: 0.0249
2024-05-22 11:55:58 [INFO]: Epoch 075 - training loss: 0.0319, validation loss: 0.0238
2024-05-22 11:55:58 [INFO]: Epoch 076 - training loss: 0.0332, validation loss: 0.0244
2024-05-22 11:55:58 [INFO]: Epoch 077 - training loss: 0.0312, validation loss: 0.0234
2024-05-22 11:55:59 [INFO]: Epoch 078 - training loss: 0.0306, validation loss: 0.0229
2024-05-22 11:55:59 [INFO]: Epoch 079 - training loss: 0.0300, validation loss: 0.0235
2024-05-22 11:55:59 [INFO]: Epoch 080 - training loss: 0.0314, validation loss: 0.0229
2024-05-22 11:55:59 [INFO]: Epoch 081 - training loss: 0.0306, validation loss: 0.0225
2024-05-22 11:56:00 [INFO]: Epoch 082 - training loss: 0.0287, validation loss: 0.0226
2024-05-22 11:56:00 [INFO]: Epoch 083 - training loss: 0.0293, validation loss: 0.0229
2024-05-22 11:56:00 [INFO]: Epoch 084 - training loss: 0.0300, validation loss: 0.0226
2024-05-22 11:56:00 [INFO]: Epoch 085 - training loss: 0.0320, validation loss: 0.0229
2024-05-22 11:56:00 [INFO]: Epoch 086 - training loss: 0.0300, validation loss: 0.0220
2024-05-22 11:56:01 [INFO]: Epoch 087 - training loss: 0.0307, validation loss: 0.0234
2024-05-22 11:56:01 [INFO]: Epoch 088 - training loss: 0.0327, validation loss: 0.0240
2024-05-22 11:56:01 [INFO]: Epoch 089 - training loss: 0.0323, validation loss: 0.0246
2024-05-22 11:56:01 [INFO]: Epoch 090 - training loss: 0.0337, validation loss: 0.0245
2024-05-22 11:56:02 [INFO]: Epoch 091 - training loss: 0.0323, validation loss: 0.0236
2024-05-22 11:56:02 [INFO]: Epoch 092 - training loss: 0.0311, validation loss: 0.0228
2024-05-22 11:56:02 [INFO]: Epoch 093 - training loss: 0.0299, validation loss: 0.0221
2024-05-22 11:56:02 [INFO]: Epoch 094 - training loss: 0.0292, validation loss: 0.0226
2024-05-22 11:56:02 [INFO]: Epoch 095 - training loss: 0.0291, validation loss: 0.0217
2024-05-22 11:56:03 [INFO]: Epoch 096 - training loss: 0.0294, validation loss: 0.0227
2024-05-22 11:56:03 [INFO]: Epoch 097 - training loss: 0.0304, validation loss: 0.0231
2024-05-22 11:56:03 [INFO]: Epoch 098 - training loss: 0.0311, validation loss: 0.0245
2024-05-22 11:56:03 [INFO]: Epoch 099 - training loss: 0.0307, validation loss: 0.0237
2024-05-22 11:56:03 [INFO]: Epoch 100 - training loss: 0.0333, validation loss: 0.0230
2024-05-22 11:56:04 [INFO]: Epoch 101 - training loss: 0.0311, validation loss: 0.0233
2024-05-22 11:56:04 [INFO]: Epoch 102 - training loss: 0.0310, validation loss: 0.0240
2024-05-22 11:56:04 [INFO]: Epoch 103 - training loss: 0.0307, validation loss: 0.0239
2024-05-22 11:56:04 [INFO]: Epoch 104 - training loss: 0.0299, validation loss: 0.0225
2024-05-22 11:56:05 [INFO]: Epoch 105 - training loss: 0.0304, validation loss: 0.0224
2024-05-22 11:56:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:56:05 [INFO]: Finished training. The best model is from epoch#95.
2024-05-22 11:56:05 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_ettm1/20240522_T115535/TimesNet.pypots
2024-05-22 11:56:05 [INFO]: TimesNet on ETTm1: MAE=0.1052, MSE=0.0239
2024-05-22 11:56:05 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-22 11:56:05 [INFO]: Using the given device: cuda:0
2024-05-22 11:56:05 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605
2024-05-22 11:56:05 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/tensorboard
2024-05-22 11:56:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 11:56:08 [INFO]: Epoch 001 - training loss: 0.7019, validation loss: 0.4194
2024-05-22 11:56:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch1_loss0.4194394201040268.pypots
2024-05-22 11:56:10 [INFO]: Epoch 002 - training loss: 0.3714, validation loss: 0.3622
2024-05-22 11:56:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch2_loss0.36216702312231064.pypots
2024-05-22 11:56:12 [INFO]: Epoch 003 - training loss: 0.3382, validation loss: 0.3378
2024-05-22 11:56:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch3_loss0.3377635031938553.pypots
2024-05-22 11:56:14 [INFO]: Epoch 004 - training loss: 0.3429, validation loss: 0.3072
2024-05-22 11:56:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch4_loss0.30715110898017883.pypots
2024-05-22 11:56:16 [INFO]: Epoch 005 - training loss: 0.3204, validation loss: 0.3069
2024-05-22 11:56:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch5_loss0.30688681453466415.pypots
2024-05-22 11:56:18 [INFO]: Epoch 006 - training loss: 0.2894, validation loss: 0.2829
2024-05-22 11:56:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch6_loss0.28289107233285904.pypots
2024-05-22 11:56:20 [INFO]: Epoch 007 - training loss: 0.2454, validation loss: 0.2682
2024-05-22 11:56:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch7_loss0.2681916579604149.pypots
2024-05-22 11:56:22 [INFO]: Epoch 008 - training loss: 0.2748, validation loss: 0.2691
2024-05-22 11:56:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch8_loss0.2690875008702278.pypots
2024-05-22 11:56:24 [INFO]: Epoch 009 - training loss: 0.2645, validation loss: 0.2721
2024-05-22 11:56:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch9_loss0.2720688730478287.pypots
2024-05-22 11:56:27 [INFO]: Epoch 010 - training loss: 0.2672, validation loss: 0.2592
2024-05-22 11:56:27 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch10_loss0.25916092842817307.pypots
2024-05-22 11:56:29 [INFO]: Epoch 011 - training loss: 0.2375, validation loss: 0.2682
2024-05-22 11:56:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch11_loss0.26817113906145096.pypots
2024-05-22 11:56:31 [INFO]: Epoch 012 - training loss: 0.2171, validation loss: 0.2465
2024-05-22 11:56:31 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch12_loss0.24647779017686844.pypots
2024-05-22 11:56:33 [INFO]: Epoch 013 - training loss: 0.2579, validation loss: 0.2381
2024-05-22 11:56:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch13_loss0.23814107850193977.pypots
2024-05-22 11:56:35 [INFO]: Epoch 014 - training loss: 0.2485, validation loss: 0.2459
2024-05-22 11:56:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch14_loss0.2459126077592373.pypots
2024-05-22 11:56:37 [INFO]: Epoch 015 - training loss: 0.2742, validation loss: 0.2403
2024-05-22 11:56:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch15_loss0.24025509133934975.pypots
2024-05-22 11:56:39 [INFO]: Epoch 016 - training loss: 0.2243, validation loss: 0.2314
2024-05-22 11:56:39 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch16_loss0.23137586936354637.pypots
2024-05-22 11:56:41 [INFO]: Epoch 017 - training loss: 0.2609, validation loss: 0.2297
2024-05-22 11:56:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch17_loss0.22966913133859634.pypots
2024-05-22 11:56:43 [INFO]: Epoch 018 - training loss: 0.2501, validation loss: 0.2265
2024-05-22 11:56:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch18_loss0.22645385935902596.pypots
2024-05-22 11:56:45 [INFO]: Epoch 019 - training loss: 0.2568, validation loss: 0.2263
2024-05-22 11:56:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch19_loss0.2263328619301319.pypots
2024-05-22 11:56:48 [INFO]: Epoch 020 - training loss: 0.2155, validation loss: 0.2155
2024-05-22 11:56:48 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch20_loss0.21548332273960114.pypots
2024-05-22 11:56:50 [INFO]: Epoch 021 - training loss: 0.2159, validation loss: 0.2027
2024-05-22 11:56:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch21_loss0.2027050442993641.pypots
2024-05-22 11:56:52 [INFO]: Epoch 022 - training loss: 0.2072, validation loss: 0.1998
2024-05-22 11:56:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch22_loss0.19982751458883286.pypots
2024-05-22 11:56:54 [INFO]: Epoch 023 - training loss: 0.2378, validation loss: 0.1951
2024-05-22 11:56:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch23_loss0.19507313519716263.pypots
2024-05-22 11:56:56 [INFO]: Epoch 024 - training loss: 0.1978, validation loss: 0.1906
2024-05-22 11:56:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch24_loss0.19060397148132324.pypots
2024-05-22 11:56:58 [INFO]: Epoch 025 - training loss: 0.1712, validation loss: 0.1914
2024-05-22 11:56:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch25_loss0.1914123259484768.pypots
2024-05-22 11:57:00 [INFO]: Epoch 026 - training loss: 0.1857, validation loss: 0.1825
2024-05-22 11:57:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch26_loss0.1825442984700203.pypots
2024-05-22 11:57:02 [INFO]: Epoch 027 - training loss: 0.1897, validation loss: 0.1849
2024-05-22 11:57:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch27_loss0.18494264781475067.pypots
2024-05-22 11:57:04 [INFO]: Epoch 028 - training loss: 0.1825, validation loss: 0.2056
2024-05-22 11:57:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch28_loss0.2056056298315525.pypots
2024-05-22 11:57:06 [INFO]: Epoch 029 - training loss: 0.2646, validation loss: 0.2126
2024-05-22 11:57:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch29_loss0.21258434653282166.pypots
2024-05-22 11:57:08 [INFO]: Epoch 030 - training loss: 0.2278, validation loss: 0.1896
2024-05-22 11:57:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch30_loss0.18958648666739464.pypots
2024-05-22 11:57:10 [INFO]: Epoch 031 - training loss: 0.2498, validation loss: 0.2022
2024-05-22 11:57:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch31_loss0.20217939093708992.pypots
2024-05-22 11:57:12 [INFO]: Epoch 032 - training loss: 0.2154, validation loss: 0.2211
2024-05-22 11:57:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch32_loss0.2210599109530449.pypots
2024-05-22 11:57:15 [INFO]: Epoch 033 - training loss: 0.2436, validation loss: 0.1934
2024-05-22 11:57:15 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch33_loss0.19335190579295158.pypots
2024-05-22 11:57:17 [INFO]: Epoch 034 - training loss: 0.2132, validation loss: 0.1992
2024-05-22 11:57:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch34_loss0.19918819516897202.pypots
2024-05-22 11:57:19 [INFO]: Epoch 035 - training loss: 0.1976, validation loss: 0.1779
2024-05-22 11:57:19 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch35_loss0.1778518259525299.pypots
2024-05-22 11:57:21 [INFO]: Epoch 036 - training loss: 0.2788, validation loss: 0.1771
2024-05-22 11:57:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch36_loss0.17708434537053108.pypots
2024-05-22 11:57:23 [INFO]: Epoch 037 - training loss: 0.2265, validation loss: 0.1919
2024-05-22 11:57:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch37_loss0.19187285751104355.pypots
2024-05-22 11:57:25 [INFO]: Epoch 038 - training loss: 0.2031, validation loss: 0.1904
2024-05-22 11:57:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch38_loss0.19044401496648788.pypots
2024-05-22 11:57:27 [INFO]: Epoch 039 - training loss: 0.2332, validation loss: 0.1697
2024-05-22 11:57:27 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch39_loss0.1696835458278656.pypots
2024-05-22 11:57:29 [INFO]: Epoch 040 - training loss: 0.1935, validation loss: 0.1697
2024-05-22 11:57:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch40_loss0.16970187053084373.pypots
2024-05-22 11:57:31 [INFO]: Epoch 041 - training loss: 0.1797, validation loss: 0.1700
2024-05-22 11:57:31 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch41_loss0.17004747316241264.pypots
2024-05-22 11:57:33 [INFO]: Epoch 042 - training loss: 0.1711, validation loss: 0.1596
2024-05-22 11:57:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch42_loss0.15955962985754013.pypots
2024-05-22 11:57:35 [INFO]: Epoch 043 - training loss: 0.1429, validation loss: 0.1586
2024-05-22 11:57:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch43_loss0.1586034819483757.pypots
2024-05-22 11:57:37 [INFO]: Epoch 044 - training loss: 0.2290, validation loss: 0.1620
2024-05-22 11:57:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch44_loss0.16204289719462395.pypots
2024-05-22 11:57:40 [INFO]: Epoch 045 - training loss: 0.1632, validation loss: 0.1591
2024-05-22 11:57:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch45_loss0.15910891816020012.pypots
2024-05-22 11:57:42 [INFO]: Epoch 046 - training loss: 0.1692, validation loss: 0.1579
2024-05-22 11:57:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch46_loss0.15786245837807655.pypots
2024-05-22 11:57:44 [INFO]: Epoch 047 - training loss: 0.1745, validation loss: 0.1537
2024-05-22 11:57:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch47_loss0.1536807231605053.pypots
2024-05-22 11:57:46 [INFO]: Epoch 048 - training loss: 0.2234, validation loss: 0.2946
2024-05-22 11:57:46 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch48_loss0.2945525124669075.pypots
2024-05-22 11:57:48 [INFO]: Epoch 049 - training loss: 0.3026, validation loss: 0.3029
2024-05-22 11:57:48 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch49_loss0.302949495613575.pypots
2024-05-22 11:57:50 [INFO]: Epoch 050 - training loss: 0.2486, validation loss: 0.2241
2024-05-22 11:57:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch50_loss0.22413412854075432.pypots
2024-05-22 11:57:52 [INFO]: Epoch 051 - training loss: 0.2104, validation loss: 0.1982
2024-05-22 11:57:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch51_loss0.19824892655014992.pypots
2024-05-22 11:57:54 [INFO]: Epoch 052 - training loss: 0.2266, validation loss: 0.1939
2024-05-22 11:57:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch52_loss0.1939171366393566.pypots
2024-05-22 11:57:56 [INFO]: Epoch 053 - training loss: 0.2161, validation loss: 0.2977
2024-05-22 11:57:56 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch53_loss0.29768017679452896.pypots
2024-05-22 11:57:58 [INFO]: Epoch 054 - training loss: 0.3425, validation loss: 0.3012
2024-05-22 11:57:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch54_loss0.30120015889406204.pypots
2024-05-22 11:58:00 [INFO]: Epoch 055 - training loss: 0.2468, validation loss: 0.2214
2024-05-22 11:58:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch55_loss0.22139829769730568.pypots
2024-05-22 11:58:03 [INFO]: Epoch 056 - training loss: 0.2116, validation loss: 0.1998
2024-05-22 11:58:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch56_loss0.19975411891937256.pypots
2024-05-22 11:58:05 [INFO]: Epoch 057 - training loss: 0.2309, validation loss: 0.1912
2024-05-22 11:58:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI_epoch57_loss0.19124263152480125.pypots
2024-05-22 11:58:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:58:05 [INFO]: Finished training. The best model is from epoch#47.
2024-05-22 11:58:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240522_T115605/CSDI.pypots
2024-05-22 11:58:20 [INFO]: CSDI on ETTm1: MAE=1.2337, MSE=20.0798
2024-05-22 11:58:21 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-22 11:58:21 [INFO]: Using the given device: cuda:0
2024-05-22 11:58:21 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240522_T115821
2024-05-22 11:58:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240522_T115821/tensorboard
2024-05-22 11:58:21 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 11:58:22 [INFO]: Epoch 001 - training loss: 23372.9945, validation loss: 0.9631
2024-05-22 11:58:22 [INFO]: Epoch 002 - training loss: 21213.6357, validation loss: 0.9650
2024-05-22 11:58:23 [INFO]: Epoch 003 - training loss: 19164.3870, validation loss: 0.9558
2024-05-22 11:58:23 [INFO]: Epoch 004 - training loss: 17332.0478, validation loss: 0.9386
2024-05-22 11:58:23 [INFO]: Epoch 005 - training loss: 15326.3969, validation loss: 0.9020
2024-05-22 11:58:23 [INFO]: Epoch 006 - training loss: 13715.2498, validation loss: 0.8150
2024-05-22 11:58:23 [INFO]: Epoch 007 - training loss: 12511.5613, validation loss: 0.6975
2024-05-22 11:58:23 [INFO]: Epoch 008 - training loss: 11735.2595, validation loss: 0.5890
2024-05-22 11:58:23 [INFO]: Epoch 009 - training loss: 11189.3895, validation loss: 0.4974
2024-05-22 11:58:24 [INFO]: Epoch 010 - training loss: 10949.1572, validation loss: 0.4645
2024-05-22 11:58:24 [INFO]: Epoch 011 - training loss: 10715.4984, validation loss: 0.4495
2024-05-22 11:58:24 [INFO]: Epoch 012 - training loss: 10334.3016, validation loss: 0.4244
2024-05-22 11:58:24 [INFO]: Epoch 013 - training loss: 10182.6780, validation loss: 0.4021
2024-05-22 11:58:24 [INFO]: Epoch 014 - training loss: 10084.4258, validation loss: 0.3793
2024-05-22 11:58:24 [INFO]: Epoch 015 - training loss: 10051.1740, validation loss: 0.3457
2024-05-22 11:58:24 [INFO]: Epoch 016 - training loss: 9888.8515, validation loss: 0.3271
2024-05-22 11:58:24 [INFO]: Epoch 017 - training loss: 9829.3104, validation loss: 0.3038
2024-05-22 11:58:25 [INFO]: Epoch 018 - training loss: 9771.0082, validation loss: 0.2875
2024-05-22 11:58:25 [INFO]: Epoch 019 - training loss: 9707.8672, validation loss: 0.2717
2024-05-22 11:58:25 [INFO]: Epoch 020 - training loss: 9661.0124, validation loss: 0.2614
2024-05-22 11:58:25 [INFO]: Epoch 021 - training loss: 9625.1139, validation loss: 0.2543
2024-05-22 11:58:25 [INFO]: Epoch 022 - training loss: 9594.0428, validation loss: 0.2452
2024-05-22 11:58:25 [INFO]: Epoch 023 - training loss: 9601.1414, validation loss: 0.2417
2024-05-22 11:58:25 [INFO]: Epoch 024 - training loss: 9542.6522, validation loss: 0.2330
2024-05-22 11:58:26 [INFO]: Epoch 025 - training loss: 9521.9347, validation loss: 0.2284
2024-05-22 11:58:26 [INFO]: Epoch 026 - training loss: 9512.1339, validation loss: 0.2206
2024-05-22 11:58:26 [INFO]: Epoch 027 - training loss: 9498.5570, validation loss: 0.2187
2024-05-22 11:58:26 [INFO]: Epoch 028 - training loss: 9488.9709, validation loss: 0.2154
2024-05-22 11:58:26 [INFO]: Epoch 029 - training loss: 9462.7781, validation loss: 0.2090
2024-05-22 11:58:26 [INFO]: Epoch 030 - training loss: 9457.4496, validation loss: 0.2056
2024-05-22 11:58:26 [INFO]: Epoch 031 - training loss: 9443.9563, validation loss: 0.2014
2024-05-22 11:58:26 [INFO]: Epoch 032 - training loss: 9434.9429, validation loss: 0.1940
2024-05-22 11:58:27 [INFO]: Epoch 033 - training loss: 9425.7721, validation loss: 0.1934
2024-05-22 11:58:27 [INFO]: Epoch 034 - training loss: 9417.9637, validation loss: 0.1915
2024-05-22 11:58:27 [INFO]: Epoch 035 - training loss: 9414.1410, validation loss: 0.1894
2024-05-22 11:58:27 [INFO]: Epoch 036 - training loss: 9413.4645, validation loss: 0.1842
2024-05-22 11:58:27 [INFO]: Epoch 037 - training loss: 9407.4114, validation loss: 0.1825
2024-05-22 11:58:27 [INFO]: Epoch 038 - training loss: 9400.1812, validation loss: 0.1776
2024-05-22 11:58:27 [INFO]: Epoch 039 - training loss: 9382.5587, validation loss: 0.1747
2024-05-22 11:58:28 [INFO]: Epoch 040 - training loss: 9378.8837, validation loss: 0.1726
2024-05-22 11:58:28 [INFO]: Epoch 041 - training loss: 9379.4397, validation loss: 0.1685
2024-05-22 11:58:28 [INFO]: Epoch 042 - training loss: 9369.7981, validation loss: 0.1671
2024-05-22 11:58:28 [INFO]: Epoch 043 - training loss: 9366.0130, validation loss: 0.1624
2024-05-22 11:58:28 [INFO]: Epoch 044 - training loss: 9367.0884, validation loss: 0.1573
2024-05-22 11:58:28 [INFO]: Epoch 045 - training loss: 9362.0861, validation loss: 0.1577
2024-05-22 11:58:28 [INFO]: Epoch 046 - training loss: 9354.9010, validation loss: 0.1544
2024-05-22 11:58:28 [INFO]: Epoch 047 - training loss: 9354.3229, validation loss: 0.1508
2024-05-22 11:58:29 [INFO]: Epoch 048 - training loss: 9354.9464, validation loss: 0.1511
2024-05-22 11:58:29 [INFO]: Epoch 049 - training loss: 9347.4535, validation loss: 0.1482
2024-05-22 11:58:29 [INFO]: Epoch 050 - training loss: 9346.9815, validation loss: 0.1442
2024-05-22 11:58:29 [INFO]: Epoch 051 - training loss: 9344.1674, validation loss: 0.1426
2024-05-22 11:58:29 [INFO]: Epoch 052 - training loss: 9340.5291, validation loss: 0.1389
2024-05-22 11:58:29 [INFO]: Epoch 053 - training loss: 9336.7579, validation loss: 0.1388
2024-05-22 11:58:29 [INFO]: Epoch 054 - training loss: 9335.6990, validation loss: 0.1366
2024-05-22 11:58:30 [INFO]: Epoch 055 - training loss: 9332.6078, validation loss: 0.1359
2024-05-22 11:58:30 [INFO]: Epoch 056 - training loss: 9331.6349, validation loss: 0.1362
2024-05-22 11:58:30 [INFO]: Epoch 057 - training loss: 9328.2719, validation loss: 0.1322
2024-05-22 11:58:30 [INFO]: Epoch 058 - training loss: 9333.6863, validation loss: 0.1323
2024-05-22 11:58:30 [INFO]: Epoch 059 - training loss: 9324.2532, validation loss: 0.1308
2024-05-22 11:58:30 [INFO]: Epoch 060 - training loss: 9323.9467, validation loss: 0.1284
2024-05-22 11:58:30 [INFO]: Epoch 061 - training loss: 9323.6863, validation loss: 0.1267
2024-05-22 11:58:30 [INFO]: Epoch 062 - training loss: 9320.5911, validation loss: 0.1260
2024-05-22 11:58:31 [INFO]: Epoch 063 - training loss: 9319.7913, validation loss: 0.1249
2024-05-22 11:58:31 [INFO]: Epoch 064 - training loss: 9317.2251, validation loss: 0.1242
2024-05-22 11:58:31 [INFO]: Epoch 065 - training loss: 9318.5585, validation loss: 0.1234
2024-05-22 11:58:31 [INFO]: Epoch 066 - training loss: 9315.0607, validation loss: 0.1225
2024-05-22 11:58:31 [INFO]: Epoch 067 - training loss: 9315.3026, validation loss: 0.1215
2024-05-22 11:58:31 [INFO]: Epoch 068 - training loss: 9312.6312, validation loss: 0.1198
2024-05-22 11:58:31 [INFO]: Epoch 069 - training loss: 9311.3666, validation loss: 0.1226
2024-05-22 11:58:31 [INFO]: Epoch 070 - training loss: 9321.6998, validation loss: 0.1187
2024-05-22 11:58:32 [INFO]: Epoch 071 - training loss: 9309.6628, validation loss: 0.1180
2024-05-22 11:58:32 [INFO]: Epoch 072 - training loss: 9309.6780, validation loss: 0.1182
2024-05-22 11:58:32 [INFO]: Epoch 073 - training loss: 9308.6044, validation loss: 0.1162
2024-05-22 11:58:32 [INFO]: Epoch 074 - training loss: 9307.6357, validation loss: 0.1174
2024-05-22 11:58:32 [INFO]: Epoch 075 - training loss: 9306.7587, validation loss: 0.1153
2024-05-22 11:58:32 [INFO]: Epoch 076 - training loss: 9304.7765, validation loss: 0.1135
2024-05-22 11:58:32 [INFO]: Epoch 077 - training loss: 9303.7661, validation loss: 0.1128
2024-05-22 11:58:33 [INFO]: Epoch 078 - training loss: 9304.1592, validation loss: 0.1124
2024-05-22 11:58:33 [INFO]: Epoch 079 - training loss: 9301.3763, validation loss: 0.1118
2024-05-22 11:58:33 [INFO]: Epoch 080 - training loss: 9302.5659, validation loss: 0.1104
2024-05-22 11:58:33 [INFO]: Epoch 081 - training loss: 9300.3546, validation loss: 0.1115
2024-05-22 11:58:33 [INFO]: Epoch 082 - training loss: 9300.6635, validation loss: 0.1092
2024-05-22 11:58:33 [INFO]: Epoch 083 - training loss: 9300.3386, validation loss: 0.1107
2024-05-22 11:58:33 [INFO]: Epoch 084 - training loss: 9301.6429, validation loss: 0.1091
2024-05-22 11:58:34 [INFO]: Epoch 085 - training loss: 9299.7231, validation loss: 0.1086
2024-05-22 11:58:34 [INFO]: Epoch 086 - training loss: 9299.7337, validation loss: 0.1092
2024-05-22 11:58:34 [INFO]: Epoch 087 - training loss: 9299.3609, validation loss: 0.1061
2024-05-22 11:58:34 [INFO]: Epoch 088 - training loss: 9297.0610, validation loss: 0.1054
2024-05-22 11:58:34 [INFO]: Epoch 089 - training loss: 9296.6677, validation loss: 0.1086
2024-05-22 11:58:34 [INFO]: Epoch 090 - training loss: 9296.3149, validation loss: 0.1045
2024-05-22 11:58:34 [INFO]: Epoch 091 - training loss: 9295.0134, validation loss: 0.1027
2024-05-22 11:58:34 [INFO]: Epoch 092 - training loss: 9294.6417, validation loss: 0.1031
2024-05-22 11:58:35 [INFO]: Epoch 093 - training loss: 9295.0733, validation loss: 0.1068
2024-05-22 11:58:35 [INFO]: Epoch 094 - training loss: 9293.2052, validation loss: 0.1025
2024-05-22 11:58:35 [INFO]: Epoch 095 - training loss: 9293.1177, validation loss: 0.1039
2024-05-22 11:58:35 [INFO]: Epoch 096 - training loss: 9292.9298, validation loss: 0.1003
2024-05-22 11:58:35 [INFO]: Epoch 097 - training loss: 9293.2599, validation loss: 0.1021
2024-05-22 11:58:35 [INFO]: Epoch 098 - training loss: 9291.4324, validation loss: 0.1016
2024-05-22 11:58:35 [INFO]: Epoch 099 - training loss: 9291.8467, validation loss: 0.1015
2024-05-22 11:58:36 [INFO]: Epoch 100 - training loss: 9292.5513, validation loss: 0.1000
2024-05-22 11:58:36 [INFO]: Epoch 101 - training loss: 9290.3684, validation loss: 0.0990
2024-05-22 11:58:36 [INFO]: Epoch 102 - training loss: 9292.5098, validation loss: 0.1008
2024-05-22 11:58:36 [INFO]: Epoch 103 - training loss: 9290.4498, validation loss: 0.0996
2024-05-22 11:58:36 [INFO]: Epoch 104 - training loss: 9288.4793, validation loss: 0.0992
2024-05-22 11:58:36 [INFO]: Epoch 105 - training loss: 9291.8364, validation loss: 0.0988
2024-05-22 11:58:36 [INFO]: Epoch 106 - training loss: 9288.7021, validation loss: 0.0963
2024-05-22 11:58:37 [INFO]: Epoch 107 - training loss: 9289.0970, validation loss: 0.0970
2024-05-22 11:58:37 [INFO]: Epoch 108 - training loss: 9290.0258, validation loss: 0.0981
2024-05-22 11:58:37 [INFO]: Epoch 109 - training loss: 9288.0898, validation loss: 0.0980
2024-05-22 11:58:37 [INFO]: Epoch 110 - training loss: 9287.2113, validation loss: 0.0953
2024-05-22 11:58:37 [INFO]: Epoch 111 - training loss: 9289.5858, validation loss: 0.0967
2024-05-22 11:58:37 [INFO]: Epoch 112 - training loss: 9287.1840, validation loss: 0.0956
2024-05-22 11:58:37 [INFO]: Epoch 113 - training loss: 9291.1802, validation loss: 0.0961
2024-05-22 11:58:37 [INFO]: Epoch 114 - training loss: 9287.5278, validation loss: 0.0940
2024-05-22 11:58:38 [INFO]: Epoch 115 - training loss: 9287.3264, validation loss: 0.0947
2024-05-22 11:58:38 [INFO]: Epoch 116 - training loss: 9285.7006, validation loss: 0.0926
2024-05-22 11:58:38 [INFO]: Epoch 117 - training loss: 9285.0533, validation loss: 0.0929
2024-05-22 11:58:38 [INFO]: Epoch 118 - training loss: 9284.8890, validation loss: 0.0928
2024-05-22 11:58:38 [INFO]: Epoch 119 - training loss: 9285.1533, validation loss: 0.0914
2024-05-22 11:58:38 [INFO]: Epoch 120 - training loss: 9285.4875, validation loss: 0.0924
2024-05-22 11:58:38 [INFO]: Epoch 121 - training loss: 9283.8046, validation loss: 0.0909
2024-05-22 11:58:39 [INFO]: Epoch 122 - training loss: 9284.3431, validation loss: 0.0906
2024-05-22 11:58:39 [INFO]: Epoch 123 - training loss: 9284.0762, validation loss: 0.0897
2024-05-22 11:58:39 [INFO]: Epoch 124 - training loss: 9283.1719, validation loss: 0.0907
2024-05-22 11:58:39 [INFO]: Epoch 125 - training loss: 9283.0077, validation loss: 0.0885
2024-05-22 11:58:39 [INFO]: Epoch 126 - training loss: 9284.3990, validation loss: 0.0899
2024-05-22 11:58:39 [INFO]: Epoch 127 - training loss: 9282.1924, validation loss: 0.0894
2024-05-22 11:58:39 [INFO]: Epoch 128 - training loss: 9282.3132, validation loss: 0.0878
2024-05-22 11:58:39 [INFO]: Epoch 129 - training loss: 9282.7745, validation loss: 0.0878
2024-05-22 11:58:40 [INFO]: Epoch 130 - training loss: 9283.0919, validation loss: 0.0876
2024-05-22 11:58:40 [INFO]: Epoch 131 - training loss: 9281.3834, validation loss: 0.0876
2024-05-22 11:58:40 [INFO]: Epoch 132 - training loss: 9282.5529, validation loss: 0.0869
2024-05-22 11:58:40 [INFO]: Epoch 133 - training loss: 9281.9294, validation loss: 0.0867
2024-05-22 11:58:40 [INFO]: Epoch 134 - training loss: 9281.0692, validation loss: 0.0854
2024-05-22 11:58:40 [INFO]: Epoch 135 - training loss: 9281.5377, validation loss: 0.0870
2024-05-22 11:58:40 [INFO]: Epoch 136 - training loss: 9279.3062, validation loss: 0.0875
2024-05-22 11:58:41 [INFO]: Epoch 137 - training loss: 9280.3534, validation loss: 0.0868
2024-05-22 11:58:41 [INFO]: Epoch 138 - training loss: 9280.9533, validation loss: 0.0858
2024-05-22 11:58:41 [INFO]: Epoch 139 - training loss: 9279.2269, validation loss: 0.0860
2024-05-22 11:58:41 [INFO]: Epoch 140 - training loss: 9280.6152, validation loss: 0.0868
2024-05-22 11:58:41 [INFO]: Epoch 141 - training loss: 9281.0341, validation loss: 0.0857
2024-05-22 11:58:41 [INFO]: Epoch 142 - training loss: 9279.9907, validation loss: 0.0874
2024-05-22 11:58:41 [INFO]: Epoch 143 - training loss: 9278.2858, validation loss: 0.0853
2024-05-22 11:58:42 [INFO]: Epoch 144 - training loss: 9280.2811, validation loss: 0.0849
2024-05-22 11:58:42 [INFO]: Epoch 145 - training loss: 9282.3447, validation loss: 0.0843
2024-05-22 11:58:42 [INFO]: Epoch 146 - training loss: 9279.9602, validation loss: 0.0856
2024-05-22 11:58:42 [INFO]: Epoch 147 - training loss: 9279.7986, validation loss: 0.0831
2024-05-22 11:58:42 [INFO]: Epoch 148 - training loss: 9280.0365, validation loss: 0.0839
2024-05-22 11:58:42 [INFO]: Epoch 149 - training loss: 9279.3758, validation loss: 0.0819
2024-05-22 11:58:42 [INFO]: Epoch 150 - training loss: 9278.3704, validation loss: 0.0849
2024-05-22 11:58:42 [INFO]: Epoch 151 - training loss: 9276.2199, validation loss: 0.0821
2024-05-22 11:58:43 [INFO]: Epoch 152 - training loss: 9277.7842, validation loss: 0.0835
2024-05-22 11:58:43 [INFO]: Epoch 153 - training loss: 9278.2314, validation loss: 0.0837
2024-05-22 11:58:43 [INFO]: Epoch 154 - training loss: 9276.7036, validation loss: 0.0820
2024-05-22 11:58:43 [INFO]: Epoch 155 - training loss: 9276.9012, validation loss: 0.0839
2024-05-22 11:58:43 [INFO]: Epoch 156 - training loss: 9277.9553, validation loss: 0.0820
2024-05-22 11:58:43 [INFO]: Epoch 157 - training loss: 9278.8076, validation loss: 0.0826
2024-05-22 11:58:43 [INFO]: Epoch 158 - training loss: 9278.2027, validation loss: 0.0808
2024-05-22 11:58:44 [INFO]: Epoch 159 - training loss: 9276.3480, validation loss: 0.0830
2024-05-22 11:58:44 [INFO]: Epoch 160 - training loss: 9279.3278, validation loss: 0.0815
2024-05-22 11:58:44 [INFO]: Epoch 161 - training loss: 9276.7272, validation loss: 0.0811
2024-05-22 11:58:44 [INFO]: Epoch 162 - training loss: 9276.1306, validation loss: 0.0808
2024-05-22 11:58:44 [INFO]: Epoch 163 - training loss: 9275.7802, validation loss: 0.0811
2024-05-22 11:58:44 [INFO]: Epoch 164 - training loss: 9276.7648, validation loss: 0.0815
2024-05-22 11:58:44 [INFO]: Epoch 165 - training loss: 9276.6805, validation loss: 0.0795
2024-05-22 11:58:44 [INFO]: Epoch 166 - training loss: 9275.6139, validation loss: 0.0815
2024-05-22 11:58:45 [INFO]: Epoch 167 - training loss: 9276.0287, validation loss: 0.0801
2024-05-22 11:58:45 [INFO]: Epoch 168 - training loss: 9274.3946, validation loss: 0.0805
2024-05-22 11:58:45 [INFO]: Epoch 169 - training loss: 9278.1630, validation loss: 0.0811
2024-05-22 11:58:45 [INFO]: Epoch 170 - training loss: 9275.8425, validation loss: 0.0797
2024-05-22 11:58:45 [INFO]: Epoch 171 - training loss: 9276.4349, validation loss: 0.0811
2024-05-22 11:58:45 [INFO]: Epoch 172 - training loss: 9275.8768, validation loss: 0.0801
2024-05-22 11:58:45 [INFO]: Epoch 173 - training loss: 9275.3868, validation loss: 0.0784
2024-05-22 11:58:46 [INFO]: Epoch 174 - training loss: 9275.5606, validation loss: 0.0796
2024-05-22 11:58:46 [INFO]: Epoch 175 - training loss: 9275.5416, validation loss: 0.0785
2024-05-22 11:58:46 [INFO]: Epoch 176 - training loss: 9275.0292, validation loss: 0.0782
2024-05-22 11:58:46 [INFO]: Epoch 177 - training loss: 9274.4992, validation loss: 0.0800
2024-05-22 11:58:46 [INFO]: Epoch 178 - training loss: 9274.6688, validation loss: 0.0795
2024-05-22 11:58:46 [INFO]: Epoch 179 - training loss: 9275.5752, validation loss: 0.0777
2024-05-22 11:58:46 [INFO]: Epoch 180 - training loss: 9275.6226, validation loss: 0.0800
2024-05-22 11:58:47 [INFO]: Epoch 181 - training loss: 9273.9890, validation loss: 0.0791
2024-05-22 11:58:47 [INFO]: Epoch 182 - training loss: 9274.4897, validation loss: 0.0773
2024-05-22 11:58:47 [INFO]: Epoch 183 - training loss: 9273.1412, validation loss: 0.0787
2024-05-22 11:58:47 [INFO]: Epoch 184 - training loss: 9273.9171, validation loss: 0.0780
2024-05-22 11:58:47 [INFO]: Epoch 185 - training loss: 9273.6174, validation loss: 0.0779
2024-05-22 11:58:47 [INFO]: Epoch 186 - training loss: 9274.9574, validation loss: 0.0785
2024-05-22 11:58:47 [INFO]: Epoch 187 - training loss: 9273.9487, validation loss: 0.0767
2024-05-22 11:58:47 [INFO]: Epoch 188 - training loss: 9276.0340, validation loss: 0.0770
2024-05-22 11:58:48 [INFO]: Epoch 189 - training loss: 9274.1212, validation loss: 0.0776
2024-05-22 11:58:48 [INFO]: Epoch 190 - training loss: 9272.5424, validation loss: 0.0769
2024-05-22 11:58:48 [INFO]: Epoch 191 - training loss: 9273.2648, validation loss: 0.0781
2024-05-22 11:58:48 [INFO]: Epoch 192 - training loss: 9275.7322, validation loss: 0.0782
2024-05-22 11:58:48 [INFO]: Epoch 193 - training loss: 9272.7242, validation loss: 0.0788
2024-05-22 11:58:48 [INFO]: Epoch 194 - training loss: 9273.6185, validation loss: 0.0786
2024-05-22 11:58:48 [INFO]: Epoch 195 - training loss: 9273.2698, validation loss: 0.0773
2024-05-22 11:58:48 [INFO]: Epoch 196 - training loss: 9274.4963, validation loss: 0.0789
2024-05-22 11:58:49 [INFO]: Epoch 197 - training loss: 9273.8140, validation loss: 0.0774
2024-05-22 11:58:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:58:49 [INFO]: Finished training. The best model is from epoch#187.
2024-05-22 11:58:49 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_ettm1/20240522_T115821/GPVAE.pypots
2024-05-22 11:58:49 [INFO]: GP-VAE on ETTm1: MAE=0.2701, MSE=0.1535
2024-05-22 11:58:49 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-22 11:58:49 [INFO]: Using the given device: cuda:0
2024-05-22 11:58:49 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240522_T115849
2024-05-22 11:58:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240522_T115849/tensorboard
2024-05-22 11:58:49 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 11:59:00 [INFO]: Epoch 001 - generator training loss: 0.4838, discriminator training loss: 0.4256, validation loss: 0.3237
2024-05-22 11:59:09 [INFO]: Epoch 002 - generator training loss: 0.1027, discriminator training loss: 0.3213, validation loss: 0.1122
2024-05-22 11:59:18 [INFO]: Epoch 003 - generator training loss: -0.1186, discriminator training loss: 0.3130, validation loss: 0.0691
2024-05-22 11:59:27 [INFO]: Epoch 004 - generator training loss: -0.1366, discriminator training loss: 0.2980, validation loss: 0.0551
2024-05-22 11:59:36 [INFO]: Epoch 005 - generator training loss: -0.1323, discriminator training loss: 0.2826, validation loss: 0.0463
2024-05-22 11:59:44 [INFO]: Epoch 006 - generator training loss: -0.1176, discriminator training loss: 0.2553, validation loss: 0.0425
2024-05-22 11:59:53 [INFO]: Epoch 007 - generator training loss: -0.0959, discriminator training loss: 0.2239, validation loss: 0.0441
2024-05-22 12:00:02 [INFO]: Epoch 008 - generator training loss: -0.0668, discriminator training loss: 0.1913, validation loss: 0.0405
2024-05-22 12:00:11 [INFO]: Epoch 009 - generator training loss: -0.0548, discriminator training loss: 0.1648, validation loss: 0.0385
2024-05-22 12:00:19 [INFO]: Epoch 010 - generator training loss: -0.0439, discriminator training loss: 0.1455, validation loss: 0.0368
2024-05-22 12:00:28 [INFO]: Epoch 011 - generator training loss: -0.0384, discriminator training loss: 0.1353, validation loss: 0.0356
2024-05-22 12:00:37 [INFO]: Epoch 012 - generator training loss: -0.0398, discriminator training loss: 0.1288, validation loss: 0.0348
2024-05-22 12:00:46 [INFO]: Epoch 013 - generator training loss: -0.0367, discriminator training loss: 0.1244, validation loss: 0.0342
2024-05-22 12:00:54 [INFO]: Epoch 014 - generator training loss: -0.0383, discriminator training loss: 0.1227, validation loss: 0.0333
2024-05-22 12:01:03 [INFO]: Epoch 015 - generator training loss: -0.0393, discriminator training loss: 0.1204, validation loss: 0.0331
2024-05-22 12:01:12 [INFO]: Epoch 016 - generator training loss: -0.0399, discriminator training loss: 0.1186, validation loss: 0.0327
2024-05-22 12:01:21 [INFO]: Epoch 017 - generator training loss: -0.0387, discriminator training loss: 0.1190, validation loss: 0.0319
2024-05-22 12:01:30 [INFO]: Epoch 018 - generator training loss: -0.0379, discriminator training loss: 0.1182, validation loss: 0.0317
2024-05-22 12:01:38 [INFO]: Epoch 019 - generator training loss: -0.0377, discriminator training loss: 0.1168, validation loss: 0.0314
2024-05-22 12:01:47 [INFO]: Epoch 020 - generator training loss: -0.0353, discriminator training loss: 0.1155, validation loss: 0.0317
2024-05-22 12:01:56 [INFO]: Epoch 021 - generator training loss: -0.0382, discriminator training loss: 0.1156, validation loss: 0.0312
2024-05-22 12:02:05 [INFO]: Epoch 022 - generator training loss: -0.0380, discriminator training loss: 0.1152, validation loss: 0.0312
2024-05-22 12:02:14 [INFO]: Epoch 023 - generator training loss: -0.0381, discriminator training loss: 0.1152, validation loss: 0.0374
2024-05-22 12:02:23 [INFO]: Epoch 024 - generator training loss: -0.0332, discriminator training loss: 0.1163, validation loss: 0.0314
2024-05-22 12:02:31 [INFO]: Epoch 025 - generator training loss: -0.0410, discriminator training loss: 0.1159, validation loss: 0.0310
2024-05-22 12:02:40 [INFO]: Epoch 026 - generator training loss: -0.0414, discriminator training loss: 0.1149, validation loss: 0.0299
2024-05-22 12:02:49 [INFO]: Epoch 027 - generator training loss: -0.0414, discriminator training loss: 0.1125, validation loss: 0.0286
2024-05-22 12:02:58 [INFO]: Epoch 028 - generator training loss: -0.0407, discriminator training loss: 0.1134, validation loss: 0.0283
2024-05-22 12:03:06 [INFO]: Epoch 029 - generator training loss: -0.0398, discriminator training loss: 0.1123, validation loss: 0.0281
2024-05-22 12:03:15 [INFO]: Epoch 030 - generator training loss: -0.0395, discriminator training loss: 0.1122, validation loss: 0.0280
2024-05-22 12:03:24 [INFO]: Epoch 031 - generator training loss: -0.0411, discriminator training loss: 0.1114, validation loss: 0.0277
2024-05-22 12:03:33 [INFO]: Epoch 032 - generator training loss: -0.0442, discriminator training loss: 0.1104, validation loss: 0.0272
2024-05-22 12:03:41 [INFO]: Epoch 033 - generator training loss: -0.0416, discriminator training loss: 0.1108, validation loss: 0.0269
2024-05-22 12:03:50 [INFO]: Epoch 034 - generator training loss: -0.0440, discriminator training loss: 0.1120, validation loss: 0.0264
2024-05-22 12:03:59 [INFO]: Epoch 035 - generator training loss: -0.0426, discriminator training loss: 0.1118, validation loss: 0.0266
2024-05-22 12:04:08 [INFO]: Epoch 036 - generator training loss: -0.0429, discriminator training loss: 0.1129, validation loss: 0.0264
2024-05-22 12:04:17 [INFO]: Epoch 037 - generator training loss: -0.0434, discriminator training loss: 0.1111, validation loss: 0.0259
2024-05-22 12:04:25 [INFO]: Epoch 038 - generator training loss: -0.0438, discriminator training loss: 0.1102, validation loss: 0.0258
2024-05-22 12:04:34 [INFO]: Epoch 039 - generator training loss: -0.0432, discriminator training loss: 0.1106, validation loss: 0.0265
2024-05-22 12:04:43 [INFO]: Epoch 040 - generator training loss: -0.0429, discriminator training loss: 0.1110, validation loss: 0.0255
2024-05-22 12:04:52 [INFO]: Epoch 041 - generator training loss: -0.0435, discriminator training loss: 0.1100, validation loss: 0.0257
2024-05-22 12:05:01 [INFO]: Epoch 042 - generator training loss: -0.0456, discriminator training loss: 0.1139, validation loss: 0.0250
2024-05-22 12:05:10 [INFO]: Epoch 043 - generator training loss: -0.0425, discriminator training loss: 0.1092, validation loss: 0.0250
2024-05-22 12:05:18 [INFO]: Epoch 044 - generator training loss: -0.0446, discriminator training loss: 0.1099, validation loss: 0.0260
2024-05-22 12:05:27 [INFO]: Epoch 045 - generator training loss: -0.0420, discriminator training loss: 0.1100, validation loss: 0.0252
2024-05-22 12:05:36 [INFO]: Epoch 046 - generator training loss: -0.0424, discriminator training loss: 0.1107, validation loss: 0.0249
2024-05-22 12:05:45 [INFO]: Epoch 047 - generator training loss: -0.0441, discriminator training loss: 0.1080, validation loss: 0.0249
2024-05-22 12:05:54 [INFO]: Epoch 048 - generator training loss: -0.0463, discriminator training loss: 0.1097, validation loss: 0.0245
2024-05-22 12:06:02 [INFO]: Epoch 049 - generator training loss: -0.0459, discriminator training loss: 0.1100, validation loss: 0.0243
2024-05-22 12:06:11 [INFO]: Epoch 050 - generator training loss: -0.0462, discriminator training loss: 0.1087, validation loss: 0.0241
2024-05-22 12:06:20 [INFO]: Epoch 051 - generator training loss: -0.0458, discriminator training loss: 0.1101, validation loss: 0.0246
2024-05-22 12:06:29 [INFO]: Epoch 052 - generator training loss: -0.0446, discriminator training loss: 0.1087, validation loss: 0.0242
2024-05-22 12:06:37 [INFO]: Epoch 053 - generator training loss: -0.0461, discriminator training loss: 0.1080, validation loss: 0.0242
2024-05-22 12:06:46 [INFO]: Epoch 054 - generator training loss: -0.0432, discriminator training loss: 0.1088, validation loss: 0.0239
2024-05-22 12:06:55 [INFO]: Epoch 055 - generator training loss: -0.0444, discriminator training loss: 0.1096, validation loss: 0.0242
2024-05-22 12:07:04 [INFO]: Epoch 056 - generator training loss: -0.0449, discriminator training loss: 0.1082, validation loss: 0.0245
2024-05-22 12:07:12 [INFO]: Epoch 057 - generator training loss: -0.0452, discriminator training loss: 0.1084, validation loss: 0.0248
2024-05-22 12:07:21 [INFO]: Epoch 058 - generator training loss: -0.0445, discriminator training loss: 0.1090, validation loss: 0.0240
2024-05-22 12:07:30 [INFO]: Epoch 059 - generator training loss: -0.0431, discriminator training loss: 0.1065, validation loss: 0.0239
2024-05-22 12:07:39 [INFO]: Epoch 060 - generator training loss: -0.0462, discriminator training loss: 0.1087, validation loss: 0.0238
2024-05-22 12:07:48 [INFO]: Epoch 061 - generator training loss: -0.0409, discriminator training loss: 0.1094, validation loss: 0.0236
2024-05-22 12:07:57 [INFO]: Epoch 062 - generator training loss: -0.0429, discriminator training loss: 0.1097, validation loss: 0.0243
2024-05-22 12:08:05 [INFO]: Epoch 063 - generator training loss: -0.0478, discriminator training loss: 0.1077, validation loss: 0.0237
2024-05-22 12:08:14 [INFO]: Epoch 064 - generator training loss: -0.0459, discriminator training loss: 0.1089, validation loss: 0.0238
2024-05-22 12:08:23 [INFO]: Epoch 065 - generator training loss: -0.0467, discriminator training loss: 0.1089, validation loss: 0.0230
2024-05-22 12:08:32 [INFO]: Epoch 066 - generator training loss: -0.0456, discriminator training loss: 0.1093, validation loss: 0.0239
2024-05-22 12:08:41 [INFO]: Epoch 067 - generator training loss: -0.0455, discriminator training loss: 0.1081, validation loss: 0.0236
2024-05-22 12:08:50 [INFO]: Epoch 068 - generator training loss: -0.0437, discriminator training loss: 0.1067, validation loss: 0.0230
2024-05-22 12:08:58 [INFO]: Epoch 069 - generator training loss: -0.0469, discriminator training loss: 0.1080, validation loss: 0.0229
2024-05-22 12:09:07 [INFO]: Epoch 070 - generator training loss: -0.0459, discriminator training loss: 0.1077, validation loss: 0.0228
2024-05-22 12:09:16 [INFO]: Epoch 071 - generator training loss: -0.0452, discriminator training loss: 0.1073, validation loss: 0.0226
2024-05-22 12:09:25 [INFO]: Epoch 072 - generator training loss: -0.0458, discriminator training loss: 0.1063, validation loss: 0.0233
2024-05-22 12:09:33 [INFO]: Epoch 073 - generator training loss: -0.0461, discriminator training loss: 0.1080, validation loss: 0.0231
2024-05-22 12:09:42 [INFO]: Epoch 074 - generator training loss: -0.0462, discriminator training loss: 0.1072, validation loss: 0.0231
2024-05-22 12:09:51 [INFO]: Epoch 075 - generator training loss: -0.0475, discriminator training loss: 0.1069, validation loss: 0.0228
2024-05-22 12:10:00 [INFO]: Epoch 076 - generator training loss: -0.0472, discriminator training loss: 0.1080, validation loss: 0.0229
2024-05-22 12:10:08 [INFO]: Epoch 077 - generator training loss: -0.0489, discriminator training loss: 0.1087, validation loss: 0.0230
2024-05-22 12:10:17 [INFO]: Epoch 078 - generator training loss: -0.0427, discriminator training loss: 0.1068, validation loss: 0.0228
2024-05-22 12:10:26 [INFO]: Epoch 079 - generator training loss: -0.0480, discriminator training loss: 0.1093, validation loss: 0.0228
2024-05-22 12:10:35 [INFO]: Epoch 080 - generator training loss: -0.0462, discriminator training loss: 0.1060, validation loss: 0.0226
2024-05-22 12:10:44 [INFO]: Epoch 081 - generator training loss: -0.0474, discriminator training loss: 0.1060, validation loss: 0.0229
2024-05-22 12:10:52 [INFO]: Epoch 082 - generator training loss: -0.0482, discriminator training loss: 0.1062, validation loss: 0.0228
2024-05-22 12:11:01 [INFO]: Epoch 083 - generator training loss: -0.0480, discriminator training loss: 0.1070, validation loss: 0.0225
2024-05-22 12:11:10 [INFO]: Epoch 084 - generator training loss: -0.0466, discriminator training loss: 0.1057, validation loss: 0.0223
2024-05-22 12:11:19 [INFO]: Epoch 085 - generator training loss: -0.0454, discriminator training loss: 0.1061, validation loss: 0.0225
2024-05-22 12:11:28 [INFO]: Epoch 086 - generator training loss: -0.0465, discriminator training loss: 0.1061, validation loss: 0.0223
2024-05-22 12:11:37 [INFO]: Epoch 087 - generator training loss: -0.0467, discriminator training loss: 0.1082, validation loss: 0.0223
2024-05-22 12:11:45 [INFO]: Epoch 088 - generator training loss: -0.0456, discriminator training loss: 0.1046, validation loss: 0.0229
2024-05-22 12:11:54 [INFO]: Epoch 089 - generator training loss: -0.0482, discriminator training loss: 0.1055, validation loss: 0.0224
2024-05-22 12:12:03 [INFO]: Epoch 090 - generator training loss: -0.0461, discriminator training loss: 0.1076, validation loss: 0.0220
2024-05-22 12:12:12 [INFO]: Epoch 091 - generator training loss: -0.0485, discriminator training loss: 0.1060, validation loss: 0.0226
2024-05-22 12:12:20 [INFO]: Epoch 092 - generator training loss: -0.0472, discriminator training loss: 0.1042, validation loss: 0.0222
2024-05-22 12:12:29 [INFO]: Epoch 093 - generator training loss: -0.0468, discriminator training loss: 0.1049, validation loss: 0.0221
2024-05-22 12:12:38 [INFO]: Epoch 094 - generator training loss: -0.0453, discriminator training loss: 0.1060, validation loss: 0.0249
2024-05-22 12:12:47 [INFO]: Epoch 095 - generator training loss: -0.0445, discriminator training loss: 0.1039, validation loss: 0.0225
2024-05-22 12:12:56 [INFO]: Epoch 096 - generator training loss: -0.0479, discriminator training loss: 0.1075, validation loss: 0.0231
2024-05-22 12:13:04 [INFO]: Epoch 097 - generator training loss: -0.0448, discriminator training loss: 0.1046, validation loss: 0.0224
2024-05-22 12:13:13 [INFO]: Epoch 098 - generator training loss: -0.0478, discriminator training loss: 0.1047, validation loss: 0.0225
2024-05-22 12:13:22 [INFO]: Epoch 099 - generator training loss: -0.0459, discriminator training loss: 0.1062, validation loss: 0.0221
2024-05-22 12:13:31 [INFO]: Epoch 100 - generator training loss: -0.0463, discriminator training loss: 0.1032, validation loss: 0.0226
2024-05-22 12:13:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:13:31 [INFO]: Finished training. The best model is from epoch#90.
2024-05-22 12:13:31 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_ettm1/20240522_T115849/USGAN.pypots
2024-05-22 12:13:32 [INFO]: US-GAN on ETTm1: MAE=0.1453, MSE=0.0590
2024-05-22 12:13:32 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-22 12:13:32 [INFO]: Using the given device: cuda:0
2024-05-22 12:13:32 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240522_T121332
2024-05-22 12:13:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240522_T121332/tensorboard
2024-05-22 12:13:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 12:13:39 [INFO]: Epoch 001 - training loss: 1.2790, validation loss: 0.3338
2024-05-22 12:13:45 [INFO]: Epoch 002 - training loss: 0.8334, validation loss: 0.0904
2024-05-22 12:13:51 [INFO]: Epoch 003 - training loss: 0.6558, validation loss: 0.0550
2024-05-22 12:13:57 [INFO]: Epoch 004 - training loss: 0.6041, validation loss: 0.0430
2024-05-22 12:14:03 [INFO]: Epoch 005 - training loss: 0.5718, validation loss: 0.0405
2024-05-22 12:14:09 [INFO]: Epoch 006 - training loss: 0.5368, validation loss: 0.0409
2024-05-22 12:14:15 [INFO]: Epoch 007 - training loss: 0.5036, validation loss: 0.0352
2024-05-22 12:14:21 [INFO]: Epoch 008 - training loss: 0.4829, validation loss: 0.0334
2024-05-22 12:14:26 [INFO]: Epoch 009 - training loss: 0.4632, validation loss: 0.0313
2024-05-22 12:14:32 [INFO]: Epoch 010 - training loss: 0.4355, validation loss: 0.0292
2024-05-22 12:14:38 [INFO]: Epoch 011 - training loss: 0.4284, validation loss: 0.0283
2024-05-22 12:14:44 [INFO]: Epoch 012 - training loss: 0.4174, validation loss: 0.0280
2024-05-22 12:14:50 [INFO]: Epoch 013 - training loss: 0.4286, validation loss: 0.0284
2024-05-22 12:14:56 [INFO]: Epoch 014 - training loss: 0.4102, validation loss: 0.0265
2024-05-22 12:15:02 [INFO]: Epoch 015 - training loss: 0.4018, validation loss: 0.0264
2024-05-22 12:15:08 [INFO]: Epoch 016 - training loss: 0.4000, validation loss: 0.0259
2024-05-22 12:15:14 [INFO]: Epoch 017 - training loss: 0.4060, validation loss: 0.0261
2024-05-22 12:15:19 [INFO]: Epoch 018 - training loss: 0.3998, validation loss: 0.0265
2024-05-22 12:15:25 [INFO]: Epoch 019 - training loss: 0.4055, validation loss: 0.0259
2024-05-22 12:15:31 [INFO]: Epoch 020 - training loss: 0.3987, validation loss: 0.0255
2024-05-22 12:15:37 [INFO]: Epoch 021 - training loss: 0.3959, validation loss: 0.0262
2024-05-22 12:15:43 [INFO]: Epoch 022 - training loss: 0.3976, validation loss: 0.0253
2024-05-22 12:15:49 [INFO]: Epoch 023 - training loss: 0.3859, validation loss: 0.0248
2024-05-22 12:15:55 [INFO]: Epoch 024 - training loss: 0.3870, validation loss: 0.0248
2024-05-22 12:16:01 [INFO]: Epoch 025 - training loss: 0.3841, validation loss: 0.0254
2024-05-22 12:16:06 [INFO]: Epoch 026 - training loss: 0.3831, validation loss: 0.0249
2024-05-22 12:16:12 [INFO]: Epoch 027 - training loss: 0.3876, validation loss: 0.0250
2024-05-22 12:16:18 [INFO]: Epoch 028 - training loss: 0.3828, validation loss: 0.0244
2024-05-22 12:16:24 [INFO]: Epoch 029 - training loss: 0.3815, validation loss: 0.0251
2024-05-22 12:16:30 [INFO]: Epoch 030 - training loss: 0.3921, validation loss: 0.0248
2024-05-22 12:16:36 [INFO]: Epoch 031 - training loss: 0.3839, validation loss: 0.0256
2024-05-22 12:16:42 [INFO]: Epoch 032 - training loss: 0.3888, validation loss: 0.0245
2024-05-22 12:16:48 [INFO]: Epoch 033 - training loss: 0.3877, validation loss: 0.0245
2024-05-22 12:16:53 [INFO]: Epoch 034 - training loss: 0.3833, validation loss: 0.0245
2024-05-22 12:16:59 [INFO]: Epoch 035 - training loss: 0.3837, validation loss: 0.0246
2024-05-22 12:17:05 [INFO]: Epoch 036 - training loss: 0.3787, validation loss: 0.0248
2024-05-22 12:17:11 [INFO]: Epoch 037 - training loss: 0.3839, validation loss: 0.0245
2024-05-22 12:17:17 [INFO]: Epoch 038 - training loss: 0.3797, validation loss: 0.0247
2024-05-22 12:17:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:17:17 [INFO]: Finished training. The best model is from epoch#28.
2024-05-22 12:17:17 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_ettm1/20240522_T121332/BRITS.pypots
2024-05-22 12:17:18 [INFO]: BRITS on ETTm1: MAE=0.1334, MSE=0.0523
2024-05-22 12:17:18 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-22 12:17:18 [INFO]: Using the given device: cuda:0
2024-05-22 12:17:18 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718
2024-05-22 12:17:18 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/tensorboard
2024-05-22 12:17:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 12:17:20 [INFO]: Epoch 001 - training loss: 1.3483, validation loss: 1.2688
2024-05-22 12:17:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch1_loss1.2688153684139252.pypots
2024-05-22 12:17:20 [INFO]: Epoch 002 - training loss: 1.0606, validation loss: 1.1066
2024-05-22 12:17:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch2_loss1.1065560281276703.pypots
2024-05-22 12:17:20 [INFO]: Epoch 003 - training loss: 1.0036, validation loss: 1.0437
2024-05-22 12:17:20 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch3_loss1.0436531752347946.pypots
2024-05-22 12:17:21 [INFO]: Epoch 004 - training loss: 0.9461, validation loss: 1.0265
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch4_loss1.0265273749828339.pypots
2024-05-22 12:17:21 [INFO]: Epoch 005 - training loss: 0.9583, validation loss: 1.0204
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch5_loss1.0203860849142075.pypots
2024-05-22 12:17:21 [INFO]: Epoch 006 - training loss: 0.9274, validation loss: 1.0076
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch6_loss1.0076097249984741.pypots
2024-05-22 12:17:21 [INFO]: Epoch 007 - training loss: 0.9188, validation loss: 1.0033
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch7_loss1.0032681673765182.pypots
2024-05-22 12:17:21 [INFO]: Epoch 008 - training loss: 0.8859, validation loss: 0.9969
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch8_loss0.9969445466995239.pypots
2024-05-22 12:17:21 [INFO]: Epoch 009 - training loss: 0.9272, validation loss: 0.9933
2024-05-22 12:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch9_loss0.9933347254991531.pypots
2024-05-22 12:17:22 [INFO]: Epoch 010 - training loss: 0.8931, validation loss: 0.9906
2024-05-22 12:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch10_loss0.9906185865402222.pypots
2024-05-22 12:17:22 [INFO]: Epoch 011 - training loss: 0.9170, validation loss: 0.9865
2024-05-22 12:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch11_loss0.9864848703145981.pypots
2024-05-22 12:17:22 [INFO]: Epoch 012 - training loss: 0.8933, validation loss: 0.9831
2024-05-22 12:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch12_loss0.9830868095159531.pypots
2024-05-22 12:17:22 [INFO]: Epoch 013 - training loss: 0.8890, validation loss: 0.9822
2024-05-22 12:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch13_loss0.9822242558002472.pypots
2024-05-22 12:17:22 [INFO]: Epoch 014 - training loss: 0.8614, validation loss: 0.9802
2024-05-22 12:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch14_loss0.9801903516054153.pypots
2024-05-22 12:17:23 [INFO]: Epoch 015 - training loss: 0.8884, validation loss: 0.9798
2024-05-22 12:17:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch15_loss0.9798312187194824.pypots
2024-05-22 12:17:23 [INFO]: Epoch 016 - training loss: 0.9014, validation loss: 0.9796
2024-05-22 12:17:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch16_loss0.9796031713485718.pypots
2024-05-22 12:17:23 [INFO]: Epoch 017 - training loss: 0.8622, validation loss: 0.9741
2024-05-22 12:17:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch17_loss0.9740772098302841.pypots
2024-05-22 12:17:23 [INFO]: Epoch 018 - training loss: 0.8665, validation loss: 0.9697
2024-05-22 12:17:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch18_loss0.9696662724018097.pypots
2024-05-22 12:17:23 [INFO]: Epoch 019 - training loss: 0.8575, validation loss: 0.9667
2024-05-22 12:17:23 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch19_loss0.9667286574840546.pypots
2024-05-22 12:17:24 [INFO]: Epoch 020 - training loss: 0.8365, validation loss: 0.9640
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch20_loss0.9640454947948456.pypots
2024-05-22 12:17:24 [INFO]: Epoch 021 - training loss: 0.8370, validation loss: 0.9614
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch21_loss0.9613775163888931.pypots
2024-05-22 12:17:24 [INFO]: Epoch 022 - training loss: 0.8260, validation loss: 0.9598
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch22_loss0.9598157852888107.pypots
2024-05-22 12:17:24 [INFO]: Epoch 023 - training loss: 0.8228, validation loss: 0.9578
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch23_loss0.9577910304069519.pypots
2024-05-22 12:17:24 [INFO]: Epoch 024 - training loss: 0.8397, validation loss: 0.9548
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch24_loss0.9547712802886963.pypots
2024-05-22 12:17:24 [INFO]: Epoch 025 - training loss: 0.8428, validation loss: 0.9552
2024-05-22 12:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch25_loss0.9552175253629684.pypots
2024-05-22 12:17:25 [INFO]: Epoch 026 - training loss: 0.8334, validation loss: 0.9552
2024-05-22 12:17:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch26_loss0.9552163332700729.pypots
2024-05-22 12:17:25 [INFO]: Epoch 027 - training loss: 0.8096, validation loss: 0.9504
2024-05-22 12:17:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch27_loss0.9503784477710724.pypots
2024-05-22 12:17:25 [INFO]: Epoch 028 - training loss: 0.8309, validation loss: 0.9498
2024-05-22 12:17:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch28_loss0.9497537016868591.pypots
2024-05-22 12:17:25 [INFO]: Epoch 029 - training loss: 0.8380, validation loss: 0.9479
2024-05-22 12:17:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch29_loss0.9479068666696548.pypots
2024-05-22 12:17:25 [INFO]: Epoch 030 - training loss: 0.8359, validation loss: 0.9445
2024-05-22 12:17:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch30_loss0.9444701969623566.pypots
2024-05-22 12:17:26 [INFO]: Epoch 031 - training loss: 0.8200, validation loss: 0.9445
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch31_loss0.9445060789585114.pypots
2024-05-22 12:17:26 [INFO]: Epoch 032 - training loss: 0.8270, validation loss: 0.9408
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch32_loss0.9407690316438675.pypots
2024-05-22 12:17:26 [INFO]: Epoch 033 - training loss: 0.8140, validation loss: 0.9364
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch33_loss0.9364351630210876.pypots
2024-05-22 12:17:26 [INFO]: Epoch 034 - training loss: 0.8267, validation loss: 0.9366
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch34_loss0.9366061836481094.pypots
2024-05-22 12:17:26 [INFO]: Epoch 035 - training loss: 0.7933, validation loss: 0.9335
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch35_loss0.9334683418273926.pypots
2024-05-22 12:17:27 [INFO]: Epoch 036 - training loss: 0.7995, validation loss: 0.9301
2024-05-22 12:17:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch36_loss0.9301277548074722.pypots
2024-05-22 12:17:27 [INFO]: Epoch 037 - training loss: 0.8101, validation loss: 0.9280
2024-05-22 12:17:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch37_loss0.9280087649822235.pypots
2024-05-22 12:17:27 [INFO]: Epoch 038 - training loss: 0.7914, validation loss: 0.9273
2024-05-22 12:17:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch38_loss0.9272738248109818.pypots
2024-05-22 12:17:27 [INFO]: Epoch 039 - training loss: 0.7994, validation loss: 0.9234
2024-05-22 12:17:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch39_loss0.923402413725853.pypots
2024-05-22 12:17:27 [INFO]: Epoch 040 - training loss: 0.7956, validation loss: 0.9209
2024-05-22 12:17:27 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch40_loss0.9209420084953308.pypots
2024-05-22 12:17:28 [INFO]: Epoch 041 - training loss: 0.8186, validation loss: 0.9170
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch41_loss0.9169650971889496.pypots
2024-05-22 12:17:28 [INFO]: Epoch 042 - training loss: 0.7808, validation loss: 0.9127
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch42_loss0.9126731157302856.pypots
2024-05-22 12:17:28 [INFO]: Epoch 043 - training loss: 0.7918, validation loss: 0.9105
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch43_loss0.9104655534029007.pypots
2024-05-22 12:17:28 [INFO]: Epoch 044 - training loss: 0.7927, validation loss: 0.9114
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch44_loss0.9113509804010391.pypots
2024-05-22 12:17:28 [INFO]: Epoch 045 - training loss: 0.7777, validation loss: 0.9083
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch45_loss0.9083329439163208.pypots
2024-05-22 12:17:28 [INFO]: Epoch 046 - training loss: 0.7953, validation loss: 0.9087
2024-05-22 12:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch46_loss0.9086782783269882.pypots
2024-05-22 12:17:29 [INFO]: Epoch 047 - training loss: 0.7918, validation loss: 0.9053
2024-05-22 12:17:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch47_loss0.9052656441926956.pypots
2024-05-22 12:17:29 [INFO]: Epoch 048 - training loss: 0.7914, validation loss: 0.9036
2024-05-22 12:17:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch48_loss0.9036342352628708.pypots
2024-05-22 12:17:29 [INFO]: Epoch 049 - training loss: 0.7701, validation loss: 0.9021
2024-05-22 12:17:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch49_loss0.9020970016717911.pypots
2024-05-22 12:17:29 [INFO]: Epoch 050 - training loss: 0.7865, validation loss: 0.9019
2024-05-22 12:17:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch50_loss0.9018778502941132.pypots
2024-05-22 12:17:29 [INFO]: Epoch 051 - training loss: 0.7958, validation loss: 0.8991
2024-05-22 12:17:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch51_loss0.8991300016641617.pypots
2024-05-22 12:17:30 [INFO]: Epoch 052 - training loss: 0.7734, validation loss: 0.8974
2024-05-22 12:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch52_loss0.897397369146347.pypots
2024-05-22 12:17:30 [INFO]: Epoch 053 - training loss: 0.8143, validation loss: 0.8963
2024-05-22 12:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch53_loss0.896310344338417.pypots
2024-05-22 12:17:30 [INFO]: Epoch 054 - training loss: 0.7919, validation loss: 0.8955
2024-05-22 12:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch54_loss0.8954917937517166.pypots
2024-05-22 12:17:30 [INFO]: Epoch 055 - training loss: 0.7844, validation loss: 0.8945
2024-05-22 12:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch55_loss0.8944618254899979.pypots
2024-05-22 12:17:30 [INFO]: Epoch 056 - training loss: 0.7820, validation loss: 0.8931
2024-05-22 12:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch56_loss0.8931201994419098.pypots
2024-05-22 12:17:31 [INFO]: Epoch 057 - training loss: 0.7709, validation loss: 0.8896
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch57_loss0.8895725905895233.pypots
2024-05-22 12:17:31 [INFO]: Epoch 058 - training loss: 0.7902, validation loss: 0.8899
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch58_loss0.8898551762104034.pypots
2024-05-22 12:17:31 [INFO]: Epoch 059 - training loss: 0.7873, validation loss: 0.8896
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch59_loss0.8896127194166183.pypots
2024-05-22 12:17:31 [INFO]: Epoch 060 - training loss: 0.7853, validation loss: 0.8887
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch60_loss0.888705313205719.pypots
2024-05-22 12:17:31 [INFO]: Epoch 061 - training loss: 0.7859, validation loss: 0.8874
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch61_loss0.8874169141054153.pypots
2024-05-22 12:17:31 [INFO]: Epoch 062 - training loss: 0.7593, validation loss: 0.8879
2024-05-22 12:17:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch62_loss0.8879486918449402.pypots
2024-05-22 12:17:32 [INFO]: Epoch 063 - training loss: 0.7610, validation loss: 0.8887
2024-05-22 12:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch63_loss0.8886825442314148.pypots
2024-05-22 12:17:32 [INFO]: Epoch 064 - training loss: 0.7760, validation loss: 0.8886
2024-05-22 12:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch64_loss0.8886282593011856.pypots
2024-05-22 12:17:32 [INFO]: Epoch 065 - training loss: 0.7834, validation loss: 0.8840
2024-05-22 12:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch65_loss0.8840413838624954.pypots
2024-05-22 12:17:32 [INFO]: Epoch 066 - training loss: 0.7845, validation loss: 0.8840
2024-05-22 12:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch66_loss0.8839900940656662.pypots
2024-05-22 12:17:32 [INFO]: Epoch 067 - training loss: 0.7790, validation loss: 0.8830
2024-05-22 12:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch67_loss0.8829946666955948.pypots
2024-05-22 12:17:33 [INFO]: Epoch 068 - training loss: 0.7534, validation loss: 0.8846
2024-05-22 12:17:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch68_loss0.8845983743667603.pypots
2024-05-22 12:17:33 [INFO]: Epoch 069 - training loss: 0.7812, validation loss: 0.8825
2024-05-22 12:17:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch69_loss0.8825484812259674.pypots
2024-05-22 12:17:33 [INFO]: Epoch 070 - training loss: 0.7862, validation loss: 0.8822
2024-05-22 12:17:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch70_loss0.8822461068630219.pypots
2024-05-22 12:17:33 [INFO]: Epoch 071 - training loss: 0.7925, validation loss: 0.8828
2024-05-22 12:17:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch71_loss0.8828325867652893.pypots
2024-05-22 12:17:33 [INFO]: Epoch 072 - training loss: 0.7715, validation loss: 0.8815
2024-05-22 12:17:33 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch72_loss0.881459504365921.pypots
2024-05-22 12:17:34 [INFO]: Epoch 073 - training loss: 0.7625, validation loss: 0.8818
2024-05-22 12:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch73_loss0.8818286806344986.pypots
2024-05-22 12:17:34 [INFO]: Epoch 074 - training loss: 0.7693, validation loss: 0.8793
2024-05-22 12:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch74_loss0.8793186843395233.pypots
2024-05-22 12:17:34 [INFO]: Epoch 075 - training loss: 0.7581, validation loss: 0.8789
2024-05-22 12:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch75_loss0.8789044767618179.pypots
2024-05-22 12:17:34 [INFO]: Epoch 076 - training loss: 0.7726, validation loss: 0.8818
2024-05-22 12:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch76_loss0.8817964047193527.pypots
2024-05-22 12:17:34 [INFO]: Epoch 077 - training loss: 0.7718, validation loss: 0.8808
2024-05-22 12:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch77_loss0.8808346688747406.pypots
2024-05-22 12:17:35 [INFO]: Epoch 078 - training loss: 0.7633, validation loss: 0.8840
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch78_loss0.8839582055807114.pypots
2024-05-22 12:17:35 [INFO]: Epoch 079 - training loss: 0.7819, validation loss: 0.8759
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch79_loss0.8759156465530396.pypots
2024-05-22 12:17:35 [INFO]: Epoch 080 - training loss: 0.7687, validation loss: 0.8794
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch80_loss0.8793593347072601.pypots
2024-05-22 12:17:35 [INFO]: Epoch 081 - training loss: 0.7731, validation loss: 0.8782
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch81_loss0.8782025426626205.pypots
2024-05-22 12:17:35 [INFO]: Epoch 082 - training loss: 0.7679, validation loss: 0.8833
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch82_loss0.8832779228687286.pypots
2024-05-22 12:17:35 [INFO]: Epoch 083 - training loss: 0.7585, validation loss: 0.8771
2024-05-22 12:17:35 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch83_loss0.8770767152309418.pypots
2024-05-22 12:17:36 [INFO]: Epoch 084 - training loss: 0.7707, validation loss: 0.8790
2024-05-22 12:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch84_loss0.8789812624454498.pypots
2024-05-22 12:17:36 [INFO]: Epoch 085 - training loss: 0.7772, validation loss: 0.8823
2024-05-22 12:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch85_loss0.8822691142559052.pypots
2024-05-22 12:17:36 [INFO]: Epoch 086 - training loss: 0.7646, validation loss: 0.8835
2024-05-22 12:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch86_loss0.8834594637155533.pypots
2024-05-22 12:17:36 [INFO]: Epoch 087 - training loss: 0.7517, validation loss: 0.8832
2024-05-22 12:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch87_loss0.8832017034292221.pypots
2024-05-22 12:17:36 [INFO]: Epoch 088 - training loss: 0.7845, validation loss: 0.8836
2024-05-22 12:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch88_loss0.8836335688829422.pypots
2024-05-22 12:17:37 [INFO]: Epoch 089 - training loss: 0.7699, validation loss: 0.8816
2024-05-22 12:17:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN_epoch89_loss0.8816040754318237.pypots
2024-05-22 12:17:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:17:37 [INFO]: Finished training. The best model is from epoch#79.
2024-05-22 12:17:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240522_T121718/MRNN.pypots
2024-05-22 12:17:37 [INFO]: MRNN on ETTm1: MAE=0.7114, MSE=1.2660
2024-05-22 12:17:37 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-22 12:17:37 [INFO]: Using the given device: cpu
2024-05-22 12:17:37 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 12:17:37 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-22 12:17:37 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-22 12:17:37 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 12:17:37 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-22 12:17:37 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-22 12:17:37 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 12:17:37 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-22 12:17:37 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-22 12:17:37 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 12:17:37 [INFO]: Using the given device: cuda:0
2024-05-22 12:17:37 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240522_T121737
2024-05-22 12:17:37 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240522_T121737/tensorboard
2024-05-22 12:17:37 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 12:17:38 [INFO]: Epoch 001 - training loss: 1.1375, validation loss: 0.2782
2024-05-22 12:17:38 [INFO]: Epoch 002 - training loss: 0.8494, validation loss: 0.1424
2024-05-22 12:17:39 [INFO]: Epoch 003 - training loss: 0.7620, validation loss: 0.1169
2024-05-22 12:17:39 [INFO]: Epoch 004 - training loss: 0.7065, validation loss: 0.0733
2024-05-22 12:17:40 [INFO]: Epoch 005 - training loss: 0.6711, validation loss: 0.0751
2024-05-22 12:17:40 [INFO]: Epoch 006 - training loss: 0.6618, validation loss: 0.0781
2024-05-22 12:17:41 [INFO]: Epoch 007 - training loss: 0.6483, validation loss: 0.0707
2024-05-22 12:17:41 [INFO]: Epoch 008 - training loss: 0.6110, validation loss: 0.0774
2024-05-22 12:17:42 [INFO]: Epoch 009 - training loss: 0.5969, validation loss: 0.0651
2024-05-22 12:17:42 [INFO]: Epoch 010 - training loss: 0.5736, validation loss: 0.0758
2024-05-22 12:17:43 [INFO]: Epoch 011 - training loss: 0.5751, validation loss: 0.0533
2024-05-22 12:17:43 [INFO]: Epoch 012 - training loss: 0.5689, validation loss: 0.0571
2024-05-22 12:17:44 [INFO]: Epoch 013 - training loss: 0.5477, validation loss: 0.0603
2024-05-22 12:17:44 [INFO]: Epoch 014 - training loss: 0.5377, validation loss: 0.0539
2024-05-22 12:17:45 [INFO]: Epoch 015 - training loss: 0.5375, validation loss: 0.0540
2024-05-22 12:17:45 [INFO]: Epoch 016 - training loss: 0.5288, validation loss: 0.0515
2024-05-22 12:17:46 [INFO]: Epoch 017 - training loss: 0.5136, validation loss: 0.0615
2024-05-22 12:17:46 [INFO]: Epoch 018 - training loss: 0.5125, validation loss: 0.0686
2024-05-22 12:17:47 [INFO]: Epoch 019 - training loss: 0.5112, validation loss: 0.0445
2024-05-22 12:17:47 [INFO]: Epoch 020 - training loss: 0.4955, validation loss: 0.0466
2024-05-22 12:17:48 [INFO]: Epoch 021 - training loss: 0.4894, validation loss: 0.0433
2024-05-22 12:17:48 [INFO]: Epoch 022 - training loss: 0.4772, validation loss: 0.0587
2024-05-22 12:17:49 [INFO]: Epoch 023 - training loss: 0.4857, validation loss: 0.0521
2024-05-22 12:17:49 [INFO]: Epoch 024 - training loss: 0.4539, validation loss: 0.0481
2024-05-22 12:17:50 [INFO]: Epoch 025 - training loss: 0.4420, validation loss: 0.0457
2024-05-22 12:17:50 [INFO]: Epoch 026 - training loss: 0.4624, validation loss: 0.0483
2024-05-22 12:17:51 [INFO]: Epoch 027 - training loss: 0.4387, validation loss: 0.0477
2024-05-22 12:17:52 [INFO]: Epoch 028 - training loss: 0.4371, validation loss: 0.0477
2024-05-22 12:17:52 [INFO]: Epoch 029 - training loss: 0.4182, validation loss: 0.0425
2024-05-22 12:17:53 [INFO]: Epoch 030 - training loss: 0.4333, validation loss: 0.0583
2024-05-22 12:17:53 [INFO]: Epoch 031 - training loss: 0.4090, validation loss: 0.0423
2024-05-22 12:17:54 [INFO]: Epoch 032 - training loss: 0.4010, validation loss: 0.0388
2024-05-22 12:17:54 [INFO]: Epoch 033 - training loss: 0.3985, validation loss: 0.0512
2024-05-22 12:17:55 [INFO]: Epoch 034 - training loss: 0.3968, validation loss: 0.0397
2024-05-22 12:17:55 [INFO]: Epoch 035 - training loss: 0.3950, validation loss: 0.0583
2024-05-22 12:17:56 [INFO]: Epoch 036 - training loss: 0.3904, validation loss: 0.0597
2024-05-22 12:17:56 [INFO]: Epoch 037 - training loss: 0.3785, validation loss: 0.0352
2024-05-22 12:17:57 [INFO]: Epoch 038 - training loss: 0.3704, validation loss: 0.0363
2024-05-22 12:17:57 [INFO]: Epoch 039 - training loss: 0.3691, validation loss: 0.0414
2024-05-22 12:17:58 [INFO]: Epoch 040 - training loss: 0.3607, validation loss: 0.0387
2024-05-22 12:17:58 [INFO]: Epoch 041 - training loss: 0.3724, validation loss: 0.0381
2024-05-22 12:17:59 [INFO]: Epoch 042 - training loss: 0.3759, validation loss: 0.0418
2024-05-22 12:17:59 [INFO]: Epoch 043 - training loss: 0.3642, validation loss: 0.0371
2024-05-22 12:18:00 [INFO]: Epoch 044 - training loss: 0.3648, validation loss: 0.0376
2024-05-22 12:18:00 [INFO]: Epoch 045 - training loss: 0.3540, validation loss: 0.0412
2024-05-22 12:18:01 [INFO]: Epoch 046 - training loss: 0.3509, validation loss: 0.0369
2024-05-22 12:18:01 [INFO]: Epoch 047 - training loss: 0.3421, validation loss: 0.0472
2024-05-22 12:18:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:18:01 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 12:18:01 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_ettm1/20240522_T121737/SAITS.pypots
2024-05-22 12:18:01 [INFO]: SAITS on ETTm1: MAE=0.1572, MSE=0.0457
2024-05-22 12:18:01 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-22 12:18:01 [INFO]: Using the given device: cuda:0
2024-05-22 12:18:01 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240522_T121801
2024-05-22 12:18:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240522_T121801/tensorboard
2024-05-22 12:18:01 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 12:18:02 [INFO]: Epoch 001 - training loss: 1.2142, validation loss: 0.3386
2024-05-22 12:18:02 [INFO]: Epoch 002 - training loss: 0.7147, validation loss: 0.1468
2024-05-22 12:18:02 [INFO]: Epoch 003 - training loss: 0.5835, validation loss: 0.1121
2024-05-22 12:18:02 [INFO]: Epoch 004 - training loss: 0.5208, validation loss: 0.0948
2024-05-22 12:18:02 [INFO]: Epoch 005 - training loss: 0.4844, validation loss: 0.0737
2024-05-22 12:18:03 [INFO]: Epoch 006 - training loss: 0.4523, validation loss: 0.0667
2024-05-22 12:18:03 [INFO]: Epoch 007 - training loss: 0.4379, validation loss: 0.0670
2024-05-22 12:18:03 [INFO]: Epoch 008 - training loss: 0.4167, validation loss: 0.0621
2024-05-22 12:18:03 [INFO]: Epoch 009 - training loss: 0.4084, validation loss: 0.0504
2024-05-22 12:18:04 [INFO]: Epoch 010 - training loss: 0.3869, validation loss: 0.0579
2024-05-22 12:18:04 [INFO]: Epoch 011 - training loss: 0.3820, validation loss: 0.0496
2024-05-22 12:18:04 [INFO]: Epoch 012 - training loss: 0.3760, validation loss: 0.0501
2024-05-22 12:18:04 [INFO]: Epoch 013 - training loss: 0.3562, validation loss: 0.0549
2024-05-22 12:18:04 [INFO]: Epoch 014 - training loss: 0.3567, validation loss: 0.0418
2024-05-22 12:18:05 [INFO]: Epoch 015 - training loss: 0.3490, validation loss: 0.0440
2024-05-22 12:18:05 [INFO]: Epoch 016 - training loss: 0.3471, validation loss: 0.0458
2024-05-22 12:18:05 [INFO]: Epoch 017 - training loss: 0.3394, validation loss: 0.0464
2024-05-22 12:18:05 [INFO]: Epoch 018 - training loss: 0.3352, validation loss: 0.0443
2024-05-22 12:18:05 [INFO]: Epoch 019 - training loss: 0.3284, validation loss: 0.0415
2024-05-22 12:18:06 [INFO]: Epoch 020 - training loss: 0.3245, validation loss: 0.0460
2024-05-22 12:18:06 [INFO]: Epoch 021 - training loss: 0.3271, validation loss: 0.0476
2024-05-22 12:18:06 [INFO]: Epoch 022 - training loss: 0.3140, validation loss: 0.0398
2024-05-22 12:18:06 [INFO]: Epoch 023 - training loss: 0.3126, validation loss: 0.0353
2024-05-22 12:18:07 [INFO]: Epoch 024 - training loss: 0.3062, validation loss: 0.0385
2024-05-22 12:18:07 [INFO]: Epoch 025 - training loss: 0.3031, validation loss: 0.0374
2024-05-22 12:18:07 [INFO]: Epoch 026 - training loss: 0.2997, validation loss: 0.0368
2024-05-22 12:18:07 [INFO]: Epoch 027 - training loss: 0.2931, validation loss: 0.0380
2024-05-22 12:18:07 [INFO]: Epoch 028 - training loss: 0.2979, validation loss: 0.0409
2024-05-22 12:18:08 [INFO]: Epoch 029 - training loss: 0.3146, validation loss: 0.0413
2024-05-22 12:18:08 [INFO]: Epoch 030 - training loss: 0.3008, validation loss: 0.0366
2024-05-22 12:18:08 [INFO]: Epoch 031 - training loss: 0.2884, validation loss: 0.0345
2024-05-22 12:18:08 [INFO]: Epoch 032 - training loss: 0.2844, validation loss: 0.0310
2024-05-22 12:18:09 [INFO]: Epoch 033 - training loss: 0.2753, validation loss: 0.0340
2024-05-22 12:18:09 [INFO]: Epoch 034 - training loss: 0.2760, validation loss: 0.0344
2024-05-22 12:18:09 [INFO]: Epoch 035 - training loss: 0.2674, validation loss: 0.0303
2024-05-22 12:18:09 [INFO]: Epoch 036 - training loss: 0.2652, validation loss: 0.0320
2024-05-22 12:18:09 [INFO]: Epoch 037 - training loss: 0.2642, validation loss: 0.0328
2024-05-22 12:18:10 [INFO]: Epoch 038 - training loss: 0.2625, validation loss: 0.0328
2024-05-22 12:18:10 [INFO]: Epoch 039 - training loss: 0.2623, validation loss: 0.0345
2024-05-22 12:18:10 [INFO]: Epoch 040 - training loss: 0.2766, validation loss: 0.0309
2024-05-22 12:18:10 [INFO]: Epoch 041 - training loss: 0.2640, validation loss: 0.0292
2024-05-22 12:18:10 [INFO]: Epoch 042 - training loss: 0.2605, validation loss: 0.0264
2024-05-22 12:18:11 [INFO]: Epoch 043 - training loss: 0.2512, validation loss: 0.0275
2024-05-22 12:18:11 [INFO]: Epoch 044 - training loss: 0.2519, validation loss: 0.0254
2024-05-22 12:18:11 [INFO]: Epoch 045 - training loss: 0.2473, validation loss: 0.0272
2024-05-22 12:18:11 [INFO]: Epoch 046 - training loss: 0.2424, validation loss: 0.0273
2024-05-22 12:18:12 [INFO]: Epoch 047 - training loss: 0.2389, validation loss: 0.0272
2024-05-22 12:18:12 [INFO]: Epoch 048 - training loss: 0.2387, validation loss: 0.0265
2024-05-22 12:18:12 [INFO]: Epoch 049 - training loss: 0.2377, validation loss: 0.0299
2024-05-22 12:18:12 [INFO]: Epoch 050 - training loss: 0.2389, validation loss: 0.0294
2024-05-22 12:18:12 [INFO]: Epoch 051 - training loss: 0.2358, validation loss: 0.0266
2024-05-22 12:18:13 [INFO]: Epoch 052 - training loss: 0.2326, validation loss: 0.0275
2024-05-22 12:18:13 [INFO]: Epoch 053 - training loss: 0.2447, validation loss: 0.0303
2024-05-22 12:18:13 [INFO]: Epoch 054 - training loss: 0.2315, validation loss: 0.0292
2024-05-22 12:18:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:18:13 [INFO]: Finished training. The best model is from epoch#44.
2024-05-22 12:18:13 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_ettm1/20240522_T121801/Transformer.pypots
2024-05-22 12:18:13 [INFO]: Transformer on ETTm1: MAE=0.1386, MSE=0.0371
2024-05-22 12:18:13 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-22 12:18:13 [INFO]: Using the given device: cuda:0
2024-05-22 12:18:13 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240522_T121813
2024-05-22 12:18:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240522_T121813/tensorboard
2024-05-22 12:18:13 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 12:18:14 [INFO]: Epoch 001 - training loss: 0.1452, validation loss: 0.0604
2024-05-22 12:18:14 [INFO]: Epoch 002 - training loss: 0.0752, validation loss: 0.0476
2024-05-22 12:18:14 [INFO]: Epoch 003 - training loss: 0.0628, validation loss: 0.0401
2024-05-22 12:18:14 [INFO]: Epoch 004 - training loss: 0.0545, validation loss: 0.0357
2024-05-22 12:18:14 [INFO]: Epoch 005 - training loss: 0.0513, validation loss: 0.0379
2024-05-22 12:18:15 [INFO]: Epoch 006 - training loss: 0.0487, validation loss: 0.0338
2024-05-22 12:18:15 [INFO]: Epoch 007 - training loss: 0.0451, validation loss: 0.0351
2024-05-22 12:18:15 [INFO]: Epoch 008 - training loss: 0.0459, validation loss: 0.0330
2024-05-22 12:18:15 [INFO]: Epoch 009 - training loss: 0.0479, validation loss: 0.0338
2024-05-22 12:18:15 [INFO]: Epoch 010 - training loss: 0.0453, validation loss: 0.0342
2024-05-22 12:18:16 [INFO]: Epoch 011 - training loss: 0.0454, validation loss: 0.0331
2024-05-22 12:18:16 [INFO]: Epoch 012 - training loss: 0.0492, validation loss: 0.0333
2024-05-22 12:18:16 [INFO]: Epoch 013 - training loss: 0.0449, validation loss: 0.0314
2024-05-22 12:18:16 [INFO]: Epoch 014 - training loss: 0.0432, validation loss: 0.0288
2024-05-22 12:18:17 [INFO]: Epoch 015 - training loss: 0.0436, validation loss: 0.0307
2024-05-22 12:18:17 [INFO]: Epoch 016 - training loss: 0.0428, validation loss: 0.0324
2024-05-22 12:18:17 [INFO]: Epoch 017 - training loss: 0.0428, validation loss: 0.0297
2024-05-22 12:18:17 [INFO]: Epoch 018 - training loss: 0.0423, validation loss: 0.0295
2024-05-22 12:18:17 [INFO]: Epoch 019 - training loss: 0.0411, validation loss: 0.0304
2024-05-22 12:18:18 [INFO]: Epoch 020 - training loss: 0.0425, validation loss: 0.0341
2024-05-22 12:18:18 [INFO]: Epoch 021 - training loss: 0.0433, validation loss: 0.0314
2024-05-22 12:18:18 [INFO]: Epoch 022 - training loss: 0.0416, validation loss: 0.0298
2024-05-22 12:18:18 [INFO]: Epoch 023 - training loss: 0.0419, validation loss: 0.0286
2024-05-22 12:18:18 [INFO]: Epoch 024 - training loss: 0.0414, validation loss: 0.0291
2024-05-22 12:18:19 [INFO]: Epoch 025 - training loss: 0.0405, validation loss: 0.0312
2024-05-22 12:18:19 [INFO]: Epoch 026 - training loss: 0.0422, validation loss: 0.0297
2024-05-22 12:18:19 [INFO]: Epoch 027 - training loss: 0.0412, validation loss: 0.0296
2024-05-22 12:18:19 [INFO]: Epoch 028 - training loss: 0.0403, validation loss: 0.0297
2024-05-22 12:18:19 [INFO]: Epoch 029 - training loss: 0.0389, validation loss: 0.0288
2024-05-22 12:18:20 [INFO]: Epoch 030 - training loss: 0.0375, validation loss: 0.0272
2024-05-22 12:18:20 [INFO]: Epoch 031 - training loss: 0.0397, validation loss: 0.0283
2024-05-22 12:18:20 [INFO]: Epoch 032 - training loss: 0.0398, validation loss: 0.0277
2024-05-22 12:18:20 [INFO]: Epoch 033 - training loss: 0.0375, validation loss: 0.0268
2024-05-22 12:18:21 [INFO]: Epoch 034 - training loss: 0.0376, validation loss: 0.0267
2024-05-22 12:18:21 [INFO]: Epoch 035 - training loss: 0.0362, validation loss: 0.0279
2024-05-22 12:18:21 [INFO]: Epoch 036 - training loss: 0.0370, validation loss: 0.0281
2024-05-22 12:18:21 [INFO]: Epoch 037 - training loss: 0.0371, validation loss: 0.0267
2024-05-22 12:18:21 [INFO]: Epoch 038 - training loss: 0.0346, validation loss: 0.0265
2024-05-22 12:18:22 [INFO]: Epoch 039 - training loss: 0.0360, validation loss: 0.0263
2024-05-22 12:18:22 [INFO]: Epoch 040 - training loss: 0.0358, validation loss: 0.0267
2024-05-22 12:18:22 [INFO]: Epoch 041 - training loss: 0.0353, validation loss: 0.0259
2024-05-22 12:18:22 [INFO]: Epoch 042 - training loss: 0.0353, validation loss: 0.0263
2024-05-22 12:18:22 [INFO]: Epoch 043 - training loss: 0.0357, validation loss: 0.0266
2024-05-22 12:18:23 [INFO]: Epoch 044 - training loss: 0.0359, validation loss: 0.0279
2024-05-22 12:18:23 [INFO]: Epoch 045 - training loss: 0.0358, validation loss: 0.0277
2024-05-22 12:18:23 [INFO]: Epoch 046 - training loss: 0.0371, validation loss: 0.0258
2024-05-22 12:18:23 [INFO]: Epoch 047 - training loss: 0.0358, validation loss: 0.0258
2024-05-22 12:18:23 [INFO]: Epoch 048 - training loss: 0.0378, validation loss: 0.0265
2024-05-22 12:18:24 [INFO]: Epoch 049 - training loss: 0.0365, validation loss: 0.0268
2024-05-22 12:18:24 [INFO]: Epoch 050 - training loss: 0.0348, validation loss: 0.0261
2024-05-22 12:18:24 [INFO]: Epoch 051 - training loss: 0.0350, validation loss: 0.0252
2024-05-22 12:18:24 [INFO]: Epoch 052 - training loss: 0.0351, validation loss: 0.0245
2024-05-22 12:18:25 [INFO]: Epoch 053 - training loss: 0.0363, validation loss: 0.0258
2024-05-22 12:18:25 [INFO]: Epoch 054 - training loss: 0.0378, validation loss: 0.0279
2024-05-22 12:18:25 [INFO]: Epoch 055 - training loss: 0.0353, validation loss: 0.0252
2024-05-22 12:18:25 [INFO]: Epoch 056 - training loss: 0.0360, validation loss: 0.0254
2024-05-22 12:18:25 [INFO]: Epoch 057 - training loss: 0.0344, validation loss: 0.0262
2024-05-22 12:18:26 [INFO]: Epoch 058 - training loss: 0.0332, validation loss: 0.0257
2024-05-22 12:18:26 [INFO]: Epoch 059 - training loss: 0.0346, validation loss: 0.0262
2024-05-22 12:18:26 [INFO]: Epoch 060 - training loss: 0.0350, validation loss: 0.0250
2024-05-22 12:18:26 [INFO]: Epoch 061 - training loss: 0.0343, validation loss: 0.0261
2024-05-22 12:18:26 [INFO]: Epoch 062 - training loss: 0.0338, validation loss: 0.0244
2024-05-22 12:18:27 [INFO]: Epoch 063 - training loss: 0.0361, validation loss: 0.0249
2024-05-22 12:18:27 [INFO]: Epoch 064 - training loss: 0.0409, validation loss: 0.0273
2024-05-22 12:18:27 [INFO]: Epoch 065 - training loss: 0.0454, validation loss: 0.0267
2024-05-22 12:18:27 [INFO]: Epoch 066 - training loss: 0.0359, validation loss: 0.0264
2024-05-22 12:18:28 [INFO]: Epoch 067 - training loss: 0.0360, validation loss: 0.0277
2024-05-22 12:18:28 [INFO]: Epoch 068 - training loss: 0.0392, validation loss: 0.0278
2024-05-22 12:18:28 [INFO]: Epoch 069 - training loss: 0.0340, validation loss: 0.0249
2024-05-22 12:18:28 [INFO]: Epoch 070 - training loss: 0.0319, validation loss: 0.0246
2024-05-22 12:18:28 [INFO]: Epoch 071 - training loss: 0.0333, validation loss: 0.0254
2024-05-22 12:18:29 [INFO]: Epoch 072 - training loss: 0.0344, validation loss: 0.0254
2024-05-22 12:18:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:18:29 [INFO]: Finished training. The best model is from epoch#62.
2024-05-22 12:18:29 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_ettm1/20240522_T121813/TimesNet.pypots
2024-05-22 12:18:29 [INFO]: TimesNet on ETTm1: MAE=0.1133, MSE=0.0269
2024-05-22 12:18:29 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-22 12:18:29 [INFO]: Using the given device: cuda:0
2024-05-22 12:18:29 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829
2024-05-22 12:18:29 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/tensorboard
2024-05-22 12:18:29 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 12:18:31 [INFO]: Epoch 001 - training loss: 0.6884, validation loss: 0.4101
2024-05-22 12:18:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch1_loss0.4101082682609558.pypots
2024-05-22 12:18:33 [INFO]: Epoch 002 - training loss: 0.3805, validation loss: 0.3747
2024-05-22 12:18:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch2_loss0.3746815398335457.pypots
2024-05-22 12:18:35 [INFO]: Epoch 003 - training loss: 0.3108, validation loss: 0.3379
2024-05-22 12:18:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch3_loss0.3379334285855293.pypots
2024-05-22 12:18:37 [INFO]: Epoch 004 - training loss: 0.2902, validation loss: 0.3437
2024-05-22 12:18:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch4_loss0.3437179625034332.pypots
2024-05-22 12:18:39 [INFO]: Epoch 005 - training loss: 0.3627, validation loss: 0.2910
2024-05-22 12:18:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch5_loss0.2909806966781616.pypots
2024-05-22 12:18:41 [INFO]: Epoch 006 - training loss: 0.2565, validation loss: 0.2823
2024-05-22 12:18:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch6_loss0.2822535112500191.pypots
2024-05-22 12:18:43 [INFO]: Epoch 007 - training loss: 0.3040, validation loss: 0.2744
2024-05-22 12:18:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch7_loss0.27444538474082947.pypots
2024-05-22 12:18:45 [INFO]: Epoch 008 - training loss: 0.2683, validation loss: 0.2677
2024-05-22 12:18:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch8_loss0.2677104026079178.pypots
2024-05-22 12:18:47 [INFO]: Epoch 009 - training loss: 0.2739, validation loss: 0.2670
2024-05-22 12:18:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch9_loss0.26698607951402664.pypots
2024-05-22 12:18:49 [INFO]: Epoch 010 - training loss: 0.3162, validation loss: 0.2544
2024-05-22 12:18:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch10_loss0.2544315829873085.pypots
2024-05-22 12:18:52 [INFO]: Epoch 011 - training loss: 0.2888, validation loss: 0.2464
2024-05-22 12:18:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch11_loss0.24640897288918495.pypots
2024-05-22 12:18:54 [INFO]: Epoch 012 - training loss: 0.2091, validation loss: 0.2498
2024-05-22 12:18:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch12_loss0.24983997270464897.pypots
2024-05-22 12:18:56 [INFO]: Epoch 013 - training loss: 0.2333, validation loss: 0.2551
2024-05-22 12:18:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch13_loss0.25511589646339417.pypots
2024-05-22 12:18:58 [INFO]: Epoch 014 - training loss: 0.2336, validation loss: 0.2425
2024-05-22 12:18:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch14_loss0.2424766644835472.pypots
2024-05-22 12:19:00 [INFO]: Epoch 015 - training loss: 0.2121, validation loss: 0.2182
2024-05-22 12:19:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch15_loss0.21816400066018105.pypots
2024-05-22 12:19:02 [INFO]: Epoch 016 - training loss: 0.1971, validation loss: 0.2071
2024-05-22 12:19:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch16_loss0.2070777341723442.pypots
2024-05-22 12:19:04 [INFO]: Epoch 017 - training loss: 0.2091, validation loss: 0.2079
2024-05-22 12:19:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch17_loss0.20792775973677635.pypots
2024-05-22 12:19:06 [INFO]: Epoch 018 - training loss: 0.2031, validation loss: 0.2067
2024-05-22 12:19:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch18_loss0.2066500075161457.pypots
2024-05-22 12:19:08 [INFO]: Epoch 019 - training loss: 0.2220, validation loss: 0.2192
2024-05-22 12:19:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch19_loss0.21917754039168358.pypots
2024-05-22 12:19:10 [INFO]: Epoch 020 - training loss: 0.2127, validation loss: 0.2061
2024-05-22 12:19:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch20_loss0.20613669604063034.pypots
2024-05-22 12:19:12 [INFO]: Epoch 021 - training loss: 0.2526, validation loss: 0.2283
2024-05-22 12:19:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch21_loss0.22832592204213142.pypots
2024-05-22 12:19:14 [INFO]: Epoch 022 - training loss: 0.2329, validation loss: 0.2251
2024-05-22 12:19:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch22_loss0.22510994225740433.pypots
2024-05-22 12:19:17 [INFO]: Epoch 023 - training loss: 0.2317, validation loss: 0.1998
2024-05-22 12:19:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch23_loss0.19979633018374443.pypots
2024-05-22 12:19:19 [INFO]: Epoch 024 - training loss: 0.2285, validation loss: 0.2141
2024-05-22 12:19:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch24_loss0.2141386829316616.pypots
2024-05-22 12:19:21 [INFO]: Epoch 025 - training loss: 0.1991, validation loss: 0.1976
2024-05-22 12:19:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch25_loss0.19756735488772392.pypots
2024-05-22 12:19:23 [INFO]: Epoch 026 - training loss: 0.2156, validation loss: 0.1776
2024-05-22 12:19:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch26_loss0.17755554243922234.pypots
2024-05-22 12:19:25 [INFO]: Epoch 027 - training loss: 0.1899, validation loss: 0.1775
2024-05-22 12:19:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch27_loss0.17749567702412605.pypots
2024-05-22 12:19:27 [INFO]: Epoch 028 - training loss: 0.2306, validation loss: 0.1704
2024-05-22 12:19:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch28_loss0.17042458057403564.pypots
2024-05-22 12:19:29 [INFO]: Epoch 029 - training loss: 0.1840, validation loss: 0.1745
2024-05-22 12:19:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch29_loss0.17453588172793388.pypots
2024-05-22 12:19:31 [INFO]: Epoch 030 - training loss: 0.1825, validation loss: 0.1682
2024-05-22 12:19:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch30_loss0.16823792085051537.pypots
2024-05-22 12:19:33 [INFO]: Epoch 031 - training loss: 0.2135, validation loss: 0.1622
2024-05-22 12:19:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch31_loss0.1622408889234066.pypots
2024-05-22 12:19:35 [INFO]: Epoch 032 - training loss: 0.2033, validation loss: 0.1614
2024-05-22 12:19:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch32_loss0.16137294098734856.pypots
2024-05-22 12:19:37 [INFO]: Epoch 033 - training loss: 0.1580, validation loss: 0.1641
2024-05-22 12:19:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch33_loss0.16410281881690025.pypots
2024-05-22 12:19:39 [INFO]: Epoch 034 - training loss: 0.1889, validation loss: 0.1575
2024-05-22 12:19:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch34_loss0.15748542547225952.pypots
2024-05-22 12:19:41 [INFO]: Epoch 035 - training loss: 0.1737, validation loss: 0.1596
2024-05-22 12:19:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch35_loss0.15957817062735558.pypots
2024-05-22 12:19:44 [INFO]: Epoch 036 - training loss: 0.1394, validation loss: 0.1515
2024-05-22 12:19:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch36_loss0.15150528028607368.pypots
2024-05-22 12:19:46 [INFO]: Epoch 037 - training loss: 0.1854, validation loss: 0.1524
2024-05-22 12:19:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch37_loss0.15242505073547363.pypots
2024-05-22 12:19:48 [INFO]: Epoch 038 - training loss: 0.1596, validation loss: 0.1543
2024-05-22 12:19:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch38_loss0.1543181724846363.pypots
2024-05-22 12:19:50 [INFO]: Epoch 039 - training loss: 0.1805, validation loss: 0.1568
2024-05-22 12:19:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch39_loss0.15676314383745193.pypots
2024-05-22 12:19:52 [INFO]: Epoch 040 - training loss: 0.1804, validation loss: 0.1601
2024-05-22 12:19:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch40_loss0.16013523936271667.pypots
2024-05-22 12:19:54 [INFO]: Epoch 041 - training loss: 0.1729, validation loss: 0.1453
2024-05-22 12:19:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch41_loss0.14531118795275688.pypots
2024-05-22 12:19:56 [INFO]: Epoch 042 - training loss: 0.2178, validation loss: 0.1803
2024-05-22 12:19:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch42_loss0.18034255877137184.pypots
2024-05-22 12:19:58 [INFO]: Epoch 043 - training loss: 0.1886, validation loss: 0.1679
2024-05-22 12:19:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch43_loss0.16792936623096466.pypots
2024-05-22 12:20:00 [INFO]: Epoch 044 - training loss: 0.1770, validation loss: 0.1555
2024-05-22 12:20:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch44_loss0.15552961081266403.pypots
2024-05-22 12:20:02 [INFO]: Epoch 045 - training loss: 0.1988, validation loss: 0.1464
2024-05-22 12:20:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch45_loss0.1464303806424141.pypots
2024-05-22 12:20:04 [INFO]: Epoch 046 - training loss: 0.1734, validation loss: 0.1425
2024-05-22 12:20:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch46_loss0.14249276369810104.pypots
2024-05-22 12:20:06 [INFO]: Epoch 047 - training loss: 0.1548, validation loss: 0.1391
2024-05-22 12:20:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch47_loss0.13911040499806404.pypots
2024-05-22 12:20:09 [INFO]: Epoch 048 - training loss: 0.1557, validation loss: 0.1407
2024-05-22 12:20:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch48_loss0.1406794711947441.pypots
2024-05-22 12:20:11 [INFO]: Epoch 049 - training loss: 0.1745, validation loss: 0.1390
2024-05-22 12:20:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch49_loss0.13897401466965675.pypots
2024-05-22 12:20:13 [INFO]: Epoch 050 - training loss: 0.1536, validation loss: 0.1373
2024-05-22 12:20:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch50_loss0.13733483478426933.pypots
2024-05-22 12:20:15 [INFO]: Epoch 051 - training loss: 0.1874, validation loss: 0.1437
2024-05-22 12:20:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch51_loss0.1437058001756668.pypots
2024-05-22 12:20:17 [INFO]: Epoch 052 - training loss: 0.1610, validation loss: 0.1445
2024-05-22 12:20:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch52_loss0.1445074900984764.pypots
2024-05-22 12:20:19 [INFO]: Epoch 053 - training loss: 0.1806, validation loss: 0.1411
2024-05-22 12:20:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch53_loss0.14112348854541779.pypots
2024-05-22 12:20:21 [INFO]: Epoch 054 - training loss: 0.1515, validation loss: 0.1425
2024-05-22 12:20:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch54_loss0.14247491210699081.pypots
2024-05-22 12:20:23 [INFO]: Epoch 055 - training loss: 0.1419, validation loss: 0.1349
2024-05-22 12:20:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch55_loss0.13486822694540024.pypots
2024-05-22 12:20:25 [INFO]: Epoch 056 - training loss: 0.1618, validation loss: 0.1387
2024-05-22 12:20:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch56_loss0.13870534300804138.pypots
2024-05-22 12:20:27 [INFO]: Epoch 057 - training loss: 0.1655, validation loss: 0.1364
2024-05-22 12:20:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch57_loss0.13637002930045128.pypots
2024-05-22 12:20:29 [INFO]: Epoch 058 - training loss: 0.1837, validation loss: 0.1339
2024-05-22 12:20:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch58_loss0.1339273639023304.pypots
2024-05-22 12:20:31 [INFO]: Epoch 059 - training loss: 0.1382, validation loss: 0.1351
2024-05-22 12:20:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch59_loss0.13506396487355232.pypots
2024-05-22 12:20:33 [INFO]: Epoch 060 - training loss: 0.1486, validation loss: 0.1315
2024-05-22 12:20:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch60_loss0.13151159323751926.pypots
2024-05-22 12:20:36 [INFO]: Epoch 061 - training loss: 0.1684, validation loss: 0.1347
2024-05-22 12:20:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch61_loss0.13468992337584496.pypots
2024-05-22 12:20:38 [INFO]: Epoch 062 - training loss: 0.1538, validation loss: 0.1401
2024-05-22 12:20:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch62_loss0.14011316746473312.pypots
2024-05-22 12:20:40 [INFO]: Epoch 063 - training loss: 0.1816, validation loss: 0.1386
2024-05-22 12:20:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch63_loss0.13859950751066208.pypots
2024-05-22 12:20:42 [INFO]: Epoch 064 - training loss: 0.1734, validation loss: 0.1338
2024-05-22 12:20:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch64_loss0.13375458121299744.pypots
2024-05-22 12:20:44 [INFO]: Epoch 065 - training loss: 0.1439, validation loss: 0.1324
2024-05-22 12:20:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch65_loss0.13237949274480343.pypots
2024-05-22 12:20:46 [INFO]: Epoch 066 - training loss: 0.1357, validation loss: 0.1346
2024-05-22 12:20:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch66_loss0.13461849093437195.pypots
2024-05-22 12:20:48 [INFO]: Epoch 067 - training loss: 0.1609, validation loss: 0.1339
2024-05-22 12:20:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch67_loss0.13394776359200478.pypots
2024-05-22 12:20:50 [INFO]: Epoch 068 - training loss: 0.1552, validation loss: 0.1301
2024-05-22 12:20:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch68_loss0.13011064566671848.pypots
2024-05-22 12:20:52 [INFO]: Epoch 069 - training loss: 0.1445, validation loss: 0.1351
2024-05-22 12:20:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch69_loss0.13509055227041245.pypots
2024-05-22 12:20:54 [INFO]: Epoch 070 - training loss: 0.1757, validation loss: 0.1331
2024-05-22 12:20:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch70_loss0.1331003848463297.pypots
2024-05-22 12:20:56 [INFO]: Epoch 071 - training loss: 0.1359, validation loss: 0.1297
2024-05-22 12:20:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch71_loss0.12969559617340565.pypots
2024-05-22 12:20:58 [INFO]: Epoch 072 - training loss: 0.1470, validation loss: 0.1273
2024-05-22 12:20:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch72_loss0.12733647413551807.pypots
2024-05-22 12:21:01 [INFO]: Epoch 073 - training loss: 0.1596, validation loss: 0.1330
2024-05-22 12:21:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch73_loss0.13303252682089806.pypots
2024-05-22 12:21:03 [INFO]: Epoch 074 - training loss: 0.1536, validation loss: 0.1258
2024-05-22 12:21:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch74_loss0.12577572464942932.pypots
2024-05-22 12:21:05 [INFO]: Epoch 075 - training loss: 0.1365, validation loss: 0.1256
2024-05-22 12:21:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch75_loss0.1256497111171484.pypots
2024-05-22 12:21:07 [INFO]: Epoch 076 - training loss: 0.1558, validation loss: 0.1267
2024-05-22 12:21:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch76_loss0.12668301537632942.pypots
2024-05-22 12:21:09 [INFO]: Epoch 077 - training loss: 0.1499, validation loss: 0.1277
2024-05-22 12:21:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch77_loss0.1277136281132698.pypots
2024-05-22 12:21:11 [INFO]: Epoch 078 - training loss: 0.1416, validation loss: 0.1242
2024-05-22 12:21:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch78_loss0.1242386307567358.pypots
2024-05-22 12:21:13 [INFO]: Epoch 079 - training loss: 0.1337, validation loss: 0.1282
2024-05-22 12:21:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch79_loss0.12816501781344414.pypots
2024-05-22 12:21:15 [INFO]: Epoch 080 - training loss: 0.1410, validation loss: 0.1333
2024-05-22 12:21:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch80_loss0.133255984634161.pypots
2024-05-22 12:21:17 [INFO]: Epoch 081 - training loss: 0.1607, validation loss: 0.1323
2024-05-22 12:21:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch81_loss0.13234367035329342.pypots
2024-05-22 12:21:19 [INFO]: Epoch 082 - training loss: 0.1439, validation loss: 0.1306
2024-05-22 12:21:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch82_loss0.13056275434792042.pypots
2024-05-22 12:21:21 [INFO]: Epoch 083 - training loss: 0.1624, validation loss: 0.1381
2024-05-22 12:21:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch83_loss0.13812054693698883.pypots
2024-05-22 12:21:23 [INFO]: Epoch 084 - training loss: 0.2421, validation loss: 0.1444
2024-05-22 12:21:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch84_loss0.1444246582686901.pypots
2024-05-22 12:21:25 [INFO]: Epoch 085 - training loss: 0.1678, validation loss: 0.1343
2024-05-22 12:21:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch85_loss0.13425886444747448.pypots
2024-05-22 12:21:28 [INFO]: Epoch 086 - training loss: 0.1539, validation loss: 0.1283
2024-05-22 12:21:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch86_loss0.12826844491064548.pypots
2024-05-22 12:21:30 [INFO]: Epoch 087 - training loss: 0.1641, validation loss: 0.1300
2024-05-22 12:21:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch87_loss0.1299692913889885.pypots
2024-05-22 12:21:32 [INFO]: Epoch 088 - training loss: 0.1509, validation loss: 0.1279
2024-05-22 12:21:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI_epoch88_loss0.12785341776907444.pypots
2024-05-22 12:21:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:21:32 [INFO]: Finished training. The best model is from epoch#78.
2024-05-22 12:21:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240522_T121829/CSDI.pypots
2024-05-22 12:21:48 [INFO]: CSDI on ETTm1: MAE=0.1943, MSE=0.6042
2024-05-22 12:21:48 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-22 12:21:48 [INFO]: Using the given device: cuda:0
2024-05-22 12:21:48 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240522_T122148
2024-05-22 12:21:48 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240522_T122148/tensorboard
2024-05-22 12:21:48 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 12:21:48 [INFO]: Epoch 001 - training loss: 23795.7043, validation loss: 0.9690
2024-05-22 12:21:48 [INFO]: Epoch 002 - training loss: 21592.2524, validation loss: 0.9587
2024-05-22 12:21:48 [INFO]: Epoch 003 - training loss: 19693.1489, validation loss: 0.9443
2024-05-22 12:21:48 [INFO]: Epoch 004 - training loss: 17498.3178, validation loss: 0.9204
2024-05-22 12:21:48 [INFO]: Epoch 005 - training loss: 15564.0744, validation loss: 0.8770
2024-05-22 12:21:48 [INFO]: Epoch 006 - training loss: 13935.6938, validation loss: 0.7732
2024-05-22 12:21:49 [INFO]: Epoch 007 - training loss: 12826.6097, validation loss: 0.6479
2024-05-22 12:21:49 [INFO]: Epoch 008 - training loss: 12014.0573, validation loss: 0.5607
2024-05-22 12:21:49 [INFO]: Epoch 009 - training loss: 11295.2956, validation loss: 0.5060
2024-05-22 12:21:49 [INFO]: Epoch 010 - training loss: 10954.0959, validation loss: 0.4783
2024-05-22 12:21:49 [INFO]: Epoch 011 - training loss: 10626.1183, validation loss: 0.4731
2024-05-22 12:21:49 [INFO]: Epoch 012 - training loss: 10556.9272, validation loss: 0.4696
2024-05-22 12:21:49 [INFO]: Epoch 013 - training loss: 10225.0431, validation loss: 0.4633
2024-05-22 12:21:49 [INFO]: Epoch 014 - training loss: 10131.2863, validation loss: 0.4599
2024-05-22 12:21:50 [INFO]: Epoch 015 - training loss: 10104.2375, validation loss: 0.4436
2024-05-22 12:21:50 [INFO]: Epoch 016 - training loss: 9952.6733, validation loss: 0.4370
2024-05-22 12:21:50 [INFO]: Epoch 017 - training loss: 9852.7078, validation loss: 0.4230
2024-05-22 12:21:50 [INFO]: Epoch 018 - training loss: 9784.9380, validation loss: 0.4046
2024-05-22 12:21:50 [INFO]: Epoch 019 - training loss: 9734.8956, validation loss: 0.3931
2024-05-22 12:21:50 [INFO]: Epoch 020 - training loss: 9694.0261, validation loss: 0.3676
2024-05-22 12:21:50 [INFO]: Epoch 021 - training loss: 9652.4780, validation loss: 0.3372
2024-05-22 12:21:51 [INFO]: Epoch 022 - training loss: 9669.4333, validation loss: 0.3137
2024-05-22 12:21:51 [INFO]: Epoch 023 - training loss: 9605.7233, validation loss: 0.2926
2024-05-22 12:21:51 [INFO]: Epoch 024 - training loss: 9556.7545, validation loss: 0.2780
2024-05-22 12:21:51 [INFO]: Epoch 025 - training loss: 9568.5051, validation loss: 0.2656
2024-05-22 12:21:51 [INFO]: Epoch 026 - training loss: 9516.7900, validation loss: 0.2549
2024-05-22 12:21:51 [INFO]: Epoch 027 - training loss: 9498.1409, validation loss: 0.2482
2024-05-22 12:21:51 [INFO]: Epoch 028 - training loss: 9491.3448, validation loss: 0.2423
2024-05-22 12:21:51 [INFO]: Epoch 029 - training loss: 9464.6963, validation loss: 0.2352
2024-05-22 12:21:52 [INFO]: Epoch 030 - training loss: 9454.9498, validation loss: 0.2319
2024-05-22 12:21:52 [INFO]: Epoch 031 - training loss: 9445.8503, validation loss: 0.2276
2024-05-22 12:21:52 [INFO]: Epoch 032 - training loss: 9436.8071, validation loss: 0.2197
2024-05-22 12:21:52 [INFO]: Epoch 033 - training loss: 9426.4507, validation loss: 0.2150
2024-05-22 12:21:52 [INFO]: Epoch 034 - training loss: 9419.2745, validation loss: 0.2117
2024-05-22 12:21:52 [INFO]: Epoch 035 - training loss: 9418.7529, validation loss: 0.2081
2024-05-22 12:21:52 [INFO]: Epoch 036 - training loss: 9429.2729, validation loss: 0.2059
2024-05-22 12:21:52 [INFO]: Epoch 037 - training loss: 9400.4241, validation loss: 0.2000
2024-05-22 12:21:53 [INFO]: Epoch 038 - training loss: 9395.0494, validation loss: 0.1937
2024-05-22 12:21:53 [INFO]: Epoch 039 - training loss: 9400.3730, validation loss: 0.1905
2024-05-22 12:21:53 [INFO]: Epoch 040 - training loss: 9383.1556, validation loss: 0.1859
2024-05-22 12:21:53 [INFO]: Epoch 041 - training loss: 9379.0642, validation loss: 0.1785
2024-05-22 12:21:53 [INFO]: Epoch 042 - training loss: 9371.1480, validation loss: 0.1773
2024-05-22 12:21:53 [INFO]: Epoch 043 - training loss: 9381.0891, validation loss: 0.1704
2024-05-22 12:21:53 [INFO]: Epoch 044 - training loss: 9371.5503, validation loss: 0.1748
2024-05-22 12:21:53 [INFO]: Epoch 045 - training loss: 9364.1536, validation loss: 0.1682
2024-05-22 12:21:54 [INFO]: Epoch 046 - training loss: 9355.0719, validation loss: 0.1656
2024-05-22 12:21:54 [INFO]: Epoch 047 - training loss: 9354.9772, validation loss: 0.1617
2024-05-22 12:21:54 [INFO]: Epoch 048 - training loss: 9347.9046, validation loss: 0.1546
2024-05-22 12:21:54 [INFO]: Epoch 049 - training loss: 9345.9141, validation loss: 0.1520
2024-05-22 12:21:54 [INFO]: Epoch 050 - training loss: 9347.2767, validation loss: 0.1492
2024-05-22 12:21:54 [INFO]: Epoch 051 - training loss: 9343.7587, validation loss: 0.1471
2024-05-22 12:21:54 [INFO]: Epoch 052 - training loss: 9341.9567, validation loss: 0.1427
2024-05-22 12:21:54 [INFO]: Epoch 053 - training loss: 9335.4007, validation loss: 0.1416
2024-05-22 12:21:55 [INFO]: Epoch 054 - training loss: 9335.9874, validation loss: 0.1383
2024-05-22 12:21:55 [INFO]: Epoch 055 - training loss: 9336.7900, validation loss: 0.1382
2024-05-22 12:21:55 [INFO]: Epoch 056 - training loss: 9331.2711, validation loss: 0.1346
2024-05-22 12:21:55 [INFO]: Epoch 057 - training loss: 9329.5097, validation loss: 0.1330
2024-05-22 12:21:55 [INFO]: Epoch 058 - training loss: 9328.6887, validation loss: 0.1315
2024-05-22 12:21:55 [INFO]: Epoch 059 - training loss: 9324.5012, validation loss: 0.1310
2024-05-22 12:21:55 [INFO]: Epoch 060 - training loss: 9325.1757, validation loss: 0.1293
2024-05-22 12:21:56 [INFO]: Epoch 061 - training loss: 9321.6439, validation loss: 0.1258
2024-05-22 12:21:56 [INFO]: Epoch 062 - training loss: 9323.6567, validation loss: 0.1270
2024-05-22 12:21:56 [INFO]: Epoch 063 - training loss: 9355.3937, validation loss: 0.1249
2024-05-22 12:21:56 [INFO]: Epoch 064 - training loss: 9316.8976, validation loss: 0.1237
2024-05-22 12:21:56 [INFO]: Epoch 065 - training loss: 9319.7515, validation loss: 0.1225
2024-05-22 12:21:56 [INFO]: Epoch 066 - training loss: 9313.3011, validation loss: 0.1211
2024-05-22 12:21:56 [INFO]: Epoch 067 - training loss: 9311.0630, validation loss: 0.1207
2024-05-22 12:21:56 [INFO]: Epoch 068 - training loss: 9313.6940, validation loss: 0.1191
2024-05-22 12:21:57 [INFO]: Epoch 069 - training loss: 9314.0684, validation loss: 0.1189
2024-05-22 12:21:57 [INFO]: Epoch 070 - training loss: 9310.4238, validation loss: 0.1164
2024-05-22 12:21:57 [INFO]: Epoch 071 - training loss: 9312.1707, validation loss: 0.1161
2024-05-22 12:21:57 [INFO]: Epoch 072 - training loss: 9307.7010, validation loss: 0.1170
2024-05-22 12:21:57 [INFO]: Epoch 073 - training loss: 9313.5154, validation loss: 0.1132
2024-05-22 12:21:57 [INFO]: Epoch 074 - training loss: 9307.7355, validation loss: 0.1126
2024-05-22 12:21:57 [INFO]: Epoch 075 - training loss: 9306.2384, validation loss: 0.1138
2024-05-22 12:21:57 [INFO]: Epoch 076 - training loss: 9303.9261, validation loss: 0.1128
2024-05-22 12:21:58 [INFO]: Epoch 077 - training loss: 9309.0626, validation loss: 0.1106
2024-05-22 12:21:58 [INFO]: Epoch 078 - training loss: 9302.8392, validation loss: 0.1129
2024-05-22 12:21:58 [INFO]: Epoch 079 - training loss: 9303.8995, validation loss: 0.1106
2024-05-22 12:21:58 [INFO]: Epoch 080 - training loss: 9301.8309, validation loss: 0.1104
2024-05-22 12:21:58 [INFO]: Epoch 081 - training loss: 9300.6325, validation loss: 0.1101
2024-05-22 12:21:58 [INFO]: Epoch 082 - training loss: 9301.1060, validation loss: 0.1087
2024-05-22 12:21:58 [INFO]: Epoch 083 - training loss: 9297.0594, validation loss: 0.1097
2024-05-22 12:21:58 [INFO]: Epoch 084 - training loss: 9299.1007, validation loss: 0.1077
2024-05-22 12:21:59 [INFO]: Epoch 085 - training loss: 9300.9322, validation loss: 0.1087
2024-05-22 12:21:59 [INFO]: Epoch 086 - training loss: 9298.6656, validation loss: 0.1066
2024-05-22 12:21:59 [INFO]: Epoch 087 - training loss: 9299.0456, validation loss: 0.1061
2024-05-22 12:21:59 [INFO]: Epoch 088 - training loss: 9296.4383, validation loss: 0.1055
2024-05-22 12:21:59 [INFO]: Epoch 089 - training loss: 9295.9552, validation loss: 0.1056
2024-05-22 12:21:59 [INFO]: Epoch 090 - training loss: 9296.0762, validation loss: 0.1049
2024-05-22 12:21:59 [INFO]: Epoch 091 - training loss: 9295.2460, validation loss: 0.1041
2024-05-22 12:21:59 [INFO]: Epoch 092 - training loss: 9293.2749, validation loss: 0.1043
2024-05-22 12:22:00 [INFO]: Epoch 093 - training loss: 9322.5971, validation loss: 0.1032
2024-05-22 12:22:00 [INFO]: Epoch 094 - training loss: 9293.2039, validation loss: 0.1043
2024-05-22 12:22:00 [INFO]: Epoch 095 - training loss: 9292.4651, validation loss: 0.1025
2024-05-22 12:22:00 [INFO]: Epoch 096 - training loss: 9293.5887, validation loss: 0.1019
2024-05-22 12:22:00 [INFO]: Epoch 097 - training loss: 9291.1780, validation loss: 0.1020
2024-05-22 12:22:00 [INFO]: Epoch 098 - training loss: 9291.7211, validation loss: 0.1019
2024-05-22 12:22:00 [INFO]: Epoch 099 - training loss: 9291.7917, validation loss: 0.1009
2024-05-22 12:22:01 [INFO]: Epoch 100 - training loss: 9289.5872, validation loss: 0.0999
2024-05-22 12:22:01 [INFO]: Epoch 101 - training loss: 9288.7497, validation loss: 0.1009
2024-05-22 12:22:01 [INFO]: Epoch 102 - training loss: 9292.1238, validation loss: 0.1001
2024-05-22 12:22:01 [INFO]: Epoch 103 - training loss: 9291.2869, validation loss: 0.0987
2024-05-22 12:22:01 [INFO]: Epoch 104 - training loss: 9288.8650, validation loss: 0.0999
2024-05-22 12:22:01 [INFO]: Epoch 105 - training loss: 9288.6922, validation loss: 0.0980
2024-05-22 12:22:01 [INFO]: Epoch 106 - training loss: 9289.5457, validation loss: 0.0982
2024-05-22 12:22:01 [INFO]: Epoch 107 - training loss: 9286.8633, validation loss: 0.0994
2024-05-22 12:22:02 [INFO]: Epoch 108 - training loss: 9287.8730, validation loss: 0.0979
2024-05-22 12:22:02 [INFO]: Epoch 109 - training loss: 9286.6047, validation loss: 0.0975
2024-05-22 12:22:02 [INFO]: Epoch 110 - training loss: 9286.6369, validation loss: 0.0972
2024-05-22 12:22:02 [INFO]: Epoch 111 - training loss: 9286.8256, validation loss: 0.0969
2024-05-22 12:22:02 [INFO]: Epoch 112 - training loss: 9286.2438, validation loss: 0.0952
2024-05-22 12:22:02 [INFO]: Epoch 113 - training loss: 9286.3848, validation loss: 0.0955
2024-05-22 12:22:02 [INFO]: Epoch 114 - training loss: 9284.8389, validation loss: 0.0957
2024-05-22 12:22:02 [INFO]: Epoch 115 - training loss: 9283.9548, validation loss: 0.0951
2024-05-22 12:22:03 [INFO]: Epoch 116 - training loss: 9285.4715, validation loss: 0.0943
2024-05-22 12:22:03 [INFO]: Epoch 117 - training loss: 9286.6796, validation loss: 0.0945
2024-05-22 12:22:03 [INFO]: Epoch 118 - training loss: 9285.2540, validation loss: 0.0942
2024-05-22 12:22:03 [INFO]: Epoch 119 - training loss: 9283.3267, validation loss: 0.0937
2024-05-22 12:22:03 [INFO]: Epoch 120 - training loss: 9285.2332, validation loss: 0.0926
2024-05-22 12:22:03 [INFO]: Epoch 121 - training loss: 9283.9402, validation loss: 0.0916
2024-05-22 12:22:03 [INFO]: Epoch 122 - training loss: 9283.7224, validation loss: 0.0911
2024-05-22 12:22:03 [INFO]: Epoch 123 - training loss: 9284.6732, validation loss: 0.0925
2024-05-22 12:22:04 [INFO]: Epoch 124 - training loss: 9284.2851, validation loss: 0.0911
2024-05-22 12:22:04 [INFO]: Epoch 125 - training loss: 9284.9022, validation loss: 0.0928
2024-05-22 12:22:04 [INFO]: Epoch 126 - training loss: 9282.8559, validation loss: 0.0910
2024-05-22 12:22:04 [INFO]: Epoch 127 - training loss: 9280.9713, validation loss: 0.0904
2024-05-22 12:22:04 [INFO]: Epoch 128 - training loss: 9283.7728, validation loss: 0.0897
2024-05-22 12:22:04 [INFO]: Epoch 129 - training loss: 9281.4393, validation loss: 0.0895
2024-05-22 12:22:04 [INFO]: Epoch 130 - training loss: 9283.0132, validation loss: 0.0889
2024-05-22 12:22:04 [INFO]: Epoch 131 - training loss: 9281.8547, validation loss: 0.0897
2024-05-22 12:22:05 [INFO]: Epoch 132 - training loss: 9281.8717, validation loss: 0.0894
2024-05-22 12:22:05 [INFO]: Epoch 133 - training loss: 9281.2123, validation loss: 0.0870
2024-05-22 12:22:05 [INFO]: Epoch 134 - training loss: 9282.1088, validation loss: 0.0889
2024-05-22 12:22:05 [INFO]: Epoch 135 - training loss: 9281.9703, validation loss: 0.0887
2024-05-22 12:22:05 [INFO]: Epoch 136 - training loss: 9279.6644, validation loss: 0.0892
2024-05-22 12:22:05 [INFO]: Epoch 137 - training loss: 9281.1663, validation loss: 0.0877
2024-05-22 12:22:05 [INFO]: Epoch 138 - training loss: 9280.5237, validation loss: 0.0864
2024-05-22 12:22:06 [INFO]: Epoch 139 - training loss: 9280.0417, validation loss: 0.0869
2024-05-22 12:22:06 [INFO]: Epoch 140 - training loss: 9279.4905, validation loss: 0.0867
2024-05-22 12:22:06 [INFO]: Epoch 141 - training loss: 9280.0024, validation loss: 0.0858
2024-05-22 12:22:06 [INFO]: Epoch 142 - training loss: 9279.5088, validation loss: 0.0851
2024-05-22 12:22:06 [INFO]: Epoch 143 - training loss: 9279.6141, validation loss: 0.0866
2024-05-22 12:22:06 [INFO]: Epoch 144 - training loss: 9277.8666, validation loss: 0.0871
2024-05-22 12:22:06 [INFO]: Epoch 145 - training loss: 9281.2724, validation loss: 0.0845
2024-05-22 12:22:06 [INFO]: Epoch 146 - training loss: 9278.4257, validation loss: 0.0842
2024-05-22 12:22:07 [INFO]: Epoch 147 - training loss: 9278.0215, validation loss: 0.0854
2024-05-22 12:22:07 [INFO]: Epoch 148 - training loss: 9277.4543, validation loss: 0.0838
2024-05-22 12:22:07 [INFO]: Epoch 149 - training loss: 9278.3146, validation loss: 0.0847
2024-05-22 12:22:07 [INFO]: Epoch 150 - training loss: 9277.8228, validation loss: 0.0846
2024-05-22 12:22:07 [INFO]: Epoch 151 - training loss: 9278.3373, validation loss: 0.0857
2024-05-22 12:22:07 [INFO]: Epoch 152 - training loss: 9277.3040, validation loss: 0.0844
2024-05-22 12:22:07 [INFO]: Epoch 153 - training loss: 9277.5603, validation loss: 0.0842
2024-05-22 12:22:07 [INFO]: Epoch 154 - training loss: 9279.3602, validation loss: 0.0850
2024-05-22 12:22:08 [INFO]: Epoch 155 - training loss: 9277.9216, validation loss: 0.0833
2024-05-22 12:22:08 [INFO]: Epoch 156 - training loss: 9277.6122, validation loss: 0.0833
2024-05-22 12:22:08 [INFO]: Epoch 157 - training loss: 9277.2997, validation loss: 0.0834
2024-05-22 12:22:08 [INFO]: Epoch 158 - training loss: 9276.0490, validation loss: 0.0830
2024-05-22 12:22:08 [INFO]: Epoch 159 - training loss: 9276.3157, validation loss: 0.0829
2024-05-22 12:22:08 [INFO]: Epoch 160 - training loss: 9276.3571, validation loss: 0.0820
2024-05-22 12:22:08 [INFO]: Epoch 161 - training loss: 9274.9916, validation loss: 0.0821
2024-05-22 12:22:08 [INFO]: Epoch 162 - training loss: 9275.0406, validation loss: 0.0812
2024-05-22 12:22:09 [INFO]: Epoch 163 - training loss: 9275.5264, validation loss: 0.0824
2024-05-22 12:22:09 [INFO]: Epoch 164 - training loss: 9277.6669, validation loss: 0.0818
2024-05-22 12:22:09 [INFO]: Epoch 165 - training loss: 9277.2361, validation loss: 0.0809
2024-05-22 12:22:09 [INFO]: Epoch 166 - training loss: 9276.2563, validation loss: 0.0803
2024-05-22 12:22:09 [INFO]: Epoch 167 - training loss: 9276.1672, validation loss: 0.0812
2024-05-22 12:22:09 [INFO]: Epoch 168 - training loss: 9274.8300, validation loss: 0.0809
2024-05-22 12:22:09 [INFO]: Epoch 169 - training loss: 9274.8846, validation loss: 0.0808
2024-05-22 12:22:09 [INFO]: Epoch 170 - training loss: 9275.9190, validation loss: 0.0800
2024-05-22 12:22:10 [INFO]: Epoch 171 - training loss: 9275.7134, validation loss: 0.0810
2024-05-22 12:22:10 [INFO]: Epoch 172 - training loss: 9274.6548, validation loss: 0.0814
2024-05-22 12:22:10 [INFO]: Epoch 173 - training loss: 9275.6114, validation loss: 0.0810
2024-05-22 12:22:10 [INFO]: Epoch 174 - training loss: 9276.8758, validation loss: 0.0800
2024-05-22 12:22:10 [INFO]: Epoch 175 - training loss: 9275.3837, validation loss: 0.0810
2024-05-22 12:22:10 [INFO]: Epoch 176 - training loss: 9274.8456, validation loss: 0.0796
2024-05-22 12:22:10 [INFO]: Epoch 177 - training loss: 9275.5922, validation loss: 0.0798
2024-05-22 12:22:11 [INFO]: Epoch 178 - training loss: 9274.6453, validation loss: 0.0787
2024-05-22 12:22:11 [INFO]: Epoch 179 - training loss: 9274.5934, validation loss: 0.0788
2024-05-22 12:22:11 [INFO]: Epoch 180 - training loss: 9273.9573, validation loss: 0.0790
2024-05-22 12:22:11 [INFO]: Epoch 181 - training loss: 9275.0945, validation loss: 0.0807
2024-05-22 12:22:11 [INFO]: Epoch 182 - training loss: 9274.7638, validation loss: 0.0820
2024-05-22 12:22:11 [INFO]: Epoch 183 - training loss: 9274.7843, validation loss: 0.0793
2024-05-22 12:22:11 [INFO]: Epoch 184 - training loss: 9273.5370, validation loss: 0.0799
2024-05-22 12:22:11 [INFO]: Epoch 185 - training loss: 9273.4996, validation loss: 0.0805
2024-05-22 12:22:12 [INFO]: Epoch 186 - training loss: 9274.9371, validation loss: 0.0792
2024-05-22 12:22:12 [INFO]: Epoch 187 - training loss: 9273.9240, validation loss: 0.0792
2024-05-22 12:22:12 [INFO]: Epoch 188 - training loss: 9274.2734, validation loss: 0.0785
2024-05-22 12:22:12 [INFO]: Epoch 189 - training loss: 9274.2040, validation loss: 0.0792
2024-05-22 12:22:12 [INFO]: Epoch 190 - training loss: 9273.4068, validation loss: 0.0787
2024-05-22 12:22:12 [INFO]: Epoch 191 - training loss: 9274.1440, validation loss: 0.0791
2024-05-22 12:22:12 [INFO]: Epoch 192 - training loss: 9273.3643, validation loss: 0.0791
2024-05-22 12:22:12 [INFO]: Epoch 193 - training loss: 9273.5128, validation loss: 0.0802
2024-05-22 12:22:13 [INFO]: Epoch 194 - training loss: 9273.0572, validation loss: 0.0787
2024-05-22 12:22:13 [INFO]: Epoch 195 - training loss: 9273.5125, validation loss: 0.0776
2024-05-22 12:22:13 [INFO]: Epoch 196 - training loss: 9273.9577, validation loss: 0.0783
2024-05-22 12:22:13 [INFO]: Epoch 197 - training loss: 9273.0004, validation loss: 0.0781
2024-05-22 12:22:13 [INFO]: Epoch 198 - training loss: 9272.7351, validation loss: 0.0770
2024-05-22 12:22:13 [INFO]: Epoch 199 - training loss: 9273.5341, validation loss: 0.0785
2024-05-22 12:22:13 [INFO]: Epoch 200 - training loss: 9273.2062, validation loss: 0.0785
2024-05-22 12:22:13 [INFO]: Epoch 201 - training loss: 9274.4911, validation loss: 0.0768
2024-05-22 12:22:14 [INFO]: Epoch 202 - training loss: 9273.9350, validation loss: 0.0778
2024-05-22 12:22:14 [INFO]: Epoch 203 - training loss: 9274.0281, validation loss: 0.0780
2024-05-22 12:22:14 [INFO]: Epoch 204 - training loss: 9271.9093, validation loss: 0.0772
2024-05-22 12:22:14 [INFO]: Epoch 205 - training loss: 9272.7136, validation loss: 0.0784
2024-05-22 12:22:14 [INFO]: Epoch 206 - training loss: 9272.2667, validation loss: 0.0787
2024-05-22 12:22:14 [INFO]: Epoch 207 - training loss: 9272.2437, validation loss: 0.0770
2024-05-22 12:22:14 [INFO]: Epoch 208 - training loss: 9274.1309, validation loss: 0.0775
2024-05-22 12:22:15 [INFO]: Epoch 209 - training loss: 9273.0488, validation loss: 0.0761
2024-05-22 12:22:15 [INFO]: Epoch 210 - training loss: 9274.7257, validation loss: 0.0776
2024-05-22 12:22:15 [INFO]: Epoch 211 - training loss: 9271.8121, validation loss: 0.0782
2024-05-22 12:22:15 [INFO]: Epoch 212 - training loss: 9270.5031, validation loss: 0.0773
2024-05-22 12:22:15 [INFO]: Epoch 213 - training loss: 9272.9437, validation loss: 0.0760
2024-05-22 12:22:15 [INFO]: Epoch 214 - training loss: 9273.0272, validation loss: 0.0756
2024-05-22 12:22:15 [INFO]: Epoch 215 - training loss: 9272.3519, validation loss: 0.0758
2024-05-22 12:22:15 [INFO]: Epoch 216 - training loss: 9271.6779, validation loss: 0.0795
2024-05-22 12:22:16 [INFO]: Epoch 217 - training loss: 9272.4346, validation loss: 0.0774
2024-05-22 12:22:16 [INFO]: Epoch 218 - training loss: 9271.5737, validation loss: 0.0769
2024-05-22 12:22:16 [INFO]: Epoch 219 - training loss: 9272.4535, validation loss: 0.0776
2024-05-22 12:22:16 [INFO]: Epoch 220 - training loss: 9271.4821, validation loss: 0.0785
2024-05-22 12:22:16 [INFO]: Epoch 221 - training loss: 9271.8524, validation loss: 0.0781
2024-05-22 12:22:16 [INFO]: Epoch 222 - training loss: 9270.7470, validation loss: 0.0781
2024-05-22 12:22:16 [INFO]: Epoch 223 - training loss: 9271.7342, validation loss: 0.0774
2024-05-22 12:22:16 [INFO]: Epoch 224 - training loss: 9271.6660, validation loss: 0.0758
2024-05-22 12:22:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:22:16 [INFO]: Finished training. The best model is from epoch#214.
2024-05-22 12:22:16 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_ettm1/20240522_T122148/GPVAE.pypots
2024-05-22 12:22:16 [INFO]: GP-VAE on ETTm1: MAE=0.2689, MSE=0.1579
2024-05-22 12:22:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-22 12:22:16 [INFO]: Using the given device: cuda:0
2024-05-22 12:22:16 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240522_T122216
2024-05-22 12:22:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240522_T122216/tensorboard
2024-05-22 12:22:16 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 12:22:27 [INFO]: Epoch 001 - generator training loss: 0.4523, discriminator training loss: 0.4242, validation loss: 0.3083
2024-05-22 12:22:36 [INFO]: Epoch 002 - generator training loss: 0.0019, discriminator training loss: 0.3247, validation loss: 0.1170
2024-05-22 12:22:45 [INFO]: Epoch 003 - generator training loss: -0.1279, discriminator training loss: 0.3108, validation loss: 0.0662
2024-05-22 12:22:53 [INFO]: Epoch 004 - generator training loss: -0.1420, discriminator training loss: 0.2960, validation loss: 0.0527
2024-05-22 12:23:02 [INFO]: Epoch 005 - generator training loss: -0.1309, discriminator training loss: 0.2769, validation loss: 0.0446
2024-05-22 12:23:11 [INFO]: Epoch 006 - generator training loss: -0.1055, discriminator training loss: 0.2497, validation loss: 0.0412
2024-05-22 12:23:20 [INFO]: Epoch 007 - generator training loss: -0.0857, discriminator training loss: 0.2130, validation loss: 0.0389
2024-05-22 12:23:29 [INFO]: Epoch 008 - generator training loss: -0.0638, discriminator training loss: 0.1810, validation loss: 0.0378
2024-05-22 12:23:38 [INFO]: Epoch 009 - generator training loss: -0.0481, discriminator training loss: 0.1559, validation loss: 0.0362
2024-05-22 12:23:47 [INFO]: Epoch 010 - generator training loss: -0.0382, discriminator training loss: 0.1387, validation loss: 0.0353
2024-05-22 12:23:55 [INFO]: Epoch 011 - generator training loss: -0.0384, discriminator training loss: 0.1308, validation loss: 0.0350
2024-05-22 12:24:04 [INFO]: Epoch 012 - generator training loss: -0.0380, discriminator training loss: 0.1246, validation loss: 0.0341
2024-05-22 12:24:13 [INFO]: Epoch 013 - generator training loss: -0.0395, discriminator training loss: 0.1248, validation loss: 0.0337
2024-05-22 12:24:22 [INFO]: Epoch 014 - generator training loss: -0.0351, discriminator training loss: 0.1222, validation loss: 0.0329
2024-05-22 12:24:30 [INFO]: Epoch 015 - generator training loss: -0.0369, discriminator training loss: 0.1199, validation loss: 0.0328
2024-05-22 12:24:39 [INFO]: Epoch 016 - generator training loss: -0.0352, discriminator training loss: 0.1193, validation loss: 0.0320
2024-05-22 12:24:48 [INFO]: Epoch 017 - generator training loss: -0.0367, discriminator training loss: 0.1166, validation loss: 0.0314
2024-05-22 12:24:57 [INFO]: Epoch 018 - generator training loss: -0.0371, discriminator training loss: 0.1186, validation loss: 0.0313
2024-05-22 12:25:05 [INFO]: Epoch 019 - generator training loss: -0.0387, discriminator training loss: 0.1167, validation loss: 0.0310
2024-05-22 12:25:14 [INFO]: Epoch 020 - generator training loss: -0.0389, discriminator training loss: 0.1148, validation loss: 0.0306
2024-05-22 12:25:23 [INFO]: Epoch 021 - generator training loss: -0.0389, discriminator training loss: 0.1162, validation loss: 0.0302
2024-05-22 12:25:32 [INFO]: Epoch 022 - generator training loss: -0.0377, discriminator training loss: 0.1151, validation loss: 0.0301
2024-05-22 12:25:41 [INFO]: Epoch 023 - generator training loss: -0.0395, discriminator training loss: 0.1138, validation loss: 0.0302
2024-05-22 12:25:49 [INFO]: Epoch 024 - generator training loss: -0.0387, discriminator training loss: 0.1164, validation loss: 0.0300
2024-05-22 12:25:58 [INFO]: Epoch 025 - generator training loss: -0.0393, discriminator training loss: 0.1134, validation loss: 0.0292
2024-05-22 12:26:07 [INFO]: Epoch 026 - generator training loss: -0.0425, discriminator training loss: 0.1109, validation loss: 0.0290
2024-05-22 12:26:16 [INFO]: Epoch 027 - generator training loss: -0.0401, discriminator training loss: 0.1135, validation loss: 0.0284
2024-05-22 12:26:25 [INFO]: Epoch 028 - generator training loss: -0.0418, discriminator training loss: 0.1125, validation loss: 0.0283
2024-05-22 12:26:34 [INFO]: Epoch 029 - generator training loss: -0.0412, discriminator training loss: 0.1125, validation loss: 0.0278
2024-05-22 12:26:42 [INFO]: Epoch 030 - generator training loss: -0.0415, discriminator training loss: 0.1123, validation loss: 0.0274
2024-05-22 12:26:51 [INFO]: Epoch 031 - generator training loss: -0.0429, discriminator training loss: 0.1134, validation loss: 0.0276
2024-05-22 12:27:00 [INFO]: Epoch 032 - generator training loss: -0.0415, discriminator training loss: 0.1118, validation loss: 0.0272
2024-05-22 12:27:09 [INFO]: Epoch 033 - generator training loss: -0.0435, discriminator training loss: 0.1110, validation loss: 0.0265
2024-05-22 12:27:18 [INFO]: Epoch 034 - generator training loss: -0.0437, discriminator training loss: 0.1119, validation loss: 0.0270
2024-05-22 12:27:26 [INFO]: Epoch 035 - generator training loss: -0.0409, discriminator training loss: 0.1099, validation loss: 0.0266
2024-05-22 12:27:35 [INFO]: Epoch 036 - generator training loss: -0.0432, discriminator training loss: 0.1094, validation loss: 0.0259
2024-05-22 12:27:44 [INFO]: Epoch 037 - generator training loss: -0.0428, discriminator training loss: 0.1104, validation loss: 0.0261
2024-05-22 12:27:53 [INFO]: Epoch 038 - generator training loss: -0.0443, discriminator training loss: 0.1106, validation loss: 0.0253
2024-05-22 12:28:01 [INFO]: Epoch 039 - generator training loss: -0.0456, discriminator training loss: 0.1120, validation loss: 0.0256
2024-05-22 12:28:10 [INFO]: Epoch 040 - generator training loss: -0.0445, discriminator training loss: 0.1103, validation loss: 0.0249
2024-05-22 12:28:19 [INFO]: Epoch 041 - generator training loss: -0.0443, discriminator training loss: 0.1095, validation loss: 0.0247
2024-05-22 12:28:28 [INFO]: Epoch 042 - generator training loss: -0.0428, discriminator training loss: 0.1104, validation loss: 0.0253
2024-05-22 12:28:36 [INFO]: Epoch 043 - generator training loss: -0.0415, discriminator training loss: 0.1078, validation loss: 0.0254
2024-05-22 12:28:45 [INFO]: Epoch 044 - generator training loss: -0.0406, discriminator training loss: 0.1093, validation loss: 0.0250
2024-05-22 12:28:54 [INFO]: Epoch 045 - generator training loss: -0.0433, discriminator training loss: 0.1081, validation loss: 0.0247
2024-05-22 12:29:03 [INFO]: Epoch 046 - generator training loss: -0.0447, discriminator training loss: 0.1103, validation loss: 0.0251
2024-05-22 12:29:12 [INFO]: Epoch 047 - generator training loss: -0.0421, discriminator training loss: 0.1089, validation loss: 0.0253
2024-05-22 12:29:20 [INFO]: Epoch 048 - generator training loss: -0.0445, discriminator training loss: 0.1090, validation loss: 0.0247
2024-05-22 12:29:29 [INFO]: Epoch 049 - generator training loss: -0.0450, discriminator training loss: 0.1086, validation loss: 0.0241
2024-05-22 12:29:38 [INFO]: Epoch 050 - generator training loss: -0.0445, discriminator training loss: 0.1085, validation loss: 0.0253
2024-05-22 12:29:47 [INFO]: Epoch 051 - generator training loss: -0.0424, discriminator training loss: 0.1086, validation loss: 0.0246
2024-05-22 12:29:56 [INFO]: Epoch 052 - generator training loss: -0.0468, discriminator training loss: 0.1086, validation loss: 0.0241
2024-05-22 12:30:05 [INFO]: Epoch 053 - generator training loss: -0.0426, discriminator training loss: 0.1116, validation loss: 0.0242
2024-05-22 12:30:14 [INFO]: Epoch 054 - generator training loss: -0.0460, discriminator training loss: 0.1088, validation loss: 0.0237
2024-05-22 12:30:23 [INFO]: Epoch 055 - generator training loss: -0.0456, discriminator training loss: 0.1075, validation loss: 0.0243
2024-05-22 12:30:32 [INFO]: Epoch 056 - generator training loss: -0.0451, discriminator training loss: 0.1099, validation loss: 0.0244
2024-05-22 12:30:41 [INFO]: Epoch 057 - generator training loss: -0.0441, discriminator training loss: 0.1086, validation loss: 0.0237
2024-05-22 12:30:50 [INFO]: Epoch 058 - generator training loss: -0.0454, discriminator training loss: 0.1076, validation loss: 0.0237
2024-05-22 12:30:59 [INFO]: Epoch 059 - generator training loss: -0.0456, discriminator training loss: 0.1079, validation loss: 0.0239
2024-05-22 12:31:08 [INFO]: Epoch 060 - generator training loss: -0.0458, discriminator training loss: 0.1083, validation loss: 0.0241
2024-05-22 12:31:17 [INFO]: Epoch 061 - generator training loss: -0.0440, discriminator training loss: 0.1071, validation loss: 0.0238
2024-05-22 12:31:26 [INFO]: Epoch 062 - generator training loss: -0.0442, discriminator training loss: 0.1076, validation loss: 0.0249
2024-05-22 12:31:35 [INFO]: Epoch 063 - generator training loss: -0.0463, discriminator training loss: 0.1094, validation loss: 0.0237
2024-05-22 12:31:44 [INFO]: Epoch 064 - generator training loss: -0.0457, discriminator training loss: 0.1085, validation loss: 0.0233
2024-05-22 12:31:53 [INFO]: Epoch 065 - generator training loss: -0.0448, discriminator training loss: 0.1096, validation loss: 0.0233
2024-05-22 12:32:02 [INFO]: Epoch 066 - generator training loss: -0.0454, discriminator training loss: 0.1069, validation loss: 0.0231
2024-05-22 12:32:11 [INFO]: Epoch 067 - generator training loss: -0.0456, discriminator training loss: 0.1088, validation loss: 0.0236
2024-05-22 12:32:20 [INFO]: Epoch 068 - generator training loss: -0.0457, discriminator training loss: 0.1065, validation loss: 0.0232
2024-05-22 12:32:29 [INFO]: Epoch 069 - generator training loss: -0.0460, discriminator training loss: 0.1068, validation loss: 0.0231
2024-05-22 12:32:38 [INFO]: Epoch 070 - generator training loss: -0.0493, discriminator training loss: 0.1072, validation loss: 0.0228
2024-05-22 12:32:47 [INFO]: Epoch 071 - generator training loss: -0.0472, discriminator training loss: 0.1064, validation loss: 0.0232
2024-05-22 12:32:56 [INFO]: Epoch 072 - generator training loss: -0.0458, discriminator training loss: 0.1088, validation loss: 0.0230
2024-05-22 12:33:05 [INFO]: Epoch 073 - generator training loss: -0.0436, discriminator training loss: 0.1058, validation loss: 0.0230
2024-05-22 12:33:14 [INFO]: Epoch 074 - generator training loss: -0.0466, discriminator training loss: 0.1086, validation loss: 0.0232
2024-05-22 12:33:23 [INFO]: Epoch 075 - generator training loss: -0.0449, discriminator training loss: 0.1076, validation loss: 0.0229
2024-05-22 12:33:32 [INFO]: Epoch 076 - generator training loss: -0.0458, discriminator training loss: 0.1082, validation loss: 0.0228
2024-05-22 12:33:41 [INFO]: Epoch 077 - generator training loss: -0.0470, discriminator training loss: 0.1060, validation loss: 0.0227
2024-05-22 12:33:50 [INFO]: Epoch 078 - generator training loss: -0.0454, discriminator training loss: 0.1067, validation loss: 0.0228
2024-05-22 12:33:59 [INFO]: Epoch 079 - generator training loss: -0.0482, discriminator training loss: 0.1067, validation loss: 0.0225
2024-05-22 12:34:08 [INFO]: Epoch 080 - generator training loss: -0.0461, discriminator training loss: 0.1072, validation loss: 0.0223
2024-05-22 12:34:17 [INFO]: Epoch 081 - generator training loss: -0.0493, discriminator training loss: 0.1094, validation loss: 0.0229
2024-05-22 12:34:26 [INFO]: Epoch 082 - generator training loss: -0.0462, discriminator training loss: 0.1070, validation loss: 0.0231
2024-05-22 12:34:35 [INFO]: Epoch 083 - generator training loss: -0.0480, discriminator training loss: 0.1071, validation loss: 0.0226
2024-05-22 12:34:44 [INFO]: Epoch 084 - generator training loss: -0.0470, discriminator training loss: 0.1056, validation loss: 0.0223
2024-05-22 12:34:53 [INFO]: Epoch 085 - generator training loss: -0.0481, discriminator training loss: 0.1045, validation loss: 0.0237
2024-05-22 12:35:02 [INFO]: Epoch 086 - generator training loss: -0.0505, discriminator training loss: 0.1061, validation loss: 0.0222
2024-05-22 12:35:11 [INFO]: Epoch 087 - generator training loss: -0.0493, discriminator training loss: 0.1045, validation loss: 0.0225
2024-05-22 12:35:20 [INFO]: Epoch 088 - generator training loss: -0.0486, discriminator training loss: 0.1054, validation loss: 0.0225
2024-05-22 12:35:29 [INFO]: Epoch 089 - generator training loss: -0.0492, discriminator training loss: 0.1036, validation loss: 0.0220
2024-05-22 12:35:38 [INFO]: Epoch 090 - generator training loss: -0.0501, discriminator training loss: 0.1048, validation loss: 0.0224
2024-05-22 12:35:47 [INFO]: Epoch 091 - generator training loss: -0.0487, discriminator training loss: 0.1048, validation loss: 0.0229
2024-05-22 12:35:56 [INFO]: Epoch 092 - generator training loss: -0.0500, discriminator training loss: 0.1075, validation loss: 0.0228
2024-05-22 12:36:05 [INFO]: Epoch 093 - generator training loss: -0.0462, discriminator training loss: 0.1056, validation loss: 0.0219
2024-05-22 12:36:14 [INFO]: Epoch 094 - generator training loss: -0.0488, discriminator training loss: 0.1055, validation loss: 0.0220
2024-05-22 12:36:23 [INFO]: Epoch 095 - generator training loss: -0.0486, discriminator training loss: 0.1057, validation loss: 0.0224
2024-05-22 12:36:32 [INFO]: Epoch 096 - generator training loss: -0.0470, discriminator training loss: 0.1053, validation loss: 0.0223
2024-05-22 12:36:41 [INFO]: Epoch 097 - generator training loss: -0.0486, discriminator training loss: 0.1046, validation loss: 0.0222
2024-05-22 12:36:50 [INFO]: Epoch 098 - generator training loss: -0.0496, discriminator training loss: 0.1032, validation loss: 0.0225
2024-05-22 12:36:59 [INFO]: Epoch 099 - generator training loss: -0.0492, discriminator training loss: 0.1052, validation loss: 0.0218
2024-05-22 12:37:08 [INFO]: Epoch 100 - generator training loss: -0.0496, discriminator training loss: 0.1051, validation loss: 0.0229
2024-05-22 12:37:17 [INFO]: Epoch 101 - generator training loss: -0.0485, discriminator training loss: 0.1051, validation loss: 0.0215
2024-05-22 12:37:26 [INFO]: Epoch 102 - generator training loss: -0.0477, discriminator training loss: 0.1015, validation loss: 0.0221
2024-05-22 12:37:35 [INFO]: Epoch 103 - generator training loss: -0.0503, discriminator training loss: 0.1061, validation loss: 0.0220
2024-05-22 12:37:44 [INFO]: Epoch 104 - generator training loss: -0.0503, discriminator training loss: 0.1041, validation loss: 0.0220
2024-05-22 12:37:53 [INFO]: Epoch 105 - generator training loss: -0.0522, discriminator training loss: 0.1053, validation loss: 0.0221
2024-05-22 12:38:02 [INFO]: Epoch 106 - generator training loss: -0.0476, discriminator training loss: 0.1038, validation loss: 0.0223
2024-05-22 12:38:11 [INFO]: Epoch 107 - generator training loss: -0.0488, discriminator training loss: 0.1039, validation loss: 0.0218
2024-05-22 12:38:20 [INFO]: Epoch 108 - generator training loss: -0.0491, discriminator training loss: 0.1035, validation loss: 0.0222
2024-05-22 12:38:29 [INFO]: Epoch 109 - generator training loss: -0.0497, discriminator training loss: 0.1071, validation loss: 0.0225
2024-05-22 12:38:38 [INFO]: Epoch 110 - generator training loss: -0.0483, discriminator training loss: 0.1054, validation loss: 0.0214
2024-05-22 12:38:47 [INFO]: Epoch 111 - generator training loss: -0.0502, discriminator training loss: 0.1048, validation loss: 0.0215
2024-05-22 12:38:56 [INFO]: Epoch 112 - generator training loss: -0.0501, discriminator training loss: 0.1063, validation loss: 0.0225
2024-05-22 12:39:05 [INFO]: Epoch 113 - generator training loss: -0.0482, discriminator training loss: 0.1028, validation loss: 0.0215
2024-05-22 12:39:14 [INFO]: Epoch 114 - generator training loss: -0.0518, discriminator training loss: 0.1041, validation loss: 0.0215
2024-05-22 12:39:23 [INFO]: Epoch 115 - generator training loss: -0.0504, discriminator training loss: 0.1061, validation loss: 0.0218
2024-05-22 12:39:32 [INFO]: Epoch 116 - generator training loss: -0.0495, discriminator training loss: 0.1058, validation loss: 0.0210
2024-05-22 12:39:41 [INFO]: Epoch 117 - generator training loss: -0.0510, discriminator training loss: 0.1038, validation loss: 0.0216
2024-05-22 12:39:50 [INFO]: Epoch 118 - generator training loss: -0.0500, discriminator training loss: 0.1052, validation loss: 0.0215
2024-05-22 12:39:59 [INFO]: Epoch 119 - generator training loss: -0.0472, discriminator training loss: 0.1036, validation loss: 0.0227
2024-05-22 12:40:08 [INFO]: Epoch 120 - generator training loss: -0.0501, discriminator training loss: 0.1031, validation loss: 0.0218
2024-05-22 12:40:17 [INFO]: Epoch 121 - generator training loss: -0.0496, discriminator training loss: 0.1036, validation loss: 0.0220
2024-05-22 12:40:26 [INFO]: Epoch 122 - generator training loss: -0.0482, discriminator training loss: 0.1036, validation loss: 0.0216
2024-05-22 12:40:35 [INFO]: Epoch 123 - generator training loss: -0.0478, discriminator training loss: 0.1058, validation loss: 0.0221
2024-05-22 12:40:44 [INFO]: Epoch 124 - generator training loss: -0.0476, discriminator training loss: 0.1043, validation loss: 0.0216
2024-05-22 12:40:53 [INFO]: Epoch 125 - generator training loss: -0.0492, discriminator training loss: 0.1042, validation loss: 0.0218
2024-05-22 12:41:02 [INFO]: Epoch 126 - generator training loss: -0.0503, discriminator training loss: 0.1026, validation loss: 0.0217
2024-05-22 12:41:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:41:02 [INFO]: Finished training. The best model is from epoch#116.
2024-05-22 12:41:02 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_ettm1/20240522_T122216/USGAN.pypots
2024-05-22 12:41:03 [INFO]: US-GAN on ETTm1: MAE=0.1371, MSE=0.0492
2024-05-22 12:41:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-22 12:41:03 [INFO]: Using the given device: cuda:0
2024-05-22 12:41:03 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240522_T124103
2024-05-22 12:41:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240522_T124103/tensorboard
2024-05-22 12:41:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 12:41:11 [INFO]: Epoch 001 - training loss: 1.2952, validation loss: 0.2993
2024-05-22 12:41:17 [INFO]: Epoch 002 - training loss: 0.8675, validation loss: 0.0868
2024-05-22 12:41:23 [INFO]: Epoch 003 - training loss: 0.7023, validation loss: 0.0577
2024-05-22 12:41:29 [INFO]: Epoch 004 - training loss: 0.6334, validation loss: 0.0452
2024-05-22 12:41:35 [INFO]: Epoch 005 - training loss: 0.5901, validation loss: 0.0405
2024-05-22 12:41:41 [INFO]: Epoch 006 - training loss: 0.5625, validation loss: 0.0405
2024-05-22 12:41:46 [INFO]: Epoch 007 - training loss: 0.5363, validation loss: 0.0383
2024-05-22 12:41:53 [INFO]: Epoch 008 - training loss: 0.5093, validation loss: 0.0353
2024-05-22 12:41:58 [INFO]: Epoch 009 - training loss: 0.4856, validation loss: 0.0338
2024-05-22 12:42:04 [INFO]: Epoch 010 - training loss: 0.4686, validation loss: 0.0328
2024-05-22 12:42:10 [INFO]: Epoch 011 - training loss: 0.4544, validation loss: 0.0304
2024-05-22 12:42:16 [INFO]: Epoch 012 - training loss: 0.4423, validation loss: 0.0292
2024-05-22 12:42:22 [INFO]: Epoch 013 - training loss: 0.4237, validation loss: 0.0405
2024-05-22 12:42:28 [INFO]: Epoch 014 - training loss: 0.4548, validation loss: 0.0308
2024-05-22 12:42:34 [INFO]: Epoch 015 - training loss: 0.4182, validation loss: 0.0287
2024-05-22 12:42:40 [INFO]: Epoch 016 - training loss: 0.4065, validation loss: 0.0273
2024-05-22 12:42:46 [INFO]: Epoch 017 - training loss: 0.4565, validation loss: 0.0276
2024-05-22 12:42:52 [INFO]: Epoch 018 - training loss: 0.4188, validation loss: 0.0281
2024-05-22 12:42:58 [INFO]: Epoch 019 - training loss: 0.4071, validation loss: 0.0257
2024-05-22 12:43:04 [INFO]: Epoch 020 - training loss: 0.3887, validation loss: 0.0263
2024-05-22 12:43:10 [INFO]: Epoch 021 - training loss: 0.3855, validation loss: 0.0258
2024-05-22 12:43:16 [INFO]: Epoch 022 - training loss: 0.3886, validation loss: 0.0254
2024-05-22 12:43:22 [INFO]: Epoch 023 - training loss: 0.3905, validation loss: 0.0255
2024-05-22 12:43:28 [INFO]: Epoch 024 - training loss: 0.3877, validation loss: 0.0251
2024-05-22 12:43:34 [INFO]: Epoch 025 - training loss: 0.3877, validation loss: 0.0256
2024-05-22 12:43:40 [INFO]: Epoch 026 - training loss: 0.3835, validation loss: 0.0253
2024-05-22 12:43:46 [INFO]: Epoch 027 - training loss: 0.3841, validation loss: 0.0251
2024-05-22 12:43:52 [INFO]: Epoch 028 - training loss: 0.3867, validation loss: 0.0253
2024-05-22 12:43:58 [INFO]: Epoch 029 - training loss: 0.3854, validation loss: 0.0250
2024-05-22 12:44:04 [INFO]: Epoch 030 - training loss: 0.3875, validation loss: 0.0252
2024-05-22 12:44:10 [INFO]: Epoch 031 - training loss: 0.3820, validation loss: 0.0254
2024-05-22 12:44:16 [INFO]: Epoch 032 - training loss: 0.3781, validation loss: 0.0246
2024-05-22 12:44:22 [INFO]: Epoch 033 - training loss: 0.3815, validation loss: 0.0248
2024-05-22 12:44:28 [INFO]: Epoch 034 - training loss: 0.3865, validation loss: 0.0253
2024-05-22 12:44:34 [INFO]: Epoch 035 - training loss: 0.3943, validation loss: 0.0244
2024-05-22 12:44:40 [INFO]: Epoch 036 - training loss: 0.3775, validation loss: 0.0243
2024-05-22 12:44:46 [INFO]: Epoch 037 - training loss: 0.3958, validation loss: 0.0259
2024-05-22 12:44:52 [INFO]: Epoch 038 - training loss: 0.3854, validation loss: 0.0248
2024-05-22 12:44:58 [INFO]: Epoch 039 - training loss: 0.3753, validation loss: 0.0251
2024-05-22 12:45:04 [INFO]: Epoch 040 - training loss: 0.3767, validation loss: 0.0249
2024-05-22 12:45:10 [INFO]: Epoch 041 - training loss: 0.3823, validation loss: 0.0245
2024-05-22 12:45:16 [INFO]: Epoch 042 - training loss: 0.3811, validation loss: 0.0248
2024-05-22 12:45:22 [INFO]: Epoch 043 - training loss: 0.3745, validation loss: 0.0243
2024-05-22 12:45:28 [INFO]: Epoch 044 - training loss: 0.3791, validation loss: 0.0244
2024-05-22 12:45:34 [INFO]: Epoch 045 - training loss: 0.3749, validation loss: 0.0243
2024-05-22 12:45:40 [INFO]: Epoch 046 - training loss: 0.3788, validation loss: 0.0247
2024-05-22 12:45:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:45:40 [INFO]: Finished training. The best model is from epoch#36.
2024-05-22 12:45:40 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_ettm1/20240522_T124103/BRITS.pypots
2024-05-22 12:45:41 [INFO]: BRITS on ETTm1: MAE=0.1334, MSE=0.0526
2024-05-22 12:45:41 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-22 12:45:41 [INFO]: Using the given device: cuda:0
2024-05-22 12:45:41 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541
2024-05-22 12:45:41 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/tensorboard
2024-05-22 12:45:41 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 12:45:42 [INFO]: Epoch 001 - training loss: 1.3773, validation loss: 1.3602
2024-05-22 12:45:42 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch1_loss1.3601628243923187.pypots
2024-05-22 12:45:43 [INFO]: Epoch 002 - training loss: 1.0905, validation loss: 1.2271
2024-05-22 12:45:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch2_loss1.2270876467227936.pypots
2024-05-22 12:45:43 [INFO]: Epoch 003 - training loss: 0.9861, validation loss: 1.1231
2024-05-22 12:45:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch3_loss1.123109295964241.pypots
2024-05-22 12:45:43 [INFO]: Epoch 004 - training loss: 0.9561, validation loss: 1.0641
2024-05-22 12:45:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch4_loss1.0640605837106705.pypots
2024-05-22 12:45:43 [INFO]: Epoch 005 - training loss: 0.9240, validation loss: 1.0420
2024-05-22 12:45:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch5_loss1.0419862568378448.pypots
2024-05-22 12:45:43 [INFO]: Epoch 006 - training loss: 0.9049, validation loss: 1.0260
2024-05-22 12:45:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch6_loss1.0260237455368042.pypots
2024-05-22 12:45:44 [INFO]: Epoch 007 - training loss: 0.9335, validation loss: 1.0118
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch7_loss1.0117761343717575.pypots
2024-05-22 12:45:44 [INFO]: Epoch 008 - training loss: 0.9249, validation loss: 1.0056
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch8_loss1.0056265145540237.pypots
2024-05-22 12:45:44 [INFO]: Epoch 009 - training loss: 0.9165, validation loss: 0.9989
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch9_loss0.9989389479160309.pypots
2024-05-22 12:45:44 [INFO]: Epoch 010 - training loss: 0.9024, validation loss: 0.9980
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch10_loss0.9979796260595322.pypots
2024-05-22 12:45:44 [INFO]: Epoch 011 - training loss: 0.9086, validation loss: 0.9935
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch11_loss0.9935083836317062.pypots
2024-05-22 12:45:44 [INFO]: Epoch 012 - training loss: 0.8813, validation loss: 0.9908
2024-05-22 12:45:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch12_loss0.9908466637134552.pypots
2024-05-22 12:45:45 [INFO]: Epoch 013 - training loss: 0.8865, validation loss: 0.9860
2024-05-22 12:45:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch13_loss0.9860344529151917.pypots
2024-05-22 12:45:45 [INFO]: Epoch 014 - training loss: 0.8743, validation loss: 0.9851
2024-05-22 12:45:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch14_loss0.9851463437080383.pypots
2024-05-22 12:45:45 [INFO]: Epoch 015 - training loss: 0.8836, validation loss: 0.9823
2024-05-22 12:45:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch15_loss0.9822850823402405.pypots
2024-05-22 12:45:45 [INFO]: Epoch 016 - training loss: 0.8378, validation loss: 0.9807
2024-05-22 12:45:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch16_loss0.9807335436344147.pypots
2024-05-22 12:45:45 [INFO]: Epoch 017 - training loss: 0.8729, validation loss: 0.9757
2024-05-22 12:45:45 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch17_loss0.9757334738969803.pypots
2024-05-22 12:45:46 [INFO]: Epoch 018 - training loss: 0.8392, validation loss: 0.9730
2024-05-22 12:45:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch18_loss0.9730424284934998.pypots
2024-05-22 12:45:46 [INFO]: Epoch 019 - training loss: 0.8728, validation loss: 0.9703
2024-05-22 12:45:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch19_loss0.9703161269426346.pypots
2024-05-22 12:45:46 [INFO]: Epoch 020 - training loss: 0.8765, validation loss: 0.9662
2024-05-22 12:45:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch20_loss0.9661514163017273.pypots
2024-05-22 12:45:46 [INFO]: Epoch 021 - training loss: 0.8482, validation loss: 0.9661
2024-05-22 12:45:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch21_loss0.9661131799221039.pypots
2024-05-22 12:45:46 [INFO]: Epoch 022 - training loss: 0.8264, validation loss: 0.9610
2024-05-22 12:45:46 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch22_loss0.9609681665897369.pypots
2024-05-22 12:45:47 [INFO]: Epoch 023 - training loss: 0.8301, validation loss: 0.9596
2024-05-22 12:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch23_loss0.9595500230789185.pypots
2024-05-22 12:45:47 [INFO]: Epoch 024 - training loss: 0.8398, validation loss: 0.9598
2024-05-22 12:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch24_loss0.9598401039838791.pypots
2024-05-22 12:45:47 [INFO]: Epoch 025 - training loss: 0.8402, validation loss: 0.9548
2024-05-22 12:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch25_loss0.9548216462135315.pypots
2024-05-22 12:45:47 [INFO]: Epoch 026 - training loss: 0.8270, validation loss: 0.9506
2024-05-22 12:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch26_loss0.9505862891674042.pypots
2024-05-22 12:45:47 [INFO]: Epoch 027 - training loss: 0.8202, validation loss: 0.9485
2024-05-22 12:45:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch27_loss0.9484641402959824.pypots
2024-05-22 12:45:48 [INFO]: Epoch 028 - training loss: 0.8110, validation loss: 0.9478
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch28_loss0.9478368908166885.pypots
2024-05-22 12:45:48 [INFO]: Epoch 029 - training loss: 0.8397, validation loss: 0.9428
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch29_loss0.9428383857011795.pypots
2024-05-22 12:45:48 [INFO]: Epoch 030 - training loss: 0.8182, validation loss: 0.9406
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch30_loss0.9406174868345261.pypots
2024-05-22 12:45:48 [INFO]: Epoch 031 - training loss: 0.8488, validation loss: 0.9417
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch31_loss0.9417065978050232.pypots
2024-05-22 12:45:48 [INFO]: Epoch 032 - training loss: 0.8145, validation loss: 0.9374
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch32_loss0.9373764097690582.pypots
2024-05-22 12:45:48 [INFO]: Epoch 033 - training loss: 0.8282, validation loss: 0.9346
2024-05-22 12:45:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch33_loss0.934614509344101.pypots
2024-05-22 12:45:49 [INFO]: Epoch 034 - training loss: 0.8185, validation loss: 0.9303
2024-05-22 12:45:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch34_loss0.9303146749734879.pypots
2024-05-22 12:45:49 [INFO]: Epoch 035 - training loss: 0.7986, validation loss: 0.9333
2024-05-22 12:45:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch35_loss0.9332969784736633.pypots
2024-05-22 12:45:49 [INFO]: Epoch 036 - training loss: 0.7938, validation loss: 0.9296
2024-05-22 12:45:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch36_loss0.929612472653389.pypots
2024-05-22 12:45:49 [INFO]: Epoch 037 - training loss: 0.8102, validation loss: 0.9239
2024-05-22 12:45:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch37_loss0.9239277988672256.pypots
2024-05-22 12:45:49 [INFO]: Epoch 038 - training loss: 0.8193, validation loss: 0.9201
2024-05-22 12:45:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch38_loss0.9201412349939346.pypots
2024-05-22 12:45:50 [INFO]: Epoch 039 - training loss: 0.8080, validation loss: 0.9215
2024-05-22 12:45:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch39_loss0.92154560983181.pypots
2024-05-22 12:45:50 [INFO]: Epoch 040 - training loss: 0.7919, validation loss: 0.9165
2024-05-22 12:45:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch40_loss0.9164615720510483.pypots
2024-05-22 12:45:50 [INFO]: Epoch 041 - training loss: 0.8041, validation loss: 0.9152
2024-05-22 12:45:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch41_loss0.915218323469162.pypots
2024-05-22 12:45:50 [INFO]: Epoch 042 - training loss: 0.7776, validation loss: 0.9105
2024-05-22 12:45:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch42_loss0.9105287045240402.pypots
2024-05-22 12:45:50 [INFO]: Epoch 043 - training loss: 0.8060, validation loss: 0.9068
2024-05-22 12:45:50 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch43_loss0.9068398773670197.pypots
2024-05-22 12:45:51 [INFO]: Epoch 044 - training loss: 0.7732, validation loss: 0.9070
2024-05-22 12:45:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch44_loss0.9069817066192627.pypots
2024-05-22 12:45:51 [INFO]: Epoch 045 - training loss: 0.7851, validation loss: 0.9005
2024-05-22 12:45:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch45_loss0.9004877507686615.pypots
2024-05-22 12:45:51 [INFO]: Epoch 046 - training loss: 0.7989, validation loss: 0.9009
2024-05-22 12:45:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch46_loss0.9009165614843369.pypots
2024-05-22 12:45:51 [INFO]: Epoch 047 - training loss: 0.7685, validation loss: 0.8986
2024-05-22 12:45:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch47_loss0.898565798997879.pypots
2024-05-22 12:45:51 [INFO]: Epoch 048 - training loss: 0.7862, validation loss: 0.8965
2024-05-22 12:45:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch48_loss0.8964626789093018.pypots
2024-05-22 12:45:52 [INFO]: Epoch 049 - training loss: 0.7706, validation loss: 0.8958
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch49_loss0.8957629799842834.pypots
2024-05-22 12:45:52 [INFO]: Epoch 050 - training loss: 0.8009, validation loss: 0.8944
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch50_loss0.8944326341152191.pypots
2024-05-22 12:45:52 [INFO]: Epoch 051 - training loss: 0.8245, validation loss: 0.8928
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch51_loss0.8927889615297318.pypots
2024-05-22 12:45:52 [INFO]: Epoch 052 - training loss: 0.7815, validation loss: 0.8910
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch52_loss0.8909705579280853.pypots
2024-05-22 12:45:52 [INFO]: Epoch 053 - training loss: 0.7960, validation loss: 0.8884
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch53_loss0.888367235660553.pypots
2024-05-22 12:45:52 [INFO]: Epoch 054 - training loss: 0.7662, validation loss: 0.8871
2024-05-22 12:45:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch54_loss0.8871213495731354.pypots
2024-05-22 12:45:53 [INFO]: Epoch 055 - training loss: 0.7642, validation loss: 0.8862
2024-05-22 12:45:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch55_loss0.8862337321043015.pypots
2024-05-22 12:45:53 [INFO]: Epoch 056 - training loss: 0.7959, validation loss: 0.8823
2024-05-22 12:45:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch56_loss0.8823113739490509.pypots
2024-05-22 12:45:53 [INFO]: Epoch 057 - training loss: 0.7918, validation loss: 0.8812
2024-05-22 12:45:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch57_loss0.8812180012464523.pypots
2024-05-22 12:45:53 [INFO]: Epoch 058 - training loss: 0.7953, validation loss: 0.8807
2024-05-22 12:45:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch58_loss0.8806925266981125.pypots
2024-05-22 12:45:53 [INFO]: Epoch 059 - training loss: 0.7738, validation loss: 0.8801
2024-05-22 12:45:53 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch59_loss0.8800525069236755.pypots
2024-05-22 12:45:54 [INFO]: Epoch 060 - training loss: 0.7810, validation loss: 0.8805
2024-05-22 12:45:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch60_loss0.880542203783989.pypots
2024-05-22 12:45:54 [INFO]: Epoch 061 - training loss: 0.7835, validation loss: 0.8783
2024-05-22 12:45:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch61_loss0.8782891184091568.pypots
2024-05-22 12:45:54 [INFO]: Epoch 062 - training loss: 0.7812, validation loss: 0.8773
2024-05-22 12:45:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch62_loss0.877283051609993.pypots
2024-05-22 12:45:54 [INFO]: Epoch 063 - training loss: 0.7670, validation loss: 0.8754
2024-05-22 12:45:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch63_loss0.8754130601882935.pypots
2024-05-22 12:45:54 [INFO]: Epoch 064 - training loss: 0.8067, validation loss: 0.8765
2024-05-22 12:45:54 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch64_loss0.8764619678258896.pypots
2024-05-22 12:45:55 [INFO]: Epoch 065 - training loss: 0.8044, validation loss: 0.8739
2024-05-22 12:45:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch65_loss0.8738719522953033.pypots
2024-05-22 12:45:55 [INFO]: Epoch 066 - training loss: 0.7771, validation loss: 0.8730
2024-05-22 12:45:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch66_loss0.8729932010173798.pypots
2024-05-22 12:45:55 [INFO]: Epoch 067 - training loss: 0.7920, validation loss: 0.8723
2024-05-22 12:45:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch67_loss0.8723070025444031.pypots
2024-05-22 12:45:55 [INFO]: Epoch 068 - training loss: 0.7887, validation loss: 0.8731
2024-05-22 12:45:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch68_loss0.873142883181572.pypots
2024-05-22 12:45:55 [INFO]: Epoch 069 - training loss: 0.8004, validation loss: 0.8733
2024-05-22 12:45:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch69_loss0.8732760101556778.pypots
2024-05-22 12:45:56 [INFO]: Epoch 070 - training loss: 0.7791, validation loss: 0.8691
2024-05-22 12:45:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch70_loss0.8690922409296036.pypots
2024-05-22 12:45:56 [INFO]: Epoch 071 - training loss: 0.7870, validation loss: 0.8686
2024-05-22 12:45:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch71_loss0.8685793876647949.pypots
2024-05-22 12:45:56 [INFO]: Epoch 072 - training loss: 0.7764, validation loss: 0.8674
2024-05-22 12:45:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch72_loss0.867436558008194.pypots
2024-05-22 12:45:56 [INFO]: Epoch 073 - training loss: 0.7754, validation loss: 0.8674
2024-05-22 12:45:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch73_loss0.8674428164958954.pypots
2024-05-22 12:45:56 [INFO]: Epoch 074 - training loss: 0.7711, validation loss: 0.8669
2024-05-22 12:45:56 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch74_loss0.8668590188026428.pypots
2024-05-22 12:45:57 [INFO]: Epoch 075 - training loss: 0.7653, validation loss: 0.8668
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch75_loss0.866793155670166.pypots
2024-05-22 12:45:57 [INFO]: Epoch 076 - training loss: 0.7715, validation loss: 0.8668
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch76_loss0.8668170720338821.pypots
2024-05-22 12:45:57 [INFO]: Epoch 077 - training loss: 0.7794, validation loss: 0.8671
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch77_loss0.8671320527791977.pypots
2024-05-22 12:45:57 [INFO]: Epoch 078 - training loss: 0.7936, validation loss: 0.8633
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch78_loss0.8633441776037216.pypots
2024-05-22 12:45:57 [INFO]: Epoch 079 - training loss: 0.7950, validation loss: 0.8684
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch79_loss0.8683604300022125.pypots
2024-05-22 12:45:57 [INFO]: Epoch 080 - training loss: 0.7680, validation loss: 0.8653
2024-05-22 12:45:57 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch80_loss0.8653340637683868.pypots
2024-05-22 12:45:58 [INFO]: Epoch 081 - training loss: 0.7895, validation loss: 0.8633
2024-05-22 12:45:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch81_loss0.8632856905460358.pypots
2024-05-22 12:45:58 [INFO]: Epoch 082 - training loss: 0.7802, validation loss: 0.8670
2024-05-22 12:45:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch82_loss0.8670354932546616.pypots
2024-05-22 12:45:58 [INFO]: Epoch 083 - training loss: 0.7648, validation loss: 0.8629
2024-05-22 12:45:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch83_loss0.8628679811954498.pypots
2024-05-22 12:45:58 [INFO]: Epoch 084 - training loss: 0.8345, validation loss: 0.8654
2024-05-22 12:45:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch84_loss0.8654480427503586.pypots
2024-05-22 12:45:58 [INFO]: Epoch 085 - training loss: 0.8077, validation loss: 0.8604
2024-05-22 12:45:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch85_loss0.8603682070970535.pypots
2024-05-22 12:45:59 [INFO]: Epoch 086 - training loss: 0.7938, validation loss: 0.8633
2024-05-22 12:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch86_loss0.8633421361446381.pypots
2024-05-22 12:45:59 [INFO]: Epoch 087 - training loss: 0.7901, validation loss: 0.8630
2024-05-22 12:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch87_loss0.863038957118988.pypots
2024-05-22 12:45:59 [INFO]: Epoch 088 - training loss: 0.7609, validation loss: 0.8628
2024-05-22 12:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch88_loss0.8627971857786179.pypots
2024-05-22 12:45:59 [INFO]: Epoch 089 - training loss: 0.7723, validation loss: 0.8632
2024-05-22 12:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch89_loss0.8632407039403915.pypots
2024-05-22 12:45:59 [INFO]: Epoch 090 - training loss: 0.7519, validation loss: 0.8587
2024-05-22 12:45:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch90_loss0.8586840182542801.pypots
2024-05-22 12:46:00 [INFO]: Epoch 091 - training loss: 0.7770, validation loss: 0.8603
2024-05-22 12:46:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch91_loss0.8603016138076782.pypots
2024-05-22 12:46:00 [INFO]: Epoch 092 - training loss: 0.7684, validation loss: 0.8622
2024-05-22 12:46:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch92_loss0.8621767908334732.pypots
2024-05-22 12:46:00 [INFO]: Epoch 093 - training loss: 0.7694, validation loss: 0.8596
2024-05-22 12:46:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch93_loss0.8595801293849945.pypots
2024-05-22 12:46:00 [INFO]: Epoch 094 - training loss: 0.7686, validation loss: 0.8597
2024-05-22 12:46:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch94_loss0.8597253859043121.pypots
2024-05-22 12:46:00 [INFO]: Epoch 095 - training loss: 0.7807, validation loss: 0.8612
2024-05-22 12:46:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch95_loss0.8612366765737534.pypots
2024-05-22 12:46:01 [INFO]: Epoch 096 - training loss: 0.7548, validation loss: 0.8621
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch96_loss0.8620960414409637.pypots
2024-05-22 12:46:01 [INFO]: Epoch 097 - training loss: 0.7818, validation loss: 0.8610
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch97_loss0.8610409796237946.pypots
2024-05-22 12:46:01 [INFO]: Epoch 098 - training loss: 0.7646, validation loss: 0.8632
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch98_loss0.8631622195243835.pypots
2024-05-22 12:46:01 [INFO]: Epoch 099 - training loss: 0.7729, validation loss: 0.8579
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch99_loss0.8579181134700775.pypots
2024-05-22 12:46:01 [INFO]: Epoch 100 - training loss: 0.8163, validation loss: 0.8605
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch100_loss0.8605450391769409.pypots
2024-05-22 12:46:01 [INFO]: Epoch 101 - training loss: 0.7792, validation loss: 0.8591
2024-05-22 12:46:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch101_loss0.859083503484726.pypots
2024-05-22 12:46:02 [INFO]: Epoch 102 - training loss: 0.8262, validation loss: 0.8621
2024-05-22 12:46:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch102_loss0.8621436208486557.pypots
2024-05-22 12:46:02 [INFO]: Epoch 103 - training loss: 0.7587, validation loss: 0.8606
2024-05-22 12:46:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch103_loss0.8605528473854065.pypots
2024-05-22 12:46:02 [INFO]: Epoch 104 - training loss: 0.7890, validation loss: 0.8624
2024-05-22 12:46:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch104_loss0.8623704314231873.pypots
2024-05-22 12:46:02 [INFO]: Epoch 105 - training loss: 0.7567, validation loss: 0.8612
2024-05-22 12:46:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch105_loss0.8611927181482315.pypots
2024-05-22 12:46:02 [INFO]: Epoch 106 - training loss: 0.7861, validation loss: 0.8601
2024-05-22 12:46:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch106_loss0.8601129502058029.pypots
2024-05-22 12:46:03 [INFO]: Epoch 107 - training loss: 0.7765, validation loss: 0.8620
2024-05-22 12:46:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch107_loss0.8620477616786957.pypots
2024-05-22 12:46:03 [INFO]: Epoch 108 - training loss: 0.7554, validation loss: 0.8617
2024-05-22 12:46:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch108_loss0.8616844564676285.pypots
2024-05-22 12:46:03 [INFO]: Epoch 109 - training loss: 0.7444, validation loss: 0.8612
2024-05-22 12:46:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN_epoch109_loss0.8612372726202011.pypots
2024-05-22 12:46:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:46:03 [INFO]: Finished training. The best model is from epoch#99.
2024-05-22 12:46:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240522_T124541/MRNN.pypots
2024-05-22 12:46:03 [INFO]: MRNN on ETTm1: MAE=0.7266, MSE=1.3099
2024-05-22 12:46:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-22 12:46:03 [INFO]: Using the given device: cpu
2024-05-22 12:46:03 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 12:46:03 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-22 12:46:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-22 12:46:03 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 12:46:03 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-22 12:46:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-22 12:46:03 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 12:46:03 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-22 12:46:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-22 12:46:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 12:46:04 [INFO]: Using the given device: cuda:0
2024-05-22 12:46:04 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240522_T124604
2024-05-22 12:46:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240522_T124604/tensorboard
2024-05-22 12:46:04 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 12:46:04 [INFO]: Epoch 001 - training loss: 1.1795, validation loss: 0.2812
2024-05-22 12:46:05 [INFO]: Epoch 002 - training loss: 0.8433, validation loss: 0.1504
2024-05-22 12:46:05 [INFO]: Epoch 003 - training loss: 0.7312, validation loss: 0.1435
2024-05-22 12:46:06 [INFO]: Epoch 004 - training loss: 0.6680, validation loss: 0.0990
2024-05-22 12:46:06 [INFO]: Epoch 005 - training loss: 0.6441, validation loss: 0.0877
2024-05-22 12:46:07 [INFO]: Epoch 006 - training loss: 0.5931, validation loss: 0.0916
2024-05-22 12:46:07 [INFO]: Epoch 007 - training loss: 0.5787, validation loss: 0.0922
2024-05-22 12:46:08 [INFO]: Epoch 008 - training loss: 0.5571, validation loss: 0.0659
2024-05-22 12:46:08 [INFO]: Epoch 009 - training loss: 0.5600, validation loss: 0.0791
2024-05-22 12:46:09 [INFO]: Epoch 010 - training loss: 0.5521, validation loss: 0.0734
2024-05-22 12:46:09 [INFO]: Epoch 011 - training loss: 0.5284, validation loss: 0.0895
2024-05-22 12:46:10 [INFO]: Epoch 012 - training loss: 0.5168, validation loss: 0.0834
2024-05-22 12:46:10 [INFO]: Epoch 013 - training loss: 0.5091, validation loss: 0.0682
2024-05-22 12:46:11 [INFO]: Epoch 014 - training loss: 0.4860, validation loss: 0.0665
2024-05-22 12:46:11 [INFO]: Epoch 015 - training loss: 0.4934, validation loss: 0.0618
2024-05-22 12:46:12 [INFO]: Epoch 016 - training loss: 0.4817, validation loss: 0.0541
2024-05-22 12:46:12 [INFO]: Epoch 017 - training loss: 0.4781, validation loss: 0.0573
2024-05-22 12:46:13 [INFO]: Epoch 018 - training loss: 0.4702, validation loss: 0.0541
2024-05-22 12:46:13 [INFO]: Epoch 019 - training loss: 0.4474, validation loss: 0.0453
2024-05-22 12:46:14 [INFO]: Epoch 020 - training loss: 0.4459, validation loss: 0.0566
2024-05-22 12:46:14 [INFO]: Epoch 021 - training loss: 0.4559, validation loss: 0.0523
2024-05-22 12:46:15 [INFO]: Epoch 022 - training loss: 0.4438, validation loss: 0.0417
2024-05-22 12:46:15 [INFO]: Epoch 023 - training loss: 0.4332, validation loss: 0.0602
2024-05-22 12:46:16 [INFO]: Epoch 024 - training loss: 0.4234, validation loss: 0.0489
2024-05-22 12:46:16 [INFO]: Epoch 025 - training loss: 0.4187, validation loss: 0.0467
2024-05-22 12:46:17 [INFO]: Epoch 026 - training loss: 0.4309, validation loss: 0.0520
2024-05-22 12:46:17 [INFO]: Epoch 027 - training loss: 0.4190, validation loss: 0.0513
2024-05-22 12:46:18 [INFO]: Epoch 028 - training loss: 0.4198, validation loss: 0.0459
2024-05-22 12:46:18 [INFO]: Epoch 029 - training loss: 0.4062, validation loss: 0.0459
2024-05-22 12:46:19 [INFO]: Epoch 030 - training loss: 0.4152, validation loss: 0.0489
2024-05-22 12:46:19 [INFO]: Epoch 031 - training loss: 0.3903, validation loss: 0.0388
2024-05-22 12:46:20 [INFO]: Epoch 032 - training loss: 0.3948, validation loss: 0.0393
2024-05-22 12:46:21 [INFO]: Epoch 033 - training loss: 0.3834, validation loss: 0.0619
2024-05-22 12:46:21 [INFO]: Epoch 034 - training loss: 0.3803, validation loss: 0.0406
2024-05-22 12:46:22 [INFO]: Epoch 035 - training loss: 0.3752, validation loss: 0.0467
2024-05-22 12:46:22 [INFO]: Epoch 036 - training loss: 0.3683, validation loss: 0.0381
2024-05-22 12:46:23 [INFO]: Epoch 037 - training loss: 0.3780, validation loss: 0.0378
2024-05-22 12:46:23 [INFO]: Epoch 038 - training loss: 0.4001, validation loss: 0.0405
2024-05-22 12:46:24 [INFO]: Epoch 039 - training loss: 0.4049, validation loss: 0.0425
2024-05-22 12:46:24 [INFO]: Epoch 040 - training loss: 0.3735, validation loss: 0.0458
2024-05-22 12:46:25 [INFO]: Epoch 041 - training loss: 0.3689, validation loss: 0.0437
2024-05-22 12:46:25 [INFO]: Epoch 042 - training loss: 0.3638, validation loss: 0.0382
2024-05-22 12:46:26 [INFO]: Epoch 043 - training loss: 0.3471, validation loss: 0.0392
2024-05-22 12:46:26 [INFO]: Epoch 044 - training loss: 0.3501, validation loss: 0.0523
2024-05-22 12:46:27 [INFO]: Epoch 045 - training loss: 0.3553, validation loss: 0.0429
2024-05-22 12:46:27 [INFO]: Epoch 046 - training loss: 0.3402, validation loss: 0.0452
2024-05-22 12:46:28 [INFO]: Epoch 047 - training loss: 0.3617, validation loss: 0.0476
2024-05-22 12:46:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:46:28 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 12:46:28 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_ettm1/20240522_T124604/SAITS.pypots
2024-05-22 12:46:28 [INFO]: SAITS on ETTm1: MAE=0.1582, MSE=0.0545
2024-05-22 12:46:28 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-22 12:46:28 [INFO]: Using the given device: cuda:0
2024-05-22 12:46:28 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240522_T124628
2024-05-22 12:46:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240522_T124628/tensorboard
2024-05-22 12:46:28 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 12:46:28 [INFO]: Epoch 001 - training loss: 1.2697, validation loss: 0.3220
2024-05-22 12:46:28 [INFO]: Epoch 002 - training loss: 0.7625, validation loss: 0.1644
2024-05-22 12:46:28 [INFO]: Epoch 003 - training loss: 0.6144, validation loss: 0.1264
2024-05-22 12:46:29 [INFO]: Epoch 004 - training loss: 0.5433, validation loss: 0.0917
2024-05-22 12:46:29 [INFO]: Epoch 005 - training loss: 0.4973, validation loss: 0.0746
2024-05-22 12:46:29 [INFO]: Epoch 006 - training loss: 0.4703, validation loss: 0.0689
2024-05-22 12:46:29 [INFO]: Epoch 007 - training loss: 0.4479, validation loss: 0.0661
2024-05-22 12:46:30 [INFO]: Epoch 008 - training loss: 0.4232, validation loss: 0.0634
2024-05-22 12:46:30 [INFO]: Epoch 009 - training loss: 0.4187, validation loss: 0.0577
2024-05-22 12:46:30 [INFO]: Epoch 010 - training loss: 0.3961, validation loss: 0.0544
2024-05-22 12:46:30 [INFO]: Epoch 011 - training loss: 0.3913, validation loss: 0.0554
2024-05-22 12:46:30 [INFO]: Epoch 012 - training loss: 0.3821, validation loss: 0.0540
2024-05-22 12:46:31 [INFO]: Epoch 013 - training loss: 0.3698, validation loss: 0.0495
2024-05-22 12:46:31 [INFO]: Epoch 014 - training loss: 0.3578, validation loss: 0.0465
2024-05-22 12:46:31 [INFO]: Epoch 015 - training loss: 0.3558, validation loss: 0.0495
2024-05-22 12:46:31 [INFO]: Epoch 016 - training loss: 0.3530, validation loss: 0.0472
2024-05-22 12:46:32 [INFO]: Epoch 017 - training loss: 0.3459, validation loss: 0.0507
2024-05-22 12:46:32 [INFO]: Epoch 018 - training loss: 0.3403, validation loss: 0.0505
2024-05-22 12:46:32 [INFO]: Epoch 019 - training loss: 0.3400, validation loss: 0.0493
2024-05-22 12:46:32 [INFO]: Epoch 020 - training loss: 0.3410, validation loss: 0.0411
2024-05-22 12:46:32 [INFO]: Epoch 021 - training loss: 0.3250, validation loss: 0.0451
2024-05-22 12:46:33 [INFO]: Epoch 022 - training loss: 0.3186, validation loss: 0.0416
2024-05-22 12:46:33 [INFO]: Epoch 023 - training loss: 0.3174, validation loss: 0.0380
2024-05-22 12:46:33 [INFO]: Epoch 024 - training loss: 0.3106, validation loss: 0.0466
2024-05-22 12:46:33 [INFO]: Epoch 025 - training loss: 0.3149, validation loss: 0.0360
2024-05-22 12:46:33 [INFO]: Epoch 026 - training loss: 0.3031, validation loss: 0.0364
2024-05-22 12:46:34 [INFO]: Epoch 027 - training loss: 0.3006, validation loss: 0.0390
2024-05-22 12:46:34 [INFO]: Epoch 028 - training loss: 0.2914, validation loss: 0.0402
2024-05-22 12:46:34 [INFO]: Epoch 029 - training loss: 0.2893, validation loss: 0.0395
2024-05-22 12:46:34 [INFO]: Epoch 030 - training loss: 0.2938, validation loss: 0.0409
2024-05-22 12:46:35 [INFO]: Epoch 031 - training loss: 0.2868, validation loss: 0.0399
2024-05-22 12:46:35 [INFO]: Epoch 032 - training loss: 0.2819, validation loss: 0.0364
2024-05-22 12:46:35 [INFO]: Epoch 033 - training loss: 0.2801, validation loss: 0.0341
2024-05-22 12:46:35 [INFO]: Epoch 034 - training loss: 0.2807, validation loss: 0.0360
2024-05-22 12:46:35 [INFO]: Epoch 035 - training loss: 0.2741, validation loss: 0.0349
2024-05-22 12:46:36 [INFO]: Epoch 036 - training loss: 0.2814, validation loss: 0.0395
2024-05-22 12:46:36 [INFO]: Epoch 037 - training loss: 0.2748, validation loss: 0.0294
2024-05-22 12:46:36 [INFO]: Epoch 038 - training loss: 0.2618, validation loss: 0.0320
2024-05-22 12:46:36 [INFO]: Epoch 039 - training loss: 0.2620, validation loss: 0.0328
2024-05-22 12:46:37 [INFO]: Epoch 040 - training loss: 0.2690, validation loss: 0.0385
2024-05-22 12:46:37 [INFO]: Epoch 041 - training loss: 0.2629, validation loss: 0.0324
2024-05-22 12:46:37 [INFO]: Epoch 042 - training loss: 0.2603, validation loss: 0.0314
2024-05-22 12:46:37 [INFO]: Epoch 043 - training loss: 0.2551, validation loss: 0.0318
2024-05-22 12:46:37 [INFO]: Epoch 044 - training loss: 0.2552, validation loss: 0.0311
2024-05-22 12:46:38 [INFO]: Epoch 045 - training loss: 0.2467, validation loss: 0.0318
2024-05-22 12:46:38 [INFO]: Epoch 046 - training loss: 0.2492, validation loss: 0.0314
2024-05-22 12:46:38 [INFO]: Epoch 047 - training loss: 0.2484, validation loss: 0.0310
2024-05-22 12:46:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:46:38 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 12:46:38 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_ettm1/20240522_T124628/Transformer.pypots
2024-05-22 12:46:38 [INFO]: Transformer on ETTm1: MAE=0.1579, MSE=0.0461
2024-05-22 12:46:38 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-22 12:46:38 [INFO]: Using the given device: cuda:0
2024-05-22 12:46:38 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240522_T124638
2024-05-22 12:46:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240522_T124638/tensorboard
2024-05-22 12:46:38 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 12:46:39 [INFO]: Epoch 001 - training loss: 0.1514, validation loss: 0.0535
2024-05-22 12:46:39 [INFO]: Epoch 002 - training loss: 0.0708, validation loss: 0.0395
2024-05-22 12:46:39 [INFO]: Epoch 003 - training loss: 0.0576, validation loss: 0.0382
2024-05-22 12:46:39 [INFO]: Epoch 004 - training loss: 0.0554, validation loss: 0.0373
2024-05-22 12:46:39 [INFO]: Epoch 005 - training loss: 0.0532, validation loss: 0.0355
2024-05-22 12:46:40 [INFO]: Epoch 006 - training loss: 0.0479, validation loss: 0.0336
2024-05-22 12:46:40 [INFO]: Epoch 007 - training loss: 0.0477, validation loss: 0.0316
2024-05-22 12:46:40 [INFO]: Epoch 008 - training loss: 0.0438, validation loss: 0.0322
2024-05-22 12:46:40 [INFO]: Epoch 009 - training loss: 0.0427, validation loss: 0.0328
2024-05-22 12:46:40 [INFO]: Epoch 010 - training loss: 0.0451, validation loss: 0.0321
2024-05-22 12:46:41 [INFO]: Epoch 011 - training loss: 0.0456, validation loss: 0.0344
2024-05-22 12:46:41 [INFO]: Epoch 012 - training loss: 0.0449, validation loss: 0.0324
2024-05-22 12:46:41 [INFO]: Epoch 013 - training loss: 0.0451, validation loss: 0.0325
2024-05-22 12:46:41 [INFO]: Epoch 014 - training loss: 0.0474, validation loss: 0.0312
2024-05-22 12:46:42 [INFO]: Epoch 015 - training loss: 0.0519, validation loss: 0.0382
2024-05-22 12:46:42 [INFO]: Epoch 016 - training loss: 0.0498, validation loss: 0.0356
2024-05-22 12:46:42 [INFO]: Epoch 017 - training loss: 0.0436, validation loss: 0.0294
2024-05-22 12:46:42 [INFO]: Epoch 018 - training loss: 0.0431, validation loss: 0.0282
2024-05-22 12:46:42 [INFO]: Epoch 019 - training loss: 0.0457, validation loss: 0.0302
2024-05-22 12:46:43 [INFO]: Epoch 020 - training loss: 0.0447, validation loss: 0.0302
2024-05-22 12:46:43 [INFO]: Epoch 021 - training loss: 0.0465, validation loss: 0.0337
2024-05-22 12:46:43 [INFO]: Epoch 022 - training loss: 0.0447, validation loss: 0.0324
2024-05-22 12:46:43 [INFO]: Epoch 023 - training loss: 0.0449, validation loss: 0.0307
2024-05-22 12:46:43 [INFO]: Epoch 024 - training loss: 0.0406, validation loss: 0.0304
2024-05-22 12:46:44 [INFO]: Epoch 025 - training loss: 0.0397, validation loss: 0.0297
2024-05-22 12:46:44 [INFO]: Epoch 026 - training loss: 0.0388, validation loss: 0.0283
2024-05-22 12:46:44 [INFO]: Epoch 027 - training loss: 0.0404, validation loss: 0.0310
2024-05-22 12:46:44 [INFO]: Epoch 028 - training loss: 0.0429, validation loss: 0.0342
2024-05-22 12:46:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:46:44 [INFO]: Finished training. The best model is from epoch#18.
2024-05-22 12:46:44 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_ettm1/20240522_T124638/TimesNet.pypots
2024-05-22 12:46:44 [INFO]: TimesNet on ETTm1: MAE=0.1271, MSE=0.0348
2024-05-22 12:46:44 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-22 12:46:44 [INFO]: Using the given device: cuda:0
2024-05-22 12:46:44 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644
2024-05-22 12:46:44 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/tensorboard
2024-05-22 12:46:44 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 12:46:46 [INFO]: Epoch 001 - training loss: 0.7409, validation loss: 0.4700
2024-05-22 12:46:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch1_loss0.4700450152158737.pypots
2024-05-22 12:46:49 [INFO]: Epoch 002 - training loss: 0.4159, validation loss: 0.3671
2024-05-22 12:46:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch2_loss0.3670603111386299.pypots
2024-05-22 12:46:51 [INFO]: Epoch 003 - training loss: 0.3519, validation loss: 0.3618
2024-05-22 12:46:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch3_loss0.36181648820638657.pypots
2024-05-22 12:46:53 [INFO]: Epoch 004 - training loss: 0.3799, validation loss: 0.3381
2024-05-22 12:46:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch4_loss0.3380845785140991.pypots
2024-05-22 12:46:55 [INFO]: Epoch 005 - training loss: 0.3158, validation loss: 0.3467
2024-05-22 12:46:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch5_loss0.3466716706752777.pypots
2024-05-22 12:46:57 [INFO]: Epoch 006 - training loss: 0.3092, validation loss: 0.3814
2024-05-22 12:46:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch6_loss0.3814375475049019.pypots
2024-05-22 12:46:59 [INFO]: Epoch 007 - training loss: 0.3134, validation loss: 0.3165
2024-05-22 12:46:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch7_loss0.31652621179819107.pypots
2024-05-22 12:47:01 [INFO]: Epoch 008 - training loss: 0.3099, validation loss: 0.2940
2024-05-22 12:47:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch8_loss0.29403049498796463.pypots
2024-05-22 12:47:03 [INFO]: Epoch 009 - training loss: 0.3040, validation loss: 0.2878
2024-05-22 12:47:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch9_loss0.2877787724137306.pypots
2024-05-22 12:47:05 [INFO]: Epoch 010 - training loss: 0.2310, validation loss: 0.2920
2024-05-22 12:47:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch10_loss0.2920089215040207.pypots
2024-05-22 12:47:07 [INFO]: Epoch 011 - training loss: 0.2747, validation loss: 0.2634
2024-05-22 12:47:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch11_loss0.2633623108267784.pypots
2024-05-22 12:47:09 [INFO]: Epoch 012 - training loss: 0.2451, validation loss: 0.2617
2024-05-22 12:47:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch12_loss0.261726513504982.pypots
2024-05-22 12:47:11 [INFO]: Epoch 013 - training loss: 0.2764, validation loss: 0.2564
2024-05-22 12:47:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch13_loss0.2564239576458931.pypots
2024-05-22 12:47:14 [INFO]: Epoch 014 - training loss: 0.2318, validation loss: 0.2511
2024-05-22 12:47:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch14_loss0.25113285705447197.pypots
2024-05-22 12:47:16 [INFO]: Epoch 015 - training loss: 0.2205, validation loss: 0.2368
2024-05-22 12:47:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch15_loss0.23675120994448662.pypots
2024-05-22 12:47:18 [INFO]: Epoch 016 - training loss: 0.2298, validation loss: 0.2312
2024-05-22 12:47:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch16_loss0.2312168851494789.pypots
2024-05-22 12:47:20 [INFO]: Epoch 017 - training loss: 0.2322, validation loss: 0.2259
2024-05-22 12:47:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch17_loss0.22593384236097336.pypots
2024-05-22 12:47:22 [INFO]: Epoch 018 - training loss: 0.2073, validation loss: 0.2408
2024-05-22 12:47:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch18_loss0.24082083627581596.pypots
2024-05-22 12:47:24 [INFO]: Epoch 019 - training loss: 0.2477, validation loss: 0.2269
2024-05-22 12:47:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch19_loss0.2269444763660431.pypots
2024-05-22 12:47:26 [INFO]: Epoch 020 - training loss: 0.2256, validation loss: 0.2327
2024-05-22 12:47:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch20_loss0.23273609578609467.pypots
2024-05-22 12:47:28 [INFO]: Epoch 021 - training loss: 0.1921, validation loss: 0.2107
2024-05-22 12:47:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch21_loss0.2106604278087616.pypots
2024-05-22 12:47:30 [INFO]: Epoch 022 - training loss: 0.2484, validation loss: 0.1997
2024-05-22 12:47:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch22_loss0.199656181037426.pypots
2024-05-22 12:47:32 [INFO]: Epoch 023 - training loss: 0.2147, validation loss: 0.2020
2024-05-22 12:47:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch23_loss0.2020002156496048.pypots
2024-05-22 12:47:34 [INFO]: Epoch 024 - training loss: 0.2143, validation loss: 0.1974
2024-05-22 12:47:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch24_loss0.19741028919816017.pypots
2024-05-22 12:47:36 [INFO]: Epoch 025 - training loss: 0.2168, validation loss: 0.1889
2024-05-22 12:47:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch25_loss0.1889030747115612.pypots
2024-05-22 12:47:39 [INFO]: Epoch 026 - training loss: 0.2124, validation loss: 0.1848
2024-05-22 12:47:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch26_loss0.1848250851035118.pypots
2024-05-22 12:47:41 [INFO]: Epoch 027 - training loss: 0.1913, validation loss: 0.1886
2024-05-22 12:47:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch27_loss0.18859648704528809.pypots
2024-05-22 12:47:43 [INFO]: Epoch 028 - training loss: 0.2043, validation loss: 0.1803
2024-05-22 12:47:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch28_loss0.1803336851298809.pypots
2024-05-22 12:47:45 [INFO]: Epoch 029 - training loss: 0.2188, validation loss: 0.1951
2024-05-22 12:47:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch29_loss0.1950760781764984.pypots
2024-05-22 12:47:47 [INFO]: Epoch 030 - training loss: 0.2141, validation loss: 0.1919
2024-05-22 12:47:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch30_loss0.19193926826119423.pypots
2024-05-22 12:47:49 [INFO]: Epoch 031 - training loss: 0.2029, validation loss: 0.1872
2024-05-22 12:47:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch31_loss0.1872083842754364.pypots
2024-05-22 12:47:51 [INFO]: Epoch 032 - training loss: 0.2288, validation loss: 0.1865
2024-05-22 12:47:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch32_loss0.18649590015411377.pypots
2024-05-22 12:47:53 [INFO]: Epoch 033 - training loss: 0.1832, validation loss: 0.1836
2024-05-22 12:47:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch33_loss0.18359322100877762.pypots
2024-05-22 12:47:55 [INFO]: Epoch 034 - training loss: 0.1887, validation loss: 0.1802
2024-05-22 12:47:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch34_loss0.18018260970711708.pypots
2024-05-22 12:47:57 [INFO]: Epoch 035 - training loss: 0.2260, validation loss: 0.1766
2024-05-22 12:47:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch35_loss0.1766287125647068.pypots
2024-05-22 12:47:59 [INFO]: Epoch 036 - training loss: 0.1900, validation loss: 0.1723
2024-05-22 12:47:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch36_loss0.17232632264494896.pypots
2024-05-22 12:48:01 [INFO]: Epoch 037 - training loss: 0.1758, validation loss: 0.1687
2024-05-22 12:48:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch37_loss0.16865207999944687.pypots
2024-05-22 12:48:04 [INFO]: Epoch 038 - training loss: 0.1737, validation loss: 0.1653
2024-05-22 12:48:04 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch38_loss0.16527532041072845.pypots
2024-05-22 12:48:06 [INFO]: Epoch 039 - training loss: 0.1765, validation loss: 0.1624
2024-05-22 12:48:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch39_loss0.16236983612179756.pypots
2024-05-22 12:48:08 [INFO]: Epoch 040 - training loss: 0.1740, validation loss: 0.1584
2024-05-22 12:48:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch40_loss0.15844663232564926.pypots
2024-05-22 12:48:10 [INFO]: Epoch 041 - training loss: 0.1726, validation loss: 0.1545
2024-05-22 12:48:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch41_loss0.1544535905122757.pypots
2024-05-22 12:48:12 [INFO]: Epoch 042 - training loss: 0.1444, validation loss: 0.1496
2024-05-22 12:48:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch42_loss0.14963863790035248.pypots
2024-05-22 12:48:14 [INFO]: Epoch 043 - training loss: 0.1654, validation loss: 0.1560
2024-05-22 12:48:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch43_loss0.1560111902654171.pypots
2024-05-22 12:48:16 [INFO]: Epoch 044 - training loss: 0.1614, validation loss: 0.1507
2024-05-22 12:48:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch44_loss0.15069985762238503.pypots
2024-05-22 12:48:18 [INFO]: Epoch 045 - training loss: 0.2109, validation loss: 0.1639
2024-05-22 12:48:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch45_loss0.16393772512674332.pypots
2024-05-22 12:48:20 [INFO]: Epoch 046 - training loss: 0.2046, validation loss: 0.1731
2024-05-22 12:48:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch46_loss0.17310534790158272.pypots
2024-05-22 12:48:22 [INFO]: Epoch 047 - training loss: 0.2029, validation loss: 0.1685
2024-05-22 12:48:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch47_loss0.16851869598031044.pypots
2024-05-22 12:48:24 [INFO]: Epoch 048 - training loss: 0.1898, validation loss: 0.1636
2024-05-22 12:48:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch48_loss0.16359737887978554.pypots
2024-05-22 12:48:27 [INFO]: Epoch 049 - training loss: 0.1870, validation loss: 0.1583
2024-05-22 12:48:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch49_loss0.15828689187765121.pypots
2024-05-22 12:48:29 [INFO]: Epoch 050 - training loss: 0.1786, validation loss: 0.1553
2024-05-22 12:48:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch50_loss0.15533770993351936.pypots
2024-05-22 12:48:31 [INFO]: Epoch 051 - training loss: 0.1731, validation loss: 0.1569
2024-05-22 12:48:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch51_loss0.1568591147661209.pypots
2024-05-22 12:48:33 [INFO]: Epoch 052 - training loss: 0.1491, validation loss: 0.1494
2024-05-22 12:48:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch52_loss0.1494089849293232.pypots
2024-05-22 12:48:35 [INFO]: Epoch 053 - training loss: 0.1603, validation loss: 0.1475
2024-05-22 12:48:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch53_loss0.1474849320948124.pypots
2024-05-22 12:48:37 [INFO]: Epoch 054 - training loss: 0.1835, validation loss: 0.1603
2024-05-22 12:48:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch54_loss0.1603233702480793.pypots
2024-05-22 12:48:39 [INFO]: Epoch 055 - training loss: 0.2215, validation loss: 0.1618
2024-05-22 12:48:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch55_loss0.16176870465278625.pypots
2024-05-22 12:48:41 [INFO]: Epoch 056 - training loss: 0.1617, validation loss: 0.1619
2024-05-22 12:48:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch56_loss0.1618589051067829.pypots
2024-05-22 12:48:43 [INFO]: Epoch 057 - training loss: 0.1892, validation loss: 0.1459
2024-05-22 12:48:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch57_loss0.14589336514472961.pypots
2024-05-22 12:48:45 [INFO]: Epoch 058 - training loss: 0.1784, validation loss: 0.1488
2024-05-22 12:48:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch58_loss0.148776575922966.pypots
2024-05-22 12:48:47 [INFO]: Epoch 059 - training loss: 0.1541, validation loss: 0.1437
2024-05-22 12:48:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch59_loss0.1437160111963749.pypots
2024-05-22 12:48:49 [INFO]: Epoch 060 - training loss: 0.1707, validation loss: 0.1371
2024-05-22 12:48:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch60_loss0.13712791725993156.pypots
2024-05-22 12:48:52 [INFO]: Epoch 061 - training loss: 0.1733, validation loss: 0.1357
2024-05-22 12:48:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch61_loss0.13570520654320717.pypots
2024-05-22 12:48:54 [INFO]: Epoch 062 - training loss: 0.1552, validation loss: 0.1348
2024-05-22 12:48:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch62_loss0.1347903497517109.pypots
2024-05-22 12:48:56 [INFO]: Epoch 063 - training loss: 0.1585, validation loss: 0.1422
2024-05-22 12:48:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch63_loss0.1421724185347557.pypots
2024-05-22 12:48:58 [INFO]: Epoch 064 - training loss: 0.1551, validation loss: 0.1378
2024-05-22 12:48:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch64_loss0.13782550022006035.pypots
2024-05-22 12:49:00 [INFO]: Epoch 065 - training loss: 0.1553, validation loss: 0.1355
2024-05-22 12:49:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch65_loss0.13551899045705795.pypots
2024-05-22 12:49:02 [INFO]: Epoch 066 - training loss: 0.2321, validation loss: 0.1360
2024-05-22 12:49:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch66_loss0.1359814815223217.pypots
2024-05-22 12:49:04 [INFO]: Epoch 067 - training loss: 0.1539, validation loss: 0.1400
2024-05-22 12:49:04 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch67_loss0.13996760174632072.pypots
2024-05-22 12:49:06 [INFO]: Epoch 068 - training loss: 0.2017, validation loss: 0.1437
2024-05-22 12:49:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch68_loss0.14372924342751503.pypots
2024-05-22 12:49:08 [INFO]: Epoch 069 - training loss: 0.1584, validation loss: 0.1432
2024-05-22 12:49:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch69_loss0.14322008192539215.pypots
2024-05-22 12:49:10 [INFO]: Epoch 070 - training loss: 0.1954, validation loss: 0.1669
2024-05-22 12:49:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch70_loss0.16694633290171623.pypots
2024-05-22 12:49:12 [INFO]: Epoch 071 - training loss: 0.1714, validation loss: 0.1568
2024-05-22 12:49:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch71_loss0.1567993126809597.pypots
2024-05-22 12:49:14 [INFO]: Epoch 072 - training loss: 0.1699, validation loss: 0.1469
2024-05-22 12:49:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI_epoch72_loss0.1469459980726242.pypots
2024-05-22 12:49:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:49:14 [INFO]: Finished training. The best model is from epoch#62.
2024-05-22 12:49:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240522_T124644/CSDI.pypots
2024-05-22 12:49:30 [INFO]: CSDI on ETTm1: MAE=0.1779, MSE=0.2337
2024-05-22 12:49:30 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-22 12:49:30 [INFO]: Using the given device: cuda:0
2024-05-22 12:49:30 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240522_T124930
2024-05-22 12:49:30 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240522_T124930/tensorboard
2024-05-22 12:49:30 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 12:49:31 [INFO]: Epoch 001 - training loss: 23637.9535, validation loss: 0.9655
2024-05-22 12:49:31 [INFO]: Epoch 002 - training loss: 21482.9384, validation loss: 0.9622
2024-05-22 12:49:31 [INFO]: Epoch 003 - training loss: 19481.1185, validation loss: 0.9556
2024-05-22 12:49:31 [INFO]: Epoch 004 - training loss: 17307.2278, validation loss: 0.9349
2024-05-22 12:49:31 [INFO]: Epoch 005 - training loss: 15446.9643, validation loss: 0.8849
2024-05-22 12:49:31 [INFO]: Epoch 006 - training loss: 14004.3486, validation loss: 0.7926
2024-05-22 12:49:31 [INFO]: Epoch 007 - training loss: 12700.9304, validation loss: 0.6966
2024-05-22 12:49:31 [INFO]: Epoch 008 - training loss: 11880.9288, validation loss: 0.6471
2024-05-22 12:49:32 [INFO]: Epoch 009 - training loss: 11362.4582, validation loss: 0.5933
2024-05-22 12:49:32 [INFO]: Epoch 010 - training loss: 10902.0515, validation loss: 0.5259
2024-05-22 12:49:32 [INFO]: Epoch 011 - training loss: 10591.2215, validation loss: 0.4626
2024-05-22 12:49:32 [INFO]: Epoch 012 - training loss: 10389.0494, validation loss: 0.4378
2024-05-22 12:49:32 [INFO]: Epoch 013 - training loss: 10314.5681, validation loss: 0.4206
2024-05-22 12:49:32 [INFO]: Epoch 014 - training loss: 10079.5169, validation loss: 0.4054
2024-05-22 12:49:32 [INFO]: Epoch 015 - training loss: 10047.9628, validation loss: 0.3869
2024-05-22 12:49:33 [INFO]: Epoch 016 - training loss: 9883.6107, validation loss: 0.3688
2024-05-22 12:49:33 [INFO]: Epoch 017 - training loss: 9821.9307, validation loss: 0.3560
2024-05-22 12:49:33 [INFO]: Epoch 018 - training loss: 9852.1808, validation loss: 0.3358
2024-05-22 12:49:33 [INFO]: Epoch 019 - training loss: 9715.7189, validation loss: 0.3257
2024-05-22 12:49:33 [INFO]: Epoch 020 - training loss: 9760.7881, validation loss: 0.3109
2024-05-22 12:49:33 [INFO]: Epoch 021 - training loss: 9637.6038, validation loss: 0.3074
2024-05-22 12:49:33 [INFO]: Epoch 022 - training loss: 9603.8889, validation loss: 0.2952
2024-05-22 12:49:33 [INFO]: Epoch 023 - training loss: 9584.2274, validation loss: 0.2892
2024-05-22 12:49:34 [INFO]: Epoch 024 - training loss: 9564.6282, validation loss: 0.2881
2024-05-22 12:49:34 [INFO]: Epoch 025 - training loss: 9546.3188, validation loss: 0.2829
2024-05-22 12:49:34 [INFO]: Epoch 026 - training loss: 9523.9099, validation loss: 0.2735
2024-05-22 12:49:34 [INFO]: Epoch 027 - training loss: 9571.4916, validation loss: 0.2645
2024-05-22 12:49:34 [INFO]: Epoch 028 - training loss: 9540.4254, validation loss: 0.2590
2024-05-22 12:49:34 [INFO]: Epoch 029 - training loss: 9466.0574, validation loss: 0.2508
2024-05-22 12:49:34 [INFO]: Epoch 030 - training loss: 9454.5526, validation loss: 0.2476
2024-05-22 12:49:35 [INFO]: Epoch 031 - training loss: 9446.2739, validation loss: 0.2418
2024-05-22 12:49:35 [INFO]: Epoch 032 - training loss: 9455.9615, validation loss: 0.2333
2024-05-22 12:49:35 [INFO]: Epoch 033 - training loss: 9444.4566, validation loss: 0.2294
2024-05-22 12:49:35 [INFO]: Epoch 034 - training loss: 9421.9858, validation loss: 0.2332
2024-05-22 12:49:35 [INFO]: Epoch 035 - training loss: 9418.0364, validation loss: 0.2245
2024-05-22 12:49:35 [INFO]: Epoch 036 - training loss: 9409.7069, validation loss: 0.2158
2024-05-22 12:49:35 [INFO]: Epoch 037 - training loss: 9396.7934, validation loss: 0.2124
2024-05-22 12:49:36 [INFO]: Epoch 038 - training loss: 9401.9625, validation loss: 0.2062
2024-05-22 12:49:36 [INFO]: Epoch 039 - training loss: 9388.6078, validation loss: 0.1990
2024-05-22 12:49:36 [INFO]: Epoch 040 - training loss: 9381.2472, validation loss: 0.1958
2024-05-22 12:49:36 [INFO]: Epoch 041 - training loss: 9377.7720, validation loss: 0.1913
2024-05-22 12:49:36 [INFO]: Epoch 042 - training loss: 9376.8524, validation loss: 0.1862
2024-05-22 12:49:36 [INFO]: Epoch 043 - training loss: 9371.7054, validation loss: 0.1794
2024-05-22 12:49:36 [INFO]: Epoch 044 - training loss: 9374.7510, validation loss: 0.1777
2024-05-22 12:49:36 [INFO]: Epoch 045 - training loss: 9361.3932, validation loss: 0.1752
2024-05-22 12:49:37 [INFO]: Epoch 046 - training loss: 9360.8776, validation loss: 0.1722
2024-05-22 12:49:37 [INFO]: Epoch 047 - training loss: 9353.5086, validation loss: 0.1648
2024-05-22 12:49:37 [INFO]: Epoch 048 - training loss: 9354.4859, validation loss: 0.1624
2024-05-22 12:49:37 [INFO]: Epoch 049 - training loss: 9347.9064, validation loss: 0.1591
2024-05-22 12:49:37 [INFO]: Epoch 050 - training loss: 9350.5442, validation loss: 0.1561
2024-05-22 12:49:37 [INFO]: Epoch 051 - training loss: 9343.3810, validation loss: 0.1547
2024-05-22 12:49:37 [INFO]: Epoch 052 - training loss: 9342.5572, validation loss: 0.1517
2024-05-22 12:49:38 [INFO]: Epoch 053 - training loss: 9335.7177, validation loss: 0.1478
2024-05-22 12:49:38 [INFO]: Epoch 054 - training loss: 9340.5942, validation loss: 0.1472
2024-05-22 12:49:38 [INFO]: Epoch 055 - training loss: 9339.9383, validation loss: 0.1428
2024-05-22 12:49:38 [INFO]: Epoch 056 - training loss: 9331.7233, validation loss: 0.1431
2024-05-22 12:49:38 [INFO]: Epoch 057 - training loss: 9330.2545, validation loss: 0.1402
2024-05-22 12:49:38 [INFO]: Epoch 058 - training loss: 9327.3649, validation loss: 0.1372
2024-05-22 12:49:38 [INFO]: Epoch 059 - training loss: 9329.8965, validation loss: 0.1366
2024-05-22 12:49:38 [INFO]: Epoch 060 - training loss: 9323.3028, validation loss: 0.1355
2024-05-22 12:49:39 [INFO]: Epoch 061 - training loss: 9328.3553, validation loss: 0.1349
2024-05-22 12:49:39 [INFO]: Epoch 062 - training loss: 9322.7370, validation loss: 0.1315
2024-05-22 12:49:39 [INFO]: Epoch 063 - training loss: 9320.8906, validation loss: 0.1297
2024-05-22 12:49:39 [INFO]: Epoch 064 - training loss: 9319.5088, validation loss: 0.1296
2024-05-22 12:49:39 [INFO]: Epoch 065 - training loss: 9318.0597, validation loss: 0.1286
2024-05-22 12:49:39 [INFO]: Epoch 066 - training loss: 9317.9945, validation loss: 0.1267
2024-05-22 12:49:39 [INFO]: Epoch 067 - training loss: 9317.8359, validation loss: 0.1269
2024-05-22 12:49:40 [INFO]: Epoch 068 - training loss: 9315.9320, validation loss: 0.1237
2024-05-22 12:49:40 [INFO]: Epoch 069 - training loss: 9315.8099, validation loss: 0.1250
2024-05-22 12:49:40 [INFO]: Epoch 070 - training loss: 9312.8364, validation loss: 0.1248
2024-05-22 12:49:40 [INFO]: Epoch 071 - training loss: 9312.6339, validation loss: 0.1233
2024-05-22 12:49:40 [INFO]: Epoch 072 - training loss: 9308.5432, validation loss: 0.1228
2024-05-22 12:49:40 [INFO]: Epoch 073 - training loss: 9310.1792, validation loss: 0.1218
2024-05-22 12:49:40 [INFO]: Epoch 074 - training loss: 9310.2971, validation loss: 0.1209
2024-05-22 12:49:40 [INFO]: Epoch 075 - training loss: 9306.0457, validation loss: 0.1217
2024-05-22 12:49:41 [INFO]: Epoch 076 - training loss: 9307.4751, validation loss: 0.1196
2024-05-22 12:49:41 [INFO]: Epoch 077 - training loss: 9305.3199, validation loss: 0.1190
2024-05-22 12:49:41 [INFO]: Epoch 078 - training loss: 9306.1812, validation loss: 0.1188
2024-05-22 12:49:41 [INFO]: Epoch 079 - training loss: 9305.8795, validation loss: 0.1183
2024-05-22 12:49:41 [INFO]: Epoch 080 - training loss: 9300.7115, validation loss: 0.1170
2024-05-22 12:49:41 [INFO]: Epoch 081 - training loss: 9301.8925, validation loss: 0.1160
2024-05-22 12:49:41 [INFO]: Epoch 082 - training loss: 9301.9015, validation loss: 0.1158
2024-05-22 12:49:42 [INFO]: Epoch 083 - training loss: 9303.0063, validation loss: 0.1151
2024-05-22 12:49:42 [INFO]: Epoch 084 - training loss: 9302.9759, validation loss: 0.1137
2024-05-22 12:49:42 [INFO]: Epoch 085 - training loss: 9299.8812, validation loss: 0.1131
2024-05-22 12:49:42 [INFO]: Epoch 086 - training loss: 9299.1662, validation loss: 0.1132
2024-05-22 12:49:42 [INFO]: Epoch 087 - training loss: 9299.1642, validation loss: 0.1113
2024-05-22 12:49:42 [INFO]: Epoch 088 - training loss: 9298.1011, validation loss: 0.1132
2024-05-22 12:49:42 [INFO]: Epoch 089 - training loss: 9297.2975, validation loss: 0.1106
2024-05-22 12:49:42 [INFO]: Epoch 090 - training loss: 9297.1334, validation loss: 0.1114
2024-05-22 12:49:43 [INFO]: Epoch 091 - training loss: 9296.3438, validation loss: 0.1109
2024-05-22 12:49:43 [INFO]: Epoch 092 - training loss: 9295.5994, validation loss: 0.1107
2024-05-22 12:49:43 [INFO]: Epoch 093 - training loss: 9296.9710, validation loss: 0.1094
2024-05-22 12:49:43 [INFO]: Epoch 094 - training loss: 9294.7249, validation loss: 0.1096
2024-05-22 12:49:43 [INFO]: Epoch 095 - training loss: 9295.5727, validation loss: 0.1084
2024-05-22 12:49:43 [INFO]: Epoch 096 - training loss: 9295.4183, validation loss: 0.1070
2024-05-22 12:49:43 [INFO]: Epoch 097 - training loss: 9293.8890, validation loss: 0.1093
2024-05-22 12:49:44 [INFO]: Epoch 098 - training loss: 9294.8927, validation loss: 0.1070
2024-05-22 12:49:44 [INFO]: Epoch 099 - training loss: 9293.8019, validation loss: 0.1063
2024-05-22 12:49:44 [INFO]: Epoch 100 - training loss: 9294.2806, validation loss: 0.1060
2024-05-22 12:49:44 [INFO]: Epoch 101 - training loss: 9293.5798, validation loss: 0.1054
2024-05-22 12:49:44 [INFO]: Epoch 102 - training loss: 9293.7638, validation loss: 0.1053
2024-05-22 12:49:44 [INFO]: Epoch 103 - training loss: 9291.2369, validation loss: 0.1044
2024-05-22 12:49:44 [INFO]: Epoch 104 - training loss: 9288.2729, validation loss: 0.1043
2024-05-22 12:49:45 [INFO]: Epoch 105 - training loss: 9290.5196, validation loss: 0.1041
2024-05-22 12:49:45 [INFO]: Epoch 106 - training loss: 9289.5646, validation loss: 0.1014
2024-05-22 12:49:45 [INFO]: Epoch 107 - training loss: 9290.5635, validation loss: 0.1020
2024-05-22 12:49:45 [INFO]: Epoch 108 - training loss: 9288.6293, validation loss: 0.1026
2024-05-22 12:49:45 [INFO]: Epoch 109 - training loss: 9288.1865, validation loss: 0.1012
2024-05-22 12:49:45 [INFO]: Epoch 110 - training loss: 9290.0936, validation loss: 0.1014
2024-05-22 12:49:45 [INFO]: Epoch 111 - training loss: 9287.0076, validation loss: 0.0997
2024-05-22 12:49:45 [INFO]: Epoch 112 - training loss: 9289.2026, validation loss: 0.0989
2024-05-22 12:49:46 [INFO]: Epoch 113 - training loss: 9286.9825, validation loss: 0.0999
2024-05-22 12:49:46 [INFO]: Epoch 114 - training loss: 9286.6763, validation loss: 0.0992
2024-05-22 12:49:46 [INFO]: Epoch 115 - training loss: 9287.3448, validation loss: 0.0987
2024-05-22 12:49:46 [INFO]: Epoch 116 - training loss: 9284.0596, validation loss: 0.0988
2024-05-22 12:49:46 [INFO]: Epoch 117 - training loss: 9285.9133, validation loss: 0.0963
2024-05-22 12:49:46 [INFO]: Epoch 118 - training loss: 9285.4629, validation loss: 0.0968
2024-05-22 12:49:46 [INFO]: Epoch 119 - training loss: 9286.9096, validation loss: 0.0978
2024-05-22 12:49:47 [INFO]: Epoch 120 - training loss: 9285.0983, validation loss: 0.0956
2024-05-22 12:49:47 [INFO]: Epoch 121 - training loss: 9284.7639, validation loss: 0.0970
2024-05-22 12:49:47 [INFO]: Epoch 122 - training loss: 9285.6645, validation loss: 0.0962
2024-05-22 12:49:47 [INFO]: Epoch 123 - training loss: 9285.3695, validation loss: 0.0943
2024-05-22 12:49:47 [INFO]: Epoch 124 - training loss: 9283.5078, validation loss: 0.0943
2024-05-22 12:49:47 [INFO]: Epoch 125 - training loss: 9282.7853, validation loss: 0.0937
2024-05-22 12:49:47 [INFO]: Epoch 126 - training loss: 9284.5603, validation loss: 0.0945
2024-05-22 12:49:47 [INFO]: Epoch 127 - training loss: 9281.2845, validation loss: 0.0930
2024-05-22 12:49:48 [INFO]: Epoch 128 - training loss: 9282.8087, validation loss: 0.0934
2024-05-22 12:49:48 [INFO]: Epoch 129 - training loss: 9289.1096, validation loss: 0.0923
2024-05-22 12:49:48 [INFO]: Epoch 130 - training loss: 9284.7068, validation loss: 0.0920
2024-05-22 12:49:48 [INFO]: Epoch 131 - training loss: 9282.5847, validation loss: 0.0916
2024-05-22 12:49:48 [INFO]: Epoch 132 - training loss: 9282.4210, validation loss: 0.0905
2024-05-22 12:49:48 [INFO]: Epoch 133 - training loss: 9282.4146, validation loss: 0.0913
2024-05-22 12:49:48 [INFO]: Epoch 134 - training loss: 9282.0222, validation loss: 0.0912
2024-05-22 12:49:49 [INFO]: Epoch 135 - training loss: 9281.1074, validation loss: 0.0899
2024-05-22 12:49:49 [INFO]: Epoch 136 - training loss: 9280.1912, validation loss: 0.0906
2024-05-22 12:49:49 [INFO]: Epoch 137 - training loss: 9280.0693, validation loss: 0.0893
2024-05-22 12:49:49 [INFO]: Epoch 138 - training loss: 9280.4399, validation loss: 0.0897
2024-05-22 12:49:49 [INFO]: Epoch 139 - training loss: 9284.1672, validation loss: 0.0889
2024-05-22 12:49:49 [INFO]: Epoch 140 - training loss: 9280.2333, validation loss: 0.0889
2024-05-22 12:49:49 [INFO]: Epoch 141 - training loss: 9280.6391, validation loss: 0.0875
2024-05-22 12:49:49 [INFO]: Epoch 142 - training loss: 9280.5477, validation loss: 0.0899
2024-05-22 12:49:50 [INFO]: Epoch 143 - training loss: 9279.9308, validation loss: 0.0891
2024-05-22 12:49:50 [INFO]: Epoch 144 - training loss: 9280.1410, validation loss: 0.0894
2024-05-22 12:49:50 [INFO]: Epoch 145 - training loss: 9280.4919, validation loss: 0.0876
2024-05-22 12:49:50 [INFO]: Epoch 146 - training loss: 9279.2875, validation loss: 0.0886
2024-05-22 12:49:50 [INFO]: Epoch 147 - training loss: 9280.0733, validation loss: 0.0876
2024-05-22 12:49:50 [INFO]: Epoch 148 - training loss: 9279.4017, validation loss: 0.0860
2024-05-22 12:49:50 [INFO]: Epoch 149 - training loss: 9278.8788, validation loss: 0.0887
2024-05-22 12:49:51 [INFO]: Epoch 150 - training loss: 9278.7447, validation loss: 0.0854
2024-05-22 12:49:51 [INFO]: Epoch 151 - training loss: 9279.7222, validation loss: 0.0864
2024-05-22 12:49:51 [INFO]: Epoch 152 - training loss: 9277.7029, validation loss: 0.0857
2024-05-22 12:49:51 [INFO]: Epoch 153 - training loss: 9277.7261, validation loss: 0.0857
2024-05-22 12:49:51 [INFO]: Epoch 154 - training loss: 9277.4503, validation loss: 0.0862
2024-05-22 12:49:51 [INFO]: Epoch 155 - training loss: 9278.2003, validation loss: 0.0848
2024-05-22 12:49:51 [INFO]: Epoch 156 - training loss: 9278.9437, validation loss: 0.0850
2024-05-22 12:49:52 [INFO]: Epoch 157 - training loss: 9276.6724, validation loss: 0.0843
2024-05-22 12:49:52 [INFO]: Epoch 158 - training loss: 9277.7907, validation loss: 0.0845
2024-05-22 12:49:52 [INFO]: Epoch 159 - training loss: 9278.1683, validation loss: 0.0843
2024-05-22 12:49:52 [INFO]: Epoch 160 - training loss: 9279.1528, validation loss: 0.0828
2024-05-22 12:49:52 [INFO]: Epoch 161 - training loss: 9276.3654, validation loss: 0.0839
2024-05-22 12:49:52 [INFO]: Epoch 162 - training loss: 9276.9982, validation loss: 0.0836
2024-05-22 12:49:52 [INFO]: Epoch 163 - training loss: 9277.6779, validation loss: 0.0817
2024-05-22 12:49:52 [INFO]: Epoch 164 - training loss: 9277.3101, validation loss: 0.0844
2024-05-22 12:49:53 [INFO]: Epoch 165 - training loss: 9275.9626, validation loss: 0.0831
2024-05-22 12:49:53 [INFO]: Epoch 166 - training loss: 9275.7708, validation loss: 0.0823
2024-05-22 12:49:53 [INFO]: Epoch 167 - training loss: 9275.4590, validation loss: 0.0830
2024-05-22 12:49:53 [INFO]: Epoch 168 - training loss: 9278.3738, validation loss: 0.0816
2024-05-22 12:49:53 [INFO]: Epoch 169 - training loss: 9276.1505, validation loss: 0.0827
2024-05-22 12:49:53 [INFO]: Epoch 170 - training loss: 9276.2346, validation loss: 0.0824
2024-05-22 12:49:53 [INFO]: Epoch 171 - training loss: 9274.8960, validation loss: 0.0806
2024-05-22 12:49:54 [INFO]: Epoch 172 - training loss: 9277.0699, validation loss: 0.0811
2024-05-22 12:49:54 [INFO]: Epoch 173 - training loss: 9277.2792, validation loss: 0.0821
2024-05-22 12:49:54 [INFO]: Epoch 174 - training loss: 9275.0331, validation loss: 0.0809
2024-05-22 12:49:54 [INFO]: Epoch 175 - training loss: 9274.7449, validation loss: 0.0820
2024-05-22 12:49:54 [INFO]: Epoch 176 - training loss: 9275.0805, validation loss: 0.0808
2024-05-22 12:49:54 [INFO]: Epoch 177 - training loss: 9276.0394, validation loss: 0.0807
2024-05-22 12:49:54 [INFO]: Epoch 178 - training loss: 9274.1470, validation loss: 0.0811
2024-05-22 12:49:54 [INFO]: Epoch 179 - training loss: 9275.5521, validation loss: 0.0797
2024-05-22 12:49:55 [INFO]: Epoch 180 - training loss: 9275.5569, validation loss: 0.0818
2024-05-22 12:49:55 [INFO]: Epoch 181 - training loss: 9275.4175, validation loss: 0.0811
2024-05-22 12:49:55 [INFO]: Epoch 182 - training loss: 9274.7054, validation loss: 0.0803
2024-05-22 12:49:55 [INFO]: Epoch 183 - training loss: 9275.0370, validation loss: 0.0798
2024-05-22 12:49:55 [INFO]: Epoch 184 - training loss: 9274.4591, validation loss: 0.0798
2024-05-22 12:49:55 [INFO]: Epoch 185 - training loss: 9274.6628, validation loss: 0.0781
2024-05-22 12:49:55 [INFO]: Epoch 186 - training loss: 9275.0832, validation loss: 0.0798
2024-05-22 12:49:56 [INFO]: Epoch 187 - training loss: 9275.2209, validation loss: 0.0800
2024-05-22 12:49:56 [INFO]: Epoch 188 - training loss: 9274.9853, validation loss: 0.0797
2024-05-22 12:49:56 [INFO]: Epoch 189 - training loss: 9275.4788, validation loss: 0.0794
2024-05-22 12:49:56 [INFO]: Epoch 190 - training loss: 9275.6863, validation loss: 0.0777
2024-05-22 12:49:56 [INFO]: Epoch 191 - training loss: 9275.0181, validation loss: 0.0786
2024-05-22 12:49:56 [INFO]: Epoch 192 - training loss: 9274.4965, validation loss: 0.0775
2024-05-22 12:49:56 [INFO]: Epoch 193 - training loss: 9273.6576, validation loss: 0.0785
2024-05-22 12:49:56 [INFO]: Epoch 194 - training loss: 9273.1182, validation loss: 0.0774
2024-05-22 12:49:57 [INFO]: Epoch 195 - training loss: 9273.8193, validation loss: 0.0802
2024-05-22 12:49:57 [INFO]: Epoch 196 - training loss: 9274.2291, validation loss: 0.0781
2024-05-22 12:49:57 [INFO]: Epoch 197 - training loss: 9272.3583, validation loss: 0.0776
2024-05-22 12:49:57 [INFO]: Epoch 198 - training loss: 9274.2449, validation loss: 0.0773
2024-05-22 12:49:57 [INFO]: Epoch 199 - training loss: 9274.7682, validation loss: 0.0769
2024-05-22 12:49:57 [INFO]: Epoch 200 - training loss: 9273.1920, validation loss: 0.0799
2024-05-22 12:49:57 [INFO]: Epoch 201 - training loss: 9272.7958, validation loss: 0.0767
2024-05-22 12:49:58 [INFO]: Epoch 202 - training loss: 9273.3438, validation loss: 0.0773
2024-05-22 12:49:58 [INFO]: Epoch 203 - training loss: 9274.5828, validation loss: 0.0777
2024-05-22 12:49:58 [INFO]: Epoch 204 - training loss: 9274.0776, validation loss: 0.0772
2024-05-22 12:49:58 [INFO]: Epoch 205 - training loss: 9272.5748, validation loss: 0.0786
2024-05-22 12:49:58 [INFO]: Epoch 206 - training loss: 9273.2219, validation loss: 0.0786
2024-05-22 12:49:58 [INFO]: Epoch 207 - training loss: 9272.5312, validation loss: 0.0759
2024-05-22 12:49:58 [INFO]: Epoch 208 - training loss: 9272.6595, validation loss: 0.0765
2024-05-22 12:49:58 [INFO]: Epoch 209 - training loss: 9273.1858, validation loss: 0.0770
2024-05-22 12:49:59 [INFO]: Epoch 210 - training loss: 9272.5654, validation loss: 0.0768
2024-05-22 12:49:59 [INFO]: Epoch 211 - training loss: 9273.0795, validation loss: 0.0765
2024-05-22 12:49:59 [INFO]: Epoch 212 - training loss: 9272.7814, validation loss: 0.0764
2024-05-22 12:49:59 [INFO]: Epoch 213 - training loss: 9272.7129, validation loss: 0.0779
2024-05-22 12:49:59 [INFO]: Epoch 214 - training loss: 9271.1080, validation loss: 0.0782
2024-05-22 12:49:59 [INFO]: Epoch 215 - training loss: 9273.0972, validation loss: 0.0777
2024-05-22 12:49:59 [INFO]: Epoch 216 - training loss: 9271.8398, validation loss: 0.0763
2024-05-22 12:50:00 [INFO]: Epoch 217 - training loss: 9271.5623, validation loss: 0.0754
2024-05-22 12:50:00 [INFO]: Epoch 218 - training loss: 9271.3222, validation loss: 0.0776
2024-05-22 12:50:00 [INFO]: Epoch 219 - training loss: 9271.8511, validation loss: 0.0765
2024-05-22 12:50:00 [INFO]: Epoch 220 - training loss: 9273.3862, validation loss: 0.0763
2024-05-22 12:50:00 [INFO]: Epoch 221 - training loss: 9272.1399, validation loss: 0.0774
2024-05-22 12:50:00 [INFO]: Epoch 222 - training loss: 9271.6768, validation loss: 0.0763
2024-05-22 12:50:00 [INFO]: Epoch 223 - training loss: 9271.3440, validation loss: 0.0777
2024-05-22 12:50:01 [INFO]: Epoch 224 - training loss: 9272.8459, validation loss: 0.0750
2024-05-22 12:50:01 [INFO]: Epoch 225 - training loss: 9273.0010, validation loss: 0.0756
2024-05-22 12:50:01 [INFO]: Epoch 226 - training loss: 9270.6882, validation loss: 0.0767
2024-05-22 12:50:01 [INFO]: Epoch 227 - training loss: 9271.8779, validation loss: 0.0749
2024-05-22 12:50:01 [INFO]: Epoch 228 - training loss: 9272.1589, validation loss: 0.0760
2024-05-22 12:50:01 [INFO]: Epoch 229 - training loss: 9273.0640, validation loss: 0.0764
2024-05-22 12:50:01 [INFO]: Epoch 230 - training loss: 9270.7639, validation loss: 0.0743
2024-05-22 12:50:01 [INFO]: Epoch 231 - training loss: 9271.8500, validation loss: 0.0756
2024-05-22 12:50:02 [INFO]: Epoch 232 - training loss: 9271.1156, validation loss: 0.0761
2024-05-22 12:50:02 [INFO]: Epoch 233 - training loss: 9269.3514, validation loss: 0.0754
2024-05-22 12:50:02 [INFO]: Epoch 234 - training loss: 9270.7134, validation loss: 0.0742
2024-05-22 12:50:02 [INFO]: Epoch 235 - training loss: 9270.8538, validation loss: 0.0757
2024-05-22 12:50:02 [INFO]: Epoch 236 - training loss: 9272.7976, validation loss: 0.0758
2024-05-22 12:50:02 [INFO]: Epoch 237 - training loss: 9271.4676, validation loss: 0.0769
2024-05-22 12:50:02 [INFO]: Epoch 238 - training loss: 9271.4532, validation loss: 0.0742
2024-05-22 12:50:03 [INFO]: Epoch 239 - training loss: 9272.2762, validation loss: 0.0770
2024-05-22 12:50:03 [INFO]: Epoch 240 - training loss: 9271.2095, validation loss: 0.0739
2024-05-22 12:50:03 [INFO]: Epoch 241 - training loss: 9270.0255, validation loss: 0.0750
2024-05-22 12:50:03 [INFO]: Epoch 242 - training loss: 9272.3058, validation loss: 0.0758
2024-05-22 12:50:03 [INFO]: Epoch 243 - training loss: 9270.7413, validation loss: 0.0757
2024-05-22 12:50:03 [INFO]: Epoch 244 - training loss: 9272.4737, validation loss: 0.0745
2024-05-22 12:50:03 [INFO]: Epoch 245 - training loss: 9270.5815, validation loss: 0.0763
2024-05-22 12:50:03 [INFO]: Epoch 246 - training loss: 9271.4578, validation loss: 0.0767
2024-05-22 12:50:04 [INFO]: Epoch 247 - training loss: 9270.7279, validation loss: 0.0765
2024-05-22 12:50:04 [INFO]: Epoch 248 - training loss: 9270.9377, validation loss: 0.0762
2024-05-22 12:50:04 [INFO]: Epoch 249 - training loss: 9269.9386, validation loss: 0.0750
2024-05-22 12:50:04 [INFO]: Epoch 250 - training loss: 9270.9381, validation loss: 0.0757
2024-05-22 12:50:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:50:04 [INFO]: Finished training. The best model is from epoch#240.
2024-05-22 12:50:04 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_ettm1/20240522_T124930/GPVAE.pypots
2024-05-22 12:50:04 [INFO]: GP-VAE on ETTm1: MAE=0.2724, MSE=0.1623
2024-05-22 12:50:04 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-22 12:50:04 [INFO]: Using the given device: cuda:0
2024-05-22 12:50:04 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240522_T125004
2024-05-22 12:50:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240522_T125004/tensorboard
2024-05-22 12:50:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 12:50:15 [INFO]: Epoch 001 - generator training loss: 0.5105, discriminator training loss: 0.4233, validation loss: 0.3110
2024-05-22 12:50:24 [INFO]: Epoch 002 - generator training loss: 0.0085, discriminator training loss: 0.3191, validation loss: 0.1095
2024-05-22 12:50:33 [INFO]: Epoch 003 - generator training loss: -0.1190, discriminator training loss: 0.3077, validation loss: 0.0639
2024-05-22 12:50:42 [INFO]: Epoch 004 - generator training loss: -0.1361, discriminator training loss: 0.2946, validation loss: 0.0498
2024-05-22 12:50:51 [INFO]: Epoch 005 - generator training loss: -0.1231, discriminator training loss: 0.2726, validation loss: 0.0446
2024-05-22 12:51:00 [INFO]: Epoch 006 - generator training loss: -0.1006, discriminator training loss: 0.2404, validation loss: 0.0417
2024-05-22 12:51:09 [INFO]: Epoch 007 - generator training loss: -0.0754, discriminator training loss: 0.2049, validation loss: 0.0395
2024-05-22 12:51:18 [INFO]: Epoch 008 - generator training loss: -0.0567, discriminator training loss: 0.1748, validation loss: 0.0390
2024-05-22 12:51:27 [INFO]: Epoch 009 - generator training loss: -0.0436, discriminator training loss: 0.1531, validation loss: 0.0360
2024-05-22 12:51:36 [INFO]: Epoch 010 - generator training loss: -0.0370, discriminator training loss: 0.1380, validation loss: 0.0351
2024-05-22 12:51:45 [INFO]: Epoch 011 - generator training loss: -0.0353, discriminator training loss: 0.1324, validation loss: 0.0353
2024-05-22 12:51:54 [INFO]: Epoch 012 - generator training loss: -0.0304, discriminator training loss: 0.1272, validation loss: 0.0351
2024-05-22 12:52:03 [INFO]: Epoch 013 - generator training loss: -0.0312, discriminator training loss: 0.1257, validation loss: 0.0346
2024-05-22 12:52:12 [INFO]: Epoch 014 - generator training loss: -0.0322, discriminator training loss: 0.1218, validation loss: 0.0342
2024-05-22 12:52:21 [INFO]: Epoch 015 - generator training loss: -0.0326, discriminator training loss: 0.1215, validation loss: 0.0339
2024-05-22 12:52:29 [INFO]: Epoch 016 - generator training loss: -0.0303, discriminator training loss: 0.1186, validation loss: 0.0339
2024-05-22 12:52:38 [INFO]: Epoch 017 - generator training loss: -0.0294, discriminator training loss: 0.1191, validation loss: 0.0333
2024-05-22 12:52:47 [INFO]: Epoch 018 - generator training loss: -0.0292, discriminator training loss: 0.1181, validation loss: 0.0330
2024-05-22 12:52:56 [INFO]: Epoch 019 - generator training loss: -0.0324, discriminator training loss: 0.1158, validation loss: 0.0325
2024-05-22 12:53:05 [INFO]: Epoch 020 - generator training loss: -0.0333, discriminator training loss: 0.1164, validation loss: 0.0322
2024-05-22 12:53:14 [INFO]: Epoch 021 - generator training loss: -0.0336, discriminator training loss: 0.1149, validation loss: 0.0318
2024-05-22 12:53:23 [INFO]: Epoch 022 - generator training loss: -0.0357, discriminator training loss: 0.1157, validation loss: 0.0312
2024-05-22 12:53:32 [INFO]: Epoch 023 - generator training loss: -0.0361, discriminator training loss: 0.1150, validation loss: 0.0320
2024-05-22 12:53:41 [INFO]: Epoch 024 - generator training loss: -0.0352, discriminator training loss: 0.1129, validation loss: 0.0314
2024-05-22 12:53:50 [INFO]: Epoch 025 - generator training loss: -0.0364, discriminator training loss: 0.1151, validation loss: 0.0320
2024-05-22 12:53:59 [INFO]: Epoch 026 - generator training loss: -0.0378, discriminator training loss: 0.1142, validation loss: 0.0313
2024-05-22 12:54:08 [INFO]: Epoch 027 - generator training loss: -0.0363, discriminator training loss: 0.1137, validation loss: 0.0306
2024-05-22 12:54:17 [INFO]: Epoch 028 - generator training loss: -0.0364, discriminator training loss: 0.1110, validation loss: 0.0303
2024-05-22 12:54:26 [INFO]: Epoch 029 - generator training loss: -0.0365, discriminator training loss: 0.1113, validation loss: 0.0307
2024-05-22 12:54:35 [INFO]: Epoch 030 - generator training loss: -0.0353, discriminator training loss: 0.1142, validation loss: 0.0308
2024-05-22 12:54:44 [INFO]: Epoch 031 - generator training loss: -0.0359, discriminator training loss: 0.1124, validation loss: 0.0305
2024-05-22 12:54:54 [INFO]: Epoch 032 - generator training loss: -0.0364, discriminator training loss: 0.1118, validation loss: 0.0295
2024-05-22 12:55:02 [INFO]: Epoch 033 - generator training loss: -0.0364, discriminator training loss: 0.1111, validation loss: 0.0298
2024-05-22 12:55:11 [INFO]: Epoch 034 - generator training loss: -0.0371, discriminator training loss: 0.1131, validation loss: 0.0298
2024-05-22 12:55:20 [INFO]: Epoch 035 - generator training loss: -0.0391, discriminator training loss: 0.1113, validation loss: 0.0291
2024-05-22 12:55:29 [INFO]: Epoch 036 - generator training loss: -0.0394, discriminator training loss: 0.1106, validation loss: 0.0289
2024-05-22 12:55:38 [INFO]: Epoch 037 - generator training loss: -0.0396, discriminator training loss: 0.1106, validation loss: 0.0290
2024-05-22 12:55:47 [INFO]: Epoch 038 - generator training loss: -0.0375, discriminator training loss: 0.1114, validation loss: 0.0285
2024-05-22 12:55:56 [INFO]: Epoch 039 - generator training loss: -0.0406, discriminator training loss: 0.1114, validation loss: 0.0286
2024-05-22 12:56:05 [INFO]: Epoch 040 - generator training loss: -0.0406, discriminator training loss: 0.1098, validation loss: 0.0281
2024-05-22 12:56:14 [INFO]: Epoch 041 - generator training loss: -0.0438, discriminator training loss: 0.1082, validation loss: 0.0278
2024-05-22 12:56:23 [INFO]: Epoch 042 - generator training loss: -0.0427, discriminator training loss: 0.1095, validation loss: 0.0284
2024-05-22 12:56:32 [INFO]: Epoch 043 - generator training loss: -0.0388, discriminator training loss: 0.1106, validation loss: 0.0281
2024-05-22 12:56:42 [INFO]: Epoch 044 - generator training loss: -0.0391, discriminator training loss: 0.1098, validation loss: 0.0274
2024-05-22 12:56:51 [INFO]: Epoch 045 - generator training loss: -0.0424, discriminator training loss: 0.1080, validation loss: 0.0279
2024-05-22 12:57:00 [INFO]: Epoch 046 - generator training loss: -0.0419, discriminator training loss: 0.1091, validation loss: 0.0278
2024-05-22 12:57:09 [INFO]: Epoch 047 - generator training loss: -0.0411, discriminator training loss: 0.1085, validation loss: 0.0269
2024-05-22 12:57:18 [INFO]: Epoch 048 - generator training loss: -0.0427, discriminator training loss: 0.1088, validation loss: 0.0267
2024-05-22 12:57:27 [INFO]: Epoch 049 - generator training loss: -0.0427, discriminator training loss: 0.1096, validation loss: 0.0267
2024-05-22 12:57:36 [INFO]: Epoch 050 - generator training loss: -0.0412, discriminator training loss: 0.1088, validation loss: 0.0267
2024-05-22 12:57:45 [INFO]: Epoch 051 - generator training loss: -0.0430, discriminator training loss: 0.1088, validation loss: 0.0267
2024-05-22 12:57:54 [INFO]: Epoch 052 - generator training loss: -0.0458, discriminator training loss: 0.1087, validation loss: 0.0261
2024-05-22 12:58:03 [INFO]: Epoch 053 - generator training loss: -0.0439, discriminator training loss: 0.1109, validation loss: 0.0256
2024-05-22 12:58:12 [INFO]: Epoch 054 - generator training loss: -0.0443, discriminator training loss: 0.1088, validation loss: 0.0256
2024-05-22 12:58:21 [INFO]: Epoch 055 - generator training loss: -0.0459, discriminator training loss: 0.1092, validation loss: 0.0262
2024-05-22 12:58:30 [INFO]: Epoch 056 - generator training loss: -0.0432, discriminator training loss: 0.1089, validation loss: 0.0249
2024-05-22 12:58:38 [INFO]: Epoch 057 - generator training loss: -0.0444, discriminator training loss: 0.1098, validation loss: 0.0260
2024-05-22 12:58:47 [INFO]: Epoch 058 - generator training loss: -0.0439, discriminator training loss: 0.1070, validation loss: 0.0249
2024-05-22 12:58:56 [INFO]: Epoch 059 - generator training loss: -0.0449, discriminator training loss: 0.1064, validation loss: 0.0254
2024-05-22 12:59:05 [INFO]: Epoch 060 - generator training loss: -0.0467, discriminator training loss: 0.1106, validation loss: 0.0244
2024-05-22 12:59:14 [INFO]: Epoch 061 - generator training loss: -0.0458, discriminator training loss: 0.1087, validation loss: 0.0244
2024-05-22 12:59:23 [INFO]: Epoch 062 - generator training loss: -0.0476, discriminator training loss: 0.1095, validation loss: 0.0245
2024-05-22 12:59:32 [INFO]: Epoch 063 - generator training loss: -0.0469, discriminator training loss: 0.1072, validation loss: 0.0243
2024-05-22 12:59:41 [INFO]: Epoch 064 - generator training loss: -0.0493, discriminator training loss: 0.1086, validation loss: 0.0242
2024-05-22 12:59:50 [INFO]: Epoch 065 - generator training loss: -0.0449, discriminator training loss: 0.1079, validation loss: 0.0243
2024-05-22 12:59:58 [INFO]: Epoch 066 - generator training loss: -0.0464, discriminator training loss: 0.1064, validation loss: 0.0246
2024-05-22 13:00:07 [INFO]: Epoch 067 - generator training loss: -0.0442, discriminator training loss: 0.1083, validation loss: 0.0256
2024-05-22 13:00:16 [INFO]: Epoch 068 - generator training loss: -0.0472, discriminator training loss: 0.1061, validation loss: 0.0237
2024-05-22 13:00:25 [INFO]: Epoch 069 - generator training loss: -0.0472, discriminator training loss: 0.1078, validation loss: 0.0238
2024-05-22 13:00:34 [INFO]: Epoch 070 - generator training loss: -0.0456, discriminator training loss: 0.1082, validation loss: 0.0240
2024-05-22 13:00:43 [INFO]: Epoch 071 - generator training loss: -0.0468, discriminator training loss: 0.1084, validation loss: 0.0237
2024-05-22 13:00:52 [INFO]: Epoch 072 - generator training loss: -0.0485, discriminator training loss: 0.1079, validation loss: 0.0232
2024-05-22 13:01:01 [INFO]: Epoch 073 - generator training loss: -0.0465, discriminator training loss: 0.1069, validation loss: 0.0235
2024-05-22 13:01:10 [INFO]: Epoch 074 - generator training loss: -0.0493, discriminator training loss: 0.1072, validation loss: 0.0231
2024-05-22 13:01:19 [INFO]: Epoch 075 - generator training loss: -0.0456, discriminator training loss: 0.1097, validation loss: 0.0227
2024-05-22 13:01:28 [INFO]: Epoch 076 - generator training loss: -0.0447, discriminator training loss: 0.1078, validation loss: 0.0250
2024-05-22 13:01:37 [INFO]: Epoch 077 - generator training loss: -0.0474, discriminator training loss: 0.1065, validation loss: 0.0236
2024-05-22 13:01:45 [INFO]: Epoch 078 - generator training loss: -0.0483, discriminator training loss: 0.1087, validation loss: 0.0230
2024-05-22 13:01:54 [INFO]: Epoch 079 - generator training loss: -0.0471, discriminator training loss: 0.1084, validation loss: 0.0224
2024-05-22 13:02:03 [INFO]: Epoch 080 - generator training loss: -0.0479, discriminator training loss: 0.1077, validation loss: 0.0233
2024-05-22 13:02:12 [INFO]: Epoch 081 - generator training loss: -0.0476, discriminator training loss: 0.1050, validation loss: 0.0231
2024-05-22 13:02:21 [INFO]: Epoch 082 - generator training loss: -0.0480, discriminator training loss: 0.1058, validation loss: 0.0233
2024-05-22 13:02:30 [INFO]: Epoch 083 - generator training loss: -0.0474, discriminator training loss: 0.1062, validation loss: 0.0236
2024-05-22 13:02:39 [INFO]: Epoch 084 - generator training loss: -0.0464, discriminator training loss: 0.1066, validation loss: 0.0223
2024-05-22 13:02:48 [INFO]: Epoch 085 - generator training loss: -0.0500, discriminator training loss: 0.1055, validation loss: 0.0223
2024-05-22 13:02:57 [INFO]: Epoch 086 - generator training loss: -0.0484, discriminator training loss: 0.1079, validation loss: 0.0229
2024-05-22 13:03:05 [INFO]: Epoch 087 - generator training loss: -0.0476, discriminator training loss: 0.1071, validation loss: 0.0221
2024-05-22 13:03:14 [INFO]: Epoch 088 - generator training loss: -0.0494, discriminator training loss: 0.1044, validation loss: 0.0217
2024-05-22 13:03:23 [INFO]: Epoch 089 - generator training loss: -0.0505, discriminator training loss: 0.1077, validation loss: 0.0220
2024-05-22 13:03:32 [INFO]: Epoch 090 - generator training loss: -0.0465, discriminator training loss: 0.1062, validation loss: 0.0223
2024-05-22 13:03:41 [INFO]: Epoch 091 - generator training loss: -0.0523, discriminator training loss: 0.1076, validation loss: 0.0220
2024-05-22 13:03:50 [INFO]: Epoch 092 - generator training loss: -0.0486, discriminator training loss: 0.1051, validation loss: 0.0226
2024-05-22 13:03:59 [INFO]: Epoch 093 - generator training loss: -0.0476, discriminator training loss: 0.1045, validation loss: 0.0226
2024-05-22 13:04:08 [INFO]: Epoch 094 - generator training loss: -0.0487, discriminator training loss: 0.1079, validation loss: 0.0234
2024-05-22 13:04:17 [INFO]: Epoch 095 - generator training loss: -0.0471, discriminator training loss: 0.1048, validation loss: 0.0236
2024-05-22 13:04:26 [INFO]: Epoch 096 - generator training loss: -0.0476, discriminator training loss: 0.1063, validation loss: 0.0218
2024-05-22 13:04:35 [INFO]: Epoch 097 - generator training loss: -0.0466, discriminator training loss: 0.1055, validation loss: 0.0248
2024-05-22 13:04:44 [INFO]: Epoch 098 - generator training loss: -0.0475, discriminator training loss: 0.1068, validation loss: 0.0238
2024-05-22 13:04:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:04:44 [INFO]: Finished training. The best model is from epoch#88.
2024-05-22 13:04:44 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_ettm1/20240522_T125004/USGAN.pypots
2024-05-22 13:04:45 [INFO]: US-GAN on ETTm1: MAE=0.1428, MSE=0.0514
2024-05-22 13:04:45 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-22 13:04:45 [INFO]: Using the given device: cuda:0
2024-05-22 13:04:45 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240522_T130445
2024-05-22 13:04:45 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240522_T130445/tensorboard
2024-05-22 13:04:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 13:04:52 [INFO]: Epoch 001 - training loss: 1.3042, validation loss: 0.2670
2024-05-22 13:04:58 [INFO]: Epoch 002 - training loss: 0.8909, validation loss: 0.0935
2024-05-22 13:05:04 [INFO]: Epoch 003 - training loss: 0.7245, validation loss: 0.0618
2024-05-22 13:05:10 [INFO]: Epoch 004 - training loss: 0.6515, validation loss: 0.0472
2024-05-22 13:05:16 [INFO]: Epoch 005 - training loss: 0.5995, validation loss: 0.0424
2024-05-22 13:05:22 [INFO]: Epoch 006 - training loss: 0.5673, validation loss: 0.0391
2024-05-22 13:05:28 [INFO]: Epoch 007 - training loss: 0.5446, validation loss: 0.0381
2024-05-22 13:05:34 [INFO]: Epoch 008 - training loss: 0.5108, validation loss: 0.0360
2024-05-22 13:05:40 [INFO]: Epoch 009 - training loss: 0.4924, validation loss: 0.0355
2024-05-22 13:05:46 [INFO]: Epoch 010 - training loss: 0.4777, validation loss: 0.0334
2024-05-22 13:05:51 [INFO]: Epoch 011 - training loss: 0.4573, validation loss: 0.0341
2024-05-22 13:05:57 [INFO]: Epoch 012 - training loss: 0.4451, validation loss: 0.0315
2024-05-22 13:06:03 [INFO]: Epoch 013 - training loss: 0.4304, validation loss: 0.0306
2024-05-22 13:06:09 [INFO]: Epoch 014 - training loss: 0.4188, validation loss: 0.0301
2024-05-22 13:06:15 [INFO]: Epoch 015 - training loss: 0.4138, validation loss: 0.0293
2024-05-22 13:06:21 [INFO]: Epoch 016 - training loss: 0.4038, validation loss: 0.0276
2024-05-22 13:06:27 [INFO]: Epoch 017 - training loss: 0.4018, validation loss: 0.0266
2024-05-22 13:06:33 [INFO]: Epoch 018 - training loss: 0.4001, validation loss: 0.0265
2024-05-22 13:06:39 [INFO]: Epoch 019 - training loss: 0.3938, validation loss: 0.0259
2024-05-22 13:06:45 [INFO]: Epoch 020 - training loss: 0.4069, validation loss: 0.0255
2024-05-22 13:06:51 [INFO]: Epoch 021 - training loss: 0.3980, validation loss: 0.0261
2024-05-22 13:06:57 [INFO]: Epoch 022 - training loss: 0.3982, validation loss: 0.0253
2024-05-22 13:07:03 [INFO]: Epoch 023 - training loss: 0.3991, validation loss: 0.0250
2024-05-22 13:07:09 [INFO]: Epoch 024 - training loss: 0.4470, validation loss: 0.0263
2024-05-22 13:07:15 [INFO]: Epoch 025 - training loss: 0.4153, validation loss: 0.0260
2024-05-22 13:07:21 [INFO]: Epoch 026 - training loss: 0.4056, validation loss: 0.0274
2024-05-22 13:07:26 [INFO]: Epoch 027 - training loss: 0.3990, validation loss: 0.0252
2024-05-22 13:07:32 [INFO]: Epoch 028 - training loss: 0.3902, validation loss: 0.0250
2024-05-22 13:07:38 [INFO]: Epoch 029 - training loss: 0.3853, validation loss: 0.0254
2024-05-22 13:07:44 [INFO]: Epoch 030 - training loss: 0.3832, validation loss: 0.0250
2024-05-22 13:07:50 [INFO]: Epoch 031 - training loss: 0.3827, validation loss: 0.0246
2024-05-22 13:07:56 [INFO]: Epoch 032 - training loss: 0.3861, validation loss: 0.0244
2024-05-22 13:08:02 [INFO]: Epoch 033 - training loss: 0.3875, validation loss: 0.0248
2024-05-22 13:08:08 [INFO]: Epoch 034 - training loss: 0.3846, validation loss: 0.0248
2024-05-22 13:08:14 [INFO]: Epoch 035 - training loss: 0.3810, validation loss: 0.0243
2024-05-22 13:08:20 [INFO]: Epoch 036 - training loss: 0.3833, validation loss: 0.0246
2024-05-22 13:08:26 [INFO]: Epoch 037 - training loss: 0.4347, validation loss: 0.0244
2024-05-22 13:08:32 [INFO]: Epoch 038 - training loss: 0.4114, validation loss: 0.0275
2024-05-22 13:08:37 [INFO]: Epoch 039 - training loss: 0.3954, validation loss: 0.0251
2024-05-22 13:08:43 [INFO]: Epoch 040 - training loss: 0.3798, validation loss: 0.0249
2024-05-22 13:08:49 [INFO]: Epoch 041 - training loss: 0.3784, validation loss: 0.0247
2024-05-22 13:08:55 [INFO]: Epoch 042 - training loss: 0.3763, validation loss: 0.0249
2024-05-22 13:09:01 [INFO]: Epoch 043 - training loss: 0.3754, validation loss: 0.0246
2024-05-22 13:09:07 [INFO]: Epoch 044 - training loss: 0.3825, validation loss: 0.0247
2024-05-22 13:09:13 [INFO]: Epoch 045 - training loss: 0.3881, validation loss: 0.0247
2024-05-22 13:09:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:09:13 [INFO]: Finished training. The best model is from epoch#35.
2024-05-22 13:09:13 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_ettm1/20240522_T130445/BRITS.pypots
2024-05-22 13:09:14 [INFO]: BRITS on ETTm1: MAE=0.1338, MSE=0.0537
2024-05-22 13:09:14 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-22 13:09:14 [INFO]: Using the given device: cuda:0
2024-05-22 13:09:14 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914
2024-05-22 13:09:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/tensorboard
2024-05-22 13:09:14 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 13:09:16 [INFO]: Epoch 001 - training loss: 1.4366, validation loss: 1.3637
2024-05-22 13:09:16 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch1_loss1.3637339770793915.pypots
2024-05-22 13:09:16 [INFO]: Epoch 002 - training loss: 1.0692, validation loss: 1.2065
2024-05-22 13:09:16 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch2_loss1.2064690291881561.pypots
2024-05-22 13:09:16 [INFO]: Epoch 003 - training loss: 0.9821, validation loss: 1.1121
2024-05-22 13:09:16 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch3_loss1.1120698153972626.pypots
2024-05-22 13:09:16 [INFO]: Epoch 004 - training loss: 0.9683, validation loss: 1.0678
2024-05-22 13:09:16 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch4_loss1.0677925050258636.pypots
2024-05-22 13:09:17 [INFO]: Epoch 005 - training loss: 0.9242, validation loss: 1.0497
2024-05-22 13:09:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch5_loss1.0496536195278168.pypots
2024-05-22 13:09:17 [INFO]: Epoch 006 - training loss: 0.9476, validation loss: 1.0406
2024-05-22 13:09:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch6_loss1.0406212657690048.pypots
2024-05-22 13:09:17 [INFO]: Epoch 007 - training loss: 0.9301, validation loss: 1.0282
2024-05-22 13:09:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch7_loss1.0281540006399155.pypots
2024-05-22 13:09:17 [INFO]: Epoch 008 - training loss: 0.9237, validation loss: 1.0135
2024-05-22 13:09:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch8_loss1.0134547501802444.pypots
2024-05-22 13:09:17 [INFO]: Epoch 009 - training loss: 0.9113, validation loss: 1.0029
2024-05-22 13:09:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch9_loss1.002930998802185.pypots
2024-05-22 13:09:18 [INFO]: Epoch 010 - training loss: 0.9112, validation loss: 0.9964
2024-05-22 13:09:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch10_loss0.9963723421096802.pypots
2024-05-22 13:09:18 [INFO]: Epoch 011 - training loss: 0.8726, validation loss: 0.9885
2024-05-22 13:09:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch11_loss0.9884546995162964.pypots
2024-05-22 13:09:18 [INFO]: Epoch 012 - training loss: 0.8778, validation loss: 0.9796
2024-05-22 13:09:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch12_loss0.979635939002037.pypots
2024-05-22 13:09:18 [INFO]: Epoch 013 - training loss: 0.8795, validation loss: 0.9766
2024-05-22 13:09:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch13_loss0.9765557497739792.pypots
2024-05-22 13:09:18 [INFO]: Epoch 014 - training loss: 0.8964, validation loss: 0.9737
2024-05-22 13:09:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch14_loss0.9737418293952942.pypots
2024-05-22 13:09:19 [INFO]: Epoch 015 - training loss: 0.8730, validation loss: 0.9666
2024-05-22 13:09:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch15_loss0.9666465520858765.pypots
2024-05-22 13:09:19 [INFO]: Epoch 016 - training loss: 0.8587, validation loss: 0.9648
2024-05-22 13:09:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch16_loss0.9647603332996368.pypots
2024-05-22 13:09:19 [INFO]: Epoch 017 - training loss: 0.8749, validation loss: 0.9656
2024-05-22 13:09:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch17_loss0.9656446427106857.pypots
2024-05-22 13:09:19 [INFO]: Epoch 018 - training loss: 0.8620, validation loss: 0.9620
2024-05-22 13:09:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch18_loss0.9619776159524918.pypots
2024-05-22 13:09:19 [INFO]: Epoch 019 - training loss: 0.8281, validation loss: 0.9600
2024-05-22 13:09:19 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch19_loss0.9599509090185165.pypots
2024-05-22 13:09:20 [INFO]: Epoch 020 - training loss: 0.8120, validation loss: 0.9559
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch20_loss0.9558500945568085.pypots
2024-05-22 13:09:20 [INFO]: Epoch 021 - training loss: 0.8377, validation loss: 0.9549
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch21_loss0.9549162983894348.pypots
2024-05-22 13:09:20 [INFO]: Epoch 022 - training loss: 0.8261, validation loss: 0.9536
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch22_loss0.9535864889621735.pypots
2024-05-22 13:09:20 [INFO]: Epoch 023 - training loss: 0.8220, validation loss: 0.9513
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch23_loss0.9513423442840576.pypots
2024-05-22 13:09:20 [INFO]: Epoch 024 - training loss: 0.8218, validation loss: 0.9495
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch24_loss0.9495274126529694.pypots
2024-05-22 13:09:20 [INFO]: Epoch 025 - training loss: 0.8253, validation loss: 0.9482
2024-05-22 13:09:20 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch25_loss0.948244109749794.pypots
2024-05-22 13:09:21 [INFO]: Epoch 026 - training loss: 0.8373, validation loss: 0.9480
2024-05-22 13:09:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch26_loss0.9480250179767609.pypots
2024-05-22 13:09:21 [INFO]: Epoch 027 - training loss: 0.8364, validation loss: 0.9474
2024-05-22 13:09:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch27_loss0.9474261701107025.pypots
2024-05-22 13:09:21 [INFO]: Epoch 028 - training loss: 0.8239, validation loss: 0.9454
2024-05-22 13:09:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch28_loss0.9454462230205536.pypots
2024-05-22 13:09:21 [INFO]: Epoch 029 - training loss: 0.8047, validation loss: 0.9457
2024-05-22 13:09:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch29_loss0.9456855654716492.pypots
2024-05-22 13:09:21 [INFO]: Epoch 030 - training loss: 0.8271, validation loss: 0.9425
2024-05-22 13:09:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch30_loss0.9425263851881027.pypots
2024-05-22 13:09:22 [INFO]: Epoch 031 - training loss: 0.8050, validation loss: 0.9416
2024-05-22 13:09:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch31_loss0.9416219592094421.pypots
2024-05-22 13:09:22 [INFO]: Epoch 032 - training loss: 0.8128, validation loss: 0.9372
2024-05-22 13:09:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch32_loss0.9372286647558212.pypots
2024-05-22 13:09:22 [INFO]: Epoch 033 - training loss: 0.8145, validation loss: 0.9357
2024-05-22 13:09:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch33_loss0.9356786459684372.pypots
2024-05-22 13:09:22 [INFO]: Epoch 034 - training loss: 0.7809, validation loss: 0.9342
2024-05-22 13:09:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch34_loss0.9342169910669327.pypots
2024-05-22 13:09:22 [INFO]: Epoch 035 - training loss: 0.7928, validation loss: 0.9325
2024-05-22 13:09:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch35_loss0.9325130134820938.pypots
2024-05-22 13:09:23 [INFO]: Epoch 036 - training loss: 0.8047, validation loss: 0.9290
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch36_loss0.9289657473564148.pypots
2024-05-22 13:09:23 [INFO]: Epoch 037 - training loss: 0.7992, validation loss: 0.9277
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch37_loss0.9276597052812576.pypots
2024-05-22 13:09:23 [INFO]: Epoch 038 - training loss: 0.7794, validation loss: 0.9215
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch38_loss0.9214725345373154.pypots
2024-05-22 13:09:23 [INFO]: Epoch 039 - training loss: 0.8009, validation loss: 0.9209
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch39_loss0.9208701550960541.pypots
2024-05-22 13:09:23 [INFO]: Epoch 040 - training loss: 0.7923, validation loss: 0.9197
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch40_loss0.9197331815958023.pypots
2024-05-22 13:09:24 [INFO]: Epoch 041 - training loss: 0.7995, validation loss: 0.9143
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch41_loss0.9143042862415314.pypots
2024-05-22 13:09:24 [INFO]: Epoch 042 - training loss: 0.7962, validation loss: 0.9125
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch42_loss0.912457063794136.pypots
2024-05-22 13:09:24 [INFO]: Epoch 043 - training loss: 0.7926, validation loss: 0.9125
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch43_loss0.9124516844749451.pypots
2024-05-22 13:09:24 [INFO]: Epoch 044 - training loss: 0.7899, validation loss: 0.9093
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch44_loss0.9092919230461121.pypots
2024-05-22 13:09:24 [INFO]: Epoch 045 - training loss: 0.7866, validation loss: 0.9055
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch45_loss0.9055275171995163.pypots
2024-05-22 13:09:24 [INFO]: Epoch 046 - training loss: 0.8316, validation loss: 0.9053
2024-05-22 13:09:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch46_loss0.905345544219017.pypots
2024-05-22 13:09:25 [INFO]: Epoch 047 - training loss: 0.8041, validation loss: 0.9021
2024-05-22 13:09:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch47_loss0.9020965844392776.pypots
2024-05-22 13:09:25 [INFO]: Epoch 048 - training loss: 0.8081, validation loss: 0.8974
2024-05-22 13:09:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch48_loss0.897355318069458.pypots
2024-05-22 13:09:25 [INFO]: Epoch 049 - training loss: 0.7996, validation loss: 0.8979
2024-05-22 13:09:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch49_loss0.8979040235280991.pypots
2024-05-22 13:09:25 [INFO]: Epoch 050 - training loss: 0.8013, validation loss: 0.8950
2024-05-22 13:09:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch50_loss0.8950235098600388.pypots
2024-05-22 13:09:25 [INFO]: Epoch 051 - training loss: 0.8260, validation loss: 0.8907
2024-05-22 13:09:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch51_loss0.8906727284193039.pypots
2024-05-22 13:09:26 [INFO]: Epoch 052 - training loss: 0.8127, validation loss: 0.8896
2024-05-22 13:09:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch52_loss0.8895986378192902.pypots
2024-05-22 13:09:26 [INFO]: Epoch 053 - training loss: 0.8046, validation loss: 0.8887
2024-05-22 13:09:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch53_loss0.8886712938547134.pypots
2024-05-22 13:09:26 [INFO]: Epoch 054 - training loss: 0.7690, validation loss: 0.8867
2024-05-22 13:09:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch54_loss0.8866940438747406.pypots
2024-05-22 13:09:26 [INFO]: Epoch 055 - training loss: 0.7937, validation loss: 0.8874
2024-05-22 13:09:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch55_loss0.8874414712190628.pypots
2024-05-22 13:09:26 [INFO]: Epoch 056 - training loss: 0.7864, validation loss: 0.8840
2024-05-22 13:09:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch56_loss0.8839783668518066.pypots
2024-05-22 13:09:27 [INFO]: Epoch 057 - training loss: 0.7778, validation loss: 0.8826
2024-05-22 13:09:27 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch57_loss0.8826133757829666.pypots
2024-05-22 13:09:27 [INFO]: Epoch 058 - training loss: 0.8120, validation loss: 0.8835
2024-05-22 13:09:27 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch58_loss0.8834624737501144.pypots
2024-05-22 13:09:27 [INFO]: Epoch 059 - training loss: 0.8284, validation loss: 0.8820
2024-05-22 13:09:27 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch59_loss0.8819577991962433.pypots
2024-05-22 13:09:27 [INFO]: Epoch 060 - training loss: 0.7961, validation loss: 0.8770
2024-05-22 13:09:27 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch60_loss0.8769549131393433.pypots
2024-05-22 13:09:27 [INFO]: Epoch 061 - training loss: 0.8047, validation loss: 0.8766
2024-05-22 13:09:27 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch61_loss0.8765713721513748.pypots
2024-05-22 13:09:28 [INFO]: Epoch 062 - training loss: 0.7958, validation loss: 0.8762
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch62_loss0.8762429058551788.pypots
2024-05-22 13:09:28 [INFO]: Epoch 063 - training loss: 0.7865, validation loss: 0.8733
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch63_loss0.873280867934227.pypots
2024-05-22 13:09:28 [INFO]: Epoch 064 - training loss: 0.7827, validation loss: 0.8730
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch64_loss0.8730417937040329.pypots
2024-05-22 13:09:28 [INFO]: Epoch 065 - training loss: 0.7659, validation loss: 0.8709
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch65_loss0.8708614408969879.pypots
2024-05-22 13:09:28 [INFO]: Epoch 066 - training loss: 0.7755, validation loss: 0.8705
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch66_loss0.8704957216978073.pypots
2024-05-22 13:09:28 [INFO]: Epoch 067 - training loss: 0.7564, validation loss: 0.8731
2024-05-22 13:09:28 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch67_loss0.8730548471212387.pypots
2024-05-22 13:09:29 [INFO]: Epoch 068 - training loss: 0.7862, validation loss: 0.8661
2024-05-22 13:09:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch68_loss0.8661000281572342.pypots
2024-05-22 13:09:29 [INFO]: Epoch 069 - training loss: 0.7685, validation loss: 0.8658
2024-05-22 13:09:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch69_loss0.8657819181680679.pypots
2024-05-22 13:09:29 [INFO]: Epoch 070 - training loss: 0.7615, validation loss: 0.8681
2024-05-22 13:09:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch70_loss0.8680571764707565.pypots
2024-05-22 13:09:29 [INFO]: Epoch 071 - training loss: 0.7921, validation loss: 0.8641
2024-05-22 13:09:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch71_loss0.8640539348125458.pypots
2024-05-22 13:09:29 [INFO]: Epoch 072 - training loss: 0.8038, validation loss: 0.8669
2024-05-22 13:09:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch72_loss0.8668642342090607.pypots
2024-05-22 13:09:30 [INFO]: Epoch 073 - training loss: 0.7758, validation loss: 0.8630
2024-05-22 13:09:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch73_loss0.8629779070615768.pypots
2024-05-22 13:09:30 [INFO]: Epoch 074 - training loss: 0.7860, validation loss: 0.8660
2024-05-22 13:09:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch74_loss0.86600661277771.pypots
2024-05-22 13:09:30 [INFO]: Epoch 075 - training loss: 0.7910, validation loss: 0.8629
2024-05-22 13:09:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch75_loss0.8628832548856735.pypots
2024-05-22 13:09:30 [INFO]: Epoch 076 - training loss: 0.7758, validation loss: 0.8631
2024-05-22 13:09:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch76_loss0.8630677163600922.pypots
2024-05-22 13:09:30 [INFO]: Epoch 077 - training loss: 0.7567, validation loss: 0.8627
2024-05-22 13:09:30 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch77_loss0.8626832664012909.pypots
2024-05-22 13:09:31 [INFO]: Epoch 078 - training loss: 0.7842, validation loss: 0.8600
2024-05-22 13:09:31 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch78_loss0.8599518090486526.pypots
2024-05-22 13:09:31 [INFO]: Epoch 079 - training loss: 0.7753, validation loss: 0.8630
2024-05-22 13:09:31 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch79_loss0.8630387634038925.pypots
2024-05-22 13:09:31 [INFO]: Epoch 080 - training loss: 0.7793, validation loss: 0.8604
2024-05-22 13:09:31 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch80_loss0.8604300618171692.pypots
2024-05-22 13:09:31 [INFO]: Epoch 081 - training loss: 0.7891, validation loss: 0.8588
2024-05-22 13:09:31 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch81_loss0.8587740510702133.pypots
2024-05-22 13:09:31 [INFO]: Epoch 082 - training loss: 0.7736, validation loss: 0.8619
2024-05-22 13:09:31 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch82_loss0.8618832528591156.pypots
2024-05-22 13:09:32 [INFO]: Epoch 083 - training loss: 0.7703, validation loss: 0.8572
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch83_loss0.8571743071079254.pypots
2024-05-22 13:09:32 [INFO]: Epoch 084 - training loss: 0.7939, validation loss: 0.8574
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch84_loss0.8574192523956299.pypots
2024-05-22 13:09:32 [INFO]: Epoch 085 - training loss: 0.7652, validation loss: 0.8564
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch85_loss0.8563853204250336.pypots
2024-05-22 13:09:32 [INFO]: Epoch 086 - training loss: 0.7792, validation loss: 0.8575
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch86_loss0.8574692457914352.pypots
2024-05-22 13:09:32 [INFO]: Epoch 087 - training loss: 0.7545, validation loss: 0.8558
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch87_loss0.8558045029640198.pypots
2024-05-22 13:09:32 [INFO]: Epoch 088 - training loss: 0.7710, validation loss: 0.8575
2024-05-22 13:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch88_loss0.8574805110692978.pypots
2024-05-22 13:09:33 [INFO]: Epoch 089 - training loss: 0.7785, validation loss: 0.8524
2024-05-22 13:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch89_loss0.8523714989423752.pypots
2024-05-22 13:09:33 [INFO]: Epoch 090 - training loss: 0.7673, validation loss: 0.8552
2024-05-22 13:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch90_loss0.855173796415329.pypots
2024-05-22 13:09:33 [INFO]: Epoch 091 - training loss: 0.7778, validation loss: 0.8521
2024-05-22 13:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch91_loss0.8520886898040771.pypots
2024-05-22 13:09:33 [INFO]: Epoch 092 - training loss: 0.7835, validation loss: 0.8561
2024-05-22 13:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch92_loss0.85613152384758.pypots
2024-05-22 13:09:33 [INFO]: Epoch 093 - training loss: 0.8095, validation loss: 0.8537
2024-05-22 13:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch93_loss0.853667363524437.pypots
2024-05-22 13:09:34 [INFO]: Epoch 094 - training loss: 0.7705, validation loss: 0.8510
2024-05-22 13:09:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch94_loss0.8509694337844849.pypots
2024-05-22 13:09:34 [INFO]: Epoch 095 - training loss: 0.7687, validation loss: 0.8513
2024-05-22 13:09:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch95_loss0.8512985408306122.pypots
2024-05-22 13:09:34 [INFO]: Epoch 096 - training loss: 0.7680, validation loss: 0.8508
2024-05-22 13:09:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch96_loss0.850820928812027.pypots
2024-05-22 13:09:34 [INFO]: Epoch 097 - training loss: 0.7756, validation loss: 0.8504
2024-05-22 13:09:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch97_loss0.8503649979829788.pypots
2024-05-22 13:09:34 [INFO]: Epoch 098 - training loss: 0.7728, validation loss: 0.8492
2024-05-22 13:09:34 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch98_loss0.8491672873497009.pypots
2024-05-22 13:09:35 [INFO]: Epoch 099 - training loss: 0.7714, validation loss: 0.8485
2024-05-22 13:09:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch99_loss0.848530724644661.pypots
2024-05-22 13:09:35 [INFO]: Epoch 100 - training loss: 0.7673, validation loss: 0.8493
2024-05-22 13:09:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch100_loss0.849304735660553.pypots
2024-05-22 13:09:35 [INFO]: Epoch 101 - training loss: 0.7820, validation loss: 0.8486
2024-05-22 13:09:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch101_loss0.8486428260803223.pypots
2024-05-22 13:09:35 [INFO]: Epoch 102 - training loss: 0.7713, validation loss: 0.8460
2024-05-22 13:09:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch102_loss0.8459899574518204.pypots
2024-05-22 13:09:35 [INFO]: Epoch 103 - training loss: 0.7566, validation loss: 0.8481
2024-05-22 13:09:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch103_loss0.8481097221374512.pypots
2024-05-22 13:09:36 [INFO]: Epoch 104 - training loss: 0.7580, validation loss: 0.8474
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch104_loss0.8474476486444473.pypots
2024-05-22 13:09:36 [INFO]: Epoch 105 - training loss: 0.7587, validation loss: 0.8448
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch105_loss0.844783365726471.pypots
2024-05-22 13:09:36 [INFO]: Epoch 106 - training loss: 0.7786, validation loss: 0.8479
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch106_loss0.8478758633136749.pypots
2024-05-22 13:09:36 [INFO]: Epoch 107 - training loss: 0.7678, validation loss: 0.8472
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch107_loss0.8472159653902054.pypots
2024-05-22 13:09:36 [INFO]: Epoch 108 - training loss: 0.7807, validation loss: 0.8483
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch108_loss0.8482813537120819.pypots
2024-05-22 13:09:36 [INFO]: Epoch 109 - training loss: 0.7822, validation loss: 0.8459
2024-05-22 13:09:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch109_loss0.8458868265151978.pypots
2024-05-22 13:09:37 [INFO]: Epoch 110 - training loss: 0.7519, validation loss: 0.8412
2024-05-22 13:09:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch110_loss0.8412433564662933.pypots
2024-05-22 13:09:37 [INFO]: Epoch 111 - training loss: 0.7539, validation loss: 0.8462
2024-05-22 13:09:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch111_loss0.846197634935379.pypots
2024-05-22 13:09:37 [INFO]: Epoch 112 - training loss: 0.7770, validation loss: 0.8405
2024-05-22 13:09:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch112_loss0.8404956459999084.pypots
2024-05-22 13:09:37 [INFO]: Epoch 113 - training loss: 0.7837, validation loss: 0.8445
2024-05-22 13:09:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch113_loss0.8444799035787582.pypots
2024-05-22 13:09:37 [INFO]: Epoch 114 - training loss: 0.7692, validation loss: 0.8441
2024-05-22 13:09:37 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch114_loss0.8440858572721481.pypots
2024-05-22 13:09:38 [INFO]: Epoch 115 - training loss: 0.7501, validation loss: 0.8403
2024-05-22 13:09:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch115_loss0.8402744382619858.pypots
2024-05-22 13:09:38 [INFO]: Epoch 116 - training loss: 0.7462, validation loss: 0.8454
2024-05-22 13:09:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch116_loss0.8453590124845505.pypots
2024-05-22 13:09:38 [INFO]: Epoch 117 - training loss: 0.7813, validation loss: 0.8404
2024-05-22 13:09:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch117_loss0.8404321223497391.pypots
2024-05-22 13:09:38 [INFO]: Epoch 118 - training loss: 0.7755, validation loss: 0.8418
2024-05-22 13:09:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch118_loss0.8418120294809341.pypots
2024-05-22 13:09:38 [INFO]: Epoch 119 - training loss: 0.7664, validation loss: 0.8424
2024-05-22 13:09:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch119_loss0.8424305468797684.pypots
2024-05-22 13:09:39 [INFO]: Epoch 120 - training loss: 0.7657, validation loss: 0.8392
2024-05-22 13:09:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch120_loss0.8391962051391602.pypots
2024-05-22 13:09:39 [INFO]: Epoch 121 - training loss: 0.7608, validation loss: 0.8429
2024-05-22 13:09:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch121_loss0.8429199308156967.pypots
2024-05-22 13:09:39 [INFO]: Epoch 122 - training loss: 0.7638, validation loss: 0.8416
2024-05-22 13:09:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch122_loss0.8416476398706436.pypots
2024-05-22 13:09:39 [INFO]: Epoch 123 - training loss: 0.7699, validation loss: 0.8414
2024-05-22 13:09:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch123_loss0.8413549661636353.pypots
2024-05-22 13:09:39 [INFO]: Epoch 124 - training loss: 0.7617, validation loss: 0.8386
2024-05-22 13:09:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch124_loss0.8385864645242691.pypots
2024-05-22 13:09:40 [INFO]: Epoch 125 - training loss: 0.7863, validation loss: 0.8437
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch125_loss0.8437007069587708.pypots
2024-05-22 13:09:40 [INFO]: Epoch 126 - training loss: 0.7604, validation loss: 0.8386
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch126_loss0.8386058807373047.pypots
2024-05-22 13:09:40 [INFO]: Epoch 127 - training loss: 0.7691, validation loss: 0.8358
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch127_loss0.8358386754989624.pypots
2024-05-22 13:09:40 [INFO]: Epoch 128 - training loss: 0.7802, validation loss: 0.8398
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch128_loss0.8397615402936935.pypots
2024-05-22 13:09:40 [INFO]: Epoch 129 - training loss: 0.7537, validation loss: 0.8401
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch129_loss0.8400860130786896.pypots
2024-05-22 13:09:40 [INFO]: Epoch 130 - training loss: 0.7819, validation loss: 0.8368
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch130_loss0.8367540091276169.pypots
2024-05-22 13:09:41 [INFO]: Epoch 131 - training loss: 0.7780, validation loss: 0.8359
2024-05-22 13:09:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch131_loss0.8359139114618301.pypots
2024-05-22 13:09:41 [INFO]: Epoch 132 - training loss: 0.7859, validation loss: 0.8353
2024-05-22 13:09:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch132_loss0.8352937549352646.pypots
2024-05-22 13:09:41 [INFO]: Epoch 133 - training loss: 0.8003, validation loss: 0.8375
2024-05-22 13:09:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch133_loss0.8374584466218948.pypots
2024-05-22 13:09:41 [INFO]: Epoch 134 - training loss: 0.7592, validation loss: 0.8393
2024-05-22 13:09:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch134_loss0.8392656147480011.pypots
2024-05-22 13:09:41 [INFO]: Epoch 135 - training loss: 0.8022, validation loss: 0.8352
2024-05-22 13:09:41 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch135_loss0.8351880759000778.pypots
2024-05-22 13:09:42 [INFO]: Epoch 136 - training loss: 0.7674, validation loss: 0.8335
2024-05-22 13:09:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch136_loss0.8335356116294861.pypots
2024-05-22 13:09:42 [INFO]: Epoch 137 - training loss: 0.7620, validation loss: 0.8347
2024-05-22 13:09:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch137_loss0.8347017019987106.pypots
2024-05-22 13:09:42 [INFO]: Epoch 138 - training loss: 0.7564, validation loss: 0.8341
2024-05-22 13:09:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch138_loss0.8340985327959061.pypots
2024-05-22 13:09:42 [INFO]: Epoch 139 - training loss: 0.7610, validation loss: 0.8361
2024-05-22 13:09:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch139_loss0.836099311709404.pypots
2024-05-22 13:09:42 [INFO]: Epoch 140 - training loss: 0.7659, validation loss: 0.8322
2024-05-22 13:09:42 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch140_loss0.8321672677993774.pypots
2024-05-22 13:09:43 [INFO]: Epoch 141 - training loss: 0.7526, validation loss: 0.8356
2024-05-22 13:09:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch141_loss0.8356007486581802.pypots
2024-05-22 13:09:43 [INFO]: Epoch 142 - training loss: 0.7635, validation loss: 0.8345
2024-05-22 13:09:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch142_loss0.8344942480325699.pypots
2024-05-22 13:09:43 [INFO]: Epoch 143 - training loss: 0.7609, validation loss: 0.8355
2024-05-22 13:09:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch143_loss0.8354949802160263.pypots
2024-05-22 13:09:43 [INFO]: Epoch 144 - training loss: 0.7952, validation loss: 0.8347
2024-05-22 13:09:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch144_loss0.834650069475174.pypots
2024-05-22 13:09:43 [INFO]: Epoch 145 - training loss: 0.7618, validation loss: 0.8318
2024-05-22 13:09:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch145_loss0.8317946344614029.pypots
2024-05-22 13:09:44 [INFO]: Epoch 146 - training loss: 0.7520, validation loss: 0.8298
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch146_loss0.8297720402479172.pypots
2024-05-22 13:09:44 [INFO]: Epoch 147 - training loss: 0.7595, validation loss: 0.8320
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch147_loss0.8320252746343613.pypots
2024-05-22 13:09:44 [INFO]: Epoch 148 - training loss: 0.7642, validation loss: 0.8291
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch148_loss0.8291118890047073.pypots
2024-05-22 13:09:44 [INFO]: Epoch 149 - training loss: 0.7548, validation loss: 0.8334
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch149_loss0.8333909809589386.pypots
2024-05-22 13:09:44 [INFO]: Epoch 150 - training loss: 0.7516, validation loss: 0.8338
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch150_loss0.83384570479393.pypots
2024-05-22 13:09:44 [INFO]: Epoch 151 - training loss: 0.7586, validation loss: 0.8324
2024-05-22 13:09:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch151_loss0.8324074447154999.pypots
2024-05-22 13:09:45 [INFO]: Epoch 152 - training loss: 0.7568, validation loss: 0.8338
2024-05-22 13:09:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch152_loss0.8337801545858383.pypots
2024-05-22 13:09:45 [INFO]: Epoch 153 - training loss: 0.7895, validation loss: 0.8291
2024-05-22 13:09:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch153_loss0.8290610760450363.pypots
2024-05-22 13:09:45 [INFO]: Epoch 154 - training loss: 0.7638, validation loss: 0.8309
2024-05-22 13:09:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch154_loss0.8308560252189636.pypots
2024-05-22 13:09:45 [INFO]: Epoch 155 - training loss: 0.7482, validation loss: 0.8302
2024-05-22 13:09:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch155_loss0.8301571160554886.pypots
2024-05-22 13:09:45 [INFO]: Epoch 156 - training loss: 0.7574, validation loss: 0.8259
2024-05-22 13:09:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch156_loss0.8259065449237823.pypots
2024-05-22 13:09:46 [INFO]: Epoch 157 - training loss: 0.7699, validation loss: 0.8300
2024-05-22 13:09:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch157_loss0.8300224840641022.pypots
2024-05-22 13:09:46 [INFO]: Epoch 158 - training loss: 0.7586, validation loss: 0.8278
2024-05-22 13:09:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch158_loss0.8278295695781708.pypots
2024-05-22 13:09:46 [INFO]: Epoch 159 - training loss: 0.7595, validation loss: 0.8309
2024-05-22 13:09:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch159_loss0.8308895379304886.pypots
2024-05-22 13:09:46 [INFO]: Epoch 160 - training loss: 0.7398, validation loss: 0.8307
2024-05-22 13:09:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch160_loss0.8307215869426727.pypots
2024-05-22 13:09:46 [INFO]: Epoch 161 - training loss: 0.7619, validation loss: 0.8343
2024-05-22 13:09:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch161_loss0.8343234062194824.pypots
2024-05-22 13:09:47 [INFO]: Epoch 162 - training loss: 0.7450, validation loss: 0.8254
2024-05-22 13:09:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch162_loss0.8253600299358368.pypots
2024-05-22 13:09:47 [INFO]: Epoch 163 - training loss: 0.7356, validation loss: 0.8288
2024-05-22 13:09:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch163_loss0.8288256973028183.pypots
2024-05-22 13:09:47 [INFO]: Epoch 164 - training loss: 0.7709, validation loss: 0.8299
2024-05-22 13:09:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch164_loss0.8298807591199875.pypots
2024-05-22 13:09:47 [INFO]: Epoch 165 - training loss: 0.7427, validation loss: 0.8264
2024-05-22 13:09:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch165_loss0.8264463543891907.pypots
2024-05-22 13:09:47 [INFO]: Epoch 166 - training loss: 0.7565, validation loss: 0.8299
2024-05-22 13:09:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch166_loss0.8299051821231842.pypots
2024-05-22 13:09:48 [INFO]: Epoch 167 - training loss: 0.7618, validation loss: 0.8281
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch167_loss0.8280510008335114.pypots
2024-05-22 13:09:48 [INFO]: Epoch 168 - training loss: 0.7501, validation loss: 0.8254
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch168_loss0.8254330605268478.pypots
2024-05-22 13:09:48 [INFO]: Epoch 169 - training loss: 0.8066, validation loss: 0.8271
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch169_loss0.8270534127950668.pypots
2024-05-22 13:09:48 [INFO]: Epoch 170 - training loss: 0.8088, validation loss: 0.8294
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch170_loss0.8293847888708115.pypots
2024-05-22 13:09:48 [INFO]: Epoch 171 - training loss: 0.7502, validation loss: 0.8317
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch171_loss0.8316522389650345.pypots
2024-05-22 13:09:48 [INFO]: Epoch 172 - training loss: 0.7772, validation loss: 0.8268
2024-05-22 13:09:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN_epoch172_loss0.8268218785524368.pypots
2024-05-22 13:09:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:09:48 [INFO]: Finished training. The best model is from epoch#162.
2024-05-22 13:09:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240522_T130914/MRNN.pypots
2024-05-22 13:09:49 [INFO]: MRNN on ETTm1: MAE=0.6181, MSE=1.0216
2024-05-22 13:09:49 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-22 13:09:49 [INFO]: Using the given device: cpu
2024-05-22 13:09:49 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 13:09:49 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-22 13:09:49 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-22 13:09:49 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 13:09:49 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-22 13:09:49 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-22 13:09:49 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 13:09:49 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-22 13:09:49 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-22 13:09:49 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 13:09:49 [INFO]: Using the given device: cuda:0
2024-05-22 13:09:49 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240522_T130949
2024-05-22 13:09:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240522_T130949/tensorboard
2024-05-22 13:09:49 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 13:09:50 [INFO]: Epoch 001 - training loss: 1.2098, validation loss: 0.3241
2024-05-22 13:09:50 [INFO]: Epoch 002 - training loss: 0.8997, validation loss: 0.1621
2024-05-22 13:09:51 [INFO]: Epoch 003 - training loss: 0.7691, validation loss: 0.1154
2024-05-22 13:09:51 [INFO]: Epoch 004 - training loss: 0.7109, validation loss: 0.1227
2024-05-22 13:09:52 [INFO]: Epoch 005 - training loss: 0.6777, validation loss: 0.0749
2024-05-22 13:09:52 [INFO]: Epoch 006 - training loss: 0.6610, validation loss: 0.0944
2024-05-22 13:09:53 [INFO]: Epoch 007 - training loss: 0.6533, validation loss: 0.0816
2024-05-22 13:09:53 [INFO]: Epoch 008 - training loss: 0.6234, validation loss: 0.0907
2024-05-22 13:09:54 [INFO]: Epoch 009 - training loss: 0.6106, validation loss: 0.0774
2024-05-22 13:09:54 [INFO]: Epoch 010 - training loss: 0.6060, validation loss: 0.1040
2024-05-22 13:09:55 [INFO]: Epoch 011 - training loss: 0.5975, validation loss: 0.0870
2024-05-22 13:09:55 [INFO]: Epoch 012 - training loss: 0.5770, validation loss: 0.0796
2024-05-22 13:09:56 [INFO]: Epoch 013 - training loss: 0.5720, validation loss: 0.0521
2024-05-22 13:09:56 [INFO]: Epoch 014 - training loss: 0.5661, validation loss: 0.0781
2024-05-22 13:09:57 [INFO]: Epoch 015 - training loss: 0.5590, validation loss: 0.0559
2024-05-22 13:09:57 [INFO]: Epoch 016 - training loss: 0.5523, validation loss: 0.0582
2024-05-22 13:09:58 [INFO]: Epoch 017 - training loss: 0.5480, validation loss: 0.0630
2024-05-22 13:09:58 [INFO]: Epoch 018 - training loss: 0.5553, validation loss: 0.0578
2024-05-22 13:09:59 [INFO]: Epoch 019 - training loss: 0.5319, validation loss: 0.0503
2024-05-22 13:09:59 [INFO]: Epoch 020 - training loss: 0.5472, validation loss: 0.0634
2024-05-22 13:10:00 [INFO]: Epoch 021 - training loss: 0.5464, validation loss: 0.0658
2024-05-22 13:10:00 [INFO]: Epoch 022 - training loss: 0.5209, validation loss: 0.0518
2024-05-22 13:10:01 [INFO]: Epoch 023 - training loss: 0.5118, validation loss: 0.0600
2024-05-22 13:10:01 [INFO]: Epoch 024 - training loss: 0.5150, validation loss: 0.0542
2024-05-22 13:10:02 [INFO]: Epoch 025 - training loss: 0.5031, validation loss: 0.0464
2024-05-22 13:10:02 [INFO]: Epoch 026 - training loss: 0.4985, validation loss: 0.0550
2024-05-22 13:10:03 [INFO]: Epoch 027 - training loss: 0.4895, validation loss: 0.0393
2024-05-22 13:10:03 [INFO]: Epoch 028 - training loss: 0.4882, validation loss: 0.0489
2024-05-22 13:10:04 [INFO]: Epoch 029 - training loss: 0.4825, validation loss: 0.0437
2024-05-22 13:10:04 [INFO]: Epoch 030 - training loss: 0.5069, validation loss: 0.0523
2024-05-22 13:10:05 [INFO]: Epoch 031 - training loss: 0.4961, validation loss: 0.0413
2024-05-22 13:10:05 [INFO]: Epoch 032 - training loss: 0.4843, validation loss: 0.0438
2024-05-22 13:10:06 [INFO]: Epoch 033 - training loss: 0.4843, validation loss: 0.0468
2024-05-22 13:10:06 [INFO]: Epoch 034 - training loss: 0.4734, validation loss: 0.0400
2024-05-22 13:10:07 [INFO]: Epoch 035 - training loss: 0.4671, validation loss: 0.0465
2024-05-22 13:10:07 [INFO]: Epoch 036 - training loss: 0.4639, validation loss: 0.0371
2024-05-22 13:10:08 [INFO]: Epoch 037 - training loss: 0.4507, validation loss: 0.0436
2024-05-22 13:10:09 [INFO]: Epoch 038 - training loss: 0.4562, validation loss: 0.0441
2024-05-22 13:10:09 [INFO]: Epoch 039 - training loss: 0.4449, validation loss: 0.0433
2024-05-22 13:10:10 [INFO]: Epoch 040 - training loss: 0.4482, validation loss: 0.0476
2024-05-22 13:10:10 [INFO]: Epoch 041 - training loss: 0.4454, validation loss: 0.0375
2024-05-22 13:10:11 [INFO]: Epoch 042 - training loss: 0.4421, validation loss: 0.0335
2024-05-22 13:10:11 [INFO]: Epoch 043 - training loss: 0.4469, validation loss: 0.0444
2024-05-22 13:10:12 [INFO]: Epoch 044 - training loss: 0.4352, validation loss: 0.0346
2024-05-22 13:10:12 [INFO]: Epoch 045 - training loss: 0.4379, validation loss: 0.0431
2024-05-22 13:10:13 [INFO]: Epoch 046 - training loss: 0.4379, validation loss: 0.0423
2024-05-22 13:10:13 [INFO]: Epoch 047 - training loss: 0.4352, validation loss: 0.0326
2024-05-22 13:10:14 [INFO]: Epoch 048 - training loss: 0.4324, validation loss: 0.0296
2024-05-22 13:10:14 [INFO]: Epoch 049 - training loss: 0.4302, validation loss: 0.0338
2024-05-22 13:10:15 [INFO]: Epoch 050 - training loss: 0.4257, validation loss: 0.0374
2024-05-22 13:10:15 [INFO]: Epoch 051 - training loss: 0.4228, validation loss: 0.0383
2024-05-22 13:10:16 [INFO]: Epoch 052 - training loss: 0.4220, validation loss: 0.0346
2024-05-22 13:10:16 [INFO]: Epoch 053 - training loss: 0.4092, validation loss: 0.0317
2024-05-22 13:10:17 [INFO]: Epoch 054 - training loss: 0.4047, validation loss: 0.0310
2024-05-22 13:10:17 [INFO]: Epoch 055 - training loss: 0.4019, validation loss: 0.0293
2024-05-22 13:10:18 [INFO]: Epoch 056 - training loss: 0.4189, validation loss: 0.0498
2024-05-22 13:10:18 [INFO]: Epoch 057 - training loss: 0.4122, validation loss: 0.0362
2024-05-22 13:10:19 [INFO]: Epoch 058 - training loss: 0.4076, validation loss: 0.0393
2024-05-22 13:10:19 [INFO]: Epoch 059 - training loss: 0.4038, validation loss: 0.0314
2024-05-22 13:10:20 [INFO]: Epoch 060 - training loss: 0.3967, validation loss: 0.0378
2024-05-22 13:10:20 [INFO]: Epoch 061 - training loss: 0.3935, validation loss: 0.0258
2024-05-22 13:10:21 [INFO]: Epoch 062 - training loss: 0.3974, validation loss: 0.0278
2024-05-22 13:10:21 [INFO]: Epoch 063 - training loss: 0.3817, validation loss: 0.0288
2024-05-22 13:10:22 [INFO]: Epoch 064 - training loss: 0.3746, validation loss: 0.0358
2024-05-22 13:10:22 [INFO]: Epoch 065 - training loss: 0.3738, validation loss: 0.0295
2024-05-22 13:10:23 [INFO]: Epoch 066 - training loss: 0.3510, validation loss: 0.0269
2024-05-22 13:10:23 [INFO]: Epoch 067 - training loss: 0.3472, validation loss: 0.0289
2024-05-22 13:10:24 [INFO]: Epoch 068 - training loss: 0.3464, validation loss: 0.0312
2024-05-22 13:10:24 [INFO]: Epoch 069 - training loss: 0.3331, validation loss: 0.0314
2024-05-22 13:10:25 [INFO]: Epoch 070 - training loss: 0.3364, validation loss: 0.0296
2024-05-22 13:10:25 [INFO]: Epoch 071 - training loss: 0.3392, validation loss: 0.0290
2024-05-22 13:10:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:10:25 [INFO]: Finished training. The best model is from epoch#61.
2024-05-22 13:10:25 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_ettm1/20240522_T130949/SAITS.pypots
2024-05-22 13:10:25 [INFO]: SAITS on ETTm1: MAE=0.1491, MSE=0.0406
2024-05-22 13:10:25 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-22 13:10:25 [INFO]: Using the given device: cuda:0
2024-05-22 13:10:25 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240522_T131025
2024-05-22 13:10:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240522_T131025/tensorboard
2024-05-22 13:10:26 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 13:10:26 [INFO]: Epoch 001 - training loss: 1.2260, validation loss: 0.3427
2024-05-22 13:10:26 [INFO]: Epoch 002 - training loss: 0.7426, validation loss: 0.1603
2024-05-22 13:10:26 [INFO]: Epoch 003 - training loss: 0.6105, validation loss: 0.1150
2024-05-22 13:10:26 [INFO]: Epoch 004 - training loss: 0.5493, validation loss: 0.0936
2024-05-22 13:10:27 [INFO]: Epoch 005 - training loss: 0.5002, validation loss: 0.0796
2024-05-22 13:10:27 [INFO]: Epoch 006 - training loss: 0.4701, validation loss: 0.0737
2024-05-22 13:10:27 [INFO]: Epoch 007 - training loss: 0.4446, validation loss: 0.0659
2024-05-22 13:10:27 [INFO]: Epoch 008 - training loss: 0.4330, validation loss: 0.0684
2024-05-22 13:10:27 [INFO]: Epoch 009 - training loss: 0.4179, validation loss: 0.0658
2024-05-22 13:10:28 [INFO]: Epoch 010 - training loss: 0.4024, validation loss: 0.0560
2024-05-22 13:10:28 [INFO]: Epoch 011 - training loss: 0.3858, validation loss: 0.0602
2024-05-22 13:10:28 [INFO]: Epoch 012 - training loss: 0.3821, validation loss: 0.0540
2024-05-22 13:10:28 [INFO]: Epoch 013 - training loss: 0.3785, validation loss: 0.0575
2024-05-22 13:10:29 [INFO]: Epoch 014 - training loss: 0.3677, validation loss: 0.0474
2024-05-22 13:10:29 [INFO]: Epoch 015 - training loss: 0.3700, validation loss: 0.0506
2024-05-22 13:10:29 [INFO]: Epoch 016 - training loss: 0.3609, validation loss: 0.0553
2024-05-22 13:10:29 [INFO]: Epoch 017 - training loss: 0.3444, validation loss: 0.0525
2024-05-22 13:10:29 [INFO]: Epoch 018 - training loss: 0.3502, validation loss: 0.0445
2024-05-22 13:10:30 [INFO]: Epoch 019 - training loss: 0.3310, validation loss: 0.0398
2024-05-22 13:10:30 [INFO]: Epoch 020 - training loss: 0.3245, validation loss: 0.0445
2024-05-22 13:10:30 [INFO]: Epoch 021 - training loss: 0.3243, validation loss: 0.0409
2024-05-22 13:10:30 [INFO]: Epoch 022 - training loss: 0.3308, validation loss: 0.0424
2024-05-22 13:10:31 [INFO]: Epoch 023 - training loss: 0.3251, validation loss: 0.0379
2024-05-22 13:10:31 [INFO]: Epoch 024 - training loss: 0.3163, validation loss: 0.0398
2024-05-22 13:10:31 [INFO]: Epoch 025 - training loss: 0.3102, validation loss: 0.0354
2024-05-22 13:10:31 [INFO]: Epoch 026 - training loss: 0.3046, validation loss: 0.0357
2024-05-22 13:10:31 [INFO]: Epoch 027 - training loss: 0.2988, validation loss: 0.0386
2024-05-22 13:10:32 [INFO]: Epoch 028 - training loss: 0.3032, validation loss: 0.0468
2024-05-22 13:10:32 [INFO]: Epoch 029 - training loss: 0.3073, validation loss: 0.0379
2024-05-22 13:10:32 [INFO]: Epoch 030 - training loss: 0.2968, validation loss: 0.0399
2024-05-22 13:10:32 [INFO]: Epoch 031 - training loss: 0.2919, validation loss: 0.0341
2024-05-22 13:10:32 [INFO]: Epoch 032 - training loss: 0.2850, validation loss: 0.0321
2024-05-22 13:10:33 [INFO]: Epoch 033 - training loss: 0.2800, validation loss: 0.0356
2024-05-22 13:10:33 [INFO]: Epoch 034 - training loss: 0.2805, validation loss: 0.0360
2024-05-22 13:10:33 [INFO]: Epoch 035 - training loss: 0.2750, validation loss: 0.0321
2024-05-22 13:10:33 [INFO]: Epoch 036 - training loss: 0.2813, validation loss: 0.0319
2024-05-22 13:10:34 [INFO]: Epoch 037 - training loss: 0.2721, validation loss: 0.0336
2024-05-22 13:10:34 [INFO]: Epoch 038 - training loss: 0.2741, validation loss: 0.0305
2024-05-22 13:10:34 [INFO]: Epoch 039 - training loss: 0.2739, validation loss: 0.0292
2024-05-22 13:10:34 [INFO]: Epoch 040 - training loss: 0.2682, validation loss: 0.0295
2024-05-22 13:10:34 [INFO]: Epoch 041 - training loss: 0.2587, validation loss: 0.0304
2024-05-22 13:10:35 [INFO]: Epoch 042 - training loss: 0.2597, validation loss: 0.0329
2024-05-22 13:10:35 [INFO]: Epoch 043 - training loss: 0.2599, validation loss: 0.0302
2024-05-22 13:10:35 [INFO]: Epoch 044 - training loss: 0.2579, validation loss: 0.0299
2024-05-22 13:10:35 [INFO]: Epoch 045 - training loss: 0.2533, validation loss: 0.0277
2024-05-22 13:10:36 [INFO]: Epoch 046 - training loss: 0.2524, validation loss: 0.0276
2024-05-22 13:10:36 [INFO]: Epoch 047 - training loss: 0.2463, validation loss: 0.0309
2024-05-22 13:10:36 [INFO]: Epoch 048 - training loss: 0.2472, validation loss: 0.0280
2024-05-22 13:10:36 [INFO]: Epoch 049 - training loss: 0.2434, validation loss: 0.0268
2024-05-22 13:10:36 [INFO]: Epoch 050 - training loss: 0.2437, validation loss: 0.0339
2024-05-22 13:10:37 [INFO]: Epoch 051 - training loss: 0.2474, validation loss: 0.0273
2024-05-22 13:10:37 [INFO]: Epoch 052 - training loss: 0.2353, validation loss: 0.0301
2024-05-22 13:10:37 [INFO]: Epoch 053 - training loss: 0.2376, validation loss: 0.0266
2024-05-22 13:10:37 [INFO]: Epoch 054 - training loss: 0.2405, validation loss: 0.0337
2024-05-22 13:10:37 [INFO]: Epoch 055 - training loss: 0.2365, validation loss: 0.0261
2024-05-22 13:10:38 [INFO]: Epoch 056 - training loss: 0.2357, validation loss: 0.0261
2024-05-22 13:10:38 [INFO]: Epoch 057 - training loss: 0.2374, validation loss: 0.0275
2024-05-22 13:10:38 [INFO]: Epoch 058 - training loss: 0.2306, validation loss: 0.0307
2024-05-22 13:10:38 [INFO]: Epoch 059 - training loss: 0.2439, validation loss: 0.0269
2024-05-22 13:10:39 [INFO]: Epoch 060 - training loss: 0.2351, validation loss: 0.0318
2024-05-22 13:10:39 [INFO]: Epoch 061 - training loss: 0.2407, validation loss: 0.0269
2024-05-22 13:10:39 [INFO]: Epoch 062 - training loss: 0.2297, validation loss: 0.0333
2024-05-22 13:10:39 [INFO]: Epoch 063 - training loss: 0.2301, validation loss: 0.0266
2024-05-22 13:10:39 [INFO]: Epoch 064 - training loss: 0.2244, validation loss: 0.0268
2024-05-22 13:10:40 [INFO]: Epoch 065 - training loss: 0.2234, validation loss: 0.0258
2024-05-22 13:10:40 [INFO]: Epoch 066 - training loss: 0.2195, validation loss: 0.0258
2024-05-22 13:10:40 [INFO]: Epoch 067 - training loss: 0.2144, validation loss: 0.0292
2024-05-22 13:10:40 [INFO]: Epoch 068 - training loss: 0.2193, validation loss: 0.0256
2024-05-22 13:10:41 [INFO]: Epoch 069 - training loss: 0.2179, validation loss: 0.0279
2024-05-22 13:10:41 [INFO]: Epoch 070 - training loss: 0.2241, validation loss: 0.0308
2024-05-22 13:10:41 [INFO]: Epoch 071 - training loss: 0.2295, validation loss: 0.0258
2024-05-22 13:10:41 [INFO]: Epoch 072 - training loss: 0.2220, validation loss: 0.0267
2024-05-22 13:10:41 [INFO]: Epoch 073 - training loss: 0.2169, validation loss: 0.0274
2024-05-22 13:10:42 [INFO]: Epoch 074 - training loss: 0.2154, validation loss: 0.0247
2024-05-22 13:10:42 [INFO]: Epoch 075 - training loss: 0.2138, validation loss: 0.0245
2024-05-22 13:10:42 [INFO]: Epoch 076 - training loss: 0.2117, validation loss: 0.0260
2024-05-22 13:10:42 [INFO]: Epoch 077 - training loss: 0.2119, validation loss: 0.0254
2024-05-22 13:10:42 [INFO]: Epoch 078 - training loss: 0.2177, validation loss: 0.0248
2024-05-22 13:10:43 [INFO]: Epoch 079 - training loss: 0.2130, validation loss: 0.0260
2024-05-22 13:10:43 [INFO]: Epoch 080 - training loss: 0.2104, validation loss: 0.0305
2024-05-22 13:10:43 [INFO]: Epoch 081 - training loss: 0.2120, validation loss: 0.0260
2024-05-22 13:10:43 [INFO]: Epoch 082 - training loss: 0.2085, validation loss: 0.0266
2024-05-22 13:10:44 [INFO]: Epoch 083 - training loss: 0.2118, validation loss: 0.0248
2024-05-22 13:10:44 [INFO]: Epoch 084 - training loss: 0.2044, validation loss: 0.0272
2024-05-22 13:10:44 [INFO]: Epoch 085 - training loss: 0.2102, validation loss: 0.0246
2024-05-22 13:10:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:10:44 [INFO]: Finished training. The best model is from epoch#75.
2024-05-22 13:10:44 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_ettm1/20240522_T131025/Transformer.pypots
2024-05-22 13:10:44 [INFO]: Transformer on ETTm1: MAE=0.1275, MSE=0.0311
2024-05-22 13:10:44 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-22 13:10:44 [INFO]: Using the given device: cuda:0
2024-05-22 13:10:44 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240522_T131044
2024-05-22 13:10:44 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240522_T131044/tensorboard
2024-05-22 13:10:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 13:10:44 [INFO]: Epoch 001 - training loss: 0.1416, validation loss: 0.0494
2024-05-22 13:10:45 [INFO]: Epoch 002 - training loss: 0.0637, validation loss: 0.0401
2024-05-22 13:10:45 [INFO]: Epoch 003 - training loss: 0.0545, validation loss: 0.0339
2024-05-22 13:10:45 [INFO]: Epoch 004 - training loss: 0.0540, validation loss: 0.0438
2024-05-22 13:10:45 [INFO]: Epoch 005 - training loss: 0.0596, validation loss: 0.0397
2024-05-22 13:10:46 [INFO]: Epoch 006 - training loss: 0.0492, validation loss: 0.0328
2024-05-22 13:10:46 [INFO]: Epoch 007 - training loss: 0.0458, validation loss: 0.0321
2024-05-22 13:10:46 [INFO]: Epoch 008 - training loss: 0.0466, validation loss: 0.0330
2024-05-22 13:10:46 [INFO]: Epoch 009 - training loss: 0.0448, validation loss: 0.0315
2024-05-22 13:10:46 [INFO]: Epoch 010 - training loss: 0.0466, validation loss: 0.0325
2024-05-22 13:10:47 [INFO]: Epoch 011 - training loss: 0.0481, validation loss: 0.0339
2024-05-22 13:10:47 [INFO]: Epoch 012 - training loss: 0.0472, validation loss: 0.0311
2024-05-22 13:10:47 [INFO]: Epoch 013 - training loss: 0.0455, validation loss: 0.0325
2024-05-22 13:10:47 [INFO]: Epoch 014 - training loss: 0.0449, validation loss: 0.0344
2024-05-22 13:10:47 [INFO]: Epoch 015 - training loss: 0.0451, validation loss: 0.0318
2024-05-22 13:10:48 [INFO]: Epoch 016 - training loss: 0.0446, validation loss: 0.0323
2024-05-22 13:10:48 [INFO]: Epoch 017 - training loss: 0.0434, validation loss: 0.0352
2024-05-22 13:10:48 [INFO]: Epoch 018 - training loss: 0.0449, validation loss: 0.0352
2024-05-22 13:10:48 [INFO]: Epoch 019 - training loss: 0.0478, validation loss: 0.0324
2024-05-22 13:10:49 [INFO]: Epoch 020 - training loss: 0.0436, validation loss: 0.0309
2024-05-22 13:10:49 [INFO]: Epoch 021 - training loss: 0.0408, validation loss: 0.0282
2024-05-22 13:10:49 [INFO]: Epoch 022 - training loss: 0.0457, validation loss: 0.0344
2024-05-22 13:10:49 [INFO]: Epoch 023 - training loss: 0.0471, validation loss: 0.0335
2024-05-22 13:10:49 [INFO]: Epoch 024 - training loss: 0.0409, validation loss: 0.0305
2024-05-22 13:10:50 [INFO]: Epoch 025 - training loss: 0.0397, validation loss: 0.0273
2024-05-22 13:10:50 [INFO]: Epoch 026 - training loss: 0.0421, validation loss: 0.0330
2024-05-22 13:10:50 [INFO]: Epoch 027 - training loss: 0.0453, validation loss: 0.0278
2024-05-22 13:10:50 [INFO]: Epoch 028 - training loss: 0.0429, validation loss: 0.0316
2024-05-22 13:10:50 [INFO]: Epoch 029 - training loss: 0.0419, validation loss: 0.0303
2024-05-22 13:10:51 [INFO]: Epoch 030 - training loss: 0.0406, validation loss: 0.0300
2024-05-22 13:10:51 [INFO]: Epoch 031 - training loss: 0.0382, validation loss: 0.0280
2024-05-22 13:10:51 [INFO]: Epoch 032 - training loss: 0.0382, validation loss: 0.0278
2024-05-22 13:10:51 [INFO]: Epoch 033 - training loss: 0.0379, validation loss: 0.0288
2024-05-22 13:10:51 [INFO]: Epoch 034 - training loss: 0.0363, validation loss: 0.0318
2024-05-22 13:10:52 [INFO]: Epoch 035 - training loss: 0.0392, validation loss: 0.0296
2024-05-22 13:10:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:10:52 [INFO]: Finished training. The best model is from epoch#25.
2024-05-22 13:10:52 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_ettm1/20240522_T131044/TimesNet.pypots
2024-05-22 13:10:52 [INFO]: TimesNet on ETTm1: MAE=0.1232, MSE=0.0312
2024-05-22 13:10:52 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-22 13:10:52 [INFO]: Using the given device: cuda:0
2024-05-22 13:10:52 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052
2024-05-22 13:10:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/tensorboard
2024-05-22 13:10:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 13:10:54 [INFO]: Epoch 001 - training loss: 0.7030, validation loss: 0.5226
2024-05-22 13:10:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch1_loss0.5225813910365105.pypots
2024-05-22 13:10:56 [INFO]: Epoch 002 - training loss: 0.4210, validation loss: 0.4159
2024-05-22 13:10:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch2_loss0.4159076064825058.pypots
2024-05-22 13:10:58 [INFO]: Epoch 003 - training loss: 0.4071, validation loss: 0.3487
2024-05-22 13:10:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch3_loss0.34870337694883347.pypots
2024-05-22 13:11:00 [INFO]: Epoch 004 - training loss: 0.3843, validation loss: 0.3234
2024-05-22 13:11:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch4_loss0.3234403058886528.pypots
2024-05-22 13:11:02 [INFO]: Epoch 005 - training loss: 0.2821, validation loss: 0.3167
2024-05-22 13:11:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch5_loss0.31667398661375046.pypots
2024-05-22 13:11:04 [INFO]: Epoch 006 - training loss: 0.2445, validation loss: 0.2824
2024-05-22 13:11:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch6_loss0.28243882954120636.pypots
2024-05-22 13:11:06 [INFO]: Epoch 007 - training loss: 0.2789, validation loss: 0.2754
2024-05-22 13:11:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch7_loss0.275357685983181.pypots
2024-05-22 13:11:08 [INFO]: Epoch 008 - training loss: 0.2702, validation loss: 0.2875
2024-05-22 13:11:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch8_loss0.28753795474767685.pypots
2024-05-22 13:11:11 [INFO]: Epoch 009 - training loss: 0.2515, validation loss: 0.2570
2024-05-22 13:11:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch9_loss0.25696998834609985.pypots
2024-05-22 13:11:13 [INFO]: Epoch 010 - training loss: 0.2710, validation loss: 0.2759
2024-05-22 13:11:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch10_loss0.2759220153093338.pypots
2024-05-22 13:11:15 [INFO]: Epoch 011 - training loss: 0.3157, validation loss: 0.2537
2024-05-22 13:11:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch11_loss0.2536681406199932.pypots
2024-05-22 13:11:17 [INFO]: Epoch 012 - training loss: 0.2391, validation loss: 0.2524
2024-05-22 13:11:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch12_loss0.25239770486950874.pypots
2024-05-22 13:11:19 [INFO]: Epoch 013 - training loss: 0.2274, validation loss: 0.2281
2024-05-22 13:11:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch13_loss0.2280597910284996.pypots
2024-05-22 13:11:21 [INFO]: Epoch 014 - training loss: 0.2167, validation loss: 0.2178
2024-05-22 13:11:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch14_loss0.21784862875938416.pypots
2024-05-22 13:11:23 [INFO]: Epoch 015 - training loss: 0.1997, validation loss: 0.2156
2024-05-22 13:11:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch15_loss0.21561682224273682.pypots
2024-05-22 13:11:25 [INFO]: Epoch 016 - training loss: 0.2213, validation loss: 0.2149
2024-05-22 13:11:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch16_loss0.2148633636534214.pypots
2024-05-22 13:11:27 [INFO]: Epoch 017 - training loss: 0.2052, validation loss: 0.2119
2024-05-22 13:11:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch17_loss0.21190328896045685.pypots
2024-05-22 13:11:29 [INFO]: Epoch 018 - training loss: 0.1965, validation loss: 0.2041
2024-05-22 13:11:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch18_loss0.20406828448176384.pypots
2024-05-22 13:11:31 [INFO]: Epoch 019 - training loss: 0.1934, validation loss: 0.2019
2024-05-22 13:11:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch19_loss0.2019152157008648.pypots
2024-05-22 13:11:33 [INFO]: Epoch 020 - training loss: 0.2077, validation loss: 0.1926
2024-05-22 13:11:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch20_loss0.19258152693510056.pypots
2024-05-22 13:11:36 [INFO]: Epoch 021 - training loss: 0.1888, validation loss: 0.1882
2024-05-22 13:11:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch21_loss0.18823928758502007.pypots
2024-05-22 13:11:38 [INFO]: Epoch 022 - training loss: 0.1788, validation loss: 0.1848
2024-05-22 13:11:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch22_loss0.18483051285147667.pypots
2024-05-22 13:11:40 [INFO]: Epoch 023 - training loss: 0.1941, validation loss: 0.1865
2024-05-22 13:11:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch23_loss0.18648751452565193.pypots
2024-05-22 13:11:42 [INFO]: Epoch 024 - training loss: 0.2482, validation loss: 0.2084
2024-05-22 13:11:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch24_loss0.20842984691262245.pypots
2024-05-22 13:11:44 [INFO]: Epoch 025 - training loss: 0.2050, validation loss: 0.1956
2024-05-22 13:11:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch25_loss0.19559447467327118.pypots
2024-05-22 13:11:46 [INFO]: Epoch 026 - training loss: 0.2088, validation loss: 0.1809
2024-05-22 13:11:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch26_loss0.18089742958545685.pypots
2024-05-22 13:11:48 [INFO]: Epoch 027 - training loss: 0.1976, validation loss: 0.1715
2024-05-22 13:11:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch27_loss0.1714666746556759.pypots
2024-05-22 13:11:50 [INFO]: Epoch 028 - training loss: 0.1668, validation loss: 0.1707
2024-05-22 13:11:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch28_loss0.17069720476865768.pypots
2024-05-22 13:11:52 [INFO]: Epoch 029 - training loss: 0.1951, validation loss: 0.1708
2024-05-22 13:11:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch29_loss0.1708356887102127.pypots
2024-05-22 13:11:54 [INFO]: Epoch 030 - training loss: 0.1759, validation loss: 0.1778
2024-05-22 13:11:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch30_loss0.17782878130674362.pypots
2024-05-22 13:11:56 [INFO]: Epoch 031 - training loss: 0.1908, validation loss: 0.1945
2024-05-22 13:11:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch31_loss0.19452884420752525.pypots
2024-05-22 13:11:58 [INFO]: Epoch 032 - training loss: 0.1996, validation loss: 0.2160
2024-05-22 13:11:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch32_loss0.21599318459630013.pypots
2024-05-22 13:12:00 [INFO]: Epoch 033 - training loss: 0.3131, validation loss: 0.2310
2024-05-22 13:12:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch33_loss0.23100117966532707.pypots
2024-05-22 13:12:03 [INFO]: Epoch 034 - training loss: 0.2696, validation loss: 0.1936
2024-05-22 13:12:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch34_loss0.19355370849370956.pypots
2024-05-22 13:12:05 [INFO]: Epoch 035 - training loss: 0.2273, validation loss: 0.1801
2024-05-22 13:12:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch35_loss0.1800592578947544.pypots
2024-05-22 13:12:07 [INFO]: Epoch 036 - training loss: 0.2126, validation loss: 0.1714
2024-05-22 13:12:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch36_loss0.17137768492102623.pypots
2024-05-22 13:12:09 [INFO]: Epoch 037 - training loss: 0.2598, validation loss: 0.1628
2024-05-22 13:12:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch37_loss0.16283272579312325.pypots
2024-05-22 13:12:11 [INFO]: Epoch 038 - training loss: 0.1837, validation loss: 0.1740
2024-05-22 13:12:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch38_loss0.17400285974144936.pypots
2024-05-22 13:12:13 [INFO]: Epoch 039 - training loss: 0.1641, validation loss: 0.1605
2024-05-22 13:12:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch39_loss0.16052087768912315.pypots
2024-05-22 13:12:15 [INFO]: Epoch 040 - training loss: 0.1708, validation loss: 0.1548
2024-05-22 13:12:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch40_loss0.15482406318187714.pypots
2024-05-22 13:12:17 [INFO]: Epoch 041 - training loss: 0.1561, validation loss: 0.1519
2024-05-22 13:12:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch41_loss0.15189571306109428.pypots
2024-05-22 13:12:19 [INFO]: Epoch 042 - training loss: 0.1664, validation loss: 0.1639
2024-05-22 13:12:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch42_loss0.1639476753771305.pypots
2024-05-22 13:12:21 [INFO]: Epoch 043 - training loss: 0.1895, validation loss: 0.1712
2024-05-22 13:12:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch43_loss0.17117467150092125.pypots
2024-05-22 13:12:23 [INFO]: Epoch 044 - training loss: 0.2299, validation loss: 0.1629
2024-05-22 13:12:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch44_loss0.16288767009973526.pypots
2024-05-22 13:12:25 [INFO]: Epoch 045 - training loss: 0.2054, validation loss: 0.1603
2024-05-22 13:12:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch45_loss0.1602822169661522.pypots
2024-05-22 13:12:28 [INFO]: Epoch 046 - training loss: 0.1744, validation loss: 0.1529
2024-05-22 13:12:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch46_loss0.15292290598154068.pypots
2024-05-22 13:12:30 [INFO]: Epoch 047 - training loss: 0.2100, validation loss: 0.1524
2024-05-22 13:12:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch47_loss0.15236759558320045.pypots
2024-05-22 13:12:32 [INFO]: Epoch 048 - training loss: 0.1794, validation loss: 0.1494
2024-05-22 13:12:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch48_loss0.1493527628481388.pypots
2024-05-22 13:12:34 [INFO]: Epoch 049 - training loss: 0.1743, validation loss: 0.1437
2024-05-22 13:12:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch49_loss0.14370883628726006.pypots
2024-05-22 13:12:36 [INFO]: Epoch 050 - training loss: 0.1627, validation loss: 0.1439
2024-05-22 13:12:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch50_loss0.14386619627475739.pypots
2024-05-22 13:12:38 [INFO]: Epoch 051 - training loss: 0.1406, validation loss: 0.1393
2024-05-22 13:12:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch51_loss0.1392677016556263.pypots
2024-05-22 13:12:40 [INFO]: Epoch 052 - training loss: 0.1656, validation loss: 0.1414
2024-05-22 13:12:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch52_loss0.1413736343383789.pypots
2024-05-22 13:12:42 [INFO]: Epoch 053 - training loss: 0.1444, validation loss: 0.1396
2024-05-22 13:12:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch53_loss0.13959594070911407.pypots
2024-05-22 13:12:44 [INFO]: Epoch 054 - training loss: 0.1347, validation loss: 0.1409
2024-05-22 13:12:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch54_loss0.1408531405031681.pypots
2024-05-22 13:12:46 [INFO]: Epoch 055 - training loss: 0.1969, validation loss: 0.1379
2024-05-22 13:12:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch55_loss0.13787361606955528.pypots
2024-05-22 13:12:48 [INFO]: Epoch 056 - training loss: 0.1924, validation loss: 0.1422
2024-05-22 13:12:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch56_loss0.14220025017857552.pypots
2024-05-22 13:12:50 [INFO]: Epoch 057 - training loss: 0.1856, validation loss: 0.1412
2024-05-22 13:12:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch57_loss0.14117638021707535.pypots
2024-05-22 13:12:53 [INFO]: Epoch 058 - training loss: 0.1714, validation loss: 0.1385
2024-05-22 13:12:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch58_loss0.13851052895188332.pypots
2024-05-22 13:12:55 [INFO]: Epoch 059 - training loss: 0.1436, validation loss: 0.1356
2024-05-22 13:12:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch59_loss0.13556891307234764.pypots
2024-05-22 13:12:57 [INFO]: Epoch 060 - training loss: 0.1903, validation loss: 0.1450
2024-05-22 13:12:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch60_loss0.14498631283640862.pypots
2024-05-22 13:12:59 [INFO]: Epoch 061 - training loss: 0.2053, validation loss: 0.1643
2024-05-22 13:12:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch61_loss0.16431913524866104.pypots
2024-05-22 13:13:01 [INFO]: Epoch 062 - training loss: 0.1875, validation loss: 0.1679
2024-05-22 13:13:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch62_loss0.1678524911403656.pypots
2024-05-22 13:13:03 [INFO]: Epoch 063 - training loss: 0.2062, validation loss: 0.1494
2024-05-22 13:13:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch63_loss0.14941363781690598.pypots
2024-05-22 13:13:05 [INFO]: Epoch 064 - training loss: 0.1569, validation loss: 0.1488
2024-05-22 13:13:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch64_loss0.1487892121076584.pypots
2024-05-22 13:13:07 [INFO]: Epoch 065 - training loss: 0.2347, validation loss: 0.1441
2024-05-22 13:13:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch65_loss0.1440977081656456.pypots
2024-05-22 13:13:09 [INFO]: Epoch 066 - training loss: 0.1498, validation loss: 0.1377
2024-05-22 13:13:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch66_loss0.13772401213645935.pypots
2024-05-22 13:13:11 [INFO]: Epoch 067 - training loss: 0.1383, validation loss: 0.1428
2024-05-22 13:13:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch67_loss0.14277024194598198.pypots
2024-05-22 13:13:13 [INFO]: Epoch 068 - training loss: 0.1754, validation loss: 0.1452
2024-05-22 13:13:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch68_loss0.1451987586915493.pypots
2024-05-22 13:13:15 [INFO]: Epoch 069 - training loss: 0.1469, validation loss: 0.1430
2024-05-22 13:13:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI_epoch69_loss0.14298518002033234.pypots
2024-05-22 13:13:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:13:15 [INFO]: Finished training. The best model is from epoch#59.
2024-05-22 13:13:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240522_T131052/CSDI.pypots
2024-05-22 13:13:31 [INFO]: CSDI on ETTm1: MAE=0.1381, MSE=0.0624
2024-05-22 13:13:31 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-22 13:13:31 [INFO]: Using the given device: cuda:0
2024-05-22 13:13:31 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240522_T131331
2024-05-22 13:13:31 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240522_T131331/tensorboard
2024-05-22 13:13:31 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 13:13:31 [INFO]: Epoch 001 - training loss: 23767.1172, validation loss: 0.9736
2024-05-22 13:13:32 [INFO]: Epoch 002 - training loss: 21720.1735, validation loss: 0.9768
2024-05-22 13:13:32 [INFO]: Epoch 003 - training loss: 19748.7040, validation loss: 0.9745
2024-05-22 13:13:32 [INFO]: Epoch 004 - training loss: 17835.8557, validation loss: 0.9616
2024-05-22 13:13:32 [INFO]: Epoch 005 - training loss: 16067.2129, validation loss: 0.9343
2024-05-22 13:13:32 [INFO]: Epoch 006 - training loss: 14469.2363, validation loss: 0.8799
2024-05-22 13:13:32 [INFO]: Epoch 007 - training loss: 13318.6153, validation loss: 0.7894
2024-05-22 13:13:32 [INFO]: Epoch 008 - training loss: 12331.7335, validation loss: 0.6698
2024-05-22 13:13:33 [INFO]: Epoch 009 - training loss: 11774.7504, validation loss: 0.5706
2024-05-22 13:13:33 [INFO]: Epoch 010 - training loss: 11108.9932, validation loss: 0.4992
2024-05-22 13:13:33 [INFO]: Epoch 011 - training loss: 10763.6691, validation loss: 0.4695
2024-05-22 13:13:33 [INFO]: Epoch 012 - training loss: 10536.3264, validation loss: 0.4514
2024-05-22 13:13:33 [INFO]: Epoch 013 - training loss: 10346.0526, validation loss: 0.4413
2024-05-22 13:13:33 [INFO]: Epoch 014 - training loss: 10347.3356, validation loss: 0.4240
2024-05-22 13:13:33 [INFO]: Epoch 015 - training loss: 10137.5713, validation loss: 0.3971
2024-05-22 13:13:34 [INFO]: Epoch 016 - training loss: 10034.6039, validation loss: 0.3753
2024-05-22 13:13:34 [INFO]: Epoch 017 - training loss: 9913.1921, validation loss: 0.3571
2024-05-22 13:13:34 [INFO]: Epoch 018 - training loss: 9923.9444, validation loss: 0.3395
2024-05-22 13:13:34 [INFO]: Epoch 019 - training loss: 9795.3580, validation loss: 0.3278
2024-05-22 13:13:34 [INFO]: Epoch 020 - training loss: 9730.9734, validation loss: 0.3213
2024-05-22 13:13:34 [INFO]: Epoch 021 - training loss: 9681.7347, validation loss: 0.3001
2024-05-22 13:13:34 [INFO]: Epoch 022 - training loss: 9669.9535, validation loss: 0.3000
2024-05-22 13:13:34 [INFO]: Epoch 023 - training loss: 9625.2908, validation loss: 0.2908
2024-05-22 13:13:35 [INFO]: Epoch 024 - training loss: 9631.9595, validation loss: 0.2814
2024-05-22 13:13:35 [INFO]: Epoch 025 - training loss: 9565.6959, validation loss: 0.2788
2024-05-22 13:13:35 [INFO]: Epoch 026 - training loss: 9546.0327, validation loss: 0.2801
2024-05-22 13:13:35 [INFO]: Epoch 027 - training loss: 9546.6653, validation loss: 0.2745
2024-05-22 13:13:35 [INFO]: Epoch 028 - training loss: 9538.4539, validation loss: 0.2636
2024-05-22 13:13:35 [INFO]: Epoch 029 - training loss: 9491.2186, validation loss: 0.2564
2024-05-22 13:13:35 [INFO]: Epoch 030 - training loss: 9482.0677, validation loss: 0.2471
2024-05-22 13:13:36 [INFO]: Epoch 031 - training loss: 9476.6431, validation loss: 0.2379
2024-05-22 13:13:36 [INFO]: Epoch 032 - training loss: 9458.2086, validation loss: 0.2338
2024-05-22 13:13:36 [INFO]: Epoch 033 - training loss: 9451.8807, validation loss: 0.2288
2024-05-22 13:13:36 [INFO]: Epoch 034 - training loss: 9450.1084, validation loss: 0.2226
2024-05-22 13:13:36 [INFO]: Epoch 035 - training loss: 9458.1113, validation loss: 0.2191
2024-05-22 13:13:36 [INFO]: Epoch 036 - training loss: 9425.3228, validation loss: 0.2121
2024-05-22 13:13:36 [INFO]: Epoch 037 - training loss: 9424.7336, validation loss: 0.2081
2024-05-22 13:13:36 [INFO]: Epoch 038 - training loss: 9408.1454, validation loss: 0.2028
2024-05-22 13:13:37 [INFO]: Epoch 039 - training loss: 9402.0367, validation loss: 0.1961
2024-05-22 13:13:37 [INFO]: Epoch 040 - training loss: 9419.1677, validation loss: 0.1964
2024-05-22 13:13:37 [INFO]: Epoch 041 - training loss: 9402.9346, validation loss: 0.1906
2024-05-22 13:13:37 [INFO]: Epoch 042 - training loss: 9382.7746, validation loss: 0.1844
2024-05-22 13:13:37 [INFO]: Epoch 043 - training loss: 9391.4889, validation loss: 0.1819
2024-05-22 13:13:37 [INFO]: Epoch 044 - training loss: 9373.8492, validation loss: 0.1777
2024-05-22 13:13:37 [INFO]: Epoch 045 - training loss: 9380.4847, validation loss: 0.1727
2024-05-22 13:13:38 [INFO]: Epoch 046 - training loss: 9370.3182, validation loss: 0.1683
2024-05-22 13:13:38 [INFO]: Epoch 047 - training loss: 9380.6527, validation loss: 0.1658
2024-05-22 13:13:38 [INFO]: Epoch 048 - training loss: 9357.4008, validation loss: 0.1636
2024-05-22 13:13:38 [INFO]: Epoch 049 - training loss: 9355.7041, validation loss: 0.1627
2024-05-22 13:13:38 [INFO]: Epoch 050 - training loss: 9350.5464, validation loss: 0.1578
2024-05-22 13:13:38 [INFO]: Epoch 051 - training loss: 9353.4631, validation loss: 0.1556
2024-05-22 13:13:38 [INFO]: Epoch 052 - training loss: 9350.2952, validation loss: 0.1529
2024-05-22 13:13:39 [INFO]: Epoch 053 - training loss: 9344.6042, validation loss: 0.1506
2024-05-22 13:13:39 [INFO]: Epoch 054 - training loss: 9339.9163, validation loss: 0.1476
2024-05-22 13:13:39 [INFO]: Epoch 055 - training loss: 9342.2985, validation loss: 0.1453
2024-05-22 13:13:39 [INFO]: Epoch 056 - training loss: 9337.8030, validation loss: 0.1441
2024-05-22 13:13:39 [INFO]: Epoch 057 - training loss: 9336.0312, validation loss: 0.1422
2024-05-22 13:13:39 [INFO]: Epoch 058 - training loss: 9330.1224, validation loss: 0.1408
2024-05-22 13:13:39 [INFO]: Epoch 059 - training loss: 9331.6741, validation loss: 0.1397
2024-05-22 13:13:39 [INFO]: Epoch 060 - training loss: 9328.1857, validation loss: 0.1378
2024-05-22 13:13:40 [INFO]: Epoch 061 - training loss: 9330.0675, validation loss: 0.1368
2024-05-22 13:13:40 [INFO]: Epoch 062 - training loss: 9331.1308, validation loss: 0.1338
2024-05-22 13:13:40 [INFO]: Epoch 063 - training loss: 9322.6136, validation loss: 0.1358
2024-05-22 13:13:40 [INFO]: Epoch 064 - training loss: 9330.4794, validation loss: 0.1317
2024-05-22 13:13:40 [INFO]: Epoch 065 - training loss: 9327.2613, validation loss: 0.1315
2024-05-22 13:13:40 [INFO]: Epoch 066 - training loss: 9320.1417, validation loss: 0.1309
2024-05-22 13:13:40 [INFO]: Epoch 067 - training loss: 9320.3757, validation loss: 0.1300
2024-05-22 13:13:41 [INFO]: Epoch 068 - training loss: 9320.4362, validation loss: 0.1301
2024-05-22 13:13:41 [INFO]: Epoch 069 - training loss: 9315.9747, validation loss: 0.1273
2024-05-22 13:13:41 [INFO]: Epoch 070 - training loss: 9313.7072, validation loss: 0.1276
2024-05-22 13:13:41 [INFO]: Epoch 071 - training loss: 9315.6339, validation loss: 0.1248
2024-05-22 13:13:41 [INFO]: Epoch 072 - training loss: 9312.9584, validation loss: 0.1242
2024-05-22 13:13:41 [INFO]: Epoch 073 - training loss: 9315.8738, validation loss: 0.1245
2024-05-22 13:13:41 [INFO]: Epoch 074 - training loss: 9309.5743, validation loss: 0.1232
2024-05-22 13:13:41 [INFO]: Epoch 075 - training loss: 9309.3488, validation loss: 0.1233
2024-05-22 13:13:42 [INFO]: Epoch 076 - training loss: 9309.2906, validation loss: 0.1228
2024-05-22 13:13:42 [INFO]: Epoch 077 - training loss: 9306.8669, validation loss: 0.1210
2024-05-22 13:13:42 [INFO]: Epoch 078 - training loss: 9306.3177, validation loss: 0.1206
2024-05-22 13:13:42 [INFO]: Epoch 079 - training loss: 9308.0729, validation loss: 0.1196
2024-05-22 13:13:42 [INFO]: Epoch 080 - training loss: 9306.8743, validation loss: 0.1189
2024-05-22 13:13:42 [INFO]: Epoch 081 - training loss: 9304.2518, validation loss: 0.1180
2024-05-22 13:13:42 [INFO]: Epoch 082 - training loss: 9302.3757, validation loss: 0.1176
2024-05-22 13:13:43 [INFO]: Epoch 083 - training loss: 9303.6031, validation loss: 0.1178
2024-05-22 13:13:43 [INFO]: Epoch 084 - training loss: 9304.6116, validation loss: 0.1165
2024-05-22 13:13:43 [INFO]: Epoch 085 - training loss: 9300.4539, validation loss: 0.1172
2024-05-22 13:13:43 [INFO]: Epoch 086 - training loss: 9300.9554, validation loss: 0.1155
2024-05-22 13:13:43 [INFO]: Epoch 087 - training loss: 9302.0033, validation loss: 0.1155
2024-05-22 13:13:43 [INFO]: Epoch 088 - training loss: 9306.6138, validation loss: 0.1138
2024-05-22 13:13:43 [INFO]: Epoch 089 - training loss: 9299.0531, validation loss: 0.1133
2024-05-22 13:13:43 [INFO]: Epoch 090 - training loss: 9296.0336, validation loss: 0.1128
2024-05-22 13:13:44 [INFO]: Epoch 091 - training loss: 9296.7914, validation loss: 0.1122
2024-05-22 13:13:44 [INFO]: Epoch 092 - training loss: 9296.4435, validation loss: 0.1128
2024-05-22 13:13:44 [INFO]: Epoch 093 - training loss: 9296.4980, validation loss: 0.1114
2024-05-22 13:13:44 [INFO]: Epoch 094 - training loss: 9298.2244, validation loss: 0.1110
2024-05-22 13:13:44 [INFO]: Epoch 095 - training loss: 9300.2892, validation loss: 0.1109
2024-05-22 13:13:44 [INFO]: Epoch 096 - training loss: 9297.7059, validation loss: 0.1092
2024-05-22 13:13:44 [INFO]: Epoch 097 - training loss: 9296.2420, validation loss: 0.1087
2024-05-22 13:13:45 [INFO]: Epoch 098 - training loss: 9296.0031, validation loss: 0.1079
2024-05-22 13:13:45 [INFO]: Epoch 099 - training loss: 9296.6455, validation loss: 0.1093
2024-05-22 13:13:45 [INFO]: Epoch 100 - training loss: 9294.3412, validation loss: 0.1074
2024-05-22 13:13:45 [INFO]: Epoch 101 - training loss: 9292.8497, validation loss: 0.1077
2024-05-22 13:13:45 [INFO]: Epoch 102 - training loss: 9293.1287, validation loss: 0.1075
2024-05-22 13:13:45 [INFO]: Epoch 103 - training loss: 9295.4647, validation loss: 0.1062
2024-05-22 13:13:45 [INFO]: Epoch 104 - training loss: 9292.0118, validation loss: 0.1060
2024-05-22 13:13:45 [INFO]: Epoch 105 - training loss: 9292.2609, validation loss: 0.1043
2024-05-22 13:13:46 [INFO]: Epoch 106 - training loss: 9290.4070, validation loss: 0.1043
2024-05-22 13:13:46 [INFO]: Epoch 107 - training loss: 9292.4760, validation loss: 0.1042
2024-05-22 13:13:46 [INFO]: Epoch 108 - training loss: 9291.5204, validation loss: 0.1037
2024-05-22 13:13:46 [INFO]: Epoch 109 - training loss: 9288.6747, validation loss: 0.1036
2024-05-22 13:13:46 [INFO]: Epoch 110 - training loss: 9290.0081, validation loss: 0.1016
2024-05-22 13:13:46 [INFO]: Epoch 111 - training loss: 9288.2105, validation loss: 0.1040
2024-05-22 13:13:46 [INFO]: Epoch 112 - training loss: 9289.6082, validation loss: 0.1017
2024-05-22 13:13:47 [INFO]: Epoch 113 - training loss: 9290.9505, validation loss: 0.1010
2024-05-22 13:13:47 [INFO]: Epoch 114 - training loss: 9287.7898, validation loss: 0.1006
2024-05-22 13:13:47 [INFO]: Epoch 115 - training loss: 9288.1088, validation loss: 0.1001
2024-05-22 13:13:47 [INFO]: Epoch 116 - training loss: 9288.3671, validation loss: 0.1002
2024-05-22 13:13:47 [INFO]: Epoch 117 - training loss: 9288.6901, validation loss: 0.0984
2024-05-22 13:13:47 [INFO]: Epoch 118 - training loss: 9285.6461, validation loss: 0.1006
2024-05-22 13:13:47 [INFO]: Epoch 119 - training loss: 9286.7902, validation loss: 0.0997
2024-05-22 13:13:47 [INFO]: Epoch 120 - training loss: 9285.4506, validation loss: 0.0982
2024-05-22 13:13:48 [INFO]: Epoch 121 - training loss: 9287.0827, validation loss: 0.0985
2024-05-22 13:13:48 [INFO]: Epoch 122 - training loss: 9289.8921, validation loss: 0.0971
2024-05-22 13:13:48 [INFO]: Epoch 123 - training loss: 9286.4221, validation loss: 0.0974
2024-05-22 13:13:48 [INFO]: Epoch 124 - training loss: 9284.3623, validation loss: 0.0964
2024-05-22 13:13:48 [INFO]: Epoch 125 - training loss: 9285.0080, validation loss: 0.0963
2024-05-22 13:13:48 [INFO]: Epoch 126 - training loss: 9284.5014, validation loss: 0.0958
2024-05-22 13:13:48 [INFO]: Epoch 127 - training loss: 9283.6301, validation loss: 0.0961
2024-05-22 13:13:49 [INFO]: Epoch 128 - training loss: 9283.0287, validation loss: 0.0968
2024-05-22 13:13:49 [INFO]: Epoch 129 - training loss: 9282.9056, validation loss: 0.0951
2024-05-22 13:13:49 [INFO]: Epoch 130 - training loss: 9283.2700, validation loss: 0.0945
2024-05-22 13:13:49 [INFO]: Epoch 131 - training loss: 9283.4917, validation loss: 0.0958
2024-05-22 13:13:49 [INFO]: Epoch 132 - training loss: 9288.2562, validation loss: 0.0933
2024-05-22 13:13:49 [INFO]: Epoch 133 - training loss: 9283.2717, validation loss: 0.0938
2024-05-22 13:13:49 [INFO]: Epoch 134 - training loss: 9281.5103, validation loss: 0.0937
2024-05-22 13:13:50 [INFO]: Epoch 135 - training loss: 9281.1832, validation loss: 0.0927
2024-05-22 13:13:50 [INFO]: Epoch 136 - training loss: 9281.6516, validation loss: 0.0929
2024-05-22 13:13:50 [INFO]: Epoch 137 - training loss: 9281.8878, validation loss: 0.0932
2024-05-22 13:13:50 [INFO]: Epoch 138 - training loss: 9281.5107, validation loss: 0.0927
2024-05-22 13:13:50 [INFO]: Epoch 139 - training loss: 9280.4036, validation loss: 0.0926
2024-05-22 13:13:50 [INFO]: Epoch 140 - training loss: 9281.3492, validation loss: 0.0922
2024-05-22 13:13:50 [INFO]: Epoch 141 - training loss: 9280.7702, validation loss: 0.0917
2024-05-22 13:13:50 [INFO]: Epoch 142 - training loss: 9280.9323, validation loss: 0.0918
2024-05-22 13:13:51 [INFO]: Epoch 143 - training loss: 9280.5301, validation loss: 0.0914
2024-05-22 13:13:51 [INFO]: Epoch 144 - training loss: 9280.7348, validation loss: 0.0910
2024-05-22 13:13:51 [INFO]: Epoch 145 - training loss: 9281.7039, validation loss: 0.0908
2024-05-22 13:13:51 [INFO]: Epoch 146 - training loss: 9279.3181, validation loss: 0.0920
2024-05-22 13:13:51 [INFO]: Epoch 147 - training loss: 9280.1898, validation loss: 0.0906
2024-05-22 13:13:51 [INFO]: Epoch 148 - training loss: 9279.5999, validation loss: 0.0892
2024-05-22 13:13:51 [INFO]: Epoch 149 - training loss: 9281.3946, validation loss: 0.0899
2024-05-22 13:13:52 [INFO]: Epoch 150 - training loss: 9280.7754, validation loss: 0.0920
2024-05-22 13:13:52 [INFO]: Epoch 151 - training loss: 9281.1721, validation loss: 0.0895
2024-05-22 13:13:52 [INFO]: Epoch 152 - training loss: 9278.4198, validation loss: 0.0901
2024-05-22 13:13:52 [INFO]: Epoch 153 - training loss: 9278.0645, validation loss: 0.0875
2024-05-22 13:13:52 [INFO]: Epoch 154 - training loss: 9279.7616, validation loss: 0.0900
2024-05-22 13:13:52 [INFO]: Epoch 155 - training loss: 9279.1572, validation loss: 0.0872
2024-05-22 13:13:52 [INFO]: Epoch 156 - training loss: 9280.9641, validation loss: 0.0887
2024-05-22 13:13:52 [INFO]: Epoch 157 - training loss: 9278.0185, validation loss: 0.0865
2024-05-22 13:13:53 [INFO]: Epoch 158 - training loss: 9279.2980, validation loss: 0.0871
2024-05-22 13:13:53 [INFO]: Epoch 159 - training loss: 9279.8066, validation loss: 0.0877
2024-05-22 13:13:53 [INFO]: Epoch 160 - training loss: 9277.9644, validation loss: 0.0867
2024-05-22 13:13:53 [INFO]: Epoch 161 - training loss: 9278.4044, validation loss: 0.0879
2024-05-22 13:13:53 [INFO]: Epoch 162 - training loss: 9275.8420, validation loss: 0.0862
2024-05-22 13:13:53 [INFO]: Epoch 163 - training loss: 9276.4534, validation loss: 0.0862
2024-05-22 13:13:53 [INFO]: Epoch 164 - training loss: 9280.4886, validation loss: 0.0857
2024-05-22 13:13:54 [INFO]: Epoch 165 - training loss: 9277.1212, validation loss: 0.0852
2024-05-22 13:13:54 [INFO]: Epoch 166 - training loss: 9277.9246, validation loss: 0.0856
2024-05-22 13:13:54 [INFO]: Epoch 167 - training loss: 9278.8742, validation loss: 0.0843
2024-05-22 13:13:54 [INFO]: Epoch 168 - training loss: 9276.9763, validation loss: 0.0846
2024-05-22 13:13:54 [INFO]: Epoch 169 - training loss: 9279.6281, validation loss: 0.0856
2024-05-22 13:13:54 [INFO]: Epoch 170 - training loss: 9277.3357, validation loss: 0.0847
2024-05-22 13:13:54 [INFO]: Epoch 171 - training loss: 9276.6057, validation loss: 0.0855
2024-05-22 13:13:55 [INFO]: Epoch 172 - training loss: 9277.5254, validation loss: 0.0840
2024-05-22 13:13:55 [INFO]: Epoch 173 - training loss: 9277.5268, validation loss: 0.0842
2024-05-22 13:13:55 [INFO]: Epoch 174 - training loss: 9276.3223, validation loss: 0.0853
2024-05-22 13:13:55 [INFO]: Epoch 175 - training loss: 9276.1423, validation loss: 0.0827
2024-05-22 13:13:55 [INFO]: Epoch 176 - training loss: 9276.5239, validation loss: 0.0833
2024-05-22 13:13:55 [INFO]: Epoch 177 - training loss: 9276.2437, validation loss: 0.0829
2024-05-22 13:13:55 [INFO]: Epoch 178 - training loss: 9275.4780, validation loss: 0.0827
2024-05-22 13:13:55 [INFO]: Epoch 179 - training loss: 9275.2109, validation loss: 0.0824
2024-05-22 13:13:56 [INFO]: Epoch 180 - training loss: 9275.6318, validation loss: 0.0827
2024-05-22 13:13:56 [INFO]: Epoch 181 - training loss: 9276.2792, validation loss: 0.0831
2024-05-22 13:13:56 [INFO]: Epoch 182 - training loss: 9274.8958, validation loss: 0.0827
2024-05-22 13:13:56 [INFO]: Epoch 183 - training loss: 9275.4371, validation loss: 0.0827
2024-05-22 13:13:56 [INFO]: Epoch 184 - training loss: 9276.0785, validation loss: 0.0826
2024-05-22 13:13:56 [INFO]: Epoch 185 - training loss: 9274.9075, validation loss: 0.0839
2024-05-22 13:13:56 [INFO]: Epoch 186 - training loss: 9276.3570, validation loss: 0.0827
2024-05-22 13:13:57 [INFO]: Epoch 187 - training loss: 9274.9825, validation loss: 0.0841
2024-05-22 13:13:57 [INFO]: Epoch 188 - training loss: 9273.7219, validation loss: 0.0805
2024-05-22 13:13:57 [INFO]: Epoch 189 - training loss: 9275.5097, validation loss: 0.0807
2024-05-22 13:13:57 [INFO]: Epoch 190 - training loss: 9274.7974, validation loss: 0.0824
2024-05-22 13:13:57 [INFO]: Epoch 191 - training loss: 9276.7097, validation loss: 0.0821
2024-05-22 13:13:57 [INFO]: Epoch 192 - training loss: 9274.7059, validation loss: 0.0794
2024-05-22 13:13:57 [INFO]: Epoch 193 - training loss: 9274.9558, validation loss: 0.0834
2024-05-22 13:13:57 [INFO]: Epoch 194 - training loss: 9274.2331, validation loss: 0.0832
2024-05-22 13:13:58 [INFO]: Epoch 195 - training loss: 9273.6216, validation loss: 0.0820
2024-05-22 13:13:58 [INFO]: Epoch 196 - training loss: 9274.3560, validation loss: 0.0823
2024-05-22 13:13:58 [INFO]: Epoch 197 - training loss: 9273.4750, validation loss: 0.0819
2024-05-22 13:13:58 [INFO]: Epoch 198 - training loss: 9274.4824, validation loss: 0.0815
2024-05-22 13:13:58 [INFO]: Epoch 199 - training loss: 9274.6036, validation loss: 0.0794
2024-05-22 13:13:58 [INFO]: Epoch 200 - training loss: 9274.5543, validation loss: 0.0821
2024-05-22 13:13:58 [INFO]: Epoch 201 - training loss: 9273.1443, validation loss: 0.0816
2024-05-22 13:13:59 [INFO]: Epoch 202 - training loss: 9273.7689, validation loss: 0.0818
2024-05-22 13:13:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:13:59 [INFO]: Finished training. The best model is from epoch#192.
2024-05-22 13:13:59 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_ettm1/20240522_T131331/GPVAE.pypots
2024-05-22 13:13:59 [INFO]: GP-VAE on ETTm1: MAE=0.2954, MSE=0.1789
2024-05-22 13:13:59 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-22 13:13:59 [INFO]: Using the given device: cuda:0
2024-05-22 13:13:59 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240522_T131359
2024-05-22 13:13:59 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240522_T131359/tensorboard
2024-05-22 13:13:59 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 13:14:09 [INFO]: Epoch 001 - generator training loss: 0.5008, discriminator training loss: 0.4185, validation loss: 0.3313
2024-05-22 13:14:18 [INFO]: Epoch 002 - generator training loss: 0.0051, discriminator training loss: 0.3238, validation loss: 0.1089
2024-05-22 13:14:27 [INFO]: Epoch 003 - generator training loss: -0.1159, discriminator training loss: 0.3094, validation loss: 0.0603
2024-05-22 13:14:36 [INFO]: Epoch 004 - generator training loss: -0.1396, discriminator training loss: 0.2958, validation loss: 0.0508
2024-05-22 13:14:45 [INFO]: Epoch 005 - generator training loss: -0.1323, discriminator training loss: 0.2816, validation loss: 0.0442
2024-05-22 13:14:54 [INFO]: Epoch 006 - generator training loss: -0.1110, discriminator training loss: 0.2527, validation loss: 0.0411
2024-05-22 13:15:03 [INFO]: Epoch 007 - generator training loss: -0.0871, discriminator training loss: 0.2210, validation loss: 0.0387
2024-05-22 13:15:11 [INFO]: Epoch 008 - generator training loss: -0.0666, discriminator training loss: 0.1877, validation loss: 0.0393
2024-05-22 13:15:20 [INFO]: Epoch 009 - generator training loss: -0.0475, discriminator training loss: 0.1608, validation loss: 0.0380
2024-05-22 13:15:29 [INFO]: Epoch 010 - generator training loss: -0.0384, discriminator training loss: 0.1437, validation loss: 0.0371
2024-05-22 13:15:38 [INFO]: Epoch 011 - generator training loss: -0.0335, discriminator training loss: 0.1345, validation loss: 0.0364
2024-05-22 13:15:47 [INFO]: Epoch 012 - generator training loss: -0.0337, discriminator training loss: 0.1274, validation loss: 0.0363
2024-05-22 13:15:56 [INFO]: Epoch 013 - generator training loss: -0.0319, discriminator training loss: 0.1234, validation loss: 0.0353
2024-05-22 13:16:05 [INFO]: Epoch 014 - generator training loss: -0.0326, discriminator training loss: 0.1203, validation loss: 0.0343
2024-05-22 13:16:14 [INFO]: Epoch 015 - generator training loss: -0.0332, discriminator training loss: 0.1184, validation loss: 0.0342
2024-05-22 13:16:23 [INFO]: Epoch 016 - generator training loss: -0.0275, discriminator training loss: 0.1168, validation loss: 0.0343
2024-05-22 13:16:32 [INFO]: Epoch 017 - generator training loss: -0.0326, discriminator training loss: 0.1167, validation loss: 0.0339
2024-05-22 13:16:41 [INFO]: Epoch 018 - generator training loss: -0.0301, discriminator training loss: 0.1175, validation loss: 0.0332
2024-05-22 13:16:50 [INFO]: Epoch 019 - generator training loss: -0.0334, discriminator training loss: 0.1166, validation loss: 0.0330
2024-05-22 13:16:58 [INFO]: Epoch 020 - generator training loss: -0.0376, discriminator training loss: 0.1153, validation loss: 0.0323
2024-05-22 13:17:07 [INFO]: Epoch 021 - generator training loss: -0.0326, discriminator training loss: 0.1132, validation loss: 0.0325
2024-05-22 13:17:16 [INFO]: Epoch 022 - generator training loss: -0.0375, discriminator training loss: 0.1148, validation loss: 0.0323
2024-05-22 13:17:25 [INFO]: Epoch 023 - generator training loss: -0.0332, discriminator training loss: 0.1153, validation loss: 0.0317
2024-05-22 13:17:34 [INFO]: Epoch 024 - generator training loss: -0.0348, discriminator training loss: 0.1140, validation loss: 0.0312
2024-05-22 13:17:43 [INFO]: Epoch 025 - generator training loss: -0.0351, discriminator training loss: 0.1158, validation loss: 0.0326
2024-05-22 13:17:52 [INFO]: Epoch 026 - generator training loss: -0.0373, discriminator training loss: 0.1138, validation loss: 0.0311
2024-05-22 13:18:01 [INFO]: Epoch 027 - generator training loss: -0.0388, discriminator training loss: 0.1118, validation loss: 0.0309
2024-05-22 13:18:09 [INFO]: Epoch 028 - generator training loss: -0.0376, discriminator training loss: 0.1105, validation loss: 0.0307
2024-05-22 13:18:18 [INFO]: Epoch 029 - generator training loss: -0.0394, discriminator training loss: 0.1137, validation loss: 0.0312
2024-05-22 13:18:27 [INFO]: Epoch 030 - generator training loss: -0.0383, discriminator training loss: 0.1138, validation loss: 0.0307
2024-05-22 13:18:36 [INFO]: Epoch 031 - generator training loss: -0.0362, discriminator training loss: 0.1116, validation loss: 0.0307
2024-05-22 13:18:45 [INFO]: Epoch 032 - generator training loss: -0.0397, discriminator training loss: 0.1121, validation loss: 0.0299
2024-05-22 13:18:54 [INFO]: Epoch 033 - generator training loss: -0.0386, discriminator training loss: 0.1114, validation loss: 0.0300
2024-05-22 13:19:03 [INFO]: Epoch 034 - generator training loss: -0.0359, discriminator training loss: 0.1131, validation loss: 0.0299
2024-05-22 13:19:12 [INFO]: Epoch 035 - generator training loss: -0.0393, discriminator training loss: 0.1136, validation loss: 0.0300
2024-05-22 13:19:21 [INFO]: Epoch 036 - generator training loss: -0.0377, discriminator training loss: 0.1106, validation loss: 0.0301
2024-05-22 13:19:30 [INFO]: Epoch 037 - generator training loss: -0.0422, discriminator training loss: 0.1104, validation loss: 0.0296
2024-05-22 13:19:39 [INFO]: Epoch 038 - generator training loss: -0.0421, discriminator training loss: 0.1099, validation loss: 0.0288
2024-05-22 13:19:48 [INFO]: Epoch 039 - generator training loss: -0.0399, discriminator training loss: 0.1098, validation loss: 0.0282
2024-05-22 13:19:57 [INFO]: Epoch 040 - generator training loss: -0.0413, discriminator training loss: 0.1085, validation loss: 0.0292
2024-05-22 13:20:05 [INFO]: Epoch 041 - generator training loss: -0.0421, discriminator training loss: 0.1123, validation loss: 0.0282
2024-05-22 13:20:14 [INFO]: Epoch 042 - generator training loss: -0.0397, discriminator training loss: 0.1105, validation loss: 0.0279
2024-05-22 13:20:23 [INFO]: Epoch 043 - generator training loss: -0.0408, discriminator training loss: 0.1099, validation loss: 0.0281
2024-05-22 13:20:32 [INFO]: Epoch 044 - generator training loss: -0.0416, discriminator training loss: 0.1092, validation loss: 0.0275
2024-05-22 13:20:41 [INFO]: Epoch 045 - generator training loss: -0.0403, discriminator training loss: 0.1095, validation loss: 0.0277
2024-05-22 13:20:50 [INFO]: Epoch 046 - generator training loss: -0.0424, discriminator training loss: 0.1103, validation loss: 0.0272
2024-05-22 13:20:59 [INFO]: Epoch 047 - generator training loss: -0.0427, discriminator training loss: 0.1101, validation loss: 0.0268
2024-05-22 13:21:08 [INFO]: Epoch 048 - generator training loss: -0.0442, discriminator training loss: 0.1121, validation loss: 0.0267
2024-05-22 13:21:16 [INFO]: Epoch 049 - generator training loss: -0.0458, discriminator training loss: 0.1107, validation loss: 0.0267
2024-05-22 13:21:25 [INFO]: Epoch 050 - generator training loss: -0.0427, discriminator training loss: 0.1101, validation loss: 0.0265
2024-05-22 13:21:34 [INFO]: Epoch 051 - generator training loss: -0.0450, discriminator training loss: 0.1096, validation loss: 0.0259
2024-05-22 13:21:43 [INFO]: Epoch 052 - generator training loss: -0.0442, discriminator training loss: 0.1089, validation loss: 0.0258
2024-05-22 13:21:52 [INFO]: Epoch 053 - generator training loss: -0.0444, discriminator training loss: 0.1090, validation loss: 0.0253
2024-05-22 13:22:01 [INFO]: Epoch 054 - generator training loss: -0.0454, discriminator training loss: 0.1077, validation loss: 0.0248
2024-05-22 13:22:10 [INFO]: Epoch 055 - generator training loss: -0.0462, discriminator training loss: 0.1076, validation loss: 0.0250
2024-05-22 13:22:19 [INFO]: Epoch 056 - generator training loss: -0.0459, discriminator training loss: 0.1061, validation loss: 0.0251
2024-05-22 13:22:28 [INFO]: Epoch 057 - generator training loss: -0.0479, discriminator training loss: 0.1074, validation loss: 0.0252
2024-05-22 13:22:37 [INFO]: Epoch 058 - generator training loss: -0.0474, discriminator training loss: 0.1097, validation loss: 0.0244
2024-05-22 13:22:46 [INFO]: Epoch 059 - generator training loss: -0.0470, discriminator training loss: 0.1067, validation loss: 0.0237
2024-05-22 13:22:54 [INFO]: Epoch 060 - generator training loss: -0.0484, discriminator training loss: 0.1098, validation loss: 0.0235
2024-05-22 13:23:03 [INFO]: Epoch 061 - generator training loss: -0.0437, discriminator training loss: 0.1090, validation loss: 0.0237
2024-05-22 13:23:12 [INFO]: Epoch 062 - generator training loss: -0.0481, discriminator training loss: 0.1068, validation loss: 0.0230
2024-05-22 13:23:21 [INFO]: Epoch 063 - generator training loss: -0.0506, discriminator training loss: 0.1083, validation loss: 0.0232
2024-05-22 13:23:31 [INFO]: Epoch 064 - generator training loss: -0.0470, discriminator training loss: 0.1096, validation loss: 0.0227
2024-05-22 13:23:40 [INFO]: Epoch 065 - generator training loss: -0.0444, discriminator training loss: 0.1091, validation loss: 0.0227
2024-05-22 13:23:49 [INFO]: Epoch 066 - generator training loss: -0.0463, discriminator training loss: 0.1091, validation loss: 0.0255
2024-05-22 13:23:58 [INFO]: Epoch 067 - generator training loss: -0.0455, discriminator training loss: 0.1087, validation loss: 0.0247
2024-05-22 13:24:07 [INFO]: Epoch 068 - generator training loss: -0.0471, discriminator training loss: 0.1083, validation loss: 0.0234
2024-05-22 13:24:16 [INFO]: Epoch 069 - generator training loss: -0.0481, discriminator training loss: 0.1075, validation loss: 0.0237
2024-05-22 13:24:25 [INFO]: Epoch 070 - generator training loss: -0.0468, discriminator training loss: 0.1061, validation loss: 0.0226
2024-05-22 13:24:34 [INFO]: Epoch 071 - generator training loss: -0.0499, discriminator training loss: 0.1066, validation loss: 0.0231
2024-05-22 13:24:43 [INFO]: Epoch 072 - generator training loss: -0.0459, discriminator training loss: 0.1058, validation loss: 0.0222
2024-05-22 13:24:52 [INFO]: Epoch 073 - generator training loss: -0.0497, discriminator training loss: 0.1063, validation loss: 0.0222
2024-05-22 13:25:01 [INFO]: Epoch 074 - generator training loss: -0.0462, discriminator training loss: 0.1065, validation loss: 0.0223
2024-05-22 13:25:10 [INFO]: Epoch 075 - generator training loss: -0.0504, discriminator training loss: 0.1071, validation loss: 0.0224
2024-05-22 13:25:19 [INFO]: Epoch 076 - generator training loss: -0.0483, discriminator training loss: 0.1086, validation loss: 0.0223
2024-05-22 13:25:28 [INFO]: Epoch 077 - generator training loss: -0.0478, discriminator training loss: 0.1078, validation loss: 0.0220
2024-05-22 13:25:37 [INFO]: Epoch 078 - generator training loss: -0.0468, discriminator training loss: 0.1070, validation loss: 0.0223
2024-05-22 13:25:46 [INFO]: Epoch 079 - generator training loss: -0.0483, discriminator training loss: 0.1068, validation loss: 0.0219
2024-05-22 13:25:55 [INFO]: Epoch 080 - generator training loss: -0.0487, discriminator training loss: 0.1070, validation loss: 0.0220
2024-05-22 13:26:04 [INFO]: Epoch 081 - generator training loss: -0.0510, discriminator training loss: 0.1069, validation loss: 0.0223
2024-05-22 13:26:13 [INFO]: Epoch 082 - generator training loss: -0.0465, discriminator training loss: 0.1074, validation loss: 0.0225
2024-05-22 13:26:22 [INFO]: Epoch 083 - generator training loss: -0.0491, discriminator training loss: 0.1042, validation loss: 0.0220
2024-05-22 13:26:31 [INFO]: Epoch 084 - generator training loss: -0.0487, discriminator training loss: 0.1077, validation loss: 0.0217
2024-05-22 13:26:40 [INFO]: Epoch 085 - generator training loss: -0.0496, discriminator training loss: 0.1062, validation loss: 0.0224
2024-05-22 13:26:49 [INFO]: Epoch 086 - generator training loss: -0.0488, discriminator training loss: 0.1069, validation loss: 0.0223
2024-05-22 13:26:58 [INFO]: Epoch 087 - generator training loss: -0.0483, discriminator training loss: 0.1045, validation loss: 0.0220
2024-05-22 13:27:07 [INFO]: Epoch 088 - generator training loss: -0.0476, discriminator training loss: 0.1079, validation loss: 0.0221
2024-05-22 13:27:16 [INFO]: Epoch 089 - generator training loss: -0.0482, discriminator training loss: 0.1080, validation loss: 0.0217
2024-05-22 13:27:25 [INFO]: Epoch 090 - generator training loss: -0.0463, discriminator training loss: 0.1064, validation loss: 0.0221
2024-05-22 13:27:34 [INFO]: Epoch 091 - generator training loss: -0.0488, discriminator training loss: 0.1047, validation loss: 0.0217
2024-05-22 13:27:43 [INFO]: Epoch 092 - generator training loss: -0.0482, discriminator training loss: 0.1067, validation loss: 0.0221
2024-05-22 13:27:52 [INFO]: Epoch 093 - generator training loss: -0.0488, discriminator training loss: 0.1059, validation loss: 0.0220
2024-05-22 13:28:01 [INFO]: Epoch 094 - generator training loss: -0.0494, discriminator training loss: 0.1051, validation loss: 0.0217
2024-05-22 13:28:10 [INFO]: Epoch 095 - generator training loss: -0.0474, discriminator training loss: 0.1067, validation loss: 0.0217
2024-05-22 13:28:19 [INFO]: Epoch 096 - generator training loss: -0.0477, discriminator training loss: 0.1068, validation loss: 0.0219
2024-05-22 13:28:28 [INFO]: Epoch 097 - generator training loss: -0.0464, discriminator training loss: 0.1053, validation loss: 0.0213
2024-05-22 13:28:37 [INFO]: Epoch 098 - generator training loss: -0.0517, discriminator training loss: 0.1046, validation loss: 0.0216
2024-05-22 13:28:46 [INFO]: Epoch 099 - generator training loss: -0.0504, discriminator training loss: 0.1070, validation loss: 0.0216
2024-05-22 13:28:55 [INFO]: Epoch 100 - generator training loss: -0.0480, discriminator training loss: 0.1040, validation loss: 0.0214
2024-05-22 13:29:04 [INFO]: Epoch 101 - generator training loss: -0.0544, discriminator training loss: 0.1055, validation loss: 0.0218
2024-05-22 13:29:13 [INFO]: Epoch 102 - generator training loss: -0.0465, discriminator training loss: 0.1081, validation loss: 0.0226
2024-05-22 13:29:22 [INFO]: Epoch 103 - generator training loss: -0.0500, discriminator training loss: 0.1057, validation loss: 0.0222
2024-05-22 13:29:31 [INFO]: Epoch 104 - generator training loss: -0.0456, discriminator training loss: 0.1050, validation loss: 0.0212
2024-05-22 13:29:40 [INFO]: Epoch 105 - generator training loss: -0.0478, discriminator training loss: 0.1020, validation loss: 0.0215
2024-05-22 13:29:49 [INFO]: Epoch 106 - generator training loss: -0.0520, discriminator training loss: 0.1048, validation loss: 0.0226
2024-05-22 13:29:58 [INFO]: Epoch 107 - generator training loss: -0.0486, discriminator training loss: 0.1041, validation loss: 0.0215
2024-05-22 13:30:07 [INFO]: Epoch 108 - generator training loss: -0.0488, discriminator training loss: 0.1044, validation loss: 0.0212
2024-05-22 13:30:16 [INFO]: Epoch 109 - generator training loss: -0.0502, discriminator training loss: 0.1027, validation loss: 0.0213
2024-05-22 13:30:25 [INFO]: Epoch 110 - generator training loss: -0.0485, discriminator training loss: 0.1035, validation loss: 0.0214
2024-05-22 13:30:34 [INFO]: Epoch 111 - generator training loss: -0.0477, discriminator training loss: 0.1049, validation loss: 0.0218
2024-05-22 13:30:43 [INFO]: Epoch 112 - generator training loss: -0.0485, discriminator training loss: 0.1042, validation loss: 0.0212
2024-05-22 13:30:52 [INFO]: Epoch 113 - generator training loss: -0.0507, discriminator training loss: 0.1072, validation loss: 0.0220
2024-05-22 13:31:01 [INFO]: Epoch 114 - generator training loss: -0.0466, discriminator training loss: 0.1036, validation loss: 0.0211
2024-05-22 13:31:10 [INFO]: Epoch 115 - generator training loss: -0.0513, discriminator training loss: 0.1056, validation loss: 0.0214
2024-05-22 13:31:19 [INFO]: Epoch 116 - generator training loss: -0.0474, discriminator training loss: 0.1067, validation loss: 0.0220
2024-05-22 13:31:28 [INFO]: Epoch 117 - generator training loss: -0.0489, discriminator training loss: 0.1061, validation loss: 0.0213
2024-05-22 13:31:37 [INFO]: Epoch 118 - generator training loss: -0.0475, discriminator training loss: 0.1022, validation loss: 0.0216
2024-05-22 13:31:46 [INFO]: Epoch 119 - generator training loss: -0.0476, discriminator training loss: 0.1048, validation loss: 0.0209
2024-05-22 13:31:55 [INFO]: Epoch 120 - generator training loss: -0.0506, discriminator training loss: 0.1059, validation loss: 0.0207
2024-05-22 13:32:04 [INFO]: Epoch 121 - generator training loss: -0.0499, discriminator training loss: 0.1050, validation loss: 0.0213
2024-05-22 13:32:13 [INFO]: Epoch 122 - generator training loss: -0.0490, discriminator training loss: 0.1039, validation loss: 0.0211
2024-05-22 13:32:22 [INFO]: Epoch 123 - generator training loss: -0.0471, discriminator training loss: 0.1028, validation loss: 0.0211
2024-05-22 13:32:31 [INFO]: Epoch 124 - generator training loss: -0.0510, discriminator training loss: 0.1038, validation loss: 0.0210
2024-05-22 13:32:40 [INFO]: Epoch 125 - generator training loss: -0.0493, discriminator training loss: 0.1053, validation loss: 0.0209
2024-05-22 13:32:49 [INFO]: Epoch 126 - generator training loss: -0.0475, discriminator training loss: 0.1034, validation loss: 0.0210
2024-05-22 13:32:59 [INFO]: Epoch 127 - generator training loss: -0.0510, discriminator training loss: 0.1040, validation loss: 0.0207
2024-05-22 13:33:07 [INFO]: Epoch 128 - generator training loss: -0.0488, discriminator training loss: 0.1032, validation loss: 0.0227
2024-05-22 13:33:16 [INFO]: Epoch 129 - generator training loss: -0.0488, discriminator training loss: 0.1062, validation loss: 0.0209
2024-05-22 13:33:25 [INFO]: Epoch 130 - generator training loss: -0.0467, discriminator training loss: 0.1042, validation loss: 0.0212
2024-05-22 13:33:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:33:25 [INFO]: Finished training. The best model is from epoch#120.
2024-05-22 13:33:25 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_ettm1/20240522_T131359/USGAN.pypots
2024-05-22 13:33:26 [INFO]: US-GAN on ETTm1: MAE=0.1372, MSE=0.0492
2024-05-22 13:33:26 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-22 13:33:26 [INFO]: Using the given device: cuda:0
2024-05-22 13:33:26 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240522_T133326
2024-05-22 13:33:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240522_T133326/tensorboard
2024-05-22 13:33:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 13:33:34 [INFO]: Epoch 001 - training loss: 1.2885, validation loss: 0.2410
2024-05-22 13:33:40 [INFO]: Epoch 002 - training loss: 0.8342, validation loss: 0.0832
2024-05-22 13:33:46 [INFO]: Epoch 003 - training loss: 0.6670, validation loss: 0.0547
2024-05-22 13:33:52 [INFO]: Epoch 004 - training loss: 0.5865, validation loss: 0.0438
2024-05-22 13:33:58 [INFO]: Epoch 005 - training loss: 0.5447, validation loss: 0.0402
2024-05-22 13:34:04 [INFO]: Epoch 006 - training loss: 0.5163, validation loss: 0.0363
2024-05-22 13:34:10 [INFO]: Epoch 007 - training loss: 0.4892, validation loss: 0.0363
2024-05-22 13:34:16 [INFO]: Epoch 008 - training loss: 0.4646, validation loss: 0.0342
2024-05-22 13:34:22 [INFO]: Epoch 009 - training loss: 0.4511, validation loss: 0.0310
2024-05-22 13:34:28 [INFO]: Epoch 010 - training loss: 0.4540, validation loss: 0.0293
2024-05-22 13:34:34 [INFO]: Epoch 011 - training loss: 0.4393, validation loss: 0.0287
2024-05-22 13:34:40 [INFO]: Epoch 012 - training loss: 0.4249, validation loss: 0.0280
2024-05-22 13:34:46 [INFO]: Epoch 013 - training loss: 0.4122, validation loss: 0.0270
2024-05-22 13:34:52 [INFO]: Epoch 014 - training loss: 0.4067, validation loss: 0.0270
2024-05-22 13:34:58 [INFO]: Epoch 015 - training loss: 0.4013, validation loss: 0.0257
2024-05-22 13:35:04 [INFO]: Epoch 016 - training loss: 0.4113, validation loss: 0.0254
2024-05-22 13:35:10 [INFO]: Epoch 017 - training loss: 0.4024, validation loss: 0.0260
2024-05-22 13:35:16 [INFO]: Epoch 018 - training loss: 0.4041, validation loss: 0.0263
2024-05-22 13:35:22 [INFO]: Epoch 019 - training loss: 0.4106, validation loss: 0.0259
2024-05-22 13:35:28 [INFO]: Epoch 020 - training loss: 0.4020, validation loss: 0.0264
2024-05-22 13:35:34 [INFO]: Epoch 021 - training loss: 0.3876, validation loss: 0.0254
2024-05-22 13:35:39 [INFO]: Epoch 022 - training loss: 0.3903, validation loss: 0.0255
2024-05-22 13:35:45 [INFO]: Epoch 023 - training loss: 0.4016, validation loss: 0.0256
2024-05-22 13:35:51 [INFO]: Epoch 024 - training loss: 0.3953, validation loss: 0.0258
2024-05-22 13:35:57 [INFO]: Epoch 025 - training loss: 0.3908, validation loss: 0.0256
2024-05-22 13:36:03 [INFO]: Epoch 026 - training loss: 0.3884, validation loss: 0.0258
2024-05-22 13:36:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:36:03 [INFO]: Finished training. The best model is from epoch#16.
2024-05-22 13:36:03 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_ettm1/20240522_T133326/BRITS.pypots
2024-05-22 13:36:04 [INFO]: BRITS on ETTm1: MAE=0.1358, MSE=0.0561
2024-05-22 13:36:04 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-22 13:36:04 [INFO]: Using the given device: cuda:0
2024-05-22 13:36:04 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604
2024-05-22 13:36:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/tensorboard
2024-05-22 13:36:04 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 13:36:06 [INFO]: Epoch 001 - training loss: 1.3995, validation loss: 1.2643
2024-05-22 13:36:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch1_loss1.264297068119049.pypots
2024-05-22 13:36:06 [INFO]: Epoch 002 - training loss: 1.0569, validation loss: 1.1363
2024-05-22 13:36:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch2_loss1.136343464255333.pypots
2024-05-22 13:36:07 [INFO]: Epoch 003 - training loss: 0.9752, validation loss: 1.0615
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch3_loss1.0614540576934814.pypots
2024-05-22 13:36:07 [INFO]: Epoch 004 - training loss: 0.9358, validation loss: 1.0402
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch4_loss1.040195494890213.pypots
2024-05-22 13:36:07 [INFO]: Epoch 005 - training loss: 0.9426, validation loss: 1.0277
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch5_loss1.027700424194336.pypots
2024-05-22 13:36:07 [INFO]: Epoch 006 - training loss: 0.9010, validation loss: 1.0202
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch6_loss1.0201883018016815.pypots
2024-05-22 13:36:07 [INFO]: Epoch 007 - training loss: 0.8890, validation loss: 1.0089
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch7_loss1.0088518261909485.pypots
2024-05-22 13:36:07 [INFO]: Epoch 008 - training loss: 0.8850, validation loss: 0.9999
2024-05-22 13:36:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch8_loss0.9998588562011719.pypots
2024-05-22 13:36:08 [INFO]: Epoch 009 - training loss: 0.9052, validation loss: 0.9955
2024-05-22 13:36:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch9_loss0.995498850941658.pypots
2024-05-22 13:36:08 [INFO]: Epoch 010 - training loss: 0.8924, validation loss: 0.9871
2024-05-22 13:36:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch10_loss0.9870640635490417.pypots
2024-05-22 13:36:08 [INFO]: Epoch 011 - training loss: 0.8924, validation loss: 0.9820
2024-05-22 13:36:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch11_loss0.9820185303688049.pypots
2024-05-22 13:36:08 [INFO]: Epoch 012 - training loss: 0.8583, validation loss: 0.9783
2024-05-22 13:36:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch12_loss0.9782569259405136.pypots
2024-05-22 13:36:08 [INFO]: Epoch 013 - training loss: 0.8725, validation loss: 0.9781
2024-05-22 13:36:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch13_loss0.9780912101268768.pypots
2024-05-22 13:36:09 [INFO]: Epoch 014 - training loss: 0.8591, validation loss: 0.9755
2024-05-22 13:36:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch14_loss0.9754513949155807.pypots
2024-05-22 13:36:09 [INFO]: Epoch 015 - training loss: 0.8649, validation loss: 0.9731
2024-05-22 13:36:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch15_loss0.9731139540672302.pypots
2024-05-22 13:36:09 [INFO]: Epoch 016 - training loss: 0.8547, validation loss: 0.9676
2024-05-22 13:36:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch16_loss0.9675907790660858.pypots
2024-05-22 13:36:09 [INFO]: Epoch 017 - training loss: 0.8378, validation loss: 0.9636
2024-05-22 13:36:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch17_loss0.9635829478502274.pypots
2024-05-22 13:36:09 [INFO]: Epoch 018 - training loss: 0.8435, validation loss: 0.9600
2024-05-22 13:36:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch18_loss0.959983691573143.pypots
2024-05-22 13:36:10 [INFO]: Epoch 019 - training loss: 0.8387, validation loss: 0.9574
2024-05-22 13:36:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch19_loss0.9573761224746704.pypots
2024-05-22 13:36:10 [INFO]: Epoch 020 - training loss: 0.8340, validation loss: 0.9532
2024-05-22 13:36:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch20_loss0.9531503915786743.pypots
2024-05-22 13:36:10 [INFO]: Epoch 021 - training loss: 0.8437, validation loss: 0.9472
2024-05-22 13:36:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch21_loss0.9472105354070663.pypots
2024-05-22 13:36:10 [INFO]: Epoch 022 - training loss: 0.8373, validation loss: 0.9455
2024-05-22 13:36:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch22_loss0.945511668920517.pypots
2024-05-22 13:36:10 [INFO]: Epoch 023 - training loss: 0.8362, validation loss: 0.9428
2024-05-22 13:36:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch23_loss0.9427994340658188.pypots
2024-05-22 13:36:11 [INFO]: Epoch 024 - training loss: 0.8404, validation loss: 0.9367
2024-05-22 13:36:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch24_loss0.9366689622402191.pypots
2024-05-22 13:36:11 [INFO]: Epoch 025 - training loss: 0.8186, validation loss: 0.9331
2024-05-22 13:36:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch25_loss0.9331268221139908.pypots
2024-05-22 13:36:11 [INFO]: Epoch 026 - training loss: 0.8162, validation loss: 0.9274
2024-05-22 13:36:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch26_loss0.9274424761533737.pypots
2024-05-22 13:36:11 [INFO]: Epoch 027 - training loss: 0.8334, validation loss: 0.9230
2024-05-22 13:36:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch27_loss0.9229679256677628.pypots
2024-05-22 13:36:11 [INFO]: Epoch 028 - training loss: 0.8153, validation loss: 0.9207
2024-05-22 13:36:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch28_loss0.9207363128662109.pypots
2024-05-22 13:36:12 [INFO]: Epoch 029 - training loss: 0.8056, validation loss: 0.9183
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch29_loss0.9182923287153244.pypots
2024-05-22 13:36:12 [INFO]: Epoch 030 - training loss: 0.7965, validation loss: 0.9155
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch30_loss0.9154769778251648.pypots
2024-05-22 13:36:12 [INFO]: Epoch 031 - training loss: 0.7987, validation loss: 0.9150
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch31_loss0.9150246828794479.pypots
2024-05-22 13:36:12 [INFO]: Epoch 032 - training loss: 0.8277, validation loss: 0.9126
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch32_loss0.9125686883926392.pypots
2024-05-22 13:36:12 [INFO]: Epoch 033 - training loss: 0.8212, validation loss: 0.9135
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch33_loss0.9135404825210571.pypots
2024-05-22 13:36:12 [INFO]: Epoch 034 - training loss: 0.8034, validation loss: 0.9105
2024-05-22 13:36:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch34_loss0.9105058759450912.pypots
2024-05-22 13:36:13 [INFO]: Epoch 035 - training loss: 0.8088, validation loss: 0.9068
2024-05-22 13:36:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch35_loss0.9068449884653091.pypots
2024-05-22 13:36:13 [INFO]: Epoch 036 - training loss: 0.8013, validation loss: 0.9059
2024-05-22 13:36:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch36_loss0.9059174209833145.pypots
2024-05-22 13:36:13 [INFO]: Epoch 037 - training loss: 0.8030, validation loss: 0.9036
2024-05-22 13:36:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch37_loss0.9036175757646561.pypots
2024-05-22 13:36:13 [INFO]: Epoch 038 - training loss: 0.7995, validation loss: 0.9020
2024-05-22 13:36:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch38_loss0.9020010828971863.pypots
2024-05-22 13:36:13 [INFO]: Epoch 039 - training loss: 0.8098, validation loss: 0.9024
2024-05-22 13:36:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch39_loss0.9023618549108505.pypots
2024-05-22 13:36:14 [INFO]: Epoch 040 - training loss: 0.7816, validation loss: 0.9040
2024-05-22 13:36:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch40_loss0.9040108025074005.pypots
2024-05-22 13:36:14 [INFO]: Epoch 041 - training loss: 0.7828, validation loss: 0.8978
2024-05-22 13:36:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch41_loss0.8978345096111298.pypots
2024-05-22 13:36:14 [INFO]: Epoch 042 - training loss: 0.7968, validation loss: 0.8968
2024-05-22 13:36:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch42_loss0.8968022614717484.pypots
2024-05-22 13:36:14 [INFO]: Epoch 043 - training loss: 0.8048, validation loss: 0.8975
2024-05-22 13:36:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch43_loss0.8975169658660889.pypots
2024-05-22 13:36:14 [INFO]: Epoch 044 - training loss: 0.7975, validation loss: 0.8973
2024-05-22 13:36:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch44_loss0.8972661346197128.pypots
2024-05-22 13:36:15 [INFO]: Epoch 045 - training loss: 0.7953, validation loss: 0.9001
2024-05-22 13:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch45_loss0.9001425057649612.pypots
2024-05-22 13:36:15 [INFO]: Epoch 046 - training loss: 0.8018, validation loss: 0.8967
2024-05-22 13:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch46_loss0.8967248797416687.pypots
2024-05-22 13:36:15 [INFO]: Epoch 047 - training loss: 0.7955, validation loss: 0.8926
2024-05-22 13:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch47_loss0.8926232308149338.pypots
2024-05-22 13:36:15 [INFO]: Epoch 048 - training loss: 0.7857, validation loss: 0.8933
2024-05-22 13:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch48_loss0.8932797312736511.pypots
2024-05-22 13:36:15 [INFO]: Epoch 049 - training loss: 0.8443, validation loss: 0.8954
2024-05-22 13:36:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch49_loss0.8954439610242844.pypots
2024-05-22 13:36:16 [INFO]: Epoch 050 - training loss: 0.8090, validation loss: 0.8956
2024-05-22 13:36:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch50_loss0.8955882489681244.pypots
2024-05-22 13:36:16 [INFO]: Epoch 051 - training loss: 0.8204, validation loss: 0.8937
2024-05-22 13:36:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch51_loss0.8937359601259232.pypots
2024-05-22 13:36:16 [INFO]: Epoch 052 - training loss: 0.7811, validation loss: 0.8956
2024-05-22 13:36:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch52_loss0.8956033140420914.pypots
2024-05-22 13:36:16 [INFO]: Epoch 053 - training loss: 0.7944, validation loss: 0.8953
2024-05-22 13:36:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch53_loss0.8952973783016205.pypots
2024-05-22 13:36:16 [INFO]: Epoch 054 - training loss: 0.7776, validation loss: 0.8993
2024-05-22 13:36:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch54_loss0.8993132412433624.pypots
2024-05-22 13:36:16 [INFO]: Epoch 055 - training loss: 0.7705, validation loss: 0.8955
2024-05-22 13:36:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch55_loss0.895500123500824.pypots
2024-05-22 13:36:17 [INFO]: Epoch 056 - training loss: 0.7876, validation loss: 0.8951
2024-05-22 13:36:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch56_loss0.8951450139284134.pypots
2024-05-22 13:36:17 [INFO]: Epoch 057 - training loss: 0.7926, validation loss: 0.8960
2024-05-22 13:36:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN_epoch57_loss0.8959603160619736.pypots
2024-05-22 13:36:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:36:17 [INFO]: Finished training. The best model is from epoch#47.
2024-05-22 13:36:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240522_T133604/MRNN.pypots
2024-05-22 13:36:17 [INFO]: MRNN on ETTm1: MAE=0.8904, MSE=1.6894
2024-05-22 13:36:17 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-22 13:36:17 [INFO]: Using the given device: cpu
2024-05-22 13:36:17 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 13:36:17 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-22 13:36:17 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-22 13:36:17 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 13:36:17 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-22 13:36:17 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-22 13:36:17 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 13:36:17 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-22 13:36:17 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-22 13:36:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 13:36:17 [INFO]: Using the given device: cuda:0
2024-05-22 13:36:17 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240522_T133617
2024-05-22 13:36:17 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240522_T133617/tensorboard
2024-05-22 13:36:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 13:36:18 [INFO]: Epoch 001 - training loss: 1.1774, validation loss: 0.2645
2024-05-22 13:36:18 [INFO]: Epoch 002 - training loss: 0.9188, validation loss: 0.1336
2024-05-22 13:36:19 [INFO]: Epoch 003 - training loss: 0.8135, validation loss: 0.1067
2024-05-22 13:36:19 [INFO]: Epoch 004 - training loss: 0.7639, validation loss: 0.0948
2024-05-22 13:36:20 [INFO]: Epoch 005 - training loss: 0.7217, validation loss: 0.0829
2024-05-22 13:36:21 [INFO]: Epoch 006 - training loss: 0.7012, validation loss: 0.0778
2024-05-22 13:36:21 [INFO]: Epoch 007 - training loss: 0.6756, validation loss: 0.0683
2024-05-22 13:36:22 [INFO]: Epoch 008 - training loss: 0.6639, validation loss: 0.0832
2024-05-22 13:36:22 [INFO]: Epoch 009 - training loss: 0.6457, validation loss: 0.0964
2024-05-22 13:36:23 [INFO]: Epoch 010 - training loss: 0.6520, validation loss: 0.0729
2024-05-22 13:36:23 [INFO]: Epoch 011 - training loss: 0.6300, validation loss: 0.0712
2024-05-22 13:36:24 [INFO]: Epoch 012 - training loss: 0.6313, validation loss: 0.0762
2024-05-22 13:36:24 [INFO]: Epoch 013 - training loss: 0.6153, validation loss: 0.0621
2024-05-22 13:36:25 [INFO]: Epoch 014 - training loss: 0.6028, validation loss: 0.0653
2024-05-22 13:36:25 [INFO]: Epoch 015 - training loss: 0.6167, validation loss: 0.0648
2024-05-22 13:36:26 [INFO]: Epoch 016 - training loss: 0.6046, validation loss: 0.0626
2024-05-22 13:36:26 [INFO]: Epoch 017 - training loss: 0.5776, validation loss: 0.0677
2024-05-22 13:36:27 [INFO]: Epoch 018 - training loss: 0.5814, validation loss: 0.0580
2024-05-22 13:36:27 [INFO]: Epoch 019 - training loss: 0.6001, validation loss: 0.0734
2024-05-22 13:36:28 [INFO]: Epoch 020 - training loss: 0.5904, validation loss: 0.0619
2024-05-22 13:36:28 [INFO]: Epoch 021 - training loss: 0.5660, validation loss: 0.0468
2024-05-22 13:36:29 [INFO]: Epoch 022 - training loss: 0.5520, validation loss: 0.0613
2024-05-22 13:36:29 [INFO]: Epoch 023 - training loss: 0.5810, validation loss: 0.0608
2024-05-22 13:36:30 [INFO]: Epoch 024 - training loss: 0.5554, validation loss: 0.0580
2024-05-22 13:36:30 [INFO]: Epoch 025 - training loss: 0.5637, validation loss: 0.0715
2024-05-22 13:36:31 [INFO]: Epoch 026 - training loss: 0.5730, validation loss: 0.0781
2024-05-22 13:36:31 [INFO]: Epoch 027 - training loss: 0.5466, validation loss: 0.0561
2024-05-22 13:36:32 [INFO]: Epoch 028 - training loss: 0.5536, validation loss: 0.0427
2024-05-22 13:36:32 [INFO]: Epoch 029 - training loss: 0.5337, validation loss: 0.0543
2024-05-22 13:36:33 [INFO]: Epoch 030 - training loss: 0.5517, validation loss: 0.0634
2024-05-22 13:36:33 [INFO]: Epoch 031 - training loss: 0.5367, validation loss: 0.0488
2024-05-22 13:36:34 [INFO]: Epoch 032 - training loss: 0.5126, validation loss: 0.0342
2024-05-22 13:36:34 [INFO]: Epoch 033 - training loss: 0.5201, validation loss: 0.0369
2024-05-22 13:36:35 [INFO]: Epoch 034 - training loss: 0.5067, validation loss: 0.0336
2024-05-22 13:36:35 [INFO]: Epoch 035 - training loss: 0.5057, validation loss: 0.0405
2024-05-22 13:36:36 [INFO]: Epoch 036 - training loss: 0.5038, validation loss: 0.0376
2024-05-22 13:36:36 [INFO]: Epoch 037 - training loss: 0.5012, validation loss: 0.0381
2024-05-22 13:36:37 [INFO]: Epoch 038 - training loss: 0.4986, validation loss: 0.0347
2024-05-22 13:36:37 [INFO]: Epoch 039 - training loss: 0.5017, validation loss: 0.0417
2024-05-22 13:36:38 [INFO]: Epoch 040 - training loss: 0.5210, validation loss: 0.0466
2024-05-22 13:36:38 [INFO]: Epoch 041 - training loss: 0.5197, validation loss: 0.0723
2024-05-22 13:36:39 [INFO]: Epoch 042 - training loss: 0.4997, validation loss: 0.0372
2024-05-22 13:36:39 [INFO]: Epoch 043 - training loss: 0.5131, validation loss: 0.0466
2024-05-22 13:36:40 [INFO]: Epoch 044 - training loss: 0.5102, validation loss: 0.0440
2024-05-22 13:36:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:36:40 [INFO]: Finished training. The best model is from epoch#34.
2024-05-22 13:36:40 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_ettm1/20240522_T133617/SAITS.pypots
2024-05-22 13:36:40 [INFO]: SAITS on ETTm1: MAE=0.1557, MSE=0.0486
2024-05-22 13:36:40 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-22 13:36:40 [INFO]: Using the given device: cuda:0
2024-05-22 13:36:40 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240522_T133640
2024-05-22 13:36:40 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240522_T133640/tensorboard
2024-05-22 13:36:40 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 13:36:40 [INFO]: Epoch 001 - training loss: 1.1768, validation loss: 0.3489
2024-05-22 13:36:41 [INFO]: Epoch 002 - training loss: 0.7456, validation loss: 0.1865
2024-05-22 13:36:41 [INFO]: Epoch 003 - training loss: 0.6166, validation loss: 0.1189
2024-05-22 13:36:41 [INFO]: Epoch 004 - training loss: 0.5456, validation loss: 0.0916
2024-05-22 13:36:41 [INFO]: Epoch 005 - training loss: 0.4994, validation loss: 0.0756
2024-05-22 13:36:41 [INFO]: Epoch 006 - training loss: 0.4702, validation loss: 0.0742
2024-05-22 13:36:42 [INFO]: Epoch 007 - training loss: 0.4400, validation loss: 0.0625
2024-05-22 13:36:42 [INFO]: Epoch 008 - training loss: 0.4250, validation loss: 0.0585
2024-05-22 13:36:42 [INFO]: Epoch 009 - training loss: 0.4080, validation loss: 0.0553
2024-05-22 13:36:42 [INFO]: Epoch 010 - training loss: 0.3920, validation loss: 0.0529
2024-05-22 13:36:42 [INFO]: Epoch 011 - training loss: 0.3814, validation loss: 0.0517
2024-05-22 13:36:43 [INFO]: Epoch 012 - training loss: 0.3741, validation loss: 0.0641
2024-05-22 13:36:43 [INFO]: Epoch 013 - training loss: 0.3658, validation loss: 0.0497
2024-05-22 13:36:43 [INFO]: Epoch 014 - training loss: 0.3627, validation loss: 0.0523
2024-05-22 13:36:43 [INFO]: Epoch 015 - training loss: 0.3587, validation loss: 0.0435
2024-05-22 13:36:44 [INFO]: Epoch 016 - training loss: 0.3484, validation loss: 0.0460
2024-05-22 13:36:44 [INFO]: Epoch 017 - training loss: 0.3395, validation loss: 0.0403
2024-05-22 13:36:44 [INFO]: Epoch 018 - training loss: 0.3369, validation loss: 0.0434
2024-05-22 13:36:44 [INFO]: Epoch 019 - training loss: 0.3323, validation loss: 0.0628
2024-05-22 13:36:44 [INFO]: Epoch 020 - training loss: 0.3374, validation loss: 0.0413
2024-05-22 13:36:45 [INFO]: Epoch 021 - training loss: 0.3270, validation loss: 0.0395
2024-05-22 13:36:45 [INFO]: Epoch 022 - training loss: 0.3135, validation loss: 0.0395
2024-05-22 13:36:45 [INFO]: Epoch 023 - training loss: 0.3213, validation loss: 0.0396
2024-05-22 13:36:45 [INFO]: Epoch 024 - training loss: 0.3055, validation loss: 0.0376
2024-05-22 13:36:46 [INFO]: Epoch 025 - training loss: 0.3070, validation loss: 0.0360
2024-05-22 13:36:46 [INFO]: Epoch 026 - training loss: 0.3027, validation loss: 0.0376
2024-05-22 13:36:46 [INFO]: Epoch 027 - training loss: 0.3089, validation loss: 0.0381
2024-05-22 13:36:46 [INFO]: Epoch 028 - training loss: 0.3005, validation loss: 0.0383
2024-05-22 13:36:46 [INFO]: Epoch 029 - training loss: 0.2935, validation loss: 0.0391
2024-05-22 13:36:47 [INFO]: Epoch 030 - training loss: 0.2907, validation loss: 0.0319
2024-05-22 13:36:47 [INFO]: Epoch 031 - training loss: 0.2818, validation loss: 0.0342
2024-05-22 13:36:47 [INFO]: Epoch 032 - training loss: 0.2818, validation loss: 0.0376
2024-05-22 13:36:47 [INFO]: Epoch 033 - training loss: 0.2791, validation loss: 0.0372
2024-05-22 13:36:47 [INFO]: Epoch 034 - training loss: 0.2792, validation loss: 0.0338
2024-05-22 13:36:48 [INFO]: Epoch 035 - training loss: 0.2744, validation loss: 0.0330
2024-05-22 13:36:48 [INFO]: Epoch 036 - training loss: 0.2692, validation loss: 0.0330
2024-05-22 13:36:48 [INFO]: Epoch 037 - training loss: 0.2664, validation loss: 0.0325
2024-05-22 13:36:48 [INFO]: Epoch 038 - training loss: 0.2628, validation loss: 0.0280
2024-05-22 13:36:49 [INFO]: Epoch 039 - training loss: 0.2594, validation loss: 0.0281
2024-05-22 13:36:49 [INFO]: Epoch 040 - training loss: 0.2589, validation loss: 0.0290
2024-05-22 13:36:49 [INFO]: Epoch 041 - training loss: 0.2570, validation loss: 0.0301
2024-05-22 13:36:49 [INFO]: Epoch 042 - training loss: 0.2621, validation loss: 0.0282
2024-05-22 13:36:49 [INFO]: Epoch 043 - training loss: 0.2549, validation loss: 0.0275
2024-05-22 13:36:50 [INFO]: Epoch 044 - training loss: 0.2516, validation loss: 0.0291
2024-05-22 13:36:50 [INFO]: Epoch 045 - training loss: 0.2535, validation loss: 0.0327
2024-05-22 13:36:50 [INFO]: Epoch 046 - training loss: 0.2523, validation loss: 0.0278
2024-05-22 13:36:50 [INFO]: Epoch 047 - training loss: 0.2444, validation loss: 0.0289
2024-05-22 13:36:51 [INFO]: Epoch 048 - training loss: 0.2441, validation loss: 0.0303
2024-05-22 13:36:51 [INFO]: Epoch 049 - training loss: 0.2446, validation loss: 0.0321
2024-05-22 13:36:51 [INFO]: Epoch 050 - training loss: 0.2398, validation loss: 0.0296
2024-05-22 13:36:51 [INFO]: Epoch 051 - training loss: 0.2367, validation loss: 0.0341
2024-05-22 13:36:51 [INFO]: Epoch 052 - training loss: 0.2455, validation loss: 0.0355
2024-05-22 13:36:52 [INFO]: Epoch 053 - training loss: 0.2578, validation loss: 0.0301
2024-05-22 13:36:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:36:52 [INFO]: Finished training. The best model is from epoch#43.
2024-05-22 13:36:52 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_ettm1/20240522_T133640/Transformer.pypots
2024-05-22 13:36:52 [INFO]: Transformer on ETTm1: MAE=0.1779, MSE=0.0535
2024-05-22 13:36:52 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-22 13:36:52 [INFO]: Using the given device: cuda:0
2024-05-22 13:36:52 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240522_T133652
2024-05-22 13:36:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240522_T133652/tensorboard
2024-05-22 13:36:52 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 13:36:52 [INFO]: Epoch 001 - training loss: 0.1721, validation loss: 0.0588
2024-05-22 13:36:52 [INFO]: Epoch 002 - training loss: 0.0705, validation loss: 0.0452
2024-05-22 13:36:53 [INFO]: Epoch 003 - training loss: 0.0571, validation loss: 0.0392
2024-05-22 13:36:53 [INFO]: Epoch 004 - training loss: 0.0564, validation loss: 0.0340
2024-05-22 13:36:53 [INFO]: Epoch 005 - training loss: 0.0522, validation loss: 0.0344
2024-05-22 13:36:53 [INFO]: Epoch 006 - training loss: 0.0470, validation loss: 0.0320
2024-05-22 13:36:53 [INFO]: Epoch 007 - training loss: 0.0474, validation loss: 0.0318
2024-05-22 13:36:54 [INFO]: Epoch 008 - training loss: 0.0457, validation loss: 0.0324
2024-05-22 13:36:54 [INFO]: Epoch 009 - training loss: 0.0480, validation loss: 0.0335
2024-05-22 13:36:54 [INFO]: Epoch 010 - training loss: 0.0482, validation loss: 0.0367
2024-05-22 13:36:54 [INFO]: Epoch 011 - training loss: 0.0497, validation loss: 0.0332
2024-05-22 13:36:54 [INFO]: Epoch 012 - training loss: 0.0469, validation loss: 0.0342
2024-05-22 13:36:55 [INFO]: Epoch 013 - training loss: 0.0530, validation loss: 0.0340
2024-05-22 13:36:55 [INFO]: Epoch 014 - training loss: 0.0488, validation loss: 0.0331
2024-05-22 13:36:55 [INFO]: Epoch 015 - training loss: 0.0446, validation loss: 0.0322
2024-05-22 13:36:55 [INFO]: Epoch 016 - training loss: 0.0433, validation loss: 0.0333
2024-05-22 13:36:55 [INFO]: Epoch 017 - training loss: 0.0440, validation loss: 0.0322
2024-05-22 13:36:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:36:55 [INFO]: Finished training. The best model is from epoch#7.
2024-05-22 13:36:56 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_ettm1/20240522_T133652/TimesNet.pypots
2024-05-22 13:36:56 [INFO]: TimesNet on ETTm1: MAE=0.1256, MSE=0.0330
2024-05-22 13:36:56 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-22 13:36:56 [INFO]: Using the given device: cuda:0
2024-05-22 13:36:56 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656
2024-05-22 13:36:56 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/tensorboard
2024-05-22 13:36:56 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 13:36:58 [INFO]: Epoch 001 - training loss: 0.7101, validation loss: 0.4778
2024-05-22 13:36:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch1_loss0.4777671992778778.pypots
2024-05-22 13:37:00 [INFO]: Epoch 002 - training loss: 0.4207, validation loss: 0.3774
2024-05-22 13:37:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch2_loss0.3774099797010422.pypots
2024-05-22 13:37:02 [INFO]: Epoch 003 - training loss: 0.3467, validation loss: 0.3296
2024-05-22 13:37:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch3_loss0.32957823574543.pypots
2024-05-22 13:37:04 [INFO]: Epoch 004 - training loss: 0.3538, validation loss: 0.3188
2024-05-22 13:37:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch4_loss0.31883981078863144.pypots
2024-05-22 13:37:06 [INFO]: Epoch 005 - training loss: 0.2673, validation loss: 0.2855
2024-05-22 13:37:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch5_loss0.28545180708169937.pypots
2024-05-22 13:37:08 [INFO]: Epoch 006 - training loss: 0.2872, validation loss: 0.2907
2024-05-22 13:37:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch6_loss0.2907336577773094.pypots
2024-05-22 13:37:10 [INFO]: Epoch 007 - training loss: 0.3393, validation loss: 0.2839
2024-05-22 13:37:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch7_loss0.2838715612888336.pypots
2024-05-22 13:37:12 [INFO]: Epoch 008 - training loss: 0.2878, validation loss: 0.2663
2024-05-22 13:37:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch8_loss0.2663455381989479.pypots
2024-05-22 13:37:14 [INFO]: Epoch 009 - training loss: 0.2708, validation loss: 0.2629
2024-05-22 13:37:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch9_loss0.262897253036499.pypots
2024-05-22 13:37:16 [INFO]: Epoch 010 - training loss: 0.2635, validation loss: 0.2546
2024-05-22 13:37:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch10_loss0.25458071753382683.pypots
2024-05-22 13:37:18 [INFO]: Epoch 011 - training loss: 0.2750, validation loss: 0.2424
2024-05-22 13:37:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch11_loss0.24243520945310593.pypots
2024-05-22 13:37:21 [INFO]: Epoch 012 - training loss: 0.2383, validation loss: 0.2298
2024-05-22 13:37:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch12_loss0.22976110875606537.pypots
2024-05-22 13:37:23 [INFO]: Epoch 013 - training loss: 0.2230, validation loss: 0.2237
2024-05-22 13:37:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch13_loss0.2237195298075676.pypots
2024-05-22 13:37:25 [INFO]: Epoch 014 - training loss: 0.2465, validation loss: 0.2265
2024-05-22 13:37:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch14_loss0.2264580987393856.pypots
2024-05-22 13:37:27 [INFO]: Epoch 015 - training loss: 0.2469, validation loss: 0.2320
2024-05-22 13:37:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch15_loss0.2320101223886013.pypots
2024-05-22 13:37:29 [INFO]: Epoch 016 - training loss: 0.2258, validation loss: 0.2227
2024-05-22 13:37:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch16_loss0.22268887236714363.pypots
2024-05-22 13:37:31 [INFO]: Epoch 017 - training loss: 0.2357, validation loss: 0.2134
2024-05-22 13:37:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch17_loss0.21339858695864677.pypots
2024-05-22 13:37:33 [INFO]: Epoch 018 - training loss: 0.2063, validation loss: 0.2172
2024-05-22 13:37:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch18_loss0.21717338263988495.pypots
2024-05-22 13:37:35 [INFO]: Epoch 019 - training loss: 0.2577, validation loss: 0.2216
2024-05-22 13:37:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch19_loss0.22160594165325165.pypots
2024-05-22 13:37:37 [INFO]: Epoch 020 - training loss: 0.2511, validation loss: 0.2156
2024-05-22 13:37:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch20_loss0.21563612297177315.pypots
2024-05-22 13:37:39 [INFO]: Epoch 021 - training loss: 0.2191, validation loss: 0.2082
2024-05-22 13:37:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch21_loss0.20819056406617165.pypots
2024-05-22 13:37:41 [INFO]: Epoch 022 - training loss: 0.2142, validation loss: 0.1941
2024-05-22 13:37:41 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch22_loss0.19413144886493683.pypots
2024-05-22 13:37:44 [INFO]: Epoch 023 - training loss: 0.2221, validation loss: 0.2054
2024-05-22 13:37:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch23_loss0.20544689148664474.pypots
2024-05-22 13:37:46 [INFO]: Epoch 024 - training loss: 0.2322, validation loss: 0.2038
2024-05-22 13:37:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch24_loss0.2037757858633995.pypots
2024-05-22 13:37:48 [INFO]: Epoch 025 - training loss: 0.2625, validation loss: 0.1959
2024-05-22 13:37:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch25_loss0.1959257461130619.pypots
2024-05-22 13:37:50 [INFO]: Epoch 026 - training loss: 0.2111, validation loss: 0.1940
2024-05-22 13:37:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch26_loss0.19403276219964027.pypots
2024-05-22 13:37:52 [INFO]: Epoch 027 - training loss: 0.2100, validation loss: 0.1904
2024-05-22 13:37:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch27_loss0.19038142263889313.pypots
2024-05-22 13:37:54 [INFO]: Epoch 028 - training loss: 0.1946, validation loss: 0.1813
2024-05-22 13:37:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch28_loss0.18126781284809113.pypots
2024-05-22 13:37:56 [INFO]: Epoch 029 - training loss: 0.1912, validation loss: 0.1796
2024-05-22 13:37:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch29_loss0.1796232871711254.pypots
2024-05-22 13:37:58 [INFO]: Epoch 030 - training loss: 0.1780, validation loss: 0.1834
2024-05-22 13:37:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch30_loss0.1834084838628769.pypots
2024-05-22 13:38:00 [INFO]: Epoch 031 - training loss: 0.1598, validation loss: 0.1767
2024-05-22 13:38:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch31_loss0.1767088919878006.pypots
2024-05-22 13:38:02 [INFO]: Epoch 032 - training loss: 0.1898, validation loss: 0.1729
2024-05-22 13:38:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch32_loss0.17291180416941643.pypots
2024-05-22 13:38:04 [INFO]: Epoch 033 - training loss: 0.1883, validation loss: 0.1791
2024-05-22 13:38:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch33_loss0.1790848784148693.pypots
2024-05-22 13:38:06 [INFO]: Epoch 034 - training loss: 0.1680, validation loss: 0.1730
2024-05-22 13:38:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch34_loss0.17298508062958717.pypots
2024-05-22 13:38:09 [INFO]: Epoch 035 - training loss: 0.1952, validation loss: 0.1743
2024-05-22 13:38:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch35_loss0.17425063624978065.pypots
2024-05-22 13:38:11 [INFO]: Epoch 036 - training loss: 0.1809, validation loss: 0.1718
2024-05-22 13:38:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch36_loss0.1717611514031887.pypots
2024-05-22 13:38:13 [INFO]: Epoch 037 - training loss: 0.1948, validation loss: 0.1933
2024-05-22 13:38:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch37_loss0.1932520680129528.pypots
2024-05-22 13:38:15 [INFO]: Epoch 038 - training loss: 0.1646, validation loss: 0.1645
2024-05-22 13:38:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch38_loss0.16453279554843903.pypots
2024-05-22 13:38:17 [INFO]: Epoch 039 - training loss: 0.2363, validation loss: 0.1689
2024-05-22 13:38:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch39_loss0.1689024306833744.pypots
2024-05-22 13:38:19 [INFO]: Epoch 040 - training loss: 0.1572, validation loss: 0.1604
2024-05-22 13:38:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch40_loss0.1604371853172779.pypots
2024-05-22 13:38:21 [INFO]: Epoch 041 - training loss: 0.1640, validation loss: 0.1567
2024-05-22 13:38:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch41_loss0.15672114118933678.pypots
2024-05-22 13:38:23 [INFO]: Epoch 042 - training loss: 0.2019, validation loss: 0.1666
2024-05-22 13:38:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch42_loss0.166634663939476.pypots
2024-05-22 13:38:25 [INFO]: Epoch 043 - training loss: 0.2068, validation loss: 0.1716
2024-05-22 13:38:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch43_loss0.17156484350562096.pypots
2024-05-22 13:38:27 [INFO]: Epoch 044 - training loss: 0.2660, validation loss: 0.2226
2024-05-22 13:38:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch44_loss0.22260580956935883.pypots
2024-05-22 13:38:29 [INFO]: Epoch 045 - training loss: 0.2787, validation loss: 0.2308
2024-05-22 13:38:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch45_loss0.23080363124608994.pypots
2024-05-22 13:38:31 [INFO]: Epoch 046 - training loss: 0.2219, validation loss: 0.1991
2024-05-22 13:38:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch46_loss0.19912463799118996.pypots
2024-05-22 13:38:34 [INFO]: Epoch 047 - training loss: 0.1891, validation loss: 0.1899
2024-05-22 13:38:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch47_loss0.18993808701634407.pypots
2024-05-22 13:38:36 [INFO]: Epoch 048 - training loss: 0.1978, validation loss: 0.1775
2024-05-22 13:38:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch48_loss0.1775016263127327.pypots
2024-05-22 13:38:38 [INFO]: Epoch 049 - training loss: 0.1774, validation loss: 0.1722
2024-05-22 13:38:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch49_loss0.1722489707171917.pypots
2024-05-22 13:38:40 [INFO]: Epoch 050 - training loss: 0.1724, validation loss: 0.1724
2024-05-22 13:38:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch50_loss0.17239254340529442.pypots
2024-05-22 13:38:42 [INFO]: Epoch 051 - training loss: 0.2874, validation loss: 0.4771
2024-05-22 13:38:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI_epoch51_loss0.4771348834037781.pypots
2024-05-22 13:38:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:38:42 [INFO]: Finished training. The best model is from epoch#41.
2024-05-22 13:38:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240522_T133656/CSDI.pypots
2024-05-22 13:38:58 [INFO]: CSDI on ETTm1: MAE=0.7893, MSE=6.4566
2024-05-22 13:38:58 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-22 13:38:58 [INFO]: Using the given device: cuda:0
2024-05-22 13:38:58 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240522_T133858
2024-05-22 13:38:58 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240522_T133858/tensorboard
2024-05-22 13:38:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 13:38:58 [INFO]: Epoch 001 - training loss: 23576.2383, validation loss: 0.9735
2024-05-22 13:38:58 [INFO]: Epoch 002 - training loss: 21371.9948, validation loss: 0.9625
2024-05-22 13:38:58 [INFO]: Epoch 003 - training loss: 19442.3875, validation loss: 0.9525
2024-05-22 13:38:58 [INFO]: Epoch 004 - training loss: 17422.6041, validation loss: 0.9298
2024-05-22 13:38:58 [INFO]: Epoch 005 - training loss: 15601.8419, validation loss: 0.8838
2024-05-22 13:38:59 [INFO]: Epoch 006 - training loss: 13991.0187, validation loss: 0.7958
2024-05-22 13:38:59 [INFO]: Epoch 007 - training loss: 12732.8146, validation loss: 0.6666
2024-05-22 13:38:59 [INFO]: Epoch 008 - training loss: 11997.8769, validation loss: 0.5497
2024-05-22 13:38:59 [INFO]: Epoch 009 - training loss: 11439.4843, validation loss: 0.4781
2024-05-22 13:38:59 [INFO]: Epoch 010 - training loss: 10866.1205, validation loss: 0.4495
2024-05-22 13:38:59 [INFO]: Epoch 011 - training loss: 10752.4157, validation loss: 0.4314
2024-05-22 13:38:59 [INFO]: Epoch 012 - training loss: 10404.7751, validation loss: 0.4185
2024-05-22 13:39:00 [INFO]: Epoch 013 - training loss: 10249.9698, validation loss: 0.3966
2024-05-22 13:39:00 [INFO]: Epoch 014 - training loss: 10141.8315, validation loss: 0.3737
2024-05-22 13:39:00 [INFO]: Epoch 015 - training loss: 10014.6133, validation loss: 0.3517
2024-05-22 13:39:00 [INFO]: Epoch 016 - training loss: 9882.6421, validation loss: 0.3234
2024-05-22 13:39:00 [INFO]: Epoch 017 - training loss: 9817.2216, validation loss: 0.3002
2024-05-22 13:39:00 [INFO]: Epoch 018 - training loss: 9763.8710, validation loss: 0.2706
2024-05-22 13:39:00 [INFO]: Epoch 019 - training loss: 9721.9471, validation loss: 0.2577
2024-05-22 13:39:01 [INFO]: Epoch 020 - training loss: 9664.2864, validation loss: 0.2415
2024-05-22 13:39:01 [INFO]: Epoch 021 - training loss: 9618.8907, validation loss: 0.2289
2024-05-22 13:39:01 [INFO]: Epoch 022 - training loss: 9597.3373, validation loss: 0.2216
2024-05-22 13:39:01 [INFO]: Epoch 023 - training loss: 9605.2914, validation loss: 0.2131
2024-05-22 13:39:01 [INFO]: Epoch 024 - training loss: 9551.5140, validation loss: 0.2066
2024-05-22 13:39:01 [INFO]: Epoch 025 - training loss: 9536.1754, validation loss: 0.1998
2024-05-22 13:39:01 [INFO]: Epoch 026 - training loss: 9525.4608, validation loss: 0.1947
2024-05-22 13:39:02 [INFO]: Epoch 027 - training loss: 9494.2935, validation loss: 0.1914
2024-05-22 13:39:02 [INFO]: Epoch 028 - training loss: 9485.4181, validation loss: 0.1866
2024-05-22 13:39:02 [INFO]: Epoch 029 - training loss: 9462.9642, validation loss: 0.1827
2024-05-22 13:39:02 [INFO]: Epoch 030 - training loss: 9448.7446, validation loss: 0.1786
2024-05-22 13:39:02 [INFO]: Epoch 031 - training loss: 9453.1562, validation loss: 0.1736
2024-05-22 13:39:02 [INFO]: Epoch 032 - training loss: 9434.9355, validation loss: 0.1706
2024-05-22 13:39:02 [INFO]: Epoch 033 - training loss: 9434.0861, validation loss: 0.1673
2024-05-22 13:39:02 [INFO]: Epoch 034 - training loss: 9413.4707, validation loss: 0.1601
2024-05-22 13:39:03 [INFO]: Epoch 035 - training loss: 9423.8464, validation loss: 0.1580
2024-05-22 13:39:03 [INFO]: Epoch 036 - training loss: 9400.5760, validation loss: 0.1546
2024-05-22 13:39:03 [INFO]: Epoch 037 - training loss: 9402.9494, validation loss: 0.1516
2024-05-22 13:39:03 [INFO]: Epoch 038 - training loss: 9384.8761, validation loss: 0.1501
2024-05-22 13:39:03 [INFO]: Epoch 039 - training loss: 9384.9449, validation loss: 0.1482
2024-05-22 13:39:03 [INFO]: Epoch 040 - training loss: 9377.3888, validation loss: 0.1468
2024-05-22 13:39:04 [INFO]: Epoch 041 - training loss: 9371.2166, validation loss: 0.1454
2024-05-22 13:39:04 [INFO]: Epoch 042 - training loss: 9373.1179, validation loss: 0.1430
2024-05-22 13:39:04 [INFO]: Epoch 043 - training loss: 9366.2934, validation loss: 0.1404
2024-05-22 13:39:04 [INFO]: Epoch 044 - training loss: 9359.3860, validation loss: 0.1397
2024-05-22 13:39:04 [INFO]: Epoch 045 - training loss: 9354.5311, validation loss: 0.1393
2024-05-22 13:39:04 [INFO]: Epoch 046 - training loss: 9353.4611, validation loss: 0.1379
2024-05-22 13:39:04 [INFO]: Epoch 047 - training loss: 9351.6670, validation loss: 0.1358
2024-05-22 13:39:04 [INFO]: Epoch 048 - training loss: 9348.0548, validation loss: 0.1338
2024-05-22 13:39:05 [INFO]: Epoch 049 - training loss: 9353.6800, validation loss: 0.1345
2024-05-22 13:39:05 [INFO]: Epoch 050 - training loss: 9345.7138, validation loss: 0.1311
2024-05-22 13:39:05 [INFO]: Epoch 051 - training loss: 9339.2191, validation loss: 0.1319
2024-05-22 13:39:05 [INFO]: Epoch 052 - training loss: 9337.4847, validation loss: 0.1313
2024-05-22 13:39:05 [INFO]: Epoch 053 - training loss: 9356.7706, validation loss: 0.1303
2024-05-22 13:39:05 [INFO]: Epoch 054 - training loss: 9333.0116, validation loss: 0.1282
2024-05-22 13:39:05 [INFO]: Epoch 055 - training loss: 9339.9460, validation loss: 0.1270
2024-05-22 13:39:06 [INFO]: Epoch 056 - training loss: 9325.3954, validation loss: 0.1274
2024-05-22 13:39:06 [INFO]: Epoch 057 - training loss: 9331.8898, validation loss: 0.1261
2024-05-22 13:39:06 [INFO]: Epoch 058 - training loss: 9323.5271, validation loss: 0.1252
2024-05-22 13:39:06 [INFO]: Epoch 059 - training loss: 9322.3854, validation loss: 0.1255
2024-05-22 13:39:06 [INFO]: Epoch 060 - training loss: 9319.9280, validation loss: 0.1239
2024-05-22 13:39:06 [INFO]: Epoch 061 - training loss: 9319.3646, validation loss: 0.1243
2024-05-22 13:39:06 [INFO]: Epoch 062 - training loss: 9319.0742, validation loss: 0.1222
2024-05-22 13:39:07 [INFO]: Epoch 063 - training loss: 9316.9022, validation loss: 0.1219
2024-05-22 13:39:07 [INFO]: Epoch 064 - training loss: 9317.9296, validation loss: 0.1211
2024-05-22 13:39:07 [INFO]: Epoch 065 - training loss: 9314.9976, validation loss: 0.1212
2024-05-22 13:39:07 [INFO]: Epoch 066 - training loss: 9312.4721, validation loss: 0.1208
2024-05-22 13:39:07 [INFO]: Epoch 067 - training loss: 9313.3054, validation loss: 0.1185
2024-05-22 13:39:07 [INFO]: Epoch 068 - training loss: 9312.2966, validation loss: 0.1195
2024-05-22 13:39:07 [INFO]: Epoch 069 - training loss: 9310.6166, validation loss: 0.1180
2024-05-22 13:39:07 [INFO]: Epoch 070 - training loss: 9311.0478, validation loss: 0.1188
2024-05-22 13:39:08 [INFO]: Epoch 071 - training loss: 9308.7579, validation loss: 0.1172
2024-05-22 13:39:08 [INFO]: Epoch 072 - training loss: 9309.3189, validation loss: 0.1173
2024-05-22 13:39:08 [INFO]: Epoch 073 - training loss: 9307.3570, validation loss: 0.1185
2024-05-22 13:39:08 [INFO]: Epoch 074 - training loss: 9307.2585, validation loss: 0.1156
2024-05-22 13:39:08 [INFO]: Epoch 075 - training loss: 9306.0773, validation loss: 0.1161
2024-05-22 13:39:08 [INFO]: Epoch 076 - training loss: 9303.5868, validation loss: 0.1147
2024-05-22 13:39:08 [INFO]: Epoch 077 - training loss: 9303.5626, validation loss: 0.1141
2024-05-22 13:39:09 [INFO]: Epoch 078 - training loss: 9301.4166, validation loss: 0.1141
2024-05-22 13:39:09 [INFO]: Epoch 079 - training loss: 9301.8600, validation loss: 0.1128
2024-05-22 13:39:09 [INFO]: Epoch 080 - training loss: 9302.6173, validation loss: 0.1130
2024-05-22 13:39:09 [INFO]: Epoch 081 - training loss: 9302.5216, validation loss: 0.1149
2024-05-22 13:39:09 [INFO]: Epoch 082 - training loss: 9301.0366, validation loss: 0.1108
2024-05-22 13:39:09 [INFO]: Epoch 083 - training loss: 9300.8809, validation loss: 0.1104
2024-05-22 13:39:09 [INFO]: Epoch 084 - training loss: 9300.9439, validation loss: 0.1115
2024-05-22 13:39:10 [INFO]: Epoch 085 - training loss: 9299.0253, validation loss: 0.1104
2024-05-22 13:39:10 [INFO]: Epoch 086 - training loss: 9297.7234, validation loss: 0.1111
2024-05-22 13:39:10 [INFO]: Epoch 087 - training loss: 9297.3105, validation loss: 0.1086
2024-05-22 13:39:10 [INFO]: Epoch 088 - training loss: 9298.7745, validation loss: 0.1075
2024-05-22 13:39:10 [INFO]: Epoch 089 - training loss: 9295.7357, validation loss: 0.1076
2024-05-22 13:39:10 [INFO]: Epoch 090 - training loss: 9297.8141, validation loss: 0.1067
2024-05-22 13:39:10 [INFO]: Epoch 091 - training loss: 9297.5274, validation loss: 0.1060
2024-05-22 13:39:10 [INFO]: Epoch 092 - training loss: 9296.5914, validation loss: 0.1056
2024-05-22 13:39:11 [INFO]: Epoch 093 - training loss: 9295.9067, validation loss: 0.1043
2024-05-22 13:39:11 [INFO]: Epoch 094 - training loss: 9294.9958, validation loss: 0.1061
2024-05-22 13:39:11 [INFO]: Epoch 095 - training loss: 9294.1757, validation loss: 0.1050
2024-05-22 13:39:11 [INFO]: Epoch 096 - training loss: 9293.9588, validation loss: 0.1033
2024-05-22 13:39:11 [INFO]: Epoch 097 - training loss: 9293.7022, validation loss: 0.1046
2024-05-22 13:39:11 [INFO]: Epoch 098 - training loss: 9291.8787, validation loss: 0.1039
2024-05-22 13:39:11 [INFO]: Epoch 099 - training loss: 9293.4948, validation loss: 0.1018
2024-05-22 13:39:12 [INFO]: Epoch 100 - training loss: 9289.9476, validation loss: 0.1034
2024-05-22 13:39:12 [INFO]: Epoch 101 - training loss: 9292.3503, validation loss: 0.1021
2024-05-22 13:39:12 [INFO]: Epoch 102 - training loss: 9288.0810, validation loss: 0.1008
2024-05-22 13:39:12 [INFO]: Epoch 103 - training loss: 9288.3001, validation loss: 0.1005
2024-05-22 13:39:12 [INFO]: Epoch 104 - training loss: 9288.5247, validation loss: 0.1013
2024-05-22 13:39:12 [INFO]: Epoch 105 - training loss: 9287.6400, validation loss: 0.1003
2024-05-22 13:39:12 [INFO]: Epoch 106 - training loss: 9289.9621, validation loss: 0.1008
2024-05-22 13:39:13 [INFO]: Epoch 107 - training loss: 9288.1041, validation loss: 0.0999
2024-05-22 13:39:13 [INFO]: Epoch 108 - training loss: 9290.7723, validation loss: 0.0987
2024-05-22 13:39:13 [INFO]: Epoch 109 - training loss: 9288.0693, validation loss: 0.0987
2024-05-22 13:39:13 [INFO]: Epoch 110 - training loss: 9287.7466, validation loss: 0.1005
2024-05-22 13:39:13 [INFO]: Epoch 111 - training loss: 9285.9482, validation loss: 0.0980
2024-05-22 13:39:13 [INFO]: Epoch 112 - training loss: 9287.6948, validation loss: 0.0985
2024-05-22 13:39:13 [INFO]: Epoch 113 - training loss: 9284.4232, validation loss: 0.0974
2024-05-22 13:39:13 [INFO]: Epoch 114 - training loss: 9286.1791, validation loss: 0.0963
2024-05-22 13:39:14 [INFO]: Epoch 115 - training loss: 9285.0255, validation loss: 0.0957
2024-05-22 13:39:14 [INFO]: Epoch 116 - training loss: 9285.2703, validation loss: 0.0958
2024-05-22 13:39:14 [INFO]: Epoch 117 - training loss: 9285.1083, validation loss: 0.0949
2024-05-22 13:39:14 [INFO]: Epoch 118 - training loss: 9284.7549, validation loss: 0.0942
2024-05-22 13:39:14 [INFO]: Epoch 119 - training loss: 9282.7850, validation loss: 0.0949
2024-05-22 13:39:14 [INFO]: Epoch 120 - training loss: 9283.7885, validation loss: 0.0945
2024-05-22 13:39:14 [INFO]: Epoch 121 - training loss: 9284.4542, validation loss: 0.0937
2024-05-22 13:39:15 [INFO]: Epoch 122 - training loss: 9286.0334, validation loss: 0.0940
2024-05-22 13:39:15 [INFO]: Epoch 123 - training loss: 9282.8217, validation loss: 0.0929
2024-05-22 13:39:15 [INFO]: Epoch 124 - training loss: 9284.2366, validation loss: 0.0942
2024-05-22 13:39:15 [INFO]: Epoch 125 - training loss: 9284.1440, validation loss: 0.0916
2024-05-22 13:39:15 [INFO]: Epoch 126 - training loss: 9283.3192, validation loss: 0.0907
2024-05-22 13:39:15 [INFO]: Epoch 127 - training loss: 9282.1860, validation loss: 0.0912
2024-05-22 13:39:15 [INFO]: Epoch 128 - training loss: 9283.4755, validation loss: 0.0904
2024-05-22 13:39:16 [INFO]: Epoch 129 - training loss: 9282.3357, validation loss: 0.0915
2024-05-22 13:39:16 [INFO]: Epoch 130 - training loss: 9281.1767, validation loss: 0.0903
2024-05-22 13:39:16 [INFO]: Epoch 131 - training loss: 9281.9425, validation loss: 0.0925
2024-05-22 13:39:16 [INFO]: Epoch 132 - training loss: 9280.3025, validation loss: 0.0905
2024-05-22 13:39:16 [INFO]: Epoch 133 - training loss: 9281.7410, validation loss: 0.0911
2024-05-22 13:39:16 [INFO]: Epoch 134 - training loss: 9282.6508, validation loss: 0.0901
2024-05-22 13:39:16 [INFO]: Epoch 135 - training loss: 9281.6043, validation loss: 0.0905
2024-05-22 13:39:16 [INFO]: Epoch 136 - training loss: 9281.2870, validation loss: 0.0884
2024-05-22 13:39:17 [INFO]: Epoch 137 - training loss: 9279.3630, validation loss: 0.0891
2024-05-22 13:39:17 [INFO]: Epoch 138 - training loss: 9280.0591, validation loss: 0.0886
2024-05-22 13:39:17 [INFO]: Epoch 139 - training loss: 9279.4985, validation loss: 0.0906
2024-05-22 13:39:17 [INFO]: Epoch 140 - training loss: 9280.6343, validation loss: 0.0888
2024-05-22 13:39:17 [INFO]: Epoch 141 - training loss: 9280.2448, validation loss: 0.0883
2024-05-22 13:39:17 [INFO]: Epoch 142 - training loss: 9280.3361, validation loss: 0.0869
2024-05-22 13:39:17 [INFO]: Epoch 143 - training loss: 9281.3766, validation loss: 0.0878
2024-05-22 13:39:18 [INFO]: Epoch 144 - training loss: 9279.5031, validation loss: 0.0873
2024-05-22 13:39:18 [INFO]: Epoch 145 - training loss: 9280.0574, validation loss: 0.0873
2024-05-22 13:39:18 [INFO]: Epoch 146 - training loss: 9280.9813, validation loss: 0.0899
2024-05-22 13:39:18 [INFO]: Epoch 147 - training loss: 9280.0489, validation loss: 0.0860
2024-05-22 13:39:18 [INFO]: Epoch 148 - training loss: 9279.1453, validation loss: 0.0892
2024-05-22 13:39:18 [INFO]: Epoch 149 - training loss: 9279.3532, validation loss: 0.0873
2024-05-22 13:39:18 [INFO]: Epoch 150 - training loss: 9277.5082, validation loss: 0.0866
2024-05-22 13:39:19 [INFO]: Epoch 151 - training loss: 9278.8589, validation loss: 0.0862
2024-05-22 13:39:19 [INFO]: Epoch 152 - training loss: 9278.6724, validation loss: 0.0848
2024-05-22 13:39:19 [INFO]: Epoch 153 - training loss: 9277.5998, validation loss: 0.0876
2024-05-22 13:39:19 [INFO]: Epoch 154 - training loss: 9278.4260, validation loss: 0.0859
2024-05-22 13:39:19 [INFO]: Epoch 155 - training loss: 9279.4698, validation loss: 0.0855
2024-05-22 13:39:19 [INFO]: Epoch 156 - training loss: 9278.5025, validation loss: 0.0848
2024-05-22 13:39:19 [INFO]: Epoch 157 - training loss: 9278.0420, validation loss: 0.0864
2024-05-22 13:39:19 [INFO]: Epoch 158 - training loss: 9278.7136, validation loss: 0.0828
2024-05-22 13:39:20 [INFO]: Epoch 159 - training loss: 9276.7408, validation loss: 0.0830
2024-05-22 13:39:20 [INFO]: Epoch 160 - training loss: 9277.6188, validation loss: 0.0841
2024-05-22 13:39:20 [INFO]: Epoch 161 - training loss: 9276.3081, validation loss: 0.0841
2024-05-22 13:39:20 [INFO]: Epoch 162 - training loss: 9276.2463, validation loss: 0.0841
2024-05-22 13:39:20 [INFO]: Epoch 163 - training loss: 9276.2671, validation loss: 0.0853
2024-05-22 13:39:20 [INFO]: Epoch 164 - training loss: 9276.4724, validation loss: 0.0836
2024-05-22 13:39:20 [INFO]: Epoch 165 - training loss: 9275.4907, validation loss: 0.0844
2024-05-22 13:39:21 [INFO]: Epoch 166 - training loss: 9275.7780, validation loss: 0.0834
2024-05-22 13:39:21 [INFO]: Epoch 167 - training loss: 9276.1973, validation loss: 0.0830
2024-05-22 13:39:21 [INFO]: Epoch 168 - training loss: 9276.5499, validation loss: 0.0827
2024-05-22 13:39:21 [INFO]: Epoch 169 - training loss: 9275.8999, validation loss: 0.0840
2024-05-22 13:39:21 [INFO]: Epoch 170 - training loss: 9276.2504, validation loss: 0.0801
2024-05-22 13:39:21 [INFO]: Epoch 171 - training loss: 9276.3996, validation loss: 0.0837
2024-05-22 13:39:21 [INFO]: Epoch 172 - training loss: 9275.8891, validation loss: 0.0818
2024-05-22 13:39:22 [INFO]: Epoch 173 - training loss: 9276.2672, validation loss: 0.0822
2024-05-22 13:39:22 [INFO]: Epoch 174 - training loss: 9275.0951, validation loss: 0.0802
2024-05-22 13:39:22 [INFO]: Epoch 175 - training loss: 9274.4399, validation loss: 0.0814
2024-05-22 13:39:22 [INFO]: Epoch 176 - training loss: 9276.9191, validation loss: 0.0824
2024-05-22 13:39:22 [INFO]: Epoch 177 - training loss: 9275.1354, validation loss: 0.0828
2024-05-22 13:39:22 [INFO]: Epoch 178 - training loss: 9275.2773, validation loss: 0.0823
2024-05-22 13:39:22 [INFO]: Epoch 179 - training loss: 9275.1262, validation loss: 0.0801
2024-05-22 13:39:22 [INFO]: Epoch 180 - training loss: 9275.4796, validation loss: 0.0826
2024-05-22 13:39:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:39:22 [INFO]: Finished training. The best model is from epoch#170.
2024-05-22 13:39:22 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_ettm1/20240522_T133858/GPVAE.pypots
2024-05-22 13:39:22 [INFO]: GP-VAE on ETTm1: MAE=0.2867, MSE=0.1737
2024-05-22 13:39:22 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-22 13:39:22 [INFO]: Using the given device: cuda:0
2024-05-22 13:39:22 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240522_T133922
2024-05-22 13:39:22 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240522_T133922/tensorboard
2024-05-22 13:39:22 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 13:39:33 [INFO]: Epoch 001 - generator training loss: 0.5174, discriminator training loss: 0.4258, validation loss: 0.3208
2024-05-22 13:39:42 [INFO]: Epoch 002 - generator training loss: 0.0162, discriminator training loss: 0.3175, validation loss: 0.1162
2024-05-22 13:39:51 [INFO]: Epoch 003 - generator training loss: -0.1228, discriminator training loss: 0.3097, validation loss: 0.0625
2024-05-22 13:40:00 [INFO]: Epoch 004 - generator training loss: -0.1337, discriminator training loss: 0.2943, validation loss: 0.0497
2024-05-22 13:40:09 [INFO]: Epoch 005 - generator training loss: -0.1255, discriminator training loss: 0.2737, validation loss: 0.0448
2024-05-22 13:40:18 [INFO]: Epoch 006 - generator training loss: -0.1045, discriminator training loss: 0.2470, validation loss: 0.0418
2024-05-22 13:40:27 [INFO]: Epoch 007 - generator training loss: -0.0773, discriminator training loss: 0.2116, validation loss: 0.0400
2024-05-22 13:40:36 [INFO]: Epoch 008 - generator training loss: -0.0582, discriminator training loss: 0.1795, validation loss: 0.0384
2024-05-22 13:40:45 [INFO]: Epoch 009 - generator training loss: -0.0419, discriminator training loss: 0.1565, validation loss: 0.0385
2024-05-22 13:40:54 [INFO]: Epoch 010 - generator training loss: -0.0391, discriminator training loss: 0.1423, validation loss: 0.0369
2024-05-22 13:41:03 [INFO]: Epoch 011 - generator training loss: -0.0346, discriminator training loss: 0.1324, validation loss: 0.0361
2024-05-22 13:41:12 [INFO]: Epoch 012 - generator training loss: -0.0327, discriminator training loss: 0.1275, validation loss: 0.0356
2024-05-22 13:41:21 [INFO]: Epoch 013 - generator training loss: -0.0337, discriminator training loss: 0.1254, validation loss: 0.0362
2024-05-22 13:41:30 [INFO]: Epoch 014 - generator training loss: -0.0317, discriminator training loss: 0.1217, validation loss: 0.0341
2024-05-22 13:41:39 [INFO]: Epoch 015 - generator training loss: -0.0331, discriminator training loss: 0.1207, validation loss: 0.0352
2024-05-22 13:41:48 [INFO]: Epoch 016 - generator training loss: -0.0322, discriminator training loss: 0.1173, validation loss: 0.0339
2024-05-22 13:41:57 [INFO]: Epoch 017 - generator training loss: -0.0312, discriminator training loss: 0.1168, validation loss: 0.0340
2024-05-22 13:42:06 [INFO]: Epoch 018 - generator training loss: -0.0333, discriminator training loss: 0.1180, validation loss: 0.0330
2024-05-22 13:42:15 [INFO]: Epoch 019 - generator training loss: -0.0308, discriminator training loss: 0.1154, validation loss: 0.0328
2024-05-22 13:42:24 [INFO]: Epoch 020 - generator training loss: -0.0319, discriminator training loss: 0.1162, validation loss: 0.0348
2024-05-22 13:42:33 [INFO]: Epoch 021 - generator training loss: -0.0306, discriminator training loss: 0.1178, validation loss: 0.0328
2024-05-22 13:42:42 [INFO]: Epoch 022 - generator training loss: -0.0345, discriminator training loss: 0.1138, validation loss: 0.0328
2024-05-22 13:42:51 [INFO]: Epoch 023 - generator training loss: -0.0318, discriminator training loss: 0.1134, validation loss: 0.0326
2024-05-22 13:43:00 [INFO]: Epoch 024 - generator training loss: -0.0320, discriminator training loss: 0.1139, validation loss: 0.0315
2024-05-22 13:43:09 [INFO]: Epoch 025 - generator training loss: -0.0348, discriminator training loss: 0.1128, validation loss: 0.0313
2024-05-22 13:43:18 [INFO]: Epoch 026 - generator training loss: -0.0365, discriminator training loss: 0.1130, validation loss: 0.0307
2024-05-22 13:43:27 [INFO]: Epoch 027 - generator training loss: -0.0361, discriminator training loss: 0.1117, validation loss: 0.0320
2024-05-22 13:43:36 [INFO]: Epoch 028 - generator training loss: -0.0333, discriminator training loss: 0.1112, validation loss: 0.0312
2024-05-22 13:43:45 [INFO]: Epoch 029 - generator training loss: -0.0339, discriminator training loss: 0.1109, validation loss: 0.0317
2024-05-22 13:43:54 [INFO]: Epoch 030 - generator training loss: -0.0368, discriminator training loss: 0.1131, validation loss: 0.0316
2024-05-22 13:44:03 [INFO]: Epoch 031 - generator training loss: -0.0358, discriminator training loss: 0.1101, validation loss: 0.0295
2024-05-22 13:44:12 [INFO]: Epoch 032 - generator training loss: -0.0342, discriminator training loss: 0.1102, validation loss: 0.0293
2024-05-22 13:44:21 [INFO]: Epoch 033 - generator training loss: -0.0362, discriminator training loss: 0.1118, validation loss: 0.0299
2024-05-22 13:44:30 [INFO]: Epoch 034 - generator training loss: -0.0346, discriminator training loss: 0.1108, validation loss: 0.0298
2024-05-22 13:44:39 [INFO]: Epoch 035 - generator training loss: -0.0328, discriminator training loss: 0.1119, validation loss: 0.0299
2024-05-22 13:44:48 [INFO]: Epoch 036 - generator training loss: -0.0336, discriminator training loss: 0.1102, validation loss: 0.0300
2024-05-22 13:44:57 [INFO]: Epoch 037 - generator training loss: -0.0374, discriminator training loss: 0.1116, validation loss: 0.0307
2024-05-22 13:45:06 [INFO]: Epoch 038 - generator training loss: -0.0373, discriminator training loss: 0.1111, validation loss: 0.0289
2024-05-22 13:45:15 [INFO]: Epoch 039 - generator training loss: -0.0363, discriminator training loss: 0.1108, validation loss: 0.0294
2024-05-22 13:45:24 [INFO]: Epoch 040 - generator training loss: -0.0385, discriminator training loss: 0.1115, validation loss: 0.0289
2024-05-22 13:45:33 [INFO]: Epoch 041 - generator training loss: -0.0354, discriminator training loss: 0.1114, validation loss: 0.0289
2024-05-22 13:45:42 [INFO]: Epoch 042 - generator training loss: -0.0368, discriminator training loss: 0.1107, validation loss: 0.0284
2024-05-22 13:45:51 [INFO]: Epoch 043 - generator training loss: -0.0385, discriminator training loss: 0.1108, validation loss: 0.0292
2024-05-22 13:46:00 [INFO]: Epoch 044 - generator training loss: -0.0365, discriminator training loss: 0.1108, validation loss: 0.0287
2024-05-22 13:46:09 [INFO]: Epoch 045 - generator training loss: -0.0361, discriminator training loss: 0.1106, validation loss: 0.0287
2024-05-22 13:46:18 [INFO]: Epoch 046 - generator training loss: -0.0360, discriminator training loss: 0.1091, validation loss: 0.0281
2024-05-22 13:46:27 [INFO]: Epoch 047 - generator training loss: -0.0370, discriminator training loss: 0.1096, validation loss: 0.0289
2024-05-22 13:46:36 [INFO]: Epoch 048 - generator training loss: -0.0327, discriminator training loss: 0.1109, validation loss: 0.0306
2024-05-22 13:46:45 [INFO]: Epoch 049 - generator training loss: -0.0352, discriminator training loss: 0.1109, validation loss: 0.0295
2024-05-22 13:46:54 [INFO]: Epoch 050 - generator training loss: -0.0388, discriminator training loss: 0.1077, validation loss: 0.0279
2024-05-22 13:47:03 [INFO]: Epoch 051 - generator training loss: -0.0389, discriminator training loss: 0.1100, validation loss: 0.0284
2024-05-22 13:47:11 [INFO]: Epoch 052 - generator training loss: -0.0378, discriminator training loss: 0.1105, validation loss: 0.0277
2024-05-22 13:47:20 [INFO]: Epoch 053 - generator training loss: -0.0386, discriminator training loss: 0.1097, validation loss: 0.0273
2024-05-22 13:47:29 [INFO]: Epoch 054 - generator training loss: -0.0390, discriminator training loss: 0.1092, validation loss: 0.0274
2024-05-22 13:47:38 [INFO]: Epoch 055 - generator training loss: -0.0378, discriminator training loss: 0.1102, validation loss: 0.0276
2024-05-22 13:47:47 [INFO]: Epoch 056 - generator training loss: -0.0384, discriminator training loss: 0.1087, validation loss: 0.0269
2024-05-22 13:47:56 [INFO]: Epoch 057 - generator training loss: -0.0368, discriminator training loss: 0.1079, validation loss: 0.0265
2024-05-22 13:48:05 [INFO]: Epoch 058 - generator training loss: -0.0440, discriminator training loss: 0.1094, validation loss: 0.0263
2024-05-22 13:48:14 [INFO]: Epoch 059 - generator training loss: -0.0392, discriminator training loss: 0.1090, validation loss: 0.0255
2024-05-22 13:48:23 [INFO]: Epoch 060 - generator training loss: -0.0421, discriminator training loss: 0.1071, validation loss: 0.0252
2024-05-22 13:48:33 [INFO]: Epoch 061 - generator training loss: -0.0401, discriminator training loss: 0.1066, validation loss: 0.0256
2024-05-22 13:48:42 [INFO]: Epoch 062 - generator training loss: -0.0409, discriminator training loss: 0.1079, validation loss: 0.0261
2024-05-22 13:48:51 [INFO]: Epoch 063 - generator training loss: -0.0438, discriminator training loss: 0.1066, validation loss: 0.0248
2024-05-22 13:49:00 [INFO]: Epoch 064 - generator training loss: -0.0402, discriminator training loss: 0.1102, validation loss: 0.0250
2024-05-22 13:49:09 [INFO]: Epoch 065 - generator training loss: -0.0411, discriminator training loss: 0.1080, validation loss: 0.0244
2024-05-22 13:49:18 [INFO]: Epoch 066 - generator training loss: -0.0428, discriminator training loss: 0.1079, validation loss: 0.0243
2024-05-22 13:49:27 [INFO]: Epoch 067 - generator training loss: -0.0442, discriminator training loss: 0.1077, validation loss: 0.0242
2024-05-22 13:49:36 [INFO]: Epoch 068 - generator training loss: -0.0450, discriminator training loss: 0.1099, validation loss: 0.0242
2024-05-22 13:49:45 [INFO]: Epoch 069 - generator training loss: -0.0440, discriminator training loss: 0.1084, validation loss: 0.0239
2024-05-22 13:49:54 [INFO]: Epoch 070 - generator training loss: -0.0442, discriminator training loss: 0.1070, validation loss: 0.0238
2024-05-22 13:50:03 [INFO]: Epoch 071 - generator training loss: -0.0426, discriminator training loss: 0.1065, validation loss: 0.0238
2024-05-22 13:50:12 [INFO]: Epoch 072 - generator training loss: -0.0425, discriminator training loss: 0.1073, validation loss: 0.0236
2024-05-22 13:50:21 [INFO]: Epoch 073 - generator training loss: -0.0439, discriminator training loss: 0.1080, validation loss: 0.0236
2024-05-22 13:50:30 [INFO]: Epoch 074 - generator training loss: -0.0451, discriminator training loss: 0.1070, validation loss: 0.0229
2024-05-22 13:50:39 [INFO]: Epoch 075 - generator training loss: -0.0455, discriminator training loss: 0.1068, validation loss: 0.0232
2024-05-22 13:50:48 [INFO]: Epoch 076 - generator training loss: -0.0424, discriminator training loss: 0.1087, validation loss: 0.0228
2024-05-22 13:50:57 [INFO]: Epoch 077 - generator training loss: -0.0428, discriminator training loss: 0.1092, validation loss: 0.0234
2024-05-22 13:51:06 [INFO]: Epoch 078 - generator training loss: -0.0446, discriminator training loss: 0.1082, validation loss: 0.0238
2024-05-22 13:51:15 [INFO]: Epoch 079 - generator training loss: -0.0425, discriminator training loss: 0.1093, validation loss: 0.0232
2024-05-22 13:51:24 [INFO]: Epoch 080 - generator training loss: -0.0445, discriminator training loss: 0.1052, validation loss: 0.0227
2024-05-22 13:51:33 [INFO]: Epoch 081 - generator training loss: -0.0433, discriminator training loss: 0.1086, validation loss: 0.0237
2024-05-22 13:51:42 [INFO]: Epoch 082 - generator training loss: -0.0427, discriminator training loss: 0.1083, validation loss: 0.0234
2024-05-22 13:51:51 [INFO]: Epoch 083 - generator training loss: -0.0410, discriminator training loss: 0.1053, validation loss: 0.0237
2024-05-22 13:52:00 [INFO]: Epoch 084 - generator training loss: -0.0432, discriminator training loss: 0.1075, validation loss: 0.0224
2024-05-22 13:52:09 [INFO]: Epoch 085 - generator training loss: -0.0445, discriminator training loss: 0.1054, validation loss: 0.0231
2024-05-22 13:52:19 [INFO]: Epoch 086 - generator training loss: -0.0455, discriminator training loss: 0.1091, validation loss: 0.0223
2024-05-22 13:52:28 [INFO]: Epoch 087 - generator training loss: -0.0427, discriminator training loss: 0.1067, validation loss: 0.0221
2024-05-22 13:52:37 [INFO]: Epoch 088 - generator training loss: -0.0450, discriminator training loss: 0.1092, validation loss: 0.0224
2024-05-22 13:52:46 [INFO]: Epoch 089 - generator training loss: -0.0444, discriminator training loss: 0.1074, validation loss: 0.0244
2024-05-22 13:52:54 [INFO]: Epoch 090 - generator training loss: -0.0431, discriminator training loss: 0.1057, validation loss: 0.0245
2024-05-22 13:53:03 [INFO]: Epoch 091 - generator training loss: -0.0433, discriminator training loss: 0.1046, validation loss: 0.0226
2024-05-22 13:53:12 [INFO]: Epoch 092 - generator training loss: -0.0473, discriminator training loss: 0.1063, validation loss: 0.0224
2024-05-22 13:53:21 [INFO]: Epoch 093 - generator training loss: -0.0470, discriminator training loss: 0.1055, validation loss: 0.0220
2024-05-22 13:53:30 [INFO]: Epoch 094 - generator training loss: -0.0469, discriminator training loss: 0.1054, validation loss: 0.0226
2024-05-22 13:53:39 [INFO]: Epoch 095 - generator training loss: -0.0451, discriminator training loss: 0.1062, validation loss: 0.0222
2024-05-22 13:53:48 [INFO]: Epoch 096 - generator training loss: -0.0495, discriminator training loss: 0.1059, validation loss: 0.0222
2024-05-22 13:53:57 [INFO]: Epoch 097 - generator training loss: -0.0463, discriminator training loss: 0.1036, validation loss: 0.0221
2024-05-22 13:54:06 [INFO]: Epoch 098 - generator training loss: -0.0467, discriminator training loss: 0.1051, validation loss: 0.0225
2024-05-22 13:54:14 [INFO]: Epoch 099 - generator training loss: -0.0504, discriminator training loss: 0.1057, validation loss: 0.0218
2024-05-22 13:54:23 [INFO]: Epoch 100 - generator training loss: -0.0434, discriminator training loss: 0.1057, validation loss: 0.0220
2024-05-22 13:54:32 [INFO]: Epoch 101 - generator training loss: -0.0461, discriminator training loss: 0.1060, validation loss: 0.0224
2024-05-22 13:54:41 [INFO]: Epoch 102 - generator training loss: -0.0497, discriminator training loss: 0.1076, validation loss: 0.0223
2024-05-22 13:54:50 [INFO]: Epoch 103 - generator training loss: -0.0520, discriminator training loss: 0.1050, validation loss: 0.0218
2024-05-22 13:54:59 [INFO]: Epoch 104 - generator training loss: -0.0483, discriminator training loss: 0.1055, validation loss: 0.0215
2024-05-22 13:55:08 [INFO]: Epoch 105 - generator training loss: -0.0483, discriminator training loss: 0.1076, validation loss: 0.0224
2024-05-22 13:55:17 [INFO]: Epoch 106 - generator training loss: -0.0483, discriminator training loss: 0.1057, validation loss: 0.0215
2024-05-22 13:55:26 [INFO]: Epoch 107 - generator training loss: -0.0475, discriminator training loss: 0.1039, validation loss: 0.0216
2024-05-22 13:55:35 [INFO]: Epoch 108 - generator training loss: -0.0486, discriminator training loss: 0.1066, validation loss: 0.0219
2024-05-22 13:55:44 [INFO]: Epoch 109 - generator training loss: -0.0470, discriminator training loss: 0.1046, validation loss: 0.0214
2024-05-22 13:55:53 [INFO]: Epoch 110 - generator training loss: -0.0507, discriminator training loss: 0.1041, validation loss: 0.0219
2024-05-22 13:56:01 [INFO]: Epoch 111 - generator training loss: -0.0458, discriminator training loss: 0.1042, validation loss: 0.0219
2024-05-22 13:56:10 [INFO]: Epoch 112 - generator training loss: -0.0525, discriminator training loss: 0.1071, validation loss: 0.0214
2024-05-22 13:56:19 [INFO]: Epoch 113 - generator training loss: -0.0484, discriminator training loss: 0.1051, validation loss: 0.0217
2024-05-22 13:56:28 [INFO]: Epoch 114 - generator training loss: -0.0488, discriminator training loss: 0.1056, validation loss: 0.0216
2024-05-22 13:56:37 [INFO]: Epoch 115 - generator training loss: -0.0476, discriminator training loss: 0.1019, validation loss: 0.0215
2024-05-22 13:56:46 [INFO]: Epoch 116 - generator training loss: -0.0460, discriminator training loss: 0.1048, validation loss: 0.0220
2024-05-22 13:56:55 [INFO]: Epoch 117 - generator training loss: -0.0480, discriminator training loss: 0.1033, validation loss: 0.0220
2024-05-22 13:57:04 [INFO]: Epoch 118 - generator training loss: -0.0516, discriminator training loss: 0.1041, validation loss: 0.0211
2024-05-22 13:57:13 [INFO]: Epoch 119 - generator training loss: -0.0478, discriminator training loss: 0.1050, validation loss: 0.0212
2024-05-22 13:57:22 [INFO]: Epoch 120 - generator training loss: -0.0482, discriminator training loss: 0.1060, validation loss: 0.0221
2024-05-22 13:57:30 [INFO]: Epoch 121 - generator training loss: -0.0499, discriminator training loss: 0.1058, validation loss: 0.0212
2024-05-22 13:57:39 [INFO]: Epoch 122 - generator training loss: -0.0471, discriminator training loss: 0.1048, validation loss: 0.0210
2024-05-22 13:57:48 [INFO]: Epoch 123 - generator training loss: -0.0479, discriminator training loss: 0.1052, validation loss: 0.0222
2024-05-22 13:57:57 [INFO]: Epoch 124 - generator training loss: -0.0497, discriminator training loss: 0.1033, validation loss: 0.0214
2024-05-22 13:58:06 [INFO]: Epoch 125 - generator training loss: -0.0494, discriminator training loss: 0.1027, validation loss: 0.0219
2024-05-22 13:58:15 [INFO]: Epoch 126 - generator training loss: -0.0478, discriminator training loss: 0.1032, validation loss: 0.0215
2024-05-22 13:58:24 [INFO]: Epoch 127 - generator training loss: -0.0485, discriminator training loss: 0.1032, validation loss: 0.0221
2024-05-22 13:58:33 [INFO]: Epoch 128 - generator training loss: -0.0485, discriminator training loss: 0.1042, validation loss: 0.0212
2024-05-22 13:58:42 [INFO]: Epoch 129 - generator training loss: -0.0471, discriminator training loss: 0.1036, validation loss: 0.0217
2024-05-22 13:58:51 [INFO]: Epoch 130 - generator training loss: -0.0474, discriminator training loss: 0.1035, validation loss: 0.0214
2024-05-22 13:59:00 [INFO]: Epoch 131 - generator training loss: -0.0490, discriminator training loss: 0.1035, validation loss: 0.0213
2024-05-22 13:59:09 [INFO]: Epoch 132 - generator training loss: -0.0479, discriminator training loss: 0.1036, validation loss: 0.0210
2024-05-22 13:59:17 [INFO]: Epoch 133 - generator training loss: -0.0505, discriminator training loss: 0.1041, validation loss: 0.0213
2024-05-22 13:59:26 [INFO]: Epoch 134 - generator training loss: -0.0485, discriminator training loss: 0.1038, validation loss: 0.0219
2024-05-22 13:59:35 [INFO]: Epoch 135 - generator training loss: -0.0510, discriminator training loss: 0.1036, validation loss: 0.0223
2024-05-22 13:59:44 [INFO]: Epoch 136 - generator training loss: -0.0461, discriminator training loss: 0.1041, validation loss: 0.0210
2024-05-22 13:59:53 [INFO]: Epoch 137 - generator training loss: -0.0490, discriminator training loss: 0.1043, validation loss: 0.0211
2024-05-22 14:00:02 [INFO]: Epoch 138 - generator training loss: -0.0472, discriminator training loss: 0.1033, validation loss: 0.0225
2024-05-22 14:00:11 [INFO]: Epoch 139 - generator training loss: -0.0495, discriminator training loss: 0.1015, validation loss: 0.0213
2024-05-22 14:00:20 [INFO]: Epoch 140 - generator training loss: -0.0487, discriminator training loss: 0.1052, validation loss: 0.0214
2024-05-22 14:00:28 [INFO]: Epoch 141 - generator training loss: -0.0482, discriminator training loss: 0.1013, validation loss: 0.0215
2024-05-22 14:00:37 [INFO]: Epoch 142 - generator training loss: -0.0498, discriminator training loss: 0.1037, validation loss: 0.0219
2024-05-22 14:00:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:00:37 [INFO]: Finished training. The best model is from epoch#132.
2024-05-22 14:00:37 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_ettm1/20240522_T133922/USGAN.pypots
2024-05-22 14:00:38 [INFO]: US-GAN on ETTm1: MAE=0.1395, MSE=0.0499
2024-05-22 14:00:38 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-22 14:00:38 [INFO]: Using the given device: cuda:0
2024-05-22 14:00:38 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240522_T140038
2024-05-22 14:00:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240522_T140038/tensorboard
2024-05-22 14:00:38 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 14:00:46 [INFO]: Epoch 001 - training loss: 1.3587, validation loss: 0.3071
2024-05-22 14:00:52 [INFO]: Epoch 002 - training loss: 0.9147, validation loss: 0.0912
2024-05-22 14:00:58 [INFO]: Epoch 003 - training loss: 0.7402, validation loss: 0.0560
2024-05-22 14:01:04 [INFO]: Epoch 004 - training loss: 0.6617, validation loss: 0.0463
2024-05-22 14:01:10 [INFO]: Epoch 005 - training loss: 0.6236, validation loss: 0.0399
2024-05-22 14:01:16 [INFO]: Epoch 006 - training loss: 0.5898, validation loss: 0.0394
2024-05-22 14:01:22 [INFO]: Epoch 007 - training loss: 0.5608, validation loss: 0.0377
2024-05-22 14:01:28 [INFO]: Epoch 008 - training loss: 0.5274, validation loss: 0.0355
2024-05-22 14:01:34 [INFO]: Epoch 009 - training loss: 0.5053, validation loss: 0.0352
2024-05-22 14:01:39 [INFO]: Epoch 010 - training loss: 0.4922, validation loss: 0.0336
2024-05-22 14:01:45 [INFO]: Epoch 011 - training loss: 0.4655, validation loss: 0.0313
2024-05-22 14:01:51 [INFO]: Epoch 012 - training loss: 0.4496, validation loss: 0.0303
2024-05-22 14:01:57 [INFO]: Epoch 013 - training loss: 0.4319, validation loss: 0.0290
2024-05-22 14:02:03 [INFO]: Epoch 014 - training loss: 0.4285, validation loss: 0.0287
2024-05-22 14:02:09 [INFO]: Epoch 015 - training loss: 0.4114, validation loss: 0.0277
2024-05-22 14:02:15 [INFO]: Epoch 016 - training loss: 0.4058, validation loss: 0.0269
2024-05-22 14:02:21 [INFO]: Epoch 017 - training loss: 0.4002, validation loss: 0.0256
2024-05-22 14:02:27 [INFO]: Epoch 018 - training loss: 0.3948, validation loss: 0.0255
2024-05-22 14:02:33 [INFO]: Epoch 019 - training loss: 0.3892, validation loss: 0.0260
2024-05-22 14:02:39 [INFO]: Epoch 020 - training loss: 0.3863, validation loss: 0.0247
2024-05-22 14:02:45 [INFO]: Epoch 021 - training loss: 0.3953, validation loss: 0.0253
2024-05-22 14:02:50 [INFO]: Epoch 022 - training loss: 0.3956, validation loss: 0.0251
2024-05-22 14:02:56 [INFO]: Epoch 023 - training loss: 0.3870, validation loss: 0.0253
2024-05-22 14:03:02 [INFO]: Epoch 024 - training loss: 0.3867, validation loss: 0.0250
2024-05-22 14:03:08 [INFO]: Epoch 025 - training loss: 0.3875, validation loss: 0.0251
2024-05-22 14:03:14 [INFO]: Epoch 026 - training loss: 0.3859, validation loss: 0.0249
2024-05-22 14:03:20 [INFO]: Epoch 027 - training loss: 0.3950, validation loss: 0.0250
2024-05-22 14:03:26 [INFO]: Epoch 028 - training loss: 0.3960, validation loss: 0.0259
2024-05-22 14:03:32 [INFO]: Epoch 029 - training loss: 0.3975, validation loss: 0.0250
2024-05-22 14:03:38 [INFO]: Epoch 030 - training loss: 0.3908, validation loss: 0.0247
2024-05-22 14:03:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:03:38 [INFO]: Finished training. The best model is from epoch#20.
2024-05-22 14:03:38 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_ettm1/20240522_T140038/BRITS.pypots
2024-05-22 14:03:39 [INFO]: BRITS on ETTm1: MAE=0.1313, MSE=0.0533
2024-05-22 14:03:39 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-22 14:03:39 [INFO]: Using the given device: cuda:0
2024-05-22 14:03:39 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339
2024-05-22 14:03:39 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/tensorboard
2024-05-22 14:03:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 14:03:41 [INFO]: Epoch 001 - training loss: 1.4428, validation loss: 1.2578
2024-05-22 14:03:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch1_loss1.257796660065651.pypots
2024-05-22 14:03:41 [INFO]: Epoch 002 - training loss: 1.0654, validation loss: 1.1098
2024-05-22 14:03:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch2_loss1.1098277121782303.pypots
2024-05-22 14:03:41 [INFO]: Epoch 003 - training loss: 0.9599, validation loss: 1.0444
2024-05-22 14:03:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch3_loss1.044380322098732.pypots
2024-05-22 14:03:41 [INFO]: Epoch 004 - training loss: 0.9443, validation loss: 1.0282
2024-05-22 14:03:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch4_loss1.0282020568847656.pypots
2024-05-22 14:03:42 [INFO]: Epoch 005 - training loss: 0.9530, validation loss: 1.0191
2024-05-22 14:03:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch5_loss1.0190963000059128.pypots
2024-05-22 14:03:42 [INFO]: Epoch 006 - training loss: 0.9305, validation loss: 1.0100
2024-05-22 14:03:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch6_loss1.0100304931402206.pypots
2024-05-22 14:03:42 [INFO]: Epoch 007 - training loss: 0.9663, validation loss: 1.0095
2024-05-22 14:03:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch7_loss1.0095259249210358.pypots
2024-05-22 14:03:42 [INFO]: Epoch 008 - training loss: 0.9084, validation loss: 1.0067
2024-05-22 14:03:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch8_loss1.0067035853862762.pypots
2024-05-22 14:03:42 [INFO]: Epoch 009 - training loss: 0.9051, validation loss: 1.0081
2024-05-22 14:03:42 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch9_loss1.0080757290124893.pypots
2024-05-22 14:03:43 [INFO]: Epoch 010 - training loss: 0.8873, validation loss: 1.0064
2024-05-22 14:03:43 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch10_loss1.0064408034086227.pypots
2024-05-22 14:03:43 [INFO]: Epoch 011 - training loss: 0.8773, validation loss: 1.0040
2024-05-22 14:03:43 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch11_loss1.0039554238319397.pypots
2024-05-22 14:03:43 [INFO]: Epoch 012 - training loss: 0.8739, validation loss: 0.9961
2024-05-22 14:03:43 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch12_loss0.9960814118385315.pypots
2024-05-22 14:03:43 [INFO]: Epoch 013 - training loss: 0.8941, validation loss: 0.9927
2024-05-22 14:03:43 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch13_loss0.9926695078611374.pypots
2024-05-22 14:03:43 [INFO]: Epoch 014 - training loss: 0.8695, validation loss: 0.9917
2024-05-22 14:03:43 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch14_loss0.9917031526565552.pypots
2024-05-22 14:03:44 [INFO]: Epoch 015 - training loss: 0.8677, validation loss: 0.9902
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch15_loss0.9902394264936447.pypots
2024-05-22 14:03:44 [INFO]: Epoch 016 - training loss: 0.8450, validation loss: 0.9831
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch16_loss0.9830636233091354.pypots
2024-05-22 14:03:44 [INFO]: Epoch 017 - training loss: 0.8607, validation loss: 0.9800
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch17_loss0.979972630739212.pypots
2024-05-22 14:03:44 [INFO]: Epoch 018 - training loss: 0.8456, validation loss: 0.9779
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch18_loss0.9778596311807632.pypots
2024-05-22 14:03:44 [INFO]: Epoch 019 - training loss: 0.8427, validation loss: 0.9736
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch19_loss0.9735519587993622.pypots
2024-05-22 14:03:44 [INFO]: Epoch 020 - training loss: 0.8579, validation loss: 0.9719
2024-05-22 14:03:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch20_loss0.9719432443380356.pypots
2024-05-22 14:03:45 [INFO]: Epoch 021 - training loss: 0.8483, validation loss: 0.9692
2024-05-22 14:03:45 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch21_loss0.9691669344902039.pypots
2024-05-22 14:03:45 [INFO]: Epoch 022 - training loss: 0.8341, validation loss: 0.9635
2024-05-22 14:03:45 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch22_loss0.9634941816329956.pypots
2024-05-22 14:03:45 [INFO]: Epoch 023 - training loss: 0.8485, validation loss: 0.9640
2024-05-22 14:03:45 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch23_loss0.9639777839183807.pypots
2024-05-22 14:03:45 [INFO]: Epoch 024 - training loss: 0.8336, validation loss: 0.9616
2024-05-22 14:03:46 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch24_loss0.9615633487701416.pypots
2024-05-22 14:03:47 [INFO]: Epoch 025 - training loss: 0.8414, validation loss: 0.9594
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch25_loss0.9594341069459915.pypots
2024-05-22 14:03:47 [INFO]: Epoch 026 - training loss: 0.8219, validation loss: 0.9599
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch26_loss0.9599270224571228.pypots
2024-05-22 14:03:47 [INFO]: Epoch 027 - training loss: 0.8282, validation loss: 0.9562
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch27_loss0.9562014639377594.pypots
2024-05-22 14:03:47 [INFO]: Epoch 028 - training loss: 0.8236, validation loss: 0.9570
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch28_loss0.9570114612579346.pypots
2024-05-22 14:03:47 [INFO]: Epoch 029 - training loss: 0.8106, validation loss: 0.9529
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch29_loss0.9529333859682083.pypots
2024-05-22 14:03:47 [INFO]: Epoch 030 - training loss: 0.7901, validation loss: 0.9503
2024-05-22 14:03:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch30_loss0.9502816796302795.pypots
2024-05-22 14:03:48 [INFO]: Epoch 031 - training loss: 0.8018, validation loss: 0.9504
2024-05-22 14:03:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch31_loss0.9503525495529175.pypots
2024-05-22 14:03:48 [INFO]: Epoch 032 - training loss: 0.7924, validation loss: 0.9474
2024-05-22 14:03:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch32_loss0.9473856091499329.pypots
2024-05-22 14:03:48 [INFO]: Epoch 033 - training loss: 0.8525, validation loss: 0.9443
2024-05-22 14:03:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch33_loss0.9443062543869019.pypots
2024-05-22 14:03:48 [INFO]: Epoch 034 - training loss: 0.8091, validation loss: 0.9409
2024-05-22 14:03:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch34_loss0.9408596754074097.pypots
2024-05-22 14:03:48 [INFO]: Epoch 035 - training loss: 0.7815, validation loss: 0.9408
2024-05-22 14:03:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch35_loss0.9407813996076584.pypots
2024-05-22 14:03:49 [INFO]: Epoch 036 - training loss: 0.8188, validation loss: 0.9380
2024-05-22 14:03:49 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch36_loss0.9380493611097336.pypots
2024-05-22 14:03:49 [INFO]: Epoch 037 - training loss: 0.8266, validation loss: 0.9352
2024-05-22 14:03:49 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch37_loss0.9351863861083984.pypots
2024-05-22 14:03:49 [INFO]: Epoch 038 - training loss: 0.8131, validation loss: 0.9331
2024-05-22 14:03:49 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch38_loss0.9330956637859344.pypots
2024-05-22 14:03:49 [INFO]: Epoch 039 - training loss: 0.8149, validation loss: 0.9285
2024-05-22 14:03:49 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch39_loss0.9285314530134201.pypots
2024-05-22 14:03:49 [INFO]: Epoch 040 - training loss: 0.7995, validation loss: 0.9272
2024-05-22 14:03:49 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch40_loss0.9272257685661316.pypots
2024-05-22 14:03:50 [INFO]: Epoch 041 - training loss: 0.8025, validation loss: 0.9249
2024-05-22 14:03:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch41_loss0.9249430298805237.pypots
2024-05-22 14:03:50 [INFO]: Epoch 042 - training loss: 0.7980, validation loss: 0.9210
2024-05-22 14:03:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch42_loss0.9209900200366974.pypots
2024-05-22 14:03:50 [INFO]: Epoch 043 - training loss: 0.7770, validation loss: 0.9171
2024-05-22 14:03:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch43_loss0.9170836210250854.pypots
2024-05-22 14:03:50 [INFO]: Epoch 044 - training loss: 0.7997, validation loss: 0.9163
2024-05-22 14:03:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch44_loss0.9162680059671402.pypots
2024-05-22 14:03:50 [INFO]: Epoch 045 - training loss: 0.8014, validation loss: 0.9152
2024-05-22 14:03:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch45_loss0.9151769280433655.pypots
2024-05-22 14:03:51 [INFO]: Epoch 046 - training loss: 0.7772, validation loss: 0.9111
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch46_loss0.9111463576555252.pypots
2024-05-22 14:03:51 [INFO]: Epoch 047 - training loss: 0.8230, validation loss: 0.9103
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch47_loss0.910336047410965.pypots
2024-05-22 14:03:51 [INFO]: Epoch 048 - training loss: 0.7681, validation loss: 0.9064
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch48_loss0.9063976109027863.pypots
2024-05-22 14:03:51 [INFO]: Epoch 049 - training loss: 0.7930, validation loss: 0.9062
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch49_loss0.9061790406703949.pypots
2024-05-22 14:03:51 [INFO]: Epoch 050 - training loss: 0.7907, validation loss: 0.9066
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch50_loss0.9066065847873688.pypots
2024-05-22 14:03:51 [INFO]: Epoch 051 - training loss: 0.8141, validation loss: 0.9038
2024-05-22 14:03:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch51_loss0.9038330018520355.pypots
2024-05-22 14:03:52 [INFO]: Epoch 052 - training loss: 0.7629, validation loss: 0.9036
2024-05-22 14:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch52_loss0.9036097228527069.pypots
2024-05-22 14:03:52 [INFO]: Epoch 053 - training loss: 0.7914, validation loss: 0.9033
2024-05-22 14:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch53_loss0.90330870449543.pypots
2024-05-22 14:03:52 [INFO]: Epoch 054 - training loss: 0.8038, validation loss: 0.9004
2024-05-22 14:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch54_loss0.9003816395998001.pypots
2024-05-22 14:03:52 [INFO]: Epoch 055 - training loss: 0.7677, validation loss: 0.8987
2024-05-22 14:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch55_loss0.8986878097057343.pypots
2024-05-22 14:03:52 [INFO]: Epoch 056 - training loss: 0.7782, validation loss: 0.8982
2024-05-22 14:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch56_loss0.898180365562439.pypots
2024-05-22 14:03:53 [INFO]: Epoch 057 - training loss: 0.7930, validation loss: 0.8969
2024-05-22 14:03:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch57_loss0.8969383239746094.pypots
2024-05-22 14:03:53 [INFO]: Epoch 058 - training loss: 0.7771, validation loss: 0.8969
2024-05-22 14:03:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch58_loss0.8969197124242783.pypots
2024-05-22 14:03:53 [INFO]: Epoch 059 - training loss: 0.7782, validation loss: 0.8950
2024-05-22 14:03:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch59_loss0.8949850797653198.pypots
2024-05-22 14:03:53 [INFO]: Epoch 060 - training loss: 0.7793, validation loss: 0.8952
2024-05-22 14:03:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch60_loss0.8951632380485535.pypots
2024-05-22 14:03:53 [INFO]: Epoch 061 - training loss: 0.7762, validation loss: 0.8927
2024-05-22 14:03:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch61_loss0.8927151411771774.pypots
2024-05-22 14:03:54 [INFO]: Epoch 062 - training loss: 0.7962, validation loss: 0.8942
2024-05-22 14:03:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch62_loss0.8942406177520752.pypots
2024-05-22 14:03:54 [INFO]: Epoch 063 - training loss: 0.7948, validation loss: 0.8910
2024-05-22 14:03:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch63_loss0.8910067081451416.pypots
2024-05-22 14:03:54 [INFO]: Epoch 064 - training loss: 0.7585, validation loss: 0.8916
2024-05-22 14:03:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch64_loss0.8915922343730927.pypots
2024-05-22 14:03:54 [INFO]: Epoch 065 - training loss: 0.7735, validation loss: 0.8921
2024-05-22 14:03:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch65_loss0.8920925706624985.pypots
2024-05-22 14:03:54 [INFO]: Epoch 066 - training loss: 0.7822, validation loss: 0.8915
2024-05-22 14:03:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch66_loss0.8915241211652756.pypots
2024-05-22 14:03:55 [INFO]: Epoch 067 - training loss: 0.7794, validation loss: 0.8913
2024-05-22 14:03:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch67_loss0.8913375288248062.pypots
2024-05-22 14:03:55 [INFO]: Epoch 068 - training loss: 0.7823, validation loss: 0.8893
2024-05-22 14:03:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch68_loss0.8893292546272278.pypots
2024-05-22 14:03:55 [INFO]: Epoch 069 - training loss: 0.7542, validation loss: 0.8899
2024-05-22 14:03:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch69_loss0.8898505568504333.pypots
2024-05-22 14:03:55 [INFO]: Epoch 070 - training loss: 0.7855, validation loss: 0.8894
2024-05-22 14:03:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch70_loss0.8894489258527756.pypots
2024-05-22 14:03:55 [INFO]: Epoch 071 - training loss: 0.7799, validation loss: 0.8884
2024-05-22 14:03:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch71_loss0.8883890062570572.pypots
2024-05-22 14:03:56 [INFO]: Epoch 072 - training loss: 0.8004, validation loss: 0.8892
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch72_loss0.8892098367214203.pypots
2024-05-22 14:03:56 [INFO]: Epoch 073 - training loss: 0.7945, validation loss: 0.8886
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch73_loss0.8886454403400421.pypots
2024-05-22 14:03:56 [INFO]: Epoch 074 - training loss: 0.7729, validation loss: 0.8880
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch74_loss0.8879987895488739.pypots
2024-05-22 14:03:56 [INFO]: Epoch 075 - training loss: 0.7748, validation loss: 0.8870
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch75_loss0.886998638510704.pypots
2024-05-22 14:03:56 [INFO]: Epoch 076 - training loss: 0.7595, validation loss: 0.8868
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch76_loss0.8867570012807846.pypots
2024-05-22 14:03:57 [INFO]: Epoch 077 - training loss: 0.7694, validation loss: 0.8873
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch77_loss0.8872533291578293.pypots
2024-05-22 14:03:57 [INFO]: Epoch 078 - training loss: 0.7724, validation loss: 0.8857
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch78_loss0.8856696337461472.pypots
2024-05-22 14:03:57 [INFO]: Epoch 079 - training loss: 0.7688, validation loss: 0.8842
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch79_loss0.8841568529605865.pypots
2024-05-22 14:03:57 [INFO]: Epoch 080 - training loss: 0.7791, validation loss: 0.8862
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch80_loss0.8861853331327438.pypots
2024-05-22 14:03:57 [INFO]: Epoch 081 - training loss: 0.7643, validation loss: 0.8836
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch81_loss0.8836374431848526.pypots
2024-05-22 14:03:57 [INFO]: Epoch 082 - training loss: 0.7509, validation loss: 0.8824
2024-05-22 14:03:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch82_loss0.8823698908090591.pypots
2024-05-22 14:03:58 [INFO]: Epoch 083 - training loss: 0.7570, validation loss: 0.8814
2024-05-22 14:03:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch83_loss0.8813576996326447.pypots
2024-05-22 14:03:58 [INFO]: Epoch 084 - training loss: 0.7818, validation loss: 0.8806
2024-05-22 14:03:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch84_loss0.8806164562702179.pypots
2024-05-22 14:03:58 [INFO]: Epoch 085 - training loss: 0.7877, validation loss: 0.8845
2024-05-22 14:03:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch85_loss0.8845373839139938.pypots
2024-05-22 14:03:58 [INFO]: Epoch 086 - training loss: 0.7771, validation loss: 0.8849
2024-05-22 14:03:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch86_loss0.8848978877067566.pypots
2024-05-22 14:03:58 [INFO]: Epoch 087 - training loss: 0.7739, validation loss: 0.8852
2024-05-22 14:03:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch87_loss0.8851851373910904.pypots
2024-05-22 14:03:59 [INFO]: Epoch 088 - training loss: 0.7753, validation loss: 0.8832
2024-05-22 14:03:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch88_loss0.8832264095544815.pypots
2024-05-22 14:03:59 [INFO]: Epoch 089 - training loss: 0.7845, validation loss: 0.8811
2024-05-22 14:03:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch89_loss0.8810791373252869.pypots
2024-05-22 14:03:59 [INFO]: Epoch 090 - training loss: 0.7681, validation loss: 0.8797
2024-05-22 14:03:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch90_loss0.8796950131654739.pypots
2024-05-22 14:03:59 [INFO]: Epoch 091 - training loss: 0.7832, validation loss: 0.8775
2024-05-22 14:03:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch91_loss0.877452090382576.pypots
2024-05-22 14:03:59 [INFO]: Epoch 092 - training loss: 0.7715, validation loss: 0.8819
2024-05-22 14:03:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch92_loss0.881883978843689.pypots
2024-05-22 14:04:00 [INFO]: Epoch 093 - training loss: 0.7730, validation loss: 0.8777
2024-05-22 14:04:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch93_loss0.8776882737874985.pypots
2024-05-22 14:04:00 [INFO]: Epoch 094 - training loss: 0.7677, validation loss: 0.8808
2024-05-22 14:04:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch94_loss0.8807516247034073.pypots
2024-05-22 14:04:00 [INFO]: Epoch 095 - training loss: 0.7736, validation loss: 0.8800
2024-05-22 14:04:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch95_loss0.8800298422574997.pypots
2024-05-22 14:04:00 [INFO]: Epoch 096 - training loss: 0.7712, validation loss: 0.8769
2024-05-22 14:04:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch96_loss0.8768754601478577.pypots
2024-05-22 14:04:00 [INFO]: Epoch 097 - training loss: 0.7843, validation loss: 0.8781
2024-05-22 14:04:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch97_loss0.8780913352966309.pypots
2024-05-22 14:04:01 [INFO]: Epoch 098 - training loss: 0.7744, validation loss: 0.8783
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch98_loss0.8782785683870316.pypots
2024-05-22 14:04:01 [INFO]: Epoch 099 - training loss: 0.7767, validation loss: 0.8768
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch99_loss0.8767611980438232.pypots
2024-05-22 14:04:01 [INFO]: Epoch 100 - training loss: 0.7848, validation loss: 0.8763
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch100_loss0.8762835115194321.pypots
2024-05-22 14:04:01 [INFO]: Epoch 101 - training loss: 0.7947, validation loss: 0.8746
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch101_loss0.874567374587059.pypots
2024-05-22 14:04:01 [INFO]: Epoch 102 - training loss: 0.7639, validation loss: 0.8760
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch102_loss0.876011073589325.pypots
2024-05-22 14:04:01 [INFO]: Epoch 103 - training loss: 0.7729, validation loss: 0.8768
2024-05-22 14:04:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch103_loss0.8768061399459839.pypots
2024-05-22 14:04:02 [INFO]: Epoch 104 - training loss: 0.7750, validation loss: 0.8749
2024-05-22 14:04:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch104_loss0.8748918622732162.pypots
2024-05-22 14:04:02 [INFO]: Epoch 105 - training loss: 0.7683, validation loss: 0.8705
2024-05-22 14:04:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch105_loss0.8705390095710754.pypots
2024-05-22 14:04:02 [INFO]: Epoch 106 - training loss: 0.7515, validation loss: 0.8726
2024-05-22 14:04:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch106_loss0.8726249635219574.pypots
2024-05-22 14:04:02 [INFO]: Epoch 107 - training loss: 0.7796, validation loss: 0.8715
2024-05-22 14:04:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch107_loss0.8714607357978821.pypots
2024-05-22 14:04:02 [INFO]: Epoch 108 - training loss: 0.7741, validation loss: 0.8710
2024-05-22 14:04:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch108_loss0.8709825128316879.pypots
2024-05-22 14:04:03 [INFO]: Epoch 109 - training loss: 0.7562, validation loss: 0.8745
2024-05-22 14:04:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch109_loss0.8745134323835373.pypots
2024-05-22 14:04:03 [INFO]: Epoch 110 - training loss: 0.7626, validation loss: 0.8738
2024-05-22 14:04:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch110_loss0.8737905770540237.pypots
2024-05-22 14:04:03 [INFO]: Epoch 111 - training loss: 0.7601, validation loss: 0.8709
2024-05-22 14:04:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch111_loss0.8708995431661606.pypots
2024-05-22 14:04:03 [INFO]: Epoch 112 - training loss: 0.7654, validation loss: 0.8707
2024-05-22 14:04:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch112_loss0.8707146197557449.pypots
2024-05-22 14:04:03 [INFO]: Epoch 113 - training loss: 0.7867, validation loss: 0.8728
2024-05-22 14:04:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch113_loss0.8728087991476059.pypots
2024-05-22 14:04:04 [INFO]: Epoch 114 - training loss: 0.8076, validation loss: 0.8709
2024-05-22 14:04:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch114_loss0.870905801653862.pypots
2024-05-22 14:04:04 [INFO]: Epoch 115 - training loss: 0.7669, validation loss: 0.8706
2024-05-22 14:04:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN_epoch115_loss0.8706100285053253.pypots
2024-05-22 14:04:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:04:04 [INFO]: Finished training. The best model is from epoch#105.
2024-05-22 14:04:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240522_T140339/MRNN.pypots
2024-05-22 14:04:04 [INFO]: MRNN on ETTm1: MAE=0.7012, MSE=1.2466
2024-05-22 14:04:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-22 14:04:04 [INFO]: Using the given device: cpu
2024-05-22 14:04:04 [INFO]: LOCF on ETTm1: MAE=0.1376, MSE=0.0773
2024-05-22 14:04:04 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-22 14:04:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-22 14:04:04 [INFO]: Median on ETTm1: MAE=0.6554, MSE=0.8235
2024-05-22 14:04:04 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-22 14:04:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-22 14:04:04 [INFO]: Mean on ETTm1: MAE=0.6609, MSE=0.8067
2024-05-22 14:04:04 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-22 14:04:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-22 14:04:04 [INFO]: 
SAITS on data/ettm1: MAE=0.164±0.018587854088193308, MSE=0.054±0.014095523754580478
Transformer on data/ettm1: MAE=0.154±0.018348751288406535, MSE=0.043±0.008038942000656513
TimesNet on data/ettm1: MAE=0.119±0.00838951258016135, MSE=0.030±0.004021238886978022
CSDI on data/ettm1: MAE=0.507±0.4358861433542835, MSE=5.487±7.677957897252113
GPVAE on data/ettm1: MAE=0.279±0.010524652861839637, MSE=0.165±0.009560401526233721
USGAN on data/ettm1: MAE=0.140±0.0032506516803292485, MSE=0.052±0.0037155992116289453
BRITS on data/ettm1: MAE=0.134±0.0014408082421172139, MSE=0.054±0.0013497642896087058
MRNN on data/ettm1: MAE=0.730±0.0888180745926969, MSE=1.307±0.21589749946169495
LOCF on data/ettm1: MAE=0.138±0.0, MSE=0.077±0.0
Median on data/ettm1: MAE=0.655±0.0, MSE=0.824±0.0
Mean on data/ettm1: MAE=0.661±0.0, MSE=0.807±0.0

