2024-05-22 11:55:01 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 11:55:02 [INFO]: Using the given device: cuda:0
2024-05-22 11:55:02 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240522_T115502
2024-05-22 11:55:02 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_air_quality/20240522_T115502/tensorboard
2024-05-22 11:55:02 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 11:55:05 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.5203
2024-05-22 11:55:06 [INFO]: Epoch 002 - training loss: 0.7635, validation loss: 0.4014
2024-05-22 11:55:06 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.3264
2024-05-22 11:55:07 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.2863
2024-05-22 11:55:07 [INFO]: Epoch 005 - training loss: 0.5245, validation loss: 0.2651
2024-05-22 11:55:08 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 0.2554
2024-05-22 11:55:09 [INFO]: Epoch 007 - training loss: 0.4623, validation loss: 0.2426
2024-05-22 11:55:09 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2375
2024-05-22 11:55:10 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2323
2024-05-22 11:55:11 [INFO]: Epoch 010 - training loss: 0.4174, validation loss: 0.2287
2024-05-22 11:55:11 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2223
2024-05-22 11:55:12 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.2194
2024-05-22 11:55:13 [INFO]: Epoch 013 - training loss: 0.3904, validation loss: 0.2152
2024-05-22 11:55:13 [INFO]: Epoch 014 - training loss: 0.3820, validation loss: 0.2138
2024-05-22 11:55:14 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.2105
2024-05-22 11:55:15 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.2082
2024-05-22 11:55:15 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.2055
2024-05-22 11:55:16 [INFO]: Epoch 018 - training loss: 0.3616, validation loss: 0.2048
2024-05-22 11:55:17 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.2011
2024-05-22 11:55:17 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.1994
2024-05-22 11:55:18 [INFO]: Epoch 021 - training loss: 0.3494, validation loss: 0.1984
2024-05-22 11:55:19 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.1964
2024-05-22 11:55:19 [INFO]: Epoch 023 - training loss: 0.3431, validation loss: 0.1964
2024-05-22 11:55:20 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.1933
2024-05-22 11:55:21 [INFO]: Epoch 025 - training loss: 0.3383, validation loss: 0.1921
2024-05-22 11:55:21 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.1916
2024-05-22 11:55:22 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.1894
2024-05-22 11:55:23 [INFO]: Epoch 028 - training loss: 0.3305, validation loss: 0.1885
2024-05-22 11:55:23 [INFO]: Epoch 029 - training loss: 0.3271, validation loss: 0.1869
2024-05-22 11:55:24 [INFO]: Epoch 030 - training loss: 0.3263, validation loss: 0.1856
2024-05-22 11:55:25 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.1855
2024-05-22 11:55:25 [INFO]: Epoch 032 - training loss: 0.3209, validation loss: 0.1837
2024-05-22 11:55:26 [INFO]: Epoch 033 - training loss: 0.3195, validation loss: 0.1812
2024-05-22 11:55:27 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1817
2024-05-22 11:55:27 [INFO]: Epoch 035 - training loss: 0.3184, validation loss: 0.1811
2024-05-22 11:55:28 [INFO]: Epoch 036 - training loss: 0.3155, validation loss: 0.1802
2024-05-22 11:55:29 [INFO]: Epoch 037 - training loss: 0.3136, validation loss: 0.1776
2024-05-22 11:55:29 [INFO]: Epoch 038 - training loss: 0.3093, validation loss: 0.1776
2024-05-22 11:55:30 [INFO]: Epoch 039 - training loss: 0.3089, validation loss: 0.1756
2024-05-22 11:55:31 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1743
2024-05-22 11:55:31 [INFO]: Epoch 041 - training loss: 0.3044, validation loss: 0.1736
2024-05-22 11:55:32 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.1732
2024-05-22 11:55:33 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.1718
2024-05-22 11:55:33 [INFO]: Epoch 044 - training loss: 0.3007, validation loss: 0.1714
2024-05-22 11:55:34 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.1716
2024-05-22 11:55:35 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.1701
2024-05-22 11:55:35 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1687
2024-05-22 11:55:36 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1688
2024-05-22 11:55:37 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.1676
2024-05-22 11:55:37 [INFO]: Epoch 050 - training loss: 0.2912, validation loss: 0.1668
2024-05-22 11:55:38 [INFO]: Epoch 051 - training loss: 0.2916, validation loss: 0.1672
2024-05-22 11:55:39 [INFO]: Epoch 052 - training loss: 0.2898, validation loss: 0.1651
2024-05-22 11:55:39 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.1650
2024-05-22 11:55:40 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1641
2024-05-22 11:55:41 [INFO]: Epoch 055 - training loss: 0.2848, validation loss: 0.1631
2024-05-22 11:55:42 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1623
2024-05-22 11:55:42 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.1609
2024-05-22 11:55:43 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.1606
2024-05-22 11:55:44 [INFO]: Epoch 059 - training loss: 0.2805, validation loss: 0.1601
2024-05-22 11:55:44 [INFO]: Epoch 060 - training loss: 0.2808, validation loss: 0.1602
2024-05-22 11:55:45 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1598
2024-05-22 11:55:46 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1585
2024-05-22 11:55:46 [INFO]: Epoch 063 - training loss: 0.2755, validation loss: 0.1583
2024-05-22 11:55:47 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1571
2024-05-22 11:55:48 [INFO]: Epoch 065 - training loss: 0.2727, validation loss: 0.1574
2024-05-22 11:55:48 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1568
2024-05-22 11:55:49 [INFO]: Epoch 067 - training loss: 0.2702, validation loss: 0.1558
2024-05-22 11:55:50 [INFO]: Epoch 068 - training loss: 0.2703, validation loss: 0.1553
2024-05-22 11:55:50 [INFO]: Epoch 069 - training loss: 0.2677, validation loss: 0.1552
2024-05-22 11:55:51 [INFO]: Epoch 070 - training loss: 0.2671, validation loss: 0.1553
2024-05-22 11:55:52 [INFO]: Epoch 071 - training loss: 0.2658, validation loss: 0.1544
2024-05-22 11:55:52 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1531
2024-05-22 11:55:53 [INFO]: Epoch 073 - training loss: 0.2662, validation loss: 0.1531
2024-05-22 11:55:54 [INFO]: Epoch 074 - training loss: 0.2638, validation loss: 0.1525
2024-05-22 11:55:54 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.1522
2024-05-22 11:55:55 [INFO]: Epoch 076 - training loss: 0.2615, validation loss: 0.1520
2024-05-22 11:55:56 [INFO]: Epoch 077 - training loss: 0.2610, validation loss: 0.1516
2024-05-22 11:55:56 [INFO]: Epoch 078 - training loss: 0.2611, validation loss: 0.1520
2024-05-22 11:55:57 [INFO]: Epoch 079 - training loss: 0.2603, validation loss: 0.1508
2024-05-22 11:55:58 [INFO]: Epoch 080 - training loss: 0.2574, validation loss: 0.1503
2024-05-22 11:55:58 [INFO]: Epoch 081 - training loss: 0.2578, validation loss: 0.1505
2024-05-22 11:55:59 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.1502
2024-05-22 11:56:00 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1494
2024-05-22 11:56:00 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1484
2024-05-22 11:56:01 [INFO]: Epoch 085 - training loss: 0.2534, validation loss: 0.1487
2024-05-22 11:56:02 [INFO]: Epoch 086 - training loss: 0.2533, validation loss: 0.1476
2024-05-22 11:56:02 [INFO]: Epoch 087 - training loss: 0.2540, validation loss: 0.1478
2024-05-22 11:56:03 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1474
2024-05-22 11:56:04 [INFO]: Epoch 089 - training loss: 0.2516, validation loss: 0.1467
2024-05-22 11:56:04 [INFO]: Epoch 090 - training loss: 0.2504, validation loss: 0.1462
2024-05-22 11:56:05 [INFO]: Epoch 091 - training loss: 0.2500, validation loss: 0.1464
2024-05-22 11:56:06 [INFO]: Epoch 092 - training loss: 0.2496, validation loss: 0.1458
2024-05-22 11:56:06 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1459
2024-05-22 11:56:07 [INFO]: Epoch 094 - training loss: 0.2472, validation loss: 0.1454
2024-05-22 11:56:08 [INFO]: Epoch 095 - training loss: 0.2475, validation loss: 0.1451
2024-05-22 11:56:08 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1453
2024-05-22 11:56:09 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1450
2024-05-22 11:56:10 [INFO]: Epoch 098 - training loss: 0.2459, validation loss: 0.1444
2024-05-22 11:56:10 [INFO]: Epoch 099 - training loss: 0.2448, validation loss: 0.1452
2024-05-22 11:56:11 [INFO]: Epoch 100 - training loss: 0.2465, validation loss: 0.1441
2024-05-22 11:56:12 [INFO]: Epoch 101 - training loss: 0.2451, validation loss: 0.1436
2024-05-22 11:56:12 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1433
2024-05-22 11:56:13 [INFO]: Epoch 103 - training loss: 0.2429, validation loss: 0.1435
2024-05-22 11:56:14 [INFO]: Epoch 104 - training loss: 0.2426, validation loss: 0.1433
2024-05-22 11:56:14 [INFO]: Epoch 105 - training loss: 0.2430, validation loss: 0.1431
2024-05-22 11:56:15 [INFO]: Epoch 106 - training loss: 0.2420, validation loss: 0.1425
2024-05-22 11:56:16 [INFO]: Epoch 107 - training loss: 0.2417, validation loss: 0.1429
2024-05-22 11:56:16 [INFO]: Epoch 108 - training loss: 0.2405, validation loss: 0.1421
2024-05-22 11:56:17 [INFO]: Epoch 109 - training loss: 0.2401, validation loss: 0.1428
2024-05-22 11:56:18 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1425
2024-05-22 11:56:18 [INFO]: Epoch 111 - training loss: 0.2396, validation loss: 0.1432
2024-05-22 11:56:19 [INFO]: Epoch 112 - training loss: 0.2383, validation loss: 0.1415
2024-05-22 11:56:20 [INFO]: Epoch 113 - training loss: 0.2368, validation loss: 0.1415
2024-05-22 11:56:20 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1413
2024-05-22 11:56:21 [INFO]: Epoch 115 - training loss: 0.2379, validation loss: 0.1408
2024-05-22 11:56:22 [INFO]: Epoch 116 - training loss: 0.2376, validation loss: 0.1409
2024-05-22 11:56:22 [INFO]: Epoch 117 - training loss: 0.2352, validation loss: 0.1411
2024-05-22 11:56:23 [INFO]: Epoch 118 - training loss: 0.2349, validation loss: 0.1410
2024-05-22 11:56:24 [INFO]: Epoch 119 - training loss: 0.2340, validation loss: 0.1399
2024-05-22 11:56:24 [INFO]: Epoch 120 - training loss: 0.2331, validation loss: 0.1401
2024-05-22 11:56:25 [INFO]: Epoch 121 - training loss: 0.2324, validation loss: 0.1391
2024-05-22 11:56:25 [INFO]: Epoch 122 - training loss: 0.2342, validation loss: 0.1398
2024-05-22 11:56:26 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1393
2024-05-22 11:56:27 [INFO]: Epoch 124 - training loss: 0.2320, validation loss: 0.1391
2024-05-22 11:56:27 [INFO]: Epoch 125 - training loss: 0.2323, validation loss: 0.1396
2024-05-22 11:56:28 [INFO]: Epoch 126 - training loss: 0.2313, validation loss: 0.1387
2024-05-22 11:56:29 [INFO]: Epoch 127 - training loss: 0.2326, validation loss: 0.1393
2024-05-22 11:56:29 [INFO]: Epoch 128 - training loss: 0.2309, validation loss: 0.1399
2024-05-22 11:56:30 [INFO]: Epoch 129 - training loss: 0.2301, validation loss: 0.1391
2024-05-22 11:56:31 [INFO]: Epoch 130 - training loss: 0.2300, validation loss: 0.1385
2024-05-22 11:56:31 [INFO]: Epoch 131 - training loss: 0.2298, validation loss: 0.1386
2024-05-22 11:56:32 [INFO]: Epoch 132 - training loss: 0.2300, validation loss: 0.1383
2024-05-22 11:56:33 [INFO]: Epoch 133 - training loss: 0.2289, validation loss: 0.1391
2024-05-22 11:56:33 [INFO]: Epoch 134 - training loss: 0.2279, validation loss: 0.1381
2024-05-22 11:56:34 [INFO]: Epoch 135 - training loss: 0.2270, validation loss: 0.1379
2024-05-22 11:56:35 [INFO]: Epoch 136 - training loss: 0.2283, validation loss: 0.1389
2024-05-22 11:56:35 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1374
2024-05-22 11:56:36 [INFO]: Epoch 138 - training loss: 0.2264, validation loss: 0.1375
2024-05-22 11:56:37 [INFO]: Epoch 139 - training loss: 0.2248, validation loss: 0.1371
2024-05-22 11:56:37 [INFO]: Epoch 140 - training loss: 0.2258, validation loss: 0.1364
2024-05-22 11:56:38 [INFO]: Epoch 141 - training loss: 0.2263, validation loss: 0.1373
2024-05-22 11:56:39 [INFO]: Epoch 142 - training loss: 0.2249, validation loss: 0.1366
2024-05-22 11:56:39 [INFO]: Epoch 143 - training loss: 0.2246, validation loss: 0.1361
2024-05-22 11:56:40 [INFO]: Epoch 144 - training loss: 0.2235, validation loss: 0.1354
2024-05-22 11:56:41 [INFO]: Epoch 145 - training loss: 0.2238, validation loss: 0.1361
2024-05-22 11:56:41 [INFO]: Epoch 146 - training loss: 0.2232, validation loss: 0.1361
2024-05-22 11:56:42 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1363
2024-05-22 11:56:43 [INFO]: Epoch 148 - training loss: 0.2224, validation loss: 0.1365
2024-05-22 11:56:43 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1351
2024-05-22 11:56:44 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1354
2024-05-22 11:56:45 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1348
2024-05-22 11:56:45 [INFO]: Epoch 152 - training loss: 0.2216, validation loss: 0.1346
2024-05-22 11:56:46 [INFO]: Epoch 153 - training loss: 0.2202, validation loss: 0.1348
2024-05-22 11:56:46 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1348
2024-05-22 11:56:47 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1343
2024-05-22 11:56:48 [INFO]: Epoch 156 - training loss: 0.2193, validation loss: 0.1350
2024-05-22 11:56:48 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1344
2024-05-22 11:56:49 [INFO]: Epoch 158 - training loss: 0.2200, validation loss: 0.1344
2024-05-22 11:56:50 [INFO]: Epoch 159 - training loss: 0.2189, validation loss: 0.1341
2024-05-22 11:56:50 [INFO]: Epoch 160 - training loss: 0.2198, validation loss: 0.1349
2024-05-22 11:56:51 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1341
2024-05-22 11:56:52 [INFO]: Epoch 162 - training loss: 0.2226, validation loss: 0.1341
2024-05-22 11:56:52 [INFO]: Epoch 163 - training loss: 0.2193, validation loss: 0.1337
2024-05-22 11:56:53 [INFO]: Epoch 164 - training loss: 0.2169, validation loss: 0.1339
2024-05-22 11:56:54 [INFO]: Epoch 165 - training loss: 0.2175, validation loss: 0.1338
2024-05-22 11:56:54 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1340
2024-05-22 11:56:55 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1339
2024-05-22 11:56:56 [INFO]: Epoch 168 - training loss: 0.2165, validation loss: 0.1330
2024-05-22 11:56:56 [INFO]: Epoch 169 - training loss: 0.2167, validation loss: 0.1333
2024-05-22 11:56:57 [INFO]: Epoch 170 - training loss: 0.2166, validation loss: 0.1330
2024-05-22 11:56:58 [INFO]: Epoch 171 - training loss: 0.2167, validation loss: 0.1334
2024-05-22 11:56:58 [INFO]: Epoch 172 - training loss: 0.2182, validation loss: 0.1341
2024-05-22 11:56:59 [INFO]: Epoch 173 - training loss: 0.2148, validation loss: 0.1329
2024-05-22 11:57:00 [INFO]: Epoch 174 - training loss: 0.2140, validation loss: 0.1319
2024-05-22 11:57:00 [INFO]: Epoch 175 - training loss: 0.2138, validation loss: 0.1333
2024-05-22 11:57:01 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1324
2024-05-22 11:57:02 [INFO]: Epoch 177 - training loss: 0.2137, validation loss: 0.1322
2024-05-22 11:57:02 [INFO]: Epoch 178 - training loss: 0.2150, validation loss: 0.1329
2024-05-22 11:57:03 [INFO]: Epoch 179 - training loss: 0.2127, validation loss: 0.1323
2024-05-22 11:57:04 [INFO]: Epoch 180 - training loss: 0.2136, validation loss: 0.1323
2024-05-22 11:57:04 [INFO]: Epoch 181 - training loss: 0.2144, validation loss: 0.1331
2024-05-22 11:57:05 [INFO]: Epoch 182 - training loss: 0.2185, validation loss: 0.1317
2024-05-22 11:57:05 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1316
2024-05-22 11:57:06 [INFO]: Epoch 184 - training loss: 0.2124, validation loss: 0.1319
2024-05-22 11:57:07 [INFO]: Epoch 185 - training loss: 0.2115, validation loss: 0.1324
2024-05-22 11:57:07 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1317
2024-05-22 11:57:08 [INFO]: Epoch 187 - training loss: 0.2111, validation loss: 0.1311
2024-05-22 11:57:09 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1315
2024-05-22 11:57:09 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.1311
2024-05-22 11:57:10 [INFO]: Epoch 190 - training loss: 0.2115, validation loss: 0.1326
2024-05-22 11:57:11 [INFO]: Epoch 191 - training loss: 0.2106, validation loss: 0.1310
2024-05-22 11:57:11 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.1312
2024-05-22 11:57:12 [INFO]: Epoch 193 - training loss: 0.2090, validation loss: 0.1313
2024-05-22 11:57:13 [INFO]: Epoch 194 - training loss: 0.2087, validation loss: 0.1315
2024-05-22 11:57:13 [INFO]: Epoch 195 - training loss: 0.2099, validation loss: 0.1313
2024-05-22 11:57:14 [INFO]: Epoch 196 - training loss: 0.2092, validation loss: 0.1316
2024-05-22 11:57:15 [INFO]: Epoch 197 - training loss: 0.2090, validation loss: 0.1309
2024-05-22 11:57:15 [INFO]: Epoch 198 - training loss: 0.2077, validation loss: 0.1310
2024-05-22 11:57:16 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.1308
2024-05-22 11:57:17 [INFO]: Epoch 200 - training loss: 0.2076, validation loss: 0.1309
2024-05-22 11:57:17 [INFO]: Epoch 201 - training loss: 0.2080, validation loss: 0.1307
2024-05-22 11:57:18 [INFO]: Epoch 202 - training loss: 0.2088, validation loss: 0.1301
2024-05-22 11:57:19 [INFO]: Epoch 203 - training loss: 0.2083, validation loss: 0.1301
2024-05-22 11:57:19 [INFO]: Epoch 204 - training loss: 0.2079, validation loss: 0.1307
2024-05-22 11:57:20 [INFO]: Epoch 205 - training loss: 0.2064, validation loss: 0.1301
2024-05-22 11:57:21 [INFO]: Epoch 206 - training loss: 0.2066, validation loss: 0.1304
2024-05-22 11:57:21 [INFO]: Epoch 207 - training loss: 0.2053, validation loss: 0.1289
2024-05-22 11:57:22 [INFO]: Epoch 208 - training loss: 0.2058, validation loss: 0.1300
2024-05-22 11:57:23 [INFO]: Epoch 209 - training loss: 0.2084, validation loss: 0.1300
2024-05-22 11:57:23 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1295
2024-05-22 11:57:24 [INFO]: Epoch 211 - training loss: 0.2053, validation loss: 0.1306
2024-05-22 11:57:24 [INFO]: Epoch 212 - training loss: 0.2033, validation loss: 0.1298
2024-05-22 11:57:25 [INFO]: Epoch 213 - training loss: 0.2050, validation loss: 0.1296
2024-05-22 11:57:26 [INFO]: Epoch 214 - training loss: 0.2050, validation loss: 0.1309
2024-05-22 11:57:26 [INFO]: Epoch 215 - training loss: 0.2042, validation loss: 0.1296
2024-05-22 11:57:27 [INFO]: Epoch 216 - training loss: 0.2038, validation loss: 0.1291
2024-05-22 11:57:28 [INFO]: Epoch 217 - training loss: 0.2034, validation loss: 0.1295
2024-05-22 11:57:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:57:28 [INFO]: Finished training. The best model is from epoch#207.
2024-05-22 11:57:28 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_air_quality/20240522_T115502/SAITS.pypots
2024-05-22 11:57:28 [INFO]: SAITS on Air-Quality: MAE=0.1469, MSE=0.1191
2024-05-22 11:57:28 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-22 11:57:28 [INFO]: Using the given device: cuda:0
2024-05-22 11:57:28 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240522_T115728
2024-05-22 11:57:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_air_quality/20240522_T115728/tensorboard
2024-05-22 11:57:28 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 11:57:28 [INFO]: Epoch 001 - training loss: 0.9071, validation loss: 0.4744
2024-05-22 11:57:29 [INFO]: Epoch 002 - training loss: 0.5758, validation loss: 0.3657
2024-05-22 11:57:29 [INFO]: Epoch 003 - training loss: 0.4888, validation loss: 0.3042
2024-05-22 11:57:29 [INFO]: Epoch 004 - training loss: 0.4411, validation loss: 0.2748
2024-05-22 11:57:30 [INFO]: Epoch 005 - training loss: 0.4147, validation loss: 0.2589
2024-05-22 11:57:30 [INFO]: Epoch 006 - training loss: 0.3890, validation loss: 0.2483
2024-05-22 11:57:30 [INFO]: Epoch 007 - training loss: 0.3759, validation loss: 0.2402
2024-05-22 11:57:31 [INFO]: Epoch 008 - training loss: 0.3661, validation loss: 0.2355
2024-05-22 11:57:31 [INFO]: Epoch 009 - training loss: 0.3549, validation loss: 0.2295
2024-05-22 11:57:31 [INFO]: Epoch 010 - training loss: 0.3475, validation loss: 0.2238
2024-05-22 11:57:32 [INFO]: Epoch 011 - training loss: 0.3391, validation loss: 0.2214
2024-05-22 11:57:32 [INFO]: Epoch 012 - training loss: 0.3340, validation loss: 0.2167
2024-05-22 11:57:32 [INFO]: Epoch 013 - training loss: 0.3281, validation loss: 0.2139
2024-05-22 11:57:33 [INFO]: Epoch 014 - training loss: 0.3246, validation loss: 0.2123
2024-05-22 11:57:33 [INFO]: Epoch 015 - training loss: 0.3254, validation loss: 0.2093
2024-05-22 11:57:33 [INFO]: Epoch 016 - training loss: 0.3188, validation loss: 0.2056
2024-05-22 11:57:33 [INFO]: Epoch 017 - training loss: 0.3155, validation loss: 0.2031
2024-05-22 11:57:34 [INFO]: Epoch 018 - training loss: 0.3116, validation loss: 0.1999
2024-05-22 11:57:34 [INFO]: Epoch 019 - training loss: 0.3083, validation loss: 0.1985
2024-05-22 11:57:34 [INFO]: Epoch 020 - training loss: 0.3080, validation loss: 0.1943
2024-05-22 11:57:35 [INFO]: Epoch 021 - training loss: 0.3044, validation loss: 0.1942
2024-05-22 11:57:35 [INFO]: Epoch 022 - training loss: 0.3013, validation loss: 0.1919
2024-05-22 11:57:35 [INFO]: Epoch 023 - training loss: 0.2992, validation loss: 0.1904
2024-05-22 11:57:36 [INFO]: Epoch 024 - training loss: 0.2952, validation loss: 0.1891
2024-05-22 11:57:36 [INFO]: Epoch 025 - training loss: 0.2949, validation loss: 0.1888
2024-05-22 11:57:36 [INFO]: Epoch 026 - training loss: 0.2936, validation loss: 0.1872
2024-05-22 11:57:37 [INFO]: Epoch 027 - training loss: 0.2929, validation loss: 0.1878
2024-05-22 11:57:37 [INFO]: Epoch 028 - training loss: 0.2890, validation loss: 0.1857
2024-05-22 11:57:37 [INFO]: Epoch 029 - training loss: 0.2865, validation loss: 0.1854
2024-05-22 11:57:38 [INFO]: Epoch 030 - training loss: 0.2882, validation loss: 0.1839
2024-05-22 11:57:38 [INFO]: Epoch 031 - training loss: 0.2867, validation loss: 0.1838
2024-05-22 11:57:38 [INFO]: Epoch 032 - training loss: 0.2845, validation loss: 0.1834
2024-05-22 11:57:39 [INFO]: Epoch 033 - training loss: 0.2838, validation loss: 0.1820
2024-05-22 11:57:39 [INFO]: Epoch 034 - training loss: 0.2804, validation loss: 0.1825
2024-05-22 11:57:39 [INFO]: Epoch 035 - training loss: 0.2789, validation loss: 0.1814
2024-05-22 11:57:39 [INFO]: Epoch 036 - training loss: 0.2773, validation loss: 0.1806
2024-05-22 11:57:40 [INFO]: Epoch 037 - training loss: 0.2757, validation loss: 0.1828
2024-05-22 11:57:40 [INFO]: Epoch 038 - training loss: 0.2767, validation loss: 0.1785
2024-05-22 11:57:40 [INFO]: Epoch 039 - training loss: 0.2762, validation loss: 0.1800
2024-05-22 11:57:41 [INFO]: Epoch 040 - training loss: 0.2733, validation loss: 0.1784
2024-05-22 11:57:41 [INFO]: Epoch 041 - training loss: 0.2699, validation loss: 0.1782
2024-05-22 11:57:41 [INFO]: Epoch 042 - training loss: 0.2713, validation loss: 0.1795
2024-05-22 11:57:42 [INFO]: Epoch 043 - training loss: 0.2705, validation loss: 0.1769
2024-05-22 11:57:42 [INFO]: Epoch 044 - training loss: 0.2699, validation loss: 0.1763
2024-05-22 11:57:42 [INFO]: Epoch 045 - training loss: 0.2718, validation loss: 0.1777
2024-05-22 11:57:43 [INFO]: Epoch 046 - training loss: 0.2681, validation loss: 0.1777
2024-05-22 11:57:43 [INFO]: Epoch 047 - training loss: 0.2677, validation loss: 0.1776
2024-05-22 11:57:43 [INFO]: Epoch 048 - training loss: 0.2688, validation loss: 0.1762
2024-05-22 11:57:44 [INFO]: Epoch 049 - training loss: 0.2653, validation loss: 0.1743
2024-05-22 11:57:44 [INFO]: Epoch 050 - training loss: 0.2638, validation loss: 0.1739
2024-05-22 11:57:44 [INFO]: Epoch 051 - training loss: 0.2612, validation loss: 0.1733
2024-05-22 11:57:44 [INFO]: Epoch 052 - training loss: 0.2611, validation loss: 0.1774
2024-05-22 11:57:45 [INFO]: Epoch 053 - training loss: 0.2630, validation loss: 0.1735
2024-05-22 11:57:45 [INFO]: Epoch 054 - training loss: 0.2617, validation loss: 0.1741
2024-05-22 11:57:45 [INFO]: Epoch 055 - training loss: 0.2591, validation loss: 0.1708
2024-05-22 11:57:46 [INFO]: Epoch 056 - training loss: 0.2601, validation loss: 0.1718
2024-05-22 11:57:46 [INFO]: Epoch 057 - training loss: 0.2581, validation loss: 0.1721
2024-05-22 11:57:46 [INFO]: Epoch 058 - training loss: 0.2559, validation loss: 0.1715
2024-05-22 11:57:47 [INFO]: Epoch 059 - training loss: 0.2584, validation loss: 0.1717
2024-05-22 11:57:47 [INFO]: Epoch 060 - training loss: 0.2566, validation loss: 0.1718
2024-05-22 11:57:47 [INFO]: Epoch 061 - training loss: 0.2564, validation loss: 0.1703
2024-05-22 11:57:48 [INFO]: Epoch 062 - training loss: 0.2572, validation loss: 0.1714
2024-05-22 11:57:48 [INFO]: Epoch 063 - training loss: 0.2554, validation loss: 0.1705
2024-05-22 11:57:48 [INFO]: Epoch 064 - training loss: 0.2520, validation loss: 0.1720
2024-05-22 11:57:49 [INFO]: Epoch 065 - training loss: 0.2527, validation loss: 0.1694
2024-05-22 11:57:49 [INFO]: Epoch 066 - training loss: 0.2507, validation loss: 0.1704
2024-05-22 11:57:49 [INFO]: Epoch 067 - training loss: 0.2489, validation loss: 0.1674
2024-05-22 11:57:50 [INFO]: Epoch 068 - training loss: 0.2494, validation loss: 0.1672
2024-05-22 11:57:50 [INFO]: Epoch 069 - training loss: 0.2480, validation loss: 0.1677
2024-05-22 11:57:50 [INFO]: Epoch 070 - training loss: 0.2476, validation loss: 0.1677
2024-05-22 11:57:50 [INFO]: Epoch 071 - training loss: 0.2476, validation loss: 0.1680
2024-05-22 11:57:51 [INFO]: Epoch 072 - training loss: 0.2457, validation loss: 0.1665
2024-05-22 11:57:51 [INFO]: Epoch 073 - training loss: 0.2527, validation loss: 0.1694
2024-05-22 11:57:51 [INFO]: Epoch 074 - training loss: 0.2497, validation loss: 0.1662
2024-05-22 11:57:52 [INFO]: Epoch 075 - training loss: 0.2438, validation loss: 0.1649
2024-05-22 11:57:52 [INFO]: Epoch 076 - training loss: 0.2431, validation loss: 0.1647
2024-05-22 11:57:52 [INFO]: Epoch 077 - training loss: 0.2416, validation loss: 0.1651
2024-05-22 11:57:53 [INFO]: Epoch 078 - training loss: 0.2414, validation loss: 0.1650
2024-05-22 11:57:53 [INFO]: Epoch 079 - training loss: 0.2405, validation loss: 0.1655
2024-05-22 11:57:53 [INFO]: Epoch 080 - training loss: 0.2403, validation loss: 0.1658
2024-05-22 11:57:54 [INFO]: Epoch 081 - training loss: 0.2420, validation loss: 0.1653
2024-05-22 11:57:54 [INFO]: Epoch 082 - training loss: 0.2409, validation loss: 0.1643
2024-05-22 11:57:54 [INFO]: Epoch 083 - training loss: 0.2386, validation loss: 0.1636
2024-05-22 11:57:55 [INFO]: Epoch 084 - training loss: 0.2387, validation loss: 0.1633
2024-05-22 11:57:55 [INFO]: Epoch 085 - training loss: 0.2354, validation loss: 0.1638
2024-05-22 11:57:55 [INFO]: Epoch 086 - training loss: 0.2387, validation loss: 0.1620
2024-05-22 11:57:55 [INFO]: Epoch 087 - training loss: 0.2371, validation loss: 0.1628
2024-05-22 11:57:56 [INFO]: Epoch 088 - training loss: 0.2360, validation loss: 0.1617
2024-05-22 11:57:56 [INFO]: Epoch 089 - training loss: 0.2367, validation loss: 0.1608
2024-05-22 11:57:56 [INFO]: Epoch 090 - training loss: 0.2353, validation loss: 0.1617
2024-05-22 11:57:57 [INFO]: Epoch 091 - training loss: 0.2322, validation loss: 0.1620
2024-05-22 11:57:57 [INFO]: Epoch 092 - training loss: 0.2337, validation loss: 0.1618
2024-05-22 11:57:57 [INFO]: Epoch 093 - training loss: 0.2339, validation loss: 0.1603
2024-05-22 11:57:58 [INFO]: Epoch 094 - training loss: 0.2332, validation loss: 0.1601
2024-05-22 11:57:58 [INFO]: Epoch 095 - training loss: 0.2336, validation loss: 0.1588
2024-05-22 11:57:58 [INFO]: Epoch 096 - training loss: 0.2311, validation loss: 0.1596
2024-05-22 11:57:59 [INFO]: Epoch 097 - training loss: 0.2288, validation loss: 0.1597
2024-05-22 11:57:59 [INFO]: Epoch 098 - training loss: 0.2320, validation loss: 0.1590
2024-05-22 11:57:59 [INFO]: Epoch 099 - training loss: 0.2307, validation loss: 0.1583
2024-05-22 11:58:00 [INFO]: Epoch 100 - training loss: 0.2302, validation loss: 0.1591
2024-05-22 11:58:00 [INFO]: Epoch 101 - training loss: 0.2279, validation loss: 0.1594
2024-05-22 11:58:00 [INFO]: Epoch 102 - training loss: 0.2260, validation loss: 0.1590
2024-05-22 11:58:00 [INFO]: Epoch 103 - training loss: 0.2297, validation loss: 0.1582
2024-05-22 11:58:01 [INFO]: Epoch 104 - training loss: 0.2303, validation loss: 0.1592
2024-05-22 11:58:01 [INFO]: Epoch 105 - training loss: 0.2261, validation loss: 0.1565
2024-05-22 11:58:01 [INFO]: Epoch 106 - training loss: 0.2278, validation loss: 0.1590
2024-05-22 11:58:02 [INFO]: Epoch 107 - training loss: 0.2271, validation loss: 0.1575
2024-05-22 11:58:02 [INFO]: Epoch 108 - training loss: 0.2259, validation loss: 0.1567
2024-05-22 11:58:02 [INFO]: Epoch 109 - training loss: 0.2249, validation loss: 0.1567
2024-05-22 11:58:03 [INFO]: Epoch 110 - training loss: 0.2227, validation loss: 0.1560
2024-05-22 11:58:03 [INFO]: Epoch 111 - training loss: 0.2240, validation loss: 0.1543
2024-05-22 11:58:03 [INFO]: Epoch 112 - training loss: 0.2222, validation loss: 0.1561
2024-05-22 11:58:04 [INFO]: Epoch 113 - training loss: 0.2243, validation loss: 0.1554
2024-05-22 11:58:04 [INFO]: Epoch 114 - training loss: 0.2231, validation loss: 0.1551
2024-05-22 11:58:04 [INFO]: Epoch 115 - training loss: 0.2222, validation loss: 0.1557
2024-05-22 11:58:05 [INFO]: Epoch 116 - training loss: 0.2221, validation loss: 0.1554
2024-05-22 11:58:05 [INFO]: Epoch 117 - training loss: 0.2221, validation loss: 0.1534
2024-05-22 11:58:05 [INFO]: Epoch 118 - training loss: 0.2196, validation loss: 0.1556
2024-05-22 11:58:06 [INFO]: Epoch 119 - training loss: 0.2207, validation loss: 0.1552
2024-05-22 11:58:06 [INFO]: Epoch 120 - training loss: 0.2248, validation loss: 0.1544
2024-05-22 11:58:06 [INFO]: Epoch 121 - training loss: 0.2201, validation loss: 0.1532
2024-05-22 11:58:07 [INFO]: Epoch 122 - training loss: 0.2196, validation loss: 0.1552
2024-05-22 11:58:07 [INFO]: Epoch 123 - training loss: 0.2193, validation loss: 0.1556
2024-05-22 11:58:07 [INFO]: Epoch 124 - training loss: 0.2200, validation loss: 0.1534
2024-05-22 11:58:07 [INFO]: Epoch 125 - training loss: 0.2171, validation loss: 0.1531
2024-05-22 11:58:08 [INFO]: Epoch 126 - training loss: 0.2157, validation loss: 0.1522
2024-05-22 11:58:08 [INFO]: Epoch 127 - training loss: 0.2170, validation loss: 0.1525
2024-05-22 11:58:08 [INFO]: Epoch 128 - training loss: 0.2168, validation loss: 0.1533
2024-05-22 11:58:09 [INFO]: Epoch 129 - training loss: 0.2180, validation loss: 0.1512
2024-05-22 11:58:09 [INFO]: Epoch 130 - training loss: 0.2164, validation loss: 0.1513
2024-05-22 11:58:09 [INFO]: Epoch 131 - training loss: 0.2167, validation loss: 0.1541
2024-05-22 11:58:10 [INFO]: Epoch 132 - training loss: 0.2168, validation loss: 0.1509
2024-05-22 11:58:10 [INFO]: Epoch 133 - training loss: 0.2142, validation loss: 0.1510
2024-05-22 11:58:10 [INFO]: Epoch 134 - training loss: 0.2160, validation loss: 0.1503
2024-05-22 11:58:11 [INFO]: Epoch 135 - training loss: 0.2157, validation loss: 0.1518
2024-05-22 11:58:11 [INFO]: Epoch 136 - training loss: 0.2152, validation loss: 0.1514
2024-05-22 11:58:11 [INFO]: Epoch 137 - training loss: 0.2142, validation loss: 0.1509
2024-05-22 11:58:12 [INFO]: Epoch 138 - training loss: 0.2137, validation loss: 0.1505
2024-05-22 11:58:12 [INFO]: Epoch 139 - training loss: 0.2123, validation loss: 0.1503
2024-05-22 11:58:12 [INFO]: Epoch 140 - training loss: 0.2114, validation loss: 0.1496
2024-05-22 11:58:12 [INFO]: Epoch 141 - training loss: 0.2135, validation loss: 0.1520
2024-05-22 11:58:13 [INFO]: Epoch 142 - training loss: 0.2107, validation loss: 0.1501
2024-05-22 11:58:13 [INFO]: Epoch 143 - training loss: 0.2107, validation loss: 0.1485
2024-05-22 11:58:13 [INFO]: Epoch 144 - training loss: 0.2132, validation loss: 0.1491
2024-05-22 11:58:14 [INFO]: Epoch 145 - training loss: 0.2106, validation loss: 0.1489
2024-05-22 11:58:14 [INFO]: Epoch 146 - training loss: 0.2095, validation loss: 0.1497
2024-05-22 11:58:14 [INFO]: Epoch 147 - training loss: 0.2103, validation loss: 0.1488
2024-05-22 11:58:15 [INFO]: Epoch 148 - training loss: 0.2107, validation loss: 0.1490
2024-05-22 11:58:15 [INFO]: Epoch 149 - training loss: 0.2092, validation loss: 0.1471
2024-05-22 11:58:15 [INFO]: Epoch 150 - training loss: 0.2103, validation loss: 0.1487
2024-05-22 11:58:16 [INFO]: Epoch 151 - training loss: 0.2165, validation loss: 0.1473
2024-05-22 11:58:16 [INFO]: Epoch 152 - training loss: 0.2120, validation loss: 0.1481
2024-05-22 11:58:17 [INFO]: Epoch 153 - training loss: 0.2094, validation loss: 0.1481
2024-05-22 11:58:17 [INFO]: Epoch 154 - training loss: 0.2081, validation loss: 0.1469
2024-05-22 11:58:17 [INFO]: Epoch 155 - training loss: 0.2084, validation loss: 0.1473
2024-05-22 11:58:17 [INFO]: Epoch 156 - training loss: 0.2081, validation loss: 0.1474
2024-05-22 11:58:18 [INFO]: Epoch 157 - training loss: 0.2075, validation loss: 0.1464
2024-05-22 11:58:18 [INFO]: Epoch 158 - training loss: 0.2082, validation loss: 0.1480
2024-05-22 11:58:18 [INFO]: Epoch 159 - training loss: 0.2068, validation loss: 0.1469
2024-05-22 11:58:19 [INFO]: Epoch 160 - training loss: 0.2070, validation loss: 0.1493
2024-05-22 11:58:19 [INFO]: Epoch 161 - training loss: 0.2056, validation loss: 0.1471
2024-05-22 11:58:19 [INFO]: Epoch 162 - training loss: 0.2049, validation loss: 0.1455
2024-05-22 11:58:20 [INFO]: Epoch 163 - training loss: 0.2041, validation loss: 0.1460
2024-05-22 11:58:20 [INFO]: Epoch 164 - training loss: 0.2042, validation loss: 0.1457
2024-05-22 11:58:20 [INFO]: Epoch 165 - training loss: 0.2029, validation loss: 0.1460
2024-05-22 11:58:21 [INFO]: Epoch 166 - training loss: 0.2033, validation loss: 0.1459
2024-05-22 11:58:21 [INFO]: Epoch 167 - training loss: 0.2053, validation loss: 0.1459
2024-05-22 11:58:21 [INFO]: Epoch 168 - training loss: 0.2031, validation loss: 0.1459
2024-05-22 11:58:22 [INFO]: Epoch 169 - training loss: 0.2027, validation loss: 0.1461
2024-05-22 11:58:22 [INFO]: Epoch 170 - training loss: 0.2023, validation loss: 0.1475
2024-05-22 11:58:22 [INFO]: Epoch 171 - training loss: 0.2026, validation loss: 0.1460
2024-05-22 11:58:23 [INFO]: Epoch 172 - training loss: 0.2029, validation loss: 0.1446
2024-05-22 11:58:23 [INFO]: Epoch 173 - training loss: 0.2024, validation loss: 0.1452
2024-05-22 11:58:23 [INFO]: Epoch 174 - training loss: 0.2015, validation loss: 0.1436
2024-05-22 11:58:23 [INFO]: Epoch 175 - training loss: 0.2011, validation loss: 0.1454
2024-05-22 11:58:24 [INFO]: Epoch 176 - training loss: 0.2031, validation loss: 0.1445
2024-05-22 11:58:24 [INFO]: Epoch 177 - training loss: 0.2017, validation loss: 0.1450
2024-05-22 11:58:24 [INFO]: Epoch 178 - training loss: 0.2017, validation loss: 0.1469
2024-05-22 11:58:25 [INFO]: Epoch 179 - training loss: 0.2019, validation loss: 0.1439
2024-05-22 11:58:25 [INFO]: Epoch 180 - training loss: 0.2033, validation loss: 0.1449
2024-05-22 11:58:25 [INFO]: Epoch 181 - training loss: 0.1998, validation loss: 0.1448
2024-05-22 11:58:26 [INFO]: Epoch 182 - training loss: 0.2005, validation loss: 0.1432
2024-05-22 11:58:26 [INFO]: Epoch 183 - training loss: 0.1996, validation loss: 0.1438
2024-05-22 11:58:26 [INFO]: Epoch 184 - training loss: 0.2009, validation loss: 0.1440
2024-05-22 11:58:27 [INFO]: Epoch 185 - training loss: 0.1998, validation loss: 0.1440
2024-05-22 11:58:27 [INFO]: Epoch 186 - training loss: 0.1990, validation loss: 0.1437
2024-05-22 11:58:27 [INFO]: Epoch 187 - training loss: 0.1982, validation loss: 0.1430
2024-05-22 11:58:28 [INFO]: Epoch 188 - training loss: 0.1981, validation loss: 0.1439
2024-05-22 11:58:28 [INFO]: Epoch 189 - training loss: 0.1984, validation loss: 0.1434
2024-05-22 11:58:28 [INFO]: Epoch 190 - training loss: 0.1989, validation loss: 0.1427
2024-05-22 11:58:29 [INFO]: Epoch 191 - training loss: 0.1983, validation loss: 0.1433
2024-05-22 11:58:29 [INFO]: Epoch 192 - training loss: 0.1995, validation loss: 0.1432
2024-05-22 11:58:29 [INFO]: Epoch 193 - training loss: 0.1968, validation loss: 0.1431
2024-05-22 11:58:30 [INFO]: Epoch 194 - training loss: 0.1981, validation loss: 0.1422
2024-05-22 11:58:30 [INFO]: Epoch 195 - training loss: 0.1975, validation loss: 0.1442
2024-05-22 11:58:30 [INFO]: Epoch 196 - training loss: 0.2015, validation loss: 0.1425
2024-05-22 11:58:31 [INFO]: Epoch 197 - training loss: 0.1980, validation loss: 0.1418
2024-05-22 11:58:31 [INFO]: Epoch 198 - training loss: 0.1955, validation loss: 0.1428
2024-05-22 11:58:31 [INFO]: Epoch 199 - training loss: 0.1945, validation loss: 0.1412
2024-05-22 11:58:32 [INFO]: Epoch 200 - training loss: 0.1946, validation loss: 0.1416
2024-05-22 11:58:32 [INFO]: Epoch 201 - training loss: 0.1982, validation loss: 0.1447
2024-05-22 11:58:32 [INFO]: Epoch 202 - training loss: 0.2008, validation loss: 0.1414
2024-05-22 11:58:32 [INFO]: Epoch 203 - training loss: 0.1966, validation loss: 0.1413
2024-05-22 11:58:33 [INFO]: Epoch 204 - training loss: 0.1957, validation loss: 0.1413
2024-05-22 11:58:33 [INFO]: Epoch 205 - training loss: 0.1947, validation loss: 0.1399
2024-05-22 11:58:33 [INFO]: Epoch 206 - training loss: 0.1947, validation loss: 0.1412
2024-05-22 11:58:34 [INFO]: Epoch 207 - training loss: 0.1937, validation loss: 0.1404
2024-05-22 11:58:34 [INFO]: Epoch 208 - training loss: 0.1934, validation loss: 0.1416
2024-05-22 11:58:34 [INFO]: Epoch 209 - training loss: 0.1951, validation loss: 0.1412
2024-05-22 11:58:35 [INFO]: Epoch 210 - training loss: 0.1966, validation loss: 0.1392
2024-05-22 11:58:35 [INFO]: Epoch 211 - training loss: 0.1947, validation loss: 0.1418
2024-05-22 11:58:35 [INFO]: Epoch 212 - training loss: 0.1924, validation loss: 0.1406
2024-05-22 11:58:36 [INFO]: Epoch 213 - training loss: 0.1928, validation loss: 0.1420
2024-05-22 11:58:36 [INFO]: Epoch 214 - training loss: 0.1960, validation loss: 0.1413
2024-05-22 11:58:36 [INFO]: Epoch 215 - training loss: 0.1924, validation loss: 0.1398
2024-05-22 11:58:37 [INFO]: Epoch 216 - training loss: 0.1903, validation loss: 0.1395
2024-05-22 11:58:37 [INFO]: Epoch 217 - training loss: 0.1919, validation loss: 0.1393
2024-05-22 11:58:37 [INFO]: Epoch 218 - training loss: 0.1932, validation loss: 0.1395
2024-05-22 11:58:38 [INFO]: Epoch 219 - training loss: 0.1911, validation loss: 0.1398
2024-05-22 11:58:38 [INFO]: Epoch 220 - training loss: 0.1912, validation loss: 0.1394
2024-05-22 11:58:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:58:38 [INFO]: Finished training. The best model is from epoch#210.
2024-05-22 11:58:38 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_air_quality/20240522_T115728/Transformer.pypots
2024-05-22 11:58:38 [INFO]: Transformer on Air-Quality: MAE=0.1589, MSE=0.1306
2024-05-22 11:58:38 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-22 11:58:38 [INFO]: Using the given device: cuda:0
2024-05-22 11:58:38 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240522_T115838
2024-05-22 11:58:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_air_quality/20240522_T115838/tensorboard
2024-05-22 11:58:39 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 11:58:40 [INFO]: Epoch 001 - training loss: 0.3020, validation loss: 0.2858
2024-05-22 11:58:41 [INFO]: Epoch 002 - training loss: 0.2611, validation loss: 0.2356
2024-05-22 11:58:41 [INFO]: Epoch 003 - training loss: 0.1908, validation loss: 0.2265
2024-05-22 11:58:42 [INFO]: Epoch 004 - training loss: 0.1795, validation loss: 0.2174
2024-05-22 11:58:42 [INFO]: Epoch 005 - training loss: 0.1599, validation loss: 0.2141
2024-05-22 11:58:43 [INFO]: Epoch 006 - training loss: 0.1583, validation loss: 0.2056
2024-05-22 11:58:43 [INFO]: Epoch 007 - training loss: 0.1736, validation loss: 0.2078
2024-05-22 11:58:44 [INFO]: Epoch 008 - training loss: 0.1786, validation loss: 0.1979
2024-05-22 11:58:44 [INFO]: Epoch 009 - training loss: 0.1435, validation loss: 0.1844
2024-05-22 11:58:45 [INFO]: Epoch 010 - training loss: 0.1437, validation loss: 0.1820
2024-05-22 11:58:45 [INFO]: Epoch 011 - training loss: 0.1625, validation loss: 0.1873
2024-05-22 11:58:46 [INFO]: Epoch 012 - training loss: 0.1338, validation loss: 0.1830
2024-05-22 11:58:46 [INFO]: Epoch 013 - training loss: 0.1463, validation loss: 0.1740
2024-05-22 11:58:47 [INFO]: Epoch 014 - training loss: 0.1410, validation loss: 0.1805
2024-05-22 11:58:48 [INFO]: Epoch 015 - training loss: 0.1368, validation loss: 0.1761
2024-05-22 11:58:48 [INFO]: Epoch 016 - training loss: 0.1231, validation loss: 0.1781
2024-05-22 11:58:49 [INFO]: Epoch 017 - training loss: 0.1249, validation loss: 0.1726
2024-05-22 11:58:49 [INFO]: Epoch 018 - training loss: 0.1197, validation loss: 0.1703
2024-05-22 11:58:50 [INFO]: Epoch 019 - training loss: 0.1165, validation loss: 0.1685
2024-05-22 11:58:50 [INFO]: Epoch 020 - training loss: 0.1326, validation loss: 0.1637
2024-05-22 11:58:51 [INFO]: Epoch 021 - training loss: 0.1460, validation loss: 0.1660
2024-05-22 11:58:51 [INFO]: Epoch 022 - training loss: 0.1200, validation loss: 0.1650
2024-05-22 11:58:52 [INFO]: Epoch 023 - training loss: 0.1327, validation loss: 0.1665
2024-05-22 11:58:52 [INFO]: Epoch 024 - training loss: 0.1254, validation loss: 0.1708
2024-05-22 11:58:53 [INFO]: Epoch 025 - training loss: 0.1297, validation loss: 0.1655
2024-05-22 11:58:53 [INFO]: Epoch 026 - training loss: 0.1327, validation loss: 0.1811
2024-05-22 11:58:54 [INFO]: Epoch 027 - training loss: 0.1291, validation loss: 0.1685
2024-05-22 11:58:54 [INFO]: Epoch 028 - training loss: 0.1118, validation loss: 0.1646
2024-05-22 11:58:55 [INFO]: Epoch 029 - training loss: 0.1177, validation loss: 0.1660
2024-05-22 11:58:56 [INFO]: Epoch 030 - training loss: 0.1147, validation loss: 0.1621
2024-05-22 11:58:56 [INFO]: Epoch 031 - training loss: 0.1235, validation loss: 0.1680
2024-05-22 11:58:57 [INFO]: Epoch 032 - training loss: 0.1295, validation loss: 0.1679
2024-05-22 11:58:57 [INFO]: Epoch 033 - training loss: 0.1304, validation loss: 0.1612
2024-05-22 11:58:58 [INFO]: Epoch 034 - training loss: 0.1245, validation loss: 0.1605
2024-05-22 11:58:58 [INFO]: Epoch 035 - training loss: 0.1135, validation loss: 0.1593
2024-05-22 11:58:59 [INFO]: Epoch 036 - training loss: 0.1146, validation loss: 0.1609
2024-05-22 11:58:59 [INFO]: Epoch 037 - training loss: 0.1257, validation loss: 0.1598
2024-05-22 11:59:00 [INFO]: Epoch 038 - training loss: 0.1097, validation loss: 0.1631
2024-05-22 11:59:00 [INFO]: Epoch 039 - training loss: 0.0997, validation loss: 0.1667
2024-05-22 11:59:01 [INFO]: Epoch 040 - training loss: 0.1184, validation loss: 0.1643
2024-05-22 11:59:01 [INFO]: Epoch 041 - training loss: 0.1160, validation loss: 0.1616
2024-05-22 11:59:02 [INFO]: Epoch 042 - training loss: 0.1189, validation loss: 0.1632
2024-05-22 11:59:02 [INFO]: Epoch 043 - training loss: 0.1199, validation loss: 0.1616
2024-05-22 11:59:03 [INFO]: Epoch 044 - training loss: 0.1169, validation loss: 0.1600
2024-05-22 11:59:03 [INFO]: Epoch 045 - training loss: 0.0953, validation loss: 0.1573
2024-05-22 11:59:04 [INFO]: Epoch 046 - training loss: 0.1060, validation loss: 0.1700
2024-05-22 11:59:05 [INFO]: Epoch 047 - training loss: 0.1059, validation loss: 0.1629
2024-05-22 11:59:05 [INFO]: Epoch 048 - training loss: 0.0969, validation loss: 0.1620
2024-05-22 11:59:06 [INFO]: Epoch 049 - training loss: 0.1084, validation loss: 0.1570
2024-05-22 11:59:06 [INFO]: Epoch 050 - training loss: 0.1180, validation loss: 0.1556
2024-05-22 11:59:07 [INFO]: Epoch 051 - training loss: 0.1065, validation loss: 0.1580
2024-05-22 11:59:07 [INFO]: Epoch 052 - training loss: 0.1127, validation loss: 0.1623
2024-05-22 11:59:08 [INFO]: Epoch 053 - training loss: 0.0972, validation loss: 0.1676
2024-05-22 11:59:08 [INFO]: Epoch 054 - training loss: 0.1168, validation loss: 0.1800
2024-05-22 11:59:09 [INFO]: Epoch 055 - training loss: 0.1053, validation loss: 0.1601
2024-05-22 11:59:09 [INFO]: Epoch 056 - training loss: 0.0987, validation loss: 0.1574
2024-05-22 11:59:10 [INFO]: Epoch 057 - training loss: 0.1076, validation loss: 0.1718
2024-05-22 11:59:11 [INFO]: Epoch 058 - training loss: 0.1163, validation loss: 0.1605
2024-05-22 11:59:11 [INFO]: Epoch 059 - training loss: 0.1057, validation loss: 0.1621
2024-05-22 11:59:12 [INFO]: Epoch 060 - training loss: 0.1009, validation loss: 0.1632
2024-05-22 11:59:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 11:59:12 [INFO]: Finished training. The best model is from epoch#50.
2024-05-22 11:59:12 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_air_quality/20240522_T115838/TimesNet.pypots
2024-05-22 11:59:12 [INFO]: TimesNet on Air-Quality: MAE=0.1586, MSE=0.1656
2024-05-22 11:59:12 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-22 11:59:12 [INFO]: Using the given device: cuda:0
2024-05-22 11:59:12 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912
2024-05-22 11:59:12 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/tensorboard
2024-05-22 11:59:12 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 11:59:29 [INFO]: Epoch 001 - training loss: 0.4902, validation loss: 0.3390
2024-05-22 11:59:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch1_loss0.3389756292104721.pypots
2024-05-22 11:59:46 [INFO]: Epoch 002 - training loss: 0.2818, validation loss: 0.2802
2024-05-22 11:59:46 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch2_loss0.28019365668296814.pypots
2024-05-22 12:00:03 [INFO]: Epoch 003 - training loss: 0.2724, validation loss: 0.2589
2024-05-22 12:00:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch3_loss0.2589174032211304.pypots
2024-05-22 12:00:20 [INFO]: Epoch 004 - training loss: 0.2774, validation loss: 0.2360
2024-05-22 12:00:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch4_loss0.23597991615533828.pypots
2024-05-22 12:00:37 [INFO]: Epoch 005 - training loss: 0.2281, validation loss: 0.2131
2024-05-22 12:00:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch5_loss0.21305928081274034.pypots
2024-05-22 12:00:54 [INFO]: Epoch 006 - training loss: 0.2108, validation loss: 0.2017
2024-05-22 12:00:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch6_loss0.2017357423901558.pypots
2024-05-22 12:01:10 [INFO]: Epoch 007 - training loss: 0.1911, validation loss: 0.1916
2024-05-22 12:01:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch7_loss0.1916474163532257.pypots
2024-05-22 12:01:27 [INFO]: Epoch 008 - training loss: 0.1880, validation loss: 0.1780
2024-05-22 12:01:27 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch8_loss0.17803995609283446.pypots
2024-05-22 12:01:44 [INFO]: Epoch 009 - training loss: 0.1875, validation loss: 0.1637
2024-05-22 12:01:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch9_loss0.1637182801961899.pypots
2024-05-22 12:02:01 [INFO]: Epoch 010 - training loss: 0.1870, validation loss: 0.1596
2024-05-22 12:02:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch10_loss0.1596044570207596.pypots
2024-05-22 12:02:18 [INFO]: Epoch 011 - training loss: 0.1799, validation loss: 0.1547
2024-05-22 12:02:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch11_loss0.1547284334897995.pypots
2024-05-22 12:02:35 [INFO]: Epoch 012 - training loss: 0.1706, validation loss: 0.1522
2024-05-22 12:02:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch12_loss0.15223246514797212.pypots
2024-05-22 12:02:51 [INFO]: Epoch 013 - training loss: 0.1974, validation loss: 0.1552
2024-05-22 12:02:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch13_loss0.15519162118434907.pypots
2024-05-22 12:03:08 [INFO]: Epoch 014 - training loss: 0.1755, validation loss: 0.1515
2024-05-22 12:03:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch14_loss0.15150849223136903.pypots
2024-05-22 12:03:25 [INFO]: Epoch 015 - training loss: 0.1748, validation loss: 0.1508
2024-05-22 12:03:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch15_loss0.15081706196069716.pypots
2024-05-22 12:03:42 [INFO]: Epoch 016 - training loss: 0.1756, validation loss: 0.1488
2024-05-22 12:03:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch16_loss0.1488406851887703.pypots
2024-05-22 12:03:59 [INFO]: Epoch 017 - training loss: 0.1624, validation loss: 0.1458
2024-05-22 12:03:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch17_loss0.14581780433654784.pypots
2024-05-22 12:04:16 [INFO]: Epoch 018 - training loss: 0.1643, validation loss: 0.1423
2024-05-22 12:04:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch18_loss0.1423432134091854.pypots
2024-05-22 12:04:32 [INFO]: Epoch 019 - training loss: 0.1752, validation loss: 0.1363
2024-05-22 12:04:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch19_loss0.13630035296082496.pypots
2024-05-22 12:04:49 [INFO]: Epoch 020 - training loss: 0.1744, validation loss: 0.1404
2024-05-22 12:04:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch20_loss0.14035681784152984.pypots
2024-05-22 12:05:06 [INFO]: Epoch 021 - training loss: 0.1447, validation loss: 0.1402
2024-05-22 12:05:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch21_loss0.14023903459310533.pypots
2024-05-22 12:05:23 [INFO]: Epoch 022 - training loss: 0.1462, validation loss: 0.1344
2024-05-22 12:05:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch22_loss0.13443220630288125.pypots
2024-05-22 12:05:40 [INFO]: Epoch 023 - training loss: 0.1549, validation loss: 0.1337
2024-05-22 12:05:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch23_loss0.1336817465722561.pypots
2024-05-22 12:05:56 [INFO]: Epoch 024 - training loss: 0.1483, validation loss: 0.1328
2024-05-22 12:05:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch24_loss0.13277870416641235.pypots
2024-05-22 12:06:13 [INFO]: Epoch 025 - training loss: 0.1461, validation loss: 0.1412
2024-05-22 12:06:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch25_loss0.1411587916314602.pypots
2024-05-22 12:06:30 [INFO]: Epoch 026 - training loss: 0.1667, validation loss: 0.1495
2024-05-22 12:06:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch26_loss0.14951914995908738.pypots
2024-05-22 12:06:47 [INFO]: Epoch 027 - training loss: 0.1457, validation loss: 0.1334
2024-05-22 12:06:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch27_loss0.13338858336210252.pypots
2024-05-22 12:07:04 [INFO]: Epoch 028 - training loss: 0.1492, validation loss: 0.1296
2024-05-22 12:07:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch28_loss0.129610725492239.pypots
2024-05-22 12:07:21 [INFO]: Epoch 029 - training loss: 0.1563, validation loss: 0.1357
2024-05-22 12:07:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch29_loss0.1356867514550686.pypots
2024-05-22 12:07:37 [INFO]: Epoch 030 - training loss: 0.1381, validation loss: 0.1272
2024-05-22 12:07:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch30_loss0.1272353745996952.pypots
2024-05-22 12:07:54 [INFO]: Epoch 031 - training loss: 0.1428, validation loss: 0.1251
2024-05-22 12:07:54 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch31_loss0.1251491867005825.pypots
2024-05-22 12:08:11 [INFO]: Epoch 032 - training loss: 0.1346, validation loss: 0.1279
2024-05-22 12:08:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch32_loss0.12788189724087715.pypots
2024-05-22 12:08:28 [INFO]: Epoch 033 - training loss: 0.1242, validation loss: 0.1317
2024-05-22 12:08:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch33_loss0.13173776790499686.pypots
2024-05-22 12:08:45 [INFO]: Epoch 034 - training loss: 0.1406, validation loss: 0.1280
2024-05-22 12:08:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch34_loss0.1280488573014736.pypots
2024-05-22 12:09:02 [INFO]: Epoch 035 - training loss: 0.1558, validation loss: 0.1244
2024-05-22 12:09:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch35_loss0.12442156672477722.pypots
2024-05-22 12:09:18 [INFO]: Epoch 036 - training loss: 0.1369, validation loss: 0.1275
2024-05-22 12:09:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch36_loss0.12747233882546424.pypots
2024-05-22 12:09:35 [INFO]: Epoch 037 - training loss: 0.1400, validation loss: 0.1391
2024-05-22 12:09:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch37_loss0.13908994272351266.pypots
2024-05-22 12:09:52 [INFO]: Epoch 038 - training loss: 0.1335, validation loss: 0.1285
2024-05-22 12:09:52 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch38_loss0.1284674070775509.pypots
2024-05-22 12:10:09 [INFO]: Epoch 039 - training loss: 0.1210, validation loss: 0.1229
2024-05-22 12:10:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch39_loss0.12287608981132507.pypots
2024-05-22 12:10:26 [INFO]: Epoch 040 - training loss: 0.1245, validation loss: 0.1212
2024-05-22 12:10:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch40_loss0.12116272151470184.pypots
2024-05-22 12:10:42 [INFO]: Epoch 041 - training loss: 0.1325, validation loss: 0.1187
2024-05-22 12:10:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch41_loss0.11874063238501549.pypots
2024-05-22 12:10:59 [INFO]: Epoch 042 - training loss: 0.1310, validation loss: 0.1200
2024-05-22 12:10:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch42_loss0.12004013434052467.pypots
2024-05-22 12:11:16 [INFO]: Epoch 043 - training loss: 0.1368, validation loss: 0.1203
2024-05-22 12:11:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch43_loss0.12029093131422997.pypots
2024-05-22 12:11:33 [INFO]: Epoch 044 - training loss: 0.1255, validation loss: 0.1185
2024-05-22 12:11:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch44_loss0.11850580349564552.pypots
2024-05-22 12:11:50 [INFO]: Epoch 045 - training loss: 0.1202, validation loss: 0.1219
2024-05-22 12:11:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch45_loss0.12191174477338791.pypots
2024-05-22 12:12:07 [INFO]: Epoch 046 - training loss: 0.1238, validation loss: 0.1179
2024-05-22 12:12:07 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch46_loss0.1179119512438774.pypots
2024-05-22 12:12:23 [INFO]: Epoch 047 - training loss: 0.1316, validation loss: 0.1161
2024-05-22 12:12:23 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch47_loss0.11614880859851837.pypots
2024-05-22 12:12:40 [INFO]: Epoch 048 - training loss: 0.1254, validation loss: 0.1215
2024-05-22 12:12:40 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch48_loss0.12151890769600868.pypots
2024-05-22 12:12:57 [INFO]: Epoch 049 - training loss: 0.1351, validation loss: 0.1179
2024-05-22 12:12:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch49_loss0.11790427938103676.pypots
2024-05-22 12:13:14 [INFO]: Epoch 050 - training loss: 0.1245, validation loss: 0.1173
2024-05-22 12:13:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch50_loss0.11728983223438263.pypots
2024-05-22 12:13:31 [INFO]: Epoch 051 - training loss: 0.1274, validation loss: 0.1163
2024-05-22 12:13:31 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch51_loss0.11627650484442711.pypots
2024-05-22 12:13:48 [INFO]: Epoch 052 - training loss: 0.1303, validation loss: 0.1130
2024-05-22 12:13:48 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch52_loss0.11298838332295418.pypots
2024-05-22 12:14:04 [INFO]: Epoch 053 - training loss: 0.1151, validation loss: 0.1122
2024-05-22 12:14:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch53_loss0.11217107176780701.pypots
2024-05-22 12:14:21 [INFO]: Epoch 054 - training loss: 0.1225, validation loss: 0.1125
2024-05-22 12:14:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch54_loss0.11248111948370934.pypots
2024-05-22 12:14:38 [INFO]: Epoch 055 - training loss: 0.1271, validation loss: 0.1173
2024-05-22 12:14:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch55_loss0.1172979936003685.pypots
2024-05-22 12:14:55 [INFO]: Epoch 056 - training loss: 0.1367, validation loss: 0.1125
2024-05-22 12:14:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch56_loss0.1125047355890274.pypots
2024-05-22 12:15:12 [INFO]: Epoch 057 - training loss: 0.1259, validation loss: 0.1125
2024-05-22 12:15:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch57_loss0.1124594271183014.pypots
2024-05-22 12:15:28 [INFO]: Epoch 058 - training loss: 0.1285, validation loss: 0.1137
2024-05-22 12:15:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch58_loss0.11366374045610428.pypots
2024-05-22 12:15:45 [INFO]: Epoch 059 - training loss: 0.1269, validation loss: 0.1134
2024-05-22 12:15:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch59_loss0.11343893706798554.pypots
2024-05-22 12:16:02 [INFO]: Epoch 060 - training loss: 0.1300, validation loss: 0.1084
2024-05-22 12:16:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch60_loss0.10839551091194152.pypots
2024-05-22 12:16:19 [INFO]: Epoch 061 - training loss: 0.1220, validation loss: 0.1104
2024-05-22 12:16:19 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch61_loss0.11037369519472122.pypots
2024-05-22 12:16:36 [INFO]: Epoch 062 - training loss: 0.1186, validation loss: 0.1100
2024-05-22 12:16:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch62_loss0.11004302725195884.pypots
2024-05-22 12:16:53 [INFO]: Epoch 063 - training loss: 0.1274, validation loss: 0.1145
2024-05-22 12:16:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch63_loss0.1144668035209179.pypots
2024-05-22 12:17:09 [INFO]: Epoch 064 - training loss: 0.1325, validation loss: 0.1148
2024-05-22 12:17:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch64_loss0.11480428799986839.pypots
2024-05-22 12:17:26 [INFO]: Epoch 065 - training loss: 0.1132, validation loss: 0.1161
2024-05-22 12:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch65_loss0.11605039164423943.pypots
2024-05-22 12:17:43 [INFO]: Epoch 066 - training loss: 0.1285, validation loss: 0.1105
2024-05-22 12:17:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch66_loss0.11046047210693359.pypots
2024-05-22 12:18:00 [INFO]: Epoch 067 - training loss: 0.1233, validation loss: 0.1116
2024-05-22 12:18:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch67_loss0.11158986836671829.pypots
2024-05-22 12:18:17 [INFO]: Epoch 068 - training loss: 0.1082, validation loss: 0.1083
2024-05-22 12:18:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch68_loss0.10827092006802559.pypots
2024-05-22 12:18:33 [INFO]: Epoch 069 - training loss: 0.1100, validation loss: 0.1077
2024-05-22 12:18:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch69_loss0.10765987113118172.pypots
2024-05-22 12:18:50 [INFO]: Epoch 070 - training loss: 0.1296, validation loss: 0.1123
2024-05-22 12:18:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch70_loss0.11230452135205268.pypots
2024-05-22 12:19:07 [INFO]: Epoch 071 - training loss: 0.1266, validation loss: 0.1083
2024-05-22 12:19:07 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch71_loss0.10828918218612671.pypots
2024-05-22 12:19:24 [INFO]: Epoch 072 - training loss: 0.1164, validation loss: 0.1057
2024-05-22 12:19:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch72_loss0.1056583732366562.pypots
2024-05-22 12:19:41 [INFO]: Epoch 073 - training loss: 0.1244, validation loss: 0.1056
2024-05-22 12:19:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch73_loss0.1056321144104004.pypots
2024-05-22 12:19:57 [INFO]: Epoch 074 - training loss: 0.1226, validation loss: 0.1100
2024-05-22 12:19:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch74_loss0.10998571142554284.pypots
2024-05-22 12:20:14 [INFO]: Epoch 075 - training loss: 0.1082, validation loss: 0.1065
2024-05-22 12:20:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch75_loss0.10652535259723664.pypots
2024-05-22 12:20:31 [INFO]: Epoch 076 - training loss: 0.1109, validation loss: 0.1072
2024-05-22 12:20:31 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch76_loss0.10723427906632424.pypots
2024-05-22 12:20:48 [INFO]: Epoch 077 - training loss: 0.1187, validation loss: 0.1066
2024-05-22 12:20:48 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch77_loss0.10659122318029404.pypots
2024-05-22 12:21:05 [INFO]: Epoch 078 - training loss: 0.1157, validation loss: 0.1052
2024-05-22 12:21:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch78_loss0.1052480898797512.pypots
2024-05-22 12:21:22 [INFO]: Epoch 079 - training loss: 0.1051, validation loss: 0.1104
2024-05-22 12:21:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch79_loss0.11036829948425293.pypots
2024-05-22 12:21:38 [INFO]: Epoch 080 - training loss: 0.1034, validation loss: 0.1073
2024-05-22 12:21:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch80_loss0.10731728300452233.pypots
2024-05-22 12:21:55 [INFO]: Epoch 081 - training loss: 0.1280, validation loss: 0.1060
2024-05-22 12:21:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch81_loss0.1059929832816124.pypots
2024-05-22 12:22:12 [INFO]: Epoch 082 - training loss: 0.1183, validation loss: 0.1044
2024-05-22 12:22:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch82_loss0.10444803759455681.pypots
2024-05-22 12:22:29 [INFO]: Epoch 083 - training loss: 0.0962, validation loss: 0.1050
2024-05-22 12:22:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch83_loss0.10502384454011918.pypots
2024-05-22 12:22:46 [INFO]: Epoch 084 - training loss: 0.1154, validation loss: 0.1051
2024-05-22 12:22:46 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch84_loss0.10514402687549591.pypots
2024-05-22 12:23:03 [INFO]: Epoch 085 - training loss: 0.1123, validation loss: 0.1053
2024-05-22 12:23:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch85_loss0.1053170919418335.pypots
2024-05-22 12:23:19 [INFO]: Epoch 086 - training loss: 0.1113, validation loss: 0.1048
2024-05-22 12:23:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch86_loss0.10481200739741325.pypots
2024-05-22 12:23:36 [INFO]: Epoch 087 - training loss: 0.1095, validation loss: 0.1070
2024-05-22 12:23:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch87_loss0.10695089250802994.pypots
2024-05-22 12:23:53 [INFO]: Epoch 088 - training loss: 0.1133, validation loss: 0.1051
2024-05-22 12:23:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch88_loss0.10514049306511879.pypots
2024-05-22 12:24:10 [INFO]: Epoch 089 - training loss: 0.1392, validation loss: 0.1191
2024-05-22 12:24:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch89_loss0.11912652477622032.pypots
2024-05-22 12:24:27 [INFO]: Epoch 090 - training loss: 0.1192, validation loss: 0.1108
2024-05-22 12:24:27 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch90_loss0.11075114160776138.pypots
2024-05-22 12:24:44 [INFO]: Epoch 091 - training loss: 0.1124, validation loss: 0.1032
2024-05-22 12:24:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch91_loss0.10316832140088081.pypots
2024-05-22 12:25:00 [INFO]: Epoch 092 - training loss: 0.1045, validation loss: 0.1037
2024-05-22 12:25:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch92_loss0.10367601066827774.pypots
2024-05-22 12:25:17 [INFO]: Epoch 093 - training loss: 0.1266, validation loss: 0.1052
2024-05-22 12:25:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch93_loss0.10524451285600663.pypots
2024-05-22 12:25:34 [INFO]: Epoch 094 - training loss: 0.1177, validation loss: 0.1082
2024-05-22 12:25:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch94_loss0.10822005793452263.pypots
2024-05-22 12:25:51 [INFO]: Epoch 095 - training loss: 0.1155, validation loss: 0.1073
2024-05-22 12:25:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch95_loss0.10731710568070411.pypots
2024-05-22 12:26:08 [INFO]: Epoch 096 - training loss: 0.1134, validation loss: 0.1063
2024-05-22 12:26:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch96_loss0.10632568299770355.pypots
2024-05-22 12:26:25 [INFO]: Epoch 097 - training loss: 0.1190, validation loss: 0.1066
2024-05-22 12:26:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch97_loss0.10661079362034798.pypots
2024-05-22 12:26:41 [INFO]: Epoch 098 - training loss: 0.1095, validation loss: 0.1059
2024-05-22 12:26:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch98_loss0.10587608218193054.pypots
2024-05-22 12:26:58 [INFO]: Epoch 099 - training loss: 0.1226, validation loss: 0.1047
2024-05-22 12:26:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch99_loss0.10469870865345002.pypots
2024-05-22 12:27:15 [INFO]: Epoch 100 - training loss: 0.1119, validation loss: 0.1036
2024-05-22 12:27:15 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch100_loss0.10363862067461013.pypots
2024-05-22 12:27:32 [INFO]: Epoch 101 - training loss: 0.1293, validation loss: 0.1054
2024-05-22 12:27:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI_epoch101_loss0.10536899790167809.pypots
2024-05-22 12:27:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:27:32 [INFO]: Finished training. The best model is from epoch#91.
2024-05-22 12:27:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_air_quality/20240522_T115912/CSDI.pypots
2024-05-22 12:29:52 [INFO]: CSDI on Air-Quality: MAE=0.1107, MSE=0.2120
2024-05-22 12:29:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-22 12:29:52 [INFO]: Using the given device: cuda:0
2024-05-22 12:29:52 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240522_T122952
2024-05-22 12:29:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_air_quality/20240522_T122952/tensorboard
2024-05-22 12:29:52 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 12:29:53 [INFO]: Epoch 001 - training loss: 63887.0856, validation loss: 0.6556
2024-05-22 12:29:53 [INFO]: Epoch 002 - training loss: 42038.3377, validation loss: 0.5838
2024-05-22 12:29:54 [INFO]: Epoch 003 - training loss: 41779.7063, validation loss: 0.5337
2024-05-22 12:29:54 [INFO]: Epoch 004 - training loss: 41654.9081, validation loss: 0.4871
2024-05-22 12:29:54 [INFO]: Epoch 005 - training loss: 41543.1649, validation loss: 0.4343
2024-05-22 12:29:54 [INFO]: Epoch 006 - training loss: 41559.0298, validation loss: 0.4449
2024-05-22 12:29:55 [INFO]: Epoch 007 - training loss: 41486.2784, validation loss: 0.4177
2024-05-22 12:29:55 [INFO]: Epoch 008 - training loss: 41414.2337, validation loss: 0.3659
2024-05-22 12:29:55 [INFO]: Epoch 009 - training loss: 41373.7425, validation loss: 0.3422
2024-05-22 12:29:56 [INFO]: Epoch 010 - training loss: 41355.7096, validation loss: 0.3379
2024-05-22 12:29:56 [INFO]: Epoch 011 - training loss: 41353.5531, validation loss: 0.3438
2024-05-22 12:29:56 [INFO]: Epoch 012 - training loss: 41351.0467, validation loss: 0.3260
2024-05-22 12:29:57 [INFO]: Epoch 013 - training loss: 41391.8579, validation loss: 0.3291
2024-05-22 12:29:57 [INFO]: Epoch 014 - training loss: 41336.8872, validation loss: 0.3388
2024-05-22 12:29:57 [INFO]: Epoch 015 - training loss: 41308.8142, validation loss: 0.3164
2024-05-22 12:29:58 [INFO]: Epoch 016 - training loss: 41299.9200, validation loss: 0.3077
2024-05-22 12:29:58 [INFO]: Epoch 017 - training loss: 41293.4852, validation loss: 0.3076
2024-05-22 12:29:58 [INFO]: Epoch 018 - training loss: 41291.0612, validation loss: 0.3095
2024-05-22 12:29:58 [INFO]: Epoch 019 - training loss: 41286.0294, validation loss: 0.3016
2024-05-22 12:29:59 [INFO]: Epoch 020 - training loss: 41262.8885, validation loss: 0.2830
2024-05-22 12:29:59 [INFO]: Epoch 021 - training loss: 41249.2038, validation loss: 0.2777
2024-05-22 12:29:59 [INFO]: Epoch 022 - training loss: 41237.9889, validation loss: 0.2761
2024-05-22 12:30:00 [INFO]: Epoch 023 - training loss: 41234.1599, validation loss: 0.2769
2024-05-22 12:30:00 [INFO]: Epoch 024 - training loss: 41246.4755, validation loss: 0.2782
2024-05-22 12:30:00 [INFO]: Epoch 025 - training loss: 41242.8717, validation loss: 0.2802
2024-05-22 12:30:01 [INFO]: Epoch 026 - training loss: 41273.6836, validation loss: 0.2807
2024-05-22 12:30:01 [INFO]: Epoch 027 - training loss: 41237.9382, validation loss: 0.2849
2024-05-22 12:30:01 [INFO]: Epoch 028 - training loss: 41233.7632, validation loss: 0.2776
2024-05-22 12:30:02 [INFO]: Epoch 029 - training loss: 41227.0667, validation loss: 0.2784
2024-05-22 12:30:02 [INFO]: Epoch 030 - training loss: 41230.3179, validation loss: 0.2696
2024-05-22 12:30:02 [INFO]: Epoch 031 - training loss: 41391.8608, validation loss: 0.3083
2024-05-22 12:30:02 [INFO]: Epoch 032 - training loss: 41295.9209, validation loss: 0.2914
2024-05-22 12:30:03 [INFO]: Epoch 033 - training loss: 41264.0205, validation loss: 0.2926
2024-05-22 12:30:03 [INFO]: Epoch 034 - training loss: 41255.4621, validation loss: 0.2842
2024-05-22 12:30:03 [INFO]: Epoch 035 - training loss: 41233.4635, validation loss: 0.2771
2024-05-22 12:30:04 [INFO]: Epoch 036 - training loss: 41229.9407, validation loss: 0.2639
2024-05-22 12:30:04 [INFO]: Epoch 037 - training loss: 41204.1580, validation loss: 0.2609
2024-05-22 12:30:04 [INFO]: Epoch 038 - training loss: 41201.3251, validation loss: 0.2549
2024-05-22 12:30:05 [INFO]: Epoch 039 - training loss: 41192.5467, validation loss: 0.2632
2024-05-22 12:30:05 [INFO]: Epoch 040 - training loss: 41198.0231, validation loss: 0.2615
2024-05-22 12:30:05 [INFO]: Epoch 041 - training loss: 41207.7700, validation loss: 0.2511
2024-05-22 12:30:06 [INFO]: Epoch 042 - training loss: 41191.4281, validation loss: 0.2567
2024-05-22 12:30:06 [INFO]: Epoch 043 - training loss: 41200.1196, validation loss: 0.2619
2024-05-22 12:30:06 [INFO]: Epoch 044 - training loss: 41183.0479, validation loss: 0.2446
2024-05-22 12:30:06 [INFO]: Epoch 045 - training loss: 41173.1170, validation loss: 0.2439
2024-05-22 12:30:07 [INFO]: Epoch 046 - training loss: 41170.0982, validation loss: 0.2537
2024-05-22 12:30:07 [INFO]: Epoch 047 - training loss: 41172.8341, validation loss: 0.2479
2024-05-22 12:30:07 [INFO]: Epoch 048 - training loss: 41170.6871, validation loss: 0.2397
2024-05-22 12:30:08 [INFO]: Epoch 049 - training loss: 41169.5874, validation loss: 0.2455
2024-05-22 12:30:08 [INFO]: Epoch 050 - training loss: 41180.7415, validation loss: 0.2471
2024-05-22 12:30:08 [INFO]: Epoch 051 - training loss: 41180.7115, validation loss: 0.2585
2024-05-22 12:30:09 [INFO]: Epoch 052 - training loss: 41182.6751, validation loss: 0.2677
2024-05-22 12:30:09 [INFO]: Epoch 053 - training loss: 41206.5589, validation loss: 0.2446
2024-05-22 12:30:09 [INFO]: Epoch 054 - training loss: 41179.5693, validation loss: 0.2531
2024-05-22 12:30:10 [INFO]: Epoch 055 - training loss: 41187.5964, validation loss: 0.2700
2024-05-22 12:30:10 [INFO]: Epoch 056 - training loss: 41209.5411, validation loss: 0.2593
2024-05-22 12:30:10 [INFO]: Epoch 057 - training loss: 41167.3141, validation loss: 0.2425
2024-05-22 12:30:10 [INFO]: Epoch 058 - training loss: 41164.5661, validation loss: 0.2414
2024-05-22 12:30:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:30:10 [INFO]: Finished training. The best model is from epoch#48.
2024-05-22 12:30:10 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_air_quality/20240522_T122952/GPVAE.pypots
2024-05-22 12:30:11 [INFO]: GP-VAE on Air-Quality: MAE=0.2811, MSE=0.2415
2024-05-22 12:30:11 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-22 12:30:11 [INFO]: Using the given device: cuda:0
2024-05-22 12:30:11 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240522_T123011
2024-05-22 12:30:11 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_air_quality/20240522_T123011/tensorboard
2024-05-22 12:30:11 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 12:30:15 [INFO]: Epoch 001 - generator training loss: 0.6102, discriminator training loss: 0.2957, validation loss: 0.5318
2024-05-22 12:30:19 [INFO]: Epoch 002 - generator training loss: 0.2952, discriminator training loss: 0.0674, validation loss: 0.4027
2024-05-22 12:30:23 [INFO]: Epoch 003 - generator training loss: 0.2186, discriminator training loss: 0.0636, validation loss: 0.3343
2024-05-22 12:30:28 [INFO]: Epoch 004 - generator training loss: 0.1804, discriminator training loss: 0.0622, validation loss: 0.2931
2024-05-22 12:30:32 [INFO]: Epoch 005 - generator training loss: 0.1558, discriminator training loss: 0.0623, validation loss: 0.2672
2024-05-22 12:30:36 [INFO]: Epoch 006 - generator training loss: 0.1378, discriminator training loss: 0.0612, validation loss: 0.2496
2024-05-22 12:30:39 [INFO]: Epoch 007 - generator training loss: 0.1235, discriminator training loss: 0.0609, validation loss: 0.2357
2024-05-22 12:30:44 [INFO]: Epoch 008 - generator training loss: 0.1124, discriminator training loss: 0.0602, validation loss: 0.2248
2024-05-22 12:30:48 [INFO]: Epoch 009 - generator training loss: 0.1034, discriminator training loss: 0.0594, validation loss: 0.2158
2024-05-22 12:30:52 [INFO]: Epoch 010 - generator training loss: 0.0937, discriminator training loss: 0.0591, validation loss: 0.2093
2024-05-22 12:30:56 [INFO]: Epoch 011 - generator training loss: 0.0884, discriminator training loss: 0.0584, validation loss: 0.2031
2024-05-22 12:31:00 [INFO]: Epoch 012 - generator training loss: 0.0839, discriminator training loss: 0.0571, validation loss: 0.1978
2024-05-22 12:31:04 [INFO]: Epoch 013 - generator training loss: 0.0825, discriminator training loss: 0.0559, validation loss: 0.1936
2024-05-22 12:31:08 [INFO]: Epoch 014 - generator training loss: 0.0783, discriminator training loss: 0.0542, validation loss: 0.1897
2024-05-22 12:31:12 [INFO]: Epoch 015 - generator training loss: 0.0765, discriminator training loss: 0.0523, validation loss: 0.1862
2024-05-22 12:31:16 [INFO]: Epoch 016 - generator training loss: 0.0741, discriminator training loss: 0.0507, validation loss: 0.1835
2024-05-22 12:31:20 [INFO]: Epoch 017 - generator training loss: 0.0723, discriminator training loss: 0.0490, validation loss: 0.1810
2024-05-22 12:31:24 [INFO]: Epoch 018 - generator training loss: 0.0712, discriminator training loss: 0.0477, validation loss: 0.1779
2024-05-22 12:31:28 [INFO]: Epoch 019 - generator training loss: 0.0691, discriminator training loss: 0.0463, validation loss: 0.1777
2024-05-22 12:31:32 [INFO]: Epoch 020 - generator training loss: 0.0671, discriminator training loss: 0.0458, validation loss: 0.1769
2024-05-22 12:31:36 [INFO]: Epoch 021 - generator training loss: 0.0650, discriminator training loss: 0.0456, validation loss: 0.1763
2024-05-22 12:31:40 [INFO]: Epoch 022 - generator training loss: 0.0647, discriminator training loss: 0.0447, validation loss: 0.1752
2024-05-22 12:31:44 [INFO]: Epoch 023 - generator training loss: 0.0631, discriminator training loss: 0.0438, validation loss: 0.1747
2024-05-22 12:31:48 [INFO]: Epoch 024 - generator training loss: 0.0628, discriminator training loss: 0.0430, validation loss: 0.1736
2024-05-22 12:31:52 [INFO]: Epoch 025 - generator training loss: 0.0605, discriminator training loss: 0.0421, validation loss: 0.1722
2024-05-22 12:31:56 [INFO]: Epoch 026 - generator training loss: 0.0594, discriminator training loss: 0.0419, validation loss: 0.1715
2024-05-22 12:32:00 [INFO]: Epoch 027 - generator training loss: 0.0581, discriminator training loss: 0.0409, validation loss: 0.1708
2024-05-22 12:32:04 [INFO]: Epoch 028 - generator training loss: 0.0576, discriminator training loss: 0.0402, validation loss: 0.1704
2024-05-22 12:32:08 [INFO]: Epoch 029 - generator training loss: 0.0560, discriminator training loss: 0.0394, validation loss: 0.1691
2024-05-22 12:32:12 [INFO]: Epoch 030 - generator training loss: 0.0549, discriminator training loss: 0.0386, validation loss: 0.1680
2024-05-22 12:32:16 [INFO]: Epoch 031 - generator training loss: 0.0556, discriminator training loss: 0.0377, validation loss: 0.1672
2024-05-22 12:32:20 [INFO]: Epoch 032 - generator training loss: 0.0546, discriminator training loss: 0.0367, validation loss: 0.1668
2024-05-22 12:32:24 [INFO]: Epoch 033 - generator training loss: 0.0542, discriminator training loss: 0.0357, validation loss: 0.1663
2024-05-22 12:32:28 [INFO]: Epoch 034 - generator training loss: 0.0540, discriminator training loss: 0.0350, validation loss: 0.1646
2024-05-22 12:32:32 [INFO]: Epoch 035 - generator training loss: 0.0538, discriminator training loss: 0.0342, validation loss: 0.1642
2024-05-22 12:32:36 [INFO]: Epoch 036 - generator training loss: 0.0550, discriminator training loss: 0.0333, validation loss: 0.1631
2024-05-22 12:32:41 [INFO]: Epoch 037 - generator training loss: 0.0536, discriminator training loss: 0.0327, validation loss: 0.1627
2024-05-22 12:32:45 [INFO]: Epoch 038 - generator training loss: 0.0529, discriminator training loss: 0.0321, validation loss: 0.1617
2024-05-22 12:32:49 [INFO]: Epoch 039 - generator training loss: 0.0529, discriminator training loss: 0.0315, validation loss: 0.1609
2024-05-22 12:32:53 [INFO]: Epoch 040 - generator training loss: 0.0521, discriminator training loss: 0.0307, validation loss: 0.1601
2024-05-22 12:32:57 [INFO]: Epoch 041 - generator training loss: 0.0523, discriminator training loss: 0.0301, validation loss: 0.1595
2024-05-22 12:33:01 [INFO]: Epoch 042 - generator training loss: 0.0516, discriminator training loss: 0.0297, validation loss: 0.1589
2024-05-22 12:33:05 [INFO]: Epoch 043 - generator training loss: 0.0510, discriminator training loss: 0.0292, validation loss: 0.1585
2024-05-22 12:33:09 [INFO]: Epoch 044 - generator training loss: 0.0516, discriminator training loss: 0.0285, validation loss: 0.1576
2024-05-22 12:33:13 [INFO]: Epoch 045 - generator training loss: 0.0511, discriminator training loss: 0.0280, validation loss: 0.1570
2024-05-22 12:33:17 [INFO]: Epoch 046 - generator training loss: 0.0505, discriminator training loss: 0.0275, validation loss: 0.1568
2024-05-22 12:33:21 [INFO]: Epoch 047 - generator training loss: 0.0501, discriminator training loss: 0.0270, validation loss: 0.1555
2024-05-22 12:33:25 [INFO]: Epoch 048 - generator training loss: 0.0501, discriminator training loss: 0.0267, validation loss: 0.1547
2024-05-22 12:33:29 [INFO]: Epoch 049 - generator training loss: 0.0498, discriminator training loss: 0.0261, validation loss: 0.1544
2024-05-22 12:33:33 [INFO]: Epoch 050 - generator training loss: 0.0499, discriminator training loss: 0.0257, validation loss: 0.1538
2024-05-22 12:33:37 [INFO]: Epoch 051 - generator training loss: 0.0496, discriminator training loss: 0.0251, validation loss: 0.1528
2024-05-22 12:33:41 [INFO]: Epoch 052 - generator training loss: 0.0490, discriminator training loss: 0.0248, validation loss: 0.1523
2024-05-22 12:33:45 [INFO]: Epoch 053 - generator training loss: 0.0492, discriminator training loss: 0.0244, validation loss: 0.1520
2024-05-22 12:33:49 [INFO]: Epoch 054 - generator training loss: 0.0490, discriminator training loss: 0.0241, validation loss: 0.1515
2024-05-22 12:33:53 [INFO]: Epoch 055 - generator training loss: 0.0483, discriminator training loss: 0.0239, validation loss: 0.1511
2024-05-22 12:33:57 [INFO]: Epoch 056 - generator training loss: 0.0478, discriminator training loss: 0.0232, validation loss: 0.1502
2024-05-22 12:34:01 [INFO]: Epoch 057 - generator training loss: 0.0476, discriminator training loss: 0.0231, validation loss: 0.1498
2024-05-22 12:34:05 [INFO]: Epoch 058 - generator training loss: 0.0475, discriminator training loss: 0.0228, validation loss: 0.1488
2024-05-22 12:34:09 [INFO]: Epoch 059 - generator training loss: 0.0474, discriminator training loss: 0.0223, validation loss: 0.1487
2024-05-22 12:34:13 [INFO]: Epoch 060 - generator training loss: 0.0466, discriminator training loss: 0.0220, validation loss: 0.1480
2024-05-22 12:34:17 [INFO]: Epoch 061 - generator training loss: 0.0464, discriminator training loss: 0.0217, validation loss: 0.1475
2024-05-22 12:34:21 [INFO]: Epoch 062 - generator training loss: 0.0456, discriminator training loss: 0.0217, validation loss: 0.1474
2024-05-22 12:34:25 [INFO]: Epoch 063 - generator training loss: 0.0464, discriminator training loss: 0.0214, validation loss: 0.1466
2024-05-22 12:34:29 [INFO]: Epoch 064 - generator training loss: 0.0456, discriminator training loss: 0.0210, validation loss: 0.1464
2024-05-22 12:34:33 [INFO]: Epoch 065 - generator training loss: 0.0453, discriminator training loss: 0.0207, validation loss: 0.1462
2024-05-22 12:34:37 [INFO]: Epoch 066 - generator training loss: 0.0449, discriminator training loss: 0.0205, validation loss: 0.1453
2024-05-22 12:34:41 [INFO]: Epoch 067 - generator training loss: 0.0449, discriminator training loss: 0.0204, validation loss: 0.1451
2024-05-22 12:34:45 [INFO]: Epoch 068 - generator training loss: 0.0448, discriminator training loss: 0.0201, validation loss: 0.1446
2024-05-22 12:34:49 [INFO]: Epoch 069 - generator training loss: 0.0443, discriminator training loss: 0.0199, validation loss: 0.1444
2024-05-22 12:34:53 [INFO]: Epoch 070 - generator training loss: 0.0439, discriminator training loss: 0.0195, validation loss: 0.1441
2024-05-22 12:34:58 [INFO]: Epoch 071 - generator training loss: 0.0434, discriminator training loss: 0.0195, validation loss: 0.1434
2024-05-22 12:35:02 [INFO]: Epoch 072 - generator training loss: 0.0434, discriminator training loss: 0.0191, validation loss: 0.1435
2024-05-22 12:35:06 [INFO]: Epoch 073 - generator training loss: 0.0435, discriminator training loss: 0.0190, validation loss: 0.1430
2024-05-22 12:35:10 [INFO]: Epoch 074 - generator training loss: 0.0426, discriminator training loss: 0.0189, validation loss: 0.1430
2024-05-22 12:35:14 [INFO]: Epoch 075 - generator training loss: 0.0429, discriminator training loss: 0.0187, validation loss: 0.1426
2024-05-22 12:35:18 [INFO]: Epoch 076 - generator training loss: 0.0421, discriminator training loss: 0.0187, validation loss: 0.1418
2024-05-22 12:35:22 [INFO]: Epoch 077 - generator training loss: 0.0425, discriminator training loss: 0.0184, validation loss: 0.1421
2024-05-22 12:35:26 [INFO]: Epoch 078 - generator training loss: 0.0424, discriminator training loss: 0.0181, validation loss: 0.1413
2024-05-22 12:35:30 [INFO]: Epoch 079 - generator training loss: 0.0416, discriminator training loss: 0.0180, validation loss: 0.1415
2024-05-22 12:35:34 [INFO]: Epoch 080 - generator training loss: 0.0410, discriminator training loss: 0.0179, validation loss: 0.1408
2024-05-22 12:35:38 [INFO]: Epoch 081 - generator training loss: 0.0415, discriminator training loss: 0.0176, validation loss: 0.1404
2024-05-22 12:35:42 [INFO]: Epoch 082 - generator training loss: 0.0405, discriminator training loss: 0.0175, validation loss: 0.1405
2024-05-22 12:35:46 [INFO]: Epoch 083 - generator training loss: 0.0409, discriminator training loss: 0.0176, validation loss: 0.1408
2024-05-22 12:35:50 [INFO]: Epoch 084 - generator training loss: 0.0408, discriminator training loss: 0.0174, validation loss: 0.1393
2024-05-22 12:35:54 [INFO]: Epoch 085 - generator training loss: 0.0418, discriminator training loss: 0.0171, validation loss: 0.1404
2024-05-22 12:35:58 [INFO]: Epoch 086 - generator training loss: 0.0407, discriminator training loss: 0.0169, validation loss: 0.1398
2024-05-22 12:36:02 [INFO]: Epoch 087 - generator training loss: 0.0395, discriminator training loss: 0.0169, validation loss: 0.1403
2024-05-22 12:36:06 [INFO]: Epoch 088 - generator training loss: 0.0393, discriminator training loss: 0.0166, validation loss: 0.1396
2024-05-22 12:36:10 [INFO]: Epoch 089 - generator training loss: 0.0392, discriminator training loss: 0.0166, validation loss: 0.1394
2024-05-22 12:36:14 [INFO]: Epoch 090 - generator training loss: 0.0392, discriminator training loss: 0.0165, validation loss: 0.1393
2024-05-22 12:36:18 [INFO]: Epoch 091 - generator training loss: 0.0388, discriminator training loss: 0.0165, validation loss: 0.1388
2024-05-22 12:36:22 [INFO]: Epoch 092 - generator training loss: 0.0386, discriminator training loss: 0.0163, validation loss: 0.1387
2024-05-22 12:36:26 [INFO]: Epoch 093 - generator training loss: 0.0384, discriminator training loss: 0.0161, validation loss: 0.1390
2024-05-22 12:36:30 [INFO]: Epoch 094 - generator training loss: 0.0383, discriminator training loss: 0.0160, validation loss: 0.1393
2024-05-22 12:36:34 [INFO]: Epoch 095 - generator training loss: 0.0380, discriminator training loss: 0.0159, validation loss: 0.1390
2024-05-22 12:36:38 [INFO]: Epoch 096 - generator training loss: 0.0378, discriminator training loss: 0.0160, validation loss: 0.1386
2024-05-22 12:36:42 [INFO]: Epoch 097 - generator training loss: 0.0376, discriminator training loss: 0.0157, validation loss: 0.1385
2024-05-22 12:36:46 [INFO]: Epoch 098 - generator training loss: 0.0375, discriminator training loss: 0.0157, validation loss: 0.1386
2024-05-22 12:36:50 [INFO]: Epoch 099 - generator training loss: 0.0385, discriminator training loss: 0.0156, validation loss: 0.1380
2024-05-22 12:36:54 [INFO]: Epoch 100 - generator training loss: 0.0376, discriminator training loss: 0.0154, validation loss: 0.1380
2024-05-22 12:36:58 [INFO]: Epoch 101 - generator training loss: 0.0370, discriminator training loss: 0.0154, validation loss: 0.1383
2024-05-22 12:37:02 [INFO]: Epoch 102 - generator training loss: 0.0372, discriminator training loss: 0.0154, validation loss: 0.1395
2024-05-22 12:37:06 [INFO]: Epoch 103 - generator training loss: 0.0370, discriminator training loss: 0.0152, validation loss: 0.1384
2024-05-22 12:37:10 [INFO]: Epoch 104 - generator training loss: 0.0366, discriminator training loss: 0.0150, validation loss: 0.1382
2024-05-22 12:37:14 [INFO]: Epoch 105 - generator training loss: 0.0363, discriminator training loss: 0.0152, validation loss: 0.1381
2024-05-22 12:37:18 [INFO]: Epoch 106 - generator training loss: 0.0361, discriminator training loss: 0.0150, validation loss: 0.1378
2024-05-22 12:37:23 [INFO]: Epoch 107 - generator training loss: 0.0360, discriminator training loss: 0.0150, validation loss: 0.1385
2024-05-22 12:37:27 [INFO]: Epoch 108 - generator training loss: 0.0360, discriminator training loss: 0.0148, validation loss: 0.1390
2024-05-22 12:37:31 [INFO]: Epoch 109 - generator training loss: 0.0361, discriminator training loss: 0.0148, validation loss: 0.1383
2024-05-22 12:37:35 [INFO]: Epoch 110 - generator training loss: 0.0359, discriminator training loss: 0.0146, validation loss: 0.1381
2024-05-22 12:37:39 [INFO]: Epoch 111 - generator training loss: 0.0354, discriminator training loss: 0.0147, validation loss: 0.1381
2024-05-22 12:37:43 [INFO]: Epoch 112 - generator training loss: 0.0349, discriminator training loss: 0.0148, validation loss: 0.1378
2024-05-22 12:37:47 [INFO]: Epoch 113 - generator training loss: 0.0352, discriminator training loss: 0.0145, validation loss: 0.1381
2024-05-22 12:37:51 [INFO]: Epoch 114 - generator training loss: 0.0348, discriminator training loss: 0.0144, validation loss: 0.1374
2024-05-22 12:37:55 [INFO]: Epoch 115 - generator training loss: 0.0347, discriminator training loss: 0.0145, validation loss: 0.1383
2024-05-22 12:37:59 [INFO]: Epoch 116 - generator training loss: 0.0349, discriminator training loss: 0.0140, validation loss: 0.1386
2024-05-22 12:38:03 [INFO]: Epoch 117 - generator training loss: 0.0346, discriminator training loss: 0.0140, validation loss: 0.1378
2024-05-22 12:38:07 [INFO]: Epoch 118 - generator training loss: 0.0344, discriminator training loss: 0.0141, validation loss: 0.1390
2024-05-22 12:38:11 [INFO]: Epoch 119 - generator training loss: 0.0347, discriminator training loss: 0.0140, validation loss: 0.1380
2024-05-22 12:38:15 [INFO]: Epoch 120 - generator training loss: 0.0340, discriminator training loss: 0.0143, validation loss: 0.1375
2024-05-22 12:38:19 [INFO]: Epoch 121 - generator training loss: 0.0352, discriminator training loss: 0.0139, validation loss: 0.1391
2024-05-22 12:38:23 [INFO]: Epoch 122 - generator training loss: 0.0358, discriminator training loss: 0.0138, validation loss: 0.1378
2024-05-22 12:38:27 [INFO]: Epoch 123 - generator training loss: 0.0342, discriminator training loss: 0.0138, validation loss: 0.1387
2024-05-22 12:38:31 [INFO]: Epoch 124 - generator training loss: 0.0344, discriminator training loss: 0.0138, validation loss: 0.1382
2024-05-22 12:38:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:38:31 [INFO]: Finished training. The best model is from epoch#114.
2024-05-22 12:38:31 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_air_quality/20240522_T123011/USGAN.pypots
2024-05-22 12:38:32 [INFO]: US-GAN on Air-Quality: MAE=0.1764, MSE=0.1277
2024-05-22 12:38:32 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-22 12:38:32 [INFO]: Using the given device: cuda:0
2024-05-22 12:38:32 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240522_T123832
2024-05-22 12:38:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_air_quality/20240522_T123832/tensorboard
2024-05-22 12:38:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 12:38:35 [INFO]: Epoch 001 - training loss: 1.4107, validation loss: 0.9410
2024-05-22 12:38:38 [INFO]: Epoch 002 - training loss: 1.1342, validation loss: 0.6960
2024-05-22 12:38:41 [INFO]: Epoch 003 - training loss: 0.9397, validation loss: 0.5851
2024-05-22 12:38:43 [INFO]: Epoch 004 - training loss: 0.8314, validation loss: 0.5191
2024-05-22 12:38:46 [INFO]: Epoch 005 - training loss: 0.7554, validation loss: 0.4726
2024-05-22 12:38:49 [INFO]: Epoch 006 - training loss: 0.6995, validation loss: 0.4344
2024-05-22 12:38:52 [INFO]: Epoch 007 - training loss: 0.6566, validation loss: 0.4057
2024-05-22 12:38:54 [INFO]: Epoch 008 - training loss: 0.6217, validation loss: 0.3824
2024-05-22 12:38:57 [INFO]: Epoch 009 - training loss: 0.5953, validation loss: 0.3634
2024-05-22 12:39:00 [INFO]: Epoch 010 - training loss: 0.5734, validation loss: 0.3476
2024-05-22 12:39:02 [INFO]: Epoch 011 - training loss: 0.5544, validation loss: 0.3347
2024-05-22 12:39:05 [INFO]: Epoch 012 - training loss: 0.5393, validation loss: 0.3237
2024-05-22 12:39:08 [INFO]: Epoch 013 - training loss: 0.5279, validation loss: 0.3141
2024-05-22 12:39:11 [INFO]: Epoch 014 - training loss: 0.5155, validation loss: 0.3062
2024-05-22 12:39:13 [INFO]: Epoch 015 - training loss: 0.5044, validation loss: 0.2988
2024-05-22 12:39:16 [INFO]: Epoch 016 - training loss: 0.4941, validation loss: 0.2922
2024-05-22 12:39:19 [INFO]: Epoch 017 - training loss: 0.4857, validation loss: 0.2865
2024-05-22 12:39:21 [INFO]: Epoch 018 - training loss: 0.4764, validation loss: 0.2811
2024-05-22 12:39:24 [INFO]: Epoch 019 - training loss: 0.4689, validation loss: 0.2758
2024-05-22 12:39:27 [INFO]: Epoch 020 - training loss: 0.4608, validation loss: 0.2715
2024-05-22 12:39:30 [INFO]: Epoch 021 - training loss: 0.4551, validation loss: 0.2673
2024-05-22 12:39:32 [INFO]: Epoch 022 - training loss: 0.4481, validation loss: 0.2634
2024-05-22 12:39:35 [INFO]: Epoch 023 - training loss: 0.4415, validation loss: 0.2595
2024-05-22 12:39:38 [INFO]: Epoch 024 - training loss: 0.4356, validation loss: 0.2562
2024-05-22 12:39:40 [INFO]: Epoch 025 - training loss: 0.4305, validation loss: 0.2525
2024-05-22 12:39:43 [INFO]: Epoch 026 - training loss: 0.4247, validation loss: 0.2492
2024-05-22 12:39:46 [INFO]: Epoch 027 - training loss: 0.4195, validation loss: 0.2463
2024-05-22 12:39:49 [INFO]: Epoch 028 - training loss: 0.4151, validation loss: 0.2430
2024-05-22 12:39:51 [INFO]: Epoch 029 - training loss: 0.4098, validation loss: 0.2402
2024-05-22 12:39:54 [INFO]: Epoch 030 - training loss: 0.4053, validation loss: 0.2371
2024-05-22 12:39:57 [INFO]: Epoch 031 - training loss: 0.3998, validation loss: 0.2347
2024-05-22 12:40:00 [INFO]: Epoch 032 - training loss: 0.3962, validation loss: 0.2322
2024-05-22 12:40:02 [INFO]: Epoch 033 - training loss: 0.3919, validation loss: 0.2296
2024-05-22 12:40:05 [INFO]: Epoch 034 - training loss: 0.3874, validation loss: 0.2266
2024-05-22 12:40:08 [INFO]: Epoch 035 - training loss: 0.3840, validation loss: 0.2240
2024-05-22 12:40:10 [INFO]: Epoch 036 - training loss: 0.3802, validation loss: 0.2219
2024-05-22 12:40:13 [INFO]: Epoch 037 - training loss: 0.3762, validation loss: 0.2195
2024-05-22 12:40:16 [INFO]: Epoch 038 - training loss: 0.3730, validation loss: 0.2174
2024-05-22 12:40:19 [INFO]: Epoch 039 - training loss: 0.3687, validation loss: 0.2152
2024-05-22 12:40:21 [INFO]: Epoch 040 - training loss: 0.3668, validation loss: 0.2131
2024-05-22 12:40:24 [INFO]: Epoch 041 - training loss: 0.3632, validation loss: 0.2112
2024-05-22 12:40:27 [INFO]: Epoch 042 - training loss: 0.3599, validation loss: 0.2090
2024-05-22 12:40:29 [INFO]: Epoch 043 - training loss: 0.3573, validation loss: 0.2074
2024-05-22 12:40:32 [INFO]: Epoch 044 - training loss: 0.3543, validation loss: 0.2056
2024-05-22 12:40:35 [INFO]: Epoch 045 - training loss: 0.3520, validation loss: 0.2038
2024-05-22 12:40:38 [INFO]: Epoch 046 - training loss: 0.3489, validation loss: 0.2027
2024-05-22 12:40:40 [INFO]: Epoch 047 - training loss: 0.3465, validation loss: 0.2008
2024-05-22 12:40:43 [INFO]: Epoch 048 - training loss: 0.3437, validation loss: 0.1991
2024-05-22 12:40:46 [INFO]: Epoch 049 - training loss: 0.3424, validation loss: 0.1978
2024-05-22 12:40:48 [INFO]: Epoch 050 - training loss: 0.3394, validation loss: 0.1968
2024-05-22 12:40:51 [INFO]: Epoch 051 - training loss: 0.3367, validation loss: 0.1954
2024-05-22 12:40:54 [INFO]: Epoch 052 - training loss: 0.3353, validation loss: 0.1943
2024-05-22 12:40:57 [INFO]: Epoch 053 - training loss: 0.3323, validation loss: 0.1932
2024-05-22 12:40:59 [INFO]: Epoch 054 - training loss: 0.3307, validation loss: 0.1920
2024-05-22 12:41:02 [INFO]: Epoch 055 - training loss: 0.3287, validation loss: 0.1909
2024-05-22 12:41:05 [INFO]: Epoch 056 - training loss: 0.3268, validation loss: 0.1904
2024-05-22 12:41:07 [INFO]: Epoch 057 - training loss: 0.3249, validation loss: 0.1895
2024-05-22 12:41:10 [INFO]: Epoch 058 - training loss: 0.3231, validation loss: 0.1884
2024-05-22 12:41:13 [INFO]: Epoch 059 - training loss: 0.3214, validation loss: 0.1874
2024-05-22 12:41:16 [INFO]: Epoch 060 - training loss: 0.3197, validation loss: 0.1868
2024-05-22 12:41:18 [INFO]: Epoch 061 - training loss: 0.3186, validation loss: 0.1860
2024-05-22 12:41:21 [INFO]: Epoch 062 - training loss: 0.3164, validation loss: 0.1854
2024-05-22 12:41:24 [INFO]: Epoch 063 - training loss: 0.3146, validation loss: 0.1844
2024-05-22 12:41:26 [INFO]: Epoch 064 - training loss: 0.3136, validation loss: 0.1836
2024-05-22 12:41:29 [INFO]: Epoch 065 - training loss: 0.3124, validation loss: 0.1829
2024-05-22 12:41:32 [INFO]: Epoch 066 - training loss: 0.3119, validation loss: 0.1823
2024-05-22 12:41:35 [INFO]: Epoch 067 - training loss: 0.3094, validation loss: 0.1817
2024-05-22 12:41:37 [INFO]: Epoch 068 - training loss: 0.3086, validation loss: 0.1813
2024-05-22 12:41:40 [INFO]: Epoch 069 - training loss: 0.3076, validation loss: 0.1806
2024-05-22 12:41:43 [INFO]: Epoch 070 - training loss: 0.3055, validation loss: 0.1800
2024-05-22 12:41:46 [INFO]: Epoch 071 - training loss: 0.3043, validation loss: 0.1792
2024-05-22 12:41:48 [INFO]: Epoch 072 - training loss: 0.3027, validation loss: 0.1787
2024-05-22 12:41:51 [INFO]: Epoch 073 - training loss: 0.3021, validation loss: 0.1781
2024-05-22 12:41:54 [INFO]: Epoch 074 - training loss: 0.3013, validation loss: 0.1775
2024-05-22 12:41:56 [INFO]: Epoch 075 - training loss: 0.2994, validation loss: 0.1770
2024-05-22 12:41:59 [INFO]: Epoch 076 - training loss: 0.2988, validation loss: 0.1766
2024-05-22 12:42:02 [INFO]: Epoch 077 - training loss: 0.2971, validation loss: 0.1761
2024-05-22 12:42:05 [INFO]: Epoch 078 - training loss: 0.2965, validation loss: 0.1755
2024-05-22 12:42:07 [INFO]: Epoch 079 - training loss: 0.2959, validation loss: 0.1749
2024-05-22 12:42:10 [INFO]: Epoch 080 - training loss: 0.2950, validation loss: 0.1746
2024-05-22 12:42:13 [INFO]: Epoch 081 - training loss: 0.2938, validation loss: 0.1741
2024-05-22 12:42:15 [INFO]: Epoch 082 - training loss: 0.2929, validation loss: 0.1736
2024-05-22 12:42:18 [INFO]: Epoch 083 - training loss: 0.2923, validation loss: 0.1732
2024-05-22 12:42:21 [INFO]: Epoch 084 - training loss: 0.2916, validation loss: 0.1725
2024-05-22 12:42:24 [INFO]: Epoch 085 - training loss: 0.2901, validation loss: 0.1719
2024-05-22 12:42:26 [INFO]: Epoch 086 - training loss: 0.2897, validation loss: 0.1715
2024-05-22 12:42:29 [INFO]: Epoch 087 - training loss: 0.2890, validation loss: 0.1711
2024-05-22 12:42:32 [INFO]: Epoch 088 - training loss: 0.2883, validation loss: 0.1707
2024-05-22 12:42:34 [INFO]: Epoch 089 - training loss: 0.2870, validation loss: 0.1699
2024-05-22 12:42:37 [INFO]: Epoch 090 - training loss: 0.2868, validation loss: 0.1697
2024-05-22 12:42:40 [INFO]: Epoch 091 - training loss: 0.2850, validation loss: 0.1693
2024-05-22 12:42:43 [INFO]: Epoch 092 - training loss: 0.2851, validation loss: 0.1688
2024-05-22 12:42:45 [INFO]: Epoch 093 - training loss: 0.2843, validation loss: 0.1684
2024-05-22 12:42:48 [INFO]: Epoch 094 - training loss: 0.2836, validation loss: 0.1680
2024-05-22 12:42:51 [INFO]: Epoch 095 - training loss: 0.2828, validation loss: 0.1676
2024-05-22 12:42:53 [INFO]: Epoch 096 - training loss: 0.2832, validation loss: 0.1672
2024-05-22 12:42:56 [INFO]: Epoch 097 - training loss: 0.2809, validation loss: 0.1668
2024-05-22 12:42:59 [INFO]: Epoch 098 - training loss: 0.2807, validation loss: 0.1662
2024-05-22 12:43:02 [INFO]: Epoch 099 - training loss: 0.2802, validation loss: 0.1659
2024-05-22 12:43:04 [INFO]: Epoch 100 - training loss: 0.2799, validation loss: 0.1655
2024-05-22 12:43:07 [INFO]: Epoch 101 - training loss: 0.2791, validation loss: 0.1650
2024-05-22 12:43:10 [INFO]: Epoch 102 - training loss: 0.2784, validation loss: 0.1646
2024-05-22 12:43:12 [INFO]: Epoch 103 - training loss: 0.2777, validation loss: 0.1642
2024-05-22 12:43:15 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1638
2024-05-22 12:43:18 [INFO]: Epoch 105 - training loss: 0.2768, validation loss: 0.1635
2024-05-22 12:43:21 [INFO]: Epoch 106 - training loss: 0.2763, validation loss: 0.1630
2024-05-22 12:43:23 [INFO]: Epoch 107 - training loss: 0.2753, validation loss: 0.1626
2024-05-22 12:43:26 [INFO]: Epoch 108 - training loss: 0.2751, validation loss: 0.1623
2024-05-22 12:43:29 [INFO]: Epoch 109 - training loss: 0.2743, validation loss: 0.1619
2024-05-22 12:43:31 [INFO]: Epoch 110 - training loss: 0.2734, validation loss: 0.1615
2024-05-22 12:43:34 [INFO]: Epoch 111 - training loss: 0.2735, validation loss: 0.1612
2024-05-22 12:43:37 [INFO]: Epoch 112 - training loss: 0.2727, validation loss: 0.1608
2024-05-22 12:43:40 [INFO]: Epoch 113 - training loss: 0.2722, validation loss: 0.1605
2024-05-22 12:43:42 [INFO]: Epoch 114 - training loss: 0.2721, validation loss: 0.1600
2024-05-22 12:43:45 [INFO]: Epoch 115 - training loss: 0.2714, validation loss: 0.1596
2024-05-22 12:43:48 [INFO]: Epoch 116 - training loss: 0.2706, validation loss: 0.1593
2024-05-22 12:43:51 [INFO]: Epoch 117 - training loss: 0.2707, validation loss: 0.1589
2024-05-22 12:43:53 [INFO]: Epoch 118 - training loss: 0.2696, validation loss: 0.1585
2024-05-22 12:43:56 [INFO]: Epoch 119 - training loss: 0.2691, validation loss: 0.1582
2024-05-22 12:43:59 [INFO]: Epoch 120 - training loss: 0.2685, validation loss: 0.1577
2024-05-22 12:44:01 [INFO]: Epoch 121 - training loss: 0.2686, validation loss: 0.1574
2024-05-22 12:44:04 [INFO]: Epoch 122 - training loss: 0.2676, validation loss: 0.1572
2024-05-22 12:44:07 [INFO]: Epoch 123 - training loss: 0.2672, validation loss: 0.1570
2024-05-22 12:44:10 [INFO]: Epoch 124 - training loss: 0.2667, validation loss: 0.1564
2024-05-22 12:44:12 [INFO]: Epoch 125 - training loss: 0.2665, validation loss: 0.1560
2024-05-22 12:44:15 [INFO]: Epoch 126 - training loss: 0.2653, validation loss: 0.1560
2024-05-22 12:44:18 [INFO]: Epoch 127 - training loss: 0.2651, validation loss: 0.1554
2024-05-22 12:44:20 [INFO]: Epoch 128 - training loss: 0.2656, validation loss: 0.1551
2024-05-22 12:44:23 [INFO]: Epoch 129 - training loss: 0.2647, validation loss: 0.1547
2024-05-22 12:44:26 [INFO]: Epoch 130 - training loss: 0.2650, validation loss: 0.1544
2024-05-22 12:44:29 [INFO]: Epoch 131 - training loss: 0.2635, validation loss: 0.1541
2024-05-22 12:44:31 [INFO]: Epoch 132 - training loss: 0.2638, validation loss: 0.1537
2024-05-22 12:44:34 [INFO]: Epoch 133 - training loss: 0.2628, validation loss: 0.1533
2024-05-22 12:44:37 [INFO]: Epoch 134 - training loss: 0.2625, validation loss: 0.1532
2024-05-22 12:44:39 [INFO]: Epoch 135 - training loss: 0.2616, validation loss: 0.1527
2024-05-22 12:44:42 [INFO]: Epoch 136 - training loss: 0.2616, validation loss: 0.1525
2024-05-22 12:44:45 [INFO]: Epoch 137 - training loss: 0.2611, validation loss: 0.1519
2024-05-22 12:44:48 [INFO]: Epoch 138 - training loss: 0.2607, validation loss: 0.1521
2024-05-22 12:44:50 [INFO]: Epoch 139 - training loss: 0.2601, validation loss: 0.1514
2024-05-22 12:44:53 [INFO]: Epoch 140 - training loss: 0.2594, validation loss: 0.1510
2024-05-22 12:44:56 [INFO]: Epoch 141 - training loss: 0.2598, validation loss: 0.1507
2024-05-22 12:44:58 [INFO]: Epoch 142 - training loss: 0.2597, validation loss: 0.1506
2024-05-22 12:45:01 [INFO]: Epoch 143 - training loss: 0.2587, validation loss: 0.1502
2024-05-22 12:45:04 [INFO]: Epoch 144 - training loss: 0.2588, validation loss: 0.1502
2024-05-22 12:45:07 [INFO]: Epoch 145 - training loss: 0.2587, validation loss: 0.1497
2024-05-22 12:45:09 [INFO]: Epoch 146 - training loss: 0.2574, validation loss: 0.1495
2024-05-22 12:45:12 [INFO]: Epoch 147 - training loss: 0.2572, validation loss: 0.1493
2024-05-22 12:45:15 [INFO]: Epoch 148 - training loss: 0.2572, validation loss: 0.1489
2024-05-22 12:45:17 [INFO]: Epoch 149 - training loss: 0.2574, validation loss: 0.1487
2024-05-22 12:45:20 [INFO]: Epoch 150 - training loss: 0.2564, validation loss: 0.1484
2024-05-22 12:45:23 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1481
2024-05-22 12:45:26 [INFO]: Epoch 152 - training loss: 0.2559, validation loss: 0.1479
2024-05-22 12:45:28 [INFO]: Epoch 153 - training loss: 0.2559, validation loss: 0.1477
2024-05-22 12:45:31 [INFO]: Epoch 154 - training loss: 0.2551, validation loss: 0.1475
2024-05-22 12:45:34 [INFO]: Epoch 155 - training loss: 0.2549, validation loss: 0.1471
2024-05-22 12:45:36 [INFO]: Epoch 156 - training loss: 0.2546, validation loss: 0.1467
2024-05-22 12:45:39 [INFO]: Epoch 157 - training loss: 0.2546, validation loss: 0.1466
2024-05-22 12:45:42 [INFO]: Epoch 158 - training loss: 0.2538, validation loss: 0.1465
2024-05-22 12:45:45 [INFO]: Epoch 159 - training loss: 0.2536, validation loss: 0.1460
2024-05-22 12:45:47 [INFO]: Epoch 160 - training loss: 0.2532, validation loss: 0.1458
2024-05-22 12:45:50 [INFO]: Epoch 161 - training loss: 0.2526, validation loss: 0.1457
2024-05-22 12:45:53 [INFO]: Epoch 162 - training loss: 0.2524, validation loss: 0.1455
2024-05-22 12:45:55 [INFO]: Epoch 163 - training loss: 0.2527, validation loss: 0.1452
2024-05-22 12:45:58 [INFO]: Epoch 164 - training loss: 0.2525, validation loss: 0.1448
2024-05-22 12:46:01 [INFO]: Epoch 165 - training loss: 0.2520, validation loss: 0.1448
2024-05-22 12:46:04 [INFO]: Epoch 166 - training loss: 0.2513, validation loss: 0.1446
2024-05-22 12:46:06 [INFO]: Epoch 167 - training loss: 0.2508, validation loss: 0.1445
2024-05-22 12:46:09 [INFO]: Epoch 168 - training loss: 0.2513, validation loss: 0.1441
2024-05-22 12:46:12 [INFO]: Epoch 169 - training loss: 0.2517, validation loss: 0.1438
2024-05-22 12:46:14 [INFO]: Epoch 170 - training loss: 0.2506, validation loss: 0.1435
2024-05-22 12:46:17 [INFO]: Epoch 171 - training loss: 0.2501, validation loss: 0.1434
2024-05-22 12:46:20 [INFO]: Epoch 172 - training loss: 0.2499, validation loss: 0.1433
2024-05-22 12:46:23 [INFO]: Epoch 173 - training loss: 0.2497, validation loss: 0.1429
2024-05-22 12:46:25 [INFO]: Epoch 174 - training loss: 0.2502, validation loss: 0.1429
2024-05-22 12:46:28 [INFO]: Epoch 175 - training loss: 0.2492, validation loss: 0.1425
2024-05-22 12:46:31 [INFO]: Epoch 176 - training loss: 0.2490, validation loss: 0.1425
2024-05-22 12:46:33 [INFO]: Epoch 177 - training loss: 0.2483, validation loss: 0.1423
2024-05-22 12:46:36 [INFO]: Epoch 178 - training loss: 0.2484, validation loss: 0.1421
2024-05-22 12:46:39 [INFO]: Epoch 179 - training loss: 0.2484, validation loss: 0.1419
2024-05-22 12:46:42 [INFO]: Epoch 180 - training loss: 0.2480, validation loss: 0.1417
2024-05-22 12:46:44 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1414
2024-05-22 12:46:47 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1413
2024-05-22 12:46:50 [INFO]: Epoch 183 - training loss: 0.2470, validation loss: 0.1409
2024-05-22 12:46:52 [INFO]: Epoch 184 - training loss: 0.2468, validation loss: 0.1411
2024-05-22 12:46:55 [INFO]: Epoch 185 - training loss: 0.2466, validation loss: 0.1408
2024-05-22 12:46:58 [INFO]: Epoch 186 - training loss: 0.2466, validation loss: 0.1406
2024-05-22 12:47:00 [INFO]: Epoch 187 - training loss: 0.2464, validation loss: 0.1405
2024-05-22 12:47:03 [INFO]: Epoch 188 - training loss: 0.2461, validation loss: 0.1403
2024-05-22 12:47:06 [INFO]: Epoch 189 - training loss: 0.2462, validation loss: 0.1401
2024-05-22 12:47:09 [INFO]: Epoch 190 - training loss: 0.2458, validation loss: 0.1399
2024-05-22 12:47:11 [INFO]: Epoch 191 - training loss: 0.2454, validation loss: 0.1398
2024-05-22 12:47:14 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1398
2024-05-22 12:47:17 [INFO]: Epoch 193 - training loss: 0.2449, validation loss: 0.1394
2024-05-22 12:47:19 [INFO]: Epoch 194 - training loss: 0.2450, validation loss: 0.1394
2024-05-22 12:47:22 [INFO]: Epoch 195 - training loss: 0.2443, validation loss: 0.1391
2024-05-22 12:47:25 [INFO]: Epoch 196 - training loss: 0.2446, validation loss: 0.1390
2024-05-22 12:47:28 [INFO]: Epoch 197 - training loss: 0.2442, validation loss: 0.1389
2024-05-22 12:47:30 [INFO]: Epoch 198 - training loss: 0.2442, validation loss: 0.1385
2024-05-22 12:47:33 [INFO]: Epoch 199 - training loss: 0.2439, validation loss: 0.1387
2024-05-22 12:47:36 [INFO]: Epoch 200 - training loss: 0.2436, validation loss: 0.1385
2024-05-22 12:47:38 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1383
2024-05-22 12:47:41 [INFO]: Epoch 202 - training loss: 0.2436, validation loss: 0.1380
2024-05-22 12:47:44 [INFO]: Epoch 203 - training loss: 0.2425, validation loss: 0.1379
2024-05-22 12:47:47 [INFO]: Epoch 204 - training loss: 0.2426, validation loss: 0.1377
2024-05-22 12:47:49 [INFO]: Epoch 205 - training loss: 0.2431, validation loss: 0.1377
2024-05-22 12:47:52 [INFO]: Epoch 206 - training loss: 0.2425, validation loss: 0.1377
2024-05-22 12:47:55 [INFO]: Epoch 207 - training loss: 0.2425, validation loss: 0.1374
2024-05-22 12:47:57 [INFO]: Epoch 208 - training loss: 0.2422, validation loss: 0.1371
2024-05-22 12:48:00 [INFO]: Epoch 209 - training loss: 0.2424, validation loss: 0.1370
2024-05-22 12:48:03 [INFO]: Epoch 210 - training loss: 0.2417, validation loss: 0.1370
2024-05-22 12:48:06 [INFO]: Epoch 211 - training loss: 0.2417, validation loss: 0.1367
2024-05-22 12:48:08 [INFO]: Epoch 212 - training loss: 0.2409, validation loss: 0.1368
2024-05-22 12:48:11 [INFO]: Epoch 213 - training loss: 0.2410, validation loss: 0.1367
2024-05-22 12:48:14 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.1364
2024-05-22 12:48:16 [INFO]: Epoch 215 - training loss: 0.2413, validation loss: 0.1363
2024-05-22 12:48:19 [INFO]: Epoch 216 - training loss: 0.2403, validation loss: 0.1362
2024-05-22 12:48:22 [INFO]: Epoch 217 - training loss: 0.2397, validation loss: 0.1362
2024-05-22 12:48:25 [INFO]: Epoch 218 - training loss: 0.2402, validation loss: 0.1360
2024-05-22 12:48:27 [INFO]: Epoch 219 - training loss: 0.2399, validation loss: 0.1358
2024-05-22 12:48:30 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.1357
2024-05-22 12:48:33 [INFO]: Epoch 221 - training loss: 0.2393, validation loss: 0.1357
2024-05-22 12:48:35 [INFO]: Epoch 222 - training loss: 0.2397, validation loss: 0.1356
2024-05-22 12:48:38 [INFO]: Epoch 223 - training loss: 0.2393, validation loss: 0.1356
2024-05-22 12:48:41 [INFO]: Epoch 224 - training loss: 0.2388, validation loss: 0.1352
2024-05-22 12:48:43 [INFO]: Epoch 225 - training loss: 0.2398, validation loss: 0.1352
2024-05-22 12:48:46 [INFO]: Epoch 226 - training loss: 0.2388, validation loss: 0.1349
2024-05-22 12:48:49 [INFO]: Epoch 227 - training loss: 0.2389, validation loss: 0.1349
2024-05-22 12:48:52 [INFO]: Epoch 228 - training loss: 0.2384, validation loss: 0.1347
2024-05-22 12:48:54 [INFO]: Epoch 229 - training loss: 0.2381, validation loss: 0.1347
2024-05-22 12:48:57 [INFO]: Epoch 230 - training loss: 0.2380, validation loss: 0.1346
2024-05-22 12:49:00 [INFO]: Epoch 231 - training loss: 0.2383, validation loss: 0.1346
2024-05-22 12:49:02 [INFO]: Epoch 232 - training loss: 0.2380, validation loss: 0.1342
2024-05-22 12:49:05 [INFO]: Epoch 233 - training loss: 0.2374, validation loss: 0.1343
2024-05-22 12:49:08 [INFO]: Epoch 234 - training loss: 0.2375, validation loss: 0.1341
2024-05-22 12:49:11 [INFO]: Epoch 235 - training loss: 0.2370, validation loss: 0.1340
2024-05-22 12:49:13 [INFO]: Epoch 236 - training loss: 0.2375, validation loss: 0.1341
2024-05-22 12:49:16 [INFO]: Epoch 237 - training loss: 0.2367, validation loss: 0.1338
2024-05-22 12:49:19 [INFO]: Epoch 238 - training loss: 0.2372, validation loss: 0.1335
2024-05-22 12:49:21 [INFO]: Epoch 239 - training loss: 0.2367, validation loss: 0.1335
2024-05-22 12:49:24 [INFO]: Epoch 240 - training loss: 0.2362, validation loss: 0.1334
2024-05-22 12:49:27 [INFO]: Epoch 241 - training loss: 0.2366, validation loss: 0.1336
2024-05-22 12:49:29 [INFO]: Epoch 242 - training loss: 0.2360, validation loss: 0.1334
2024-05-22 12:49:32 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1333
2024-05-22 12:49:35 [INFO]: Epoch 244 - training loss: 0.2361, validation loss: 0.1332
2024-05-22 12:49:38 [INFO]: Epoch 245 - training loss: 0.2361, validation loss: 0.1332
2024-05-22 12:49:41 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.1329
2024-05-22 12:49:43 [INFO]: Epoch 247 - training loss: 0.2356, validation loss: 0.1329
2024-05-22 12:49:46 [INFO]: Epoch 248 - training loss: 0.2352, validation loss: 0.1329
2024-05-22 12:49:49 [INFO]: Epoch 249 - training loss: 0.2351, validation loss: 0.1328
2024-05-22 12:49:52 [INFO]: Epoch 250 - training loss: 0.2351, validation loss: 0.1326
2024-05-22 12:49:55 [INFO]: Epoch 251 - training loss: 0.2350, validation loss: 0.1325
2024-05-22 12:49:57 [INFO]: Epoch 252 - training loss: 0.2350, validation loss: 0.1325
2024-05-22 12:50:00 [INFO]: Epoch 253 - training loss: 0.2347, validation loss: 0.1322
2024-05-22 12:50:03 [INFO]: Epoch 254 - training loss: 0.2355, validation loss: 0.1323
2024-05-22 12:50:06 [INFO]: Epoch 255 - training loss: 0.2345, validation loss: 0.1323
2024-05-22 12:50:08 [INFO]: Epoch 256 - training loss: 0.2343, validation loss: 0.1321
2024-05-22 12:50:11 [INFO]: Epoch 257 - training loss: 0.2341, validation loss: 0.1322
2024-05-22 12:50:14 [INFO]: Epoch 258 - training loss: 0.2341, validation loss: 0.1319
2024-05-22 12:50:17 [INFO]: Epoch 259 - training loss: 0.2340, validation loss: 0.1319
2024-05-22 12:50:19 [INFO]: Epoch 260 - training loss: 0.2336, validation loss: 0.1317
2024-05-22 12:50:22 [INFO]: Epoch 261 - training loss: 0.2338, validation loss: 0.1318
2024-05-22 12:50:25 [INFO]: Epoch 262 - training loss: 0.2333, validation loss: 0.1316
2024-05-22 12:50:27 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1316
2024-05-22 12:50:30 [INFO]: Epoch 264 - training loss: 0.2330, validation loss: 0.1314
2024-05-22 12:50:33 [INFO]: Epoch 265 - training loss: 0.2328, validation loss: 0.1316
2024-05-22 12:50:36 [INFO]: Epoch 266 - training loss: 0.2333, validation loss: 0.1313
2024-05-22 12:50:38 [INFO]: Epoch 267 - training loss: 0.2327, validation loss: 0.1313
2024-05-22 12:50:41 [INFO]: Epoch 268 - training loss: 0.2334, validation loss: 0.1313
2024-05-22 12:50:44 [INFO]: Epoch 269 - training loss: 0.2329, validation loss: 0.1311
2024-05-22 12:50:46 [INFO]: Epoch 270 - training loss: 0.2324, validation loss: 0.1309
2024-05-22 12:50:49 [INFO]: Epoch 271 - training loss: 0.2326, validation loss: 0.1310
2024-05-22 12:50:52 [INFO]: Epoch 272 - training loss: 0.2321, validation loss: 0.1309
2024-05-22 12:50:55 [INFO]: Epoch 273 - training loss: 0.2322, validation loss: 0.1309
2024-05-22 12:50:57 [INFO]: Epoch 274 - training loss: 0.2317, validation loss: 0.1307
2024-05-22 12:51:00 [INFO]: Epoch 275 - training loss: 0.2317, validation loss: 0.1307
2024-05-22 12:51:03 [INFO]: Epoch 276 - training loss: 0.2318, validation loss: 0.1307
2024-05-22 12:51:05 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.1306
2024-05-22 12:51:08 [INFO]: Epoch 278 - training loss: 0.2318, validation loss: 0.1306
2024-05-22 12:51:11 [INFO]: Epoch 279 - training loss: 0.2315, validation loss: 0.1304
2024-05-22 12:51:14 [INFO]: Epoch 280 - training loss: 0.2310, validation loss: 0.1306
2024-05-22 12:51:16 [INFO]: Epoch 281 - training loss: 0.2314, validation loss: 0.1305
2024-05-22 12:51:19 [INFO]: Epoch 282 - training loss: 0.2315, validation loss: 0.1302
2024-05-22 12:51:22 [INFO]: Epoch 283 - training loss: 0.2308, validation loss: 0.1303
2024-05-22 12:51:24 [INFO]: Epoch 284 - training loss: 0.2312, validation loss: 0.1301
2024-05-22 12:51:27 [INFO]: Epoch 285 - training loss: 0.2308, validation loss: 0.1301
2024-05-22 12:51:30 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1300
2024-05-22 12:51:33 [INFO]: Epoch 287 - training loss: 0.2307, validation loss: 0.1300
2024-05-22 12:51:35 [INFO]: Epoch 288 - training loss: 0.2307, validation loss: 0.1299
2024-05-22 12:51:38 [INFO]: Epoch 289 - training loss: 0.2304, validation loss: 0.1299
2024-05-22 12:51:41 [INFO]: Epoch 290 - training loss: 0.2303, validation loss: 0.1297
2024-05-22 12:51:44 [INFO]: Epoch 291 - training loss: 0.2302, validation loss: 0.1298
2024-05-22 12:51:46 [INFO]: Epoch 292 - training loss: 0.2300, validation loss: 0.1298
2024-05-22 12:51:49 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.1297
2024-05-22 12:51:52 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.1295
2024-05-22 12:51:54 [INFO]: Epoch 295 - training loss: 0.2299, validation loss: 0.1297
2024-05-22 12:51:57 [INFO]: Epoch 296 - training loss: 0.2300, validation loss: 0.1295
2024-05-22 12:52:00 [INFO]: Epoch 297 - training loss: 0.2298, validation loss: 0.1294
2024-05-22 12:52:03 [INFO]: Epoch 298 - training loss: 0.2300, validation loss: 0.1294
2024-05-22 12:52:05 [INFO]: Epoch 299 - training loss: 0.2299, validation loss: 0.1293
2024-05-22 12:52:08 [INFO]: Epoch 300 - training loss: 0.2294, validation loss: 0.1293
2024-05-22 12:52:08 [INFO]: Finished training. The best model is from epoch#300.
2024-05-22 12:52:08 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_air_quality/20240522_T123832/BRITS.pypots
2024-05-22 12:52:09 [INFO]: BRITS on Air-Quality: MAE=0.1427, MSE=0.1155
2024-05-22 12:52:09 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-22 12:52:09 [INFO]: Using the given device: cuda:0
2024-05-22 12:52:09 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209
2024-05-22 12:52:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/tensorboard
2024-05-22 12:52:09 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 12:52:13 [INFO]: Epoch 001 - training loss: 1.5087, validation loss: 0.7973
2024-05-22 12:52:13 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch1_loss0.7972947388887406.pypots
2024-05-22 12:52:17 [INFO]: Epoch 002 - training loss: 1.0719, validation loss: 0.7429
2024-05-22 12:52:17 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch2_loss0.7429162114858627.pypots
2024-05-22 12:52:21 [INFO]: Epoch 003 - training loss: 0.9874, validation loss: 0.7250
2024-05-22 12:52:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch3_loss0.7249618351459504.pypots
2024-05-22 12:52:25 [INFO]: Epoch 004 - training loss: 0.9796, validation loss: 0.7132
2024-05-22 12:52:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch4_loss0.7131824433803559.pypots
2024-05-22 12:52:28 [INFO]: Epoch 005 - training loss: 0.9780, validation loss: 0.7054
2024-05-22 12:52:28 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch5_loss0.7054213792085647.pypots
2024-05-22 12:52:32 [INFO]: Epoch 006 - training loss: 0.9442, validation loss: 0.6996
2024-05-22 12:52:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch6_loss0.6996212035417557.pypots
2024-05-22 12:52:36 [INFO]: Epoch 007 - training loss: 0.9353, validation loss: 0.6946
2024-05-22 12:52:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch7_loss0.6945976108312607.pypots
2024-05-22 12:52:40 [INFO]: Epoch 008 - training loss: 0.9276, validation loss: 0.6908
2024-05-22 12:52:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch8_loss0.6908492356538772.pypots
2024-05-22 12:52:43 [INFO]: Epoch 009 - training loss: 0.9116, validation loss: 0.6877
2024-05-22 12:52:43 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch9_loss0.6877116680145263.pypots
2024-05-22 12:52:47 [INFO]: Epoch 010 - training loss: 0.9053, validation loss: 0.6859
2024-05-22 12:52:47 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch10_loss0.6858634233474732.pypots
2024-05-22 12:52:51 [INFO]: Epoch 011 - training loss: 0.8989, validation loss: 0.6843
2024-05-22 12:52:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch11_loss0.6843310505151748.pypots
2024-05-22 12:52:55 [INFO]: Epoch 012 - training loss: 0.9179, validation loss: 0.6828
2024-05-22 12:52:55 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch12_loss0.6828281968832016.pypots
2024-05-22 12:52:59 [INFO]: Epoch 013 - training loss: 0.9071, validation loss: 0.6824
2024-05-22 12:52:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch13_loss0.6823547393083572.pypots
2024-05-22 12:53:02 [INFO]: Epoch 014 - training loss: 0.8879, validation loss: 0.6814
2024-05-22 12:53:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch14_loss0.6814438700675964.pypots
2024-05-22 12:53:06 [INFO]: Epoch 015 - training loss: 0.8898, validation loss: 0.6807
2024-05-22 12:53:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch15_loss0.68067367374897.pypots
2024-05-22 12:53:10 [INFO]: Epoch 016 - training loss: 0.8848, validation loss: 0.6798
2024-05-22 12:53:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch16_loss0.6798080563545227.pypots
2024-05-22 12:53:14 [INFO]: Epoch 017 - training loss: 0.8773, validation loss: 0.6796
2024-05-22 12:53:14 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch17_loss0.6796470433473587.pypots
2024-05-22 12:53:17 [INFO]: Epoch 018 - training loss: 0.8787, validation loss: 0.6799
2024-05-22 12:53:17 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch18_loss0.6799400597810745.pypots
2024-05-22 12:53:21 [INFO]: Epoch 019 - training loss: 0.8952, validation loss: 0.6815
2024-05-22 12:53:21 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch19_loss0.6814808487892151.pypots
2024-05-22 12:53:25 [INFO]: Epoch 020 - training loss: 0.9118, validation loss: 0.6818
2024-05-22 12:53:25 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch20_loss0.6817537873983384.pypots
2024-05-22 12:53:29 [INFO]: Epoch 021 - training loss: 0.8849, validation loss: 0.6811
2024-05-22 12:53:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch21_loss0.681110167503357.pypots
2024-05-22 12:53:32 [INFO]: Epoch 022 - training loss: 0.8680, validation loss: 0.6819
2024-05-22 12:53:32 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch22_loss0.6819309711456298.pypots
2024-05-22 12:53:36 [INFO]: Epoch 023 - training loss: 0.8831, validation loss: 0.6835
2024-05-22 12:53:36 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch23_loss0.6834611058235168.pypots
2024-05-22 12:53:40 [INFO]: Epoch 024 - training loss: 0.8668, validation loss: 0.6829
2024-05-22 12:53:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch24_loss0.682931923866272.pypots
2024-05-22 12:53:44 [INFO]: Epoch 025 - training loss: 0.8510, validation loss: 0.6857
2024-05-22 12:53:44 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch25_loss0.6856817871332168.pypots
2024-05-22 12:53:47 [INFO]: Epoch 026 - training loss: 0.8645, validation loss: 0.6876
2024-05-22 12:53:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch26_loss0.6875581502914428.pypots
2024-05-22 12:53:51 [INFO]: Epoch 027 - training loss: 0.8600, validation loss: 0.6875
2024-05-22 12:53:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN_epoch27_loss0.6875138223171234.pypots
2024-05-22 12:53:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:53:51 [INFO]: Finished training. The best model is from epoch#17.
2024-05-22 12:53:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_air_quality/20240522_T125209/MRNN.pypots
2024-05-22 12:53:52 [INFO]: MRNN on Air-Quality: MAE=0.5250, MSE=0.6255
2024-05-22 12:53:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-22 12:53:52 [INFO]: Using the given device: cpu
2024-05-22 12:53:52 [INFO]: LOCF on Air-Quality: MAE=0.2063, MSE=0.2445
2024-05-22 12:53:52 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-22 12:53:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-22 12:53:52 [INFO]: Median on Air-Quality: MAE=0.6676, MSE=1.0184
2024-05-22 12:53:52 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-22 12:53:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-22 12:53:52 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=0.9535
2024-05-22 12:53:52 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-22 12:53:52 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-22 12:53:52 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 12:53:53 [INFO]: Using the given device: cuda:0
2024-05-22 12:53:53 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240522_T125353
2024-05-22 12:53:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_air_quality/20240522_T125353/tensorboard
2024-05-22 12:53:53 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 12:53:53 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.5157
2024-05-22 12:53:54 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.4016
2024-05-22 12:53:55 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3337
2024-05-22 12:53:55 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.2908
2024-05-22 12:53:56 [INFO]: Epoch 005 - training loss: 0.5196, validation loss: 0.2652
2024-05-22 12:53:57 [INFO]: Epoch 006 - training loss: 0.4823, validation loss: 0.2522
2024-05-22 12:53:57 [INFO]: Epoch 007 - training loss: 0.4580, validation loss: 0.2431
2024-05-22 12:53:58 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2376
2024-05-22 12:53:59 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.2298
2024-05-22 12:53:59 [INFO]: Epoch 010 - training loss: 0.4143, validation loss: 0.2256
2024-05-22 12:54:00 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2228
2024-05-22 12:54:01 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.2176
2024-05-22 12:54:02 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.2128
2024-05-22 12:54:02 [INFO]: Epoch 014 - training loss: 0.3823, validation loss: 0.2105
2024-05-22 12:54:03 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.2089
2024-05-22 12:54:04 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.2074
2024-05-22 12:54:04 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2042
2024-05-22 12:54:05 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.2015
2024-05-22 12:54:06 [INFO]: Epoch 019 - training loss: 0.3570, validation loss: 0.2015
2024-05-22 12:54:06 [INFO]: Epoch 020 - training loss: 0.3546, validation loss: 0.1982
2024-05-22 12:54:07 [INFO]: Epoch 021 - training loss: 0.3499, validation loss: 0.1972
2024-05-22 12:54:08 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.1945
2024-05-22 12:54:08 [INFO]: Epoch 023 - training loss: 0.3427, validation loss: 0.1932
2024-05-22 12:54:09 [INFO]: Epoch 024 - training loss: 0.3414, validation loss: 0.1912
2024-05-22 12:54:10 [INFO]: Epoch 025 - training loss: 0.3380, validation loss: 0.1900
2024-05-22 12:54:10 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 0.1883
2024-05-22 12:54:11 [INFO]: Epoch 027 - training loss: 0.3314, validation loss: 0.1863
2024-05-22 12:54:12 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1853
2024-05-22 12:54:12 [INFO]: Epoch 029 - training loss: 0.3257, validation loss: 0.1848
2024-05-22 12:54:13 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.1832
2024-05-22 12:54:14 [INFO]: Epoch 031 - training loss: 0.3250, validation loss: 0.1818
2024-05-22 12:54:14 [INFO]: Epoch 032 - training loss: 0.3188, validation loss: 0.1795
2024-05-22 12:54:15 [INFO]: Epoch 033 - training loss: 0.3169, validation loss: 0.1779
2024-05-22 12:54:16 [INFO]: Epoch 034 - training loss: 0.3155, validation loss: 0.1771
2024-05-22 12:54:16 [INFO]: Epoch 035 - training loss: 0.3129, validation loss: 0.1757
2024-05-22 12:54:17 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.1757
2024-05-22 12:54:18 [INFO]: Epoch 037 - training loss: 0.3126, validation loss: 0.1739
2024-05-22 12:54:18 [INFO]: Epoch 038 - training loss: 0.3109, validation loss: 0.1729
2024-05-22 12:54:19 [INFO]: Epoch 039 - training loss: 0.3076, validation loss: 0.1715
2024-05-22 12:54:20 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.1709
2024-05-22 12:54:20 [INFO]: Epoch 041 - training loss: 0.3030, validation loss: 0.1693
2024-05-22 12:54:21 [INFO]: Epoch 042 - training loss: 0.3013, validation loss: 0.1695
2024-05-22 12:54:22 [INFO]: Epoch 043 - training loss: 0.2995, validation loss: 0.1678
2024-05-22 12:54:22 [INFO]: Epoch 044 - training loss: 0.2991, validation loss: 0.1666
2024-05-22 12:54:23 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1657
2024-05-22 12:54:24 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.1659
2024-05-22 12:54:24 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1641
2024-05-22 12:54:25 [INFO]: Epoch 048 - training loss: 0.2938, validation loss: 0.1640
2024-05-22 12:54:26 [INFO]: Epoch 049 - training loss: 0.2918, validation loss: 0.1632
2024-05-22 12:54:26 [INFO]: Epoch 050 - training loss: 0.2892, validation loss: 0.1631
2024-05-22 12:54:27 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.1621
2024-05-22 12:54:28 [INFO]: Epoch 052 - training loss: 0.2890, validation loss: 0.1620
2024-05-22 12:54:28 [INFO]: Epoch 053 - training loss: 0.2858, validation loss: 0.1603
2024-05-22 12:54:29 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1599
2024-05-22 12:54:30 [INFO]: Epoch 055 - training loss: 0.2827, validation loss: 0.1591
2024-05-22 12:54:30 [INFO]: Epoch 056 - training loss: 0.2811, validation loss: 0.1587
2024-05-22 12:54:31 [INFO]: Epoch 057 - training loss: 0.2813, validation loss: 0.1583
2024-05-22 12:54:32 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1585
2024-05-22 12:54:32 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1577
2024-05-22 12:54:33 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1570
2024-05-22 12:54:34 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1558
2024-05-22 12:54:34 [INFO]: Epoch 062 - training loss: 0.2736, validation loss: 0.1562
2024-05-22 12:54:35 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.1557
2024-05-22 12:54:36 [INFO]: Epoch 064 - training loss: 0.2727, validation loss: 0.1553
2024-05-22 12:54:36 [INFO]: Epoch 065 - training loss: 0.2708, validation loss: 0.1549
2024-05-22 12:54:37 [INFO]: Epoch 066 - training loss: 0.2712, validation loss: 0.1534
2024-05-22 12:54:38 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1540
2024-05-22 12:54:38 [INFO]: Epoch 068 - training loss: 0.2677, validation loss: 0.1540
2024-05-22 12:54:39 [INFO]: Epoch 069 - training loss: 0.2675, validation loss: 0.1534
2024-05-22 12:54:40 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1533
2024-05-22 12:54:40 [INFO]: Epoch 071 - training loss: 0.2646, validation loss: 0.1531
2024-05-22 12:54:41 [INFO]: Epoch 072 - training loss: 0.2643, validation loss: 0.1525
2024-05-22 12:54:42 [INFO]: Epoch 073 - training loss: 0.2628, validation loss: 0.1525
2024-05-22 12:54:42 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1517
2024-05-22 12:54:43 [INFO]: Epoch 075 - training loss: 0.2620, validation loss: 0.1519
2024-05-22 12:54:44 [INFO]: Epoch 076 - training loss: 0.2606, validation loss: 0.1508
2024-05-22 12:54:44 [INFO]: Epoch 077 - training loss: 0.2600, validation loss: 0.1506
2024-05-22 12:54:45 [INFO]: Epoch 078 - training loss: 0.2598, validation loss: 0.1506
2024-05-22 12:54:46 [INFO]: Epoch 079 - training loss: 0.2579, validation loss: 0.1511
2024-05-22 12:54:46 [INFO]: Epoch 080 - training loss: 0.2581, validation loss: 0.1503
2024-05-22 12:54:47 [INFO]: Epoch 081 - training loss: 0.2571, validation loss: 0.1497
2024-05-22 12:54:48 [INFO]: Epoch 082 - training loss: 0.2586, validation loss: 0.1487
2024-05-22 12:54:48 [INFO]: Epoch 083 - training loss: 0.2565, validation loss: 0.1480
2024-05-22 12:54:49 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1487
2024-05-22 12:54:50 [INFO]: Epoch 085 - training loss: 0.2535, validation loss: 0.1483
2024-05-22 12:54:50 [INFO]: Epoch 086 - training loss: 0.2543, validation loss: 0.1479
2024-05-22 12:54:51 [INFO]: Epoch 087 - training loss: 0.2549, validation loss: 0.1479
2024-05-22 12:54:52 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1482
2024-05-22 12:54:52 [INFO]: Epoch 089 - training loss: 0.2529, validation loss: 0.1474
2024-05-22 12:54:53 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1477
2024-05-22 12:54:54 [INFO]: Epoch 091 - training loss: 0.2501, validation loss: 0.1476
2024-05-22 12:54:54 [INFO]: Epoch 092 - training loss: 0.2503, validation loss: 0.1466
2024-05-22 12:54:55 [INFO]: Epoch 093 - training loss: 0.2494, validation loss: 0.1459
2024-05-22 12:54:56 [INFO]: Epoch 094 - training loss: 0.2493, validation loss: 0.1463
2024-05-22 12:54:56 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1456
2024-05-22 12:54:57 [INFO]: Epoch 096 - training loss: 0.2472, validation loss: 0.1456
2024-05-22 12:54:58 [INFO]: Epoch 097 - training loss: 0.2464, validation loss: 0.1459
2024-05-22 12:54:58 [INFO]: Epoch 098 - training loss: 0.2456, validation loss: 0.1450
2024-05-22 12:54:59 [INFO]: Epoch 099 - training loss: 0.2460, validation loss: 0.1456
2024-05-22 12:55:00 [INFO]: Epoch 100 - training loss: 0.2476, validation loss: 0.1450
2024-05-22 12:55:00 [INFO]: Epoch 101 - training loss: 0.2470, validation loss: 0.1440
2024-05-22 12:55:01 [INFO]: Epoch 102 - training loss: 0.2435, validation loss: 0.1446
2024-05-22 12:55:02 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1441
2024-05-22 12:55:02 [INFO]: Epoch 104 - training loss: 0.2447, validation loss: 0.1432
2024-05-22 12:55:03 [INFO]: Epoch 105 - training loss: 0.2421, validation loss: 0.1441
2024-05-22 12:55:04 [INFO]: Epoch 106 - training loss: 0.2409, validation loss: 0.1436
2024-05-22 12:55:04 [INFO]: Epoch 107 - training loss: 0.2407, validation loss: 0.1426
2024-05-22 12:55:05 [INFO]: Epoch 108 - training loss: 0.2409, validation loss: 0.1434
2024-05-22 12:55:06 [INFO]: Epoch 109 - training loss: 0.2410, validation loss: 0.1422
2024-05-22 12:55:06 [INFO]: Epoch 110 - training loss: 0.2391, validation loss: 0.1428
2024-05-22 12:55:07 [INFO]: Epoch 111 - training loss: 0.2389, validation loss: 0.1441
2024-05-22 12:55:08 [INFO]: Epoch 112 - training loss: 0.2381, validation loss: 0.1416
2024-05-22 12:55:08 [INFO]: Epoch 113 - training loss: 0.2385, validation loss: 0.1430
2024-05-22 12:55:09 [INFO]: Epoch 114 - training loss: 0.2376, validation loss: 0.1428
2024-05-22 12:55:10 [INFO]: Epoch 115 - training loss: 0.2377, validation loss: 0.1422
2024-05-22 12:55:10 [INFO]: Epoch 116 - training loss: 0.2378, validation loss: 0.1424
2024-05-22 12:55:11 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1419
2024-05-22 12:55:12 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1421
2024-05-22 12:55:12 [INFO]: Epoch 119 - training loss: 0.2348, validation loss: 0.1404
2024-05-22 12:55:13 [INFO]: Epoch 120 - training loss: 0.2341, validation loss: 0.1420
2024-05-22 12:55:14 [INFO]: Epoch 121 - training loss: 0.2349, validation loss: 0.1418
2024-05-22 12:55:14 [INFO]: Epoch 122 - training loss: 0.2343, validation loss: 0.1419
2024-05-22 12:55:15 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1397
2024-05-22 12:55:16 [INFO]: Epoch 124 - training loss: 0.2333, validation loss: 0.1409
2024-05-22 12:55:16 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1401
2024-05-22 12:55:17 [INFO]: Epoch 126 - training loss: 0.2326, validation loss: 0.1401
2024-05-22 12:55:18 [INFO]: Epoch 127 - training loss: 0.2316, validation loss: 0.1402
2024-05-22 12:55:18 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1403
2024-05-22 12:55:19 [INFO]: Epoch 129 - training loss: 0.2310, validation loss: 0.1402
2024-05-22 12:55:20 [INFO]: Epoch 130 - training loss: 0.2315, validation loss: 0.1394
2024-05-22 12:55:20 [INFO]: Epoch 131 - training loss: 0.2317, validation loss: 0.1390
2024-05-22 12:55:21 [INFO]: Epoch 132 - training loss: 0.2294, validation loss: 0.1394
2024-05-22 12:55:22 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1380
2024-05-22 12:55:22 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1381
2024-05-22 12:55:23 [INFO]: Epoch 135 - training loss: 0.2281, validation loss: 0.1387
2024-05-22 12:55:24 [INFO]: Epoch 136 - training loss: 0.2271, validation loss: 0.1385
2024-05-22 12:55:24 [INFO]: Epoch 137 - training loss: 0.2285, validation loss: 0.1384
2024-05-22 12:55:25 [INFO]: Epoch 138 - training loss: 0.2276, validation loss: 0.1378
2024-05-22 12:55:26 [INFO]: Epoch 139 - training loss: 0.2265, validation loss: 0.1400
2024-05-22 12:55:26 [INFO]: Epoch 140 - training loss: 0.2281, validation loss: 0.1377
2024-05-22 12:55:27 [INFO]: Epoch 141 - training loss: 0.2259, validation loss: 0.1380
2024-05-22 12:55:28 [INFO]: Epoch 142 - training loss: 0.2259, validation loss: 0.1374
2024-05-22 12:55:28 [INFO]: Epoch 143 - training loss: 0.2263, validation loss: 0.1387
2024-05-22 12:55:29 [INFO]: Epoch 144 - training loss: 0.2262, validation loss: 0.1374
2024-05-22 12:55:30 [INFO]: Epoch 145 - training loss: 0.2249, validation loss: 0.1367
2024-05-22 12:55:30 [INFO]: Epoch 146 - training loss: 0.2247, validation loss: 0.1363
2024-05-22 12:55:31 [INFO]: Epoch 147 - training loss: 0.2255, validation loss: 0.1378
2024-05-22 12:55:32 [INFO]: Epoch 148 - training loss: 0.2254, validation loss: 0.1365
2024-05-22 12:55:32 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1360
2024-05-22 12:55:33 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1368
2024-05-22 12:55:34 [INFO]: Epoch 151 - training loss: 0.2232, validation loss: 0.1362
2024-05-22 12:55:34 [INFO]: Epoch 152 - training loss: 0.2210, validation loss: 0.1368
2024-05-22 12:55:35 [INFO]: Epoch 153 - training loss: 0.2219, validation loss: 0.1355
2024-05-22 12:55:36 [INFO]: Epoch 154 - training loss: 0.2209, validation loss: 0.1353
2024-05-22 12:55:36 [INFO]: Epoch 155 - training loss: 0.2200, validation loss: 0.1350
2024-05-22 12:55:37 [INFO]: Epoch 156 - training loss: 0.2209, validation loss: 0.1358
2024-05-22 12:55:38 [INFO]: Epoch 157 - training loss: 0.2214, validation loss: 0.1351
2024-05-22 12:55:38 [INFO]: Epoch 158 - training loss: 0.2212, validation loss: 0.1352
2024-05-22 12:55:39 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1371
2024-05-22 12:55:40 [INFO]: Epoch 160 - training loss: 0.2208, validation loss: 0.1348
2024-05-22 12:55:40 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1356
2024-05-22 12:55:41 [INFO]: Epoch 162 - training loss: 0.2197, validation loss: 0.1346
2024-05-22 12:55:42 [INFO]: Epoch 163 - training loss: 0.2177, validation loss: 0.1340
2024-05-22 12:55:42 [INFO]: Epoch 164 - training loss: 0.2188, validation loss: 0.1350
2024-05-22 12:55:43 [INFO]: Epoch 165 - training loss: 0.2185, validation loss: 0.1344
2024-05-22 12:55:44 [INFO]: Epoch 166 - training loss: 0.2178, validation loss: 0.1349
2024-05-22 12:55:44 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1335
2024-05-22 12:55:45 [INFO]: Epoch 168 - training loss: 0.2167, validation loss: 0.1337
2024-05-22 12:55:46 [INFO]: Epoch 169 - training loss: 0.2170, validation loss: 0.1345
2024-05-22 12:55:46 [INFO]: Epoch 170 - training loss: 0.2157, validation loss: 0.1340
2024-05-22 12:55:47 [INFO]: Epoch 171 - training loss: 0.2165, validation loss: 0.1328
2024-05-22 12:55:48 [INFO]: Epoch 172 - training loss: 0.2148, validation loss: 0.1336
2024-05-22 12:55:48 [INFO]: Epoch 173 - training loss: 0.2154, validation loss: 0.1335
2024-05-22 12:55:49 [INFO]: Epoch 174 - training loss: 0.2147, validation loss: 0.1341
2024-05-22 12:55:50 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1339
2024-05-22 12:55:50 [INFO]: Epoch 176 - training loss: 0.2173, validation loss: 0.1335
2024-05-22 12:55:51 [INFO]: Epoch 177 - training loss: 0.2144, validation loss: 0.1330
2024-05-22 12:55:52 [INFO]: Epoch 178 - training loss: 0.2132, validation loss: 0.1337
2024-05-22 12:55:52 [INFO]: Epoch 179 - training loss: 0.2135, validation loss: 0.1322
2024-05-22 12:55:53 [INFO]: Epoch 180 - training loss: 0.2134, validation loss: 0.1333
2024-05-22 12:55:54 [INFO]: Epoch 181 - training loss: 0.2130, validation loss: 0.1332
2024-05-22 12:55:54 [INFO]: Epoch 182 - training loss: 0.2127, validation loss: 0.1323
2024-05-22 12:55:55 [INFO]: Epoch 183 - training loss: 0.2129, validation loss: 0.1340
2024-05-22 12:55:56 [INFO]: Epoch 184 - training loss: 0.2135, validation loss: 0.1319
2024-05-22 12:55:56 [INFO]: Epoch 185 - training loss: 0.2138, validation loss: 0.1325
2024-05-22 12:55:57 [INFO]: Epoch 186 - training loss: 0.2129, validation loss: 0.1330
2024-05-22 12:55:58 [INFO]: Epoch 187 - training loss: 0.2122, validation loss: 0.1328
2024-05-22 12:55:58 [INFO]: Epoch 188 - training loss: 0.2111, validation loss: 0.1332
2024-05-22 12:55:59 [INFO]: Epoch 189 - training loss: 0.2111, validation loss: 0.1327
2024-05-22 12:56:00 [INFO]: Epoch 190 - training loss: 0.2102, validation loss: 0.1322
2024-05-22 12:56:00 [INFO]: Epoch 191 - training loss: 0.2100, validation loss: 0.1323
2024-05-22 12:56:01 [INFO]: Epoch 192 - training loss: 0.2100, validation loss: 0.1324
2024-05-22 12:56:02 [INFO]: Epoch 193 - training loss: 0.2098, validation loss: 0.1312
2024-05-22 12:56:02 [INFO]: Epoch 194 - training loss: 0.2097, validation loss: 0.1324
2024-05-22 12:56:03 [INFO]: Epoch 195 - training loss: 0.2103, validation loss: 0.1330
2024-05-22 12:56:04 [INFO]: Epoch 196 - training loss: 0.2094, validation loss: 0.1320
2024-05-22 12:56:04 [INFO]: Epoch 197 - training loss: 0.2080, validation loss: 0.1330
2024-05-22 12:56:05 [INFO]: Epoch 198 - training loss: 0.2084, validation loss: 0.1318
2024-05-22 12:56:06 [INFO]: Epoch 199 - training loss: 0.2109, validation loss: 0.1325
2024-05-22 12:56:06 [INFO]: Epoch 200 - training loss: 0.2096, validation loss: 0.1315
2024-05-22 12:56:07 [INFO]: Epoch 201 - training loss: 0.2081, validation loss: 0.1317
2024-05-22 12:56:08 [INFO]: Epoch 202 - training loss: 0.2077, validation loss: 0.1314
2024-05-22 12:56:08 [INFO]: Epoch 203 - training loss: 0.2075, validation loss: 0.1314
2024-05-22 12:56:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:56:08 [INFO]: Finished training. The best model is from epoch#193.
2024-05-22 12:56:09 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_air_quality/20240522_T125353/SAITS.pypots
2024-05-22 12:56:09 [INFO]: SAITS on Air-Quality: MAE=0.1464, MSE=0.1170
2024-05-22 12:56:09 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-22 12:56:09 [INFO]: Using the given device: cuda:0
2024-05-22 12:56:09 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240522_T125609
2024-05-22 12:56:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_air_quality/20240522_T125609/tensorboard
2024-05-22 12:56:09 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 12:56:09 [INFO]: Epoch 001 - training loss: 0.9189, validation loss: 0.4625
2024-05-22 12:56:09 [INFO]: Epoch 002 - training loss: 0.5748, validation loss: 0.3571
2024-05-22 12:56:10 [INFO]: Epoch 003 - training loss: 0.4868, validation loss: 0.2963
2024-05-22 12:56:10 [INFO]: Epoch 004 - training loss: 0.4388, validation loss: 0.2729
2024-05-22 12:56:10 [INFO]: Epoch 005 - training loss: 0.4109, validation loss: 0.2592
2024-05-22 12:56:11 [INFO]: Epoch 006 - training loss: 0.3930, validation loss: 0.2483
2024-05-22 12:56:11 [INFO]: Epoch 007 - training loss: 0.3756, validation loss: 0.2415
2024-05-22 12:56:11 [INFO]: Epoch 008 - training loss: 0.3660, validation loss: 0.2354
2024-05-22 12:56:12 [INFO]: Epoch 009 - training loss: 0.3564, validation loss: 0.2295
2024-05-22 12:56:12 [INFO]: Epoch 010 - training loss: 0.3498, validation loss: 0.2252
2024-05-22 12:56:12 [INFO]: Epoch 011 - training loss: 0.3442, validation loss: 0.2243
2024-05-22 12:56:13 [INFO]: Epoch 012 - training loss: 0.3393, validation loss: 0.2178
2024-05-22 12:56:13 [INFO]: Epoch 013 - training loss: 0.3316, validation loss: 0.2131
2024-05-22 12:56:13 [INFO]: Epoch 014 - training loss: 0.3282, validation loss: 0.2097
2024-05-22 12:56:13 [INFO]: Epoch 015 - training loss: 0.3238, validation loss: 0.2073
2024-05-22 12:56:14 [INFO]: Epoch 016 - training loss: 0.3199, validation loss: 0.2043
2024-05-22 12:56:14 [INFO]: Epoch 017 - training loss: 0.3141, validation loss: 0.2001
2024-05-22 12:56:14 [INFO]: Epoch 018 - training loss: 0.3104, validation loss: 0.1984
2024-05-22 12:56:15 [INFO]: Epoch 019 - training loss: 0.3078, validation loss: 0.1953
2024-05-22 12:56:15 [INFO]: Epoch 020 - training loss: 0.3043, validation loss: 0.1940
2024-05-22 12:56:15 [INFO]: Epoch 021 - training loss: 0.3035, validation loss: 0.1912
2024-05-22 12:56:16 [INFO]: Epoch 022 - training loss: 0.3023, validation loss: 0.1899
2024-05-22 12:56:16 [INFO]: Epoch 023 - training loss: 0.3023, validation loss: 0.1883
2024-05-22 12:56:16 [INFO]: Epoch 024 - training loss: 0.2963, validation loss: 0.1872
2024-05-22 12:56:17 [INFO]: Epoch 025 - training loss: 0.2941, validation loss: 0.1870
2024-05-22 12:56:17 [INFO]: Epoch 026 - training loss: 0.2932, validation loss: 0.1857
2024-05-22 12:56:17 [INFO]: Epoch 027 - training loss: 0.2908, validation loss: 0.1852
2024-05-22 12:56:18 [INFO]: Epoch 028 - training loss: 0.2882, validation loss: 0.1832
2024-05-22 12:56:18 [INFO]: Epoch 029 - training loss: 0.2862, validation loss: 0.1858
2024-05-22 12:56:18 [INFO]: Epoch 030 - training loss: 0.2875, validation loss: 0.1812
2024-05-22 12:56:19 [INFO]: Epoch 031 - training loss: 0.2886, validation loss: 0.1827
2024-05-22 12:56:19 [INFO]: Epoch 032 - training loss: 0.2827, validation loss: 0.1811
2024-05-22 12:56:19 [INFO]: Epoch 033 - training loss: 0.2807, validation loss: 0.1812
2024-05-22 12:56:19 [INFO]: Epoch 034 - training loss: 0.2808, validation loss: 0.1804
2024-05-22 12:56:20 [INFO]: Epoch 035 - training loss: 0.2782, validation loss: 0.1785
2024-05-22 12:56:20 [INFO]: Epoch 036 - training loss: 0.2742, validation loss: 0.1784
2024-05-22 12:56:20 [INFO]: Epoch 037 - training loss: 0.2769, validation loss: 0.1785
2024-05-22 12:56:21 [INFO]: Epoch 038 - training loss: 0.2759, validation loss: 0.1776
2024-05-22 12:56:21 [INFO]: Epoch 039 - training loss: 0.2724, validation loss: 0.1792
2024-05-22 12:56:21 [INFO]: Epoch 040 - training loss: 0.2724, validation loss: 0.1774
2024-05-22 12:56:22 [INFO]: Epoch 041 - training loss: 0.2706, validation loss: 0.1742
2024-05-22 12:56:22 [INFO]: Epoch 042 - training loss: 0.2713, validation loss: 0.1756
2024-05-22 12:56:22 [INFO]: Epoch 043 - training loss: 0.2703, validation loss: 0.1748
2024-05-22 12:56:23 [INFO]: Epoch 044 - training loss: 0.2695, validation loss: 0.1746
2024-05-22 12:56:23 [INFO]: Epoch 045 - training loss: 0.2672, validation loss: 0.1722
2024-05-22 12:56:23 [INFO]: Epoch 046 - training loss: 0.2641, validation loss: 0.1744
2024-05-22 12:56:24 [INFO]: Epoch 047 - training loss: 0.2675, validation loss: 0.1748
2024-05-22 12:56:24 [INFO]: Epoch 048 - training loss: 0.2669, validation loss: 0.1730
2024-05-22 12:56:24 [INFO]: Epoch 049 - training loss: 0.2638, validation loss: 0.1726
2024-05-22 12:56:25 [INFO]: Epoch 050 - training loss: 0.2633, validation loss: 0.1740
2024-05-22 12:56:25 [INFO]: Epoch 051 - training loss: 0.2635, validation loss: 0.1707
2024-05-22 12:56:25 [INFO]: Epoch 052 - training loss: 0.2605, validation loss: 0.1698
2024-05-22 12:56:25 [INFO]: Epoch 053 - training loss: 0.2635, validation loss: 0.1705
2024-05-22 12:56:26 [INFO]: Epoch 054 - training loss: 0.2592, validation loss: 0.1704
2024-05-22 12:56:26 [INFO]: Epoch 055 - training loss: 0.2571, validation loss: 0.1719
2024-05-22 12:56:26 [INFO]: Epoch 056 - training loss: 0.2579, validation loss: 0.1699
2024-05-22 12:56:27 [INFO]: Epoch 057 - training loss: 0.2561, validation loss: 0.1670
2024-05-22 12:56:27 [INFO]: Epoch 058 - training loss: 0.2556, validation loss: 0.1696
2024-05-22 12:56:27 [INFO]: Epoch 059 - training loss: 0.2545, validation loss: 0.1671
2024-05-22 12:56:28 [INFO]: Epoch 060 - training loss: 0.2519, validation loss: 0.1677
2024-05-22 12:56:28 [INFO]: Epoch 061 - training loss: 0.2528, validation loss: 0.1678
2024-05-22 12:56:28 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1695
2024-05-22 12:56:29 [INFO]: Epoch 063 - training loss: 0.2538, validation loss: 0.1658
2024-05-22 12:56:29 [INFO]: Epoch 064 - training loss: 0.2517, validation loss: 0.1660
2024-05-22 12:56:29 [INFO]: Epoch 065 - training loss: 0.2500, validation loss: 0.1663
2024-05-22 12:56:30 [INFO]: Epoch 066 - training loss: 0.2532, validation loss: 0.1662
2024-05-22 12:56:30 [INFO]: Epoch 067 - training loss: 0.2499, validation loss: 0.1644
2024-05-22 12:56:30 [INFO]: Epoch 068 - training loss: 0.2480, validation loss: 0.1647
2024-05-22 12:56:31 [INFO]: Epoch 069 - training loss: 0.2477, validation loss: 0.1664
2024-05-22 12:56:31 [INFO]: Epoch 070 - training loss: 0.2479, validation loss: 0.1633
2024-05-22 12:56:31 [INFO]: Epoch 071 - training loss: 0.2476, validation loss: 0.1625
2024-05-22 12:56:31 [INFO]: Epoch 072 - training loss: 0.2514, validation loss: 0.1649
2024-05-22 12:56:32 [INFO]: Epoch 073 - training loss: 0.2475, validation loss: 0.1631
2024-05-22 12:56:32 [INFO]: Epoch 074 - training loss: 0.2438, validation loss: 0.1618
2024-05-22 12:56:32 [INFO]: Epoch 075 - training loss: 0.2463, validation loss: 0.1631
2024-05-22 12:56:33 [INFO]: Epoch 076 - training loss: 0.2435, validation loss: 0.1607
2024-05-22 12:56:33 [INFO]: Epoch 077 - training loss: 0.2422, validation loss: 0.1609
2024-05-22 12:56:33 [INFO]: Epoch 078 - training loss: 0.2441, validation loss: 0.1631
2024-05-22 12:56:34 [INFO]: Epoch 079 - training loss: 0.2409, validation loss: 0.1629
2024-05-22 12:56:34 [INFO]: Epoch 080 - training loss: 0.2393, validation loss: 0.1624
2024-05-22 12:56:34 [INFO]: Epoch 081 - training loss: 0.2395, validation loss: 0.1599
2024-05-22 12:56:35 [INFO]: Epoch 082 - training loss: 0.2402, validation loss: 0.1614
2024-05-22 12:56:35 [INFO]: Epoch 083 - training loss: 0.2406, validation loss: 0.1634
2024-05-22 12:56:35 [INFO]: Epoch 084 - training loss: 0.2384, validation loss: 0.1613
2024-05-22 12:56:36 [INFO]: Epoch 085 - training loss: 0.2364, validation loss: 0.1599
2024-05-22 12:56:36 [INFO]: Epoch 086 - training loss: 0.2357, validation loss: 0.1579
2024-05-22 12:56:36 [INFO]: Epoch 087 - training loss: 0.2339, validation loss: 0.1590
2024-05-22 12:56:37 [INFO]: Epoch 088 - training loss: 0.2347, validation loss: 0.1583
2024-05-22 12:56:37 [INFO]: Epoch 089 - training loss: 0.2345, validation loss: 0.1587
2024-05-22 12:56:37 [INFO]: Epoch 090 - training loss: 0.2353, validation loss: 0.1579
2024-05-22 12:56:37 [INFO]: Epoch 091 - training loss: 0.2311, validation loss: 0.1576
2024-05-22 12:56:38 [INFO]: Epoch 092 - training loss: 0.2333, validation loss: 0.1572
2024-05-22 12:56:38 [INFO]: Epoch 093 - training loss: 0.2331, validation loss: 0.1574
2024-05-22 12:56:38 [INFO]: Epoch 094 - training loss: 0.2316, validation loss: 0.1573
2024-05-22 12:56:39 [INFO]: Epoch 095 - training loss: 0.2357, validation loss: 0.1582
2024-05-22 12:56:39 [INFO]: Epoch 096 - training loss: 0.2330, validation loss: 0.1568
2024-05-22 12:56:39 [INFO]: Epoch 097 - training loss: 0.2316, validation loss: 0.1571
2024-05-22 12:56:40 [INFO]: Epoch 098 - training loss: 0.2302, validation loss: 0.1580
2024-05-22 12:56:40 [INFO]: Epoch 099 - training loss: 0.2301, validation loss: 0.1579
2024-05-22 12:56:40 [INFO]: Epoch 100 - training loss: 0.2290, validation loss: 0.1565
2024-05-22 12:56:41 [INFO]: Epoch 101 - training loss: 0.2271, validation loss: 0.1550
2024-05-22 12:56:41 [INFO]: Epoch 102 - training loss: 0.2278, validation loss: 0.1549
2024-05-22 12:56:41 [INFO]: Epoch 103 - training loss: 0.2320, validation loss: 0.1547
2024-05-22 12:56:42 [INFO]: Epoch 104 - training loss: 0.2284, validation loss: 0.1538
2024-05-22 12:56:42 [INFO]: Epoch 105 - training loss: 0.2287, validation loss: 0.1548
2024-05-22 12:56:42 [INFO]: Epoch 106 - training loss: 0.2294, validation loss: 0.1540
2024-05-22 12:56:42 [INFO]: Epoch 107 - training loss: 0.2258, validation loss: 0.1528
2024-05-22 12:56:43 [INFO]: Epoch 108 - training loss: 0.2245, validation loss: 0.1551
2024-05-22 12:56:43 [INFO]: Epoch 109 - training loss: 0.2262, validation loss: 0.1545
2024-05-22 12:56:43 [INFO]: Epoch 110 - training loss: 0.2229, validation loss: 0.1557
2024-05-22 12:56:44 [INFO]: Epoch 111 - training loss: 0.2222, validation loss: 0.1535
2024-05-22 12:56:44 [INFO]: Epoch 112 - training loss: 0.2227, validation loss: 0.1533
2024-05-22 12:56:44 [INFO]: Epoch 113 - training loss: 0.2228, validation loss: 0.1542
2024-05-22 12:56:45 [INFO]: Epoch 114 - training loss: 0.2218, validation loss: 0.1523
2024-05-22 12:56:45 [INFO]: Epoch 115 - training loss: 0.2233, validation loss: 0.1539
2024-05-22 12:56:45 [INFO]: Epoch 116 - training loss: 0.2209, validation loss: 0.1526
2024-05-22 12:56:46 [INFO]: Epoch 117 - training loss: 0.2210, validation loss: 0.1536
2024-05-22 12:56:46 [INFO]: Epoch 118 - training loss: 0.2207, validation loss: 0.1503
2024-05-22 12:56:46 [INFO]: Epoch 119 - training loss: 0.2190, validation loss: 0.1532
2024-05-22 12:56:47 [INFO]: Epoch 120 - training loss: 0.2221, validation loss: 0.1518
2024-05-22 12:56:47 [INFO]: Epoch 121 - training loss: 0.2202, validation loss: 0.1514
2024-05-22 12:56:47 [INFO]: Epoch 122 - training loss: 0.2195, validation loss: 0.1505
2024-05-22 12:56:48 [INFO]: Epoch 123 - training loss: 0.2191, validation loss: 0.1515
2024-05-22 12:56:48 [INFO]: Epoch 124 - training loss: 0.2198, validation loss: 0.1536
2024-05-22 12:56:48 [INFO]: Epoch 125 - training loss: 0.2242, validation loss: 0.1496
2024-05-22 12:56:49 [INFO]: Epoch 126 - training loss: 0.2192, validation loss: 0.1515
2024-05-22 12:56:49 [INFO]: Epoch 127 - training loss: 0.2177, validation loss: 0.1503
2024-05-22 12:56:49 [INFO]: Epoch 128 - training loss: 0.2148, validation loss: 0.1499
2024-05-22 12:56:49 [INFO]: Epoch 129 - training loss: 0.2173, validation loss: 0.1526
2024-05-22 12:56:50 [INFO]: Epoch 130 - training loss: 0.2192, validation loss: 0.1488
2024-05-22 12:56:50 [INFO]: Epoch 131 - training loss: 0.2175, validation loss: 0.1492
2024-05-22 12:56:50 [INFO]: Epoch 132 - training loss: 0.2163, validation loss: 0.1519
2024-05-22 12:56:51 [INFO]: Epoch 133 - training loss: 0.2145, validation loss: 0.1481
2024-05-22 12:56:51 [INFO]: Epoch 134 - training loss: 0.2131, validation loss: 0.1481
2024-05-22 12:56:51 [INFO]: Epoch 135 - training loss: 0.2148, validation loss: 0.1494
2024-05-22 12:56:52 [INFO]: Epoch 136 - training loss: 0.2156, validation loss: 0.1495
2024-05-22 12:56:52 [INFO]: Epoch 137 - training loss: 0.2147, validation loss: 0.1509
2024-05-22 12:56:52 [INFO]: Epoch 138 - training loss: 0.2167, validation loss: 0.1485
2024-05-22 12:56:53 [INFO]: Epoch 139 - training loss: 0.2135, validation loss: 0.1494
2024-05-22 12:56:53 [INFO]: Epoch 140 - training loss: 0.2116, validation loss: 0.1480
2024-05-22 12:56:53 [INFO]: Epoch 141 - training loss: 0.2142, validation loss: 0.1494
2024-05-22 12:56:54 [INFO]: Epoch 142 - training loss: 0.2155, validation loss: 0.1485
2024-05-22 12:56:54 [INFO]: Epoch 143 - training loss: 0.2136, validation loss: 0.1477
2024-05-22 12:56:54 [INFO]: Epoch 144 - training loss: 0.2131, validation loss: 0.1474
2024-05-22 12:56:55 [INFO]: Epoch 145 - training loss: 0.2106, validation loss: 0.1473
2024-05-22 12:56:55 [INFO]: Epoch 146 - training loss: 0.2095, validation loss: 0.1482
2024-05-22 12:56:55 [INFO]: Epoch 147 - training loss: 0.2094, validation loss: 0.1468
2024-05-22 12:56:55 [INFO]: Epoch 148 - training loss: 0.2106, validation loss: 0.1473
2024-05-22 12:56:56 [INFO]: Epoch 149 - training loss: 0.2092, validation loss: 0.1484
2024-05-22 12:56:56 [INFO]: Epoch 150 - training loss: 0.2105, validation loss: 0.1481
2024-05-22 12:56:56 [INFO]: Epoch 151 - training loss: 0.2107, validation loss: 0.1461
2024-05-22 12:56:57 [INFO]: Epoch 152 - training loss: 0.2121, validation loss: 0.1450
2024-05-22 12:56:57 [INFO]: Epoch 153 - training loss: 0.2093, validation loss: 0.1460
2024-05-22 12:56:57 [INFO]: Epoch 154 - training loss: 0.2079, validation loss: 0.1466
2024-05-22 12:56:58 [INFO]: Epoch 155 - training loss: 0.2085, validation loss: 0.1469
2024-05-22 12:56:58 [INFO]: Epoch 156 - training loss: 0.2093, validation loss: 0.1457
2024-05-22 12:56:58 [INFO]: Epoch 157 - training loss: 0.2074, validation loss: 0.1467
2024-05-22 12:56:59 [INFO]: Epoch 158 - training loss: 0.2053, validation loss: 0.1459
2024-05-22 12:56:59 [INFO]: Epoch 159 - training loss: 0.2066, validation loss: 0.1449
2024-05-22 12:56:59 [INFO]: Epoch 160 - training loss: 0.2064, validation loss: 0.1451
2024-05-22 12:57:00 [INFO]: Epoch 161 - training loss: 0.2057, validation loss: 0.1462
2024-05-22 12:57:00 [INFO]: Epoch 162 - training loss: 0.2060, validation loss: 0.1473
2024-05-22 12:57:00 [INFO]: Epoch 163 - training loss: 0.2069, validation loss: 0.1440
2024-05-22 12:57:00 [INFO]: Epoch 164 - training loss: 0.2087, validation loss: 0.1449
2024-05-22 12:57:01 [INFO]: Epoch 165 - training loss: 0.2052, validation loss: 0.1450
2024-05-22 12:57:01 [INFO]: Epoch 166 - training loss: 0.2048, validation loss: 0.1449
2024-05-22 12:57:01 [INFO]: Epoch 167 - training loss: 0.2042, validation loss: 0.1443
2024-05-22 12:57:02 [INFO]: Epoch 168 - training loss: 0.2051, validation loss: 0.1437
2024-05-22 12:57:02 [INFO]: Epoch 169 - training loss: 0.2035, validation loss: 0.1453
2024-05-22 12:57:02 [INFO]: Epoch 170 - training loss: 0.2035, validation loss: 0.1456
2024-05-22 12:57:03 [INFO]: Epoch 171 - training loss: 0.2044, validation loss: 0.1441
2024-05-22 12:57:03 [INFO]: Epoch 172 - training loss: 0.2026, validation loss: 0.1433
2024-05-22 12:57:03 [INFO]: Epoch 173 - training loss: 0.2012, validation loss: 0.1435
2024-05-22 12:57:04 [INFO]: Epoch 174 - training loss: 0.2011, validation loss: 0.1435
2024-05-22 12:57:04 [INFO]: Epoch 175 - training loss: 0.2050, validation loss: 0.1437
2024-05-22 12:57:04 [INFO]: Epoch 176 - training loss: 0.2049, validation loss: 0.1433
2024-05-22 12:57:05 [INFO]: Epoch 177 - training loss: 0.2023, validation loss: 0.1442
2024-05-22 12:57:05 [INFO]: Epoch 178 - training loss: 0.2017, validation loss: 0.1432
2024-05-22 12:57:05 [INFO]: Epoch 179 - training loss: 0.1994, validation loss: 0.1438
2024-05-22 12:57:06 [INFO]: Epoch 180 - training loss: 0.2003, validation loss: 0.1439
2024-05-22 12:57:06 [INFO]: Epoch 181 - training loss: 0.2021, validation loss: 0.1430
2024-05-22 12:57:06 [INFO]: Epoch 182 - training loss: 0.1982, validation loss: 0.1430
2024-05-22 12:57:07 [INFO]: Epoch 183 - training loss: 0.1990, validation loss: 0.1442
2024-05-22 12:57:07 [INFO]: Epoch 184 - training loss: 0.2001, validation loss: 0.1424
2024-05-22 12:57:07 [INFO]: Epoch 185 - training loss: 0.1998, validation loss: 0.1429
2024-05-22 12:57:07 [INFO]: Epoch 186 - training loss: 0.1986, validation loss: 0.1429
2024-05-22 12:57:08 [INFO]: Epoch 187 - training loss: 0.1984, validation loss: 0.1446
2024-05-22 12:57:08 [INFO]: Epoch 188 - training loss: 0.2014, validation loss: 0.1420
2024-05-22 12:57:08 [INFO]: Epoch 189 - training loss: 0.2011, validation loss: 0.1420
2024-05-22 12:57:09 [INFO]: Epoch 190 - training loss: 0.1982, validation loss: 0.1411
2024-05-22 12:57:09 [INFO]: Epoch 191 - training loss: 0.1977, validation loss: 0.1417
2024-05-22 12:57:09 [INFO]: Epoch 192 - training loss: 0.1982, validation loss: 0.1431
2024-05-22 12:57:10 [INFO]: Epoch 193 - training loss: 0.1994, validation loss: 0.1419
2024-05-22 12:57:10 [INFO]: Epoch 194 - training loss: 0.1973, validation loss: 0.1420
2024-05-22 12:57:10 [INFO]: Epoch 195 - training loss: 0.1977, validation loss: 0.1407
2024-05-22 12:57:11 [INFO]: Epoch 196 - training loss: 0.1956, validation loss: 0.1413
2024-05-22 12:57:11 [INFO]: Epoch 197 - training loss: 0.1966, validation loss: 0.1408
2024-05-22 12:57:11 [INFO]: Epoch 198 - training loss: 0.1979, validation loss: 0.1421
2024-05-22 12:57:12 [INFO]: Epoch 199 - training loss: 0.1990, validation loss: 0.1410
2024-05-22 12:57:12 [INFO]: Epoch 200 - training loss: 0.1984, validation loss: 0.1439
2024-05-22 12:57:12 [INFO]: Epoch 201 - training loss: 0.1991, validation loss: 0.1417
2024-05-22 12:57:13 [INFO]: Epoch 202 - training loss: 0.1979, validation loss: 0.1417
2024-05-22 12:57:13 [INFO]: Epoch 203 - training loss: 0.2006, validation loss: 0.1409
2024-05-22 12:57:13 [INFO]: Epoch 204 - training loss: 0.1990, validation loss: 0.1419
2024-05-22 12:57:13 [INFO]: Epoch 205 - training loss: 0.1953, validation loss: 0.1410
2024-05-22 12:57:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:57:13 [INFO]: Finished training. The best model is from epoch#195.
2024-05-22 12:57:14 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_air_quality/20240522_T125609/Transformer.pypots
2024-05-22 12:57:14 [INFO]: Transformer on Air-Quality: MAE=0.1610, MSE=0.1323
2024-05-22 12:57:14 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-22 12:57:14 [INFO]: Using the given device: cuda:0
2024-05-22 12:57:14 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240522_T125714
2024-05-22 12:57:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_air_quality/20240522_T125714/tensorboard
2024-05-22 12:57:14 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 12:57:15 [INFO]: Epoch 001 - training loss: 0.3268, validation loss: 0.2712
2024-05-22 12:57:15 [INFO]: Epoch 002 - training loss: 0.2256, validation loss: 0.2366
2024-05-22 12:57:16 [INFO]: Epoch 003 - training loss: 0.1905, validation loss: 0.2307
2024-05-22 12:57:16 [INFO]: Epoch 004 - training loss: 0.1796, validation loss: 0.2216
2024-05-22 12:57:17 [INFO]: Epoch 005 - training loss: 0.1717, validation loss: 0.2171
2024-05-22 12:57:17 [INFO]: Epoch 006 - training loss: 0.1623, validation loss: 0.2106
2024-05-22 12:57:18 [INFO]: Epoch 007 - training loss: 0.1746, validation loss: 0.2192
2024-05-22 12:57:18 [INFO]: Epoch 008 - training loss: 0.1538, validation loss: 0.2114
2024-05-22 12:57:19 [INFO]: Epoch 009 - training loss: 0.1539, validation loss: 0.2119
2024-05-22 12:57:19 [INFO]: Epoch 010 - training loss: 0.1517, validation loss: 0.2051
2024-05-22 12:57:20 [INFO]: Epoch 011 - training loss: 0.1417, validation loss: 0.1989
2024-05-22 12:57:20 [INFO]: Epoch 012 - training loss: 0.1577, validation loss: 0.2029
2024-05-22 12:57:21 [INFO]: Epoch 013 - training loss: 0.1486, validation loss: 0.1901
2024-05-22 12:57:21 [INFO]: Epoch 014 - training loss: 0.1389, validation loss: 0.1922
2024-05-22 12:57:22 [INFO]: Epoch 015 - training loss: 0.1525, validation loss: 0.1858
2024-05-22 12:57:22 [INFO]: Epoch 016 - training loss: 0.1254, validation loss: 0.1793
2024-05-22 12:57:23 [INFO]: Epoch 017 - training loss: 0.1357, validation loss: 0.1857
2024-05-22 12:57:23 [INFO]: Epoch 018 - training loss: 0.1455, validation loss: 0.1812
2024-05-22 12:57:24 [INFO]: Epoch 019 - training loss: 0.1252, validation loss: 0.1811
2024-05-22 12:57:25 [INFO]: Epoch 020 - training loss: 0.1258, validation loss: 0.1778
2024-05-22 12:57:25 [INFO]: Epoch 021 - training loss: 0.1385, validation loss: 0.1712
2024-05-22 12:57:26 [INFO]: Epoch 022 - training loss: 0.1347, validation loss: 0.1724
2024-05-22 12:57:26 [INFO]: Epoch 023 - training loss: 0.1197, validation loss: 0.1732
2024-05-22 12:57:27 [INFO]: Epoch 024 - training loss: 0.1275, validation loss: 0.1826
2024-05-22 12:57:27 [INFO]: Epoch 025 - training loss: 0.1295, validation loss: 0.1698
2024-05-22 12:57:28 [INFO]: Epoch 026 - training loss: 0.1304, validation loss: 0.1732
2024-05-22 12:57:28 [INFO]: Epoch 027 - training loss: 0.1086, validation loss: 0.1752
2024-05-22 12:57:29 [INFO]: Epoch 028 - training loss: 0.1303, validation loss: 0.1736
2024-05-22 12:57:29 [INFO]: Epoch 029 - training loss: 0.1185, validation loss: 0.1692
2024-05-22 12:57:30 [INFO]: Epoch 030 - training loss: 0.1101, validation loss: 0.1647
2024-05-22 12:57:30 [INFO]: Epoch 031 - training loss: 0.1087, validation loss: 0.1657
2024-05-22 12:57:31 [INFO]: Epoch 032 - training loss: 0.1061, validation loss: 0.1688
2024-05-22 12:57:31 [INFO]: Epoch 033 - training loss: 0.1147, validation loss: 0.1641
2024-05-22 12:57:32 [INFO]: Epoch 034 - training loss: 0.1126, validation loss: 0.1640
2024-05-22 12:57:32 [INFO]: Epoch 035 - training loss: 0.1144, validation loss: 0.1637
2024-05-22 12:57:33 [INFO]: Epoch 036 - training loss: 0.1014, validation loss: 0.1757
2024-05-22 12:57:33 [INFO]: Epoch 037 - training loss: 0.1042, validation loss: 0.1739
2024-05-22 12:57:34 [INFO]: Epoch 038 - training loss: 0.1339, validation loss: 0.1644
2024-05-22 12:57:34 [INFO]: Epoch 039 - training loss: 0.1051, validation loss: 0.1704
2024-05-22 12:57:35 [INFO]: Epoch 040 - training loss: 0.1131, validation loss: 0.1669
2024-05-22 12:57:36 [INFO]: Epoch 041 - training loss: 0.1410, validation loss: 0.1662
2024-05-22 12:57:36 [INFO]: Epoch 042 - training loss: 0.1153, validation loss: 0.1664
2024-05-22 12:57:37 [INFO]: Epoch 043 - training loss: 0.1105, validation loss: 0.1676
2024-05-22 12:57:37 [INFO]: Epoch 044 - training loss: 0.0977, validation loss: 0.1772
2024-05-22 12:57:38 [INFO]: Epoch 045 - training loss: 0.1085, validation loss: 0.1661
2024-05-22 12:57:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 12:57:38 [INFO]: Finished training. The best model is from epoch#35.
2024-05-22 12:57:38 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_air_quality/20240522_T125714/TimesNet.pypots
2024-05-22 12:57:38 [INFO]: TimesNet on Air-Quality: MAE=0.1612, MSE=0.1663
2024-05-22 12:57:38 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-22 12:57:38 [INFO]: Using the given device: cuda:0
2024-05-22 12:57:38 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738
2024-05-22 12:57:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/tensorboard
2024-05-22 12:57:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 12:57:55 [INFO]: Epoch 001 - training loss: 0.4950, validation loss: 0.3602
2024-05-22 12:57:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch1_loss0.36019819378852846.pypots
2024-05-22 12:58:11 [INFO]: Epoch 002 - training loss: 0.3184, validation loss: 0.2840
2024-05-22 12:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch2_loss0.28403380513191223.pypots
2024-05-22 12:58:28 [INFO]: Epoch 003 - training loss: 0.2545, validation loss: 0.2375
2024-05-22 12:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch3_loss0.23748077303171158.pypots
2024-05-22 12:58:45 [INFO]: Epoch 004 - training loss: 0.2151, validation loss: 0.1972
2024-05-22 12:58:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch4_loss0.19718504697084427.pypots
2024-05-22 12:59:02 [INFO]: Epoch 005 - training loss: 0.1891, validation loss: 0.1884
2024-05-22 12:59:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch5_loss0.1883756026625633.pypots
2024-05-22 12:59:19 [INFO]: Epoch 006 - training loss: 0.2126, validation loss: 0.1792
2024-05-22 12:59:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch6_loss0.17922637909650802.pypots
2024-05-22 12:59:35 [INFO]: Epoch 007 - training loss: 0.2033, validation loss: 0.1638
2024-05-22 12:59:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch7_loss0.16380236595869063.pypots
2024-05-22 12:59:52 [INFO]: Epoch 008 - training loss: 0.1630, validation loss: 0.1632
2024-05-22 12:59:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch8_loss0.16324598342180252.pypots
2024-05-22 13:00:09 [INFO]: Epoch 009 - training loss: 0.1641, validation loss: 0.1578
2024-05-22 13:00:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch9_loss0.1578305184841156.pypots
2024-05-22 13:00:26 [INFO]: Epoch 010 - training loss: 0.1829, validation loss: 0.1595
2024-05-22 13:00:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch10_loss0.15951036661863327.pypots
2024-05-22 13:00:43 [INFO]: Epoch 011 - training loss: 0.1701, validation loss: 0.1488
2024-05-22 13:00:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch11_loss0.14877884984016418.pypots
2024-05-22 13:00:59 [INFO]: Epoch 012 - training loss: 0.1610, validation loss: 0.1505
2024-05-22 13:00:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch12_loss0.15047487020492553.pypots
2024-05-22 13:01:16 [INFO]: Epoch 013 - training loss: 0.1679, validation loss: 0.1466
2024-05-22 13:01:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch13_loss0.1466110333800316.pypots
2024-05-22 13:01:33 [INFO]: Epoch 014 - training loss: 0.1677, validation loss: 0.1463
2024-05-22 13:01:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch14_loss0.14629407376050949.pypots
2024-05-22 13:01:50 [INFO]: Epoch 015 - training loss: 0.1673, validation loss: 0.1461
2024-05-22 13:01:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch15_loss0.14614745676517488.pypots
2024-05-22 13:02:07 [INFO]: Epoch 016 - training loss: 0.1624, validation loss: 0.1423
2024-05-22 13:02:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch16_loss0.1423323504626751.pypots
2024-05-22 13:02:23 [INFO]: Epoch 017 - training loss: 0.1588, validation loss: 0.1472
2024-05-22 13:02:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch17_loss0.1471683993935585.pypots
2024-05-22 13:02:40 [INFO]: Epoch 018 - training loss: 0.1696, validation loss: 0.1404
2024-05-22 13:02:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch18_loss0.14044079408049584.pypots
2024-05-22 13:02:57 [INFO]: Epoch 019 - training loss: 0.1623, validation loss: 0.1342
2024-05-22 13:02:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch19_loss0.1341741770505905.pypots
2024-05-22 13:03:14 [INFO]: Epoch 020 - training loss: 0.1438, validation loss: 0.1360
2024-05-22 13:03:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch20_loss0.13595858514308928.pypots
2024-05-22 13:03:31 [INFO]: Epoch 021 - training loss: 0.1456, validation loss: 0.1383
2024-05-22 13:03:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch21_loss0.13829230964183808.pypots
2024-05-22 13:03:47 [INFO]: Epoch 022 - training loss: 0.1605, validation loss: 0.1314
2024-05-22 13:03:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch22_loss0.13143198266625405.pypots
2024-05-22 13:04:04 [INFO]: Epoch 023 - training loss: 0.1386, validation loss: 0.1319
2024-05-22 13:04:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch23_loss0.13191362470388412.pypots
2024-05-22 13:04:21 [INFO]: Epoch 024 - training loss: 0.1487, validation loss: 0.1354
2024-05-22 13:04:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch24_loss0.1354113422334194.pypots
2024-05-22 13:04:38 [INFO]: Epoch 025 - training loss: 0.1329, validation loss: 0.1319
2024-05-22 13:04:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch25_loss0.13190749585628508.pypots
2024-05-22 13:04:55 [INFO]: Epoch 026 - training loss: 0.1223, validation loss: 0.1270
2024-05-22 13:04:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch26_loss0.1270151898264885.pypots
2024-05-22 13:05:11 [INFO]: Epoch 027 - training loss: 0.1469, validation loss: 0.1303
2024-05-22 13:05:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch27_loss0.13033332005143167.pypots
2024-05-22 13:05:28 [INFO]: Epoch 028 - training loss: 0.1465, validation loss: 0.1306
2024-05-22 13:05:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch28_loss0.130616445094347.pypots
2024-05-22 13:05:45 [INFO]: Epoch 029 - training loss: 0.1317, validation loss: 0.1277
2024-05-22 13:05:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch29_loss0.12768042981624603.pypots
2024-05-22 13:06:02 [INFO]: Epoch 030 - training loss: 0.1233, validation loss: 0.1244
2024-05-22 13:06:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch30_loss0.12443594112992287.pypots
2024-05-22 13:06:19 [INFO]: Epoch 031 - training loss: 0.1415, validation loss: 0.1248
2024-05-22 13:06:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch31_loss0.12478862553834916.pypots
2024-05-22 13:06:35 [INFO]: Epoch 032 - training loss: 0.1417, validation loss: 0.1249
2024-05-22 13:06:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch32_loss0.12494617998600006.pypots
2024-05-22 13:06:52 [INFO]: Epoch 033 - training loss: 0.1384, validation loss: 0.1236
2024-05-22 13:06:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch33_loss0.12363713383674621.pypots
2024-05-22 13:07:09 [INFO]: Epoch 034 - training loss: 0.1366, validation loss: 0.1315
2024-05-22 13:07:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch34_loss0.13153294324874878.pypots
2024-05-22 13:07:26 [INFO]: Epoch 035 - training loss: 0.1299, validation loss: 0.1202
2024-05-22 13:07:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch35_loss0.12015166431665421.pypots
2024-05-22 13:07:43 [INFO]: Epoch 036 - training loss: 0.1395, validation loss: 0.1189
2024-05-22 13:07:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch36_loss0.1189355082809925.pypots
2024-05-22 13:07:59 [INFO]: Epoch 037 - training loss: 0.1242, validation loss: 0.1297
2024-05-22 13:07:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch37_loss0.1297026678919792.pypots
2024-05-22 13:08:16 [INFO]: Epoch 038 - training loss: 0.1399, validation loss: 0.1237
2024-05-22 13:08:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch38_loss0.1237318716943264.pypots
2024-05-22 13:08:33 [INFO]: Epoch 039 - training loss: 0.1188, validation loss: 0.1221
2024-05-22 13:08:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch39_loss0.1220669336616993.pypots
2024-05-22 13:08:50 [INFO]: Epoch 040 - training loss: 0.1323, validation loss: 0.1201
2024-05-22 13:08:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch40_loss0.12013576254248619.pypots
2024-05-22 13:09:06 [INFO]: Epoch 041 - training loss: 0.1395, validation loss: 0.1180
2024-05-22 13:09:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch41_loss0.11797924041748047.pypots
2024-05-22 13:09:23 [INFO]: Epoch 042 - training loss: 0.1117, validation loss: 0.1163
2024-05-22 13:09:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch42_loss0.11627084538340568.pypots
2024-05-22 13:09:40 [INFO]: Epoch 043 - training loss: 0.1314, validation loss: 0.1170
2024-05-22 13:09:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch43_loss0.1169733464717865.pypots
2024-05-22 13:09:57 [INFO]: Epoch 044 - training loss: 0.1289, validation loss: 0.1151
2024-05-22 13:09:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch44_loss0.1150776319205761.pypots
2024-05-22 13:10:14 [INFO]: Epoch 045 - training loss: 0.1251, validation loss: 0.1167
2024-05-22 13:10:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch45_loss0.1166605606675148.pypots
2024-05-22 13:10:30 [INFO]: Epoch 046 - training loss: 0.1262, validation loss: 0.1166
2024-05-22 13:10:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch46_loss0.11661777570843697.pypots
2024-05-22 13:10:47 [INFO]: Epoch 047 - training loss: 0.1297, validation loss: 0.1127
2024-05-22 13:10:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch47_loss0.11267728731036186.pypots
2024-05-22 13:11:04 [INFO]: Epoch 048 - training loss: 0.1186, validation loss: 0.1151
2024-05-22 13:11:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch48_loss0.11506161689758301.pypots
2024-05-22 13:11:21 [INFO]: Epoch 049 - training loss: 0.1209, validation loss: 0.1125
2024-05-22 13:11:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch49_loss0.11250400319695472.pypots
2024-05-22 13:11:38 [INFO]: Epoch 050 - training loss: 0.1233, validation loss: 0.1134
2024-05-22 13:11:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch50_loss0.11341132372617721.pypots
2024-05-22 13:11:54 [INFO]: Epoch 051 - training loss: 0.1181, validation loss: 0.1126
2024-05-22 13:11:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch51_loss0.11262218579649926.pypots
2024-05-22 13:12:11 [INFO]: Epoch 052 - training loss: 0.1212, validation loss: 0.1113
2024-05-22 13:12:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch52_loss0.11125205755233765.pypots
2024-05-22 13:12:28 [INFO]: Epoch 053 - training loss: 0.1297, validation loss: 0.1136
2024-05-22 13:12:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch53_loss0.11362173408269882.pypots
2024-05-22 13:12:45 [INFO]: Epoch 054 - training loss: 0.1288, validation loss: 0.1154
2024-05-22 13:12:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch54_loss0.11543509364128113.pypots
2024-05-22 13:13:01 [INFO]: Epoch 055 - training loss: 0.1200, validation loss: 0.1135
2024-05-22 13:13:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch55_loss0.11345000416040421.pypots
2024-05-22 13:13:18 [INFO]: Epoch 056 - training loss: 0.1471, validation loss: 0.1122
2024-05-22 13:13:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch56_loss0.11215548440814019.pypots
2024-05-22 13:13:35 [INFO]: Epoch 057 - training loss: 0.1247, validation loss: 0.1101
2024-05-22 13:13:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch57_loss0.1101056158542633.pypots
2024-05-22 13:13:52 [INFO]: Epoch 058 - training loss: 0.1332, validation loss: 0.1146
2024-05-22 13:13:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch58_loss0.11462638750672341.pypots
2024-05-22 13:14:09 [INFO]: Epoch 059 - training loss: 0.1166, validation loss: 0.1090
2024-05-22 13:14:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch59_loss0.10903585925698281.pypots
2024-05-22 13:14:26 [INFO]: Epoch 060 - training loss: 0.1113, validation loss: 0.1089
2024-05-22 13:14:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch60_loss0.10887889936566353.pypots
2024-05-22 13:14:42 [INFO]: Epoch 061 - training loss: 0.1145, validation loss: 0.1087
2024-05-22 13:14:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch61_loss0.10866016373038292.pypots
2024-05-22 13:14:59 [INFO]: Epoch 062 - training loss: 0.1164, validation loss: 0.1082
2024-05-22 13:14:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch62_loss0.10823129564523697.pypots
2024-05-22 13:15:16 [INFO]: Epoch 063 - training loss: 0.1104, validation loss: 0.1173
2024-05-22 13:15:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch63_loss0.1173379011452198.pypots
2024-05-22 13:15:33 [INFO]: Epoch 064 - training loss: 0.1247, validation loss: 0.1094
2024-05-22 13:15:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch64_loss0.1093514084815979.pypots
2024-05-22 13:15:49 [INFO]: Epoch 065 - training loss: 0.1152, validation loss: 0.1170
2024-05-22 13:15:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch65_loss0.1169632114470005.pypots
2024-05-22 13:16:06 [INFO]: Epoch 066 - training loss: 0.1276, validation loss: 0.1082
2024-05-22 13:16:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch66_loss0.10824941620230674.pypots
2024-05-22 13:16:23 [INFO]: Epoch 067 - training loss: 0.1217, validation loss: 0.1109
2024-05-22 13:16:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch67_loss0.11091339513659478.pypots
2024-05-22 13:16:40 [INFO]: Epoch 068 - training loss: 0.1179, validation loss: 0.1068
2024-05-22 13:16:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch68_loss0.10680815577507019.pypots
2024-05-22 13:16:57 [INFO]: Epoch 069 - training loss: 0.1239, validation loss: 0.1084
2024-05-22 13:16:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch69_loss0.1084420807659626.pypots
2024-05-22 13:17:13 [INFO]: Epoch 070 - training loss: 0.1261, validation loss: 0.1064
2024-05-22 13:17:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch70_loss0.10636937692761421.pypots
2024-05-22 13:17:30 [INFO]: Epoch 071 - training loss: 0.1099, validation loss: 0.1064
2024-05-22 13:17:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch71_loss0.10642786249518395.pypots
2024-05-22 13:17:47 [INFO]: Epoch 072 - training loss: 0.1174, validation loss: 0.1060
2024-05-22 13:17:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch72_loss0.10597984939813614.pypots
2024-05-22 13:18:04 [INFO]: Epoch 073 - training loss: 0.1217, validation loss: 0.1054
2024-05-22 13:18:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch73_loss0.10543013140559196.pypots
2024-05-22 13:18:21 [INFO]: Epoch 074 - training loss: 0.1057, validation loss: 0.1105
2024-05-22 13:18:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch74_loss0.11050478219985962.pypots
2024-05-22 13:18:37 [INFO]: Epoch 075 - training loss: 0.1126, validation loss: 0.1079
2024-05-22 13:18:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch75_loss0.10789030194282531.pypots
2024-05-22 13:18:54 [INFO]: Epoch 076 - training loss: 0.1170, validation loss: 0.1058
2024-05-22 13:18:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch76_loss0.10576759725809097.pypots
2024-05-22 13:19:11 [INFO]: Epoch 077 - training loss: 0.1182, validation loss: 0.1096
2024-05-22 13:19:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch77_loss0.1096048265695572.pypots
2024-05-22 13:19:28 [INFO]: Epoch 078 - training loss: 0.1167, validation loss: 0.1064
2024-05-22 13:19:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch78_loss0.10635852217674255.pypots
2024-05-22 13:19:45 [INFO]: Epoch 079 - training loss: 0.1184, validation loss: 0.1114
2024-05-22 13:19:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch79_loss0.11135780364274979.pypots
2024-05-22 13:20:01 [INFO]: Epoch 080 - training loss: 0.1221, validation loss: 0.1078
2024-05-22 13:20:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch80_loss0.10776043757796287.pypots
2024-05-22 13:20:18 [INFO]: Epoch 081 - training loss: 0.1196, validation loss: 0.1066
2024-05-22 13:20:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch81_loss0.1065803587436676.pypots
2024-05-22 13:20:35 [INFO]: Epoch 082 - training loss: 0.1214, validation loss: 0.1070
2024-05-22 13:20:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch82_loss0.10703933984041214.pypots
2024-05-22 13:20:52 [INFO]: Epoch 083 - training loss: 0.1186, validation loss: 0.1063
2024-05-22 13:20:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI_epoch83_loss0.10627650395035744.pypots
2024-05-22 13:20:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:20:52 [INFO]: Finished training. The best model is from epoch#73.
2024-05-22 13:20:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_air_quality/20240522_T125738/CSDI.pypots
2024-05-22 13:23:12 [INFO]: CSDI on Air-Quality: MAE=0.1102, MSE=0.2125
2024-05-22 13:23:12 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-22 13:23:12 [INFO]: Using the given device: cuda:0
2024-05-22 13:23:12 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240522_T132312
2024-05-22 13:23:12 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_air_quality/20240522_T132312/tensorboard
2024-05-22 13:23:12 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 13:23:12 [INFO]: Epoch 001 - training loss: 62266.7569, validation loss: 0.6500
2024-05-22 13:23:13 [INFO]: Epoch 002 - training loss: 42014.5511, validation loss: 0.5916
2024-05-22 13:23:13 [INFO]: Epoch 003 - training loss: 41756.8419, validation loss: 0.5585
2024-05-22 13:23:13 [INFO]: Epoch 004 - training loss: 41621.8759, validation loss: 0.4652
2024-05-22 13:23:14 [INFO]: Epoch 005 - training loss: 41556.0787, validation loss: 0.4548
2024-05-22 13:23:14 [INFO]: Epoch 006 - training loss: 41500.5314, validation loss: 0.4226
2024-05-22 13:23:14 [INFO]: Epoch 007 - training loss: 41448.1186, validation loss: 0.3840
2024-05-22 13:23:15 [INFO]: Epoch 008 - training loss: 41412.9878, validation loss: 0.3757
2024-05-22 13:23:15 [INFO]: Epoch 009 - training loss: 41410.3254, validation loss: 0.3701
2024-05-22 13:23:15 [INFO]: Epoch 010 - training loss: 41383.5249, validation loss: 0.3658
2024-05-22 13:23:16 [INFO]: Epoch 011 - training loss: 41373.5971, validation loss: 0.3531
2024-05-22 13:23:16 [INFO]: Epoch 012 - training loss: 41339.1914, validation loss: 0.3439
2024-05-22 13:23:16 [INFO]: Epoch 013 - training loss: 41329.4566, validation loss: 0.3354
2024-05-22 13:23:17 [INFO]: Epoch 014 - training loss: 41361.7024, validation loss: 0.3213
2024-05-22 13:23:17 [INFO]: Epoch 015 - training loss: 41300.8040, validation loss: 0.3096
2024-05-22 13:23:17 [INFO]: Epoch 016 - training loss: 41292.7255, validation loss: 0.3072
2024-05-22 13:23:18 [INFO]: Epoch 017 - training loss: 41279.3487, validation loss: 0.2999
2024-05-22 13:23:18 [INFO]: Epoch 018 - training loss: 41267.6756, validation loss: 0.2905
2024-05-22 13:23:18 [INFO]: Epoch 019 - training loss: 41279.1493, validation loss: 0.2888
2024-05-22 13:23:19 [INFO]: Epoch 020 - training loss: 41256.9319, validation loss: 0.2912
2024-05-22 13:23:19 [INFO]: Epoch 021 - training loss: 41254.6421, validation loss: 0.2874
2024-05-22 13:23:19 [INFO]: Epoch 022 - training loss: 41255.5107, validation loss: 0.3048
2024-05-22 13:23:20 [INFO]: Epoch 023 - training loss: 41256.3708, validation loss: 0.3071
2024-05-22 13:23:20 [INFO]: Epoch 024 - training loss: 41261.2179, validation loss: 0.2877
2024-05-22 13:23:20 [INFO]: Epoch 025 - training loss: 41249.9083, validation loss: 0.2847
2024-05-22 13:23:21 [INFO]: Epoch 026 - training loss: 41278.6725, validation loss: 0.3205
2024-05-22 13:23:21 [INFO]: Epoch 027 - training loss: 41251.7875, validation loss: 0.2815
2024-05-22 13:23:21 [INFO]: Epoch 028 - training loss: 41224.4588, validation loss: 0.2713
2024-05-22 13:23:22 [INFO]: Epoch 029 - training loss: 41208.7344, validation loss: 0.2663
2024-05-22 13:23:22 [INFO]: Epoch 030 - training loss: 41211.6133, validation loss: 0.2867
2024-05-22 13:23:22 [INFO]: Epoch 031 - training loss: 41213.9501, validation loss: 0.2594
2024-05-22 13:23:23 [INFO]: Epoch 032 - training loss: 41220.7283, validation loss: 0.2740
2024-05-22 13:23:23 [INFO]: Epoch 033 - training loss: 41278.9342, validation loss: 0.2854
2024-05-22 13:23:23 [INFO]: Epoch 034 - training loss: 41250.1195, validation loss: 0.2732
2024-05-22 13:23:24 [INFO]: Epoch 035 - training loss: 41231.4359, validation loss: 0.2767
2024-05-22 13:23:24 [INFO]: Epoch 036 - training loss: 41208.4938, validation loss: 0.2719
2024-05-22 13:23:24 [INFO]: Epoch 037 - training loss: 41223.7692, validation loss: 0.2644
2024-05-22 13:23:25 [INFO]: Epoch 038 - training loss: 41200.5745, validation loss: 0.2654
2024-05-22 13:23:25 [INFO]: Epoch 039 - training loss: 41186.9084, validation loss: 0.2524
2024-05-22 13:23:25 [INFO]: Epoch 040 - training loss: 41187.8414, validation loss: 0.2493
2024-05-22 13:23:26 [INFO]: Epoch 041 - training loss: 41178.1473, validation loss: 0.2494
2024-05-22 13:23:26 [INFO]: Epoch 042 - training loss: 41176.3401, validation loss: 0.2553
2024-05-22 13:23:26 [INFO]: Epoch 043 - training loss: 41185.3737, validation loss: 0.2537
2024-05-22 13:23:27 [INFO]: Epoch 044 - training loss: 41190.7556, validation loss: 0.2765
2024-05-22 13:23:27 [INFO]: Epoch 045 - training loss: 41216.8659, validation loss: 0.2772
2024-05-22 13:23:27 [INFO]: Epoch 046 - training loss: 41242.0939, validation loss: 0.2676
2024-05-22 13:23:28 [INFO]: Epoch 047 - training loss: 41200.7650, validation loss: 0.2566
2024-05-22 13:23:28 [INFO]: Epoch 048 - training loss: 41193.6976, validation loss: 0.2554
2024-05-22 13:23:28 [INFO]: Epoch 049 - training loss: 41179.6262, validation loss: 0.2467
2024-05-22 13:23:29 [INFO]: Epoch 050 - training loss: 41168.2076, validation loss: 0.2447
2024-05-22 13:23:29 [INFO]: Epoch 051 - training loss: 41167.7551, validation loss: 0.2476
2024-05-22 13:23:29 [INFO]: Epoch 052 - training loss: 41170.2794, validation loss: 0.2484
2024-05-22 13:23:30 [INFO]: Epoch 053 - training loss: 41174.8653, validation loss: 0.2482
2024-05-22 13:23:30 [INFO]: Epoch 054 - training loss: 41162.3144, validation loss: 0.2438
2024-05-22 13:23:30 [INFO]: Epoch 055 - training loss: 41157.7284, validation loss: 0.2486
2024-05-22 13:23:30 [INFO]: Epoch 056 - training loss: 41155.1866, validation loss: 0.2488
2024-05-22 13:23:31 [INFO]: Epoch 057 - training loss: 41160.8526, validation loss: 0.2489
2024-05-22 13:23:31 [INFO]: Epoch 058 - training loss: 41162.9755, validation loss: 0.2535
2024-05-22 13:23:31 [INFO]: Epoch 059 - training loss: 41156.1739, validation loss: 0.2531
2024-05-22 13:23:32 [INFO]: Epoch 060 - training loss: 41157.9706, validation loss: 0.2549
2024-05-22 13:23:32 [INFO]: Epoch 061 - training loss: 41208.3992, validation loss: 0.3006
2024-05-22 13:23:32 [INFO]: Epoch 062 - training loss: 41261.1100, validation loss: 0.2790
2024-05-22 13:23:33 [INFO]: Epoch 063 - training loss: 41199.8571, validation loss: 0.2467
2024-05-22 13:23:33 [INFO]: Epoch 064 - training loss: 41171.1483, validation loss: 0.2475
2024-05-22 13:23:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:23:33 [INFO]: Finished training. The best model is from epoch#54.
2024-05-22 13:23:33 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_air_quality/20240522_T132312/GPVAE.pypots
2024-05-22 13:23:33 [INFO]: GP-VAE on Air-Quality: MAE=0.2779, MSE=0.2426
2024-05-22 13:23:33 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-22 13:23:33 [INFO]: Using the given device: cuda:0
2024-05-22 13:23:33 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240522_T132333
2024-05-22 13:23:33 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_air_quality/20240522_T132333/tensorboard
2024-05-22 13:23:33 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 13:23:38 [INFO]: Epoch 001 - generator training loss: 0.6081, discriminator training loss: 0.2897, validation loss: 0.5160
2024-05-22 13:23:42 [INFO]: Epoch 002 - generator training loss: 0.2883, discriminator training loss: 0.0681, validation loss: 0.3904
2024-05-22 13:23:46 [INFO]: Epoch 003 - generator training loss: 0.2140, discriminator training loss: 0.0633, validation loss: 0.3240
2024-05-22 13:23:50 [INFO]: Epoch 004 - generator training loss: 0.1780, discriminator training loss: 0.0619, validation loss: 0.2880
2024-05-22 13:23:54 [INFO]: Epoch 005 - generator training loss: 0.1533, discriminator training loss: 0.0612, validation loss: 0.2632
2024-05-22 13:23:58 [INFO]: Epoch 006 - generator training loss: 0.1368, discriminator training loss: 0.0608, validation loss: 0.2455
2024-05-22 13:24:02 [INFO]: Epoch 007 - generator training loss: 0.1226, discriminator training loss: 0.0605, validation loss: 0.2324
2024-05-22 13:24:06 [INFO]: Epoch 008 - generator training loss: 0.1116, discriminator training loss: 0.0604, validation loss: 0.2225
2024-05-22 13:24:10 [INFO]: Epoch 009 - generator training loss: 0.1036, discriminator training loss: 0.0600, validation loss: 0.2146
2024-05-22 13:24:15 [INFO]: Epoch 010 - generator training loss: 0.0984, discriminator training loss: 0.0588, validation loss: 0.2064
2024-05-22 13:24:19 [INFO]: Epoch 011 - generator training loss: 0.0935, discriminator training loss: 0.0572, validation loss: 0.2021
2024-05-22 13:24:23 [INFO]: Epoch 012 - generator training loss: 0.0891, discriminator training loss: 0.0566, validation loss: 0.1965
2024-05-22 13:24:27 [INFO]: Epoch 013 - generator training loss: 0.0860, discriminator training loss: 0.0546, validation loss: 0.1927
2024-05-22 13:24:31 [INFO]: Epoch 014 - generator training loss: 0.0834, discriminator training loss: 0.0535, validation loss: 0.1888
2024-05-22 13:24:35 [INFO]: Epoch 015 - generator training loss: 0.0802, discriminator training loss: 0.0515, validation loss: 0.1863
2024-05-22 13:24:39 [INFO]: Epoch 016 - generator training loss: 0.0801, discriminator training loss: 0.0489, validation loss: 0.1828
2024-05-22 13:24:43 [INFO]: Epoch 017 - generator training loss: 0.0758, discriminator training loss: 0.0485, validation loss: 0.1800
2024-05-22 13:24:47 [INFO]: Epoch 018 - generator training loss: 0.0745, discriminator training loss: 0.0469, validation loss: 0.1779
2024-05-22 13:24:51 [INFO]: Epoch 019 - generator training loss: 0.0727, discriminator training loss: 0.0455, validation loss: 0.1758
2024-05-22 13:24:55 [INFO]: Epoch 020 - generator training loss: 0.0706, discriminator training loss: 0.0452, validation loss: 0.1737
2024-05-22 13:24:59 [INFO]: Epoch 021 - generator training loss: 0.0695, discriminator training loss: 0.0439, validation loss: 0.1714
2024-05-22 13:25:03 [INFO]: Epoch 022 - generator training loss: 0.0676, discriminator training loss: 0.0439, validation loss: 0.1699
2024-05-22 13:25:07 [INFO]: Epoch 023 - generator training loss: 0.0670, discriminator training loss: 0.0430, validation loss: 0.1681
2024-05-22 13:25:11 [INFO]: Epoch 024 - generator training loss: 0.0647, discriminator training loss: 0.0421, validation loss: 0.1670
2024-05-22 13:25:15 [INFO]: Epoch 025 - generator training loss: 0.0667, discriminator training loss: 0.0414, validation loss: 0.1658
2024-05-22 13:25:19 [INFO]: Epoch 026 - generator training loss: 0.0633, discriminator training loss: 0.0405, validation loss: 0.1641
2024-05-22 13:25:23 [INFO]: Epoch 027 - generator training loss: 0.0639, discriminator training loss: 0.0400, validation loss: 0.1633
2024-05-22 13:25:27 [INFO]: Epoch 028 - generator training loss: 0.0618, discriminator training loss: 0.0392, validation loss: 0.1619
2024-05-22 13:25:31 [INFO]: Epoch 029 - generator training loss: 0.0606, discriminator training loss: 0.0381, validation loss: 0.1612
2024-05-22 13:25:35 [INFO]: Epoch 030 - generator training loss: 0.0604, discriminator training loss: 0.0374, validation loss: 0.1604
2024-05-22 13:25:39 [INFO]: Epoch 031 - generator training loss: 0.0601, discriminator training loss: 0.0364, validation loss: 0.1592
2024-05-22 13:25:44 [INFO]: Epoch 032 - generator training loss: 0.0599, discriminator training loss: 0.0357, validation loss: 0.1577
2024-05-22 13:25:48 [INFO]: Epoch 033 - generator training loss: 0.0589, discriminator training loss: 0.0349, validation loss: 0.1570
2024-05-22 13:25:52 [INFO]: Epoch 034 - generator training loss: 0.0585, discriminator training loss: 0.0340, validation loss: 0.1564
2024-05-22 13:25:56 [INFO]: Epoch 035 - generator training loss: 0.0602, discriminator training loss: 0.0331, validation loss: 0.1559
2024-05-22 13:26:00 [INFO]: Epoch 036 - generator training loss: 0.0601, discriminator training loss: 0.0325, validation loss: 0.1550
2024-05-22 13:26:04 [INFO]: Epoch 037 - generator training loss: 0.0571, discriminator training loss: 0.0322, validation loss: 0.1543
2024-05-22 13:26:08 [INFO]: Epoch 038 - generator training loss: 0.0559, discriminator training loss: 0.0313, validation loss: 0.1542
2024-05-22 13:26:12 [INFO]: Epoch 039 - generator training loss: 0.0554, discriminator training loss: 0.0306, validation loss: 0.1539
2024-05-22 13:26:16 [INFO]: Epoch 040 - generator training loss: 0.0551, discriminator training loss: 0.0303, validation loss: 0.1534
2024-05-22 13:26:20 [INFO]: Epoch 041 - generator training loss: 0.0540, discriminator training loss: 0.0296, validation loss: 0.1525
2024-05-22 13:26:24 [INFO]: Epoch 042 - generator training loss: 0.0538, discriminator training loss: 0.0290, validation loss: 0.1521
2024-05-22 13:26:28 [INFO]: Epoch 043 - generator training loss: 0.0557, discriminator training loss: 0.0289, validation loss: 0.1507
2024-05-22 13:26:32 [INFO]: Epoch 044 - generator training loss: 0.0529, discriminator training loss: 0.0281, validation loss: 0.1509
2024-05-22 13:26:36 [INFO]: Epoch 045 - generator training loss: 0.0533, discriminator training loss: 0.0277, validation loss: 0.1496
2024-05-22 13:26:40 [INFO]: Epoch 046 - generator training loss: 0.0522, discriminator training loss: 0.0271, validation loss: 0.1494
2024-05-22 13:26:44 [INFO]: Epoch 047 - generator training loss: 0.0521, discriminator training loss: 0.0265, validation loss: 0.1487
2024-05-22 13:26:48 [INFO]: Epoch 048 - generator training loss: 0.0528, discriminator training loss: 0.0261, validation loss: 0.1481
2024-05-22 13:26:52 [INFO]: Epoch 049 - generator training loss: 0.0520, discriminator training loss: 0.0256, validation loss: 0.1472
2024-05-22 13:26:56 [INFO]: Epoch 050 - generator training loss: 0.0514, discriminator training loss: 0.0251, validation loss: 0.1462
2024-05-22 13:27:00 [INFO]: Epoch 051 - generator training loss: 0.0505, discriminator training loss: 0.0249, validation loss: 0.1462
2024-05-22 13:27:04 [INFO]: Epoch 052 - generator training loss: 0.0512, discriminator training loss: 0.0245, validation loss: 0.1453
2024-05-22 13:27:09 [INFO]: Epoch 053 - generator training loss: 0.0507, discriminator training loss: 0.0239, validation loss: 0.1452
2024-05-22 13:27:13 [INFO]: Epoch 054 - generator training loss: 0.0501, discriminator training loss: 0.0234, validation loss: 0.1445
2024-05-22 13:27:17 [INFO]: Epoch 055 - generator training loss: 0.0491, discriminator training loss: 0.0232, validation loss: 0.1439
2024-05-22 13:27:21 [INFO]: Epoch 056 - generator training loss: 0.0491, discriminator training loss: 0.0230, validation loss: 0.1433
2024-05-22 13:27:25 [INFO]: Epoch 057 - generator training loss: 0.0499, discriminator training loss: 0.0224, validation loss: 0.1431
2024-05-22 13:27:29 [INFO]: Epoch 058 - generator training loss: 0.0493, discriminator training loss: 0.0219, validation loss: 0.1425
2024-05-22 13:27:33 [INFO]: Epoch 059 - generator training loss: 0.0504, discriminator training loss: 0.0219, validation loss: 0.1421
2024-05-22 13:27:37 [INFO]: Epoch 060 - generator training loss: 0.0482, discriminator training loss: 0.0217, validation loss: 0.1425
2024-05-22 13:27:41 [INFO]: Epoch 061 - generator training loss: 0.0478, discriminator training loss: 0.0213, validation loss: 0.1417
2024-05-22 13:27:45 [INFO]: Epoch 062 - generator training loss: 0.0475, discriminator training loss: 0.0209, validation loss: 0.1409
2024-05-22 13:27:49 [INFO]: Epoch 063 - generator training loss: 0.0469, discriminator training loss: 0.0207, validation loss: 0.1403
2024-05-22 13:27:53 [INFO]: Epoch 064 - generator training loss: 0.0466, discriminator training loss: 0.0205, validation loss: 0.1401
2024-05-22 13:27:57 [INFO]: Epoch 065 - generator training loss: 0.0461, discriminator training loss: 0.0202, validation loss: 0.1396
2024-05-22 13:28:01 [INFO]: Epoch 066 - generator training loss: 0.0459, discriminator training loss: 0.0199, validation loss: 0.1392
2024-05-22 13:28:05 [INFO]: Epoch 067 - generator training loss: 0.0460, discriminator training loss: 0.0199, validation loss: 0.1387
2024-05-22 13:28:09 [INFO]: Epoch 068 - generator training loss: 0.0458, discriminator training loss: 0.0194, validation loss: 0.1383
2024-05-22 13:28:13 [INFO]: Epoch 069 - generator training loss: 0.0451, discriminator training loss: 0.0194, validation loss: 0.1382
2024-05-22 13:28:17 [INFO]: Epoch 070 - generator training loss: 0.0456, discriminator training loss: 0.0193, validation loss: 0.1378
2024-05-22 13:28:21 [INFO]: Epoch 071 - generator training loss: 0.0446, discriminator training loss: 0.0188, validation loss: 0.1377
2024-05-22 13:28:25 [INFO]: Epoch 072 - generator training loss: 0.0449, discriminator training loss: 0.0188, validation loss: 0.1376
2024-05-22 13:28:29 [INFO]: Epoch 073 - generator training loss: 0.0445, discriminator training loss: 0.0188, validation loss: 0.1376
2024-05-22 13:28:33 [INFO]: Epoch 074 - generator training loss: 0.0449, discriminator training loss: 0.0185, validation loss: 0.1373
2024-05-22 13:28:37 [INFO]: Epoch 075 - generator training loss: 0.0441, discriminator training loss: 0.0182, validation loss: 0.1365
2024-05-22 13:28:42 [INFO]: Epoch 076 - generator training loss: 0.0439, discriminator training loss: 0.0183, validation loss: 0.1362
2024-05-22 13:28:46 [INFO]: Epoch 077 - generator training loss: 0.0438, discriminator training loss: 0.0180, validation loss: 0.1361
2024-05-22 13:28:50 [INFO]: Epoch 078 - generator training loss: 0.0432, discriminator training loss: 0.0177, validation loss: 0.1361
2024-05-22 13:28:54 [INFO]: Epoch 079 - generator training loss: 0.0428, discriminator training loss: 0.0177, validation loss: 0.1361
2024-05-22 13:28:58 [INFO]: Epoch 080 - generator training loss: 0.0423, discriminator training loss: 0.0175, validation loss: 0.1352
2024-05-22 13:29:02 [INFO]: Epoch 081 - generator training loss: 0.0430, discriminator training loss: 0.0174, validation loss: 0.1359
2024-05-22 13:29:06 [INFO]: Epoch 082 - generator training loss: 0.0422, discriminator training loss: 0.0172, validation loss: 0.1354
2024-05-22 13:29:10 [INFO]: Epoch 083 - generator training loss: 0.0419, discriminator training loss: 0.0171, validation loss: 0.1358
2024-05-22 13:29:14 [INFO]: Epoch 084 - generator training loss: 0.0416, discriminator training loss: 0.0168, validation loss: 0.1353
2024-05-22 13:29:18 [INFO]: Epoch 085 - generator training loss: 0.0422, discriminator training loss: 0.0169, validation loss: 0.1350
2024-05-22 13:29:22 [INFO]: Epoch 086 - generator training loss: 0.0425, discriminator training loss: 0.0166, validation loss: 0.1348
2024-05-22 13:29:26 [INFO]: Epoch 087 - generator training loss: 0.0416, discriminator training loss: 0.0163, validation loss: 0.1344
2024-05-22 13:29:30 [INFO]: Epoch 088 - generator training loss: 0.0413, discriminator training loss: 0.0164, validation loss: 0.1345
2024-05-22 13:29:34 [INFO]: Epoch 089 - generator training loss: 0.0406, discriminator training loss: 0.0164, validation loss: 0.1348
2024-05-22 13:29:38 [INFO]: Epoch 090 - generator training loss: 0.0405, discriminator training loss: 0.0163, validation loss: 0.1340
2024-05-22 13:29:42 [INFO]: Epoch 091 - generator training loss: 0.0403, discriminator training loss: 0.0161, validation loss: 0.1345
2024-05-22 13:29:46 [INFO]: Epoch 092 - generator training loss: 0.0402, discriminator training loss: 0.0161, validation loss: 0.1343
2024-05-22 13:29:50 [INFO]: Epoch 093 - generator training loss: 0.0410, discriminator training loss: 0.0158, validation loss: 0.1339
2024-05-22 13:29:54 [INFO]: Epoch 094 - generator training loss: 0.0405, discriminator training loss: 0.0158, validation loss: 0.1338
2024-05-22 13:29:59 [INFO]: Epoch 095 - generator training loss: 0.0417, discriminator training loss: 0.0157, validation loss: 0.1349
2024-05-22 13:30:03 [INFO]: Epoch 096 - generator training loss: 0.0443, discriminator training loss: 0.0156, validation loss: 0.1348
2024-05-22 13:30:07 [INFO]: Epoch 097 - generator training loss: 0.0415, discriminator training loss: 0.0156, validation loss: 0.1339
2024-05-22 13:30:11 [INFO]: Epoch 098 - generator training loss: 0.0398, discriminator training loss: 0.0153, validation loss: 0.1333
2024-05-22 13:30:15 [INFO]: Epoch 099 - generator training loss: 0.0397, discriminator training loss: 0.0152, validation loss: 0.1336
2024-05-22 13:30:19 [INFO]: Epoch 100 - generator training loss: 0.0386, discriminator training loss: 0.0153, validation loss: 0.1340
2024-05-22 13:30:23 [INFO]: Epoch 101 - generator training loss: 0.0384, discriminator training loss: 0.0151, validation loss: 0.1333
2024-05-22 13:30:27 [INFO]: Epoch 102 - generator training loss: 0.0382, discriminator training loss: 0.0149, validation loss: 0.1336
2024-05-22 13:30:31 [INFO]: Epoch 103 - generator training loss: 0.0382, discriminator training loss: 0.0152, validation loss: 0.1332
2024-05-22 13:30:35 [INFO]: Epoch 104 - generator training loss: 0.0384, discriminator training loss: 0.0148, validation loss: 0.1342
2024-05-22 13:30:39 [INFO]: Epoch 105 - generator training loss: 0.0388, discriminator training loss: 0.0150, validation loss: 0.1337
2024-05-22 13:30:43 [INFO]: Epoch 106 - generator training loss: 0.0381, discriminator training loss: 0.0149, validation loss: 0.1332
2024-05-22 13:30:47 [INFO]: Epoch 107 - generator training loss: 0.0379, discriminator training loss: 0.0148, validation loss: 0.1340
2024-05-22 13:30:51 [INFO]: Epoch 108 - generator training loss: 0.0378, discriminator training loss: 0.0147, validation loss: 0.1340
2024-05-22 13:30:55 [INFO]: Epoch 109 - generator training loss: 0.0368, discriminator training loss: 0.0146, validation loss: 0.1339
2024-05-22 13:30:59 [INFO]: Epoch 110 - generator training loss: 0.0368, discriminator training loss: 0.0146, validation loss: 0.1336
2024-05-22 13:31:03 [INFO]: Epoch 111 - generator training loss: 0.0366, discriminator training loss: 0.0144, validation loss: 0.1331
2024-05-22 13:31:07 [INFO]: Epoch 112 - generator training loss: 0.0369, discriminator training loss: 0.0144, validation loss: 0.1345
2024-05-22 13:31:11 [INFO]: Epoch 113 - generator training loss: 0.0374, discriminator training loss: 0.0143, validation loss: 0.1338
2024-05-22 13:31:16 [INFO]: Epoch 114 - generator training loss: 0.0371, discriminator training loss: 0.0143, validation loss: 0.1330
2024-05-22 13:31:20 [INFO]: Epoch 115 - generator training loss: 0.0363, discriminator training loss: 0.0140, validation loss: 0.1330
2024-05-22 13:31:24 [INFO]: Epoch 116 - generator training loss: 0.0357, discriminator training loss: 0.0141, validation loss: 0.1338
2024-05-22 13:31:28 [INFO]: Epoch 117 - generator training loss: 0.0355, discriminator training loss: 0.0140, validation loss: 0.1332
2024-05-22 13:31:32 [INFO]: Epoch 118 - generator training loss: 0.0354, discriminator training loss: 0.0139, validation loss: 0.1340
2024-05-22 13:31:36 [INFO]: Epoch 119 - generator training loss: 0.0353, discriminator training loss: 0.0138, validation loss: 0.1342
2024-05-22 13:31:40 [INFO]: Epoch 120 - generator training loss: 0.0353, discriminator training loss: 0.0139, validation loss: 0.1330
2024-05-22 13:31:44 [INFO]: Epoch 121 - generator training loss: 0.0349, discriminator training loss: 0.0137, validation loss: 0.1330
2024-05-22 13:31:48 [INFO]: Epoch 122 - generator training loss: 0.0351, discriminator training loss: 0.0137, validation loss: 0.1329
2024-05-22 13:31:52 [INFO]: Epoch 123 - generator training loss: 0.0342, discriminator training loss: 0.0137, validation loss: 0.1327
2024-05-22 13:31:56 [INFO]: Epoch 124 - generator training loss: 0.0345, discriminator training loss: 0.0138, validation loss: 0.1337
2024-05-22 13:32:00 [INFO]: Epoch 125 - generator training loss: 0.0342, discriminator training loss: 0.0137, validation loss: 0.1333
2024-05-22 13:32:04 [INFO]: Epoch 126 - generator training loss: 0.0344, discriminator training loss: 0.0134, validation loss: 0.1348
2024-05-22 13:32:08 [INFO]: Epoch 127 - generator training loss: 0.0357, discriminator training loss: 0.0134, validation loss: 0.1338
2024-05-22 13:32:12 [INFO]: Epoch 128 - generator training loss: 0.0347, discriminator training loss: 0.0134, validation loss: 0.1343
2024-05-22 13:32:16 [INFO]: Epoch 129 - generator training loss: 0.0344, discriminator training loss: 0.0134, validation loss: 0.1337
2024-05-22 13:32:20 [INFO]: Epoch 130 - generator training loss: 0.0338, discriminator training loss: 0.0131, validation loss: 0.1331
2024-05-22 13:32:24 [INFO]: Epoch 131 - generator training loss: 0.0336, discriminator training loss: 0.0132, validation loss: 0.1337
2024-05-22 13:32:28 [INFO]: Epoch 132 - generator training loss: 0.0331, discriminator training loss: 0.0132, validation loss: 0.1341
2024-05-22 13:32:32 [INFO]: Epoch 133 - generator training loss: 0.0328, discriminator training loss: 0.0133, validation loss: 0.1338
2024-05-22 13:32:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:32:32 [INFO]: Finished training. The best model is from epoch#123.
2024-05-22 13:32:32 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_air_quality/20240522_T132333/USGAN.pypots
2024-05-22 13:32:33 [INFO]: US-GAN on Air-Quality: MAE=0.1748, MSE=0.1278
2024-05-22 13:32:33 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-22 13:32:33 [INFO]: Using the given device: cuda:0
2024-05-22 13:32:33 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240522_T133233
2024-05-22 13:32:33 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_air_quality/20240522_T133233/tensorboard
2024-05-22 13:32:33 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 13:32:37 [INFO]: Epoch 001 - training loss: 1.4138, validation loss: 0.9406
2024-05-22 13:32:40 [INFO]: Epoch 002 - training loss: 1.1334, validation loss: 0.6977
2024-05-22 13:32:43 [INFO]: Epoch 003 - training loss: 0.9423, validation loss: 0.5889
2024-05-22 13:32:45 [INFO]: Epoch 004 - training loss: 0.8351, validation loss: 0.5216
2024-05-22 13:32:48 [INFO]: Epoch 005 - training loss: 0.7591, validation loss: 0.4759
2024-05-22 13:32:51 [INFO]: Epoch 006 - training loss: 0.7033, validation loss: 0.4400
2024-05-22 13:32:54 [INFO]: Epoch 007 - training loss: 0.6596, validation loss: 0.4109
2024-05-22 13:32:56 [INFO]: Epoch 008 - training loss: 0.6250, validation loss: 0.3877
2024-05-22 13:32:59 [INFO]: Epoch 009 - training loss: 0.5984, validation loss: 0.3681
2024-05-22 13:33:02 [INFO]: Epoch 010 - training loss: 0.5756, validation loss: 0.3527
2024-05-22 13:33:05 [INFO]: Epoch 011 - training loss: 0.5590, validation loss: 0.3392
2024-05-22 13:33:07 [INFO]: Epoch 012 - training loss: 0.5443, validation loss: 0.3283
2024-05-22 13:33:10 [INFO]: Epoch 013 - training loss: 0.5306, validation loss: 0.3176
2024-05-22 13:33:13 [INFO]: Epoch 014 - training loss: 0.5173, validation loss: 0.3087
2024-05-22 13:33:16 [INFO]: Epoch 015 - training loss: 0.5061, validation loss: 0.3014
2024-05-22 13:33:18 [INFO]: Epoch 016 - training loss: 0.4973, validation loss: 0.2953
2024-05-22 13:33:21 [INFO]: Epoch 017 - training loss: 0.4882, validation loss: 0.2887
2024-05-22 13:33:24 [INFO]: Epoch 018 - training loss: 0.4805, validation loss: 0.2832
2024-05-22 13:33:27 [INFO]: Epoch 019 - training loss: 0.4721, validation loss: 0.2776
2024-05-22 13:33:29 [INFO]: Epoch 020 - training loss: 0.4640, validation loss: 0.2732
2024-05-22 13:33:32 [INFO]: Epoch 021 - training loss: 0.4574, validation loss: 0.2686
2024-05-22 13:33:35 [INFO]: Epoch 022 - training loss: 0.4512, validation loss: 0.2645
2024-05-22 13:33:37 [INFO]: Epoch 023 - training loss: 0.4448, validation loss: 0.2605
2024-05-22 13:33:40 [INFO]: Epoch 024 - training loss: 0.4388, validation loss: 0.2569
2024-05-22 13:33:43 [INFO]: Epoch 025 - training loss: 0.4322, validation loss: 0.2534
2024-05-22 13:33:46 [INFO]: Epoch 026 - training loss: 0.4276, validation loss: 0.2503
2024-05-22 13:33:48 [INFO]: Epoch 027 - training loss: 0.4214, validation loss: 0.2468
2024-05-22 13:33:51 [INFO]: Epoch 028 - training loss: 0.4168, validation loss: 0.2435
2024-05-22 13:33:54 [INFO]: Epoch 029 - training loss: 0.4122, validation loss: 0.2405
2024-05-22 13:33:57 [INFO]: Epoch 030 - training loss: 0.4065, validation loss: 0.2375
2024-05-22 13:33:59 [INFO]: Epoch 031 - training loss: 0.4026, validation loss: 0.2345
2024-05-22 13:34:02 [INFO]: Epoch 032 - training loss: 0.3983, validation loss: 0.2321
2024-05-22 13:34:05 [INFO]: Epoch 033 - training loss: 0.3943, validation loss: 0.2294
2024-05-22 13:34:07 [INFO]: Epoch 034 - training loss: 0.3900, validation loss: 0.2266
2024-05-22 13:34:10 [INFO]: Epoch 035 - training loss: 0.3860, validation loss: 0.2241
2024-05-22 13:34:13 [INFO]: Epoch 036 - training loss: 0.3834, validation loss: 0.2217
2024-05-22 13:34:16 [INFO]: Epoch 037 - training loss: 0.3790, validation loss: 0.2194
2024-05-22 13:34:18 [INFO]: Epoch 038 - training loss: 0.3751, validation loss: 0.2171
2024-05-22 13:34:21 [INFO]: Epoch 039 - training loss: 0.3721, validation loss: 0.2147
2024-05-22 13:34:24 [INFO]: Epoch 040 - training loss: 0.3677, validation loss: 0.2123
2024-05-22 13:34:27 [INFO]: Epoch 041 - training loss: 0.3644, validation loss: 0.2106
2024-05-22 13:34:29 [INFO]: Epoch 042 - training loss: 0.3615, validation loss: 0.2087
2024-05-22 13:34:32 [INFO]: Epoch 043 - training loss: 0.3587, validation loss: 0.2066
2024-05-22 13:34:35 [INFO]: Epoch 044 - training loss: 0.3555, validation loss: 0.2045
2024-05-22 13:34:38 [INFO]: Epoch 045 - training loss: 0.3534, validation loss: 0.2027
2024-05-22 13:34:40 [INFO]: Epoch 046 - training loss: 0.3506, validation loss: 0.2009
2024-05-22 13:34:43 [INFO]: Epoch 047 - training loss: 0.3480, validation loss: 0.1994
2024-05-22 13:34:46 [INFO]: Epoch 048 - training loss: 0.3458, validation loss: 0.1976
2024-05-22 13:34:49 [INFO]: Epoch 049 - training loss: 0.3433, validation loss: 0.1962
2024-05-22 13:34:51 [INFO]: Epoch 050 - training loss: 0.3400, validation loss: 0.1948
2024-05-22 13:34:54 [INFO]: Epoch 051 - training loss: 0.3375, validation loss: 0.1935
2024-05-22 13:34:57 [INFO]: Epoch 052 - training loss: 0.3361, validation loss: 0.1922
2024-05-22 13:34:59 [INFO]: Epoch 053 - training loss: 0.3335, validation loss: 0.1910
2024-05-22 13:35:02 [INFO]: Epoch 054 - training loss: 0.3324, validation loss: 0.1900
2024-05-22 13:35:05 [INFO]: Epoch 055 - training loss: 0.3300, validation loss: 0.1891
2024-05-22 13:35:08 [INFO]: Epoch 056 - training loss: 0.3276, validation loss: 0.1882
2024-05-22 13:35:10 [INFO]: Epoch 057 - training loss: 0.3257, validation loss: 0.1875
2024-05-22 13:35:13 [INFO]: Epoch 058 - training loss: 0.3249, validation loss: 0.1865
2024-05-22 13:35:16 [INFO]: Epoch 059 - training loss: 0.3215, validation loss: 0.1857
2024-05-22 13:35:19 [INFO]: Epoch 060 - training loss: 0.3204, validation loss: 0.1851
2024-05-22 13:35:21 [INFO]: Epoch 061 - training loss: 0.3182, validation loss: 0.1843
2024-05-22 13:35:24 [INFO]: Epoch 062 - training loss: 0.3164, validation loss: 0.1838
2024-05-22 13:35:27 [INFO]: Epoch 063 - training loss: 0.3150, validation loss: 0.1832
2024-05-22 13:35:30 [INFO]: Epoch 064 - training loss: 0.3142, validation loss: 0.1826
2024-05-22 13:35:32 [INFO]: Epoch 065 - training loss: 0.3126, validation loss: 0.1822
2024-05-22 13:35:35 [INFO]: Epoch 066 - training loss: 0.3111, validation loss: 0.1815
2024-05-22 13:35:38 [INFO]: Epoch 067 - training loss: 0.3091, validation loss: 0.1810
2024-05-22 13:35:40 [INFO]: Epoch 068 - training loss: 0.3077, validation loss: 0.1805
2024-05-22 13:35:43 [INFO]: Epoch 069 - training loss: 0.3072, validation loss: 0.1797
2024-05-22 13:35:46 [INFO]: Epoch 070 - training loss: 0.3056, validation loss: 0.1793
2024-05-22 13:35:49 [INFO]: Epoch 071 - training loss: 0.3044, validation loss: 0.1789
2024-05-22 13:35:51 [INFO]: Epoch 072 - training loss: 0.3032, validation loss: 0.1784
2024-05-22 13:35:54 [INFO]: Epoch 073 - training loss: 0.3025, validation loss: 0.1780
2024-05-22 13:35:57 [INFO]: Epoch 074 - training loss: 0.3011, validation loss: 0.1777
2024-05-22 13:36:00 [INFO]: Epoch 075 - training loss: 0.3000, validation loss: 0.1771
2024-05-22 13:36:02 [INFO]: Epoch 076 - training loss: 0.2987, validation loss: 0.1765
2024-05-22 13:36:05 [INFO]: Epoch 077 - training loss: 0.2982, validation loss: 0.1759
2024-05-22 13:36:08 [INFO]: Epoch 078 - training loss: 0.2970, validation loss: 0.1754
2024-05-22 13:36:10 [INFO]: Epoch 079 - training loss: 0.2967, validation loss: 0.1754
2024-05-22 13:36:13 [INFO]: Epoch 080 - training loss: 0.2954, validation loss: 0.1745
2024-05-22 13:36:16 [INFO]: Epoch 081 - training loss: 0.2943, validation loss: 0.1741
2024-05-22 13:36:19 [INFO]: Epoch 082 - training loss: 0.2938, validation loss: 0.1737
2024-05-22 13:36:21 [INFO]: Epoch 083 - training loss: 0.2928, validation loss: 0.1734
2024-05-22 13:36:24 [INFO]: Epoch 084 - training loss: 0.2919, validation loss: 0.1728
2024-05-22 13:36:27 [INFO]: Epoch 085 - training loss: 0.2912, validation loss: 0.1725
2024-05-22 13:36:30 [INFO]: Epoch 086 - training loss: 0.2897, validation loss: 0.1719
2024-05-22 13:36:32 [INFO]: Epoch 087 - training loss: 0.2893, validation loss: 0.1714
2024-05-22 13:36:35 [INFO]: Epoch 088 - training loss: 0.2886, validation loss: 0.1711
2024-05-22 13:36:38 [INFO]: Epoch 089 - training loss: 0.2878, validation loss: 0.1705
2024-05-22 13:36:41 [INFO]: Epoch 090 - training loss: 0.2868, validation loss: 0.1703
2024-05-22 13:36:43 [INFO]: Epoch 091 - training loss: 0.2858, validation loss: 0.1696
2024-05-22 13:36:46 [INFO]: Epoch 092 - training loss: 0.2849, validation loss: 0.1692
2024-05-22 13:36:49 [INFO]: Epoch 093 - training loss: 0.2846, validation loss: 0.1690
2024-05-22 13:36:51 [INFO]: Epoch 094 - training loss: 0.2841, validation loss: 0.1685
2024-05-22 13:36:54 [INFO]: Epoch 095 - training loss: 0.2834, validation loss: 0.1681
2024-05-22 13:36:57 [INFO]: Epoch 096 - training loss: 0.2825, validation loss: 0.1677
2024-05-22 13:37:00 [INFO]: Epoch 097 - training loss: 0.2824, validation loss: 0.1673
2024-05-22 13:37:02 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.1669
2024-05-22 13:37:05 [INFO]: Epoch 099 - training loss: 0.2801, validation loss: 0.1665
2024-05-22 13:37:08 [INFO]: Epoch 100 - training loss: 0.2802, validation loss: 0.1659
2024-05-22 13:37:11 [INFO]: Epoch 101 - training loss: 0.2796, validation loss: 0.1656
2024-05-22 13:37:13 [INFO]: Epoch 102 - training loss: 0.2784, validation loss: 0.1649
2024-05-22 13:37:16 [INFO]: Epoch 103 - training loss: 0.2779, validation loss: 0.1645
2024-05-22 13:37:19 [INFO]: Epoch 104 - training loss: 0.2775, validation loss: 0.1641
2024-05-22 13:37:21 [INFO]: Epoch 105 - training loss: 0.2768, validation loss: 0.1637
2024-05-22 13:37:24 [INFO]: Epoch 106 - training loss: 0.2762, validation loss: 0.1633
2024-05-22 13:37:27 [INFO]: Epoch 107 - training loss: 0.2757, validation loss: 0.1629
2024-05-22 13:37:30 [INFO]: Epoch 108 - training loss: 0.2751, validation loss: 0.1624
2024-05-22 13:37:32 [INFO]: Epoch 109 - training loss: 0.2742, validation loss: 0.1618
2024-05-22 13:37:35 [INFO]: Epoch 110 - training loss: 0.2740, validation loss: 0.1615
2024-05-22 13:37:38 [INFO]: Epoch 111 - training loss: 0.2730, validation loss: 0.1610
2024-05-22 13:37:40 [INFO]: Epoch 112 - training loss: 0.2735, validation loss: 0.1607
2024-05-22 13:37:43 [INFO]: Epoch 113 - training loss: 0.2723, validation loss: 0.1605
2024-05-22 13:37:46 [INFO]: Epoch 114 - training loss: 0.2720, validation loss: 0.1598
2024-05-22 13:37:49 [INFO]: Epoch 115 - training loss: 0.2716, validation loss: 0.1594
2024-05-22 13:37:51 [INFO]: Epoch 116 - training loss: 0.2712, validation loss: 0.1592
2024-05-22 13:37:54 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1586
2024-05-22 13:37:57 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1583
2024-05-22 13:38:00 [INFO]: Epoch 119 - training loss: 0.2704, validation loss: 0.1578
2024-05-22 13:38:02 [INFO]: Epoch 120 - training loss: 0.2689, validation loss: 0.1575
2024-05-22 13:38:05 [INFO]: Epoch 121 - training loss: 0.2686, validation loss: 0.1571
2024-05-22 13:38:08 [INFO]: Epoch 122 - training loss: 0.2682, validation loss: 0.1569
2024-05-22 13:38:10 [INFO]: Epoch 123 - training loss: 0.2678, validation loss: 0.1565
2024-05-22 13:38:13 [INFO]: Epoch 124 - training loss: 0.2671, validation loss: 0.1562
2024-05-22 13:38:16 [INFO]: Epoch 125 - training loss: 0.2666, validation loss: 0.1558
2024-05-22 13:38:19 [INFO]: Epoch 126 - training loss: 0.2659, validation loss: 0.1555
2024-05-22 13:38:21 [INFO]: Epoch 127 - training loss: 0.2662, validation loss: 0.1550
2024-05-22 13:38:24 [INFO]: Epoch 128 - training loss: 0.2652, validation loss: 0.1547
2024-05-22 13:38:27 [INFO]: Epoch 129 - training loss: 0.2649, validation loss: 0.1544
2024-05-22 13:38:30 [INFO]: Epoch 130 - training loss: 0.2639, validation loss: 0.1540
2024-05-22 13:38:32 [INFO]: Epoch 131 - training loss: 0.2635, validation loss: 0.1540
2024-05-22 13:38:35 [INFO]: Epoch 132 - training loss: 0.2633, validation loss: 0.1536
2024-05-22 13:38:38 [INFO]: Epoch 133 - training loss: 0.2629, validation loss: 0.1532
2024-05-22 13:38:40 [INFO]: Epoch 134 - training loss: 0.2624, validation loss: 0.1530
2024-05-22 13:38:43 [INFO]: Epoch 135 - training loss: 0.2626, validation loss: 0.1525
2024-05-22 13:38:46 [INFO]: Epoch 136 - training loss: 0.2621, validation loss: 0.1523
2024-05-22 13:38:49 [INFO]: Epoch 137 - training loss: 0.2613, validation loss: 0.1519
2024-05-22 13:38:51 [INFO]: Epoch 138 - training loss: 0.2610, validation loss: 0.1515
2024-05-22 13:38:54 [INFO]: Epoch 139 - training loss: 0.2606, validation loss: 0.1513
2024-05-22 13:38:57 [INFO]: Epoch 140 - training loss: 0.2604, validation loss: 0.1511
2024-05-22 13:39:00 [INFO]: Epoch 141 - training loss: 0.2603, validation loss: 0.1507
2024-05-22 13:39:02 [INFO]: Epoch 142 - training loss: 0.2600, validation loss: 0.1504
2024-05-22 13:39:05 [INFO]: Epoch 143 - training loss: 0.2591, validation loss: 0.1501
2024-05-22 13:39:08 [INFO]: Epoch 144 - training loss: 0.2590, validation loss: 0.1499
2024-05-22 13:39:11 [INFO]: Epoch 145 - training loss: 0.2589, validation loss: 0.1496
2024-05-22 13:39:14 [INFO]: Epoch 146 - training loss: 0.2581, validation loss: 0.1492
2024-05-22 13:39:16 [INFO]: Epoch 147 - training loss: 0.2577, validation loss: 0.1487
2024-05-22 13:39:19 [INFO]: Epoch 148 - training loss: 0.2570, validation loss: 0.1488
2024-05-22 13:39:22 [INFO]: Epoch 149 - training loss: 0.2576, validation loss: 0.1485
2024-05-22 13:39:25 [INFO]: Epoch 150 - training loss: 0.2573, validation loss: 0.1482
2024-05-22 13:39:28 [INFO]: Epoch 151 - training loss: 0.2564, validation loss: 0.1479
2024-05-22 13:39:30 [INFO]: Epoch 152 - training loss: 0.2564, validation loss: 0.1476
2024-05-22 13:39:33 [INFO]: Epoch 153 - training loss: 0.2564, validation loss: 0.1475
2024-05-22 13:39:36 [INFO]: Epoch 154 - training loss: 0.2555, validation loss: 0.1471
2024-05-22 13:39:38 [INFO]: Epoch 155 - training loss: 0.2550, validation loss: 0.1470
2024-05-22 13:39:41 [INFO]: Epoch 156 - training loss: 0.2554, validation loss: 0.1468
2024-05-22 13:39:44 [INFO]: Epoch 157 - training loss: 0.2546, validation loss: 0.1464
2024-05-22 13:39:47 [INFO]: Epoch 158 - training loss: 0.2540, validation loss: 0.1462
2024-05-22 13:39:49 [INFO]: Epoch 159 - training loss: 0.2537, validation loss: 0.1458
2024-05-22 13:39:52 [INFO]: Epoch 160 - training loss: 0.2533, validation loss: 0.1458
2024-05-22 13:39:55 [INFO]: Epoch 161 - training loss: 0.2532, validation loss: 0.1454
2024-05-22 13:39:58 [INFO]: Epoch 162 - training loss: 0.2525, validation loss: 0.1453
2024-05-22 13:40:00 [INFO]: Epoch 163 - training loss: 0.2526, validation loss: 0.1450
2024-05-22 13:40:03 [INFO]: Epoch 164 - training loss: 0.2526, validation loss: 0.1447
2024-05-22 13:40:06 [INFO]: Epoch 165 - training loss: 0.2523, validation loss: 0.1448
2024-05-22 13:40:09 [INFO]: Epoch 166 - training loss: 0.2515, validation loss: 0.1443
2024-05-22 13:40:11 [INFO]: Epoch 167 - training loss: 0.2519, validation loss: 0.1444
2024-05-22 13:40:14 [INFO]: Epoch 168 - training loss: 0.2512, validation loss: 0.1440
2024-05-22 13:40:17 [INFO]: Epoch 169 - training loss: 0.2512, validation loss: 0.1439
2024-05-22 13:40:19 [INFO]: Epoch 170 - training loss: 0.2510, validation loss: 0.1437
2024-05-22 13:40:22 [INFO]: Epoch 171 - training loss: 0.2506, validation loss: 0.1435
2024-05-22 13:40:25 [INFO]: Epoch 172 - training loss: 0.2505, validation loss: 0.1430
2024-05-22 13:40:28 [INFO]: Epoch 173 - training loss: 0.2498, validation loss: 0.1429
2024-05-22 13:40:31 [INFO]: Epoch 174 - training loss: 0.2496, validation loss: 0.1428
2024-05-22 13:40:33 [INFO]: Epoch 175 - training loss: 0.2498, validation loss: 0.1426
2024-05-22 13:40:36 [INFO]: Epoch 176 - training loss: 0.2488, validation loss: 0.1424
2024-05-22 13:40:39 [INFO]: Epoch 177 - training loss: 0.2489, validation loss: 0.1421
2024-05-22 13:40:41 [INFO]: Epoch 178 - training loss: 0.2489, validation loss: 0.1421
2024-05-22 13:40:44 [INFO]: Epoch 179 - training loss: 0.2483, validation loss: 0.1419
2024-05-22 13:40:47 [INFO]: Epoch 180 - training loss: 0.2480, validation loss: 0.1417
2024-05-22 13:40:50 [INFO]: Epoch 181 - training loss: 0.2481, validation loss: 0.1414
2024-05-22 13:40:52 [INFO]: Epoch 182 - training loss: 0.2479, validation loss: 0.1413
2024-05-22 13:40:55 [INFO]: Epoch 183 - training loss: 0.2477, validation loss: 0.1410
2024-05-22 13:40:58 [INFO]: Epoch 184 - training loss: 0.2470, validation loss: 0.1408
2024-05-22 13:41:01 [INFO]: Epoch 185 - training loss: 0.2473, validation loss: 0.1408
2024-05-22 13:41:03 [INFO]: Epoch 186 - training loss: 0.2470, validation loss: 0.1404
2024-05-22 13:41:06 [INFO]: Epoch 187 - training loss: 0.2464, validation loss: 0.1404
2024-05-22 13:41:09 [INFO]: Epoch 188 - training loss: 0.2466, validation loss: 0.1403
2024-05-22 13:41:12 [INFO]: Epoch 189 - training loss: 0.2464, validation loss: 0.1402
2024-05-22 13:41:14 [INFO]: Epoch 190 - training loss: 0.2461, validation loss: 0.1398
2024-05-22 13:41:17 [INFO]: Epoch 191 - training loss: 0.2456, validation loss: 0.1397
2024-05-22 13:41:20 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1396
2024-05-22 13:41:22 [INFO]: Epoch 193 - training loss: 0.2449, validation loss: 0.1395
2024-05-22 13:41:25 [INFO]: Epoch 194 - training loss: 0.2451, validation loss: 0.1393
2024-05-22 13:41:28 [INFO]: Epoch 195 - training loss: 0.2445, validation loss: 0.1391
2024-05-22 13:41:31 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1389
2024-05-22 13:41:33 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.1386
2024-05-22 13:41:36 [INFO]: Epoch 198 - training loss: 0.2443, validation loss: 0.1385
2024-05-22 13:41:39 [INFO]: Epoch 199 - training loss: 0.2442, validation loss: 0.1385
2024-05-22 13:41:42 [INFO]: Epoch 200 - training loss: 0.2437, validation loss: 0.1382
2024-05-22 13:41:44 [INFO]: Epoch 201 - training loss: 0.2443, validation loss: 0.1383
2024-05-22 13:41:47 [INFO]: Epoch 202 - training loss: 0.2435, validation loss: 0.1380
2024-05-22 13:41:50 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.1378
2024-05-22 13:41:52 [INFO]: Epoch 204 - training loss: 0.2435, validation loss: 0.1377
2024-05-22 13:41:55 [INFO]: Epoch 205 - training loss: 0.2426, validation loss: 0.1375
2024-05-22 13:41:58 [INFO]: Epoch 206 - training loss: 0.2432, validation loss: 0.1374
2024-05-22 13:42:01 [INFO]: Epoch 207 - training loss: 0.2427, validation loss: 0.1372
2024-05-22 13:42:03 [INFO]: Epoch 208 - training loss: 0.2423, validation loss: 0.1372
2024-05-22 13:42:06 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.1371
2024-05-22 13:42:09 [INFO]: Epoch 210 - training loss: 0.2415, validation loss: 0.1367
2024-05-22 13:42:12 [INFO]: Epoch 211 - training loss: 0.2415, validation loss: 0.1369
2024-05-22 13:42:14 [INFO]: Epoch 212 - training loss: 0.2417, validation loss: 0.1366
2024-05-22 13:42:17 [INFO]: Epoch 213 - training loss: 0.2411, validation loss: 0.1365
2024-05-22 13:42:20 [INFO]: Epoch 214 - training loss: 0.2415, validation loss: 0.1364
2024-05-22 13:42:23 [INFO]: Epoch 215 - training loss: 0.2413, validation loss: 0.1362
2024-05-22 13:42:25 [INFO]: Epoch 216 - training loss: 0.2414, validation loss: 0.1360
2024-05-22 13:42:28 [INFO]: Epoch 217 - training loss: 0.2405, validation loss: 0.1358
2024-05-22 13:42:31 [INFO]: Epoch 218 - training loss: 0.2404, validation loss: 0.1357
2024-05-22 13:42:34 [INFO]: Epoch 219 - training loss: 0.2402, validation loss: 0.1356
2024-05-22 13:42:36 [INFO]: Epoch 220 - training loss: 0.2403, validation loss: 0.1355
2024-05-22 13:42:39 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1355
2024-05-22 13:42:42 [INFO]: Epoch 222 - training loss: 0.2396, validation loss: 0.1355
2024-05-22 13:42:45 [INFO]: Epoch 223 - training loss: 0.2397, validation loss: 0.1351
2024-05-22 13:42:47 [INFO]: Epoch 224 - training loss: 0.2392, validation loss: 0.1351
2024-05-22 13:42:50 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.1350
2024-05-22 13:42:53 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.1348
2024-05-22 13:42:55 [INFO]: Epoch 227 - training loss: 0.2393, validation loss: 0.1347
2024-05-22 13:42:58 [INFO]: Epoch 228 - training loss: 0.2391, validation loss: 0.1346
2024-05-22 13:43:01 [INFO]: Epoch 229 - training loss: 0.2386, validation loss: 0.1344
2024-05-22 13:43:04 [INFO]: Epoch 230 - training loss: 0.2389, validation loss: 0.1344
2024-05-22 13:43:06 [INFO]: Epoch 231 - training loss: 0.2382, validation loss: 0.1342
2024-05-22 13:43:09 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.1342
2024-05-22 13:43:12 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1341
2024-05-22 13:43:15 [INFO]: Epoch 234 - training loss: 0.2387, validation loss: 0.1339
2024-05-22 13:43:17 [INFO]: Epoch 235 - training loss: 0.2378, validation loss: 0.1338
2024-05-22 13:43:20 [INFO]: Epoch 236 - training loss: 0.2374, validation loss: 0.1338
2024-05-22 13:43:23 [INFO]: Epoch 237 - training loss: 0.2372, validation loss: 0.1336
2024-05-22 13:43:26 [INFO]: Epoch 238 - training loss: 0.2377, validation loss: 0.1336
2024-05-22 13:43:28 [INFO]: Epoch 239 - training loss: 0.2373, validation loss: 0.1335
2024-05-22 13:43:31 [INFO]: Epoch 240 - training loss: 0.2369, validation loss: 0.1333
2024-05-22 13:43:34 [INFO]: Epoch 241 - training loss: 0.2370, validation loss: 0.1333
2024-05-22 13:43:36 [INFO]: Epoch 242 - training loss: 0.2374, validation loss: 0.1333
2024-05-22 13:43:39 [INFO]: Epoch 243 - training loss: 0.2366, validation loss: 0.1332
2024-05-22 13:43:42 [INFO]: Epoch 244 - training loss: 0.2361, validation loss: 0.1328
2024-05-22 13:43:45 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1329
2024-05-22 13:43:47 [INFO]: Epoch 246 - training loss: 0.2360, validation loss: 0.1328
2024-05-22 13:43:50 [INFO]: Epoch 247 - training loss: 0.2355, validation loss: 0.1326
2024-05-22 13:43:53 [INFO]: Epoch 248 - training loss: 0.2359, validation loss: 0.1326
2024-05-22 13:43:56 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1325
2024-05-22 13:43:58 [INFO]: Epoch 250 - training loss: 0.2356, validation loss: 0.1326
2024-05-22 13:44:01 [INFO]: Epoch 251 - training loss: 0.2354, validation loss: 0.1325
2024-05-22 13:44:04 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.1323
2024-05-22 13:44:07 [INFO]: Epoch 253 - training loss: 0.2350, validation loss: 0.1322
2024-05-22 13:44:09 [INFO]: Epoch 254 - training loss: 0.2350, validation loss: 0.1320
2024-05-22 13:44:12 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.1319
2024-05-22 13:44:15 [INFO]: Epoch 256 - training loss: 0.2345, validation loss: 0.1319
2024-05-22 13:44:17 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1319
2024-05-22 13:44:20 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.1317
2024-05-22 13:44:23 [INFO]: Epoch 259 - training loss: 0.2344, validation loss: 0.1316
2024-05-22 13:44:26 [INFO]: Epoch 260 - training loss: 0.2342, validation loss: 0.1318
2024-05-22 13:44:28 [INFO]: Epoch 261 - training loss: 0.2340, validation loss: 0.1316
2024-05-22 13:44:31 [INFO]: Epoch 262 - training loss: 0.2335, validation loss: 0.1317
2024-05-22 13:44:34 [INFO]: Epoch 263 - training loss: 0.2336, validation loss: 0.1316
2024-05-22 13:44:37 [INFO]: Epoch 264 - training loss: 0.2333, validation loss: 0.1314
2024-05-22 13:44:39 [INFO]: Epoch 265 - training loss: 0.2335, validation loss: 0.1314
2024-05-22 13:44:42 [INFO]: Epoch 266 - training loss: 0.2335, validation loss: 0.1312
2024-05-22 13:44:45 [INFO]: Epoch 267 - training loss: 0.2331, validation loss: 0.1311
2024-05-22 13:44:48 [INFO]: Epoch 268 - training loss: 0.2330, validation loss: 0.1311
2024-05-22 13:44:50 [INFO]: Epoch 269 - training loss: 0.2330, validation loss: 0.1310
2024-05-22 13:44:53 [INFO]: Epoch 270 - training loss: 0.2329, validation loss: 0.1309
2024-05-22 13:44:56 [INFO]: Epoch 271 - training loss: 0.2337, validation loss: 0.1309
2024-05-22 13:44:59 [INFO]: Epoch 272 - training loss: 0.2326, validation loss: 0.1307
2024-05-22 13:45:01 [INFO]: Epoch 273 - training loss: 0.2324, validation loss: 0.1306
2024-05-22 13:45:04 [INFO]: Epoch 274 - training loss: 0.2327, validation loss: 0.1305
2024-05-22 13:45:07 [INFO]: Epoch 275 - training loss: 0.2322, validation loss: 0.1304
2024-05-22 13:45:09 [INFO]: Epoch 276 - training loss: 0.2322, validation loss: 0.1305
2024-05-22 13:45:12 [INFO]: Epoch 277 - training loss: 0.2324, validation loss: 0.1305
2024-05-22 13:45:15 [INFO]: Epoch 278 - training loss: 0.2319, validation loss: 0.1303
2024-05-22 13:45:18 [INFO]: Epoch 279 - training loss: 0.2318, validation loss: 0.1301
2024-05-22 13:45:20 [INFO]: Epoch 280 - training loss: 0.2317, validation loss: 0.1303
2024-05-22 13:45:23 [INFO]: Epoch 281 - training loss: 0.2317, validation loss: 0.1301
2024-05-22 13:45:26 [INFO]: Epoch 282 - training loss: 0.2314, validation loss: 0.1300
2024-05-22 13:45:29 [INFO]: Epoch 283 - training loss: 0.2320, validation loss: 0.1302
2024-05-22 13:45:31 [INFO]: Epoch 284 - training loss: 0.2313, validation loss: 0.1299
2024-05-22 13:45:34 [INFO]: Epoch 285 - training loss: 0.2315, validation loss: 0.1299
2024-05-22 13:45:37 [INFO]: Epoch 286 - training loss: 0.2306, validation loss: 0.1299
2024-05-22 13:45:40 [INFO]: Epoch 287 - training loss: 0.2309, validation loss: 0.1299
2024-05-22 13:45:42 [INFO]: Epoch 288 - training loss: 0.2310, validation loss: 0.1296
2024-05-22 13:45:45 [INFO]: Epoch 289 - training loss: 0.2305, validation loss: 0.1297
2024-05-22 13:45:48 [INFO]: Epoch 290 - training loss: 0.2308, validation loss: 0.1296
2024-05-22 13:45:51 [INFO]: Epoch 291 - training loss: 0.2308, validation loss: 0.1296
2024-05-22 13:45:53 [INFO]: Epoch 292 - training loss: 0.2308, validation loss: 0.1295
2024-05-22 13:45:56 [INFO]: Epoch 293 - training loss: 0.2307, validation loss: 0.1295
2024-05-22 13:45:59 [INFO]: Epoch 294 - training loss: 0.2304, validation loss: 0.1295
2024-05-22 13:46:01 [INFO]: Epoch 295 - training loss: 0.2300, validation loss: 0.1293
2024-05-22 13:46:04 [INFO]: Epoch 296 - training loss: 0.2304, validation loss: 0.1294
2024-05-22 13:46:07 [INFO]: Epoch 297 - training loss: 0.2302, validation loss: 0.1291
2024-05-22 13:46:10 [INFO]: Epoch 298 - training loss: 0.2296, validation loss: 0.1293
2024-05-22 13:46:12 [INFO]: Epoch 299 - training loss: 0.2297, validation loss: 0.1290
2024-05-22 13:46:15 [INFO]: Epoch 300 - training loss: 0.2298, validation loss: 0.1290
2024-05-22 13:46:15 [INFO]: Finished training. The best model is from epoch#299.
2024-05-22 13:46:15 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_air_quality/20240522_T133233/BRITS.pypots
2024-05-22 13:46:16 [INFO]: BRITS on Air-Quality: MAE=0.1429, MSE=0.1139
2024-05-22 13:46:16 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-22 13:46:16 [INFO]: Using the given device: cuda:0
2024-05-22 13:46:16 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616
2024-05-22 13:46:16 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/tensorboard
2024-05-22 13:46:16 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 13:46:20 [INFO]: Epoch 001 - training loss: 1.4743, validation loss: 0.8018
2024-05-22 13:46:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch1_loss0.801768559217453.pypots
2024-05-22 13:46:24 [INFO]: Epoch 002 - training loss: 1.0679, validation loss: 0.7464
2024-05-22 13:46:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch2_loss0.7463620483875275.pypots
2024-05-22 13:46:28 [INFO]: Epoch 003 - training loss: 0.9818, validation loss: 0.7253
2024-05-22 13:46:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch3_loss0.7253065824508667.pypots
2024-05-22 13:46:32 [INFO]: Epoch 004 - training loss: 0.9674, validation loss: 0.7133
2024-05-22 13:46:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch4_loss0.713254988193512.pypots
2024-05-22 13:46:36 [INFO]: Epoch 005 - training loss: 0.9594, validation loss: 0.7050
2024-05-22 13:46:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch5_loss0.7049852639436722.pypots
2024-05-22 13:46:39 [INFO]: Epoch 006 - training loss: 0.9485, validation loss: 0.6996
2024-05-22 13:46:39 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch6_loss0.6995511144399643.pypots
2024-05-22 13:46:43 [INFO]: Epoch 007 - training loss: 0.9364, validation loss: 0.6947
2024-05-22 13:46:43 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch7_loss0.6946706891059875.pypots
2024-05-22 13:46:47 [INFO]: Epoch 008 - training loss: 0.9347, validation loss: 0.6906
2024-05-22 13:46:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch8_loss0.6905946582555771.pypots
2024-05-22 13:46:51 [INFO]: Epoch 009 - training loss: 0.9566, validation loss: 0.6877
2024-05-22 13:46:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch9_loss0.6877070397138596.pypots
2024-05-22 13:46:55 [INFO]: Epoch 010 - training loss: 0.9682, validation loss: 0.6859
2024-05-22 13:46:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch10_loss0.6858760863542557.pypots
2024-05-22 13:46:58 [INFO]: Epoch 011 - training loss: 0.9233, validation loss: 0.6839
2024-05-22 13:46:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch11_loss0.6838920950889588.pypots
2024-05-22 13:47:02 [INFO]: Epoch 012 - training loss: 0.9283, validation loss: 0.6838
2024-05-22 13:47:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch12_loss0.6838456600904464.pypots
2024-05-22 13:47:06 [INFO]: Epoch 013 - training loss: 0.9219, validation loss: 0.6813
2024-05-22 13:47:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch13_loss0.6812979429960251.pypots
2024-05-22 13:47:10 [INFO]: Epoch 014 - training loss: 0.9177, validation loss: 0.6815
2024-05-22 13:47:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch14_loss0.6814514368772506.pypots
2024-05-22 13:47:14 [INFO]: Epoch 015 - training loss: 0.9091, validation loss: 0.6800
2024-05-22 13:47:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch15_loss0.6799623936414718.pypots
2024-05-22 13:47:17 [INFO]: Epoch 016 - training loss: 0.8925, validation loss: 0.6799
2024-05-22 13:47:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch16_loss0.679936146736145.pypots
2024-05-22 13:47:21 [INFO]: Epoch 017 - training loss: 0.8997, validation loss: 0.6837
2024-05-22 13:47:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch17_loss0.6836597204208374.pypots
2024-05-22 13:47:25 [INFO]: Epoch 018 - training loss: 0.8897, validation loss: 0.6795
2024-05-22 13:47:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch18_loss0.6794526726007462.pypots
2024-05-22 13:47:29 [INFO]: Epoch 019 - training loss: 0.8812, validation loss: 0.6796
2024-05-22 13:47:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch19_loss0.679637148976326.pypots
2024-05-22 13:47:32 [INFO]: Epoch 020 - training loss: 0.8856, validation loss: 0.6807
2024-05-22 13:47:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch20_loss0.6806513637304306.pypots
2024-05-22 13:47:36 [INFO]: Epoch 021 - training loss: 0.8784, validation loss: 0.6811
2024-05-22 13:47:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch21_loss0.681073996424675.pypots
2024-05-22 13:47:40 [INFO]: Epoch 022 - training loss: 0.8732, validation loss: 0.6832
2024-05-22 13:47:40 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch22_loss0.6831756949424743.pypots
2024-05-22 13:47:44 [INFO]: Epoch 023 - training loss: 0.9011, validation loss: 0.6830
2024-05-22 13:47:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch23_loss0.6830180048942566.pypots
2024-05-22 13:47:48 [INFO]: Epoch 024 - training loss: 0.8988, validation loss: 0.6884
2024-05-22 13:47:48 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch24_loss0.6884475082159043.pypots
2024-05-22 13:47:51 [INFO]: Epoch 025 - training loss: 0.9036, validation loss: 0.6823
2024-05-22 13:47:51 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch25_loss0.6822853922843933.pypots
2024-05-22 13:47:55 [INFO]: Epoch 026 - training loss: 0.8765, validation loss: 0.6827
2024-05-22 13:47:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch26_loss0.6827022314071656.pypots
2024-05-22 13:47:59 [INFO]: Epoch 027 - training loss: 0.8761, validation loss: 0.6854
2024-05-22 13:47:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch27_loss0.6853973865509033.pypots
2024-05-22 13:48:03 [INFO]: Epoch 028 - training loss: 0.8743, validation loss: 0.6852
2024-05-22 13:48:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN_epoch28_loss0.6851652383804321.pypots
2024-05-22 13:48:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:48:03 [INFO]: Finished training. The best model is from epoch#18.
2024-05-22 13:48:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_air_quality/20240522_T134616/MRNN.pypots
2024-05-22 13:48:03 [INFO]: MRNN on Air-Quality: MAE=0.5255, MSE=0.6236
2024-05-22 13:48:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-22 13:48:03 [INFO]: Using the given device: cpu
2024-05-22 13:48:03 [INFO]: LOCF on Air-Quality: MAE=0.2063, MSE=0.2445
2024-05-22 13:48:03 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-22 13:48:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-22 13:48:04 [INFO]: Median on Air-Quality: MAE=0.6676, MSE=1.0184
2024-05-22 13:48:04 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-22 13:48:04 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-22 13:48:04 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=0.9535
2024-05-22 13:48:04 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-22 13:48:04 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-22 13:48:04 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 13:48:04 [INFO]: Using the given device: cuda:0
2024-05-22 13:48:04 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240522_T134804
2024-05-22 13:48:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_air_quality/20240522_T134804/tensorboard
2024-05-22 13:48:04 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 13:48:05 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.5272
2024-05-22 13:48:06 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.3990
2024-05-22 13:48:06 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.3240
2024-05-22 13:48:07 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.2862
2024-05-22 13:48:08 [INFO]: Epoch 005 - training loss: 0.5266, validation loss: 0.2651
2024-05-22 13:48:08 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2504
2024-05-22 13:48:09 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2405
2024-05-22 13:48:10 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2345
2024-05-22 13:48:10 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.2288
2024-05-22 13:48:11 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.2240
2024-05-22 13:48:12 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.2216
2024-05-22 13:48:12 [INFO]: Epoch 012 - training loss: 0.3973, validation loss: 0.2166
2024-05-22 13:48:13 [INFO]: Epoch 013 - training loss: 0.3884, validation loss: 0.2147
2024-05-22 13:48:14 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2116
2024-05-22 13:48:14 [INFO]: Epoch 015 - training loss: 0.3764, validation loss: 0.2087
2024-05-22 13:48:15 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2065
2024-05-22 13:48:16 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2060
2024-05-22 13:48:16 [INFO]: Epoch 018 - training loss: 0.3589, validation loss: 0.2037
2024-05-22 13:48:17 [INFO]: Epoch 019 - training loss: 0.3567, validation loss: 0.2014
2024-05-22 13:48:18 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.1999
2024-05-22 13:48:18 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.1994
2024-05-22 13:48:19 [INFO]: Epoch 022 - training loss: 0.3464, validation loss: 0.1967
2024-05-22 13:48:20 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1957
2024-05-22 13:48:20 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.1937
2024-05-22 13:48:21 [INFO]: Epoch 025 - training loss: 0.3379, validation loss: 0.1924
2024-05-22 13:48:22 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.1911
2024-05-22 13:48:22 [INFO]: Epoch 027 - training loss: 0.3309, validation loss: 0.1910
2024-05-22 13:48:23 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.1891
2024-05-22 13:48:24 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.1883
2024-05-22 13:48:24 [INFO]: Epoch 030 - training loss: 0.3262, validation loss: 0.1871
2024-05-22 13:48:25 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.1856
2024-05-22 13:48:26 [INFO]: Epoch 032 - training loss: 0.3205, validation loss: 0.1841
2024-05-22 13:48:26 [INFO]: Epoch 033 - training loss: 0.3174, validation loss: 0.1835
2024-05-22 13:48:27 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1826
2024-05-22 13:48:28 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1813
2024-05-22 13:48:28 [INFO]: Epoch 036 - training loss: 0.3139, validation loss: 0.1800
2024-05-22 13:48:29 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1803
2024-05-22 13:48:30 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.1792
2024-05-22 13:48:30 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.1778
2024-05-22 13:48:31 [INFO]: Epoch 040 - training loss: 0.3052, validation loss: 0.1757
2024-05-22 13:48:32 [INFO]: Epoch 041 - training loss: 0.3049, validation loss: 0.1749
2024-05-22 13:48:32 [INFO]: Epoch 042 - training loss: 0.3030, validation loss: 0.1758
2024-05-22 13:48:33 [INFO]: Epoch 043 - training loss: 0.2999, validation loss: 0.1740
2024-05-22 13:48:34 [INFO]: Epoch 044 - training loss: 0.2980, validation loss: 0.1736
2024-05-22 13:48:34 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.1726
2024-05-22 13:48:35 [INFO]: Epoch 046 - training loss: 0.2958, validation loss: 0.1720
2024-05-22 13:48:36 [INFO]: Epoch 047 - training loss: 0.2951, validation loss: 0.1706
2024-05-22 13:48:36 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.1694
2024-05-22 13:48:37 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1679
2024-05-22 13:48:38 [INFO]: Epoch 050 - training loss: 0.2899, validation loss: 0.1681
2024-05-22 13:48:38 [INFO]: Epoch 051 - training loss: 0.2899, validation loss: 0.1676
2024-05-22 13:48:39 [INFO]: Epoch 052 - training loss: 0.2872, validation loss: 0.1665
2024-05-22 13:48:40 [INFO]: Epoch 053 - training loss: 0.2862, validation loss: 0.1653
2024-05-22 13:48:40 [INFO]: Epoch 054 - training loss: 0.2844, validation loss: 0.1651
2024-05-22 13:48:41 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.1640
2024-05-22 13:48:42 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1637
2024-05-22 13:48:42 [INFO]: Epoch 057 - training loss: 0.2801, validation loss: 0.1628
2024-05-22 13:48:43 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1612
2024-05-22 13:48:44 [INFO]: Epoch 059 - training loss: 0.2782, validation loss: 0.1617
2024-05-22 13:48:44 [INFO]: Epoch 060 - training loss: 0.2775, validation loss: 0.1592
2024-05-22 13:48:45 [INFO]: Epoch 061 - training loss: 0.2769, validation loss: 0.1609
2024-05-22 13:48:46 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1600
2024-05-22 13:48:46 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.1586
2024-05-22 13:48:47 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1586
2024-05-22 13:48:48 [INFO]: Epoch 065 - training loss: 0.2720, validation loss: 0.1583
2024-05-22 13:48:48 [INFO]: Epoch 066 - training loss: 0.2711, validation loss: 0.1573
2024-05-22 13:48:49 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1562
2024-05-22 13:48:50 [INFO]: Epoch 068 - training loss: 0.2695, validation loss: 0.1564
2024-05-22 13:48:50 [INFO]: Epoch 069 - training loss: 0.2678, validation loss: 0.1550
2024-05-22 13:48:51 [INFO]: Epoch 070 - training loss: 0.2666, validation loss: 0.1550
2024-05-22 13:48:52 [INFO]: Epoch 071 - training loss: 0.2660, validation loss: 0.1546
2024-05-22 13:48:52 [INFO]: Epoch 072 - training loss: 0.2634, validation loss: 0.1548
2024-05-22 13:48:53 [INFO]: Epoch 073 - training loss: 0.2636, validation loss: 0.1530
2024-05-22 13:48:54 [INFO]: Epoch 074 - training loss: 0.2633, validation loss: 0.1537
2024-05-22 13:48:54 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1521
2024-05-22 13:48:55 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1526
2024-05-22 13:48:56 [INFO]: Epoch 077 - training loss: 0.2614, validation loss: 0.1513
2024-05-22 13:48:56 [INFO]: Epoch 078 - training loss: 0.2602, validation loss: 0.1515
2024-05-22 13:48:57 [INFO]: Epoch 079 - training loss: 0.2586, validation loss: 0.1500
2024-05-22 13:48:58 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1507
2024-05-22 13:48:58 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1499
2024-05-22 13:48:59 [INFO]: Epoch 082 - training loss: 0.2568, validation loss: 0.1498
2024-05-22 13:49:00 [INFO]: Epoch 083 - training loss: 0.2568, validation loss: 0.1494
2024-05-22 13:49:00 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1491
2024-05-22 13:49:01 [INFO]: Epoch 085 - training loss: 0.2549, validation loss: 0.1487
2024-05-22 13:49:02 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1481
2024-05-22 13:49:02 [INFO]: Epoch 087 - training loss: 0.2531, validation loss: 0.1485
2024-05-22 13:49:03 [INFO]: Epoch 088 - training loss: 0.2528, validation loss: 0.1476
2024-05-22 13:49:04 [INFO]: Epoch 089 - training loss: 0.2546, validation loss: 0.1479
2024-05-22 13:49:04 [INFO]: Epoch 090 - training loss: 0.2554, validation loss: 0.1479
2024-05-22 13:49:05 [INFO]: Epoch 091 - training loss: 0.2537, validation loss: 0.1474
2024-05-22 13:49:06 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1466
2024-05-22 13:49:06 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1460
2024-05-22 13:49:07 [INFO]: Epoch 094 - training loss: 0.2475, validation loss: 0.1453
2024-05-22 13:49:08 [INFO]: Epoch 095 - training loss: 0.2495, validation loss: 0.1456
2024-05-22 13:49:08 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1455
2024-05-22 13:49:09 [INFO]: Epoch 097 - training loss: 0.2486, validation loss: 0.1443
2024-05-22 13:49:10 [INFO]: Epoch 098 - training loss: 0.2481, validation loss: 0.1440
2024-05-22 13:49:10 [INFO]: Epoch 099 - training loss: 0.2469, validation loss: 0.1447
2024-05-22 13:49:11 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1449
2024-05-22 13:49:12 [INFO]: Epoch 101 - training loss: 0.2441, validation loss: 0.1440
2024-05-22 13:49:12 [INFO]: Epoch 102 - training loss: 0.2441, validation loss: 0.1430
2024-05-22 13:49:13 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1436
2024-05-22 13:49:14 [INFO]: Epoch 104 - training loss: 0.2431, validation loss: 0.1428
2024-05-22 13:49:14 [INFO]: Epoch 105 - training loss: 0.2420, validation loss: 0.1426
2024-05-22 13:49:15 [INFO]: Epoch 106 - training loss: 0.2424, validation loss: 0.1424
2024-05-22 13:49:16 [INFO]: Epoch 107 - training loss: 0.2429, validation loss: 0.1420
2024-05-22 13:49:16 [INFO]: Epoch 108 - training loss: 0.2408, validation loss: 0.1425
2024-05-22 13:49:17 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1422
2024-05-22 13:49:18 [INFO]: Epoch 110 - training loss: 0.2413, validation loss: 0.1412
2024-05-22 13:49:18 [INFO]: Epoch 111 - training loss: 0.2403, validation loss: 0.1414
2024-05-22 13:49:19 [INFO]: Epoch 112 - training loss: 0.2391, validation loss: 0.1410
2024-05-22 13:49:20 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1404
2024-05-22 13:49:20 [INFO]: Epoch 114 - training loss: 0.2379, validation loss: 0.1407
2024-05-22 13:49:21 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1403
2024-05-22 13:49:22 [INFO]: Epoch 116 - training loss: 0.2375, validation loss: 0.1408
2024-05-22 13:49:22 [INFO]: Epoch 117 - training loss: 0.2364, validation loss: 0.1407
2024-05-22 13:49:23 [INFO]: Epoch 118 - training loss: 0.2363, validation loss: 0.1400
2024-05-22 13:49:24 [INFO]: Epoch 119 - training loss: 0.2359, validation loss: 0.1402
2024-05-22 13:49:24 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1395
2024-05-22 13:49:25 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1397
2024-05-22 13:49:26 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1393
2024-05-22 13:49:26 [INFO]: Epoch 123 - training loss: 0.2352, validation loss: 0.1383
2024-05-22 13:49:27 [INFO]: Epoch 124 - training loss: 0.2332, validation loss: 0.1383
2024-05-22 13:49:28 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1385
2024-05-22 13:49:29 [INFO]: Epoch 126 - training loss: 0.2339, validation loss: 0.1385
2024-05-22 13:49:29 [INFO]: Epoch 127 - training loss: 0.2322, validation loss: 0.1373
2024-05-22 13:49:30 [INFO]: Epoch 128 - training loss: 0.2318, validation loss: 0.1372
2024-05-22 13:49:31 [INFO]: Epoch 129 - training loss: 0.2311, validation loss: 0.1374
2024-05-22 13:49:31 [INFO]: Epoch 130 - training loss: 0.2313, validation loss: 0.1372
2024-05-22 13:49:32 [INFO]: Epoch 131 - training loss: 0.2307, validation loss: 0.1365
2024-05-22 13:49:33 [INFO]: Epoch 132 - training loss: 0.2310, validation loss: 0.1376
2024-05-22 13:49:33 [INFO]: Epoch 133 - training loss: 0.2316, validation loss: 0.1365
2024-05-22 13:49:34 [INFO]: Epoch 134 - training loss: 0.2314, validation loss: 0.1365
2024-05-22 13:49:35 [INFO]: Epoch 135 - training loss: 0.2316, validation loss: 0.1367
2024-05-22 13:49:35 [INFO]: Epoch 136 - training loss: 0.2300, validation loss: 0.1356
2024-05-22 13:49:36 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1358
2024-05-22 13:49:37 [INFO]: Epoch 138 - training loss: 0.2282, validation loss: 0.1356
2024-05-22 13:49:37 [INFO]: Epoch 139 - training loss: 0.2269, validation loss: 0.1350
2024-05-22 13:49:38 [INFO]: Epoch 140 - training loss: 0.2270, validation loss: 0.1352
2024-05-22 13:49:39 [INFO]: Epoch 141 - training loss: 0.2264, validation loss: 0.1349
2024-05-22 13:49:39 [INFO]: Epoch 142 - training loss: 0.2261, validation loss: 0.1352
2024-05-22 13:49:40 [INFO]: Epoch 143 - training loss: 0.2271, validation loss: 0.1344
2024-05-22 13:49:41 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1346
2024-05-22 13:49:41 [INFO]: Epoch 145 - training loss: 0.2253, validation loss: 0.1350
2024-05-22 13:49:42 [INFO]: Epoch 146 - training loss: 0.2257, validation loss: 0.1343
2024-05-22 13:49:43 [INFO]: Epoch 147 - training loss: 0.2259, validation loss: 0.1342
2024-05-22 13:49:43 [INFO]: Epoch 148 - training loss: 0.2236, validation loss: 0.1342
2024-05-22 13:49:44 [INFO]: Epoch 149 - training loss: 0.2237, validation loss: 0.1341
2024-05-22 13:49:45 [INFO]: Epoch 150 - training loss: 0.2228, validation loss: 0.1335
2024-05-22 13:49:45 [INFO]: Epoch 151 - training loss: 0.2239, validation loss: 0.1342
2024-05-22 13:49:46 [INFO]: Epoch 152 - training loss: 0.2236, validation loss: 0.1343
2024-05-22 13:49:47 [INFO]: Epoch 153 - training loss: 0.2220, validation loss: 0.1340
2024-05-22 13:49:47 [INFO]: Epoch 154 - training loss: 0.2220, validation loss: 0.1332
2024-05-22 13:49:48 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1337
2024-05-22 13:49:49 [INFO]: Epoch 156 - training loss: 0.2210, validation loss: 0.1334
2024-05-22 13:49:49 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1318
2024-05-22 13:49:50 [INFO]: Epoch 158 - training loss: 0.2209, validation loss: 0.1329
2024-05-22 13:49:51 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1341
2024-05-22 13:49:51 [INFO]: Epoch 160 - training loss: 0.2221, validation loss: 0.1321
2024-05-22 13:49:52 [INFO]: Epoch 161 - training loss: 0.2219, validation loss: 0.1328
2024-05-22 13:49:53 [INFO]: Epoch 162 - training loss: 0.2190, validation loss: 0.1319
2024-05-22 13:49:53 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1323
2024-05-22 13:49:54 [INFO]: Epoch 164 - training loss: 0.2182, validation loss: 0.1316
2024-05-22 13:49:55 [INFO]: Epoch 165 - training loss: 0.2172, validation loss: 0.1321
2024-05-22 13:49:55 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1306
2024-05-22 13:49:56 [INFO]: Epoch 167 - training loss: 0.2172, validation loss: 0.1311
2024-05-22 13:49:57 [INFO]: Epoch 168 - training loss: 0.2168, validation loss: 0.1309
2024-05-22 13:49:57 [INFO]: Epoch 169 - training loss: 0.2154, validation loss: 0.1306
2024-05-22 13:49:58 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1318
2024-05-22 13:49:59 [INFO]: Epoch 171 - training loss: 0.2191, validation loss: 0.1326
2024-05-22 13:49:59 [INFO]: Epoch 172 - training loss: 0.2160, validation loss: 0.1309
2024-05-22 13:50:00 [INFO]: Epoch 173 - training loss: 0.2156, validation loss: 0.1310
2024-05-22 13:50:01 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1308
2024-05-22 13:50:01 [INFO]: Epoch 175 - training loss: 0.2172, validation loss: 0.1311
2024-05-22 13:50:02 [INFO]: Epoch 176 - training loss: 0.2168, validation loss: 0.1303
2024-05-22 13:50:03 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1308
2024-05-22 13:50:03 [INFO]: Epoch 178 - training loss: 0.2153, validation loss: 0.1298
2024-05-22 13:50:04 [INFO]: Epoch 179 - training loss: 0.2154, validation loss: 0.1294
2024-05-22 13:50:05 [INFO]: Epoch 180 - training loss: 0.2150, validation loss: 0.1295
2024-05-22 13:50:05 [INFO]: Epoch 181 - training loss: 0.2138, validation loss: 0.1301
2024-05-22 13:50:06 [INFO]: Epoch 182 - training loss: 0.2141, validation loss: 0.1296
2024-05-22 13:50:07 [INFO]: Epoch 183 - training loss: 0.2168, validation loss: 0.1305
2024-05-22 13:50:07 [INFO]: Epoch 184 - training loss: 0.2151, validation loss: 0.1292
2024-05-22 13:50:08 [INFO]: Epoch 185 - training loss: 0.2122, validation loss: 0.1295
2024-05-22 13:50:09 [INFO]: Epoch 186 - training loss: 0.2107, validation loss: 0.1292
2024-05-22 13:50:09 [INFO]: Epoch 187 - training loss: 0.2119, validation loss: 0.1295
2024-05-22 13:50:10 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1294
2024-05-22 13:50:11 [INFO]: Epoch 189 - training loss: 0.2114, validation loss: 0.1290
2024-05-22 13:50:11 [INFO]: Epoch 190 - training loss: 0.2101, validation loss: 0.1296
2024-05-22 13:50:12 [INFO]: Epoch 191 - training loss: 0.2097, validation loss: 0.1287
2024-05-22 13:50:13 [INFO]: Epoch 192 - training loss: 0.2103, validation loss: 0.1283
2024-05-22 13:50:13 [INFO]: Epoch 193 - training loss: 0.2093, validation loss: 0.1291
2024-05-22 13:50:14 [INFO]: Epoch 194 - training loss: 0.2090, validation loss: 0.1289
2024-05-22 13:50:15 [INFO]: Epoch 195 - training loss: 0.2095, validation loss: 0.1277
2024-05-22 13:50:15 [INFO]: Epoch 196 - training loss: 0.2085, validation loss: 0.1280
2024-05-22 13:50:16 [INFO]: Epoch 197 - training loss: 0.2081, validation loss: 0.1286
2024-05-22 13:50:17 [INFO]: Epoch 198 - training loss: 0.2082, validation loss: 0.1281
2024-05-22 13:50:17 [INFO]: Epoch 199 - training loss: 0.2085, validation loss: 0.1293
2024-05-22 13:50:18 [INFO]: Epoch 200 - training loss: 0.2082, validation loss: 0.1280
2024-05-22 13:50:19 [INFO]: Epoch 201 - training loss: 0.2074, validation loss: 0.1277
2024-05-22 13:50:19 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.1295
2024-05-22 13:50:20 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1277
2024-05-22 13:50:21 [INFO]: Epoch 204 - training loss: 0.2086, validation loss: 0.1277
2024-05-22 13:50:21 [INFO]: Epoch 205 - training loss: 0.2076, validation loss: 0.1273
2024-05-22 13:50:22 [INFO]: Epoch 206 - training loss: 0.2065, validation loss: 0.1276
2024-05-22 13:50:23 [INFO]: Epoch 207 - training loss: 0.2068, validation loss: 0.1274
2024-05-22 13:50:23 [INFO]: Epoch 208 - training loss: 0.2066, validation loss: 0.1269
2024-05-22 13:50:24 [INFO]: Epoch 209 - training loss: 0.2068, validation loss: 0.1276
2024-05-22 13:50:25 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1276
2024-05-22 13:50:25 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.1273
2024-05-22 13:50:26 [INFO]: Epoch 212 - training loss: 0.2061, validation loss: 0.1277
2024-05-22 13:50:27 [INFO]: Epoch 213 - training loss: 0.2058, validation loss: 0.1277
2024-05-22 13:50:27 [INFO]: Epoch 214 - training loss: 0.2043, validation loss: 0.1269
2024-05-22 13:50:28 [INFO]: Epoch 215 - training loss: 0.2044, validation loss: 0.1270
2024-05-22 13:50:29 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.1267
2024-05-22 13:50:29 [INFO]: Epoch 217 - training loss: 0.2028, validation loss: 0.1275
2024-05-22 13:50:30 [INFO]: Epoch 218 - training loss: 0.2035, validation loss: 0.1270
2024-05-22 13:50:31 [INFO]: Epoch 219 - training loss: 0.2049, validation loss: 0.1284
2024-05-22 13:50:31 [INFO]: Epoch 220 - training loss: 0.2039, validation loss: 0.1277
2024-05-22 13:50:32 [INFO]: Epoch 221 - training loss: 0.2022, validation loss: 0.1272
2024-05-22 13:50:33 [INFO]: Epoch 222 - training loss: 0.2027, validation loss: 0.1272
2024-05-22 13:50:33 [INFO]: Epoch 223 - training loss: 0.2026, validation loss: 0.1278
2024-05-22 13:50:34 [INFO]: Epoch 224 - training loss: 0.2044, validation loss: 0.1269
2024-05-22 13:50:35 [INFO]: Epoch 225 - training loss: 0.2042, validation loss: 0.1273
2024-05-22 13:50:35 [INFO]: Epoch 226 - training loss: 0.2022, validation loss: 0.1262
2024-05-22 13:50:36 [INFO]: Epoch 227 - training loss: 0.2015, validation loss: 0.1275
2024-05-22 13:50:37 [INFO]: Epoch 228 - training loss: 0.2020, validation loss: 0.1272
2024-05-22 13:50:37 [INFO]: Epoch 229 - training loss: 0.2010, validation loss: 0.1267
2024-05-22 13:50:38 [INFO]: Epoch 230 - training loss: 0.2008, validation loss: 0.1264
2024-05-22 13:50:39 [INFO]: Epoch 231 - training loss: 0.2007, validation loss: 0.1265
2024-05-22 13:50:39 [INFO]: Epoch 232 - training loss: 0.2001, validation loss: 0.1261
2024-05-22 13:50:40 [INFO]: Epoch 233 - training loss: 0.2026, validation loss: 0.1263
2024-05-22 13:50:41 [INFO]: Epoch 234 - training loss: 0.2002, validation loss: 0.1263
2024-05-22 13:50:41 [INFO]: Epoch 235 - training loss: 0.2000, validation loss: 0.1257
2024-05-22 13:50:42 [INFO]: Epoch 236 - training loss: 0.1991, validation loss: 0.1265
2024-05-22 13:50:43 [INFO]: Epoch 237 - training loss: 0.1995, validation loss: 0.1266
2024-05-22 13:50:43 [INFO]: Epoch 238 - training loss: 0.1989, validation loss: 0.1256
2024-05-22 13:50:44 [INFO]: Epoch 239 - training loss: 0.1981, validation loss: 0.1265
2024-05-22 13:50:45 [INFO]: Epoch 240 - training loss: 0.1990, validation loss: 0.1273
2024-05-22 13:50:45 [INFO]: Epoch 241 - training loss: 0.2013, validation loss: 0.1258
2024-05-22 13:50:46 [INFO]: Epoch 242 - training loss: 0.2000, validation loss: 0.1254
2024-05-22 13:50:47 [INFO]: Epoch 243 - training loss: 0.1992, validation loss: 0.1267
2024-05-22 13:50:47 [INFO]: Epoch 244 - training loss: 0.1994, validation loss: 0.1267
2024-05-22 13:50:48 [INFO]: Epoch 245 - training loss: 0.1999, validation loss: 0.1269
2024-05-22 13:50:49 [INFO]: Epoch 246 - training loss: 0.2007, validation loss: 0.1262
2024-05-22 13:50:49 [INFO]: Epoch 247 - training loss: 0.1996, validation loss: 0.1283
2024-05-22 13:50:50 [INFO]: Epoch 248 - training loss: 0.2003, validation loss: 0.1262
2024-05-22 13:50:51 [INFO]: Epoch 249 - training loss: 0.1972, validation loss: 0.1263
2024-05-22 13:50:51 [INFO]: Epoch 250 - training loss: 0.1966, validation loss: 0.1261
2024-05-22 13:50:52 [INFO]: Epoch 251 - training loss: 0.1969, validation loss: 0.1257
2024-05-22 13:50:53 [INFO]: Epoch 252 - training loss: 0.1971, validation loss: 0.1258
2024-05-22 13:50:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:50:53 [INFO]: Finished training. The best model is from epoch#242.
2024-05-22 13:50:53 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_air_quality/20240522_T134804/SAITS.pypots
2024-05-22 13:50:53 [INFO]: SAITS on Air-Quality: MAE=0.1435, MSE=0.1143
2024-05-22 13:50:53 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-22 13:50:53 [INFO]: Using the given device: cuda:0
2024-05-22 13:50:53 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240522_T135053
2024-05-22 13:50:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_air_quality/20240522_T135053/tensorboard
2024-05-22 13:50:53 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 13:50:53 [INFO]: Epoch 001 - training loss: 0.9104, validation loss: 0.4740
2024-05-22 13:50:54 [INFO]: Epoch 002 - training loss: 0.5771, validation loss: 0.3489
2024-05-22 13:50:54 [INFO]: Epoch 003 - training loss: 0.4863, validation loss: 0.2960
2024-05-22 13:50:54 [INFO]: Epoch 004 - training loss: 0.4403, validation loss: 0.2728
2024-05-22 13:50:55 [INFO]: Epoch 005 - training loss: 0.4108, validation loss: 0.2604
2024-05-22 13:50:55 [INFO]: Epoch 006 - training loss: 0.3932, validation loss: 0.2493
2024-05-22 13:50:55 [INFO]: Epoch 007 - training loss: 0.3802, validation loss: 0.2424
2024-05-22 13:50:56 [INFO]: Epoch 008 - training loss: 0.3672, validation loss: 0.2369
2024-05-22 13:50:56 [INFO]: Epoch 009 - training loss: 0.3559, validation loss: 0.2326
2024-05-22 13:50:56 [INFO]: Epoch 010 - training loss: 0.3504, validation loss: 0.2266
2024-05-22 13:50:57 [INFO]: Epoch 011 - training loss: 0.3416, validation loss: 0.2237
2024-05-22 13:50:57 [INFO]: Epoch 012 - training loss: 0.3388, validation loss: 0.2193
2024-05-22 13:50:57 [INFO]: Epoch 013 - training loss: 0.3336, validation loss: 0.2180
2024-05-22 13:50:58 [INFO]: Epoch 014 - training loss: 0.3302, validation loss: 0.2135
2024-05-22 13:50:58 [INFO]: Epoch 015 - training loss: 0.3244, validation loss: 0.2105
2024-05-22 13:50:58 [INFO]: Epoch 016 - training loss: 0.3211, validation loss: 0.2078
2024-05-22 13:50:58 [INFO]: Epoch 017 - training loss: 0.3154, validation loss: 0.2050
2024-05-22 13:50:59 [INFO]: Epoch 018 - training loss: 0.3135, validation loss: 0.2019
2024-05-22 13:50:59 [INFO]: Epoch 019 - training loss: 0.3100, validation loss: 0.1999
2024-05-22 13:50:59 [INFO]: Epoch 020 - training loss: 0.3096, validation loss: 0.1994
2024-05-22 13:51:00 [INFO]: Epoch 021 - training loss: 0.3084, validation loss: 0.1965
2024-05-22 13:51:00 [INFO]: Epoch 022 - training loss: 0.3047, validation loss: 0.1918
2024-05-22 13:51:00 [INFO]: Epoch 023 - training loss: 0.3013, validation loss: 0.1917
2024-05-22 13:51:01 [INFO]: Epoch 024 - training loss: 0.2978, validation loss: 0.1895
2024-05-22 13:51:01 [INFO]: Epoch 025 - training loss: 0.2960, validation loss: 0.1878
2024-05-22 13:51:01 [INFO]: Epoch 026 - training loss: 0.2934, validation loss: 0.1876
2024-05-22 13:51:02 [INFO]: Epoch 027 - training loss: 0.2907, validation loss: 0.1862
2024-05-22 13:51:02 [INFO]: Epoch 028 - training loss: 0.2894, validation loss: 0.1865
2024-05-22 13:51:02 [INFO]: Epoch 029 - training loss: 0.2886, validation loss: 0.1858
2024-05-22 13:51:03 [INFO]: Epoch 030 - training loss: 0.2870, validation loss: 0.1847
2024-05-22 13:51:03 [INFO]: Epoch 031 - training loss: 0.2856, validation loss: 0.1833
2024-05-22 13:51:03 [INFO]: Epoch 032 - training loss: 0.2838, validation loss: 0.1825
2024-05-22 13:51:04 [INFO]: Epoch 033 - training loss: 0.2809, validation loss: 0.1820
2024-05-22 13:51:04 [INFO]: Epoch 034 - training loss: 0.2801, validation loss: 0.1812
2024-05-22 13:51:04 [INFO]: Epoch 035 - training loss: 0.2827, validation loss: 0.1821
2024-05-22 13:51:04 [INFO]: Epoch 036 - training loss: 0.2832, validation loss: 0.1801
2024-05-22 13:51:05 [INFO]: Epoch 037 - training loss: 0.2794, validation loss: 0.1797
2024-05-22 13:51:05 [INFO]: Epoch 038 - training loss: 0.2779, validation loss: 0.1797
2024-05-22 13:51:05 [INFO]: Epoch 039 - training loss: 0.2758, validation loss: 0.1789
2024-05-22 13:51:06 [INFO]: Epoch 040 - training loss: 0.2742, validation loss: 0.1793
2024-05-22 13:51:06 [INFO]: Epoch 041 - training loss: 0.2751, validation loss: 0.1776
2024-05-22 13:51:06 [INFO]: Epoch 042 - training loss: 0.2744, validation loss: 0.1781
2024-05-22 13:51:07 [INFO]: Epoch 043 - training loss: 0.2724, validation loss: 0.1761
2024-05-22 13:51:07 [INFO]: Epoch 044 - training loss: 0.2726, validation loss: 0.1775
2024-05-22 13:51:07 [INFO]: Epoch 045 - training loss: 0.2708, validation loss: 0.1773
2024-05-22 13:51:08 [INFO]: Epoch 046 - training loss: 0.2687, validation loss: 0.1768
2024-05-22 13:51:08 [INFO]: Epoch 047 - training loss: 0.2679, validation loss: 0.1770
2024-05-22 13:51:08 [INFO]: Epoch 048 - training loss: 0.2646, validation loss: 0.1744
2024-05-22 13:51:09 [INFO]: Epoch 049 - training loss: 0.2644, validation loss: 0.1748
2024-05-22 13:51:09 [INFO]: Epoch 050 - training loss: 0.2687, validation loss: 0.1761
2024-05-22 13:51:09 [INFO]: Epoch 051 - training loss: 0.2652, validation loss: 0.1747
2024-05-22 13:51:10 [INFO]: Epoch 052 - training loss: 0.2629, validation loss: 0.1712
2024-05-22 13:51:10 [INFO]: Epoch 053 - training loss: 0.2599, validation loss: 0.1739
2024-05-22 13:51:10 [INFO]: Epoch 054 - training loss: 0.2590, validation loss: 0.1759
2024-05-22 13:51:10 [INFO]: Epoch 055 - training loss: 0.2599, validation loss: 0.1713
2024-05-22 13:51:11 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.1722
2024-05-22 13:51:11 [INFO]: Epoch 057 - training loss: 0.2572, validation loss: 0.1717
2024-05-22 13:51:11 [INFO]: Epoch 058 - training loss: 0.2574, validation loss: 0.1733
2024-05-22 13:51:12 [INFO]: Epoch 059 - training loss: 0.2563, validation loss: 0.1719
2024-05-22 13:51:12 [INFO]: Epoch 060 - training loss: 0.2544, validation loss: 0.1696
2024-05-22 13:51:12 [INFO]: Epoch 061 - training loss: 0.2567, validation loss: 0.1714
2024-05-22 13:51:13 [INFO]: Epoch 062 - training loss: 0.2572, validation loss: 0.1688
2024-05-22 13:51:13 [INFO]: Epoch 063 - training loss: 0.2558, validation loss: 0.1682
2024-05-22 13:51:13 [INFO]: Epoch 064 - training loss: 0.2536, validation loss: 0.1685
2024-05-22 13:51:14 [INFO]: Epoch 065 - training loss: 0.2512, validation loss: 0.1676
2024-05-22 13:51:14 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1695
2024-05-22 13:51:14 [INFO]: Epoch 067 - training loss: 0.2504, validation loss: 0.1666
2024-05-22 13:51:15 [INFO]: Epoch 068 - training loss: 0.2502, validation loss: 0.1659
2024-05-22 13:51:15 [INFO]: Epoch 069 - training loss: 0.2510, validation loss: 0.1684
2024-05-22 13:51:15 [INFO]: Epoch 070 - training loss: 0.2498, validation loss: 0.1685
2024-05-22 13:51:16 [INFO]: Epoch 071 - training loss: 0.2489, validation loss: 0.1660
2024-05-22 13:51:16 [INFO]: Epoch 072 - training loss: 0.2461, validation loss: 0.1684
2024-05-22 13:51:16 [INFO]: Epoch 073 - training loss: 0.2447, validation loss: 0.1669
2024-05-22 13:51:16 [INFO]: Epoch 074 - training loss: 0.2428, validation loss: 0.1672
2024-05-22 13:51:17 [INFO]: Epoch 075 - training loss: 0.2431, validation loss: 0.1652
2024-05-22 13:51:17 [INFO]: Epoch 076 - training loss: 0.2447, validation loss: 0.1669
2024-05-22 13:51:17 [INFO]: Epoch 077 - training loss: 0.2434, validation loss: 0.1648
2024-05-22 13:51:18 [INFO]: Epoch 078 - training loss: 0.2428, validation loss: 0.1657
2024-05-22 13:51:18 [INFO]: Epoch 079 - training loss: 0.2440, validation loss: 0.1656
2024-05-22 13:51:18 [INFO]: Epoch 080 - training loss: 0.2431, validation loss: 0.1629
2024-05-22 13:51:19 [INFO]: Epoch 081 - training loss: 0.2434, validation loss: 0.1630
2024-05-22 13:51:19 [INFO]: Epoch 082 - training loss: 0.2429, validation loss: 0.1625
2024-05-22 13:51:19 [INFO]: Epoch 083 - training loss: 0.2443, validation loss: 0.1629
2024-05-22 13:51:20 [INFO]: Epoch 084 - training loss: 0.2411, validation loss: 0.1632
2024-05-22 13:51:20 [INFO]: Epoch 085 - training loss: 0.2370, validation loss: 0.1628
2024-05-22 13:51:20 [INFO]: Epoch 086 - training loss: 0.2356, validation loss: 0.1616
2024-05-22 13:51:21 [INFO]: Epoch 087 - training loss: 0.2363, validation loss: 0.1615
2024-05-22 13:51:21 [INFO]: Epoch 088 - training loss: 0.2354, validation loss: 0.1617
2024-05-22 13:51:21 [INFO]: Epoch 089 - training loss: 0.2343, validation loss: 0.1597
2024-05-22 13:51:22 [INFO]: Epoch 090 - training loss: 0.2335, validation loss: 0.1607
2024-05-22 13:51:22 [INFO]: Epoch 091 - training loss: 0.2338, validation loss: 0.1611
2024-05-22 13:51:22 [INFO]: Epoch 092 - training loss: 0.2353, validation loss: 0.1618
2024-05-22 13:51:22 [INFO]: Epoch 093 - training loss: 0.2343, validation loss: 0.1587
2024-05-22 13:51:23 [INFO]: Epoch 094 - training loss: 0.2341, validation loss: 0.1623
2024-05-22 13:51:23 [INFO]: Epoch 095 - training loss: 0.2329, validation loss: 0.1608
2024-05-22 13:51:23 [INFO]: Epoch 096 - training loss: 0.2312, validation loss: 0.1584
2024-05-22 13:51:24 [INFO]: Epoch 097 - training loss: 0.2294, validation loss: 0.1585
2024-05-22 13:51:24 [INFO]: Epoch 098 - training loss: 0.2293, validation loss: 0.1596
2024-05-22 13:51:24 [INFO]: Epoch 099 - training loss: 0.2301, validation loss: 0.1601
2024-05-22 13:51:25 [INFO]: Epoch 100 - training loss: 0.2321, validation loss: 0.1591
2024-05-22 13:51:25 [INFO]: Epoch 101 - training loss: 0.2322, validation loss: 0.1577
2024-05-22 13:51:25 [INFO]: Epoch 102 - training loss: 0.2286, validation loss: 0.1580
2024-05-22 13:51:26 [INFO]: Epoch 103 - training loss: 0.2281, validation loss: 0.1579
2024-05-22 13:51:26 [INFO]: Epoch 104 - training loss: 0.2277, validation loss: 0.1591
2024-05-22 13:51:26 [INFO]: Epoch 105 - training loss: 0.2260, validation loss: 0.1561
2024-05-22 13:51:27 [INFO]: Epoch 106 - training loss: 0.2249, validation loss: 0.1587
2024-05-22 13:51:27 [INFO]: Epoch 107 - training loss: 0.2242, validation loss: 0.1557
2024-05-22 13:51:27 [INFO]: Epoch 108 - training loss: 0.2237, validation loss: 0.1572
2024-05-22 13:51:28 [INFO]: Epoch 109 - training loss: 0.2251, validation loss: 0.1571
2024-05-22 13:51:28 [INFO]: Epoch 110 - training loss: 0.2266, validation loss: 0.1572
2024-05-22 13:51:28 [INFO]: Epoch 111 - training loss: 0.2266, validation loss: 0.1549
2024-05-22 13:51:28 [INFO]: Epoch 112 - training loss: 0.2263, validation loss: 0.1550
2024-05-22 13:51:29 [INFO]: Epoch 113 - training loss: 0.2261, validation loss: 0.1552
2024-05-22 13:51:29 [INFO]: Epoch 114 - training loss: 0.2256, validation loss: 0.1546
2024-05-22 13:51:29 [INFO]: Epoch 115 - training loss: 0.2249, validation loss: 0.1549
2024-05-22 13:51:30 [INFO]: Epoch 116 - training loss: 0.2221, validation loss: 0.1544
2024-05-22 13:51:30 [INFO]: Epoch 117 - training loss: 0.2220, validation loss: 0.1546
2024-05-22 13:51:30 [INFO]: Epoch 118 - training loss: 0.2195, validation loss: 0.1548
2024-05-22 13:51:31 [INFO]: Epoch 119 - training loss: 0.2189, validation loss: 0.1527
2024-05-22 13:51:31 [INFO]: Epoch 120 - training loss: 0.2234, validation loss: 0.1549
2024-05-22 13:51:31 [INFO]: Epoch 121 - training loss: 0.2194, validation loss: 0.1534
2024-05-22 13:51:32 [INFO]: Epoch 122 - training loss: 0.2194, validation loss: 0.1518
2024-05-22 13:51:32 [INFO]: Epoch 123 - training loss: 0.2192, validation loss: 0.1527
2024-05-22 13:51:32 [INFO]: Epoch 124 - training loss: 0.2197, validation loss: 0.1511
2024-05-22 13:51:33 [INFO]: Epoch 125 - training loss: 0.2168, validation loss: 0.1522
2024-05-22 13:51:33 [INFO]: Epoch 126 - training loss: 0.2163, validation loss: 0.1525
2024-05-22 13:51:33 [INFO]: Epoch 127 - training loss: 0.2173, validation loss: 0.1544
2024-05-22 13:51:34 [INFO]: Epoch 128 - training loss: 0.2168, validation loss: 0.1516
2024-05-22 13:51:34 [INFO]: Epoch 129 - training loss: 0.2171, validation loss: 0.1528
2024-05-22 13:51:34 [INFO]: Epoch 130 - training loss: 0.2185, validation loss: 0.1526
2024-05-22 13:51:34 [INFO]: Epoch 131 - training loss: 0.2180, validation loss: 0.1522
2024-05-22 13:51:35 [INFO]: Epoch 132 - training loss: 0.2149, validation loss: 0.1523
2024-05-22 13:51:35 [INFO]: Epoch 133 - training loss: 0.2152, validation loss: 0.1507
2024-05-22 13:51:35 [INFO]: Epoch 134 - training loss: 0.2172, validation loss: 0.1513
2024-05-22 13:51:36 [INFO]: Epoch 135 - training loss: 0.2142, validation loss: 0.1508
2024-05-22 13:51:36 [INFO]: Epoch 136 - training loss: 0.2164, validation loss: 0.1525
2024-05-22 13:51:36 [INFO]: Epoch 137 - training loss: 0.2206, validation loss: 0.1510
2024-05-22 13:51:37 [INFO]: Epoch 138 - training loss: 0.2137, validation loss: 0.1499
2024-05-22 13:51:37 [INFO]: Epoch 139 - training loss: 0.2138, validation loss: 0.1498
2024-05-22 13:51:37 [INFO]: Epoch 140 - training loss: 0.2135, validation loss: 0.1508
2024-05-22 13:51:38 [INFO]: Epoch 141 - training loss: 0.2138, validation loss: 0.1508
2024-05-22 13:51:38 [INFO]: Epoch 142 - training loss: 0.2134, validation loss: 0.1488
2024-05-22 13:51:38 [INFO]: Epoch 143 - training loss: 0.2145, validation loss: 0.1495
2024-05-22 13:51:39 [INFO]: Epoch 144 - training loss: 0.2121, validation loss: 0.1500
2024-05-22 13:51:39 [INFO]: Epoch 145 - training loss: 0.2111, validation loss: 0.1497
2024-05-22 13:51:39 [INFO]: Epoch 146 - training loss: 0.2101, validation loss: 0.1482
2024-05-22 13:51:40 [INFO]: Epoch 147 - training loss: 0.2102, validation loss: 0.1484
2024-05-22 13:51:40 [INFO]: Epoch 148 - training loss: 0.2086, validation loss: 0.1501
2024-05-22 13:51:40 [INFO]: Epoch 149 - training loss: 0.2103, validation loss: 0.1499
2024-05-22 13:51:40 [INFO]: Epoch 150 - training loss: 0.2116, validation loss: 0.1496
2024-05-22 13:51:41 [INFO]: Epoch 151 - training loss: 0.2104, validation loss: 0.1484
2024-05-22 13:51:41 [INFO]: Epoch 152 - training loss: 0.2103, validation loss: 0.1482
2024-05-22 13:51:41 [INFO]: Epoch 153 - training loss: 0.2072, validation loss: 0.1484
2024-05-22 13:51:42 [INFO]: Epoch 154 - training loss: 0.2089, validation loss: 0.1473
2024-05-22 13:51:42 [INFO]: Epoch 155 - training loss: 0.2113, validation loss: 0.1479
2024-05-22 13:51:42 [INFO]: Epoch 156 - training loss: 0.2080, validation loss: 0.1486
2024-05-22 13:51:43 [INFO]: Epoch 157 - training loss: 0.2086, validation loss: 0.1477
2024-05-22 13:51:43 [INFO]: Epoch 158 - training loss: 0.2076, validation loss: 0.1463
2024-05-22 13:51:43 [INFO]: Epoch 159 - training loss: 0.2069, validation loss: 0.1472
2024-05-22 13:51:44 [INFO]: Epoch 160 - training loss: 0.2083, validation loss: 0.1462
2024-05-22 13:51:44 [INFO]: Epoch 161 - training loss: 0.2077, validation loss: 0.1468
2024-05-22 13:51:44 [INFO]: Epoch 162 - training loss: 0.2050, validation loss: 0.1468
2024-05-22 13:51:45 [INFO]: Epoch 163 - training loss: 0.2058, validation loss: 0.1464
2024-05-22 13:51:45 [INFO]: Epoch 164 - training loss: 0.2052, validation loss: 0.1453
2024-05-22 13:51:45 [INFO]: Epoch 165 - training loss: 0.2057, validation loss: 0.1469
2024-05-22 13:51:46 [INFO]: Epoch 166 - training loss: 0.2068, validation loss: 0.1464
2024-05-22 13:51:46 [INFO]: Epoch 167 - training loss: 0.2060, validation loss: 0.1464
2024-05-22 13:51:46 [INFO]: Epoch 168 - training loss: 0.2043, validation loss: 0.1471
2024-05-22 13:51:46 [INFO]: Epoch 169 - training loss: 0.2071, validation loss: 0.1450
2024-05-22 13:51:47 [INFO]: Epoch 170 - training loss: 0.2045, validation loss: 0.1455
2024-05-22 13:51:47 [INFO]: Epoch 171 - training loss: 0.2017, validation loss: 0.1451
2024-05-22 13:51:47 [INFO]: Epoch 172 - training loss: 0.2027, validation loss: 0.1437
2024-05-22 13:51:48 [INFO]: Epoch 173 - training loss: 0.2025, validation loss: 0.1456
2024-05-22 13:51:48 [INFO]: Epoch 174 - training loss: 0.2034, validation loss: 0.1445
2024-05-22 13:51:48 [INFO]: Epoch 175 - training loss: 0.2038, validation loss: 0.1452
2024-05-22 13:51:49 [INFO]: Epoch 176 - training loss: 0.2043, validation loss: 0.1446
2024-05-22 13:51:49 [INFO]: Epoch 177 - training loss: 0.2029, validation loss: 0.1444
2024-05-22 13:51:49 [INFO]: Epoch 178 - training loss: 0.2048, validation loss: 0.1441
2024-05-22 13:51:50 [INFO]: Epoch 179 - training loss: 0.2025, validation loss: 0.1436
2024-05-22 13:51:50 [INFO]: Epoch 180 - training loss: 0.2026, validation loss: 0.1434
2024-05-22 13:51:50 [INFO]: Epoch 181 - training loss: 0.2003, validation loss: 0.1449
2024-05-22 13:51:51 [INFO]: Epoch 182 - training loss: 0.2020, validation loss: 0.1442
2024-05-22 13:51:51 [INFO]: Epoch 183 - training loss: 0.2030, validation loss: 0.1434
2024-05-22 13:51:51 [INFO]: Epoch 184 - training loss: 0.1997, validation loss: 0.1437
2024-05-22 13:51:52 [INFO]: Epoch 185 - training loss: 0.2003, validation loss: 0.1442
2024-05-22 13:51:52 [INFO]: Epoch 186 - training loss: 0.1998, validation loss: 0.1446
2024-05-22 13:51:52 [INFO]: Epoch 187 - training loss: 0.2014, validation loss: 0.1429
2024-05-22 13:51:52 [INFO]: Epoch 188 - training loss: 0.1984, validation loss: 0.1432
2024-05-22 13:51:53 [INFO]: Epoch 189 - training loss: 0.1996, validation loss: 0.1450
2024-05-22 13:51:53 [INFO]: Epoch 190 - training loss: 0.2003, validation loss: 0.1423
2024-05-22 13:51:53 [INFO]: Epoch 191 - training loss: 0.1981, validation loss: 0.1425
2024-05-22 13:51:54 [INFO]: Epoch 192 - training loss: 0.1976, validation loss: 0.1424
2024-05-22 13:51:54 [INFO]: Epoch 193 - training loss: 0.1984, validation loss: 0.1421
2024-05-22 13:51:54 [INFO]: Epoch 194 - training loss: 0.1975, validation loss: 0.1425
2024-05-22 13:51:55 [INFO]: Epoch 195 - training loss: 0.1996, validation loss: 0.1418
2024-05-22 13:51:55 [INFO]: Epoch 196 - training loss: 0.1995, validation loss: 0.1423
2024-05-22 13:51:55 [INFO]: Epoch 197 - training loss: 0.1972, validation loss: 0.1430
2024-05-22 13:51:56 [INFO]: Epoch 198 - training loss: 0.1970, validation loss: 0.1417
2024-05-22 13:51:56 [INFO]: Epoch 199 - training loss: 0.1976, validation loss: 0.1421
2024-05-22 13:51:56 [INFO]: Epoch 200 - training loss: 0.1975, validation loss: 0.1424
2024-05-22 13:51:57 [INFO]: Epoch 201 - training loss: 0.1973, validation loss: 0.1424
2024-05-22 13:51:57 [INFO]: Epoch 202 - training loss: 0.1960, validation loss: 0.1414
2024-05-22 13:51:57 [INFO]: Epoch 203 - training loss: 0.1950, validation loss: 0.1413
2024-05-22 13:51:58 [INFO]: Epoch 204 - training loss: 0.1953, validation loss: 0.1415
2024-05-22 13:51:58 [INFO]: Epoch 205 - training loss: 0.1959, validation loss: 0.1412
2024-05-22 13:51:58 [INFO]: Epoch 206 - training loss: 0.1940, validation loss: 0.1414
2024-05-22 13:51:58 [INFO]: Epoch 207 - training loss: 0.1933, validation loss: 0.1404
2024-05-22 13:51:59 [INFO]: Epoch 208 - training loss: 0.1966, validation loss: 0.1416
2024-05-22 13:51:59 [INFO]: Epoch 209 - training loss: 0.1943, validation loss: 0.1416
2024-05-22 13:51:59 [INFO]: Epoch 210 - training loss: 0.1936, validation loss: 0.1425
2024-05-22 13:52:00 [INFO]: Epoch 211 - training loss: 0.1931, validation loss: 0.1408
2024-05-22 13:52:00 [INFO]: Epoch 212 - training loss: 0.1918, validation loss: 0.1407
2024-05-22 13:52:00 [INFO]: Epoch 213 - training loss: 0.1951, validation loss: 0.1400
2024-05-22 13:52:01 [INFO]: Epoch 214 - training loss: 0.1942, validation loss: 0.1402
2024-05-22 13:52:01 [INFO]: Epoch 215 - training loss: 0.1933, validation loss: 0.1416
2024-05-22 13:52:01 [INFO]: Epoch 216 - training loss: 0.1914, validation loss: 0.1406
2024-05-22 13:52:02 [INFO]: Epoch 217 - training loss: 0.1924, validation loss: 0.1400
2024-05-22 13:52:02 [INFO]: Epoch 218 - training loss: 0.1918, validation loss: 0.1406
2024-05-22 13:52:02 [INFO]: Epoch 219 - training loss: 0.1920, validation loss: 0.1404
2024-05-22 13:52:03 [INFO]: Epoch 220 - training loss: 0.1924, validation loss: 0.1386
2024-05-22 13:52:03 [INFO]: Epoch 221 - training loss: 0.1917, validation loss: 0.1395
2024-05-22 13:52:03 [INFO]: Epoch 222 - training loss: 0.1913, validation loss: 0.1404
2024-05-22 13:52:03 [INFO]: Epoch 223 - training loss: 0.1927, validation loss: 0.1403
2024-05-22 13:52:04 [INFO]: Epoch 224 - training loss: 0.1916, validation loss: 0.1410
2024-05-22 13:52:04 [INFO]: Epoch 225 - training loss: 0.1908, validation loss: 0.1391
2024-05-22 13:52:04 [INFO]: Epoch 226 - training loss: 0.1923, validation loss: 0.1395
2024-05-22 13:52:05 [INFO]: Epoch 227 - training loss: 0.1894, validation loss: 0.1398
2024-05-22 13:52:05 [INFO]: Epoch 228 - training loss: 0.1918, validation loss: 0.1394
2024-05-22 13:52:05 [INFO]: Epoch 229 - training loss: 0.1913, validation loss: 0.1402
2024-05-22 13:52:06 [INFO]: Epoch 230 - training loss: 0.1886, validation loss: 0.1381
2024-05-22 13:52:06 [INFO]: Epoch 231 - training loss: 0.1882, validation loss: 0.1384
2024-05-22 13:52:06 [INFO]: Epoch 232 - training loss: 0.1881, validation loss: 0.1393
2024-05-22 13:52:07 [INFO]: Epoch 233 - training loss: 0.1935, validation loss: 0.1396
2024-05-22 13:52:07 [INFO]: Epoch 234 - training loss: 0.1913, validation loss: 0.1390
2024-05-22 13:52:07 [INFO]: Epoch 235 - training loss: 0.1874, validation loss: 0.1388
2024-05-22 13:52:08 [INFO]: Epoch 236 - training loss: 0.1881, validation loss: 0.1384
2024-05-22 13:52:08 [INFO]: Epoch 237 - training loss: 0.1891, validation loss: 0.1380
2024-05-22 13:52:08 [INFO]: Epoch 238 - training loss: 0.1872, validation loss: 0.1405
2024-05-22 13:52:09 [INFO]: Epoch 239 - training loss: 0.1876, validation loss: 0.1381
2024-05-22 13:52:09 [INFO]: Epoch 240 - training loss: 0.1876, validation loss: 0.1399
2024-05-22 13:52:09 [INFO]: Epoch 241 - training loss: 0.1871, validation loss: 0.1381
2024-05-22 13:52:09 [INFO]: Epoch 242 - training loss: 0.1897, validation loss: 0.1386
2024-05-22 13:52:10 [INFO]: Epoch 243 - training loss: 0.1887, validation loss: 0.1387
2024-05-22 13:52:10 [INFO]: Epoch 244 - training loss: 0.1877, validation loss: 0.1388
2024-05-22 13:52:10 [INFO]: Epoch 245 - training loss: 0.1898, validation loss: 0.1373
2024-05-22 13:52:11 [INFO]: Epoch 246 - training loss: 0.1860, validation loss: 0.1381
2024-05-22 13:52:11 [INFO]: Epoch 247 - training loss: 0.1856, validation loss: 0.1382
2024-05-22 13:52:11 [INFO]: Epoch 248 - training loss: 0.1856, validation loss: 0.1387
2024-05-22 13:52:12 [INFO]: Epoch 249 - training loss: 0.1878, validation loss: 0.1372
2024-05-22 13:52:12 [INFO]: Epoch 250 - training loss: 0.1863, validation loss: 0.1371
2024-05-22 13:52:12 [INFO]: Epoch 251 - training loss: 0.1838, validation loss: 0.1383
2024-05-22 13:52:13 [INFO]: Epoch 252 - training loss: 0.1855, validation loss: 0.1373
2024-05-22 13:52:13 [INFO]: Epoch 253 - training loss: 0.1859, validation loss: 0.1366
2024-05-22 13:52:13 [INFO]: Epoch 254 - training loss: 0.1862, validation loss: 0.1371
2024-05-22 13:52:14 [INFO]: Epoch 255 - training loss: 0.1860, validation loss: 0.1364
2024-05-22 13:52:14 [INFO]: Epoch 256 - training loss: 0.1850, validation loss: 0.1379
2024-05-22 13:52:14 [INFO]: Epoch 257 - training loss: 0.1833, validation loss: 0.1367
2024-05-22 13:52:15 [INFO]: Epoch 258 - training loss: 0.1843, validation loss: 0.1378
2024-05-22 13:52:15 [INFO]: Epoch 259 - training loss: 0.1836, validation loss: 0.1360
2024-05-22 13:52:15 [INFO]: Epoch 260 - training loss: 0.1840, validation loss: 0.1367
2024-05-22 13:52:15 [INFO]: Epoch 261 - training loss: 0.1837, validation loss: 0.1359
2024-05-22 13:52:16 [INFO]: Epoch 262 - training loss: 0.1857, validation loss: 0.1360
2024-05-22 13:52:16 [INFO]: Epoch 263 - training loss: 0.1880, validation loss: 0.1364
2024-05-22 13:52:16 [INFO]: Epoch 264 - training loss: 0.1873, validation loss: 0.1360
2024-05-22 13:52:17 [INFO]: Epoch 265 - training loss: 0.1816, validation loss: 0.1363
2024-05-22 13:52:17 [INFO]: Epoch 266 - training loss: 0.1825, validation loss: 0.1364
2024-05-22 13:52:17 [INFO]: Epoch 267 - training loss: 0.1828, validation loss: 0.1358
2024-05-22 13:52:18 [INFO]: Epoch 268 - training loss: 0.1848, validation loss: 0.1372
2024-05-22 13:52:18 [INFO]: Epoch 269 - training loss: 0.1826, validation loss: 0.1361
2024-05-22 13:52:18 [INFO]: Epoch 270 - training loss: 0.1822, validation loss: 0.1368
2024-05-22 13:52:19 [INFO]: Epoch 271 - training loss: 0.1813, validation loss: 0.1362
2024-05-22 13:52:19 [INFO]: Epoch 272 - training loss: 0.1818, validation loss: 0.1356
2024-05-22 13:52:19 [INFO]: Epoch 273 - training loss: 0.1817, validation loss: 0.1355
2024-05-22 13:52:20 [INFO]: Epoch 274 - training loss: 0.1806, validation loss: 0.1350
2024-05-22 13:52:20 [INFO]: Epoch 275 - training loss: 0.1802, validation loss: 0.1372
2024-05-22 13:52:20 [INFO]: Epoch 276 - training loss: 0.1856, validation loss: 0.1370
2024-05-22 13:52:21 [INFO]: Epoch 277 - training loss: 0.1836, validation loss: 0.1356
2024-05-22 13:52:21 [INFO]: Epoch 278 - training loss: 0.1823, validation loss: 0.1353
2024-05-22 13:52:21 [INFO]: Epoch 279 - training loss: 0.1859, validation loss: 0.1353
2024-05-22 13:52:21 [INFO]: Epoch 280 - training loss: 0.1828, validation loss: 0.1366
2024-05-22 13:52:22 [INFO]: Epoch 281 - training loss: 0.1817, validation loss: 0.1366
2024-05-22 13:52:22 [INFO]: Epoch 282 - training loss: 0.1848, validation loss: 0.1350
2024-05-22 13:52:22 [INFO]: Epoch 283 - training loss: 0.1801, validation loss: 0.1357
2024-05-22 13:52:23 [INFO]: Epoch 284 - training loss: 0.1782, validation loss: 0.1351
2024-05-22 13:52:23 [INFO]: Epoch 285 - training loss: 0.1779, validation loss: 0.1353
2024-05-22 13:52:23 [INFO]: Epoch 286 - training loss: 0.1775, validation loss: 0.1341
2024-05-22 13:52:24 [INFO]: Epoch 287 - training loss: 0.1788, validation loss: 0.1348
2024-05-22 13:52:24 [INFO]: Epoch 288 - training loss: 0.1773, validation loss: 0.1340
2024-05-22 13:52:24 [INFO]: Epoch 289 - training loss: 0.1777, validation loss: 0.1353
2024-05-22 13:52:25 [INFO]: Epoch 290 - training loss: 0.1769, validation loss: 0.1342
2024-05-22 13:52:25 [INFO]: Epoch 291 - training loss: 0.1776, validation loss: 0.1337
2024-05-22 13:52:25 [INFO]: Epoch 292 - training loss: 0.1778, validation loss: 0.1339
2024-05-22 13:52:26 [INFO]: Epoch 293 - training loss: 0.1778, validation loss: 0.1364
2024-05-22 13:52:26 [INFO]: Epoch 294 - training loss: 0.1776, validation loss: 0.1328
2024-05-22 13:52:26 [INFO]: Epoch 295 - training loss: 0.1788, validation loss: 0.1336
2024-05-22 13:52:27 [INFO]: Epoch 296 - training loss: 0.1799, validation loss: 0.1345
2024-05-22 13:52:27 [INFO]: Epoch 297 - training loss: 0.1782, validation loss: 0.1342
2024-05-22 13:52:27 [INFO]: Epoch 298 - training loss: 0.1770, validation loss: 0.1343
2024-05-22 13:52:27 [INFO]: Epoch 299 - training loss: 0.1757, validation loss: 0.1343
2024-05-22 13:52:28 [INFO]: Epoch 300 - training loss: 0.1772, validation loss: 0.1334
2024-05-22 13:52:28 [INFO]: Finished training. The best model is from epoch#294.
2024-05-22 13:52:28 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_air_quality/20240522_T135053/Transformer.pypots
2024-05-22 13:52:28 [INFO]: Transformer on Air-Quality: MAE=0.1562, MSE=0.1265
2024-05-22 13:52:28 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-22 13:52:28 [INFO]: Using the given device: cuda:0
2024-05-22 13:52:28 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240522_T135228
2024-05-22 13:52:28 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_air_quality/20240522_T135228/tensorboard
2024-05-22 13:52:28 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 13:52:29 [INFO]: Epoch 001 - training loss: 0.2888, validation loss: 0.2792
2024-05-22 13:52:29 [INFO]: Epoch 002 - training loss: 0.2287, validation loss: 0.2341
2024-05-22 13:52:30 [INFO]: Epoch 003 - training loss: 0.1972, validation loss: 0.2294
2024-05-22 13:52:30 [INFO]: Epoch 004 - training loss: 0.1652, validation loss: 0.2118
2024-05-22 13:52:31 [INFO]: Epoch 005 - training loss: 0.1785, validation loss: 0.2027
2024-05-22 13:52:31 [INFO]: Epoch 006 - training loss: 0.1675, validation loss: 0.1929
2024-05-22 13:52:32 [INFO]: Epoch 007 - training loss: 0.1681, validation loss: 0.1936
2024-05-22 13:52:32 [INFO]: Epoch 008 - training loss: 0.1441, validation loss: 0.1918
2024-05-22 13:52:33 [INFO]: Epoch 009 - training loss: 0.1573, validation loss: 0.1838
2024-05-22 13:52:34 [INFO]: Epoch 010 - training loss: 0.1475, validation loss: 0.1848
2024-05-22 13:52:34 [INFO]: Epoch 011 - training loss: 0.1378, validation loss: 0.1754
2024-05-22 13:52:35 [INFO]: Epoch 012 - training loss: 0.1364, validation loss: 0.1850
2024-05-22 13:52:35 [INFO]: Epoch 013 - training loss: 0.1470, validation loss: 0.1931
2024-05-22 13:52:36 [INFO]: Epoch 014 - training loss: 0.1345, validation loss: 0.1806
2024-05-22 13:52:36 [INFO]: Epoch 015 - training loss: 0.1368, validation loss: 0.1811
2024-05-22 13:52:37 [INFO]: Epoch 016 - training loss: 0.1335, validation loss: 0.1800
2024-05-22 13:52:37 [INFO]: Epoch 017 - training loss: 0.1098, validation loss: 0.1714
2024-05-22 13:52:38 [INFO]: Epoch 018 - training loss: 0.1391, validation loss: 0.1781
2024-05-22 13:52:38 [INFO]: Epoch 019 - training loss: 0.1288, validation loss: 0.1794
2024-05-22 13:52:39 [INFO]: Epoch 020 - training loss: 0.1253, validation loss: 0.1725
2024-05-22 13:52:39 [INFO]: Epoch 021 - training loss: 0.1215, validation loss: 0.1740
2024-05-22 13:52:40 [INFO]: Epoch 022 - training loss: 0.1133, validation loss: 0.1748
2024-05-22 13:52:40 [INFO]: Epoch 023 - training loss: 0.1179, validation loss: 0.1730
2024-05-22 13:52:41 [INFO]: Epoch 024 - training loss: 0.1105, validation loss: 0.1737
2024-05-22 13:52:41 [INFO]: Epoch 025 - training loss: 0.1311, validation loss: 0.1864
2024-05-22 13:52:42 [INFO]: Epoch 026 - training loss: 0.1238, validation loss: 0.1743
2024-05-22 13:52:42 [INFO]: Epoch 027 - training loss: 0.1355, validation loss: 0.1766
2024-05-22 13:52:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 13:52:42 [INFO]: Finished training. The best model is from epoch#17.
2024-05-22 13:52:43 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_air_quality/20240522_T135228/TimesNet.pypots
2024-05-22 13:52:43 [INFO]: TimesNet on Air-Quality: MAE=0.1696, MSE=0.1660
2024-05-22 13:52:43 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-22 13:52:43 [INFO]: Using the given device: cuda:0
2024-05-22 13:52:43 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243
2024-05-22 13:52:43 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/tensorboard
2024-05-22 13:52:43 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 13:53:00 [INFO]: Epoch 001 - training loss: 0.4908, validation loss: 0.3672
2024-05-22 13:53:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch1_loss0.36717950999736787.pypots
2024-05-22 13:53:16 [INFO]: Epoch 002 - training loss: 0.2681, validation loss: 0.2911
2024-05-22 13:53:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch2_loss0.29105560183525087.pypots
2024-05-22 13:53:33 [INFO]: Epoch 003 - training loss: 0.2668, validation loss: 0.2610
2024-05-22 13:53:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch3_loss0.26099717170000075.pypots
2024-05-22 13:53:50 [INFO]: Epoch 004 - training loss: 0.2652, validation loss: 0.2336
2024-05-22 13:53:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch4_loss0.23357972055673598.pypots
2024-05-22 13:54:07 [INFO]: Epoch 005 - training loss: 0.2191, validation loss: 0.2078
2024-05-22 13:54:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch5_loss0.20784779340028764.pypots
2024-05-22 13:54:24 [INFO]: Epoch 006 - training loss: 0.2309, validation loss: 0.1853
2024-05-22 13:54:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch6_loss0.18526486605405806.pypots
2024-05-22 13:54:41 [INFO]: Epoch 007 - training loss: 0.1891, validation loss: 0.1839
2024-05-22 13:54:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch7_loss0.18390968441963196.pypots
2024-05-22 13:54:57 [INFO]: Epoch 008 - training loss: 0.1974, validation loss: 0.1754
2024-05-22 13:54:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch8_loss0.17544802129268647.pypots
2024-05-22 13:55:14 [INFO]: Epoch 009 - training loss: 0.1892, validation loss: 0.1741
2024-05-22 13:55:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch9_loss0.17405393570661545.pypots
2024-05-22 13:55:31 [INFO]: Epoch 010 - training loss: 0.1984, validation loss: 0.1770
2024-05-22 13:55:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch10_loss0.17696937769651414.pypots
2024-05-22 13:55:48 [INFO]: Epoch 011 - training loss: 0.1659, validation loss: 0.1526
2024-05-22 13:55:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch11_loss0.15264946818351746.pypots
2024-05-22 13:56:05 [INFO]: Epoch 012 - training loss: 0.1707, validation loss: 0.1526
2024-05-22 13:56:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch12_loss0.1526040568947792.pypots
2024-05-22 13:56:22 [INFO]: Epoch 013 - training loss: 0.1667, validation loss: 0.1535
2024-05-22 13:56:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch13_loss0.15349970310926436.pypots
2024-05-22 13:56:38 [INFO]: Epoch 014 - training loss: 0.1696, validation loss: 0.1475
2024-05-22 13:56:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch14_loss0.1475205808877945.pypots
2024-05-22 13:56:55 [INFO]: Epoch 015 - training loss: 0.1557, validation loss: 0.1508
2024-05-22 13:56:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch15_loss0.15077899545431137.pypots
2024-05-22 13:57:12 [INFO]: Epoch 016 - training loss: 0.1471, validation loss: 0.1426
2024-05-22 13:57:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch16_loss0.1425913006067276.pypots
2024-05-22 13:57:29 [INFO]: Epoch 017 - training loss: 0.1793, validation loss: 0.1554
2024-05-22 13:57:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch17_loss0.15543871372938156.pypots
2024-05-22 13:57:46 [INFO]: Epoch 018 - training loss: 0.1769, validation loss: 0.1427
2024-05-22 13:57:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch18_loss0.1427493527531624.pypots
2024-05-22 13:58:03 [INFO]: Epoch 019 - training loss: 0.1560, validation loss: 0.1343
2024-05-22 13:58:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch19_loss0.13425461947917938.pypots
2024-05-22 13:58:19 [INFO]: Epoch 020 - training loss: 0.1668, validation loss: 0.1422
2024-05-22 13:58:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch20_loss0.14218506664037706.pypots
2024-05-22 13:58:36 [INFO]: Epoch 021 - training loss: 0.1472, validation loss: 0.1335
2024-05-22 13:58:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch21_loss0.13349947556853295.pypots
2024-05-22 13:58:53 [INFO]: Epoch 022 - training loss: 0.1612, validation loss: 0.1380
2024-05-22 13:58:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch22_loss0.13804128319025039.pypots
2024-05-22 13:59:10 [INFO]: Epoch 023 - training loss: 0.1413, validation loss: 0.1337
2024-05-22 13:59:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch23_loss0.13374361842870713.pypots
2024-05-22 13:59:27 [INFO]: Epoch 024 - training loss: 0.1437, validation loss: 0.1432
2024-05-22 13:59:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch24_loss0.14321483746171.pypots
2024-05-22 13:59:44 [INFO]: Epoch 025 - training loss: 0.1474, validation loss: 0.1312
2024-05-22 13:59:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch25_loss0.13118960186839104.pypots
2024-05-22 14:00:00 [INFO]: Epoch 026 - training loss: 0.1475, validation loss: 0.1278
2024-05-22 14:00:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch26_loss0.12775769904255868.pypots
2024-05-22 14:00:17 [INFO]: Epoch 027 - training loss: 0.1448, validation loss: 0.1268
2024-05-22 14:00:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch27_loss0.12683139070868493.pypots
2024-05-22 14:00:34 [INFO]: Epoch 028 - training loss: 0.1310, validation loss: 0.1293
2024-05-22 14:00:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch28_loss0.1293058656156063.pypots
2024-05-22 14:00:51 [INFO]: Epoch 029 - training loss: 0.1631, validation loss: 0.1316
2024-05-22 14:00:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch29_loss0.13159167319536208.pypots
2024-05-22 14:01:08 [INFO]: Epoch 030 - training loss: 0.1323, validation loss: 0.1301
2024-05-22 14:01:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch30_loss0.13014207780361176.pypots
2024-05-22 14:01:25 [INFO]: Epoch 031 - training loss: 0.1365, validation loss: 0.1279
2024-05-22 14:01:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch31_loss0.12790102511644363.pypots
2024-05-22 14:01:41 [INFO]: Epoch 032 - training loss: 0.1327, validation loss: 0.1250
2024-05-22 14:01:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch32_loss0.12499701380729675.pypots
2024-05-22 14:01:58 [INFO]: Epoch 033 - training loss: 0.1263, validation loss: 0.1239
2024-05-22 14:01:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch33_loss0.12391011044383049.pypots
2024-05-22 14:02:15 [INFO]: Epoch 034 - training loss: 0.1302, validation loss: 0.1214
2024-05-22 14:02:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch34_loss0.12136558890342712.pypots
2024-05-22 14:02:32 [INFO]: Epoch 035 - training loss: 0.1347, validation loss: 0.1229
2024-05-22 14:02:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch35_loss0.12293023690581321.pypots
2024-05-22 14:02:49 [INFO]: Epoch 036 - training loss: 0.1432, validation loss: 0.1218
2024-05-22 14:02:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch36_loss0.12177441269159317.pypots
2024-05-22 14:03:06 [INFO]: Epoch 037 - training loss: 0.1293, validation loss: 0.1262
2024-05-22 14:03:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch37_loss0.12617705687880515.pypots
2024-05-22 14:03:22 [INFO]: Epoch 038 - training loss: 0.1333, validation loss: 0.1221
2024-05-22 14:03:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch38_loss0.12205749079585075.pypots
2024-05-22 14:03:39 [INFO]: Epoch 039 - training loss: 0.1338, validation loss: 0.1224
2024-05-22 14:03:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch39_loss0.12244118973612786.pypots
2024-05-22 14:03:56 [INFO]: Epoch 040 - training loss: 0.1371, validation loss: 0.1212
2024-05-22 14:03:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch40_loss0.12119395658373833.pypots
2024-05-22 14:04:13 [INFO]: Epoch 041 - training loss: 0.1264, validation loss: 0.1247
2024-05-22 14:04:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch41_loss0.12472795471549034.pypots
2024-05-22 14:04:30 [INFO]: Epoch 042 - training loss: 0.1260, validation loss: 0.1172
2024-05-22 14:04:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch42_loss0.1171664573252201.pypots
2024-05-22 14:04:47 [INFO]: Epoch 043 - training loss: 0.1313, validation loss: 0.1238
2024-05-22 14:04:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch43_loss0.1238128550350666.pypots
2024-05-22 14:05:03 [INFO]: Epoch 044 - training loss: 0.1280, validation loss: 0.1219
2024-05-22 14:05:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch44_loss0.12185400873422622.pypots
2024-05-22 14:05:20 [INFO]: Epoch 045 - training loss: 0.1311, validation loss: 0.1208
2024-05-22 14:05:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch45_loss0.12077085971832276.pypots
2024-05-22 14:05:37 [INFO]: Epoch 046 - training loss: 0.1316, validation loss: 0.1199
2024-05-22 14:05:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch46_loss0.11993303298950195.pypots
2024-05-22 14:05:54 [INFO]: Epoch 047 - training loss: 0.1165, validation loss: 0.1149
2024-05-22 14:05:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch47_loss0.11485436409711838.pypots
2024-05-22 14:06:11 [INFO]: Epoch 048 - training loss: 0.1320, validation loss: 0.1194
2024-05-22 14:06:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch48_loss0.11935712844133377.pypots
2024-05-22 14:06:27 [INFO]: Epoch 049 - training loss: 0.1373, validation loss: 0.1146
2024-05-22 14:06:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch49_loss0.11462145820260047.pypots
2024-05-22 14:06:44 [INFO]: Epoch 050 - training loss: 0.1236, validation loss: 0.1152
2024-05-22 14:06:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch50_loss0.11521109119057656.pypots
2024-05-22 14:07:01 [INFO]: Epoch 051 - training loss: 0.1301, validation loss: 0.1134
2024-05-22 14:07:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch51_loss0.11336456388235092.pypots
2024-05-22 14:07:18 [INFO]: Epoch 052 - training loss: 0.1221, validation loss: 0.1136
2024-05-22 14:07:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch52_loss0.11355456486344337.pypots
2024-05-22 14:07:35 [INFO]: Epoch 053 - training loss: 0.1373, validation loss: 0.1153
2024-05-22 14:07:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch53_loss0.1153406023979187.pypots
2024-05-22 14:07:52 [INFO]: Epoch 054 - training loss: 0.1235, validation loss: 0.1212
2024-05-22 14:07:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch54_loss0.12121715918183326.pypots
2024-05-22 14:08:08 [INFO]: Epoch 055 - training loss: 0.1365, validation loss: 0.1128
2024-05-22 14:08:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch55_loss0.11280397325754166.pypots
2024-05-22 14:08:25 [INFO]: Epoch 056 - training loss: 0.1253, validation loss: 0.1148
2024-05-22 14:08:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch56_loss0.1147757701575756.pypots
2024-05-22 14:08:42 [INFO]: Epoch 057 - training loss: 0.1215, validation loss: 0.1162
2024-05-22 14:08:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch57_loss0.11620410084724427.pypots
2024-05-22 14:08:59 [INFO]: Epoch 058 - training loss: 0.1383, validation loss: 0.1150
2024-05-22 14:08:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch58_loss0.11495712324976921.pypots
2024-05-22 14:09:16 [INFO]: Epoch 059 - training loss: 0.1203, validation loss: 0.1103
2024-05-22 14:09:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch59_loss0.11028005480766297.pypots
2024-05-22 14:09:33 [INFO]: Epoch 060 - training loss: 0.1380, validation loss: 0.1106
2024-05-22 14:09:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch60_loss0.11063235923647881.pypots
2024-05-22 14:09:49 [INFO]: Epoch 061 - training loss: 0.1263, validation loss: 0.1093
2024-05-22 14:09:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch61_loss0.10927804857492447.pypots
2024-05-22 14:10:06 [INFO]: Epoch 062 - training loss: 0.1134, validation loss: 0.1129
2024-05-22 14:10:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch62_loss0.11289590522646904.pypots
2024-05-22 14:10:23 [INFO]: Epoch 063 - training loss: 0.1133, validation loss: 0.1108
2024-05-22 14:10:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch63_loss0.11083777770400047.pypots
2024-05-22 14:10:40 [INFO]: Epoch 064 - training loss: 0.1264, validation loss: 0.1101
2024-05-22 14:10:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch64_loss0.11013333722949029.pypots
2024-05-22 14:10:58 [INFO]: Epoch 065 - training loss: 0.1167, validation loss: 0.1083
2024-05-22 14:10:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch65_loss0.10826551988720894.pypots
2024-05-22 14:11:16 [INFO]: Epoch 066 - training loss: 0.1252, validation loss: 0.1093
2024-05-22 14:11:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch66_loss0.1092948004603386.pypots
2024-05-22 14:11:33 [INFO]: Epoch 067 - training loss: 0.1205, validation loss: 0.1127
2024-05-22 14:11:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch67_loss0.11265836283564568.pypots
2024-05-22 14:11:50 [INFO]: Epoch 068 - training loss: 0.1267, validation loss: 0.1123
2024-05-22 14:11:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch68_loss0.11230987831950187.pypots
2024-05-22 14:12:08 [INFO]: Epoch 069 - training loss: 0.1284, validation loss: 0.1112
2024-05-22 14:12:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch69_loss0.11115975603461266.pypots
2024-05-22 14:12:25 [INFO]: Epoch 070 - training loss: 0.1196, validation loss: 0.1146
2024-05-22 14:12:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch70_loss0.11463072523474693.pypots
2024-05-22 14:12:43 [INFO]: Epoch 071 - training loss: 0.1276, validation loss: 0.1091
2024-05-22 14:12:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch71_loss0.1090885043144226.pypots
2024-05-22 14:13:00 [INFO]: Epoch 072 - training loss: 0.1250, validation loss: 0.1099
2024-05-22 14:13:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch72_loss0.10986801013350486.pypots
2024-05-22 14:13:16 [INFO]: Epoch 073 - training loss: 0.1230, validation loss: 0.1079
2024-05-22 14:13:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch73_loss0.1079163484275341.pypots
2024-05-22 14:13:34 [INFO]: Epoch 074 - training loss: 0.1277, validation loss: 0.1089
2024-05-22 14:13:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch74_loss0.10887260362505913.pypots
2024-05-22 14:13:51 [INFO]: Epoch 075 - training loss: 0.1073, validation loss: 0.1052
2024-05-22 14:13:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch75_loss0.10515055432915688.pypots
2024-05-22 14:14:08 [INFO]: Epoch 076 - training loss: 0.1107, validation loss: 0.1083
2024-05-22 14:14:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch76_loss0.10828699618577957.pypots
2024-05-22 14:14:25 [INFO]: Epoch 077 - training loss: 0.1269, validation loss: 0.1131
2024-05-22 14:14:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch77_loss0.11309433802962303.pypots
2024-05-22 14:14:42 [INFO]: Epoch 078 - training loss: 0.1138, validation loss: 0.1098
2024-05-22 14:14:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch78_loss0.10976926982402802.pypots
2024-05-22 14:14:59 [INFO]: Epoch 079 - training loss: 0.1233, validation loss: 0.1122
2024-05-22 14:14:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch79_loss0.11217665895819665.pypots
2024-05-22 14:15:16 [INFO]: Epoch 080 - training loss: 0.1192, validation loss: 0.1090
2024-05-22 14:15:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch80_loss0.10897131487727166.pypots
2024-05-22 14:15:33 [INFO]: Epoch 081 - training loss: 0.1152, validation loss: 0.1076
2024-05-22 14:15:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch81_loss0.10763545408844948.pypots
2024-05-22 14:15:50 [INFO]: Epoch 082 - training loss: 0.1226, validation loss: 0.1087
2024-05-22 14:15:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch82_loss0.1086897075176239.pypots
2024-05-22 14:16:08 [INFO]: Epoch 083 - training loss: 0.1081, validation loss: 0.1058
2024-05-22 14:16:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch83_loss0.1058125913143158.pypots
2024-05-22 14:16:25 [INFO]: Epoch 084 - training loss: 0.1248, validation loss: 0.1080
2024-05-22 14:16:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch84_loss0.10804782435297966.pypots
2024-05-22 14:16:42 [INFO]: Epoch 085 - training loss: 0.1360, validation loss: 0.1138
2024-05-22 14:16:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI_epoch85_loss0.11376962885260582.pypots
2024-05-22 14:16:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:16:42 [INFO]: Finished training. The best model is from epoch#75.
2024-05-22 14:16:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_air_quality/20240522_T135243/CSDI.pypots
2024-05-22 14:19:03 [INFO]: CSDI on Air-Quality: MAE=0.1137, MSE=0.2362
2024-05-22 14:19:04 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-22 14:19:04 [INFO]: Using the given device: cuda:0
2024-05-22 14:19:04 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240522_T141904
2024-05-22 14:19:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_air_quality/20240522_T141904/tensorboard
2024-05-22 14:19:04 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 14:19:04 [INFO]: Epoch 001 - training loss: 63995.9437, validation loss: 0.6509
2024-05-22 14:19:04 [INFO]: Epoch 002 - training loss: 42032.6411, validation loss: 0.5666
2024-05-22 14:19:05 [INFO]: Epoch 003 - training loss: 41768.5417, validation loss: 0.5342
2024-05-22 14:19:05 [INFO]: Epoch 004 - training loss: 41630.0796, validation loss: 0.4746
2024-05-22 14:19:05 [INFO]: Epoch 005 - training loss: 41559.2661, validation loss: 0.4210
2024-05-22 14:19:06 [INFO]: Epoch 006 - training loss: 41489.9634, validation loss: 0.4004
2024-05-22 14:19:06 [INFO]: Epoch 007 - training loss: 41470.2504, validation loss: 0.3817
2024-05-22 14:19:06 [INFO]: Epoch 008 - training loss: 41421.9854, validation loss: 0.3930
2024-05-22 14:19:07 [INFO]: Epoch 009 - training loss: 41442.3232, validation loss: 0.3827
2024-05-22 14:19:07 [INFO]: Epoch 010 - training loss: 41379.8780, validation loss: 0.3327
2024-05-22 14:19:07 [INFO]: Epoch 011 - training loss: 41342.8488, validation loss: 0.3274
2024-05-22 14:19:08 [INFO]: Epoch 012 - training loss: 41336.4290, validation loss: 0.3689
2024-05-22 14:19:08 [INFO]: Epoch 013 - training loss: 41373.3536, validation loss: 0.3280
2024-05-22 14:19:08 [INFO]: Epoch 014 - training loss: 41321.4657, validation loss: 0.3335
2024-05-22 14:19:09 [INFO]: Epoch 015 - training loss: 41310.4612, validation loss: 0.3129
2024-05-22 14:19:09 [INFO]: Epoch 016 - training loss: 41312.0787, validation loss: 0.3092
2024-05-22 14:19:09 [INFO]: Epoch 017 - training loss: 41335.4515, validation loss: 0.3017
2024-05-22 14:19:10 [INFO]: Epoch 018 - training loss: 41285.2121, validation loss: 0.3049
2024-05-22 14:19:10 [INFO]: Epoch 019 - training loss: 41263.6143, validation loss: 0.2908
2024-05-22 14:19:10 [INFO]: Epoch 020 - training loss: 41256.1931, validation loss: 0.2851
2024-05-22 14:19:11 [INFO]: Epoch 021 - training loss: 41254.6576, validation loss: 0.2888
2024-05-22 14:19:11 [INFO]: Epoch 022 - training loss: 41255.8673, validation loss: 0.2816
2024-05-22 14:19:11 [INFO]: Epoch 023 - training loss: 41250.4931, validation loss: 0.2826
2024-05-22 14:19:12 [INFO]: Epoch 024 - training loss: 41246.6270, validation loss: 0.2888
2024-05-22 14:19:12 [INFO]: Epoch 025 - training loss: 41238.6237, validation loss: 0.2756
2024-05-22 14:19:12 [INFO]: Epoch 026 - training loss: 41242.0285, validation loss: 0.2760
2024-05-22 14:19:13 [INFO]: Epoch 027 - training loss: 41248.2125, validation loss: 0.2969
2024-05-22 14:19:13 [INFO]: Epoch 028 - training loss: 41278.9084, validation loss: 0.2810
2024-05-22 14:19:13 [INFO]: Epoch 029 - training loss: 41233.3728, validation loss: 0.2752
2024-05-22 14:19:14 [INFO]: Epoch 030 - training loss: 41235.4090, validation loss: 0.2772
2024-05-22 14:19:14 [INFO]: Epoch 031 - training loss: 41225.7802, validation loss: 0.2719
2024-05-22 14:19:14 [INFO]: Epoch 032 - training loss: 41209.4285, validation loss: 0.2662
2024-05-22 14:19:15 [INFO]: Epoch 033 - training loss: 41198.2231, validation loss: 0.2663
2024-05-22 14:19:15 [INFO]: Epoch 034 - training loss: 41199.0676, validation loss: 0.2543
2024-05-22 14:19:15 [INFO]: Epoch 035 - training loss: 41208.8066, validation loss: 0.2621
2024-05-22 14:19:16 [INFO]: Epoch 036 - training loss: 41215.9304, validation loss: 0.2704
2024-05-22 14:19:16 [INFO]: Epoch 037 - training loss: 41199.4604, validation loss: 0.3049
2024-05-22 14:19:16 [INFO]: Epoch 038 - training loss: 41319.0298, validation loss: 0.2947
2024-05-22 14:19:17 [INFO]: Epoch 039 - training loss: 41237.1113, validation loss: 0.2767
2024-05-22 14:19:17 [INFO]: Epoch 040 - training loss: 41238.5431, validation loss: 0.2696
2024-05-22 14:19:17 [INFO]: Epoch 041 - training loss: 41201.3763, validation loss: 0.2554
2024-05-22 14:19:18 [INFO]: Epoch 042 - training loss: 41186.6231, validation loss: 0.2544
2024-05-22 14:19:18 [INFO]: Epoch 043 - training loss: 41182.4932, validation loss: 0.2533
2024-05-22 14:19:18 [INFO]: Epoch 044 - training loss: 41175.6114, validation loss: 0.2501
2024-05-22 14:19:19 [INFO]: Epoch 045 - training loss: 41174.8618, validation loss: 0.2476
2024-05-22 14:19:19 [INFO]: Epoch 046 - training loss: 41171.3678, validation loss: 0.2541
2024-05-22 14:19:19 [INFO]: Epoch 047 - training loss: 41169.0894, validation loss: 0.2495
2024-05-22 14:19:20 [INFO]: Epoch 048 - training loss: 41167.2704, validation loss: 0.2467
2024-05-22 14:19:20 [INFO]: Epoch 049 - training loss: 41178.0422, validation loss: 0.2489
2024-05-22 14:19:20 [INFO]: Epoch 050 - training loss: 41188.8861, validation loss: 0.2653
2024-05-22 14:19:21 [INFO]: Epoch 051 - training loss: 41179.9877, validation loss: 0.2647
2024-05-22 14:19:21 [INFO]: Epoch 052 - training loss: 41167.6221, validation loss: 0.2421
2024-05-22 14:19:21 [INFO]: Epoch 053 - training loss: 41167.4372, validation loss: 0.2469
2024-05-22 14:19:22 [INFO]: Epoch 054 - training loss: 41163.3079, validation loss: 0.2423
2024-05-22 14:19:22 [INFO]: Epoch 055 - training loss: 41165.6892, validation loss: 0.2478
2024-05-22 14:19:22 [INFO]: Epoch 056 - training loss: 41188.8223, validation loss: 0.2491
2024-05-22 14:19:23 [INFO]: Epoch 057 - training loss: 41176.5919, validation loss: 0.2567
2024-05-22 14:19:23 [INFO]: Epoch 058 - training loss: 41179.2824, validation loss: 0.2610
2024-05-22 14:19:23 [INFO]: Epoch 059 - training loss: 41208.1955, validation loss: 0.2604
2024-05-22 14:19:24 [INFO]: Epoch 060 - training loss: 41180.6453, validation loss: 0.2563
2024-05-22 14:19:24 [INFO]: Epoch 061 - training loss: 41158.5061, validation loss: 0.2445
2024-05-22 14:19:24 [INFO]: Epoch 062 - training loss: 41151.9688, validation loss: 0.2404
2024-05-22 14:19:25 [INFO]: Epoch 063 - training loss: 41146.7290, validation loss: 0.2410
2024-05-22 14:19:25 [INFO]: Epoch 064 - training loss: 41144.6764, validation loss: 0.2434
2024-05-22 14:19:25 [INFO]: Epoch 065 - training loss: 41149.1557, validation loss: 0.2399
2024-05-22 14:19:26 [INFO]: Epoch 066 - training loss: 41145.3555, validation loss: 0.2370
2024-05-22 14:19:26 [INFO]: Epoch 067 - training loss: 41148.9023, validation loss: 0.2552
2024-05-22 14:19:26 [INFO]: Epoch 068 - training loss: 41151.1772, validation loss: 0.2498
2024-05-22 14:19:27 [INFO]: Epoch 069 - training loss: 41155.4997, validation loss: 0.2660
2024-05-22 14:19:27 [INFO]: Epoch 070 - training loss: 41151.3170, validation loss: 0.2606
2024-05-22 14:19:27 [INFO]: Epoch 071 - training loss: 41159.4016, validation loss: 0.2500
2024-05-22 14:19:28 [INFO]: Epoch 072 - training loss: 41142.5775, validation loss: 0.2480
2024-05-22 14:19:28 [INFO]: Epoch 073 - training loss: 41135.9317, validation loss: 0.2361
2024-05-22 14:19:28 [INFO]: Epoch 074 - training loss: 41131.4288, validation loss: 0.2464
2024-05-22 14:19:29 [INFO]: Epoch 075 - training loss: 41219.4878, validation loss: 0.2663
2024-05-22 14:19:29 [INFO]: Epoch 076 - training loss: 41272.8876, validation loss: 0.2653
2024-05-22 14:19:29 [INFO]: Epoch 077 - training loss: 41238.7620, validation loss: 0.2550
2024-05-22 14:19:30 [INFO]: Epoch 078 - training loss: 41199.7245, validation loss: 0.2676
2024-05-22 14:19:30 [INFO]: Epoch 079 - training loss: 41175.8306, validation loss: 0.2404
2024-05-22 14:19:30 [INFO]: Epoch 080 - training loss: 41167.4009, validation loss: 0.2305
2024-05-22 14:19:31 [INFO]: Epoch 081 - training loss: 41185.2601, validation loss: 0.2397
2024-05-22 14:19:31 [INFO]: Epoch 082 - training loss: 41171.0499, validation loss: 0.2450
2024-05-22 14:19:31 [INFO]: Epoch 083 - training loss: 41171.6902, validation loss: 0.2490
2024-05-22 14:19:32 [INFO]: Epoch 084 - training loss: 41167.6843, validation loss: 0.2406
2024-05-22 14:19:32 [INFO]: Epoch 085 - training loss: 41149.9129, validation loss: 0.2329
2024-05-22 14:19:32 [INFO]: Epoch 086 - training loss: 41148.1347, validation loss: 0.2325
2024-05-22 14:19:33 [INFO]: Epoch 087 - training loss: 41143.0302, validation loss: 0.2312
2024-05-22 14:19:33 [INFO]: Epoch 088 - training loss: 41132.9097, validation loss: 0.2344
2024-05-22 14:19:33 [INFO]: Epoch 089 - training loss: 41132.6089, validation loss: 0.2323
2024-05-22 14:19:34 [INFO]: Epoch 090 - training loss: 41130.6989, validation loss: 0.2303
2024-05-22 14:19:34 [INFO]: Epoch 091 - training loss: 41134.3006, validation loss: 0.2573
2024-05-22 14:19:34 [INFO]: Epoch 092 - training loss: 41153.1589, validation loss: 0.2404
2024-05-22 14:19:35 [INFO]: Epoch 093 - training loss: 41142.0088, validation loss: 0.2411
2024-05-22 14:19:35 [INFO]: Epoch 094 - training loss: 41134.0641, validation loss: 0.2286
2024-05-22 14:19:35 [INFO]: Epoch 095 - training loss: 41143.4962, validation loss: 0.2273
2024-05-22 14:19:36 [INFO]: Epoch 096 - training loss: 41145.2543, validation loss: 0.2462
2024-05-22 14:19:36 [INFO]: Epoch 097 - training loss: 41148.0297, validation loss: 0.2459
2024-05-22 14:19:36 [INFO]: Epoch 098 - training loss: 41158.5260, validation loss: 0.2513
2024-05-22 14:19:37 [INFO]: Epoch 099 - training loss: 41166.2875, validation loss: 0.2241
2024-05-22 14:19:37 [INFO]: Epoch 100 - training loss: 41143.6806, validation loss: 0.2318
2024-05-22 14:19:37 [INFO]: Epoch 101 - training loss: 41126.6988, validation loss: 0.2303
2024-05-22 14:19:38 [INFO]: Epoch 102 - training loss: 41122.9129, validation loss: 0.2270
2024-05-22 14:19:38 [INFO]: Epoch 103 - training loss: 41120.7025, validation loss: 0.2243
2024-05-22 14:19:38 [INFO]: Epoch 104 - training loss: 41119.0868, validation loss: 0.2216
2024-05-22 14:19:39 [INFO]: Epoch 105 - training loss: 41120.3189, validation loss: 0.2296
2024-05-22 14:19:39 [INFO]: Epoch 106 - training loss: 41122.3112, validation loss: 0.2271
2024-05-22 14:19:39 [INFO]: Epoch 107 - training loss: 41119.3385, validation loss: 0.2312
2024-05-22 14:19:40 [INFO]: Epoch 108 - training loss: 41120.9401, validation loss: 0.2227
2024-05-22 14:19:40 [INFO]: Epoch 109 - training loss: 41117.0493, validation loss: 0.2276
2024-05-22 14:19:40 [INFO]: Epoch 110 - training loss: 41113.6698, validation loss: 0.2271
2024-05-22 14:19:41 [INFO]: Epoch 111 - training loss: 41109.5661, validation loss: 0.2258
2024-05-22 14:19:41 [INFO]: Epoch 112 - training loss: 41119.2623, validation loss: 0.2255
2024-05-22 14:19:41 [INFO]: Epoch 113 - training loss: 41123.6366, validation loss: 0.2320
2024-05-22 14:19:42 [INFO]: Epoch 114 - training loss: 41120.3083, validation loss: 0.2425
2024-05-22 14:19:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:19:42 [INFO]: Finished training. The best model is from epoch#104.
2024-05-22 14:19:42 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_air_quality/20240522_T141904/GPVAE.pypots
2024-05-22 14:19:42 [INFO]: GP-VAE on Air-Quality: MAE=0.2746, MSE=0.2332
2024-05-22 14:19:42 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-22 14:19:42 [INFO]: Using the given device: cuda:0
2024-05-22 14:19:43 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240522_T141942
2024-05-22 14:19:43 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_air_quality/20240522_T141942/tensorboard
2024-05-22 14:19:43 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 14:19:47 [INFO]: Epoch 001 - generator training loss: 0.6344, discriminator training loss: 0.2920, validation loss: 0.5173
2024-05-22 14:19:51 [INFO]: Epoch 002 - generator training loss: 0.2951, discriminator training loss: 0.0674, validation loss: 0.3929
2024-05-22 14:19:56 [INFO]: Epoch 003 - generator training loss: 0.2150, discriminator training loss: 0.0637, validation loss: 0.3265
2024-05-22 14:20:00 [INFO]: Epoch 004 - generator training loss: 0.1780, discriminator training loss: 0.0621, validation loss: 0.2862
2024-05-22 14:20:04 [INFO]: Epoch 005 - generator training loss: 0.1532, discriminator training loss: 0.0620, validation loss: 0.2618
2024-05-22 14:20:08 [INFO]: Epoch 006 - generator training loss: 0.1341, discriminator training loss: 0.0623, validation loss: 0.2428
2024-05-22 14:20:12 [INFO]: Epoch 007 - generator training loss: 0.1215, discriminator training loss: 0.0608, validation loss: 0.2303
2024-05-22 14:20:16 [INFO]: Epoch 008 - generator training loss: 0.1110, discriminator training loss: 0.0605, validation loss: 0.2205
2024-05-22 14:20:20 [INFO]: Epoch 009 - generator training loss: 0.1028, discriminator training loss: 0.0594, validation loss: 0.2128
2024-05-22 14:20:24 [INFO]: Epoch 010 - generator training loss: 0.0950, discriminator training loss: 0.0584, validation loss: 0.2062
2024-05-22 14:20:28 [INFO]: Epoch 011 - generator training loss: 0.0883, discriminator training loss: 0.0575, validation loss: 0.2006
2024-05-22 14:20:32 [INFO]: Epoch 012 - generator training loss: 0.0846, discriminator training loss: 0.0561, validation loss: 0.1963
2024-05-22 14:20:36 [INFO]: Epoch 013 - generator training loss: 0.0811, discriminator training loss: 0.0547, validation loss: 0.1921
2024-05-22 14:20:40 [INFO]: Epoch 014 - generator training loss: 0.0776, discriminator training loss: 0.0530, validation loss: 0.1883
2024-05-22 14:20:44 [INFO]: Epoch 015 - generator training loss: 0.0761, discriminator training loss: 0.0512, validation loss: 0.1860
2024-05-22 14:20:48 [INFO]: Epoch 016 - generator training loss: 0.0742, discriminator training loss: 0.0493, validation loss: 0.1824
2024-05-22 14:20:52 [INFO]: Epoch 017 - generator training loss: 0.0732, discriminator training loss: 0.0479, validation loss: 0.1804
2024-05-22 14:20:56 [INFO]: Epoch 018 - generator training loss: 0.0697, discriminator training loss: 0.0466, validation loss: 0.1776
2024-05-22 14:21:00 [INFO]: Epoch 019 - generator training loss: 0.0679, discriminator training loss: 0.0458, validation loss: 0.1766
2024-05-22 14:21:04 [INFO]: Epoch 020 - generator training loss: 0.0666, discriminator training loss: 0.0451, validation loss: 0.1740
2024-05-22 14:21:08 [INFO]: Epoch 021 - generator training loss: 0.0646, discriminator training loss: 0.0444, validation loss: 0.1735
2024-05-22 14:21:12 [INFO]: Epoch 022 - generator training loss: 0.0649, discriminator training loss: 0.0439, validation loss: 0.1711
2024-05-22 14:21:16 [INFO]: Epoch 023 - generator training loss: 0.0641, discriminator training loss: 0.0428, validation loss: 0.1692
2024-05-22 14:21:20 [INFO]: Epoch 024 - generator training loss: 0.0613, discriminator training loss: 0.0418, validation loss: 0.1683
2024-05-22 14:21:24 [INFO]: Epoch 025 - generator training loss: 0.0600, discriminator training loss: 0.0413, validation loss: 0.1673
2024-05-22 14:21:28 [INFO]: Epoch 026 - generator training loss: 0.0592, discriminator training loss: 0.0406, validation loss: 0.1658
2024-05-22 14:21:32 [INFO]: Epoch 027 - generator training loss: 0.0584, discriminator training loss: 0.0395, validation loss: 0.1647
2024-05-22 14:21:36 [INFO]: Epoch 028 - generator training loss: 0.0586, discriminator training loss: 0.0389, validation loss: 0.1631
2024-05-22 14:21:40 [INFO]: Epoch 029 - generator training loss: 0.0571, discriminator training loss: 0.0382, validation loss: 0.1629
2024-05-22 14:21:44 [INFO]: Epoch 030 - generator training loss: 0.0563, discriminator training loss: 0.0374, validation loss: 0.1613
2024-05-22 14:21:48 [INFO]: Epoch 031 - generator training loss: 0.0547, discriminator training loss: 0.0374, validation loss: 0.1604
2024-05-22 14:21:52 [INFO]: Epoch 032 - generator training loss: 0.0557, discriminator training loss: 0.0362, validation loss: 0.1589
2024-05-22 14:21:56 [INFO]: Epoch 033 - generator training loss: 0.0550, discriminator training loss: 0.0350, validation loss: 0.1585
2024-05-22 14:22:00 [INFO]: Epoch 034 - generator training loss: 0.0545, discriminator training loss: 0.0341, validation loss: 0.1579
2024-05-22 14:22:04 [INFO]: Epoch 035 - generator training loss: 0.0539, discriminator training loss: 0.0336, validation loss: 0.1570
2024-05-22 14:22:08 [INFO]: Epoch 036 - generator training loss: 0.0533, discriminator training loss: 0.0330, validation loss: 0.1560
2024-05-22 14:22:12 [INFO]: Epoch 037 - generator training loss: 0.0527, discriminator training loss: 0.0324, validation loss: 0.1555
2024-05-22 14:22:16 [INFO]: Epoch 038 - generator training loss: 0.0539, discriminator training loss: 0.0316, validation loss: 0.1546
2024-05-22 14:22:20 [INFO]: Epoch 039 - generator training loss: 0.0515, discriminator training loss: 0.0310, validation loss: 0.1539
2024-05-22 14:22:24 [INFO]: Epoch 040 - generator training loss: 0.0514, discriminator training loss: 0.0304, validation loss: 0.1534
2024-05-22 14:22:28 [INFO]: Epoch 041 - generator training loss: 0.0513, discriminator training loss: 0.0296, validation loss: 0.1523
2024-05-22 14:22:32 [INFO]: Epoch 042 - generator training loss: 0.0511, discriminator training loss: 0.0291, validation loss: 0.1513
2024-05-22 14:22:36 [INFO]: Epoch 043 - generator training loss: 0.0508, discriminator training loss: 0.0283, validation loss: 0.1514
2024-05-22 14:22:40 [INFO]: Epoch 044 - generator training loss: 0.0505, discriminator training loss: 0.0282, validation loss: 0.1506
2024-05-22 14:22:44 [INFO]: Epoch 045 - generator training loss: 0.0500, discriminator training loss: 0.0277, validation loss: 0.1500
2024-05-22 14:22:48 [INFO]: Epoch 046 - generator training loss: 0.0493, discriminator training loss: 0.0272, validation loss: 0.1493
2024-05-22 14:22:52 [INFO]: Epoch 047 - generator training loss: 0.0497, discriminator training loss: 0.0267, validation loss: 0.1487
2024-05-22 14:22:56 [INFO]: Epoch 048 - generator training loss: 0.0489, discriminator training loss: 0.0261, validation loss: 0.1479
2024-05-22 14:23:00 [INFO]: Epoch 049 - generator training loss: 0.0482, discriminator training loss: 0.0255, validation loss: 0.1480
2024-05-22 14:23:04 [INFO]: Epoch 050 - generator training loss: 0.0477, discriminator training loss: 0.0251, validation loss: 0.1471
2024-05-22 14:23:08 [INFO]: Epoch 051 - generator training loss: 0.0480, discriminator training loss: 0.0249, validation loss: 0.1464
2024-05-22 14:23:12 [INFO]: Epoch 052 - generator training loss: 0.0471, discriminator training loss: 0.0245, validation loss: 0.1463
2024-05-22 14:23:16 [INFO]: Epoch 053 - generator training loss: 0.0473, discriminator training loss: 0.0244, validation loss: 0.1453
2024-05-22 14:23:20 [INFO]: Epoch 054 - generator training loss: 0.0469, discriminator training loss: 0.0239, validation loss: 0.1455
2024-05-22 14:23:24 [INFO]: Epoch 055 - generator training loss: 0.0467, discriminator training loss: 0.0234, validation loss: 0.1447
2024-05-22 14:23:28 [INFO]: Epoch 056 - generator training loss: 0.0459, discriminator training loss: 0.0231, validation loss: 0.1445
2024-05-22 14:23:32 [INFO]: Epoch 057 - generator training loss: 0.0467, discriminator training loss: 0.0230, validation loss: 0.1435
2024-05-22 14:23:36 [INFO]: Epoch 058 - generator training loss: 0.0452, discriminator training loss: 0.0226, validation loss: 0.1434
2024-05-22 14:23:40 [INFO]: Epoch 059 - generator training loss: 0.0451, discriminator training loss: 0.0223, validation loss: 0.1428
2024-05-22 14:23:44 [INFO]: Epoch 060 - generator training loss: 0.0458, discriminator training loss: 0.0220, validation loss: 0.1425
2024-05-22 14:23:48 [INFO]: Epoch 061 - generator training loss: 0.0449, discriminator training loss: 0.0218, validation loss: 0.1421
2024-05-22 14:23:52 [INFO]: Epoch 062 - generator training loss: 0.0443, discriminator training loss: 0.0215, validation loss: 0.1422
2024-05-22 14:23:56 [INFO]: Epoch 063 - generator training loss: 0.0450, discriminator training loss: 0.0214, validation loss: 0.1416
2024-05-22 14:24:00 [INFO]: Epoch 064 - generator training loss: 0.0442, discriminator training loss: 0.0207, validation loss: 0.1414
2024-05-22 14:24:04 [INFO]: Epoch 065 - generator training loss: 0.0448, discriminator training loss: 0.0205, validation loss: 0.1401
2024-05-22 14:24:08 [INFO]: Epoch 066 - generator training loss: 0.0437, discriminator training loss: 0.0202, validation loss: 0.1400
2024-05-22 14:24:12 [INFO]: Epoch 067 - generator training loss: 0.0436, discriminator training loss: 0.0204, validation loss: 0.1399
2024-05-22 14:24:17 [INFO]: Epoch 068 - generator training loss: 0.0425, discriminator training loss: 0.0200, validation loss: 0.1404
2024-05-22 14:24:21 [INFO]: Epoch 069 - generator training loss: 0.0426, discriminator training loss: 0.0197, validation loss: 0.1391
2024-05-22 14:24:25 [INFO]: Epoch 070 - generator training loss: 0.0424, discriminator training loss: 0.0195, validation loss: 0.1388
2024-05-22 14:24:29 [INFO]: Epoch 071 - generator training loss: 0.0421, discriminator training loss: 0.0194, validation loss: 0.1387
2024-05-22 14:24:33 [INFO]: Epoch 072 - generator training loss: 0.0425, discriminator training loss: 0.0194, validation loss: 0.1384
2024-05-22 14:24:37 [INFO]: Epoch 073 - generator training loss: 0.0416, discriminator training loss: 0.0191, validation loss: 0.1386
2024-05-22 14:24:41 [INFO]: Epoch 074 - generator training loss: 0.0412, discriminator training loss: 0.0189, validation loss: 0.1382
2024-05-22 14:24:45 [INFO]: Epoch 075 - generator training loss: 0.0412, discriminator training loss: 0.0186, validation loss: 0.1383
2024-05-22 14:24:49 [INFO]: Epoch 076 - generator training loss: 0.0408, discriminator training loss: 0.0185, validation loss: 0.1379
2024-05-22 14:24:53 [INFO]: Epoch 077 - generator training loss: 0.0426, discriminator training loss: 0.0184, validation loss: 0.1366
2024-05-22 14:24:57 [INFO]: Epoch 078 - generator training loss: 0.0416, discriminator training loss: 0.0182, validation loss: 0.1369
2024-05-22 14:25:01 [INFO]: Epoch 079 - generator training loss: 0.0402, discriminator training loss: 0.0182, validation loss: 0.1375
2024-05-22 14:25:05 [INFO]: Epoch 080 - generator training loss: 0.0403, discriminator training loss: 0.0178, validation loss: 0.1366
2024-05-22 14:25:09 [INFO]: Epoch 081 - generator training loss: 0.0402, discriminator training loss: 0.0176, validation loss: 0.1365
2024-05-22 14:25:13 [INFO]: Epoch 082 - generator training loss: 0.0401, discriminator training loss: 0.0174, validation loss: 0.1366
2024-05-22 14:25:17 [INFO]: Epoch 083 - generator training loss: 0.0401, discriminator training loss: 0.0175, validation loss: 0.1361
2024-05-22 14:25:21 [INFO]: Epoch 084 - generator training loss: 0.0397, discriminator training loss: 0.0174, validation loss: 0.1361
2024-05-22 14:25:25 [INFO]: Epoch 085 - generator training loss: 0.0390, discriminator training loss: 0.0172, validation loss: 0.1366
2024-05-22 14:25:29 [INFO]: Epoch 086 - generator training loss: 0.0397, discriminator training loss: 0.0172, validation loss: 0.1360
2024-05-22 14:25:33 [INFO]: Epoch 087 - generator training loss: 0.0385, discriminator training loss: 0.0168, validation loss: 0.1357
2024-05-22 14:25:37 [INFO]: Epoch 088 - generator training loss: 0.0398, discriminator training loss: 0.0167, validation loss: 0.1365
2024-05-22 14:25:41 [INFO]: Epoch 089 - generator training loss: 0.0395, discriminator training loss: 0.0167, validation loss: 0.1352
2024-05-22 14:25:45 [INFO]: Epoch 090 - generator training loss: 0.0389, discriminator training loss: 0.0168, validation loss: 0.1370
2024-05-22 14:25:49 [INFO]: Epoch 091 - generator training loss: 0.0384, discriminator training loss: 0.0165, validation loss: 0.1359
2024-05-22 14:25:53 [INFO]: Epoch 092 - generator training loss: 0.0380, discriminator training loss: 0.0162, validation loss: 0.1357
2024-05-22 14:25:57 [INFO]: Epoch 093 - generator training loss: 0.0377, discriminator training loss: 0.0161, validation loss: 0.1357
2024-05-22 14:26:01 [INFO]: Epoch 094 - generator training loss: 0.0390, discriminator training loss: 0.0162, validation loss: 0.1358
2024-05-22 14:26:05 [INFO]: Epoch 095 - generator training loss: 0.0376, discriminator training loss: 0.0161, validation loss: 0.1357
2024-05-22 14:26:09 [INFO]: Epoch 096 - generator training loss: 0.0378, discriminator training loss: 0.0160, validation loss: 0.1349
2024-05-22 14:26:13 [INFO]: Epoch 097 - generator training loss: 0.0368, discriminator training loss: 0.0159, validation loss: 0.1353
2024-05-22 14:26:17 [INFO]: Epoch 098 - generator training loss: 0.0365, discriminator training loss: 0.0155, validation loss: 0.1350
2024-05-22 14:26:21 [INFO]: Epoch 099 - generator training loss: 0.0366, discriminator training loss: 0.0157, validation loss: 0.1354
2024-05-22 14:26:25 [INFO]: Epoch 100 - generator training loss: 0.0367, discriminator training loss: 0.0157, validation loss: 0.1350
2024-05-22 14:26:29 [INFO]: Epoch 101 - generator training loss: 0.0360, discriminator training loss: 0.0154, validation loss: 0.1349
2024-05-22 14:26:33 [INFO]: Epoch 102 - generator training loss: 0.0362, discriminator training loss: 0.0156, validation loss: 0.1353
2024-05-22 14:26:37 [INFO]: Epoch 103 - generator training loss: 0.0364, discriminator training loss: 0.0151, validation loss: 0.1351
2024-05-22 14:26:41 [INFO]: Epoch 104 - generator training loss: 0.0358, discriminator training loss: 0.0151, validation loss: 0.1353
2024-05-22 14:26:45 [INFO]: Epoch 105 - generator training loss: 0.0358, discriminator training loss: 0.0150, validation loss: 0.1356
2024-05-22 14:26:49 [INFO]: Epoch 106 - generator training loss: 0.0355, discriminator training loss: 0.0149, validation loss: 0.1364
2024-05-22 14:26:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:26:49 [INFO]: Finished training. The best model is from epoch#96.
2024-05-22 14:26:49 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_air_quality/20240522_T141942/USGAN.pypots
2024-05-22 14:26:50 [INFO]: US-GAN on Air-Quality: MAE=0.1738, MSE=0.1244
2024-05-22 14:26:50 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-22 14:26:50 [INFO]: Using the given device: cuda:0
2024-05-22 14:26:50 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240522_T142650
2024-05-22 14:26:50 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_air_quality/20240522_T142650/tensorboard
2024-05-22 14:26:50 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 14:26:54 [INFO]: Epoch 001 - training loss: 1.4054, validation loss: 0.9295
2024-05-22 14:26:56 [INFO]: Epoch 002 - training loss: 1.1330, validation loss: 0.6928
2024-05-22 14:26:59 [INFO]: Epoch 003 - training loss: 0.9410, validation loss: 0.5809
2024-05-22 14:27:02 [INFO]: Epoch 004 - training loss: 0.8335, validation loss: 0.5168
2024-05-22 14:27:05 [INFO]: Epoch 005 - training loss: 0.7607, validation loss: 0.4728
2024-05-22 14:27:07 [INFO]: Epoch 006 - training loss: 0.7031, validation loss: 0.4352
2024-05-22 14:27:10 [INFO]: Epoch 007 - training loss: 0.6585, validation loss: 0.4073
2024-05-22 14:27:13 [INFO]: Epoch 008 - training loss: 0.6236, validation loss: 0.3839
2024-05-22 14:27:15 [INFO]: Epoch 009 - training loss: 0.5961, validation loss: 0.3649
2024-05-22 14:27:18 [INFO]: Epoch 010 - training loss: 0.5756, validation loss: 0.3492
2024-05-22 14:27:21 [INFO]: Epoch 011 - training loss: 0.5564, validation loss: 0.3363
2024-05-22 14:27:24 [INFO]: Epoch 012 - training loss: 0.5417, validation loss: 0.3253
2024-05-22 14:27:26 [INFO]: Epoch 013 - training loss: 0.5271, validation loss: 0.3155
2024-05-22 14:27:29 [INFO]: Epoch 014 - training loss: 0.5177, validation loss: 0.3070
2024-05-22 14:27:32 [INFO]: Epoch 015 - training loss: 0.5047, validation loss: 0.3000
2024-05-22 14:27:35 [INFO]: Epoch 016 - training loss: 0.4947, validation loss: 0.2929
2024-05-22 14:27:37 [INFO]: Epoch 017 - training loss: 0.4860, validation loss: 0.2870
2024-05-22 14:27:40 [INFO]: Epoch 018 - training loss: 0.4773, validation loss: 0.2811
2024-05-22 14:27:43 [INFO]: Epoch 019 - training loss: 0.4689, validation loss: 0.2760
2024-05-22 14:27:45 [INFO]: Epoch 020 - training loss: 0.4623, validation loss: 0.2710
2024-05-22 14:27:48 [INFO]: Epoch 021 - training loss: 0.4548, validation loss: 0.2670
2024-05-22 14:27:51 [INFO]: Epoch 022 - training loss: 0.4488, validation loss: 0.2628
2024-05-22 14:27:54 [INFO]: Epoch 023 - training loss: 0.4422, validation loss: 0.2588
2024-05-22 14:27:56 [INFO]: Epoch 024 - training loss: 0.4372, validation loss: 0.2552
2024-05-22 14:27:59 [INFO]: Epoch 025 - training loss: 0.4306, validation loss: 0.2513
2024-05-22 14:28:02 [INFO]: Epoch 026 - training loss: 0.4257, validation loss: 0.2481
2024-05-22 14:28:04 [INFO]: Epoch 027 - training loss: 0.4200, validation loss: 0.2448
2024-05-22 14:28:07 [INFO]: Epoch 028 - training loss: 0.4146, validation loss: 0.2414
2024-05-22 14:28:10 [INFO]: Epoch 029 - training loss: 0.4099, validation loss: 0.2382
2024-05-22 14:28:13 [INFO]: Epoch 030 - training loss: 0.4054, validation loss: 0.2356
2024-05-22 14:28:15 [INFO]: Epoch 031 - training loss: 0.4006, validation loss: 0.2325
2024-05-22 14:28:18 [INFO]: Epoch 032 - training loss: 0.3966, validation loss: 0.2299
2024-05-22 14:28:21 [INFO]: Epoch 033 - training loss: 0.3924, validation loss: 0.2272
2024-05-22 14:28:24 [INFO]: Epoch 034 - training loss: 0.3891, validation loss: 0.2245
2024-05-22 14:28:26 [INFO]: Epoch 035 - training loss: 0.3848, validation loss: 0.2224
2024-05-22 14:28:29 [INFO]: Epoch 036 - training loss: 0.3808, validation loss: 0.2197
2024-05-22 14:28:32 [INFO]: Epoch 037 - training loss: 0.3764, validation loss: 0.2174
2024-05-22 14:28:34 [INFO]: Epoch 038 - training loss: 0.3733, validation loss: 0.2155
2024-05-22 14:28:37 [INFO]: Epoch 039 - training loss: 0.3705, validation loss: 0.2130
2024-05-22 14:28:40 [INFO]: Epoch 040 - training loss: 0.3668, validation loss: 0.2105
2024-05-22 14:28:43 [INFO]: Epoch 041 - training loss: 0.3643, validation loss: 0.2089
2024-05-22 14:28:45 [INFO]: Epoch 042 - training loss: 0.3602, validation loss: 0.2067
2024-05-22 14:28:48 [INFO]: Epoch 043 - training loss: 0.3582, validation loss: 0.2048
2024-05-22 14:28:51 [INFO]: Epoch 044 - training loss: 0.3550, validation loss: 0.2031
2024-05-22 14:28:54 [INFO]: Epoch 045 - training loss: 0.3527, validation loss: 0.2016
2024-05-22 14:28:56 [INFO]: Epoch 046 - training loss: 0.3499, validation loss: 0.2000
2024-05-22 14:28:59 [INFO]: Epoch 047 - training loss: 0.3471, validation loss: 0.1985
2024-05-22 14:29:02 [INFO]: Epoch 048 - training loss: 0.3452, validation loss: 0.1973
2024-05-22 14:29:04 [INFO]: Epoch 049 - training loss: 0.3423, validation loss: 0.1964
2024-05-22 14:29:07 [INFO]: Epoch 050 - training loss: 0.3402, validation loss: 0.1949
2024-05-22 14:29:10 [INFO]: Epoch 051 - training loss: 0.3369, validation loss: 0.1938
2024-05-22 14:29:13 [INFO]: Epoch 052 - training loss: 0.3353, validation loss: 0.1927
2024-05-22 14:29:15 [INFO]: Epoch 053 - training loss: 0.3336, validation loss: 0.1918
2024-05-22 14:29:18 [INFO]: Epoch 054 - training loss: 0.3311, validation loss: 0.1906
2024-05-22 14:29:21 [INFO]: Epoch 055 - training loss: 0.3293, validation loss: 0.1900
2024-05-22 14:29:24 [INFO]: Epoch 056 - training loss: 0.3276, validation loss: 0.1895
2024-05-22 14:29:26 [INFO]: Epoch 057 - training loss: 0.3268, validation loss: 0.1881
2024-05-22 14:29:29 [INFO]: Epoch 058 - training loss: 0.3245, validation loss: 0.1874
2024-05-22 14:29:32 [INFO]: Epoch 059 - training loss: 0.3218, validation loss: 0.1869
2024-05-22 14:29:34 [INFO]: Epoch 060 - training loss: 0.3202, validation loss: 0.1855
2024-05-22 14:29:37 [INFO]: Epoch 061 - training loss: 0.3184, validation loss: 0.1852
2024-05-22 14:29:40 [INFO]: Epoch 062 - training loss: 0.3168, validation loss: 0.1844
2024-05-22 14:29:43 [INFO]: Epoch 063 - training loss: 0.3158, validation loss: 0.1837
2024-05-22 14:29:45 [INFO]: Epoch 064 - training loss: 0.3137, validation loss: 0.1829
2024-05-22 14:29:48 [INFO]: Epoch 065 - training loss: 0.3122, validation loss: 0.1823
2024-05-22 14:29:51 [INFO]: Epoch 066 - training loss: 0.3115, validation loss: 0.1815
2024-05-22 14:29:53 [INFO]: Epoch 067 - training loss: 0.3096, validation loss: 0.1810
2024-05-22 14:29:56 [INFO]: Epoch 068 - training loss: 0.3085, validation loss: 0.1803
2024-05-22 14:29:59 [INFO]: Epoch 069 - training loss: 0.3070, validation loss: 0.1798
2024-05-22 14:30:02 [INFO]: Epoch 070 - training loss: 0.3066, validation loss: 0.1793
2024-05-22 14:30:04 [INFO]: Epoch 071 - training loss: 0.3051, validation loss: 0.1788
2024-05-22 14:30:07 [INFO]: Epoch 072 - training loss: 0.3030, validation loss: 0.1781
2024-05-22 14:30:10 [INFO]: Epoch 073 - training loss: 0.3033, validation loss: 0.1776
2024-05-22 14:30:13 [INFO]: Epoch 074 - training loss: 0.3014, validation loss: 0.1770
2024-05-22 14:30:15 [INFO]: Epoch 075 - training loss: 0.3002, validation loss: 0.1764
2024-05-22 14:30:18 [INFO]: Epoch 076 - training loss: 0.2997, validation loss: 0.1758
2024-05-22 14:30:21 [INFO]: Epoch 077 - training loss: 0.2984, validation loss: 0.1751
2024-05-22 14:30:23 [INFO]: Epoch 078 - training loss: 0.2974, validation loss: 0.1748
2024-05-22 14:30:26 [INFO]: Epoch 079 - training loss: 0.2961, validation loss: 0.1743
2024-05-22 14:30:29 [INFO]: Epoch 080 - training loss: 0.2949, validation loss: 0.1737
2024-05-22 14:30:32 [INFO]: Epoch 081 - training loss: 0.2945, validation loss: 0.1730
2024-05-22 14:30:34 [INFO]: Epoch 082 - training loss: 0.2931, validation loss: 0.1726
2024-05-22 14:30:37 [INFO]: Epoch 083 - training loss: 0.2926, validation loss: 0.1719
2024-05-22 14:30:40 [INFO]: Epoch 084 - training loss: 0.2919, validation loss: 0.1715
2024-05-22 14:30:43 [INFO]: Epoch 085 - training loss: 0.2911, validation loss: 0.1713
2024-05-22 14:30:45 [INFO]: Epoch 086 - training loss: 0.2900, validation loss: 0.1705
2024-05-22 14:30:48 [INFO]: Epoch 087 - training loss: 0.2886, validation loss: 0.1699
2024-05-22 14:30:51 [INFO]: Epoch 088 - training loss: 0.2879, validation loss: 0.1697
2024-05-22 14:30:54 [INFO]: Epoch 089 - training loss: 0.2871, validation loss: 0.1689
2024-05-22 14:30:56 [INFO]: Epoch 090 - training loss: 0.2873, validation loss: 0.1685
2024-05-22 14:30:59 [INFO]: Epoch 091 - training loss: 0.2858, validation loss: 0.1680
2024-05-22 14:31:02 [INFO]: Epoch 092 - training loss: 0.2853, validation loss: 0.1678
2024-05-22 14:31:04 [INFO]: Epoch 093 - training loss: 0.2851, validation loss: 0.1670
2024-05-22 14:31:07 [INFO]: Epoch 094 - training loss: 0.2841, validation loss: 0.1668
2024-05-22 14:31:10 [INFO]: Epoch 095 - training loss: 0.2832, validation loss: 0.1662
2024-05-22 14:31:13 [INFO]: Epoch 096 - training loss: 0.2823, validation loss: 0.1657
2024-05-22 14:31:15 [INFO]: Epoch 097 - training loss: 0.2819, validation loss: 0.1652
2024-05-22 14:31:18 [INFO]: Epoch 098 - training loss: 0.2817, validation loss: 0.1648
2024-05-22 14:31:21 [INFO]: Epoch 099 - training loss: 0.2804, validation loss: 0.1643
2024-05-22 14:31:24 [INFO]: Epoch 100 - training loss: 0.2795, validation loss: 0.1638
2024-05-22 14:31:26 [INFO]: Epoch 101 - training loss: 0.2799, validation loss: 0.1636
2024-05-22 14:31:29 [INFO]: Epoch 102 - training loss: 0.2796, validation loss: 0.1631
2024-05-22 14:31:32 [INFO]: Epoch 103 - training loss: 0.2790, validation loss: 0.1627
2024-05-22 14:31:34 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1620
2024-05-22 14:31:37 [INFO]: Epoch 105 - training loss: 0.2768, validation loss: 0.1617
2024-05-22 14:31:40 [INFO]: Epoch 106 - training loss: 0.2757, validation loss: 0.1611
2024-05-22 14:31:43 [INFO]: Epoch 107 - training loss: 0.2762, validation loss: 0.1609
2024-05-22 14:31:45 [INFO]: Epoch 108 - training loss: 0.2750, validation loss: 0.1603
2024-05-22 14:31:48 [INFO]: Epoch 109 - training loss: 0.2749, validation loss: 0.1600
2024-05-22 14:31:51 [INFO]: Epoch 110 - training loss: 0.2747, validation loss: 0.1596
2024-05-22 14:31:53 [INFO]: Epoch 111 - training loss: 0.2737, validation loss: 0.1592
2024-05-22 14:31:56 [INFO]: Epoch 112 - training loss: 0.2741, validation loss: 0.1587
2024-05-22 14:31:59 [INFO]: Epoch 113 - training loss: 0.2731, validation loss: 0.1584
2024-05-22 14:32:02 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1581
2024-05-22 14:32:04 [INFO]: Epoch 115 - training loss: 0.2715, validation loss: 0.1577
2024-05-22 14:32:07 [INFO]: Epoch 116 - training loss: 0.2711, validation loss: 0.1572
2024-05-22 14:32:10 [INFO]: Epoch 117 - training loss: 0.2702, validation loss: 0.1569
2024-05-22 14:32:13 [INFO]: Epoch 118 - training loss: 0.2706, validation loss: 0.1565
2024-05-22 14:32:15 [INFO]: Epoch 119 - training loss: 0.2692, validation loss: 0.1561
2024-05-22 14:32:18 [INFO]: Epoch 120 - training loss: 0.2691, validation loss: 0.1556
2024-05-22 14:32:21 [INFO]: Epoch 121 - training loss: 0.2680, validation loss: 0.1553
2024-05-22 14:32:23 [INFO]: Epoch 122 - training loss: 0.2680, validation loss: 0.1550
2024-05-22 14:32:26 [INFO]: Epoch 123 - training loss: 0.2682, validation loss: 0.1546
2024-05-22 14:32:29 [INFO]: Epoch 124 - training loss: 0.2668, validation loss: 0.1542
2024-05-22 14:32:32 [INFO]: Epoch 125 - training loss: 0.2663, validation loss: 0.1539
2024-05-22 14:32:34 [INFO]: Epoch 126 - training loss: 0.2666, validation loss: 0.1535
2024-05-22 14:32:37 [INFO]: Epoch 127 - training loss: 0.2658, validation loss: 0.1531
2024-05-22 14:32:40 [INFO]: Epoch 128 - training loss: 0.2656, validation loss: 0.1529
2024-05-22 14:32:43 [INFO]: Epoch 129 - training loss: 0.2651, validation loss: 0.1527
2024-05-22 14:32:45 [INFO]: Epoch 130 - training loss: 0.2646, validation loss: 0.1522
2024-05-22 14:32:48 [INFO]: Epoch 131 - training loss: 0.2645, validation loss: 0.1518
2024-05-22 14:32:51 [INFO]: Epoch 132 - training loss: 0.2633, validation loss: 0.1515
2024-05-22 14:32:54 [INFO]: Epoch 133 - training loss: 0.2631, validation loss: 0.1512
2024-05-22 14:32:56 [INFO]: Epoch 134 - training loss: 0.2630, validation loss: 0.1508
2024-05-22 14:32:59 [INFO]: Epoch 135 - training loss: 0.2624, validation loss: 0.1504
2024-05-22 14:33:02 [INFO]: Epoch 136 - training loss: 0.2618, validation loss: 0.1502
2024-05-22 14:33:04 [INFO]: Epoch 137 - training loss: 0.2616, validation loss: 0.1500
2024-05-22 14:33:07 [INFO]: Epoch 138 - training loss: 0.2610, validation loss: 0.1496
2024-05-22 14:33:10 [INFO]: Epoch 139 - training loss: 0.2609, validation loss: 0.1492
2024-05-22 14:33:13 [INFO]: Epoch 140 - training loss: 0.2606, validation loss: 0.1489
2024-05-22 14:33:15 [INFO]: Epoch 141 - training loss: 0.2600, validation loss: 0.1485
2024-05-22 14:33:18 [INFO]: Epoch 142 - training loss: 0.2598, validation loss: 0.1482
2024-05-22 14:33:21 [INFO]: Epoch 143 - training loss: 0.2591, validation loss: 0.1480
2024-05-22 14:33:24 [INFO]: Epoch 144 - training loss: 0.2593, validation loss: 0.1477
2024-05-22 14:33:26 [INFO]: Epoch 145 - training loss: 0.2590, validation loss: 0.1474
2024-05-22 14:33:29 [INFO]: Epoch 146 - training loss: 0.2584, validation loss: 0.1473
2024-05-22 14:33:32 [INFO]: Epoch 147 - training loss: 0.2578, validation loss: 0.1469
2024-05-22 14:33:34 [INFO]: Epoch 148 - training loss: 0.2576, validation loss: 0.1465
2024-05-22 14:33:37 [INFO]: Epoch 149 - training loss: 0.2569, validation loss: 0.1466
2024-05-22 14:33:40 [INFO]: Epoch 150 - training loss: 0.2577, validation loss: 0.1462
2024-05-22 14:33:43 [INFO]: Epoch 151 - training loss: 0.2568, validation loss: 0.1459
2024-05-22 14:33:45 [INFO]: Epoch 152 - training loss: 0.2565, validation loss: 0.1457
2024-05-22 14:33:48 [INFO]: Epoch 153 - training loss: 0.2558, validation loss: 0.1455
2024-05-22 14:33:51 [INFO]: Epoch 154 - training loss: 0.2552, validation loss: 0.1452
2024-05-22 14:33:53 [INFO]: Epoch 155 - training loss: 0.2561, validation loss: 0.1449
2024-05-22 14:33:56 [INFO]: Epoch 156 - training loss: 0.2552, validation loss: 0.1445
2024-05-22 14:33:59 [INFO]: Epoch 157 - training loss: 0.2549, validation loss: 0.1442
2024-05-22 14:34:02 [INFO]: Epoch 158 - training loss: 0.2544, validation loss: 0.1441
2024-05-22 14:34:04 [INFO]: Epoch 159 - training loss: 0.2535, validation loss: 0.1436
2024-05-22 14:34:07 [INFO]: Epoch 160 - training loss: 0.2536, validation loss: 0.1434
2024-05-22 14:34:10 [INFO]: Epoch 161 - training loss: 0.2532, validation loss: 0.1433
2024-05-22 14:34:12 [INFO]: Epoch 162 - training loss: 0.2532, validation loss: 0.1430
2024-05-22 14:34:15 [INFO]: Epoch 163 - training loss: 0.2531, validation loss: 0.1430
2024-05-22 14:34:18 [INFO]: Epoch 164 - training loss: 0.2522, validation loss: 0.1427
2024-05-22 14:34:21 [INFO]: Epoch 165 - training loss: 0.2526, validation loss: 0.1425
2024-05-22 14:34:23 [INFO]: Epoch 166 - training loss: 0.2516, validation loss: 0.1421
2024-05-22 14:34:26 [INFO]: Epoch 167 - training loss: 0.2516, validation loss: 0.1421
2024-05-22 14:34:29 [INFO]: Epoch 168 - training loss: 0.2516, validation loss: 0.1418
2024-05-22 14:34:32 [INFO]: Epoch 169 - training loss: 0.2513, validation loss: 0.1416
2024-05-22 14:34:34 [INFO]: Epoch 170 - training loss: 0.2511, validation loss: 0.1412
2024-05-22 14:34:37 [INFO]: Epoch 171 - training loss: 0.2505, validation loss: 0.1412
2024-05-22 14:34:40 [INFO]: Epoch 172 - training loss: 0.2504, validation loss: 0.1409
2024-05-22 14:34:43 [INFO]: Epoch 173 - training loss: 0.2500, validation loss: 0.1407
2024-05-22 14:34:45 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1406
2024-05-22 14:34:48 [INFO]: Epoch 175 - training loss: 0.2499, validation loss: 0.1402
2024-05-22 14:34:51 [INFO]: Epoch 176 - training loss: 0.2497, validation loss: 0.1403
2024-05-22 14:34:53 [INFO]: Epoch 177 - training loss: 0.2492, validation loss: 0.1400
2024-05-22 14:34:56 [INFO]: Epoch 178 - training loss: 0.2490, validation loss: 0.1398
2024-05-22 14:34:59 [INFO]: Epoch 179 - training loss: 0.2489, validation loss: 0.1397
2024-05-22 14:35:02 [INFO]: Epoch 180 - training loss: 0.2482, validation loss: 0.1393
2024-05-22 14:35:04 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1392
2024-05-22 14:35:07 [INFO]: Epoch 182 - training loss: 0.2476, validation loss: 0.1390
2024-05-22 14:35:10 [INFO]: Epoch 183 - training loss: 0.2479, validation loss: 0.1387
2024-05-22 14:35:13 [INFO]: Epoch 184 - training loss: 0.2474, validation loss: 0.1387
2024-05-22 14:35:15 [INFO]: Epoch 185 - training loss: 0.2474, validation loss: 0.1386
2024-05-22 14:35:18 [INFO]: Epoch 186 - training loss: 0.2473, validation loss: 0.1383
2024-05-22 14:35:21 [INFO]: Epoch 187 - training loss: 0.2468, validation loss: 0.1384
2024-05-22 14:35:23 [INFO]: Epoch 188 - training loss: 0.2466, validation loss: 0.1381
2024-05-22 14:35:26 [INFO]: Epoch 189 - training loss: 0.2466, validation loss: 0.1379
2024-05-22 14:35:29 [INFO]: Epoch 190 - training loss: 0.2463, validation loss: 0.1378
2024-05-22 14:35:32 [INFO]: Epoch 191 - training loss: 0.2457, validation loss: 0.1375
2024-05-22 14:35:34 [INFO]: Epoch 192 - training loss: 0.2457, validation loss: 0.1372
2024-05-22 14:35:37 [INFO]: Epoch 193 - training loss: 0.2456, validation loss: 0.1373
2024-05-22 14:35:40 [INFO]: Epoch 194 - training loss: 0.2455, validation loss: 0.1372
2024-05-22 14:35:42 [INFO]: Epoch 195 - training loss: 0.2450, validation loss: 0.1369
2024-05-22 14:35:45 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1366
2024-05-22 14:35:48 [INFO]: Epoch 197 - training loss: 0.2451, validation loss: 0.1365
2024-05-22 14:35:51 [INFO]: Epoch 198 - training loss: 0.2447, validation loss: 0.1364
2024-05-22 14:35:53 [INFO]: Epoch 199 - training loss: 0.2441, validation loss: 0.1363
2024-05-22 14:35:56 [INFO]: Epoch 200 - training loss: 0.2440, validation loss: 0.1361
2024-05-22 14:35:59 [INFO]: Epoch 201 - training loss: 0.2441, validation loss: 0.1360
2024-05-22 14:36:02 [INFO]: Epoch 202 - training loss: 0.2435, validation loss: 0.1359
2024-05-22 14:36:04 [INFO]: Epoch 203 - training loss: 0.2435, validation loss: 0.1359
2024-05-22 14:36:07 [INFO]: Epoch 204 - training loss: 0.2433, validation loss: 0.1358
2024-05-22 14:36:10 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.1353
2024-05-22 14:36:12 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.1353
2024-05-22 14:36:15 [INFO]: Epoch 207 - training loss: 0.2431, validation loss: 0.1351
2024-05-22 14:36:18 [INFO]: Epoch 208 - training loss: 0.2426, validation loss: 0.1349
2024-05-22 14:36:21 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.1350
2024-05-22 14:36:23 [INFO]: Epoch 210 - training loss: 0.2423, validation loss: 0.1349
2024-05-22 14:36:26 [INFO]: Epoch 211 - training loss: 0.2420, validation loss: 0.1347
2024-05-22 14:36:29 [INFO]: Epoch 212 - training loss: 0.2419, validation loss: 0.1344
2024-05-22 14:36:32 [INFO]: Epoch 213 - training loss: 0.2413, validation loss: 0.1346
2024-05-22 14:36:34 [INFO]: Epoch 214 - training loss: 0.2410, validation loss: 0.1343
2024-05-22 14:36:37 [INFO]: Epoch 215 - training loss: 0.2414, validation loss: 0.1340
2024-05-22 14:36:40 [INFO]: Epoch 216 - training loss: 0.2408, validation loss: 0.1338
2024-05-22 14:36:43 [INFO]: Epoch 217 - training loss: 0.2407, validation loss: 0.1339
2024-05-22 14:36:45 [INFO]: Epoch 218 - training loss: 0.2401, validation loss: 0.1338
2024-05-22 14:36:48 [INFO]: Epoch 219 - training loss: 0.2400, validation loss: 0.1335
2024-05-22 14:36:51 [INFO]: Epoch 220 - training loss: 0.2406, validation loss: 0.1335
2024-05-22 14:36:53 [INFO]: Epoch 221 - training loss: 0.2399, validation loss: 0.1334
2024-05-22 14:36:56 [INFO]: Epoch 222 - training loss: 0.2399, validation loss: 0.1334
2024-05-22 14:36:59 [INFO]: Epoch 223 - training loss: 0.2393, validation loss: 0.1332
2024-05-22 14:37:02 [INFO]: Epoch 224 - training loss: 0.2391, validation loss: 0.1330
2024-05-22 14:37:04 [INFO]: Epoch 225 - training loss: 0.2398, validation loss: 0.1330
2024-05-22 14:37:07 [INFO]: Epoch 226 - training loss: 0.2392, validation loss: 0.1327
2024-05-22 14:37:10 [INFO]: Epoch 227 - training loss: 0.2394, validation loss: 0.1328
2024-05-22 14:37:13 [INFO]: Epoch 228 - training loss: 0.2393, validation loss: 0.1327
2024-05-22 14:37:15 [INFO]: Epoch 229 - training loss: 0.2385, validation loss: 0.1327
2024-05-22 14:37:18 [INFO]: Epoch 230 - training loss: 0.2384, validation loss: 0.1324
2024-05-22 14:37:21 [INFO]: Epoch 231 - training loss: 0.2386, validation loss: 0.1321
2024-05-22 14:37:23 [INFO]: Epoch 232 - training loss: 0.2381, validation loss: 0.1321
2024-05-22 14:37:26 [INFO]: Epoch 233 - training loss: 0.2377, validation loss: 0.1320
2024-05-22 14:37:29 [INFO]: Epoch 234 - training loss: 0.2381, validation loss: 0.1322
2024-05-22 14:37:32 [INFO]: Epoch 235 - training loss: 0.2378, validation loss: 0.1319
2024-05-22 14:37:34 [INFO]: Epoch 236 - training loss: 0.2370, validation loss: 0.1319
2024-05-22 14:37:37 [INFO]: Epoch 237 - training loss: 0.2372, validation loss: 0.1317
2024-05-22 14:37:40 [INFO]: Epoch 238 - training loss: 0.2372, validation loss: 0.1314
2024-05-22 14:37:43 [INFO]: Epoch 239 - training loss: 0.2368, validation loss: 0.1313
2024-05-22 14:37:45 [INFO]: Epoch 240 - training loss: 0.2367, validation loss: 0.1316
2024-05-22 14:37:48 [INFO]: Epoch 241 - training loss: 0.2371, validation loss: 0.1313
2024-05-22 14:37:51 [INFO]: Epoch 242 - training loss: 0.2372, validation loss: 0.1310
2024-05-22 14:37:53 [INFO]: Epoch 243 - training loss: 0.2362, validation loss: 0.1310
2024-05-22 14:37:56 [INFO]: Epoch 244 - training loss: 0.2360, validation loss: 0.1309
2024-05-22 14:37:59 [INFO]: Epoch 245 - training loss: 0.2361, validation loss: 0.1308
2024-05-22 14:38:02 [INFO]: Epoch 246 - training loss: 0.2362, validation loss: 0.1307
2024-05-22 14:38:04 [INFO]: Epoch 247 - training loss: 0.2357, validation loss: 0.1307
2024-05-22 14:38:07 [INFO]: Epoch 248 - training loss: 0.2357, validation loss: 0.1305
2024-05-22 14:38:10 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1304
2024-05-22 14:38:13 [INFO]: Epoch 250 - training loss: 0.2355, validation loss: 0.1304
2024-05-22 14:38:15 [INFO]: Epoch 251 - training loss: 0.2352, validation loss: 0.1304
2024-05-22 14:38:18 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1304
2024-05-22 14:38:21 [INFO]: Epoch 253 - training loss: 0.2358, validation loss: 0.1301
2024-05-22 14:38:23 [INFO]: Epoch 254 - training loss: 0.2349, validation loss: 0.1301
2024-05-22 14:38:26 [INFO]: Epoch 255 - training loss: 0.2345, validation loss: 0.1302
2024-05-22 14:38:29 [INFO]: Epoch 256 - training loss: 0.2347, validation loss: 0.1299
2024-05-22 14:38:32 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1298
2024-05-22 14:38:34 [INFO]: Epoch 258 - training loss: 0.2342, validation loss: 0.1297
2024-05-22 14:38:37 [INFO]: Epoch 259 - training loss: 0.2343, validation loss: 0.1297
2024-05-22 14:38:40 [INFO]: Epoch 260 - training loss: 0.2344, validation loss: 0.1296
2024-05-22 14:38:43 [INFO]: Epoch 261 - training loss: 0.2338, validation loss: 0.1295
2024-05-22 14:38:45 [INFO]: Epoch 262 - training loss: 0.2339, validation loss: 0.1295
2024-05-22 14:38:48 [INFO]: Epoch 263 - training loss: 0.2341, validation loss: 0.1293
2024-05-22 14:38:51 [INFO]: Epoch 264 - training loss: 0.2336, validation loss: 0.1292
2024-05-22 14:38:53 [INFO]: Epoch 265 - training loss: 0.2335, validation loss: 0.1293
2024-05-22 14:38:56 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.1291
2024-05-22 14:38:59 [INFO]: Epoch 267 - training loss: 0.2332, validation loss: 0.1289
2024-05-22 14:39:02 [INFO]: Epoch 268 - training loss: 0.2333, validation loss: 0.1289
2024-05-22 14:39:04 [INFO]: Epoch 269 - training loss: 0.2330, validation loss: 0.1288
2024-05-22 14:39:07 [INFO]: Epoch 270 - training loss: 0.2330, validation loss: 0.1288
2024-05-22 14:39:10 [INFO]: Epoch 271 - training loss: 0.2329, validation loss: 0.1286
2024-05-22 14:39:13 [INFO]: Epoch 272 - training loss: 0.2329, validation loss: 0.1286
2024-05-22 14:39:15 [INFO]: Epoch 273 - training loss: 0.2328, validation loss: 0.1287
2024-05-22 14:39:18 [INFO]: Epoch 274 - training loss: 0.2321, validation loss: 0.1285
2024-05-22 14:39:21 [INFO]: Epoch 275 - training loss: 0.2323, validation loss: 0.1284
2024-05-22 14:39:23 [INFO]: Epoch 276 - training loss: 0.2324, validation loss: 0.1284
2024-05-22 14:39:26 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.1283
2024-05-22 14:39:29 [INFO]: Epoch 278 - training loss: 0.2321, validation loss: 0.1282
2024-05-22 14:39:32 [INFO]: Epoch 279 - training loss: 0.2314, validation loss: 0.1281
2024-05-22 14:39:34 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.1282
2024-05-22 14:39:37 [INFO]: Epoch 281 - training loss: 0.2311, validation loss: 0.1281
2024-05-22 14:39:40 [INFO]: Epoch 282 - training loss: 0.2312, validation loss: 0.1280
2024-05-22 14:39:42 [INFO]: Epoch 283 - training loss: 0.2310, validation loss: 0.1280
2024-05-22 14:39:45 [INFO]: Epoch 284 - training loss: 0.2308, validation loss: 0.1279
2024-05-22 14:39:48 [INFO]: Epoch 285 - training loss: 0.2306, validation loss: 0.1277
2024-05-22 14:39:51 [INFO]: Epoch 286 - training loss: 0.2308, validation loss: 0.1279
2024-05-22 14:39:53 [INFO]: Epoch 287 - training loss: 0.2309, validation loss: 0.1276
2024-05-22 14:39:56 [INFO]: Epoch 288 - training loss: 0.2301, validation loss: 0.1277
2024-05-22 14:39:59 [INFO]: Epoch 289 - training loss: 0.2304, validation loss: 0.1276
2024-05-22 14:40:02 [INFO]: Epoch 290 - training loss: 0.2303, validation loss: 0.1277
2024-05-22 14:40:04 [INFO]: Epoch 291 - training loss: 0.2303, validation loss: 0.1274
2024-05-22 14:40:07 [INFO]: Epoch 292 - training loss: 0.2300, validation loss: 0.1275
2024-05-22 14:40:10 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.1275
2024-05-22 14:40:12 [INFO]: Epoch 294 - training loss: 0.2302, validation loss: 0.1272
2024-05-22 14:40:15 [INFO]: Epoch 295 - training loss: 0.2298, validation loss: 0.1273
2024-05-22 14:40:18 [INFO]: Epoch 296 - training loss: 0.2296, validation loss: 0.1272
2024-05-22 14:40:21 [INFO]: Epoch 297 - training loss: 0.2297, validation loss: 0.1273
2024-05-22 14:40:23 [INFO]: Epoch 298 - training loss: 0.2295, validation loss: 0.1271
2024-05-22 14:40:26 [INFO]: Epoch 299 - training loss: 0.2299, validation loss: 0.1271
2024-05-22 14:40:29 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.1270
2024-05-22 14:40:29 [INFO]: Finished training. The best model is from epoch#300.
2024-05-22 14:40:29 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_air_quality/20240522_T142650/BRITS.pypots
2024-05-22 14:40:30 [INFO]: BRITS on Air-Quality: MAE=0.1427, MSE=0.1147
2024-05-22 14:40:30 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-22 14:40:30 [INFO]: Using the given device: cuda:0
2024-05-22 14:40:30 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030
2024-05-22 14:40:30 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/tensorboard
2024-05-22 14:40:30 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 14:40:35 [INFO]: Epoch 001 - training loss: 1.4589, validation loss: 0.8051
2024-05-22 14:40:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch1_loss0.8051159054040908.pypots
2024-05-22 14:40:39 [INFO]: Epoch 002 - training loss: 1.0659, validation loss: 0.7519
2024-05-22 14:40:39 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch2_loss0.751948794722557.pypots
2024-05-22 14:40:43 [INFO]: Epoch 003 - training loss: 0.9887, validation loss: 0.7265
2024-05-22 14:40:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch3_loss0.7265489161014557.pypots
2024-05-22 14:40:47 [INFO]: Epoch 004 - training loss: 0.9548, validation loss: 0.7129
2024-05-22 14:40:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch4_loss0.7128704130649567.pypots
2024-05-22 14:40:51 [INFO]: Epoch 005 - training loss: 0.9611, validation loss: 0.7055
2024-05-22 14:40:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch5_loss0.705450227856636.pypots
2024-05-22 14:40:55 [INFO]: Epoch 006 - training loss: 0.9527, validation loss: 0.6994
2024-05-22 14:40:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch6_loss0.6994322806596756.pypots
2024-05-22 14:40:58 [INFO]: Epoch 007 - training loss: 0.9444, validation loss: 0.6936
2024-05-22 14:40:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch7_loss0.6936082869768143.pypots
2024-05-22 14:41:02 [INFO]: Epoch 008 - training loss: 0.9254, validation loss: 0.6904
2024-05-22 14:41:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch8_loss0.6904411077499389.pypots
2024-05-22 14:41:06 [INFO]: Epoch 009 - training loss: 0.9216, validation loss: 0.6873
2024-05-22 14:41:06 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch9_loss0.687342444062233.pypots
2024-05-22 14:41:10 [INFO]: Epoch 010 - training loss: 0.9179, validation loss: 0.6855
2024-05-22 14:41:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch10_loss0.6855058521032333.pypots
2024-05-22 14:41:14 [INFO]: Epoch 011 - training loss: 0.9176, validation loss: 0.6832
2024-05-22 14:41:14 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch11_loss0.6832097709178925.pypots
2024-05-22 14:41:17 [INFO]: Epoch 012 - training loss: 0.9144, validation loss: 0.6835
2024-05-22 14:41:17 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch12_loss0.6835333853960037.pypots
2024-05-22 14:41:21 [INFO]: Epoch 013 - training loss: 0.9104, validation loss: 0.6828
2024-05-22 14:41:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch13_loss0.6828486174345016.pypots
2024-05-22 14:41:25 [INFO]: Epoch 014 - training loss: 0.8976, validation loss: 0.6818
2024-05-22 14:41:25 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch14_loss0.6818351805210113.pypots
2024-05-22 14:41:29 [INFO]: Epoch 015 - training loss: 0.9016, validation loss: 0.6822
2024-05-22 14:41:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch15_loss0.68219752907753.pypots
2024-05-22 14:41:32 [INFO]: Epoch 016 - training loss: 0.9003, validation loss: 0.6803
2024-05-22 14:41:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch16_loss0.6802912950515747.pypots
2024-05-22 14:41:36 [INFO]: Epoch 017 - training loss: 0.9348, validation loss: 0.6806
2024-05-22 14:41:36 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch17_loss0.6806156516075135.pypots
2024-05-22 14:41:40 [INFO]: Epoch 018 - training loss: 0.8779, validation loss: 0.6800
2024-05-22 14:41:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch18_loss0.6799688786268234.pypots
2024-05-22 14:41:44 [INFO]: Epoch 019 - training loss: 0.8907, validation loss: 0.6798
2024-05-22 14:41:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch19_loss0.679794442653656.pypots
2024-05-22 14:41:48 [INFO]: Epoch 020 - training loss: 0.8912, validation loss: 0.6814
2024-05-22 14:41:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch20_loss0.6814461022615432.pypots
2024-05-22 14:41:52 [INFO]: Epoch 021 - training loss: 0.8796, validation loss: 0.6818
2024-05-22 14:41:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch21_loss0.6817920625209808.pypots
2024-05-22 14:41:55 [INFO]: Epoch 022 - training loss: 0.8846, validation loss: 0.6830
2024-05-22 14:41:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch22_loss0.6830173552036285.pypots
2024-05-22 14:41:59 [INFO]: Epoch 023 - training loss: 0.8774, validation loss: 0.6817
2024-05-22 14:41:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch23_loss0.6817199647426605.pypots
2024-05-22 14:42:03 [INFO]: Epoch 024 - training loss: 0.8701, validation loss: 0.6817
2024-05-22 14:42:03 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch24_loss0.6816964209079742.pypots
2024-05-22 14:42:07 [INFO]: Epoch 025 - training loss: 0.8822, validation loss: 0.6835
2024-05-22 14:42:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch25_loss0.6834821820259094.pypots
2024-05-22 14:42:10 [INFO]: Epoch 026 - training loss: 0.8558, validation loss: 0.6834
2024-05-22 14:42:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch26_loss0.683414414525032.pypots
2024-05-22 14:42:14 [INFO]: Epoch 027 - training loss: 0.8709, validation loss: 0.6850
2024-05-22 14:42:14 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch27_loss0.6849928140640259.pypots
2024-05-22 14:42:18 [INFO]: Epoch 028 - training loss: 0.8688, validation loss: 0.6860
2024-05-22 14:42:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch28_loss0.6860107868909836.pypots
2024-05-22 14:42:22 [INFO]: Epoch 029 - training loss: 0.8605, validation loss: 0.6906
2024-05-22 14:42:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN_epoch29_loss0.6906096011400222.pypots
2024-05-22 14:42:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:42:22 [INFO]: Finished training. The best model is from epoch#19.
2024-05-22 14:42:22 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_air_quality/20240522_T144030/MRNN.pypots
2024-05-22 14:42:22 [INFO]: MRNN on Air-Quality: MAE=0.5257, MSE=0.6279
2024-05-22 14:42:23 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-22 14:42:23 [INFO]: Using the given device: cpu
2024-05-22 14:42:23 [INFO]: LOCF on Air-Quality: MAE=0.2063, MSE=0.2445
2024-05-22 14:42:23 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-22 14:42:23 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-22 14:42:23 [INFO]: Median on Air-Quality: MAE=0.6676, MSE=1.0184
2024-05-22 14:42:23 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-22 14:42:23 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-22 14:42:23 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=0.9535
2024-05-22 14:42:23 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-22 14:42:23 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-22 14:42:23 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 14:42:25 [INFO]: Using the given device: cuda:0
2024-05-22 14:42:25 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240522_T144225
2024-05-22 14:42:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_air_quality/20240522_T144225/tensorboard
2024-05-22 14:42:25 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 14:42:26 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5294
2024-05-22 14:42:26 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.4074
2024-05-22 14:42:27 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.3280
2024-05-22 14:42:28 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.2911
2024-05-22 14:42:28 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2662
2024-05-22 14:42:29 [INFO]: Epoch 006 - training loss: 0.4870, validation loss: 0.2534
2024-05-22 14:42:30 [INFO]: Epoch 007 - training loss: 0.4609, validation loss: 0.2430
2024-05-22 14:42:30 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2362
2024-05-22 14:42:31 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.2302
2024-05-22 14:42:32 [INFO]: Epoch 010 - training loss: 0.4169, validation loss: 0.2254
2024-05-22 14:42:32 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.2208
2024-05-22 14:42:33 [INFO]: Epoch 012 - training loss: 0.3972, validation loss: 0.2165
2024-05-22 14:42:34 [INFO]: Epoch 013 - training loss: 0.3888, validation loss: 0.2142
2024-05-22 14:42:34 [INFO]: Epoch 014 - training loss: 0.3837, validation loss: 0.2110
2024-05-22 14:42:35 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.2111
2024-05-22 14:42:36 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2074
2024-05-22 14:42:36 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2045
2024-05-22 14:42:37 [INFO]: Epoch 018 - training loss: 0.3608, validation loss: 0.2023
2024-05-22 14:42:38 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.1997
2024-05-22 14:42:38 [INFO]: Epoch 020 - training loss: 0.3527, validation loss: 0.1987
2024-05-22 14:42:39 [INFO]: Epoch 021 - training loss: 0.3471, validation loss: 0.1968
2024-05-22 14:42:40 [INFO]: Epoch 022 - training loss: 0.3453, validation loss: 0.1949
2024-05-22 14:42:40 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.1951
2024-05-22 14:42:41 [INFO]: Epoch 024 - training loss: 0.3394, validation loss: 0.1928
2024-05-22 14:42:42 [INFO]: Epoch 025 - training loss: 0.3368, validation loss: 0.1908
2024-05-22 14:42:42 [INFO]: Epoch 026 - training loss: 0.3322, validation loss: 0.1891
2024-05-22 14:42:43 [INFO]: Epoch 027 - training loss: 0.3302, validation loss: 0.1877
2024-05-22 14:42:44 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1860
2024-05-22 14:42:44 [INFO]: Epoch 029 - training loss: 0.3269, validation loss: 0.1845
2024-05-22 14:42:45 [INFO]: Epoch 030 - training loss: 0.3236, validation loss: 0.1821
2024-05-22 14:42:46 [INFO]: Epoch 031 - training loss: 0.3215, validation loss: 0.1809
2024-05-22 14:42:46 [INFO]: Epoch 032 - training loss: 0.3223, validation loss: 0.1808
2024-05-22 14:42:47 [INFO]: Epoch 033 - training loss: 0.3180, validation loss: 0.1787
2024-05-22 14:42:48 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.1778
2024-05-22 14:42:48 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.1765
2024-05-22 14:42:49 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1750
2024-05-22 14:42:50 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1722
2024-05-22 14:42:50 [INFO]: Epoch 038 - training loss: 0.3082, validation loss: 0.1721
2024-05-22 14:42:51 [INFO]: Epoch 039 - training loss: 0.3080, validation loss: 0.1704
2024-05-22 14:42:52 [INFO]: Epoch 040 - training loss: 0.3068, validation loss: 0.1696
2024-05-22 14:42:52 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1686
2024-05-22 14:42:53 [INFO]: Epoch 042 - training loss: 0.3023, validation loss: 0.1674
2024-05-22 14:42:54 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1667
2024-05-22 14:42:54 [INFO]: Epoch 044 - training loss: 0.2989, validation loss: 0.1650
2024-05-22 14:42:55 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1644
2024-05-22 14:42:56 [INFO]: Epoch 046 - training loss: 0.2965, validation loss: 0.1638
2024-05-22 14:42:56 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1624
2024-05-22 14:42:57 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1613
2024-05-22 14:42:58 [INFO]: Epoch 049 - training loss: 0.2919, validation loss: 0.1604
2024-05-22 14:42:59 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1599
2024-05-22 14:42:59 [INFO]: Epoch 051 - training loss: 0.2896, validation loss: 0.1603
2024-05-22 14:43:00 [INFO]: Epoch 052 - training loss: 0.2874, validation loss: 0.1583
2024-05-22 14:43:01 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.1588
2024-05-22 14:43:01 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1578
2024-05-22 14:43:02 [INFO]: Epoch 055 - training loss: 0.2857, validation loss: 0.1578
2024-05-22 14:43:03 [INFO]: Epoch 056 - training loss: 0.2834, validation loss: 0.1558
2024-05-22 14:43:03 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1556
2024-05-22 14:43:04 [INFO]: Epoch 058 - training loss: 0.2803, validation loss: 0.1563
2024-05-22 14:43:05 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1554
2024-05-22 14:43:05 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1552
2024-05-22 14:43:06 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1547
2024-05-22 14:43:07 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.1541
2024-05-22 14:43:07 [INFO]: Epoch 063 - training loss: 0.2773, validation loss: 0.1541
2024-05-22 14:43:08 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.1543
2024-05-22 14:43:09 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.1526
2024-05-22 14:43:09 [INFO]: Epoch 066 - training loss: 0.2718, validation loss: 0.1529
2024-05-22 14:43:10 [INFO]: Epoch 067 - training loss: 0.2700, validation loss: 0.1525
2024-05-22 14:43:11 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1519
2024-05-22 14:43:11 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1510
2024-05-22 14:43:12 [INFO]: Epoch 070 - training loss: 0.2688, validation loss: 0.1511
2024-05-22 14:43:13 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.1510
2024-05-22 14:43:13 [INFO]: Epoch 072 - training loss: 0.2647, validation loss: 0.1511
2024-05-22 14:43:14 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1501
2024-05-22 14:43:15 [INFO]: Epoch 074 - training loss: 0.2642, validation loss: 0.1502
2024-05-22 14:43:15 [INFO]: Epoch 075 - training loss: 0.2643, validation loss: 0.1496
2024-05-22 14:43:16 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.1500
2024-05-22 14:43:17 [INFO]: Epoch 077 - training loss: 0.2623, validation loss: 0.1487
2024-05-22 14:43:17 [INFO]: Epoch 078 - training loss: 0.2622, validation loss: 0.1484
2024-05-22 14:43:18 [INFO]: Epoch 079 - training loss: 0.2613, validation loss: 0.1485
2024-05-22 14:43:19 [INFO]: Epoch 080 - training loss: 0.2599, validation loss: 0.1476
2024-05-22 14:43:19 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1486
2024-05-22 14:43:20 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1473
2024-05-22 14:43:21 [INFO]: Epoch 083 - training loss: 0.2577, validation loss: 0.1467
2024-05-22 14:43:21 [INFO]: Epoch 084 - training loss: 0.2559, validation loss: 0.1473
2024-05-22 14:43:22 [INFO]: Epoch 085 - training loss: 0.2556, validation loss: 0.1465
2024-05-22 14:43:23 [INFO]: Epoch 086 - training loss: 0.2547, validation loss: 0.1466
2024-05-22 14:43:23 [INFO]: Epoch 087 - training loss: 0.2541, validation loss: 0.1462
2024-05-22 14:43:24 [INFO]: Epoch 088 - training loss: 0.2544, validation loss: 0.1462
2024-05-22 14:43:25 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1464
2024-05-22 14:43:25 [INFO]: Epoch 090 - training loss: 0.2514, validation loss: 0.1458
2024-05-22 14:43:26 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1454
2024-05-22 14:43:27 [INFO]: Epoch 092 - training loss: 0.2498, validation loss: 0.1444
2024-05-22 14:43:27 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1443
2024-05-22 14:43:28 [INFO]: Epoch 094 - training loss: 0.2490, validation loss: 0.1441
2024-05-22 14:43:29 [INFO]: Epoch 095 - training loss: 0.2486, validation loss: 0.1431
2024-05-22 14:43:29 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1441
2024-05-22 14:43:30 [INFO]: Epoch 097 - training loss: 0.2492, validation loss: 0.1440
2024-05-22 14:43:31 [INFO]: Epoch 098 - training loss: 0.2497, validation loss: 0.1431
2024-05-22 14:43:31 [INFO]: Epoch 099 - training loss: 0.2462, validation loss: 0.1436
2024-05-22 14:43:32 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1425
2024-05-22 14:43:33 [INFO]: Epoch 101 - training loss: 0.2454, validation loss: 0.1431
2024-05-22 14:43:33 [INFO]: Epoch 102 - training loss: 0.2443, validation loss: 0.1423
2024-05-22 14:43:34 [INFO]: Epoch 103 - training loss: 0.2437, validation loss: 0.1420
2024-05-22 14:43:35 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1418
2024-05-22 14:43:35 [INFO]: Epoch 105 - training loss: 0.2429, validation loss: 0.1419
2024-05-22 14:43:36 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1412
2024-05-22 14:43:37 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1412
2024-05-22 14:43:37 [INFO]: Epoch 108 - training loss: 0.2458, validation loss: 0.1419
2024-05-22 14:43:38 [INFO]: Epoch 109 - training loss: 0.2415, validation loss: 0.1409
2024-05-22 14:43:39 [INFO]: Epoch 110 - training loss: 0.2437, validation loss: 0.1410
2024-05-22 14:43:39 [INFO]: Epoch 111 - training loss: 0.2404, validation loss: 0.1407
2024-05-22 14:43:40 [INFO]: Epoch 112 - training loss: 0.2382, validation loss: 0.1404
2024-05-22 14:43:41 [INFO]: Epoch 113 - training loss: 0.2407, validation loss: 0.1395
2024-05-22 14:43:41 [INFO]: Epoch 114 - training loss: 0.2383, validation loss: 0.1393
2024-05-22 14:43:42 [INFO]: Epoch 115 - training loss: 0.2384, validation loss: 0.1398
2024-05-22 14:43:43 [INFO]: Epoch 116 - training loss: 0.2383, validation loss: 0.1388
2024-05-22 14:43:43 [INFO]: Epoch 117 - training loss: 0.2398, validation loss: 0.1394
2024-05-22 14:43:44 [INFO]: Epoch 118 - training loss: 0.2380, validation loss: 0.1384
2024-05-22 14:43:45 [INFO]: Epoch 119 - training loss: 0.2366, validation loss: 0.1380
2024-05-22 14:43:45 [INFO]: Epoch 120 - training loss: 0.2358, validation loss: 0.1388
2024-05-22 14:43:46 [INFO]: Epoch 121 - training loss: 0.2358, validation loss: 0.1386
2024-05-22 14:43:47 [INFO]: Epoch 122 - training loss: 0.2340, validation loss: 0.1380
2024-05-22 14:43:47 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1379
2024-05-22 14:43:48 [INFO]: Epoch 124 - training loss: 0.2336, validation loss: 0.1381
2024-05-22 14:43:49 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1384
2024-05-22 14:43:49 [INFO]: Epoch 126 - training loss: 0.2329, validation loss: 0.1388
2024-05-22 14:43:50 [INFO]: Epoch 127 - training loss: 0.2338, validation loss: 0.1382
2024-05-22 14:43:51 [INFO]: Epoch 128 - training loss: 0.2339, validation loss: 0.1377
2024-05-22 14:43:51 [INFO]: Epoch 129 - training loss: 0.2318, validation loss: 0.1378
2024-05-22 14:43:52 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1377
2024-05-22 14:43:53 [INFO]: Epoch 131 - training loss: 0.2310, validation loss: 0.1374
2024-05-22 14:43:53 [INFO]: Epoch 132 - training loss: 0.2303, validation loss: 0.1373
2024-05-22 14:43:54 [INFO]: Epoch 133 - training loss: 0.2295, validation loss: 0.1370
2024-05-22 14:43:55 [INFO]: Epoch 134 - training loss: 0.2306, validation loss: 0.1366
2024-05-22 14:43:55 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1367
2024-05-22 14:43:56 [INFO]: Epoch 136 - training loss: 0.2286, validation loss: 0.1371
2024-05-22 14:43:57 [INFO]: Epoch 137 - training loss: 0.2277, validation loss: 0.1369
2024-05-22 14:43:57 [INFO]: Epoch 138 - training loss: 0.2286, validation loss: 0.1370
2024-05-22 14:43:58 [INFO]: Epoch 139 - training loss: 0.2281, validation loss: 0.1366
2024-05-22 14:43:59 [INFO]: Epoch 140 - training loss: 0.2268, validation loss: 0.1377
2024-05-22 14:43:59 [INFO]: Epoch 141 - training loss: 0.2287, validation loss: 0.1367
2024-05-22 14:44:00 [INFO]: Epoch 142 - training loss: 0.2293, validation loss: 0.1365
2024-05-22 14:44:01 [INFO]: Epoch 143 - training loss: 0.2273, validation loss: 0.1358
2024-05-22 14:44:01 [INFO]: Epoch 144 - training loss: 0.2264, validation loss: 0.1361
2024-05-22 14:44:02 [INFO]: Epoch 145 - training loss: 0.2261, validation loss: 0.1367
2024-05-22 14:44:03 [INFO]: Epoch 146 - training loss: 0.2251, validation loss: 0.1367
2024-05-22 14:44:03 [INFO]: Epoch 147 - training loss: 0.2251, validation loss: 0.1367
2024-05-22 14:44:04 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1350
2024-05-22 14:44:05 [INFO]: Epoch 149 - training loss: 0.2239, validation loss: 0.1353
2024-05-22 14:44:05 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1335
2024-05-22 14:44:06 [INFO]: Epoch 151 - training loss: 0.2231, validation loss: 0.1345
2024-05-22 14:44:07 [INFO]: Epoch 152 - training loss: 0.2238, validation loss: 0.1353
2024-05-22 14:44:07 [INFO]: Epoch 153 - training loss: 0.2231, validation loss: 0.1350
2024-05-22 14:44:08 [INFO]: Epoch 154 - training loss: 0.2222, validation loss: 0.1339
2024-05-22 14:44:09 [INFO]: Epoch 155 - training loss: 0.2226, validation loss: 0.1349
2024-05-22 14:44:09 [INFO]: Epoch 156 - training loss: 0.2233, validation loss: 0.1346
2024-05-22 14:44:10 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1347
2024-05-22 14:44:11 [INFO]: Epoch 158 - training loss: 0.2210, validation loss: 0.1340
2024-05-22 14:44:11 [INFO]: Epoch 159 - training loss: 0.2199, validation loss: 0.1336
2024-05-22 14:44:12 [INFO]: Epoch 160 - training loss: 0.2199, validation loss: 0.1336
2024-05-22 14:44:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:44:12 [INFO]: Finished training. The best model is from epoch#150.
2024-05-22 14:44:12 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_air_quality/20240522_T144225/SAITS.pypots
2024-05-22 14:44:12 [INFO]: SAITS on Air-Quality: MAE=0.1521, MSE=0.1251
2024-05-22 14:44:12 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-22 14:44:12 [INFO]: Using the given device: cuda:0
2024-05-22 14:44:12 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240522_T144412
2024-05-22 14:44:12 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_air_quality/20240522_T144412/tensorboard
2024-05-22 14:44:12 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 14:44:13 [INFO]: Epoch 001 - training loss: 0.9096, validation loss: 0.4645
2024-05-22 14:44:13 [INFO]: Epoch 002 - training loss: 0.5719, validation loss: 0.3555
2024-05-22 14:44:13 [INFO]: Epoch 003 - training loss: 0.4835, validation loss: 0.3000
2024-05-22 14:44:13 [INFO]: Epoch 004 - training loss: 0.4352, validation loss: 0.2767
2024-05-22 14:44:14 [INFO]: Epoch 005 - training loss: 0.4071, validation loss: 0.2560
2024-05-22 14:44:14 [INFO]: Epoch 006 - training loss: 0.3875, validation loss: 0.2485
2024-05-22 14:44:14 [INFO]: Epoch 007 - training loss: 0.3749, validation loss: 0.2424
2024-05-22 14:44:15 [INFO]: Epoch 008 - training loss: 0.3649, validation loss: 0.2378
2024-05-22 14:44:15 [INFO]: Epoch 009 - training loss: 0.3548, validation loss: 0.2323
2024-05-22 14:44:15 [INFO]: Epoch 010 - training loss: 0.3464, validation loss: 0.2278
2024-05-22 14:44:16 [INFO]: Epoch 011 - training loss: 0.3378, validation loss: 0.2233
2024-05-22 14:44:16 [INFO]: Epoch 012 - training loss: 0.3338, validation loss: 0.2209
2024-05-22 14:44:16 [INFO]: Epoch 013 - training loss: 0.3321, validation loss: 0.2186
2024-05-22 14:44:17 [INFO]: Epoch 014 - training loss: 0.3278, validation loss: 0.2140
2024-05-22 14:44:17 [INFO]: Epoch 015 - training loss: 0.3211, validation loss: 0.2107
2024-05-22 14:44:17 [INFO]: Epoch 016 - training loss: 0.3157, validation loss: 0.2066
2024-05-22 14:44:18 [INFO]: Epoch 017 - training loss: 0.3177, validation loss: 0.2053
2024-05-22 14:44:18 [INFO]: Epoch 018 - training loss: 0.3127, validation loss: 0.2020
2024-05-22 14:44:18 [INFO]: Epoch 019 - training loss: 0.3077, validation loss: 0.2018
2024-05-22 14:44:18 [INFO]: Epoch 020 - training loss: 0.3055, validation loss: 0.1981
2024-05-22 14:44:19 [INFO]: Epoch 021 - training loss: 0.3039, validation loss: 0.1965
2024-05-22 14:44:19 [INFO]: Epoch 022 - training loss: 0.3017, validation loss: 0.1944
2024-05-22 14:44:19 [INFO]: Epoch 023 - training loss: 0.2983, validation loss: 0.1930
2024-05-22 14:44:20 [INFO]: Epoch 024 - training loss: 0.2970, validation loss: 0.1898
2024-05-22 14:44:20 [INFO]: Epoch 025 - training loss: 0.2949, validation loss: 0.1896
2024-05-22 14:44:20 [INFO]: Epoch 026 - training loss: 0.2930, validation loss: 0.1886
2024-05-22 14:44:21 [INFO]: Epoch 027 - training loss: 0.2905, validation loss: 0.1865
2024-05-22 14:44:21 [INFO]: Epoch 028 - training loss: 0.2903, validation loss: 0.1857
2024-05-22 14:44:21 [INFO]: Epoch 029 - training loss: 0.2882, validation loss: 0.1854
2024-05-22 14:44:22 [INFO]: Epoch 030 - training loss: 0.2843, validation loss: 0.1849
2024-05-22 14:44:22 [INFO]: Epoch 031 - training loss: 0.2867, validation loss: 0.1834
2024-05-22 14:44:22 [INFO]: Epoch 032 - training loss: 0.2824, validation loss: 0.1819
2024-05-22 14:44:23 [INFO]: Epoch 033 - training loss: 0.2823, validation loss: 0.1821
2024-05-22 14:44:23 [INFO]: Epoch 034 - training loss: 0.2813, validation loss: 0.1822
2024-05-22 14:44:23 [INFO]: Epoch 035 - training loss: 0.2805, validation loss: 0.1815
2024-05-22 14:44:24 [INFO]: Epoch 036 - training loss: 0.2799, validation loss: 0.1799
2024-05-22 14:44:24 [INFO]: Epoch 037 - training loss: 0.2776, validation loss: 0.1798
2024-05-22 14:44:24 [INFO]: Epoch 038 - training loss: 0.2748, validation loss: 0.1785
2024-05-22 14:44:24 [INFO]: Epoch 039 - training loss: 0.2767, validation loss: 0.1780
2024-05-22 14:44:25 [INFO]: Epoch 040 - training loss: 0.2724, validation loss: 0.1773
2024-05-22 14:44:25 [INFO]: Epoch 041 - training loss: 0.2689, validation loss: 0.1768
2024-05-22 14:44:25 [INFO]: Epoch 042 - training loss: 0.2704, validation loss: 0.1764
2024-05-22 14:44:26 [INFO]: Epoch 043 - training loss: 0.2694, validation loss: 0.1740
2024-05-22 14:44:26 [INFO]: Epoch 044 - training loss: 0.2687, validation loss: 0.1750
2024-05-22 14:44:26 [INFO]: Epoch 045 - training loss: 0.2691, validation loss: 0.1760
2024-05-22 14:44:27 [INFO]: Epoch 046 - training loss: 0.2678, validation loss: 0.1753
2024-05-22 14:44:27 [INFO]: Epoch 047 - training loss: 0.2652, validation loss: 0.1759
2024-05-22 14:44:27 [INFO]: Epoch 048 - training loss: 0.2644, validation loss: 0.1732
2024-05-22 14:44:28 [INFO]: Epoch 049 - training loss: 0.2624, validation loss: 0.1746
2024-05-22 14:44:28 [INFO]: Epoch 050 - training loss: 0.2623, validation loss: 0.1743
2024-05-22 14:44:28 [INFO]: Epoch 051 - training loss: 0.2604, validation loss: 0.1717
2024-05-22 14:44:29 [INFO]: Epoch 052 - training loss: 0.2604, validation loss: 0.1707
2024-05-22 14:44:29 [INFO]: Epoch 053 - training loss: 0.2617, validation loss: 0.1719
2024-05-22 14:44:29 [INFO]: Epoch 054 - training loss: 0.2604, validation loss: 0.1728
2024-05-22 14:44:29 [INFO]: Epoch 055 - training loss: 0.2590, validation loss: 0.1723
2024-05-22 14:44:30 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.1708
2024-05-22 14:44:30 [INFO]: Epoch 057 - training loss: 0.2597, validation loss: 0.1718
2024-05-22 14:44:30 [INFO]: Epoch 058 - training loss: 0.2555, validation loss: 0.1682
2024-05-22 14:44:31 [INFO]: Epoch 059 - training loss: 0.2547, validation loss: 0.1683
2024-05-22 14:44:31 [INFO]: Epoch 060 - training loss: 0.2561, validation loss: 0.1696
2024-05-22 14:44:31 [INFO]: Epoch 061 - training loss: 0.2522, validation loss: 0.1687
2024-05-22 14:44:32 [INFO]: Epoch 062 - training loss: 0.2514, validation loss: 0.1680
2024-05-22 14:44:32 [INFO]: Epoch 063 - training loss: 0.2518, validation loss: 0.1668
2024-05-22 14:44:32 [INFO]: Epoch 064 - training loss: 0.2523, validation loss: 0.1660
2024-05-22 14:44:33 [INFO]: Epoch 065 - training loss: 0.2509, validation loss: 0.1678
2024-05-22 14:44:33 [INFO]: Epoch 066 - training loss: 0.2588, validation loss: 0.1690
2024-05-22 14:44:33 [INFO]: Epoch 067 - training loss: 0.2540, validation loss: 0.1674
2024-05-22 14:44:34 [INFO]: Epoch 068 - training loss: 0.2486, validation loss: 0.1647
2024-05-22 14:44:34 [INFO]: Epoch 069 - training loss: 0.2463, validation loss: 0.1653
2024-05-22 14:44:34 [INFO]: Epoch 070 - training loss: 0.2452, validation loss: 0.1656
2024-05-22 14:44:34 [INFO]: Epoch 071 - training loss: 0.2451, validation loss: 0.1653
2024-05-22 14:44:35 [INFO]: Epoch 072 - training loss: 0.2461, validation loss: 0.1645
2024-05-22 14:44:35 [INFO]: Epoch 073 - training loss: 0.2458, validation loss: 0.1645
2024-05-22 14:44:35 [INFO]: Epoch 074 - training loss: 0.2455, validation loss: 0.1643
2024-05-22 14:44:36 [INFO]: Epoch 075 - training loss: 0.2452, validation loss: 0.1640
2024-05-22 14:44:36 [INFO]: Epoch 076 - training loss: 0.2445, validation loss: 0.1629
2024-05-22 14:44:36 [INFO]: Epoch 077 - training loss: 0.2427, validation loss: 0.1636
2024-05-22 14:44:37 [INFO]: Epoch 078 - training loss: 0.2395, validation loss: 0.1641
2024-05-22 14:44:37 [INFO]: Epoch 079 - training loss: 0.2396, validation loss: 0.1620
2024-05-22 14:44:37 [INFO]: Epoch 080 - training loss: 0.2430, validation loss: 0.1638
2024-05-22 14:44:38 [INFO]: Epoch 081 - training loss: 0.2415, validation loss: 0.1622
2024-05-22 14:44:38 [INFO]: Epoch 082 - training loss: 0.2383, validation loss: 0.1631
2024-05-22 14:44:38 [INFO]: Epoch 083 - training loss: 0.2376, validation loss: 0.1618
2024-05-22 14:44:39 [INFO]: Epoch 084 - training loss: 0.2414, validation loss: 0.1611
2024-05-22 14:44:39 [INFO]: Epoch 085 - training loss: 0.2403, validation loss: 0.1599
2024-05-22 14:44:39 [INFO]: Epoch 086 - training loss: 0.2400, validation loss: 0.1610
2024-05-22 14:44:39 [INFO]: Epoch 087 - training loss: 0.2347, validation loss: 0.1613
2024-05-22 14:44:40 [INFO]: Epoch 088 - training loss: 0.2366, validation loss: 0.1598
2024-05-22 14:44:40 [INFO]: Epoch 089 - training loss: 0.2402, validation loss: 0.1608
2024-05-22 14:44:40 [INFO]: Epoch 090 - training loss: 0.2356, validation loss: 0.1597
2024-05-22 14:44:41 [INFO]: Epoch 091 - training loss: 0.2346, validation loss: 0.1608
2024-05-22 14:44:41 [INFO]: Epoch 092 - training loss: 0.2323, validation loss: 0.1592
2024-05-22 14:44:41 [INFO]: Epoch 093 - training loss: 0.2325, validation loss: 0.1590
2024-05-22 14:44:42 [INFO]: Epoch 094 - training loss: 0.2313, validation loss: 0.1586
2024-05-22 14:44:42 [INFO]: Epoch 095 - training loss: 0.2317, validation loss: 0.1593
2024-05-22 14:44:42 [INFO]: Epoch 096 - training loss: 0.2293, validation loss: 0.1584
2024-05-22 14:44:43 [INFO]: Epoch 097 - training loss: 0.2319, validation loss: 0.1590
2024-05-22 14:44:43 [INFO]: Epoch 098 - training loss: 0.2311, validation loss: 0.1569
2024-05-22 14:44:43 [INFO]: Epoch 099 - training loss: 0.2269, validation loss: 0.1586
2024-05-22 14:44:44 [INFO]: Epoch 100 - training loss: 0.2280, validation loss: 0.1571
2024-05-22 14:44:44 [INFO]: Epoch 101 - training loss: 0.2291, validation loss: 0.1557
2024-05-22 14:44:44 [INFO]: Epoch 102 - training loss: 0.2295, validation loss: 0.1585
2024-05-22 14:44:44 [INFO]: Epoch 103 - training loss: 0.2309, validation loss: 0.1569
2024-05-22 14:44:45 [INFO]: Epoch 104 - training loss: 0.2269, validation loss: 0.1548
2024-05-22 14:44:45 [INFO]: Epoch 105 - training loss: 0.2263, validation loss: 0.1554
2024-05-22 14:44:45 [INFO]: Epoch 106 - training loss: 0.2285, validation loss: 0.1543
2024-05-22 14:44:46 [INFO]: Epoch 107 - training loss: 0.2267, validation loss: 0.1559
2024-05-22 14:44:46 [INFO]: Epoch 108 - training loss: 0.2259, validation loss: 0.1537
2024-05-22 14:44:46 [INFO]: Epoch 109 - training loss: 0.2270, validation loss: 0.1531
2024-05-22 14:44:47 [INFO]: Epoch 110 - training loss: 0.2255, validation loss: 0.1542
2024-05-22 14:44:47 [INFO]: Epoch 111 - training loss: 0.2232, validation loss: 0.1530
2024-05-22 14:44:47 [INFO]: Epoch 112 - training loss: 0.2230, validation loss: 0.1533
2024-05-22 14:44:48 [INFO]: Epoch 113 - training loss: 0.2220, validation loss: 0.1554
2024-05-22 14:44:48 [INFO]: Epoch 114 - training loss: 0.2224, validation loss: 0.1531
2024-05-22 14:44:48 [INFO]: Epoch 115 - training loss: 0.2198, validation loss: 0.1551
2024-05-22 14:44:49 [INFO]: Epoch 116 - training loss: 0.2207, validation loss: 0.1526
2024-05-22 14:44:49 [INFO]: Epoch 117 - training loss: 0.2201, validation loss: 0.1523
2024-05-22 14:44:49 [INFO]: Epoch 118 - training loss: 0.2186, validation loss: 0.1543
2024-05-22 14:44:50 [INFO]: Epoch 119 - training loss: 0.2191, validation loss: 0.1524
2024-05-22 14:44:50 [INFO]: Epoch 120 - training loss: 0.2192, validation loss: 0.1524
2024-05-22 14:44:50 [INFO]: Epoch 121 - training loss: 0.2183, validation loss: 0.1514
2024-05-22 14:44:50 [INFO]: Epoch 122 - training loss: 0.2193, validation loss: 0.1516
2024-05-22 14:44:51 [INFO]: Epoch 123 - training loss: 0.2191, validation loss: 0.1524
2024-05-22 14:44:51 [INFO]: Epoch 124 - training loss: 0.2180, validation loss: 0.1511
2024-05-22 14:44:51 [INFO]: Epoch 125 - training loss: 0.2188, validation loss: 0.1520
2024-05-22 14:44:52 [INFO]: Epoch 126 - training loss: 0.2176, validation loss: 0.1510
2024-05-22 14:44:52 [INFO]: Epoch 127 - training loss: 0.2158, validation loss: 0.1502
2024-05-22 14:44:52 [INFO]: Epoch 128 - training loss: 0.2193, validation loss: 0.1523
2024-05-22 14:44:53 [INFO]: Epoch 129 - training loss: 0.2185, validation loss: 0.1516
2024-05-22 14:44:53 [INFO]: Epoch 130 - training loss: 0.2142, validation loss: 0.1514
2024-05-22 14:44:53 [INFO]: Epoch 131 - training loss: 0.2168, validation loss: 0.1508
2024-05-22 14:44:54 [INFO]: Epoch 132 - training loss: 0.2165, validation loss: 0.1507
2024-05-22 14:44:54 [INFO]: Epoch 133 - training loss: 0.2133, validation loss: 0.1500
2024-05-22 14:44:54 [INFO]: Epoch 134 - training loss: 0.2149, validation loss: 0.1507
2024-05-22 14:44:55 [INFO]: Epoch 135 - training loss: 0.2125, validation loss: 0.1506
2024-05-22 14:44:55 [INFO]: Epoch 136 - training loss: 0.2119, validation loss: 0.1504
2024-05-22 14:44:55 [INFO]: Epoch 137 - training loss: 0.2122, validation loss: 0.1496
2024-05-22 14:44:55 [INFO]: Epoch 138 - training loss: 0.2128, validation loss: 0.1498
2024-05-22 14:44:56 [INFO]: Epoch 139 - training loss: 0.2138, validation loss: 0.1497
2024-05-22 14:44:56 [INFO]: Epoch 140 - training loss: 0.2147, validation loss: 0.1500
2024-05-22 14:44:56 [INFO]: Epoch 141 - training loss: 0.2124, validation loss: 0.1492
2024-05-22 14:44:57 [INFO]: Epoch 142 - training loss: 0.2112, validation loss: 0.1493
2024-05-22 14:44:57 [INFO]: Epoch 143 - training loss: 0.2122, validation loss: 0.1496
2024-05-22 14:44:57 [INFO]: Epoch 144 - training loss: 0.2092, validation loss: 0.1477
2024-05-22 14:44:58 [INFO]: Epoch 145 - training loss: 0.2115, validation loss: 0.1483
2024-05-22 14:44:58 [INFO]: Epoch 146 - training loss: 0.2122, validation loss: 0.1475
2024-05-22 14:44:58 [INFO]: Epoch 147 - training loss: 0.2098, validation loss: 0.1491
2024-05-22 14:44:59 [INFO]: Epoch 148 - training loss: 0.2098, validation loss: 0.1484
2024-05-22 14:44:59 [INFO]: Epoch 149 - training loss: 0.2110, validation loss: 0.1491
2024-05-22 14:44:59 [INFO]: Epoch 150 - training loss: 0.2091, validation loss: 0.1483
2024-05-22 14:45:00 [INFO]: Epoch 151 - training loss: 0.2089, validation loss: 0.1474
2024-05-22 14:45:00 [INFO]: Epoch 152 - training loss: 0.2096, validation loss: 0.1468
2024-05-22 14:45:00 [INFO]: Epoch 153 - training loss: 0.2080, validation loss: 0.1486
2024-05-22 14:45:00 [INFO]: Epoch 154 - training loss: 0.2079, validation loss: 0.1474
2024-05-22 14:45:01 [INFO]: Epoch 155 - training loss: 0.2083, validation loss: 0.1464
2024-05-22 14:45:01 [INFO]: Epoch 156 - training loss: 0.2080, validation loss: 0.1472
2024-05-22 14:45:01 [INFO]: Epoch 157 - training loss: 0.2073, validation loss: 0.1469
2024-05-22 14:45:02 [INFO]: Epoch 158 - training loss: 0.2108, validation loss: 0.1463
2024-05-22 14:45:02 [INFO]: Epoch 159 - training loss: 0.2060, validation loss: 0.1467
2024-05-22 14:45:02 [INFO]: Epoch 160 - training loss: 0.2054, validation loss: 0.1467
2024-05-22 14:45:03 [INFO]: Epoch 161 - training loss: 0.2051, validation loss: 0.1462
2024-05-22 14:45:03 [INFO]: Epoch 162 - training loss: 0.2042, validation loss: 0.1481
2024-05-22 14:45:03 [INFO]: Epoch 163 - training loss: 0.2054, validation loss: 0.1466
2024-05-22 14:45:04 [INFO]: Epoch 164 - training loss: 0.2070, validation loss: 0.1464
2024-05-22 14:45:04 [INFO]: Epoch 165 - training loss: 0.2100, validation loss: 0.1455
2024-05-22 14:45:04 [INFO]: Epoch 166 - training loss: 0.2051, validation loss: 0.1452
2024-05-22 14:45:05 [INFO]: Epoch 167 - training loss: 0.2061, validation loss: 0.1455
2024-05-22 14:45:05 [INFO]: Epoch 168 - training loss: 0.2060, validation loss: 0.1448
2024-05-22 14:45:05 [INFO]: Epoch 169 - training loss: 0.2040, validation loss: 0.1449
2024-05-22 14:45:05 [INFO]: Epoch 170 - training loss: 0.2051, validation loss: 0.1447
2024-05-22 14:45:06 [INFO]: Epoch 171 - training loss: 0.2044, validation loss: 0.1459
2024-05-22 14:45:06 [INFO]: Epoch 172 - training loss: 0.2038, validation loss: 0.1442
2024-05-22 14:45:06 [INFO]: Epoch 173 - training loss: 0.2018, validation loss: 0.1445
2024-05-22 14:45:07 [INFO]: Epoch 174 - training loss: 0.2009, validation loss: 0.1455
2024-05-22 14:45:07 [INFO]: Epoch 175 - training loss: 0.2048, validation loss: 0.1488
2024-05-22 14:45:07 [INFO]: Epoch 176 - training loss: 0.2017, validation loss: 0.1445
2024-05-22 14:45:08 [INFO]: Epoch 177 - training loss: 0.2013, validation loss: 0.1448
2024-05-22 14:45:08 [INFO]: Epoch 178 - training loss: 0.2010, validation loss: 0.1458
2024-05-22 14:45:08 [INFO]: Epoch 179 - training loss: 0.1997, validation loss: 0.1448
2024-05-22 14:45:09 [INFO]: Epoch 180 - training loss: 0.2025, validation loss: 0.1457
2024-05-22 14:45:09 [INFO]: Epoch 181 - training loss: 0.2014, validation loss: 0.1448
2024-05-22 14:45:09 [INFO]: Epoch 182 - training loss: 0.2016, validation loss: 0.1430
2024-05-22 14:45:10 [INFO]: Epoch 183 - training loss: 0.2005, validation loss: 0.1438
2024-05-22 14:45:10 [INFO]: Epoch 184 - training loss: 0.2011, validation loss: 0.1435
2024-05-22 14:45:10 [INFO]: Epoch 185 - training loss: 0.2000, validation loss: 0.1443
2024-05-22 14:45:10 [INFO]: Epoch 186 - training loss: 0.2016, validation loss: 0.1445
2024-05-22 14:45:11 [INFO]: Epoch 187 - training loss: 0.2016, validation loss: 0.1415
2024-05-22 14:45:11 [INFO]: Epoch 188 - training loss: 0.1987, validation loss: 0.1429
2024-05-22 14:45:11 [INFO]: Epoch 189 - training loss: 0.1970, validation loss: 0.1444
2024-05-22 14:45:12 [INFO]: Epoch 190 - training loss: 0.1979, validation loss: 0.1425
2024-05-22 14:45:12 [INFO]: Epoch 191 - training loss: 0.1975, validation loss: 0.1433
2024-05-22 14:45:12 [INFO]: Epoch 192 - training loss: 0.1975, validation loss: 0.1440
2024-05-22 14:45:13 [INFO]: Epoch 193 - training loss: 0.1993, validation loss: 0.1431
2024-05-22 14:45:13 [INFO]: Epoch 194 - training loss: 0.1963, validation loss: 0.1426
2024-05-22 14:45:13 [INFO]: Epoch 195 - training loss: 0.1947, validation loss: 0.1438
2024-05-22 14:45:14 [INFO]: Epoch 196 - training loss: 0.1951, validation loss: 0.1423
2024-05-22 14:45:14 [INFO]: Epoch 197 - training loss: 0.1953, validation loss: 0.1424
2024-05-22 14:45:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:45:14 [INFO]: Finished training. The best model is from epoch#187.
2024-05-22 14:45:14 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_air_quality/20240522_T144412/Transformer.pypots
2024-05-22 14:45:14 [INFO]: Transformer on Air-Quality: MAE=0.1627, MSE=0.1346
2024-05-22 14:45:14 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-22 14:45:14 [INFO]: Using the given device: cuda:0
2024-05-22 14:45:14 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240522_T144514
2024-05-22 14:45:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_air_quality/20240522_T144514/tensorboard
2024-05-22 14:45:14 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 14:45:15 [INFO]: Epoch 001 - training loss: 0.2960, validation loss: 0.2789
2024-05-22 14:45:16 [INFO]: Epoch 002 - training loss: 0.2076, validation loss: 0.2501
2024-05-22 14:45:16 [INFO]: Epoch 003 - training loss: 0.1926, validation loss: 0.2364
2024-05-22 14:45:17 [INFO]: Epoch 004 - training loss: 0.1742, validation loss: 0.2117
2024-05-22 14:45:17 [INFO]: Epoch 005 - training loss: 0.1740, validation loss: 0.2014
2024-05-22 14:45:18 [INFO]: Epoch 006 - training loss: 0.1566, validation loss: 0.1997
2024-05-22 14:45:18 [INFO]: Epoch 007 - training loss: 0.1638, validation loss: 0.1923
2024-05-22 14:45:19 [INFO]: Epoch 008 - training loss: 0.1734, validation loss: 0.1971
2024-05-22 14:45:19 [INFO]: Epoch 009 - training loss: 0.1411, validation loss: 0.1939
2024-05-22 14:45:20 [INFO]: Epoch 010 - training loss: 0.1440, validation loss: 0.1830
2024-05-22 14:45:20 [INFO]: Epoch 011 - training loss: 0.1442, validation loss: 0.1895
2024-05-22 14:45:21 [INFO]: Epoch 012 - training loss: 0.1359, validation loss: 0.1830
2024-05-22 14:45:21 [INFO]: Epoch 013 - training loss: 0.1447, validation loss: 0.1776
2024-05-22 14:45:22 [INFO]: Epoch 014 - training loss: 0.1477, validation loss: 0.1783
2024-05-22 14:45:22 [INFO]: Epoch 015 - training loss: 0.1367, validation loss: 0.1852
2024-05-22 14:45:23 [INFO]: Epoch 016 - training loss: 0.1291, validation loss: 0.1766
2024-05-22 14:45:23 [INFO]: Epoch 017 - training loss: 0.1443, validation loss: 0.1840
2024-05-22 14:45:24 [INFO]: Epoch 018 - training loss: 0.1276, validation loss: 0.1777
2024-05-22 14:45:24 [INFO]: Epoch 019 - training loss: 0.1254, validation loss: 0.1829
2024-05-22 14:45:25 [INFO]: Epoch 020 - training loss: 0.1119, validation loss: 0.1849
2024-05-22 14:45:25 [INFO]: Epoch 021 - training loss: 0.1201, validation loss: 0.1794
2024-05-22 14:45:26 [INFO]: Epoch 022 - training loss: 0.1196, validation loss: 0.1786
2024-05-22 14:45:26 [INFO]: Epoch 023 - training loss: 0.1418, validation loss: 0.1772
2024-05-22 14:45:27 [INFO]: Epoch 024 - training loss: 0.1204, validation loss: 0.1749
2024-05-22 14:45:28 [INFO]: Epoch 025 - training loss: 0.1154, validation loss: 0.1745
2024-05-22 14:45:28 [INFO]: Epoch 026 - training loss: 0.1419, validation loss: 0.1765
2024-05-22 14:45:29 [INFO]: Epoch 027 - training loss: 0.1356, validation loss: 0.1773
2024-05-22 14:45:29 [INFO]: Epoch 028 - training loss: 0.1246, validation loss: 0.1660
2024-05-22 14:45:30 [INFO]: Epoch 029 - training loss: 0.1113, validation loss: 0.1698
2024-05-22 14:45:30 [INFO]: Epoch 030 - training loss: 0.1111, validation loss: 0.1757
2024-05-22 14:45:31 [INFO]: Epoch 031 - training loss: 0.1217, validation loss: 0.1749
2024-05-22 14:45:31 [INFO]: Epoch 032 - training loss: 0.1294, validation loss: 0.1783
2024-05-22 14:45:32 [INFO]: Epoch 033 - training loss: 0.1136, validation loss: 0.1744
2024-05-22 14:45:32 [INFO]: Epoch 034 - training loss: 0.1111, validation loss: 0.1733
2024-05-22 14:45:33 [INFO]: Epoch 035 - training loss: 0.1194, validation loss: 0.1628
2024-05-22 14:45:33 [INFO]: Epoch 036 - training loss: 0.1403, validation loss: 0.1628
2024-05-22 14:45:34 [INFO]: Epoch 037 - training loss: 0.1149, validation loss: 0.1651
2024-05-22 14:45:34 [INFO]: Epoch 038 - training loss: 0.1165, validation loss: 0.1615
2024-05-22 14:45:35 [INFO]: Epoch 039 - training loss: 0.1124, validation loss: 0.1657
2024-05-22 14:45:35 [INFO]: Epoch 040 - training loss: 0.1163, validation loss: 0.1647
2024-05-22 14:45:36 [INFO]: Epoch 041 - training loss: 0.1138, validation loss: 0.1711
2024-05-22 14:45:36 [INFO]: Epoch 042 - training loss: 0.1139, validation loss: 0.1744
2024-05-22 14:45:37 [INFO]: Epoch 043 - training loss: 0.1008, validation loss: 0.1684
2024-05-22 14:45:37 [INFO]: Epoch 044 - training loss: 0.0985, validation loss: 0.1736
2024-05-22 14:45:38 [INFO]: Epoch 045 - training loss: 0.1022, validation loss: 0.1628
2024-05-22 14:45:38 [INFO]: Epoch 046 - training loss: 0.1219, validation loss: 0.1600
2024-05-22 14:45:39 [INFO]: Epoch 047 - training loss: 0.1019, validation loss: 0.1651
2024-05-22 14:45:39 [INFO]: Epoch 048 - training loss: 0.0992, validation loss: 0.1719
2024-05-22 14:45:40 [INFO]: Epoch 049 - training loss: 0.0980, validation loss: 0.1641
2024-05-22 14:45:41 [INFO]: Epoch 050 - training loss: 0.1018, validation loss: 0.1693
2024-05-22 14:45:41 [INFO]: Epoch 051 - training loss: 0.0848, validation loss: 0.1719
2024-05-22 14:45:42 [INFO]: Epoch 052 - training loss: 0.1366, validation loss: 0.1708
2024-05-22 14:45:42 [INFO]: Epoch 053 - training loss: 0.1025, validation loss: 0.1701
2024-05-22 14:45:43 [INFO]: Epoch 054 - training loss: 0.1086, validation loss: 0.1736
2024-05-22 14:45:43 [INFO]: Epoch 055 - training loss: 0.1007, validation loss: 0.1723
2024-05-22 14:45:44 [INFO]: Epoch 056 - training loss: 0.1092, validation loss: 0.1672
2024-05-22 14:45:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 14:45:44 [INFO]: Finished training. The best model is from epoch#46.
2024-05-22 14:45:44 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_air_quality/20240522_T144514/TimesNet.pypots
2024-05-22 14:45:44 [INFO]: TimesNet on Air-Quality: MAE=0.1605, MSE=0.1674
2024-05-22 14:45:44 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-22 14:45:44 [INFO]: Using the given device: cuda:0
2024-05-22 14:45:44 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544
2024-05-22 14:45:44 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/tensorboard
2024-05-22 14:45:44 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 14:46:01 [INFO]: Epoch 001 - training loss: 0.4818, validation loss: 0.3362
2024-05-22 14:46:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch1_loss0.33624855875968934.pypots
2024-05-22 14:46:18 [INFO]: Epoch 002 - training loss: 0.2907, validation loss: 0.2838
2024-05-22 14:46:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch2_loss0.28378571271896363.pypots
2024-05-22 14:46:34 [INFO]: Epoch 003 - training loss: 0.2708, validation loss: 0.2368
2024-05-22 14:46:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch3_loss0.23675543665885926.pypots
2024-05-22 14:46:51 [INFO]: Epoch 004 - training loss: 0.2467, validation loss: 0.2087
2024-05-22 14:46:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch4_loss0.20873269587755203.pypots
2024-05-22 14:47:08 [INFO]: Epoch 005 - training loss: 0.1952, validation loss: 0.1902
2024-05-22 14:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch5_loss0.19021790325641633.pypots
2024-05-22 14:47:25 [INFO]: Epoch 006 - training loss: 0.1996, validation loss: 0.1729
2024-05-22 14:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch6_loss0.17289212793111802.pypots
2024-05-22 14:47:42 [INFO]: Epoch 007 - training loss: 0.2118, validation loss: 0.1650
2024-05-22 14:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch7_loss0.16503966003656387.pypots
2024-05-22 14:47:58 [INFO]: Epoch 008 - training loss: 0.1728, validation loss: 0.1676
2024-05-22 14:47:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch8_loss0.16760480999946595.pypots
2024-05-22 14:48:15 [INFO]: Epoch 009 - training loss: 0.1752, validation loss: 0.1570
2024-05-22 14:48:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch9_loss0.1569633886218071.pypots
2024-05-22 14:48:32 [INFO]: Epoch 010 - training loss: 0.1789, validation loss: 0.1564
2024-05-22 14:48:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch10_loss0.15644439607858657.pypots
2024-05-22 14:48:49 [INFO]: Epoch 011 - training loss: 0.1751, validation loss: 0.1493
2024-05-22 14:48:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch11_loss0.149260076880455.pypots
2024-05-22 14:49:06 [INFO]: Epoch 012 - training loss: 0.1627, validation loss: 0.1466
2024-05-22 14:49:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch12_loss0.14663726091384888.pypots
2024-05-22 14:49:23 [INFO]: Epoch 013 - training loss: 0.1682, validation loss: 0.1464
2024-05-22 14:49:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch13_loss0.1464494913816452.pypots
2024-05-22 14:49:39 [INFO]: Epoch 014 - training loss: 0.1569, validation loss: 0.1452
2024-05-22 14:49:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch14_loss0.14515492618083953.pypots
2024-05-22 14:49:56 [INFO]: Epoch 015 - training loss: 0.1664, validation loss: 0.1471
2024-05-22 14:49:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch15_loss0.1470601812005043.pypots
2024-05-22 14:50:13 [INFO]: Epoch 016 - training loss: 0.1587, validation loss: 0.1428
2024-05-22 14:50:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch16_loss0.14280746057629584.pypots
2024-05-22 14:50:30 [INFO]: Epoch 017 - training loss: 0.1610, validation loss: 0.1452
2024-05-22 14:50:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch17_loss0.14519651383161544.pypots
2024-05-22 14:50:47 [INFO]: Epoch 018 - training loss: 0.1578, validation loss: 0.1386
2024-05-22 14:50:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch18_loss0.1386166162788868.pypots
2024-05-22 14:51:03 [INFO]: Epoch 019 - training loss: 0.1699, validation loss: 0.1356
2024-05-22 14:51:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch19_loss0.1356293648481369.pypots
2024-05-22 14:51:20 [INFO]: Epoch 020 - training loss: 0.1431, validation loss: 0.1365
2024-05-22 14:51:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch20_loss0.13649583980441093.pypots
2024-05-22 14:51:37 [INFO]: Epoch 021 - training loss: 0.1652, validation loss: 0.1345
2024-05-22 14:51:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch21_loss0.13449186086654663.pypots
2024-05-22 14:51:54 [INFO]: Epoch 022 - training loss: 0.1530, validation loss: 0.1393
2024-05-22 14:51:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch22_loss0.13927531987428665.pypots
2024-05-22 14:52:11 [INFO]: Epoch 023 - training loss: 0.1489, validation loss: 0.1331
2024-05-22 14:52:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch23_loss0.13309585601091384.pypots
2024-05-22 14:52:28 [INFO]: Epoch 024 - training loss: 0.1430, validation loss: 0.1308
2024-05-22 14:52:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch24_loss0.13078735545277595.pypots
2024-05-22 14:52:44 [INFO]: Epoch 025 - training loss: 0.1547, validation loss: 0.1341
2024-05-22 14:52:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch25_loss0.13407162204384804.pypots
2024-05-22 14:53:01 [INFO]: Epoch 026 - training loss: 0.1560, validation loss: 0.1287
2024-05-22 14:53:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch26_loss0.12870323807001113.pypots
2024-05-22 14:53:18 [INFO]: Epoch 027 - training loss: 0.1532, validation loss: 0.1301
2024-05-22 14:53:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch27_loss0.13008956909179686.pypots
2024-05-22 14:53:35 [INFO]: Epoch 028 - training loss: 0.1305, validation loss: 0.1267
2024-05-22 14:53:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch28_loss0.12673317342996598.pypots
2024-05-22 14:53:52 [INFO]: Epoch 029 - training loss: 0.1410, validation loss: 0.1337
2024-05-22 14:53:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch29_loss0.13367182314395903.pypots
2024-05-22 14:54:08 [INFO]: Epoch 030 - training loss: 0.1290, validation loss: 0.1256
2024-05-22 14:54:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch30_loss0.12564409598708154.pypots
2024-05-22 14:54:25 [INFO]: Epoch 031 - training loss: 0.1438, validation loss: 0.1243
2024-05-22 14:54:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch31_loss0.12433234304189682.pypots
2024-05-22 14:54:42 [INFO]: Epoch 032 - training loss: 0.1295, validation loss: 0.1223
2024-05-22 14:54:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch32_loss0.12234492599964142.pypots
2024-05-22 14:54:59 [INFO]: Epoch 033 - training loss: 0.1431, validation loss: 0.1251
2024-05-22 14:54:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch33_loss0.1251070186495781.pypots
2024-05-22 14:55:16 [INFO]: Epoch 034 - training loss: 0.1474, validation loss: 0.1213
2024-05-22 14:55:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch34_loss0.12126585692167283.pypots
2024-05-22 14:55:33 [INFO]: Epoch 035 - training loss: 0.1291, validation loss: 0.1237
2024-05-22 14:55:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch35_loss0.12373514324426652.pypots
2024-05-22 14:55:49 [INFO]: Epoch 036 - training loss: 0.1290, validation loss: 0.1250
2024-05-22 14:55:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch36_loss0.12501651123166085.pypots
2024-05-22 14:56:06 [INFO]: Epoch 037 - training loss: 0.1388, validation loss: 0.1235
2024-05-22 14:56:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch37_loss0.12352227941155433.pypots
2024-05-22 14:56:23 [INFO]: Epoch 038 - training loss: 0.1202, validation loss: 0.1198
2024-05-22 14:56:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch38_loss0.11977258622646332.pypots
2024-05-22 14:56:40 [INFO]: Epoch 039 - training loss: 0.1303, validation loss: 0.1181
2024-05-22 14:56:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch39_loss0.11810329407453538.pypots
2024-05-22 14:56:57 [INFO]: Epoch 040 - training loss: 0.1364, validation loss: 0.1243
2024-05-22 14:56:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch40_loss0.1242670789361.pypots
2024-05-22 14:57:13 [INFO]: Epoch 041 - training loss: 0.1269, validation loss: 0.1247
2024-05-22 14:57:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch41_loss0.12472190782427788.pypots
2024-05-22 14:57:30 [INFO]: Epoch 042 - training loss: 0.1344, validation loss: 0.1204
2024-05-22 14:57:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch42_loss0.1204379066824913.pypots
2024-05-22 14:57:47 [INFO]: Epoch 043 - training loss: 0.1300, validation loss: 0.1163
2024-05-22 14:57:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch43_loss0.11634219512343406.pypots
2024-05-22 14:58:04 [INFO]: Epoch 044 - training loss: 0.1239, validation loss: 0.1219
2024-05-22 14:58:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch44_loss0.12187552303075791.pypots
2024-05-22 14:58:21 [INFO]: Epoch 045 - training loss: 0.1135, validation loss: 0.1174
2024-05-22 14:58:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch45_loss0.11742972880601883.pypots
2024-05-22 14:58:38 [INFO]: Epoch 046 - training loss: 0.1254, validation loss: 0.1153
2024-05-22 14:58:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch46_loss0.1152806743979454.pypots
2024-05-22 14:58:54 [INFO]: Epoch 047 - training loss: 0.1245, validation loss: 0.1153
2024-05-22 14:58:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch47_loss0.11533094719052314.pypots
2024-05-22 14:59:11 [INFO]: Epoch 048 - training loss: 0.1355, validation loss: 0.1142
2024-05-22 14:59:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch48_loss0.11415880694985389.pypots
2024-05-22 14:59:28 [INFO]: Epoch 049 - training loss: 0.1251, validation loss: 0.1132
2024-05-22 14:59:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch49_loss0.11322231739759445.pypots
2024-05-22 14:59:45 [INFO]: Epoch 050 - training loss: 0.1182, validation loss: 0.1152
2024-05-22 14:59:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch50_loss0.11516654342412949.pypots
2024-05-22 15:00:02 [INFO]: Epoch 051 - training loss: 0.1212, validation loss: 0.1142
2024-05-22 15:00:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch51_loss0.11417808830738067.pypots
2024-05-22 15:00:18 [INFO]: Epoch 052 - training loss: 0.1335, validation loss: 0.1148
2024-05-22 15:00:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch52_loss0.1147542305290699.pypots
2024-05-22 15:00:35 [INFO]: Epoch 053 - training loss: 0.1099, validation loss: 0.1113
2024-05-22 15:00:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch53_loss0.11126070916652679.pypots
2024-05-22 15:00:52 [INFO]: Epoch 054 - training loss: 0.1231, validation loss: 0.1111
2024-05-22 15:00:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch54_loss0.11111656725406646.pypots
2024-05-22 15:01:09 [INFO]: Epoch 055 - training loss: 0.1106, validation loss: 0.1123
2024-05-22 15:01:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch55_loss0.11231587305665017.pypots
2024-05-22 15:01:26 [INFO]: Epoch 056 - training loss: 0.1204, validation loss: 0.1113
2024-05-22 15:01:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch56_loss0.11134854331612587.pypots
2024-05-22 15:01:43 [INFO]: Epoch 057 - training loss: 0.1240, validation loss: 0.1095
2024-05-22 15:01:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch57_loss0.10951485112309456.pypots
2024-05-22 15:01:59 [INFO]: Epoch 058 - training loss: 0.1273, validation loss: 0.1086
2024-05-22 15:01:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch58_loss0.1086430773139.pypots
2024-05-22 15:02:16 [INFO]: Epoch 059 - training loss: 0.1160, validation loss: 0.1104
2024-05-22 15:02:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch59_loss0.11037591844797134.pypots
2024-05-22 15:02:33 [INFO]: Epoch 060 - training loss: 0.1034, validation loss: 0.1098
2024-05-22 15:02:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch60_loss0.1098458930850029.pypots
2024-05-22 15:02:50 [INFO]: Epoch 061 - training loss: 0.1346, validation loss: 0.1099
2024-05-22 15:02:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch61_loss0.10990381836891175.pypots
2024-05-22 15:03:07 [INFO]: Epoch 062 - training loss: 0.1246, validation loss: 0.1083
2024-05-22 15:03:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch62_loss0.10833305269479751.pypots
2024-05-22 15:03:23 [INFO]: Epoch 063 - training loss: 0.1197, validation loss: 0.1088
2024-05-22 15:03:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch63_loss0.10875253602862359.pypots
2024-05-22 15:03:40 [INFO]: Epoch 064 - training loss: 0.1198, validation loss: 0.1097
2024-05-22 15:03:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch64_loss0.10967945829033851.pypots
2024-05-22 15:03:57 [INFO]: Epoch 065 - training loss: 0.1362, validation loss: 0.1133
2024-05-22 15:03:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch65_loss0.11328503862023354.pypots
2024-05-22 15:04:14 [INFO]: Epoch 066 - training loss: 0.1244, validation loss: 0.1108
2024-05-22 15:04:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch66_loss0.11077319905161857.pypots
2024-05-22 15:04:31 [INFO]: Epoch 067 - training loss: 0.1247, validation loss: 0.1076
2024-05-22 15:04:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch67_loss0.10756269097328186.pypots
2024-05-22 15:04:47 [INFO]: Epoch 068 - training loss: 0.1143, validation loss: 0.1094
2024-05-22 15:04:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch68_loss0.10944032520055771.pypots
2024-05-22 15:05:04 [INFO]: Epoch 069 - training loss: 0.1223, validation loss: 0.1058
2024-05-22 15:05:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch69_loss0.10575921833515167.pypots
2024-05-22 15:05:21 [INFO]: Epoch 070 - training loss: 0.1073, validation loss: 0.1072
2024-05-22 15:05:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch70_loss0.10720557272434235.pypots
2024-05-22 15:05:38 [INFO]: Epoch 071 - training loss: 0.1252, validation loss: 0.1140
2024-05-22 15:05:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch71_loss0.11397709921002389.pypots
2024-05-22 15:05:55 [INFO]: Epoch 072 - training loss: 0.1441, validation loss: 0.1080
2024-05-22 15:05:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch72_loss0.10799513682723046.pypots
2024-05-22 15:06:12 [INFO]: Epoch 073 - training loss: 0.1239, validation loss: 0.1054
2024-05-22 15:06:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch73_loss0.1053568921983242.pypots
2024-05-22 15:06:28 [INFO]: Epoch 074 - training loss: 0.1267, validation loss: 0.1049
2024-05-22 15:06:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch74_loss0.10491861328482628.pypots
2024-05-22 15:06:45 [INFO]: Epoch 075 - training loss: 0.1218, validation loss: 0.1044
2024-05-22 15:06:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch75_loss0.10438657253980636.pypots
2024-05-22 15:07:02 [INFO]: Epoch 076 - training loss: 0.1061, validation loss: 0.1067
2024-05-22 15:07:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch76_loss0.10674760043621064.pypots
2024-05-22 15:07:19 [INFO]: Epoch 077 - training loss: 0.1314, validation loss: 0.1063
2024-05-22 15:07:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch77_loss0.10634273961186409.pypots
2024-05-22 15:07:36 [INFO]: Epoch 078 - training loss: 0.1139, validation loss: 0.1053
2024-05-22 15:07:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch78_loss0.10532799437642097.pypots
2024-05-22 15:07:52 [INFO]: Epoch 079 - training loss: 0.1072, validation loss: 0.1061
2024-05-22 15:07:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch79_loss0.10606246739625931.pypots
2024-05-22 15:08:09 [INFO]: Epoch 080 - training loss: 0.1247, validation loss: 0.1061
2024-05-22 15:08:09 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch80_loss0.10612045675516128.pypots
2024-05-22 15:08:26 [INFO]: Epoch 081 - training loss: 0.1202, validation loss: 0.1039
2024-05-22 15:08:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch81_loss0.10386273264884949.pypots
2024-05-22 15:08:43 [INFO]: Epoch 082 - training loss: 0.1200, validation loss: 0.1073
2024-05-22 15:08:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch82_loss0.10728219673037528.pypots
2024-05-22 15:09:00 [INFO]: Epoch 083 - training loss: 0.1047, validation loss: 0.1049
2024-05-22 15:09:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch83_loss0.10493303164839744.pypots
2024-05-22 15:09:17 [INFO]: Epoch 084 - training loss: 0.1036, validation loss: 0.1040
2024-05-22 15:09:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch84_loss0.10403548553586006.pypots
2024-05-22 15:09:33 [INFO]: Epoch 085 - training loss: 0.1102, validation loss: 0.1031
2024-05-22 15:09:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch85_loss0.10313165634870529.pypots
2024-05-22 15:09:50 [INFO]: Epoch 086 - training loss: 0.1230, validation loss: 0.1023
2024-05-22 15:09:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch86_loss0.10225313603878021.pypots
2024-05-22 15:10:07 [INFO]: Epoch 087 - training loss: 0.1042, validation loss: 0.1056
2024-05-22 15:10:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch87_loss0.10558666735887527.pypots
2024-05-22 15:10:24 [INFO]: Epoch 088 - training loss: 0.1089, validation loss: 0.1057
2024-05-22 15:10:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch88_loss0.1057414472103119.pypots
2024-05-22 15:10:41 [INFO]: Epoch 089 - training loss: 0.1233, validation loss: 0.1015
2024-05-22 15:10:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch89_loss0.10151971206068992.pypots
2024-05-22 15:10:57 [INFO]: Epoch 090 - training loss: 0.1037, validation loss: 0.1032
2024-05-22 15:10:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch90_loss0.10317478328943253.pypots
2024-05-22 15:11:14 [INFO]: Epoch 091 - training loss: 0.1245, validation loss: 0.1033
2024-05-22 15:11:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch91_loss0.10326973795890808.pypots
2024-05-22 15:11:31 [INFO]: Epoch 092 - training loss: 0.1114, validation loss: 0.1028
2024-05-22 15:11:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch92_loss0.102793388068676.pypots
2024-05-22 15:11:48 [INFO]: Epoch 093 - training loss: 0.1217, validation loss: 0.1026
2024-05-22 15:11:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch93_loss0.10257765576243401.pypots
2024-05-22 15:12:05 [INFO]: Epoch 094 - training loss: 0.1007, validation loss: 0.1037
2024-05-22 15:12:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch94_loss0.10371566563844681.pypots
2024-05-22 15:12:22 [INFO]: Epoch 095 - training loss: 0.1074, validation loss: 0.1026
2024-05-22 15:12:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch95_loss0.10259877368807793.pypots
2024-05-22 15:12:38 [INFO]: Epoch 096 - training loss: 0.1114, validation loss: 0.1028
2024-05-22 15:12:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch96_loss0.10279560759663582.pypots
2024-05-22 15:12:55 [INFO]: Epoch 097 - training loss: 0.1170, validation loss: 0.1032
2024-05-22 15:12:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch97_loss0.10320226624608039.pypots
2024-05-22 15:13:12 [INFO]: Epoch 098 - training loss: 0.1105, validation loss: 0.1024
2024-05-22 15:13:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch98_loss0.1023983635008335.pypots
2024-05-22 15:13:29 [INFO]: Epoch 099 - training loss: 0.1000, validation loss: 0.1013
2024-05-22 15:13:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch99_loss0.10130739361047744.pypots
2024-05-22 15:13:46 [INFO]: Epoch 100 - training loss: 0.1176, validation loss: 0.0996
2024-05-22 15:13:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch100_loss0.09963513240218162.pypots
2024-05-22 15:14:02 [INFO]: Epoch 101 - training loss: 0.1063, validation loss: 0.1011
2024-05-22 15:14:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch101_loss0.10112537145614624.pypots
2024-05-22 15:14:19 [INFO]: Epoch 102 - training loss: 0.1169, validation loss: 0.1078
2024-05-22 15:14:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch102_loss0.10776849538087845.pypots
2024-05-22 15:14:36 [INFO]: Epoch 103 - training loss: 0.1146, validation loss: 0.1017
2024-05-22 15:14:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch103_loss0.10174869671463967.pypots
2024-05-22 15:14:53 [INFO]: Epoch 104 - training loss: 0.1062, validation loss: 0.1027
2024-05-22 15:14:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch104_loss0.10271222665905952.pypots
2024-05-22 15:15:10 [INFO]: Epoch 105 - training loss: 0.1193, validation loss: 0.1073
2024-05-22 15:15:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch105_loss0.10730984136462211.pypots
2024-05-22 15:15:27 [INFO]: Epoch 106 - training loss: 0.1039, validation loss: 0.1015
2024-05-22 15:15:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch106_loss0.10153021514415742.pypots
2024-05-22 15:15:43 [INFO]: Epoch 107 - training loss: 0.1180, validation loss: 0.0993
2024-05-22 15:15:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch107_loss0.09932563751935959.pypots
2024-05-22 15:16:00 [INFO]: Epoch 108 - training loss: 0.1067, validation loss: 0.1027
2024-05-22 15:16:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch108_loss0.10269928202033043.pypots
2024-05-22 15:16:17 [INFO]: Epoch 109 - training loss: 0.1204, validation loss: 0.1022
2024-05-22 15:16:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch109_loss0.10219306647777557.pypots
2024-05-22 15:16:34 [INFO]: Epoch 110 - training loss: 0.1101, validation loss: 0.1048
2024-05-22 15:16:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch110_loss0.10478566512465477.pypots
2024-05-22 15:16:51 [INFO]: Epoch 111 - training loss: 0.1155, validation loss: 0.1003
2024-05-22 15:16:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch111_loss0.10028282180428505.pypots
2024-05-22 15:17:07 [INFO]: Epoch 112 - training loss: 0.1285, validation loss: 0.1022
2024-05-22 15:17:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch112_loss0.10218822658061981.pypots
2024-05-22 15:17:24 [INFO]: Epoch 113 - training loss: 0.1111, validation loss: 0.1015
2024-05-22 15:17:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch113_loss0.10146099850535392.pypots
2024-05-22 15:17:41 [INFO]: Epoch 114 - training loss: 0.1044, validation loss: 0.0976
2024-05-22 15:17:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch114_loss0.09763765633106232.pypots
2024-05-22 15:17:58 [INFO]: Epoch 115 - training loss: 0.1194, validation loss: 0.1015
2024-05-22 15:17:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch115_loss0.10145597234368324.pypots
2024-05-22 15:18:15 [INFO]: Epoch 116 - training loss: 0.1002, validation loss: 0.1011
2024-05-22 15:18:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch116_loss0.1011448159813881.pypots
2024-05-22 15:18:32 [INFO]: Epoch 117 - training loss: 0.1216, validation loss: 0.0987
2024-05-22 15:18:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch117_loss0.09873794168233871.pypots
2024-05-22 15:18:48 [INFO]: Epoch 118 - training loss: 0.1061, validation loss: 0.1021
2024-05-22 15:18:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch118_loss0.10211819708347321.pypots
2024-05-22 15:19:05 [INFO]: Epoch 119 - training loss: 0.1173, validation loss: 0.1042
2024-05-22 15:19:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch119_loss0.10424264147877693.pypots
2024-05-22 15:19:22 [INFO]: Epoch 120 - training loss: 0.1269, validation loss: 0.1013
2024-05-22 15:19:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch120_loss0.1013339564204216.pypots
2024-05-22 15:19:39 [INFO]: Epoch 121 - training loss: 0.1194, validation loss: 0.0993
2024-05-22 15:19:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch121_loss0.09927466437220574.pypots
2024-05-22 15:19:56 [INFO]: Epoch 122 - training loss: 0.1014, validation loss: 0.1022
2024-05-22 15:19:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch122_loss0.10221508145332336.pypots
2024-05-22 15:20:12 [INFO]: Epoch 123 - training loss: 0.1186, validation loss: 0.1017
2024-05-22 15:20:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch123_loss0.10171108543872834.pypots
2024-05-22 15:20:29 [INFO]: Epoch 124 - training loss: 0.1057, validation loss: 0.0993
2024-05-22 15:20:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI_epoch124_loss0.09932331293821335.pypots
2024-05-22 15:20:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:20:29 [INFO]: Finished training. The best model is from epoch#114.
2024-05-22 15:20:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_air_quality/20240522_T144544/CSDI.pypots
2024-05-22 15:22:50 [INFO]: CSDI on Air-Quality: MAE=0.1015, MSE=0.1459
2024-05-22 15:22:50 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-22 15:22:50 [INFO]: Using the given device: cuda:0
2024-05-22 15:22:50 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240522_T152250
2024-05-22 15:22:50 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_air_quality/20240522_T152250/tensorboard
2024-05-22 15:22:50 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 15:22:50 [INFO]: Epoch 001 - training loss: 62831.3831, validation loss: 0.6592
2024-05-22 15:22:50 [INFO]: Epoch 002 - training loss: 42084.1043, validation loss: 0.5810
2024-05-22 15:22:51 [INFO]: Epoch 003 - training loss: 41757.8388, validation loss: 0.5211
2024-05-22 15:22:51 [INFO]: Epoch 004 - training loss: 41618.9242, validation loss: 0.4728
2024-05-22 15:22:51 [INFO]: Epoch 005 - training loss: 41546.8303, validation loss: 0.4458
2024-05-22 15:22:52 [INFO]: Epoch 006 - training loss: 41638.1955, validation loss: 0.4553
2024-05-22 15:22:52 [INFO]: Epoch 007 - training loss: 41499.8299, validation loss: 0.4057
2024-05-22 15:22:52 [INFO]: Epoch 008 - training loss: 41425.5012, validation loss: 0.3784
2024-05-22 15:22:53 [INFO]: Epoch 009 - training loss: 41392.8413, validation loss: 0.3558
2024-05-22 15:22:53 [INFO]: Epoch 010 - training loss: 41363.1620, validation loss: 0.3498
2024-05-22 15:22:53 [INFO]: Epoch 011 - training loss: 41361.2642, validation loss: 0.3330
2024-05-22 15:22:54 [INFO]: Epoch 012 - training loss: 41353.6869, validation loss: 0.3355
2024-05-22 15:22:54 [INFO]: Epoch 013 - training loss: 41340.2451, validation loss: 0.3345
2024-05-22 15:22:54 [INFO]: Epoch 014 - training loss: 41351.6223, validation loss: 0.3330
2024-05-22 15:22:55 [INFO]: Epoch 015 - training loss: 41330.8122, validation loss: 0.3281
2024-05-22 15:22:55 [INFO]: Epoch 016 - training loss: 41302.3249, validation loss: 0.3149
2024-05-22 15:22:55 [INFO]: Epoch 017 - training loss: 41289.8715, validation loss: 0.3035
2024-05-22 15:22:56 [INFO]: Epoch 018 - training loss: 41283.0713, validation loss: 0.3088
2024-05-22 15:22:56 [INFO]: Epoch 019 - training loss: 41279.8228, validation loss: 0.3321
2024-05-22 15:22:56 [INFO]: Epoch 020 - training loss: 41286.0315, validation loss: 0.3090
2024-05-22 15:22:57 [INFO]: Epoch 021 - training loss: 41266.5900, validation loss: 0.2971
2024-05-22 15:22:57 [INFO]: Epoch 022 - training loss: 41263.2221, validation loss: 0.2839
2024-05-22 15:22:57 [INFO]: Epoch 023 - training loss: 41250.5043, validation loss: 0.2798
2024-05-22 15:22:58 [INFO]: Epoch 024 - training loss: 41252.2378, validation loss: 0.2846
2024-05-22 15:22:58 [INFO]: Epoch 025 - training loss: 41233.9999, validation loss: 0.2727
2024-05-22 15:22:58 [INFO]: Epoch 026 - training loss: 41228.3128, validation loss: 0.2760
2024-05-22 15:22:59 [INFO]: Epoch 027 - training loss: 41274.1764, validation loss: 0.3497
2024-05-22 15:22:59 [INFO]: Epoch 028 - training loss: 41286.0806, validation loss: 0.2841
2024-05-22 15:22:59 [INFO]: Epoch 029 - training loss: 41230.2869, validation loss: 0.2670
2024-05-22 15:23:00 [INFO]: Epoch 030 - training loss: 41220.7182, validation loss: 0.2719
2024-05-22 15:23:00 [INFO]: Epoch 031 - training loss: 41214.4573, validation loss: 0.2625
2024-05-22 15:23:00 [INFO]: Epoch 032 - training loss: 41200.4086, validation loss: 0.2618
2024-05-22 15:23:01 [INFO]: Epoch 033 - training loss: 41199.9618, validation loss: 0.2584
2024-05-22 15:23:01 [INFO]: Epoch 034 - training loss: 41204.5861, validation loss: 0.2589
2024-05-22 15:23:01 [INFO]: Epoch 035 - training loss: 41202.9080, validation loss: 0.2483
2024-05-22 15:23:01 [INFO]: Epoch 036 - training loss: 41215.4674, validation loss: 0.2713
2024-05-22 15:23:02 [INFO]: Epoch 037 - training loss: 41365.0488, validation loss: 0.3062
2024-05-22 15:23:02 [INFO]: Epoch 038 - training loss: 41263.4592, validation loss: 0.2629
2024-05-22 15:23:02 [INFO]: Epoch 039 - training loss: 41217.5998, validation loss: 0.2720
2024-05-22 15:23:03 [INFO]: Epoch 040 - training loss: 41212.2293, validation loss: 0.2646
2024-05-22 15:23:03 [INFO]: Epoch 041 - training loss: 41201.5492, validation loss: 0.2672
2024-05-22 15:23:03 [INFO]: Epoch 042 - training loss: 41194.1856, validation loss: 0.2543
2024-05-22 15:23:04 [INFO]: Epoch 043 - training loss: 41179.4867, validation loss: 0.2452
2024-05-22 15:23:04 [INFO]: Epoch 044 - training loss: 41181.5369, validation loss: 0.2602
2024-05-22 15:23:04 [INFO]: Epoch 045 - training loss: 41182.1338, validation loss: 0.2454
2024-05-22 15:23:05 [INFO]: Epoch 046 - training loss: 41174.5315, validation loss: 0.2439
2024-05-22 15:23:05 [INFO]: Epoch 047 - training loss: 41168.4823, validation loss: 0.2413
2024-05-22 15:23:05 [INFO]: Epoch 048 - training loss: 41169.1939, validation loss: 0.2447
2024-05-22 15:23:06 [INFO]: Epoch 049 - training loss: 41164.4094, validation loss: 0.2380
2024-05-22 15:23:06 [INFO]: Epoch 050 - training loss: 41164.0035, validation loss: 0.2381
2024-05-22 15:23:06 [INFO]: Epoch 051 - training loss: 41165.3992, validation loss: 0.2452
2024-05-22 15:23:07 [INFO]: Epoch 052 - training loss: 41168.8581, validation loss: 0.2472
2024-05-22 15:23:07 [INFO]: Epoch 053 - training loss: 41190.8964, validation loss: 0.2538
2024-05-22 15:23:07 [INFO]: Epoch 054 - training loss: 41169.5069, validation loss: 0.2739
2024-05-22 15:23:08 [INFO]: Epoch 055 - training loss: 41203.7323, validation loss: 0.2587
2024-05-22 15:23:08 [INFO]: Epoch 056 - training loss: 41185.9252, validation loss: 0.2665
2024-05-22 15:23:08 [INFO]: Epoch 057 - training loss: 41231.1128, validation loss: 0.2620
2024-05-22 15:23:09 [INFO]: Epoch 058 - training loss: 41183.3152, validation loss: 0.2488
2024-05-22 15:23:09 [INFO]: Epoch 059 - training loss: 41162.6361, validation loss: 0.2537
2024-05-22 15:23:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:23:09 [INFO]: Finished training. The best model is from epoch#49.
2024-05-22 15:23:09 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_air_quality/20240522_T152250/GPVAE.pypots
2024-05-22 15:23:09 [INFO]: GP-VAE on Air-Quality: MAE=0.2785, MSE=0.2473
2024-05-22 15:23:09 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-22 15:23:09 [INFO]: Using the given device: cuda:0
2024-05-22 15:23:09 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240522_T152309
2024-05-22 15:23:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_air_quality/20240522_T152309/tensorboard
2024-05-22 15:23:09 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 15:23:14 [INFO]: Epoch 001 - generator training loss: 0.6005, discriminator training loss: 0.2878, validation loss: 0.5188
2024-05-22 15:23:18 [INFO]: Epoch 002 - generator training loss: 0.2828, discriminator training loss: 0.0676, validation loss: 0.3830
2024-05-22 15:23:22 [INFO]: Epoch 003 - generator training loss: 0.2073, discriminator training loss: 0.0632, validation loss: 0.3203
2024-05-22 15:23:26 [INFO]: Epoch 004 - generator training loss: 0.1704, discriminator training loss: 0.0620, validation loss: 0.2809
2024-05-22 15:23:30 [INFO]: Epoch 005 - generator training loss: 0.1474, discriminator training loss: 0.0620, validation loss: 0.2560
2024-05-22 15:23:34 [INFO]: Epoch 006 - generator training loss: 0.1292, discriminator training loss: 0.0608, validation loss: 0.2386
2024-05-22 15:23:38 [INFO]: Epoch 007 - generator training loss: 0.1162, discriminator training loss: 0.0605, validation loss: 0.2264
2024-05-22 15:23:42 [INFO]: Epoch 008 - generator training loss: 0.1075, discriminator training loss: 0.0603, validation loss: 0.2170
2024-05-22 15:23:46 [INFO]: Epoch 009 - generator training loss: 0.0989, discriminator training loss: 0.0592, validation loss: 0.2088
2024-05-22 15:23:50 [INFO]: Epoch 010 - generator training loss: 0.0926, discriminator training loss: 0.0582, validation loss: 0.2030
2024-05-22 15:23:54 [INFO]: Epoch 011 - generator training loss: 0.0862, discriminator training loss: 0.0574, validation loss: 0.1977
2024-05-22 15:23:58 [INFO]: Epoch 012 - generator training loss: 0.0832, discriminator training loss: 0.0557, validation loss: 0.1927
2024-05-22 15:24:02 [INFO]: Epoch 013 - generator training loss: 0.0814, discriminator training loss: 0.0538, validation loss: 0.1885
2024-05-22 15:24:06 [INFO]: Epoch 014 - generator training loss: 0.0778, discriminator training loss: 0.0519, validation loss: 0.1855
2024-05-22 15:24:10 [INFO]: Epoch 015 - generator training loss: 0.0754, discriminator training loss: 0.0506, validation loss: 0.1819
2024-05-22 15:24:14 [INFO]: Epoch 016 - generator training loss: 0.0748, discriminator training loss: 0.0490, validation loss: 0.1788
2024-05-22 15:24:18 [INFO]: Epoch 017 - generator training loss: 0.0712, discriminator training loss: 0.0473, validation loss: 0.1763
2024-05-22 15:24:22 [INFO]: Epoch 018 - generator training loss: 0.0699, discriminator training loss: 0.0462, validation loss: 0.1740
2024-05-22 15:24:26 [INFO]: Epoch 019 - generator training loss: 0.0676, discriminator training loss: 0.0457, validation loss: 0.1721
2024-05-22 15:24:30 [INFO]: Epoch 020 - generator training loss: 0.0668, discriminator training loss: 0.0457, validation loss: 0.1700
2024-05-22 15:24:34 [INFO]: Epoch 021 - generator training loss: 0.0659, discriminator training loss: 0.0441, validation loss: 0.1693
2024-05-22 15:24:38 [INFO]: Epoch 022 - generator training loss: 0.0634, discriminator training loss: 0.0436, validation loss: 0.1674
2024-05-22 15:24:42 [INFO]: Epoch 023 - generator training loss: 0.0627, discriminator training loss: 0.0426, validation loss: 0.1653
2024-05-22 15:24:46 [INFO]: Epoch 024 - generator training loss: 0.0629, discriminator training loss: 0.0426, validation loss: 0.1649
2024-05-22 15:24:50 [INFO]: Epoch 025 - generator training loss: 0.0602, discriminator training loss: 0.0419, validation loss: 0.1629
2024-05-22 15:24:54 [INFO]: Epoch 026 - generator training loss: 0.0596, discriminator training loss: 0.0409, validation loss: 0.1622
2024-05-22 15:24:58 [INFO]: Epoch 027 - generator training loss: 0.0579, discriminator training loss: 0.0399, validation loss: 0.1610
2024-05-22 15:25:02 [INFO]: Epoch 028 - generator training loss: 0.0574, discriminator training loss: 0.0393, validation loss: 0.1605
2024-05-22 15:25:06 [INFO]: Epoch 029 - generator training loss: 0.0571, discriminator training loss: 0.0391, validation loss: 0.1585
2024-05-22 15:25:10 [INFO]: Epoch 030 - generator training loss: 0.0549, discriminator training loss: 0.0385, validation loss: 0.1583
2024-05-22 15:25:14 [INFO]: Epoch 031 - generator training loss: 0.0556, discriminator training loss: 0.0370, validation loss: 0.1574
2024-05-22 15:25:18 [INFO]: Epoch 032 - generator training loss: 0.0543, discriminator training loss: 0.0357, validation loss: 0.1560
2024-05-22 15:25:23 [INFO]: Epoch 033 - generator training loss: 0.0530, discriminator training loss: 0.0350, validation loss: 0.1550
2024-05-22 15:25:27 [INFO]: Epoch 034 - generator training loss: 0.0519, discriminator training loss: 0.0345, validation loss: 0.1542
2024-05-22 15:25:31 [INFO]: Epoch 035 - generator training loss: 0.0506, discriminator training loss: 0.0339, validation loss: 0.1530
2024-05-22 15:25:35 [INFO]: Epoch 036 - generator training loss: 0.0507, discriminator training loss: 0.0332, validation loss: 0.1518
2024-05-22 15:25:39 [INFO]: Epoch 037 - generator training loss: 0.0503, discriminator training loss: 0.0324, validation loss: 0.1513
2024-05-22 15:25:43 [INFO]: Epoch 038 - generator training loss: 0.0500, discriminator training loss: 0.0316, validation loss: 0.1504
2024-05-22 15:25:47 [INFO]: Epoch 039 - generator training loss: 0.0490, discriminator training loss: 0.0308, validation loss: 0.1491
2024-05-22 15:25:51 [INFO]: Epoch 040 - generator training loss: 0.0491, discriminator training loss: 0.0303, validation loss: 0.1487
2024-05-22 15:25:55 [INFO]: Epoch 041 - generator training loss: 0.0487, discriminator training loss: 0.0300, validation loss: 0.1479
2024-05-22 15:25:59 [INFO]: Epoch 042 - generator training loss: 0.0481, discriminator training loss: 0.0292, validation loss: 0.1469
2024-05-22 15:26:03 [INFO]: Epoch 043 - generator training loss: 0.0474, discriminator training loss: 0.0285, validation loss: 0.1464
2024-05-22 15:26:07 [INFO]: Epoch 044 - generator training loss: 0.0462, discriminator training loss: 0.0283, validation loss: 0.1457
2024-05-22 15:26:11 [INFO]: Epoch 045 - generator training loss: 0.0468, discriminator training loss: 0.0278, validation loss: 0.1444
2024-05-22 15:26:15 [INFO]: Epoch 046 - generator training loss: 0.0464, discriminator training loss: 0.0272, validation loss: 0.1446
2024-05-22 15:26:19 [INFO]: Epoch 047 - generator training loss: 0.0456, discriminator training loss: 0.0267, validation loss: 0.1437
2024-05-22 15:26:23 [INFO]: Epoch 048 - generator training loss: 0.0455, discriminator training loss: 0.0264, validation loss: 0.1433
2024-05-22 15:26:27 [INFO]: Epoch 049 - generator training loss: 0.0451, discriminator training loss: 0.0259, validation loss: 0.1429
2024-05-22 15:26:31 [INFO]: Epoch 050 - generator training loss: 0.0442, discriminator training loss: 0.0257, validation loss: 0.1418
2024-05-22 15:26:35 [INFO]: Epoch 051 - generator training loss: 0.0444, discriminator training loss: 0.0252, validation loss: 0.1417
2024-05-22 15:26:39 [INFO]: Epoch 052 - generator training loss: 0.0445, discriminator training loss: 0.0245, validation loss: 0.1409
2024-05-22 15:26:43 [INFO]: Epoch 053 - generator training loss: 0.0444, discriminator training loss: 0.0241, validation loss: 0.1403
2024-05-22 15:26:47 [INFO]: Epoch 054 - generator training loss: 0.0436, discriminator training loss: 0.0240, validation loss: 0.1403
2024-05-22 15:26:51 [INFO]: Epoch 055 - generator training loss: 0.0435, discriminator training loss: 0.0237, validation loss: 0.1396
2024-05-22 15:26:55 [INFO]: Epoch 056 - generator training loss: 0.0442, discriminator training loss: 0.0230, validation loss: 0.1387
2024-05-22 15:26:59 [INFO]: Epoch 057 - generator training loss: 0.0430, discriminator training loss: 0.0230, validation loss: 0.1387
2024-05-22 15:27:03 [INFO]: Epoch 058 - generator training loss: 0.0428, discriminator training loss: 0.0227, validation loss: 0.1382
2024-05-22 15:27:07 [INFO]: Epoch 059 - generator training loss: 0.0428, discriminator training loss: 0.0228, validation loss: 0.1380
2024-05-22 15:27:11 [INFO]: Epoch 060 - generator training loss: 0.0417, discriminator training loss: 0.0224, validation loss: 0.1373
2024-05-22 15:27:15 [INFO]: Epoch 061 - generator training loss: 0.0423, discriminator training loss: 0.0218, validation loss: 0.1374
2024-05-22 15:27:19 [INFO]: Epoch 062 - generator training loss: 0.0418, discriminator training loss: 0.0215, validation loss: 0.1367
2024-05-22 15:27:23 [INFO]: Epoch 063 - generator training loss: 0.0411, discriminator training loss: 0.0213, validation loss: 0.1363
2024-05-22 15:27:27 [INFO]: Epoch 064 - generator training loss: 0.0406, discriminator training loss: 0.0212, validation loss: 0.1362
2024-05-22 15:27:31 [INFO]: Epoch 065 - generator training loss: 0.0412, discriminator training loss: 0.0208, validation loss: 0.1355
2024-05-22 15:27:35 [INFO]: Epoch 066 - generator training loss: 0.0409, discriminator training loss: 0.0206, validation loss: 0.1355
2024-05-22 15:27:39 [INFO]: Epoch 067 - generator training loss: 0.0405, discriminator training loss: 0.0204, validation loss: 0.1349
2024-05-22 15:27:43 [INFO]: Epoch 068 - generator training loss: 0.0404, discriminator training loss: 0.0201, validation loss: 0.1351
2024-05-22 15:27:47 [INFO]: Epoch 069 - generator training loss: 0.0401, discriminator training loss: 0.0199, validation loss: 0.1344
2024-05-22 15:27:51 [INFO]: Epoch 070 - generator training loss: 0.0402, discriminator training loss: 0.0202, validation loss: 0.1349
2024-05-22 15:27:55 [INFO]: Epoch 071 - generator training loss: 0.0394, discriminator training loss: 0.0196, validation loss: 0.1349
2024-05-22 15:27:59 [INFO]: Epoch 072 - generator training loss: 0.0392, discriminator training loss: 0.0195, validation loss: 0.1340
2024-05-22 15:28:03 [INFO]: Epoch 073 - generator training loss: 0.0394, discriminator training loss: 0.0191, validation loss: 0.1341
2024-05-22 15:28:07 [INFO]: Epoch 074 - generator training loss: 0.0396, discriminator training loss: 0.0190, validation loss: 0.1335
2024-05-22 15:28:11 [INFO]: Epoch 075 - generator training loss: 0.0405, discriminator training loss: 0.0187, validation loss: 0.1342
2024-05-22 15:28:16 [INFO]: Epoch 076 - generator training loss: 0.0386, discriminator training loss: 0.0184, validation loss: 0.1330
2024-05-22 15:28:20 [INFO]: Epoch 077 - generator training loss: 0.0383, discriminator training loss: 0.0183, validation loss: 0.1333
2024-05-22 15:28:24 [INFO]: Epoch 078 - generator training loss: 0.0383, discriminator training loss: 0.0180, validation loss: 0.1332
2024-05-22 15:28:28 [INFO]: Epoch 079 - generator training loss: 0.0385, discriminator training loss: 0.0180, validation loss: 0.1329
2024-05-22 15:28:32 [INFO]: Epoch 080 - generator training loss: 0.0384, discriminator training loss: 0.0181, validation loss: 0.1320
2024-05-22 15:28:36 [INFO]: Epoch 081 - generator training loss: 0.0376, discriminator training loss: 0.0179, validation loss: 0.1328
2024-05-22 15:28:40 [INFO]: Epoch 082 - generator training loss: 0.0377, discriminator training loss: 0.0177, validation loss: 0.1321
2024-05-22 15:28:44 [INFO]: Epoch 083 - generator training loss: 0.0377, discriminator training loss: 0.0176, validation loss: 0.1320
2024-05-22 15:28:48 [INFO]: Epoch 084 - generator training loss: 0.0372, discriminator training loss: 0.0174, validation loss: 0.1317
2024-05-22 15:28:52 [INFO]: Epoch 085 - generator training loss: 0.0369, discriminator training loss: 0.0174, validation loss: 0.1315
2024-05-22 15:28:56 [INFO]: Epoch 086 - generator training loss: 0.0367, discriminator training loss: 0.0171, validation loss: 0.1316
2024-05-22 15:29:00 [INFO]: Epoch 087 - generator training loss: 0.0371, discriminator training loss: 0.0169, validation loss: 0.1320
2024-05-22 15:29:04 [INFO]: Epoch 088 - generator training loss: 0.0365, discriminator training loss: 0.0169, validation loss: 0.1304
2024-05-22 15:29:08 [INFO]: Epoch 089 - generator training loss: 0.0359, discriminator training loss: 0.0167, validation loss: 0.1308
2024-05-22 15:29:12 [INFO]: Epoch 090 - generator training loss: 0.0357, discriminator training loss: 0.0167, validation loss: 0.1311
2024-05-22 15:29:16 [INFO]: Epoch 091 - generator training loss: 0.0362, discriminator training loss: 0.0166, validation loss: 0.1314
2024-05-22 15:29:20 [INFO]: Epoch 092 - generator training loss: 0.0359, discriminator training loss: 0.0162, validation loss: 0.1314
2024-05-22 15:29:24 [INFO]: Epoch 093 - generator training loss: 0.0354, discriminator training loss: 0.0163, validation loss: 0.1307
2024-05-22 15:29:28 [INFO]: Epoch 094 - generator training loss: 0.0350, discriminator training loss: 0.0161, validation loss: 0.1317
2024-05-22 15:29:32 [INFO]: Epoch 095 - generator training loss: 0.0352, discriminator training loss: 0.0161, validation loss: 0.1305
2024-05-22 15:29:36 [INFO]: Epoch 096 - generator training loss: 0.0355, discriminator training loss: 0.0159, validation loss: 0.1314
2024-05-22 15:29:40 [INFO]: Epoch 097 - generator training loss: 0.0359, discriminator training loss: 0.0159, validation loss: 0.1312
2024-05-22 15:29:44 [INFO]: Epoch 098 - generator training loss: 0.0344, discriminator training loss: 0.0158, validation loss: 0.1300
2024-05-22 15:29:48 [INFO]: Epoch 099 - generator training loss: 0.0344, discriminator training loss: 0.0158, validation loss: 0.1302
2024-05-22 15:29:52 [INFO]: Epoch 100 - generator training loss: 0.0343, discriminator training loss: 0.0155, validation loss: 0.1312
2024-05-22 15:29:56 [INFO]: Epoch 101 - generator training loss: 0.0341, discriminator training loss: 0.0158, validation loss: 0.1297
2024-05-22 15:30:00 [INFO]: Epoch 102 - generator training loss: 0.0341, discriminator training loss: 0.0154, validation loss: 0.1304
2024-05-22 15:30:04 [INFO]: Epoch 103 - generator training loss: 0.0339, discriminator training loss: 0.0154, validation loss: 0.1312
2024-05-22 15:30:08 [INFO]: Epoch 104 - generator training loss: 0.0338, discriminator training loss: 0.0152, validation loss: 0.1296
2024-05-22 15:30:12 [INFO]: Epoch 105 - generator training loss: 0.0341, discriminator training loss: 0.0154, validation loss: 0.1296
2024-05-22 15:30:16 [INFO]: Epoch 106 - generator training loss: 0.0338, discriminator training loss: 0.0152, validation loss: 0.1295
2024-05-22 15:30:20 [INFO]: Epoch 107 - generator training loss: 0.0333, discriminator training loss: 0.0151, validation loss: 0.1299
2024-05-22 15:30:24 [INFO]: Epoch 108 - generator training loss: 0.0331, discriminator training loss: 0.0151, validation loss: 0.1294
2024-05-22 15:30:28 [INFO]: Epoch 109 - generator training loss: 0.0327, discriminator training loss: 0.0149, validation loss: 0.1299
2024-05-22 15:30:32 [INFO]: Epoch 110 - generator training loss: 0.0323, discriminator training loss: 0.0150, validation loss: 0.1303
2024-05-22 15:30:36 [INFO]: Epoch 111 - generator training loss: 0.0328, discriminator training loss: 0.0148, validation loss: 0.1298
2024-05-22 15:30:40 [INFO]: Epoch 112 - generator training loss: 0.0323, discriminator training loss: 0.0147, validation loss: 0.1299
2024-05-22 15:30:44 [INFO]: Epoch 113 - generator training loss: 0.0337, discriminator training loss: 0.0147, validation loss: 0.1308
2024-05-22 15:30:48 [INFO]: Epoch 114 - generator training loss: 0.0324, discriminator training loss: 0.0146, validation loss: 0.1304
2024-05-22 15:30:52 [INFO]: Epoch 115 - generator training loss: 0.0324, discriminator training loss: 0.0147, validation loss: 0.1296
2024-05-22 15:30:56 [INFO]: Epoch 116 - generator training loss: 0.0323, discriminator training loss: 0.0143, validation loss: 0.1293
2024-05-22 15:31:00 [INFO]: Epoch 117 - generator training loss: 0.0324, discriminator training loss: 0.0143, validation loss: 0.1325
2024-05-22 15:31:04 [INFO]: Epoch 118 - generator training loss: 0.0326, discriminator training loss: 0.0144, validation loss: 0.1294
2024-05-22 15:31:08 [INFO]: Epoch 119 - generator training loss: 0.0322, discriminator training loss: 0.0143, validation loss: 0.1295
2024-05-22 15:31:12 [INFO]: Epoch 120 - generator training loss: 0.0313, discriminator training loss: 0.0144, validation loss: 0.1287
2024-05-22 15:31:16 [INFO]: Epoch 121 - generator training loss: 0.0309, discriminator training loss: 0.0142, validation loss: 0.1292
2024-05-22 15:31:20 [INFO]: Epoch 122 - generator training loss: 0.0307, discriminator training loss: 0.0142, validation loss: 0.1291
2024-05-22 15:31:24 [INFO]: Epoch 123 - generator training loss: 0.0317, discriminator training loss: 0.0140, validation loss: 0.1288
2024-05-22 15:31:28 [INFO]: Epoch 124 - generator training loss: 0.0308, discriminator training loss: 0.0141, validation loss: 0.1291
2024-05-22 15:31:32 [INFO]: Epoch 125 - generator training loss: 0.0305, discriminator training loss: 0.0141, validation loss: 0.1282
2024-05-22 15:31:36 [INFO]: Epoch 126 - generator training loss: 0.0307, discriminator training loss: 0.0138, validation loss: 0.1284
2024-05-22 15:31:40 [INFO]: Epoch 127 - generator training loss: 0.0302, discriminator training loss: 0.0137, validation loss: 0.1289
2024-05-22 15:31:44 [INFO]: Epoch 128 - generator training loss: 0.0306, discriminator training loss: 0.0136, validation loss: 0.1287
2024-05-22 15:31:48 [INFO]: Epoch 129 - generator training loss: 0.0300, discriminator training loss: 0.0136, validation loss: 0.1289
2024-05-22 15:31:52 [INFO]: Epoch 130 - generator training loss: 0.0300, discriminator training loss: 0.0134, validation loss: 0.1286
2024-05-22 15:31:56 [INFO]: Epoch 131 - generator training loss: 0.0298, discriminator training loss: 0.0134, validation loss: 0.1289
2024-05-22 15:32:00 [INFO]: Epoch 132 - generator training loss: 0.0295, discriminator training loss: 0.0135, validation loss: 0.1291
2024-05-22 15:32:05 [INFO]: Epoch 133 - generator training loss: 0.0299, discriminator training loss: 0.0134, validation loss: 0.1289
2024-05-22 15:32:09 [INFO]: Epoch 134 - generator training loss: 0.0300, discriminator training loss: 0.0133, validation loss: 0.1295
2024-05-22 15:32:13 [INFO]: Epoch 135 - generator training loss: 0.0306, discriminator training loss: 0.0132, validation loss: 0.1297
2024-05-22 15:32:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:32:13 [INFO]: Finished training. The best model is from epoch#125.
2024-05-22 15:32:13 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_air_quality/20240522_T152309/USGAN.pypots
2024-05-22 15:32:13 [INFO]: US-GAN on Air-Quality: MAE=0.1688, MSE=0.1186
2024-05-22 15:32:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-22 15:32:13 [INFO]: Using the given device: cuda:0
2024-05-22 15:32:13 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240522_T153213
2024-05-22 15:32:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_air_quality/20240522_T153213/tensorboard
2024-05-22 15:32:13 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 15:32:17 [INFO]: Epoch 001 - training loss: 1.3944, validation loss: 0.9259
2024-05-22 15:32:19 [INFO]: Epoch 002 - training loss: 1.1231, validation loss: 0.6973
2024-05-22 15:32:22 [INFO]: Epoch 003 - training loss: 0.9354, validation loss: 0.5952
2024-05-22 15:32:25 [INFO]: Epoch 004 - training loss: 0.8270, validation loss: 0.5262
2024-05-22 15:32:28 [INFO]: Epoch 005 - training loss: 0.7523, validation loss: 0.4799
2024-05-22 15:32:30 [INFO]: Epoch 006 - training loss: 0.6983, validation loss: 0.4417
2024-05-22 15:32:33 [INFO]: Epoch 007 - training loss: 0.6530, validation loss: 0.4114
2024-05-22 15:32:36 [INFO]: Epoch 008 - training loss: 0.6207, validation loss: 0.3866
2024-05-22 15:32:39 [INFO]: Epoch 009 - training loss: 0.5927, validation loss: 0.3670
2024-05-22 15:32:41 [INFO]: Epoch 010 - training loss: 0.5722, validation loss: 0.3502
2024-05-22 15:32:44 [INFO]: Epoch 011 - training loss: 0.5549, validation loss: 0.3362
2024-05-22 15:32:47 [INFO]: Epoch 012 - training loss: 0.5397, validation loss: 0.3246
2024-05-22 15:32:49 [INFO]: Epoch 013 - training loss: 0.5276, validation loss: 0.3146
2024-05-22 15:32:52 [INFO]: Epoch 014 - training loss: 0.5173, validation loss: 0.3068
2024-05-22 15:32:55 [INFO]: Epoch 015 - training loss: 0.5049, validation loss: 0.2985
2024-05-22 15:32:58 [INFO]: Epoch 016 - training loss: 0.4943, validation loss: 0.2916
2024-05-22 15:33:00 [INFO]: Epoch 017 - training loss: 0.4849, validation loss: 0.2858
2024-05-22 15:33:03 [INFO]: Epoch 018 - training loss: 0.4773, validation loss: 0.2801
2024-05-22 15:33:06 [INFO]: Epoch 019 - training loss: 0.4700, validation loss: 0.2751
2024-05-22 15:33:08 [INFO]: Epoch 020 - training loss: 0.4639, validation loss: 0.2711
2024-05-22 15:33:11 [INFO]: Epoch 021 - training loss: 0.4558, validation loss: 0.2657
2024-05-22 15:33:14 [INFO]: Epoch 022 - training loss: 0.4487, validation loss: 0.2616
2024-05-22 15:33:17 [INFO]: Epoch 023 - training loss: 0.4438, validation loss: 0.2580
2024-05-22 15:33:19 [INFO]: Epoch 024 - training loss: 0.4363, validation loss: 0.2542
2024-05-22 15:33:22 [INFO]: Epoch 025 - training loss: 0.4307, validation loss: 0.2506
2024-05-22 15:33:25 [INFO]: Epoch 026 - training loss: 0.4254, validation loss: 0.2474
2024-05-22 15:33:27 [INFO]: Epoch 027 - training loss: 0.4208, validation loss: 0.2441
2024-05-22 15:33:30 [INFO]: Epoch 028 - training loss: 0.4150, validation loss: 0.2409
2024-05-22 15:33:33 [INFO]: Epoch 029 - training loss: 0.4100, validation loss: 0.2381
2024-05-22 15:33:35 [INFO]: Epoch 030 - training loss: 0.4059, validation loss: 0.2354
2024-05-22 15:33:38 [INFO]: Epoch 031 - training loss: 0.4007, validation loss: 0.2325
2024-05-22 15:33:41 [INFO]: Epoch 032 - training loss: 0.3974, validation loss: 0.2299
2024-05-22 15:33:44 [INFO]: Epoch 033 - training loss: 0.3919, validation loss: 0.2272
2024-05-22 15:33:46 [INFO]: Epoch 034 - training loss: 0.3886, validation loss: 0.2241
2024-05-22 15:33:49 [INFO]: Epoch 035 - training loss: 0.3849, validation loss: 0.2218
2024-05-22 15:33:52 [INFO]: Epoch 036 - training loss: 0.3815, validation loss: 0.2194
2024-05-22 15:33:54 [INFO]: Epoch 037 - training loss: 0.3774, validation loss: 0.2169
2024-05-22 15:33:57 [INFO]: Epoch 038 - training loss: 0.3745, validation loss: 0.2148
2024-05-22 15:34:00 [INFO]: Epoch 039 - training loss: 0.3708, validation loss: 0.2124
2024-05-22 15:34:03 [INFO]: Epoch 040 - training loss: 0.3673, validation loss: 0.2102
2024-05-22 15:34:05 [INFO]: Epoch 041 - training loss: 0.3648, validation loss: 0.2082
2024-05-22 15:34:08 [INFO]: Epoch 042 - training loss: 0.3606, validation loss: 0.2068
2024-05-22 15:34:11 [INFO]: Epoch 043 - training loss: 0.3588, validation loss: 0.2045
2024-05-22 15:34:13 [INFO]: Epoch 044 - training loss: 0.3567, validation loss: 0.2030
2024-05-22 15:34:16 [INFO]: Epoch 045 - training loss: 0.3526, validation loss: 0.2011
2024-05-22 15:34:19 [INFO]: Epoch 046 - training loss: 0.3498, validation loss: 0.1998
2024-05-22 15:34:22 [INFO]: Epoch 047 - training loss: 0.3471, validation loss: 0.1980
2024-05-22 15:34:24 [INFO]: Epoch 048 - training loss: 0.3456, validation loss: 0.1965
2024-05-22 15:34:27 [INFO]: Epoch 049 - training loss: 0.3440, validation loss: 0.1957
2024-05-22 15:34:30 [INFO]: Epoch 050 - training loss: 0.3403, validation loss: 0.1940
2024-05-22 15:34:33 [INFO]: Epoch 051 - training loss: 0.3385, validation loss: 0.1930
2024-05-22 15:34:35 [INFO]: Epoch 052 - training loss: 0.3354, validation loss: 0.1920
2024-05-22 15:34:38 [INFO]: Epoch 053 - training loss: 0.3338, validation loss: 0.1911
2024-05-22 15:34:41 [INFO]: Epoch 054 - training loss: 0.3316, validation loss: 0.1901
2024-05-22 15:34:43 [INFO]: Epoch 055 - training loss: 0.3299, validation loss: 0.1894
2024-05-22 15:34:46 [INFO]: Epoch 056 - training loss: 0.3283, validation loss: 0.1886
2024-05-22 15:34:49 [INFO]: Epoch 057 - training loss: 0.3260, validation loss: 0.1879
2024-05-22 15:34:52 [INFO]: Epoch 058 - training loss: 0.3243, validation loss: 0.1871
2024-05-22 15:34:54 [INFO]: Epoch 059 - training loss: 0.3228, validation loss: 0.1861
2024-05-22 15:34:57 [INFO]: Epoch 060 - training loss: 0.3212, validation loss: 0.1856
2024-05-22 15:35:00 [INFO]: Epoch 061 - training loss: 0.3187, validation loss: 0.1848
2024-05-22 15:35:02 [INFO]: Epoch 062 - training loss: 0.3170, validation loss: 0.1842
2024-05-22 15:35:05 [INFO]: Epoch 063 - training loss: 0.3157, validation loss: 0.1836
2024-05-22 15:35:08 [INFO]: Epoch 064 - training loss: 0.3141, validation loss: 0.1829
2024-05-22 15:35:10 [INFO]: Epoch 065 - training loss: 0.3129, validation loss: 0.1824
2024-05-22 15:35:13 [INFO]: Epoch 066 - training loss: 0.3115, validation loss: 0.1819
2024-05-22 15:35:16 [INFO]: Epoch 067 - training loss: 0.3105, validation loss: 0.1812
2024-05-22 15:35:19 [INFO]: Epoch 068 - training loss: 0.3084, validation loss: 0.1810
2024-05-22 15:35:21 [INFO]: Epoch 069 - training loss: 0.3076, validation loss: 0.1803
2024-05-22 15:35:24 [INFO]: Epoch 070 - training loss: 0.3063, validation loss: 0.1798
2024-05-22 15:35:27 [INFO]: Epoch 071 - training loss: 0.3054, validation loss: 0.1792
2024-05-22 15:35:29 [INFO]: Epoch 072 - training loss: 0.3035, validation loss: 0.1784
2024-05-22 15:35:32 [INFO]: Epoch 073 - training loss: 0.3030, validation loss: 0.1782
2024-05-22 15:35:35 [INFO]: Epoch 074 - training loss: 0.3009, validation loss: 0.1773
2024-05-22 15:35:38 [INFO]: Epoch 075 - training loss: 0.3002, validation loss: 0.1767
2024-05-22 15:35:40 [INFO]: Epoch 076 - training loss: 0.2992, validation loss: 0.1762
2024-05-22 15:35:43 [INFO]: Epoch 077 - training loss: 0.2984, validation loss: 0.1757
2024-05-22 15:35:46 [INFO]: Epoch 078 - training loss: 0.2986, validation loss: 0.1755
2024-05-22 15:35:48 [INFO]: Epoch 079 - training loss: 0.2968, validation loss: 0.1747
2024-05-22 15:35:51 [INFO]: Epoch 080 - training loss: 0.2954, validation loss: 0.1746
2024-05-22 15:35:54 [INFO]: Epoch 081 - training loss: 0.2946, validation loss: 0.1738
2024-05-22 15:35:57 [INFO]: Epoch 082 - training loss: 0.2936, validation loss: 0.1731
2024-05-22 15:35:59 [INFO]: Epoch 083 - training loss: 0.2932, validation loss: 0.1729
2024-05-22 15:36:02 [INFO]: Epoch 084 - training loss: 0.2920, validation loss: 0.1723
2024-05-22 15:36:05 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1718
2024-05-22 15:36:07 [INFO]: Epoch 086 - training loss: 0.2909, validation loss: 0.1714
2024-05-22 15:36:10 [INFO]: Epoch 087 - training loss: 0.2895, validation loss: 0.1708
2024-05-22 15:36:13 [INFO]: Epoch 088 - training loss: 0.2890, validation loss: 0.1702
2024-05-22 15:36:16 [INFO]: Epoch 089 - training loss: 0.2883, validation loss: 0.1699
2024-05-22 15:36:18 [INFO]: Epoch 090 - training loss: 0.2882, validation loss: 0.1692
2024-05-22 15:36:21 [INFO]: Epoch 091 - training loss: 0.2862, validation loss: 0.1687
2024-05-22 15:36:24 [INFO]: Epoch 092 - training loss: 0.2862, validation loss: 0.1685
2024-05-22 15:36:26 [INFO]: Epoch 093 - training loss: 0.2849, validation loss: 0.1679
2024-05-22 15:36:29 [INFO]: Epoch 094 - training loss: 0.2848, validation loss: 0.1674
2024-05-22 15:36:32 [INFO]: Epoch 095 - training loss: 0.2832, validation loss: 0.1670
2024-05-22 15:36:35 [INFO]: Epoch 096 - training loss: 0.2821, validation loss: 0.1663
2024-05-22 15:36:37 [INFO]: Epoch 097 - training loss: 0.2818, validation loss: 0.1658
2024-05-22 15:36:40 [INFO]: Epoch 098 - training loss: 0.2809, validation loss: 0.1654
2024-05-22 15:36:43 [INFO]: Epoch 099 - training loss: 0.2806, validation loss: 0.1649
2024-05-22 15:36:45 [INFO]: Epoch 100 - training loss: 0.2804, validation loss: 0.1645
2024-05-22 15:36:48 [INFO]: Epoch 101 - training loss: 0.2795, validation loss: 0.1638
2024-05-22 15:36:51 [INFO]: Epoch 102 - training loss: 0.2785, validation loss: 0.1633
2024-05-22 15:36:54 [INFO]: Epoch 103 - training loss: 0.2782, validation loss: 0.1630
2024-05-22 15:36:56 [INFO]: Epoch 104 - training loss: 0.2778, validation loss: 0.1626
2024-05-22 15:36:59 [INFO]: Epoch 105 - training loss: 0.2773, validation loss: 0.1619
2024-05-22 15:37:02 [INFO]: Epoch 106 - training loss: 0.2768, validation loss: 0.1618
2024-05-22 15:37:04 [INFO]: Epoch 107 - training loss: 0.2754, validation loss: 0.1610
2024-05-22 15:37:07 [INFO]: Epoch 108 - training loss: 0.2755, validation loss: 0.1608
2024-05-22 15:37:10 [INFO]: Epoch 109 - training loss: 0.2748, validation loss: 0.1603
2024-05-22 15:37:13 [INFO]: Epoch 110 - training loss: 0.2742, validation loss: 0.1598
2024-05-22 15:37:15 [INFO]: Epoch 111 - training loss: 0.2735, validation loss: 0.1594
2024-05-22 15:37:18 [INFO]: Epoch 112 - training loss: 0.2733, validation loss: 0.1591
2024-05-22 15:37:21 [INFO]: Epoch 113 - training loss: 0.2726, validation loss: 0.1585
2024-05-22 15:37:23 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1581
2024-05-22 15:37:26 [INFO]: Epoch 115 - training loss: 0.2719, validation loss: 0.1576
2024-05-22 15:37:29 [INFO]: Epoch 116 - training loss: 0.2707, validation loss: 0.1573
2024-05-22 15:37:32 [INFO]: Epoch 117 - training loss: 0.2704, validation loss: 0.1568
2024-05-22 15:37:34 [INFO]: Epoch 118 - training loss: 0.2703, validation loss: 0.1565
2024-05-22 15:37:37 [INFO]: Epoch 119 - training loss: 0.2694, validation loss: 0.1559
2024-05-22 15:37:40 [INFO]: Epoch 120 - training loss: 0.2693, validation loss: 0.1557
2024-05-22 15:37:42 [INFO]: Epoch 121 - training loss: 0.2688, validation loss: 0.1556
2024-05-22 15:37:45 [INFO]: Epoch 122 - training loss: 0.2681, validation loss: 0.1549
2024-05-22 15:37:48 [INFO]: Epoch 123 - training loss: 0.2676, validation loss: 0.1544
2024-05-22 15:37:51 [INFO]: Epoch 124 - training loss: 0.2670, validation loss: 0.1540
2024-05-22 15:37:53 [INFO]: Epoch 125 - training loss: 0.2671, validation loss: 0.1537
2024-05-22 15:37:56 [INFO]: Epoch 126 - training loss: 0.2663, validation loss: 0.1534
2024-05-22 15:37:59 [INFO]: Epoch 127 - training loss: 0.2663, validation loss: 0.1531
2024-05-22 15:38:01 [INFO]: Epoch 128 - training loss: 0.2651, validation loss: 0.1525
2024-05-22 15:38:04 [INFO]: Epoch 129 - training loss: 0.2652, validation loss: 0.1523
2024-05-22 15:38:07 [INFO]: Epoch 130 - training loss: 0.2642, validation loss: 0.1520
2024-05-22 15:38:10 [INFO]: Epoch 131 - training loss: 0.2643, validation loss: 0.1515
2024-05-22 15:38:12 [INFO]: Epoch 132 - training loss: 0.2639, validation loss: 0.1510
2024-05-22 15:38:15 [INFO]: Epoch 133 - training loss: 0.2637, validation loss: 0.1509
2024-05-22 15:38:18 [INFO]: Epoch 134 - training loss: 0.2632, validation loss: 0.1506
2024-05-22 15:38:20 [INFO]: Epoch 135 - training loss: 0.2621, validation loss: 0.1502
2024-05-22 15:38:23 [INFO]: Epoch 136 - training loss: 0.2619, validation loss: 0.1497
2024-05-22 15:38:26 [INFO]: Epoch 137 - training loss: 0.2623, validation loss: 0.1496
2024-05-22 15:38:29 [INFO]: Epoch 138 - training loss: 0.2617, validation loss: 0.1492
2024-05-22 15:38:31 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1488
2024-05-22 15:38:34 [INFO]: Epoch 140 - training loss: 0.2603, validation loss: 0.1486
2024-05-22 15:38:37 [INFO]: Epoch 141 - training loss: 0.2601, validation loss: 0.1482
2024-05-22 15:38:39 [INFO]: Epoch 142 - training loss: 0.2601, validation loss: 0.1480
2024-05-22 15:38:42 [INFO]: Epoch 143 - training loss: 0.2594, validation loss: 0.1478
2024-05-22 15:38:45 [INFO]: Epoch 144 - training loss: 0.2586, validation loss: 0.1474
2024-05-22 15:38:48 [INFO]: Epoch 145 - training loss: 0.2593, validation loss: 0.1472
2024-05-22 15:38:50 [INFO]: Epoch 146 - training loss: 0.2586, validation loss: 0.1468
2024-05-22 15:38:53 [INFO]: Epoch 147 - training loss: 0.2580, validation loss: 0.1466
2024-05-22 15:38:56 [INFO]: Epoch 148 - training loss: 0.2574, validation loss: 0.1464
2024-05-22 15:38:58 [INFO]: Epoch 149 - training loss: 0.2569, validation loss: 0.1460
2024-05-22 15:39:01 [INFO]: Epoch 150 - training loss: 0.2577, validation loss: 0.1459
2024-05-22 15:39:04 [INFO]: Epoch 151 - training loss: 0.2568, validation loss: 0.1456
2024-05-22 15:39:07 [INFO]: Epoch 152 - training loss: 0.2560, validation loss: 0.1452
2024-05-22 15:39:09 [INFO]: Epoch 153 - training loss: 0.2565, validation loss: 0.1451
2024-05-22 15:39:12 [INFO]: Epoch 154 - training loss: 0.2553, validation loss: 0.1446
2024-05-22 15:39:15 [INFO]: Epoch 155 - training loss: 0.2562, validation loss: 0.1445
2024-05-22 15:39:17 [INFO]: Epoch 156 - training loss: 0.2552, validation loss: 0.1442
2024-05-22 15:39:20 [INFO]: Epoch 157 - training loss: 0.2550, validation loss: 0.1439
2024-05-22 15:39:23 [INFO]: Epoch 158 - training loss: 0.2540, validation loss: 0.1437
2024-05-22 15:39:26 [INFO]: Epoch 159 - training loss: 0.2542, validation loss: 0.1434
2024-05-22 15:39:28 [INFO]: Epoch 160 - training loss: 0.2539, validation loss: 0.1431
2024-05-22 15:39:31 [INFO]: Epoch 161 - training loss: 0.2539, validation loss: 0.1430
2024-05-22 15:39:34 [INFO]: Epoch 162 - training loss: 0.2530, validation loss: 0.1429
2024-05-22 15:39:36 [INFO]: Epoch 163 - training loss: 0.2533, validation loss: 0.1425
2024-05-22 15:39:39 [INFO]: Epoch 164 - training loss: 0.2526, validation loss: 0.1423
2024-05-22 15:39:42 [INFO]: Epoch 165 - training loss: 0.2519, validation loss: 0.1422
2024-05-22 15:39:44 [INFO]: Epoch 166 - training loss: 0.2516, validation loss: 0.1421
2024-05-22 15:39:47 [INFO]: Epoch 167 - training loss: 0.2518, validation loss: 0.1418
2024-05-22 15:39:50 [INFO]: Epoch 168 - training loss: 0.2516, validation loss: 0.1415
2024-05-22 15:39:53 [INFO]: Epoch 169 - training loss: 0.2512, validation loss: 0.1412
2024-05-22 15:39:55 [INFO]: Epoch 170 - training loss: 0.2512, validation loss: 0.1411
2024-05-22 15:39:58 [INFO]: Epoch 171 - training loss: 0.2504, validation loss: 0.1408
2024-05-22 15:40:01 [INFO]: Epoch 172 - training loss: 0.2507, validation loss: 0.1407
2024-05-22 15:40:03 [INFO]: Epoch 173 - training loss: 0.2501, validation loss: 0.1406
2024-05-22 15:40:06 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1404
2024-05-22 15:40:09 [INFO]: Epoch 175 - training loss: 0.2495, validation loss: 0.1401
2024-05-22 15:40:12 [INFO]: Epoch 176 - training loss: 0.2492, validation loss: 0.1400
2024-05-22 15:40:14 [INFO]: Epoch 177 - training loss: 0.2491, validation loss: 0.1397
2024-05-22 15:40:17 [INFO]: Epoch 178 - training loss: 0.2488, validation loss: 0.1395
2024-05-22 15:40:20 [INFO]: Epoch 179 - training loss: 0.2491, validation loss: 0.1392
2024-05-22 15:40:22 [INFO]: Epoch 180 - training loss: 0.2480, validation loss: 0.1391
2024-05-22 15:40:25 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1390
2024-05-22 15:40:28 [INFO]: Epoch 182 - training loss: 0.2475, validation loss: 0.1387
2024-05-22 15:40:31 [INFO]: Epoch 183 - training loss: 0.2473, validation loss: 0.1386
2024-05-22 15:40:33 [INFO]: Epoch 184 - training loss: 0.2479, validation loss: 0.1385
2024-05-22 15:40:36 [INFO]: Epoch 185 - training loss: 0.2472, validation loss: 0.1382
2024-05-22 15:40:39 [INFO]: Epoch 186 - training loss: 0.2469, validation loss: 0.1380
2024-05-22 15:40:42 [INFO]: Epoch 187 - training loss: 0.2468, validation loss: 0.1381
2024-05-22 15:40:44 [INFO]: Epoch 188 - training loss: 0.2461, validation loss: 0.1378
2024-05-22 15:40:47 [INFO]: Epoch 189 - training loss: 0.2461, validation loss: 0.1376
2024-05-22 15:40:50 [INFO]: Epoch 190 - training loss: 0.2459, validation loss: 0.1375
2024-05-22 15:40:52 [INFO]: Epoch 191 - training loss: 0.2457, validation loss: 0.1373
2024-05-22 15:40:55 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1372
2024-05-22 15:40:58 [INFO]: Epoch 193 - training loss: 0.2458, validation loss: 0.1370
2024-05-22 15:41:01 [INFO]: Epoch 194 - training loss: 0.2446, validation loss: 0.1370
2024-05-22 15:41:03 [INFO]: Epoch 195 - training loss: 0.2447, validation loss: 0.1370
2024-05-22 15:41:06 [INFO]: Epoch 196 - training loss: 0.2450, validation loss: 0.1366
2024-05-22 15:41:09 [INFO]: Epoch 197 - training loss: 0.2448, validation loss: 0.1363
2024-05-22 15:41:11 [INFO]: Epoch 198 - training loss: 0.2444, validation loss: 0.1364
2024-05-22 15:41:14 [INFO]: Epoch 199 - training loss: 0.2437, validation loss: 0.1363
2024-05-22 15:41:17 [INFO]: Epoch 200 - training loss: 0.2436, validation loss: 0.1360
2024-05-22 15:41:19 [INFO]: Epoch 201 - training loss: 0.2433, validation loss: 0.1358
2024-05-22 15:41:22 [INFO]: Epoch 202 - training loss: 0.2435, validation loss: 0.1356
2024-05-22 15:41:25 [INFO]: Epoch 203 - training loss: 0.2441, validation loss: 0.1355
2024-05-22 15:41:28 [INFO]: Epoch 204 - training loss: 0.2429, validation loss: 0.1354
2024-05-22 15:41:30 [INFO]: Epoch 205 - training loss: 0.2428, validation loss: 0.1354
2024-05-22 15:41:33 [INFO]: Epoch 206 - training loss: 0.2434, validation loss: 0.1352
2024-05-22 15:41:36 [INFO]: Epoch 207 - training loss: 0.2418, validation loss: 0.1350
2024-05-22 15:41:38 [INFO]: Epoch 208 - training loss: 0.2423, validation loss: 0.1352
2024-05-22 15:41:41 [INFO]: Epoch 209 - training loss: 0.2419, validation loss: 0.1348
2024-05-22 15:41:44 [INFO]: Epoch 210 - training loss: 0.2421, validation loss: 0.1346
2024-05-22 15:41:47 [INFO]: Epoch 211 - training loss: 0.2419, validation loss: 0.1346
2024-05-22 15:41:49 [INFO]: Epoch 212 - training loss: 0.2416, validation loss: 0.1344
2024-05-22 15:41:52 [INFO]: Epoch 213 - training loss: 0.2417, validation loss: 0.1343
2024-05-22 15:41:55 [INFO]: Epoch 214 - training loss: 0.2412, validation loss: 0.1342
2024-05-22 15:41:57 [INFO]: Epoch 215 - training loss: 0.2412, validation loss: 0.1340
2024-05-22 15:42:00 [INFO]: Epoch 216 - training loss: 0.2404, validation loss: 0.1339
2024-05-22 15:42:03 [INFO]: Epoch 217 - training loss: 0.2404, validation loss: 0.1336
2024-05-22 15:42:06 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1336
2024-05-22 15:42:08 [INFO]: Epoch 219 - training loss: 0.2402, validation loss: 0.1338
2024-05-22 15:42:11 [INFO]: Epoch 220 - training loss: 0.2405, validation loss: 0.1336
2024-05-22 15:42:14 [INFO]: Epoch 221 - training loss: 0.2399, validation loss: 0.1334
2024-05-22 15:42:16 [INFO]: Epoch 222 - training loss: 0.2397, validation loss: 0.1333
2024-05-22 15:42:19 [INFO]: Epoch 223 - training loss: 0.2397, validation loss: 0.1332
2024-05-22 15:42:22 [INFO]: Epoch 224 - training loss: 0.2392, validation loss: 0.1331
2024-05-22 15:42:25 [INFO]: Epoch 225 - training loss: 0.2391, validation loss: 0.1328
2024-05-22 15:42:27 [INFO]: Epoch 226 - training loss: 0.2386, validation loss: 0.1328
2024-05-22 15:42:30 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.1327
2024-05-22 15:42:33 [INFO]: Epoch 228 - training loss: 0.2385, validation loss: 0.1327
2024-05-22 15:42:36 [INFO]: Epoch 229 - training loss: 0.2384, validation loss: 0.1326
2024-05-22 15:42:38 [INFO]: Epoch 230 - training loss: 0.2389, validation loss: 0.1325
2024-05-22 15:42:41 [INFO]: Epoch 231 - training loss: 0.2380, validation loss: 0.1323
2024-05-22 15:42:44 [INFO]: Epoch 232 - training loss: 0.2382, validation loss: 0.1321
2024-05-22 15:42:46 [INFO]: Epoch 233 - training loss: 0.2374, validation loss: 0.1321
2024-05-22 15:42:49 [INFO]: Epoch 234 - training loss: 0.2379, validation loss: 0.1320
2024-05-22 15:42:52 [INFO]: Epoch 235 - training loss: 0.2375, validation loss: 0.1320
2024-05-22 15:42:54 [INFO]: Epoch 236 - training loss: 0.2379, validation loss: 0.1320
2024-05-22 15:42:57 [INFO]: Epoch 237 - training loss: 0.2383, validation loss: 0.1317
2024-05-22 15:43:00 [INFO]: Epoch 238 - training loss: 0.2370, validation loss: 0.1316
2024-05-22 15:43:03 [INFO]: Epoch 239 - training loss: 0.2366, validation loss: 0.1316
2024-05-22 15:43:05 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.1313
2024-05-22 15:43:08 [INFO]: Epoch 241 - training loss: 0.2368, validation loss: 0.1311
2024-05-22 15:43:11 [INFO]: Epoch 242 - training loss: 0.2365, validation loss: 0.1314
2024-05-22 15:43:13 [INFO]: Epoch 243 - training loss: 0.2363, validation loss: 0.1312
2024-05-22 15:43:16 [INFO]: Epoch 244 - training loss: 0.2368, validation loss: 0.1312
2024-05-22 15:43:19 [INFO]: Epoch 245 - training loss: 0.2366, validation loss: 0.1309
2024-05-22 15:43:22 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.1309
2024-05-22 15:43:24 [INFO]: Epoch 247 - training loss: 0.2359, validation loss: 0.1308
2024-05-22 15:43:27 [INFO]: Epoch 248 - training loss: 0.2355, validation loss: 0.1308
2024-05-22 15:43:30 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1306
2024-05-22 15:43:32 [INFO]: Epoch 250 - training loss: 0.2353, validation loss: 0.1308
2024-05-22 15:43:35 [INFO]: Epoch 251 - training loss: 0.2353, validation loss: 0.1305
2024-05-22 15:43:38 [INFO]: Epoch 252 - training loss: 0.2350, validation loss: 0.1304
2024-05-22 15:43:41 [INFO]: Epoch 253 - training loss: 0.2349, validation loss: 0.1303
2024-05-22 15:43:43 [INFO]: Epoch 254 - training loss: 0.2354, validation loss: 0.1303
2024-05-22 15:43:46 [INFO]: Epoch 255 - training loss: 0.2346, validation loss: 0.1302
2024-05-22 15:43:49 [INFO]: Epoch 256 - training loss: 0.2345, validation loss: 0.1302
2024-05-22 15:43:51 [INFO]: Epoch 257 - training loss: 0.2343, validation loss: 0.1300
2024-05-22 15:43:54 [INFO]: Epoch 258 - training loss: 0.2345, validation loss: 0.1299
2024-05-22 15:43:57 [INFO]: Epoch 259 - training loss: 0.2340, validation loss: 0.1298
2024-05-22 15:44:00 [INFO]: Epoch 260 - training loss: 0.2341, validation loss: 0.1298
2024-05-22 15:44:02 [INFO]: Epoch 261 - training loss: 0.2335, validation loss: 0.1298
2024-05-22 15:44:05 [INFO]: Epoch 262 - training loss: 0.2342, validation loss: 0.1297
2024-05-22 15:44:08 [INFO]: Epoch 263 - training loss: 0.2338, validation loss: 0.1296
2024-05-22 15:44:10 [INFO]: Epoch 264 - training loss: 0.2335, validation loss: 0.1296
2024-05-22 15:44:13 [INFO]: Epoch 265 - training loss: 0.2339, validation loss: 0.1295
2024-05-22 15:44:16 [INFO]: Epoch 266 - training loss: 0.2334, validation loss: 0.1294
2024-05-22 15:44:19 [INFO]: Epoch 267 - training loss: 0.2331, validation loss: 0.1292
2024-05-22 15:44:21 [INFO]: Epoch 268 - training loss: 0.2333, validation loss: 0.1293
2024-05-22 15:44:24 [INFO]: Epoch 269 - training loss: 0.2325, validation loss: 0.1292
2024-05-22 15:44:27 [INFO]: Epoch 270 - training loss: 0.2327, validation loss: 0.1291
2024-05-22 15:44:29 [INFO]: Epoch 271 - training loss: 0.2335, validation loss: 0.1291
2024-05-22 15:44:32 [INFO]: Epoch 272 - training loss: 0.2321, validation loss: 0.1291
2024-05-22 15:44:35 [INFO]: Epoch 273 - training loss: 0.2323, validation loss: 0.1291
2024-05-22 15:44:38 [INFO]: Epoch 274 - training loss: 0.2320, validation loss: 0.1289
2024-05-22 15:44:40 [INFO]: Epoch 275 - training loss: 0.2322, validation loss: 0.1288
2024-05-22 15:44:43 [INFO]: Epoch 276 - training loss: 0.2319, validation loss: 0.1289
2024-05-22 15:44:46 [INFO]: Epoch 277 - training loss: 0.2321, validation loss: 0.1289
2024-05-22 15:44:48 [INFO]: Epoch 278 - training loss: 0.2318, validation loss: 0.1286
2024-05-22 15:44:51 [INFO]: Epoch 279 - training loss: 0.2314, validation loss: 0.1284
2024-05-22 15:44:54 [INFO]: Epoch 280 - training loss: 0.2318, validation loss: 0.1286
2024-05-22 15:44:57 [INFO]: Epoch 281 - training loss: 0.2316, validation loss: 0.1284
2024-05-22 15:44:59 [INFO]: Epoch 282 - training loss: 0.2320, validation loss: 0.1286
2024-05-22 15:45:02 [INFO]: Epoch 283 - training loss: 0.2313, validation loss: 0.1286
2024-05-22 15:45:05 [INFO]: Epoch 284 - training loss: 0.2311, validation loss: 0.1282
2024-05-22 15:45:07 [INFO]: Epoch 285 - training loss: 0.2309, validation loss: 0.1282
2024-05-22 15:45:10 [INFO]: Epoch 286 - training loss: 0.2313, validation loss: 0.1281
2024-05-22 15:45:13 [INFO]: Epoch 287 - training loss: 0.2307, validation loss: 0.1281
2024-05-22 15:45:16 [INFO]: Epoch 288 - training loss: 0.2303, validation loss: 0.1282
2024-05-22 15:45:18 [INFO]: Epoch 289 - training loss: 0.2313, validation loss: 0.1281
2024-05-22 15:45:21 [INFO]: Epoch 290 - training loss: 0.2303, validation loss: 0.1280
2024-05-22 15:45:24 [INFO]: Epoch 291 - training loss: 0.2299, validation loss: 0.1280
2024-05-22 15:45:26 [INFO]: Epoch 292 - training loss: 0.2302, validation loss: 0.1280
2024-05-22 15:45:29 [INFO]: Epoch 293 - training loss: 0.2301, validation loss: 0.1277
2024-05-22 15:45:32 [INFO]: Epoch 294 - training loss: 0.2303, validation loss: 0.1279
2024-05-22 15:45:35 [INFO]: Epoch 295 - training loss: 0.2302, validation loss: 0.1279
2024-05-22 15:45:37 [INFO]: Epoch 296 - training loss: 0.2301, validation loss: 0.1279
2024-05-22 15:45:40 [INFO]: Epoch 297 - training loss: 0.2301, validation loss: 0.1277
2024-05-22 15:45:43 [INFO]: Epoch 298 - training loss: 0.2298, validation loss: 0.1277
2024-05-22 15:45:45 [INFO]: Epoch 299 - training loss: 0.2298, validation loss: 0.1277
2024-05-22 15:45:48 [INFO]: Epoch 300 - training loss: 0.2296, validation loss: 0.1274
2024-05-22 15:45:48 [INFO]: Finished training. The best model is from epoch#300.
2024-05-22 15:45:48 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_air_quality/20240522_T153213/BRITS.pypots
2024-05-22 15:45:49 [INFO]: BRITS on Air-Quality: MAE=0.1424, MSE=0.1133
2024-05-22 15:45:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-22 15:45:49 [INFO]: Using the given device: cuda:0
2024-05-22 15:45:49 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549
2024-05-22 15:45:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/tensorboard
2024-05-22 15:45:49 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 15:45:53 [INFO]: Epoch 001 - training loss: 1.4752, validation loss: 0.8015
2024-05-22 15:45:53 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch1_loss0.8014715284109115.pypots
2024-05-22 15:45:57 [INFO]: Epoch 002 - training loss: 1.0681, validation loss: 0.7460
2024-05-22 15:45:57 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch2_loss0.7459828108549118.pypots
2024-05-22 15:46:01 [INFO]: Epoch 003 - training loss: 0.9843, validation loss: 0.7260
2024-05-22 15:46:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch3_loss0.7259679049253464.pypots
2024-05-22 15:46:05 [INFO]: Epoch 004 - training loss: 0.9629, validation loss: 0.7124
2024-05-22 15:46:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch4_loss0.7123693436384201.pypots
2024-05-22 15:46:08 [INFO]: Epoch 005 - training loss: 0.9844, validation loss: 0.7053
2024-05-22 15:46:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch5_loss0.7053414076566696.pypots
2024-05-22 15:46:12 [INFO]: Epoch 006 - training loss: 0.9559, validation loss: 0.6984
2024-05-22 15:46:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch6_loss0.6983729541301728.pypots
2024-05-22 15:46:16 [INFO]: Epoch 007 - training loss: 0.9367, validation loss: 0.6939
2024-05-22 15:46:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch7_loss0.6939161002635956.pypots
2024-05-22 15:46:20 [INFO]: Epoch 008 - training loss: 0.9361, validation loss: 0.6914
2024-05-22 15:46:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch8_loss0.6914316117763519.pypots
2024-05-22 15:46:24 [INFO]: Epoch 009 - training loss: 0.9268, validation loss: 0.6871
2024-05-22 15:46:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch9_loss0.6871186465024948.pypots
2024-05-22 15:46:27 [INFO]: Epoch 010 - training loss: 0.9138, validation loss: 0.6847
2024-05-22 15:46:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch10_loss0.6847296327352523.pypots
2024-05-22 15:46:31 [INFO]: Epoch 011 - training loss: 0.9095, validation loss: 0.6836
2024-05-22 15:46:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch11_loss0.6836199462413788.pypots
2024-05-22 15:46:35 [INFO]: Epoch 012 - training loss: 0.9053, validation loss: 0.6829
2024-05-22 15:46:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch12_loss0.6829281598329544.pypots
2024-05-22 15:46:39 [INFO]: Epoch 013 - training loss: 0.9069, validation loss: 0.6837
2024-05-22 15:46:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch13_loss0.6837416261434555.pypots
2024-05-22 15:46:42 [INFO]: Epoch 014 - training loss: 0.9329, validation loss: 0.6807
2024-05-22 15:46:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch14_loss0.6807010769844055.pypots
2024-05-22 15:46:46 [INFO]: Epoch 015 - training loss: 0.9036, validation loss: 0.6796
2024-05-22 15:46:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch15_loss0.6796136766672134.pypots
2024-05-22 15:46:50 [INFO]: Epoch 016 - training loss: 0.8846, validation loss: 0.6808
2024-05-22 15:46:50 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch16_loss0.6808081209659577.pypots
2024-05-22 15:46:54 [INFO]: Epoch 017 - training loss: 0.8888, validation loss: 0.6791
2024-05-22 15:46:54 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch17_loss0.6790534675121307.pypots
2024-05-22 15:46:58 [INFO]: Epoch 018 - training loss: 0.8910, validation loss: 0.6783
2024-05-22 15:46:58 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch18_loss0.6783406585454941.pypots
2024-05-22 15:47:01 [INFO]: Epoch 019 - training loss: 0.9037, validation loss: 0.6800
2024-05-22 15:47:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch19_loss0.6799861818552018.pypots
2024-05-22 15:47:05 [INFO]: Epoch 020 - training loss: 0.8905, validation loss: 0.6793
2024-05-22 15:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch20_loss0.6792717546224594.pypots
2024-05-22 15:47:09 [INFO]: Epoch 021 - training loss: 0.8896, validation loss: 0.6820
2024-05-22 15:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch21_loss0.6820129871368408.pypots
2024-05-22 15:47:13 [INFO]: Epoch 022 - training loss: 0.8917, validation loss: 0.6796
2024-05-22 15:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch22_loss0.6795639425516129.pypots
2024-05-22 15:47:16 [INFO]: Epoch 023 - training loss: 0.8755, validation loss: 0.6815
2024-05-22 15:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch23_loss0.6814843893051148.pypots
2024-05-22 15:47:20 [INFO]: Epoch 024 - training loss: 0.8725, validation loss: 0.6825
2024-05-22 15:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch24_loss0.6824824005365372.pypots
2024-05-22 15:47:24 [INFO]: Epoch 025 - training loss: 0.8714, validation loss: 0.6838
2024-05-22 15:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch25_loss0.6837556481361389.pypots
2024-05-22 15:47:28 [INFO]: Epoch 026 - training loss: 0.8712, validation loss: 0.6828
2024-05-22 15:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch26_loss0.6828420370817184.pypots
2024-05-22 15:47:31 [INFO]: Epoch 027 - training loss: 0.8639, validation loss: 0.6842
2024-05-22 15:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch27_loss0.6842372059822083.pypots
2024-05-22 15:47:35 [INFO]: Epoch 028 - training loss: 0.8842, validation loss: 0.6838
2024-05-22 15:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN_epoch28_loss0.68384750187397.pypots
2024-05-22 15:47:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:47:35 [INFO]: Finished training. The best model is from epoch#18.
2024-05-22 15:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_air_quality/20240522_T154549/MRNN.pypots
2024-05-22 15:47:36 [INFO]: MRNN on Air-Quality: MAE=0.5236, MSE=0.6231
2024-05-22 15:47:36 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-22 15:47:36 [INFO]: Using the given device: cpu
2024-05-22 15:47:36 [INFO]: LOCF on Air-Quality: MAE=0.2063, MSE=0.2445
2024-05-22 15:47:36 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-22 15:47:36 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-22 15:47:36 [INFO]: Median on Air-Quality: MAE=0.6676, MSE=1.0184
2024-05-22 15:47:36 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-22 15:47:36 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-22 15:47:36 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=0.9535
2024-05-22 15:47:36 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-22 15:47:36 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-22 15:47:36 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 15:47:36 [INFO]: Using the given device: cuda:0
2024-05-22 15:47:36 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240522_T154736
2024-05-22 15:47:36 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_air_quality/20240522_T154736/tensorboard
2024-05-22 15:47:37 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-22 15:47:37 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.5103
2024-05-22 15:47:38 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.3952
2024-05-22 15:47:39 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 0.3214
2024-05-22 15:47:39 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.2840
2024-05-22 15:47:40 [INFO]: Epoch 005 - training loss: 0.5166, validation loss: 0.2657
2024-05-22 15:47:41 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2497
2024-05-22 15:47:41 [INFO]: Epoch 007 - training loss: 0.4559, validation loss: 0.2413
2024-05-22 15:47:42 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2322
2024-05-22 15:47:43 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2283
2024-05-22 15:47:43 [INFO]: Epoch 010 - training loss: 0.4137, validation loss: 0.2228
2024-05-22 15:47:44 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2201
2024-05-22 15:47:45 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.2163
2024-05-22 15:47:45 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.2142
2024-05-22 15:47:46 [INFO]: Epoch 014 - training loss: 0.3818, validation loss: 0.2108
2024-05-22 15:47:47 [INFO]: Epoch 015 - training loss: 0.3748, validation loss: 0.2087
2024-05-22 15:47:47 [INFO]: Epoch 016 - training loss: 0.3699, validation loss: 0.2059
2024-05-22 15:47:48 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2033
2024-05-22 15:47:49 [INFO]: Epoch 018 - training loss: 0.3607, validation loss: 0.2011
2024-05-22 15:47:49 [INFO]: Epoch 019 - training loss: 0.3554, validation loss: 0.1986
2024-05-22 15:47:50 [INFO]: Epoch 020 - training loss: 0.3525, validation loss: 0.1978
2024-05-22 15:47:51 [INFO]: Epoch 021 - training loss: 0.3506, validation loss: 0.1953
2024-05-22 15:47:51 [INFO]: Epoch 022 - training loss: 0.3457, validation loss: 0.1935
2024-05-22 15:47:52 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.1940
2024-05-22 15:47:53 [INFO]: Epoch 024 - training loss: 0.3403, validation loss: 0.1923
2024-05-22 15:47:53 [INFO]: Epoch 025 - training loss: 0.3363, validation loss: 0.1902
2024-05-22 15:47:54 [INFO]: Epoch 026 - training loss: 0.3337, validation loss: 0.1877
2024-05-22 15:47:55 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.1870
2024-05-22 15:47:55 [INFO]: Epoch 028 - training loss: 0.3295, validation loss: 0.1860
2024-05-22 15:47:56 [INFO]: Epoch 029 - training loss: 0.3267, validation loss: 0.1839
2024-05-22 15:47:57 [INFO]: Epoch 030 - training loss: 0.3243, validation loss: 0.1820
2024-05-22 15:47:57 [INFO]: Epoch 031 - training loss: 0.3238, validation loss: 0.1819
2024-05-22 15:47:58 [INFO]: Epoch 032 - training loss: 0.3214, validation loss: 0.1803
2024-05-22 15:47:59 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.1780
2024-05-22 15:47:59 [INFO]: Epoch 034 - training loss: 0.3190, validation loss: 0.1784
2024-05-22 15:48:00 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1768
2024-05-22 15:48:01 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1744
2024-05-22 15:48:01 [INFO]: Epoch 037 - training loss: 0.3106, validation loss: 0.1744
2024-05-22 15:48:02 [INFO]: Epoch 038 - training loss: 0.3112, validation loss: 0.1729
2024-05-22 15:48:03 [INFO]: Epoch 039 - training loss: 0.3074, validation loss: 0.1716
2024-05-22 15:48:03 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1708
2024-05-22 15:48:04 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1699
2024-05-22 15:48:05 [INFO]: Epoch 042 - training loss: 0.3039, validation loss: 0.1696
2024-05-22 15:48:05 [INFO]: Epoch 043 - training loss: 0.3016, validation loss: 0.1680
2024-05-22 15:48:06 [INFO]: Epoch 044 - training loss: 0.3005, validation loss: 0.1666
2024-05-22 15:48:07 [INFO]: Epoch 045 - training loss: 0.2986, validation loss: 0.1664
2024-05-22 15:48:07 [INFO]: Epoch 046 - training loss: 0.2966, validation loss: 0.1656
2024-05-22 15:48:08 [INFO]: Epoch 047 - training loss: 0.2961, validation loss: 0.1644
2024-05-22 15:48:09 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.1638
2024-05-22 15:48:09 [INFO]: Epoch 049 - training loss: 0.2921, validation loss: 0.1632
2024-05-22 15:48:10 [INFO]: Epoch 050 - training loss: 0.2923, validation loss: 0.1622
2024-05-22 15:48:11 [INFO]: Epoch 051 - training loss: 0.2902, validation loss: 0.1621
2024-05-22 15:48:11 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1600
2024-05-22 15:48:12 [INFO]: Epoch 053 - training loss: 0.2884, validation loss: 0.1603
2024-05-22 15:48:13 [INFO]: Epoch 054 - training loss: 0.2873, validation loss: 0.1604
2024-05-22 15:48:13 [INFO]: Epoch 055 - training loss: 0.2860, validation loss: 0.1594
2024-05-22 15:48:14 [INFO]: Epoch 056 - training loss: 0.2849, validation loss: 0.1588
2024-05-22 15:48:15 [INFO]: Epoch 057 - training loss: 0.2830, validation loss: 0.1580
2024-05-22 15:48:15 [INFO]: Epoch 058 - training loss: 0.2808, validation loss: 0.1581
2024-05-22 15:48:16 [INFO]: Epoch 059 - training loss: 0.2801, validation loss: 0.1573
2024-05-22 15:48:17 [INFO]: Epoch 060 - training loss: 0.2789, validation loss: 0.1566
2024-05-22 15:48:17 [INFO]: Epoch 061 - training loss: 0.2787, validation loss: 0.1559
2024-05-22 15:48:18 [INFO]: Epoch 062 - training loss: 0.2778, validation loss: 0.1553
2024-05-22 15:48:19 [INFO]: Epoch 063 - training loss: 0.2762, validation loss: 0.1549
2024-05-22 15:48:19 [INFO]: Epoch 064 - training loss: 0.2746, validation loss: 0.1546
2024-05-22 15:48:20 [INFO]: Epoch 065 - training loss: 0.2737, validation loss: 0.1539
2024-05-22 15:48:21 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.1541
2024-05-22 15:48:21 [INFO]: Epoch 067 - training loss: 0.2739, validation loss: 0.1540
2024-05-22 15:48:22 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.1527
2024-05-22 15:48:23 [INFO]: Epoch 069 - training loss: 0.2714, validation loss: 0.1524
2024-05-22 15:48:23 [INFO]: Epoch 070 - training loss: 0.2691, validation loss: 0.1524
2024-05-22 15:48:24 [INFO]: Epoch 071 - training loss: 0.2676, validation loss: 0.1513
2024-05-22 15:48:25 [INFO]: Epoch 072 - training loss: 0.2661, validation loss: 0.1510
2024-05-22 15:48:25 [INFO]: Epoch 073 - training loss: 0.2639, validation loss: 0.1508
2024-05-22 15:48:26 [INFO]: Epoch 074 - training loss: 0.2653, validation loss: 0.1501
2024-05-22 15:48:27 [INFO]: Epoch 075 - training loss: 0.2641, validation loss: 0.1497
2024-05-22 15:48:27 [INFO]: Epoch 076 - training loss: 0.2634, validation loss: 0.1495
2024-05-22 15:48:28 [INFO]: Epoch 077 - training loss: 0.2620, validation loss: 0.1497
2024-05-22 15:48:29 [INFO]: Epoch 078 - training loss: 0.2618, validation loss: 0.1488
2024-05-22 15:48:29 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.1493
2024-05-22 15:48:30 [INFO]: Epoch 080 - training loss: 0.2604, validation loss: 0.1482
2024-05-22 15:48:31 [INFO]: Epoch 081 - training loss: 0.2587, validation loss: 0.1482
2024-05-22 15:48:31 [INFO]: Epoch 082 - training loss: 0.2592, validation loss: 0.1473
2024-05-22 15:48:32 [INFO]: Epoch 083 - training loss: 0.2564, validation loss: 0.1465
2024-05-22 15:48:33 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.1465
2024-05-22 15:48:33 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1472
2024-05-22 15:48:34 [INFO]: Epoch 086 - training loss: 0.2550, validation loss: 0.1466
2024-05-22 15:48:35 [INFO]: Epoch 087 - training loss: 0.2537, validation loss: 0.1459
2024-05-22 15:48:35 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1465
2024-05-22 15:48:36 [INFO]: Epoch 089 - training loss: 0.2531, validation loss: 0.1449
2024-05-22 15:48:37 [INFO]: Epoch 090 - training loss: 0.2522, validation loss: 0.1443
2024-05-22 15:48:37 [INFO]: Epoch 091 - training loss: 0.2519, validation loss: 0.1451
2024-05-22 15:48:38 [INFO]: Epoch 092 - training loss: 0.2510, validation loss: 0.1439
2024-05-22 15:48:39 [INFO]: Epoch 093 - training loss: 0.2503, validation loss: 0.1443
2024-05-22 15:48:39 [INFO]: Epoch 094 - training loss: 0.2513, validation loss: 0.1443
2024-05-22 15:48:40 [INFO]: Epoch 095 - training loss: 0.2496, validation loss: 0.1440
2024-05-22 15:48:41 [INFO]: Epoch 096 - training loss: 0.2489, validation loss: 0.1433
2024-05-22 15:48:41 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1434
2024-05-22 15:48:42 [INFO]: Epoch 098 - training loss: 0.2477, validation loss: 0.1422
2024-05-22 15:48:43 [INFO]: Epoch 099 - training loss: 0.2476, validation loss: 0.1422
2024-05-22 15:48:43 [INFO]: Epoch 100 - training loss: 0.2466, validation loss: 0.1418
2024-05-22 15:48:44 [INFO]: Epoch 101 - training loss: 0.2450, validation loss: 0.1416
2024-05-22 15:48:45 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1420
2024-05-22 15:48:45 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1413
2024-05-22 15:48:46 [INFO]: Epoch 104 - training loss: 0.2453, validation loss: 0.1416
2024-05-22 15:48:47 [INFO]: Epoch 105 - training loss: 0.2436, validation loss: 0.1399
2024-05-22 15:48:47 [INFO]: Epoch 106 - training loss: 0.2441, validation loss: 0.1402
2024-05-22 15:48:48 [INFO]: Epoch 107 - training loss: 0.2435, validation loss: 0.1410
2024-05-22 15:48:49 [INFO]: Epoch 108 - training loss: 0.2432, validation loss: 0.1398
2024-05-22 15:48:49 [INFO]: Epoch 109 - training loss: 0.2434, validation loss: 0.1395
2024-05-22 15:48:50 [INFO]: Epoch 110 - training loss: 0.2421, validation loss: 0.1399
2024-05-22 15:48:51 [INFO]: Epoch 111 - training loss: 0.2409, validation loss: 0.1393
2024-05-22 15:48:51 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1398
2024-05-22 15:48:52 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1383
2024-05-22 15:48:53 [INFO]: Epoch 114 - training loss: 0.2399, validation loss: 0.1385
2024-05-22 15:48:53 [INFO]: Epoch 115 - training loss: 0.2381, validation loss: 0.1387
2024-05-22 15:48:54 [INFO]: Epoch 116 - training loss: 0.2388, validation loss: 0.1380
2024-05-22 15:48:54 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1383
2024-05-22 15:48:55 [INFO]: Epoch 118 - training loss: 0.2366, validation loss: 0.1378
2024-05-22 15:48:56 [INFO]: Epoch 119 - training loss: 0.2355, validation loss: 0.1381
2024-05-22 15:48:56 [INFO]: Epoch 120 - training loss: 0.2362, validation loss: 0.1384
2024-05-22 15:48:57 [INFO]: Epoch 121 - training loss: 0.2361, validation loss: 0.1379
2024-05-22 15:48:58 [INFO]: Epoch 122 - training loss: 0.2360, validation loss: 0.1378
2024-05-22 15:48:58 [INFO]: Epoch 123 - training loss: 0.2349, validation loss: 0.1379
2024-05-22 15:48:59 [INFO]: Epoch 124 - training loss: 0.2348, validation loss: 0.1371
2024-05-22 15:49:00 [INFO]: Epoch 125 - training loss: 0.2341, validation loss: 0.1386
2024-05-22 15:49:00 [INFO]: Epoch 126 - training loss: 0.2354, validation loss: 0.1365
2024-05-22 15:49:01 [INFO]: Epoch 127 - training loss: 0.2337, validation loss: 0.1364
2024-05-22 15:49:02 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1365
2024-05-22 15:49:02 [INFO]: Epoch 129 - training loss: 0.2333, validation loss: 0.1368
2024-05-22 15:49:03 [INFO]: Epoch 130 - training loss: 0.2341, validation loss: 0.1361
2024-05-22 15:49:04 [INFO]: Epoch 131 - training loss: 0.2325, validation loss: 0.1361
2024-05-22 15:49:04 [INFO]: Epoch 132 - training loss: 0.2311, validation loss: 0.1352
2024-05-22 15:49:05 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1359
2024-05-22 15:49:06 [INFO]: Epoch 134 - training loss: 0.2297, validation loss: 0.1357
2024-05-22 15:49:06 [INFO]: Epoch 135 - training loss: 0.2297, validation loss: 0.1353
2024-05-22 15:49:07 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1350
2024-05-22 15:49:08 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1349
2024-05-22 15:49:08 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1345
2024-05-22 15:49:09 [INFO]: Epoch 139 - training loss: 0.2288, validation loss: 0.1339
2024-05-22 15:49:10 [INFO]: Epoch 140 - training loss: 0.2273, validation loss: 0.1344
2024-05-22 15:49:10 [INFO]: Epoch 141 - training loss: 0.2274, validation loss: 0.1337
2024-05-22 15:49:11 [INFO]: Epoch 142 - training loss: 0.2268, validation loss: 0.1330
2024-05-22 15:49:12 [INFO]: Epoch 143 - training loss: 0.2261, validation loss: 0.1334
2024-05-22 15:49:12 [INFO]: Epoch 144 - training loss: 0.2279, validation loss: 0.1329
2024-05-22 15:49:13 [INFO]: Epoch 145 - training loss: 0.2274, validation loss: 0.1338
2024-05-22 15:49:14 [INFO]: Epoch 146 - training loss: 0.2263, validation loss: 0.1332
2024-05-22 15:49:14 [INFO]: Epoch 147 - training loss: 0.2261, validation loss: 0.1329
2024-05-22 15:49:15 [INFO]: Epoch 148 - training loss: 0.2253, validation loss: 0.1315
2024-05-22 15:49:16 [INFO]: Epoch 149 - training loss: 0.2252, validation loss: 0.1328
2024-05-22 15:49:16 [INFO]: Epoch 150 - training loss: 0.2249, validation loss: 0.1325
2024-05-22 15:49:17 [INFO]: Epoch 151 - training loss: 0.2233, validation loss: 0.1325
2024-05-22 15:49:18 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1327
2024-05-22 15:49:18 [INFO]: Epoch 153 - training loss: 0.2226, validation loss: 0.1319
2024-05-22 15:49:19 [INFO]: Epoch 154 - training loss: 0.2231, validation loss: 0.1325
2024-05-22 15:49:20 [INFO]: Epoch 155 - training loss: 0.2234, validation loss: 0.1323
2024-05-22 15:49:20 [INFO]: Epoch 156 - training loss: 0.2232, validation loss: 0.1313
2024-05-22 15:49:21 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1315
2024-05-22 15:49:22 [INFO]: Epoch 158 - training loss: 0.2223, validation loss: 0.1312
2024-05-22 15:49:22 [INFO]: Epoch 159 - training loss: 0.2220, validation loss: 0.1321
2024-05-22 15:49:23 [INFO]: Epoch 160 - training loss: 0.2216, validation loss: 0.1315
2024-05-22 15:49:24 [INFO]: Epoch 161 - training loss: 0.2205, validation loss: 0.1315
2024-05-22 15:49:24 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1313
2024-05-22 15:49:25 [INFO]: Epoch 163 - training loss: 0.2200, validation loss: 0.1314
2024-05-22 15:49:26 [INFO]: Epoch 164 - training loss: 0.2196, validation loss: 0.1311
2024-05-22 15:49:26 [INFO]: Epoch 165 - training loss: 0.2193, validation loss: 0.1309
2024-05-22 15:49:27 [INFO]: Epoch 166 - training loss: 0.2188, validation loss: 0.1304
2024-05-22 15:49:28 [INFO]: Epoch 167 - training loss: 0.2192, validation loss: 0.1314
2024-05-22 15:49:28 [INFO]: Epoch 168 - training loss: 0.2193, validation loss: 0.1307
2024-05-22 15:49:29 [INFO]: Epoch 169 - training loss: 0.2179, validation loss: 0.1302
2024-05-22 15:49:30 [INFO]: Epoch 170 - training loss: 0.2175, validation loss: 0.1293
2024-05-22 15:49:30 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1297
2024-05-22 15:49:31 [INFO]: Epoch 172 - training loss: 0.2196, validation loss: 0.1302
2024-05-22 15:49:32 [INFO]: Epoch 173 - training loss: 0.2185, validation loss: 0.1302
2024-05-22 15:49:32 [INFO]: Epoch 174 - training loss: 0.2177, validation loss: 0.1292
2024-05-22 15:49:33 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1300
2024-05-22 15:49:34 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1299
2024-05-22 15:49:34 [INFO]: Epoch 177 - training loss: 0.2148, validation loss: 0.1294
2024-05-22 15:49:35 [INFO]: Epoch 178 - training loss: 0.2154, validation loss: 0.1295
2024-05-22 15:49:36 [INFO]: Epoch 179 - training loss: 0.2153, validation loss: 0.1290
2024-05-22 15:49:36 [INFO]: Epoch 180 - training loss: 0.2138, validation loss: 0.1288
2024-05-22 15:49:37 [INFO]: Epoch 181 - training loss: 0.2146, validation loss: 0.1289
2024-05-22 15:49:38 [INFO]: Epoch 182 - training loss: 0.2162, validation loss: 0.1293
2024-05-22 15:49:38 [INFO]: Epoch 183 - training loss: 0.2150, validation loss: 0.1288
2024-05-22 15:49:39 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1292
2024-05-22 15:49:40 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1287
2024-05-22 15:49:40 [INFO]: Epoch 186 - training loss: 0.2125, validation loss: 0.1286
2024-05-22 15:49:41 [INFO]: Epoch 187 - training loss: 0.2136, validation loss: 0.1289
2024-05-22 15:49:42 [INFO]: Epoch 188 - training loss: 0.2139, validation loss: 0.1291
2024-05-22 15:49:42 [INFO]: Epoch 189 - training loss: 0.2124, validation loss: 0.1285
2024-05-22 15:49:43 [INFO]: Epoch 190 - training loss: 0.2135, validation loss: 0.1288
2024-05-22 15:49:44 [INFO]: Epoch 191 - training loss: 0.2114, validation loss: 0.1284
2024-05-22 15:49:44 [INFO]: Epoch 192 - training loss: 0.2109, validation loss: 0.1269
2024-05-22 15:49:45 [INFO]: Epoch 193 - training loss: 0.2103, validation loss: 0.1279
2024-05-22 15:49:46 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.1284
2024-05-22 15:49:46 [INFO]: Epoch 195 - training loss: 0.2111, validation loss: 0.1277
2024-05-22 15:49:47 [INFO]: Epoch 196 - training loss: 0.2109, validation loss: 0.1284
2024-05-22 15:49:48 [INFO]: Epoch 197 - training loss: 0.2110, validation loss: 0.1281
2024-05-22 15:49:48 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.1292
2024-05-22 15:49:49 [INFO]: Epoch 199 - training loss: 0.2112, validation loss: 0.1281
2024-05-22 15:49:50 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.1274
2024-05-22 15:49:50 [INFO]: Epoch 201 - training loss: 0.2102, validation loss: 0.1276
2024-05-22 15:49:51 [INFO]: Epoch 202 - training loss: 0.2095, validation loss: 0.1274
2024-05-22 15:49:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:49:51 [INFO]: Finished training. The best model is from epoch#192.
2024-05-22 15:49:51 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_air_quality/20240522_T154736/SAITS.pypots
2024-05-22 15:49:51 [INFO]: SAITS on Air-Quality: MAE=0.1478, MSE=0.1199
2024-05-22 15:49:51 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-22 15:49:51 [INFO]: Using the given device: cuda:0
2024-05-22 15:49:51 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240522_T154951
2024-05-22 15:49:51 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_air_quality/20240522_T154951/tensorboard
2024-05-22 15:49:51 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-22 15:49:52 [INFO]: Epoch 001 - training loss: 0.9231, validation loss: 0.4721
2024-05-22 15:49:52 [INFO]: Epoch 002 - training loss: 0.5770, validation loss: 0.3516
2024-05-22 15:49:52 [INFO]: Epoch 003 - training loss: 0.4871, validation loss: 0.3060
2024-05-22 15:49:53 [INFO]: Epoch 004 - training loss: 0.4414, validation loss: 0.2729
2024-05-22 15:49:53 [INFO]: Epoch 005 - training loss: 0.4115, validation loss: 0.2616
2024-05-22 15:49:53 [INFO]: Epoch 006 - training loss: 0.3937, validation loss: 0.2504
2024-05-22 15:49:54 [INFO]: Epoch 007 - training loss: 0.3807, validation loss: 0.2418
2024-05-22 15:49:54 [INFO]: Epoch 008 - training loss: 0.3692, validation loss: 0.2356
2024-05-22 15:49:54 [INFO]: Epoch 009 - training loss: 0.3574, validation loss: 0.2309
2024-05-22 15:49:54 [INFO]: Epoch 010 - training loss: 0.3493, validation loss: 0.2278
2024-05-22 15:49:55 [INFO]: Epoch 011 - training loss: 0.3452, validation loss: 0.2214
2024-05-22 15:49:55 [INFO]: Epoch 012 - training loss: 0.3392, validation loss: 0.2201
2024-05-22 15:49:55 [INFO]: Epoch 013 - training loss: 0.3319, validation loss: 0.2159
2024-05-22 15:49:56 [INFO]: Epoch 014 - training loss: 0.3283, validation loss: 0.2117
2024-05-22 15:49:56 [INFO]: Epoch 015 - training loss: 0.3238, validation loss: 0.2094
2024-05-22 15:49:56 [INFO]: Epoch 016 - training loss: 0.3195, validation loss: 0.2059
2024-05-22 15:49:57 [INFO]: Epoch 017 - training loss: 0.3163, validation loss: 0.2024
2024-05-22 15:49:57 [INFO]: Epoch 018 - training loss: 0.3139, validation loss: 0.2008
2024-05-22 15:49:57 [INFO]: Epoch 019 - training loss: 0.3098, validation loss: 0.1989
2024-05-22 15:49:58 [INFO]: Epoch 020 - training loss: 0.3070, validation loss: 0.1969
2024-05-22 15:49:58 [INFO]: Epoch 021 - training loss: 0.3081, validation loss: 0.1937
2024-05-22 15:49:58 [INFO]: Epoch 022 - training loss: 0.3023, validation loss: 0.1926
2024-05-22 15:49:59 [INFO]: Epoch 023 - training loss: 0.3006, validation loss: 0.1916
2024-05-22 15:49:59 [INFO]: Epoch 024 - training loss: 0.2985, validation loss: 0.1900
2024-05-22 15:49:59 [INFO]: Epoch 025 - training loss: 0.2958, validation loss: 0.1895
2024-05-22 15:49:59 [INFO]: Epoch 026 - training loss: 0.2958, validation loss: 0.1868
2024-05-22 15:50:00 [INFO]: Epoch 027 - training loss: 0.2911, validation loss: 0.1857
2024-05-22 15:50:00 [INFO]: Epoch 028 - training loss: 0.2902, validation loss: 0.1851
2024-05-22 15:50:00 [INFO]: Epoch 029 - training loss: 0.2904, validation loss: 0.1844
2024-05-22 15:50:01 [INFO]: Epoch 030 - training loss: 0.2889, validation loss: 0.1844
2024-05-22 15:50:01 [INFO]: Epoch 031 - training loss: 0.2856, validation loss: 0.1827
2024-05-22 15:50:01 [INFO]: Epoch 032 - training loss: 0.2840, validation loss: 0.1811
2024-05-22 15:50:02 [INFO]: Epoch 033 - training loss: 0.2817, validation loss: 0.1804
2024-05-22 15:50:02 [INFO]: Epoch 034 - training loss: 0.2822, validation loss: 0.1803
2024-05-22 15:50:02 [INFO]: Epoch 035 - training loss: 0.2798, validation loss: 0.1807
2024-05-22 15:50:03 [INFO]: Epoch 036 - training loss: 0.2775, validation loss: 0.1783
2024-05-22 15:50:03 [INFO]: Epoch 037 - training loss: 0.2770, validation loss: 0.1795
2024-05-22 15:50:03 [INFO]: Epoch 038 - training loss: 0.2763, validation loss: 0.1788
2024-05-22 15:50:04 [INFO]: Epoch 039 - training loss: 0.2762, validation loss: 0.1788
2024-05-22 15:50:04 [INFO]: Epoch 040 - training loss: 0.2745, validation loss: 0.1790
2024-05-22 15:50:04 [INFO]: Epoch 041 - training loss: 0.2734, validation loss: 0.1775
2024-05-22 15:50:04 [INFO]: Epoch 042 - training loss: 0.2745, validation loss: 0.1778
2024-05-22 15:50:05 [INFO]: Epoch 043 - training loss: 0.2709, validation loss: 0.1757
2024-05-22 15:50:05 [INFO]: Epoch 044 - training loss: 0.2735, validation loss: 0.1766
2024-05-22 15:50:05 [INFO]: Epoch 045 - training loss: 0.2773, validation loss: 0.1756
2024-05-22 15:50:06 [INFO]: Epoch 046 - training loss: 0.2709, validation loss: 0.1742
2024-05-22 15:50:06 [INFO]: Epoch 047 - training loss: 0.2673, validation loss: 0.1741
2024-05-22 15:50:06 [INFO]: Epoch 048 - training loss: 0.2654, validation loss: 0.1739
2024-05-22 15:50:07 [INFO]: Epoch 049 - training loss: 0.2656, validation loss: 0.1743
2024-05-22 15:50:07 [INFO]: Epoch 050 - training loss: 0.2682, validation loss: 0.1730
2024-05-22 15:50:07 [INFO]: Epoch 051 - training loss: 0.2634, validation loss: 0.1736
2024-05-22 15:50:08 [INFO]: Epoch 052 - training loss: 0.2607, validation loss: 0.1736
2024-05-22 15:50:08 [INFO]: Epoch 053 - training loss: 0.2616, validation loss: 0.1726
2024-05-22 15:50:08 [INFO]: Epoch 054 - training loss: 0.2629, validation loss: 0.1709
2024-05-22 15:50:09 [INFO]: Epoch 055 - training loss: 0.2604, validation loss: 0.1709
2024-05-22 15:50:09 [INFO]: Epoch 056 - training loss: 0.2582, validation loss: 0.1723
2024-05-22 15:50:09 [INFO]: Epoch 057 - training loss: 0.2595, validation loss: 0.1697
2024-05-22 15:50:09 [INFO]: Epoch 058 - training loss: 0.2570, validation loss: 0.1703
2024-05-22 15:50:10 [INFO]: Epoch 059 - training loss: 0.2591, validation loss: 0.1706
2024-05-22 15:50:10 [INFO]: Epoch 060 - training loss: 0.2564, validation loss: 0.1686
2024-05-22 15:50:10 [INFO]: Epoch 061 - training loss: 0.2555, validation loss: 0.1693
2024-05-22 15:50:11 [INFO]: Epoch 062 - training loss: 0.2547, validation loss: 0.1708
2024-05-22 15:50:11 [INFO]: Epoch 063 - training loss: 0.2552, validation loss: 0.1697
2024-05-22 15:50:11 [INFO]: Epoch 064 - training loss: 0.2531, validation loss: 0.1707
2024-05-22 15:50:12 [INFO]: Epoch 065 - training loss: 0.2524, validation loss: 0.1688
2024-05-22 15:50:12 [INFO]: Epoch 066 - training loss: 0.2513, validation loss: 0.1694
2024-05-22 15:50:12 [INFO]: Epoch 067 - training loss: 0.2517, validation loss: 0.1681
2024-05-22 15:50:13 [INFO]: Epoch 068 - training loss: 0.2492, validation loss: 0.1692
2024-05-22 15:50:13 [INFO]: Epoch 069 - training loss: 0.2493, validation loss: 0.1665
2024-05-22 15:50:13 [INFO]: Epoch 070 - training loss: 0.2488, validation loss: 0.1674
2024-05-22 15:50:14 [INFO]: Epoch 071 - training loss: 0.2478, validation loss: 0.1674
2024-05-22 15:50:14 [INFO]: Epoch 072 - training loss: 0.2489, validation loss: 0.1652
2024-05-22 15:50:14 [INFO]: Epoch 073 - training loss: 0.2453, validation loss: 0.1653
2024-05-22 15:50:15 [INFO]: Epoch 074 - training loss: 0.2465, validation loss: 0.1646
2024-05-22 15:50:15 [INFO]: Epoch 075 - training loss: 0.2472, validation loss: 0.1679
2024-05-22 15:50:15 [INFO]: Epoch 076 - training loss: 0.2446, validation loss: 0.1646
2024-05-22 15:50:15 [INFO]: Epoch 077 - training loss: 0.2444, validation loss: 0.1657
2024-05-22 15:50:16 [INFO]: Epoch 078 - training loss: 0.2456, validation loss: 0.1646
2024-05-22 15:50:16 [INFO]: Epoch 079 - training loss: 0.2429, validation loss: 0.1626
2024-05-22 15:50:16 [INFO]: Epoch 080 - training loss: 0.2444, validation loss: 0.1639
2024-05-22 15:50:17 [INFO]: Epoch 081 - training loss: 0.2432, validation loss: 0.1645
2024-05-22 15:50:17 [INFO]: Epoch 082 - training loss: 0.2470, validation loss: 0.1640
2024-05-22 15:50:17 [INFO]: Epoch 083 - training loss: 0.2422, validation loss: 0.1630
2024-05-22 15:50:18 [INFO]: Epoch 084 - training loss: 0.2403, validation loss: 0.1625
2024-05-22 15:50:18 [INFO]: Epoch 085 - training loss: 0.2386, validation loss: 0.1631
2024-05-22 15:50:18 [INFO]: Epoch 086 - training loss: 0.2385, validation loss: 0.1628
2024-05-22 15:50:19 [INFO]: Epoch 087 - training loss: 0.2382, validation loss: 0.1608
2024-05-22 15:50:19 [INFO]: Epoch 088 - training loss: 0.2380, validation loss: 0.1632
2024-05-22 15:50:19 [INFO]: Epoch 089 - training loss: 0.2382, validation loss: 0.1613
2024-05-22 15:50:20 [INFO]: Epoch 090 - training loss: 0.2352, validation loss: 0.1614
2024-05-22 15:50:20 [INFO]: Epoch 091 - training loss: 0.2356, validation loss: 0.1617
2024-05-22 15:50:20 [INFO]: Epoch 092 - training loss: 0.2342, validation loss: 0.1598
2024-05-22 15:50:20 [INFO]: Epoch 093 - training loss: 0.2336, validation loss: 0.1597
2024-05-22 15:50:21 [INFO]: Epoch 094 - training loss: 0.2341, validation loss: 0.1593
2024-05-22 15:50:21 [INFO]: Epoch 095 - training loss: 0.2356, validation loss: 0.1601
2024-05-22 15:50:21 [INFO]: Epoch 096 - training loss: 0.2340, validation loss: 0.1590
2024-05-22 15:50:22 [INFO]: Epoch 097 - training loss: 0.2340, validation loss: 0.1608
2024-05-22 15:50:22 [INFO]: Epoch 098 - training loss: 0.2317, validation loss: 0.1596
2024-05-22 15:50:22 [INFO]: Epoch 099 - training loss: 0.2332, validation loss: 0.1597
2024-05-22 15:50:23 [INFO]: Epoch 100 - training loss: 0.2310, validation loss: 0.1582
2024-05-22 15:50:23 [INFO]: Epoch 101 - training loss: 0.2325, validation loss: 0.1592
2024-05-22 15:50:23 [INFO]: Epoch 102 - training loss: 0.2316, validation loss: 0.1582
2024-05-22 15:50:24 [INFO]: Epoch 103 - training loss: 0.2272, validation loss: 0.1585
2024-05-22 15:50:24 [INFO]: Epoch 104 - training loss: 0.2265, validation loss: 0.1582
2024-05-22 15:50:24 [INFO]: Epoch 105 - training loss: 0.2269, validation loss: 0.1565
2024-05-22 15:50:25 [INFO]: Epoch 106 - training loss: 0.2280, validation loss: 0.1600
2024-05-22 15:50:25 [INFO]: Epoch 107 - training loss: 0.2314, validation loss: 0.1563
2024-05-22 15:50:25 [INFO]: Epoch 108 - training loss: 0.2261, validation loss: 0.1583
2024-05-22 15:50:25 [INFO]: Epoch 109 - training loss: 0.2236, validation loss: 0.1595
2024-05-22 15:50:26 [INFO]: Epoch 110 - training loss: 0.2236, validation loss: 0.1570
2024-05-22 15:50:26 [INFO]: Epoch 111 - training loss: 0.2261, validation loss: 0.1568
2024-05-22 15:50:26 [INFO]: Epoch 112 - training loss: 0.2263, validation loss: 0.1549
2024-05-22 15:50:27 [INFO]: Epoch 113 - training loss: 0.2245, validation loss: 0.1567
2024-05-22 15:50:27 [INFO]: Epoch 114 - training loss: 0.2253, validation loss: 0.1543
2024-05-22 15:50:27 [INFO]: Epoch 115 - training loss: 0.2264, validation loss: 0.1553
2024-05-22 15:50:28 [INFO]: Epoch 116 - training loss: 0.2263, validation loss: 0.1558
2024-05-22 15:50:28 [INFO]: Epoch 117 - training loss: 0.2242, validation loss: 0.1546
2024-05-22 15:50:28 [INFO]: Epoch 118 - training loss: 0.2222, validation loss: 0.1544
2024-05-22 15:50:29 [INFO]: Epoch 119 - training loss: 0.2215, validation loss: 0.1543
2024-05-22 15:50:29 [INFO]: Epoch 120 - training loss: 0.2226, validation loss: 0.1563
2024-05-22 15:50:29 [INFO]: Epoch 121 - training loss: 0.2203, validation loss: 0.1538
2024-05-22 15:50:30 [INFO]: Epoch 122 - training loss: 0.2189, validation loss: 0.1547
2024-05-22 15:50:30 [INFO]: Epoch 123 - training loss: 0.2195, validation loss: 0.1543
2024-05-22 15:50:30 [INFO]: Epoch 124 - training loss: 0.2185, validation loss: 0.1527
2024-05-22 15:50:31 [INFO]: Epoch 125 - training loss: 0.2193, validation loss: 0.1541
2024-05-22 15:50:31 [INFO]: Epoch 126 - training loss: 0.2241, validation loss: 0.1545
2024-05-22 15:50:31 [INFO]: Epoch 127 - training loss: 0.2204, validation loss: 0.1524
2024-05-22 15:50:31 [INFO]: Epoch 128 - training loss: 0.2172, validation loss: 0.1529
2024-05-22 15:50:32 [INFO]: Epoch 129 - training loss: 0.2168, validation loss: 0.1518
2024-05-22 15:50:32 [INFO]: Epoch 130 - training loss: 0.2155, validation loss: 0.1524
2024-05-22 15:50:32 [INFO]: Epoch 131 - training loss: 0.2153, validation loss: 0.1533
2024-05-22 15:50:33 [INFO]: Epoch 132 - training loss: 0.2162, validation loss: 0.1505
2024-05-22 15:50:33 [INFO]: Epoch 133 - training loss: 0.2155, validation loss: 0.1510
2024-05-22 15:50:33 [INFO]: Epoch 134 - training loss: 0.2151, validation loss: 0.1508
2024-05-22 15:50:34 [INFO]: Epoch 135 - training loss: 0.2138, validation loss: 0.1511
2024-05-22 15:50:34 [INFO]: Epoch 136 - training loss: 0.2169, validation loss: 0.1523
2024-05-22 15:50:34 [INFO]: Epoch 137 - training loss: 0.2162, validation loss: 0.1520
2024-05-22 15:50:35 [INFO]: Epoch 138 - training loss: 0.2138, validation loss: 0.1519
2024-05-22 15:50:35 [INFO]: Epoch 139 - training loss: 0.2157, validation loss: 0.1498
2024-05-22 15:50:35 [INFO]: Epoch 140 - training loss: 0.2143, validation loss: 0.1510
2024-05-22 15:50:36 [INFO]: Epoch 141 - training loss: 0.2158, validation loss: 0.1516
2024-05-22 15:50:36 [INFO]: Epoch 142 - training loss: 0.2138, validation loss: 0.1505
2024-05-22 15:50:36 [INFO]: Epoch 143 - training loss: 0.2129, validation loss: 0.1498
2024-05-22 15:50:37 [INFO]: Epoch 144 - training loss: 0.2125, validation loss: 0.1489
2024-05-22 15:50:37 [INFO]: Epoch 145 - training loss: 0.2113, validation loss: 0.1493
2024-05-22 15:50:37 [INFO]: Epoch 146 - training loss: 0.2110, validation loss: 0.1502
2024-05-22 15:50:37 [INFO]: Epoch 147 - training loss: 0.2131, validation loss: 0.1487
2024-05-22 15:50:38 [INFO]: Epoch 148 - training loss: 0.2190, validation loss: 0.1482
2024-05-22 15:50:38 [INFO]: Epoch 149 - training loss: 0.2136, validation loss: 0.1477
2024-05-22 15:50:38 [INFO]: Epoch 150 - training loss: 0.2110, validation loss: 0.1481
2024-05-22 15:50:39 [INFO]: Epoch 151 - training loss: 0.2090, validation loss: 0.1468
2024-05-22 15:50:39 [INFO]: Epoch 152 - training loss: 0.2070, validation loss: 0.1476
2024-05-22 15:50:39 [INFO]: Epoch 153 - training loss: 0.2079, validation loss: 0.1488
2024-05-22 15:50:40 [INFO]: Epoch 154 - training loss: 0.2079, validation loss: 0.1497
2024-05-22 15:50:40 [INFO]: Epoch 155 - training loss: 0.2079, validation loss: 0.1464
2024-05-22 15:50:40 [INFO]: Epoch 156 - training loss: 0.2077, validation loss: 0.1485
2024-05-22 15:50:41 [INFO]: Epoch 157 - training loss: 0.2090, validation loss: 0.1464
2024-05-22 15:50:41 [INFO]: Epoch 158 - training loss: 0.2107, validation loss: 0.1476
2024-05-22 15:50:41 [INFO]: Epoch 159 - training loss: 0.2113, validation loss: 0.1463
2024-05-22 15:50:42 [INFO]: Epoch 160 - training loss: 0.2075, validation loss: 0.1481
2024-05-22 15:50:42 [INFO]: Epoch 161 - training loss: 0.2081, validation loss: 0.1463
2024-05-22 15:50:42 [INFO]: Epoch 162 - training loss: 0.2069, validation loss: 0.1479
2024-05-22 15:50:43 [INFO]: Epoch 163 - training loss: 0.2055, validation loss: 0.1463
2024-05-22 15:50:43 [INFO]: Epoch 164 - training loss: 0.2043, validation loss: 0.1480
2024-05-22 15:50:43 [INFO]: Epoch 165 - training loss: 0.2061, validation loss: 0.1467
2024-05-22 15:50:43 [INFO]: Epoch 166 - training loss: 0.2058, validation loss: 0.1496
2024-05-22 15:50:44 [INFO]: Epoch 167 - training loss: 0.2062, validation loss: 0.1458
2024-05-22 15:50:44 [INFO]: Epoch 168 - training loss: 0.2047, validation loss: 0.1458
2024-05-22 15:50:44 [INFO]: Epoch 169 - training loss: 0.2061, validation loss: 0.1473
2024-05-22 15:50:45 [INFO]: Epoch 170 - training loss: 0.2055, validation loss: 0.1456
2024-05-22 15:50:45 [INFO]: Epoch 171 - training loss: 0.2051, validation loss: 0.1460
2024-05-22 15:50:45 [INFO]: Epoch 172 - training loss: 0.2046, validation loss: 0.1454
2024-05-22 15:50:46 [INFO]: Epoch 173 - training loss: 0.2048, validation loss: 0.1477
2024-05-22 15:50:46 [INFO]: Epoch 174 - training loss: 0.2080, validation loss: 0.1453
2024-05-22 15:50:46 [INFO]: Epoch 175 - training loss: 0.2068, validation loss: 0.1444
2024-05-22 15:50:47 [INFO]: Epoch 176 - training loss: 0.2014, validation loss: 0.1466
2024-05-22 15:50:47 [INFO]: Epoch 177 - training loss: 0.2021, validation loss: 0.1443
2024-05-22 15:50:47 [INFO]: Epoch 178 - training loss: 0.2021, validation loss: 0.1453
2024-05-22 15:50:48 [INFO]: Epoch 179 - training loss: 0.2023, validation loss: 0.1450
2024-05-22 15:50:48 [INFO]: Epoch 180 - training loss: 0.2017, validation loss: 0.1450
2024-05-22 15:50:48 [INFO]: Epoch 181 - training loss: 0.2046, validation loss: 0.1449
2024-05-22 15:50:48 [INFO]: Epoch 182 - training loss: 0.2030, validation loss: 0.1453
2024-05-22 15:50:49 [INFO]: Epoch 183 - training loss: 0.2027, validation loss: 0.1439
2024-05-22 15:50:49 [INFO]: Epoch 184 - training loss: 0.2003, validation loss: 0.1442
2024-05-22 15:50:49 [INFO]: Epoch 185 - training loss: 0.1996, validation loss: 0.1457
2024-05-22 15:50:50 [INFO]: Epoch 186 - training loss: 0.2000, validation loss: 0.1445
2024-05-22 15:50:50 [INFO]: Epoch 187 - training loss: 0.1990, validation loss: 0.1440
2024-05-22 15:50:50 [INFO]: Epoch 188 - training loss: 0.2030, validation loss: 0.1429
2024-05-22 15:50:51 [INFO]: Epoch 189 - training loss: 0.2018, validation loss: 0.1448
2024-05-22 15:50:51 [INFO]: Epoch 190 - training loss: 0.1982, validation loss: 0.1428
2024-05-22 15:50:51 [INFO]: Epoch 191 - training loss: 0.1994, validation loss: 0.1435
2024-05-22 15:50:52 [INFO]: Epoch 192 - training loss: 0.1987, validation loss: 0.1422
2024-05-22 15:50:52 [INFO]: Epoch 193 - training loss: 0.1978, validation loss: 0.1431
2024-05-22 15:50:52 [INFO]: Epoch 194 - training loss: 0.1989, validation loss: 0.1426
2024-05-22 15:50:53 [INFO]: Epoch 195 - training loss: 0.1989, validation loss: 0.1424
2024-05-22 15:50:53 [INFO]: Epoch 196 - training loss: 0.1983, validation loss: 0.1419
2024-05-22 15:50:53 [INFO]: Epoch 197 - training loss: 0.1989, validation loss: 0.1429
2024-05-22 15:50:53 [INFO]: Epoch 198 - training loss: 0.1979, validation loss: 0.1416
2024-05-22 15:50:54 [INFO]: Epoch 199 - training loss: 0.1965, validation loss: 0.1425
2024-05-22 15:50:54 [INFO]: Epoch 200 - training loss: 0.1975, validation loss: 0.1425
2024-05-22 15:50:54 [INFO]: Epoch 201 - training loss: 0.1974, validation loss: 0.1427
2024-05-22 15:50:55 [INFO]: Epoch 202 - training loss: 0.1983, validation loss: 0.1418
2024-05-22 15:50:55 [INFO]: Epoch 203 - training loss: 0.1972, validation loss: 0.1420
2024-05-22 15:50:55 [INFO]: Epoch 204 - training loss: 0.1955, validation loss: 0.1418
2024-05-22 15:50:56 [INFO]: Epoch 205 - training loss: 0.1958, validation loss: 0.1417
2024-05-22 15:50:56 [INFO]: Epoch 206 - training loss: 0.1957, validation loss: 0.1399
2024-05-22 15:50:56 [INFO]: Epoch 207 - training loss: 0.1952, validation loss: 0.1405
2024-05-22 15:50:57 [INFO]: Epoch 208 - training loss: 0.1954, validation loss: 0.1409
2024-05-22 15:50:57 [INFO]: Epoch 209 - training loss: 0.1959, validation loss: 0.1417
2024-05-22 15:50:57 [INFO]: Epoch 210 - training loss: 0.1941, validation loss: 0.1419
2024-05-22 15:50:58 [INFO]: Epoch 211 - training loss: 0.1947, validation loss: 0.1410
2024-05-22 15:50:58 [INFO]: Epoch 212 - training loss: 0.1941, validation loss: 0.1417
2024-05-22 15:50:58 [INFO]: Epoch 213 - training loss: 0.1933, validation loss: 0.1408
2024-05-22 15:50:59 [INFO]: Epoch 214 - training loss: 0.1927, validation loss: 0.1428
2024-05-22 15:50:59 [INFO]: Epoch 215 - training loss: 0.1935, validation loss: 0.1415
2024-05-22 15:50:59 [INFO]: Epoch 216 - training loss: 0.1925, validation loss: 0.1399
2024-05-22 15:50:59 [INFO]: Epoch 217 - training loss: 0.1930, validation loss: 0.1410
2024-05-22 15:51:00 [INFO]: Epoch 218 - training loss: 0.1948, validation loss: 0.1408
2024-05-22 15:51:00 [INFO]: Epoch 219 - training loss: 0.1943, validation loss: 0.1415
2024-05-22 15:51:00 [INFO]: Epoch 220 - training loss: 0.1949, validation loss: 0.1405
2024-05-22 15:51:01 [INFO]: Epoch 221 - training loss: 0.1951, validation loss: 0.1433
2024-05-22 15:51:01 [INFO]: Epoch 222 - training loss: 0.1947, validation loss: 0.1397
2024-05-22 15:51:01 [INFO]: Epoch 223 - training loss: 0.1966, validation loss: 0.1394
2024-05-22 15:51:02 [INFO]: Epoch 224 - training loss: 0.1936, validation loss: 0.1405
2024-05-22 15:51:02 [INFO]: Epoch 225 - training loss: 0.1942, validation loss: 0.1389
2024-05-22 15:51:02 [INFO]: Epoch 226 - training loss: 0.1900, validation loss: 0.1401
2024-05-22 15:51:03 [INFO]: Epoch 227 - training loss: 0.1910, validation loss: 0.1403
2024-05-22 15:51:03 [INFO]: Epoch 228 - training loss: 0.1916, validation loss: 0.1405
2024-05-22 15:51:03 [INFO]: Epoch 229 - training loss: 0.1910, validation loss: 0.1401
2024-05-22 15:51:04 [INFO]: Epoch 230 - training loss: 0.1904, validation loss: 0.1393
2024-05-22 15:51:04 [INFO]: Epoch 231 - training loss: 0.1889, validation loss: 0.1389
2024-05-22 15:51:04 [INFO]: Epoch 232 - training loss: 0.1885, validation loss: 0.1384
2024-05-22 15:51:04 [INFO]: Epoch 233 - training loss: 0.1889, validation loss: 0.1385
2024-05-22 15:51:05 [INFO]: Epoch 234 - training loss: 0.1889, validation loss: 0.1410
2024-05-22 15:51:05 [INFO]: Epoch 235 - training loss: 0.1900, validation loss: 0.1395
2024-05-22 15:51:05 [INFO]: Epoch 236 - training loss: 0.1888, validation loss: 0.1402
2024-05-22 15:51:06 [INFO]: Epoch 237 - training loss: 0.1883, validation loss: 0.1377
2024-05-22 15:51:06 [INFO]: Epoch 238 - training loss: 0.1897, validation loss: 0.1399
2024-05-22 15:51:06 [INFO]: Epoch 239 - training loss: 0.1889, validation loss: 0.1385
2024-05-22 15:51:07 [INFO]: Epoch 240 - training loss: 0.1917, validation loss: 0.1399
2024-05-22 15:51:07 [INFO]: Epoch 241 - training loss: 0.1905, validation loss: 0.1389
2024-05-22 15:51:07 [INFO]: Epoch 242 - training loss: 0.1884, validation loss: 0.1385
2024-05-22 15:51:08 [INFO]: Epoch 243 - training loss: 0.1872, validation loss: 0.1369
2024-05-22 15:51:08 [INFO]: Epoch 244 - training loss: 0.1887, validation loss: 0.1400
2024-05-22 15:51:08 [INFO]: Epoch 245 - training loss: 0.1880, validation loss: 0.1387
2024-05-22 15:51:09 [INFO]: Epoch 246 - training loss: 0.1870, validation loss: 0.1386
2024-05-22 15:51:09 [INFO]: Epoch 247 - training loss: 0.1882, validation loss: 0.1383
2024-05-22 15:51:09 [INFO]: Epoch 248 - training loss: 0.1852, validation loss: 0.1399
2024-05-22 15:51:09 [INFO]: Epoch 249 - training loss: 0.1861, validation loss: 0.1379
2024-05-22 15:51:10 [INFO]: Epoch 250 - training loss: 0.1853, validation loss: 0.1394
2024-05-22 15:51:10 [INFO]: Epoch 251 - training loss: 0.1870, validation loss: 0.1376
2024-05-22 15:51:10 [INFO]: Epoch 252 - training loss: 0.1872, validation loss: 0.1360
2024-05-22 15:51:11 [INFO]: Epoch 253 - training loss: 0.1858, validation loss: 0.1381
2024-05-22 15:51:11 [INFO]: Epoch 254 - training loss: 0.1849, validation loss: 0.1376
2024-05-22 15:51:11 [INFO]: Epoch 255 - training loss: 0.1838, validation loss: 0.1375
2024-05-22 15:51:12 [INFO]: Epoch 256 - training loss: 0.1837, validation loss: 0.1364
2024-05-22 15:51:12 [INFO]: Epoch 257 - training loss: 0.1837, validation loss: 0.1370
2024-05-22 15:51:12 [INFO]: Epoch 258 - training loss: 0.1876, validation loss: 0.1374
2024-05-22 15:51:13 [INFO]: Epoch 259 - training loss: 0.1890, validation loss: 0.1378
2024-05-22 15:51:13 [INFO]: Epoch 260 - training loss: 0.1850, validation loss: 0.1369
2024-05-22 15:51:13 [INFO]: Epoch 261 - training loss: 0.1839, validation loss: 0.1366
2024-05-22 15:51:14 [INFO]: Epoch 262 - training loss: 0.1827, validation loss: 0.1368
2024-05-22 15:51:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:51:14 [INFO]: Finished training. The best model is from epoch#252.
2024-05-22 15:51:14 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_air_quality/20240522_T154951/Transformer.pypots
2024-05-22 15:51:14 [INFO]: Transformer on Air-Quality: MAE=0.1555, MSE=0.1285
2024-05-22 15:51:14 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-22 15:51:14 [INFO]: Using the given device: cuda:0
2024-05-22 15:51:14 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240522_T155114
2024-05-22 15:51:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_air_quality/20240522_T155114/tensorboard
2024-05-22 15:51:14 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-22 15:51:15 [INFO]: Epoch 001 - training loss: 0.2754, validation loss: 0.2705
2024-05-22 15:51:15 [INFO]: Epoch 002 - training loss: 0.2060, validation loss: 0.2370
2024-05-22 15:51:16 [INFO]: Epoch 003 - training loss: 0.1863, validation loss: 0.2274
2024-05-22 15:51:16 [INFO]: Epoch 004 - training loss: 0.1807, validation loss: 0.2145
2024-05-22 15:51:17 [INFO]: Epoch 005 - training loss: 0.1572, validation loss: 0.2022
2024-05-22 15:51:17 [INFO]: Epoch 006 - training loss: 0.1770, validation loss: 0.1906
2024-05-22 15:51:18 [INFO]: Epoch 007 - training loss: 0.1519, validation loss: 0.1912
2024-05-22 15:51:18 [INFO]: Epoch 008 - training loss: 0.1556, validation loss: 0.1883
2024-05-22 15:51:19 [INFO]: Epoch 009 - training loss: 0.1531, validation loss: 0.1952
2024-05-22 15:51:19 [INFO]: Epoch 010 - training loss: 0.1375, validation loss: 0.1945
2024-05-22 15:51:20 [INFO]: Epoch 011 - training loss: 0.1429, validation loss: 0.1826
2024-05-22 15:51:20 [INFO]: Epoch 012 - training loss: 0.1337, validation loss: 0.1868
2024-05-22 15:51:21 [INFO]: Epoch 013 - training loss: 0.1530, validation loss: 0.1860
2024-05-22 15:51:21 [INFO]: Epoch 014 - training loss: 0.1313, validation loss: 0.1796
2024-05-22 15:51:22 [INFO]: Epoch 015 - training loss: 0.1277, validation loss: 0.1805
2024-05-22 15:51:22 [INFO]: Epoch 016 - training loss: 0.1290, validation loss: 0.1780
2024-05-22 15:51:23 [INFO]: Epoch 017 - training loss: 0.1272, validation loss: 0.1729
2024-05-22 15:51:24 [INFO]: Epoch 018 - training loss: 0.1259, validation loss: 0.1728
2024-05-22 15:51:24 [INFO]: Epoch 019 - training loss: 0.1499, validation loss: 0.1850
2024-05-22 15:51:25 [INFO]: Epoch 020 - training loss: 0.1315, validation loss: 0.1685
2024-05-22 15:51:25 [INFO]: Epoch 021 - training loss: 0.1391, validation loss: 0.1756
2024-05-22 15:51:26 [INFO]: Epoch 022 - training loss: 0.1327, validation loss: 0.1783
2024-05-22 15:51:26 [INFO]: Epoch 023 - training loss: 0.1246, validation loss: 0.1680
2024-05-22 15:51:27 [INFO]: Epoch 024 - training loss: 0.1250, validation loss: 0.1738
2024-05-22 15:51:27 [INFO]: Epoch 025 - training loss: 0.1387, validation loss: 0.1773
2024-05-22 15:51:28 [INFO]: Epoch 026 - training loss: 0.1126, validation loss: 0.1792
2024-05-22 15:51:28 [INFO]: Epoch 027 - training loss: 0.1164, validation loss: 0.1745
2024-05-22 15:51:29 [INFO]: Epoch 028 - training loss: 0.1155, validation loss: 0.1764
2024-05-22 15:51:29 [INFO]: Epoch 029 - training loss: 0.1344, validation loss: 0.1745
2024-05-22 15:51:30 [INFO]: Epoch 030 - training loss: 0.1161, validation loss: 0.1724
2024-05-22 15:51:30 [INFO]: Epoch 031 - training loss: 0.1197, validation loss: 0.1753
2024-05-22 15:51:31 [INFO]: Epoch 032 - training loss: 0.1132, validation loss: 0.1720
2024-05-22 15:51:31 [INFO]: Epoch 033 - training loss: 0.1147, validation loss: 0.1700
2024-05-22 15:51:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 15:51:31 [INFO]: Finished training. The best model is from epoch#23.
2024-05-22 15:51:32 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_air_quality/20240522_T155114/TimesNet.pypots
2024-05-22 15:51:32 [INFO]: TimesNet on Air-Quality: MAE=0.1656, MSE=0.1595
2024-05-22 15:51:32 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-22 15:51:32 [INFO]: Using the given device: cuda:0
2024-05-22 15:51:32 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132
2024-05-22 15:51:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/tensorboard
2024-05-22 15:51:32 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-22 15:51:48 [INFO]: Epoch 001 - training loss: 0.4844, validation loss: 0.3810
2024-05-22 15:51:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch1_loss0.38103061318397524.pypots
2024-05-22 15:52:05 [INFO]: Epoch 002 - training loss: 0.2902, validation loss: 0.2639
2024-05-22 15:52:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch2_loss0.2639385685324669.pypots
2024-05-22 15:52:22 [INFO]: Epoch 003 - training loss: 0.2638, validation loss: 0.2255
2024-05-22 15:52:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch3_loss0.22549342960119248.pypots
2024-05-22 15:52:39 [INFO]: Epoch 004 - training loss: 0.2276, validation loss: 0.1913
2024-05-22 15:52:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch4_loss0.19133950024843216.pypots
2024-05-22 15:52:56 [INFO]: Epoch 005 - training loss: 0.1932, validation loss: 0.1748
2024-05-22 15:52:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch5_loss0.17477425634860994.pypots
2024-05-22 15:53:13 [INFO]: Epoch 006 - training loss: 0.1910, validation loss: 0.1715
2024-05-22 15:53:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch6_loss0.17151094675064088.pypots
2024-05-22 15:53:29 [INFO]: Epoch 007 - training loss: 0.1755, validation loss: 0.1627
2024-05-22 15:53:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch7_loss0.16273936480283738.pypots
2024-05-22 15:53:46 [INFO]: Epoch 008 - training loss: 0.1852, validation loss: 0.1578
2024-05-22 15:53:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch8_loss0.15778088867664336.pypots
2024-05-22 15:54:03 [INFO]: Epoch 009 - training loss: 0.1778, validation loss: 0.1704
2024-05-22 15:54:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch9_loss0.17040006667375565.pypots
2024-05-22 15:54:20 [INFO]: Epoch 010 - training loss: 0.1797, validation loss: 0.1533
2024-05-22 15:54:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch10_loss0.15330942571163178.pypots
2024-05-22 15:54:37 [INFO]: Epoch 011 - training loss: 0.1869, validation loss: 0.1494
2024-05-22 15:54:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch11_loss0.14936006665229798.pypots
2024-05-22 15:54:53 [INFO]: Epoch 012 - training loss: 0.1842, validation loss: 0.1491
2024-05-22 15:54:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch12_loss0.14912165701389313.pypots
2024-05-22 15:55:10 [INFO]: Epoch 013 - training loss: 0.1693, validation loss: 0.1516
2024-05-22 15:55:10 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch13_loss0.15163294970989227.pypots
2024-05-22 15:55:27 [INFO]: Epoch 014 - training loss: 0.1783, validation loss: 0.1476
2024-05-22 15:55:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch14_loss0.14756760895252227.pypots
2024-05-22 15:55:44 [INFO]: Epoch 015 - training loss: 0.1578, validation loss: 0.1471
2024-05-22 15:55:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch15_loss0.14712039679288863.pypots
2024-05-22 15:56:01 [INFO]: Epoch 016 - training loss: 0.1558, validation loss: 0.1375
2024-05-22 15:56:01 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch16_loss0.1374637320637703.pypots
2024-05-22 15:56:18 [INFO]: Epoch 017 - training loss: 0.1554, validation loss: 0.1385
2024-05-22 15:56:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch17_loss0.13845610842108727.pypots
2024-05-22 15:56:34 [INFO]: Epoch 018 - training loss: 0.1373, validation loss: 0.1365
2024-05-22 15:56:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch18_loss0.13652496561408042.pypots
2024-05-22 15:56:51 [INFO]: Epoch 019 - training loss: 0.1451, validation loss: 0.1329
2024-05-22 15:56:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch19_loss0.13291334733366966.pypots
2024-05-22 15:57:08 [INFO]: Epoch 020 - training loss: 0.1518, validation loss: 0.1385
2024-05-22 15:57:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch20_loss0.138477723300457.pypots
2024-05-22 15:57:25 [INFO]: Epoch 021 - training loss: 0.1440, validation loss: 0.1332
2024-05-22 15:57:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch21_loss0.1332403115928173.pypots
2024-05-22 15:57:42 [INFO]: Epoch 022 - training loss: 0.1544, validation loss: 0.1346
2024-05-22 15:57:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch22_loss0.13461980149149894.pypots
2024-05-22 15:57:58 [INFO]: Epoch 023 - training loss: 0.1374, validation loss: 0.1339
2024-05-22 15:57:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch23_loss0.1338628314435482.pypots
2024-05-22 15:58:15 [INFO]: Epoch 024 - training loss: 0.1517, validation loss: 0.1328
2024-05-22 15:58:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch24_loss0.13281821608543395.pypots
2024-05-22 15:58:32 [INFO]: Epoch 025 - training loss: 0.1549, validation loss: 0.1298
2024-05-22 15:58:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch25_loss0.1298062413930893.pypots
2024-05-22 15:58:49 [INFO]: Epoch 026 - training loss: 0.1377, validation loss: 0.1261
2024-05-22 15:58:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch26_loss0.12610427513718606.pypots
2024-05-22 15:59:06 [INFO]: Epoch 027 - training loss: 0.1401, validation loss: 0.1285
2024-05-22 15:59:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch27_loss0.12848397120833396.pypots
2024-05-22 15:59:23 [INFO]: Epoch 028 - training loss: 0.1511, validation loss: 0.1239
2024-05-22 15:59:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch28_loss0.12390719726681709.pypots
2024-05-22 15:59:39 [INFO]: Epoch 029 - training loss: 0.1580, validation loss: 0.1270
2024-05-22 15:59:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch29_loss0.12696922868490218.pypots
2024-05-22 15:59:56 [INFO]: Epoch 030 - training loss: 0.1517, validation loss: 0.1219
2024-05-22 15:59:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch30_loss0.12189821302890777.pypots
2024-05-22 16:00:13 [INFO]: Epoch 031 - training loss: 0.1350, validation loss: 0.1243
2024-05-22 16:00:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch31_loss0.12434568926692009.pypots
2024-05-22 16:00:30 [INFO]: Epoch 032 - training loss: 0.1309, validation loss: 0.1237
2024-05-22 16:00:30 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch32_loss0.12366923689842224.pypots
2024-05-22 16:00:47 [INFO]: Epoch 033 - training loss: 0.1404, validation loss: 0.1231
2024-05-22 16:00:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch33_loss0.12314138486981392.pypots
2024-05-22 16:01:03 [INFO]: Epoch 034 - training loss: 0.1356, validation loss: 0.1280
2024-05-22 16:01:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch34_loss0.12800046801567078.pypots
2024-05-22 16:01:20 [INFO]: Epoch 035 - training loss: 0.1368, validation loss: 0.1202
2024-05-22 16:01:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch35_loss0.12023653537034988.pypots
2024-05-22 16:01:37 [INFO]: Epoch 036 - training loss: 0.1213, validation loss: 0.1204
2024-05-22 16:01:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch36_loss0.1204399399459362.pypots
2024-05-22 16:01:54 [INFO]: Epoch 037 - training loss: 0.1160, validation loss: 0.1217
2024-05-22 16:01:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch37_loss0.12167147547006607.pypots
2024-05-22 16:02:11 [INFO]: Epoch 038 - training loss: 0.1249, validation loss: 0.1190
2024-05-22 16:02:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch38_loss0.11901652216911315.pypots
2024-05-22 16:02:27 [INFO]: Epoch 039 - training loss: 0.1408, validation loss: 0.1197
2024-05-22 16:02:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch39_loss0.11972100064158439.pypots
2024-05-22 16:02:44 [INFO]: Epoch 040 - training loss: 0.1318, validation loss: 0.1208
2024-05-22 16:02:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch40_loss0.12077807337045669.pypots
2024-05-22 16:03:01 [INFO]: Epoch 041 - training loss: 0.1275, validation loss: 0.1192
2024-05-22 16:03:01 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch41_loss0.11921940967440606.pypots
2024-05-22 16:03:18 [INFO]: Epoch 042 - training loss: 0.1324, validation loss: 0.1187
2024-05-22 16:03:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch42_loss0.1186889462172985.pypots
2024-05-22 16:03:35 [INFO]: Epoch 043 - training loss: 0.1427, validation loss: 0.1167
2024-05-22 16:03:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch43_loss0.11673091500997543.pypots
2024-05-22 16:03:52 [INFO]: Epoch 044 - training loss: 0.1278, validation loss: 0.1174
2024-05-22 16:03:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch44_loss0.11741446554660798.pypots
2024-05-22 16:04:08 [INFO]: Epoch 045 - training loss: 0.1195, validation loss: 0.1255
2024-05-22 16:04:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch45_loss0.12553816437721252.pypots
2024-05-22 16:04:25 [INFO]: Epoch 046 - training loss: 0.1265, validation loss: 0.1154
2024-05-22 16:04:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch46_loss0.11541134640574455.pypots
2024-05-22 16:04:42 [INFO]: Epoch 047 - training loss: 0.1236, validation loss: 0.1185
2024-05-22 16:04:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch47_loss0.11849103271961212.pypots
2024-05-22 16:04:59 [INFO]: Epoch 048 - training loss: 0.1295, validation loss: 0.1195
2024-05-22 16:04:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch48_loss0.11946839392185211.pypots
2024-05-22 16:05:16 [INFO]: Epoch 049 - training loss: 0.1065, validation loss: 0.1184
2024-05-22 16:05:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch49_loss0.11836010441184044.pypots
2024-05-22 16:05:32 [INFO]: Epoch 050 - training loss: 0.1326, validation loss: 0.1302
2024-05-22 16:05:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch50_loss0.13022817224264144.pypots
2024-05-22 16:05:49 [INFO]: Epoch 051 - training loss: 0.1189, validation loss: 0.1197
2024-05-22 16:05:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch51_loss0.11965078040957451.pypots
2024-05-22 16:06:06 [INFO]: Epoch 052 - training loss: 0.1214, validation loss: 0.1109
2024-05-22 16:06:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch52_loss0.11094666793942451.pypots
2024-05-22 16:06:23 [INFO]: Epoch 053 - training loss: 0.1348, validation loss: 0.1142
2024-05-22 16:06:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch53_loss0.11424705609679223.pypots
2024-05-22 16:06:40 [INFO]: Epoch 054 - training loss: 0.1218, validation loss: 0.1157
2024-05-22 16:06:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch54_loss0.1156564213335514.pypots
2024-05-22 16:06:57 [INFO]: Epoch 055 - training loss: 0.1255, validation loss: 0.1177
2024-05-22 16:06:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch55_loss0.11768768653273583.pypots
2024-05-22 16:07:13 [INFO]: Epoch 056 - training loss: 0.1270, validation loss: 0.1214
2024-05-22 16:07:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch56_loss0.12136840969324111.pypots
2024-05-22 16:07:30 [INFO]: Epoch 057 - training loss: 0.1219, validation loss: 0.1111
2024-05-22 16:07:30 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch57_loss0.11110836490988732.pypots
2024-05-22 16:07:47 [INFO]: Epoch 058 - training loss: 0.1110, validation loss: 0.1133
2024-05-22 16:07:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch58_loss0.11332042217254638.pypots
2024-05-22 16:08:04 [INFO]: Epoch 059 - training loss: 0.1252, validation loss: 0.1162
2024-05-22 16:08:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch59_loss0.11622115075588227.pypots
2024-05-22 16:08:21 [INFO]: Epoch 060 - training loss: 0.1165, validation loss: 0.1111
2024-05-22 16:08:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch60_loss0.11113821715116501.pypots
2024-05-22 16:08:37 [INFO]: Epoch 061 - training loss: 0.1185, validation loss: 0.1103
2024-05-22 16:08:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch61_loss0.11031175255775452.pypots
2024-05-22 16:08:54 [INFO]: Epoch 062 - training loss: 0.1252, validation loss: 0.1126
2024-05-22 16:08:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch62_loss0.11257086768746376.pypots
2024-05-22 16:09:11 [INFO]: Epoch 063 - training loss: 0.1316, validation loss: 0.1106
2024-05-22 16:09:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch63_loss0.11064449548721314.pypots
2024-05-22 16:09:28 [INFO]: Epoch 064 - training loss: 0.1200, validation loss: 0.1116
2024-05-22 16:09:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch64_loss0.11162104159593582.pypots
2024-05-22 16:09:45 [INFO]: Epoch 065 - training loss: 0.1205, validation loss: 0.1197
2024-05-22 16:09:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch65_loss0.11969033628702164.pypots
2024-05-22 16:10:02 [INFO]: Epoch 066 - training loss: 0.1434, validation loss: 0.1112
2024-05-22 16:10:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch66_loss0.11124675571918488.pypots
2024-05-22 16:10:18 [INFO]: Epoch 067 - training loss: 0.1260, validation loss: 0.1130
2024-05-22 16:10:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch67_loss0.11295920014381408.pypots
2024-05-22 16:10:35 [INFO]: Epoch 068 - training loss: 0.1276, validation loss: 0.1138
2024-05-22 16:10:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch68_loss0.11383396834135055.pypots
2024-05-22 16:10:52 [INFO]: Epoch 069 - training loss: 0.1173, validation loss: 0.1088
2024-05-22 16:10:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch69_loss0.10881272181868554.pypots
2024-05-22 16:11:09 [INFO]: Epoch 070 - training loss: 0.1260, validation loss: 0.1074
2024-05-22 16:11:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch70_loss0.10737390518188476.pypots
2024-05-22 16:11:26 [INFO]: Epoch 071 - training loss: 0.1200, validation loss: 0.1100
2024-05-22 16:11:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch71_loss0.110048858076334.pypots
2024-05-22 16:11:42 [INFO]: Epoch 072 - training loss: 0.1054, validation loss: 0.1077
2024-05-22 16:11:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch72_loss0.10772979110479355.pypots
2024-05-22 16:11:59 [INFO]: Epoch 073 - training loss: 0.1123, validation loss: 0.1067
2024-05-22 16:11:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch73_loss0.10666201114654542.pypots
2024-05-22 16:12:16 [INFO]: Epoch 074 - training loss: 0.0909, validation loss: 0.1203
2024-05-22 16:12:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch74_loss0.12025713175535202.pypots
2024-05-22 16:12:33 [INFO]: Epoch 075 - training loss: 0.1236, validation loss: 0.1071
2024-05-22 16:12:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch75_loss0.1070939376950264.pypots
2024-05-22 16:12:50 [INFO]: Epoch 076 - training loss: 0.1196, validation loss: 0.1068
2024-05-22 16:12:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch76_loss0.10675423294305801.pypots
2024-05-22 16:13:07 [INFO]: Epoch 077 - training loss: 0.1233, validation loss: 0.1102
2024-05-22 16:13:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch77_loss0.11022084429860116.pypots
2024-05-22 16:13:23 [INFO]: Epoch 078 - training loss: 0.1282, validation loss: 0.1097
2024-05-22 16:13:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch78_loss0.1096839502453804.pypots
2024-05-22 16:13:40 [INFO]: Epoch 079 - training loss: 0.1141, validation loss: 0.1080
2024-05-22 16:13:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch79_loss0.10802542045712471.pypots
2024-05-22 16:13:57 [INFO]: Epoch 080 - training loss: 0.1121, validation loss: 0.1087
2024-05-22 16:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch80_loss0.10872430354356766.pypots
2024-05-22 16:14:14 [INFO]: Epoch 081 - training loss: 0.1095, validation loss: 0.1056
2024-05-22 16:14:14 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch81_loss0.10561630874872208.pypots
2024-05-22 16:14:31 [INFO]: Epoch 082 - training loss: 0.1101, validation loss: 0.1053
2024-05-22 16:14:31 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch82_loss0.10526136904954911.pypots
2024-05-22 16:14:47 [INFO]: Epoch 083 - training loss: 0.1188, validation loss: 0.1069
2024-05-22 16:14:47 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch83_loss0.10685240030288697.pypots
2024-05-22 16:15:04 [INFO]: Epoch 084 - training loss: 0.1078, validation loss: 0.1081
2024-05-22 16:15:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch84_loss0.10809011086821556.pypots
2024-05-22 16:15:21 [INFO]: Epoch 085 - training loss: 0.1143, validation loss: 0.1090
2024-05-22 16:15:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch85_loss0.10896039828658104.pypots
2024-05-22 16:15:38 [INFO]: Epoch 086 - training loss: 0.1193, validation loss: 0.1065
2024-05-22 16:15:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch86_loss0.1064843438565731.pypots
2024-05-22 16:15:55 [INFO]: Epoch 087 - training loss: 0.1028, validation loss: 0.1064
2024-05-22 16:15:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch87_loss0.10641680955886841.pypots
2024-05-22 16:16:11 [INFO]: Epoch 088 - training loss: 0.1168, validation loss: 0.1061
2024-05-22 16:16:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch88_loss0.1060750313103199.pypots
2024-05-22 16:16:28 [INFO]: Epoch 089 - training loss: 0.1075, validation loss: 0.1062
2024-05-22 16:16:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch89_loss0.10617496222257614.pypots
2024-05-22 16:16:45 [INFO]: Epoch 090 - training loss: 0.1221, validation loss: 0.1087
2024-05-22 16:16:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch90_loss0.10866204053163528.pypots
2024-05-22 16:17:02 [INFO]: Epoch 091 - training loss: 0.1119, validation loss: 0.1048
2024-05-22 16:17:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch91_loss0.10476211681962014.pypots
2024-05-22 16:17:19 [INFO]: Epoch 092 - training loss: 0.1123, validation loss: 0.1049
2024-05-22 16:17:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch92_loss0.104899450391531.pypots
2024-05-22 16:17:36 [INFO]: Epoch 093 - training loss: 0.1173, validation loss: 0.1083
2024-05-22 16:17:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch93_loss0.10834033042192459.pypots
2024-05-22 16:17:52 [INFO]: Epoch 094 - training loss: 0.1298, validation loss: 0.1067
2024-05-22 16:17:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch94_loss0.10673476755619049.pypots
2024-05-22 16:18:09 [INFO]: Epoch 095 - training loss: 0.1215, validation loss: 0.1057
2024-05-22 16:18:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch95_loss0.1056761957705021.pypots
2024-05-22 16:18:26 [INFO]: Epoch 096 - training loss: 0.1228, validation loss: 0.1065
2024-05-22 16:18:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch96_loss0.10650743618607521.pypots
2024-05-22 16:18:43 [INFO]: Epoch 097 - training loss: 0.1224, validation loss: 0.1091
2024-05-22 16:18:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch97_loss0.10907008424401284.pypots
2024-05-22 16:19:00 [INFO]: Epoch 098 - training loss: 0.1079, validation loss: 0.1069
2024-05-22 16:19:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch98_loss0.10686941593885421.pypots
2024-05-22 16:19:17 [INFO]: Epoch 099 - training loss: 0.1107, validation loss: 0.1083
2024-05-22 16:19:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch99_loss0.10827218964695931.pypots
2024-05-22 16:19:33 [INFO]: Epoch 100 - training loss: 0.1120, validation loss: 0.1058
2024-05-22 16:19:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch100_loss0.10576520636677741.pypots
2024-05-22 16:19:50 [INFO]: Epoch 101 - training loss: 0.1199, validation loss: 0.1056
2024-05-22 16:19:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI_epoch101_loss0.10560269579291344.pypots
2024-05-22 16:19:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:19:50 [INFO]: Finished training. The best model is from epoch#91.
2024-05-22 16:19:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_air_quality/20240522_T155132/CSDI.pypots
2024-05-22 16:22:11 [INFO]: CSDI on Air-Quality: MAE=0.1061, MSE=0.1043
2024-05-22 16:22:11 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-22 16:22:11 [INFO]: Using the given device: cuda:0
2024-05-22 16:22:11 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240522_T162211
2024-05-22 16:22:11 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_air_quality/20240522_T162211/tensorboard
2024-05-22 16:22:11 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-22 16:22:11 [INFO]: Epoch 001 - training loss: 62933.6939, validation loss: 0.6527
2024-05-22 16:22:12 [INFO]: Epoch 002 - training loss: 42072.2185, validation loss: 0.6083
2024-05-22 16:22:12 [INFO]: Epoch 003 - training loss: 41784.8407, validation loss: 0.5592
2024-05-22 16:22:12 [INFO]: Epoch 004 - training loss: 41659.0496, validation loss: 0.5071
2024-05-22 16:22:13 [INFO]: Epoch 005 - training loss: 41559.5266, validation loss: 0.4420
2024-05-22 16:22:13 [INFO]: Epoch 006 - training loss: 41496.8066, validation loss: 0.4171
2024-05-22 16:22:13 [INFO]: Epoch 007 - training loss: 41503.2368, validation loss: 0.4205
2024-05-22 16:22:14 [INFO]: Epoch 008 - training loss: 41452.3601, validation loss: 0.3845
2024-05-22 16:22:14 [INFO]: Epoch 009 - training loss: 41399.3749, validation loss: 0.3695
2024-05-22 16:22:14 [INFO]: Epoch 010 - training loss: 41371.3071, validation loss: 0.3538
2024-05-22 16:22:15 [INFO]: Epoch 011 - training loss: 41355.8659, validation loss: 0.3359
2024-05-22 16:22:15 [INFO]: Epoch 012 - training loss: 41366.7406, validation loss: 0.3287
2024-05-22 16:22:15 [INFO]: Epoch 013 - training loss: 41323.3124, validation loss: 0.3255
2024-05-22 16:22:16 [INFO]: Epoch 014 - training loss: 41309.1411, validation loss: 0.3195
2024-05-22 16:22:16 [INFO]: Epoch 015 - training loss: 41301.6195, validation loss: 0.3031
2024-05-22 16:22:16 [INFO]: Epoch 016 - training loss: 41290.4042, validation loss: 0.3107
2024-05-22 16:22:17 [INFO]: Epoch 017 - training loss: 41295.9591, validation loss: 0.2999
2024-05-22 16:22:17 [INFO]: Epoch 018 - training loss: 41278.8530, validation loss: 0.2908
2024-05-22 16:22:17 [INFO]: Epoch 019 - training loss: 41274.1092, validation loss: 0.3127
2024-05-22 16:22:18 [INFO]: Epoch 020 - training loss: 41265.4149, validation loss: 0.2842
2024-05-22 16:22:18 [INFO]: Epoch 021 - training loss: 41256.5545, validation loss: 0.2950
2024-05-22 16:22:18 [INFO]: Epoch 022 - training loss: 41244.4359, validation loss: 0.2813
2024-05-22 16:22:19 [INFO]: Epoch 023 - training loss: 41246.4792, validation loss: 0.2789
2024-05-22 16:22:19 [INFO]: Epoch 024 - training loss: 41242.8176, validation loss: 0.2800
2024-05-22 16:22:19 [INFO]: Epoch 025 - training loss: 41269.2627, validation loss: 0.3126
2024-05-22 16:22:20 [INFO]: Epoch 026 - training loss: 41297.4841, validation loss: 0.3410
2024-05-22 16:22:20 [INFO]: Epoch 027 - training loss: 41321.0625, validation loss: 0.2812
2024-05-22 16:22:20 [INFO]: Epoch 028 - training loss: 41251.3604, validation loss: 0.2906
2024-05-22 16:22:21 [INFO]: Epoch 029 - training loss: 41243.2771, validation loss: 0.2761
2024-05-22 16:22:21 [INFO]: Epoch 030 - training loss: 41253.2549, validation loss: 0.3104
2024-05-22 16:22:22 [INFO]: Epoch 031 - training loss: 41239.7973, validation loss: 0.2721
2024-05-22 16:22:22 [INFO]: Epoch 032 - training loss: 41212.7737, validation loss: 0.2592
2024-05-22 16:22:22 [INFO]: Epoch 033 - training loss: 41216.2758, validation loss: 0.2721
2024-05-22 16:22:23 [INFO]: Epoch 034 - training loss: 41201.9443, validation loss: 0.2533
2024-05-22 16:22:23 [INFO]: Epoch 035 - training loss: 41195.3746, validation loss: 0.2598
2024-05-22 16:22:23 [INFO]: Epoch 036 - training loss: 41193.4965, validation loss: 0.2588
2024-05-22 16:22:24 [INFO]: Epoch 037 - training loss: 41206.1623, validation loss: 0.2611
2024-05-22 16:22:24 [INFO]: Epoch 038 - training loss: 41191.4162, validation loss: 0.2669
2024-05-22 16:22:24 [INFO]: Epoch 039 - training loss: 41204.4938, validation loss: 0.2684
2024-05-22 16:22:25 [INFO]: Epoch 040 - training loss: 41189.1046, validation loss: 0.2639
2024-05-22 16:22:25 [INFO]: Epoch 041 - training loss: 41187.0984, validation loss: 0.2664
2024-05-22 16:22:25 [INFO]: Epoch 042 - training loss: 41196.5408, validation loss: 0.3568
2024-05-22 16:22:26 [INFO]: Epoch 043 - training loss: 41244.2312, validation loss: 0.2921
2024-05-22 16:22:26 [INFO]: Epoch 044 - training loss: 41235.5945, validation loss: 0.2776
2024-05-22 16:22:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:22:26 [INFO]: Finished training. The best model is from epoch#34.
2024-05-22 16:22:26 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_air_quality/20240522_T162211/GPVAE.pypots
2024-05-22 16:22:26 [INFO]: GP-VAE on Air-Quality: MAE=0.2978, MSE=0.2717
2024-05-22 16:22:26 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-22 16:22:26 [INFO]: Using the given device: cuda:0
2024-05-22 16:22:26 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240522_T162226
2024-05-22 16:22:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_air_quality/20240522_T162226/tensorboard
2024-05-22 16:22:26 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-22 16:22:31 [INFO]: Epoch 001 - generator training loss: 0.6001, discriminator training loss: 0.2858, validation loss: 0.5142
2024-05-22 16:22:35 [INFO]: Epoch 002 - generator training loss: 0.2919, discriminator training loss: 0.0664, validation loss: 0.3958
2024-05-22 16:22:39 [INFO]: Epoch 003 - generator training loss: 0.2162, discriminator training loss: 0.0632, validation loss: 0.3298
2024-05-22 16:22:43 [INFO]: Epoch 004 - generator training loss: 0.1807, discriminator training loss: 0.0620, validation loss: 0.2900
2024-05-22 16:22:47 [INFO]: Epoch 005 - generator training loss: 0.1590, discriminator training loss: 0.0615, validation loss: 0.2653
2024-05-22 16:22:51 [INFO]: Epoch 006 - generator training loss: 0.1406, discriminator training loss: 0.0617, validation loss: 0.2493
2024-05-22 16:22:55 [INFO]: Epoch 007 - generator training loss: 0.1285, discriminator training loss: 0.0608, validation loss: 0.2363
2024-05-22 16:22:59 [INFO]: Epoch 008 - generator training loss: 0.1208, discriminator training loss: 0.0599, validation loss: 0.2270
2024-05-22 16:23:03 [INFO]: Epoch 009 - generator training loss: 0.1101, discriminator training loss: 0.0600, validation loss: 0.2191
2024-05-22 16:23:07 [INFO]: Epoch 010 - generator training loss: 0.1045, discriminator training loss: 0.0588, validation loss: 0.2128
2024-05-22 16:23:11 [INFO]: Epoch 011 - generator training loss: 0.1002, discriminator training loss: 0.0576, validation loss: 0.2071
2024-05-22 16:23:15 [INFO]: Epoch 012 - generator training loss: 0.0951, discriminator training loss: 0.0566, validation loss: 0.2029
2024-05-22 16:23:19 [INFO]: Epoch 013 - generator training loss: 0.0917, discriminator training loss: 0.0549, validation loss: 0.1992
2024-05-22 16:23:23 [INFO]: Epoch 014 - generator training loss: 0.0871, discriminator training loss: 0.0535, validation loss: 0.1958
2024-05-22 16:23:27 [INFO]: Epoch 015 - generator training loss: 0.0866, discriminator training loss: 0.0516, validation loss: 0.1936
2024-05-22 16:23:31 [INFO]: Epoch 016 - generator training loss: 0.0820, discriminator training loss: 0.0501, validation loss: 0.1912
2024-05-22 16:23:35 [INFO]: Epoch 017 - generator training loss: 0.0798, discriminator training loss: 0.0487, validation loss: 0.1892
2024-05-22 16:23:39 [INFO]: Epoch 018 - generator training loss: 0.0785, discriminator training loss: 0.0471, validation loss: 0.1877
2024-05-22 16:23:43 [INFO]: Epoch 019 - generator training loss: 0.0762, discriminator training loss: 0.0461, validation loss: 0.1858
2024-05-22 16:23:47 [INFO]: Epoch 020 - generator training loss: 0.0745, discriminator training loss: 0.0455, validation loss: 0.1840
2024-05-22 16:23:51 [INFO]: Epoch 021 - generator training loss: 0.0717, discriminator training loss: 0.0448, validation loss: 0.1818
2024-05-22 16:23:55 [INFO]: Epoch 022 - generator training loss: 0.0693, discriminator training loss: 0.0440, validation loss: 0.1807
2024-05-22 16:23:59 [INFO]: Epoch 023 - generator training loss: 0.0678, discriminator training loss: 0.0433, validation loss: 0.1783
2024-05-22 16:24:04 [INFO]: Epoch 024 - generator training loss: 0.0669, discriminator training loss: 0.0429, validation loss: 0.1775
2024-05-22 16:24:08 [INFO]: Epoch 025 - generator training loss: 0.0652, discriminator training loss: 0.0420, validation loss: 0.1756
2024-05-22 16:24:12 [INFO]: Epoch 026 - generator training loss: 0.0650, discriminator training loss: 0.0413, validation loss: 0.1744
2024-05-22 16:24:16 [INFO]: Epoch 027 - generator training loss: 0.0639, discriminator training loss: 0.0405, validation loss: 0.1732
2024-05-22 16:24:20 [INFO]: Epoch 028 - generator training loss: 0.0634, discriminator training loss: 0.0394, validation loss: 0.1724
2024-05-22 16:24:24 [INFO]: Epoch 029 - generator training loss: 0.0617, discriminator training loss: 0.0388, validation loss: 0.1709
2024-05-22 16:24:28 [INFO]: Epoch 030 - generator training loss: 0.0627, discriminator training loss: 0.0379, validation loss: 0.1696
2024-05-22 16:24:32 [INFO]: Epoch 031 - generator training loss: 0.0608, discriminator training loss: 0.0373, validation loss: 0.1690
2024-05-22 16:24:36 [INFO]: Epoch 032 - generator training loss: 0.0595, discriminator training loss: 0.0364, validation loss: 0.1676
2024-05-22 16:24:40 [INFO]: Epoch 033 - generator training loss: 0.0597, discriminator training loss: 0.0353, validation loss: 0.1671
2024-05-22 16:24:44 [INFO]: Epoch 034 - generator training loss: 0.0597, discriminator training loss: 0.0344, validation loss: 0.1661
2024-05-22 16:24:48 [INFO]: Epoch 035 - generator training loss: 0.0607, discriminator training loss: 0.0336, validation loss: 0.1658
2024-05-22 16:24:52 [INFO]: Epoch 036 - generator training loss: 0.0590, discriminator training loss: 0.0329, validation loss: 0.1651
2024-05-22 16:24:56 [INFO]: Epoch 037 - generator training loss: 0.0583, discriminator training loss: 0.0321, validation loss: 0.1638
2024-05-22 16:25:00 [INFO]: Epoch 038 - generator training loss: 0.0589, discriminator training loss: 0.0315, validation loss: 0.1630
2024-05-22 16:25:04 [INFO]: Epoch 039 - generator training loss: 0.0568, discriminator training loss: 0.0308, validation loss: 0.1620
2024-05-22 16:25:08 [INFO]: Epoch 040 - generator training loss: 0.0559, discriminator training loss: 0.0299, validation loss: 0.1604
2024-05-22 16:25:12 [INFO]: Epoch 041 - generator training loss: 0.0549, discriminator training loss: 0.0301, validation loss: 0.1599
2024-05-22 16:25:16 [INFO]: Epoch 042 - generator training loss: 0.0569, discriminator training loss: 0.0290, validation loss: 0.1585
2024-05-22 16:25:20 [INFO]: Epoch 043 - generator training loss: 0.0544, discriminator training loss: 0.0284, validation loss: 0.1578
2024-05-22 16:25:24 [INFO]: Epoch 044 - generator training loss: 0.0540, discriminator training loss: 0.0277, validation loss: 0.1571
2024-05-22 16:25:28 [INFO]: Epoch 045 - generator training loss: 0.0532, discriminator training loss: 0.0274, validation loss: 0.1565
2024-05-22 16:25:32 [INFO]: Epoch 046 - generator training loss: 0.0536, discriminator training loss: 0.0268, validation loss: 0.1559
2024-05-22 16:25:36 [INFO]: Epoch 047 - generator training loss: 0.0523, discriminator training loss: 0.0262, validation loss: 0.1548
2024-05-22 16:25:40 [INFO]: Epoch 048 - generator training loss: 0.0526, discriminator training loss: 0.0262, validation loss: 0.1545
2024-05-22 16:25:44 [INFO]: Epoch 049 - generator training loss: 0.0521, discriminator training loss: 0.0255, validation loss: 0.1539
2024-05-22 16:25:48 [INFO]: Epoch 050 - generator training loss: 0.0512, discriminator training loss: 0.0250, validation loss: 0.1533
2024-05-22 16:25:52 [INFO]: Epoch 051 - generator training loss: 0.0508, discriminator training loss: 0.0248, validation loss: 0.1529
2024-05-22 16:25:56 [INFO]: Epoch 052 - generator training loss: 0.0508, discriminator training loss: 0.0243, validation loss: 0.1519
2024-05-22 16:26:00 [INFO]: Epoch 053 - generator training loss: 0.0501, discriminator training loss: 0.0240, validation loss: 0.1516
2024-05-22 16:26:04 [INFO]: Epoch 054 - generator training loss: 0.0496, discriminator training loss: 0.0236, validation loss: 0.1513
2024-05-22 16:26:09 [INFO]: Epoch 055 - generator training loss: 0.0497, discriminator training loss: 0.0232, validation loss: 0.1506
2024-05-22 16:26:13 [INFO]: Epoch 056 - generator training loss: 0.0492, discriminator training loss: 0.0230, validation loss: 0.1496
2024-05-22 16:26:17 [INFO]: Epoch 057 - generator training loss: 0.0489, discriminator training loss: 0.0229, validation loss: 0.1498
2024-05-22 16:26:21 [INFO]: Epoch 058 - generator training loss: 0.0487, discriminator training loss: 0.0225, validation loss: 0.1493
2024-05-22 16:26:25 [INFO]: Epoch 059 - generator training loss: 0.0486, discriminator training loss: 0.0222, validation loss: 0.1492
2024-05-22 16:26:29 [INFO]: Epoch 060 - generator training loss: 0.0493, discriminator training loss: 0.0219, validation loss: 0.1484
2024-05-22 16:26:33 [INFO]: Epoch 061 - generator training loss: 0.0473, discriminator training loss: 0.0216, validation loss: 0.1478
2024-05-22 16:26:37 [INFO]: Epoch 062 - generator training loss: 0.0482, discriminator training loss: 0.0212, validation loss: 0.1479
2024-05-22 16:26:41 [INFO]: Epoch 063 - generator training loss: 0.0478, discriminator training loss: 0.0209, validation loss: 0.1469
2024-05-22 16:26:45 [INFO]: Epoch 064 - generator training loss: 0.0467, discriminator training loss: 0.0208, validation loss: 0.1465
2024-05-22 16:26:49 [INFO]: Epoch 065 - generator training loss: 0.0467, discriminator training loss: 0.0205, validation loss: 0.1467
2024-05-22 16:26:53 [INFO]: Epoch 066 - generator training loss: 0.0466, discriminator training loss: 0.0202, validation loss: 0.1464
2024-05-22 16:26:57 [INFO]: Epoch 067 - generator training loss: 0.0458, discriminator training loss: 0.0202, validation loss: 0.1460
2024-05-22 16:27:01 [INFO]: Epoch 068 - generator training loss: 0.0460, discriminator training loss: 0.0197, validation loss: 0.1459
2024-05-22 16:27:05 [INFO]: Epoch 069 - generator training loss: 0.0451, discriminator training loss: 0.0198, validation loss: 0.1456
2024-05-22 16:27:09 [INFO]: Epoch 070 - generator training loss: 0.0451, discriminator training loss: 0.0195, validation loss: 0.1448
2024-05-22 16:27:13 [INFO]: Epoch 071 - generator training loss: 0.0452, discriminator training loss: 0.0192, validation loss: 0.1446
2024-05-22 16:27:17 [INFO]: Epoch 072 - generator training loss: 0.0449, discriminator training loss: 0.0191, validation loss: 0.1452
2024-05-22 16:27:21 [INFO]: Epoch 073 - generator training loss: 0.0448, discriminator training loss: 0.0189, validation loss: 0.1442
2024-05-22 16:27:25 [INFO]: Epoch 074 - generator training loss: 0.0443, discriminator training loss: 0.0186, validation loss: 0.1436
2024-05-22 16:27:29 [INFO]: Epoch 075 - generator training loss: 0.0445, discriminator training loss: 0.0183, validation loss: 0.1436
2024-05-22 16:27:33 [INFO]: Epoch 076 - generator training loss: 0.0440, discriminator training loss: 0.0184, validation loss: 0.1437
2024-05-22 16:27:37 [INFO]: Epoch 077 - generator training loss: 0.0437, discriminator training loss: 0.0179, validation loss: 0.1438
2024-05-22 16:27:41 [INFO]: Epoch 078 - generator training loss: 0.0445, discriminator training loss: 0.0181, validation loss: 0.1433
2024-05-22 16:27:45 [INFO]: Epoch 079 - generator training loss: 0.0435, discriminator training loss: 0.0176, validation loss: 0.1432
2024-05-22 16:27:49 [INFO]: Epoch 080 - generator training loss: 0.0438, discriminator training loss: 0.0178, validation loss: 0.1424
2024-05-22 16:27:53 [INFO]: Epoch 081 - generator training loss: 0.0425, discriminator training loss: 0.0175, validation loss: 0.1423
2024-05-22 16:27:57 [INFO]: Epoch 082 - generator training loss: 0.0428, discriminator training loss: 0.0176, validation loss: 0.1426
2024-05-22 16:28:01 [INFO]: Epoch 083 - generator training loss: 0.0424, discriminator training loss: 0.0172, validation loss: 0.1422
2024-05-22 16:28:05 [INFO]: Epoch 084 - generator training loss: 0.0421, discriminator training loss: 0.0171, validation loss: 0.1421
2024-05-22 16:28:09 [INFO]: Epoch 085 - generator training loss: 0.0423, discriminator training loss: 0.0170, validation loss: 0.1412
2024-05-22 16:28:13 [INFO]: Epoch 086 - generator training loss: 0.0427, discriminator training loss: 0.0167, validation loss: 0.1416
2024-05-22 16:28:18 [INFO]: Epoch 087 - generator training loss: 0.0415, discriminator training loss: 0.0167, validation loss: 0.1403
2024-05-22 16:28:22 [INFO]: Epoch 088 - generator training loss: 0.0409, discriminator training loss: 0.0167, validation loss: 0.1395
2024-05-22 16:28:26 [INFO]: Epoch 089 - generator training loss: 0.0407, discriminator training loss: 0.0166, validation loss: 0.1403
2024-05-22 16:28:30 [INFO]: Epoch 090 - generator training loss: 0.0410, discriminator training loss: 0.0165, validation loss: 0.1386
2024-05-22 16:28:34 [INFO]: Epoch 091 - generator training loss: 0.0399, discriminator training loss: 0.0165, validation loss: 0.1396
2024-05-22 16:28:38 [INFO]: Epoch 092 - generator training loss: 0.0391, discriminator training loss: 0.0163, validation loss: 0.1388
2024-05-22 16:28:42 [INFO]: Epoch 093 - generator training loss: 0.0390, discriminator training loss: 0.0159, validation loss: 0.1386
2024-05-22 16:28:46 [INFO]: Epoch 094 - generator training loss: 0.0388, discriminator training loss: 0.0161, validation loss: 0.1381
2024-05-22 16:28:50 [INFO]: Epoch 095 - generator training loss: 0.0383, discriminator training loss: 0.0161, validation loss: 0.1384
2024-05-22 16:28:54 [INFO]: Epoch 096 - generator training loss: 0.0386, discriminator training loss: 0.0158, validation loss: 0.1385
2024-05-22 16:28:58 [INFO]: Epoch 097 - generator training loss: 0.0386, discriminator training loss: 0.0156, validation loss: 0.1381
2024-05-22 16:29:02 [INFO]: Epoch 098 - generator training loss: 0.0381, discriminator training loss: 0.0156, validation loss: 0.1388
2024-05-22 16:29:06 [INFO]: Epoch 099 - generator training loss: 0.0380, discriminator training loss: 0.0157, validation loss: 0.1384
2024-05-22 16:29:10 [INFO]: Epoch 100 - generator training loss: 0.0378, discriminator training loss: 0.0156, validation loss: 0.1378
2024-05-22 16:29:14 [INFO]: Epoch 101 - generator training loss: 0.0372, discriminator training loss: 0.0155, validation loss: 0.1380
2024-05-22 16:29:18 [INFO]: Epoch 102 - generator training loss: 0.0401, discriminator training loss: 0.0152, validation loss: 0.1375
2024-05-22 16:29:22 [INFO]: Epoch 103 - generator training loss: 0.0392, discriminator training loss: 0.0153, validation loss: 0.1385
2024-05-22 16:29:26 [INFO]: Epoch 104 - generator training loss: 0.0381, discriminator training loss: 0.0155, validation loss: 0.1371
2024-05-22 16:29:30 [INFO]: Epoch 105 - generator training loss: 0.0390, discriminator training loss: 0.0151, validation loss: 0.1391
2024-05-22 16:29:34 [INFO]: Epoch 106 - generator training loss: 0.0370, discriminator training loss: 0.0153, validation loss: 0.1374
2024-05-22 16:29:38 [INFO]: Epoch 107 - generator training loss: 0.0367, discriminator training loss: 0.0149, validation loss: 0.1374
2024-05-22 16:29:42 [INFO]: Epoch 108 - generator training loss: 0.0359, discriminator training loss: 0.0150, validation loss: 0.1377
2024-05-22 16:29:46 [INFO]: Epoch 109 - generator training loss: 0.0360, discriminator training loss: 0.0149, validation loss: 0.1373
2024-05-22 16:29:50 [INFO]: Epoch 110 - generator training loss: 0.0355, discriminator training loss: 0.0148, validation loss: 0.1372
2024-05-22 16:29:54 [INFO]: Epoch 111 - generator training loss: 0.0357, discriminator training loss: 0.0147, validation loss: 0.1364
2024-05-22 16:29:58 [INFO]: Epoch 112 - generator training loss: 0.0357, discriminator training loss: 0.0146, validation loss: 0.1366
2024-05-22 16:30:02 [INFO]: Epoch 113 - generator training loss: 0.0353, discriminator training loss: 0.0145, validation loss: 0.1369
2024-05-22 16:30:06 [INFO]: Epoch 114 - generator training loss: 0.0348, discriminator training loss: 0.0144, validation loss: 0.1366
2024-05-22 16:30:10 [INFO]: Epoch 115 - generator training loss: 0.0351, discriminator training loss: 0.0141, validation loss: 0.1365
2024-05-22 16:30:14 [INFO]: Epoch 116 - generator training loss: 0.0341, discriminator training loss: 0.0141, validation loss: 0.1369
2024-05-22 16:30:18 [INFO]: Epoch 117 - generator training loss: 0.0343, discriminator training loss: 0.0142, validation loss: 0.1370
2024-05-22 16:30:22 [INFO]: Epoch 118 - generator training loss: 0.0349, discriminator training loss: 0.0143, validation loss: 0.1358
2024-05-22 16:30:26 [INFO]: Epoch 119 - generator training loss: 0.0339, discriminator training loss: 0.0143, validation loss: 0.1362
2024-05-22 16:30:30 [INFO]: Epoch 120 - generator training loss: 0.0337, discriminator training loss: 0.0142, validation loss: 0.1361
2024-05-22 16:30:34 [INFO]: Epoch 121 - generator training loss: 0.0339, discriminator training loss: 0.0140, validation loss: 0.1370
2024-05-22 16:30:38 [INFO]: Epoch 122 - generator training loss: 0.0335, discriminator training loss: 0.0136, validation loss: 0.1364
2024-05-22 16:30:42 [INFO]: Epoch 123 - generator training loss: 0.0333, discriminator training loss: 0.0137, validation loss: 0.1373
2024-05-22 16:30:46 [INFO]: Epoch 124 - generator training loss: 0.0343, discriminator training loss: 0.0136, validation loss: 0.1362
2024-05-22 16:30:50 [INFO]: Epoch 125 - generator training loss: 0.0336, discriminator training loss: 0.0137, validation loss: 0.1367
2024-05-22 16:30:54 [INFO]: Epoch 126 - generator training loss: 0.0329, discriminator training loss: 0.0137, validation loss: 0.1366
2024-05-22 16:30:58 [INFO]: Epoch 127 - generator training loss: 0.0330, discriminator training loss: 0.0136, validation loss: 0.1369
2024-05-22 16:31:03 [INFO]: Epoch 128 - generator training loss: 0.0325, discriminator training loss: 0.0135, validation loss: 0.1370
2024-05-22 16:31:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:31:03 [INFO]: Finished training. The best model is from epoch#118.
2024-05-22 16:31:03 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_air_quality/20240522_T162226/USGAN.pypots
2024-05-22 16:31:03 [INFO]: US-GAN on Air-Quality: MAE=0.1742, MSE=0.1278
2024-05-22 16:31:03 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-22 16:31:03 [INFO]: Using the given device: cuda:0
2024-05-22 16:31:03 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240522_T163103
2024-05-22 16:31:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_air_quality/20240522_T163103/tensorboard
2024-05-22 16:31:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-22 16:31:07 [INFO]: Epoch 001 - training loss: 1.4119, validation loss: 0.9331
2024-05-22 16:31:10 [INFO]: Epoch 002 - training loss: 1.1314, validation loss: 0.6976
2024-05-22 16:31:12 [INFO]: Epoch 003 - training loss: 0.9467, validation loss: 0.5907
2024-05-22 16:31:15 [INFO]: Epoch 004 - training loss: 0.8361, validation loss: 0.5208
2024-05-22 16:31:18 [INFO]: Epoch 005 - training loss: 0.7612, validation loss: 0.4760
2024-05-22 16:31:21 [INFO]: Epoch 006 - training loss: 0.7041, validation loss: 0.4372
2024-05-22 16:31:23 [INFO]: Epoch 007 - training loss: 0.6616, validation loss: 0.4081
2024-05-22 16:31:26 [INFO]: Epoch 008 - training loss: 0.6226, validation loss: 0.3852
2024-05-22 16:31:29 [INFO]: Epoch 009 - training loss: 0.5969, validation loss: 0.3657
2024-05-22 16:31:31 [INFO]: Epoch 010 - training loss: 0.5758, validation loss: 0.3497
2024-05-22 16:31:34 [INFO]: Epoch 011 - training loss: 0.5589, validation loss: 0.3364
2024-05-22 16:31:37 [INFO]: Epoch 012 - training loss: 0.5416, validation loss: 0.3257
2024-05-22 16:31:40 [INFO]: Epoch 013 - training loss: 0.5285, validation loss: 0.3164
2024-05-22 16:31:42 [INFO]: Epoch 014 - training loss: 0.5172, validation loss: 0.3078
2024-05-22 16:31:45 [INFO]: Epoch 015 - training loss: 0.5060, validation loss: 0.3005
2024-05-22 16:31:48 [INFO]: Epoch 016 - training loss: 0.4961, validation loss: 0.2940
2024-05-22 16:31:51 [INFO]: Epoch 017 - training loss: 0.4873, validation loss: 0.2879
2024-05-22 16:31:53 [INFO]: Epoch 018 - training loss: 0.4794, validation loss: 0.2827
2024-05-22 16:31:56 [INFO]: Epoch 019 - training loss: 0.4720, validation loss: 0.2779
2024-05-22 16:31:59 [INFO]: Epoch 020 - training loss: 0.4658, validation loss: 0.2732
2024-05-22 16:32:01 [INFO]: Epoch 021 - training loss: 0.4570, validation loss: 0.2691
2024-05-22 16:32:04 [INFO]: Epoch 022 - training loss: 0.4509, validation loss: 0.2650
2024-05-22 16:32:07 [INFO]: Epoch 023 - training loss: 0.4442, validation loss: 0.2611
2024-05-22 16:32:10 [INFO]: Epoch 024 - training loss: 0.4394, validation loss: 0.2573
2024-05-22 16:32:12 [INFO]: Epoch 025 - training loss: 0.4335, validation loss: 0.2539
2024-05-22 16:32:15 [INFO]: Epoch 026 - training loss: 0.4270, validation loss: 0.2504
2024-05-22 16:32:18 [INFO]: Epoch 027 - training loss: 0.4218, validation loss: 0.2472
2024-05-22 16:32:21 [INFO]: Epoch 028 - training loss: 0.4171, validation loss: 0.2441
2024-05-22 16:32:23 [INFO]: Epoch 029 - training loss: 0.4119, validation loss: 0.2406
2024-05-22 16:32:26 [INFO]: Epoch 030 - training loss: 0.4072, validation loss: 0.2379
2024-05-22 16:32:29 [INFO]: Epoch 031 - training loss: 0.4017, validation loss: 0.2349
2024-05-22 16:32:31 [INFO]: Epoch 032 - training loss: 0.3977, validation loss: 0.2320
2024-05-22 16:32:34 [INFO]: Epoch 033 - training loss: 0.3934, validation loss: 0.2293
2024-05-22 16:32:37 [INFO]: Epoch 034 - training loss: 0.3900, validation loss: 0.2271
2024-05-22 16:32:40 [INFO]: Epoch 035 - training loss: 0.3849, validation loss: 0.2241
2024-05-22 16:32:42 [INFO]: Epoch 036 - training loss: 0.3816, validation loss: 0.2217
2024-05-22 16:32:45 [INFO]: Epoch 037 - training loss: 0.3777, validation loss: 0.2192
2024-05-22 16:32:48 [INFO]: Epoch 038 - training loss: 0.3743, validation loss: 0.2168
2024-05-22 16:32:51 [INFO]: Epoch 039 - training loss: 0.3711, validation loss: 0.2149
2024-05-22 16:32:53 [INFO]: Epoch 040 - training loss: 0.3674, validation loss: 0.2120
2024-05-22 16:32:56 [INFO]: Epoch 041 - training loss: 0.3639, validation loss: 0.2105
2024-05-22 16:32:59 [INFO]: Epoch 042 - training loss: 0.3609, validation loss: 0.2077
2024-05-22 16:33:02 [INFO]: Epoch 043 - training loss: 0.3582, validation loss: 0.2056
2024-05-22 16:33:04 [INFO]: Epoch 044 - training loss: 0.3550, validation loss: 0.2037
2024-05-22 16:33:07 [INFO]: Epoch 045 - training loss: 0.3523, validation loss: 0.2017
2024-05-22 16:33:10 [INFO]: Epoch 046 - training loss: 0.3493, validation loss: 0.2000
2024-05-22 16:33:13 [INFO]: Epoch 047 - training loss: 0.3469, validation loss: 0.1983
2024-05-22 16:33:15 [INFO]: Epoch 048 - training loss: 0.3445, validation loss: 0.1965
2024-05-22 16:33:18 [INFO]: Epoch 049 - training loss: 0.3423, validation loss: 0.1947
2024-05-22 16:33:21 [INFO]: Epoch 050 - training loss: 0.3396, validation loss: 0.1931
2024-05-22 16:33:23 [INFO]: Epoch 051 - training loss: 0.3370, validation loss: 0.1918
2024-05-22 16:33:26 [INFO]: Epoch 052 - training loss: 0.3342, validation loss: 0.1904
2024-05-22 16:33:29 [INFO]: Epoch 053 - training loss: 0.3326, validation loss: 0.1890
2024-05-22 16:33:32 [INFO]: Epoch 054 - training loss: 0.3308, validation loss: 0.1878
2024-05-22 16:33:34 [INFO]: Epoch 055 - training loss: 0.3295, validation loss: 0.1869
2024-05-22 16:33:37 [INFO]: Epoch 056 - training loss: 0.3259, validation loss: 0.1857
2024-05-22 16:33:40 [INFO]: Epoch 057 - training loss: 0.3244, validation loss: 0.1848
2024-05-22 16:33:43 [INFO]: Epoch 058 - training loss: 0.3232, validation loss: 0.1838
2024-05-22 16:33:45 [INFO]: Epoch 059 - training loss: 0.3205, validation loss: 0.1831
2024-05-22 16:33:48 [INFO]: Epoch 060 - training loss: 0.3193, validation loss: 0.1822
2024-05-22 16:33:51 [INFO]: Epoch 061 - training loss: 0.3171, validation loss: 0.1815
2024-05-22 16:33:54 [INFO]: Epoch 062 - training loss: 0.3158, validation loss: 0.1807
2024-05-22 16:33:56 [INFO]: Epoch 063 - training loss: 0.3140, validation loss: 0.1802
2024-05-22 16:33:59 [INFO]: Epoch 064 - training loss: 0.3138, validation loss: 0.1796
2024-05-22 16:34:02 [INFO]: Epoch 065 - training loss: 0.3113, validation loss: 0.1791
2024-05-22 16:34:04 [INFO]: Epoch 066 - training loss: 0.3096, validation loss: 0.1787
2024-05-22 16:34:07 [INFO]: Epoch 067 - training loss: 0.3085, validation loss: 0.1779
2024-05-22 16:34:10 [INFO]: Epoch 068 - training loss: 0.3082, validation loss: 0.1773
2024-05-22 16:34:13 [INFO]: Epoch 069 - training loss: 0.3058, validation loss: 0.1769
2024-05-22 16:34:15 [INFO]: Epoch 070 - training loss: 0.3044, validation loss: 0.1762
2024-05-22 16:34:18 [INFO]: Epoch 071 - training loss: 0.3030, validation loss: 0.1760
2024-05-22 16:34:21 [INFO]: Epoch 072 - training loss: 0.3018, validation loss: 0.1753
2024-05-22 16:34:24 [INFO]: Epoch 073 - training loss: 0.3009, validation loss: 0.1751
2024-05-22 16:34:26 [INFO]: Epoch 074 - training loss: 0.3005, validation loss: 0.1744
2024-05-22 16:34:29 [INFO]: Epoch 075 - training loss: 0.2994, validation loss: 0.1737
2024-05-22 16:34:32 [INFO]: Epoch 076 - training loss: 0.2978, validation loss: 0.1735
2024-05-22 16:34:35 [INFO]: Epoch 077 - training loss: 0.2971, validation loss: 0.1731
2024-05-22 16:34:37 [INFO]: Epoch 078 - training loss: 0.2953, validation loss: 0.1727
2024-05-22 16:34:40 [INFO]: Epoch 079 - training loss: 0.2955, validation loss: 0.1722
2024-05-22 16:34:43 [INFO]: Epoch 080 - training loss: 0.2941, validation loss: 0.1720
2024-05-22 16:34:45 [INFO]: Epoch 081 - training loss: 0.2935, validation loss: 0.1714
2024-05-22 16:34:48 [INFO]: Epoch 082 - training loss: 0.2921, validation loss: 0.1711
2024-05-22 16:34:51 [INFO]: Epoch 083 - training loss: 0.2915, validation loss: 0.1707
2024-05-22 16:34:54 [INFO]: Epoch 084 - training loss: 0.2902, validation loss: 0.1701
2024-05-22 16:34:56 [INFO]: Epoch 085 - training loss: 0.2902, validation loss: 0.1697
2024-05-22 16:34:59 [INFO]: Epoch 086 - training loss: 0.2899, validation loss: 0.1695
2024-05-22 16:35:02 [INFO]: Epoch 087 - training loss: 0.2876, validation loss: 0.1687
2024-05-22 16:35:05 [INFO]: Epoch 088 - training loss: 0.2867, validation loss: 0.1686
2024-05-22 16:35:07 [INFO]: Epoch 089 - training loss: 0.2871, validation loss: 0.1681
2024-05-22 16:35:10 [INFO]: Epoch 090 - training loss: 0.2856, validation loss: 0.1678
2024-05-22 16:35:13 [INFO]: Epoch 091 - training loss: 0.2854, validation loss: 0.1675
2024-05-22 16:35:16 [INFO]: Epoch 092 - training loss: 0.2843, validation loss: 0.1669
2024-05-22 16:35:18 [INFO]: Epoch 093 - training loss: 0.2827, validation loss: 0.1665
2024-05-22 16:35:21 [INFO]: Epoch 094 - training loss: 0.2830, validation loss: 0.1662
2024-05-22 16:35:24 [INFO]: Epoch 095 - training loss: 0.2822, validation loss: 0.1658
2024-05-22 16:35:26 [INFO]: Epoch 096 - training loss: 0.2813, validation loss: 0.1655
2024-05-22 16:35:29 [INFO]: Epoch 097 - training loss: 0.2808, validation loss: 0.1652
2024-05-22 16:35:32 [INFO]: Epoch 098 - training loss: 0.2798, validation loss: 0.1648
2024-05-22 16:35:35 [INFO]: Epoch 099 - training loss: 0.2791, validation loss: 0.1643
2024-05-22 16:35:37 [INFO]: Epoch 100 - training loss: 0.2782, validation loss: 0.1641
2024-05-22 16:35:40 [INFO]: Epoch 101 - training loss: 0.2785, validation loss: 0.1635
2024-05-22 16:35:43 [INFO]: Epoch 102 - training loss: 0.2775, validation loss: 0.1633
2024-05-22 16:35:46 [INFO]: Epoch 103 - training loss: 0.2771, validation loss: 0.1628
2024-05-22 16:35:48 [INFO]: Epoch 104 - training loss: 0.2756, validation loss: 0.1626
2024-05-22 16:35:51 [INFO]: Epoch 105 - training loss: 0.2752, validation loss: 0.1620
2024-05-22 16:35:54 [INFO]: Epoch 106 - training loss: 0.2744, validation loss: 0.1617
2024-05-22 16:35:57 [INFO]: Epoch 107 - training loss: 0.2740, validation loss: 0.1613
2024-05-22 16:35:59 [INFO]: Epoch 108 - training loss: 0.2741, validation loss: 0.1608
2024-05-22 16:36:02 [INFO]: Epoch 109 - training loss: 0.2734, validation loss: 0.1603
2024-05-22 16:36:05 [INFO]: Epoch 110 - training loss: 0.2724, validation loss: 0.1602
2024-05-22 16:36:07 [INFO]: Epoch 111 - training loss: 0.2716, validation loss: 0.1598
2024-05-22 16:36:10 [INFO]: Epoch 112 - training loss: 0.2720, validation loss: 0.1594
2024-05-22 16:36:13 [INFO]: Epoch 113 - training loss: 0.2709, validation loss: 0.1592
2024-05-22 16:36:16 [INFO]: Epoch 114 - training loss: 0.2705, validation loss: 0.1589
2024-05-22 16:36:18 [INFO]: Epoch 115 - training loss: 0.2702, validation loss: 0.1584
2024-05-22 16:36:21 [INFO]: Epoch 116 - training loss: 0.2693, validation loss: 0.1580
2024-05-22 16:36:24 [INFO]: Epoch 117 - training loss: 0.2693, validation loss: 0.1577
2024-05-22 16:36:27 [INFO]: Epoch 118 - training loss: 0.2684, validation loss: 0.1573
2024-05-22 16:36:29 [INFO]: Epoch 119 - training loss: 0.2677, validation loss: 0.1569
2024-05-22 16:36:32 [INFO]: Epoch 120 - training loss: 0.2672, validation loss: 0.1567
2024-05-22 16:36:35 [INFO]: Epoch 121 - training loss: 0.2676, validation loss: 0.1563
2024-05-22 16:36:37 [INFO]: Epoch 122 - training loss: 0.2664, validation loss: 0.1558
2024-05-22 16:36:40 [INFO]: Epoch 123 - training loss: 0.2664, validation loss: 0.1556
2024-05-22 16:36:43 [INFO]: Epoch 124 - training loss: 0.2659, validation loss: 0.1552
2024-05-22 16:36:46 [INFO]: Epoch 125 - training loss: 0.2649, validation loss: 0.1549
2024-05-22 16:36:48 [INFO]: Epoch 126 - training loss: 0.2654, validation loss: 0.1544
2024-05-22 16:36:51 [INFO]: Epoch 127 - training loss: 0.2643, validation loss: 0.1541
2024-05-22 16:36:54 [INFO]: Epoch 128 - training loss: 0.2637, validation loss: 0.1539
2024-05-22 16:36:57 [INFO]: Epoch 129 - training loss: 0.2639, validation loss: 0.1534
2024-05-22 16:36:59 [INFO]: Epoch 130 - training loss: 0.2635, validation loss: 0.1531
2024-05-22 16:37:02 [INFO]: Epoch 131 - training loss: 0.2625, validation loss: 0.1528
2024-05-22 16:37:05 [INFO]: Epoch 132 - training loss: 0.2626, validation loss: 0.1525
2024-05-22 16:37:08 [INFO]: Epoch 133 - training loss: 0.2617, validation loss: 0.1523
2024-05-22 16:37:10 [INFO]: Epoch 134 - training loss: 0.2611, validation loss: 0.1522
2024-05-22 16:37:13 [INFO]: Epoch 135 - training loss: 0.2613, validation loss: 0.1517
2024-05-22 16:37:16 [INFO]: Epoch 136 - training loss: 0.2600, validation loss: 0.1513
2024-05-22 16:37:19 [INFO]: Epoch 137 - training loss: 0.2601, validation loss: 0.1508
2024-05-22 16:37:21 [INFO]: Epoch 138 - training loss: 0.2598, validation loss: 0.1507
2024-05-22 16:37:24 [INFO]: Epoch 139 - training loss: 0.2598, validation loss: 0.1504
2024-05-22 16:37:27 [INFO]: Epoch 140 - training loss: 0.2598, validation loss: 0.1500
2024-05-22 16:37:29 [INFO]: Epoch 141 - training loss: 0.2592, validation loss: 0.1498
2024-05-22 16:37:32 [INFO]: Epoch 142 - training loss: 0.2587, validation loss: 0.1495
2024-05-22 16:37:35 [INFO]: Epoch 143 - training loss: 0.2580, validation loss: 0.1493
2024-05-22 16:37:38 [INFO]: Epoch 144 - training loss: 0.2577, validation loss: 0.1488
2024-05-22 16:37:40 [INFO]: Epoch 145 - training loss: 0.2575, validation loss: 0.1486
2024-05-22 16:37:43 [INFO]: Epoch 146 - training loss: 0.2572, validation loss: 0.1484
2024-05-22 16:37:46 [INFO]: Epoch 147 - training loss: 0.2561, validation loss: 0.1482
2024-05-22 16:37:49 [INFO]: Epoch 148 - training loss: 0.2564, validation loss: 0.1480
2024-05-22 16:37:51 [INFO]: Epoch 149 - training loss: 0.2557, validation loss: 0.1476
2024-05-22 16:37:54 [INFO]: Epoch 150 - training loss: 0.2560, validation loss: 0.1475
2024-05-22 16:37:57 [INFO]: Epoch 151 - training loss: 0.2558, validation loss: 0.1471
2024-05-22 16:37:59 [INFO]: Epoch 152 - training loss: 0.2555, validation loss: 0.1467
2024-05-22 16:38:02 [INFO]: Epoch 153 - training loss: 0.2546, validation loss: 0.1465
2024-05-22 16:38:05 [INFO]: Epoch 154 - training loss: 0.2541, validation loss: 0.1463
2024-05-22 16:38:08 [INFO]: Epoch 155 - training loss: 0.2540, validation loss: 0.1461
2024-05-22 16:38:10 [INFO]: Epoch 156 - training loss: 0.2536, validation loss: 0.1459
2024-05-22 16:38:13 [INFO]: Epoch 157 - training loss: 0.2535, validation loss: 0.1457
2024-05-22 16:38:16 [INFO]: Epoch 158 - training loss: 0.2532, validation loss: 0.1453
2024-05-22 16:38:19 [INFO]: Epoch 159 - training loss: 0.2523, validation loss: 0.1451
2024-05-22 16:38:21 [INFO]: Epoch 160 - training loss: 0.2526, validation loss: 0.1450
2024-05-22 16:38:24 [INFO]: Epoch 161 - training loss: 0.2525, validation loss: 0.1447
2024-05-22 16:38:27 [INFO]: Epoch 162 - training loss: 0.2523, validation loss: 0.1445
2024-05-22 16:38:30 [INFO]: Epoch 163 - training loss: 0.2514, validation loss: 0.1442
2024-05-22 16:38:32 [INFO]: Epoch 164 - training loss: 0.2519, validation loss: 0.1439
2024-05-22 16:38:35 [INFO]: Epoch 165 - training loss: 0.2514, validation loss: 0.1437
2024-05-22 16:38:38 [INFO]: Epoch 166 - training loss: 0.2507, validation loss: 0.1436
2024-05-22 16:38:40 [INFO]: Epoch 167 - training loss: 0.2503, validation loss: 0.1434
2024-05-22 16:38:43 [INFO]: Epoch 168 - training loss: 0.2503, validation loss: 0.1432
2024-05-22 16:38:46 [INFO]: Epoch 169 - training loss: 0.2502, validation loss: 0.1429
2024-05-22 16:38:49 [INFO]: Epoch 170 - training loss: 0.2500, validation loss: 0.1426
2024-05-22 16:38:51 [INFO]: Epoch 171 - training loss: 0.2494, validation loss: 0.1426
2024-05-22 16:38:54 [INFO]: Epoch 172 - training loss: 0.2492, validation loss: 0.1424
2024-05-22 16:38:57 [INFO]: Epoch 173 - training loss: 0.2487, validation loss: 0.1421
2024-05-22 16:39:00 [INFO]: Epoch 174 - training loss: 0.2485, validation loss: 0.1419
2024-05-22 16:39:02 [INFO]: Epoch 175 - training loss: 0.2485, validation loss: 0.1418
2024-05-22 16:39:05 [INFO]: Epoch 176 - training loss: 0.2488, validation loss: 0.1416
2024-05-22 16:39:08 [INFO]: Epoch 177 - training loss: 0.2478, validation loss: 0.1414
2024-05-22 16:39:11 [INFO]: Epoch 178 - training loss: 0.2474, validation loss: 0.1410
2024-05-22 16:39:13 [INFO]: Epoch 179 - training loss: 0.2475, validation loss: 0.1410
2024-05-22 16:39:16 [INFO]: Epoch 180 - training loss: 0.2471, validation loss: 0.1407
2024-05-22 16:39:19 [INFO]: Epoch 181 - training loss: 0.2472, validation loss: 0.1407
2024-05-22 16:39:22 [INFO]: Epoch 182 - training loss: 0.2471, validation loss: 0.1403
2024-05-22 16:39:24 [INFO]: Epoch 183 - training loss: 0.2464, validation loss: 0.1403
2024-05-22 16:39:27 [INFO]: Epoch 184 - training loss: 0.2463, validation loss: 0.1402
2024-05-22 16:39:30 [INFO]: Epoch 185 - training loss: 0.2468, validation loss: 0.1401
2024-05-22 16:39:32 [INFO]: Epoch 186 - training loss: 0.2457, validation loss: 0.1399
2024-05-22 16:39:35 [INFO]: Epoch 187 - training loss: 0.2457, validation loss: 0.1395
2024-05-22 16:39:38 [INFO]: Epoch 188 - training loss: 0.2459, validation loss: 0.1395
2024-05-22 16:39:41 [INFO]: Epoch 189 - training loss: 0.2454, validation loss: 0.1393
2024-05-22 16:39:43 [INFO]: Epoch 190 - training loss: 0.2451, validation loss: 0.1392
2024-05-22 16:39:46 [INFO]: Epoch 191 - training loss: 0.2446, validation loss: 0.1391
2024-05-22 16:39:49 [INFO]: Epoch 192 - training loss: 0.2449, validation loss: 0.1388
2024-05-22 16:39:52 [INFO]: Epoch 193 - training loss: 0.2445, validation loss: 0.1386
2024-05-22 16:39:54 [INFO]: Epoch 194 - training loss: 0.2440, validation loss: 0.1386
2024-05-22 16:39:57 [INFO]: Epoch 195 - training loss: 0.2443, validation loss: 0.1382
2024-05-22 16:40:00 [INFO]: Epoch 196 - training loss: 0.2439, validation loss: 0.1382
2024-05-22 16:40:02 [INFO]: Epoch 197 - training loss: 0.2432, validation loss: 0.1378
2024-05-22 16:40:05 [INFO]: Epoch 198 - training loss: 0.2435, validation loss: 0.1378
2024-05-22 16:40:08 [INFO]: Epoch 199 - training loss: 0.2442, validation loss: 0.1378
2024-05-22 16:40:11 [INFO]: Epoch 200 - training loss: 0.2432, validation loss: 0.1375
2024-05-22 16:40:13 [INFO]: Epoch 201 - training loss: 0.2428, validation loss: 0.1375
2024-05-22 16:40:16 [INFO]: Epoch 202 - training loss: 0.2427, validation loss: 0.1372
2024-05-22 16:40:19 [INFO]: Epoch 203 - training loss: 0.2423, validation loss: 0.1371
2024-05-22 16:40:22 [INFO]: Epoch 204 - training loss: 0.2426, validation loss: 0.1369
2024-05-22 16:40:24 [INFO]: Epoch 205 - training loss: 0.2424, validation loss: 0.1369
2024-05-22 16:40:27 [INFO]: Epoch 206 - training loss: 0.2422, validation loss: 0.1367
2024-05-22 16:40:30 [INFO]: Epoch 207 - training loss: 0.2418, validation loss: 0.1366
2024-05-22 16:40:33 [INFO]: Epoch 208 - training loss: 0.2414, validation loss: 0.1365
2024-05-22 16:40:35 [INFO]: Epoch 209 - training loss: 0.2413, validation loss: 0.1363
2024-05-22 16:40:38 [INFO]: Epoch 210 - training loss: 0.2416, validation loss: 0.1362
2024-05-22 16:40:41 [INFO]: Epoch 211 - training loss: 0.2417, validation loss: 0.1362
2024-05-22 16:40:43 [INFO]: Epoch 212 - training loss: 0.2410, validation loss: 0.1359
2024-05-22 16:40:46 [INFO]: Epoch 213 - training loss: 0.2407, validation loss: 0.1358
2024-05-22 16:40:49 [INFO]: Epoch 214 - training loss: 0.2405, validation loss: 0.1358
2024-05-22 16:40:52 [INFO]: Epoch 215 - training loss: 0.2406, validation loss: 0.1355
2024-05-22 16:40:54 [INFO]: Epoch 216 - training loss: 0.2400, validation loss: 0.1355
2024-05-22 16:40:57 [INFO]: Epoch 217 - training loss: 0.2400, validation loss: 0.1353
2024-05-22 16:41:00 [INFO]: Epoch 218 - training loss: 0.2397, validation loss: 0.1353
2024-05-22 16:41:03 [INFO]: Epoch 219 - training loss: 0.2390, validation loss: 0.1353
2024-05-22 16:41:05 [INFO]: Epoch 220 - training loss: 0.2393, validation loss: 0.1349
2024-05-22 16:41:08 [INFO]: Epoch 221 - training loss: 0.2392, validation loss: 0.1349
2024-05-22 16:41:11 [INFO]: Epoch 222 - training loss: 0.2388, validation loss: 0.1346
2024-05-22 16:41:14 [INFO]: Epoch 223 - training loss: 0.2392, validation loss: 0.1347
2024-05-22 16:41:16 [INFO]: Epoch 224 - training loss: 0.2391, validation loss: 0.1346
2024-05-22 16:41:19 [INFO]: Epoch 225 - training loss: 0.2384, validation loss: 0.1343
2024-05-22 16:41:22 [INFO]: Epoch 226 - training loss: 0.2385, validation loss: 0.1342
2024-05-22 16:41:25 [INFO]: Epoch 227 - training loss: 0.2380, validation loss: 0.1340
2024-05-22 16:41:27 [INFO]: Epoch 228 - training loss: 0.2381, validation loss: 0.1340
2024-05-22 16:41:30 [INFO]: Epoch 229 - training loss: 0.2376, validation loss: 0.1340
2024-05-22 16:41:33 [INFO]: Epoch 230 - training loss: 0.2377, validation loss: 0.1339
2024-05-22 16:41:35 [INFO]: Epoch 231 - training loss: 0.2378, validation loss: 0.1336
2024-05-22 16:41:38 [INFO]: Epoch 232 - training loss: 0.2374, validation loss: 0.1335
2024-05-22 16:41:41 [INFO]: Epoch 233 - training loss: 0.2367, validation loss: 0.1334
2024-05-22 16:41:44 [INFO]: Epoch 234 - training loss: 0.2371, validation loss: 0.1335
2024-05-22 16:41:46 [INFO]: Epoch 235 - training loss: 0.2368, validation loss: 0.1333
2024-05-22 16:41:49 [INFO]: Epoch 236 - training loss: 0.2370, validation loss: 0.1332
2024-05-22 16:41:52 [INFO]: Epoch 237 - training loss: 0.2372, validation loss: 0.1332
2024-05-22 16:41:55 [INFO]: Epoch 238 - training loss: 0.2367, validation loss: 0.1331
2024-05-22 16:41:57 [INFO]: Epoch 239 - training loss: 0.2363, validation loss: 0.1328
2024-05-22 16:42:00 [INFO]: Epoch 240 - training loss: 0.2366, validation loss: 0.1328
2024-05-22 16:42:03 [INFO]: Epoch 241 - training loss: 0.2362, validation loss: 0.1328
2024-05-22 16:42:05 [INFO]: Epoch 242 - training loss: 0.2360, validation loss: 0.1325
2024-05-22 16:42:08 [INFO]: Epoch 243 - training loss: 0.2360, validation loss: 0.1324
2024-05-22 16:42:11 [INFO]: Epoch 244 - training loss: 0.2358, validation loss: 0.1325
2024-05-22 16:42:14 [INFO]: Epoch 245 - training loss: 0.2352, validation loss: 0.1323
2024-05-22 16:42:16 [INFO]: Epoch 246 - training loss: 0.2353, validation loss: 0.1323
2024-05-22 16:42:19 [INFO]: Epoch 247 - training loss: 0.2354, validation loss: 0.1321
2024-05-22 16:42:22 [INFO]: Epoch 248 - training loss: 0.2354, validation loss: 0.1321
2024-05-22 16:42:25 [INFO]: Epoch 249 - training loss: 0.2355, validation loss: 0.1320
2024-05-22 16:42:27 [INFO]: Epoch 250 - training loss: 0.2351, validation loss: 0.1318
2024-05-22 16:42:30 [INFO]: Epoch 251 - training loss: 0.2346, validation loss: 0.1317
2024-05-22 16:42:33 [INFO]: Epoch 252 - training loss: 0.2345, validation loss: 0.1319
2024-05-22 16:42:36 [INFO]: Epoch 253 - training loss: 0.2341, validation loss: 0.1315
2024-05-22 16:42:38 [INFO]: Epoch 254 - training loss: 0.2343, validation loss: 0.1317
2024-05-22 16:42:41 [INFO]: Epoch 255 - training loss: 0.2339, validation loss: 0.1313
2024-05-22 16:42:44 [INFO]: Epoch 256 - training loss: 0.2338, validation loss: 0.1313
2024-05-22 16:42:46 [INFO]: Epoch 257 - training loss: 0.2339, validation loss: 0.1313
2024-05-22 16:42:49 [INFO]: Epoch 258 - training loss: 0.2339, validation loss: 0.1311
2024-05-22 16:42:52 [INFO]: Epoch 259 - training loss: 0.2333, validation loss: 0.1312
2024-05-22 16:42:55 [INFO]: Epoch 260 - training loss: 0.2332, validation loss: 0.1311
2024-05-22 16:42:57 [INFO]: Epoch 261 - training loss: 0.2333, validation loss: 0.1309
2024-05-22 16:43:00 [INFO]: Epoch 262 - training loss: 0.2329, validation loss: 0.1308
2024-05-22 16:43:03 [INFO]: Epoch 263 - training loss: 0.2328, validation loss: 0.1309
2024-05-22 16:43:06 [INFO]: Epoch 264 - training loss: 0.2335, validation loss: 0.1307
2024-05-22 16:43:08 [INFO]: Epoch 265 - training loss: 0.2329, validation loss: 0.1307
2024-05-22 16:43:11 [INFO]: Epoch 266 - training loss: 0.2332, validation loss: 0.1306
2024-05-22 16:43:14 [INFO]: Epoch 267 - training loss: 0.2324, validation loss: 0.1304
2024-05-22 16:43:17 [INFO]: Epoch 268 - training loss: 0.2325, validation loss: 0.1303
2024-05-22 16:43:19 [INFO]: Epoch 269 - training loss: 0.2319, validation loss: 0.1305
2024-05-22 16:43:22 [INFO]: Epoch 270 - training loss: 0.2321, validation loss: 0.1305
2024-05-22 16:43:25 [INFO]: Epoch 271 - training loss: 0.2322, validation loss: 0.1301
2024-05-22 16:43:28 [INFO]: Epoch 272 - training loss: 0.2316, validation loss: 0.1300
2024-05-22 16:43:30 [INFO]: Epoch 273 - training loss: 0.2316, validation loss: 0.1300
2024-05-22 16:43:33 [INFO]: Epoch 274 - training loss: 0.2322, validation loss: 0.1301
2024-05-22 16:43:36 [INFO]: Epoch 275 - training loss: 0.2316, validation loss: 0.1300
2024-05-22 16:43:38 [INFO]: Epoch 276 - training loss: 0.2315, validation loss: 0.1298
2024-05-22 16:43:41 [INFO]: Epoch 277 - training loss: 0.2316, validation loss: 0.1298
2024-05-22 16:43:44 [INFO]: Epoch 278 - training loss: 0.2310, validation loss: 0.1299
2024-05-22 16:43:47 [INFO]: Epoch 279 - training loss: 0.2311, validation loss: 0.1300
2024-05-22 16:43:49 [INFO]: Epoch 280 - training loss: 0.2313, validation loss: 0.1297
2024-05-22 16:43:52 [INFO]: Epoch 281 - training loss: 0.2312, validation loss: 0.1296
2024-05-22 16:43:55 [INFO]: Epoch 282 - training loss: 0.2309, validation loss: 0.1295
2024-05-22 16:43:58 [INFO]: Epoch 283 - training loss: 0.2308, validation loss: 0.1296
2024-05-22 16:44:00 [INFO]: Epoch 284 - training loss: 0.2306, validation loss: 0.1294
2024-05-22 16:44:03 [INFO]: Epoch 285 - training loss: 0.2305, validation loss: 0.1293
2024-05-22 16:44:06 [INFO]: Epoch 286 - training loss: 0.2305, validation loss: 0.1293
2024-05-22 16:44:09 [INFO]: Epoch 287 - training loss: 0.2303, validation loss: 0.1293
2024-05-22 16:44:11 [INFO]: Epoch 288 - training loss: 0.2302, validation loss: 0.1292
2024-05-22 16:44:14 [INFO]: Epoch 289 - training loss: 0.2301, validation loss: 0.1291
2024-05-22 16:44:17 [INFO]: Epoch 290 - training loss: 0.2303, validation loss: 0.1292
2024-05-22 16:44:19 [INFO]: Epoch 291 - training loss: 0.2299, validation loss: 0.1290
2024-05-22 16:44:22 [INFO]: Epoch 292 - training loss: 0.2300, validation loss: 0.1291
2024-05-22 16:44:25 [INFO]: Epoch 293 - training loss: 0.2303, validation loss: 0.1289
2024-05-22 16:44:28 [INFO]: Epoch 294 - training loss: 0.2298, validation loss: 0.1288
2024-05-22 16:44:30 [INFO]: Epoch 295 - training loss: 0.2299, validation loss: 0.1290
2024-05-22 16:44:33 [INFO]: Epoch 296 - training loss: 0.2293, validation loss: 0.1287
2024-05-22 16:44:36 [INFO]: Epoch 297 - training loss: 0.2295, validation loss: 0.1288
2024-05-22 16:44:39 [INFO]: Epoch 298 - training loss: 0.2290, validation loss: 0.1287
2024-05-22 16:44:41 [INFO]: Epoch 299 - training loss: 0.2289, validation loss: 0.1287
2024-05-22 16:44:44 [INFO]: Epoch 300 - training loss: 0.2290, validation loss: 0.1287
2024-05-22 16:44:44 [INFO]: Finished training. The best model is from epoch#298.
2024-05-22 16:44:45 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_air_quality/20240522_T163103/BRITS.pypots
2024-05-22 16:44:46 [INFO]: BRITS on Air-Quality: MAE=0.1424, MSE=0.1153
2024-05-22 16:44:46 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-22 16:44:46 [INFO]: Using the given device: cuda:0
2024-05-22 16:44:46 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446
2024-05-22 16:44:46 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/tensorboard
2024-05-22 16:44:46 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-22 16:44:50 [INFO]: Epoch 001 - training loss: 1.4996, validation loss: 0.8048
2024-05-22 16:44:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch1_loss0.8048463106155396.pypots
2024-05-22 16:44:54 [INFO]: Epoch 002 - training loss: 1.0633, validation loss: 0.7477
2024-05-22 16:44:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch2_loss0.7477400571107864.pypots
2024-05-22 16:44:58 [INFO]: Epoch 003 - training loss: 0.9931, validation loss: 0.7268
2024-05-22 16:44:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch3_loss0.7268065512180328.pypots
2024-05-22 16:45:02 [INFO]: Epoch 004 - training loss: 0.9710, validation loss: 0.7147
2024-05-22 16:45:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch4_loss0.7146848380565644.pypots
2024-05-22 16:45:06 [INFO]: Epoch 005 - training loss: 0.9593, validation loss: 0.7062
2024-05-22 16:45:06 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch5_loss0.706191149353981.pypots
2024-05-22 16:45:09 [INFO]: Epoch 006 - training loss: 0.9399, validation loss: 0.7003
2024-05-22 16:45:09 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch6_loss0.7002859055995941.pypots
2024-05-22 16:45:13 [INFO]: Epoch 007 - training loss: 0.9352, validation loss: 0.6949
2024-05-22 16:45:13 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch7_loss0.6949338555335999.pypots
2024-05-22 16:45:17 [INFO]: Epoch 008 - training loss: 0.9364, validation loss: 0.6908
2024-05-22 16:45:17 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch8_loss0.6907566249370575.pypots
2024-05-22 16:45:21 [INFO]: Epoch 009 - training loss: 0.9352, validation loss: 0.6884
2024-05-22 16:45:21 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch9_loss0.6884491533041001.pypots
2024-05-22 16:45:25 [INFO]: Epoch 010 - training loss: 0.9277, validation loss: 0.6859
2024-05-22 16:45:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch10_loss0.6858651489019394.pypots
2024-05-22 16:45:28 [INFO]: Epoch 011 - training loss: 0.9190, validation loss: 0.6835
2024-05-22 16:45:29 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch11_loss0.6835213214159012.pypots
2024-05-22 16:45:33 [INFO]: Epoch 012 - training loss: 0.9141, validation loss: 0.6822
2024-05-22 16:45:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch12_loss0.682210186123848.pypots
2024-05-22 16:45:37 [INFO]: Epoch 013 - training loss: 0.9003, validation loss: 0.6819
2024-05-22 16:45:37 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch13_loss0.6818680763244629.pypots
2024-05-22 16:45:41 [INFO]: Epoch 014 - training loss: 0.9081, validation loss: 0.6804
2024-05-22 16:45:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch14_loss0.6804377287626266.pypots
2024-05-22 16:45:44 [INFO]: Epoch 015 - training loss: 0.8942, validation loss: 0.6804
2024-05-22 16:45:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch15_loss0.6803508281707764.pypots
2024-05-22 16:45:48 [INFO]: Epoch 016 - training loss: 0.9044, validation loss: 0.6791
2024-05-22 16:45:48 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch16_loss0.6791172802448273.pypots
2024-05-22 16:45:52 [INFO]: Epoch 017 - training loss: 0.8981, validation loss: 0.6787
2024-05-22 16:45:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch17_loss0.6787056863307953.pypots
2024-05-22 16:45:56 [INFO]: Epoch 018 - training loss: 0.8857, validation loss: 0.6789
2024-05-22 16:45:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch18_loss0.6788857728242874.pypots
2024-05-22 16:45:59 [INFO]: Epoch 019 - training loss: 0.9059, validation loss: 0.6787
2024-05-22 16:45:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch19_loss0.6786682099103928.pypots
2024-05-22 16:46:03 [INFO]: Epoch 020 - training loss: 0.8894, validation loss: 0.6800
2024-05-22 16:46:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch20_loss0.6799751251935959.pypots
2024-05-22 16:46:07 [INFO]: Epoch 021 - training loss: 0.8860, validation loss: 0.6800
2024-05-22 16:46:07 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch21_loss0.679985323548317.pypots
2024-05-22 16:46:11 [INFO]: Epoch 022 - training loss: 0.8688, validation loss: 0.6805
2024-05-22 16:46:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch22_loss0.6804956823587418.pypots
2024-05-22 16:46:15 [INFO]: Epoch 023 - training loss: 0.8841, validation loss: 0.6803
2024-05-22 16:46:15 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch23_loss0.6803477674722671.pypots
2024-05-22 16:46:18 [INFO]: Epoch 024 - training loss: 0.8746, validation loss: 0.6800
2024-05-22 16:46:18 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch24_loss0.6799830496311188.pypots
2024-05-22 16:46:22 [INFO]: Epoch 025 - training loss: 0.8910, validation loss: 0.6803
2024-05-22 16:46:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch25_loss0.6802509933710098.pypots
2024-05-22 16:46:26 [INFO]: Epoch 026 - training loss: 0.8862, validation loss: 0.6821
2024-05-22 16:46:26 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch26_loss0.6820737838745117.pypots
2024-05-22 16:46:30 [INFO]: Epoch 027 - training loss: 0.8758, validation loss: 0.6811
2024-05-22 16:46:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch27_loss0.6810826122760772.pypots
2024-05-22 16:46:33 [INFO]: Epoch 028 - training loss: 0.8637, validation loss: 0.6832
2024-05-22 16:46:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch28_loss0.6831762462854385.pypots
2024-05-22 16:46:37 [INFO]: Epoch 029 - training loss: 0.8633, validation loss: 0.6810
2024-05-22 16:46:37 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN_epoch29_loss0.6810176074504852.pypots
2024-05-22 16:46:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:46:37 [INFO]: Finished training. The best model is from epoch#19.
2024-05-22 16:46:37 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_air_quality/20240522_T164446/MRNN.pypots
2024-05-22 16:46:38 [INFO]: MRNN on Air-Quality: MAE=0.5220, MSE=0.6203
2024-05-22 16:46:38 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-22 16:46:38 [INFO]: Using the given device: cpu
2024-05-22 16:46:38 [INFO]: LOCF on Air-Quality: MAE=0.2063, MSE=0.2445
2024-05-22 16:46:38 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-22 16:46:38 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-22 16:46:38 [INFO]: Median on Air-Quality: MAE=0.6676, MSE=1.0184
2024-05-22 16:46:38 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-22 16:46:38 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-22 16:46:38 [INFO]: Mean on Air-Quality: MAE=0.6965, MSE=0.9535
2024-05-22 16:46:38 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-22 16:46:38 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-22 16:46:38 [INFO]: 
SAITS on data/air_quality: MAE=0.147±0.0027902268540865617, MSE=0.119±0.0035835746432725723
Transformer on data/air_quality: MAE=0.159±0.00274382465199844, MSE=0.130±0.0028260210906760684
TimesNet on data/air_quality: MAE=0.163±0.003976297595126789, MSE=0.165±0.00280572193802439
CSDI on data/air_quality: MAE=0.108±0.004230105572538601, MSE=0.182±0.04921832210903968
GPVAE on data/air_quality: MAE=0.282±0.008187146519854627, MSE=0.247±0.01304993589476899
USGAN on data/air_quality: MAE=0.174±0.0025563316310899943, MSE=0.125±0.0035786375154929643
BRITS on data/air_quality: MAE=0.143±0.00019712658897714022, MSE=0.115±0.0008338946914493876
MRNN on data/air_quality: MAE=0.524±0.0014029516774556425, MSE=0.624±0.002529854450601976
LOCF on data/air_quality: MAE=0.206±2.7755575615628914e-17, MSE=0.244±2.7755575615628914e-17
Median on data/air_quality: MAE=0.668±0.0, MSE=1.018±0.0
Mean on data/air_quality: MAE=0.697±0.0, MSE=0.954±0.0

