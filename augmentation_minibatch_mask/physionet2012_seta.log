2024-05-23 17:39:41 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-23 17:39:41 [INFO]: Using the given device: cuda:0
2024-05-23 17:39:42 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T173942
2024-05-23 17:39:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T173942/tensorboard
2024-05-23 17:39:42 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 17:39:44 [INFO]: Epoch 001 - training loss: 1.0743, validation loss: 0.4992
2024-05-23 17:39:45 [INFO]: Epoch 002 - training loss: 0.7874, validation loss: 0.4293
2024-05-23 17:39:46 [INFO]: Epoch 003 - training loss: 0.6070, validation loss: 0.4022
2024-05-23 17:39:47 [INFO]: Epoch 004 - training loss: 0.5305, validation loss: 0.3901
2024-05-23 17:39:49 [INFO]: Epoch 005 - training loss: 0.4848, validation loss: 0.3726
2024-05-23 17:39:50 [INFO]: Epoch 006 - training loss: 0.4510, validation loss: 0.3638
2024-05-23 17:39:51 [INFO]: Epoch 007 - training loss: 0.4328, validation loss: 0.3460
2024-05-23 17:39:53 [INFO]: Epoch 008 - training loss: 0.4154, validation loss: 0.3398
2024-05-23 17:39:54 [INFO]: Epoch 009 - training loss: 0.4042, validation loss: 0.3323
2024-05-23 17:39:55 [INFO]: Epoch 010 - training loss: 0.3834, validation loss: 0.3233
2024-05-23 17:39:56 [INFO]: Epoch 011 - training loss: 0.3747, validation loss: 0.3141
2024-05-23 17:39:58 [INFO]: Epoch 012 - training loss: 0.3606, validation loss: 0.3124
2024-05-23 17:39:59 [INFO]: Epoch 013 - training loss: 0.3516, validation loss: 0.3046
2024-05-23 17:40:00 [INFO]: Epoch 014 - training loss: 0.3415, validation loss: 0.2970
2024-05-23 17:40:02 [INFO]: Epoch 015 - training loss: 0.3356, validation loss: 0.2929
2024-05-23 17:40:03 [INFO]: Epoch 016 - training loss: 0.3310, validation loss: 0.2913
2024-05-23 17:40:04 [INFO]: Epoch 017 - training loss: 0.3249, validation loss: 0.2863
2024-05-23 17:40:05 [INFO]: Epoch 018 - training loss: 0.3222, validation loss: 0.2852
2024-05-23 17:40:07 [INFO]: Epoch 019 - training loss: 0.3190, validation loss: 0.2808
2024-05-23 17:40:08 [INFO]: Epoch 020 - training loss: 0.3092, validation loss: 0.2783
2024-05-23 17:40:09 [INFO]: Epoch 021 - training loss: 0.3064, validation loss: 0.2810
2024-05-23 17:40:11 [INFO]: Epoch 022 - training loss: 0.3078, validation loss: 0.2760
2024-05-23 17:40:12 [INFO]: Epoch 023 - training loss: 0.3001, validation loss: 0.2780
2024-05-23 17:40:13 [INFO]: Epoch 024 - training loss: 0.3017, validation loss: 0.2713
2024-05-23 17:40:14 [INFO]: Epoch 025 - training loss: 0.2994, validation loss: 0.2700
2024-05-23 17:40:16 [INFO]: Epoch 026 - training loss: 0.2940, validation loss: 0.2717
2024-05-23 17:40:17 [INFO]: Epoch 027 - training loss: 0.2902, validation loss: 0.2693
2024-05-23 17:40:18 [INFO]: Epoch 028 - training loss: 0.2918, validation loss: 0.2658
2024-05-23 17:40:20 [INFO]: Epoch 029 - training loss: 0.2871, validation loss: 0.2653
2024-05-23 17:40:21 [INFO]: Epoch 030 - training loss: 0.2860, validation loss: 0.2603
2024-05-23 17:40:22 [INFO]: Epoch 031 - training loss: 0.2863, validation loss: 0.2655
2024-05-23 17:40:23 [INFO]: Epoch 032 - training loss: 0.2873, validation loss: 0.2607
2024-05-23 17:40:25 [INFO]: Epoch 033 - training loss: 0.2786, validation loss: 0.2613
2024-05-23 17:40:26 [INFO]: Epoch 034 - training loss: 0.2806, validation loss: 0.2624
2024-05-23 17:40:27 [INFO]: Epoch 035 - training loss: 0.2804, validation loss: 0.2650
2024-05-23 17:40:29 [INFO]: Epoch 036 - training loss: 0.2786, validation loss: 0.2589
2024-05-23 17:40:30 [INFO]: Epoch 037 - training loss: 0.2776, validation loss: 0.2562
2024-05-23 17:40:31 [INFO]: Epoch 038 - training loss: 0.2787, validation loss: 0.2627
2024-05-23 17:40:32 [INFO]: Epoch 039 - training loss: 0.2737, validation loss: 0.2567
2024-05-23 17:40:34 [INFO]: Epoch 040 - training loss: 0.2718, validation loss: 0.2593
2024-05-23 17:40:35 [INFO]: Epoch 041 - training loss: 0.2702, validation loss: 0.2567
2024-05-23 17:40:36 [INFO]: Epoch 042 - training loss: 0.2723, validation loss: 0.2558
2024-05-23 17:40:38 [INFO]: Epoch 043 - training loss: 0.2695, validation loss: 0.2537
2024-05-23 17:40:39 [INFO]: Epoch 044 - training loss: 0.2664, validation loss: 0.2529
2024-05-23 17:40:40 [INFO]: Epoch 045 - training loss: 0.2677, validation loss: 0.2558
2024-05-23 17:40:41 [INFO]: Epoch 046 - training loss: 0.2671, validation loss: 0.2538
2024-05-23 17:40:43 [INFO]: Epoch 047 - training loss: 0.2663, validation loss: 0.2536
2024-05-23 17:40:44 [INFO]: Epoch 048 - training loss: 0.2661, validation loss: 0.2569
2024-05-23 17:40:45 [INFO]: Epoch 049 - training loss: 0.2639, validation loss: 0.2572
2024-05-23 17:40:47 [INFO]: Epoch 050 - training loss: 0.2655, validation loss: 0.2559
2024-05-23 17:40:48 [INFO]: Epoch 051 - training loss: 0.2614, validation loss: 0.2546
2024-05-23 17:40:49 [INFO]: Epoch 052 - training loss: 0.2625, validation loss: 0.2579
2024-05-23 17:40:50 [INFO]: Epoch 053 - training loss: 0.2643, validation loss: 0.2502
2024-05-23 17:40:52 [INFO]: Epoch 054 - training loss: 0.2618, validation loss: 0.2510
2024-05-23 17:40:53 [INFO]: Epoch 055 - training loss: 0.2613, validation loss: 0.2500
2024-05-23 17:40:54 [INFO]: Epoch 056 - training loss: 0.2606, validation loss: 0.2531
2024-05-23 17:40:56 [INFO]: Epoch 057 - training loss: 0.2570, validation loss: 0.2492
2024-05-23 17:40:57 [INFO]: Epoch 058 - training loss: 0.2610, validation loss: 0.2486
2024-05-23 17:40:58 [INFO]: Epoch 059 - training loss: 0.2573, validation loss: 0.2510
2024-05-23 17:41:00 [INFO]: Epoch 060 - training loss: 0.2573, validation loss: 0.2545
2024-05-23 17:41:01 [INFO]: Epoch 061 - training loss: 0.2588, validation loss: 0.2529
2024-05-23 17:41:02 [INFO]: Epoch 062 - training loss: 0.2581, validation loss: 0.2509
2024-05-23 17:41:03 [INFO]: Epoch 063 - training loss: 0.2542, validation loss: 0.2543
2024-05-23 17:41:05 [INFO]: Epoch 064 - training loss: 0.2552, validation loss: 0.2488
2024-05-23 17:41:06 [INFO]: Epoch 065 - training loss: 0.2524, validation loss: 0.2500
2024-05-23 17:41:07 [INFO]: Epoch 066 - training loss: 0.2532, validation loss: 0.2479
2024-05-23 17:41:09 [INFO]: Epoch 067 - training loss: 0.2532, validation loss: 0.2536
2024-05-23 17:41:10 [INFO]: Epoch 068 - training loss: 0.2517, validation loss: 0.2527
2024-05-23 17:41:11 [INFO]: Epoch 069 - training loss: 0.2535, validation loss: 0.2495
2024-05-23 17:41:13 [INFO]: Epoch 070 - training loss: 0.2520, validation loss: 0.2713
2024-05-23 17:41:14 [INFO]: Epoch 071 - training loss: 0.2504, validation loss: 0.2505
2024-05-23 17:41:15 [INFO]: Epoch 072 - training loss: 0.2511, validation loss: 0.2493
2024-05-23 17:41:16 [INFO]: Epoch 073 - training loss: 0.2495, validation loss: 0.2480
2024-05-23 17:41:18 [INFO]: Epoch 074 - training loss: 0.2495, validation loss: 0.2537
2024-05-23 17:41:19 [INFO]: Epoch 075 - training loss: 0.2480, validation loss: 0.2489
2024-05-23 17:41:20 [INFO]: Epoch 076 - training loss: 0.2489, validation loss: 0.2513
2024-05-23 17:41:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:41:20 [INFO]: Finished training. The best model is from epoch#66.
2024-05-23 17:41:21 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T173942/SAITS.pypots
2024-05-23 17:41:21 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2131, MSE=0.2689
2024-05-23 17:41:21 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 17:41:21 [INFO]: Using the given device: cuda:0
2024-05-23 17:41:21 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T174121
2024-05-23 17:41:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T174121/tensorboard
2024-05-23 17:41:21 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 17:41:22 [INFO]: Epoch 001 - training loss: 1.1749, validation loss: 0.5924
2024-05-23 17:41:22 [INFO]: Epoch 002 - training loss: 0.7471, validation loss: 0.4801
2024-05-23 17:41:23 [INFO]: Epoch 003 - training loss: 0.6364, validation loss: 0.4513
2024-05-23 17:41:24 [INFO]: Epoch 004 - training loss: 0.5861, validation loss: 0.4372
2024-05-23 17:41:25 [INFO]: Epoch 005 - training loss: 0.5471, validation loss: 0.4231
2024-05-23 17:41:25 [INFO]: Epoch 006 - training loss: 0.5199, validation loss: 0.4141
2024-05-23 17:41:26 [INFO]: Epoch 007 - training loss: 0.4948, validation loss: 0.4036
2024-05-23 17:41:27 [INFO]: Epoch 008 - training loss: 0.4737, validation loss: 0.3886
2024-05-23 17:41:27 [INFO]: Epoch 009 - training loss: 0.4588, validation loss: 0.3967
2024-05-23 17:41:28 [INFO]: Epoch 010 - training loss: 0.4504, validation loss: 0.3785
2024-05-23 17:41:29 [INFO]: Epoch 011 - training loss: 0.4372, validation loss: 0.3751
2024-05-23 17:41:30 [INFO]: Epoch 012 - training loss: 0.4277, validation loss: 0.3679
2024-05-23 17:41:30 [INFO]: Epoch 013 - training loss: 0.4144, validation loss: 0.3564
2024-05-23 17:41:31 [INFO]: Epoch 014 - training loss: 0.4100, validation loss: 0.3525
2024-05-23 17:41:32 [INFO]: Epoch 015 - training loss: 0.4020, validation loss: 0.3502
2024-05-23 17:41:32 [INFO]: Epoch 016 - training loss: 0.3951, validation loss: 0.3502
2024-05-23 17:41:33 [INFO]: Epoch 017 - training loss: 0.3821, validation loss: 0.3449
2024-05-23 17:41:34 [INFO]: Epoch 018 - training loss: 0.3886, validation loss: 0.3368
2024-05-23 17:41:35 [INFO]: Epoch 019 - training loss: 0.3728, validation loss: 0.3310
2024-05-23 17:41:35 [INFO]: Epoch 020 - training loss: 0.3695, validation loss: 0.3315
2024-05-23 17:41:36 [INFO]: Epoch 021 - training loss: 0.3632, validation loss: 0.3324
2024-05-23 17:41:37 [INFO]: Epoch 022 - training loss: 0.3612, validation loss: 0.3277
2024-05-23 17:41:37 [INFO]: Epoch 023 - training loss: 0.3522, validation loss: 0.3239
2024-05-23 17:41:38 [INFO]: Epoch 024 - training loss: 0.3525, validation loss: 0.3192
2024-05-23 17:41:39 [INFO]: Epoch 025 - training loss: 0.3490, validation loss: 0.3175
2024-05-23 17:41:40 [INFO]: Epoch 026 - training loss: 0.3467, validation loss: 0.3169
2024-05-23 17:41:40 [INFO]: Epoch 027 - training loss: 0.3431, validation loss: 0.3158
2024-05-23 17:41:41 [INFO]: Epoch 028 - training loss: 0.3415, validation loss: 0.3106
2024-05-23 17:41:42 [INFO]: Epoch 029 - training loss: 0.3368, validation loss: 0.3124
2024-05-23 17:41:42 [INFO]: Epoch 030 - training loss: 0.3355, validation loss: 0.3106
2024-05-23 17:41:43 [INFO]: Epoch 031 - training loss: 0.3333, validation loss: 0.3095
2024-05-23 17:41:44 [INFO]: Epoch 032 - training loss: 0.3302, validation loss: 0.3064
2024-05-23 17:41:45 [INFO]: Epoch 033 - training loss: 0.3312, validation loss: 0.3074
2024-05-23 17:41:45 [INFO]: Epoch 034 - training loss: 0.3270, validation loss: 0.3094
2024-05-23 17:41:46 [INFO]: Epoch 035 - training loss: 0.3260, validation loss: 0.3023
2024-05-23 17:41:47 [INFO]: Epoch 036 - training loss: 0.3241, validation loss: 0.3073
2024-05-23 17:41:47 [INFO]: Epoch 037 - training loss: 0.3195, validation loss: 0.3048
2024-05-23 17:41:48 [INFO]: Epoch 038 - training loss: 0.3208, validation loss: 0.3018
2024-05-23 17:41:49 [INFO]: Epoch 039 - training loss: 0.3174, validation loss: 0.2998
2024-05-23 17:41:50 [INFO]: Epoch 040 - training loss: 0.3178, validation loss: 0.2982
2024-05-23 17:41:50 [INFO]: Epoch 041 - training loss: 0.3129, validation loss: 0.2985
2024-05-23 17:41:51 [INFO]: Epoch 042 - training loss: 0.3154, validation loss: 0.2967
2024-05-23 17:41:52 [INFO]: Epoch 043 - training loss: 0.3139, validation loss: 0.2934
2024-05-23 17:41:52 [INFO]: Epoch 044 - training loss: 0.3108, validation loss: 0.2945
2024-05-23 17:41:53 [INFO]: Epoch 045 - training loss: 0.3132, validation loss: 0.2926
2024-05-23 17:41:54 [INFO]: Epoch 046 - training loss: 0.3100, validation loss: 0.2922
2024-05-23 17:41:55 [INFO]: Epoch 047 - training loss: 0.3055, validation loss: 0.2891
2024-05-23 17:41:55 [INFO]: Epoch 048 - training loss: 0.3067, validation loss: 0.2899
2024-05-23 17:41:56 [INFO]: Epoch 049 - training loss: 0.3033, validation loss: 0.2892
2024-05-23 17:41:57 [INFO]: Epoch 050 - training loss: 0.3025, validation loss: 0.2875
2024-05-23 17:41:57 [INFO]: Epoch 051 - training loss: 0.3054, validation loss: 0.2870
2024-05-23 17:41:58 [INFO]: Epoch 052 - training loss: 0.3019, validation loss: 0.2885
2024-05-23 17:41:59 [INFO]: Epoch 053 - training loss: 0.3000, validation loss: 0.2848
2024-05-23 17:42:00 [INFO]: Epoch 054 - training loss: 0.2992, validation loss: 0.2820
2024-05-23 17:42:00 [INFO]: Epoch 055 - training loss: 0.3002, validation loss: 0.2829
2024-05-23 17:42:01 [INFO]: Epoch 056 - training loss: 0.2955, validation loss: 0.2809
2024-05-23 17:42:02 [INFO]: Epoch 057 - training loss: 0.2956, validation loss: 0.2830
2024-05-23 17:42:03 [INFO]: Epoch 058 - training loss: 0.2981, validation loss: 0.2818
2024-05-23 17:42:03 [INFO]: Epoch 059 - training loss: 0.2959, validation loss: 0.2776
2024-05-23 17:42:04 [INFO]: Epoch 060 - training loss: 0.2986, validation loss: 0.2793
2024-05-23 17:42:05 [INFO]: Epoch 061 - training loss: 0.2967, validation loss: 0.2789
2024-05-23 17:42:05 [INFO]: Epoch 062 - training loss: 0.2927, validation loss: 0.2788
2024-05-23 17:42:06 [INFO]: Epoch 063 - training loss: 0.2934, validation loss: 0.2867
2024-05-23 17:42:07 [INFO]: Epoch 064 - training loss: 0.2937, validation loss: 0.2815
2024-05-23 17:42:08 [INFO]: Epoch 065 - training loss: 0.2929, validation loss: 0.2766
2024-05-23 17:42:08 [INFO]: Epoch 066 - training loss: 0.2915, validation loss: 0.2738
2024-05-23 17:42:09 [INFO]: Epoch 067 - training loss: 0.2910, validation loss: 0.2739
2024-05-23 17:42:10 [INFO]: Epoch 068 - training loss: 0.2880, validation loss: 0.2735
2024-05-23 17:42:10 [INFO]: Epoch 069 - training loss: 0.2896, validation loss: 0.2756
2024-05-23 17:42:11 [INFO]: Epoch 070 - training loss: 0.2889, validation loss: 0.2739
2024-05-23 17:42:12 [INFO]: Epoch 071 - training loss: 0.2864, validation loss: 0.2756
2024-05-23 17:42:13 [INFO]: Epoch 072 - training loss: 0.2857, validation loss: 0.2698
2024-05-23 17:42:13 [INFO]: Epoch 073 - training loss: 0.2834, validation loss: 0.2689
2024-05-23 17:42:14 [INFO]: Epoch 074 - training loss: 0.2829, validation loss: 0.2722
2024-05-23 17:42:15 [INFO]: Epoch 075 - training loss: 0.2829, validation loss: 0.2720
2024-05-23 17:42:15 [INFO]: Epoch 076 - training loss: 0.2827, validation loss: 0.2712
2024-05-23 17:42:16 [INFO]: Epoch 077 - training loss: 0.2810, validation loss: 0.2687
2024-05-23 17:42:17 [INFO]: Epoch 078 - training loss: 0.2815, validation loss: 0.2695
2024-05-23 17:42:18 [INFO]: Epoch 079 - training loss: 0.2819, validation loss: 0.2710
2024-05-23 17:42:18 [INFO]: Epoch 080 - training loss: 0.2806, validation loss: 0.2693
2024-05-23 17:42:19 [INFO]: Epoch 081 - training loss: 0.2813, validation loss: 0.2671
2024-05-23 17:42:20 [INFO]: Epoch 082 - training loss: 0.2789, validation loss: 0.2715
2024-05-23 17:42:20 [INFO]: Epoch 083 - training loss: 0.2804, validation loss: 0.2658
2024-05-23 17:42:21 [INFO]: Epoch 084 - training loss: 0.2748, validation loss: 0.2676
2024-05-23 17:42:22 [INFO]: Epoch 085 - training loss: 0.2765, validation loss: 0.2681
2024-05-23 17:42:23 [INFO]: Epoch 086 - training loss: 0.2790, validation loss: 0.2667
2024-05-23 17:42:23 [INFO]: Epoch 087 - training loss: 0.2738, validation loss: 0.2676
2024-05-23 17:42:24 [INFO]: Epoch 088 - training loss: 0.2753, validation loss: 0.2665
2024-05-23 17:42:25 [INFO]: Epoch 089 - training loss: 0.2747, validation loss: 0.2632
2024-05-23 17:42:25 [INFO]: Epoch 090 - training loss: 0.2750, validation loss: 0.2631
2024-05-23 17:42:26 [INFO]: Epoch 091 - training loss: 0.2747, validation loss: 0.2630
2024-05-23 17:42:27 [INFO]: Epoch 092 - training loss: 0.2758, validation loss: 0.2616
2024-05-23 17:42:28 [INFO]: Epoch 093 - training loss: 0.2726, validation loss: 0.2651
2024-05-23 17:42:28 [INFO]: Epoch 094 - training loss: 0.2740, validation loss: 0.2655
2024-05-23 17:42:29 [INFO]: Epoch 095 - training loss: 0.2739, validation loss: 0.2607
2024-05-23 17:42:30 [INFO]: Epoch 096 - training loss: 0.2725, validation loss: 0.2605
2024-05-23 17:42:31 [INFO]: Epoch 097 - training loss: 0.2724, validation loss: 0.2645
2024-05-23 17:42:31 [INFO]: Epoch 098 - training loss: 0.2712, validation loss: 0.2636
2024-05-23 17:42:32 [INFO]: Epoch 099 - training loss: 0.2704, validation loss: 0.2629
2024-05-23 17:42:33 [INFO]: Epoch 100 - training loss: 0.2700, validation loss: 0.2614
2024-05-23 17:42:34 [INFO]: Epoch 101 - training loss: 0.2684, validation loss: 0.2634
2024-05-23 17:42:34 [INFO]: Epoch 102 - training loss: 0.2700, validation loss: 0.2616
2024-05-23 17:42:35 [INFO]: Epoch 103 - training loss: 0.2685, validation loss: 0.2610
2024-05-23 17:42:36 [INFO]: Epoch 104 - training loss: 0.2698, validation loss: 0.2590
2024-05-23 17:42:37 [INFO]: Epoch 105 - training loss: 0.2679, validation loss: 0.2616
2024-05-23 17:42:38 [INFO]: Epoch 106 - training loss: 0.2675, validation loss: 0.2577
2024-05-23 17:42:38 [INFO]: Epoch 107 - training loss: 0.2680, validation loss: 0.2654
2024-05-23 17:42:39 [INFO]: Epoch 108 - training loss: 0.2680, validation loss: 0.2607
2024-05-23 17:42:40 [INFO]: Epoch 109 - training loss: 0.2694, validation loss: 0.2595
2024-05-23 17:42:41 [INFO]: Epoch 110 - training loss: 0.2645, validation loss: 0.2611
2024-05-23 17:42:42 [INFO]: Epoch 111 - training loss: 0.2675, validation loss: 0.2604
2024-05-23 17:42:43 [INFO]: Epoch 112 - training loss: 0.2640, validation loss: 0.2566
2024-05-23 17:42:44 [INFO]: Epoch 113 - training loss: 0.2652, validation loss: 0.2606
2024-05-23 17:42:45 [INFO]: Epoch 114 - training loss: 0.2620, validation loss: 0.2618
2024-05-23 17:42:45 [INFO]: Epoch 115 - training loss: 0.2629, validation loss: 0.2598
2024-05-23 17:42:46 [INFO]: Epoch 116 - training loss: 0.2662, validation loss: 0.2615
2024-05-23 17:42:47 [INFO]: Epoch 117 - training loss: 0.2636, validation loss: 0.2567
2024-05-23 17:42:48 [INFO]: Epoch 118 - training loss: 0.2651, validation loss: 0.2596
2024-05-23 17:42:49 [INFO]: Epoch 119 - training loss: 0.2636, validation loss: 0.2536
2024-05-23 17:42:49 [INFO]: Epoch 120 - training loss: 0.2652, validation loss: 0.2574
2024-05-23 17:42:50 [INFO]: Epoch 121 - training loss: 0.2672, validation loss: 0.2559
2024-05-23 17:42:51 [INFO]: Epoch 122 - training loss: 0.2631, validation loss: 0.2640
2024-05-23 17:42:52 [INFO]: Epoch 123 - training loss: 0.2608, validation loss: 0.2586
2024-05-23 17:42:52 [INFO]: Epoch 124 - training loss: 0.2637, validation loss: 0.2564
2024-05-23 17:42:53 [INFO]: Epoch 125 - training loss: 0.2617, validation loss: 0.2581
2024-05-23 17:42:54 [INFO]: Epoch 126 - training loss: 0.2608, validation loss: 0.2564
2024-05-23 17:42:54 [INFO]: Epoch 127 - training loss: 0.2610, validation loss: 0.2605
2024-05-23 17:42:55 [INFO]: Epoch 128 - training loss: 0.2595, validation loss: 0.2602
2024-05-23 17:42:56 [INFO]: Epoch 129 - training loss: 0.2617, validation loss: 0.2601
2024-05-23 17:42:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:42:56 [INFO]: Finished training. The best model is from epoch#119.
2024-05-23 17:42:56 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T174121/Transformer.pypots
2024-05-23 17:42:56 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2221, MSE=0.2792
2024-05-23 17:42:56 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 17:42:56 [INFO]: Using the given device: cuda:0
2024-05-23 17:42:56 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T174256
2024-05-23 17:42:56 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T174256/tensorboard
2024-05-23 17:42:56 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 17:42:58 [INFO]: Epoch 001 - training loss: 0.4514, validation loss: 1.1565
2024-05-23 17:42:58 [INFO]: Epoch 002 - training loss: 0.8641, validation loss: 0.7951
2024-05-23 17:42:59 [INFO]: Epoch 003 - training loss: 0.4399, validation loss: 0.6813
2024-05-23 17:43:00 [INFO]: Epoch 004 - training loss: 0.5636, validation loss: 0.5097
2024-05-23 17:43:01 [INFO]: Epoch 005 - training loss: 0.4117, validation loss: 0.3708
2024-05-23 17:43:02 [INFO]: Epoch 006 - training loss: 0.4012, validation loss: 0.3260
2024-05-23 17:43:03 [INFO]: Epoch 007 - training loss: 0.3759, validation loss: 0.3362
2024-05-23 17:43:03 [INFO]: Epoch 008 - training loss: 0.3391, validation loss: 0.3225
2024-05-23 17:43:04 [INFO]: Epoch 009 - training loss: 0.3388, validation loss: 0.3268
2024-05-23 17:43:05 [INFO]: Epoch 010 - training loss: 0.3794, validation loss: 0.3397
2024-05-23 17:43:06 [INFO]: Epoch 011 - training loss: 0.3272, validation loss: 0.3500
2024-05-23 17:43:07 [INFO]: Epoch 012 - training loss: 0.3175, validation loss: 0.3418
2024-05-23 17:43:08 [INFO]: Epoch 013 - training loss: 0.3145, validation loss: 0.3278
2024-05-23 17:43:09 [INFO]: Epoch 014 - training loss: 0.3235, validation loss: 0.3919
2024-05-23 17:43:10 [INFO]: Epoch 015 - training loss: 0.3184, validation loss: 0.4275
2024-05-23 17:43:10 [INFO]: Epoch 016 - training loss: 0.3337, validation loss: 0.3118
2024-05-23 17:43:11 [INFO]: Epoch 017 - training loss: 0.3317, validation loss: 0.3907
2024-05-23 17:43:12 [INFO]: Epoch 018 - training loss: 0.3494, validation loss: 0.2986
2024-05-23 17:43:13 [INFO]: Epoch 019 - training loss: 0.3373, validation loss: 0.3233
2024-05-23 17:43:14 [INFO]: Epoch 020 - training loss: 0.3179, validation loss: 0.2963
2024-05-23 17:43:15 [INFO]: Epoch 021 - training loss: 0.3054, validation loss: 0.3011
2024-05-23 17:43:16 [INFO]: Epoch 022 - training loss: 0.3144, validation loss: 0.2922
2024-05-23 17:43:17 [INFO]: Epoch 023 - training loss: 0.3185, validation loss: 0.3159
2024-05-23 17:43:17 [INFO]: Epoch 024 - training loss: 0.2906, validation loss: 0.3236
2024-05-23 17:43:18 [INFO]: Epoch 025 - training loss: 0.2963, validation loss: 0.3226
2024-05-23 17:43:19 [INFO]: Epoch 026 - training loss: 0.3088, validation loss: 0.4020
2024-05-23 17:43:20 [INFO]: Epoch 027 - training loss: 0.2806, validation loss: 0.3521
2024-05-23 17:43:21 [INFO]: Epoch 028 - training loss: 0.3007, validation loss: 0.3302
2024-05-23 17:43:22 [INFO]: Epoch 029 - training loss: 0.3188, validation loss: 0.2975
2024-05-23 17:43:23 [INFO]: Epoch 030 - training loss: 0.2988, validation loss: 0.2857
2024-05-23 17:43:24 [INFO]: Epoch 031 - training loss: 0.3036, validation loss: 0.3047
2024-05-23 17:43:24 [INFO]: Epoch 032 - training loss: 0.3013, validation loss: 0.4137
2024-05-23 17:43:25 [INFO]: Epoch 033 - training loss: 0.2967, validation loss: 0.3342
2024-05-23 17:43:26 [INFO]: Epoch 034 - training loss: 0.3112, validation loss: 0.3855
2024-05-23 17:43:27 [INFO]: Epoch 035 - training loss: 0.3226, validation loss: 0.2813
2024-05-23 17:43:28 [INFO]: Epoch 036 - training loss: 0.4051, validation loss: 0.2838
2024-05-23 17:43:29 [INFO]: Epoch 037 - training loss: 0.3444, validation loss: 0.3065
2024-05-23 17:43:30 [INFO]: Epoch 038 - training loss: 0.2830, validation loss: 0.2928
2024-05-23 17:43:31 [INFO]: Epoch 039 - training loss: 0.2824, validation loss: 0.2923
2024-05-23 17:43:32 [INFO]: Epoch 040 - training loss: 0.2851, validation loss: 0.2860
2024-05-23 17:43:32 [INFO]: Epoch 041 - training loss: 0.2890, validation loss: 0.2835
2024-05-23 17:43:33 [INFO]: Epoch 042 - training loss: 0.3091, validation loss: 0.3149
2024-05-23 17:43:34 [INFO]: Epoch 043 - training loss: 0.3214, validation loss: 0.3290
2024-05-23 17:43:35 [INFO]: Epoch 044 - training loss: 0.3108, validation loss: 0.2987
2024-05-23 17:43:36 [INFO]: Epoch 045 - training loss: 0.3089, validation loss: 0.2946
2024-05-23 17:43:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:43:36 [INFO]: Finished training. The best model is from epoch#35.
2024-05-23 17:43:36 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T174256/TimesNet.pypots
2024-05-23 17:43:36 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2775, MSE=0.3164
2024-05-23 17:43:36 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 17:43:36 [INFO]: Using the given device: cuda:0
2024-05-23 17:43:36 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336
2024-05-23 17:43:36 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/tensorboard
2024-05-23 17:43:36 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 17:44:20 [INFO]: Epoch 001 - training loss: 0.4169, validation loss: 0.3436
2024-05-23 17:44:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch1_loss0.34359412342309953.pypots
2024-05-23 17:45:04 [INFO]: Epoch 002 - training loss: 0.3347, validation loss: 0.3064
2024-05-23 17:45:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch2_loss0.3063539072871208.pypots
2024-05-23 17:45:49 [INFO]: Epoch 003 - training loss: 0.2954, validation loss: 0.2516
2024-05-23 17:45:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch3_loss0.25157018974423406.pypots
2024-05-23 17:46:33 [INFO]: Epoch 004 - training loss: 0.2718, validation loss: 0.2379
2024-05-23 17:46:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch4_loss0.23794105798006057.pypots
2024-05-23 17:47:17 [INFO]: Epoch 005 - training loss: 0.2558, validation loss: 0.2243
2024-05-23 17:47:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch5_loss0.2243056081235409.pypots
2024-05-23 17:48:01 [INFO]: Epoch 006 - training loss: 0.2366, validation loss: 0.2172
2024-05-23 17:48:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch6_loss0.21716892048716546.pypots
2024-05-23 17:48:45 [INFO]: Epoch 007 - training loss: 0.2556, validation loss: 0.2124
2024-05-23 17:48:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch7_loss0.21235558837652208.pypots
2024-05-23 17:49:29 [INFO]: Epoch 008 - training loss: 0.2573, validation loss: 0.2101
2024-05-23 17:49:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch8_loss0.21012174785137178.pypots
2024-05-23 17:50:13 [INFO]: Epoch 009 - training loss: 0.2424, validation loss: 0.2091
2024-05-23 17:50:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch9_loss0.20912332609295844.pypots
2024-05-23 17:50:58 [INFO]: Epoch 010 - training loss: 0.2453, validation loss: 0.2049
2024-05-23 17:50:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch10_loss0.20489214658737182.pypots
2024-05-23 17:51:42 [INFO]: Epoch 011 - training loss: 0.2476, validation loss: 0.2019
2024-05-23 17:51:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch11_loss0.20194066241383551.pypots
2024-05-23 17:52:26 [INFO]: Epoch 012 - training loss: 0.2581, validation loss: 0.1971
2024-05-23 17:52:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch12_loss0.19707854315638543.pypots
2024-05-23 17:53:10 [INFO]: Epoch 013 - training loss: 0.2311, validation loss: 0.1980
2024-05-23 17:53:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch13_loss0.19798558950424194.pypots
2024-05-23 17:53:53 [INFO]: Epoch 014 - training loss: 0.2354, validation loss: 0.1962
2024-05-23 17:53:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch14_loss0.196154897660017.pypots
2024-05-23 17:54:37 [INFO]: Epoch 015 - training loss: 0.2356, validation loss: 0.1965
2024-05-23 17:54:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch15_loss0.19646081998944281.pypots
2024-05-23 17:55:21 [INFO]: Epoch 016 - training loss: 0.2333, validation loss: 0.1945
2024-05-23 17:55:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch16_loss0.19447060003876687.pypots
2024-05-23 17:56:06 [INFO]: Epoch 017 - training loss: 0.2386, validation loss: 0.1969
2024-05-23 17:56:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch17_loss0.19686343967914582.pypots
2024-05-23 17:56:50 [INFO]: Epoch 018 - training loss: 0.2417, validation loss: 0.1948
2024-05-23 17:56:50 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch18_loss0.1948120467364788.pypots
2024-05-23 17:57:33 [INFO]: Epoch 019 - training loss: 0.2333, validation loss: 0.1908
2024-05-23 17:57:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch19_loss0.1908419370651245.pypots
2024-05-23 17:58:17 [INFO]: Epoch 020 - training loss: 0.2280, validation loss: 0.1932
2024-05-23 17:58:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch20_loss0.19315157756209372.pypots
2024-05-23 17:59:01 [INFO]: Epoch 021 - training loss: 0.2327, validation loss: 0.1906
2024-05-23 17:59:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch21_loss0.19058585166931152.pypots
2024-05-23 17:59:45 [INFO]: Epoch 022 - training loss: 0.2213, validation loss: 0.1891
2024-05-23 17:59:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch22_loss0.1890884444117546.pypots
2024-05-23 18:00:30 [INFO]: Epoch 023 - training loss: 0.2381, validation loss: 0.1893
2024-05-23 18:00:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch23_loss0.18932239189743996.pypots
2024-05-23 18:01:14 [INFO]: Epoch 024 - training loss: 0.2281, validation loss: 0.1894
2024-05-23 18:01:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch24_loss0.18938519731163977.pypots
2024-05-23 18:01:58 [INFO]: Epoch 025 - training loss: 0.2281, validation loss: 0.1881
2024-05-23 18:01:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch25_loss0.1881164327263832.pypots
2024-05-23 18:02:42 [INFO]: Epoch 026 - training loss: 0.2286, validation loss: 0.1886
2024-05-23 18:02:42 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch26_loss0.18858449012041092.pypots
2024-05-23 18:03:26 [INFO]: Epoch 027 - training loss: 0.2218, validation loss: 0.1857
2024-05-23 18:03:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch27_loss0.1857309803366661.pypots
2024-05-23 18:04:09 [INFO]: Epoch 028 - training loss: 0.2276, validation loss: 0.1870
2024-05-23 18:04:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch28_loss0.18700530156493186.pypots
2024-05-23 18:04:53 [INFO]: Epoch 029 - training loss: 0.2291, validation loss: 0.1849
2024-05-23 18:04:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch29_loss0.18486205488443375.pypots
2024-05-23 18:05:37 [INFO]: Epoch 030 - training loss: 0.2242, validation loss: 0.1879
2024-05-23 18:05:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch30_loss0.1879010908305645.pypots
2024-05-23 18:06:21 [INFO]: Epoch 031 - training loss: 0.2195, validation loss: 0.1858
2024-05-23 18:06:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch31_loss0.18584635928273202.pypots
2024-05-23 18:07:05 [INFO]: Epoch 032 - training loss: 0.2228, validation loss: 0.1874
2024-05-23 18:07:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch32_loss0.18738360181450844.pypots
2024-05-23 18:07:49 [INFO]: Epoch 033 - training loss: 0.2278, validation loss: 0.1861
2024-05-23 18:07:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch33_loss0.1860912635922432.pypots
2024-05-23 18:08:33 [INFO]: Epoch 034 - training loss: 0.2194, validation loss: 0.1837
2024-05-23 18:08:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch34_loss0.18374100774526597.pypots
2024-05-23 18:09:17 [INFO]: Epoch 035 - training loss: 0.2321, validation loss: 0.1832
2024-05-23 18:09:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch35_loss0.18323104158043862.pypots
2024-05-23 18:10:01 [INFO]: Epoch 036 - training loss: 0.2171, validation loss: 0.1833
2024-05-23 18:10:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch36_loss0.18329449668526648.pypots
2024-05-23 18:10:45 [INFO]: Epoch 037 - training loss: 0.2257, validation loss: 0.1843
2024-05-23 18:10:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch37_loss0.18433787897229195.pypots
2024-05-23 18:11:29 [INFO]: Epoch 038 - training loss: 0.2157, validation loss: 0.1852
2024-05-23 18:11:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch38_loss0.18515875190496445.pypots
2024-05-23 18:12:13 [INFO]: Epoch 039 - training loss: 0.2223, validation loss: 0.1819
2024-05-23 18:12:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch39_loss0.18193644136190415.pypots
2024-05-23 18:12:57 [INFO]: Epoch 040 - training loss: 0.2192, validation loss: 0.1824
2024-05-23 18:12:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch40_loss0.1824067659676075.pypots
2024-05-23 18:13:41 [INFO]: Epoch 041 - training loss: 0.2176, validation loss: 0.1845
2024-05-23 18:13:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch41_loss0.18446118682622908.pypots
2024-05-23 18:14:25 [INFO]: Epoch 042 - training loss: 0.2202, validation loss: 0.1872
2024-05-23 18:14:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch42_loss0.18719749972224237.pypots
2024-05-23 18:15:09 [INFO]: Epoch 043 - training loss: 0.2215, validation loss: 0.1805
2024-05-23 18:15:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch43_loss0.1805061385035515.pypots
2024-05-23 18:15:53 [INFO]: Epoch 044 - training loss: 0.2234, validation loss: 0.1827
2024-05-23 18:15:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch44_loss0.1827169641852379.pypots
2024-05-23 18:16:37 [INFO]: Epoch 045 - training loss: 0.2283, validation loss: 0.1818
2024-05-23 18:16:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch45_loss0.181785299628973.pypots
2024-05-23 18:17:21 [INFO]: Epoch 046 - training loss: 0.2330, validation loss: 0.1815
2024-05-23 18:17:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch46_loss0.1815277650952339.pypots
2024-05-23 18:18:05 [INFO]: Epoch 047 - training loss: 0.2255, validation loss: 0.1810
2024-05-23 18:18:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch47_loss0.18104715496301652.pypots
2024-05-23 18:18:49 [INFO]: Epoch 048 - training loss: 0.2185, validation loss: 0.1783
2024-05-23 18:18:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch48_loss0.1782501943409443.pypots
2024-05-23 18:19:33 [INFO]: Epoch 049 - training loss: 0.2265, validation loss: 0.1809
2024-05-23 18:19:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch49_loss0.18094936832785607.pypots
2024-05-23 18:20:17 [INFO]: Epoch 050 - training loss: 0.2219, validation loss: 0.1789
2024-05-23 18:20:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch50_loss0.17889834344387054.pypots
2024-05-23 18:21:01 [INFO]: Epoch 051 - training loss: 0.2066, validation loss: 0.1809
2024-05-23 18:21:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch51_loss0.18087996393442154.pypots
2024-05-23 18:21:45 [INFO]: Epoch 052 - training loss: 0.2085, validation loss: 0.1807
2024-05-23 18:21:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch52_loss0.18071250319480897.pypots
2024-05-23 18:22:29 [INFO]: Epoch 053 - training loss: 0.2135, validation loss: 0.1848
2024-05-23 18:22:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch53_loss0.18477730005979537.pypots
2024-05-23 18:23:13 [INFO]: Epoch 054 - training loss: 0.2140, validation loss: 0.1814
2024-05-23 18:23:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch54_loss0.18136992454528808.pypots
2024-05-23 18:23:57 [INFO]: Epoch 055 - training loss: 0.2057, validation loss: 0.1796
2024-05-23 18:23:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch55_loss0.17955958023667334.pypots
2024-05-23 18:24:41 [INFO]: Epoch 056 - training loss: 0.2170, validation loss: 0.1792
2024-05-23 18:24:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch56_loss0.17922947332262992.pypots
2024-05-23 18:25:25 [INFO]: Epoch 057 - training loss: 0.2164, validation loss: 0.1801
2024-05-23 18:25:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch57_loss0.18013377636671066.pypots
2024-05-23 18:26:09 [INFO]: Epoch 058 - training loss: 0.2062, validation loss: 0.1770
2024-05-23 18:26:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch58_loss0.1769530937075615.pypots
2024-05-23 18:26:53 [INFO]: Epoch 059 - training loss: 0.2208, validation loss: 0.1800
2024-05-23 18:26:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch59_loss0.1799997605383396.pypots
2024-05-23 18:27:37 [INFO]: Epoch 060 - training loss: 0.2207, validation loss: 0.1783
2024-05-23 18:27:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch60_loss0.17826048135757447.pypots
2024-05-23 18:28:21 [INFO]: Epoch 061 - training loss: 0.2171, validation loss: 0.1769
2024-05-23 18:28:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch61_loss0.17687586098909377.pypots
2024-05-23 18:29:05 [INFO]: Epoch 062 - training loss: 0.2281, validation loss: 0.1786
2024-05-23 18:29:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch62_loss0.17864391952753067.pypots
2024-05-23 18:29:49 [INFO]: Epoch 063 - training loss: 0.2171, validation loss: 0.1759
2024-05-23 18:29:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch63_loss0.17586129605770112.pypots
2024-05-23 18:30:33 [INFO]: Epoch 064 - training loss: 0.2315, validation loss: 0.1822
2024-05-23 18:30:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch64_loss0.18221450746059417.pypots
2024-05-23 18:31:17 [INFO]: Epoch 065 - training loss: 0.2168, validation loss: 0.1768
2024-05-23 18:31:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch65_loss0.17675472423434258.pypots
2024-05-23 18:32:01 [INFO]: Epoch 066 - training loss: 0.2162, validation loss: 0.1776
2024-05-23 18:32:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch66_loss0.17762457430362702.pypots
2024-05-23 18:32:45 [INFO]: Epoch 067 - training loss: 0.2100, validation loss: 0.1789
2024-05-23 18:32:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch67_loss0.17885730266571045.pypots
2024-05-23 18:33:29 [INFO]: Epoch 068 - training loss: 0.2123, validation loss: 0.1767
2024-05-23 18:33:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch68_loss0.17671064138412476.pypots
2024-05-23 18:34:13 [INFO]: Epoch 069 - training loss: 0.2227, validation loss: 0.1800
2024-05-23 18:34:13 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch69_loss0.18004048019647598.pypots
2024-05-23 18:34:57 [INFO]: Epoch 070 - training loss: 0.2124, validation loss: 0.1758
2024-05-23 18:34:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch70_loss0.17578234672546386.pypots
2024-05-23 18:35:41 [INFO]: Epoch 071 - training loss: 0.2178, validation loss: 0.1757
2024-05-23 18:35:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch71_loss0.17574011757969857.pypots
2024-05-23 18:36:25 [INFO]: Epoch 072 - training loss: 0.2088, validation loss: 0.1731
2024-05-23 18:36:25 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch72_loss0.17309541627764702.pypots
2024-05-23 18:37:09 [INFO]: Epoch 073 - training loss: 0.2121, validation loss: 0.1755
2024-05-23 18:37:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch73_loss0.17554793134331703.pypots
2024-05-23 18:37:53 [INFO]: Epoch 074 - training loss: 0.2246, validation loss: 0.1744
2024-05-23 18:37:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch74_loss0.1744461752474308.pypots
2024-05-23 18:38:37 [INFO]: Epoch 075 - training loss: 0.2202, validation loss: 0.1753
2024-05-23 18:38:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch75_loss0.1752936139702797.pypots
2024-05-23 18:39:21 [INFO]: Epoch 076 - training loss: 0.2154, validation loss: 0.1739
2024-05-23 18:39:21 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch76_loss0.1739098034799099.pypots
2024-05-23 18:40:05 [INFO]: Epoch 077 - training loss: 0.2170, validation loss: 0.1777
2024-05-23 18:40:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch77_loss0.17772267013788223.pypots
2024-05-23 18:40:49 [INFO]: Epoch 078 - training loss: 0.2090, validation loss: 0.1767
2024-05-23 18:40:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch78_loss0.17665421813726426.pypots
2024-05-23 18:41:33 [INFO]: Epoch 079 - training loss: 0.2101, validation loss: 0.1753
2024-05-23 18:41:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch79_loss0.17533096224069594.pypots
2024-05-23 18:42:17 [INFO]: Epoch 080 - training loss: 0.2162, validation loss: 0.1765
2024-05-23 18:42:17 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch80_loss0.1764868028461933.pypots
2024-05-23 18:43:01 [INFO]: Epoch 081 - training loss: 0.2199, validation loss: 0.1768
2024-05-23 18:43:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch81_loss0.1767972633242607.pypots
2024-05-23 18:43:45 [INFO]: Epoch 082 - training loss: 0.2196, validation loss: 0.1747
2024-05-23 18:43:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI_epoch82_loss0.1746670737862587.pypots
2024-05-23 18:43:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:43:45 [INFO]: Finished training. The best model is from epoch#72.
2024-05-23 18:43:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T174336/CSDI.pypots
2024-05-23 18:51:05 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2455, MSE=1.6690
2024-05-23 19:20:25 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 19:20:25 [INFO]: Using the given device: cuda:0
2024-05-23 19:20:25 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T192025
2024-05-23 19:20:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T192025/tensorboard
2024-05-23 19:20:25 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 19:20:29 [INFO]: Epoch 001 - training loss: 42229.0330, validation loss: 0.9077
2024-05-23 19:20:30 [INFO]: Epoch 002 - training loss: 24365.1927, validation loss: 0.7535
2024-05-23 19:20:30 [INFO]: Epoch 003 - training loss: 23501.9240, validation loss: 0.6980
2024-05-23 19:20:31 [INFO]: Epoch 004 - training loss: 23216.4525, validation loss: 0.6917
2024-05-23 19:20:31 [INFO]: Epoch 005 - training loss: 23077.9307, validation loss: 0.6777
2024-05-23 19:20:32 [INFO]: Epoch 006 - training loss: 22999.3150, validation loss: 0.6803
2024-05-23 19:20:32 [INFO]: Epoch 007 - training loss: 22951.4402, validation loss: 0.6768
2024-05-23 19:20:33 [INFO]: Epoch 008 - training loss: 22919.7385, validation loss: 0.6746
2024-05-23 19:20:34 [INFO]: Epoch 009 - training loss: 22898.8193, validation loss: 0.6739
2024-05-23 19:20:34 [INFO]: Epoch 010 - training loss: 22883.5675, validation loss: 0.6684
2024-05-23 19:20:35 [INFO]: Epoch 011 - training loss: 22873.7733, validation loss: 0.6709
2024-05-23 19:20:35 [INFO]: Epoch 012 - training loss: 22864.3307, validation loss: 0.6803
2024-05-23 19:20:36 [INFO]: Epoch 013 - training loss: 22858.3663, validation loss: 0.6649
2024-05-23 19:20:36 [INFO]: Epoch 014 - training loss: 22854.1032, validation loss: 0.6738
2024-05-23 19:20:37 [INFO]: Epoch 015 - training loss: 22849.9963, validation loss: 0.6609
2024-05-23 19:20:38 [INFO]: Epoch 016 - training loss: 22846.0162, validation loss: 0.6639
2024-05-23 19:20:38 [INFO]: Epoch 017 - training loss: 22843.1274, validation loss: 0.6534
2024-05-23 19:20:39 [INFO]: Epoch 018 - training loss: 22840.1419, validation loss: 0.6509
2024-05-23 19:20:39 [INFO]: Epoch 019 - training loss: 22839.0563, validation loss: 0.6442
2024-05-23 19:20:40 [INFO]: Epoch 020 - training loss: 22836.3855, validation loss: 0.6416
2024-05-23 19:20:40 [INFO]: Epoch 021 - training loss: 22834.9827, validation loss: 0.6390
2024-05-23 19:20:41 [INFO]: Epoch 022 - training loss: 22833.1729, validation loss: 0.6465
2024-05-23 19:20:42 [INFO]: Epoch 023 - training loss: 22831.6593, validation loss: 0.6347
2024-05-23 19:20:42 [INFO]: Epoch 024 - training loss: 22830.9187, validation loss: 0.6321
2024-05-23 19:20:43 [INFO]: Epoch 025 - training loss: 22829.5182, validation loss: 0.6319
2024-05-23 19:20:43 [INFO]: Epoch 026 - training loss: 22828.1073, validation loss: 0.6423
2024-05-23 19:20:44 [INFO]: Epoch 027 - training loss: 22827.4957, validation loss: 0.6206
2024-05-23 19:20:44 [INFO]: Epoch 028 - training loss: 22824.7431, validation loss: 0.6283
2024-05-23 19:20:45 [INFO]: Epoch 029 - training loss: 22823.4813, validation loss: 0.6092
2024-05-23 19:20:46 [INFO]: Epoch 030 - training loss: 22821.7743, validation loss: 0.6143
2024-05-23 19:20:46 [INFO]: Epoch 031 - training loss: 22820.5837, validation loss: 0.6099
2024-05-23 19:20:47 [INFO]: Epoch 032 - training loss: 22819.6734, validation loss: 0.5972
2024-05-23 19:20:47 [INFO]: Epoch 033 - training loss: 22818.4707, validation loss: 0.6015
2024-05-23 19:20:48 [INFO]: Epoch 034 - training loss: 22817.4829, validation loss: 0.6028
2024-05-23 19:20:48 [INFO]: Epoch 035 - training loss: 22818.0696, validation loss: 0.6059
2024-05-23 19:20:49 [INFO]: Epoch 036 - training loss: 22817.1428, validation loss: 0.5967
2024-05-23 19:20:50 [INFO]: Epoch 037 - training loss: 22816.4622, validation loss: 0.5933
2024-05-23 19:20:50 [INFO]: Epoch 038 - training loss: 22815.3873, validation loss: 0.5906
2024-05-23 19:20:51 [INFO]: Epoch 039 - training loss: 22815.5595, validation loss: 0.5910
2024-05-23 19:20:51 [INFO]: Epoch 040 - training loss: 22814.5668, validation loss: 0.5842
2024-05-23 19:20:52 [INFO]: Epoch 041 - training loss: 22812.8142, validation loss: 0.5907
2024-05-23 19:20:53 [INFO]: Epoch 042 - training loss: 22811.8782, validation loss: 0.5846
2024-05-23 19:20:53 [INFO]: Epoch 043 - training loss: 22811.1052, validation loss: 0.5782
2024-05-23 19:20:54 [INFO]: Epoch 044 - training loss: 22810.3290, validation loss: 0.5847
2024-05-23 19:20:54 [INFO]: Epoch 045 - training loss: 22809.6189, validation loss: 0.5706
2024-05-23 19:20:55 [INFO]: Epoch 046 - training loss: 22808.0561, validation loss: 0.5678
2024-05-23 19:20:55 [INFO]: Epoch 047 - training loss: 22807.3832, validation loss: 0.5637
2024-05-23 19:20:56 [INFO]: Epoch 048 - training loss: 22806.9033, validation loss: 0.5677
2024-05-23 19:20:57 [INFO]: Epoch 049 - training loss: 22806.2697, validation loss: 0.5568
2024-05-23 19:20:57 [INFO]: Epoch 050 - training loss: 22806.9152, validation loss: 0.5589
2024-05-23 19:20:58 [INFO]: Epoch 051 - training loss: 22806.5330, validation loss: 0.5555
2024-05-23 19:20:59 [INFO]: Epoch 052 - training loss: 22804.8601, validation loss: 0.5679
2024-05-23 19:20:59 [INFO]: Epoch 053 - training loss: 22804.4188, validation loss: 0.5483
2024-05-23 19:21:00 [INFO]: Epoch 054 - training loss: 22803.7706, validation loss: 0.5484
2024-05-23 19:21:00 [INFO]: Epoch 055 - training loss: 22803.1285, validation loss: 0.5518
2024-05-23 19:21:01 [INFO]: Epoch 056 - training loss: 22803.8690, validation loss: 0.5582
2024-05-23 19:21:01 [INFO]: Epoch 057 - training loss: 22803.6048, validation loss: 0.5673
2024-05-23 19:21:02 [INFO]: Epoch 058 - training loss: 22805.5204, validation loss: 0.5434
2024-05-23 19:21:02 [INFO]: Epoch 059 - training loss: 22802.8178, validation loss: 0.5428
2024-05-23 19:21:03 [INFO]: Epoch 060 - training loss: 22802.8387, validation loss: 0.5462
2024-05-23 19:21:04 [INFO]: Epoch 061 - training loss: 22801.5068, validation loss: 0.5341
2024-05-23 19:21:04 [INFO]: Epoch 062 - training loss: 22800.4970, validation loss: 0.5350
2024-05-23 19:21:05 [INFO]: Epoch 063 - training loss: 22799.3166, validation loss: 0.5284
2024-05-23 19:21:05 [INFO]: Epoch 064 - training loss: 22798.8278, validation loss: 0.5282
2024-05-23 19:21:06 [INFO]: Epoch 065 - training loss: 22797.8868, validation loss: 0.5223
2024-05-23 19:21:06 [INFO]: Epoch 066 - training loss: 22797.4080, validation loss: 0.5169
2024-05-23 19:21:07 [INFO]: Epoch 067 - training loss: 22796.8011, validation loss: 0.5270
2024-05-23 19:21:08 [INFO]: Epoch 068 - training loss: 22796.4215, validation loss: 0.5132
2024-05-23 19:21:08 [INFO]: Epoch 069 - training loss: 22796.6548, validation loss: 0.5202
2024-05-23 19:21:09 [INFO]: Epoch 070 - training loss: 22796.1214, validation loss: 0.5169
2024-05-23 19:21:09 [INFO]: Epoch 071 - training loss: 22795.5586, validation loss: 0.5124
2024-05-23 19:21:10 [INFO]: Epoch 072 - training loss: 22795.2184, validation loss: 0.5152
2024-05-23 19:21:10 [INFO]: Epoch 073 - training loss: 22795.3082, validation loss: 0.5124
2024-05-23 19:21:11 [INFO]: Epoch 074 - training loss: 22794.6348, validation loss: 0.5106
2024-05-23 19:21:12 [INFO]: Epoch 075 - training loss: 22795.6855, validation loss: 0.5106
2024-05-23 19:21:12 [INFO]: Epoch 076 - training loss: 22793.6250, validation loss: 0.5127
2024-05-23 19:21:13 [INFO]: Epoch 077 - training loss: 22794.2647, validation loss: 0.5095
2024-05-23 19:21:13 [INFO]: Epoch 078 - training loss: 22793.4750, validation loss: 0.5062
2024-05-23 19:21:14 [INFO]: Epoch 079 - training loss: 22794.9420, validation loss: 0.5046
2024-05-23 19:21:14 [INFO]: Epoch 080 - training loss: 22794.2177, validation loss: 0.5127
2024-05-23 19:21:15 [INFO]: Epoch 081 - training loss: 22794.6755, validation loss: 0.5016
2024-05-23 19:21:16 [INFO]: Epoch 082 - training loss: 22792.8121, validation loss: 0.5018
2024-05-23 19:21:16 [INFO]: Epoch 083 - training loss: 22792.2658, validation loss: 0.5061
2024-05-23 19:21:17 [INFO]: Epoch 084 - training loss: 22791.6194, validation loss: 0.5029
2024-05-23 19:21:17 [INFO]: Epoch 085 - training loss: 22791.1720, validation loss: 0.5042
2024-05-23 19:21:18 [INFO]: Epoch 086 - training loss: 22791.3424, validation loss: 0.5063
2024-05-23 19:21:18 [INFO]: Epoch 087 - training loss: 22791.2021, validation loss: 0.5008
2024-05-23 19:21:19 [INFO]: Epoch 088 - training loss: 22792.4225, validation loss: 0.4992
2024-05-23 19:21:20 [INFO]: Epoch 089 - training loss: 22792.8372, validation loss: 0.5034
2024-05-23 19:21:20 [INFO]: Epoch 090 - training loss: 22792.4559, validation loss: 0.4990
2024-05-23 19:21:21 [INFO]: Epoch 091 - training loss: 22791.1541, validation loss: 0.4972
2024-05-23 19:21:21 [INFO]: Epoch 092 - training loss: 22791.2583, validation loss: 0.4960
2024-05-23 19:21:22 [INFO]: Epoch 093 - training loss: 22790.6449, validation loss: 0.4936
2024-05-23 19:21:22 [INFO]: Epoch 094 - training loss: 22790.2370, validation loss: 0.4988
2024-05-23 19:21:23 [INFO]: Epoch 095 - training loss: 22789.6172, validation loss: 0.4906
2024-05-23 19:21:24 [INFO]: Epoch 096 - training loss: 22789.4393, validation loss: 0.5002
2024-05-23 19:21:24 [INFO]: Epoch 097 - training loss: 22789.7842, validation loss: 0.4922
2024-05-23 19:21:25 [INFO]: Epoch 098 - training loss: 22789.7221, validation loss: 0.4927
2024-05-23 19:21:25 [INFO]: Epoch 099 - training loss: 22789.2678, validation loss: 0.4926
2024-05-23 19:21:26 [INFO]: Epoch 100 - training loss: 22788.7311, validation loss: 0.4900
2024-05-23 19:21:26 [INFO]: Epoch 101 - training loss: 22789.0067, validation loss: 0.4937
2024-05-23 19:21:27 [INFO]: Epoch 102 - training loss: 22792.0449, validation loss: 0.4924
2024-05-23 19:21:28 [INFO]: Epoch 103 - training loss: 22790.4311, validation loss: 0.4955
2024-05-23 19:21:28 [INFO]: Epoch 104 - training loss: 22790.0937, validation loss: 0.4899
2024-05-23 19:21:29 [INFO]: Epoch 105 - training loss: 22788.8656, validation loss: 0.4931
2024-05-23 19:21:29 [INFO]: Epoch 106 - training loss: 22787.8967, validation loss: 0.4918
2024-05-23 19:21:30 [INFO]: Epoch 107 - training loss: 22787.8660, validation loss: 0.4898
2024-05-23 19:21:31 [INFO]: Epoch 108 - training loss: 22787.6888, validation loss: 0.4900
2024-05-23 19:21:31 [INFO]: Epoch 109 - training loss: 22787.9511, validation loss: 0.4847
2024-05-23 19:21:32 [INFO]: Epoch 110 - training loss: 22787.7080, validation loss: 0.4892
2024-05-23 19:21:32 [INFO]: Epoch 111 - training loss: 22787.3222, validation loss: 0.4840
2024-05-23 19:21:33 [INFO]: Epoch 112 - training loss: 22786.9370, validation loss: 0.4883
2024-05-23 19:21:33 [INFO]: Epoch 113 - training loss: 22787.2142, validation loss: 0.4862
2024-05-23 19:21:34 [INFO]: Epoch 114 - training loss: 22787.2196, validation loss: 0.4924
2024-05-23 19:21:35 [INFO]: Epoch 115 - training loss: 22787.0829, validation loss: 0.4878
2024-05-23 19:21:35 [INFO]: Epoch 116 - training loss: 22787.3796, validation loss: 0.4894
2024-05-23 19:21:36 [INFO]: Epoch 117 - training loss: 22787.0090, validation loss: 0.4857
2024-05-23 19:21:36 [INFO]: Epoch 118 - training loss: 22786.9093, validation loss: 0.4903
2024-05-23 19:21:37 [INFO]: Epoch 119 - training loss: 22787.0526, validation loss: 0.4844
2024-05-23 19:21:37 [INFO]: Epoch 120 - training loss: 22787.0182, validation loss: 0.4867
2024-05-23 19:21:38 [INFO]: Epoch 121 - training loss: 22786.7493, validation loss: 0.4929
2024-05-23 19:21:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:21:38 [INFO]: Finished training. The best model is from epoch#111.
2024-05-23 19:21:38 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T192025/GPVAE.pypots
2024-05-23 19:21:38 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4309, MSE=0.5208
2024-05-23 19:21:38 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 19:21:38 [INFO]: Using the given device: cuda:0
2024-05-23 19:21:38 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T192138
2024-05-23 19:21:38 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T192138/tensorboard
2024-05-23 19:21:39 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 19:22:02 [INFO]: Epoch 001 - generator training loss: 0.5786, discriminator training loss: 0.3790, validation loss: 0.6275
2024-05-23 19:22:20 [INFO]: Epoch 002 - generator training loss: 0.4586, discriminator training loss: 0.2573, validation loss: 0.5353
2024-05-23 19:22:39 [INFO]: Epoch 003 - generator training loss: 0.4342, discriminator training loss: 0.2063, validation loss: 0.5157
2024-05-23 19:22:57 [INFO]: Epoch 004 - generator training loss: 0.4457, discriminator training loss: 0.1545, validation loss: 0.4939
2024-05-23 19:23:16 [INFO]: Epoch 005 - generator training loss: 0.4367, discriminator training loss: 0.1250, validation loss: 0.4869
2024-05-23 19:23:34 [INFO]: Epoch 006 - generator training loss: 0.4302, discriminator training loss: 0.1047, validation loss: 0.4676
2024-05-23 19:23:53 [INFO]: Epoch 007 - generator training loss: 0.4198, discriminator training loss: 0.0907, validation loss: 0.4574
2024-05-23 19:24:12 [INFO]: Epoch 008 - generator training loss: 0.4109, discriminator training loss: 0.0811, validation loss: 0.4501
2024-05-23 19:24:30 [INFO]: Epoch 009 - generator training loss: 0.4042, discriminator training loss: 0.0729, validation loss: 0.4394
2024-05-23 19:24:49 [INFO]: Epoch 010 - generator training loss: 0.3965, discriminator training loss: 0.0665, validation loss: 0.4365
2024-05-23 19:25:07 [INFO]: Epoch 011 - generator training loss: 0.3900, discriminator training loss: 0.0609, validation loss: 0.4265
2024-05-23 19:25:26 [INFO]: Epoch 012 - generator training loss: 0.3857, discriminator training loss: 0.0564, validation loss: 0.4184
2024-05-23 19:25:44 [INFO]: Epoch 013 - generator training loss: 0.3773, discriminator training loss: 0.0525, validation loss: 0.4170
2024-05-23 19:26:03 [INFO]: Epoch 014 - generator training loss: 0.3726, discriminator training loss: 0.0493, validation loss: 0.4111
2024-05-23 19:26:22 [INFO]: Epoch 015 - generator training loss: 0.3675, discriminator training loss: 0.0461, validation loss: 0.4015
2024-05-23 19:26:40 [INFO]: Epoch 016 - generator training loss: 0.3643, discriminator training loss: 0.0440, validation loss: 0.3996
2024-05-23 19:26:58 [INFO]: Epoch 017 - generator training loss: 0.3564, discriminator training loss: 0.0417, validation loss: 0.3948
2024-05-23 19:27:17 [INFO]: Epoch 018 - generator training loss: 0.3517, discriminator training loss: 0.0398, validation loss: 0.3898
2024-05-23 19:27:36 [INFO]: Epoch 019 - generator training loss: 0.3468, discriminator training loss: 0.0381, validation loss: 0.3870
2024-05-23 19:27:54 [INFO]: Epoch 020 - generator training loss: 0.3420, discriminator training loss: 0.0368, validation loss: 0.3814
2024-05-23 19:28:13 [INFO]: Epoch 021 - generator training loss: 0.3346, discriminator training loss: 0.0356, validation loss: 0.3763
2024-05-23 19:28:31 [INFO]: Epoch 022 - generator training loss: 0.3298, discriminator training loss: 0.0346, validation loss: 0.3725
2024-05-23 19:28:49 [INFO]: Epoch 023 - generator training loss: 0.3236, discriminator training loss: 0.0334, validation loss: 0.3687
2024-05-23 19:29:08 [INFO]: Epoch 024 - generator training loss: 0.3191, discriminator training loss: 0.0325, validation loss: 0.3674
2024-05-23 19:29:26 [INFO]: Epoch 025 - generator training loss: 0.3149, discriminator training loss: 0.0318, validation loss: 0.3638
2024-05-23 19:29:44 [INFO]: Epoch 026 - generator training loss: 0.3121, discriminator training loss: 0.0311, validation loss: 0.3600
2024-05-23 19:30:03 [INFO]: Epoch 027 - generator training loss: 0.3076, discriminator training loss: 0.0307, validation loss: 0.3569
2024-05-23 19:30:21 [INFO]: Epoch 028 - generator training loss: 0.3023, discriminator training loss: 0.0300, validation loss: 0.3514
2024-05-23 19:30:39 [INFO]: Epoch 029 - generator training loss: 0.2963, discriminator training loss: 0.0295, validation loss: 0.3522
2024-05-23 19:30:58 [INFO]: Epoch 030 - generator training loss: 0.2918, discriminator training loss: 0.0290, validation loss: 0.3477
2024-05-23 19:31:16 [INFO]: Epoch 031 - generator training loss: 0.2924, discriminator training loss: 0.0286, validation loss: 0.3482
2024-05-23 19:31:34 [INFO]: Epoch 032 - generator training loss: 0.2859, discriminator training loss: 0.0282, validation loss: 0.3556
2024-05-23 19:31:53 [INFO]: Epoch 033 - generator training loss: 0.2923, discriminator training loss: 0.0279, validation loss: 0.3414
2024-05-23 19:32:11 [INFO]: Epoch 034 - generator training loss: 0.2814, discriminator training loss: 0.0275, validation loss: 0.3417
2024-05-23 19:32:29 [INFO]: Epoch 035 - generator training loss: 0.2756, discriminator training loss: 0.0269, validation loss: 0.3383
2024-05-23 19:32:48 [INFO]: Epoch 036 - generator training loss: 0.2744, discriminator training loss: 0.0268, validation loss: 0.3398
2024-05-23 19:33:06 [INFO]: Epoch 037 - generator training loss: 0.2757, discriminator training loss: 0.0264, validation loss: 0.3387
2024-05-23 19:33:24 [INFO]: Epoch 038 - generator training loss: 0.2724, discriminator training loss: 0.0263, validation loss: 0.3333
2024-05-23 19:33:42 [INFO]: Epoch 039 - generator training loss: 0.2644, discriminator training loss: 0.0259, validation loss: 0.3327
2024-05-23 19:34:01 [INFO]: Epoch 040 - generator training loss: 0.2593, discriminator training loss: 0.0257, validation loss: 0.3305
2024-05-23 19:34:19 [INFO]: Epoch 041 - generator training loss: 0.2550, discriminator training loss: 0.0255, validation loss: 0.3278
2024-05-23 19:34:37 [INFO]: Epoch 042 - generator training loss: 0.2507, discriminator training loss: 0.0252, validation loss: 0.3284
2024-05-23 19:34:56 [INFO]: Epoch 043 - generator training loss: 0.2566, discriminator training loss: 0.0251, validation loss: 0.3308
2024-05-23 19:35:14 [INFO]: Epoch 044 - generator training loss: 0.2557, discriminator training loss: 0.0248, validation loss: 0.3254
2024-05-23 19:35:32 [INFO]: Epoch 045 - generator training loss: 0.2529, discriminator training loss: 0.0246, validation loss: 0.3259
2024-05-23 19:35:50 [INFO]: Epoch 046 - generator training loss: 0.2465, discriminator training loss: 0.0242, validation loss: 0.3219
2024-05-23 19:36:09 [INFO]: Epoch 047 - generator training loss: 0.2405, discriminator training loss: 0.0242, validation loss: 0.3236
2024-05-23 19:36:27 [INFO]: Epoch 048 - generator training loss: 0.2387, discriminator training loss: 0.0241, validation loss: 0.3281
2024-05-23 19:36:45 [INFO]: Epoch 049 - generator training loss: 0.2454, discriminator training loss: 0.0240, validation loss: 0.3330
2024-05-23 19:37:04 [INFO]: Epoch 050 - generator training loss: 0.2471, discriminator training loss: 0.0239, validation loss: 0.3245
2024-05-23 19:37:22 [INFO]: Epoch 051 - generator training loss: 0.2378, discriminator training loss: 0.0236, validation loss: 0.3235
2024-05-23 19:37:40 [INFO]: Epoch 052 - generator training loss: 0.2329, discriminator training loss: 0.0232, validation loss: 0.3234
2024-05-23 19:37:58 [INFO]: Epoch 053 - generator training loss: 0.2305, discriminator training loss: 0.0231, validation loss: 0.3198
2024-05-23 19:38:17 [INFO]: Epoch 054 - generator training loss: 0.2312, discriminator training loss: 0.0231, validation loss: 0.3219
2024-05-23 19:38:35 [INFO]: Epoch 055 - generator training loss: 0.2367, discriminator training loss: 0.0229, validation loss: 0.3221
2024-05-23 19:38:53 [INFO]: Epoch 056 - generator training loss: 0.2367, discriminator training loss: 0.0227, validation loss: 0.3259
2024-05-23 19:39:12 [INFO]: Epoch 057 - generator training loss: 0.2288, discriminator training loss: 0.0225, validation loss: 0.3216
2024-05-23 19:39:30 [INFO]: Epoch 058 - generator training loss: 0.2232, discriminator training loss: 0.0225, validation loss: 0.3185
2024-05-23 19:39:48 [INFO]: Epoch 059 - generator training loss: 0.2248, discriminator training loss: 0.0221, validation loss: 0.3166
2024-05-23 19:40:07 [INFO]: Epoch 060 - generator training loss: 0.2171, discriminator training loss: 0.0222, validation loss: 0.3173
2024-05-23 19:40:25 [INFO]: Epoch 061 - generator training loss: 0.2217, discriminator training loss: 0.0219, validation loss: 0.3192
2024-05-23 19:40:43 [INFO]: Epoch 062 - generator training loss: 0.2147, discriminator training loss: 0.0218, validation loss: 0.3223
2024-05-23 19:41:01 [INFO]: Epoch 063 - generator training loss: 0.2162, discriminator training loss: 0.0217, validation loss: 0.3160
2024-05-23 19:41:20 [INFO]: Epoch 064 - generator training loss: 0.2121, discriminator training loss: 0.0216, validation loss: 0.3190
2024-05-23 19:41:38 [INFO]: Epoch 065 - generator training loss: 0.2121, discriminator training loss: 0.0214, validation loss: 0.3236
2024-05-23 19:41:56 [INFO]: Epoch 066 - generator training loss: 0.2201, discriminator training loss: 0.0214, validation loss: 0.3223
2024-05-23 19:42:15 [INFO]: Epoch 067 - generator training loss: 0.2116, discriminator training loss: 0.0214, validation loss: 0.3160
2024-05-23 19:42:33 [INFO]: Epoch 068 - generator training loss: 0.2139, discriminator training loss: 0.0212, validation loss: 0.3174
2024-05-23 19:42:51 [INFO]: Epoch 069 - generator training loss: 0.2061, discriminator training loss: 0.0212, validation loss: 0.3171
2024-05-23 19:43:09 [INFO]: Epoch 070 - generator training loss: 0.2023, discriminator training loss: 0.0210, validation loss: 0.3173
2024-05-23 19:43:28 [INFO]: Epoch 071 - generator training loss: 0.1992, discriminator training loss: 0.0210, validation loss: 0.3197
2024-05-23 19:43:46 [INFO]: Epoch 072 - generator training loss: 0.1984, discriminator training loss: 0.0210, validation loss: 0.3178
2024-05-23 19:44:04 [INFO]: Epoch 073 - generator training loss: 0.1966, discriminator training loss: 0.0209, validation loss: 0.3162
2024-05-23 19:44:23 [INFO]: Epoch 074 - generator training loss: 0.2076, discriminator training loss: 0.0210, validation loss: 0.3241
2024-05-23 19:44:41 [INFO]: Epoch 075 - generator training loss: 0.2245, discriminator training loss: 0.0210, validation loss: 0.3324
2024-05-23 19:44:59 [INFO]: Epoch 076 - generator training loss: 0.2150, discriminator training loss: 0.0209, validation loss: 0.3195
2024-05-23 19:45:17 [INFO]: Epoch 077 - generator training loss: 0.2040, discriminator training loss: 0.0209, validation loss: 0.3183
2024-05-23 19:45:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:45:17 [INFO]: Finished training. The best model is from epoch#67.
2024-05-23 19:45:18 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T192138/USGAN.pypots
2024-05-23 19:45:20 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.3006, MSE=0.3247
2024-05-23 19:45:30 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 19:45:30 [INFO]: Using the given device: cuda:0
2024-05-23 19:45:30 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T194530
2024-05-23 19:45:30 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T194530/tensorboard
2024-05-23 19:45:30 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 19:45:45 [INFO]: Epoch 001 - training loss: 1.1234, validation loss: 0.5449
2024-05-23 19:45:57 [INFO]: Epoch 002 - training loss: 0.9135, validation loss: 0.4957
2024-05-23 19:46:09 [INFO]: Epoch 003 - training loss: 0.8548, validation loss: 0.4663
2024-05-23 19:46:21 [INFO]: Epoch 004 - training loss: 0.8173, validation loss: 0.4375
2024-05-23 19:46:33 [INFO]: Epoch 005 - training loss: 0.7867, validation loss: 0.4213
2024-05-23 19:46:45 [INFO]: Epoch 006 - training loss: 0.7625, validation loss: 0.4038
2024-05-23 19:46:57 [INFO]: Epoch 007 - training loss: 0.7406, validation loss: 0.3917
2024-05-23 19:47:09 [INFO]: Epoch 008 - training loss: 0.7232, validation loss: 0.3814
2024-05-23 19:47:21 [INFO]: Epoch 009 - training loss: 0.7096, validation loss: 0.3716
2024-05-23 19:47:33 [INFO]: Epoch 010 - training loss: 0.6971, validation loss: 0.3681
2024-05-23 19:47:45 [INFO]: Epoch 011 - training loss: 0.6868, validation loss: 0.3617
2024-05-23 19:47:57 [INFO]: Epoch 012 - training loss: 0.6780, validation loss: 0.3589
2024-05-23 19:48:09 [INFO]: Epoch 013 - training loss: 0.6702, validation loss: 0.3561
2024-05-23 19:48:21 [INFO]: Epoch 014 - training loss: 0.6631, validation loss: 0.3523
2024-05-23 19:48:33 [INFO]: Epoch 015 - training loss: 0.6568, validation loss: 0.3474
2024-05-23 19:48:45 [INFO]: Epoch 016 - training loss: 0.6517, validation loss: 0.3474
2024-05-23 19:48:56 [INFO]: Epoch 017 - training loss: 0.6454, validation loss: 0.3447
2024-05-23 19:49:09 [INFO]: Epoch 018 - training loss: 0.6411, validation loss: 0.3446
2024-05-23 19:49:20 [INFO]: Epoch 019 - training loss: 0.6383, validation loss: 0.3430
2024-05-23 19:49:32 [INFO]: Epoch 020 - training loss: 0.6359, validation loss: 0.3424
2024-05-23 19:49:44 [INFO]: Epoch 021 - training loss: 0.6329, validation loss: 0.3402
2024-05-23 19:49:56 [INFO]: Epoch 022 - training loss: 0.6284, validation loss: 0.3375
2024-05-23 19:50:08 [INFO]: Epoch 023 - training loss: 0.6232, validation loss: 0.3361
2024-05-23 19:50:20 [INFO]: Epoch 024 - training loss: 0.6198, validation loss: 0.3346
2024-05-23 19:50:32 [INFO]: Epoch 025 - training loss: 0.6181, validation loss: 0.3325
2024-05-23 19:50:44 [INFO]: Epoch 026 - training loss: 0.6144, validation loss: 0.3333
2024-05-23 19:50:56 [INFO]: Epoch 027 - training loss: 0.6108, validation loss: 0.3311
2024-05-23 19:51:08 [INFO]: Epoch 028 - training loss: 0.6076, validation loss: 0.3296
2024-05-23 19:51:20 [INFO]: Epoch 029 - training loss: 0.6047, validation loss: 0.3300
2024-05-23 19:51:32 [INFO]: Epoch 030 - training loss: 0.6018, validation loss: 0.3302
2024-05-23 19:51:44 [INFO]: Epoch 031 - training loss: 0.5987, validation loss: 0.3293
2024-05-23 19:51:56 [INFO]: Epoch 032 - training loss: 0.5955, validation loss: 0.3285
2024-05-23 19:52:08 [INFO]: Epoch 033 - training loss: 0.5928, validation loss: 0.3273
2024-05-23 19:52:20 [INFO]: Epoch 034 - training loss: 0.5900, validation loss: 0.3287
2024-05-23 19:52:32 [INFO]: Epoch 035 - training loss: 0.5867, validation loss: 0.3282
2024-05-23 19:52:44 [INFO]: Epoch 036 - training loss: 0.5842, validation loss: 0.3270
2024-05-23 19:52:56 [INFO]: Epoch 037 - training loss: 0.5813, validation loss: 0.3272
2024-05-23 19:53:08 [INFO]: Epoch 038 - training loss: 0.5781, validation loss: 0.3264
2024-05-23 19:53:20 [INFO]: Epoch 039 - training loss: 0.5779, validation loss: 0.3314
2024-05-23 19:53:32 [INFO]: Epoch 040 - training loss: 0.5844, validation loss: 0.3289
2024-05-23 19:53:44 [INFO]: Epoch 041 - training loss: 0.5758, validation loss: 0.3282
2024-05-23 19:53:56 [INFO]: Epoch 042 - training loss: 0.5728, validation loss: 0.3304
2024-05-23 19:54:08 [INFO]: Epoch 043 - training loss: 0.5703, validation loss: 0.3320
2024-05-23 19:54:20 [INFO]: Epoch 044 - training loss: 0.5653, validation loss: 0.3289
2024-05-23 19:54:32 [INFO]: Epoch 045 - training loss: 0.5633, validation loss: 0.3304
2024-05-23 19:54:44 [INFO]: Epoch 046 - training loss: 0.5575, validation loss: 0.3295
2024-05-23 19:54:56 [INFO]: Epoch 047 - training loss: 0.5540, validation loss: 0.3302
2024-05-23 19:55:08 [INFO]: Epoch 048 - training loss: 0.5500, validation loss: 0.3323
2024-05-23 19:55:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:55:08 [INFO]: Finished training. The best model is from epoch#38.
2024-05-23 19:55:08 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T194530/BRITS.pypots
2024-05-23 19:55:10 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2602, MSE=0.3399
2024-05-23 19:55:20 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:55:20 [INFO]: Using the given device: cuda:0
2024-05-23 19:55:20 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520
2024-05-23 19:55:20 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/tensorboard
2024-05-23 19:55:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 19:55:26 [INFO]: Epoch 001 - training loss: 1.1626, validation loss: 1.0103
2024-05-23 19:55:26 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch1_loss1.010299500823021.pypots
2024-05-23 19:55:29 [INFO]: Epoch 002 - training loss: 0.7553, validation loss: 0.9780
2024-05-23 19:55:29 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch2_loss0.9779507935047149.pypots
2024-05-23 19:55:31 [INFO]: Epoch 003 - training loss: 0.6310, validation loss: 0.9511
2024-05-23 19:55:31 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch3_loss0.9510654479265213.pypots
2024-05-23 19:55:34 [INFO]: Epoch 004 - training loss: 0.5856, validation loss: 0.9414
2024-05-23 19:55:34 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch4_loss0.9414222508668899.pypots
2024-05-23 19:55:37 [INFO]: Epoch 005 - training loss: 0.5486, validation loss: 0.9345
2024-05-23 19:55:37 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch5_loss0.9345161288976669.pypots
2024-05-23 19:55:40 [INFO]: Epoch 006 - training loss: 0.5297, validation loss: 0.9304
2024-05-23 19:55:40 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch6_loss0.9304176241159439.pypots
2024-05-23 19:55:42 [INFO]: Epoch 007 - training loss: 0.5139, validation loss: 0.9265
2024-05-23 19:55:42 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch7_loss0.9265135705471039.pypots
2024-05-23 19:55:45 [INFO]: Epoch 008 - training loss: 0.5134, validation loss: 0.9261
2024-05-23 19:55:45 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch8_loss0.9260962396860123.pypots
2024-05-23 19:55:48 [INFO]: Epoch 009 - training loss: 0.5032, validation loss: 0.9227
2024-05-23 19:55:48 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch9_loss0.9226598471403122.pypots
2024-05-23 19:55:51 [INFO]: Epoch 010 - training loss: 0.4942, validation loss: 0.9225
2024-05-23 19:55:51 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch10_loss0.9225338250398636.pypots
2024-05-23 19:55:53 [INFO]: Epoch 011 - training loss: 0.4777, validation loss: 0.9231
2024-05-23 19:55:53 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch11_loss0.923117408156395.pypots
2024-05-23 19:55:56 [INFO]: Epoch 012 - training loss: 0.4802, validation loss: 0.9232
2024-05-23 19:55:56 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch12_loss0.92316854596138.pypots
2024-05-23 19:55:59 [INFO]: Epoch 013 - training loss: 0.4701, validation loss: 0.9246
2024-05-23 19:55:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch13_loss0.9246293783187867.pypots
2024-05-23 19:56:02 [INFO]: Epoch 014 - training loss: 0.4771, validation loss: 0.9260
2024-05-23 19:56:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch14_loss0.9260087549686432.pypots
2024-05-23 19:56:04 [INFO]: Epoch 015 - training loss: 0.4676, validation loss: 0.9268
2024-05-23 19:56:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch15_loss0.9268149077892304.pypots
2024-05-23 19:56:07 [INFO]: Epoch 016 - training loss: 0.4686, validation loss: 0.9280
2024-05-23 19:56:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch16_loss0.9280052781105042.pypots
2024-05-23 19:56:10 [INFO]: Epoch 017 - training loss: 0.4751, validation loss: 0.9302
2024-05-23 19:56:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch17_loss0.9302427679300308.pypots
2024-05-23 19:56:13 [INFO]: Epoch 018 - training loss: 0.4583, validation loss: 0.9294
2024-05-23 19:56:13 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch18_loss0.9293691396713257.pypots
2024-05-23 19:56:16 [INFO]: Epoch 019 - training loss: 0.4562, validation loss: 0.9297
2024-05-23 19:56:16 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch19_loss0.9297294408082962.pypots
2024-05-23 19:56:18 [INFO]: Epoch 020 - training loss: 0.4491, validation loss: 0.9312
2024-05-23 19:56:18 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN_epoch20_loss0.9311978846788407.pypots
2024-05-23 19:56:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:56:18 [INFO]: Finished training. The best model is from epoch#10.
2024-05-23 19:56:18 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T195520/MRNN.pypots
2024-05-23 19:56:19 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6838, MSE=0.9343
2024-05-23 19:56:23 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 19:56:23 [INFO]: Using the given device: cpu
2024-05-23 19:56:23 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4114, MSE=0.6133
2024-05-23 19:56:24 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_physionet_2012_seta".
2024-05-23 19:56:24 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 19:56:24 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6898, MSE=1.0489
2024-05-23 19:56:24 [INFO]: Successfully created the given path "saved_results/round_0/Median_physionet_2012_seta".
2024-05-23 19:56:24 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_physionet_2012_seta/imputation.pkl
2024-05-23 19:56:24 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7072, MSE=1.0216
2024-05-23 19:56:24 [INFO]: Successfully created the given path "saved_results/round_0/Mean_physionet_2012_seta".
2024-05-23 19:56:24 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 19:56:24 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-23 19:56:25 [INFO]: Using the given device: cuda:0
2024-05-23 19:56:25 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T195625
2024-05-23 19:56:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T195625/tensorboard
2024-05-23 19:56:25 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 19:56:26 [INFO]: Epoch 001 - training loss: 1.0993, validation loss: 0.5041
2024-05-23 19:56:27 [INFO]: Epoch 002 - training loss: 0.6962, validation loss: 0.4467
2024-05-23 19:56:28 [INFO]: Epoch 003 - training loss: 0.5837, validation loss: 0.4048
2024-05-23 19:56:30 [INFO]: Epoch 004 - training loss: 0.5226, validation loss: 0.3923
2024-05-23 19:56:31 [INFO]: Epoch 005 - training loss: 0.4910, validation loss: 0.3778
2024-05-23 19:56:32 [INFO]: Epoch 006 - training loss: 0.4597, validation loss: 0.3644
2024-05-23 19:56:34 [INFO]: Epoch 007 - training loss: 0.4399, validation loss: 0.3548
2024-05-23 19:56:35 [INFO]: Epoch 008 - training loss: 0.4231, validation loss: 0.3438
2024-05-23 19:56:36 [INFO]: Epoch 009 - training loss: 0.4042, validation loss: 0.3317
2024-05-23 19:56:37 [INFO]: Epoch 010 - training loss: 0.3885, validation loss: 0.3249
2024-05-23 19:56:39 [INFO]: Epoch 011 - training loss: 0.3748, validation loss: 0.3155
2024-05-23 19:56:40 [INFO]: Epoch 012 - training loss: 0.3635, validation loss: 0.3065
2024-05-23 19:56:41 [INFO]: Epoch 013 - training loss: 0.3570, validation loss: 0.3064
2024-05-23 19:56:42 [INFO]: Epoch 014 - training loss: 0.3497, validation loss: 0.3042
2024-05-23 19:56:44 [INFO]: Epoch 015 - training loss: 0.3407, validation loss: 0.3001
2024-05-23 19:56:45 [INFO]: Epoch 016 - training loss: 0.3333, validation loss: 0.2964
2024-05-23 19:56:46 [INFO]: Epoch 017 - training loss: 0.3276, validation loss: 0.2890
2024-05-23 19:56:47 [INFO]: Epoch 018 - training loss: 0.3172, validation loss: 0.2891
2024-05-23 19:56:49 [INFO]: Epoch 019 - training loss: 0.3219, validation loss: 0.2891
2024-05-23 19:56:50 [INFO]: Epoch 020 - training loss: 0.3111, validation loss: 0.2861
2024-05-23 19:56:51 [INFO]: Epoch 021 - training loss: 0.3111, validation loss: 0.2839
2024-05-23 19:56:53 [INFO]: Epoch 022 - training loss: 0.3102, validation loss: 0.2798
2024-05-23 19:56:54 [INFO]: Epoch 023 - training loss: 0.3025, validation loss: 0.2787
2024-05-23 19:56:55 [INFO]: Epoch 024 - training loss: 0.3024, validation loss: 0.2756
2024-05-23 19:56:56 [INFO]: Epoch 025 - training loss: 0.2962, validation loss: 0.2770
2024-05-23 19:56:58 [INFO]: Epoch 026 - training loss: 0.2927, validation loss: 0.2742
2024-05-23 19:56:59 [INFO]: Epoch 027 - training loss: 0.2936, validation loss: 0.2752
2024-05-23 19:57:00 [INFO]: Epoch 028 - training loss: 0.2913, validation loss: 0.2734
2024-05-23 19:57:01 [INFO]: Epoch 029 - training loss: 0.2899, validation loss: 0.2718
2024-05-23 19:57:03 [INFO]: Epoch 030 - training loss: 0.2873, validation loss: 0.2687
2024-05-23 19:57:04 [INFO]: Epoch 031 - training loss: 0.2848, validation loss: 0.2703
2024-05-23 19:57:05 [INFO]: Epoch 032 - training loss: 0.2821, validation loss: 0.2702
2024-05-23 19:57:07 [INFO]: Epoch 033 - training loss: 0.2823, validation loss: 0.2649
2024-05-23 19:57:08 [INFO]: Epoch 034 - training loss: 0.2830, validation loss: 0.2658
2024-05-23 19:57:09 [INFO]: Epoch 035 - training loss: 0.2767, validation loss: 0.2674
2024-05-23 19:57:10 [INFO]: Epoch 036 - training loss: 0.2775, validation loss: 0.2627
2024-05-23 19:57:12 [INFO]: Epoch 037 - training loss: 0.2772, validation loss: 0.2639
2024-05-23 19:57:13 [INFO]: Epoch 038 - training loss: 0.2736, validation loss: 0.2603
2024-05-23 19:57:14 [INFO]: Epoch 039 - training loss: 0.2728, validation loss: 0.2598
2024-05-23 19:57:15 [INFO]: Epoch 040 - training loss: 0.2711, validation loss: 0.2585
2024-05-23 19:57:17 [INFO]: Epoch 041 - training loss: 0.2735, validation loss: 0.2601
2024-05-23 19:57:18 [INFO]: Epoch 042 - training loss: 0.2702, validation loss: 0.2605
2024-05-23 19:57:19 [INFO]: Epoch 043 - training loss: 0.2699, validation loss: 0.2594
2024-05-23 19:57:20 [INFO]: Epoch 044 - training loss: 0.2686, validation loss: 0.2557
2024-05-23 19:57:22 [INFO]: Epoch 045 - training loss: 0.2643, validation loss: 0.2570
2024-05-23 19:57:23 [INFO]: Epoch 046 - training loss: 0.2686, validation loss: 0.2603
2024-05-23 19:57:24 [INFO]: Epoch 047 - training loss: 0.2667, validation loss: 0.2550
2024-05-23 19:57:26 [INFO]: Epoch 048 - training loss: 0.2634, validation loss: 0.2575
2024-05-23 19:57:27 [INFO]: Epoch 049 - training loss: 0.2630, validation loss: 0.2553
2024-05-23 19:57:28 [INFO]: Epoch 050 - training loss: 0.2638, validation loss: 0.2543
2024-05-23 19:57:29 [INFO]: Epoch 051 - training loss: 0.2654, validation loss: 0.2570
2024-05-23 19:57:31 [INFO]: Epoch 052 - training loss: 0.2608, validation loss: 0.2577
2024-05-23 19:57:32 [INFO]: Epoch 053 - training loss: 0.2623, validation loss: 0.2553
2024-05-23 19:57:33 [INFO]: Epoch 054 - training loss: 0.2605, validation loss: 0.2571
2024-05-23 19:57:34 [INFO]: Epoch 055 - training loss: 0.2613, validation loss: 0.2574
2024-05-23 19:57:36 [INFO]: Epoch 056 - training loss: 0.2584, validation loss: 0.2553
2024-05-23 19:57:37 [INFO]: Epoch 057 - training loss: 0.2559, validation loss: 0.2591
2024-05-23 19:57:38 [INFO]: Epoch 058 - training loss: 0.2568, validation loss: 0.2592
2024-05-23 19:57:40 [INFO]: Epoch 059 - training loss: 0.2545, validation loss: 0.2526
2024-05-23 19:57:41 [INFO]: Epoch 060 - training loss: 0.2613, validation loss: 0.2560
2024-05-23 19:57:42 [INFO]: Epoch 061 - training loss: 0.2583, validation loss: 0.2547
2024-05-23 19:57:43 [INFO]: Epoch 062 - training loss: 0.2568, validation loss: 0.2602
2024-05-23 19:57:45 [INFO]: Epoch 063 - training loss: 0.2580, validation loss: 0.2547
2024-05-23 19:57:46 [INFO]: Epoch 064 - training loss: 0.2593, validation loss: 0.2497
2024-05-23 19:57:47 [INFO]: Epoch 065 - training loss: 0.2541, validation loss: 0.2510
2024-05-23 19:57:48 [INFO]: Epoch 066 - training loss: 0.2523, validation loss: 0.2553
2024-05-23 19:57:50 [INFO]: Epoch 067 - training loss: 0.2520, validation loss: 0.2543
2024-05-23 19:57:51 [INFO]: Epoch 068 - training loss: 0.2501, validation loss: 0.2521
2024-05-23 19:57:52 [INFO]: Epoch 069 - training loss: 0.2532, validation loss: 0.2489
2024-05-23 19:57:54 [INFO]: Epoch 070 - training loss: 0.2520, validation loss: 0.2498
2024-05-23 19:57:55 [INFO]: Epoch 071 - training loss: 0.2519, validation loss: 0.2501
2024-05-23 19:57:56 [INFO]: Epoch 072 - training loss: 0.2501, validation loss: 0.2507
2024-05-23 19:57:57 [INFO]: Epoch 073 - training loss: 0.2502, validation loss: 0.2490
2024-05-23 19:57:59 [INFO]: Epoch 074 - training loss: 0.2523, validation loss: 0.2509
2024-05-23 19:58:00 [INFO]: Epoch 075 - training loss: 0.2490, validation loss: 0.2497
2024-05-23 19:58:01 [INFO]: Epoch 076 - training loss: 0.2504, validation loss: 0.2472
2024-05-23 19:58:02 [INFO]: Epoch 077 - training loss: 0.2492, validation loss: 0.2503
2024-05-23 19:58:04 [INFO]: Epoch 078 - training loss: 0.2469, validation loss: 0.2547
2024-05-23 19:58:05 [INFO]: Epoch 079 - training loss: 0.2487, validation loss: 0.2565
2024-05-23 19:58:06 [INFO]: Epoch 080 - training loss: 0.2481, validation loss: 0.2499
2024-05-23 19:58:08 [INFO]: Epoch 081 - training loss: 0.2468, validation loss: 0.2493
2024-05-23 19:58:09 [INFO]: Epoch 082 - training loss: 0.2479, validation loss: 0.2514
2024-05-23 19:58:10 [INFO]: Epoch 083 - training loss: 0.2438, validation loss: 0.2508
2024-05-23 19:58:11 [INFO]: Epoch 084 - training loss: 0.2468, validation loss: 0.2468
2024-05-23 19:58:13 [INFO]: Epoch 085 - training loss: 0.2462, validation loss: 0.2500
2024-05-23 19:58:14 [INFO]: Epoch 086 - training loss: 0.2444, validation loss: 0.2523
2024-05-23 19:58:15 [INFO]: Epoch 087 - training loss: 0.2453, validation loss: 0.2492
2024-05-23 19:58:17 [INFO]: Epoch 088 - training loss: 0.2451, validation loss: 0.2446
2024-05-23 19:58:18 [INFO]: Epoch 089 - training loss: 0.2439, validation loss: 0.2466
2024-05-23 19:58:19 [INFO]: Epoch 090 - training loss: 0.2427, validation loss: 0.2449
2024-05-23 19:58:20 [INFO]: Epoch 091 - training loss: 0.2436, validation loss: 0.2496
2024-05-23 19:58:22 [INFO]: Epoch 092 - training loss: 0.2427, validation loss: 0.2498
2024-05-23 19:58:23 [INFO]: Epoch 093 - training loss: 0.2421, validation loss: 0.2425
2024-05-23 19:58:24 [INFO]: Epoch 094 - training loss: 0.2389, validation loss: 0.2491
2024-05-23 19:58:25 [INFO]: Epoch 095 - training loss: 0.2427, validation loss: 0.2469
2024-05-23 19:58:27 [INFO]: Epoch 096 - training loss: 0.2414, validation loss: 0.2495
2024-05-23 19:58:28 [INFO]: Epoch 097 - training loss: 0.2399, validation loss: 0.2478
2024-05-23 19:58:29 [INFO]: Epoch 098 - training loss: 0.2407, validation loss: 0.2505
2024-05-23 19:58:31 [INFO]: Epoch 099 - training loss: 0.2398, validation loss: 0.2471
2024-05-23 19:58:32 [INFO]: Epoch 100 - training loss: 0.2405, validation loss: 0.2445
2024-05-23 19:58:33 [INFO]: Epoch 101 - training loss: 0.2405, validation loss: 0.2444
2024-05-23 19:58:34 [INFO]: Epoch 102 - training loss: 0.2432, validation loss: 0.2517
2024-05-23 19:58:36 [INFO]: Epoch 103 - training loss: 0.2412, validation loss: 0.2471
2024-05-23 19:58:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:58:36 [INFO]: Finished training. The best model is from epoch#93.
2024-05-23 19:58:36 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T195625/SAITS.pypots
2024-05-23 19:58:36 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2086, MSE=0.2687
2024-05-23 19:58:36 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:58:36 [INFO]: Using the given device: cuda:0
2024-05-23 19:58:36 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T195836
2024-05-23 19:58:36 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T195836/tensorboard
2024-05-23 19:58:36 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 19:58:37 [INFO]: Epoch 001 - training loss: 1.1929, validation loss: 0.5726
2024-05-23 19:58:38 [INFO]: Epoch 002 - training loss: 0.7483, validation loss: 0.4977
2024-05-23 19:58:38 [INFO]: Epoch 003 - training loss: 0.6377, validation loss: 0.4635
2024-05-23 19:58:39 [INFO]: Epoch 004 - training loss: 0.5798, validation loss: 0.4378
2024-05-23 19:58:40 [INFO]: Epoch 005 - training loss: 0.5405, validation loss: 0.4288
2024-05-23 19:58:40 [INFO]: Epoch 006 - training loss: 0.5192, validation loss: 0.4120
2024-05-23 19:58:41 [INFO]: Epoch 007 - training loss: 0.4966, validation loss: 0.4017
2024-05-23 19:58:42 [INFO]: Epoch 008 - training loss: 0.4792, validation loss: 0.3980
2024-05-23 19:58:43 [INFO]: Epoch 009 - training loss: 0.4554, validation loss: 0.3867
2024-05-23 19:58:43 [INFO]: Epoch 010 - training loss: 0.4468, validation loss: 0.3788
2024-05-23 19:58:44 [INFO]: Epoch 011 - training loss: 0.4327, validation loss: 0.3753
2024-05-23 19:58:45 [INFO]: Epoch 012 - training loss: 0.4303, validation loss: 0.3672
2024-05-23 19:58:45 [INFO]: Epoch 013 - training loss: 0.4191, validation loss: 0.3636
2024-05-23 19:58:46 [INFO]: Epoch 014 - training loss: 0.4093, validation loss: 0.3533
2024-05-23 19:58:47 [INFO]: Epoch 015 - training loss: 0.4027, validation loss: 0.3537
2024-05-23 19:58:47 [INFO]: Epoch 016 - training loss: 0.3910, validation loss: 0.3492
2024-05-23 19:58:48 [INFO]: Epoch 017 - training loss: 0.3833, validation loss: 0.3438
2024-05-23 19:58:49 [INFO]: Epoch 018 - training loss: 0.3810, validation loss: 0.3396
2024-05-23 19:58:49 [INFO]: Epoch 019 - training loss: 0.3781, validation loss: 0.3343
2024-05-23 19:58:50 [INFO]: Epoch 020 - training loss: 0.3747, validation loss: 0.3348
2024-05-23 19:58:51 [INFO]: Epoch 021 - training loss: 0.3693, validation loss: 0.3328
2024-05-23 19:58:52 [INFO]: Epoch 022 - training loss: 0.3644, validation loss: 0.3359
2024-05-23 19:58:52 [INFO]: Epoch 023 - training loss: 0.3599, validation loss: 0.3273
2024-05-23 19:58:53 [INFO]: Epoch 024 - training loss: 0.3530, validation loss: 0.3232
2024-05-23 19:58:54 [INFO]: Epoch 025 - training loss: 0.3492, validation loss: 0.3209
2024-05-23 19:58:54 [INFO]: Epoch 026 - training loss: 0.3549, validation loss: 0.3211
2024-05-23 19:58:55 [INFO]: Epoch 027 - training loss: 0.3427, validation loss: 0.3172
2024-05-23 19:58:56 [INFO]: Epoch 028 - training loss: 0.3389, validation loss: 0.3138
2024-05-23 19:58:56 [INFO]: Epoch 029 - training loss: 0.3405, validation loss: 0.3125
2024-05-23 19:58:57 [INFO]: Epoch 030 - training loss: 0.3377, validation loss: 0.3146
2024-05-23 19:58:58 [INFO]: Epoch 031 - training loss: 0.3388, validation loss: 0.3123
2024-05-23 19:58:58 [INFO]: Epoch 032 - training loss: 0.3309, validation loss: 0.3103
2024-05-23 19:58:59 [INFO]: Epoch 033 - training loss: 0.3282, validation loss: 0.3073
2024-05-23 19:59:00 [INFO]: Epoch 034 - training loss: 0.3284, validation loss: 0.3063
2024-05-23 19:59:01 [INFO]: Epoch 035 - training loss: 0.3252, validation loss: 0.3049
2024-05-23 19:59:01 [INFO]: Epoch 036 - training loss: 0.3208, validation loss: 0.3060
2024-05-23 19:59:02 [INFO]: Epoch 037 - training loss: 0.3230, validation loss: 0.3017
2024-05-23 19:59:03 [INFO]: Epoch 038 - training loss: 0.3223, validation loss: 0.2990
2024-05-23 19:59:03 [INFO]: Epoch 039 - training loss: 0.3191, validation loss: 0.3010
2024-05-23 19:59:04 [INFO]: Epoch 040 - training loss: 0.3208, validation loss: 0.2984
2024-05-23 19:59:05 [INFO]: Epoch 041 - training loss: 0.3162, validation loss: 0.2943
2024-05-23 19:59:05 [INFO]: Epoch 042 - training loss: 0.3135, validation loss: 0.3008
2024-05-23 19:59:06 [INFO]: Epoch 043 - training loss: 0.3146, validation loss: 0.2936
2024-05-23 19:59:07 [INFO]: Epoch 044 - training loss: 0.3112, validation loss: 0.2945
2024-05-23 19:59:08 [INFO]: Epoch 045 - training loss: 0.3118, validation loss: 0.2908
2024-05-23 19:59:08 [INFO]: Epoch 046 - training loss: 0.3147, validation loss: 0.2926
2024-05-23 19:59:09 [INFO]: Epoch 047 - training loss: 0.3114, validation loss: 0.2907
2024-05-23 19:59:10 [INFO]: Epoch 048 - training loss: 0.3082, validation loss: 0.2883
2024-05-23 19:59:10 [INFO]: Epoch 049 - training loss: 0.3031, validation loss: 0.2966
2024-05-23 19:59:11 [INFO]: Epoch 050 - training loss: 0.3069, validation loss: 0.2873
2024-05-23 19:59:12 [INFO]: Epoch 051 - training loss: 0.3031, validation loss: 0.2809
2024-05-23 19:59:12 [INFO]: Epoch 052 - training loss: 0.3009, validation loss: 0.2792
2024-05-23 19:59:13 [INFO]: Epoch 053 - training loss: 0.2999, validation loss: 0.2868
2024-05-23 19:59:14 [INFO]: Epoch 054 - training loss: 0.2986, validation loss: 0.2810
2024-05-23 19:59:14 [INFO]: Epoch 055 - training loss: 0.2995, validation loss: 0.2772
2024-05-23 19:59:15 [INFO]: Epoch 056 - training loss: 0.2963, validation loss: 0.2794
2024-05-23 19:59:16 [INFO]: Epoch 057 - training loss: 0.2962, validation loss: 0.2814
2024-05-23 19:59:17 [INFO]: Epoch 058 - training loss: 0.2968, validation loss: 0.2817
2024-05-23 19:59:17 [INFO]: Epoch 059 - training loss: 0.2952, validation loss: 0.2743
2024-05-23 19:59:18 [INFO]: Epoch 060 - training loss: 0.2949, validation loss: 0.2750
2024-05-23 19:59:19 [INFO]: Epoch 061 - training loss: 0.2941, validation loss: 0.2721
2024-05-23 19:59:19 [INFO]: Epoch 062 - training loss: 0.2912, validation loss: 0.2710
2024-05-23 19:59:20 [INFO]: Epoch 063 - training loss: 0.2915, validation loss: 0.2759
2024-05-23 19:59:21 [INFO]: Epoch 064 - training loss: 0.2927, validation loss: 0.2742
2024-05-23 19:59:21 [INFO]: Epoch 065 - training loss: 0.2939, validation loss: 0.2708
2024-05-23 19:59:22 [INFO]: Epoch 066 - training loss: 0.2875, validation loss: 0.2714
2024-05-23 19:59:23 [INFO]: Epoch 067 - training loss: 0.2884, validation loss: 0.2690
2024-05-23 19:59:23 [INFO]: Epoch 068 - training loss: 0.2885, validation loss: 0.2722
2024-05-23 19:59:24 [INFO]: Epoch 069 - training loss: 0.2867, validation loss: 0.2699
2024-05-23 19:59:25 [INFO]: Epoch 070 - training loss: 0.2865, validation loss: 0.2689
2024-05-23 19:59:26 [INFO]: Epoch 071 - training loss: 0.2862, validation loss: 0.2659
2024-05-23 19:59:26 [INFO]: Epoch 072 - training loss: 0.2831, validation loss: 0.2703
2024-05-23 19:59:27 [INFO]: Epoch 073 - training loss: 0.2816, validation loss: 0.2704
2024-05-23 19:59:28 [INFO]: Epoch 074 - training loss: 0.2848, validation loss: 0.2661
2024-05-23 19:59:28 [INFO]: Epoch 075 - training loss: 0.2843, validation loss: 0.2704
2024-05-23 19:59:29 [INFO]: Epoch 076 - training loss: 0.2822, validation loss: 0.2681
2024-05-23 19:59:30 [INFO]: Epoch 077 - training loss: 0.2840, validation loss: 0.2701
2024-05-23 19:59:30 [INFO]: Epoch 078 - training loss: 0.2836, validation loss: 0.2696
2024-05-23 19:59:31 [INFO]: Epoch 079 - training loss: 0.2800, validation loss: 0.2658
2024-05-23 19:59:32 [INFO]: Epoch 080 - training loss: 0.2819, validation loss: 0.2672
2024-05-23 19:59:33 [INFO]: Epoch 081 - training loss: 0.2779, validation loss: 0.2653
2024-05-23 19:59:33 [INFO]: Epoch 082 - training loss: 0.2767, validation loss: 0.2636
2024-05-23 19:59:34 [INFO]: Epoch 083 - training loss: 0.2791, validation loss: 0.2649
2024-05-23 19:59:35 [INFO]: Epoch 084 - training loss: 0.2792, validation loss: 0.2654
2024-05-23 19:59:35 [INFO]: Epoch 085 - training loss: 0.2750, validation loss: 0.2646
2024-05-23 19:59:36 [INFO]: Epoch 086 - training loss: 0.2792, validation loss: 0.2624
2024-05-23 19:59:37 [INFO]: Epoch 087 - training loss: 0.2751, validation loss: 0.2643
2024-05-23 19:59:37 [INFO]: Epoch 088 - training loss: 0.2766, validation loss: 0.2628
2024-05-23 19:59:38 [INFO]: Epoch 089 - training loss: 0.2756, validation loss: 0.2670
2024-05-23 19:59:39 [INFO]: Epoch 090 - training loss: 0.2731, validation loss: 0.2620
2024-05-23 19:59:39 [INFO]: Epoch 091 - training loss: 0.2725, validation loss: 0.2629
2024-05-23 19:59:40 [INFO]: Epoch 092 - training loss: 0.2756, validation loss: 0.2648
2024-05-23 19:59:41 [INFO]: Epoch 093 - training loss: 0.2746, validation loss: 0.2622
2024-05-23 19:59:42 [INFO]: Epoch 094 - training loss: 0.2719, validation loss: 0.2666
2024-05-23 19:59:42 [INFO]: Epoch 095 - training loss: 0.2743, validation loss: 0.2646
2024-05-23 19:59:43 [INFO]: Epoch 096 - training loss: 0.2698, validation loss: 0.2606
2024-05-23 19:59:44 [INFO]: Epoch 097 - training loss: 0.2682, validation loss: 0.2589
2024-05-23 19:59:44 [INFO]: Epoch 098 - training loss: 0.2704, validation loss: 0.2632
2024-05-23 19:59:45 [INFO]: Epoch 099 - training loss: 0.2697, validation loss: 0.2603
2024-05-23 19:59:46 [INFO]: Epoch 100 - training loss: 0.2702, validation loss: 0.2626
2024-05-23 19:59:46 [INFO]: Epoch 101 - training loss: 0.2679, validation loss: 0.2646
2024-05-23 19:59:47 [INFO]: Epoch 102 - training loss: 0.2695, validation loss: 0.2629
2024-05-23 19:59:48 [INFO]: Epoch 103 - training loss: 0.2704, validation loss: 0.2599
2024-05-23 19:59:48 [INFO]: Epoch 104 - training loss: 0.2678, validation loss: 0.2585
2024-05-23 19:59:49 [INFO]: Epoch 105 - training loss: 0.2646, validation loss: 0.2610
2024-05-23 19:59:50 [INFO]: Epoch 106 - training loss: 0.2671, validation loss: 0.2541
2024-05-23 19:59:51 [INFO]: Epoch 107 - training loss: 0.2677, validation loss: 0.2589
2024-05-23 19:59:51 [INFO]: Epoch 108 - training loss: 0.2679, validation loss: 0.2599
2024-05-23 19:59:52 [INFO]: Epoch 109 - training loss: 0.2672, validation loss: 0.2601
2024-05-23 19:59:53 [INFO]: Epoch 110 - training loss: 0.2674, validation loss: 0.2589
2024-05-23 19:59:53 [INFO]: Epoch 111 - training loss: 0.2630, validation loss: 0.2634
2024-05-23 19:59:54 [INFO]: Epoch 112 - training loss: 0.2651, validation loss: 0.2603
2024-05-23 19:59:55 [INFO]: Epoch 113 - training loss: 0.2649, validation loss: 0.2568
2024-05-23 19:59:55 [INFO]: Epoch 114 - training loss: 0.2619, validation loss: 0.2612
2024-05-23 19:59:56 [INFO]: Epoch 115 - training loss: 0.2623, validation loss: 0.2554
2024-05-23 19:59:57 [INFO]: Epoch 116 - training loss: 0.2650, validation loss: 0.2565
2024-05-23 19:59:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:59:57 [INFO]: Finished training. The best model is from epoch#106.
2024-05-23 19:59:57 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T195836/Transformer.pypots
2024-05-23 19:59:57 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2202, MSE=0.2707
2024-05-23 19:59:57 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 19:59:57 [INFO]: Using the given device: cuda:0
2024-05-23 19:59:57 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T195957
2024-05-23 19:59:57 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T195957/tensorboard
2024-05-23 19:59:57 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 19:59:58 [INFO]: Epoch 001 - training loss: 0.5461, validation loss: 0.9025
2024-05-23 19:59:59 [INFO]: Epoch 002 - training loss: 0.4291, validation loss: 0.9452
2024-05-23 20:00:00 [INFO]: Epoch 003 - training loss: 0.5778, validation loss: 0.5468
2024-05-23 20:00:01 [INFO]: Epoch 004 - training loss: 0.4459, validation loss: 0.3857
2024-05-23 20:00:01 [INFO]: Epoch 005 - training loss: 0.4899, validation loss: 0.3330
2024-05-23 20:00:02 [INFO]: Epoch 006 - training loss: 0.3581, validation loss: 0.3261
2024-05-23 20:00:03 [INFO]: Epoch 007 - training loss: 0.3686, validation loss: 0.3663
2024-05-23 20:00:04 [INFO]: Epoch 008 - training loss: 0.3555, validation loss: 0.3362
2024-05-23 20:00:05 [INFO]: Epoch 009 - training loss: 0.3250, validation loss: 0.3245
2024-05-23 20:00:05 [INFO]: Epoch 010 - training loss: 0.3166, validation loss: 0.3145
2024-05-23 20:00:06 [INFO]: Epoch 011 - training loss: 0.3536, validation loss: 0.3488
2024-05-23 20:00:07 [INFO]: Epoch 012 - training loss: 0.4061, validation loss: 0.3222
2024-05-23 20:00:08 [INFO]: Epoch 013 - training loss: 0.3622, validation loss: 0.3134
2024-05-23 20:00:09 [INFO]: Epoch 014 - training loss: 0.3322, validation loss: 0.3108
2024-05-23 20:00:09 [INFO]: Epoch 015 - training loss: 0.3374, validation loss: 0.3293
2024-05-23 20:00:10 [INFO]: Epoch 016 - training loss: 0.3270, validation loss: 0.3064
2024-05-23 20:00:11 [INFO]: Epoch 017 - training loss: 0.3249, validation loss: 0.3083
2024-05-23 20:00:12 [INFO]: Epoch 018 - training loss: 0.3208, validation loss: 0.2979
2024-05-23 20:00:13 [INFO]: Epoch 019 - training loss: 0.3296, validation loss: 0.2977
2024-05-23 20:00:13 [INFO]: Epoch 020 - training loss: 0.3756, validation loss: 0.3058
2024-05-23 20:00:14 [INFO]: Epoch 021 - training loss: 0.3045, validation loss: 0.3057
2024-05-23 20:00:15 [INFO]: Epoch 022 - training loss: 0.3166, validation loss: 0.2994
2024-05-23 20:00:16 [INFO]: Epoch 023 - training loss: 0.3445, validation loss: 0.3332
2024-05-23 20:00:17 [INFO]: Epoch 024 - training loss: 0.3049, validation loss: 0.3694
2024-05-23 20:00:17 [INFO]: Epoch 025 - training loss: 0.3323, validation loss: 0.3845
2024-05-23 20:00:18 [INFO]: Epoch 026 - training loss: 0.3005, validation loss: 0.3100
2024-05-23 20:00:19 [INFO]: Epoch 027 - training loss: 0.3038, validation loss: 0.3001
2024-05-23 20:00:20 [INFO]: Epoch 028 - training loss: 0.3388, validation loss: 0.3813
2024-05-23 20:00:21 [INFO]: Epoch 029 - training loss: 0.3309, validation loss: 0.3352
2024-05-23 20:00:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:00:21 [INFO]: Finished training. The best model is from epoch#19.
2024-05-23 20:00:21 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T195957/TimesNet.pypots
2024-05-23 20:00:21 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.3158, MSE=0.3652
2024-05-23 20:00:21 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 20:00:21 [INFO]: Using the given device: cuda:0
2024-05-23 20:00:21 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021
2024-05-23 20:00:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/tensorboard
2024-05-23 20:00:21 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 20:01:05 [INFO]: Epoch 001 - training loss: 0.4226, validation loss: 0.3404
2024-05-23 20:01:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch1_loss0.3404017224907875.pypots
2024-05-23 20:01:48 [INFO]: Epoch 002 - training loss: 0.3168, validation loss: 0.2940
2024-05-23 20:01:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch2_loss0.29398567229509354.pypots
2024-05-23 20:02:32 [INFO]: Epoch 003 - training loss: 0.2918, validation loss: 0.2545
2024-05-23 20:02:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch3_loss0.254452683031559.pypots
2024-05-23 20:03:15 [INFO]: Epoch 004 - training loss: 0.2652, validation loss: 0.2401
2024-05-23 20:03:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch4_loss0.24009652361273764.pypots
2024-05-23 20:03:59 [INFO]: Epoch 005 - training loss: 0.2634, validation loss: 0.2236
2024-05-23 20:03:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch5_loss0.22357061132788658.pypots
2024-05-23 20:04:43 [INFO]: Epoch 006 - training loss: 0.2609, validation loss: 0.2199
2024-05-23 20:04:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch6_loss0.21992846205830574.pypots
2024-05-23 20:05:27 [INFO]: Epoch 007 - training loss: 0.2445, validation loss: 0.2161
2024-05-23 20:05:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch7_loss0.21607506945729255.pypots
2024-05-23 20:06:11 [INFO]: Epoch 008 - training loss: 0.2507, validation loss: 0.2089
2024-05-23 20:06:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch8_loss0.20887889340519905.pypots
2024-05-23 20:06:55 [INFO]: Epoch 009 - training loss: 0.2374, validation loss: 0.2035
2024-05-23 20:06:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch9_loss0.20349502712488174.pypots
2024-05-23 20:07:39 [INFO]: Epoch 010 - training loss: 0.2527, validation loss: 0.2038
2024-05-23 20:07:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch10_loss0.20376612544059752.pypots
2024-05-23 20:08:23 [INFO]: Epoch 011 - training loss: 0.2482, validation loss: 0.2058
2024-05-23 20:08:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch11_loss0.2057965114712715.pypots
2024-05-23 20:09:07 [INFO]: Epoch 012 - training loss: 0.2323, validation loss: 0.2017
2024-05-23 20:09:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch12_loss0.20173244327306747.pypots
2024-05-23 20:09:51 [INFO]: Epoch 013 - training loss: 0.2340, validation loss: 0.1987
2024-05-23 20:09:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch13_loss0.19867396578192711.pypots
2024-05-23 20:10:34 [INFO]: Epoch 014 - training loss: 0.2355, validation loss: 0.1969
2024-05-23 20:10:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch14_loss0.1968726098537445.pypots
2024-05-23 20:11:18 [INFO]: Epoch 015 - training loss: 0.2452, validation loss: 0.1957
2024-05-23 20:11:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch15_loss0.19568051248788834.pypots
2024-05-23 20:12:01 [INFO]: Epoch 016 - training loss: 0.2398, validation loss: 0.1943
2024-05-23 20:12:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch16_loss0.19431557059288024.pypots
2024-05-23 20:12:45 [INFO]: Epoch 017 - training loss: 0.2395, validation loss: 0.1956
2024-05-23 20:12:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch17_loss0.19556018635630606.pypots
2024-05-23 20:13:28 [INFO]: Epoch 018 - training loss: 0.2336, validation loss: 0.1988
2024-05-23 20:13:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch18_loss0.19876011535525323.pypots
2024-05-23 20:14:12 [INFO]: Epoch 019 - training loss: 0.2380, validation loss: 0.1940
2024-05-23 20:14:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch19_loss0.19401681125164033.pypots
2024-05-23 20:14:55 [INFO]: Epoch 020 - training loss: 0.2262, validation loss: 0.1928
2024-05-23 20:14:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch20_loss0.19281721711158753.pypots
2024-05-23 20:15:39 [INFO]: Epoch 021 - training loss: 0.2281, validation loss: 0.1890
2024-05-23 20:15:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch21_loss0.18896427005529404.pypots
2024-05-23 20:16:23 [INFO]: Epoch 022 - training loss: 0.2383, validation loss: 0.1912
2024-05-23 20:16:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch22_loss0.1912403129041195.pypots
2024-05-23 20:17:08 [INFO]: Epoch 023 - training loss: 0.2247, validation loss: 0.1919
2024-05-23 20:17:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch23_loss0.19186634942889214.pypots
2024-05-23 20:17:52 [INFO]: Epoch 024 - training loss: 0.2276, validation loss: 0.1885
2024-05-23 20:17:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch24_loss0.18853009715676308.pypots
2024-05-23 20:18:35 [INFO]: Epoch 025 - training loss: 0.2185, validation loss: 0.1897
2024-05-23 20:18:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch25_loss0.1897488735616207.pypots
2024-05-23 20:19:19 [INFO]: Epoch 026 - training loss: 0.2337, validation loss: 0.1872
2024-05-23 20:19:19 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch26_loss0.18715015798807144.pypots
2024-05-23 20:20:03 [INFO]: Epoch 027 - training loss: 0.2266, validation loss: 0.1896
2024-05-23 20:20:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch27_loss0.1896416999399662.pypots
2024-05-23 20:20:47 [INFO]: Epoch 028 - training loss: 0.2258, validation loss: 0.1883
2024-05-23 20:20:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch28_loss0.18832902014255523.pypots
2024-05-23 20:21:30 [INFO]: Epoch 029 - training loss: 0.2198, validation loss: 0.1870
2024-05-23 20:21:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch29_loss0.18703701272606849.pypots
2024-05-23 20:22:14 [INFO]: Epoch 030 - training loss: 0.2278, validation loss: 0.1899
2024-05-23 20:22:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch30_loss0.18989022374153136.pypots
2024-05-23 20:22:57 [INFO]: Epoch 031 - training loss: 0.2237, validation loss: 0.1874
2024-05-23 20:22:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch31_loss0.18738591223955153.pypots
2024-05-23 20:23:41 [INFO]: Epoch 032 - training loss: 0.2149, validation loss: 0.1869
2024-05-23 20:23:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch32_loss0.18688022270798682.pypots
2024-05-23 20:24:25 [INFO]: Epoch 033 - training loss: 0.2307, validation loss: 0.1875
2024-05-23 20:24:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch33_loss0.187528033554554.pypots
2024-05-23 20:25:09 [INFO]: Epoch 034 - training loss: 0.2153, validation loss: 0.1842
2024-05-23 20:25:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch34_loss0.1841509036719799.pypots
2024-05-23 20:25:53 [INFO]: Epoch 035 - training loss: 0.2349, validation loss: 0.1845
2024-05-23 20:25:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch35_loss0.18449908792972564.pypots
2024-05-23 20:26:37 [INFO]: Epoch 036 - training loss: 0.2243, validation loss: 0.1823
2024-05-23 20:26:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch36_loss0.1823033183813095.pypots
2024-05-23 20:27:20 [INFO]: Epoch 037 - training loss: 0.2161, validation loss: 0.1849
2024-05-23 20:27:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch37_loss0.18492487221956252.pypots
2024-05-23 20:28:04 [INFO]: Epoch 038 - training loss: 0.2178, validation loss: 0.1816
2024-05-23 20:28:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch38_loss0.18155122101306914.pypots
2024-05-23 20:28:48 [INFO]: Epoch 039 - training loss: 0.2279, validation loss: 0.1828
2024-05-23 20:28:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch39_loss0.18280268087983131.pypots
2024-05-23 20:29:32 [INFO]: Epoch 040 - training loss: 0.2301, validation loss: 0.1848
2024-05-23 20:29:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch40_loss0.18483738005161285.pypots
2024-05-23 20:30:15 [INFO]: Epoch 041 - training loss: 0.2124, validation loss: 0.1837
2024-05-23 20:30:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch41_loss0.1836612343788147.pypots
2024-05-23 20:30:59 [INFO]: Epoch 042 - training loss: 0.2258, validation loss: 0.1863
2024-05-23 20:30:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch42_loss0.1863439328968525.pypots
2024-05-23 20:31:43 [INFO]: Epoch 043 - training loss: 0.2248, validation loss: 0.1805
2024-05-23 20:31:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch43_loss0.18045739606022834.pypots
2024-05-23 20:32:27 [INFO]: Epoch 044 - training loss: 0.2296, validation loss: 0.1836
2024-05-23 20:32:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch44_loss0.18358168229460717.pypots
2024-05-23 20:33:11 [INFO]: Epoch 045 - training loss: 0.2206, validation loss: 0.1784
2024-05-23 20:33:11 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch45_loss0.17843239083886148.pypots
2024-05-23 20:33:54 [INFO]: Epoch 046 - training loss: 0.2263, validation loss: 0.1836
2024-05-23 20:33:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch46_loss0.1835947662591934.pypots
2024-05-23 20:34:38 [INFO]: Epoch 047 - training loss: 0.2201, validation loss: 0.1812
2024-05-23 20:34:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch47_loss0.18119025304913522.pypots
2024-05-23 20:35:22 [INFO]: Epoch 048 - training loss: 0.2277, validation loss: 0.1791
2024-05-23 20:35:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch48_loss0.1791181094944477.pypots
2024-05-23 20:36:06 [INFO]: Epoch 049 - training loss: 0.2229, validation loss: 0.1782
2024-05-23 20:36:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch49_loss0.1782127283513546.pypots
2024-05-23 20:36:50 [INFO]: Epoch 050 - training loss: 0.2217, validation loss: 0.1805
2024-05-23 20:36:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch50_loss0.18054268434643744.pypots
2024-05-23 20:37:34 [INFO]: Epoch 051 - training loss: 0.2158, validation loss: 0.1805
2024-05-23 20:37:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch51_loss0.18054909035563468.pypots
2024-05-23 20:38:18 [INFO]: Epoch 052 - training loss: 0.2263, validation loss: 0.1796
2024-05-23 20:38:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch52_loss0.17964354977011682.pypots
2024-05-23 20:39:02 [INFO]: Epoch 053 - training loss: 0.2188, validation loss: 0.1810
2024-05-23 20:39:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch53_loss0.18096627816557884.pypots
2024-05-23 20:39:45 [INFO]: Epoch 054 - training loss: 0.2225, validation loss: 0.1818
2024-05-23 20:39:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch54_loss0.18176994249224662.pypots
2024-05-23 20:40:29 [INFO]: Epoch 055 - training loss: 0.2099, validation loss: 0.1779
2024-05-23 20:40:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch55_loss0.17787031307816506.pypots
2024-05-23 20:41:13 [INFO]: Epoch 056 - training loss: 0.2203, validation loss: 0.1778
2024-05-23 20:41:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch56_loss0.17775595039129258.pypots
2024-05-23 20:41:56 [INFO]: Epoch 057 - training loss: 0.2180, validation loss: 0.1771
2024-05-23 20:41:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch57_loss0.17712387070059776.pypots
2024-05-23 20:42:40 [INFO]: Epoch 058 - training loss: 0.2264, validation loss: 0.1792
2024-05-23 20:42:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch58_loss0.17924805730581284.pypots
2024-05-23 20:43:24 [INFO]: Epoch 059 - training loss: 0.2309, validation loss: 0.1773
2024-05-23 20:43:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch59_loss0.17730878964066504.pypots
2024-05-23 20:44:08 [INFO]: Epoch 060 - training loss: 0.2140, validation loss: 0.1774
2024-05-23 20:44:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch60_loss0.1774003155529499.pypots
2024-05-23 20:44:52 [INFO]: Epoch 061 - training loss: 0.2117, validation loss: 0.1815
2024-05-23 20:44:52 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch61_loss0.1815274864435196.pypots
2024-05-23 20:45:36 [INFO]: Epoch 062 - training loss: 0.2187, validation loss: 0.1777
2024-05-23 20:45:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch62_loss0.17770432457327842.pypots
2024-05-23 20:46:20 [INFO]: Epoch 063 - training loss: 0.2198, validation loss: 0.1763
2024-05-23 20:46:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch63_loss0.17632784321904182.pypots
2024-05-23 20:47:04 [INFO]: Epoch 064 - training loss: 0.2145, validation loss: 0.1768
2024-05-23 20:47:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch64_loss0.17681842744350434.pypots
2024-05-23 20:47:48 [INFO]: Epoch 065 - training loss: 0.2250, validation loss: 0.1781
2024-05-23 20:47:48 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch65_loss0.17811951339244841.pypots
2024-05-23 20:48:32 [INFO]: Epoch 066 - training loss: 0.2135, validation loss: 0.1768
2024-05-23 20:48:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch66_loss0.17680309414863588.pypots
2024-05-23 20:49:15 [INFO]: Epoch 067 - training loss: 0.2153, validation loss: 0.1770
2024-05-23 20:49:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch67_loss0.177039535343647.pypots
2024-05-23 20:49:59 [INFO]: Epoch 068 - training loss: 0.2211, validation loss: 0.1784
2024-05-23 20:49:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch68_loss0.17840718775987624.pypots
2024-05-23 20:50:42 [INFO]: Epoch 069 - training loss: 0.2196, validation loss: 0.1765
2024-05-23 20:50:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch69_loss0.17652803510427476.pypots
2024-05-23 20:51:26 [INFO]: Epoch 070 - training loss: 0.2187, validation loss: 0.1775
2024-05-23 20:51:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch70_loss0.17748285159468652.pypots
2024-05-23 20:52:09 [INFO]: Epoch 071 - training loss: 0.2151, validation loss: 0.1778
2024-05-23 20:52:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch71_loss0.17784918174147607.pypots
2024-05-23 20:52:53 [INFO]: Epoch 072 - training loss: 0.2158, validation loss: 0.1743
2024-05-23 20:52:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch72_loss0.17432332485914231.pypots
2024-05-23 20:53:36 [INFO]: Epoch 073 - training loss: 0.2183, validation loss: 0.1748
2024-05-23 20:53:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch73_loss0.17484063059091567.pypots
2024-05-23 20:54:20 [INFO]: Epoch 074 - training loss: 0.2174, validation loss: 0.1744
2024-05-23 20:54:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch74_loss0.1744304671883583.pypots
2024-05-23 20:55:03 [INFO]: Epoch 075 - training loss: 0.2297, validation loss: 0.1764
2024-05-23 20:55:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch75_loss0.17641628310084342.pypots
2024-05-23 20:55:47 [INFO]: Epoch 076 - training loss: 0.2087, validation loss: 0.1780
2024-05-23 20:55:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch76_loss0.17802388072013856.pypots
2024-05-23 20:56:30 [INFO]: Epoch 077 - training loss: 0.2071, validation loss: 0.1781
2024-05-23 20:56:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch77_loss0.17813739851117133.pypots
2024-05-23 20:57:14 [INFO]: Epoch 078 - training loss: 0.2242, validation loss: 0.1794
2024-05-23 20:57:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch78_loss0.17944543585181236.pypots
2024-05-23 20:57:58 [INFO]: Epoch 079 - training loss: 0.2261, validation loss: 0.1763
2024-05-23 20:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch79_loss0.1762545019388199.pypots
2024-05-23 20:58:41 [INFO]: Epoch 080 - training loss: 0.2183, validation loss: 0.1757
2024-05-23 20:58:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch80_loss0.17570561170578003.pypots
2024-05-23 20:59:25 [INFO]: Epoch 081 - training loss: 0.2162, validation loss: 0.1738
2024-05-23 20:59:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch81_loss0.17375603541731835.pypots
2024-05-23 21:00:09 [INFO]: Epoch 082 - training loss: 0.2224, validation loss: 0.1750
2024-05-23 21:00:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch82_loss0.17501578778028487.pypots
2024-05-23 21:00:54 [INFO]: Epoch 083 - training loss: 0.2205, validation loss: 0.1747
2024-05-23 21:00:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch83_loss0.1746988371014595.pypots
2024-05-23 21:01:38 [INFO]: Epoch 084 - training loss: 0.2198, validation loss: 0.1749
2024-05-23 21:01:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch84_loss0.17486527636647226.pypots
2024-05-23 21:02:22 [INFO]: Epoch 085 - training loss: 0.2133, validation loss: 0.1747
2024-05-23 21:02:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch85_loss0.1747228667140007.pypots
2024-05-23 21:03:06 [INFO]: Epoch 086 - training loss: 0.2207, validation loss: 0.1785
2024-05-23 21:03:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch86_loss0.1785060741007328.pypots
2024-05-23 21:03:50 [INFO]: Epoch 087 - training loss: 0.2146, validation loss: 0.1742
2024-05-23 21:03:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch87_loss0.17420604601502418.pypots
2024-05-23 21:04:34 [INFO]: Epoch 088 - training loss: 0.2249, validation loss: 0.1758
2024-05-23 21:04:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch88_loss0.17584071457386016.pypots
2024-05-23 21:05:18 [INFO]: Epoch 089 - training loss: 0.2164, validation loss: 0.1730
2024-05-23 21:05:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch89_loss0.17299773469567298.pypots
2024-05-23 21:06:02 [INFO]: Epoch 090 - training loss: 0.2125, validation loss: 0.1751
2024-05-23 21:06:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch90_loss0.17511788234114647.pypots
2024-05-23 21:06:46 [INFO]: Epoch 091 - training loss: 0.2116, validation loss: 0.1771
2024-05-23 21:06:46 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch91_loss0.17714372798800468.pypots
2024-05-23 21:07:30 [INFO]: Epoch 092 - training loss: 0.2150, validation loss: 0.1734
2024-05-23 21:07:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch92_loss0.17342609614133836.pypots
2024-05-23 21:08:15 [INFO]: Epoch 093 - training loss: 0.2127, validation loss: 0.1745
2024-05-23 21:08:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch93_loss0.17447138652205468.pypots
2024-05-23 21:08:58 [INFO]: Epoch 094 - training loss: 0.2233, validation loss: 0.1729
2024-05-23 21:08:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch94_loss0.17287267819046975.pypots
2024-05-23 21:09:42 [INFO]: Epoch 095 - training loss: 0.2160, validation loss: 0.1735
2024-05-23 21:09:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch95_loss0.17354823872447014.pypots
2024-05-23 21:10:26 [INFO]: Epoch 096 - training loss: 0.2071, validation loss: 0.1730
2024-05-23 21:10:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch96_loss0.1730426222085953.pypots
2024-05-23 21:11:10 [INFO]: Epoch 097 - training loss: 0.2184, validation loss: 0.1729
2024-05-23 21:11:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch97_loss0.17288664877414703.pypots
2024-05-23 21:11:53 [INFO]: Epoch 098 - training loss: 0.2063, validation loss: 0.1732
2024-05-23 21:11:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch98_loss0.17318523228168486.pypots
2024-05-23 21:12:37 [INFO]: Epoch 099 - training loss: 0.2112, validation loss: 0.1723
2024-05-23 21:12:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch99_loss0.17233861088752747.pypots
2024-05-23 21:13:20 [INFO]: Epoch 100 - training loss: 0.2158, validation loss: 0.1740
2024-05-23 21:13:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch100_loss0.17398758083581925.pypots
2024-05-23 21:14:04 [INFO]: Epoch 101 - training loss: 0.2074, validation loss: 0.1727
2024-05-23 21:14:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch101_loss0.17272910475730896.pypots
2024-05-23 21:14:47 [INFO]: Epoch 102 - training loss: 0.2142, validation loss: 0.1723
2024-05-23 21:14:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch102_loss0.17226287201046944.pypots
2024-05-23 21:15:31 [INFO]: Epoch 103 - training loss: 0.2067, validation loss: 0.1719
2024-05-23 21:15:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch103_loss0.1718849502503872.pypots
2024-05-23 21:16:15 [INFO]: Epoch 104 - training loss: 0.2088, validation loss: 0.1727
2024-05-23 21:16:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch104_loss0.17269968912005423.pypots
2024-05-23 21:16:59 [INFO]: Epoch 105 - training loss: 0.2243, validation loss: 0.1730
2024-05-23 21:16:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch105_loss0.1729533389210701.pypots
2024-05-23 21:17:43 [INFO]: Epoch 106 - training loss: 0.2149, validation loss: 0.1736
2024-05-23 21:17:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch106_loss0.17356590777635575.pypots
2024-05-23 21:18:27 [INFO]: Epoch 107 - training loss: 0.2213, validation loss: 0.1721
2024-05-23 21:18:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch107_loss0.17209690660238267.pypots
2024-05-23 21:19:12 [INFO]: Epoch 108 - training loss: 0.2191, validation loss: 0.1726
2024-05-23 21:19:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch108_loss0.1726265974342823.pypots
2024-05-23 21:19:56 [INFO]: Epoch 109 - training loss: 0.2141, validation loss: 0.1741
2024-05-23 21:19:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch109_loss0.1740960843861103.pypots
2024-05-23 21:20:40 [INFO]: Epoch 110 - training loss: 0.2097, validation loss: 0.1723
2024-05-23 21:20:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch110_loss0.1723004825413227.pypots
2024-05-23 21:21:24 [INFO]: Epoch 111 - training loss: 0.2165, validation loss: 0.1705
2024-05-23 21:21:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch111_loss0.1704539731144905.pypots
2024-05-23 21:22:08 [INFO]: Epoch 112 - training loss: 0.2147, validation loss: 0.1719
2024-05-23 21:22:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch112_loss0.17188987359404564.pypots
2024-05-23 21:22:51 [INFO]: Epoch 113 - training loss: 0.2149, validation loss: 0.1699
2024-05-23 21:22:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch113_loss0.16987835392355918.pypots
2024-05-23 21:23:35 [INFO]: Epoch 114 - training loss: 0.2131, validation loss: 0.1716
2024-05-23 21:23:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch114_loss0.17161786556243896.pypots
2024-05-23 21:24:18 [INFO]: Epoch 115 - training loss: 0.2099, validation loss: 0.1726
2024-05-23 21:24:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch115_loss0.1726411409676075.pypots
2024-05-23 21:25:02 [INFO]: Epoch 116 - training loss: 0.2077, validation loss: 0.1727
2024-05-23 21:25:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch116_loss0.17272085696458817.pypots
2024-05-23 21:25:47 [INFO]: Epoch 117 - training loss: 0.2168, validation loss: 0.1707
2024-05-23 21:25:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch117_loss0.1707044467329979.pypots
2024-05-23 21:26:31 [INFO]: Epoch 118 - training loss: 0.2056, validation loss: 0.1709
2024-05-23 21:26:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch118_loss0.17089983597397804.pypots
2024-05-23 21:27:15 [INFO]: Epoch 119 - training loss: 0.1973, validation loss: 0.1715
2024-05-23 21:27:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch119_loss0.1714721903204918.pypots
2024-05-23 21:27:59 [INFO]: Epoch 120 - training loss: 0.2147, validation loss: 0.1719
2024-05-23 21:27:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch120_loss0.17193940058350562.pypots
2024-05-23 21:28:42 [INFO]: Epoch 121 - training loss: 0.2208, validation loss: 0.1725
2024-05-23 21:28:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch121_loss0.1724996641278267.pypots
2024-05-23 21:29:26 [INFO]: Epoch 122 - training loss: 0.1962, validation loss: 0.1698
2024-05-23 21:29:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch122_loss0.16977046206593513.pypots
2024-05-23 21:30:09 [INFO]: Epoch 123 - training loss: 0.2089, validation loss: 0.1716
2024-05-23 21:30:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch123_loss0.17156946510076523.pypots
2024-05-23 21:30:53 [INFO]: Epoch 124 - training loss: 0.2175, validation loss: 0.1699
2024-05-23 21:30:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch124_loss0.16987274438142777.pypots
2024-05-23 21:31:36 [INFO]: Epoch 125 - training loss: 0.2097, validation loss: 0.1701
2024-05-23 21:31:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch125_loss0.17006807550787925.pypots
2024-05-23 21:32:20 [INFO]: Epoch 126 - training loss: 0.1908, validation loss: 0.1711
2024-05-23 21:32:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch126_loss0.17114732265472413.pypots
2024-05-23 21:33:03 [INFO]: Epoch 127 - training loss: 0.2156, validation loss: 0.1716
2024-05-23 21:33:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch127_loss0.17162545919418334.pypots
2024-05-23 21:33:47 [INFO]: Epoch 128 - training loss: 0.2096, validation loss: 0.1709
2024-05-23 21:33:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch128_loss0.1709357477724552.pypots
2024-05-23 21:34:30 [INFO]: Epoch 129 - training loss: 0.2074, validation loss: 0.1700
2024-05-23 21:34:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch129_loss0.1700482986867428.pypots
2024-05-23 21:35:14 [INFO]: Epoch 130 - training loss: 0.2116, validation loss: 0.1694
2024-05-23 21:35:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch130_loss0.16939244344830512.pypots
2024-05-23 21:35:57 [INFO]: Epoch 131 - training loss: 0.2094, validation loss: 0.1699
2024-05-23 21:35:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch131_loss0.16986576244235038.pypots
2024-05-23 21:36:41 [INFO]: Epoch 132 - training loss: 0.2075, validation loss: 0.1700
2024-05-23 21:36:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch132_loss0.170026795566082.pypots
2024-05-23 21:37:24 [INFO]: Epoch 133 - training loss: 0.2063, validation loss: 0.1721
2024-05-23 21:37:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch133_loss0.17210028320550919.pypots
2024-05-23 21:38:08 [INFO]: Epoch 134 - training loss: 0.2130, validation loss: 0.1695
2024-05-23 21:38:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch134_loss0.16946597248315812.pypots
2024-05-23 21:38:53 [INFO]: Epoch 135 - training loss: 0.2032, validation loss: 0.1700
2024-05-23 21:38:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch135_loss0.16999060064554214.pypots
2024-05-23 21:39:37 [INFO]: Epoch 136 - training loss: 0.2077, validation loss: 0.1696
2024-05-23 21:39:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch136_loss0.16960538998246194.pypots
2024-05-23 21:40:21 [INFO]: Epoch 137 - training loss: 0.2203, validation loss: 0.1703
2024-05-23 21:40:21 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch137_loss0.17029890269041062.pypots
2024-05-23 21:41:05 [INFO]: Epoch 138 - training loss: 0.2065, validation loss: 0.1692
2024-05-23 21:41:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch138_loss0.16920052096247673.pypots
2024-05-23 21:41:49 [INFO]: Epoch 139 - training loss: 0.2084, validation loss: 0.1703
2024-05-23 21:41:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch139_loss0.17029705122113228.pypots
2024-05-23 21:42:33 [INFO]: Epoch 140 - training loss: 0.2220, validation loss: 0.1684
2024-05-23 21:42:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch140_loss0.1683775618672371.pypots
2024-05-23 21:43:17 [INFO]: Epoch 141 - training loss: 0.2047, validation loss: 0.1690
2024-05-23 21:43:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch141_loss0.16900937929749488.pypots
2024-05-23 21:44:01 [INFO]: Epoch 142 - training loss: 0.2177, validation loss: 0.1683
2024-05-23 21:44:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch142_loss0.16832232847809792.pypots
2024-05-23 21:44:44 [INFO]: Epoch 143 - training loss: 0.2231, validation loss: 0.1691
2024-05-23 21:44:44 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch143_loss0.16910095736384392.pypots
2024-05-23 21:45:28 [INFO]: Epoch 144 - training loss: 0.2224, validation loss: 0.1706
2024-05-23 21:45:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch144_loss0.17062089145183562.pypots
2024-05-23 21:46:12 [INFO]: Epoch 145 - training loss: 0.2073, validation loss: 0.1689
2024-05-23 21:46:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch145_loss0.1688924700021744.pypots
2024-05-23 21:46:55 [INFO]: Epoch 146 - training loss: 0.2118, validation loss: 0.1697
2024-05-23 21:46:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch146_loss0.16974659785628318.pypots
2024-05-23 21:47:39 [INFO]: Epoch 147 - training loss: 0.1979, validation loss: 0.1736
2024-05-23 21:47:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch147_loss0.1736431673169136.pypots
2024-05-23 21:48:22 [INFO]: Epoch 148 - training loss: 0.2130, validation loss: 0.1674
2024-05-23 21:48:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch148_loss0.16742113530635833.pypots
2024-05-23 21:49:06 [INFO]: Epoch 149 - training loss: 0.2008, validation loss: 0.1686
2024-05-23 21:49:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch149_loss0.168624210357666.pypots
2024-05-23 21:49:49 [INFO]: Epoch 150 - training loss: 0.2117, validation loss: 0.1686
2024-05-23 21:49:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch150_loss0.1685970090329647.pypots
2024-05-23 21:50:33 [INFO]: Epoch 151 - training loss: 0.2088, validation loss: 0.1690
2024-05-23 21:50:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch151_loss0.16897755786776542.pypots
2024-05-23 21:51:16 [INFO]: Epoch 152 - training loss: 0.2091, validation loss: 0.1677
2024-05-23 21:51:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch152_loss0.16766197383403778.pypots
2024-05-23 21:52:00 [INFO]: Epoch 153 - training loss: 0.2046, validation loss: 0.1689
2024-05-23 21:52:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch153_loss0.16890625283122063.pypots
2024-05-23 21:52:43 [INFO]: Epoch 154 - training loss: 0.2176, validation loss: 0.1681
2024-05-23 21:52:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch154_loss0.16806925237178802.pypots
2024-05-23 21:53:27 [INFO]: Epoch 155 - training loss: 0.2154, validation loss: 0.1687
2024-05-23 21:53:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch155_loss0.168711094558239.pypots
2024-05-23 21:54:10 [INFO]: Epoch 156 - training loss: 0.2066, validation loss: 0.1687
2024-05-23 21:54:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch156_loss0.16873001158237458.pypots
2024-05-23 21:54:54 [INFO]: Epoch 157 - training loss: 0.2211, validation loss: 0.1699
2024-05-23 21:54:54 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch157_loss0.16985860839486122.pypots
2024-05-23 21:55:37 [INFO]: Epoch 158 - training loss: 0.2033, validation loss: 0.1704
2024-05-23 21:55:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI_epoch158_loss0.17043516263365746.pypots
2024-05-23 21:55:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:55:37 [INFO]: Finished training. The best model is from epoch#148.
2024-05-23 21:55:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T200021/CSDI.pypots
2024-05-23 22:02:58 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2242, MSE=0.3771
2024-05-23 22:32:13 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 22:32:13 [INFO]: Using the given device: cuda:0
2024-05-23 22:32:13 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T223213
2024-05-23 22:32:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T223213/tensorboard
2024-05-23 22:32:13 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 22:32:14 [INFO]: Epoch 001 - training loss: 42381.0635, validation loss: 0.9173
2024-05-23 22:32:14 [INFO]: Epoch 002 - training loss: 24385.8910, validation loss: 0.7671
2024-05-23 22:32:15 [INFO]: Epoch 003 - training loss: 23515.7785, validation loss: 0.7158
2024-05-23 22:32:15 [INFO]: Epoch 004 - training loss: 23225.7415, validation loss: 0.6876
2024-05-23 22:32:16 [INFO]: Epoch 005 - training loss: 23080.9680, validation loss: 0.6941
2024-05-23 22:32:17 [INFO]: Epoch 006 - training loss: 23000.2967, validation loss: 0.6867
2024-05-23 22:32:17 [INFO]: Epoch 007 - training loss: 22951.2846, validation loss: 0.6766
2024-05-23 22:32:18 [INFO]: Epoch 008 - training loss: 22919.9719, validation loss: 0.6798
2024-05-23 22:32:18 [INFO]: Epoch 009 - training loss: 22898.9709, validation loss: 0.6750
2024-05-23 22:32:19 [INFO]: Epoch 010 - training loss: 22883.5606, validation loss: 0.6733
2024-05-23 22:32:19 [INFO]: Epoch 011 - training loss: 22872.8566, validation loss: 0.6644
2024-05-23 22:32:20 [INFO]: Epoch 012 - training loss: 22864.2808, validation loss: 0.6656
2024-05-23 22:32:21 [INFO]: Epoch 013 - training loss: 22857.8091, validation loss: 0.6619
2024-05-23 22:32:21 [INFO]: Epoch 014 - training loss: 22852.7721, validation loss: 0.6596
2024-05-23 22:32:22 [INFO]: Epoch 015 - training loss: 22848.5378, validation loss: 0.6557
2024-05-23 22:32:22 [INFO]: Epoch 016 - training loss: 22846.8585, validation loss: 0.6510
2024-05-23 22:32:23 [INFO]: Epoch 017 - training loss: 22842.2694, validation loss: 0.6465
2024-05-23 22:32:24 [INFO]: Epoch 018 - training loss: 22839.1921, validation loss: 0.6415
2024-05-23 22:32:24 [INFO]: Epoch 019 - training loss: 22838.0735, validation loss: 0.6438
2024-05-23 22:32:25 [INFO]: Epoch 020 - training loss: 22835.7465, validation loss: 0.6397
2024-05-23 22:32:25 [INFO]: Epoch 021 - training loss: 22834.1799, validation loss: 0.6440
2024-05-23 22:32:26 [INFO]: Epoch 022 - training loss: 22833.5827, validation loss: 0.6411
2024-05-23 22:32:26 [INFO]: Epoch 023 - training loss: 22832.2662, validation loss: 0.6368
2024-05-23 22:32:27 [INFO]: Epoch 024 - training loss: 22831.0811, validation loss: 0.6323
2024-05-23 22:32:28 [INFO]: Epoch 025 - training loss: 22830.0109, validation loss: 0.6329
2024-05-23 22:32:28 [INFO]: Epoch 026 - training loss: 22829.4138, validation loss: 0.6346
2024-05-23 22:32:29 [INFO]: Epoch 027 - training loss: 22828.0196, validation loss: 0.6292
2024-05-23 22:32:29 [INFO]: Epoch 028 - training loss: 22827.9200, validation loss: 0.6248
2024-05-23 22:32:30 [INFO]: Epoch 029 - training loss: 22827.5643, validation loss: 0.6266
2024-05-23 22:32:30 [INFO]: Epoch 030 - training loss: 22826.3575, validation loss: 0.6236
2024-05-23 22:32:31 [INFO]: Epoch 031 - training loss: 22825.8276, validation loss: 0.6256
2024-05-23 22:32:32 [INFO]: Epoch 032 - training loss: 22826.3965, validation loss: 0.6194
2024-05-23 22:32:32 [INFO]: Epoch 033 - training loss: 22824.5494, validation loss: 0.6202
2024-05-23 22:32:33 [INFO]: Epoch 034 - training loss: 22822.9917, validation loss: 0.6259
2024-05-23 22:32:33 [INFO]: Epoch 035 - training loss: 22822.3375, validation loss: 0.6104
2024-05-23 22:32:34 [INFO]: Epoch 036 - training loss: 22820.8224, validation loss: 0.6117
2024-05-23 22:32:34 [INFO]: Epoch 037 - training loss: 22819.6420, validation loss: 0.6064
2024-05-23 22:32:35 [INFO]: Epoch 038 - training loss: 22818.0769, validation loss: 0.5957
2024-05-23 22:32:36 [INFO]: Epoch 039 - training loss: 22817.0112, validation loss: 0.5987
2024-05-23 22:32:36 [INFO]: Epoch 040 - training loss: 22815.5183, validation loss: 0.5869
2024-05-23 22:32:37 [INFO]: Epoch 041 - training loss: 22814.9768, validation loss: 0.5852
2024-05-23 22:32:37 [INFO]: Epoch 042 - training loss: 22813.8030, validation loss: 0.5861
2024-05-23 22:32:38 [INFO]: Epoch 043 - training loss: 22812.8136, validation loss: 0.5814
2024-05-23 22:32:39 [INFO]: Epoch 044 - training loss: 22812.5098, validation loss: 0.5779
2024-05-23 22:32:39 [INFO]: Epoch 045 - training loss: 22811.1468, validation loss: 0.5712
2024-05-23 22:32:40 [INFO]: Epoch 046 - training loss: 22810.7138, validation loss: 0.5708
2024-05-23 22:32:40 [INFO]: Epoch 047 - training loss: 22809.4019, validation loss: 0.5694
2024-05-23 22:32:41 [INFO]: Epoch 048 - training loss: 22809.1233, validation loss: 0.5592
2024-05-23 22:32:41 [INFO]: Epoch 049 - training loss: 22807.2912, validation loss: 0.5559
2024-05-23 22:32:42 [INFO]: Epoch 050 - training loss: 22806.1006, validation loss: 0.5565
2024-05-23 22:32:43 [INFO]: Epoch 051 - training loss: 22805.3083, validation loss: 0.5474
2024-05-23 22:32:43 [INFO]: Epoch 052 - training loss: 22804.2311, validation loss: 0.5461
2024-05-23 22:32:44 [INFO]: Epoch 053 - training loss: 22803.4624, validation loss: 0.5436
2024-05-23 22:32:44 [INFO]: Epoch 054 - training loss: 22803.1144, validation loss: 0.5441
2024-05-23 22:32:45 [INFO]: Epoch 055 - training loss: 22802.3254, validation loss: 0.5394
2024-05-23 22:32:45 [INFO]: Epoch 056 - training loss: 22801.7326, validation loss: 0.5338
2024-05-23 22:32:46 [INFO]: Epoch 057 - training loss: 22801.2495, validation loss: 0.5358
2024-05-23 22:32:47 [INFO]: Epoch 058 - training loss: 22800.9266, validation loss: 0.5344
2024-05-23 22:32:47 [INFO]: Epoch 059 - training loss: 22800.5231, validation loss: 0.5325
2024-05-23 22:32:48 [INFO]: Epoch 060 - training loss: 22799.9892, validation loss: 0.5357
2024-05-23 22:32:48 [INFO]: Epoch 061 - training loss: 22799.8715, validation loss: 0.5318
2024-05-23 22:32:49 [INFO]: Epoch 062 - training loss: 22801.2291, validation loss: 0.5255
2024-05-23 22:32:50 [INFO]: Epoch 063 - training loss: 22798.8565, validation loss: 0.5292
2024-05-23 22:32:50 [INFO]: Epoch 064 - training loss: 22800.1166, validation loss: 0.5298
2024-05-23 22:32:51 [INFO]: Epoch 065 - training loss: 22799.4495, validation loss: 0.5241
2024-05-23 22:32:51 [INFO]: Epoch 066 - training loss: 22797.1765, validation loss: 0.5444
2024-05-23 22:32:52 [INFO]: Epoch 067 - training loss: 22798.3562, validation loss: 0.5251
2024-05-23 22:32:52 [INFO]: Epoch 068 - training loss: 22798.1917, validation loss: 0.5175
2024-05-23 22:32:53 [INFO]: Epoch 069 - training loss: 22795.9555, validation loss: 0.5181
2024-05-23 22:32:54 [INFO]: Epoch 070 - training loss: 22795.5378, validation loss: 0.5245
2024-05-23 22:32:54 [INFO]: Epoch 071 - training loss: 22796.5612, validation loss: 0.5213
2024-05-23 22:32:55 [INFO]: Epoch 072 - training loss: 22796.5509, validation loss: 0.5131
2024-05-23 22:32:55 [INFO]: Epoch 073 - training loss: 22795.1501, validation loss: 0.5140
2024-05-23 22:32:56 [INFO]: Epoch 074 - training loss: 22795.0005, validation loss: 0.5177
2024-05-23 22:32:57 [INFO]: Epoch 075 - training loss: 22794.5579, validation loss: 0.5239
2024-05-23 22:32:57 [INFO]: Epoch 076 - training loss: 22795.2396, validation loss: 0.5164
2024-05-23 22:32:58 [INFO]: Epoch 077 - training loss: 22794.1981, validation loss: 0.5157
2024-05-23 22:32:58 [INFO]: Epoch 078 - training loss: 22794.1098, validation loss: 0.5183
2024-05-23 22:32:59 [INFO]: Epoch 079 - training loss: 22793.2510, validation loss: 0.5112
2024-05-23 22:32:59 [INFO]: Epoch 080 - training loss: 22793.4637, validation loss: 0.5121
2024-05-23 22:33:00 [INFO]: Epoch 081 - training loss: 22793.2407, validation loss: 0.5168
2024-05-23 22:33:01 [INFO]: Epoch 082 - training loss: 22793.9836, validation loss: 0.5069
2024-05-23 22:33:01 [INFO]: Epoch 083 - training loss: 22792.5686, validation loss: 0.5171
2024-05-23 22:33:02 [INFO]: Epoch 084 - training loss: 22792.5000, validation loss: 0.5099
2024-05-23 22:33:02 [INFO]: Epoch 085 - training loss: 22792.5904, validation loss: 0.5072
2024-05-23 22:33:03 [INFO]: Epoch 086 - training loss: 22792.1179, validation loss: 0.5086
2024-05-23 22:33:03 [INFO]: Epoch 087 - training loss: 22792.1463, validation loss: 0.5111
2024-05-23 22:33:04 [INFO]: Epoch 088 - training loss: 22791.7588, validation loss: 0.5075
2024-05-23 22:33:05 [INFO]: Epoch 089 - training loss: 22791.9012, validation loss: 0.5094
2024-05-23 22:33:05 [INFO]: Epoch 090 - training loss: 22791.1736, validation loss: 0.5143
2024-05-23 22:33:06 [INFO]: Epoch 091 - training loss: 22791.6589, validation loss: 0.5039
2024-05-23 22:33:06 [INFO]: Epoch 092 - training loss: 22792.0210, validation loss: 0.5094
2024-05-23 22:33:07 [INFO]: Epoch 093 - training loss: 22794.0103, validation loss: 0.5088
2024-05-23 22:33:08 [INFO]: Epoch 094 - training loss: 22796.2154, validation loss: 0.5062
2024-05-23 22:33:08 [INFO]: Epoch 095 - training loss: 22792.2744, validation loss: 0.5033
2024-05-23 22:33:09 [INFO]: Epoch 096 - training loss: 22791.3216, validation loss: 0.5033
2024-05-23 22:33:09 [INFO]: Epoch 097 - training loss: 22791.1538, validation loss: 0.5043
2024-05-23 22:33:10 [INFO]: Epoch 098 - training loss: 22790.3573, validation loss: 0.4997
2024-05-23 22:33:10 [INFO]: Epoch 099 - training loss: 22789.7392, validation loss: 0.5053
2024-05-23 22:33:11 [INFO]: Epoch 100 - training loss: 22789.6839, validation loss: 0.5012
2024-05-23 22:33:12 [INFO]: Epoch 101 - training loss: 22789.5115, validation loss: 0.4987
2024-05-23 22:33:12 [INFO]: Epoch 102 - training loss: 22790.1025, validation loss: 0.5010
2024-05-23 22:33:13 [INFO]: Epoch 103 - training loss: 22789.6605, validation loss: 0.5055
2024-05-23 22:33:13 [INFO]: Epoch 104 - training loss: 22789.6254, validation loss: 0.4989
2024-05-23 22:33:14 [INFO]: Epoch 105 - training loss: 22789.0014, validation loss: 0.4945
2024-05-23 22:33:14 [INFO]: Epoch 106 - training loss: 22788.4274, validation loss: 0.4958
2024-05-23 22:33:15 [INFO]: Epoch 107 - training loss: 22788.3674, validation loss: 0.4977
2024-05-23 22:33:16 [INFO]: Epoch 108 - training loss: 22788.6677, validation loss: 0.4954
2024-05-23 22:33:16 [INFO]: Epoch 109 - training loss: 22790.1159, validation loss: 0.5027
2024-05-23 22:33:17 [INFO]: Epoch 110 - training loss: 22790.5236, validation loss: 0.5058
2024-05-23 22:33:17 [INFO]: Epoch 111 - training loss: 22790.1718, validation loss: 0.5088
2024-05-23 22:33:18 [INFO]: Epoch 112 - training loss: 22791.4044, validation loss: 0.4969
2024-05-23 22:33:19 [INFO]: Epoch 113 - training loss: 22789.1109, validation loss: 0.4924
2024-05-23 22:33:19 [INFO]: Epoch 114 - training loss: 22788.4308, validation loss: 0.4936
2024-05-23 22:33:20 [INFO]: Epoch 115 - training loss: 22787.9399, validation loss: 0.4923
2024-05-23 22:33:20 [INFO]: Epoch 116 - training loss: 22787.9149, validation loss: 0.4915
2024-05-23 22:33:21 [INFO]: Epoch 117 - training loss: 22787.2683, validation loss: 0.4910
2024-05-23 22:33:21 [INFO]: Epoch 118 - training loss: 22787.1299, validation loss: 0.4893
2024-05-23 22:33:22 [INFO]: Epoch 119 - training loss: 22787.2654, validation loss: 0.4879
2024-05-23 22:33:23 [INFO]: Epoch 120 - training loss: 22786.9918, validation loss: 0.4897
2024-05-23 22:33:23 [INFO]: Epoch 121 - training loss: 22786.6245, validation loss: 0.4873
2024-05-23 22:33:24 [INFO]: Epoch 122 - training loss: 22786.7062, validation loss: 0.4910
2024-05-23 22:33:24 [INFO]: Epoch 123 - training loss: 22786.9492, validation loss: 0.4923
2024-05-23 22:33:25 [INFO]: Epoch 124 - training loss: 22787.1696, validation loss: 0.4897
2024-05-23 22:33:25 [INFO]: Epoch 125 - training loss: 22786.7566, validation loss: 0.4875
2024-05-23 22:33:26 [INFO]: Epoch 126 - training loss: 22786.5584, validation loss: 0.4839
2024-05-23 22:33:27 [INFO]: Epoch 127 - training loss: 22786.6182, validation loss: 0.4840
2024-05-23 22:33:27 [INFO]: Epoch 128 - training loss: 22786.1395, validation loss: 0.4878
2024-05-23 22:33:28 [INFO]: Epoch 129 - training loss: 22786.6115, validation loss: 0.4842
2024-05-23 22:33:28 [INFO]: Epoch 130 - training loss: 22785.5299, validation loss: 0.4791
2024-05-23 22:33:29 [INFO]: Epoch 131 - training loss: 22785.6926, validation loss: 0.4830
2024-05-23 22:33:29 [INFO]: Epoch 132 - training loss: 22786.2581, validation loss: 0.4813
2024-05-23 22:33:30 [INFO]: Epoch 133 - training loss: 22785.6872, validation loss: 0.4937
2024-05-23 22:33:31 [INFO]: Epoch 134 - training loss: 22786.0130, validation loss: 0.4826
2024-05-23 22:33:31 [INFO]: Epoch 135 - training loss: 22785.9168, validation loss: 0.4835
2024-05-23 22:33:32 [INFO]: Epoch 136 - training loss: 22784.8394, validation loss: 0.4854
2024-05-23 22:33:32 [INFO]: Epoch 137 - training loss: 22785.4580, validation loss: 0.4780
2024-05-23 22:33:33 [INFO]: Epoch 138 - training loss: 22785.1128, validation loss: 0.4825
2024-05-23 22:33:33 [INFO]: Epoch 139 - training loss: 22785.1555, validation loss: 0.4841
2024-05-23 22:33:34 [INFO]: Epoch 140 - training loss: 22785.0412, validation loss: 0.4820
2024-05-23 22:33:35 [INFO]: Epoch 141 - training loss: 22784.6496, validation loss: 0.4782
2024-05-23 22:33:35 [INFO]: Epoch 142 - training loss: 22784.3522, validation loss: 0.4765
2024-05-23 22:33:36 [INFO]: Epoch 143 - training loss: 22785.2980, validation loss: 0.4767
2024-05-23 22:33:36 [INFO]: Epoch 144 - training loss: 22785.1047, validation loss: 0.4782
2024-05-23 22:33:37 [INFO]: Epoch 145 - training loss: 22784.5558, validation loss: 0.4811
2024-05-23 22:33:38 [INFO]: Epoch 146 - training loss: 22784.2690, validation loss: 0.4817
2024-05-23 22:33:38 [INFO]: Epoch 147 - training loss: 22784.2117, validation loss: 0.4771
2024-05-23 22:33:39 [INFO]: Epoch 148 - training loss: 22783.6446, validation loss: 0.4765
2024-05-23 22:33:39 [INFO]: Epoch 149 - training loss: 22783.4234, validation loss: 0.4840
2024-05-23 22:33:40 [INFO]: Epoch 150 - training loss: 22784.0333, validation loss: 0.4777
2024-05-23 22:33:41 [INFO]: Epoch 151 - training loss: 22783.9444, validation loss: 0.4788
2024-05-23 22:33:41 [INFO]: Epoch 152 - training loss: 22784.0234, validation loss: 0.4845
2024-05-23 22:33:42 [INFO]: Epoch 153 - training loss: 22787.4099, validation loss: 0.4782
2024-05-23 22:33:42 [INFO]: Epoch 154 - training loss: 22783.7467, validation loss: 0.4789
2024-05-23 22:33:43 [INFO]: Epoch 155 - training loss: 22783.3760, validation loss: 0.4785
2024-05-23 22:33:44 [INFO]: Epoch 156 - training loss: 22783.1951, validation loss: 0.4757
2024-05-23 22:33:44 [INFO]: Epoch 157 - training loss: 22783.1600, validation loss: 0.4786
2024-05-23 22:33:45 [INFO]: Epoch 158 - training loss: 22783.4157, validation loss: 0.4800
2024-05-23 22:33:45 [INFO]: Epoch 159 - training loss: 22783.5410, validation loss: 0.4782
2024-05-23 22:33:46 [INFO]: Epoch 160 - training loss: 22782.5576, validation loss: 0.4761
2024-05-23 22:33:46 [INFO]: Epoch 161 - training loss: 22782.2675, validation loss: 0.4813
2024-05-23 22:33:47 [INFO]: Epoch 162 - training loss: 22782.1921, validation loss: 0.4772
2024-05-23 22:33:48 [INFO]: Epoch 163 - training loss: 22781.9854, validation loss: 0.4771
2024-05-23 22:33:48 [INFO]: Epoch 164 - training loss: 22782.1238, validation loss: 0.4781
2024-05-23 22:33:49 [INFO]: Epoch 165 - training loss: 22782.1520, validation loss: 0.4745
2024-05-23 22:33:49 [INFO]: Epoch 166 - training loss: 22782.2220, validation loss: 0.4761
2024-05-23 22:33:50 [INFO]: Epoch 167 - training loss: 22781.7766, validation loss: 0.4756
2024-05-23 22:33:51 [INFO]: Epoch 168 - training loss: 22781.6676, validation loss: 0.4769
2024-05-23 22:33:51 [INFO]: Epoch 169 - training loss: 22782.1291, validation loss: 0.4761
2024-05-23 22:33:52 [INFO]: Epoch 170 - training loss: 22782.5856, validation loss: 0.4781
2024-05-23 22:33:52 [INFO]: Epoch 171 - training loss: 22781.9976, validation loss: 0.4750
2024-05-23 22:33:53 [INFO]: Epoch 172 - training loss: 22781.2250, validation loss: 0.4794
2024-05-23 22:33:53 [INFO]: Epoch 173 - training loss: 22781.0949, validation loss: 0.4716
2024-05-23 22:33:54 [INFO]: Epoch 174 - training loss: 22780.6789, validation loss: 0.4757
2024-05-23 22:33:55 [INFO]: Epoch 175 - training loss: 22780.9683, validation loss: 0.4729
2024-05-23 22:33:55 [INFO]: Epoch 176 - training loss: 22780.8019, validation loss: 0.4763
2024-05-23 22:33:56 [INFO]: Epoch 177 - training loss: 22780.4362, validation loss: 0.4735
2024-05-23 22:33:56 [INFO]: Epoch 178 - training loss: 22779.9578, validation loss: 0.4717
2024-05-23 22:33:57 [INFO]: Epoch 179 - training loss: 22779.8726, validation loss: 0.4702
2024-05-23 22:33:57 [INFO]: Epoch 180 - training loss: 22779.8012, validation loss: 0.4748
2024-05-23 22:33:58 [INFO]: Epoch 181 - training loss: 22780.6756, validation loss: 0.4720
2024-05-23 22:33:59 [INFO]: Epoch 182 - training loss: 22780.6157, validation loss: 0.4713
2024-05-23 22:33:59 [INFO]: Epoch 183 - training loss: 22779.6155, validation loss: 0.4725
2024-05-23 22:34:00 [INFO]: Epoch 184 - training loss: 22778.9860, validation loss: 0.4694
2024-05-23 22:34:00 [INFO]: Epoch 185 - training loss: 22779.0064, validation loss: 0.4678
2024-05-23 22:34:01 [INFO]: Epoch 186 - training loss: 22779.0640, validation loss: 0.4721
2024-05-23 22:34:01 [INFO]: Epoch 187 - training loss: 22779.1454, validation loss: 0.4714
2024-05-23 22:34:02 [INFO]: Epoch 188 - training loss: 22778.9718, validation loss: 0.4705
2024-05-23 22:34:03 [INFO]: Epoch 189 - training loss: 22779.1377, validation loss: 0.4681
2024-05-23 22:34:03 [INFO]: Epoch 190 - training loss: 22778.7452, validation loss: 0.4685
2024-05-23 22:34:04 [INFO]: Epoch 191 - training loss: 22779.0325, validation loss: 0.4697
2024-05-23 22:34:04 [INFO]: Epoch 192 - training loss: 22779.3473, validation loss: 0.4714
2024-05-23 22:34:05 [INFO]: Epoch 193 - training loss: 22779.0788, validation loss: 0.4702
2024-05-23 22:34:05 [INFO]: Epoch 194 - training loss: 22778.1654, validation loss: 0.4674
2024-05-23 22:34:06 [INFO]: Epoch 195 - training loss: 22778.6419, validation loss: 0.4654
2024-05-23 22:34:07 [INFO]: Epoch 196 - training loss: 22778.0730, validation loss: 0.4657
2024-05-23 22:34:07 [INFO]: Epoch 197 - training loss: 22778.3797, validation loss: 0.4697
2024-05-23 22:34:08 [INFO]: Epoch 198 - training loss: 22777.9103, validation loss: 0.4660
2024-05-23 22:34:08 [INFO]: Epoch 199 - training loss: 22777.9470, validation loss: 0.4673
2024-05-23 22:34:09 [INFO]: Epoch 200 - training loss: 22777.5603, validation loss: 0.4650
2024-05-23 22:34:09 [INFO]: Epoch 201 - training loss: 22777.6747, validation loss: 0.4634
2024-05-23 22:34:10 [INFO]: Epoch 202 - training loss: 22776.8427, validation loss: 0.4662
2024-05-23 22:34:11 [INFO]: Epoch 203 - training loss: 22777.1648, validation loss: 0.4658
2024-05-23 22:34:11 [INFO]: Epoch 204 - training loss: 22776.7742, validation loss: 0.4655
2024-05-23 22:34:12 [INFO]: Epoch 205 - training loss: 22777.0941, validation loss: 0.4683
2024-05-23 22:34:12 [INFO]: Epoch 206 - training loss: 22776.9526, validation loss: 0.4632
2024-05-23 22:34:13 [INFO]: Epoch 207 - training loss: 22776.7689, validation loss: 0.4652
2024-05-23 22:34:14 [INFO]: Epoch 208 - training loss: 22776.9777, validation loss: 0.4649
2024-05-23 22:34:14 [INFO]: Epoch 209 - training loss: 22776.3332, validation loss: 0.4671
2024-05-23 22:34:15 [INFO]: Epoch 210 - training loss: 22776.8556, validation loss: 0.4658
2024-05-23 22:34:15 [INFO]: Epoch 211 - training loss: 22776.6700, validation loss: 0.4681
2024-05-23 22:34:16 [INFO]: Epoch 212 - training loss: 22776.6025, validation loss: 0.4641
2024-05-23 22:34:16 [INFO]: Epoch 213 - training loss: 22776.3203, validation loss: 0.4622
2024-05-23 22:34:17 [INFO]: Epoch 214 - training loss: 22776.2574, validation loss: 0.4627
2024-05-23 22:34:18 [INFO]: Epoch 215 - training loss: 22776.5410, validation loss: 0.4643
2024-05-23 22:34:18 [INFO]: Epoch 216 - training loss: 22776.1561, validation loss: 0.4657
2024-05-23 22:34:19 [INFO]: Epoch 217 - training loss: 22776.6037, validation loss: 0.4624
2024-05-23 22:34:19 [INFO]: Epoch 218 - training loss: 22776.2720, validation loss: 0.4640
2024-05-23 22:34:20 [INFO]: Epoch 219 - training loss: 22776.0770, validation loss: 0.4665
2024-05-23 22:34:20 [INFO]: Epoch 220 - training loss: 22775.8780, validation loss: 0.4598
2024-05-23 22:34:21 [INFO]: Epoch 221 - training loss: 22776.3154, validation loss: 0.4648
2024-05-23 22:34:22 [INFO]: Epoch 222 - training loss: 22775.3578, validation loss: 0.4632
2024-05-23 22:34:22 [INFO]: Epoch 223 - training loss: 22775.2297, validation loss: 0.4622
2024-05-23 22:34:23 [INFO]: Epoch 224 - training loss: 22775.6374, validation loss: 0.4630
2024-05-23 22:34:23 [INFO]: Epoch 225 - training loss: 22775.0477, validation loss: 0.4616
2024-05-23 22:34:24 [INFO]: Epoch 226 - training loss: 22775.3458, validation loss: 0.4633
2024-05-23 22:34:24 [INFO]: Epoch 227 - training loss: 22775.1708, validation loss: 0.4623
2024-05-23 22:34:25 [INFO]: Epoch 228 - training loss: 22775.3698, validation loss: 0.4616
2024-05-23 22:34:26 [INFO]: Epoch 229 - training loss: 22775.2141, validation loss: 0.4613
2024-05-23 22:34:26 [INFO]: Epoch 230 - training loss: 22774.9579, validation loss: 0.4647
2024-05-23 22:34:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:34:26 [INFO]: Finished training. The best model is from epoch#220.
2024-05-23 22:34:26 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T223213/GPVAE.pypots
2024-05-23 22:34:26 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4155, MSE=0.4935
2024-05-23 22:34:27 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 22:34:27 [INFO]: Using the given device: cuda:0
2024-05-23 22:34:27 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T223427
2024-05-23 22:34:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T223427/tensorboard
2024-05-23 22:34:27 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 22:34:48 [INFO]: Epoch 001 - generator training loss: 0.5996, discriminator training loss: 0.3751, validation loss: 0.6420
2024-05-23 22:35:06 [INFO]: Epoch 002 - generator training loss: 0.4796, discriminator training loss: 0.2550, validation loss: 0.5452
2024-05-23 22:35:25 [INFO]: Epoch 003 - generator training loss: 0.4545, discriminator training loss: 0.1998, validation loss: 0.5311
2024-05-23 22:35:43 [INFO]: Epoch 004 - generator training loss: 0.4590, discriminator training loss: 0.1495, validation loss: 0.5018
2024-05-23 22:36:02 [INFO]: Epoch 005 - generator training loss: 0.4470, discriminator training loss: 0.1209, validation loss: 0.4899
2024-05-23 22:36:20 [INFO]: Epoch 006 - generator training loss: 0.4351, discriminator training loss: 0.1018, validation loss: 0.4809
2024-05-23 22:36:39 [INFO]: Epoch 007 - generator training loss: 0.4226, discriminator training loss: 0.0883, validation loss: 0.4606
2024-05-23 22:36:57 [INFO]: Epoch 008 - generator training loss: 0.4075, discriminator training loss: 0.0786, validation loss: 0.4492
2024-05-23 22:37:15 [INFO]: Epoch 009 - generator training loss: 0.4010, discriminator training loss: 0.0709, validation loss: 0.4443
2024-05-23 22:37:34 [INFO]: Epoch 010 - generator training loss: 0.3951, discriminator training loss: 0.0645, validation loss: 0.4366
2024-05-23 22:37:52 [INFO]: Epoch 011 - generator training loss: 0.3892, discriminator training loss: 0.0592, validation loss: 0.4304
2024-05-23 22:38:11 [INFO]: Epoch 012 - generator training loss: 0.3828, discriminator training loss: 0.0547, validation loss: 0.4253
2024-05-23 22:38:29 [INFO]: Epoch 013 - generator training loss: 0.3783, discriminator training loss: 0.0511, validation loss: 0.4198
2024-05-23 22:38:48 [INFO]: Epoch 014 - generator training loss: 0.3711, discriminator training loss: 0.0478, validation loss: 0.4114
2024-05-23 22:39:06 [INFO]: Epoch 015 - generator training loss: 0.3671, discriminator training loss: 0.0450, validation loss: 0.4066
2024-05-23 22:39:24 [INFO]: Epoch 016 - generator training loss: 0.3625, discriminator training loss: 0.0428, validation loss: 0.3995
2024-05-23 22:39:43 [INFO]: Epoch 017 - generator training loss: 0.3559, discriminator training loss: 0.0408, validation loss: 0.3972
2024-05-23 22:40:01 [INFO]: Epoch 018 - generator training loss: 0.3503, discriminator training loss: 0.0390, validation loss: 0.3945
2024-05-23 22:40:19 [INFO]: Epoch 019 - generator training loss: 0.3452, discriminator training loss: 0.0377, validation loss: 0.3905
2024-05-23 22:40:38 [INFO]: Epoch 020 - generator training loss: 0.3406, discriminator training loss: 0.0365, validation loss: 0.3830
2024-05-23 22:40:56 [INFO]: Epoch 021 - generator training loss: 0.3334, discriminator training loss: 0.0352, validation loss: 0.3789
2024-05-23 22:41:15 [INFO]: Epoch 022 - generator training loss: 0.3294, discriminator training loss: 0.0343, validation loss: 0.3744
2024-05-23 22:41:33 [INFO]: Epoch 023 - generator training loss: 0.3265, discriminator training loss: 0.0334, validation loss: 0.3733
2024-05-23 22:41:51 [INFO]: Epoch 024 - generator training loss: 0.3219, discriminator training loss: 0.0325, validation loss: 0.3672
2024-05-23 22:42:10 [INFO]: Epoch 025 - generator training loss: 0.3192, discriminator training loss: 0.0317, validation loss: 0.3667
2024-05-23 22:42:28 [INFO]: Epoch 026 - generator training loss: 0.3119, discriminator training loss: 0.0310, validation loss: 0.3584
2024-05-23 22:42:47 [INFO]: Epoch 027 - generator training loss: 0.3087, discriminator training loss: 0.0305, validation loss: 0.3554
2024-05-23 22:43:05 [INFO]: Epoch 028 - generator training loss: 0.3020, discriminator training loss: 0.0300, validation loss: 0.3587
2024-05-23 22:43:24 [INFO]: Epoch 029 - generator training loss: 0.2996, discriminator training loss: 0.0293, validation loss: 0.3530
2024-05-23 22:43:42 [INFO]: Epoch 030 - generator training loss: 0.3009, discriminator training loss: 0.0290, validation loss: 0.3536
2024-05-23 22:44:00 [INFO]: Epoch 031 - generator training loss: 0.2948, discriminator training loss: 0.0283, validation loss: 0.3464
2024-05-23 22:44:19 [INFO]: Epoch 032 - generator training loss: 0.2911, discriminator training loss: 0.0281, validation loss: 0.3444
2024-05-23 22:44:37 [INFO]: Epoch 033 - generator training loss: 0.2844, discriminator training loss: 0.0278, validation loss: 0.3387
2024-05-23 22:44:56 [INFO]: Epoch 034 - generator training loss: 0.2793, discriminator training loss: 0.0274, validation loss: 0.3378
2024-05-23 22:45:14 [INFO]: Epoch 035 - generator training loss: 0.2786, discriminator training loss: 0.0270, validation loss: 0.3365
2024-05-23 22:45:32 [INFO]: Epoch 036 - generator training loss: 0.2725, discriminator training loss: 0.0267, validation loss: 0.3353
2024-05-23 22:45:51 [INFO]: Epoch 037 - generator training loss: 0.2790, discriminator training loss: 0.0266, validation loss: 0.3358
2024-05-23 22:46:09 [INFO]: Epoch 038 - generator training loss: 0.2699, discriminator training loss: 0.0260, validation loss: 0.3355
2024-05-23 22:46:28 [INFO]: Epoch 039 - generator training loss: 0.2645, discriminator training loss: 0.0258, validation loss: 0.3298
2024-05-23 22:46:46 [INFO]: Epoch 040 - generator training loss: 0.2638, discriminator training loss: 0.0257, validation loss: 0.3326
2024-05-23 22:47:05 [INFO]: Epoch 041 - generator training loss: 0.2606, discriminator training loss: 0.0255, validation loss: 0.3286
2024-05-23 22:47:23 [INFO]: Epoch 042 - generator training loss: 0.2611, discriminator training loss: 0.0251, validation loss: 0.3322
2024-05-23 22:47:41 [INFO]: Epoch 043 - generator training loss: 0.2577, discriminator training loss: 0.0250, validation loss: 0.3302
2024-05-23 22:48:00 [INFO]: Epoch 044 - generator training loss: 0.2563, discriminator training loss: 0.0247, validation loss: 0.3286
2024-05-23 22:48:18 [INFO]: Epoch 045 - generator training loss: 0.2505, discriminator training loss: 0.0245, validation loss: 0.3282
2024-05-23 22:48:37 [INFO]: Epoch 046 - generator training loss: 0.2457, discriminator training loss: 0.0242, validation loss: 0.3275
2024-05-23 22:48:55 [INFO]: Epoch 047 - generator training loss: 0.2418, discriminator training loss: 0.0241, validation loss: 0.3232
2024-05-23 22:49:13 [INFO]: Epoch 048 - generator training loss: 0.2387, discriminator training loss: 0.0238, validation loss: 0.3247
2024-05-23 22:49:32 [INFO]: Epoch 049 - generator training loss: 0.2404, discriminator training loss: 0.0238, validation loss: 0.3235
2024-05-23 22:49:50 [INFO]: Epoch 050 - generator training loss: 0.2428, discriminator training loss: 0.0236, validation loss: 0.3256
2024-05-23 22:50:08 [INFO]: Epoch 051 - generator training loss: 0.2465, discriminator training loss: 0.0236, validation loss: 0.3248
2024-05-23 22:50:27 [INFO]: Epoch 052 - generator training loss: 0.2407, discriminator training loss: 0.0233, validation loss: 0.3257
2024-05-23 22:50:45 [INFO]: Epoch 053 - generator training loss: 0.2337, discriminator training loss: 0.0232, validation loss: 0.3238
2024-05-23 22:51:04 [INFO]: Epoch 054 - generator training loss: 0.2335, discriminator training loss: 0.0230, validation loss: 0.3257
2024-05-23 22:51:22 [INFO]: Epoch 055 - generator training loss: 0.2300, discriminator training loss: 0.0230, validation loss: 0.3231
2024-05-23 22:51:40 [INFO]: Epoch 056 - generator training loss: 0.2348, discriminator training loss: 0.0228, validation loss: 0.3227
2024-05-23 22:51:59 [INFO]: Epoch 057 - generator training loss: 0.2282, discriminator training loss: 0.0227, validation loss: 0.3218
2024-05-23 22:52:17 [INFO]: Epoch 058 - generator training loss: 0.2254, discriminator training loss: 0.0227, validation loss: 0.3178
2024-05-23 22:52:36 [INFO]: Epoch 059 - generator training loss: 0.2245, discriminator training loss: 0.0227, validation loss: 0.3223
2024-05-23 22:52:54 [INFO]: Epoch 060 - generator training loss: 0.2198, discriminator training loss: 0.0225, validation loss: 0.3202
2024-05-23 22:53:13 [INFO]: Epoch 061 - generator training loss: 0.2201, discriminator training loss: 0.0225, validation loss: 0.3166
2024-05-23 22:53:31 [INFO]: Epoch 062 - generator training loss: 0.2211, discriminator training loss: 0.0225, validation loss: 0.3242
2024-05-23 22:53:49 [INFO]: Epoch 063 - generator training loss: 0.2250, discriminator training loss: 0.0224, validation loss: 0.3179
2024-05-23 22:54:08 [INFO]: Epoch 064 - generator training loss: 0.2190, discriminator training loss: 0.0222, validation loss: 0.3153
2024-05-23 22:54:26 [INFO]: Epoch 065 - generator training loss: 0.2108, discriminator training loss: 0.0220, validation loss: 0.3154
2024-05-23 22:54:45 [INFO]: Epoch 066 - generator training loss: 0.2080, discriminator training loss: 0.0221, validation loss: 0.3195
2024-05-23 22:55:03 [INFO]: Epoch 067 - generator training loss: 0.2069, discriminator training loss: 0.0220, validation loss: 0.3168
2024-05-23 22:55:21 [INFO]: Epoch 068 - generator training loss: 0.2089, discriminator training loss: 0.0219, validation loss: 0.3241
2024-05-23 22:55:40 [INFO]: Epoch 069 - generator training loss: 0.2170, discriminator training loss: 0.0219, validation loss: 0.3185
2024-05-23 22:55:58 [INFO]: Epoch 070 - generator training loss: 0.2111, discriminator training loss: 0.0217, validation loss: 0.3295
2024-05-23 22:56:17 [INFO]: Epoch 071 - generator training loss: 0.2240, discriminator training loss: 0.0218, validation loss: 0.3178
2024-05-23 22:56:35 [INFO]: Epoch 072 - generator training loss: 0.2065, discriminator training loss: 0.0214, validation loss: 0.3173
2024-05-23 22:56:53 [INFO]: Epoch 073 - generator training loss: 0.2083, discriminator training loss: 0.0215, validation loss: 0.3186
2024-05-23 22:57:12 [INFO]: Epoch 074 - generator training loss: 0.2087, discriminator training loss: 0.0215, validation loss: 0.3197
2024-05-23 22:57:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:57:12 [INFO]: Finished training. The best model is from epoch#64.
2024-05-23 22:57:12 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T223427/USGAN.pypots
2024-05-23 22:57:14 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.3003, MSE=0.3349
2024-05-23 22:57:24 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 22:57:24 [INFO]: Using the given device: cuda:0
2024-05-23 22:57:24 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T225724
2024-05-23 22:57:24 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T225724/tensorboard
2024-05-23 22:57:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 22:57:39 [INFO]: Epoch 001 - training loss: 1.1161, validation loss: 0.5452
2024-05-23 22:57:51 [INFO]: Epoch 002 - training loss: 0.9074, validation loss: 0.4843
2024-05-23 22:58:03 [INFO]: Epoch 003 - training loss: 0.8429, validation loss: 0.4496
2024-05-23 22:58:15 [INFO]: Epoch 004 - training loss: 0.8028, validation loss: 0.4277
2024-05-23 22:58:27 [INFO]: Epoch 005 - training loss: 0.7724, validation loss: 0.4084
2024-05-23 22:58:40 [INFO]: Epoch 006 - training loss: 0.7510, validation loss: 0.3972
2024-05-23 22:58:52 [INFO]: Epoch 007 - training loss: 0.7327, validation loss: 0.3849
2024-05-23 22:59:04 [INFO]: Epoch 008 - training loss: 0.7180, validation loss: 0.3781
2024-05-23 22:59:16 [INFO]: Epoch 009 - training loss: 0.7049, validation loss: 0.3697
2024-05-23 22:59:28 [INFO]: Epoch 010 - training loss: 0.6939, validation loss: 0.3642
2024-05-23 22:59:40 [INFO]: Epoch 011 - training loss: 0.6843, validation loss: 0.3610
2024-05-23 22:59:52 [INFO]: Epoch 012 - training loss: 0.6771, validation loss: 0.3581
2024-05-23 23:00:04 [INFO]: Epoch 013 - training loss: 0.6694, validation loss: 0.3533
2024-05-23 23:00:16 [INFO]: Epoch 014 - training loss: 0.6620, validation loss: 0.3519
2024-05-23 23:00:28 [INFO]: Epoch 015 - training loss: 0.6576, validation loss: 0.3503
2024-05-23 23:00:40 [INFO]: Epoch 016 - training loss: 0.6520, validation loss: 0.3460
2024-05-23 23:00:52 [INFO]: Epoch 017 - training loss: 0.6467, validation loss: 0.3453
2024-05-23 23:01:04 [INFO]: Epoch 018 - training loss: 0.6425, validation loss: 0.3445
2024-05-23 23:01:16 [INFO]: Epoch 019 - training loss: 0.6380, validation loss: 0.3424
2024-05-23 23:01:28 [INFO]: Epoch 020 - training loss: 0.6337, validation loss: 0.3407
2024-05-23 23:01:40 [INFO]: Epoch 021 - training loss: 0.6300, validation loss: 0.3393
2024-05-23 23:01:52 [INFO]: Epoch 022 - training loss: 0.6253, validation loss: 0.3388
2024-05-23 23:02:04 [INFO]: Epoch 023 - training loss: 0.6222, validation loss: 0.3372
2024-05-23 23:02:16 [INFO]: Epoch 024 - training loss: 0.6194, validation loss: 0.3370
2024-05-23 23:02:28 [INFO]: Epoch 025 - training loss: 0.6189, validation loss: 0.3352
2024-05-23 23:02:40 [INFO]: Epoch 026 - training loss: 0.6146, validation loss: 0.3342
2024-05-23 23:02:52 [INFO]: Epoch 027 - training loss: 0.6105, validation loss: 0.3349
2024-05-23 23:03:05 [INFO]: Epoch 028 - training loss: 0.6063, validation loss: 0.3319
2024-05-23 23:03:17 [INFO]: Epoch 029 - training loss: 0.6032, validation loss: 0.3314
2024-05-23 23:03:29 [INFO]: Epoch 030 - training loss: 0.6008, validation loss: 0.3315
2024-05-23 23:03:41 [INFO]: Epoch 031 - training loss: 0.5985, validation loss: 0.3306
2024-05-23 23:03:53 [INFO]: Epoch 032 - training loss: 0.5950, validation loss: 0.3321
2024-05-23 23:04:05 [INFO]: Epoch 033 - training loss: 0.5922, validation loss: 0.3323
2024-05-23 23:04:17 [INFO]: Epoch 034 - training loss: 0.5890, validation loss: 0.3322
2024-05-23 23:04:29 [INFO]: Epoch 035 - training loss: 0.5864, validation loss: 0.3316
2024-05-23 23:04:41 [INFO]: Epoch 036 - training loss: 0.5864, validation loss: 0.3371
2024-05-23 23:04:53 [INFO]: Epoch 037 - training loss: 0.5932, validation loss: 0.3318
2024-05-23 23:05:05 [INFO]: Epoch 038 - training loss: 0.5860, validation loss: 0.3323
2024-05-23 23:05:17 [INFO]: Epoch 039 - training loss: 0.5801, validation loss: 0.3333
2024-05-23 23:05:29 [INFO]: Epoch 040 - training loss: 0.5755, validation loss: 0.3319
2024-05-23 23:05:42 [INFO]: Epoch 041 - training loss: 0.5722, validation loss: 0.3339
2024-05-23 23:05:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:05:42 [INFO]: Finished training. The best model is from epoch#31.
2024-05-23 23:05:42 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T225724/BRITS.pypots
2024-05-23 23:05:44 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2610, MSE=0.3419
2024-05-23 23:05:54 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 23:05:54 [INFO]: Using the given device: cuda:0
2024-05-23 23:05:54 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554
2024-05-23 23:05:54 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/tensorboard
2024-05-23 23:05:54 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 23:05:59 [INFO]: Epoch 001 - training loss: 1.2398, validation loss: 1.0120
2024-05-23 23:05:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch1_loss1.0120332688093185.pypots
2024-05-23 23:06:02 [INFO]: Epoch 002 - training loss: 0.7985, validation loss: 0.9855
2024-05-23 23:06:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch2_loss0.985474881529808.pypots
2024-05-23 23:06:05 [INFO]: Epoch 003 - training loss: 0.6484, validation loss: 0.9596
2024-05-23 23:06:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch3_loss0.9596320450305938.pypots
2024-05-23 23:06:08 [INFO]: Epoch 004 - training loss: 0.6030, validation loss: 0.9418
2024-05-23 23:06:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch4_loss0.9417663872241974.pypots
2024-05-23 23:06:11 [INFO]: Epoch 005 - training loss: 0.5690, validation loss: 0.9340
2024-05-23 23:06:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch5_loss0.9340354174375534.pypots
2024-05-23 23:06:13 [INFO]: Epoch 006 - training loss: 0.5490, validation loss: 0.9303
2024-05-23 23:06:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch6_loss0.9302769303321838.pypots
2024-05-23 23:06:16 [INFO]: Epoch 007 - training loss: 0.5337, validation loss: 0.9264
2024-05-23 23:06:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch7_loss0.9264172732830047.pypots
2024-05-23 23:06:19 [INFO]: Epoch 008 - training loss: 0.5197, validation loss: 0.9258
2024-05-23 23:06:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch8_loss0.9257634878158569.pypots
2024-05-23 23:06:22 [INFO]: Epoch 009 - training loss: 0.5133, validation loss: 0.9232
2024-05-23 23:06:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch9_loss0.9232156276702881.pypots
2024-05-23 23:06:24 [INFO]: Epoch 010 - training loss: 0.4984, validation loss: 0.9222
2024-05-23 23:06:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch10_loss0.9221862077713012.pypots
2024-05-23 23:06:27 [INFO]: Epoch 011 - training loss: 0.4962, validation loss: 0.9220
2024-05-23 23:06:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch11_loss0.9219895869493484.pypots
2024-05-23 23:06:30 [INFO]: Epoch 012 - training loss: 0.4867, validation loss: 0.9215
2024-05-23 23:06:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch12_loss0.9214627981185913.pypots
2024-05-23 23:06:33 [INFO]: Epoch 013 - training loss: 0.4824, validation loss: 0.9222
2024-05-23 23:06:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch13_loss0.922218245267868.pypots
2024-05-23 23:06:36 [INFO]: Epoch 014 - training loss: 0.4812, validation loss: 0.9231
2024-05-23 23:06:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch14_loss0.9231023907661438.pypots
2024-05-23 23:06:38 [INFO]: Epoch 015 - training loss: 0.4664, validation loss: 0.9238
2024-05-23 23:06:38 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch15_loss0.923794400691986.pypots
2024-05-23 23:06:41 [INFO]: Epoch 016 - training loss: 0.4726, validation loss: 0.9257
2024-05-23 23:06:41 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch16_loss0.9256647735834121.pypots
2024-05-23 23:06:44 [INFO]: Epoch 017 - training loss: 0.4636, validation loss: 0.9262
2024-05-23 23:06:44 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch17_loss0.9262250095605851.pypots
2024-05-23 23:06:47 [INFO]: Epoch 018 - training loss: 0.4643, validation loss: 0.9274
2024-05-23 23:06:47 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch18_loss0.9274193227291108.pypots
2024-05-23 23:06:49 [INFO]: Epoch 019 - training loss: 0.4620, validation loss: 0.9289
2024-05-23 23:06:49 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch19_loss0.9288516491651535.pypots
2024-05-23 23:06:52 [INFO]: Epoch 020 - training loss: 0.4582, validation loss: 0.9293
2024-05-23 23:06:52 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch20_loss0.9293468862771987.pypots
2024-05-23 23:06:55 [INFO]: Epoch 021 - training loss: 0.4478, validation loss: 0.9307
2024-05-23 23:06:55 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch21_loss0.9307158291339874.pypots
2024-05-23 23:06:58 [INFO]: Epoch 022 - training loss: 0.4561, validation loss: 0.9308
2024-05-23 23:06:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN_epoch22_loss0.9307542085647583.pypots
2024-05-23 23:06:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:06:58 [INFO]: Finished training. The best model is from epoch#12.
2024-05-23 23:06:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T230554/MRNN.pypots
2024-05-23 23:06:59 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6843, MSE=0.9334
2024-05-23 23:07:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 23:07:03 [INFO]: Using the given device: cpu
2024-05-23 23:07:03 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4114, MSE=0.6133
2024-05-23 23:07:03 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_physionet_2012_seta".
2024-05-23 23:07:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 23:07:03 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6898, MSE=1.0489
2024-05-23 23:07:03 [INFO]: Successfully created the given path "saved_results/round_1/Median_physionet_2012_seta".
2024-05-23 23:07:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_physionet_2012_seta/imputation.pkl
2024-05-23 23:07:03 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7072, MSE=1.0216
2024-05-23 23:07:03 [INFO]: Successfully created the given path "saved_results/round_1/Mean_physionet_2012_seta".
2024-05-23 23:07:03 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 23:07:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-23 23:07:03 [INFO]: Using the given device: cuda:0
2024-05-23 23:07:03 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T230703
2024-05-23 23:07:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T230703/tensorboard
2024-05-23 23:07:03 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 23:07:05 [INFO]: Epoch 001 - training loss: 1.0568, validation loss: 0.4964
2024-05-23 23:07:06 [INFO]: Epoch 002 - training loss: 0.6763, validation loss: 0.4325
2024-05-23 23:07:07 [INFO]: Epoch 003 - training loss: 0.5718, validation loss: 0.4029
2024-05-23 23:07:08 [INFO]: Epoch 004 - training loss: 0.5191, validation loss: 0.3932
2024-05-23 23:07:10 [INFO]: Epoch 005 - training loss: 0.4806, validation loss: 0.3807
2024-05-23 23:07:11 [INFO]: Epoch 006 - training loss: 0.4565, validation loss: 0.3631
2024-05-23 23:07:12 [INFO]: Epoch 007 - training loss: 0.4396, validation loss: 0.3532
2024-05-23 23:07:14 [INFO]: Epoch 008 - training loss: 0.4231, validation loss: 0.3459
2024-05-23 23:07:15 [INFO]: Epoch 009 - training loss: 0.4028, validation loss: 0.3353
2024-05-23 23:07:16 [INFO]: Epoch 010 - training loss: 0.3855, validation loss: 0.3221
2024-05-23 23:07:17 [INFO]: Epoch 011 - training loss: 0.3743, validation loss: 0.3175
2024-05-23 23:07:19 [INFO]: Epoch 012 - training loss: 0.3662, validation loss: 0.3142
2024-05-23 23:07:20 [INFO]: Epoch 013 - training loss: 0.3586, validation loss: 0.3164
2024-05-23 23:07:21 [INFO]: Epoch 014 - training loss: 0.3521, validation loss: 0.3022
2024-05-23 23:07:22 [INFO]: Epoch 015 - training loss: 0.3409, validation loss: 0.3004
2024-05-23 23:07:24 [INFO]: Epoch 016 - training loss: 0.3400, validation loss: 0.2955
2024-05-23 23:07:25 [INFO]: Epoch 017 - training loss: 0.3314, validation loss: 0.2971
2024-05-23 23:07:26 [INFO]: Epoch 018 - training loss: 0.3229, validation loss: 0.2920
2024-05-23 23:07:27 [INFO]: Epoch 019 - training loss: 0.3225, validation loss: 0.2910
2024-05-23 23:07:29 [INFO]: Epoch 020 - training loss: 0.3137, validation loss: 0.2804
2024-05-23 23:07:30 [INFO]: Epoch 021 - training loss: 0.3072, validation loss: 0.2853
2024-05-23 23:07:31 [INFO]: Epoch 022 - training loss: 0.3071, validation loss: 0.2796
2024-05-23 23:07:33 [INFO]: Epoch 023 - training loss: 0.3025, validation loss: 0.2795
2024-05-23 23:07:34 [INFO]: Epoch 024 - training loss: 0.3008, validation loss: 0.2800
2024-05-23 23:07:35 [INFO]: Epoch 025 - training loss: 0.2945, validation loss: 0.2767
2024-05-23 23:07:36 [INFO]: Epoch 026 - training loss: 0.2940, validation loss: 0.2744
2024-05-23 23:07:38 [INFO]: Epoch 027 - training loss: 0.2939, validation loss: 0.2698
2024-05-23 23:07:39 [INFO]: Epoch 028 - training loss: 0.2904, validation loss: 0.2677
2024-05-23 23:07:40 [INFO]: Epoch 029 - training loss: 0.2891, validation loss: 0.2714
2024-05-23 23:07:41 [INFO]: Epoch 030 - training loss: 0.2847, validation loss: 0.2696
2024-05-23 23:07:43 [INFO]: Epoch 031 - training loss: 0.2825, validation loss: 0.2712
2024-05-23 23:07:44 [INFO]: Epoch 032 - training loss: 0.2850, validation loss: 0.2655
2024-05-23 23:07:45 [INFO]: Epoch 033 - training loss: 0.2813, validation loss: 0.2676
2024-05-23 23:07:46 [INFO]: Epoch 034 - training loss: 0.2777, validation loss: 0.2681
2024-05-23 23:07:48 [INFO]: Epoch 035 - training loss: 0.2771, validation loss: 0.2585
2024-05-23 23:07:49 [INFO]: Epoch 036 - training loss: 0.2749, validation loss: 0.2646
2024-05-23 23:07:50 [INFO]: Epoch 037 - training loss: 0.2729, validation loss: 0.2605
2024-05-23 23:07:52 [INFO]: Epoch 038 - training loss: 0.2751, validation loss: 0.2648
2024-05-23 23:07:53 [INFO]: Epoch 039 - training loss: 0.2726, validation loss: 0.2591
2024-05-23 23:07:54 [INFO]: Epoch 040 - training loss: 0.2744, validation loss: 0.2582
2024-05-23 23:07:55 [INFO]: Epoch 041 - training loss: 0.2706, validation loss: 0.2575
2024-05-23 23:07:57 [INFO]: Epoch 042 - training loss: 0.2692, validation loss: 0.2570
2024-05-23 23:07:58 [INFO]: Epoch 043 - training loss: 0.2671, validation loss: 0.2559
2024-05-23 23:07:59 [INFO]: Epoch 044 - training loss: 0.2658, validation loss: 0.2520
2024-05-23 23:08:00 [INFO]: Epoch 045 - training loss: 0.2659, validation loss: 0.2520
2024-05-23 23:08:02 [INFO]: Epoch 046 - training loss: 0.2657, validation loss: 0.2529
2024-05-23 23:08:03 [INFO]: Epoch 047 - training loss: 0.2664, validation loss: 0.2559
2024-05-23 23:08:04 [INFO]: Epoch 048 - training loss: 0.2632, validation loss: 0.2545
2024-05-23 23:08:05 [INFO]: Epoch 049 - training loss: 0.2641, validation loss: 0.2543
2024-05-23 23:08:07 [INFO]: Epoch 050 - training loss: 0.2608, validation loss: 0.2547
2024-05-23 23:08:08 [INFO]: Epoch 051 - training loss: 0.2618, validation loss: 0.2541
2024-05-23 23:08:09 [INFO]: Epoch 052 - training loss: 0.2611, validation loss: 0.2498
2024-05-23 23:08:11 [INFO]: Epoch 053 - training loss: 0.2600, validation loss: 0.2526
2024-05-23 23:08:12 [INFO]: Epoch 054 - training loss: 0.2592, validation loss: 0.2559
2024-05-23 23:08:13 [INFO]: Epoch 055 - training loss: 0.2597, validation loss: 0.2491
2024-05-23 23:08:14 [INFO]: Epoch 056 - training loss: 0.2589, validation loss: 0.2573
2024-05-23 23:08:16 [INFO]: Epoch 057 - training loss: 0.2629, validation loss: 0.2535
2024-05-23 23:08:17 [INFO]: Epoch 058 - training loss: 0.2560, validation loss: 0.2564
2024-05-23 23:08:18 [INFO]: Epoch 059 - training loss: 0.2542, validation loss: 0.2531
2024-05-23 23:08:20 [INFO]: Epoch 060 - training loss: 0.2519, validation loss: 0.2522
2024-05-23 23:08:21 [INFO]: Epoch 061 - training loss: 0.2565, validation loss: 0.2795
2024-05-23 23:08:22 [INFO]: Epoch 062 - training loss: 0.2530, validation loss: 0.2552
2024-05-23 23:08:23 [INFO]: Epoch 063 - training loss: 0.2549, validation loss: 0.2547
2024-05-23 23:08:25 [INFO]: Epoch 064 - training loss: 0.2530, validation loss: 0.2520
2024-05-23 23:08:26 [INFO]: Epoch 065 - training loss: 0.2502, validation loss: 0.2496
2024-05-23 23:08:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:08:26 [INFO]: Finished training. The best model is from epoch#55.
2024-05-23 23:08:26 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T230703/SAITS.pypots
2024-05-23 23:08:26 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2087, MSE=0.2595
2024-05-23 23:08:26 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 23:08:26 [INFO]: Using the given device: cuda:0
2024-05-23 23:08:26 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T230826
2024-05-23 23:08:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T230826/tensorboard
2024-05-23 23:08:26 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 23:08:27 [INFO]: Epoch 001 - training loss: 1.2163, validation loss: 0.6032
2024-05-23 23:08:28 [INFO]: Epoch 002 - training loss: 0.7667, validation loss: 0.4857
2024-05-23 23:08:29 [INFO]: Epoch 003 - training loss: 0.6411, validation loss: 0.4618
2024-05-23 23:08:29 [INFO]: Epoch 004 - training loss: 0.5894, validation loss: 0.4363
2024-05-23 23:08:30 [INFO]: Epoch 005 - training loss: 0.5521, validation loss: 0.4243
2024-05-23 23:08:31 [INFO]: Epoch 006 - training loss: 0.5201, validation loss: 0.4179
2024-05-23 23:08:31 [INFO]: Epoch 007 - training loss: 0.5050, validation loss: 0.4094
2024-05-23 23:08:32 [INFO]: Epoch 008 - training loss: 0.4824, validation loss: 0.3964
2024-05-23 23:08:33 [INFO]: Epoch 009 - training loss: 0.4661, validation loss: 0.3911
2024-05-23 23:08:33 [INFO]: Epoch 010 - training loss: 0.4461, validation loss: 0.3845
2024-05-23 23:08:34 [INFO]: Epoch 011 - training loss: 0.4378, validation loss: 0.3880
2024-05-23 23:08:35 [INFO]: Epoch 012 - training loss: 0.4348, validation loss: 0.3707
2024-05-23 23:08:36 [INFO]: Epoch 013 - training loss: 0.4171, validation loss: 0.3658
2024-05-23 23:08:36 [INFO]: Epoch 014 - training loss: 0.4078, validation loss: 0.3617
2024-05-23 23:08:37 [INFO]: Epoch 015 - training loss: 0.4033, validation loss: 0.3568
2024-05-23 23:08:38 [INFO]: Epoch 016 - training loss: 0.3977, validation loss: 0.3493
2024-05-23 23:08:38 [INFO]: Epoch 017 - training loss: 0.3873, validation loss: 0.3488
2024-05-23 23:08:39 [INFO]: Epoch 018 - training loss: 0.3818, validation loss: 0.3396
2024-05-23 23:08:40 [INFO]: Epoch 019 - training loss: 0.3786, validation loss: 0.3424
2024-05-23 23:08:41 [INFO]: Epoch 020 - training loss: 0.3701, validation loss: 0.3401
2024-05-23 23:08:41 [INFO]: Epoch 021 - training loss: 0.3667, validation loss: 0.3309
2024-05-23 23:08:42 [INFO]: Epoch 022 - training loss: 0.3606, validation loss: 0.3353
2024-05-23 23:08:43 [INFO]: Epoch 023 - training loss: 0.3605, validation loss: 0.3305
2024-05-23 23:08:43 [INFO]: Epoch 024 - training loss: 0.3514, validation loss: 0.3256
2024-05-23 23:08:44 [INFO]: Epoch 025 - training loss: 0.3510, validation loss: 0.3272
2024-05-23 23:08:45 [INFO]: Epoch 026 - training loss: 0.3450, validation loss: 0.3190
2024-05-23 23:08:45 [INFO]: Epoch 027 - training loss: 0.3450, validation loss: 0.3200
2024-05-23 23:08:46 [INFO]: Epoch 028 - training loss: 0.3446, validation loss: 0.3156
2024-05-23 23:08:47 [INFO]: Epoch 029 - training loss: 0.3393, validation loss: 0.3134
2024-05-23 23:08:48 [INFO]: Epoch 030 - training loss: 0.3376, validation loss: 0.3192
2024-05-23 23:08:48 [INFO]: Epoch 031 - training loss: 0.3353, validation loss: 0.3145
2024-05-23 23:08:49 [INFO]: Epoch 032 - training loss: 0.3329, validation loss: 0.3119
2024-05-23 23:08:50 [INFO]: Epoch 033 - training loss: 0.3271, validation loss: 0.3072
2024-05-23 23:08:50 [INFO]: Epoch 034 - training loss: 0.3264, validation loss: 0.3077
2024-05-23 23:08:51 [INFO]: Epoch 035 - training loss: 0.3270, validation loss: 0.3100
2024-05-23 23:08:52 [INFO]: Epoch 036 - training loss: 0.3261, validation loss: 0.3033
2024-05-23 23:08:52 [INFO]: Epoch 037 - training loss: 0.3237, validation loss: 0.3060
2024-05-23 23:08:53 [INFO]: Epoch 038 - training loss: 0.3245, validation loss: 0.3076
2024-05-23 23:08:54 [INFO]: Epoch 039 - training loss: 0.3211, validation loss: 0.3020
2024-05-23 23:08:55 [INFO]: Epoch 040 - training loss: 0.3201, validation loss: 0.2982
2024-05-23 23:08:55 [INFO]: Epoch 041 - training loss: 0.3191, validation loss: 0.2985
2024-05-23 23:08:56 [INFO]: Epoch 042 - training loss: 0.3164, validation loss: 0.2998
2024-05-23 23:08:57 [INFO]: Epoch 043 - training loss: 0.3148, validation loss: 0.2950
2024-05-23 23:08:57 [INFO]: Epoch 044 - training loss: 0.3097, validation loss: 0.2975
2024-05-23 23:08:58 [INFO]: Epoch 045 - training loss: 0.3073, validation loss: 0.2931
2024-05-23 23:08:59 [INFO]: Epoch 046 - training loss: 0.3086, validation loss: 0.2961
2024-05-23 23:08:59 [INFO]: Epoch 047 - training loss: 0.3107, validation loss: 0.2947
2024-05-23 23:09:00 [INFO]: Epoch 048 - training loss: 0.3059, validation loss: 0.2946
2024-05-23 23:09:01 [INFO]: Epoch 049 - training loss: 0.3065, validation loss: 0.2917
2024-05-23 23:09:02 [INFO]: Epoch 050 - training loss: 0.3034, validation loss: 0.2919
2024-05-23 23:09:02 [INFO]: Epoch 051 - training loss: 0.3046, validation loss: 0.2884
2024-05-23 23:09:03 [INFO]: Epoch 052 - training loss: 0.3035, validation loss: 0.2872
2024-05-23 23:09:04 [INFO]: Epoch 053 - training loss: 0.3001, validation loss: 0.2860
2024-05-23 23:09:04 [INFO]: Epoch 054 - training loss: 0.3005, validation loss: 0.2871
2024-05-23 23:09:05 [INFO]: Epoch 055 - training loss: 0.2996, validation loss: 0.2852
2024-05-23 23:09:06 [INFO]: Epoch 056 - training loss: 0.3023, validation loss: 0.2858
2024-05-23 23:09:06 [INFO]: Epoch 057 - training loss: 0.2972, validation loss: 0.2832
2024-05-23 23:09:07 [INFO]: Epoch 058 - training loss: 0.2964, validation loss: 0.2829
2024-05-23 23:09:08 [INFO]: Epoch 059 - training loss: 0.2949, validation loss: 0.2834
2024-05-23 23:09:09 [INFO]: Epoch 060 - training loss: 0.2944, validation loss: 0.2810
2024-05-23 23:09:09 [INFO]: Epoch 061 - training loss: 0.2962, validation loss: 0.2776
2024-05-23 23:09:10 [INFO]: Epoch 062 - training loss: 0.2928, validation loss: 0.2778
2024-05-23 23:09:11 [INFO]: Epoch 063 - training loss: 0.2932, validation loss: 0.2787
2024-05-23 23:09:11 [INFO]: Epoch 064 - training loss: 0.2925, validation loss: 0.2831
2024-05-23 23:09:12 [INFO]: Epoch 065 - training loss: 0.2921, validation loss: 0.2754
2024-05-23 23:09:13 [INFO]: Epoch 066 - training loss: 0.2891, validation loss: 0.2767
2024-05-23 23:09:13 [INFO]: Epoch 067 - training loss: 0.2871, validation loss: 0.2770
2024-05-23 23:09:14 [INFO]: Epoch 068 - training loss: 0.2871, validation loss: 0.2775
2024-05-23 23:09:15 [INFO]: Epoch 069 - training loss: 0.2897, validation loss: 0.2752
2024-05-23 23:09:16 [INFO]: Epoch 070 - training loss: 0.2865, validation loss: 0.2766
2024-05-23 23:09:16 [INFO]: Epoch 071 - training loss: 0.2871, validation loss: 0.2761
2024-05-23 23:09:17 [INFO]: Epoch 072 - training loss: 0.2838, validation loss: 0.2745
2024-05-23 23:09:18 [INFO]: Epoch 073 - training loss: 0.2865, validation loss: 0.2740
2024-05-23 23:09:18 [INFO]: Epoch 074 - training loss: 0.2834, validation loss: 0.2749
2024-05-23 23:09:19 [INFO]: Epoch 075 - training loss: 0.2856, validation loss: 0.2740
2024-05-23 23:09:20 [INFO]: Epoch 076 - training loss: 0.2831, validation loss: 0.2732
2024-05-23 23:09:20 [INFO]: Epoch 077 - training loss: 0.2841, validation loss: 0.2735
2024-05-23 23:09:21 [INFO]: Epoch 078 - training loss: 0.2815, validation loss: 0.2692
2024-05-23 23:09:22 [INFO]: Epoch 079 - training loss: 0.2828, validation loss: 0.2701
2024-05-23 23:09:22 [INFO]: Epoch 080 - training loss: 0.2808, validation loss: 0.2682
2024-05-23 23:09:23 [INFO]: Epoch 081 - training loss: 0.2822, validation loss: 0.2663
2024-05-23 23:09:24 [INFO]: Epoch 082 - training loss: 0.2803, validation loss: 0.2663
2024-05-23 23:09:25 [INFO]: Epoch 083 - training loss: 0.2816, validation loss: 0.2674
2024-05-23 23:09:25 [INFO]: Epoch 084 - training loss: 0.2774, validation loss: 0.2669
2024-05-23 23:09:26 [INFO]: Epoch 085 - training loss: 0.2769, validation loss: 0.2644
2024-05-23 23:09:27 [INFO]: Epoch 086 - training loss: 0.2813, validation loss: 0.2660
2024-05-23 23:09:27 [INFO]: Epoch 087 - training loss: 0.2772, validation loss: 0.2708
2024-05-23 23:09:28 [INFO]: Epoch 088 - training loss: 0.2788, validation loss: 0.2699
2024-05-23 23:09:29 [INFO]: Epoch 089 - training loss: 0.2771, validation loss: 0.2683
2024-05-23 23:09:29 [INFO]: Epoch 090 - training loss: 0.2752, validation loss: 0.2655
2024-05-23 23:09:30 [INFO]: Epoch 091 - training loss: 0.2753, validation loss: 0.2689
2024-05-23 23:09:31 [INFO]: Epoch 092 - training loss: 0.2783, validation loss: 0.2643
2024-05-23 23:09:32 [INFO]: Epoch 093 - training loss: 0.2742, validation loss: 0.2699
2024-05-23 23:09:32 [INFO]: Epoch 094 - training loss: 0.2745, validation loss: 0.2637
2024-05-23 23:09:33 [INFO]: Epoch 095 - training loss: 0.2719, validation loss: 0.2660
2024-05-23 23:09:34 [INFO]: Epoch 096 - training loss: 0.2737, validation loss: 0.2669
2024-05-23 23:09:34 [INFO]: Epoch 097 - training loss: 0.2730, validation loss: 0.2669
2024-05-23 23:09:35 [INFO]: Epoch 098 - training loss: 0.2706, validation loss: 0.2676
2024-05-23 23:09:36 [INFO]: Epoch 099 - training loss: 0.2712, validation loss: 0.2657
2024-05-23 23:09:36 [INFO]: Epoch 100 - training loss: 0.2703, validation loss: 0.2650
2024-05-23 23:09:37 [INFO]: Epoch 101 - training loss: 0.2682, validation loss: 0.2652
2024-05-23 23:09:38 [INFO]: Epoch 102 - training loss: 0.2706, validation loss: 0.2630
2024-05-23 23:09:38 [INFO]: Epoch 103 - training loss: 0.2703, validation loss: 0.2660
2024-05-23 23:09:39 [INFO]: Epoch 104 - training loss: 0.2721, validation loss: 0.2667
2024-05-23 23:09:40 [INFO]: Epoch 105 - training loss: 0.2681, validation loss: 0.2681
2024-05-23 23:09:41 [INFO]: Epoch 106 - training loss: 0.2671, validation loss: 0.2634
2024-05-23 23:09:41 [INFO]: Epoch 107 - training loss: 0.2651, validation loss: 0.2631
2024-05-23 23:09:42 [INFO]: Epoch 108 - training loss: 0.2689, validation loss: 0.2643
2024-05-23 23:09:43 [INFO]: Epoch 109 - training loss: 0.2650, validation loss: 0.2638
2024-05-23 23:09:43 [INFO]: Epoch 110 - training loss: 0.2683, validation loss: 0.2649
2024-05-23 23:09:44 [INFO]: Epoch 111 - training loss: 0.2648, validation loss: 0.2619
2024-05-23 23:09:45 [INFO]: Epoch 112 - training loss: 0.2667, validation loss: 0.2661
2024-05-23 23:09:45 [INFO]: Epoch 113 - training loss: 0.2643, validation loss: 0.2603
2024-05-23 23:09:46 [INFO]: Epoch 114 - training loss: 0.2623, validation loss: 0.2625
2024-05-23 23:09:47 [INFO]: Epoch 115 - training loss: 0.2650, validation loss: 0.2610
2024-05-23 23:09:47 [INFO]: Epoch 116 - training loss: 0.2660, validation loss: 0.2629
2024-05-23 23:09:48 [INFO]: Epoch 117 - training loss: 0.2617, validation loss: 0.2621
2024-05-23 23:09:49 [INFO]: Epoch 118 - training loss: 0.2652, validation loss: 0.2592
2024-05-23 23:09:50 [INFO]: Epoch 119 - training loss: 0.2642, validation loss: 0.2656
2024-05-23 23:09:50 [INFO]: Epoch 120 - training loss: 0.2621, validation loss: 0.2604
2024-05-23 23:09:51 [INFO]: Epoch 121 - training loss: 0.2626, validation loss: 0.2628
2024-05-23 23:09:52 [INFO]: Epoch 122 - training loss: 0.2608, validation loss: 0.2616
2024-05-23 23:09:52 [INFO]: Epoch 123 - training loss: 0.2605, validation loss: 0.2597
2024-05-23 23:09:53 [INFO]: Epoch 124 - training loss: 0.2608, validation loss: 0.2609
2024-05-23 23:09:54 [INFO]: Epoch 125 - training loss: 0.2633, validation loss: 0.2613
2024-05-23 23:09:54 [INFO]: Epoch 126 - training loss: 0.2588, validation loss: 0.2551
2024-05-23 23:09:55 [INFO]: Epoch 127 - training loss: 0.2618, validation loss: 0.2590
2024-05-23 23:09:56 [INFO]: Epoch 128 - training loss: 0.2598, validation loss: 0.2672
2024-05-23 23:09:56 [INFO]: Epoch 129 - training loss: 0.2608, validation loss: 0.2577
2024-05-23 23:09:57 [INFO]: Epoch 130 - training loss: 0.2593, validation loss: 0.2602
2024-05-23 23:09:58 [INFO]: Epoch 131 - training loss: 0.2580, validation loss: 0.2558
2024-05-23 23:09:59 [INFO]: Epoch 132 - training loss: 0.2558, validation loss: 0.2600
2024-05-23 23:09:59 [INFO]: Epoch 133 - training loss: 0.2572, validation loss: 0.2577
2024-05-23 23:10:00 [INFO]: Epoch 134 - training loss: 0.2571, validation loss: 0.2622
2024-05-23 23:10:01 [INFO]: Epoch 135 - training loss: 0.2594, validation loss: 0.2571
2024-05-23 23:10:01 [INFO]: Epoch 136 - training loss: 0.2588, validation loss: 0.2632
2024-05-23 23:10:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:10:01 [INFO]: Finished training. The best model is from epoch#126.
2024-05-23 23:10:01 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T230826/Transformer.pypots
2024-05-23 23:10:01 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2207, MSE=0.2721
2024-05-23 23:10:02 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 23:10:02 [INFO]: Using the given device: cuda:0
2024-05-23 23:10:02 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T231002
2024-05-23 23:10:02 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T231002/tensorboard
2024-05-23 23:10:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 23:10:03 [INFO]: Epoch 001 - training loss: 0.4543, validation loss: 0.3427
2024-05-23 23:10:03 [INFO]: Epoch 002 - training loss: 0.4413, validation loss: 0.3256
2024-05-23 23:10:04 [INFO]: Epoch 003 - training loss: 0.3578, validation loss: 0.8208
2024-05-23 23:10:05 [INFO]: Epoch 004 - training loss: 0.4416, validation loss: 0.3358
2024-05-23 23:10:06 [INFO]: Epoch 005 - training loss: 0.3967, validation loss: 0.3228
2024-05-23 23:10:07 [INFO]: Epoch 006 - training loss: 0.3582, validation loss: 1.3462
2024-05-23 23:10:07 [INFO]: Epoch 007 - training loss: 0.6156, validation loss: 1.0692
2024-05-23 23:10:08 [INFO]: Epoch 008 - training loss: 0.3641, validation loss: 0.6571
2024-05-23 23:10:09 [INFO]: Epoch 009 - training loss: 0.4636, validation loss: 1.2731
2024-05-23 23:10:10 [INFO]: Epoch 010 - training loss: 0.5298, validation loss: 0.3478
2024-05-23 23:10:11 [INFO]: Epoch 011 - training loss: 0.3842, validation loss: 0.3433
2024-05-23 23:10:11 [INFO]: Epoch 012 - training loss: 0.3763, validation loss: 0.3720
2024-05-23 23:10:12 [INFO]: Epoch 013 - training loss: 0.3633, validation loss: 0.3077
2024-05-23 23:10:13 [INFO]: Epoch 014 - training loss: 0.3282, validation loss: 0.3065
2024-05-23 23:10:14 [INFO]: Epoch 015 - training loss: 0.3280, validation loss: 0.3225
2024-05-23 23:10:15 [INFO]: Epoch 016 - training loss: 0.3390, validation loss: 0.3036
2024-05-23 23:10:15 [INFO]: Epoch 017 - training loss: 0.3580, validation loss: 0.3205
2024-05-23 23:10:16 [INFO]: Epoch 018 - training loss: 0.3428, validation loss: 0.3017
2024-05-23 23:10:17 [INFO]: Epoch 019 - training loss: 0.3385, validation loss: 0.3034
2024-05-23 23:10:18 [INFO]: Epoch 020 - training loss: 0.3261, validation loss: 0.3055
2024-05-23 23:10:19 [INFO]: Epoch 021 - training loss: 0.3395, validation loss: 0.3475
2024-05-23 23:10:20 [INFO]: Epoch 022 - training loss: 0.3289, validation loss: 0.3134
2024-05-23 23:10:20 [INFO]: Epoch 023 - training loss: 0.3239, validation loss: 0.3213
2024-05-23 23:10:21 [INFO]: Epoch 024 - training loss: 0.3213, validation loss: 0.3572
2024-05-23 23:10:22 [INFO]: Epoch 025 - training loss: 0.2889, validation loss: 0.3472
2024-05-23 23:10:23 [INFO]: Epoch 026 - training loss: 0.3106, validation loss: 0.3390
2024-05-23 23:10:24 [INFO]: Epoch 027 - training loss: 0.3252, validation loss: 0.3449
2024-05-23 23:10:24 [INFO]: Epoch 028 - training loss: 0.3142, validation loss: 0.4291
2024-05-23 23:10:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:10:24 [INFO]: Finished training. The best model is from epoch#18.
2024-05-23 23:10:24 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T231002/TimesNet.pypots
2024-05-23 23:10:24 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2865, MSE=0.3282
2024-05-23 23:10:25 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 23:10:25 [INFO]: Using the given device: cuda:0
2024-05-23 23:10:25 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025
2024-05-23 23:10:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/tensorboard
2024-05-23 23:10:25 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 23:11:08 [INFO]: Epoch 001 - training loss: 0.4118, validation loss: 0.3357
2024-05-23 23:11:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch1_loss0.3357318609952927.pypots
2024-05-23 23:11:52 [INFO]: Epoch 002 - training loss: 0.3315, validation loss: 0.2882
2024-05-23 23:11:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch2_loss0.2882229074835777.pypots
2024-05-23 23:12:36 [INFO]: Epoch 003 - training loss: 0.2876, validation loss: 0.2504
2024-05-23 23:12:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch3_loss0.25041431188583374.pypots
2024-05-23 23:13:19 [INFO]: Epoch 004 - training loss: 0.2596, validation loss: 0.2337
2024-05-23 23:13:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch4_loss0.23373663872480394.pypots
2024-05-23 23:14:03 [INFO]: Epoch 005 - training loss: 0.2554, validation loss: 0.2231
2024-05-23 23:14:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch5_loss0.22312148436903953.pypots
2024-05-23 23:14:47 [INFO]: Epoch 006 - training loss: 0.2502, validation loss: 0.2189
2024-05-23 23:14:47 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch6_loss0.2188740409910679.pypots
2024-05-23 23:15:31 [INFO]: Epoch 007 - training loss: 0.2410, validation loss: 0.2097
2024-05-23 23:15:31 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch7_loss0.20969129502773284.pypots
2024-05-23 23:16:15 [INFO]: Epoch 008 - training loss: 0.2458, validation loss: 0.2044
2024-05-23 23:16:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch8_loss0.20442312061786652.pypots
2024-05-23 23:16:59 [INFO]: Epoch 009 - training loss: 0.2487, validation loss: 0.2043
2024-05-23 23:16:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch9_loss0.20432094410061835.pypots
2024-05-23 23:17:43 [INFO]: Epoch 010 - training loss: 0.2475, validation loss: 0.2057
2024-05-23 23:17:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch10_loss0.20566550716757775.pypots
2024-05-23 23:18:26 [INFO]: Epoch 011 - training loss: 0.2393, validation loss: 0.2005
2024-05-23 23:18:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch11_loss0.20049306005239487.pypots
2024-05-23 23:19:10 [INFO]: Epoch 012 - training loss: 0.2400, validation loss: 0.1989
2024-05-23 23:19:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch12_loss0.19887107759714126.pypots
2024-05-23 23:19:54 [INFO]: Epoch 013 - training loss: 0.2270, validation loss: 0.1986
2024-05-23 23:19:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch13_loss0.19856954514980316.pypots
2024-05-23 23:20:38 [INFO]: Epoch 014 - training loss: 0.2356, validation loss: 0.1974
2024-05-23 23:20:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch14_loss0.19741229042410852.pypots
2024-05-23 23:21:22 [INFO]: Epoch 015 - training loss: 0.2327, validation loss: 0.1943
2024-05-23 23:21:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch15_loss0.19426265731453896.pypots
2024-05-23 23:22:06 [INFO]: Epoch 016 - training loss: 0.2422, validation loss: 0.1923
2024-05-23 23:22:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch16_loss0.19225146397948265.pypots
2024-05-23 23:22:50 [INFO]: Epoch 017 - training loss: 0.2341, validation loss: 0.1944
2024-05-23 23:22:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch17_loss0.19439449682831764.pypots
2024-05-23 23:23:34 [INFO]: Epoch 018 - training loss: 0.2268, validation loss: 0.1931
2024-05-23 23:23:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch18_loss0.1930510073900223.pypots
2024-05-23 23:24:18 [INFO]: Epoch 019 - training loss: 0.2429, validation loss: 0.1933
2024-05-23 23:24:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch19_loss0.19334989190101623.pypots
2024-05-23 23:25:02 [INFO]: Epoch 020 - training loss: 0.2425, validation loss: 0.1912
2024-05-23 23:25:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch20_loss0.19124396666884422.pypots
2024-05-23 23:25:46 [INFO]: Epoch 021 - training loss: 0.2231, validation loss: 0.1925
2024-05-23 23:25:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch21_loss0.19251298829913138.pypots
2024-05-23 23:26:30 [INFO]: Epoch 022 - training loss: 0.2351, validation loss: 0.1928
2024-05-23 23:26:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch22_loss0.1928350120782852.pypots
2024-05-23 23:27:14 [INFO]: Epoch 023 - training loss: 0.2159, validation loss: 0.1884
2024-05-23 23:27:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch23_loss0.18839287459850312.pypots
2024-05-23 23:27:58 [INFO]: Epoch 024 - training loss: 0.2309, validation loss: 0.1931
2024-05-23 23:27:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch24_loss0.1931214861571789.pypots
2024-05-23 23:28:41 [INFO]: Epoch 025 - training loss: 0.2301, validation loss: 0.1879
2024-05-23 23:28:41 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch25_loss0.1878814972937107.pypots
2024-05-23 23:29:25 [INFO]: Epoch 026 - training loss: 0.2429, validation loss: 0.1899
2024-05-23 23:29:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch26_loss0.18989621624350547.pypots
2024-05-23 23:30:08 [INFO]: Epoch 027 - training loss: 0.2292, validation loss: 0.1908
2024-05-23 23:30:08 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch27_loss0.19075267538428306.pypots
2024-05-23 23:30:52 [INFO]: Epoch 028 - training loss: 0.2236, validation loss: 0.1913
2024-05-23 23:30:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch28_loss0.19129215329885482.pypots
2024-05-23 23:31:36 [INFO]: Epoch 029 - training loss: 0.2204, validation loss: 0.1869
2024-05-23 23:31:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch29_loss0.18690174892544748.pypots
2024-05-23 23:32:20 [INFO]: Epoch 030 - training loss: 0.2324, validation loss: 0.1863
2024-05-23 23:32:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch30_loss0.18625192791223527.pypots
2024-05-23 23:33:04 [INFO]: Epoch 031 - training loss: 0.2210, validation loss: 0.1853
2024-05-23 23:33:04 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch31_loss0.18532902374863625.pypots
2024-05-23 23:33:48 [INFO]: Epoch 032 - training loss: 0.2334, validation loss: 0.1870
2024-05-23 23:33:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch32_loss0.18700017109513284.pypots
2024-05-23 23:34:32 [INFO]: Epoch 033 - training loss: 0.2181, validation loss: 0.1862
2024-05-23 23:34:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch33_loss0.1861816793680191.pypots
2024-05-23 23:35:16 [INFO]: Epoch 034 - training loss: 0.2280, validation loss: 0.1909
2024-05-23 23:35:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch34_loss0.19090297147631646.pypots
2024-05-23 23:35:59 [INFO]: Epoch 035 - training loss: 0.2237, validation loss: 0.1854
2024-05-23 23:35:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch35_loss0.18540156334638597.pypots
2024-05-23 23:36:43 [INFO]: Epoch 036 - training loss: 0.2280, validation loss: 0.1838
2024-05-23 23:36:43 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch36_loss0.18377895951271056.pypots
2024-05-23 23:37:26 [INFO]: Epoch 037 - training loss: 0.2247, validation loss: 0.1854
2024-05-23 23:37:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch37_loss0.18535070791840552.pypots
2024-05-23 23:38:09 [INFO]: Epoch 038 - training loss: 0.2247, validation loss: 0.1847
2024-05-23 23:38:10 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch38_loss0.1847128078341484.pypots
2024-05-23 23:38:53 [INFO]: Epoch 039 - training loss: 0.2285, validation loss: 0.1836
2024-05-23 23:38:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch39_loss0.18363398611545562.pypots
2024-05-23 23:39:37 [INFO]: Epoch 040 - training loss: 0.2208, validation loss: 0.1830
2024-05-23 23:39:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch40_loss0.18295927345752716.pypots
2024-05-23 23:40:21 [INFO]: Epoch 041 - training loss: 0.2184, validation loss: 0.1814
2024-05-23 23:40:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch41_loss0.1813829243183136.pypots
2024-05-23 23:41:05 [INFO]: Epoch 042 - training loss: 0.2160, validation loss: 0.1833
2024-05-23 23:41:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch42_loss0.18334849178791046.pypots
2024-05-23 23:41:48 [INFO]: Epoch 043 - training loss: 0.2173, validation loss: 0.1815
2024-05-23 23:41:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch43_loss0.18151582553982734.pypots
2024-05-23 23:42:32 [INFO]: Epoch 044 - training loss: 0.2361, validation loss: 0.1840
2024-05-23 23:42:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch44_loss0.1839991830289364.pypots
2024-05-23 23:43:16 [INFO]: Epoch 045 - training loss: 0.2228, validation loss: 0.1808
2024-05-23 23:43:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch45_loss0.1807558238506317.pypots
2024-05-23 23:44:00 [INFO]: Epoch 046 - training loss: 0.2170, validation loss: 0.1808
2024-05-23 23:44:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch46_loss0.18082852587103843.pypots
2024-05-23 23:44:44 [INFO]: Epoch 047 - training loss: 0.2192, validation loss: 0.1830
2024-05-23 23:44:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch47_loss0.18303005918860435.pypots
2024-05-23 23:45:27 [INFO]: Epoch 048 - training loss: 0.2208, validation loss: 0.1816
2024-05-23 23:45:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch48_loss0.1816105179488659.pypots
2024-05-23 23:46:11 [INFO]: Epoch 049 - training loss: 0.2130, validation loss: 0.1807
2024-05-23 23:46:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch49_loss0.18074773848056794.pypots
2024-05-23 23:46:55 [INFO]: Epoch 050 - training loss: 0.2260, validation loss: 0.1797
2024-05-23 23:46:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch50_loss0.1797416739165783.pypots
2024-05-23 23:47:38 [INFO]: Epoch 051 - training loss: 0.2220, validation loss: 0.1821
2024-05-23 23:47:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch51_loss0.18211558237671852.pypots
2024-05-23 23:48:22 [INFO]: Epoch 052 - training loss: 0.2287, validation loss: 0.1812
2024-05-23 23:48:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch52_loss0.18116386905312537.pypots
2024-05-23 23:49:06 [INFO]: Epoch 053 - training loss: 0.2252, validation loss: 0.1791
2024-05-23 23:49:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch53_loss0.17907543405890464.pypots
2024-05-23 23:49:50 [INFO]: Epoch 054 - training loss: 0.2149, validation loss: 0.1793
2024-05-23 23:49:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch54_loss0.17933817356824874.pypots
2024-05-23 23:50:34 [INFO]: Epoch 055 - training loss: 0.2237, validation loss: 0.1820
2024-05-23 23:50:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch55_loss0.18197280168533325.pypots
2024-05-23 23:51:18 [INFO]: Epoch 056 - training loss: 0.2239, validation loss: 0.1825
2024-05-23 23:51:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch56_loss0.18249121829867362.pypots
2024-05-23 23:52:02 [INFO]: Epoch 057 - training loss: 0.2245, validation loss: 0.1799
2024-05-23 23:52:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch57_loss0.17994560226798056.pypots
2024-05-23 23:52:45 [INFO]: Epoch 058 - training loss: 0.2164, validation loss: 0.1780
2024-05-23 23:52:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch58_loss0.1780362069606781.pypots
2024-05-23 23:53:29 [INFO]: Epoch 059 - training loss: 0.2197, validation loss: 0.1797
2024-05-23 23:53:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch59_loss0.17968822792172431.pypots
2024-05-23 23:54:12 [INFO]: Epoch 060 - training loss: 0.2108, validation loss: 0.1775
2024-05-23 23:54:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch60_loss0.17749403193593025.pypots
2024-05-23 23:54:56 [INFO]: Epoch 061 - training loss: 0.2192, validation loss: 0.1801
2024-05-23 23:54:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch61_loss0.1800939068198204.pypots
2024-05-23 23:55:39 [INFO]: Epoch 062 - training loss: 0.2124, validation loss: 0.1800
2024-05-23 23:55:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch62_loss0.18004560694098473.pypots
2024-05-23 23:56:23 [INFO]: Epoch 063 - training loss: 0.2225, validation loss: 0.1762
2024-05-23 23:56:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch63_loss0.17623829916119577.pypots
2024-05-23 23:57:06 [INFO]: Epoch 064 - training loss: 0.2242, validation loss: 0.1796
2024-05-23 23:57:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch64_loss0.17962427884340287.pypots
2024-05-23 23:57:50 [INFO]: Epoch 065 - training loss: 0.2164, validation loss: 0.1763
2024-05-23 23:57:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch65_loss0.1763323649764061.pypots
2024-05-23 23:58:34 [INFO]: Epoch 066 - training loss: 0.2198, validation loss: 0.1789
2024-05-23 23:58:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch66_loss0.1789086289703846.pypots
2024-05-23 23:59:18 [INFO]: Epoch 067 - training loss: 0.2224, validation loss: 0.1773
2024-05-23 23:59:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch67_loss0.17731306180357934.pypots
2024-05-24 00:00:02 [INFO]: Epoch 068 - training loss: 0.2097, validation loss: 0.1769
2024-05-24 00:00:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch68_loss0.1768720306456089.pypots
2024-05-24 00:00:46 [INFO]: Epoch 069 - training loss: 0.2318, validation loss: 0.1768
2024-05-24 00:00:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch69_loss0.17681143209338188.pypots
2024-05-24 00:01:30 [INFO]: Epoch 070 - training loss: 0.2226, validation loss: 0.1783
2024-05-24 00:01:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch70_loss0.17825077772140502.pypots
2024-05-24 00:02:14 [INFO]: Epoch 071 - training loss: 0.2167, validation loss: 0.1766
2024-05-24 00:02:14 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch71_loss0.17657849118113517.pypots
2024-05-24 00:02:58 [INFO]: Epoch 072 - training loss: 0.2239, validation loss: 0.1762
2024-05-24 00:02:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch72_loss0.17619226425886153.pypots
2024-05-24 00:03:41 [INFO]: Epoch 073 - training loss: 0.2206, validation loss: 0.1769
2024-05-24 00:03:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch73_loss0.1768665425479412.pypots
2024-05-24 00:04:25 [INFO]: Epoch 074 - training loss: 0.2045, validation loss: 0.1765
2024-05-24 00:04:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch74_loss0.17653556317090988.pypots
2024-05-24 00:05:09 [INFO]: Epoch 075 - training loss: 0.2083, validation loss: 0.1761
2024-05-24 00:05:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch75_loss0.176126691699028.pypots
2024-05-24 00:05:53 [INFO]: Epoch 076 - training loss: 0.2143, validation loss: 0.1769
2024-05-24 00:05:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch76_loss0.17694150432944297.pypots
2024-05-24 00:06:37 [INFO]: Epoch 077 - training loss: 0.2178, validation loss: 0.1773
2024-05-24 00:06:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch77_loss0.1773123860359192.pypots
2024-05-24 00:07:21 [INFO]: Epoch 078 - training loss: 0.2169, validation loss: 0.1750
2024-05-24 00:07:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch78_loss0.17500275373458862.pypots
2024-05-24 00:08:05 [INFO]: Epoch 079 - training loss: 0.2206, validation loss: 0.1750
2024-05-24 00:08:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch79_loss0.17495696917176246.pypots
2024-05-24 00:08:48 [INFO]: Epoch 080 - training loss: 0.2205, validation loss: 0.1747
2024-05-24 00:08:49 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch80_loss0.1747286707162857.pypots
2024-05-24 00:09:32 [INFO]: Epoch 081 - training loss: 0.2257, validation loss: 0.1777
2024-05-24 00:09:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch81_loss0.17768806889653205.pypots
2024-05-24 00:10:16 [INFO]: Epoch 082 - training loss: 0.2196, validation loss: 0.1732
2024-05-24 00:10:16 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch82_loss0.1732012264430523.pypots
2024-05-24 00:11:00 [INFO]: Epoch 083 - training loss: 0.2268, validation loss: 0.1773
2024-05-24 00:11:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch83_loss0.1772691197693348.pypots
2024-05-24 00:11:44 [INFO]: Epoch 084 - training loss: 0.2120, validation loss: 0.1751
2024-05-24 00:11:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch84_loss0.17508099749684333.pypots
2024-05-24 00:12:28 [INFO]: Epoch 085 - training loss: 0.2244, validation loss: 0.1762
2024-05-24 00:12:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch85_loss0.1762412056326866.pypots
2024-05-24 00:13:12 [INFO]: Epoch 086 - training loss: 0.2229, validation loss: 0.1753
2024-05-24 00:13:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch86_loss0.17532862797379495.pypots
2024-05-24 00:13:55 [INFO]: Epoch 087 - training loss: 0.2112, validation loss: 0.1751
2024-05-24 00:13:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch87_loss0.1750507913529873.pypots
2024-05-24 00:14:39 [INFO]: Epoch 088 - training loss: 0.2137, validation loss: 0.1763
2024-05-24 00:14:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch88_loss0.17627547308802605.pypots
2024-05-24 00:15:23 [INFO]: Epoch 089 - training loss: 0.2171, validation loss: 0.1757
2024-05-24 00:15:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch89_loss0.17571799457073212.pypots
2024-05-24 00:16:07 [INFO]: Epoch 090 - training loss: 0.1974, validation loss: 0.1763
2024-05-24 00:16:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch90_loss0.17628661319613456.pypots
2024-05-24 00:16:51 [INFO]: Epoch 091 - training loss: 0.2169, validation loss: 0.1734
2024-05-24 00:16:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch91_loss0.17340094074606896.pypots
2024-05-24 00:17:35 [INFO]: Epoch 092 - training loss: 0.2127, validation loss: 0.1724
2024-05-24 00:17:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch92_loss0.1724012315273285.pypots
2024-05-24 00:18:18 [INFO]: Epoch 093 - training loss: 0.2211, validation loss: 0.1732
2024-05-24 00:18:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch93_loss0.17321941256523132.pypots
2024-05-24 00:19:02 [INFO]: Epoch 094 - training loss: 0.2072, validation loss: 0.1782
2024-05-24 00:19:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch94_loss0.17820275500416755.pypots
2024-05-24 00:19:45 [INFO]: Epoch 095 - training loss: 0.2203, validation loss: 0.1751
2024-05-24 00:19:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch95_loss0.17511529549956323.pypots
2024-05-24 00:20:29 [INFO]: Epoch 096 - training loss: 0.2113, validation loss: 0.1737
2024-05-24 00:20:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch96_loss0.1736901268362999.pypots
2024-05-24 00:21:12 [INFO]: Epoch 097 - training loss: 0.2159, validation loss: 0.1737
2024-05-24 00:21:12 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch97_loss0.17366765215992927.pypots
2024-05-24 00:21:56 [INFO]: Epoch 098 - training loss: 0.2103, validation loss: 0.1723
2024-05-24 00:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch98_loss0.17231248691678047.pypots
2024-05-24 00:22:39 [INFO]: Epoch 099 - training loss: 0.2235, validation loss: 0.1710
2024-05-24 00:22:39 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch99_loss0.1710023835301399.pypots
2024-05-24 00:23:23 [INFO]: Epoch 100 - training loss: 0.2125, validation loss: 0.1748
2024-05-24 00:23:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch100_loss0.17481643855571746.pypots
2024-05-24 00:24:06 [INFO]: Epoch 101 - training loss: 0.2183, validation loss: 0.1725
2024-05-24 00:24:06 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch101_loss0.1724587596952915.pypots
2024-05-24 00:24:50 [INFO]: Epoch 102 - training loss: 0.2113, validation loss: 0.1740
2024-05-24 00:24:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch102_loss0.17404135167598725.pypots
2024-05-24 00:25:33 [INFO]: Epoch 103 - training loss: 0.2112, validation loss: 0.1729
2024-05-24 00:25:33 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch103_loss0.1729382261633873.pypots
2024-05-24 00:26:17 [INFO]: Epoch 104 - training loss: 0.2223, validation loss: 0.1773
2024-05-24 00:26:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch104_loss0.17727667540311814.pypots
2024-05-24 00:27:01 [INFO]: Epoch 105 - training loss: 0.2211, validation loss: 0.1740
2024-05-24 00:27:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch105_loss0.17401950806379318.pypots
2024-05-24 00:27:45 [INFO]: Epoch 106 - training loss: 0.2137, validation loss: 0.1718
2024-05-24 00:27:45 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch106_loss0.17182805091142656.pypots
2024-05-24 00:28:29 [INFO]: Epoch 107 - training loss: 0.2114, validation loss: 0.1726
2024-05-24 00:28:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch107_loss0.17259953692555427.pypots
2024-05-24 00:29:13 [INFO]: Epoch 108 - training loss: 0.2136, validation loss: 0.1742
2024-05-24 00:29:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch108_loss0.174222119897604.pypots
2024-05-24 00:29:57 [INFO]: Epoch 109 - training loss: 0.2096, validation loss: 0.1740
2024-05-24 00:29:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI_epoch109_loss0.17395093962550162.pypots
2024-05-24 00:29:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:29:57 [INFO]: Finished training. The best model is from epoch#99.
2024-05-24 00:29:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T231025/CSDI.pypots
2024-05-24 00:37:18 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2255, MSE=0.3225
2024-05-24 07:30:31 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 07:34:00 [INFO]: Using the given device: cuda:0
2024-05-24 07:34:01 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_physionet_2012_seta/20240524_T073400
2024-05-24 07:34:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_physionet_2012_seta/20240524_T073400/tensorboard
2024-05-24 07:34:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 07:34:02 [INFO]: Epoch 001 - training loss: 42160.1609, validation loss: 0.9440
2024-05-24 07:34:03 [INFO]: Epoch 002 - training loss: 24423.5632, validation loss: 0.7684
2024-05-24 07:34:04 [INFO]: Epoch 003 - training loss: 23535.1956, validation loss: 0.7223
2024-05-24 07:34:04 [INFO]: Epoch 004 - training loss: 23237.7409, validation loss: 0.7023
2024-05-24 07:34:05 [INFO]: Epoch 005 - training loss: 23089.6854, validation loss: 0.6817
2024-05-24 07:34:05 [INFO]: Epoch 006 - training loss: 23007.6351, validation loss: 0.6805
2024-05-24 07:34:06 [INFO]: Epoch 007 - training loss: 22956.2317, validation loss: 0.6737
2024-05-24 07:34:06 [INFO]: Epoch 008 - training loss: 22923.3227, validation loss: 0.6728
2024-05-24 07:34:07 [INFO]: Epoch 009 - training loss: 22901.2350, validation loss: 0.6742
2024-05-24 07:34:08 [INFO]: Epoch 010 - training loss: 22885.7504, validation loss: 0.6820
2024-05-24 07:34:08 [INFO]: Epoch 011 - training loss: 22874.4297, validation loss: 0.6702
2024-05-24 07:34:09 [INFO]: Epoch 012 - training loss: 22865.8275, validation loss: 0.6632
2024-05-24 07:34:09 [INFO]: Epoch 013 - training loss: 22859.9215, validation loss: 0.6651
2024-05-24 07:34:10 [INFO]: Epoch 014 - training loss: 22855.3014, validation loss: 0.6638
2024-05-24 07:34:11 [INFO]: Epoch 015 - training loss: 22850.0692, validation loss: 0.6619
2024-05-24 07:34:11 [INFO]: Epoch 016 - training loss: 22846.8444, validation loss: 0.6621
2024-05-24 07:34:12 [INFO]: Epoch 017 - training loss: 22843.7105, validation loss: 0.6532
2024-05-24 07:34:12 [INFO]: Epoch 018 - training loss: 22840.9816, validation loss: 0.6535
2024-05-24 07:34:13 [INFO]: Epoch 019 - training loss: 22838.9587, validation loss: 0.6431
2024-05-24 07:34:13 [INFO]: Epoch 020 - training loss: 22837.5010, validation loss: 0.6466
2024-05-24 07:34:14 [INFO]: Epoch 021 - training loss: 22836.7529, validation loss: 0.6403
2024-05-24 07:34:15 [INFO]: Epoch 022 - training loss: 22834.2744, validation loss: 0.6416
2024-05-24 07:34:15 [INFO]: Epoch 023 - training loss: 22832.2467, validation loss: 0.6424
2024-05-24 07:34:16 [INFO]: Epoch 024 - training loss: 22831.0125, validation loss: 0.6305
2024-05-24 07:34:17 [INFO]: Epoch 025 - training loss: 22829.4781, validation loss: 0.6347
2024-05-24 07:34:17 [INFO]: Epoch 026 - training loss: 22828.7827, validation loss: 0.6264
2024-05-24 07:34:18 [INFO]: Epoch 027 - training loss: 22827.8163, validation loss: 0.6226
2024-05-24 07:34:18 [INFO]: Epoch 028 - training loss: 22826.8969, validation loss: 0.6196
2024-05-24 07:34:19 [INFO]: Epoch 029 - training loss: 22824.7151, validation loss: 0.6099
2024-05-24 07:34:19 [INFO]: Epoch 030 - training loss: 22822.4904, validation loss: 0.6040
2024-05-24 07:34:20 [INFO]: Epoch 031 - training loss: 22821.2730, validation loss: 0.6078
2024-05-24 07:34:21 [INFO]: Epoch 032 - training loss: 22820.7025, validation loss: 0.6013
2024-05-24 07:34:21 [INFO]: Epoch 033 - training loss: 22818.8654, validation loss: 0.5934
2024-05-24 07:34:22 [INFO]: Epoch 034 - training loss: 22817.9908, validation loss: 0.5977
2024-05-24 07:34:22 [INFO]: Epoch 035 - training loss: 22816.7112, validation loss: 0.5988
2024-05-24 07:34:23 [INFO]: Epoch 036 - training loss: 22816.1538, validation loss: 0.5914
2024-05-24 07:34:24 [INFO]: Epoch 037 - training loss: 22815.2999, validation loss: 0.5850
2024-05-24 07:34:24 [INFO]: Epoch 038 - training loss: 22814.5652, validation loss: 0.5823
2024-05-24 07:34:25 [INFO]: Epoch 039 - training loss: 22813.8241, validation loss: 0.5783
2024-05-24 07:34:25 [INFO]: Epoch 040 - training loss: 22813.5126, validation loss: 0.5750
2024-05-24 07:34:26 [INFO]: Epoch 041 - training loss: 22811.5815, validation loss: 0.5744
2024-05-24 07:34:27 [INFO]: Epoch 042 - training loss: 22810.7443, validation loss: 0.5653
2024-05-24 07:34:27 [INFO]: Epoch 043 - training loss: 22809.4324, validation loss: 0.5635
2024-05-24 07:34:28 [INFO]: Epoch 044 - training loss: 22808.5116, validation loss: 0.5632
2024-05-24 07:34:28 [INFO]: Epoch 045 - training loss: 22808.1441, validation loss: 0.5614
2024-05-24 07:34:29 [INFO]: Epoch 046 - training loss: 22807.6670, validation loss: 0.5719
2024-05-24 07:34:29 [INFO]: Epoch 047 - training loss: 22807.4050, validation loss: 0.5633
2024-05-24 07:34:30 [INFO]: Epoch 048 - training loss: 22806.5378, validation loss: 0.5539
2024-05-24 07:34:31 [INFO]: Epoch 049 - training loss: 22805.4118, validation loss: 0.5503
2024-05-24 07:34:31 [INFO]: Epoch 050 - training loss: 22804.9575, validation loss: 0.5560
2024-05-24 07:34:32 [INFO]: Epoch 051 - training loss: 22805.0676, validation loss: 0.5502
2024-05-24 07:34:32 [INFO]: Epoch 052 - training loss: 22804.3817, validation loss: 0.5483
2024-05-24 07:34:33 [INFO]: Epoch 053 - training loss: 22804.2433, validation loss: 0.5449
2024-05-24 07:34:33 [INFO]: Epoch 054 - training loss: 22803.4125, validation loss: 0.5466
2024-05-24 07:34:34 [INFO]: Epoch 055 - training loss: 22802.3527, validation loss: 0.5432
2024-05-24 07:34:35 [INFO]: Epoch 056 - training loss: 22801.8069, validation loss: 0.5432
2024-05-24 07:34:35 [INFO]: Epoch 057 - training loss: 22801.3445, validation loss: 0.5350
2024-05-24 07:34:36 [INFO]: Epoch 058 - training loss: 22800.8010, validation loss: 0.5417
2024-05-24 07:34:36 [INFO]: Epoch 059 - training loss: 22800.2905, validation loss: 0.5354
2024-05-24 07:34:37 [INFO]: Epoch 060 - training loss: 22801.2244, validation loss: 0.5446
2024-05-24 07:34:37 [INFO]: Epoch 061 - training loss: 22802.7070, validation loss: 0.5313
2024-05-24 07:34:38 [INFO]: Epoch 062 - training loss: 22801.2261, validation loss: 0.5382
2024-05-24 07:34:39 [INFO]: Epoch 063 - training loss: 22799.4492, validation loss: 0.5243
2024-05-24 07:34:39 [INFO]: Epoch 064 - training loss: 22798.4615, validation loss: 0.5228
2024-05-24 07:34:40 [INFO]: Epoch 065 - training loss: 22797.2464, validation loss: 0.5200
2024-05-24 07:34:40 [INFO]: Epoch 066 - training loss: 22797.6899, validation loss: 0.5275
2024-05-24 07:34:41 [INFO]: Epoch 067 - training loss: 22797.2800, validation loss: 0.5244
2024-05-24 07:34:41 [INFO]: Epoch 068 - training loss: 22797.1712, validation loss: 0.5234
2024-05-24 07:34:42 [INFO]: Epoch 069 - training loss: 22795.9605, validation loss: 0.5161
2024-05-24 07:34:43 [INFO]: Epoch 070 - training loss: 22795.8289, validation loss: 0.5141
2024-05-24 07:34:43 [INFO]: Epoch 071 - training loss: 22795.1608, validation loss: 0.5156
2024-05-24 07:34:44 [INFO]: Epoch 072 - training loss: 22795.6923, validation loss: 0.5163
2024-05-24 07:34:44 [INFO]: Epoch 073 - training loss: 22794.6380, validation loss: 0.5111
2024-05-24 07:34:45 [INFO]: Epoch 074 - training loss: 22794.5210, validation loss: 0.5118
2024-05-24 07:34:46 [INFO]: Epoch 075 - training loss: 22795.0311, validation loss: 0.5109
2024-05-24 07:34:46 [INFO]: Epoch 076 - training loss: 22794.3594, validation loss: 0.5089
2024-05-24 07:34:47 [INFO]: Epoch 077 - training loss: 22793.7983, validation loss: 0.5139
2024-05-24 07:34:47 [INFO]: Epoch 078 - training loss: 22793.6355, validation loss: 0.5134
2024-05-24 07:34:48 [INFO]: Epoch 079 - training loss: 22794.0286, validation loss: 0.5105
2024-05-24 07:34:48 [INFO]: Epoch 080 - training loss: 22793.2302, validation loss: 0.5075
2024-05-24 07:34:49 [INFO]: Epoch 081 - training loss: 22793.0976, validation loss: 0.5052
2024-05-24 07:34:50 [INFO]: Epoch 082 - training loss: 22793.6343, validation loss: 0.5088
2024-05-24 07:34:50 [INFO]: Epoch 083 - training loss: 22794.2583, validation loss: 0.5029
2024-05-24 07:34:51 [INFO]: Epoch 084 - training loss: 22792.8781, validation loss: 0.5054
2024-05-24 07:34:51 [INFO]: Epoch 085 - training loss: 22794.4748, validation loss: 0.5077
2024-05-24 07:34:52 [INFO]: Epoch 086 - training loss: 22792.4704, validation loss: 0.5090
2024-05-24 07:34:52 [INFO]: Epoch 087 - training loss: 22792.1440, validation loss: 0.5021
2024-05-24 07:34:53 [INFO]: Epoch 088 - training loss: 22791.0414, validation loss: 0.5029
2024-05-24 07:34:54 [INFO]: Epoch 089 - training loss: 22790.8919, validation loss: 0.5068
2024-05-24 07:34:54 [INFO]: Epoch 090 - training loss: 22791.8922, validation loss: 0.5004
2024-05-24 07:34:55 [INFO]: Epoch 091 - training loss: 22791.3245, validation loss: 0.4978
2024-05-24 07:34:55 [INFO]: Epoch 092 - training loss: 22790.4401, validation loss: 0.4992
2024-05-24 07:34:56 [INFO]: Epoch 093 - training loss: 22790.2004, validation loss: 0.5011
2024-05-24 07:34:56 [INFO]: Epoch 094 - training loss: 22789.6406, validation loss: 0.4957
2024-05-24 07:34:57 [INFO]: Epoch 095 - training loss: 22790.6838, validation loss: 0.4977
2024-05-24 07:34:58 [INFO]: Epoch 096 - training loss: 22789.9968, validation loss: 0.5016
2024-05-24 07:34:58 [INFO]: Epoch 097 - training loss: 22789.4815, validation loss: 0.4956
2024-05-24 07:34:59 [INFO]: Epoch 098 - training loss: 22789.5936, validation loss: 0.4934
2024-05-24 07:34:59 [INFO]: Epoch 099 - training loss: 22789.3113, validation loss: 0.4937
2024-05-24 07:35:00 [INFO]: Epoch 100 - training loss: 22789.3251, validation loss: 0.4949
2024-05-24 07:35:00 [INFO]: Epoch 101 - training loss: 22789.3295, validation loss: 0.4979
2024-05-24 07:35:01 [INFO]: Epoch 102 - training loss: 22788.3195, validation loss: 0.4912
2024-05-24 07:35:02 [INFO]: Epoch 103 - training loss: 22788.7051, validation loss: 0.4913
2024-05-24 07:35:02 [INFO]: Epoch 104 - training loss: 22788.1623, validation loss: 0.4907
2024-05-24 07:35:03 [INFO]: Epoch 105 - training loss: 22787.7675, validation loss: 0.4951
2024-05-24 07:35:03 [INFO]: Epoch 106 - training loss: 22788.6481, validation loss: 0.4937
2024-05-24 07:35:04 [INFO]: Epoch 107 - training loss: 22789.2591, validation loss: 0.4965
2024-05-24 07:35:05 [INFO]: Epoch 108 - training loss: 22788.3801, validation loss: 0.4981
2024-05-24 07:35:05 [INFO]: Epoch 109 - training loss: 22791.1751, validation loss: 0.4863
2024-05-24 07:35:06 [INFO]: Epoch 110 - training loss: 22788.0943, validation loss: 0.4874
2024-05-24 07:35:06 [INFO]: Epoch 111 - training loss: 22787.8901, validation loss: 0.4874
2024-05-24 07:35:07 [INFO]: Epoch 112 - training loss: 22787.2787, validation loss: 0.4908
2024-05-24 07:35:07 [INFO]: Epoch 113 - training loss: 22788.5284, validation loss: 0.4847
2024-05-24 07:35:08 [INFO]: Epoch 114 - training loss: 22787.7644, validation loss: 0.4875
2024-05-24 07:35:09 [INFO]: Epoch 115 - training loss: 22786.7795, validation loss: 0.4815
2024-05-24 07:35:09 [INFO]: Epoch 116 - training loss: 22786.5990, validation loss: 0.4899
2024-05-24 07:35:10 [INFO]: Epoch 117 - training loss: 22786.5145, validation loss: 0.4846
2024-05-24 07:35:10 [INFO]: Epoch 118 - training loss: 22787.8519, validation loss: 0.4871
2024-05-24 07:35:11 [INFO]: Epoch 119 - training loss: 22786.4475, validation loss: 0.4847
2024-05-24 07:35:11 [INFO]: Epoch 120 - training loss: 22785.9476, validation loss: 0.4849
2024-05-24 07:35:12 [INFO]: Epoch 121 - training loss: 22785.9690, validation loss: 0.4838
2024-05-24 07:35:13 [INFO]: Epoch 122 - training loss: 22785.7406, validation loss: 0.4815
2024-05-24 07:35:13 [INFO]: Epoch 123 - training loss: 22785.6161, validation loss: 0.4804
2024-05-24 07:35:14 [INFO]: Epoch 124 - training loss: 22786.4298, validation loss: 0.4819
2024-05-24 07:35:14 [INFO]: Epoch 125 - training loss: 22786.4062, validation loss: 0.4843
2024-05-24 07:35:15 [INFO]: Epoch 126 - training loss: 22785.5759, validation loss: 0.4885
2024-05-24 07:35:15 [INFO]: Epoch 127 - training loss: 22786.0073, validation loss: 0.4804
2024-05-24 07:35:16 [INFO]: Epoch 128 - training loss: 22785.8532, validation loss: 0.4789
2024-05-24 07:35:17 [INFO]: Epoch 129 - training loss: 22786.2647, validation loss: 0.4793
2024-05-24 07:35:17 [INFO]: Epoch 130 - training loss: 22785.2586, validation loss: 0.4822
2024-05-24 07:35:18 [INFO]: Epoch 131 - training loss: 22784.8593, validation loss: 0.4804
2024-05-24 07:35:18 [INFO]: Epoch 132 - training loss: 22784.8660, validation loss: 0.4834
2024-05-24 07:35:19 [INFO]: Epoch 133 - training loss: 22784.8616, validation loss: 0.4799
2024-05-24 07:35:20 [INFO]: Epoch 134 - training loss: 22784.4248, validation loss: 0.4822
2024-05-24 07:35:20 [INFO]: Epoch 135 - training loss: 22784.8015, validation loss: 0.4798
2024-05-24 07:35:21 [INFO]: Epoch 136 - training loss: 22785.0412, validation loss: 0.4837
2024-05-24 07:35:21 [INFO]: Epoch 137 - training loss: 22784.7852, validation loss: 0.4765
2024-05-24 07:35:22 [INFO]: Epoch 138 - training loss: 22784.7175, validation loss: 0.4792
2024-05-24 07:35:22 [INFO]: Epoch 139 - training loss: 22784.2380, validation loss: 0.4811
2024-05-24 07:35:23 [INFO]: Epoch 140 - training loss: 22785.1152, validation loss: 0.4812
2024-05-24 07:35:24 [INFO]: Epoch 141 - training loss: 22784.8644, validation loss: 0.4783
2024-05-24 07:35:24 [INFO]: Epoch 142 - training loss: 22784.1804, validation loss: 0.4802
2024-05-24 07:35:25 [INFO]: Epoch 143 - training loss: 22784.4558, validation loss: 0.4753
2024-05-24 07:35:25 [INFO]: Epoch 144 - training loss: 22783.8023, validation loss: 0.4800
2024-05-24 07:35:26 [INFO]: Epoch 145 - training loss: 22783.7766, validation loss: 0.4767
2024-05-24 07:35:26 [INFO]: Epoch 146 - training loss: 22783.8747, validation loss: 0.4789
2024-05-24 07:35:27 [INFO]: Epoch 147 - training loss: 22783.9957, validation loss: 0.4763
2024-05-24 07:35:28 [INFO]: Epoch 148 - training loss: 22783.6068, validation loss: 0.4780
2024-05-24 07:35:28 [INFO]: Epoch 149 - training loss: 22783.4798, validation loss: 0.4764
2024-05-24 07:35:29 [INFO]: Epoch 150 - training loss: 22783.6206, validation loss: 0.4787
2024-05-24 07:35:29 [INFO]: Epoch 151 - training loss: 22783.5619, validation loss: 0.4759
2024-05-24 07:35:30 [INFO]: Epoch 152 - training loss: 22783.3249, validation loss: 0.4802
2024-05-24 07:35:30 [INFO]: Epoch 153 - training loss: 22783.7271, validation loss: 0.4757
2024-05-24 07:35:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 07:35:30 [INFO]: Finished training. The best model is from epoch#143.
2024-05-24 07:35:31 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_physionet_2012_seta/20240524_T073400/GPVAE.pypots
2024-05-24 07:35:31 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4204, MSE=0.5055
2024-05-24 07:35:31 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 07:35:31 [INFO]: Using the given device: cuda:0
2024-05-24 07:35:31 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_physionet_2012_seta/20240524_T073531
2024-05-24 07:35:31 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_physionet_2012_seta/20240524_T073531/tensorboard
2024-05-24 07:35:31 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 07:35:52 [INFO]: Epoch 001 - generator training loss: 0.5762, discriminator training loss: 0.3770, validation loss: 0.6303
2024-05-24 07:36:11 [INFO]: Epoch 002 - generator training loss: 0.4636, discriminator training loss: 0.2578, validation loss: 0.5346
2024-05-24 07:36:29 [INFO]: Epoch 003 - generator training loss: 0.4249, discriminator training loss: 0.2091, validation loss: 0.5131
2024-05-24 07:36:48 [INFO]: Epoch 004 - generator training loss: 0.4359, discriminator training loss: 0.1556, validation loss: 0.4946
2024-05-24 07:37:06 [INFO]: Epoch 005 - generator training loss: 0.4337, discriminator training loss: 0.1273, validation loss: 0.4851
2024-05-24 07:37:24 [INFO]: Epoch 006 - generator training loss: 0.4273, discriminator training loss: 0.1069, validation loss: 0.4656
2024-05-24 07:37:43 [INFO]: Epoch 007 - generator training loss: 0.4176, discriminator training loss: 0.0915, validation loss: 0.4543
2024-05-24 07:38:01 [INFO]: Epoch 008 - generator training loss: 0.4085, discriminator training loss: 0.0811, validation loss: 0.4468
2024-05-24 07:38:19 [INFO]: Epoch 009 - generator training loss: 0.3993, discriminator training loss: 0.0729, validation loss: 0.4365
2024-05-24 07:38:38 [INFO]: Epoch 010 - generator training loss: 0.3892, discriminator training loss: 0.0663, validation loss: 0.4274
2024-05-24 07:38:56 [INFO]: Epoch 011 - generator training loss: 0.3860, discriminator training loss: 0.0610, validation loss: 0.4211
2024-05-24 07:39:15 [INFO]: Epoch 012 - generator training loss: 0.3766, discriminator training loss: 0.0559, validation loss: 0.4121
2024-05-24 07:39:33 [INFO]: Epoch 013 - generator training loss: 0.3714, discriminator training loss: 0.0518, validation loss: 0.4071
2024-05-24 07:39:51 [INFO]: Epoch 014 - generator training loss: 0.3651, discriminator training loss: 0.0487, validation loss: 0.4054
2024-05-24 07:40:10 [INFO]: Epoch 015 - generator training loss: 0.3599, discriminator training loss: 0.0458, validation loss: 0.3960
2024-05-24 07:40:28 [INFO]: Epoch 016 - generator training loss: 0.3537, discriminator training loss: 0.0432, validation loss: 0.3899
2024-05-24 07:40:46 [INFO]: Epoch 017 - generator training loss: 0.3483, discriminator training loss: 0.0409, validation loss: 0.3858
2024-05-24 07:41:05 [INFO]: Epoch 018 - generator training loss: 0.3429, discriminator training loss: 0.0391, validation loss: 0.3781
2024-05-24 07:41:23 [INFO]: Epoch 019 - generator training loss: 0.3372, discriminator training loss: 0.0376, validation loss: 0.3763
2024-05-24 07:41:42 [INFO]: Epoch 020 - generator training loss: 0.3321, discriminator training loss: 0.0363, validation loss: 0.3711
2024-05-24 07:42:00 [INFO]: Epoch 021 - generator training loss: 0.3260, discriminator training loss: 0.0352, validation loss: 0.3686
2024-05-24 07:42:18 [INFO]: Epoch 022 - generator training loss: 0.3227, discriminator training loss: 0.0339, validation loss: 0.3681
2024-05-24 07:42:37 [INFO]: Epoch 023 - generator training loss: 0.3201, discriminator training loss: 0.0330, validation loss: 0.3616
2024-05-24 07:42:55 [INFO]: Epoch 024 - generator training loss: 0.3144, discriminator training loss: 0.0322, validation loss: 0.3585
2024-05-24 07:43:14 [INFO]: Epoch 025 - generator training loss: 0.3087, discriminator training loss: 0.0314, validation loss: 0.3602
2024-05-24 07:43:32 [INFO]: Epoch 026 - generator training loss: 0.3080, discriminator training loss: 0.0307, validation loss: 0.3563
2024-05-24 07:43:51 [INFO]: Epoch 027 - generator training loss: 0.3074, discriminator training loss: 0.0301, validation loss: 0.3567
2024-05-24 07:44:09 [INFO]: Epoch 028 - generator training loss: 0.3021, discriminator training loss: 0.0295, validation loss: 0.3520
2024-05-24 07:44:27 [INFO]: Epoch 029 - generator training loss: 0.2968, discriminator training loss: 0.0290, validation loss: 0.3477
2024-05-24 07:44:46 [INFO]: Epoch 030 - generator training loss: 0.2898, discriminator training loss: 0.0287, validation loss: 0.3433
2024-05-24 07:45:04 [INFO]: Epoch 031 - generator training loss: 0.2840, discriminator training loss: 0.0281, validation loss: 0.3417
2024-05-24 07:45:22 [INFO]: Epoch 032 - generator training loss: 0.2801, discriminator training loss: 0.0277, validation loss: 0.3455
2024-05-24 07:45:41 [INFO]: Epoch 033 - generator training loss: 0.2842, discriminator training loss: 0.0275, validation loss: 0.3396
2024-05-24 07:45:59 [INFO]: Epoch 034 - generator training loss: 0.2790, discriminator training loss: 0.0270, validation loss: 0.3414
2024-05-24 07:46:18 [INFO]: Epoch 035 - generator training loss: 0.2744, discriminator training loss: 0.0266, validation loss: 0.3350
2024-05-24 07:46:36 [INFO]: Epoch 036 - generator training loss: 0.2695, discriminator training loss: 0.0263, validation loss: 0.3324
2024-05-24 07:46:54 [INFO]: Epoch 037 - generator training loss: 0.2792, discriminator training loss: 0.0262, validation loss: 0.3422
2024-05-24 07:47:13 [INFO]: Epoch 038 - generator training loss: 0.2760, discriminator training loss: 0.0256, validation loss: 0.3393
2024-05-24 07:47:31 [INFO]: Epoch 039 - generator training loss: 0.2728, discriminator training loss: 0.0253, validation loss: 0.3306
2024-05-24 07:47:49 [INFO]: Epoch 040 - generator training loss: 0.2623, discriminator training loss: 0.0250, validation loss: 0.3281
2024-05-24 07:48:08 [INFO]: Epoch 041 - generator training loss: 0.2592, discriminator training loss: 0.0250, validation loss: 0.3275
2024-05-24 07:48:26 [INFO]: Epoch 042 - generator training loss: 0.2542, discriminator training loss: 0.0246, validation loss: 0.3327
2024-05-24 07:48:45 [INFO]: Epoch 043 - generator training loss: 0.2558, discriminator training loss: 0.0245, validation loss: 0.3293
2024-05-24 07:49:03 [INFO]: Epoch 044 - generator training loss: 0.2557, discriminator training loss: 0.0242, validation loss: 0.3332
2024-05-24 07:49:21 [INFO]: Epoch 045 - generator training loss: 0.2517, discriminator training loss: 0.0241, validation loss: 0.3244
2024-05-24 07:49:40 [INFO]: Epoch 046 - generator training loss: 0.2470, discriminator training loss: 0.0239, validation loss: 0.3237
2024-05-24 07:49:58 [INFO]: Epoch 047 - generator training loss: 0.2463, discriminator training loss: 0.0237, validation loss: 0.3262
2024-05-24 07:50:17 [INFO]: Epoch 048 - generator training loss: 0.2450, discriminator training loss: 0.0235, validation loss: 0.3244
2024-05-24 07:50:35 [INFO]: Epoch 049 - generator training loss: 0.2409, discriminator training loss: 0.0235, validation loss: 0.3204
2024-05-24 07:50:53 [INFO]: Epoch 050 - generator training loss: 0.2395, discriminator training loss: 0.0234, validation loss: 0.3195
2024-05-24 07:51:12 [INFO]: Epoch 051 - generator training loss: 0.2396, discriminator training loss: 0.0232, validation loss: 0.3237
2024-05-24 07:51:30 [INFO]: Epoch 052 - generator training loss: 0.2367, discriminator training loss: 0.0229, validation loss: 0.3208
2024-05-24 07:51:49 [INFO]: Epoch 053 - generator training loss: 0.2320, discriminator training loss: 0.0231, validation loss: 0.3201
2024-05-24 07:52:07 [INFO]: Epoch 054 - generator training loss: 0.2289, discriminator training loss: 0.0228, validation loss: 0.3195
2024-05-24 07:52:25 [INFO]: Epoch 055 - generator training loss: 0.2269, discriminator training loss: 0.0227, validation loss: 0.3178
2024-05-24 07:52:44 [INFO]: Epoch 056 - generator training loss: 0.2316, discriminator training loss: 0.0226, validation loss: 0.3176
2024-05-24 07:53:02 [INFO]: Epoch 057 - generator training loss: 0.2270, discriminator training loss: 0.0226, validation loss: 0.3213
2024-05-24 07:53:21 [INFO]: Epoch 058 - generator training loss: 0.2294, discriminator training loss: 0.0224, validation loss: 0.3232
2024-05-24 07:53:39 [INFO]: Epoch 059 - generator training loss: 0.2300, discriminator training loss: 0.0225, validation loss: 0.3174
2024-05-24 07:53:57 [INFO]: Epoch 060 - generator training loss: 0.2240, discriminator training loss: 0.0222, validation loss: 0.3159
2024-05-24 07:54:16 [INFO]: Epoch 061 - generator training loss: 0.2201, discriminator training loss: 0.0221, validation loss: 0.3186
2024-05-24 07:54:34 [INFO]: Epoch 062 - generator training loss: 0.2182, discriminator training loss: 0.0219, validation loss: 0.3161
2024-05-24 07:54:53 [INFO]: Epoch 063 - generator training loss: 0.2176, discriminator training loss: 0.0220, validation loss: 0.3186
2024-05-24 07:55:11 [INFO]: Epoch 064 - generator training loss: 0.2154, discriminator training loss: 0.0218, validation loss: 0.3182
2024-05-24 07:55:29 [INFO]: Epoch 065 - generator training loss: 0.2164, discriminator training loss: 0.0216, validation loss: 0.3157
2024-05-24 07:55:48 [INFO]: Epoch 066 - generator training loss: 0.2108, discriminator training loss: 0.0216, validation loss: 0.3152
2024-05-24 07:56:06 [INFO]: Epoch 067 - generator training loss: 0.2072, discriminator training loss: 0.0215, validation loss: 0.3160
2024-05-24 07:56:25 [INFO]: Epoch 068 - generator training loss: 0.2098, discriminator training loss: 0.0214, validation loss: 0.3241
2024-05-24 07:56:43 [INFO]: Epoch 069 - generator training loss: 0.2087, discriminator training loss: 0.0214, validation loss: 0.3154
2024-05-24 07:57:02 [INFO]: Epoch 070 - generator training loss: 0.2187, discriminator training loss: 0.0213, validation loss: 0.3197
2024-05-24 07:57:20 [INFO]: Epoch 071 - generator training loss: 0.2087, discriminator training loss: 0.0211, validation loss: 0.3160
2024-05-24 07:57:38 [INFO]: Epoch 072 - generator training loss: 0.2040, discriminator training loss: 0.0209, validation loss: 0.3174
2024-05-24 07:57:57 [INFO]: Epoch 073 - generator training loss: 0.2012, discriminator training loss: 0.0207, validation loss: 0.3159
2024-05-24 07:58:15 [INFO]: Epoch 074 - generator training loss: 0.2009, discriminator training loss: 0.0208, validation loss: 0.3210
2024-05-24 07:58:34 [INFO]: Epoch 075 - generator training loss: 0.1992, discriminator training loss: 0.0206, validation loss: 0.3173
2024-05-24 07:58:52 [INFO]: Epoch 076 - generator training loss: 0.1981, discriminator training loss: 0.0206, validation loss: 0.3130
2024-05-24 07:59:10 [INFO]: Epoch 077 - generator training loss: 0.1948, discriminator training loss: 0.0205, validation loss: 0.3190
2024-05-24 07:59:29 [INFO]: Epoch 078 - generator training loss: 0.1907, discriminator training loss: 0.0205, validation loss: 0.3160
2024-05-24 07:59:47 [INFO]: Epoch 079 - generator training loss: 0.1899, discriminator training loss: 0.0202, validation loss: 0.3159
2024-05-24 08:00:06 [INFO]: Epoch 080 - generator training loss: 0.1918, discriminator training loss: 0.0203, validation loss: 0.3152
2024-05-24 08:00:24 [INFO]: Epoch 081 - generator training loss: 0.1871, discriminator training loss: 0.0201, validation loss: 0.3160
2024-05-24 08:00:43 [INFO]: Epoch 082 - generator training loss: 0.1862, discriminator training loss: 0.0202, validation loss: 0.3158
2024-05-24 08:01:01 [INFO]: Epoch 083 - generator training loss: 0.1853, discriminator training loss: 0.0201, validation loss: 0.3170
2024-05-24 08:01:19 [INFO]: Epoch 084 - generator training loss: 0.1900, discriminator training loss: 0.0201, validation loss: 0.3170
2024-05-24 08:01:38 [INFO]: Epoch 085 - generator training loss: 0.1856, discriminator training loss: 0.0200, validation loss: 0.3170
2024-05-24 08:01:56 [INFO]: Epoch 086 - generator training loss: 0.1825, discriminator training loss: 0.0198, validation loss: 0.3178
2024-05-24 08:01:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:01:56 [INFO]: Finished training. The best model is from epoch#76.
2024-05-24 08:01:56 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_physionet_2012_seta/20240524_T073531/USGAN.pypots
2024-05-24 08:01:59 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2995, MSE=0.3295
2024-05-24 08:02:09 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 08:02:09 [INFO]: Using the given device: cuda:0
2024-05-24 08:02:09 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_physionet_2012_seta/20240524_T080209
2024-05-24 08:02:09 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_physionet_2012_seta/20240524_T080209/tensorboard
2024-05-24 08:02:09 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 08:02:24 [INFO]: Epoch 001 - training loss: 1.1134, validation loss: 0.5406
2024-05-24 08:02:36 [INFO]: Epoch 002 - training loss: 0.9077, validation loss: 0.4905
2024-05-24 08:02:48 [INFO]: Epoch 003 - training loss: 0.8507, validation loss: 0.4619
2024-05-24 08:03:00 [INFO]: Epoch 004 - training loss: 0.8137, validation loss: 0.4387
2024-05-24 08:03:12 [INFO]: Epoch 005 - training loss: 0.7833, validation loss: 0.4199
2024-05-24 08:03:24 [INFO]: Epoch 006 - training loss: 0.7617, validation loss: 0.4066
2024-05-24 08:03:36 [INFO]: Epoch 007 - training loss: 0.7407, validation loss: 0.3926
2024-05-24 08:03:48 [INFO]: Epoch 008 - training loss: 0.7240, validation loss: 0.3839
2024-05-24 08:04:00 [INFO]: Epoch 009 - training loss: 0.7103, validation loss: 0.3739
2024-05-24 08:04:12 [INFO]: Epoch 010 - training loss: 0.6984, validation loss: 0.3669
2024-05-24 08:04:24 [INFO]: Epoch 011 - training loss: 0.6878, validation loss: 0.3617
2024-05-24 08:04:36 [INFO]: Epoch 012 - training loss: 0.6792, validation loss: 0.3591
2024-05-24 08:04:48 [INFO]: Epoch 013 - training loss: 0.6713, validation loss: 0.3536
2024-05-24 08:05:00 [INFO]: Epoch 014 - training loss: 0.6643, validation loss: 0.3493
2024-05-24 08:05:12 [INFO]: Epoch 015 - training loss: 0.6571, validation loss: 0.3477
2024-05-24 08:05:25 [INFO]: Epoch 016 - training loss: 0.6518, validation loss: 0.3456
2024-05-24 08:05:37 [INFO]: Epoch 017 - training loss: 0.6473, validation loss: 0.3431
2024-05-24 08:05:49 [INFO]: Epoch 018 - training loss: 0.6430, validation loss: 0.3441
2024-05-24 08:06:01 [INFO]: Epoch 019 - training loss: 0.6382, validation loss: 0.3420
2024-05-24 08:06:13 [INFO]: Epoch 020 - training loss: 0.6340, validation loss: 0.3393
2024-05-24 08:06:25 [INFO]: Epoch 021 - training loss: 0.6301, validation loss: 0.3372
2024-05-24 08:06:37 [INFO]: Epoch 022 - training loss: 0.6281, validation loss: 0.3383
2024-05-24 08:06:49 [INFO]: Epoch 023 - training loss: 0.6242, validation loss: 0.3354
2024-05-24 08:07:01 [INFO]: Epoch 024 - training loss: 0.6203, validation loss: 0.3341
2024-05-24 08:07:13 [INFO]: Epoch 025 - training loss: 0.6171, validation loss: 0.3319
2024-05-24 08:07:25 [INFO]: Epoch 026 - training loss: 0.6146, validation loss: 0.3326
2024-05-24 08:07:37 [INFO]: Epoch 027 - training loss: 0.6103, validation loss: 0.3315
2024-05-24 08:07:49 [INFO]: Epoch 028 - training loss: 0.6075, validation loss: 0.3318
2024-05-24 08:08:01 [INFO]: Epoch 029 - training loss: 0.6047, validation loss: 0.3306
2024-05-24 08:08:13 [INFO]: Epoch 030 - training loss: 0.6016, validation loss: 0.3296
2024-05-24 08:08:25 [INFO]: Epoch 031 - training loss: 0.5984, validation loss: 0.3283
2024-05-24 08:08:37 [INFO]: Epoch 032 - training loss: 0.5960, validation loss: 0.3289
2024-05-24 08:08:49 [INFO]: Epoch 033 - training loss: 0.5993, validation loss: 0.3287
2024-05-24 08:09:01 [INFO]: Epoch 034 - training loss: 0.5916, validation loss: 0.3271
2024-05-24 08:09:13 [INFO]: Epoch 035 - training loss: 0.5875, validation loss: 0.3269
2024-05-24 08:09:26 [INFO]: Epoch 036 - training loss: 0.5848, validation loss: 0.3280
2024-05-24 08:09:38 [INFO]: Epoch 037 - training loss: 0.5814, validation loss: 0.3267
2024-05-24 08:09:50 [INFO]: Epoch 038 - training loss: 0.5787, validation loss: 0.3280
2024-05-24 08:10:02 [INFO]: Epoch 039 - training loss: 0.5767, validation loss: 0.3296
2024-05-24 08:10:14 [INFO]: Epoch 040 - training loss: 0.5791, validation loss: 0.3331
2024-05-24 08:10:26 [INFO]: Epoch 041 - training loss: 0.5827, validation loss: 0.3309
2024-05-24 08:10:38 [INFO]: Epoch 042 - training loss: 0.5747, validation loss: 0.3308
2024-05-24 08:10:50 [INFO]: Epoch 043 - training loss: 0.5763, validation loss: 0.3312
2024-05-24 08:11:02 [INFO]: Epoch 044 - training loss: 0.5718, validation loss: 0.3314
2024-05-24 08:11:14 [INFO]: Epoch 045 - training loss: 0.5630, validation loss: 0.3294
2024-05-24 08:11:26 [INFO]: Epoch 046 - training loss: 0.5591, validation loss: 0.3319
2024-05-24 08:11:38 [INFO]: Epoch 047 - training loss: 0.5639, validation loss: 0.3366
2024-05-24 08:11:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:11:38 [INFO]: Finished training. The best model is from epoch#37.
2024-05-24 08:11:38 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_physionet_2012_seta/20240524_T080209/BRITS.pypots
2024-05-24 08:11:41 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2647, MSE=0.3439
2024-05-24 08:11:50 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:11:50 [INFO]: Using the given device: cuda:0
2024-05-24 08:11:50 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150
2024-05-24 08:11:50 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/tensorboard
2024-05-24 08:11:50 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 08:11:56 [INFO]: Epoch 001 - training loss: 1.3416, validation loss: 1.0103
2024-05-24 08:11:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch1_loss1.0102767854928971.pypots
2024-05-24 08:11:59 [INFO]: Epoch 002 - training loss: 0.8532, validation loss: 0.9777
2024-05-24 08:11:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch2_loss0.9776560813188553.pypots
2024-05-24 08:12:02 [INFO]: Epoch 003 - training loss: 0.6630, validation loss: 0.9549
2024-05-24 08:12:02 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch3_loss0.9548998773097992.pypots
2024-05-24 08:12:04 [INFO]: Epoch 004 - training loss: 0.6101, validation loss: 0.9429
2024-05-24 08:12:04 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch4_loss0.9428514689207077.pypots
2024-05-24 08:12:07 [INFO]: Epoch 005 - training loss: 0.5819, validation loss: 0.9364
2024-05-24 08:12:07 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch5_loss0.9363512933254242.pypots
2024-05-24 08:12:10 [INFO]: Epoch 006 - training loss: 0.5594, validation loss: 0.9314
2024-05-24 08:12:10 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch6_loss0.9313591718673706.pypots
2024-05-24 08:12:13 [INFO]: Epoch 007 - training loss: 0.5435, validation loss: 0.9274
2024-05-24 08:12:13 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch7_loss0.9273751676082611.pypots
2024-05-24 08:12:15 [INFO]: Epoch 008 - training loss: 0.5295, validation loss: 0.9258
2024-05-24 08:12:15 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch8_loss0.9258394449949264.pypots
2024-05-24 08:12:18 [INFO]: Epoch 009 - training loss: 0.5176, validation loss: 0.9234
2024-05-24 08:12:18 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch9_loss0.9233838319778442.pypots
2024-05-24 08:12:21 [INFO]: Epoch 010 - training loss: 0.5036, validation loss: 0.9225
2024-05-24 08:12:21 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch10_loss0.9225496768951416.pypots
2024-05-24 08:12:24 [INFO]: Epoch 011 - training loss: 0.4937, validation loss: 0.9228
2024-05-24 08:12:24 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch11_loss0.9227888345718384.pypots
2024-05-24 08:12:26 [INFO]: Epoch 012 - training loss: 0.4939, validation loss: 0.9226
2024-05-24 08:12:26 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch12_loss0.9226049989461899.pypots
2024-05-24 08:12:29 [INFO]: Epoch 013 - training loss: 0.4841, validation loss: 0.9239
2024-05-24 08:12:29 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch13_loss0.9239195704460144.pypots
2024-05-24 08:12:32 [INFO]: Epoch 014 - training loss: 0.4754, validation loss: 0.9249
2024-05-24 08:12:32 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch14_loss0.9249313980340957.pypots
2024-05-24 08:12:35 [INFO]: Epoch 015 - training loss: 0.4739, validation loss: 0.9261
2024-05-24 08:12:35 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch15_loss0.9261207312345505.pypots
2024-05-24 08:12:38 [INFO]: Epoch 016 - training loss: 0.4770, validation loss: 0.9280
2024-05-24 08:12:38 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch16_loss0.9279713660478592.pypots
2024-05-24 08:12:40 [INFO]: Epoch 017 - training loss: 0.4685, validation loss: 0.9293
2024-05-24 08:12:40 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch17_loss0.9293167740106583.pypots
2024-05-24 08:12:43 [INFO]: Epoch 018 - training loss: 0.4596, validation loss: 0.9292
2024-05-24 08:12:43 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch18_loss0.9292176902294159.pypots
2024-05-24 08:12:46 [INFO]: Epoch 019 - training loss: 0.4595, validation loss: 0.9301
2024-05-24 08:12:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch19_loss0.9301417320966721.pypots
2024-05-24 08:12:49 [INFO]: Epoch 020 - training loss: 0.4558, validation loss: 0.9315
2024-05-24 08:12:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN_epoch20_loss0.9315224081277848.pypots
2024-05-24 08:12:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:12:49 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 08:12:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T081150/MRNN.pypots
2024-05-24 08:12:50 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6869, MSE=0.9354
2024-05-24 08:12:54 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 08:12:54 [INFO]: Using the given device: cpu
2024-05-24 08:12:54 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4114, MSE=0.6133
2024-05-24 08:12:54 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_physionet_2012_seta".
2024-05-24 08:12:54 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 08:12:54 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6898, MSE=1.0489
2024-05-24 08:12:54 [INFO]: Successfully created the given path "saved_results/round_2/Median_physionet_2012_seta".
2024-05-24 08:12:54 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_physionet_2012_seta/imputation.pkl
2024-05-24 08:12:54 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7072, MSE=1.0216
2024-05-24 08:12:54 [INFO]: Successfully created the given path "saved_results/round_2/Mean_physionet_2012_seta".
2024-05-24 08:12:54 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 08:12:54 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-24 08:12:55 [INFO]: Using the given device: cuda:0
2024-05-24 08:12:55 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T081255
2024-05-24 08:12:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T081255/tensorboard
2024-05-24 08:12:55 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-24 08:12:56 [INFO]: Epoch 001 - training loss: 1.1261, validation loss: 0.5034
2024-05-24 08:12:58 [INFO]: Epoch 002 - training loss: 0.7243, validation loss: 0.4473
2024-05-24 08:12:59 [INFO]: Epoch 003 - training loss: 0.5978, validation loss: 0.4135
2024-05-24 08:13:00 [INFO]: Epoch 004 - training loss: 0.5316, validation loss: 0.3963
2024-05-24 08:13:01 [INFO]: Epoch 005 - training loss: 0.4928, validation loss: 0.3856
2024-05-24 08:13:03 [INFO]: Epoch 006 - training loss: 0.4650, validation loss: 0.3703
2024-05-24 08:13:04 [INFO]: Epoch 007 - training loss: 0.4427, validation loss: 0.3670
2024-05-24 08:13:05 [INFO]: Epoch 008 - training loss: 0.4165, validation loss: 0.3414
2024-05-24 08:13:07 [INFO]: Epoch 009 - training loss: 0.4025, validation loss: 0.3336
2024-05-24 08:13:08 [INFO]: Epoch 010 - training loss: 0.3876, validation loss: 0.3215
2024-05-24 08:13:09 [INFO]: Epoch 011 - training loss: 0.3750, validation loss: 0.3167
2024-05-24 08:13:10 [INFO]: Epoch 012 - training loss: 0.3677, validation loss: 0.3088
2024-05-24 08:13:12 [INFO]: Epoch 013 - training loss: 0.3494, validation loss: 0.3049
2024-05-24 08:13:13 [INFO]: Epoch 014 - training loss: 0.3459, validation loss: 0.3045
2024-05-24 08:13:14 [INFO]: Epoch 015 - training loss: 0.3401, validation loss: 0.2952
2024-05-24 08:13:15 [INFO]: Epoch 016 - training loss: 0.3345, validation loss: 0.2952
2024-05-24 08:13:17 [INFO]: Epoch 017 - training loss: 0.3246, validation loss: 0.2916
2024-05-24 08:13:18 [INFO]: Epoch 018 - training loss: 0.3218, validation loss: 0.2884
2024-05-24 08:13:19 [INFO]: Epoch 019 - training loss: 0.3151, validation loss: 0.2881
2024-05-24 08:13:20 [INFO]: Epoch 020 - training loss: 0.3146, validation loss: 0.2852
2024-05-24 08:13:22 [INFO]: Epoch 021 - training loss: 0.3058, validation loss: 0.2793
2024-05-24 08:13:23 [INFO]: Epoch 022 - training loss: 0.3058, validation loss: 0.2809
2024-05-24 08:13:24 [INFO]: Epoch 023 - training loss: 0.3064, validation loss: 0.2823
2024-05-24 08:13:26 [INFO]: Epoch 024 - training loss: 0.2980, validation loss: 0.2787
2024-05-24 08:13:27 [INFO]: Epoch 025 - training loss: 0.2983, validation loss: 0.2737
2024-05-24 08:13:28 [INFO]: Epoch 026 - training loss: 0.2922, validation loss: 0.2759
2024-05-24 08:13:29 [INFO]: Epoch 027 - training loss: 0.2919, validation loss: 0.2749
2024-05-24 08:13:31 [INFO]: Epoch 028 - training loss: 0.2909, validation loss: 0.2732
2024-05-24 08:13:32 [INFO]: Epoch 029 - training loss: 0.2865, validation loss: 0.2746
2024-05-24 08:13:33 [INFO]: Epoch 030 - training loss: 0.2872, validation loss: 0.2685
2024-05-24 08:13:34 [INFO]: Epoch 031 - training loss: 0.2846, validation loss: 0.2684
2024-05-24 08:13:36 [INFO]: Epoch 032 - training loss: 0.2823, validation loss: 0.2670
2024-05-24 08:13:37 [INFO]: Epoch 033 - training loss: 0.2794, validation loss: 0.2673
2024-05-24 08:13:38 [INFO]: Epoch 034 - training loss: 0.2794, validation loss: 0.2669
2024-05-24 08:13:40 [INFO]: Epoch 035 - training loss: 0.2774, validation loss: 0.2649
2024-05-24 08:13:41 [INFO]: Epoch 036 - training loss: 0.2782, validation loss: 0.2609
2024-05-24 08:13:42 [INFO]: Epoch 037 - training loss: 0.2743, validation loss: 0.2647
2024-05-24 08:13:43 [INFO]: Epoch 038 - training loss: 0.2771, validation loss: 0.2645
2024-05-24 08:13:45 [INFO]: Epoch 039 - training loss: 0.2736, validation loss: 0.2649
2024-05-24 08:13:46 [INFO]: Epoch 040 - training loss: 0.2747, validation loss: 0.2643
2024-05-24 08:13:47 [INFO]: Epoch 041 - training loss: 0.2735, validation loss: 0.2642
2024-05-24 08:13:48 [INFO]: Epoch 042 - training loss: 0.2739, validation loss: 0.2596
2024-05-24 08:13:50 [INFO]: Epoch 043 - training loss: 0.2696, validation loss: 0.2647
2024-05-24 08:13:51 [INFO]: Epoch 044 - training loss: 0.2674, validation loss: 0.2604
2024-05-24 08:13:52 [INFO]: Epoch 045 - training loss: 0.2702, validation loss: 0.2622
2024-05-24 08:13:53 [INFO]: Epoch 046 - training loss: 0.2671, validation loss: 0.2631
2024-05-24 08:13:55 [INFO]: Epoch 047 - training loss: 0.2677, validation loss: 0.2610
2024-05-24 08:13:56 [INFO]: Epoch 048 - training loss: 0.2674, validation loss: 0.2643
2024-05-24 08:13:57 [INFO]: Epoch 049 - training loss: 0.2671, validation loss: 0.2587
2024-05-24 08:13:59 [INFO]: Epoch 050 - training loss: 0.2631, validation loss: 0.2551
2024-05-24 08:14:00 [INFO]: Epoch 051 - training loss: 0.2632, validation loss: 0.2509
2024-05-24 08:14:01 [INFO]: Epoch 052 - training loss: 0.2623, validation loss: 0.2533
2024-05-24 08:14:02 [INFO]: Epoch 053 - training loss: 0.2615, validation loss: 0.2557
2024-05-24 08:14:04 [INFO]: Epoch 054 - training loss: 0.2598, validation loss: 0.2610
2024-05-24 08:14:05 [INFO]: Epoch 055 - training loss: 0.2611, validation loss: 0.2595
2024-05-24 08:14:06 [INFO]: Epoch 056 - training loss: 0.2588, validation loss: 0.2588
2024-05-24 08:14:08 [INFO]: Epoch 057 - training loss: 0.2588, validation loss: 0.2552
2024-05-24 08:14:09 [INFO]: Epoch 058 - training loss: 0.2584, validation loss: 0.2568
2024-05-24 08:14:10 [INFO]: Epoch 059 - training loss: 0.2579, validation loss: 0.2544
2024-05-24 08:14:11 [INFO]: Epoch 060 - training loss: 0.2577, validation loss: 0.2565
2024-05-24 08:14:13 [INFO]: Epoch 061 - training loss: 0.2563, validation loss: 0.2550
2024-05-24 08:14:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:14:13 [INFO]: Finished training. The best model is from epoch#51.
2024-05-24 08:14:13 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T081255/SAITS.pypots
2024-05-24 08:14:13 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2163, MSE=0.2695
2024-05-24 08:14:13 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:14:13 [INFO]: Using the given device: cuda:0
2024-05-24 08:14:13 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T081413
2024-05-24 08:14:13 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T081413/tensorboard
2024-05-24 08:14:13 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-24 08:14:14 [INFO]: Epoch 001 - training loss: 1.2870, validation loss: 0.6381
2024-05-24 08:14:15 [INFO]: Epoch 002 - training loss: 0.7860, validation loss: 0.4815
2024-05-24 08:14:15 [INFO]: Epoch 003 - training loss: 0.6517, validation loss: 0.4525
2024-05-24 08:14:16 [INFO]: Epoch 004 - training loss: 0.5948, validation loss: 0.4320
2024-05-24 08:14:17 [INFO]: Epoch 005 - training loss: 0.5646, validation loss: 0.4249
2024-05-24 08:14:17 [INFO]: Epoch 006 - training loss: 0.5251, validation loss: 0.4109
2024-05-24 08:14:18 [INFO]: Epoch 007 - training loss: 0.5045, validation loss: 0.4064
2024-05-24 08:14:19 [INFO]: Epoch 008 - training loss: 0.4800, validation loss: 0.3931
2024-05-24 08:14:19 [INFO]: Epoch 009 - training loss: 0.4622, validation loss: 0.3871
2024-05-24 08:14:20 [INFO]: Epoch 010 - training loss: 0.4576, validation loss: 0.3765
2024-05-24 08:14:21 [INFO]: Epoch 011 - training loss: 0.4383, validation loss: 0.3786
2024-05-24 08:14:21 [INFO]: Epoch 012 - training loss: 0.4314, validation loss: 0.3671
2024-05-24 08:14:22 [INFO]: Epoch 013 - training loss: 0.4181, validation loss: 0.3608
2024-05-24 08:14:23 [INFO]: Epoch 014 - training loss: 0.4095, validation loss: 0.3578
2024-05-24 08:14:24 [INFO]: Epoch 015 - training loss: 0.4017, validation loss: 0.3510
2024-05-24 08:14:24 [INFO]: Epoch 016 - training loss: 0.3942, validation loss: 0.3446
2024-05-24 08:14:25 [INFO]: Epoch 017 - training loss: 0.3887, validation loss: 0.3445
2024-05-24 08:14:26 [INFO]: Epoch 018 - training loss: 0.3839, validation loss: 0.3406
2024-05-24 08:14:26 [INFO]: Epoch 019 - training loss: 0.3789, validation loss: 0.3333
2024-05-24 08:14:27 [INFO]: Epoch 020 - training loss: 0.3722, validation loss: 0.3331
2024-05-24 08:14:28 [INFO]: Epoch 021 - training loss: 0.3685, validation loss: 0.3366
2024-05-24 08:14:28 [INFO]: Epoch 022 - training loss: 0.3637, validation loss: 0.3270
2024-05-24 08:14:29 [INFO]: Epoch 023 - training loss: 0.3563, validation loss: 0.3254
2024-05-24 08:14:30 [INFO]: Epoch 024 - training loss: 0.3570, validation loss: 0.3203
2024-05-24 08:14:31 [INFO]: Epoch 025 - training loss: 0.3513, validation loss: 0.3223
2024-05-24 08:14:31 [INFO]: Epoch 026 - training loss: 0.3528, validation loss: 0.3164
2024-05-24 08:14:32 [INFO]: Epoch 027 - training loss: 0.3451, validation loss: 0.3158
2024-05-24 08:14:33 [INFO]: Epoch 028 - training loss: 0.3413, validation loss: 0.3118
2024-05-24 08:14:33 [INFO]: Epoch 029 - training loss: 0.3375, validation loss: 0.3116
2024-05-24 08:14:34 [INFO]: Epoch 030 - training loss: 0.3367, validation loss: 0.3108
2024-05-24 08:14:35 [INFO]: Epoch 031 - training loss: 0.3337, validation loss: 0.3106
2024-05-24 08:14:35 [INFO]: Epoch 032 - training loss: 0.3300, validation loss: 0.3064
2024-05-24 08:14:36 [INFO]: Epoch 033 - training loss: 0.3339, validation loss: 0.3075
2024-05-24 08:14:37 [INFO]: Epoch 034 - training loss: 0.3277, validation loss: 0.3017
2024-05-24 08:14:37 [INFO]: Epoch 035 - training loss: 0.3276, validation loss: 0.3068
2024-05-24 08:14:38 [INFO]: Epoch 036 - training loss: 0.3248, validation loss: 0.3061
2024-05-24 08:14:39 [INFO]: Epoch 037 - training loss: 0.3253, validation loss: 0.2961
2024-05-24 08:14:40 [INFO]: Epoch 038 - training loss: 0.3214, validation loss: 0.2995
2024-05-24 08:14:40 [INFO]: Epoch 039 - training loss: 0.3185, validation loss: 0.2995
2024-05-24 08:14:41 [INFO]: Epoch 040 - training loss: 0.3158, validation loss: 0.2949
2024-05-24 08:14:42 [INFO]: Epoch 041 - training loss: 0.3154, validation loss: 0.2989
2024-05-24 08:14:42 [INFO]: Epoch 042 - training loss: 0.3163, validation loss: 0.2925
2024-05-24 08:14:43 [INFO]: Epoch 043 - training loss: 0.3141, validation loss: 0.2957
2024-05-24 08:14:44 [INFO]: Epoch 044 - training loss: 0.3113, validation loss: 0.2917
2024-05-24 08:14:44 [INFO]: Epoch 045 - training loss: 0.3125, validation loss: 0.2923
2024-05-24 08:14:45 [INFO]: Epoch 046 - training loss: 0.3077, validation loss: 0.2890
2024-05-24 08:14:46 [INFO]: Epoch 047 - training loss: 0.3061, validation loss: 0.2906
2024-05-24 08:14:46 [INFO]: Epoch 048 - training loss: 0.3080, validation loss: 0.2904
2024-05-24 08:14:47 [INFO]: Epoch 049 - training loss: 0.3064, validation loss: 0.2890
2024-05-24 08:14:48 [INFO]: Epoch 050 - training loss: 0.3041, validation loss: 0.2891
2024-05-24 08:14:49 [INFO]: Epoch 051 - training loss: 0.3019, validation loss: 0.2854
2024-05-24 08:14:49 [INFO]: Epoch 052 - training loss: 0.2997, validation loss: 0.2903
2024-05-24 08:14:50 [INFO]: Epoch 053 - training loss: 0.3013, validation loss: 0.2847
2024-05-24 08:14:51 [INFO]: Epoch 054 - training loss: 0.2960, validation loss: 0.2798
2024-05-24 08:14:51 [INFO]: Epoch 055 - training loss: 0.2982, validation loss: 0.2828
2024-05-24 08:14:52 [INFO]: Epoch 056 - training loss: 0.2991, validation loss: 0.2777
2024-05-24 08:14:53 [INFO]: Epoch 057 - training loss: 0.2962, validation loss: 0.2795
2024-05-24 08:14:53 [INFO]: Epoch 058 - training loss: 0.2978, validation loss: 0.2787
2024-05-24 08:14:54 [INFO]: Epoch 059 - training loss: 0.2931, validation loss: 0.2799
2024-05-24 08:14:55 [INFO]: Epoch 060 - training loss: 0.2974, validation loss: 0.2772
2024-05-24 08:14:55 [INFO]: Epoch 061 - training loss: 0.2951, validation loss: 0.2730
2024-05-24 08:14:56 [INFO]: Epoch 062 - training loss: 0.2904, validation loss: 0.2763
2024-05-24 08:14:57 [INFO]: Epoch 063 - training loss: 0.2923, validation loss: 0.2766
2024-05-24 08:14:58 [INFO]: Epoch 064 - training loss: 0.2911, validation loss: 0.2811
2024-05-24 08:14:58 [INFO]: Epoch 065 - training loss: 0.2899, validation loss: 0.2757
2024-05-24 08:14:59 [INFO]: Epoch 066 - training loss: 0.2879, validation loss: 0.2762
2024-05-24 08:15:00 [INFO]: Epoch 067 - training loss: 0.2856, validation loss: 0.2779
2024-05-24 08:15:00 [INFO]: Epoch 068 - training loss: 0.2870, validation loss: 0.2735
2024-05-24 08:15:01 [INFO]: Epoch 069 - training loss: 0.2859, validation loss: 0.2761
2024-05-24 08:15:02 [INFO]: Epoch 070 - training loss: 0.2856, validation loss: 0.2691
2024-05-24 08:15:02 [INFO]: Epoch 071 - training loss: 0.2867, validation loss: 0.2688
2024-05-24 08:15:03 [INFO]: Epoch 072 - training loss: 0.2833, validation loss: 0.2709
2024-05-24 08:15:04 [INFO]: Epoch 073 - training loss: 0.2858, validation loss: 0.2688
2024-05-24 08:15:05 [INFO]: Epoch 074 - training loss: 0.2829, validation loss: 0.2688
2024-05-24 08:15:05 [INFO]: Epoch 075 - training loss: 0.2817, validation loss: 0.2688
2024-05-24 08:15:06 [INFO]: Epoch 076 - training loss: 0.2804, validation loss: 0.2684
2024-05-24 08:15:07 [INFO]: Epoch 077 - training loss: 0.2824, validation loss: 0.2726
2024-05-24 08:15:07 [INFO]: Epoch 078 - training loss: 0.2808, validation loss: 0.2663
2024-05-24 08:15:08 [INFO]: Epoch 079 - training loss: 0.2795, validation loss: 0.2700
2024-05-24 08:15:09 [INFO]: Epoch 080 - training loss: 0.2824, validation loss: 0.2690
2024-05-24 08:15:09 [INFO]: Epoch 081 - training loss: 0.2799, validation loss: 0.2643
2024-05-24 08:15:10 [INFO]: Epoch 082 - training loss: 0.2799, validation loss: 0.2627
2024-05-24 08:15:11 [INFO]: Epoch 083 - training loss: 0.2763, validation loss: 0.2727
2024-05-24 08:15:11 [INFO]: Epoch 084 - training loss: 0.2734, validation loss: 0.2656
2024-05-24 08:15:12 [INFO]: Epoch 085 - training loss: 0.2782, validation loss: 0.2654
2024-05-24 08:15:13 [INFO]: Epoch 086 - training loss: 0.2769, validation loss: 0.2651
2024-05-24 08:15:14 [INFO]: Epoch 087 - training loss: 0.2787, validation loss: 0.2686
2024-05-24 08:15:14 [INFO]: Epoch 088 - training loss: 0.2736, validation loss: 0.2633
2024-05-24 08:15:15 [INFO]: Epoch 089 - training loss: 0.2752, validation loss: 0.2654
2024-05-24 08:15:16 [INFO]: Epoch 090 - training loss: 0.2746, validation loss: 0.2650
2024-05-24 08:15:16 [INFO]: Epoch 091 - training loss: 0.2719, validation loss: 0.2655
2024-05-24 08:15:17 [INFO]: Epoch 092 - training loss: 0.2732, validation loss: 0.2617
2024-05-24 08:15:18 [INFO]: Epoch 093 - training loss: 0.2700, validation loss: 0.2663
2024-05-24 08:15:19 [INFO]: Epoch 094 - training loss: 0.2732, validation loss: 0.2605
2024-05-24 08:15:19 [INFO]: Epoch 095 - training loss: 0.2722, validation loss: 0.2587
2024-05-24 08:15:20 [INFO]: Epoch 096 - training loss: 0.2693, validation loss: 0.2621
2024-05-24 08:15:21 [INFO]: Epoch 097 - training loss: 0.2708, validation loss: 0.2590
2024-05-24 08:15:21 [INFO]: Epoch 098 - training loss: 0.2687, validation loss: 0.2633
2024-05-24 08:15:22 [INFO]: Epoch 099 - training loss: 0.2724, validation loss: 0.2615
2024-05-24 08:15:23 [INFO]: Epoch 100 - training loss: 0.2662, validation loss: 0.2616
2024-05-24 08:15:24 [INFO]: Epoch 101 - training loss: 0.2701, validation loss: 0.2636
2024-05-24 08:15:24 [INFO]: Epoch 102 - training loss: 0.2679, validation loss: 0.2642
2024-05-24 08:15:25 [INFO]: Epoch 103 - training loss: 0.2684, validation loss: 0.2652
2024-05-24 08:15:26 [INFO]: Epoch 104 - training loss: 0.2666, validation loss: 0.2698
2024-05-24 08:15:26 [INFO]: Epoch 105 - training loss: 0.2668, validation loss: 0.2626
2024-05-24 08:15:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:15:26 [INFO]: Finished training. The best model is from epoch#95.
2024-05-24 08:15:27 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T081413/Transformer.pypots
2024-05-24 08:15:27 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2220, MSE=0.2751
2024-05-24 08:15:27 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_physionet_2012_seta/imputation.pkl
2024-05-24 08:15:27 [INFO]: Using the given device: cuda:0
2024-05-24 08:15:27 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T081527
2024-05-24 08:15:27 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T081527/tensorboard
2024-05-24 08:15:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-24 08:15:28 [INFO]: Epoch 001 - training loss: 0.4294, validation loss: 0.3709
2024-05-24 08:15:29 [INFO]: Epoch 002 - training loss: 0.3345, validation loss: 0.9153
2024-05-24 08:15:29 [INFO]: Epoch 003 - training loss: 0.6611, validation loss: 0.4801
2024-05-24 08:15:30 [INFO]: Epoch 004 - training loss: 0.3757, validation loss: 0.3315
2024-05-24 08:15:31 [INFO]: Epoch 005 - training loss: 0.4356, validation loss: 0.5959
2024-05-24 08:15:32 [INFO]: Epoch 006 - training loss: 0.5680, validation loss: 0.3908
2024-05-24 08:15:33 [INFO]: Epoch 007 - training loss: 0.4220, validation loss: 0.3433
2024-05-24 08:15:33 [INFO]: Epoch 008 - training loss: 0.3560, validation loss: 0.3254
2024-05-24 08:15:34 [INFO]: Epoch 009 - training loss: 0.3332, validation loss: 0.4104
2024-05-24 08:15:35 [INFO]: Epoch 010 - training loss: 0.3843, validation loss: 0.3545
2024-05-24 08:15:36 [INFO]: Epoch 011 - training loss: 0.3449, validation loss: 0.3435
2024-05-24 08:15:37 [INFO]: Epoch 012 - training loss: 0.3332, validation loss: 0.3145
2024-05-24 08:15:37 [INFO]: Epoch 013 - training loss: 0.3422, validation loss: 0.3110
2024-05-24 08:15:38 [INFO]: Epoch 014 - training loss: 0.3323, validation loss: 0.3383
2024-05-24 08:15:39 [INFO]: Epoch 015 - training loss: 0.3137, validation loss: 0.3250
2024-05-24 08:15:40 [INFO]: Epoch 016 - training loss: 0.3508, validation loss: 0.3166
2024-05-24 08:15:41 [INFO]: Epoch 017 - training loss: 0.3212, validation loss: 0.3259
2024-05-24 08:15:41 [INFO]: Epoch 018 - training loss: 0.3408, validation loss: 0.3352
2024-05-24 08:15:42 [INFO]: Epoch 019 - training loss: 0.3295, validation loss: 0.3010
2024-05-24 08:15:43 [INFO]: Epoch 020 - training loss: 0.3164, validation loss: 0.2969
2024-05-24 08:15:44 [INFO]: Epoch 021 - training loss: 0.2989, validation loss: 0.2953
2024-05-24 08:15:45 [INFO]: Epoch 022 - training loss: 0.2984, validation loss: 0.2894
2024-05-24 08:15:45 [INFO]: Epoch 023 - training loss: 0.3522, validation loss: 0.3326
2024-05-24 08:15:46 [INFO]: Epoch 024 - training loss: 0.3425, validation loss: 0.3655
2024-05-24 08:15:47 [INFO]: Epoch 025 - training loss: 0.3106, validation loss: 0.3561
2024-05-24 08:15:48 [INFO]: Epoch 026 - training loss: 0.2997, validation loss: 0.3359
2024-05-24 08:15:49 [INFO]: Epoch 027 - training loss: 0.3155, validation loss: 0.3143
2024-05-24 08:15:49 [INFO]: Epoch 028 - training loss: 0.3169, validation loss: 0.3757
2024-05-24 08:15:50 [INFO]: Epoch 029 - training loss: 0.3078, validation loss: 0.3325
2024-05-24 08:15:51 [INFO]: Epoch 030 - training loss: 0.3165, validation loss: 0.2995
2024-05-24 08:15:52 [INFO]: Epoch 031 - training loss: 0.3153, validation loss: 0.3129
2024-05-24 08:15:53 [INFO]: Epoch 032 - training loss: 0.3030, validation loss: 0.3097
2024-05-24 08:15:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:15:53 [INFO]: Finished training. The best model is from epoch#22.
2024-05-24 08:15:53 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T081527/TimesNet.pypots
2024-05-24 08:15:53 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2863, MSE=0.3291
2024-05-24 08:15:53 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-24 08:15:53 [INFO]: Using the given device: cuda:0
2024-05-24 08:15:53 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553
2024-05-24 08:15:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/tensorboard
2024-05-24 08:15:53 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-24 08:16:37 [INFO]: Epoch 001 - training loss: 0.4077, validation loss: 0.3408
2024-05-24 08:16:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch1_loss0.3408439740538597.pypots
2024-05-24 08:17:20 [INFO]: Epoch 002 - training loss: 0.3300, validation loss: 0.3027
2024-05-24 08:17:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch2_loss0.30273298770189283.pypots
2024-05-24 08:18:04 [INFO]: Epoch 003 - training loss: 0.2897, validation loss: 0.2463
2024-05-24 08:18:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch3_loss0.24625562950968743.pypots
2024-05-24 08:18:47 [INFO]: Epoch 004 - training loss: 0.2695, validation loss: 0.2321
2024-05-24 08:18:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch4_loss0.2320964552462101.pypots
2024-05-24 08:19:31 [INFO]: Epoch 005 - training loss: 0.2644, validation loss: 0.2241
2024-05-24 08:19:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch5_loss0.2240889199078083.pypots
2024-05-24 08:20:14 [INFO]: Epoch 006 - training loss: 0.2554, validation loss: 0.2197
2024-05-24 08:20:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch6_loss0.21966739371418953.pypots
2024-05-24 08:20:58 [INFO]: Epoch 007 - training loss: 0.2503, validation loss: 0.2124
2024-05-24 08:20:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch7_loss0.21239331737160683.pypots
2024-05-24 08:21:41 [INFO]: Epoch 008 - training loss: 0.2345, validation loss: 0.2083
2024-05-24 08:21:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch8_loss0.20826819017529488.pypots
2024-05-24 08:22:25 [INFO]: Epoch 009 - training loss: 0.2505, validation loss: 0.2087
2024-05-24 08:22:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch9_loss0.20871101841330528.pypots
2024-05-24 08:23:08 [INFO]: Epoch 010 - training loss: 0.2490, validation loss: 0.2049
2024-05-24 08:23:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch10_loss0.20492610856890678.pypots
2024-05-24 08:23:52 [INFO]: Epoch 011 - training loss: 0.2402, validation loss: 0.2039
2024-05-24 08:23:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch11_loss0.20385820791125298.pypots
2024-05-24 08:24:35 [INFO]: Epoch 012 - training loss: 0.2254, validation loss: 0.1977
2024-05-24 08:24:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch12_loss0.19765422493219376.pypots
2024-05-24 08:25:19 [INFO]: Epoch 013 - training loss: 0.2462, validation loss: 0.1989
2024-05-24 08:25:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch13_loss0.1988705538213253.pypots
2024-05-24 08:26:03 [INFO]: Epoch 014 - training loss: 0.2357, validation loss: 0.1957
2024-05-24 08:26:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch14_loss0.19565083980560302.pypots
2024-05-24 08:26:47 [INFO]: Epoch 015 - training loss: 0.2414, validation loss: 0.1976
2024-05-24 08:26:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch15_loss0.1975703939795494.pypots
2024-05-24 08:27:31 [INFO]: Epoch 016 - training loss: 0.2339, validation loss: 0.1954
2024-05-24 08:27:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch16_loss0.19538915753364564.pypots
2024-05-24 08:28:15 [INFO]: Epoch 017 - training loss: 0.2209, validation loss: 0.1928
2024-05-24 08:28:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch17_loss0.19283107295632362.pypots
2024-05-24 08:28:59 [INFO]: Epoch 018 - training loss: 0.2159, validation loss: 0.1998
2024-05-24 08:28:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch18_loss0.19976005628705024.pypots
2024-05-24 08:29:42 [INFO]: Epoch 019 - training loss: 0.2314, validation loss: 0.1899
2024-05-24 08:29:42 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch19_loss0.18989671692252158.pypots
2024-05-24 08:30:26 [INFO]: Epoch 020 - training loss: 0.2401, validation loss: 0.1999
2024-05-24 08:30:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch20_loss0.19992351904511452.pypots
2024-05-24 08:31:10 [INFO]: Epoch 021 - training loss: 0.2261, validation loss: 0.1895
2024-05-24 08:31:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch21_loss0.18952190428972243.pypots
2024-05-24 08:31:54 [INFO]: Epoch 022 - training loss: 0.2256, validation loss: 0.1924
2024-05-24 08:31:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch22_loss0.1924319662153721.pypots
2024-05-24 08:32:38 [INFO]: Epoch 023 - training loss: 0.2299, validation loss: 0.1944
2024-05-24 08:32:38 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch23_loss0.19441369473934172.pypots
2024-05-24 08:33:23 [INFO]: Epoch 024 - training loss: 0.2251, validation loss: 0.1898
2024-05-24 08:33:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch24_loss0.1897793360054493.pypots
2024-05-24 08:34:07 [INFO]: Epoch 025 - training loss: 0.2250, validation loss: 0.1903
2024-05-24 08:34:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch25_loss0.1902763642370701.pypots
2024-05-24 08:34:51 [INFO]: Epoch 026 - training loss: 0.2182, validation loss: 0.1854
2024-05-24 08:34:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch26_loss0.18543125912547112.pypots
2024-05-24 08:35:35 [INFO]: Epoch 027 - training loss: 0.2356, validation loss: 0.1900
2024-05-24 08:35:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch27_loss0.19001410156488419.pypots
2024-05-24 08:36:19 [INFO]: Epoch 028 - training loss: 0.2312, validation loss: 0.1890
2024-05-24 08:36:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch28_loss0.18896710127592087.pypots
2024-05-24 08:37:02 [INFO]: Epoch 029 - training loss: 0.2236, validation loss: 0.1902
2024-05-24 08:37:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch29_loss0.19016118422150613.pypots
2024-05-24 08:37:46 [INFO]: Epoch 030 - training loss: 0.2209, validation loss: 0.1868
2024-05-24 08:37:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch30_loss0.18681310638785362.pypots
2024-05-24 08:38:29 [INFO]: Epoch 031 - training loss: 0.2158, validation loss: 0.1969
2024-05-24 08:38:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch31_loss0.19693973883986474.pypots
2024-05-24 08:39:13 [INFO]: Epoch 032 - training loss: 0.2298, validation loss: 0.1832
2024-05-24 08:39:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch32_loss0.1832384191453457.pypots
2024-05-24 08:39:56 [INFO]: Epoch 033 - training loss: 0.2280, validation loss: 0.1840
2024-05-24 08:39:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch33_loss0.18396896719932557.pypots
2024-05-24 08:40:40 [INFO]: Epoch 034 - training loss: 0.2152, validation loss: 0.1858
2024-05-24 08:40:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch34_loss0.1857542634010315.pypots
2024-05-24 08:41:24 [INFO]: Epoch 035 - training loss: 0.2353, validation loss: 0.1839
2024-05-24 08:41:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch35_loss0.1838656783103943.pypots
2024-05-24 08:42:08 [INFO]: Epoch 036 - training loss: 0.2182, validation loss: 0.1843
2024-05-24 08:42:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch36_loss0.1843039758503437.pypots
2024-05-24 08:42:52 [INFO]: Epoch 037 - training loss: 0.2250, validation loss: 0.1831
2024-05-24 08:42:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch37_loss0.18312999457120896.pypots
2024-05-24 08:43:36 [INFO]: Epoch 038 - training loss: 0.2244, validation loss: 0.1826
2024-05-24 08:43:36 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch38_loss0.18260112553834915.pypots
2024-05-24 08:44:20 [INFO]: Epoch 039 - training loss: 0.2154, validation loss: 0.1818
2024-05-24 08:44:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch39_loss0.18176901787519456.pypots
2024-05-24 08:45:04 [INFO]: Epoch 040 - training loss: 0.2310, validation loss: 0.1826
2024-05-24 08:45:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch40_loss0.18256460204720498.pypots
2024-05-24 08:45:48 [INFO]: Epoch 041 - training loss: 0.2124, validation loss: 0.1828
2024-05-24 08:45:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch41_loss0.1828260637819767.pypots
2024-05-24 08:46:32 [INFO]: Epoch 042 - training loss: 0.2183, validation loss: 0.1835
2024-05-24 08:46:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch42_loss0.1834535740315914.pypots
2024-05-24 08:47:16 [INFO]: Epoch 043 - training loss: 0.2237, validation loss: 0.1820
2024-05-24 08:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch43_loss0.18202171921730043.pypots
2024-05-24 08:48:00 [INFO]: Epoch 044 - training loss: 0.2159, validation loss: 0.1791
2024-05-24 08:48:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch44_loss0.17913596853613853.pypots
2024-05-24 08:48:44 [INFO]: Epoch 045 - training loss: 0.2242, validation loss: 0.1808
2024-05-24 08:48:44 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch45_loss0.1808192402124405.pypots
2024-05-24 08:49:27 [INFO]: Epoch 046 - training loss: 0.2303, validation loss: 0.1802
2024-05-24 08:49:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch46_loss0.1801546573638916.pypots
2024-05-24 08:50:11 [INFO]: Epoch 047 - training loss: 0.2104, validation loss: 0.1808
2024-05-24 08:50:11 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch47_loss0.18078057691454888.pypots
2024-05-24 08:50:55 [INFO]: Epoch 048 - training loss: 0.2244, validation loss: 0.1797
2024-05-24 08:50:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch48_loss0.179730424284935.pypots
2024-05-24 08:51:39 [INFO]: Epoch 049 - training loss: 0.2300, validation loss: 0.1816
2024-05-24 08:51:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch49_loss0.1816154606640339.pypots
2024-05-24 08:52:23 [INFO]: Epoch 050 - training loss: 0.2210, validation loss: 0.1802
2024-05-24 08:52:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch50_loss0.18020230010151864.pypots
2024-05-24 08:53:06 [INFO]: Epoch 051 - training loss: 0.2114, validation loss: 0.1794
2024-05-24 08:53:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch51_loss0.17940471619367598.pypots
2024-05-24 08:53:50 [INFO]: Epoch 052 - training loss: 0.2238, validation loss: 0.1786
2024-05-24 08:53:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch52_loss0.17864498272538185.pypots
2024-05-24 08:54:33 [INFO]: Epoch 053 - training loss: 0.2141, validation loss: 0.1780
2024-05-24 08:54:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch53_loss0.17804540544748307.pypots
2024-05-24 08:55:17 [INFO]: Epoch 054 - training loss: 0.2248, validation loss: 0.1800
2024-05-24 08:55:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch54_loss0.1799511656165123.pypots
2024-05-24 08:56:01 [INFO]: Epoch 055 - training loss: 0.2231, validation loss: 0.1811
2024-05-24 08:56:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch55_loss0.18109057769179343.pypots
2024-05-24 08:56:45 [INFO]: Epoch 056 - training loss: 0.2183, validation loss: 0.1812
2024-05-24 08:56:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch56_loss0.18117570132017136.pypots
2024-05-24 08:57:29 [INFO]: Epoch 057 - training loss: 0.2184, validation loss: 0.1773
2024-05-24 08:57:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch57_loss0.17733967304229736.pypots
2024-05-24 08:58:13 [INFO]: Epoch 058 - training loss: 0.2198, validation loss: 0.1786
2024-05-24 08:58:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch58_loss0.17864347994327545.pypots
2024-05-24 08:58:56 [INFO]: Epoch 059 - training loss: 0.2139, validation loss: 0.1785
2024-05-24 08:58:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch59_loss0.1785396419465542.pypots
2024-05-24 08:59:40 [INFO]: Epoch 060 - training loss: 0.2211, validation loss: 0.1789
2024-05-24 08:59:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch60_loss0.17894955053925515.pypots
2024-05-24 09:00:24 [INFO]: Epoch 061 - training loss: 0.2066, validation loss: 0.1752
2024-05-24 09:00:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch61_loss0.17517639249563216.pypots
2024-05-24 09:01:08 [INFO]: Epoch 062 - training loss: 0.2135, validation loss: 0.1785
2024-05-24 09:01:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch62_loss0.17851205617189408.pypots
2024-05-24 09:01:51 [INFO]: Epoch 063 - training loss: 0.2170, validation loss: 0.1778
2024-05-24 09:01:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch63_loss0.1778458423912525.pypots
2024-05-24 09:02:35 [INFO]: Epoch 064 - training loss: 0.2219, validation loss: 0.1776
2024-05-24 09:02:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch64_loss0.17762427926063537.pypots
2024-05-24 09:03:18 [INFO]: Epoch 065 - training loss: 0.2277, validation loss: 0.1776
2024-05-24 09:03:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch65_loss0.17759164720773696.pypots
2024-05-24 09:04:02 [INFO]: Epoch 066 - training loss: 0.2162, validation loss: 0.1758
2024-05-24 09:04:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch66_loss0.17582818120718002.pypots
2024-05-24 09:04:45 [INFO]: Epoch 067 - training loss: 0.2161, validation loss: 0.1773
2024-05-24 09:04:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch67_loss0.177304495126009.pypots
2024-05-24 09:05:29 [INFO]: Epoch 068 - training loss: 0.2121, validation loss: 0.1766
2024-05-24 09:05:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch68_loss0.17657192349433898.pypots
2024-05-24 09:06:13 [INFO]: Epoch 069 - training loss: 0.2083, validation loss: 0.1780
2024-05-24 09:06:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch69_loss0.1780277244746685.pypots
2024-05-24 09:06:57 [INFO]: Epoch 070 - training loss: 0.2166, validation loss: 0.1770
2024-05-24 09:06:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch70_loss0.17698871940374375.pypots
2024-05-24 09:07:40 [INFO]: Epoch 071 - training loss: 0.2145, validation loss: 0.1788
2024-05-24 09:07:40 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI_epoch71_loss0.17884578853845595.pypots
2024-05-24 09:07:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:07:40 [INFO]: Finished training. The best model is from epoch#61.
2024-05-24 09:07:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T081553/CSDI.pypots
2024-05-24 09:15:02 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2566, MSE=0.9999
2024-05-24 09:44:15 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 09:44:15 [INFO]: Using the given device: cuda:0
2024-05-24 09:44:15 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T094415
2024-05-24 09:44:15 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T094415/tensorboard
2024-05-24 09:44:15 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 09:44:16 [INFO]: Epoch 001 - training loss: 42569.5441, validation loss: 0.9295
2024-05-24 09:44:17 [INFO]: Epoch 002 - training loss: 24410.5244, validation loss: 0.7627
2024-05-24 09:44:17 [INFO]: Epoch 003 - training loss: 23507.1770, validation loss: 0.7020
2024-05-24 09:44:18 [INFO]: Epoch 004 - training loss: 23218.1777, validation loss: 0.6758
2024-05-24 09:44:18 [INFO]: Epoch 005 - training loss: 23079.1665, validation loss: 0.6758
2024-05-24 09:44:19 [INFO]: Epoch 006 - training loss: 23000.3553, validation loss: 0.6767
2024-05-24 09:44:19 [INFO]: Epoch 007 - training loss: 22952.7648, validation loss: 0.6752
2024-05-24 09:44:20 [INFO]: Epoch 008 - training loss: 22921.1874, validation loss: 0.6711
2024-05-24 09:44:21 [INFO]: Epoch 009 - training loss: 22899.5406, validation loss: 0.6788
2024-05-24 09:44:21 [INFO]: Epoch 010 - training loss: 22884.7146, validation loss: 0.6782
2024-05-24 09:44:22 [INFO]: Epoch 011 - training loss: 22873.8947, validation loss: 0.6727
2024-05-24 09:44:22 [INFO]: Epoch 012 - training loss: 22865.1698, validation loss: 0.6641
2024-05-24 09:44:23 [INFO]: Epoch 013 - training loss: 22859.5020, validation loss: 0.6632
2024-05-24 09:44:23 [INFO]: Epoch 014 - training loss: 22853.8287, validation loss: 0.6648
2024-05-24 09:44:24 [INFO]: Epoch 015 - training loss: 22850.1309, validation loss: 0.6558
2024-05-24 09:44:25 [INFO]: Epoch 016 - training loss: 22845.8992, validation loss: 0.6525
2024-05-24 09:44:25 [INFO]: Epoch 017 - training loss: 22843.7927, validation loss: 0.6511
2024-05-24 09:44:26 [INFO]: Epoch 018 - training loss: 22840.3528, validation loss: 0.6446
2024-05-24 09:44:26 [INFO]: Epoch 019 - training loss: 22839.2852, validation loss: 0.6415
2024-05-24 09:44:27 [INFO]: Epoch 020 - training loss: 22836.9063, validation loss: 0.6497
2024-05-24 09:44:27 [INFO]: Epoch 021 - training loss: 22836.6461, validation loss: 0.6472
2024-05-24 09:44:28 [INFO]: Epoch 022 - training loss: 22833.6094, validation loss: 0.6332
2024-05-24 09:44:28 [INFO]: Epoch 023 - training loss: 22832.3461, validation loss: 0.6320
2024-05-24 09:44:29 [INFO]: Epoch 024 - training loss: 22830.2252, validation loss: 0.6260
2024-05-24 09:44:30 [INFO]: Epoch 025 - training loss: 22830.1008, validation loss: 0.6260
2024-05-24 09:44:30 [INFO]: Epoch 026 - training loss: 22827.5201, validation loss: 0.6159
2024-05-24 09:44:31 [INFO]: Epoch 027 - training loss: 22826.3246, validation loss: 0.6286
2024-05-24 09:44:31 [INFO]: Epoch 028 - training loss: 22824.5178, validation loss: 0.6052
2024-05-24 09:44:32 [INFO]: Epoch 029 - training loss: 22822.4584, validation loss: 0.6019
2024-05-24 09:44:32 [INFO]: Epoch 030 - training loss: 22820.9518, validation loss: 0.6024
2024-05-24 09:44:33 [INFO]: Epoch 031 - training loss: 22820.4112, validation loss: 0.6278
2024-05-24 09:44:34 [INFO]: Epoch 032 - training loss: 22821.7768, validation loss: 0.5967
2024-05-24 09:44:34 [INFO]: Epoch 033 - training loss: 22819.2752, validation loss: 0.5966
2024-05-24 09:44:35 [INFO]: Epoch 034 - training loss: 22818.1090, validation loss: 0.5912
2024-05-24 09:44:35 [INFO]: Epoch 035 - training loss: 22817.2302, validation loss: 0.5935
2024-05-24 09:44:36 [INFO]: Epoch 036 - training loss: 22816.9607, validation loss: 0.5866
2024-05-24 09:44:36 [INFO]: Epoch 037 - training loss: 22815.1324, validation loss: 0.5848
2024-05-24 09:44:37 [INFO]: Epoch 038 - training loss: 22814.6313, validation loss: 0.6001
2024-05-24 09:44:37 [INFO]: Epoch 039 - training loss: 22813.9075, validation loss: 0.5774
2024-05-24 09:44:38 [INFO]: Epoch 040 - training loss: 22813.5842, validation loss: 0.5819
2024-05-24 09:44:39 [INFO]: Epoch 041 - training loss: 22813.1536, validation loss: 0.5799
2024-05-24 09:44:39 [INFO]: Epoch 042 - training loss: 22812.1863, validation loss: 0.5776
2024-05-24 09:44:40 [INFO]: Epoch 043 - training loss: 22811.6134, validation loss: 0.5743
2024-05-24 09:44:40 [INFO]: Epoch 044 - training loss: 22810.8319, validation loss: 0.5690
2024-05-24 09:44:41 [INFO]: Epoch 045 - training loss: 22809.0240, validation loss: 0.5647
2024-05-24 09:44:41 [INFO]: Epoch 046 - training loss: 22808.4035, validation loss: 0.5626
2024-05-24 09:44:42 [INFO]: Epoch 047 - training loss: 22807.5544, validation loss: 0.5589
2024-05-24 09:44:43 [INFO]: Epoch 048 - training loss: 22806.4429, validation loss: 0.5521
2024-05-24 09:44:43 [INFO]: Epoch 049 - training loss: 22805.9906, validation loss: 0.5513
2024-05-24 09:44:44 [INFO]: Epoch 050 - training loss: 22805.2249, validation loss: 0.5441
2024-05-24 09:44:44 [INFO]: Epoch 051 - training loss: 22804.7130, validation loss: 0.5518
2024-05-24 09:44:45 [INFO]: Epoch 052 - training loss: 22804.5530, validation loss: 0.5439
2024-05-24 09:44:45 [INFO]: Epoch 053 - training loss: 22803.5255, validation loss: 0.5417
2024-05-24 09:44:46 [INFO]: Epoch 054 - training loss: 22804.1564, validation loss: 0.5410
2024-05-24 09:44:46 [INFO]: Epoch 055 - training loss: 22802.6543, validation loss: 0.5359
2024-05-24 09:44:47 [INFO]: Epoch 056 - training loss: 22802.1314, validation loss: 0.5326
2024-05-24 09:44:48 [INFO]: Epoch 057 - training loss: 22801.7637, validation loss: 0.5301
2024-05-24 09:44:48 [INFO]: Epoch 058 - training loss: 22801.0103, validation loss: 0.5365
2024-05-24 09:44:49 [INFO]: Epoch 059 - training loss: 22800.5534, validation loss: 0.5296
2024-05-24 09:44:49 [INFO]: Epoch 060 - training loss: 22800.2692, validation loss: 0.5304
2024-05-24 09:44:50 [INFO]: Epoch 061 - training loss: 22799.9174, validation loss: 0.5375
2024-05-24 09:44:50 [INFO]: Epoch 062 - training loss: 22799.7260, validation loss: 0.5284
2024-05-24 09:44:51 [INFO]: Epoch 063 - training loss: 22799.4009, validation loss: 0.5281
2024-05-24 09:44:51 [INFO]: Epoch 064 - training loss: 22799.5228, validation loss: 0.5351
2024-05-24 09:44:52 [INFO]: Epoch 065 - training loss: 22799.1012, validation loss: 0.5271
2024-05-24 09:44:53 [INFO]: Epoch 066 - training loss: 22799.7077, validation loss: 0.5225
2024-05-24 09:44:53 [INFO]: Epoch 067 - training loss: 22798.8576, validation loss: 0.5286
2024-05-24 09:44:54 [INFO]: Epoch 068 - training loss: 22798.3503, validation loss: 0.5280
2024-05-24 09:44:54 [INFO]: Epoch 069 - training loss: 22797.8943, validation loss: 0.5247
2024-05-24 09:44:55 [INFO]: Epoch 070 - training loss: 22797.1468, validation loss: 0.5197
2024-05-24 09:44:55 [INFO]: Epoch 071 - training loss: 22796.8096, validation loss: 0.5379
2024-05-24 09:44:56 [INFO]: Epoch 072 - training loss: 22797.6894, validation loss: 0.5329
2024-05-24 09:44:56 [INFO]: Epoch 073 - training loss: 22796.7382, validation loss: 0.5204
2024-05-24 09:44:57 [INFO]: Epoch 074 - training loss: 22796.4239, validation loss: 0.5656
2024-05-24 09:44:58 [INFO]: Epoch 075 - training loss: 22799.5957, validation loss: 0.5332
2024-05-24 09:44:58 [INFO]: Epoch 076 - training loss: 22797.7296, validation loss: 0.5204
2024-05-24 09:44:59 [INFO]: Epoch 077 - training loss: 22794.8455, validation loss: 0.5209
2024-05-24 09:44:59 [INFO]: Epoch 078 - training loss: 22795.5214, validation loss: 0.5191
2024-05-24 09:45:00 [INFO]: Epoch 079 - training loss: 22794.3715, validation loss: 0.5183
2024-05-24 09:45:00 [INFO]: Epoch 080 - training loss: 22794.1258, validation loss: 0.5156
2024-05-24 09:45:01 [INFO]: Epoch 081 - training loss: 22794.1658, validation loss: 0.5167
2024-05-24 09:45:01 [INFO]: Epoch 082 - training loss: 22793.9112, validation loss: 0.5137
2024-05-24 09:45:02 [INFO]: Epoch 083 - training loss: 22793.8553, validation loss: 0.5137
2024-05-24 09:45:03 [INFO]: Epoch 084 - training loss: 22793.2236, validation loss: 0.5119
2024-05-24 09:45:03 [INFO]: Epoch 085 - training loss: 22792.9019, validation loss: 0.5119
2024-05-24 09:45:04 [INFO]: Epoch 086 - training loss: 22792.8659, validation loss: 0.5134
2024-05-24 09:45:04 [INFO]: Epoch 087 - training loss: 22793.8782, validation loss: 0.5093
2024-05-24 09:45:05 [INFO]: Epoch 088 - training loss: 22795.3921, validation loss: 0.5141
2024-05-24 09:45:05 [INFO]: Epoch 089 - training loss: 22793.8426, validation loss: 0.5121
2024-05-24 09:45:06 [INFO]: Epoch 090 - training loss: 22792.8479, validation loss: 0.5105
2024-05-24 09:45:07 [INFO]: Epoch 091 - training loss: 22792.1505, validation loss: 0.5097
2024-05-24 09:45:07 [INFO]: Epoch 092 - training loss: 22792.5065, validation loss: 0.5071
2024-05-24 09:45:08 [INFO]: Epoch 093 - training loss: 22791.8411, validation loss: 0.5090
2024-05-24 09:45:08 [INFO]: Epoch 094 - training loss: 22791.3603, validation loss: 0.5041
2024-05-24 09:45:09 [INFO]: Epoch 095 - training loss: 22790.9512, validation loss: 0.5127
2024-05-24 09:45:09 [INFO]: Epoch 096 - training loss: 22791.1178, validation loss: 0.5022
2024-05-24 09:45:10 [INFO]: Epoch 097 - training loss: 22791.2444, validation loss: 0.5041
2024-05-24 09:45:10 [INFO]: Epoch 098 - training loss: 22790.8413, validation loss: 0.5071
2024-05-24 09:45:11 [INFO]: Epoch 099 - training loss: 22791.1452, validation loss: 0.5043
2024-05-24 09:45:12 [INFO]: Epoch 100 - training loss: 22790.5791, validation loss: 0.5056
2024-05-24 09:45:12 [INFO]: Epoch 101 - training loss: 22790.9648, validation loss: 0.5019
2024-05-24 09:45:13 [INFO]: Epoch 102 - training loss: 22790.1785, validation loss: 0.5015
2024-05-24 09:45:13 [INFO]: Epoch 103 - training loss: 22789.5546, validation loss: 0.5082
2024-05-24 09:45:14 [INFO]: Epoch 104 - training loss: 22790.6314, validation loss: 0.5013
2024-05-24 09:45:14 [INFO]: Epoch 105 - training loss: 22790.6234, validation loss: 0.5062
2024-05-24 09:45:15 [INFO]: Epoch 106 - training loss: 22791.3870, validation loss: 0.5031
2024-05-24 09:45:15 [INFO]: Epoch 107 - training loss: 22791.7969, validation loss: 0.4982
2024-05-24 09:45:16 [INFO]: Epoch 108 - training loss: 22789.1365, validation loss: 0.4981
2024-05-24 09:45:17 [INFO]: Epoch 109 - training loss: 22789.9516, validation loss: 0.4967
2024-05-24 09:45:17 [INFO]: Epoch 110 - training loss: 22788.2878, validation loss: 0.4897
2024-05-24 09:45:18 [INFO]: Epoch 111 - training loss: 22787.9867, validation loss: 0.4921
2024-05-24 09:45:18 [INFO]: Epoch 112 - training loss: 22787.7864, validation loss: 0.4902
2024-05-24 09:45:19 [INFO]: Epoch 113 - training loss: 22787.4515, validation loss: 0.4911
2024-05-24 09:45:19 [INFO]: Epoch 114 - training loss: 22787.6166, validation loss: 0.5006
2024-05-24 09:45:20 [INFO]: Epoch 115 - training loss: 22787.4194, validation loss: 0.4945
2024-05-24 09:45:20 [INFO]: Epoch 116 - training loss: 22787.4911, validation loss: 0.4877
2024-05-24 09:45:21 [INFO]: Epoch 117 - training loss: 22787.8746, validation loss: 0.4865
2024-05-24 09:45:22 [INFO]: Epoch 118 - training loss: 22787.4569, validation loss: 0.4910
2024-05-24 09:45:22 [INFO]: Epoch 119 - training loss: 22787.3251, validation loss: 0.4861
2024-05-24 09:45:23 [INFO]: Epoch 120 - training loss: 22787.1575, validation loss: 0.4871
2024-05-24 09:45:23 [INFO]: Epoch 121 - training loss: 22786.7407, validation loss: 0.4876
2024-05-24 09:45:24 [INFO]: Epoch 122 - training loss: 22786.4080, validation loss: 0.4854
2024-05-24 09:45:24 [INFO]: Epoch 123 - training loss: 22786.6200, validation loss: 0.4881
2024-05-24 09:45:25 [INFO]: Epoch 124 - training loss: 22787.5322, validation loss: 0.4866
2024-05-24 09:45:26 [INFO]: Epoch 125 - training loss: 22787.0524, validation loss: 0.4923
2024-05-24 09:45:26 [INFO]: Epoch 126 - training loss: 22786.3014, validation loss: 0.4926
2024-05-24 09:45:27 [INFO]: Epoch 127 - training loss: 22787.1544, validation loss: 0.4867
2024-05-24 09:45:27 [INFO]: Epoch 128 - training loss: 22785.7779, validation loss: 0.4906
2024-05-24 09:45:28 [INFO]: Epoch 129 - training loss: 22785.8750, validation loss: 0.4871
2024-05-24 09:45:28 [INFO]: Epoch 130 - training loss: 22785.9368, validation loss: 0.4828
2024-05-24 09:45:29 [INFO]: Epoch 131 - training loss: 22785.7991, validation loss: 0.4800
2024-05-24 09:45:29 [INFO]: Epoch 132 - training loss: 22785.4994, validation loss: 0.4783
2024-05-24 09:45:30 [INFO]: Epoch 133 - training loss: 22784.9614, validation loss: 0.4828
2024-05-24 09:45:31 [INFO]: Epoch 134 - training loss: 22785.0469, validation loss: 0.4822
2024-05-24 09:45:31 [INFO]: Epoch 135 - training loss: 22784.4955, validation loss: 0.4808
2024-05-24 09:45:32 [INFO]: Epoch 136 - training loss: 22784.5539, validation loss: 0.4775
2024-05-24 09:45:32 [INFO]: Epoch 137 - training loss: 22784.5531, validation loss: 0.4809
2024-05-24 09:45:33 [INFO]: Epoch 138 - training loss: 22784.4883, validation loss: 0.4855
2024-05-24 09:45:33 [INFO]: Epoch 139 - training loss: 22784.4053, validation loss: 0.4831
2024-05-24 09:45:34 [INFO]: Epoch 140 - training loss: 22784.5635, validation loss: 0.4749
2024-05-24 09:45:34 [INFO]: Epoch 141 - training loss: 22784.3935, validation loss: 0.4790
2024-05-24 09:45:35 [INFO]: Epoch 142 - training loss: 22784.7328, validation loss: 0.4762
2024-05-24 09:45:36 [INFO]: Epoch 143 - training loss: 22784.4777, validation loss: 0.4806
2024-05-24 09:45:36 [INFO]: Epoch 144 - training loss: 22784.7290, validation loss: 0.4746
2024-05-24 09:45:37 [INFO]: Epoch 145 - training loss: 22784.2445, validation loss: 0.4807
2024-05-24 09:45:37 [INFO]: Epoch 146 - training loss: 22784.1876, validation loss: 0.4826
2024-05-24 09:45:38 [INFO]: Epoch 147 - training loss: 22784.2145, validation loss: 0.4853
2024-05-24 09:45:38 [INFO]: Epoch 148 - training loss: 22784.1886, validation loss: 0.4754
2024-05-24 09:45:39 [INFO]: Epoch 149 - training loss: 22783.5049, validation loss: 0.4766
2024-05-24 09:45:39 [INFO]: Epoch 150 - training loss: 22783.5756, validation loss: 0.4743
2024-05-24 09:45:40 [INFO]: Epoch 151 - training loss: 22782.9979, validation loss: 0.4786
2024-05-24 09:45:41 [INFO]: Epoch 152 - training loss: 22783.0197, validation loss: 0.4712
2024-05-24 09:45:41 [INFO]: Epoch 153 - training loss: 22782.9421, validation loss: 0.4726
2024-05-24 09:45:42 [INFO]: Epoch 154 - training loss: 22782.6506, validation loss: 0.4750
2024-05-24 09:45:42 [INFO]: Epoch 155 - training loss: 22782.6922, validation loss: 0.4763
2024-05-24 09:45:43 [INFO]: Epoch 156 - training loss: 22782.8414, validation loss: 0.4696
2024-05-24 09:45:43 [INFO]: Epoch 157 - training loss: 22782.8445, validation loss: 0.4725
2024-05-24 09:45:44 [INFO]: Epoch 158 - training loss: 22782.3781, validation loss: 0.4731
2024-05-24 09:45:44 [INFO]: Epoch 159 - training loss: 22783.4177, validation loss: 0.4711
2024-05-24 09:45:45 [INFO]: Epoch 160 - training loss: 22782.5127, validation loss: 0.4743
2024-05-24 09:45:46 [INFO]: Epoch 161 - training loss: 22782.0263, validation loss: 0.4720
2024-05-24 09:45:46 [INFO]: Epoch 162 - training loss: 22781.9500, validation loss: 0.4704
2024-05-24 09:45:47 [INFO]: Epoch 163 - training loss: 22781.7148, validation loss: 0.4723
2024-05-24 09:45:47 [INFO]: Epoch 164 - training loss: 22781.6448, validation loss: 0.4690
2024-05-24 09:45:48 [INFO]: Epoch 165 - training loss: 22782.1312, validation loss: 0.4731
2024-05-24 09:45:48 [INFO]: Epoch 166 - training loss: 22781.9365, validation loss: 0.4706
2024-05-24 09:45:49 [INFO]: Epoch 167 - training loss: 22781.8581, validation loss: 0.4696
2024-05-24 09:45:50 [INFO]: Epoch 168 - training loss: 22782.1841, validation loss: 0.4716
2024-05-24 09:45:50 [INFO]: Epoch 169 - training loss: 22782.4330, validation loss: 0.4705
2024-05-24 09:45:51 [INFO]: Epoch 170 - training loss: 22781.7125, validation loss: 0.4703
2024-05-24 09:45:51 [INFO]: Epoch 171 - training loss: 22781.5887, validation loss: 0.4710
2024-05-24 09:45:52 [INFO]: Epoch 172 - training loss: 22781.8507, validation loss: 0.4672
2024-05-24 09:45:52 [INFO]: Epoch 173 - training loss: 22781.1428, validation loss: 0.4718
2024-05-24 09:45:53 [INFO]: Epoch 174 - training loss: 22781.2559, validation loss: 0.4698
2024-05-24 09:45:53 [INFO]: Epoch 175 - training loss: 22781.3369, validation loss: 0.4714
2024-05-24 09:45:54 [INFO]: Epoch 176 - training loss: 22781.5411, validation loss: 0.4675
2024-05-24 09:45:55 [INFO]: Epoch 177 - training loss: 22780.6374, validation loss: 0.4699
2024-05-24 09:45:55 [INFO]: Epoch 178 - training loss: 22780.4612, validation loss: 0.4673
2024-05-24 09:45:56 [INFO]: Epoch 179 - training loss: 22780.2178, validation loss: 0.4660
2024-05-24 09:45:56 [INFO]: Epoch 180 - training loss: 22780.2466, validation loss: 0.4695
2024-05-24 09:45:57 [INFO]: Epoch 181 - training loss: 22780.3601, validation loss: 0.4654
2024-05-24 09:45:57 [INFO]: Epoch 182 - training loss: 22780.2400, validation loss: 0.4659
2024-05-24 09:45:58 [INFO]: Epoch 183 - training loss: 22780.6953, validation loss: 0.4683
2024-05-24 09:45:58 [INFO]: Epoch 184 - training loss: 22780.9681, validation loss: 0.4702
2024-05-24 09:45:59 [INFO]: Epoch 185 - training loss: 22780.7732, validation loss: 0.4683
2024-05-24 09:46:00 [INFO]: Epoch 186 - training loss: 22781.0995, validation loss: 0.4671
2024-05-24 09:46:00 [INFO]: Epoch 187 - training loss: 22780.4532, validation loss: 0.4671
2024-05-24 09:46:01 [INFO]: Epoch 188 - training loss: 22780.5878, validation loss: 0.4676
2024-05-24 09:46:01 [INFO]: Epoch 189 - training loss: 22780.2798, validation loss: 0.4660
2024-05-24 09:46:02 [INFO]: Epoch 190 - training loss: 22779.7189, validation loss: 0.4659
2024-05-24 09:46:02 [INFO]: Epoch 191 - training loss: 22779.4155, validation loss: 0.4690
2024-05-24 09:46:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:46:02 [INFO]: Finished training. The best model is from epoch#181.
2024-05-24 09:46:02 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T094415/GPVAE.pypots
2024-05-24 09:46:02 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4160, MSE=0.4966
2024-05-24 09:46:03 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 09:46:03 [INFO]: Using the given device: cuda:0
2024-05-24 09:46:03 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T094603
2024-05-24 09:46:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T094603/tensorboard
2024-05-24 09:46:03 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 09:46:24 [INFO]: Epoch 001 - generator training loss: 0.5729, discriminator training loss: 0.3852, validation loss: 0.6230
2024-05-24 09:46:43 [INFO]: Epoch 002 - generator training loss: 0.4595, discriminator training loss: 0.2619, validation loss: 0.5288
2024-05-24 09:47:01 [INFO]: Epoch 003 - generator training loss: 0.4173, discriminator training loss: 0.2150, validation loss: 0.4968
2024-05-24 09:47:19 [INFO]: Epoch 004 - generator training loss: 0.4358, discriminator training loss: 0.1604, validation loss: 0.4915
2024-05-24 09:47:38 [INFO]: Epoch 005 - generator training loss: 0.4361, discriminator training loss: 0.1278, validation loss: 0.4726
2024-05-24 09:47:56 [INFO]: Epoch 006 - generator training loss: 0.4288, discriminator training loss: 0.1078, validation loss: 0.4608
2024-05-24 09:48:15 [INFO]: Epoch 007 - generator training loss: 0.4143, discriminator training loss: 0.0924, validation loss: 0.4426
2024-05-24 09:48:33 [INFO]: Epoch 008 - generator training loss: 0.4030, discriminator training loss: 0.0820, validation loss: 0.4300
2024-05-24 09:48:51 [INFO]: Epoch 009 - generator training loss: 0.3915, discriminator training loss: 0.0738, validation loss: 0.4260
2024-05-24 09:49:10 [INFO]: Epoch 010 - generator training loss: 0.3832, discriminator training loss: 0.0668, validation loss: 0.4107
2024-05-24 09:49:28 [INFO]: Epoch 011 - generator training loss: 0.3751, discriminator training loss: 0.0612, validation loss: 0.4068
2024-05-24 09:49:47 [INFO]: Epoch 012 - generator training loss: 0.3684, discriminator training loss: 0.0566, validation loss: 0.4007
2024-05-24 09:50:05 [INFO]: Epoch 013 - generator training loss: 0.3623, discriminator training loss: 0.0525, validation loss: 0.3926
2024-05-24 09:50:23 [INFO]: Epoch 014 - generator training loss: 0.3575, discriminator training loss: 0.0494, validation loss: 0.3871
2024-05-24 09:50:42 [INFO]: Epoch 015 - generator training loss: 0.3508, discriminator training loss: 0.0462, validation loss: 0.3831
2024-05-24 09:51:00 [INFO]: Epoch 016 - generator training loss: 0.3460, discriminator training loss: 0.0438, validation loss: 0.3821
2024-05-24 09:51:19 [INFO]: Epoch 017 - generator training loss: 0.3410, discriminator training loss: 0.0418, validation loss: 0.3695
2024-05-24 09:51:37 [INFO]: Epoch 018 - generator training loss: 0.3358, discriminator training loss: 0.0399, validation loss: 0.3652
2024-05-24 09:51:55 [INFO]: Epoch 019 - generator training loss: 0.3315, discriminator training loss: 0.0383, validation loss: 0.3618
2024-05-24 09:52:14 [INFO]: Epoch 020 - generator training loss: 0.3257, discriminator training loss: 0.0368, validation loss: 0.3585
2024-05-24 09:52:32 [INFO]: Epoch 021 - generator training loss: 0.3225, discriminator training loss: 0.0357, validation loss: 0.3533
2024-05-24 09:52:51 [INFO]: Epoch 022 - generator training loss: 0.3154, discriminator training loss: 0.0346, validation loss: 0.3502
2024-05-24 09:53:09 [INFO]: Epoch 023 - generator training loss: 0.3120, discriminator training loss: 0.0337, validation loss: 0.3502
2024-05-24 09:53:27 [INFO]: Epoch 024 - generator training loss: 0.3095, discriminator training loss: 0.0329, validation loss: 0.3442
2024-05-24 09:53:46 [INFO]: Epoch 025 - generator training loss: 0.3036, discriminator training loss: 0.0321, validation loss: 0.3485
2024-05-24 09:54:04 [INFO]: Epoch 026 - generator training loss: 0.3042, discriminator training loss: 0.0314, validation loss: 0.3403
2024-05-24 09:54:23 [INFO]: Epoch 027 - generator training loss: 0.2990, discriminator training loss: 0.0309, validation loss: 0.3392
2024-05-24 09:54:41 [INFO]: Epoch 028 - generator training loss: 0.2919, discriminator training loss: 0.0303, validation loss: 0.3374
2024-05-24 09:54:59 [INFO]: Epoch 029 - generator training loss: 0.2894, discriminator training loss: 0.0299, validation loss: 0.3374
2024-05-24 09:55:18 [INFO]: Epoch 030 - generator training loss: 0.2869, discriminator training loss: 0.0293, validation loss: 0.3331
2024-05-24 09:55:36 [INFO]: Epoch 031 - generator training loss: 0.2816, discriminator training loss: 0.0289, validation loss: 0.3301
2024-05-24 09:55:55 [INFO]: Epoch 032 - generator training loss: 0.2827, discriminator training loss: 0.0285, validation loss: 0.3312
2024-05-24 09:56:13 [INFO]: Epoch 033 - generator training loss: 0.2781, discriminator training loss: 0.0282, validation loss: 0.3256
2024-05-24 09:56:32 [INFO]: Epoch 034 - generator training loss: 0.2693, discriminator training loss: 0.0277, validation loss: 0.3280
2024-05-24 09:56:50 [INFO]: Epoch 035 - generator training loss: 0.2671, discriminator training loss: 0.0274, validation loss: 0.3315
2024-05-24 09:57:08 [INFO]: Epoch 036 - generator training loss: 0.2717, discriminator training loss: 0.0270, validation loss: 0.3216
2024-05-24 09:57:27 [INFO]: Epoch 037 - generator training loss: 0.2674, discriminator training loss: 0.0267, validation loss: 0.3266
2024-05-24 09:57:45 [INFO]: Epoch 038 - generator training loss: 0.2612, discriminator training loss: 0.0264, validation loss: 0.3229
2024-05-24 09:58:04 [INFO]: Epoch 039 - generator training loss: 0.2576, discriminator training loss: 0.0262, validation loss: 0.3179
2024-05-24 09:58:22 [INFO]: Epoch 040 - generator training loss: 0.2526, discriminator training loss: 0.0260, validation loss: 0.3182
2024-05-24 09:58:40 [INFO]: Epoch 041 - generator training loss: 0.2565, discriminator training loss: 0.0256, validation loss: 0.3305
2024-05-24 09:58:59 [INFO]: Epoch 042 - generator training loss: 0.2654, discriminator training loss: 0.0254, validation loss: 0.3226
2024-05-24 09:59:17 [INFO]: Epoch 043 - generator training loss: 0.2546, discriminator training loss: 0.0250, validation loss: 0.3200
2024-05-24 09:59:36 [INFO]: Epoch 044 - generator training loss: 0.2495, discriminator training loss: 0.0250, validation loss: 0.3203
2024-05-24 09:59:54 [INFO]: Epoch 045 - generator training loss: 0.2452, discriminator training loss: 0.0247, validation loss: 0.3157
2024-05-24 10:00:12 [INFO]: Epoch 046 - generator training loss: 0.2420, discriminator training loss: 0.0244, validation loss: 0.3126
2024-05-24 10:00:31 [INFO]: Epoch 047 - generator training loss: 0.2393, discriminator training loss: 0.0244, validation loss: 0.3143
2024-05-24 10:00:49 [INFO]: Epoch 048 - generator training loss: 0.2359, discriminator training loss: 0.0241, validation loss: 0.3151
2024-05-24 10:01:08 [INFO]: Epoch 049 - generator training loss: 0.2358, discriminator training loss: 0.0241, validation loss: 0.3146
2024-05-24 10:01:26 [INFO]: Epoch 050 - generator training loss: 0.2400, discriminator training loss: 0.0239, validation loss: 0.3180
2024-05-24 10:01:44 [INFO]: Epoch 051 - generator training loss: 0.2354, discriminator training loss: 0.0238, validation loss: 0.3115
2024-05-24 10:02:03 [INFO]: Epoch 052 - generator training loss: 0.2364, discriminator training loss: 0.0235, validation loss: 0.3113
2024-05-24 10:02:21 [INFO]: Epoch 053 - generator training loss: 0.2309, discriminator training loss: 0.0236, validation loss: 0.3128
2024-05-24 10:02:40 [INFO]: Epoch 054 - generator training loss: 0.2281, discriminator training loss: 0.0234, validation loss: 0.3104
2024-05-24 10:02:58 [INFO]: Epoch 055 - generator training loss: 0.2250, discriminator training loss: 0.0232, validation loss: 0.3119
2024-05-24 10:03:16 [INFO]: Epoch 056 - generator training loss: 0.2231, discriminator training loss: 0.0233, validation loss: 0.3106
2024-05-24 10:03:35 [INFO]: Epoch 057 - generator training loss: 0.2212, discriminator training loss: 0.0230, validation loss: 0.3118
2024-05-24 10:03:53 [INFO]: Epoch 058 - generator training loss: 0.2264, discriminator training loss: 0.0231, validation loss: 0.3135
2024-05-24 10:04:12 [INFO]: Epoch 059 - generator training loss: 0.2214, discriminator training loss: 0.0230, validation loss: 0.3115
2024-05-24 10:04:30 [INFO]: Epoch 060 - generator training loss: 0.2155, discriminator training loss: 0.0229, validation loss: 0.3100
2024-05-24 10:04:48 [INFO]: Epoch 061 - generator training loss: 0.2191, discriminator training loss: 0.0226, validation loss: 0.3102
2024-05-24 10:05:07 [INFO]: Epoch 062 - generator training loss: 0.2198, discriminator training loss: 0.0226, validation loss: 0.3143
2024-05-24 10:05:25 [INFO]: Epoch 063 - generator training loss: 0.2167, discriminator training loss: 0.0225, validation loss: 0.3100
2024-05-24 10:05:44 [INFO]: Epoch 064 - generator training loss: 0.2142, discriminator training loss: 0.0224, validation loss: 0.3076
2024-05-24 10:06:02 [INFO]: Epoch 065 - generator training loss: 0.2092, discriminator training loss: 0.0223, validation loss: 0.3148
2024-05-24 10:06:20 [INFO]: Epoch 066 - generator training loss: 0.2096, discriminator training loss: 0.0221, validation loss: 0.3087
2024-05-24 10:06:39 [INFO]: Epoch 067 - generator training loss: 0.2112, discriminator training loss: 0.0221, validation loss: 0.3095
2024-05-24 10:06:57 [INFO]: Epoch 068 - generator training loss: 0.2045, discriminator training loss: 0.0220, validation loss: 0.3064
2024-05-24 10:07:16 [INFO]: Epoch 069 - generator training loss: 0.2007, discriminator training loss: 0.0219, validation loss: 0.3066
2024-05-24 10:07:34 [INFO]: Epoch 070 - generator training loss: 0.2001, discriminator training loss: 0.0218, validation loss: 0.3083
2024-05-24 10:07:52 [INFO]: Epoch 071 - generator training loss: 0.2041, discriminator training loss: 0.0219, validation loss: 0.3087
2024-05-24 10:08:11 [INFO]: Epoch 072 - generator training loss: 0.2019, discriminator training loss: 0.0219, validation loss: 0.3097
2024-05-24 10:08:29 [INFO]: Epoch 073 - generator training loss: 0.2001, discriminator training loss: 0.0216, validation loss: 0.3101
2024-05-24 10:08:48 [INFO]: Epoch 074 - generator training loss: 0.2001, discriminator training loss: 0.0215, validation loss: 0.3072
2024-05-24 10:09:06 [INFO]: Epoch 075 - generator training loss: 0.1981, discriminator training loss: 0.0215, validation loss: 0.3061
2024-05-24 10:09:24 [INFO]: Epoch 076 - generator training loss: 0.1953, discriminator training loss: 0.0214, validation loss: 0.3074
2024-05-24 10:09:43 [INFO]: Epoch 077 - generator training loss: 0.1922, discriminator training loss: 0.0213, validation loss: 0.3058
2024-05-24 10:10:01 [INFO]: Epoch 078 - generator training loss: 0.1875, discriminator training loss: 0.0213, validation loss: 0.3099
2024-05-24 10:10:20 [INFO]: Epoch 079 - generator training loss: 0.1893, discriminator training loss: 0.0211, validation loss: 0.3075
2024-05-24 10:10:38 [INFO]: Epoch 080 - generator training loss: 0.1863, discriminator training loss: 0.0210, validation loss: 0.3068
2024-05-24 10:10:56 [INFO]: Epoch 081 - generator training loss: 0.1878, discriminator training loss: 0.0210, validation loss: 0.3061
2024-05-24 10:11:15 [INFO]: Epoch 082 - generator training loss: 0.1836, discriminator training loss: 0.0209, validation loss: 0.3083
2024-05-24 10:11:33 [INFO]: Epoch 083 - generator training loss: 0.1802, discriminator training loss: 0.0207, validation loss: 0.3092
2024-05-24 10:11:52 [INFO]: Epoch 084 - generator training loss: 0.1782, discriminator training loss: 0.0207, validation loss: 0.3068
2024-05-24 10:12:10 [INFO]: Epoch 085 - generator training loss: 0.1837, discriminator training loss: 0.0207, validation loss: 0.3098
2024-05-24 10:12:28 [INFO]: Epoch 086 - generator training loss: 0.1778, discriminator training loss: 0.0206, validation loss: 0.3088
2024-05-24 10:12:47 [INFO]: Epoch 087 - generator training loss: 0.1748, discriminator training loss: 0.0205, validation loss: 0.3079
2024-05-24 10:12:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:12:47 [INFO]: Finished training. The best model is from epoch#77.
2024-05-24 10:12:47 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T094603/USGAN.pypots
2024-05-24 10:12:49 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2942, MSE=0.3240
2024-05-24 10:12:59 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 10:12:59 [INFO]: Using the given device: cuda:0
2024-05-24 10:12:59 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T101259
2024-05-24 10:12:59 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T101259/tensorboard
2024-05-24 10:12:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 10:13:14 [INFO]: Epoch 001 - training loss: 1.1295, validation loss: 0.5500
2024-05-24 10:13:26 [INFO]: Epoch 002 - training loss: 0.9156, validation loss: 0.4892
2024-05-24 10:13:38 [INFO]: Epoch 003 - training loss: 0.8557, validation loss: 0.4558
2024-05-24 10:13:50 [INFO]: Epoch 004 - training loss: 0.8185, validation loss: 0.4359
2024-05-24 10:14:02 [INFO]: Epoch 005 - training loss: 0.7907, validation loss: 0.4175
2024-05-24 10:14:14 [INFO]: Epoch 006 - training loss: 0.7684, validation loss: 0.4038
2024-05-24 10:14:26 [INFO]: Epoch 007 - training loss: 0.7492, validation loss: 0.3923
2024-05-24 10:14:38 [INFO]: Epoch 008 - training loss: 0.7318, validation loss: 0.3812
2024-05-24 10:14:50 [INFO]: Epoch 009 - training loss: 0.7171, validation loss: 0.3726
2024-05-24 10:15:02 [INFO]: Epoch 010 - training loss: 0.7036, validation loss: 0.3670
2024-05-24 10:15:14 [INFO]: Epoch 011 - training loss: 0.6931, validation loss: 0.3628
2024-05-24 10:15:26 [INFO]: Epoch 012 - training loss: 0.6835, validation loss: 0.3559
2024-05-24 10:15:38 [INFO]: Epoch 013 - training loss: 0.6737, validation loss: 0.3528
2024-05-24 10:15:50 [INFO]: Epoch 014 - training loss: 0.6671, validation loss: 0.3480
2024-05-24 10:16:02 [INFO]: Epoch 015 - training loss: 0.6607, validation loss: 0.3473
2024-05-24 10:16:14 [INFO]: Epoch 016 - training loss: 0.6531, validation loss: 0.3442
2024-05-24 10:16:26 [INFO]: Epoch 017 - training loss: 0.6484, validation loss: 0.3431
2024-05-24 10:16:38 [INFO]: Epoch 018 - training loss: 0.6436, validation loss: 0.3428
2024-05-24 10:16:50 [INFO]: Epoch 019 - training loss: 0.6390, validation loss: 0.3408
2024-05-24 10:17:02 [INFO]: Epoch 020 - training loss: 0.6344, validation loss: 0.3383
2024-05-24 10:17:14 [INFO]: Epoch 021 - training loss: 0.6307, validation loss: 0.3383
2024-05-24 10:17:26 [INFO]: Epoch 022 - training loss: 0.6271, validation loss: 0.3367
2024-05-24 10:17:39 [INFO]: Epoch 023 - training loss: 0.6233, validation loss: 0.3352
2024-05-24 10:17:51 [INFO]: Epoch 024 - training loss: 0.6194, validation loss: 0.3339
2024-05-24 10:18:03 [INFO]: Epoch 025 - training loss: 0.6164, validation loss: 0.3330
2024-05-24 10:18:15 [INFO]: Epoch 026 - training loss: 0.6139, validation loss: 0.3325
2024-05-24 10:18:27 [INFO]: Epoch 027 - training loss: 0.6110, validation loss: 0.3340
2024-05-24 10:18:39 [INFO]: Epoch 028 - training loss: 0.6083, validation loss: 0.3311
2024-05-24 10:18:51 [INFO]: Epoch 029 - training loss: 0.6079, validation loss: 0.3304
2024-05-24 10:19:03 [INFO]: Epoch 030 - training loss: 0.6006, validation loss: 0.3285
2024-05-24 10:19:15 [INFO]: Epoch 031 - training loss: 0.5980, validation loss: 0.3288
2024-05-24 10:19:27 [INFO]: Epoch 032 - training loss: 0.5947, validation loss: 0.3291
2024-05-24 10:19:39 [INFO]: Epoch 033 - training loss: 0.5920, validation loss: 0.3289
2024-05-24 10:19:51 [INFO]: Epoch 034 - training loss: 0.5893, validation loss: 0.3274
2024-05-24 10:20:03 [INFO]: Epoch 035 - training loss: 0.5859, validation loss: 0.3277
2024-05-24 10:20:15 [INFO]: Epoch 036 - training loss: 0.5840, validation loss: 0.3289
2024-05-24 10:20:27 [INFO]: Epoch 037 - training loss: 0.5805, validation loss: 0.3286
2024-05-24 10:20:39 [INFO]: Epoch 038 - training loss: 0.5775, validation loss: 0.3290
2024-05-24 10:20:51 [INFO]: Epoch 039 - training loss: 0.5741, validation loss: 0.3289
2024-05-24 10:21:03 [INFO]: Epoch 040 - training loss: 0.5722, validation loss: 0.3289
2024-05-24 10:21:15 [INFO]: Epoch 041 - training loss: 0.5689, validation loss: 0.3294
2024-05-24 10:21:27 [INFO]: Epoch 042 - training loss: 0.5681, validation loss: 0.3303
2024-05-24 10:21:39 [INFO]: Epoch 043 - training loss: 0.5663, validation loss: 0.3308
2024-05-24 10:21:51 [INFO]: Epoch 044 - training loss: 0.5618, validation loss: 0.3316
2024-05-24 10:21:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:21:51 [INFO]: Finished training. The best model is from epoch#34.
2024-05-24 10:21:51 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T101259/BRITS.pypots
2024-05-24 10:21:53 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2610, MSE=0.3401
2024-05-24 10:22:03 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 10:22:03 [INFO]: Using the given device: cuda:0
2024-05-24 10:22:03 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203
2024-05-24 10:22:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/tensorboard
2024-05-24 10:22:03 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 10:22:09 [INFO]: Epoch 001 - training loss: 1.0876, validation loss: 1.0100
2024-05-24 10:22:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch1_loss1.0099748641252517.pypots
2024-05-24 10:22:12 [INFO]: Epoch 002 - training loss: 0.6807, validation loss: 0.9788
2024-05-24 10:22:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch2_loss0.9788363575935364.pypots
2024-05-24 10:22:14 [INFO]: Epoch 003 - training loss: 0.6082, validation loss: 0.9516
2024-05-24 10:22:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch3_loss0.9515517711639404.pypots
2024-05-24 10:22:17 [INFO]: Epoch 004 - training loss: 0.5631, validation loss: 0.9376
2024-05-24 10:22:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch4_loss0.9375953942537307.pypots
2024-05-24 10:22:20 [INFO]: Epoch 005 - training loss: 0.5426, validation loss: 0.9312
2024-05-24 10:22:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch5_loss0.9312488615512848.pypots
2024-05-24 10:22:23 [INFO]: Epoch 006 - training loss: 0.5275, validation loss: 0.9276
2024-05-24 10:22:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch6_loss0.9276175647974014.pypots
2024-05-24 10:22:25 [INFO]: Epoch 007 - training loss: 0.5104, validation loss: 0.9235
2024-05-24 10:22:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch7_loss0.9234708428382874.pypots
2024-05-24 10:22:28 [INFO]: Epoch 008 - training loss: 0.5105, validation loss: 0.9223
2024-05-24 10:22:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch8_loss0.9222826540470124.pypots
2024-05-24 10:22:31 [INFO]: Epoch 009 - training loss: 0.4940, validation loss: 0.9200
2024-05-24 10:22:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch9_loss0.9200359910726548.pypots
2024-05-24 10:22:34 [INFO]: Epoch 010 - training loss: 0.4898, validation loss: 0.9182
2024-05-24 10:22:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch10_loss0.9181797683238984.pypots
2024-05-24 10:22:36 [INFO]: Epoch 011 - training loss: 0.4851, validation loss: 0.9188
2024-05-24 10:22:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch11_loss0.918772503733635.pypots
2024-05-24 10:22:39 [INFO]: Epoch 012 - training loss: 0.4817, validation loss: 0.9189
2024-05-24 10:22:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch12_loss0.9189444273710251.pypots
2024-05-24 10:22:42 [INFO]: Epoch 013 - training loss: 0.4775, validation loss: 0.9205
2024-05-24 10:22:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch13_loss0.9205382496118546.pypots
2024-05-24 10:22:45 [INFO]: Epoch 014 - training loss: 0.4795, validation loss: 0.9205
2024-05-24 10:22:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch14_loss0.920517948269844.pypots
2024-05-24 10:22:48 [INFO]: Epoch 015 - training loss: 0.4609, validation loss: 0.9206
2024-05-24 10:22:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch15_loss0.9206340163946152.pypots
2024-05-24 10:22:50 [INFO]: Epoch 016 - training loss: 0.4596, validation loss: 0.9221
2024-05-24 10:22:50 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch16_loss0.9221442013978958.pypots
2024-05-24 10:22:53 [INFO]: Epoch 017 - training loss: 0.4611, validation loss: 0.9241
2024-05-24 10:22:53 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch17_loss0.9240834295749665.pypots
2024-05-24 10:22:56 [INFO]: Epoch 018 - training loss: 0.4688, validation loss: 0.9245
2024-05-24 10:22:56 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch18_loss0.9245252013206482.pypots
2024-05-24 10:22:59 [INFO]: Epoch 019 - training loss: 0.4584, validation loss: 0.9247
2024-05-24 10:22:59 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch19_loss0.9246781498193741.pypots
2024-05-24 10:23:01 [INFO]: Epoch 020 - training loss: 0.4694, validation loss: 0.9306
2024-05-24 10:23:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN_epoch20_loss0.9306175827980041.pypots
2024-05-24 10:23:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:23:01 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 10:23:01 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T102203/MRNN.pypots
2024-05-24 10:23:02 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6873, MSE=0.9367
2024-05-24 10:23:07 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 10:23:07 [INFO]: Using the given device: cpu
2024-05-24 10:23:07 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4114, MSE=0.6133
2024-05-24 10:23:07 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_physionet_2012_seta".
2024-05-24 10:23:07 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 10:23:07 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6898, MSE=1.0489
2024-05-24 10:23:07 [INFO]: Successfully created the given path "saved_results/round_3/Median_physionet_2012_seta".
2024-05-24 10:23:07 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_physionet_2012_seta/imputation.pkl
2024-05-24 10:23:07 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7072, MSE=1.0216
2024-05-24 10:23:07 [INFO]: Successfully created the given path "saved_results/round_3/Mean_physionet_2012_seta".
2024-05-24 10:23:07 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 10:23:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-24 10:23:07 [INFO]: Using the given device: cuda:0
2024-05-24 10:23:07 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T102307
2024-05-24 10:23:07 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T102307/tensorboard
2024-05-24 10:23:07 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-24 10:23:08 [INFO]: Epoch 001 - training loss: 1.0751, validation loss: 0.4954
2024-05-24 10:23:10 [INFO]: Epoch 002 - training loss: 0.6645, validation loss: 0.4319
2024-05-24 10:23:11 [INFO]: Epoch 003 - training loss: 0.5785, validation loss: 0.4159
2024-05-24 10:23:12 [INFO]: Epoch 004 - training loss: 0.5218, validation loss: 0.3915
2024-05-24 10:23:13 [INFO]: Epoch 005 - training loss: 0.4846, validation loss: 0.3777
2024-05-24 10:23:15 [INFO]: Epoch 006 - training loss: 0.4611, validation loss: 0.3659
2024-05-24 10:23:16 [INFO]: Epoch 007 - training loss: 0.4420, validation loss: 0.3558
2024-05-24 10:23:17 [INFO]: Epoch 008 - training loss: 0.4192, validation loss: 0.3440
2024-05-24 10:23:18 [INFO]: Epoch 009 - training loss: 0.3997, validation loss: 0.3286
2024-05-24 10:23:20 [INFO]: Epoch 010 - training loss: 0.3900, validation loss: 0.3222
2024-05-24 10:23:21 [INFO]: Epoch 011 - training loss: 0.3788, validation loss: 0.3177
2024-05-24 10:23:22 [INFO]: Epoch 012 - training loss: 0.3690, validation loss: 0.3141
2024-05-24 10:23:23 [INFO]: Epoch 013 - training loss: 0.3562, validation loss: 0.3095
2024-05-24 10:23:25 [INFO]: Epoch 014 - training loss: 0.3492, validation loss: 0.3015
2024-05-24 10:23:26 [INFO]: Epoch 015 - training loss: 0.3347, validation loss: 0.2989
2024-05-24 10:23:27 [INFO]: Epoch 016 - training loss: 0.3327, validation loss: 0.2942
2024-05-24 10:23:29 [INFO]: Epoch 017 - training loss: 0.3319, validation loss: 0.2959
2024-05-24 10:23:30 [INFO]: Epoch 018 - training loss: 0.3207, validation loss: 0.2919
2024-05-24 10:23:31 [INFO]: Epoch 019 - training loss: 0.3163, validation loss: 0.2908
2024-05-24 10:23:32 [INFO]: Epoch 020 - training loss: 0.3119, validation loss: 0.2836
2024-05-24 10:23:34 [INFO]: Epoch 021 - training loss: 0.3077, validation loss: 0.2803
2024-05-24 10:23:35 [INFO]: Epoch 022 - training loss: 0.3074, validation loss: 0.2788
2024-05-24 10:23:36 [INFO]: Epoch 023 - training loss: 0.3017, validation loss: 0.2780
2024-05-24 10:23:37 [INFO]: Epoch 024 - training loss: 0.2985, validation loss: 0.2777
2024-05-24 10:23:39 [INFO]: Epoch 025 - training loss: 0.2976, validation loss: 0.2713
2024-05-24 10:23:40 [INFO]: Epoch 026 - training loss: 0.2909, validation loss: 0.2742
2024-05-24 10:23:41 [INFO]: Epoch 027 - training loss: 0.2905, validation loss: 0.2743
2024-05-24 10:23:42 [INFO]: Epoch 028 - training loss: 0.2884, validation loss: 0.2702
2024-05-24 10:23:44 [INFO]: Epoch 029 - training loss: 0.2834, validation loss: 0.2677
2024-05-24 10:23:45 [INFO]: Epoch 030 - training loss: 0.2818, validation loss: 0.2655
2024-05-24 10:23:46 [INFO]: Epoch 031 - training loss: 0.2816, validation loss: 0.2697
2024-05-24 10:23:48 [INFO]: Epoch 032 - training loss: 0.2815, validation loss: 0.2647
2024-05-24 10:23:49 [INFO]: Epoch 033 - training loss: 0.2801, validation loss: 0.2643
2024-05-24 10:23:50 [INFO]: Epoch 034 - training loss: 0.2786, validation loss: 0.2662
2024-05-24 10:23:51 [INFO]: Epoch 035 - training loss: 0.2755, validation loss: 0.2664
2024-05-24 10:23:53 [INFO]: Epoch 036 - training loss: 0.2738, validation loss: 0.2657
2024-05-24 10:23:54 [INFO]: Epoch 037 - training loss: 0.2743, validation loss: 0.2627
2024-05-24 10:23:55 [INFO]: Epoch 038 - training loss: 0.2701, validation loss: 0.2650
2024-05-24 10:23:56 [INFO]: Epoch 039 - training loss: 0.2723, validation loss: 0.2610
2024-05-24 10:23:58 [INFO]: Epoch 040 - training loss: 0.2712, validation loss: 0.2610
2024-05-24 10:23:59 [INFO]: Epoch 041 - training loss: 0.2711, validation loss: 0.2597
2024-05-24 10:24:00 [INFO]: Epoch 042 - training loss: 0.2675, validation loss: 0.2638
2024-05-24 10:24:01 [INFO]: Epoch 043 - training loss: 0.2651, validation loss: 0.2647
2024-05-24 10:24:03 [INFO]: Epoch 044 - training loss: 0.2675, validation loss: 0.2591
2024-05-24 10:24:04 [INFO]: Epoch 045 - training loss: 0.2643, validation loss: 0.2614
2024-05-24 10:24:05 [INFO]: Epoch 046 - training loss: 0.2646, validation loss: 0.2589
2024-05-24 10:24:06 [INFO]: Epoch 047 - training loss: 0.2616, validation loss: 0.2617
2024-05-24 10:24:08 [INFO]: Epoch 048 - training loss: 0.2613, validation loss: 0.2619
2024-05-24 10:24:09 [INFO]: Epoch 049 - training loss: 0.2626, validation loss: 0.2602
2024-05-24 10:24:10 [INFO]: Epoch 050 - training loss: 0.2604, validation loss: 0.2578
2024-05-24 10:24:12 [INFO]: Epoch 051 - training loss: 0.2586, validation loss: 0.2583
2024-05-24 10:24:13 [INFO]: Epoch 052 - training loss: 0.2585, validation loss: 0.2610
2024-05-24 10:24:14 [INFO]: Epoch 053 - training loss: 0.2588, validation loss: 0.2600
2024-05-24 10:24:15 [INFO]: Epoch 054 - training loss: 0.2559, validation loss: 0.2591
2024-05-24 10:24:17 [INFO]: Epoch 055 - training loss: 0.2564, validation loss: 0.2536
2024-05-24 10:24:18 [INFO]: Epoch 056 - training loss: 0.2565, validation loss: 0.2584
2024-05-24 10:24:19 [INFO]: Epoch 057 - training loss: 0.2572, validation loss: 0.2570
2024-05-24 10:24:20 [INFO]: Epoch 058 - training loss: 0.2572, validation loss: 0.2557
2024-05-24 10:24:22 [INFO]: Epoch 059 - training loss: 0.2546, validation loss: 0.2568
2024-05-24 10:24:23 [INFO]: Epoch 060 - training loss: 0.2544, validation loss: 0.2572
2024-05-24 10:24:24 [INFO]: Epoch 061 - training loss: 0.2530, validation loss: 0.2611
2024-05-24 10:24:26 [INFO]: Epoch 062 - training loss: 0.2526, validation loss: 0.2614
2024-05-24 10:24:27 [INFO]: Epoch 063 - training loss: 0.2488, validation loss: 0.2553
2024-05-24 10:24:28 [INFO]: Epoch 064 - training loss: 0.2504, validation loss: 0.2540
2024-05-24 10:24:29 [INFO]: Epoch 065 - training loss: 0.2497, validation loss: 0.2514
2024-05-24 10:24:31 [INFO]: Epoch 066 - training loss: 0.2505, validation loss: 0.2530
2024-05-24 10:24:32 [INFO]: Epoch 067 - training loss: 0.2475, validation loss: 0.2522
2024-05-24 10:24:33 [INFO]: Epoch 068 - training loss: 0.2479, validation loss: 0.2574
2024-05-24 10:24:34 [INFO]: Epoch 069 - training loss: 0.2503, validation loss: 0.2535
2024-05-24 10:24:36 [INFO]: Epoch 070 - training loss: 0.2500, validation loss: 0.2574
2024-05-24 10:24:37 [INFO]: Epoch 071 - training loss: 0.2485, validation loss: 0.2567
2024-05-24 10:24:38 [INFO]: Epoch 072 - training loss: 0.2493, validation loss: 0.2598
2024-05-24 10:24:39 [INFO]: Epoch 073 - training loss: 0.2473, validation loss: 0.2516
2024-05-24 10:24:41 [INFO]: Epoch 074 - training loss: 0.2473, validation loss: 0.2497
2024-05-24 10:24:42 [INFO]: Epoch 075 - training loss: 0.2467, validation loss: 0.2514
2024-05-24 10:24:43 [INFO]: Epoch 076 - training loss: 0.2442, validation loss: 0.2514
2024-05-24 10:24:45 [INFO]: Epoch 077 - training loss: 0.2455, validation loss: 0.2525
2024-05-24 10:24:46 [INFO]: Epoch 078 - training loss: 0.2457, validation loss: 0.2549
2024-05-24 10:24:47 [INFO]: Epoch 079 - training loss: 0.2452, validation loss: 0.2538
2024-05-24 10:24:48 [INFO]: Epoch 080 - training loss: 0.2454, validation loss: 0.2525
2024-05-24 10:24:50 [INFO]: Epoch 081 - training loss: 0.2453, validation loss: 0.2563
2024-05-24 10:24:51 [INFO]: Epoch 082 - training loss: 0.2441, validation loss: 0.2487
2024-05-24 10:24:52 [INFO]: Epoch 083 - training loss: 0.2409, validation loss: 0.2550
2024-05-24 10:24:53 [INFO]: Epoch 084 - training loss: 0.2405, validation loss: 0.2514
2024-05-24 10:24:55 [INFO]: Epoch 085 - training loss: 0.2390, validation loss: 0.2545
2024-05-24 10:24:56 [INFO]: Epoch 086 - training loss: 0.2428, validation loss: 0.2540
2024-05-24 10:24:57 [INFO]: Epoch 087 - training loss: 0.2397, validation loss: 0.2529
2024-05-24 10:24:59 [INFO]: Epoch 088 - training loss: 0.2448, validation loss: 0.2612
2024-05-24 10:25:00 [INFO]: Epoch 089 - training loss: 0.2433, validation loss: 0.2530
2024-05-24 10:25:01 [INFO]: Epoch 090 - training loss: 0.2400, validation loss: 0.2557
2024-05-24 10:25:02 [INFO]: Epoch 091 - training loss: 0.2403, validation loss: 0.2547
2024-05-24 10:25:04 [INFO]: Epoch 092 - training loss: 0.2392, validation loss: 0.2510
2024-05-24 10:25:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:25:04 [INFO]: Finished training. The best model is from epoch#82.
2024-05-24 10:25:04 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T102307/SAITS.pypots
2024-05-24 10:25:04 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2084, MSE=0.2729
2024-05-24 10:25:04 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_physionet_2012_seta/imputation.pkl
2024-05-24 10:25:04 [INFO]: Using the given device: cuda:0
2024-05-24 10:25:04 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T102504
2024-05-24 10:25:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T102504/tensorboard
2024-05-24 10:25:04 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-24 10:25:05 [INFO]: Epoch 001 - training loss: 1.2235, validation loss: 0.6119
2024-05-24 10:25:06 [INFO]: Epoch 002 - training loss: 0.7630, validation loss: 0.4878
2024-05-24 10:25:06 [INFO]: Epoch 003 - training loss: 0.6472, validation loss: 0.4681
2024-05-24 10:25:07 [INFO]: Epoch 004 - training loss: 0.5984, validation loss: 0.4365
2024-05-24 10:25:08 [INFO]: Epoch 005 - training loss: 0.5533, validation loss: 0.4223
2024-05-24 10:25:08 [INFO]: Epoch 006 - training loss: 0.5245, validation loss: 0.4156
2024-05-24 10:25:09 [INFO]: Epoch 007 - training loss: 0.5008, validation loss: 0.4085
2024-05-24 10:25:10 [INFO]: Epoch 008 - training loss: 0.4836, validation loss: 0.3969
2024-05-24 10:25:10 [INFO]: Epoch 009 - training loss: 0.4717, validation loss: 0.3947
2024-05-24 10:25:11 [INFO]: Epoch 010 - training loss: 0.4583, validation loss: 0.3896
2024-05-24 10:25:12 [INFO]: Epoch 011 - training loss: 0.4442, validation loss: 0.3866
2024-05-24 10:25:13 [INFO]: Epoch 012 - training loss: 0.4351, validation loss: 0.3681
2024-05-24 10:25:13 [INFO]: Epoch 013 - training loss: 0.4167, validation loss: 0.3636
2024-05-24 10:25:14 [INFO]: Epoch 014 - training loss: 0.4139, validation loss: 0.3598
2024-05-24 10:25:15 [INFO]: Epoch 015 - training loss: 0.4078, validation loss: 0.3525
2024-05-24 10:25:15 [INFO]: Epoch 016 - training loss: 0.3988, validation loss: 0.3462
2024-05-24 10:25:16 [INFO]: Epoch 017 - training loss: 0.3888, validation loss: 0.3452
2024-05-24 10:25:17 [INFO]: Epoch 018 - training loss: 0.3919, validation loss: 0.3466
2024-05-24 10:25:17 [INFO]: Epoch 019 - training loss: 0.3806, validation loss: 0.3364
2024-05-24 10:25:18 [INFO]: Epoch 020 - training loss: 0.3743, validation loss: 0.3364
2024-05-24 10:25:19 [INFO]: Epoch 021 - training loss: 0.3689, validation loss: 0.3368
2024-05-24 10:25:19 [INFO]: Epoch 022 - training loss: 0.3661, validation loss: 0.3325
2024-05-24 10:25:20 [INFO]: Epoch 023 - training loss: 0.3624, validation loss: 0.3284
2024-05-24 10:25:21 [INFO]: Epoch 024 - training loss: 0.3579, validation loss: 0.3257
2024-05-24 10:25:22 [INFO]: Epoch 025 - training loss: 0.3531, validation loss: 0.3195
2024-05-24 10:25:23 [INFO]: Epoch 026 - training loss: 0.3502, validation loss: 0.3210
2024-05-24 10:25:23 [INFO]: Epoch 027 - training loss: 0.3485, validation loss: 0.3226
2024-05-24 10:25:24 [INFO]: Epoch 028 - training loss: 0.3481, validation loss: 0.3193
2024-05-24 10:25:25 [INFO]: Epoch 029 - training loss: 0.3410, validation loss: 0.3144
2024-05-24 10:25:25 [INFO]: Epoch 030 - training loss: 0.3393, validation loss: 0.3151
2024-05-24 10:25:26 [INFO]: Epoch 031 - training loss: 0.3395, validation loss: 0.3148
2024-05-24 10:25:27 [INFO]: Epoch 032 - training loss: 0.3335, validation loss: 0.3135
2024-05-24 10:25:27 [INFO]: Epoch 033 - training loss: 0.3292, validation loss: 0.3102
2024-05-24 10:25:28 [INFO]: Epoch 034 - training loss: 0.3316, validation loss: 0.3083
2024-05-24 10:25:29 [INFO]: Epoch 035 - training loss: 0.3280, validation loss: 0.3052
2024-05-24 10:25:29 [INFO]: Epoch 036 - training loss: 0.3233, validation loss: 0.3057
2024-05-24 10:25:30 [INFO]: Epoch 037 - training loss: 0.3218, validation loss: 0.3058
2024-05-24 10:25:31 [INFO]: Epoch 038 - training loss: 0.3226, validation loss: 0.2990
2024-05-24 10:25:32 [INFO]: Epoch 039 - training loss: 0.3209, validation loss: 0.3050
2024-05-24 10:25:32 [INFO]: Epoch 040 - training loss: 0.3219, validation loss: 0.3006
2024-05-24 10:25:33 [INFO]: Epoch 041 - training loss: 0.3171, validation loss: 0.3005
2024-05-24 10:25:34 [INFO]: Epoch 042 - training loss: 0.3120, validation loss: 0.2995
2024-05-24 10:25:34 [INFO]: Epoch 043 - training loss: 0.3154, validation loss: 0.2955
2024-05-24 10:25:35 [INFO]: Epoch 044 - training loss: 0.3121, validation loss: 0.2938
2024-05-24 10:25:36 [INFO]: Epoch 045 - training loss: 0.3142, validation loss: 0.2931
2024-05-24 10:25:37 [INFO]: Epoch 046 - training loss: 0.3099, validation loss: 0.2917
2024-05-24 10:25:37 [INFO]: Epoch 047 - training loss: 0.3123, validation loss: 0.2965
2024-05-24 10:25:38 [INFO]: Epoch 048 - training loss: 0.3077, validation loss: 0.2879
2024-05-24 10:25:39 [INFO]: Epoch 049 - training loss: 0.3052, validation loss: 0.2905
2024-05-24 10:25:39 [INFO]: Epoch 050 - training loss: 0.3088, validation loss: 0.2918
2024-05-24 10:25:40 [INFO]: Epoch 051 - training loss: 0.3059, validation loss: 0.2877
2024-05-24 10:25:41 [INFO]: Epoch 052 - training loss: 0.3042, validation loss: 0.2892
2024-05-24 10:25:41 [INFO]: Epoch 053 - training loss: 0.3021, validation loss: 0.2872
2024-05-24 10:25:42 [INFO]: Epoch 054 - training loss: 0.3042, validation loss: 0.2821
2024-05-24 10:25:43 [INFO]: Epoch 055 - training loss: 0.3008, validation loss: 0.2825
2024-05-24 10:25:44 [INFO]: Epoch 056 - training loss: 0.2948, validation loss: 0.2803
2024-05-24 10:25:44 [INFO]: Epoch 057 - training loss: 0.2970, validation loss: 0.2834
2024-05-24 10:25:45 [INFO]: Epoch 058 - training loss: 0.2964, validation loss: 0.2784
2024-05-24 10:25:46 [INFO]: Epoch 059 - training loss: 0.2955, validation loss: 0.2807
2024-05-24 10:25:46 [INFO]: Epoch 060 - training loss: 0.2972, validation loss: 0.2810
2024-05-24 10:25:47 [INFO]: Epoch 061 - training loss: 0.2947, validation loss: 0.2800
2024-05-24 10:25:48 [INFO]: Epoch 062 - training loss: 0.2929, validation loss: 0.2805
2024-05-24 10:25:48 [INFO]: Epoch 063 - training loss: 0.2965, validation loss: 0.2766
2024-05-24 10:25:49 [INFO]: Epoch 064 - training loss: 0.2935, validation loss: 0.2775
2024-05-24 10:25:50 [INFO]: Epoch 065 - training loss: 0.2908, validation loss: 0.2741
2024-05-24 10:25:50 [INFO]: Epoch 066 - training loss: 0.2919, validation loss: 0.2743
2024-05-24 10:25:51 [INFO]: Epoch 067 - training loss: 0.2891, validation loss: 0.2748
2024-05-24 10:25:52 [INFO]: Epoch 068 - training loss: 0.2909, validation loss: 0.2760
2024-05-24 10:25:53 [INFO]: Epoch 069 - training loss: 0.2890, validation loss: 0.2728
2024-05-24 10:25:53 [INFO]: Epoch 070 - training loss: 0.2902, validation loss: 0.2761
2024-05-24 10:25:54 [INFO]: Epoch 071 - training loss: 0.2856, validation loss: 0.2690
2024-05-24 10:25:55 [INFO]: Epoch 072 - training loss: 0.2857, validation loss: 0.2719
2024-05-24 10:25:55 [INFO]: Epoch 073 - training loss: 0.2845, validation loss: 0.2719
2024-05-24 10:25:56 [INFO]: Epoch 074 - training loss: 0.2851, validation loss: 0.2701
2024-05-24 10:25:57 [INFO]: Epoch 075 - training loss: 0.2843, validation loss: 0.2697
2024-05-24 10:25:57 [INFO]: Epoch 076 - training loss: 0.2832, validation loss: 0.2692
2024-05-24 10:25:58 [INFO]: Epoch 077 - training loss: 0.2839, validation loss: 0.2730
2024-05-24 10:25:59 [INFO]: Epoch 078 - training loss: 0.2828, validation loss: 0.2690
2024-05-24 10:25:59 [INFO]: Epoch 079 - training loss: 0.2805, validation loss: 0.2703
2024-05-24 10:26:00 [INFO]: Epoch 080 - training loss: 0.2843, validation loss: 0.2693
2024-05-24 10:26:01 [INFO]: Epoch 081 - training loss: 0.2826, validation loss: 0.2709
2024-05-24 10:26:02 [INFO]: Epoch 082 - training loss: 0.2843, validation loss: 0.2699
2024-05-24 10:26:02 [INFO]: Epoch 083 - training loss: 0.2816, validation loss: 0.2695
2024-05-24 10:26:03 [INFO]: Epoch 084 - training loss: 0.2813, validation loss: 0.2794
2024-05-24 10:26:04 [INFO]: Epoch 085 - training loss: 0.2780, validation loss: 0.2675
2024-05-24 10:26:04 [INFO]: Epoch 086 - training loss: 0.2822, validation loss: 0.2694
2024-05-24 10:26:05 [INFO]: Epoch 087 - training loss: 0.2763, validation loss: 0.2680
2024-05-24 10:26:06 [INFO]: Epoch 088 - training loss: 0.2771, validation loss: 0.2639
2024-05-24 10:26:07 [INFO]: Epoch 089 - training loss: 0.2747, validation loss: 0.2671
2024-05-24 10:26:07 [INFO]: Epoch 090 - training loss: 0.2770, validation loss: 0.2674
2024-05-24 10:26:08 [INFO]: Epoch 091 - training loss: 0.2773, validation loss: 0.2651
2024-05-24 10:26:09 [INFO]: Epoch 092 - training loss: 0.2744, validation loss: 0.2630
2024-05-24 10:26:09 [INFO]: Epoch 093 - training loss: 0.2743, validation loss: 0.2664
2024-05-24 10:26:10 [INFO]: Epoch 094 - training loss: 0.2723, validation loss: 0.2604
2024-05-24 10:26:11 [INFO]: Epoch 095 - training loss: 0.2750, validation loss: 0.2686
2024-05-24 10:26:12 [INFO]: Epoch 096 - training loss: 0.2714, validation loss: 0.2672
2024-05-24 10:26:12 [INFO]: Epoch 097 - training loss: 0.2720, validation loss: 0.2656
2024-05-24 10:26:13 [INFO]: Epoch 098 - training loss: 0.2713, validation loss: 0.2653
2024-05-24 10:26:14 [INFO]: Epoch 099 - training loss: 0.2722, validation loss: 0.2642
2024-05-24 10:26:14 [INFO]: Epoch 100 - training loss: 0.2708, validation loss: 0.2651
2024-05-24 10:26:15 [INFO]: Epoch 101 - training loss: 0.2716, validation loss: 0.2637
2024-05-24 10:26:16 [INFO]: Epoch 102 - training loss: 0.2703, validation loss: 0.2639
2024-05-24 10:26:16 [INFO]: Epoch 103 - training loss: 0.2704, validation loss: 0.2600
2024-05-24 10:26:17 [INFO]: Epoch 104 - training loss: 0.2683, validation loss: 0.2620
2024-05-24 10:26:18 [INFO]: Epoch 105 - training loss: 0.2692, validation loss: 0.2606
2024-05-24 10:26:18 [INFO]: Epoch 106 - training loss: 0.2670, validation loss: 0.2588
2024-05-24 10:26:19 [INFO]: Epoch 107 - training loss: 0.2685, validation loss: 0.2600
2024-05-24 10:26:20 [INFO]: Epoch 108 - training loss: 0.2700, validation loss: 0.2609
2024-05-24 10:26:21 [INFO]: Epoch 109 - training loss: 0.2681, validation loss: 0.2600
2024-05-24 10:26:21 [INFO]: Epoch 110 - training loss: 0.2704, validation loss: 0.2607
2024-05-24 10:26:22 [INFO]: Epoch 111 - training loss: 0.2678, validation loss: 0.2609
2024-05-24 10:26:23 [INFO]: Epoch 112 - training loss: 0.2657, validation loss: 0.2634
2024-05-24 10:26:23 [INFO]: Epoch 113 - training loss: 0.2662, validation loss: 0.2652
2024-05-24 10:26:24 [INFO]: Epoch 114 - training loss: 0.2663, validation loss: 0.2574
2024-05-24 10:26:25 [INFO]: Epoch 115 - training loss: 0.2655, validation loss: 0.2597
2024-05-24 10:26:25 [INFO]: Epoch 116 - training loss: 0.2659, validation loss: 0.2595
2024-05-24 10:26:26 [INFO]: Epoch 117 - training loss: 0.2661, validation loss: 0.2621
2024-05-24 10:26:27 [INFO]: Epoch 118 - training loss: 0.2655, validation loss: 0.2589
2024-05-24 10:26:28 [INFO]: Epoch 119 - training loss: 0.2652, validation loss: 0.2597
2024-05-24 10:26:28 [INFO]: Epoch 120 - training loss: 0.2638, validation loss: 0.2540
2024-05-24 10:26:29 [INFO]: Epoch 121 - training loss: 0.2615, validation loss: 0.2597
2024-05-24 10:26:30 [INFO]: Epoch 122 - training loss: 0.2606, validation loss: 0.2595
2024-05-24 10:26:30 [INFO]: Epoch 123 - training loss: 0.2627, validation loss: 0.2556
2024-05-24 10:26:31 [INFO]: Epoch 124 - training loss: 0.2611, validation loss: 0.2611
2024-05-24 10:26:32 [INFO]: Epoch 125 - training loss: 0.2601, validation loss: 0.2559
2024-05-24 10:26:32 [INFO]: Epoch 126 - training loss: 0.2606, validation loss: 0.2589
2024-05-24 10:26:33 [INFO]: Epoch 127 - training loss: 0.2601, validation loss: 0.2554
2024-05-24 10:26:34 [INFO]: Epoch 128 - training loss: 0.2591, validation loss: 0.2582
2024-05-24 10:26:34 [INFO]: Epoch 129 - training loss: 0.2591, validation loss: 0.2570
2024-05-24 10:26:35 [INFO]: Epoch 130 - training loss: 0.2625, validation loss: 0.2570
2024-05-24 10:26:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:26:35 [INFO]: Finished training. The best model is from epoch#120.
2024-05-24 10:26:35 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T102504/Transformer.pypots
2024-05-24 10:26:35 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2226, MSE=0.2721
2024-05-24 10:26:35 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_physionet_2012_seta/imputation.pkl
2024-05-24 10:26:35 [INFO]: Using the given device: cuda:0
2024-05-24 10:26:35 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T102635
2024-05-24 10:26:35 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T102635/tensorboard
2024-05-24 10:26:36 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-24 10:26:36 [INFO]: Epoch 001 - training loss: 0.5093, validation loss: 0.3653
2024-05-24 10:26:37 [INFO]: Epoch 002 - training loss: 0.3965, validation loss: 0.6476
2024-05-24 10:26:38 [INFO]: Epoch 003 - training loss: 0.3701, validation loss: 0.5070
2024-05-24 10:26:39 [INFO]: Epoch 004 - training loss: 0.4384, validation loss: 0.5326
2024-05-24 10:26:40 [INFO]: Epoch 005 - training loss: 0.5315, validation loss: 0.6977
2024-05-24 10:26:40 [INFO]: Epoch 006 - training loss: 0.3415, validation loss: 0.5142
2024-05-24 10:26:41 [INFO]: Epoch 007 - training loss: 0.5168, validation loss: 0.4076
2024-05-24 10:26:42 [INFO]: Epoch 008 - training loss: 0.3680, validation loss: 0.4322
2024-05-24 10:26:43 [INFO]: Epoch 009 - training loss: 0.3636, validation loss: 0.3120
2024-05-24 10:26:44 [INFO]: Epoch 010 - training loss: 0.3323, validation loss: 0.3078
2024-05-24 10:26:44 [INFO]: Epoch 011 - training loss: 0.3115, validation loss: 0.3063
2024-05-24 10:26:45 [INFO]: Epoch 012 - training loss: 0.3402, validation loss: 0.3497
2024-05-24 10:26:46 [INFO]: Epoch 013 - training loss: 0.3007, validation loss: 0.3131
2024-05-24 10:26:47 [INFO]: Epoch 014 - training loss: 0.3113, validation loss: 0.3060
2024-05-24 10:26:48 [INFO]: Epoch 015 - training loss: 0.3256, validation loss: 0.3023
2024-05-24 10:26:48 [INFO]: Epoch 016 - training loss: 0.3058, validation loss: 0.3005
2024-05-24 10:26:49 [INFO]: Epoch 017 - training loss: 0.3139, validation loss: 0.3414
2024-05-24 10:26:50 [INFO]: Epoch 018 - training loss: 0.3148, validation loss: 0.3099
2024-05-24 10:26:51 [INFO]: Epoch 019 - training loss: 0.2968, validation loss: 0.3031
2024-05-24 10:26:52 [INFO]: Epoch 020 - training loss: 0.3249, validation loss: 0.3140
2024-05-24 10:26:52 [INFO]: Epoch 021 - training loss: 0.3207, validation loss: 0.2995
2024-05-24 10:26:53 [INFO]: Epoch 022 - training loss: 0.3099, validation loss: 0.3076
2024-05-24 10:26:54 [INFO]: Epoch 023 - training loss: 0.3333, validation loss: 0.2990
2024-05-24 10:26:55 [INFO]: Epoch 024 - training loss: 0.3225, validation loss: 0.2878
2024-05-24 10:26:56 [INFO]: Epoch 025 - training loss: 0.3264, validation loss: 0.3519
2024-05-24 10:26:56 [INFO]: Epoch 026 - training loss: 0.2940, validation loss: 0.2962
2024-05-24 10:26:57 [INFO]: Epoch 027 - training loss: 0.3026, validation loss: 0.2901
2024-05-24 10:26:58 [INFO]: Epoch 028 - training loss: 0.3051, validation loss: 0.2858
2024-05-24 10:26:59 [INFO]: Epoch 029 - training loss: 0.3243, validation loss: 0.2845
2024-05-24 10:27:00 [INFO]: Epoch 030 - training loss: 0.2786, validation loss: 0.2811
2024-05-24 10:27:00 [INFO]: Epoch 031 - training loss: 0.2895, validation loss: 0.2849
2024-05-24 10:27:01 [INFO]: Epoch 032 - training loss: 0.3390, validation loss: 0.3080
2024-05-24 10:27:02 [INFO]: Epoch 033 - training loss: 0.2916, validation loss: 0.3032
2024-05-24 10:27:03 [INFO]: Epoch 034 - training loss: 0.3009, validation loss: 0.4072
2024-05-24 10:27:04 [INFO]: Epoch 035 - training loss: 0.3003, validation loss: 0.3039
2024-05-24 10:27:04 [INFO]: Epoch 036 - training loss: 0.2598, validation loss: 0.2997
2024-05-24 10:27:05 [INFO]: Epoch 037 - training loss: 0.3140, validation loss: 0.2990
2024-05-24 10:27:06 [INFO]: Epoch 038 - training loss: 0.3784, validation loss: 0.2961
2024-05-24 10:27:07 [INFO]: Epoch 039 - training loss: 0.3679, validation loss: 0.2956
2024-05-24 10:27:08 [INFO]: Epoch 040 - training loss: 0.2757, validation loss: 0.2940
2024-05-24 10:27:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:27:08 [INFO]: Finished training. The best model is from epoch#30.
2024-05-24 10:27:08 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T102635/TimesNet.pypots
2024-05-24 10:27:08 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2764, MSE=0.3117
2024-05-24 10:27:08 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-24 10:27:08 [INFO]: Using the given device: cuda:0
2024-05-24 10:27:08 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708
2024-05-24 10:27:08 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/tensorboard
2024-05-24 10:27:08 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-24 10:27:52 [INFO]: Epoch 001 - training loss: 0.4140, validation loss: 0.3395
2024-05-24 10:27:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch1_loss0.3394532114267349.pypots
2024-05-24 10:28:35 [INFO]: Epoch 002 - training loss: 0.3209, validation loss: 0.2824
2024-05-24 10:28:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch2_loss0.28244254887104037.pypots
2024-05-24 10:29:19 [INFO]: Epoch 003 - training loss: 0.2875, validation loss: 0.2473
2024-05-24 10:29:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch3_loss0.24732314199209213.pypots
2024-05-24 10:30:02 [INFO]: Epoch 004 - training loss: 0.2738, validation loss: 0.2337
2024-05-24 10:30:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch4_loss0.23365495279431342.pypots
2024-05-24 10:30:45 [INFO]: Epoch 005 - training loss: 0.2636, validation loss: 0.2193
2024-05-24 10:30:45 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch5_loss0.219257003813982.pypots
2024-05-24 10:31:29 [INFO]: Epoch 006 - training loss: 0.2521, validation loss: 0.2160
2024-05-24 10:31:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch6_loss0.21602951884269714.pypots
2024-05-24 10:32:12 [INFO]: Epoch 007 - training loss: 0.2512, validation loss: 0.2094
2024-05-24 10:32:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch7_loss0.2093802124261856.pypots
2024-05-24 10:32:56 [INFO]: Epoch 008 - training loss: 0.2453, validation loss: 0.2061
2024-05-24 10:32:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch8_loss0.20613061115145684.pypots
2024-05-24 10:33:39 [INFO]: Epoch 009 - training loss: 0.2247, validation loss: 0.2042
2024-05-24 10:33:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch9_loss0.20416019186377526.pypots
2024-05-24 10:34:23 [INFO]: Epoch 010 - training loss: 0.2392, validation loss: 0.2023
2024-05-24 10:34:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch10_loss0.20229650437831878.pypots
2024-05-24 10:35:07 [INFO]: Epoch 011 - training loss: 0.2310, validation loss: 0.2025
2024-05-24 10:35:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch11_loss0.20246649980545045.pypots
2024-05-24 10:35:51 [INFO]: Epoch 012 - training loss: 0.2466, validation loss: 0.2063
2024-05-24 10:35:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch12_loss0.20630923360586167.pypots
2024-05-24 10:36:36 [INFO]: Epoch 013 - training loss: 0.2339, validation loss: 0.1972
2024-05-24 10:36:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch13_loss0.19723614826798438.pypots
2024-05-24 10:37:20 [INFO]: Epoch 014 - training loss: 0.2433, validation loss: 0.1963
2024-05-24 10:37:20 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch14_loss0.1962801955640316.pypots
2024-05-24 10:38:04 [INFO]: Epoch 015 - training loss: 0.2352, validation loss: 0.1956
2024-05-24 10:38:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch15_loss0.1955994874238968.pypots
2024-05-24 10:38:48 [INFO]: Epoch 016 - training loss: 0.2450, validation loss: 0.1945
2024-05-24 10:38:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch16_loss0.19445550665259362.pypots
2024-05-24 10:39:32 [INFO]: Epoch 017 - training loss: 0.2351, validation loss: 0.1954
2024-05-24 10:39:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch17_loss0.19535789340734483.pypots
2024-05-24 10:40:15 [INFO]: Epoch 018 - training loss: 0.2277, validation loss: 0.1933
2024-05-24 10:40:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch18_loss0.1933483935892582.pypots
2024-05-24 10:40:59 [INFO]: Epoch 019 - training loss: 0.2349, validation loss: 0.1917
2024-05-24 10:40:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch19_loss0.19170240834355354.pypots
2024-05-24 10:41:42 [INFO]: Epoch 020 - training loss: 0.2298, validation loss: 0.1925
2024-05-24 10:41:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch20_loss0.19250474795699118.pypots
2024-05-24 10:42:26 [INFO]: Epoch 021 - training loss: 0.2269, validation loss: 0.1889
2024-05-24 10:42:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch21_loss0.18887767493724822.pypots
2024-05-24 10:43:09 [INFO]: Epoch 022 - training loss: 0.2295, validation loss: 0.1907
2024-05-24 10:43:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch22_loss0.19073872566223143.pypots
2024-05-24 10:43:53 [INFO]: Epoch 023 - training loss: 0.2220, validation loss: 0.1897
2024-05-24 10:43:53 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch23_loss0.1897383838891983.pypots
2024-05-24 10:44:37 [INFO]: Epoch 024 - training loss: 0.2274, validation loss: 0.1893
2024-05-24 10:44:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch24_loss0.1892659291625023.pypots
2024-05-24 10:45:22 [INFO]: Epoch 025 - training loss: 0.2312, validation loss: 0.1888
2024-05-24 10:45:22 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch25_loss0.1888158969581127.pypots
2024-05-24 10:46:06 [INFO]: Epoch 026 - training loss: 0.2207, validation loss: 0.1882
2024-05-24 10:46:06 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch26_loss0.1881872221827507.pypots
2024-05-24 10:46:50 [INFO]: Epoch 027 - training loss: 0.2345, validation loss: 0.1876
2024-05-24 10:46:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch27_loss0.18758516758680344.pypots
2024-05-24 10:47:34 [INFO]: Epoch 028 - training loss: 0.2276, validation loss: 0.1873
2024-05-24 10:47:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch28_loss0.18725112229585647.pypots
2024-05-24 10:48:18 [INFO]: Epoch 029 - training loss: 0.2160, validation loss: 0.1850
2024-05-24 10:48:18 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch29_loss0.1850203052163124.pypots
2024-05-24 10:49:02 [INFO]: Epoch 030 - training loss: 0.2348, validation loss: 0.1851
2024-05-24 10:49:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch30_loss0.18509167954325675.pypots
2024-05-24 10:49:46 [INFO]: Epoch 031 - training loss: 0.2238, validation loss: 0.1846
2024-05-24 10:49:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch31_loss0.1846208542585373.pypots
2024-05-24 10:50:29 [INFO]: Epoch 032 - training loss: 0.2237, validation loss: 0.1858
2024-05-24 10:50:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch32_loss0.18582110852003098.pypots
2024-05-24 10:51:13 [INFO]: Epoch 033 - training loss: 0.2260, validation loss: 0.1843
2024-05-24 10:51:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch33_loss0.18431079685688018.pypots
2024-05-24 10:51:56 [INFO]: Epoch 034 - training loss: 0.2158, validation loss: 0.1871
2024-05-24 10:51:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch34_loss0.18709165304899217.pypots
2024-05-24 10:52:40 [INFO]: Epoch 035 - training loss: 0.2208, validation loss: 0.1854
2024-05-24 10:52:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch35_loss0.1854260228574276.pypots
2024-05-24 10:53:24 [INFO]: Epoch 036 - training loss: 0.2256, validation loss: 0.1859
2024-05-24 10:53:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch36_loss0.1859254077076912.pypots
2024-05-24 10:54:08 [INFO]: Epoch 037 - training loss: 0.2192, validation loss: 0.1837
2024-05-24 10:54:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch37_loss0.18366743475198746.pypots
2024-05-24 10:54:52 [INFO]: Epoch 038 - training loss: 0.2270, validation loss: 0.1829
2024-05-24 10:54:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch38_loss0.1828566588461399.pypots
2024-05-24 10:55:37 [INFO]: Epoch 039 - training loss: 0.2190, validation loss: 0.1832
2024-05-24 10:55:37 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch39_loss0.18315951228141786.pypots
2024-05-24 10:56:21 [INFO]: Epoch 040 - training loss: 0.2156, validation loss: 0.1814
2024-05-24 10:56:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch40_loss0.1814490705728531.pypots
2024-05-24 10:57:05 [INFO]: Epoch 041 - training loss: 0.2123, validation loss: 0.1817
2024-05-24 10:57:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch41_loss0.1816675692796707.pypots
2024-05-24 10:57:49 [INFO]: Epoch 042 - training loss: 0.2313, validation loss: 0.1840
2024-05-24 10:57:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch42_loss0.18404534384608268.pypots
2024-05-24 10:58:32 [INFO]: Epoch 043 - training loss: 0.2167, validation loss: 0.1828
2024-05-24 10:58:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch43_loss0.1828270971775055.pypots
2024-05-24 10:59:16 [INFO]: Epoch 044 - training loss: 0.2246, validation loss: 0.1817
2024-05-24 10:59:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch44_loss0.1817110411822796.pypots
2024-05-24 10:59:59 [INFO]: Epoch 045 - training loss: 0.2316, validation loss: 0.1812
2024-05-24 10:59:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch45_loss0.18119172379374504.pypots
2024-05-24 11:00:42 [INFO]: Epoch 046 - training loss: 0.2220, validation loss: 0.1804
2024-05-24 11:00:43 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch46_loss0.1803988881409168.pypots
2024-05-24 11:01:26 [INFO]: Epoch 047 - training loss: 0.2194, validation loss: 0.1807
2024-05-24 11:01:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch47_loss0.1807186208665371.pypots
2024-05-24 11:02:10 [INFO]: Epoch 048 - training loss: 0.2228, validation loss: 0.1803
2024-05-24 11:02:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch48_loss0.18031391650438308.pypots
2024-05-24 11:02:55 [INFO]: Epoch 049 - training loss: 0.2220, validation loss: 0.1795
2024-05-24 11:02:55 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch49_loss0.1794921912252903.pypots
2024-05-24 11:03:39 [INFO]: Epoch 050 - training loss: 0.2164, validation loss: 0.1780
2024-05-24 11:03:39 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch50_loss0.17796415686607361.pypots
2024-05-24 11:04:23 [INFO]: Epoch 051 - training loss: 0.2188, validation loss: 0.1861
2024-05-24 11:04:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch51_loss0.18611509576439858.pypots
2024-05-24 11:05:07 [INFO]: Epoch 052 - training loss: 0.2171, validation loss: 0.1791
2024-05-24 11:05:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch52_loss0.1791354462504387.pypots
2024-05-24 11:05:51 [INFO]: Epoch 053 - training loss: 0.2203, validation loss: 0.1792
2024-05-24 11:05:51 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch53_loss0.17915267944335939.pypots
2024-05-24 11:06:35 [INFO]: Epoch 054 - training loss: 0.2126, validation loss: 0.1793
2024-05-24 11:06:35 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch54_loss0.17931838929653168.pypots
2024-05-24 11:07:19 [INFO]: Epoch 055 - training loss: 0.2300, validation loss: 0.1822
2024-05-24 11:07:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch55_loss0.18224970251321793.pypots
2024-05-24 11:08:03 [INFO]: Epoch 056 - training loss: 0.2122, validation loss: 0.1788
2024-05-24 11:08:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch56_loss0.17876664847135543.pypots
2024-05-24 11:08:48 [INFO]: Epoch 057 - training loss: 0.2175, validation loss: 0.1775
2024-05-24 11:08:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch57_loss0.177544766664505.pypots
2024-05-24 11:09:32 [INFO]: Epoch 058 - training loss: 0.2154, validation loss: 0.1791
2024-05-24 11:09:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch58_loss0.17910379096865653.pypots
2024-05-24 11:10:16 [INFO]: Epoch 059 - training loss: 0.2256, validation loss: 0.1788
2024-05-24 11:10:16 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch59_loss0.17875670045614242.pypots
2024-05-24 11:11:00 [INFO]: Epoch 060 - training loss: 0.2193, validation loss: 0.1772
2024-05-24 11:11:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch60_loss0.1772260084748268.pypots
2024-05-24 11:11:44 [INFO]: Epoch 061 - training loss: 0.2262, validation loss: 0.1770
2024-05-24 11:11:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch61_loss0.17697996273636818.pypots
2024-05-24 11:12:28 [INFO]: Epoch 062 - training loss: 0.2125, validation loss: 0.1786
2024-05-24 11:12:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch62_loss0.1785560704767704.pypots
2024-05-24 11:13:12 [INFO]: Epoch 063 - training loss: 0.2254, validation loss: 0.1757
2024-05-24 11:13:12 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch63_loss0.17574747279286385.pypots
2024-05-24 11:13:56 [INFO]: Epoch 064 - training loss: 0.2159, validation loss: 0.1761
2024-05-24 11:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch64_loss0.17611797526478767.pypots
2024-05-24 11:14:40 [INFO]: Epoch 065 - training loss: 0.2206, validation loss: 0.1771
2024-05-24 11:14:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch65_loss0.17713162526488305.pypots
2024-05-24 11:15:24 [INFO]: Epoch 066 - training loss: 0.2146, validation loss: 0.1769
2024-05-24 11:15:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch66_loss0.17688170447945595.pypots
2024-05-24 11:16:08 [INFO]: Epoch 067 - training loss: 0.2212, validation loss: 0.1776
2024-05-24 11:16:08 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch67_loss0.17763976901769638.pypots
2024-05-24 11:16:52 [INFO]: Epoch 068 - training loss: 0.2271, validation loss: 0.1766
2024-05-24 11:16:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch68_loss0.17664656192064285.pypots
2024-05-24 11:17:36 [INFO]: Epoch 069 - training loss: 0.2162, validation loss: 0.1762
2024-05-24 11:17:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch69_loss0.17615826055407524.pypots
2024-05-24 11:18:21 [INFO]: Epoch 070 - training loss: 0.2231, validation loss: 0.1786
2024-05-24 11:18:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch70_loss0.17859582155942916.pypots
2024-05-24 11:19:05 [INFO]: Epoch 071 - training loss: 0.2263, validation loss: 0.1778
2024-05-24 11:19:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch71_loss0.1777629904448986.pypots
2024-05-24 11:19:49 [INFO]: Epoch 072 - training loss: 0.2132, validation loss: 0.1761
2024-05-24 11:19:49 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch72_loss0.1760966010391712.pypots
2024-05-24 11:20:33 [INFO]: Epoch 073 - training loss: 0.2116, validation loss: 0.1769
2024-05-24 11:20:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI_epoch73_loss0.17694249674677848.pypots
2024-05-24 11:20:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 11:20:33 [INFO]: Finished training. The best model is from epoch#63.
2024-05-24 11:20:33 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T102708/CSDI.pypots
2024-05-24 11:27:56 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2439, MSE=0.4240
2024-05-24 11:57:26 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 11:57:26 [INFO]: Using the given device: cuda:0
2024-05-24 11:57:26 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T115726
2024-05-24 11:57:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T115726/tensorboard
2024-05-24 11:57:26 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 11:57:26 [INFO]: Epoch 001 - training loss: 42282.0030, validation loss: 0.9239
2024-05-24 11:57:27 [INFO]: Epoch 002 - training loss: 24368.0438, validation loss: 0.7549
2024-05-24 11:57:27 [INFO]: Epoch 003 - training loss: 23500.3588, validation loss: 0.7160
2024-05-24 11:57:28 [INFO]: Epoch 004 - training loss: 23216.1549, validation loss: 0.6990
2024-05-24 11:57:28 [INFO]: Epoch 005 - training loss: 23078.3736, validation loss: 0.6819
2024-05-24 11:57:29 [INFO]: Epoch 006 - training loss: 23001.0814, validation loss: 0.6791
2024-05-24 11:57:29 [INFO]: Epoch 007 - training loss: 22952.8562, validation loss: 0.6788
2024-05-24 11:57:30 [INFO]: Epoch 008 - training loss: 22921.8226, validation loss: 0.6773
2024-05-24 11:57:31 [INFO]: Epoch 009 - training loss: 22900.5300, validation loss: 0.6742
2024-05-24 11:57:31 [INFO]: Epoch 010 - training loss: 22885.2492, validation loss: 0.6818
2024-05-24 11:57:32 [INFO]: Epoch 011 - training loss: 22874.0511, validation loss: 0.6707
2024-05-24 11:57:32 [INFO]: Epoch 012 - training loss: 22865.3897, validation loss: 0.6689
2024-05-24 11:57:33 [INFO]: Epoch 013 - training loss: 22859.3791, validation loss: 0.6699
2024-05-24 11:57:33 [INFO]: Epoch 014 - training loss: 22854.7262, validation loss: 0.6657
2024-05-24 11:57:34 [INFO]: Epoch 015 - training loss: 22850.0265, validation loss: 0.6570
2024-05-24 11:57:34 [INFO]: Epoch 016 - training loss: 22846.4455, validation loss: 0.6559
2024-05-24 11:57:35 [INFO]: Epoch 017 - training loss: 22843.5468, validation loss: 0.6619
2024-05-24 11:57:36 [INFO]: Epoch 018 - training loss: 22840.6838, validation loss: 0.6531
2024-05-24 11:57:36 [INFO]: Epoch 019 - training loss: 22838.1524, validation loss: 0.6449
2024-05-24 11:57:37 [INFO]: Epoch 020 - training loss: 22836.8394, validation loss: 0.6558
2024-05-24 11:57:37 [INFO]: Epoch 021 - training loss: 22835.8008, validation loss: 0.6454
2024-05-24 11:57:38 [INFO]: Epoch 022 - training loss: 22834.2773, validation loss: 0.6408
2024-05-24 11:57:38 [INFO]: Epoch 023 - training loss: 22833.1129, validation loss: 0.6411
2024-05-24 11:57:39 [INFO]: Epoch 024 - training loss: 22832.6040, validation loss: 0.6418
2024-05-24 11:57:39 [INFO]: Epoch 025 - training loss: 22830.8423, validation loss: 0.6362
2024-05-24 11:57:40 [INFO]: Epoch 026 - training loss: 22829.9547, validation loss: 0.6365
2024-05-24 11:57:41 [INFO]: Epoch 027 - training loss: 22829.2506, validation loss: 0.6362
2024-05-24 11:57:41 [INFO]: Epoch 028 - training loss: 22828.2976, validation loss: 0.6340
2024-05-24 11:57:42 [INFO]: Epoch 029 - training loss: 22827.6666, validation loss: 0.6425
2024-05-24 11:57:42 [INFO]: Epoch 030 - training loss: 22827.7380, validation loss: 0.6311
2024-05-24 11:57:43 [INFO]: Epoch 031 - training loss: 22826.7788, validation loss: 0.6256
2024-05-24 11:57:43 [INFO]: Epoch 032 - training loss: 22826.2002, validation loss: 0.6226
2024-05-24 11:57:44 [INFO]: Epoch 033 - training loss: 22825.7310, validation loss: 0.6193
2024-05-24 11:57:44 [INFO]: Epoch 034 - training loss: 22824.2670, validation loss: 0.6181
2024-05-24 11:57:45 [INFO]: Epoch 035 - training loss: 22823.3167, validation loss: 0.6189
2024-05-24 11:57:46 [INFO]: Epoch 036 - training loss: 22822.6614, validation loss: 0.6132
2024-05-24 11:57:46 [INFO]: Epoch 037 - training loss: 22820.3766, validation loss: 0.6049
2024-05-24 11:57:47 [INFO]: Epoch 038 - training loss: 22818.6493, validation loss: 0.5972
2024-05-24 11:57:47 [INFO]: Epoch 039 - training loss: 22817.7606, validation loss: 0.5968
2024-05-24 11:57:48 [INFO]: Epoch 040 - training loss: 22816.3276, validation loss: 0.5917
2024-05-24 11:57:48 [INFO]: Epoch 041 - training loss: 22816.6033, validation loss: 0.5896
2024-05-24 11:57:49 [INFO]: Epoch 042 - training loss: 22815.2990, validation loss: 0.5864
2024-05-24 11:57:49 [INFO]: Epoch 043 - training loss: 22813.9795, validation loss: 0.5746
2024-05-24 11:57:50 [INFO]: Epoch 044 - training loss: 22811.9781, validation loss: 0.5731
2024-05-24 11:57:51 [INFO]: Epoch 045 - training loss: 22810.3406, validation loss: 0.5667
2024-05-24 11:57:51 [INFO]: Epoch 046 - training loss: 22809.5999, validation loss: 0.5604
2024-05-24 11:57:52 [INFO]: Epoch 047 - training loss: 22808.3204, validation loss: 0.5614
2024-05-24 11:57:52 [INFO]: Epoch 048 - training loss: 22807.8144, validation loss: 0.5576
2024-05-24 11:57:53 [INFO]: Epoch 049 - training loss: 22807.5779, validation loss: 0.5586
2024-05-24 11:57:53 [INFO]: Epoch 050 - training loss: 22806.0233, validation loss: 0.5592
2024-05-24 11:57:54 [INFO]: Epoch 051 - training loss: 22804.9403, validation loss: 0.5543
2024-05-24 11:57:54 [INFO]: Epoch 052 - training loss: 22804.4861, validation loss: 0.5535
2024-05-24 11:57:55 [INFO]: Epoch 053 - training loss: 22803.6978, validation loss: 0.5450
2024-05-24 11:57:55 [INFO]: Epoch 054 - training loss: 22803.1141, validation loss: 0.5399
2024-05-24 11:57:56 [INFO]: Epoch 055 - training loss: 22802.4367, validation loss: 0.5373
2024-05-24 11:57:57 [INFO]: Epoch 056 - training loss: 22802.4802, validation loss: 0.5339
2024-05-24 11:57:57 [INFO]: Epoch 057 - training loss: 22801.3769, validation loss: 0.5283
2024-05-24 11:57:58 [INFO]: Epoch 058 - training loss: 22801.4895, validation loss: 0.5305
2024-05-24 11:57:58 [INFO]: Epoch 059 - training loss: 22801.1068, validation loss: 0.5248
2024-05-24 11:57:59 [INFO]: Epoch 060 - training loss: 22800.2805, validation loss: 0.5266
2024-05-24 11:57:59 [INFO]: Epoch 061 - training loss: 22800.4044, validation loss: 0.5259
2024-05-24 11:58:00 [INFO]: Epoch 062 - training loss: 22800.4391, validation loss: 0.5255
2024-05-24 11:58:00 [INFO]: Epoch 063 - training loss: 22798.1300, validation loss: 0.5220
2024-05-24 11:58:01 [INFO]: Epoch 064 - training loss: 22797.6974, validation loss: 0.5229
2024-05-24 11:58:02 [INFO]: Epoch 065 - training loss: 22798.1155, validation loss: 0.5226
2024-05-24 11:58:02 [INFO]: Epoch 066 - training loss: 22797.0283, validation loss: 0.5165
2024-05-24 11:58:03 [INFO]: Epoch 067 - training loss: 22796.5450, validation loss: 0.5138
2024-05-24 11:58:03 [INFO]: Epoch 068 - training loss: 22797.4861, validation loss: 0.5260
2024-05-24 11:58:04 [INFO]: Epoch 069 - training loss: 22796.3874, validation loss: 0.5154
2024-05-24 11:58:04 [INFO]: Epoch 070 - training loss: 22797.1316, validation loss: 0.5184
2024-05-24 11:58:05 [INFO]: Epoch 071 - training loss: 22795.9248, validation loss: 0.5109
2024-05-24 11:58:05 [INFO]: Epoch 072 - training loss: 22796.8598, validation loss: 0.5144
2024-05-24 11:58:06 [INFO]: Epoch 073 - training loss: 22795.0494, validation loss: 0.5157
2024-05-24 11:58:07 [INFO]: Epoch 074 - training loss: 22794.9232, validation loss: 0.5151
2024-05-24 11:58:07 [INFO]: Epoch 075 - training loss: 22794.1016, validation loss: 0.5210
2024-05-24 11:58:08 [INFO]: Epoch 076 - training loss: 22794.3069, validation loss: 0.5098
2024-05-24 11:58:08 [INFO]: Epoch 077 - training loss: 22794.2273, validation loss: 0.5121
2024-05-24 11:58:09 [INFO]: Epoch 078 - training loss: 22793.7315, validation loss: 0.5200
2024-05-24 11:58:09 [INFO]: Epoch 079 - training loss: 22793.5337, validation loss: 0.5130
2024-05-24 11:58:10 [INFO]: Epoch 080 - training loss: 22793.2695, validation loss: 0.5148
2024-05-24 11:58:10 [INFO]: Epoch 081 - training loss: 22793.5190, validation loss: 0.5145
2024-05-24 11:58:11 [INFO]: Epoch 082 - training loss: 22793.6737, validation loss: 0.5176
2024-05-24 11:58:12 [INFO]: Epoch 083 - training loss: 22794.9181, validation loss: 0.5129
2024-05-24 11:58:12 [INFO]: Epoch 084 - training loss: 22794.5394, validation loss: 0.5271
2024-05-24 11:58:13 [INFO]: Epoch 085 - training loss: 22797.3192, validation loss: 0.5106
2024-05-24 11:58:13 [INFO]: Epoch 086 - training loss: 22792.8865, validation loss: 0.5180
2024-05-24 11:58:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 11:58:13 [INFO]: Finished training. The best model is from epoch#76.
2024-05-24 11:58:13 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T115726/GPVAE.pypots
2024-05-24 11:58:13 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4445, MSE=0.5387
2024-05-24 11:58:14 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 11:58:14 [INFO]: Using the given device: cuda:0
2024-05-24 11:58:14 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T115814
2024-05-24 11:58:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T115814/tensorboard
2024-05-24 11:58:14 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 11:58:35 [INFO]: Epoch 001 - generator training loss: 0.5942, discriminator training loss: 0.3812, validation loss: 0.6403
2024-05-24 11:58:53 [INFO]: Epoch 002 - generator training loss: 0.4675, discriminator training loss: 0.2588, validation loss: 0.5379
2024-05-24 11:59:12 [INFO]: Epoch 003 - generator training loss: 0.4401, discriminator training loss: 0.2066, validation loss: 0.5258
2024-05-24 11:59:30 [INFO]: Epoch 004 - generator training loss: 0.4517, discriminator training loss: 0.1535, validation loss: 0.5101
2024-05-24 11:59:48 [INFO]: Epoch 005 - generator training loss: 0.4457, discriminator training loss: 0.1238, validation loss: 0.4910
2024-05-24 12:00:07 [INFO]: Epoch 006 - generator training loss: 0.4368, discriminator training loss: 0.1045, validation loss: 0.4807
2024-05-24 12:00:25 [INFO]: Epoch 007 - generator training loss: 0.4245, discriminator training loss: 0.0904, validation loss: 0.4688
2024-05-24 12:00:44 [INFO]: Epoch 008 - generator training loss: 0.4122, discriminator training loss: 0.0806, validation loss: 0.4572
2024-05-24 12:01:02 [INFO]: Epoch 009 - generator training loss: 0.4065, discriminator training loss: 0.0726, validation loss: 0.4449
2024-05-24 12:01:20 [INFO]: Epoch 010 - generator training loss: 0.3964, discriminator training loss: 0.0663, validation loss: 0.4412
2024-05-24 12:01:38 [INFO]: Epoch 011 - generator training loss: 0.3890, discriminator training loss: 0.0609, validation loss: 0.4287
2024-05-24 12:01:57 [INFO]: Epoch 012 - generator training loss: 0.3829, discriminator training loss: 0.0564, validation loss: 0.4218
2024-05-24 12:02:15 [INFO]: Epoch 013 - generator training loss: 0.3765, discriminator training loss: 0.0523, validation loss: 0.4177
2024-05-24 12:02:34 [INFO]: Epoch 014 - generator training loss: 0.3706, discriminator training loss: 0.0490, validation loss: 0.4092
2024-05-24 12:02:52 [INFO]: Epoch 015 - generator training loss: 0.3656, discriminator training loss: 0.0462, validation loss: 0.4012
2024-05-24 12:03:10 [INFO]: Epoch 016 - generator training loss: 0.3607, discriminator training loss: 0.0437, validation loss: 0.3977
2024-05-24 12:03:29 [INFO]: Epoch 017 - generator training loss: 0.3538, discriminator training loss: 0.0416, validation loss: 0.3932
2024-05-24 12:03:47 [INFO]: Epoch 018 - generator training loss: 0.3478, discriminator training loss: 0.0400, validation loss: 0.3882
2024-05-24 12:04:05 [INFO]: Epoch 019 - generator training loss: 0.3411, discriminator training loss: 0.0383, validation loss: 0.3827
2024-05-24 12:04:24 [INFO]: Epoch 020 - generator training loss: 0.3375, discriminator training loss: 0.0369, validation loss: 0.3786
2024-05-24 12:04:42 [INFO]: Epoch 021 - generator training loss: 0.3330, discriminator training loss: 0.0358, validation loss: 0.3717
2024-05-24 12:05:00 [INFO]: Epoch 022 - generator training loss: 0.3286, discriminator training loss: 0.0349, validation loss: 0.3682
2024-05-24 12:05:19 [INFO]: Epoch 023 - generator training loss: 0.3246, discriminator training loss: 0.0340, validation loss: 0.3655
2024-05-24 12:05:37 [INFO]: Epoch 024 - generator training loss: 0.3183, discriminator training loss: 0.0330, validation loss: 0.3623
2024-05-24 12:05:55 [INFO]: Epoch 025 - generator training loss: 0.3133, discriminator training loss: 0.0323, validation loss: 0.3579
2024-05-24 12:06:14 [INFO]: Epoch 026 - generator training loss: 0.3083, discriminator training loss: 0.0317, validation loss: 0.3551
2024-05-24 12:06:32 [INFO]: Epoch 027 - generator training loss: 0.3050, discriminator training loss: 0.0308, validation loss: 0.3567
2024-05-24 12:06:50 [INFO]: Epoch 028 - generator training loss: 0.3057, discriminator training loss: 0.0303, validation loss: 0.3531
2024-05-24 12:07:09 [INFO]: Epoch 029 - generator training loss: 0.2995, discriminator training loss: 0.0299, validation loss: 0.3499
2024-05-24 12:07:27 [INFO]: Epoch 030 - generator training loss: 0.3014, discriminator training loss: 0.0294, validation loss: 0.3511
2024-05-24 12:07:45 [INFO]: Epoch 031 - generator training loss: 0.2942, discriminator training loss: 0.0290, validation loss: 0.3457
2024-05-24 12:08:04 [INFO]: Epoch 032 - generator training loss: 0.2894, discriminator training loss: 0.0285, validation loss: 0.3411
2024-05-24 12:08:22 [INFO]: Epoch 033 - generator training loss: 0.2843, discriminator training loss: 0.0280, validation loss: 0.3413
2024-05-24 12:08:40 [INFO]: Epoch 034 - generator training loss: 0.2851, discriminator training loss: 0.0279, validation loss: 0.3461
2024-05-24 12:08:59 [INFO]: Epoch 035 - generator training loss: 0.2843, discriminator training loss: 0.0276, validation loss: 0.3399
2024-05-24 12:09:17 [INFO]: Epoch 036 - generator training loss: 0.2790, discriminator training loss: 0.0271, validation loss: 0.3364
2024-05-24 12:09:35 [INFO]: Epoch 037 - generator training loss: 0.2738, discriminator training loss: 0.0268, validation loss: 0.3315
2024-05-24 12:09:54 [INFO]: Epoch 038 - generator training loss: 0.2674, discriminator training loss: 0.0266, validation loss: 0.3304
2024-05-24 12:10:12 [INFO]: Epoch 039 - generator training loss: 0.2660, discriminator training loss: 0.0264, validation loss: 0.3302
2024-05-24 12:10:30 [INFO]: Epoch 040 - generator training loss: 0.2630, discriminator training loss: 0.0260, validation loss: 0.3323
2024-05-24 12:10:49 [INFO]: Epoch 041 - generator training loss: 0.2736, discriminator training loss: 0.0259, validation loss: 0.3364
2024-05-24 12:11:07 [INFO]: Epoch 042 - generator training loss: 0.2691, discriminator training loss: 0.0256, validation loss: 0.3296
2024-05-24 12:11:25 [INFO]: Epoch 043 - generator training loss: 0.2607, discriminator training loss: 0.0253, validation loss: 0.3276
2024-05-24 12:11:44 [INFO]: Epoch 044 - generator training loss: 0.2568, discriminator training loss: 0.0251, validation loss: 0.3234
2024-05-24 12:12:02 [INFO]: Epoch 045 - generator training loss: 0.2551, discriminator training loss: 0.0248, validation loss: 0.3236
2024-05-24 12:12:20 [INFO]: Epoch 046 - generator training loss: 0.2522, discriminator training loss: 0.0247, validation loss: 0.3300
2024-05-24 12:12:39 [INFO]: Epoch 047 - generator training loss: 0.2489, discriminator training loss: 0.0245, validation loss: 0.3220
2024-05-24 12:12:57 [INFO]: Epoch 048 - generator training loss: 0.2412, discriminator training loss: 0.0244, validation loss: 0.3207
2024-05-24 12:13:15 [INFO]: Epoch 049 - generator training loss: 0.2400, discriminator training loss: 0.0241, validation loss: 0.3191
2024-05-24 12:13:34 [INFO]: Epoch 050 - generator training loss: 0.2400, discriminator training loss: 0.0240, validation loss: 0.3213
2024-05-24 12:13:52 [INFO]: Epoch 051 - generator training loss: 0.2378, discriminator training loss: 0.0239, validation loss: 0.3236
2024-05-24 12:14:10 [INFO]: Epoch 052 - generator training loss: 0.2394, discriminator training loss: 0.0237, validation loss: 0.3188
2024-05-24 12:14:28 [INFO]: Epoch 053 - generator training loss: 0.2330, discriminator training loss: 0.0235, validation loss: 0.3160
2024-05-24 12:14:47 [INFO]: Epoch 054 - generator training loss: 0.2287, discriminator training loss: 0.0234, validation loss: 0.3146
2024-05-24 12:15:05 [INFO]: Epoch 055 - generator training loss: 0.2269, discriminator training loss: 0.0234, validation loss: 0.3141
2024-05-24 12:15:24 [INFO]: Epoch 056 - generator training loss: 0.2302, discriminator training loss: 0.0233, validation loss: 0.3176
2024-05-24 12:15:42 [INFO]: Epoch 057 - generator training loss: 0.2326, discriminator training loss: 0.0229, validation loss: 0.3175
2024-05-24 12:16:00 [INFO]: Epoch 058 - generator training loss: 0.2269, discriminator training loss: 0.0228, validation loss: 0.3148
2024-05-24 12:16:18 [INFO]: Epoch 059 - generator training loss: 0.2208, discriminator training loss: 0.0227, validation loss: 0.3139
2024-05-24 12:16:37 [INFO]: Epoch 060 - generator training loss: 0.2175, discriminator training loss: 0.0226, validation loss: 0.3117
2024-05-24 12:16:55 [INFO]: Epoch 061 - generator training loss: 0.2149, discriminator training loss: 0.0224, validation loss: 0.3184
2024-05-24 12:17:14 [INFO]: Epoch 062 - generator training loss: 0.2170, discriminator training loss: 0.0225, validation loss: 0.3131
2024-05-24 12:17:32 [INFO]: Epoch 063 - generator training loss: 0.2150, discriminator training loss: 0.0222, validation loss: 0.3123
2024-05-24 12:17:50 [INFO]: Epoch 064 - generator training loss: 0.2122, discriminator training loss: 0.0221, validation loss: 0.3100
2024-05-24 12:18:08 [INFO]: Epoch 065 - generator training loss: 0.2123, discriminator training loss: 0.0223, validation loss: 0.3122
2024-05-24 12:18:27 [INFO]: Epoch 066 - generator training loss: 0.2111, discriminator training loss: 0.0219, validation loss: 0.3119
2024-05-24 12:18:45 [INFO]: Epoch 067 - generator training loss: 0.2063, discriminator training loss: 0.0219, validation loss: 0.3118
2024-05-24 12:19:04 [INFO]: Epoch 068 - generator training loss: 0.2047, discriminator training loss: 0.0217, validation loss: 0.3118
2024-05-24 12:19:22 [INFO]: Epoch 069 - generator training loss: 0.2036, discriminator training loss: 0.0214, validation loss: 0.3106
2024-05-24 12:19:40 [INFO]: Epoch 070 - generator training loss: 0.2037, discriminator training loss: 0.0215, validation loss: 0.3106
2024-05-24 12:19:59 [INFO]: Epoch 071 - generator training loss: 0.2031, discriminator training loss: 0.0214, validation loss: 0.3128
2024-05-24 12:20:17 [INFO]: Epoch 072 - generator training loss: 0.2013, discriminator training loss: 0.0213, validation loss: 0.3097
2024-05-24 12:20:35 [INFO]: Epoch 073 - generator training loss: 0.1971, discriminator training loss: 0.0211, validation loss: 0.3115
2024-05-24 12:20:53 [INFO]: Epoch 074 - generator training loss: 0.1919, discriminator training loss: 0.0211, validation loss: 0.3111
2024-05-24 12:21:12 [INFO]: Epoch 075 - generator training loss: 0.1926, discriminator training loss: 0.0210, validation loss: 0.3113
2024-05-24 12:21:30 [INFO]: Epoch 076 - generator training loss: 0.1910, discriminator training loss: 0.0208, validation loss: 0.3121
2024-05-24 12:21:49 [INFO]: Epoch 077 - generator training loss: 0.1902, discriminator training loss: 0.0207, validation loss: 0.3124
2024-05-24 12:22:07 [INFO]: Epoch 078 - generator training loss: 0.1924, discriminator training loss: 0.0207, validation loss: 0.3154
2024-05-24 12:22:25 [INFO]: Epoch 079 - generator training loss: 0.1867, discriminator training loss: 0.0206, validation loss: 0.3145
2024-05-24 12:22:43 [INFO]: Epoch 080 - generator training loss: 0.1850, discriminator training loss: 0.0205, validation loss: 0.3124
2024-05-24 12:23:02 [INFO]: Epoch 081 - generator training loss: 0.1826, discriminator training loss: 0.0204, validation loss: 0.3122
2024-05-24 12:23:20 [INFO]: Epoch 082 - generator training loss: 0.1843, discriminator training loss: 0.0204, validation loss: 0.3108
2024-05-24 12:23:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 12:23:20 [INFO]: Finished training. The best model is from epoch#72.
2024-05-24 12:23:20 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T115814/USGAN.pypots
2024-05-24 12:23:23 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2941, MSE=0.3200
2024-05-24 12:23:32 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 12:23:32 [INFO]: Using the given device: cuda:0
2024-05-24 12:23:32 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T122332
2024-05-24 12:23:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T122332/tensorboard
2024-05-24 12:23:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 12:23:47 [INFO]: Epoch 001 - training loss: 1.1243, validation loss: 0.5505
2024-05-24 12:23:59 [INFO]: Epoch 002 - training loss: 0.9196, validation loss: 0.4906
2024-05-24 12:24:11 [INFO]: Epoch 003 - training loss: 0.8594, validation loss: 0.4655
2024-05-24 12:24:23 [INFO]: Epoch 004 - training loss: 0.8230, validation loss: 0.4428
2024-05-24 12:24:35 [INFO]: Epoch 005 - training loss: 0.7946, validation loss: 0.4275
2024-05-24 12:24:47 [INFO]: Epoch 006 - training loss: 0.7709, validation loss: 0.4110
2024-05-24 12:24:59 [INFO]: Epoch 007 - training loss: 0.7495, validation loss: 0.3991
2024-05-24 12:25:11 [INFO]: Epoch 008 - training loss: 0.7311, validation loss: 0.3867
2024-05-24 12:25:23 [INFO]: Epoch 009 - training loss: 0.7145, validation loss: 0.3791
2024-05-24 12:25:35 [INFO]: Epoch 010 - training loss: 0.7022, validation loss: 0.3724
2024-05-24 12:25:47 [INFO]: Epoch 011 - training loss: 0.6904, validation loss: 0.3681
2024-05-24 12:25:59 [INFO]: Epoch 012 - training loss: 0.6811, validation loss: 0.3623
2024-05-24 12:26:11 [INFO]: Epoch 013 - training loss: 0.6723, validation loss: 0.3582
2024-05-24 12:26:23 [INFO]: Epoch 014 - training loss: 0.6645, validation loss: 0.3546
2024-05-24 12:26:35 [INFO]: Epoch 015 - training loss: 0.6578, validation loss: 0.3524
2024-05-24 12:26:47 [INFO]: Epoch 016 - training loss: 0.6532, validation loss: 0.3492
2024-05-24 12:26:59 [INFO]: Epoch 017 - training loss: 0.6472, validation loss: 0.3482
2024-05-24 12:27:11 [INFO]: Epoch 018 - training loss: 0.6433, validation loss: 0.3452
2024-05-24 12:27:23 [INFO]: Epoch 019 - training loss: 0.6382, validation loss: 0.3429
2024-05-24 12:27:35 [INFO]: Epoch 020 - training loss: 0.6349, validation loss: 0.3425
2024-05-24 12:27:47 [INFO]: Epoch 021 - training loss: 0.6301, validation loss: 0.3401
2024-05-24 12:27:59 [INFO]: Epoch 022 - training loss: 0.6278, validation loss: 0.3393
2024-05-24 12:28:11 [INFO]: Epoch 023 - training loss: 0.6242, validation loss: 0.3392
2024-05-24 12:28:23 [INFO]: Epoch 024 - training loss: 0.6199, validation loss: 0.3370
2024-05-24 12:28:35 [INFO]: Epoch 025 - training loss: 0.6177, validation loss: 0.3351
2024-05-24 12:28:47 [INFO]: Epoch 026 - training loss: 0.6133, validation loss: 0.3340
2024-05-24 12:28:59 [INFO]: Epoch 027 - training loss: 0.6110, validation loss: 0.3322
2024-05-24 12:29:11 [INFO]: Epoch 028 - training loss: 0.6079, validation loss: 0.3336
2024-05-24 12:29:23 [INFO]: Epoch 029 - training loss: 0.6064, validation loss: 0.3339
2024-05-24 12:29:35 [INFO]: Epoch 030 - training loss: 0.6046, validation loss: 0.3314
2024-05-24 12:29:48 [INFO]: Epoch 031 - training loss: 0.5991, validation loss: 0.3300
2024-05-24 12:30:00 [INFO]: Epoch 032 - training loss: 0.5963, validation loss: 0.3292
2024-05-24 12:30:12 [INFO]: Epoch 033 - training loss: 0.5925, validation loss: 0.3302
2024-05-24 12:30:24 [INFO]: Epoch 034 - training loss: 0.5899, validation loss: 0.3298
2024-05-24 12:30:36 [INFO]: Epoch 035 - training loss: 0.5871, validation loss: 0.3284
2024-05-24 12:30:48 [INFO]: Epoch 036 - training loss: 0.5837, validation loss: 0.3295
2024-05-24 12:31:00 [INFO]: Epoch 037 - training loss: 0.5817, validation loss: 0.3285
2024-05-24 12:31:12 [INFO]: Epoch 038 - training loss: 0.5785, validation loss: 0.3286
2024-05-24 12:31:24 [INFO]: Epoch 039 - training loss: 0.5756, validation loss: 0.3297
2024-05-24 12:31:36 [INFO]: Epoch 040 - training loss: 0.5733, validation loss: 0.3306
2024-05-24 12:31:48 [INFO]: Epoch 041 - training loss: 0.5743, validation loss: 0.3303
2024-05-24 12:32:00 [INFO]: Epoch 042 - training loss: 0.5729, validation loss: 0.3350
2024-05-24 12:32:12 [INFO]: Epoch 043 - training loss: 0.5757, validation loss: 0.3299
2024-05-24 12:32:24 [INFO]: Epoch 044 - training loss: 0.5690, validation loss: 0.3351
2024-05-24 12:32:36 [INFO]: Epoch 045 - training loss: 0.5713, validation loss: 0.3350
2024-05-24 12:32:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 12:32:36 [INFO]: Finished training. The best model is from epoch#35.
2024-05-24 12:32:36 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T122332/BRITS.pypots
2024-05-24 12:32:39 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2678, MSE=0.3421
2024-05-24 12:32:49 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 12:32:49 [INFO]: Using the given device: cuda:0
2024-05-24 12:32:49 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249
2024-05-24 12:32:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/tensorboard
2024-05-24 12:32:49 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 12:32:54 [INFO]: Epoch 001 - training loss: 1.1110, validation loss: 1.0122
2024-05-24 12:32:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch1_loss1.0121573865413667.pypots
2024-05-24 12:32:57 [INFO]: Epoch 002 - training loss: 0.7127, validation loss: 0.9807
2024-05-24 12:32:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch2_loss0.9806674391031265.pypots
2024-05-24 12:33:00 [INFO]: Epoch 003 - training loss: 0.6279, validation loss: 0.9543
2024-05-24 12:33:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch3_loss0.9543292611837387.pypots
2024-05-24 12:33:03 [INFO]: Epoch 004 - training loss: 0.5767, validation loss: 0.9425
2024-05-24 12:33:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch4_loss0.9424875497817993.pypots
2024-05-24 12:33:05 [INFO]: Epoch 005 - training loss: 0.5499, validation loss: 0.9345
2024-05-24 12:33:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch5_loss0.9344636052846909.pypots
2024-05-24 12:33:08 [INFO]: Epoch 006 - training loss: 0.5309, validation loss: 0.9292
2024-05-24 12:33:08 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch6_loss0.9292134940624237.pypots
2024-05-24 12:33:11 [INFO]: Epoch 007 - training loss: 0.5223, validation loss: 0.9257
2024-05-24 12:33:11 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch7_loss0.9257358610630035.pypots
2024-05-24 12:33:14 [INFO]: Epoch 008 - training loss: 0.5064, validation loss: 0.9234
2024-05-24 12:33:14 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch8_loss0.9233960717916488.pypots
2024-05-24 12:33:16 [INFO]: Epoch 009 - training loss: 0.5020, validation loss: 0.9224
2024-05-24 12:33:16 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch9_loss0.9224485874176025.pypots
2024-05-24 12:33:19 [INFO]: Epoch 010 - training loss: 0.4905, validation loss: 0.9203
2024-05-24 12:33:19 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch10_loss0.9203249424695968.pypots
2024-05-24 12:33:22 [INFO]: Epoch 011 - training loss: 0.4802, validation loss: 0.9204
2024-05-24 12:33:22 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch11_loss0.9204435467720031.pypots
2024-05-24 12:33:25 [INFO]: Epoch 012 - training loss: 0.4812, validation loss: 0.9205
2024-05-24 12:33:25 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch12_loss0.920524588227272.pypots
2024-05-24 12:33:27 [INFO]: Epoch 013 - training loss: 0.4714, validation loss: 0.9211
2024-05-24 12:33:27 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch13_loss0.9211226433515549.pypots
2024-05-24 12:33:30 [INFO]: Epoch 014 - training loss: 0.4724, validation loss: 0.9227
2024-05-24 12:33:30 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch14_loss0.9226698130369186.pypots
2024-05-24 12:33:33 [INFO]: Epoch 015 - training loss: 0.4579, validation loss: 0.9240
2024-05-24 12:33:33 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch15_loss0.9240220785140991.pypots
2024-05-24 12:33:36 [INFO]: Epoch 016 - training loss: 0.4600, validation loss: 0.9264
2024-05-24 12:33:36 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch16_loss0.9264150500297547.pypots
2024-05-24 12:33:38 [INFO]: Epoch 017 - training loss: 0.4731, validation loss: 0.9273
2024-05-24 12:33:38 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch17_loss0.9272813230752945.pypots
2024-05-24 12:33:41 [INFO]: Epoch 018 - training loss: 0.4688, validation loss: 0.9303
2024-05-24 12:33:41 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch18_loss0.9302679866552352.pypots
2024-05-24 12:33:44 [INFO]: Epoch 019 - training loss: 0.4563, validation loss: 0.9297
2024-05-24 12:33:44 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch19_loss0.9297345221042633.pypots
2024-05-24 12:33:47 [INFO]: Epoch 020 - training loss: 0.4492, validation loss: 0.9311
2024-05-24 12:33:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN_epoch20_loss0.9310906887054443.pypots
2024-05-24 12:33:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 12:33:47 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 12:33:47 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T123249/MRNN.pypots
2024-05-24 12:33:48 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6840, MSE=0.9351
2024-05-24 12:33:52 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 12:33:52 [INFO]: Using the given device: cpu
2024-05-24 12:33:52 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4114, MSE=0.6133
2024-05-24 12:33:52 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_physionet_2012_seta".
2024-05-24 12:33:52 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 12:33:52 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6898, MSE=1.0489
2024-05-24 12:33:52 [INFO]: Successfully created the given path "saved_results/round_4/Median_physionet_2012_seta".
2024-05-24 12:33:52 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_physionet_2012_seta/imputation.pkl
2024-05-24 12:33:52 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7072, MSE=1.0216
2024-05-24 12:33:52 [INFO]: Successfully created the given path "saved_results/round_4/Mean_physionet_2012_seta".
2024-05-24 12:33:52 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 12:33:52 [INFO]: 
SAITS on data/physionet_2012_seta: MAE=0.211±0.0031630824131990676, MSE=0.268±0.004442146825443379
Transformer on data/physionet_2012_seta: MAE=0.222±0.0008994345071083162, MSE=0.274±0.0030411222410358482
TimesNet on data/physionet_2012_seta: MAE=0.289±0.014287043546064571, MSE=0.330±0.018762909022534965
CSDI on data/physionet_2012_seta: MAE=0.239±0.012493380041604083, MSE=0.759±0.5166793380792009
GPVAE on data/physionet_2012_seta: MAE=0.425±0.011010297879331617, MSE=0.511±0.016775237426961683
USGAN on data/physionet_2012_seta: MAE=0.298±0.002958317165249372, MSE=0.327±0.005103003220218983
BRITS on data/physionet_2012_seta: MAE=0.263±0.0028700160844782213, MSE=0.342±0.0014683679776996393
MRNN on data/physionet_2012_seta: MAE=0.685±0.0015203511943459292, MSE=0.935±0.0010958031025308605
LOCF on data/physionet_2012_seta: MAE=0.411±5.551115123125783e-17, MSE=0.613±0.0
Median on data/physionet_2012_seta: MAE=0.690±0.0, MSE=1.049±0.0
Mean on data/physionet_2012_seta: MAE=0.707±0.0, MSE=1.022±0.0

