2024-05-23 17:20:55 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-23 17:20:55 [INFO]: Using the given device: cuda:0
2024-05-23 17:20:55 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240523_T172055
2024-05-23 17:20:55 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240523_T172055/tensorboard
2024-05-23 17:20:56 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 17:21:04 [INFO]: Epoch 001 - training loss: 1.0426, validation loss: 0.5213
2024-05-23 17:21:04 [INFO]: Epoch 002 - training loss: 0.7501, validation loss: 0.3980
2024-05-23 17:21:05 [INFO]: Epoch 003 - training loss: 0.6421, validation loss: 0.3198
2024-05-23 17:21:06 [INFO]: Epoch 004 - training loss: 0.5667, validation loss: 0.2778
2024-05-23 17:21:06 [INFO]: Epoch 005 - training loss: 0.5130, validation loss: 0.2536
2024-05-23 17:21:07 [INFO]: Epoch 006 - training loss: 0.4745, validation loss: 0.2400
2024-05-23 17:21:07 [INFO]: Epoch 007 - training loss: 0.4480, validation loss: 0.2302
2024-05-23 17:21:08 [INFO]: Epoch 008 - training loss: 0.4277, validation loss: 0.2245
2024-05-23 17:21:08 [INFO]: Epoch 009 - training loss: 0.4137, validation loss: 0.2186
2024-05-23 17:21:09 [INFO]: Epoch 010 - training loss: 0.4014, validation loss: 0.2131
2024-05-23 17:21:10 [INFO]: Epoch 011 - training loss: 0.3917, validation loss: 0.2094
2024-05-23 17:21:10 [INFO]: Epoch 012 - training loss: 0.3842, validation loss: 0.2069
2024-05-23 17:21:11 [INFO]: Epoch 013 - training loss: 0.3777, validation loss: 0.2021
2024-05-23 17:21:11 [INFO]: Epoch 014 - training loss: 0.3693, validation loss: 0.2001
2024-05-23 17:21:12 [INFO]: Epoch 015 - training loss: 0.3634, validation loss: 0.1957
2024-05-23 17:21:12 [INFO]: Epoch 016 - training loss: 0.3580, validation loss: 0.1947
2024-05-23 17:21:13 [INFO]: Epoch 017 - training loss: 0.3523, validation loss: 0.1911
2024-05-23 17:21:14 [INFO]: Epoch 018 - training loss: 0.3476, validation loss: 0.1899
2024-05-23 17:21:14 [INFO]: Epoch 019 - training loss: 0.3443, validation loss: 0.1874
2024-05-23 17:21:15 [INFO]: Epoch 020 - training loss: 0.3392, validation loss: 0.1852
2024-05-23 17:21:15 [INFO]: Epoch 021 - training loss: 0.3351, validation loss: 0.1821
2024-05-23 17:21:16 [INFO]: Epoch 022 - training loss: 0.3306, validation loss: 0.1822
2024-05-23 17:21:17 [INFO]: Epoch 023 - training loss: 0.3280, validation loss: 0.1784
2024-05-23 17:21:17 [INFO]: Epoch 024 - training loss: 0.3246, validation loss: 0.1781
2024-05-23 17:21:18 [INFO]: Epoch 025 - training loss: 0.3231, validation loss: 0.1758
2024-05-23 17:21:18 [INFO]: Epoch 026 - training loss: 0.3185, validation loss: 0.1749
2024-05-23 17:21:19 [INFO]: Epoch 027 - training loss: 0.3153, validation loss: 0.1727
2024-05-23 17:21:19 [INFO]: Epoch 028 - training loss: 0.3130, validation loss: 0.1713
2024-05-23 17:21:20 [INFO]: Epoch 029 - training loss: 0.3112, validation loss: 0.1702
2024-05-23 17:21:21 [INFO]: Epoch 030 - training loss: 0.3091, validation loss: 0.1696
2024-05-23 17:21:21 [INFO]: Epoch 031 - training loss: 0.3060, validation loss: 0.1682
2024-05-23 17:21:22 [INFO]: Epoch 032 - training loss: 0.3048, validation loss: 0.1671
2024-05-23 17:21:22 [INFO]: Epoch 033 - training loss: 0.3025, validation loss: 0.1656
2024-05-23 17:21:23 [INFO]: Epoch 034 - training loss: 0.2993, validation loss: 0.1640
2024-05-23 17:21:24 [INFO]: Epoch 035 - training loss: 0.2963, validation loss: 0.1628
2024-05-23 17:21:24 [INFO]: Epoch 036 - training loss: 0.2948, validation loss: 0.1617
2024-05-23 17:21:25 [INFO]: Epoch 037 - training loss: 0.2933, validation loss: 0.1603
2024-05-23 17:21:25 [INFO]: Epoch 038 - training loss: 0.2934, validation loss: 0.1599
2024-05-23 17:21:26 [INFO]: Epoch 039 - training loss: 0.2906, validation loss: 0.1590
2024-05-23 17:21:27 [INFO]: Epoch 040 - training loss: 0.2881, validation loss: 0.1576
2024-05-23 17:21:27 [INFO]: Epoch 041 - training loss: 0.2850, validation loss: 0.1559
2024-05-23 17:21:28 [INFO]: Epoch 042 - training loss: 0.2835, validation loss: 0.1561
2024-05-23 17:21:28 [INFO]: Epoch 043 - training loss: 0.2833, validation loss: 0.1552
2024-05-23 17:21:29 [INFO]: Epoch 044 - training loss: 0.2807, validation loss: 0.1540
2024-05-23 17:21:29 [INFO]: Epoch 045 - training loss: 0.2786, validation loss: 0.1526
2024-05-23 17:21:30 [INFO]: Epoch 046 - training loss: 0.2772, validation loss: 0.1528
2024-05-23 17:21:31 [INFO]: Epoch 047 - training loss: 0.2764, validation loss: 0.1523
2024-05-23 17:21:31 [INFO]: Epoch 048 - training loss: 0.2751, validation loss: 0.1510
2024-05-23 17:21:32 [INFO]: Epoch 049 - training loss: 0.2726, validation loss: 0.1500
2024-05-23 17:21:32 [INFO]: Epoch 050 - training loss: 0.2715, validation loss: 0.1492
2024-05-23 17:21:33 [INFO]: Epoch 051 - training loss: 0.2694, validation loss: 0.1485
2024-05-23 17:21:34 [INFO]: Epoch 052 - training loss: 0.2686, validation loss: 0.1475
2024-05-23 17:21:34 [INFO]: Epoch 053 - training loss: 0.2666, validation loss: 0.1465
2024-05-23 17:21:35 [INFO]: Epoch 054 - training loss: 0.2638, validation loss: 0.1457
2024-05-23 17:21:35 [INFO]: Epoch 055 - training loss: 0.2639, validation loss: 0.1443
2024-05-23 17:21:36 [INFO]: Epoch 056 - training loss: 0.2620, validation loss: 0.1438
2024-05-23 17:21:36 [INFO]: Epoch 057 - training loss: 0.2613, validation loss: 0.1435
2024-05-23 17:21:37 [INFO]: Epoch 058 - training loss: 0.2591, validation loss: 0.1422
2024-05-23 17:21:38 [INFO]: Epoch 059 - training loss: 0.2574, validation loss: 0.1417
2024-05-23 17:21:38 [INFO]: Epoch 060 - training loss: 0.2557, validation loss: 0.1412
2024-05-23 17:21:39 [INFO]: Epoch 061 - training loss: 0.2540, validation loss: 0.1410
2024-05-23 17:21:39 [INFO]: Epoch 062 - training loss: 0.2540, validation loss: 0.1410
2024-05-23 17:21:40 [INFO]: Epoch 063 - training loss: 0.2522, validation loss: 0.1389
2024-05-23 17:21:41 [INFO]: Epoch 064 - training loss: 0.2511, validation loss: 0.1381
2024-05-23 17:21:41 [INFO]: Epoch 065 - training loss: 0.2487, validation loss: 0.1374
2024-05-23 17:21:42 [INFO]: Epoch 066 - training loss: 0.2480, validation loss: 0.1372
2024-05-23 17:21:42 [INFO]: Epoch 067 - training loss: 0.2473, validation loss: 0.1361
2024-05-23 17:21:43 [INFO]: Epoch 068 - training loss: 0.2460, validation loss: 0.1358
2024-05-23 17:21:43 [INFO]: Epoch 069 - training loss: 0.2443, validation loss: 0.1352
2024-05-23 17:21:44 [INFO]: Epoch 070 - training loss: 0.2430, validation loss: 0.1354
2024-05-23 17:21:45 [INFO]: Epoch 071 - training loss: 0.2429, validation loss: 0.1342
2024-05-23 17:21:45 [INFO]: Epoch 072 - training loss: 0.2420, validation loss: 0.1353
2024-05-23 17:21:46 [INFO]: Epoch 073 - training loss: 0.2414, validation loss: 0.1339
2024-05-23 17:21:46 [INFO]: Epoch 074 - training loss: 0.2391, validation loss: 0.1339
2024-05-23 17:21:47 [INFO]: Epoch 075 - training loss: 0.2380, validation loss: 0.1342
2024-05-23 17:21:47 [INFO]: Epoch 076 - training loss: 0.2371, validation loss: 0.1330
2024-05-23 17:21:48 [INFO]: Epoch 077 - training loss: 0.2364, validation loss: 0.1330
2024-05-23 17:21:49 [INFO]: Epoch 078 - training loss: 0.2357, validation loss: 0.1328
2024-05-23 17:21:49 [INFO]: Epoch 079 - training loss: 0.2339, validation loss: 0.1327
2024-05-23 17:21:50 [INFO]: Epoch 080 - training loss: 0.2336, validation loss: 0.1319
2024-05-23 17:21:50 [INFO]: Epoch 081 - training loss: 0.2335, validation loss: 0.1319
2024-05-23 17:21:51 [INFO]: Epoch 082 - training loss: 0.2316, validation loss: 0.1315
2024-05-23 17:21:52 [INFO]: Epoch 083 - training loss: 0.2304, validation loss: 0.1320
2024-05-23 17:21:52 [INFO]: Epoch 084 - training loss: 0.2296, validation loss: 0.1313
2024-05-23 17:21:53 [INFO]: Epoch 085 - training loss: 0.2286, validation loss: 0.1306
2024-05-23 17:21:53 [INFO]: Epoch 086 - training loss: 0.2296, validation loss: 0.1296
2024-05-23 17:21:54 [INFO]: Epoch 087 - training loss: 0.2282, validation loss: 0.1305
2024-05-23 17:21:55 [INFO]: Epoch 088 - training loss: 0.2280, validation loss: 0.1311
2024-05-23 17:21:55 [INFO]: Epoch 089 - training loss: 0.2264, validation loss: 0.1293
2024-05-23 17:21:56 [INFO]: Epoch 090 - training loss: 0.2251, validation loss: 0.1300
2024-05-23 17:21:56 [INFO]: Epoch 091 - training loss: 0.2250, validation loss: 0.1294
2024-05-23 17:21:57 [INFO]: Epoch 092 - training loss: 0.2244, validation loss: 0.1294
2024-05-23 17:21:57 [INFO]: Epoch 093 - training loss: 0.2233, validation loss: 0.1286
2024-05-23 17:21:58 [INFO]: Epoch 094 - training loss: 0.2223, validation loss: 0.1277
2024-05-23 17:21:59 [INFO]: Epoch 095 - training loss: 0.2214, validation loss: 0.1284
2024-05-23 17:21:59 [INFO]: Epoch 096 - training loss: 0.2210, validation loss: 0.1287
2024-05-23 17:22:00 [INFO]: Epoch 097 - training loss: 0.2213, validation loss: 0.1278
2024-05-23 17:22:00 [INFO]: Epoch 098 - training loss: 0.2203, validation loss: 0.1286
2024-05-23 17:22:01 [INFO]: Epoch 099 - training loss: 0.2206, validation loss: 0.1276
2024-05-23 17:22:01 [INFO]: Epoch 100 - training loss: 0.2212, validation loss: 0.1270
2024-05-23 17:22:02 [INFO]: Epoch 101 - training loss: 0.2199, validation loss: 0.1281
2024-05-23 17:22:03 [INFO]: Epoch 102 - training loss: 0.2185, validation loss: 0.1270
2024-05-23 17:22:03 [INFO]: Epoch 103 - training loss: 0.2171, validation loss: 0.1274
2024-05-23 17:22:04 [INFO]: Epoch 104 - training loss: 0.2158, validation loss: 0.1274
2024-05-23 17:22:04 [INFO]: Epoch 105 - training loss: 0.2152, validation loss: 0.1273
2024-05-23 17:22:05 [INFO]: Epoch 106 - training loss: 0.2146, validation loss: 0.1270
2024-05-23 17:22:05 [INFO]: Epoch 107 - training loss: 0.2142, validation loss: 0.1263
2024-05-23 17:22:06 [INFO]: Epoch 108 - training loss: 0.2140, validation loss: 0.1266
2024-05-23 17:22:07 [INFO]: Epoch 109 - training loss: 0.2133, validation loss: 0.1271
2024-05-23 17:22:07 [INFO]: Epoch 110 - training loss: 0.2123, validation loss: 0.1259
2024-05-23 17:22:08 [INFO]: Epoch 111 - training loss: 0.2132, validation loss: 0.1265
2024-05-23 17:22:08 [INFO]: Epoch 112 - training loss: 0.2121, validation loss: 0.1255
2024-05-23 17:22:09 [INFO]: Epoch 113 - training loss: 0.2113, validation loss: 0.1254
2024-05-23 17:22:10 [INFO]: Epoch 114 - training loss: 0.2103, validation loss: 0.1263
2024-05-23 17:22:10 [INFO]: Epoch 115 - training loss: 0.2102, validation loss: 0.1250
2024-05-23 17:22:11 [INFO]: Epoch 116 - training loss: 0.2092, validation loss: 0.1255
2024-05-23 17:22:11 [INFO]: Epoch 117 - training loss: 0.2090, validation loss: 0.1248
2024-05-23 17:22:12 [INFO]: Epoch 118 - training loss: 0.2077, validation loss: 0.1245
2024-05-23 17:22:12 [INFO]: Epoch 119 - training loss: 0.2081, validation loss: 0.1253
2024-05-23 17:22:13 [INFO]: Epoch 120 - training loss: 0.2080, validation loss: 0.1249
2024-05-23 17:22:14 [INFO]: Epoch 121 - training loss: 0.2071, validation loss: 0.1247
2024-05-23 17:22:14 [INFO]: Epoch 122 - training loss: 0.2057, validation loss: 0.1243
2024-05-23 17:22:15 [INFO]: Epoch 123 - training loss: 0.2061, validation loss: 0.1248
2024-05-23 17:22:15 [INFO]: Epoch 124 - training loss: 0.2048, validation loss: 0.1235
2024-05-23 17:22:16 [INFO]: Epoch 125 - training loss: 0.2041, validation loss: 0.1240
2024-05-23 17:22:16 [INFO]: Epoch 126 - training loss: 0.2054, validation loss: 0.1243
2024-05-23 17:22:17 [INFO]: Epoch 127 - training loss: 0.2058, validation loss: 0.1237
2024-05-23 17:22:18 [INFO]: Epoch 128 - training loss: 0.2034, validation loss: 0.1234
2024-05-23 17:22:18 [INFO]: Epoch 129 - training loss: 0.2045, validation loss: 0.1224
2024-05-23 17:22:19 [INFO]: Epoch 130 - training loss: 0.2028, validation loss: 0.1219
2024-05-23 17:22:19 [INFO]: Epoch 131 - training loss: 0.2017, validation loss: 0.1224
2024-05-23 17:22:20 [INFO]: Epoch 132 - training loss: 0.2025, validation loss: 0.1223
2024-05-23 17:22:21 [INFO]: Epoch 133 - training loss: 0.2009, validation loss: 0.1222
2024-05-23 17:22:21 [INFO]: Epoch 134 - training loss: 0.2004, validation loss: 0.1218
2024-05-23 17:22:22 [INFO]: Epoch 135 - training loss: 0.1998, validation loss: 0.1227
2024-05-23 17:22:22 [INFO]: Epoch 136 - training loss: 0.2000, validation loss: 0.1228
2024-05-23 17:22:23 [INFO]: Epoch 137 - training loss: 0.1994, validation loss: 0.1217
2024-05-23 17:22:23 [INFO]: Epoch 138 - training loss: 0.1988, validation loss: 0.1213
2024-05-23 17:22:24 [INFO]: Epoch 139 - training loss: 0.1977, validation loss: 0.1219
2024-05-23 17:22:25 [INFO]: Epoch 140 - training loss: 0.1990, validation loss: 0.1213
2024-05-23 17:22:25 [INFO]: Epoch 141 - training loss: 0.1978, validation loss: 0.1221
2024-05-23 17:22:26 [INFO]: Epoch 142 - training loss: 0.1978, validation loss: 0.1210
2024-05-23 17:22:26 [INFO]: Epoch 143 - training loss: 0.1967, validation loss: 0.1214
2024-05-23 17:22:27 [INFO]: Epoch 144 - training loss: 0.1957, validation loss: 0.1215
2024-05-23 17:22:28 [INFO]: Epoch 145 - training loss: 0.1951, validation loss: 0.1211
2024-05-23 17:22:28 [INFO]: Epoch 146 - training loss: 0.1953, validation loss: 0.1204
2024-05-23 17:22:29 [INFO]: Epoch 147 - training loss: 0.1947, validation loss: 0.1212
2024-05-23 17:22:29 [INFO]: Epoch 148 - training loss: 0.1941, validation loss: 0.1206
2024-05-23 17:22:30 [INFO]: Epoch 149 - training loss: 0.1942, validation loss: 0.1210
2024-05-23 17:22:30 [INFO]: Epoch 150 - training loss: 0.1939, validation loss: 0.1209
2024-05-23 17:22:31 [INFO]: Epoch 151 - training loss: 0.1928, validation loss: 0.1218
2024-05-23 17:22:32 [INFO]: Epoch 152 - training loss: 0.1940, validation loss: 0.1210
2024-05-23 17:22:32 [INFO]: Epoch 153 - training loss: 0.1940, validation loss: 0.1211
2024-05-23 17:22:33 [INFO]: Epoch 154 - training loss: 0.1947, validation loss: 0.1202
2024-05-23 17:22:33 [INFO]: Epoch 155 - training loss: 0.1926, validation loss: 0.1200
2024-05-23 17:22:34 [INFO]: Epoch 156 - training loss: 0.1918, validation loss: 0.1207
2024-05-23 17:22:35 [INFO]: Epoch 157 - training loss: 0.1906, validation loss: 0.1203
2024-05-23 17:22:35 [INFO]: Epoch 158 - training loss: 0.1898, validation loss: 0.1205
2024-05-23 17:22:36 [INFO]: Epoch 159 - training loss: 0.1896, validation loss: 0.1199
2024-05-23 17:22:36 [INFO]: Epoch 160 - training loss: 0.1902, validation loss: 0.1200
2024-05-23 17:22:37 [INFO]: Epoch 161 - training loss: 0.1905, validation loss: 0.1199
2024-05-23 17:22:37 [INFO]: Epoch 162 - training loss: 0.1902, validation loss: 0.1192
2024-05-23 17:22:38 [INFO]: Epoch 163 - training loss: 0.1896, validation loss: 0.1191
2024-05-23 17:22:39 [INFO]: Epoch 164 - training loss: 0.1888, validation loss: 0.1189
2024-05-23 17:22:39 [INFO]: Epoch 165 - training loss: 0.1876, validation loss: 0.1185
2024-05-23 17:22:40 [INFO]: Epoch 166 - training loss: 0.1879, validation loss: 0.1192
2024-05-23 17:22:40 [INFO]: Epoch 167 - training loss: 0.1890, validation loss: 0.1187
2024-05-23 17:22:41 [INFO]: Epoch 168 - training loss: 0.1877, validation loss: 0.1188
2024-05-23 17:22:42 [INFO]: Epoch 169 - training loss: 0.1884, validation loss: 0.1174
2024-05-23 17:22:42 [INFO]: Epoch 170 - training loss: 0.1863, validation loss: 0.1188
2024-05-23 17:22:43 [INFO]: Epoch 171 - training loss: 0.1862, validation loss: 0.1181
2024-05-23 17:22:43 [INFO]: Epoch 172 - training loss: 0.1859, validation loss: 0.1186
2024-05-23 17:22:44 [INFO]: Epoch 173 - training loss: 0.1849, validation loss: 0.1182
2024-05-23 17:22:44 [INFO]: Epoch 174 - training loss: 0.1841, validation loss: 0.1179
2024-05-23 17:22:45 [INFO]: Epoch 175 - training loss: 0.1837, validation loss: 0.1178
2024-05-23 17:22:46 [INFO]: Epoch 176 - training loss: 0.1846, validation loss: 0.1180
2024-05-23 17:22:46 [INFO]: Epoch 177 - training loss: 0.1830, validation loss: 0.1181
2024-05-23 17:22:47 [INFO]: Epoch 178 - training loss: 0.1842, validation loss: 0.1176
2024-05-23 17:22:47 [INFO]: Epoch 179 - training loss: 0.1833, validation loss: 0.1185
2024-05-23 17:22:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:22:47 [INFO]: Finished training. The best model is from epoch#169.
2024-05-23 17:22:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240523_T172055/SAITS.pypots
2024-05-23 17:22:48 [INFO]: SAITS on Air-Quality: MAE=0.1542, MSE=0.1588
2024-05-23 17:22:48 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-23 17:22:48 [INFO]: Using the given device: cuda:0
2024-05-23 17:22:48 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240523_T172248
2024-05-23 17:22:48 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240523_T172248/tensorboard
2024-05-23 17:22:48 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 17:22:48 [INFO]: Epoch 001 - training loss: 0.8699, validation loss: 0.4607
2024-05-23 17:22:48 [INFO]: Epoch 002 - training loss: 0.5569, validation loss: 0.3289
2024-05-23 17:22:49 [INFO]: Epoch 003 - training loss: 0.4622, validation loss: 0.2796
2024-05-23 17:22:49 [INFO]: Epoch 004 - training loss: 0.4177, validation loss: 0.2597
2024-05-23 17:22:49 [INFO]: Epoch 005 - training loss: 0.3897, validation loss: 0.2441
2024-05-23 17:22:49 [INFO]: Epoch 006 - training loss: 0.3721, validation loss: 0.2343
2024-05-23 17:22:50 [INFO]: Epoch 007 - training loss: 0.3534, validation loss: 0.2239
2024-05-23 17:22:50 [INFO]: Epoch 008 - training loss: 0.3408, validation loss: 0.2193
2024-05-23 17:22:50 [INFO]: Epoch 009 - training loss: 0.3313, validation loss: 0.2126
2024-05-23 17:22:50 [INFO]: Epoch 010 - training loss: 0.3235, validation loss: 0.2111
2024-05-23 17:22:51 [INFO]: Epoch 011 - training loss: 0.3180, validation loss: 0.2046
2024-05-23 17:22:51 [INFO]: Epoch 012 - training loss: 0.3111, validation loss: 0.2033
2024-05-23 17:22:51 [INFO]: Epoch 013 - training loss: 0.3044, validation loss: 0.1970
2024-05-23 17:22:51 [INFO]: Epoch 014 - training loss: 0.2988, validation loss: 0.1930
2024-05-23 17:22:51 [INFO]: Epoch 015 - training loss: 0.2944, validation loss: 0.1894
2024-05-23 17:22:52 [INFO]: Epoch 016 - training loss: 0.2912, validation loss: 0.1892
2024-05-23 17:22:52 [INFO]: Epoch 017 - training loss: 0.2884, validation loss: 0.1854
2024-05-23 17:22:52 [INFO]: Epoch 018 - training loss: 0.2839, validation loss: 0.1842
2024-05-23 17:22:52 [INFO]: Epoch 019 - training loss: 0.2816, validation loss: 0.1829
2024-05-23 17:22:53 [INFO]: Epoch 020 - training loss: 0.2775, validation loss: 0.1783
2024-05-23 17:22:53 [INFO]: Epoch 021 - training loss: 0.2745, validation loss: 0.1769
2024-05-23 17:22:53 [INFO]: Epoch 022 - training loss: 0.2702, validation loss: 0.1753
2024-05-23 17:22:53 [INFO]: Epoch 023 - training loss: 0.2697, validation loss: 0.1758
2024-05-23 17:22:54 [INFO]: Epoch 024 - training loss: 0.2683, validation loss: 0.1742
2024-05-23 17:22:54 [INFO]: Epoch 025 - training loss: 0.2649, validation loss: 0.1734
2024-05-23 17:22:54 [INFO]: Epoch 026 - training loss: 0.2608, validation loss: 0.1716
2024-05-23 17:22:54 [INFO]: Epoch 027 - training loss: 0.2584, validation loss: 0.1711
2024-05-23 17:22:55 [INFO]: Epoch 028 - training loss: 0.2582, validation loss: 0.1703
2024-05-23 17:22:55 [INFO]: Epoch 029 - training loss: 0.2561, validation loss: 0.1689
2024-05-23 17:22:55 [INFO]: Epoch 030 - training loss: 0.2522, validation loss: 0.1695
2024-05-23 17:22:55 [INFO]: Epoch 031 - training loss: 0.2522, validation loss: 0.1686
2024-05-23 17:22:56 [INFO]: Epoch 032 - training loss: 0.2486, validation loss: 0.1676
2024-05-23 17:22:56 [INFO]: Epoch 033 - training loss: 0.2489, validation loss: 0.1662
2024-05-23 17:22:56 [INFO]: Epoch 034 - training loss: 0.2450, validation loss: 0.1662
2024-05-23 17:22:56 [INFO]: Epoch 035 - training loss: 0.2456, validation loss: 0.1673
2024-05-23 17:22:56 [INFO]: Epoch 036 - training loss: 0.2429, validation loss: 0.1636
2024-05-23 17:22:57 [INFO]: Epoch 037 - training loss: 0.2423, validation loss: 0.1650
2024-05-23 17:22:57 [INFO]: Epoch 038 - training loss: 0.2396, validation loss: 0.1613
2024-05-23 17:22:57 [INFO]: Epoch 039 - training loss: 0.2381, validation loss: 0.1617
2024-05-23 17:22:57 [INFO]: Epoch 040 - training loss: 0.2365, validation loss: 0.1619
2024-05-23 17:22:58 [INFO]: Epoch 041 - training loss: 0.2346, validation loss: 0.1614
2024-05-23 17:22:58 [INFO]: Epoch 042 - training loss: 0.2318, validation loss: 0.1600
2024-05-23 17:22:58 [INFO]: Epoch 043 - training loss: 0.2302, validation loss: 0.1606
2024-05-23 17:22:58 [INFO]: Epoch 044 - training loss: 0.2281, validation loss: 0.1587
2024-05-23 17:22:59 [INFO]: Epoch 045 - training loss: 0.2276, validation loss: 0.1605
2024-05-23 17:22:59 [INFO]: Epoch 046 - training loss: 0.2303, validation loss: 0.1600
2024-05-23 17:22:59 [INFO]: Epoch 047 - training loss: 0.2296, validation loss: 0.1618
2024-05-23 17:22:59 [INFO]: Epoch 048 - training loss: 0.2296, validation loss: 0.1574
2024-05-23 17:23:00 [INFO]: Epoch 049 - training loss: 0.2308, validation loss: 0.1597
2024-05-23 17:23:00 [INFO]: Epoch 050 - training loss: 0.2248, validation loss: 0.1570
2024-05-23 17:23:00 [INFO]: Epoch 051 - training loss: 0.2223, validation loss: 0.1571
2024-05-23 17:23:00 [INFO]: Epoch 052 - training loss: 0.2240, validation loss: 0.1545
2024-05-23 17:23:00 [INFO]: Epoch 053 - training loss: 0.2187, validation loss: 0.1554
2024-05-23 17:23:01 [INFO]: Epoch 054 - training loss: 0.2171, validation loss: 0.1542
2024-05-23 17:23:01 [INFO]: Epoch 055 - training loss: 0.2159, validation loss: 0.1543
2024-05-23 17:23:01 [INFO]: Epoch 056 - training loss: 0.2177, validation loss: 0.1539
2024-05-23 17:23:01 [INFO]: Epoch 057 - training loss: 0.2174, validation loss: 0.1548
2024-05-23 17:23:02 [INFO]: Epoch 058 - training loss: 0.2181, validation loss: 0.1538
2024-05-23 17:23:02 [INFO]: Epoch 059 - training loss: 0.2189, validation loss: 0.1533
2024-05-23 17:23:02 [INFO]: Epoch 060 - training loss: 0.2167, validation loss: 0.1537
2024-05-23 17:23:02 [INFO]: Epoch 061 - training loss: 0.2142, validation loss: 0.1514
2024-05-23 17:23:03 [INFO]: Epoch 062 - training loss: 0.2117, validation loss: 0.1517
2024-05-23 17:23:03 [INFO]: Epoch 063 - training loss: 0.2096, validation loss: 0.1528
2024-05-23 17:23:03 [INFO]: Epoch 064 - training loss: 0.2090, validation loss: 0.1504
2024-05-23 17:23:03 [INFO]: Epoch 065 - training loss: 0.2054, validation loss: 0.1508
2024-05-23 17:23:04 [INFO]: Epoch 066 - training loss: 0.2054, validation loss: 0.1508
2024-05-23 17:23:04 [INFO]: Epoch 067 - training loss: 0.2054, validation loss: 0.1525
2024-05-23 17:23:04 [INFO]: Epoch 068 - training loss: 0.2046, validation loss: 0.1514
2024-05-23 17:23:04 [INFO]: Epoch 069 - training loss: 0.2031, validation loss: 0.1489
2024-05-23 17:23:04 [INFO]: Epoch 070 - training loss: 0.2038, validation loss: 0.1491
2024-05-23 17:23:05 [INFO]: Epoch 071 - training loss: 0.2023, validation loss: 0.1497
2024-05-23 17:23:05 [INFO]: Epoch 072 - training loss: 0.1998, validation loss: 0.1489
2024-05-23 17:23:05 [INFO]: Epoch 073 - training loss: 0.2035, validation loss: 0.1506
2024-05-23 17:23:05 [INFO]: Epoch 074 - training loss: 0.2051, validation loss: 0.1495
2024-05-23 17:23:06 [INFO]: Epoch 075 - training loss: 0.1981, validation loss: 0.1479
2024-05-23 17:23:06 [INFO]: Epoch 076 - training loss: 0.1964, validation loss: 0.1471
2024-05-23 17:23:06 [INFO]: Epoch 077 - training loss: 0.1952, validation loss: 0.1467
2024-05-23 17:23:06 [INFO]: Epoch 078 - training loss: 0.1953, validation loss: 0.1484
2024-05-23 17:23:07 [INFO]: Epoch 079 - training loss: 0.1945, validation loss: 0.1474
2024-05-23 17:23:07 [INFO]: Epoch 080 - training loss: 0.1939, validation loss: 0.1455
2024-05-23 17:23:07 [INFO]: Epoch 081 - training loss: 0.1945, validation loss: 0.1472
2024-05-23 17:23:07 [INFO]: Epoch 082 - training loss: 0.1907, validation loss: 0.1468
2024-05-23 17:23:08 [INFO]: Epoch 083 - training loss: 0.1908, validation loss: 0.1471
2024-05-23 17:23:08 [INFO]: Epoch 084 - training loss: 0.1896, validation loss: 0.1438
2024-05-23 17:23:08 [INFO]: Epoch 085 - training loss: 0.1911, validation loss: 0.1452
2024-05-23 17:23:08 [INFO]: Epoch 086 - training loss: 0.1908, validation loss: 0.1453
2024-05-23 17:23:08 [INFO]: Epoch 087 - training loss: 0.1905, validation loss: 0.1434
2024-05-23 17:23:09 [INFO]: Epoch 088 - training loss: 0.1863, validation loss: 0.1437
2024-05-23 17:23:09 [INFO]: Epoch 089 - training loss: 0.1846, validation loss: 0.1435
2024-05-23 17:23:09 [INFO]: Epoch 090 - training loss: 0.1849, validation loss: 0.1442
2024-05-23 17:23:09 [INFO]: Epoch 091 - training loss: 0.1849, validation loss: 0.1455
2024-05-23 17:23:10 [INFO]: Epoch 092 - training loss: 0.1839, validation loss: 0.1427
2024-05-23 17:23:10 [INFO]: Epoch 093 - training loss: 0.1827, validation loss: 0.1457
2024-05-23 17:23:10 [INFO]: Epoch 094 - training loss: 0.1822, validation loss: 0.1428
2024-05-23 17:23:10 [INFO]: Epoch 095 - training loss: 0.1821, validation loss: 0.1428
2024-05-23 17:23:11 [INFO]: Epoch 096 - training loss: 0.1809, validation loss: 0.1424
2024-05-23 17:23:11 [INFO]: Epoch 097 - training loss: 0.1833, validation loss: 0.1422
2024-05-23 17:23:11 [INFO]: Epoch 098 - training loss: 0.1806, validation loss: 0.1420
2024-05-23 17:23:11 [INFO]: Epoch 099 - training loss: 0.1798, validation loss: 0.1414
2024-05-23 17:23:12 [INFO]: Epoch 100 - training loss: 0.1786, validation loss: 0.1428
2024-05-23 17:23:12 [INFO]: Epoch 101 - training loss: 0.1778, validation loss: 0.1421
2024-05-23 17:23:12 [INFO]: Epoch 102 - training loss: 0.1804, validation loss: 0.1409
2024-05-23 17:23:12 [INFO]: Epoch 103 - training loss: 0.1777, validation loss: 0.1447
2024-05-23 17:23:12 [INFO]: Epoch 104 - training loss: 0.1766, validation loss: 0.1415
2024-05-23 17:23:13 [INFO]: Epoch 105 - training loss: 0.1767, validation loss: 0.1409
2024-05-23 17:23:13 [INFO]: Epoch 106 - training loss: 0.1748, validation loss: 0.1400
2024-05-23 17:23:13 [INFO]: Epoch 107 - training loss: 0.1735, validation loss: 0.1406
2024-05-23 17:23:13 [INFO]: Epoch 108 - training loss: 0.1752, validation loss: 0.1401
2024-05-23 17:23:14 [INFO]: Epoch 109 - training loss: 0.1769, validation loss: 0.1408
2024-05-23 17:23:14 [INFO]: Epoch 110 - training loss: 0.1760, validation loss: 0.1409
2024-05-23 17:23:14 [INFO]: Epoch 111 - training loss: 0.1735, validation loss: 0.1390
2024-05-23 17:23:14 [INFO]: Epoch 112 - training loss: 0.1756, validation loss: 0.1405
2024-05-23 17:23:15 [INFO]: Epoch 113 - training loss: 0.1726, validation loss: 0.1422
2024-05-23 17:23:15 [INFO]: Epoch 114 - training loss: 0.1708, validation loss: 0.1407
2024-05-23 17:23:15 [INFO]: Epoch 115 - training loss: 0.1696, validation loss: 0.1410
2024-05-23 17:23:15 [INFO]: Epoch 116 - training loss: 0.1691, validation loss: 0.1411
2024-05-23 17:23:15 [INFO]: Epoch 117 - training loss: 0.1678, validation loss: 0.1407
2024-05-23 17:23:16 [INFO]: Epoch 118 - training loss: 0.1666, validation loss: 0.1400
2024-05-23 17:23:16 [INFO]: Epoch 119 - training loss: 0.1659, validation loss: 0.1398
2024-05-23 17:23:16 [INFO]: Epoch 120 - training loss: 0.1653, validation loss: 0.1394
2024-05-23 17:23:16 [INFO]: Epoch 121 - training loss: 0.1653, validation loss: 0.1392
2024-05-23 17:23:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:23:16 [INFO]: Finished training. The best model is from epoch#111.
2024-05-23 17:23:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240523_T172248/Transformer.pypots
2024-05-23 17:23:16 [INFO]: Transformer on Air-Quality: MAE=0.1717, MSE=0.1804
2024-05-23 17:23:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-23 17:23:16 [INFO]: Using the given device: cuda:0
2024-05-23 17:23:16 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172316
2024-05-23 17:23:16 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172316/tensorboard
2024-05-23 17:23:17 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 17:23:23 [INFO]: Epoch 001 - training loss: 0.2717, validation loss: 0.2591
2024-05-23 17:23:24 [INFO]: Epoch 002 - training loss: 0.2023, validation loss: 0.2405
2024-05-23 17:23:24 [INFO]: Epoch 003 - training loss: 0.1736, validation loss: 0.2169
2024-05-23 17:23:24 [INFO]: Epoch 004 - training loss: 0.1458, validation loss: 0.2109
2024-05-23 17:23:25 [INFO]: Epoch 005 - training loss: 0.1330, validation loss: 0.2047
2024-05-23 17:23:25 [INFO]: Epoch 006 - training loss: 0.1311, validation loss: 0.2005
2024-05-23 17:23:26 [INFO]: Epoch 007 - training loss: 0.1271, validation loss: 0.1951
2024-05-23 17:23:26 [INFO]: Epoch 008 - training loss: 0.1130, validation loss: 0.1887
2024-05-23 17:23:27 [INFO]: Epoch 009 - training loss: 0.1075, validation loss: 0.1873
2024-05-23 17:23:27 [INFO]: Epoch 010 - training loss: 0.1023, validation loss: 0.1845
2024-05-23 17:23:27 [INFO]: Epoch 011 - training loss: 0.0962, validation loss: 0.1857
2024-05-23 17:23:28 [INFO]: Epoch 012 - training loss: 0.0947, validation loss: 0.1781
2024-05-23 17:23:28 [INFO]: Epoch 013 - training loss: 0.0865, validation loss: 0.1869
2024-05-23 17:23:29 [INFO]: Epoch 014 - training loss: 0.0839, validation loss: 0.1834
2024-05-23 17:23:29 [INFO]: Epoch 015 - training loss: 0.0830, validation loss: 0.1790
2024-05-23 17:23:29 [INFO]: Epoch 016 - training loss: 0.0788, validation loss: 0.1811
2024-05-23 17:23:30 [INFO]: Epoch 017 - training loss: 0.0778, validation loss: 0.1798
2024-05-23 17:23:30 [INFO]: Epoch 018 - training loss: 0.0803, validation loss: 0.1847
2024-05-23 17:23:31 [INFO]: Epoch 019 - training loss: 0.0757, validation loss: 0.1743
2024-05-23 17:23:31 [INFO]: Epoch 020 - training loss: 0.0737, validation loss: 0.1783
2024-05-23 17:23:32 [INFO]: Epoch 021 - training loss: 0.0696, validation loss: 0.1752
2024-05-23 17:23:32 [INFO]: Epoch 022 - training loss: 0.0672, validation loss: 0.1741
2024-05-23 17:23:32 [INFO]: Epoch 023 - training loss: 0.0708, validation loss: 0.1737
2024-05-23 17:23:33 [INFO]: Epoch 024 - training loss: 0.0685, validation loss: 0.1698
2024-05-23 17:23:33 [INFO]: Epoch 025 - training loss: 0.0631, validation loss: 0.1694
2024-05-23 17:23:34 [INFO]: Epoch 026 - training loss: 0.0638, validation loss: 0.1719
2024-05-23 17:23:34 [INFO]: Epoch 027 - training loss: 0.0622, validation loss: 0.1682
2024-05-23 17:23:35 [INFO]: Epoch 028 - training loss: 0.0614, validation loss: 0.1656
2024-05-23 17:23:35 [INFO]: Epoch 029 - training loss: 0.0648, validation loss: 0.1663
2024-05-23 17:23:35 [INFO]: Epoch 030 - training loss: 0.0612, validation loss: 0.1654
2024-05-23 17:23:36 [INFO]: Epoch 031 - training loss: 0.0595, validation loss: 0.1646
2024-05-23 17:23:36 [INFO]: Epoch 032 - training loss: 0.0571, validation loss: 0.1674
2024-05-23 17:23:37 [INFO]: Epoch 033 - training loss: 0.0566, validation loss: 0.1654
2024-05-23 17:23:37 [INFO]: Epoch 034 - training loss: 0.0584, validation loss: 0.1639
2024-05-23 17:23:37 [INFO]: Epoch 035 - training loss: 0.0547, validation loss: 0.1605
2024-05-23 17:23:38 [INFO]: Epoch 036 - training loss: 0.0531, validation loss: 0.1659
2024-05-23 17:23:38 [INFO]: Epoch 037 - training loss: 0.0502, validation loss: 0.1614
2024-05-23 17:23:39 [INFO]: Epoch 038 - training loss: 0.0513, validation loss: 0.1637
2024-05-23 17:23:39 [INFO]: Epoch 039 - training loss: 0.0501, validation loss: 0.1610
2024-05-23 17:23:40 [INFO]: Epoch 040 - training loss: 0.0492, validation loss: 0.1626
2024-05-23 17:23:40 [INFO]: Epoch 041 - training loss: 0.0485, validation loss: 0.1618
2024-05-23 17:23:40 [INFO]: Epoch 042 - training loss: 0.0479, validation loss: 0.1627
2024-05-23 17:23:41 [INFO]: Epoch 043 - training loss: 0.0458, validation loss: 0.1615
2024-05-23 17:23:41 [INFO]: Epoch 044 - training loss: 0.0451, validation loss: 0.1593
2024-05-23 17:23:42 [INFO]: Epoch 045 - training loss: 0.0461, validation loss: 0.1646
2024-05-23 17:23:42 [INFO]: Epoch 046 - training loss: 0.0468, validation loss: 0.1578
2024-05-23 17:23:43 [INFO]: Epoch 047 - training loss: 0.0479, validation loss: 0.1597
2024-05-23 17:23:43 [INFO]: Epoch 048 - training loss: 0.0465, validation loss: 0.1577
2024-05-23 17:23:43 [INFO]: Epoch 049 - training loss: 0.0448, validation loss: 0.1601
2024-05-23 17:23:44 [INFO]: Epoch 050 - training loss: 0.0443, validation loss: 0.1562
2024-05-23 17:23:44 [INFO]: Epoch 051 - training loss: 0.0444, validation loss: 0.1659
2024-05-23 17:23:45 [INFO]: Epoch 052 - training loss: 0.0463, validation loss: 0.1558
2024-05-23 17:23:45 [INFO]: Epoch 053 - training loss: 0.0462, validation loss: 0.1571
2024-05-23 17:23:46 [INFO]: Epoch 054 - training loss: 0.0443, validation loss: 0.1592
2024-05-23 17:23:46 [INFO]: Epoch 055 - training loss: 0.0439, validation loss: 0.1622
2024-05-23 17:23:46 [INFO]: Epoch 056 - training loss: 0.0422, validation loss: 0.1650
2024-05-23 17:23:47 [INFO]: Epoch 057 - training loss: 0.0419, validation loss: 0.1580
2024-05-23 17:23:47 [INFO]: Epoch 058 - training loss: 0.0415, validation loss: 0.1558
2024-05-23 17:23:48 [INFO]: Epoch 059 - training loss: 0.0396, validation loss: 0.1566
2024-05-23 17:23:48 [INFO]: Epoch 060 - training loss: 0.0376, validation loss: 0.1584
2024-05-23 17:23:49 [INFO]: Epoch 061 - training loss: 0.0363, validation loss: 0.1588
2024-05-23 17:23:49 [INFO]: Epoch 062 - training loss: 0.0362, validation loss: 0.1555
2024-05-23 17:23:49 [INFO]: Epoch 063 - training loss: 0.0376, validation loss: 0.1572
2024-05-23 17:23:50 [INFO]: Epoch 064 - training loss: 0.0366, validation loss: 0.1561
2024-05-23 17:23:50 [INFO]: Epoch 065 - training loss: 0.0355, validation loss: 0.1559
2024-05-23 17:23:51 [INFO]: Epoch 066 - training loss: 0.0342, validation loss: 0.1571
2024-05-23 17:23:51 [INFO]: Epoch 067 - training loss: 0.0371, validation loss: 0.1559
2024-05-23 17:23:52 [INFO]: Epoch 068 - training loss: 0.0386, validation loss: 0.1549
2024-05-23 17:23:52 [INFO]: Epoch 069 - training loss: 0.0359, validation loss: 0.1557
2024-05-23 17:23:52 [INFO]: Epoch 070 - training loss: 0.0438, validation loss: 0.1622
2024-05-23 17:23:53 [INFO]: Epoch 071 - training loss: 0.0454, validation loss: 0.1579
2024-05-23 17:23:53 [INFO]: Epoch 072 - training loss: 0.0411, validation loss: 0.1561
2024-05-23 17:23:54 [INFO]: Epoch 073 - training loss: 0.0354, validation loss: 0.1563
2024-05-23 17:23:54 [INFO]: Epoch 074 - training loss: 0.0388, validation loss: 0.1555
2024-05-23 17:23:55 [INFO]: Epoch 075 - training loss: 0.0331, validation loss: 0.1568
2024-05-23 17:23:55 [INFO]: Epoch 076 - training loss: 0.0315, validation loss: 0.1544
2024-05-23 17:23:55 [INFO]: Epoch 077 - training loss: 0.0315, validation loss: 0.1531
2024-05-23 17:23:56 [INFO]: Epoch 078 - training loss: 0.0310, validation loss: 0.1562
2024-05-23 17:23:56 [INFO]: Epoch 079 - training loss: 0.0300, validation loss: 0.1545
2024-05-23 17:23:57 [INFO]: Epoch 080 - training loss: 0.0289, validation loss: 0.1554
2024-05-23 17:23:57 [INFO]: Epoch 081 - training loss: 0.0302, validation loss: 0.1546
2024-05-23 17:23:58 [INFO]: Epoch 082 - training loss: 0.0303, validation loss: 0.1569
2024-05-23 17:23:58 [INFO]: Epoch 083 - training loss: 0.0312, validation loss: 0.1571
2024-05-23 17:23:58 [INFO]: Epoch 084 - training loss: 0.0299, validation loss: 0.1551
2024-05-23 17:23:59 [INFO]: Epoch 085 - training loss: 0.0294, validation loss: 0.1532
2024-05-23 17:23:59 [INFO]: Epoch 086 - training loss: 0.0284, validation loss: 0.1558
2024-05-23 17:24:00 [INFO]: Epoch 087 - training loss: 0.0304, validation loss: 0.1572
2024-05-23 17:24:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:24:00 [INFO]: Finished training. The best model is from epoch#77.
2024-05-23 17:24:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172316/TimesNet.pypots
2024-05-23 17:24:00 [INFO]: TimesNet on Air-Quality: MAE=0.1603, MSE=0.2282
2024-05-23 17:24:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-23 17:24:00 [INFO]: Using the given device: cuda:0
2024-05-23 17:24:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400
2024-05-23 17:24:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/tensorboard
2024-05-23 17:24:00 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 17:24:18 [INFO]: Epoch 001 - training loss: 0.5143, validation loss: 0.3188
2024-05-23 17:24:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch1_loss0.3188487946987152.pypots
2024-05-23 17:24:34 [INFO]: Epoch 002 - training loss: 0.2627, validation loss: 0.2620
2024-05-23 17:24:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch2_loss0.2620485633611679.pypots
2024-05-23 17:24:50 [INFO]: Epoch 003 - training loss: 0.2451, validation loss: 0.2281
2024-05-23 17:24:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch3_loss0.22814250141382217.pypots
2024-05-23 17:25:07 [INFO]: Epoch 004 - training loss: 0.2191, validation loss: 0.1950
2024-05-23 17:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch4_loss0.1949984073638916.pypots
2024-05-23 17:25:23 [INFO]: Epoch 005 - training loss: 0.2101, validation loss: 0.1822
2024-05-23 17:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch5_loss0.18218744546175003.pypots
2024-05-23 17:25:39 [INFO]: Epoch 006 - training loss: 0.1647, validation loss: 0.1697
2024-05-23 17:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch6_loss0.16969578713178635.pypots
2024-05-23 17:25:56 [INFO]: Epoch 007 - training loss: 0.1594, validation loss: 0.1569
2024-05-23 17:25:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch7_loss0.1569279044866562.pypots
2024-05-23 17:26:12 [INFO]: Epoch 008 - training loss: 0.1595, validation loss: 0.1529
2024-05-23 17:26:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch8_loss0.15285706371068955.pypots
2024-05-23 17:26:28 [INFO]: Epoch 009 - training loss: 0.1713, validation loss: 0.1554
2024-05-23 17:26:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch9_loss0.15539570152759552.pypots
2024-05-23 17:26:44 [INFO]: Epoch 010 - training loss: 0.1494, validation loss: 0.1507
2024-05-23 17:26:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch10_loss0.15065490007400512.pypots
2024-05-23 17:27:01 [INFO]: Epoch 011 - training loss: 0.1410, validation loss: 0.1483
2024-05-23 17:27:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch11_loss0.14825129210948945.pypots
2024-05-23 17:27:17 [INFO]: Epoch 012 - training loss: 0.1569, validation loss: 0.1435
2024-05-23 17:27:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch12_loss0.143466567248106.pypots
2024-05-23 17:27:33 [INFO]: Epoch 013 - training loss: 0.1547, validation loss: 0.1467
2024-05-23 17:27:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch13_loss0.14671746343374253.pypots
2024-05-23 17:27:50 [INFO]: Epoch 014 - training loss: 0.1620, validation loss: 0.1437
2024-05-23 17:27:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch14_loss0.14368131011724472.pypots
2024-05-23 17:28:06 [INFO]: Epoch 015 - training loss: 0.1474, validation loss: 0.1378
2024-05-23 17:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch15_loss0.13780680298805237.pypots
2024-05-23 17:28:22 [INFO]: Epoch 016 - training loss: 0.1451, validation loss: 0.1415
2024-05-23 17:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch16_loss0.14148740395903586.pypots
2024-05-23 17:28:39 [INFO]: Epoch 017 - training loss: 0.1633, validation loss: 0.1367
2024-05-23 17:28:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch17_loss0.13674820438027382.pypots
2024-05-23 17:28:55 [INFO]: Epoch 018 - training loss: 0.1457, validation loss: 0.1397
2024-05-23 17:28:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch18_loss0.1397438108921051.pypots
2024-05-23 17:29:11 [INFO]: Epoch 019 - training loss: 0.1439, validation loss: 0.1352
2024-05-23 17:29:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch19_loss0.13523017913103103.pypots
2024-05-23 17:29:28 [INFO]: Epoch 020 - training loss: 0.1240, validation loss: 0.1354
2024-05-23 17:29:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch20_loss0.13540708646178246.pypots
2024-05-23 17:29:44 [INFO]: Epoch 021 - training loss: 0.1412, validation loss: 0.1330
2024-05-23 17:29:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch21_loss0.13304398953914642.pypots
2024-05-23 17:30:00 [INFO]: Epoch 022 - training loss: 0.1365, validation loss: 0.1293
2024-05-23 17:30:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch22_loss0.12929800450801848.pypots
2024-05-23 17:30:17 [INFO]: Epoch 023 - training loss: 0.1477, validation loss: 0.1380
2024-05-23 17:30:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch23_loss0.1379990004003048.pypots
2024-05-23 17:30:33 [INFO]: Epoch 024 - training loss: 0.1398, validation loss: 0.1369
2024-05-23 17:30:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch24_loss0.13694966211915016.pypots
2024-05-23 17:30:49 [INFO]: Epoch 025 - training loss: 0.1361, validation loss: 0.1307
2024-05-23 17:30:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch25_loss0.13071072474122047.pypots
2024-05-23 17:31:05 [INFO]: Epoch 026 - training loss: 0.1278, validation loss: 0.1291
2024-05-23 17:31:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch26_loss0.129092013835907.pypots
2024-05-23 17:31:22 [INFO]: Epoch 027 - training loss: 0.1422, validation loss: 0.1287
2024-05-23 17:31:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch27_loss0.128696508705616.pypots
2024-05-23 17:31:38 [INFO]: Epoch 028 - training loss: 0.1398, validation loss: 0.1280
2024-05-23 17:31:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch28_loss0.1279692269861698.pypots
2024-05-23 17:31:54 [INFO]: Epoch 029 - training loss: 0.1193, validation loss: 0.1293
2024-05-23 17:31:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch29_loss0.12934512197971343.pypots
2024-05-23 17:32:11 [INFO]: Epoch 030 - training loss: 0.1224, validation loss: 0.1255
2024-05-23 17:32:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch30_loss0.12553648948669432.pypots
2024-05-23 17:32:27 [INFO]: Epoch 031 - training loss: 0.1280, validation loss: 0.1251
2024-05-23 17:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch31_loss0.12514765858650206.pypots
2024-05-23 17:32:43 [INFO]: Epoch 032 - training loss: 0.1286, validation loss: 0.1277
2024-05-23 17:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch32_loss0.12770228311419488.pypots
2024-05-23 17:32:59 [INFO]: Epoch 033 - training loss: 0.1168, validation loss: 0.1250
2024-05-23 17:33:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch33_loss0.1250487506389618.pypots
2024-05-23 17:33:16 [INFO]: Epoch 034 - training loss: 0.1349, validation loss: 0.1273
2024-05-23 17:33:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch34_loss0.1273337870836258.pypots
2024-05-23 17:33:32 [INFO]: Epoch 035 - training loss: 0.1249, validation loss: 0.1217
2024-05-23 17:33:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch35_loss0.12171288058161736.pypots
2024-05-23 17:33:48 [INFO]: Epoch 036 - training loss: 0.1161, validation loss: 0.1210
2024-05-23 17:33:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch36_loss0.12102655693888664.pypots
2024-05-23 17:34:05 [INFO]: Epoch 037 - training loss: 0.1249, validation loss: 0.1221
2024-05-23 17:34:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch37_loss0.12212179228663445.pypots
2024-05-23 17:34:21 [INFO]: Epoch 038 - training loss: 0.1320, validation loss: 0.1245
2024-05-23 17:34:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch38_loss0.12449172735214234.pypots
2024-05-23 17:34:37 [INFO]: Epoch 039 - training loss: 0.1264, validation loss: 0.1255
2024-05-23 17:34:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch39_loss0.12554229870438577.pypots
2024-05-23 17:34:54 [INFO]: Epoch 040 - training loss: 0.1147, validation loss: 0.1195
2024-05-23 17:34:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch40_loss0.11950809955596924.pypots
2024-05-23 17:35:10 [INFO]: Epoch 041 - training loss: 0.1253, validation loss: 0.1227
2024-05-23 17:35:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch41_loss0.12270878627896309.pypots
2024-05-23 17:35:26 [INFO]: Epoch 042 - training loss: 0.1138, validation loss: 0.1189
2024-05-23 17:35:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch42_loss0.11894919201731682.pypots
2024-05-23 17:35:43 [INFO]: Epoch 043 - training loss: 0.1239, validation loss: 0.1188
2024-05-23 17:35:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch43_loss0.11878896057605744.pypots
2024-05-23 17:35:59 [INFO]: Epoch 044 - training loss: 0.1204, validation loss: 0.1174
2024-05-23 17:35:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch44_loss0.11735753491520881.pypots
2024-05-23 17:36:15 [INFO]: Epoch 045 - training loss: 0.1177, validation loss: 0.1168
2024-05-23 17:36:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch45_loss0.1167929358780384.pypots
2024-05-23 17:36:31 [INFO]: Epoch 046 - training loss: 0.1260, validation loss: 0.1193
2024-05-23 17:36:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch46_loss0.11926420554518699.pypots
2024-05-23 17:36:48 [INFO]: Epoch 047 - training loss: 0.1177, validation loss: 0.1176
2024-05-23 17:36:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch47_loss0.11755354925990105.pypots
2024-05-23 17:37:04 [INFO]: Epoch 048 - training loss: 0.1157, validation loss: 0.1153
2024-05-23 17:37:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch48_loss0.11528003811836243.pypots
2024-05-23 17:37:20 [INFO]: Epoch 049 - training loss: 0.1185, validation loss: 0.1164
2024-05-23 17:37:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch49_loss0.1163906678557396.pypots
2024-05-23 17:37:37 [INFO]: Epoch 050 - training loss: 0.1039, validation loss: 0.1131
2024-05-23 17:37:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch50_loss0.1131191998720169.pypots
2024-05-23 17:37:53 [INFO]: Epoch 051 - training loss: 0.1091, validation loss: 0.1154
2024-05-23 17:37:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch51_loss0.11541998237371445.pypots
2024-05-23 17:38:09 [INFO]: Epoch 052 - training loss: 0.1055, validation loss: 0.1148
2024-05-23 17:38:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch52_loss0.11476823836565017.pypots
2024-05-23 17:38:25 [INFO]: Epoch 053 - training loss: 0.1156, validation loss: 0.1159
2024-05-23 17:38:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch53_loss0.11587659418582916.pypots
2024-05-23 17:38:42 [INFO]: Epoch 054 - training loss: 0.1289, validation loss: 0.1148
2024-05-23 17:38:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch54_loss0.1148306243121624.pypots
2024-05-23 17:38:58 [INFO]: Epoch 055 - training loss: 0.1100, validation loss: 0.1166
2024-05-23 17:38:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch55_loss0.11659875437617302.pypots
2024-05-23 17:39:14 [INFO]: Epoch 056 - training loss: 0.1016, validation loss: 0.1145
2024-05-23 17:39:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch56_loss0.11451152712106705.pypots
2024-05-23 17:39:31 [INFO]: Epoch 057 - training loss: 0.0985, validation loss: 0.1181
2024-05-23 17:39:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch57_loss0.1181024968624115.pypots
2024-05-23 17:39:47 [INFO]: Epoch 058 - training loss: 0.1260, validation loss: 0.1118
2024-05-23 17:39:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch58_loss0.11184271350502968.pypots
2024-05-23 17:40:03 [INFO]: Epoch 059 - training loss: 0.1186, validation loss: 0.1114
2024-05-23 17:40:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch59_loss0.11136239245533944.pypots
2024-05-23 17:40:19 [INFO]: Epoch 060 - training loss: 0.1158, validation loss: 0.1149
2024-05-23 17:40:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch60_loss0.1148644857108593.pypots
2024-05-23 17:40:36 [INFO]: Epoch 061 - training loss: 0.1094, validation loss: 0.1124
2024-05-23 17:40:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch61_loss0.1124009445309639.pypots
2024-05-23 17:40:52 [INFO]: Epoch 062 - training loss: 0.1060, validation loss: 0.1144
2024-05-23 17:40:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch62_loss0.11443236321210862.pypots
2024-05-23 17:41:08 [INFO]: Epoch 063 - training loss: 0.1080, validation loss: 0.1119
2024-05-23 17:41:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch63_loss0.11189382299780845.pypots
2024-05-23 17:41:25 [INFO]: Epoch 064 - training loss: 0.0920, validation loss: 0.1115
2024-05-23 17:41:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch64_loss0.1115033894777298.pypots
2024-05-23 17:41:41 [INFO]: Epoch 065 - training loss: 0.1139, validation loss: 0.1142
2024-05-23 17:41:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch65_loss0.11420370489358903.pypots
2024-05-23 17:41:57 [INFO]: Epoch 066 - training loss: 0.0994, validation loss: 0.1099
2024-05-23 17:41:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch66_loss0.10988767966628074.pypots
2024-05-23 17:42:13 [INFO]: Epoch 067 - training loss: 0.1156, validation loss: 0.1125
2024-05-23 17:42:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch67_loss0.11252809166908265.pypots
2024-05-23 17:42:30 [INFO]: Epoch 068 - training loss: 0.1064, validation loss: 0.1101
2024-05-23 17:42:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch68_loss0.11007708758115768.pypots
2024-05-23 17:42:46 [INFO]: Epoch 069 - training loss: 0.1092, validation loss: 0.1072
2024-05-23 17:42:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch69_loss0.10721912309527397.pypots
2024-05-23 17:43:02 [INFO]: Epoch 070 - training loss: 0.1028, validation loss: 0.1083
2024-05-23 17:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch70_loss0.10831488072872161.pypots
2024-05-23 17:43:19 [INFO]: Epoch 071 - training loss: 0.1111, validation loss: 0.1081
2024-05-23 17:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch71_loss0.10813010409474373.pypots
2024-05-23 17:43:35 [INFO]: Epoch 072 - training loss: 0.1140, validation loss: 0.1075
2024-05-23 17:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch72_loss0.10748780667781829.pypots
2024-05-23 17:43:51 [INFO]: Epoch 073 - training loss: 0.0973, validation loss: 0.1063
2024-05-23 17:43:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch73_loss0.10628139749169349.pypots
2024-05-23 17:44:08 [INFO]: Epoch 074 - training loss: 0.1133, validation loss: 0.1073
2024-05-23 17:44:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch74_loss0.107337386906147.pypots
2024-05-23 17:44:24 [INFO]: Epoch 075 - training loss: 0.1044, validation loss: 0.1083
2024-05-23 17:44:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch75_loss0.1083110012114048.pypots
2024-05-23 17:44:40 [INFO]: Epoch 076 - training loss: 0.1102, validation loss: 0.1063
2024-05-23 17:44:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch76_loss0.10628335997462272.pypots
2024-05-23 17:44:56 [INFO]: Epoch 077 - training loss: 0.1076, validation loss: 0.1073
2024-05-23 17:44:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch77_loss0.1073184609413147.pypots
2024-05-23 17:45:13 [INFO]: Epoch 078 - training loss: 0.1040, validation loss: 0.1071
2024-05-23 17:45:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch78_loss0.107117660343647.pypots
2024-05-23 17:45:29 [INFO]: Epoch 079 - training loss: 0.1066, validation loss: 0.1060
2024-05-23 17:45:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch79_loss0.10599719732999802.pypots
2024-05-23 17:45:45 [INFO]: Epoch 080 - training loss: 0.1057, validation loss: 0.1060
2024-05-23 17:45:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch80_loss0.10602534785866738.pypots
2024-05-23 17:46:02 [INFO]: Epoch 081 - training loss: 0.0982, validation loss: 0.1044
2024-05-23 17:46:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch81_loss0.10439473912119865.pypots
2024-05-23 17:46:18 [INFO]: Epoch 082 - training loss: 0.1039, validation loss: 0.1069
2024-05-23 17:46:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch82_loss0.10689841434359551.pypots
2024-05-23 17:46:34 [INFO]: Epoch 083 - training loss: 0.1132, validation loss: 0.1066
2024-05-23 17:46:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch83_loss0.10663884282112121.pypots
2024-05-23 17:46:50 [INFO]: Epoch 084 - training loss: 0.0977, validation loss: 0.1077
2024-05-23 17:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch84_loss0.10768287926912308.pypots
2024-05-23 17:47:07 [INFO]: Epoch 085 - training loss: 0.1023, validation loss: 0.1101
2024-05-23 17:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch85_loss0.11013857051730155.pypots
2024-05-23 17:47:23 [INFO]: Epoch 086 - training loss: 0.1004, validation loss: 0.1063
2024-05-23 17:47:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch86_loss0.1062801755964756.pypots
2024-05-23 17:47:39 [INFO]: Epoch 087 - training loss: 0.0978, validation loss: 0.1051
2024-05-23 17:47:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch87_loss0.10513656884431839.pypots
2024-05-23 17:47:56 [INFO]: Epoch 088 - training loss: 0.1116, validation loss: 0.1061
2024-05-23 17:47:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch88_loss0.1061169072985649.pypots
2024-05-23 17:48:12 [INFO]: Epoch 089 - training loss: 0.1058, validation loss: 0.1033
2024-05-23 17:48:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch89_loss0.1032678559422493.pypots
2024-05-23 17:48:28 [INFO]: Epoch 090 - training loss: 0.1049, validation loss: 0.1032
2024-05-23 17:48:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch90_loss0.10317970365285874.pypots
2024-05-23 17:48:44 [INFO]: Epoch 091 - training loss: 0.1083, validation loss: 0.1037
2024-05-23 17:48:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch91_loss0.10371643155813218.pypots
2024-05-23 17:49:01 [INFO]: Epoch 092 - training loss: 0.1090, validation loss: 0.1049
2024-05-23 17:49:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch92_loss0.10491624474525452.pypots
2024-05-23 17:49:17 [INFO]: Epoch 093 - training loss: 0.0918, validation loss: 0.1050
2024-05-23 17:49:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch93_loss0.10503008887171746.pypots
2024-05-23 17:49:33 [INFO]: Epoch 094 - training loss: 0.1038, validation loss: 0.1021
2024-05-23 17:49:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch94_loss0.10210216268897057.pypots
2024-05-23 17:49:50 [INFO]: Epoch 095 - training loss: 0.1142, validation loss: 0.1091
2024-05-23 17:49:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch95_loss0.1090998724102974.pypots
2024-05-23 17:50:06 [INFO]: Epoch 096 - training loss: 0.0959, validation loss: 0.1045
2024-05-23 17:50:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch96_loss0.10454231649637222.pypots
2024-05-23 17:50:22 [INFO]: Epoch 097 - training loss: 0.1087, validation loss: 0.1076
2024-05-23 17:50:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch97_loss0.1075505182147026.pypots
2024-05-23 17:50:38 [INFO]: Epoch 098 - training loss: 0.1162, validation loss: 0.1076
2024-05-23 17:50:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch98_loss0.10760767012834549.pypots
2024-05-23 17:50:55 [INFO]: Epoch 099 - training loss: 0.1032, validation loss: 0.1046
2024-05-23 17:50:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch99_loss0.1046102486550808.pypots
2024-05-23 17:51:11 [INFO]: Epoch 100 - training loss: 0.1005, validation loss: 0.1054
2024-05-23 17:51:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch100_loss0.10542998388409615.pypots
2024-05-23 17:51:27 [INFO]: Epoch 101 - training loss: 0.0992, validation loss: 0.1037
2024-05-23 17:51:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch101_loss0.10371878445148468.pypots
2024-05-23 17:51:44 [INFO]: Epoch 102 - training loss: 0.0968, validation loss: 0.1040
2024-05-23 17:51:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch102_loss0.10397539660334587.pypots
2024-05-23 17:52:00 [INFO]: Epoch 103 - training loss: 0.1195, validation loss: 0.1060
2024-05-23 17:52:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch103_loss0.10604356750845909.pypots
2024-05-23 17:52:16 [INFO]: Epoch 104 - training loss: 0.1001, validation loss: 0.1148
2024-05-23 17:52:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI_epoch104_loss0.11483701094985008.pypots
2024-05-23 17:52:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:52:16 [INFO]: Finished training. The best model is from epoch#94.
2024-05-23 17:52:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240523_T172400/CSDI.pypots
2024-05-23 17:54:34 [INFO]: CSDI on Air-Quality: MAE=0.1015, MSE=0.1584
2024-05-23 17:54:34 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-23 17:54:34 [INFO]: Using the given device: cuda:0
2024-05-23 17:54:34 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175434
2024-05-23 17:54:34 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175434/tensorboard
2024-05-23 17:54:34 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 17:54:36 [INFO]: Epoch 001 - training loss: 63839.7963, validation loss: 0.6804
2024-05-23 17:54:36 [INFO]: Epoch 002 - training loss: 41834.2587, validation loss: 0.5890
2024-05-23 17:54:36 [INFO]: Epoch 003 - training loss: 41510.8927, validation loss: 0.5523
2024-05-23 17:54:36 [INFO]: Epoch 004 - training loss: 41395.6152, validation loss: 0.5346
2024-05-23 17:54:37 [INFO]: Epoch 005 - training loss: 41295.7465, validation loss: 0.5256
2024-05-23 17:54:37 [INFO]: Epoch 006 - training loss: 41242.5010, validation loss: 0.4219
2024-05-23 17:54:37 [INFO]: Epoch 007 - training loss: 41178.5237, validation loss: 0.4041
2024-05-23 17:54:37 [INFO]: Epoch 008 - training loss: 41159.5385, validation loss: 0.3690
2024-05-23 17:54:38 [INFO]: Epoch 009 - training loss: 41138.1910, validation loss: 0.3504
2024-05-23 17:54:38 [INFO]: Epoch 010 - training loss: 41096.0324, validation loss: 0.3354
2024-05-23 17:54:38 [INFO]: Epoch 011 - training loss: 41067.5184, validation loss: 0.3358
2024-05-23 17:54:38 [INFO]: Epoch 012 - training loss: 41071.3001, validation loss: 0.3564
2024-05-23 17:54:38 [INFO]: Epoch 013 - training loss: 41082.6863, validation loss: 0.3231
2024-05-23 17:54:39 [INFO]: Epoch 014 - training loss: 41033.3643, validation loss: 0.3109
2024-05-23 17:54:39 [INFO]: Epoch 015 - training loss: 41012.0764, validation loss: 0.2948
2024-05-23 17:54:39 [INFO]: Epoch 016 - training loss: 40993.4955, validation loss: 0.2921
2024-05-23 17:54:39 [INFO]: Epoch 017 - training loss: 40988.6807, validation loss: 0.2870
2024-05-23 17:54:40 [INFO]: Epoch 018 - training loss: 40988.9400, validation loss: 0.2978
2024-05-23 17:54:40 [INFO]: Epoch 019 - training loss: 40976.6042, validation loss: 0.3034
2024-05-23 17:54:40 [INFO]: Epoch 020 - training loss: 40973.0382, validation loss: 0.2761
2024-05-23 17:54:40 [INFO]: Epoch 021 - training loss: 40950.6534, validation loss: 0.2738
2024-05-23 17:54:41 [INFO]: Epoch 022 - training loss: 40943.2789, validation loss: 0.2832
2024-05-23 17:54:41 [INFO]: Epoch 023 - training loss: 40967.5279, validation loss: 0.2708
2024-05-23 17:54:41 [INFO]: Epoch 024 - training loss: 40962.5616, validation loss: 0.2908
2024-05-23 17:54:41 [INFO]: Epoch 025 - training loss: 40954.0830, validation loss: 0.2738
2024-05-23 17:54:41 [INFO]: Epoch 026 - training loss: 40954.6390, validation loss: 0.2825
2024-05-23 17:54:42 [INFO]: Epoch 027 - training loss: 40971.0674, validation loss: 0.2586
2024-05-23 17:54:42 [INFO]: Epoch 028 - training loss: 40925.3741, validation loss: 0.2596
2024-05-23 17:54:42 [INFO]: Epoch 029 - training loss: 40918.9991, validation loss: 0.2580
2024-05-23 17:54:42 [INFO]: Epoch 030 - training loss: 40909.5943, validation loss: 0.2492
2024-05-23 17:54:43 [INFO]: Epoch 031 - training loss: 40905.9646, validation loss: 0.2508
2024-05-23 17:54:43 [INFO]: Epoch 032 - training loss: 40904.2316, validation loss: 0.2489
2024-05-23 17:54:43 [INFO]: Epoch 033 - training loss: 40912.9009, validation loss: 0.2548
2024-05-23 17:54:43 [INFO]: Epoch 034 - training loss: 40950.9018, validation loss: 0.2708
2024-05-23 17:54:43 [INFO]: Epoch 035 - training loss: 40946.6597, validation loss: 0.2682
2024-05-23 17:54:44 [INFO]: Epoch 036 - training loss: 40930.0230, validation loss: 0.2534
2024-05-23 17:54:44 [INFO]: Epoch 037 - training loss: 40904.2989, validation loss: 0.2460
2024-05-23 17:54:44 [INFO]: Epoch 038 - training loss: 40897.6853, validation loss: 0.2361
2024-05-23 17:54:44 [INFO]: Epoch 039 - training loss: 40891.5123, validation loss: 0.2386
2024-05-23 17:54:45 [INFO]: Epoch 040 - training loss: 40890.2244, validation loss: 0.2383
2024-05-23 17:54:45 [INFO]: Epoch 041 - training loss: 40894.0307, validation loss: 0.2830
2024-05-23 17:54:45 [INFO]: Epoch 042 - training loss: 40910.6091, validation loss: 0.2501
2024-05-23 17:54:45 [INFO]: Epoch 043 - training loss: 40915.9569, validation loss: 0.2490
2024-05-23 17:54:46 [INFO]: Epoch 044 - training loss: 40916.7674, validation loss: 0.2510
2024-05-23 17:54:46 [INFO]: Epoch 045 - training loss: 40899.0450, validation loss: 0.2518
2024-05-23 17:54:46 [INFO]: Epoch 046 - training loss: 40898.6140, validation loss: 0.2495
2024-05-23 17:54:46 [INFO]: Epoch 047 - training loss: 40890.8194, validation loss: 0.2344
2024-05-23 17:54:46 [INFO]: Epoch 048 - training loss: 40874.8012, validation loss: 0.2300
2024-05-23 17:54:47 [INFO]: Epoch 049 - training loss: 40870.7368, validation loss: 0.2245
2024-05-23 17:54:47 [INFO]: Epoch 050 - training loss: 40868.7620, validation loss: 0.2261
2024-05-23 17:54:47 [INFO]: Epoch 051 - training loss: 40858.9758, validation loss: 0.2229
2024-05-23 17:54:47 [INFO]: Epoch 052 - training loss: 40856.1019, validation loss: 0.2240
2024-05-23 17:54:48 [INFO]: Epoch 053 - training loss: 40857.3082, validation loss: 0.2222
2024-05-23 17:54:48 [INFO]: Epoch 054 - training loss: 40862.8624, validation loss: 0.2294
2024-05-23 17:54:48 [INFO]: Epoch 055 - training loss: 40856.0988, validation loss: 0.2387
2024-05-23 17:54:48 [INFO]: Epoch 056 - training loss: 40858.6688, validation loss: 0.2227
2024-05-23 17:54:49 [INFO]: Epoch 057 - training loss: 40853.0884, validation loss: 0.2262
2024-05-23 17:54:49 [INFO]: Epoch 058 - training loss: 40849.6183, validation loss: 0.2176
2024-05-23 17:54:49 [INFO]: Epoch 059 - training loss: 40853.9666, validation loss: 0.2228
2024-05-23 17:54:49 [INFO]: Epoch 060 - training loss: 40880.0616, validation loss: 0.2370
2024-05-23 17:54:49 [INFO]: Epoch 061 - training loss: 40865.2765, validation loss: 0.2384
2024-05-23 17:54:50 [INFO]: Epoch 062 - training loss: 40880.1810, validation loss: 0.2224
2024-05-23 17:54:50 [INFO]: Epoch 063 - training loss: 40852.7736, validation loss: 0.2156
2024-05-23 17:54:50 [INFO]: Epoch 064 - training loss: 40863.3223, validation loss: 0.2250
2024-05-23 17:54:50 [INFO]: Epoch 065 - training loss: 40866.5538, validation loss: 0.2472
2024-05-23 17:54:51 [INFO]: Epoch 066 - training loss: 40906.0966, validation loss: 0.2211
2024-05-23 17:54:51 [INFO]: Epoch 067 - training loss: 40848.6370, validation loss: 0.2144
2024-05-23 17:54:51 [INFO]: Epoch 068 - training loss: 40845.4165, validation loss: 0.2176
2024-05-23 17:54:51 [INFO]: Epoch 069 - training loss: 40843.1238, validation loss: 0.2197
2024-05-23 17:54:52 [INFO]: Epoch 070 - training loss: 40847.6649, validation loss: 0.2189
2024-05-23 17:54:52 [INFO]: Epoch 071 - training loss: 40840.9103, validation loss: 0.2128
2024-05-23 17:54:52 [INFO]: Epoch 072 - training loss: 40834.2151, validation loss: 0.2116
2024-05-23 17:54:52 [INFO]: Epoch 073 - training loss: 40838.9295, validation loss: 0.2178
2024-05-23 17:54:52 [INFO]: Epoch 074 - training loss: 40842.8685, validation loss: 0.2105
2024-05-23 17:54:53 [INFO]: Epoch 075 - training loss: 40837.9664, validation loss: 0.2134
2024-05-23 17:54:53 [INFO]: Epoch 076 - training loss: 40836.8915, validation loss: 0.2081
2024-05-23 17:54:53 [INFO]: Epoch 077 - training loss: 40829.3549, validation loss: 0.2141
2024-05-23 17:54:53 [INFO]: Epoch 078 - training loss: 40842.4443, validation loss: 0.2190
2024-05-23 17:54:54 [INFO]: Epoch 079 - training loss: 40837.1641, validation loss: 0.2519
2024-05-23 17:54:54 [INFO]: Epoch 080 - training loss: 40956.5786, validation loss: 0.2293
2024-05-23 17:54:54 [INFO]: Epoch 081 - training loss: 40893.8342, validation loss: 0.2163
2024-05-23 17:54:54 [INFO]: Epoch 082 - training loss: 40850.6091, validation loss: 0.2090
2024-05-23 17:54:54 [INFO]: Epoch 083 - training loss: 40832.7096, validation loss: 0.2136
2024-05-23 17:54:55 [INFO]: Epoch 084 - training loss: 40836.0611, validation loss: 0.2134
2024-05-23 17:54:55 [INFO]: Epoch 085 - training loss: 40827.6192, validation loss: 0.2096
2024-05-23 17:54:55 [INFO]: Epoch 086 - training loss: 40829.6545, validation loss: 0.2096
2024-05-23 17:54:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:54:55 [INFO]: Finished training. The best model is from epoch#76.
2024-05-23 17:54:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175434/GPVAE.pypots
2024-05-23 17:54:55 [INFO]: GP-VAE on Air-Quality: MAE=0.2638, MSE=0.2459
2024-05-23 17:54:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-23 17:54:55 [INFO]: Using the given device: cuda:0
2024-05-23 17:54:55 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240523_T175455
2024-05-23 17:54:55 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240523_T175455/tensorboard
2024-05-23 17:54:55 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 17:55:00 [INFO]: Epoch 001 - generator training loss: 0.4368, discriminator training loss: 0.4495, validation loss: 0.5024
2024-05-23 17:55:03 [INFO]: Epoch 002 - generator training loss: 0.0913, discriminator training loss: 0.3613, validation loss: 0.3805
2024-05-23 17:55:07 [INFO]: Epoch 003 - generator training loss: 0.0353, discriminator training loss: 0.3572, validation loss: 0.3161
2024-05-23 17:55:10 [INFO]: Epoch 004 - generator training loss: -0.0033, discriminator training loss: 0.3551, validation loss: 0.2773
2024-05-23 17:55:13 [INFO]: Epoch 005 - generator training loss: -0.0319, discriminator training loss: 0.3537, validation loss: 0.2501
2024-05-23 17:55:16 [INFO]: Epoch 006 - generator training loss: -0.0501, discriminator training loss: 0.3515, validation loss: 0.2320
2024-05-23 17:55:20 [INFO]: Epoch 007 - generator training loss: -0.0625, discriminator training loss: 0.3497, validation loss: 0.2186
2024-05-23 17:55:23 [INFO]: Epoch 008 - generator training loss: -0.0712, discriminator training loss: 0.3477, validation loss: 0.2081
2024-05-23 17:55:26 [INFO]: Epoch 009 - generator training loss: -0.0802, discriminator training loss: 0.3453, validation loss: 0.1990
2024-05-23 17:55:29 [INFO]: Epoch 010 - generator training loss: -0.0861, discriminator training loss: 0.3428, validation loss: 0.1920
2024-05-23 17:55:33 [INFO]: Epoch 011 - generator training loss: -0.0910, discriminator training loss: 0.3403, validation loss: 0.1863
2024-05-23 17:55:36 [INFO]: Epoch 012 - generator training loss: -0.0953, discriminator training loss: 0.3376, validation loss: 0.1808
2024-05-23 17:55:39 [INFO]: Epoch 013 - generator training loss: -0.0983, discriminator training loss: 0.3348, validation loss: 0.1767
2024-05-23 17:55:42 [INFO]: Epoch 014 - generator training loss: -0.1005, discriminator training loss: 0.3317, validation loss: 0.1725
2024-05-23 17:55:46 [INFO]: Epoch 015 - generator training loss: -0.1018, discriminator training loss: 0.3283, validation loss: 0.1695
2024-05-23 17:55:49 [INFO]: Epoch 016 - generator training loss: -0.1029, discriminator training loss: 0.3248, validation loss: 0.1665
2024-05-23 17:55:52 [INFO]: Epoch 017 - generator training loss: -0.1029, discriminator training loss: 0.3211, validation loss: 0.1628
2024-05-23 17:55:55 [INFO]: Epoch 018 - generator training loss: -0.1034, discriminator training loss: 0.3171, validation loss: 0.1601
2024-05-23 17:55:59 [INFO]: Epoch 019 - generator training loss: -0.0993, discriminator training loss: 0.3132, validation loss: 0.1576
2024-05-23 17:56:02 [INFO]: Epoch 020 - generator training loss: -0.1007, discriminator training loss: 0.3090, validation loss: 0.1557
2024-05-23 17:56:06 [INFO]: Epoch 021 - generator training loss: -0.1001, discriminator training loss: 0.3047, validation loss: 0.1527
2024-05-23 17:56:09 [INFO]: Epoch 022 - generator training loss: -0.0961, discriminator training loss: 0.3006, validation loss: 0.1511
2024-05-23 17:56:13 [INFO]: Epoch 023 - generator training loss: -0.0968, discriminator training loss: 0.2963, validation loss: 0.1488
2024-05-23 17:56:16 [INFO]: Epoch 024 - generator training loss: -0.0951, discriminator training loss: 0.2918, validation loss: 0.1467
2024-05-23 17:56:20 [INFO]: Epoch 025 - generator training loss: -0.0932, discriminator training loss: 0.2877, validation loss: 0.1452
2024-05-23 17:56:23 [INFO]: Epoch 026 - generator training loss: -0.0923, discriminator training loss: 0.2837, validation loss: 0.1435
2024-05-23 17:56:26 [INFO]: Epoch 027 - generator training loss: -0.0905, discriminator training loss: 0.2798, validation loss: 0.1419
2024-05-23 17:56:29 [INFO]: Epoch 028 - generator training loss: -0.0884, discriminator training loss: 0.2756, validation loss: 0.1403
2024-05-23 17:56:33 [INFO]: Epoch 029 - generator training loss: -0.0865, discriminator training loss: 0.2723, validation loss: 0.1390
2024-05-23 17:56:36 [INFO]: Epoch 030 - generator training loss: -0.0839, discriminator training loss: 0.2688, validation loss: 0.1370
2024-05-23 17:56:39 [INFO]: Epoch 031 - generator training loss: -0.0839, discriminator training loss: 0.2651, validation loss: 0.1356
2024-05-23 17:56:42 [INFO]: Epoch 032 - generator training loss: -0.0821, discriminator training loss: 0.2618, validation loss: 0.1346
2024-05-23 17:56:46 [INFO]: Epoch 033 - generator training loss: -0.0779, discriminator training loss: 0.2588, validation loss: 0.1328
2024-05-23 17:56:49 [INFO]: Epoch 034 - generator training loss: -0.0803, discriminator training loss: 0.2560, validation loss: 0.1323
2024-05-23 17:56:52 [INFO]: Epoch 035 - generator training loss: -0.0779, discriminator training loss: 0.2533, validation loss: 0.1308
2024-05-23 17:56:56 [INFO]: Epoch 036 - generator training loss: -0.0784, discriminator training loss: 0.2507, validation loss: 0.1297
2024-05-23 17:56:59 [INFO]: Epoch 037 - generator training loss: -0.0763, discriminator training loss: 0.2478, validation loss: 0.1286
2024-05-23 17:57:02 [INFO]: Epoch 038 - generator training loss: -0.0753, discriminator training loss: 0.2459, validation loss: 0.1279
2024-05-23 17:57:05 [INFO]: Epoch 039 - generator training loss: -0.0755, discriminator training loss: 0.2433, validation loss: 0.1267
2024-05-23 17:57:09 [INFO]: Epoch 040 - generator training loss: -0.0746, discriminator training loss: 0.2413, validation loss: 0.1255
2024-05-23 17:57:12 [INFO]: Epoch 041 - generator training loss: -0.0741, discriminator training loss: 0.2396, validation loss: 0.1248
2024-05-23 17:57:15 [INFO]: Epoch 042 - generator training loss: -0.0754, discriminator training loss: 0.2374, validation loss: 0.1233
2024-05-23 17:57:18 [INFO]: Epoch 043 - generator training loss: -0.0736, discriminator training loss: 0.2359, validation loss: 0.1225
2024-05-23 17:57:22 [INFO]: Epoch 044 - generator training loss: -0.0740, discriminator training loss: 0.2344, validation loss: 0.1216
2024-05-23 17:57:25 [INFO]: Epoch 045 - generator training loss: -0.0734, discriminator training loss: 0.2325, validation loss: 0.1208
2024-05-23 17:57:28 [INFO]: Epoch 046 - generator training loss: -0.0725, discriminator training loss: 0.2316, validation loss: 0.1193
2024-05-23 17:57:31 [INFO]: Epoch 047 - generator training loss: -0.0727, discriminator training loss: 0.2299, validation loss: 0.1192
2024-05-23 17:57:35 [INFO]: Epoch 048 - generator training loss: -0.0732, discriminator training loss: 0.2282, validation loss: 0.1185
2024-05-23 17:57:38 [INFO]: Epoch 049 - generator training loss: -0.0731, discriminator training loss: 0.2277, validation loss: 0.1183
2024-05-23 17:57:41 [INFO]: Epoch 050 - generator training loss: -0.0721, discriminator training loss: 0.2261, validation loss: 0.1167
2024-05-23 17:57:44 [INFO]: Epoch 051 - generator training loss: -0.0726, discriminator training loss: 0.2251, validation loss: 0.1167
2024-05-23 17:57:48 [INFO]: Epoch 052 - generator training loss: -0.0727, discriminator training loss: 0.2240, validation loss: 0.1157
2024-05-23 17:57:51 [INFO]: Epoch 053 - generator training loss: -0.0728, discriminator training loss: 0.2230, validation loss: 0.1150
2024-05-23 17:57:54 [INFO]: Epoch 054 - generator training loss: -0.0724, discriminator training loss: 0.2219, validation loss: 0.1146
2024-05-23 17:57:57 [INFO]: Epoch 055 - generator training loss: -0.0728, discriminator training loss: 0.2211, validation loss: 0.1135
2024-05-23 17:58:01 [INFO]: Epoch 056 - generator training loss: -0.0725, discriminator training loss: 0.2205, validation loss: 0.1131
2024-05-23 17:58:04 [INFO]: Epoch 057 - generator training loss: -0.0720, discriminator training loss: 0.2199, validation loss: 0.1129
2024-05-23 17:58:07 [INFO]: Epoch 058 - generator training loss: -0.0723, discriminator training loss: 0.2191, validation loss: 0.1122
2024-05-23 17:58:11 [INFO]: Epoch 059 - generator training loss: -0.0725, discriminator training loss: 0.2180, validation loss: 0.1121
2024-05-23 17:58:14 [INFO]: Epoch 060 - generator training loss: -0.0719, discriminator training loss: 0.2181, validation loss: 0.1110
2024-05-23 17:58:17 [INFO]: Epoch 061 - generator training loss: -0.0726, discriminator training loss: 0.2167, validation loss: 0.1108
2024-05-23 17:58:20 [INFO]: Epoch 062 - generator training loss: -0.0727, discriminator training loss: 0.2166, validation loss: 0.1105
2024-05-23 17:58:24 [INFO]: Epoch 063 - generator training loss: -0.0727, discriminator training loss: 0.2154, validation loss: 0.1100
2024-05-23 17:58:27 [INFO]: Epoch 064 - generator training loss: -0.0727, discriminator training loss: 0.2154, validation loss: 0.1094
2024-05-23 17:58:30 [INFO]: Epoch 065 - generator training loss: -0.0731, discriminator training loss: 0.2143, validation loss: 0.1089
2024-05-23 17:58:33 [INFO]: Epoch 066 - generator training loss: -0.0733, discriminator training loss: 0.2140, validation loss: 0.1080
2024-05-23 17:58:37 [INFO]: Epoch 067 - generator training loss: -0.0727, discriminator training loss: 0.2137, validation loss: 0.1081
2024-05-23 17:58:40 [INFO]: Epoch 068 - generator training loss: -0.0732, discriminator training loss: 0.2131, validation loss: 0.1077
2024-05-23 17:58:43 [INFO]: Epoch 069 - generator training loss: -0.0732, discriminator training loss: 0.2128, validation loss: 0.1074
2024-05-23 17:58:47 [INFO]: Epoch 070 - generator training loss: -0.0727, discriminator training loss: 0.2128, validation loss: 0.1075
2024-05-23 17:58:50 [INFO]: Epoch 071 - generator training loss: -0.0716, discriminator training loss: 0.2121, validation loss: 0.1073
2024-05-23 17:58:53 [INFO]: Epoch 072 - generator training loss: -0.0729, discriminator training loss: 0.2115, validation loss: 0.1065
2024-05-23 17:58:56 [INFO]: Epoch 073 - generator training loss: -0.0733, discriminator training loss: 0.2114, validation loss: 0.1067
2024-05-23 17:59:00 [INFO]: Epoch 074 - generator training loss: -0.0735, discriminator training loss: 0.2114, validation loss: 0.1055
2024-05-23 17:59:03 [INFO]: Epoch 075 - generator training loss: -0.0732, discriminator training loss: 0.2106, validation loss: 0.1059
2024-05-23 17:59:06 [INFO]: Epoch 076 - generator training loss: -0.0734, discriminator training loss: 0.2105, validation loss: 0.1056
2024-05-23 17:59:10 [INFO]: Epoch 077 - generator training loss: -0.0755, discriminator training loss: 0.2100, validation loss: 0.1046
2024-05-23 17:59:13 [INFO]: Epoch 078 - generator training loss: -0.0747, discriminator training loss: 0.2094, validation loss: 0.1046
2024-05-23 17:59:16 [INFO]: Epoch 079 - generator training loss: -0.0746, discriminator training loss: 0.2095, validation loss: 0.1044
2024-05-23 17:59:19 [INFO]: Epoch 080 - generator training loss: -0.0755, discriminator training loss: 0.2092, validation loss: 0.1040
2024-05-23 17:59:23 [INFO]: Epoch 081 - generator training loss: -0.0761, discriminator training loss: 0.2090, validation loss: 0.1046
2024-05-23 17:59:26 [INFO]: Epoch 082 - generator training loss: -0.0750, discriminator training loss: 0.2088, validation loss: 0.1040
2024-05-23 17:59:29 [INFO]: Epoch 083 - generator training loss: -0.0754, discriminator training loss: 0.2082, validation loss: 0.1036
2024-05-23 17:59:32 [INFO]: Epoch 084 - generator training loss: -0.0757, discriminator training loss: 0.2082, validation loss: 0.1042
2024-05-23 17:59:36 [INFO]: Epoch 085 - generator training loss: -0.0751, discriminator training loss: 0.2079, validation loss: 0.1029
2024-05-23 17:59:39 [INFO]: Epoch 086 - generator training loss: -0.0768, discriminator training loss: 0.2075, validation loss: 0.1035
2024-05-23 17:59:42 [INFO]: Epoch 087 - generator training loss: -0.0767, discriminator training loss: 0.2072, validation loss: 0.1034
2024-05-23 17:59:45 [INFO]: Epoch 088 - generator training loss: -0.0759, discriminator training loss: 0.2076, validation loss: 0.1025
2024-05-23 17:59:49 [INFO]: Epoch 089 - generator training loss: -0.0767, discriminator training loss: 0.2072, validation loss: 0.1030
2024-05-23 17:59:52 [INFO]: Epoch 090 - generator training loss: -0.0767, discriminator training loss: 0.2067, validation loss: 0.1027
2024-05-23 17:59:55 [INFO]: Epoch 091 - generator training loss: -0.0771, discriminator training loss: 0.2071, validation loss: 0.1025
2024-05-23 17:59:59 [INFO]: Epoch 092 - generator training loss: -0.0776, discriminator training loss: 0.2067, validation loss: 0.1028
2024-05-23 18:00:02 [INFO]: Epoch 093 - generator training loss: -0.0779, discriminator training loss: 0.2067, validation loss: 0.1020
2024-05-23 18:00:05 [INFO]: Epoch 094 - generator training loss: -0.0773, discriminator training loss: 0.2059, validation loss: 0.1011
2024-05-23 18:00:08 [INFO]: Epoch 095 - generator training loss: -0.0772, discriminator training loss: 0.2057, validation loss: 0.1016
2024-05-23 18:00:12 [INFO]: Epoch 096 - generator training loss: -0.0780, discriminator training loss: 0.2056, validation loss: 0.1011
2024-05-23 18:00:15 [INFO]: Epoch 097 - generator training loss: -0.0780, discriminator training loss: 0.2067, validation loss: 0.1018
2024-05-23 18:00:18 [INFO]: Epoch 098 - generator training loss: -0.0786, discriminator training loss: 0.2055, validation loss: 0.1020
2024-05-23 18:00:21 [INFO]: Epoch 099 - generator training loss: -0.0781, discriminator training loss: 0.2055, validation loss: 0.1016
2024-05-23 18:00:25 [INFO]: Epoch 100 - generator training loss: -0.0784, discriminator training loss: 0.2052, validation loss: 0.1009
2024-05-23 18:00:28 [INFO]: Epoch 101 - generator training loss: -0.0788, discriminator training loss: 0.2054, validation loss: 0.1013
2024-05-23 18:00:31 [INFO]: Epoch 102 - generator training loss: -0.0786, discriminator training loss: 0.2045, validation loss: 0.1006
2024-05-23 18:00:34 [INFO]: Epoch 103 - generator training loss: -0.0794, discriminator training loss: 0.2050, validation loss: 0.1008
2024-05-23 18:00:38 [INFO]: Epoch 104 - generator training loss: -0.0781, discriminator training loss: 0.2050, validation loss: 0.1007
2024-05-23 18:00:41 [INFO]: Epoch 105 - generator training loss: -0.0787, discriminator training loss: 0.2047, validation loss: 0.1005
2024-05-23 18:00:44 [INFO]: Epoch 106 - generator training loss: -0.0778, discriminator training loss: 0.2046, validation loss: 0.1006
2024-05-23 18:00:47 [INFO]: Epoch 107 - generator training loss: -0.0787, discriminator training loss: 0.2044, validation loss: 0.0998
2024-05-23 18:00:51 [INFO]: Epoch 108 - generator training loss: -0.0798, discriminator training loss: 0.2045, validation loss: 0.1000
2024-05-23 18:00:54 [INFO]: Epoch 109 - generator training loss: -0.0789, discriminator training loss: 0.2044, validation loss: 0.1006
2024-05-23 18:00:57 [INFO]: Epoch 110 - generator training loss: -0.0807, discriminator training loss: 0.2043, validation loss: 0.0997
2024-05-23 18:01:01 [INFO]: Epoch 111 - generator training loss: -0.0802, discriminator training loss: 0.2035, validation loss: 0.0997
2024-05-23 18:01:04 [INFO]: Epoch 112 - generator training loss: -0.0809, discriminator training loss: 0.2033, validation loss: 0.1001
2024-05-23 18:01:07 [INFO]: Epoch 113 - generator training loss: -0.0808, discriminator training loss: 0.2039, validation loss: 0.1003
2024-05-23 18:01:10 [INFO]: Epoch 114 - generator training loss: -0.0806, discriminator training loss: 0.2031, validation loss: 0.0994
2024-05-23 18:01:14 [INFO]: Epoch 115 - generator training loss: -0.0807, discriminator training loss: 0.2037, validation loss: 0.0991
2024-05-23 18:01:17 [INFO]: Epoch 116 - generator training loss: -0.0816, discriminator training loss: 0.2036, validation loss: 0.0991
2024-05-23 18:01:20 [INFO]: Epoch 117 - generator training loss: -0.0810, discriminator training loss: 0.2032, validation loss: 0.1002
2024-05-23 18:01:23 [INFO]: Epoch 118 - generator training loss: -0.0804, discriminator training loss: 0.2030, validation loss: 0.0984
2024-05-23 18:01:27 [INFO]: Epoch 119 - generator training loss: -0.0812, discriminator training loss: 0.2029, validation loss: 0.0990
2024-05-23 18:01:30 [INFO]: Epoch 120 - generator training loss: -0.0812, discriminator training loss: 0.2023, validation loss: 0.0991
2024-05-23 18:01:33 [INFO]: Epoch 121 - generator training loss: -0.0817, discriminator training loss: 0.2024, validation loss: 0.0988
2024-05-23 18:01:36 [INFO]: Epoch 122 - generator training loss: -0.0817, discriminator training loss: 0.2032, validation loss: 0.0990
2024-05-23 18:01:40 [INFO]: Epoch 123 - generator training loss: -0.0818, discriminator training loss: 0.2025, validation loss: 0.0989
2024-05-23 18:01:43 [INFO]: Epoch 124 - generator training loss: -0.0825, discriminator training loss: 0.2024, validation loss: 0.0985
2024-05-23 18:01:46 [INFO]: Epoch 125 - generator training loss: -0.0809, discriminator training loss: 0.2025, validation loss: 0.0989
2024-05-23 18:01:49 [INFO]: Epoch 126 - generator training loss: -0.0822, discriminator training loss: 0.2025, validation loss: 0.0997
2024-05-23 18:01:53 [INFO]: Epoch 127 - generator training loss: -0.0816, discriminator training loss: 0.2022, validation loss: 0.0988
2024-05-23 18:01:56 [INFO]: Epoch 128 - generator training loss: -0.0816, discriminator training loss: 0.2018, validation loss: 0.0995
2024-05-23 18:01:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:01:56 [INFO]: Finished training. The best model is from epoch#118.
2024-05-23 18:01:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240523_T175455/USGAN.pypots
2024-05-23 18:01:57 [INFO]: US-GAN on Air-Quality: MAE=0.1497, MSE=0.1222
2024-05-23 18:01:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-23 18:01:57 [INFO]: Using the given device: cuda:0
2024-05-23 18:01:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240523_T180157
2024-05-23 18:01:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240523_T180157/tensorboard
2024-05-23 18:01:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 18:01:59 [INFO]: Epoch 001 - training loss: 1.4013, validation loss: 0.9319
2024-05-23 18:02:02 [INFO]: Epoch 002 - training loss: 1.1345, validation loss: 0.6953
2024-05-23 18:02:04 [INFO]: Epoch 003 - training loss: 0.9460, validation loss: 0.5894
2024-05-23 18:02:06 [INFO]: Epoch 004 - training loss: 0.8386, validation loss: 0.5230
2024-05-23 18:02:08 [INFO]: Epoch 005 - training loss: 0.7672, validation loss: 0.4757
2024-05-23 18:02:10 [INFO]: Epoch 006 - training loss: 0.7117, validation loss: 0.4386
2024-05-23 18:02:13 [INFO]: Epoch 007 - training loss: 0.6693, validation loss: 0.4100
2024-05-23 18:02:15 [INFO]: Epoch 008 - training loss: 0.6351, validation loss: 0.3861
2024-05-23 18:02:17 [INFO]: Epoch 009 - training loss: 0.6114, validation loss: 0.3661
2024-05-23 18:02:19 [INFO]: Epoch 010 - training loss: 0.5901, validation loss: 0.3499
2024-05-23 18:02:21 [INFO]: Epoch 011 - training loss: 0.5708, validation loss: 0.3348
2024-05-23 18:02:23 [INFO]: Epoch 012 - training loss: 0.5557, validation loss: 0.3235
2024-05-23 18:02:26 [INFO]: Epoch 013 - training loss: 0.5427, validation loss: 0.3128
2024-05-23 18:02:28 [INFO]: Epoch 014 - training loss: 0.5311, validation loss: 0.3034
2024-05-23 18:02:30 [INFO]: Epoch 015 - training loss: 0.5201, validation loss: 0.2949
2024-05-23 18:02:32 [INFO]: Epoch 016 - training loss: 0.5125, validation loss: 0.2876
2024-05-23 18:02:34 [INFO]: Epoch 017 - training loss: 0.5019, validation loss: 0.2807
2024-05-23 18:02:37 [INFO]: Epoch 018 - training loss: 0.4939, validation loss: 0.2748
2024-05-23 18:02:39 [INFO]: Epoch 019 - training loss: 0.4859, validation loss: 0.2695
2024-05-23 18:02:41 [INFO]: Epoch 020 - training loss: 0.4794, validation loss: 0.2640
2024-05-23 18:02:43 [INFO]: Epoch 021 - training loss: 0.4718, validation loss: 0.2593
2024-05-23 18:02:45 [INFO]: Epoch 022 - training loss: 0.4647, validation loss: 0.2549
2024-05-23 18:02:47 [INFO]: Epoch 023 - training loss: 0.4587, validation loss: 0.2503
2024-05-23 18:02:50 [INFO]: Epoch 024 - training loss: 0.4529, validation loss: 0.2464
2024-05-23 18:02:52 [INFO]: Epoch 025 - training loss: 0.4469, validation loss: 0.2422
2024-05-23 18:02:54 [INFO]: Epoch 026 - training loss: 0.4421, validation loss: 0.2386
2024-05-23 18:02:56 [INFO]: Epoch 027 - training loss: 0.4358, validation loss: 0.2347
2024-05-23 18:02:59 [INFO]: Epoch 028 - training loss: 0.4304, validation loss: 0.2315
2024-05-23 18:03:01 [INFO]: Epoch 029 - training loss: 0.4256, validation loss: 0.2279
2024-05-23 18:03:03 [INFO]: Epoch 030 - training loss: 0.4205, validation loss: 0.2248
2024-05-23 18:03:05 [INFO]: Epoch 031 - training loss: 0.4171, validation loss: 0.2219
2024-05-23 18:03:07 [INFO]: Epoch 032 - training loss: 0.4124, validation loss: 0.2190
2024-05-23 18:03:09 [INFO]: Epoch 033 - training loss: 0.4090, validation loss: 0.2158
2024-05-23 18:03:12 [INFO]: Epoch 034 - training loss: 0.4041, validation loss: 0.2134
2024-05-23 18:03:14 [INFO]: Epoch 035 - training loss: 0.4001, validation loss: 0.2105
2024-05-23 18:03:16 [INFO]: Epoch 036 - training loss: 0.3966, validation loss: 0.2082
2024-05-23 18:03:18 [INFO]: Epoch 037 - training loss: 0.3930, validation loss: 0.2051
2024-05-23 18:03:20 [INFO]: Epoch 038 - training loss: 0.3904, validation loss: 0.2026
2024-05-23 18:03:23 [INFO]: Epoch 039 - training loss: 0.3862, validation loss: 0.2008
2024-05-23 18:03:25 [INFO]: Epoch 040 - training loss: 0.3825, validation loss: 0.1985
2024-05-23 18:03:27 [INFO]: Epoch 041 - training loss: 0.3800, validation loss: 0.1962
2024-05-23 18:03:29 [INFO]: Epoch 042 - training loss: 0.3760, validation loss: 0.1945
2024-05-23 18:03:31 [INFO]: Epoch 043 - training loss: 0.3735, validation loss: 0.1923
2024-05-23 18:03:34 [INFO]: Epoch 044 - training loss: 0.3705, validation loss: 0.1906
2024-05-23 18:03:36 [INFO]: Epoch 045 - training loss: 0.3680, validation loss: 0.1885
2024-05-23 18:03:38 [INFO]: Epoch 046 - training loss: 0.3648, validation loss: 0.1868
2024-05-23 18:03:40 [INFO]: Epoch 047 - training loss: 0.3633, validation loss: 0.1854
2024-05-23 18:03:42 [INFO]: Epoch 048 - training loss: 0.3596, validation loss: 0.1828
2024-05-23 18:03:44 [INFO]: Epoch 049 - training loss: 0.3582, validation loss: 0.1813
2024-05-23 18:03:47 [INFO]: Epoch 050 - training loss: 0.3547, validation loss: 0.1802
2024-05-23 18:03:49 [INFO]: Epoch 051 - training loss: 0.3528, validation loss: 0.1788
2024-05-23 18:03:51 [INFO]: Epoch 052 - training loss: 0.3501, validation loss: 0.1775
2024-05-23 18:03:53 [INFO]: Epoch 053 - training loss: 0.3479, validation loss: 0.1758
2024-05-23 18:03:55 [INFO]: Epoch 054 - training loss: 0.3464, validation loss: 0.1741
2024-05-23 18:03:58 [INFO]: Epoch 055 - training loss: 0.3445, validation loss: 0.1728
2024-05-23 18:04:00 [INFO]: Epoch 056 - training loss: 0.3425, validation loss: 0.1720
2024-05-23 18:04:02 [INFO]: Epoch 057 - training loss: 0.3401, validation loss: 0.1709
2024-05-23 18:04:04 [INFO]: Epoch 058 - training loss: 0.3384, validation loss: 0.1693
2024-05-23 18:04:06 [INFO]: Epoch 059 - training loss: 0.3371, validation loss: 0.1686
2024-05-23 18:04:09 [INFO]: Epoch 060 - training loss: 0.3341, validation loss: 0.1670
2024-05-23 18:04:11 [INFO]: Epoch 061 - training loss: 0.3324, validation loss: 0.1662
2024-05-23 18:04:13 [INFO]: Epoch 062 - training loss: 0.3308, validation loss: 0.1652
2024-05-23 18:04:15 [INFO]: Epoch 063 - training loss: 0.3301, validation loss: 0.1640
2024-05-23 18:04:17 [INFO]: Epoch 064 - training loss: 0.3283, validation loss: 0.1636
2024-05-23 18:04:19 [INFO]: Epoch 065 - training loss: 0.3278, validation loss: 0.1622
2024-05-23 18:04:22 [INFO]: Epoch 066 - training loss: 0.3248, validation loss: 0.1612
2024-05-23 18:04:24 [INFO]: Epoch 067 - training loss: 0.3240, validation loss: 0.1601
2024-05-23 18:04:26 [INFO]: Epoch 068 - training loss: 0.3230, validation loss: 0.1591
2024-05-23 18:04:28 [INFO]: Epoch 069 - training loss: 0.3214, validation loss: 0.1583
2024-05-23 18:04:31 [INFO]: Epoch 070 - training loss: 0.3213, validation loss: 0.1576
2024-05-23 18:04:33 [INFO]: Epoch 071 - training loss: 0.3190, validation loss: 0.1560
2024-05-23 18:04:35 [INFO]: Epoch 072 - training loss: 0.3178, validation loss: 0.1552
2024-05-23 18:04:37 [INFO]: Epoch 073 - training loss: 0.3163, validation loss: 0.1545
2024-05-23 18:04:39 [INFO]: Epoch 074 - training loss: 0.3164, validation loss: 0.1538
2024-05-23 18:04:41 [INFO]: Epoch 075 - training loss: 0.3150, validation loss: 0.1531
2024-05-23 18:04:44 [INFO]: Epoch 076 - training loss: 0.3132, validation loss: 0.1522
2024-05-23 18:04:46 [INFO]: Epoch 077 - training loss: 0.3122, validation loss: 0.1516
2024-05-23 18:04:48 [INFO]: Epoch 078 - training loss: 0.3110, validation loss: 0.1506
2024-05-23 18:04:50 [INFO]: Epoch 079 - training loss: 0.3113, validation loss: 0.1498
2024-05-23 18:04:52 [INFO]: Epoch 080 - training loss: 0.3106, validation loss: 0.1490
2024-05-23 18:04:55 [INFO]: Epoch 081 - training loss: 0.3088, validation loss: 0.1483
2024-05-23 18:04:57 [INFO]: Epoch 082 - training loss: 0.3071, validation loss: 0.1478
2024-05-23 18:04:59 [INFO]: Epoch 083 - training loss: 0.3063, validation loss: 0.1468
2024-05-23 18:05:01 [INFO]: Epoch 084 - training loss: 0.3056, validation loss: 0.1463
2024-05-23 18:05:03 [INFO]: Epoch 085 - training loss: 0.3050, validation loss: 0.1456
2024-05-23 18:05:06 [INFO]: Epoch 086 - training loss: 0.3045, validation loss: 0.1449
2024-05-23 18:05:08 [INFO]: Epoch 087 - training loss: 0.3032, validation loss: 0.1442
2024-05-23 18:05:10 [INFO]: Epoch 088 - training loss: 0.3017, validation loss: 0.1436
2024-05-23 18:05:12 [INFO]: Epoch 089 - training loss: 0.3012, validation loss: 0.1428
2024-05-23 18:05:14 [INFO]: Epoch 090 - training loss: 0.3008, validation loss: 0.1422
2024-05-23 18:05:17 [INFO]: Epoch 091 - training loss: 0.3005, validation loss: 0.1418
2024-05-23 18:05:19 [INFO]: Epoch 092 - training loss: 0.2995, validation loss: 0.1410
2024-05-23 18:05:21 [INFO]: Epoch 093 - training loss: 0.2986, validation loss: 0.1404
2024-05-23 18:05:23 [INFO]: Epoch 094 - training loss: 0.2987, validation loss: 0.1397
2024-05-23 18:05:25 [INFO]: Epoch 095 - training loss: 0.2973, validation loss: 0.1393
2024-05-23 18:05:28 [INFO]: Epoch 096 - training loss: 0.2959, validation loss: 0.1387
2024-05-23 18:05:30 [INFO]: Epoch 097 - training loss: 0.2960, validation loss: 0.1380
2024-05-23 18:05:32 [INFO]: Epoch 098 - training loss: 0.2952, validation loss: 0.1374
2024-05-23 18:05:34 [INFO]: Epoch 099 - training loss: 0.2947, validation loss: 0.1370
2024-05-23 18:05:36 [INFO]: Epoch 100 - training loss: 0.2937, validation loss: 0.1363
2024-05-23 18:05:38 [INFO]: Epoch 101 - training loss: 0.2932, validation loss: 0.1358
2024-05-23 18:05:41 [INFO]: Epoch 102 - training loss: 0.2919, validation loss: 0.1354
2024-05-23 18:05:43 [INFO]: Epoch 103 - training loss: 0.2919, validation loss: 0.1348
2024-05-23 18:05:45 [INFO]: Epoch 104 - training loss: 0.2914, validation loss: 0.1341
2024-05-23 18:05:47 [INFO]: Epoch 105 - training loss: 0.2901, validation loss: 0.1337
2024-05-23 18:05:49 [INFO]: Epoch 106 - training loss: 0.2904, validation loss: 0.1330
2024-05-23 18:05:52 [INFO]: Epoch 107 - training loss: 0.2893, validation loss: 0.1327
2024-05-23 18:05:54 [INFO]: Epoch 108 - training loss: 0.2885, validation loss: 0.1319
2024-05-23 18:05:56 [INFO]: Epoch 109 - training loss: 0.2884, validation loss: 0.1316
2024-05-23 18:05:58 [INFO]: Epoch 110 - training loss: 0.2877, validation loss: 0.1313
2024-05-23 18:06:00 [INFO]: Epoch 111 - training loss: 0.2874, validation loss: 0.1307
2024-05-23 18:06:03 [INFO]: Epoch 112 - training loss: 0.2863, validation loss: 0.1303
2024-05-23 18:06:05 [INFO]: Epoch 113 - training loss: 0.2862, validation loss: 0.1297
2024-05-23 18:06:07 [INFO]: Epoch 114 - training loss: 0.2856, validation loss: 0.1294
2024-05-23 18:06:09 [INFO]: Epoch 115 - training loss: 0.2852, validation loss: 0.1289
2024-05-23 18:06:11 [INFO]: Epoch 116 - training loss: 0.2844, validation loss: 0.1285
2024-05-23 18:06:14 [INFO]: Epoch 117 - training loss: 0.2837, validation loss: 0.1281
2024-05-23 18:06:16 [INFO]: Epoch 118 - training loss: 0.2839, validation loss: 0.1275
2024-05-23 18:06:18 [INFO]: Epoch 119 - training loss: 0.2828, validation loss: 0.1271
2024-05-23 18:06:20 [INFO]: Epoch 120 - training loss: 0.2824, validation loss: 0.1267
2024-05-23 18:06:22 [INFO]: Epoch 121 - training loss: 0.2821, validation loss: 0.1261
2024-05-23 18:06:25 [INFO]: Epoch 122 - training loss: 0.2815, validation loss: 0.1257
2024-05-23 18:06:27 [INFO]: Epoch 123 - training loss: 0.2811, validation loss: 0.1256
2024-05-23 18:06:29 [INFO]: Epoch 124 - training loss: 0.2805, validation loss: 0.1251
2024-05-23 18:06:31 [INFO]: Epoch 125 - training loss: 0.2803, validation loss: 0.1246
2024-05-23 18:06:33 [INFO]: Epoch 126 - training loss: 0.2794, validation loss: 0.1239
2024-05-23 18:06:36 [INFO]: Epoch 127 - training loss: 0.2792, validation loss: 0.1238
2024-05-23 18:06:38 [INFO]: Epoch 128 - training loss: 0.2784, validation loss: 0.1233
2024-05-23 18:06:40 [INFO]: Epoch 129 - training loss: 0.2787, validation loss: 0.1230
2024-05-23 18:06:42 [INFO]: Epoch 130 - training loss: 0.2784, validation loss: 0.1227
2024-05-23 18:06:44 [INFO]: Epoch 131 - training loss: 0.2776, validation loss: 0.1223
2024-05-23 18:06:46 [INFO]: Epoch 132 - training loss: 0.2765, validation loss: 0.1222
2024-05-23 18:06:49 [INFO]: Epoch 133 - training loss: 0.2767, validation loss: 0.1215
2024-05-23 18:06:51 [INFO]: Epoch 134 - training loss: 0.2766, validation loss: 0.1212
2024-05-23 18:06:53 [INFO]: Epoch 135 - training loss: 0.2757, validation loss: 0.1209
2024-05-23 18:06:55 [INFO]: Epoch 136 - training loss: 0.2754, validation loss: 0.1202
2024-05-23 18:06:57 [INFO]: Epoch 137 - training loss: 0.2747, validation loss: 0.1201
2024-05-23 18:07:00 [INFO]: Epoch 138 - training loss: 0.2745, validation loss: 0.1198
2024-05-23 18:07:02 [INFO]: Epoch 139 - training loss: 0.2749, validation loss: 0.1193
2024-05-23 18:07:04 [INFO]: Epoch 140 - training loss: 0.2738, validation loss: 0.1190
2024-05-23 18:07:06 [INFO]: Epoch 141 - training loss: 0.2732, validation loss: 0.1189
2024-05-23 18:07:08 [INFO]: Epoch 142 - training loss: 0.2730, validation loss: 0.1185
2024-05-23 18:07:10 [INFO]: Epoch 143 - training loss: 0.2730, validation loss: 0.1181
2024-05-23 18:07:13 [INFO]: Epoch 144 - training loss: 0.2729, validation loss: 0.1178
2024-05-23 18:07:15 [INFO]: Epoch 145 - training loss: 0.2716, validation loss: 0.1173
2024-05-23 18:07:17 [INFO]: Epoch 146 - training loss: 0.2716, validation loss: 0.1171
2024-05-23 18:07:19 [INFO]: Epoch 147 - training loss: 0.2715, validation loss: 0.1167
2024-05-23 18:07:21 [INFO]: Epoch 148 - training loss: 0.2711, validation loss: 0.1165
2024-05-23 18:07:24 [INFO]: Epoch 149 - training loss: 0.2712, validation loss: 0.1163
2024-05-23 18:07:26 [INFO]: Epoch 150 - training loss: 0.2701, validation loss: 0.1157
2024-05-23 18:07:28 [INFO]: Epoch 151 - training loss: 0.2698, validation loss: 0.1155
2024-05-23 18:07:30 [INFO]: Epoch 152 - training loss: 0.2697, validation loss: 0.1151
2024-05-23 18:07:32 [INFO]: Epoch 153 - training loss: 0.2695, validation loss: 0.1149
2024-05-23 18:07:35 [INFO]: Epoch 154 - training loss: 0.2690, validation loss: 0.1146
2024-05-23 18:07:37 [INFO]: Epoch 155 - training loss: 0.2687, validation loss: 0.1143
2024-05-23 18:07:39 [INFO]: Epoch 156 - training loss: 0.2685, validation loss: 0.1141
2024-05-23 18:07:41 [INFO]: Epoch 157 - training loss: 0.2679, validation loss: 0.1137
2024-05-23 18:07:43 [INFO]: Epoch 158 - training loss: 0.2679, validation loss: 0.1133
2024-05-23 18:07:46 [INFO]: Epoch 159 - training loss: 0.2676, validation loss: 0.1132
2024-05-23 18:07:48 [INFO]: Epoch 160 - training loss: 0.2669, validation loss: 0.1129
2024-05-23 18:07:50 [INFO]: Epoch 161 - training loss: 0.2668, validation loss: 0.1127
2024-05-23 18:07:52 [INFO]: Epoch 162 - training loss: 0.2669, validation loss: 0.1123
2024-05-23 18:07:54 [INFO]: Epoch 163 - training loss: 0.2662, validation loss: 0.1121
2024-05-23 18:07:57 [INFO]: Epoch 164 - training loss: 0.2659, validation loss: 0.1117
2024-05-23 18:07:59 [INFO]: Epoch 165 - training loss: 0.2655, validation loss: 0.1114
2024-05-23 18:08:01 [INFO]: Epoch 166 - training loss: 0.2649, validation loss: 0.1115
2024-05-23 18:08:03 [INFO]: Epoch 167 - training loss: 0.2650, validation loss: 0.1109
2024-05-23 18:08:05 [INFO]: Epoch 168 - training loss: 0.2647, validation loss: 0.1109
2024-05-23 18:08:07 [INFO]: Epoch 169 - training loss: 0.2641, validation loss: 0.1105
2024-05-23 18:08:10 [INFO]: Epoch 170 - training loss: 0.2640, validation loss: 0.1103
2024-05-23 18:08:12 [INFO]: Epoch 171 - training loss: 0.2638, validation loss: 0.1102
2024-05-23 18:08:14 [INFO]: Epoch 172 - training loss: 0.2635, validation loss: 0.1099
2024-05-23 18:08:16 [INFO]: Epoch 173 - training loss: 0.2630, validation loss: 0.1096
2024-05-23 18:08:18 [INFO]: Epoch 174 - training loss: 0.2636, validation loss: 0.1092
2024-05-23 18:08:21 [INFO]: Epoch 175 - training loss: 0.2630, validation loss: 0.1090
2024-05-23 18:08:23 [INFO]: Epoch 176 - training loss: 0.2621, validation loss: 0.1090
2024-05-23 18:08:25 [INFO]: Epoch 177 - training loss: 0.2619, validation loss: 0.1086
2024-05-23 18:08:27 [INFO]: Epoch 178 - training loss: 0.2619, validation loss: 0.1083
2024-05-23 18:08:29 [INFO]: Epoch 179 - training loss: 0.2620, validation loss: 0.1082
2024-05-23 18:08:31 [INFO]: Epoch 180 - training loss: 0.2616, validation loss: 0.1081
2024-05-23 18:08:34 [INFO]: Epoch 181 - training loss: 0.2613, validation loss: 0.1076
2024-05-23 18:08:36 [INFO]: Epoch 182 - training loss: 0.2614, validation loss: 0.1075
2024-05-23 18:08:38 [INFO]: Epoch 183 - training loss: 0.2608, validation loss: 0.1073
2024-05-23 18:08:40 [INFO]: Epoch 184 - training loss: 0.2600, validation loss: 0.1070
2024-05-23 18:08:42 [INFO]: Epoch 185 - training loss: 0.2597, validation loss: 0.1068
2024-05-23 18:08:45 [INFO]: Epoch 186 - training loss: 0.2599, validation loss: 0.1065
2024-05-23 18:08:47 [INFO]: Epoch 187 - training loss: 0.2604, validation loss: 0.1065
2024-05-23 18:08:49 [INFO]: Epoch 188 - training loss: 0.2595, validation loss: 0.1062
2024-05-23 18:08:51 [INFO]: Epoch 189 - training loss: 0.2594, validation loss: 0.1060
2024-05-23 18:08:53 [INFO]: Epoch 190 - training loss: 0.2590, validation loss: 0.1058
2024-05-23 18:08:56 [INFO]: Epoch 191 - training loss: 0.2591, validation loss: 0.1054
2024-05-23 18:08:58 [INFO]: Epoch 192 - training loss: 0.2585, validation loss: 0.1052
2024-05-23 18:09:00 [INFO]: Epoch 193 - training loss: 0.2582, validation loss: 0.1052
2024-05-23 18:09:02 [INFO]: Epoch 194 - training loss: 0.2580, validation loss: 0.1050
2024-05-23 18:09:04 [INFO]: Epoch 195 - training loss: 0.2587, validation loss: 0.1049
2024-05-23 18:09:06 [INFO]: Epoch 196 - training loss: 0.2574, validation loss: 0.1044
2024-05-23 18:09:09 [INFO]: Epoch 197 - training loss: 0.2573, validation loss: 0.1043
2024-05-23 18:09:11 [INFO]: Epoch 198 - training loss: 0.2575, validation loss: 0.1040
2024-05-23 18:09:13 [INFO]: Epoch 199 - training loss: 0.2570, validation loss: 0.1039
2024-05-23 18:09:15 [INFO]: Epoch 200 - training loss: 0.2566, validation loss: 0.1036
2024-05-23 18:09:17 [INFO]: Epoch 201 - training loss: 0.2570, validation loss: 0.1035
2024-05-23 18:09:20 [INFO]: Epoch 202 - training loss: 0.2566, validation loss: 0.1034
2024-05-23 18:09:22 [INFO]: Epoch 203 - training loss: 0.2557, validation loss: 0.1031
2024-05-23 18:09:24 [INFO]: Epoch 204 - training loss: 0.2558, validation loss: 0.1030
2024-05-23 18:09:26 [INFO]: Epoch 205 - training loss: 0.2555, validation loss: 0.1029
2024-05-23 18:09:28 [INFO]: Epoch 206 - training loss: 0.2555, validation loss: 0.1026
2024-05-23 18:09:31 [INFO]: Epoch 207 - training loss: 0.2553, validation loss: 0.1025
2024-05-23 18:09:33 [INFO]: Epoch 208 - training loss: 0.2551, validation loss: 0.1024
2024-05-23 18:09:35 [INFO]: Epoch 209 - training loss: 0.2547, validation loss: 0.1022
2024-05-23 18:09:37 [INFO]: Epoch 210 - training loss: 0.2548, validation loss: 0.1019
2024-05-23 18:09:39 [INFO]: Epoch 211 - training loss: 0.2545, validation loss: 0.1020
2024-05-23 18:09:42 [INFO]: Epoch 212 - training loss: 0.2550, validation loss: 0.1018
2024-05-23 18:09:44 [INFO]: Epoch 213 - training loss: 0.2538, validation loss: 0.1014
2024-05-23 18:09:46 [INFO]: Epoch 214 - training loss: 0.2537, validation loss: 0.1013
2024-05-23 18:09:48 [INFO]: Epoch 215 - training loss: 0.2534, validation loss: 0.1013
2024-05-23 18:09:50 [INFO]: Epoch 216 - training loss: 0.2532, validation loss: 0.1010
2024-05-23 18:09:52 [INFO]: Epoch 217 - training loss: 0.2534, validation loss: 0.1009
2024-05-23 18:09:55 [INFO]: Epoch 218 - training loss: 0.2529, validation loss: 0.1007
2024-05-23 18:09:57 [INFO]: Epoch 219 - training loss: 0.2530, validation loss: 0.1005
2024-05-23 18:09:59 [INFO]: Epoch 220 - training loss: 0.2522, validation loss: 0.1004
2024-05-23 18:10:01 [INFO]: Epoch 221 - training loss: 0.2526, validation loss: 0.1004
2024-05-23 18:10:03 [INFO]: Epoch 222 - training loss: 0.2523, validation loss: 0.1000
2024-05-23 18:10:06 [INFO]: Epoch 223 - training loss: 0.2531, validation loss: 0.1002
2024-05-23 18:10:08 [INFO]: Epoch 224 - training loss: 0.2519, validation loss: 0.0998
2024-05-23 18:10:10 [INFO]: Epoch 225 - training loss: 0.2515, validation loss: 0.0996
2024-05-23 18:10:12 [INFO]: Epoch 226 - training loss: 0.2515, validation loss: 0.0994
2024-05-23 18:10:14 [INFO]: Epoch 227 - training loss: 0.2514, validation loss: 0.0994
2024-05-23 18:10:17 [INFO]: Epoch 228 - training loss: 0.2515, validation loss: 0.0992
2024-05-23 18:10:19 [INFO]: Epoch 229 - training loss: 0.2509, validation loss: 0.0991
2024-05-23 18:10:21 [INFO]: Epoch 230 - training loss: 0.2516, validation loss: 0.0990
2024-05-23 18:10:23 [INFO]: Epoch 231 - training loss: 0.2506, validation loss: 0.0987
2024-05-23 18:10:25 [INFO]: Epoch 232 - training loss: 0.2502, validation loss: 0.0987
2024-05-23 18:10:27 [INFO]: Epoch 233 - training loss: 0.2501, validation loss: 0.0985
2024-05-23 18:10:30 [INFO]: Epoch 234 - training loss: 0.2508, validation loss: 0.0984
2024-05-23 18:10:32 [INFO]: Epoch 235 - training loss: 0.2494, validation loss: 0.0983
2024-05-23 18:10:34 [INFO]: Epoch 236 - training loss: 0.2496, validation loss: 0.0981
2024-05-23 18:10:36 [INFO]: Epoch 237 - training loss: 0.2497, validation loss: 0.0979
2024-05-23 18:10:38 [INFO]: Epoch 238 - training loss: 0.2492, validation loss: 0.0977
2024-05-23 18:10:41 [INFO]: Epoch 239 - training loss: 0.2499, validation loss: 0.0977
2024-05-23 18:10:43 [INFO]: Epoch 240 - training loss: 0.2491, validation loss: 0.0974
2024-05-23 18:10:45 [INFO]: Epoch 241 - training loss: 0.2487, validation loss: 0.0977
2024-05-23 18:10:47 [INFO]: Epoch 242 - training loss: 0.2486, validation loss: 0.0974
2024-05-23 18:10:49 [INFO]: Epoch 243 - training loss: 0.2486, validation loss: 0.0971
2024-05-23 18:10:52 [INFO]: Epoch 244 - training loss: 0.2487, validation loss: 0.0973
2024-05-23 18:10:54 [INFO]: Epoch 245 - training loss: 0.2487, validation loss: 0.0969
2024-05-23 18:10:56 [INFO]: Epoch 246 - training loss: 0.2480, validation loss: 0.0970
2024-05-23 18:10:58 [INFO]: Epoch 247 - training loss: 0.2489, validation loss: 0.0969
2024-05-23 18:11:01 [INFO]: Epoch 248 - training loss: 0.2479, validation loss: 0.0965
2024-05-23 18:11:03 [INFO]: Epoch 249 - training loss: 0.2481, validation loss: 0.0965
2024-05-23 18:11:05 [INFO]: Epoch 250 - training loss: 0.2481, validation loss: 0.0965
2024-05-23 18:11:07 [INFO]: Epoch 251 - training loss: 0.2471, validation loss: 0.0963
2024-05-23 18:11:09 [INFO]: Epoch 252 - training loss: 0.2478, validation loss: 0.0961
2024-05-23 18:11:11 [INFO]: Epoch 253 - training loss: 0.2470, validation loss: 0.0961
2024-05-23 18:11:14 [INFO]: Epoch 254 - training loss: 0.2468, validation loss: 0.0959
2024-05-23 18:11:16 [INFO]: Epoch 255 - training loss: 0.2466, validation loss: 0.0958
2024-05-23 18:11:18 [INFO]: Epoch 256 - training loss: 0.2465, validation loss: 0.0959
2024-05-23 18:11:20 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0956
2024-05-23 18:11:22 [INFO]: Epoch 258 - training loss: 0.2464, validation loss: 0.0955
2024-05-23 18:11:25 [INFO]: Epoch 259 - training loss: 0.2459, validation loss: 0.0954
2024-05-23 18:11:27 [INFO]: Epoch 260 - training loss: 0.2461, validation loss: 0.0953
2024-05-23 18:11:29 [INFO]: Epoch 261 - training loss: 0.2460, validation loss: 0.0952
2024-05-23 18:11:31 [INFO]: Epoch 262 - training loss: 0.2456, validation loss: 0.0951
2024-05-23 18:11:33 [INFO]: Epoch 263 - training loss: 0.2455, validation loss: 0.0950
2024-05-23 18:11:36 [INFO]: Epoch 264 - training loss: 0.2460, validation loss: 0.0950
2024-05-23 18:11:38 [INFO]: Epoch 265 - training loss: 0.2459, validation loss: 0.0949
2024-05-23 18:11:40 [INFO]: Epoch 266 - training loss: 0.2450, validation loss: 0.0945
2024-05-23 18:11:42 [INFO]: Epoch 267 - training loss: 0.2452, validation loss: 0.0946
2024-05-23 18:11:44 [INFO]: Epoch 268 - training loss: 0.2451, validation loss: 0.0945
2024-05-23 18:11:47 [INFO]: Epoch 269 - training loss: 0.2448, validation loss: 0.0943
2024-05-23 18:11:49 [INFO]: Epoch 270 - training loss: 0.2442, validation loss: 0.0943
2024-05-23 18:11:51 [INFO]: Epoch 271 - training loss: 0.2443, validation loss: 0.0942
2024-05-23 18:11:53 [INFO]: Epoch 272 - training loss: 0.2441, validation loss: 0.0941
2024-05-23 18:11:55 [INFO]: Epoch 273 - training loss: 0.2446, validation loss: 0.0939
2024-05-23 18:11:58 [INFO]: Epoch 274 - training loss: 0.2439, validation loss: 0.0939
2024-05-23 18:12:00 [INFO]: Epoch 275 - training loss: 0.2436, validation loss: 0.0939
2024-05-23 18:12:02 [INFO]: Epoch 276 - training loss: 0.2436, validation loss: 0.0937
2024-05-23 18:12:04 [INFO]: Epoch 277 - training loss: 0.2436, validation loss: 0.0937
2024-05-23 18:12:06 [INFO]: Epoch 278 - training loss: 0.2433, validation loss: 0.0935
2024-05-23 18:12:08 [INFO]: Epoch 279 - training loss: 0.2435, validation loss: 0.0935
2024-05-23 18:12:11 [INFO]: Epoch 280 - training loss: 0.2435, validation loss: 0.0934
2024-05-23 18:12:13 [INFO]: Epoch 281 - training loss: 0.2431, validation loss: 0.0933
2024-05-23 18:12:15 [INFO]: Epoch 282 - training loss: 0.2429, validation loss: 0.0933
2024-05-23 18:12:17 [INFO]: Epoch 283 - training loss: 0.2429, validation loss: 0.0932
2024-05-23 18:12:19 [INFO]: Epoch 284 - training loss: 0.2430, validation loss: 0.0933
2024-05-23 18:12:22 [INFO]: Epoch 285 - training loss: 0.2425, validation loss: 0.0931
2024-05-23 18:12:24 [INFO]: Epoch 286 - training loss: 0.2424, validation loss: 0.0930
2024-05-23 18:12:26 [INFO]: Epoch 287 - training loss: 0.2421, validation loss: 0.0929
2024-05-23 18:12:28 [INFO]: Epoch 288 - training loss: 0.2421, validation loss: 0.0929
2024-05-23 18:12:30 [INFO]: Epoch 289 - training loss: 0.2418, validation loss: 0.0926
2024-05-23 18:12:33 [INFO]: Epoch 290 - training loss: 0.2422, validation loss: 0.0925
2024-05-23 18:12:35 [INFO]: Epoch 291 - training loss: 0.2424, validation loss: 0.0925
2024-05-23 18:12:37 [INFO]: Epoch 292 - training loss: 0.2420, validation loss: 0.0927
2024-05-23 18:12:39 [INFO]: Epoch 293 - training loss: 0.2415, validation loss: 0.0924
2024-05-23 18:12:42 [INFO]: Epoch 294 - training loss: 0.2415, validation loss: 0.0925
2024-05-23 18:12:44 [INFO]: Epoch 295 - training loss: 0.2424, validation loss: 0.0924
2024-05-23 18:12:46 [INFO]: Epoch 296 - training loss: 0.2415, validation loss: 0.0923
2024-05-23 18:12:48 [INFO]: Epoch 297 - training loss: 0.2414, validation loss: 0.0919
2024-05-23 18:12:50 [INFO]: Epoch 298 - training loss: 0.2410, validation loss: 0.0920
2024-05-23 18:12:52 [INFO]: Epoch 299 - training loss: 0.2411, validation loss: 0.0919
2024-05-23 18:12:55 [INFO]: Epoch 300 - training loss: 0.2407, validation loss: 0.0919
2024-05-23 18:12:55 [INFO]: Finished training. The best model is from epoch#300.
2024-05-23 18:12:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240523_T180157/BRITS.pypots
2024-05-23 18:12:55 [INFO]: BRITS on Air-Quality: MAE=0.1412, MSE=0.1281
2024-05-23 18:12:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-23 18:12:55 [INFO]: Using the given device: cuda:0
2024-05-23 18:12:55 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255
2024-05-23 18:12:55 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/tensorboard
2024-05-23 18:12:55 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 18:12:59 [INFO]: Epoch 001 - training loss: 1.4258, validation loss: 0.8161
2024-05-23 18:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch1_loss0.8160501629114151.pypots
2024-05-23 18:13:02 [INFO]: Epoch 002 - training loss: 1.0164, validation loss: 0.7567
2024-05-23 18:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch2_loss0.7567083686590195.pypots
2024-05-23 18:13:05 [INFO]: Epoch 003 - training loss: 0.9689, validation loss: 0.7361
2024-05-23 18:13:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch3_loss0.7361088007688522.pypots
2024-05-23 18:13:08 [INFO]: Epoch 004 - training loss: 0.9522, validation loss: 0.7234
2024-05-23 18:13:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch4_loss0.7233743786811828.pypots
2024-05-23 18:13:11 [INFO]: Epoch 005 - training loss: 0.9345, validation loss: 0.7143
2024-05-23 18:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch5_loss0.7143172442913055.pypots
2024-05-23 18:13:14 [INFO]: Epoch 006 - training loss: 0.9129, validation loss: 0.7079
2024-05-23 18:13:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch6_loss0.7079125851392746.pypots
2024-05-23 18:13:17 [INFO]: Epoch 007 - training loss: 0.9226, validation loss: 0.7034
2024-05-23 18:13:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch7_loss0.7034196496009827.pypots
2024-05-23 18:13:20 [INFO]: Epoch 008 - training loss: 0.9063, validation loss: 0.6995
2024-05-23 18:13:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch8_loss0.6995001643896103.pypots
2024-05-23 18:13:23 [INFO]: Epoch 009 - training loss: 0.8951, validation loss: 0.6966
2024-05-23 18:13:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch9_loss0.6965722024440766.pypots
2024-05-23 18:13:26 [INFO]: Epoch 010 - training loss: 0.8914, validation loss: 0.6941
2024-05-23 18:13:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch10_loss0.6941341310739517.pypots
2024-05-23 18:13:29 [INFO]: Epoch 011 - training loss: 0.8846, validation loss: 0.6926
2024-05-23 18:13:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch11_loss0.6925504088401795.pypots
2024-05-23 18:13:32 [INFO]: Epoch 012 - training loss: 0.8875, validation loss: 0.6908
2024-05-23 18:13:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch12_loss0.6907837748527527.pypots
2024-05-23 18:13:35 [INFO]: Epoch 013 - training loss: 0.8870, validation loss: 0.6908
2024-05-23 18:13:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch13_loss0.6908113330602645.pypots
2024-05-23 18:13:38 [INFO]: Epoch 014 - training loss: 0.8857, validation loss: 0.6890
2024-05-23 18:13:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch14_loss0.6889877468347549.pypots
2024-05-23 18:13:41 [INFO]: Epoch 015 - training loss: 0.8708, validation loss: 0.6889
2024-05-23 18:13:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch15_loss0.6889106452465057.pypots
2024-05-23 18:13:44 [INFO]: Epoch 016 - training loss: 0.8662, validation loss: 0.6873
2024-05-23 18:13:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch16_loss0.6873176723718644.pypots
2024-05-23 18:13:47 [INFO]: Epoch 017 - training loss: 0.8712, validation loss: 0.6865
2024-05-23 18:13:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch17_loss0.6865002453327179.pypots
2024-05-23 18:13:50 [INFO]: Epoch 018 - training loss: 0.8912, validation loss: 0.6856
2024-05-23 18:13:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch18_loss0.6855894356966019.pypots
2024-05-23 18:13:53 [INFO]: Epoch 019 - training loss: 0.8663, validation loss: 0.6880
2024-05-23 18:13:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch19_loss0.6880427122116088.pypots
2024-05-23 18:13:56 [INFO]: Epoch 020 - training loss: 0.8559, validation loss: 0.6858
2024-05-23 18:13:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch20_loss0.6858154356479644.pypots
2024-05-23 18:13:59 [INFO]: Epoch 021 - training loss: 0.8514, validation loss: 0.6850
2024-05-23 18:13:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch21_loss0.6849965274333953.pypots
2024-05-23 18:14:02 [INFO]: Epoch 022 - training loss: 0.8573, validation loss: 0.6844
2024-05-23 18:14:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch22_loss0.68437060713768.pypots
2024-05-23 18:14:05 [INFO]: Epoch 023 - training loss: 0.8520, validation loss: 0.6844
2024-05-23 18:14:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch23_loss0.6843696892261505.pypots
2024-05-23 18:14:08 [INFO]: Epoch 024 - training loss: 0.8623, validation loss: 0.6856
2024-05-23 18:14:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch24_loss0.6855966240167618.pypots
2024-05-23 18:14:11 [INFO]: Epoch 025 - training loss: 0.8406, validation loss: 0.6871
2024-05-23 18:14:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch25_loss0.6870639741420745.pypots
2024-05-23 18:14:14 [INFO]: Epoch 026 - training loss: 0.8474, validation loss: 0.6843
2024-05-23 18:14:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch26_loss0.6843052536249161.pypots
2024-05-23 18:14:17 [INFO]: Epoch 027 - training loss: 0.8375, validation loss: 0.6848
2024-05-23 18:14:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch27_loss0.684786906838417.pypots
2024-05-23 18:14:20 [INFO]: Epoch 028 - training loss: 0.8422, validation loss: 0.6853
2024-05-23 18:14:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch28_loss0.6852875232696534.pypots
2024-05-23 18:14:24 [INFO]: Epoch 029 - training loss: 0.8442, validation loss: 0.6845
2024-05-23 18:14:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch29_loss0.684545424580574.pypots
2024-05-23 18:14:27 [INFO]: Epoch 030 - training loss: 0.8450, validation loss: 0.6853
2024-05-23 18:14:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch30_loss0.6853078842163086.pypots
2024-05-23 18:14:30 [INFO]: Epoch 031 - training loss: 0.8363, validation loss: 0.6844
2024-05-23 18:14:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch31_loss0.6844445407390595.pypots
2024-05-23 18:14:33 [INFO]: Epoch 032 - training loss: 0.8273, validation loss: 0.6859
2024-05-23 18:14:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch32_loss0.6858837217092514.pypots
2024-05-23 18:14:36 [INFO]: Epoch 033 - training loss: 0.8384, validation loss: 0.6863
2024-05-23 18:14:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch33_loss0.6862683057785034.pypots
2024-05-23 18:14:39 [INFO]: Epoch 034 - training loss: 0.8410, validation loss: 0.6858
2024-05-23 18:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch34_loss0.6858381241559982.pypots
2024-05-23 18:14:42 [INFO]: Epoch 035 - training loss: 0.8530, validation loss: 0.6893
2024-05-23 18:14:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch35_loss0.6893376857042313.pypots
2024-05-23 18:14:45 [INFO]: Epoch 036 - training loss: 0.8617, validation loss: 0.6864
2024-05-23 18:14:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN_epoch36_loss0.6863898605108261.pypots
2024-05-23 18:14:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:14:45 [INFO]: Finished training. The best model is from epoch#26.
2024-05-23 18:14:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240523_T181255/MRNN.pypots
2024-05-23 18:14:46 [INFO]: MRNN on Air-Quality: MAE=0.5181, MSE=0.6578
2024-05-23 18:14:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-23 18:14:46 [INFO]: Using the given device: cpu
2024-05-23 18:14:46 [INFO]: LOCF on Air-Quality: MAE=0.2050, MSE=0.3453
2024-05-23 18:14:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-23 18:14:46 [INFO]: Median on Air-Quality: MAE=0.6635, MSE=1.0575
2024-05-23 18:14:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-23 18:14:46 [INFO]: Mean on Air-Quality: MAE=0.6949, MSE=0.9966
2024-05-23 18:14:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-23 18:14:46 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-23 18:14:46 [INFO]: Using the given device: cuda:0
2024-05-23 18:14:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240523_T181446
2024-05-23 18:14:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240523_T181446/tensorboard
2024-05-23 18:14:46 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 18:14:47 [INFO]: Epoch 001 - training loss: 1.0348, validation loss: 0.5257
2024-05-23 18:14:47 [INFO]: Epoch 002 - training loss: 0.7363, validation loss: 0.4013
2024-05-23 18:14:48 [INFO]: Epoch 003 - training loss: 0.6281, validation loss: 0.3230
2024-05-23 18:14:48 [INFO]: Epoch 004 - training loss: 0.5571, validation loss: 0.2845
2024-05-23 18:14:49 [INFO]: Epoch 005 - training loss: 0.5080, validation loss: 0.2576
2024-05-23 18:14:49 [INFO]: Epoch 006 - training loss: 0.4737, validation loss: 0.2437
2024-05-23 18:14:50 [INFO]: Epoch 007 - training loss: 0.4479, validation loss: 0.2336
2024-05-23 18:14:51 [INFO]: Epoch 008 - training loss: 0.4297, validation loss: 0.2255
2024-05-23 18:14:51 [INFO]: Epoch 009 - training loss: 0.4150, validation loss: 0.2196
2024-05-23 18:14:52 [INFO]: Epoch 010 - training loss: 0.4034, validation loss: 0.2134
2024-05-23 18:14:52 [INFO]: Epoch 011 - training loss: 0.3934, validation loss: 0.2087
2024-05-23 18:14:53 [INFO]: Epoch 012 - training loss: 0.3850, validation loss: 0.2040
2024-05-23 18:14:54 [INFO]: Epoch 013 - training loss: 0.3774, validation loss: 0.2020
2024-05-23 18:14:54 [INFO]: Epoch 014 - training loss: 0.3705, validation loss: 0.1987
2024-05-23 18:14:55 [INFO]: Epoch 015 - training loss: 0.3628, validation loss: 0.1953
2024-05-23 18:14:55 [INFO]: Epoch 016 - training loss: 0.3588, validation loss: 0.1936
2024-05-23 18:14:56 [INFO]: Epoch 017 - training loss: 0.3523, validation loss: 0.1904
2024-05-23 18:14:56 [INFO]: Epoch 018 - training loss: 0.3473, validation loss: 0.1883
2024-05-23 18:14:57 [INFO]: Epoch 019 - training loss: 0.3428, validation loss: 0.1854
2024-05-23 18:14:58 [INFO]: Epoch 020 - training loss: 0.3394, validation loss: 0.1838
2024-05-23 18:14:58 [INFO]: Epoch 021 - training loss: 0.3349, validation loss: 0.1814
2024-05-23 18:14:59 [INFO]: Epoch 022 - training loss: 0.3331, validation loss: 0.1807
2024-05-23 18:14:59 [INFO]: Epoch 023 - training loss: 0.3277, validation loss: 0.1780
2024-05-23 18:15:00 [INFO]: Epoch 024 - training loss: 0.3233, validation loss: 0.1776
2024-05-23 18:15:01 [INFO]: Epoch 025 - training loss: 0.3197, validation loss: 0.1755
2024-05-23 18:15:01 [INFO]: Epoch 026 - training loss: 0.3200, validation loss: 0.1742
2024-05-23 18:15:02 [INFO]: Epoch 027 - training loss: 0.3158, validation loss: 0.1727
2024-05-23 18:15:02 [INFO]: Epoch 028 - training loss: 0.3130, validation loss: 0.1707
2024-05-23 18:15:03 [INFO]: Epoch 029 - training loss: 0.3093, validation loss: 0.1700
2024-05-23 18:15:04 [INFO]: Epoch 030 - training loss: 0.3080, validation loss: 0.1669
2024-05-23 18:15:04 [INFO]: Epoch 031 - training loss: 0.3054, validation loss: 0.1659
2024-05-23 18:15:05 [INFO]: Epoch 032 - training loss: 0.3032, validation loss: 0.1654
2024-05-23 18:15:05 [INFO]: Epoch 033 - training loss: 0.3001, validation loss: 0.1639
2024-05-23 18:15:06 [INFO]: Epoch 034 - training loss: 0.2978, validation loss: 0.1618
2024-05-23 18:15:06 [INFO]: Epoch 035 - training loss: 0.2951, validation loss: 0.1598
2024-05-23 18:15:07 [INFO]: Epoch 036 - training loss: 0.2944, validation loss: 0.1583
2024-05-23 18:15:08 [INFO]: Epoch 037 - training loss: 0.2913, validation loss: 0.1578
2024-05-23 18:15:08 [INFO]: Epoch 038 - training loss: 0.2893, validation loss: 0.1572
2024-05-23 18:15:09 [INFO]: Epoch 039 - training loss: 0.2867, validation loss: 0.1554
2024-05-23 18:15:09 [INFO]: Epoch 040 - training loss: 0.2856, validation loss: 0.1541
2024-05-23 18:15:10 [INFO]: Epoch 041 - training loss: 0.2837, validation loss: 0.1533
2024-05-23 18:15:11 [INFO]: Epoch 042 - training loss: 0.2815, validation loss: 0.1528
2024-05-23 18:15:11 [INFO]: Epoch 043 - training loss: 0.2803, validation loss: 0.1519
2024-05-23 18:15:12 [INFO]: Epoch 044 - training loss: 0.2786, validation loss: 0.1503
2024-05-23 18:15:12 [INFO]: Epoch 045 - training loss: 0.2762, validation loss: 0.1505
2024-05-23 18:15:13 [INFO]: Epoch 046 - training loss: 0.2742, validation loss: 0.1487
2024-05-23 18:15:13 [INFO]: Epoch 047 - training loss: 0.2747, validation loss: 0.1489
2024-05-23 18:15:14 [INFO]: Epoch 048 - training loss: 0.2720, validation loss: 0.1469
2024-05-23 18:15:15 [INFO]: Epoch 049 - training loss: 0.2696, validation loss: 0.1465
2024-05-23 18:15:15 [INFO]: Epoch 050 - training loss: 0.2679, validation loss: 0.1461
2024-05-23 18:15:16 [INFO]: Epoch 051 - training loss: 0.2665, validation loss: 0.1448
2024-05-23 18:15:16 [INFO]: Epoch 052 - training loss: 0.2648, validation loss: 0.1443
2024-05-23 18:15:17 [INFO]: Epoch 053 - training loss: 0.2636, validation loss: 0.1438
2024-05-23 18:15:17 [INFO]: Epoch 054 - training loss: 0.2618, validation loss: 0.1441
2024-05-23 18:15:18 [INFO]: Epoch 055 - training loss: 0.2602, validation loss: 0.1424
2024-05-23 18:15:19 [INFO]: Epoch 056 - training loss: 0.2587, validation loss: 0.1422
2024-05-23 18:15:19 [INFO]: Epoch 057 - training loss: 0.2574, validation loss: 0.1414
2024-05-23 18:15:20 [INFO]: Epoch 058 - training loss: 0.2568, validation loss: 0.1417
2024-05-23 18:15:20 [INFO]: Epoch 059 - training loss: 0.2545, validation loss: 0.1412
2024-05-23 18:15:21 [INFO]: Epoch 060 - training loss: 0.2535, validation loss: 0.1396
2024-05-23 18:15:21 [INFO]: Epoch 061 - training loss: 0.2530, validation loss: 0.1395
2024-05-23 18:15:22 [INFO]: Epoch 062 - training loss: 0.2518, validation loss: 0.1402
2024-05-23 18:15:23 [INFO]: Epoch 063 - training loss: 0.2522, validation loss: 0.1395
2024-05-23 18:15:23 [INFO]: Epoch 064 - training loss: 0.2508, validation loss: 0.1389
2024-05-23 18:15:24 [INFO]: Epoch 065 - training loss: 0.2475, validation loss: 0.1396
2024-05-23 18:15:24 [INFO]: Epoch 066 - training loss: 0.2461, validation loss: 0.1379
2024-05-23 18:15:25 [INFO]: Epoch 067 - training loss: 0.2449, validation loss: 0.1381
2024-05-23 18:15:26 [INFO]: Epoch 068 - training loss: 0.2442, validation loss: 0.1380
2024-05-23 18:15:26 [INFO]: Epoch 069 - training loss: 0.2431, validation loss: 0.1370
2024-05-23 18:15:27 [INFO]: Epoch 070 - training loss: 0.2411, validation loss: 0.1368
2024-05-23 18:15:27 [INFO]: Epoch 071 - training loss: 0.2415, validation loss: 0.1365
2024-05-23 18:15:28 [INFO]: Epoch 072 - training loss: 0.2413, validation loss: 0.1359
2024-05-23 18:15:28 [INFO]: Epoch 073 - training loss: 0.2392, validation loss: 0.1355
2024-05-23 18:15:29 [INFO]: Epoch 074 - training loss: 0.2377, validation loss: 0.1360
2024-05-23 18:15:30 [INFO]: Epoch 075 - training loss: 0.2371, validation loss: 0.1351
2024-05-23 18:15:30 [INFO]: Epoch 076 - training loss: 0.2360, validation loss: 0.1342
2024-05-23 18:15:31 [INFO]: Epoch 077 - training loss: 0.2353, validation loss: 0.1338
2024-05-23 18:15:31 [INFO]: Epoch 078 - training loss: 0.2348, validation loss: 0.1337
2024-05-23 18:15:32 [INFO]: Epoch 079 - training loss: 0.2335, validation loss: 0.1338
2024-05-23 18:15:32 [INFO]: Epoch 080 - training loss: 0.2327, validation loss: 0.1332
2024-05-23 18:15:33 [INFO]: Epoch 081 - training loss: 0.2320, validation loss: 0.1338
2024-05-23 18:15:34 [INFO]: Epoch 082 - training loss: 0.2308, validation loss: 0.1334
2024-05-23 18:15:34 [INFO]: Epoch 083 - training loss: 0.2310, validation loss: 0.1326
2024-05-23 18:15:35 [INFO]: Epoch 084 - training loss: 0.2301, validation loss: 0.1322
2024-05-23 18:15:35 [INFO]: Epoch 085 - training loss: 0.2285, validation loss: 0.1323
2024-05-23 18:15:36 [INFO]: Epoch 086 - training loss: 0.2285, validation loss: 0.1326
2024-05-23 18:15:36 [INFO]: Epoch 087 - training loss: 0.2284, validation loss: 0.1328
2024-05-23 18:15:37 [INFO]: Epoch 088 - training loss: 0.2261, validation loss: 0.1312
2024-05-23 18:15:38 [INFO]: Epoch 089 - training loss: 0.2258, validation loss: 0.1304
2024-05-23 18:15:38 [INFO]: Epoch 090 - training loss: 0.2250, validation loss: 0.1312
2024-05-23 18:15:39 [INFO]: Epoch 091 - training loss: 0.2244, validation loss: 0.1313
2024-05-23 18:15:39 [INFO]: Epoch 092 - training loss: 0.2246, validation loss: 0.1309
2024-05-23 18:15:40 [INFO]: Epoch 093 - training loss: 0.2236, validation loss: 0.1308
2024-05-23 18:15:40 [INFO]: Epoch 094 - training loss: 0.2226, validation loss: 0.1306
2024-05-23 18:15:41 [INFO]: Epoch 095 - training loss: 0.2216, validation loss: 0.1305
2024-05-23 18:15:42 [INFO]: Epoch 096 - training loss: 0.2210, validation loss: 0.1294
2024-05-23 18:15:42 [INFO]: Epoch 097 - training loss: 0.2201, validation loss: 0.1301
2024-05-23 18:15:43 [INFO]: Epoch 098 - training loss: 0.2203, validation loss: 0.1291
2024-05-23 18:15:43 [INFO]: Epoch 099 - training loss: 0.2196, validation loss: 0.1297
2024-05-23 18:15:44 [INFO]: Epoch 100 - training loss: 0.2185, validation loss: 0.1290
2024-05-23 18:15:44 [INFO]: Epoch 101 - training loss: 0.2178, validation loss: 0.1292
2024-05-23 18:15:45 [INFO]: Epoch 102 - training loss: 0.2172, validation loss: 0.1288
2024-05-23 18:15:46 [INFO]: Epoch 103 - training loss: 0.2157, validation loss: 0.1281
2024-05-23 18:15:46 [INFO]: Epoch 104 - training loss: 0.2163, validation loss: 0.1271
2024-05-23 18:15:47 [INFO]: Epoch 105 - training loss: 0.2153, validation loss: 0.1273
2024-05-23 18:15:48 [INFO]: Epoch 106 - training loss: 0.2144, validation loss: 0.1280
2024-05-23 18:15:48 [INFO]: Epoch 107 - training loss: 0.2136, validation loss: 0.1274
2024-05-23 18:15:49 [INFO]: Epoch 108 - training loss: 0.2130, validation loss: 0.1275
2024-05-23 18:15:49 [INFO]: Epoch 109 - training loss: 0.2129, validation loss: 0.1267
2024-05-23 18:15:50 [INFO]: Epoch 110 - training loss: 0.2125, validation loss: 0.1276
2024-05-23 18:15:50 [INFO]: Epoch 111 - training loss: 0.2127, validation loss: 0.1269
2024-05-23 18:15:51 [INFO]: Epoch 112 - training loss: 0.2119, validation loss: 0.1271
2024-05-23 18:15:52 [INFO]: Epoch 113 - training loss: 0.2112, validation loss: 0.1268
2024-05-23 18:15:52 [INFO]: Epoch 114 - training loss: 0.2101, validation loss: 0.1268
2024-05-23 18:15:53 [INFO]: Epoch 115 - training loss: 0.2100, validation loss: 0.1270
2024-05-23 18:15:53 [INFO]: Epoch 116 - training loss: 0.2094, validation loss: 0.1263
2024-05-23 18:15:54 [INFO]: Epoch 117 - training loss: 0.2078, validation loss: 0.1259
2024-05-23 18:15:54 [INFO]: Epoch 118 - training loss: 0.2081, validation loss: 0.1262
2024-05-23 18:15:55 [INFO]: Epoch 119 - training loss: 0.2085, validation loss: 0.1262
2024-05-23 18:15:56 [INFO]: Epoch 120 - training loss: 0.2079, validation loss: 0.1259
2024-05-23 18:15:56 [INFO]: Epoch 121 - training loss: 0.2078, validation loss: 0.1273
2024-05-23 18:15:57 [INFO]: Epoch 122 - training loss: 0.2059, validation loss: 0.1251
2024-05-23 18:15:57 [INFO]: Epoch 123 - training loss: 0.2043, validation loss: 0.1237
2024-05-23 18:15:58 [INFO]: Epoch 124 - training loss: 0.2041, validation loss: 0.1243
2024-05-23 18:15:58 [INFO]: Epoch 125 - training loss: 0.2044, validation loss: 0.1255
2024-05-23 18:15:59 [INFO]: Epoch 126 - training loss: 0.2043, validation loss: 0.1245
2024-05-23 18:16:00 [INFO]: Epoch 127 - training loss: 0.2040, validation loss: 0.1259
2024-05-23 18:16:00 [INFO]: Epoch 128 - training loss: 0.2028, validation loss: 0.1254
2024-05-23 18:16:01 [INFO]: Epoch 129 - training loss: 0.2022, validation loss: 0.1242
2024-05-23 18:16:01 [INFO]: Epoch 130 - training loss: 0.2030, validation loss: 0.1250
2024-05-23 18:16:02 [INFO]: Epoch 131 - training loss: 0.2012, validation loss: 0.1237
2024-05-23 18:16:03 [INFO]: Epoch 132 - training loss: 0.2011, validation loss: 0.1234
2024-05-23 18:16:03 [INFO]: Epoch 133 - training loss: 0.2012, validation loss: 0.1230
2024-05-23 18:16:04 [INFO]: Epoch 134 - training loss: 0.1997, validation loss: 0.1224
2024-05-23 18:16:04 [INFO]: Epoch 135 - training loss: 0.1990, validation loss: 0.1237
2024-05-23 18:16:05 [INFO]: Epoch 136 - training loss: 0.1991, validation loss: 0.1228
2024-05-23 18:16:05 [INFO]: Epoch 137 - training loss: 0.1981, validation loss: 0.1232
2024-05-23 18:16:06 [INFO]: Epoch 138 - training loss: 0.1978, validation loss: 0.1229
2024-05-23 18:16:07 [INFO]: Epoch 139 - training loss: 0.1977, validation loss: 0.1224
2024-05-23 18:16:07 [INFO]: Epoch 140 - training loss: 0.1992, validation loss: 0.1238
2024-05-23 18:16:08 [INFO]: Epoch 141 - training loss: 0.1992, validation loss: 0.1238
2024-05-23 18:16:08 [INFO]: Epoch 142 - training loss: 0.1970, validation loss: 0.1228
2024-05-23 18:16:09 [INFO]: Epoch 143 - training loss: 0.1967, validation loss: 0.1223
2024-05-23 18:16:10 [INFO]: Epoch 144 - training loss: 0.1953, validation loss: 0.1216
2024-05-23 18:16:10 [INFO]: Epoch 145 - training loss: 0.1945, validation loss: 0.1223
2024-05-23 18:16:11 [INFO]: Epoch 146 - training loss: 0.1948, validation loss: 0.1232
2024-05-23 18:16:11 [INFO]: Epoch 147 - training loss: 0.1945, validation loss: 0.1221
2024-05-23 18:16:12 [INFO]: Epoch 148 - training loss: 0.1949, validation loss: 0.1229
2024-05-23 18:16:13 [INFO]: Epoch 149 - training loss: 0.1949, validation loss: 0.1211
2024-05-23 18:16:13 [INFO]: Epoch 150 - training loss: 0.1926, validation loss: 0.1203
2024-05-23 18:16:14 [INFO]: Epoch 151 - training loss: 0.1917, validation loss: 0.1210
2024-05-23 18:16:14 [INFO]: Epoch 152 - training loss: 0.1917, validation loss: 0.1214
2024-05-23 18:16:15 [INFO]: Epoch 153 - training loss: 0.1935, validation loss: 0.1212
2024-05-23 18:16:15 [INFO]: Epoch 154 - training loss: 0.1911, validation loss: 0.1215
2024-05-23 18:16:16 [INFO]: Epoch 155 - training loss: 0.1904, validation loss: 0.1206
2024-05-23 18:16:17 [INFO]: Epoch 156 - training loss: 0.1904, validation loss: 0.1216
2024-05-23 18:16:17 [INFO]: Epoch 157 - training loss: 0.1898, validation loss: 0.1210
2024-05-23 18:16:18 [INFO]: Epoch 158 - training loss: 0.1907, validation loss: 0.1206
2024-05-23 18:16:18 [INFO]: Epoch 159 - training loss: 0.1909, validation loss: 0.1222
2024-05-23 18:16:19 [INFO]: Epoch 160 - training loss: 0.1892, validation loss: 0.1200
2024-05-23 18:16:20 [INFO]: Epoch 161 - training loss: 0.1877, validation loss: 0.1201
2024-05-23 18:16:20 [INFO]: Epoch 162 - training loss: 0.1880, validation loss: 0.1202
2024-05-23 18:16:21 [INFO]: Epoch 163 - training loss: 0.1871, validation loss: 0.1207
2024-05-23 18:16:21 [INFO]: Epoch 164 - training loss: 0.1872, validation loss: 0.1194
2024-05-23 18:16:22 [INFO]: Epoch 165 - training loss: 0.1864, validation loss: 0.1185
2024-05-23 18:16:22 [INFO]: Epoch 166 - training loss: 0.1874, validation loss: 0.1192
2024-05-23 18:16:23 [INFO]: Epoch 167 - training loss: 0.1898, validation loss: 0.1202
2024-05-23 18:16:24 [INFO]: Epoch 168 - training loss: 0.1874, validation loss: 0.1201
2024-05-23 18:16:24 [INFO]: Epoch 169 - training loss: 0.1877, validation loss: 0.1202
2024-05-23 18:16:25 [INFO]: Epoch 170 - training loss: 0.1881, validation loss: 0.1197
2024-05-23 18:16:25 [INFO]: Epoch 171 - training loss: 0.1859, validation loss: 0.1204
2024-05-23 18:16:26 [INFO]: Epoch 172 - training loss: 0.1845, validation loss: 0.1190
2024-05-23 18:16:27 [INFO]: Epoch 173 - training loss: 0.1849, validation loss: 0.1187
2024-05-23 18:16:27 [INFO]: Epoch 174 - training loss: 0.1833, validation loss: 0.1184
2024-05-23 18:16:28 [INFO]: Epoch 175 - training loss: 0.1824, validation loss: 0.1190
2024-05-23 18:16:28 [INFO]: Epoch 176 - training loss: 0.1826, validation loss: 0.1198
2024-05-23 18:16:29 [INFO]: Epoch 177 - training loss: 0.1832, validation loss: 0.1203
2024-05-23 18:16:30 [INFO]: Epoch 178 - training loss: 0.1828, validation loss: 0.1191
2024-05-23 18:16:30 [INFO]: Epoch 179 - training loss: 0.1841, validation loss: 0.1200
2024-05-23 18:16:31 [INFO]: Epoch 180 - training loss: 0.1834, validation loss: 0.1183
2024-05-23 18:16:31 [INFO]: Epoch 181 - training loss: 0.1815, validation loss: 0.1178
2024-05-23 18:16:32 [INFO]: Epoch 182 - training loss: 0.1806, validation loss: 0.1182
2024-05-23 18:16:32 [INFO]: Epoch 183 - training loss: 0.1811, validation loss: 0.1183
2024-05-23 18:16:33 [INFO]: Epoch 184 - training loss: 0.1798, validation loss: 0.1188
2024-05-23 18:16:34 [INFO]: Epoch 185 - training loss: 0.1792, validation loss: 0.1176
2024-05-23 18:16:34 [INFO]: Epoch 186 - training loss: 0.1801, validation loss: 0.1185
2024-05-23 18:16:35 [INFO]: Epoch 187 - training loss: 0.1798, validation loss: 0.1182
2024-05-23 18:16:35 [INFO]: Epoch 188 - training loss: 0.1793, validation loss: 0.1184
2024-05-23 18:16:36 [INFO]: Epoch 189 - training loss: 0.1779, validation loss: 0.1190
2024-05-23 18:16:37 [INFO]: Epoch 190 - training loss: 0.1779, validation loss: 0.1178
2024-05-23 18:16:37 [INFO]: Epoch 191 - training loss: 0.1775, validation loss: 0.1173
2024-05-23 18:16:38 [INFO]: Epoch 192 - training loss: 0.1779, validation loss: 0.1175
2024-05-23 18:16:38 [INFO]: Epoch 193 - training loss: 0.1772, validation loss: 0.1172
2024-05-23 18:16:39 [INFO]: Epoch 194 - training loss: 0.1766, validation loss: 0.1183
2024-05-23 18:16:39 [INFO]: Epoch 195 - training loss: 0.1778, validation loss: 0.1173
2024-05-23 18:16:40 [INFO]: Epoch 196 - training loss: 0.1775, validation loss: 0.1174
2024-05-23 18:16:41 [INFO]: Epoch 197 - training loss: 0.1777, validation loss: 0.1178
2024-05-23 18:16:41 [INFO]: Epoch 198 - training loss: 0.1777, validation loss: 0.1165
2024-05-23 18:16:42 [INFO]: Epoch 199 - training loss: 0.1772, validation loss: 0.1168
2024-05-23 18:16:42 [INFO]: Epoch 200 - training loss: 0.1757, validation loss: 0.1172
2024-05-23 18:16:43 [INFO]: Epoch 201 - training loss: 0.1752, validation loss: 0.1164
2024-05-23 18:16:44 [INFO]: Epoch 202 - training loss: 0.1753, validation loss: 0.1169
2024-05-23 18:16:44 [INFO]: Epoch 203 - training loss: 0.1744, validation loss: 0.1183
2024-05-23 18:16:45 [INFO]: Epoch 204 - training loss: 0.1760, validation loss: 0.1177
2024-05-23 18:16:45 [INFO]: Epoch 205 - training loss: 0.1742, validation loss: 0.1171
2024-05-23 18:16:46 [INFO]: Epoch 206 - training loss: 0.1735, validation loss: 0.1159
2024-05-23 18:16:46 [INFO]: Epoch 207 - training loss: 0.1730, validation loss: 0.1170
2024-05-23 18:16:47 [INFO]: Epoch 208 - training loss: 0.1732, validation loss: 0.1169
2024-05-23 18:16:48 [INFO]: Epoch 209 - training loss: 0.1719, validation loss: 0.1171
2024-05-23 18:16:48 [INFO]: Epoch 210 - training loss: 0.1716, validation loss: 0.1178
2024-05-23 18:16:49 [INFO]: Epoch 211 - training loss: 0.1723, validation loss: 0.1177
2024-05-23 18:16:49 [INFO]: Epoch 212 - training loss: 0.1719, validation loss: 0.1168
2024-05-23 18:16:50 [INFO]: Epoch 213 - training loss: 0.1715, validation loss: 0.1173
2024-05-23 18:16:51 [INFO]: Epoch 214 - training loss: 0.1721, validation loss: 0.1175
2024-05-23 18:16:51 [INFO]: Epoch 215 - training loss: 0.1705, validation loss: 0.1163
2024-05-23 18:16:52 [INFO]: Epoch 216 - training loss: 0.1715, validation loss: 0.1161
2024-05-23 18:16:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:16:52 [INFO]: Finished training. The best model is from epoch#206.
2024-05-23 18:16:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240523_T181446/SAITS.pypots
2024-05-23 18:16:52 [INFO]: SAITS on Air-Quality: MAE=0.1502, MSE=0.1521
2024-05-23 18:16:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-23 18:16:52 [INFO]: Using the given device: cuda:0
2024-05-23 18:16:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240523_T181652
2024-05-23 18:16:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240523_T181652/tensorboard
2024-05-23 18:16:52 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 18:16:52 [INFO]: Epoch 001 - training loss: 0.8954, validation loss: 0.4642
2024-05-23 18:16:53 [INFO]: Epoch 002 - training loss: 0.5585, validation loss: 0.3492
2024-05-23 18:16:53 [INFO]: Epoch 003 - training loss: 0.4671, validation loss: 0.2877
2024-05-23 18:16:53 [INFO]: Epoch 004 - training loss: 0.4198, validation loss: 0.2626
2024-05-23 18:16:53 [INFO]: Epoch 005 - training loss: 0.3900, validation loss: 0.2466
2024-05-23 18:16:54 [INFO]: Epoch 006 - training loss: 0.3696, validation loss: 0.2373
2024-05-23 18:16:54 [INFO]: Epoch 007 - training loss: 0.3534, validation loss: 0.2281
2024-05-23 18:16:54 [INFO]: Epoch 008 - training loss: 0.3426, validation loss: 0.2240
2024-05-23 18:16:54 [INFO]: Epoch 009 - training loss: 0.3341, validation loss: 0.2167
2024-05-23 18:16:55 [INFO]: Epoch 010 - training loss: 0.3225, validation loss: 0.2134
2024-05-23 18:16:55 [INFO]: Epoch 011 - training loss: 0.3168, validation loss: 0.2076
2024-05-23 18:16:55 [INFO]: Epoch 012 - training loss: 0.3099, validation loss: 0.2055
2024-05-23 18:16:55 [INFO]: Epoch 013 - training loss: 0.3047, validation loss: 0.2025
2024-05-23 18:16:55 [INFO]: Epoch 014 - training loss: 0.3033, validation loss: 0.1973
2024-05-23 18:16:56 [INFO]: Epoch 015 - training loss: 0.2964, validation loss: 0.1957
2024-05-23 18:16:56 [INFO]: Epoch 016 - training loss: 0.2929, validation loss: 0.1910
2024-05-23 18:16:56 [INFO]: Epoch 017 - training loss: 0.2880, validation loss: 0.1900
2024-05-23 18:16:56 [INFO]: Epoch 018 - training loss: 0.2845, validation loss: 0.1876
2024-05-23 18:16:57 [INFO]: Epoch 019 - training loss: 0.2820, validation loss: 0.1866
2024-05-23 18:16:57 [INFO]: Epoch 020 - training loss: 0.2786, validation loss: 0.1866
2024-05-23 18:16:57 [INFO]: Epoch 021 - training loss: 0.2753, validation loss: 0.1802
2024-05-23 18:16:57 [INFO]: Epoch 022 - training loss: 0.2737, validation loss: 0.1816
2024-05-23 18:16:58 [INFO]: Epoch 023 - training loss: 0.2691, validation loss: 0.1791
2024-05-23 18:16:58 [INFO]: Epoch 024 - training loss: 0.2661, validation loss: 0.1774
2024-05-23 18:16:58 [INFO]: Epoch 025 - training loss: 0.2640, validation loss: 0.1755
2024-05-23 18:16:58 [INFO]: Epoch 026 - training loss: 0.2630, validation loss: 0.1753
2024-05-23 18:16:59 [INFO]: Epoch 027 - training loss: 0.2672, validation loss: 0.1721
2024-05-23 18:16:59 [INFO]: Epoch 028 - training loss: 0.2617, validation loss: 0.1724
2024-05-23 18:16:59 [INFO]: Epoch 029 - training loss: 0.2567, validation loss: 0.1720
2024-05-23 18:16:59 [INFO]: Epoch 030 - training loss: 0.2535, validation loss: 0.1697
2024-05-23 18:17:00 [INFO]: Epoch 031 - training loss: 0.2524, validation loss: 0.1694
2024-05-23 18:17:00 [INFO]: Epoch 032 - training loss: 0.2505, validation loss: 0.1718
2024-05-23 18:17:00 [INFO]: Epoch 033 - training loss: 0.2498, validation loss: 0.1684
2024-05-23 18:17:00 [INFO]: Epoch 034 - training loss: 0.2480, validation loss: 0.1673
2024-05-23 18:17:00 [INFO]: Epoch 035 - training loss: 0.2453, validation loss: 0.1665
2024-05-23 18:17:01 [INFO]: Epoch 036 - training loss: 0.2425, validation loss: 0.1669
2024-05-23 18:17:01 [INFO]: Epoch 037 - training loss: 0.2421, validation loss: 0.1650
2024-05-23 18:17:01 [INFO]: Epoch 038 - training loss: 0.2400, validation loss: 0.1649
2024-05-23 18:17:01 [INFO]: Epoch 039 - training loss: 0.2401, validation loss: 0.1663
2024-05-23 18:17:02 [INFO]: Epoch 040 - training loss: 0.2368, validation loss: 0.1624
2024-05-23 18:17:02 [INFO]: Epoch 041 - training loss: 0.2346, validation loss: 0.1638
2024-05-23 18:17:02 [INFO]: Epoch 042 - training loss: 0.2361, validation loss: 0.1632
2024-05-23 18:17:02 [INFO]: Epoch 043 - training loss: 0.2342, validation loss: 0.1623
2024-05-23 18:17:03 [INFO]: Epoch 044 - training loss: 0.2324, validation loss: 0.1628
2024-05-23 18:17:03 [INFO]: Epoch 045 - training loss: 0.2328, validation loss: 0.1607
2024-05-23 18:17:03 [INFO]: Epoch 046 - training loss: 0.2289, validation loss: 0.1624
2024-05-23 18:17:03 [INFO]: Epoch 047 - training loss: 0.2276, validation loss: 0.1608
2024-05-23 18:17:04 [INFO]: Epoch 048 - training loss: 0.2250, validation loss: 0.1592
2024-05-23 18:17:04 [INFO]: Epoch 049 - training loss: 0.2252, validation loss: 0.1588
2024-05-23 18:17:04 [INFO]: Epoch 050 - training loss: 0.2238, validation loss: 0.1593
2024-05-23 18:17:04 [INFO]: Epoch 051 - training loss: 0.2223, validation loss: 0.1606
2024-05-23 18:17:04 [INFO]: Epoch 052 - training loss: 0.2217, validation loss: 0.1591
2024-05-23 18:17:05 [INFO]: Epoch 053 - training loss: 0.2219, validation loss: 0.1586
2024-05-23 18:17:05 [INFO]: Epoch 054 - training loss: 0.2203, validation loss: 0.1587
2024-05-23 18:17:05 [INFO]: Epoch 055 - training loss: 0.2185, validation loss: 0.1574
2024-05-23 18:17:05 [INFO]: Epoch 056 - training loss: 0.2149, validation loss: 0.1565
2024-05-23 18:17:06 [INFO]: Epoch 057 - training loss: 0.2142, validation loss: 0.1558
2024-05-23 18:17:06 [INFO]: Epoch 058 - training loss: 0.2158, validation loss: 0.1586
2024-05-23 18:17:06 [INFO]: Epoch 059 - training loss: 0.2130, validation loss: 0.1572
2024-05-23 18:17:06 [INFO]: Epoch 060 - training loss: 0.2125, validation loss: 0.1554
2024-05-23 18:17:07 [INFO]: Epoch 061 - training loss: 0.2111, validation loss: 0.1545
2024-05-23 18:17:07 [INFO]: Epoch 062 - training loss: 0.2092, validation loss: 0.1548
2024-05-23 18:17:07 [INFO]: Epoch 063 - training loss: 0.2083, validation loss: 0.1544
2024-05-23 18:17:07 [INFO]: Epoch 064 - training loss: 0.2082, validation loss: 0.1529
2024-05-23 18:17:08 [INFO]: Epoch 065 - training loss: 0.2079, validation loss: 0.1537
2024-05-23 18:17:08 [INFO]: Epoch 066 - training loss: 0.2057, validation loss: 0.1528
2024-05-23 18:17:08 [INFO]: Epoch 067 - training loss: 0.2047, validation loss: 0.1530
2024-05-23 18:17:08 [INFO]: Epoch 068 - training loss: 0.2034, validation loss: 0.1547
2024-05-23 18:17:09 [INFO]: Epoch 069 - training loss: 0.2043, validation loss: 0.1526
2024-05-23 18:17:09 [INFO]: Epoch 070 - training loss: 0.2037, validation loss: 0.1526
2024-05-23 18:17:09 [INFO]: Epoch 071 - training loss: 0.2030, validation loss: 0.1524
2024-05-23 18:17:09 [INFO]: Epoch 072 - training loss: 0.2009, validation loss: 0.1509
2024-05-23 18:17:09 [INFO]: Epoch 073 - training loss: 0.2004, validation loss: 0.1527
2024-05-23 18:17:10 [INFO]: Epoch 074 - training loss: 0.2002, validation loss: 0.1525
2024-05-23 18:17:10 [INFO]: Epoch 075 - training loss: 0.2020, validation loss: 0.1542
2024-05-23 18:17:10 [INFO]: Epoch 076 - training loss: 0.2017, validation loss: 0.1483
2024-05-23 18:17:10 [INFO]: Epoch 077 - training loss: 0.1965, validation loss: 0.1504
2024-05-23 18:17:11 [INFO]: Epoch 078 - training loss: 0.1971, validation loss: 0.1504
2024-05-23 18:17:11 [INFO]: Epoch 079 - training loss: 0.1953, validation loss: 0.1490
2024-05-23 18:17:11 [INFO]: Epoch 080 - training loss: 0.1926, validation loss: 0.1508
2024-05-23 18:17:11 [INFO]: Epoch 081 - training loss: 0.1938, validation loss: 0.1483
2024-05-23 18:17:12 [INFO]: Epoch 082 - training loss: 0.1936, validation loss: 0.1500
2024-05-23 18:17:12 [INFO]: Epoch 083 - training loss: 0.1966, validation loss: 0.1500
2024-05-23 18:17:12 [INFO]: Epoch 084 - training loss: 0.1984, validation loss: 0.1481
2024-05-23 18:17:12 [INFO]: Epoch 085 - training loss: 0.1905, validation loss: 0.1480
2024-05-23 18:17:13 [INFO]: Epoch 086 - training loss: 0.1888, validation loss: 0.1469
2024-05-23 18:17:13 [INFO]: Epoch 087 - training loss: 0.1865, validation loss: 0.1475
2024-05-23 18:17:13 [INFO]: Epoch 088 - training loss: 0.1853, validation loss: 0.1465
2024-05-23 18:17:13 [INFO]: Epoch 089 - training loss: 0.1863, validation loss: 0.1471
2024-05-23 18:17:13 [INFO]: Epoch 090 - training loss: 0.1855, validation loss: 0.1457
2024-05-23 18:17:14 [INFO]: Epoch 091 - training loss: 0.1851, validation loss: 0.1473
2024-05-23 18:17:14 [INFO]: Epoch 092 - training loss: 0.1856, validation loss: 0.1455
2024-05-23 18:17:14 [INFO]: Epoch 093 - training loss: 0.1846, validation loss: 0.1449
2024-05-23 18:17:14 [INFO]: Epoch 094 - training loss: 0.1852, validation loss: 0.1467
2024-05-23 18:17:15 [INFO]: Epoch 095 - training loss: 0.1847, validation loss: 0.1483
2024-05-23 18:17:15 [INFO]: Epoch 096 - training loss: 0.1850, validation loss: 0.1469
2024-05-23 18:17:15 [INFO]: Epoch 097 - training loss: 0.1850, validation loss: 0.1475
2024-05-23 18:17:15 [INFO]: Epoch 098 - training loss: 0.1808, validation loss: 0.1440
2024-05-23 18:17:16 [INFO]: Epoch 099 - training loss: 0.1793, validation loss: 0.1450
2024-05-23 18:17:16 [INFO]: Epoch 100 - training loss: 0.1801, validation loss: 0.1442
2024-05-23 18:17:16 [INFO]: Epoch 101 - training loss: 0.1795, validation loss: 0.1446
2024-05-23 18:17:16 [INFO]: Epoch 102 - training loss: 0.1795, validation loss: 0.1440
2024-05-23 18:17:17 [INFO]: Epoch 103 - training loss: 0.1784, validation loss: 0.1471
2024-05-23 18:17:17 [INFO]: Epoch 104 - training loss: 0.1791, validation loss: 0.1444
2024-05-23 18:17:17 [INFO]: Epoch 105 - training loss: 0.1769, validation loss: 0.1451
2024-05-23 18:17:17 [INFO]: Epoch 106 - training loss: 0.1746, validation loss: 0.1438
2024-05-23 18:17:18 [INFO]: Epoch 107 - training loss: 0.1728, validation loss: 0.1438
2024-05-23 18:17:18 [INFO]: Epoch 108 - training loss: 0.1733, validation loss: 0.1433
2024-05-23 18:17:18 [INFO]: Epoch 109 - training loss: 0.1707, validation loss: 0.1429
2024-05-23 18:17:18 [INFO]: Epoch 110 - training loss: 0.1718, validation loss: 0.1432
2024-05-23 18:17:18 [INFO]: Epoch 111 - training loss: 0.1718, validation loss: 0.1417
2024-05-23 18:17:19 [INFO]: Epoch 112 - training loss: 0.1715, validation loss: 0.1440
2024-05-23 18:17:19 [INFO]: Epoch 113 - training loss: 0.1714, validation loss: 0.1424
2024-05-23 18:17:19 [INFO]: Epoch 114 - training loss: 0.1697, validation loss: 0.1427
2024-05-23 18:17:19 [INFO]: Epoch 115 - training loss: 0.1693, validation loss: 0.1423
2024-05-23 18:17:20 [INFO]: Epoch 116 - training loss: 0.1694, validation loss: 0.1433
2024-05-23 18:17:20 [INFO]: Epoch 117 - training loss: 0.1683, validation loss: 0.1411
2024-05-23 18:17:20 [INFO]: Epoch 118 - training loss: 0.1698, validation loss: 0.1444
2024-05-23 18:17:20 [INFO]: Epoch 119 - training loss: 0.1687, validation loss: 0.1415
2024-05-23 18:17:21 [INFO]: Epoch 120 - training loss: 0.1683, validation loss: 0.1425
2024-05-23 18:17:21 [INFO]: Epoch 121 - training loss: 0.1682, validation loss: 0.1437
2024-05-23 18:17:21 [INFO]: Epoch 122 - training loss: 0.1649, validation loss: 0.1410
2024-05-23 18:17:21 [INFO]: Epoch 123 - training loss: 0.1646, validation loss: 0.1424
2024-05-23 18:17:22 [INFO]: Epoch 124 - training loss: 0.1633, validation loss: 0.1422
2024-05-23 18:17:22 [INFO]: Epoch 125 - training loss: 0.1634, validation loss: 0.1404
2024-05-23 18:17:22 [INFO]: Epoch 126 - training loss: 0.1625, validation loss: 0.1427
2024-05-23 18:17:22 [INFO]: Epoch 127 - training loss: 0.1624, validation loss: 0.1413
2024-05-23 18:17:22 [INFO]: Epoch 128 - training loss: 0.1632, validation loss: 0.1431
2024-05-23 18:17:23 [INFO]: Epoch 129 - training loss: 0.1640, validation loss: 0.1400
2024-05-23 18:17:23 [INFO]: Epoch 130 - training loss: 0.1612, validation loss: 0.1399
2024-05-23 18:17:23 [INFO]: Epoch 131 - training loss: 0.1600, validation loss: 0.1415
2024-05-23 18:17:23 [INFO]: Epoch 132 - training loss: 0.1590, validation loss: 0.1386
2024-05-23 18:17:24 [INFO]: Epoch 133 - training loss: 0.1593, validation loss: 0.1399
2024-05-23 18:17:24 [INFO]: Epoch 134 - training loss: 0.1574, validation loss: 0.1403
2024-05-23 18:17:24 [INFO]: Epoch 135 - training loss: 0.1573, validation loss: 0.1398
2024-05-23 18:17:24 [INFO]: Epoch 136 - training loss: 0.1580, validation loss: 0.1398
2024-05-23 18:17:25 [INFO]: Epoch 137 - training loss: 0.1579, validation loss: 0.1377
2024-05-23 18:17:25 [INFO]: Epoch 138 - training loss: 0.1594, validation loss: 0.1408
2024-05-23 18:17:25 [INFO]: Epoch 139 - training loss: 0.1598, validation loss: 0.1402
2024-05-23 18:17:25 [INFO]: Epoch 140 - training loss: 0.1576, validation loss: 0.1399
2024-05-23 18:17:26 [INFO]: Epoch 141 - training loss: 0.1561, validation loss: 0.1409
2024-05-23 18:17:26 [INFO]: Epoch 142 - training loss: 0.1561, validation loss: 0.1408
2024-05-23 18:17:26 [INFO]: Epoch 143 - training loss: 0.1545, validation loss: 0.1397
2024-05-23 18:17:26 [INFO]: Epoch 144 - training loss: 0.1546, validation loss: 0.1416
2024-05-23 18:17:27 [INFO]: Epoch 145 - training loss: 0.1553, validation loss: 0.1385
2024-05-23 18:17:27 [INFO]: Epoch 146 - training loss: 0.1522, validation loss: 0.1397
2024-05-23 18:17:27 [INFO]: Epoch 147 - training loss: 0.1535, validation loss: 0.1385
2024-05-23 18:17:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:17:27 [INFO]: Finished training. The best model is from epoch#137.
2024-05-23 18:17:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240523_T181652/Transformer.pypots
2024-05-23 18:17:27 [INFO]: Transformer on Air-Quality: MAE=0.1721, MSE=0.1798
2024-05-23 18:17:27 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-23 18:17:27 [INFO]: Using the given device: cuda:0
2024-05-23 18:17:27 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181727
2024-05-23 18:17:27 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181727/tensorboard
2024-05-23 18:17:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 18:17:28 [INFO]: Epoch 001 - training loss: 0.2931, validation loss: 0.2608
2024-05-23 18:17:28 [INFO]: Epoch 002 - training loss: 0.2147, validation loss: 0.2443
2024-05-23 18:17:29 [INFO]: Epoch 003 - training loss: 0.1758, validation loss: 0.2193
2024-05-23 18:17:29 [INFO]: Epoch 004 - training loss: 0.1538, validation loss: 0.2072
2024-05-23 18:17:30 [INFO]: Epoch 005 - training loss: 0.1470, validation loss: 0.2024
2024-05-23 18:17:30 [INFO]: Epoch 006 - training loss: 0.1423, validation loss: 0.1961
2024-05-23 18:17:31 [INFO]: Epoch 007 - training loss: 0.1297, validation loss: 0.1954
2024-05-23 18:17:31 [INFO]: Epoch 008 - training loss: 0.1198, validation loss: 0.1925
2024-05-23 18:17:31 [INFO]: Epoch 009 - training loss: 0.1151, validation loss: 0.1872
2024-05-23 18:17:32 [INFO]: Epoch 010 - training loss: 0.1066, validation loss: 0.1874
2024-05-23 18:17:32 [INFO]: Epoch 011 - training loss: 0.0983, validation loss: 0.1842
2024-05-23 18:17:33 [INFO]: Epoch 012 - training loss: 0.0951, validation loss: 0.1807
2024-05-23 18:17:33 [INFO]: Epoch 013 - training loss: 0.0950, validation loss: 0.1914
2024-05-23 18:17:34 [INFO]: Epoch 014 - training loss: 0.0930, validation loss: 0.1830
2024-05-23 18:17:34 [INFO]: Epoch 015 - training loss: 0.0827, validation loss: 0.1998
2024-05-23 18:17:34 [INFO]: Epoch 016 - training loss: 0.0816, validation loss: 0.1950
2024-05-23 18:17:35 [INFO]: Epoch 017 - training loss: 0.0788, validation loss: 0.1989
2024-05-23 18:17:35 [INFO]: Epoch 018 - training loss: 0.0793, validation loss: 0.2014
2024-05-23 18:17:36 [INFO]: Epoch 019 - training loss: 0.0827, validation loss: 0.1846
2024-05-23 18:17:36 [INFO]: Epoch 020 - training loss: 0.0792, validation loss: 0.1889
2024-05-23 18:17:37 [INFO]: Epoch 021 - training loss: 0.0753, validation loss: 0.1833
2024-05-23 18:17:37 [INFO]: Epoch 022 - training loss: 0.0706, validation loss: 0.1896
2024-05-23 18:17:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:17:37 [INFO]: Finished training. The best model is from epoch#12.
2024-05-23 18:17:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181727/TimesNet.pypots
2024-05-23 18:17:37 [INFO]: TimesNet on Air-Quality: MAE=0.1718, MSE=0.2175
2024-05-23 18:17:37 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-23 18:17:37 [INFO]: Using the given device: cuda:0
2024-05-23 18:17:37 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737
2024-05-23 18:17:37 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/tensorboard
2024-05-23 18:17:37 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 18:17:54 [INFO]: Epoch 001 - training loss: 0.5049, validation loss: 0.3187
2024-05-23 18:17:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch1_loss0.3187040686607361.pypots
2024-05-23 18:18:10 [INFO]: Epoch 002 - training loss: 0.2951, validation loss: 0.2622
2024-05-23 18:18:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch2_loss0.26224041134119036.pypots
2024-05-23 18:18:27 [INFO]: Epoch 003 - training loss: 0.2507, validation loss: 0.2352
2024-05-23 18:18:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch3_loss0.2352302387356758.pypots
2024-05-23 18:18:43 [INFO]: Epoch 004 - training loss: 0.2341, validation loss: 0.2167
2024-05-23 18:18:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch4_loss0.21666526794433594.pypots
2024-05-23 18:18:59 [INFO]: Epoch 005 - training loss: 0.2102, validation loss: 0.1961
2024-05-23 18:19:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch5_loss0.19611517786979676.pypots
2024-05-23 18:19:16 [INFO]: Epoch 006 - training loss: 0.1815, validation loss: 0.1786
2024-05-23 18:19:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch6_loss0.17855383455753326.pypots
2024-05-23 18:19:32 [INFO]: Epoch 007 - training loss: 0.1763, validation loss: 0.1679
2024-05-23 18:19:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch7_loss0.1678639531135559.pypots
2024-05-23 18:19:49 [INFO]: Epoch 008 - training loss: 0.1666, validation loss: 0.1578
2024-05-23 18:19:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch8_loss0.15781237185001373.pypots
2024-05-23 18:20:05 [INFO]: Epoch 009 - training loss: 0.1600, validation loss: 0.1509
2024-05-23 18:20:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch9_loss0.15086520910263063.pypots
2024-05-23 18:20:21 [INFO]: Epoch 010 - training loss: 0.1823, validation loss: 0.1529
2024-05-23 18:20:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch10_loss0.1528835266828537.pypots
2024-05-23 18:20:38 [INFO]: Epoch 011 - training loss: 0.1692, validation loss: 0.1468
2024-05-23 18:20:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch11_loss0.14683831632137298.pypots
2024-05-23 18:20:54 [INFO]: Epoch 012 - training loss: 0.1472, validation loss: 0.1472
2024-05-23 18:20:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch12_loss0.14724890142679214.pypots
2024-05-23 18:21:11 [INFO]: Epoch 013 - training loss: 0.1429, validation loss: 0.1469
2024-05-23 18:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch13_loss0.14694059044122695.pypots
2024-05-23 18:21:27 [INFO]: Epoch 014 - training loss: 0.1589, validation loss: 0.1466
2024-05-23 18:21:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch14_loss0.14657497704029082.pypots
2024-05-23 18:21:43 [INFO]: Epoch 015 - training loss: 0.1561, validation loss: 0.1433
2024-05-23 18:21:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch15_loss0.14326226934790612.pypots
2024-05-23 18:22:00 [INFO]: Epoch 016 - training loss: 0.1794, validation loss: 0.1422
2024-05-23 18:22:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch16_loss0.14221126213669777.pypots
2024-05-23 18:22:16 [INFO]: Epoch 017 - training loss: 0.1575, validation loss: 0.1425
2024-05-23 18:22:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch17_loss0.14249603524804116.pypots
2024-05-23 18:22:33 [INFO]: Epoch 018 - training loss: 0.1349, validation loss: 0.1387
2024-05-23 18:22:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch18_loss0.13871775716543197.pypots
2024-05-23 18:22:49 [INFO]: Epoch 019 - training loss: 0.1481, validation loss: 0.1455
2024-05-23 18:22:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch19_loss0.14553572684526445.pypots
2024-05-23 18:23:05 [INFO]: Epoch 020 - training loss: 0.1437, validation loss: 0.1474
2024-05-23 18:23:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch20_loss0.14743150025606155.pypots
2024-05-23 18:23:22 [INFO]: Epoch 021 - training loss: 0.1503, validation loss: 0.1404
2024-05-23 18:23:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch21_loss0.1403748519718647.pypots
2024-05-23 18:23:38 [INFO]: Epoch 022 - training loss: 0.1426, validation loss: 0.1338
2024-05-23 18:23:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch22_loss0.13383483439683913.pypots
2024-05-23 18:23:54 [INFO]: Epoch 023 - training loss: 0.1303, validation loss: 0.1393
2024-05-23 18:23:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch23_loss0.13931731060147284.pypots
2024-05-23 18:24:11 [INFO]: Epoch 024 - training loss: 0.1309, validation loss: 0.1301
2024-05-23 18:24:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch24_loss0.13006543070077897.pypots
2024-05-23 18:24:27 [INFO]: Epoch 025 - training loss: 0.1325, validation loss: 0.1322
2024-05-23 18:24:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch25_loss0.1321880578994751.pypots
2024-05-23 18:24:43 [INFO]: Epoch 026 - training loss: 0.1426, validation loss: 0.1337
2024-05-23 18:24:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch26_loss0.13368621319532395.pypots
2024-05-23 18:25:00 [INFO]: Epoch 027 - training loss: 0.1368, validation loss: 0.1296
2024-05-23 18:25:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch27_loss0.12958128675818442.pypots
2024-05-23 18:25:16 [INFO]: Epoch 028 - training loss: 0.1231, validation loss: 0.1303
2024-05-23 18:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch28_loss0.13029631450772286.pypots
2024-05-23 18:25:32 [INFO]: Epoch 029 - training loss: 0.1321, validation loss: 0.1270
2024-05-23 18:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch29_loss0.12704282850027085.pypots
2024-05-23 18:25:49 [INFO]: Epoch 030 - training loss: 0.1252, validation loss: 0.1302
2024-05-23 18:25:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch30_loss0.13024111986160278.pypots
2024-05-23 18:26:05 [INFO]: Epoch 031 - training loss: 0.1223, validation loss: 0.1316
2024-05-23 18:26:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch31_loss0.13159019276499748.pypots
2024-05-23 18:26:21 [INFO]: Epoch 032 - training loss: 0.1257, validation loss: 0.1320
2024-05-23 18:26:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch32_loss0.13199954777956008.pypots
2024-05-23 18:26:38 [INFO]: Epoch 033 - training loss: 0.1408, validation loss: 0.1246
2024-05-23 18:26:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch33_loss0.12461713030934334.pypots
2024-05-23 18:26:54 [INFO]: Epoch 034 - training loss: 0.1285, validation loss: 0.1277
2024-05-23 18:26:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch34_loss0.1277097910642624.pypots
2024-05-23 18:27:11 [INFO]: Epoch 035 - training loss: 0.1236, validation loss: 0.1278
2024-05-23 18:27:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch35_loss0.12780307233333588.pypots
2024-05-23 18:27:27 [INFO]: Epoch 036 - training loss: 0.1245, validation loss: 0.1252
2024-05-23 18:27:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch36_loss0.12515279725193978.pypots
2024-05-23 18:27:43 [INFO]: Epoch 037 - training loss: 0.1316, validation loss: 0.1286
2024-05-23 18:27:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch37_loss0.12856427803635598.pypots
2024-05-23 18:28:00 [INFO]: Epoch 038 - training loss: 0.1184, validation loss: 0.1248
2024-05-23 18:28:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch38_loss0.12478481754660606.pypots
2024-05-23 18:28:16 [INFO]: Epoch 039 - training loss: 0.1308, validation loss: 0.1266
2024-05-23 18:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch39_loss0.12663211822509765.pypots
2024-05-23 18:28:32 [INFO]: Epoch 040 - training loss: 0.1107, validation loss: 0.1230
2024-05-23 18:28:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch40_loss0.12296720817685128.pypots
2024-05-23 18:28:49 [INFO]: Epoch 041 - training loss: 0.1378, validation loss: 0.1212
2024-05-23 18:28:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch41_loss0.12117150202393531.pypots
2024-05-23 18:29:05 [INFO]: Epoch 042 - training loss: 0.1049, validation loss: 0.1217
2024-05-23 18:29:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch42_loss0.12173569202423096.pypots
2024-05-23 18:29:22 [INFO]: Epoch 043 - training loss: 0.1142, validation loss: 0.1196
2024-05-23 18:29:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch43_loss0.11956265345215797.pypots
2024-05-23 18:29:38 [INFO]: Epoch 044 - training loss: 0.1200, validation loss: 0.1207
2024-05-23 18:29:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch44_loss0.12070142328739167.pypots
2024-05-23 18:29:54 [INFO]: Epoch 045 - training loss: 0.1149, validation loss: 0.1196
2024-05-23 18:29:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch45_loss0.11958372071385384.pypots
2024-05-23 18:30:11 [INFO]: Epoch 046 - training loss: 0.1239, validation loss: 0.1168
2024-05-23 18:30:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch46_loss0.11683604940772056.pypots
2024-05-23 18:30:27 [INFO]: Epoch 047 - training loss: 0.1281, validation loss: 0.1182
2024-05-23 18:30:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch47_loss0.11821184605360031.pypots
2024-05-23 18:30:43 [INFO]: Epoch 048 - training loss: 0.1192, validation loss: 0.1174
2024-05-23 18:30:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch48_loss0.11740471348166466.pypots
2024-05-23 18:31:00 [INFO]: Epoch 049 - training loss: 0.1378, validation loss: 0.1181
2024-05-23 18:31:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch49_loss0.11814785376191139.pypots
2024-05-23 18:31:16 [INFO]: Epoch 050 - training loss: 0.1113, validation loss: 0.1192
2024-05-23 18:31:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch50_loss0.11917750686407089.pypots
2024-05-23 18:31:33 [INFO]: Epoch 051 - training loss: 0.1094, validation loss: 0.1180
2024-05-23 18:31:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch51_loss0.11800310090184211.pypots
2024-05-23 18:31:49 [INFO]: Epoch 052 - training loss: 0.1266, validation loss: 0.1182
2024-05-23 18:31:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch52_loss0.11823787391185761.pypots
2024-05-23 18:32:05 [INFO]: Epoch 053 - training loss: 0.1168, validation loss: 0.1246
2024-05-23 18:32:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch53_loss0.12461714446544647.pypots
2024-05-23 18:32:22 [INFO]: Epoch 054 - training loss: 0.1163, validation loss: 0.1238
2024-05-23 18:32:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch54_loss0.12382238134741783.pypots
2024-05-23 18:32:38 [INFO]: Epoch 055 - training loss: 0.1240, validation loss: 0.1152
2024-05-23 18:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch55_loss0.11522289291024208.pypots
2024-05-23 18:32:55 [INFO]: Epoch 056 - training loss: 0.1122, validation loss: 0.1153
2024-05-23 18:32:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch56_loss0.115291628241539.pypots
2024-05-23 18:33:11 [INFO]: Epoch 057 - training loss: 0.1186, validation loss: 0.1175
2024-05-23 18:33:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch57_loss0.11754401847720146.pypots
2024-05-23 18:33:27 [INFO]: Epoch 058 - training loss: 0.1052, validation loss: 0.1156
2024-05-23 18:33:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch58_loss0.11562857776880264.pypots
2024-05-23 18:33:44 [INFO]: Epoch 059 - training loss: 0.1143, validation loss: 0.1145
2024-05-23 18:33:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch59_loss0.11445912346243858.pypots
2024-05-23 18:34:00 [INFO]: Epoch 060 - training loss: 0.1180, validation loss: 0.1139
2024-05-23 18:34:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch60_loss0.1139314703643322.pypots
2024-05-23 18:34:16 [INFO]: Epoch 061 - training loss: 0.1168, validation loss: 0.1147
2024-05-23 18:34:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch61_loss0.11469995826482773.pypots
2024-05-23 18:34:33 [INFO]: Epoch 062 - training loss: 0.1199, validation loss: 0.1123
2024-05-23 18:34:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch62_loss0.11227303966879845.pypots
2024-05-23 18:34:49 [INFO]: Epoch 063 - training loss: 0.1083, validation loss: 0.1121
2024-05-23 18:34:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch63_loss0.11206185519695282.pypots
2024-05-23 18:35:06 [INFO]: Epoch 064 - training loss: 0.1011, validation loss: 0.1117
2024-05-23 18:35:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch64_loss0.11168909519910812.pypots
2024-05-23 18:35:22 [INFO]: Epoch 065 - training loss: 0.1096, validation loss: 0.1122
2024-05-23 18:35:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch65_loss0.11217569336295127.pypots
2024-05-23 18:35:38 [INFO]: Epoch 066 - training loss: 0.1117, validation loss: 0.1124
2024-05-23 18:35:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch66_loss0.11236726865172386.pypots
2024-05-23 18:35:55 [INFO]: Epoch 067 - training loss: 0.1254, validation loss: 0.1155
2024-05-23 18:35:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch67_loss0.11547886803746224.pypots
2024-05-23 18:36:11 [INFO]: Epoch 068 - training loss: 0.1034, validation loss: 0.1118
2024-05-23 18:36:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch68_loss0.1118427760899067.pypots
2024-05-23 18:36:28 [INFO]: Epoch 069 - training loss: 0.1122, validation loss: 0.1118
2024-05-23 18:36:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch69_loss0.11181483715772629.pypots
2024-05-23 18:36:44 [INFO]: Epoch 070 - training loss: 0.1221, validation loss: 0.1121
2024-05-23 18:36:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch70_loss0.1120990790426731.pypots
2024-05-23 18:37:00 [INFO]: Epoch 071 - training loss: 0.1065, validation loss: 0.1156
2024-05-23 18:37:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch71_loss0.11558943763375282.pypots
2024-05-23 18:37:17 [INFO]: Epoch 072 - training loss: 0.1065, validation loss: 0.1094
2024-05-23 18:37:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch72_loss0.10944016873836518.pypots
2024-05-23 18:37:33 [INFO]: Epoch 073 - training loss: 0.1255, validation loss: 0.1115
2024-05-23 18:37:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch73_loss0.11146576032042503.pypots
2024-05-23 18:37:50 [INFO]: Epoch 074 - training loss: 0.1101, validation loss: 0.1109
2024-05-23 18:37:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch74_loss0.11088845133781433.pypots
2024-05-23 18:38:06 [INFO]: Epoch 075 - training loss: 0.1031, validation loss: 0.1090
2024-05-23 18:38:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch75_loss0.10904154404997826.pypots
2024-05-23 18:38:23 [INFO]: Epoch 076 - training loss: 0.1074, validation loss: 0.1099
2024-05-23 18:38:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch76_loss0.1098519317805767.pypots
2024-05-23 18:38:39 [INFO]: Epoch 077 - training loss: 0.1172, validation loss: 0.1103
2024-05-23 18:38:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch77_loss0.11027648523449898.pypots
2024-05-23 18:38:55 [INFO]: Epoch 078 - training loss: 0.1253, validation loss: 0.1130
2024-05-23 18:38:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch78_loss0.11297079995274543.pypots
2024-05-23 18:39:12 [INFO]: Epoch 079 - training loss: 0.1070, validation loss: 0.1106
2024-05-23 18:39:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch79_loss0.11059145629405975.pypots
2024-05-23 18:39:28 [INFO]: Epoch 080 - training loss: 0.1078, validation loss: 0.1090
2024-05-23 18:39:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch80_loss0.1089733935892582.pypots
2024-05-23 18:39:45 [INFO]: Epoch 081 - training loss: 0.1001, validation loss: 0.1065
2024-05-23 18:39:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch81_loss0.10654113069176674.pypots
2024-05-23 18:40:01 [INFO]: Epoch 082 - training loss: 0.1111, validation loss: 0.1095
2024-05-23 18:40:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch82_loss0.10951773747801781.pypots
2024-05-23 18:40:17 [INFO]: Epoch 083 - training loss: 0.1069, validation loss: 0.1076
2024-05-23 18:40:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch83_loss0.10760815367102623.pypots
2024-05-23 18:40:34 [INFO]: Epoch 084 - training loss: 0.1002, validation loss: 0.1086
2024-05-23 18:40:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch84_loss0.10863451138138772.pypots
2024-05-23 18:40:50 [INFO]: Epoch 085 - training loss: 0.1267, validation loss: 0.1094
2024-05-23 18:40:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch85_loss0.10938992723822594.pypots
2024-05-23 18:41:06 [INFO]: Epoch 086 - training loss: 0.1086, validation loss: 0.1063
2024-05-23 18:41:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch86_loss0.1063009887933731.pypots
2024-05-23 18:41:23 [INFO]: Epoch 087 - training loss: 0.1174, validation loss: 0.1067
2024-05-23 18:41:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch87_loss0.10672153308987617.pypots
2024-05-23 18:41:39 [INFO]: Epoch 088 - training loss: 0.1069, validation loss: 0.1082
2024-05-23 18:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch88_loss0.10823120474815369.pypots
2024-05-23 18:41:55 [INFO]: Epoch 089 - training loss: 0.1214, validation loss: 0.1107
2024-05-23 18:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch89_loss0.11072342023253441.pypots
2024-05-23 18:42:12 [INFO]: Epoch 090 - training loss: 0.1080, validation loss: 0.1102
2024-05-23 18:42:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch90_loss0.11016563028097152.pypots
2024-05-23 18:42:28 [INFO]: Epoch 091 - training loss: 0.1093, validation loss: 0.1078
2024-05-23 18:42:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch91_loss0.10775085836648941.pypots
2024-05-23 18:42:44 [INFO]: Epoch 092 - training loss: 0.1027, validation loss: 0.1093
2024-05-23 18:42:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch92_loss0.10926590859889984.pypots
2024-05-23 18:43:01 [INFO]: Epoch 093 - training loss: 0.0963, validation loss: 0.1051
2024-05-23 18:43:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch93_loss0.10508476793766022.pypots
2024-05-23 18:43:17 [INFO]: Epoch 094 - training loss: 0.0964, validation loss: 0.1051
2024-05-23 18:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch94_loss0.10508893951773643.pypots
2024-05-23 18:43:33 [INFO]: Epoch 095 - training loss: 0.1063, validation loss: 0.1052
2024-05-23 18:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch95_loss0.10519932582974434.pypots
2024-05-23 18:43:50 [INFO]: Epoch 096 - training loss: 0.1051, validation loss: 0.1080
2024-05-23 18:43:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch96_loss0.10796516761183739.pypots
2024-05-23 18:44:06 [INFO]: Epoch 097 - training loss: 0.1059, validation loss: 0.1087
2024-05-23 18:44:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch97_loss0.10872242152690888.pypots
2024-05-23 18:44:22 [INFO]: Epoch 098 - training loss: 0.1083, validation loss: 0.1043
2024-05-23 18:44:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch98_loss0.10430445596575737.pypots
2024-05-23 18:44:39 [INFO]: Epoch 099 - training loss: 0.1017, validation loss: 0.1073
2024-05-23 18:44:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch99_loss0.1072546474635601.pypots
2024-05-23 18:44:55 [INFO]: Epoch 100 - training loss: 0.0979, validation loss: 0.1073
2024-05-23 18:44:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch100_loss0.1072878323495388.pypots
2024-05-23 18:45:12 [INFO]: Epoch 101 - training loss: 0.1055, validation loss: 0.1073
2024-05-23 18:45:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch101_loss0.1072610653936863.pypots
2024-05-23 18:45:28 [INFO]: Epoch 102 - training loss: 0.1134, validation loss: 0.1081
2024-05-23 18:45:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch102_loss0.10814773291349411.pypots
2024-05-23 18:45:45 [INFO]: Epoch 103 - training loss: 0.1054, validation loss: 0.1038
2024-05-23 18:45:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch103_loss0.1037931688129902.pypots
2024-05-23 18:46:01 [INFO]: Epoch 104 - training loss: 0.0902, validation loss: 0.1041
2024-05-23 18:46:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch104_loss0.10406680107116699.pypots
2024-05-23 18:46:17 [INFO]: Epoch 105 - training loss: 0.1106, validation loss: 0.1045
2024-05-23 18:46:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch105_loss0.10454845055937767.pypots
2024-05-23 18:46:34 [INFO]: Epoch 106 - training loss: 0.1127, validation loss: 0.1050
2024-05-23 18:46:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch106_loss0.10504788309335708.pypots
2024-05-23 18:46:50 [INFO]: Epoch 107 - training loss: 0.0985, validation loss: 0.1047
2024-05-23 18:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch107_loss0.10468645170331001.pypots
2024-05-23 18:47:06 [INFO]: Epoch 108 - training loss: 0.0997, validation loss: 0.1043
2024-05-23 18:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch108_loss0.10429040864109992.pypots
2024-05-23 18:47:23 [INFO]: Epoch 109 - training loss: 0.1137, validation loss: 0.1028
2024-05-23 18:47:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch109_loss0.1028328575193882.pypots
2024-05-23 18:47:39 [INFO]: Epoch 110 - training loss: 0.1048, validation loss: 0.1064
2024-05-23 18:47:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch110_loss0.10636260211467743.pypots
2024-05-23 18:47:55 [INFO]: Epoch 111 - training loss: 0.0939, validation loss: 0.1106
2024-05-23 18:47:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch111_loss0.11061107739806175.pypots
2024-05-23 18:48:12 [INFO]: Epoch 112 - training loss: 0.1160, validation loss: 0.1069
2024-05-23 18:48:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch112_loss0.10685205906629562.pypots
2024-05-23 18:48:28 [INFO]: Epoch 113 - training loss: 0.1002, validation loss: 0.1026
2024-05-23 18:48:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch113_loss0.10264945104718208.pypots
2024-05-23 18:48:44 [INFO]: Epoch 114 - training loss: 0.1080, validation loss: 0.1041
2024-05-23 18:48:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch114_loss0.10408225283026695.pypots
2024-05-23 18:49:01 [INFO]: Epoch 115 - training loss: 0.0972, validation loss: 0.1067
2024-05-23 18:49:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch115_loss0.10667272955179215.pypots
2024-05-23 18:49:17 [INFO]: Epoch 116 - training loss: 0.1003, validation loss: 0.1044
2024-05-23 18:49:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch116_loss0.10438375994563102.pypots
2024-05-23 18:49:34 [INFO]: Epoch 117 - training loss: 0.0871, validation loss: 0.1019
2024-05-23 18:49:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch117_loss0.10188696458935738.pypots
2024-05-23 18:49:50 [INFO]: Epoch 118 - training loss: 0.0907, validation loss: 0.1051
2024-05-23 18:49:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch118_loss0.10505445972085.pypots
2024-05-23 18:50:06 [INFO]: Epoch 119 - training loss: 0.0886, validation loss: 0.1025
2024-05-23 18:50:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch119_loss0.10249396488070488.pypots
2024-05-23 18:50:23 [INFO]: Epoch 120 - training loss: 0.0896, validation loss: 0.1040
2024-05-23 18:50:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch120_loss0.10395561531186104.pypots
2024-05-23 18:50:39 [INFO]: Epoch 121 - training loss: 0.0935, validation loss: 0.1098
2024-05-23 18:50:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch121_loss0.10979759395122528.pypots
2024-05-23 18:50:56 [INFO]: Epoch 122 - training loss: 0.1080, validation loss: 0.1071
2024-05-23 18:50:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch122_loss0.10707146897912026.pypots
2024-05-23 18:51:12 [INFO]: Epoch 123 - training loss: 0.0947, validation loss: 0.1062
2024-05-23 18:51:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch123_loss0.1061844363808632.pypots
2024-05-23 18:51:28 [INFO]: Epoch 124 - training loss: 0.0905, validation loss: 0.1060
2024-05-23 18:51:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch124_loss0.10599306374788284.pypots
2024-05-23 18:51:45 [INFO]: Epoch 125 - training loss: 0.1117, validation loss: 0.1036
2024-05-23 18:51:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch125_loss0.10357853174209594.pypots
2024-05-23 18:52:01 [INFO]: Epoch 126 - training loss: 0.1017, validation loss: 0.1043
2024-05-23 18:52:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch126_loss0.1043175406754017.pypots
2024-05-23 18:52:17 [INFO]: Epoch 127 - training loss: 0.0970, validation loss: 0.1028
2024-05-23 18:52:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI_epoch127_loss0.10277775526046753.pypots
2024-05-23 18:52:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:52:17 [INFO]: Finished training. The best model is from epoch#117.
2024-05-23 18:52:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240523_T181737/CSDI.pypots
2024-05-23 18:54:36 [INFO]: CSDI on Air-Quality: MAE=0.0992, MSE=0.1544
2024-05-23 18:54:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-23 18:54:36 [INFO]: Using the given device: cuda:0
2024-05-23 18:54:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240523_T185436
2024-05-23 18:54:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240523_T185436/tensorboard
2024-05-23 18:54:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 18:54:36 [INFO]: Epoch 001 - training loss: 63659.5639, validation loss: 0.6465
2024-05-23 18:54:36 [INFO]: Epoch 002 - training loss: 41801.3957, validation loss: 0.5745
2024-05-23 18:54:37 [INFO]: Epoch 003 - training loss: 41475.0767, validation loss: 0.5361
2024-05-23 18:54:37 [INFO]: Epoch 004 - training loss: 41376.1622, validation loss: 0.4747
2024-05-23 18:54:37 [INFO]: Epoch 005 - training loss: 41274.0522, validation loss: 0.4308
2024-05-23 18:54:37 [INFO]: Epoch 006 - training loss: 41215.2073, validation loss: 0.4150
2024-05-23 18:54:37 [INFO]: Epoch 007 - training loss: 41179.6264, validation loss: 0.5352
2024-05-23 18:54:38 [INFO]: Epoch 008 - training loss: 41294.8319, validation loss: 0.4310
2024-05-23 18:54:38 [INFO]: Epoch 009 - training loss: 41150.4486, validation loss: 0.3686
2024-05-23 18:54:38 [INFO]: Epoch 010 - training loss: 41090.6714, validation loss: 0.3396
2024-05-23 18:54:38 [INFO]: Epoch 011 - training loss: 41072.8325, validation loss: 0.3333
2024-05-23 18:54:39 [INFO]: Epoch 012 - training loss: 41051.7219, validation loss: 0.3106
2024-05-23 18:54:39 [INFO]: Epoch 013 - training loss: 41040.3255, validation loss: 0.3257
2024-05-23 18:54:39 [INFO]: Epoch 014 - training loss: 41036.9903, validation loss: 0.3150
2024-05-23 18:54:39 [INFO]: Epoch 015 - training loss: 41013.6970, validation loss: 0.3164
2024-05-23 18:54:40 [INFO]: Epoch 016 - training loss: 41006.8934, validation loss: 0.3082
2024-05-23 18:54:40 [INFO]: Epoch 017 - training loss: 40999.9792, validation loss: 0.2887
2024-05-23 18:54:40 [INFO]: Epoch 018 - training loss: 40987.6819, validation loss: 0.2982
2024-05-23 18:54:40 [INFO]: Epoch 019 - training loss: 40991.2925, validation loss: 0.2976
2024-05-23 18:54:41 [INFO]: Epoch 020 - training loss: 40979.2354, validation loss: 0.3083
2024-05-23 18:54:41 [INFO]: Epoch 021 - training loss: 40979.6764, validation loss: 0.2853
2024-05-23 18:54:41 [INFO]: Epoch 022 - training loss: 40980.9819, validation loss: 0.2753
2024-05-23 18:54:41 [INFO]: Epoch 023 - training loss: 40944.6328, validation loss: 0.2672
2024-05-23 18:54:42 [INFO]: Epoch 024 - training loss: 40937.4183, validation loss: 0.2626
2024-05-23 18:54:42 [INFO]: Epoch 025 - training loss: 40961.5132, validation loss: 0.2966
2024-05-23 18:54:42 [INFO]: Epoch 026 - training loss: 40950.5515, validation loss: 0.2725
2024-05-23 18:54:42 [INFO]: Epoch 027 - training loss: 40952.1597, validation loss: 0.2835
2024-05-23 18:54:43 [INFO]: Epoch 028 - training loss: 40926.7286, validation loss: 0.2544
2024-05-23 18:54:43 [INFO]: Epoch 029 - training loss: 40919.0000, validation loss: 0.2518
2024-05-23 18:54:43 [INFO]: Epoch 030 - training loss: 40911.4769, validation loss: 0.2509
2024-05-23 18:54:43 [INFO]: Epoch 031 - training loss: 40908.7772, validation loss: 0.2537
2024-05-23 18:54:44 [INFO]: Epoch 032 - training loss: 40954.8857, validation loss: 0.2794
2024-05-23 18:54:44 [INFO]: Epoch 033 - training loss: 40932.1011, validation loss: 0.2630
2024-05-23 18:54:44 [INFO]: Epoch 034 - training loss: 40921.5505, validation loss: 0.2665
2024-05-23 18:54:44 [INFO]: Epoch 035 - training loss: 40925.1939, validation loss: 0.2705
2024-05-23 18:54:45 [INFO]: Epoch 036 - training loss: 40962.5064, validation loss: 0.2655
2024-05-23 18:54:45 [INFO]: Epoch 037 - training loss: 40988.2639, validation loss: 0.2614
2024-05-23 18:54:45 [INFO]: Epoch 038 - training loss: 40958.0104, validation loss: 0.2544
2024-05-23 18:54:45 [INFO]: Epoch 039 - training loss: 40946.8964, validation loss: 0.2733
2024-05-23 18:54:46 [INFO]: Epoch 040 - training loss: 40946.6982, validation loss: 0.2534
2024-05-23 18:54:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:54:46 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 18:54:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240523_T185436/GPVAE.pypots
2024-05-23 18:54:46 [INFO]: GP-VAE on Air-Quality: MAE=0.3100, MSE=0.3073
2024-05-23 18:54:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-23 18:54:46 [INFO]: Using the given device: cuda:0
2024-05-23 18:54:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240523_T185446
2024-05-23 18:54:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240523_T185446/tensorboard
2024-05-23 18:54:46 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 18:54:50 [INFO]: Epoch 001 - generator training loss: 0.4523, discriminator training loss: 0.4570, validation loss: 0.5187
2024-05-23 18:54:53 [INFO]: Epoch 002 - generator training loss: 0.0912, discriminator training loss: 0.3616, validation loss: 0.3920
2024-05-23 18:54:56 [INFO]: Epoch 003 - generator training loss: 0.0306, discriminator training loss: 0.3571, validation loss: 0.3225
2024-05-23 18:55:00 [INFO]: Epoch 004 - generator training loss: -0.0060, discriminator training loss: 0.3551, validation loss: 0.2787
2024-05-23 18:55:03 [INFO]: Epoch 005 - generator training loss: -0.0331, discriminator training loss: 0.3536, validation loss: 0.2532
2024-05-23 18:55:06 [INFO]: Epoch 006 - generator training loss: -0.0491, discriminator training loss: 0.3519, validation loss: 0.2358
2024-05-23 18:55:10 [INFO]: Epoch 007 - generator training loss: -0.0617, discriminator training loss: 0.3497, validation loss: 0.2220
2024-05-23 18:55:13 [INFO]: Epoch 008 - generator training loss: -0.0701, discriminator training loss: 0.3480, validation loss: 0.2106
2024-05-23 18:55:16 [INFO]: Epoch 009 - generator training loss: -0.0806, discriminator training loss: 0.3460, validation loss: 0.2018
2024-05-23 18:55:20 [INFO]: Epoch 010 - generator training loss: -0.0860, discriminator training loss: 0.3436, validation loss: 0.1951
2024-05-23 18:55:23 [INFO]: Epoch 011 - generator training loss: -0.0897, discriminator training loss: 0.3410, validation loss: 0.1884
2024-05-23 18:55:26 [INFO]: Epoch 012 - generator training loss: -0.0938, discriminator training loss: 0.3383, validation loss: 0.1835
2024-05-23 18:55:30 [INFO]: Epoch 013 - generator training loss: -0.0964, discriminator training loss: 0.3357, validation loss: 0.1760
2024-05-23 18:55:33 [INFO]: Epoch 014 - generator training loss: -0.0999, discriminator training loss: 0.3328, validation loss: 0.1721
2024-05-23 18:55:37 [INFO]: Epoch 015 - generator training loss: -0.1018, discriminator training loss: 0.3293, validation loss: 0.1677
2024-05-23 18:55:40 [INFO]: Epoch 016 - generator training loss: -0.1037, discriminator training loss: 0.3260, validation loss: 0.1644
2024-05-23 18:55:43 [INFO]: Epoch 017 - generator training loss: -0.1017, discriminator training loss: 0.3225, validation loss: 0.1612
2024-05-23 18:55:47 [INFO]: Epoch 018 - generator training loss: -0.1022, discriminator training loss: 0.3185, validation loss: 0.1586
2024-05-23 18:55:50 [INFO]: Epoch 019 - generator training loss: -0.1026, discriminator training loss: 0.3147, validation loss: 0.1553
2024-05-23 18:55:53 [INFO]: Epoch 020 - generator training loss: -0.1016, discriminator training loss: 0.3108, validation loss: 0.1536
2024-05-23 18:55:57 [INFO]: Epoch 021 - generator training loss: -0.1010, discriminator training loss: 0.3066, validation loss: 0.1507
2024-05-23 18:56:00 [INFO]: Epoch 022 - generator training loss: -0.0996, discriminator training loss: 0.3026, validation loss: 0.1492
2024-05-23 18:56:03 [INFO]: Epoch 023 - generator training loss: -0.0978, discriminator training loss: 0.2985, validation loss: 0.1470
2024-05-23 18:56:07 [INFO]: Epoch 024 - generator training loss: -0.0962, discriminator training loss: 0.2945, validation loss: 0.1452
2024-05-23 18:56:10 [INFO]: Epoch 025 - generator training loss: -0.0947, discriminator training loss: 0.2903, validation loss: 0.1431
2024-05-23 18:56:13 [INFO]: Epoch 026 - generator training loss: -0.0925, discriminator training loss: 0.2863, validation loss: 0.1411
2024-05-23 18:56:17 [INFO]: Epoch 027 - generator training loss: -0.0916, discriminator training loss: 0.2826, validation loss: 0.1398
2024-05-23 18:56:20 [INFO]: Epoch 028 - generator training loss: -0.0904, discriminator training loss: 0.2787, validation loss: 0.1379
2024-05-23 18:56:23 [INFO]: Epoch 029 - generator training loss: -0.0888, discriminator training loss: 0.2750, validation loss: 0.1363
2024-05-23 18:56:27 [INFO]: Epoch 030 - generator training loss: -0.0876, discriminator training loss: 0.2714, validation loss: 0.1353
2024-05-23 18:56:30 [INFO]: Epoch 031 - generator training loss: -0.0862, discriminator training loss: 0.2680, validation loss: 0.1339
2024-05-23 18:56:33 [INFO]: Epoch 032 - generator training loss: -0.0842, discriminator training loss: 0.2647, validation loss: 0.1323
2024-05-23 18:56:37 [INFO]: Epoch 033 - generator training loss: -0.0844, discriminator training loss: 0.2616, validation loss: 0.1310
2024-05-23 18:56:40 [INFO]: Epoch 034 - generator training loss: -0.0826, discriminator training loss: 0.2590, validation loss: 0.1298
2024-05-23 18:56:43 [INFO]: Epoch 035 - generator training loss: -0.0821, discriminator training loss: 0.2560, validation loss: 0.1283
2024-05-23 18:56:47 [INFO]: Epoch 036 - generator training loss: -0.0805, discriminator training loss: 0.2537, validation loss: 0.1273
2024-05-23 18:56:50 [INFO]: Epoch 037 - generator training loss: -0.0795, discriminator training loss: 0.2511, validation loss: 0.1265
2024-05-23 18:56:53 [INFO]: Epoch 038 - generator training loss: -0.0800, discriminator training loss: 0.2492, validation loss: 0.1247
2024-05-23 18:56:57 [INFO]: Epoch 039 - generator training loss: -0.0790, discriminator training loss: 0.2466, validation loss: 0.1236
2024-05-23 18:57:00 [INFO]: Epoch 040 - generator training loss: -0.0772, discriminator training loss: 0.2446, validation loss: 0.1225
2024-05-23 18:57:03 [INFO]: Epoch 041 - generator training loss: -0.0776, discriminator training loss: 0.2432, validation loss: 0.1214
2024-05-23 18:57:07 [INFO]: Epoch 042 - generator training loss: -0.0754, discriminator training loss: 0.2410, validation loss: 0.1210
2024-05-23 18:57:10 [INFO]: Epoch 043 - generator training loss: -0.0760, discriminator training loss: 0.2395, validation loss: 0.1191
2024-05-23 18:57:13 [INFO]: Epoch 044 - generator training loss: -0.0764, discriminator training loss: 0.2379, validation loss: 0.1186
2024-05-23 18:57:17 [INFO]: Epoch 045 - generator training loss: -0.0758, discriminator training loss: 0.2361, validation loss: 0.1179
2024-05-23 18:57:20 [INFO]: Epoch 046 - generator training loss: -0.0759, discriminator training loss: 0.2350, validation loss: 0.1176
2024-05-23 18:57:23 [INFO]: Epoch 047 - generator training loss: -0.0763, discriminator training loss: 0.2335, validation loss: 0.1164
2024-05-23 18:57:27 [INFO]: Epoch 048 - generator training loss: -0.0758, discriminator training loss: 0.2322, validation loss: 0.1159
2024-05-23 18:57:30 [INFO]: Epoch 049 - generator training loss: -0.0752, discriminator training loss: 0.2309, validation loss: 0.1152
2024-05-23 18:57:34 [INFO]: Epoch 050 - generator training loss: -0.0734, discriminator training loss: 0.2295, validation loss: 0.1142
2024-05-23 18:57:37 [INFO]: Epoch 051 - generator training loss: -0.0748, discriminator training loss: 0.2288, validation loss: 0.1143
2024-05-23 18:57:40 [INFO]: Epoch 052 - generator training loss: -0.0749, discriminator training loss: 0.2277, validation loss: 0.1130
2024-05-23 18:57:44 [INFO]: Epoch 053 - generator training loss: -0.0745, discriminator training loss: 0.2269, validation loss: 0.1127
2024-05-23 18:57:47 [INFO]: Epoch 054 - generator training loss: -0.0748, discriminator training loss: 0.2259, validation loss: 0.1123
2024-05-23 18:57:50 [INFO]: Epoch 055 - generator training loss: -0.0740, discriminator training loss: 0.2249, validation loss: 0.1113
2024-05-23 18:57:54 [INFO]: Epoch 056 - generator training loss: -0.0740, discriminator training loss: 0.2241, validation loss: 0.1112
2024-05-23 18:57:57 [INFO]: Epoch 057 - generator training loss: -0.0741, discriminator training loss: 0.2231, validation loss: 0.1107
2024-05-23 18:58:00 [INFO]: Epoch 058 - generator training loss: -0.0747, discriminator training loss: 0.2224, validation loss: 0.1102
2024-05-23 18:58:04 [INFO]: Epoch 059 - generator training loss: -0.0754, discriminator training loss: 0.2218, validation loss: 0.1096
2024-05-23 18:58:07 [INFO]: Epoch 060 - generator training loss: -0.0753, discriminator training loss: 0.2207, validation loss: 0.1100
2024-05-23 18:58:10 [INFO]: Epoch 061 - generator training loss: -0.0748, discriminator training loss: 0.2204, validation loss: 0.1082
2024-05-23 18:58:14 [INFO]: Epoch 062 - generator training loss: -0.0740, discriminator training loss: 0.2194, validation loss: 0.1082
2024-05-23 18:58:17 [INFO]: Epoch 063 - generator training loss: -0.0752, discriminator training loss: 0.2186, validation loss: 0.1083
2024-05-23 18:58:20 [INFO]: Epoch 064 - generator training loss: -0.0750, discriminator training loss: 0.2180, validation loss: 0.1074
2024-05-23 18:58:24 [INFO]: Epoch 065 - generator training loss: -0.0741, discriminator training loss: 0.2177, validation loss: 0.1068
2024-05-23 18:58:27 [INFO]: Epoch 066 - generator training loss: -0.0756, discriminator training loss: 0.2170, validation loss: 0.1062
2024-05-23 18:58:30 [INFO]: Epoch 067 - generator training loss: -0.0741, discriminator training loss: 0.2169, validation loss: 0.1062
2024-05-23 18:58:34 [INFO]: Epoch 068 - generator training loss: -0.0749, discriminator training loss: 0.2164, validation loss: 0.1068
2024-05-23 18:58:37 [INFO]: Epoch 069 - generator training loss: -0.0760, discriminator training loss: 0.2154, validation loss: 0.1057
2024-05-23 18:58:40 [INFO]: Epoch 070 - generator training loss: -0.0738, discriminator training loss: 0.2152, validation loss: 0.1049
2024-05-23 18:58:44 [INFO]: Epoch 071 - generator training loss: -0.0756, discriminator training loss: 0.2146, validation loss: 0.1054
2024-05-23 18:58:47 [INFO]: Epoch 072 - generator training loss: -0.0756, discriminator training loss: 0.2144, validation loss: 0.1053
2024-05-23 18:58:50 [INFO]: Epoch 073 - generator training loss: -0.0755, discriminator training loss: 0.2141, validation loss: 0.1050
2024-05-23 18:58:54 [INFO]: Epoch 074 - generator training loss: -0.0758, discriminator training loss: 0.2136, validation loss: 0.1073
2024-05-23 18:58:57 [INFO]: Epoch 075 - generator training loss: -0.0740, discriminator training loss: 0.2132, validation loss: 0.1039
2024-05-23 18:59:00 [INFO]: Epoch 076 - generator training loss: -0.0757, discriminator training loss: 0.2129, validation loss: 0.1041
2024-05-23 18:59:04 [INFO]: Epoch 077 - generator training loss: -0.0763, discriminator training loss: 0.2126, validation loss: 0.1029
2024-05-23 18:59:07 [INFO]: Epoch 078 - generator training loss: -0.0767, discriminator training loss: 0.2118, validation loss: 0.1034
2024-05-23 18:59:10 [INFO]: Epoch 079 - generator training loss: -0.0763, discriminator training loss: 0.2121, validation loss: 0.1028
2024-05-23 18:59:14 [INFO]: Epoch 080 - generator training loss: -0.0772, discriminator training loss: 0.2114, validation loss: 0.1027
2024-05-23 18:59:17 [INFO]: Epoch 081 - generator training loss: -0.0776, discriminator training loss: 0.2112, validation loss: 0.1025
2024-05-23 18:59:21 [INFO]: Epoch 082 - generator training loss: -0.0768, discriminator training loss: 0.2108, validation loss: 0.1026
2024-05-23 18:59:24 [INFO]: Epoch 083 - generator training loss: -0.0773, discriminator training loss: 0.2102, validation loss: 0.1021
2024-05-23 18:59:27 [INFO]: Epoch 084 - generator training loss: -0.0766, discriminator training loss: 0.2100, validation loss: 0.1025
2024-05-23 18:59:31 [INFO]: Epoch 085 - generator training loss: -0.0777, discriminator training loss: 0.2102, validation loss: 0.1022
2024-05-23 18:59:34 [INFO]: Epoch 086 - generator training loss: -0.0778, discriminator training loss: 0.2099, validation loss: 0.1023
2024-05-23 18:59:37 [INFO]: Epoch 087 - generator training loss: -0.0774, discriminator training loss: 0.2093, validation loss: 0.1012
2024-05-23 18:59:41 [INFO]: Epoch 088 - generator training loss: -0.0788, discriminator training loss: 0.2093, validation loss: 0.1017
2024-05-23 18:59:44 [INFO]: Epoch 089 - generator training loss: -0.0780, discriminator training loss: 0.2095, validation loss: 0.1020
2024-05-23 18:59:47 [INFO]: Epoch 090 - generator training loss: -0.0780, discriminator training loss: 0.2088, validation loss: 0.1013
2024-05-23 18:59:51 [INFO]: Epoch 091 - generator training loss: -0.0786, discriminator training loss: 0.2089, validation loss: 0.1017
2024-05-23 18:59:54 [INFO]: Epoch 092 - generator training loss: -0.0788, discriminator training loss: 0.2080, validation loss: 0.1010
2024-05-23 18:59:58 [INFO]: Epoch 093 - generator training loss: -0.0783, discriminator training loss: 0.2086, validation loss: 0.1012
2024-05-23 19:00:01 [INFO]: Epoch 094 - generator training loss: -0.0792, discriminator training loss: 0.2078, validation loss: 0.1009
2024-05-23 19:00:04 [INFO]: Epoch 095 - generator training loss: -0.0789, discriminator training loss: 0.2080, validation loss: 0.1003
2024-05-23 19:00:08 [INFO]: Epoch 096 - generator training loss: -0.0801, discriminator training loss: 0.2076, validation loss: 0.1009
2024-05-23 19:00:11 [INFO]: Epoch 097 - generator training loss: -0.0802, discriminator training loss: 0.2073, validation loss: 0.1000
2024-05-23 19:00:14 [INFO]: Epoch 098 - generator training loss: -0.0786, discriminator training loss: 0.2072, validation loss: 0.1010
2024-05-23 19:00:18 [INFO]: Epoch 099 - generator training loss: -0.0799, discriminator training loss: 0.2073, validation loss: 0.0996
2024-05-23 19:00:21 [INFO]: Epoch 100 - generator training loss: -0.0803, discriminator training loss: 0.2073, validation loss: 0.0999
2024-05-23 19:00:24 [INFO]: Epoch 101 - generator training loss: -0.0818, discriminator training loss: 0.2063, validation loss: 0.0992
2024-05-23 19:00:28 [INFO]: Epoch 102 - generator training loss: -0.0805, discriminator training loss: 0.2070, validation loss: 0.1001
2024-05-23 19:00:31 [INFO]: Epoch 103 - generator training loss: -0.0811, discriminator training loss: 0.2066, validation loss: 0.0995
2024-05-23 19:00:35 [INFO]: Epoch 104 - generator training loss: -0.0820, discriminator training loss: 0.2060, validation loss: 0.0989
2024-05-23 19:00:38 [INFO]: Epoch 105 - generator training loss: -0.0813, discriminator training loss: 0.2061, validation loss: 0.0992
2024-05-23 19:00:41 [INFO]: Epoch 106 - generator training loss: -0.0810, discriminator training loss: 0.2058, validation loss: 0.0992
2024-05-23 19:00:45 [INFO]: Epoch 107 - generator training loss: -0.0820, discriminator training loss: 0.2060, validation loss: 0.0993
2024-05-23 19:00:48 [INFO]: Epoch 108 - generator training loss: -0.0817, discriminator training loss: 0.2059, validation loss: 0.0985
2024-05-23 19:00:51 [INFO]: Epoch 109 - generator training loss: -0.0823, discriminator training loss: 0.2054, validation loss: 0.0991
2024-05-23 19:00:55 [INFO]: Epoch 110 - generator training loss: -0.0821, discriminator training loss: 0.2054, validation loss: 0.0987
2024-05-23 19:00:58 [INFO]: Epoch 111 - generator training loss: -0.0838, discriminator training loss: 0.2047, validation loss: 0.1008
2024-05-23 19:01:01 [INFO]: Epoch 112 - generator training loss: -0.0817, discriminator training loss: 0.2045, validation loss: 0.0988
2024-05-23 19:01:05 [INFO]: Epoch 113 - generator training loss: -0.0818, discriminator training loss: 0.2049, validation loss: 0.0985
2024-05-23 19:01:08 [INFO]: Epoch 114 - generator training loss: -0.0823, discriminator training loss: 0.2045, validation loss: 0.0983
2024-05-23 19:01:11 [INFO]: Epoch 115 - generator training loss: -0.0834, discriminator training loss: 0.2045, validation loss: 0.0982
2024-05-23 19:01:15 [INFO]: Epoch 116 - generator training loss: -0.0826, discriminator training loss: 0.2045, validation loss: 0.0982
2024-05-23 19:01:18 [INFO]: Epoch 117 - generator training loss: -0.0826, discriminator training loss: 0.2043, validation loss: 0.0987
2024-05-23 19:01:21 [INFO]: Epoch 118 - generator training loss: -0.0834, discriminator training loss: 0.2046, validation loss: 0.0988
2024-05-23 19:01:25 [INFO]: Epoch 119 - generator training loss: -0.0812, discriminator training loss: 0.2039, validation loss: 0.0995
2024-05-23 19:01:28 [INFO]: Epoch 120 - generator training loss: -0.0831, discriminator training loss: 0.2046, validation loss: 0.0988
2024-05-23 19:01:31 [INFO]: Epoch 121 - generator training loss: -0.0838, discriminator training loss: 0.2039, validation loss: 0.0976
2024-05-23 19:01:35 [INFO]: Epoch 122 - generator training loss: -0.0845, discriminator training loss: 0.2041, validation loss: 0.0983
2024-05-23 19:01:38 [INFO]: Epoch 123 - generator training loss: -0.0837, discriminator training loss: 0.2037, validation loss: 0.0971
2024-05-23 19:01:41 [INFO]: Epoch 124 - generator training loss: -0.0839, discriminator training loss: 0.2039, validation loss: 0.0979
2024-05-23 19:01:45 [INFO]: Epoch 125 - generator training loss: -0.0840, discriminator training loss: 0.2036, validation loss: 0.0995
2024-05-23 19:01:48 [INFO]: Epoch 126 - generator training loss: -0.0839, discriminator training loss: 0.2032, validation loss: 0.0985
2024-05-23 19:01:52 [INFO]: Epoch 127 - generator training loss: -0.0850, discriminator training loss: 0.2038, validation loss: 0.0973
2024-05-23 19:01:55 [INFO]: Epoch 128 - generator training loss: -0.0850, discriminator training loss: 0.2032, validation loss: 0.0978
2024-05-23 19:01:58 [INFO]: Epoch 129 - generator training loss: -0.0844, discriminator training loss: 0.2032, validation loss: 0.0970
2024-05-23 19:02:02 [INFO]: Epoch 130 - generator training loss: -0.0846, discriminator training loss: 0.2027, validation loss: 0.0976
2024-05-23 19:02:05 [INFO]: Epoch 131 - generator training loss: -0.0849, discriminator training loss: 0.2025, validation loss: 0.0980
2024-05-23 19:02:08 [INFO]: Epoch 132 - generator training loss: -0.0852, discriminator training loss: 0.2025, validation loss: 0.0971
2024-05-23 19:02:12 [INFO]: Epoch 133 - generator training loss: -0.0857, discriminator training loss: 0.2025, validation loss: 0.0975
2024-05-23 19:02:15 [INFO]: Epoch 134 - generator training loss: -0.0844, discriminator training loss: 0.2026, validation loss: 0.0980
2024-05-23 19:02:18 [INFO]: Epoch 135 - generator training loss: -0.0856, discriminator training loss: 0.2020, validation loss: 0.0969
2024-05-23 19:02:22 [INFO]: Epoch 136 - generator training loss: -0.0854, discriminator training loss: 0.2022, validation loss: 0.0989
2024-05-23 19:02:25 [INFO]: Epoch 137 - generator training loss: -0.0855, discriminator training loss: 0.2022, validation loss: 0.0981
2024-05-23 19:02:28 [INFO]: Epoch 138 - generator training loss: -0.0851, discriminator training loss: 0.2024, validation loss: 0.0979
2024-05-23 19:02:32 [INFO]: Epoch 139 - generator training loss: -0.0859, discriminator training loss: 0.2023, validation loss: 0.0985
2024-05-23 19:02:35 [INFO]: Epoch 140 - generator training loss: -0.0857, discriminator training loss: 0.2020, validation loss: 0.0974
2024-05-23 19:02:38 [INFO]: Epoch 141 - generator training loss: -0.0856, discriminator training loss: 0.2012, validation loss: 0.0984
2024-05-23 19:02:42 [INFO]: Epoch 142 - generator training loss: -0.0851, discriminator training loss: 0.2017, validation loss: 0.0976
2024-05-23 19:02:45 [INFO]: Epoch 143 - generator training loss: -0.0851, discriminator training loss: 0.2017, validation loss: 0.0984
2024-05-23 19:02:48 [INFO]: Epoch 144 - generator training loss: -0.0863, discriminator training loss: 0.2014, validation loss: 0.0976
2024-05-23 19:02:52 [INFO]: Epoch 145 - generator training loss: -0.0859, discriminator training loss: 0.2014, validation loss: 0.0968
2024-05-23 19:02:55 [INFO]: Epoch 146 - generator training loss: -0.0862, discriminator training loss: 0.2009, validation loss: 0.0986
2024-05-23 19:02:58 [INFO]: Epoch 147 - generator training loss: -0.0868, discriminator training loss: 0.2016, validation loss: 0.0975
2024-05-23 19:03:01 [INFO]: Epoch 148 - generator training loss: -0.0863, discriminator training loss: 0.2016, validation loss: 0.0982
2024-05-23 19:03:05 [INFO]: Epoch 149 - generator training loss: -0.0869, discriminator training loss: 0.2015, validation loss: 0.0974
2024-05-23 19:03:08 [INFO]: Epoch 150 - generator training loss: -0.0859, discriminator training loss: 0.2013, validation loss: 0.0980
2024-05-23 19:03:12 [INFO]: Epoch 151 - generator training loss: -0.0865, discriminator training loss: 0.2009, validation loss: 0.0978
2024-05-23 19:03:15 [INFO]: Epoch 152 - generator training loss: -0.0869, discriminator training loss: 0.2010, validation loss: 0.0977
2024-05-23 19:03:18 [INFO]: Epoch 153 - generator training loss: -0.0869, discriminator training loss: 0.2004, validation loss: 0.0973
2024-05-23 19:03:22 [INFO]: Epoch 154 - generator training loss: -0.0874, discriminator training loss: 0.2007, validation loss: 0.0979
2024-05-23 19:03:25 [INFO]: Epoch 155 - generator training loss: -0.0868, discriminator training loss: 0.2007, validation loss: 0.0972
2024-05-23 19:03:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:03:25 [INFO]: Finished training. The best model is from epoch#145.
2024-05-23 19:03:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240523_T185446/USGAN.pypots
2024-05-23 19:03:25 [INFO]: US-GAN on Air-Quality: MAE=0.1483, MSE=0.1244
2024-05-23 19:03:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-23 19:03:25 [INFO]: Using the given device: cuda:0
2024-05-23 19:03:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240523_T190325
2024-05-23 19:03:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240523_T190325/tensorboard
2024-05-23 19:03:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 19:03:28 [INFO]: Epoch 001 - training loss: 1.4060, validation loss: 0.9219
2024-05-23 19:03:30 [INFO]: Epoch 002 - training loss: 1.1420, validation loss: 0.6905
2024-05-23 19:03:33 [INFO]: Epoch 003 - training loss: 0.9534, validation loss: 0.5882
2024-05-23 19:03:35 [INFO]: Epoch 004 - training loss: 0.8412, validation loss: 0.5181
2024-05-23 19:03:37 [INFO]: Epoch 005 - training loss: 0.7676, validation loss: 0.4736
2024-05-23 19:03:39 [INFO]: Epoch 006 - training loss: 0.7117, validation loss: 0.4391
2024-05-23 19:03:42 [INFO]: Epoch 007 - training loss: 0.6692, validation loss: 0.4094
2024-05-23 19:03:44 [INFO]: Epoch 008 - training loss: 0.6341, validation loss: 0.3861
2024-05-23 19:03:46 [INFO]: Epoch 009 - training loss: 0.6079, validation loss: 0.3665
2024-05-23 19:03:48 [INFO]: Epoch 010 - training loss: 0.5856, validation loss: 0.3494
2024-05-23 19:03:50 [INFO]: Epoch 011 - training loss: 0.5670, validation loss: 0.3360
2024-05-23 19:03:53 [INFO]: Epoch 012 - training loss: 0.5519, validation loss: 0.3242
2024-05-23 19:03:55 [INFO]: Epoch 013 - training loss: 0.5405, validation loss: 0.3141
2024-05-23 19:03:57 [INFO]: Epoch 014 - training loss: 0.5276, validation loss: 0.3057
2024-05-23 19:03:59 [INFO]: Epoch 015 - training loss: 0.5170, validation loss: 0.2980
2024-05-23 19:04:02 [INFO]: Epoch 016 - training loss: 0.5077, validation loss: 0.2905
2024-05-23 19:04:04 [INFO]: Epoch 017 - training loss: 0.5002, validation loss: 0.2843
2024-05-23 19:04:06 [INFO]: Epoch 018 - training loss: 0.4927, validation loss: 0.2786
2024-05-23 19:04:08 [INFO]: Epoch 019 - training loss: 0.4828, validation loss: 0.2731
2024-05-23 19:04:11 [INFO]: Epoch 020 - training loss: 0.4767, validation loss: 0.2681
2024-05-23 19:04:13 [INFO]: Epoch 021 - training loss: 0.4688, validation loss: 0.2634
2024-05-23 19:04:15 [INFO]: Epoch 022 - training loss: 0.4620, validation loss: 0.2591
2024-05-23 19:04:17 [INFO]: Epoch 023 - training loss: 0.4562, validation loss: 0.2549
2024-05-23 19:04:20 [INFO]: Epoch 024 - training loss: 0.4503, validation loss: 0.2509
2024-05-23 19:04:22 [INFO]: Epoch 025 - training loss: 0.4448, validation loss: 0.2471
2024-05-23 19:04:24 [INFO]: Epoch 026 - training loss: 0.4404, validation loss: 0.2436
2024-05-23 19:04:26 [INFO]: Epoch 027 - training loss: 0.4345, validation loss: 0.2402
2024-05-23 19:04:29 [INFO]: Epoch 028 - training loss: 0.4291, validation loss: 0.2368
2024-05-23 19:04:31 [INFO]: Epoch 029 - training loss: 0.4247, validation loss: 0.2336
2024-05-23 19:04:33 [INFO]: Epoch 030 - training loss: 0.4196, validation loss: 0.2308
2024-05-23 19:04:35 [INFO]: Epoch 031 - training loss: 0.4150, validation loss: 0.2275
2024-05-23 19:04:37 [INFO]: Epoch 032 - training loss: 0.4112, validation loss: 0.2247
2024-05-23 19:04:40 [INFO]: Epoch 033 - training loss: 0.4069, validation loss: 0.2215
2024-05-23 19:04:42 [INFO]: Epoch 034 - training loss: 0.4044, validation loss: 0.2191
2024-05-23 19:04:44 [INFO]: Epoch 035 - training loss: 0.3987, validation loss: 0.2163
2024-05-23 19:04:46 [INFO]: Epoch 036 - training loss: 0.3953, validation loss: 0.2136
2024-05-23 19:04:49 [INFO]: Epoch 037 - training loss: 0.3918, validation loss: 0.2112
2024-05-23 19:04:51 [INFO]: Epoch 038 - training loss: 0.3887, validation loss: 0.2091
2024-05-23 19:04:53 [INFO]: Epoch 039 - training loss: 0.3847, validation loss: 0.2063
2024-05-23 19:04:55 [INFO]: Epoch 040 - training loss: 0.3815, validation loss: 0.2042
2024-05-23 19:04:57 [INFO]: Epoch 041 - training loss: 0.3786, validation loss: 0.2023
2024-05-23 19:05:00 [INFO]: Epoch 042 - training loss: 0.3755, validation loss: 0.1999
2024-05-23 19:05:02 [INFO]: Epoch 043 - training loss: 0.3726, validation loss: 0.1979
2024-05-23 19:05:04 [INFO]: Epoch 044 - training loss: 0.3694, validation loss: 0.1956
2024-05-23 19:05:06 [INFO]: Epoch 045 - training loss: 0.3671, validation loss: 0.1937
2024-05-23 19:05:09 [INFO]: Epoch 046 - training loss: 0.3646, validation loss: 0.1918
2024-05-23 19:05:11 [INFO]: Epoch 047 - training loss: 0.3617, validation loss: 0.1898
2024-05-23 19:05:13 [INFO]: Epoch 048 - training loss: 0.3593, validation loss: 0.1880
2024-05-23 19:05:15 [INFO]: Epoch 049 - training loss: 0.3576, validation loss: 0.1864
2024-05-23 19:05:17 [INFO]: Epoch 050 - training loss: 0.3550, validation loss: 0.1847
2024-05-23 19:05:20 [INFO]: Epoch 051 - training loss: 0.3525, validation loss: 0.1829
2024-05-23 19:05:22 [INFO]: Epoch 052 - training loss: 0.3506, validation loss: 0.1815
2024-05-23 19:05:24 [INFO]: Epoch 053 - training loss: 0.3482, validation loss: 0.1800
2024-05-23 19:05:26 [INFO]: Epoch 054 - training loss: 0.3455, validation loss: 0.1786
2024-05-23 19:05:29 [INFO]: Epoch 055 - training loss: 0.3440, validation loss: 0.1770
2024-05-23 19:05:31 [INFO]: Epoch 056 - training loss: 0.3426, validation loss: 0.1757
2024-05-23 19:05:33 [INFO]: Epoch 057 - training loss: 0.3400, validation loss: 0.1743
2024-05-23 19:05:35 [INFO]: Epoch 058 - training loss: 0.3383, validation loss: 0.1731
2024-05-23 19:05:37 [INFO]: Epoch 059 - training loss: 0.3364, validation loss: 0.1721
2024-05-23 19:05:40 [INFO]: Epoch 060 - training loss: 0.3347, validation loss: 0.1708
2024-05-23 19:05:42 [INFO]: Epoch 061 - training loss: 0.3335, validation loss: 0.1694
2024-05-23 19:05:44 [INFO]: Epoch 062 - training loss: 0.3320, validation loss: 0.1684
2024-05-23 19:05:46 [INFO]: Epoch 063 - training loss: 0.3299, validation loss: 0.1674
2024-05-23 19:05:49 [INFO]: Epoch 064 - training loss: 0.3287, validation loss: 0.1661
2024-05-23 19:05:51 [INFO]: Epoch 065 - training loss: 0.3269, validation loss: 0.1653
2024-05-23 19:05:53 [INFO]: Epoch 066 - training loss: 0.3262, validation loss: 0.1643
2024-05-23 19:05:55 [INFO]: Epoch 067 - training loss: 0.3245, validation loss: 0.1632
2024-05-23 19:05:58 [INFO]: Epoch 068 - training loss: 0.3227, validation loss: 0.1626
2024-05-23 19:06:00 [INFO]: Epoch 069 - training loss: 0.3216, validation loss: 0.1615
2024-05-23 19:06:02 [INFO]: Epoch 070 - training loss: 0.3202, validation loss: 0.1602
2024-05-23 19:06:04 [INFO]: Epoch 071 - training loss: 0.3193, validation loss: 0.1593
2024-05-23 19:06:06 [INFO]: Epoch 072 - training loss: 0.3181, validation loss: 0.1584
2024-05-23 19:06:09 [INFO]: Epoch 073 - training loss: 0.3164, validation loss: 0.1575
2024-05-23 19:06:11 [INFO]: Epoch 074 - training loss: 0.3159, validation loss: 0.1568
2024-05-23 19:06:13 [INFO]: Epoch 075 - training loss: 0.3144, validation loss: 0.1562
2024-05-23 19:06:15 [INFO]: Epoch 076 - training loss: 0.3134, validation loss: 0.1553
2024-05-23 19:06:18 [INFO]: Epoch 077 - training loss: 0.3122, validation loss: 0.1541
2024-05-23 19:06:20 [INFO]: Epoch 078 - training loss: 0.3115, validation loss: 0.1534
2024-05-23 19:06:22 [INFO]: Epoch 079 - training loss: 0.3107, validation loss: 0.1525
2024-05-23 19:06:24 [INFO]: Epoch 080 - training loss: 0.3109, validation loss: 0.1522
2024-05-23 19:06:27 [INFO]: Epoch 081 - training loss: 0.3083, validation loss: 0.1508
2024-05-23 19:06:29 [INFO]: Epoch 082 - training loss: 0.3074, validation loss: 0.1502
2024-05-23 19:06:31 [INFO]: Epoch 083 - training loss: 0.3072, validation loss: 0.1495
2024-05-23 19:06:33 [INFO]: Epoch 084 - training loss: 0.3059, validation loss: 0.1487
2024-05-23 19:06:35 [INFO]: Epoch 085 - training loss: 0.3050, validation loss: 0.1485
2024-05-23 19:06:38 [INFO]: Epoch 086 - training loss: 0.3036, validation loss: 0.1474
2024-05-23 19:06:40 [INFO]: Epoch 087 - training loss: 0.3032, validation loss: 0.1469
2024-05-23 19:06:42 [INFO]: Epoch 088 - training loss: 0.3030, validation loss: 0.1460
2024-05-23 19:06:44 [INFO]: Epoch 089 - training loss: 0.3016, validation loss: 0.1455
2024-05-23 19:06:47 [INFO]: Epoch 090 - training loss: 0.3008, validation loss: 0.1450
2024-05-23 19:06:49 [INFO]: Epoch 091 - training loss: 0.3000, validation loss: 0.1443
2024-05-23 19:06:51 [INFO]: Epoch 092 - training loss: 0.2992, validation loss: 0.1433
2024-05-23 19:06:53 [INFO]: Epoch 093 - training loss: 0.2986, validation loss: 0.1428
2024-05-23 19:06:55 [INFO]: Epoch 094 - training loss: 0.2985, validation loss: 0.1424
2024-05-23 19:06:58 [INFO]: Epoch 095 - training loss: 0.2974, validation loss: 0.1416
2024-05-23 19:07:00 [INFO]: Epoch 096 - training loss: 0.2968, validation loss: 0.1408
2024-05-23 19:07:02 [INFO]: Epoch 097 - training loss: 0.2956, validation loss: 0.1402
2024-05-23 19:07:04 [INFO]: Epoch 098 - training loss: 0.2951, validation loss: 0.1398
2024-05-23 19:07:07 [INFO]: Epoch 099 - training loss: 0.2947, validation loss: 0.1392
2024-05-23 19:07:09 [INFO]: Epoch 100 - training loss: 0.2940, validation loss: 0.1387
2024-05-23 19:07:11 [INFO]: Epoch 101 - training loss: 0.2929, validation loss: 0.1378
2024-05-23 19:07:13 [INFO]: Epoch 102 - training loss: 0.2928, validation loss: 0.1375
2024-05-23 19:07:15 [INFO]: Epoch 103 - training loss: 0.2918, validation loss: 0.1369
2024-05-23 19:07:18 [INFO]: Epoch 104 - training loss: 0.2920, validation loss: 0.1364
2024-05-23 19:07:20 [INFO]: Epoch 105 - training loss: 0.2906, validation loss: 0.1359
2024-05-23 19:07:22 [INFO]: Epoch 106 - training loss: 0.2906, validation loss: 0.1353
2024-05-23 19:07:24 [INFO]: Epoch 107 - training loss: 0.2899, validation loss: 0.1346
2024-05-23 19:07:27 [INFO]: Epoch 108 - training loss: 0.2888, validation loss: 0.1342
2024-05-23 19:07:29 [INFO]: Epoch 109 - training loss: 0.2886, validation loss: 0.1339
2024-05-23 19:07:31 [INFO]: Epoch 110 - training loss: 0.2882, validation loss: 0.1333
2024-05-23 19:07:33 [INFO]: Epoch 111 - training loss: 0.2873, validation loss: 0.1328
2024-05-23 19:07:36 [INFO]: Epoch 112 - training loss: 0.2866, validation loss: 0.1321
2024-05-23 19:07:38 [INFO]: Epoch 113 - training loss: 0.2865, validation loss: 0.1316
2024-05-23 19:07:40 [INFO]: Epoch 114 - training loss: 0.2860, validation loss: 0.1313
2024-05-23 19:07:42 [INFO]: Epoch 115 - training loss: 0.2854, validation loss: 0.1308
2024-05-23 19:07:44 [INFO]: Epoch 116 - training loss: 0.2850, validation loss: 0.1303
2024-05-23 19:07:47 [INFO]: Epoch 117 - training loss: 0.2840, validation loss: 0.1299
2024-05-23 19:07:49 [INFO]: Epoch 118 - training loss: 0.2838, validation loss: 0.1294
2024-05-23 19:07:51 [INFO]: Epoch 119 - training loss: 0.2829, validation loss: 0.1290
2024-05-23 19:07:53 [INFO]: Epoch 120 - training loss: 0.2825, validation loss: 0.1287
2024-05-23 19:07:56 [INFO]: Epoch 121 - training loss: 0.2826, validation loss: 0.1280
2024-05-23 19:07:58 [INFO]: Epoch 122 - training loss: 0.2819, validation loss: 0.1276
2024-05-23 19:08:00 [INFO]: Epoch 123 - training loss: 0.2811, validation loss: 0.1272
2024-05-23 19:08:02 [INFO]: Epoch 124 - training loss: 0.2811, validation loss: 0.1268
2024-05-23 19:08:04 [INFO]: Epoch 125 - training loss: 0.2798, validation loss: 0.1265
2024-05-23 19:08:07 [INFO]: Epoch 126 - training loss: 0.2797, validation loss: 0.1260
2024-05-23 19:08:09 [INFO]: Epoch 127 - training loss: 0.2796, validation loss: 0.1256
2024-05-23 19:08:11 [INFO]: Epoch 128 - training loss: 0.2788, validation loss: 0.1250
2024-05-23 19:08:13 [INFO]: Epoch 129 - training loss: 0.2783, validation loss: 0.1250
2024-05-23 19:08:16 [INFO]: Epoch 130 - training loss: 0.2785, validation loss: 0.1243
2024-05-23 19:08:18 [INFO]: Epoch 131 - training loss: 0.2776, validation loss: 0.1243
2024-05-23 19:08:20 [INFO]: Epoch 132 - training loss: 0.2772, validation loss: 0.1236
2024-05-23 19:08:22 [INFO]: Epoch 133 - training loss: 0.2765, validation loss: 0.1234
2024-05-23 19:08:25 [INFO]: Epoch 134 - training loss: 0.2763, validation loss: 0.1229
2024-05-23 19:08:27 [INFO]: Epoch 135 - training loss: 0.2763, validation loss: 0.1225
2024-05-23 19:08:29 [INFO]: Epoch 136 - training loss: 0.2755, validation loss: 0.1221
2024-05-23 19:08:31 [INFO]: Epoch 137 - training loss: 0.2751, validation loss: 0.1218
2024-05-23 19:08:34 [INFO]: Epoch 138 - training loss: 0.2753, validation loss: 0.1214
2024-05-23 19:08:36 [INFO]: Epoch 139 - training loss: 0.2749, validation loss: 0.1211
2024-05-23 19:08:38 [INFO]: Epoch 140 - training loss: 0.2737, validation loss: 0.1209
2024-05-23 19:08:40 [INFO]: Epoch 141 - training loss: 0.2742, validation loss: 0.1205
2024-05-23 19:08:43 [INFO]: Epoch 142 - training loss: 0.2734, validation loss: 0.1200
2024-05-23 19:08:45 [INFO]: Epoch 143 - training loss: 0.2726, validation loss: 0.1198
2024-05-23 19:08:47 [INFO]: Epoch 144 - training loss: 0.2720, validation loss: 0.1194
2024-05-23 19:08:49 [INFO]: Epoch 145 - training loss: 0.2723, validation loss: 0.1186
2024-05-23 19:08:51 [INFO]: Epoch 146 - training loss: 0.2726, validation loss: 0.1186
2024-05-23 19:08:54 [INFO]: Epoch 147 - training loss: 0.2713, validation loss: 0.1182
2024-05-23 19:08:56 [INFO]: Epoch 148 - training loss: 0.2711, validation loss: 0.1181
2024-05-23 19:08:58 [INFO]: Epoch 149 - training loss: 0.2704, validation loss: 0.1175
2024-05-23 19:09:01 [INFO]: Epoch 150 - training loss: 0.2707, validation loss: 0.1172
2024-05-23 19:09:03 [INFO]: Epoch 151 - training loss: 0.2694, validation loss: 0.1169
2024-05-23 19:09:05 [INFO]: Epoch 152 - training loss: 0.2695, validation loss: 0.1164
2024-05-23 19:09:07 [INFO]: Epoch 153 - training loss: 0.2693, validation loss: 0.1162
2024-05-23 19:09:09 [INFO]: Epoch 154 - training loss: 0.2691, validation loss: 0.1160
2024-05-23 19:09:12 [INFO]: Epoch 155 - training loss: 0.2688, validation loss: 0.1156
2024-05-23 19:09:14 [INFO]: Epoch 156 - training loss: 0.2683, validation loss: 0.1153
2024-05-23 19:09:16 [INFO]: Epoch 157 - training loss: 0.2680, validation loss: 0.1150
2024-05-23 19:09:18 [INFO]: Epoch 158 - training loss: 0.2677, validation loss: 0.1146
2024-05-23 19:09:20 [INFO]: Epoch 159 - training loss: 0.2674, validation loss: 0.1143
2024-05-23 19:09:23 [INFO]: Epoch 160 - training loss: 0.2675, validation loss: 0.1140
2024-05-23 19:09:25 [INFO]: Epoch 161 - training loss: 0.2671, validation loss: 0.1139
2024-05-23 19:09:27 [INFO]: Epoch 162 - training loss: 0.2664, validation loss: 0.1135
2024-05-23 19:09:29 [INFO]: Epoch 163 - training loss: 0.2665, validation loss: 0.1132
2024-05-23 19:09:32 [INFO]: Epoch 164 - training loss: 0.2656, validation loss: 0.1129
2024-05-23 19:09:34 [INFO]: Epoch 165 - training loss: 0.2654, validation loss: 0.1128
2024-05-23 19:09:36 [INFO]: Epoch 166 - training loss: 0.2652, validation loss: 0.1125
2024-05-23 19:09:38 [INFO]: Epoch 167 - training loss: 0.2650, validation loss: 0.1126
2024-05-23 19:09:41 [INFO]: Epoch 168 - training loss: 0.2642, validation loss: 0.1119
2024-05-23 19:09:43 [INFO]: Epoch 169 - training loss: 0.2644, validation loss: 0.1117
2024-05-23 19:09:45 [INFO]: Epoch 170 - training loss: 0.2643, validation loss: 0.1116
2024-05-23 19:09:47 [INFO]: Epoch 171 - training loss: 0.2638, validation loss: 0.1112
2024-05-23 19:09:49 [INFO]: Epoch 172 - training loss: 0.2638, validation loss: 0.1109
2024-05-23 19:09:52 [INFO]: Epoch 173 - training loss: 0.2634, validation loss: 0.1107
2024-05-23 19:09:54 [INFO]: Epoch 174 - training loss: 0.2633, validation loss: 0.1105
2024-05-23 19:09:56 [INFO]: Epoch 175 - training loss: 0.2628, validation loss: 0.1101
2024-05-23 19:09:58 [INFO]: Epoch 176 - training loss: 0.2621, validation loss: 0.1100
2024-05-23 19:10:00 [INFO]: Epoch 177 - training loss: 0.2620, validation loss: 0.1097
2024-05-23 19:10:03 [INFO]: Epoch 178 - training loss: 0.2618, validation loss: 0.1094
2024-05-23 19:10:05 [INFO]: Epoch 179 - training loss: 0.2617, validation loss: 0.1093
2024-05-23 19:10:07 [INFO]: Epoch 180 - training loss: 0.2614, validation loss: 0.1091
2024-05-23 19:10:09 [INFO]: Epoch 181 - training loss: 0.2615, validation loss: 0.1088
2024-05-23 19:10:12 [INFO]: Epoch 182 - training loss: 0.2615, validation loss: 0.1088
2024-05-23 19:10:14 [INFO]: Epoch 183 - training loss: 0.2606, validation loss: 0.1085
2024-05-23 19:10:16 [INFO]: Epoch 184 - training loss: 0.2605, validation loss: 0.1080
2024-05-23 19:10:18 [INFO]: Epoch 185 - training loss: 0.2600, validation loss: 0.1078
2024-05-23 19:10:20 [INFO]: Epoch 186 - training loss: 0.2606, validation loss: 0.1076
2024-05-23 19:10:23 [INFO]: Epoch 187 - training loss: 0.2595, validation loss: 0.1075
2024-05-23 19:10:25 [INFO]: Epoch 188 - training loss: 0.2590, validation loss: 0.1073
2024-05-23 19:10:27 [INFO]: Epoch 189 - training loss: 0.2595, validation loss: 0.1069
2024-05-23 19:10:29 [INFO]: Epoch 190 - training loss: 0.2594, validation loss: 0.1066
2024-05-23 19:10:32 [INFO]: Epoch 191 - training loss: 0.2587, validation loss: 0.1065
2024-05-23 19:10:34 [INFO]: Epoch 192 - training loss: 0.2594, validation loss: 0.1065
2024-05-23 19:10:36 [INFO]: Epoch 193 - training loss: 0.2588, validation loss: 0.1061
2024-05-23 19:10:38 [INFO]: Epoch 194 - training loss: 0.2580, validation loss: 0.1058
2024-05-23 19:10:41 [INFO]: Epoch 195 - training loss: 0.2585, validation loss: 0.1056
2024-05-23 19:10:43 [INFO]: Epoch 196 - training loss: 0.2578, validation loss: 0.1056
2024-05-23 19:10:45 [INFO]: Epoch 197 - training loss: 0.2576, validation loss: 0.1051
2024-05-23 19:10:47 [INFO]: Epoch 198 - training loss: 0.2572, validation loss: 0.1050
2024-05-23 19:10:49 [INFO]: Epoch 199 - training loss: 0.2571, validation loss: 0.1049
2024-05-23 19:10:52 [INFO]: Epoch 200 - training loss: 0.2567, validation loss: 0.1048
2024-05-23 19:10:54 [INFO]: Epoch 201 - training loss: 0.2565, validation loss: 0.1046
2024-05-23 19:10:56 [INFO]: Epoch 202 - training loss: 0.2562, validation loss: 0.1043
2024-05-23 19:10:58 [INFO]: Epoch 203 - training loss: 0.2563, validation loss: 0.1040
2024-05-23 19:11:01 [INFO]: Epoch 204 - training loss: 0.2560, validation loss: 0.1041
2024-05-23 19:11:03 [INFO]: Epoch 205 - training loss: 0.2554, validation loss: 0.1036
2024-05-23 19:11:05 [INFO]: Epoch 206 - training loss: 0.2553, validation loss: 0.1037
2024-05-23 19:11:07 [INFO]: Epoch 207 - training loss: 0.2554, validation loss: 0.1033
2024-05-23 19:11:10 [INFO]: Epoch 208 - training loss: 0.2551, validation loss: 0.1032
2024-05-23 19:11:12 [INFO]: Epoch 209 - training loss: 0.2545, validation loss: 0.1031
2024-05-23 19:11:14 [INFO]: Epoch 210 - training loss: 0.2552, validation loss: 0.1027
2024-05-23 19:11:16 [INFO]: Epoch 211 - training loss: 0.2546, validation loss: 0.1027
2024-05-23 19:11:18 [INFO]: Epoch 212 - training loss: 0.2542, validation loss: 0.1025
2024-05-23 19:11:21 [INFO]: Epoch 213 - training loss: 0.2543, validation loss: 0.1023
2024-05-23 19:11:23 [INFO]: Epoch 214 - training loss: 0.2547, validation loss: 0.1021
2024-05-23 19:11:25 [INFO]: Epoch 215 - training loss: 0.2540, validation loss: 0.1020
2024-05-23 19:11:27 [INFO]: Epoch 216 - training loss: 0.2533, validation loss: 0.1017
2024-05-23 19:11:30 [INFO]: Epoch 217 - training loss: 0.2534, validation loss: 0.1016
2024-05-23 19:11:32 [INFO]: Epoch 218 - training loss: 0.2529, validation loss: 0.1017
2024-05-23 19:11:34 [INFO]: Epoch 219 - training loss: 0.2530, validation loss: 0.1015
2024-05-23 19:11:36 [INFO]: Epoch 220 - training loss: 0.2528, validation loss: 0.1011
2024-05-23 19:11:39 [INFO]: Epoch 221 - training loss: 0.2531, validation loss: 0.1009
2024-05-23 19:11:41 [INFO]: Epoch 222 - training loss: 0.2527, validation loss: 0.1008
2024-05-23 19:11:43 [INFO]: Epoch 223 - training loss: 0.2520, validation loss: 0.1007
2024-05-23 19:11:45 [INFO]: Epoch 224 - training loss: 0.2518, validation loss: 0.1006
2024-05-23 19:11:48 [INFO]: Epoch 225 - training loss: 0.2516, validation loss: 0.1002
2024-05-23 19:11:50 [INFO]: Epoch 226 - training loss: 0.2518, validation loss: 0.1002
2024-05-23 19:11:52 [INFO]: Epoch 227 - training loss: 0.2511, validation loss: 0.1001
2024-05-23 19:11:54 [INFO]: Epoch 228 - training loss: 0.2515, validation loss: 0.1000
2024-05-23 19:11:56 [INFO]: Epoch 229 - training loss: 0.2509, validation loss: 0.0997
2024-05-23 19:11:59 [INFO]: Epoch 230 - training loss: 0.2508, validation loss: 0.0998
2024-05-23 19:12:01 [INFO]: Epoch 231 - training loss: 0.2510, validation loss: 0.0997
2024-05-23 19:12:03 [INFO]: Epoch 232 - training loss: 0.2506, validation loss: 0.0993
2024-05-23 19:12:05 [INFO]: Epoch 233 - training loss: 0.2502, validation loss: 0.0990
2024-05-23 19:12:07 [INFO]: Epoch 234 - training loss: 0.2501, validation loss: 0.0991
2024-05-23 19:12:10 [INFO]: Epoch 235 - training loss: 0.2501, validation loss: 0.0990
2024-05-23 19:12:12 [INFO]: Epoch 236 - training loss: 0.2499, validation loss: 0.0988
2024-05-23 19:12:14 [INFO]: Epoch 237 - training loss: 0.2496, validation loss: 0.0987
2024-05-23 19:12:16 [INFO]: Epoch 238 - training loss: 0.2494, validation loss: 0.0987
2024-05-23 19:12:19 [INFO]: Epoch 239 - training loss: 0.2496, validation loss: 0.0983
2024-05-23 19:12:21 [INFO]: Epoch 240 - training loss: 0.2491, validation loss: 0.0982
2024-05-23 19:12:23 [INFO]: Epoch 241 - training loss: 0.2494, validation loss: 0.0981
2024-05-23 19:12:25 [INFO]: Epoch 242 - training loss: 0.2486, validation loss: 0.0979
2024-05-23 19:12:28 [INFO]: Epoch 243 - training loss: 0.2490, validation loss: 0.0979
2024-05-23 19:12:30 [INFO]: Epoch 244 - training loss: 0.2485, validation loss: 0.0979
2024-05-23 19:12:32 [INFO]: Epoch 245 - training loss: 0.2488, validation loss: 0.0976
2024-05-23 19:12:34 [INFO]: Epoch 246 - training loss: 0.2480, validation loss: 0.0973
2024-05-23 19:12:36 [INFO]: Epoch 247 - training loss: 0.2478, validation loss: 0.0974
2024-05-23 19:12:39 [INFO]: Epoch 248 - training loss: 0.2474, validation loss: 0.0971
2024-05-23 19:12:41 [INFO]: Epoch 249 - training loss: 0.2478, validation loss: 0.0971
2024-05-23 19:12:43 [INFO]: Epoch 250 - training loss: 0.2476, validation loss: 0.0971
2024-05-23 19:12:45 [INFO]: Epoch 251 - training loss: 0.2472, validation loss: 0.0969
2024-05-23 19:12:48 [INFO]: Epoch 252 - training loss: 0.2468, validation loss: 0.0968
2024-05-23 19:12:50 [INFO]: Epoch 253 - training loss: 0.2469, validation loss: 0.0968
2024-05-23 19:12:52 [INFO]: Epoch 254 - training loss: 0.2468, validation loss: 0.0965
2024-05-23 19:12:54 [INFO]: Epoch 255 - training loss: 0.2469, validation loss: 0.0965
2024-05-23 19:12:56 [INFO]: Epoch 256 - training loss: 0.2465, validation loss: 0.0963
2024-05-23 19:12:59 [INFO]: Epoch 257 - training loss: 0.2462, validation loss: 0.0962
2024-05-23 19:13:01 [INFO]: Epoch 258 - training loss: 0.2462, validation loss: 0.0959
2024-05-23 19:13:03 [INFO]: Epoch 259 - training loss: 0.2468, validation loss: 0.0959
2024-05-23 19:13:05 [INFO]: Epoch 260 - training loss: 0.2465, validation loss: 0.0960
2024-05-23 19:13:08 [INFO]: Epoch 261 - training loss: 0.2458, validation loss: 0.0957
2024-05-23 19:13:10 [INFO]: Epoch 262 - training loss: 0.2459, validation loss: 0.0956
2024-05-23 19:13:12 [INFO]: Epoch 263 - training loss: 0.2452, validation loss: 0.0954
2024-05-23 19:13:14 [INFO]: Epoch 264 - training loss: 0.2464, validation loss: 0.0953
2024-05-23 19:13:16 [INFO]: Epoch 265 - training loss: 0.2458, validation loss: 0.0951
2024-05-23 19:13:19 [INFO]: Epoch 266 - training loss: 0.2450, validation loss: 0.0952
2024-05-23 19:13:21 [INFO]: Epoch 267 - training loss: 0.2448, validation loss: 0.0949
2024-05-23 19:13:23 [INFO]: Epoch 268 - training loss: 0.2454, validation loss: 0.0949
2024-05-23 19:13:25 [INFO]: Epoch 269 - training loss: 0.2445, validation loss: 0.0947
2024-05-23 19:13:27 [INFO]: Epoch 270 - training loss: 0.2451, validation loss: 0.0949
2024-05-23 19:13:30 [INFO]: Epoch 271 - training loss: 0.2442, validation loss: 0.0945
2024-05-23 19:13:32 [INFO]: Epoch 272 - training loss: 0.2445, validation loss: 0.0945
2024-05-23 19:13:34 [INFO]: Epoch 273 - training loss: 0.2441, validation loss: 0.0944
2024-05-23 19:13:36 [INFO]: Epoch 274 - training loss: 0.2441, validation loss: 0.0943
2024-05-23 19:13:39 [INFO]: Epoch 275 - training loss: 0.2439, validation loss: 0.0943
2024-05-23 19:13:41 [INFO]: Epoch 276 - training loss: 0.2440, validation loss: 0.0941
2024-05-23 19:13:43 [INFO]: Epoch 277 - training loss: 0.2439, validation loss: 0.0940
2024-05-23 19:13:45 [INFO]: Epoch 278 - training loss: 0.2437, validation loss: 0.0940
2024-05-23 19:13:47 [INFO]: Epoch 279 - training loss: 0.2433, validation loss: 0.0940
2024-05-23 19:13:50 [INFO]: Epoch 280 - training loss: 0.2434, validation loss: 0.0937
2024-05-23 19:13:52 [INFO]: Epoch 281 - training loss: 0.2435, validation loss: 0.0937
2024-05-23 19:13:54 [INFO]: Epoch 282 - training loss: 0.2432, validation loss: 0.0936
2024-05-23 19:13:56 [INFO]: Epoch 283 - training loss: 0.2430, validation loss: 0.0936
2024-05-23 19:13:59 [INFO]: Epoch 284 - training loss: 0.2424, validation loss: 0.0935
2024-05-23 19:14:01 [INFO]: Epoch 285 - training loss: 0.2425, validation loss: 0.0933
2024-05-23 19:14:03 [INFO]: Epoch 286 - training loss: 0.2425, validation loss: 0.0933
2024-05-23 19:14:05 [INFO]: Epoch 287 - training loss: 0.2427, validation loss: 0.0933
2024-05-23 19:14:08 [INFO]: Epoch 288 - training loss: 0.2423, validation loss: 0.0931
2024-05-23 19:14:10 [INFO]: Epoch 289 - training loss: 0.2425, validation loss: 0.0930
2024-05-23 19:14:12 [INFO]: Epoch 290 - training loss: 0.2421, validation loss: 0.0930
2024-05-23 19:14:14 [INFO]: Epoch 291 - training loss: 0.2423, validation loss: 0.0930
2024-05-23 19:14:17 [INFO]: Epoch 292 - training loss: 0.2420, validation loss: 0.0926
2024-05-23 19:14:19 [INFO]: Epoch 293 - training loss: 0.2425, validation loss: 0.0929
2024-05-23 19:14:21 [INFO]: Epoch 294 - training loss: 0.2415, validation loss: 0.0927
2024-05-23 19:14:23 [INFO]: Epoch 295 - training loss: 0.2417, validation loss: 0.0929
2024-05-23 19:14:26 [INFO]: Epoch 296 - training loss: 0.2413, validation loss: 0.0924
2024-05-23 19:14:28 [INFO]: Epoch 297 - training loss: 0.2415, validation loss: 0.0925
2024-05-23 19:14:30 [INFO]: Epoch 298 - training loss: 0.2412, validation loss: 0.0922
2024-05-23 19:14:32 [INFO]: Epoch 299 - training loss: 0.2411, validation loss: 0.0923
2024-05-23 19:14:35 [INFO]: Epoch 300 - training loss: 0.2413, validation loss: 0.0923
2024-05-23 19:14:35 [INFO]: Finished training. The best model is from epoch#298.
2024-05-23 19:14:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240523_T190325/BRITS.pypots
2024-05-23 19:14:35 [INFO]: BRITS on Air-Quality: MAE=0.1419, MSE=0.1310
2024-05-23 19:14:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-23 19:14:35 [INFO]: Using the given device: cuda:0
2024-05-23 19:14:35 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435
2024-05-23 19:14:35 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/tensorboard
2024-05-23 19:14:35 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 19:14:39 [INFO]: Epoch 001 - training loss: 1.4763, validation loss: 0.8048
2024-05-23 19:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch1_loss0.8047537565231323.pypots
2024-05-23 19:14:42 [INFO]: Epoch 002 - training loss: 1.0390, validation loss: 0.7514
2024-05-23 19:14:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch2_loss0.7514429479837418.pypots
2024-05-23 19:14:45 [INFO]: Epoch 003 - training loss: 0.9697, validation loss: 0.7342
2024-05-23 19:14:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch3_loss0.734213063120842.pypots
2024-05-23 19:14:48 [INFO]: Epoch 004 - training loss: 0.9279, validation loss: 0.7220
2024-05-23 19:14:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch4_loss0.7219545274972916.pypots
2024-05-23 19:14:51 [INFO]: Epoch 005 - training loss: 0.9188, validation loss: 0.7142
2024-05-23 19:14:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch5_loss0.7141962081193924.pypots
2024-05-23 19:14:54 [INFO]: Epoch 006 - training loss: 0.9192, validation loss: 0.7072
2024-05-23 19:14:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch6_loss0.7072414100170136.pypots
2024-05-23 19:14:57 [INFO]: Epoch 007 - training loss: 0.9035, validation loss: 0.7023
2024-05-23 19:14:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch7_loss0.7023297518491745.pypots
2024-05-23 19:15:00 [INFO]: Epoch 008 - training loss: 0.9137, validation loss: 0.6999
2024-05-23 19:15:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch8_loss0.6999002993106842.pypots
2024-05-23 19:15:03 [INFO]: Epoch 009 - training loss: 0.8916, validation loss: 0.6969
2024-05-23 19:15:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch9_loss0.6968973785638809.pypots
2024-05-23 19:15:06 [INFO]: Epoch 010 - training loss: 0.8859, validation loss: 0.6946
2024-05-23 19:15:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch10_loss0.6945709973573685.pypots
2024-05-23 19:15:09 [INFO]: Epoch 011 - training loss: 0.8823, validation loss: 0.6927
2024-05-23 19:15:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch11_loss0.6927210330963135.pypots
2024-05-23 19:15:12 [INFO]: Epoch 012 - training loss: 0.8700, validation loss: 0.6913
2024-05-23 19:15:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch12_loss0.6912765890359879.pypots
2024-05-23 19:15:15 [INFO]: Epoch 013 - training loss: 0.8840, validation loss: 0.6902
2024-05-23 19:15:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch13_loss0.6902486681938171.pypots
2024-05-23 19:15:18 [INFO]: Epoch 014 - training loss: 0.8676, validation loss: 0.6897
2024-05-23 19:15:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch14_loss0.6897142589092254.pypots
2024-05-23 19:15:21 [INFO]: Epoch 015 - training loss: 0.8633, validation loss: 0.6889
2024-05-23 19:15:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch15_loss0.6888961315155029.pypots
2024-05-23 19:15:24 [INFO]: Epoch 016 - training loss: 0.8705, validation loss: 0.6883
2024-05-23 19:15:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch16_loss0.6882634401321411.pypots
2024-05-23 19:15:27 [INFO]: Epoch 017 - training loss: 0.8787, validation loss: 0.6871
2024-05-23 19:15:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch17_loss0.6871446818113327.pypots
2024-05-23 19:15:30 [INFO]: Epoch 018 - training loss: 0.8659, validation loss: 0.6863
2024-05-23 19:15:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch18_loss0.6863061934709549.pypots
2024-05-23 19:15:33 [INFO]: Epoch 019 - training loss: 0.8499, validation loss: 0.6864
2024-05-23 19:15:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch19_loss0.6863596767187119.pypots
2024-05-23 19:15:36 [INFO]: Epoch 020 - training loss: 0.8425, validation loss: 0.6861
2024-05-23 19:15:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch20_loss0.6860759526491165.pypots
2024-05-23 19:15:39 [INFO]: Epoch 021 - training loss: 0.8647, validation loss: 0.6865
2024-05-23 19:15:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch21_loss0.6864659041166306.pypots
2024-05-23 19:15:42 [INFO]: Epoch 022 - training loss: 0.8522, validation loss: 0.6855
2024-05-23 19:15:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch22_loss0.6854527920484543.pypots
2024-05-23 19:15:45 [INFO]: Epoch 023 - training loss: 0.8344, validation loss: 0.6854
2024-05-23 19:15:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch23_loss0.6853985846042633.pypots
2024-05-23 19:15:48 [INFO]: Epoch 024 - training loss: 0.8307, validation loss: 0.6885
2024-05-23 19:15:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch24_loss0.6884523242712021.pypots
2024-05-23 19:15:51 [INFO]: Epoch 025 - training loss: 0.8600, validation loss: 0.6892
2024-05-23 19:15:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch25_loss0.6892216056585312.pypots
2024-05-23 19:15:55 [INFO]: Epoch 026 - training loss: 0.8663, validation loss: 0.6858
2024-05-23 19:15:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch26_loss0.6857717484235764.pypots
2024-05-23 19:15:58 [INFO]: Epoch 027 - training loss: 0.8396, validation loss: 0.6904
2024-05-23 19:15:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch27_loss0.6903958112001419.pypots
2024-05-23 19:16:01 [INFO]: Epoch 028 - training loss: 0.8766, validation loss: 0.6870
2024-05-23 19:16:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch28_loss0.6869643121957779.pypots
2024-05-23 19:16:04 [INFO]: Epoch 029 - training loss: 0.8559, validation loss: 0.6890
2024-05-23 19:16:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch29_loss0.6889775454998016.pypots
2024-05-23 19:16:07 [INFO]: Epoch 030 - training loss: 0.8568, validation loss: 0.6853
2024-05-23 19:16:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch30_loss0.6852956503629685.pypots
2024-05-23 19:16:10 [INFO]: Epoch 031 - training loss: 0.8438, validation loss: 0.6883
2024-05-23 19:16:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch31_loss0.6882620066404342.pypots
2024-05-23 19:16:13 [INFO]: Epoch 032 - training loss: 0.8210, validation loss: 0.6872
2024-05-23 19:16:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch32_loss0.6871781170368194.pypots
2024-05-23 19:16:16 [INFO]: Epoch 033 - training loss: 0.8321, validation loss: 0.6898
2024-05-23 19:16:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch33_loss0.6897745639085769.pypots
2024-05-23 19:16:19 [INFO]: Epoch 034 - training loss: 0.8172, validation loss: 0.6877
2024-05-23 19:16:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch34_loss0.6876658916473388.pypots
2024-05-23 19:16:22 [INFO]: Epoch 035 - training loss: 0.8134, validation loss: 0.6891
2024-05-23 19:16:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch35_loss0.689099007844925.pypots
2024-05-23 19:16:25 [INFO]: Epoch 036 - training loss: 0.8317, validation loss: 0.6884
2024-05-23 19:16:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch36_loss0.6884179472923279.pypots
2024-05-23 19:16:28 [INFO]: Epoch 037 - training loss: 0.8048, validation loss: 0.6873
2024-05-23 19:16:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch37_loss0.6873286068439484.pypots
2024-05-23 19:16:31 [INFO]: Epoch 038 - training loss: 0.8095, validation loss: 0.6915
2024-05-23 19:16:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch38_loss0.6914701402187348.pypots
2024-05-23 19:16:34 [INFO]: Epoch 039 - training loss: 0.8119, validation loss: 0.6887
2024-05-23 19:16:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch39_loss0.6887453109025955.pypots
2024-05-23 19:16:37 [INFO]: Epoch 040 - training loss: 0.8267, validation loss: 0.6910
2024-05-23 19:16:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN_epoch40_loss0.6909890741109848.pypots
2024-05-23 19:16:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:16:37 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 19:16:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240523_T191435/MRNN.pypots
2024-05-23 19:16:38 [INFO]: MRNN on Air-Quality: MAE=0.5199, MSE=0.6610
2024-05-23 19:16:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-23 19:16:38 [INFO]: Using the given device: cpu
2024-05-23 19:16:38 [INFO]: LOCF on Air-Quality: MAE=0.2050, MSE=0.3453
2024-05-23 19:16:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-23 19:16:38 [INFO]: Median on Air-Quality: MAE=0.6635, MSE=1.0575
2024-05-23 19:16:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-23 19:16:38 [INFO]: Mean on Air-Quality: MAE=0.6949, MSE=0.9966
2024-05-23 19:16:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-23 19:16:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-23 19:16:38 [INFO]: Using the given device: cuda:0
2024-05-23 19:16:38 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240523_T191638
2024-05-23 19:16:38 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240523_T191638/tensorboard
2024-05-23 19:16:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 19:16:38 [INFO]: Epoch 001 - training loss: 1.0416, validation loss: 0.5351
2024-05-23 19:16:39 [INFO]: Epoch 002 - training loss: 0.7492, validation loss: 0.3974
2024-05-23 19:16:40 [INFO]: Epoch 003 - training loss: 0.6453, validation loss: 0.3213
2024-05-23 19:16:41 [INFO]: Epoch 004 - training loss: 0.5715, validation loss: 0.2812
2024-05-23 19:16:42 [INFO]: Epoch 005 - training loss: 0.5182, validation loss: 0.2598
2024-05-23 19:16:42 [INFO]: Epoch 006 - training loss: 0.4801, validation loss: 0.2435
2024-05-23 19:16:43 [INFO]: Epoch 007 - training loss: 0.4530, validation loss: 0.2330
2024-05-23 19:16:43 [INFO]: Epoch 008 - training loss: 0.4330, validation loss: 0.2240
2024-05-23 19:16:44 [INFO]: Epoch 009 - training loss: 0.4179, validation loss: 0.2183
2024-05-23 19:16:44 [INFO]: Epoch 010 - training loss: 0.4052, validation loss: 0.2143
2024-05-23 19:16:45 [INFO]: Epoch 011 - training loss: 0.3981, validation loss: 0.2097
2024-05-23 19:16:46 [INFO]: Epoch 012 - training loss: 0.3878, validation loss: 0.2049
2024-05-23 19:16:46 [INFO]: Epoch 013 - training loss: 0.3790, validation loss: 0.2020
2024-05-23 19:16:47 [INFO]: Epoch 014 - training loss: 0.3707, validation loss: 0.1976
2024-05-23 19:16:47 [INFO]: Epoch 015 - training loss: 0.3641, validation loss: 0.1953
2024-05-23 19:16:48 [INFO]: Epoch 016 - training loss: 0.3589, validation loss: 0.1940
2024-05-23 19:16:49 [INFO]: Epoch 017 - training loss: 0.3526, validation loss: 0.1894
2024-05-23 19:16:49 [INFO]: Epoch 018 - training loss: 0.3482, validation loss: 0.1878
2024-05-23 19:16:50 [INFO]: Epoch 019 - training loss: 0.3443, validation loss: 0.1858
2024-05-23 19:16:50 [INFO]: Epoch 020 - training loss: 0.3396, validation loss: 0.1846
2024-05-23 19:16:51 [INFO]: Epoch 021 - training loss: 0.3343, validation loss: 0.1834
2024-05-23 19:16:52 [INFO]: Epoch 022 - training loss: 0.3314, validation loss: 0.1806
2024-05-23 19:16:52 [INFO]: Epoch 023 - training loss: 0.3277, validation loss: 0.1786
2024-05-23 19:16:53 [INFO]: Epoch 024 - training loss: 0.3254, validation loss: 0.1774
2024-05-23 19:16:53 [INFO]: Epoch 025 - training loss: 0.3221, validation loss: 0.1763
2024-05-23 19:16:54 [INFO]: Epoch 026 - training loss: 0.3195, validation loss: 0.1752
2024-05-23 19:16:54 [INFO]: Epoch 027 - training loss: 0.3161, validation loss: 0.1743
2024-05-23 19:16:57 [INFO]: Epoch 028 - training loss: 0.3126, validation loss: 0.1721
2024-05-23 19:16:57 [INFO]: Epoch 029 - training loss: 0.3091, validation loss: 0.1711
2024-05-23 19:16:58 [INFO]: Epoch 030 - training loss: 0.3074, validation loss: 0.1701
2024-05-23 19:16:59 [INFO]: Epoch 031 - training loss: 0.3047, validation loss: 0.1696
2024-05-23 19:16:59 [INFO]: Epoch 032 - training loss: 0.3048, validation loss: 0.1688
2024-05-23 19:17:00 [INFO]: Epoch 033 - training loss: 0.3013, validation loss: 0.1661
2024-05-23 19:17:00 [INFO]: Epoch 034 - training loss: 0.2987, validation loss: 0.1660
2024-05-23 19:17:01 [INFO]: Epoch 035 - training loss: 0.2972, validation loss: 0.1645
2024-05-23 19:17:01 [INFO]: Epoch 036 - training loss: 0.2937, validation loss: 0.1620
2024-05-23 19:17:02 [INFO]: Epoch 037 - training loss: 0.2927, validation loss: 0.1613
2024-05-23 19:17:03 [INFO]: Epoch 038 - training loss: 0.2909, validation loss: 0.1607
2024-05-23 19:17:03 [INFO]: Epoch 039 - training loss: 0.2883, validation loss: 0.1606
2024-05-23 19:17:04 [INFO]: Epoch 040 - training loss: 0.2861, validation loss: 0.1583
2024-05-23 19:17:04 [INFO]: Epoch 041 - training loss: 0.2846, validation loss: 0.1580
2024-05-23 19:17:05 [INFO]: Epoch 042 - training loss: 0.2821, validation loss: 0.1570
2024-05-23 19:17:06 [INFO]: Epoch 043 - training loss: 0.2815, validation loss: 0.1562
2024-05-23 19:17:06 [INFO]: Epoch 044 - training loss: 0.2798, validation loss: 0.1555
2024-05-23 19:17:07 [INFO]: Epoch 045 - training loss: 0.2773, validation loss: 0.1547
2024-05-23 19:17:07 [INFO]: Epoch 046 - training loss: 0.2754, validation loss: 0.1540
2024-05-23 19:17:08 [INFO]: Epoch 047 - training loss: 0.2752, validation loss: 0.1528
2024-05-23 19:17:09 [INFO]: Epoch 048 - training loss: 0.2732, validation loss: 0.1521
2024-05-23 19:17:09 [INFO]: Epoch 049 - training loss: 0.2728, validation loss: 0.1511
2024-05-23 19:17:10 [INFO]: Epoch 050 - training loss: 0.2724, validation loss: 0.1499
2024-05-23 19:17:10 [INFO]: Epoch 051 - training loss: 0.2705, validation loss: 0.1495
2024-05-23 19:17:11 [INFO]: Epoch 052 - training loss: 0.2664, validation loss: 0.1490
2024-05-23 19:17:12 [INFO]: Epoch 053 - training loss: 0.2643, validation loss: 0.1488
2024-05-23 19:17:12 [INFO]: Epoch 054 - training loss: 0.2626, validation loss: 0.1478
2024-05-23 19:17:13 [INFO]: Epoch 055 - training loss: 0.2617, validation loss: 0.1473
2024-05-23 19:17:13 [INFO]: Epoch 056 - training loss: 0.2606, validation loss: 0.1465
2024-05-23 19:17:14 [INFO]: Epoch 057 - training loss: 0.2589, validation loss: 0.1458
2024-05-23 19:17:14 [INFO]: Epoch 058 - training loss: 0.2570, validation loss: 0.1453
2024-05-23 19:17:15 [INFO]: Epoch 059 - training loss: 0.2556, validation loss: 0.1441
2024-05-23 19:17:16 [INFO]: Epoch 060 - training loss: 0.2546, validation loss: 0.1433
2024-05-23 19:17:16 [INFO]: Epoch 061 - training loss: 0.2530, validation loss: 0.1430
2024-05-23 19:17:17 [INFO]: Epoch 062 - training loss: 0.2528, validation loss: 0.1424
2024-05-23 19:17:17 [INFO]: Epoch 063 - training loss: 0.2519, validation loss: 0.1413
2024-05-23 19:17:18 [INFO]: Epoch 064 - training loss: 0.2490, validation loss: 0.1416
2024-05-23 19:17:18 [INFO]: Epoch 065 - training loss: 0.2486, validation loss: 0.1410
2024-05-23 19:17:19 [INFO]: Epoch 066 - training loss: 0.2469, validation loss: 0.1403
2024-05-23 19:17:20 [INFO]: Epoch 067 - training loss: 0.2460, validation loss: 0.1396
2024-05-23 19:17:20 [INFO]: Epoch 068 - training loss: 0.2440, validation loss: 0.1399
2024-05-23 19:17:21 [INFO]: Epoch 069 - training loss: 0.2436, validation loss: 0.1406
2024-05-23 19:17:21 [INFO]: Epoch 070 - training loss: 0.2420, validation loss: 0.1389
2024-05-23 19:17:22 [INFO]: Epoch 071 - training loss: 0.2414, validation loss: 0.1385
2024-05-23 19:17:23 [INFO]: Epoch 072 - training loss: 0.2406, validation loss: 0.1383
2024-05-23 19:17:23 [INFO]: Epoch 073 - training loss: 0.2385, validation loss: 0.1379
2024-05-23 19:17:24 [INFO]: Epoch 074 - training loss: 0.2373, validation loss: 0.1375
2024-05-23 19:17:24 [INFO]: Epoch 075 - training loss: 0.2372, validation loss: 0.1365
2024-05-23 19:17:25 [INFO]: Epoch 076 - training loss: 0.2356, validation loss: 0.1374
2024-05-23 19:17:25 [INFO]: Epoch 077 - training loss: 0.2363, validation loss: 0.1362
2024-05-23 19:17:26 [INFO]: Epoch 078 - training loss: 0.2353, validation loss: 0.1370
2024-05-23 19:17:27 [INFO]: Epoch 079 - training loss: 0.2332, validation loss: 0.1355
2024-05-23 19:17:27 [INFO]: Epoch 080 - training loss: 0.2313, validation loss: 0.1353
2024-05-23 19:17:28 [INFO]: Epoch 081 - training loss: 0.2311, validation loss: 0.1346
2024-05-23 19:17:28 [INFO]: Epoch 082 - training loss: 0.2316, validation loss: 0.1347
2024-05-23 19:17:29 [INFO]: Epoch 083 - training loss: 0.2307, validation loss: 0.1341
2024-05-23 19:17:29 [INFO]: Epoch 084 - training loss: 0.2295, validation loss: 0.1345
2024-05-23 19:17:30 [INFO]: Epoch 085 - training loss: 0.2284, validation loss: 0.1340
2024-05-23 19:17:31 [INFO]: Epoch 086 - training loss: 0.2283, validation loss: 0.1348
2024-05-23 19:17:31 [INFO]: Epoch 087 - training loss: 0.2276, validation loss: 0.1342
2024-05-23 19:17:32 [INFO]: Epoch 088 - training loss: 0.2269, validation loss: 0.1333
2024-05-23 19:17:32 [INFO]: Epoch 089 - training loss: 0.2288, validation loss: 0.1339
2024-05-23 19:17:33 [INFO]: Epoch 090 - training loss: 0.2253, validation loss: 0.1315
2024-05-23 19:17:34 [INFO]: Epoch 091 - training loss: 0.2246, validation loss: 0.1333
2024-05-23 19:17:34 [INFO]: Epoch 092 - training loss: 0.2245, validation loss: 0.1320
2024-05-23 19:17:35 [INFO]: Epoch 093 - training loss: 0.2227, validation loss: 0.1326
2024-05-23 19:17:35 [INFO]: Epoch 094 - training loss: 0.2223, validation loss: 0.1309
2024-05-23 19:17:36 [INFO]: Epoch 095 - training loss: 0.2221, validation loss: 0.1316
2024-05-23 19:17:36 [INFO]: Epoch 096 - training loss: 0.2200, validation loss: 0.1306
2024-05-23 19:17:37 [INFO]: Epoch 097 - training loss: 0.2191, validation loss: 0.1305
2024-05-23 19:17:38 [INFO]: Epoch 098 - training loss: 0.2194, validation loss: 0.1316
2024-05-23 19:17:38 [INFO]: Epoch 099 - training loss: 0.2195, validation loss: 0.1305
2024-05-23 19:17:39 [INFO]: Epoch 100 - training loss: 0.2188, validation loss: 0.1300
2024-05-23 19:17:39 [INFO]: Epoch 101 - training loss: 0.2168, validation loss: 0.1292
2024-05-23 19:17:40 [INFO]: Epoch 102 - training loss: 0.2158, validation loss: 0.1298
2024-05-23 19:17:40 [INFO]: Epoch 103 - training loss: 0.2152, validation loss: 0.1288
2024-05-23 19:17:41 [INFO]: Epoch 104 - training loss: 0.2155, validation loss: 0.1300
2024-05-23 19:17:42 [INFO]: Epoch 105 - training loss: 0.2147, validation loss: 0.1288
2024-05-23 19:17:42 [INFO]: Epoch 106 - training loss: 0.2135, validation loss: 0.1287
2024-05-23 19:17:43 [INFO]: Epoch 107 - training loss: 0.2127, validation loss: 0.1285
2024-05-23 19:17:44 [INFO]: Epoch 108 - training loss: 0.2119, validation loss: 0.1288
2024-05-23 19:17:44 [INFO]: Epoch 109 - training loss: 0.2119, validation loss: 0.1287
2024-05-23 19:17:45 [INFO]: Epoch 110 - training loss: 0.2120, validation loss: 0.1286
2024-05-23 19:17:45 [INFO]: Epoch 111 - training loss: 0.2112, validation loss: 0.1284
2024-05-23 19:17:46 [INFO]: Epoch 112 - training loss: 0.2110, validation loss: 0.1275
2024-05-23 19:17:47 [INFO]: Epoch 113 - training loss: 0.2096, validation loss: 0.1273
2024-05-23 19:17:47 [INFO]: Epoch 114 - training loss: 0.2090, validation loss: 0.1266
2024-05-23 19:17:48 [INFO]: Epoch 115 - training loss: 0.2090, validation loss: 0.1272
2024-05-23 19:17:48 [INFO]: Epoch 116 - training loss: 0.2083, validation loss: 0.1276
2024-05-23 19:17:49 [INFO]: Epoch 117 - training loss: 0.2086, validation loss: 0.1265
2024-05-23 19:17:49 [INFO]: Epoch 118 - training loss: 0.2078, validation loss: 0.1263
2024-05-23 19:17:50 [INFO]: Epoch 119 - training loss: 0.2065, validation loss: 0.1261
2024-05-23 19:17:51 [INFO]: Epoch 120 - training loss: 0.2054, validation loss: 0.1262
2024-05-23 19:17:51 [INFO]: Epoch 121 - training loss: 0.2052, validation loss: 0.1274
2024-05-23 19:17:52 [INFO]: Epoch 122 - training loss: 0.2059, validation loss: 0.1257
2024-05-23 19:17:52 [INFO]: Epoch 123 - training loss: 0.2061, validation loss: 0.1255
2024-05-23 19:17:53 [INFO]: Epoch 124 - training loss: 0.2040, validation loss: 0.1238
2024-05-23 19:17:54 [INFO]: Epoch 125 - training loss: 0.2038, validation loss: 0.1254
2024-05-23 19:17:54 [INFO]: Epoch 126 - training loss: 0.2032, validation loss: 0.1246
2024-05-23 19:17:55 [INFO]: Epoch 127 - training loss: 0.2028, validation loss: 0.1252
2024-05-23 19:17:55 [INFO]: Epoch 128 - training loss: 0.2027, validation loss: 0.1240
2024-05-23 19:17:56 [INFO]: Epoch 129 - training loss: 0.2015, validation loss: 0.1248
2024-05-23 19:17:56 [INFO]: Epoch 130 - training loss: 0.2032, validation loss: 0.1246
2024-05-23 19:17:57 [INFO]: Epoch 131 - training loss: 0.2052, validation loss: 0.1235
2024-05-23 19:17:58 [INFO]: Epoch 132 - training loss: 0.2024, validation loss: 0.1233
2024-05-23 19:17:58 [INFO]: Epoch 133 - training loss: 0.2007, validation loss: 0.1234
2024-05-23 19:17:59 [INFO]: Epoch 134 - training loss: 0.1998, validation loss: 0.1236
2024-05-23 19:17:59 [INFO]: Epoch 135 - training loss: 0.1993, validation loss: 0.1226
2024-05-23 19:18:00 [INFO]: Epoch 136 - training loss: 0.1982, validation loss: 0.1225
2024-05-23 19:18:00 [INFO]: Epoch 137 - training loss: 0.1981, validation loss: 0.1228
2024-05-23 19:18:01 [INFO]: Epoch 138 - training loss: 0.1975, validation loss: 0.1221
2024-05-23 19:18:02 [INFO]: Epoch 139 - training loss: 0.1975, validation loss: 0.1202
2024-05-23 19:18:02 [INFO]: Epoch 140 - training loss: 0.1975, validation loss: 0.1218
2024-05-23 19:18:03 [INFO]: Epoch 141 - training loss: 0.1971, validation loss: 0.1219
2024-05-23 19:18:03 [INFO]: Epoch 142 - training loss: 0.1969, validation loss: 0.1212
2024-05-23 19:18:04 [INFO]: Epoch 143 - training loss: 0.1955, validation loss: 0.1217
2024-05-23 19:18:05 [INFO]: Epoch 144 - training loss: 0.1940, validation loss: 0.1211
2024-05-23 19:18:05 [INFO]: Epoch 145 - training loss: 0.1946, validation loss: 0.1213
2024-05-23 19:18:06 [INFO]: Epoch 146 - training loss: 0.1945, validation loss: 0.1217
2024-05-23 19:18:06 [INFO]: Epoch 147 - training loss: 0.1931, validation loss: 0.1207
2024-05-23 19:18:07 [INFO]: Epoch 148 - training loss: 0.1938, validation loss: 0.1215
2024-05-23 19:18:07 [INFO]: Epoch 149 - training loss: 0.1922, validation loss: 0.1200
2024-05-23 19:18:08 [INFO]: Epoch 150 - training loss: 0.1921, validation loss: 0.1205
2024-05-23 19:18:09 [INFO]: Epoch 151 - training loss: 0.1912, validation loss: 0.1205
2024-05-23 19:18:09 [INFO]: Epoch 152 - training loss: 0.1907, validation loss: 0.1200
2024-05-23 19:18:10 [INFO]: Epoch 153 - training loss: 0.1905, validation loss: 0.1212
2024-05-23 19:18:10 [INFO]: Epoch 154 - training loss: 0.1918, validation loss: 0.1198
2024-05-23 19:18:11 [INFO]: Epoch 155 - training loss: 0.1908, validation loss: 0.1197
2024-05-23 19:18:11 [INFO]: Epoch 156 - training loss: 0.1886, validation loss: 0.1196
2024-05-23 19:18:12 [INFO]: Epoch 157 - training loss: 0.1902, validation loss: 0.1186
2024-05-23 19:18:13 [INFO]: Epoch 158 - training loss: 0.1897, validation loss: 0.1206
2024-05-23 19:18:13 [INFO]: Epoch 159 - training loss: 0.1886, validation loss: 0.1207
2024-05-23 19:18:14 [INFO]: Epoch 160 - training loss: 0.1881, validation loss: 0.1194
2024-05-23 19:18:14 [INFO]: Epoch 161 - training loss: 0.1874, validation loss: 0.1200
2024-05-23 19:18:15 [INFO]: Epoch 162 - training loss: 0.1871, validation loss: 0.1191
2024-05-23 19:18:16 [INFO]: Epoch 163 - training loss: 0.1875, validation loss: 0.1187
2024-05-23 19:18:16 [INFO]: Epoch 164 - training loss: 0.1873, validation loss: 0.1205
2024-05-23 19:18:17 [INFO]: Epoch 165 - training loss: 0.1875, validation loss: 0.1183
2024-05-23 19:18:17 [INFO]: Epoch 166 - training loss: 0.1871, validation loss: 0.1203
2024-05-23 19:18:18 [INFO]: Epoch 167 - training loss: 0.1876, validation loss: 0.1184
2024-05-23 19:18:18 [INFO]: Epoch 168 - training loss: 0.1853, validation loss: 0.1185
2024-05-23 19:18:19 [INFO]: Epoch 169 - training loss: 0.1850, validation loss: 0.1197
2024-05-23 19:18:20 [INFO]: Epoch 170 - training loss: 0.1851, validation loss: 0.1189
2024-05-23 19:18:20 [INFO]: Epoch 171 - training loss: 0.1847, validation loss: 0.1183
2024-05-23 19:18:21 [INFO]: Epoch 172 - training loss: 0.1832, validation loss: 0.1194
2024-05-23 19:18:21 [INFO]: Epoch 173 - training loss: 0.1838, validation loss: 0.1188
2024-05-23 19:18:22 [INFO]: Epoch 174 - training loss: 0.1831, validation loss: 0.1192
2024-05-23 19:18:22 [INFO]: Epoch 175 - training loss: 0.1824, validation loss: 0.1190
2024-05-23 19:18:23 [INFO]: Epoch 176 - training loss: 0.1812, validation loss: 0.1179
2024-05-23 19:18:24 [INFO]: Epoch 177 - training loss: 0.1815, validation loss: 0.1185
2024-05-23 19:18:24 [INFO]: Epoch 178 - training loss: 0.1823, validation loss: 0.1184
2024-05-23 19:18:25 [INFO]: Epoch 179 - training loss: 0.1812, validation loss: 0.1179
2024-05-23 19:18:25 [INFO]: Epoch 180 - training loss: 0.1799, validation loss: 0.1187
2024-05-23 19:18:26 [INFO]: Epoch 181 - training loss: 0.1793, validation loss: 0.1181
2024-05-23 19:18:26 [INFO]: Epoch 182 - training loss: 0.1805, validation loss: 0.1188
2024-05-23 19:18:27 [INFO]: Epoch 183 - training loss: 0.1804, validation loss: 0.1183
2024-05-23 19:18:28 [INFO]: Epoch 184 - training loss: 0.1813, validation loss: 0.1194
2024-05-23 19:18:28 [INFO]: Epoch 185 - training loss: 0.1844, validation loss: 0.1177
2024-05-23 19:18:29 [INFO]: Epoch 186 - training loss: 0.1818, validation loss: 0.1181
2024-05-23 19:18:29 [INFO]: Epoch 187 - training loss: 0.1804, validation loss: 0.1176
2024-05-23 19:18:30 [INFO]: Epoch 188 - training loss: 0.1784, validation loss: 0.1173
2024-05-23 19:18:31 [INFO]: Epoch 189 - training loss: 0.1786, validation loss: 0.1172
2024-05-23 19:18:31 [INFO]: Epoch 190 - training loss: 0.1769, validation loss: 0.1176
2024-05-23 19:18:32 [INFO]: Epoch 191 - training loss: 0.1771, validation loss: 0.1170
2024-05-23 19:18:33 [INFO]: Epoch 192 - training loss: 0.1786, validation loss: 0.1182
2024-05-23 19:18:33 [INFO]: Epoch 193 - training loss: 0.1781, validation loss: 0.1173
2024-05-23 19:18:34 [INFO]: Epoch 194 - training loss: 0.1766, validation loss: 0.1164
2024-05-23 19:18:34 [INFO]: Epoch 195 - training loss: 0.1755, validation loss: 0.1173
2024-05-23 19:18:35 [INFO]: Epoch 196 - training loss: 0.1757, validation loss: 0.1164
2024-05-23 19:18:35 [INFO]: Epoch 197 - training loss: 0.1759, validation loss: 0.1167
2024-05-23 19:18:36 [INFO]: Epoch 198 - training loss: 0.1753, validation loss: 0.1175
2024-05-23 19:18:37 [INFO]: Epoch 199 - training loss: 0.1778, validation loss: 0.1171
2024-05-23 19:18:37 [INFO]: Epoch 200 - training loss: 0.1765, validation loss: 0.1180
2024-05-23 19:18:38 [INFO]: Epoch 201 - training loss: 0.1749, validation loss: 0.1172
2024-05-23 19:18:38 [INFO]: Epoch 202 - training loss: 0.1737, validation loss: 0.1163
2024-05-23 19:18:39 [INFO]: Epoch 203 - training loss: 0.1731, validation loss: 0.1162
2024-05-23 19:18:40 [INFO]: Epoch 204 - training loss: 0.1737, validation loss: 0.1168
2024-05-23 19:18:40 [INFO]: Epoch 205 - training loss: 0.1723, validation loss: 0.1170
2024-05-23 19:18:41 [INFO]: Epoch 206 - training loss: 0.1721, validation loss: 0.1160
2024-05-23 19:18:41 [INFO]: Epoch 207 - training loss: 0.1716, validation loss: 0.1177
2024-05-23 19:18:42 [INFO]: Epoch 208 - training loss: 0.1717, validation loss: 0.1157
2024-05-23 19:18:42 [INFO]: Epoch 209 - training loss: 0.1715, validation loss: 0.1167
2024-05-23 19:18:43 [INFO]: Epoch 210 - training loss: 0.1718, validation loss: 0.1173
2024-05-23 19:18:44 [INFO]: Epoch 211 - training loss: 0.1711, validation loss: 0.1168
2024-05-23 19:18:44 [INFO]: Epoch 212 - training loss: 0.1713, validation loss: 0.1166
2024-05-23 19:18:45 [INFO]: Epoch 213 - training loss: 0.1718, validation loss: 0.1154
2024-05-23 19:18:45 [INFO]: Epoch 214 - training loss: 0.1709, validation loss: 0.1168
2024-05-23 19:18:46 [INFO]: Epoch 215 - training loss: 0.1697, validation loss: 0.1165
2024-05-23 19:18:47 [INFO]: Epoch 216 - training loss: 0.1694, validation loss: 0.1158
2024-05-23 19:18:47 [INFO]: Epoch 217 - training loss: 0.1703, validation loss: 0.1187
2024-05-23 19:18:48 [INFO]: Epoch 218 - training loss: 0.1716, validation loss: 0.1162
2024-05-23 19:18:48 [INFO]: Epoch 219 - training loss: 0.1698, validation loss: 0.1156
2024-05-23 19:18:49 [INFO]: Epoch 220 - training loss: 0.1697, validation loss: 0.1154
2024-05-23 19:18:49 [INFO]: Epoch 221 - training loss: 0.1713, validation loss: 0.1181
2024-05-23 19:18:50 [INFO]: Epoch 222 - training loss: 0.1695, validation loss: 0.1182
2024-05-23 19:18:51 [INFO]: Epoch 223 - training loss: 0.1692, validation loss: 0.1168
2024-05-23 19:18:51 [INFO]: Epoch 224 - training loss: 0.1687, validation loss: 0.1173
2024-05-23 19:18:52 [INFO]: Epoch 225 - training loss: 0.1695, validation loss: 0.1167
2024-05-23 19:18:52 [INFO]: Epoch 226 - training loss: 0.1700, validation loss: 0.1171
2024-05-23 19:18:53 [INFO]: Epoch 227 - training loss: 0.1696, validation loss: 0.1181
2024-05-23 19:18:53 [INFO]: Epoch 228 - training loss: 0.1699, validation loss: 0.1149
2024-05-23 19:18:54 [INFO]: Epoch 229 - training loss: 0.1670, validation loss: 0.1158
2024-05-23 19:18:55 [INFO]: Epoch 230 - training loss: 0.1660, validation loss: 0.1150
2024-05-23 19:18:55 [INFO]: Epoch 231 - training loss: 0.1669, validation loss: 0.1171
2024-05-23 19:18:56 [INFO]: Epoch 232 - training loss: 0.1660, validation loss: 0.1158
2024-05-23 19:18:56 [INFO]: Epoch 233 - training loss: 0.1664, validation loss: 0.1154
2024-05-23 19:18:57 [INFO]: Epoch 234 - training loss: 0.1656, validation loss: 0.1167
2024-05-23 19:18:57 [INFO]: Epoch 235 - training loss: 0.1649, validation loss: 0.1156
2024-05-23 19:18:58 [INFO]: Epoch 236 - training loss: 0.1640, validation loss: 0.1164
2024-05-23 19:18:59 [INFO]: Epoch 237 - training loss: 0.1636, validation loss: 0.1147
2024-05-23 19:18:59 [INFO]: Epoch 238 - training loss: 0.1649, validation loss: 0.1147
2024-05-23 19:19:00 [INFO]: Epoch 239 - training loss: 0.1643, validation loss: 0.1144
2024-05-23 19:19:00 [INFO]: Epoch 240 - training loss: 0.1640, validation loss: 0.1160
2024-05-23 19:19:01 [INFO]: Epoch 241 - training loss: 0.1632, validation loss: 0.1152
2024-05-23 19:19:02 [INFO]: Epoch 242 - training loss: 0.1638, validation loss: 0.1149
2024-05-23 19:19:02 [INFO]: Epoch 243 - training loss: 0.1625, validation loss: 0.1155
2024-05-23 19:19:03 [INFO]: Epoch 244 - training loss: 0.1623, validation loss: 0.1152
2024-05-23 19:19:03 [INFO]: Epoch 245 - training loss: 0.1619, validation loss: 0.1170
2024-05-23 19:19:04 [INFO]: Epoch 246 - training loss: 0.1623, validation loss: 0.1154
2024-05-23 19:19:04 [INFO]: Epoch 247 - training loss: 0.1619, validation loss: 0.1151
2024-05-23 19:19:05 [INFO]: Epoch 248 - training loss: 0.1616, validation loss: 0.1149
2024-05-23 19:19:06 [INFO]: Epoch 249 - training loss: 0.1623, validation loss: 0.1161
2024-05-23 19:19:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:19:06 [INFO]: Finished training. The best model is from epoch#239.
2024-05-23 19:19:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240523_T191638/SAITS.pypots
2024-05-23 19:19:06 [INFO]: SAITS on Air-Quality: MAE=0.1529, MSE=0.1575
2024-05-23 19:19:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-23 19:19:06 [INFO]: Using the given device: cuda:0
2024-05-23 19:19:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240523_T191906
2024-05-23 19:19:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240523_T191906/tensorboard
2024-05-23 19:19:06 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 19:19:06 [INFO]: Epoch 001 - training loss: 0.8724, validation loss: 0.4594
2024-05-23 19:19:06 [INFO]: Epoch 002 - training loss: 0.5497, validation loss: 0.3369
2024-05-23 19:19:07 [INFO]: Epoch 003 - training loss: 0.4642, validation loss: 0.2851
2024-05-23 19:19:07 [INFO]: Epoch 004 - training loss: 0.4191, validation loss: 0.2609
2024-05-23 19:19:07 [INFO]: Epoch 005 - training loss: 0.3913, validation loss: 0.2484
2024-05-23 19:19:07 [INFO]: Epoch 006 - training loss: 0.3693, validation loss: 0.2365
2024-05-23 19:19:08 [INFO]: Epoch 007 - training loss: 0.3537, validation loss: 0.2286
2024-05-23 19:19:08 [INFO]: Epoch 008 - training loss: 0.3402, validation loss: 0.2218
2024-05-23 19:19:08 [INFO]: Epoch 009 - training loss: 0.3318, validation loss: 0.2172
2024-05-23 19:19:09 [INFO]: Epoch 010 - training loss: 0.3222, validation loss: 0.2110
2024-05-23 19:19:09 [INFO]: Epoch 011 - training loss: 0.3165, validation loss: 0.2089
2024-05-23 19:19:09 [INFO]: Epoch 012 - training loss: 0.3117, validation loss: 0.2030
2024-05-23 19:19:09 [INFO]: Epoch 013 - training loss: 0.3057, validation loss: 0.1997
2024-05-23 19:19:10 [INFO]: Epoch 014 - training loss: 0.3017, validation loss: 0.1990
2024-05-23 19:19:10 [INFO]: Epoch 015 - training loss: 0.2961, validation loss: 0.1929
2024-05-23 19:19:10 [INFO]: Epoch 016 - training loss: 0.2911, validation loss: 0.1914
2024-05-23 19:19:10 [INFO]: Epoch 017 - training loss: 0.2864, validation loss: 0.1898
2024-05-23 19:19:11 [INFO]: Epoch 018 - training loss: 0.2880, validation loss: 0.1841
2024-05-23 19:19:11 [INFO]: Epoch 019 - training loss: 0.2828, validation loss: 0.1848
2024-05-23 19:19:11 [INFO]: Epoch 020 - training loss: 0.2772, validation loss: 0.1817
2024-05-23 19:19:11 [INFO]: Epoch 021 - training loss: 0.2746, validation loss: 0.1798
2024-05-23 19:19:11 [INFO]: Epoch 022 - training loss: 0.2707, validation loss: 0.1782
2024-05-23 19:19:12 [INFO]: Epoch 023 - training loss: 0.2703, validation loss: 0.1767
2024-05-23 19:19:12 [INFO]: Epoch 024 - training loss: 0.2682, validation loss: 0.1766
2024-05-23 19:19:12 [INFO]: Epoch 025 - training loss: 0.2653, validation loss: 0.1734
2024-05-23 19:19:12 [INFO]: Epoch 026 - training loss: 0.2635, validation loss: 0.1733
2024-05-23 19:19:13 [INFO]: Epoch 027 - training loss: 0.2609, validation loss: 0.1724
2024-05-23 19:19:13 [INFO]: Epoch 028 - training loss: 0.2584, validation loss: 0.1733
2024-05-23 19:19:13 [INFO]: Epoch 029 - training loss: 0.2558, validation loss: 0.1693
2024-05-23 19:19:13 [INFO]: Epoch 030 - training loss: 0.2536, validation loss: 0.1695
2024-05-23 19:19:14 [INFO]: Epoch 031 - training loss: 0.2519, validation loss: 0.1681
2024-05-23 19:19:14 [INFO]: Epoch 032 - training loss: 0.2538, validation loss: 0.1683
2024-05-23 19:19:14 [INFO]: Epoch 033 - training loss: 0.2491, validation loss: 0.1675
2024-05-23 19:19:14 [INFO]: Epoch 034 - training loss: 0.2450, validation loss: 0.1665
2024-05-23 19:19:14 [INFO]: Epoch 035 - training loss: 0.2448, validation loss: 0.1672
2024-05-23 19:19:15 [INFO]: Epoch 036 - training loss: 0.2441, validation loss: 0.1660
2024-05-23 19:19:15 [INFO]: Epoch 037 - training loss: 0.2421, validation loss: 0.1645
2024-05-23 19:19:15 [INFO]: Epoch 038 - training loss: 0.2404, validation loss: 0.1634
2024-05-23 19:19:15 [INFO]: Epoch 039 - training loss: 0.2399, validation loss: 0.1626
2024-05-23 19:19:16 [INFO]: Epoch 040 - training loss: 0.2378, validation loss: 0.1627
2024-05-23 19:19:16 [INFO]: Epoch 041 - training loss: 0.2364, validation loss: 0.1627
2024-05-23 19:19:16 [INFO]: Epoch 042 - training loss: 0.2335, validation loss: 0.1615
2024-05-23 19:19:16 [INFO]: Epoch 043 - training loss: 0.2329, validation loss: 0.1632
2024-05-23 19:19:17 [INFO]: Epoch 044 - training loss: 0.2321, validation loss: 0.1616
2024-05-23 19:19:17 [INFO]: Epoch 045 - training loss: 0.2323, validation loss: 0.1625
2024-05-23 19:19:17 [INFO]: Epoch 046 - training loss: 0.2319, validation loss: 0.1615
2024-05-23 19:19:17 [INFO]: Epoch 047 - training loss: 0.2258, validation loss: 0.1599
2024-05-23 19:19:17 [INFO]: Epoch 048 - training loss: 0.2271, validation loss: 0.1585
2024-05-23 19:19:18 [INFO]: Epoch 049 - training loss: 0.2242, validation loss: 0.1581
2024-05-23 19:19:18 [INFO]: Epoch 050 - training loss: 0.2228, validation loss: 0.1598
2024-05-23 19:19:18 [INFO]: Epoch 051 - training loss: 0.2231, validation loss: 0.1586
2024-05-23 19:19:18 [INFO]: Epoch 052 - training loss: 0.2212, validation loss: 0.1585
2024-05-23 19:19:19 [INFO]: Epoch 053 - training loss: 0.2205, validation loss: 0.1588
2024-05-23 19:19:19 [INFO]: Epoch 054 - training loss: 0.2198, validation loss: 0.1564
2024-05-23 19:19:19 [INFO]: Epoch 055 - training loss: 0.2173, validation loss: 0.1569
2024-05-23 19:19:19 [INFO]: Epoch 056 - training loss: 0.2154, validation loss: 0.1559
2024-05-23 19:19:20 [INFO]: Epoch 057 - training loss: 0.2170, validation loss: 0.1559
2024-05-23 19:19:20 [INFO]: Epoch 058 - training loss: 0.2175, validation loss: 0.1548
2024-05-23 19:19:20 [INFO]: Epoch 059 - training loss: 0.2137, validation loss: 0.1559
2024-05-23 19:19:20 [INFO]: Epoch 060 - training loss: 0.2129, validation loss: 0.1553
2024-05-23 19:19:20 [INFO]: Epoch 061 - training loss: 0.2113, validation loss: 0.1539
2024-05-23 19:19:21 [INFO]: Epoch 062 - training loss: 0.2115, validation loss: 0.1541
2024-05-23 19:19:21 [INFO]: Epoch 063 - training loss: 0.2159, validation loss: 0.1542
2024-05-23 19:19:21 [INFO]: Epoch 064 - training loss: 0.2109, validation loss: 0.1531
2024-05-23 19:19:21 [INFO]: Epoch 065 - training loss: 0.2074, validation loss: 0.1531
2024-05-23 19:19:22 [INFO]: Epoch 066 - training loss: 0.2060, validation loss: 0.1506
2024-05-23 19:19:22 [INFO]: Epoch 067 - training loss: 0.2082, validation loss: 0.1512
2024-05-23 19:19:22 [INFO]: Epoch 068 - training loss: 0.2075, validation loss: 0.1508
2024-05-23 19:19:22 [INFO]: Epoch 069 - training loss: 0.2033, validation loss: 0.1517
2024-05-23 19:19:23 [INFO]: Epoch 070 - training loss: 0.2018, validation loss: 0.1512
2024-05-23 19:19:23 [INFO]: Epoch 071 - training loss: 0.2003, validation loss: 0.1500
2024-05-23 19:19:23 [INFO]: Epoch 072 - training loss: 0.2006, validation loss: 0.1499
2024-05-23 19:19:24 [INFO]: Epoch 073 - training loss: 0.1993, validation loss: 0.1495
2024-05-23 19:19:24 [INFO]: Epoch 074 - training loss: 0.1983, validation loss: 0.1493
2024-05-23 19:19:24 [INFO]: Epoch 075 - training loss: 0.1978, validation loss: 0.1489
2024-05-23 19:19:24 [INFO]: Epoch 076 - training loss: 0.1979, validation loss: 0.1495
2024-05-23 19:19:24 [INFO]: Epoch 077 - training loss: 0.1949, validation loss: 0.1479
2024-05-23 19:19:25 [INFO]: Epoch 078 - training loss: 0.1943, validation loss: 0.1489
2024-05-23 19:19:25 [INFO]: Epoch 079 - training loss: 0.1948, validation loss: 0.1485
2024-05-23 19:19:25 [INFO]: Epoch 080 - training loss: 0.1933, validation loss: 0.1468
2024-05-23 19:19:25 [INFO]: Epoch 081 - training loss: 0.1938, validation loss: 0.1465
2024-05-23 19:19:26 [INFO]: Epoch 082 - training loss: 0.1944, validation loss: 0.1492
2024-05-23 19:19:26 [INFO]: Epoch 083 - training loss: 0.1935, validation loss: 0.1487
2024-05-23 19:19:26 [INFO]: Epoch 084 - training loss: 0.1912, validation loss: 0.1475
2024-05-23 19:19:26 [INFO]: Epoch 085 - training loss: 0.1901, validation loss: 0.1465
2024-05-23 19:19:27 [INFO]: Epoch 086 - training loss: 0.1899, validation loss: 0.1475
2024-05-23 19:19:27 [INFO]: Epoch 087 - training loss: 0.1887, validation loss: 0.1485
2024-05-23 19:19:27 [INFO]: Epoch 088 - training loss: 0.1931, validation loss: 0.1444
2024-05-23 19:19:27 [INFO]: Epoch 089 - training loss: 0.1879, validation loss: 0.1476
2024-05-23 19:19:27 [INFO]: Epoch 090 - training loss: 0.1869, validation loss: 0.1467
2024-05-23 19:19:28 [INFO]: Epoch 091 - training loss: 0.1865, validation loss: 0.1442
2024-05-23 19:19:28 [INFO]: Epoch 092 - training loss: 0.1873, validation loss: 0.1460
2024-05-23 19:19:28 [INFO]: Epoch 093 - training loss: 0.1852, validation loss: 0.1451
2024-05-23 19:19:28 [INFO]: Epoch 094 - training loss: 0.1826, validation loss: 0.1460
2024-05-23 19:19:29 [INFO]: Epoch 095 - training loss: 0.1864, validation loss: 0.1460
2024-05-23 19:19:29 [INFO]: Epoch 096 - training loss: 0.1824, validation loss: 0.1438
2024-05-23 19:19:29 [INFO]: Epoch 097 - training loss: 0.1801, validation loss: 0.1449
2024-05-23 19:19:29 [INFO]: Epoch 098 - training loss: 0.1808, validation loss: 0.1434
2024-05-23 19:19:30 [INFO]: Epoch 099 - training loss: 0.1784, validation loss: 0.1446
2024-05-23 19:19:30 [INFO]: Epoch 100 - training loss: 0.1785, validation loss: 0.1445
2024-05-23 19:19:30 [INFO]: Epoch 101 - training loss: 0.1783, validation loss: 0.1441
2024-05-23 19:19:30 [INFO]: Epoch 102 - training loss: 0.1800, validation loss: 0.1439
2024-05-23 19:19:30 [INFO]: Epoch 103 - training loss: 0.1806, validation loss: 0.1453
2024-05-23 19:19:31 [INFO]: Epoch 104 - training loss: 0.1768, validation loss: 0.1438
2024-05-23 19:19:31 [INFO]: Epoch 105 - training loss: 0.1755, validation loss: 0.1446
2024-05-23 19:19:31 [INFO]: Epoch 106 - training loss: 0.1750, validation loss: 0.1448
2024-05-23 19:19:31 [INFO]: Epoch 107 - training loss: 0.1739, validation loss: 0.1417
2024-05-23 19:19:32 [INFO]: Epoch 108 - training loss: 0.1743, validation loss: 0.1429
2024-05-23 19:19:32 [INFO]: Epoch 109 - training loss: 0.1737, validation loss: 0.1428
2024-05-23 19:19:32 [INFO]: Epoch 110 - training loss: 0.1723, validation loss: 0.1421
2024-05-23 19:19:32 [INFO]: Epoch 111 - training loss: 0.1712, validation loss: 0.1428
2024-05-23 19:19:33 [INFO]: Epoch 112 - training loss: 0.1692, validation loss: 0.1411
2024-05-23 19:19:33 [INFO]: Epoch 113 - training loss: 0.1688, validation loss: 0.1427
2024-05-23 19:19:33 [INFO]: Epoch 114 - training loss: 0.1725, validation loss: 0.1416
2024-05-23 19:19:33 [INFO]: Epoch 115 - training loss: 0.1710, validation loss: 0.1412
2024-05-23 19:19:34 [INFO]: Epoch 116 - training loss: 0.1675, validation loss: 0.1402
2024-05-23 19:19:34 [INFO]: Epoch 117 - training loss: 0.1676, validation loss: 0.1410
2024-05-23 19:19:34 [INFO]: Epoch 118 - training loss: 0.1690, validation loss: 0.1407
2024-05-23 19:19:34 [INFO]: Epoch 119 - training loss: 0.1681, validation loss: 0.1397
2024-05-23 19:19:35 [INFO]: Epoch 120 - training loss: 0.1697, validation loss: 0.1418
2024-05-23 19:19:35 [INFO]: Epoch 121 - training loss: 0.1665, validation loss: 0.1413
2024-05-23 19:19:35 [INFO]: Epoch 122 - training loss: 0.1666, validation loss: 0.1402
2024-05-23 19:19:35 [INFO]: Epoch 123 - training loss: 0.1701, validation loss: 0.1412
2024-05-23 19:19:36 [INFO]: Epoch 124 - training loss: 0.1698, validation loss: 0.1430
2024-05-23 19:19:36 [INFO]: Epoch 125 - training loss: 0.1665, validation loss: 0.1400
2024-05-23 19:19:36 [INFO]: Epoch 126 - training loss: 0.1649, validation loss: 0.1400
2024-05-23 19:19:36 [INFO]: Epoch 127 - training loss: 0.1646, validation loss: 0.1403
2024-05-23 19:19:37 [INFO]: Epoch 128 - training loss: 0.1624, validation loss: 0.1401
2024-05-23 19:19:37 [INFO]: Epoch 129 - training loss: 0.1612, validation loss: 0.1396
2024-05-23 19:19:37 [INFO]: Epoch 130 - training loss: 0.1597, validation loss: 0.1398
2024-05-23 19:19:37 [INFO]: Epoch 131 - training loss: 0.1601, validation loss: 0.1408
2024-05-23 19:19:37 [INFO]: Epoch 132 - training loss: 0.1618, validation loss: 0.1411
2024-05-23 19:19:38 [INFO]: Epoch 133 - training loss: 0.1624, validation loss: 0.1405
2024-05-23 19:19:38 [INFO]: Epoch 134 - training loss: 0.1647, validation loss: 0.1391
2024-05-23 19:19:38 [INFO]: Epoch 135 - training loss: 0.1601, validation loss: 0.1401
2024-05-23 19:19:38 [INFO]: Epoch 136 - training loss: 0.1580, validation loss: 0.1380
2024-05-23 19:19:39 [INFO]: Epoch 137 - training loss: 0.1574, validation loss: 0.1390
2024-05-23 19:19:39 [INFO]: Epoch 138 - training loss: 0.1591, validation loss: 0.1390
2024-05-23 19:19:39 [INFO]: Epoch 139 - training loss: 0.1584, validation loss: 0.1389
2024-05-23 19:19:39 [INFO]: Epoch 140 - training loss: 0.1549, validation loss: 0.1390
2024-05-23 19:19:40 [INFO]: Epoch 141 - training loss: 0.1542, validation loss: 0.1407
2024-05-23 19:19:40 [INFO]: Epoch 142 - training loss: 0.1538, validation loss: 0.1397
2024-05-23 19:19:40 [INFO]: Epoch 143 - training loss: 0.1542, validation loss: 0.1386
2024-05-23 19:19:40 [INFO]: Epoch 144 - training loss: 0.1549, validation loss: 0.1379
2024-05-23 19:19:41 [INFO]: Epoch 145 - training loss: 0.1534, validation loss: 0.1392
2024-05-23 19:19:41 [INFO]: Epoch 146 - training loss: 0.1554, validation loss: 0.1390
2024-05-23 19:19:41 [INFO]: Epoch 147 - training loss: 0.1555, validation loss: 0.1375
2024-05-23 19:19:41 [INFO]: Epoch 148 - training loss: 0.1540, validation loss: 0.1394
2024-05-23 19:19:41 [INFO]: Epoch 149 - training loss: 0.1538, validation loss: 0.1394
2024-05-23 19:19:42 [INFO]: Epoch 150 - training loss: 0.1519, validation loss: 0.1377
2024-05-23 19:19:42 [INFO]: Epoch 151 - training loss: 0.1518, validation loss: 0.1371
2024-05-23 19:19:42 [INFO]: Epoch 152 - training loss: 0.1514, validation loss: 0.1371
2024-05-23 19:19:42 [INFO]: Epoch 153 - training loss: 0.1489, validation loss: 0.1386
2024-05-23 19:19:43 [INFO]: Epoch 154 - training loss: 0.1486, validation loss: 0.1374
2024-05-23 19:19:43 [INFO]: Epoch 155 - training loss: 0.1501, validation loss: 0.1379
2024-05-23 19:19:43 [INFO]: Epoch 156 - training loss: 0.1500, validation loss: 0.1380
2024-05-23 19:19:43 [INFO]: Epoch 157 - training loss: 0.1477, validation loss: 0.1387
2024-05-23 19:19:46 [INFO]: Epoch 158 - training loss: 0.1497, validation loss: 0.1378
2024-05-23 19:19:46 [INFO]: Epoch 159 - training loss: 0.1490, validation loss: 0.1368
2024-05-23 19:19:46 [INFO]: Epoch 160 - training loss: 0.1498, validation loss: 0.1385
2024-05-23 19:19:47 [INFO]: Epoch 161 - training loss: 0.1511, validation loss: 0.1388
2024-05-23 19:19:47 [INFO]: Epoch 162 - training loss: 0.1473, validation loss: 0.1391
2024-05-23 19:19:47 [INFO]: Epoch 163 - training loss: 0.1462, validation loss: 0.1373
2024-05-23 19:19:47 [INFO]: Epoch 164 - training loss: 0.1451, validation loss: 0.1373
2024-05-23 19:19:48 [INFO]: Epoch 165 - training loss: 0.1453, validation loss: 0.1383
2024-05-23 19:19:48 [INFO]: Epoch 166 - training loss: 0.1467, validation loss: 0.1372
2024-05-23 19:19:48 [INFO]: Epoch 167 - training loss: 0.1466, validation loss: 0.1381
2024-05-23 19:19:48 [INFO]: Epoch 168 - training loss: 0.1460, validation loss: 0.1383
2024-05-23 19:19:49 [INFO]: Epoch 169 - training loss: 0.1468, validation loss: 0.1372
2024-05-23 19:19:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:19:49 [INFO]: Finished training. The best model is from epoch#159.
2024-05-23 19:19:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240523_T191906/Transformer.pypots
2024-05-23 19:19:49 [INFO]: Transformer on Air-Quality: MAE=0.1710, MSE=0.1769
2024-05-23 19:19:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-23 19:19:49 [INFO]: Using the given device: cuda:0
2024-05-23 19:19:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240523_T191949
2024-05-23 19:19:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240523_T191949/tensorboard
2024-05-23 19:19:49 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 19:19:49 [INFO]: Epoch 001 - training loss: 0.2812, validation loss: 0.2754
2024-05-23 19:19:50 [INFO]: Epoch 002 - training loss: 0.2165, validation loss: 0.2477
2024-05-23 19:19:50 [INFO]: Epoch 003 - training loss: 0.1825, validation loss: 0.2256
2024-05-23 19:19:51 [INFO]: Epoch 004 - training loss: 0.1536, validation loss: 0.2155
2024-05-23 19:19:51 [INFO]: Epoch 005 - training loss: 0.1406, validation loss: 0.2102
2024-05-23 19:19:52 [INFO]: Epoch 006 - training loss: 0.1285, validation loss: 0.1993
2024-05-23 19:19:52 [INFO]: Epoch 007 - training loss: 0.1188, validation loss: 0.1968
2024-05-23 19:19:52 [INFO]: Epoch 008 - training loss: 0.1158, validation loss: 0.1961
2024-05-23 19:19:53 [INFO]: Epoch 009 - training loss: 0.1114, validation loss: 0.1930
2024-05-23 19:19:53 [INFO]: Epoch 010 - training loss: 0.1065, validation loss: 0.1923
2024-05-23 19:19:54 [INFO]: Epoch 011 - training loss: 0.1040, validation loss: 0.1934
2024-05-23 19:19:54 [INFO]: Epoch 012 - training loss: 0.0977, validation loss: 0.1922
2024-05-23 19:19:55 [INFO]: Epoch 013 - training loss: 0.0942, validation loss: 0.1942
2024-05-23 19:19:55 [INFO]: Epoch 014 - training loss: 0.0929, validation loss: 0.2004
2024-05-23 19:19:56 [INFO]: Epoch 015 - training loss: 0.0862, validation loss: 0.1997
2024-05-23 19:19:56 [INFO]: Epoch 016 - training loss: 0.0824, validation loss: 0.1870
2024-05-23 19:19:56 [INFO]: Epoch 017 - training loss: 0.0797, validation loss: 0.1932
2024-05-23 19:19:57 [INFO]: Epoch 018 - training loss: 0.0756, validation loss: 0.1909
2024-05-23 19:19:57 [INFO]: Epoch 019 - training loss: 0.0748, validation loss: 0.1912
2024-05-23 19:19:58 [INFO]: Epoch 020 - training loss: 0.0712, validation loss: 0.1862
2024-05-23 19:19:58 [INFO]: Epoch 021 - training loss: 0.0698, validation loss: 0.1849
2024-05-23 19:19:59 [INFO]: Epoch 022 - training loss: 0.0690, validation loss: 0.1874
2024-05-23 19:19:59 [INFO]: Epoch 023 - training loss: 0.0709, validation loss: 0.1837
2024-05-23 19:19:59 [INFO]: Epoch 024 - training loss: 0.0723, validation loss: 0.1905
2024-05-23 19:20:00 [INFO]: Epoch 025 - training loss: 0.0664, validation loss: 0.1759
2024-05-23 19:20:00 [INFO]: Epoch 026 - training loss: 0.0665, validation loss: 0.1788
2024-05-23 19:20:01 [INFO]: Epoch 027 - training loss: 0.0681, validation loss: 0.1827
2024-05-23 19:20:01 [INFO]: Epoch 028 - training loss: 0.0635, validation loss: 0.1773
2024-05-23 19:20:01 [INFO]: Epoch 029 - training loss: 0.0604, validation loss: 0.1789
2024-05-23 19:20:02 [INFO]: Epoch 030 - training loss: 0.0624, validation loss: 0.1721
2024-05-23 19:20:02 [INFO]: Epoch 031 - training loss: 0.0622, validation loss: 0.1811
2024-05-23 19:20:03 [INFO]: Epoch 032 - training loss: 0.0662, validation loss: 0.1833
2024-05-23 19:20:03 [INFO]: Epoch 033 - training loss: 0.0683, validation loss: 0.1691
2024-05-23 19:20:04 [INFO]: Epoch 034 - training loss: 0.0592, validation loss: 0.1706
2024-05-23 19:20:04 [INFO]: Epoch 035 - training loss: 0.0550, validation loss: 0.1732
2024-05-23 19:20:04 [INFO]: Epoch 036 - training loss: 0.0574, validation loss: 0.1677
2024-05-23 19:20:05 [INFO]: Epoch 037 - training loss: 0.0528, validation loss: 0.1710
2024-05-23 19:20:05 [INFO]: Epoch 038 - training loss: 0.0556, validation loss: 0.1660
2024-05-23 19:20:06 [INFO]: Epoch 039 - training loss: 0.0513, validation loss: 0.1720
2024-05-23 19:20:06 [INFO]: Epoch 040 - training loss: 0.0509, validation loss: 0.1678
2024-05-23 19:20:07 [INFO]: Epoch 041 - training loss: 0.0503, validation loss: 0.1656
2024-05-23 19:20:07 [INFO]: Epoch 042 - training loss: 0.0506, validation loss: 0.1632
2024-05-23 19:20:07 [INFO]: Epoch 043 - training loss: 0.0486, validation loss: 0.1650
2024-05-23 19:20:08 [INFO]: Epoch 044 - training loss: 0.0479, validation loss: 0.1645
2024-05-23 19:20:08 [INFO]: Epoch 045 - training loss: 0.0468, validation loss: 0.1610
2024-05-23 19:20:09 [INFO]: Epoch 046 - training loss: 0.0452, validation loss: 0.1609
2024-05-23 19:20:09 [INFO]: Epoch 047 - training loss: 0.0441, validation loss: 0.1651
2024-05-23 19:20:10 [INFO]: Epoch 048 - training loss: 0.0433, validation loss: 0.1659
2024-05-23 19:20:10 [INFO]: Epoch 049 - training loss: 0.0429, validation loss: 0.1610
2024-05-23 19:20:10 [INFO]: Epoch 050 - training loss: 0.0431, validation loss: 0.1626
2024-05-23 19:20:11 [INFO]: Epoch 051 - training loss: 0.0421, validation loss: 0.1609
2024-05-23 19:20:11 [INFO]: Epoch 052 - training loss: 0.0423, validation loss: 0.1655
2024-05-23 19:20:12 [INFO]: Epoch 053 - training loss: 0.0409, validation loss: 0.1630
2024-05-23 19:20:12 [INFO]: Epoch 054 - training loss: 0.0413, validation loss: 0.1588
2024-05-23 19:20:13 [INFO]: Epoch 055 - training loss: 0.0432, validation loss: 0.1655
2024-05-23 19:20:13 [INFO]: Epoch 056 - training loss: 0.0419, validation loss: 0.1604
2024-05-23 19:20:13 [INFO]: Epoch 057 - training loss: 0.0414, validation loss: 0.1616
2024-05-23 19:20:14 [INFO]: Epoch 058 - training loss: 0.0423, validation loss: 0.1620
2024-05-23 19:20:14 [INFO]: Epoch 059 - training loss: 0.0424, validation loss: 0.1645
2024-05-23 19:20:15 [INFO]: Epoch 060 - training loss: 0.0443, validation loss: 0.1651
2024-05-23 19:20:15 [INFO]: Epoch 061 - training loss: 0.0443, validation loss: 0.1641
2024-05-23 19:20:16 [INFO]: Epoch 062 - training loss: 0.0410, validation loss: 0.1582
2024-05-23 19:20:16 [INFO]: Epoch 063 - training loss: 0.0405, validation loss: 0.1608
2024-05-23 19:20:16 [INFO]: Epoch 064 - training loss: 0.0413, validation loss: 0.1681
2024-05-23 19:20:17 [INFO]: Epoch 065 - training loss: 0.0381, validation loss: 0.1612
2024-05-23 19:20:17 [INFO]: Epoch 066 - training loss: 0.0376, validation loss: 0.1591
2024-05-23 19:20:18 [INFO]: Epoch 067 - training loss: 0.0415, validation loss: 0.1611
2024-05-23 19:20:18 [INFO]: Epoch 068 - training loss: 0.0379, validation loss: 0.1628
2024-05-23 19:20:19 [INFO]: Epoch 069 - training loss: 0.0376, validation loss: 0.1634
2024-05-23 19:20:19 [INFO]: Epoch 070 - training loss: 0.0364, validation loss: 0.1567
2024-05-23 19:20:19 [INFO]: Epoch 071 - training loss: 0.0336, validation loss: 0.1614
2024-05-23 19:20:20 [INFO]: Epoch 072 - training loss: 0.0327, validation loss: 0.1580
2024-05-23 19:20:20 [INFO]: Epoch 073 - training loss: 0.0317, validation loss: 0.1571
2024-05-23 19:20:21 [INFO]: Epoch 074 - training loss: 0.0311, validation loss: 0.1580
2024-05-23 19:20:21 [INFO]: Epoch 075 - training loss: 0.0309, validation loss: 0.1568
2024-05-23 19:20:22 [INFO]: Epoch 076 - training loss: 0.0302, validation loss: 0.1556
2024-05-23 19:20:22 [INFO]: Epoch 077 - training loss: 0.0306, validation loss: 0.1592
2024-05-23 19:20:22 [INFO]: Epoch 078 - training loss: 0.0300, validation loss: 0.1568
2024-05-23 19:20:23 [INFO]: Epoch 079 - training loss: 0.0304, validation loss: 0.1592
2024-05-23 19:20:23 [INFO]: Epoch 080 - training loss: 0.0301, validation loss: 0.1540
2024-05-23 19:20:24 [INFO]: Epoch 081 - training loss: 0.0299, validation loss: 0.1564
2024-05-23 19:20:24 [INFO]: Epoch 082 - training loss: 0.0313, validation loss: 0.1579
2024-05-23 19:20:25 [INFO]: Epoch 083 - training loss: 0.0324, validation loss: 0.1571
2024-05-23 19:20:25 [INFO]: Epoch 084 - training loss: 0.0325, validation loss: 0.1640
2024-05-23 19:20:26 [INFO]: Epoch 085 - training loss: 0.0306, validation loss: 0.1562
2024-05-23 19:20:26 [INFO]: Epoch 086 - training loss: 0.0330, validation loss: 0.1580
2024-05-23 19:20:27 [INFO]: Epoch 087 - training loss: 0.0323, validation loss: 0.1563
2024-05-23 19:20:27 [INFO]: Epoch 088 - training loss: 0.0301, validation loss: 0.1557
2024-05-23 19:20:27 [INFO]: Epoch 089 - training loss: 0.0289, validation loss: 0.1569
2024-05-23 19:20:28 [INFO]: Epoch 090 - training loss: 0.0297, validation loss: 0.1562
2024-05-23 19:20:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:20:28 [INFO]: Finished training. The best model is from epoch#80.
2024-05-23 19:20:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240523_T191949/TimesNet.pypots
2024-05-23 19:20:28 [INFO]: TimesNet on Air-Quality: MAE=0.1608, MSE=0.2199
2024-05-23 19:20:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-23 19:20:28 [INFO]: Using the given device: cuda:0
2024-05-23 19:20:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028
2024-05-23 19:20:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/tensorboard
2024-05-23 19:20:28 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 19:20:44 [INFO]: Epoch 001 - training loss: 0.5112, validation loss: 0.3301
2024-05-23 19:20:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch1_loss0.33009024858474734.pypots
2024-05-23 19:21:01 [INFO]: Epoch 002 - training loss: 0.2960, validation loss: 0.2597
2024-05-23 19:21:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch2_loss0.25971063524484633.pypots
2024-05-23 19:21:17 [INFO]: Epoch 003 - training loss: 0.2471, validation loss: 0.2227
2024-05-23 19:21:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch3_loss0.22271050214767457.pypots
2024-05-23 19:21:33 [INFO]: Epoch 004 - training loss: 0.2238, validation loss: 0.2056
2024-05-23 19:21:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch4_loss0.20562589913606644.pypots
2024-05-23 19:21:50 [INFO]: Epoch 005 - training loss: 0.1952, validation loss: 0.1835
2024-05-23 19:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch5_loss0.1835149958729744.pypots
2024-05-23 19:22:06 [INFO]: Epoch 006 - training loss: 0.1888, validation loss: 0.1739
2024-05-23 19:22:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch6_loss0.1739347517490387.pypots
2024-05-23 19:22:22 [INFO]: Epoch 007 - training loss: 0.1674, validation loss: 0.1666
2024-05-23 19:22:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch7_loss0.16656057238578797.pypots
2024-05-23 19:22:39 [INFO]: Epoch 008 - training loss: 0.1705, validation loss: 0.1576
2024-05-23 19:22:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch8_loss0.15759815275669098.pypots
2024-05-23 19:22:55 [INFO]: Epoch 009 - training loss: 0.1633, validation loss: 0.1569
2024-05-23 19:22:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch9_loss0.15692776292562485.pypots
2024-05-23 19:23:11 [INFO]: Epoch 010 - training loss: 0.1616, validation loss: 0.1562
2024-05-23 19:23:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch10_loss0.1562372103333473.pypots
2024-05-23 19:23:28 [INFO]: Epoch 011 - training loss: 0.1540, validation loss: 0.1556
2024-05-23 19:23:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch11_loss0.15555118173360824.pypots
2024-05-23 19:23:44 [INFO]: Epoch 012 - training loss: 0.1656, validation loss: 0.1444
2024-05-23 19:23:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch12_loss0.14440686926245688.pypots
2024-05-23 19:24:01 [INFO]: Epoch 013 - training loss: 0.1486, validation loss: 0.1463
2024-05-23 19:24:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch13_loss0.14630856215953827.pypots
2024-05-23 19:24:17 [INFO]: Epoch 014 - training loss: 0.1544, validation loss: 0.1421
2024-05-23 19:24:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch14_loss0.14212497398257257.pypots
2024-05-23 19:24:33 [INFO]: Epoch 015 - training loss: 0.1569, validation loss: 0.1590
2024-05-23 19:24:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch15_loss0.15898868888616563.pypots
2024-05-23 19:24:50 [INFO]: Epoch 016 - training loss: 0.1643, validation loss: 0.1500
2024-05-23 19:24:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch16_loss0.14996575713157653.pypots
2024-05-23 19:25:06 [INFO]: Epoch 017 - training loss: 0.1539, validation loss: 0.1440
2024-05-23 19:25:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch17_loss0.14403524175286292.pypots
2024-05-23 19:25:23 [INFO]: Epoch 018 - training loss: 0.1372, validation loss: 0.1467
2024-05-23 19:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch18_loss0.14674222022294997.pypots
2024-05-23 19:25:39 [INFO]: Epoch 019 - training loss: 0.1522, validation loss: 0.1364
2024-05-23 19:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch19_loss0.1364450991153717.pypots
2024-05-23 19:25:55 [INFO]: Epoch 020 - training loss: 0.1422, validation loss: 0.1390
2024-05-23 19:25:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch20_loss0.13897414207458497.pypots
2024-05-23 19:26:12 [INFO]: Epoch 021 - training loss: 0.1307, validation loss: 0.1331
2024-05-23 19:26:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch21_loss0.13314374312758445.pypots
2024-05-23 19:26:28 [INFO]: Epoch 022 - training loss: 0.1392, validation loss: 0.1330
2024-05-23 19:26:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch22_loss0.13300149887800217.pypots
2024-05-23 19:26:44 [INFO]: Epoch 023 - training loss: 0.1418, validation loss: 0.1322
2024-05-23 19:26:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch23_loss0.13223177939653397.pypots
2024-05-23 19:27:01 [INFO]: Epoch 024 - training loss: 0.1408, validation loss: 0.1300
2024-05-23 19:27:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch24_loss0.13002303913235663.pypots
2024-05-23 19:27:17 [INFO]: Epoch 025 - training loss: 0.1334, validation loss: 0.1282
2024-05-23 19:27:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch25_loss0.12816239446401595.pypots
2024-05-23 19:27:33 [INFO]: Epoch 026 - training loss: 0.1256, validation loss: 0.1280
2024-05-23 19:27:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch26_loss0.12798650860786437.pypots
2024-05-23 19:27:50 [INFO]: Epoch 027 - training loss: 0.1413, validation loss: 0.1358
2024-05-23 19:27:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch27_loss0.1357721321284771.pypots
2024-05-23 19:28:06 [INFO]: Epoch 028 - training loss: 0.1322, validation loss: 0.1275
2024-05-23 19:28:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch28_loss0.12746840938925744.pypots
2024-05-23 19:28:22 [INFO]: Epoch 029 - training loss: 0.1280, validation loss: 0.1254
2024-05-23 19:28:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch29_loss0.12541645839810373.pypots
2024-05-23 19:28:39 [INFO]: Epoch 030 - training loss: 0.1178, validation loss: 0.1251
2024-05-23 19:28:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch30_loss0.1250590667128563.pypots
2024-05-23 19:28:55 [INFO]: Epoch 031 - training loss: 0.1261, validation loss: 0.1268
2024-05-23 19:28:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch31_loss0.1268354371190071.pypots
2024-05-23 19:29:11 [INFO]: Epoch 032 - training loss: 0.1112, validation loss: 0.1264
2024-05-23 19:29:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch32_loss0.12638913914561273.pypots
2024-05-23 19:29:28 [INFO]: Epoch 033 - training loss: 0.1211, validation loss: 0.1237
2024-05-23 19:29:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch33_loss0.12366744428873062.pypots
2024-05-23 19:29:44 [INFO]: Epoch 034 - training loss: 0.1193, validation loss: 0.1254
2024-05-23 19:29:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch34_loss0.1253884479403496.pypots
2024-05-23 19:30:00 [INFO]: Epoch 035 - training loss: 0.1270, validation loss: 0.1306
2024-05-23 19:30:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch35_loss0.1306004785001278.pypots
2024-05-23 19:30:17 [INFO]: Epoch 036 - training loss: 0.1268, validation loss: 0.1263
2024-05-23 19:30:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch36_loss0.12630242481827736.pypots
2024-05-23 19:30:33 [INFO]: Epoch 037 - training loss: 0.1179, validation loss: 0.1248
2024-05-23 19:30:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch37_loss0.12482435926795006.pypots
2024-05-23 19:30:49 [INFO]: Epoch 038 - training loss: 0.1328, validation loss: 0.1259
2024-05-23 19:30:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch38_loss0.1259182021021843.pypots
2024-05-23 19:31:06 [INFO]: Epoch 039 - training loss: 0.1248, validation loss: 0.1212
2024-05-23 19:31:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch39_loss0.12124157547950745.pypots
2024-05-23 19:31:22 [INFO]: Epoch 040 - training loss: 0.1056, validation loss: 0.1218
2024-05-23 19:31:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch40_loss0.12176154404878617.pypots
2024-05-23 19:31:38 [INFO]: Epoch 041 - training loss: 0.1294, validation loss: 0.1204
2024-05-23 19:31:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch41_loss0.12036575824022293.pypots
2024-05-23 19:31:55 [INFO]: Epoch 042 - training loss: 0.1223, validation loss: 0.1217
2024-05-23 19:31:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch42_loss0.12173169627785682.pypots
2024-05-23 19:32:11 [INFO]: Epoch 043 - training loss: 0.1200, validation loss: 0.1228
2024-05-23 19:32:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch43_loss0.12280350551009178.pypots
2024-05-23 19:32:27 [INFO]: Epoch 044 - training loss: 0.1217, validation loss: 0.1188
2024-05-23 19:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch44_loss0.11881797537207603.pypots
2024-05-23 19:32:44 [INFO]: Epoch 045 - training loss: 0.1263, validation loss: 0.1190
2024-05-23 19:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch45_loss0.11903307810425759.pypots
2024-05-23 19:33:00 [INFO]: Epoch 046 - training loss: 0.1117, validation loss: 0.1178
2024-05-23 19:33:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch46_loss0.1177549697458744.pypots
2024-05-23 19:33:16 [INFO]: Epoch 047 - training loss: 0.1126, validation loss: 0.1158
2024-05-23 19:33:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch47_loss0.1158493734896183.pypots
2024-05-23 19:33:33 [INFO]: Epoch 048 - training loss: 0.1120, validation loss: 0.1166
2024-05-23 19:33:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch48_loss0.1165513552725315.pypots
2024-05-23 19:33:49 [INFO]: Epoch 049 - training loss: 0.1214, validation loss: 0.1178
2024-05-23 19:33:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch49_loss0.11781623214483261.pypots
2024-05-23 19:34:05 [INFO]: Epoch 050 - training loss: 0.1003, validation loss: 0.1154
2024-05-23 19:34:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch50_loss0.11540853008627891.pypots
2024-05-23 19:34:22 [INFO]: Epoch 051 - training loss: 0.1289, validation loss: 0.1176
2024-05-23 19:34:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch51_loss0.11758917942643166.pypots
2024-05-23 19:34:38 [INFO]: Epoch 052 - training loss: 0.1275, validation loss: 0.1182
2024-05-23 19:34:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch52_loss0.11824072375893593.pypots
2024-05-23 19:34:55 [INFO]: Epoch 053 - training loss: 0.1231, validation loss: 0.1167
2024-05-23 19:34:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch53_loss0.11670104041695595.pypots
2024-05-23 19:35:11 [INFO]: Epoch 054 - training loss: 0.1196, validation loss: 0.1180
2024-05-23 19:35:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch54_loss0.11801526471972465.pypots
2024-05-23 19:35:27 [INFO]: Epoch 055 - training loss: 0.1132, validation loss: 0.1143
2024-05-23 19:35:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch55_loss0.1143337495625019.pypots
2024-05-23 19:35:44 [INFO]: Epoch 056 - training loss: 0.1132, validation loss: 0.1157
2024-05-23 19:35:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch56_loss0.1157045267522335.pypots
2024-05-23 19:36:00 [INFO]: Epoch 057 - training loss: 0.1167, validation loss: 0.1172
2024-05-23 19:36:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch57_loss0.11720496788620949.pypots
2024-05-23 19:36:16 [INFO]: Epoch 058 - training loss: 0.1075, validation loss: 0.1185
2024-05-23 19:36:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch58_loss0.11846880763769149.pypots
2024-05-23 19:36:33 [INFO]: Epoch 059 - training loss: 0.1145, validation loss: 0.1181
2024-05-23 19:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch59_loss0.11814038008451462.pypots
2024-05-23 19:36:49 [INFO]: Epoch 060 - training loss: 0.1127, validation loss: 0.1154
2024-05-23 19:36:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch60_loss0.11544885709881783.pypots
2024-05-23 19:37:06 [INFO]: Epoch 061 - training loss: 0.1102, validation loss: 0.1131
2024-05-23 19:37:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch61_loss0.11310689747333527.pypots
2024-05-23 19:37:22 [INFO]: Epoch 062 - training loss: 0.1125, validation loss: 0.1139
2024-05-23 19:37:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch62_loss0.11386837288737298.pypots
2024-05-23 19:37:38 [INFO]: Epoch 063 - training loss: 0.1166, validation loss: 0.1133
2024-05-23 19:37:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch63_loss0.11332640498876571.pypots
2024-05-23 19:37:55 [INFO]: Epoch 064 - training loss: 0.1135, validation loss: 0.1161
2024-05-23 19:37:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch64_loss0.11607853397727012.pypots
2024-05-23 19:38:11 [INFO]: Epoch 065 - training loss: 0.1185, validation loss: 0.1135
2024-05-23 19:38:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch65_loss0.11351890042424202.pypots
2024-05-23 19:38:27 [INFO]: Epoch 066 - training loss: 0.1094, validation loss: 0.1129
2024-05-23 19:38:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch66_loss0.11290547251701355.pypots
2024-05-23 19:38:44 [INFO]: Epoch 067 - training loss: 0.1040, validation loss: 0.1110
2024-05-23 19:38:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch67_loss0.11095907092094422.pypots
2024-05-23 19:39:00 [INFO]: Epoch 068 - training loss: 0.1090, validation loss: 0.1116
2024-05-23 19:39:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch68_loss0.1116213969886303.pypots
2024-05-23 19:39:16 [INFO]: Epoch 069 - training loss: 0.1094, validation loss: 0.1156
2024-05-23 19:39:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch69_loss0.11555789858102798.pypots
2024-05-23 19:39:33 [INFO]: Epoch 070 - training loss: 0.1265, validation loss: 0.1132
2024-05-23 19:39:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch70_loss0.11322286427021026.pypots
2024-05-23 19:39:49 [INFO]: Epoch 071 - training loss: 0.1113, validation loss: 0.1097
2024-05-23 19:39:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch71_loss0.10966829508543015.pypots
2024-05-23 19:40:06 [INFO]: Epoch 072 - training loss: 0.1025, validation loss: 0.1113
2024-05-23 19:40:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch72_loss0.11130439564585685.pypots
2024-05-23 19:40:22 [INFO]: Epoch 073 - training loss: 0.1177, validation loss: 0.1096
2024-05-23 19:40:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch73_loss0.10959192961454392.pypots
2024-05-23 19:40:39 [INFO]: Epoch 074 - training loss: 0.1058, validation loss: 0.1096
2024-05-23 19:40:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch74_loss0.10962837040424347.pypots
2024-05-23 19:40:55 [INFO]: Epoch 075 - training loss: 0.1018, validation loss: 0.1100
2024-05-23 19:40:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch75_loss0.11001311540603638.pypots
2024-05-23 19:41:11 [INFO]: Epoch 076 - training loss: 0.1197, validation loss: 0.1080
2024-05-23 19:41:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch76_loss0.10802797004580497.pypots
2024-05-23 19:41:28 [INFO]: Epoch 077 - training loss: 0.1233, validation loss: 0.1091
2024-05-23 19:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch77_loss0.10910442024469376.pypots
2024-05-23 19:41:44 [INFO]: Epoch 078 - training loss: 0.1050, validation loss: 0.1119
2024-05-23 19:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch78_loss0.11192456409335136.pypots
2024-05-23 19:42:01 [INFO]: Epoch 079 - training loss: 0.1069, validation loss: 0.1104
2024-05-23 19:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch79_loss0.11035857275128365.pypots
2024-05-23 19:42:17 [INFO]: Epoch 080 - training loss: 0.1139, validation loss: 0.1121
2024-05-23 19:42:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch80_loss0.11207624301314353.pypots
2024-05-23 19:42:33 [INFO]: Epoch 081 - training loss: 0.1121, validation loss: 0.1130
2024-05-23 19:42:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch81_loss0.11297283172607422.pypots
2024-05-23 19:42:50 [INFO]: Epoch 082 - training loss: 0.1142, validation loss: 0.1095
2024-05-23 19:42:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch82_loss0.10952867344021797.pypots
2024-05-23 19:43:06 [INFO]: Epoch 083 - training loss: 0.1123, validation loss: 0.1071
2024-05-23 19:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch83_loss0.10714142993092537.pypots
2024-05-23 19:43:22 [INFO]: Epoch 084 - training loss: 0.1030, validation loss: 0.1055
2024-05-23 19:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch84_loss0.1055316261947155.pypots
2024-05-23 19:43:39 [INFO]: Epoch 085 - training loss: 0.1118, validation loss: 0.1047
2024-05-23 19:43:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch85_loss0.10467537343502045.pypots
2024-05-23 19:43:55 [INFO]: Epoch 086 - training loss: 0.1031, validation loss: 0.1083
2024-05-23 19:43:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch86_loss0.10833437591791154.pypots
2024-05-23 19:44:12 [INFO]: Epoch 087 - training loss: 0.1082, validation loss: 0.1053
2024-05-23 19:44:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch87_loss0.10526087433099747.pypots
2024-05-23 19:44:28 [INFO]: Epoch 088 - training loss: 0.0963, validation loss: 0.1053
2024-05-23 19:44:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch88_loss0.10526756569743156.pypots
2024-05-23 19:44:44 [INFO]: Epoch 089 - training loss: 0.1150, validation loss: 0.1038
2024-05-23 19:44:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch89_loss0.1038330152630806.pypots
2024-05-23 19:45:01 [INFO]: Epoch 090 - training loss: 0.1030, validation loss: 0.1092
2024-05-23 19:45:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch90_loss0.10916334390640259.pypots
2024-05-23 19:45:17 [INFO]: Epoch 091 - training loss: 0.1010, validation loss: 0.1047
2024-05-23 19:45:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch91_loss0.10467319488525391.pypots
2024-05-23 19:45:33 [INFO]: Epoch 092 - training loss: 0.1085, validation loss: 0.1041
2024-05-23 19:45:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch92_loss0.10411589592695236.pypots
2024-05-23 19:45:50 [INFO]: Epoch 093 - training loss: 0.1089, validation loss: 0.1080
2024-05-23 19:45:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch93_loss0.10803435817360878.pypots
2024-05-23 19:46:06 [INFO]: Epoch 094 - training loss: 0.1095, validation loss: 0.1052
2024-05-23 19:46:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch94_loss0.10517570972442628.pypots
2024-05-23 19:46:22 [INFO]: Epoch 095 - training loss: 0.1032, validation loss: 0.1064
2024-05-23 19:46:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch95_loss0.10639241486787795.pypots
2024-05-23 19:46:39 [INFO]: Epoch 096 - training loss: 0.1051, validation loss: 0.1052
2024-05-23 19:46:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch96_loss0.10517192780971527.pypots
2024-05-23 19:46:55 [INFO]: Epoch 097 - training loss: 0.1064, validation loss: 0.1040
2024-05-23 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch97_loss0.10396711453795433.pypots
2024-05-23 19:47:11 [INFO]: Epoch 098 - training loss: 0.1077, validation loss: 0.1058
2024-05-23 19:47:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch98_loss0.10584939569234848.pypots
2024-05-23 19:47:28 [INFO]: Epoch 099 - training loss: 0.1015, validation loss: 0.1087
2024-05-23 19:47:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI_epoch99_loss0.1086615800857544.pypots
2024-05-23 19:47:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:47:28 [INFO]: Finished training. The best model is from epoch#89.
2024-05-23 19:47:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240523_T192028/CSDI.pypots
2024-05-23 19:49:46 [INFO]: CSDI on Air-Quality: MAE=0.1087, MSE=0.3459
2024-05-23 19:49:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-23 19:49:46 [INFO]: Using the given device: cuda:0
2024-05-23 19:49:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240523_T194946
2024-05-23 19:49:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240523_T194946/tensorboard
2024-05-23 19:49:46 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 19:49:46 [INFO]: Epoch 001 - training loss: 63601.0817, validation loss: 0.6527
2024-05-23 19:49:47 [INFO]: Epoch 002 - training loss: 41841.2705, validation loss: 0.5801
2024-05-23 19:49:47 [INFO]: Epoch 003 - training loss: 41513.2137, validation loss: 0.5492
2024-05-23 19:49:47 [INFO]: Epoch 004 - training loss: 41385.9261, validation loss: 0.4927
2024-05-23 19:49:47 [INFO]: Epoch 005 - training loss: 41304.9534, validation loss: 0.5104
2024-05-23 19:49:48 [INFO]: Epoch 006 - training loss: 41340.1551, validation loss: 0.4415
2024-05-23 19:49:48 [INFO]: Epoch 007 - training loss: 41196.7455, validation loss: 0.3968
2024-05-23 19:49:48 [INFO]: Epoch 008 - training loss: 41148.6395, validation loss: 0.3590
2024-05-23 19:49:48 [INFO]: Epoch 009 - training loss: 41128.8446, validation loss: 0.3566
2024-05-23 19:49:49 [INFO]: Epoch 010 - training loss: 41104.5913, validation loss: 0.3735
2024-05-23 19:49:49 [INFO]: Epoch 011 - training loss: 41071.8488, validation loss: 0.3332
2024-05-23 19:49:49 [INFO]: Epoch 012 - training loss: 41054.3061, validation loss: 0.3276
2024-05-23 19:49:49 [INFO]: Epoch 013 - training loss: 41041.8600, validation loss: 0.3174
2024-05-23 19:49:50 [INFO]: Epoch 014 - training loss: 41023.1811, validation loss: 0.3041
2024-05-23 19:49:50 [INFO]: Epoch 015 - training loss: 41017.3222, validation loss: 0.3256
2024-05-23 19:49:50 [INFO]: Epoch 016 - training loss: 40998.5748, validation loss: 0.2851
2024-05-23 19:49:50 [INFO]: Epoch 017 - training loss: 40985.2581, validation loss: 0.2840
2024-05-23 19:49:51 [INFO]: Epoch 018 - training loss: 40981.9456, validation loss: 0.2892
2024-05-23 19:49:51 [INFO]: Epoch 019 - training loss: 41004.2866, validation loss: 0.3448
2024-05-23 19:49:51 [INFO]: Epoch 020 - training loss: 40996.0181, validation loss: 0.2968
2024-05-23 19:49:51 [INFO]: Epoch 021 - training loss: 40972.9627, validation loss: 0.2724
2024-05-23 19:49:52 [INFO]: Epoch 022 - training loss: 40946.1292, validation loss: 0.2639
2024-05-23 19:49:52 [INFO]: Epoch 023 - training loss: 40943.5981, validation loss: 0.2787
2024-05-23 19:49:52 [INFO]: Epoch 024 - training loss: 40940.0914, validation loss: 0.2683
2024-05-23 19:49:52 [INFO]: Epoch 025 - training loss: 40943.8171, validation loss: 0.2706
2024-05-23 19:49:53 [INFO]: Epoch 026 - training loss: 40933.4190, validation loss: 0.2643
2024-05-23 19:49:53 [INFO]: Epoch 027 - training loss: 40933.7389, validation loss: 0.2593
2024-05-23 19:49:53 [INFO]: Epoch 028 - training loss: 40929.3835, validation loss: 0.2600
2024-05-23 19:49:53 [INFO]: Epoch 029 - training loss: 40956.6444, validation loss: 0.2717
2024-05-23 19:49:54 [INFO]: Epoch 030 - training loss: 41032.3636, validation loss: 0.2885
2024-05-23 19:49:54 [INFO]: Epoch 031 - training loss: 40944.7423, validation loss: 0.2647
2024-05-23 19:49:54 [INFO]: Epoch 032 - training loss: 40920.0956, validation loss: 0.2481
2024-05-23 19:49:54 [INFO]: Epoch 033 - training loss: 40904.8971, validation loss: 0.2696
2024-05-23 19:49:55 [INFO]: Epoch 034 - training loss: 40905.9606, validation loss: 0.2450
2024-05-23 19:49:55 [INFO]: Epoch 035 - training loss: 40903.5493, validation loss: 0.2460
2024-05-23 19:49:55 [INFO]: Epoch 036 - training loss: 40891.5312, validation loss: 0.2460
2024-05-23 19:49:55 [INFO]: Epoch 037 - training loss: 40889.1354, validation loss: 0.2363
2024-05-23 19:49:56 [INFO]: Epoch 038 - training loss: 40884.1709, validation loss: 0.2372
2024-05-23 19:49:56 [INFO]: Epoch 039 - training loss: 40887.9929, validation loss: 0.2578
2024-05-23 19:49:56 [INFO]: Epoch 040 - training loss: 40897.9744, validation loss: 0.2341
2024-05-23 19:49:56 [INFO]: Epoch 041 - training loss: 40894.7310, validation loss: 0.2428
2024-05-23 19:49:56 [INFO]: Epoch 042 - training loss: 40881.7487, validation loss: 0.2335
2024-05-23 19:49:57 [INFO]: Epoch 043 - training loss: 40871.9413, validation loss: 0.2401
2024-05-23 19:49:57 [INFO]: Epoch 044 - training loss: 40872.3329, validation loss: 0.2330
2024-05-23 19:49:57 [INFO]: Epoch 045 - training loss: 40874.8563, validation loss: 0.2506
2024-05-23 19:49:57 [INFO]: Epoch 046 - training loss: 40878.9034, validation loss: 0.2376
2024-05-23 19:49:58 [INFO]: Epoch 047 - training loss: 40871.9618, validation loss: 0.2479
2024-05-23 19:49:58 [INFO]: Epoch 048 - training loss: 40883.2588, validation loss: 0.2458
2024-05-23 19:49:58 [INFO]: Epoch 049 - training loss: 40892.8016, validation loss: 0.2311
2024-05-23 19:49:58 [INFO]: Epoch 050 - training loss: 40885.9839, validation loss: 0.2415
2024-05-23 19:49:59 [INFO]: Epoch 051 - training loss: 40895.0422, validation loss: 0.2920
2024-05-23 19:49:59 [INFO]: Epoch 052 - training loss: 40996.1185, validation loss: 0.2525
2024-05-23 19:49:59 [INFO]: Epoch 053 - training loss: 40922.3199, validation loss: 0.2400
2024-05-23 19:49:59 [INFO]: Epoch 054 - training loss: 40903.3273, validation loss: 0.2414
2024-05-23 19:50:00 [INFO]: Epoch 055 - training loss: 40890.1481, validation loss: 0.2306
2024-05-23 19:50:00 [INFO]: Epoch 056 - training loss: 40872.7743, validation loss: 0.2239
2024-05-23 19:50:00 [INFO]: Epoch 057 - training loss: 40878.7875, validation loss: 0.2256
2024-05-23 19:50:00 [INFO]: Epoch 058 - training loss: 40871.8973, validation loss: 0.2276
2024-05-23 19:50:01 [INFO]: Epoch 059 - training loss: 40869.0054, validation loss: 0.2257
2024-05-23 19:50:01 [INFO]: Epoch 060 - training loss: 40868.1839, validation loss: 0.2286
2024-05-23 19:50:01 [INFO]: Epoch 061 - training loss: 40856.7277, validation loss: 0.2191
2024-05-23 19:50:01 [INFO]: Epoch 062 - training loss: 40861.0007, validation loss: 0.2291
2024-05-23 19:50:02 [INFO]: Epoch 063 - training loss: 40862.8154, validation loss: 0.2336
2024-05-23 19:50:02 [INFO]: Epoch 064 - training loss: 40858.5122, validation loss: 0.2182
2024-05-23 19:50:02 [INFO]: Epoch 065 - training loss: 40853.8955, validation loss: 0.2255
2024-05-23 19:50:02 [INFO]: Epoch 066 - training loss: 40859.2454, validation loss: 0.2257
2024-05-23 19:50:03 [INFO]: Epoch 067 - training loss: 40859.2792, validation loss: 0.2325
2024-05-23 19:50:03 [INFO]: Epoch 068 - training loss: 40930.5132, validation loss: 0.2454
2024-05-23 19:50:03 [INFO]: Epoch 069 - training loss: 40913.3964, validation loss: 0.2443
2024-05-23 19:50:03 [INFO]: Epoch 070 - training loss: 40892.4988, validation loss: 0.2273
2024-05-23 19:50:04 [INFO]: Epoch 071 - training loss: 40870.2507, validation loss: 0.2225
2024-05-23 19:50:04 [INFO]: Epoch 072 - training loss: 40857.2545, validation loss: 0.2156
2024-05-23 19:50:04 [INFO]: Epoch 073 - training loss: 40860.5511, validation loss: 0.2281
2024-05-23 19:50:04 [INFO]: Epoch 074 - training loss: 40868.8037, validation loss: 0.2478
2024-05-23 19:50:05 [INFO]: Epoch 075 - training loss: 40887.0787, validation loss: 0.2351
2024-05-23 19:50:05 [INFO]: Epoch 076 - training loss: 40852.7399, validation loss: 0.2200
2024-05-23 19:50:05 [INFO]: Epoch 077 - training loss: 40854.3199, validation loss: 0.2146
2024-05-23 19:50:05 [INFO]: Epoch 078 - training loss: 40838.2597, validation loss: 0.2124
2024-05-23 19:50:06 [INFO]: Epoch 079 - training loss: 40835.8832, validation loss: 0.2119
2024-05-23 19:50:06 [INFO]: Epoch 080 - training loss: 40835.0467, validation loss: 0.2139
2024-05-23 19:50:06 [INFO]: Epoch 081 - training loss: 40834.0246, validation loss: 0.2114
2024-05-23 19:50:06 [INFO]: Epoch 082 - training loss: 40834.3676, validation loss: 0.2174
2024-05-23 19:50:07 [INFO]: Epoch 083 - training loss: 40836.8462, validation loss: 0.2214
2024-05-23 19:50:07 [INFO]: Epoch 084 - training loss: 40831.5408, validation loss: 0.2126
2024-05-23 19:50:07 [INFO]: Epoch 085 - training loss: 40834.1359, validation loss: 0.2262
2024-05-23 19:50:07 [INFO]: Epoch 086 - training loss: 40908.6208, validation loss: 0.2960
2024-05-23 19:50:08 [INFO]: Epoch 087 - training loss: 40900.0697, validation loss: 0.2260
2024-05-23 19:50:08 [INFO]: Epoch 088 - training loss: 40852.0292, validation loss: 0.2310
2024-05-23 19:50:08 [INFO]: Epoch 089 - training loss: 40851.5583, validation loss: 0.2233
2024-05-23 19:50:08 [INFO]: Epoch 090 - training loss: 40846.2962, validation loss: 0.2300
2024-05-23 19:50:09 [INFO]: Epoch 091 - training loss: 40841.3050, validation loss: 0.2144
2024-05-23 19:50:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:50:09 [INFO]: Finished training. The best model is from epoch#81.
2024-05-23 19:50:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240523_T194946/GPVAE.pypots
2024-05-23 19:50:09 [INFO]: GP-VAE on Air-Quality: MAE=0.2622, MSE=0.2549
2024-05-23 19:50:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-23 19:50:09 [INFO]: Using the given device: cuda:0
2024-05-23 19:50:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240523_T195009
2024-05-23 19:50:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240523_T195009/tensorboard
2024-05-23 19:50:09 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 19:50:13 [INFO]: Epoch 001 - generator training loss: 0.4532, discriminator training loss: 0.4496, validation loss: 0.5247
2024-05-23 19:50:16 [INFO]: Epoch 002 - generator training loss: 0.0924, discriminator training loss: 0.3617, validation loss: 0.3985
2024-05-23 19:50:19 [INFO]: Epoch 003 - generator training loss: 0.0299, discriminator training loss: 0.3571, validation loss: 0.3294
2024-05-23 19:50:23 [INFO]: Epoch 004 - generator training loss: -0.0003, discriminator training loss: 0.3553, validation loss: 0.2877
2024-05-23 19:50:26 [INFO]: Epoch 005 - generator training loss: -0.0311, discriminator training loss: 0.3533, validation loss: 0.2613
2024-05-23 19:50:29 [INFO]: Epoch 006 - generator training loss: -0.0465, discriminator training loss: 0.3516, validation loss: 0.2413
2024-05-23 19:50:32 [INFO]: Epoch 007 - generator training loss: -0.0587, discriminator training loss: 0.3495, validation loss: 0.2265
2024-05-23 19:50:36 [INFO]: Epoch 008 - generator training loss: -0.0680, discriminator training loss: 0.3476, validation loss: 0.2141
2024-05-23 19:50:39 [INFO]: Epoch 009 - generator training loss: -0.0753, discriminator training loss: 0.3452, validation loss: 0.2043
2024-05-23 19:50:43 [INFO]: Epoch 010 - generator training loss: -0.0835, discriminator training loss: 0.3431, validation loss: 0.1965
2024-05-23 19:50:46 [INFO]: Epoch 011 - generator training loss: -0.0887, discriminator training loss: 0.3407, validation loss: 0.1894
2024-05-23 19:50:49 [INFO]: Epoch 012 - generator training loss: -0.0923, discriminator training loss: 0.3382, validation loss: 0.1840
2024-05-23 19:50:53 [INFO]: Epoch 013 - generator training loss: -0.0956, discriminator training loss: 0.3353, validation loss: 0.1791
2024-05-23 19:50:56 [INFO]: Epoch 014 - generator training loss: -0.0969, discriminator training loss: 0.3327, validation loss: 0.1750
2024-05-23 19:50:59 [INFO]: Epoch 015 - generator training loss: -0.0982, discriminator training loss: 0.3293, validation loss: 0.1709
2024-05-23 19:51:03 [INFO]: Epoch 016 - generator training loss: -0.1000, discriminator training loss: 0.3259, validation loss: 0.1676
2024-05-23 19:51:06 [INFO]: Epoch 017 - generator training loss: -0.0999, discriminator training loss: 0.3222, validation loss: 0.1645
2024-05-23 19:51:09 [INFO]: Epoch 018 - generator training loss: -0.0989, discriminator training loss: 0.3184, validation loss: 0.1610
2024-05-23 19:51:13 [INFO]: Epoch 019 - generator training loss: -0.0983, discriminator training loss: 0.3142, validation loss: 0.1584
2024-05-23 19:51:16 [INFO]: Epoch 020 - generator training loss: -0.0973, discriminator training loss: 0.3101, validation loss: 0.1563
2024-05-23 19:51:19 [INFO]: Epoch 021 - generator training loss: -0.0955, discriminator training loss: 0.3056, validation loss: 0.1541
2024-05-23 19:51:23 [INFO]: Epoch 022 - generator training loss: -0.0953, discriminator training loss: 0.3015, validation loss: 0.1517
2024-05-23 19:51:26 [INFO]: Epoch 023 - generator training loss: -0.0924, discriminator training loss: 0.2969, validation loss: 0.1497
2024-05-23 19:51:29 [INFO]: Epoch 024 - generator training loss: -0.0916, discriminator training loss: 0.2928, validation loss: 0.1475
2024-05-23 19:51:33 [INFO]: Epoch 025 - generator training loss: -0.0894, discriminator training loss: 0.2885, validation loss: 0.1462
2024-05-23 19:51:36 [INFO]: Epoch 026 - generator training loss: -0.0854, discriminator training loss: 0.2846, validation loss: 0.1442
2024-05-23 19:51:39 [INFO]: Epoch 027 - generator training loss: -0.0865, discriminator training loss: 0.2802, validation loss: 0.1424
2024-05-23 19:51:43 [INFO]: Epoch 028 - generator training loss: -0.0859, discriminator training loss: 0.2762, validation loss: 0.1410
2024-05-23 19:51:46 [INFO]: Epoch 029 - generator training loss: -0.0840, discriminator training loss: 0.2727, validation loss: 0.1388
2024-05-23 19:51:49 [INFO]: Epoch 030 - generator training loss: -0.0826, discriminator training loss: 0.2697, validation loss: 0.1375
2024-05-23 19:51:53 [INFO]: Epoch 031 - generator training loss: -0.0811, discriminator training loss: 0.2659, validation loss: 0.1362
2024-05-23 19:51:56 [INFO]: Epoch 032 - generator training loss: -0.0800, discriminator training loss: 0.2627, validation loss: 0.1341
2024-05-23 19:51:59 [INFO]: Epoch 033 - generator training loss: -0.0797, discriminator training loss: 0.2599, validation loss: 0.1333
2024-05-23 19:52:02 [INFO]: Epoch 034 - generator training loss: -0.0784, discriminator training loss: 0.2570, validation loss: 0.1327
2024-05-23 19:52:06 [INFO]: Epoch 035 - generator training loss: -0.0771, discriminator training loss: 0.2545, validation loss: 0.1303
2024-05-23 19:52:09 [INFO]: Epoch 036 - generator training loss: -0.0766, discriminator training loss: 0.2520, validation loss: 0.1296
2024-05-23 19:52:12 [INFO]: Epoch 037 - generator training loss: -0.0751, discriminator training loss: 0.2496, validation loss: 0.1282
2024-05-23 19:52:16 [INFO]: Epoch 038 - generator training loss: -0.0755, discriminator training loss: 0.2473, validation loss: 0.1273
2024-05-23 19:52:19 [INFO]: Epoch 039 - generator training loss: -0.0754, discriminator training loss: 0.2449, validation loss: 0.1257
2024-05-23 19:52:22 [INFO]: Epoch 040 - generator training loss: -0.0743, discriminator training loss: 0.2428, validation loss: 0.1251
2024-05-23 19:52:26 [INFO]: Epoch 041 - generator training loss: -0.0728, discriminator training loss: 0.2408, validation loss: 0.1236
2024-05-23 19:52:29 [INFO]: Epoch 042 - generator training loss: -0.0727, discriminator training loss: 0.2388, validation loss: 0.1228
2024-05-23 19:52:33 [INFO]: Epoch 043 - generator training loss: -0.0726, discriminator training loss: 0.2372, validation loss: 0.1219
2024-05-23 19:52:36 [INFO]: Epoch 044 - generator training loss: -0.0722, discriminator training loss: 0.2358, validation loss: 0.1206
2024-05-23 19:52:39 [INFO]: Epoch 045 - generator training loss: -0.0722, discriminator training loss: 0.2342, validation loss: 0.1197
2024-05-23 19:52:42 [INFO]: Epoch 046 - generator training loss: -0.0723, discriminator training loss: 0.2328, validation loss: 0.1190
2024-05-23 19:52:46 [INFO]: Epoch 047 - generator training loss: -0.0719, discriminator training loss: 0.2316, validation loss: 0.1179
2024-05-23 19:52:49 [INFO]: Epoch 048 - generator training loss: -0.0711, discriminator training loss: 0.2306, validation loss: 0.1172
2024-05-23 19:52:52 [INFO]: Epoch 049 - generator training loss: -0.0696, discriminator training loss: 0.2291, validation loss: 0.1158
2024-05-23 19:52:56 [INFO]: Epoch 050 - generator training loss: -0.0709, discriminator training loss: 0.2278, validation loss: 0.1160
2024-05-23 19:52:59 [INFO]: Epoch 051 - generator training loss: -0.0714, discriminator training loss: 0.2268, validation loss: 0.1149
2024-05-23 19:53:02 [INFO]: Epoch 052 - generator training loss: -0.0706, discriminator training loss: 0.2257, validation loss: 0.1141
2024-05-23 19:53:06 [INFO]: Epoch 053 - generator training loss: -0.0712, discriminator training loss: 0.2249, validation loss: 0.1130
2024-05-23 19:53:09 [INFO]: Epoch 054 - generator training loss: -0.0721, discriminator training loss: 0.2236, validation loss: 0.1124
2024-05-23 19:53:12 [INFO]: Epoch 055 - generator training loss: -0.0714, discriminator training loss: 0.2236, validation loss: 0.1113
2024-05-23 19:53:16 [INFO]: Epoch 056 - generator training loss: -0.0723, discriminator training loss: 0.2219, validation loss: 0.1113
2024-05-23 19:53:19 [INFO]: Epoch 057 - generator training loss: -0.0720, discriminator training loss: 0.2214, validation loss: 0.1107
2024-05-23 19:53:22 [INFO]: Epoch 058 - generator training loss: -0.0724, discriminator training loss: 0.2209, validation loss: 0.1104
2024-05-23 19:53:26 [INFO]: Epoch 059 - generator training loss: -0.0727, discriminator training loss: 0.2197, validation loss: 0.1094
2024-05-23 19:53:29 [INFO]: Epoch 060 - generator training loss: -0.0722, discriminator training loss: 0.2196, validation loss: 0.1086
2024-05-23 19:53:32 [INFO]: Epoch 061 - generator training loss: -0.0718, discriminator training loss: 0.2189, validation loss: 0.1075
2024-05-23 19:53:36 [INFO]: Epoch 062 - generator training loss: -0.0716, discriminator training loss: 0.2180, validation loss: 0.1070
2024-05-23 19:53:39 [INFO]: Epoch 063 - generator training loss: -0.0713, discriminator training loss: 0.2173, validation loss: 0.1081
2024-05-23 19:53:42 [INFO]: Epoch 064 - generator training loss: -0.0721, discriminator training loss: 0.2171, validation loss: 0.1060
2024-05-23 19:53:46 [INFO]: Epoch 065 - generator training loss: -0.0729, discriminator training loss: 0.2161, validation loss: 0.1061
2024-05-23 19:53:49 [INFO]: Epoch 066 - generator training loss: -0.0717, discriminator training loss: 0.2157, validation loss: 0.1059
2024-05-23 19:53:52 [INFO]: Epoch 067 - generator training loss: -0.0732, discriminator training loss: 0.2152, validation loss: 0.1058
2024-05-23 19:53:56 [INFO]: Epoch 068 - generator training loss: -0.0735, discriminator training loss: 0.2150, validation loss: 0.1051
2024-05-23 19:53:59 [INFO]: Epoch 069 - generator training loss: -0.0730, discriminator training loss: 0.2147, validation loss: 0.1051
2024-05-23 19:54:02 [INFO]: Epoch 070 - generator training loss: -0.0727, discriminator training loss: 0.2138, validation loss: 0.1037
2024-05-23 19:54:06 [INFO]: Epoch 071 - generator training loss: -0.0735, discriminator training loss: 0.2134, validation loss: 0.1049
2024-05-23 19:54:09 [INFO]: Epoch 072 - generator training loss: -0.0746, discriminator training loss: 0.2136, validation loss: 0.1034
2024-05-23 19:54:12 [INFO]: Epoch 073 - generator training loss: -0.0731, discriminator training loss: 0.2130, validation loss: 0.1033
2024-05-23 19:54:16 [INFO]: Epoch 074 - generator training loss: -0.0736, discriminator training loss: 0.2126, validation loss: 0.1025
2024-05-23 19:54:19 [INFO]: Epoch 075 - generator training loss: -0.0739, discriminator training loss: 0.2117, validation loss: 0.1025
2024-05-23 19:54:22 [INFO]: Epoch 076 - generator training loss: -0.0741, discriminator training loss: 0.2119, validation loss: 0.1024
2024-05-23 19:54:26 [INFO]: Epoch 077 - generator training loss: -0.0746, discriminator training loss: 0.2113, validation loss: 0.1023
2024-05-23 19:54:29 [INFO]: Epoch 078 - generator training loss: -0.0752, discriminator training loss: 0.2113, validation loss: 0.1026
2024-05-23 19:54:32 [INFO]: Epoch 079 - generator training loss: -0.0756, discriminator training loss: 0.2112, validation loss: 0.1018
2024-05-23 19:54:36 [INFO]: Epoch 080 - generator training loss: -0.0750, discriminator training loss: 0.2102, validation loss: 0.1015
2024-05-23 19:54:39 [INFO]: Epoch 081 - generator training loss: -0.0755, discriminator training loss: 0.2098, validation loss: 0.1018
2024-05-23 19:54:42 [INFO]: Epoch 082 - generator training loss: -0.0756, discriminator training loss: 0.2100, validation loss: 0.1012
2024-05-23 19:54:46 [INFO]: Epoch 083 - generator training loss: -0.0761, discriminator training loss: 0.2096, validation loss: 0.1004
2024-05-23 19:54:49 [INFO]: Epoch 084 - generator training loss: -0.0768, discriminator training loss: 0.2098, validation loss: 0.1007
2024-05-23 19:54:52 [INFO]: Epoch 085 - generator training loss: -0.0761, discriminator training loss: 0.2090, validation loss: 0.1005
2024-05-23 19:54:56 [INFO]: Epoch 086 - generator training loss: -0.0774, discriminator training loss: 0.2088, validation loss: 0.1005
2024-05-23 19:54:59 [INFO]: Epoch 087 - generator training loss: -0.0766, discriminator training loss: 0.2086, validation loss: 0.0995
2024-05-23 19:55:02 [INFO]: Epoch 088 - generator training loss: -0.0769, discriminator training loss: 0.2083, validation loss: 0.1004
2024-05-23 19:55:06 [INFO]: Epoch 089 - generator training loss: -0.0775, discriminator training loss: 0.2082, validation loss: 0.1000
2024-05-23 19:55:09 [INFO]: Epoch 090 - generator training loss: -0.0778, discriminator training loss: 0.2080, validation loss: 0.0995
2024-05-23 19:55:12 [INFO]: Epoch 091 - generator training loss: -0.0774, discriminator training loss: 0.2076, validation loss: 0.0992
2024-05-23 19:55:16 [INFO]: Epoch 092 - generator training loss: -0.0783, discriminator training loss: 0.2076, validation loss: 0.0998
2024-05-23 19:55:19 [INFO]: Epoch 093 - generator training loss: -0.0774, discriminator training loss: 0.2076, validation loss: 0.0988
2024-05-23 19:55:22 [INFO]: Epoch 094 - generator training loss: -0.0772, discriminator training loss: 0.2075, validation loss: 0.0992
2024-05-23 19:55:26 [INFO]: Epoch 095 - generator training loss: -0.0775, discriminator training loss: 0.2070, validation loss: 0.0980
2024-05-23 19:55:29 [INFO]: Epoch 096 - generator training loss: -0.0778, discriminator training loss: 0.2070, validation loss: 0.0999
2024-05-23 19:55:32 [INFO]: Epoch 097 - generator training loss: -0.0785, discriminator training loss: 0.2065, validation loss: 0.0984
2024-05-23 19:55:36 [INFO]: Epoch 098 - generator training loss: -0.0782, discriminator training loss: 0.2065, validation loss: 0.0984
2024-05-23 19:55:39 [INFO]: Epoch 099 - generator training loss: -0.0787, discriminator training loss: 0.2066, validation loss: 0.0981
2024-05-23 19:55:42 [INFO]: Epoch 100 - generator training loss: -0.0786, discriminator training loss: 0.2065, validation loss: 0.0989
2024-05-23 19:55:46 [INFO]: Epoch 101 - generator training loss: -0.0777, discriminator training loss: 0.2064, validation loss: 0.0981
2024-05-23 19:55:49 [INFO]: Epoch 102 - generator training loss: -0.0781, discriminator training loss: 0.2057, validation loss: 0.0981
2024-05-23 19:55:52 [INFO]: Epoch 103 - generator training loss: -0.0791, discriminator training loss: 0.2059, validation loss: 0.0984
2024-05-23 19:55:56 [INFO]: Epoch 104 - generator training loss: -0.0785, discriminator training loss: 0.2056, validation loss: 0.0980
2024-05-23 19:55:59 [INFO]: Epoch 105 - generator training loss: -0.0802, discriminator training loss: 0.2054, validation loss: 0.0982
2024-05-23 19:56:02 [INFO]: Epoch 106 - generator training loss: -0.0796, discriminator training loss: 0.2052, validation loss: 0.0972
2024-05-23 19:56:06 [INFO]: Epoch 107 - generator training loss: -0.0806, discriminator training loss: 0.2057, validation loss: 0.0974
2024-05-23 19:56:09 [INFO]: Epoch 108 - generator training loss: -0.0808, discriminator training loss: 0.2049, validation loss: 0.0967
2024-05-23 19:56:12 [INFO]: Epoch 109 - generator training loss: -0.0801, discriminator training loss: 0.2050, validation loss: 0.0971
2024-05-23 19:56:16 [INFO]: Epoch 110 - generator training loss: -0.0804, discriminator training loss: 0.2048, validation loss: 0.0971
2024-05-23 19:56:19 [INFO]: Epoch 111 - generator training loss: -0.0809, discriminator training loss: 0.2048, validation loss: 0.0965
2024-05-23 19:56:23 [INFO]: Epoch 112 - generator training loss: -0.0810, discriminator training loss: 0.2046, validation loss: 0.0967
2024-05-23 19:56:26 [INFO]: Epoch 113 - generator training loss: -0.0803, discriminator training loss: 0.2043, validation loss: 0.0963
2024-05-23 19:56:29 [INFO]: Epoch 114 - generator training loss: -0.0815, discriminator training loss: 0.2041, validation loss: 0.0971
2024-05-23 19:56:33 [INFO]: Epoch 115 - generator training loss: -0.0812, discriminator training loss: 0.2041, validation loss: 0.0962
2024-05-23 19:56:36 [INFO]: Epoch 116 - generator training loss: -0.0811, discriminator training loss: 0.2041, validation loss: 0.0975
2024-05-23 19:56:39 [INFO]: Epoch 117 - generator training loss: -0.0808, discriminator training loss: 0.2042, validation loss: 0.0957
2024-05-23 19:56:43 [INFO]: Epoch 118 - generator training loss: -0.0821, discriminator training loss: 0.2038, validation loss: 0.0961
2024-05-23 19:56:46 [INFO]: Epoch 119 - generator training loss: -0.0815, discriminator training loss: 0.2037, validation loss: 0.0953
2024-05-23 19:56:49 [INFO]: Epoch 120 - generator training loss: -0.0817, discriminator training loss: 0.2033, validation loss: 0.0959
2024-05-23 19:56:53 [INFO]: Epoch 121 - generator training loss: -0.0826, discriminator training loss: 0.2035, validation loss: 0.0956
2024-05-23 19:56:56 [INFO]: Epoch 122 - generator training loss: -0.0819, discriminator training loss: 0.2034, validation loss: 0.0957
2024-05-23 19:56:59 [INFO]: Epoch 123 - generator training loss: -0.0820, discriminator training loss: 0.2032, validation loss: 0.0967
2024-05-23 19:57:03 [INFO]: Epoch 124 - generator training loss: -0.0821, discriminator training loss: 0.2030, validation loss: 0.0949
2024-05-23 19:57:06 [INFO]: Epoch 125 - generator training loss: -0.0821, discriminator training loss: 0.2032, validation loss: 0.0960
2024-05-23 19:57:09 [INFO]: Epoch 126 - generator training loss: -0.0825, discriminator training loss: 0.2027, validation loss: 0.0958
2024-05-23 19:57:13 [INFO]: Epoch 127 - generator training loss: -0.0830, discriminator training loss: 0.2032, validation loss: 0.0953
2024-05-23 19:57:16 [INFO]: Epoch 128 - generator training loss: -0.0824, discriminator training loss: 0.2031, validation loss: 0.0960
2024-05-23 19:57:19 [INFO]: Epoch 129 - generator training loss: -0.0832, discriminator training loss: 0.2024, validation loss: 0.0960
2024-05-23 19:57:22 [INFO]: Epoch 130 - generator training loss: -0.0834, discriminator training loss: 0.2022, validation loss: 0.0960
2024-05-23 19:57:26 [INFO]: Epoch 131 - generator training loss: -0.0833, discriminator training loss: 0.2025, validation loss: 0.0961
2024-05-23 19:57:29 [INFO]: Epoch 132 - generator training loss: -0.0828, discriminator training loss: 0.2019, validation loss: 0.0948
2024-05-23 19:57:32 [INFO]: Epoch 133 - generator training loss: -0.0833, discriminator training loss: 0.2020, validation loss: 0.0951
2024-05-23 19:57:36 [INFO]: Epoch 134 - generator training loss: -0.0836, discriminator training loss: 0.2024, validation loss: 0.0952
2024-05-23 19:57:39 [INFO]: Epoch 135 - generator training loss: -0.0826, discriminator training loss: 0.2019, validation loss: 0.0947
2024-05-23 19:57:42 [INFO]: Epoch 136 - generator training loss: -0.0841, discriminator training loss: 0.2017, validation loss: 0.0960
2024-05-23 19:57:46 [INFO]: Epoch 137 - generator training loss: -0.0841, discriminator training loss: 0.2018, validation loss: 0.0951
2024-05-23 19:57:49 [INFO]: Epoch 138 - generator training loss: -0.0837, discriminator training loss: 0.2013, validation loss: 0.0951
2024-05-23 19:57:52 [INFO]: Epoch 139 - generator training loss: -0.0841, discriminator training loss: 0.2014, validation loss: 0.0954
2024-05-23 19:57:56 [INFO]: Epoch 140 - generator training loss: -0.0841, discriminator training loss: 0.2012, validation loss: 0.0960
2024-05-23 19:57:59 [INFO]: Epoch 141 - generator training loss: -0.0844, discriminator training loss: 0.2012, validation loss: 0.0948
2024-05-23 19:58:02 [INFO]: Epoch 142 - generator training loss: -0.0843, discriminator training loss: 0.2009, validation loss: 0.0950
2024-05-23 19:58:06 [INFO]: Epoch 143 - generator training loss: -0.0848, discriminator training loss: 0.2011, validation loss: 0.0943
2024-05-23 19:58:09 [INFO]: Epoch 144 - generator training loss: -0.0834, discriminator training loss: 0.2010, validation loss: 0.0956
2024-05-23 19:58:12 [INFO]: Epoch 145 - generator training loss: -0.0813, discriminator training loss: 0.2006, validation loss: 0.0956
2024-05-23 19:58:16 [INFO]: Epoch 146 - generator training loss: -0.0830, discriminator training loss: 0.2014, validation loss: 0.0953
2024-05-23 19:58:19 [INFO]: Epoch 147 - generator training loss: -0.0841, discriminator training loss: 0.2009, validation loss: 0.0944
2024-05-23 19:58:22 [INFO]: Epoch 148 - generator training loss: -0.0844, discriminator training loss: 0.2009, validation loss: 0.0952
2024-05-23 19:58:26 [INFO]: Epoch 149 - generator training loss: -0.0844, discriminator training loss: 0.2005, validation loss: 0.0947
2024-05-23 19:58:29 [INFO]: Epoch 150 - generator training loss: -0.0855, discriminator training loss: 0.2004, validation loss: 0.0953
2024-05-23 19:58:32 [INFO]: Epoch 151 - generator training loss: -0.0843, discriminator training loss: 0.2004, validation loss: 0.0953
2024-05-23 19:58:36 [INFO]: Epoch 152 - generator training loss: -0.0851, discriminator training loss: 0.2008, validation loss: 0.0945
2024-05-23 19:58:39 [INFO]: Epoch 153 - generator training loss: -0.0850, discriminator training loss: 0.1999, validation loss: 0.0955
2024-05-23 19:58:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:58:39 [INFO]: Finished training. The best model is from epoch#143.
2024-05-23 19:58:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240523_T195009/USGAN.pypots
2024-05-23 19:58:39 [INFO]: US-GAN on Air-Quality: MAE=0.1490, MSE=0.1178
2024-05-23 19:58:39 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-23 19:58:39 [INFO]: Using the given device: cuda:0
2024-05-23 19:58:39 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240523_T195839
2024-05-23 19:58:39 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240523_T195839/tensorboard
2024-05-23 19:58:39 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 19:58:42 [INFO]: Epoch 001 - training loss: 1.4050, validation loss: 0.9255
2024-05-23 19:58:44 [INFO]: Epoch 002 - training loss: 1.1342, validation loss: 0.6911
2024-05-23 19:58:47 [INFO]: Epoch 003 - training loss: 0.9478, validation loss: 0.5853
2024-05-23 19:58:49 [INFO]: Epoch 004 - training loss: 0.8382, validation loss: 0.5164
2024-05-23 19:58:51 [INFO]: Epoch 005 - training loss: 0.7647, validation loss: 0.4699
2024-05-23 19:58:54 [INFO]: Epoch 006 - training loss: 0.7097, validation loss: 0.4329
2024-05-23 19:58:56 [INFO]: Epoch 007 - training loss: 0.6665, validation loss: 0.4034
2024-05-23 19:58:58 [INFO]: Epoch 008 - training loss: 0.6341, validation loss: 0.3796
2024-05-23 19:59:00 [INFO]: Epoch 009 - training loss: 0.6101, validation loss: 0.3607
2024-05-23 19:59:03 [INFO]: Epoch 010 - training loss: 0.5871, validation loss: 0.3453
2024-05-23 19:59:05 [INFO]: Epoch 011 - training loss: 0.5701, validation loss: 0.3325
2024-05-23 19:59:07 [INFO]: Epoch 012 - training loss: 0.5563, validation loss: 0.3212
2024-05-23 19:59:09 [INFO]: Epoch 013 - training loss: 0.5425, validation loss: 0.3106
2024-05-23 19:59:12 [INFO]: Epoch 014 - training loss: 0.5307, validation loss: 0.3015
2024-05-23 19:59:14 [INFO]: Epoch 015 - training loss: 0.5203, validation loss: 0.2940
2024-05-23 19:59:16 [INFO]: Epoch 016 - training loss: 0.5109, validation loss: 0.2869
2024-05-23 19:59:18 [INFO]: Epoch 017 - training loss: 0.5021, validation loss: 0.2805
2024-05-23 19:59:20 [INFO]: Epoch 018 - training loss: 0.4932, validation loss: 0.2746
2024-05-23 19:59:23 [INFO]: Epoch 019 - training loss: 0.4870, validation loss: 0.2696
2024-05-23 19:59:25 [INFO]: Epoch 020 - training loss: 0.4786, validation loss: 0.2641
2024-05-23 19:59:27 [INFO]: Epoch 021 - training loss: 0.4706, validation loss: 0.2593
2024-05-23 19:59:29 [INFO]: Epoch 022 - training loss: 0.4652, validation loss: 0.2551
2024-05-23 19:59:32 [INFO]: Epoch 023 - training loss: 0.4584, validation loss: 0.2509
2024-05-23 19:59:34 [INFO]: Epoch 024 - training loss: 0.4526, validation loss: 0.2470
2024-05-23 19:59:36 [INFO]: Epoch 025 - training loss: 0.4468, validation loss: 0.2429
2024-05-23 19:59:38 [INFO]: Epoch 026 - training loss: 0.4407, validation loss: 0.2390
2024-05-23 19:59:40 [INFO]: Epoch 027 - training loss: 0.4365, validation loss: 0.2359
2024-05-23 19:59:43 [INFO]: Epoch 028 - training loss: 0.4297, validation loss: 0.2326
2024-05-23 19:59:45 [INFO]: Epoch 029 - training loss: 0.4269, validation loss: 0.2290
2024-05-23 19:59:47 [INFO]: Epoch 030 - training loss: 0.4209, validation loss: 0.2258
2024-05-23 19:59:49 [INFO]: Epoch 031 - training loss: 0.4163, validation loss: 0.2231
2024-05-23 19:59:52 [INFO]: Epoch 032 - training loss: 0.4125, validation loss: 0.2200
2024-05-23 19:59:54 [INFO]: Epoch 033 - training loss: 0.4086, validation loss: 0.2169
2024-05-23 19:59:56 [INFO]: Epoch 034 - training loss: 0.4035, validation loss: 0.2141
2024-05-23 19:59:58 [INFO]: Epoch 035 - training loss: 0.4001, validation loss: 0.2116
2024-05-23 20:00:00 [INFO]: Epoch 036 - training loss: 0.3966, validation loss: 0.2090
2024-05-23 20:00:03 [INFO]: Epoch 037 - training loss: 0.3924, validation loss: 0.2063
2024-05-23 20:00:05 [INFO]: Epoch 038 - training loss: 0.3890, validation loss: 0.2041
2024-05-23 20:00:07 [INFO]: Epoch 039 - training loss: 0.3859, validation loss: 0.2014
2024-05-23 20:00:09 [INFO]: Epoch 040 - training loss: 0.3821, validation loss: 0.1991
2024-05-23 20:00:12 [INFO]: Epoch 041 - training loss: 0.3786, validation loss: 0.1969
2024-05-23 20:00:14 [INFO]: Epoch 042 - training loss: 0.3766, validation loss: 0.1948
2024-05-23 20:00:16 [INFO]: Epoch 043 - training loss: 0.3731, validation loss: 0.1923
2024-05-23 20:00:18 [INFO]: Epoch 044 - training loss: 0.3690, validation loss: 0.1902
2024-05-23 20:00:20 [INFO]: Epoch 045 - training loss: 0.3673, validation loss: 0.1884
2024-05-23 20:00:23 [INFO]: Epoch 046 - training loss: 0.3645, validation loss: 0.1865
2024-05-23 20:00:25 [INFO]: Epoch 047 - training loss: 0.3611, validation loss: 0.1852
2024-05-23 20:00:27 [INFO]: Epoch 048 - training loss: 0.3594, validation loss: 0.1834
2024-05-23 20:00:29 [INFO]: Epoch 049 - training loss: 0.3561, validation loss: 0.1821
2024-05-23 20:00:32 [INFO]: Epoch 050 - training loss: 0.3545, validation loss: 0.1803
2024-05-23 20:00:34 [INFO]: Epoch 051 - training loss: 0.3521, validation loss: 0.1788
2024-05-23 20:00:36 [INFO]: Epoch 052 - training loss: 0.3508, validation loss: 0.1772
2024-05-23 20:00:39 [INFO]: Epoch 053 - training loss: 0.3476, validation loss: 0.1761
2024-05-23 20:00:41 [INFO]: Epoch 054 - training loss: 0.3462, validation loss: 0.1747
2024-05-23 20:00:43 [INFO]: Epoch 055 - training loss: 0.3454, validation loss: 0.1738
2024-05-23 20:00:45 [INFO]: Epoch 056 - training loss: 0.3428, validation loss: 0.1719
2024-05-23 20:00:47 [INFO]: Epoch 057 - training loss: 0.3396, validation loss: 0.1709
2024-05-23 20:00:50 [INFO]: Epoch 058 - training loss: 0.3382, validation loss: 0.1697
2024-05-23 20:00:52 [INFO]: Epoch 059 - training loss: 0.3359, validation loss: 0.1689
2024-05-23 20:00:54 [INFO]: Epoch 060 - training loss: 0.3352, validation loss: 0.1677
2024-05-23 20:00:56 [INFO]: Epoch 061 - training loss: 0.3326, validation loss: 0.1665
2024-05-23 20:00:59 [INFO]: Epoch 062 - training loss: 0.3313, validation loss: 0.1653
2024-05-23 20:01:01 [INFO]: Epoch 063 - training loss: 0.3304, validation loss: 0.1641
2024-05-23 20:01:03 [INFO]: Epoch 064 - training loss: 0.3279, validation loss: 0.1634
2024-05-23 20:01:05 [INFO]: Epoch 065 - training loss: 0.3266, validation loss: 0.1621
2024-05-23 20:01:08 [INFO]: Epoch 066 - training loss: 0.3258, validation loss: 0.1612
2024-05-23 20:01:10 [INFO]: Epoch 067 - training loss: 0.3235, validation loss: 0.1605
2024-05-23 20:01:12 [INFO]: Epoch 068 - training loss: 0.3229, validation loss: 0.1593
2024-05-23 20:01:14 [INFO]: Epoch 069 - training loss: 0.3223, validation loss: 0.1582
2024-05-23 20:01:17 [INFO]: Epoch 070 - training loss: 0.3208, validation loss: 0.1574
2024-05-23 20:01:19 [INFO]: Epoch 071 - training loss: 0.3188, validation loss: 0.1564
2024-05-23 20:01:21 [INFO]: Epoch 072 - training loss: 0.3174, validation loss: 0.1556
2024-05-23 20:01:24 [INFO]: Epoch 073 - training loss: 0.3168, validation loss: 0.1547
2024-05-23 20:01:26 [INFO]: Epoch 074 - training loss: 0.3154, validation loss: 0.1539
2024-05-23 20:01:28 [INFO]: Epoch 075 - training loss: 0.3153, validation loss: 0.1531
2024-05-23 20:01:30 [INFO]: Epoch 076 - training loss: 0.3141, validation loss: 0.1522
2024-05-23 20:01:32 [INFO]: Epoch 077 - training loss: 0.3123, validation loss: 0.1516
2024-05-23 20:01:35 [INFO]: Epoch 078 - training loss: 0.3115, validation loss: 0.1505
2024-05-23 20:01:37 [INFO]: Epoch 079 - training loss: 0.3103, validation loss: 0.1499
2024-05-23 20:01:39 [INFO]: Epoch 080 - training loss: 0.3097, validation loss: 0.1490
2024-05-23 20:01:41 [INFO]: Epoch 081 - training loss: 0.3090, validation loss: 0.1485
2024-05-23 20:01:44 [INFO]: Epoch 082 - training loss: 0.3076, validation loss: 0.1479
2024-05-23 20:01:46 [INFO]: Epoch 083 - training loss: 0.3066, validation loss: 0.1470
2024-05-23 20:01:48 [INFO]: Epoch 084 - training loss: 0.3063, validation loss: 0.1459
2024-05-23 20:01:50 [INFO]: Epoch 085 - training loss: 0.3053, validation loss: 0.1454
2024-05-23 20:01:52 [INFO]: Epoch 086 - training loss: 0.3047, validation loss: 0.1449
2024-05-23 20:01:55 [INFO]: Epoch 087 - training loss: 0.3032, validation loss: 0.1440
2024-05-23 20:01:57 [INFO]: Epoch 088 - training loss: 0.3026, validation loss: 0.1435
2024-05-23 20:01:59 [INFO]: Epoch 089 - training loss: 0.3015, validation loss: 0.1428
2024-05-23 20:02:01 [INFO]: Epoch 090 - training loss: 0.3014, validation loss: 0.1421
2024-05-23 20:02:04 [INFO]: Epoch 091 - training loss: 0.3004, validation loss: 0.1415
2024-05-23 20:02:06 [INFO]: Epoch 092 - training loss: 0.2995, validation loss: 0.1409
2024-05-23 20:02:08 [INFO]: Epoch 093 - training loss: 0.2987, validation loss: 0.1403
2024-05-23 20:02:10 [INFO]: Epoch 094 - training loss: 0.2976, validation loss: 0.1395
2024-05-23 20:02:12 [INFO]: Epoch 095 - training loss: 0.2975, validation loss: 0.1389
2024-05-23 20:02:15 [INFO]: Epoch 096 - training loss: 0.2966, validation loss: 0.1382
2024-05-23 20:02:17 [INFO]: Epoch 097 - training loss: 0.2955, validation loss: 0.1376
2024-05-23 20:02:19 [INFO]: Epoch 098 - training loss: 0.2952, validation loss: 0.1373
2024-05-23 20:02:21 [INFO]: Epoch 099 - training loss: 0.2944, validation loss: 0.1367
2024-05-23 20:02:24 [INFO]: Epoch 100 - training loss: 0.2941, validation loss: 0.1362
2024-05-23 20:02:26 [INFO]: Epoch 101 - training loss: 0.2938, validation loss: 0.1354
2024-05-23 20:02:28 [INFO]: Epoch 102 - training loss: 0.2930, validation loss: 0.1347
2024-05-23 20:02:30 [INFO]: Epoch 103 - training loss: 0.2919, validation loss: 0.1343
2024-05-23 20:02:33 [INFO]: Epoch 104 - training loss: 0.2917, validation loss: 0.1338
2024-05-23 20:02:35 [INFO]: Epoch 105 - training loss: 0.2906, validation loss: 0.1333
2024-05-23 20:02:37 [INFO]: Epoch 106 - training loss: 0.2911, validation loss: 0.1328
2024-05-23 20:02:39 [INFO]: Epoch 107 - training loss: 0.2908, validation loss: 0.1323
2024-05-23 20:02:41 [INFO]: Epoch 108 - training loss: 0.2891, validation loss: 0.1318
2024-05-23 20:02:44 [INFO]: Epoch 109 - training loss: 0.2889, validation loss: 0.1313
2024-05-23 20:02:46 [INFO]: Epoch 110 - training loss: 0.2877, validation loss: 0.1308
2024-05-23 20:02:48 [INFO]: Epoch 111 - training loss: 0.2872, validation loss: 0.1305
2024-05-23 20:02:50 [INFO]: Epoch 112 - training loss: 0.2873, validation loss: 0.1297
2024-05-23 20:02:53 [INFO]: Epoch 113 - training loss: 0.2865, validation loss: 0.1294
2024-05-23 20:02:55 [INFO]: Epoch 114 - training loss: 0.2866, validation loss: 0.1289
2024-05-23 20:02:57 [INFO]: Epoch 115 - training loss: 0.2857, validation loss: 0.1284
2024-05-23 20:02:59 [INFO]: Epoch 116 - training loss: 0.2849, validation loss: 0.1279
2024-05-23 20:03:02 [INFO]: Epoch 117 - training loss: 0.2843, validation loss: 0.1274
2024-05-23 20:03:04 [INFO]: Epoch 118 - training loss: 0.2839, validation loss: 0.1270
2024-05-23 20:03:06 [INFO]: Epoch 119 - training loss: 0.2837, validation loss: 0.1266
2024-05-23 20:03:08 [INFO]: Epoch 120 - training loss: 0.2833, validation loss: 0.1263
2024-05-23 20:03:11 [INFO]: Epoch 121 - training loss: 0.2826, validation loss: 0.1255
2024-05-23 20:03:13 [INFO]: Epoch 122 - training loss: 0.2815, validation loss: 0.1252
2024-05-23 20:03:15 [INFO]: Epoch 123 - training loss: 0.2812, validation loss: 0.1247
2024-05-23 20:03:17 [INFO]: Epoch 124 - training loss: 0.2808, validation loss: 0.1245
2024-05-23 20:03:19 [INFO]: Epoch 125 - training loss: 0.2803, validation loss: 0.1241
2024-05-23 20:03:22 [INFO]: Epoch 126 - training loss: 0.2796, validation loss: 0.1236
2024-05-23 20:03:24 [INFO]: Epoch 127 - training loss: 0.2802, validation loss: 0.1232
2024-05-23 20:03:26 [INFO]: Epoch 128 - training loss: 0.2788, validation loss: 0.1226
2024-05-23 20:03:28 [INFO]: Epoch 129 - training loss: 0.2785, validation loss: 0.1224
2024-05-23 20:03:31 [INFO]: Epoch 130 - training loss: 0.2781, validation loss: 0.1218
2024-05-23 20:03:33 [INFO]: Epoch 131 - training loss: 0.2776, validation loss: 0.1216
2024-05-23 20:03:35 [INFO]: Epoch 132 - training loss: 0.2772, validation loss: 0.1212
2024-05-23 20:03:37 [INFO]: Epoch 133 - training loss: 0.2769, validation loss: 0.1209
2024-05-23 20:03:39 [INFO]: Epoch 134 - training loss: 0.2769, validation loss: 0.1206
2024-05-23 20:03:42 [INFO]: Epoch 135 - training loss: 0.2764, validation loss: 0.1202
2024-05-23 20:03:44 [INFO]: Epoch 136 - training loss: 0.2756, validation loss: 0.1197
2024-05-23 20:03:46 [INFO]: Epoch 137 - training loss: 0.2758, validation loss: 0.1195
2024-05-23 20:03:48 [INFO]: Epoch 138 - training loss: 0.2752, validation loss: 0.1191
2024-05-23 20:03:51 [INFO]: Epoch 139 - training loss: 0.2748, validation loss: 0.1185
2024-05-23 20:03:53 [INFO]: Epoch 140 - training loss: 0.2740, validation loss: 0.1184
2024-05-23 20:03:55 [INFO]: Epoch 141 - training loss: 0.2743, validation loss: 0.1181
2024-05-23 20:03:57 [INFO]: Epoch 142 - training loss: 0.2732, validation loss: 0.1176
2024-05-23 20:03:59 [INFO]: Epoch 143 - training loss: 0.2737, validation loss: 0.1173
2024-05-23 20:04:02 [INFO]: Epoch 144 - training loss: 0.2730, validation loss: 0.1169
2024-05-23 20:04:04 [INFO]: Epoch 145 - training loss: 0.2725, validation loss: 0.1167
2024-05-23 20:04:06 [INFO]: Epoch 146 - training loss: 0.2717, validation loss: 0.1162
2024-05-23 20:04:08 [INFO]: Epoch 147 - training loss: 0.2712, validation loss: 0.1161
2024-05-23 20:04:11 [INFO]: Epoch 148 - training loss: 0.2713, validation loss: 0.1157
2024-05-23 20:04:13 [INFO]: Epoch 149 - training loss: 0.2704, validation loss: 0.1155
2024-05-23 20:04:15 [INFO]: Epoch 150 - training loss: 0.2707, validation loss: 0.1151
2024-05-23 20:04:17 [INFO]: Epoch 151 - training loss: 0.2703, validation loss: 0.1147
2024-05-23 20:04:19 [INFO]: Epoch 152 - training loss: 0.2701, validation loss: 0.1144
2024-05-23 20:04:22 [INFO]: Epoch 153 - training loss: 0.2692, validation loss: 0.1142
2024-05-23 20:04:24 [INFO]: Epoch 154 - training loss: 0.2690, validation loss: 0.1137
2024-05-23 20:04:26 [INFO]: Epoch 155 - training loss: 0.2688, validation loss: 0.1135
2024-05-23 20:04:28 [INFO]: Epoch 156 - training loss: 0.2678, validation loss: 0.1133
2024-05-23 20:04:30 [INFO]: Epoch 157 - training loss: 0.2682, validation loss: 0.1131
2024-05-23 20:04:33 [INFO]: Epoch 158 - training loss: 0.2679, validation loss: 0.1127
2024-05-23 20:04:35 [INFO]: Epoch 159 - training loss: 0.2676, validation loss: 0.1122
2024-05-23 20:04:37 [INFO]: Epoch 160 - training loss: 0.2673, validation loss: 0.1120
2024-05-23 20:04:39 [INFO]: Epoch 161 - training loss: 0.2664, validation loss: 0.1120
2024-05-23 20:04:42 [INFO]: Epoch 162 - training loss: 0.2677, validation loss: 0.1117
2024-05-23 20:04:44 [INFO]: Epoch 163 - training loss: 0.2666, validation loss: 0.1113
2024-05-23 20:04:46 [INFO]: Epoch 164 - training loss: 0.2661, validation loss: 0.1109
2024-05-23 20:04:48 [INFO]: Epoch 165 - training loss: 0.2654, validation loss: 0.1107
2024-05-23 20:04:50 [INFO]: Epoch 166 - training loss: 0.2655, validation loss: 0.1105
2024-05-23 20:04:53 [INFO]: Epoch 167 - training loss: 0.2658, validation loss: 0.1103
2024-05-23 20:04:55 [INFO]: Epoch 168 - training loss: 0.2648, validation loss: 0.1097
2024-05-23 20:04:57 [INFO]: Epoch 169 - training loss: 0.2648, validation loss: 0.1097
2024-05-23 20:04:59 [INFO]: Epoch 170 - training loss: 0.2646, validation loss: 0.1094
2024-05-23 20:05:01 [INFO]: Epoch 171 - training loss: 0.2640, validation loss: 0.1093
2024-05-23 20:05:04 [INFO]: Epoch 172 - training loss: 0.2634, validation loss: 0.1089
2024-05-23 20:05:06 [INFO]: Epoch 173 - training loss: 0.2638, validation loss: 0.1087
2024-05-23 20:05:08 [INFO]: Epoch 174 - training loss: 0.2632, validation loss: 0.1084
2024-05-23 20:05:10 [INFO]: Epoch 175 - training loss: 0.2627, validation loss: 0.1082
2024-05-23 20:05:13 [INFO]: Epoch 176 - training loss: 0.2631, validation loss: 0.1080
2024-05-23 20:05:15 [INFO]: Epoch 177 - training loss: 0.2625, validation loss: 0.1079
2024-05-23 20:05:17 [INFO]: Epoch 178 - training loss: 0.2623, validation loss: 0.1074
2024-05-23 20:05:19 [INFO]: Epoch 179 - training loss: 0.2625, validation loss: 0.1075
2024-05-23 20:05:22 [INFO]: Epoch 180 - training loss: 0.2613, validation loss: 0.1073
2024-05-23 20:05:24 [INFO]: Epoch 181 - training loss: 0.2609, validation loss: 0.1070
2024-05-23 20:05:26 [INFO]: Epoch 182 - training loss: 0.2609, validation loss: 0.1067
2024-05-23 20:05:28 [INFO]: Epoch 183 - training loss: 0.2606, validation loss: 0.1065
2024-05-23 20:05:30 [INFO]: Epoch 184 - training loss: 0.2600, validation loss: 0.1064
2024-05-23 20:05:33 [INFO]: Epoch 185 - training loss: 0.2605, validation loss: 0.1061
2024-05-23 20:05:35 [INFO]: Epoch 186 - training loss: 0.2601, validation loss: 0.1059
2024-05-23 20:05:37 [INFO]: Epoch 187 - training loss: 0.2601, validation loss: 0.1056
2024-05-23 20:05:39 [INFO]: Epoch 188 - training loss: 0.2593, validation loss: 0.1054
2024-05-23 20:05:42 [INFO]: Epoch 189 - training loss: 0.2595, validation loss: 0.1053
2024-05-23 20:05:44 [INFO]: Epoch 190 - training loss: 0.2591, validation loss: 0.1049
2024-05-23 20:05:46 [INFO]: Epoch 191 - training loss: 0.2585, validation loss: 0.1048
2024-05-23 20:05:48 [INFO]: Epoch 192 - training loss: 0.2585, validation loss: 0.1047
2024-05-23 20:05:50 [INFO]: Epoch 193 - training loss: 0.2579, validation loss: 0.1046
2024-05-23 20:05:53 [INFO]: Epoch 194 - training loss: 0.2579, validation loss: 0.1043
2024-05-23 20:05:55 [INFO]: Epoch 195 - training loss: 0.2583, validation loss: 0.1042
2024-05-23 20:05:57 [INFO]: Epoch 196 - training loss: 0.2575, validation loss: 0.1038
2024-05-23 20:05:59 [INFO]: Epoch 197 - training loss: 0.2572, validation loss: 0.1038
2024-05-23 20:06:02 [INFO]: Epoch 198 - training loss: 0.2577, validation loss: 0.1036
2024-05-23 20:06:04 [INFO]: Epoch 199 - training loss: 0.2573, validation loss: 0.1031
2024-05-23 20:06:06 [INFO]: Epoch 200 - training loss: 0.2569, validation loss: 0.1030
2024-05-23 20:06:08 [INFO]: Epoch 201 - training loss: 0.2565, validation loss: 0.1030
2024-05-23 20:06:10 [INFO]: Epoch 202 - training loss: 0.2562, validation loss: 0.1027
2024-05-23 20:06:13 [INFO]: Epoch 203 - training loss: 0.2562, validation loss: 0.1025
2024-05-23 20:06:15 [INFO]: Epoch 204 - training loss: 0.2558, validation loss: 0.1026
2024-05-23 20:06:17 [INFO]: Epoch 205 - training loss: 0.2558, validation loss: 0.1023
2024-05-23 20:06:19 [INFO]: Epoch 206 - training loss: 0.2555, validation loss: 0.1021
2024-05-23 20:06:21 [INFO]: Epoch 207 - training loss: 0.2553, validation loss: 0.1019
2024-05-23 20:06:24 [INFO]: Epoch 208 - training loss: 0.2548, validation loss: 0.1018
2024-05-23 20:06:26 [INFO]: Epoch 209 - training loss: 0.2551, validation loss: 0.1015
2024-05-23 20:06:28 [INFO]: Epoch 210 - training loss: 0.2553, validation loss: 0.1013
2024-05-23 20:06:30 [INFO]: Epoch 211 - training loss: 0.2548, validation loss: 0.1011
2024-05-23 20:06:33 [INFO]: Epoch 212 - training loss: 0.2540, validation loss: 0.1009
2024-05-23 20:06:35 [INFO]: Epoch 213 - training loss: 0.2538, validation loss: 0.1010
2024-05-23 20:06:37 [INFO]: Epoch 214 - training loss: 0.2537, validation loss: 0.1007
2024-05-23 20:06:39 [INFO]: Epoch 215 - training loss: 0.2532, validation loss: 0.1005
2024-05-23 20:06:41 [INFO]: Epoch 216 - training loss: 0.2534, validation loss: 0.1004
2024-05-23 20:06:44 [INFO]: Epoch 217 - training loss: 0.2534, validation loss: 0.1002
2024-05-23 20:06:46 [INFO]: Epoch 218 - training loss: 0.2532, validation loss: 0.1000
2024-05-23 20:06:48 [INFO]: Epoch 219 - training loss: 0.2530, validation loss: 0.1000
2024-05-23 20:06:50 [INFO]: Epoch 220 - training loss: 0.2535, validation loss: 0.0998
2024-05-23 20:06:52 [INFO]: Epoch 221 - training loss: 0.2524, validation loss: 0.0996
2024-05-23 20:06:55 [INFO]: Epoch 222 - training loss: 0.2526, validation loss: 0.0993
2024-05-23 20:06:57 [INFO]: Epoch 223 - training loss: 0.2521, validation loss: 0.0993
2024-05-23 20:06:59 [INFO]: Epoch 224 - training loss: 0.2521, validation loss: 0.0990
2024-05-23 20:07:01 [INFO]: Epoch 225 - training loss: 0.2520, validation loss: 0.0989
2024-05-23 20:07:04 [INFO]: Epoch 226 - training loss: 0.2520, validation loss: 0.0987
2024-05-23 20:07:06 [INFO]: Epoch 227 - training loss: 0.2513, validation loss: 0.0985
2024-05-23 20:07:08 [INFO]: Epoch 228 - training loss: 0.2514, validation loss: 0.0985
2024-05-23 20:07:10 [INFO]: Epoch 229 - training loss: 0.2510, validation loss: 0.0984
2024-05-23 20:07:13 [INFO]: Epoch 230 - training loss: 0.2510, validation loss: 0.0982
2024-05-23 20:07:15 [INFO]: Epoch 231 - training loss: 0.2507, validation loss: 0.0981
2024-05-23 20:07:17 [INFO]: Epoch 232 - training loss: 0.2504, validation loss: 0.0979
2024-05-23 20:07:19 [INFO]: Epoch 233 - training loss: 0.2503, validation loss: 0.0978
2024-05-23 20:07:21 [INFO]: Epoch 234 - training loss: 0.2506, validation loss: 0.0976
2024-05-23 20:07:24 [INFO]: Epoch 235 - training loss: 0.2500, validation loss: 0.0975
2024-05-23 20:07:26 [INFO]: Epoch 236 - training loss: 0.2494, validation loss: 0.0973
2024-05-23 20:07:28 [INFO]: Epoch 237 - training loss: 0.2497, validation loss: 0.0972
2024-05-23 20:07:30 [INFO]: Epoch 238 - training loss: 0.2492, validation loss: 0.0970
2024-05-23 20:07:32 [INFO]: Epoch 239 - training loss: 0.2491, validation loss: 0.0971
2024-05-23 20:07:35 [INFO]: Epoch 240 - training loss: 0.2493, validation loss: 0.0969
2024-05-23 20:07:37 [INFO]: Epoch 241 - training loss: 0.2498, validation loss: 0.0968
2024-05-23 20:07:39 [INFO]: Epoch 242 - training loss: 0.2490, validation loss: 0.0966
2024-05-23 20:07:41 [INFO]: Epoch 243 - training loss: 0.2486, validation loss: 0.0964
2024-05-23 20:07:43 [INFO]: Epoch 244 - training loss: 0.2486, validation loss: 0.0964
2024-05-23 20:07:46 [INFO]: Epoch 245 - training loss: 0.2482, validation loss: 0.0961
2024-05-23 20:07:48 [INFO]: Epoch 246 - training loss: 0.2483, validation loss: 0.0960
2024-05-23 20:07:50 [INFO]: Epoch 247 - training loss: 0.2478, validation loss: 0.0958
2024-05-23 20:07:52 [INFO]: Epoch 248 - training loss: 0.2482, validation loss: 0.0960
2024-05-23 20:07:55 [INFO]: Epoch 249 - training loss: 0.2474, validation loss: 0.0959
2024-05-23 20:07:57 [INFO]: Epoch 250 - training loss: 0.2482, validation loss: 0.0957
2024-05-23 20:07:59 [INFO]: Epoch 251 - training loss: 0.2475, validation loss: 0.0958
2024-05-23 20:08:01 [INFO]: Epoch 252 - training loss: 0.2474, validation loss: 0.0956
2024-05-23 20:08:03 [INFO]: Epoch 253 - training loss: 0.2476, validation loss: 0.0952
2024-05-23 20:08:06 [INFO]: Epoch 254 - training loss: 0.2470, validation loss: 0.0954
2024-05-23 20:08:08 [INFO]: Epoch 255 - training loss: 0.2471, validation loss: 0.0950
2024-05-23 20:08:10 [INFO]: Epoch 256 - training loss: 0.2463, validation loss: 0.0949
2024-05-23 20:08:12 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0949
2024-05-23 20:08:14 [INFO]: Epoch 258 - training loss: 0.2464, validation loss: 0.0946
2024-05-23 20:08:17 [INFO]: Epoch 259 - training loss: 0.2463, validation loss: 0.0947
2024-05-23 20:08:19 [INFO]: Epoch 260 - training loss: 0.2458, validation loss: 0.0946
2024-05-23 20:08:21 [INFO]: Epoch 261 - training loss: 0.2460, validation loss: 0.0946
2024-05-23 20:08:23 [INFO]: Epoch 262 - training loss: 0.2461, validation loss: 0.0945
2024-05-23 20:08:25 [INFO]: Epoch 263 - training loss: 0.2452, validation loss: 0.0944
2024-05-23 20:08:28 [INFO]: Epoch 264 - training loss: 0.2455, validation loss: 0.0944
2024-05-23 20:08:30 [INFO]: Epoch 265 - training loss: 0.2453, validation loss: 0.0941
2024-05-23 20:08:32 [INFO]: Epoch 266 - training loss: 0.2457, validation loss: 0.0940
2024-05-23 20:08:34 [INFO]: Epoch 267 - training loss: 0.2451, validation loss: 0.0940
2024-05-23 20:08:37 [INFO]: Epoch 268 - training loss: 0.2455, validation loss: 0.0937
2024-05-23 20:08:39 [INFO]: Epoch 269 - training loss: 0.2443, validation loss: 0.0939
2024-05-23 20:08:41 [INFO]: Epoch 270 - training loss: 0.2446, validation loss: 0.0936
2024-05-23 20:08:43 [INFO]: Epoch 271 - training loss: 0.2446, validation loss: 0.0935
2024-05-23 20:08:46 [INFO]: Epoch 272 - training loss: 0.2442, validation loss: 0.0936
2024-05-23 20:08:48 [INFO]: Epoch 273 - training loss: 0.2437, validation loss: 0.0932
2024-05-23 20:08:50 [INFO]: Epoch 274 - training loss: 0.2449, validation loss: 0.0933
2024-05-23 20:08:52 [INFO]: Epoch 275 - training loss: 0.2436, validation loss: 0.0932
2024-05-23 20:08:54 [INFO]: Epoch 276 - training loss: 0.2441, validation loss: 0.0931
2024-05-23 20:08:57 [INFO]: Epoch 277 - training loss: 0.2435, validation loss: 0.0932
2024-05-23 20:08:59 [INFO]: Epoch 278 - training loss: 0.2433, validation loss: 0.0928
2024-05-23 20:09:01 [INFO]: Epoch 279 - training loss: 0.2438, validation loss: 0.0929
2024-05-23 20:09:03 [INFO]: Epoch 280 - training loss: 0.2433, validation loss: 0.0928
2024-05-23 20:09:05 [INFO]: Epoch 281 - training loss: 0.2429, validation loss: 0.0927
2024-05-23 20:09:08 [INFO]: Epoch 282 - training loss: 0.2431, validation loss: 0.0925
2024-05-23 20:09:10 [INFO]: Epoch 283 - training loss: 0.2427, validation loss: 0.0924
2024-05-23 20:09:12 [INFO]: Epoch 284 - training loss: 0.2423, validation loss: 0.0925
2024-05-23 20:09:14 [INFO]: Epoch 285 - training loss: 0.2425, validation loss: 0.0925
2024-05-23 20:09:16 [INFO]: Epoch 286 - training loss: 0.2422, validation loss: 0.0923
2024-05-23 20:09:19 [INFO]: Epoch 287 - training loss: 0.2425, validation loss: 0.0923
2024-05-23 20:09:21 [INFO]: Epoch 288 - training loss: 0.2427, validation loss: 0.0922
2024-05-23 20:09:23 [INFO]: Epoch 289 - training loss: 0.2424, validation loss: 0.0921
2024-05-23 20:09:25 [INFO]: Epoch 290 - training loss: 0.2421, validation loss: 0.0920
2024-05-23 20:09:28 [INFO]: Epoch 291 - training loss: 0.2418, validation loss: 0.0921
2024-05-23 20:09:30 [INFO]: Epoch 292 - training loss: 0.2420, validation loss: 0.0918
2024-05-23 20:09:32 [INFO]: Epoch 293 - training loss: 0.2416, validation loss: 0.0919
2024-05-23 20:09:34 [INFO]: Epoch 294 - training loss: 0.2413, validation loss: 0.0917
2024-05-23 20:09:36 [INFO]: Epoch 295 - training loss: 0.2411, validation loss: 0.0916
2024-05-23 20:09:39 [INFO]: Epoch 296 - training loss: 0.2411, validation loss: 0.0918
2024-05-23 20:09:41 [INFO]: Epoch 297 - training loss: 0.2411, validation loss: 0.0914
2024-05-23 20:09:43 [INFO]: Epoch 298 - training loss: 0.2410, validation loss: 0.0913
2024-05-23 20:09:45 [INFO]: Epoch 299 - training loss: 0.2407, validation loss: 0.0913
2024-05-23 20:09:48 [INFO]: Epoch 300 - training loss: 0.2410, validation loss: 0.0915
2024-05-23 20:09:48 [INFO]: Finished training. The best model is from epoch#299.
2024-05-23 20:09:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240523_T195839/BRITS.pypots
2024-05-23 20:09:48 [INFO]: BRITS on Air-Quality: MAE=0.1416, MSE=0.1336
2024-05-23 20:09:48 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-23 20:09:48 [INFO]: Using the given device: cuda:0
2024-05-23 20:09:48 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948
2024-05-23 20:09:48 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/tensorboard
2024-05-23 20:09:48 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 20:09:52 [INFO]: Epoch 001 - training loss: 1.5012, validation loss: 0.8145
2024-05-23 20:09:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch1_loss0.814495387673378.pypots
2024-05-23 20:09:55 [INFO]: Epoch 002 - training loss: 1.0675, validation loss: 0.7571
2024-05-23 20:09:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch2_loss0.7570705205202103.pypots
2024-05-23 20:09:58 [INFO]: Epoch 003 - training loss: 0.9708, validation loss: 0.7353
2024-05-23 20:09:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch3_loss0.7353498607873916.pypots
2024-05-23 20:10:01 [INFO]: Epoch 004 - training loss: 0.9497, validation loss: 0.7236
2024-05-23 20:10:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch4_loss0.7236348122358323.pypots
2024-05-23 20:10:04 [INFO]: Epoch 005 - training loss: 0.9391, validation loss: 0.7139
2024-05-23 20:10:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch5_loss0.7139070510864258.pypots
2024-05-23 20:10:07 [INFO]: Epoch 006 - training loss: 0.9127, validation loss: 0.7081
2024-05-23 20:10:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch6_loss0.7081230610609055.pypots
2024-05-23 20:10:10 [INFO]: Epoch 007 - training loss: 0.9203, validation loss: 0.7037
2024-05-23 20:10:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch7_loss0.7037410020828248.pypots
2024-05-23 20:10:13 [INFO]: Epoch 008 - training loss: 0.9192, validation loss: 0.6998
2024-05-23 20:10:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch8_loss0.699841657280922.pypots
2024-05-23 20:10:16 [INFO]: Epoch 009 - training loss: 0.9189, validation loss: 0.6967
2024-05-23 20:10:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch9_loss0.6967216014862061.pypots
2024-05-23 20:10:19 [INFO]: Epoch 010 - training loss: 0.9168, validation loss: 0.6953
2024-05-23 20:10:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch10_loss0.6952548682689667.pypots
2024-05-23 20:10:22 [INFO]: Epoch 011 - training loss: 0.8939, validation loss: 0.6919
2024-05-23 20:10:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch11_loss0.6918994814157486.pypots
2024-05-23 20:10:25 [INFO]: Epoch 012 - training loss: 0.8900, validation loss: 0.6911
2024-05-23 20:10:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch12_loss0.6911336004734039.pypots
2024-05-23 20:10:28 [INFO]: Epoch 013 - training loss: 0.8829, validation loss: 0.6892
2024-05-23 20:10:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch13_loss0.6892396718263626.pypots
2024-05-23 20:10:31 [INFO]: Epoch 014 - training loss: 0.8707, validation loss: 0.6896
2024-05-23 20:10:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch14_loss0.6896414518356323.pypots
2024-05-23 20:10:34 [INFO]: Epoch 015 - training loss: 0.8842, validation loss: 0.6886
2024-05-23 20:10:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch15_loss0.6885582506656647.pypots
2024-05-23 20:10:37 [INFO]: Epoch 016 - training loss: 0.8677, validation loss: 0.6870
2024-05-23 20:10:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch16_loss0.6869943529367447.pypots
2024-05-23 20:10:41 [INFO]: Epoch 017 - training loss: 0.8730, validation loss: 0.6878
2024-05-23 20:10:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch17_loss0.6878440469503403.pypots
2024-05-23 20:10:44 [INFO]: Epoch 018 - training loss: 0.8849, validation loss: 0.6872
2024-05-23 20:10:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch18_loss0.687194150686264.pypots
2024-05-23 20:10:47 [INFO]: Epoch 019 - training loss: 0.8547, validation loss: 0.6869
2024-05-23 20:10:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch19_loss0.6869447559118271.pypots
2024-05-23 20:10:50 [INFO]: Epoch 020 - training loss: 0.8515, validation loss: 0.6871
2024-05-23 20:10:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch20_loss0.6870703369379043.pypots
2024-05-23 20:10:53 [INFO]: Epoch 021 - training loss: 0.8564, validation loss: 0.6850
2024-05-23 20:10:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch21_loss0.6850317895412446.pypots
2024-05-23 20:10:56 [INFO]: Epoch 022 - training loss: 0.8514, validation loss: 0.6854
2024-05-23 20:10:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch22_loss0.685381543636322.pypots
2024-05-23 20:10:59 [INFO]: Epoch 023 - training loss: 0.8540, validation loss: 0.6871
2024-05-23 20:10:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch23_loss0.6871237874031066.pypots
2024-05-23 20:11:02 [INFO]: Epoch 024 - training loss: 0.8436, validation loss: 0.6859
2024-05-23 20:11:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch24_loss0.6858891248703003.pypots
2024-05-23 20:11:05 [INFO]: Epoch 025 - training loss: 0.8777, validation loss: 0.6843
2024-05-23 20:11:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch25_loss0.6843144685029984.pypots
2024-05-23 20:11:08 [INFO]: Epoch 026 - training loss: 0.8519, validation loss: 0.6872
2024-05-23 20:11:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch26_loss0.6871587187051773.pypots
2024-05-23 20:11:11 [INFO]: Epoch 027 - training loss: 0.8510, validation loss: 0.6866
2024-05-23 20:11:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch27_loss0.6866368383169175.pypots
2024-05-23 20:11:14 [INFO]: Epoch 028 - training loss: 0.8361, validation loss: 0.6854
2024-05-23 20:11:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch28_loss0.6854116588830947.pypots
2024-05-23 20:11:17 [INFO]: Epoch 029 - training loss: 0.8328, validation loss: 0.6852
2024-05-23 20:11:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch29_loss0.6851822882890701.pypots
2024-05-23 20:11:20 [INFO]: Epoch 030 - training loss: 0.8462, validation loss: 0.6876
2024-05-23 20:11:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch30_loss0.687565615773201.pypots
2024-05-23 20:11:23 [INFO]: Epoch 031 - training loss: 0.8447, validation loss: 0.6856
2024-05-23 20:11:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch31_loss0.6856180846691131.pypots
2024-05-23 20:11:26 [INFO]: Epoch 032 - training loss: 0.8229, validation loss: 0.6863
2024-05-23 20:11:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch32_loss0.686272257566452.pypots
2024-05-23 20:11:29 [INFO]: Epoch 033 - training loss: 0.8186, validation loss: 0.6867
2024-05-23 20:11:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch33_loss0.6866717576980591.pypots
2024-05-23 20:11:32 [INFO]: Epoch 034 - training loss: 0.8265, validation loss: 0.6860
2024-05-23 20:11:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch34_loss0.686044117808342.pypots
2024-05-23 20:11:35 [INFO]: Epoch 035 - training loss: 0.8163, validation loss: 0.6873
2024-05-23 20:11:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN_epoch35_loss0.68728988468647.pypots
2024-05-23 20:11:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:11:35 [INFO]: Finished training. The best model is from epoch#25.
2024-05-23 20:11:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240523_T200948/MRNN.pypots
2024-05-23 20:11:36 [INFO]: MRNN on Air-Quality: MAE=0.5172, MSE=0.6580
2024-05-23 20:11:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-23 20:11:36 [INFO]: Using the given device: cpu
2024-05-23 20:11:36 [INFO]: LOCF on Air-Quality: MAE=0.2050, MSE=0.3453
2024-05-23 20:11:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-23 20:11:36 [INFO]: Median on Air-Quality: MAE=0.6635, MSE=1.0575
2024-05-23 20:11:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-23 20:11:36 [INFO]: Mean on Air-Quality: MAE=0.6949, MSE=0.9966
2024-05-23 20:11:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-23 20:11:36 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-23 20:11:36 [INFO]: Using the given device: cuda:0
2024-05-23 20:11:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240523_T201136
2024-05-23 20:11:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240523_T201136/tensorboard
2024-05-23 20:11:36 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 20:11:37 [INFO]: Epoch 001 - training loss: 1.0411, validation loss: 0.5326
2024-05-23 20:11:37 [INFO]: Epoch 002 - training loss: 0.7558, validation loss: 0.4076
2024-05-23 20:11:38 [INFO]: Epoch 003 - training loss: 0.6470, validation loss: 0.3301
2024-05-23 20:11:39 [INFO]: Epoch 004 - training loss: 0.5740, validation loss: 0.2875
2024-05-23 20:11:39 [INFO]: Epoch 005 - training loss: 0.5207, validation loss: 0.2643
2024-05-23 20:11:40 [INFO]: Epoch 006 - training loss: 0.4827, validation loss: 0.2480
2024-05-23 20:11:40 [INFO]: Epoch 007 - training loss: 0.4533, validation loss: 0.2357
2024-05-23 20:11:41 [INFO]: Epoch 008 - training loss: 0.4340, validation loss: 0.2265
2024-05-23 20:11:42 [INFO]: Epoch 009 - training loss: 0.4201, validation loss: 0.2198
2024-05-23 20:11:42 [INFO]: Epoch 010 - training loss: 0.4060, validation loss: 0.2144
2024-05-23 20:11:43 [INFO]: Epoch 011 - training loss: 0.3954, validation loss: 0.2096
2024-05-23 20:11:43 [INFO]: Epoch 012 - training loss: 0.3863, validation loss: 0.2052
2024-05-23 20:11:44 [INFO]: Epoch 013 - training loss: 0.3789, validation loss: 0.2028
2024-05-23 20:11:44 [INFO]: Epoch 014 - training loss: 0.3711, validation loss: 0.1990
2024-05-23 20:11:45 [INFO]: Epoch 015 - training loss: 0.3633, validation loss: 0.1953
2024-05-23 20:11:46 [INFO]: Epoch 016 - training loss: 0.3582, validation loss: 0.1932
2024-05-23 20:11:46 [INFO]: Epoch 017 - training loss: 0.3527, validation loss: 0.1930
2024-05-23 20:11:47 [INFO]: Epoch 018 - training loss: 0.3472, validation loss: 0.1885
2024-05-23 20:11:47 [INFO]: Epoch 019 - training loss: 0.3417, validation loss: 0.1861
2024-05-23 20:11:48 [INFO]: Epoch 020 - training loss: 0.3380, validation loss: 0.1845
2024-05-23 20:11:49 [INFO]: Epoch 021 - training loss: 0.3349, validation loss: 0.1830
2024-05-23 20:11:49 [INFO]: Epoch 022 - training loss: 0.3296, validation loss: 0.1800
2024-05-23 20:11:50 [INFO]: Epoch 023 - training loss: 0.3254, validation loss: 0.1786
2024-05-23 20:11:50 [INFO]: Epoch 024 - training loss: 0.3239, validation loss: 0.1771
2024-05-23 20:11:51 [INFO]: Epoch 025 - training loss: 0.3190, validation loss: 0.1767
2024-05-23 20:11:51 [INFO]: Epoch 026 - training loss: 0.3168, validation loss: 0.1740
2024-05-23 20:11:52 [INFO]: Epoch 027 - training loss: 0.3148, validation loss: 0.1727
2024-05-23 20:11:53 [INFO]: Epoch 028 - training loss: 0.3123, validation loss: 0.1724
2024-05-23 20:11:53 [INFO]: Epoch 029 - training loss: 0.3100, validation loss: 0.1703
2024-05-23 20:11:54 [INFO]: Epoch 030 - training loss: 0.3077, validation loss: 0.1693
2024-05-23 20:11:54 [INFO]: Epoch 031 - training loss: 0.3051, validation loss: 0.1683
2024-05-23 20:11:55 [INFO]: Epoch 032 - training loss: 0.3023, validation loss: 0.1668
2024-05-23 20:11:56 [INFO]: Epoch 033 - training loss: 0.3004, validation loss: 0.1668
2024-05-23 20:11:56 [INFO]: Epoch 034 - training loss: 0.2994, validation loss: 0.1644
2024-05-23 20:11:57 [INFO]: Epoch 035 - training loss: 0.2961, validation loss: 0.1648
2024-05-23 20:11:57 [INFO]: Epoch 036 - training loss: 0.2940, validation loss: 0.1637
2024-05-23 20:11:58 [INFO]: Epoch 037 - training loss: 0.2913, validation loss: 0.1621
2024-05-23 20:11:58 [INFO]: Epoch 038 - training loss: 0.2892, validation loss: 0.1613
2024-05-23 20:11:59 [INFO]: Epoch 039 - training loss: 0.2884, validation loss: 0.1605
2024-05-23 20:12:00 [INFO]: Epoch 040 - training loss: 0.2878, validation loss: 0.1591
2024-05-23 20:12:00 [INFO]: Epoch 041 - training loss: 0.2852, validation loss: 0.1588
2024-05-23 20:12:01 [INFO]: Epoch 042 - training loss: 0.2833, validation loss: 0.1572
2024-05-23 20:12:01 [INFO]: Epoch 043 - training loss: 0.2812, validation loss: 0.1567
2024-05-23 20:12:02 [INFO]: Epoch 044 - training loss: 0.2806, validation loss: 0.1565
2024-05-23 20:12:03 [INFO]: Epoch 045 - training loss: 0.2779, validation loss: 0.1553
2024-05-23 20:12:03 [INFO]: Epoch 046 - training loss: 0.2762, validation loss: 0.1545
2024-05-23 20:12:04 [INFO]: Epoch 047 - training loss: 0.2751, validation loss: 0.1542
2024-05-23 20:12:04 [INFO]: Epoch 048 - training loss: 0.2750, validation loss: 0.1532
2024-05-23 20:12:05 [INFO]: Epoch 049 - training loss: 0.2750, validation loss: 0.1527
2024-05-23 20:12:05 [INFO]: Epoch 050 - training loss: 0.2707, validation loss: 0.1512
2024-05-23 20:12:06 [INFO]: Epoch 051 - training loss: 0.2690, validation loss: 0.1499
2024-05-23 20:12:07 [INFO]: Epoch 052 - training loss: 0.2671, validation loss: 0.1486
2024-05-23 20:12:07 [INFO]: Epoch 053 - training loss: 0.2660, validation loss: 0.1490
2024-05-23 20:12:08 [INFO]: Epoch 054 - training loss: 0.2646, validation loss: 0.1481
2024-05-23 20:12:08 [INFO]: Epoch 055 - training loss: 0.2637, validation loss: 0.1475
2024-05-23 20:12:09 [INFO]: Epoch 056 - training loss: 0.2630, validation loss: 0.1478
2024-05-23 20:12:10 [INFO]: Epoch 057 - training loss: 0.2614, validation loss: 0.1454
2024-05-23 20:12:10 [INFO]: Epoch 058 - training loss: 0.2588, validation loss: 0.1457
2024-05-23 20:12:11 [INFO]: Epoch 059 - training loss: 0.2571, validation loss: 0.1455
2024-05-23 20:12:11 [INFO]: Epoch 060 - training loss: 0.2554, validation loss: 0.1448
2024-05-23 20:12:12 [INFO]: Epoch 061 - training loss: 0.2549, validation loss: 0.1428
2024-05-23 20:12:13 [INFO]: Epoch 062 - training loss: 0.2534, validation loss: 0.1433
2024-05-23 20:12:13 [INFO]: Epoch 063 - training loss: 0.2523, validation loss: 0.1431
2024-05-23 20:12:14 [INFO]: Epoch 064 - training loss: 0.2518, validation loss: 0.1422
2024-05-23 20:12:14 [INFO]: Epoch 065 - training loss: 0.2497, validation loss: 0.1414
2024-05-23 20:12:15 [INFO]: Epoch 066 - training loss: 0.2482, validation loss: 0.1418
2024-05-23 20:12:15 [INFO]: Epoch 067 - training loss: 0.2467, validation loss: 0.1403
2024-05-23 20:12:16 [INFO]: Epoch 068 - training loss: 0.2471, validation loss: 0.1396
2024-05-23 20:12:17 [INFO]: Epoch 069 - training loss: 0.2444, validation loss: 0.1387
2024-05-23 20:12:17 [INFO]: Epoch 070 - training loss: 0.2444, validation loss: 0.1392
2024-05-23 20:12:18 [INFO]: Epoch 071 - training loss: 0.2421, validation loss: 0.1386
2024-05-23 20:12:18 [INFO]: Epoch 072 - training loss: 0.2412, validation loss: 0.1392
2024-05-23 20:12:19 [INFO]: Epoch 073 - training loss: 0.2408, validation loss: 0.1377
2024-05-23 20:12:20 [INFO]: Epoch 074 - training loss: 0.2415, validation loss: 0.1377
2024-05-23 20:12:20 [INFO]: Epoch 075 - training loss: 0.2385, validation loss: 0.1372
2024-05-23 20:12:21 [INFO]: Epoch 076 - training loss: 0.2366, validation loss: 0.1360
2024-05-23 20:12:21 [INFO]: Epoch 077 - training loss: 0.2353, validation loss: 0.1358
2024-05-23 20:12:22 [INFO]: Epoch 078 - training loss: 0.2356, validation loss: 0.1357
2024-05-23 20:12:22 [INFO]: Epoch 079 - training loss: 0.2337, validation loss: 0.1353
2024-05-23 20:12:23 [INFO]: Epoch 080 - training loss: 0.2342, validation loss: 0.1354
2024-05-23 20:12:24 [INFO]: Epoch 081 - training loss: 0.2330, validation loss: 0.1349
2024-05-23 20:12:24 [INFO]: Epoch 082 - training loss: 0.2308, validation loss: 0.1342
2024-05-23 20:12:25 [INFO]: Epoch 083 - training loss: 0.2310, validation loss: 0.1342
2024-05-23 20:12:25 [INFO]: Epoch 084 - training loss: 0.2298, validation loss: 0.1343
2024-05-23 20:12:26 [INFO]: Epoch 085 - training loss: 0.2290, validation loss: 0.1341
2024-05-23 20:12:27 [INFO]: Epoch 086 - training loss: 0.2280, validation loss: 0.1327
2024-05-23 20:12:27 [INFO]: Epoch 087 - training loss: 0.2270, validation loss: 0.1332
2024-05-23 20:12:28 [INFO]: Epoch 088 - training loss: 0.2257, validation loss: 0.1323
2024-05-23 20:12:28 [INFO]: Epoch 089 - training loss: 0.2255, validation loss: 0.1323
2024-05-23 20:12:29 [INFO]: Epoch 090 - training loss: 0.2247, validation loss: 0.1339
2024-05-23 20:12:29 [INFO]: Epoch 091 - training loss: 0.2259, validation loss: 0.1331
2024-05-23 20:12:30 [INFO]: Epoch 092 - training loss: 0.2240, validation loss: 0.1328
2024-05-23 20:12:31 [INFO]: Epoch 093 - training loss: 0.2238, validation loss: 0.1316
2024-05-23 20:12:31 [INFO]: Epoch 094 - training loss: 0.2224, validation loss: 0.1325
2024-05-23 20:12:32 [INFO]: Epoch 095 - training loss: 0.2226, validation loss: 0.1321
2024-05-23 20:12:32 [INFO]: Epoch 096 - training loss: 0.2210, validation loss: 0.1316
2024-05-23 20:12:33 [INFO]: Epoch 097 - training loss: 0.2199, validation loss: 0.1312
2024-05-23 20:12:34 [INFO]: Epoch 098 - training loss: 0.2194, validation loss: 0.1306
2024-05-23 20:12:34 [INFO]: Epoch 099 - training loss: 0.2180, validation loss: 0.1297
2024-05-23 20:12:35 [INFO]: Epoch 100 - training loss: 0.2178, validation loss: 0.1302
2024-05-23 20:12:35 [INFO]: Epoch 101 - training loss: 0.2167, validation loss: 0.1312
2024-05-23 20:12:36 [INFO]: Epoch 102 - training loss: 0.2167, validation loss: 0.1296
2024-05-23 20:12:36 [INFO]: Epoch 103 - training loss: 0.2155, validation loss: 0.1306
2024-05-23 20:12:37 [INFO]: Epoch 104 - training loss: 0.2147, validation loss: 0.1285
2024-05-23 20:12:38 [INFO]: Epoch 105 - training loss: 0.2171, validation loss: 0.1290
2024-05-23 20:12:38 [INFO]: Epoch 106 - training loss: 0.2162, validation loss: 0.1283
2024-05-23 20:12:39 [INFO]: Epoch 107 - training loss: 0.2143, validation loss: 0.1274
2024-05-23 20:12:39 [INFO]: Epoch 108 - training loss: 0.2131, validation loss: 0.1287
2024-05-23 20:12:40 [INFO]: Epoch 109 - training loss: 0.2121, validation loss: 0.1286
2024-05-23 20:12:41 [INFO]: Epoch 110 - training loss: 0.2129, validation loss: 0.1270
2024-05-23 20:12:41 [INFO]: Epoch 111 - training loss: 0.2114, validation loss: 0.1281
2024-05-23 20:12:42 [INFO]: Epoch 112 - training loss: 0.2103, validation loss: 0.1273
2024-05-23 20:12:42 [INFO]: Epoch 113 - training loss: 0.2108, validation loss: 0.1261
2024-05-23 20:12:43 [INFO]: Epoch 114 - training loss: 0.2098, validation loss: 0.1266
2024-05-23 20:12:43 [INFO]: Epoch 115 - training loss: 0.2088, validation loss: 0.1275
2024-05-23 20:12:44 [INFO]: Epoch 116 - training loss: 0.2080, validation loss: 0.1265
2024-05-23 20:12:45 [INFO]: Epoch 117 - training loss: 0.2073, validation loss: 0.1261
2024-05-23 20:12:45 [INFO]: Epoch 118 - training loss: 0.2088, validation loss: 0.1267
2024-05-23 20:12:46 [INFO]: Epoch 119 - training loss: 0.2067, validation loss: 0.1255
2024-05-23 20:12:46 [INFO]: Epoch 120 - training loss: 0.2070, validation loss: 0.1254
2024-05-23 20:12:47 [INFO]: Epoch 121 - training loss: 0.2068, validation loss: 0.1245
2024-05-23 20:12:48 [INFO]: Epoch 122 - training loss: 0.2050, validation loss: 0.1250
2024-05-23 20:12:48 [INFO]: Epoch 123 - training loss: 0.2039, validation loss: 0.1256
2024-05-23 20:12:49 [INFO]: Epoch 124 - training loss: 0.2036, validation loss: 0.1249
2024-05-23 20:12:49 [INFO]: Epoch 125 - training loss: 0.2031, validation loss: 0.1237
2024-05-23 20:12:50 [INFO]: Epoch 126 - training loss: 0.2035, validation loss: 0.1256
2024-05-23 20:12:50 [INFO]: Epoch 127 - training loss: 0.2028, validation loss: 0.1230
2024-05-23 20:12:51 [INFO]: Epoch 128 - training loss: 0.2027, validation loss: 0.1240
2024-05-23 20:12:52 [INFO]: Epoch 129 - training loss: 0.2012, validation loss: 0.1235
2024-05-23 20:12:52 [INFO]: Epoch 130 - training loss: 0.2006, validation loss: 0.1240
2024-05-23 20:12:53 [INFO]: Epoch 131 - training loss: 0.1999, validation loss: 0.1231
2024-05-23 20:12:53 [INFO]: Epoch 132 - training loss: 0.1987, validation loss: 0.1237
2024-05-23 20:12:54 [INFO]: Epoch 133 - training loss: 0.1999, validation loss: 0.1229
2024-05-23 20:12:55 [INFO]: Epoch 134 - training loss: 0.1987, validation loss: 0.1235
2024-05-23 20:12:55 [INFO]: Epoch 135 - training loss: 0.1979, validation loss: 0.1229
2024-05-23 20:12:56 [INFO]: Epoch 136 - training loss: 0.1975, validation loss: 0.1228
2024-05-23 20:12:56 [INFO]: Epoch 137 - training loss: 0.1975, validation loss: 0.1212
2024-05-23 20:12:57 [INFO]: Epoch 138 - training loss: 0.1966, validation loss: 0.1225
2024-05-23 20:12:57 [INFO]: Epoch 139 - training loss: 0.1968, validation loss: 0.1226
2024-05-23 20:12:58 [INFO]: Epoch 140 - training loss: 0.1965, validation loss: 0.1221
2024-05-23 20:12:59 [INFO]: Epoch 141 - training loss: 0.1960, validation loss: 0.1218
2024-05-23 20:12:59 [INFO]: Epoch 142 - training loss: 0.1957, validation loss: 0.1217
2024-05-23 20:13:00 [INFO]: Epoch 143 - training loss: 0.1952, validation loss: 0.1215
2024-05-23 20:13:00 [INFO]: Epoch 144 - training loss: 0.1964, validation loss: 0.1207
2024-05-23 20:13:01 [INFO]: Epoch 145 - training loss: 0.1942, validation loss: 0.1197
2024-05-23 20:13:02 [INFO]: Epoch 146 - training loss: 0.1938, validation loss: 0.1215
2024-05-23 20:13:02 [INFO]: Epoch 147 - training loss: 0.1945, validation loss: 0.1214
2024-05-23 20:13:03 [INFO]: Epoch 148 - training loss: 0.1934, validation loss: 0.1217
2024-05-23 20:13:03 [INFO]: Epoch 149 - training loss: 0.1921, validation loss: 0.1205
2024-05-23 20:13:04 [INFO]: Epoch 150 - training loss: 0.1912, validation loss: 0.1206
2024-05-23 20:13:05 [INFO]: Epoch 151 - training loss: 0.1916, validation loss: 0.1207
2024-05-23 20:13:05 [INFO]: Epoch 152 - training loss: 0.1922, validation loss: 0.1208
2024-05-23 20:13:06 [INFO]: Epoch 153 - training loss: 0.1933, validation loss: 0.1216
2024-05-23 20:13:06 [INFO]: Epoch 154 - training loss: 0.1915, validation loss: 0.1192
2024-05-23 20:13:07 [INFO]: Epoch 155 - training loss: 0.1900, validation loss: 0.1200
2024-05-23 20:13:07 [INFO]: Epoch 156 - training loss: 0.1890, validation loss: 0.1196
2024-05-23 20:13:08 [INFO]: Epoch 157 - training loss: 0.1910, validation loss: 0.1199
2024-05-23 20:13:09 [INFO]: Epoch 158 - training loss: 0.1897, validation loss: 0.1202
2024-05-23 20:13:09 [INFO]: Epoch 159 - training loss: 0.1890, validation loss: 0.1188
2024-05-23 20:13:10 [INFO]: Epoch 160 - training loss: 0.1878, validation loss: 0.1201
2024-05-23 20:13:10 [INFO]: Epoch 161 - training loss: 0.1882, validation loss: 0.1194
2024-05-23 20:13:11 [INFO]: Epoch 162 - training loss: 0.1868, validation loss: 0.1186
2024-05-23 20:13:12 [INFO]: Epoch 163 - training loss: 0.1858, validation loss: 0.1207
2024-05-23 20:13:12 [INFO]: Epoch 164 - training loss: 0.1882, validation loss: 0.1183
2024-05-23 20:13:13 [INFO]: Epoch 165 - training loss: 0.1878, validation loss: 0.1199
2024-05-23 20:13:13 [INFO]: Epoch 166 - training loss: 0.1875, validation loss: 0.1185
2024-05-23 20:13:14 [INFO]: Epoch 167 - training loss: 0.1861, validation loss: 0.1186
2024-05-23 20:13:14 [INFO]: Epoch 168 - training loss: 0.1849, validation loss: 0.1184
2024-05-23 20:13:15 [INFO]: Epoch 169 - training loss: 0.1849, validation loss: 0.1185
2024-05-23 20:13:16 [INFO]: Epoch 170 - training loss: 0.1842, validation loss: 0.1190
2024-05-23 20:13:16 [INFO]: Epoch 171 - training loss: 0.1833, validation loss: 0.1189
2024-05-23 20:13:17 [INFO]: Epoch 172 - training loss: 0.1840, validation loss: 0.1191
2024-05-23 20:13:17 [INFO]: Epoch 173 - training loss: 0.1827, validation loss: 0.1181
2024-05-23 20:13:18 [INFO]: Epoch 174 - training loss: 0.1828, validation loss: 0.1185
2024-05-23 20:13:19 [INFO]: Epoch 175 - training loss: 0.1825, validation loss: 0.1180
2024-05-23 20:13:19 [INFO]: Epoch 176 - training loss: 0.1826, validation loss: 0.1186
2024-05-23 20:13:20 [INFO]: Epoch 177 - training loss: 0.1828, validation loss: 0.1178
2024-05-23 20:13:20 [INFO]: Epoch 178 - training loss: 0.1825, validation loss: 0.1192
2024-05-23 20:13:21 [INFO]: Epoch 179 - training loss: 0.1820, validation loss: 0.1182
2024-05-23 20:13:21 [INFO]: Epoch 180 - training loss: 0.1806, validation loss: 0.1182
2024-05-23 20:13:22 [INFO]: Epoch 181 - training loss: 0.1802, validation loss: 0.1190
2024-05-23 20:13:23 [INFO]: Epoch 182 - training loss: 0.1793, validation loss: 0.1191
2024-05-23 20:13:23 [INFO]: Epoch 183 - training loss: 0.1791, validation loss: 0.1172
2024-05-23 20:13:24 [INFO]: Epoch 184 - training loss: 0.1792, validation loss: 0.1179
2024-05-23 20:13:24 [INFO]: Epoch 185 - training loss: 0.1799, validation loss: 0.1173
2024-05-23 20:13:25 [INFO]: Epoch 186 - training loss: 0.1797, validation loss: 0.1179
2024-05-23 20:13:26 [INFO]: Epoch 187 - training loss: 0.1783, validation loss: 0.1173
2024-05-23 20:13:26 [INFO]: Epoch 188 - training loss: 0.1775, validation loss: 0.1173
2024-05-23 20:13:27 [INFO]: Epoch 189 - training loss: 0.1769, validation loss: 0.1188
2024-05-23 20:13:27 [INFO]: Epoch 190 - training loss: 0.1771, validation loss: 0.1173
2024-05-23 20:13:28 [INFO]: Epoch 191 - training loss: 0.1765, validation loss: 0.1171
2024-05-23 20:13:28 [INFO]: Epoch 192 - training loss: 0.1774, validation loss: 0.1168
2024-05-23 20:13:29 [INFO]: Epoch 193 - training loss: 0.1750, validation loss: 0.1170
2024-05-23 20:13:30 [INFO]: Epoch 194 - training loss: 0.1767, validation loss: 0.1169
2024-05-23 20:13:30 [INFO]: Epoch 195 - training loss: 0.1755, validation loss: 0.1167
2024-05-23 20:13:31 [INFO]: Epoch 196 - training loss: 0.1751, validation loss: 0.1170
2024-05-23 20:13:31 [INFO]: Epoch 197 - training loss: 0.1763, validation loss: 0.1177
2024-05-23 20:13:32 [INFO]: Epoch 198 - training loss: 0.1764, validation loss: 0.1180
2024-05-23 20:13:33 [INFO]: Epoch 199 - training loss: 0.1772, validation loss: 0.1175
2024-05-23 20:13:33 [INFO]: Epoch 200 - training loss: 0.1747, validation loss: 0.1174
2024-05-23 20:13:34 [INFO]: Epoch 201 - training loss: 0.1752, validation loss: 0.1178
2024-05-23 20:13:34 [INFO]: Epoch 202 - training loss: 0.1740, validation loss: 0.1171
2024-05-23 20:13:35 [INFO]: Epoch 203 - training loss: 0.1737, validation loss: 0.1157
2024-05-23 20:13:35 [INFO]: Epoch 204 - training loss: 0.1726, validation loss: 0.1160
2024-05-23 20:13:36 [INFO]: Epoch 205 - training loss: 0.1718, validation loss: 0.1166
2024-05-23 20:13:37 [INFO]: Epoch 206 - training loss: 0.1726, validation loss: 0.1187
2024-05-23 20:13:37 [INFO]: Epoch 207 - training loss: 0.1731, validation loss: 0.1165
2024-05-23 20:13:38 [INFO]: Epoch 208 - training loss: 0.1714, validation loss: 0.1168
2024-05-23 20:13:38 [INFO]: Epoch 209 - training loss: 0.1705, validation loss: 0.1156
2024-05-23 20:13:39 [INFO]: Epoch 210 - training loss: 0.1710, validation loss: 0.1166
2024-05-23 20:13:40 [INFO]: Epoch 211 - training loss: 0.1711, validation loss: 0.1161
2024-05-23 20:13:40 [INFO]: Epoch 212 - training loss: 0.1695, validation loss: 0.1170
2024-05-23 20:13:41 [INFO]: Epoch 213 - training loss: 0.1696, validation loss: 0.1167
2024-05-23 20:13:41 [INFO]: Epoch 214 - training loss: 0.1711, validation loss: 0.1158
2024-05-23 20:13:42 [INFO]: Epoch 215 - training loss: 0.1690, validation loss: 0.1153
2024-05-23 20:13:43 [INFO]: Epoch 216 - training loss: 0.1684, validation loss: 0.1158
2024-05-23 20:13:43 [INFO]: Epoch 217 - training loss: 0.1683, validation loss: 0.1163
2024-05-23 20:13:44 [INFO]: Epoch 218 - training loss: 0.1683, validation loss: 0.1143
2024-05-23 20:13:44 [INFO]: Epoch 219 - training loss: 0.1677, validation loss: 0.1167
2024-05-23 20:13:45 [INFO]: Epoch 220 - training loss: 0.1678, validation loss: 0.1147
2024-05-23 20:13:45 [INFO]: Epoch 221 - training loss: 0.1675, validation loss: 0.1150
2024-05-23 20:13:46 [INFO]: Epoch 222 - training loss: 0.1679, validation loss: 0.1167
2024-05-23 20:13:47 [INFO]: Epoch 223 - training loss: 0.1671, validation loss: 0.1159
2024-05-23 20:13:47 [INFO]: Epoch 224 - training loss: 0.1677, validation loss: 0.1157
2024-05-23 20:13:48 [INFO]: Epoch 225 - training loss: 0.1686, validation loss: 0.1157
2024-05-23 20:13:48 [INFO]: Epoch 226 - training loss: 0.1668, validation loss: 0.1147
2024-05-23 20:13:49 [INFO]: Epoch 227 - training loss: 0.1660, validation loss: 0.1160
2024-05-23 20:13:50 [INFO]: Epoch 228 - training loss: 0.1658, validation loss: 0.1152
2024-05-23 20:13:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:13:50 [INFO]: Finished training. The best model is from epoch#218.
2024-05-23 20:13:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240523_T201136/SAITS.pypots
2024-05-23 20:13:50 [INFO]: SAITS on Air-Quality: MAE=0.1486, MSE=0.1508
2024-05-23 20:13:50 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-23 20:13:50 [INFO]: Using the given device: cuda:0
2024-05-23 20:13:50 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240523_T201350
2024-05-23 20:13:50 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240523_T201350/tensorboard
2024-05-23 20:13:50 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 20:13:50 [INFO]: Epoch 001 - training loss: 0.9154, validation loss: 0.4764
2024-05-23 20:13:50 [INFO]: Epoch 002 - training loss: 0.5590, validation loss: 0.3496
2024-05-23 20:13:51 [INFO]: Epoch 003 - training loss: 0.4663, validation loss: 0.2911
2024-05-23 20:13:51 [INFO]: Epoch 004 - training loss: 0.4190, validation loss: 0.2642
2024-05-23 20:13:51 [INFO]: Epoch 005 - training loss: 0.3895, validation loss: 0.2500
2024-05-23 20:13:51 [INFO]: Epoch 006 - training loss: 0.3714, validation loss: 0.2404
2024-05-23 20:13:51 [INFO]: Epoch 007 - training loss: 0.3545, validation loss: 0.2333
2024-05-23 20:13:52 [INFO]: Epoch 008 - training loss: 0.3418, validation loss: 0.2228
2024-05-23 20:13:52 [INFO]: Epoch 009 - training loss: 0.3293, validation loss: 0.2179
2024-05-23 20:13:52 [INFO]: Epoch 010 - training loss: 0.3242, validation loss: 0.2141
2024-05-23 20:13:52 [INFO]: Epoch 011 - training loss: 0.3168, validation loss: 0.2094
2024-05-23 20:13:53 [INFO]: Epoch 012 - training loss: 0.3129, validation loss: 0.2028
2024-05-23 20:13:53 [INFO]: Epoch 013 - training loss: 0.3045, validation loss: 0.2011
2024-05-23 20:13:53 [INFO]: Epoch 014 - training loss: 0.2990, validation loss: 0.1976
2024-05-23 20:13:53 [INFO]: Epoch 015 - training loss: 0.2939, validation loss: 0.1965
2024-05-23 20:13:54 [INFO]: Epoch 016 - training loss: 0.2919, validation loss: 0.1912
2024-05-23 20:13:54 [INFO]: Epoch 017 - training loss: 0.2870, validation loss: 0.1892
2024-05-23 20:13:54 [INFO]: Epoch 018 - training loss: 0.2838, validation loss: 0.1867
2024-05-23 20:13:54 [INFO]: Epoch 019 - training loss: 0.2805, validation loss: 0.1828
2024-05-23 20:13:54 [INFO]: Epoch 020 - training loss: 0.2773, validation loss: 0.1815
2024-05-23 20:13:55 [INFO]: Epoch 021 - training loss: 0.2741, validation loss: 0.1788
2024-05-23 20:13:55 [INFO]: Epoch 022 - training loss: 0.2718, validation loss: 0.1764
2024-05-23 20:13:55 [INFO]: Epoch 023 - training loss: 0.2692, validation loss: 0.1755
2024-05-23 20:13:55 [INFO]: Epoch 024 - training loss: 0.2666, validation loss: 0.1750
2024-05-23 20:13:56 [INFO]: Epoch 025 - training loss: 0.2630, validation loss: 0.1728
2024-05-23 20:13:56 [INFO]: Epoch 026 - training loss: 0.2609, validation loss: 0.1729
2024-05-23 20:13:56 [INFO]: Epoch 027 - training loss: 0.2577, validation loss: 0.1710
2024-05-23 20:13:56 [INFO]: Epoch 028 - training loss: 0.2567, validation loss: 0.1715
2024-05-23 20:13:57 [INFO]: Epoch 029 - training loss: 0.2563, validation loss: 0.1691
2024-05-23 20:13:57 [INFO]: Epoch 030 - training loss: 0.2573, validation loss: 0.1711
2024-05-23 20:13:57 [INFO]: Epoch 031 - training loss: 0.2628, validation loss: 0.1705
2024-05-23 20:13:57 [INFO]: Epoch 032 - training loss: 0.2503, validation loss: 0.1686
2024-05-23 20:13:58 [INFO]: Epoch 033 - training loss: 0.2488, validation loss: 0.1672
2024-05-23 20:13:58 [INFO]: Epoch 034 - training loss: 0.2450, validation loss: 0.1659
2024-05-23 20:13:58 [INFO]: Epoch 035 - training loss: 0.2437, validation loss: 0.1652
2024-05-23 20:13:58 [INFO]: Epoch 036 - training loss: 0.2440, validation loss: 0.1653
2024-05-23 20:13:58 [INFO]: Epoch 037 - training loss: 0.2406, validation loss: 0.1656
2024-05-23 20:13:59 [INFO]: Epoch 038 - training loss: 0.2403, validation loss: 0.1627
2024-05-23 20:13:59 [INFO]: Epoch 039 - training loss: 0.2393, validation loss: 0.1627
2024-05-23 20:13:59 [INFO]: Epoch 040 - training loss: 0.2354, validation loss: 0.1621
2024-05-23 20:13:59 [INFO]: Epoch 041 - training loss: 0.2356, validation loss: 0.1621
2024-05-23 20:14:00 [INFO]: Epoch 042 - training loss: 0.2337, validation loss: 0.1630
2024-05-23 20:14:00 [INFO]: Epoch 043 - training loss: 0.2340, validation loss: 0.1609
2024-05-23 20:14:00 [INFO]: Epoch 044 - training loss: 0.2304, validation loss: 0.1607
2024-05-23 20:14:00 [INFO]: Epoch 045 - training loss: 0.2289, validation loss: 0.1597
2024-05-23 20:14:01 [INFO]: Epoch 046 - training loss: 0.2283, validation loss: 0.1592
2024-05-23 20:14:01 [INFO]: Epoch 047 - training loss: 0.2263, validation loss: 0.1604
2024-05-23 20:14:01 [INFO]: Epoch 048 - training loss: 0.2281, validation loss: 0.1592
2024-05-23 20:14:01 [INFO]: Epoch 049 - training loss: 0.2244, validation loss: 0.1578
2024-05-23 20:14:01 [INFO]: Epoch 050 - training loss: 0.2219, validation loss: 0.1571
2024-05-23 20:14:02 [INFO]: Epoch 051 - training loss: 0.2209, validation loss: 0.1581
2024-05-23 20:14:02 [INFO]: Epoch 052 - training loss: 0.2220, validation loss: 0.1563
2024-05-23 20:14:02 [INFO]: Epoch 053 - training loss: 0.2210, validation loss: 0.1567
2024-05-23 20:14:02 [INFO]: Epoch 054 - training loss: 0.2188, validation loss: 0.1541
2024-05-23 20:14:03 [INFO]: Epoch 055 - training loss: 0.2163, validation loss: 0.1566
2024-05-23 20:14:03 [INFO]: Epoch 056 - training loss: 0.2158, validation loss: 0.1549
2024-05-23 20:14:03 [INFO]: Epoch 057 - training loss: 0.2153, validation loss: 0.1534
2024-05-23 20:14:03 [INFO]: Epoch 058 - training loss: 0.2131, validation loss: 0.1538
2024-05-23 20:14:04 [INFO]: Epoch 059 - training loss: 0.2121, validation loss: 0.1526
2024-05-23 20:14:04 [INFO]: Epoch 060 - training loss: 0.2102, validation loss: 0.1525
2024-05-23 20:14:04 [INFO]: Epoch 061 - training loss: 0.2089, validation loss: 0.1529
2024-05-23 20:14:04 [INFO]: Epoch 062 - training loss: 0.2084, validation loss: 0.1516
2024-05-23 20:14:05 [INFO]: Epoch 063 - training loss: 0.2077, validation loss: 0.1514
2024-05-23 20:14:05 [INFO]: Epoch 064 - training loss: 0.2056, validation loss: 0.1514
2024-05-23 20:14:05 [INFO]: Epoch 065 - training loss: 0.2047, validation loss: 0.1518
2024-05-23 20:14:05 [INFO]: Epoch 066 - training loss: 0.2037, validation loss: 0.1510
2024-05-23 20:14:05 [INFO]: Epoch 067 - training loss: 0.2054, validation loss: 0.1500
2024-05-23 20:14:06 [INFO]: Epoch 068 - training loss: 0.2050, validation loss: 0.1514
2024-05-23 20:14:06 [INFO]: Epoch 069 - training loss: 0.2059, validation loss: 0.1529
2024-05-23 20:14:06 [INFO]: Epoch 070 - training loss: 0.2041, validation loss: 0.1479
2024-05-23 20:14:06 [INFO]: Epoch 071 - training loss: 0.2016, validation loss: 0.1479
2024-05-23 20:14:07 [INFO]: Epoch 072 - training loss: 0.2015, validation loss: 0.1503
2024-05-23 20:14:07 [INFO]: Epoch 073 - training loss: 0.2014, validation loss: 0.1480
2024-05-23 20:14:07 [INFO]: Epoch 074 - training loss: 0.1997, validation loss: 0.1481
2024-05-23 20:14:07 [INFO]: Epoch 075 - training loss: 0.2018, validation loss: 0.1489
2024-05-23 20:14:08 [INFO]: Epoch 076 - training loss: 0.1970, validation loss: 0.1482
2024-05-23 20:14:08 [INFO]: Epoch 077 - training loss: 0.1965, validation loss: 0.1478
2024-05-23 20:14:08 [INFO]: Epoch 078 - training loss: 0.1948, validation loss: 0.1456
2024-05-23 20:14:08 [INFO]: Epoch 079 - training loss: 0.1946, validation loss: 0.1469
2024-05-23 20:14:08 [INFO]: Epoch 080 - training loss: 0.1996, validation loss: 0.1471
2024-05-23 20:14:09 [INFO]: Epoch 081 - training loss: 0.1938, validation loss: 0.1470
2024-05-23 20:14:09 [INFO]: Epoch 082 - training loss: 0.1915, validation loss: 0.1450
2024-05-23 20:14:09 [INFO]: Epoch 083 - training loss: 0.1897, validation loss: 0.1465
2024-05-23 20:14:09 [INFO]: Epoch 084 - training loss: 0.1885, validation loss: 0.1454
2024-05-23 20:14:10 [INFO]: Epoch 085 - training loss: 0.1882, validation loss: 0.1446
2024-05-23 20:14:10 [INFO]: Epoch 086 - training loss: 0.1860, validation loss: 0.1444
2024-05-23 20:14:10 [INFO]: Epoch 087 - training loss: 0.1853, validation loss: 0.1433
2024-05-23 20:14:10 [INFO]: Epoch 088 - training loss: 0.1859, validation loss: 0.1432
2024-05-23 20:14:11 [INFO]: Epoch 089 - training loss: 0.1867, validation loss: 0.1450
2024-05-23 20:14:11 [INFO]: Epoch 090 - training loss: 0.1845, validation loss: 0.1431
2024-05-23 20:14:11 [INFO]: Epoch 091 - training loss: 0.1839, validation loss: 0.1428
2024-05-23 20:14:11 [INFO]: Epoch 092 - training loss: 0.1842, validation loss: 0.1432
2024-05-23 20:14:12 [INFO]: Epoch 093 - training loss: 0.1832, validation loss: 0.1418
2024-05-23 20:14:12 [INFO]: Epoch 094 - training loss: 0.1808, validation loss: 0.1424
2024-05-23 20:14:12 [INFO]: Epoch 095 - training loss: 0.1823, validation loss: 0.1438
2024-05-23 20:14:12 [INFO]: Epoch 096 - training loss: 0.1861, validation loss: 0.1441
2024-05-23 20:14:12 [INFO]: Epoch 097 - training loss: 0.1889, validation loss: 0.1424
2024-05-23 20:14:13 [INFO]: Epoch 098 - training loss: 0.1815, validation loss: 0.1444
2024-05-23 20:14:13 [INFO]: Epoch 099 - training loss: 0.1794, validation loss: 0.1405
2024-05-23 20:14:13 [INFO]: Epoch 100 - training loss: 0.1780, validation loss: 0.1441
2024-05-23 20:14:13 [INFO]: Epoch 101 - training loss: 0.1780, validation loss: 0.1427
2024-05-23 20:14:14 [INFO]: Epoch 102 - training loss: 0.1784, validation loss: 0.1416
2024-05-23 20:14:14 [INFO]: Epoch 103 - training loss: 0.1779, validation loss: 0.1410
2024-05-23 20:14:14 [INFO]: Epoch 104 - training loss: 0.1765, validation loss: 0.1419
2024-05-23 20:14:14 [INFO]: Epoch 105 - training loss: 0.1761, validation loss: 0.1403
2024-05-23 20:14:15 [INFO]: Epoch 106 - training loss: 0.1766, validation loss: 0.1427
2024-05-23 20:14:15 [INFO]: Epoch 107 - training loss: 0.1775, validation loss: 0.1398
2024-05-23 20:14:15 [INFO]: Epoch 108 - training loss: 0.1745, validation loss: 0.1420
2024-05-23 20:14:15 [INFO]: Epoch 109 - training loss: 0.1728, validation loss: 0.1410
2024-05-23 20:14:15 [INFO]: Epoch 110 - training loss: 0.1716, validation loss: 0.1397
2024-05-23 20:14:16 [INFO]: Epoch 111 - training loss: 0.1704, validation loss: 0.1397
2024-05-23 20:14:16 [INFO]: Epoch 112 - training loss: 0.1710, validation loss: 0.1405
2024-05-23 20:14:16 [INFO]: Epoch 113 - training loss: 0.1718, validation loss: 0.1411
2024-05-23 20:14:16 [INFO]: Epoch 114 - training loss: 0.1698, validation loss: 0.1410
2024-05-23 20:14:17 [INFO]: Epoch 115 - training loss: 0.1683, validation loss: 0.1406
2024-05-23 20:14:17 [INFO]: Epoch 116 - training loss: 0.1682, validation loss: 0.1394
2024-05-23 20:14:17 [INFO]: Epoch 117 - training loss: 0.1707, validation loss: 0.1405
2024-05-23 20:14:17 [INFO]: Epoch 118 - training loss: 0.1697, validation loss: 0.1387
2024-05-23 20:14:18 [INFO]: Epoch 119 - training loss: 0.1676, validation loss: 0.1416
2024-05-23 20:14:18 [INFO]: Epoch 120 - training loss: 0.1677, validation loss: 0.1405
2024-05-23 20:14:18 [INFO]: Epoch 121 - training loss: 0.1653, validation loss: 0.1398
2024-05-23 20:14:18 [INFO]: Epoch 122 - training loss: 0.1643, validation loss: 0.1411
2024-05-23 20:14:18 [INFO]: Epoch 123 - training loss: 0.1632, validation loss: 0.1389
2024-05-23 20:14:19 [INFO]: Epoch 124 - training loss: 0.1639, validation loss: 0.1397
2024-05-23 20:14:19 [INFO]: Epoch 125 - training loss: 0.1651, validation loss: 0.1375
2024-05-23 20:14:19 [INFO]: Epoch 126 - training loss: 0.1636, validation loss: 0.1388
2024-05-23 20:14:19 [INFO]: Epoch 127 - training loss: 0.1646, validation loss: 0.1439
2024-05-23 20:14:20 [INFO]: Epoch 128 - training loss: 0.1632, validation loss: 0.1393
2024-05-23 20:14:20 [INFO]: Epoch 129 - training loss: 0.1617, validation loss: 0.1399
2024-05-23 20:14:20 [INFO]: Epoch 130 - training loss: 0.1624, validation loss: 0.1387
2024-05-23 20:14:20 [INFO]: Epoch 131 - training loss: 0.1604, validation loss: 0.1391
2024-05-23 20:14:21 [INFO]: Epoch 132 - training loss: 0.1596, validation loss: 0.1394
2024-05-23 20:14:21 [INFO]: Epoch 133 - training loss: 0.1612, validation loss: 0.1389
2024-05-23 20:14:21 [INFO]: Epoch 134 - training loss: 0.1597, validation loss: 0.1390
2024-05-23 20:14:21 [INFO]: Epoch 135 - training loss: 0.1572, validation loss: 0.1387
2024-05-23 20:14:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:14:21 [INFO]: Finished training. The best model is from epoch#125.
2024-05-23 20:14:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240523_T201350/Transformer.pypots
2024-05-23 20:14:21 [INFO]: Transformer on Air-Quality: MAE=0.1708, MSE=0.1795
2024-05-23 20:14:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-23 20:14:21 [INFO]: Using the given device: cuda:0
2024-05-23 20:14:21 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240523_T201421
2024-05-23 20:14:21 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240523_T201421/tensorboard
2024-05-23 20:14:22 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 20:14:22 [INFO]: Epoch 001 - training loss: 0.2674, validation loss: 0.2555
2024-05-23 20:14:23 [INFO]: Epoch 002 - training loss: 0.2077, validation loss: 0.2379
2024-05-23 20:14:23 [INFO]: Epoch 003 - training loss: 0.1781, validation loss: 0.2173
2024-05-23 20:14:23 [INFO]: Epoch 004 - training loss: 0.1546, validation loss: 0.2053
2024-05-23 20:14:24 [INFO]: Epoch 005 - training loss: 0.1453, validation loss: 0.1998
2024-05-23 20:14:24 [INFO]: Epoch 006 - training loss: 0.1277, validation loss: 0.1949
2024-05-23 20:14:25 [INFO]: Epoch 007 - training loss: 0.1118, validation loss: 0.1895
2024-05-23 20:14:25 [INFO]: Epoch 008 - training loss: 0.1035, validation loss: 0.1882
2024-05-23 20:14:26 [INFO]: Epoch 009 - training loss: 0.1010, validation loss: 0.1972
2024-05-23 20:14:26 [INFO]: Epoch 010 - training loss: 0.1076, validation loss: 0.1912
2024-05-23 20:14:27 [INFO]: Epoch 011 - training loss: 0.0995, validation loss: 0.1981
2024-05-23 20:14:27 [INFO]: Epoch 012 - training loss: 0.0959, validation loss: 0.1919
2024-05-23 20:14:27 [INFO]: Epoch 013 - training loss: 0.0919, validation loss: 0.1932
2024-05-23 20:14:28 [INFO]: Epoch 014 - training loss: 0.0855, validation loss: 0.1954
2024-05-23 20:14:28 [INFO]: Epoch 015 - training loss: 0.0861, validation loss: 0.1962
2024-05-23 20:14:29 [INFO]: Epoch 016 - training loss: 0.0792, validation loss: 0.1943
2024-05-23 20:14:29 [INFO]: Epoch 017 - training loss: 0.0781, validation loss: 0.1887
2024-05-23 20:14:30 [INFO]: Epoch 018 - training loss: 0.0745, validation loss: 0.1920
2024-05-23 20:14:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:14:30 [INFO]: Finished training. The best model is from epoch#8.
2024-05-23 20:14:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240523_T201421/TimesNet.pypots
2024-05-23 20:14:30 [INFO]: TimesNet on Air-Quality: MAE=0.1747, MSE=0.2214
2024-05-23 20:14:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-23 20:14:30 [INFO]: Using the given device: cuda:0
2024-05-23 20:14:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430
2024-05-23 20:14:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/tensorboard
2024-05-23 20:14:30 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 20:14:46 [INFO]: Epoch 001 - training loss: 0.4830, validation loss: 0.3074
2024-05-23 20:14:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch1_loss0.30744718909263613.pypots
2024-05-23 20:15:03 [INFO]: Epoch 002 - training loss: 0.2714, validation loss: 0.2509
2024-05-23 20:15:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch2_loss0.25086983740329744.pypots
2024-05-23 20:15:19 [INFO]: Epoch 003 - training loss: 0.2388, validation loss: 0.2154
2024-05-23 20:15:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch3_loss0.21540835797786712.pypots
2024-05-23 20:15:35 [INFO]: Epoch 004 - training loss: 0.2165, validation loss: 0.1874
2024-05-23 20:15:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch4_loss0.187423375248909.pypots
2024-05-23 20:15:52 [INFO]: Epoch 005 - training loss: 0.1822, validation loss: 0.1823
2024-05-23 20:15:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch5_loss0.18225986659526824.pypots
2024-05-23 20:16:08 [INFO]: Epoch 006 - training loss: 0.1788, validation loss: 0.1667
2024-05-23 20:16:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch6_loss0.16667474657297135.pypots
2024-05-23 20:16:24 [INFO]: Epoch 007 - training loss: 0.1644, validation loss: 0.1548
2024-05-23 20:16:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch7_loss0.15483006834983826.pypots
2024-05-23 20:16:41 [INFO]: Epoch 008 - training loss: 0.1552, validation loss: 0.1528
2024-05-23 20:16:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch8_loss0.1528188943862915.pypots
2024-05-23 20:16:57 [INFO]: Epoch 009 - training loss: 0.1604, validation loss: 0.1579
2024-05-23 20:16:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch9_loss0.15792907774448395.pypots
2024-05-23 20:17:14 [INFO]: Epoch 010 - training loss: 0.1556, validation loss: 0.1437
2024-05-23 20:17:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch10_loss0.14368463680148125.pypots
2024-05-23 20:17:30 [INFO]: Epoch 011 - training loss: 0.1553, validation loss: 0.1465
2024-05-23 20:17:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch11_loss0.14647798836231232.pypots
2024-05-23 20:17:46 [INFO]: Epoch 012 - training loss: 0.1470, validation loss: 0.1414
2024-05-23 20:17:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch12_loss0.14137144312262534.pypots
2024-05-23 20:18:03 [INFO]: Epoch 013 - training loss: 0.1457, validation loss: 0.1409
2024-05-23 20:18:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch13_loss0.1408650390803814.pypots
2024-05-23 20:18:19 [INFO]: Epoch 014 - training loss: 0.1405, validation loss: 0.1376
2024-05-23 20:18:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch14_loss0.13763605132699014.pypots
2024-05-23 20:18:35 [INFO]: Epoch 015 - training loss: 0.1537, validation loss: 0.1505
2024-05-23 20:18:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch15_loss0.15051760226488115.pypots
2024-05-23 20:18:52 [INFO]: Epoch 016 - training loss: 0.1398, validation loss: 0.1344
2024-05-23 20:18:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch16_loss0.13439876586198807.pypots
2024-05-23 20:19:08 [INFO]: Epoch 017 - training loss: 0.1483, validation loss: 0.1336
2024-05-23 20:19:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch17_loss0.13361800611019134.pypots
2024-05-23 20:19:24 [INFO]: Epoch 018 - training loss: 0.1394, validation loss: 0.1321
2024-05-23 20:19:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch18_loss0.13205188512802124.pypots
2024-05-23 20:19:41 [INFO]: Epoch 019 - training loss: 0.1421, validation loss: 0.1336
2024-05-23 20:19:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch19_loss0.13356284648180008.pypots
2024-05-23 20:19:57 [INFO]: Epoch 020 - training loss: 0.1276, validation loss: 0.1384
2024-05-23 20:19:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch20_loss0.13838102370500566.pypots
2024-05-23 20:20:13 [INFO]: Epoch 021 - training loss: 0.1392, validation loss: 0.1301
2024-05-23 20:20:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch21_loss0.13012656792998314.pypots
2024-05-23 20:20:30 [INFO]: Epoch 022 - training loss: 0.1352, validation loss: 0.1279
2024-05-23 20:20:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch22_loss0.12794039770960808.pypots
2024-05-23 20:20:46 [INFO]: Epoch 023 - training loss: 0.1476, validation loss: 0.1302
2024-05-23 20:20:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch23_loss0.13019946292042733.pypots
2024-05-23 20:21:03 [INFO]: Epoch 024 - training loss: 0.1378, validation loss: 0.1267
2024-05-23 20:21:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch24_loss0.12670372799038887.pypots
2024-05-23 20:21:19 [INFO]: Epoch 025 - training loss: 0.1386, validation loss: 0.1259
2024-05-23 20:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch25_loss0.12588778808712958.pypots
2024-05-23 20:21:35 [INFO]: Epoch 026 - training loss: 0.1392, validation loss: 0.1302
2024-05-23 20:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch26_loss0.1302269384264946.pypots
2024-05-23 20:21:52 [INFO]: Epoch 027 - training loss: 0.1331, validation loss: 0.1301
2024-05-23 20:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch27_loss0.13007619902491568.pypots
2024-05-23 20:22:08 [INFO]: Epoch 028 - training loss: 0.1230, validation loss: 0.1287
2024-05-23 20:22:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch28_loss0.12866831943392754.pypots
2024-05-23 20:22:24 [INFO]: Epoch 029 - training loss: 0.1178, validation loss: 0.1247
2024-05-23 20:22:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch29_loss0.12474371120333672.pypots
2024-05-23 20:22:41 [INFO]: Epoch 030 - training loss: 0.1191, validation loss: 0.1251
2024-05-23 20:22:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch30_loss0.12514984160661696.pypots
2024-05-23 20:22:57 [INFO]: Epoch 031 - training loss: 0.1217, validation loss: 0.1277
2024-05-23 20:22:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch31_loss0.12769827097654343.pypots
2024-05-23 20:23:13 [INFO]: Epoch 032 - training loss: 0.1208, validation loss: 0.1255
2024-05-23 20:23:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch32_loss0.1254600055515766.pypots
2024-05-23 20:23:30 [INFO]: Epoch 033 - training loss: 0.1338, validation loss: 0.1263
2024-05-23 20:23:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch33_loss0.12628614157438278.pypots
2024-05-23 20:23:46 [INFO]: Epoch 034 - training loss: 0.1091, validation loss: 0.1246
2024-05-23 20:23:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch34_loss0.12457197904586792.pypots
2024-05-23 20:24:02 [INFO]: Epoch 035 - training loss: 0.1202, validation loss: 0.1225
2024-05-23 20:24:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch35_loss0.12248297482728958.pypots
2024-05-23 20:24:19 [INFO]: Epoch 036 - training loss: 0.1203, validation loss: 0.1228
2024-05-23 20:24:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch36_loss0.12280544564127922.pypots
2024-05-23 20:24:35 [INFO]: Epoch 037 - training loss: 0.1162, validation loss: 0.1218
2024-05-23 20:24:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch37_loss0.12179193198680878.pypots
2024-05-23 20:24:51 [INFO]: Epoch 038 - training loss: 0.1251, validation loss: 0.1205
2024-05-23 20:24:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch38_loss0.12050890773534775.pypots
2024-05-23 20:25:08 [INFO]: Epoch 039 - training loss: 0.1305, validation loss: 0.1255
2024-05-23 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch39_loss0.1254622109234333.pypots
2024-05-23 20:25:24 [INFO]: Epoch 040 - training loss: 0.1250, validation loss: 0.1217
2024-05-23 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch40_loss0.12170137986540794.pypots
2024-05-23 20:25:40 [INFO]: Epoch 041 - training loss: 0.1283, validation loss: 0.1209
2024-05-23 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch41_loss0.12086222022771835.pypots
2024-05-23 20:25:57 [INFO]: Epoch 042 - training loss: 0.1187, validation loss: 0.1234
2024-05-23 20:25:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch42_loss0.12341637834906578.pypots
2024-05-23 20:26:13 [INFO]: Epoch 043 - training loss: 0.1268, validation loss: 0.1178
2024-05-23 20:26:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch43_loss0.11782062277197838.pypots
2024-05-23 20:26:30 [INFO]: Epoch 044 - training loss: 0.1175, validation loss: 0.1160
2024-05-23 20:26:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch44_loss0.11596567556262016.pypots
2024-05-23 20:26:46 [INFO]: Epoch 045 - training loss: 0.1278, validation loss: 0.1177
2024-05-23 20:26:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch45_loss0.1177009254693985.pypots
2024-05-23 20:27:02 [INFO]: Epoch 046 - training loss: 0.1072, validation loss: 0.1163
2024-05-23 20:27:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch46_loss0.11629894971847535.pypots
2024-05-23 20:27:19 [INFO]: Epoch 047 - training loss: 0.1151, validation loss: 0.1141
2024-05-23 20:27:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch47_loss0.11410178393125534.pypots
2024-05-23 20:27:35 [INFO]: Epoch 048 - training loss: 0.1120, validation loss: 0.1170
2024-05-23 20:27:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch48_loss0.11696793884038925.pypots
2024-05-23 20:27:51 [INFO]: Epoch 049 - training loss: 0.0989, validation loss: 0.1156
2024-05-23 20:27:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch49_loss0.1155766986310482.pypots
2024-05-23 20:28:08 [INFO]: Epoch 050 - training loss: 0.1153, validation loss: 0.1155
2024-05-23 20:28:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch50_loss0.11550727263092994.pypots
2024-05-23 20:28:24 [INFO]: Epoch 051 - training loss: 0.1257, validation loss: 0.1135
2024-05-23 20:28:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch51_loss0.1134790986776352.pypots
2024-05-23 20:28:40 [INFO]: Epoch 052 - training loss: 0.1114, validation loss: 0.1138
2024-05-23 20:28:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch52_loss0.11376649737358094.pypots
2024-05-23 20:28:57 [INFO]: Epoch 053 - training loss: 0.1216, validation loss: 0.1174
2024-05-23 20:28:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch53_loss0.11738891899585724.pypots
2024-05-23 20:29:13 [INFO]: Epoch 054 - training loss: 0.1188, validation loss: 0.1188
2024-05-23 20:29:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch54_loss0.11884240210056304.pypots
2024-05-23 20:29:29 [INFO]: Epoch 055 - training loss: 0.1142, validation loss: 0.1170
2024-05-23 20:29:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch55_loss0.11699916049838066.pypots
2024-05-23 20:29:46 [INFO]: Epoch 056 - training loss: 0.1043, validation loss: 0.1154
2024-05-23 20:29:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch56_loss0.11540781632065773.pypots
2024-05-23 20:30:02 [INFO]: Epoch 057 - training loss: 0.1049, validation loss: 0.1117
2024-05-23 20:30:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch57_loss0.11170597895979881.pypots
2024-05-23 20:30:18 [INFO]: Epoch 058 - training loss: 0.1052, validation loss: 0.1096
2024-05-23 20:30:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch58_loss0.10962445959448815.pypots
2024-05-23 20:30:35 [INFO]: Epoch 059 - training loss: 0.1055, validation loss: 0.1138
2024-05-23 20:30:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch59_loss0.11379798874258995.pypots
2024-05-23 20:30:51 [INFO]: Epoch 060 - training loss: 0.1174, validation loss: 0.1114
2024-05-23 20:30:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch60_loss0.11135590746998787.pypots
2024-05-23 20:31:07 [INFO]: Epoch 061 - training loss: 0.0997, validation loss: 0.1098
2024-05-23 20:31:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch61_loss0.10982199311256409.pypots
2024-05-23 20:31:24 [INFO]: Epoch 062 - training loss: 0.1092, validation loss: 0.1104
2024-05-23 20:31:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch62_loss0.11037966832518578.pypots
2024-05-23 20:31:40 [INFO]: Epoch 063 - training loss: 0.1090, validation loss: 0.1103
2024-05-23 20:31:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch63_loss0.1102936990559101.pypots
2024-05-23 20:31:56 [INFO]: Epoch 064 - training loss: 0.1159, validation loss: 0.1094
2024-05-23 20:31:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch64_loss0.10936049744486809.pypots
2024-05-23 20:32:13 [INFO]: Epoch 065 - training loss: 0.1058, validation loss: 0.1091
2024-05-23 20:32:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch65_loss0.10911442413926124.pypots
2024-05-23 20:32:29 [INFO]: Epoch 066 - training loss: 0.1075, validation loss: 0.1094
2024-05-23 20:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch66_loss0.10939207598567009.pypots
2024-05-23 20:32:45 [INFO]: Epoch 067 - training loss: 0.1077, validation loss: 0.1077
2024-05-23 20:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch67_loss0.10768401771783828.pypots
2024-05-23 20:33:02 [INFO]: Epoch 068 - training loss: 0.1030, validation loss: 0.1126
2024-05-23 20:33:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch68_loss0.11259375736117364.pypots
2024-05-23 20:33:18 [INFO]: Epoch 069 - training loss: 0.1084, validation loss: 0.1088
2024-05-23 20:33:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch69_loss0.10882098227739334.pypots
2024-05-23 20:33:34 [INFO]: Epoch 070 - training loss: 0.1107, validation loss: 0.1097
2024-05-23 20:33:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch70_loss0.10971877574920655.pypots
2024-05-23 20:33:51 [INFO]: Epoch 071 - training loss: 0.1125, validation loss: 0.1127
2024-05-23 20:33:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch71_loss0.11272552460432053.pypots
2024-05-23 20:34:07 [INFO]: Epoch 072 - training loss: 0.1164, validation loss: 0.1081
2024-05-23 20:34:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch72_loss0.10807866230607033.pypots
2024-05-23 20:34:23 [INFO]: Epoch 073 - training loss: 0.1141, validation loss: 0.1076
2024-05-23 20:34:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch73_loss0.10759870335459709.pypots
2024-05-23 20:34:40 [INFO]: Epoch 074 - training loss: 0.1028, validation loss: 0.1082
2024-05-23 20:34:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch74_loss0.10824681669473649.pypots
2024-05-23 20:34:56 [INFO]: Epoch 075 - training loss: 0.1011, validation loss: 0.1080
2024-05-23 20:34:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch75_loss0.10802324041724205.pypots
2024-05-23 20:35:12 [INFO]: Epoch 076 - training loss: 0.1047, validation loss: 0.1054
2024-05-23 20:35:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch76_loss0.10544178113341332.pypots
2024-05-23 20:35:29 [INFO]: Epoch 077 - training loss: 0.0990, validation loss: 0.1090
2024-05-23 20:35:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch77_loss0.10897751450538636.pypots
2024-05-23 20:35:45 [INFO]: Epoch 078 - training loss: 0.1160, validation loss: 0.1072
2024-05-23 20:35:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch78_loss0.10724389925599098.pypots
2024-05-23 20:36:01 [INFO]: Epoch 079 - training loss: 0.1067, validation loss: 0.1050
2024-05-23 20:36:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch79_loss0.10497624948620796.pypots
2024-05-23 20:36:18 [INFO]: Epoch 080 - training loss: 0.1156, validation loss: 0.1053
2024-05-23 20:36:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch80_loss0.1052516222000122.pypots
2024-05-23 20:36:34 [INFO]: Epoch 081 - training loss: 0.1072, validation loss: 0.1064
2024-05-23 20:36:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch81_loss0.10635316595435143.pypots
2024-05-23 20:36:50 [INFO]: Epoch 082 - training loss: 0.1105, validation loss: 0.1073
2024-05-23 20:36:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch82_loss0.10730892047286034.pypots
2024-05-23 20:37:07 [INFO]: Epoch 083 - training loss: 0.0998, validation loss: 0.1058
2024-05-23 20:37:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch83_loss0.10578127801418305.pypots
2024-05-23 20:37:23 [INFO]: Epoch 084 - training loss: 0.1168, validation loss: 0.1066
2024-05-23 20:37:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch84_loss0.10663193389773369.pypots
2024-05-23 20:37:39 [INFO]: Epoch 085 - training loss: 0.1075, validation loss: 0.1092
2024-05-23 20:37:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch85_loss0.10922010689973831.pypots
2024-05-23 20:37:56 [INFO]: Epoch 086 - training loss: 0.1147, validation loss: 0.1053
2024-05-23 20:37:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch86_loss0.10525908470153808.pypots
2024-05-23 20:38:12 [INFO]: Epoch 087 - training loss: 0.1019, validation loss: 0.1062
2024-05-23 20:38:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch87_loss0.10622272565960884.pypots
2024-05-23 20:38:28 [INFO]: Epoch 088 - training loss: 0.0981, validation loss: 0.1043
2024-05-23 20:38:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch88_loss0.10433675944805146.pypots
2024-05-23 20:38:45 [INFO]: Epoch 089 - training loss: 0.1123, validation loss: 0.1047
2024-05-23 20:38:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch89_loss0.10469371601939201.pypots
2024-05-23 20:39:01 [INFO]: Epoch 090 - training loss: 0.0994, validation loss: 0.1023
2024-05-23 20:39:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch90_loss0.10232167914509774.pypots
2024-05-23 20:39:17 [INFO]: Epoch 091 - training loss: 0.1056, validation loss: 0.1044
2024-05-23 20:39:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch91_loss0.10443690419197083.pypots
2024-05-23 20:39:34 [INFO]: Epoch 092 - training loss: 0.1033, validation loss: 0.1051
2024-05-23 20:39:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch92_loss0.105098856985569.pypots
2024-05-23 20:39:50 [INFO]: Epoch 093 - training loss: 0.1038, validation loss: 0.1038
2024-05-23 20:39:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch93_loss0.10375484377145767.pypots
2024-05-23 20:40:06 [INFO]: Epoch 094 - training loss: 0.1071, validation loss: 0.1032
2024-05-23 20:40:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch94_loss0.10317085161805153.pypots
2024-05-23 20:40:23 [INFO]: Epoch 095 - training loss: 0.0921, validation loss: 0.1034
2024-05-23 20:40:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch95_loss0.1034153863787651.pypots
2024-05-23 20:40:39 [INFO]: Epoch 096 - training loss: 0.0986, validation loss: 0.1043
2024-05-23 20:40:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch96_loss0.10431740581989288.pypots
2024-05-23 20:40:55 [INFO]: Epoch 097 - training loss: 0.1015, validation loss: 0.1027
2024-05-23 20:40:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch97_loss0.10273647159337998.pypots
2024-05-23 20:41:12 [INFO]: Epoch 098 - training loss: 0.1141, validation loss: 0.1028
2024-05-23 20:41:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch98_loss0.10281910151243209.pypots
2024-05-23 20:41:28 [INFO]: Epoch 099 - training loss: 0.1089, validation loss: 0.1031
2024-05-23 20:41:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch99_loss0.10307749658823014.pypots
2024-05-23 20:41:44 [INFO]: Epoch 100 - training loss: 0.1158, validation loss: 0.1068
2024-05-23 20:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI_epoch100_loss0.1067835159599781.pypots
2024-05-23 20:41:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:41:44 [INFO]: Finished training. The best model is from epoch#90.
2024-05-23 20:41:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240523_T201430/CSDI.pypots
2024-05-23 20:44:03 [INFO]: CSDI on Air-Quality: MAE=0.1078, MSE=0.2831
2024-05-23 20:44:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-23 20:44:03 [INFO]: Using the given device: cuda:0
2024-05-23 20:44:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240523_T204403
2024-05-23 20:44:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240523_T204403/tensorboard
2024-05-23 20:44:03 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 20:44:03 [INFO]: Epoch 001 - training loss: 63782.8248, validation loss: 0.6777
2024-05-23 20:44:03 [INFO]: Epoch 002 - training loss: 41833.1382, validation loss: 0.5910
2024-05-23 20:44:03 [INFO]: Epoch 003 - training loss: 41521.2471, validation loss: 0.5911
2024-05-23 20:44:04 [INFO]: Epoch 004 - training loss: 41408.9022, validation loss: 0.4819
2024-05-23 20:44:04 [INFO]: Epoch 005 - training loss: 41330.6807, validation loss: 0.4717
2024-05-23 20:44:04 [INFO]: Epoch 006 - training loss: 41271.5916, validation loss: 0.4414
2024-05-23 20:44:04 [INFO]: Epoch 007 - training loss: 41198.6092, validation loss: 0.4112
2024-05-23 20:44:05 [INFO]: Epoch 008 - training loss: 41173.6162, validation loss: 0.3567
2024-05-23 20:44:05 [INFO]: Epoch 009 - training loss: 41130.5680, validation loss: 0.3402
2024-05-23 20:44:05 [INFO]: Epoch 010 - training loss: 41101.2759, validation loss: 0.3448
2024-05-23 20:44:05 [INFO]: Epoch 011 - training loss: 41082.5774, validation loss: 0.3336
2024-05-23 20:44:05 [INFO]: Epoch 012 - training loss: 41070.7992, validation loss: 0.3240
2024-05-23 20:44:06 [INFO]: Epoch 013 - training loss: 41064.4057, validation loss: 0.3357
2024-05-23 20:44:06 [INFO]: Epoch 014 - training loss: 41060.1833, validation loss: 0.3198
2024-05-23 20:44:06 [INFO]: Epoch 015 - training loss: 41019.3819, validation loss: 0.2984
2024-05-23 20:44:06 [INFO]: Epoch 016 - training loss: 41007.6166, validation loss: 0.3206
2024-05-23 20:44:07 [INFO]: Epoch 017 - training loss: 41020.0890, validation loss: 0.2940
2024-05-23 20:44:07 [INFO]: Epoch 018 - training loss: 41022.8228, validation loss: 0.3069
2024-05-23 20:44:07 [INFO]: Epoch 019 - training loss: 40995.5534, validation loss: 0.2877
2024-05-23 20:44:07 [INFO]: Epoch 020 - training loss: 40964.4126, validation loss: 0.2779
2024-05-23 20:44:08 [INFO]: Epoch 021 - training loss: 40980.0923, validation loss: 0.3143
2024-05-23 20:44:08 [INFO]: Epoch 022 - training loss: 40986.7873, validation loss: 0.2842
2024-05-23 20:44:08 [INFO]: Epoch 023 - training loss: 40960.8779, validation loss: 0.2689
2024-05-23 20:44:08 [INFO]: Epoch 024 - training loss: 40945.8286, validation loss: 0.2610
2024-05-23 20:44:09 [INFO]: Epoch 025 - training loss: 40944.1450, validation loss: 0.2666
2024-05-23 20:44:09 [INFO]: Epoch 026 - training loss: 40938.1040, validation loss: 0.2617
2024-05-23 20:44:09 [INFO]: Epoch 027 - training loss: 40936.2737, validation loss: 0.2632
2024-05-23 20:44:09 [INFO]: Epoch 028 - training loss: 40935.3597, validation loss: 0.2514
2024-05-23 20:44:10 [INFO]: Epoch 029 - training loss: 40917.3316, validation loss: 0.2557
2024-05-23 20:44:10 [INFO]: Epoch 030 - training loss: 40918.6538, validation loss: 0.2994
2024-05-23 20:44:10 [INFO]: Epoch 031 - training loss: 40962.6277, validation loss: 0.2578
2024-05-23 20:44:10 [INFO]: Epoch 032 - training loss: 40910.5346, validation loss: 0.2560
2024-05-23 20:44:11 [INFO]: Epoch 033 - training loss: 40909.2726, validation loss: 0.2424
2024-05-23 20:44:11 [INFO]: Epoch 034 - training loss: 40897.9115, validation loss: 0.2693
2024-05-23 20:44:11 [INFO]: Epoch 035 - training loss: 40945.6231, validation loss: 0.2714
2024-05-23 20:44:11 [INFO]: Epoch 036 - training loss: 40971.1305, validation loss: 0.2663
2024-05-23 20:44:11 [INFO]: Epoch 037 - training loss: 40943.3396, validation loss: 0.2412
2024-05-23 20:44:12 [INFO]: Epoch 038 - training loss: 40896.2635, validation loss: 0.2372
2024-05-23 20:44:12 [INFO]: Epoch 039 - training loss: 40893.3631, validation loss: 0.2433
2024-05-23 20:44:12 [INFO]: Epoch 040 - training loss: 40887.0457, validation loss: 0.2388
2024-05-23 20:44:12 [INFO]: Epoch 041 - training loss: 40910.4977, validation loss: 0.2817
2024-05-23 20:44:13 [INFO]: Epoch 042 - training loss: 40928.1703, validation loss: 0.2436
2024-05-23 20:44:13 [INFO]: Epoch 043 - training loss: 40889.2909, validation loss: 0.2371
2024-05-23 20:44:13 [INFO]: Epoch 044 - training loss: 40883.8134, validation loss: 0.2295
2024-05-23 20:44:13 [INFO]: Epoch 045 - training loss: 40878.8886, validation loss: 0.2306
2024-05-23 20:44:14 [INFO]: Epoch 046 - training loss: 40874.0883, validation loss: 0.2401
2024-05-23 20:44:14 [INFO]: Epoch 047 - training loss: 40907.7937, validation loss: 0.2597
2024-05-23 20:44:14 [INFO]: Epoch 048 - training loss: 40928.7786, validation loss: 0.2632
2024-05-23 20:44:14 [INFO]: Epoch 049 - training loss: 40903.1016, validation loss: 0.2317
2024-05-23 20:44:15 [INFO]: Epoch 050 - training loss: 40885.5881, validation loss: 0.2354
2024-05-23 20:44:15 [INFO]: Epoch 051 - training loss: 40868.2742, validation loss: 0.2244
2024-05-23 20:44:15 [INFO]: Epoch 052 - training loss: 40866.9922, validation loss: 0.2250
2024-05-23 20:44:15 [INFO]: Epoch 053 - training loss: 40860.9034, validation loss: 0.2278
2024-05-23 20:44:16 [INFO]: Epoch 054 - training loss: 40880.5197, validation loss: 0.2334
2024-05-23 20:44:16 [INFO]: Epoch 055 - training loss: 40863.3801, validation loss: 0.2217
2024-05-23 20:44:16 [INFO]: Epoch 056 - training loss: 40858.2802, validation loss: 0.2207
2024-05-23 20:44:16 [INFO]: Epoch 057 - training loss: 40864.0719, validation loss: 0.2261
2024-05-23 20:44:17 [INFO]: Epoch 058 - training loss: 40855.1402, validation loss: 0.2249
2024-05-23 20:44:17 [INFO]: Epoch 059 - training loss: 40852.9249, validation loss: 0.2187
2024-05-23 20:44:17 [INFO]: Epoch 060 - training loss: 40851.6220, validation loss: 0.2259
2024-05-23 20:44:17 [INFO]: Epoch 061 - training loss: 40858.1165, validation loss: 0.2263
2024-05-23 20:44:17 [INFO]: Epoch 062 - training loss: 40868.3151, validation loss: 0.2279
2024-05-23 20:44:18 [INFO]: Epoch 063 - training loss: 40853.3472, validation loss: 0.2393
2024-05-23 20:44:18 [INFO]: Epoch 064 - training loss: 40868.3132, validation loss: 0.2272
2024-05-23 20:44:18 [INFO]: Epoch 065 - training loss: 40860.2461, validation loss: 0.2253
2024-05-23 20:44:18 [INFO]: Epoch 066 - training loss: 40869.4363, validation loss: 0.2226
2024-05-23 20:44:19 [INFO]: Epoch 067 - training loss: 40851.8659, validation loss: 0.2175
2024-05-23 20:44:19 [INFO]: Epoch 068 - training loss: 40850.9630, validation loss: 0.2207
2024-05-23 20:44:19 [INFO]: Epoch 069 - training loss: 40850.1263, validation loss: 0.2182
2024-05-23 20:44:19 [INFO]: Epoch 070 - training loss: 40845.3260, validation loss: 0.2161
2024-05-23 20:44:20 [INFO]: Epoch 071 - training loss: 40845.0289, validation loss: 0.2164
2024-05-23 20:44:20 [INFO]: Epoch 072 - training loss: 40835.6531, validation loss: 0.2171
2024-05-23 20:44:20 [INFO]: Epoch 073 - training loss: 40840.1155, validation loss: 0.2153
2024-05-23 20:44:20 [INFO]: Epoch 074 - training loss: 40842.2144, validation loss: 0.2207
2024-05-23 20:44:21 [INFO]: Epoch 075 - training loss: 40841.2973, validation loss: 0.2259
2024-05-23 20:44:21 [INFO]: Epoch 076 - training loss: 40866.8139, validation loss: 0.2272
2024-05-23 20:44:21 [INFO]: Epoch 077 - training loss: 40855.6810, validation loss: 0.2308
2024-05-23 20:44:21 [INFO]: Epoch 078 - training loss: 40865.0490, validation loss: 0.2172
2024-05-23 20:44:22 [INFO]: Epoch 079 - training loss: 40841.1956, validation loss: 0.2156
2024-05-23 20:44:22 [INFO]: Epoch 080 - training loss: 40832.4770, validation loss: 0.2141
2024-05-23 20:44:22 [INFO]: Epoch 081 - training loss: 40838.8694, validation loss: 0.2178
2024-05-23 20:44:22 [INFO]: Epoch 082 - training loss: 40836.8640, validation loss: 0.2404
2024-05-23 20:44:23 [INFO]: Epoch 083 - training loss: 40844.1136, validation loss: 0.2125
2024-05-23 20:44:23 [INFO]: Epoch 084 - training loss: 40827.6761, validation loss: 0.2113
2024-05-23 20:44:23 [INFO]: Epoch 085 - training loss: 40832.9057, validation loss: 0.2184
2024-05-23 20:44:23 [INFO]: Epoch 086 - training loss: 40830.0407, validation loss: 0.2257
2024-05-23 20:44:24 [INFO]: Epoch 087 - training loss: 40846.6243, validation loss: 0.2155
2024-05-23 20:44:24 [INFO]: Epoch 088 - training loss: 40835.0735, validation loss: 0.2083
2024-05-23 20:44:24 [INFO]: Epoch 089 - training loss: 40830.4773, validation loss: 0.2143
2024-05-23 20:44:24 [INFO]: Epoch 090 - training loss: 40833.6448, validation loss: 0.2137
2024-05-23 20:44:24 [INFO]: Epoch 091 - training loss: 40829.3791, validation loss: 0.2143
2024-05-23 20:44:25 [INFO]: Epoch 092 - training loss: 40832.7361, validation loss: 0.2089
2024-05-23 20:44:25 [INFO]: Epoch 093 - training loss: 40833.2769, validation loss: 0.2057
2024-05-23 20:44:25 [INFO]: Epoch 094 - training loss: 40859.5162, validation loss: 0.2118
2024-05-23 20:44:25 [INFO]: Epoch 095 - training loss: 40841.6084, validation loss: 0.2057
2024-05-23 20:44:26 [INFO]: Epoch 096 - training loss: 40825.3420, validation loss: 0.2018
2024-05-23 20:44:26 [INFO]: Epoch 097 - training loss: 40817.5237, validation loss: 0.2026
2024-05-23 20:44:26 [INFO]: Epoch 098 - training loss: 40813.8760, validation loss: 0.2023
2024-05-23 20:44:26 [INFO]: Epoch 099 - training loss: 40813.6823, validation loss: 0.1994
2024-05-23 20:44:27 [INFO]: Epoch 100 - training loss: 40807.8899, validation loss: 0.1995
2024-05-23 20:44:27 [INFO]: Epoch 101 - training loss: 40811.2542, validation loss: 0.2105
2024-05-23 20:44:27 [INFO]: Epoch 102 - training loss: 40816.9608, validation loss: 0.2184
2024-05-23 20:44:27 [INFO]: Epoch 103 - training loss: 40842.0525, validation loss: 0.2121
2024-05-23 20:44:28 [INFO]: Epoch 104 - training loss: 40823.0123, validation loss: 0.2231
2024-05-23 20:44:28 [INFO]: Epoch 105 - training loss: 40832.6970, validation loss: 0.2131
2024-05-23 20:44:28 [INFO]: Epoch 106 - training loss: 40816.6399, validation loss: 0.2017
2024-05-23 20:44:28 [INFO]: Epoch 107 - training loss: 40810.0366, validation loss: 0.2023
2024-05-23 20:44:29 [INFO]: Epoch 108 - training loss: 40818.6962, validation loss: 0.2247
2024-05-23 20:44:29 [INFO]: Epoch 109 - training loss: 40838.3180, validation loss: 0.2062
2024-05-23 20:44:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:44:29 [INFO]: Finished training. The best model is from epoch#99.
2024-05-23 20:44:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240523_T204403/GPVAE.pypots
2024-05-23 20:44:29 [INFO]: GP-VAE on Air-Quality: MAE=0.2610, MSE=0.2457
2024-05-23 20:44:29 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-23 20:44:29 [INFO]: Using the given device: cuda:0
2024-05-23 20:44:29 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240523_T204429
2024-05-23 20:44:29 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240523_T204429/tensorboard
2024-05-23 20:44:29 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 20:44:33 [INFO]: Epoch 001 - generator training loss: 0.4102, discriminator training loss: 0.4486, validation loss: 0.5028
2024-05-23 20:44:36 [INFO]: Epoch 002 - generator training loss: 0.0865, discriminator training loss: 0.3616, validation loss: 0.3771
2024-05-23 20:44:39 [INFO]: Epoch 003 - generator training loss: 0.0220, discriminator training loss: 0.3570, validation loss: 0.3159
2024-05-23 20:44:43 [INFO]: Epoch 004 - generator training loss: -0.0131, discriminator training loss: 0.3553, validation loss: 0.2728
2024-05-23 20:44:46 [INFO]: Epoch 005 - generator training loss: -0.0360, discriminator training loss: 0.3533, validation loss: 0.2459
2024-05-23 20:44:49 [INFO]: Epoch 006 - generator training loss: -0.0531, discriminator training loss: 0.3515, validation loss: 0.2260
2024-05-23 20:44:53 [INFO]: Epoch 007 - generator training loss: -0.0654, discriminator training loss: 0.3493, validation loss: 0.2116
2024-05-23 20:44:56 [INFO]: Epoch 008 - generator training loss: -0.0756, discriminator training loss: 0.3470, validation loss: 0.2003
2024-05-23 20:44:59 [INFO]: Epoch 009 - generator training loss: -0.0816, discriminator training loss: 0.3452, validation loss: 0.1922
2024-05-23 20:45:03 [INFO]: Epoch 010 - generator training loss: -0.0883, discriminator training loss: 0.3424, validation loss: 0.1847
2024-05-23 20:45:06 [INFO]: Epoch 011 - generator training loss: -0.0932, discriminator training loss: 0.3395, validation loss: 0.1786
2024-05-23 20:45:09 [INFO]: Epoch 012 - generator training loss: -0.0959, discriminator training loss: 0.3368, validation loss: 0.1738
2024-05-23 20:45:13 [INFO]: Epoch 013 - generator training loss: -0.0987, discriminator training loss: 0.3336, validation loss: 0.1683
2024-05-23 20:45:16 [INFO]: Epoch 014 - generator training loss: -0.1015, discriminator training loss: 0.3302, validation loss: 0.1648
2024-05-23 20:45:19 [INFO]: Epoch 015 - generator training loss: -0.1029, discriminator training loss: 0.3267, validation loss: 0.1605
2024-05-23 20:45:23 [INFO]: Epoch 016 - generator training loss: -0.1035, discriminator training loss: 0.3229, validation loss: 0.1573
2024-05-23 20:45:26 [INFO]: Epoch 017 - generator training loss: -0.1036, discriminator training loss: 0.3190, validation loss: 0.1551
2024-05-23 20:45:29 [INFO]: Epoch 018 - generator training loss: -0.1031, discriminator training loss: 0.3152, validation loss: 0.1511
2024-05-23 20:45:32 [INFO]: Epoch 019 - generator training loss: -0.1035, discriminator training loss: 0.3109, validation loss: 0.1489
2024-05-23 20:45:36 [INFO]: Epoch 020 - generator training loss: -0.1015, discriminator training loss: 0.3067, validation loss: 0.1465
2024-05-23 20:45:39 [INFO]: Epoch 021 - generator training loss: -0.1010, discriminator training loss: 0.3024, validation loss: 0.1445
2024-05-23 20:45:42 [INFO]: Epoch 022 - generator training loss: -0.1001, discriminator training loss: 0.2980, validation loss: 0.1418
2024-05-23 20:45:46 [INFO]: Epoch 023 - generator training loss: -0.0984, discriminator training loss: 0.2937, validation loss: 0.1404
2024-05-23 20:45:49 [INFO]: Epoch 024 - generator training loss: -0.0957, discriminator training loss: 0.2894, validation loss: 0.1387
2024-05-23 20:45:52 [INFO]: Epoch 025 - generator training loss: -0.0945, discriminator training loss: 0.2853, validation loss: 0.1368
2024-05-23 20:45:56 [INFO]: Epoch 026 - generator training loss: -0.0932, discriminator training loss: 0.2814, validation loss: 0.1350
2024-05-23 20:45:59 [INFO]: Epoch 027 - generator training loss: -0.0916, discriminator training loss: 0.2775, validation loss: 0.1342
2024-05-23 20:46:02 [INFO]: Epoch 028 - generator training loss: -0.0906, discriminator training loss: 0.2738, validation loss: 0.1320
2024-05-23 20:46:05 [INFO]: Epoch 029 - generator training loss: -0.0890, discriminator training loss: 0.2702, validation loss: 0.1308
2024-05-23 20:46:09 [INFO]: Epoch 030 - generator training loss: -0.0879, discriminator training loss: 0.2672, validation loss: 0.1301
2024-05-23 20:46:12 [INFO]: Epoch 031 - generator training loss: -0.0867, discriminator training loss: 0.2638, validation loss: 0.1275
2024-05-23 20:46:15 [INFO]: Epoch 032 - generator training loss: -0.0861, discriminator training loss: 0.2609, validation loss: 0.1271
2024-05-23 20:46:18 [INFO]: Epoch 033 - generator training loss: -0.0868, discriminator training loss: 0.2583, validation loss: 0.1257
2024-05-23 20:46:22 [INFO]: Epoch 034 - generator training loss: -0.0848, discriminator training loss: 0.2554, validation loss: 0.1248
2024-05-23 20:46:25 [INFO]: Epoch 035 - generator training loss: -0.0841, discriminator training loss: 0.2529, validation loss: 0.1231
2024-05-23 20:46:28 [INFO]: Epoch 036 - generator training loss: -0.0841, discriminator training loss: 0.2505, validation loss: 0.1209
2024-05-23 20:46:31 [INFO]: Epoch 037 - generator training loss: -0.0832, discriminator training loss: 0.2484, validation loss: 0.1200
2024-05-23 20:46:35 [INFO]: Epoch 038 - generator training loss: -0.0823, discriminator training loss: 0.2464, validation loss: 0.1189
2024-05-23 20:46:38 [INFO]: Epoch 039 - generator training loss: -0.0819, discriminator training loss: 0.2443, validation loss: 0.1183
2024-05-23 20:46:41 [INFO]: Epoch 040 - generator training loss: -0.0818, discriminator training loss: 0.2426, validation loss: 0.1170
2024-05-23 20:46:44 [INFO]: Epoch 041 - generator training loss: -0.0824, discriminator training loss: 0.2410, validation loss: 0.1157
2024-05-23 20:46:48 [INFO]: Epoch 042 - generator training loss: -0.0811, discriminator training loss: 0.2393, validation loss: 0.1148
2024-05-23 20:46:51 [INFO]: Epoch 043 - generator training loss: -0.0810, discriminator training loss: 0.2375, validation loss: 0.1139
2024-05-23 20:46:54 [INFO]: Epoch 044 - generator training loss: -0.0804, discriminator training loss: 0.2359, validation loss: 0.1123
2024-05-23 20:46:57 [INFO]: Epoch 045 - generator training loss: -0.0801, discriminator training loss: 0.2345, validation loss: 0.1116
2024-05-23 20:47:01 [INFO]: Epoch 046 - generator training loss: -0.0795, discriminator training loss: 0.2336, validation loss: 0.1114
2024-05-23 20:47:04 [INFO]: Epoch 047 - generator training loss: -0.0791, discriminator training loss: 0.2319, validation loss: 0.1105
2024-05-23 20:47:07 [INFO]: Epoch 048 - generator training loss: -0.0797, discriminator training loss: 0.2305, validation loss: 0.1100
2024-05-23 20:47:11 [INFO]: Epoch 049 - generator training loss: -0.0782, discriminator training loss: 0.2297, validation loss: 0.1079
2024-05-23 20:47:14 [INFO]: Epoch 050 - generator training loss: -0.0800, discriminator training loss: 0.2290, validation loss: 0.1085
2024-05-23 20:47:17 [INFO]: Epoch 051 - generator training loss: -0.0796, discriminator training loss: 0.2273, validation loss: 0.1077
2024-05-23 20:47:21 [INFO]: Epoch 052 - generator training loss: -0.0791, discriminator training loss: 0.2264, validation loss: 0.1061
2024-05-23 20:47:24 [INFO]: Epoch 053 - generator training loss: -0.0780, discriminator training loss: 0.2254, validation loss: 0.1057
2024-05-23 20:47:27 [INFO]: Epoch 054 - generator training loss: -0.0796, discriminator training loss: 0.2248, validation loss: 0.1054
2024-05-23 20:47:30 [INFO]: Epoch 055 - generator training loss: -0.0798, discriminator training loss: 0.2240, validation loss: 0.1042
2024-05-23 20:47:34 [INFO]: Epoch 056 - generator training loss: -0.0777, discriminator training loss: 0.2234, validation loss: 0.1043
2024-05-23 20:47:37 [INFO]: Epoch 057 - generator training loss: -0.0782, discriminator training loss: 0.2223, validation loss: 0.1033
2024-05-23 20:47:40 [INFO]: Epoch 058 - generator training loss: -0.0786, discriminator training loss: 0.2213, validation loss: 0.1032
2024-05-23 20:47:44 [INFO]: Epoch 059 - generator training loss: -0.0789, discriminator training loss: 0.2209, validation loss: 0.1022
2024-05-23 20:47:47 [INFO]: Epoch 060 - generator training loss: -0.0789, discriminator training loss: 0.2201, validation loss: 0.1024
2024-05-23 20:47:51 [INFO]: Epoch 061 - generator training loss: -0.0785, discriminator training loss: 0.2193, validation loss: 0.1020
2024-05-23 20:47:54 [INFO]: Epoch 062 - generator training loss: -0.0798, discriminator training loss: 0.2187, validation loss: 0.1015
2024-05-23 20:47:58 [INFO]: Epoch 063 - generator training loss: -0.0791, discriminator training loss: 0.2182, validation loss: 0.1010
2024-05-23 20:48:01 [INFO]: Epoch 064 - generator training loss: -0.0787, discriminator training loss: 0.2174, validation loss: 0.1002
2024-05-23 20:48:05 [INFO]: Epoch 065 - generator training loss: -0.0793, discriminator training loss: 0.2173, validation loss: 0.0995
2024-05-23 20:48:08 [INFO]: Epoch 066 - generator training loss: -0.0798, discriminator training loss: 0.2170, validation loss: 0.0995
2024-05-23 20:48:12 [INFO]: Epoch 067 - generator training loss: -0.0799, discriminator training loss: 0.2159, validation loss: 0.0990
2024-05-23 20:48:15 [INFO]: Epoch 068 - generator training loss: -0.0800, discriminator training loss: 0.2155, validation loss: 0.0993
2024-05-23 20:48:18 [INFO]: Epoch 069 - generator training loss: -0.0793, discriminator training loss: 0.2152, validation loss: 0.0984
2024-05-23 20:48:22 [INFO]: Epoch 070 - generator training loss: -0.0796, discriminator training loss: 0.2143, validation loss: 0.0990
2024-05-23 20:48:25 [INFO]: Epoch 071 - generator training loss: -0.0803, discriminator training loss: 0.2146, validation loss: 0.0975
2024-05-23 20:48:29 [INFO]: Epoch 072 - generator training loss: -0.0802, discriminator training loss: 0.2138, validation loss: 0.0976
2024-05-23 20:48:32 [INFO]: Epoch 073 - generator training loss: -0.0805, discriminator training loss: 0.2137, validation loss: 0.0977
2024-05-23 20:48:36 [INFO]: Epoch 074 - generator training loss: -0.0812, discriminator training loss: 0.2130, validation loss: 0.0969
2024-05-23 20:48:39 [INFO]: Epoch 075 - generator training loss: -0.0806, discriminator training loss: 0.2131, validation loss: 0.0963
2024-05-23 20:48:43 [INFO]: Epoch 076 - generator training loss: -0.0803, discriminator training loss: 0.2124, validation loss: 0.0974
2024-05-23 20:48:46 [INFO]: Epoch 077 - generator training loss: -0.0810, discriminator training loss: 0.2117, validation loss: 0.0958
2024-05-23 20:48:50 [INFO]: Epoch 078 - generator training loss: -0.0804, discriminator training loss: 0.2119, validation loss: 0.0959
2024-05-23 20:48:53 [INFO]: Epoch 079 - generator training loss: -0.0814, discriminator training loss: 0.2116, validation loss: 0.0957
2024-05-23 20:48:57 [INFO]: Epoch 080 - generator training loss: -0.0815, discriminator training loss: 0.2111, validation loss: 0.0956
2024-05-23 20:49:00 [INFO]: Epoch 081 - generator training loss: -0.0815, discriminator training loss: 0.2116, validation loss: 0.0953
2024-05-23 20:49:04 [INFO]: Epoch 082 - generator training loss: -0.0814, discriminator training loss: 0.2101, validation loss: 0.0954
2024-05-23 20:49:07 [INFO]: Epoch 083 - generator training loss: -0.0814, discriminator training loss: 0.2104, validation loss: 0.0950
2024-05-23 20:49:11 [INFO]: Epoch 084 - generator training loss: -0.0816, discriminator training loss: 0.2103, validation loss: 0.0952
2024-05-23 20:49:14 [INFO]: Epoch 085 - generator training loss: -0.0816, discriminator training loss: 0.2100, validation loss: 0.0948
2024-05-23 20:49:18 [INFO]: Epoch 086 - generator training loss: -0.0816, discriminator training loss: 0.2097, validation loss: 0.0939
2024-05-23 20:49:21 [INFO]: Epoch 087 - generator training loss: -0.0814, discriminator training loss: 0.2093, validation loss: 0.0935
2024-05-23 20:49:25 [INFO]: Epoch 088 - generator training loss: -0.0821, discriminator training loss: 0.2088, validation loss: 0.0938
2024-05-23 20:49:28 [INFO]: Epoch 089 - generator training loss: -0.0828, discriminator training loss: 0.2089, validation loss: 0.0943
2024-05-23 20:49:31 [INFO]: Epoch 090 - generator training loss: -0.0819, discriminator training loss: 0.2089, validation loss: 0.0940
2024-05-23 20:49:35 [INFO]: Epoch 091 - generator training loss: -0.0833, discriminator training loss: 0.2083, validation loss: 0.0943
2024-05-23 20:49:38 [INFO]: Epoch 092 - generator training loss: -0.0836, discriminator training loss: 0.2085, validation loss: 0.0930
2024-05-23 20:49:42 [INFO]: Epoch 093 - generator training loss: -0.0834, discriminator training loss: 0.2081, validation loss: 0.0927
2024-05-23 20:49:45 [INFO]: Epoch 094 - generator training loss: -0.0833, discriminator training loss: 0.2081, validation loss: 0.0936
2024-05-23 20:49:48 [INFO]: Epoch 095 - generator training loss: -0.0833, discriminator training loss: 0.2075, validation loss: 0.0927
2024-05-23 20:49:52 [INFO]: Epoch 096 - generator training loss: -0.0833, discriminator training loss: 0.2073, validation loss: 0.0934
2024-05-23 20:49:55 [INFO]: Epoch 097 - generator training loss: -0.0835, discriminator training loss: 0.2073, validation loss: 0.0926
2024-05-23 20:49:59 [INFO]: Epoch 098 - generator training loss: -0.0839, discriminator training loss: 0.2074, validation loss: 0.0927
2024-05-23 20:50:02 [INFO]: Epoch 099 - generator training loss: -0.0840, discriminator training loss: 0.2070, validation loss: 0.0927
2024-05-23 20:50:06 [INFO]: Epoch 100 - generator training loss: -0.0835, discriminator training loss: 0.2066, validation loss: 0.0921
2024-05-23 20:50:09 [INFO]: Epoch 101 - generator training loss: -0.0840, discriminator training loss: 0.2067, validation loss: 0.0924
2024-05-23 20:50:12 [INFO]: Epoch 102 - generator training loss: -0.0839, discriminator training loss: 0.2064, validation loss: 0.0925
2024-05-23 20:50:16 [INFO]: Epoch 103 - generator training loss: -0.0844, discriminator training loss: 0.2068, validation loss: 0.0927
2024-05-23 20:50:20 [INFO]: Epoch 104 - generator training loss: -0.0842, discriminator training loss: 0.2061, validation loss: 0.0919
2024-05-23 20:50:23 [INFO]: Epoch 105 - generator training loss: -0.0841, discriminator training loss: 0.2060, validation loss: 0.0924
2024-05-23 20:50:27 [INFO]: Epoch 106 - generator training loss: -0.0852, discriminator training loss: 0.2066, validation loss: 0.0921
2024-05-23 20:50:31 [INFO]: Epoch 107 - generator training loss: -0.0845, discriminator training loss: 0.2058, validation loss: 0.0923
2024-05-23 20:50:34 [INFO]: Epoch 108 - generator training loss: -0.0850, discriminator training loss: 0.2059, validation loss: 0.0913
2024-05-23 20:50:38 [INFO]: Epoch 109 - generator training loss: -0.0848, discriminator training loss: 0.2055, validation loss: 0.0912
2024-05-23 20:50:41 [INFO]: Epoch 110 - generator training loss: -0.0853, discriminator training loss: 0.2058, validation loss: 0.0910
2024-05-23 20:50:45 [INFO]: Epoch 111 - generator training loss: -0.0844, discriminator training loss: 0.2055, validation loss: 0.0922
2024-05-23 20:50:48 [INFO]: Epoch 112 - generator training loss: -0.0858, discriminator training loss: 0.2058, validation loss: 0.0916
2024-05-23 20:50:52 [INFO]: Epoch 113 - generator training loss: -0.0862, discriminator training loss: 0.2055, validation loss: 0.0908
2024-05-23 20:50:56 [INFO]: Epoch 114 - generator training loss: -0.0859, discriminator training loss: 0.2052, validation loss: 0.0905
2024-05-23 20:50:59 [INFO]: Epoch 115 - generator training loss: -0.0860, discriminator training loss: 0.2049, validation loss: 0.0917
2024-05-23 20:51:03 [INFO]: Epoch 116 - generator training loss: -0.0857, discriminator training loss: 0.2050, validation loss: 0.0910
2024-05-23 20:51:07 [INFO]: Epoch 117 - generator training loss: -0.0863, discriminator training loss: 0.2047, validation loss: 0.0910
2024-05-23 20:51:10 [INFO]: Epoch 118 - generator training loss: -0.0861, discriminator training loss: 0.2047, validation loss: 0.0907
2024-05-23 20:51:14 [INFO]: Epoch 119 - generator training loss: -0.0862, discriminator training loss: 0.2042, validation loss: 0.0913
2024-05-23 20:51:17 [INFO]: Epoch 120 - generator training loss: -0.0864, discriminator training loss: 0.2046, validation loss: 0.0912
2024-05-23 20:51:21 [INFO]: Epoch 121 - generator training loss: -0.0868, discriminator training loss: 0.2042, validation loss: 0.0905
2024-05-23 20:51:24 [INFO]: Epoch 122 - generator training loss: -0.0865, discriminator training loss: 0.2041, validation loss: 0.0909
2024-05-23 20:51:28 [INFO]: Epoch 123 - generator training loss: -0.0863, discriminator training loss: 0.2038, validation loss: 0.0898
2024-05-23 20:51:32 [INFO]: Epoch 124 - generator training loss: -0.0870, discriminator training loss: 0.2039, validation loss: 0.0907
2024-05-23 20:51:35 [INFO]: Epoch 125 - generator training loss: -0.0868, discriminator training loss: 0.2035, validation loss: 0.0899
2024-05-23 20:51:39 [INFO]: Epoch 126 - generator training loss: -0.0873, discriminator training loss: 0.2035, validation loss: 0.0901
2024-05-23 20:51:42 [INFO]: Epoch 127 - generator training loss: -0.0881, discriminator training loss: 0.2033, validation loss: 0.0906
2024-05-23 20:51:46 [INFO]: Epoch 128 - generator training loss: -0.0867, discriminator training loss: 0.2032, validation loss: 0.0901
2024-05-23 20:51:50 [INFO]: Epoch 129 - generator training loss: -0.0872, discriminator training loss: 0.2031, validation loss: 0.0894
2024-05-23 20:51:53 [INFO]: Epoch 130 - generator training loss: -0.0871, discriminator training loss: 0.2035, validation loss: 0.0900
2024-05-23 20:51:57 [INFO]: Epoch 131 - generator training loss: -0.0874, discriminator training loss: 0.2027, validation loss: 0.0900
2024-05-23 20:52:00 [INFO]: Epoch 132 - generator training loss: -0.0878, discriminator training loss: 0.2031, validation loss: 0.0902
2024-05-23 20:52:04 [INFO]: Epoch 133 - generator training loss: -0.0885, discriminator training loss: 0.2032, validation loss: 0.0894
2024-05-23 20:52:07 [INFO]: Epoch 134 - generator training loss: -0.0883, discriminator training loss: 0.2026, validation loss: 0.0903
2024-05-23 20:52:11 [INFO]: Epoch 135 - generator training loss: -0.0880, discriminator training loss: 0.2028, validation loss: 0.0900
2024-05-23 20:52:14 [INFO]: Epoch 136 - generator training loss: -0.0880, discriminator training loss: 0.2026, validation loss: 0.0895
2024-05-23 20:52:18 [INFO]: Epoch 137 - generator training loss: -0.0883, discriminator training loss: 0.2023, validation loss: 0.0901
2024-05-23 20:52:21 [INFO]: Epoch 138 - generator training loss: -0.0875, discriminator training loss: 0.2023, validation loss: 0.0926
2024-05-23 20:52:25 [INFO]: Epoch 139 - generator training loss: -0.0872, discriminator training loss: 0.2025, validation loss: 0.0898
2024-05-23 20:52:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:52:25 [INFO]: Finished training. The best model is from epoch#129.
2024-05-23 20:52:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240523_T204429/USGAN.pypots
2024-05-23 20:52:25 [INFO]: US-GAN on Air-Quality: MAE=0.1462, MSE=0.1250
2024-05-23 20:52:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-23 20:52:25 [INFO]: Using the given device: cuda:0
2024-05-23 20:52:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240523_T205225
2024-05-23 20:52:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240523_T205225/tensorboard
2024-05-23 20:52:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 20:52:28 [INFO]: Epoch 001 - training loss: 1.4212, validation loss: 0.9616
2024-05-23 20:52:30 [INFO]: Epoch 002 - training loss: 1.1532, validation loss: 0.7162
2024-05-23 20:52:33 [INFO]: Epoch 003 - training loss: 0.9597, validation loss: 0.6029
2024-05-23 20:52:35 [INFO]: Epoch 004 - training loss: 0.8482, validation loss: 0.5319
2024-05-23 20:52:37 [INFO]: Epoch 005 - training loss: 0.7707, validation loss: 0.4834
2024-05-23 20:52:40 [INFO]: Epoch 006 - training loss: 0.7143, validation loss: 0.4444
2024-05-23 20:52:42 [INFO]: Epoch 007 - training loss: 0.6704, validation loss: 0.4139
2024-05-23 20:52:44 [INFO]: Epoch 008 - training loss: 0.6359, validation loss: 0.3890
2024-05-23 20:52:47 [INFO]: Epoch 009 - training loss: 0.6116, validation loss: 0.3694
2024-05-23 20:52:49 [INFO]: Epoch 010 - training loss: 0.5898, validation loss: 0.3529
2024-05-23 20:52:51 [INFO]: Epoch 011 - training loss: 0.5732, validation loss: 0.3394
2024-05-23 20:52:54 [INFO]: Epoch 012 - training loss: 0.5583, validation loss: 0.3276
2024-05-23 20:52:56 [INFO]: Epoch 013 - training loss: 0.5451, validation loss: 0.3167
2024-05-23 20:52:58 [INFO]: Epoch 014 - training loss: 0.5334, validation loss: 0.3076
2024-05-23 20:53:01 [INFO]: Epoch 015 - training loss: 0.5221, validation loss: 0.3000
2024-05-23 20:53:03 [INFO]: Epoch 016 - training loss: 0.5120, validation loss: 0.2925
2024-05-23 20:53:05 [INFO]: Epoch 017 - training loss: 0.5037, validation loss: 0.2859
2024-05-23 20:53:07 [INFO]: Epoch 018 - training loss: 0.4947, validation loss: 0.2798
2024-05-23 20:53:10 [INFO]: Epoch 019 - training loss: 0.4875, validation loss: 0.2745
2024-05-23 20:53:12 [INFO]: Epoch 020 - training loss: 0.4793, validation loss: 0.2694
2024-05-23 20:53:14 [INFO]: Epoch 021 - training loss: 0.4732, validation loss: 0.2646
2024-05-23 20:53:17 [INFO]: Epoch 022 - training loss: 0.4655, validation loss: 0.2596
2024-05-23 20:53:19 [INFO]: Epoch 023 - training loss: 0.4590, validation loss: 0.2552
2024-05-23 20:53:21 [INFO]: Epoch 024 - training loss: 0.4532, validation loss: 0.2512
2024-05-23 20:53:24 [INFO]: Epoch 025 - training loss: 0.4472, validation loss: 0.2469
2024-05-23 20:53:26 [INFO]: Epoch 026 - training loss: 0.4422, validation loss: 0.2434
2024-05-23 20:53:28 [INFO]: Epoch 027 - training loss: 0.4363, validation loss: 0.2391
2024-05-23 20:53:31 [INFO]: Epoch 028 - training loss: 0.4309, validation loss: 0.2357
2024-05-23 20:53:33 [INFO]: Epoch 029 - training loss: 0.4262, validation loss: 0.2319
2024-05-23 20:53:35 [INFO]: Epoch 030 - training loss: 0.4211, validation loss: 0.2285
2024-05-23 20:53:38 [INFO]: Epoch 031 - training loss: 0.4171, validation loss: 0.2255
2024-05-23 20:53:40 [INFO]: Epoch 032 - training loss: 0.4119, validation loss: 0.2224
2024-05-23 20:53:42 [INFO]: Epoch 033 - training loss: 0.4085, validation loss: 0.2200
2024-05-23 20:53:45 [INFO]: Epoch 034 - training loss: 0.4036, validation loss: 0.2164
2024-05-23 20:53:47 [INFO]: Epoch 035 - training loss: 0.4003, validation loss: 0.2135
2024-05-23 20:53:49 [INFO]: Epoch 036 - training loss: 0.3958, validation loss: 0.2110
2024-05-23 20:53:52 [INFO]: Epoch 037 - training loss: 0.3924, validation loss: 0.2083
2024-05-23 20:53:54 [INFO]: Epoch 038 - training loss: 0.3890, validation loss: 0.2062
2024-05-23 20:53:56 [INFO]: Epoch 039 - training loss: 0.3848, validation loss: 0.2035
2024-05-23 20:53:59 [INFO]: Epoch 040 - training loss: 0.3819, validation loss: 0.2012
2024-05-23 20:54:01 [INFO]: Epoch 041 - training loss: 0.3788, validation loss: 0.1987
2024-05-23 20:54:04 [INFO]: Epoch 042 - training loss: 0.3760, validation loss: 0.1968
2024-05-23 20:54:06 [INFO]: Epoch 043 - training loss: 0.3726, validation loss: 0.1943
2024-05-23 20:54:08 [INFO]: Epoch 044 - training loss: 0.3699, validation loss: 0.1925
2024-05-23 20:54:11 [INFO]: Epoch 045 - training loss: 0.3666, validation loss: 0.1907
2024-05-23 20:54:13 [INFO]: Epoch 046 - training loss: 0.3643, validation loss: 0.1887
2024-05-23 20:54:16 [INFO]: Epoch 047 - training loss: 0.3619, validation loss: 0.1867
2024-05-23 20:54:18 [INFO]: Epoch 048 - training loss: 0.3584, validation loss: 0.1851
2024-05-23 20:54:20 [INFO]: Epoch 049 - training loss: 0.3576, validation loss: 0.1834
2024-05-23 20:54:23 [INFO]: Epoch 050 - training loss: 0.3548, validation loss: 0.1817
2024-05-23 20:54:25 [INFO]: Epoch 051 - training loss: 0.3513, validation loss: 0.1802
2024-05-23 20:54:27 [INFO]: Epoch 052 - training loss: 0.3501, validation loss: 0.1790
2024-05-23 20:54:30 [INFO]: Epoch 053 - training loss: 0.3482, validation loss: 0.1775
2024-05-23 20:54:32 [INFO]: Epoch 054 - training loss: 0.3456, validation loss: 0.1766
2024-05-23 20:54:35 [INFO]: Epoch 055 - training loss: 0.3441, validation loss: 0.1748
2024-05-23 20:54:37 [INFO]: Epoch 056 - training loss: 0.3413, validation loss: 0.1734
2024-05-23 20:54:39 [INFO]: Epoch 057 - training loss: 0.3399, validation loss: 0.1725
2024-05-23 20:54:42 [INFO]: Epoch 058 - training loss: 0.3387, validation loss: 0.1710
2024-05-23 20:54:44 [INFO]: Epoch 059 - training loss: 0.3370, validation loss: 0.1700
2024-05-23 20:54:46 [INFO]: Epoch 060 - training loss: 0.3346, validation loss: 0.1689
2024-05-23 20:54:49 [INFO]: Epoch 061 - training loss: 0.3333, validation loss: 0.1678
2024-05-23 20:54:51 [INFO]: Epoch 062 - training loss: 0.3306, validation loss: 0.1668
2024-05-23 20:54:53 [INFO]: Epoch 063 - training loss: 0.3297, validation loss: 0.1657
2024-05-23 20:54:56 [INFO]: Epoch 064 - training loss: 0.3281, validation loss: 0.1646
2024-05-23 20:54:58 [INFO]: Epoch 065 - training loss: 0.3266, validation loss: 0.1639
2024-05-23 20:55:01 [INFO]: Epoch 066 - training loss: 0.3256, validation loss: 0.1626
2024-05-23 20:55:03 [INFO]: Epoch 067 - training loss: 0.3239, validation loss: 0.1619
2024-05-23 20:55:05 [INFO]: Epoch 068 - training loss: 0.3228, validation loss: 0.1613
2024-05-23 20:55:08 [INFO]: Epoch 069 - training loss: 0.3227, validation loss: 0.1606
2024-05-23 20:55:10 [INFO]: Epoch 070 - training loss: 0.3206, validation loss: 0.1586
2024-05-23 20:55:13 [INFO]: Epoch 071 - training loss: 0.3187, validation loss: 0.1579
2024-05-23 20:55:15 [INFO]: Epoch 072 - training loss: 0.3172, validation loss: 0.1569
2024-05-23 20:55:17 [INFO]: Epoch 073 - training loss: 0.3164, validation loss: 0.1564
2024-05-23 20:55:20 [INFO]: Epoch 074 - training loss: 0.3152, validation loss: 0.1556
2024-05-23 20:55:22 [INFO]: Epoch 075 - training loss: 0.3146, validation loss: 0.1547
2024-05-23 20:55:24 [INFO]: Epoch 076 - training loss: 0.3131, validation loss: 0.1539
2024-05-23 20:55:27 [INFO]: Epoch 077 - training loss: 0.3125, validation loss: 0.1530
2024-05-23 20:55:29 [INFO]: Epoch 078 - training loss: 0.3114, validation loss: 0.1522
2024-05-23 20:55:31 [INFO]: Epoch 079 - training loss: 0.3108, validation loss: 0.1517
2024-05-23 20:55:34 [INFO]: Epoch 080 - training loss: 0.3090, validation loss: 0.1509
2024-05-23 20:55:36 [INFO]: Epoch 081 - training loss: 0.3092, validation loss: 0.1500
2024-05-23 20:55:39 [INFO]: Epoch 082 - training loss: 0.3073, validation loss: 0.1494
2024-05-23 20:55:41 [INFO]: Epoch 083 - training loss: 0.3065, validation loss: 0.1485
2024-05-23 20:55:43 [INFO]: Epoch 084 - training loss: 0.3053, validation loss: 0.1479
2024-05-23 20:55:46 [INFO]: Epoch 085 - training loss: 0.3058, validation loss: 0.1470
2024-05-23 20:55:48 [INFO]: Epoch 086 - training loss: 0.3047, validation loss: 0.1464
2024-05-23 20:55:51 [INFO]: Epoch 087 - training loss: 0.3030, validation loss: 0.1461
2024-05-23 20:55:53 [INFO]: Epoch 088 - training loss: 0.3020, validation loss: 0.1451
2024-05-23 20:55:55 [INFO]: Epoch 089 - training loss: 0.3021, validation loss: 0.1446
2024-05-23 20:55:58 [INFO]: Epoch 090 - training loss: 0.3009, validation loss: 0.1439
2024-05-23 20:56:00 [INFO]: Epoch 091 - training loss: 0.3000, validation loss: 0.1433
2024-05-23 20:56:02 [INFO]: Epoch 092 - training loss: 0.2989, validation loss: 0.1427
2024-05-23 20:56:05 [INFO]: Epoch 093 - training loss: 0.2984, validation loss: 0.1419
2024-05-23 20:56:07 [INFO]: Epoch 094 - training loss: 0.2974, validation loss: 0.1413
2024-05-23 20:56:10 [INFO]: Epoch 095 - training loss: 0.2976, validation loss: 0.1409
2024-05-23 20:56:12 [INFO]: Epoch 096 - training loss: 0.2963, validation loss: 0.1400
2024-05-23 20:56:14 [INFO]: Epoch 097 - training loss: 0.2956, validation loss: 0.1398
2024-05-23 20:56:17 [INFO]: Epoch 098 - training loss: 0.2955, validation loss: 0.1388
2024-05-23 20:56:19 [INFO]: Epoch 099 - training loss: 0.2944, validation loss: 0.1383
2024-05-23 20:56:21 [INFO]: Epoch 100 - training loss: 0.2940, validation loss: 0.1378
2024-05-23 20:56:24 [INFO]: Epoch 101 - training loss: 0.2930, validation loss: 0.1370
2024-05-23 20:56:26 [INFO]: Epoch 102 - training loss: 0.2931, validation loss: 0.1366
2024-05-23 20:56:29 [INFO]: Epoch 103 - training loss: 0.2921, validation loss: 0.1361
2024-05-23 20:56:31 [INFO]: Epoch 104 - training loss: 0.2912, validation loss: 0.1355
2024-05-23 20:56:33 [INFO]: Epoch 105 - training loss: 0.2908, validation loss: 0.1351
2024-05-23 20:56:36 [INFO]: Epoch 106 - training loss: 0.2897, validation loss: 0.1344
2024-05-23 20:56:38 [INFO]: Epoch 107 - training loss: 0.2898, validation loss: 0.1340
2024-05-23 20:56:40 [INFO]: Epoch 108 - training loss: 0.2890, validation loss: 0.1334
2024-05-23 20:56:43 [INFO]: Epoch 109 - training loss: 0.2884, validation loss: 0.1328
2024-05-23 20:56:45 [INFO]: Epoch 110 - training loss: 0.2875, validation loss: 0.1324
2024-05-23 20:56:48 [INFO]: Epoch 111 - training loss: 0.2879, validation loss: 0.1320
2024-05-23 20:56:50 [INFO]: Epoch 112 - training loss: 0.2869, validation loss: 0.1312
2024-05-23 20:56:52 [INFO]: Epoch 113 - training loss: 0.2859, validation loss: 0.1308
2024-05-23 20:56:55 [INFO]: Epoch 114 - training loss: 0.2855, validation loss: 0.1303
2024-05-23 20:56:57 [INFO]: Epoch 115 - training loss: 0.2849, validation loss: 0.1299
2024-05-23 20:56:59 [INFO]: Epoch 116 - training loss: 0.2844, validation loss: 0.1292
2024-05-23 20:57:02 [INFO]: Epoch 117 - training loss: 0.2839, validation loss: 0.1289
2024-05-23 20:57:04 [INFO]: Epoch 118 - training loss: 0.2838, validation loss: 0.1287
2024-05-23 20:57:06 [INFO]: Epoch 119 - training loss: 0.2833, validation loss: 0.1281
2024-05-23 20:57:09 [INFO]: Epoch 120 - training loss: 0.2833, validation loss: 0.1276
2024-05-23 20:57:11 [INFO]: Epoch 121 - training loss: 0.2827, validation loss: 0.1274
2024-05-23 20:57:14 [INFO]: Epoch 122 - training loss: 0.2824, validation loss: 0.1267
2024-05-23 20:57:16 [INFO]: Epoch 123 - training loss: 0.2811, validation loss: 0.1263
2024-05-23 20:57:18 [INFO]: Epoch 124 - training loss: 0.2808, validation loss: 0.1259
2024-05-23 20:57:21 [INFO]: Epoch 125 - training loss: 0.2805, validation loss: 0.1255
2024-05-23 20:57:23 [INFO]: Epoch 126 - training loss: 0.2802, validation loss: 0.1250
2024-05-23 20:57:25 [INFO]: Epoch 127 - training loss: 0.2790, validation loss: 0.1248
2024-05-23 20:57:28 [INFO]: Epoch 128 - training loss: 0.2793, validation loss: 0.1243
2024-05-23 20:57:30 [INFO]: Epoch 129 - training loss: 0.2782, validation loss: 0.1239
2024-05-23 20:57:33 [INFO]: Epoch 130 - training loss: 0.2778, validation loss: 0.1235
2024-05-23 20:57:35 [INFO]: Epoch 131 - training loss: 0.2776, validation loss: 0.1231
2024-05-23 20:57:37 [INFO]: Epoch 132 - training loss: 0.2771, validation loss: 0.1226
2024-05-23 20:57:40 [INFO]: Epoch 133 - training loss: 0.2766, validation loss: 0.1225
2024-05-23 20:57:42 [INFO]: Epoch 134 - training loss: 0.2767, validation loss: 0.1219
2024-05-23 20:57:44 [INFO]: Epoch 135 - training loss: 0.2761, validation loss: 0.1218
2024-05-23 20:57:47 [INFO]: Epoch 136 - training loss: 0.2754, validation loss: 0.1210
2024-05-23 20:57:49 [INFO]: Epoch 137 - training loss: 0.2752, validation loss: 0.1208
2024-05-23 20:57:52 [INFO]: Epoch 138 - training loss: 0.2748, validation loss: 0.1203
2024-05-23 20:57:54 [INFO]: Epoch 139 - training loss: 0.2740, validation loss: 0.1199
2024-05-23 20:57:56 [INFO]: Epoch 140 - training loss: 0.2740, validation loss: 0.1198
2024-05-23 20:57:59 [INFO]: Epoch 141 - training loss: 0.2739, validation loss: 0.1192
2024-05-23 20:58:01 [INFO]: Epoch 142 - training loss: 0.2735, validation loss: 0.1188
2024-05-23 20:58:04 [INFO]: Epoch 143 - training loss: 0.2733, validation loss: 0.1184
2024-05-23 20:58:06 [INFO]: Epoch 144 - training loss: 0.2732, validation loss: 0.1182
2024-05-23 20:58:09 [INFO]: Epoch 145 - training loss: 0.2720, validation loss: 0.1181
2024-05-23 20:58:11 [INFO]: Epoch 146 - training loss: 0.2726, validation loss: 0.1177
2024-05-23 20:58:14 [INFO]: Epoch 147 - training loss: 0.2715, validation loss: 0.1172
2024-05-23 20:58:16 [INFO]: Epoch 148 - training loss: 0.2711, validation loss: 0.1170
2024-05-23 20:58:19 [INFO]: Epoch 149 - training loss: 0.2713, validation loss: 0.1164
2024-05-23 20:58:21 [INFO]: Epoch 150 - training loss: 0.2709, validation loss: 0.1165
2024-05-23 20:58:24 [INFO]: Epoch 151 - training loss: 0.2700, validation loss: 0.1159
2024-05-23 20:58:26 [INFO]: Epoch 152 - training loss: 0.2704, validation loss: 0.1157
2024-05-23 20:58:29 [INFO]: Epoch 153 - training loss: 0.2694, validation loss: 0.1152
2024-05-23 20:58:31 [INFO]: Epoch 154 - training loss: 0.2699, validation loss: 0.1150
2024-05-23 20:58:34 [INFO]: Epoch 155 - training loss: 0.2689, validation loss: 0.1145
2024-05-23 20:58:36 [INFO]: Epoch 156 - training loss: 0.2684, validation loss: 0.1144
2024-05-23 20:58:39 [INFO]: Epoch 157 - training loss: 0.2686, validation loss: 0.1140
2024-05-23 20:58:41 [INFO]: Epoch 158 - training loss: 0.2671, validation loss: 0.1138
2024-05-23 20:58:43 [INFO]: Epoch 159 - training loss: 0.2676, validation loss: 0.1136
2024-05-23 20:58:46 [INFO]: Epoch 160 - training loss: 0.2673, validation loss: 0.1133
2024-05-23 20:58:48 [INFO]: Epoch 161 - training loss: 0.2671, validation loss: 0.1130
2024-05-23 20:58:51 [INFO]: Epoch 162 - training loss: 0.2668, validation loss: 0.1126
2024-05-23 20:58:53 [INFO]: Epoch 163 - training loss: 0.2662, validation loss: 0.1125
2024-05-23 20:58:56 [INFO]: Epoch 164 - training loss: 0.2655, validation loss: 0.1122
2024-05-23 20:58:58 [INFO]: Epoch 165 - training loss: 0.2657, validation loss: 0.1120
2024-05-23 20:59:01 [INFO]: Epoch 166 - training loss: 0.2656, validation loss: 0.1118
2024-05-23 20:59:03 [INFO]: Epoch 167 - training loss: 0.2650, validation loss: 0.1115
2024-05-23 20:59:06 [INFO]: Epoch 168 - training loss: 0.2647, validation loss: 0.1111
2024-05-23 20:59:08 [INFO]: Epoch 169 - training loss: 0.2646, validation loss: 0.1111
2024-05-23 20:59:11 [INFO]: Epoch 170 - training loss: 0.2641, validation loss: 0.1108
2024-05-23 20:59:13 [INFO]: Epoch 171 - training loss: 0.2637, validation loss: 0.1106
2024-05-23 20:59:16 [INFO]: Epoch 172 - training loss: 0.2635, validation loss: 0.1103
2024-05-23 20:59:18 [INFO]: Epoch 173 - training loss: 0.2630, validation loss: 0.1101
2024-05-23 20:59:21 [INFO]: Epoch 174 - training loss: 0.2632, validation loss: 0.1099
2024-05-23 20:59:23 [INFO]: Epoch 175 - training loss: 0.2626, validation loss: 0.1097
2024-05-23 20:59:26 [INFO]: Epoch 176 - training loss: 0.2627, validation loss: 0.1095
2024-05-23 20:59:28 [INFO]: Epoch 177 - training loss: 0.2622, validation loss: 0.1092
2024-05-23 20:59:31 [INFO]: Epoch 178 - training loss: 0.2625, validation loss: 0.1087
2024-05-23 20:59:33 [INFO]: Epoch 179 - training loss: 0.2617, validation loss: 0.1087
2024-05-23 20:59:36 [INFO]: Epoch 180 - training loss: 0.2614, validation loss: 0.1085
2024-05-23 20:59:38 [INFO]: Epoch 181 - training loss: 0.2619, validation loss: 0.1081
2024-05-23 20:59:41 [INFO]: Epoch 182 - training loss: 0.2615, validation loss: 0.1082
2024-05-23 20:59:43 [INFO]: Epoch 183 - training loss: 0.2608, validation loss: 0.1077
2024-05-23 20:59:46 [INFO]: Epoch 184 - training loss: 0.2609, validation loss: 0.1075
2024-05-23 20:59:48 [INFO]: Epoch 185 - training loss: 0.2606, validation loss: 0.1073
2024-05-23 20:59:51 [INFO]: Epoch 186 - training loss: 0.2601, validation loss: 0.1073
2024-05-23 20:59:53 [INFO]: Epoch 187 - training loss: 0.2598, validation loss: 0.1068
2024-05-23 20:59:55 [INFO]: Epoch 188 - training loss: 0.2594, validation loss: 0.1067
2024-05-23 20:59:58 [INFO]: Epoch 189 - training loss: 0.2591, validation loss: 0.1063
2024-05-23 21:00:00 [INFO]: Epoch 190 - training loss: 0.2594, validation loss: 0.1063
2024-05-23 21:00:03 [INFO]: Epoch 191 - training loss: 0.2591, validation loss: 0.1063
2024-05-23 21:00:05 [INFO]: Epoch 192 - training loss: 0.2592, validation loss: 0.1059
2024-05-23 21:00:08 [INFO]: Epoch 193 - training loss: 0.2590, validation loss: 0.1056
2024-05-23 21:00:10 [INFO]: Epoch 194 - training loss: 0.2585, validation loss: 0.1057
2024-05-23 21:00:13 [INFO]: Epoch 195 - training loss: 0.2580, validation loss: 0.1052
2024-05-23 21:00:15 [INFO]: Epoch 196 - training loss: 0.2576, validation loss: 0.1051
2024-05-23 21:00:18 [INFO]: Epoch 197 - training loss: 0.2575, validation loss: 0.1049
2024-05-23 21:00:20 [INFO]: Epoch 198 - training loss: 0.2575, validation loss: 0.1047
2024-05-23 21:00:23 [INFO]: Epoch 199 - training loss: 0.2568, validation loss: 0.1046
2024-05-23 21:00:25 [INFO]: Epoch 200 - training loss: 0.2571, validation loss: 0.1043
2024-05-23 21:00:28 [INFO]: Epoch 201 - training loss: 0.2566, validation loss: 0.1043
2024-05-23 21:00:30 [INFO]: Epoch 202 - training loss: 0.2563, validation loss: 0.1042
2024-05-23 21:00:33 [INFO]: Epoch 203 - training loss: 0.2562, validation loss: 0.1037
2024-05-23 21:00:35 [INFO]: Epoch 204 - training loss: 0.2572, validation loss: 0.1036
2024-05-23 21:00:38 [INFO]: Epoch 205 - training loss: 0.2557, validation loss: 0.1031
2024-05-23 21:00:40 [INFO]: Epoch 206 - training loss: 0.2557, validation loss: 0.1030
2024-05-23 21:00:43 [INFO]: Epoch 207 - training loss: 0.2565, validation loss: 0.1032
2024-05-23 21:00:45 [INFO]: Epoch 208 - training loss: 0.2551, validation loss: 0.1025
2024-05-23 21:00:47 [INFO]: Epoch 209 - training loss: 0.2551, validation loss: 0.1027
2024-05-23 21:00:50 [INFO]: Epoch 210 - training loss: 0.2546, validation loss: 0.1024
2024-05-23 21:00:52 [INFO]: Epoch 211 - training loss: 0.2548, validation loss: 0.1023
2024-05-23 21:00:54 [INFO]: Epoch 212 - training loss: 0.2542, validation loss: 0.1023
2024-05-23 21:00:57 [INFO]: Epoch 213 - training loss: 0.2544, validation loss: 0.1017
2024-05-23 21:00:59 [INFO]: Epoch 214 - training loss: 0.2540, validation loss: 0.1018
2024-05-23 21:01:02 [INFO]: Epoch 215 - training loss: 0.2539, validation loss: 0.1016
2024-05-23 21:01:05 [INFO]: Epoch 216 - training loss: 0.2541, validation loss: 0.1015
2024-05-23 21:01:07 [INFO]: Epoch 217 - training loss: 0.2536, validation loss: 0.1011
2024-05-23 21:01:09 [INFO]: Epoch 218 - training loss: 0.2531, validation loss: 0.1010
2024-05-23 21:01:12 [INFO]: Epoch 219 - training loss: 0.2535, validation loss: 0.1009
2024-05-23 21:01:14 [INFO]: Epoch 220 - training loss: 0.2531, validation loss: 0.1007
2024-05-23 21:01:16 [INFO]: Epoch 221 - training loss: 0.2527, validation loss: 0.1006
2024-05-23 21:01:19 [INFO]: Epoch 222 - training loss: 0.2526, validation loss: 0.1005
2024-05-23 21:01:21 [INFO]: Epoch 223 - training loss: 0.2525, validation loss: 0.1003
2024-05-23 21:01:23 [INFO]: Epoch 224 - training loss: 0.2524, validation loss: 0.1002
2024-05-23 21:01:26 [INFO]: Epoch 225 - training loss: 0.2518, validation loss: 0.1001
2024-05-23 21:01:28 [INFO]: Epoch 226 - training loss: 0.2520, validation loss: 0.0999
2024-05-23 21:01:30 [INFO]: Epoch 227 - training loss: 0.2514, validation loss: 0.0999
2024-05-23 21:01:32 [INFO]: Epoch 228 - training loss: 0.2513, validation loss: 0.0995
2024-05-23 21:01:35 [INFO]: Epoch 229 - training loss: 0.2514, validation loss: 0.0994
2024-05-23 21:01:37 [INFO]: Epoch 230 - training loss: 0.2512, validation loss: 0.0992
2024-05-23 21:01:39 [INFO]: Epoch 231 - training loss: 0.2510, validation loss: 0.0994
2024-05-23 21:01:41 [INFO]: Epoch 232 - training loss: 0.2506, validation loss: 0.0991
2024-05-23 21:01:43 [INFO]: Epoch 233 - training loss: 0.2508, validation loss: 0.0989
2024-05-23 21:01:46 [INFO]: Epoch 234 - training loss: 0.2503, validation loss: 0.0988
2024-05-23 21:01:48 [INFO]: Epoch 235 - training loss: 0.2502, validation loss: 0.0986
2024-05-23 21:01:50 [INFO]: Epoch 236 - training loss: 0.2500, validation loss: 0.0985
2024-05-23 21:01:52 [INFO]: Epoch 237 - training loss: 0.2501, validation loss: 0.0984
2024-05-23 21:01:54 [INFO]: Epoch 238 - training loss: 0.2493, validation loss: 0.0983
2024-05-23 21:01:56 [INFO]: Epoch 239 - training loss: 0.2498, validation loss: 0.0981
2024-05-23 21:01:59 [INFO]: Epoch 240 - training loss: 0.2496, validation loss: 0.0980
2024-05-23 21:02:01 [INFO]: Epoch 241 - training loss: 0.2492, validation loss: 0.0979
2024-05-23 21:02:03 [INFO]: Epoch 242 - training loss: 0.2497, validation loss: 0.0977
2024-05-23 21:02:05 [INFO]: Epoch 243 - training loss: 0.2489, validation loss: 0.0976
2024-05-23 21:02:07 [INFO]: Epoch 244 - training loss: 0.2493, validation loss: 0.0976
2024-05-23 21:02:10 [INFO]: Epoch 245 - training loss: 0.2488, validation loss: 0.0973
2024-05-23 21:02:12 [INFO]: Epoch 246 - training loss: 0.2483, validation loss: 0.0974
2024-05-23 21:02:14 [INFO]: Epoch 247 - training loss: 0.2489, validation loss: 0.0971
2024-05-23 21:02:16 [INFO]: Epoch 248 - training loss: 0.2481, validation loss: 0.0971
2024-05-23 21:02:19 [INFO]: Epoch 249 - training loss: 0.2478, validation loss: 0.0970
2024-05-23 21:02:21 [INFO]: Epoch 250 - training loss: 0.2472, validation loss: 0.0969
2024-05-23 21:02:23 [INFO]: Epoch 251 - training loss: 0.2474, validation loss: 0.0969
2024-05-23 21:02:25 [INFO]: Epoch 252 - training loss: 0.2474, validation loss: 0.0965
2024-05-23 21:02:27 [INFO]: Epoch 253 - training loss: 0.2473, validation loss: 0.0965
2024-05-23 21:02:30 [INFO]: Epoch 254 - training loss: 0.2470, validation loss: 0.0963
2024-05-23 21:02:32 [INFO]: Epoch 255 - training loss: 0.2470, validation loss: 0.0962
2024-05-23 21:02:34 [INFO]: Epoch 256 - training loss: 0.2466, validation loss: 0.0960
2024-05-23 21:02:36 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0960
2024-05-23 21:02:38 [INFO]: Epoch 258 - training loss: 0.2464, validation loss: 0.0959
2024-05-23 21:02:41 [INFO]: Epoch 259 - training loss: 0.2463, validation loss: 0.0959
2024-05-23 21:02:43 [INFO]: Epoch 260 - training loss: 0.2461, validation loss: 0.0959
2024-05-23 21:02:45 [INFO]: Epoch 261 - training loss: 0.2459, validation loss: 0.0956
2024-05-23 21:02:47 [INFO]: Epoch 262 - training loss: 0.2463, validation loss: 0.0954
2024-05-23 21:02:49 [INFO]: Epoch 263 - training loss: 0.2456, validation loss: 0.0952
2024-05-23 21:02:52 [INFO]: Epoch 264 - training loss: 0.2456, validation loss: 0.0953
2024-05-23 21:02:54 [INFO]: Epoch 265 - training loss: 0.2460, validation loss: 0.0952
2024-05-23 21:02:56 [INFO]: Epoch 266 - training loss: 0.2452, validation loss: 0.0951
2024-05-23 21:02:58 [INFO]: Epoch 267 - training loss: 0.2453, validation loss: 0.0949
2024-05-23 21:03:00 [INFO]: Epoch 268 - training loss: 0.2449, validation loss: 0.0949
2024-05-23 21:03:03 [INFO]: Epoch 269 - training loss: 0.2448, validation loss: 0.0948
2024-05-23 21:03:05 [INFO]: Epoch 270 - training loss: 0.2454, validation loss: 0.0945
2024-05-23 21:03:07 [INFO]: Epoch 271 - training loss: 0.2444, validation loss: 0.0944
2024-05-23 21:03:09 [INFO]: Epoch 272 - training loss: 0.2445, validation loss: 0.0944
2024-05-23 21:03:11 [INFO]: Epoch 273 - training loss: 0.2443, validation loss: 0.0943
2024-05-23 21:03:14 [INFO]: Epoch 274 - training loss: 0.2440, validation loss: 0.0941
2024-05-23 21:03:16 [INFO]: Epoch 275 - training loss: 0.2444, validation loss: 0.0941
2024-05-23 21:03:18 [INFO]: Epoch 276 - training loss: 0.2441, validation loss: 0.0941
2024-05-23 21:03:20 [INFO]: Epoch 277 - training loss: 0.2442, validation loss: 0.0939
2024-05-23 21:03:22 [INFO]: Epoch 278 - training loss: 0.2436, validation loss: 0.0939
2024-05-23 21:03:24 [INFO]: Epoch 279 - training loss: 0.2433, validation loss: 0.0938
2024-05-23 21:03:27 [INFO]: Epoch 280 - training loss: 0.2430, validation loss: 0.0936
2024-05-23 21:03:29 [INFO]: Epoch 281 - training loss: 0.2437, validation loss: 0.0935
2024-05-23 21:03:31 [INFO]: Epoch 282 - training loss: 0.2433, validation loss: 0.0934
2024-05-23 21:03:33 [INFO]: Epoch 283 - training loss: 0.2433, validation loss: 0.0936
2024-05-23 21:03:35 [INFO]: Epoch 284 - training loss: 0.2430, validation loss: 0.0931
2024-05-23 21:03:38 [INFO]: Epoch 285 - training loss: 0.2432, validation loss: 0.0932
2024-05-23 21:03:40 [INFO]: Epoch 286 - training loss: 0.2425, validation loss: 0.0932
2024-05-23 21:03:42 [INFO]: Epoch 287 - training loss: 0.2431, validation loss: 0.0931
2024-05-23 21:03:44 [INFO]: Epoch 288 - training loss: 0.2425, validation loss: 0.0932
2024-05-23 21:03:46 [INFO]: Epoch 289 - training loss: 0.2427, validation loss: 0.0932
2024-05-23 21:03:49 [INFO]: Epoch 290 - training loss: 0.2430, validation loss: 0.0927
2024-05-23 21:03:51 [INFO]: Epoch 291 - training loss: 0.2425, validation loss: 0.0927
2024-05-23 21:03:53 [INFO]: Epoch 292 - training loss: 0.2419, validation loss: 0.0927
2024-05-23 21:03:55 [INFO]: Epoch 293 - training loss: 0.2419, validation loss: 0.0927
2024-05-23 21:03:57 [INFO]: Epoch 294 - training loss: 0.2417, validation loss: 0.0925
2024-05-23 21:04:00 [INFO]: Epoch 295 - training loss: 0.2418, validation loss: 0.0924
2024-05-23 21:04:02 [INFO]: Epoch 296 - training loss: 0.2423, validation loss: 0.0924
2024-05-23 21:04:04 [INFO]: Epoch 297 - training loss: 0.2414, validation loss: 0.0925
2024-05-23 21:04:06 [INFO]: Epoch 298 - training loss: 0.2416, validation loss: 0.0921
2024-05-23 21:04:08 [INFO]: Epoch 299 - training loss: 0.2416, validation loss: 0.0922
2024-05-23 21:04:11 [INFO]: Epoch 300 - training loss: 0.2407, validation loss: 0.0920
2024-05-23 21:04:11 [INFO]: Finished training. The best model is from epoch#300.
2024-05-23 21:04:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240523_T205225/BRITS.pypots
2024-05-23 21:04:11 [INFO]: BRITS on Air-Quality: MAE=0.1417, MSE=0.1287
2024-05-23 21:04:11 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-23 21:04:11 [INFO]: Using the given device: cuda:0
2024-05-23 21:04:11 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411
2024-05-23 21:04:11 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/tensorboard
2024-05-23 21:04:11 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 21:04:15 [INFO]: Epoch 001 - training loss: 1.4734, validation loss: 0.8269
2024-05-23 21:04:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch1_loss0.8268927961587906.pypots
2024-05-23 21:04:18 [INFO]: Epoch 002 - training loss: 1.0638, validation loss: 0.7690
2024-05-23 21:04:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch2_loss0.7690050512552261.pypots
2024-05-23 21:04:21 [INFO]: Epoch 003 - training loss: 0.9814, validation loss: 0.7429
2024-05-23 21:04:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch3_loss0.7428810387849808.pypots
2024-05-23 21:04:24 [INFO]: Epoch 004 - training loss: 0.9467, validation loss: 0.7264
2024-05-23 21:04:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch4_loss0.7264210492372513.pypots
2024-05-23 21:04:27 [INFO]: Epoch 005 - training loss: 0.9352, validation loss: 0.7157
2024-05-23 21:04:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch5_loss0.7157172054052353.pypots
2024-05-23 21:04:30 [INFO]: Epoch 006 - training loss: 0.9350, validation loss: 0.7094
2024-05-23 21:04:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch6_loss0.7093507289886475.pypots
2024-05-23 21:04:33 [INFO]: Epoch 007 - training loss: 0.9223, validation loss: 0.7050
2024-05-23 21:04:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch7_loss0.7050131261348724.pypots
2024-05-23 21:04:36 [INFO]: Epoch 008 - training loss: 0.8980, validation loss: 0.7004
2024-05-23 21:04:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch8_loss0.7003663659095765.pypots
2024-05-23 21:04:39 [INFO]: Epoch 009 - training loss: 0.9099, validation loss: 0.6967
2024-05-23 21:04:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch9_loss0.696725657582283.pypots
2024-05-23 21:04:42 [INFO]: Epoch 010 - training loss: 0.8936, validation loss: 0.6951
2024-05-23 21:04:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch10_loss0.6950752526521683.pypots
2024-05-23 21:04:45 [INFO]: Epoch 011 - training loss: 0.8725, validation loss: 0.6929
2024-05-23 21:04:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch11_loss0.6929220914840698.pypots
2024-05-23 21:04:48 [INFO]: Epoch 012 - training loss: 0.8781, validation loss: 0.6913
2024-05-23 21:04:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch12_loss0.6913012444972992.pypots
2024-05-23 21:04:51 [INFO]: Epoch 013 - training loss: 0.8894, validation loss: 0.6900
2024-05-23 21:04:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch13_loss0.6900331288576126.pypots
2024-05-23 21:04:54 [INFO]: Epoch 014 - training loss: 0.8722, validation loss: 0.6888
2024-05-23 21:04:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch14_loss0.6888179749250412.pypots
2024-05-23 21:04:57 [INFO]: Epoch 015 - training loss: 0.8755, validation loss: 0.6879
2024-05-23 21:04:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch15_loss0.6879007786512374.pypots
2024-05-23 21:05:00 [INFO]: Epoch 016 - training loss: 0.8755, validation loss: 0.6870
2024-05-23 21:05:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch16_loss0.6870489239692688.pypots
2024-05-23 21:05:03 [INFO]: Epoch 017 - training loss: 0.8611, validation loss: 0.6867
2024-05-23 21:05:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch17_loss0.686698979139328.pypots
2024-05-23 21:05:06 [INFO]: Epoch 018 - training loss: 0.8733, validation loss: 0.6862
2024-05-23 21:05:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch18_loss0.6861541986465454.pypots
2024-05-23 21:05:09 [INFO]: Epoch 019 - training loss: 0.8557, validation loss: 0.6874
2024-05-23 21:05:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch19_loss0.687414926290512.pypots
2024-05-23 21:05:12 [INFO]: Epoch 020 - training loss: 0.8562, validation loss: 0.6864
2024-05-23 21:05:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch20_loss0.6864489555358887.pypots
2024-05-23 21:05:15 [INFO]: Epoch 021 - training loss: 0.8549, validation loss: 0.6856
2024-05-23 21:05:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch21_loss0.6856466352939605.pypots
2024-05-23 21:05:18 [INFO]: Epoch 022 - training loss: 0.8565, validation loss: 0.6862
2024-05-23 21:05:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch22_loss0.6862292170524598.pypots
2024-05-23 21:05:21 [INFO]: Epoch 023 - training loss: 0.8600, validation loss: 0.6863
2024-05-23 21:05:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch23_loss0.6862752616405488.pypots
2024-05-23 21:05:24 [INFO]: Epoch 024 - training loss: 0.8697, validation loss: 0.6855
2024-05-23 21:05:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch24_loss0.6855336099863052.pypots
2024-05-23 21:05:27 [INFO]: Epoch 025 - training loss: 0.8459, validation loss: 0.6860
2024-05-23 21:05:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch25_loss0.6860012412071228.pypots
2024-05-23 21:05:30 [INFO]: Epoch 026 - training loss: 0.8385, validation loss: 0.6850
2024-05-23 21:05:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch26_loss0.6850218772888184.pypots
2024-05-23 21:05:33 [INFO]: Epoch 027 - training loss: 0.8356, validation loss: 0.6891
2024-05-23 21:05:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch27_loss0.6890955567359924.pypots
2024-05-23 21:05:36 [INFO]: Epoch 028 - training loss: 0.8417, validation loss: 0.6845
2024-05-23 21:05:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch28_loss0.6844827175140381.pypots
2024-05-23 21:05:39 [INFO]: Epoch 029 - training loss: 0.8391, validation loss: 0.6851
2024-05-23 21:05:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch29_loss0.6851465255022049.pypots
2024-05-23 21:05:42 [INFO]: Epoch 030 - training loss: 0.8405, validation loss: 0.6872
2024-05-23 21:05:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch30_loss0.6871569693088532.pypots
2024-05-23 21:05:45 [INFO]: Epoch 031 - training loss: 0.8486, validation loss: 0.6862
2024-05-23 21:05:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch31_loss0.6861503571271896.pypots
2024-05-23 21:05:48 [INFO]: Epoch 032 - training loss: 0.8384, validation loss: 0.6865
2024-05-23 21:05:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch32_loss0.6864955097436904.pypots
2024-05-23 21:05:51 [INFO]: Epoch 033 - training loss: 0.8415, validation loss: 0.6863
2024-05-23 21:05:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch33_loss0.6862762868404388.pypots
2024-05-23 21:05:54 [INFO]: Epoch 034 - training loss: 0.8300, validation loss: 0.6862
2024-05-23 21:05:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch34_loss0.6861820071935654.pypots
2024-05-23 21:05:57 [INFO]: Epoch 035 - training loss: 0.8274, validation loss: 0.6864
2024-05-23 21:05:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch35_loss0.686419865489006.pypots
2024-05-23 21:06:00 [INFO]: Epoch 036 - training loss: 0.8279, validation loss: 0.6872
2024-05-23 21:06:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch36_loss0.6871703416109085.pypots
2024-05-23 21:06:03 [INFO]: Epoch 037 - training loss: 0.8139, validation loss: 0.6859
2024-05-23 21:06:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch37_loss0.68585584461689.pypots
2024-05-23 21:06:06 [INFO]: Epoch 038 - training loss: 0.8185, validation loss: 0.6868
2024-05-23 21:06:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN_epoch38_loss0.6868114173412323.pypots
2024-05-23 21:06:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:06:06 [INFO]: Finished training. The best model is from epoch#28.
2024-05-23 21:06:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240523_T210411/MRNN.pypots
2024-05-23 21:06:07 [INFO]: MRNN on Air-Quality: MAE=0.5189, MSE=0.6569
2024-05-23 21:06:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-23 21:06:07 [INFO]: Using the given device: cpu
2024-05-23 21:06:07 [INFO]: LOCF on Air-Quality: MAE=0.2050, MSE=0.3453
2024-05-23 21:06:07 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-23 21:06:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-23 21:06:07 [INFO]: Median on Air-Quality: MAE=0.6635, MSE=1.0575
2024-05-23 21:06:07 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-23 21:06:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-23 21:06:07 [INFO]: Mean on Air-Quality: MAE=0.6949, MSE=0.9966
2024-05-23 21:06:07 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-23 21:06:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-23 21:06:07 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-23 21:06:07 [INFO]: Using the given device: cuda:0
2024-05-23 21:06:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240523_T210607
2024-05-23 21:06:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240523_T210607/tensorboard
2024-05-23 21:06:07 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 21:06:08 [INFO]: Epoch 001 - training loss: 1.0445, validation loss: 0.5143
2024-05-23 21:06:08 [INFO]: Epoch 002 - training loss: 0.7442, validation loss: 0.3947
2024-05-23 21:06:09 [INFO]: Epoch 003 - training loss: 0.6372, validation loss: 0.3163
2024-05-23 21:06:09 [INFO]: Epoch 004 - training loss: 0.5633, validation loss: 0.2772
2024-05-23 21:06:10 [INFO]: Epoch 005 - training loss: 0.5096, validation loss: 0.2563
2024-05-23 21:06:11 [INFO]: Epoch 006 - training loss: 0.4716, validation loss: 0.2405
2024-05-23 21:06:11 [INFO]: Epoch 007 - training loss: 0.4459, validation loss: 0.2320
2024-05-23 21:06:12 [INFO]: Epoch 008 - training loss: 0.4281, validation loss: 0.2242
2024-05-23 21:06:12 [INFO]: Epoch 009 - training loss: 0.4139, validation loss: 0.2180
2024-05-23 21:06:13 [INFO]: Epoch 010 - training loss: 0.4010, validation loss: 0.2123
2024-05-23 21:06:13 [INFO]: Epoch 011 - training loss: 0.3930, validation loss: 0.2081
2024-05-23 21:06:14 [INFO]: Epoch 012 - training loss: 0.3852, validation loss: 0.2057
2024-05-23 21:06:15 [INFO]: Epoch 013 - training loss: 0.3747, validation loss: 0.2015
2024-05-23 21:06:15 [INFO]: Epoch 014 - training loss: 0.3685, validation loss: 0.1974
2024-05-23 21:06:16 [INFO]: Epoch 015 - training loss: 0.3639, validation loss: 0.1954
2024-05-23 21:06:16 [INFO]: Epoch 016 - training loss: 0.3562, validation loss: 0.1917
2024-05-23 21:06:17 [INFO]: Epoch 017 - training loss: 0.3531, validation loss: 0.1899
2024-05-23 21:06:18 [INFO]: Epoch 018 - training loss: 0.3466, validation loss: 0.1873
2024-05-23 21:06:18 [INFO]: Epoch 019 - training loss: 0.3422, validation loss: 0.1860
2024-05-23 21:06:19 [INFO]: Epoch 020 - training loss: 0.3386, validation loss: 0.1848
2024-05-23 21:06:19 [INFO]: Epoch 021 - training loss: 0.3340, validation loss: 0.1815
2024-05-23 21:06:20 [INFO]: Epoch 022 - training loss: 0.3323, validation loss: 0.1792
2024-05-23 21:06:20 [INFO]: Epoch 023 - training loss: 0.3267, validation loss: 0.1776
2024-05-23 21:06:21 [INFO]: Epoch 024 - training loss: 0.3234, validation loss: 0.1775
2024-05-23 21:06:22 [INFO]: Epoch 025 - training loss: 0.3210, validation loss: 0.1747
2024-05-23 21:06:22 [INFO]: Epoch 026 - training loss: 0.3181, validation loss: 0.1728
2024-05-23 21:06:23 [INFO]: Epoch 027 - training loss: 0.3148, validation loss: 0.1721
2024-05-23 21:06:23 [INFO]: Epoch 028 - training loss: 0.3131, validation loss: 0.1715
2024-05-23 21:06:24 [INFO]: Epoch 029 - training loss: 0.3119, validation loss: 0.1692
2024-05-23 21:06:24 [INFO]: Epoch 030 - training loss: 0.3078, validation loss: 0.1686
2024-05-23 21:06:25 [INFO]: Epoch 031 - training loss: 0.3064, validation loss: 0.1665
2024-05-23 21:06:26 [INFO]: Epoch 032 - training loss: 0.3032, validation loss: 0.1656
2024-05-23 21:06:26 [INFO]: Epoch 033 - training loss: 0.3008, validation loss: 0.1654
2024-05-23 21:06:27 [INFO]: Epoch 034 - training loss: 0.2996, validation loss: 0.1633
2024-05-23 21:06:27 [INFO]: Epoch 035 - training loss: 0.2972, validation loss: 0.1619
2024-05-23 21:06:28 [INFO]: Epoch 036 - training loss: 0.2941, validation loss: 0.1606
2024-05-23 21:06:28 [INFO]: Epoch 037 - training loss: 0.2923, validation loss: 0.1594
2024-05-23 21:06:29 [INFO]: Epoch 038 - training loss: 0.2906, validation loss: 0.1589
2024-05-23 21:06:30 [INFO]: Epoch 039 - training loss: 0.2891, validation loss: 0.1570
2024-05-23 21:06:30 [INFO]: Epoch 040 - training loss: 0.2874, validation loss: 0.1558
2024-05-23 21:06:31 [INFO]: Epoch 041 - training loss: 0.2859, validation loss: 0.1545
2024-05-23 21:06:31 [INFO]: Epoch 042 - training loss: 0.2833, validation loss: 0.1541
2024-05-23 21:06:32 [INFO]: Epoch 043 - training loss: 0.2815, validation loss: 0.1536
2024-05-23 21:06:32 [INFO]: Epoch 044 - training loss: 0.2800, validation loss: 0.1518
2024-05-23 21:06:33 [INFO]: Epoch 045 - training loss: 0.2789, validation loss: 0.1506
2024-05-23 21:06:34 [INFO]: Epoch 046 - training loss: 0.2765, validation loss: 0.1512
2024-05-23 21:06:34 [INFO]: Epoch 047 - training loss: 0.2758, validation loss: 0.1504
2024-05-23 21:06:35 [INFO]: Epoch 048 - training loss: 0.2735, validation loss: 0.1485
2024-05-23 21:06:35 [INFO]: Epoch 049 - training loss: 0.2720, validation loss: 0.1485
2024-05-23 21:06:36 [INFO]: Epoch 050 - training loss: 0.2708, validation loss: 0.1466
2024-05-23 21:06:36 [INFO]: Epoch 051 - training loss: 0.2695, validation loss: 0.1462
2024-05-23 21:06:37 [INFO]: Epoch 052 - training loss: 0.2695, validation loss: 0.1459
2024-05-23 21:06:38 [INFO]: Epoch 053 - training loss: 0.2660, validation loss: 0.1451
2024-05-23 21:06:38 [INFO]: Epoch 054 - training loss: 0.2643, validation loss: 0.1444
2024-05-23 21:06:39 [INFO]: Epoch 055 - training loss: 0.2633, validation loss: 0.1441
2024-05-23 21:06:39 [INFO]: Epoch 056 - training loss: 0.2634, validation loss: 0.1442
2024-05-23 21:06:40 [INFO]: Epoch 057 - training loss: 0.2612, validation loss: 0.1434
2024-05-23 21:06:41 [INFO]: Epoch 058 - training loss: 0.2592, validation loss: 0.1428
2024-05-23 21:06:41 [INFO]: Epoch 059 - training loss: 0.2576, validation loss: 0.1423
2024-05-23 21:06:42 [INFO]: Epoch 060 - training loss: 0.2557, validation loss: 0.1413
2024-05-23 21:06:42 [INFO]: Epoch 061 - training loss: 0.2549, validation loss: 0.1406
2024-05-23 21:06:43 [INFO]: Epoch 062 - training loss: 0.2539, validation loss: 0.1402
2024-05-23 21:06:43 [INFO]: Epoch 063 - training loss: 0.2538, validation loss: 0.1408
2024-05-23 21:06:44 [INFO]: Epoch 064 - training loss: 0.2513, validation loss: 0.1391
2024-05-23 21:06:45 [INFO]: Epoch 065 - training loss: 0.2497, validation loss: 0.1394
2024-05-23 21:06:45 [INFO]: Epoch 066 - training loss: 0.2490, validation loss: 0.1387
2024-05-23 21:06:46 [INFO]: Epoch 067 - training loss: 0.2481, validation loss: 0.1390
2024-05-23 21:06:46 [INFO]: Epoch 068 - training loss: 0.2475, validation loss: 0.1369
2024-05-23 21:06:47 [INFO]: Epoch 069 - training loss: 0.2471, validation loss: 0.1386
2024-05-23 21:06:48 [INFO]: Epoch 070 - training loss: 0.2455, validation loss: 0.1375
2024-05-23 21:06:48 [INFO]: Epoch 071 - training loss: 0.2435, validation loss: 0.1370
2024-05-23 21:06:49 [INFO]: Epoch 072 - training loss: 0.2437, validation loss: 0.1376
2024-05-23 21:06:49 [INFO]: Epoch 073 - training loss: 0.2425, validation loss: 0.1371
2024-05-23 21:06:50 [INFO]: Epoch 074 - training loss: 0.2402, validation loss: 0.1360
2024-05-23 21:06:50 [INFO]: Epoch 075 - training loss: 0.2397, validation loss: 0.1355
2024-05-23 21:06:51 [INFO]: Epoch 076 - training loss: 0.2385, validation loss: 0.1356
2024-05-23 21:06:52 [INFO]: Epoch 077 - training loss: 0.2373, validation loss: 0.1345
2024-05-23 21:06:52 [INFO]: Epoch 078 - training loss: 0.2371, validation loss: 0.1346
2024-05-23 21:06:53 [INFO]: Epoch 079 - training loss: 0.2360, validation loss: 0.1348
2024-05-23 21:06:53 [INFO]: Epoch 080 - training loss: 0.2352, validation loss: 0.1350
2024-05-23 21:06:54 [INFO]: Epoch 081 - training loss: 0.2333, validation loss: 0.1342
2024-05-23 21:06:54 [INFO]: Epoch 082 - training loss: 0.2335, validation loss: 0.1352
2024-05-23 21:06:55 [INFO]: Epoch 083 - training loss: 0.2341, validation loss: 0.1351
2024-05-23 21:06:56 [INFO]: Epoch 084 - training loss: 0.2331, validation loss: 0.1338
2024-05-23 21:06:56 [INFO]: Epoch 085 - training loss: 0.2317, validation loss: 0.1334
2024-05-23 21:06:57 [INFO]: Epoch 086 - training loss: 0.2301, validation loss: 0.1333
2024-05-23 21:06:57 [INFO]: Epoch 087 - training loss: 0.2291, validation loss: 0.1324
2024-05-23 21:06:58 [INFO]: Epoch 088 - training loss: 0.2284, validation loss: 0.1335
2024-05-23 21:06:58 [INFO]: Epoch 089 - training loss: 0.2277, validation loss: 0.1321
2024-05-23 21:06:59 [INFO]: Epoch 090 - training loss: 0.2281, validation loss: 0.1321
2024-05-23 21:07:00 [INFO]: Epoch 091 - training loss: 0.2269, validation loss: 0.1333
2024-05-23 21:07:00 [INFO]: Epoch 092 - training loss: 0.2275, validation loss: 0.1325
2024-05-23 21:07:01 [INFO]: Epoch 093 - training loss: 0.2251, validation loss: 0.1311
2024-05-23 21:07:01 [INFO]: Epoch 094 - training loss: 0.2245, validation loss: 0.1318
2024-05-23 21:07:02 [INFO]: Epoch 095 - training loss: 0.2242, validation loss: 0.1318
2024-05-23 21:07:02 [INFO]: Epoch 096 - training loss: 0.2230, validation loss: 0.1319
2024-05-23 21:07:03 [INFO]: Epoch 097 - training loss: 0.2235, validation loss: 0.1313
2024-05-23 21:07:04 [INFO]: Epoch 098 - training loss: 0.2235, validation loss: 0.1311
2024-05-23 21:07:04 [INFO]: Epoch 099 - training loss: 0.2226, validation loss: 0.1306
2024-05-23 21:07:05 [INFO]: Epoch 100 - training loss: 0.2206, validation loss: 0.1295
2024-05-23 21:07:05 [INFO]: Epoch 101 - training loss: 0.2194, validation loss: 0.1297
2024-05-23 21:07:06 [INFO]: Epoch 102 - training loss: 0.2191, validation loss: 0.1304
2024-05-23 21:07:06 [INFO]: Epoch 103 - training loss: 0.2187, validation loss: 0.1298
2024-05-23 21:07:07 [INFO]: Epoch 104 - training loss: 0.2178, validation loss: 0.1298
2024-05-23 21:07:08 [INFO]: Epoch 105 - training loss: 0.2182, validation loss: 0.1289
2024-05-23 21:07:08 [INFO]: Epoch 106 - training loss: 0.2179, validation loss: 0.1301
2024-05-23 21:07:09 [INFO]: Epoch 107 - training loss: 0.2165, validation loss: 0.1289
2024-05-23 21:07:09 [INFO]: Epoch 108 - training loss: 0.2157, validation loss: 0.1303
2024-05-23 21:07:10 [INFO]: Epoch 109 - training loss: 0.2151, validation loss: 0.1288
2024-05-23 21:07:10 [INFO]: Epoch 110 - training loss: 0.2158, validation loss: 0.1275
2024-05-23 21:07:11 [INFO]: Epoch 111 - training loss: 0.2146, validation loss: 0.1293
2024-05-23 21:07:12 [INFO]: Epoch 112 - training loss: 0.2140, validation loss: 0.1291
2024-05-23 21:07:12 [INFO]: Epoch 113 - training loss: 0.2176, validation loss: 0.1280
2024-05-23 21:07:13 [INFO]: Epoch 114 - training loss: 0.2138, validation loss: 0.1273
2024-05-23 21:07:13 [INFO]: Epoch 115 - training loss: 0.2118, validation loss: 0.1280
2024-05-23 21:07:14 [INFO]: Epoch 116 - training loss: 0.2108, validation loss: 0.1280
2024-05-23 21:07:15 [INFO]: Epoch 117 - training loss: 0.2109, validation loss: 0.1272
2024-05-23 21:07:15 [INFO]: Epoch 118 - training loss: 0.2104, validation loss: 0.1277
2024-05-23 21:07:16 [INFO]: Epoch 119 - training loss: 0.2091, validation loss: 0.1280
2024-05-23 21:07:16 [INFO]: Epoch 120 - training loss: 0.2083, validation loss: 0.1285
2024-05-23 21:07:17 [INFO]: Epoch 121 - training loss: 0.2077, validation loss: 0.1277
2024-05-23 21:07:17 [INFO]: Epoch 122 - training loss: 0.2071, validation loss: 0.1267
2024-05-23 21:07:18 [INFO]: Epoch 123 - training loss: 0.2076, validation loss: 0.1280
2024-05-23 21:07:19 [INFO]: Epoch 124 - training loss: 0.2077, validation loss: 0.1265
2024-05-23 21:07:19 [INFO]: Epoch 125 - training loss: 0.2062, validation loss: 0.1277
2024-05-23 21:07:20 [INFO]: Epoch 126 - training loss: 0.2054, validation loss: 0.1265
2024-05-23 21:07:21 [INFO]: Epoch 127 - training loss: 0.2056, validation loss: 0.1263
2024-05-23 21:07:21 [INFO]: Epoch 128 - training loss: 0.2050, validation loss: 0.1262
2024-05-23 21:07:22 [INFO]: Epoch 129 - training loss: 0.2043, validation loss: 0.1258
2024-05-23 21:07:22 [INFO]: Epoch 130 - training loss: 0.2038, validation loss: 0.1261
2024-05-23 21:07:23 [INFO]: Epoch 131 - training loss: 0.2034, validation loss: 0.1256
2024-05-23 21:07:23 [INFO]: Epoch 132 - training loss: 0.2037, validation loss: 0.1248
2024-05-23 21:07:24 [INFO]: Epoch 133 - training loss: 0.2031, validation loss: 0.1254
2024-05-23 21:07:25 [INFO]: Epoch 134 - training loss: 0.2043, validation loss: 0.1254
2024-05-23 21:07:25 [INFO]: Epoch 135 - training loss: 0.2037, validation loss: 0.1260
2024-05-23 21:07:26 [INFO]: Epoch 136 - training loss: 0.2026, validation loss: 0.1255
2024-05-23 21:07:26 [INFO]: Epoch 137 - training loss: 0.2018, validation loss: 0.1244
2024-05-23 21:07:27 [INFO]: Epoch 138 - training loss: 0.2009, validation loss: 0.1242
2024-05-23 21:07:28 [INFO]: Epoch 139 - training loss: 0.2002, validation loss: 0.1249
2024-05-23 21:07:28 [INFO]: Epoch 140 - training loss: 0.1993, validation loss: 0.1248
2024-05-23 21:07:29 [INFO]: Epoch 141 - training loss: 0.1999, validation loss: 0.1241
2024-05-23 21:07:29 [INFO]: Epoch 142 - training loss: 0.1997, validation loss: 0.1251
2024-05-23 21:07:30 [INFO]: Epoch 143 - training loss: 0.1978, validation loss: 0.1235
2024-05-23 21:07:30 [INFO]: Epoch 144 - training loss: 0.1997, validation loss: 0.1244
2024-05-23 21:07:31 [INFO]: Epoch 145 - training loss: 0.1991, validation loss: 0.1254
2024-05-23 21:07:32 [INFO]: Epoch 146 - training loss: 0.1972, validation loss: 0.1239
2024-05-23 21:07:32 [INFO]: Epoch 147 - training loss: 0.1975, validation loss: 0.1231
2024-05-23 21:07:33 [INFO]: Epoch 148 - training loss: 0.1975, validation loss: 0.1236
2024-05-23 21:07:33 [INFO]: Epoch 149 - training loss: 0.1966, validation loss: 0.1243
2024-05-23 21:07:34 [INFO]: Epoch 150 - training loss: 0.1951, validation loss: 0.1237
2024-05-23 21:07:35 [INFO]: Epoch 151 - training loss: 0.1951, validation loss: 0.1233
2024-05-23 21:07:36 [INFO]: Epoch 152 - training loss: 0.1948, validation loss: 0.1243
2024-05-23 21:07:36 [INFO]: Epoch 153 - training loss: 0.1937, validation loss: 0.1230
2024-05-23 21:07:37 [INFO]: Epoch 154 - training loss: 0.1946, validation loss: 0.1238
2024-05-23 21:07:37 [INFO]: Epoch 155 - training loss: 0.1937, validation loss: 0.1239
2024-05-23 21:07:38 [INFO]: Epoch 156 - training loss: 0.1939, validation loss: 0.1231
2024-05-23 21:07:39 [INFO]: Epoch 157 - training loss: 0.1940, validation loss: 0.1233
2024-05-23 21:07:39 [INFO]: Epoch 158 - training loss: 0.1925, validation loss: 0.1235
2024-05-23 21:07:40 [INFO]: Epoch 159 - training loss: 0.1930, validation loss: 0.1212
2024-05-23 21:07:40 [INFO]: Epoch 160 - training loss: 0.1910, validation loss: 0.1221
2024-05-23 21:07:41 [INFO]: Epoch 161 - training loss: 0.1904, validation loss: 0.1220
2024-05-23 21:07:41 [INFO]: Epoch 162 - training loss: 0.1903, validation loss: 0.1222
2024-05-23 21:07:42 [INFO]: Epoch 163 - training loss: 0.1904, validation loss: 0.1221
2024-05-23 21:07:43 [INFO]: Epoch 164 - training loss: 0.1898, validation loss: 0.1225
2024-05-23 21:07:43 [INFO]: Epoch 165 - training loss: 0.1894, validation loss: 0.1229
2024-05-23 21:07:44 [INFO]: Epoch 166 - training loss: 0.1897, validation loss: 0.1217
2024-05-23 21:07:44 [INFO]: Epoch 167 - training loss: 0.1884, validation loss: 0.1216
2024-05-23 21:07:45 [INFO]: Epoch 168 - training loss: 0.1884, validation loss: 0.1226
2024-05-23 21:07:46 [INFO]: Epoch 169 - training loss: 0.1881, validation loss: 0.1223
2024-05-23 21:07:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:07:46 [INFO]: Finished training. The best model is from epoch#159.
2024-05-23 21:07:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240523_T210607/SAITS.pypots
2024-05-23 21:07:46 [INFO]: SAITS on Air-Quality: MAE=0.1542, MSE=0.1581
2024-05-23 21:07:46 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-23 21:07:46 [INFO]: Using the given device: cuda:0
2024-05-23 21:07:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240523_T210746
2024-05-23 21:07:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240523_T210746/tensorboard
2024-05-23 21:07:46 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 21:07:46 [INFO]: Epoch 001 - training loss: 0.9073, validation loss: 0.4816
2024-05-23 21:07:46 [INFO]: Epoch 002 - training loss: 0.5676, validation loss: 0.3548
2024-05-23 21:07:47 [INFO]: Epoch 003 - training loss: 0.4734, validation loss: 0.2928
2024-05-23 21:07:47 [INFO]: Epoch 004 - training loss: 0.4224, validation loss: 0.2659
2024-05-23 21:07:47 [INFO]: Epoch 005 - training loss: 0.3934, validation loss: 0.2506
2024-05-23 21:07:47 [INFO]: Epoch 006 - training loss: 0.3722, validation loss: 0.2398
2024-05-23 21:07:47 [INFO]: Epoch 007 - training loss: 0.3560, validation loss: 0.2296
2024-05-23 21:07:48 [INFO]: Epoch 008 - training loss: 0.3432, validation loss: 0.2231
2024-05-23 21:07:48 [INFO]: Epoch 009 - training loss: 0.3339, validation loss: 0.2191
2024-05-23 21:07:48 [INFO]: Epoch 010 - training loss: 0.3240, validation loss: 0.2123
2024-05-23 21:07:48 [INFO]: Epoch 011 - training loss: 0.3189, validation loss: 0.2103
2024-05-23 21:07:49 [INFO]: Epoch 012 - training loss: 0.3148, validation loss: 0.2039
2024-05-23 21:07:49 [INFO]: Epoch 013 - training loss: 0.3072, validation loss: 0.2017
2024-05-23 21:07:49 [INFO]: Epoch 014 - training loss: 0.3034, validation loss: 0.1975
2024-05-23 21:07:49 [INFO]: Epoch 015 - training loss: 0.2981, validation loss: 0.1970
2024-05-23 21:07:50 [INFO]: Epoch 016 - training loss: 0.2945, validation loss: 0.1941
2024-05-23 21:07:51 [INFO]: Epoch 017 - training loss: 0.2888, validation loss: 0.1908
2024-05-23 21:07:51 [INFO]: Epoch 018 - training loss: 0.2879, validation loss: 0.1878
2024-05-23 21:07:51 [INFO]: Epoch 019 - training loss: 0.2838, validation loss: 0.1854
2024-05-23 21:07:51 [INFO]: Epoch 020 - training loss: 0.2783, validation loss: 0.1831
2024-05-23 21:07:52 [INFO]: Epoch 021 - training loss: 0.2759, validation loss: 0.1798
2024-05-23 21:07:52 [INFO]: Epoch 022 - training loss: 0.2723, validation loss: 0.1784
2024-05-23 21:07:52 [INFO]: Epoch 023 - training loss: 0.2712, validation loss: 0.1786
2024-05-23 21:07:52 [INFO]: Epoch 024 - training loss: 0.2691, validation loss: 0.1763
2024-05-23 21:07:53 [INFO]: Epoch 025 - training loss: 0.2646, validation loss: 0.1750
2024-05-23 21:07:53 [INFO]: Epoch 026 - training loss: 0.2658, validation loss: 0.1751
2024-05-23 21:07:53 [INFO]: Epoch 027 - training loss: 0.2617, validation loss: 0.1717
2024-05-23 21:07:53 [INFO]: Epoch 028 - training loss: 0.2585, validation loss: 0.1713
2024-05-23 21:07:53 [INFO]: Epoch 029 - training loss: 0.2567, validation loss: 0.1729
2024-05-23 21:07:54 [INFO]: Epoch 030 - training loss: 0.2562, validation loss: 0.1704
2024-05-23 21:07:54 [INFO]: Epoch 031 - training loss: 0.2539, validation loss: 0.1684
2024-05-23 21:07:54 [INFO]: Epoch 032 - training loss: 0.2527, validation loss: 0.1677
2024-05-23 21:07:54 [INFO]: Epoch 033 - training loss: 0.2503, validation loss: 0.1684
2024-05-23 21:07:55 [INFO]: Epoch 034 - training loss: 0.2486, validation loss: 0.1666
2024-05-23 21:07:55 [INFO]: Epoch 035 - training loss: 0.2445, validation loss: 0.1660
2024-05-23 21:07:55 [INFO]: Epoch 036 - training loss: 0.2427, validation loss: 0.1653
2024-05-23 21:07:55 [INFO]: Epoch 037 - training loss: 0.2413, validation loss: 0.1630
2024-05-23 21:07:56 [INFO]: Epoch 038 - training loss: 0.2395, validation loss: 0.1657
2024-05-23 21:07:56 [INFO]: Epoch 039 - training loss: 0.2395, validation loss: 0.1646
2024-05-23 21:07:56 [INFO]: Epoch 040 - training loss: 0.2367, validation loss: 0.1644
2024-05-23 21:07:56 [INFO]: Epoch 041 - training loss: 0.2364, validation loss: 0.1616
2024-05-23 21:07:57 [INFO]: Epoch 042 - training loss: 0.2348, validation loss: 0.1614
2024-05-23 21:07:57 [INFO]: Epoch 043 - training loss: 0.2318, validation loss: 0.1611
2024-05-23 21:07:57 [INFO]: Epoch 044 - training loss: 0.2325, validation loss: 0.1610
2024-05-23 21:07:57 [INFO]: Epoch 045 - training loss: 0.2310, validation loss: 0.1588
2024-05-23 21:07:57 [INFO]: Epoch 046 - training loss: 0.2302, validation loss: 0.1615
2024-05-23 21:07:58 [INFO]: Epoch 047 - training loss: 0.2281, validation loss: 0.1612
2024-05-23 21:07:58 [INFO]: Epoch 048 - training loss: 0.2287, validation loss: 0.1585
2024-05-23 21:07:58 [INFO]: Epoch 049 - training loss: 0.2269, validation loss: 0.1596
2024-05-23 21:07:58 [INFO]: Epoch 050 - training loss: 0.2271, validation loss: 0.1595
2024-05-23 21:07:59 [INFO]: Epoch 051 - training loss: 0.2253, validation loss: 0.1580
2024-05-23 21:07:59 [INFO]: Epoch 052 - training loss: 0.2220, validation loss: 0.1582
2024-05-23 21:07:59 [INFO]: Epoch 053 - training loss: 0.2209, validation loss: 0.1574
2024-05-23 21:07:59 [INFO]: Epoch 054 - training loss: 0.2200, validation loss: 0.1561
2024-05-23 21:08:00 [INFO]: Epoch 055 - training loss: 0.2178, validation loss: 0.1572
2024-05-23 21:08:00 [INFO]: Epoch 056 - training loss: 0.2184, validation loss: 0.1564
2024-05-23 21:08:00 [INFO]: Epoch 057 - training loss: 0.2181, validation loss: 0.1550
2024-05-23 21:08:00 [INFO]: Epoch 058 - training loss: 0.2162, validation loss: 0.1554
2024-05-23 21:08:00 [INFO]: Epoch 059 - training loss: 0.2143, validation loss: 0.1548
2024-05-23 21:08:01 [INFO]: Epoch 060 - training loss: 0.2123, validation loss: 0.1556
2024-05-23 21:08:01 [INFO]: Epoch 061 - training loss: 0.2117, validation loss: 0.1557
2024-05-23 21:08:01 [INFO]: Epoch 062 - training loss: 0.2107, validation loss: 0.1533
2024-05-23 21:08:01 [INFO]: Epoch 063 - training loss: 0.2126, validation loss: 0.1531
2024-05-23 21:08:02 [INFO]: Epoch 064 - training loss: 0.2094, validation loss: 0.1535
2024-05-23 21:08:02 [INFO]: Epoch 065 - training loss: 0.2098, validation loss: 0.1546
2024-05-23 21:08:02 [INFO]: Epoch 066 - training loss: 0.2080, validation loss: 0.1510
2024-05-23 21:08:02 [INFO]: Epoch 067 - training loss: 0.2062, validation loss: 0.1502
2024-05-23 21:08:03 [INFO]: Epoch 068 - training loss: 0.2042, validation loss: 0.1527
2024-05-23 21:08:03 [INFO]: Epoch 069 - training loss: 0.2026, validation loss: 0.1514
2024-05-23 21:08:03 [INFO]: Epoch 070 - training loss: 0.2040, validation loss: 0.1506
2024-05-23 21:08:03 [INFO]: Epoch 071 - training loss: 0.2045, validation loss: 0.1500
2024-05-23 21:08:03 [INFO]: Epoch 072 - training loss: 0.2073, validation loss: 0.1487
2024-05-23 21:08:04 [INFO]: Epoch 073 - training loss: 0.2025, validation loss: 0.1500
2024-05-23 21:08:04 [INFO]: Epoch 074 - training loss: 0.2013, validation loss: 0.1505
2024-05-23 21:08:04 [INFO]: Epoch 075 - training loss: 0.2017, validation loss: 0.1492
2024-05-23 21:08:04 [INFO]: Epoch 076 - training loss: 0.2006, validation loss: 0.1515
2024-05-23 21:08:05 [INFO]: Epoch 077 - training loss: 0.2013, validation loss: 0.1492
2024-05-23 21:08:05 [INFO]: Epoch 078 - training loss: 0.1961, validation loss: 0.1478
2024-05-23 21:08:05 [INFO]: Epoch 079 - training loss: 0.1951, validation loss: 0.1478
2024-05-23 21:08:05 [INFO]: Epoch 080 - training loss: 0.1948, validation loss: 0.1475
2024-05-23 21:08:06 [INFO]: Epoch 081 - training loss: 0.1936, validation loss: 0.1489
2024-05-23 21:08:06 [INFO]: Epoch 082 - training loss: 0.1937, validation loss: 0.1473
2024-05-23 21:08:06 [INFO]: Epoch 083 - training loss: 0.1945, validation loss: 0.1470
2024-05-23 21:08:06 [INFO]: Epoch 084 - training loss: 0.1947, validation loss: 0.1477
2024-05-23 21:08:06 [INFO]: Epoch 085 - training loss: 0.1943, validation loss: 0.1476
2024-05-23 21:08:07 [INFO]: Epoch 086 - training loss: 0.1902, validation loss: 0.1467
2024-05-23 21:08:07 [INFO]: Epoch 087 - training loss: 0.1927, validation loss: 0.1472
2024-05-23 21:08:07 [INFO]: Epoch 088 - training loss: 0.1916, validation loss: 0.1454
2024-05-23 21:08:07 [INFO]: Epoch 089 - training loss: 0.1894, validation loss: 0.1467
2024-05-23 21:08:08 [INFO]: Epoch 090 - training loss: 0.1889, validation loss: 0.1462
2024-05-23 21:08:08 [INFO]: Epoch 091 - training loss: 0.1889, validation loss: 0.1472
2024-05-23 21:08:08 [INFO]: Epoch 092 - training loss: 0.1856, validation loss: 0.1441
2024-05-23 21:08:08 [INFO]: Epoch 093 - training loss: 0.1840, validation loss: 0.1449
2024-05-23 21:08:09 [INFO]: Epoch 094 - training loss: 0.1845, validation loss: 0.1448
2024-05-23 21:08:09 [INFO]: Epoch 095 - training loss: 0.1835, validation loss: 0.1444
2024-05-23 21:08:09 [INFO]: Epoch 096 - training loss: 0.1824, validation loss: 0.1448
2024-05-23 21:08:09 [INFO]: Epoch 097 - training loss: 0.1812, validation loss: 0.1448
2024-05-23 21:08:09 [INFO]: Epoch 098 - training loss: 0.1807, validation loss: 0.1461
2024-05-23 21:08:10 [INFO]: Epoch 099 - training loss: 0.1813, validation loss: 0.1446
2024-05-23 21:08:10 [INFO]: Epoch 100 - training loss: 0.1803, validation loss: 0.1445
2024-05-23 21:08:10 [INFO]: Epoch 101 - training loss: 0.1812, validation loss: 0.1431
2024-05-23 21:08:11 [INFO]: Epoch 102 - training loss: 0.1799, validation loss: 0.1448
2024-05-23 21:08:11 [INFO]: Epoch 103 - training loss: 0.1808, validation loss: 0.1432
2024-05-23 21:08:11 [INFO]: Epoch 104 - training loss: 0.1786, validation loss: 0.1421
2024-05-23 21:08:11 [INFO]: Epoch 105 - training loss: 0.1757, validation loss: 0.1431
2024-05-23 21:08:12 [INFO]: Epoch 106 - training loss: 0.1766, validation loss: 0.1440
2024-05-23 21:08:12 [INFO]: Epoch 107 - training loss: 0.1753, validation loss: 0.1428
2024-05-23 21:08:12 [INFO]: Epoch 108 - training loss: 0.1757, validation loss: 0.1434
2024-05-23 21:08:12 [INFO]: Epoch 109 - training loss: 0.1753, validation loss: 0.1419
2024-05-23 21:08:12 [INFO]: Epoch 110 - training loss: 0.1729, validation loss: 0.1429
2024-05-23 21:08:13 [INFO]: Epoch 111 - training loss: 0.1721, validation loss: 0.1418
2024-05-23 21:08:13 [INFO]: Epoch 112 - training loss: 0.1758, validation loss: 0.1413
2024-05-23 21:08:13 [INFO]: Epoch 113 - training loss: 0.1735, validation loss: 0.1421
2024-05-23 21:08:13 [INFO]: Epoch 114 - training loss: 0.1718, validation loss: 0.1432
2024-05-23 21:08:14 [INFO]: Epoch 115 - training loss: 0.1706, validation loss: 0.1418
2024-05-23 21:08:14 [INFO]: Epoch 116 - training loss: 0.1695, validation loss: 0.1404
2024-05-23 21:08:14 [INFO]: Epoch 117 - training loss: 0.1691, validation loss: 0.1420
2024-05-23 21:08:14 [INFO]: Epoch 118 - training loss: 0.1700, validation loss: 0.1423
2024-05-23 21:08:15 [INFO]: Epoch 119 - training loss: 0.1688, validation loss: 0.1443
2024-05-23 21:08:15 [INFO]: Epoch 120 - training loss: 0.1703, validation loss: 0.1402
2024-05-23 21:08:15 [INFO]: Epoch 121 - training loss: 0.1683, validation loss: 0.1414
2024-05-23 21:08:15 [INFO]: Epoch 122 - training loss: 0.1688, validation loss: 0.1410
2024-05-23 21:08:16 [INFO]: Epoch 123 - training loss: 0.1661, validation loss: 0.1404
2024-05-23 21:08:16 [INFO]: Epoch 124 - training loss: 0.1645, validation loss: 0.1415
2024-05-23 21:08:16 [INFO]: Epoch 125 - training loss: 0.1633, validation loss: 0.1412
2024-05-23 21:08:17 [INFO]: Epoch 126 - training loss: 0.1641, validation loss: 0.1410
2024-05-23 21:08:17 [INFO]: Epoch 127 - training loss: 0.1642, validation loss: 0.1397
2024-05-23 21:08:17 [INFO]: Epoch 128 - training loss: 0.1634, validation loss: 0.1414
2024-05-23 21:08:17 [INFO]: Epoch 129 - training loss: 0.1655, validation loss: 0.1417
2024-05-23 21:08:17 [INFO]: Epoch 130 - training loss: 0.1648, validation loss: 0.1406
2024-05-23 21:08:18 [INFO]: Epoch 131 - training loss: 0.1634, validation loss: 0.1389
2024-05-23 21:08:18 [INFO]: Epoch 132 - training loss: 0.1614, validation loss: 0.1392
2024-05-23 21:08:18 [INFO]: Epoch 133 - training loss: 0.1629, validation loss: 0.1408
2024-05-23 21:08:18 [INFO]: Epoch 134 - training loss: 0.1596, validation loss: 0.1400
2024-05-23 21:08:19 [INFO]: Epoch 135 - training loss: 0.1590, validation loss: 0.1396
2024-05-23 21:08:19 [INFO]: Epoch 136 - training loss: 0.1602, validation loss: 0.1392
2024-05-23 21:08:19 [INFO]: Epoch 137 - training loss: 0.1609, validation loss: 0.1392
2024-05-23 21:08:19 [INFO]: Epoch 138 - training loss: 0.1584, validation loss: 0.1385
2024-05-23 21:08:20 [INFO]: Epoch 139 - training loss: 0.1568, validation loss: 0.1396
2024-05-23 21:08:20 [INFO]: Epoch 140 - training loss: 0.1580, validation loss: 0.1390
2024-05-23 21:08:20 [INFO]: Epoch 141 - training loss: 0.1559, validation loss: 0.1386
2024-05-23 21:08:20 [INFO]: Epoch 142 - training loss: 0.1557, validation loss: 0.1382
2024-05-23 21:08:21 [INFO]: Epoch 143 - training loss: 0.1544, validation loss: 0.1389
2024-05-23 21:08:21 [INFO]: Epoch 144 - training loss: 0.1559, validation loss: 0.1416
2024-05-23 21:08:21 [INFO]: Epoch 145 - training loss: 0.1564, validation loss: 0.1393
2024-05-23 21:08:21 [INFO]: Epoch 146 - training loss: 0.1555, validation loss: 0.1389
2024-05-23 21:08:21 [INFO]: Epoch 147 - training loss: 0.1572, validation loss: 0.1402
2024-05-23 21:08:22 [INFO]: Epoch 148 - training loss: 0.1558, validation loss: 0.1383
2024-05-23 21:08:22 [INFO]: Epoch 149 - training loss: 0.1573, validation loss: 0.1393
2024-05-23 21:08:22 [INFO]: Epoch 150 - training loss: 0.1537, validation loss: 0.1380
2024-05-23 21:08:22 [INFO]: Epoch 151 - training loss: 0.1535, validation loss: 0.1382
2024-05-23 21:08:23 [INFO]: Epoch 152 - training loss: 0.1548, validation loss: 0.1377
2024-05-23 21:08:23 [INFO]: Epoch 153 - training loss: 0.1515, validation loss: 0.1388
2024-05-23 21:08:23 [INFO]: Epoch 154 - training loss: 0.1502, validation loss: 0.1376
2024-05-23 21:08:23 [INFO]: Epoch 155 - training loss: 0.1493, validation loss: 0.1391
2024-05-23 21:08:24 [INFO]: Epoch 156 - training loss: 0.1504, validation loss: 0.1392
2024-05-23 21:08:24 [INFO]: Epoch 157 - training loss: 0.1514, validation loss: 0.1393
2024-05-23 21:08:24 [INFO]: Epoch 158 - training loss: 0.1493, validation loss: 0.1378
2024-05-23 21:08:24 [INFO]: Epoch 159 - training loss: 0.1479, validation loss: 0.1374
2024-05-23 21:08:25 [INFO]: Epoch 160 - training loss: 0.1481, validation loss: 0.1398
2024-05-23 21:08:25 [INFO]: Epoch 161 - training loss: 0.1476, validation loss: 0.1383
2024-05-23 21:08:25 [INFO]: Epoch 162 - training loss: 0.1480, validation loss: 0.1384
2024-05-23 21:08:25 [INFO]: Epoch 163 - training loss: 0.1468, validation loss: 0.1382
2024-05-23 21:08:25 [INFO]: Epoch 164 - training loss: 0.1461, validation loss: 0.1380
2024-05-23 21:08:26 [INFO]: Epoch 165 - training loss: 0.1457, validation loss: 0.1389
2024-05-23 21:08:26 [INFO]: Epoch 166 - training loss: 0.1451, validation loss: 0.1364
2024-05-23 21:08:26 [INFO]: Epoch 167 - training loss: 0.1450, validation loss: 0.1382
2024-05-23 21:08:26 [INFO]: Epoch 168 - training loss: 0.1460, validation loss: 0.1385
2024-05-23 21:08:27 [INFO]: Epoch 169 - training loss: 0.1454, validation loss: 0.1381
2024-05-23 21:08:27 [INFO]: Epoch 170 - training loss: 0.1442, validation loss: 0.1386
2024-05-23 21:08:27 [INFO]: Epoch 171 - training loss: 0.1423, validation loss: 0.1404
2024-05-23 21:08:27 [INFO]: Epoch 172 - training loss: 0.1429, validation loss: 0.1377
2024-05-23 21:08:28 [INFO]: Epoch 173 - training loss: 0.1431, validation loss: 0.1388
2024-05-23 21:08:28 [INFO]: Epoch 174 - training loss: 0.1439, validation loss: 0.1383
2024-05-23 21:08:28 [INFO]: Epoch 175 - training loss: 0.1467, validation loss: 0.1403
2024-05-23 21:08:28 [INFO]: Epoch 176 - training loss: 0.1435, validation loss: 0.1380
2024-05-23 21:08:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:08:28 [INFO]: Finished training. The best model is from epoch#166.
2024-05-23 21:08:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240523_T210746/Transformer.pypots
2024-05-23 21:08:28 [INFO]: Transformer on Air-Quality: MAE=0.1704, MSE=0.1784
2024-05-23 21:08:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-23 21:08:28 [INFO]: Using the given device: cuda:0
2024-05-23 21:08:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240523_T210828
2024-05-23 21:08:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240523_T210828/tensorboard
2024-05-23 21:08:29 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 21:08:29 [INFO]: Epoch 001 - training loss: 0.2623, validation loss: 0.2774
2024-05-23 21:08:30 [INFO]: Epoch 002 - training loss: 0.2132, validation loss: 0.2396
2024-05-23 21:08:30 [INFO]: Epoch 003 - training loss: 0.1684, validation loss: 0.2143
2024-05-23 21:08:30 [INFO]: Epoch 004 - training loss: 0.1450, validation loss: 0.2066
2024-05-23 21:08:31 [INFO]: Epoch 005 - training loss: 0.1283, validation loss: 0.1949
2024-05-23 21:08:31 [INFO]: Epoch 006 - training loss: 0.1173, validation loss: 0.1979
2024-05-23 21:08:32 [INFO]: Epoch 007 - training loss: 0.1103, validation loss: 0.1879
2024-05-23 21:08:32 [INFO]: Epoch 008 - training loss: 0.1060, validation loss: 0.1964
2024-05-23 21:08:33 [INFO]: Epoch 009 - training loss: 0.1164, validation loss: 0.2086
2024-05-23 21:08:33 [INFO]: Epoch 010 - training loss: 0.1079, validation loss: 0.1893
2024-05-23 21:08:34 [INFO]: Epoch 011 - training loss: 0.0989, validation loss: 0.1966
2024-05-23 21:08:34 [INFO]: Epoch 012 - training loss: 0.0901, validation loss: 0.1963
2024-05-23 21:08:34 [INFO]: Epoch 013 - training loss: 0.0879, validation loss: 0.1880
2024-05-23 21:08:35 [INFO]: Epoch 014 - training loss: 0.0857, validation loss: 0.1925
2024-05-23 21:08:35 [INFO]: Epoch 015 - training loss: 0.0805, validation loss: 0.1780
2024-05-23 21:08:36 [INFO]: Epoch 016 - training loss: 0.0792, validation loss: 0.1849
2024-05-23 21:08:36 [INFO]: Epoch 017 - training loss: 0.0783, validation loss: 0.1808
2024-05-23 21:08:37 [INFO]: Epoch 018 - training loss: 0.0793, validation loss: 0.1823
2024-05-23 21:08:37 [INFO]: Epoch 019 - training loss: 0.0774, validation loss: 0.1796
2024-05-23 21:08:38 [INFO]: Epoch 020 - training loss: 0.0711, validation loss: 0.1733
2024-05-23 21:08:38 [INFO]: Epoch 021 - training loss: 0.0687, validation loss: 0.1767
2024-05-23 21:08:38 [INFO]: Epoch 022 - training loss: 0.0687, validation loss: 0.1769
2024-05-23 21:08:39 [INFO]: Epoch 023 - training loss: 0.0662, validation loss: 0.1741
2024-05-23 21:08:39 [INFO]: Epoch 024 - training loss: 0.0649, validation loss: 0.1801
2024-05-23 21:08:40 [INFO]: Epoch 025 - training loss: 0.0640, validation loss: 0.1750
2024-05-23 21:08:40 [INFO]: Epoch 026 - training loss: 0.0603, validation loss: 0.1706
2024-05-23 21:08:41 [INFO]: Epoch 027 - training loss: 0.0588, validation loss: 0.1706
2024-05-23 21:08:41 [INFO]: Epoch 028 - training loss: 0.0573, validation loss: 0.1729
2024-05-23 21:08:41 [INFO]: Epoch 029 - training loss: 0.0565, validation loss: 0.1716
2024-05-23 21:08:42 [INFO]: Epoch 030 - training loss: 0.0571, validation loss: 0.1718
2024-05-23 21:08:42 [INFO]: Epoch 031 - training loss: 0.0590, validation loss: 0.1756
2024-05-23 21:08:43 [INFO]: Epoch 032 - training loss: 0.0573, validation loss: 0.1712
2024-05-23 21:08:43 [INFO]: Epoch 033 - training loss: 0.0554, validation loss: 0.1768
2024-05-23 21:08:43 [INFO]: Epoch 034 - training loss: 0.0560, validation loss: 0.1715
2024-05-23 21:08:44 [INFO]: Epoch 035 - training loss: 0.0562, validation loss: 0.1713
2024-05-23 21:08:44 [INFO]: Epoch 036 - training loss: 0.0582, validation loss: 0.1687
2024-05-23 21:08:45 [INFO]: Epoch 037 - training loss: 0.0552, validation loss: 0.1685
2024-05-23 21:08:45 [INFO]: Epoch 038 - training loss: 0.0514, validation loss: 0.1677
2024-05-23 21:08:46 [INFO]: Epoch 039 - training loss: 0.0525, validation loss: 0.1666
2024-05-23 21:08:46 [INFO]: Epoch 040 - training loss: 0.0525, validation loss: 0.1696
2024-05-23 21:08:46 [INFO]: Epoch 041 - training loss: 0.0522, validation loss: 0.1688
2024-05-23 21:08:47 [INFO]: Epoch 042 - training loss: 0.0503, validation loss: 0.1642
2024-05-23 21:08:47 [INFO]: Epoch 043 - training loss: 0.0480, validation loss: 0.1651
2024-05-23 21:08:48 [INFO]: Epoch 044 - training loss: 0.0507, validation loss: 0.1701
2024-05-23 21:08:48 [INFO]: Epoch 045 - training loss: 0.0475, validation loss: 0.1660
2024-05-23 21:08:49 [INFO]: Epoch 046 - training loss: 0.0435, validation loss: 0.1634
2024-05-23 21:08:49 [INFO]: Epoch 047 - training loss: 0.0439, validation loss: 0.1640
2024-05-23 21:08:49 [INFO]: Epoch 048 - training loss: 0.0451, validation loss: 0.1630
2024-05-23 21:08:50 [INFO]: Epoch 049 - training loss: 0.0439, validation loss: 0.1624
2024-05-23 21:08:50 [INFO]: Epoch 050 - training loss: 0.0412, validation loss: 0.1631
2024-05-23 21:08:51 [INFO]: Epoch 051 - training loss: 0.0420, validation loss: 0.1610
2024-05-23 21:08:51 [INFO]: Epoch 052 - training loss: 0.0422, validation loss: 0.1657
2024-05-23 21:08:52 [INFO]: Epoch 053 - training loss: 0.0486, validation loss: 0.1673
2024-05-23 21:08:52 [INFO]: Epoch 054 - training loss: 0.0473, validation loss: 0.1634
2024-05-23 21:08:52 [INFO]: Epoch 055 - training loss: 0.0430, validation loss: 0.1632
2024-05-23 21:08:53 [INFO]: Epoch 056 - training loss: 0.0380, validation loss: 0.1609
2024-05-23 21:08:53 [INFO]: Epoch 057 - training loss: 0.0379, validation loss: 0.1605
2024-05-23 21:08:54 [INFO]: Epoch 058 - training loss: 0.0391, validation loss: 0.1634
2024-05-23 21:08:54 [INFO]: Epoch 059 - training loss: 0.0370, validation loss: 0.1630
2024-05-23 21:08:55 [INFO]: Epoch 060 - training loss: 0.0387, validation loss: 0.1649
2024-05-23 21:08:55 [INFO]: Epoch 061 - training loss: 0.0376, validation loss: 0.1637
2024-05-23 21:08:55 [INFO]: Epoch 062 - training loss: 0.0384, validation loss: 0.1617
2024-05-23 21:08:56 [INFO]: Epoch 063 - training loss: 0.0366, validation loss: 0.1675
2024-05-23 21:08:56 [INFO]: Epoch 064 - training loss: 0.0390, validation loss: 0.1630
2024-05-23 21:08:57 [INFO]: Epoch 065 - training loss: 0.0383, validation loss: 0.1607
2024-05-23 21:08:57 [INFO]: Epoch 066 - training loss: 0.0368, validation loss: 0.1575
2024-05-23 21:08:58 [INFO]: Epoch 067 - training loss: 0.0357, validation loss: 0.1640
2024-05-23 21:08:58 [INFO]: Epoch 068 - training loss: 0.0337, validation loss: 0.1593
2024-05-23 21:08:58 [INFO]: Epoch 069 - training loss: 0.0323, validation loss: 0.1622
2024-05-23 21:08:59 [INFO]: Epoch 070 - training loss: 0.0335, validation loss: 0.1608
2024-05-23 21:08:59 [INFO]: Epoch 071 - training loss: 0.0339, validation loss: 0.1618
2024-05-23 21:09:00 [INFO]: Epoch 072 - training loss: 0.0341, validation loss: 0.1587
2024-05-23 21:09:00 [INFO]: Epoch 073 - training loss: 0.0315, validation loss: 0.1580
2024-05-23 21:09:00 [INFO]: Epoch 074 - training loss: 0.0308, validation loss: 0.1592
2024-05-23 21:09:01 [INFO]: Epoch 075 - training loss: 0.0299, validation loss: 0.1583
2024-05-23 21:09:01 [INFO]: Epoch 076 - training loss: 0.0304, validation loss: 0.1584
2024-05-23 21:09:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:09:01 [INFO]: Finished training. The best model is from epoch#66.
2024-05-23 21:09:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240523_T210828/TimesNet.pypots
2024-05-23 21:09:02 [INFO]: TimesNet on Air-Quality: MAE=0.1609, MSE=0.2021
2024-05-23 21:09:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-23 21:09:02 [INFO]: Using the given device: cuda:0
2024-05-23 21:09:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902
2024-05-23 21:09:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/tensorboard
2024-05-23 21:09:02 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 21:09:18 [INFO]: Epoch 001 - training loss: 0.5504, validation loss: 0.3691
2024-05-23 21:09:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch1_loss0.3691143780946732.pypots
2024-05-23 21:09:34 [INFO]: Epoch 002 - training loss: 0.3185, validation loss: 0.2703
2024-05-23 21:09:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch2_loss0.2703197464346886.pypots
2024-05-23 21:09:51 [INFO]: Epoch 003 - training loss: 0.2554, validation loss: 0.2470
2024-05-23 21:09:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch3_loss0.2470196843147278.pypots
2024-05-23 21:10:07 [INFO]: Epoch 004 - training loss: 0.2350, validation loss: 0.2277
2024-05-23 21:10:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch4_loss0.22765635848045349.pypots
2024-05-23 21:10:23 [INFO]: Epoch 005 - training loss: 0.2371, validation loss: 0.2168
2024-05-23 21:10:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch5_loss0.21680204719305038.pypots
2024-05-23 21:10:39 [INFO]: Epoch 006 - training loss: 0.2013, validation loss: 0.1940
2024-05-23 21:10:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch6_loss0.1939944490790367.pypots
2024-05-23 21:10:56 [INFO]: Epoch 007 - training loss: 0.1949, validation loss: 0.1814
2024-05-23 21:10:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch7_loss0.18140280544757842.pypots
2024-05-23 21:11:12 [INFO]: Epoch 008 - training loss: 0.1823, validation loss: 0.1779
2024-05-23 21:11:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch8_loss0.1779310390353203.pypots
2024-05-23 21:11:28 [INFO]: Epoch 009 - training loss: 0.1579, validation loss: 0.1624
2024-05-23 21:11:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch9_loss0.16238840222358703.pypots
2024-05-23 21:11:45 [INFO]: Epoch 010 - training loss: 0.1677, validation loss: 0.1540
2024-05-23 21:11:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch10_loss0.1539509117603302.pypots
2024-05-23 21:12:01 [INFO]: Epoch 011 - training loss: 0.1604, validation loss: 0.1536
2024-05-23 21:12:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch11_loss0.15364018380641936.pypots
2024-05-23 21:12:17 [INFO]: Epoch 012 - training loss: 0.1583, validation loss: 0.1510
2024-05-23 21:12:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch12_loss0.1509888231754303.pypots
2024-05-23 21:12:33 [INFO]: Epoch 013 - training loss: 0.1532, validation loss: 0.1466
2024-05-23 21:12:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch13_loss0.14656662046909333.pypots
2024-05-23 21:12:50 [INFO]: Epoch 014 - training loss: 0.1739, validation loss: 0.1562
2024-05-23 21:12:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch14_loss0.15621253997087478.pypots
2024-05-23 21:13:06 [INFO]: Epoch 015 - training loss: 0.1571, validation loss: 0.1469
2024-05-23 21:13:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch15_loss0.14688095599412918.pypots
2024-05-23 21:13:22 [INFO]: Epoch 016 - training loss: 0.1607, validation loss: 0.1413
2024-05-23 21:13:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch16_loss0.14126860499382018.pypots
2024-05-23 21:13:39 [INFO]: Epoch 017 - training loss: 0.1490, validation loss: 0.1399
2024-05-23 21:13:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch17_loss0.1399093024432659.pypots
2024-05-23 21:13:55 [INFO]: Epoch 018 - training loss: 0.1319, validation loss: 0.1387
2024-05-23 21:13:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch18_loss0.1387366309762001.pypots
2024-05-23 21:14:11 [INFO]: Epoch 019 - training loss: 0.1419, validation loss: 0.1407
2024-05-23 21:14:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch19_loss0.14074074551463128.pypots
2024-05-23 21:14:27 [INFO]: Epoch 020 - training loss: 0.1323, validation loss: 0.1397
2024-05-23 21:14:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch20_loss0.13971181809902192.pypots
2024-05-23 21:14:44 [INFO]: Epoch 021 - training loss: 0.1438, validation loss: 0.1376
2024-05-23 21:14:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch21_loss0.1376083694398403.pypots
2024-05-23 21:15:00 [INFO]: Epoch 022 - training loss: 0.1461, validation loss: 0.1379
2024-05-23 21:15:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch22_loss0.13786722496151924.pypots
2024-05-23 21:15:16 [INFO]: Epoch 023 - training loss: 0.1353, validation loss: 0.1353
2024-05-23 21:15:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch23_loss0.13529490754008294.pypots
2024-05-23 21:15:33 [INFO]: Epoch 024 - training loss: 0.1418, validation loss: 0.1346
2024-05-23 21:15:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch24_loss0.13463841676712035.pypots
2024-05-23 21:15:49 [INFO]: Epoch 025 - training loss: 0.1387, validation loss: 0.1440
2024-05-23 21:15:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch25_loss0.1439662106335163.pypots
2024-05-23 21:16:05 [INFO]: Epoch 026 - training loss: 0.1572, validation loss: 0.1347
2024-05-23 21:16:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch26_loss0.13473753705620767.pypots
2024-05-23 21:16:21 [INFO]: Epoch 027 - training loss: 0.1418, validation loss: 0.1373
2024-05-23 21:16:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch27_loss0.13733686730265618.pypots
2024-05-23 21:16:38 [INFO]: Epoch 028 - training loss: 0.1388, validation loss: 0.1332
2024-05-23 21:16:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch28_loss0.13320648595690726.pypots
2024-05-23 21:16:54 [INFO]: Epoch 029 - training loss: 0.1376, validation loss: 0.1297
2024-05-23 21:16:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch29_loss0.12969437763094901.pypots
2024-05-23 21:17:10 [INFO]: Epoch 030 - training loss: 0.1272, validation loss: 0.1294
2024-05-23 21:17:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch30_loss0.12940976098179818.pypots
2024-05-23 21:17:27 [INFO]: Epoch 031 - training loss: 0.1283, validation loss: 0.1287
2024-05-23 21:17:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch31_loss0.12869540825486184.pypots
2024-05-23 21:17:43 [INFO]: Epoch 032 - training loss: 0.1338, validation loss: 0.1344
2024-05-23 21:17:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch32_loss0.13442251533269883.pypots
2024-05-23 21:17:59 [INFO]: Epoch 033 - training loss: 0.1240, validation loss: 0.1313
2024-05-23 21:17:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch33_loss0.13131604567170144.pypots
2024-05-23 21:18:15 [INFO]: Epoch 034 - training loss: 0.1354, validation loss: 0.1271
2024-05-23 21:18:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch34_loss0.12706615701317786.pypots
2024-05-23 21:18:32 [INFO]: Epoch 035 - training loss: 0.1364, validation loss: 0.1267
2024-05-23 21:18:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch35_loss0.12670618891716004.pypots
2024-05-23 21:18:48 [INFO]: Epoch 036 - training loss: 0.1154, validation loss: 0.1260
2024-05-23 21:18:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch36_loss0.12603450044989586.pypots
2024-05-23 21:19:04 [INFO]: Epoch 037 - training loss: 0.1263, validation loss: 0.1264
2024-05-23 21:19:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch37_loss0.12643520906567574.pypots
2024-05-23 21:19:21 [INFO]: Epoch 038 - training loss: 0.1361, validation loss: 0.1255
2024-05-23 21:19:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch38_loss0.1255267947912216.pypots
2024-05-23 21:19:37 [INFO]: Epoch 039 - training loss: 0.1210, validation loss: 0.1260
2024-05-23 21:19:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch39_loss0.1260160245001316.pypots
2024-05-23 21:19:53 [INFO]: Epoch 040 - training loss: 0.1327, validation loss: 0.1286
2024-05-23 21:19:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch40_loss0.12863835990428923.pypots
2024-05-23 21:20:09 [INFO]: Epoch 041 - training loss: 0.1395, validation loss: 0.1228
2024-05-23 21:20:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch41_loss0.12282853797078133.pypots
2024-05-23 21:20:26 [INFO]: Epoch 042 - training loss: 0.1323, validation loss: 0.1223
2024-05-23 21:20:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch42_loss0.12231708243489266.pypots
2024-05-23 21:20:42 [INFO]: Epoch 043 - training loss: 0.1228, validation loss: 0.1213
2024-05-23 21:20:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch43_loss0.1212837591767311.pypots
2024-05-23 21:20:58 [INFO]: Epoch 044 - training loss: 0.1209, validation loss: 0.1216
2024-05-23 21:20:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch44_loss0.12159426882863045.pypots
2024-05-23 21:21:15 [INFO]: Epoch 045 - training loss: 0.1259, validation loss: 0.1212
2024-05-23 21:21:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch45_loss0.12123789191246033.pypots
2024-05-23 21:21:31 [INFO]: Epoch 046 - training loss: 0.1186, validation loss: 0.1216
2024-05-23 21:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch46_loss0.12159203961491585.pypots
2024-05-23 21:21:47 [INFO]: Epoch 047 - training loss: 0.1218, validation loss: 0.1200
2024-05-23 21:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch47_loss0.12004359662532807.pypots
2024-05-23 21:22:03 [INFO]: Epoch 048 - training loss: 0.1239, validation loss: 0.1192
2024-05-23 21:22:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch48_loss0.11918769702315331.pypots
2024-05-23 21:22:20 [INFO]: Epoch 049 - training loss: 0.1011, validation loss: 0.1182
2024-05-23 21:22:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch49_loss0.11816080138087273.pypots
2024-05-23 21:22:36 [INFO]: Epoch 050 - training loss: 0.1146, validation loss: 0.1214
2024-05-23 21:22:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch50_loss0.12143419831991195.pypots
2024-05-23 21:22:52 [INFO]: Epoch 051 - training loss: 0.1087, validation loss: 0.1183
2024-05-23 21:22:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch51_loss0.11825703009963036.pypots
2024-05-23 21:23:09 [INFO]: Epoch 052 - training loss: 0.1107, validation loss: 0.1220
2024-05-23 21:23:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch52_loss0.12204884365200996.pypots
2024-05-23 21:23:25 [INFO]: Epoch 053 - training loss: 0.1159, validation loss: 0.1176
2024-05-23 21:23:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch53_loss0.11763684004545212.pypots
2024-05-23 21:23:41 [INFO]: Epoch 054 - training loss: 0.1221, validation loss: 0.1174
2024-05-23 21:23:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch54_loss0.11741589084267616.pypots
2024-05-23 21:23:58 [INFO]: Epoch 055 - training loss: 0.1260, validation loss: 0.1165
2024-05-23 21:23:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch55_loss0.11651793494820595.pypots
2024-05-23 21:24:14 [INFO]: Epoch 056 - training loss: 0.1272, validation loss: 0.1185
2024-05-23 21:24:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch56_loss0.1185369610786438.pypots
2024-05-23 21:24:30 [INFO]: Epoch 057 - training loss: 0.1035, validation loss: 0.1168
2024-05-23 21:24:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch57_loss0.1167883649468422.pypots
2024-05-23 21:24:46 [INFO]: Epoch 058 - training loss: 0.1128, validation loss: 0.1120
2024-05-23 21:24:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch58_loss0.11202686205506325.pypots
2024-05-23 21:25:03 [INFO]: Epoch 059 - training loss: 0.1174, validation loss: 0.1141
2024-05-23 21:25:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch59_loss0.1140853650867939.pypots
2024-05-23 21:25:19 [INFO]: Epoch 060 - training loss: 0.1088, validation loss: 0.1131
2024-05-23 21:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch60_loss0.11306245252490044.pypots
2024-05-23 21:25:35 [INFO]: Epoch 061 - training loss: 0.1033, validation loss: 0.1187
2024-05-23 21:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch61_loss0.11874152645468712.pypots
2024-05-23 21:25:51 [INFO]: Epoch 062 - training loss: 0.1191, validation loss: 0.1199
2024-05-23 21:25:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch62_loss0.11988258436322212.pypots
2024-05-23 21:26:08 [INFO]: Epoch 063 - training loss: 0.1250, validation loss: 0.1147
2024-05-23 21:26:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch63_loss0.11469959020614624.pypots
2024-05-23 21:26:24 [INFO]: Epoch 064 - training loss: 0.1052, validation loss: 0.1127
2024-05-23 21:26:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch64_loss0.1126848429441452.pypots
2024-05-23 21:26:40 [INFO]: Epoch 065 - training loss: 0.1151, validation loss: 0.1190
2024-05-23 21:26:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch65_loss0.11903829500079155.pypots
2024-05-23 21:26:57 [INFO]: Epoch 066 - training loss: 0.1160, validation loss: 0.1144
2024-05-23 21:26:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch66_loss0.11442332044243812.pypots
2024-05-23 21:27:13 [INFO]: Epoch 067 - training loss: 0.0966, validation loss: 0.1130
2024-05-23 21:27:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch67_loss0.11304184645414353.pypots
2024-05-23 21:27:29 [INFO]: Epoch 068 - training loss: 0.1125, validation loss: 0.1126
2024-05-23 21:27:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI_epoch68_loss0.11256026625633239.pypots
2024-05-23 21:27:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:27:29 [INFO]: Finished training. The best model is from epoch#58.
2024-05-23 21:27:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240523_T210902/CSDI.pypots
2024-05-23 21:29:47 [INFO]: CSDI on Air-Quality: MAE=0.1122, MSE=0.1742
2024-05-23 21:29:47 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-23 21:29:47 [INFO]: Using the given device: cuda:0
2024-05-23 21:29:47 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240523_T212947
2024-05-23 21:29:47 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240523_T212947/tensorboard
2024-05-23 21:29:47 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 21:29:47 [INFO]: Epoch 001 - training loss: 64386.4090, validation loss: 0.6390
2024-05-23 21:29:48 [INFO]: Epoch 002 - training loss: 41839.7493, validation loss: 0.5880
2024-05-23 21:29:48 [INFO]: Epoch 003 - training loss: 41492.2418, validation loss: 0.5275
2024-05-23 21:29:48 [INFO]: Epoch 004 - training loss: 41364.5978, validation loss: 0.4924
2024-05-23 21:29:48 [INFO]: Epoch 005 - training loss: 41278.0706, validation loss: 0.4288
2024-05-23 21:29:49 [INFO]: Epoch 006 - training loss: 41211.7723, validation loss: 0.3945
2024-05-23 21:29:49 [INFO]: Epoch 007 - training loss: 41172.3908, validation loss: 0.3653
2024-05-23 21:29:49 [INFO]: Epoch 008 - training loss: 41146.6496, validation loss: 0.3482
2024-05-23 21:29:49 [INFO]: Epoch 009 - training loss: 41125.7062, validation loss: 0.3495
2024-05-23 21:29:50 [INFO]: Epoch 010 - training loss: 41088.9240, validation loss: 0.3271
2024-05-23 21:29:50 [INFO]: Epoch 011 - training loss: 41058.2141, validation loss: 0.3227
2024-05-23 21:29:50 [INFO]: Epoch 012 - training loss: 41045.3015, validation loss: 0.3160
2024-05-23 21:29:50 [INFO]: Epoch 013 - training loss: 41039.0661, validation loss: 0.3318
2024-05-23 21:29:51 [INFO]: Epoch 014 - training loss: 41036.7120, validation loss: 0.3158
2024-05-23 21:29:51 [INFO]: Epoch 015 - training loss: 41023.1169, validation loss: 0.3076
2024-05-23 21:29:51 [INFO]: Epoch 016 - training loss: 41004.8009, validation loss: 0.3110
2024-05-23 21:29:51 [INFO]: Epoch 017 - training loss: 41040.3720, validation loss: 0.2942
2024-05-23 21:29:51 [INFO]: Epoch 018 - training loss: 40992.3019, validation loss: 0.2872
2024-05-23 21:29:52 [INFO]: Epoch 019 - training loss: 40987.8801, validation loss: 0.2830
2024-05-23 21:29:52 [INFO]: Epoch 020 - training loss: 40975.7737, validation loss: 0.2908
2024-05-23 21:29:52 [INFO]: Epoch 021 - training loss: 40963.3621, validation loss: 0.2721
2024-05-23 21:29:52 [INFO]: Epoch 022 - training loss: 40961.1415, validation loss: 0.2771
2024-05-23 21:29:53 [INFO]: Epoch 023 - training loss: 40945.5163, validation loss: 0.2671
2024-05-23 21:29:53 [INFO]: Epoch 024 - training loss: 40936.9183, validation loss: 0.2669
2024-05-23 21:29:53 [INFO]: Epoch 025 - training loss: 40942.4625, validation loss: 0.2771
2024-05-23 21:29:53 [INFO]: Epoch 026 - training loss: 40938.2141, validation loss: 0.2780
2024-05-23 21:29:54 [INFO]: Epoch 027 - training loss: 40929.0420, validation loss: 0.2587
2024-05-23 21:29:54 [INFO]: Epoch 028 - training loss: 40922.5598, validation loss: 0.2942
2024-05-23 21:29:54 [INFO]: Epoch 029 - training loss: 40922.6000, validation loss: 0.2611
2024-05-23 21:29:54 [INFO]: Epoch 030 - training loss: 40906.6949, validation loss: 0.2489
2024-05-23 21:29:55 [INFO]: Epoch 031 - training loss: 40920.8545, validation loss: 0.2598
2024-05-23 21:29:55 [INFO]: Epoch 032 - training loss: 40998.4716, validation loss: 0.2705
2024-05-23 21:29:55 [INFO]: Epoch 033 - training loss: 41035.1275, validation loss: 0.2697
2024-05-23 21:29:55 [INFO]: Epoch 034 - training loss: 40968.7276, validation loss: 0.2570
2024-05-23 21:29:56 [INFO]: Epoch 035 - training loss: 40953.7743, validation loss: 0.2634
2024-05-23 21:29:56 [INFO]: Epoch 036 - training loss: 40941.8647, validation loss: 0.2544
2024-05-23 21:29:56 [INFO]: Epoch 037 - training loss: 40933.3627, validation loss: 0.2629
2024-05-23 21:29:56 [INFO]: Epoch 038 - training loss: 40924.3440, validation loss: 0.2533
2024-05-23 21:29:57 [INFO]: Epoch 039 - training loss: 40904.0530, validation loss: 0.2466
2024-05-23 21:29:57 [INFO]: Epoch 040 - training loss: 40891.1419, validation loss: 0.2349
2024-05-23 21:29:57 [INFO]: Epoch 041 - training loss: 40884.9792, validation loss: 0.2397
2024-05-23 21:29:57 [INFO]: Epoch 042 - training loss: 40880.9171, validation loss: 0.2380
2024-05-23 21:29:57 [INFO]: Epoch 043 - training loss: 40883.5735, validation loss: 0.2365
2024-05-23 21:29:58 [INFO]: Epoch 044 - training loss: 40881.8709, validation loss: 0.2466
2024-05-23 21:29:58 [INFO]: Epoch 045 - training loss: 40895.0997, validation loss: 0.2587
2024-05-23 21:29:58 [INFO]: Epoch 046 - training loss: 40907.9680, validation loss: 0.2622
2024-05-23 21:29:58 [INFO]: Epoch 047 - training loss: 40899.3319, validation loss: 0.2581
2024-05-23 21:29:59 [INFO]: Epoch 048 - training loss: 40929.2798, validation loss: 0.2402
2024-05-23 21:29:59 [INFO]: Epoch 049 - training loss: 40873.7174, validation loss: 0.2287
2024-05-23 21:29:59 [INFO]: Epoch 050 - training loss: 40875.8608, validation loss: 0.2357
2024-05-23 21:29:59 [INFO]: Epoch 051 - training loss: 40868.5205, validation loss: 0.2269
2024-05-23 21:30:00 [INFO]: Epoch 052 - training loss: 40865.5666, validation loss: 0.2213
2024-05-23 21:30:00 [INFO]: Epoch 053 - training loss: 40859.0903, validation loss: 0.2214
2024-05-23 21:30:00 [INFO]: Epoch 054 - training loss: 40866.7727, validation loss: 0.2224
2024-05-23 21:30:00 [INFO]: Epoch 055 - training loss: 40855.2376, validation loss: 0.2218
2024-05-23 21:30:01 [INFO]: Epoch 056 - training loss: 40852.9688, validation loss: 0.2228
2024-05-23 21:30:01 [INFO]: Epoch 057 - training loss: 40851.4478, validation loss: 0.2183
2024-05-23 21:30:01 [INFO]: Epoch 058 - training loss: 40856.4492, validation loss: 0.2212
2024-05-23 21:30:01 [INFO]: Epoch 059 - training loss: 40853.7185, validation loss: 0.2237
2024-05-23 21:30:02 [INFO]: Epoch 060 - training loss: 40853.0150, validation loss: 0.2249
2024-05-23 21:30:02 [INFO]: Epoch 061 - training loss: 40854.7114, validation loss: 0.2222
2024-05-23 21:30:02 [INFO]: Epoch 062 - training loss: 40845.4482, validation loss: 0.2565
2024-05-23 21:30:02 [INFO]: Epoch 063 - training loss: 40849.6826, validation loss: 0.2371
2024-05-23 21:30:02 [INFO]: Epoch 064 - training loss: 40862.0804, validation loss: 0.2428
2024-05-23 21:30:03 [INFO]: Epoch 065 - training loss: 40977.2791, validation loss: 0.2813
2024-05-23 21:30:03 [INFO]: Epoch 066 - training loss: 40964.7286, validation loss: 0.2520
2024-05-23 21:30:03 [INFO]: Epoch 067 - training loss: 40929.1855, validation loss: 0.2321
2024-05-23 21:30:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:30:03 [INFO]: Finished training. The best model is from epoch#57.
2024-05-23 21:30:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240523_T212947/GPVAE.pypots
2024-05-23 21:30:03 [INFO]: GP-VAE on Air-Quality: MAE=0.2808, MSE=0.2800
2024-05-23 21:30:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-23 21:30:03 [INFO]: Using the given device: cuda:0
2024-05-23 21:30:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240523_T213003
2024-05-23 21:30:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240523_T213003/tensorboard
2024-05-23 21:30:03 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 21:30:07 [INFO]: Epoch 001 - generator training loss: 0.4768, discriminator training loss: 0.4578, validation loss: 0.5129
2024-05-23 21:30:10 [INFO]: Epoch 002 - generator training loss: 0.0914, discriminator training loss: 0.3618, validation loss: 0.3841
2024-05-23 21:30:14 [INFO]: Epoch 003 - generator training loss: 0.0334, discriminator training loss: 0.3573, validation loss: 0.3193
2024-05-23 21:30:17 [INFO]: Epoch 004 - generator training loss: -0.0030, discriminator training loss: 0.3557, validation loss: 0.2812
2024-05-23 21:30:20 [INFO]: Epoch 005 - generator training loss: -0.0266, discriminator training loss: 0.3536, validation loss: 0.2543
2024-05-23 21:30:24 [INFO]: Epoch 006 - generator training loss: -0.0420, discriminator training loss: 0.3519, validation loss: 0.2354
2024-05-23 21:30:27 [INFO]: Epoch 007 - generator training loss: -0.0557, discriminator training loss: 0.3499, validation loss: 0.2219
2024-05-23 21:30:30 [INFO]: Epoch 008 - generator training loss: -0.0656, discriminator training loss: 0.3480, validation loss: 0.2108
2024-05-23 21:30:33 [INFO]: Epoch 009 - generator training loss: -0.0740, discriminator training loss: 0.3457, validation loss: 0.2019
2024-05-23 21:30:37 [INFO]: Epoch 010 - generator training loss: -0.0802, discriminator training loss: 0.3437, validation loss: 0.1944
2024-05-23 21:30:40 [INFO]: Epoch 011 - generator training loss: -0.0856, discriminator training loss: 0.3413, validation loss: 0.1883
2024-05-23 21:30:44 [INFO]: Epoch 012 - generator training loss: -0.0885, discriminator training loss: 0.3387, validation loss: 0.1826
2024-05-23 21:30:48 [INFO]: Epoch 013 - generator training loss: -0.0920, discriminator training loss: 0.3360, validation loss: 0.1778
2024-05-23 21:30:51 [INFO]: Epoch 014 - generator training loss: -0.0925, discriminator training loss: 0.3331, validation loss: 0.1731
2024-05-23 21:30:54 [INFO]: Epoch 015 - generator training loss: -0.0950, discriminator training loss: 0.3298, validation loss: 0.1695
2024-05-23 21:30:58 [INFO]: Epoch 016 - generator training loss: -0.0968, discriminator training loss: 0.3263, validation loss: 0.1661
2024-05-23 21:31:01 [INFO]: Epoch 017 - generator training loss: -0.0967, discriminator training loss: 0.3227, validation loss: 0.1636
2024-05-23 21:31:04 [INFO]: Epoch 018 - generator training loss: -0.0944, discriminator training loss: 0.3189, validation loss: 0.1604
2024-05-23 21:31:07 [INFO]: Epoch 019 - generator training loss: -0.0959, discriminator training loss: 0.3147, validation loss: 0.1580
2024-05-23 21:31:11 [INFO]: Epoch 020 - generator training loss: -0.0968, discriminator training loss: 0.3110, validation loss: 0.1554
2024-05-23 21:31:14 [INFO]: Epoch 021 - generator training loss: -0.0960, discriminator training loss: 0.3071, validation loss: 0.1528
2024-05-23 21:31:17 [INFO]: Epoch 022 - generator training loss: -0.0954, discriminator training loss: 0.3029, validation loss: 0.1498
2024-05-23 21:31:21 [INFO]: Epoch 023 - generator training loss: -0.0943, discriminator training loss: 0.2990, validation loss: 0.1478
2024-05-23 21:31:24 [INFO]: Epoch 024 - generator training loss: -0.0914, discriminator training loss: 0.2947, validation loss: 0.1458
2024-05-23 21:31:27 [INFO]: Epoch 025 - generator training loss: -0.0912, discriminator training loss: 0.2908, validation loss: 0.1436
2024-05-23 21:31:30 [INFO]: Epoch 026 - generator training loss: -0.0909, discriminator training loss: 0.2872, validation loss: 0.1417
2024-05-23 21:31:34 [INFO]: Epoch 027 - generator training loss: -0.0897, discriminator training loss: 0.2833, validation loss: 0.1396
2024-05-23 21:31:37 [INFO]: Epoch 028 - generator training loss: -0.0881, discriminator training loss: 0.2799, validation loss: 0.1383
2024-05-23 21:31:40 [INFO]: Epoch 029 - generator training loss: -0.0876, discriminator training loss: 0.2764, validation loss: 0.1365
2024-05-23 21:31:44 [INFO]: Epoch 030 - generator training loss: -0.0862, discriminator training loss: 0.2730, validation loss: 0.1348
2024-05-23 21:31:47 [INFO]: Epoch 031 - generator training loss: -0.0846, discriminator training loss: 0.2694, validation loss: 0.1334
2024-05-23 21:31:50 [INFO]: Epoch 032 - generator training loss: -0.0837, discriminator training loss: 0.2664, validation loss: 0.1317
2024-05-23 21:31:53 [INFO]: Epoch 033 - generator training loss: -0.0821, discriminator training loss: 0.2638, validation loss: 0.1305
2024-05-23 21:31:57 [INFO]: Epoch 034 - generator training loss: -0.0833, discriminator training loss: 0.2609, validation loss: 0.1291
2024-05-23 21:32:00 [INFO]: Epoch 035 - generator training loss: -0.0813, discriminator training loss: 0.2583, validation loss: 0.1283
2024-05-23 21:32:03 [INFO]: Epoch 036 - generator training loss: -0.0805, discriminator training loss: 0.2555, validation loss: 0.1266
2024-05-23 21:32:07 [INFO]: Epoch 037 - generator training loss: -0.0781, discriminator training loss: 0.2531, validation loss: 0.1250
2024-05-23 21:32:10 [INFO]: Epoch 038 - generator training loss: -0.0789, discriminator training loss: 0.2511, validation loss: 0.1241
2024-05-23 21:32:13 [INFO]: Epoch 039 - generator training loss: -0.0777, discriminator training loss: 0.2483, validation loss: 0.1236
2024-05-23 21:32:17 [INFO]: Epoch 040 - generator training loss: -0.0766, discriminator training loss: 0.2464, validation loss: 0.1227
2024-05-23 21:32:20 [INFO]: Epoch 041 - generator training loss: -0.0763, discriminator training loss: 0.2447, validation loss: 0.1219
2024-05-23 21:32:24 [INFO]: Epoch 042 - generator training loss: -0.0771, discriminator training loss: 0.2429, validation loss: 0.1202
2024-05-23 21:32:27 [INFO]: Epoch 043 - generator training loss: -0.0758, discriminator training loss: 0.2413, validation loss: 0.1191
2024-05-23 21:32:31 [INFO]: Epoch 044 - generator training loss: -0.0755, discriminator training loss: 0.2397, validation loss: 0.1186
2024-05-23 21:32:34 [INFO]: Epoch 045 - generator training loss: -0.0752, discriminator training loss: 0.2380, validation loss: 0.1180
2024-05-23 21:32:38 [INFO]: Epoch 046 - generator training loss: -0.0753, discriminator training loss: 0.2366, validation loss: 0.1173
2024-05-23 21:32:41 [INFO]: Epoch 047 - generator training loss: -0.0751, discriminator training loss: 0.2355, validation loss: 0.1162
2024-05-23 21:32:45 [INFO]: Epoch 048 - generator training loss: -0.0752, discriminator training loss: 0.2340, validation loss: 0.1154
2024-05-23 21:32:48 [INFO]: Epoch 049 - generator training loss: -0.0754, discriminator training loss: 0.2328, validation loss: 0.1151
2024-05-23 21:32:52 [INFO]: Epoch 050 - generator training loss: -0.0723, discriminator training loss: 0.2315, validation loss: 0.1139
2024-05-23 21:32:56 [INFO]: Epoch 051 - generator training loss: -0.0741, discriminator training loss: 0.2306, validation loss: 0.1134
2024-05-23 21:32:59 [INFO]: Epoch 052 - generator training loss: -0.0747, discriminator training loss: 0.2295, validation loss: 0.1132
2024-05-23 21:33:03 [INFO]: Epoch 053 - generator training loss: -0.0750, discriminator training loss: 0.2285, validation loss: 0.1120
2024-05-23 21:33:06 [INFO]: Epoch 054 - generator training loss: -0.0743, discriminator training loss: 0.2276, validation loss: 0.1113
2024-05-23 21:33:10 [INFO]: Epoch 055 - generator training loss: -0.0738, discriminator training loss: 0.2269, validation loss: 0.1106
2024-05-23 21:33:13 [INFO]: Epoch 056 - generator training loss: -0.0746, discriminator training loss: 0.2256, validation loss: 0.1104
2024-05-23 21:33:17 [INFO]: Epoch 057 - generator training loss: -0.0745, discriminator training loss: 0.2247, validation loss: 0.1099
2024-05-23 21:33:20 [INFO]: Epoch 058 - generator training loss: -0.0739, discriminator training loss: 0.2242, validation loss: 0.1091
2024-05-23 21:33:23 [INFO]: Epoch 059 - generator training loss: -0.0727, discriminator training loss: 0.2236, validation loss: 0.1085
2024-05-23 21:33:27 [INFO]: Epoch 060 - generator training loss: -0.0736, discriminator training loss: 0.2225, validation loss: 0.1079
2024-05-23 21:33:30 [INFO]: Epoch 061 - generator training loss: -0.0744, discriminator training loss: 0.2218, validation loss: 0.1078
2024-05-23 21:33:33 [INFO]: Epoch 062 - generator training loss: -0.0739, discriminator training loss: 0.2215, validation loss: 0.1073
2024-05-23 21:33:37 [INFO]: Epoch 063 - generator training loss: -0.0743, discriminator training loss: 0.2206, validation loss: 0.1061
2024-05-23 21:33:40 [INFO]: Epoch 064 - generator training loss: -0.0740, discriminator training loss: 0.2200, validation loss: 0.1062
2024-05-23 21:33:43 [INFO]: Epoch 065 - generator training loss: -0.0741, discriminator training loss: 0.2199, validation loss: 0.1059
2024-05-23 21:33:47 [INFO]: Epoch 066 - generator training loss: -0.0741, discriminator training loss: 0.2189, validation loss: 0.1055
2024-05-23 21:33:50 [INFO]: Epoch 067 - generator training loss: -0.0737, discriminator training loss: 0.2182, validation loss: 0.1053
2024-05-23 21:33:53 [INFO]: Epoch 068 - generator training loss: -0.0755, discriminator training loss: 0.2177, validation loss: 0.1047
2024-05-23 21:33:57 [INFO]: Epoch 069 - generator training loss: -0.0750, discriminator training loss: 0.2174, validation loss: 0.1040
2024-05-23 21:34:00 [INFO]: Epoch 070 - generator training loss: -0.0753, discriminator training loss: 0.2173, validation loss: 0.1040
2024-05-23 21:34:03 [INFO]: Epoch 071 - generator training loss: -0.0751, discriminator training loss: 0.2165, validation loss: 0.1040
2024-05-23 21:34:07 [INFO]: Epoch 072 - generator training loss: -0.0753, discriminator training loss: 0.2164, validation loss: 0.1028
2024-05-23 21:34:10 [INFO]: Epoch 073 - generator training loss: -0.0756, discriminator training loss: 0.2159, validation loss: 0.1030
2024-05-23 21:34:13 [INFO]: Epoch 074 - generator training loss: -0.0755, discriminator training loss: 0.2157, validation loss: 0.1025
2024-05-23 21:34:16 [INFO]: Epoch 075 - generator training loss: -0.0763, discriminator training loss: 0.2152, validation loss: 0.1026
2024-05-23 21:34:20 [INFO]: Epoch 076 - generator training loss: -0.0754, discriminator training loss: 0.2147, validation loss: 0.1025
2024-05-23 21:34:23 [INFO]: Epoch 077 - generator training loss: -0.0751, discriminator training loss: 0.2145, validation loss: 0.1015
2024-05-23 21:34:26 [INFO]: Epoch 078 - generator training loss: -0.0760, discriminator training loss: 0.2136, validation loss: 0.1017
2024-05-23 21:34:30 [INFO]: Epoch 079 - generator training loss: -0.0760, discriminator training loss: 0.2133, validation loss: 0.1013
2024-05-23 21:34:33 [INFO]: Epoch 080 - generator training loss: -0.0762, discriminator training loss: 0.2136, validation loss: 0.1009
2024-05-23 21:34:37 [INFO]: Epoch 081 - generator training loss: -0.0755, discriminator training loss: 0.2128, validation loss: 0.1006
2024-05-23 21:34:40 [INFO]: Epoch 082 - generator training loss: -0.0763, discriminator training loss: 0.2128, validation loss: 0.1005
2024-05-23 21:34:43 [INFO]: Epoch 083 - generator training loss: -0.0768, discriminator training loss: 0.2119, validation loss: 0.1000
2024-05-23 21:34:46 [INFO]: Epoch 084 - generator training loss: -0.0760, discriminator training loss: 0.2117, validation loss: 0.1004
2024-05-23 21:34:50 [INFO]: Epoch 085 - generator training loss: -0.0770, discriminator training loss: 0.2120, validation loss: 0.0993
2024-05-23 21:34:53 [INFO]: Epoch 086 - generator training loss: -0.0774, discriminator training loss: 0.2118, validation loss: 0.0995
2024-05-23 21:34:56 [INFO]: Epoch 087 - generator training loss: -0.0770, discriminator training loss: 0.2112, validation loss: 0.0990
2024-05-23 21:35:00 [INFO]: Epoch 088 - generator training loss: -0.0766, discriminator training loss: 0.2110, validation loss: 0.0988
2024-05-23 21:35:03 [INFO]: Epoch 089 - generator training loss: -0.0765, discriminator training loss: 0.2105, validation loss: 0.0986
2024-05-23 21:35:06 [INFO]: Epoch 090 - generator training loss: -0.0776, discriminator training loss: 0.2107, validation loss: 0.0986
2024-05-23 21:35:10 [INFO]: Epoch 091 - generator training loss: -0.0774, discriminator training loss: 0.2106, validation loss: 0.0984
2024-05-23 21:35:13 [INFO]: Epoch 092 - generator training loss: -0.0779, discriminator training loss: 0.2103, validation loss: 0.0984
2024-05-23 21:35:16 [INFO]: Epoch 093 - generator training loss: -0.0785, discriminator training loss: 0.2095, validation loss: 0.0979
2024-05-23 21:35:20 [INFO]: Epoch 094 - generator training loss: -0.0779, discriminator training loss: 0.2098, validation loss: 0.0977
2024-05-23 21:35:23 [INFO]: Epoch 095 - generator training loss: -0.0785, discriminator training loss: 0.2094, validation loss: 0.0974
2024-05-23 21:35:26 [INFO]: Epoch 096 - generator training loss: -0.0790, discriminator training loss: 0.2090, validation loss: 0.0973
2024-05-23 21:35:30 [INFO]: Epoch 097 - generator training loss: -0.0786, discriminator training loss: 0.2092, validation loss: 0.0980
2024-05-23 21:35:33 [INFO]: Epoch 098 - generator training loss: -0.0794, discriminator training loss: 0.2092, validation loss: 0.0968
2024-05-23 21:35:36 [INFO]: Epoch 099 - generator training loss: -0.0790, discriminator training loss: 0.2089, validation loss: 0.0970
2024-05-23 21:35:39 [INFO]: Epoch 100 - generator training loss: -0.0794, discriminator training loss: 0.2083, validation loss: 0.0966
2024-05-23 21:35:43 [INFO]: Epoch 101 - generator training loss: -0.0797, discriminator training loss: 0.2080, validation loss: 0.0966
2024-05-23 21:35:46 [INFO]: Epoch 102 - generator training loss: -0.0793, discriminator training loss: 0.2077, validation loss: 0.0964
2024-05-23 21:35:50 [INFO]: Epoch 103 - generator training loss: -0.0792, discriminator training loss: 0.2081, validation loss: 0.0977
2024-05-23 21:35:53 [INFO]: Epoch 104 - generator training loss: -0.0795, discriminator training loss: 0.2079, validation loss: 0.0959
2024-05-23 21:35:56 [INFO]: Epoch 105 - generator training loss: -0.0790, discriminator training loss: 0.2078, validation loss: 0.0961
2024-05-23 21:36:00 [INFO]: Epoch 106 - generator training loss: -0.0805, discriminator training loss: 0.2071, validation loss: 0.0961
2024-05-23 21:36:03 [INFO]: Epoch 107 - generator training loss: -0.0802, discriminator training loss: 0.2073, validation loss: 0.0958
2024-05-23 21:36:06 [INFO]: Epoch 108 - generator training loss: -0.0807, discriminator training loss: 0.2069, validation loss: 0.0960
2024-05-23 21:36:09 [INFO]: Epoch 109 - generator training loss: -0.0797, discriminator training loss: 0.2068, validation loss: 0.0955
2024-05-23 21:36:13 [INFO]: Epoch 110 - generator training loss: -0.0805, discriminator training loss: 0.2068, validation loss: 0.0949
2024-05-23 21:36:16 [INFO]: Epoch 111 - generator training loss: -0.0807, discriminator training loss: 0.2067, validation loss: 0.0958
2024-05-23 21:36:19 [INFO]: Epoch 112 - generator training loss: -0.0807, discriminator training loss: 0.2066, validation loss: 0.0950
2024-05-23 21:36:23 [INFO]: Epoch 113 - generator training loss: -0.0814, discriminator training loss: 0.2066, validation loss: 0.0947
2024-05-23 21:36:26 [INFO]: Epoch 114 - generator training loss: -0.0812, discriminator training loss: 0.2063, validation loss: 0.0963
2024-05-23 21:36:30 [INFO]: Epoch 115 - generator training loss: -0.0818, discriminator training loss: 0.2063, validation loss: 0.0948
2024-05-23 21:36:33 [INFO]: Epoch 116 - generator training loss: -0.0808, discriminator training loss: 0.2057, validation loss: 0.0946
2024-05-23 21:36:37 [INFO]: Epoch 117 - generator training loss: -0.0812, discriminator training loss: 0.2056, validation loss: 0.0946
2024-05-23 21:36:40 [INFO]: Epoch 118 - generator training loss: -0.0817, discriminator training loss: 0.2055, validation loss: 0.0957
2024-05-23 21:36:43 [INFO]: Epoch 119 - generator training loss: -0.0823, discriminator training loss: 0.2059, validation loss: 0.0953
2024-05-23 21:36:47 [INFO]: Epoch 120 - generator training loss: -0.0814, discriminator training loss: 0.2051, validation loss: 0.0954
2024-05-23 21:36:50 [INFO]: Epoch 121 - generator training loss: -0.0806, discriminator training loss: 0.2056, validation loss: 0.0957
2024-05-23 21:36:53 [INFO]: Epoch 122 - generator training loss: -0.0820, discriminator training loss: 0.2052, validation loss: 0.0946
2024-05-23 21:36:57 [INFO]: Epoch 123 - generator training loss: -0.0810, discriminator training loss: 0.2051, validation loss: 0.0942
2024-05-23 21:37:00 [INFO]: Epoch 124 - generator training loss: -0.0813, discriminator training loss: 0.2050, validation loss: 0.0948
2024-05-23 21:37:03 [INFO]: Epoch 125 - generator training loss: -0.0826, discriminator training loss: 0.2047, validation loss: 0.0947
2024-05-23 21:37:07 [INFO]: Epoch 126 - generator training loss: -0.0831, discriminator training loss: 0.2046, validation loss: 0.0945
2024-05-23 21:37:10 [INFO]: Epoch 127 - generator training loss: -0.0827, discriminator training loss: 0.2048, validation loss: 0.0944
2024-05-23 21:37:13 [INFO]: Epoch 128 - generator training loss: -0.0827, discriminator training loss: 0.2046, validation loss: 0.0941
2024-05-23 21:37:17 [INFO]: Epoch 129 - generator training loss: -0.0827, discriminator training loss: 0.2044, validation loss: 0.0938
2024-05-23 21:37:20 [INFO]: Epoch 130 - generator training loss: -0.0830, discriminator training loss: 0.2044, validation loss: 0.0943
2024-05-23 21:37:23 [INFO]: Epoch 131 - generator training loss: -0.0831, discriminator training loss: 0.2037, validation loss: 0.0945
2024-05-23 21:37:26 [INFO]: Epoch 132 - generator training loss: -0.0839, discriminator training loss: 0.2040, validation loss: 0.0931
2024-05-23 21:37:30 [INFO]: Epoch 133 - generator training loss: -0.0835, discriminator training loss: 0.2040, validation loss: 0.0943
2024-05-23 21:37:33 [INFO]: Epoch 134 - generator training loss: -0.0840, discriminator training loss: 0.2031, validation loss: 0.0934
2024-05-23 21:37:37 [INFO]: Epoch 135 - generator training loss: -0.0840, discriminator training loss: 0.2041, validation loss: 0.0936
2024-05-23 21:37:40 [INFO]: Epoch 136 - generator training loss: -0.0841, discriminator training loss: 0.2032, validation loss: 0.0940
2024-05-23 21:37:43 [INFO]: Epoch 137 - generator training loss: -0.0838, discriminator training loss: 0.2035, validation loss: 0.0932
2024-05-23 21:37:47 [INFO]: Epoch 138 - generator training loss: -0.0836, discriminator training loss: 0.2033, validation loss: 0.0941
2024-05-23 21:37:50 [INFO]: Epoch 139 - generator training loss: -0.0831, discriminator training loss: 0.2035, validation loss: 0.0943
2024-05-23 21:37:53 [INFO]: Epoch 140 - generator training loss: -0.0835, discriminator training loss: 0.2031, validation loss: 0.0941
2024-05-23 21:37:57 [INFO]: Epoch 141 - generator training loss: -0.0837, discriminator training loss: 0.2031, validation loss: 0.0943
2024-05-23 21:38:00 [INFO]: Epoch 142 - generator training loss: -0.0841, discriminator training loss: 0.2030, validation loss: 0.0939
2024-05-23 21:38:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:38:00 [INFO]: Finished training. The best model is from epoch#132.
2024-05-23 21:38:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240523_T213003/USGAN.pypots
2024-05-23 21:38:01 [INFO]: US-GAN on Air-Quality: MAE=0.1502, MSE=0.1374
2024-05-23 21:38:01 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-23 21:38:01 [INFO]: Using the given device: cuda:0
2024-05-23 21:38:01 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240523_T213801
2024-05-23 21:38:01 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240523_T213801/tensorboard
2024-05-23 21:38:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 21:38:04 [INFO]: Epoch 001 - training loss: 1.4058, validation loss: 0.9435
2024-05-23 21:38:06 [INFO]: Epoch 002 - training loss: 1.1410, validation loss: 0.7026
2024-05-23 21:38:08 [INFO]: Epoch 003 - training loss: 0.9484, validation loss: 0.5879
2024-05-23 21:38:10 [INFO]: Epoch 004 - training loss: 0.8369, validation loss: 0.5191
2024-05-23 21:38:13 [INFO]: Epoch 005 - training loss: 0.7632, validation loss: 0.4717
2024-05-23 21:38:15 [INFO]: Epoch 006 - training loss: 0.7092, validation loss: 0.4359
2024-05-23 21:38:17 [INFO]: Epoch 007 - training loss: 0.6670, validation loss: 0.4058
2024-05-23 21:38:19 [INFO]: Epoch 008 - training loss: 0.6343, validation loss: 0.3844
2024-05-23 21:38:22 [INFO]: Epoch 009 - training loss: 0.6073, validation loss: 0.3663
2024-05-23 21:38:24 [INFO]: Epoch 010 - training loss: 0.5874, validation loss: 0.3503
2024-05-23 21:38:26 [INFO]: Epoch 011 - training loss: 0.5700, validation loss: 0.3366
2024-05-23 21:38:28 [INFO]: Epoch 012 - training loss: 0.5549, validation loss: 0.3245
2024-05-23 21:38:30 [INFO]: Epoch 013 - training loss: 0.5434, validation loss: 0.3149
2024-05-23 21:38:33 [INFO]: Epoch 014 - training loss: 0.5306, validation loss: 0.3063
2024-05-23 21:38:35 [INFO]: Epoch 015 - training loss: 0.5199, validation loss: 0.2980
2024-05-23 21:38:38 [INFO]: Epoch 016 - training loss: 0.5125, validation loss: 0.2911
2024-05-23 21:38:40 [INFO]: Epoch 017 - training loss: 0.5036, validation loss: 0.2843
2024-05-23 21:38:42 [INFO]: Epoch 018 - training loss: 0.4933, validation loss: 0.2783
2024-05-23 21:38:45 [INFO]: Epoch 019 - training loss: 0.4859, validation loss: 0.2726
2024-05-23 21:38:47 [INFO]: Epoch 020 - training loss: 0.4780, validation loss: 0.2676
2024-05-23 21:38:49 [INFO]: Epoch 021 - training loss: 0.4720, validation loss: 0.2629
2024-05-23 21:38:52 [INFO]: Epoch 022 - training loss: 0.4661, validation loss: 0.2583
2024-05-23 21:38:54 [INFO]: Epoch 023 - training loss: 0.4597, validation loss: 0.2541
2024-05-23 21:38:57 [INFO]: Epoch 024 - training loss: 0.4528, validation loss: 0.2500
2024-05-23 21:38:59 [INFO]: Epoch 025 - training loss: 0.4474, validation loss: 0.2460
2024-05-23 21:39:01 [INFO]: Epoch 026 - training loss: 0.4420, validation loss: 0.2421
2024-05-23 21:39:04 [INFO]: Epoch 027 - training loss: 0.4372, validation loss: 0.2389
2024-05-23 21:39:06 [INFO]: Epoch 028 - training loss: 0.4309, validation loss: 0.2351
2024-05-23 21:39:08 [INFO]: Epoch 029 - training loss: 0.4258, validation loss: 0.2322
2024-05-23 21:39:11 [INFO]: Epoch 030 - training loss: 0.4218, validation loss: 0.2290
2024-05-23 21:39:13 [INFO]: Epoch 031 - training loss: 0.4181, validation loss: 0.2263
2024-05-23 21:39:16 [INFO]: Epoch 032 - training loss: 0.4131, validation loss: 0.2227
2024-05-23 21:39:18 [INFO]: Epoch 033 - training loss: 0.4098, validation loss: 0.2200
2024-05-23 21:39:20 [INFO]: Epoch 034 - training loss: 0.4043, validation loss: 0.2169
2024-05-23 21:39:23 [INFO]: Epoch 035 - training loss: 0.4015, validation loss: 0.2141
2024-05-23 21:39:25 [INFO]: Epoch 036 - training loss: 0.3963, validation loss: 0.2109
2024-05-23 21:39:28 [INFO]: Epoch 037 - training loss: 0.3925, validation loss: 0.2083
2024-05-23 21:39:30 [INFO]: Epoch 038 - training loss: 0.3891, validation loss: 0.2062
2024-05-23 21:39:32 [INFO]: Epoch 039 - training loss: 0.3862, validation loss: 0.2043
2024-05-23 21:39:35 [INFO]: Epoch 040 - training loss: 0.3842, validation loss: 0.2018
2024-05-23 21:39:37 [INFO]: Epoch 041 - training loss: 0.3797, validation loss: 0.1985
2024-05-23 21:39:39 [INFO]: Epoch 042 - training loss: 0.3764, validation loss: 0.1969
2024-05-23 21:39:42 [INFO]: Epoch 043 - training loss: 0.3728, validation loss: 0.1945
2024-05-23 21:39:44 [INFO]: Epoch 044 - training loss: 0.3699, validation loss: 0.1922
2024-05-23 21:39:46 [INFO]: Epoch 045 - training loss: 0.3674, validation loss: 0.1903
2024-05-23 21:39:49 [INFO]: Epoch 046 - training loss: 0.3647, validation loss: 0.1887
2024-05-23 21:39:51 [INFO]: Epoch 047 - training loss: 0.3624, validation loss: 0.1864
2024-05-23 21:39:54 [INFO]: Epoch 048 - training loss: 0.3597, validation loss: 0.1849
2024-05-23 21:39:56 [INFO]: Epoch 049 - training loss: 0.3570, validation loss: 0.1829
2024-05-23 21:39:58 [INFO]: Epoch 050 - training loss: 0.3545, validation loss: 0.1812
2024-05-23 21:40:01 [INFO]: Epoch 051 - training loss: 0.3528, validation loss: 0.1796
2024-05-23 21:40:03 [INFO]: Epoch 052 - training loss: 0.3500, validation loss: 0.1777
2024-05-23 21:40:05 [INFO]: Epoch 053 - training loss: 0.3486, validation loss: 0.1762
2024-05-23 21:40:08 [INFO]: Epoch 054 - training loss: 0.3460, validation loss: 0.1750
2024-05-23 21:40:10 [INFO]: Epoch 055 - training loss: 0.3447, validation loss: 0.1734
2024-05-23 21:40:12 [INFO]: Epoch 056 - training loss: 0.3425, validation loss: 0.1722
2024-05-23 21:40:15 [INFO]: Epoch 057 - training loss: 0.3401, validation loss: 0.1706
2024-05-23 21:40:17 [INFO]: Epoch 058 - training loss: 0.3384, validation loss: 0.1694
2024-05-23 21:40:20 [INFO]: Epoch 059 - training loss: 0.3370, validation loss: 0.1682
2024-05-23 21:40:22 [INFO]: Epoch 060 - training loss: 0.3351, validation loss: 0.1669
2024-05-23 21:40:24 [INFO]: Epoch 061 - training loss: 0.3340, validation loss: 0.1657
2024-05-23 21:40:27 [INFO]: Epoch 062 - training loss: 0.3317, validation loss: 0.1645
2024-05-23 21:40:29 [INFO]: Epoch 063 - training loss: 0.3299, validation loss: 0.1637
2024-05-23 21:40:32 [INFO]: Epoch 064 - training loss: 0.3286, validation loss: 0.1623
2024-05-23 21:40:34 [INFO]: Epoch 065 - training loss: 0.3271, validation loss: 0.1613
2024-05-23 21:40:36 [INFO]: Epoch 066 - training loss: 0.3252, validation loss: 0.1606
2024-05-23 21:40:39 [INFO]: Epoch 067 - training loss: 0.3246, validation loss: 0.1597
2024-05-23 21:40:41 [INFO]: Epoch 068 - training loss: 0.3227, validation loss: 0.1587
2024-05-23 21:40:43 [INFO]: Epoch 069 - training loss: 0.3216, validation loss: 0.1575
2024-05-23 21:40:46 [INFO]: Epoch 070 - training loss: 0.3204, validation loss: 0.1566
2024-05-23 21:40:48 [INFO]: Epoch 071 - training loss: 0.3192, validation loss: 0.1560
2024-05-23 21:40:50 [INFO]: Epoch 072 - training loss: 0.3179, validation loss: 0.1551
2024-05-23 21:40:52 [INFO]: Epoch 073 - training loss: 0.3172, validation loss: 0.1538
2024-05-23 21:40:55 [INFO]: Epoch 074 - training loss: 0.3160, validation loss: 0.1531
2024-05-23 21:40:57 [INFO]: Epoch 075 - training loss: 0.3148, validation loss: 0.1523
2024-05-23 21:40:59 [INFO]: Epoch 076 - training loss: 0.3138, validation loss: 0.1515
2024-05-23 21:41:01 [INFO]: Epoch 077 - training loss: 0.3127, validation loss: 0.1509
2024-05-23 21:41:04 [INFO]: Epoch 078 - training loss: 0.3119, validation loss: 0.1500
2024-05-23 21:41:06 [INFO]: Epoch 079 - training loss: 0.3105, validation loss: 0.1492
2024-05-23 21:41:08 [INFO]: Epoch 080 - training loss: 0.3093, validation loss: 0.1484
2024-05-23 21:41:10 [INFO]: Epoch 081 - training loss: 0.3082, validation loss: 0.1475
2024-05-23 21:41:12 [INFO]: Epoch 082 - training loss: 0.3070, validation loss: 0.1470
2024-05-23 21:41:15 [INFO]: Epoch 083 - training loss: 0.3068, validation loss: 0.1465
2024-05-23 21:41:17 [INFO]: Epoch 084 - training loss: 0.3058, validation loss: 0.1458
2024-05-23 21:41:19 [INFO]: Epoch 085 - training loss: 0.3050, validation loss: 0.1449
2024-05-23 21:41:21 [INFO]: Epoch 086 - training loss: 0.3036, validation loss: 0.1443
2024-05-23 21:41:24 [INFO]: Epoch 087 - training loss: 0.3028, validation loss: 0.1438
2024-05-23 21:41:26 [INFO]: Epoch 088 - training loss: 0.3026, validation loss: 0.1430
2024-05-23 21:41:28 [INFO]: Epoch 089 - training loss: 0.3016, validation loss: 0.1422
2024-05-23 21:41:30 [INFO]: Epoch 090 - training loss: 0.3006, validation loss: 0.1417
2024-05-23 21:41:32 [INFO]: Epoch 091 - training loss: 0.3004, validation loss: 0.1412
2024-05-23 21:41:35 [INFO]: Epoch 092 - training loss: 0.3002, validation loss: 0.1406
2024-05-23 21:41:37 [INFO]: Epoch 093 - training loss: 0.2985, validation loss: 0.1399
2024-05-23 21:41:39 [INFO]: Epoch 094 - training loss: 0.2981, validation loss: 0.1394
2024-05-23 21:41:41 [INFO]: Epoch 095 - training loss: 0.2972, validation loss: 0.1387
2024-05-23 21:41:44 [INFO]: Epoch 096 - training loss: 0.2971, validation loss: 0.1382
2024-05-23 21:41:46 [INFO]: Epoch 097 - training loss: 0.2959, validation loss: 0.1378
2024-05-23 21:41:48 [INFO]: Epoch 098 - training loss: 0.2951, validation loss: 0.1372
2024-05-23 21:41:50 [INFO]: Epoch 099 - training loss: 0.2952, validation loss: 0.1365
2024-05-23 21:41:52 [INFO]: Epoch 100 - training loss: 0.2943, validation loss: 0.1358
2024-05-23 21:41:55 [INFO]: Epoch 101 - training loss: 0.2926, validation loss: 0.1354
2024-05-23 21:41:57 [INFO]: Epoch 102 - training loss: 0.2924, validation loss: 0.1347
2024-05-23 21:41:59 [INFO]: Epoch 103 - training loss: 0.2928, validation loss: 0.1345
2024-05-23 21:42:02 [INFO]: Epoch 104 - training loss: 0.2921, validation loss: 0.1339
2024-05-23 21:42:04 [INFO]: Epoch 105 - training loss: 0.2909, validation loss: 0.1333
2024-05-23 21:42:06 [INFO]: Epoch 106 - training loss: 0.2900, validation loss: 0.1329
2024-05-23 21:42:08 [INFO]: Epoch 107 - training loss: 0.2896, validation loss: 0.1323
2024-05-23 21:42:10 [INFO]: Epoch 108 - training loss: 0.2894, validation loss: 0.1318
2024-05-23 21:42:13 [INFO]: Epoch 109 - training loss: 0.2886, validation loss: 0.1313
2024-05-23 21:42:15 [INFO]: Epoch 110 - training loss: 0.2879, validation loss: 0.1313
2024-05-23 21:42:17 [INFO]: Epoch 111 - training loss: 0.2870, validation loss: 0.1307
2024-05-23 21:42:19 [INFO]: Epoch 112 - training loss: 0.2870, validation loss: 0.1302
2024-05-23 21:42:22 [INFO]: Epoch 113 - training loss: 0.2856, validation loss: 0.1298
2024-05-23 21:42:24 [INFO]: Epoch 114 - training loss: 0.2858, validation loss: 0.1293
2024-05-23 21:42:26 [INFO]: Epoch 115 - training loss: 0.2851, validation loss: 0.1291
2024-05-23 21:42:28 [INFO]: Epoch 116 - training loss: 0.2847, validation loss: 0.1286
2024-05-23 21:42:30 [INFO]: Epoch 117 - training loss: 0.2843, validation loss: 0.1282
2024-05-23 21:42:33 [INFO]: Epoch 118 - training loss: 0.2834, validation loss: 0.1278
2024-05-23 21:42:35 [INFO]: Epoch 119 - training loss: 0.2830, validation loss: 0.1275
2024-05-23 21:42:37 [INFO]: Epoch 120 - training loss: 0.2829, validation loss: 0.1271
2024-05-23 21:42:39 [INFO]: Epoch 121 - training loss: 0.2820, validation loss: 0.1265
2024-05-23 21:42:42 [INFO]: Epoch 122 - training loss: 0.2816, validation loss: 0.1260
2024-05-23 21:42:44 [INFO]: Epoch 123 - training loss: 0.2815, validation loss: 0.1255
2024-05-23 21:42:46 [INFO]: Epoch 124 - training loss: 0.2803, validation loss: 0.1254
2024-05-23 21:42:48 [INFO]: Epoch 125 - training loss: 0.2800, validation loss: 0.1249
2024-05-23 21:42:50 [INFO]: Epoch 126 - training loss: 0.2796, validation loss: 0.1244
2024-05-23 21:42:53 [INFO]: Epoch 127 - training loss: 0.2794, validation loss: 0.1242
2024-05-23 21:42:55 [INFO]: Epoch 128 - training loss: 0.2792, validation loss: 0.1237
2024-05-23 21:42:57 [INFO]: Epoch 129 - training loss: 0.2787, validation loss: 0.1233
2024-05-23 21:42:59 [INFO]: Epoch 130 - training loss: 0.2774, validation loss: 0.1229
2024-05-23 21:43:02 [INFO]: Epoch 131 - training loss: 0.2775, validation loss: 0.1226
2024-05-23 21:43:04 [INFO]: Epoch 132 - training loss: 0.2776, validation loss: 0.1223
2024-05-23 21:43:06 [INFO]: Epoch 133 - training loss: 0.2775, validation loss: 0.1219
2024-05-23 21:43:08 [INFO]: Epoch 134 - training loss: 0.2770, validation loss: 0.1214
2024-05-23 21:43:10 [INFO]: Epoch 135 - training loss: 0.2759, validation loss: 0.1212
2024-05-23 21:43:13 [INFO]: Epoch 136 - training loss: 0.2755, validation loss: 0.1207
2024-05-23 21:43:15 [INFO]: Epoch 137 - training loss: 0.2748, validation loss: 0.1205
2024-05-23 21:43:17 [INFO]: Epoch 138 - training loss: 0.2748, validation loss: 0.1199
2024-05-23 21:43:19 [INFO]: Epoch 139 - training loss: 0.2741, validation loss: 0.1197
2024-05-23 21:43:22 [INFO]: Epoch 140 - training loss: 0.2734, validation loss: 0.1194
2024-05-23 21:43:24 [INFO]: Epoch 141 - training loss: 0.2732, validation loss: 0.1189
2024-05-23 21:43:26 [INFO]: Epoch 142 - training loss: 0.2734, validation loss: 0.1186
2024-05-23 21:43:28 [INFO]: Epoch 143 - training loss: 0.2728, validation loss: 0.1183
2024-05-23 21:43:30 [INFO]: Epoch 144 - training loss: 0.2730, validation loss: 0.1182
2024-05-23 21:43:33 [INFO]: Epoch 145 - training loss: 0.2722, validation loss: 0.1177
2024-05-23 21:43:35 [INFO]: Epoch 146 - training loss: 0.2720, validation loss: 0.1173
2024-05-23 21:43:37 [INFO]: Epoch 147 - training loss: 0.2712, validation loss: 0.1171
2024-05-23 21:43:39 [INFO]: Epoch 148 - training loss: 0.2713, validation loss: 0.1168
2024-05-23 21:43:42 [INFO]: Epoch 149 - training loss: 0.2703, validation loss: 0.1164
2024-05-23 21:43:44 [INFO]: Epoch 150 - training loss: 0.2698, validation loss: 0.1161
2024-05-23 21:43:46 [INFO]: Epoch 151 - training loss: 0.2702, validation loss: 0.1157
2024-05-23 21:43:48 [INFO]: Epoch 152 - training loss: 0.2696, validation loss: 0.1157
2024-05-23 21:43:51 [INFO]: Epoch 153 - training loss: 0.2694, validation loss: 0.1152
2024-05-23 21:43:53 [INFO]: Epoch 154 - training loss: 0.2693, validation loss: 0.1149
2024-05-23 21:43:55 [INFO]: Epoch 155 - training loss: 0.2688, validation loss: 0.1147
2024-05-23 21:43:57 [INFO]: Epoch 156 - training loss: 0.2681, validation loss: 0.1144
2024-05-23 21:43:59 [INFO]: Epoch 157 - training loss: 0.2679, validation loss: 0.1139
2024-05-23 21:44:02 [INFO]: Epoch 158 - training loss: 0.2671, validation loss: 0.1139
2024-05-23 21:44:04 [INFO]: Epoch 159 - training loss: 0.2676, validation loss: 0.1135
2024-05-23 21:44:06 [INFO]: Epoch 160 - training loss: 0.2665, validation loss: 0.1132
2024-05-23 21:44:08 [INFO]: Epoch 161 - training loss: 0.2668, validation loss: 0.1129
2024-05-23 21:44:11 [INFO]: Epoch 162 - training loss: 0.2666, validation loss: 0.1126
2024-05-23 21:44:13 [INFO]: Epoch 163 - training loss: 0.2658, validation loss: 0.1125
2024-05-23 21:44:15 [INFO]: Epoch 164 - training loss: 0.2653, validation loss: 0.1121
2024-05-23 21:44:17 [INFO]: Epoch 165 - training loss: 0.2653, validation loss: 0.1119
2024-05-23 21:44:19 [INFO]: Epoch 166 - training loss: 0.2653, validation loss: 0.1116
2024-05-23 21:44:22 [INFO]: Epoch 167 - training loss: 0.2651, validation loss: 0.1115
2024-05-23 21:44:24 [INFO]: Epoch 168 - training loss: 0.2640, validation loss: 0.1109
2024-05-23 21:44:26 [INFO]: Epoch 169 - training loss: 0.2642, validation loss: 0.1109
2024-05-23 21:44:28 [INFO]: Epoch 170 - training loss: 0.2639, validation loss: 0.1106
2024-05-23 21:44:31 [INFO]: Epoch 171 - training loss: 0.2635, validation loss: 0.1103
2024-05-23 21:44:33 [INFO]: Epoch 172 - training loss: 0.2640, validation loss: 0.1102
2024-05-23 21:44:35 [INFO]: Epoch 173 - training loss: 0.2630, validation loss: 0.1098
2024-05-23 21:44:37 [INFO]: Epoch 174 - training loss: 0.2636, validation loss: 0.1094
2024-05-23 21:44:40 [INFO]: Epoch 175 - training loss: 0.2628, validation loss: 0.1092
2024-05-23 21:44:42 [INFO]: Epoch 176 - training loss: 0.2620, validation loss: 0.1091
2024-05-23 21:44:44 [INFO]: Epoch 177 - training loss: 0.2625, validation loss: 0.1088
2024-05-23 21:44:46 [INFO]: Epoch 178 - training loss: 0.2622, validation loss: 0.1089
2024-05-23 21:44:49 [INFO]: Epoch 179 - training loss: 0.2616, validation loss: 0.1086
2024-05-23 21:44:51 [INFO]: Epoch 180 - training loss: 0.2614, validation loss: 0.1081
2024-05-23 21:44:53 [INFO]: Epoch 181 - training loss: 0.2610, validation loss: 0.1078
2024-05-23 21:44:55 [INFO]: Epoch 182 - training loss: 0.2607, validation loss: 0.1076
2024-05-23 21:44:57 [INFO]: Epoch 183 - training loss: 0.2609, validation loss: 0.1076
2024-05-23 21:45:00 [INFO]: Epoch 184 - training loss: 0.2601, validation loss: 0.1073
2024-05-23 21:45:02 [INFO]: Epoch 185 - training loss: 0.2601, validation loss: 0.1072
2024-05-23 21:45:04 [INFO]: Epoch 186 - training loss: 0.2603, validation loss: 0.1068
2024-05-23 21:45:06 [INFO]: Epoch 187 - training loss: 0.2596, validation loss: 0.1066
2024-05-23 21:45:09 [INFO]: Epoch 188 - training loss: 0.2595, validation loss: 0.1065
2024-05-23 21:45:11 [INFO]: Epoch 189 - training loss: 0.2595, validation loss: 0.1064
2024-05-23 21:45:13 [INFO]: Epoch 190 - training loss: 0.2591, validation loss: 0.1060
2024-05-23 21:45:15 [INFO]: Epoch 191 - training loss: 0.2597, validation loss: 0.1059
2024-05-23 21:45:18 [INFO]: Epoch 192 - training loss: 0.2581, validation loss: 0.1055
2024-05-23 21:45:20 [INFO]: Epoch 193 - training loss: 0.2582, validation loss: 0.1056
2024-05-23 21:45:22 [INFO]: Epoch 194 - training loss: 0.2581, validation loss: 0.1051
2024-05-23 21:45:24 [INFO]: Epoch 195 - training loss: 0.2572, validation loss: 0.1052
2024-05-23 21:45:26 [INFO]: Epoch 196 - training loss: 0.2581, validation loss: 0.1048
2024-05-23 21:45:29 [INFO]: Epoch 197 - training loss: 0.2581, validation loss: 0.1047
2024-05-23 21:45:31 [INFO]: Epoch 198 - training loss: 0.2570, validation loss: 0.1046
2024-05-23 21:45:33 [INFO]: Epoch 199 - training loss: 0.2565, validation loss: 0.1043
2024-05-23 21:45:35 [INFO]: Epoch 200 - training loss: 0.2576, validation loss: 0.1041
2024-05-23 21:45:38 [INFO]: Epoch 201 - training loss: 0.2564, validation loss: 0.1039
2024-05-23 21:45:40 [INFO]: Epoch 202 - training loss: 0.2565, validation loss: 0.1039
2024-05-23 21:45:42 [INFO]: Epoch 203 - training loss: 0.2562, validation loss: 0.1037
2024-05-23 21:45:44 [INFO]: Epoch 204 - training loss: 0.2557, validation loss: 0.1035
2024-05-23 21:45:47 [INFO]: Epoch 205 - training loss: 0.2557, validation loss: 0.1033
2024-05-23 21:45:49 [INFO]: Epoch 206 - training loss: 0.2554, validation loss: 0.1029
2024-05-23 21:45:51 [INFO]: Epoch 207 - training loss: 0.2550, validation loss: 0.1028
2024-05-23 21:45:53 [INFO]: Epoch 208 - training loss: 0.2549, validation loss: 0.1029
2024-05-23 21:45:55 [INFO]: Epoch 209 - training loss: 0.2547, validation loss: 0.1025
2024-05-23 21:45:58 [INFO]: Epoch 210 - training loss: 0.2544, validation loss: 0.1024
2024-05-23 21:46:00 [INFO]: Epoch 211 - training loss: 0.2543, validation loss: 0.1022
2024-05-23 21:46:02 [INFO]: Epoch 212 - training loss: 0.2543, validation loss: 0.1020
2024-05-23 21:46:04 [INFO]: Epoch 213 - training loss: 0.2536, validation loss: 0.1018
2024-05-23 21:46:07 [INFO]: Epoch 214 - training loss: 0.2535, validation loss: 0.1019
2024-05-23 21:46:09 [INFO]: Epoch 215 - training loss: 0.2533, validation loss: 0.1016
2024-05-23 21:46:11 [INFO]: Epoch 216 - training loss: 0.2529, validation loss: 0.1012
2024-05-23 21:46:13 [INFO]: Epoch 217 - training loss: 0.2530, validation loss: 0.1011
2024-05-23 21:46:16 [INFO]: Epoch 218 - training loss: 0.2529, validation loss: 0.1009
2024-05-23 21:46:18 [INFO]: Epoch 219 - training loss: 0.2527, validation loss: 0.1009
2024-05-23 21:46:20 [INFO]: Epoch 220 - training loss: 0.2525, validation loss: 0.1009
2024-05-23 21:46:22 [INFO]: Epoch 221 - training loss: 0.2529, validation loss: 0.1005
2024-05-23 21:46:24 [INFO]: Epoch 222 - training loss: 0.2522, validation loss: 0.1004
2024-05-23 21:46:27 [INFO]: Epoch 223 - training loss: 0.2523, validation loss: 0.1003
2024-05-23 21:46:29 [INFO]: Epoch 224 - training loss: 0.2518, validation loss: 0.1000
2024-05-23 21:46:31 [INFO]: Epoch 225 - training loss: 0.2512, validation loss: 0.1000
2024-05-23 21:46:33 [INFO]: Epoch 226 - training loss: 0.2513, validation loss: 0.0999
2024-05-23 21:46:36 [INFO]: Epoch 227 - training loss: 0.2511, validation loss: 0.0994
2024-05-23 21:46:38 [INFO]: Epoch 228 - training loss: 0.2515, validation loss: 0.0996
2024-05-23 21:46:40 [INFO]: Epoch 229 - training loss: 0.2508, validation loss: 0.0993
2024-05-23 21:46:42 [INFO]: Epoch 230 - training loss: 0.2505, validation loss: 0.0992
2024-05-23 21:46:44 [INFO]: Epoch 231 - training loss: 0.2511, validation loss: 0.0992
2024-05-23 21:46:47 [INFO]: Epoch 232 - training loss: 0.2503, validation loss: 0.0989
2024-05-23 21:46:49 [INFO]: Epoch 233 - training loss: 0.2511, validation loss: 0.0988
2024-05-23 21:46:51 [INFO]: Epoch 234 - training loss: 0.2502, validation loss: 0.0986
2024-05-23 21:46:54 [INFO]: Epoch 235 - training loss: 0.2502, validation loss: 0.0984
2024-05-23 21:46:56 [INFO]: Epoch 236 - training loss: 0.2497, validation loss: 0.0985
2024-05-23 21:46:58 [INFO]: Epoch 237 - training loss: 0.2494, validation loss: 0.0982
2024-05-23 21:47:00 [INFO]: Epoch 238 - training loss: 0.2493, validation loss: 0.0981
2024-05-23 21:47:02 [INFO]: Epoch 239 - training loss: 0.2498, validation loss: 0.0979
2024-05-23 21:47:05 [INFO]: Epoch 240 - training loss: 0.2493, validation loss: 0.0979
2024-05-23 21:47:07 [INFO]: Epoch 241 - training loss: 0.2488, validation loss: 0.0976
2024-05-23 21:47:09 [INFO]: Epoch 242 - training loss: 0.2486, validation loss: 0.0976
2024-05-23 21:47:11 [INFO]: Epoch 243 - training loss: 0.2485, validation loss: 0.0975
2024-05-23 21:47:14 [INFO]: Epoch 244 - training loss: 0.2484, validation loss: 0.0972
2024-05-23 21:47:16 [INFO]: Epoch 245 - training loss: 0.2480, validation loss: 0.0971
2024-05-23 21:47:18 [INFO]: Epoch 246 - training loss: 0.2483, validation loss: 0.0972
2024-05-23 21:47:20 [INFO]: Epoch 247 - training loss: 0.2482, validation loss: 0.0968
2024-05-23 21:47:23 [INFO]: Epoch 248 - training loss: 0.2473, validation loss: 0.0970
2024-05-23 21:47:25 [INFO]: Epoch 249 - training loss: 0.2475, validation loss: 0.0968
2024-05-23 21:47:27 [INFO]: Epoch 250 - training loss: 0.2477, validation loss: 0.0966
2024-05-23 21:47:29 [INFO]: Epoch 251 - training loss: 0.2473, validation loss: 0.0963
2024-05-23 21:47:31 [INFO]: Epoch 252 - training loss: 0.2472, validation loss: 0.0964
2024-05-23 21:47:34 [INFO]: Epoch 253 - training loss: 0.2470, validation loss: 0.0963
2024-05-23 21:47:36 [INFO]: Epoch 254 - training loss: 0.2469, validation loss: 0.0962
2024-05-23 21:47:38 [INFO]: Epoch 255 - training loss: 0.2468, validation loss: 0.0960
2024-05-23 21:47:40 [INFO]: Epoch 256 - training loss: 0.2463, validation loss: 0.0960
2024-05-23 21:47:43 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0960
2024-05-23 21:47:45 [INFO]: Epoch 258 - training loss: 0.2459, validation loss: 0.0958
2024-05-23 21:47:47 [INFO]: Epoch 259 - training loss: 0.2462, validation loss: 0.0956
2024-05-23 21:47:49 [INFO]: Epoch 260 - training loss: 0.2457, validation loss: 0.0956
2024-05-23 21:47:51 [INFO]: Epoch 261 - training loss: 0.2463, validation loss: 0.0955
2024-05-23 21:47:54 [INFO]: Epoch 262 - training loss: 0.2460, validation loss: 0.0954
2024-05-23 21:47:56 [INFO]: Epoch 263 - training loss: 0.2457, validation loss: 0.0952
2024-05-23 21:47:58 [INFO]: Epoch 264 - training loss: 0.2457, validation loss: 0.0950
2024-05-23 21:48:00 [INFO]: Epoch 265 - training loss: 0.2452, validation loss: 0.0952
2024-05-23 21:48:03 [INFO]: Epoch 266 - training loss: 0.2450, validation loss: 0.0949
2024-05-23 21:48:05 [INFO]: Epoch 267 - training loss: 0.2445, validation loss: 0.0946
2024-05-23 21:48:07 [INFO]: Epoch 268 - training loss: 0.2446, validation loss: 0.0947
2024-05-23 21:48:09 [INFO]: Epoch 269 - training loss: 0.2444, validation loss: 0.0947
2024-05-23 21:48:11 [INFO]: Epoch 270 - training loss: 0.2444, validation loss: 0.0946
2024-05-23 21:48:14 [INFO]: Epoch 271 - training loss: 0.2445, validation loss: 0.0944
2024-05-23 21:48:16 [INFO]: Epoch 272 - training loss: 0.2443, validation loss: 0.0944
2024-05-23 21:48:18 [INFO]: Epoch 273 - training loss: 0.2439, validation loss: 0.0943
2024-05-23 21:48:20 [INFO]: Epoch 274 - training loss: 0.2440, validation loss: 0.0940
2024-05-23 21:48:23 [INFO]: Epoch 275 - training loss: 0.2439, validation loss: 0.0941
2024-05-23 21:48:25 [INFO]: Epoch 276 - training loss: 0.2438, validation loss: 0.0939
2024-05-23 21:48:27 [INFO]: Epoch 277 - training loss: 0.2438, validation loss: 0.0940
2024-05-23 21:48:29 [INFO]: Epoch 278 - training loss: 0.2438, validation loss: 0.0936
2024-05-23 21:48:32 [INFO]: Epoch 279 - training loss: 0.2428, validation loss: 0.0936
2024-05-23 21:48:34 [INFO]: Epoch 280 - training loss: 0.2432, validation loss: 0.0937
2024-05-23 21:48:36 [INFO]: Epoch 281 - training loss: 0.2429, validation loss: 0.0935
2024-05-23 21:48:38 [INFO]: Epoch 282 - training loss: 0.2429, validation loss: 0.0934
2024-05-23 21:48:41 [INFO]: Epoch 283 - training loss: 0.2430, validation loss: 0.0934
2024-05-23 21:48:43 [INFO]: Epoch 284 - training loss: 0.2427, validation loss: 0.0931
2024-05-23 21:48:45 [INFO]: Epoch 285 - training loss: 0.2427, validation loss: 0.0933
2024-05-23 21:48:47 [INFO]: Epoch 286 - training loss: 0.2427, validation loss: 0.0930
2024-05-23 21:48:49 [INFO]: Epoch 287 - training loss: 0.2420, validation loss: 0.0929
2024-05-23 21:48:52 [INFO]: Epoch 288 - training loss: 0.2422, validation loss: 0.0930
2024-05-23 21:48:54 [INFO]: Epoch 289 - training loss: 0.2416, validation loss: 0.0930
2024-05-23 21:48:56 [INFO]: Epoch 290 - training loss: 0.2420, validation loss: 0.0926
2024-05-23 21:48:58 [INFO]: Epoch 291 - training loss: 0.2420, validation loss: 0.0927
2024-05-23 21:49:00 [INFO]: Epoch 292 - training loss: 0.2419, validation loss: 0.0926
2024-05-23 21:49:03 [INFO]: Epoch 293 - training loss: 0.2414, validation loss: 0.0926
2024-05-23 21:49:05 [INFO]: Epoch 294 - training loss: 0.2420, validation loss: 0.0925
2024-05-23 21:49:07 [INFO]: Epoch 295 - training loss: 0.2409, validation loss: 0.0924
2024-05-23 21:49:09 [INFO]: Epoch 296 - training loss: 0.2416, validation loss: 0.0922
2024-05-23 21:49:12 [INFO]: Epoch 297 - training loss: 0.2409, validation loss: 0.0923
2024-05-23 21:49:14 [INFO]: Epoch 298 - training loss: 0.2415, validation loss: 0.0923
2024-05-23 21:49:16 [INFO]: Epoch 299 - training loss: 0.2409, validation loss: 0.0921
2024-05-23 21:49:18 [INFO]: Epoch 300 - training loss: 0.2405, validation loss: 0.0920
2024-05-23 21:49:18 [INFO]: Finished training. The best model is from epoch#300.
2024-05-23 21:49:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240523_T213801/BRITS.pypots
2024-05-23 21:49:19 [INFO]: BRITS on Air-Quality: MAE=0.1415, MSE=0.1337
2024-05-23 21:49:19 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-23 21:49:19 [INFO]: Using the given device: cuda:0
2024-05-23 21:49:19 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919
2024-05-23 21:49:19 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/tensorboard
2024-05-23 21:49:19 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 21:49:22 [INFO]: Epoch 001 - training loss: 1.4790, validation loss: 0.8187
2024-05-23 21:49:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch1_loss0.8186676859855652.pypots
2024-05-23 21:49:25 [INFO]: Epoch 002 - training loss: 1.0412, validation loss: 0.7595
2024-05-23 21:49:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch2_loss0.7594968974590302.pypots
2024-05-23 21:49:29 [INFO]: Epoch 003 - training loss: 0.9695, validation loss: 0.7389
2024-05-23 21:49:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch3_loss0.7388708472251893.pypots
2024-05-23 21:49:32 [INFO]: Epoch 004 - training loss: 0.9343, validation loss: 0.7240
2024-05-23 21:49:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch4_loss0.7240070879459382.pypots
2024-05-23 21:49:35 [INFO]: Epoch 005 - training loss: 0.9264, validation loss: 0.7155
2024-05-23 21:49:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch5_loss0.7155362874269485.pypots
2024-05-23 21:49:38 [INFO]: Epoch 006 - training loss: 0.9197, validation loss: 0.7094
2024-05-23 21:49:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch6_loss0.7094117611646652.pypots
2024-05-23 21:49:41 [INFO]: Epoch 007 - training loss: 0.9045, validation loss: 0.7038
2024-05-23 21:49:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch7_loss0.7037644714117051.pypots
2024-05-23 21:49:44 [INFO]: Epoch 008 - training loss: 0.9071, validation loss: 0.7007
2024-05-23 21:49:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch8_loss0.7007348477840424.pypots
2024-05-23 21:49:47 [INFO]: Epoch 009 - training loss: 0.8855, validation loss: 0.6977
2024-05-23 21:49:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch9_loss0.6977451473474503.pypots
2024-05-23 21:49:50 [INFO]: Epoch 010 - training loss: 0.8839, validation loss: 0.6962
2024-05-23 21:49:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch10_loss0.6962056189775467.pypots
2024-05-23 21:49:53 [INFO]: Epoch 011 - training loss: 0.8971, validation loss: 0.6931
2024-05-23 21:49:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch11_loss0.6931108683347702.pypots
2024-05-23 21:49:56 [INFO]: Epoch 012 - training loss: 0.8756, validation loss: 0.6921
2024-05-23 21:49:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch12_loss0.6920965373516083.pypots
2024-05-23 21:49:59 [INFO]: Epoch 013 - training loss: 0.8764, validation loss: 0.6910
2024-05-23 21:49:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch13_loss0.6909505009651185.pypots
2024-05-23 21:50:02 [INFO]: Epoch 014 - training loss: 0.8780, validation loss: 0.6888
2024-05-23 21:50:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch14_loss0.6888132512569427.pypots
2024-05-23 21:50:05 [INFO]: Epoch 015 - training loss: 0.8537, validation loss: 0.6892
2024-05-23 21:50:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch15_loss0.6891955196857452.pypots
2024-05-23 21:50:08 [INFO]: Epoch 016 - training loss: 0.8657, validation loss: 0.6882
2024-05-23 21:50:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch16_loss0.6881587147712708.pypots
2024-05-23 21:50:11 [INFO]: Epoch 017 - training loss: 0.8512, validation loss: 0.6873
2024-05-23 21:50:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch17_loss0.6873468846082688.pypots
2024-05-23 21:50:14 [INFO]: Epoch 018 - training loss: 0.8735, validation loss: 0.6876
2024-05-23 21:50:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch18_loss0.6876453727483749.pypots
2024-05-23 21:50:17 [INFO]: Epoch 019 - training loss: 0.8507, validation loss: 0.6873
2024-05-23 21:50:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch19_loss0.6872930347919464.pypots
2024-05-23 21:50:20 [INFO]: Epoch 020 - training loss: 0.8312, validation loss: 0.6852
2024-05-23 21:50:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch20_loss0.685183310508728.pypots
2024-05-23 21:50:23 [INFO]: Epoch 021 - training loss: 0.8472, validation loss: 0.6852
2024-05-23 21:50:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch21_loss0.6851609945297241.pypots
2024-05-23 21:50:26 [INFO]: Epoch 022 - training loss: 0.8357, validation loss: 0.6857
2024-05-23 21:50:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch22_loss0.6857181638479233.pypots
2024-05-23 21:50:30 [INFO]: Epoch 023 - training loss: 0.8412, validation loss: 0.6857
2024-05-23 21:50:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch23_loss0.6856994748115539.pypots
2024-05-23 21:50:33 [INFO]: Epoch 024 - training loss: 0.8302, validation loss: 0.6865
2024-05-23 21:50:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch24_loss0.6865414381027222.pypots
2024-05-23 21:50:36 [INFO]: Epoch 025 - training loss: 0.8372, validation loss: 0.6860
2024-05-23 21:50:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch25_loss0.6859909176826477.pypots
2024-05-23 21:50:39 [INFO]: Epoch 026 - training loss: 0.8458, validation loss: 0.6860
2024-05-23 21:50:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch26_loss0.6859809070825577.pypots
2024-05-23 21:50:42 [INFO]: Epoch 027 - training loss: 0.8781, validation loss: 0.6891
2024-05-23 21:50:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch27_loss0.6891151398420334.pypots
2024-05-23 21:50:45 [INFO]: Epoch 028 - training loss: 0.8306, validation loss: 0.6885
2024-05-23 21:50:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch28_loss0.6884511440992356.pypots
2024-05-23 21:50:48 [INFO]: Epoch 029 - training loss: 0.8190, validation loss: 0.6864
2024-05-23 21:50:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch29_loss0.6863800108432769.pypots
2024-05-23 21:50:51 [INFO]: Epoch 030 - training loss: 0.8245, validation loss: 0.6849
2024-05-23 21:50:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch30_loss0.684874203801155.pypots
2024-05-23 21:50:54 [INFO]: Epoch 031 - training loss: 0.8079, validation loss: 0.6865
2024-05-23 21:50:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch31_loss0.6864611357450485.pypots
2024-05-23 21:50:57 [INFO]: Epoch 032 - training loss: 0.8161, validation loss: 0.6874
2024-05-23 21:50:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch32_loss0.6873828530311584.pypots
2024-05-23 21:51:00 [INFO]: Epoch 033 - training loss: 0.8253, validation loss: 0.6875
2024-05-23 21:51:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch33_loss0.6874715745449066.pypots
2024-05-23 21:51:03 [INFO]: Epoch 034 - training loss: 0.8064, validation loss: 0.6884
2024-05-23 21:51:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch34_loss0.6883619397878646.pypots
2024-05-23 21:51:06 [INFO]: Epoch 035 - training loss: 0.8144, validation loss: 0.6904
2024-05-23 21:51:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch35_loss0.6903529644012452.pypots
2024-05-23 21:51:09 [INFO]: Epoch 036 - training loss: 0.8117, validation loss: 0.6924
2024-05-23 21:51:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch36_loss0.69239262342453.pypots
2024-05-23 21:51:12 [INFO]: Epoch 037 - training loss: 0.8039, validation loss: 0.6871
2024-05-23 21:51:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch37_loss0.6870998561382293.pypots
2024-05-23 21:51:15 [INFO]: Epoch 038 - training loss: 0.8091, validation loss: 0.6876
2024-05-23 21:51:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch38_loss0.687587833404541.pypots
2024-05-23 21:51:18 [INFO]: Epoch 039 - training loss: 0.7997, validation loss: 0.6890
2024-05-23 21:51:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch39_loss0.6890466570854187.pypots
2024-05-23 21:51:22 [INFO]: Epoch 040 - training loss: 0.8138, validation loss: 0.6862
2024-05-23 21:51:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN_epoch40_loss0.6862457424402237.pypots
2024-05-23 21:51:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:51:22 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 21:51:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240523_T214919/MRNN.pypots
2024-05-23 21:51:22 [INFO]: MRNN on Air-Quality: MAE=0.5171, MSE=0.6574
2024-05-23 21:51:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-23 21:51:22 [INFO]: Using the given device: cpu
2024-05-23 21:51:22 [INFO]: LOCF on Air-Quality: MAE=0.2050, MSE=0.3453
2024-05-23 21:51:22 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-23 21:51:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-23 21:51:22 [INFO]: Median on Air-Quality: MAE=0.6635, MSE=1.0575
2024-05-23 21:51:22 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-23 21:51:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-23 21:51:22 [INFO]: Mean on Air-Quality: MAE=0.6949, MSE=0.9966
2024-05-23 21:51:22 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-23 21:51:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-23 21:51:22 [INFO]: 
SAITS on data/air_quality: MAE=0.152±0.00225270010206824, MSE=0.155±0.003336248210423257
Transformer on data/air_quality: MAE=0.171±0.0006218480272229789, MSE=0.179±0.0012313647735954251
TimesNet on data/air_quality: MAE=0.166±0.00626568817674605, MSE=0.218±0.00862892892603175
CSDI on data/air_quality: MAE=0.106±0.0048183366244155075, MSE=0.223±0.07741726925488202
GPVAE on data/air_quality: MAE=0.276±0.018656441770218118, MSE=0.267±0.02383553642714128
USGAN on data/air_quality: MAE=0.149±0.0013813412942226154, MSE=0.125±0.006526902739426195
BRITS on data/air_quality: MAE=0.142±0.00023864842132021648, MSE=0.131±0.002371421527471908
MRNN on data/air_quality: MAE=0.518±0.001048862206802417, MSE=0.658±0.001442468318920512
LOCF on data/air_quality: MAE=0.205±0.0, MSE=0.345±0.0
Median on data/air_quality: MAE=0.663±0.0, MSE=1.058±0.0
Mean on data/air_quality: MAE=0.695±0.0, MSE=0.997±1.1102230246251565e-16