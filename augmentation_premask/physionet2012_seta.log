2024-05-23 17:23:06 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-23 17:23:07 [INFO]: Using the given device: cuda:0
2024-05-23 17:23:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172307
2024-05-23 17:23:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172307/tensorboard
2024-05-23 17:23:08 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 17:23:17 [INFO]: Epoch 001 - training loss: 1.0415, validation loss: 0.4984
2024-05-23 17:23:18 [INFO]: Epoch 002 - training loss: 0.6788, validation loss: 0.4454
2024-05-23 17:23:19 [INFO]: Epoch 003 - training loss: 0.5656, validation loss: 0.4154
2024-05-23 17:23:20 [INFO]: Epoch 004 - training loss: 0.5105, validation loss: 0.4044
2024-05-23 17:23:21 [INFO]: Epoch 005 - training loss: 0.4619, validation loss: 0.3861
2024-05-23 17:23:23 [INFO]: Epoch 006 - training loss: 0.4344, validation loss: 0.3856
2024-05-23 17:23:24 [INFO]: Epoch 007 - training loss: 0.4153, validation loss: 0.3715
2024-05-23 17:23:25 [INFO]: Epoch 008 - training loss: 0.3882, validation loss: 0.3698
2024-05-23 17:23:26 [INFO]: Epoch 009 - training loss: 0.3727, validation loss: 0.3668
2024-05-23 17:23:27 [INFO]: Epoch 010 - training loss: 0.3611, validation loss: 0.3528
2024-05-23 17:23:28 [INFO]: Epoch 011 - training loss: 0.3409, validation loss: 0.3612
2024-05-23 17:23:29 [INFO]: Epoch 012 - training loss: 0.3241, validation loss: 0.3505
2024-05-23 17:23:30 [INFO]: Epoch 013 - training loss: 0.3067, validation loss: 0.3498
2024-05-23 17:23:32 [INFO]: Epoch 014 - training loss: 0.3000, validation loss: 0.3492
2024-05-23 17:23:33 [INFO]: Epoch 015 - training loss: 0.2893, validation loss: 0.3507
2024-05-23 17:23:34 [INFO]: Epoch 016 - training loss: 0.2746, validation loss: 0.3421
2024-05-23 17:23:35 [INFO]: Epoch 017 - training loss: 0.2724, validation loss: 0.3401
2024-05-23 17:23:36 [INFO]: Epoch 018 - training loss: 0.2567, validation loss: 0.3415
2024-05-23 17:23:37 [INFO]: Epoch 019 - training loss: 0.2529, validation loss: 0.3428
2024-05-23 17:23:38 [INFO]: Epoch 020 - training loss: 0.2438, validation loss: 0.3422
2024-05-23 17:23:39 [INFO]: Epoch 021 - training loss: 0.2430, validation loss: 0.3396
2024-05-23 17:23:41 [INFO]: Epoch 022 - training loss: 0.2344, validation loss: 0.3417
2024-05-23 17:23:42 [INFO]: Epoch 023 - training loss: 0.2272, validation loss: 0.3400
2024-05-23 17:23:43 [INFO]: Epoch 024 - training loss: 0.2198, validation loss: 0.3359
2024-05-23 17:23:44 [INFO]: Epoch 025 - training loss: 0.2099, validation loss: 0.3367
2024-05-23 17:23:45 [INFO]: Epoch 026 - training loss: 0.2105, validation loss: 0.3375
2024-05-23 17:23:46 [INFO]: Epoch 027 - training loss: 0.2030, validation loss: 0.3365
2024-05-23 17:23:47 [INFO]: Epoch 028 - training loss: 0.1999, validation loss: 0.3361
2024-05-23 17:23:49 [INFO]: Epoch 029 - training loss: 0.1974, validation loss: 0.3329
2024-05-23 17:23:50 [INFO]: Epoch 030 - training loss: 0.1922, validation loss: 0.3378
2024-05-23 17:23:51 [INFO]: Epoch 031 - training loss: 0.1856, validation loss: 0.3337
2024-05-23 17:23:52 [INFO]: Epoch 032 - training loss: 0.1865, validation loss: 0.3375
2024-05-23 17:23:53 [INFO]: Epoch 033 - training loss: 0.1871, validation loss: 0.3307
2024-05-23 17:23:54 [INFO]: Epoch 034 - training loss: 0.1778, validation loss: 0.3388
2024-05-23 17:23:56 [INFO]: Epoch 035 - training loss: 0.1721, validation loss: 0.3352
2024-05-23 17:23:57 [INFO]: Epoch 036 - training loss: 0.1709, validation loss: 0.3365
2024-05-23 17:23:58 [INFO]: Epoch 037 - training loss: 0.1680, validation loss: 0.3327
2024-05-23 17:23:59 [INFO]: Epoch 038 - training loss: 0.1672, validation loss: 0.3402
2024-05-23 17:24:00 [INFO]: Epoch 039 - training loss: 0.1646, validation loss: 0.3351
2024-05-23 17:24:01 [INFO]: Epoch 040 - training loss: 0.1639, validation loss: 0.3340
2024-05-23 17:24:03 [INFO]: Epoch 041 - training loss: 0.1595, validation loss: 0.3335
2024-05-23 17:24:04 [INFO]: Epoch 042 - training loss: 0.1602, validation loss: 0.3420
2024-05-23 17:24:05 [INFO]: Epoch 043 - training loss: 0.1590, validation loss: 0.3341
2024-05-23 17:24:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:24:05 [INFO]: Finished training. The best model is from epoch#33.
2024-05-23 17:24:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172307/SAITS.pypots
2024-05-23 17:24:05 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2657, MSE=0.2895
2024-05-23 17:24:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 17:24:06 [INFO]: Using the given device: cuda:0
2024-05-23 17:24:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172406
2024-05-23 17:24:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172406/tensorboard
2024-05-23 17:24:06 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 17:24:06 [INFO]: Epoch 001 - training loss: 1.1415, validation loss: 0.5532
2024-05-23 17:24:07 [INFO]: Epoch 002 - training loss: 0.7122, validation loss: 0.4902
2024-05-23 17:24:08 [INFO]: Epoch 003 - training loss: 0.6155, validation loss: 0.4619
2024-05-23 17:24:08 [INFO]: Epoch 004 - training loss: 0.5629, validation loss: 0.4508
2024-05-23 17:24:09 [INFO]: Epoch 005 - training loss: 0.5288, validation loss: 0.4421
2024-05-23 17:24:09 [INFO]: Epoch 006 - training loss: 0.4949, validation loss: 0.4213
2024-05-23 17:24:10 [INFO]: Epoch 007 - training loss: 0.4656, validation loss: 0.4159
2024-05-23 17:24:11 [INFO]: Epoch 008 - training loss: 0.4525, validation loss: 0.4128
2024-05-23 17:24:11 [INFO]: Epoch 009 - training loss: 0.4357, validation loss: 0.4029
2024-05-23 17:24:12 [INFO]: Epoch 010 - training loss: 0.4191, validation loss: 0.3937
2024-05-23 17:24:12 [INFO]: Epoch 011 - training loss: 0.3989, validation loss: 0.3892
2024-05-23 17:24:13 [INFO]: Epoch 012 - training loss: 0.3864, validation loss: 0.3903
2024-05-23 17:24:13 [INFO]: Epoch 013 - training loss: 0.3807, validation loss: 0.3802
2024-05-23 17:24:14 [INFO]: Epoch 014 - training loss: 0.3697, validation loss: 0.3811
2024-05-23 17:24:15 [INFO]: Epoch 015 - training loss: 0.3587, validation loss: 0.3803
2024-05-23 17:24:16 [INFO]: Epoch 016 - training loss: 0.3517, validation loss: 0.3813
2024-05-23 17:24:16 [INFO]: Epoch 017 - training loss: 0.3440, validation loss: 0.3717
2024-05-23 17:24:17 [INFO]: Epoch 018 - training loss: 0.3352, validation loss: 0.3658
2024-05-23 17:24:17 [INFO]: Epoch 019 - training loss: 0.3307, validation loss: 0.3638
2024-05-23 17:24:18 [INFO]: Epoch 020 - training loss: 0.3237, validation loss: 0.3660
2024-05-23 17:24:19 [INFO]: Epoch 021 - training loss: 0.3141, validation loss: 0.3635
2024-05-23 17:24:19 [INFO]: Epoch 022 - training loss: 0.3086, validation loss: 0.3643
2024-05-23 17:24:20 [INFO]: Epoch 023 - training loss: 0.2970, validation loss: 0.3597
2024-05-23 17:24:20 [INFO]: Epoch 024 - training loss: 0.2951, validation loss: 0.3582
2024-05-23 17:24:21 [INFO]: Epoch 025 - training loss: 0.2901, validation loss: 0.3549
2024-05-23 17:24:21 [INFO]: Epoch 026 - training loss: 0.2849, validation loss: 0.3592
2024-05-23 17:24:22 [INFO]: Epoch 027 - training loss: 0.2829, validation loss: 0.3541
2024-05-23 17:24:23 [INFO]: Epoch 028 - training loss: 0.2784, validation loss: 0.3662
2024-05-23 17:24:23 [INFO]: Epoch 029 - training loss: 0.2726, validation loss: 0.3562
2024-05-23 17:24:24 [INFO]: Epoch 030 - training loss: 0.2699, validation loss: 0.3597
2024-05-23 17:24:24 [INFO]: Epoch 031 - training loss: 0.2624, validation loss: 0.3563
2024-05-23 17:24:25 [INFO]: Epoch 032 - training loss: 0.2597, validation loss: 0.3549
2024-05-23 17:24:26 [INFO]: Epoch 033 - training loss: 0.2561, validation loss: 0.3520
2024-05-23 17:24:26 [INFO]: Epoch 034 - training loss: 0.2494, validation loss: 0.3573
2024-05-23 17:24:27 [INFO]: Epoch 035 - training loss: 0.2470, validation loss: 0.3562
2024-05-23 17:24:27 [INFO]: Epoch 036 - training loss: 0.2440, validation loss: 0.3545
2024-05-23 17:24:28 [INFO]: Epoch 037 - training loss: 0.2412, validation loss: 0.3576
2024-05-23 17:24:29 [INFO]: Epoch 038 - training loss: 0.2397, validation loss: 0.3571
2024-05-23 17:24:29 [INFO]: Epoch 039 - training loss: 0.2346, validation loss: 0.3537
2024-05-23 17:24:30 [INFO]: Epoch 040 - training loss: 0.2332, validation loss: 0.3581
2024-05-23 17:24:30 [INFO]: Epoch 041 - training loss: 0.2314, validation loss: 0.3561
2024-05-23 17:24:31 [INFO]: Epoch 042 - training loss: 0.2258, validation loss: 0.3584
2024-05-23 17:24:32 [INFO]: Epoch 043 - training loss: 0.2234, validation loss: 0.3554
2024-05-23 17:24:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:24:32 [INFO]: Finished training. The best model is from epoch#33.
2024-05-23 17:24:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172406/Transformer.pypots
2024-05-23 17:24:32 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2839, MSE=0.2986
2024-05-23 17:24:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 17:24:32 [INFO]: Using the given device: cuda:0
2024-05-23 17:24:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172432
2024-05-23 17:24:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172432/tensorboard
2024-05-23 17:24:32 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 17:24:38 [INFO]: Epoch 001 - training loss: 0.4791, validation loss: 0.6362
2024-05-23 17:24:39 [INFO]: Epoch 002 - training loss: 0.3787, validation loss: 2.2316
2024-05-23 17:24:40 [INFO]: Epoch 003 - training loss: 0.7716, validation loss: 0.4121
2024-05-23 17:24:41 [INFO]: Epoch 004 - training loss: 0.3449, validation loss: 0.3826
2024-05-23 17:24:41 [INFO]: Epoch 005 - training loss: 0.3312, validation loss: 0.3757
2024-05-23 17:24:42 [INFO]: Epoch 006 - training loss: 0.3181, validation loss: 0.3253
2024-05-23 17:24:43 [INFO]: Epoch 007 - training loss: 0.3041, validation loss: 0.3270
2024-05-23 17:24:43 [INFO]: Epoch 008 - training loss: 0.2896, validation loss: 0.3353
2024-05-23 17:24:44 [INFO]: Epoch 009 - training loss: 0.2858, validation loss: 0.3133
2024-05-23 17:24:45 [INFO]: Epoch 010 - training loss: 0.2822, validation loss: 0.3251
2024-05-23 17:24:46 [INFO]: Epoch 011 - training loss: 0.2757, validation loss: 0.3207
2024-05-23 17:24:46 [INFO]: Epoch 012 - training loss: 0.2673, validation loss: 0.3284
2024-05-23 17:24:47 [INFO]: Epoch 013 - training loss: 0.2640, validation loss: 0.3288
2024-05-23 17:24:48 [INFO]: Epoch 014 - training loss: 0.2718, validation loss: 0.3288
2024-05-23 17:24:49 [INFO]: Epoch 015 - training loss: 0.2795, validation loss: 0.3159
2024-05-23 17:24:49 [INFO]: Epoch 016 - training loss: 0.2629, validation loss: 0.3329
2024-05-23 17:24:50 [INFO]: Epoch 017 - training loss: 0.2490, validation loss: 0.3202
2024-05-23 17:24:51 [INFO]: Epoch 018 - training loss: 0.2426, validation loss: 0.3365
2024-05-23 17:24:51 [INFO]: Epoch 019 - training loss: 0.2381, validation loss: 0.3340
2024-05-23 17:24:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:24:51 [INFO]: Finished training. The best model is from epoch#9.
2024-05-23 17:24:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172432/TimesNet.pypots
2024-05-23 17:24:52 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2891, MSE=0.2836
2024-05-23 17:24:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 17:24:52 [INFO]: Using the given device: cuda:0
2024-05-23 17:24:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452
2024-05-23 17:24:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/tensorboard
2024-05-23 17:24:52 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 17:25:36 [INFO]: Epoch 001 - training loss: 0.4309, validation loss: 0.3366
2024-05-23 17:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch1_loss0.3365690976381302.pypots
2024-05-23 17:26:19 [INFO]: Epoch 002 - training loss: 0.3219, validation loss: 0.3058
2024-05-23 17:26:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch2_loss0.3057858183979988.pypots
2024-05-23 17:27:03 [INFO]: Epoch 003 - training loss: 0.2958, validation loss: 0.2813
2024-05-23 17:27:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch3_loss0.2813489124178886.pypots
2024-05-23 17:27:47 [INFO]: Epoch 004 - training loss: 0.2600, validation loss: 0.2519
2024-05-23 17:27:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch4_loss0.2519289702177048.pypots
2024-05-23 17:28:30 [INFO]: Epoch 005 - training loss: 0.2683, validation loss: 0.2489
2024-05-23 17:28:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch5_loss0.24886178895831107.pypots
2024-05-23 17:29:14 [INFO]: Epoch 006 - training loss: 0.2530, validation loss: 0.2385
2024-05-23 17:29:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch6_loss0.23845692723989487.pypots
2024-05-23 17:29:58 [INFO]: Epoch 007 - training loss: 0.2391, validation loss: 0.2270
2024-05-23 17:29:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch7_loss0.2269957147538662.pypots
2024-05-23 17:30:42 [INFO]: Epoch 008 - training loss: 0.2417, validation loss: 0.2311
2024-05-23 17:30:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch8_loss0.23109735995531083.pypots
2024-05-23 17:31:26 [INFO]: Epoch 009 - training loss: 0.2362, validation loss: 0.2208
2024-05-23 17:31:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch9_loss0.22076579555869102.pypots
2024-05-23 17:32:09 [INFO]: Epoch 010 - training loss: 0.2235, validation loss: 0.2134
2024-05-23 17:32:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch10_loss0.2133884459733963.pypots
2024-05-23 17:32:53 [INFO]: Epoch 011 - training loss: 0.2250, validation loss: 0.2159
2024-05-23 17:32:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch11_loss0.21588833257555962.pypots
2024-05-23 17:33:36 [INFO]: Epoch 012 - training loss: 0.2263, validation loss: 0.2131
2024-05-23 17:33:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch12_loss0.21306920573115348.pypots
2024-05-23 17:34:20 [INFO]: Epoch 013 - training loss: 0.2189, validation loss: 0.2143
2024-05-23 17:34:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch13_loss0.21427622586488723.pypots
2024-05-23 17:35:04 [INFO]: Epoch 014 - training loss: 0.2233, validation loss: 0.2118
2024-05-23 17:35:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch14_loss0.2117934085428715.pypots
2024-05-23 17:35:48 [INFO]: Epoch 015 - training loss: 0.2211, validation loss: 0.2095
2024-05-23 17:35:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch15_loss0.20948545038700103.pypots
2024-05-23 17:36:32 [INFO]: Epoch 016 - training loss: 0.2050, validation loss: 0.2052
2024-05-23 17:36:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch16_loss0.20518705770373344.pypots
2024-05-23 17:37:16 [INFO]: Epoch 017 - training loss: 0.2000, validation loss: 0.2074
2024-05-23 17:37:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch17_loss0.2074311003088951.pypots
2024-05-23 17:37:59 [INFO]: Epoch 018 - training loss: 0.2053, validation loss: 0.2023
2024-05-23 17:37:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch18_loss0.20226990729570388.pypots
2024-05-23 17:38:43 [INFO]: Epoch 019 - training loss: 0.2072, validation loss: 0.2052
2024-05-23 17:38:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch19_loss0.205194590985775.pypots
2024-05-23 17:39:27 [INFO]: Epoch 020 - training loss: 0.2276, validation loss: 0.2042
2024-05-23 17:39:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch20_loss0.20417295768857002.pypots
2024-05-23 17:40:11 [INFO]: Epoch 021 - training loss: 0.2079, validation loss: 0.2016
2024-05-23 17:40:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch21_loss0.2016381949186325.pypots
2024-05-23 17:40:55 [INFO]: Epoch 022 - training loss: 0.1995, validation loss: 0.2016
2024-05-23 17:40:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch22_loss0.2016058824956417.pypots
2024-05-23 17:41:39 [INFO]: Epoch 023 - training loss: 0.2069, validation loss: 0.2002
2024-05-23 17:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch23_loss0.20017834827303888.pypots
2024-05-23 17:42:23 [INFO]: Epoch 024 - training loss: 0.2004, validation loss: 0.2009
2024-05-23 17:42:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch24_loss0.20085999816656114.pypots
2024-05-23 17:43:06 [INFO]: Epoch 025 - training loss: 0.2132, validation loss: 0.2037
2024-05-23 17:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch25_loss0.2036666043102741.pypots
2024-05-23 17:43:50 [INFO]: Epoch 026 - training loss: 0.2136, validation loss: 0.2026
2024-05-23 17:43:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch26_loss0.2026084505021572.pypots
2024-05-23 17:44:34 [INFO]: Epoch 027 - training loss: 0.1998, validation loss: 0.1966
2024-05-23 17:44:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch27_loss0.1965643621981144.pypots
2024-05-23 17:45:18 [INFO]: Epoch 028 - training loss: 0.2036, validation loss: 0.2024
2024-05-23 17:45:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch28_loss0.20244734212756157.pypots
2024-05-23 17:46:01 [INFO]: Epoch 029 - training loss: 0.2124, validation loss: 0.1954
2024-05-23 17:46:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch29_loss0.19535174667835237.pypots
2024-05-23 17:46:45 [INFO]: Epoch 030 - training loss: 0.2090, validation loss: 0.1952
2024-05-23 17:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch30_loss0.19524950683116912.pypots
2024-05-23 17:47:29 [INFO]: Epoch 031 - training loss: 0.1955, validation loss: 0.1963
2024-05-23 17:47:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch31_loss0.19631102681159973.pypots
2024-05-23 17:48:13 [INFO]: Epoch 032 - training loss: 0.2025, validation loss: 0.1978
2024-05-23 17:48:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch32_loss0.1977803222835064.pypots
2024-05-23 17:48:56 [INFO]: Epoch 033 - training loss: 0.1960, validation loss: 0.1967
2024-05-23 17:48:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch33_loss0.19665494412183762.pypots
2024-05-23 17:49:40 [INFO]: Epoch 034 - training loss: 0.1987, validation loss: 0.1970
2024-05-23 17:49:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch34_loss0.19700324907898903.pypots
2024-05-23 17:50:23 [INFO]: Epoch 035 - training loss: 0.2051, validation loss: 0.1924
2024-05-23 17:50:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch35_loss0.1924407497048378.pypots
2024-05-23 17:51:07 [INFO]: Epoch 036 - training loss: 0.1933, validation loss: 0.1923
2024-05-23 17:51:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch36_loss0.19233464822173119.pypots
2024-05-23 17:51:50 [INFO]: Epoch 037 - training loss: 0.1976, validation loss: 0.1940
2024-05-23 17:51:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch37_loss0.19397104680538177.pypots
2024-05-23 17:52:34 [INFO]: Epoch 038 - training loss: 0.2041, validation loss: 0.1928
2024-05-23 17:52:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch38_loss0.1928123064339161.pypots
2024-05-23 17:53:17 [INFO]: Epoch 039 - training loss: 0.1955, validation loss: 0.2039
2024-05-23 17:53:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch39_loss0.2038845218718052.pypots
2024-05-23 17:54:01 [INFO]: Epoch 040 - training loss: 0.1910, validation loss: 0.1941
2024-05-23 17:54:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch40_loss0.19406994432210922.pypots
2024-05-23 17:54:45 [INFO]: Epoch 041 - training loss: 0.1998, validation loss: 0.1959
2024-05-23 17:54:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch41_loss0.19592007175087928.pypots
2024-05-23 17:55:28 [INFO]: Epoch 042 - training loss: 0.1863, validation loss: 0.1968
2024-05-23 17:55:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch42_loss0.1968134820461273.pypots
2024-05-23 17:56:12 [INFO]: Epoch 043 - training loss: 0.2042, validation loss: 0.1906
2024-05-23 17:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch43_loss0.1905861735343933.pypots
2024-05-23 17:56:55 [INFO]: Epoch 044 - training loss: 0.2013, validation loss: 0.1909
2024-05-23 17:56:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch44_loss0.1909445084631443.pypots
2024-05-23 17:57:39 [INFO]: Epoch 045 - training loss: 0.1955, validation loss: 0.1906
2024-05-23 17:57:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch45_loss0.19055543839931488.pypots
2024-05-23 17:58:22 [INFO]: Epoch 046 - training loss: 0.1920, validation loss: 0.1931
2024-05-23 17:58:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch46_loss0.19314085096120834.pypots
2024-05-23 17:59:06 [INFO]: Epoch 047 - training loss: 0.1974, validation loss: 0.1901
2024-05-23 17:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch47_loss0.19012149199843406.pypots
2024-05-23 17:59:50 [INFO]: Epoch 048 - training loss: 0.1939, validation loss: 0.1903
2024-05-23 17:59:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch48_loss0.19027784392237662.pypots
2024-05-23 18:00:33 [INFO]: Epoch 049 - training loss: 0.1906, validation loss: 0.1958
2024-05-23 18:00:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch49_loss0.1957809843122959.pypots
2024-05-23 18:01:17 [INFO]: Epoch 050 - training loss: 0.2009, validation loss: 0.1887
2024-05-23 18:01:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch50_loss0.18871647119522095.pypots
2024-05-23 18:02:00 [INFO]: Epoch 051 - training loss: 0.1999, validation loss: 0.1883
2024-05-23 18:02:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch51_loss0.18830547109246254.pypots
2024-05-23 18:02:44 [INFO]: Epoch 052 - training loss: 0.1880, validation loss: 0.1896
2024-05-23 18:02:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch52_loss0.18964334949851036.pypots
2024-05-23 18:03:28 [INFO]: Epoch 053 - training loss: 0.1863, validation loss: 0.1871
2024-05-23 18:03:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch53_loss0.18710778802633285.pypots
2024-05-23 18:04:11 [INFO]: Epoch 054 - training loss: 0.1866, validation loss: 0.1914
2024-05-23 18:04:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch54_loss0.1914174161851406.pypots
2024-05-23 18:04:55 [INFO]: Epoch 055 - training loss: 0.1930, validation loss: 0.1905
2024-05-23 18:04:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch55_loss0.19054684340953826.pypots
2024-05-23 18:05:39 [INFO]: Epoch 056 - training loss: 0.1858, validation loss: 0.1907
2024-05-23 18:05:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch56_loss0.19065622091293336.pypots
2024-05-23 18:06:22 [INFO]: Epoch 057 - training loss: 0.2000, validation loss: 0.1888
2024-05-23 18:06:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch57_loss0.1887838639318943.pypots
2024-05-23 18:07:06 [INFO]: Epoch 058 - training loss: 0.1929, validation loss: 0.1883
2024-05-23 18:07:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch58_loss0.1882549874484539.pypots
2024-05-23 18:07:50 [INFO]: Epoch 059 - training loss: 0.1948, validation loss: 0.1895
2024-05-23 18:07:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch59_loss0.1895251490175724.pypots
2024-05-23 18:08:33 [INFO]: Epoch 060 - training loss: 0.1966, validation loss: 0.1895
2024-05-23 18:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch60_loss0.18948485627770423.pypots
2024-05-23 18:09:17 [INFO]: Epoch 061 - training loss: 0.1809, validation loss: 0.1898
2024-05-23 18:09:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch61_loss0.189822219312191.pypots
2024-05-23 18:10:01 [INFO]: Epoch 062 - training loss: 0.1979, validation loss: 0.1868
2024-05-23 18:10:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch62_loss0.18684635907411576.pypots
2024-05-23 18:10:45 [INFO]: Epoch 063 - training loss: 0.1982, validation loss: 0.1891
2024-05-23 18:10:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch63_loss0.1890926741063595.pypots
2024-05-23 18:11:29 [INFO]: Epoch 064 - training loss: 0.1956, validation loss: 0.1883
2024-05-23 18:11:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch64_loss0.18834297508001327.pypots
2024-05-23 18:12:13 [INFO]: Epoch 065 - training loss: 0.1928, validation loss: 0.1879
2024-05-23 18:12:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch65_loss0.18793850615620614.pypots
2024-05-23 18:12:56 [INFO]: Epoch 066 - training loss: 0.1967, validation loss: 0.1877
2024-05-23 18:12:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch66_loss0.18774943351745604.pypots
2024-05-23 18:13:40 [INFO]: Epoch 067 - training loss: 0.1844, validation loss: 0.1857
2024-05-23 18:13:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch67_loss0.18567741587758063.pypots
2024-05-23 18:14:24 [INFO]: Epoch 068 - training loss: 0.1983, validation loss: 0.1877
2024-05-23 18:14:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch68_loss0.1876835510134697.pypots
2024-05-23 18:15:08 [INFO]: Epoch 069 - training loss: 0.1818, validation loss: 0.1865
2024-05-23 18:15:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch69_loss0.18651129454374313.pypots
2024-05-23 18:15:52 [INFO]: Epoch 070 - training loss: 0.1935, validation loss: 0.1850
2024-05-23 18:15:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch70_loss0.18504780530929565.pypots
2024-05-23 18:16:35 [INFO]: Epoch 071 - training loss: 0.1907, validation loss: 0.1852
2024-05-23 18:16:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch71_loss0.18524713739752768.pypots
2024-05-23 18:17:19 [INFO]: Epoch 072 - training loss: 0.1813, validation loss: 0.1892
2024-05-23 18:17:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch72_loss0.1891959138214588.pypots
2024-05-23 18:18:03 [INFO]: Epoch 073 - training loss: 0.1890, validation loss: 0.1869
2024-05-23 18:18:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch73_loss0.18690082281827927.pypots
2024-05-23 18:18:46 [INFO]: Epoch 074 - training loss: 0.1970, validation loss: 0.1860
2024-05-23 18:18:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch74_loss0.18596228435635567.pypots
2024-05-23 18:19:30 [INFO]: Epoch 075 - training loss: 0.1926, validation loss: 0.1892
2024-05-23 18:19:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch75_loss0.1892197050154209.pypots
2024-05-23 18:20:14 [INFO]: Epoch 076 - training loss: 0.1892, validation loss: 0.1849
2024-05-23 18:20:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch76_loss0.18490996807813645.pypots
2024-05-23 18:20:58 [INFO]: Epoch 077 - training loss: 0.1898, validation loss: 0.1851
2024-05-23 18:20:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch77_loss0.18506654351949692.pypots
2024-05-23 18:21:42 [INFO]: Epoch 078 - training loss: 0.1922, validation loss: 0.1852
2024-05-23 18:21:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch78_loss0.1852015547454357.pypots
2024-05-23 18:22:25 [INFO]: Epoch 079 - training loss: 0.1787, validation loss: 0.1876
2024-05-23 18:22:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch79_loss0.18761998638510705.pypots
2024-05-23 18:23:09 [INFO]: Epoch 080 - training loss: 0.1955, validation loss: 0.1901
2024-05-23 18:23:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch80_loss0.19010035693645477.pypots
2024-05-23 18:23:53 [INFO]: Epoch 081 - training loss: 0.1913, validation loss: 0.1852
2024-05-23 18:23:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch81_loss0.18524818047881125.pypots
2024-05-23 18:24:37 [INFO]: Epoch 082 - training loss: 0.1862, validation loss: 0.1836
2024-05-23 18:24:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch82_loss0.1836306668817997.pypots
2024-05-23 18:25:20 [INFO]: Epoch 083 - training loss: 0.1949, validation loss: 0.1854
2024-05-23 18:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch83_loss0.1854444794356823.pypots
2024-05-23 18:26:04 [INFO]: Epoch 084 - training loss: 0.1839, validation loss: 0.1843
2024-05-23 18:26:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch84_loss0.18430075719952582.pypots
2024-05-23 18:26:48 [INFO]: Epoch 085 - training loss: 0.1908, validation loss: 0.1856
2024-05-23 18:26:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch85_loss0.18557274639606475.pypots
2024-05-23 18:27:31 [INFO]: Epoch 086 - training loss: 0.1866, validation loss: 0.1846
2024-05-23 18:27:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch86_loss0.18462158367037773.pypots
2024-05-23 18:28:15 [INFO]: Epoch 087 - training loss: 0.1876, validation loss: 0.1838
2024-05-23 18:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch87_loss0.18383617997169494.pypots
2024-05-23 18:28:59 [INFO]: Epoch 088 - training loss: 0.1949, validation loss: 0.1850
2024-05-23 18:28:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch88_loss0.18501424193382263.pypots
2024-05-23 18:29:42 [INFO]: Epoch 089 - training loss: 0.1833, validation loss: 0.1888
2024-05-23 18:29:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch89_loss0.18876712322235106.pypots
2024-05-23 18:30:26 [INFO]: Epoch 090 - training loss: 0.1901, validation loss: 0.1855
2024-05-23 18:30:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch90_loss0.1854618489742279.pypots
2024-05-23 18:31:10 [INFO]: Epoch 091 - training loss: 0.1776, validation loss: 0.1837
2024-05-23 18:31:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch91_loss0.1836617633700371.pypots
2024-05-23 18:31:53 [INFO]: Epoch 092 - training loss: 0.1853, validation loss: 0.1843
2024-05-23 18:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI_epoch92_loss0.18433926478028298.pypots
2024-05-23 18:31:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:31:53 [INFO]: Finished training. The best model is from epoch#82.
2024-05-23 18:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172452/CSDI.pypots
2024-05-23 18:39:13 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2339, MSE=0.2528
2024-05-23 19:08:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 19:08:28 [INFO]: Using the given device: cuda:0
2024-05-23 19:08:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T190828
2024-05-23 19:08:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T190828/tensorboard
2024-05-23 19:08:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 19:08:31 [INFO]: Epoch 001 - training loss: 42590.6853, validation loss: 0.9434
2024-05-23 19:08:31 [INFO]: Epoch 002 - training loss: 24399.6823, validation loss: 0.7539
2024-05-23 19:08:32 [INFO]: Epoch 003 - training loss: 23474.9996, validation loss: 0.7305
2024-05-23 19:08:32 [INFO]: Epoch 004 - training loss: 23182.0828, validation loss: 0.6875
2024-05-23 19:08:33 [INFO]: Epoch 005 - training loss: 23034.6801, validation loss: 0.6739
2024-05-23 19:08:34 [INFO]: Epoch 006 - training loss: 22952.5328, validation loss: 0.6711
2024-05-23 19:08:34 [INFO]: Epoch 007 - training loss: 22903.6539, validation loss: 0.6690
2024-05-23 19:08:35 [INFO]: Epoch 008 - training loss: 22872.2660, validation loss: 0.6682
2024-05-23 19:08:35 [INFO]: Epoch 009 - training loss: 22851.4206, validation loss: 0.6663
2024-05-23 19:08:36 [INFO]: Epoch 010 - training loss: 22836.4237, validation loss: 0.6667
2024-05-23 19:08:37 [INFO]: Epoch 011 - training loss: 22825.8462, validation loss: 0.6757
2024-05-23 19:08:37 [INFO]: Epoch 012 - training loss: 22817.9052, validation loss: 0.6627
2024-05-23 19:08:38 [INFO]: Epoch 013 - training loss: 22812.5058, validation loss: 0.6684
2024-05-23 19:08:38 [INFO]: Epoch 014 - training loss: 22807.3886, validation loss: 0.6588
2024-05-23 19:08:39 [INFO]: Epoch 015 - training loss: 22803.7381, validation loss: 0.6561
2024-05-23 19:08:39 [INFO]: Epoch 016 - training loss: 22800.2958, validation loss: 0.6592
2024-05-23 19:08:40 [INFO]: Epoch 017 - training loss: 22799.1790, validation loss: 0.6519
2024-05-23 19:08:41 [INFO]: Epoch 018 - training loss: 22796.2530, validation loss: 0.6536
2024-05-23 19:08:41 [INFO]: Epoch 019 - training loss: 22794.2123, validation loss: 0.6506
2024-05-23 19:08:42 [INFO]: Epoch 020 - training loss: 22791.9219, validation loss: 0.6418
2024-05-23 19:08:42 [INFO]: Epoch 021 - training loss: 22790.0737, validation loss: 0.6407
2024-05-23 19:08:43 [INFO]: Epoch 022 - training loss: 22788.6724, validation loss: 0.6377
2024-05-23 19:08:44 [INFO]: Epoch 023 - training loss: 22787.8518, validation loss: 0.6388
2024-05-23 19:08:44 [INFO]: Epoch 024 - training loss: 22787.4424, validation loss: 0.6347
2024-05-23 19:08:45 [INFO]: Epoch 025 - training loss: 22787.1101, validation loss: 0.6346
2024-05-23 19:08:45 [INFO]: Epoch 026 - training loss: 22785.2426, validation loss: 0.6379
2024-05-23 19:08:46 [INFO]: Epoch 027 - training loss: 22784.7515, validation loss: 0.6356
2024-05-23 19:08:46 [INFO]: Epoch 028 - training loss: 22783.6692, validation loss: 0.6408
2024-05-23 19:08:47 [INFO]: Epoch 029 - training loss: 22783.4630, validation loss: 0.6315
2024-05-23 19:08:48 [INFO]: Epoch 030 - training loss: 22782.6365, validation loss: 0.6304
2024-05-23 19:08:48 [INFO]: Epoch 031 - training loss: 22783.4208, validation loss: 0.6338
2024-05-23 19:08:49 [INFO]: Epoch 032 - training loss: 22782.2916, validation loss: 0.6284
2024-05-23 19:08:49 [INFO]: Epoch 033 - training loss: 22781.9949, validation loss: 0.6279
2024-05-23 19:08:50 [INFO]: Epoch 034 - training loss: 22781.5774, validation loss: 0.6284
2024-05-23 19:08:50 [INFO]: Epoch 035 - training loss: 22781.2423, validation loss: 0.6285
2024-05-23 19:08:51 [INFO]: Epoch 036 - training loss: 22780.7194, validation loss: 0.6314
2024-05-23 19:08:52 [INFO]: Epoch 037 - training loss: 22780.4367, validation loss: 0.6318
2024-05-23 19:08:52 [INFO]: Epoch 038 - training loss: 22779.9065, validation loss: 0.6364
2024-05-23 19:08:53 [INFO]: Epoch 039 - training loss: 22780.8815, validation loss: 0.6275
2024-05-23 19:08:53 [INFO]: Epoch 040 - training loss: 22780.1461, validation loss: 0.6271
2024-05-23 19:08:54 [INFO]: Epoch 041 - training loss: 22778.8930, validation loss: 0.6278
2024-05-23 19:08:55 [INFO]: Epoch 042 - training loss: 22778.3845, validation loss: 0.6222
2024-05-23 19:08:55 [INFO]: Epoch 043 - training loss: 22777.3878, validation loss: 0.6188
2024-05-23 19:08:56 [INFO]: Epoch 044 - training loss: 22776.5165, validation loss: 0.6169
2024-05-23 19:08:56 [INFO]: Epoch 045 - training loss: 22776.0390, validation loss: 0.6132
2024-05-23 19:08:57 [INFO]: Epoch 046 - training loss: 22774.7700, validation loss: 0.6160
2024-05-23 19:08:57 [INFO]: Epoch 047 - training loss: 22774.2132, validation loss: 0.6094
2024-05-23 19:08:58 [INFO]: Epoch 048 - training loss: 22773.0173, validation loss: 0.6082
2024-05-23 19:08:59 [INFO]: Epoch 049 - training loss: 22772.4634, validation loss: 0.6084
2024-05-23 19:08:59 [INFO]: Epoch 050 - training loss: 22771.7202, validation loss: 0.6034
2024-05-23 19:09:00 [INFO]: Epoch 051 - training loss: 22771.9836, validation loss: 0.6034
2024-05-23 19:09:00 [INFO]: Epoch 052 - training loss: 22769.7460, validation loss: 0.6001
2024-05-23 19:09:01 [INFO]: Epoch 053 - training loss: 22769.1913, validation loss: 0.5942
2024-05-23 19:09:02 [INFO]: Epoch 054 - training loss: 22768.8778, validation loss: 0.6132
2024-05-23 19:09:02 [INFO]: Epoch 055 - training loss: 22768.8016, validation loss: 0.5846
2024-05-23 19:09:03 [INFO]: Epoch 056 - training loss: 22767.2855, validation loss: 0.5889
2024-05-23 19:09:03 [INFO]: Epoch 057 - training loss: 22765.5348, validation loss: 0.5800
2024-05-23 19:09:04 [INFO]: Epoch 058 - training loss: 22764.8553, validation loss: 0.5777
2024-05-23 19:09:05 [INFO]: Epoch 059 - training loss: 22764.5068, validation loss: 0.5732
2024-05-23 19:09:05 [INFO]: Epoch 060 - training loss: 22763.5525, validation loss: 0.5720
2024-05-23 19:09:06 [INFO]: Epoch 061 - training loss: 22762.8241, validation loss: 0.5690
2024-05-23 19:09:06 [INFO]: Epoch 062 - training loss: 22762.6841, validation loss: 0.5678
2024-05-23 19:09:07 [INFO]: Epoch 063 - training loss: 22761.9963, validation loss: 0.5668
2024-05-23 19:09:07 [INFO]: Epoch 064 - training loss: 22761.6161, validation loss: 0.5657
2024-05-23 19:09:08 [INFO]: Epoch 065 - training loss: 22761.1110, validation loss: 0.5653
2024-05-23 19:09:09 [INFO]: Epoch 066 - training loss: 22760.9067, validation loss: 0.5630
2024-05-23 19:09:09 [INFO]: Epoch 067 - training loss: 22760.5589, validation loss: 0.5587
2024-05-23 19:09:10 [INFO]: Epoch 068 - training loss: 22760.4132, validation loss: 0.5773
2024-05-23 19:09:10 [INFO]: Epoch 069 - training loss: 22765.7864, validation loss: 0.5543
2024-05-23 19:09:11 [INFO]: Epoch 070 - training loss: 22761.0919, validation loss: 0.5519
2024-05-23 19:09:12 [INFO]: Epoch 071 - training loss: 22758.5561, validation loss: 0.5513
2024-05-23 19:09:12 [INFO]: Epoch 072 - training loss: 22758.0210, validation loss: 0.5485
2024-05-23 19:09:13 [INFO]: Epoch 073 - training loss: 22757.5686, validation loss: 0.5505
2024-05-23 19:09:13 [INFO]: Epoch 074 - training loss: 22757.2466, validation loss: 0.5523
2024-05-23 19:09:14 [INFO]: Epoch 075 - training loss: 22757.1028, validation loss: 0.5431
2024-05-23 19:09:14 [INFO]: Epoch 076 - training loss: 22756.6317, validation loss: 0.5422
2024-05-23 19:09:15 [INFO]: Epoch 077 - training loss: 22756.5667, validation loss: 0.5421
2024-05-23 19:09:16 [INFO]: Epoch 078 - training loss: 22756.5251, validation loss: 0.5419
2024-05-23 19:09:16 [INFO]: Epoch 079 - training loss: 22756.4347, validation loss: 0.5404
2024-05-23 19:09:17 [INFO]: Epoch 080 - training loss: 22755.6556, validation loss: 0.5371
2024-05-23 19:09:17 [INFO]: Epoch 081 - training loss: 22755.3589, validation loss: 0.5414
2024-05-23 19:09:18 [INFO]: Epoch 082 - training loss: 22754.8280, validation loss: 0.5378
2024-05-23 19:09:19 [INFO]: Epoch 083 - training loss: 22755.1386, validation loss: 0.5353
2024-05-23 19:09:19 [INFO]: Epoch 084 - training loss: 22754.9104, validation loss: 0.5337
2024-05-23 19:09:20 [INFO]: Epoch 085 - training loss: 22755.6551, validation loss: 0.5300
2024-05-23 19:09:21 [INFO]: Epoch 086 - training loss: 22753.8551, validation loss: 0.5321
2024-05-23 19:09:21 [INFO]: Epoch 087 - training loss: 22753.7037, validation loss: 0.5289
2024-05-23 19:09:22 [INFO]: Epoch 088 - training loss: 22753.1184, validation loss: 0.5284
2024-05-23 19:09:22 [INFO]: Epoch 089 - training loss: 22753.9945, validation loss: 0.5263
2024-05-23 19:09:23 [INFO]: Epoch 090 - training loss: 22752.9743, validation loss: 0.5529
2024-05-23 19:09:24 [INFO]: Epoch 091 - training loss: 22756.7182, validation loss: 0.5278
2024-05-23 19:09:24 [INFO]: Epoch 092 - training loss: 22753.8054, validation loss: 0.5344
2024-05-23 19:09:25 [INFO]: Epoch 093 - training loss: 22753.0789, validation loss: 0.5267
2024-05-23 19:09:25 [INFO]: Epoch 094 - training loss: 22752.3783, validation loss: 0.5282
2024-05-23 19:09:26 [INFO]: Epoch 095 - training loss: 22751.6904, validation loss: 0.5206
2024-05-23 19:09:26 [INFO]: Epoch 096 - training loss: 22751.5019, validation loss: 0.5270
2024-05-23 19:09:27 [INFO]: Epoch 097 - training loss: 22751.3012, validation loss: 0.5235
2024-05-23 19:09:28 [INFO]: Epoch 098 - training loss: 22751.1222, validation loss: 0.5180
2024-05-23 19:09:28 [INFO]: Epoch 099 - training loss: 22750.7916, validation loss: 0.5212
2024-05-23 19:09:29 [INFO]: Epoch 100 - training loss: 22750.5949, validation loss: 0.5203
2024-05-23 19:09:29 [INFO]: Epoch 101 - training loss: 22750.6915, validation loss: 0.5173
2024-05-23 19:09:30 [INFO]: Epoch 102 - training loss: 22750.4356, validation loss: 0.5220
2024-05-23 19:09:31 [INFO]: Epoch 103 - training loss: 22751.3635, validation loss: 0.5179
2024-05-23 19:09:31 [INFO]: Epoch 104 - training loss: 22750.8332, validation loss: 0.5178
2024-05-23 19:09:32 [INFO]: Epoch 105 - training loss: 22750.5333, validation loss: 0.5220
2024-05-23 19:09:32 [INFO]: Epoch 106 - training loss: 22750.6239, validation loss: 0.5171
2024-05-23 19:09:33 [INFO]: Epoch 107 - training loss: 22749.9634, validation loss: 0.5141
2024-05-23 19:09:33 [INFO]: Epoch 108 - training loss: 22749.5984, validation loss: 0.5139
2024-05-23 19:09:34 [INFO]: Epoch 109 - training loss: 22749.2953, validation loss: 0.5143
2024-05-23 19:09:35 [INFO]: Epoch 110 - training loss: 22749.7417, validation loss: 0.5113
2024-05-23 19:09:35 [INFO]: Epoch 111 - training loss: 22749.7021, validation loss: 0.5153
2024-05-23 19:09:36 [INFO]: Epoch 112 - training loss: 22749.7678, validation loss: 0.5119
2024-05-23 19:09:37 [INFO]: Epoch 113 - training loss: 22749.7770, validation loss: 0.5117
2024-05-23 19:09:37 [INFO]: Epoch 114 - training loss: 22749.3885, validation loss: 0.5086
2024-05-23 19:09:38 [INFO]: Epoch 115 - training loss: 22748.7801, validation loss: 0.5223
2024-05-23 19:09:38 [INFO]: Epoch 116 - training loss: 22749.1319, validation loss: 0.5150
2024-05-23 19:09:39 [INFO]: Epoch 117 - training loss: 22751.1807, validation loss: 0.5104
2024-05-23 19:09:39 [INFO]: Epoch 118 - training loss: 22751.2019, validation loss: 0.5075
2024-05-23 19:09:40 [INFO]: Epoch 119 - training loss: 22749.0842, validation loss: 0.5111
2024-05-23 19:09:41 [INFO]: Epoch 120 - training loss: 22748.3651, validation loss: 0.5078
2024-05-23 19:09:41 [INFO]: Epoch 121 - training loss: 22748.3523, validation loss: 0.5053
2024-05-23 19:09:42 [INFO]: Epoch 122 - training loss: 22748.2021, validation loss: 0.5083
2024-05-23 19:09:42 [INFO]: Epoch 123 - training loss: 22747.9817, validation loss: 0.5032
2024-05-23 19:09:43 [INFO]: Epoch 124 - training loss: 22747.8230, validation loss: 0.5040
2024-05-23 19:09:44 [INFO]: Epoch 125 - training loss: 22747.6778, validation loss: 0.5035
2024-05-23 19:09:44 [INFO]: Epoch 126 - training loss: 22747.3178, validation loss: 0.5033
2024-05-23 19:09:45 [INFO]: Epoch 127 - training loss: 22747.1654, validation loss: 0.5008
2024-05-23 19:09:45 [INFO]: Epoch 128 - training loss: 22747.3247, validation loss: 0.5011
2024-05-23 19:09:46 [INFO]: Epoch 129 - training loss: 22747.1098, validation loss: 0.5057
2024-05-23 19:09:46 [INFO]: Epoch 130 - training loss: 22747.4735, validation loss: 0.5006
2024-05-23 19:09:47 [INFO]: Epoch 131 - training loss: 22749.6357, validation loss: 0.4968
2024-05-23 19:09:48 [INFO]: Epoch 132 - training loss: 22747.4074, validation loss: 0.5016
2024-05-23 19:09:48 [INFO]: Epoch 133 - training loss: 22748.2327, validation loss: 0.4978
2024-05-23 19:09:49 [INFO]: Epoch 134 - training loss: 22746.5312, validation loss: 0.5014
2024-05-23 19:09:49 [INFO]: Epoch 135 - training loss: 22746.3706, validation loss: 0.5085
2024-05-23 19:09:50 [INFO]: Epoch 136 - training loss: 22746.2988, validation loss: 0.4956
2024-05-23 19:09:50 [INFO]: Epoch 137 - training loss: 22748.5208, validation loss: 0.4972
2024-05-23 19:09:51 [INFO]: Epoch 138 - training loss: 22746.8822, validation loss: 0.5090
2024-05-23 19:09:52 [INFO]: Epoch 139 - training loss: 22751.6987, validation loss: 0.4998
2024-05-23 19:09:52 [INFO]: Epoch 140 - training loss: 22748.1627, validation loss: 0.4991
2024-05-23 19:09:53 [INFO]: Epoch 141 - training loss: 22745.9083, validation loss: 0.4921
2024-05-23 19:09:53 [INFO]: Epoch 142 - training loss: 22745.9957, validation loss: 0.4906
2024-05-23 19:09:54 [INFO]: Epoch 143 - training loss: 22745.7145, validation loss: 0.4916
2024-05-23 19:09:54 [INFO]: Epoch 144 - training loss: 22745.3836, validation loss: 0.4976
2024-05-23 19:09:55 [INFO]: Epoch 145 - training loss: 22745.9418, validation loss: 0.4900
2024-05-23 19:09:56 [INFO]: Epoch 146 - training loss: 22745.9171, validation loss: 0.4910
2024-05-23 19:09:56 [INFO]: Epoch 147 - training loss: 22745.4116, validation loss: 0.4888
2024-05-23 19:09:57 [INFO]: Epoch 148 - training loss: 22745.3038, validation loss: 0.4886
2024-05-23 19:09:57 [INFO]: Epoch 149 - training loss: 22744.7340, validation loss: 0.4888
2024-05-23 19:09:58 [INFO]: Epoch 150 - training loss: 22744.6002, validation loss: 0.4866
2024-05-23 19:09:59 [INFO]: Epoch 151 - training loss: 22744.3413, validation loss: 0.4859
2024-05-23 19:09:59 [INFO]: Epoch 152 - training loss: 22744.2390, validation loss: 0.4860
2024-05-23 19:10:00 [INFO]: Epoch 153 - training loss: 22744.1906, validation loss: 0.4840
2024-05-23 19:10:00 [INFO]: Epoch 154 - training loss: 22743.9973, validation loss: 0.4842
2024-05-23 19:10:01 [INFO]: Epoch 155 - training loss: 22743.9491, validation loss: 0.4843
2024-05-23 19:10:01 [INFO]: Epoch 156 - training loss: 22743.9860, validation loss: 0.4834
2024-05-23 19:10:02 [INFO]: Epoch 157 - training loss: 22744.1544, validation loss: 0.4826
2024-05-23 19:10:03 [INFO]: Epoch 158 - training loss: 22744.8765, validation loss: 0.4861
2024-05-23 19:10:03 [INFO]: Epoch 159 - training loss: 22746.2273, validation loss: 0.4830
2024-05-23 19:10:04 [INFO]: Epoch 160 - training loss: 22744.7645, validation loss: 0.4833
2024-05-23 19:10:04 [INFO]: Epoch 161 - training loss: 22743.7408, validation loss: 0.4818
2024-05-23 19:10:05 [INFO]: Epoch 162 - training loss: 22743.9016, validation loss: 0.4806
2024-05-23 19:10:05 [INFO]: Epoch 163 - training loss: 22743.6288, validation loss: 0.4783
2024-05-23 19:10:06 [INFO]: Epoch 164 - training loss: 22743.5500, validation loss: 0.4770
2024-05-23 19:10:07 [INFO]: Epoch 165 - training loss: 22743.5866, validation loss: 0.4818
2024-05-23 19:10:07 [INFO]: Epoch 166 - training loss: 22743.5965, validation loss: 0.4751
2024-05-23 19:10:08 [INFO]: Epoch 167 - training loss: 22743.1885, validation loss: 0.4763
2024-05-23 19:10:08 [INFO]: Epoch 168 - training loss: 22743.1044, validation loss: 0.4768
2024-05-23 19:10:09 [INFO]: Epoch 169 - training loss: 22743.3021, validation loss: 0.4781
2024-05-23 19:10:09 [INFO]: Epoch 170 - training loss: 22743.0633, validation loss: 0.4743
2024-05-23 19:10:10 [INFO]: Epoch 171 - training loss: 22743.0007, validation loss: 0.4743
2024-05-23 19:10:11 [INFO]: Epoch 172 - training loss: 22743.0562, validation loss: 0.4731
2024-05-23 19:10:12 [INFO]: Epoch 173 - training loss: 22743.5931, validation loss: 0.4736
2024-05-23 19:10:12 [INFO]: Epoch 174 - training loss: 22743.4274, validation loss: 0.4744
2024-05-23 19:10:13 [INFO]: Epoch 175 - training loss: 22742.7812, validation loss: 0.4713
2024-05-23 19:10:13 [INFO]: Epoch 176 - training loss: 22742.3581, validation loss: 0.4752
2024-05-23 19:10:14 [INFO]: Epoch 177 - training loss: 22742.3035, validation loss: 0.4681
2024-05-23 19:10:15 [INFO]: Epoch 178 - training loss: 22742.3237, validation loss: 0.4752
2024-05-23 19:10:15 [INFO]: Epoch 179 - training loss: 22742.6687, validation loss: 0.4692
2024-05-23 19:10:16 [INFO]: Epoch 180 - training loss: 22742.1897, validation loss: 0.4755
2024-05-23 19:10:16 [INFO]: Epoch 181 - training loss: 22742.5062, validation loss: 0.4707
2024-05-23 19:10:17 [INFO]: Epoch 182 - training loss: 22742.2701, validation loss: 0.4687
2024-05-23 19:10:18 [INFO]: Epoch 183 - training loss: 22742.0385, validation loss: 0.4687
2024-05-23 19:10:18 [INFO]: Epoch 184 - training loss: 22742.6353, validation loss: 0.4677
2024-05-23 19:10:19 [INFO]: Epoch 185 - training loss: 22741.7817, validation loss: 0.4706
2024-05-23 19:10:19 [INFO]: Epoch 186 - training loss: 22741.9206, validation loss: 0.4676
2024-05-23 19:10:20 [INFO]: Epoch 187 - training loss: 22742.3991, validation loss: 0.4743
2024-05-23 19:10:21 [INFO]: Epoch 188 - training loss: 22741.7475, validation loss: 0.4649
2024-05-23 19:10:21 [INFO]: Epoch 189 - training loss: 22741.1522, validation loss: 0.4705
2024-05-23 19:10:22 [INFO]: Epoch 190 - training loss: 22740.9946, validation loss: 0.4685
2024-05-23 19:10:22 [INFO]: Epoch 191 - training loss: 22740.8820, validation loss: 0.4699
2024-05-23 19:10:23 [INFO]: Epoch 192 - training loss: 22740.2358, validation loss: 0.4678
2024-05-23 19:10:23 [INFO]: Epoch 193 - training loss: 22740.5957, validation loss: 0.4693
2024-05-23 19:10:24 [INFO]: Epoch 194 - training loss: 22741.5444, validation loss: 0.4614
2024-05-23 19:10:25 [INFO]: Epoch 195 - training loss: 22740.6971, validation loss: 0.4678
2024-05-23 19:10:25 [INFO]: Epoch 196 - training loss: 22740.2792, validation loss: 0.4622
2024-05-23 19:10:26 [INFO]: Epoch 197 - training loss: 22739.8781, validation loss: 0.4665
2024-05-23 19:10:26 [INFO]: Epoch 198 - training loss: 22739.5136, validation loss: 0.4678
2024-05-23 19:10:27 [INFO]: Epoch 199 - training loss: 22739.2805, validation loss: 0.4728
2024-05-23 19:10:27 [INFO]: Epoch 200 - training loss: 22739.2410, validation loss: 0.4683
2024-05-23 19:10:28 [INFO]: Epoch 201 - training loss: 22741.0745, validation loss: 0.4734
2024-05-23 19:10:29 [INFO]: Epoch 202 - training loss: 22740.5604, validation loss: 0.4668
2024-05-23 19:10:29 [INFO]: Epoch 203 - training loss: 22739.9889, validation loss: 0.4657
2024-05-23 19:10:30 [INFO]: Epoch 204 - training loss: 22739.5435, validation loss: 0.4696
2024-05-23 19:10:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:10:30 [INFO]: Finished training. The best model is from epoch#194.
2024-05-23 19:10:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T190828/GPVAE.pypots
2024-05-23 19:10:30 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.3995, MSE=0.4035
2024-05-23 19:10:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 19:10:30 [INFO]: Using the given device: cuda:0
2024-05-23 19:10:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T191030
2024-05-23 19:10:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T191030/tensorboard
2024-05-23 19:10:31 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 19:10:52 [INFO]: Epoch 001 - generator training loss: 0.6044, discriminator training loss: 0.3833, validation loss: 0.6424
2024-05-23 19:11:11 [INFO]: Epoch 002 - generator training loss: 0.4852, discriminator training loss: 0.2734, validation loss: 0.5582
2024-05-23 19:11:29 [INFO]: Epoch 003 - generator training loss: 0.4349, discriminator training loss: 0.2358, validation loss: 0.5411
2024-05-23 19:11:48 [INFO]: Epoch 004 - generator training loss: 0.4463, discriminator training loss: 0.1879, validation loss: 0.5311
2024-05-23 19:12:06 [INFO]: Epoch 005 - generator training loss: 0.4477, discriminator training loss: 0.1582, validation loss: 0.5123
2024-05-23 19:12:25 [INFO]: Epoch 006 - generator training loss: 0.4391, discriminator training loss: 0.1395, validation loss: 0.4944
2024-05-23 19:12:43 [INFO]: Epoch 007 - generator training loss: 0.4264, discriminator training loss: 0.1254, validation loss: 0.4903
2024-05-23 19:13:02 [INFO]: Epoch 008 - generator training loss: 0.4208, discriminator training loss: 0.1147, validation loss: 0.4790
2024-05-23 19:13:20 [INFO]: Epoch 009 - generator training loss: 0.4107, discriminator training loss: 0.1065, validation loss: 0.4709
2024-05-23 19:13:39 [INFO]: Epoch 010 - generator training loss: 0.3995, discriminator training loss: 0.1000, validation loss: 0.4636
2024-05-23 19:13:57 [INFO]: Epoch 011 - generator training loss: 0.3924, discriminator training loss: 0.0941, validation loss: 0.4583
2024-05-23 19:14:16 [INFO]: Epoch 012 - generator training loss: 0.3842, discriminator training loss: 0.0890, validation loss: 0.4479
2024-05-23 19:14:34 [INFO]: Epoch 013 - generator training loss: 0.3798, discriminator training loss: 0.0847, validation loss: 0.4420
2024-05-23 19:14:53 [INFO]: Epoch 014 - generator training loss: 0.3730, discriminator training loss: 0.0808, validation loss: 0.4390
2024-05-23 19:15:11 [INFO]: Epoch 015 - generator training loss: 0.3681, discriminator training loss: 0.0774, validation loss: 0.4316
2024-05-23 19:15:30 [INFO]: Epoch 016 - generator training loss: 0.3647, discriminator training loss: 0.0745, validation loss: 0.4282
2024-05-23 19:15:48 [INFO]: Epoch 017 - generator training loss: 0.3580, discriminator training loss: 0.0716, validation loss: 0.4231
2024-05-23 19:16:06 [INFO]: Epoch 018 - generator training loss: 0.3537, discriminator training loss: 0.0692, validation loss: 0.4200
2024-05-23 19:16:25 [INFO]: Epoch 019 - generator training loss: 0.3506, discriminator training loss: 0.0667, validation loss: 0.4162
2024-05-23 19:16:44 [INFO]: Epoch 020 - generator training loss: 0.3443, discriminator training loss: 0.0646, validation loss: 0.4106
2024-05-23 19:17:02 [INFO]: Epoch 021 - generator training loss: 0.3408, discriminator training loss: 0.0627, validation loss: 0.4074
2024-05-23 19:17:20 [INFO]: Epoch 022 - generator training loss: 0.3369, discriminator training loss: 0.0609, validation loss: 0.4056
2024-05-23 19:17:39 [INFO]: Epoch 023 - generator training loss: 0.3319, discriminator training loss: 0.0592, validation loss: 0.3991
2024-05-23 19:17:58 [INFO]: Epoch 024 - generator training loss: 0.3301, discriminator training loss: 0.0578, validation loss: 0.3991
2024-05-23 19:18:16 [INFO]: Epoch 025 - generator training loss: 0.3245, discriminator training loss: 0.0564, validation loss: 0.3959
2024-05-23 19:18:35 [INFO]: Epoch 026 - generator training loss: 0.3217, discriminator training loss: 0.0552, validation loss: 0.3931
2024-05-23 19:18:53 [INFO]: Epoch 027 - generator training loss: 0.3164, discriminator training loss: 0.0540, validation loss: 0.3883
2024-05-23 19:19:12 [INFO]: Epoch 028 - generator training loss: 0.3132, discriminator training loss: 0.0530, validation loss: 0.3879
2024-05-23 19:19:30 [INFO]: Epoch 029 - generator training loss: 0.3124, discriminator training loss: 0.0524, validation loss: 0.3857
2024-05-23 19:19:49 [INFO]: Epoch 030 - generator training loss: 0.3068, discriminator training loss: 0.0512, validation loss: 0.3811
2024-05-23 19:20:07 [INFO]: Epoch 031 - generator training loss: 0.3051, discriminator training loss: 0.0505, validation loss: 0.3856
2024-05-23 19:20:26 [INFO]: Epoch 032 - generator training loss: 0.3098, discriminator training loss: 0.0499, validation loss: 0.3831
2024-05-23 19:20:44 [INFO]: Epoch 033 - generator training loss: 0.3084, discriminator training loss: 0.0493, validation loss: 0.3803
2024-05-23 19:21:03 [INFO]: Epoch 034 - generator training loss: 0.2971, discriminator training loss: 0.0487, validation loss: 0.3739
2024-05-23 19:21:21 [INFO]: Epoch 035 - generator training loss: 0.2941, discriminator training loss: 0.0481, validation loss: 0.3761
2024-05-23 19:21:40 [INFO]: Epoch 036 - generator training loss: 0.2905, discriminator training loss: 0.0477, validation loss: 0.3696
2024-05-23 19:21:58 [INFO]: Epoch 037 - generator training loss: 0.2804, discriminator training loss: 0.0474, validation loss: 0.3638
2024-05-23 19:22:17 [INFO]: Epoch 038 - generator training loss: 0.2785, discriminator training loss: 0.0470, validation loss: 0.3669
2024-05-23 19:22:35 [INFO]: Epoch 039 - generator training loss: 0.2772, discriminator training loss: 0.0467, validation loss: 0.3634
2024-05-23 19:22:54 [INFO]: Epoch 040 - generator training loss: 0.2871, discriminator training loss: 0.0464, validation loss: 0.3668
2024-05-23 19:23:12 [INFO]: Epoch 041 - generator training loss: 0.2779, discriminator training loss: 0.0461, validation loss: 0.3624
2024-05-23 19:23:31 [INFO]: Epoch 042 - generator training loss: 0.2738, discriminator training loss: 0.0458, validation loss: 0.3631
2024-05-23 19:23:49 [INFO]: Epoch 043 - generator training loss: 0.2647, discriminator training loss: 0.0454, validation loss: 0.3605
2024-05-23 19:24:07 [INFO]: Epoch 044 - generator training loss: 0.2643, discriminator training loss: 0.0451, validation loss: 0.3574
2024-05-23 19:24:26 [INFO]: Epoch 045 - generator training loss: 0.2608, discriminator training loss: 0.0450, validation loss: 0.3580
2024-05-23 19:24:44 [INFO]: Epoch 046 - generator training loss: 0.2601, discriminator training loss: 0.0448, validation loss: 0.3610
2024-05-23 19:25:03 [INFO]: Epoch 047 - generator training loss: 0.2559, discriminator training loss: 0.0446, validation loss: 0.3572
2024-05-23 19:25:21 [INFO]: Epoch 048 - generator training loss: 0.2530, discriminator training loss: 0.0444, validation loss: 0.3510
2024-05-23 19:25:40 [INFO]: Epoch 049 - generator training loss: 0.2487, discriminator training loss: 0.0443, validation loss: 0.3503
2024-05-23 19:25:58 [INFO]: Epoch 050 - generator training loss: 0.2488, discriminator training loss: 0.0441, validation loss: 0.3481
2024-05-23 19:26:17 [INFO]: Epoch 051 - generator training loss: 0.2433, discriminator training loss: 0.0439, validation loss: 0.3484
2024-05-23 19:26:35 [INFO]: Epoch 052 - generator training loss: 0.2440, discriminator training loss: 0.0438, validation loss: 0.3500
2024-05-23 19:26:54 [INFO]: Epoch 053 - generator training loss: 0.2451, discriminator training loss: 0.0439, validation loss: 0.3428
2024-05-23 19:27:12 [INFO]: Epoch 054 - generator training loss: 0.2395, discriminator training loss: 0.0435, validation loss: 0.3478
2024-05-23 19:27:31 [INFO]: Epoch 055 - generator training loss: 0.2539, discriminator training loss: 0.0436, validation loss: 0.3443
2024-05-23 19:27:49 [INFO]: Epoch 056 - generator training loss: 0.2382, discriminator training loss: 0.0431, validation loss: 0.3507
2024-05-23 19:28:08 [INFO]: Epoch 057 - generator training loss: 0.2419, discriminator training loss: 0.0429, validation loss: 0.3458
2024-05-23 19:28:26 [INFO]: Epoch 058 - generator training loss: 0.2338, discriminator training loss: 0.0430, validation loss: 0.3438
2024-05-23 19:28:44 [INFO]: Epoch 059 - generator training loss: 0.2358, discriminator training loss: 0.0429, validation loss: 0.3421
2024-05-23 19:29:03 [INFO]: Epoch 060 - generator training loss: 0.2311, discriminator training loss: 0.0425, validation loss: 0.3408
2024-05-23 19:29:21 [INFO]: Epoch 061 - generator training loss: 0.2277, discriminator training loss: 0.0427, validation loss: 0.3414
2024-05-23 19:29:40 [INFO]: Epoch 062 - generator training loss: 0.2226, discriminator training loss: 0.0424, validation loss: 0.3410
2024-05-23 19:29:58 [INFO]: Epoch 063 - generator training loss: 0.2227, discriminator training loss: 0.0422, validation loss: 0.3440
2024-05-23 19:30:16 [INFO]: Epoch 064 - generator training loss: 0.2231, discriminator training loss: 0.0424, validation loss: 0.3435
2024-05-23 19:30:35 [INFO]: Epoch 065 - generator training loss: 0.2167, discriminator training loss: 0.0420, validation loss: 0.3410
2024-05-23 19:30:54 [INFO]: Epoch 066 - generator training loss: 0.2152, discriminator training loss: 0.0419, validation loss: 0.3398
2024-05-23 19:31:12 [INFO]: Epoch 067 - generator training loss: 0.2161, discriminator training loss: 0.0418, validation loss: 0.3408
2024-05-23 19:31:30 [INFO]: Epoch 068 - generator training loss: 0.2098, discriminator training loss: 0.0417, validation loss: 0.3369
2024-05-23 19:31:48 [INFO]: Epoch 069 - generator training loss: 0.2077, discriminator training loss: 0.0416, validation loss: 0.3381
2024-05-23 19:32:06 [INFO]: Epoch 070 - generator training loss: 0.2102, discriminator training loss: 0.0416, validation loss: 0.3364
2024-05-23 19:32:25 [INFO]: Epoch 071 - generator training loss: 0.2107, discriminator training loss: 0.0415, validation loss: 0.3399
2024-05-23 19:32:43 [INFO]: Epoch 072 - generator training loss: 0.2087, discriminator training loss: 0.0415, validation loss: 0.3414
2024-05-23 19:33:01 [INFO]: Epoch 073 - generator training loss: 0.2081, discriminator training loss: 0.0414, validation loss: 0.3360
2024-05-23 19:33:19 [INFO]: Epoch 074 - generator training loss: 0.2014, discriminator training loss: 0.0414, validation loss: 0.3403
2024-05-23 19:33:38 [INFO]: Epoch 075 - generator training loss: 0.2021, discriminator training loss: 0.0413, validation loss: 0.3413
2024-05-23 19:33:56 [INFO]: Epoch 076 - generator training loss: 0.2001, discriminator training loss: 0.0411, validation loss: 0.3355
2024-05-23 19:34:14 [INFO]: Epoch 077 - generator training loss: 0.1983, discriminator training loss: 0.0409, validation loss: 0.3420
2024-05-23 19:34:32 [INFO]: Epoch 078 - generator training loss: 0.1977, discriminator training loss: 0.0409, validation loss: 0.3403
2024-05-23 19:34:50 [INFO]: Epoch 079 - generator training loss: 0.1942, discriminator training loss: 0.0407, validation loss: 0.3409
2024-05-23 19:35:09 [INFO]: Epoch 080 - generator training loss: 0.1924, discriminator training loss: 0.0407, validation loss: 0.3429
2024-05-23 19:35:27 [INFO]: Epoch 081 - generator training loss: 0.1915, discriminator training loss: 0.0409, validation loss: 0.3426
2024-05-23 19:35:45 [INFO]: Epoch 082 - generator training loss: 0.1909, discriminator training loss: 0.0405, validation loss: 0.3430
2024-05-23 19:36:03 [INFO]: Epoch 083 - generator training loss: 0.1940, discriminator training loss: 0.0406, validation loss: 0.3483
2024-05-23 19:36:22 [INFO]: Epoch 084 - generator training loss: 0.1978, discriminator training loss: 0.0406, validation loss: 0.3433
2024-05-23 19:36:40 [INFO]: Epoch 085 - generator training loss: 0.1957, discriminator training loss: 0.0404, validation loss: 0.3369
2024-05-23 19:36:58 [INFO]: Epoch 086 - generator training loss: 0.1909, discriminator training loss: 0.0405, validation loss: 0.3426
2024-05-23 19:36:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:36:58 [INFO]: Finished training. The best model is from epoch#76.
2024-05-23 19:36:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T191030/USGAN.pypots
2024-05-23 19:37:00 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2965, MSE=0.2668
2024-05-23 19:37:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 19:37:10 [INFO]: Using the given device: cuda:0
2024-05-23 19:37:10 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T193710
2024-05-23 19:37:10 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T193710/tensorboard
2024-05-23 19:37:10 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 19:37:25 [INFO]: Epoch 001 - training loss: 1.1355, validation loss: 0.5516
2024-05-23 19:37:37 [INFO]: Epoch 002 - training loss: 0.9213, validation loss: 0.4922
2024-05-23 19:37:49 [INFO]: Epoch 003 - training loss: 0.8601, validation loss: 0.4665
2024-05-23 19:38:01 [INFO]: Epoch 004 - training loss: 0.8235, validation loss: 0.4459
2024-05-23 19:38:13 [INFO]: Epoch 005 - training loss: 0.7959, validation loss: 0.4277
2024-05-23 19:38:24 [INFO]: Epoch 006 - training loss: 0.7730, validation loss: 0.4187
2024-05-23 19:38:36 [INFO]: Epoch 007 - training loss: 0.7546, validation loss: 0.4082
2024-05-23 19:38:48 [INFO]: Epoch 008 - training loss: 0.7389, validation loss: 0.4023
2024-05-23 19:39:00 [INFO]: Epoch 009 - training loss: 0.7258, validation loss: 0.3973
2024-05-23 19:39:13 [INFO]: Epoch 010 - training loss: 0.7146, validation loss: 0.3917
2024-05-23 19:39:25 [INFO]: Epoch 011 - training loss: 0.7053, validation loss: 0.3880
2024-05-23 19:39:37 [INFO]: Epoch 012 - training loss: 0.6974, validation loss: 0.3872
2024-05-23 19:39:49 [INFO]: Epoch 013 - training loss: 0.6902, validation loss: 0.3840
2024-05-23 19:40:00 [INFO]: Epoch 014 - training loss: 0.6834, validation loss: 0.3820
2024-05-23 19:40:12 [INFO]: Epoch 015 - training loss: 0.6781, validation loss: 0.3826
2024-05-23 19:40:24 [INFO]: Epoch 016 - training loss: 0.6731, validation loss: 0.3797
2024-05-23 19:40:36 [INFO]: Epoch 017 - training loss: 0.6692, validation loss: 0.3791
2024-05-23 19:40:48 [INFO]: Epoch 018 - training loss: 0.6648, validation loss: 0.3797
2024-05-23 19:41:01 [INFO]: Epoch 019 - training loss: 0.6612, validation loss: 0.3778
2024-05-23 19:41:13 [INFO]: Epoch 020 - training loss: 0.6573, validation loss: 0.3766
2024-05-23 19:41:25 [INFO]: Epoch 021 - training loss: 0.6540, validation loss: 0.3754
2024-05-23 19:41:37 [INFO]: Epoch 022 - training loss: 0.6501, validation loss: 0.3766
2024-05-23 19:41:49 [INFO]: Epoch 023 - training loss: 0.6474, validation loss: 0.3759
2024-05-23 19:42:01 [INFO]: Epoch 024 - training loss: 0.6450, validation loss: 0.3750
2024-05-23 19:42:13 [INFO]: Epoch 025 - training loss: 0.6414, validation loss: 0.3751
2024-05-23 19:42:26 [INFO]: Epoch 026 - training loss: 0.6386, validation loss: 0.3741
2024-05-23 19:42:38 [INFO]: Epoch 027 - training loss: 0.6367, validation loss: 0.3763
2024-05-23 19:42:50 [INFO]: Epoch 028 - training loss: 0.6353, validation loss: 0.3741
2024-05-23 19:43:02 [INFO]: Epoch 029 - training loss: 0.6303, validation loss: 0.3730
2024-05-23 19:43:14 [INFO]: Epoch 030 - training loss: 0.6285, validation loss: 0.3733
2024-05-23 19:43:26 [INFO]: Epoch 031 - training loss: 0.6249, validation loss: 0.3708
2024-05-23 19:43:38 [INFO]: Epoch 032 - training loss: 0.6224, validation loss: 0.3742
2024-05-23 19:43:51 [INFO]: Epoch 033 - training loss: 0.6214, validation loss: 0.3723
2024-05-23 19:44:03 [INFO]: Epoch 034 - training loss: 0.6168, validation loss: 0.3722
2024-05-23 19:44:15 [INFO]: Epoch 035 - training loss: 0.6141, validation loss: 0.3720
2024-05-23 19:44:27 [INFO]: Epoch 036 - training loss: 0.6120, validation loss: 0.3725
2024-05-23 19:44:39 [INFO]: Epoch 037 - training loss: 0.6094, validation loss: 0.3723
2024-05-23 19:44:51 [INFO]: Epoch 038 - training loss: 0.6073, validation loss: 0.3737
2024-05-23 19:45:03 [INFO]: Epoch 039 - training loss: 0.6046, validation loss: 0.3722
2024-05-23 19:45:16 [INFO]: Epoch 040 - training loss: 0.6013, validation loss: 0.3720
2024-05-23 19:45:28 [INFO]: Epoch 041 - training loss: 0.5985, validation loss: 0.3739
2024-05-23 19:45:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:45:28 [INFO]: Finished training. The best model is from epoch#31.
2024-05-23 19:45:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T193710/BRITS.pypots
2024-05-23 19:45:30 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2570, MSE=0.2558
2024-05-23 19:45:40 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:45:40 [INFO]: Using the given device: cuda:0
2024-05-23 19:45:40 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540
2024-05-23 19:45:40 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/tensorboard
2024-05-23 19:45:40 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 19:45:46 [INFO]: Epoch 001 - training loss: 1.1614, validation loss: 0.9963
2024-05-23 19:45:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch1_loss0.9963474929332733.pypots
2024-05-23 19:45:49 [INFO]: Epoch 002 - training loss: 0.7087, validation loss: 0.9712
2024-05-23 19:45:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch2_loss0.9711982578039169.pypots
2024-05-23 19:45:52 [INFO]: Epoch 003 - training loss: 0.5973, validation loss: 0.9456
2024-05-23 19:45:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch3_loss0.9455702543258667.pypots
2024-05-23 19:45:54 [INFO]: Epoch 004 - training loss: 0.5511, validation loss: 0.9339
2024-05-23 19:45:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch4_loss0.9339490562677384.pypots
2024-05-23 19:45:57 [INFO]: Epoch 005 - training loss: 0.5304, validation loss: 0.9277
2024-05-23 19:45:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch5_loss0.9276632606983185.pypots
2024-05-23 19:46:00 [INFO]: Epoch 006 - training loss: 0.5034, validation loss: 0.9239
2024-05-23 19:46:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch6_loss0.923872098326683.pypots
2024-05-23 19:46:03 [INFO]: Epoch 007 - training loss: 0.4964, validation loss: 0.9214
2024-05-23 19:46:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch7_loss0.9214174956083298.pypots
2024-05-23 19:46:06 [INFO]: Epoch 008 - training loss: 0.4842, validation loss: 0.9201
2024-05-23 19:46:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch8_loss0.9200607806444168.pypots
2024-05-23 19:46:09 [INFO]: Epoch 009 - training loss: 0.4790, validation loss: 0.9194
2024-05-23 19:46:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch9_loss0.9193722516298294.pypots
2024-05-23 19:46:12 [INFO]: Epoch 010 - training loss: 0.4698, validation loss: 0.9197
2024-05-23 19:46:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch10_loss0.9197041541337967.pypots
2024-05-23 19:46:14 [INFO]: Epoch 011 - training loss: 0.4585, validation loss: 0.9207
2024-05-23 19:46:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch11_loss0.920726090669632.pypots
2024-05-23 19:46:17 [INFO]: Epoch 012 - training loss: 0.4587, validation loss: 0.9228
2024-05-23 19:46:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch12_loss0.9227751791477203.pypots
2024-05-23 19:46:20 [INFO]: Epoch 013 - training loss: 0.4537, validation loss: 0.9244
2024-05-23 19:46:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch13_loss0.9243767708539963.pypots
2024-05-23 19:46:23 [INFO]: Epoch 014 - training loss: 0.4500, validation loss: 0.9262
2024-05-23 19:46:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch14_loss0.92615547478199.pypots
2024-05-23 19:46:25 [INFO]: Epoch 015 - training loss: 0.4496, validation loss: 0.9280
2024-05-23 19:46:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch15_loss0.9279611229896545.pypots
2024-05-23 19:46:28 [INFO]: Epoch 016 - training loss: 0.4435, validation loss: 0.9291
2024-05-23 19:46:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch16_loss0.9291376858949661.pypots
2024-05-23 19:46:31 [INFO]: Epoch 017 - training loss: 0.4349, validation loss: 0.9307
2024-05-23 19:46:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch17_loss0.9306845873594284.pypots
2024-05-23 19:46:34 [INFO]: Epoch 018 - training loss: 0.4336, validation loss: 0.9317
2024-05-23 19:46:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch18_loss0.9317100346088409.pypots
2024-05-23 19:46:36 [INFO]: Epoch 019 - training loss: 0.4408, validation loss: 0.9338
2024-05-23 19:46:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN_epoch19_loss0.9338180303573609.pypots
2024-05-23 19:46:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:46:36 [INFO]: Finished training. The best model is from epoch#9.
2024-05-23 19:46:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T194540/MRNN.pypots
2024-05-23 19:46:37 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6886, MSE=0.8984
2024-05-23 19:46:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 19:46:42 [INFO]: Using the given device: cpu
2024-05-23 19:46:42 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4036, MSE=0.5059
2024-05-23 19:46:42 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_physionet_2012_seta".
2024-05-23 19:46:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 19:46:42 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6901, MSE=1.0191
2024-05-23 19:46:42 [INFO]: Successfully created the given path "saved_results/round_0/Median_physionet_2012_seta".
2024-05-23 19:46:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_physionet_2012_seta/imputation.pkl
2024-05-23 19:46:42 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7055, MSE=0.9762
2024-05-23 19:46:42 [INFO]: Successfully created the given path "saved_results/round_0/Mean_physionet_2012_seta".
2024-05-23 19:46:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 19:46:42 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-23 19:46:42 [INFO]: Using the given device: cuda:0
2024-05-23 19:46:42 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T194642
2024-05-23 19:46:42 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T194642/tensorboard
2024-05-23 19:46:42 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 19:46:43 [INFO]: Epoch 001 - training loss: 1.0739, validation loss: 0.5180
2024-05-23 19:46:44 [INFO]: Epoch 002 - training loss: 0.6983, validation loss: 0.4545
2024-05-23 19:46:46 [INFO]: Epoch 003 - training loss: 0.5863, validation loss: 0.4261
2024-05-23 19:46:47 [INFO]: Epoch 004 - training loss: 0.5162, validation loss: 0.4009
2024-05-23 19:46:49 [INFO]: Epoch 005 - training loss: 0.4706, validation loss: 0.3917
2024-05-23 19:46:50 [INFO]: Epoch 006 - training loss: 0.4460, validation loss: 0.3880
2024-05-23 19:46:51 [INFO]: Epoch 007 - training loss: 0.4214, validation loss: 0.3903
2024-05-23 19:46:52 [INFO]: Epoch 008 - training loss: 0.3946, validation loss: 0.3731
2024-05-23 19:46:53 [INFO]: Epoch 009 - training loss: 0.3776, validation loss: 0.3637
2024-05-23 19:46:54 [INFO]: Epoch 010 - training loss: 0.3557, validation loss: 0.3647
2024-05-23 19:46:56 [INFO]: Epoch 011 - training loss: 0.3369, validation loss: 0.3481
2024-05-23 19:46:57 [INFO]: Epoch 012 - training loss: 0.3207, validation loss: 0.3403
2024-05-23 19:46:58 [INFO]: Epoch 013 - training loss: 0.3075, validation loss: 0.3471
2024-05-23 19:46:59 [INFO]: Epoch 014 - training loss: 0.2974, validation loss: 0.3455
2024-05-23 19:47:00 [INFO]: Epoch 015 - training loss: 0.2891, validation loss: 0.3397
2024-05-23 19:47:01 [INFO]: Epoch 016 - training loss: 0.2766, validation loss: 0.3385
2024-05-23 19:47:02 [INFO]: Epoch 017 - training loss: 0.2651, validation loss: 0.3364
2024-05-23 19:47:04 [INFO]: Epoch 018 - training loss: 0.2575, validation loss: 0.3385
2024-05-23 19:47:05 [INFO]: Epoch 019 - training loss: 0.2482, validation loss: 0.3399
2024-05-23 19:47:06 [INFO]: Epoch 020 - training loss: 0.2432, validation loss: 0.3399
2024-05-23 19:47:07 [INFO]: Epoch 021 - training loss: 0.2350, validation loss: 0.3335
2024-05-23 19:47:08 [INFO]: Epoch 022 - training loss: 0.2299, validation loss: 0.3340
2024-05-23 19:47:09 [INFO]: Epoch 023 - training loss: 0.2254, validation loss: 0.3371
2024-05-23 19:47:11 [INFO]: Epoch 024 - training loss: 0.2175, validation loss: 0.3339
2024-05-23 19:47:12 [INFO]: Epoch 025 - training loss: 0.2109, validation loss: 0.3345
2024-05-23 19:47:13 [INFO]: Epoch 026 - training loss: 0.2083, validation loss: 0.3303
2024-05-23 19:47:14 [INFO]: Epoch 027 - training loss: 0.2046, validation loss: 0.3337
2024-05-23 19:47:15 [INFO]: Epoch 028 - training loss: 0.2046, validation loss: 0.3382
2024-05-23 19:47:16 [INFO]: Epoch 029 - training loss: 0.1948, validation loss: 0.3310
2024-05-23 19:47:18 [INFO]: Epoch 030 - training loss: 0.1902, validation loss: 0.3277
2024-05-23 19:47:19 [INFO]: Epoch 031 - training loss: 0.1843, validation loss: 0.3333
2024-05-23 19:47:20 [INFO]: Epoch 032 - training loss: 0.1828, validation loss: 0.3306
2024-05-23 19:47:21 [INFO]: Epoch 033 - training loss: 0.1802, validation loss: 0.3340
2024-05-23 19:47:22 [INFO]: Epoch 034 - training loss: 0.1787, validation loss: 0.3307
2024-05-23 19:47:23 [INFO]: Epoch 035 - training loss: 0.1737, validation loss: 0.3374
2024-05-23 19:47:25 [INFO]: Epoch 036 - training loss: 0.1718, validation loss: 0.3346
2024-05-23 19:47:26 [INFO]: Epoch 037 - training loss: 0.1706, validation loss: 0.3382
2024-05-23 19:47:27 [INFO]: Epoch 038 - training loss: 0.1670, validation loss: 0.3373
2024-05-23 19:47:28 [INFO]: Epoch 039 - training loss: 0.1663, validation loss: 0.3357
2024-05-23 19:47:30 [INFO]: Epoch 040 - training loss: 0.1648, validation loss: 0.3315
2024-05-23 19:47:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:47:30 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 19:47:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T194642/SAITS.pypots
2024-05-23 19:47:30 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2654, MSE=0.2873
2024-05-23 19:47:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:47:30 [INFO]: Using the given device: cuda:0
2024-05-23 19:47:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T194730
2024-05-23 19:47:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T194730/tensorboard
2024-05-23 19:47:30 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 19:47:31 [INFO]: Epoch 001 - training loss: 1.1892, validation loss: 0.6184
2024-05-23 19:47:31 [INFO]: Epoch 002 - training loss: 0.7623, validation loss: 0.5038
2024-05-23 19:47:32 [INFO]: Epoch 003 - training loss: 0.6409, validation loss: 0.4842
2024-05-23 19:47:33 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.4629
2024-05-23 19:47:33 [INFO]: Epoch 005 - training loss: 0.5460, validation loss: 0.4499
2024-05-23 19:47:34 [INFO]: Epoch 006 - training loss: 0.5118, validation loss: 0.4204
2024-05-23 19:47:34 [INFO]: Epoch 007 - training loss: 0.4830, validation loss: 0.4150
2024-05-23 19:47:35 [INFO]: Epoch 008 - training loss: 0.4629, validation loss: 0.4121
2024-05-23 19:47:36 [INFO]: Epoch 009 - training loss: 0.4397, validation loss: 0.3978
2024-05-23 19:47:36 [INFO]: Epoch 010 - training loss: 0.4229, validation loss: 0.3951
2024-05-23 19:47:37 [INFO]: Epoch 011 - training loss: 0.4048, validation loss: 0.3917
2024-05-23 19:47:37 [INFO]: Epoch 012 - training loss: 0.3980, validation loss: 0.3895
2024-05-23 19:47:38 [INFO]: Epoch 013 - training loss: 0.3864, validation loss: 0.3828
2024-05-23 19:47:39 [INFO]: Epoch 014 - training loss: 0.3678, validation loss: 0.3773
2024-05-23 19:47:39 [INFO]: Epoch 015 - training loss: 0.3568, validation loss: 0.3748
2024-05-23 19:47:40 [INFO]: Epoch 016 - training loss: 0.3485, validation loss: 0.3743
2024-05-23 19:47:40 [INFO]: Epoch 017 - training loss: 0.3435, validation loss: 0.3735
2024-05-23 19:47:41 [INFO]: Epoch 018 - training loss: 0.3388, validation loss: 0.3657
2024-05-23 19:47:41 [INFO]: Epoch 019 - training loss: 0.3258, validation loss: 0.3626
2024-05-23 19:47:42 [INFO]: Epoch 020 - training loss: 0.3227, validation loss: 0.3608
2024-05-23 19:47:43 [INFO]: Epoch 021 - training loss: 0.3130, validation loss: 0.3586
2024-05-23 19:47:43 [INFO]: Epoch 022 - training loss: 0.3078, validation loss: 0.3561
2024-05-23 19:47:44 [INFO]: Epoch 023 - training loss: 0.3081, validation loss: 0.3660
2024-05-23 19:47:44 [INFO]: Epoch 024 - training loss: 0.2970, validation loss: 0.3533
2024-05-23 19:47:45 [INFO]: Epoch 025 - training loss: 0.2899, validation loss: 0.3553
2024-05-23 19:47:46 [INFO]: Epoch 026 - training loss: 0.2826, validation loss: 0.3568
2024-05-23 19:47:46 [INFO]: Epoch 027 - training loss: 0.2799, validation loss: 0.3527
2024-05-23 19:47:47 [INFO]: Epoch 028 - training loss: 0.2767, validation loss: 0.3520
2024-05-23 19:47:47 [INFO]: Epoch 029 - training loss: 0.2726, validation loss: 0.3506
2024-05-23 19:47:48 [INFO]: Epoch 030 - training loss: 0.2682, validation loss: 0.3497
2024-05-23 19:47:49 [INFO]: Epoch 031 - training loss: 0.2647, validation loss: 0.3532
2024-05-23 19:47:49 [INFO]: Epoch 032 - training loss: 0.2643, validation loss: 0.3499
2024-05-23 19:47:50 [INFO]: Epoch 033 - training loss: 0.2506, validation loss: 0.3491
2024-05-23 19:47:50 [INFO]: Epoch 034 - training loss: 0.2509, validation loss: 0.3493
2024-05-23 19:47:51 [INFO]: Epoch 035 - training loss: 0.2490, validation loss: 0.3508
2024-05-23 19:47:52 [INFO]: Epoch 036 - training loss: 0.2426, validation loss: 0.3516
2024-05-23 19:47:52 [INFO]: Epoch 037 - training loss: 0.2394, validation loss: 0.3489
2024-05-23 19:47:53 [INFO]: Epoch 038 - training loss: 0.2365, validation loss: 0.3492
2024-05-23 19:47:53 [INFO]: Epoch 039 - training loss: 0.2370, validation loss: 0.3550
2024-05-23 19:47:54 [INFO]: Epoch 040 - training loss: 0.2319, validation loss: 0.3522
2024-05-23 19:47:55 [INFO]: Epoch 041 - training loss: 0.2289, validation loss: 0.3513
2024-05-23 19:47:55 [INFO]: Epoch 042 - training loss: 0.2275, validation loss: 0.3527
2024-05-23 19:47:56 [INFO]: Epoch 043 - training loss: 0.2221, validation loss: 0.3489
2024-05-23 19:47:56 [INFO]: Epoch 044 - training loss: 0.2200, validation loss: 0.3502
2024-05-23 19:47:57 [INFO]: Epoch 045 - training loss: 0.2171, validation loss: 0.3518
2024-05-23 19:47:58 [INFO]: Epoch 046 - training loss: 0.2144, validation loss: 0.3529
2024-05-23 19:47:58 [INFO]: Epoch 047 - training loss: 0.2110, validation loss: 0.3517
2024-05-23 19:47:59 [INFO]: Epoch 048 - training loss: 0.2053, validation loss: 0.3557
2024-05-23 19:48:00 [INFO]: Epoch 049 - training loss: 0.2066, validation loss: 0.3545
2024-05-23 19:48:00 [INFO]: Epoch 050 - training loss: 0.2061, validation loss: 0.3499
2024-05-23 19:48:01 [INFO]: Epoch 051 - training loss: 0.2013, validation loss: 0.3515
2024-05-23 19:48:01 [INFO]: Epoch 052 - training loss: 0.2051, validation loss: 0.3541
2024-05-23 19:48:02 [INFO]: Epoch 053 - training loss: 0.2012, validation loss: 0.3537
2024-05-23 19:48:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:48:02 [INFO]: Finished training. The best model is from epoch#43.
2024-05-23 19:48:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T194730/Transformer.pypots
2024-05-23 19:48:02 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2838, MSE=0.3060
2024-05-23 19:48:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 19:48:02 [INFO]: Using the given device: cuda:0
2024-05-23 19:48:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T194802
2024-05-23 19:48:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T194802/tensorboard
2024-05-23 19:48:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 19:48:03 [INFO]: Epoch 001 - training loss: 0.4377, validation loss: 0.7883
2024-05-23 19:48:04 [INFO]: Epoch 002 - training loss: 0.4444, validation loss: 1.8644
2024-05-23 19:48:05 [INFO]: Epoch 003 - training loss: 0.6867, validation loss: 0.5570
2024-05-23 19:48:05 [INFO]: Epoch 004 - training loss: 0.3924, validation loss: 0.4215
2024-05-23 19:48:06 [INFO]: Epoch 005 - training loss: 0.3560, validation loss: 0.3950
2024-05-23 19:48:07 [INFO]: Epoch 006 - training loss: 0.3335, validation loss: 0.3369
2024-05-23 19:48:07 [INFO]: Epoch 007 - training loss: 0.3182, validation loss: 0.3388
2024-05-23 19:48:08 [INFO]: Epoch 008 - training loss: 0.3121, validation loss: 0.3290
2024-05-23 19:48:09 [INFO]: Epoch 009 - training loss: 0.3092, validation loss: 0.3225
2024-05-23 19:48:10 [INFO]: Epoch 010 - training loss: 0.3012, validation loss: 0.3193
2024-05-23 19:48:10 [INFO]: Epoch 011 - training loss: 0.2917, validation loss: 0.3113
2024-05-23 19:48:11 [INFO]: Epoch 012 - training loss: 0.2863, validation loss: 0.3180
2024-05-23 19:48:12 [INFO]: Epoch 013 - training loss: 0.2782, validation loss: 0.3201
2024-05-23 19:48:12 [INFO]: Epoch 014 - training loss: 0.2862, validation loss: 0.3153
2024-05-23 19:48:13 [INFO]: Epoch 015 - training loss: 0.2748, validation loss: 0.3123
2024-05-23 19:48:14 [INFO]: Epoch 016 - training loss: 0.2651, validation loss: 0.3099
2024-05-23 19:48:14 [INFO]: Epoch 017 - training loss: 0.2625, validation loss: 0.3102
2024-05-23 19:48:15 [INFO]: Epoch 018 - training loss: 0.2615, validation loss: 0.3098
2024-05-23 19:48:16 [INFO]: Epoch 019 - training loss: 0.2549, validation loss: 0.3218
2024-05-23 19:48:17 [INFO]: Epoch 020 - training loss: 0.2577, validation loss: 0.3120
2024-05-23 19:48:17 [INFO]: Epoch 021 - training loss: 0.2448, validation loss: 0.3261
2024-05-23 19:48:18 [INFO]: Epoch 022 - training loss: 0.2436, validation loss: 0.3124
2024-05-23 19:48:19 [INFO]: Epoch 023 - training loss: 0.2381, validation loss: 0.3299
2024-05-23 19:48:19 [INFO]: Epoch 024 - training loss: 0.2414, validation loss: 0.3146
2024-05-23 19:48:20 [INFO]: Epoch 025 - training loss: 0.2416, validation loss: 0.3242
2024-05-23 19:48:21 [INFO]: Epoch 026 - training loss: 0.2244, validation loss: 0.3098
2024-05-23 19:48:22 [INFO]: Epoch 027 - training loss: 0.2241, validation loss: 0.3156
2024-05-23 19:48:22 [INFO]: Epoch 028 - training loss: 0.2193, validation loss: 0.3152
2024-05-23 19:48:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:48:22 [INFO]: Finished training. The best model is from epoch#18.
2024-05-23 19:48:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T194802/TimesNet.pypots
2024-05-23 19:48:22 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2893, MSE=0.2753
2024-05-23 19:48:23 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 19:48:23 [INFO]: Using the given device: cuda:0
2024-05-23 19:48:23 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823
2024-05-23 19:48:23 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/tensorboard
2024-05-23 19:48:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 19:49:06 [INFO]: Epoch 001 - training loss: 0.4187, validation loss: 0.3340
2024-05-23 19:49:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch1_loss0.33404270708560946.pypots
2024-05-23 19:49:49 [INFO]: Epoch 002 - training loss: 0.3153, validation loss: 0.3133
2024-05-23 19:49:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch2_loss0.3133423626422882.pypots
2024-05-23 19:50:33 [INFO]: Epoch 003 - training loss: 0.3093, validation loss: 0.2928
2024-05-23 19:50:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch3_loss0.2927590638399124.pypots
2024-05-23 19:51:16 [INFO]: Epoch 004 - training loss: 0.2941, validation loss: 0.2761
2024-05-23 19:51:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch4_loss0.2760874226689339.pypots
2024-05-23 19:51:59 [INFO]: Epoch 005 - training loss: 0.2716, validation loss: 0.2795
2024-05-23 19:52:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch5_loss0.27949289679527284.pypots
2024-05-23 19:52:43 [INFO]: Epoch 006 - training loss: 0.2686, validation loss: 0.2519
2024-05-23 19:52:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch6_loss0.25185387134552.pypots
2024-05-23 19:53:27 [INFO]: Epoch 007 - training loss: 0.2583, validation loss: 0.2418
2024-05-23 19:53:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch7_loss0.24182847663760185.pypots
2024-05-23 19:54:11 [INFO]: Epoch 008 - training loss: 0.2467, validation loss: 0.2340
2024-05-23 19:54:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch8_loss0.23402431458234788.pypots
2024-05-23 19:54:55 [INFO]: Epoch 009 - training loss: 0.2338, validation loss: 0.2273
2024-05-23 19:54:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch9_loss0.22732681632041932.pypots
2024-05-23 19:55:39 [INFO]: Epoch 010 - training loss: 0.2347, validation loss: 0.2279
2024-05-23 19:55:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch10_loss0.22785281538963317.pypots
2024-05-23 19:56:23 [INFO]: Epoch 011 - training loss: 0.2291, validation loss: 0.2193
2024-05-23 19:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch11_loss0.2192631669342518.pypots
2024-05-23 19:57:06 [INFO]: Epoch 012 - training loss: 0.2229, validation loss: 0.2183
2024-05-23 19:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch12_loss0.21825386434793473.pypots
2024-05-23 19:57:50 [INFO]: Epoch 013 - training loss: 0.2229, validation loss: 0.2143
2024-05-23 19:57:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch13_loss0.21426876857876778.pypots
2024-05-23 19:58:34 [INFO]: Epoch 014 - training loss: 0.2279, validation loss: 0.2138
2024-05-23 19:58:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch14_loss0.21377346366643907.pypots
2024-05-23 19:59:18 [INFO]: Epoch 015 - training loss: 0.2248, validation loss: 0.2197
2024-05-23 19:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch15_loss0.21969116777181624.pypots
2024-05-23 20:00:02 [INFO]: Epoch 016 - training loss: 0.2136, validation loss: 0.2110
2024-05-23 20:00:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch16_loss0.21102822050452233.pypots
2024-05-23 20:00:46 [INFO]: Epoch 017 - training loss: 0.2199, validation loss: 0.2150
2024-05-23 20:00:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch17_loss0.21499437168240548.pypots
2024-05-23 20:01:29 [INFO]: Epoch 018 - training loss: 0.2184, validation loss: 0.2096
2024-05-23 20:01:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch18_loss0.20955684334039687.pypots
2024-05-23 20:02:13 [INFO]: Epoch 019 - training loss: 0.2164, validation loss: 0.2044
2024-05-23 20:02:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch19_loss0.2044173039495945.pypots
2024-05-23 20:02:58 [INFO]: Epoch 020 - training loss: 0.2100, validation loss: 0.2068
2024-05-23 20:02:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch20_loss0.2067783445119858.pypots
2024-05-23 20:03:42 [INFO]: Epoch 021 - training loss: 0.2138, validation loss: 0.2037
2024-05-23 20:03:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch21_loss0.20367831662297248.pypots
2024-05-23 20:04:26 [INFO]: Epoch 022 - training loss: 0.2104, validation loss: 0.2073
2024-05-23 20:04:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch22_loss0.20725914984941482.pypots
2024-05-23 20:05:10 [INFO]: Epoch 023 - training loss: 0.2093, validation loss: 0.2046
2024-05-23 20:05:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch23_loss0.20459998175501823.pypots
2024-05-23 20:05:53 [INFO]: Epoch 024 - training loss: 0.2157, validation loss: 0.2042
2024-05-23 20:05:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch24_loss0.2042471818625927.pypots
2024-05-23 20:06:37 [INFO]: Epoch 025 - training loss: 0.2106, validation loss: 0.2037
2024-05-23 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch25_loss0.20371083095669745.pypots
2024-05-23 20:07:21 [INFO]: Epoch 026 - training loss: 0.2094, validation loss: 0.2019
2024-05-23 20:07:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch26_loss0.20193870961666108.pypots
2024-05-23 20:08:05 [INFO]: Epoch 027 - training loss: 0.2052, validation loss: 0.1980
2024-05-23 20:08:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch27_loss0.19801102578639984.pypots
2024-05-23 20:08:49 [INFO]: Epoch 028 - training loss: 0.1937, validation loss: 0.1987
2024-05-23 20:08:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch28_loss0.1986703872680664.pypots
2024-05-23 20:09:33 [INFO]: Epoch 029 - training loss: 0.2099, validation loss: 0.1991
2024-05-23 20:09:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch29_loss0.1990626834332943.pypots
2024-05-23 20:10:16 [INFO]: Epoch 030 - training loss: 0.1996, validation loss: 0.1973
2024-05-23 20:10:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch30_loss0.19726819172501564.pypots
2024-05-23 20:11:00 [INFO]: Epoch 031 - training loss: 0.2135, validation loss: 0.1975
2024-05-23 20:11:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch31_loss0.1974545456469059.pypots
2024-05-23 20:11:44 [INFO]: Epoch 032 - training loss: 0.2064, validation loss: 0.1997
2024-05-23 20:11:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch32_loss0.19972554072737694.pypots
2024-05-23 20:12:28 [INFO]: Epoch 033 - training loss: 0.2059, validation loss: 0.1979
2024-05-23 20:12:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch33_loss0.19789017736911774.pypots
2024-05-23 20:13:11 [INFO]: Epoch 034 - training loss: 0.1930, validation loss: 0.1986
2024-05-23 20:13:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch34_loss0.19857668355107308.pypots
2024-05-23 20:13:55 [INFO]: Epoch 035 - training loss: 0.1942, validation loss: 0.1947
2024-05-23 20:13:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch35_loss0.19473858475685119.pypots
2024-05-23 20:14:39 [INFO]: Epoch 036 - training loss: 0.1915, validation loss: 0.2001
2024-05-23 20:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch36_loss0.20005856826901436.pypots
2024-05-23 20:15:23 [INFO]: Epoch 037 - training loss: 0.2076, validation loss: 0.1935
2024-05-23 20:15:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch37_loss0.19352129325270653.pypots
2024-05-23 20:16:07 [INFO]: Epoch 038 - training loss: 0.1944, validation loss: 0.1984
2024-05-23 20:16:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch38_loss0.19844067469239235.pypots
2024-05-23 20:16:51 [INFO]: Epoch 039 - training loss: 0.1929, validation loss: 0.1930
2024-05-23 20:16:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch39_loss0.19296351224184036.pypots
2024-05-23 20:17:34 [INFO]: Epoch 040 - training loss: 0.2035, validation loss: 0.1906
2024-05-23 20:17:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch40_loss0.1906096816062927.pypots
2024-05-23 20:18:18 [INFO]: Epoch 041 - training loss: 0.1928, validation loss: 0.1931
2024-05-23 20:18:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch41_loss0.19309544190764427.pypots
2024-05-23 20:19:02 [INFO]: Epoch 042 - training loss: 0.2026, validation loss: 0.1940
2024-05-23 20:19:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch42_loss0.1940050467848778.pypots
2024-05-23 20:19:46 [INFO]: Epoch 043 - training loss: 0.1965, validation loss: 0.1927
2024-05-23 20:19:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch43_loss0.19272115230560302.pypots
2024-05-23 20:20:29 [INFO]: Epoch 044 - training loss: 0.1969, validation loss: 0.1919
2024-05-23 20:20:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch44_loss0.19191737249493598.pypots
2024-05-23 20:21:13 [INFO]: Epoch 045 - training loss: 0.1938, validation loss: 0.1911
2024-05-23 20:21:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch45_loss0.19110837131738662.pypots
2024-05-23 20:21:57 [INFO]: Epoch 046 - training loss: 0.1913, validation loss: 0.1894
2024-05-23 20:21:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch46_loss0.1894020527601242.pypots
2024-05-23 20:22:41 [INFO]: Epoch 047 - training loss: 0.1908, validation loss: 0.1927
2024-05-23 20:22:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch47_loss0.19272807985544205.pypots
2024-05-23 20:23:25 [INFO]: Epoch 048 - training loss: 0.1989, validation loss: 0.1899
2024-05-23 20:23:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch48_loss0.1898946538567543.pypots
2024-05-23 20:24:09 [INFO]: Epoch 049 - training loss: 0.1949, validation loss: 0.1919
2024-05-23 20:24:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch49_loss0.19191498905420304.pypots
2024-05-23 20:24:53 [INFO]: Epoch 050 - training loss: 0.1960, validation loss: 0.1900
2024-05-23 20:24:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch50_loss0.18997356817126274.pypots
2024-05-23 20:25:38 [INFO]: Epoch 051 - training loss: 0.1931, validation loss: 0.1868
2024-05-23 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch51_loss0.1867625005543232.pypots
2024-05-23 20:26:22 [INFO]: Epoch 052 - training loss: 0.1846, validation loss: 0.1881
2024-05-23 20:26:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch52_loss0.18811478465795517.pypots
2024-05-23 20:27:06 [INFO]: Epoch 053 - training loss: 0.1873, validation loss: 0.1908
2024-05-23 20:27:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch53_loss0.19076821208000183.pypots
2024-05-23 20:27:50 [INFO]: Epoch 054 - training loss: 0.1976, validation loss: 0.1903
2024-05-23 20:27:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch54_loss0.19026123434305192.pypots
2024-05-23 20:28:34 [INFO]: Epoch 055 - training loss: 0.1888, validation loss: 0.1881
2024-05-23 20:28:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch55_loss0.1880667433142662.pypots
2024-05-23 20:29:18 [INFO]: Epoch 056 - training loss: 0.1958, validation loss: 0.1865
2024-05-23 20:29:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch56_loss0.1865408316254616.pypots
2024-05-23 20:30:02 [INFO]: Epoch 057 - training loss: 0.2038, validation loss: 0.1885
2024-05-23 20:30:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch57_loss0.18851352035999297.pypots
2024-05-23 20:30:46 [INFO]: Epoch 058 - training loss: 0.1889, validation loss: 0.1886
2024-05-23 20:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch58_loss0.18859701603651047.pypots
2024-05-23 20:31:30 [INFO]: Epoch 059 - training loss: 0.1894, validation loss: 0.1870
2024-05-23 20:31:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch59_loss0.18700186535716057.pypots
2024-05-23 20:32:14 [INFO]: Epoch 060 - training loss: 0.1994, validation loss: 0.1874
2024-05-23 20:32:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch60_loss0.18741342797875404.pypots
2024-05-23 20:32:58 [INFO]: Epoch 061 - training loss: 0.1902, validation loss: 0.1889
2024-05-23 20:32:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch61_loss0.1888858273625374.pypots
2024-05-23 20:33:42 [INFO]: Epoch 062 - training loss: 0.1980, validation loss: 0.1884
2024-05-23 20:33:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch62_loss0.18841916993260382.pypots
2024-05-23 20:34:26 [INFO]: Epoch 063 - training loss: 0.1877, validation loss: 0.1871
2024-05-23 20:34:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch63_loss0.18707526996731758.pypots
2024-05-23 20:35:09 [INFO]: Epoch 064 - training loss: 0.2041, validation loss: 0.1875
2024-05-23 20:35:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch64_loss0.18747939988970758.pypots
2024-05-23 20:35:53 [INFO]: Epoch 065 - training loss: 0.1836, validation loss: 0.1832
2024-05-23 20:35:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch65_loss0.18318454846739768.pypots
2024-05-23 20:36:37 [INFO]: Epoch 066 - training loss: 0.1917, validation loss: 0.1859
2024-05-23 20:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch66_loss0.18585015386343.pypots
2024-05-23 20:37:20 [INFO]: Epoch 067 - training loss: 0.1942, validation loss: 0.1868
2024-05-23 20:37:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch67_loss0.18681877925992013.pypots
2024-05-23 20:38:04 [INFO]: Epoch 068 - training loss: 0.1908, validation loss: 0.1884
2024-05-23 20:38:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch68_loss0.1883653335273266.pypots
2024-05-23 20:38:48 [INFO]: Epoch 069 - training loss: 0.1943, validation loss: 0.1869
2024-05-23 20:38:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch69_loss0.18694768399000167.pypots
2024-05-23 20:39:31 [INFO]: Epoch 070 - training loss: 0.1859, validation loss: 0.1863
2024-05-23 20:39:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch70_loss0.18632791042327881.pypots
2024-05-23 20:40:15 [INFO]: Epoch 071 - training loss: 0.1907, validation loss: 0.1868
2024-05-23 20:40:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch71_loss0.1867946669459343.pypots
2024-05-23 20:40:59 [INFO]: Epoch 072 - training loss: 0.1961, validation loss: 0.1859
2024-05-23 20:40:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch72_loss0.18586537688970567.pypots
2024-05-23 20:41:42 [INFO]: Epoch 073 - training loss: 0.2035, validation loss: 0.1864
2024-05-23 20:41:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch73_loss0.18635068982839584.pypots
2024-05-23 20:42:26 [INFO]: Epoch 074 - training loss: 0.1884, validation loss: 0.1866
2024-05-23 20:42:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch74_loss0.18662483915686606.pypots
2024-05-23 20:43:09 [INFO]: Epoch 075 - training loss: 0.1817, validation loss: 0.1820
2024-05-23 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch75_loss0.18198702931404115.pypots
2024-05-23 20:43:53 [INFO]: Epoch 076 - training loss: 0.1915, validation loss: 0.1870
2024-05-23 20:43:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch76_loss0.1869868002831936.pypots
2024-05-23 20:44:37 [INFO]: Epoch 077 - training loss: 0.1910, validation loss: 0.1832
2024-05-23 20:44:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch77_loss0.18322297930717468.pypots
2024-05-23 20:45:20 [INFO]: Epoch 078 - training loss: 0.1794, validation loss: 0.1827
2024-05-23 20:45:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch78_loss0.18271807655692102.pypots
2024-05-23 20:46:04 [INFO]: Epoch 079 - training loss: 0.1853, validation loss: 0.1858
2024-05-23 20:46:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch79_loss0.18583307042717934.pypots
2024-05-23 20:46:48 [INFO]: Epoch 080 - training loss: 0.1859, validation loss: 0.1872
2024-05-23 20:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch80_loss0.18721341863274574.pypots
2024-05-23 20:47:31 [INFO]: Epoch 081 - training loss: 0.1921, validation loss: 0.1821
2024-05-23 20:47:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch81_loss0.18214715868234635.pypots
2024-05-23 20:48:15 [INFO]: Epoch 082 - training loss: 0.1933, validation loss: 0.1831
2024-05-23 20:48:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch82_loss0.18313502073287963.pypots
2024-05-23 20:48:59 [INFO]: Epoch 083 - training loss: 0.1920, validation loss: 0.1835
2024-05-23 20:48:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch83_loss0.1835314527153969.pypots
2024-05-23 20:49:43 [INFO]: Epoch 084 - training loss: 0.1940, validation loss: 0.1859
2024-05-23 20:49:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch84_loss0.18591751605272294.pypots
2024-05-23 20:50:26 [INFO]: Epoch 085 - training loss: 0.1860, validation loss: 0.1849
2024-05-23 20:50:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI_epoch85_loss0.18490993231534958.pypots
2024-05-23 20:50:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:50:26 [INFO]: Finished training. The best model is from epoch#75.
2024-05-23 20:50:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T194823/CSDI.pypots
2024-05-23 20:57:47 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2368, MSE=0.3324
2024-05-23 21:27:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 21:27:09 [INFO]: Using the given device: cuda:0
2024-05-23 21:27:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T212709
2024-05-23 21:27:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T212709/tensorboard
2024-05-23 21:27:09 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 21:27:10 [INFO]: Epoch 001 - training loss: 42758.1806, validation loss: 0.9583
2024-05-23 21:27:10 [INFO]: Epoch 002 - training loss: 24439.6097, validation loss: 0.7564
2024-05-23 21:27:11 [INFO]: Epoch 003 - training loss: 23483.0425, validation loss: 0.7220
2024-05-23 21:27:11 [INFO]: Epoch 004 - training loss: 23184.6797, validation loss: 0.6830
2024-05-23 21:27:12 [INFO]: Epoch 005 - training loss: 23038.9793, validation loss: 0.6789
2024-05-23 21:27:13 [INFO]: Epoch 006 - training loss: 22956.9820, validation loss: 0.6718
2024-05-23 21:27:13 [INFO]: Epoch 007 - training loss: 22908.4265, validation loss: 0.6753
2024-05-23 21:27:14 [INFO]: Epoch 008 - training loss: 22875.4847, validation loss: 0.6726
2024-05-23 21:27:14 [INFO]: Epoch 009 - training loss: 22854.7553, validation loss: 0.6691
2024-05-23 21:27:15 [INFO]: Epoch 010 - training loss: 22839.3376, validation loss: 0.6649
2024-05-23 21:27:15 [INFO]: Epoch 011 - training loss: 22828.1301, validation loss: 0.6650
2024-05-23 21:27:16 [INFO]: Epoch 012 - training loss: 22820.1771, validation loss: 0.6615
2024-05-23 21:27:17 [INFO]: Epoch 013 - training loss: 22813.7476, validation loss: 0.6634
2024-05-23 21:27:17 [INFO]: Epoch 014 - training loss: 22808.5195, validation loss: 0.6565
2024-05-23 21:27:18 [INFO]: Epoch 015 - training loss: 22804.6661, validation loss: 0.6554
2024-05-23 21:27:18 [INFO]: Epoch 016 - training loss: 22801.8162, validation loss: 0.6513
2024-05-23 21:27:19 [INFO]: Epoch 017 - training loss: 22798.6404, validation loss: 0.6519
2024-05-23 21:27:20 [INFO]: Epoch 018 - training loss: 22796.9375, validation loss: 0.6724
2024-05-23 21:27:20 [INFO]: Epoch 019 - training loss: 22795.9502, validation loss: 0.6482
2024-05-23 21:27:21 [INFO]: Epoch 020 - training loss: 22792.7918, validation loss: 0.6564
2024-05-23 21:27:21 [INFO]: Epoch 021 - training loss: 22791.9446, validation loss: 0.6416
2024-05-23 21:27:22 [INFO]: Epoch 022 - training loss: 22789.6976, validation loss: 0.6395
2024-05-23 21:27:23 [INFO]: Epoch 023 - training loss: 22788.4643, validation loss: 0.6375
2024-05-23 21:27:23 [INFO]: Epoch 024 - training loss: 22787.9067, validation loss: 0.6389
2024-05-23 21:27:24 [INFO]: Epoch 025 - training loss: 22786.7444, validation loss: 0.6336
2024-05-23 21:27:24 [INFO]: Epoch 026 - training loss: 22785.3763, validation loss: 0.6300
2024-05-23 21:27:25 [INFO]: Epoch 027 - training loss: 22785.0717, validation loss: 0.6340
2024-05-23 21:27:25 [INFO]: Epoch 028 - training loss: 22784.2399, validation loss: 0.6372
2024-05-23 21:27:26 [INFO]: Epoch 029 - training loss: 22783.7610, validation loss: 0.6287
2024-05-23 21:27:27 [INFO]: Epoch 030 - training loss: 22783.0776, validation loss: 0.6278
2024-05-23 21:27:27 [INFO]: Epoch 031 - training loss: 22782.1369, validation loss: 0.6386
2024-05-23 21:27:28 [INFO]: Epoch 032 - training loss: 22782.0867, validation loss: 0.6415
2024-05-23 21:27:28 [INFO]: Epoch 033 - training loss: 22781.5107, validation loss: 0.6257
2024-05-23 21:27:29 [INFO]: Epoch 034 - training loss: 22780.4666, validation loss: 0.6255
2024-05-23 21:27:30 [INFO]: Epoch 035 - training loss: 22780.1882, validation loss: 0.6273
2024-05-23 21:27:30 [INFO]: Epoch 036 - training loss: 22779.3291, validation loss: 0.6177
2024-05-23 21:27:31 [INFO]: Epoch 037 - training loss: 22778.9632, validation loss: 0.6251
2024-05-23 21:27:31 [INFO]: Epoch 038 - training loss: 22777.3968, validation loss: 0.6139
2024-05-23 21:27:32 [INFO]: Epoch 039 - training loss: 22776.7358, validation loss: 0.6117
2024-05-23 21:27:33 [INFO]: Epoch 040 - training loss: 22775.7383, validation loss: 0.6090
2024-05-23 21:27:33 [INFO]: Epoch 041 - training loss: 22774.9401, validation loss: 0.6050
2024-05-23 21:27:34 [INFO]: Epoch 042 - training loss: 22773.5907, validation loss: 0.6001
2024-05-23 21:27:34 [INFO]: Epoch 043 - training loss: 22773.0419, validation loss: 0.5979
2024-05-23 21:27:35 [INFO]: Epoch 044 - training loss: 22772.2848, validation loss: 0.5939
2024-05-23 21:27:36 [INFO]: Epoch 045 - training loss: 22773.4485, validation loss: 0.5984
2024-05-23 21:27:36 [INFO]: Epoch 046 - training loss: 22770.1600, validation loss: 0.5872
2024-05-23 21:27:37 [INFO]: Epoch 047 - training loss: 22770.8247, validation loss: 0.6138
2024-05-23 21:27:37 [INFO]: Epoch 048 - training loss: 22770.0016, validation loss: 0.5846
2024-05-23 21:27:38 [INFO]: Epoch 049 - training loss: 22768.1932, validation loss: 0.6319
2024-05-23 21:27:39 [INFO]: Epoch 050 - training loss: 22769.0483, validation loss: 0.5772
2024-05-23 21:27:39 [INFO]: Epoch 051 - training loss: 22767.1899, validation loss: 0.5775
2024-05-23 21:27:40 [INFO]: Epoch 052 - training loss: 22766.5039, validation loss: 0.5969
2024-05-23 21:27:40 [INFO]: Epoch 053 - training loss: 22766.3639, validation loss: 0.5716
2024-05-23 21:27:41 [INFO]: Epoch 054 - training loss: 22765.4147, validation loss: 0.5747
2024-05-23 21:27:42 [INFO]: Epoch 055 - training loss: 22764.0572, validation loss: 0.5644
2024-05-23 21:27:42 [INFO]: Epoch 056 - training loss: 22763.3806, validation loss: 0.5616
2024-05-23 21:27:43 [INFO]: Epoch 057 - training loss: 22762.5519, validation loss: 0.5617
2024-05-23 21:27:43 [INFO]: Epoch 058 - training loss: 22762.0456, validation loss: 0.5619
2024-05-23 21:27:44 [INFO]: Epoch 059 - training loss: 22761.6066, validation loss: 0.5718
2024-05-23 21:27:45 [INFO]: Epoch 060 - training loss: 22761.5190, validation loss: 0.5573
2024-05-23 21:27:45 [INFO]: Epoch 061 - training loss: 22760.7980, validation loss: 0.5524
2024-05-23 21:27:46 [INFO]: Epoch 062 - training loss: 22760.3861, validation loss: 0.5485
2024-05-23 21:27:46 [INFO]: Epoch 063 - training loss: 22759.3771, validation loss: 0.5469
2024-05-23 21:27:47 [INFO]: Epoch 064 - training loss: 22759.3802, validation loss: 0.5435
2024-05-23 21:27:48 [INFO]: Epoch 065 - training loss: 22758.3885, validation loss: 0.5425
2024-05-23 21:27:48 [INFO]: Epoch 066 - training loss: 22758.1706, validation loss: 0.5432
2024-05-23 21:27:49 [INFO]: Epoch 067 - training loss: 22757.7119, validation loss: 0.5349
2024-05-23 21:27:49 [INFO]: Epoch 068 - training loss: 22758.0198, validation loss: 0.5333
2024-05-23 21:27:50 [INFO]: Epoch 069 - training loss: 22756.8061, validation loss: 0.5320
2024-05-23 21:27:51 [INFO]: Epoch 070 - training loss: 22756.9283, validation loss: 0.5320
2024-05-23 21:27:51 [INFO]: Epoch 071 - training loss: 22755.8187, validation loss: 0.5309
2024-05-23 21:27:52 [INFO]: Epoch 072 - training loss: 22755.3251, validation loss: 0.5270
2024-05-23 21:27:52 [INFO]: Epoch 073 - training loss: 22755.6159, validation loss: 0.5235
2024-05-23 21:27:53 [INFO]: Epoch 074 - training loss: 22754.8297, validation loss: 0.5245
2024-05-23 21:27:54 [INFO]: Epoch 075 - training loss: 22754.2099, validation loss: 0.5410
2024-05-23 21:27:54 [INFO]: Epoch 076 - training loss: 22754.3751, validation loss: 0.5266
2024-05-23 21:27:55 [INFO]: Epoch 077 - training loss: 22754.0413, validation loss: 0.5293
2024-05-23 21:27:55 [INFO]: Epoch 078 - training loss: 22753.9177, validation loss: 0.5246
2024-05-23 21:27:56 [INFO]: Epoch 079 - training loss: 22754.1099, validation loss: 0.5218
2024-05-23 21:27:56 [INFO]: Epoch 080 - training loss: 22753.0342, validation loss: 0.5283
2024-05-23 21:27:57 [INFO]: Epoch 081 - training loss: 22753.4475, validation loss: 0.5202
2024-05-23 21:27:58 [INFO]: Epoch 082 - training loss: 22752.5462, validation loss: 0.5204
2024-05-23 21:27:58 [INFO]: Epoch 083 - training loss: 22752.0197, validation loss: 0.5232
2024-05-23 21:27:59 [INFO]: Epoch 084 - training loss: 22752.4844, validation loss: 0.5162
2024-05-23 21:27:59 [INFO]: Epoch 085 - training loss: 22753.3233, validation loss: 0.5168
2024-05-23 21:28:00 [INFO]: Epoch 086 - training loss: 22752.5272, validation loss: 0.5150
2024-05-23 21:28:01 [INFO]: Epoch 087 - training loss: 22752.8566, validation loss: 0.5143
2024-05-23 21:28:01 [INFO]: Epoch 088 - training loss: 22751.3515, validation loss: 0.5141
2024-05-23 21:28:02 [INFO]: Epoch 089 - training loss: 22750.7480, validation loss: 0.5131
2024-05-23 21:28:02 [INFO]: Epoch 090 - training loss: 22750.5464, validation loss: 0.5159
2024-05-23 21:28:03 [INFO]: Epoch 091 - training loss: 22750.3310, validation loss: 0.5131
2024-05-23 21:28:04 [INFO]: Epoch 092 - training loss: 22750.3222, validation loss: 0.5096
2024-05-23 21:28:04 [INFO]: Epoch 093 - training loss: 22750.2341, validation loss: 0.5101
2024-05-23 21:28:05 [INFO]: Epoch 094 - training loss: 22749.9593, validation loss: 0.5097
2024-05-23 21:28:05 [INFO]: Epoch 095 - training loss: 22749.7668, validation loss: 0.5121
2024-05-23 21:28:06 [INFO]: Epoch 096 - training loss: 22749.6550, validation loss: 0.5093
2024-05-23 21:28:07 [INFO]: Epoch 097 - training loss: 22749.5434, validation loss: 0.5197
2024-05-23 21:28:07 [INFO]: Epoch 098 - training loss: 22749.8376, validation loss: 0.5136
2024-05-23 21:28:08 [INFO]: Epoch 099 - training loss: 22749.4269, validation loss: 0.5098
2024-05-23 21:28:08 [INFO]: Epoch 100 - training loss: 22749.4115, validation loss: 0.5106
2024-05-23 21:28:09 [INFO]: Epoch 101 - training loss: 22750.0528, validation loss: 0.5089
2024-05-23 21:28:10 [INFO]: Epoch 102 - training loss: 22749.2333, validation loss: 0.5249
2024-05-23 21:28:10 [INFO]: Epoch 103 - training loss: 22751.9597, validation loss: 0.5092
2024-05-23 21:28:11 [INFO]: Epoch 104 - training loss: 22753.6722, validation loss: 0.5100
2024-05-23 21:28:12 [INFO]: Epoch 105 - training loss: 22750.5190, validation loss: 0.5200
2024-05-23 21:28:12 [INFO]: Epoch 106 - training loss: 22750.1773, validation loss: 0.5056
2024-05-23 21:28:13 [INFO]: Epoch 107 - training loss: 22749.0395, validation loss: 0.5046
2024-05-23 21:28:13 [INFO]: Epoch 108 - training loss: 22748.1598, validation loss: 0.5084
2024-05-23 21:28:14 [INFO]: Epoch 109 - training loss: 22748.3564, validation loss: 0.5035
2024-05-23 21:28:15 [INFO]: Epoch 110 - training loss: 22748.0683, validation loss: 0.4994
2024-05-23 21:28:15 [INFO]: Epoch 111 - training loss: 22747.5105, validation loss: 0.5033
2024-05-23 21:28:16 [INFO]: Epoch 112 - training loss: 22747.5568, validation loss: 0.5008
2024-05-23 21:28:16 [INFO]: Epoch 113 - training loss: 22747.4268, validation loss: 0.4991
2024-05-23 21:28:17 [INFO]: Epoch 114 - training loss: 22747.3222, validation loss: 0.4995
2024-05-23 21:28:17 [INFO]: Epoch 115 - training loss: 22747.1993, validation loss: 0.4970
2024-05-23 21:28:18 [INFO]: Epoch 116 - training loss: 22746.8104, validation loss: 0.4994
2024-05-23 21:28:19 [INFO]: Epoch 117 - training loss: 22747.0574, validation loss: 0.4971
2024-05-23 21:28:19 [INFO]: Epoch 118 - training loss: 22746.8958, validation loss: 0.4962
2024-05-23 21:28:20 [INFO]: Epoch 119 - training loss: 22746.5464, validation loss: 0.4981
2024-05-23 21:28:20 [INFO]: Epoch 120 - training loss: 22746.6872, validation loss: 0.4932
2024-05-23 21:28:21 [INFO]: Epoch 121 - training loss: 22746.6598, validation loss: 0.4993
2024-05-23 21:28:22 [INFO]: Epoch 122 - training loss: 22746.5086, validation loss: 0.4949
2024-05-23 21:28:22 [INFO]: Epoch 123 - training loss: 22746.1420, validation loss: 0.4966
2024-05-23 21:28:23 [INFO]: Epoch 124 - training loss: 22745.8738, validation loss: 0.4922
2024-05-23 21:28:23 [INFO]: Epoch 125 - training loss: 22745.6633, validation loss: 0.4956
2024-05-23 21:28:24 [INFO]: Epoch 126 - training loss: 22745.9096, validation loss: 0.4945
2024-05-23 21:28:25 [INFO]: Epoch 127 - training loss: 22746.5730, validation loss: 0.4940
2024-05-23 21:28:25 [INFO]: Epoch 128 - training loss: 22748.1487, validation loss: 0.4917
2024-05-23 21:28:26 [INFO]: Epoch 129 - training loss: 22749.0526, validation loss: 0.5000
2024-05-23 21:28:26 [INFO]: Epoch 130 - training loss: 22748.3267, validation loss: 0.4969
2024-05-23 21:28:27 [INFO]: Epoch 131 - training loss: 22745.9626, validation loss: 0.4898
2024-05-23 21:28:27 [INFO]: Epoch 132 - training loss: 22745.1856, validation loss: 0.4882
2024-05-23 21:28:28 [INFO]: Epoch 133 - training loss: 22744.9420, validation loss: 0.4884
2024-05-23 21:28:29 [INFO]: Epoch 134 - training loss: 22745.0062, validation loss: 0.4886
2024-05-23 21:28:29 [INFO]: Epoch 135 - training loss: 22744.8882, validation loss: 0.4881
2024-05-23 21:28:30 [INFO]: Epoch 136 - training loss: 22744.6555, validation loss: 0.4886
2024-05-23 21:28:30 [INFO]: Epoch 137 - training loss: 22745.3659, validation loss: 0.4882
2024-05-23 21:28:31 [INFO]: Epoch 138 - training loss: 22744.9509, validation loss: 0.4863
2024-05-23 21:28:32 [INFO]: Epoch 139 - training loss: 22744.9905, validation loss: 0.4869
2024-05-23 21:28:32 [INFO]: Epoch 140 - training loss: 22745.0602, validation loss: 0.4877
2024-05-23 21:28:33 [INFO]: Epoch 141 - training loss: 22745.1312, validation loss: 0.4862
2024-05-23 21:28:33 [INFO]: Epoch 142 - training loss: 22745.3827, validation loss: 0.4861
2024-05-23 21:28:34 [INFO]: Epoch 143 - training loss: 22745.7696, validation loss: 0.4850
2024-05-23 21:28:35 [INFO]: Epoch 144 - training loss: 22745.1670, validation loss: 0.4842
2024-05-23 21:28:35 [INFO]: Epoch 145 - training loss: 22744.8016, validation loss: 0.4855
2024-05-23 21:28:36 [INFO]: Epoch 146 - training loss: 22744.8098, validation loss: 0.4812
2024-05-23 21:28:36 [INFO]: Epoch 147 - training loss: 22744.4549, validation loss: 0.4826
2024-05-23 21:28:37 [INFO]: Epoch 148 - training loss: 22744.2332, validation loss: 0.4799
2024-05-23 21:28:37 [INFO]: Epoch 149 - training loss: 22744.2426, validation loss: 0.4832
2024-05-23 21:28:38 [INFO]: Epoch 150 - training loss: 22743.9124, validation loss: 0.4803
2024-05-23 21:28:39 [INFO]: Epoch 151 - training loss: 22744.0476, validation loss: 0.4852
2024-05-23 21:28:39 [INFO]: Epoch 152 - training loss: 22743.8099, validation loss: 0.4792
2024-05-23 21:28:40 [INFO]: Epoch 153 - training loss: 22743.8397, validation loss: 0.4813
2024-05-23 21:28:40 [INFO]: Epoch 154 - training loss: 22743.8671, validation loss: 0.4786
2024-05-23 21:28:41 [INFO]: Epoch 155 - training loss: 22743.4995, validation loss: 0.4806
2024-05-23 21:28:42 [INFO]: Epoch 156 - training loss: 22744.2273, validation loss: 0.4769
2024-05-23 21:28:42 [INFO]: Epoch 157 - training loss: 22744.7199, validation loss: 0.4838
2024-05-23 21:28:43 [INFO]: Epoch 158 - training loss: 22744.4484, validation loss: 0.4772
2024-05-23 21:28:43 [INFO]: Epoch 159 - training loss: 22744.1205, validation loss: 0.4776
2024-05-23 21:28:44 [INFO]: Epoch 160 - training loss: 22743.5146, validation loss: 0.4795
2024-05-23 21:28:44 [INFO]: Epoch 161 - training loss: 22743.7620, validation loss: 0.4755
2024-05-23 21:28:45 [INFO]: Epoch 162 - training loss: 22743.5877, validation loss: 0.4745
2024-05-23 21:28:46 [INFO]: Epoch 163 - training loss: 22743.3782, validation loss: 0.4742
2024-05-23 21:28:46 [INFO]: Epoch 164 - training loss: 22743.3776, validation loss: 0.4738
2024-05-23 21:28:47 [INFO]: Epoch 165 - training loss: 22742.9028, validation loss: 0.4776
2024-05-23 21:28:47 [INFO]: Epoch 166 - training loss: 22743.0022, validation loss: 0.4728
2024-05-23 21:28:48 [INFO]: Epoch 167 - training loss: 22742.7427, validation loss: 0.4751
2024-05-23 21:28:49 [INFO]: Epoch 168 - training loss: 22742.7899, validation loss: 0.4735
2024-05-23 21:28:49 [INFO]: Epoch 169 - training loss: 22742.8473, validation loss: 0.4718
2024-05-23 21:28:50 [INFO]: Epoch 170 - training loss: 22743.7104, validation loss: 0.4743
2024-05-23 21:28:50 [INFO]: Epoch 171 - training loss: 22743.2238, validation loss: 0.4701
2024-05-23 21:28:51 [INFO]: Epoch 172 - training loss: 22744.0098, validation loss: 0.4705
2024-05-23 21:28:52 [INFO]: Epoch 173 - training loss: 22742.9211, validation loss: 0.4706
2024-05-23 21:28:52 [INFO]: Epoch 174 - training loss: 22742.7098, validation loss: 0.4711
2024-05-23 21:28:53 [INFO]: Epoch 175 - training loss: 22742.2951, validation loss: 0.4731
2024-05-23 21:28:53 [INFO]: Epoch 176 - training loss: 22742.6441, validation loss: 0.4730
2024-05-23 21:28:54 [INFO]: Epoch 177 - training loss: 22742.1487, validation loss: 0.4731
2024-05-23 21:28:55 [INFO]: Epoch 178 - training loss: 22742.0519, validation loss: 0.4705
2024-05-23 21:28:55 [INFO]: Epoch 179 - training loss: 22742.4650, validation loss: 0.4723
2024-05-23 21:28:56 [INFO]: Epoch 180 - training loss: 22743.4453, validation loss: 0.4711
2024-05-23 21:28:56 [INFO]: Epoch 181 - training loss: 22743.0225, validation loss: 0.4702
2024-05-23 21:28:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:28:56 [INFO]: Finished training. The best model is from epoch#171.
2024-05-23 21:28:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T212709/GPVAE.pypots
2024-05-23 21:28:56 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4020, MSE=0.4093
2024-05-23 21:28:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 21:28:57 [INFO]: Using the given device: cuda:0
2024-05-23 21:28:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T212857
2024-05-23 21:28:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T212857/tensorboard
2024-05-23 21:28:57 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 21:29:18 [INFO]: Epoch 001 - generator training loss: 0.6107, discriminator training loss: 0.3831, validation loss: 0.6485
2024-05-23 21:29:37 [INFO]: Epoch 002 - generator training loss: 0.4899, discriminator training loss: 0.2732, validation loss: 0.5556
2024-05-23 21:29:55 [INFO]: Epoch 003 - generator training loss: 0.4489, discriminator training loss: 0.2365, validation loss: 0.5568
2024-05-23 21:30:14 [INFO]: Epoch 004 - generator training loss: 0.4618, discriminator training loss: 0.1890, validation loss: 0.5375
2024-05-23 21:30:33 [INFO]: Epoch 005 - generator training loss: 0.4548, discriminator training loss: 0.1587, validation loss: 0.5193
2024-05-23 21:30:51 [INFO]: Epoch 006 - generator training loss: 0.4425, discriminator training loss: 0.1405, validation loss: 0.5024
2024-05-23 21:31:10 [INFO]: Epoch 007 - generator training loss: 0.4301, discriminator training loss: 0.1259, validation loss: 0.4893
2024-05-23 21:31:28 [INFO]: Epoch 008 - generator training loss: 0.4154, discriminator training loss: 0.1154, validation loss: 0.4824
2024-05-23 21:31:47 [INFO]: Epoch 009 - generator training loss: 0.4051, discriminator training loss: 0.1071, validation loss: 0.4731
2024-05-23 21:32:05 [INFO]: Epoch 010 - generator training loss: 0.3999, discriminator training loss: 0.0999, validation loss: 0.4607
2024-05-23 21:32:24 [INFO]: Epoch 011 - generator training loss: 0.3935, discriminator training loss: 0.0938, validation loss: 0.4599
2024-05-23 21:32:42 [INFO]: Epoch 012 - generator training loss: 0.3901, discriminator training loss: 0.0888, validation loss: 0.4520
2024-05-23 21:33:01 [INFO]: Epoch 013 - generator training loss: 0.3854, discriminator training loss: 0.0841, validation loss: 0.4500
2024-05-23 21:33:19 [INFO]: Epoch 014 - generator training loss: 0.3822, discriminator training loss: 0.0801, validation loss: 0.4409
2024-05-23 21:33:38 [INFO]: Epoch 015 - generator training loss: 0.3776, discriminator training loss: 0.0765, validation loss: 0.4391
2024-05-23 21:33:57 [INFO]: Epoch 016 - generator training loss: 0.3732, discriminator training loss: 0.0733, validation loss: 0.4354
2024-05-23 21:34:15 [INFO]: Epoch 017 - generator training loss: 0.3732, discriminator training loss: 0.0705, validation loss: 0.4344
2024-05-23 21:34:34 [INFO]: Epoch 018 - generator training loss: 0.3679, discriminator training loss: 0.0677, validation loss: 0.4278
2024-05-23 21:34:52 [INFO]: Epoch 019 - generator training loss: 0.3635, discriminator training loss: 0.0653, validation loss: 0.4270
2024-05-23 21:35:11 [INFO]: Epoch 020 - generator training loss: 0.3611, discriminator training loss: 0.0632, validation loss: 0.4246
2024-05-23 21:35:29 [INFO]: Epoch 021 - generator training loss: 0.3540, discriminator training loss: 0.0612, validation loss: 0.4174
2024-05-23 21:35:48 [INFO]: Epoch 022 - generator training loss: 0.3531, discriminator training loss: 0.0594, validation loss: 0.4122
2024-05-23 21:36:06 [INFO]: Epoch 023 - generator training loss: 0.3472, discriminator training loss: 0.0577, validation loss: 0.4099
2024-05-23 21:36:25 [INFO]: Epoch 024 - generator training loss: 0.3428, discriminator training loss: 0.0564, validation loss: 0.4037
2024-05-23 21:36:44 [INFO]: Epoch 025 - generator training loss: 0.3393, discriminator training loss: 0.0551, validation loss: 0.4044
2024-05-23 21:37:02 [INFO]: Epoch 026 - generator training loss: 0.3359, discriminator training loss: 0.0539, validation loss: 0.3956
2024-05-23 21:37:21 [INFO]: Epoch 027 - generator training loss: 0.3282, discriminator training loss: 0.0528, validation loss: 0.3904
2024-05-23 21:37:39 [INFO]: Epoch 028 - generator training loss: 0.3231, discriminator training loss: 0.0521, validation loss: 0.3945
2024-05-23 21:37:58 [INFO]: Epoch 029 - generator training loss: 0.3206, discriminator training loss: 0.0511, validation loss: 0.3859
2024-05-23 21:38:16 [INFO]: Epoch 030 - generator training loss: 0.3147, discriminator training loss: 0.0504, validation loss: 0.3855
2024-05-23 21:38:35 [INFO]: Epoch 031 - generator training loss: 0.3103, discriminator training loss: 0.0498, validation loss: 0.3777
2024-05-23 21:38:53 [INFO]: Epoch 032 - generator training loss: 0.3087, discriminator training loss: 0.0490, validation loss: 0.3808
2024-05-23 21:39:12 [INFO]: Epoch 033 - generator training loss: 0.3042, discriminator training loss: 0.0488, validation loss: 0.3727
2024-05-23 21:39:30 [INFO]: Epoch 034 - generator training loss: 0.2968, discriminator training loss: 0.0483, validation loss: 0.3712
2024-05-23 21:39:49 [INFO]: Epoch 035 - generator training loss: 0.2969, discriminator training loss: 0.0476, validation loss: 0.3714
2024-05-23 21:40:07 [INFO]: Epoch 036 - generator training loss: 0.2955, discriminator training loss: 0.0473, validation loss: 0.3622
2024-05-23 21:40:26 [INFO]: Epoch 037 - generator training loss: 0.2921, discriminator training loss: 0.0470, validation loss: 0.3722
2024-05-23 21:40:44 [INFO]: Epoch 038 - generator training loss: 0.3055, discriminator training loss: 0.0470, validation loss: 0.3605
2024-05-23 21:41:03 [INFO]: Epoch 039 - generator training loss: 0.2871, discriminator training loss: 0.0464, validation loss: 0.3576
2024-05-23 21:41:21 [INFO]: Epoch 040 - generator training loss: 0.2794, discriminator training loss: 0.0459, validation loss: 0.3511
2024-05-23 21:41:40 [INFO]: Epoch 041 - generator training loss: 0.2743, discriminator training loss: 0.0457, validation loss: 0.3522
2024-05-23 21:41:58 [INFO]: Epoch 042 - generator training loss: 0.2742, discriminator training loss: 0.0456, validation loss: 0.3551
2024-05-23 21:42:17 [INFO]: Epoch 043 - generator training loss: 0.2678, discriminator training loss: 0.0452, validation loss: 0.3480
2024-05-23 21:42:35 [INFO]: Epoch 044 - generator training loss: 0.2634, discriminator training loss: 0.0450, validation loss: 0.3469
2024-05-23 21:42:54 [INFO]: Epoch 045 - generator training loss: 0.2614, discriminator training loss: 0.0447, validation loss: 0.3445
2024-05-23 21:43:12 [INFO]: Epoch 046 - generator training loss: 0.2571, discriminator training loss: 0.0444, validation loss: 0.3469
2024-05-23 21:43:31 [INFO]: Epoch 047 - generator training loss: 0.2576, discriminator training loss: 0.0445, validation loss: 0.3487
2024-05-23 21:43:49 [INFO]: Epoch 048 - generator training loss: 0.2569, discriminator training loss: 0.0445, validation loss: 0.3433
2024-05-23 21:44:08 [INFO]: Epoch 049 - generator training loss: 0.2509, discriminator training loss: 0.0441, validation loss: 0.3421
2024-05-23 21:44:26 [INFO]: Epoch 050 - generator training loss: 0.2510, discriminator training loss: 0.0438, validation loss: 0.3438
2024-05-23 21:44:45 [INFO]: Epoch 051 - generator training loss: 0.2465, discriminator training loss: 0.0438, validation loss: 0.3403
2024-05-23 21:45:03 [INFO]: Epoch 052 - generator training loss: 0.2433, discriminator training loss: 0.0434, validation loss: 0.3387
2024-05-23 21:45:22 [INFO]: Epoch 053 - generator training loss: 0.2401, discriminator training loss: 0.0433, validation loss: 0.3404
2024-05-23 21:45:40 [INFO]: Epoch 054 - generator training loss: 0.2381, discriminator training loss: 0.0432, validation loss: 0.3346
2024-05-23 21:45:59 [INFO]: Epoch 055 - generator training loss: 0.2333, discriminator training loss: 0.0432, validation loss: 0.3367
2024-05-23 21:46:17 [INFO]: Epoch 056 - generator training loss: 0.2302, discriminator training loss: 0.0428, validation loss: 0.3347
2024-05-23 21:46:36 [INFO]: Epoch 057 - generator training loss: 0.2337, discriminator training loss: 0.0428, validation loss: 0.3341
2024-05-23 21:46:54 [INFO]: Epoch 058 - generator training loss: 0.2309, discriminator training loss: 0.0428, validation loss: 0.3426
2024-05-23 21:47:12 [INFO]: Epoch 059 - generator training loss: 0.2305, discriminator training loss: 0.0428, validation loss: 0.3368
2024-05-23 21:47:31 [INFO]: Epoch 060 - generator training loss: 0.2293, discriminator training loss: 0.0425, validation loss: 0.3325
2024-05-23 21:47:49 [INFO]: Epoch 061 - generator training loss: 0.2220, discriminator training loss: 0.0425, validation loss: 0.3315
2024-05-23 21:48:07 [INFO]: Epoch 062 - generator training loss: 0.2189, discriminator training loss: 0.0425, validation loss: 0.3350
2024-05-23 21:48:26 [INFO]: Epoch 063 - generator training loss: 0.2168, discriminator training loss: 0.0423, validation loss: 0.3375
2024-05-23 21:48:44 [INFO]: Epoch 064 - generator training loss: 0.2190, discriminator training loss: 0.0422, validation loss: 0.3374
2024-05-23 21:49:03 [INFO]: Epoch 065 - generator training loss: 0.2230, discriminator training loss: 0.0421, validation loss: 0.3331
2024-05-23 21:49:22 [INFO]: Epoch 066 - generator training loss: 0.2195, discriminator training loss: 0.0421, validation loss: 0.3284
2024-05-23 21:49:41 [INFO]: Epoch 067 - generator training loss: 0.2178, discriminator training loss: 0.0420, validation loss: 0.3371
2024-05-23 21:50:00 [INFO]: Epoch 068 - generator training loss: 0.2204, discriminator training loss: 0.0417, validation loss: 0.3349
2024-05-23 21:50:20 [INFO]: Epoch 069 - generator training loss: 0.2106, discriminator training loss: 0.0416, validation loss: 0.3303
2024-05-23 21:50:39 [INFO]: Epoch 070 - generator training loss: 0.2086, discriminator training loss: 0.0418, validation loss: 0.3400
2024-05-23 21:50:58 [INFO]: Epoch 071 - generator training loss: 0.2098, discriminator training loss: 0.0417, validation loss: 0.3343
2024-05-23 21:51:17 [INFO]: Epoch 072 - generator training loss: 0.2066, discriminator training loss: 0.0415, validation loss: 0.3358
2024-05-23 21:51:36 [INFO]: Epoch 073 - generator training loss: 0.2048, discriminator training loss: 0.0413, validation loss: 0.3344
2024-05-23 21:51:56 [INFO]: Epoch 074 - generator training loss: 0.2061, discriminator training loss: 0.0409, validation loss: 0.3406
2024-05-23 21:52:16 [INFO]: Epoch 075 - generator training loss: 0.2104, discriminator training loss: 0.0412, validation loss: 0.3354
2024-05-23 21:52:36 [INFO]: Epoch 076 - generator training loss: 0.2089, discriminator training loss: 0.0411, validation loss: 0.3428
2024-05-23 21:52:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:52:36 [INFO]: Finished training. The best model is from epoch#66.
2024-05-23 21:52:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T212857/USGAN.pypots
2024-05-23 21:52:39 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2979, MSE=0.2613
2024-05-23 21:52:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 21:52:49 [INFO]: Using the given device: cuda:0
2024-05-23 21:52:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T215249
2024-05-23 21:52:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T215249/tensorboard
2024-05-23 21:52:49 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 21:53:04 [INFO]: Epoch 001 - training loss: 1.1413, validation loss: 0.5627
2024-05-23 21:53:17 [INFO]: Epoch 002 - training loss: 0.9282, validation loss: 0.5047
2024-05-23 21:53:30 [INFO]: Epoch 003 - training loss: 0.8666, validation loss: 0.4749
2024-05-23 21:53:42 [INFO]: Epoch 004 - training loss: 0.8308, validation loss: 0.4562
2024-05-23 21:53:55 [INFO]: Epoch 005 - training loss: 0.8041, validation loss: 0.4409
2024-05-23 21:54:07 [INFO]: Epoch 006 - training loss: 0.7818, validation loss: 0.4259
2024-05-23 21:54:20 [INFO]: Epoch 007 - training loss: 0.7636, validation loss: 0.4180
2024-05-23 21:54:32 [INFO]: Epoch 008 - training loss: 0.7480, validation loss: 0.4082
2024-05-23 21:54:45 [INFO]: Epoch 009 - training loss: 0.7344, validation loss: 0.4013
2024-05-23 21:54:57 [INFO]: Epoch 010 - training loss: 0.7235, validation loss: 0.3969
2024-05-23 21:55:10 [INFO]: Epoch 011 - training loss: 0.7139, validation loss: 0.3935
2024-05-23 21:55:23 [INFO]: Epoch 012 - training loss: 0.7048, validation loss: 0.3916
2024-05-23 21:55:35 [INFO]: Epoch 013 - training loss: 0.6970, validation loss: 0.3892
2024-05-23 21:55:48 [INFO]: Epoch 014 - training loss: 0.6900, validation loss: 0.3882
2024-05-23 21:56:01 [INFO]: Epoch 015 - training loss: 0.6843, validation loss: 0.3862
2024-05-23 21:56:14 [INFO]: Epoch 016 - training loss: 0.6789, validation loss: 0.3820
2024-05-23 21:56:27 [INFO]: Epoch 017 - training loss: 0.6734, validation loss: 0.3823
2024-05-23 21:56:40 [INFO]: Epoch 018 - training loss: 0.6687, validation loss: 0.3810
2024-05-23 21:56:52 [INFO]: Epoch 019 - training loss: 0.6650, validation loss: 0.3818
2024-05-23 21:57:05 [INFO]: Epoch 020 - training loss: 0.6608, validation loss: 0.3815
2024-05-23 21:57:18 [INFO]: Epoch 021 - training loss: 0.6572, validation loss: 0.3790
2024-05-23 21:57:31 [INFO]: Epoch 022 - training loss: 0.6530, validation loss: 0.3777
2024-05-23 21:57:43 [INFO]: Epoch 023 - training loss: 0.6501, validation loss: 0.3779
2024-05-23 21:57:56 [INFO]: Epoch 024 - training loss: 0.6468, validation loss: 0.3750
2024-05-23 21:58:09 [INFO]: Epoch 025 - training loss: 0.6439, validation loss: 0.3758
2024-05-23 21:58:22 [INFO]: Epoch 026 - training loss: 0.6408, validation loss: 0.3766
2024-05-23 21:58:35 [INFO]: Epoch 027 - training loss: 0.6386, validation loss: 0.3768
2024-05-23 21:58:47 [INFO]: Epoch 028 - training loss: 0.6356, validation loss: 0.3742
2024-05-23 21:59:00 [INFO]: Epoch 029 - training loss: 0.6316, validation loss: 0.3750
2024-05-23 21:59:13 [INFO]: Epoch 030 - training loss: 0.6293, validation loss: 0.3754
2024-05-23 21:59:25 [INFO]: Epoch 031 - training loss: 0.6261, validation loss: 0.3750
2024-05-23 21:59:38 [INFO]: Epoch 032 - training loss: 0.6242, validation loss: 0.3729
2024-05-23 21:59:51 [INFO]: Epoch 033 - training loss: 0.6211, validation loss: 0.3733
2024-05-23 22:00:04 [INFO]: Epoch 034 - training loss: 0.6189, validation loss: 0.3739
2024-05-23 22:00:17 [INFO]: Epoch 035 - training loss: 0.6191, validation loss: 0.3748
2024-05-23 22:00:29 [INFO]: Epoch 036 - training loss: 0.6175, validation loss: 0.3764
2024-05-23 22:00:41 [INFO]: Epoch 037 - training loss: 0.6161, validation loss: 0.3752
2024-05-23 22:00:53 [INFO]: Epoch 038 - training loss: 0.6121, validation loss: 0.3745
2024-05-23 22:01:05 [INFO]: Epoch 039 - training loss: 0.6073, validation loss: 0.3729
2024-05-23 22:01:17 [INFO]: Epoch 040 - training loss: 0.6032, validation loss: 0.3753
2024-05-23 22:01:29 [INFO]: Epoch 041 - training loss: 0.6057, validation loss: 0.3768
2024-05-23 22:01:41 [INFO]: Epoch 042 - training loss: 0.6019, validation loss: 0.3752
2024-05-23 22:01:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:01:41 [INFO]: Finished training. The best model is from epoch#32.
2024-05-23 22:01:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T215249/BRITS.pypots
2024-05-23 22:01:44 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2574, MSE=0.2554
2024-05-23 22:01:53 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 22:01:53 [INFO]: Using the given device: cuda:0
2024-05-23 22:01:53 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153
2024-05-23 22:01:53 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/tensorboard
2024-05-23 22:01:53 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 22:01:59 [INFO]: Epoch 001 - training loss: 1.1633, validation loss: 1.0020
2024-05-23 22:01:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch1_loss1.0019949942827224.pypots
2024-05-23 22:02:02 [INFO]: Epoch 002 - training loss: 0.7146, validation loss: 0.9742
2024-05-23 22:02:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch2_loss0.9741928488016128.pypots
2024-05-23 22:02:05 [INFO]: Epoch 003 - training loss: 0.6027, validation loss: 0.9500
2024-05-23 22:02:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch3_loss0.9500434756278991.pypots
2024-05-23 22:02:07 [INFO]: Epoch 004 - training loss: 0.5643, validation loss: 0.9400
2024-05-23 22:02:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch4_loss0.940001118183136.pypots
2024-05-23 22:02:10 [INFO]: Epoch 005 - training loss: 0.5348, validation loss: 0.9332
2024-05-23 22:02:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch5_loss0.9331682056188584.pypots
2024-05-23 22:02:13 [INFO]: Epoch 006 - training loss: 0.5149, validation loss: 0.9284
2024-05-23 22:02:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch6_loss0.9283702433109283.pypots
2024-05-23 22:02:16 [INFO]: Epoch 007 - training loss: 0.5144, validation loss: 0.9264
2024-05-23 22:02:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch7_loss0.92642442882061.pypots
2024-05-23 22:02:18 [INFO]: Epoch 008 - training loss: 0.4988, validation loss: 0.9247
2024-05-23 22:02:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch8_loss0.9247365951538086.pypots
2024-05-23 22:02:21 [INFO]: Epoch 009 - training loss: 0.4814, validation loss: 0.9214
2024-05-23 22:02:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch9_loss0.9213620126247406.pypots
2024-05-23 22:02:24 [INFO]: Epoch 010 - training loss: 0.4776, validation loss: 0.9198
2024-05-23 22:02:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch10_loss0.9198150157928466.pypots
2024-05-23 22:02:27 [INFO]: Epoch 011 - training loss: 0.4707, validation loss: 0.9189
2024-05-23 22:02:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch11_loss0.9189288973808288.pypots
2024-05-23 22:02:29 [INFO]: Epoch 012 - training loss: 0.4612, validation loss: 0.9199
2024-05-23 22:02:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch12_loss0.9198628902435303.pypots
2024-05-23 22:02:32 [INFO]: Epoch 013 - training loss: 0.4636, validation loss: 0.9216
2024-05-23 22:02:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch13_loss0.9215931028127671.pypots
2024-05-23 22:02:35 [INFO]: Epoch 014 - training loss: 0.4460, validation loss: 0.9229
2024-05-23 22:02:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch14_loss0.9229103624820709.pypots
2024-05-23 22:02:38 [INFO]: Epoch 015 - training loss: 0.4492, validation loss: 0.9256
2024-05-23 22:02:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch15_loss0.9255958288908005.pypots
2024-05-23 22:02:41 [INFO]: Epoch 016 - training loss: 0.4433, validation loss: 0.9267
2024-05-23 22:02:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch16_loss0.9266951531171799.pypots
2024-05-23 22:02:43 [INFO]: Epoch 017 - training loss: 0.4399, validation loss: 0.9292
2024-05-23 22:02:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch17_loss0.929224967956543.pypots
2024-05-23 22:02:46 [INFO]: Epoch 018 - training loss: 0.4454, validation loss: 0.9305
2024-05-23 22:02:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch18_loss0.9305379986763.pypots
2024-05-23 22:02:49 [INFO]: Epoch 019 - training loss: 0.4373, validation loss: 0.9323
2024-05-23 22:02:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch19_loss0.9322616189718247.pypots
2024-05-23 22:02:52 [INFO]: Epoch 020 - training loss: 0.4382, validation loss: 0.9344
2024-05-23 22:02:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch20_loss0.9343946158885956.pypots
2024-05-23 22:02:54 [INFO]: Epoch 021 - training loss: 0.4335, validation loss: 0.9352
2024-05-23 22:02:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN_epoch21_loss0.9351882606744766.pypots
2024-05-23 22:02:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:02:54 [INFO]: Finished training. The best model is from epoch#11.
2024-05-23 22:02:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T220153/MRNN.pypots
2024-05-23 22:02:55 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6882, MSE=0.8998
2024-05-23 22:03:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 22:03:00 [INFO]: Using the given device: cpu
2024-05-23 22:03:00 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4036, MSE=0.5059
2024-05-23 22:03:00 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_physionet_2012_seta".
2024-05-23 22:03:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 22:03:00 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6901, MSE=1.0191
2024-05-23 22:03:00 [INFO]: Successfully created the given path "saved_results/round_1/Median_physionet_2012_seta".
2024-05-23 22:03:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_physionet_2012_seta/imputation.pkl
2024-05-23 22:03:00 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7055, MSE=0.9762
2024-05-23 22:03:00 [INFO]: Successfully created the given path "saved_results/round_1/Mean_physionet_2012_seta".
2024-05-23 22:03:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 22:03:00 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-23 22:03:00 [INFO]: Using the given device: cuda:0
2024-05-23 22:03:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T220300
2024-05-23 22:03:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T220300/tensorboard
2024-05-23 22:03:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 22:03:01 [INFO]: Epoch 001 - training loss: 1.0830, validation loss: 0.5234
2024-05-23 22:03:02 [INFO]: Epoch 002 - training loss: 0.6854, validation loss: 0.4520
2024-05-23 22:03:04 [INFO]: Epoch 003 - training loss: 0.5734, validation loss: 0.4200
2024-05-23 22:03:05 [INFO]: Epoch 004 - training loss: 0.5076, validation loss: 0.3935
2024-05-23 22:03:06 [INFO]: Epoch 005 - training loss: 0.4661, validation loss: 0.3858
2024-05-23 22:03:07 [INFO]: Epoch 006 - training loss: 0.4311, validation loss: 0.3875
2024-05-23 22:03:08 [INFO]: Epoch 007 - training loss: 0.4145, validation loss: 0.3768
2024-05-23 22:03:09 [INFO]: Epoch 008 - training loss: 0.3935, validation loss: 0.3602
2024-05-23 22:03:11 [INFO]: Epoch 009 - training loss: 0.3673, validation loss: 0.3564
2024-05-23 22:03:12 [INFO]: Epoch 010 - training loss: 0.3502, validation loss: 0.3446
2024-05-23 22:03:13 [INFO]: Epoch 011 - training loss: 0.3327, validation loss: 0.3475
2024-05-23 22:03:14 [INFO]: Epoch 012 - training loss: 0.3211, validation loss: 0.3373
2024-05-23 22:03:15 [INFO]: Epoch 013 - training loss: 0.3030, validation loss: 0.3407
2024-05-23 22:03:16 [INFO]: Epoch 014 - training loss: 0.2983, validation loss: 0.3337
2024-05-23 22:03:17 [INFO]: Epoch 015 - training loss: 0.2819, validation loss: 0.3328
2024-05-23 22:03:19 [INFO]: Epoch 016 - training loss: 0.2774, validation loss: 0.3361
2024-05-23 22:03:20 [INFO]: Epoch 017 - training loss: 0.2657, validation loss: 0.3354
2024-05-23 22:03:21 [INFO]: Epoch 018 - training loss: 0.2567, validation loss: 0.3346
2024-05-23 22:03:22 [INFO]: Epoch 019 - training loss: 0.2467, validation loss: 0.3316
2024-05-23 22:03:23 [INFO]: Epoch 020 - training loss: 0.2382, validation loss: 0.3286
2024-05-23 22:03:24 [INFO]: Epoch 021 - training loss: 0.2362, validation loss: 0.3339
2024-05-23 22:03:26 [INFO]: Epoch 022 - training loss: 0.2310, validation loss: 0.3289
2024-05-23 22:03:27 [INFO]: Epoch 023 - training loss: 0.2231, validation loss: 0.3267
2024-05-23 22:03:28 [INFO]: Epoch 024 - training loss: 0.2148, validation loss: 0.3310
2024-05-23 22:03:29 [INFO]: Epoch 025 - training loss: 0.2144, validation loss: 0.3340
2024-05-23 22:03:30 [INFO]: Epoch 026 - training loss: 0.2093, validation loss: 0.3289
2024-05-23 22:03:31 [INFO]: Epoch 027 - training loss: 0.2017, validation loss: 0.3241
2024-05-23 22:03:32 [INFO]: Epoch 028 - training loss: 0.1993, validation loss: 0.3360
2024-05-23 22:03:34 [INFO]: Epoch 029 - training loss: 0.1986, validation loss: 0.3328
2024-05-23 22:03:35 [INFO]: Epoch 030 - training loss: 0.1948, validation loss: 0.3287
2024-05-23 22:03:36 [INFO]: Epoch 031 - training loss: 0.1919, validation loss: 0.3308
2024-05-23 22:03:37 [INFO]: Epoch 032 - training loss: 0.1864, validation loss: 0.3255
2024-05-23 22:03:38 [INFO]: Epoch 033 - training loss: 0.1795, validation loss: 0.3329
2024-05-23 22:03:39 [INFO]: Epoch 034 - training loss: 0.1749, validation loss: 0.3283
2024-05-23 22:03:40 [INFO]: Epoch 035 - training loss: 0.1727, validation loss: 0.3249
2024-05-23 22:03:42 [INFO]: Epoch 036 - training loss: 0.1730, validation loss: 0.3290
2024-05-23 22:03:43 [INFO]: Epoch 037 - training loss: 0.1686, validation loss: 0.3306
2024-05-23 22:03:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:03:43 [INFO]: Finished training. The best model is from epoch#27.
2024-05-23 22:03:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T220300/SAITS.pypots
2024-05-23 22:03:43 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2653, MSE=0.2858
2024-05-23 22:03:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 22:03:43 [INFO]: Using the given device: cuda:0
2024-05-23 22:03:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T220343
2024-05-23 22:03:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T220343/tensorboard
2024-05-23 22:03:43 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 22:03:44 [INFO]: Epoch 001 - training loss: 1.2463, validation loss: 0.6137
2024-05-23 22:03:45 [INFO]: Epoch 002 - training loss: 0.7818, validation loss: 0.5181
2024-05-23 22:03:45 [INFO]: Epoch 003 - training loss: 0.6529, validation loss: 0.4822
2024-05-23 22:03:46 [INFO]: Epoch 004 - training loss: 0.5844, validation loss: 0.4554
2024-05-23 22:03:46 [INFO]: Epoch 005 - training loss: 0.5428, validation loss: 0.4354
2024-05-23 22:03:47 [INFO]: Epoch 006 - training loss: 0.5095, validation loss: 0.4272
2024-05-23 22:03:47 [INFO]: Epoch 007 - training loss: 0.4911, validation loss: 0.4190
2024-05-23 22:03:48 [INFO]: Epoch 008 - training loss: 0.4601, validation loss: 0.4090
2024-05-23 22:03:49 [INFO]: Epoch 009 - training loss: 0.4421, validation loss: 0.3969
2024-05-23 22:03:49 [INFO]: Epoch 010 - training loss: 0.4186, validation loss: 0.3987
2024-05-23 22:03:50 [INFO]: Epoch 011 - training loss: 0.4013, validation loss: 0.3910
2024-05-23 22:03:50 [INFO]: Epoch 012 - training loss: 0.4001, validation loss: 0.3908
2024-05-23 22:03:51 [INFO]: Epoch 013 - training loss: 0.3861, validation loss: 0.3827
2024-05-23 22:03:52 [INFO]: Epoch 014 - training loss: 0.3744, validation loss: 0.3740
2024-05-23 22:03:52 [INFO]: Epoch 015 - training loss: 0.3618, validation loss: 0.3732
2024-05-23 22:03:53 [INFO]: Epoch 016 - training loss: 0.3601, validation loss: 0.3737
2024-05-23 22:03:53 [INFO]: Epoch 017 - training loss: 0.3450, validation loss: 0.3680
2024-05-23 22:03:54 [INFO]: Epoch 018 - training loss: 0.3386, validation loss: 0.3707
2024-05-23 22:03:54 [INFO]: Epoch 019 - training loss: 0.3334, validation loss: 0.3653
2024-05-23 22:03:55 [INFO]: Epoch 020 - training loss: 0.3217, validation loss: 0.3626
2024-05-23 22:03:56 [INFO]: Epoch 021 - training loss: 0.3111, validation loss: 0.3619
2024-05-23 22:03:56 [INFO]: Epoch 022 - training loss: 0.3055, validation loss: 0.3624
2024-05-23 22:03:57 [INFO]: Epoch 023 - training loss: 0.2987, validation loss: 0.3582
2024-05-23 22:03:57 [INFO]: Epoch 024 - training loss: 0.2979, validation loss: 0.3587
2024-05-23 22:03:58 [INFO]: Epoch 025 - training loss: 0.2909, validation loss: 0.3592
2024-05-23 22:03:59 [INFO]: Epoch 026 - training loss: 0.2847, validation loss: 0.3546
2024-05-23 22:03:59 [INFO]: Epoch 027 - training loss: 0.2783, validation loss: 0.3590
2024-05-23 22:04:00 [INFO]: Epoch 028 - training loss: 0.2772, validation loss: 0.3538
2024-05-23 22:04:00 [INFO]: Epoch 029 - training loss: 0.2697, validation loss: 0.3520
2024-05-23 22:04:01 [INFO]: Epoch 030 - training loss: 0.2674, validation loss: 0.3535
2024-05-23 22:04:02 [INFO]: Epoch 031 - training loss: 0.2671, validation loss: 0.3542
2024-05-23 22:04:02 [INFO]: Epoch 032 - training loss: 0.2622, validation loss: 0.3506
2024-05-23 22:04:03 [INFO]: Epoch 033 - training loss: 0.2547, validation loss: 0.3530
2024-05-23 22:04:03 [INFO]: Epoch 034 - training loss: 0.2518, validation loss: 0.3531
2024-05-23 22:04:04 [INFO]: Epoch 035 - training loss: 0.2516, validation loss: 0.3570
2024-05-23 22:04:04 [INFO]: Epoch 036 - training loss: 0.2482, validation loss: 0.3574
2024-05-23 22:04:05 [INFO]: Epoch 037 - training loss: 0.2461, validation loss: 0.3553
2024-05-23 22:04:06 [INFO]: Epoch 038 - training loss: 0.2367, validation loss: 0.3529
2024-05-23 22:04:06 [INFO]: Epoch 039 - training loss: 0.2338, validation loss: 0.3525
2024-05-23 22:04:07 [INFO]: Epoch 040 - training loss: 0.2304, validation loss: 0.3528
2024-05-23 22:04:07 [INFO]: Epoch 041 - training loss: 0.2310, validation loss: 0.3561
2024-05-23 22:04:08 [INFO]: Epoch 042 - training loss: 0.2276, validation loss: 0.3561
2024-05-23 22:04:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:04:08 [INFO]: Finished training. The best model is from epoch#32.
2024-05-23 22:04:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T220343/Transformer.pypots
2024-05-23 22:04:08 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2859, MSE=0.3071
2024-05-23 22:04:08 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 22:04:08 [INFO]: Using the given device: cuda:0
2024-05-23 22:04:08 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T220408
2024-05-23 22:04:08 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T220408/tensorboard
2024-05-23 22:04:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 22:04:09 [INFO]: Epoch 001 - training loss: 0.4160, validation loss: 1.4551
2024-05-23 22:04:10 [INFO]: Epoch 002 - training loss: 0.5416, validation loss: 0.7841
2024-05-23 22:04:11 [INFO]: Epoch 003 - training loss: 0.4405, validation loss: 0.6677
2024-05-23 22:04:11 [INFO]: Epoch 004 - training loss: 0.3931, validation loss: 0.3647
2024-05-23 22:04:12 [INFO]: Epoch 005 - training loss: 0.4038, validation loss: 0.4446
2024-05-23 22:04:13 [INFO]: Epoch 006 - training loss: 0.3329, validation loss: 0.3226
2024-05-23 22:04:13 [INFO]: Epoch 007 - training loss: 0.3074, validation loss: 0.3291
2024-05-23 22:04:14 [INFO]: Epoch 008 - training loss: 0.2991, validation loss: 0.3074
2024-05-23 22:04:15 [INFO]: Epoch 009 - training loss: 0.2869, validation loss: 0.3105
2024-05-23 22:04:15 [INFO]: Epoch 010 - training loss: 0.2838, validation loss: 0.3285
2024-05-23 22:04:16 [INFO]: Epoch 011 - training loss: 0.2838, validation loss: 0.3188
2024-05-23 22:04:17 [INFO]: Epoch 012 - training loss: 0.2785, validation loss: 0.3074
2024-05-23 22:04:18 [INFO]: Epoch 013 - training loss: 0.2697, validation loss: 0.3090
2024-05-23 22:04:18 [INFO]: Epoch 014 - training loss: 0.2659, validation loss: 0.3016
2024-05-23 22:04:19 [INFO]: Epoch 015 - training loss: 0.2618, validation loss: 0.3123
2024-05-23 22:04:20 [INFO]: Epoch 016 - training loss: 0.2547, validation loss: 0.3269
2024-05-23 22:04:20 [INFO]: Epoch 017 - training loss: 0.2661, validation loss: 0.3053
2024-05-23 22:04:21 [INFO]: Epoch 018 - training loss: 0.2460, validation loss: 0.3225
2024-05-23 22:04:22 [INFO]: Epoch 019 - training loss: 0.2535, validation loss: 0.3035
2024-05-23 22:04:23 [INFO]: Epoch 020 - training loss: 0.2393, validation loss: 0.3113
2024-05-23 22:04:23 [INFO]: Epoch 021 - training loss: 0.2324, validation loss: 0.3232
2024-05-23 22:04:24 [INFO]: Epoch 022 - training loss: 0.2312, validation loss: 0.3060
2024-05-23 22:04:25 [INFO]: Epoch 023 - training loss: 0.2280, validation loss: 0.3198
2024-05-23 22:04:25 [INFO]: Epoch 024 - training loss: 0.2196, validation loss: 0.3058
2024-05-23 22:04:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:04:25 [INFO]: Finished training. The best model is from epoch#14.
2024-05-23 22:04:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T220408/TimesNet.pypots
2024-05-23 22:04:26 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2857, MSE=0.2758
2024-05-23 22:04:26 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 22:04:26 [INFO]: Using the given device: cuda:0
2024-05-23 22:04:26 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426
2024-05-23 22:04:26 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/tensorboard
2024-05-23 22:04:26 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 22:05:09 [INFO]: Epoch 001 - training loss: 0.4175, validation loss: 0.3402
2024-05-23 22:05:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch1_loss0.34019370526075365.pypots
2024-05-23 22:05:52 [INFO]: Epoch 002 - training loss: 0.3235, validation loss: 0.3163
2024-05-23 22:05:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch2_loss0.316318978369236.pypots
2024-05-23 22:06:36 [INFO]: Epoch 003 - training loss: 0.3086, validation loss: 0.2778
2024-05-23 22:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch3_loss0.2778166636824608.pypots
2024-05-23 22:07:19 [INFO]: Epoch 004 - training loss: 0.2771, validation loss: 0.2640
2024-05-23 22:07:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch4_loss0.2639727771282196.pypots
2024-05-23 22:08:02 [INFO]: Epoch 005 - training loss: 0.2704, validation loss: 0.2479
2024-05-23 22:08:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch5_loss0.24791861772537233.pypots
2024-05-23 22:08:46 [INFO]: Epoch 006 - training loss: 0.2440, validation loss: 0.2397
2024-05-23 22:08:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch6_loss0.2397004023194313.pypots
2024-05-23 22:09:29 [INFO]: Epoch 007 - training loss: 0.2463, validation loss: 0.2313
2024-05-23 22:09:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch7_loss0.2313324213027954.pypots
2024-05-23 22:10:13 [INFO]: Epoch 008 - training loss: 0.2309, validation loss: 0.2309
2024-05-23 22:10:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch8_loss0.23090190067887306.pypots
2024-05-23 22:10:56 [INFO]: Epoch 009 - training loss: 0.2272, validation loss: 0.2242
2024-05-23 22:10:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch9_loss0.22420375645160676.pypots
2024-05-23 22:11:40 [INFO]: Epoch 010 - training loss: 0.2224, validation loss: 0.2213
2024-05-23 22:11:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch10_loss0.2213195778429508.pypots
2024-05-23 22:12:23 [INFO]: Epoch 011 - training loss: 0.2229, validation loss: 0.2240
2024-05-23 22:12:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch11_loss0.22396236285567284.pypots
2024-05-23 22:13:07 [INFO]: Epoch 012 - training loss: 0.2197, validation loss: 0.2124
2024-05-23 22:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch12_loss0.21239078491926194.pypots
2024-05-23 22:13:50 [INFO]: Epoch 013 - training loss: 0.2209, validation loss: 0.2084
2024-05-23 22:13:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch13_loss0.20837568491697311.pypots
2024-05-23 22:14:34 [INFO]: Epoch 014 - training loss: 0.2106, validation loss: 0.2116
2024-05-23 22:14:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch14_loss0.21156772524118422.pypots
2024-05-23 22:15:18 [INFO]: Epoch 015 - training loss: 0.2201, validation loss: 0.2085
2024-05-23 22:15:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch15_loss0.20849345177412032.pypots
2024-05-23 22:16:01 [INFO]: Epoch 016 - training loss: 0.2091, validation loss: 0.2068
2024-05-23 22:16:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch16_loss0.2068361259996891.pypots
2024-05-23 22:16:45 [INFO]: Epoch 017 - training loss: 0.2149, validation loss: 0.2116
2024-05-23 22:16:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch17_loss0.21156093776226043.pypots
2024-05-23 22:17:28 [INFO]: Epoch 018 - training loss: 0.2079, validation loss: 0.2075
2024-05-23 22:17:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch18_loss0.2074732393026352.pypots
2024-05-23 22:18:12 [INFO]: Epoch 019 - training loss: 0.2266, validation loss: 0.2055
2024-05-23 22:18:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch19_loss0.20548368990421295.pypots
2024-05-23 22:18:55 [INFO]: Epoch 020 - training loss: 0.2172, validation loss: 0.2078
2024-05-23 22:18:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch20_loss0.20781084448099135.pypots
2024-05-23 22:19:39 [INFO]: Epoch 021 - training loss: 0.2179, validation loss: 0.2085
2024-05-23 22:19:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch21_loss0.20847238674759866.pypots
2024-05-23 22:20:23 [INFO]: Epoch 022 - training loss: 0.2122, validation loss: 0.2093
2024-05-23 22:20:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch22_loss0.20931195095181465.pypots
2024-05-23 22:21:06 [INFO]: Epoch 023 - training loss: 0.2050, validation loss: 0.1995
2024-05-23 22:21:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch23_loss0.1995496116578579.pypots
2024-05-23 22:21:50 [INFO]: Epoch 024 - training loss: 0.2077, validation loss: 0.2020
2024-05-23 22:21:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch24_loss0.20199754908680917.pypots
2024-05-23 22:22:33 [INFO]: Epoch 025 - training loss: 0.2047, validation loss: 0.1973
2024-05-23 22:22:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch25_loss0.19727698042988778.pypots
2024-05-23 22:23:17 [INFO]: Epoch 026 - training loss: 0.2033, validation loss: 0.2007
2024-05-23 22:23:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch26_loss0.20066391676664352.pypots
2024-05-23 22:24:01 [INFO]: Epoch 027 - training loss: 0.2007, validation loss: 0.1991
2024-05-23 22:24:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch27_loss0.19907331019639968.pypots
2024-05-23 22:24:45 [INFO]: Epoch 028 - training loss: 0.2023, validation loss: 0.2006
2024-05-23 22:24:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch28_loss0.20060265809297562.pypots
2024-05-23 22:25:28 [INFO]: Epoch 029 - training loss: 0.2074, validation loss: 0.1996
2024-05-23 22:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch29_loss0.19955369606614112.pypots
2024-05-23 22:26:12 [INFO]: Epoch 030 - training loss: 0.2059, validation loss: 0.1959
2024-05-23 22:26:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch30_loss0.1959015689790249.pypots
2024-05-23 22:26:56 [INFO]: Epoch 031 - training loss: 0.2032, validation loss: 0.1968
2024-05-23 22:26:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch31_loss0.1968294635415077.pypots
2024-05-23 22:27:40 [INFO]: Epoch 032 - training loss: 0.2008, validation loss: 0.1967
2024-05-23 22:27:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch32_loss0.19671523794531823.pypots
2024-05-23 22:28:23 [INFO]: Epoch 033 - training loss: 0.2001, validation loss: 0.1953
2024-05-23 22:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch33_loss0.19527774602174758.pypots
2024-05-23 22:29:07 [INFO]: Epoch 034 - training loss: 0.1964, validation loss: 0.1934
2024-05-23 22:29:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch34_loss0.19344712495803834.pypots
2024-05-23 22:29:51 [INFO]: Epoch 035 - training loss: 0.1890, validation loss: 0.1980
2024-05-23 22:29:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch35_loss0.19798694178462029.pypots
2024-05-23 22:30:34 [INFO]: Epoch 036 - training loss: 0.2013, validation loss: 0.1957
2024-05-23 22:30:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch36_loss0.19571807906031607.pypots
2024-05-23 22:31:18 [INFO]: Epoch 037 - training loss: 0.1929, validation loss: 0.1942
2024-05-23 22:31:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch37_loss0.1942171834409237.pypots
2024-05-23 22:32:02 [INFO]: Epoch 038 - training loss: 0.2050, validation loss: 0.1970
2024-05-23 22:32:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch38_loss0.1970053069293499.pypots
2024-05-23 22:32:45 [INFO]: Epoch 039 - training loss: 0.1965, validation loss: 0.1943
2024-05-23 22:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch39_loss0.1943085491657257.pypots
2024-05-23 22:33:29 [INFO]: Epoch 040 - training loss: 0.2085, validation loss: 0.1980
2024-05-23 22:33:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch40_loss0.19804356023669242.pypots
2024-05-23 22:34:13 [INFO]: Epoch 041 - training loss: 0.2013, validation loss: 0.1952
2024-05-23 22:34:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch41_loss0.1951877973973751.pypots
2024-05-23 22:34:56 [INFO]: Epoch 042 - training loss: 0.2069, validation loss: 0.1949
2024-05-23 22:34:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch42_loss0.19489009380340577.pypots
2024-05-23 22:35:40 [INFO]: Epoch 043 - training loss: 0.1951, validation loss: 0.1945
2024-05-23 22:35:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch43_loss0.19452442675828935.pypots
2024-05-23 22:36:24 [INFO]: Epoch 044 - training loss: 0.1985, validation loss: 0.1888
2024-05-23 22:36:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch44_loss0.1888020910322666.pypots
2024-05-23 22:37:08 [INFO]: Epoch 045 - training loss: 0.1973, validation loss: 0.1924
2024-05-23 22:37:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch45_loss0.19244612604379654.pypots
2024-05-23 22:37:51 [INFO]: Epoch 046 - training loss: 0.2081, validation loss: 0.1923
2024-05-23 22:37:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch46_loss0.19231149032711983.pypots
2024-05-23 22:38:35 [INFO]: Epoch 047 - training loss: 0.1841, validation loss: 0.1943
2024-05-23 22:38:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch47_loss0.19429545924067498.pypots
2024-05-23 22:39:19 [INFO]: Epoch 048 - training loss: 0.1970, validation loss: 0.1912
2024-05-23 22:39:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch48_loss0.19122280701994895.pypots
2024-05-23 22:40:03 [INFO]: Epoch 049 - training loss: 0.1974, validation loss: 0.1926
2024-05-23 22:40:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch49_loss0.19264618307352066.pypots
2024-05-23 22:40:47 [INFO]: Epoch 050 - training loss: 0.1888, validation loss: 0.1903
2024-05-23 22:40:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch50_loss0.19026050865650176.pypots
2024-05-23 22:41:31 [INFO]: Epoch 051 - training loss: 0.2064, validation loss: 0.1916
2024-05-23 22:41:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch51_loss0.19160933941602706.pypots
2024-05-23 22:42:15 [INFO]: Epoch 052 - training loss: 0.1976, validation loss: 0.1894
2024-05-23 22:42:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch52_loss0.18936873301863671.pypots
2024-05-23 22:42:59 [INFO]: Epoch 053 - training loss: 0.1943, validation loss: 0.1897
2024-05-23 22:42:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch53_loss0.1896926462650299.pypots
2024-05-23 22:43:43 [INFO]: Epoch 054 - training loss: 0.1944, validation loss: 0.1911
2024-05-23 22:43:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI_epoch54_loss0.19112460166215897.pypots
2024-05-23 22:43:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:43:43 [INFO]: Finished training. The best model is from epoch#44.
2024-05-23 22:43:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T220426/CSDI.pypots
2024-05-23 22:51:04 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2360, MSE=0.2700
2024-05-23 23:20:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 23:20:24 [INFO]: Using the given device: cuda:0
2024-05-23 23:20:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T232024
2024-05-23 23:20:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T232024/tensorboard
2024-05-23 23:20:24 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 23:20:25 [INFO]: Epoch 001 - training loss: 42660.8554, validation loss: 0.9405
2024-05-23 23:20:25 [INFO]: Epoch 002 - training loss: 24413.8874, validation loss: 0.7514
2024-05-23 23:20:26 [INFO]: Epoch 003 - training loss: 23480.8342, validation loss: 0.7342
2024-05-23 23:20:27 [INFO]: Epoch 004 - training loss: 23184.5890, validation loss: 0.7088
2024-05-23 23:20:27 [INFO]: Epoch 005 - training loss: 23036.6753, validation loss: 0.6758
2024-05-23 23:20:28 [INFO]: Epoch 006 - training loss: 22954.0616, validation loss: 0.6704
2024-05-23 23:20:28 [INFO]: Epoch 007 - training loss: 22904.2429, validation loss: 0.6740
2024-05-23 23:20:29 [INFO]: Epoch 008 - training loss: 22873.1634, validation loss: 0.6678
2024-05-23 23:20:29 [INFO]: Epoch 009 - training loss: 22851.4367, validation loss: 0.6647
2024-05-23 23:20:30 [INFO]: Epoch 010 - training loss: 22836.9930, validation loss: 0.6651
2024-05-23 23:20:30 [INFO]: Epoch 011 - training loss: 22826.5754, validation loss: 0.6622
2024-05-23 23:20:31 [INFO]: Epoch 012 - training loss: 22818.5691, validation loss: 0.6611
2024-05-23 23:20:32 [INFO]: Epoch 013 - training loss: 22813.4045, validation loss: 0.6605
2024-05-23 23:20:32 [INFO]: Epoch 014 - training loss: 22808.1508, validation loss: 0.6602
2024-05-23 23:20:33 [INFO]: Epoch 015 - training loss: 22804.5728, validation loss: 0.6546
2024-05-23 23:20:33 [INFO]: Epoch 016 - training loss: 22801.2354, validation loss: 0.6542
2024-05-23 23:20:34 [INFO]: Epoch 017 - training loss: 22798.3533, validation loss: 0.6511
2024-05-23 23:20:34 [INFO]: Epoch 018 - training loss: 22796.0054, validation loss: 0.6477
2024-05-23 23:20:35 [INFO]: Epoch 019 - training loss: 22793.9123, validation loss: 0.6472
2024-05-23 23:20:36 [INFO]: Epoch 020 - training loss: 22792.2101, validation loss: 0.6418
2024-05-23 23:20:36 [INFO]: Epoch 021 - training loss: 22791.2467, validation loss: 0.6391
2024-05-23 23:20:37 [INFO]: Epoch 022 - training loss: 22789.3414, validation loss: 0.6403
2024-05-23 23:20:37 [INFO]: Epoch 023 - training loss: 22787.5648, validation loss: 0.6372
2024-05-23 23:20:38 [INFO]: Epoch 024 - training loss: 22787.1992, validation loss: 0.6345
2024-05-23 23:20:38 [INFO]: Epoch 025 - training loss: 22786.4784, validation loss: 0.6325
2024-05-23 23:20:39 [INFO]: Epoch 026 - training loss: 22785.6474, validation loss: 0.6416
2024-05-23 23:20:39 [INFO]: Epoch 027 - training loss: 22784.8804, validation loss: 0.6317
2024-05-23 23:20:40 [INFO]: Epoch 028 - training loss: 22784.4153, validation loss: 0.6323
2024-05-23 23:20:41 [INFO]: Epoch 029 - training loss: 22783.8931, validation loss: 0.6403
2024-05-23 23:20:41 [INFO]: Epoch 030 - training loss: 22783.1150, validation loss: 0.6299
2024-05-23 23:20:42 [INFO]: Epoch 031 - training loss: 22782.8585, validation loss: 0.6338
2024-05-23 23:20:42 [INFO]: Epoch 032 - training loss: 22782.3128, validation loss: 0.6300
2024-05-23 23:20:43 [INFO]: Epoch 033 - training loss: 22781.8335, validation loss: 0.6278
2024-05-23 23:20:43 [INFO]: Epoch 034 - training loss: 22781.5069, validation loss: 0.6289
2024-05-23 23:20:44 [INFO]: Epoch 035 - training loss: 22781.0238, validation loss: 0.6267
2024-05-23 23:20:44 [INFO]: Epoch 036 - training loss: 22781.0365, validation loss: 0.6288
2024-05-23 23:20:45 [INFO]: Epoch 037 - training loss: 22780.6570, validation loss: 0.6283
2024-05-23 23:20:46 [INFO]: Epoch 038 - training loss: 22779.9085, validation loss: 0.6238
2024-05-23 23:20:46 [INFO]: Epoch 039 - training loss: 22779.3185, validation loss: 0.6231
2024-05-23 23:20:47 [INFO]: Epoch 040 - training loss: 22779.3275, validation loss: 0.6221
2024-05-23 23:20:47 [INFO]: Epoch 041 - training loss: 22777.7108, validation loss: 0.6232
2024-05-23 23:20:48 [INFO]: Epoch 042 - training loss: 22776.8605, validation loss: 0.6269
2024-05-23 23:20:48 [INFO]: Epoch 043 - training loss: 22775.7057, validation loss: 0.6093
2024-05-23 23:20:49 [INFO]: Epoch 044 - training loss: 22774.9818, validation loss: 0.6097
2024-05-23 23:20:50 [INFO]: Epoch 045 - training loss: 22773.8926, validation loss: 0.6030
2024-05-23 23:20:50 [INFO]: Epoch 046 - training loss: 22773.9900, validation loss: 0.5981
2024-05-23 23:20:51 [INFO]: Epoch 047 - training loss: 22772.6227, validation loss: 0.5940
2024-05-23 23:20:51 [INFO]: Epoch 048 - training loss: 22771.5462, validation loss: 0.5920
2024-05-23 23:20:52 [INFO]: Epoch 049 - training loss: 22770.6216, validation loss: 0.5961
2024-05-23 23:20:52 [INFO]: Epoch 050 - training loss: 22770.2437, validation loss: 0.5972
2024-05-23 23:20:53 [INFO]: Epoch 051 - training loss: 22769.5945, validation loss: 0.5893
2024-05-23 23:20:53 [INFO]: Epoch 052 - training loss: 22768.8733, validation loss: 0.5920
2024-05-23 23:20:54 [INFO]: Epoch 053 - training loss: 22768.4704, validation loss: 0.5882
2024-05-23 23:20:55 [INFO]: Epoch 054 - training loss: 22768.0818, validation loss: 0.5881
2024-05-23 23:20:55 [INFO]: Epoch 055 - training loss: 22767.5324, validation loss: 0.5877
2024-05-23 23:20:56 [INFO]: Epoch 056 - training loss: 22767.0793, validation loss: 0.5821
2024-05-23 23:20:56 [INFO]: Epoch 057 - training loss: 22766.8990, validation loss: 0.5844
2024-05-23 23:20:57 [INFO]: Epoch 058 - training loss: 22765.6342, validation loss: 0.5797
2024-05-23 23:20:57 [INFO]: Epoch 059 - training loss: 22764.8943, validation loss: 0.5731
2024-05-23 23:20:58 [INFO]: Epoch 060 - training loss: 22764.2084, validation loss: 0.5678
2024-05-23 23:20:58 [INFO]: Epoch 061 - training loss: 22763.4636, validation loss: 0.5634
2024-05-23 23:20:59 [INFO]: Epoch 062 - training loss: 22762.0434, validation loss: 0.5570
2024-05-23 23:21:00 [INFO]: Epoch 063 - training loss: 22762.3959, validation loss: 0.5577
2024-05-23 23:21:00 [INFO]: Epoch 064 - training loss: 22760.7295, validation loss: 0.5508
2024-05-23 23:21:01 [INFO]: Epoch 065 - training loss: 22760.0588, validation loss: 0.5539
2024-05-23 23:21:01 [INFO]: Epoch 066 - training loss: 22758.9412, validation loss: 0.5449
2024-05-23 23:21:02 [INFO]: Epoch 067 - training loss: 22758.8417, validation loss: 0.5401
2024-05-23 23:21:02 [INFO]: Epoch 068 - training loss: 22757.7184, validation loss: 0.5373
2024-05-23 23:21:03 [INFO]: Epoch 069 - training loss: 22757.9197, validation loss: 0.5391
2024-05-23 23:21:03 [INFO]: Epoch 070 - training loss: 22757.2190, validation loss: 0.5321
2024-05-23 23:21:04 [INFO]: Epoch 071 - training loss: 22756.9570, validation loss: 0.5812
2024-05-23 23:21:05 [INFO]: Epoch 072 - training loss: 22760.4812, validation loss: 0.5334
2024-05-23 23:21:05 [INFO]: Epoch 073 - training loss: 22756.4876, validation loss: 0.5635
2024-05-23 23:21:06 [INFO]: Epoch 074 - training loss: 22759.6934, validation loss: 0.5274
2024-05-23 23:21:06 [INFO]: Epoch 075 - training loss: 22755.5258, validation loss: 0.5444
2024-05-23 23:21:07 [INFO]: Epoch 076 - training loss: 22755.6066, validation loss: 0.5253
2024-05-23 23:21:07 [INFO]: Epoch 077 - training loss: 22754.9818, validation loss: 0.5226
2024-05-23 23:21:08 [INFO]: Epoch 078 - training loss: 22754.0461, validation loss: 0.5258
2024-05-23 23:21:08 [INFO]: Epoch 079 - training loss: 22753.7389, validation loss: 0.5213
2024-05-23 23:21:09 [INFO]: Epoch 080 - training loss: 22753.4152, validation loss: 0.5211
2024-05-23 23:21:10 [INFO]: Epoch 081 - training loss: 22753.3064, validation loss: 0.5222
2024-05-23 23:21:10 [INFO]: Epoch 082 - training loss: 22753.1406, validation loss: 0.5208
2024-05-23 23:21:11 [INFO]: Epoch 083 - training loss: 22753.0273, validation loss: 0.5199
2024-05-23 23:21:12 [INFO]: Epoch 084 - training loss: 22752.6402, validation loss: 0.5221
2024-05-23 23:21:13 [INFO]: Epoch 085 - training loss: 22752.3843, validation loss: 0.5188
2024-05-23 23:21:13 [INFO]: Epoch 086 - training loss: 22752.6389, validation loss: 0.5184
2024-05-23 23:21:14 [INFO]: Epoch 087 - training loss: 22752.7812, validation loss: 0.5150
2024-05-23 23:21:15 [INFO]: Epoch 088 - training loss: 22752.9836, validation loss: 0.5238
2024-05-23 23:21:15 [INFO]: Epoch 089 - training loss: 22752.3302, validation loss: 0.5211
2024-05-23 23:21:16 [INFO]: Epoch 090 - training loss: 22752.7680, validation loss: 0.5178
2024-05-23 23:21:16 [INFO]: Epoch 091 - training loss: 22751.5554, validation loss: 0.5170
2024-05-23 23:21:17 [INFO]: Epoch 092 - training loss: 22751.2867, validation loss: 0.5194
2024-05-23 23:21:17 [INFO]: Epoch 093 - training loss: 22750.9114, validation loss: 0.5116
2024-05-23 23:21:18 [INFO]: Epoch 094 - training loss: 22750.8520, validation loss: 0.5147
2024-05-23 23:21:18 [INFO]: Epoch 095 - training loss: 22751.3863, validation loss: 0.5127
2024-05-23 23:21:19 [INFO]: Epoch 096 - training loss: 22751.1245, validation loss: 0.5153
2024-05-23 23:21:20 [INFO]: Epoch 097 - training loss: 22751.0099, validation loss: 0.5149
2024-05-23 23:21:20 [INFO]: Epoch 098 - training loss: 22750.8328, validation loss: 0.5366
2024-05-23 23:21:21 [INFO]: Epoch 099 - training loss: 22752.6234, validation loss: 0.5131
2024-05-23 23:21:22 [INFO]: Epoch 100 - training loss: 22751.3033, validation loss: 0.5118
2024-05-23 23:21:22 [INFO]: Epoch 101 - training loss: 22750.0063, validation loss: 0.5107
2024-05-23 23:21:23 [INFO]: Epoch 102 - training loss: 22749.4145, validation loss: 0.5119
2024-05-23 23:21:23 [INFO]: Epoch 103 - training loss: 22749.4145, validation loss: 0.5114
2024-05-23 23:21:24 [INFO]: Epoch 104 - training loss: 22749.1436, validation loss: 0.5093
2024-05-23 23:21:24 [INFO]: Epoch 105 - training loss: 22748.9672, validation loss: 0.5073
2024-05-23 23:21:25 [INFO]: Epoch 106 - training loss: 22749.1603, validation loss: 0.5112
2024-05-23 23:21:25 [INFO]: Epoch 107 - training loss: 22748.9310, validation loss: 0.5039
2024-05-23 23:21:26 [INFO]: Epoch 108 - training loss: 22748.7853, validation loss: 0.5062
2024-05-23 23:21:27 [INFO]: Epoch 109 - training loss: 22748.4368, validation loss: 0.5081
2024-05-23 23:21:27 [INFO]: Epoch 110 - training loss: 22748.1883, validation loss: 0.5042
2024-05-23 23:21:28 [INFO]: Epoch 111 - training loss: 22748.3081, validation loss: 0.5044
2024-05-23 23:21:28 [INFO]: Epoch 112 - training loss: 22747.7162, validation loss: 0.5041
2024-05-23 23:21:29 [INFO]: Epoch 113 - training loss: 22747.8424, validation loss: 0.5032
2024-05-23 23:21:29 [INFO]: Epoch 114 - training loss: 22747.7260, validation loss: 0.5048
2024-05-23 23:21:30 [INFO]: Epoch 115 - training loss: 22747.6676, validation loss: 0.5037
2024-05-23 23:21:30 [INFO]: Epoch 116 - training loss: 22749.0989, validation loss: 0.5049
2024-05-23 23:21:31 [INFO]: Epoch 117 - training loss: 22748.8371, validation loss: 0.5125
2024-05-23 23:21:32 [INFO]: Epoch 118 - training loss: 22749.9482, validation loss: 0.5023
2024-05-23 23:21:32 [INFO]: Epoch 119 - training loss: 22748.2254, validation loss: 0.5191
2024-05-23 23:21:33 [INFO]: Epoch 120 - training loss: 22750.2578, validation loss: 0.5003
2024-05-23 23:21:33 [INFO]: Epoch 121 - training loss: 22747.6803, validation loss: 0.5000
2024-05-23 23:21:34 [INFO]: Epoch 122 - training loss: 22746.9143, validation loss: 0.4986
2024-05-23 23:21:34 [INFO]: Epoch 123 - training loss: 22747.0021, validation loss: 0.4984
2024-05-23 23:21:35 [INFO]: Epoch 124 - training loss: 22746.9875, validation loss: 0.4983
2024-05-23 23:21:35 [INFO]: Epoch 125 - training loss: 22746.6943, validation loss: 0.4997
2024-05-23 23:21:36 [INFO]: Epoch 126 - training loss: 22746.4384, validation loss: 0.4965
2024-05-23 23:21:37 [INFO]: Epoch 127 - training loss: 22746.2173, validation loss: 0.4974
2024-05-23 23:21:37 [INFO]: Epoch 128 - training loss: 22746.6307, validation loss: 0.4958
2024-05-23 23:21:38 [INFO]: Epoch 129 - training loss: 22746.4109, validation loss: 0.4960
2024-05-23 23:21:38 [INFO]: Epoch 130 - training loss: 22748.1919, validation loss: 0.4970
2024-05-23 23:21:39 [INFO]: Epoch 131 - training loss: 22747.2619, validation loss: 0.4969
2024-05-23 23:21:39 [INFO]: Epoch 132 - training loss: 22746.2198, validation loss: 0.4967
2024-05-23 23:21:40 [INFO]: Epoch 133 - training loss: 22746.0122, validation loss: 0.4957
2024-05-23 23:21:41 [INFO]: Epoch 134 - training loss: 22746.0175, validation loss: 0.4940
2024-05-23 23:21:41 [INFO]: Epoch 135 - training loss: 22745.9773, validation loss: 0.4962
2024-05-23 23:21:42 [INFO]: Epoch 136 - training loss: 22746.2313, validation loss: 0.4966
2024-05-23 23:21:42 [INFO]: Epoch 137 - training loss: 22746.3452, validation loss: 0.4961
2024-05-23 23:21:43 [INFO]: Epoch 138 - training loss: 22746.5306, validation loss: 0.4980
2024-05-23 23:21:43 [INFO]: Epoch 139 - training loss: 22745.8876, validation loss: 0.4995
2024-05-23 23:21:44 [INFO]: Epoch 140 - training loss: 22746.1686, validation loss: 0.4932
2024-05-23 23:21:44 [INFO]: Epoch 141 - training loss: 22746.4073, validation loss: 0.4926
2024-05-23 23:21:45 [INFO]: Epoch 142 - training loss: 22746.5446, validation loss: 0.4930
2024-05-23 23:21:46 [INFO]: Epoch 143 - training loss: 22745.8336, validation loss: 0.4940
2024-05-23 23:21:46 [INFO]: Epoch 144 - training loss: 22746.1474, validation loss: 0.4900
2024-05-23 23:21:47 [INFO]: Epoch 145 - training loss: 22745.2478, validation loss: 0.4931
2024-05-23 23:21:47 [INFO]: Epoch 146 - training loss: 22745.3326, validation loss: 0.4916
2024-05-23 23:21:48 [INFO]: Epoch 147 - training loss: 22745.5223, validation loss: 0.4927
2024-05-23 23:21:48 [INFO]: Epoch 148 - training loss: 22745.6689, validation loss: 0.4907
2024-05-23 23:21:49 [INFO]: Epoch 149 - training loss: 22745.8223, validation loss: 0.4902
2024-05-23 23:21:49 [INFO]: Epoch 150 - training loss: 22745.6361, validation loss: 0.4894
2024-05-23 23:21:50 [INFO]: Epoch 151 - training loss: 22744.7826, validation loss: 0.4897
2024-05-23 23:21:51 [INFO]: Epoch 152 - training loss: 22744.9048, validation loss: 0.4876
2024-05-23 23:21:51 [INFO]: Epoch 153 - training loss: 22744.7442, validation loss: 0.4858
2024-05-23 23:21:52 [INFO]: Epoch 154 - training loss: 22744.2817, validation loss: 0.4848
2024-05-23 23:21:52 [INFO]: Epoch 155 - training loss: 22744.3498, validation loss: 0.4877
2024-05-23 23:21:53 [INFO]: Epoch 156 - training loss: 22744.2914, validation loss: 0.4852
2024-05-23 23:21:53 [INFO]: Epoch 157 - training loss: 22744.2126, validation loss: 0.4845
2024-05-23 23:21:54 [INFO]: Epoch 158 - training loss: 22744.5425, validation loss: 0.4821
2024-05-23 23:21:54 [INFO]: Epoch 159 - training loss: 22744.6450, validation loss: 0.4825
2024-05-23 23:21:55 [INFO]: Epoch 160 - training loss: 22744.0807, validation loss: 0.4912
2024-05-23 23:21:56 [INFO]: Epoch 161 - training loss: 22744.4662, validation loss: 0.4835
2024-05-23 23:21:56 [INFO]: Epoch 162 - training loss: 22744.6300, validation loss: 0.4811
2024-05-23 23:21:57 [INFO]: Epoch 163 - training loss: 22744.3948, validation loss: 0.4811
2024-05-23 23:21:57 [INFO]: Epoch 164 - training loss: 22743.9451, validation loss: 0.4775
2024-05-23 23:21:58 [INFO]: Epoch 165 - training loss: 22743.6780, validation loss: 0.4798
2024-05-23 23:21:58 [INFO]: Epoch 166 - training loss: 22743.6924, validation loss: 0.4767
2024-05-23 23:21:59 [INFO]: Epoch 167 - training loss: 22743.7731, validation loss: 0.4794
2024-05-23 23:22:00 [INFO]: Epoch 168 - training loss: 22743.5471, validation loss: 0.4770
2024-05-23 23:22:00 [INFO]: Epoch 169 - training loss: 22743.5818, validation loss: 0.4829
2024-05-23 23:22:01 [INFO]: Epoch 170 - training loss: 22743.4964, validation loss: 0.4754
2024-05-23 23:22:01 [INFO]: Epoch 171 - training loss: 22743.2985, validation loss: 0.4762
2024-05-23 23:22:02 [INFO]: Epoch 172 - training loss: 22743.0345, validation loss: 0.4728
2024-05-23 23:22:02 [INFO]: Epoch 173 - training loss: 22743.0794, validation loss: 0.4742
2024-05-23 23:22:03 [INFO]: Epoch 174 - training loss: 22742.8610, validation loss: 0.4771
2024-05-23 23:22:04 [INFO]: Epoch 175 - training loss: 22742.3938, validation loss: 0.4783
2024-05-23 23:22:04 [INFO]: Epoch 176 - training loss: 22742.2049, validation loss: 0.4717
2024-05-23 23:22:05 [INFO]: Epoch 177 - training loss: 22742.5315, validation loss: 0.4730
2024-05-23 23:22:05 [INFO]: Epoch 178 - training loss: 22742.0014, validation loss: 0.4707
2024-05-23 23:22:06 [INFO]: Epoch 179 - training loss: 22742.3112, validation loss: 0.4701
2024-05-23 23:22:06 [INFO]: Epoch 180 - training loss: 22742.9537, validation loss: 0.4738
2024-05-23 23:22:07 [INFO]: Epoch 181 - training loss: 22743.0870, validation loss: 0.4714
2024-05-23 23:22:08 [INFO]: Epoch 182 - training loss: 22743.4189, validation loss: 0.4762
2024-05-23 23:22:08 [INFO]: Epoch 183 - training loss: 22742.7864, validation loss: 0.4709
2024-05-23 23:22:09 [INFO]: Epoch 184 - training loss: 22742.6197, validation loss: 0.4754
2024-05-23 23:22:09 [INFO]: Epoch 185 - training loss: 22742.9207, validation loss: 0.4685
2024-05-23 23:22:10 [INFO]: Epoch 186 - training loss: 22741.9354, validation loss: 0.4710
2024-05-23 23:22:10 [INFO]: Epoch 187 - training loss: 22741.5822, validation loss: 0.4667
2024-05-23 23:22:11 [INFO]: Epoch 188 - training loss: 22741.6350, validation loss: 0.4718
2024-05-23 23:22:12 [INFO]: Epoch 189 - training loss: 22742.2499, validation loss: 0.4691
2024-05-23 23:22:12 [INFO]: Epoch 190 - training loss: 22741.5044, validation loss: 0.4697
2024-05-23 23:22:13 [INFO]: Epoch 191 - training loss: 22741.5479, validation loss: 0.4673
2024-05-23 23:22:13 [INFO]: Epoch 192 - training loss: 22741.0625, validation loss: 0.4684
2024-05-23 23:22:14 [INFO]: Epoch 193 - training loss: 22740.8095, validation loss: 0.4715
2024-05-23 23:22:14 [INFO]: Epoch 194 - training loss: 22740.9220, validation loss: 0.4662
2024-05-23 23:22:15 [INFO]: Epoch 195 - training loss: 22741.6220, validation loss: 0.4659
2024-05-23 23:22:16 [INFO]: Epoch 196 - training loss: 22741.8826, validation loss: 0.4685
2024-05-23 23:22:16 [INFO]: Epoch 197 - training loss: 22741.0408, validation loss: 0.4656
2024-05-23 23:22:17 [INFO]: Epoch 198 - training loss: 22741.0572, validation loss: 0.4724
2024-05-23 23:22:17 [INFO]: Epoch 199 - training loss: 22741.4916, validation loss: 0.4674
2024-05-23 23:22:18 [INFO]: Epoch 200 - training loss: 22741.1521, validation loss: 0.4716
2024-05-23 23:22:18 [INFO]: Epoch 201 - training loss: 22740.6678, validation loss: 0.4698
2024-05-23 23:22:19 [INFO]: Epoch 202 - training loss: 22740.3393, validation loss: 0.4734
2024-05-23 23:22:20 [INFO]: Epoch 203 - training loss: 22740.1866, validation loss: 0.4694
2024-05-23 23:22:20 [INFO]: Epoch 204 - training loss: 22740.4782, validation loss: 0.4764
2024-05-23 23:22:21 [INFO]: Epoch 205 - training loss: 22741.8772, validation loss: 0.4652
2024-05-23 23:22:21 [INFO]: Epoch 206 - training loss: 22740.8471, validation loss: 0.4645
2024-05-23 23:22:22 [INFO]: Epoch 207 - training loss: 22740.8108, validation loss: 0.4648
2024-05-23 23:22:22 [INFO]: Epoch 208 - training loss: 22740.0186, validation loss: 0.4690
2024-05-23 23:22:23 [INFO]: Epoch 209 - training loss: 22739.6686, validation loss: 0.4684
2024-05-23 23:22:24 [INFO]: Epoch 210 - training loss: 22739.4287, validation loss: 0.4695
2024-05-23 23:22:24 [INFO]: Epoch 211 - training loss: 22739.4171, validation loss: 0.4710
2024-05-23 23:22:25 [INFO]: Epoch 212 - training loss: 22739.3164, validation loss: 0.4737
2024-05-23 23:22:25 [INFO]: Epoch 213 - training loss: 22739.5030, validation loss: 0.4720
2024-05-23 23:22:26 [INFO]: Epoch 214 - training loss: 22739.3160, validation loss: 0.4738
2024-05-23 23:22:26 [INFO]: Epoch 215 - training loss: 22739.8171, validation loss: 0.4737
2024-05-23 23:22:27 [INFO]: Epoch 216 - training loss: 22738.9289, validation loss: 0.4767
2024-05-23 23:22:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:22:27 [INFO]: Finished training. The best model is from epoch#206.
2024-05-23 23:22:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T232024/GPVAE.pypots
2024-05-23 23:22:27 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4008, MSE=0.4022
2024-05-23 23:22:27 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 23:22:27 [INFO]: Using the given device: cuda:0
2024-05-23 23:22:27 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T232227
2024-05-23 23:22:27 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T232227/tensorboard
2024-05-23 23:22:28 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 23:22:49 [INFO]: Epoch 001 - generator training loss: 0.5984, discriminator training loss: 0.3811, validation loss: 0.6383
2024-05-23 23:23:07 [INFO]: Epoch 002 - generator training loss: 0.4819, discriminator training loss: 0.2714, validation loss: 0.5459
2024-05-23 23:23:25 [INFO]: Epoch 003 - generator training loss: 0.4333, discriminator training loss: 0.2357, validation loss: 0.5231
2024-05-23 23:23:44 [INFO]: Epoch 004 - generator training loss: 0.4418, discriminator training loss: 0.1878, validation loss: 0.5238
2024-05-23 23:24:02 [INFO]: Epoch 005 - generator training loss: 0.4453, discriminator training loss: 0.1576, validation loss: 0.5026
2024-05-23 23:24:20 [INFO]: Epoch 006 - generator training loss: 0.4386, discriminator training loss: 0.1390, validation loss: 0.4934
2024-05-23 23:24:39 [INFO]: Epoch 007 - generator training loss: 0.4249, discriminator training loss: 0.1247, validation loss: 0.4749
2024-05-23 23:24:57 [INFO]: Epoch 008 - generator training loss: 0.4104, discriminator training loss: 0.1142, validation loss: 0.4671
2024-05-23 23:25:15 [INFO]: Epoch 009 - generator training loss: 0.4009, discriminator training loss: 0.1058, validation loss: 0.4572
2024-05-23 23:25:33 [INFO]: Epoch 010 - generator training loss: 0.3917, discriminator training loss: 0.0989, validation loss: 0.4511
2024-05-23 23:25:52 [INFO]: Epoch 011 - generator training loss: 0.3857, discriminator training loss: 0.0929, validation loss: 0.4452
2024-05-23 23:26:10 [INFO]: Epoch 012 - generator training loss: 0.3801, discriminator training loss: 0.0876, validation loss: 0.4373
2024-05-23 23:26:28 [INFO]: Epoch 013 - generator training loss: 0.3766, discriminator training loss: 0.0832, validation loss: 0.4323
2024-05-23 23:26:47 [INFO]: Epoch 014 - generator training loss: 0.3680, discriminator training loss: 0.0791, validation loss: 0.4255
2024-05-23 23:27:05 [INFO]: Epoch 015 - generator training loss: 0.3645, discriminator training loss: 0.0756, validation loss: 0.4214
2024-05-23 23:27:23 [INFO]: Epoch 016 - generator training loss: 0.3603, discriminator training loss: 0.0725, validation loss: 0.4173
2024-05-23 23:27:41 [INFO]: Epoch 017 - generator training loss: 0.3547, discriminator training loss: 0.0697, validation loss: 0.4161
2024-05-23 23:28:00 [INFO]: Epoch 018 - generator training loss: 0.3522, discriminator training loss: 0.0671, validation loss: 0.4106
2024-05-23 23:28:18 [INFO]: Epoch 019 - generator training loss: 0.3482, discriminator training loss: 0.0648, validation loss: 0.4072
2024-05-23 23:28:36 [INFO]: Epoch 020 - generator training loss: 0.3453, discriminator training loss: 0.0626, validation loss: 0.4034
2024-05-23 23:28:55 [INFO]: Epoch 021 - generator training loss: 0.3412, discriminator training loss: 0.0606, validation loss: 0.4019
2024-05-23 23:29:13 [INFO]: Epoch 022 - generator training loss: 0.3378, discriminator training loss: 0.0588, validation loss: 0.3980
2024-05-23 23:29:31 [INFO]: Epoch 023 - generator training loss: 0.3347, discriminator training loss: 0.0575, validation loss: 0.3978
2024-05-23 23:29:49 [INFO]: Epoch 024 - generator training loss: 0.3312, discriminator training loss: 0.0560, validation loss: 0.3942
2024-05-23 23:30:08 [INFO]: Epoch 025 - generator training loss: 0.3263, discriminator training loss: 0.0548, validation loss: 0.3955
2024-05-23 23:30:26 [INFO]: Epoch 026 - generator training loss: 0.3235, discriminator training loss: 0.0537, validation loss: 0.3884
2024-05-23 23:30:44 [INFO]: Epoch 027 - generator training loss: 0.3215, discriminator training loss: 0.0529, validation loss: 0.3892
2024-05-23 23:31:03 [INFO]: Epoch 028 - generator training loss: 0.3186, discriminator training loss: 0.0518, validation loss: 0.3866
2024-05-23 23:31:21 [INFO]: Epoch 029 - generator training loss: 0.3138, discriminator training loss: 0.0511, validation loss: 0.3850
2024-05-23 23:31:39 [INFO]: Epoch 030 - generator training loss: 0.3119, discriminator training loss: 0.0505, validation loss: 0.3819
2024-05-23 23:31:57 [INFO]: Epoch 031 - generator training loss: 0.3066, discriminator training loss: 0.0498, validation loss: 0.3764
2024-05-23 23:32:16 [INFO]: Epoch 032 - generator training loss: 0.3016, discriminator training loss: 0.0493, validation loss: 0.3762
2024-05-23 23:32:34 [INFO]: Epoch 033 - generator training loss: 0.3031, discriminator training loss: 0.0486, validation loss: 0.3800
2024-05-23 23:32:52 [INFO]: Epoch 034 - generator training loss: 0.3063, discriminator training loss: 0.0481, validation loss: 0.3763
2024-05-23 23:33:11 [INFO]: Epoch 035 - generator training loss: 0.2968, discriminator training loss: 0.0476, validation loss: 0.3734
2024-05-23 23:33:29 [INFO]: Epoch 036 - generator training loss: 0.2934, discriminator training loss: 0.0472, validation loss: 0.3729
2024-05-23 23:33:47 [INFO]: Epoch 037 - generator training loss: 0.2882, discriminator training loss: 0.0468, validation loss: 0.3684
2024-05-23 23:34:05 [INFO]: Epoch 038 - generator training loss: 0.2828, discriminator training loss: 0.0464, validation loss: 0.3634
2024-05-23 23:34:24 [INFO]: Epoch 039 - generator training loss: 0.2829, discriminator training loss: 0.0458, validation loss: 0.3699
2024-05-23 23:34:42 [INFO]: Epoch 040 - generator training loss: 0.2891, discriminator training loss: 0.0457, validation loss: 0.3644
2024-05-23 23:35:00 [INFO]: Epoch 041 - generator training loss: 0.2790, discriminator training loss: 0.0451, validation loss: 0.3627
2024-05-23 23:35:19 [INFO]: Epoch 042 - generator training loss: 0.2744, discriminator training loss: 0.0451, validation loss: 0.3616
2024-05-23 23:35:37 [INFO]: Epoch 043 - generator training loss: 0.2701, discriminator training loss: 0.0447, validation loss: 0.3610
2024-05-23 23:35:55 [INFO]: Epoch 044 - generator training loss: 0.2678, discriminator training loss: 0.0444, validation loss: 0.3598
2024-05-23 23:36:14 [INFO]: Epoch 045 - generator training loss: 0.2677, discriminator training loss: 0.0443, validation loss: 0.3616
2024-05-23 23:36:32 [INFO]: Epoch 046 - generator training loss: 0.2640, discriminator training loss: 0.0438, validation loss: 0.3609
2024-05-23 23:36:50 [INFO]: Epoch 047 - generator training loss: 0.2608, discriminator training loss: 0.0437, validation loss: 0.3573
2024-05-23 23:37:09 [INFO]: Epoch 048 - generator training loss: 0.2569, discriminator training loss: 0.0436, validation loss: 0.3578
2024-05-23 23:37:27 [INFO]: Epoch 049 - generator training loss: 0.2545, discriminator training loss: 0.0434, validation loss: 0.3543
2024-05-23 23:37:45 [INFO]: Epoch 050 - generator training loss: 0.2541, discriminator training loss: 0.0434, validation loss: 0.3534
2024-05-23 23:38:03 [INFO]: Epoch 051 - generator training loss: 0.2540, discriminator training loss: 0.0431, validation loss: 0.3534
2024-05-23 23:38:22 [INFO]: Epoch 052 - generator training loss: 0.2497, discriminator training loss: 0.0431, validation loss: 0.3554
2024-05-23 23:38:40 [INFO]: Epoch 053 - generator training loss: 0.2485, discriminator training loss: 0.0428, validation loss: 0.3553
2024-05-23 23:38:58 [INFO]: Epoch 054 - generator training loss: 0.2430, discriminator training loss: 0.0428, validation loss: 0.3522
2024-05-23 23:39:17 [INFO]: Epoch 055 - generator training loss: 0.2386, discriminator training loss: 0.0427, validation loss: 0.3518
2024-05-23 23:39:35 [INFO]: Epoch 056 - generator training loss: 0.2370, discriminator training loss: 0.0427, validation loss: 0.3483
2024-05-23 23:39:53 [INFO]: Epoch 057 - generator training loss: 0.2362, discriminator training loss: 0.0424, validation loss: 0.3493
2024-05-23 23:40:11 [INFO]: Epoch 058 - generator training loss: 0.2370, discriminator training loss: 0.0424, validation loss: 0.3562
2024-05-23 23:40:30 [INFO]: Epoch 059 - generator training loss: 0.2391, discriminator training loss: 0.0422, validation loss: 0.3440
2024-05-23 23:40:48 [INFO]: Epoch 060 - generator training loss: 0.2418, discriminator training loss: 0.0422, validation loss: 0.3493
2024-05-23 23:41:06 [INFO]: Epoch 061 - generator training loss: 0.2360, discriminator training loss: 0.0419, validation loss: 0.3611
2024-05-23 23:41:25 [INFO]: Epoch 062 - generator training loss: 0.2446, discriminator training loss: 0.0419, validation loss: 0.3502
2024-05-23 23:41:43 [INFO]: Epoch 063 - generator training loss: 0.2279, discriminator training loss: 0.0416, validation loss: 0.3449
2024-05-23 23:42:01 [INFO]: Epoch 064 - generator training loss: 0.2255, discriminator training loss: 0.0415, validation loss: 0.3495
2024-05-23 23:42:19 [INFO]: Epoch 065 - generator training loss: 0.2248, discriminator training loss: 0.0415, validation loss: 0.3446
2024-05-23 23:42:38 [INFO]: Epoch 066 - generator training loss: 0.2212, discriminator training loss: 0.0413, validation loss: 0.3498
2024-05-23 23:42:56 [INFO]: Epoch 067 - generator training loss: 0.2195, discriminator training loss: 0.0411, validation loss: 0.3435
2024-05-23 23:43:14 [INFO]: Epoch 068 - generator training loss: 0.2127, discriminator training loss: 0.0410, validation loss: 0.3450
2024-05-23 23:43:32 [INFO]: Epoch 069 - generator training loss: 0.2101, discriminator training loss: 0.0408, validation loss: 0.3420
2024-05-23 23:43:51 [INFO]: Epoch 070 - generator training loss: 0.2076, discriminator training loss: 0.0407, validation loss: 0.3402
2024-05-23 23:44:09 [INFO]: Epoch 071 - generator training loss: 0.2063, discriminator training loss: 0.0406, validation loss: 0.3427
2024-05-23 23:44:27 [INFO]: Epoch 072 - generator training loss: 0.2048, discriminator training loss: 0.0405, validation loss: 0.3460
2024-05-23 23:44:46 [INFO]: Epoch 073 - generator training loss: 0.2074, discriminator training loss: 0.0406, validation loss: 0.3452
2024-05-23 23:45:04 [INFO]: Epoch 074 - generator training loss: 0.2012, discriminator training loss: 0.0404, validation loss: 0.3453
2024-05-23 23:45:22 [INFO]: Epoch 075 - generator training loss: 0.1980, discriminator training loss: 0.0402, validation loss: 0.3456
2024-05-23 23:45:41 [INFO]: Epoch 076 - generator training loss: 0.1970, discriminator training loss: 0.0401, validation loss: 0.3434
2024-05-23 23:45:59 [INFO]: Epoch 077 - generator training loss: 0.1976, discriminator training loss: 0.0399, validation loss: 0.3451
2024-05-23 23:46:17 [INFO]: Epoch 078 - generator training loss: 0.1968, discriminator training loss: 0.0399, validation loss: 0.3457
2024-05-23 23:46:35 [INFO]: Epoch 079 - generator training loss: 0.1921, discriminator training loss: 0.0398, validation loss: 0.3440
2024-05-23 23:46:54 [INFO]: Epoch 080 - generator training loss: 0.1919, discriminator training loss: 0.0396, validation loss: 0.3468
2024-05-23 23:46:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:46:54 [INFO]: Finished training. The best model is from epoch#70.
2024-05-23 23:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T232227/USGAN.pypots
2024-05-23 23:46:56 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2922, MSE=0.2601
2024-05-23 23:47:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 23:47:06 [INFO]: Using the given device: cuda:0
2024-05-23 23:47:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T234706
2024-05-23 23:47:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T234706/tensorboard
2024-05-23 23:47:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 23:47:21 [INFO]: Epoch 001 - training loss: 1.1268, validation loss: 0.5612
2024-05-23 23:47:33 [INFO]: Epoch 002 - training loss: 0.9267, validation loss: 0.4972
2024-05-23 23:47:45 [INFO]: Epoch 003 - training loss: 0.8654, validation loss: 0.4685
2024-05-23 23:47:57 [INFO]: Epoch 004 - training loss: 0.8297, validation loss: 0.4449
2024-05-23 23:48:08 [INFO]: Epoch 005 - training loss: 0.8042, validation loss: 0.4312
2024-05-23 23:48:20 [INFO]: Epoch 006 - training loss: 0.7817, validation loss: 0.4188
2024-05-23 23:48:32 [INFO]: Epoch 007 - training loss: 0.7619, validation loss: 0.4084
2024-05-23 23:48:44 [INFO]: Epoch 008 - training loss: 0.7466, validation loss: 0.3998
2024-05-23 23:48:56 [INFO]: Epoch 009 - training loss: 0.7318, validation loss: 0.3925
2024-05-23 23:49:08 [INFO]: Epoch 010 - training loss: 0.7205, validation loss: 0.3889
2024-05-23 23:49:20 [INFO]: Epoch 011 - training loss: 0.7097, validation loss: 0.3853
2024-05-23 23:49:32 [INFO]: Epoch 012 - training loss: 0.7018, validation loss: 0.3843
2024-05-23 23:49:44 [INFO]: Epoch 013 - training loss: 0.6934, validation loss: 0.3836
2024-05-23 23:49:55 [INFO]: Epoch 014 - training loss: 0.6866, validation loss: 0.3781
2024-05-23 23:50:07 [INFO]: Epoch 015 - training loss: 0.6801, validation loss: 0.3791
2024-05-23 23:50:19 [INFO]: Epoch 016 - training loss: 0.6745, validation loss: 0.3795
2024-05-23 23:50:31 [INFO]: Epoch 017 - training loss: 0.6695, validation loss: 0.3775
2024-05-23 23:50:43 [INFO]: Epoch 018 - training loss: 0.6655, validation loss: 0.3769
2024-05-23 23:50:55 [INFO]: Epoch 019 - training loss: 0.6606, validation loss: 0.3743
2024-05-23 23:51:07 [INFO]: Epoch 020 - training loss: 0.6565, validation loss: 0.3745
2024-05-23 23:51:19 [INFO]: Epoch 021 - training loss: 0.6529, validation loss: 0.3763
2024-05-23 23:51:31 [INFO]: Epoch 022 - training loss: 0.6498, validation loss: 0.3750
2024-05-23 23:51:43 [INFO]: Epoch 023 - training loss: 0.6481, validation loss: 0.3752
2024-05-23 23:51:54 [INFO]: Epoch 024 - training loss: 0.6453, validation loss: 0.3740
2024-05-23 23:52:06 [INFO]: Epoch 025 - training loss: 0.6408, validation loss: 0.3729
2024-05-23 23:52:18 [INFO]: Epoch 026 - training loss: 0.6419, validation loss: 0.3733
2024-05-23 23:52:30 [INFO]: Epoch 027 - training loss: 0.6360, validation loss: 0.3723
2024-05-23 23:52:42 [INFO]: Epoch 028 - training loss: 0.6322, validation loss: 0.3717
2024-05-23 23:52:54 [INFO]: Epoch 029 - training loss: 0.6311, validation loss: 0.3730
2024-05-23 23:53:06 [INFO]: Epoch 030 - training loss: 0.6314, validation loss: 0.3731
2024-05-23 23:53:18 [INFO]: Epoch 031 - training loss: 0.6263, validation loss: 0.3729
2024-05-23 23:53:30 [INFO]: Epoch 032 - training loss: 0.6269, validation loss: 0.3723
2024-05-23 23:53:42 [INFO]: Epoch 033 - training loss: 0.6210, validation loss: 0.3726
2024-05-23 23:53:53 [INFO]: Epoch 034 - training loss: 0.6179, validation loss: 0.3727
2024-05-23 23:54:05 [INFO]: Epoch 035 - training loss: 0.6160, validation loss: 0.3724
2024-05-23 23:54:17 [INFO]: Epoch 036 - training loss: 0.6123, validation loss: 0.3736
2024-05-23 23:54:29 [INFO]: Epoch 037 - training loss: 0.6093, validation loss: 0.3722
2024-05-23 23:54:41 [INFO]: Epoch 038 - training loss: 0.6087, validation loss: 0.3740
2024-05-23 23:54:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:54:41 [INFO]: Finished training. The best model is from epoch#28.
2024-05-23 23:54:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T234706/BRITS.pypots
2024-05-23 23:54:43 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2575, MSE=0.2554
2024-05-23 23:54:53 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 23:54:53 [INFO]: Using the given device: cuda:0
2024-05-23 23:54:53 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453
2024-05-23 23:54:53 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/tensorboard
2024-05-23 23:54:53 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 23:54:59 [INFO]: Epoch 001 - training loss: 1.1147, validation loss: 0.9968
2024-05-23 23:54:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch1_loss0.9967857092618942.pypots
2024-05-23 23:55:02 [INFO]: Epoch 002 - training loss: 0.6910, validation loss: 0.9791
2024-05-23 23:55:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch2_loss0.9791277170181274.pypots
2024-05-23 23:55:04 [INFO]: Epoch 003 - training loss: 0.5945, validation loss: 0.9538
2024-05-23 23:55:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch3_loss0.9537991732358932.pypots
2024-05-23 23:55:07 [INFO]: Epoch 004 - training loss: 0.5485, validation loss: 0.9393
2024-05-23 23:55:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch4_loss0.9393162220716477.pypots
2024-05-23 23:55:10 [INFO]: Epoch 005 - training loss: 0.5237, validation loss: 0.9317
2024-05-23 23:55:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch5_loss0.9317480146884918.pypots
2024-05-23 23:55:13 [INFO]: Epoch 006 - training loss: 0.5024, validation loss: 0.9275
2024-05-23 23:55:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch6_loss0.9274923473596572.pypots
2024-05-23 23:55:15 [INFO]: Epoch 007 - training loss: 0.4910, validation loss: 0.9245
2024-05-23 23:55:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch7_loss0.924486517906189.pypots
2024-05-23 23:55:18 [INFO]: Epoch 008 - training loss: 0.4867, validation loss: 0.9238
2024-05-23 23:55:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch8_loss0.92375747859478.pypots
2024-05-23 23:55:21 [INFO]: Epoch 009 - training loss: 0.4838, validation loss: 0.9220
2024-05-23 23:55:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch9_loss0.9219535797834396.pypots
2024-05-23 23:55:24 [INFO]: Epoch 010 - training loss: 0.4673, validation loss: 0.9222
2024-05-23 23:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch10_loss0.9221890658140183.pypots
2024-05-23 23:55:27 [INFO]: Epoch 011 - training loss: 0.4601, validation loss: 0.9219
2024-05-23 23:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch11_loss0.9219127327203751.pypots
2024-05-23 23:55:29 [INFO]: Epoch 012 - training loss: 0.4563, validation loss: 0.9228
2024-05-23 23:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch12_loss0.9228162944316864.pypots
2024-05-23 23:55:32 [INFO]: Epoch 013 - training loss: 0.4502, validation loss: 0.9248
2024-05-23 23:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch13_loss0.9247619092464447.pypots
2024-05-23 23:55:35 [INFO]: Epoch 014 - training loss: 0.4509, validation loss: 0.9271
2024-05-23 23:55:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch14_loss0.9271429717540741.pypots
2024-05-23 23:55:38 [INFO]: Epoch 015 - training loss: 0.4510, validation loss: 0.9277
2024-05-23 23:55:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch15_loss0.9276821047067643.pypots
2024-05-23 23:55:40 [INFO]: Epoch 016 - training loss: 0.4434, validation loss: 0.9283
2024-05-23 23:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch16_loss0.9282548606395722.pypots
2024-05-23 23:55:43 [INFO]: Epoch 017 - training loss: 0.4413, validation loss: 0.9291
2024-05-23 23:55:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch17_loss0.9290900588035583.pypots
2024-05-23 23:55:46 [INFO]: Epoch 018 - training loss: 0.4413, validation loss: 0.9306
2024-05-23 23:55:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch18_loss0.9306146204471588.pypots
2024-05-23 23:55:49 [INFO]: Epoch 019 - training loss: 0.4331, validation loss: 0.9304
2024-05-23 23:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch19_loss0.9303971081972122.pypots
2024-05-23 23:55:52 [INFO]: Epoch 020 - training loss: 0.4332, validation loss: 0.9311
2024-05-23 23:55:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch20_loss0.9311093658208847.pypots
2024-05-23 23:55:54 [INFO]: Epoch 021 - training loss: 0.4277, validation loss: 0.9323
2024-05-23 23:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN_epoch21_loss0.9323037207126618.pypots
2024-05-23 23:55:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:55:54 [INFO]: Finished training. The best model is from epoch#11.
2024-05-23 23:55:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240523_T235453/MRNN.pypots
2024-05-23 23:55:55 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6866, MSE=0.8979
2024-05-23 23:55:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 23:55:59 [INFO]: Using the given device: cpu
2024-05-23 23:55:59 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4036, MSE=0.5059
2024-05-23 23:56:00 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_physionet_2012_seta".
2024-05-23 23:56:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 23:56:00 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6901, MSE=1.0191
2024-05-23 23:56:00 [INFO]: Successfully created the given path "saved_results/round_2/Median_physionet_2012_seta".
2024-05-23 23:56:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_physionet_2012_seta/imputation.pkl
2024-05-23 23:56:00 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7055, MSE=0.9762
2024-05-23 23:56:00 [INFO]: Successfully created the given path "saved_results/round_2/Mean_physionet_2012_seta".
2024-05-23 23:56:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 23:56:00 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-23 23:56:00 [INFO]: Using the given device: cuda:0
2024-05-23 23:56:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240523_T235600
2024-05-23 23:56:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240523_T235600/tensorboard
2024-05-23 23:56:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 23:56:01 [INFO]: Epoch 001 - training loss: 1.0674, validation loss: 0.5205
2024-05-23 23:56:02 [INFO]: Epoch 002 - training loss: 0.6986, validation loss: 0.4566
2024-05-23 23:56:03 [INFO]: Epoch 003 - training loss: 0.5751, validation loss: 0.4262
2024-05-23 23:56:05 [INFO]: Epoch 004 - training loss: 0.5183, validation loss: 0.4017
2024-05-23 23:56:06 [INFO]: Epoch 005 - training loss: 0.4778, validation loss: 0.3951
2024-05-23 23:56:07 [INFO]: Epoch 006 - training loss: 0.4447, validation loss: 0.3810
2024-05-23 23:56:08 [INFO]: Epoch 007 - training loss: 0.4108, validation loss: 0.3780
2024-05-23 23:56:09 [INFO]: Epoch 008 - training loss: 0.3892, validation loss: 0.3725
2024-05-23 23:56:10 [INFO]: Epoch 009 - training loss: 0.3702, validation loss: 0.3543
2024-05-23 23:56:12 [INFO]: Epoch 010 - training loss: 0.3495, validation loss: 0.3510
2024-05-23 23:56:13 [INFO]: Epoch 011 - training loss: 0.3351, validation loss: 0.3434
2024-05-23 23:56:14 [INFO]: Epoch 012 - training loss: 0.3210, validation loss: 0.3430
2024-05-23 23:56:15 [INFO]: Epoch 013 - training loss: 0.3083, validation loss: 0.3434
2024-05-23 23:56:16 [INFO]: Epoch 014 - training loss: 0.2962, validation loss: 0.3381
2024-05-23 23:56:17 [INFO]: Epoch 015 - training loss: 0.2841, validation loss: 0.3439
2024-05-23 23:56:18 [INFO]: Epoch 016 - training loss: 0.2735, validation loss: 0.3340
2024-05-23 23:56:20 [INFO]: Epoch 017 - training loss: 0.2626, validation loss: 0.3358
2024-05-23 23:56:21 [INFO]: Epoch 018 - training loss: 0.2590, validation loss: 0.3369
2024-05-23 23:56:22 [INFO]: Epoch 019 - training loss: 0.2517, validation loss: 0.3344
2024-05-23 23:56:23 [INFO]: Epoch 020 - training loss: 0.2422, validation loss: 0.3355
2024-05-23 23:56:24 [INFO]: Epoch 021 - training loss: 0.2325, validation loss: 0.3362
2024-05-23 23:56:25 [INFO]: Epoch 022 - training loss: 0.2265, validation loss: 0.3359
2024-05-23 23:56:26 [INFO]: Epoch 023 - training loss: 0.2279, validation loss: 0.3325
2024-05-23 23:56:28 [INFO]: Epoch 024 - training loss: 0.2192, validation loss: 0.3324
2024-05-23 23:56:29 [INFO]: Epoch 025 - training loss: 0.2120, validation loss: 0.3337
2024-05-23 23:56:30 [INFO]: Epoch 026 - training loss: 0.2107, validation loss: 0.3407
2024-05-23 23:56:31 [INFO]: Epoch 027 - training loss: 0.2052, validation loss: 0.3349
2024-05-23 23:56:32 [INFO]: Epoch 028 - training loss: 0.2014, validation loss: 0.3330
2024-05-23 23:56:33 [INFO]: Epoch 029 - training loss: 0.1948, validation loss: 0.3271
2024-05-23 23:56:35 [INFO]: Epoch 030 - training loss: 0.1933, validation loss: 0.3330
2024-05-23 23:56:36 [INFO]: Epoch 031 - training loss: 0.1877, validation loss: 0.3365
2024-05-23 23:56:37 [INFO]: Epoch 032 - training loss: 0.1892, validation loss: 0.3290
2024-05-23 23:56:38 [INFO]: Epoch 033 - training loss: 0.1833, validation loss: 0.3368
2024-05-23 23:56:39 [INFO]: Epoch 034 - training loss: 0.1803, validation loss: 0.3309
2024-05-23 23:56:40 [INFO]: Epoch 035 - training loss: 0.1794, validation loss: 0.3285
2024-05-23 23:56:41 [INFO]: Epoch 036 - training loss: 0.1765, validation loss: 0.3383
2024-05-23 23:56:43 [INFO]: Epoch 037 - training loss: 0.1724, validation loss: 0.3334
2024-05-23 23:56:44 [INFO]: Epoch 038 - training loss: 0.1685, validation loss: 0.3283
2024-05-23 23:56:45 [INFO]: Epoch 039 - training loss: 0.1647, validation loss: 0.3306
2024-05-23 23:56:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:56:45 [INFO]: Finished training. The best model is from epoch#29.
2024-05-23 23:56:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240523_T235600/SAITS.pypots
2024-05-23 23:56:45 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2702, MSE=0.2862
2024-05-23 23:56:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 23:56:45 [INFO]: Using the given device: cuda:0
2024-05-23 23:56:45 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240523_T235645
2024-05-23 23:56:45 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240523_T235645/tensorboard
2024-05-23 23:56:45 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 23:56:46 [INFO]: Epoch 001 - training loss: 1.0736, validation loss: 0.5709
2024-05-23 23:56:47 [INFO]: Epoch 002 - training loss: 0.7100, validation loss: 0.4863
2024-05-23 23:56:47 [INFO]: Epoch 003 - training loss: 0.6148, validation loss: 0.4654
2024-05-23 23:56:48 [INFO]: Epoch 004 - training loss: 0.5722, validation loss: 0.4454
2024-05-23 23:56:48 [INFO]: Epoch 005 - training loss: 0.5316, validation loss: 0.4352
2024-05-23 23:56:49 [INFO]: Epoch 006 - training loss: 0.5011, validation loss: 0.4310
2024-05-23 23:56:50 [INFO]: Epoch 007 - training loss: 0.4781, validation loss: 0.4071
2024-05-23 23:56:50 [INFO]: Epoch 008 - training loss: 0.4520, validation loss: 0.4123
2024-05-23 23:56:51 [INFO]: Epoch 009 - training loss: 0.4338, validation loss: 0.4111
2024-05-23 23:56:51 [INFO]: Epoch 010 - training loss: 0.4250, validation loss: 0.3949
2024-05-23 23:56:52 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.3914
2024-05-23 23:56:53 [INFO]: Epoch 012 - training loss: 0.3887, validation loss: 0.3866
2024-05-23 23:56:53 [INFO]: Epoch 013 - training loss: 0.3854, validation loss: 0.3801
2024-05-23 23:56:54 [INFO]: Epoch 014 - training loss: 0.3675, validation loss: 0.3745
2024-05-23 23:56:54 [INFO]: Epoch 015 - training loss: 0.3616, validation loss: 0.3763
2024-05-23 23:56:55 [INFO]: Epoch 016 - training loss: 0.3563, validation loss: 0.3758
2024-05-23 23:56:56 [INFO]: Epoch 017 - training loss: 0.3503, validation loss: 0.3696
2024-05-23 23:56:56 [INFO]: Epoch 018 - training loss: 0.3374, validation loss: 0.3670
2024-05-23 23:56:57 [INFO]: Epoch 019 - training loss: 0.3270, validation loss: 0.3640
2024-05-23 23:56:57 [INFO]: Epoch 020 - training loss: 0.3173, validation loss: 0.3657
2024-05-23 23:56:58 [INFO]: Epoch 021 - training loss: 0.3116, validation loss: 0.3604
2024-05-23 23:56:58 [INFO]: Epoch 022 - training loss: 0.3114, validation loss: 0.3595
2024-05-23 23:56:59 [INFO]: Epoch 023 - training loss: 0.2992, validation loss: 0.3533
2024-05-23 23:57:00 [INFO]: Epoch 024 - training loss: 0.2955, validation loss: 0.3579
2024-05-23 23:57:00 [INFO]: Epoch 025 - training loss: 0.2896, validation loss: 0.3570
2024-05-23 23:57:01 [INFO]: Epoch 026 - training loss: 0.2853, validation loss: 0.3579
2024-05-23 23:57:01 [INFO]: Epoch 027 - training loss: 0.2767, validation loss: 0.3520
2024-05-23 23:57:02 [INFO]: Epoch 028 - training loss: 0.2748, validation loss: 0.3528
2024-05-23 23:57:03 [INFO]: Epoch 029 - training loss: 0.2710, validation loss: 0.3578
2024-05-23 23:57:03 [INFO]: Epoch 030 - training loss: 0.2678, validation loss: 0.3527
2024-05-23 23:57:04 [INFO]: Epoch 031 - training loss: 0.2600, validation loss: 0.3544
2024-05-23 23:57:04 [INFO]: Epoch 032 - training loss: 0.2582, validation loss: 0.3505
2024-05-23 23:57:05 [INFO]: Epoch 033 - training loss: 0.2544, validation loss: 0.3493
2024-05-23 23:57:06 [INFO]: Epoch 034 - training loss: 0.2505, validation loss: 0.3541
2024-05-23 23:57:06 [INFO]: Epoch 035 - training loss: 0.2510, validation loss: 0.3517
2024-05-23 23:57:07 [INFO]: Epoch 036 - training loss: 0.2459, validation loss: 0.3493
2024-05-23 23:57:07 [INFO]: Epoch 037 - training loss: 0.2446, validation loss: 0.3546
2024-05-23 23:57:08 [INFO]: Epoch 038 - training loss: 0.2361, validation loss: 0.3556
2024-05-23 23:57:09 [INFO]: Epoch 039 - training loss: 0.2333, validation loss: 0.3492
2024-05-23 23:57:09 [INFO]: Epoch 040 - training loss: 0.2337, validation loss: 0.3523
2024-05-23 23:57:10 [INFO]: Epoch 041 - training loss: 0.2286, validation loss: 0.3487
2024-05-23 23:57:10 [INFO]: Epoch 042 - training loss: 0.2250, validation loss: 0.3507
2024-05-23 23:57:11 [INFO]: Epoch 043 - training loss: 0.2219, validation loss: 0.3489
2024-05-23 23:57:11 [INFO]: Epoch 044 - training loss: 0.2210, validation loss: 0.3529
2024-05-23 23:57:12 [INFO]: Epoch 045 - training loss: 0.2177, validation loss: 0.3516
2024-05-23 23:57:13 [INFO]: Epoch 046 - training loss: 0.2151, validation loss: 0.3562
2024-05-23 23:57:13 [INFO]: Epoch 047 - training loss: 0.2195, validation loss: 0.3561
2024-05-23 23:57:14 [INFO]: Epoch 048 - training loss: 0.2116, validation loss: 0.3576
2024-05-23 23:57:14 [INFO]: Epoch 049 - training loss: 0.2080, validation loss: 0.3542
2024-05-23 23:57:15 [INFO]: Epoch 050 - training loss: 0.2058, validation loss: 0.3537
2024-05-23 23:57:16 [INFO]: Epoch 051 - training loss: 0.2036, validation loss: 0.3533
2024-05-23 23:57:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:57:16 [INFO]: Finished training. The best model is from epoch#41.
2024-05-23 23:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240523_T235645/Transformer.pypots
2024-05-23 23:57:16 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2816, MSE=0.2964
2024-05-23 23:57:16 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 23:57:16 [INFO]: Using the given device: cuda:0
2024-05-23 23:57:16 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240523_T235716
2024-05-23 23:57:16 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240523_T235716/tensorboard
2024-05-23 23:57:16 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 23:57:17 [INFO]: Epoch 001 - training loss: 0.4397, validation loss: 1.0411
2024-05-23 23:57:17 [INFO]: Epoch 002 - training loss: 0.5195, validation loss: 0.6600
2024-05-23 23:57:18 [INFO]: Epoch 003 - training loss: 0.4316, validation loss: 0.8457
2024-05-23 23:57:19 [INFO]: Epoch 004 - training loss: 0.4218, validation loss: 0.7625
2024-05-23 23:57:20 [INFO]: Epoch 005 - training loss: 0.3955, validation loss: 0.3414
2024-05-23 23:57:20 [INFO]: Epoch 006 - training loss: 0.3524, validation loss: 0.3383
2024-05-23 23:57:21 [INFO]: Epoch 007 - training loss: 0.3146, validation loss: 0.3298
2024-05-23 23:57:22 [INFO]: Epoch 008 - training loss: 0.3029, validation loss: 0.3178
2024-05-23 23:57:22 [INFO]: Epoch 009 - training loss: 0.2919, validation loss: 0.3197
2024-05-23 23:57:23 [INFO]: Epoch 010 - training loss: 0.2877, validation loss: 0.3104
2024-05-23 23:57:24 [INFO]: Epoch 011 - training loss: 0.2917, validation loss: 0.3269
2024-05-23 23:57:25 [INFO]: Epoch 012 - training loss: 0.2821, validation loss: 0.3177
2024-05-23 23:57:25 [INFO]: Epoch 013 - training loss: 0.2690, validation loss: 0.3259
2024-05-23 23:57:26 [INFO]: Epoch 014 - training loss: 0.2672, validation loss: 0.3439
2024-05-23 23:57:27 [INFO]: Epoch 015 - training loss: 0.2884, validation loss: 0.3095
2024-05-23 23:57:27 [INFO]: Epoch 016 - training loss: 0.2634, validation loss: 0.3173
2024-05-23 23:57:28 [INFO]: Epoch 017 - training loss: 0.2598, validation loss: 0.3099
2024-05-23 23:57:29 [INFO]: Epoch 018 - training loss: 0.2507, validation loss: 0.3295
2024-05-23 23:57:29 [INFO]: Epoch 019 - training loss: 0.2640, validation loss: 0.3082
2024-05-23 23:57:30 [INFO]: Epoch 020 - training loss: 0.2388, validation loss: 0.3144
2024-05-23 23:57:31 [INFO]: Epoch 021 - training loss: 0.2411, validation loss: 0.3175
2024-05-23 23:57:32 [INFO]: Epoch 022 - training loss: 0.2363, validation loss: 0.3255
2024-05-23 23:57:32 [INFO]: Epoch 023 - training loss: 0.2391, validation loss: 0.3125
2024-05-23 23:57:33 [INFO]: Epoch 024 - training loss: 0.2260, validation loss: 0.3173
2024-05-23 23:57:34 [INFO]: Epoch 025 - training loss: 0.2232, validation loss: 0.3291
2024-05-23 23:57:34 [INFO]: Epoch 026 - training loss: 0.2155, validation loss: 0.3264
2024-05-23 23:57:35 [INFO]: Epoch 027 - training loss: 0.2158, validation loss: 0.3180
2024-05-23 23:57:36 [INFO]: Epoch 028 - training loss: 0.2117, validation loss: 0.3216
2024-05-23 23:57:36 [INFO]: Epoch 029 - training loss: 0.2069, validation loss: 0.3289
2024-05-23 23:57:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:57:36 [INFO]: Finished training. The best model is from epoch#19.
2024-05-23 23:57:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240523_T235716/TimesNet.pypots
2024-05-23 23:57:37 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2898, MSE=0.2868
2024-05-23 23:57:37 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 23:57:37 [INFO]: Using the given device: cuda:0
2024-05-23 23:57:37 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737
2024-05-23 23:57:37 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/tensorboard
2024-05-23 23:57:37 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 23:58:20 [INFO]: Epoch 001 - training loss: 0.4284, validation loss: 0.3298
2024-05-23 23:58:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch1_loss0.3297597438097.pypots
2024-05-23 23:59:04 [INFO]: Epoch 002 - training loss: 0.3139, validation loss: 0.2935
2024-05-23 23:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch2_loss0.29352663457393646.pypots
2024-05-23 23:59:47 [INFO]: Epoch 003 - training loss: 0.2766, validation loss: 0.2588
2024-05-23 23:59:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch3_loss0.2587804116308689.pypots
2024-05-24 00:00:30 [INFO]: Epoch 004 - training loss: 0.2794, validation loss: 0.2492
2024-05-24 00:00:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch4_loss0.24920684248209.pypots
2024-05-24 00:01:14 [INFO]: Epoch 005 - training loss: 0.2459, validation loss: 0.2402
2024-05-24 00:01:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch5_loss0.24017712697386742.pypots
2024-05-24 00:01:57 [INFO]: Epoch 006 - training loss: 0.2445, validation loss: 0.2256
2024-05-24 00:01:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch6_loss0.22563563883304597.pypots
2024-05-24 00:02:41 [INFO]: Epoch 007 - training loss: 0.2341, validation loss: 0.2280
2024-05-24 00:02:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch7_loss0.22802097573876381.pypots
2024-05-24 00:03:24 [INFO]: Epoch 008 - training loss: 0.2462, validation loss: 0.2268
2024-05-24 00:03:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch8_loss0.22679950371384622.pypots
2024-05-24 00:04:08 [INFO]: Epoch 009 - training loss: 0.2260, validation loss: 0.2218
2024-05-24 00:04:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch9_loss0.22183296605944633.pypots
2024-05-24 00:04:51 [INFO]: Epoch 010 - training loss: 0.2209, validation loss: 0.2142
2024-05-24 00:04:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch10_loss0.21419433131814003.pypots
2024-05-24 00:05:35 [INFO]: Epoch 011 - training loss: 0.2277, validation loss: 0.2153
2024-05-24 00:05:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch11_loss0.21526339948177337.pypots
2024-05-24 00:06:18 [INFO]: Epoch 012 - training loss: 0.2227, validation loss: 0.2138
2024-05-24 00:06:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch12_loss0.21382115706801413.pypots
2024-05-24 00:07:02 [INFO]: Epoch 013 - training loss: 0.2300, validation loss: 0.2110
2024-05-24 00:07:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch13_loss0.2110437497496605.pypots
2024-05-24 00:07:46 [INFO]: Epoch 014 - training loss: 0.2110, validation loss: 0.2119
2024-05-24 00:07:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch14_loss0.21193382665514945.pypots
2024-05-24 00:08:29 [INFO]: Epoch 015 - training loss: 0.2092, validation loss: 0.2075
2024-05-24 00:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch15_loss0.20752327367663384.pypots
2024-05-24 00:09:13 [INFO]: Epoch 016 - training loss: 0.2125, validation loss: 0.2042
2024-05-24 00:09:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch16_loss0.20423631444573404.pypots
2024-05-24 00:09:57 [INFO]: Epoch 017 - training loss: 0.2185, validation loss: 0.2033
2024-05-24 00:09:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch17_loss0.20332661792635917.pypots
2024-05-24 00:10:40 [INFO]: Epoch 018 - training loss: 0.2150, validation loss: 0.2027
2024-05-24 00:10:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch18_loss0.20273399278521537.pypots
2024-05-24 00:11:24 [INFO]: Epoch 019 - training loss: 0.2084, validation loss: 0.2045
2024-05-24 00:11:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch19_loss0.20452060475945472.pypots
2024-05-24 00:12:07 [INFO]: Epoch 020 - training loss: 0.2063, validation loss: 0.2042
2024-05-24 00:12:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch20_loss0.20418838858604432.pypots
2024-05-24 00:12:51 [INFO]: Epoch 021 - training loss: 0.2038, validation loss: 0.1987
2024-05-24 00:12:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch21_loss0.19870329201221465.pypots
2024-05-24 00:13:35 [INFO]: Epoch 022 - training loss: 0.2077, validation loss: 0.1988
2024-05-24 00:13:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch22_loss0.19879403635859488.pypots
2024-05-24 00:14:18 [INFO]: Epoch 023 - training loss: 0.2054, validation loss: 0.2002
2024-05-24 00:14:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch23_loss0.20019047930836678.pypots
2024-05-24 00:15:02 [INFO]: Epoch 024 - training loss: 0.2075, validation loss: 0.1984
2024-05-24 00:15:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch24_loss0.19835516139864923.pypots
2024-05-24 00:15:46 [INFO]: Epoch 025 - training loss: 0.1960, validation loss: 0.1986
2024-05-24 00:15:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch25_loss0.19861555397510527.pypots
2024-05-24 00:16:29 [INFO]: Epoch 026 - training loss: 0.2042, validation loss: 0.1997
2024-05-24 00:16:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch26_loss0.19971594884991645.pypots
2024-05-24 00:17:13 [INFO]: Epoch 027 - training loss: 0.2138, validation loss: 0.1962
2024-05-24 00:17:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch27_loss0.19617915526032448.pypots
2024-05-24 00:17:57 [INFO]: Epoch 028 - training loss: 0.1943, validation loss: 0.1964
2024-05-24 00:17:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch28_loss0.19641158133745193.pypots
2024-05-24 00:18:40 [INFO]: Epoch 029 - training loss: 0.2051, validation loss: 0.1981
2024-05-24 00:18:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch29_loss0.19808304682374.pypots
2024-05-24 00:19:24 [INFO]: Epoch 030 - training loss: 0.2167, validation loss: 0.2006
2024-05-24 00:19:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch30_loss0.2006068654358387.pypots
2024-05-24 00:20:08 [INFO]: Epoch 031 - training loss: 0.2107, validation loss: 0.1982
2024-05-24 00:20:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch31_loss0.19823589399456978.pypots
2024-05-24 00:20:52 [INFO]: Epoch 032 - training loss: 0.1967, validation loss: 0.1959
2024-05-24 00:20:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch32_loss0.195908872038126.pypots
2024-05-24 00:21:35 [INFO]: Epoch 033 - training loss: 0.2104, validation loss: 0.2015
2024-05-24 00:21:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch33_loss0.201507368683815.pypots
2024-05-24 00:22:19 [INFO]: Epoch 034 - training loss: 0.2124, validation loss: 0.1935
2024-05-24 00:22:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch34_loss0.1934746079146862.pypots
2024-05-24 00:23:03 [INFO]: Epoch 035 - training loss: 0.1934, validation loss: 0.1958
2024-05-24 00:23:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch35_loss0.19579240158200265.pypots
2024-05-24 00:23:47 [INFO]: Epoch 036 - training loss: 0.2053, validation loss: 0.1956
2024-05-24 00:23:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch36_loss0.19555615037679672.pypots
2024-05-24 00:24:30 [INFO]: Epoch 037 - training loss: 0.1991, validation loss: 0.1929
2024-05-24 00:24:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch37_loss0.19289041683077812.pypots
2024-05-24 00:25:14 [INFO]: Epoch 038 - training loss: 0.1936, validation loss: 0.1923
2024-05-24 00:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch38_loss0.19228572100400926.pypots
2024-05-24 00:25:58 [INFO]: Epoch 039 - training loss: 0.1893, validation loss: 0.1922
2024-05-24 00:25:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch39_loss0.1921846278011799.pypots
2024-05-24 00:26:41 [INFO]: Epoch 040 - training loss: 0.1982, validation loss: 0.1921
2024-05-24 00:26:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch40_loss0.19210756719112396.pypots
2024-05-24 00:27:25 [INFO]: Epoch 041 - training loss: 0.1971, validation loss: 0.1957
2024-05-24 00:27:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch41_loss0.19565193355083466.pypots
2024-05-24 00:28:09 [INFO]: Epoch 042 - training loss: 0.2073, validation loss: 0.1968
2024-05-24 00:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch42_loss0.1968450054526329.pypots
2024-05-24 00:28:52 [INFO]: Epoch 043 - training loss: 0.2039, validation loss: 0.1898
2024-05-24 00:28:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch43_loss0.18984534218907356.pypots
2024-05-24 00:29:36 [INFO]: Epoch 044 - training loss: 0.2079, validation loss: 0.1962
2024-05-24 00:29:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch44_loss0.19616782143712044.pypots
2024-05-24 00:30:20 [INFO]: Epoch 045 - training loss: 0.2118, validation loss: 0.1924
2024-05-24 00:30:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch45_loss0.1923530124127865.pypots
2024-05-24 00:31:03 [INFO]: Epoch 046 - training loss: 0.1960, validation loss: 0.1927
2024-05-24 00:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch46_loss0.1926585853099823.pypots
2024-05-24 00:31:47 [INFO]: Epoch 047 - training loss: 0.1952, validation loss: 0.1894
2024-05-24 00:31:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch47_loss0.1894066132605076.pypots
2024-05-24 00:32:30 [INFO]: Epoch 048 - training loss: 0.2000, validation loss: 0.1925
2024-05-24 00:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch48_loss0.19253816604614257.pypots
2024-05-24 00:33:14 [INFO]: Epoch 049 - training loss: 0.2003, validation loss: 0.1942
2024-05-24 00:33:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch49_loss0.19422761276364325.pypots
2024-05-24 00:33:58 [INFO]: Epoch 050 - training loss: 0.1963, validation loss: 0.1895
2024-05-24 00:33:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch50_loss0.18947306722402574.pypots
2024-05-24 00:34:41 [INFO]: Epoch 051 - training loss: 0.1977, validation loss: 0.1954
2024-05-24 00:34:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch51_loss0.1953590527176857.pypots
2024-05-24 00:35:25 [INFO]: Epoch 052 - training loss: 0.1945, validation loss: 0.1872
2024-05-24 00:35:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch52_loss0.18716620951890944.pypots
2024-05-24 00:36:09 [INFO]: Epoch 053 - training loss: 0.1987, validation loss: 0.1897
2024-05-24 00:36:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch53_loss0.18970133513212203.pypots
2024-05-24 00:36:52 [INFO]: Epoch 054 - training loss: 0.1962, validation loss: 0.1912
2024-05-24 00:36:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch54_loss0.1912056416273117.pypots
2024-05-24 00:37:36 [INFO]: Epoch 055 - training loss: 0.1875, validation loss: 0.1915
2024-05-24 00:37:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch55_loss0.19153419360518456.pypots
2024-05-24 00:38:20 [INFO]: Epoch 056 - training loss: 0.1989, validation loss: 0.1910
2024-05-24 00:38:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch56_loss0.19102783054113387.pypots
2024-05-24 00:39:03 [INFO]: Epoch 057 - training loss: 0.1864, validation loss: 0.1917
2024-05-24 00:39:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch57_loss0.19171692430973053.pypots
2024-05-24 00:39:47 [INFO]: Epoch 058 - training loss: 0.1918, validation loss: 0.1872
2024-05-24 00:39:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch58_loss0.18719517737627028.pypots
2024-05-24 00:40:31 [INFO]: Epoch 059 - training loss: 0.1922, validation loss: 0.1885
2024-05-24 00:40:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch59_loss0.18851301893591882.pypots
2024-05-24 00:41:14 [INFO]: Epoch 060 - training loss: 0.1960, validation loss: 0.1882
2024-05-24 00:41:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch60_loss0.1881839632987976.pypots
2024-05-24 00:41:58 [INFO]: Epoch 061 - training loss: 0.1990, validation loss: 0.1892
2024-05-24 00:41:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch61_loss0.18923085331916809.pypots
2024-05-24 00:42:42 [INFO]: Epoch 062 - training loss: 0.1847, validation loss: 0.1938
2024-05-24 00:42:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI_epoch62_loss0.1938102900981903.pypots
2024-05-24 00:42:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:42:42 [INFO]: Finished training. The best model is from epoch#52.
2024-05-24 00:42:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240523_T235737/CSDI.pypots
2024-05-24 00:50:03 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2480, MSE=0.3996
2024-05-24 07:30:31 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 07:34:00 [INFO]: Using the given device: cuda:0
2024-05-24 07:34:01 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400
2024-05-24 07:34:01 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400/tensorboard
2024-05-24 07:34:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 07:34:02 [INFO]: Epoch 001 - training loss: 42981.0941, validation loss: 0.9541
2024-05-24 07:34:03 [INFO]: Epoch 002 - training loss: 24455.0989, validation loss: 0.7615
2024-05-24 07:34:04 [INFO]: Epoch 003 - training loss: 23492.6739, validation loss: 0.7437
2024-05-24 07:34:04 [INFO]: Epoch 004 - training loss: 23193.0312, validation loss: 0.7127
2024-05-24 07:34:05 [INFO]: Epoch 005 - training loss: 23044.8394, validation loss: 0.6794
2024-05-24 07:34:05 [INFO]: Epoch 006 - training loss: 22960.6381, validation loss: 0.6743
2024-05-24 07:34:06 [INFO]: Epoch 007 - training loss: 22909.9054, validation loss: 0.6691
2024-05-24 07:34:07 [INFO]: Epoch 008 - training loss: 22877.3818, validation loss: 0.6687
2024-05-24 07:34:07 [INFO]: Epoch 009 - training loss: 22855.4680, validation loss: 0.6671
2024-05-24 07:34:08 [INFO]: Epoch 010 - training loss: 22840.2834, validation loss: 0.6652
2024-05-24 07:34:08 [INFO]: Epoch 011 - training loss: 22829.0029, validation loss: 0.6655
2024-05-24 07:34:09 [INFO]: Epoch 012 - training loss: 22820.3642, validation loss: 0.6658
2024-05-24 07:34:09 [INFO]: Epoch 013 - training loss: 22814.1502, validation loss: 0.6623
2024-05-24 07:34:10 [INFO]: Epoch 014 - training loss: 22809.1026, validation loss: 0.6592
2024-05-24 07:34:11 [INFO]: Epoch 015 - training loss: 22805.1386, validation loss: 0.6623
2024-05-24 07:34:11 [INFO]: Epoch 016 - training loss: 22802.3050, validation loss: 0.6603
2024-05-24 07:34:12 [INFO]: Epoch 017 - training loss: 22799.2920, validation loss: 0.6578
2024-05-24 07:34:12 [INFO]: Epoch 018 - training loss: 22796.9382, validation loss: 0.6501
2024-05-24 07:34:13 [INFO]: Epoch 019 - training loss: 22794.3821, validation loss: 0.6463
2024-05-24 07:34:13 [INFO]: Epoch 020 - training loss: 22792.6310, validation loss: 0.6426
2024-05-24 07:34:14 [INFO]: Epoch 021 - training loss: 22791.2457, validation loss: 0.6416
2024-05-24 07:34:15 [INFO]: Epoch 022 - training loss: 22789.5157, validation loss: 0.6378
2024-05-24 07:34:15 [INFO]: Epoch 023 - training loss: 22788.7784, validation loss: 0.6369
2024-05-24 07:34:16 [INFO]: Epoch 024 - training loss: 22787.6657, validation loss: 0.6345
2024-05-24 07:34:16 [INFO]: Epoch 025 - training loss: 22786.5568, validation loss: 0.6336
2024-05-24 07:34:17 [INFO]: Epoch 026 - training loss: 22785.6373, validation loss: 0.6412
2024-05-24 07:34:17 [INFO]: Epoch 027 - training loss: 22785.1776, validation loss: 0.6341
2024-05-24 07:34:18 [INFO]: Epoch 028 - training loss: 22784.5641, validation loss: 0.6344
2024-05-24 07:34:19 [INFO]: Epoch 029 - training loss: 22783.4980, validation loss: 0.6471
2024-05-24 07:34:19 [INFO]: Epoch 030 - training loss: 22783.5538, validation loss: 0.6297
2024-05-24 07:34:20 [INFO]: Epoch 031 - training loss: 22782.9510, validation loss: 0.6294
2024-05-24 07:34:20 [INFO]: Epoch 032 - training loss: 22782.1939, validation loss: 0.6273
2024-05-24 07:34:21 [INFO]: Epoch 033 - training loss: 22782.3507, validation loss: 0.6265
2024-05-24 07:34:21 [INFO]: Epoch 034 - training loss: 22782.0648, validation loss: 0.6284
2024-05-24 07:34:22 [INFO]: Epoch 035 - training loss: 22781.3044, validation loss: 0.6256
2024-05-24 07:34:23 [INFO]: Epoch 036 - training loss: 22780.9026, validation loss: 0.6305
2024-05-24 07:34:23 [INFO]: Epoch 037 - training loss: 22780.5822, validation loss: 0.6334
2024-05-24 07:34:24 [INFO]: Epoch 038 - training loss: 22780.6620, validation loss: 0.6268
2024-05-24 07:34:24 [INFO]: Epoch 039 - training loss: 22779.7741, validation loss: 0.6255
2024-05-24 07:34:25 [INFO]: Epoch 040 - training loss: 22779.7005, validation loss: 0.6290
2024-05-24 07:34:25 [INFO]: Epoch 041 - training loss: 22779.4177, validation loss: 0.6212
2024-05-24 07:34:26 [INFO]: Epoch 042 - training loss: 22778.7462, validation loss: 0.6193
2024-05-24 07:34:27 [INFO]: Epoch 043 - training loss: 22777.8445, validation loss: 0.6202
2024-05-24 07:34:27 [INFO]: Epoch 044 - training loss: 22776.9402, validation loss: 0.6176
2024-05-24 07:34:28 [INFO]: Epoch 045 - training loss: 22776.1135, validation loss: 0.6144
2024-05-24 07:34:28 [INFO]: Epoch 046 - training loss: 22774.9448, validation loss: 0.6105
2024-05-24 07:34:29 [INFO]: Epoch 047 - training loss: 22774.1689, validation loss: 0.6079
2024-05-24 07:34:29 [INFO]: Epoch 048 - training loss: 22773.4743, validation loss: 0.6079
2024-05-24 07:34:30 [INFO]: Epoch 049 - training loss: 22772.5528, validation loss: 0.6043
2024-05-24 07:34:31 [INFO]: Epoch 050 - training loss: 22772.1209, validation loss: 0.6032
2024-05-24 07:34:31 [INFO]: Epoch 051 - training loss: 22771.0669, validation loss: 0.5990
2024-05-24 07:34:32 [INFO]: Epoch 052 - training loss: 22770.1875, validation loss: 0.5993
2024-05-24 07:34:32 [INFO]: Epoch 053 - training loss: 22770.7354, validation loss: 0.6072
2024-05-24 07:34:33 [INFO]: Epoch 054 - training loss: 22769.3515, validation loss: 0.5902
2024-05-24 07:34:33 [INFO]: Epoch 055 - training loss: 22768.4858, validation loss: 0.5920
2024-05-24 07:34:34 [INFO]: Epoch 056 - training loss: 22767.7651, validation loss: 0.5887
2024-05-24 07:34:35 [INFO]: Epoch 057 - training loss: 22767.0906, validation loss: 0.5868
2024-05-24 07:34:35 [INFO]: Epoch 058 - training loss: 22766.2813, validation loss: 0.5907
2024-05-24 07:34:36 [INFO]: Epoch 059 - training loss: 22766.0013, validation loss: 0.5850
2024-05-24 07:34:36 [INFO]: Epoch 060 - training loss: 22765.1728, validation loss: 0.5819
2024-05-24 07:34:37 [INFO]: Epoch 061 - training loss: 22764.0972, validation loss: 0.5789
2024-05-24 07:34:37 [INFO]: Epoch 062 - training loss: 22763.3220, validation loss: 0.5775
2024-05-24 07:34:38 [INFO]: Epoch 063 - training loss: 22762.5539, validation loss: 0.5765
2024-05-24 07:34:38 [INFO]: Epoch 064 - training loss: 22762.3409, validation loss: 0.5701
2024-05-24 07:34:39 [INFO]: Epoch 065 - training loss: 22761.3787, validation loss: 0.5684
2024-05-24 07:34:40 [INFO]: Epoch 066 - training loss: 22761.1606, validation loss: 0.5614
2024-05-24 07:34:40 [INFO]: Epoch 067 - training loss: 22761.4317, validation loss: 0.5616
2024-05-24 07:34:41 [INFO]: Epoch 068 - training loss: 22760.6421, validation loss: 0.5611
2024-05-24 07:34:41 [INFO]: Epoch 069 - training loss: 22760.1076, validation loss: 0.5643
2024-05-24 07:34:42 [INFO]: Epoch 070 - training loss: 22760.0113, validation loss: 0.5595
2024-05-24 07:34:42 [INFO]: Epoch 071 - training loss: 22760.0356, validation loss: 0.5543
2024-05-24 07:34:43 [INFO]: Epoch 072 - training loss: 22759.1714, validation loss: 0.5535
2024-05-24 07:34:44 [INFO]: Epoch 073 - training loss: 22758.8260, validation loss: 0.5512
2024-05-24 07:34:44 [INFO]: Epoch 074 - training loss: 22758.3560, validation loss: 0.5485
2024-05-24 07:34:45 [INFO]: Epoch 075 - training loss: 22758.0577, validation loss: 0.5492
2024-05-24 07:34:45 [INFO]: Epoch 076 - training loss: 22757.8284, validation loss: 0.5468
2024-05-24 07:34:46 [INFO]: Epoch 077 - training loss: 22756.8510, validation loss: 0.5673
2024-05-24 07:34:46 [INFO]: Epoch 078 - training loss: 22756.9307, validation loss: 0.5477
2024-05-24 07:34:47 [INFO]: Epoch 079 - training loss: 22758.0300, validation loss: 0.5443
2024-05-24 07:34:48 [INFO]: Epoch 080 - training loss: 22758.7482, validation loss: 0.5470
2024-05-24 07:34:48 [INFO]: Epoch 081 - training loss: 22758.6875, validation loss: 0.5448
2024-05-24 07:34:49 [INFO]: Epoch 082 - training loss: 22757.0677, validation loss: 0.5563
2024-05-24 07:34:49 [INFO]: Epoch 083 - training loss: 22760.7930, validation loss: 0.5390
2024-05-24 07:34:50 [INFO]: Epoch 084 - training loss: 22756.4683, validation loss: 0.5365
2024-05-24 07:34:50 [INFO]: Epoch 085 - training loss: 22755.1465, validation loss: 0.5436
2024-05-24 07:34:51 [INFO]: Epoch 086 - training loss: 22754.8483, validation loss: 0.5356
2024-05-24 07:34:52 [INFO]: Epoch 087 - training loss: 22754.3824, validation loss: 0.5347
2024-05-24 07:34:52 [INFO]: Epoch 088 - training loss: 22754.5322, validation loss: 0.5352
2024-05-24 07:34:53 [INFO]: Epoch 089 - training loss: 22754.0229, validation loss: 0.5371
2024-05-24 07:34:53 [INFO]: Epoch 090 - training loss: 22753.9176, validation loss: 0.5459
2024-05-24 07:34:54 [INFO]: Epoch 091 - training loss: 22753.7934, validation loss: 0.5311
2024-05-24 07:34:54 [INFO]: Epoch 092 - training loss: 22753.4379, validation loss: 0.5305
2024-05-24 07:34:55 [INFO]: Epoch 093 - training loss: 22753.1458, validation loss: 0.5291
2024-05-24 07:34:55 [INFO]: Epoch 094 - training loss: 22752.9953, validation loss: 0.5316
2024-05-24 07:34:56 [INFO]: Epoch 095 - training loss: 22752.6412, validation loss: 0.5388
2024-05-24 07:34:57 [INFO]: Epoch 096 - training loss: 22753.2279, validation loss: 0.5296
2024-05-24 07:34:57 [INFO]: Epoch 097 - training loss: 22753.5561, validation loss: 0.5271
2024-05-24 07:34:58 [INFO]: Epoch 098 - training loss: 22752.1607, validation loss: 0.5289
2024-05-24 07:34:58 [INFO]: Epoch 099 - training loss: 22754.1675, validation loss: 0.5252
2024-05-24 07:34:59 [INFO]: Epoch 100 - training loss: 22752.4391, validation loss: 0.5267
2024-05-24 07:34:59 [INFO]: Epoch 101 - training loss: 22751.6439, validation loss: 0.5242
2024-05-24 07:35:00 [INFO]: Epoch 102 - training loss: 22751.1071, validation loss: 0.5236
2024-05-24 07:35:01 [INFO]: Epoch 103 - training loss: 22750.8522, validation loss: 0.5193
2024-05-24 07:35:01 [INFO]: Epoch 104 - training loss: 22750.8789, validation loss: 0.5190
2024-05-24 07:35:02 [INFO]: Epoch 105 - training loss: 22750.6733, validation loss: 0.5171
2024-05-24 07:35:02 [INFO]: Epoch 106 - training loss: 22750.9404, validation loss: 0.5166
2024-05-24 07:35:03 [INFO]: Epoch 107 - training loss: 22750.1702, validation loss: 0.5142
2024-05-24 07:35:03 [INFO]: Epoch 108 - training loss: 22750.2778, validation loss: 0.5139
2024-05-24 07:35:04 [INFO]: Epoch 109 - training loss: 22750.0442, validation loss: 0.5130
2024-05-24 07:35:05 [INFO]: Epoch 110 - training loss: 22749.6019, validation loss: 0.5099
2024-05-24 07:35:05 [INFO]: Epoch 111 - training loss: 22749.7737, validation loss: 0.5110
2024-05-24 07:35:06 [INFO]: Epoch 112 - training loss: 22749.7605, validation loss: 0.5110
2024-05-24 07:35:06 [INFO]: Epoch 113 - training loss: 22749.1158, validation loss: 0.5118
2024-05-24 07:35:07 [INFO]: Epoch 114 - training loss: 22751.5538, validation loss: 0.5083
2024-05-24 07:35:07 [INFO]: Epoch 115 - training loss: 22750.0552, validation loss: 0.5113
2024-05-24 07:35:08 [INFO]: Epoch 116 - training loss: 22751.1579, validation loss: 0.5082
2024-05-24 07:35:08 [INFO]: Epoch 117 - training loss: 22749.0190, validation loss: 0.5090
2024-05-24 07:35:09 [INFO]: Epoch 118 - training loss: 22748.7218, validation loss: 0.5046
2024-05-24 07:35:10 [INFO]: Epoch 119 - training loss: 22748.1894, validation loss: 0.5026
2024-05-24 07:35:10 [INFO]: Epoch 120 - training loss: 22747.7542, validation loss: 0.5015
2024-05-24 07:35:11 [INFO]: Epoch 121 - training loss: 22747.3346, validation loss: 0.4984
2024-05-24 07:35:11 [INFO]: Epoch 122 - training loss: 22747.0175, validation loss: 0.4982
2024-05-24 07:35:12 [INFO]: Epoch 123 - training loss: 22746.9536, validation loss: 0.4965
2024-05-24 07:35:12 [INFO]: Epoch 124 - training loss: 22746.7436, validation loss: 0.4964
2024-05-24 07:35:13 [INFO]: Epoch 125 - training loss: 22746.5957, validation loss: 0.4973
2024-05-24 07:35:14 [INFO]: Epoch 126 - training loss: 22746.6639, validation loss: 0.4979
2024-05-24 07:35:14 [INFO]: Epoch 127 - training loss: 22746.6786, validation loss: 0.4939
2024-05-24 07:35:15 [INFO]: Epoch 128 - training loss: 22746.8660, validation loss: 0.5014
2024-05-24 07:35:15 [INFO]: Epoch 129 - training loss: 22747.7645, validation loss: 0.4927
2024-05-24 07:35:16 [INFO]: Epoch 130 - training loss: 22746.9212, validation loss: 0.4961
2024-05-24 07:35:16 [INFO]: Epoch 131 - training loss: 22746.3968, validation loss: 0.4935
2024-05-24 07:35:17 [INFO]: Epoch 132 - training loss: 22746.9738, validation loss: 0.4985
2024-05-24 07:35:18 [INFO]: Epoch 133 - training loss: 22747.6806, validation loss: 0.4933
2024-05-24 07:35:18 [INFO]: Epoch 134 - training loss: 22747.5303, validation loss: 0.4985
2024-05-24 07:35:19 [INFO]: Epoch 135 - training loss: 22747.2561, validation loss: 0.4963
2024-05-24 07:35:19 [INFO]: Epoch 136 - training loss: 22746.6959, validation loss: 0.4886
2024-05-24 07:35:20 [INFO]: Epoch 137 - training loss: 22745.7018, validation loss: 0.4940
2024-05-24 07:35:20 [INFO]: Epoch 138 - training loss: 22745.5912, validation loss: 0.4895
2024-05-24 07:35:21 [INFO]: Epoch 139 - training loss: 22745.4891, validation loss: 0.4898
2024-05-24 07:35:22 [INFO]: Epoch 140 - training loss: 22745.4409, validation loss: 0.4892
2024-05-24 07:35:22 [INFO]: Epoch 141 - training loss: 22745.1221, validation loss: 0.4864
2024-05-24 07:35:23 [INFO]: Epoch 142 - training loss: 22745.4926, validation loss: 0.4853
2024-05-24 07:35:23 [INFO]: Epoch 143 - training loss: 22745.4892, validation loss: 0.4867
2024-05-24 07:35:24 [INFO]: Epoch 144 - training loss: 22745.6895, validation loss: 0.4889
2024-05-24 07:35:24 [INFO]: Epoch 145 - training loss: 22744.8206, validation loss: 0.4895
2024-05-24 07:35:25 [INFO]: Epoch 146 - training loss: 22744.8048, validation loss: 0.4860
2024-05-24 07:35:25 [INFO]: Epoch 147 - training loss: 22744.6669, validation loss: 0.4881
2024-05-24 07:35:26 [INFO]: Epoch 148 - training loss: 22744.8091, validation loss: 0.4854
2024-05-24 07:35:27 [INFO]: Epoch 149 - training loss: 22744.5658, validation loss: 0.4877
2024-05-24 07:35:27 [INFO]: Epoch 150 - training loss: 22744.4563, validation loss: 0.4835
2024-05-24 07:35:28 [INFO]: Epoch 151 - training loss: 22744.3405, validation loss: 0.4855
2024-05-24 07:35:28 [INFO]: Epoch 152 - training loss: 22744.2668, validation loss: 0.4833
2024-05-24 07:35:29 [INFO]: Epoch 153 - training loss: 22744.7331, validation loss: 0.4875
2024-05-24 07:35:29 [INFO]: Epoch 154 - training loss: 22744.9475, validation loss: 0.4855
2024-05-24 07:35:30 [INFO]: Epoch 155 - training loss: 22746.4205, validation loss: 0.4854
2024-05-24 07:35:31 [INFO]: Epoch 156 - training loss: 22745.7153, validation loss: 0.4803
2024-05-24 07:35:31 [INFO]: Epoch 157 - training loss: 22744.5937, validation loss: 0.4814
2024-05-24 07:35:32 [INFO]: Epoch 158 - training loss: 22744.1156, validation loss: 0.4815
2024-05-24 07:35:32 [INFO]: Epoch 159 - training loss: 22743.8062, validation loss: 0.4813
2024-05-24 07:35:33 [INFO]: Epoch 160 - training loss: 22744.0912, validation loss: 0.4808
2024-05-24 07:35:33 [INFO]: Epoch 161 - training loss: 22743.7662, validation loss: 0.4814
2024-05-24 07:35:34 [INFO]: Epoch 162 - training loss: 22743.5669, validation loss: 0.4804
2024-05-24 07:35:35 [INFO]: Epoch 163 - training loss: 22743.4610, validation loss: 0.4782
2024-05-24 07:35:35 [INFO]: Epoch 164 - training loss: 22743.3887, validation loss: 0.4766
2024-05-24 07:35:36 [INFO]: Epoch 165 - training loss: 22743.4864, validation loss: 0.4759
2024-05-24 07:35:36 [INFO]: Epoch 166 - training loss: 22743.2167, validation loss: 0.4763
2024-05-24 07:35:37 [INFO]: Epoch 167 - training loss: 22743.3820, validation loss: 0.4813
2024-05-24 07:35:37 [INFO]: Epoch 168 - training loss: 22743.4742, validation loss: 0.4762
2024-05-24 07:35:38 [INFO]: Epoch 169 - training loss: 22743.0617, validation loss: 0.4775
2024-05-24 07:35:39 [INFO]: Epoch 170 - training loss: 22742.9958, validation loss: 0.4702
2024-05-24 07:35:39 [INFO]: Epoch 171 - training loss: 22743.2426, validation loss: 0.4750
2024-05-24 07:35:40 [INFO]: Epoch 172 - training loss: 22742.7502, validation loss: 0.4724
2024-05-24 07:35:40 [INFO]: Epoch 173 - training loss: 22742.7247, validation loss: 0.4749
2024-05-24 07:35:41 [INFO]: Epoch 174 - training loss: 22742.5562, validation loss: 0.4714
2024-05-24 07:35:41 [INFO]: Epoch 175 - training loss: 22743.2091, validation loss: 0.4725
2024-05-24 07:35:42 [INFO]: Epoch 176 - training loss: 22742.6383, validation loss: 0.4714
2024-05-24 07:35:42 [INFO]: Epoch 177 - training loss: 22742.6584, validation loss: 0.4724
2024-05-24 07:35:43 [INFO]: Epoch 178 - training loss: 22742.4948, validation loss: 0.4696
2024-05-24 07:35:44 [INFO]: Epoch 179 - training loss: 22742.2696, validation loss: 0.4710
2024-05-24 07:35:44 [INFO]: Epoch 180 - training loss: 22742.1792, validation loss: 0.4663
2024-05-24 07:35:45 [INFO]: Epoch 181 - training loss: 22741.8326, validation loss: 0.4705
2024-05-24 07:35:45 [INFO]: Epoch 182 - training loss: 22742.0333, validation loss: 0.4665
2024-05-24 07:35:46 [INFO]: Epoch 183 - training loss: 22741.7122, validation loss: 0.4685
2024-05-24 07:35:46 [INFO]: Epoch 184 - training loss: 22742.2290, validation loss: 0.4690
2024-05-24 07:35:47 [INFO]: Epoch 185 - training loss: 22741.9194, validation loss: 0.4679
2024-05-24 07:35:48 [INFO]: Epoch 186 - training loss: 22741.9716, validation loss: 0.4656
2024-05-24 07:35:48 [INFO]: Epoch 187 - training loss: 22741.6780, validation loss: 0.4658
2024-05-24 07:35:49 [INFO]: Epoch 188 - training loss: 22741.3261, validation loss: 0.4672
2024-05-24 07:35:49 [INFO]: Epoch 189 - training loss: 22741.4341, validation loss: 0.4660
2024-05-24 07:35:50 [INFO]: Epoch 190 - training loss: 22741.2693, validation loss: 0.4647
2024-05-24 07:35:50 [INFO]: Epoch 191 - training loss: 22741.1906, validation loss: 0.4677
2024-05-24 07:35:51 [INFO]: Epoch 192 - training loss: 22741.7901, validation loss: 0.4631
2024-05-24 07:35:51 [INFO]: Epoch 193 - training loss: 22740.8230, validation loss: 0.4613
2024-05-24 07:35:52 [INFO]: Epoch 194 - training loss: 22740.7500, validation loss: 0.4620
2024-05-24 07:35:53 [INFO]: Epoch 195 - training loss: 22740.5342, validation loss: 0.4691
2024-05-24 07:35:53 [INFO]: Epoch 196 - training loss: 22740.8438, validation loss: 0.4623
2024-05-24 07:35:54 [INFO]: Epoch 197 - training loss: 22740.6192, validation loss: 0.4639
2024-05-24 07:35:54 [INFO]: Epoch 198 - training loss: 22740.5508, validation loss: 0.4624
2024-05-24 07:35:55 [INFO]: Epoch 199 - training loss: 22741.3209, validation loss: 0.4632
2024-05-24 07:35:55 [INFO]: Epoch 200 - training loss: 22740.5874, validation loss: 0.4624
2024-05-24 07:35:56 [INFO]: Epoch 201 - training loss: 22740.2622, validation loss: 0.4641
2024-05-24 07:35:57 [INFO]: Epoch 202 - training loss: 22739.9181, validation loss: 0.4622
2024-05-24 07:35:57 [INFO]: Epoch 203 - training loss: 22740.1240, validation loss: 0.4599
2024-05-24 07:35:58 [INFO]: Epoch 204 - training loss: 22740.3122, validation loss: 0.4587
2024-05-24 07:35:58 [INFO]: Epoch 205 - training loss: 22740.2829, validation loss: 0.4690
2024-05-24 07:35:59 [INFO]: Epoch 206 - training loss: 22740.2912, validation loss: 0.4609
2024-05-24 07:35:59 [INFO]: Epoch 207 - training loss: 22740.1896, validation loss: 0.4624
2024-05-24 07:36:00 [INFO]: Epoch 208 - training loss: 22739.7361, validation loss: 0.4607
2024-05-24 07:36:01 [INFO]: Epoch 209 - training loss: 22740.0755, validation loss: 0.4594
2024-05-24 07:36:01 [INFO]: Epoch 210 - training loss: 22739.5797, validation loss: 0.4597
2024-05-24 07:36:02 [INFO]: Epoch 211 - training loss: 22739.4219, validation loss: 0.4630
2024-05-24 07:36:02 [INFO]: Epoch 212 - training loss: 22738.9738, validation loss: 0.4596
2024-05-24 07:36:03 [INFO]: Epoch 213 - training loss: 22739.1076, validation loss: 0.4665
2024-05-24 07:36:03 [INFO]: Epoch 214 - training loss: 22740.2503, validation loss: 0.4595
2024-05-24 07:36:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 07:36:03 [INFO]: Finished training. The best model is from epoch#204.
2024-05-24 07:36:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400/GPVAE.pypots
2024-05-24 07:36:04 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.3967, MSE=0.3965
2024-05-24 07:36:04 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 07:36:04 [INFO]: Using the given device: cuda:0
2024-05-24 07:36:04 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073604
2024-05-24 07:36:04 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073604/tensorboard
2024-05-24 07:36:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 07:36:25 [INFO]: Epoch 001 - generator training loss: 0.5805, discriminator training loss: 0.3815, validation loss: 0.6281
2024-05-24 07:36:44 [INFO]: Epoch 002 - generator training loss: 0.4733, discriminator training loss: 0.2708, validation loss: 0.5385
2024-05-24 07:37:02 [INFO]: Epoch 003 - generator training loss: 0.4225, discriminator training loss: 0.2339, validation loss: 0.5177
2024-05-24 07:37:20 [INFO]: Epoch 004 - generator training loss: 0.4410, discriminator training loss: 0.1869, validation loss: 0.5112
2024-05-24 07:37:38 [INFO]: Epoch 005 - generator training loss: 0.4411, discriminator training loss: 0.1584, validation loss: 0.5090
2024-05-24 07:37:57 [INFO]: Epoch 006 - generator training loss: 0.4300, discriminator training loss: 0.1397, validation loss: 0.4959
2024-05-24 07:38:15 [INFO]: Epoch 007 - generator training loss: 0.4167, discriminator training loss: 0.1259, validation loss: 0.4814
2024-05-24 07:38:33 [INFO]: Epoch 008 - generator training loss: 0.4032, discriminator training loss: 0.1153, validation loss: 0.4717
2024-05-24 07:38:52 [INFO]: Epoch 009 - generator training loss: 0.3947, discriminator training loss: 0.1067, validation loss: 0.4584
2024-05-24 07:39:10 [INFO]: Epoch 010 - generator training loss: 0.3854, discriminator training loss: 0.0996, validation loss: 0.4507
2024-05-24 07:39:28 [INFO]: Epoch 011 - generator training loss: 0.3782, discriminator training loss: 0.0938, validation loss: 0.4438
2024-05-24 07:39:46 [INFO]: Epoch 012 - generator training loss: 0.3728, discriminator training loss: 0.0886, validation loss: 0.4356
2024-05-24 07:40:05 [INFO]: Epoch 013 - generator training loss: 0.3676, discriminator training loss: 0.0842, validation loss: 0.4333
2024-05-24 07:40:23 [INFO]: Epoch 014 - generator training loss: 0.3623, discriminator training loss: 0.0802, validation loss: 0.4267
2024-05-24 07:40:41 [INFO]: Epoch 015 - generator training loss: 0.3564, discriminator training loss: 0.0765, validation loss: 0.4187
2024-05-24 07:41:00 [INFO]: Epoch 016 - generator training loss: 0.3534, discriminator training loss: 0.0734, validation loss: 0.4162
2024-05-24 07:41:18 [INFO]: Epoch 017 - generator training loss: 0.3483, discriminator training loss: 0.0706, validation loss: 0.4114
2024-05-24 07:41:36 [INFO]: Epoch 018 - generator training loss: 0.3451, discriminator training loss: 0.0680, validation loss: 0.4055
2024-05-24 07:41:54 [INFO]: Epoch 019 - generator training loss: 0.3406, discriminator training loss: 0.0657, validation loss: 0.4008
2024-05-24 07:42:13 [INFO]: Epoch 020 - generator training loss: 0.3358, discriminator training loss: 0.0634, validation loss: 0.3995
2024-05-24 07:42:31 [INFO]: Epoch 021 - generator training loss: 0.3311, discriminator training loss: 0.0617, validation loss: 0.3969
2024-05-24 07:42:49 [INFO]: Epoch 022 - generator training loss: 0.3277, discriminator training loss: 0.0599, validation loss: 0.3896
2024-05-24 07:43:08 [INFO]: Epoch 023 - generator training loss: 0.3239, discriminator training loss: 0.0584, validation loss: 0.3888
2024-05-24 07:43:26 [INFO]: Epoch 024 - generator training loss: 0.3188, discriminator training loss: 0.0571, validation loss: 0.3853
2024-05-24 07:43:44 [INFO]: Epoch 025 - generator training loss: 0.3114, discriminator training loss: 0.0556, validation loss: 0.3827
2024-05-24 07:44:02 [INFO]: Epoch 026 - generator training loss: 0.3090, discriminator training loss: 0.0546, validation loss: 0.3783
2024-05-24 07:44:21 [INFO]: Epoch 027 - generator training loss: 0.3045, discriminator training loss: 0.0535, validation loss: 0.3764
2024-05-24 07:44:39 [INFO]: Epoch 028 - generator training loss: 0.3040, discriminator training loss: 0.0527, validation loss: 0.3820
2024-05-24 07:44:57 [INFO]: Epoch 029 - generator training loss: 0.3069, discriminator training loss: 0.0519, validation loss: 0.3727
2024-05-24 07:45:16 [INFO]: Epoch 030 - generator training loss: 0.2980, discriminator training loss: 0.0512, validation loss: 0.3678
2024-05-24 07:45:34 [INFO]: Epoch 031 - generator training loss: 0.2994, discriminator training loss: 0.0505, validation loss: 0.3692
2024-05-24 07:45:52 [INFO]: Epoch 032 - generator training loss: 0.2886, discriminator training loss: 0.0497, validation loss: 0.3633
2024-05-24 07:46:10 [INFO]: Epoch 033 - generator training loss: 0.2833, discriminator training loss: 0.0493, validation loss: 0.3574
2024-05-24 07:46:29 [INFO]: Epoch 034 - generator training loss: 0.2783, discriminator training loss: 0.0488, validation loss: 0.3601
2024-05-24 07:46:47 [INFO]: Epoch 035 - generator training loss: 0.2793, discriminator training loss: 0.0481, validation loss: 0.3608
2024-05-24 07:47:05 [INFO]: Epoch 036 - generator training loss: 0.2902, discriminator training loss: 0.0478, validation loss: 0.3530
2024-05-24 07:47:24 [INFO]: Epoch 037 - generator training loss: 0.2802, discriminator training loss: 0.0475, validation loss: 0.3506
2024-05-24 07:47:42 [INFO]: Epoch 038 - generator training loss: 0.2733, discriminator training loss: 0.0470, validation loss: 0.3460
2024-05-24 07:48:00 [INFO]: Epoch 039 - generator training loss: 0.2682, discriminator training loss: 0.0466, validation loss: 0.3524
2024-05-24 07:48:18 [INFO]: Epoch 040 - generator training loss: 0.2651, discriminator training loss: 0.0464, validation loss: 0.3409
2024-05-24 07:48:37 [INFO]: Epoch 041 - generator training loss: 0.2627, discriminator training loss: 0.0459, validation loss: 0.3444
2024-05-24 07:48:55 [INFO]: Epoch 042 - generator training loss: 0.2626, discriminator training loss: 0.0458, validation loss: 0.3426
2024-05-24 07:49:13 [INFO]: Epoch 043 - generator training loss: 0.2591, discriminator training loss: 0.0455, validation loss: 0.3430
2024-05-24 07:49:32 [INFO]: Epoch 044 - generator training loss: 0.2541, discriminator training loss: 0.0451, validation loss: 0.3351
2024-05-24 07:49:50 [INFO]: Epoch 045 - generator training loss: 0.2569, discriminator training loss: 0.0452, validation loss: 0.3424
2024-05-24 07:50:08 [INFO]: Epoch 046 - generator training loss: 0.2509, discriminator training loss: 0.0447, validation loss: 0.3358
2024-05-24 07:50:26 [INFO]: Epoch 047 - generator training loss: 0.2476, discriminator training loss: 0.0447, validation loss: 0.3395
2024-05-24 07:50:45 [INFO]: Epoch 048 - generator training loss: 0.2422, discriminator training loss: 0.0445, validation loss: 0.3348
2024-05-24 07:51:03 [INFO]: Epoch 049 - generator training loss: 0.2409, discriminator training loss: 0.0443, validation loss: 0.3349
2024-05-24 07:51:21 [INFO]: Epoch 050 - generator training loss: 0.2412, discriminator training loss: 0.0442, validation loss: 0.3361
2024-05-24 07:51:40 [INFO]: Epoch 051 - generator training loss: 0.2419, discriminator training loss: 0.0442, validation loss: 0.3360
2024-05-24 07:51:58 [INFO]: Epoch 052 - generator training loss: 0.2346, discriminator training loss: 0.0436, validation loss: 0.3356
2024-05-24 07:52:16 [INFO]: Epoch 053 - generator training loss: 0.2312, discriminator training loss: 0.0437, validation loss: 0.3403
2024-05-24 07:52:34 [INFO]: Epoch 054 - generator training loss: 0.2290, discriminator training loss: 0.0439, validation loss: 0.3337
2024-05-24 07:52:53 [INFO]: Epoch 055 - generator training loss: 0.2279, discriminator training loss: 0.0436, validation loss: 0.3320
2024-05-24 07:53:11 [INFO]: Epoch 056 - generator training loss: 0.2264, discriminator training loss: 0.0435, validation loss: 0.3366
2024-05-24 07:53:29 [INFO]: Epoch 057 - generator training loss: 0.2269, discriminator training loss: 0.0433, validation loss: 0.3360
2024-05-24 07:53:48 [INFO]: Epoch 058 - generator training loss: 0.2241, discriminator training loss: 0.0434, validation loss: 0.3333
2024-05-24 07:54:06 [INFO]: Epoch 059 - generator training loss: 0.2228, discriminator training loss: 0.0430, validation loss: 0.3334
2024-05-24 07:54:24 [INFO]: Epoch 060 - generator training loss: 0.2181, discriminator training loss: 0.0428, validation loss: 0.3318
2024-05-24 07:54:42 [INFO]: Epoch 061 - generator training loss: 0.2266, discriminator training loss: 0.0432, validation loss: 0.3407
2024-05-24 07:55:01 [INFO]: Epoch 062 - generator training loss: 0.2267, discriminator training loss: 0.0429, validation loss: 0.3387
2024-05-24 07:55:19 [INFO]: Epoch 063 - generator training loss: 0.2216, discriminator training loss: 0.0427, validation loss: 0.3375
2024-05-24 07:55:38 [INFO]: Epoch 064 - generator training loss: 0.2155, discriminator training loss: 0.0427, validation loss: 0.3329
2024-05-24 07:55:56 [INFO]: Epoch 065 - generator training loss: 0.2101, discriminator training loss: 0.0426, validation loss: 0.3328
2024-05-24 07:56:14 [INFO]: Epoch 066 - generator training loss: 0.2102, discriminator training loss: 0.0424, validation loss: 0.3373
2024-05-24 07:56:32 [INFO]: Epoch 067 - generator training loss: 0.2146, discriminator training loss: 0.0424, validation loss: 0.3390
2024-05-24 07:56:51 [INFO]: Epoch 068 - generator training loss: 0.2092, discriminator training loss: 0.0422, validation loss: 0.3334
2024-05-24 07:57:09 [INFO]: Epoch 069 - generator training loss: 0.2041, discriminator training loss: 0.0419, validation loss: 0.3318
2024-05-24 07:57:27 [INFO]: Epoch 070 - generator training loss: 0.2000, discriminator training loss: 0.0419, validation loss: 0.3330
2024-05-24 07:57:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 07:57:27 [INFO]: Finished training. The best model is from epoch#60.
2024-05-24 07:57:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073604/USGAN.pypots
2024-05-24 07:57:30 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2905, MSE=0.2544
2024-05-24 07:57:39 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 07:57:39 [INFO]: Using the given device: cuda:0
2024-05-24 07:57:39 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T075739
2024-05-24 07:57:39 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T075739/tensorboard
2024-05-24 07:57:39 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 07:57:54 [INFO]: Epoch 001 - training loss: 1.1282, validation loss: 0.5516
2024-05-24 07:58:06 [INFO]: Epoch 002 - training loss: 0.9204, validation loss: 0.5023
2024-05-24 07:58:18 [INFO]: Epoch 003 - training loss: 0.8628, validation loss: 0.4722
2024-05-24 07:58:30 [INFO]: Epoch 004 - training loss: 0.8259, validation loss: 0.4488
2024-05-24 07:58:42 [INFO]: Epoch 005 - training loss: 0.7990, validation loss: 0.4340
2024-05-24 07:58:54 [INFO]: Epoch 006 - training loss: 0.7755, validation loss: 0.4192
2024-05-24 07:59:06 [INFO]: Epoch 007 - training loss: 0.7550, validation loss: 0.4060
2024-05-24 07:59:17 [INFO]: Epoch 008 - training loss: 0.7405, validation loss: 0.4017
2024-05-24 07:59:29 [INFO]: Epoch 009 - training loss: 0.7270, validation loss: 0.3938
2024-05-24 07:59:41 [INFO]: Epoch 010 - training loss: 0.7151, validation loss: 0.3889
2024-05-24 07:59:53 [INFO]: Epoch 011 - training loss: 0.7046, validation loss: 0.3852
2024-05-24 08:00:05 [INFO]: Epoch 012 - training loss: 0.6964, validation loss: 0.3862
2024-05-24 08:00:17 [INFO]: Epoch 013 - training loss: 0.6896, validation loss: 0.3823
2024-05-24 08:00:29 [INFO]: Epoch 014 - training loss: 0.6835, validation loss: 0.3807
2024-05-24 08:00:41 [INFO]: Epoch 015 - training loss: 0.6784, validation loss: 0.3802
2024-05-24 08:00:53 [INFO]: Epoch 016 - training loss: 0.6729, validation loss: 0.3810
2024-05-24 08:01:04 [INFO]: Epoch 017 - training loss: 0.6684, validation loss: 0.3788
2024-05-24 08:01:16 [INFO]: Epoch 018 - training loss: 0.6640, validation loss: 0.3785
2024-05-24 08:01:28 [INFO]: Epoch 019 - training loss: 0.6602, validation loss: 0.3776
2024-05-24 08:01:40 [INFO]: Epoch 020 - training loss: 0.6570, validation loss: 0.3787
2024-05-24 08:01:52 [INFO]: Epoch 021 - training loss: 0.6530, validation loss: 0.3758
2024-05-24 08:02:04 [INFO]: Epoch 022 - training loss: 0.6494, validation loss: 0.3775
2024-05-24 08:02:16 [INFO]: Epoch 023 - training loss: 0.6466, validation loss: 0.3746
2024-05-24 08:02:28 [INFO]: Epoch 024 - training loss: 0.6431, validation loss: 0.3741
2024-05-24 08:02:40 [INFO]: Epoch 025 - training loss: 0.6408, validation loss: 0.3756
2024-05-24 08:02:52 [INFO]: Epoch 026 - training loss: 0.6397, validation loss: 0.3742
2024-05-24 08:03:04 [INFO]: Epoch 027 - training loss: 0.6388, validation loss: 0.3760
2024-05-24 08:03:15 [INFO]: Epoch 028 - training loss: 0.6338, validation loss: 0.3723
2024-05-24 08:03:27 [INFO]: Epoch 029 - training loss: 0.6301, validation loss: 0.3755
2024-05-24 08:03:39 [INFO]: Epoch 030 - training loss: 0.6281, validation loss: 0.3737
2024-05-24 08:03:51 [INFO]: Epoch 031 - training loss: 0.6242, validation loss: 0.3743
2024-05-24 08:04:03 [INFO]: Epoch 032 - training loss: 0.6217, validation loss: 0.3741
2024-05-24 08:04:15 [INFO]: Epoch 033 - training loss: 0.6207, validation loss: 0.3755
2024-05-24 08:04:27 [INFO]: Epoch 034 - training loss: 0.6211, validation loss: 0.3739
2024-05-24 08:04:39 [INFO]: Epoch 035 - training loss: 0.6160, validation loss: 0.3739
2024-05-24 08:04:51 [INFO]: Epoch 036 - training loss: 0.6136, validation loss: 0.3766
2024-05-24 08:05:03 [INFO]: Epoch 037 - training loss: 0.6092, validation loss: 0.3735
2024-05-24 08:05:14 [INFO]: Epoch 038 - training loss: 0.6068, validation loss: 0.3755
2024-05-24 08:05:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:05:14 [INFO]: Finished training. The best model is from epoch#28.
2024-05-24 08:05:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T075739/BRITS.pypots
2024-05-24 08:05:17 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2569, MSE=0.2573
2024-05-24 08:05:27 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:05:27 [INFO]: Using the given device: cuda:0
2024-05-24 08:05:27 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527
2024-05-24 08:05:27 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/tensorboard
2024-05-24 08:05:27 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 08:05:32 [INFO]: Epoch 001 - training loss: 1.1300, validation loss: 1.0028
2024-05-24 08:05:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch1_loss1.0027827382087708.pypots
2024-05-24 08:05:35 [INFO]: Epoch 002 - training loss: 0.7082, validation loss: 0.9787
2024-05-24 08:05:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch2_loss0.9786581963300705.pypots
2024-05-24 08:05:38 [INFO]: Epoch 003 - training loss: 0.6076, validation loss: 0.9522
2024-05-24 08:05:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch3_loss0.9522294878959656.pypots
2024-05-24 08:05:40 [INFO]: Epoch 004 - training loss: 0.5616, validation loss: 0.9375
2024-05-24 08:05:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch4_loss0.9374502807855606.pypots
2024-05-24 08:05:43 [INFO]: Epoch 005 - training loss: 0.5337, validation loss: 0.9297
2024-05-24 08:05:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch5_loss0.92971673309803.pypots
2024-05-24 08:05:46 [INFO]: Epoch 006 - training loss: 0.5178, validation loss: 0.9250
2024-05-24 08:05:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch6_loss0.9250024616718292.pypots
2024-05-24 08:05:49 [INFO]: Epoch 007 - training loss: 0.4993, validation loss: 0.9219
2024-05-24 08:05:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch7_loss0.9218613803386688.pypots
2024-05-24 08:05:52 [INFO]: Epoch 008 - training loss: 0.4913, validation loss: 0.9197
2024-05-24 08:05:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch8_loss0.9197443127632141.pypots
2024-05-24 08:05:54 [INFO]: Epoch 009 - training loss: 0.4811, validation loss: 0.9187
2024-05-24 08:05:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch9_loss0.9187496304512024.pypots
2024-05-24 08:05:57 [INFO]: Epoch 010 - training loss: 0.4727, validation loss: 0.9179
2024-05-24 08:05:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch10_loss0.9179476588964463.pypots
2024-05-24 08:06:00 [INFO]: Epoch 011 - training loss: 0.4623, validation loss: 0.9181
2024-05-24 08:06:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch11_loss0.9180622667074203.pypots
2024-05-24 08:06:03 [INFO]: Epoch 012 - training loss: 0.4653, validation loss: 0.9197
2024-05-24 08:06:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch12_loss0.9196649938821793.pypots
2024-05-24 08:06:05 [INFO]: Epoch 013 - training loss: 0.4577, validation loss: 0.9208
2024-05-24 08:06:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch13_loss0.920813524723053.pypots
2024-05-24 08:06:08 [INFO]: Epoch 014 - training loss: 0.4529, validation loss: 0.9222
2024-05-24 08:06:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch14_loss0.9222366750240326.pypots
2024-05-24 08:06:11 [INFO]: Epoch 015 - training loss: 0.4477, validation loss: 0.9239
2024-05-24 08:06:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch15_loss0.923914036154747.pypots
2024-05-24 08:06:14 [INFO]: Epoch 016 - training loss: 0.4496, validation loss: 0.9262
2024-05-24 08:06:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch16_loss0.9262259483337403.pypots
2024-05-24 08:06:16 [INFO]: Epoch 017 - training loss: 0.4416, validation loss: 0.9275
2024-05-24 08:06:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch17_loss0.9274753630161285.pypots
2024-05-24 08:06:19 [INFO]: Epoch 018 - training loss: 0.4431, validation loss: 0.9285
2024-05-24 08:06:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch18_loss0.9284869790077209.pypots
2024-05-24 08:06:22 [INFO]: Epoch 019 - training loss: 0.4446, validation loss: 0.9305
2024-05-24 08:06:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch19_loss0.9305398166179657.pypots
2024-05-24 08:06:25 [INFO]: Epoch 020 - training loss: 0.4380, validation loss: 0.9319
2024-05-24 08:06:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN_epoch20_loss0.9319154620170593.pypots
2024-05-24 08:06:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:06:25 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 08:06:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T080527/MRNN.pypots
2024-05-24 08:06:26 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6899, MSE=0.8979
2024-05-24 08:06:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 08:06:30 [INFO]: Using the given device: cpu
2024-05-24 08:06:30 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4036, MSE=0.5059
2024-05-24 08:06:30 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_physionet_2012_seta".
2024-05-24 08:06:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 08:06:30 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6901, MSE=1.0191
2024-05-24 08:06:30 [INFO]: Successfully created the given path "saved_results/round_3/Median_physionet_2012_seta".
2024-05-24 08:06:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_physionet_2012_seta/imputation.pkl
2024-05-24 08:06:30 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7055, MSE=0.9762
2024-05-24 08:06:30 [INFO]: Successfully created the given path "saved_results/round_3/Mean_physionet_2012_seta".
2024-05-24 08:06:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 08:06:30 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-24 08:06:31 [INFO]: Using the given device: cuda:0
2024-05-24 08:06:31 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T080631
2024-05-24 08:06:31 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T080631/tensorboard
2024-05-24 08:06:31 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-24 08:06:33 [INFO]: Epoch 001 - training loss: 1.1557, validation loss: 0.5285
2024-05-24 08:06:34 [INFO]: Epoch 002 - training loss: 0.8508, validation loss: 0.4597
2024-05-24 08:06:35 [INFO]: Epoch 003 - training loss: 0.7531, validation loss: 0.4235
2024-05-24 08:06:36 [INFO]: Epoch 004 - training loss: 0.6962, validation loss: 0.4025
2024-05-24 08:06:37 [INFO]: Epoch 005 - training loss: 0.6574, validation loss: 0.3904
2024-05-24 08:06:38 [INFO]: Epoch 006 - training loss: 0.6295, validation loss: 0.3737
2024-05-24 08:06:39 [INFO]: Epoch 007 - training loss: 0.6019, validation loss: 0.3690
2024-05-24 08:06:41 [INFO]: Epoch 008 - training loss: 0.5827, validation loss: 0.3612
2024-05-24 08:06:42 [INFO]: Epoch 009 - training loss: 0.5617, validation loss: 0.3467
2024-05-24 08:06:43 [INFO]: Epoch 010 - training loss: 0.5428, validation loss: 0.3471
2024-05-24 08:06:44 [INFO]: Epoch 011 - training loss: 0.5303, validation loss: 0.3374
2024-05-24 08:06:45 [INFO]: Epoch 012 - training loss: 0.5193, validation loss: 0.3402
2024-05-24 08:06:46 [INFO]: Epoch 013 - training loss: 0.5000, validation loss: 0.3367
2024-05-24 08:06:48 [INFO]: Epoch 014 - training loss: 0.4944, validation loss: 0.3348
2024-05-24 08:06:49 [INFO]: Epoch 015 - training loss: 0.4836, validation loss: 0.3312
2024-05-24 08:06:50 [INFO]: Epoch 016 - training loss: 0.4700, validation loss: 0.3308
2024-05-24 08:06:51 [INFO]: Epoch 017 - training loss: 0.4651, validation loss: 0.3393
2024-05-24 08:06:52 [INFO]: Epoch 018 - training loss: 0.4585, validation loss: 0.3339
2024-05-24 08:06:53 [INFO]: Epoch 019 - training loss: 0.4470, validation loss: 0.3386
2024-05-24 08:06:55 [INFO]: Epoch 020 - training loss: 0.4438, validation loss: 0.3282
2024-05-24 08:06:56 [INFO]: Epoch 021 - training loss: 0.4367, validation loss: 0.3342
2024-05-24 08:06:57 [INFO]: Epoch 022 - training loss: 0.4309, validation loss: 0.3343
2024-05-24 08:06:58 [INFO]: Epoch 023 - training loss: 0.4274, validation loss: 0.3310
2024-05-24 08:06:59 [INFO]: Epoch 024 - training loss: 0.4241, validation loss: 0.3319
2024-05-24 08:07:00 [INFO]: Epoch 025 - training loss: 0.4191, validation loss: 0.3285
2024-05-24 08:07:01 [INFO]: Epoch 026 - training loss: 0.4160, validation loss: 0.3309
2024-05-24 08:07:03 [INFO]: Epoch 027 - training loss: 0.4092, validation loss: 0.3312
2024-05-24 08:07:04 [INFO]: Epoch 028 - training loss: 0.4072, validation loss: 0.3316
2024-05-24 08:07:05 [INFO]: Epoch 029 - training loss: 0.4012, validation loss: 0.3322
2024-05-24 08:07:06 [INFO]: Epoch 030 - training loss: 0.3998, validation loss: 0.3360
2024-05-24 08:07:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:07:06 [INFO]: Finished training. The best model is from epoch#20.
2024-05-24 08:07:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T080631/SAITS.pypots
2024-05-24 08:07:06 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2700, MSE=0.2872
2024-05-24 08:07:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:07:07 [INFO]: Using the given device: cuda:0
2024-05-24 08:07:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T080707
2024-05-24 08:07:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T080707/tensorboard
2024-05-24 08:07:07 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-24 08:07:07 [INFO]: Epoch 001 - training loss: 1.1264, validation loss: 0.5611
2024-05-24 08:07:08 [INFO]: Epoch 002 - training loss: 0.7210, validation loss: 0.4918
2024-05-24 08:07:08 [INFO]: Epoch 003 - training loss: 0.6243, validation loss: 0.4736
2024-05-24 08:07:09 [INFO]: Epoch 004 - training loss: 0.5710, validation loss: 0.4514
2024-05-24 08:07:10 [INFO]: Epoch 005 - training loss: 0.5395, validation loss: 0.4390
2024-05-24 08:07:10 [INFO]: Epoch 006 - training loss: 0.5147, validation loss: 0.4363
2024-05-24 08:07:11 [INFO]: Epoch 007 - training loss: 0.4794, validation loss: 0.4218
2024-05-24 08:07:11 [INFO]: Epoch 008 - training loss: 0.4628, validation loss: 0.4159
2024-05-24 08:07:12 [INFO]: Epoch 009 - training loss: 0.4461, validation loss: 0.4142
2024-05-24 08:07:13 [INFO]: Epoch 010 - training loss: 0.4244, validation loss: 0.4022
2024-05-24 08:07:13 [INFO]: Epoch 011 - training loss: 0.4138, validation loss: 0.3951
2024-05-24 08:07:14 [INFO]: Epoch 012 - training loss: 0.3932, validation loss: 0.3960
2024-05-24 08:07:14 [INFO]: Epoch 013 - training loss: 0.3836, validation loss: 0.3847
2024-05-24 08:07:15 [INFO]: Epoch 014 - training loss: 0.3716, validation loss: 0.3835
2024-05-24 08:07:15 [INFO]: Epoch 015 - training loss: 0.3646, validation loss: 0.3766
2024-05-24 08:07:16 [INFO]: Epoch 016 - training loss: 0.3600, validation loss: 0.3754
2024-05-24 08:07:17 [INFO]: Epoch 017 - training loss: 0.3461, validation loss: 0.3717
2024-05-24 08:07:17 [INFO]: Epoch 018 - training loss: 0.3350, validation loss: 0.3683
2024-05-24 08:07:18 [INFO]: Epoch 019 - training loss: 0.3272, validation loss: 0.3627
2024-05-24 08:07:18 [INFO]: Epoch 020 - training loss: 0.3230, validation loss: 0.3645
2024-05-24 08:07:19 [INFO]: Epoch 021 - training loss: 0.3189, validation loss: 0.3625
2024-05-24 08:07:20 [INFO]: Epoch 022 - training loss: 0.3086, validation loss: 0.3559
2024-05-24 08:07:20 [INFO]: Epoch 023 - training loss: 0.3022, validation loss: 0.3595
2024-05-24 08:07:21 [INFO]: Epoch 024 - training loss: 0.2979, validation loss: 0.3603
2024-05-24 08:07:21 [INFO]: Epoch 025 - training loss: 0.2910, validation loss: 0.3622
2024-05-24 08:07:22 [INFO]: Epoch 026 - training loss: 0.2889, validation loss: 0.3535
2024-05-24 08:07:22 [INFO]: Epoch 027 - training loss: 0.2815, validation loss: 0.3562
2024-05-24 08:07:23 [INFO]: Epoch 028 - training loss: 0.2781, validation loss: 0.3537
2024-05-24 08:07:24 [INFO]: Epoch 029 - training loss: 0.2742, validation loss: 0.3516
2024-05-24 08:07:24 [INFO]: Epoch 030 - training loss: 0.2666, validation loss: 0.3564
2024-05-24 08:07:25 [INFO]: Epoch 031 - training loss: 0.2595, validation loss: 0.3491
2024-05-24 08:07:25 [INFO]: Epoch 032 - training loss: 0.2595, validation loss: 0.3505
2024-05-24 08:07:26 [INFO]: Epoch 033 - training loss: 0.2574, validation loss: 0.3584
2024-05-24 08:07:27 [INFO]: Epoch 034 - training loss: 0.2548, validation loss: 0.3530
2024-05-24 08:07:27 [INFO]: Epoch 035 - training loss: 0.2503, validation loss: 0.3507
2024-05-24 08:07:28 [INFO]: Epoch 036 - training loss: 0.2475, validation loss: 0.3508
2024-05-24 08:07:28 [INFO]: Epoch 037 - training loss: 0.2470, validation loss: 0.3576
2024-05-24 08:07:29 [INFO]: Epoch 038 - training loss: 0.2404, validation loss: 0.3542
2024-05-24 08:07:30 [INFO]: Epoch 039 - training loss: 0.2373, validation loss: 0.3560
2024-05-24 08:07:30 [INFO]: Epoch 040 - training loss: 0.2326, validation loss: 0.3511
2024-05-24 08:07:31 [INFO]: Epoch 041 - training loss: 0.2302, validation loss: 0.3510
2024-05-24 08:07:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:07:31 [INFO]: Finished training. The best model is from epoch#31.
2024-05-24 08:07:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T080707/Transformer.pypots
2024-05-24 08:07:31 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2811, MSE=0.2955
2024-05-24 08:07:31 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_physionet_2012_seta/imputation.pkl
2024-05-24 08:07:31 [INFO]: Using the given device: cuda:0
2024-05-24 08:07:31 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T080731
2024-05-24 08:07:31 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T080731/tensorboard
2024-05-24 08:07:31 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-24 08:07:32 [INFO]: Epoch 001 - training loss: 0.4495, validation loss: 1.0477
2024-05-24 08:07:33 [INFO]: Epoch 002 - training loss: 0.5263, validation loss: 1.1911
2024-05-24 08:07:33 [INFO]: Epoch 003 - training loss: 0.4511, validation loss: 0.4482
2024-05-24 08:07:34 [INFO]: Epoch 004 - training loss: 0.4129, validation loss: 0.6771
2024-05-24 08:07:35 [INFO]: Epoch 005 - training loss: 0.4237, validation loss: 0.4905
2024-05-24 08:07:35 [INFO]: Epoch 006 - training loss: 0.3550, validation loss: 0.3399
2024-05-24 08:07:36 [INFO]: Epoch 007 - training loss: 0.3164, validation loss: 0.3335
2024-05-24 08:07:37 [INFO]: Epoch 008 - training loss: 0.3069, validation loss: 0.3218
2024-05-24 08:07:38 [INFO]: Epoch 009 - training loss: 0.3007, validation loss: 0.3153
2024-05-24 08:07:38 [INFO]: Epoch 010 - training loss: 0.2961, validation loss: 0.3198
2024-05-24 08:07:39 [INFO]: Epoch 011 - training loss: 0.2904, validation loss: 0.3177
2024-05-24 08:07:40 [INFO]: Epoch 012 - training loss: 0.2922, validation loss: 0.3332
2024-05-24 08:07:40 [INFO]: Epoch 013 - training loss: 0.2825, validation loss: 0.3229
2024-05-24 08:07:41 [INFO]: Epoch 014 - training loss: 0.2744, validation loss: 0.3147
2024-05-24 08:07:42 [INFO]: Epoch 015 - training loss: 0.2690, validation loss: 0.3346
2024-05-24 08:07:42 [INFO]: Epoch 016 - training loss: 0.2752, validation loss: 0.3075
2024-05-24 08:07:43 [INFO]: Epoch 017 - training loss: 0.2667, validation loss: 0.3162
2024-05-24 08:07:44 [INFO]: Epoch 018 - training loss: 0.2550, validation loss: 0.3271
2024-05-24 08:07:45 [INFO]: Epoch 019 - training loss: 0.2517, validation loss: 0.3183
2024-05-24 08:07:45 [INFO]: Epoch 020 - training loss: 0.2462, validation loss: 0.3198
2024-05-24 08:07:46 [INFO]: Epoch 021 - training loss: 0.2440, validation loss: 0.3192
2024-05-24 08:07:47 [INFO]: Epoch 022 - training loss: 0.2365, validation loss: 0.3473
2024-05-24 08:07:47 [INFO]: Epoch 023 - training loss: 0.2366, validation loss: 0.3236
2024-05-24 08:07:48 [INFO]: Epoch 024 - training loss: 0.2374, validation loss: 0.3151
2024-05-24 08:07:49 [INFO]: Epoch 025 - training loss: 0.2374, validation loss: 0.3248
2024-05-24 08:07:50 [INFO]: Epoch 026 - training loss: 0.2232, validation loss: 0.3358
2024-05-24 08:07:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:07:50 [INFO]: Finished training. The best model is from epoch#16.
2024-05-24 08:07:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T080731/TimesNet.pypots
2024-05-24 08:07:50 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2847, MSE=0.2681
2024-05-24 08:07:50 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-24 08:07:50 [INFO]: Using the given device: cuda:0
2024-05-24 08:07:50 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750
2024-05-24 08:07:50 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/tensorboard
2024-05-24 08:07:50 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-24 08:08:33 [INFO]: Epoch 001 - training loss: 0.4116, validation loss: 0.3301
2024-05-24 08:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch1_loss0.3300650388002396.pypots
2024-05-24 08:09:17 [INFO]: Epoch 002 - training loss: 0.3117, validation loss: 0.2911
2024-05-24 08:09:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch2_loss0.2911473408341408.pypots
2024-05-24 08:10:00 [INFO]: Epoch 003 - training loss: 0.2741, validation loss: 0.2618
2024-05-24 08:10:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch3_loss0.26182762533426285.pypots
2024-05-24 08:10:43 [INFO]: Epoch 004 - training loss: 0.2562, validation loss: 0.2515
2024-05-24 08:10:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch4_loss0.25150471180677414.pypots
2024-05-24 08:11:27 [INFO]: Epoch 005 - training loss: 0.2530, validation loss: 0.2392
2024-05-24 08:11:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch5_loss0.23919856399297715.pypots
2024-05-24 08:12:11 [INFO]: Epoch 006 - training loss: 0.2398, validation loss: 0.2327
2024-05-24 08:12:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch6_loss0.2326810196042061.pypots
2024-05-24 08:12:54 [INFO]: Epoch 007 - training loss: 0.2408, validation loss: 0.2320
2024-05-24 08:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch7_loss0.2320452094078064.pypots
2024-05-24 08:13:38 [INFO]: Epoch 008 - training loss: 0.2323, validation loss: 0.2273
2024-05-24 08:13:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch8_loss0.22733094319701194.pypots
2024-05-24 08:14:22 [INFO]: Epoch 009 - training loss: 0.2285, validation loss: 0.2187
2024-05-24 08:14:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch9_loss0.21868021935224533.pypots
2024-05-24 08:15:05 [INFO]: Epoch 010 - training loss: 0.2300, validation loss: 0.2179
2024-05-24 08:15:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch10_loss0.21792785078287125.pypots
2024-05-24 08:15:49 [INFO]: Epoch 011 - training loss: 0.2215, validation loss: 0.2129
2024-05-24 08:15:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch11_loss0.21286606937646865.pypots
2024-05-24 08:16:33 [INFO]: Epoch 012 - training loss: 0.2269, validation loss: 0.2150
2024-05-24 08:16:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch12_loss0.21501687318086624.pypots
2024-05-24 08:17:16 [INFO]: Epoch 013 - training loss: 0.2207, validation loss: 0.2066
2024-05-24 08:17:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch13_loss0.2066153772175312.pypots
2024-05-24 08:18:00 [INFO]: Epoch 014 - training loss: 0.2116, validation loss: 0.2097
2024-05-24 08:18:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch14_loss0.2097168855369091.pypots
2024-05-24 08:18:44 [INFO]: Epoch 015 - training loss: 0.2176, validation loss: 0.2149
2024-05-24 08:18:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch15_loss0.21488369032740592.pypots
2024-05-24 08:19:27 [INFO]: Epoch 016 - training loss: 0.2166, validation loss: 0.2049
2024-05-24 08:19:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch16_loss0.20491155833005906.pypots
2024-05-24 08:20:11 [INFO]: Epoch 017 - training loss: 0.2174, validation loss: 0.2069
2024-05-24 08:20:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch17_loss0.2069402851164341.pypots
2024-05-24 08:20:55 [INFO]: Epoch 018 - training loss: 0.2079, validation loss: 0.2043
2024-05-24 08:20:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch18_loss0.2043095462024212.pypots
2024-05-24 08:21:38 [INFO]: Epoch 019 - training loss: 0.2169, validation loss: 0.2035
2024-05-24 08:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch19_loss0.2034906454384327.pypots
2024-05-24 08:22:22 [INFO]: Epoch 020 - training loss: 0.2040, validation loss: 0.2059
2024-05-24 08:22:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch20_loss0.20587504282593727.pypots
2024-05-24 08:23:05 [INFO]: Epoch 021 - training loss: 0.2045, validation loss: 0.2032
2024-05-24 08:23:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch21_loss0.20323313176631927.pypots
2024-05-24 08:23:49 [INFO]: Epoch 022 - training loss: 0.2117, validation loss: 0.2039
2024-05-24 08:23:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch22_loss0.20394135192036628.pypots
2024-05-24 08:24:33 [INFO]: Epoch 023 - training loss: 0.2091, validation loss: 0.1997
2024-05-24 08:24:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch23_loss0.19972292110323905.pypots
2024-05-24 08:25:16 [INFO]: Epoch 024 - training loss: 0.2008, validation loss: 0.2011
2024-05-24 08:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch24_loss0.20114065557718278.pypots
2024-05-24 08:26:00 [INFO]: Epoch 025 - training loss: 0.1959, validation loss: 0.1984
2024-05-24 08:26:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch25_loss0.19838248938322067.pypots
2024-05-24 08:26:44 [INFO]: Epoch 026 - training loss: 0.1929, validation loss: 0.1984
2024-05-24 08:26:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch26_loss0.19838404133915902.pypots
2024-05-24 08:27:27 [INFO]: Epoch 027 - training loss: 0.2029, validation loss: 0.1956
2024-05-24 08:27:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch27_loss0.19557828605175018.pypots
2024-05-24 08:28:11 [INFO]: Epoch 028 - training loss: 0.1990, validation loss: 0.1979
2024-05-24 08:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch28_loss0.19787321165204047.pypots
2024-05-24 08:28:55 [INFO]: Epoch 029 - training loss: 0.2030, validation loss: 0.1951
2024-05-24 08:28:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch29_loss0.19507358148694037.pypots
2024-05-24 08:29:38 [INFO]: Epoch 030 - training loss: 0.2023, validation loss: 0.1963
2024-05-24 08:29:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch30_loss0.19626728370785712.pypots
2024-05-24 08:30:22 [INFO]: Epoch 031 - training loss: 0.2137, validation loss: 0.1967
2024-05-24 08:30:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch31_loss0.19665560647845268.pypots
2024-05-24 08:31:05 [INFO]: Epoch 032 - training loss: 0.2007, validation loss: 0.1940
2024-05-24 08:31:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch32_loss0.19398889765143396.pypots
2024-05-24 08:31:49 [INFO]: Epoch 033 - training loss: 0.2015, validation loss: 0.1956
2024-05-24 08:31:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch33_loss0.19557259902358054.pypots
2024-05-24 08:32:33 [INFO]: Epoch 034 - training loss: 0.2007, validation loss: 0.1955
2024-05-24 08:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch34_loss0.19546736404299736.pypots
2024-05-24 08:33:16 [INFO]: Epoch 035 - training loss: 0.1991, validation loss: 0.1984
2024-05-24 08:33:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch35_loss0.198405422270298.pypots
2024-05-24 08:34:00 [INFO]: Epoch 036 - training loss: 0.2107, validation loss: 0.1947
2024-05-24 08:34:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch36_loss0.19468304067850112.pypots
2024-05-24 08:34:44 [INFO]: Epoch 037 - training loss: 0.2062, validation loss: 0.1959
2024-05-24 08:34:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch37_loss0.19594285041093826.pypots
2024-05-24 08:35:27 [INFO]: Epoch 038 - training loss: 0.2008, validation loss: 0.1950
2024-05-24 08:35:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch38_loss0.19501940459012984.pypots
2024-05-24 08:36:11 [INFO]: Epoch 039 - training loss: 0.1912, validation loss: 0.1956
2024-05-24 08:36:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch39_loss0.1956334315240383.pypots
2024-05-24 08:36:55 [INFO]: Epoch 040 - training loss: 0.2016, validation loss: 0.1927
2024-05-24 08:36:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch40_loss0.19267932772636415.pypots
2024-05-24 08:37:38 [INFO]: Epoch 041 - training loss: 0.2043, validation loss: 0.1919
2024-05-24 08:37:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch41_loss0.19190856888890268.pypots
2024-05-24 08:38:22 [INFO]: Epoch 042 - training loss: 0.2039, validation loss: 0.1930
2024-05-24 08:38:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch42_loss0.19301789924502372.pypots
2024-05-24 08:39:06 [INFO]: Epoch 043 - training loss: 0.1930, validation loss: 0.1910
2024-05-24 08:39:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch43_loss0.19096089601516725.pypots
2024-05-24 08:39:49 [INFO]: Epoch 044 - training loss: 0.1980, validation loss: 0.1892
2024-05-24 08:39:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch44_loss0.1892479509115219.pypots
2024-05-24 08:40:33 [INFO]: Epoch 045 - training loss: 0.1944, validation loss: 0.1928
2024-05-24 08:40:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch45_loss0.19279536232352257.pypots
2024-05-24 08:41:17 [INFO]: Epoch 046 - training loss: 0.2059, validation loss: 0.1913
2024-05-24 08:41:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch46_loss0.19128970429301262.pypots
2024-05-24 08:42:00 [INFO]: Epoch 047 - training loss: 0.1927, validation loss: 0.1901
2024-05-24 08:42:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch47_loss0.19007115438580513.pypots
2024-05-24 08:42:44 [INFO]: Epoch 048 - training loss: 0.1907, validation loss: 0.1886
2024-05-24 08:42:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch48_loss0.18855175673961638.pypots
2024-05-24 08:43:27 [INFO]: Epoch 049 - training loss: 0.1914, validation loss: 0.1953
2024-05-24 08:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch49_loss0.1953119270503521.pypots
2024-05-24 08:44:11 [INFO]: Epoch 050 - training loss: 0.1960, validation loss: 0.1912
2024-05-24 08:44:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch50_loss0.19123166501522065.pypots
2024-05-24 08:44:55 [INFO]: Epoch 051 - training loss: 0.2127, validation loss: 0.1935
2024-05-24 08:44:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch51_loss0.19345504567027091.pypots
2024-05-24 08:45:38 [INFO]: Epoch 052 - training loss: 0.1915, validation loss: 0.1882
2024-05-24 08:45:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch52_loss0.18821275383234023.pypots
2024-05-24 08:46:22 [INFO]: Epoch 053 - training loss: 0.1848, validation loss: 0.1892
2024-05-24 08:46:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch53_loss0.1891941599547863.pypots
2024-05-24 08:47:05 [INFO]: Epoch 054 - training loss: 0.1920, validation loss: 0.1905
2024-05-24 08:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch54_loss0.1904555656015873.pypots
2024-05-24 08:47:49 [INFO]: Epoch 055 - training loss: 0.1963, validation loss: 0.1912
2024-05-24 08:47:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch55_loss0.19118474572896957.pypots
2024-05-24 08:48:32 [INFO]: Epoch 056 - training loss: 0.1925, validation loss: 0.1881
2024-05-24 08:48:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch56_loss0.1880568668246269.pypots
2024-05-24 08:49:16 [INFO]: Epoch 057 - training loss: 0.2026, validation loss: 0.1878
2024-05-24 08:49:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch57_loss0.18782275021076203.pypots
2024-05-24 08:50:00 [INFO]: Epoch 058 - training loss: 0.2048, validation loss: 0.1867
2024-05-24 08:50:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch58_loss0.18673747926950454.pypots
2024-05-24 08:50:43 [INFO]: Epoch 059 - training loss: 0.1948, validation loss: 0.1897
2024-05-24 08:50:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch59_loss0.1897135369479656.pypots
2024-05-24 08:51:27 [INFO]: Epoch 060 - training loss: 0.1940, validation loss: 0.1894
2024-05-24 08:51:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch60_loss0.1893703483045101.pypots
2024-05-24 08:52:10 [INFO]: Epoch 061 - training loss: 0.2000, validation loss: 0.1866
2024-05-24 08:52:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch61_loss0.18656064569950104.pypots
2024-05-24 08:52:54 [INFO]: Epoch 062 - training loss: 0.1881, validation loss: 0.1890
2024-05-24 08:52:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch62_loss0.18904682323336602.pypots
2024-05-24 08:53:38 [INFO]: Epoch 063 - training loss: 0.1943, validation loss: 0.1914
2024-05-24 08:53:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch63_loss0.19139321148395538.pypots
2024-05-24 08:54:21 [INFO]: Epoch 064 - training loss: 0.1898, validation loss: 0.1868
2024-05-24 08:54:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch64_loss0.18683666437864305.pypots
2024-05-24 08:55:05 [INFO]: Epoch 065 - training loss: 0.2080, validation loss: 0.1902
2024-05-24 08:55:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch65_loss0.19019685238599776.pypots
2024-05-24 08:55:49 [INFO]: Epoch 066 - training loss: 0.1875, validation loss: 0.1863
2024-05-24 08:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch66_loss0.18625523224473.pypots
2024-05-24 08:56:32 [INFO]: Epoch 067 - training loss: 0.1910, validation loss: 0.1881
2024-05-24 08:56:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch67_loss0.18810344040393828.pypots
2024-05-24 08:57:16 [INFO]: Epoch 068 - training loss: 0.2013, validation loss: 0.1892
2024-05-24 08:57:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch68_loss0.18917214423418044.pypots
2024-05-24 08:57:59 [INFO]: Epoch 069 - training loss: 0.1923, validation loss: 0.1910
2024-05-24 08:57:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch69_loss0.19100900515913963.pypots
2024-05-24 08:58:43 [INFO]: Epoch 070 - training loss: 0.1795, validation loss: 0.1849
2024-05-24 08:58:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch70_loss0.18488051369786263.pypots
2024-05-24 08:59:27 [INFO]: Epoch 071 - training loss: 0.1960, validation loss: 0.1840
2024-05-24 08:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch71_loss0.18398915901780127.pypots
2024-05-24 09:00:10 [INFO]: Epoch 072 - training loss: 0.1748, validation loss: 0.1835
2024-05-24 09:00:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch72_loss0.1835251644253731.pypots
2024-05-24 09:00:54 [INFO]: Epoch 073 - training loss: 0.1963, validation loss: 0.1845
2024-05-24 09:00:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch73_loss0.18453365489840506.pypots
2024-05-24 09:01:38 [INFO]: Epoch 074 - training loss: 0.1858, validation loss: 0.1846
2024-05-24 09:01:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch74_loss0.18456931859254838.pypots
2024-05-24 09:02:21 [INFO]: Epoch 075 - training loss: 0.1979, validation loss: 0.1902
2024-05-24 09:02:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch75_loss0.1901549518108368.pypots
2024-05-24 09:03:05 [INFO]: Epoch 076 - training loss: 0.1955, validation loss: 0.1857
2024-05-24 09:03:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch76_loss0.18572952523827552.pypots
2024-05-24 09:03:48 [INFO]: Epoch 077 - training loss: 0.1861, validation loss: 0.1877
2024-05-24 09:03:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch77_loss0.18771279826760293.pypots
2024-05-24 09:04:32 [INFO]: Epoch 078 - training loss: 0.1889, validation loss: 0.1939
2024-05-24 09:04:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch78_loss0.1939408987760544.pypots
2024-05-24 09:05:16 [INFO]: Epoch 079 - training loss: 0.1868, validation loss: 0.1872
2024-05-24 09:05:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch79_loss0.18716106563806534.pypots
2024-05-24 09:05:59 [INFO]: Epoch 080 - training loss: 0.1863, validation loss: 0.1848
2024-05-24 09:05:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch80_loss0.18475673943758011.pypots
2024-05-24 09:06:43 [INFO]: Epoch 081 - training loss: 0.1840, validation loss: 0.1856
2024-05-24 09:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch81_loss0.18559429198503494.pypots
2024-05-24 09:07:27 [INFO]: Epoch 082 - training loss: 0.1936, validation loss: 0.1894
2024-05-24 09:07:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI_epoch82_loss0.18942976370453835.pypots
2024-05-24 09:07:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:07:27 [INFO]: Finished training. The best model is from epoch#72.
2024-05-24 09:07:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T080750/CSDI.pypots
2024-05-24 09:14:46 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2301, MSE=0.2542
2024-05-24 09:44:11 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 09:44:11 [INFO]: Using the given device: cuda:0
2024-05-24 09:44:11 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T094411
2024-05-24 09:44:11 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T094411/tensorboard
2024-05-24 09:44:11 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 09:44:11 [INFO]: Epoch 001 - training loss: 43297.4254, validation loss: 0.9289
2024-05-24 09:44:12 [INFO]: Epoch 002 - training loss: 24466.7252, validation loss: 0.7414
2024-05-24 09:44:13 [INFO]: Epoch 003 - training loss: 23488.8409, validation loss: 0.6992
2024-05-24 09:44:13 [INFO]: Epoch 004 - training loss: 23188.9410, validation loss: 0.6758
2024-05-24 09:44:14 [INFO]: Epoch 005 - training loss: 23041.9570, validation loss: 0.6756
2024-05-24 09:44:14 [INFO]: Epoch 006 - training loss: 22959.2085, validation loss: 0.6713
2024-05-24 09:44:15 [INFO]: Epoch 007 - training loss: 22908.3428, validation loss: 0.6716
2024-05-24 09:44:15 [INFO]: Epoch 008 - training loss: 22876.8162, validation loss: 0.6688
2024-05-24 09:44:16 [INFO]: Epoch 009 - training loss: 22854.1496, validation loss: 0.6666
2024-05-24 09:44:17 [INFO]: Epoch 010 - training loss: 22839.3367, validation loss: 0.6665
2024-05-24 09:44:17 [INFO]: Epoch 011 - training loss: 22828.2868, validation loss: 0.6633
2024-05-24 09:44:18 [INFO]: Epoch 012 - training loss: 22820.0289, validation loss: 0.6668
2024-05-24 09:44:18 [INFO]: Epoch 013 - training loss: 22814.0357, validation loss: 0.6606
2024-05-24 09:44:19 [INFO]: Epoch 014 - training loss: 22808.8508, validation loss: 0.6595
2024-05-24 09:44:19 [INFO]: Epoch 015 - training loss: 22805.0002, validation loss: 0.6575
2024-05-24 09:44:20 [INFO]: Epoch 016 - training loss: 22802.1570, validation loss: 0.6537
2024-05-24 09:44:21 [INFO]: Epoch 017 - training loss: 22799.2637, validation loss: 0.6535
2024-05-24 09:44:21 [INFO]: Epoch 018 - training loss: 22796.5934, validation loss: 0.6484
2024-05-24 09:44:22 [INFO]: Epoch 019 - training loss: 22794.4166, validation loss: 0.6457
2024-05-24 09:44:22 [INFO]: Epoch 020 - training loss: 22792.6846, validation loss: 0.6436
2024-05-24 09:44:23 [INFO]: Epoch 021 - training loss: 22790.9306, validation loss: 0.6427
2024-05-24 09:44:23 [INFO]: Epoch 022 - training loss: 22789.6363, validation loss: 0.6373
2024-05-24 09:44:24 [INFO]: Epoch 023 - training loss: 22788.5723, validation loss: 0.6373
2024-05-24 09:44:25 [INFO]: Epoch 024 - training loss: 22787.7963, validation loss: 0.6354
2024-05-24 09:44:25 [INFO]: Epoch 025 - training loss: 22787.1933, validation loss: 0.6348
2024-05-24 09:44:26 [INFO]: Epoch 026 - training loss: 22786.0353, validation loss: 0.6319
2024-05-24 09:44:26 [INFO]: Epoch 027 - training loss: 22785.1511, validation loss: 0.6417
2024-05-24 09:44:27 [INFO]: Epoch 028 - training loss: 22785.0308, validation loss: 0.6307
2024-05-24 09:44:28 [INFO]: Epoch 029 - training loss: 22783.6690, validation loss: 0.6325
2024-05-24 09:44:28 [INFO]: Epoch 030 - training loss: 22783.7998, validation loss: 0.6353
2024-05-24 09:44:29 [INFO]: Epoch 031 - training loss: 22782.5283, validation loss: 0.6273
2024-05-24 09:44:29 [INFO]: Epoch 032 - training loss: 22781.9509, validation loss: 0.6259
2024-05-24 09:44:30 [INFO]: Epoch 033 - training loss: 22781.8674, validation loss: 0.6343
2024-05-24 09:44:30 [INFO]: Epoch 034 - training loss: 22781.9713, validation loss: 0.6296
2024-05-24 09:44:31 [INFO]: Epoch 035 - training loss: 22782.0467, validation loss: 0.6269
2024-05-24 09:44:32 [INFO]: Epoch 036 - training loss: 22781.4751, validation loss: 0.6249
2024-05-24 09:44:32 [INFO]: Epoch 037 - training loss: 22780.4060, validation loss: 0.6223
2024-05-24 09:44:33 [INFO]: Epoch 038 - training loss: 22779.7353, validation loss: 0.6228
2024-05-24 09:44:33 [INFO]: Epoch 039 - training loss: 22778.5273, validation loss: 0.6339
2024-05-24 09:44:34 [INFO]: Epoch 040 - training loss: 22778.2294, validation loss: 0.6165
2024-05-24 09:44:34 [INFO]: Epoch 041 - training loss: 22777.1114, validation loss: 0.6173
2024-05-24 09:44:35 [INFO]: Epoch 042 - training loss: 22776.0254, validation loss: 0.6102
2024-05-24 09:44:36 [INFO]: Epoch 043 - training loss: 22774.8105, validation loss: 0.6066
2024-05-24 09:44:36 [INFO]: Epoch 044 - training loss: 22773.8243, validation loss: 0.6067
2024-05-24 09:44:37 [INFO]: Epoch 045 - training loss: 22773.0606, validation loss: 0.6118
2024-05-24 09:44:37 [INFO]: Epoch 046 - training loss: 22771.9485, validation loss: 0.6047
2024-05-24 09:44:38 [INFO]: Epoch 047 - training loss: 22771.0293, validation loss: 0.5935
2024-05-24 09:44:38 [INFO]: Epoch 048 - training loss: 22770.7975, validation loss: 0.5939
2024-05-24 09:44:39 [INFO]: Epoch 049 - training loss: 22771.5815, validation loss: 0.5960
2024-05-24 09:44:40 [INFO]: Epoch 050 - training loss: 22770.9880, validation loss: 0.5864
2024-05-24 09:44:40 [INFO]: Epoch 051 - training loss: 22768.6794, validation loss: 0.5830
2024-05-24 09:44:41 [INFO]: Epoch 052 - training loss: 22766.7867, validation loss: 0.5787
2024-05-24 09:44:41 [INFO]: Epoch 053 - training loss: 22766.2285, validation loss: 0.5866
2024-05-24 09:44:42 [INFO]: Epoch 054 - training loss: 22764.8456, validation loss: 0.5744
2024-05-24 09:44:42 [INFO]: Epoch 055 - training loss: 22763.9490, validation loss: 0.5755
2024-05-24 09:44:43 [INFO]: Epoch 056 - training loss: 22763.6785, validation loss: 0.5715
2024-05-24 09:44:44 [INFO]: Epoch 057 - training loss: 22763.3044, validation loss: 0.5680
2024-05-24 09:44:44 [INFO]: Epoch 058 - training loss: 22762.7414, validation loss: 0.5699
2024-05-24 09:44:45 [INFO]: Epoch 059 - training loss: 22762.6321, validation loss: 0.5679
2024-05-24 09:44:45 [INFO]: Epoch 060 - training loss: 22761.7054, validation loss: 0.5668
2024-05-24 09:44:46 [INFO]: Epoch 061 - training loss: 22761.9777, validation loss: 0.5669
2024-05-24 09:44:46 [INFO]: Epoch 062 - training loss: 22761.2121, validation loss: 0.5657
2024-05-24 09:44:47 [INFO]: Epoch 063 - training loss: 22760.9626, validation loss: 0.5680
2024-05-24 09:44:48 [INFO]: Epoch 064 - training loss: 22761.2182, validation loss: 0.5636
2024-05-24 09:44:48 [INFO]: Epoch 065 - training loss: 22761.1777, validation loss: 0.5669
2024-05-24 09:44:49 [INFO]: Epoch 066 - training loss: 22759.8591, validation loss: 0.5645
2024-05-24 09:44:49 [INFO]: Epoch 067 - training loss: 22759.9864, validation loss: 0.5594
2024-05-24 09:44:50 [INFO]: Epoch 068 - training loss: 22760.0277, validation loss: 0.5594
2024-05-24 09:44:51 [INFO]: Epoch 069 - training loss: 22759.0203, validation loss: 0.5584
2024-05-24 09:44:51 [INFO]: Epoch 070 - training loss: 22758.8836, validation loss: 0.5533
2024-05-24 09:44:52 [INFO]: Epoch 071 - training loss: 22758.1983, validation loss: 0.5534
2024-05-24 09:44:52 [INFO]: Epoch 072 - training loss: 22758.3003, validation loss: 0.5583
2024-05-24 09:44:53 [INFO]: Epoch 073 - training loss: 22757.9488, validation loss: 0.5518
2024-05-24 09:44:53 [INFO]: Epoch 074 - training loss: 22757.7481, validation loss: 0.5551
2024-05-24 09:44:54 [INFO]: Epoch 075 - training loss: 22757.0016, validation loss: 0.5472
2024-05-24 09:44:55 [INFO]: Epoch 076 - training loss: 22756.4190, validation loss: 0.5425
2024-05-24 09:44:55 [INFO]: Epoch 077 - training loss: 22756.1351, validation loss: 0.5667
2024-05-24 09:44:56 [INFO]: Epoch 078 - training loss: 22760.0417, validation loss: 0.5396
2024-05-24 09:44:56 [INFO]: Epoch 079 - training loss: 22757.6281, validation loss: 0.5532
2024-05-24 09:44:57 [INFO]: Epoch 080 - training loss: 22758.9473, validation loss: 0.5344
2024-05-24 09:44:57 [INFO]: Epoch 081 - training loss: 22756.8211, validation loss: 0.5344
2024-05-24 09:44:58 [INFO]: Epoch 082 - training loss: 22754.7049, validation loss: 0.5300
2024-05-24 09:44:59 [INFO]: Epoch 083 - training loss: 22753.9667, validation loss: 0.5261
2024-05-24 09:44:59 [INFO]: Epoch 084 - training loss: 22753.3478, validation loss: 0.5270
2024-05-24 09:45:00 [INFO]: Epoch 085 - training loss: 22753.3411, validation loss: 0.5253
2024-05-24 09:45:00 [INFO]: Epoch 086 - training loss: 22752.8937, validation loss: 0.5223
2024-05-24 09:45:01 [INFO]: Epoch 087 - training loss: 22752.6596, validation loss: 0.5220
2024-05-24 09:45:01 [INFO]: Epoch 088 - training loss: 22752.3041, validation loss: 0.5204
2024-05-24 09:45:02 [INFO]: Epoch 089 - training loss: 22752.2399, validation loss: 0.5227
2024-05-24 09:45:03 [INFO]: Epoch 090 - training loss: 22751.8398, validation loss: 0.5176
2024-05-24 09:45:03 [INFO]: Epoch 091 - training loss: 22751.3161, validation loss: 0.5183
2024-05-24 09:45:04 [INFO]: Epoch 092 - training loss: 22751.2454, validation loss: 0.5151
2024-05-24 09:45:04 [INFO]: Epoch 093 - training loss: 22751.5916, validation loss: 0.5206
2024-05-24 09:45:05 [INFO]: Epoch 094 - training loss: 22751.7928, validation loss: 0.5144
2024-05-24 09:45:05 [INFO]: Epoch 095 - training loss: 22751.5696, validation loss: 0.5198
2024-05-24 09:45:06 [INFO]: Epoch 096 - training loss: 22751.2159, validation loss: 0.5122
2024-05-24 09:45:07 [INFO]: Epoch 097 - training loss: 22751.8997, validation loss: 0.5093
2024-05-24 09:45:07 [INFO]: Epoch 098 - training loss: 22749.8860, validation loss: 0.5093
2024-05-24 09:45:08 [INFO]: Epoch 099 - training loss: 22750.2751, validation loss: 0.5101
2024-05-24 09:45:08 [INFO]: Epoch 100 - training loss: 22749.5458, validation loss: 0.5086
2024-05-24 09:45:09 [INFO]: Epoch 101 - training loss: 22749.4568, validation loss: 0.5086
2024-05-24 09:45:09 [INFO]: Epoch 102 - training loss: 22748.8973, validation loss: 0.5045
2024-05-24 09:45:10 [INFO]: Epoch 103 - training loss: 22748.7307, validation loss: 0.5047
2024-05-24 09:45:11 [INFO]: Epoch 104 - training loss: 22748.5252, validation loss: 0.5059
2024-05-24 09:45:11 [INFO]: Epoch 105 - training loss: 22748.5469, validation loss: 0.5022
2024-05-24 09:45:12 [INFO]: Epoch 106 - training loss: 22748.7730, validation loss: 0.5009
2024-05-24 09:45:12 [INFO]: Epoch 107 - training loss: 22748.1660, validation loss: 0.5016
2024-05-24 09:45:13 [INFO]: Epoch 108 - training loss: 22748.0495, validation loss: 0.5024
2024-05-24 09:45:14 [INFO]: Epoch 109 - training loss: 22748.0392, validation loss: 0.5028
2024-05-24 09:45:14 [INFO]: Epoch 110 - training loss: 22748.2503, validation loss: 0.5009
2024-05-24 09:45:15 [INFO]: Epoch 111 - training loss: 22748.0365, validation loss: 0.4997
2024-05-24 09:45:15 [INFO]: Epoch 112 - training loss: 22747.4854, validation loss: 0.4996
2024-05-24 09:45:16 [INFO]: Epoch 113 - training loss: 22747.8544, validation loss: 0.5012
2024-05-24 09:45:16 [INFO]: Epoch 114 - training loss: 22747.3128, validation loss: 0.5000
2024-05-24 09:45:17 [INFO]: Epoch 115 - training loss: 22748.0241, validation loss: 0.4984
2024-05-24 09:45:18 [INFO]: Epoch 116 - training loss: 22747.8027, validation loss: 0.4979
2024-05-24 09:45:18 [INFO]: Epoch 117 - training loss: 22748.5927, validation loss: 0.4986
2024-05-24 09:45:19 [INFO]: Epoch 118 - training loss: 22748.0697, validation loss: 0.4971
2024-05-24 09:45:19 [INFO]: Epoch 119 - training loss: 22747.5617, validation loss: 0.4975
2024-05-24 09:45:20 [INFO]: Epoch 120 - training loss: 22747.1060, validation loss: 0.5032
2024-05-24 09:45:20 [INFO]: Epoch 121 - training loss: 22747.3577, validation loss: 0.5087
2024-05-24 09:45:21 [INFO]: Epoch 122 - training loss: 22751.1557, validation loss: 0.4951
2024-05-24 09:45:22 [INFO]: Epoch 123 - training loss: 22748.3273, validation loss: 0.4980
2024-05-24 09:45:22 [INFO]: Epoch 124 - training loss: 22747.0342, validation loss: 0.4944
2024-05-24 09:45:23 [INFO]: Epoch 125 - training loss: 22746.2859, validation loss: 0.4969
2024-05-24 09:45:23 [INFO]: Epoch 126 - training loss: 22746.5596, validation loss: 0.4920
2024-05-24 09:45:24 [INFO]: Epoch 127 - training loss: 22746.3745, validation loss: 0.4929
2024-05-24 09:45:24 [INFO]: Epoch 128 - training loss: 22746.1767, validation loss: 0.4961
2024-05-24 09:45:25 [INFO]: Epoch 129 - training loss: 22746.1075, validation loss: 0.4925
2024-05-24 09:45:26 [INFO]: Epoch 130 - training loss: 22745.7864, validation loss: 0.4910
2024-05-24 09:45:26 [INFO]: Epoch 131 - training loss: 22747.0064, validation loss: 0.4893
2024-05-24 09:45:27 [INFO]: Epoch 132 - training loss: 22746.1499, validation loss: 0.4929
2024-05-24 09:45:27 [INFO]: Epoch 133 - training loss: 22746.0957, validation loss: 0.4893
2024-05-24 09:45:28 [INFO]: Epoch 134 - training loss: 22745.9497, validation loss: 0.4931
2024-05-24 09:45:28 [INFO]: Epoch 135 - training loss: 22745.4212, validation loss: 0.4906
2024-05-24 09:45:29 [INFO]: Epoch 136 - training loss: 22745.2898, validation loss: 0.4915
2024-05-24 09:45:30 [INFO]: Epoch 137 - training loss: 22745.7483, validation loss: 0.4880
2024-05-24 09:45:30 [INFO]: Epoch 138 - training loss: 22745.3866, validation loss: 0.4920
2024-05-24 09:45:31 [INFO]: Epoch 139 - training loss: 22746.2196, validation loss: 0.4892
2024-05-24 09:45:31 [INFO]: Epoch 140 - training loss: 22745.9060, validation loss: 0.5000
2024-05-24 09:45:32 [INFO]: Epoch 141 - training loss: 22746.5026, validation loss: 0.4894
2024-05-24 09:45:32 [INFO]: Epoch 142 - training loss: 22745.7913, validation loss: 0.4979
2024-05-24 09:45:33 [INFO]: Epoch 143 - training loss: 22745.0189, validation loss: 0.4918
2024-05-24 09:45:34 [INFO]: Epoch 144 - training loss: 22745.4201, validation loss: 0.4901
2024-05-24 09:45:34 [INFO]: Epoch 145 - training loss: 22745.2140, validation loss: 0.4848
2024-05-24 09:45:35 [INFO]: Epoch 146 - training loss: 22745.9706, validation loss: 0.4834
2024-05-24 09:45:35 [INFO]: Epoch 147 - training loss: 22746.5660, validation loss: 0.4858
2024-05-24 09:45:36 [INFO]: Epoch 148 - training loss: 22745.4901, validation loss: 0.4835
2024-05-24 09:45:36 [INFO]: Epoch 149 - training loss: 22744.5271, validation loss: 0.4816
2024-05-24 09:45:37 [INFO]: Epoch 150 - training loss: 22744.1333, validation loss: 0.4833
2024-05-24 09:45:38 [INFO]: Epoch 151 - training loss: 22744.1057, validation loss: 0.4795
2024-05-24 09:45:38 [INFO]: Epoch 152 - training loss: 22743.8046, validation loss: 0.4792
2024-05-24 09:45:39 [INFO]: Epoch 153 - training loss: 22743.8562, validation loss: 0.4777
2024-05-24 09:45:39 [INFO]: Epoch 154 - training loss: 22743.4975, validation loss: 0.4791
2024-05-24 09:45:40 [INFO]: Epoch 155 - training loss: 22743.6507, validation loss: 0.4785
2024-05-24 09:45:40 [INFO]: Epoch 156 - training loss: 22743.6147, validation loss: 0.4779
2024-05-24 09:45:41 [INFO]: Epoch 157 - training loss: 22744.4213, validation loss: 0.4712
2024-05-24 09:45:42 [INFO]: Epoch 158 - training loss: 22743.5440, validation loss: 0.4802
2024-05-24 09:45:42 [INFO]: Epoch 159 - training loss: 22744.3988, validation loss: 0.4751
2024-05-24 09:45:43 [INFO]: Epoch 160 - training loss: 22743.9811, validation loss: 0.4729
2024-05-24 09:45:43 [INFO]: Epoch 161 - training loss: 22743.0770, validation loss: 0.4747
2024-05-24 09:45:44 [INFO]: Epoch 162 - training loss: 22743.0338, validation loss: 0.4785
2024-05-24 09:45:45 [INFO]: Epoch 163 - training loss: 22743.6545, validation loss: 0.4707
2024-05-24 09:45:45 [INFO]: Epoch 164 - training loss: 22743.5014, validation loss: 0.4722
2024-05-24 09:45:46 [INFO]: Epoch 165 - training loss: 22742.9690, validation loss: 0.4682
2024-05-24 09:45:46 [INFO]: Epoch 166 - training loss: 22742.6733, validation loss: 0.4698
2024-05-24 09:45:47 [INFO]: Epoch 167 - training loss: 22742.2863, validation loss: 0.4689
2024-05-24 09:45:47 [INFO]: Epoch 168 - training loss: 22742.3987, validation loss: 0.4685
2024-05-24 09:45:48 [INFO]: Epoch 169 - training loss: 22742.1507, validation loss: 0.4680
2024-05-24 09:45:49 [INFO]: Epoch 170 - training loss: 22742.1220, validation loss: 0.4707
2024-05-24 09:45:49 [INFO]: Epoch 171 - training loss: 22742.5418, validation loss: 0.4684
2024-05-24 09:45:50 [INFO]: Epoch 172 - training loss: 22742.3817, validation loss: 0.4748
2024-05-24 09:45:50 [INFO]: Epoch 173 - training loss: 22742.7910, validation loss: 0.4675
2024-05-24 09:45:51 [INFO]: Epoch 174 - training loss: 22742.1067, validation loss: 0.4737
2024-05-24 09:45:51 [INFO]: Epoch 175 - training loss: 22742.4500, validation loss: 0.4679
2024-05-24 09:45:52 [INFO]: Epoch 176 - training loss: 22741.8826, validation loss: 0.4634
2024-05-24 09:45:53 [INFO]: Epoch 177 - training loss: 22742.1954, validation loss: 0.4653
2024-05-24 09:45:53 [INFO]: Epoch 178 - training loss: 22741.5172, validation loss: 0.4661
2024-05-24 09:45:54 [INFO]: Epoch 179 - training loss: 22742.0054, validation loss: 0.4626
2024-05-24 09:45:54 [INFO]: Epoch 180 - training loss: 22741.8407, validation loss: 0.4682
2024-05-24 09:45:55 [INFO]: Epoch 181 - training loss: 22741.6878, validation loss: 0.4641
2024-05-24 09:45:56 [INFO]: Epoch 182 - training loss: 22741.4289, validation loss: 0.4648
2024-05-24 09:45:56 [INFO]: Epoch 183 - training loss: 22741.2208, validation loss: 0.4618
2024-05-24 09:45:57 [INFO]: Epoch 184 - training loss: 22741.4062, validation loss: 0.4642
2024-05-24 09:45:57 [INFO]: Epoch 185 - training loss: 22741.1479, validation loss: 0.4632
2024-05-24 09:45:58 [INFO]: Epoch 186 - training loss: 22741.1679, validation loss: 0.4632
2024-05-24 09:45:58 [INFO]: Epoch 187 - training loss: 22741.2199, validation loss: 0.4625
2024-05-24 09:45:59 [INFO]: Epoch 188 - training loss: 22741.0818, validation loss: 0.4685
2024-05-24 09:46:00 [INFO]: Epoch 189 - training loss: 22741.2296, validation loss: 0.4642
2024-05-24 09:46:00 [INFO]: Epoch 190 - training loss: 22741.3625, validation loss: 0.4660
2024-05-24 09:46:01 [INFO]: Epoch 191 - training loss: 22741.2948, validation loss: 0.4618
2024-05-24 09:46:01 [INFO]: Epoch 192 - training loss: 22741.1557, validation loss: 0.4641
2024-05-24 09:46:02 [INFO]: Epoch 193 - training loss: 22741.1826, validation loss: 0.4648
2024-05-24 09:46:03 [INFO]: Epoch 194 - training loss: 22740.8340, validation loss: 0.4646
2024-05-24 09:46:03 [INFO]: Epoch 195 - training loss: 22740.8045, validation loss: 0.4603
2024-05-24 09:46:04 [INFO]: Epoch 196 - training loss: 22740.6699, validation loss: 0.4649
2024-05-24 09:46:04 [INFO]: Epoch 197 - training loss: 22740.7674, validation loss: 0.4610
2024-05-24 09:46:05 [INFO]: Epoch 198 - training loss: 22741.0833, validation loss: 0.4619
2024-05-24 09:46:05 [INFO]: Epoch 199 - training loss: 22741.0081, validation loss: 0.4619
2024-05-24 09:46:06 [INFO]: Epoch 200 - training loss: 22741.2066, validation loss: 0.4638
2024-05-24 09:46:07 [INFO]: Epoch 201 - training loss: 22740.6417, validation loss: 0.4654
2024-05-24 09:46:07 [INFO]: Epoch 202 - training loss: 22740.7474, validation loss: 0.4615
2024-05-24 09:46:08 [INFO]: Epoch 203 - training loss: 22740.2988, validation loss: 0.4607
2024-05-24 09:46:08 [INFO]: Epoch 204 - training loss: 22739.7887, validation loss: 0.4627
2024-05-24 09:46:09 [INFO]: Epoch 205 - training loss: 22740.0618, validation loss: 0.4584
2024-05-24 09:46:09 [INFO]: Epoch 206 - training loss: 22739.9358, validation loss: 0.4622
2024-05-24 09:46:10 [INFO]: Epoch 207 - training loss: 22739.5258, validation loss: 0.4560
2024-05-24 09:46:11 [INFO]: Epoch 208 - training loss: 22739.8778, validation loss: 0.4583
2024-05-24 09:46:11 [INFO]: Epoch 209 - training loss: 22739.5291, validation loss: 0.4612
2024-05-24 09:46:12 [INFO]: Epoch 210 - training loss: 22739.6113, validation loss: 0.4567
2024-05-24 09:46:12 [INFO]: Epoch 211 - training loss: 22739.4856, validation loss: 0.4585
2024-05-24 09:46:13 [INFO]: Epoch 212 - training loss: 22740.2740, validation loss: 0.4616
2024-05-24 09:46:14 [INFO]: Epoch 213 - training loss: 22740.4627, validation loss: 0.4596
2024-05-24 09:46:14 [INFO]: Epoch 214 - training loss: 22739.2745, validation loss: 0.4600
2024-05-24 09:46:15 [INFO]: Epoch 215 - training loss: 22739.3203, validation loss: 0.4574
2024-05-24 09:46:15 [INFO]: Epoch 216 - training loss: 22739.4875, validation loss: 0.4591
2024-05-24 09:46:16 [INFO]: Epoch 217 - training loss: 22739.3000, validation loss: 0.4552
2024-05-24 09:46:16 [INFO]: Epoch 218 - training loss: 22739.0439, validation loss: 0.4577
2024-05-24 09:46:17 [INFO]: Epoch 219 - training loss: 22738.1452, validation loss: 0.4588
2024-05-24 09:46:18 [INFO]: Epoch 220 - training loss: 22738.1445, validation loss: 0.4581
2024-05-24 09:46:18 [INFO]: Epoch 221 - training loss: 22738.9300, validation loss: 0.4610
2024-05-24 09:46:19 [INFO]: Epoch 222 - training loss: 22740.0997, validation loss: 0.4543
2024-05-24 09:46:19 [INFO]: Epoch 223 - training loss: 22739.1401, validation loss: 0.4586
2024-05-24 09:46:20 [INFO]: Epoch 224 - training loss: 22738.9624, validation loss: 0.4566
2024-05-24 09:46:20 [INFO]: Epoch 225 - training loss: 22738.6004, validation loss: 0.4583
2024-05-24 09:46:21 [INFO]: Epoch 226 - training loss: 22738.3047, validation loss: 0.4596
2024-05-24 09:46:22 [INFO]: Epoch 227 - training loss: 22738.6997, validation loss: 0.4690
2024-05-24 09:46:22 [INFO]: Epoch 228 - training loss: 22738.3821, validation loss: 0.4667
2024-05-24 09:46:23 [INFO]: Epoch 229 - training loss: 22739.0204, validation loss: 0.4630
2024-05-24 09:46:23 [INFO]: Epoch 230 - training loss: 22738.7774, validation loss: 0.4607
2024-05-24 09:46:24 [INFO]: Epoch 231 - training loss: 22738.1634, validation loss: 0.4578
2024-05-24 09:46:25 [INFO]: Epoch 232 - training loss: 22737.4648, validation loss: 0.4619
2024-05-24 09:46:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:46:25 [INFO]: Finished training. The best model is from epoch#222.
2024-05-24 09:46:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T094411/GPVAE.pypots
2024-05-24 09:46:25 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.3977, MSE=0.3996
2024-05-24 09:46:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 09:46:25 [INFO]: Using the given device: cuda:0
2024-05-24 09:46:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T094625
2024-05-24 09:46:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T094625/tensorboard
2024-05-24 09:46:25 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 09:46:46 [INFO]: Epoch 001 - generator training loss: 0.5857, discriminator training loss: 0.3809, validation loss: 0.6272
2024-05-24 09:47:05 [INFO]: Epoch 002 - generator training loss: 0.4683, discriminator training loss: 0.2718, validation loss: 0.5428
2024-05-24 09:47:23 [INFO]: Epoch 003 - generator training loss: 0.4286, discriminator training loss: 0.2364, validation loss: 0.5253
2024-05-24 09:47:41 [INFO]: Epoch 004 - generator training loss: 0.4468, discriminator training loss: 0.1885, validation loss: 0.5178
2024-05-24 09:48:00 [INFO]: Epoch 005 - generator training loss: 0.4381, discriminator training loss: 0.1594, validation loss: 0.5080
2024-05-24 09:48:18 [INFO]: Epoch 006 - generator training loss: 0.4280, discriminator training loss: 0.1408, validation loss: 0.4866
2024-05-24 09:48:36 [INFO]: Epoch 007 - generator training loss: 0.4176, discriminator training loss: 0.1263, validation loss: 0.4748
2024-05-24 09:48:55 [INFO]: Epoch 008 - generator training loss: 0.4037, discriminator training loss: 0.1157, validation loss: 0.4654
2024-05-24 09:49:13 [INFO]: Epoch 009 - generator training loss: 0.3936, discriminator training loss: 0.1071, validation loss: 0.4555
2024-05-24 09:49:32 [INFO]: Epoch 010 - generator training loss: 0.3853, discriminator training loss: 0.1000, validation loss: 0.4448
2024-05-24 09:49:50 [INFO]: Epoch 011 - generator training loss: 0.3799, discriminator training loss: 0.0941, validation loss: 0.4407
2024-05-24 09:50:08 [INFO]: Epoch 012 - generator training loss: 0.3742, discriminator training loss: 0.0887, validation loss: 0.4377
2024-05-24 09:50:27 [INFO]: Epoch 013 - generator training loss: 0.3680, discriminator training loss: 0.0843, validation loss: 0.4298
2024-05-24 09:50:45 [INFO]: Epoch 014 - generator training loss: 0.3641, discriminator training loss: 0.0802, validation loss: 0.4247
2024-05-24 09:51:03 [INFO]: Epoch 015 - generator training loss: 0.3595, discriminator training loss: 0.0766, validation loss: 0.4204
2024-05-24 09:51:21 [INFO]: Epoch 016 - generator training loss: 0.3560, discriminator training loss: 0.0735, validation loss: 0.4163
2024-05-24 09:51:40 [INFO]: Epoch 017 - generator training loss: 0.3499, discriminator training loss: 0.0704, validation loss: 0.4110
2024-05-24 09:51:58 [INFO]: Epoch 018 - generator training loss: 0.3470, discriminator training loss: 0.0680, validation loss: 0.4093
2024-05-24 09:52:16 [INFO]: Epoch 019 - generator training loss: 0.3433, discriminator training loss: 0.0654, validation loss: 0.4039
2024-05-24 09:52:35 [INFO]: Epoch 020 - generator training loss: 0.3385, discriminator training loss: 0.0634, validation loss: 0.3981
2024-05-24 09:52:53 [INFO]: Epoch 021 - generator training loss: 0.3352, discriminator training loss: 0.0613, validation loss: 0.3976
2024-05-24 09:53:11 [INFO]: Epoch 022 - generator training loss: 0.3314, discriminator training loss: 0.0595, validation loss: 0.3938
2024-05-24 09:53:29 [INFO]: Epoch 023 - generator training loss: 0.3285, discriminator training loss: 0.0581, validation loss: 0.3937
2024-05-24 09:53:48 [INFO]: Epoch 024 - generator training loss: 0.3243, discriminator training loss: 0.0566, validation loss: 0.3883
2024-05-24 09:54:06 [INFO]: Epoch 025 - generator training loss: 0.3217, discriminator training loss: 0.0553, validation loss: 0.3872
2024-05-24 09:54:24 [INFO]: Epoch 026 - generator training loss: 0.3151, discriminator training loss: 0.0542, validation loss: 0.3827
2024-05-24 09:54:43 [INFO]: Epoch 027 - generator training loss: 0.3117, discriminator training loss: 0.0531, validation loss: 0.3816
2024-05-24 09:55:01 [INFO]: Epoch 028 - generator training loss: 0.3082, discriminator training loss: 0.0522, validation loss: 0.3772
2024-05-24 09:55:19 [INFO]: Epoch 029 - generator training loss: 0.3093, discriminator training loss: 0.0514, validation loss: 0.3824
2024-05-24 09:55:38 [INFO]: Epoch 030 - generator training loss: 0.3126, discriminator training loss: 0.0508, validation loss: 0.3809
2024-05-24 09:55:56 [INFO]: Epoch 031 - generator training loss: 0.3029, discriminator training loss: 0.0499, validation loss: 0.3771
2024-05-24 09:56:14 [INFO]: Epoch 032 - generator training loss: 0.2955, discriminator training loss: 0.0494, validation loss: 0.3697
2024-05-24 09:56:32 [INFO]: Epoch 033 - generator training loss: 0.2910, discriminator training loss: 0.0487, validation loss: 0.3682
2024-05-24 09:56:51 [INFO]: Epoch 034 - generator training loss: 0.2916, discriminator training loss: 0.0483, validation loss: 0.3702
2024-05-24 09:57:09 [INFO]: Epoch 035 - generator training loss: 0.2874, discriminator training loss: 0.0479, validation loss: 0.3660
2024-05-24 09:57:27 [INFO]: Epoch 036 - generator training loss: 0.2804, discriminator training loss: 0.0473, validation loss: 0.3650
2024-05-24 09:57:46 [INFO]: Epoch 037 - generator training loss: 0.2783, discriminator training loss: 0.0468, validation loss: 0.3659
2024-05-24 09:58:04 [INFO]: Epoch 038 - generator training loss: 0.2757, discriminator training loss: 0.0465, validation loss: 0.3627
2024-05-24 09:58:22 [INFO]: Epoch 039 - generator training loss: 0.2714, discriminator training loss: 0.0461, validation loss: 0.3599
2024-05-24 09:58:40 [INFO]: Epoch 040 - generator training loss: 0.2757, discriminator training loss: 0.0458, validation loss: 0.3592
2024-05-24 09:58:59 [INFO]: Epoch 041 - generator training loss: 0.2690, discriminator training loss: 0.0454, validation loss: 0.3563
2024-05-24 09:59:17 [INFO]: Epoch 042 - generator training loss: 0.2678, discriminator training loss: 0.0451, validation loss: 0.3570
2024-05-24 09:59:35 [INFO]: Epoch 043 - generator training loss: 0.2644, discriminator training loss: 0.0446, validation loss: 0.3624
2024-05-24 09:59:54 [INFO]: Epoch 044 - generator training loss: 0.2628, discriminator training loss: 0.0447, validation loss: 0.3556
2024-05-24 10:00:12 [INFO]: Epoch 045 - generator training loss: 0.2559, discriminator training loss: 0.0442, validation loss: 0.3554
2024-05-24 10:00:30 [INFO]: Epoch 046 - generator training loss: 0.2535, discriminator training loss: 0.0443, validation loss: 0.3529
2024-05-24 10:00:48 [INFO]: Epoch 047 - generator training loss: 0.2530, discriminator training loss: 0.0439, validation loss: 0.3534
2024-05-24 10:01:07 [INFO]: Epoch 048 - generator training loss: 0.2499, discriminator training loss: 0.0438, validation loss: 0.3476
2024-05-24 10:01:25 [INFO]: Epoch 049 - generator training loss: 0.2496, discriminator training loss: 0.0437, validation loss: 0.3494
2024-05-24 10:01:43 [INFO]: Epoch 050 - generator training loss: 0.2496, discriminator training loss: 0.0434, validation loss: 0.3487
2024-05-24 10:02:01 [INFO]: Epoch 051 - generator training loss: 0.2514, discriminator training loss: 0.0434, validation loss: 0.3495
2024-05-24 10:02:20 [INFO]: Epoch 052 - generator training loss: 0.2455, discriminator training loss: 0.0433, validation loss: 0.3545
2024-05-24 10:02:38 [INFO]: Epoch 053 - generator training loss: 0.2440, discriminator training loss: 0.0434, validation loss: 0.3475
2024-05-24 10:02:56 [INFO]: Epoch 054 - generator training loss: 0.2429, discriminator training loss: 0.0433, validation loss: 0.3509
2024-05-24 10:03:14 [INFO]: Epoch 055 - generator training loss: 0.2483, discriminator training loss: 0.0430, validation loss: 0.3512
2024-05-24 10:03:33 [INFO]: Epoch 056 - generator training loss: 0.2443, discriminator training loss: 0.0431, validation loss: 0.3481
2024-05-24 10:03:51 [INFO]: Epoch 057 - generator training loss: 0.2386, discriminator training loss: 0.0428, validation loss: 0.3435
2024-05-24 10:04:09 [INFO]: Epoch 058 - generator training loss: 0.2337, discriminator training loss: 0.0430, validation loss: 0.3473
2024-05-24 10:04:28 [INFO]: Epoch 059 - generator training loss: 0.2281, discriminator training loss: 0.0424, validation loss: 0.3463
2024-05-24 10:04:46 [INFO]: Epoch 060 - generator training loss: 0.2318, discriminator training loss: 0.0428, validation loss: 0.3474
2024-05-24 10:05:04 [INFO]: Epoch 061 - generator training loss: 0.2255, discriminator training loss: 0.0424, validation loss: 0.3450
2024-05-24 10:05:22 [INFO]: Epoch 062 - generator training loss: 0.2251, discriminator training loss: 0.0423, validation loss: 0.3438
2024-05-24 10:05:41 [INFO]: Epoch 063 - generator training loss: 0.2330, discriminator training loss: 0.0421, validation loss: 0.3463
2024-05-24 10:05:59 [INFO]: Epoch 064 - generator training loss: 0.2279, discriminator training loss: 0.0421, validation loss: 0.3500
2024-05-24 10:06:17 [INFO]: Epoch 065 - generator training loss: 0.2229, discriminator training loss: 0.0421, validation loss: 0.3473
2024-05-24 10:06:35 [INFO]: Epoch 066 - generator training loss: 0.2173, discriminator training loss: 0.0421, validation loss: 0.3454
2024-05-24 10:06:54 [INFO]: Epoch 067 - generator training loss: 0.2180, discriminator training loss: 0.0418, validation loss: 0.3439
2024-05-24 10:06:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:06:54 [INFO]: Finished training. The best model is from epoch#57.
2024-05-24 10:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T094625/USGAN.pypots
2024-05-24 10:06:56 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2919, MSE=0.2607
2024-05-24 10:07:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 10:07:06 [INFO]: Using the given device: cuda:0
2024-05-24 10:07:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T100706
2024-05-24 10:07:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T100706/tensorboard
2024-05-24 10:07:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 10:07:21 [INFO]: Epoch 001 - training loss: 1.1391, validation loss: 0.5543
2024-05-24 10:07:33 [INFO]: Epoch 002 - training loss: 0.9257, validation loss: 0.4999
2024-05-24 10:07:45 [INFO]: Epoch 003 - training loss: 0.8634, validation loss: 0.4713
2024-05-24 10:07:57 [INFO]: Epoch 004 - training loss: 0.8256, validation loss: 0.4504
2024-05-24 10:08:09 [INFO]: Epoch 005 - training loss: 0.7979, validation loss: 0.4342
2024-05-24 10:08:20 [INFO]: Epoch 006 - training loss: 0.7743, validation loss: 0.4189
2024-05-24 10:08:32 [INFO]: Epoch 007 - training loss: 0.7570, validation loss: 0.4084
2024-05-24 10:08:44 [INFO]: Epoch 008 - training loss: 0.7420, validation loss: 0.4009
2024-05-24 10:08:56 [INFO]: Epoch 009 - training loss: 0.7284, validation loss: 0.3948
2024-05-24 10:09:08 [INFO]: Epoch 010 - training loss: 0.7171, validation loss: 0.3897
2024-05-24 10:09:20 [INFO]: Epoch 011 - training loss: 0.7069, validation loss: 0.3876
2024-05-24 10:09:32 [INFO]: Epoch 012 - training loss: 0.6986, validation loss: 0.3857
2024-05-24 10:09:44 [INFO]: Epoch 013 - training loss: 0.6925, validation loss: 0.3848
2024-05-24 10:09:56 [INFO]: Epoch 014 - training loss: 0.6855, validation loss: 0.3810
2024-05-24 10:10:08 [INFO]: Epoch 015 - training loss: 0.6791, validation loss: 0.3819
2024-05-24 10:10:20 [INFO]: Epoch 016 - training loss: 0.6749, validation loss: 0.3798
2024-05-24 10:10:31 [INFO]: Epoch 017 - training loss: 0.6697, validation loss: 0.3767
2024-05-24 10:10:43 [INFO]: Epoch 018 - training loss: 0.6655, validation loss: 0.3772
2024-05-24 10:10:55 [INFO]: Epoch 019 - training loss: 0.6617, validation loss: 0.3748
2024-05-24 10:11:07 [INFO]: Epoch 020 - training loss: 0.6595, validation loss: 0.3756
2024-05-24 10:11:19 [INFO]: Epoch 021 - training loss: 0.6545, validation loss: 0.3726
2024-05-24 10:11:31 [INFO]: Epoch 022 - training loss: 0.6514, validation loss: 0.3738
2024-05-24 10:11:43 [INFO]: Epoch 023 - training loss: 0.6487, validation loss: 0.3722
2024-05-24 10:11:55 [INFO]: Epoch 024 - training loss: 0.6455, validation loss: 0.3722
2024-05-24 10:12:07 [INFO]: Epoch 025 - training loss: 0.6425, validation loss: 0.3716
2024-05-24 10:12:19 [INFO]: Epoch 026 - training loss: 0.6393, validation loss: 0.3715
2024-05-24 10:12:31 [INFO]: Epoch 027 - training loss: 0.6362, validation loss: 0.3724
2024-05-24 10:12:43 [INFO]: Epoch 028 - training loss: 0.6350, validation loss: 0.3712
2024-05-24 10:12:54 [INFO]: Epoch 029 - training loss: 0.6336, validation loss: 0.3700
2024-05-24 10:13:06 [INFO]: Epoch 030 - training loss: 0.6293, validation loss: 0.3708
2024-05-24 10:13:18 [INFO]: Epoch 031 - training loss: 0.6297, validation loss: 0.3713
2024-05-24 10:13:30 [INFO]: Epoch 032 - training loss: 0.6282, validation loss: 0.3717
2024-05-24 10:13:42 [INFO]: Epoch 033 - training loss: 0.6217, validation loss: 0.3699
2024-05-24 10:13:54 [INFO]: Epoch 034 - training loss: 0.6186, validation loss: 0.3700
2024-05-24 10:14:06 [INFO]: Epoch 035 - training loss: 0.6155, validation loss: 0.3709
2024-05-24 10:14:18 [INFO]: Epoch 036 - training loss: 0.6133, validation loss: 0.3695
2024-05-24 10:14:30 [INFO]: Epoch 037 - training loss: 0.6114, validation loss: 0.3701
2024-05-24 10:14:41 [INFO]: Epoch 038 - training loss: 0.6083, validation loss: 0.3711
2024-05-24 10:14:53 [INFO]: Epoch 039 - training loss: 0.6046, validation loss: 0.3703
2024-05-24 10:15:05 [INFO]: Epoch 040 - training loss: 0.6026, validation loss: 0.3717
2024-05-24 10:15:17 [INFO]: Epoch 041 - training loss: 0.5992, validation loss: 0.3712
2024-05-24 10:15:29 [INFO]: Epoch 042 - training loss: 0.5977, validation loss: 0.3726
2024-05-24 10:15:41 [INFO]: Epoch 043 - training loss: 0.5977, validation loss: 0.3730
2024-05-24 10:15:53 [INFO]: Epoch 044 - training loss: 0.5940, validation loss: 0.3726
2024-05-24 10:16:05 [INFO]: Epoch 045 - training loss: 0.5944, validation loss: 0.3747
2024-05-24 10:16:17 [INFO]: Epoch 046 - training loss: 0.5973, validation loss: 0.3738
2024-05-24 10:16:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:16:17 [INFO]: Finished training. The best model is from epoch#36.
2024-05-24 10:16:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T100706/BRITS.pypots
2024-05-24 10:16:19 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2583, MSE=0.2553
2024-05-24 10:16:29 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 10:16:29 [INFO]: Using the given device: cuda:0
2024-05-24 10:16:29 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629
2024-05-24 10:16:29 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/tensorboard
2024-05-24 10:16:29 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 10:16:35 [INFO]: Epoch 001 - training loss: 1.2354, validation loss: 0.9995
2024-05-24 10:16:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch1_loss0.9995017558336258.pypots
2024-05-24 10:16:37 [INFO]: Epoch 002 - training loss: 0.7764, validation loss: 0.9714
2024-05-24 10:16:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch2_loss0.9714371532201767.pypots
2024-05-24 10:16:40 [INFO]: Epoch 003 - training loss: 0.6328, validation loss: 0.9512
2024-05-24 10:16:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch3_loss0.95120210647583.pypots
2024-05-24 10:16:43 [INFO]: Epoch 004 - training loss: 0.5835, validation loss: 0.9384
2024-05-24 10:16:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch4_loss0.938374537229538.pypots
2024-05-24 10:16:46 [INFO]: Epoch 005 - training loss: 0.5549, validation loss: 0.9310
2024-05-24 10:16:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch5_loss0.9309856444597244.pypots
2024-05-24 10:16:48 [INFO]: Epoch 006 - training loss: 0.5250, validation loss: 0.9265
2024-05-24 10:16:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch6_loss0.9264688611030578.pypots
2024-05-24 10:16:51 [INFO]: Epoch 007 - training loss: 0.5187, validation loss: 0.9241
2024-05-24 10:16:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch7_loss0.9240619033575058.pypots
2024-05-24 10:16:54 [INFO]: Epoch 008 - training loss: 0.5008, validation loss: 0.9221
2024-05-24 10:16:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch8_loss0.9221108078956604.pypots
2024-05-24 10:16:57 [INFO]: Epoch 009 - training loss: 0.4980, validation loss: 0.9253
2024-05-24 10:16:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch9_loss0.9253288745880127.pypots
2024-05-24 10:16:59 [INFO]: Epoch 010 - training loss: 0.4770, validation loss: 0.9218
2024-05-24 10:16:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch10_loss0.9217914938926697.pypots
2024-05-24 10:17:02 [INFO]: Epoch 011 - training loss: 0.4761, validation loss: 0.9223
2024-05-24 10:17:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch11_loss0.9222819596529007.pypots
2024-05-24 10:17:05 [INFO]: Epoch 012 - training loss: 0.4692, validation loss: 0.9235
2024-05-24 10:17:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch12_loss0.9234667450189591.pypots
2024-05-24 10:17:08 [INFO]: Epoch 013 - training loss: 0.4656, validation loss: 0.9242
2024-05-24 10:17:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch13_loss0.9241851210594177.pypots
2024-05-24 10:17:11 [INFO]: Epoch 014 - training loss: 0.4637, validation loss: 0.9259
2024-05-24 10:17:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch14_loss0.92592354118824.pypots
2024-05-24 10:17:13 [INFO]: Epoch 015 - training loss: 0.4613, validation loss: 0.9280
2024-05-24 10:17:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch15_loss0.9279964625835418.pypots
2024-05-24 10:17:16 [INFO]: Epoch 016 - training loss: 0.4477, validation loss: 0.9282
2024-05-24 10:17:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch16_loss0.9281966000795364.pypots
2024-05-24 10:17:19 [INFO]: Epoch 017 - training loss: 0.4470, validation loss: 0.9291
2024-05-24 10:17:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch17_loss0.9290988981723786.pypots
2024-05-24 10:17:22 [INFO]: Epoch 018 - training loss: 0.4432, validation loss: 0.9303
2024-05-24 10:17:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch18_loss0.9303460717201233.pypots
2024-05-24 10:17:24 [INFO]: Epoch 019 - training loss: 0.4555, validation loss: 0.9331
2024-05-24 10:17:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch19_loss0.9331032931804657.pypots
2024-05-24 10:17:27 [INFO]: Epoch 020 - training loss: 0.4442, validation loss: 0.9339
2024-05-24 10:17:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN_epoch20_loss0.9338959634304047.pypots
2024-05-24 10:17:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:17:27 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 10:17:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T101629/MRNN.pypots
2024-05-24 10:17:28 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6887, MSE=0.8984
2024-05-24 10:17:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 10:17:32 [INFO]: Using the given device: cpu
2024-05-24 10:17:32 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4036, MSE=0.5059
2024-05-24 10:17:32 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_physionet_2012_seta".
2024-05-24 10:17:33 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 10:17:33 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6901, MSE=1.0191
2024-05-24 10:17:33 [INFO]: Successfully created the given path "saved_results/round_4/Median_physionet_2012_seta".
2024-05-24 10:17:33 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_physionet_2012_seta/imputation.pkl
2024-05-24 10:17:33 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7055, MSE=0.9762
2024-05-24 10:17:33 [INFO]: Successfully created the given path "saved_results/round_4/Mean_physionet_2012_seta".
2024-05-24 10:17:33 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 10:17:33 [INFO]: 
SAITS on data/physionet_2012_seta: MAE=0.267±0.0022820207661863766, MSE=0.287±0.0013011028301313633
Transformer on data/physionet_2012_seta: MAE=0.283±0.0017462945211948666, MSE=0.301±0.0048668867298592025
TimesNet on data/physionet_2012_seta: MAE=0.288±0.002061504479423177, MSE=0.278±0.006637029915177888
CSDI on data/physionet_2012_seta: MAE=0.237±0.0060010536074733235, MSE=0.302±0.05688000820397553
GPVAE on data/physionet_2012_seta: MAE=0.399±0.0019490514839741295, MSE=0.402±0.004257452698317413
USGAN on data/physionet_2012_seta: MAE=0.294±0.0028722798498627246, MSE=0.261±0.003933140304345233
BRITS on data/physionet_2012_seta: MAE=0.257±0.0005087934392842191, MSE=0.256±0.0007443002383633998
MRNN on data/physionet_2012_seta: MAE=0.688±0.001086754980364226, MSE=0.899±0.0007121978150188678
LOCF on data/physionet_2012_seta: MAE=0.404±0.0, MSE=0.506±0.0
Median on data/physionet_2012_seta: MAE=0.690±0.0, MSE=1.019±0.0
Mean on data/physionet_2012_seta: MAE=0.706±0.0, MSE=0.976±0.0