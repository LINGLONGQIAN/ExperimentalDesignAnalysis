2024-05-25 03:57:11 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 03:57:11 [INFO]: Using the given device: cuda:0
2024-05-25 03:57:11 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T035711
2024-05-25 03:57:11 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T035711/tensorboard
2024-05-25 03:57:11 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 03:57:13 [INFO]: Epoch 001 - training loss: 1.1857, validation loss: 0.2501
2024-05-25 03:57:13 [INFO]: Epoch 002 - training loss: 0.8908, validation loss: 0.1324
2024-05-25 03:57:14 [INFO]: Epoch 003 - training loss: 0.7514, validation loss: 0.0862
2024-05-25 03:57:14 [INFO]: Epoch 004 - training loss: 0.7148, validation loss: 0.0838
2024-05-25 03:57:15 [INFO]: Epoch 005 - training loss: 0.6800, validation loss: 0.1032
2024-05-25 03:57:15 [INFO]: Epoch 006 - training loss: 0.6788, validation loss: 0.0748
2024-05-25 03:57:16 [INFO]: Epoch 007 - training loss: 0.6448, validation loss: 0.0607
2024-05-25 03:57:16 [INFO]: Epoch 008 - training loss: 0.6237, validation loss: 0.0794
2024-05-25 03:57:17 [INFO]: Epoch 009 - training loss: 0.6268, validation loss: 0.0612
2024-05-25 03:57:17 [INFO]: Epoch 010 - training loss: 0.6216, validation loss: 0.0671
2024-05-25 03:57:18 [INFO]: Epoch 011 - training loss: 0.5940, validation loss: 0.0578
2024-05-25 03:57:18 [INFO]: Epoch 012 - training loss: 0.5728, validation loss: 0.0632
2024-05-25 03:57:19 [INFO]: Epoch 013 - training loss: 0.5676, validation loss: 0.0573
2024-05-25 03:57:19 [INFO]: Epoch 014 - training loss: 0.5612, validation loss: 0.0527
2024-05-25 03:57:20 [INFO]: Epoch 015 - training loss: 0.5493, validation loss: 0.0558
2024-05-25 03:57:20 [INFO]: Epoch 016 - training loss: 0.5545, validation loss: 0.0440
2024-05-25 03:57:21 [INFO]: Epoch 017 - training loss: 0.5656, validation loss: 0.0453
2024-05-25 03:57:21 [INFO]: Epoch 018 - training loss: 0.5386, validation loss: 0.0447
2024-05-25 03:57:21 [INFO]: Epoch 019 - training loss: 0.5589, validation loss: 0.0478
2024-05-25 03:57:22 [INFO]: Epoch 020 - training loss: 0.5437, validation loss: 0.0507
2024-05-25 03:57:22 [INFO]: Epoch 021 - training loss: 0.5407, validation loss: 0.0421
2024-05-25 03:57:23 [INFO]: Epoch 022 - training loss: 0.5359, validation loss: 0.0493
2024-05-25 03:57:23 [INFO]: Epoch 023 - training loss: 0.5194, validation loss: 0.0444
2024-05-25 03:57:24 [INFO]: Epoch 024 - training loss: 0.5137, validation loss: 0.0491
2024-05-25 03:57:24 [INFO]: Epoch 025 - training loss: 0.5156, validation loss: 0.0359
2024-05-25 03:57:25 [INFO]: Epoch 026 - training loss: 0.5095, validation loss: 0.0452
2024-05-25 03:57:25 [INFO]: Epoch 027 - training loss: 0.5055, validation loss: 0.0375
2024-05-25 03:57:26 [INFO]: Epoch 028 - training loss: 0.4905, validation loss: 0.0597
2024-05-25 03:57:26 [INFO]: Epoch 029 - training loss: 0.4960, validation loss: 0.0588
2024-05-25 03:57:27 [INFO]: Epoch 030 - training loss: 0.5100, validation loss: 0.0396
2024-05-25 03:57:27 [INFO]: Epoch 031 - training loss: 0.5213, validation loss: 0.0394
2024-05-25 03:57:28 [INFO]: Epoch 032 - training loss: 0.4983, validation loss: 0.0430
2024-05-25 03:57:28 [INFO]: Epoch 033 - training loss: 0.4769, validation loss: 0.0390
2024-05-25 03:57:29 [INFO]: Epoch 034 - training loss: 0.4774, validation loss: 0.0377
2024-05-25 03:57:29 [INFO]: Epoch 035 - training loss: 0.4675, validation loss: 0.0356
2024-05-25 03:57:30 [INFO]: Epoch 036 - training loss: 0.4631, validation loss: 0.0339
2024-05-25 03:57:30 [INFO]: Epoch 037 - training loss: 0.4726, validation loss: 0.0383
2024-05-25 03:57:31 [INFO]: Epoch 038 - training loss: 0.4546, validation loss: 0.0352
2024-05-25 03:57:31 [INFO]: Epoch 039 - training loss: 0.4493, validation loss: 0.0399
2024-05-25 03:57:32 [INFO]: Epoch 040 - training loss: 0.4461, validation loss: 0.0361
2024-05-25 03:57:32 [INFO]: Epoch 041 - training loss: 0.4440, validation loss: 0.0522
2024-05-25 03:57:33 [INFO]: Epoch 042 - training loss: 0.4287, validation loss: 0.0419
2024-05-25 03:57:33 [INFO]: Epoch 043 - training loss: 0.4266, validation loss: 0.0377
2024-05-25 03:57:34 [INFO]: Epoch 044 - training loss: 0.4320, validation loss: 0.0347
2024-05-25 03:57:34 [INFO]: Epoch 045 - training loss: 0.4197, validation loss: 0.0390
2024-05-25 03:57:35 [INFO]: Epoch 046 - training loss: 0.4129, validation loss: 0.0368
2024-05-25 03:57:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:57:35 [INFO]: Finished training. The best model is from epoch#36.
2024-05-25 03:57:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_ettm1/20240525_T035711/SAITS.pypots
2024-05-25 03:57:35 [INFO]: SAITS on ETTm1: MAE=0.1774, MSE=0.0585
2024-05-25 03:57:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-25 03:57:35 [INFO]: Using the given device: cuda:0
2024-05-25 03:57:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T035735
2024-05-25 03:57:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T035735/tensorboard
2024-05-25 03:57:35 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 03:57:35 [INFO]: Epoch 001 - training loss: 1.1347, validation loss: 0.2993
2024-05-25 03:57:35 [INFO]: Epoch 002 - training loss: 0.6581, validation loss: 0.1385
2024-05-25 03:57:35 [INFO]: Epoch 003 - training loss: 0.5099, validation loss: 0.1004
2024-05-25 03:57:36 [INFO]: Epoch 004 - training loss: 0.4647, validation loss: 0.0879
2024-05-25 03:57:36 [INFO]: Epoch 005 - training loss: 0.4415, validation loss: 0.0759
2024-05-25 03:57:36 [INFO]: Epoch 006 - training loss: 0.4054, validation loss: 0.0766
2024-05-25 03:57:36 [INFO]: Epoch 007 - training loss: 0.4124, validation loss: 0.0614
2024-05-25 03:57:36 [INFO]: Epoch 008 - training loss: 0.3953, validation loss: 0.0571
2024-05-25 03:57:37 [INFO]: Epoch 009 - training loss: 0.3847, validation loss: 0.0567
2024-05-25 03:57:37 [INFO]: Epoch 010 - training loss: 0.3786, validation loss: 0.0587
2024-05-25 03:57:37 [INFO]: Epoch 011 - training loss: 0.3668, validation loss: 0.0519
2024-05-25 03:57:37 [INFO]: Epoch 012 - training loss: 0.3487, validation loss: 0.0493
2024-05-25 03:57:37 [INFO]: Epoch 013 - training loss: 0.3428, validation loss: 0.0456
2024-05-25 03:57:38 [INFO]: Epoch 014 - training loss: 0.3426, validation loss: 0.0519
2024-05-25 03:57:38 [INFO]: Epoch 015 - training loss: 0.3476, validation loss: 0.0474
2024-05-25 03:57:38 [INFO]: Epoch 016 - training loss: 0.3257, validation loss: 0.0403
2024-05-25 03:57:38 [INFO]: Epoch 017 - training loss: 0.3142, validation loss: 0.0458
2024-05-25 03:57:38 [INFO]: Epoch 018 - training loss: 0.3194, validation loss: 0.0426
2024-05-25 03:57:39 [INFO]: Epoch 019 - training loss: 0.3188, validation loss: 0.0387
2024-05-25 03:57:39 [INFO]: Epoch 020 - training loss: 0.3090, validation loss: 0.0385
2024-05-25 03:57:39 [INFO]: Epoch 021 - training loss: 0.3024, validation loss: 0.0393
2024-05-25 03:57:39 [INFO]: Epoch 022 - training loss: 0.3008, validation loss: 0.0409
2024-05-25 03:57:39 [INFO]: Epoch 023 - training loss: 0.2928, validation loss: 0.0369
2024-05-25 03:57:40 [INFO]: Epoch 024 - training loss: 0.2840, validation loss: 0.0366
2024-05-25 03:57:40 [INFO]: Epoch 025 - training loss: 0.2885, validation loss: 0.0399
2024-05-25 03:57:40 [INFO]: Epoch 026 - training loss: 0.2974, validation loss: 0.0388
2024-05-25 03:57:40 [INFO]: Epoch 027 - training loss: 0.2900, validation loss: 0.0350
2024-05-25 03:57:40 [INFO]: Epoch 028 - training loss: 0.2819, validation loss: 0.0381
2024-05-25 03:57:41 [INFO]: Epoch 029 - training loss: 0.2796, validation loss: 0.0330
2024-05-25 03:57:41 [INFO]: Epoch 030 - training loss: 0.2768, validation loss: 0.0423
2024-05-25 03:57:41 [INFO]: Epoch 031 - training loss: 0.2857, validation loss: 0.0404
2024-05-25 03:57:41 [INFO]: Epoch 032 - training loss: 0.2785, validation loss: 0.0337
2024-05-25 03:57:41 [INFO]: Epoch 033 - training loss: 0.2731, validation loss: 0.0332
2024-05-25 03:57:42 [INFO]: Epoch 034 - training loss: 0.2659, validation loss: 0.0318
2024-05-25 03:57:42 [INFO]: Epoch 035 - training loss: 0.2646, validation loss: 0.0343
2024-05-25 03:57:42 [INFO]: Epoch 036 - training loss: 0.2670, validation loss: 0.0317
2024-05-25 03:57:42 [INFO]: Epoch 037 - training loss: 0.2566, validation loss: 0.0308
2024-05-25 03:57:42 [INFO]: Epoch 038 - training loss: 0.2571, validation loss: 0.0325
2024-05-25 03:57:43 [INFO]: Epoch 039 - training loss: 0.2603, validation loss: 0.0326
2024-05-25 03:57:43 [INFO]: Epoch 040 - training loss: 0.2534, validation loss: 0.0322
2024-05-25 03:57:43 [INFO]: Epoch 041 - training loss: 0.2585, validation loss: 0.0319
2024-05-25 03:57:43 [INFO]: Epoch 042 - training loss: 0.2480, validation loss: 0.0302
2024-05-25 03:57:43 [INFO]: Epoch 043 - training loss: 0.2459, validation loss: 0.0299
2024-05-25 03:57:43 [INFO]: Epoch 044 - training loss: 0.2452, validation loss: 0.0336
2024-05-25 03:57:44 [INFO]: Epoch 045 - training loss: 0.2495, validation loss: 0.0295
2024-05-25 03:57:44 [INFO]: Epoch 046 - training loss: 0.2449, validation loss: 0.0303
2024-05-25 03:57:44 [INFO]: Epoch 047 - training loss: 0.2432, validation loss: 0.0296
2024-05-25 03:57:44 [INFO]: Epoch 048 - training loss: 0.2464, validation loss: 0.0293
2024-05-25 03:57:44 [INFO]: Epoch 049 - training loss: 0.2375, validation loss: 0.0291
2024-05-25 03:57:45 [INFO]: Epoch 050 - training loss: 0.2410, validation loss: 0.0289
2024-05-25 03:57:45 [INFO]: Epoch 051 - training loss: 0.2387, validation loss: 0.0281
2024-05-25 03:57:45 [INFO]: Epoch 052 - training loss: 0.2339, validation loss: 0.0329
2024-05-25 03:57:45 [INFO]: Epoch 053 - training loss: 0.2448, validation loss: 0.0282
2024-05-25 03:57:45 [INFO]: Epoch 054 - training loss: 0.2368, validation loss: 0.0266
2024-05-25 03:57:46 [INFO]: Epoch 055 - training loss: 0.2323, validation loss: 0.0297
2024-05-25 03:57:46 [INFO]: Epoch 056 - training loss: 0.2325, validation loss: 0.0299
2024-05-25 03:57:46 [INFO]: Epoch 057 - training loss: 0.2314, validation loss: 0.0300
2024-05-25 03:57:46 [INFO]: Epoch 058 - training loss: 0.2303, validation loss: 0.0285
2024-05-25 03:57:46 [INFO]: Epoch 059 - training loss: 0.2219, validation loss: 0.0273
2024-05-25 03:57:47 [INFO]: Epoch 060 - training loss: 0.2208, validation loss: 0.0260
2024-05-25 03:57:47 [INFO]: Epoch 061 - training loss: 0.2150, validation loss: 0.0266
2024-05-25 03:57:47 [INFO]: Epoch 062 - training loss: 0.2245, validation loss: 0.0265
2024-05-25 03:57:47 [INFO]: Epoch 063 - training loss: 0.2244, validation loss: 0.0278
2024-05-25 03:57:47 [INFO]: Epoch 064 - training loss: 0.2235, validation loss: 0.0260
2024-05-25 03:57:48 [INFO]: Epoch 065 - training loss: 0.2220, validation loss: 0.0290
2024-05-25 03:57:48 [INFO]: Epoch 066 - training loss: 0.2206, validation loss: 0.0284
2024-05-25 03:57:48 [INFO]: Epoch 067 - training loss: 0.2115, validation loss: 0.0269
2024-05-25 03:57:48 [INFO]: Epoch 068 - training loss: 0.2096, validation loss: 0.0287
2024-05-25 03:57:48 [INFO]: Epoch 069 - training loss: 0.2186, validation loss: 0.0276
2024-05-25 03:57:49 [INFO]: Epoch 070 - training loss: 0.2106, validation loss: 0.0282
2024-05-25 03:57:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:57:49 [INFO]: Finished training. The best model is from epoch#60.
2024-05-25 03:57:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_ettm1/20240525_T035735/Transformer.pypots
2024-05-25 03:57:49 [INFO]: Transformer on ETTm1: MAE=0.1563, MSE=0.0457
2024-05-25 03:57:49 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-25 03:57:49 [INFO]: Using the given device: cuda:0
2024-05-25 03:57:49 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T035749
2024-05-25 03:57:49 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T035749/tensorboard
2024-05-25 03:57:49 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 03:57:50 [INFO]: Epoch 001 - training loss: 0.1503, validation loss: 0.0536
2024-05-25 03:57:50 [INFO]: Epoch 002 - training loss: 0.0638, validation loss: 0.0385
2024-05-25 03:57:51 [INFO]: Epoch 003 - training loss: 0.0471, validation loss: 0.0305
2024-05-25 03:57:51 [INFO]: Epoch 004 - training loss: 0.0386, validation loss: 0.0283
2024-05-25 03:57:51 [INFO]: Epoch 005 - training loss: 0.0347, validation loss: 0.0275
2024-05-25 03:57:51 [INFO]: Epoch 006 - training loss: 0.0312, validation loss: 0.0253
2024-05-25 03:57:51 [INFO]: Epoch 007 - training loss: 0.0305, validation loss: 0.0247
2024-05-25 03:57:52 [INFO]: Epoch 008 - training loss: 0.0315, validation loss: 0.0238
2024-05-25 03:57:52 [INFO]: Epoch 009 - training loss: 0.0291, validation loss: 0.0234
2024-05-25 03:57:52 [INFO]: Epoch 010 - training loss: 0.0266, validation loss: 0.0238
2024-05-25 03:57:52 [INFO]: Epoch 011 - training loss: 0.0280, validation loss: 0.0230
2024-05-25 03:57:52 [INFO]: Epoch 012 - training loss: 0.0265, validation loss: 0.0240
2024-05-25 03:57:53 [INFO]: Epoch 013 - training loss: 0.0276, validation loss: 0.0238
2024-05-25 03:57:53 [INFO]: Epoch 014 - training loss: 0.0263, validation loss: 0.0226
2024-05-25 03:57:53 [INFO]: Epoch 015 - training loss: 0.0249, validation loss: 0.0216
2024-05-25 03:57:53 [INFO]: Epoch 016 - training loss: 0.0234, validation loss: 0.0219
2024-05-25 03:57:53 [INFO]: Epoch 017 - training loss: 0.0228, validation loss: 0.0222
2024-05-25 03:57:53 [INFO]: Epoch 018 - training loss: 0.0246, validation loss: 0.0233
2024-05-25 03:57:54 [INFO]: Epoch 019 - training loss: 0.0324, validation loss: 0.0250
2024-05-25 03:57:54 [INFO]: Epoch 020 - training loss: 0.0273, validation loss: 0.0235
2024-05-25 03:57:54 [INFO]: Epoch 021 - training loss: 0.0228, validation loss: 0.0217
2024-05-25 03:57:54 [INFO]: Epoch 022 - training loss: 0.0216, validation loss: 0.0217
2024-05-25 03:57:54 [INFO]: Epoch 023 - training loss: 0.0207, validation loss: 0.0219
2024-05-25 03:57:55 [INFO]: Epoch 024 - training loss: 0.0206, validation loss: 0.0218
2024-05-25 03:57:55 [INFO]: Epoch 025 - training loss: 0.0254, validation loss: 0.0222
2024-05-25 03:57:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:57:55 [INFO]: Finished training. The best model is from epoch#15.
2024-05-25 03:57:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240525_T035749/TimesNet.pypots
2024-05-25 03:57:55 [INFO]: TimesNet on ETTm1: MAE=0.1013, MSE=0.0226
2024-05-25 03:57:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-25 03:57:55 [INFO]: Using the given device: cuda:0
2024-05-25 03:57:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755
2024-05-25 03:57:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/tensorboard
2024-05-25 03:57:55 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 03:57:57 [INFO]: Epoch 001 - training loss: 0.6755, validation loss: 0.4523
2024-05-25 03:57:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch1_loss0.45228323340415955.pypots
2024-05-25 03:57:59 [INFO]: Epoch 002 - training loss: 0.3803, validation loss: 0.3928
2024-05-25 03:57:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch2_loss0.3928450718522072.pypots
2024-05-25 03:58:01 [INFO]: Epoch 003 - training loss: 0.3499, validation loss: 0.3952
2024-05-25 03:58:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch3_loss0.3951801434159279.pypots
2024-05-25 03:58:03 [INFO]: Epoch 004 - training loss: 0.3250, validation loss: 0.3199
2024-05-25 03:58:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch4_loss0.31991078704595566.pypots
2024-05-25 03:58:06 [INFO]: Epoch 005 - training loss: 0.2992, validation loss: 0.2918
2024-05-25 03:58:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch5_loss0.29184482991695404.pypots
2024-05-25 03:58:08 [INFO]: Epoch 006 - training loss: 0.3141, validation loss: 0.2821
2024-05-25 03:58:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch6_loss0.28205008059740067.pypots
2024-05-25 03:58:10 [INFO]: Epoch 007 - training loss: 0.2631, validation loss: 0.2791
2024-05-25 03:58:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch7_loss0.2791234254837036.pypots
2024-05-25 03:58:12 [INFO]: Epoch 008 - training loss: 0.2608, validation loss: 0.2628
2024-05-25 03:58:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch8_loss0.26276054233312607.pypots
2024-05-25 03:58:14 [INFO]: Epoch 009 - training loss: 0.2685, validation loss: 0.2580
2024-05-25 03:58:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch9_loss0.25799985229969025.pypots
2024-05-25 03:58:16 [INFO]: Epoch 010 - training loss: 0.2587, validation loss: 0.2532
2024-05-25 03:58:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch10_loss0.2532311715185642.pypots
2024-05-25 03:58:18 [INFO]: Epoch 011 - training loss: 0.2254, validation loss: 0.2445
2024-05-25 03:58:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch11_loss0.24451660737395287.pypots
2024-05-25 03:58:20 [INFO]: Epoch 012 - training loss: 0.2256, validation loss: 0.2393
2024-05-25 03:58:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch12_loss0.23930807411670685.pypots
2024-05-25 03:58:22 [INFO]: Epoch 013 - training loss: 0.2514, validation loss: 0.2330
2024-05-25 03:58:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch13_loss0.2330230437219143.pypots
2024-05-25 03:58:24 [INFO]: Epoch 014 - training loss: 0.2325, validation loss: 0.2346
2024-05-25 03:58:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch14_loss0.23455027863383293.pypots
2024-05-25 03:58:26 [INFO]: Epoch 015 - training loss: 0.2338, validation loss: 0.2189
2024-05-25 03:58:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch15_loss0.2188999056816101.pypots
2024-05-25 03:58:28 [INFO]: Epoch 016 - training loss: 0.2059, validation loss: 0.2130
2024-05-25 03:58:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch16_loss0.2130223736166954.pypots
2024-05-25 03:58:30 [INFO]: Epoch 017 - training loss: 0.2357, validation loss: 0.2236
2024-05-25 03:58:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch17_loss0.22357400506734848.pypots
2024-05-25 03:58:32 [INFO]: Epoch 018 - training loss: 0.2531, validation loss: 0.2385
2024-05-25 03:58:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch18_loss0.23854979127645493.pypots
2024-05-25 03:58:34 [INFO]: Epoch 019 - training loss: 0.2989, validation loss: 0.2389
2024-05-25 03:58:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch19_loss0.23892715945839882.pypots
2024-05-25 03:58:36 [INFO]: Epoch 020 - training loss: 0.2376, validation loss: 0.2114
2024-05-25 03:58:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch20_loss0.21140941232442856.pypots
2024-05-25 03:58:38 [INFO]: Epoch 021 - training loss: 0.2075, validation loss: 0.1962
2024-05-25 03:58:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch21_loss0.19623937085270882.pypots
2024-05-25 03:58:40 [INFO]: Epoch 022 - training loss: 0.2068, validation loss: 0.1931
2024-05-25 03:58:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch22_loss0.19310066103935242.pypots
2024-05-25 03:58:42 [INFO]: Epoch 023 - training loss: 0.2438, validation loss: 0.2111
2024-05-25 03:58:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch23_loss0.2111005000770092.pypots
2024-05-25 03:58:45 [INFO]: Epoch 024 - training loss: 0.2150, validation loss: 0.2030
2024-05-25 03:58:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch24_loss0.20300580188632011.pypots
2024-05-25 03:58:47 [INFO]: Epoch 025 - training loss: 0.2284, validation loss: 0.2102
2024-05-25 03:58:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch25_loss0.2101864442229271.pypots
2024-05-25 03:58:49 [INFO]: Epoch 026 - training loss: 0.2276, validation loss: 0.1893
2024-05-25 03:58:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch26_loss0.1892690509557724.pypots
2024-05-25 03:58:51 [INFO]: Epoch 027 - training loss: 0.1922, validation loss: 0.1884
2024-05-25 03:58:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch27_loss0.1884140931069851.pypots
2024-05-25 03:58:53 [INFO]: Epoch 028 - training loss: 0.1979, validation loss: 0.1815
2024-05-25 03:58:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch28_loss0.18154047429561615.pypots
2024-05-25 03:58:55 [INFO]: Epoch 029 - training loss: 0.2366, validation loss: 0.1905
2024-05-25 03:58:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch29_loss0.19046412408351898.pypots
2024-05-25 03:58:57 [INFO]: Epoch 030 - training loss: 0.1904, validation loss: 0.1881
2024-05-25 03:58:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch30_loss0.18809720873832703.pypots
2024-05-25 03:58:59 [INFO]: Epoch 031 - training loss: 0.1961, validation loss: 0.1879
2024-05-25 03:58:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch31_loss0.1879081092774868.pypots
2024-05-25 03:59:01 [INFO]: Epoch 032 - training loss: 0.1776, validation loss: 0.1802
2024-05-25 03:59:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch32_loss0.1802290640771389.pypots
2024-05-25 03:59:03 [INFO]: Epoch 033 - training loss: 0.2288, validation loss: 0.1769
2024-05-25 03:59:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch33_loss0.17687073722481728.pypots
2024-05-25 03:59:05 [INFO]: Epoch 034 - training loss: 0.1674, validation loss: 0.1839
2024-05-25 03:59:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch34_loss0.18385165929794312.pypots
2024-05-25 03:59:07 [INFO]: Epoch 035 - training loss: 0.1885, validation loss: 0.1759
2024-05-25 03:59:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch35_loss0.17588254809379578.pypots
2024-05-25 03:59:09 [INFO]: Epoch 036 - training loss: 0.1831, validation loss: 0.1777
2024-05-25 03:59:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch36_loss0.1776847019791603.pypots
2024-05-25 03:59:11 [INFO]: Epoch 037 - training loss: 0.1784, validation loss: 0.1782
2024-05-25 03:59:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch37_loss0.17823156714439392.pypots
2024-05-25 03:59:13 [INFO]: Epoch 038 - training loss: 0.1802, validation loss: 0.1665
2024-05-25 03:59:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch38_loss0.16654517129063606.pypots
2024-05-25 03:59:15 [INFO]: Epoch 039 - training loss: 0.1757, validation loss: 0.1610
2024-05-25 03:59:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch39_loss0.16103718802332878.pypots
2024-05-25 03:59:17 [INFO]: Epoch 040 - training loss: 0.1660, validation loss: 0.1593
2024-05-25 03:59:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch40_loss0.15931997820734978.pypots
2024-05-25 03:59:19 [INFO]: Epoch 041 - training loss: 0.1661, validation loss: 0.1596
2024-05-25 03:59:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch41_loss0.15956288948655128.pypots
2024-05-25 03:59:21 [INFO]: Epoch 042 - training loss: 0.2145, validation loss: 0.1576
2024-05-25 03:59:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch42_loss0.1575794406235218.pypots
2024-05-25 03:59:24 [INFO]: Epoch 043 - training loss: 0.1574, validation loss: 0.1593
2024-05-25 03:59:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch43_loss0.15932392701506615.pypots
2024-05-25 03:59:26 [INFO]: Epoch 044 - training loss: 0.1555, validation loss: 0.1572
2024-05-25 03:59:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch44_loss0.15721284225583076.pypots
2024-05-25 03:59:28 [INFO]: Epoch 045 - training loss: 0.1554, validation loss: 0.1530
2024-05-25 03:59:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch45_loss0.1530359648168087.pypots
2024-05-25 03:59:30 [INFO]: Epoch 046 - training loss: 0.1485, validation loss: 0.1564
2024-05-25 03:59:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch46_loss0.15640759840607643.pypots
2024-05-25 03:59:32 [INFO]: Epoch 047 - training loss: 0.1585, validation loss: 0.1499
2024-05-25 03:59:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch47_loss0.14987847208976746.pypots
2024-05-25 03:59:34 [INFO]: Epoch 048 - training loss: 0.1625, validation loss: 0.1555
2024-05-25 03:59:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch48_loss0.15545320510864258.pypots
2024-05-25 03:59:36 [INFO]: Epoch 049 - training loss: 0.1532, validation loss: 0.1491
2024-05-25 03:59:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch49_loss0.14911089837551117.pypots
2024-05-25 03:59:38 [INFO]: Epoch 050 - training loss: 0.1314, validation loss: 0.1502
2024-05-25 03:59:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch50_loss0.1502155400812626.pypots
2024-05-25 03:59:40 [INFO]: Epoch 051 - training loss: 0.1515, validation loss: 0.1490
2024-05-25 03:59:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch51_loss0.1489783078432083.pypots
2024-05-25 03:59:42 [INFO]: Epoch 052 - training loss: 0.1927, validation loss: 0.1661
2024-05-25 03:59:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch52_loss0.1660534366965294.pypots
2024-05-25 03:59:44 [INFO]: Epoch 053 - training loss: 0.1801, validation loss: 0.1650
2024-05-25 03:59:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch53_loss0.1649586595594883.pypots
2024-05-25 03:59:46 [INFO]: Epoch 054 - training loss: 0.1562, validation loss: 0.1537
2024-05-25 03:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch54_loss0.15365076065063477.pypots
2024-05-25 03:59:48 [INFO]: Epoch 055 - training loss: 0.1503, validation loss: 0.1452
2024-05-25 03:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch55_loss0.14521345123648643.pypots
2024-05-25 03:59:50 [INFO]: Epoch 056 - training loss: 0.1353, validation loss: 0.1446
2024-05-25 03:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch56_loss0.14462702348828316.pypots
2024-05-25 03:59:52 [INFO]: Epoch 057 - training loss: 0.1332, validation loss: 0.1455
2024-05-25 03:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch57_loss0.1454688385128975.pypots
2024-05-25 03:59:54 [INFO]: Epoch 058 - training loss: 0.1602, validation loss: 0.1486
2024-05-25 03:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch58_loss0.14863866567611694.pypots
2024-05-25 03:59:56 [INFO]: Epoch 059 - training loss: 0.1541, validation loss: 0.1452
2024-05-25 03:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch59_loss0.1451764889061451.pypots
2024-05-25 03:59:58 [INFO]: Epoch 060 - training loss: 0.1518, validation loss: 0.1464
2024-05-25 03:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch60_loss0.1463693603873253.pypots
2024-05-25 04:00:00 [INFO]: Epoch 061 - training loss: 0.1311, validation loss: 0.1444
2024-05-25 04:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch61_loss0.14440740644931793.pypots
2024-05-25 04:00:02 [INFO]: Epoch 062 - training loss: 0.2150, validation loss: 0.1424
2024-05-25 04:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch62_loss0.142431378364563.pypots
2024-05-25 04:00:05 [INFO]: Epoch 063 - training loss: 0.1451, validation loss: 0.1434
2024-05-25 04:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch63_loss0.14344606548547745.pypots
2024-05-25 04:00:07 [INFO]: Epoch 064 - training loss: 0.1593, validation loss: 0.1401
2024-05-25 04:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch64_loss0.140105988830328.pypots
2024-05-25 04:00:09 [INFO]: Epoch 065 - training loss: 0.1403, validation loss: 0.1360
2024-05-25 04:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch65_loss0.13604092225432396.pypots
2024-05-25 04:00:11 [INFO]: Epoch 066 - training loss: 0.1348, validation loss: 0.1367
2024-05-25 04:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch66_loss0.13672242686152458.pypots
2024-05-25 04:00:13 [INFO]: Epoch 067 - training loss: 0.1776, validation loss: 0.1397
2024-05-25 04:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch67_loss0.13973261043429375.pypots
2024-05-25 04:00:15 [INFO]: Epoch 068 - training loss: 0.1900, validation loss: 0.1586
2024-05-25 04:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch68_loss0.1586427018046379.pypots
2024-05-25 04:00:17 [INFO]: Epoch 069 - training loss: 0.1604, validation loss: 0.1721
2024-05-25 04:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch69_loss0.17205695807933807.pypots
2024-05-25 04:00:19 [INFO]: Epoch 070 - training loss: 0.1734, validation loss: 0.1667
2024-05-25 04:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch70_loss0.166657492518425.pypots
2024-05-25 04:00:21 [INFO]: Epoch 071 - training loss: 0.1513, validation loss: 0.1558
2024-05-25 04:00:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch71_loss0.15575093775987625.pypots
2024-05-25 04:00:23 [INFO]: Epoch 072 - training loss: 0.1660, validation loss: 0.1568
2024-05-25 04:00:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch72_loss0.15675125271081924.pypots
2024-05-25 04:00:25 [INFO]: Epoch 073 - training loss: 0.1583, validation loss: 0.1681
2024-05-25 04:00:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch73_loss0.168116495013237.pypots
2024-05-25 04:00:27 [INFO]: Epoch 074 - training loss: 0.1746, validation loss: 0.1468
2024-05-25 04:00:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch74_loss0.14683661609888077.pypots
2024-05-25 04:00:29 [INFO]: Epoch 075 - training loss: 0.1850, validation loss: 0.1570
2024-05-25 04:00:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI_epoch75_loss0.15703362599015236.pypots
2024-05-25 04:00:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:00:29 [INFO]: Finished training. The best model is from epoch#65.
2024-05-25 04:00:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240525_T035755/CSDI.pypots
2024-05-25 04:00:45 [INFO]: CSDI on ETTm1: MAE=0.1410, MSE=0.0408
2024-05-25 04:00:45 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-25 04:00:45 [INFO]: Using the given device: cuda:0
2024-05-25 04:00:45 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T040045
2024-05-25 04:00:45 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T040045/tensorboard
2024-05-25 04:00:45 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:00:45 [INFO]: Epoch 001 - training loss: 23929.5861, validation loss: 0.9628
2024-05-25 04:00:46 [INFO]: Epoch 002 - training loss: 21652.2728, validation loss: 0.9502
2024-05-25 04:00:46 [INFO]: Epoch 003 - training loss: 19689.9907, validation loss: 0.9405
2024-05-25 04:00:46 [INFO]: Epoch 004 - training loss: 17673.7529, validation loss: 0.9243
2024-05-25 04:00:46 [INFO]: Epoch 005 - training loss: 15754.8990, validation loss: 0.8734
2024-05-25 04:00:46 [INFO]: Epoch 006 - training loss: 14135.8270, validation loss: 0.7851
2024-05-25 04:00:46 [INFO]: Epoch 007 - training loss: 12922.5891, validation loss: 0.6687
2024-05-25 04:00:46 [INFO]: Epoch 008 - training loss: 11937.9266, validation loss: 0.5734
2024-05-25 04:00:47 [INFO]: Epoch 009 - training loss: 11417.5444, validation loss: 0.5151
2024-05-25 04:00:47 [INFO]: Epoch 010 - training loss: 11008.5283, validation loss: 0.4692
2024-05-25 04:00:47 [INFO]: Epoch 011 - training loss: 10812.2589, validation loss: 0.4473
2024-05-25 04:00:47 [INFO]: Epoch 012 - training loss: 10468.0121, validation loss: 0.4359
2024-05-25 04:00:47 [INFO]: Epoch 013 - training loss: 10314.3914, validation loss: 0.4166
2024-05-25 04:00:47 [INFO]: Epoch 014 - training loss: 10145.2657, validation loss: 0.3994
2024-05-25 04:00:47 [INFO]: Epoch 015 - training loss: 10066.2157, validation loss: 0.3742
2024-05-25 04:00:47 [INFO]: Epoch 016 - training loss: 9950.6387, validation loss: 0.3498
2024-05-25 04:00:48 [INFO]: Epoch 017 - training loss: 9887.6569, validation loss: 0.3201
2024-05-25 04:00:48 [INFO]: Epoch 018 - training loss: 9821.0391, validation loss: 0.2883
2024-05-25 04:00:48 [INFO]: Epoch 019 - training loss: 9759.0567, validation loss: 0.2728
2024-05-25 04:00:48 [INFO]: Epoch 020 - training loss: 9709.7507, validation loss: 0.2494
2024-05-25 04:00:48 [INFO]: Epoch 021 - training loss: 9684.6252, validation loss: 0.2406
2024-05-25 04:00:48 [INFO]: Epoch 022 - training loss: 9650.8794, validation loss: 0.2299
2024-05-25 04:00:48 [INFO]: Epoch 023 - training loss: 9620.2335, validation loss: 0.2226
2024-05-25 04:00:49 [INFO]: Epoch 024 - training loss: 9589.0367, validation loss: 0.2154
2024-05-25 04:00:49 [INFO]: Epoch 025 - training loss: 9577.1552, validation loss: 0.2083
2024-05-25 04:00:49 [INFO]: Epoch 026 - training loss: 9566.0618, validation loss: 0.1996
2024-05-25 04:00:49 [INFO]: Epoch 027 - training loss: 9533.7637, validation loss: 0.1969
2024-05-25 04:00:49 [INFO]: Epoch 028 - training loss: 9518.9355, validation loss: 0.1929
2024-05-25 04:00:49 [INFO]: Epoch 029 - training loss: 9502.1666, validation loss: 0.1938
2024-05-25 04:00:49 [INFO]: Epoch 030 - training loss: 9493.1457, validation loss: 0.1921
2024-05-25 04:00:50 [INFO]: Epoch 031 - training loss: 9480.0275, validation loss: 0.1862
2024-05-25 04:00:50 [INFO]: Epoch 032 - training loss: 9469.6976, validation loss: 0.1815
2024-05-25 04:00:50 [INFO]: Epoch 033 - training loss: 9472.3274, validation loss: 0.1806
2024-05-25 04:00:50 [INFO]: Epoch 034 - training loss: 9470.9808, validation loss: 0.1779
2024-05-25 04:00:50 [INFO]: Epoch 035 - training loss: 9448.0803, validation loss: 0.1732
2024-05-25 04:00:50 [INFO]: Epoch 036 - training loss: 9439.1223, validation loss: 0.1692
2024-05-25 04:00:50 [INFO]: Epoch 037 - training loss: 9432.7290, validation loss: 0.1681
2024-05-25 04:00:51 [INFO]: Epoch 038 - training loss: 9434.1797, validation loss: 0.1642
2024-05-25 04:00:51 [INFO]: Epoch 039 - training loss: 9428.4507, validation loss: 0.1618
2024-05-25 04:00:51 [INFO]: Epoch 040 - training loss: 9412.9344, validation loss: 0.1592
2024-05-25 04:00:51 [INFO]: Epoch 041 - training loss: 9408.4102, validation loss: 0.1557
2024-05-25 04:00:51 [INFO]: Epoch 042 - training loss: 9402.4906, validation loss: 0.1560
2024-05-25 04:00:51 [INFO]: Epoch 043 - training loss: 9400.2321, validation loss: 0.1522
2024-05-25 04:00:51 [INFO]: Epoch 044 - training loss: 9398.5027, validation loss: 0.1485
2024-05-25 04:00:51 [INFO]: Epoch 045 - training loss: 9393.0046, validation loss: 0.1457
2024-05-25 04:00:52 [INFO]: Epoch 046 - training loss: 9398.6694, validation loss: 0.1444
2024-05-25 04:00:52 [INFO]: Epoch 047 - training loss: 9398.8568, validation loss: 0.1446
2024-05-25 04:00:52 [INFO]: Epoch 048 - training loss: 9381.8026, validation loss: 0.1414
2024-05-25 04:00:52 [INFO]: Epoch 049 - training loss: 9378.8546, validation loss: 0.1402
2024-05-25 04:00:52 [INFO]: Epoch 050 - training loss: 9388.5410, validation loss: 0.1378
2024-05-25 04:00:52 [INFO]: Epoch 051 - training loss: 9372.3181, validation loss: 0.1374
2024-05-25 04:00:52 [INFO]: Epoch 052 - training loss: 9375.4266, validation loss: 0.1359
2024-05-25 04:00:53 [INFO]: Epoch 053 - training loss: 9379.2767, validation loss: 0.1348
2024-05-25 04:00:53 [INFO]: Epoch 054 - training loss: 9381.7275, validation loss: 0.1324
2024-05-25 04:00:53 [INFO]: Epoch 055 - training loss: 9364.1387, validation loss: 0.1309
2024-05-25 04:00:53 [INFO]: Epoch 056 - training loss: 9367.7665, validation loss: 0.1299
2024-05-25 04:00:53 [INFO]: Epoch 057 - training loss: 9358.6693, validation loss: 0.1288
2024-05-25 04:00:53 [INFO]: Epoch 058 - training loss: 9357.4391, validation loss: 0.1277
2024-05-25 04:00:53 [INFO]: Epoch 059 - training loss: 9356.8173, validation loss: 0.1257
2024-05-25 04:00:54 [INFO]: Epoch 060 - training loss: 9357.8303, validation loss: 0.1262
2024-05-25 04:00:54 [INFO]: Epoch 061 - training loss: 9356.4738, validation loss: 0.1257
2024-05-25 04:00:54 [INFO]: Epoch 062 - training loss: 9357.0654, validation loss: 0.1265
2024-05-25 04:00:54 [INFO]: Epoch 063 - training loss: 9358.0907, validation loss: 0.1233
2024-05-25 04:00:54 [INFO]: Epoch 064 - training loss: 9348.2980, validation loss: 0.1214
2024-05-25 04:00:54 [INFO]: Epoch 065 - training loss: 9347.4179, validation loss: 0.1221
2024-05-25 04:00:54 [INFO]: Epoch 066 - training loss: 9346.3610, validation loss: 0.1215
2024-05-25 04:00:54 [INFO]: Epoch 067 - training loss: 9347.5979, validation loss: 0.1191
2024-05-25 04:00:55 [INFO]: Epoch 068 - training loss: 9345.0362, validation loss: 0.1173
2024-05-25 04:00:55 [INFO]: Epoch 069 - training loss: 9341.2130, validation loss: 0.1178
2024-05-25 04:00:55 [INFO]: Epoch 070 - training loss: 9341.9948, validation loss: 0.1169
2024-05-25 04:00:55 [INFO]: Epoch 071 - training loss: 9339.2911, validation loss: 0.1161
2024-05-25 04:00:55 [INFO]: Epoch 072 - training loss: 9343.4020, validation loss: 0.1151
2024-05-25 04:00:55 [INFO]: Epoch 073 - training loss: 9341.4187, validation loss: 0.1146
2024-05-25 04:00:55 [INFO]: Epoch 074 - training loss: 9337.1030, validation loss: 0.1138
2024-05-25 04:00:56 [INFO]: Epoch 075 - training loss: 9336.7795, validation loss: 0.1150
2024-05-25 04:00:56 [INFO]: Epoch 076 - training loss: 9335.5221, validation loss: 0.1132
2024-05-25 04:00:56 [INFO]: Epoch 077 - training loss: 9336.4651, validation loss: 0.1133
2024-05-25 04:00:56 [INFO]: Epoch 078 - training loss: 9336.7722, validation loss: 0.1139
2024-05-25 04:00:56 [INFO]: Epoch 079 - training loss: 9334.8489, validation loss: 0.1120
2024-05-25 04:00:56 [INFO]: Epoch 080 - training loss: 9333.2086, validation loss: 0.1121
2024-05-25 04:00:56 [INFO]: Epoch 081 - training loss: 9331.4405, validation loss: 0.1090
2024-05-25 04:00:57 [INFO]: Epoch 082 - training loss: 9334.1891, validation loss: 0.1098
2024-05-25 04:00:57 [INFO]: Epoch 083 - training loss: 9336.0869, validation loss: 0.1098
2024-05-25 04:00:57 [INFO]: Epoch 084 - training loss: 9330.3655, validation loss: 0.1091
2024-05-25 04:00:57 [INFO]: Epoch 085 - training loss: 9328.9943, validation loss: 0.1085
2024-05-25 04:00:57 [INFO]: Epoch 086 - training loss: 9328.9590, validation loss: 0.1075
2024-05-25 04:00:57 [INFO]: Epoch 087 - training loss: 9328.3951, validation loss: 0.1061
2024-05-25 04:00:57 [INFO]: Epoch 088 - training loss: 9329.0814, validation loss: 0.1072
2024-05-25 04:00:58 [INFO]: Epoch 089 - training loss: 9327.4350, validation loss: 0.1056
2024-05-25 04:00:58 [INFO]: Epoch 090 - training loss: 9328.0014, validation loss: 0.1057
2024-05-25 04:00:58 [INFO]: Epoch 091 - training loss: 9326.5615, validation loss: 0.1045
2024-05-25 04:00:58 [INFO]: Epoch 092 - training loss: 9326.3433, validation loss: 0.1032
2024-05-25 04:00:58 [INFO]: Epoch 093 - training loss: 9324.9565, validation loss: 0.1034
2024-05-25 04:00:58 [INFO]: Epoch 094 - training loss: 9327.2952, validation loss: 0.1012
2024-05-25 04:00:58 [INFO]: Epoch 095 - training loss: 9324.2519, validation loss: 0.1088
2024-05-25 04:00:58 [INFO]: Epoch 096 - training loss: 9324.4313, validation loss: 0.1019
2024-05-25 04:00:59 [INFO]: Epoch 097 - training loss: 9324.9833, validation loss: 0.1008
2024-05-25 04:00:59 [INFO]: Epoch 098 - training loss: 9325.2307, validation loss: 0.1018
2024-05-25 04:00:59 [INFO]: Epoch 099 - training loss: 9324.8596, validation loss: 0.1013
2024-05-25 04:00:59 [INFO]: Epoch 100 - training loss: 9324.3665, validation loss: 0.1002
2024-05-25 04:00:59 [INFO]: Epoch 101 - training loss: 9322.7088, validation loss: 0.0998
2024-05-25 04:00:59 [INFO]: Epoch 102 - training loss: 9323.3190, validation loss: 0.0996
2024-05-25 04:00:59 [INFO]: Epoch 103 - training loss: 9321.6426, validation loss: 0.0988
2024-05-25 04:01:00 [INFO]: Epoch 104 - training loss: 9320.7307, validation loss: 0.0979
2024-05-25 04:01:00 [INFO]: Epoch 105 - training loss: 9320.7784, validation loss: 0.0975
2024-05-25 04:01:00 [INFO]: Epoch 106 - training loss: 9320.9841, validation loss: 0.0967
2024-05-25 04:01:00 [INFO]: Epoch 107 - training loss: 9320.6615, validation loss: 0.0974
2024-05-25 04:01:00 [INFO]: Epoch 108 - training loss: 9320.2947, validation loss: 0.0952
2024-05-25 04:01:00 [INFO]: Epoch 109 - training loss: 9320.9453, validation loss: 0.0947
2024-05-25 04:01:00 [INFO]: Epoch 110 - training loss: 9317.7312, validation loss: 0.0953
2024-05-25 04:01:01 [INFO]: Epoch 111 - training loss: 9317.9692, validation loss: 0.0935
2024-05-25 04:01:01 [INFO]: Epoch 112 - training loss: 9317.0941, validation loss: 0.0931
2024-05-25 04:01:01 [INFO]: Epoch 113 - training loss: 9319.1233, validation loss: 0.0942
2024-05-25 04:01:01 [INFO]: Epoch 114 - training loss: 9317.3904, validation loss: 0.0927
2024-05-25 04:01:01 [INFO]: Epoch 115 - training loss: 9318.3590, validation loss: 0.0937
2024-05-25 04:01:01 [INFO]: Epoch 116 - training loss: 9318.5284, validation loss: 0.0925
2024-05-25 04:01:01 [INFO]: Epoch 117 - training loss: 9315.9835, validation loss: 0.0921
2024-05-25 04:01:01 [INFO]: Epoch 118 - training loss: 9316.9033, validation loss: 0.0921
2024-05-25 04:01:02 [INFO]: Epoch 119 - training loss: 9317.3320, validation loss: 0.0918
2024-05-25 04:01:02 [INFO]: Epoch 120 - training loss: 9315.4608, validation loss: 0.0894
2024-05-25 04:01:02 [INFO]: Epoch 121 - training loss: 9316.0350, validation loss: 0.0895
2024-05-25 04:01:02 [INFO]: Epoch 122 - training loss: 9317.8109, validation loss: 0.0903
2024-05-25 04:01:02 [INFO]: Epoch 123 - training loss: 9314.9923, validation loss: 0.0906
2024-05-25 04:01:02 [INFO]: Epoch 124 - training loss: 9315.3293, validation loss: 0.0884
2024-05-25 04:01:02 [INFO]: Epoch 125 - training loss: 9314.6804, validation loss: 0.0901
2024-05-25 04:01:03 [INFO]: Epoch 126 - training loss: 9315.4545, validation loss: 0.0860
2024-05-25 04:01:03 [INFO]: Epoch 127 - training loss: 9313.1989, validation loss: 0.0893
2024-05-25 04:01:03 [INFO]: Epoch 128 - training loss: 9313.2930, validation loss: 0.0880
2024-05-25 04:01:03 [INFO]: Epoch 129 - training loss: 9314.1215, validation loss: 0.0880
2024-05-25 04:01:03 [INFO]: Epoch 130 - training loss: 9313.1553, validation loss: 0.0874
2024-05-25 04:01:03 [INFO]: Epoch 131 - training loss: 9312.9954, validation loss: 0.0862
2024-05-25 04:01:03 [INFO]: Epoch 132 - training loss: 9314.5314, validation loss: 0.0875
2024-05-25 04:01:04 [INFO]: Epoch 133 - training loss: 9312.6174, validation loss: 0.0862
2024-05-25 04:01:04 [INFO]: Epoch 134 - training loss: 9313.3364, validation loss: 0.0869
2024-05-25 04:01:04 [INFO]: Epoch 135 - training loss: 9313.9014, validation loss: 0.0877
2024-05-25 04:01:04 [INFO]: Epoch 136 - training loss: 9311.7791, validation loss: 0.0857
2024-05-25 04:01:04 [INFO]: Epoch 137 - training loss: 9311.6841, validation loss: 0.0845
2024-05-25 04:01:04 [INFO]: Epoch 138 - training loss: 9313.2355, validation loss: 0.0851
2024-05-25 04:01:04 [INFO]: Epoch 139 - training loss: 9310.4788, validation loss: 0.0838
2024-05-25 04:01:05 [INFO]: Epoch 140 - training loss: 9310.7786, validation loss: 0.0842
2024-05-25 04:01:05 [INFO]: Epoch 141 - training loss: 9311.0540, validation loss: 0.0844
2024-05-25 04:01:05 [INFO]: Epoch 142 - training loss: 9310.8991, validation loss: 0.0838
2024-05-25 04:01:05 [INFO]: Epoch 143 - training loss: 9309.8914, validation loss: 0.0842
2024-05-25 04:01:05 [INFO]: Epoch 144 - training loss: 9312.1445, validation loss: 0.0829
2024-05-25 04:01:05 [INFO]: Epoch 145 - training loss: 9310.5859, validation loss: 0.0823
2024-05-25 04:01:05 [INFO]: Epoch 146 - training loss: 9310.6608, validation loss: 0.0834
2024-05-25 04:01:06 [INFO]: Epoch 147 - training loss: 9311.2314, validation loss: 0.0832
2024-05-25 04:01:06 [INFO]: Epoch 148 - training loss: 9310.7816, validation loss: 0.0854
2024-05-25 04:01:06 [INFO]: Epoch 149 - training loss: 9309.8843, validation loss: 0.0834
2024-05-25 04:01:06 [INFO]: Epoch 150 - training loss: 9310.5289, validation loss: 0.0815
2024-05-25 04:01:06 [INFO]: Epoch 151 - training loss: 9309.5748, validation loss: 0.0822
2024-05-25 04:01:06 [INFO]: Epoch 152 - training loss: 9309.2162, validation loss: 0.0805
2024-05-25 04:01:06 [INFO]: Epoch 153 - training loss: 9311.7462, validation loss: 0.0802
2024-05-25 04:01:06 [INFO]: Epoch 154 - training loss: 9310.0046, validation loss: 0.0816
2024-05-25 04:01:07 [INFO]: Epoch 155 - training loss: 9309.6818, validation loss: 0.0805
2024-05-25 04:01:07 [INFO]: Epoch 156 - training loss: 9308.4008, validation loss: 0.0798
2024-05-25 04:01:07 [INFO]: Epoch 157 - training loss: 9310.0147, validation loss: 0.0798
2024-05-25 04:01:07 [INFO]: Epoch 158 - training loss: 9307.7532, validation loss: 0.0794
2024-05-25 04:01:07 [INFO]: Epoch 159 - training loss: 9309.1722, validation loss: 0.0796
2024-05-25 04:01:07 [INFO]: Epoch 160 - training loss: 9308.4320, validation loss: 0.0793
2024-05-25 04:01:07 [INFO]: Epoch 161 - training loss: 9308.4089, validation loss: 0.0796
2024-05-25 04:01:08 [INFO]: Epoch 162 - training loss: 9307.8312, validation loss: 0.0791
2024-05-25 04:01:08 [INFO]: Epoch 163 - training loss: 9308.8704, validation loss: 0.0782
2024-05-25 04:01:08 [INFO]: Epoch 164 - training loss: 9309.4849, validation loss: 0.0775
2024-05-25 04:01:08 [INFO]: Epoch 165 - training loss: 9307.9969, validation loss: 0.0798
2024-05-25 04:01:08 [INFO]: Epoch 166 - training loss: 9308.7169, validation loss: 0.0781
2024-05-25 04:01:08 [INFO]: Epoch 167 - training loss: 9307.4224, validation loss: 0.0776
2024-05-25 04:01:08 [INFO]: Epoch 168 - training loss: 9306.2350, validation loss: 0.0772
2024-05-25 04:01:09 [INFO]: Epoch 169 - training loss: 9308.8378, validation loss: 0.0766
2024-05-25 04:01:09 [INFO]: Epoch 170 - training loss: 9308.7133, validation loss: 0.0794
2024-05-25 04:01:09 [INFO]: Epoch 171 - training loss: 9306.9023, validation loss: 0.0779
2024-05-25 04:01:09 [INFO]: Epoch 172 - training loss: 9307.0361, validation loss: 0.0784
2024-05-25 04:01:09 [INFO]: Epoch 173 - training loss: 9307.4201, validation loss: 0.0775
2024-05-25 04:01:09 [INFO]: Epoch 174 - training loss: 9306.9069, validation loss: 0.0770
2024-05-25 04:01:09 [INFO]: Epoch 175 - training loss: 9306.8660, validation loss: 0.0789
2024-05-25 04:01:09 [INFO]: Epoch 176 - training loss: 9306.5925, validation loss: 0.0762
2024-05-25 04:01:10 [INFO]: Epoch 177 - training loss: 9306.9880, validation loss: 0.0766
2024-05-25 04:01:10 [INFO]: Epoch 178 - training loss: 9305.8127, validation loss: 0.0769
2024-05-25 04:01:10 [INFO]: Epoch 179 - training loss: 9308.2887, validation loss: 0.0767
2024-05-25 04:01:10 [INFO]: Epoch 180 - training loss: 9306.0726, validation loss: 0.0769
2024-05-25 04:01:10 [INFO]: Epoch 181 - training loss: 9305.2849, validation loss: 0.0757
2024-05-25 04:01:10 [INFO]: Epoch 182 - training loss: 9305.1387, validation loss: 0.0757
2024-05-25 04:01:10 [INFO]: Epoch 183 - training loss: 9306.3185, validation loss: 0.0755
2024-05-25 04:01:11 [INFO]: Epoch 184 - training loss: 9305.4427, validation loss: 0.0760
2024-05-25 04:01:11 [INFO]: Epoch 185 - training loss: 9305.2895, validation loss: 0.0745
2024-05-25 04:01:11 [INFO]: Epoch 186 - training loss: 9305.5742, validation loss: 0.0760
2024-05-25 04:01:11 [INFO]: Epoch 187 - training loss: 9306.3430, validation loss: 0.0750
2024-05-25 04:01:11 [INFO]: Epoch 188 - training loss: 9305.5154, validation loss: 0.0738
2024-05-25 04:01:11 [INFO]: Epoch 189 - training loss: 9305.6343, validation loss: 0.0741
2024-05-25 04:01:11 [INFO]: Epoch 190 - training loss: 9305.2491, validation loss: 0.0752
2024-05-25 04:01:11 [INFO]: Epoch 191 - training loss: 9305.5842, validation loss: 0.0749
2024-05-25 04:01:12 [INFO]: Epoch 192 - training loss: 9304.9358, validation loss: 0.0748
2024-05-25 04:01:12 [INFO]: Epoch 193 - training loss: 9304.7010, validation loss: 0.0754
2024-05-25 04:01:12 [INFO]: Epoch 194 - training loss: 9304.7112, validation loss: 0.0762
2024-05-25 04:01:12 [INFO]: Epoch 195 - training loss: 9304.5649, validation loss: 0.0748
2024-05-25 04:01:12 [INFO]: Epoch 196 - training loss: 9305.5772, validation loss: 0.0744
2024-05-25 04:01:12 [INFO]: Epoch 197 - training loss: 9305.5173, validation loss: 0.0734
2024-05-25 04:01:12 [INFO]: Epoch 198 - training loss: 9304.1208, validation loss: 0.0760
2024-05-25 04:01:12 [INFO]: Epoch 199 - training loss: 9304.9507, validation loss: 0.0750
2024-05-25 04:01:13 [INFO]: Epoch 200 - training loss: 9303.9507, validation loss: 0.0736
2024-05-25 04:01:13 [INFO]: Epoch 201 - training loss: 9303.8717, validation loss: 0.0732
2024-05-25 04:01:13 [INFO]: Epoch 202 - training loss: 9303.6000, validation loss: 0.0749
2024-05-25 04:01:13 [INFO]: Epoch 203 - training loss: 9304.7219, validation loss: 0.0730
2024-05-25 04:01:13 [INFO]: Epoch 204 - training loss: 9304.2768, validation loss: 0.0744
2024-05-25 04:01:13 [INFO]: Epoch 205 - training loss: 9304.4575, validation loss: 0.0742
2024-05-25 04:01:13 [INFO]: Epoch 206 - training loss: 9306.7018, validation loss: 0.0733
2024-05-25 04:01:14 [INFO]: Epoch 207 - training loss: 9304.4250, validation loss: 0.0723
2024-05-25 04:01:14 [INFO]: Epoch 208 - training loss: 9304.3986, validation loss: 0.0735
2024-05-25 04:01:14 [INFO]: Epoch 209 - training loss: 9304.1247, validation loss: 0.0721
2024-05-25 04:01:14 [INFO]: Epoch 210 - training loss: 9304.2050, validation loss: 0.0716
2024-05-25 04:01:14 [INFO]: Epoch 211 - training loss: 9303.3781, validation loss: 0.0721
2024-05-25 04:01:14 [INFO]: Epoch 212 - training loss: 9303.4182, validation loss: 0.0718
2024-05-25 04:01:14 [INFO]: Epoch 213 - training loss: 9305.7661, validation loss: 0.0699
2024-05-25 04:01:14 [INFO]: Epoch 214 - training loss: 9303.8821, validation loss: 0.0747
2024-05-25 04:01:15 [INFO]: Epoch 215 - training loss: 9304.0925, validation loss: 0.0724
2024-05-25 04:01:15 [INFO]: Epoch 216 - training loss: 9303.7620, validation loss: 0.0726
2024-05-25 04:01:15 [INFO]: Epoch 217 - training loss: 9305.9252, validation loss: 0.0732
2024-05-25 04:01:15 [INFO]: Epoch 218 - training loss: 9303.7220, validation loss: 0.0702
2024-05-25 04:01:15 [INFO]: Epoch 219 - training loss: 9303.9560, validation loss: 0.0718
2024-05-25 04:01:15 [INFO]: Epoch 220 - training loss: 9303.0983, validation loss: 0.0726
2024-05-25 04:01:15 [INFO]: Epoch 221 - training loss: 9303.4543, validation loss: 0.0711
2024-05-25 04:01:16 [INFO]: Epoch 222 - training loss: 9303.6080, validation loss: 0.0707
2024-05-25 04:01:16 [INFO]: Epoch 223 - training loss: 9303.3458, validation loss: 0.0708
2024-05-25 04:01:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:01:16 [INFO]: Finished training. The best model is from epoch#213.
2024-05-25 04:01:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240525_T040045/GPVAE.pypots
2024-05-25 04:01:16 [INFO]: GP-VAE on ETTm1: MAE=0.2553, MSE=0.1350
2024-05-25 04:01:16 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-25 04:01:16 [INFO]: Using the given device: cuda:0
2024-05-25 04:01:16 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T040116
2024-05-25 04:01:16 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T040116/tensorboard
2024-05-25 04:01:16 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 04:01:27 [INFO]: Epoch 001 - generator training loss: 0.5513, discriminator training loss: 0.3460, validation loss: 0.3398
2024-05-25 04:01:37 [INFO]: Epoch 002 - generator training loss: 0.0402, discriminator training loss: 0.2118, validation loss: 0.1039
2024-05-25 04:01:46 [INFO]: Epoch 003 - generator training loss: -0.0623, discriminator training loss: 0.1996, validation loss: 0.0639
2024-05-25 04:01:55 [INFO]: Epoch 004 - generator training loss: -0.0867, discriminator training loss: 0.1972, validation loss: 0.0500
2024-05-25 04:02:05 [INFO]: Epoch 005 - generator training loss: -0.0873, discriminator training loss: 0.1925, validation loss: 0.0459
2024-05-25 04:02:14 [INFO]: Epoch 006 - generator training loss: -0.0884, discriminator training loss: 0.1910, validation loss: 0.0409
2024-05-25 04:02:23 [INFO]: Epoch 007 - generator training loss: -0.0823, discriminator training loss: 0.1835, validation loss: 0.0384
2024-05-25 04:02:33 [INFO]: Epoch 008 - generator training loss: -0.0766, discriminator training loss: 0.1755, validation loss: 0.0383
2024-05-25 04:02:42 [INFO]: Epoch 009 - generator training loss: -0.0644, discriminator training loss: 0.1602, validation loss: 0.0372
2024-05-25 04:02:51 [INFO]: Epoch 010 - generator training loss: -0.0536, discriminator training loss: 0.1457, validation loss: 0.0354
2024-05-25 04:03:01 [INFO]: Epoch 011 - generator training loss: -0.0422, discriminator training loss: 0.1306, validation loss: 0.0357
2024-05-25 04:03:10 [INFO]: Epoch 012 - generator training loss: -0.0313, discriminator training loss: 0.1164, validation loss: 0.0352
2024-05-25 04:03:20 [INFO]: Epoch 013 - generator training loss: -0.0153, discriminator training loss: 0.1033, validation loss: 0.0354
2024-05-25 04:03:29 [INFO]: Epoch 014 - generator training loss: -0.0194, discriminator training loss: 0.0971, validation loss: 0.0342
2024-05-25 04:03:38 [INFO]: Epoch 015 - generator training loss: -0.0162, discriminator training loss: 0.0923, validation loss: 0.0334
2024-05-25 04:03:48 [INFO]: Epoch 016 - generator training loss: -0.0140, discriminator training loss: 0.0870, validation loss: 0.0330
2024-05-25 04:03:57 [INFO]: Epoch 017 - generator training loss: -0.0155, discriminator training loss: 0.0833, validation loss: 0.0332
2024-05-25 04:04:06 [INFO]: Epoch 018 - generator training loss: -0.0137, discriminator training loss: 0.0817, validation loss: 0.0328
2024-05-25 04:04:16 [INFO]: Epoch 019 - generator training loss: -0.0133, discriminator training loss: 0.0809, validation loss: 0.0319
2024-05-25 04:04:25 [INFO]: Epoch 020 - generator training loss: -0.0133, discriminator training loss: 0.0814, validation loss: 0.0316
2024-05-25 04:04:35 [INFO]: Epoch 021 - generator training loss: -0.0110, discriminator training loss: 0.0801, validation loss: 0.0313
2024-05-25 04:04:44 [INFO]: Epoch 022 - generator training loss: -0.0132, discriminator training loss: 0.0765, validation loss: 0.0308
2024-05-25 04:04:54 [INFO]: Epoch 023 - generator training loss: -0.0154, discriminator training loss: 0.0770, validation loss: 0.0301
2024-05-25 04:05:03 [INFO]: Epoch 024 - generator training loss: -0.0141, discriminator training loss: 0.0769, validation loss: 0.0302
2024-05-25 04:05:13 [INFO]: Epoch 025 - generator training loss: -0.0173, discriminator training loss: 0.0778, validation loss: 0.0293
2024-05-25 04:05:22 [INFO]: Epoch 026 - generator training loss: -0.0167, discriminator training loss: 0.0765, validation loss: 0.0297
2024-05-25 04:05:31 [INFO]: Epoch 027 - generator training loss: -0.0157, discriminator training loss: 0.0751, validation loss: 0.0293
2024-05-25 04:05:40 [INFO]: Epoch 028 - generator training loss: -0.0155, discriminator training loss: 0.0764, validation loss: 0.0288
2024-05-25 04:05:50 [INFO]: Epoch 029 - generator training loss: -0.0175, discriminator training loss: 0.0756, validation loss: 0.0286
2024-05-25 04:05:59 [INFO]: Epoch 030 - generator training loss: -0.0193, discriminator training loss: 0.0761, validation loss: 0.0284
2024-05-25 04:06:09 [INFO]: Epoch 031 - generator training loss: -0.0177, discriminator training loss: 0.0750, validation loss: 0.0270
2024-05-25 04:06:18 [INFO]: Epoch 032 - generator training loss: -0.0183, discriminator training loss: 0.0731, validation loss: 0.0266
2024-05-25 04:06:27 [INFO]: Epoch 033 - generator training loss: -0.0236, discriminator training loss: 0.0720, validation loss: 0.0260
2024-05-25 04:06:37 [INFO]: Epoch 034 - generator training loss: -0.0179, discriminator training loss: 0.0737, validation loss: 0.0257
2024-05-25 04:06:46 [INFO]: Epoch 035 - generator training loss: -0.0199, discriminator training loss: 0.0724, validation loss: 0.0260
2024-05-25 04:06:55 [INFO]: Epoch 036 - generator training loss: -0.0247, discriminator training loss: 0.0754, validation loss: 0.0249
2024-05-25 04:07:04 [INFO]: Epoch 037 - generator training loss: -0.0192, discriminator training loss: 0.0733, validation loss: 0.0245
2024-05-25 04:07:13 [INFO]: Epoch 038 - generator training loss: -0.0174, discriminator training loss: 0.0736, validation loss: 0.0245
2024-05-25 04:07:23 [INFO]: Epoch 039 - generator training loss: -0.0211, discriminator training loss: 0.0726, validation loss: 0.0241
2024-05-25 04:07:32 [INFO]: Epoch 040 - generator training loss: -0.0209, discriminator training loss: 0.0745, validation loss: 0.0233
2024-05-25 04:07:41 [INFO]: Epoch 041 - generator training loss: -0.0214, discriminator training loss: 0.0736, validation loss: 0.0233
2024-05-25 04:07:51 [INFO]: Epoch 042 - generator training loss: -0.0216, discriminator training loss: 0.0723, validation loss: 0.0231
2024-05-25 04:08:00 [INFO]: Epoch 043 - generator training loss: -0.0209, discriminator training loss: 0.0731, validation loss: 0.0224
2024-05-25 04:08:10 [INFO]: Epoch 044 - generator training loss: -0.0234, discriminator training loss: 0.0703, validation loss: 0.0229
2024-05-25 04:08:19 [INFO]: Epoch 045 - generator training loss: -0.0224, discriminator training loss: 0.0699, validation loss: 0.0226
2024-05-25 04:08:29 [INFO]: Epoch 046 - generator training loss: -0.0202, discriminator training loss: 0.0711, validation loss: 0.0223
2024-05-25 04:08:38 [INFO]: Epoch 047 - generator training loss: -0.0237, discriminator training loss: 0.0695, validation loss: 0.0223
2024-05-25 04:08:47 [INFO]: Epoch 048 - generator training loss: -0.0214, discriminator training loss: 0.0702, validation loss: 0.0226
2024-05-25 04:08:57 [INFO]: Epoch 049 - generator training loss: -0.0225, discriminator training loss: 0.0703, validation loss: 0.0221
2024-05-25 04:09:06 [INFO]: Epoch 050 - generator training loss: -0.0237, discriminator training loss: 0.0704, validation loss: 0.0219
2024-05-25 04:09:15 [INFO]: Epoch 051 - generator training loss: -0.0228, discriminator training loss: 0.0698, validation loss: 0.0218
2024-05-25 04:09:25 [INFO]: Epoch 052 - generator training loss: -0.0242, discriminator training loss: 0.0695, validation loss: 0.0217
2024-05-25 04:09:34 [INFO]: Epoch 053 - generator training loss: -0.0225, discriminator training loss: 0.0715, validation loss: 0.0214
2024-05-25 04:09:43 [INFO]: Epoch 054 - generator training loss: -0.0223, discriminator training loss: 0.0687, validation loss: 0.0219
2024-05-25 04:09:53 [INFO]: Epoch 055 - generator training loss: -0.0239, discriminator training loss: 0.0710, validation loss: 0.0213
2024-05-25 04:10:02 [INFO]: Epoch 056 - generator training loss: -0.0232, discriminator training loss: 0.0710, validation loss: 0.0214
2024-05-25 04:10:12 [INFO]: Epoch 057 - generator training loss: -0.0231, discriminator training loss: 0.0690, validation loss: 0.0217
2024-05-25 04:10:21 [INFO]: Epoch 058 - generator training loss: -0.0229, discriminator training loss: 0.0705, validation loss: 0.0209
2024-05-25 04:10:30 [INFO]: Epoch 059 - generator training loss: -0.0268, discriminator training loss: 0.0696, validation loss: 0.0220
2024-05-25 04:10:40 [INFO]: Epoch 060 - generator training loss: -0.0237, discriminator training loss: 0.0703, validation loss: 0.0217
2024-05-25 04:10:49 [INFO]: Epoch 061 - generator training loss: -0.0239, discriminator training loss: 0.0688, validation loss: 0.0207
2024-05-25 04:10:59 [INFO]: Epoch 062 - generator training loss: -0.0241, discriminator training loss: 0.0688, validation loss: 0.0211
2024-05-25 04:11:08 [INFO]: Epoch 063 - generator training loss: -0.0244, discriminator training loss: 0.0692, validation loss: 0.0210
2024-05-25 04:11:18 [INFO]: Epoch 064 - generator training loss: -0.0271, discriminator training loss: 0.0661, validation loss: 0.0212
2024-05-25 04:11:27 [INFO]: Epoch 065 - generator training loss: -0.0274, discriminator training loss: 0.0709, validation loss: 0.0203
2024-05-25 04:11:36 [INFO]: Epoch 066 - generator training loss: -0.0242, discriminator training loss: 0.0689, validation loss: 0.0203
2024-05-25 04:11:46 [INFO]: Epoch 067 - generator training loss: -0.0242, discriminator training loss: 0.0696, validation loss: 0.0204
2024-05-25 04:11:55 [INFO]: Epoch 068 - generator training loss: -0.0249, discriminator training loss: 0.0685, validation loss: 0.0207
2024-05-25 04:12:05 [INFO]: Epoch 069 - generator training loss: -0.0293, discriminator training loss: 0.0685, validation loss: 0.0203
2024-05-25 04:12:14 [INFO]: Epoch 070 - generator training loss: -0.0257, discriminator training loss: 0.0682, validation loss: 0.0203
2024-05-25 04:12:23 [INFO]: Epoch 071 - generator training loss: -0.0249, discriminator training loss: 0.0684, validation loss: 0.0204
2024-05-25 04:12:32 [INFO]: Epoch 072 - generator training loss: -0.0259, discriminator training loss: 0.0679, validation loss: 0.0204
2024-05-25 04:12:42 [INFO]: Epoch 073 - generator training loss: -0.0240, discriminator training loss: 0.0671, validation loss: 0.0205
2024-05-25 04:12:51 [INFO]: Epoch 074 - generator training loss: -0.0236, discriminator training loss: 0.0672, validation loss: 0.0201
2024-05-25 04:13:01 [INFO]: Epoch 075 - generator training loss: -0.0272, discriminator training loss: 0.0687, validation loss: 0.0201
2024-05-25 04:13:10 [INFO]: Epoch 076 - generator training loss: -0.0218, discriminator training loss: 0.0675, validation loss: 0.0198
2024-05-25 04:13:19 [INFO]: Epoch 077 - generator training loss: -0.0250, discriminator training loss: 0.0689, validation loss: 0.0204
2024-05-25 04:13:29 [INFO]: Epoch 078 - generator training loss: -0.0232, discriminator training loss: 0.0673, validation loss: 0.0205
2024-05-25 04:13:38 [INFO]: Epoch 079 - generator training loss: -0.0241, discriminator training loss: 0.0670, validation loss: 0.0200
2024-05-25 04:13:47 [INFO]: Epoch 080 - generator training loss: -0.0270, discriminator training loss: 0.0678, validation loss: 0.0202
2024-05-25 04:13:57 [INFO]: Epoch 081 - generator training loss: -0.0252, discriminator training loss: 0.0687, validation loss: 0.0205
2024-05-25 04:14:06 [INFO]: Epoch 082 - generator training loss: -0.0257, discriminator training loss: 0.0671, validation loss: 0.0206
2024-05-25 04:14:16 [INFO]: Epoch 083 - generator training loss: -0.0274, discriminator training loss: 0.0684, validation loss: 0.0203
2024-05-25 04:14:25 [INFO]: Epoch 084 - generator training loss: -0.0266, discriminator training loss: 0.0663, validation loss: 0.0199
2024-05-25 04:14:34 [INFO]: Epoch 085 - generator training loss: -0.0284, discriminator training loss: 0.0680, validation loss: 0.0196
2024-05-25 04:14:44 [INFO]: Epoch 086 - generator training loss: -0.0282, discriminator training loss: 0.0659, validation loss: 0.0194
2024-05-25 04:14:53 [INFO]: Epoch 087 - generator training loss: -0.0266, discriminator training loss: 0.0692, validation loss: 0.0201
2024-05-25 04:15:03 [INFO]: Epoch 088 - generator training loss: -0.0264, discriminator training loss: 0.0674, validation loss: 0.0201
2024-05-25 04:15:12 [INFO]: Epoch 089 - generator training loss: -0.0260, discriminator training loss: 0.0678, validation loss: 0.0200
2024-05-25 04:15:21 [INFO]: Epoch 090 - generator training loss: -0.0266, discriminator training loss: 0.0658, validation loss: 0.0195
2024-05-25 04:15:31 [INFO]: Epoch 091 - generator training loss: -0.0276, discriminator training loss: 0.0653, validation loss: 0.0192
2024-05-25 04:15:40 [INFO]: Epoch 092 - generator training loss: -0.0259, discriminator training loss: 0.0654, validation loss: 0.0200
2024-05-25 04:15:49 [INFO]: Epoch 093 - generator training loss: -0.0255, discriminator training loss: 0.0655, validation loss: 0.0198
2024-05-25 04:15:59 [INFO]: Epoch 094 - generator training loss: -0.0247, discriminator training loss: 0.0663, validation loss: 0.0208
2024-05-25 04:16:08 [INFO]: Epoch 095 - generator training loss: -0.0270, discriminator training loss: 0.0663, validation loss: 0.0195
2024-05-25 04:16:17 [INFO]: Epoch 096 - generator training loss: -0.0275, discriminator training loss: 0.0678, validation loss: 0.0203
2024-05-25 04:16:27 [INFO]: Epoch 097 - generator training loss: -0.0272, discriminator training loss: 0.0686, validation loss: 0.0196
2024-05-25 04:16:36 [INFO]: Epoch 098 - generator training loss: -0.0286, discriminator training loss: 0.0672, validation loss: 0.0198
2024-05-25 04:16:45 [INFO]: Epoch 099 - generator training loss: -0.0260, discriminator training loss: 0.0648, validation loss: 0.0199
2024-05-25 04:16:55 [INFO]: Epoch 100 - generator training loss: -0.0241, discriminator training loss: 0.0656, validation loss: 0.0208
2024-05-25 04:17:04 [INFO]: Epoch 101 - generator training loss: -0.0226, discriminator training loss: 0.0656, validation loss: 0.0212
2024-05-25 04:17:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:17:04 [INFO]: Finished training. The best model is from epoch#91.
2024-05-25 04:17:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_ettm1/20240525_T040116/USGAN.pypots
2024-05-25 04:17:05 [INFO]: US-GAN on ETTm1: MAE=0.1410, MSE=0.0470
2024-05-25 04:17:05 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-25 04:17:05 [INFO]: Using the given device: cuda:0
2024-05-25 04:17:05 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T041705
2024-05-25 04:17:05 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T041705/tensorboard
2024-05-25 04:17:05 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 04:17:13 [INFO]: Epoch 001 - training loss: 1.3626, validation loss: 0.3057
2024-05-25 04:17:20 [INFO]: Epoch 002 - training loss: 0.8948, validation loss: 0.0853
2024-05-25 04:17:26 [INFO]: Epoch 003 - training loss: 0.7116, validation loss: 0.0502
2024-05-25 04:17:32 [INFO]: Epoch 004 - training loss: 0.6428, validation loss: 0.0455
2024-05-25 04:17:38 [INFO]: Epoch 005 - training loss: 0.5909, validation loss: 0.0398
2024-05-25 04:17:45 [INFO]: Epoch 006 - training loss: 0.5538, validation loss: 0.0384
2024-05-25 04:17:51 [INFO]: Epoch 007 - training loss: 0.5269, validation loss: 0.0345
2024-05-25 04:17:57 [INFO]: Epoch 008 - training loss: 0.5057, validation loss: 0.0321
2024-05-25 04:18:03 [INFO]: Epoch 009 - training loss: 0.4840, validation loss: 0.0302
2024-05-25 04:18:10 [INFO]: Epoch 010 - training loss: 0.4746, validation loss: 0.0291
2024-05-25 04:18:16 [INFO]: Epoch 011 - training loss: 0.4528, validation loss: 0.0287
2024-05-25 04:18:22 [INFO]: Epoch 012 - training loss: 0.4352, validation loss: 0.0271
2024-05-25 04:18:28 [INFO]: Epoch 013 - training loss: 0.4277, validation loss: 0.0265
2024-05-25 04:18:34 [INFO]: Epoch 014 - training loss: 0.4219, validation loss: 0.0263
2024-05-25 04:18:41 [INFO]: Epoch 015 - training loss: 0.4176, validation loss: 0.0257
2024-05-25 04:18:47 [INFO]: Epoch 016 - training loss: 0.4087, validation loss: 0.0260
2024-05-25 04:18:53 [INFO]: Epoch 017 - training loss: 0.4028, validation loss: 0.0248
2024-05-25 04:18:59 [INFO]: Epoch 018 - training loss: 0.3989, validation loss: 0.0242
2024-05-25 04:19:06 [INFO]: Epoch 019 - training loss: 0.3938, validation loss: 0.0241
2024-05-25 04:19:12 [INFO]: Epoch 020 - training loss: 0.4054, validation loss: 0.0237
2024-05-25 04:19:18 [INFO]: Epoch 021 - training loss: 0.3979, validation loss: 0.0232
2024-05-25 04:19:24 [INFO]: Epoch 022 - training loss: 0.3911, validation loss: 0.0232
2024-05-25 04:19:30 [INFO]: Epoch 023 - training loss: 0.3844, validation loss: 0.0230
2024-05-25 04:19:37 [INFO]: Epoch 024 - training loss: 0.3855, validation loss: 0.0222
2024-05-25 04:19:43 [INFO]: Epoch 025 - training loss: 0.3782, validation loss: 0.0222
2024-05-25 04:19:49 [INFO]: Epoch 026 - training loss: 0.3853, validation loss: 0.0226
2024-05-25 04:19:55 [INFO]: Epoch 027 - training loss: 0.3778, validation loss: 0.0228
2024-05-25 04:20:02 [INFO]: Epoch 028 - training loss: 0.3774, validation loss: 0.0228
2024-05-25 04:20:08 [INFO]: Epoch 029 - training loss: 0.3808, validation loss: 0.0226
2024-05-25 04:20:14 [INFO]: Epoch 030 - training loss: 0.3800, validation loss: 0.0230
2024-05-25 04:20:20 [INFO]: Epoch 031 - training loss: 0.3790, validation loss: 0.0226
2024-05-25 04:20:27 [INFO]: Epoch 032 - training loss: 0.3829, validation loss: 0.0230
2024-05-25 04:20:33 [INFO]: Epoch 033 - training loss: 0.3890, validation loss: 0.0220
2024-05-25 04:20:39 [INFO]: Epoch 034 - training loss: 0.3766, validation loss: 0.0221
2024-05-25 04:20:45 [INFO]: Epoch 035 - training loss: 0.3767, validation loss: 0.0227
2024-05-25 04:20:52 [INFO]: Epoch 036 - training loss: 0.3801, validation loss: 0.0220
2024-05-25 04:20:58 [INFO]: Epoch 037 - training loss: 0.3748, validation loss: 0.0225
2024-05-25 04:21:04 [INFO]: Epoch 038 - training loss: 0.3819, validation loss: 0.0226
2024-05-25 04:21:10 [INFO]: Epoch 039 - training loss: 0.3828, validation loss: 0.0231
2024-05-25 04:21:17 [INFO]: Epoch 040 - training loss: 0.3761, validation loss: 0.0222
2024-05-25 04:21:23 [INFO]: Epoch 041 - training loss: 0.3786, validation loss: 0.0221
2024-05-25 04:21:29 [INFO]: Epoch 042 - training loss: 0.3706, validation loss: 0.0225
2024-05-25 04:21:35 [INFO]: Epoch 043 - training loss: 0.3702, validation loss: 0.0224
2024-05-25 04:21:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:21:35 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 04:21:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_ettm1/20240525_T041705/BRITS.pypots
2024-05-25 04:21:36 [INFO]: BRITS on ETTm1: MAE=0.1265, MSE=0.0474
2024-05-25 04:21:36 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-25 04:21:36 [INFO]: Using the given device: cuda:0
2024-05-25 04:21:36 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136
2024-05-25 04:21:36 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/tensorboard
2024-05-25 04:21:36 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 04:21:38 [INFO]: Epoch 001 - training loss: 1.4392, validation loss: 1.3084
2024-05-25 04:21:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch1_loss1.3083828836679459.pypots
2024-05-25 04:21:38 [INFO]: Epoch 002 - training loss: 1.1009, validation loss: 1.1450
2024-05-25 04:21:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch2_loss1.1450246572494507.pypots
2024-05-25 04:21:39 [INFO]: Epoch 003 - training loss: 1.0124, validation loss: 1.0602
2024-05-25 04:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch3_loss1.0602469593286514.pypots
2024-05-25 04:21:39 [INFO]: Epoch 004 - training loss: 0.9657, validation loss: 1.0162
2024-05-25 04:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch4_loss1.0161931812763214.pypots
2024-05-25 04:21:39 [INFO]: Epoch 005 - training loss: 0.9734, validation loss: 1.0025
2024-05-25 04:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch5_loss1.0025161504745483.pypots
2024-05-25 04:21:39 [INFO]: Epoch 006 - training loss: 0.9366, validation loss: 0.9927
2024-05-25 04:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch6_loss0.9927202761173248.pypots
2024-05-25 04:21:39 [INFO]: Epoch 007 - training loss: 0.9334, validation loss: 0.9874
2024-05-25 04:21:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch7_loss0.9873648136854172.pypots
2024-05-25 04:21:40 [INFO]: Epoch 008 - training loss: 0.9378, validation loss: 0.9798
2024-05-25 04:21:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch8_loss0.9798127710819244.pypots
2024-05-25 04:21:40 [INFO]: Epoch 009 - training loss: 0.9645, validation loss: 0.9806
2024-05-25 04:21:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch9_loss0.9805897921323776.pypots
2024-05-25 04:21:40 [INFO]: Epoch 010 - training loss: 0.9335, validation loss: 0.9810
2024-05-25 04:21:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch10_loss0.9809838980436325.pypots
2024-05-25 04:21:40 [INFO]: Epoch 011 - training loss: 0.9341, validation loss: 0.9802
2024-05-25 04:21:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch11_loss0.9801879525184631.pypots
2024-05-25 04:21:40 [INFO]: Epoch 012 - training loss: 0.9042, validation loss: 0.9823
2024-05-25 04:21:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch12_loss0.9822514206171036.pypots
2024-05-25 04:21:41 [INFO]: Epoch 013 - training loss: 0.8956, validation loss: 0.9806
2024-05-25 04:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch13_loss0.9805764406919479.pypots
2024-05-25 04:21:41 [INFO]: Epoch 014 - training loss: 0.8985, validation loss: 0.9806
2024-05-25 04:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch14_loss0.9806356728076935.pypots
2024-05-25 04:21:41 [INFO]: Epoch 015 - training loss: 0.8715, validation loss: 0.9809
2024-05-25 04:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch15_loss0.9808925539255142.pypots
2024-05-25 04:21:41 [INFO]: Epoch 016 - training loss: 0.8600, validation loss: 0.9799
2024-05-25 04:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch16_loss0.9798636883497238.pypots
2024-05-25 04:21:41 [INFO]: Epoch 017 - training loss: 0.8916, validation loss: 0.9775
2024-05-25 04:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch17_loss0.9775459915399551.pypots
2024-05-25 04:21:42 [INFO]: Epoch 018 - training loss: 0.8931, validation loss: 0.9802
2024-05-25 04:21:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch18_loss0.9801721274852753.pypots
2024-05-25 04:21:42 [INFO]: Epoch 019 - training loss: 0.8646, validation loss: 0.9779
2024-05-25 04:21:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch19_loss0.9778829663991928.pypots
2024-05-25 04:21:42 [INFO]: Epoch 020 - training loss: 0.8672, validation loss: 0.9793
2024-05-25 04:21:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch20_loss0.9792735576629639.pypots
2024-05-25 04:21:42 [INFO]: Epoch 021 - training loss: 0.8728, validation loss: 0.9708
2024-05-25 04:21:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch21_loss0.9707519263029099.pypots
2024-05-25 04:21:42 [INFO]: Epoch 022 - training loss: 0.8595, validation loss: 0.9700
2024-05-25 04:21:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch22_loss0.969974011182785.pypots
2024-05-25 04:21:43 [INFO]: Epoch 023 - training loss: 0.8375, validation loss: 0.9706
2024-05-25 04:21:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch23_loss0.9705507159233093.pypots
2024-05-25 04:21:43 [INFO]: Epoch 024 - training loss: 0.8478, validation loss: 0.9706
2024-05-25 04:21:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch24_loss0.9706156849861145.pypots
2024-05-25 04:21:43 [INFO]: Epoch 025 - training loss: 0.8441, validation loss: 0.9680
2024-05-25 04:21:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch25_loss0.9680323749780655.pypots
2024-05-25 04:21:43 [INFO]: Epoch 026 - training loss: 0.8350, validation loss: 0.9645
2024-05-25 04:21:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch26_loss0.9645162671804428.pypots
2024-05-25 04:21:43 [INFO]: Epoch 027 - training loss: 0.8481, validation loss: 0.9653
2024-05-25 04:21:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch27_loss0.9652737230062485.pypots
2024-05-25 04:21:44 [INFO]: Epoch 028 - training loss: 0.8352, validation loss: 0.9624
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch28_loss0.9623971283435822.pypots
2024-05-25 04:21:44 [INFO]: Epoch 029 - training loss: 0.8303, validation loss: 0.9627
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch29_loss0.9626764357089996.pypots
2024-05-25 04:21:44 [INFO]: Epoch 030 - training loss: 0.8369, validation loss: 0.9617
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch30_loss0.9617422521114349.pypots
2024-05-25 04:21:44 [INFO]: Epoch 031 - training loss: 0.8621, validation loss: 0.9595
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch31_loss0.9595425426959991.pypots
2024-05-25 04:21:44 [INFO]: Epoch 032 - training loss: 0.8463, validation loss: 0.9564
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch32_loss0.9563910365104675.pypots
2024-05-25 04:21:44 [INFO]: Epoch 033 - training loss: 0.8173, validation loss: 0.9537
2024-05-25 04:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch33_loss0.9536566883325577.pypots
2024-05-25 04:21:45 [INFO]: Epoch 034 - training loss: 0.8873, validation loss: 0.9558
2024-05-25 04:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch34_loss0.9557501822710037.pypots
2024-05-25 04:21:45 [INFO]: Epoch 035 - training loss: 0.8384, validation loss: 0.9539
2024-05-25 04:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch35_loss0.9538627415895462.pypots
2024-05-25 04:21:45 [INFO]: Epoch 036 - training loss: 0.8192, validation loss: 0.9509
2024-05-25 04:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch36_loss0.9509381353855133.pypots
2024-05-25 04:21:45 [INFO]: Epoch 037 - training loss: 0.8420, validation loss: 0.9470
2024-05-25 04:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch37_loss0.9469690471887589.pypots
2024-05-25 04:21:45 [INFO]: Epoch 038 - training loss: 0.8473, validation loss: 0.9420
2024-05-25 04:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch38_loss0.94197216629982.pypots
2024-05-25 04:21:46 [INFO]: Epoch 039 - training loss: 0.8435, validation loss: 0.9375
2024-05-25 04:21:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch39_loss0.9374811798334122.pypots
2024-05-25 04:21:46 [INFO]: Epoch 040 - training loss: 0.8121, validation loss: 0.9394
2024-05-25 04:21:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch40_loss0.9393556714057922.pypots
2024-05-25 04:21:46 [INFO]: Epoch 041 - training loss: 0.8273, validation loss: 0.9353
2024-05-25 04:21:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch41_loss0.9352678060531616.pypots
2024-05-25 04:21:46 [INFO]: Epoch 042 - training loss: 0.8475, validation loss: 0.9346
2024-05-25 04:21:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch42_loss0.934611439704895.pypots
2024-05-25 04:21:46 [INFO]: Epoch 043 - training loss: 0.7976, validation loss: 0.9274
2024-05-25 04:21:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch43_loss0.9274175316095352.pypots
2024-05-25 04:21:47 [INFO]: Epoch 044 - training loss: 0.8217, validation loss: 0.9279
2024-05-25 04:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch44_loss0.9278919398784637.pypots
2024-05-25 04:21:47 [INFO]: Epoch 045 - training loss: 0.8171, validation loss: 0.9259
2024-05-25 04:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch45_loss0.9258565008640289.pypots
2024-05-25 04:21:47 [INFO]: Epoch 046 - training loss: 0.8056, validation loss: 0.9220
2024-05-25 04:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch46_loss0.9219875037670135.pypots
2024-05-25 04:21:47 [INFO]: Epoch 047 - training loss: 0.8421, validation loss: 0.9212
2024-05-25 04:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch47_loss0.9212107211351395.pypots
2024-05-25 04:21:47 [INFO]: Epoch 048 - training loss: 0.8027, validation loss: 0.9176
2024-05-25 04:21:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch48_loss0.9175659120082855.pypots
2024-05-25 04:21:48 [INFO]: Epoch 049 - training loss: 0.8558, validation loss: 0.9149
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch49_loss0.9149082452058792.pypots
2024-05-25 04:21:48 [INFO]: Epoch 050 - training loss: 0.8531, validation loss: 0.9100
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch50_loss0.9099908769130707.pypots
2024-05-25 04:21:48 [INFO]: Epoch 051 - training loss: 0.8180, validation loss: 0.9071
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch51_loss0.9071345925331116.pypots
2024-05-25 04:21:48 [INFO]: Epoch 052 - training loss: 0.8042, validation loss: 0.9066
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch52_loss0.906638041138649.pypots
2024-05-25 04:21:48 [INFO]: Epoch 053 - training loss: 0.7944, validation loss: 0.9034
2024-05-25 04:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch53_loss0.9033572822809219.pypots
2024-05-25 04:21:49 [INFO]: Epoch 054 - training loss: 0.7901, validation loss: 0.9003
2024-05-25 04:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch54_loss0.9003196358680725.pypots
2024-05-25 04:21:49 [INFO]: Epoch 055 - training loss: 0.8152, validation loss: 0.9043
2024-05-25 04:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch55_loss0.9043073356151581.pypots
2024-05-25 04:21:49 [INFO]: Epoch 056 - training loss: 0.8151, validation loss: 0.8979
2024-05-25 04:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch56_loss0.8978569805622101.pypots
2024-05-25 04:21:49 [INFO]: Epoch 057 - training loss: 0.7972, validation loss: 0.8973
2024-05-25 04:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch57_loss0.8972825556993484.pypots
2024-05-25 04:21:49 [INFO]: Epoch 058 - training loss: 0.8140, validation loss: 0.8932
2024-05-25 04:21:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch58_loss0.8931776136159897.pypots
2024-05-25 04:21:50 [INFO]: Epoch 059 - training loss: 0.8059, validation loss: 0.8952
2024-05-25 04:21:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch59_loss0.8951869308948517.pypots
2024-05-25 04:21:50 [INFO]: Epoch 060 - training loss: 0.8027, validation loss: 0.8871
2024-05-25 04:21:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch60_loss0.8870713710784912.pypots
2024-05-25 04:21:50 [INFO]: Epoch 061 - training loss: 0.7841, validation loss: 0.8871
2024-05-25 04:21:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch61_loss0.8870661407709122.pypots
2024-05-25 04:21:50 [INFO]: Epoch 062 - training loss: 0.8004, validation loss: 0.8870
2024-05-25 04:21:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch62_loss0.8869809359312057.pypots
2024-05-25 04:21:50 [INFO]: Epoch 063 - training loss: 0.8528, validation loss: 0.8846
2024-05-25 04:21:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch63_loss0.8845731019973755.pypots
2024-05-25 04:21:51 [INFO]: Epoch 064 - training loss: 0.8031, validation loss: 0.8804
2024-05-25 04:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch64_loss0.8803818374872208.pypots
2024-05-25 04:21:51 [INFO]: Epoch 065 - training loss: 0.7920, validation loss: 0.8819
2024-05-25 04:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch65_loss0.881860613822937.pypots
2024-05-25 04:21:51 [INFO]: Epoch 066 - training loss: 0.8046, validation loss: 0.8804
2024-05-25 04:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch66_loss0.8804189711809158.pypots
2024-05-25 04:21:51 [INFO]: Epoch 067 - training loss: 0.7987, validation loss: 0.8782
2024-05-25 04:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch67_loss0.8782406002283096.pypots
2024-05-25 04:21:51 [INFO]: Epoch 068 - training loss: 0.8153, validation loss: 0.8772
2024-05-25 04:21:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch68_loss0.8772397488355637.pypots
2024-05-25 04:21:51 [INFO]: Epoch 069 - training loss: 0.7848, validation loss: 0.8800
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch69_loss0.8799610286951065.pypots
2024-05-25 04:21:52 [INFO]: Epoch 070 - training loss: 0.7961, validation loss: 0.8749
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch70_loss0.874865248799324.pypots
2024-05-25 04:21:52 [INFO]: Epoch 071 - training loss: 0.7929, validation loss: 0.8771
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch71_loss0.87712562084198.pypots
2024-05-25 04:21:52 [INFO]: Epoch 072 - training loss: 0.8065, validation loss: 0.8689
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch72_loss0.8689223527908325.pypots
2024-05-25 04:21:52 [INFO]: Epoch 073 - training loss: 0.8041, validation loss: 0.8719
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch73_loss0.8718796074390411.pypots
2024-05-25 04:21:52 [INFO]: Epoch 074 - training loss: 0.7779, validation loss: 0.8739
2024-05-25 04:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch74_loss0.8739299476146698.pypots
2024-05-25 04:21:53 [INFO]: Epoch 075 - training loss: 0.8083, validation loss: 0.8710
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch75_loss0.8710186928510666.pypots
2024-05-25 04:21:53 [INFO]: Epoch 076 - training loss: 0.7985, validation loss: 0.8704
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch76_loss0.8704094439744949.pypots
2024-05-25 04:21:53 [INFO]: Epoch 077 - training loss: 0.7963, validation loss: 0.8684
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch77_loss0.8684139996767044.pypots
2024-05-25 04:21:53 [INFO]: Epoch 078 - training loss: 0.7799, validation loss: 0.8695
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch78_loss0.8694880306720734.pypots
2024-05-25 04:21:53 [INFO]: Epoch 079 - training loss: 0.8120, validation loss: 0.8683
2024-05-25 04:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch79_loss0.8683135360479355.pypots
2024-05-25 04:21:54 [INFO]: Epoch 080 - training loss: 0.7922, validation loss: 0.8654
2024-05-25 04:21:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch80_loss0.8654108345508575.pypots
2024-05-25 04:21:54 [INFO]: Epoch 081 - training loss: 0.7851, validation loss: 0.8655
2024-05-25 04:21:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch81_loss0.865535095334053.pypots
2024-05-25 04:21:54 [INFO]: Epoch 082 - training loss: 0.8547, validation loss: 0.8649
2024-05-25 04:21:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch82_loss0.8648624122142792.pypots
2024-05-25 04:21:54 [INFO]: Epoch 083 - training loss: 0.8271, validation loss: 0.8701
2024-05-25 04:21:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch83_loss0.870062917470932.pypots
2024-05-25 04:21:54 [INFO]: Epoch 084 - training loss: 0.8136, validation loss: 0.8613
2024-05-25 04:21:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch84_loss0.8613468557596207.pypots
2024-05-25 04:21:55 [INFO]: Epoch 085 - training loss: 0.8243, validation loss: 0.8655
2024-05-25 04:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch85_loss0.8654741197824478.pypots
2024-05-25 04:21:55 [INFO]: Epoch 086 - training loss: 0.8138, validation loss: 0.8644
2024-05-25 04:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch86_loss0.8643585592508316.pypots
2024-05-25 04:21:55 [INFO]: Epoch 087 - training loss: 0.7956, validation loss: 0.8626
2024-05-25 04:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch87_loss0.8626357764005661.pypots
2024-05-25 04:21:55 [INFO]: Epoch 088 - training loss: 0.7816, validation loss: 0.8607
2024-05-25 04:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch88_loss0.8606690615415573.pypots
2024-05-25 04:21:55 [INFO]: Epoch 089 - training loss: 0.7949, validation loss: 0.8625
2024-05-25 04:21:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch89_loss0.86247918009758.pypots
2024-05-25 04:21:56 [INFO]: Epoch 090 - training loss: 0.7885, validation loss: 0.8586
2024-05-25 04:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch90_loss0.8585667461156845.pypots
2024-05-25 04:21:56 [INFO]: Epoch 091 - training loss: 0.7971, validation loss: 0.8595
2024-05-25 04:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch91_loss0.8595018833875656.pypots
2024-05-25 04:21:56 [INFO]: Epoch 092 - training loss: 0.8002, validation loss: 0.8563
2024-05-25 04:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch92_loss0.8563409596681595.pypots
2024-05-25 04:21:56 [INFO]: Epoch 093 - training loss: 0.7682, validation loss: 0.8595
2024-05-25 04:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch93_loss0.859472244977951.pypots
2024-05-25 04:21:56 [INFO]: Epoch 094 - training loss: 0.7882, validation loss: 0.8577
2024-05-25 04:21:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch94_loss0.8576778918504715.pypots
2024-05-25 04:21:57 [INFO]: Epoch 095 - training loss: 0.7898, validation loss: 0.8576
2024-05-25 04:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch95_loss0.8575595170259476.pypots
2024-05-25 04:21:57 [INFO]: Epoch 096 - training loss: 0.7991, validation loss: 0.8559
2024-05-25 04:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch96_loss0.8559280782938004.pypots
2024-05-25 04:21:57 [INFO]: Epoch 097 - training loss: 0.8136, validation loss: 0.8552
2024-05-25 04:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch97_loss0.8551924824714661.pypots
2024-05-25 04:21:57 [INFO]: Epoch 098 - training loss: 0.7838, validation loss: 0.8582
2024-05-25 04:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch98_loss0.8582342714071274.pypots
2024-05-25 04:21:57 [INFO]: Epoch 099 - training loss: 0.7903, validation loss: 0.8556
2024-05-25 04:21:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch99_loss0.8556367307901382.pypots
2024-05-25 04:21:58 [INFO]: Epoch 100 - training loss: 0.7834, validation loss: 0.8538
2024-05-25 04:21:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch100_loss0.8537664264440536.pypots
2024-05-25 04:21:58 [INFO]: Epoch 101 - training loss: 0.7935, validation loss: 0.8545
2024-05-25 04:21:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch101_loss0.8544563204050064.pypots
2024-05-25 04:21:58 [INFO]: Epoch 102 - training loss: 0.7734, validation loss: 0.8529
2024-05-25 04:21:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch102_loss0.8528665155172348.pypots
2024-05-25 04:21:58 [INFO]: Epoch 103 - training loss: 0.7828, validation loss: 0.8538
2024-05-25 04:21:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch103_loss0.8538194894790649.pypots
2024-05-25 04:21:58 [INFO]: Epoch 104 - training loss: 0.7986, validation loss: 0.8503
2024-05-25 04:21:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch104_loss0.8502829372882843.pypots
2024-05-25 04:21:59 [INFO]: Epoch 105 - training loss: 0.7658, validation loss: 0.8518
2024-05-25 04:21:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch105_loss0.8517833352088928.pypots
2024-05-25 04:21:59 [INFO]: Epoch 106 - training loss: 0.7779, validation loss: 0.8549
2024-05-25 04:21:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch106_loss0.8548697084188461.pypots
2024-05-25 04:21:59 [INFO]: Epoch 107 - training loss: 0.8002, validation loss: 0.8511
2024-05-25 04:21:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch107_loss0.8511021137237549.pypots
2024-05-25 04:21:59 [INFO]: Epoch 108 - training loss: 0.7911, validation loss: 0.8513
2024-05-25 04:21:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch108_loss0.8513428270816803.pypots
2024-05-25 04:21:59 [INFO]: Epoch 109 - training loss: 0.7787, validation loss: 0.8504
2024-05-25 04:21:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch109_loss0.8503531068563461.pypots
2024-05-25 04:22:00 [INFO]: Epoch 110 - training loss: 0.7773, validation loss: 0.8516
2024-05-25 04:22:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch110_loss0.8515975624322891.pypots
2024-05-25 04:22:00 [INFO]: Epoch 111 - training loss: 0.7905, validation loss: 0.8464
2024-05-25 04:22:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch111_loss0.8463737517595291.pypots
2024-05-25 04:22:00 [INFO]: Epoch 112 - training loss: 0.7759, validation loss: 0.8495
2024-05-25 04:22:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch112_loss0.8494606018066406.pypots
2024-05-25 04:22:00 [INFO]: Epoch 113 - training loss: 0.8139, validation loss: 0.8531
2024-05-25 04:22:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch113_loss0.8530523627996445.pypots
2024-05-25 04:22:00 [INFO]: Epoch 114 - training loss: 0.7694, validation loss: 0.8476
2024-05-25 04:22:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch114_loss0.8476004004478455.pypots
2024-05-25 04:22:01 [INFO]: Epoch 115 - training loss: 0.7914, validation loss: 0.8519
2024-05-25 04:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch115_loss0.851874902844429.pypots
2024-05-25 04:22:01 [INFO]: Epoch 116 - training loss: 0.7964, validation loss: 0.8471
2024-05-25 04:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch116_loss0.8471468985080719.pypots
2024-05-25 04:22:01 [INFO]: Epoch 117 - training loss: 0.8027, validation loss: 0.8470
2024-05-25 04:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch117_loss0.84699746966362.pypots
2024-05-25 04:22:01 [INFO]: Epoch 118 - training loss: 0.7699, validation loss: 0.8433
2024-05-25 04:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch118_loss0.8433287441730499.pypots
2024-05-25 04:22:01 [INFO]: Epoch 119 - training loss: 0.7761, validation loss: 0.8444
2024-05-25 04:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch119_loss0.8443533480167389.pypots
2024-05-25 04:22:02 [INFO]: Epoch 120 - training loss: 0.7725, validation loss: 0.8447
2024-05-25 04:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch120_loss0.8447363823652267.pypots
2024-05-25 04:22:02 [INFO]: Epoch 121 - training loss: 0.7974, validation loss: 0.8434
2024-05-25 04:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch121_loss0.8433626890182495.pypots
2024-05-25 04:22:02 [INFO]: Epoch 122 - training loss: 0.7765, validation loss: 0.8431
2024-05-25 04:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch122_loss0.8431478887796402.pypots
2024-05-25 04:22:02 [INFO]: Epoch 123 - training loss: 0.7747, validation loss: 0.8445
2024-05-25 04:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch123_loss0.8445362448692322.pypots
2024-05-25 04:22:02 [INFO]: Epoch 124 - training loss: 0.7954, validation loss: 0.8434
2024-05-25 04:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch124_loss0.8434443473815918.pypots
2024-05-25 04:22:03 [INFO]: Epoch 125 - training loss: 0.7854, validation loss: 0.8421
2024-05-25 04:22:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch125_loss0.8420952558517456.pypots
2024-05-25 04:22:03 [INFO]: Epoch 126 - training loss: 0.7837, validation loss: 0.8418
2024-05-25 04:22:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch126_loss0.8417939096689224.pypots
2024-05-25 04:22:03 [INFO]: Epoch 127 - training loss: 0.7603, validation loss: 0.8425
2024-05-25 04:22:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch127_loss0.8424876034259796.pypots
2024-05-25 04:22:03 [INFO]: Epoch 128 - training loss: 0.7780, validation loss: 0.8414
2024-05-25 04:22:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch128_loss0.8414099514484406.pypots
2024-05-25 04:22:03 [INFO]: Epoch 129 - training loss: 0.7837, validation loss: 0.8392
2024-05-25 04:22:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch129_loss0.8392234742641449.pypots
2024-05-25 04:22:04 [INFO]: Epoch 130 - training loss: 0.7964, validation loss: 0.8394
2024-05-25 04:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch130_loss0.8394321501255035.pypots
2024-05-25 04:22:04 [INFO]: Epoch 131 - training loss: 0.8334, validation loss: 0.8382
2024-05-25 04:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch131_loss0.8381941169500351.pypots
2024-05-25 04:22:04 [INFO]: Epoch 132 - training loss: 0.7777, validation loss: 0.8363
2024-05-25 04:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch132_loss0.8363056182861328.pypots
2024-05-25 04:22:04 [INFO]: Epoch 133 - training loss: 0.7981, validation loss: 0.8384
2024-05-25 04:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch133_loss0.8384304940700531.pypots
2024-05-25 04:22:04 [INFO]: Epoch 134 - training loss: 0.7655, validation loss: 0.8379
2024-05-25 04:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch134_loss0.8379149734973907.pypots
2024-05-25 04:22:05 [INFO]: Epoch 135 - training loss: 0.7697, validation loss: 0.8449
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch135_loss0.8448927104473114.pypots
2024-05-25 04:22:05 [INFO]: Epoch 136 - training loss: 0.7962, validation loss: 0.8357
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch136_loss0.8356572985649109.pypots
2024-05-25 04:22:05 [INFO]: Epoch 137 - training loss: 0.7691, validation loss: 0.8338
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch137_loss0.8337796628475189.pypots
2024-05-25 04:22:05 [INFO]: Epoch 138 - training loss: 0.7724, validation loss: 0.8357
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch138_loss0.8357084542512894.pypots
2024-05-25 04:22:05 [INFO]: Epoch 139 - training loss: 0.7706, validation loss: 0.8350
2024-05-25 04:22:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch139_loss0.8349599093198776.pypots
2024-05-25 04:22:06 [INFO]: Epoch 140 - training loss: 0.7912, validation loss: 0.8325
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch140_loss0.8324705064296722.pypots
2024-05-25 04:22:06 [INFO]: Epoch 141 - training loss: 0.8024, validation loss: 0.8336
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch141_loss0.8335642665624619.pypots
2024-05-25 04:22:06 [INFO]: Epoch 142 - training loss: 0.7870, validation loss: 0.8307
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch142_loss0.830737441778183.pypots
2024-05-25 04:22:06 [INFO]: Epoch 143 - training loss: 0.7932, validation loss: 0.8343
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch143_loss0.8342751115560532.pypots
2024-05-25 04:22:06 [INFO]: Epoch 144 - training loss: 0.7731, validation loss: 0.8318
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch144_loss0.8317863047122955.pypots
2024-05-25 04:22:06 [INFO]: Epoch 145 - training loss: 0.7881, validation loss: 0.8280
2024-05-25 04:22:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch145_loss0.8280109316110611.pypots
2024-05-25 04:22:07 [INFO]: Epoch 146 - training loss: 0.7842, validation loss: 0.8308
2024-05-25 04:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch146_loss0.8308341056108475.pypots
2024-05-25 04:22:07 [INFO]: Epoch 147 - training loss: 0.7799, validation loss: 0.8284
2024-05-25 04:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch147_loss0.8283572942018509.pypots
2024-05-25 04:22:07 [INFO]: Epoch 148 - training loss: 0.7689, validation loss: 0.8311
2024-05-25 04:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch148_loss0.8310639411211014.pypots
2024-05-25 04:22:07 [INFO]: Epoch 149 - training loss: 0.7753, validation loss: 0.8305
2024-05-25 04:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch149_loss0.8304669559001923.pypots
2024-05-25 04:22:07 [INFO]: Epoch 150 - training loss: 0.7683, validation loss: 0.8268
2024-05-25 04:22:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch150_loss0.826759397983551.pypots
2024-05-25 04:22:08 [INFO]: Epoch 151 - training loss: 0.8035, validation loss: 0.8299
2024-05-25 04:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch151_loss0.8299423456192017.pypots
2024-05-25 04:22:08 [INFO]: Epoch 152 - training loss: 0.8235, validation loss: 0.8274
2024-05-25 04:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch152_loss0.827431932091713.pypots
2024-05-25 04:22:08 [INFO]: Epoch 153 - training loss: 0.8304, validation loss: 0.8273
2024-05-25 04:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch153_loss0.827313095331192.pypots
2024-05-25 04:22:08 [INFO]: Epoch 154 - training loss: 0.8074, validation loss: 0.8284
2024-05-25 04:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch154_loss0.828403115272522.pypots
2024-05-25 04:22:08 [INFO]: Epoch 155 - training loss: 0.7917, validation loss: 0.8329
2024-05-25 04:22:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch155_loss0.8328626751899719.pypots
2024-05-25 04:22:09 [INFO]: Epoch 156 - training loss: 0.7936, validation loss: 0.8246
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch156_loss0.8246491253376007.pypots
2024-05-25 04:22:09 [INFO]: Epoch 157 - training loss: 0.7970, validation loss: 0.8265
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch157_loss0.8264897167682648.pypots
2024-05-25 04:22:09 [INFO]: Epoch 158 - training loss: 0.7719, validation loss: 0.8267
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch158_loss0.8267355114221573.pypots
2024-05-25 04:22:09 [INFO]: Epoch 159 - training loss: 0.7681, validation loss: 0.8284
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch159_loss0.8284087032079697.pypots
2024-05-25 04:22:09 [INFO]: Epoch 160 - training loss: 0.7862, validation loss: 0.8271
2024-05-25 04:22:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch160_loss0.8271077126264572.pypots
2024-05-25 04:22:10 [INFO]: Epoch 161 - training loss: 0.7882, validation loss: 0.8248
2024-05-25 04:22:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch161_loss0.8248404711484909.pypots
2024-05-25 04:22:10 [INFO]: Epoch 162 - training loss: 0.7877, validation loss: 0.8229
2024-05-25 04:22:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch162_loss0.8229046314954758.pypots
2024-05-25 04:22:10 [INFO]: Epoch 163 - training loss: 0.7703, validation loss: 0.8217
2024-05-25 04:22:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch163_loss0.821669191122055.pypots
2024-05-25 04:22:10 [INFO]: Epoch 164 - training loss: 0.7773, validation loss: 0.8176
2024-05-25 04:22:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch164_loss0.8175995349884033.pypots
2024-05-25 04:22:10 [INFO]: Epoch 165 - training loss: 0.7790, validation loss: 0.8234
2024-05-25 04:22:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch165_loss0.8234308660030365.pypots
2024-05-25 04:22:11 [INFO]: Epoch 166 - training loss: 0.7664, validation loss: 0.8249
2024-05-25 04:22:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch166_loss0.8249199688434601.pypots
2024-05-25 04:22:11 [INFO]: Epoch 167 - training loss: 0.7845, validation loss: 0.8218
2024-05-25 04:22:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch167_loss0.8218032568693161.pypots
2024-05-25 04:22:11 [INFO]: Epoch 168 - training loss: 0.7645, validation loss: 0.8229
2024-05-25 04:22:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch168_loss0.8228630870580673.pypots
2024-05-25 04:22:11 [INFO]: Epoch 169 - training loss: 0.7848, validation loss: 0.8208
2024-05-25 04:22:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch169_loss0.8208477646112442.pypots
2024-05-25 04:22:11 [INFO]: Epoch 170 - training loss: 0.8190, validation loss: 0.8185
2024-05-25 04:22:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch170_loss0.8185370862483978.pypots
2024-05-25 04:22:12 [INFO]: Epoch 171 - training loss: 0.8144, validation loss: 0.8184
2024-05-25 04:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch171_loss0.8183545172214508.pypots
2024-05-25 04:22:12 [INFO]: Epoch 172 - training loss: 0.7875, validation loss: 0.8187
2024-05-25 04:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch172_loss0.8186778426170349.pypots
2024-05-25 04:22:12 [INFO]: Epoch 173 - training loss: 0.8020, validation loss: 0.8181
2024-05-25 04:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch173_loss0.8181188553571701.pypots
2024-05-25 04:22:12 [INFO]: Epoch 174 - training loss: 0.7792, validation loss: 0.8198
2024-05-25 04:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN_epoch174_loss0.8197856694459915.pypots
2024-05-25 04:22:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:22:12 [INFO]: Finished training. The best model is from epoch#164.
2024-05-25 04:22:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240525_T042136/MRNN.pypots
2024-05-25 04:22:13 [INFO]: MRNN on ETTm1: MAE=0.6802, MSE=1.1389
2024-05-25 04:22:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-25 04:22:13 [INFO]: Using the given device: cpu
2024-05-25 04:22:13 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 04:22:13 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-25 04:22:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-25 04:22:13 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 04:22:13 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-25 04:22:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-25 04:22:13 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 04:22:13 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-25 04:22:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-25 04:22:13 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 04:22:13 [INFO]: Using the given device: cuda:0
2024-05-25 04:22:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T042213
2024-05-25 04:22:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T042213/tensorboard
2024-05-25 04:22:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 04:22:13 [INFO]: Epoch 001 - training loss: 1.0768, validation loss: 0.2584
2024-05-25 04:22:14 [INFO]: Epoch 002 - training loss: 0.7799, validation loss: 0.1261
2024-05-25 04:22:14 [INFO]: Epoch 003 - training loss: 0.6936, validation loss: 0.0922
2024-05-25 04:22:15 [INFO]: Epoch 004 - training loss: 0.6308, validation loss: 0.0829
2024-05-25 04:22:15 [INFO]: Epoch 005 - training loss: 0.6020, validation loss: 0.1026
2024-05-25 04:22:16 [INFO]: Epoch 006 - training loss: 0.5713, validation loss: 0.0741
2024-05-25 04:22:16 [INFO]: Epoch 007 - training loss: 0.5476, validation loss: 0.0652
2024-05-25 04:22:17 [INFO]: Epoch 008 - training loss: 0.5298, validation loss: 0.0609
2024-05-25 04:22:17 [INFO]: Epoch 009 - training loss: 0.5439, validation loss: 0.0564
2024-05-25 04:22:18 [INFO]: Epoch 010 - training loss: 0.5183, validation loss: 0.0682
2024-05-25 04:22:18 [INFO]: Epoch 011 - training loss: 0.5100, validation loss: 0.0539
2024-05-25 04:22:19 [INFO]: Epoch 012 - training loss: 0.5064, validation loss: 0.0685
2024-05-25 04:22:19 [INFO]: Epoch 013 - training loss: 0.4920, validation loss: 0.0491
2024-05-25 04:22:20 [INFO]: Epoch 014 - training loss: 0.4830, validation loss: 0.0613
2024-05-25 04:22:20 [INFO]: Epoch 015 - training loss: 0.4693, validation loss: 0.0508
2024-05-25 04:22:21 [INFO]: Epoch 016 - training loss: 0.4615, validation loss: 0.0528
2024-05-25 04:22:21 [INFO]: Epoch 017 - training loss: 0.4487, validation loss: 0.0455
2024-05-25 04:22:22 [INFO]: Epoch 018 - training loss: 0.4450, validation loss: 0.0507
2024-05-25 04:22:22 [INFO]: Epoch 019 - training loss: 0.4396, validation loss: 0.0396
2024-05-25 04:22:23 [INFO]: Epoch 020 - training loss: 0.4300, validation loss: 0.0432
2024-05-25 04:22:23 [INFO]: Epoch 021 - training loss: 0.4209, validation loss: 0.0396
2024-05-25 04:22:24 [INFO]: Epoch 022 - training loss: 0.4084, validation loss: 0.0372
2024-05-25 04:22:24 [INFO]: Epoch 023 - training loss: 0.4054, validation loss: 0.0424
2024-05-25 04:22:25 [INFO]: Epoch 024 - training loss: 0.4021, validation loss: 0.0427
2024-05-25 04:22:25 [INFO]: Epoch 025 - training loss: 0.4025, validation loss: 0.0442
2024-05-25 04:22:26 [INFO]: Epoch 026 - training loss: 0.3995, validation loss: 0.0985
2024-05-25 04:22:26 [INFO]: Epoch 027 - training loss: 0.4372, validation loss: 0.0405
2024-05-25 04:22:27 [INFO]: Epoch 028 - training loss: 0.3946, validation loss: 0.0405
2024-05-25 04:22:27 [INFO]: Epoch 029 - training loss: 0.3816, validation loss: 0.0398
2024-05-25 04:22:28 [INFO]: Epoch 030 - training loss: 0.3732, validation loss: 0.0394
2024-05-25 04:22:28 [INFO]: Epoch 031 - training loss: 0.3632, validation loss: 0.0425
2024-05-25 04:22:29 [INFO]: Epoch 032 - training loss: 0.3651, validation loss: 0.0400
2024-05-25 04:22:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:22:29 [INFO]: Finished training. The best model is from epoch#22.
2024-05-25 04:22:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_ettm1/20240525_T042213/SAITS.pypots
2024-05-25 04:22:29 [INFO]: SAITS on ETTm1: MAE=0.1725, MSE=0.0541
2024-05-25 04:22:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-25 04:22:29 [INFO]: Using the given device: cuda:0
2024-05-25 04:22:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T042229
2024-05-25 04:22:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T042229/tensorboard
2024-05-25 04:22:29 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 04:22:29 [INFO]: Epoch 001 - training loss: 1.1341, validation loss: 0.2555
2024-05-25 04:22:29 [INFO]: Epoch 002 - training loss: 0.6546, validation loss: 0.1293
2024-05-25 04:22:29 [INFO]: Epoch 003 - training loss: 0.5434, validation loss: 0.0921
2024-05-25 04:22:30 [INFO]: Epoch 004 - training loss: 0.4857, validation loss: 0.0914
2024-05-25 04:22:30 [INFO]: Epoch 005 - training loss: 0.4605, validation loss: 0.0723
2024-05-25 04:22:30 [INFO]: Epoch 006 - training loss: 0.4342, validation loss: 0.0686
2024-05-25 04:22:30 [INFO]: Epoch 007 - training loss: 0.4048, validation loss: 0.0629
2024-05-25 04:22:30 [INFO]: Epoch 008 - training loss: 0.3954, validation loss: 0.0609
2024-05-25 04:22:30 [INFO]: Epoch 009 - training loss: 0.3898, validation loss: 0.0589
2024-05-25 04:22:31 [INFO]: Epoch 010 - training loss: 0.3723, validation loss: 0.0558
2024-05-25 04:22:31 [INFO]: Epoch 011 - training loss: 0.3625, validation loss: 0.0513
2024-05-25 04:22:31 [INFO]: Epoch 012 - training loss: 0.3503, validation loss: 0.0524
2024-05-25 04:22:31 [INFO]: Epoch 013 - training loss: 0.3451, validation loss: 0.0470
2024-05-25 04:22:31 [INFO]: Epoch 014 - training loss: 0.3419, validation loss: 0.0510
2024-05-25 04:22:32 [INFO]: Epoch 015 - training loss: 0.3383, validation loss: 0.0490
2024-05-25 04:22:32 [INFO]: Epoch 016 - training loss: 0.3310, validation loss: 0.0446
2024-05-25 04:22:32 [INFO]: Epoch 017 - training loss: 0.3310, validation loss: 0.0439
2024-05-25 04:22:32 [INFO]: Epoch 018 - training loss: 0.3213, validation loss: 0.0453
2024-05-25 04:22:32 [INFO]: Epoch 019 - training loss: 0.3148, validation loss: 0.0429
2024-05-25 04:22:33 [INFO]: Epoch 020 - training loss: 0.3175, validation loss: 0.0452
2024-05-25 04:22:33 [INFO]: Epoch 021 - training loss: 0.3027, validation loss: 0.0399
2024-05-25 04:22:33 [INFO]: Epoch 022 - training loss: 0.3025, validation loss: 0.0410
2024-05-25 04:22:33 [INFO]: Epoch 023 - training loss: 0.2958, validation loss: 0.0397
2024-05-25 04:22:33 [INFO]: Epoch 024 - training loss: 0.2920, validation loss: 0.0386
2024-05-25 04:22:34 [INFO]: Epoch 025 - training loss: 0.2933, validation loss: 0.0374
2024-05-25 04:22:34 [INFO]: Epoch 026 - training loss: 0.2824, validation loss: 0.0380
2024-05-25 04:22:34 [INFO]: Epoch 027 - training loss: 0.2828, validation loss: 0.0418
2024-05-25 04:22:34 [INFO]: Epoch 028 - training loss: 0.2870, validation loss: 0.0421
2024-05-25 04:22:34 [INFO]: Epoch 029 - training loss: 0.2831, validation loss: 0.0390
2024-05-25 04:22:35 [INFO]: Epoch 030 - training loss: 0.2844, validation loss: 0.0373
2024-05-25 04:22:35 [INFO]: Epoch 031 - training loss: 0.2754, validation loss: 0.0360
2024-05-25 04:22:35 [INFO]: Epoch 032 - training loss: 0.2659, validation loss: 0.0396
2024-05-25 04:22:35 [INFO]: Epoch 033 - training loss: 0.2797, validation loss: 0.0353
2024-05-25 04:22:35 [INFO]: Epoch 034 - training loss: 0.2661, validation loss: 0.0334
2024-05-25 04:22:36 [INFO]: Epoch 035 - training loss: 0.2597, validation loss: 0.0364
2024-05-25 04:22:36 [INFO]: Epoch 036 - training loss: 0.2733, validation loss: 0.0355
2024-05-25 04:22:36 [INFO]: Epoch 037 - training loss: 0.2593, validation loss: 0.0369
2024-05-25 04:22:36 [INFO]: Epoch 038 - training loss: 0.2644, validation loss: 0.0358
2024-05-25 04:22:36 [INFO]: Epoch 039 - training loss: 0.2617, validation loss: 0.0318
2024-05-25 04:22:37 [INFO]: Epoch 040 - training loss: 0.2561, validation loss: 0.0356
2024-05-25 04:22:37 [INFO]: Epoch 041 - training loss: 0.2597, validation loss: 0.0336
2024-05-25 04:22:37 [INFO]: Epoch 042 - training loss: 0.2529, validation loss: 0.0312
2024-05-25 04:22:37 [INFO]: Epoch 043 - training loss: 0.2475, validation loss: 0.0331
2024-05-25 04:22:37 [INFO]: Epoch 044 - training loss: 0.2598, validation loss: 0.0307
2024-05-25 04:22:38 [INFO]: Epoch 045 - training loss: 0.2486, validation loss: 0.0304
2024-05-25 04:22:38 [INFO]: Epoch 046 - training loss: 0.2452, validation loss: 0.0304
2024-05-25 04:22:38 [INFO]: Epoch 047 - training loss: 0.2449, validation loss: 0.0297
2024-05-25 04:22:38 [INFO]: Epoch 048 - training loss: 0.2425, validation loss: 0.0315
2024-05-25 04:22:38 [INFO]: Epoch 049 - training loss: 0.2439, validation loss: 0.0283
2024-05-25 04:22:39 [INFO]: Epoch 050 - training loss: 0.2383, validation loss: 0.0285
2024-05-25 04:22:39 [INFO]: Epoch 051 - training loss: 0.2368, validation loss: 0.0344
2024-05-25 04:22:39 [INFO]: Epoch 052 - training loss: 0.2506, validation loss: 0.0305
2024-05-25 04:22:39 [INFO]: Epoch 053 - training loss: 0.2421, validation loss: 0.0311
2024-05-25 04:22:39 [INFO]: Epoch 054 - training loss: 0.2354, validation loss: 0.0344
2024-05-25 04:22:40 [INFO]: Epoch 055 - training loss: 0.2419, validation loss: 0.0324
2024-05-25 04:22:40 [INFO]: Epoch 056 - training loss: 0.2382, validation loss: 0.0289
2024-05-25 04:22:40 [INFO]: Epoch 057 - training loss: 0.2259, validation loss: 0.0302
2024-05-25 04:22:40 [INFO]: Epoch 058 - training loss: 0.2265, validation loss: 0.0304
2024-05-25 04:22:40 [INFO]: Epoch 059 - training loss: 0.2355, validation loss: 0.0279
2024-05-25 04:22:41 [INFO]: Epoch 060 - training loss: 0.2378, validation loss: 0.0289
2024-05-25 04:22:41 [INFO]: Epoch 061 - training loss: 0.2305, validation loss: 0.0268
2024-05-25 04:22:41 [INFO]: Epoch 062 - training loss: 0.2213, validation loss: 0.0267
2024-05-25 04:22:41 [INFO]: Epoch 063 - training loss: 0.2214, validation loss: 0.0292
2024-05-25 04:22:41 [INFO]: Epoch 064 - training loss: 0.2154, validation loss: 0.0269
2024-05-25 04:22:42 [INFO]: Epoch 065 - training loss: 0.2155, validation loss: 0.0284
2024-05-25 04:22:42 [INFO]: Epoch 066 - training loss: 0.2185, validation loss: 0.0286
2024-05-25 04:22:42 [INFO]: Epoch 067 - training loss: 0.2179, validation loss: 0.0268
2024-05-25 04:22:42 [INFO]: Epoch 068 - training loss: 0.2125, validation loss: 0.0280
2024-05-25 04:22:42 [INFO]: Epoch 069 - training loss: 0.2230, validation loss: 0.0262
2024-05-25 04:22:43 [INFO]: Epoch 070 - training loss: 0.2102, validation loss: 0.0267
2024-05-25 04:22:43 [INFO]: Epoch 071 - training loss: 0.2085, validation loss: 0.0269
2024-05-25 04:22:43 [INFO]: Epoch 072 - training loss: 0.2056, validation loss: 0.0287
2024-05-25 04:22:43 [INFO]: Epoch 073 - training loss: 0.2080, validation loss: 0.0271
2024-05-25 04:22:43 [INFO]: Epoch 074 - training loss: 0.2079, validation loss: 0.0308
2024-05-25 04:22:44 [INFO]: Epoch 075 - training loss: 0.2069, validation loss: 0.0256
2024-05-25 04:22:44 [INFO]: Epoch 076 - training loss: 0.2062, validation loss: 0.0280
2024-05-25 04:22:44 [INFO]: Epoch 077 - training loss: 0.2164, validation loss: 0.0269
2024-05-25 04:22:44 [INFO]: Epoch 078 - training loss: 0.2133, validation loss: 0.0284
2024-05-25 04:22:44 [INFO]: Epoch 079 - training loss: 0.2053, validation loss: 0.0272
2024-05-25 04:22:44 [INFO]: Epoch 080 - training loss: 0.2036, validation loss: 0.0264
2024-05-25 04:22:45 [INFO]: Epoch 081 - training loss: 0.1989, validation loss: 0.0269
2024-05-25 04:22:45 [INFO]: Epoch 082 - training loss: 0.1968, validation loss: 0.0267
2024-05-25 04:22:45 [INFO]: Epoch 083 - training loss: 0.2014, validation loss: 0.0252
2024-05-25 04:22:45 [INFO]: Epoch 084 - training loss: 0.1987, validation loss: 0.0252
2024-05-25 04:22:46 [INFO]: Epoch 085 - training loss: 0.2001, validation loss: 0.0284
2024-05-25 04:22:46 [INFO]: Epoch 086 - training loss: 0.2056, validation loss: 0.0317
2024-05-25 04:22:46 [INFO]: Epoch 087 - training loss: 0.2061, validation loss: 0.0253
2024-05-25 04:22:46 [INFO]: Epoch 088 - training loss: 0.2039, validation loss: 0.0249
2024-05-25 04:22:46 [INFO]: Epoch 089 - training loss: 0.1939, validation loss: 0.0264
2024-05-25 04:22:46 [INFO]: Epoch 090 - training loss: 0.1959, validation loss: 0.0280
2024-05-25 04:22:47 [INFO]: Epoch 091 - training loss: 0.2012, validation loss: 0.0260
2024-05-25 04:22:47 [INFO]: Epoch 092 - training loss: 0.1966, validation loss: 0.0239
2024-05-25 04:22:47 [INFO]: Epoch 093 - training loss: 0.1926, validation loss: 0.0258
2024-05-25 04:22:47 [INFO]: Epoch 094 - training loss: 0.2026, validation loss: 0.0266
2024-05-25 04:22:47 [INFO]: Epoch 095 - training loss: 0.2003, validation loss: 0.0257
2024-05-25 04:22:48 [INFO]: Epoch 096 - training loss: 0.1956, validation loss: 0.0258
2024-05-25 04:22:48 [INFO]: Epoch 097 - training loss: 0.1941, validation loss: 0.0261
2024-05-25 04:22:48 [INFO]: Epoch 098 - training loss: 0.1926, validation loss: 0.0238
2024-05-25 04:22:48 [INFO]: Epoch 099 - training loss: 0.1881, validation loss: 0.0254
2024-05-25 04:22:48 [INFO]: Epoch 100 - training loss: 0.1913, validation loss: 0.0243
2024-05-25 04:22:49 [INFO]: Epoch 101 - training loss: 0.1890, validation loss: 0.0240
2024-05-25 04:22:49 [INFO]: Epoch 102 - training loss: 0.1878, validation loss: 0.0244
2024-05-25 04:22:49 [INFO]: Epoch 103 - training loss: 0.1942, validation loss: 0.0240
2024-05-25 04:22:49 [INFO]: Epoch 104 - training loss: 0.1947, validation loss: 0.0263
2024-05-25 04:22:49 [INFO]: Epoch 105 - training loss: 0.1896, validation loss: 0.0246
2024-05-25 04:22:50 [INFO]: Epoch 106 - training loss: 0.1879, validation loss: 0.0235
2024-05-25 04:22:50 [INFO]: Epoch 107 - training loss: 0.1857, validation loss: 0.0240
2024-05-25 04:22:50 [INFO]: Epoch 108 - training loss: 0.1845, validation loss: 0.0268
2024-05-25 04:22:50 [INFO]: Epoch 109 - training loss: 0.1891, validation loss: 0.0237
2024-05-25 04:22:51 [INFO]: Epoch 110 - training loss: 0.1813, validation loss: 0.0257
2024-05-25 04:22:51 [INFO]: Epoch 111 - training loss: 0.1895, validation loss: 0.0246
2024-05-25 04:22:51 [INFO]: Epoch 112 - training loss: 0.1927, validation loss: 0.0244
2024-05-25 04:22:51 [INFO]: Epoch 113 - training loss: 0.1861, validation loss: 0.0268
2024-05-25 04:22:51 [INFO]: Epoch 114 - training loss: 0.1941, validation loss: 0.0233
2024-05-25 04:22:52 [INFO]: Epoch 115 - training loss: 0.1787, validation loss: 0.0236
2024-05-25 04:22:52 [INFO]: Epoch 116 - training loss: 0.1821, validation loss: 0.0239
2024-05-25 04:22:52 [INFO]: Epoch 117 - training loss: 0.1789, validation loss: 0.0252
2024-05-25 04:22:52 [INFO]: Epoch 118 - training loss: 0.1824, validation loss: 0.0230
2024-05-25 04:22:52 [INFO]: Epoch 119 - training loss: 0.1850, validation loss: 0.0270
2024-05-25 04:22:53 [INFO]: Epoch 120 - training loss: 0.1855, validation loss: 0.0234
2024-05-25 04:22:53 [INFO]: Epoch 121 - training loss: 0.1801, validation loss: 0.0229
2024-05-25 04:22:53 [INFO]: Epoch 122 - training loss: 0.1802, validation loss: 0.0269
2024-05-25 04:22:53 [INFO]: Epoch 123 - training loss: 0.1959, validation loss: 0.0251
2024-05-25 04:22:53 [INFO]: Epoch 124 - training loss: 0.2013, validation loss: 0.0236
2024-05-25 04:22:54 [INFO]: Epoch 125 - training loss: 0.1879, validation loss: 0.0221
2024-05-25 04:22:54 [INFO]: Epoch 126 - training loss: 0.1801, validation loss: 0.0234
2024-05-25 04:22:54 [INFO]: Epoch 127 - training loss: 0.1802, validation loss: 0.0256
2024-05-25 04:22:54 [INFO]: Epoch 128 - training loss: 0.1838, validation loss: 0.0268
2024-05-25 04:22:54 [INFO]: Epoch 129 - training loss: 0.1829, validation loss: 0.0228
2024-05-25 04:22:55 [INFO]: Epoch 130 - training loss: 0.1816, validation loss: 0.0257
2024-05-25 04:22:55 [INFO]: Epoch 131 - training loss: 0.1826, validation loss: 0.0230
2024-05-25 04:22:55 [INFO]: Epoch 132 - training loss: 0.1744, validation loss: 0.0214
2024-05-25 04:22:55 [INFO]: Epoch 133 - training loss: 0.1699, validation loss: 0.0240
2024-05-25 04:22:55 [INFO]: Epoch 134 - training loss: 0.1853, validation loss: 0.0228
2024-05-25 04:22:56 [INFO]: Epoch 135 - training loss: 0.1861, validation loss: 0.0237
2024-05-25 04:22:56 [INFO]: Epoch 136 - training loss: 0.1761, validation loss: 0.0236
2024-05-25 04:22:56 [INFO]: Epoch 137 - training loss: 0.1731, validation loss: 0.0229
2024-05-25 04:22:56 [INFO]: Epoch 138 - training loss: 0.1751, validation loss: 0.0243
2024-05-25 04:22:56 [INFO]: Epoch 139 - training loss: 0.1729, validation loss: 0.0218
2024-05-25 04:22:57 [INFO]: Epoch 140 - training loss: 0.1728, validation loss: 0.0249
2024-05-25 04:22:57 [INFO]: Epoch 141 - training loss: 0.1770, validation loss: 0.0240
2024-05-25 04:22:57 [INFO]: Epoch 142 - training loss: 0.1811, validation loss: 0.0248
2024-05-25 04:22:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:22:57 [INFO]: Finished training. The best model is from epoch#132.
2024-05-25 04:22:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_ettm1/20240525_T042229/Transformer.pypots
2024-05-25 04:22:57 [INFO]: Transformer on ETTm1: MAE=0.1302, MSE=0.0373
2024-05-25 04:22:57 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-25 04:22:57 [INFO]: Using the given device: cuda:0
2024-05-25 04:22:57 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T042257
2024-05-25 04:22:57 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T042257/tensorboard
2024-05-25 04:22:57 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 04:22:57 [INFO]: Epoch 001 - training loss: 0.1658, validation loss: 0.0718
2024-05-25 04:22:58 [INFO]: Epoch 002 - training loss: 0.0748, validation loss: 0.0477
2024-05-25 04:22:58 [INFO]: Epoch 003 - training loss: 0.0529, validation loss: 0.0383
2024-05-25 04:22:58 [INFO]: Epoch 004 - training loss: 0.0468, validation loss: 0.0337
2024-05-25 04:22:58 [INFO]: Epoch 005 - training loss: 0.0395, validation loss: 0.0304
2024-05-25 04:22:58 [INFO]: Epoch 006 - training loss: 0.0331, validation loss: 0.0270
2024-05-25 04:22:59 [INFO]: Epoch 007 - training loss: 0.0360, validation loss: 0.0322
2024-05-25 04:22:59 [INFO]: Epoch 008 - training loss: 0.0469, validation loss: 0.0285
2024-05-25 04:22:59 [INFO]: Epoch 009 - training loss: 0.0329, validation loss: 0.0262
2024-05-25 04:22:59 [INFO]: Epoch 010 - training loss: 0.0304, validation loss: 0.0258
2024-05-25 04:22:59 [INFO]: Epoch 011 - training loss: 0.0289, validation loss: 0.0233
2024-05-25 04:22:59 [INFO]: Epoch 012 - training loss: 0.0267, validation loss: 0.0231
2024-05-25 04:23:00 [INFO]: Epoch 013 - training loss: 0.0262, validation loss: 0.0236
2024-05-25 04:23:00 [INFO]: Epoch 014 - training loss: 0.0251, validation loss: 0.0221
2024-05-25 04:23:00 [INFO]: Epoch 015 - training loss: 0.0251, validation loss: 0.0234
2024-05-25 04:23:00 [INFO]: Epoch 016 - training loss: 0.0287, validation loss: 0.0224
2024-05-25 04:23:00 [INFO]: Epoch 017 - training loss: 0.0248, validation loss: 0.0233
2024-05-25 04:23:01 [INFO]: Epoch 018 - training loss: 0.0264, validation loss: 0.0252
2024-05-25 04:23:01 [INFO]: Epoch 019 - training loss: 0.0292, validation loss: 0.0237
2024-05-25 04:23:01 [INFO]: Epoch 020 - training loss: 0.0242, validation loss: 0.0236
2024-05-25 04:23:01 [INFO]: Epoch 021 - training loss: 0.0230, validation loss: 0.0226
2024-05-25 04:23:01 [INFO]: Epoch 022 - training loss: 0.0236, validation loss: 0.0235
2024-05-25 04:23:02 [INFO]: Epoch 023 - training loss: 0.0243, validation loss: 0.0230
2024-05-25 04:23:02 [INFO]: Epoch 024 - training loss: 0.0225, validation loss: 0.0231
2024-05-25 04:23:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:23:02 [INFO]: Finished training. The best model is from epoch#14.
2024-05-25 04:23:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240525_T042257/TimesNet.pypots
2024-05-25 04:23:02 [INFO]: TimesNet on ETTm1: MAE=0.1032, MSE=0.0234
2024-05-25 04:23:02 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-25 04:23:02 [INFO]: Using the given device: cuda:0
2024-05-25 04:23:02 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302
2024-05-25 04:23:02 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/tensorboard
2024-05-25 04:23:02 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 04:23:04 [INFO]: Epoch 001 - training loss: 0.6764, validation loss: 0.4240
2024-05-25 04:23:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch1_loss0.42397817969322205.pypots
2024-05-25 04:23:06 [INFO]: Epoch 002 - training loss: 0.4164, validation loss: 0.3788
2024-05-25 04:23:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch2_loss0.3787869065999985.pypots
2024-05-25 04:23:08 [INFO]: Epoch 003 - training loss: 0.3342, validation loss: 0.3413
2024-05-25 04:23:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch3_loss0.3412555754184723.pypots
2024-05-25 04:23:10 [INFO]: Epoch 004 - training loss: 0.3177, validation loss: 0.2929
2024-05-25 04:23:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch4_loss0.29292111098766327.pypots
2024-05-25 04:23:12 [INFO]: Epoch 005 - training loss: 0.3549, validation loss: 0.2919
2024-05-25 04:23:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch5_loss0.2919302433729172.pypots
2024-05-25 04:23:14 [INFO]: Epoch 006 - training loss: 0.3160, validation loss: 0.2728
2024-05-25 04:23:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch6_loss0.27275488525629044.pypots
2024-05-25 04:23:16 [INFO]: Epoch 007 - training loss: 0.2640, validation loss: 0.2659
2024-05-25 04:23:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch7_loss0.2658515051007271.pypots
2024-05-25 04:23:18 [INFO]: Epoch 008 - training loss: 0.2744, validation loss: 0.2687
2024-05-25 04:23:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch8_loss0.26874838024377823.pypots
2024-05-25 04:23:20 [INFO]: Epoch 009 - training loss: 0.2454, validation loss: 0.2529
2024-05-25 04:23:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch9_loss0.2529246136546135.pypots
2024-05-25 04:23:22 [INFO]: Epoch 010 - training loss: 0.3167, validation loss: 0.2567
2024-05-25 04:23:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch10_loss0.25673840939998627.pypots
2024-05-25 04:23:24 [INFO]: Epoch 011 - training loss: 0.2349, validation loss: 0.2513
2024-05-25 04:23:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch11_loss0.25125276669859886.pypots
2024-05-25 04:23:27 [INFO]: Epoch 012 - training loss: 0.2595, validation loss: 0.2446
2024-05-25 04:23:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch12_loss0.2445673979818821.pypots
2024-05-25 04:23:29 [INFO]: Epoch 013 - training loss: 0.2613, validation loss: 0.2493
2024-05-25 04:23:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch13_loss0.24930226802825928.pypots
2024-05-25 04:23:31 [INFO]: Epoch 014 - training loss: 0.2358, validation loss: 0.2304
2024-05-25 04:23:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch14_loss0.23038558661937714.pypots
2024-05-25 04:23:33 [INFO]: Epoch 015 - training loss: 0.2075, validation loss: 0.2254
2024-05-25 04:23:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch15_loss0.22538122907280922.pypots
2024-05-25 04:23:35 [INFO]: Epoch 016 - training loss: 0.2690, validation loss: 0.2350
2024-05-25 04:23:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch16_loss0.23496238514780998.pypots
2024-05-25 04:23:37 [INFO]: Epoch 017 - training loss: 0.2279, validation loss: 0.2249
2024-05-25 04:23:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch17_loss0.22493521124124527.pypots
2024-05-25 04:23:39 [INFO]: Epoch 018 - training loss: 0.2266, validation loss: 0.2148
2024-05-25 04:23:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch18_loss0.214828722178936.pypots
2024-05-25 04:23:41 [INFO]: Epoch 019 - training loss: 0.2094, validation loss: 0.2100
2024-05-25 04:23:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch19_loss0.2099999152123928.pypots
2024-05-25 04:23:43 [INFO]: Epoch 020 - training loss: 0.2242, validation loss: 0.2258
2024-05-25 04:23:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch20_loss0.22580380737781525.pypots
2024-05-25 04:23:45 [INFO]: Epoch 021 - training loss: 0.1870, validation loss: 0.2144
2024-05-25 04:23:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch21_loss0.21438190713524818.pypots
2024-05-25 04:23:47 [INFO]: Epoch 022 - training loss: 0.2253, validation loss: 0.2070
2024-05-25 04:23:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch22_loss0.20703305676579475.pypots
2024-05-25 04:23:49 [INFO]: Epoch 023 - training loss: 0.2058, validation loss: 0.2073
2024-05-25 04:23:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch23_loss0.20726760104298592.pypots
2024-05-25 04:23:51 [INFO]: Epoch 024 - training loss: 0.2125, validation loss: 0.1937
2024-05-25 04:23:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch24_loss0.19370181113481522.pypots
2024-05-25 04:23:53 [INFO]: Epoch 025 - training loss: 0.2129, validation loss: 0.1964
2024-05-25 04:23:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch25_loss0.19636661186814308.pypots
2024-05-25 04:23:55 [INFO]: Epoch 026 - training loss: 0.2163, validation loss: 0.2050
2024-05-25 04:23:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch26_loss0.20497379451990128.pypots
2024-05-25 04:23:57 [INFO]: Epoch 027 - training loss: 0.2014, validation loss: 0.1889
2024-05-25 04:23:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch27_loss0.18893225118517876.pypots
2024-05-25 04:23:59 [INFO]: Epoch 028 - training loss: 0.1904, validation loss: 0.1853
2024-05-25 04:23:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch28_loss0.18530533090233803.pypots
2024-05-25 04:24:01 [INFO]: Epoch 029 - training loss: 0.1852, validation loss: 0.1878
2024-05-25 04:24:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch29_loss0.1878257878124714.pypots
2024-05-25 04:24:04 [INFO]: Epoch 030 - training loss: 0.1895, validation loss: 0.1738
2024-05-25 04:24:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch30_loss0.17382434383034706.pypots
2024-05-25 04:24:06 [INFO]: Epoch 031 - training loss: 0.1690, validation loss: 0.1771
2024-05-25 04:24:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch31_loss0.1771065630018711.pypots
2024-05-25 04:24:08 [INFO]: Epoch 032 - training loss: 0.1748, validation loss: 0.1953
2024-05-25 04:24:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch32_loss0.19528555497527122.pypots
2024-05-25 04:24:10 [INFO]: Epoch 033 - training loss: 0.1582, validation loss: 0.1695
2024-05-25 04:24:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch33_loss0.1695334017276764.pypots
2024-05-25 04:24:12 [INFO]: Epoch 034 - training loss: 0.1990, validation loss: 0.1713
2024-05-25 04:24:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch34_loss0.17125994339585304.pypots
2024-05-25 04:24:14 [INFO]: Epoch 035 - training loss: 0.1935, validation loss: 0.1711
2024-05-25 04:24:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch35_loss0.17111937329173088.pypots
2024-05-25 04:24:16 [INFO]: Epoch 036 - training loss: 0.1739, validation loss: 0.1634
2024-05-25 04:24:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch36_loss0.16339702159166336.pypots
2024-05-25 04:24:18 [INFO]: Epoch 037 - training loss: 0.2015, validation loss: 0.1871
2024-05-25 04:24:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch37_loss0.18708839267492294.pypots
2024-05-25 04:24:20 [INFO]: Epoch 038 - training loss: 0.2028, validation loss: 0.1938
2024-05-25 04:24:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch38_loss0.1937875859439373.pypots
2024-05-25 04:24:22 [INFO]: Epoch 039 - training loss: 0.1738, validation loss: 0.1712
2024-05-25 04:24:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch39_loss0.17121485993266106.pypots
2024-05-25 04:24:24 [INFO]: Epoch 040 - training loss: 0.1870, validation loss: 0.1821
2024-05-25 04:24:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch40_loss0.18205909430980682.pypots
2024-05-25 04:24:26 [INFO]: Epoch 041 - training loss: 0.1890, validation loss: 0.1716
2024-05-25 04:24:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch41_loss0.17159052938222885.pypots
2024-05-25 04:24:28 [INFO]: Epoch 042 - training loss: 0.1684, validation loss: 0.1623
2024-05-25 04:24:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch42_loss0.16234401240944862.pypots
2024-05-25 04:24:30 [INFO]: Epoch 043 - training loss: 0.1603, validation loss: 0.1549
2024-05-25 04:24:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch43_loss0.15487074479460716.pypots
2024-05-25 04:24:32 [INFO]: Epoch 044 - training loss: 0.1861, validation loss: 0.1577
2024-05-25 04:24:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch44_loss0.15774733945727348.pypots
2024-05-25 04:24:34 [INFO]: Epoch 045 - training loss: 0.1860, validation loss: 0.1712
2024-05-25 04:24:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch45_loss0.17117683961987495.pypots
2024-05-25 04:24:36 [INFO]: Epoch 046 - training loss: 0.1676, validation loss: 0.1577
2024-05-25 04:24:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch46_loss0.1576920934021473.pypots
2024-05-25 04:24:38 [INFO]: Epoch 047 - training loss: 0.1540, validation loss: 0.1505
2024-05-25 04:24:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch47_loss0.15051280334591866.pypots
2024-05-25 04:24:40 [INFO]: Epoch 048 - training loss: 0.1681, validation loss: 0.1567
2024-05-25 04:24:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch48_loss0.1567382961511612.pypots
2024-05-25 04:24:43 [INFO]: Epoch 049 - training loss: 0.2354, validation loss: 0.1725
2024-05-25 04:24:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch49_loss0.1724575236439705.pypots
2024-05-25 04:24:45 [INFO]: Epoch 050 - training loss: 0.1554, validation loss: 0.1609
2024-05-25 04:24:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch50_loss0.16091546043753624.pypots
2024-05-25 04:24:47 [INFO]: Epoch 051 - training loss: 0.1552, validation loss: 0.1487
2024-05-25 04:24:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch51_loss0.14874117448925972.pypots
2024-05-25 04:24:49 [INFO]: Epoch 052 - training loss: 0.1294, validation loss: 0.1486
2024-05-25 04:24:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch52_loss0.14861254766583443.pypots
2024-05-25 04:24:51 [INFO]: Epoch 053 - training loss: 0.1655, validation loss: 0.1503
2024-05-25 04:24:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch53_loss0.150273896753788.pypots
2024-05-25 04:24:53 [INFO]: Epoch 054 - training loss: 0.1593, validation loss: 0.1557
2024-05-25 04:24:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch54_loss0.1556997261941433.pypots
2024-05-25 04:24:55 [INFO]: Epoch 055 - training loss: 0.1487, validation loss: 0.1515
2024-05-25 04:24:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch55_loss0.15154468268156052.pypots
2024-05-25 04:24:57 [INFO]: Epoch 056 - training loss: 0.1540, validation loss: 0.1448
2024-05-25 04:24:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch56_loss0.1447756551206112.pypots
2024-05-25 04:24:59 [INFO]: Epoch 057 - training loss: 0.1469, validation loss: 0.1447
2024-05-25 04:24:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch57_loss0.14466645196080208.pypots
2024-05-25 04:25:01 [INFO]: Epoch 058 - training loss: 0.1661, validation loss: 0.1427
2024-05-25 04:25:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch58_loss0.1427212432026863.pypots
2024-05-25 04:25:03 [INFO]: Epoch 059 - training loss: 0.1521, validation loss: 0.1425
2024-05-25 04:25:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch59_loss0.14249395579099655.pypots
2024-05-25 04:25:05 [INFO]: Epoch 060 - training loss: 0.1336, validation loss: 0.1392
2024-05-25 04:25:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch60_loss0.13915550708770752.pypots
2024-05-25 04:25:07 [INFO]: Epoch 061 - training loss: 0.1529, validation loss: 0.1449
2024-05-25 04:25:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch61_loss0.1449424810707569.pypots
2024-05-25 04:25:09 [INFO]: Epoch 062 - training loss: 0.1508, validation loss: 0.1385
2024-05-25 04:25:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch62_loss0.13845182210206985.pypots
2024-05-25 04:25:11 [INFO]: Epoch 063 - training loss: 0.2265, validation loss: 0.1463
2024-05-25 04:25:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch63_loss0.1462569758296013.pypots
2024-05-25 04:25:13 [INFO]: Epoch 064 - training loss: 0.1697, validation loss: 0.1563
2024-05-25 04:25:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch64_loss0.15631229802966118.pypots
2024-05-25 04:25:15 [INFO]: Epoch 065 - training loss: 0.1514, validation loss: 0.1428
2024-05-25 04:25:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch65_loss0.14281096309423447.pypots
2024-05-25 04:25:17 [INFO]: Epoch 066 - training loss: 0.1348, validation loss: 0.1400
2024-05-25 04:25:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch66_loss0.14003341645002365.pypots
2024-05-25 04:25:20 [INFO]: Epoch 067 - training loss: 0.1313, validation loss: 0.1419
2024-05-25 04:25:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch67_loss0.14193911850452423.pypots
2024-05-25 04:25:22 [INFO]: Epoch 068 - training loss: 0.1566, validation loss: 0.1420
2024-05-25 04:25:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch68_loss0.1419750452041626.pypots
2024-05-25 04:25:24 [INFO]: Epoch 069 - training loss: 0.1327, validation loss: 0.1389
2024-05-25 04:25:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch69_loss0.13888876885175705.pypots
2024-05-25 04:25:26 [INFO]: Epoch 070 - training loss: 0.1624, validation loss: 0.1440
2024-05-25 04:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch70_loss0.1439743973314762.pypots
2024-05-25 04:25:28 [INFO]: Epoch 071 - training loss: 0.1740, validation loss: 0.1527
2024-05-25 04:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch71_loss0.15265784040093422.pypots
2024-05-25 04:25:30 [INFO]: Epoch 072 - training loss: 0.1480, validation loss: 0.1477
2024-05-25 04:25:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI_epoch72_loss0.14766455441713333.pypots
2024-05-25 04:25:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:25:30 [INFO]: Finished training. The best model is from epoch#62.
2024-05-25 04:25:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240525_T042302/CSDI.pypots
2024-05-25 04:25:46 [INFO]: CSDI on ETTm1: MAE=0.1589, MSE=0.0662
2024-05-25 04:25:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-25 04:25:46 [INFO]: Using the given device: cuda:0
2024-05-25 04:25:46 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T042546
2024-05-25 04:25:46 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T042546/tensorboard
2024-05-25 04:25:46 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:25:46 [INFO]: Epoch 001 - training loss: 24601.2567, validation loss: 0.9795
2024-05-25 04:25:46 [INFO]: Epoch 002 - training loss: 22426.2567, validation loss: 0.9778
2024-05-25 04:25:46 [INFO]: Epoch 003 - training loss: 20493.5752, validation loss: 0.9742
2024-05-25 04:25:46 [INFO]: Epoch 004 - training loss: 18587.9733, validation loss: 0.9591
2024-05-25 04:25:46 [INFO]: Epoch 005 - training loss: 16734.9354, validation loss: 0.9361
2024-05-25 04:25:46 [INFO]: Epoch 006 - training loss: 15091.3511, validation loss: 0.8795
2024-05-25 04:25:47 [INFO]: Epoch 007 - training loss: 13733.9027, validation loss: 0.7803
2024-05-25 04:25:47 [INFO]: Epoch 008 - training loss: 12666.3592, validation loss: 0.7009
2024-05-25 04:25:47 [INFO]: Epoch 009 - training loss: 11892.1528, validation loss: 0.6214
2024-05-25 04:25:47 [INFO]: Epoch 010 - training loss: 11463.8019, validation loss: 0.5512
2024-05-25 04:25:47 [INFO]: Epoch 011 - training loss: 11048.6323, validation loss: 0.5120
2024-05-25 04:25:47 [INFO]: Epoch 012 - training loss: 10688.8076, validation loss: 0.4970
2024-05-25 04:25:48 [INFO]: Epoch 013 - training loss: 10562.8177, validation loss: 0.4833
2024-05-25 04:25:48 [INFO]: Epoch 014 - training loss: 10329.0359, validation loss: 0.4686
2024-05-25 04:25:48 [INFO]: Epoch 015 - training loss: 10186.2039, validation loss: 0.4531
2024-05-25 04:25:48 [INFO]: Epoch 016 - training loss: 10122.8564, validation loss: 0.4366
2024-05-25 04:25:48 [INFO]: Epoch 017 - training loss: 10066.0380, validation loss: 0.4211
2024-05-25 04:25:48 [INFO]: Epoch 018 - training loss: 9904.7975, validation loss: 0.3995
2024-05-25 04:25:48 [INFO]: Epoch 019 - training loss: 9847.5324, validation loss: 0.3746
2024-05-25 04:25:49 [INFO]: Epoch 020 - training loss: 9804.5787, validation loss: 0.3524
2024-05-25 04:25:49 [INFO]: Epoch 021 - training loss: 9763.8201, validation loss: 0.3309
2024-05-25 04:25:49 [INFO]: Epoch 022 - training loss: 9707.0760, validation loss: 0.3152
2024-05-25 04:25:49 [INFO]: Epoch 023 - training loss: 9698.9527, validation loss: 0.2979
2024-05-25 04:25:49 [INFO]: Epoch 024 - training loss: 9670.3608, validation loss: 0.2871
2024-05-25 04:25:49 [INFO]: Epoch 025 - training loss: 9629.0488, validation loss: 0.2760
2024-05-25 04:25:49 [INFO]: Epoch 026 - training loss: 9596.3914, validation loss: 0.2641
2024-05-25 04:25:50 [INFO]: Epoch 027 - training loss: 9585.9580, validation loss: 0.2526
2024-05-25 04:25:50 [INFO]: Epoch 028 - training loss: 9561.6078, validation loss: 0.2393
2024-05-25 04:25:50 [INFO]: Epoch 029 - training loss: 9546.9490, validation loss: 0.2288
2024-05-25 04:25:50 [INFO]: Epoch 030 - training loss: 9536.8229, validation loss: 0.2184
2024-05-25 04:25:50 [INFO]: Epoch 031 - training loss: 9518.5432, validation loss: 0.2107
2024-05-25 04:25:50 [INFO]: Epoch 032 - training loss: 9500.6431, validation loss: 0.2035
2024-05-25 04:25:50 [INFO]: Epoch 033 - training loss: 9488.7120, validation loss: 0.1992
2024-05-25 04:25:51 [INFO]: Epoch 034 - training loss: 9478.1112, validation loss: 0.1882
2024-05-25 04:25:51 [INFO]: Epoch 035 - training loss: 9473.0595, validation loss: 0.1840
2024-05-25 04:25:51 [INFO]: Epoch 036 - training loss: 9465.8058, validation loss: 0.1775
2024-05-25 04:25:51 [INFO]: Epoch 037 - training loss: 9499.0279, validation loss: 0.1716
2024-05-25 04:25:51 [INFO]: Epoch 038 - training loss: 9450.9003, validation loss: 0.1699
2024-05-25 04:25:51 [INFO]: Epoch 039 - training loss: 9439.6988, validation loss: 0.1670
2024-05-25 04:25:51 [INFO]: Epoch 040 - training loss: 9435.4829, validation loss: 0.1646
2024-05-25 04:25:52 [INFO]: Epoch 041 - training loss: 9428.1542, validation loss: 0.1590
2024-05-25 04:25:52 [INFO]: Epoch 042 - training loss: 9451.3935, validation loss: 0.1584
2024-05-25 04:25:52 [INFO]: Epoch 043 - training loss: 9416.4609, validation loss: 0.1551
2024-05-25 04:25:52 [INFO]: Epoch 044 - training loss: 9416.5642, validation loss: 0.1533
2024-05-25 04:25:52 [INFO]: Epoch 045 - training loss: 9420.1614, validation loss: 0.1474
2024-05-25 04:25:52 [INFO]: Epoch 046 - training loss: 9417.5206, validation loss: 0.1436
2024-05-25 04:25:52 [INFO]: Epoch 047 - training loss: 9400.3621, validation loss: 0.1438
2024-05-25 04:25:53 [INFO]: Epoch 048 - training loss: 9398.5170, validation loss: 0.1387
2024-05-25 04:25:53 [INFO]: Epoch 049 - training loss: 9413.1448, validation loss: 0.1384
2024-05-25 04:25:53 [INFO]: Epoch 050 - training loss: 9386.3749, validation loss: 0.1379
2024-05-25 04:25:53 [INFO]: Epoch 051 - training loss: 9384.8766, validation loss: 0.1327
2024-05-25 04:25:53 [INFO]: Epoch 052 - training loss: 9385.8463, validation loss: 0.1350
2024-05-25 04:25:53 [INFO]: Epoch 053 - training loss: 9382.5660, validation loss: 0.1319
2024-05-25 04:25:53 [INFO]: Epoch 054 - training loss: 9378.3013, validation loss: 0.1314
2024-05-25 04:25:54 [INFO]: Epoch 055 - training loss: 9373.5959, validation loss: 0.1299
2024-05-25 04:25:54 [INFO]: Epoch 056 - training loss: 9372.6368, validation loss: 0.1277
2024-05-25 04:25:54 [INFO]: Epoch 057 - training loss: 9366.9454, validation loss: 0.1283
2024-05-25 04:25:54 [INFO]: Epoch 058 - training loss: 9367.6361, validation loss: 0.1267
2024-05-25 04:25:54 [INFO]: Epoch 059 - training loss: 9397.5570, validation loss: 0.1251
2024-05-25 04:25:54 [INFO]: Epoch 060 - training loss: 9363.6346, validation loss: 0.1229
2024-05-25 04:25:54 [INFO]: Epoch 061 - training loss: 9361.3804, validation loss: 0.1237
2024-05-25 04:25:55 [INFO]: Epoch 062 - training loss: 9359.6190, validation loss: 0.1223
2024-05-25 04:25:55 [INFO]: Epoch 063 - training loss: 9355.8928, validation loss: 0.1200
2024-05-25 04:25:55 [INFO]: Epoch 064 - training loss: 9354.9487, validation loss: 0.1201
2024-05-25 04:25:55 [INFO]: Epoch 065 - training loss: 9353.6222, validation loss: 0.1198
2024-05-25 04:25:55 [INFO]: Epoch 066 - training loss: 9351.2131, validation loss: 0.1193
2024-05-25 04:25:55 [INFO]: Epoch 067 - training loss: 9350.0211, validation loss: 0.1190
2024-05-25 04:25:55 [INFO]: Epoch 068 - training loss: 9351.5745, validation loss: 0.1180
2024-05-25 04:25:56 [INFO]: Epoch 069 - training loss: 9349.0833, validation loss: 0.1174
2024-05-25 04:25:56 [INFO]: Epoch 070 - training loss: 9349.0899, validation loss: 0.1164
2024-05-25 04:25:56 [INFO]: Epoch 071 - training loss: 9347.7625, validation loss: 0.1155
2024-05-25 04:25:56 [INFO]: Epoch 072 - training loss: 9344.8910, validation loss: 0.1148
2024-05-25 04:25:56 [INFO]: Epoch 073 - training loss: 9343.1944, validation loss: 0.1148
2024-05-25 04:25:56 [INFO]: Epoch 074 - training loss: 9341.2587, validation loss: 0.1133
2024-05-25 04:25:56 [INFO]: Epoch 075 - training loss: 9343.8978, validation loss: 0.1124
2024-05-25 04:25:57 [INFO]: Epoch 076 - training loss: 9345.3572, validation loss: 0.1127
2024-05-25 04:25:57 [INFO]: Epoch 077 - training loss: 9347.4753, validation loss: 0.1115
2024-05-25 04:25:57 [INFO]: Epoch 078 - training loss: 9339.6339, validation loss: 0.1104
2024-05-25 04:25:57 [INFO]: Epoch 079 - training loss: 9340.8346, validation loss: 0.1126
2024-05-25 04:25:57 [INFO]: Epoch 080 - training loss: 9337.7717, validation loss: 0.1107
2024-05-25 04:25:57 [INFO]: Epoch 081 - training loss: 9336.8477, validation loss: 0.1102
2024-05-25 04:25:57 [INFO]: Epoch 082 - training loss: 9335.3611, validation loss: 0.1088
2024-05-25 04:25:58 [INFO]: Epoch 083 - training loss: 9338.8181, validation loss: 0.1081
2024-05-25 04:25:58 [INFO]: Epoch 084 - training loss: 9334.3680, validation loss: 0.1091
2024-05-25 04:25:58 [INFO]: Epoch 085 - training loss: 9333.4358, validation loss: 0.1069
2024-05-25 04:25:58 [INFO]: Epoch 086 - training loss: 9333.7938, validation loss: 0.1064
2024-05-25 04:25:58 [INFO]: Epoch 087 - training loss: 9332.1270, validation loss: 0.1064
2024-05-25 04:25:58 [INFO]: Epoch 088 - training loss: 9331.3695, validation loss: 0.1050
2024-05-25 04:25:58 [INFO]: Epoch 089 - training loss: 9330.1617, validation loss: 0.1052
2024-05-25 04:25:59 [INFO]: Epoch 090 - training loss: 9330.0346, validation loss: 0.1047
2024-05-25 04:25:59 [INFO]: Epoch 091 - training loss: 9328.9263, validation loss: 0.1040
2024-05-25 04:25:59 [INFO]: Epoch 092 - training loss: 9329.3135, validation loss: 0.1055
2024-05-25 04:25:59 [INFO]: Epoch 093 - training loss: 9326.9488, validation loss: 0.1033
2024-05-25 04:25:59 [INFO]: Epoch 094 - training loss: 9328.1196, validation loss: 0.1041
2024-05-25 04:25:59 [INFO]: Epoch 095 - training loss: 9334.9331, validation loss: 0.1031
2024-05-25 04:25:59 [INFO]: Epoch 096 - training loss: 9327.0977, validation loss: 0.1019
2024-05-25 04:26:00 [INFO]: Epoch 097 - training loss: 9327.3729, validation loss: 0.0994
2024-05-25 04:26:00 [INFO]: Epoch 098 - training loss: 9325.1254, validation loss: 0.1007
2024-05-25 04:26:00 [INFO]: Epoch 099 - training loss: 9325.0129, validation loss: 0.1004
2024-05-25 04:26:00 [INFO]: Epoch 100 - training loss: 9324.5306, validation loss: 0.1011
2024-05-25 04:26:00 [INFO]: Epoch 101 - training loss: 9326.2413, validation loss: 0.0998
2024-05-25 04:26:00 [INFO]: Epoch 102 - training loss: 9324.2022, validation loss: 0.0994
2024-05-25 04:26:00 [INFO]: Epoch 103 - training loss: 9327.2458, validation loss: 0.0993
2024-05-25 04:26:01 [INFO]: Epoch 104 - training loss: 9322.2898, validation loss: 0.0994
2024-05-25 04:26:01 [INFO]: Epoch 105 - training loss: 9323.8615, validation loss: 0.0985
2024-05-25 04:26:01 [INFO]: Epoch 106 - training loss: 9322.3480, validation loss: 0.0970
2024-05-25 04:26:01 [INFO]: Epoch 107 - training loss: 9322.9574, validation loss: 0.0956
2024-05-25 04:26:01 [INFO]: Epoch 108 - training loss: 9322.0494, validation loss: 0.0960
2024-05-25 04:26:01 [INFO]: Epoch 109 - training loss: 9321.4265, validation loss: 0.0958
2024-05-25 04:26:01 [INFO]: Epoch 110 - training loss: 9321.0748, validation loss: 0.0950
2024-05-25 04:26:02 [INFO]: Epoch 111 - training loss: 9321.4306, validation loss: 0.0953
2024-05-25 04:26:02 [INFO]: Epoch 112 - training loss: 9321.2461, validation loss: 0.0945
2024-05-25 04:26:02 [INFO]: Epoch 113 - training loss: 9319.4332, validation loss: 0.0950
2024-05-25 04:26:02 [INFO]: Epoch 114 - training loss: 9319.1024, validation loss: 0.0934
2024-05-25 04:26:02 [INFO]: Epoch 115 - training loss: 9318.0645, validation loss: 0.0922
2024-05-25 04:26:02 [INFO]: Epoch 116 - training loss: 9318.8026, validation loss: 0.0933
2024-05-25 04:26:02 [INFO]: Epoch 117 - training loss: 9318.9717, validation loss: 0.0931
2024-05-25 04:26:02 [INFO]: Epoch 118 - training loss: 9317.7980, validation loss: 0.0916
2024-05-25 04:26:03 [INFO]: Epoch 119 - training loss: 9316.9205, validation loss: 0.0928
2024-05-25 04:26:03 [INFO]: Epoch 120 - training loss: 9317.6014, validation loss: 0.0910
2024-05-25 04:26:03 [INFO]: Epoch 121 - training loss: 9333.0367, validation loss: 0.0904
2024-05-25 04:26:03 [INFO]: Epoch 122 - training loss: 9317.2054, validation loss: 0.0913
2024-05-25 04:26:03 [INFO]: Epoch 123 - training loss: 9316.4526, validation loss: 0.0921
2024-05-25 04:26:03 [INFO]: Epoch 124 - training loss: 9316.3015, validation loss: 0.0913
2024-05-25 04:26:03 [INFO]: Epoch 125 - training loss: 9318.0586, validation loss: 0.0888
2024-05-25 04:26:04 [INFO]: Epoch 126 - training loss: 9316.3817, validation loss: 0.0897
2024-05-25 04:26:04 [INFO]: Epoch 127 - training loss: 9317.2419, validation loss: 0.0902
2024-05-25 04:26:04 [INFO]: Epoch 128 - training loss: 9314.8590, validation loss: 0.0888
2024-05-25 04:26:04 [INFO]: Epoch 129 - training loss: 9314.8791, validation loss: 0.0896
2024-05-25 04:26:04 [INFO]: Epoch 130 - training loss: 9314.9438, validation loss: 0.0889
2024-05-25 04:26:04 [INFO]: Epoch 131 - training loss: 9316.3120, validation loss: 0.0875
2024-05-25 04:26:04 [INFO]: Epoch 132 - training loss: 9314.3804, validation loss: 0.0872
2024-05-25 04:26:05 [INFO]: Epoch 133 - training loss: 9313.6326, validation loss: 0.0872
2024-05-25 04:26:05 [INFO]: Epoch 134 - training loss: 9313.7675, validation loss: 0.0860
2024-05-25 04:26:05 [INFO]: Epoch 135 - training loss: 9312.7220, validation loss: 0.0873
2024-05-25 04:26:05 [INFO]: Epoch 136 - training loss: 9312.5956, validation loss: 0.0858
2024-05-25 04:26:05 [INFO]: Epoch 137 - training loss: 9314.8157, validation loss: 0.0865
2024-05-25 04:26:05 [INFO]: Epoch 138 - training loss: 9312.1777, validation loss: 0.0859
2024-05-25 04:26:05 [INFO]: Epoch 139 - training loss: 9312.4156, validation loss: 0.0856
2024-05-25 04:26:06 [INFO]: Epoch 140 - training loss: 9312.2942, validation loss: 0.0850
2024-05-25 04:26:06 [INFO]: Epoch 141 - training loss: 9311.1871, validation loss: 0.0859
2024-05-25 04:26:06 [INFO]: Epoch 142 - training loss: 9312.2308, validation loss: 0.0838
2024-05-25 04:26:06 [INFO]: Epoch 143 - training loss: 9313.4589, validation loss: 0.0839
2024-05-25 04:26:06 [INFO]: Epoch 144 - training loss: 9311.6119, validation loss: 0.0832
2024-05-25 04:26:06 [INFO]: Epoch 145 - training loss: 9321.1838, validation loss: 0.0835
2024-05-25 04:26:06 [INFO]: Epoch 146 - training loss: 9310.1273, validation loss: 0.0842
2024-05-25 04:26:07 [INFO]: Epoch 147 - training loss: 9311.1650, validation loss: 0.0834
2024-05-25 04:26:07 [INFO]: Epoch 148 - training loss: 9309.6363, validation loss: 0.0835
2024-05-25 04:26:07 [INFO]: Epoch 149 - training loss: 9310.3475, validation loss: 0.0844
2024-05-25 04:26:07 [INFO]: Epoch 150 - training loss: 9310.5797, validation loss: 0.0842
2024-05-25 04:26:07 [INFO]: Epoch 151 - training loss: 9310.9635, validation loss: 0.0837
2024-05-25 04:26:07 [INFO]: Epoch 152 - training loss: 9310.6354, validation loss: 0.0828
2024-05-25 04:26:07 [INFO]: Epoch 153 - training loss: 9309.9841, validation loss: 0.0828
2024-05-25 04:26:08 [INFO]: Epoch 154 - training loss: 9310.4451, validation loss: 0.0828
2024-05-25 04:26:08 [INFO]: Epoch 155 - training loss: 9311.9971, validation loss: 0.0843
2024-05-25 04:26:08 [INFO]: Epoch 156 - training loss: 9309.5800, validation loss: 0.0812
2024-05-25 04:26:08 [INFO]: Epoch 157 - training loss: 9310.1822, validation loss: 0.0813
2024-05-25 04:26:08 [INFO]: Epoch 158 - training loss: 9310.3737, validation loss: 0.0818
2024-05-25 04:26:08 [INFO]: Epoch 159 - training loss: 9312.3731, validation loss: 0.0814
2024-05-25 04:26:09 [INFO]: Epoch 160 - training loss: 9309.7958, validation loss: 0.0809
2024-05-25 04:26:09 [INFO]: Epoch 161 - training loss: 9309.4298, validation loss: 0.0808
2024-05-25 04:26:09 [INFO]: Epoch 162 - training loss: 9309.0844, validation loss: 0.0806
2024-05-25 04:26:09 [INFO]: Epoch 163 - training loss: 9308.7782, validation loss: 0.0807
2024-05-25 04:26:09 [INFO]: Epoch 164 - training loss: 9307.1341, validation loss: 0.0815
2024-05-25 04:26:09 [INFO]: Epoch 165 - training loss: 9309.1578, validation loss: 0.0800
2024-05-25 04:26:09 [INFO]: Epoch 166 - training loss: 9307.2476, validation loss: 0.0799
2024-05-25 04:26:10 [INFO]: Epoch 167 - training loss: 9308.8347, validation loss: 0.0795
2024-05-25 04:26:10 [INFO]: Epoch 168 - training loss: 9307.3951, validation loss: 0.0796
2024-05-25 04:26:10 [INFO]: Epoch 169 - training loss: 9308.8309, validation loss: 0.0788
2024-05-25 04:26:10 [INFO]: Epoch 170 - training loss: 9308.6379, validation loss: 0.0793
2024-05-25 04:26:10 [INFO]: Epoch 171 - training loss: 9307.3126, validation loss: 0.0776
2024-05-25 04:26:10 [INFO]: Epoch 172 - training loss: 9308.7724, validation loss: 0.0782
2024-05-25 04:26:10 [INFO]: Epoch 173 - training loss: 9307.6686, validation loss: 0.0797
2024-05-25 04:26:11 [INFO]: Epoch 174 - training loss: 9307.8267, validation loss: 0.0782
2024-05-25 04:26:11 [INFO]: Epoch 175 - training loss: 9306.3267, validation loss: 0.0781
2024-05-25 04:26:11 [INFO]: Epoch 176 - training loss: 9307.8227, validation loss: 0.0781
2024-05-25 04:26:11 [INFO]: Epoch 177 - training loss: 9307.8128, validation loss: 0.0800
2024-05-25 04:26:11 [INFO]: Epoch 178 - training loss: 9307.2251, validation loss: 0.0780
2024-05-25 04:26:11 [INFO]: Epoch 179 - training loss: 9307.2519, validation loss: 0.0789
2024-05-25 04:26:11 [INFO]: Epoch 180 - training loss: 9308.7312, validation loss: 0.0789
2024-05-25 04:26:12 [INFO]: Epoch 181 - training loss: 9307.4675, validation loss: 0.0774
2024-05-25 04:26:12 [INFO]: Epoch 182 - training loss: 9305.3918, validation loss: 0.0769
2024-05-25 04:26:12 [INFO]: Epoch 183 - training loss: 9307.4726, validation loss: 0.0771
2024-05-25 04:26:12 [INFO]: Epoch 184 - training loss: 9307.1731, validation loss: 0.0765
2024-05-25 04:26:12 [INFO]: Epoch 185 - training loss: 9305.5128, validation loss: 0.0764
2024-05-25 04:26:12 [INFO]: Epoch 186 - training loss: 9306.2236, validation loss: 0.0771
2024-05-25 04:26:12 [INFO]: Epoch 187 - training loss: 9306.9419, validation loss: 0.0780
2024-05-25 04:26:13 [INFO]: Epoch 188 - training loss: 9308.0897, validation loss: 0.0752
2024-05-25 04:26:13 [INFO]: Epoch 189 - training loss: 9306.3976, validation loss: 0.0754
2024-05-25 04:26:13 [INFO]: Epoch 190 - training loss: 9305.4967, validation loss: 0.0746
2024-05-25 04:26:13 [INFO]: Epoch 191 - training loss: 9304.8149, validation loss: 0.0757
2024-05-25 04:26:13 [INFO]: Epoch 192 - training loss: 9304.2594, validation loss: 0.0764
2024-05-25 04:26:13 [INFO]: Epoch 193 - training loss: 9305.2220, validation loss: 0.0764
2024-05-25 04:26:13 [INFO]: Epoch 194 - training loss: 9305.6506, validation loss: 0.0760
2024-05-25 04:26:14 [INFO]: Epoch 195 - training loss: 9306.0518, validation loss: 0.0777
2024-05-25 04:26:14 [INFO]: Epoch 196 - training loss: 9304.4138, validation loss: 0.0764
2024-05-25 04:26:14 [INFO]: Epoch 197 - training loss: 9305.6863, validation loss: 0.0749
2024-05-25 04:26:14 [INFO]: Epoch 198 - training loss: 9304.7156, validation loss: 0.0744
2024-05-25 04:26:14 [INFO]: Epoch 199 - training loss: 9304.0704, validation loss: 0.0769
2024-05-25 04:26:14 [INFO]: Epoch 200 - training loss: 9304.7778, validation loss: 0.0751
2024-05-25 04:26:14 [INFO]: Epoch 201 - training loss: 9304.6646, validation loss: 0.0756
2024-05-25 04:26:15 [INFO]: Epoch 202 - training loss: 9304.8226, validation loss: 0.0740
2024-05-25 04:26:15 [INFO]: Epoch 203 - training loss: 9305.2938, validation loss: 0.0747
2024-05-25 04:26:15 [INFO]: Epoch 204 - training loss: 9304.7150, validation loss: 0.0776
2024-05-25 04:26:15 [INFO]: Epoch 205 - training loss: 9304.6031, validation loss: 0.0746
2024-05-25 04:26:15 [INFO]: Epoch 206 - training loss: 9304.2201, validation loss: 0.0753
2024-05-25 04:26:15 [INFO]: Epoch 207 - training loss: 9305.4898, validation loss: 0.0737
2024-05-25 04:26:15 [INFO]: Epoch 208 - training loss: 9304.6268, validation loss: 0.0734
2024-05-25 04:26:16 [INFO]: Epoch 209 - training loss: 9304.9915, validation loss: 0.0738
2024-05-25 04:26:16 [INFO]: Epoch 210 - training loss: 9305.1895, validation loss: 0.0750
2024-05-25 04:26:16 [INFO]: Epoch 211 - training loss: 9304.2623, validation loss: 0.0747
2024-05-25 04:26:16 [INFO]: Epoch 212 - training loss: 9303.8392, validation loss: 0.0749
2024-05-25 04:26:16 [INFO]: Epoch 213 - training loss: 9304.7194, validation loss: 0.0750
2024-05-25 04:26:16 [INFO]: Epoch 214 - training loss: 9304.4423, validation loss: 0.0733
2024-05-25 04:26:16 [INFO]: Epoch 215 - training loss: 9305.5807, validation loss: 0.0742
2024-05-25 04:26:17 [INFO]: Epoch 216 - training loss: 9303.7664, validation loss: 0.0730
2024-05-25 04:26:17 [INFO]: Epoch 217 - training loss: 9304.3716, validation loss: 0.0749
2024-05-25 04:26:17 [INFO]: Epoch 218 - training loss: 9303.9147, validation loss: 0.0741
2024-05-25 04:26:17 [INFO]: Epoch 219 - training loss: 9303.1067, validation loss: 0.0735
2024-05-25 04:26:17 [INFO]: Epoch 220 - training loss: 9304.2096, validation loss: 0.0735
2024-05-25 04:26:17 [INFO]: Epoch 221 - training loss: 9304.5048, validation loss: 0.0705
2024-05-25 04:26:17 [INFO]: Epoch 222 - training loss: 9303.2740, validation loss: 0.0732
2024-05-25 04:26:18 [INFO]: Epoch 223 - training loss: 9302.1705, validation loss: 0.0736
2024-05-25 04:26:18 [INFO]: Epoch 224 - training loss: 9303.0311, validation loss: 0.0729
2024-05-25 04:26:18 [INFO]: Epoch 225 - training loss: 9303.5387, validation loss: 0.0716
2024-05-25 04:26:18 [INFO]: Epoch 226 - training loss: 9303.4938, validation loss: 0.0726
2024-05-25 04:26:18 [INFO]: Epoch 227 - training loss: 9304.6058, validation loss: 0.0727
2024-05-25 04:26:18 [INFO]: Epoch 228 - training loss: 9303.4156, validation loss: 0.0710
2024-05-25 04:26:18 [INFO]: Epoch 229 - training loss: 9304.4567, validation loss: 0.0741
2024-05-25 04:26:19 [INFO]: Epoch 230 - training loss: 9303.0518, validation loss: 0.0712
2024-05-25 04:26:19 [INFO]: Epoch 231 - training loss: 9303.1244, validation loss: 0.0725
2024-05-25 04:26:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:26:19 [INFO]: Finished training. The best model is from epoch#221.
2024-05-25 04:26:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240525_T042546/GPVAE.pypots
2024-05-25 04:26:19 [INFO]: GP-VAE on ETTm1: MAE=0.2548, MSE=0.1350
2024-05-25 04:26:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-25 04:26:19 [INFO]: Using the given device: cuda:0
2024-05-25 04:26:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T042619
2024-05-25 04:26:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T042619/tensorboard
2024-05-25 04:26:19 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 04:26:30 [INFO]: Epoch 001 - generator training loss: 0.5356, discriminator training loss: 0.3273, validation loss: 0.3073
2024-05-25 04:26:39 [INFO]: Epoch 002 - generator training loss: 0.0289, discriminator training loss: 0.2096, validation loss: 0.0918
2024-05-25 04:26:49 [INFO]: Epoch 003 - generator training loss: -0.0697, discriminator training loss: 0.2000, validation loss: 0.0566
2024-05-25 04:26:58 [INFO]: Epoch 004 - generator training loss: -0.0814, discriminator training loss: 0.1986, validation loss: 0.0482
2024-05-25 04:27:08 [INFO]: Epoch 005 - generator training loss: -0.0881, discriminator training loss: 0.1947, validation loss: 0.0427
2024-05-25 04:27:17 [INFO]: Epoch 006 - generator training loss: -0.0878, discriminator training loss: 0.1892, validation loss: 0.0399
2024-05-25 04:27:27 [INFO]: Epoch 007 - generator training loss: -0.0855, discriminator training loss: 0.1835, validation loss: 0.0377
2024-05-25 04:27:36 [INFO]: Epoch 008 - generator training loss: -0.0762, discriminator training loss: 0.1723, validation loss: 0.0365
2024-05-25 04:27:45 [INFO]: Epoch 009 - generator training loss: -0.0712, discriminator training loss: 0.1643, validation loss: 0.0355
2024-05-25 04:27:55 [INFO]: Epoch 010 - generator training loss: -0.0570, discriminator training loss: 0.1493, validation loss: 0.0351
2024-05-25 04:28:04 [INFO]: Epoch 011 - generator training loss: -0.0428, discriminator training loss: 0.1316, validation loss: 0.0345
2024-05-25 04:28:13 [INFO]: Epoch 012 - generator training loss: -0.0346, discriminator training loss: 0.1175, validation loss: 0.0334
2024-05-25 04:28:23 [INFO]: Epoch 013 - generator training loss: -0.0277, discriminator training loss: 0.1073, validation loss: 0.0331
2024-05-25 04:28:32 [INFO]: Epoch 014 - generator training loss: -0.0236, discriminator training loss: 0.1016, validation loss: 0.0328
2024-05-25 04:28:41 [INFO]: Epoch 015 - generator training loss: -0.0188, discriminator training loss: 0.0919, validation loss: 0.0319
2024-05-25 04:28:51 [INFO]: Epoch 016 - generator training loss: -0.0176, discriminator training loss: 0.0884, validation loss: 0.0316
2024-05-25 04:29:00 [INFO]: Epoch 017 - generator training loss: -0.0180, discriminator training loss: 0.0857, validation loss: 0.0315
2024-05-25 04:29:09 [INFO]: Epoch 018 - generator training loss: -0.0161, discriminator training loss: 0.0840, validation loss: 0.0315
2024-05-25 04:29:19 [INFO]: Epoch 019 - generator training loss: -0.0124, discriminator training loss: 0.0824, validation loss: 0.0312
2024-05-25 04:29:28 [INFO]: Epoch 020 - generator training loss: -0.0128, discriminator training loss: 0.0807, validation loss: 0.0318
2024-05-25 04:29:37 [INFO]: Epoch 021 - generator training loss: -0.0160, discriminator training loss: 0.0793, validation loss: 0.0304
2024-05-25 04:29:47 [INFO]: Epoch 022 - generator training loss: -0.0143, discriminator training loss: 0.0774, validation loss: 0.0296
2024-05-25 04:29:56 [INFO]: Epoch 023 - generator training loss: -0.0143, discriminator training loss: 0.0768, validation loss: 0.0305
2024-05-25 04:30:06 [INFO]: Epoch 024 - generator training loss: -0.0151, discriminator training loss: 0.0777, validation loss: 0.0291
2024-05-25 04:30:15 [INFO]: Epoch 025 - generator training loss: -0.0146, discriminator training loss: 0.0746, validation loss: 0.0292
2024-05-25 04:30:25 [INFO]: Epoch 026 - generator training loss: -0.0157, discriminator training loss: 0.0757, validation loss: 0.0292
2024-05-25 04:30:34 [INFO]: Epoch 027 - generator training loss: -0.0134, discriminator training loss: 0.0749, validation loss: 0.0284
2024-05-25 04:30:43 [INFO]: Epoch 028 - generator training loss: -0.0164, discriminator training loss: 0.0749, validation loss: 0.0285
2024-05-25 04:30:53 [INFO]: Epoch 029 - generator training loss: -0.0160, discriminator training loss: 0.0751, validation loss: 0.0276
2024-05-25 04:31:02 [INFO]: Epoch 030 - generator training loss: -0.0171, discriminator training loss: 0.0730, validation loss: 0.0270
2024-05-25 04:31:12 [INFO]: Epoch 031 - generator training loss: -0.0152, discriminator training loss: 0.0738, validation loss: 0.0281
2024-05-25 04:31:21 [INFO]: Epoch 032 - generator training loss: -0.0175, discriminator training loss: 0.0731, validation loss: 0.0272
2024-05-25 04:31:30 [INFO]: Epoch 033 - generator training loss: -0.0187, discriminator training loss: 0.0716, validation loss: 0.0269
2024-05-25 04:31:40 [INFO]: Epoch 034 - generator training loss: -0.0176, discriminator training loss: 0.0712, validation loss: 0.0259
2024-05-25 04:31:49 [INFO]: Epoch 035 - generator training loss: -0.0199, discriminator training loss: 0.0727, validation loss: 0.0261
2024-05-25 04:31:58 [INFO]: Epoch 036 - generator training loss: -0.0181, discriminator training loss: 0.0752, validation loss: 0.0251
2024-05-25 04:32:08 [INFO]: Epoch 037 - generator training loss: -0.0157, discriminator training loss: 0.0712, validation loss: 0.0248
2024-05-25 04:32:17 [INFO]: Epoch 038 - generator training loss: -0.0197, discriminator training loss: 0.0709, validation loss: 0.0246
2024-05-25 04:32:27 [INFO]: Epoch 039 - generator training loss: -0.0188, discriminator training loss: 0.0712, validation loss: 0.0240
2024-05-25 04:32:36 [INFO]: Epoch 040 - generator training loss: -0.0207, discriminator training loss: 0.0711, validation loss: 0.0233
2024-05-25 04:32:45 [INFO]: Epoch 041 - generator training loss: -0.0190, discriminator training loss: 0.0702, validation loss: 0.0227
2024-05-25 04:32:55 [INFO]: Epoch 042 - generator training loss: -0.0203, discriminator training loss: 0.0711, validation loss: 0.0232
2024-05-25 04:33:04 [INFO]: Epoch 043 - generator training loss: -0.0191, discriminator training loss: 0.0706, validation loss: 0.0224
2024-05-25 04:33:14 [INFO]: Epoch 044 - generator training loss: -0.0223, discriminator training loss: 0.0707, validation loss: 0.0223
2024-05-25 04:33:23 [INFO]: Epoch 045 - generator training loss: -0.0199, discriminator training loss: 0.0681, validation loss: 0.0217
2024-05-25 04:33:32 [INFO]: Epoch 046 - generator training loss: -0.0240, discriminator training loss: 0.0702, validation loss: 0.0218
2024-05-25 04:33:42 [INFO]: Epoch 047 - generator training loss: -0.0208, discriminator training loss: 0.0690, validation loss: 0.0213
2024-05-25 04:33:51 [INFO]: Epoch 048 - generator training loss: -0.0201, discriminator training loss: 0.0694, validation loss: 0.0209
2024-05-25 04:34:01 [INFO]: Epoch 049 - generator training loss: -0.0226, discriminator training loss: 0.0692, validation loss: 0.0221
2024-05-25 04:34:10 [INFO]: Epoch 050 - generator training loss: -0.0195, discriminator training loss: 0.0682, validation loss: 0.0223
2024-05-25 04:34:20 [INFO]: Epoch 051 - generator training loss: -0.0220, discriminator training loss: 0.0688, validation loss: 0.0215
2024-05-25 04:34:29 [INFO]: Epoch 052 - generator training loss: -0.0213, discriminator training loss: 0.0687, validation loss: 0.0215
2024-05-25 04:34:38 [INFO]: Epoch 053 - generator training loss: -0.0222, discriminator training loss: 0.0698, validation loss: 0.0214
2024-05-25 04:34:47 [INFO]: Epoch 054 - generator training loss: -0.0198, discriminator training loss: 0.0696, validation loss: 0.0215
2024-05-25 04:34:57 [INFO]: Epoch 055 - generator training loss: -0.0214, discriminator training loss: 0.0697, validation loss: 0.0222
2024-05-25 04:35:06 [INFO]: Epoch 056 - generator training loss: -0.0230, discriminator training loss: 0.0678, validation loss: 0.0215
2024-05-25 04:35:16 [INFO]: Epoch 057 - generator training loss: -0.0215, discriminator training loss: 0.0679, validation loss: 0.0213
2024-05-25 04:35:25 [INFO]: Epoch 058 - generator training loss: -0.0173, discriminator training loss: 0.0685, validation loss: 0.0226
2024-05-25 04:35:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:35:25 [INFO]: Finished training. The best model is from epoch#48.
2024-05-25 04:35:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_ettm1/20240525_T042619/USGAN.pypots
2024-05-25 04:35:26 [INFO]: US-GAN on ETTm1: MAE=0.1439, MSE=0.0502
2024-05-25 04:35:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-25 04:35:26 [INFO]: Using the given device: cuda:0
2024-05-25 04:35:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T043526
2024-05-25 04:35:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T043526/tensorboard
2024-05-25 04:35:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 04:35:34 [INFO]: Epoch 001 - training loss: 1.3886, validation loss: 0.2950
2024-05-25 04:35:40 [INFO]: Epoch 002 - training loss: 0.9581, validation loss: 0.0857
2024-05-25 04:35:46 [INFO]: Epoch 003 - training loss: 0.7654, validation loss: 0.0549
2024-05-25 04:35:53 [INFO]: Epoch 004 - training loss: 0.6805, validation loss: 0.0451
2024-05-25 04:35:59 [INFO]: Epoch 005 - training loss: 0.6429, validation loss: 0.0408
2024-05-25 04:36:05 [INFO]: Epoch 006 - training loss: 0.6100, validation loss: 0.0415
2024-05-25 04:36:11 [INFO]: Epoch 007 - training loss: 0.5973, validation loss: 0.0374
2024-05-25 04:36:18 [INFO]: Epoch 008 - training loss: 0.5623, validation loss: 0.0365
2024-05-25 04:36:24 [INFO]: Epoch 009 - training loss: 0.5864, validation loss: 0.0357
2024-05-25 04:36:30 [INFO]: Epoch 010 - training loss: 0.5315, validation loss: 0.0337
2024-05-25 04:36:36 [INFO]: Epoch 011 - training loss: 0.5087, validation loss: 0.0349
2024-05-25 04:36:42 [INFO]: Epoch 012 - training loss: 0.4811, validation loss: 0.0331
2024-05-25 04:36:49 [INFO]: Epoch 013 - training loss: 0.4626, validation loss: 0.0322
2024-05-25 04:36:55 [INFO]: Epoch 014 - training loss: 0.4525, validation loss: 0.0302
2024-05-25 04:37:01 [INFO]: Epoch 015 - training loss: 0.4333, validation loss: 0.0294
2024-05-25 04:37:07 [INFO]: Epoch 016 - training loss: 0.4270, validation loss: 0.0283
2024-05-25 04:37:14 [INFO]: Epoch 017 - training loss: 0.4207, validation loss: 0.0274
2024-05-25 04:37:20 [INFO]: Epoch 018 - training loss: 0.4105, validation loss: 0.0271
2024-05-25 04:37:26 [INFO]: Epoch 019 - training loss: 0.4012, validation loss: 0.0262
2024-05-25 04:37:32 [INFO]: Epoch 020 - training loss: 0.3917, validation loss: 0.0248
2024-05-25 04:37:39 [INFO]: Epoch 021 - training loss: 0.3831, validation loss: 0.0247
2024-05-25 04:37:45 [INFO]: Epoch 022 - training loss: 0.3995, validation loss: 0.0239
2024-05-25 04:37:51 [INFO]: Epoch 023 - training loss: 0.3893, validation loss: 0.0237
2024-05-25 04:37:57 [INFO]: Epoch 024 - training loss: 0.3826, validation loss: 0.0232
2024-05-25 04:38:03 [INFO]: Epoch 025 - training loss: 0.3863, validation loss: 0.0225
2024-05-25 04:38:10 [INFO]: Epoch 026 - training loss: 0.3749, validation loss: 0.0236
2024-05-25 04:38:16 [INFO]: Epoch 027 - training loss: 0.3999, validation loss: 0.0238
2024-05-25 04:38:22 [INFO]: Epoch 028 - training loss: 0.3883, validation loss: 0.0233
2024-05-25 04:38:29 [INFO]: Epoch 029 - training loss: 0.3793, validation loss: 0.0237
2024-05-25 04:38:35 [INFO]: Epoch 030 - training loss: 0.3841, validation loss: 0.0232
2024-05-25 04:38:41 [INFO]: Epoch 031 - training loss: 0.3786, validation loss: 0.0228
2024-05-25 04:38:47 [INFO]: Epoch 032 - training loss: 0.3835, validation loss: 0.0229
2024-05-25 04:38:53 [INFO]: Epoch 033 - training loss: 0.3740, validation loss: 0.0229
2024-05-25 04:39:00 [INFO]: Epoch 034 - training loss: 0.3788, validation loss: 0.0234
2024-05-25 04:39:06 [INFO]: Epoch 035 - training loss: 0.3716, validation loss: 0.0230
2024-05-25 04:39:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:39:06 [INFO]: Finished training. The best model is from epoch#25.
2024-05-25 04:39:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_ettm1/20240525_T043526/BRITS.pypots
2024-05-25 04:39:07 [INFO]: BRITS on ETTm1: MAE=0.1242, MSE=0.0453
2024-05-25 04:39:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-25 04:39:07 [INFO]: Using the given device: cuda:0
2024-05-25 04:39:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907
2024-05-25 04:39:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/tensorboard
2024-05-25 04:39:07 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 04:39:09 [INFO]: Epoch 001 - training loss: 1.3745, validation loss: 1.2777
2024-05-25 04:39:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch1_loss1.277727410197258.pypots
2024-05-25 04:39:09 [INFO]: Epoch 002 - training loss: 1.0948, validation loss: 1.1556
2024-05-25 04:39:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch2_loss1.1556142270565033.pypots
2024-05-25 04:39:09 [INFO]: Epoch 003 - training loss: 0.9845, validation loss: 1.0621
2024-05-25 04:39:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch3_loss1.062089130282402.pypots
2024-05-25 04:39:10 [INFO]: Epoch 004 - training loss: 0.9684, validation loss: 1.0162
2024-05-25 04:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch4_loss1.016169548034668.pypots
2024-05-25 04:39:10 [INFO]: Epoch 005 - training loss: 0.9906, validation loss: 0.9918
2024-05-25 04:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch5_loss0.9917676895856857.pypots
2024-05-25 04:39:10 [INFO]: Epoch 006 - training loss: 1.0304, validation loss: 0.9833
2024-05-25 04:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch6_loss0.9832606911659241.pypots
2024-05-25 04:39:10 [INFO]: Epoch 007 - training loss: 0.9851, validation loss: 0.9788
2024-05-25 04:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch7_loss0.978754386305809.pypots
2024-05-25 04:39:10 [INFO]: Epoch 008 - training loss: 0.9294, validation loss: 0.9730
2024-05-25 04:39:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch8_loss0.9729712754487991.pypots
2024-05-25 04:39:11 [INFO]: Epoch 009 - training loss: 0.9405, validation loss: 0.9700
2024-05-25 04:39:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch9_loss0.9700366109609604.pypots
2024-05-25 04:39:11 [INFO]: Epoch 010 - training loss: 0.9272, validation loss: 0.9704
2024-05-25 04:39:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch10_loss0.9704182296991348.pypots
2024-05-25 04:39:11 [INFO]: Epoch 011 - training loss: 0.8985, validation loss: 0.9710
2024-05-25 04:39:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch11_loss0.9709606170654297.pypots
2024-05-25 04:39:11 [INFO]: Epoch 012 - training loss: 0.8988, validation loss: 0.9733
2024-05-25 04:39:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch12_loss0.9733007550239563.pypots
2024-05-25 04:39:11 [INFO]: Epoch 013 - training loss: 0.9031, validation loss: 0.9724
2024-05-25 04:39:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch13_loss0.9723955541849136.pypots
2024-05-25 04:39:12 [INFO]: Epoch 014 - training loss: 0.8888, validation loss: 0.9709
2024-05-25 04:39:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch14_loss0.9709041267633438.pypots
2024-05-25 04:39:12 [INFO]: Epoch 015 - training loss: 0.9467, validation loss: 0.9715
2024-05-25 04:39:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch15_loss0.9715139865875244.pypots
2024-05-25 04:39:12 [INFO]: Epoch 016 - training loss: 0.8923, validation loss: 0.9709
2024-05-25 04:39:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch16_loss0.9709096997976303.pypots
2024-05-25 04:39:12 [INFO]: Epoch 017 - training loss: 0.8711, validation loss: 0.9665
2024-05-25 04:39:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch17_loss0.9664898961782455.pypots
2024-05-25 04:39:12 [INFO]: Epoch 018 - training loss: 0.8995, validation loss: 0.9642
2024-05-25 04:39:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch18_loss0.9642219692468643.pypots
2024-05-25 04:39:13 [INFO]: Epoch 019 - training loss: 0.8781, validation loss: 0.9616
2024-05-25 04:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch19_loss0.9616210758686066.pypots
2024-05-25 04:39:13 [INFO]: Epoch 020 - training loss: 0.8754, validation loss: 0.9610
2024-05-25 04:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch20_loss0.9609957784414291.pypots
2024-05-25 04:39:13 [INFO]: Epoch 021 - training loss: 0.8390, validation loss: 0.9596
2024-05-25 04:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch21_loss0.9595906436443329.pypots
2024-05-25 04:39:13 [INFO]: Epoch 022 - training loss: 0.8465, validation loss: 0.9534
2024-05-25 04:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch22_loss0.9533539861440659.pypots
2024-05-25 04:39:13 [INFO]: Epoch 023 - training loss: 0.8435, validation loss: 0.9495
2024-05-25 04:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch23_loss0.9494976699352264.pypots
2024-05-25 04:39:14 [INFO]: Epoch 024 - training loss: 0.8560, validation loss: 0.9499
2024-05-25 04:39:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch24_loss0.9498882293701172.pypots
2024-05-25 04:39:14 [INFO]: Epoch 025 - training loss: 0.8429, validation loss: 0.9477
2024-05-25 04:39:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch25_loss0.9477493464946747.pypots
2024-05-25 04:39:14 [INFO]: Epoch 026 - training loss: 0.8678, validation loss: 0.9425
2024-05-25 04:39:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch26_loss0.9424692988395691.pypots
2024-05-25 04:39:14 [INFO]: Epoch 027 - training loss: 0.8428, validation loss: 0.9427
2024-05-25 04:39:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch27_loss0.9427199363708496.pypots
2024-05-25 04:39:14 [INFO]: Epoch 028 - training loss: 0.8169, validation loss: 0.9394
2024-05-25 04:39:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch28_loss0.9393784999847412.pypots
2024-05-25 04:39:15 [INFO]: Epoch 029 - training loss: 0.8379, validation loss: 0.9374
2024-05-25 04:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch29_loss0.9374437481164932.pypots
2024-05-25 04:39:15 [INFO]: Epoch 030 - training loss: 0.8900, validation loss: 0.9356
2024-05-25 04:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch30_loss0.9356066584587097.pypots
2024-05-25 04:39:15 [INFO]: Epoch 031 - training loss: 0.8332, validation loss: 0.9301
2024-05-25 04:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch31_loss0.9300646185874939.pypots
2024-05-25 04:39:15 [INFO]: Epoch 032 - training loss: 0.8372, validation loss: 0.9283
2024-05-25 04:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch32_loss0.9283462315797806.pypots
2024-05-25 04:39:15 [INFO]: Epoch 033 - training loss: 0.8475, validation loss: 0.9275
2024-05-25 04:39:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch33_loss0.9274594038724899.pypots
2024-05-25 04:39:16 [INFO]: Epoch 034 - training loss: 0.8209, validation loss: 0.9238
2024-05-25 04:39:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch34_loss0.9238083213567734.pypots
2024-05-25 04:39:16 [INFO]: Epoch 035 - training loss: 0.8217, validation loss: 0.9208
2024-05-25 04:39:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch35_loss0.9207553118467331.pypots
2024-05-25 04:39:16 [INFO]: Epoch 036 - training loss: 0.8052, validation loss: 0.9178
2024-05-25 04:39:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch36_loss0.9177937507629395.pypots
2024-05-25 04:39:16 [INFO]: Epoch 037 - training loss: 0.8272, validation loss: 0.9162
2024-05-25 04:39:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch37_loss0.9162250012159348.pypots
2024-05-25 04:39:16 [INFO]: Epoch 038 - training loss: 0.8262, validation loss: 0.9163
2024-05-25 04:39:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch38_loss0.9162838757038116.pypots
2024-05-25 04:39:17 [INFO]: Epoch 039 - training loss: 0.8069, validation loss: 0.9120
2024-05-25 04:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch39_loss0.9119652658700943.pypots
2024-05-25 04:39:17 [INFO]: Epoch 040 - training loss: 0.8187, validation loss: 0.9102
2024-05-25 04:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch40_loss0.9101723581552505.pypots
2024-05-25 04:39:17 [INFO]: Epoch 041 - training loss: 0.8238, validation loss: 0.9068
2024-05-25 04:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch41_loss0.9067839235067368.pypots
2024-05-25 04:39:17 [INFO]: Epoch 042 - training loss: 0.8194, validation loss: 0.9094
2024-05-25 04:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch42_loss0.909427210688591.pypots
2024-05-25 04:39:17 [INFO]: Epoch 043 - training loss: 0.8214, validation loss: 0.9038
2024-05-25 04:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch43_loss0.9037515819072723.pypots
2024-05-25 04:39:18 [INFO]: Epoch 044 - training loss: 0.8257, validation loss: 0.9039
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch44_loss0.9039145559072495.pypots
2024-05-25 04:39:18 [INFO]: Epoch 045 - training loss: 0.8066, validation loss: 0.9008
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch45_loss0.9008076786994934.pypots
2024-05-25 04:39:18 [INFO]: Epoch 046 - training loss: 0.8300, validation loss: 0.8992
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch46_loss0.8992081135511398.pypots
2024-05-25 04:39:18 [INFO]: Epoch 047 - training loss: 0.8206, validation loss: 0.8985
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch47_loss0.8984846323728561.pypots
2024-05-25 04:39:18 [INFO]: Epoch 048 - training loss: 0.8089, validation loss: 0.8969
2024-05-25 04:39:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch48_loss0.8969222158193588.pypots
2024-05-25 04:39:19 [INFO]: Epoch 049 - training loss: 0.8224, validation loss: 0.8956
2024-05-25 04:39:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch49_loss0.895597904920578.pypots
2024-05-25 04:39:19 [INFO]: Epoch 050 - training loss: 0.8159, validation loss: 0.8933
2024-05-25 04:39:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch50_loss0.8933214396238327.pypots
2024-05-25 04:39:19 [INFO]: Epoch 051 - training loss: 0.7866, validation loss: 0.8925
2024-05-25 04:39:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch51_loss0.8925168961286545.pypots
2024-05-25 04:39:19 [INFO]: Epoch 052 - training loss: 0.8048, validation loss: 0.8913
2024-05-25 04:39:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch52_loss0.8912945836782455.pypots
2024-05-25 04:39:20 [INFO]: Epoch 053 - training loss: 0.7908, validation loss: 0.8921
2024-05-25 04:39:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch53_loss0.8921367079019547.pypots
2024-05-25 04:39:20 [INFO]: Epoch 054 - training loss: 0.7869, validation loss: 0.8890
2024-05-25 04:39:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch54_loss0.8890217989683151.pypots
2024-05-25 04:39:20 [INFO]: Epoch 055 - training loss: 0.8028, validation loss: 0.8868
2024-05-25 04:39:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch55_loss0.886777475476265.pypots
2024-05-25 04:39:20 [INFO]: Epoch 056 - training loss: 0.8329, validation loss: 0.8884
2024-05-25 04:39:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch56_loss0.8884042203426361.pypots
2024-05-25 04:39:20 [INFO]: Epoch 057 - training loss: 0.7787, validation loss: 0.8859
2024-05-25 04:39:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch57_loss0.8859186470508575.pypots
2024-05-25 04:39:21 [INFO]: Epoch 058 - training loss: 0.8007, validation loss: 0.8858
2024-05-25 04:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch58_loss0.8857550919055939.pypots
2024-05-25 04:39:21 [INFO]: Epoch 059 - training loss: 0.8029, validation loss: 0.8864
2024-05-25 04:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch59_loss0.8864211589097977.pypots
2024-05-25 04:39:21 [INFO]: Epoch 060 - training loss: 0.8006, validation loss: 0.8835
2024-05-25 04:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch60_loss0.8835496157407761.pypots
2024-05-25 04:39:21 [INFO]: Epoch 061 - training loss: 0.8166, validation loss: 0.8822
2024-05-25 04:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch61_loss0.8821625411510468.pypots
2024-05-25 04:39:21 [INFO]: Epoch 062 - training loss: 0.8230, validation loss: 0.8830
2024-05-25 04:39:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch62_loss0.8830244243144989.pypots
2024-05-25 04:39:22 [INFO]: Epoch 063 - training loss: 0.7992, validation loss: 0.8808
2024-05-25 04:39:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch63_loss0.8808464705944061.pypots
2024-05-25 04:39:22 [INFO]: Epoch 064 - training loss: 0.8051, validation loss: 0.8810
2024-05-25 04:39:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch64_loss0.8810379207134247.pypots
2024-05-25 04:39:22 [INFO]: Epoch 065 - training loss: 0.8362, validation loss: 0.8821
2024-05-25 04:39:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch65_loss0.8820610195398331.pypots
2024-05-25 04:39:22 [INFO]: Epoch 066 - training loss: 0.7985, validation loss: 0.8787
2024-05-25 04:39:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch66_loss0.878725990653038.pypots
2024-05-25 04:39:22 [INFO]: Epoch 067 - training loss: 0.8431, validation loss: 0.8799
2024-05-25 04:39:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch67_loss0.879908874630928.pypots
2024-05-25 04:39:23 [INFO]: Epoch 068 - training loss: 0.7918, validation loss: 0.8803
2024-05-25 04:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch68_loss0.8803111016750336.pypots
2024-05-25 04:39:23 [INFO]: Epoch 069 - training loss: 0.7912, validation loss: 0.8779
2024-05-25 04:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch69_loss0.8778853565454483.pypots
2024-05-25 04:39:23 [INFO]: Epoch 070 - training loss: 0.8463, validation loss: 0.8790
2024-05-25 04:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch70_loss0.8789829313755035.pypots
2024-05-25 04:39:23 [INFO]: Epoch 071 - training loss: 0.7875, validation loss: 0.8777
2024-05-25 04:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch71_loss0.8777121603488922.pypots
2024-05-25 04:39:23 [INFO]: Epoch 072 - training loss: 0.8096, validation loss: 0.8754
2024-05-25 04:39:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch72_loss0.8753651231527328.pypots
2024-05-25 04:39:24 [INFO]: Epoch 073 - training loss: 0.7891, validation loss: 0.8761
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch73_loss0.8760641366243362.pypots
2024-05-25 04:39:24 [INFO]: Epoch 074 - training loss: 0.7955, validation loss: 0.8743
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch74_loss0.8743104189634323.pypots
2024-05-25 04:39:24 [INFO]: Epoch 075 - training loss: 0.8006, validation loss: 0.8763
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch75_loss0.8762856721878052.pypots
2024-05-25 04:39:24 [INFO]: Epoch 076 - training loss: 0.8168, validation loss: 0.8761
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch76_loss0.8761216700077057.pypots
2024-05-25 04:39:24 [INFO]: Epoch 077 - training loss: 0.7935, validation loss: 0.8745
2024-05-25 04:39:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch77_loss0.8744832426309586.pypots
2024-05-25 04:39:25 [INFO]: Epoch 078 - training loss: 0.7989, validation loss: 0.8708
2024-05-25 04:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch78_loss0.870846688747406.pypots
2024-05-25 04:39:25 [INFO]: Epoch 079 - training loss: 0.8166, validation loss: 0.8705
2024-05-25 04:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch79_loss0.8704693019390106.pypots
2024-05-25 04:39:25 [INFO]: Epoch 080 - training loss: 0.8033, validation loss: 0.8711
2024-05-25 04:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch80_loss0.8711279332637787.pypots
2024-05-25 04:39:25 [INFO]: Epoch 081 - training loss: 0.8087, validation loss: 0.8703
2024-05-25 04:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch81_loss0.8703397959470749.pypots
2024-05-25 04:39:25 [INFO]: Epoch 082 - training loss: 0.7980, validation loss: 0.8685
2024-05-25 04:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch82_loss0.8685386031866074.pypots
2024-05-25 04:39:26 [INFO]: Epoch 083 - training loss: 0.7884, validation loss: 0.8689
2024-05-25 04:39:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch83_loss0.8689426630735397.pypots
2024-05-25 04:39:26 [INFO]: Epoch 084 - training loss: 0.8123, validation loss: 0.8672
2024-05-25 04:39:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch84_loss0.8672114014625549.pypots
2024-05-25 04:39:26 [INFO]: Epoch 085 - training loss: 0.8044, validation loss: 0.8662
2024-05-25 04:39:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch85_loss0.8661856800317764.pypots
2024-05-25 04:39:26 [INFO]: Epoch 086 - training loss: 0.7846, validation loss: 0.8674
2024-05-25 04:39:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch86_loss0.8674023002386093.pypots
2024-05-25 04:39:26 [INFO]: Epoch 087 - training loss: 0.8183, validation loss: 0.8678
2024-05-25 04:39:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch87_loss0.8677658438682556.pypots
2024-05-25 04:39:27 [INFO]: Epoch 088 - training loss: 0.8056, validation loss: 0.8660
2024-05-25 04:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch88_loss0.8659979104995728.pypots
2024-05-25 04:39:27 [INFO]: Epoch 089 - training loss: 0.7755, validation loss: 0.8647
2024-05-25 04:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch89_loss0.864743709564209.pypots
2024-05-25 04:39:27 [INFO]: Epoch 090 - training loss: 0.7966, validation loss: 0.8656
2024-05-25 04:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch90_loss0.8656314611434937.pypots
2024-05-25 04:39:27 [INFO]: Epoch 091 - training loss: 0.8131, validation loss: 0.8648
2024-05-25 04:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch91_loss0.8648290932178497.pypots
2024-05-25 04:39:27 [INFO]: Epoch 092 - training loss: 0.8077, validation loss: 0.8646
2024-05-25 04:39:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch92_loss0.8646140545606613.pypots
2024-05-25 04:39:28 [INFO]: Epoch 093 - training loss: 0.7951, validation loss: 0.8630
2024-05-25 04:39:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch93_loss0.8629856407642365.pypots
2024-05-25 04:39:28 [INFO]: Epoch 094 - training loss: 0.7718, validation loss: 0.8621
2024-05-25 04:39:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch94_loss0.8621167689561844.pypots
2024-05-25 04:39:28 [INFO]: Epoch 095 - training loss: 0.7816, validation loss: 0.8613
2024-05-25 04:39:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch95_loss0.8613297343254089.pypots
2024-05-25 04:39:28 [INFO]: Epoch 096 - training loss: 0.8081, validation loss: 0.8579
2024-05-25 04:39:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch96_loss0.8578607589006424.pypots
2024-05-25 04:39:28 [INFO]: Epoch 097 - training loss: 0.7887, validation loss: 0.8612
2024-05-25 04:39:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch97_loss0.8611755520105362.pypots
2024-05-25 04:39:29 [INFO]: Epoch 098 - training loss: 0.7927, validation loss: 0.8574
2024-05-25 04:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch98_loss0.8573874831199646.pypots
2024-05-25 04:39:29 [INFO]: Epoch 099 - training loss: 0.7975, validation loss: 0.8574
2024-05-25 04:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch99_loss0.8574311435222626.pypots
2024-05-25 04:39:29 [INFO]: Epoch 100 - training loss: 0.7627, validation loss: 0.8574
2024-05-25 04:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch100_loss0.8574010580778122.pypots
2024-05-25 04:39:29 [INFO]: Epoch 101 - training loss: 0.7952, validation loss: 0.8615
2024-05-25 04:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch101_loss0.8615117371082306.pypots
2024-05-25 04:39:29 [INFO]: Epoch 102 - training loss: 0.7861, validation loss: 0.8578
2024-05-25 04:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch102_loss0.8577961623668671.pypots
2024-05-25 04:39:30 [INFO]: Epoch 103 - training loss: 0.7763, validation loss: 0.8571
2024-05-25 04:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch103_loss0.8570750653743744.pypots
2024-05-25 04:39:30 [INFO]: Epoch 104 - training loss: 0.7938, validation loss: 0.8566
2024-05-25 04:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch104_loss0.8565651476383209.pypots
2024-05-25 04:39:30 [INFO]: Epoch 105 - training loss: 0.7879, validation loss: 0.8555
2024-05-25 04:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch105_loss0.8555477559566498.pypots
2024-05-25 04:39:30 [INFO]: Epoch 106 - training loss: 0.7837, validation loss: 0.8555
2024-05-25 04:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch106_loss0.8555454015731812.pypots
2024-05-25 04:39:30 [INFO]: Epoch 107 - training loss: 0.7755, validation loss: 0.8548
2024-05-25 04:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch107_loss0.8547614961862564.pypots
2024-05-25 04:39:31 [INFO]: Epoch 108 - training loss: 0.8002, validation loss: 0.8521
2024-05-25 04:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch108_loss0.8520965874195099.pypots
2024-05-25 04:39:31 [INFO]: Epoch 109 - training loss: 0.7841, validation loss: 0.8559
2024-05-25 04:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch109_loss0.855856791138649.pypots
2024-05-25 04:39:31 [INFO]: Epoch 110 - training loss: 0.7903, validation loss: 0.8536
2024-05-25 04:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch110_loss0.8536091148853302.pypots
2024-05-25 04:39:31 [INFO]: Epoch 111 - training loss: 0.7747, validation loss: 0.8519
2024-05-25 04:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch111_loss0.8518620431423187.pypots
2024-05-25 04:39:31 [INFO]: Epoch 112 - training loss: 0.7959, validation loss: 0.8532
2024-05-25 04:39:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch112_loss0.8531637936830521.pypots
2024-05-25 04:39:32 [INFO]: Epoch 113 - training loss: 0.7813, validation loss: 0.8505
2024-05-25 04:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch113_loss0.8505230844020844.pypots
2024-05-25 04:39:32 [INFO]: Epoch 114 - training loss: 0.7723, validation loss: 0.8504
2024-05-25 04:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch114_loss0.8503954708576202.pypots
2024-05-25 04:39:32 [INFO]: Epoch 115 - training loss: 0.7959, validation loss: 0.8509
2024-05-25 04:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch115_loss0.8509192764759064.pypots
2024-05-25 04:39:32 [INFO]: Epoch 116 - training loss: 0.7698, validation loss: 0.8523
2024-05-25 04:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch116_loss0.8523349761962891.pypots
2024-05-25 04:39:32 [INFO]: Epoch 117 - training loss: 0.7751, validation loss: 0.8482
2024-05-25 04:39:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch117_loss0.8482042998075485.pypots
2024-05-25 04:39:33 [INFO]: Epoch 118 - training loss: 0.7760, validation loss: 0.8500
2024-05-25 04:39:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch118_loss0.8499677181243896.pypots
2024-05-25 04:39:33 [INFO]: Epoch 119 - training loss: 0.7822, validation loss: 0.8491
2024-05-25 04:39:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch119_loss0.8491022735834122.pypots
2024-05-25 04:39:33 [INFO]: Epoch 120 - training loss: 0.7877, validation loss: 0.8490
2024-05-25 04:39:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch120_loss0.8490086197853088.pypots
2024-05-25 04:39:33 [INFO]: Epoch 121 - training loss: 0.7891, validation loss: 0.8475
2024-05-25 04:39:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch121_loss0.847462922334671.pypots
2024-05-25 04:39:33 [INFO]: Epoch 122 - training loss: 0.7774, validation loss: 0.8476
2024-05-25 04:39:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch122_loss0.8476220518350601.pypots
2024-05-25 04:39:34 [INFO]: Epoch 123 - training loss: 0.8191, validation loss: 0.8481
2024-05-25 04:39:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch123_loss0.8481374680995941.pypots
2024-05-25 04:39:34 [INFO]: Epoch 124 - training loss: 0.7913, validation loss: 0.8465
2024-05-25 04:39:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch124_loss0.8465459644794464.pypots
2024-05-25 04:39:34 [INFO]: Epoch 125 - training loss: 0.7827, validation loss: 0.8463
2024-05-25 04:39:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch125_loss0.8462631553411484.pypots
2024-05-25 04:39:34 [INFO]: Epoch 126 - training loss: 0.8217, validation loss: 0.8473
2024-05-25 04:39:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch126_loss0.8472757339477539.pypots
2024-05-25 04:39:34 [INFO]: Epoch 127 - training loss: 0.7841, validation loss: 0.8464
2024-05-25 04:39:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch127_loss0.8463817089796066.pypots
2024-05-25 04:39:35 [INFO]: Epoch 128 - training loss: 0.7857, validation loss: 0.8449
2024-05-25 04:39:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch128_loss0.8448813110589981.pypots
2024-05-25 04:39:35 [INFO]: Epoch 129 - training loss: 0.8063, validation loss: 0.8470
2024-05-25 04:39:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch129_loss0.8470207154750824.pypots
2024-05-25 04:39:35 [INFO]: Epoch 130 - training loss: 0.7986, validation loss: 0.8457
2024-05-25 04:39:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch130_loss0.8456926494836807.pypots
2024-05-25 04:39:35 [INFO]: Epoch 131 - training loss: 0.8273, validation loss: 0.8440
2024-05-25 04:39:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch131_loss0.8439557105302811.pypots
2024-05-25 04:39:35 [INFO]: Epoch 132 - training loss: 0.7865, validation loss: 0.8458
2024-05-25 04:39:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch132_loss0.8457808941602707.pypots
2024-05-25 04:39:36 [INFO]: Epoch 133 - training loss: 0.7697, validation loss: 0.8441
2024-05-25 04:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch133_loss0.8441352546215057.pypots
2024-05-25 04:39:36 [INFO]: Epoch 134 - training loss: 0.8051, validation loss: 0.8393
2024-05-25 04:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch134_loss0.8393249660730362.pypots
2024-05-25 04:39:36 [INFO]: Epoch 135 - training loss: 0.7761, validation loss: 0.8480
2024-05-25 04:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch135_loss0.8479984551668167.pypots
2024-05-25 04:39:36 [INFO]: Epoch 136 - training loss: 0.7638, validation loss: 0.8412
2024-05-25 04:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch136_loss0.8412264883518219.pypots
2024-05-25 04:39:36 [INFO]: Epoch 137 - training loss: 0.7940, validation loss: 0.8393
2024-05-25 04:39:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch137_loss0.8392947614192963.pypots
2024-05-25 04:39:37 [INFO]: Epoch 138 - training loss: 0.7969, validation loss: 0.8435
2024-05-25 04:39:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch138_loss0.8434940874576569.pypots
2024-05-25 04:39:37 [INFO]: Epoch 139 - training loss: 0.8097, validation loss: 0.8431
2024-05-25 04:39:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch139_loss0.843095064163208.pypots
2024-05-25 04:39:37 [INFO]: Epoch 140 - training loss: 0.7996, validation loss: 0.8455
2024-05-25 04:39:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch140_loss0.8455446511507034.pypots
2024-05-25 04:39:37 [INFO]: Epoch 141 - training loss: 0.8069, validation loss: 0.8433
2024-05-25 04:39:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch141_loss0.8432705998420715.pypots
2024-05-25 04:39:37 [INFO]: Epoch 142 - training loss: 0.7601, validation loss: 0.8404
2024-05-25 04:39:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch142_loss0.8404491394758224.pypots
2024-05-25 04:39:38 [INFO]: Epoch 143 - training loss: 0.7992, validation loss: 0.8405
2024-05-25 04:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch143_loss0.8405476808547974.pypots
2024-05-25 04:39:38 [INFO]: Epoch 144 - training loss: 0.7955, validation loss: 0.8366
2024-05-25 04:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch144_loss0.8365894705057144.pypots
2024-05-25 04:39:38 [INFO]: Epoch 145 - training loss: 0.7709, validation loss: 0.8368
2024-05-25 04:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch145_loss0.8367790877819061.pypots
2024-05-25 04:39:38 [INFO]: Epoch 146 - training loss: 0.8000, validation loss: 0.8362
2024-05-25 04:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch146_loss0.8362150192260742.pypots
2024-05-25 04:39:38 [INFO]: Epoch 147 - training loss: 0.7715, validation loss: 0.8355
2024-05-25 04:39:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch147_loss0.8355057537555695.pypots
2024-05-25 04:39:39 [INFO]: Epoch 148 - training loss: 0.7658, validation loss: 0.8389
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch148_loss0.838927835226059.pypots
2024-05-25 04:39:39 [INFO]: Epoch 149 - training loss: 0.8031, validation loss: 0.8382
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch149_loss0.8382110893726349.pypots
2024-05-25 04:39:39 [INFO]: Epoch 150 - training loss: 0.8101, validation loss: 0.8353
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch150_loss0.835299164056778.pypots
2024-05-25 04:39:39 [INFO]: Epoch 151 - training loss: 0.7717, validation loss: 0.8383
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch151_loss0.8383458703756332.pypots
2024-05-25 04:39:39 [INFO]: Epoch 152 - training loss: 0.7765, validation loss: 0.8337
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch152_loss0.8336657583713531.pypots
2024-05-25 04:39:39 [INFO]: Epoch 153 - training loss: 0.8188, validation loss: 0.8360
2024-05-25 04:39:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch153_loss0.8359783887863159.pypots
2024-05-25 04:39:40 [INFO]: Epoch 154 - training loss: 0.7889, validation loss: 0.8340
2024-05-25 04:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch154_loss0.833959624171257.pypots
2024-05-25 04:39:40 [INFO]: Epoch 155 - training loss: 0.7846, validation loss: 0.8333
2024-05-25 04:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch155_loss0.8333217948675156.pypots
2024-05-25 04:39:40 [INFO]: Epoch 156 - training loss: 0.7833, validation loss: 0.8324
2024-05-25 04:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch156_loss0.8323862552642822.pypots
2024-05-25 04:39:40 [INFO]: Epoch 157 - training loss: 0.7697, validation loss: 0.8345
2024-05-25 04:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch157_loss0.8344936370849609.pypots
2024-05-25 04:39:40 [INFO]: Epoch 158 - training loss: 0.7889, validation loss: 0.8338
2024-05-25 04:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch158_loss0.8337767720222473.pypots
2024-05-25 04:39:41 [INFO]: Epoch 159 - training loss: 0.7936, validation loss: 0.8326
2024-05-25 04:39:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch159_loss0.8326032757759094.pypots
2024-05-25 04:39:41 [INFO]: Epoch 160 - training loss: 0.7741, validation loss: 0.8328
2024-05-25 04:39:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch160_loss0.8327941298484802.pypots
2024-05-25 04:39:41 [INFO]: Epoch 161 - training loss: 0.7738, validation loss: 0.8316
2024-05-25 04:39:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch161_loss0.8315557837486267.pypots
2024-05-25 04:39:41 [INFO]: Epoch 162 - training loss: 0.7938, validation loss: 0.8323
2024-05-25 04:39:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch162_loss0.8322786241769791.pypots
2024-05-25 04:39:41 [INFO]: Epoch 163 - training loss: 0.7950, validation loss: 0.8302
2024-05-25 04:39:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch163_loss0.8302222937345505.pypots
2024-05-25 04:39:42 [INFO]: Epoch 164 - training loss: 0.7825, validation loss: 0.8317
2024-05-25 04:39:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch164_loss0.8316538482904434.pypots
2024-05-25 04:39:42 [INFO]: Epoch 165 - training loss: 0.7918, validation loss: 0.8322
2024-05-25 04:39:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch165_loss0.8321999609470367.pypots
2024-05-25 04:39:42 [INFO]: Epoch 166 - training loss: 0.7756, validation loss: 0.8302
2024-05-25 04:39:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch166_loss0.8302347362041473.pypots
2024-05-25 04:39:42 [INFO]: Epoch 167 - training loss: 0.7719, validation loss: 0.8302
2024-05-25 04:39:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch167_loss0.830204427242279.pypots
2024-05-25 04:39:42 [INFO]: Epoch 168 - training loss: 0.8174, validation loss: 0.8290
2024-05-25 04:39:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch168_loss0.8289699256420135.pypots
2024-05-25 04:39:43 [INFO]: Epoch 169 - training loss: 0.7653, validation loss: 0.8281
2024-05-25 04:39:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch169_loss0.8280927985906601.pypots
2024-05-25 04:39:43 [INFO]: Epoch 170 - training loss: 0.7624, validation loss: 0.8330
2024-05-25 04:39:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch170_loss0.8329830914735794.pypots
2024-05-25 04:39:43 [INFO]: Epoch 171 - training loss: 0.7955, validation loss: 0.8300
2024-05-25 04:39:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch171_loss0.8300044536590576.pypots
2024-05-25 04:39:43 [INFO]: Epoch 172 - training loss: 0.7845, validation loss: 0.8289
2024-05-25 04:39:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch172_loss0.8288600891828537.pypots
2024-05-25 04:39:43 [INFO]: Epoch 173 - training loss: 0.7868, validation loss: 0.8298
2024-05-25 04:39:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch173_loss0.8297854214906693.pypots
2024-05-25 04:39:44 [INFO]: Epoch 174 - training loss: 0.7587, validation loss: 0.8278
2024-05-25 04:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch174_loss0.8278120309114456.pypots
2024-05-25 04:39:44 [INFO]: Epoch 175 - training loss: 0.7865, validation loss: 0.8299
2024-05-25 04:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch175_loss0.8299099057912827.pypots
2024-05-25 04:39:44 [INFO]: Epoch 176 - training loss: 0.7589, validation loss: 0.8276
2024-05-25 04:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch176_loss0.8275635093450546.pypots
2024-05-25 04:39:44 [INFO]: Epoch 177 - training loss: 0.7730, validation loss: 0.8289
2024-05-25 04:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch177_loss0.828940823674202.pypots
2024-05-25 04:39:44 [INFO]: Epoch 178 - training loss: 0.7593, validation loss: 0.8247
2024-05-25 04:39:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch178_loss0.8247438818216324.pypots
2024-05-25 04:39:45 [INFO]: Epoch 179 - training loss: 0.7885, validation loss: 0.8271
2024-05-25 04:39:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch179_loss0.8270915746688843.pypots
2024-05-25 04:39:45 [INFO]: Epoch 180 - training loss: 0.7853, validation loss: 0.8249
2024-05-25 04:39:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch180_loss0.8248911798000336.pypots
2024-05-25 04:39:45 [INFO]: Epoch 181 - training loss: 0.7673, validation loss: 0.8237
2024-05-25 04:39:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch181_loss0.82370325922966.pypots
2024-05-25 04:39:45 [INFO]: Epoch 182 - training loss: 0.7750, validation loss: 0.8235
2024-05-25 04:39:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch182_loss0.8235282897949219.pypots
2024-05-25 04:39:45 [INFO]: Epoch 183 - training loss: 0.7768, validation loss: 0.8228
2024-05-25 04:39:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch183_loss0.8228272497653961.pypots
2024-05-25 04:39:46 [INFO]: Epoch 184 - training loss: 0.7921, validation loss: 0.8259
2024-05-25 04:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch184_loss0.825854629278183.pypots
2024-05-25 04:39:46 [INFO]: Epoch 185 - training loss: 0.8261, validation loss: 0.8220
2024-05-25 04:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch185_loss0.8219760656356812.pypots
2024-05-25 04:39:46 [INFO]: Epoch 186 - training loss: 0.7960, validation loss: 0.8213
2024-05-25 04:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch186_loss0.8213417381048203.pypots
2024-05-25 04:39:46 [INFO]: Epoch 187 - training loss: 0.7995, validation loss: 0.8228
2024-05-25 04:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch187_loss0.8228228241205215.pypots
2024-05-25 04:39:46 [INFO]: Epoch 188 - training loss: 0.7661, validation loss: 0.8215
2024-05-25 04:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch188_loss0.8214940130710602.pypots
2024-05-25 04:39:47 [INFO]: Epoch 189 - training loss: 0.7745, validation loss: 0.8226
2024-05-25 04:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch189_loss0.8226108998060226.pypots
2024-05-25 04:39:47 [INFO]: Epoch 190 - training loss: 0.7659, validation loss: 0.8194
2024-05-25 04:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch190_loss0.819438636302948.pypots
2024-05-25 04:39:47 [INFO]: Epoch 191 - training loss: 0.7726, validation loss: 0.8198
2024-05-25 04:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch191_loss0.8197809308767319.pypots
2024-05-25 04:39:47 [INFO]: Epoch 192 - training loss: 0.7639, validation loss: 0.8189
2024-05-25 04:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch192_loss0.8189024180173874.pypots
2024-05-25 04:39:47 [INFO]: Epoch 193 - training loss: 0.8138, validation loss: 0.8215
2024-05-25 04:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch193_loss0.8215179890394211.pypots
2024-05-25 04:39:48 [INFO]: Epoch 194 - training loss: 0.7696, validation loss: 0.8179
2024-05-25 04:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch194_loss0.8179204910993576.pypots
2024-05-25 04:39:48 [INFO]: Epoch 195 - training loss: 0.7907, validation loss: 0.8179
2024-05-25 04:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch195_loss0.8178786784410477.pypots
2024-05-25 04:39:48 [INFO]: Epoch 196 - training loss: 0.7745, validation loss: 0.8167
2024-05-25 04:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch196_loss0.81671541929245.pypots
2024-05-25 04:39:48 [INFO]: Epoch 197 - training loss: 0.7889, validation loss: 0.8220
2024-05-25 04:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch197_loss0.8220260590314865.pypots
2024-05-25 04:39:48 [INFO]: Epoch 198 - training loss: 0.7732, validation loss: 0.8202
2024-05-25 04:39:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch198_loss0.820163682103157.pypots
2024-05-25 04:39:49 [INFO]: Epoch 199 - training loss: 0.7780, validation loss: 0.8181
2024-05-25 04:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch199_loss0.8180589079856873.pypots
2024-05-25 04:39:49 [INFO]: Epoch 200 - training loss: 0.7745, validation loss: 0.8192
2024-05-25 04:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch200_loss0.8192436993122101.pypots
2024-05-25 04:39:49 [INFO]: Epoch 201 - training loss: 0.7827, validation loss: 0.8175
2024-05-25 04:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch201_loss0.8174572438001633.pypots
2024-05-25 04:39:49 [INFO]: Epoch 202 - training loss: 0.7802, validation loss: 0.8172
2024-05-25 04:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch202_loss0.8172164708375931.pypots
2024-05-25 04:39:49 [INFO]: Epoch 203 - training loss: 0.7627, validation loss: 0.8171
2024-05-25 04:39:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch203_loss0.8171086609363556.pypots
2024-05-25 04:39:50 [INFO]: Epoch 204 - training loss: 0.7958, validation loss: 0.8175
2024-05-25 04:39:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch204_loss0.8175345808267593.pypots
2024-05-25 04:39:50 [INFO]: Epoch 205 - training loss: 0.7793, validation loss: 0.8202
2024-05-25 04:39:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch205_loss0.8202438652515411.pypots
2024-05-25 04:39:50 [INFO]: Epoch 206 - training loss: 0.7930, validation loss: 0.8172
2024-05-25 04:39:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN_epoch206_loss0.8172494024038315.pypots
2024-05-25 04:39:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:39:50 [INFO]: Finished training. The best model is from epoch#196.
2024-05-25 04:39:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240525_T043907/MRNN.pypots
2024-05-25 04:39:50 [INFO]: MRNN on ETTm1: MAE=0.6481, MSE=1.1037
2024-05-25 04:39:50 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-25 04:39:50 [INFO]: Using the given device: cpu
2024-05-25 04:39:50 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 04:39:50 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-25 04:39:50 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-25 04:39:50 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 04:39:50 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-25 04:39:50 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-25 04:39:50 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 04:39:50 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-25 04:39:50 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-25 04:39:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 04:39:50 [INFO]: Using the given device: cuda:0
2024-05-25 04:39:50 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T043950
2024-05-25 04:39:50 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T043950/tensorboard
2024-05-25 04:39:50 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 04:39:51 [INFO]: Epoch 001 - training loss: 1.1321, validation loss: 0.2448
2024-05-25 04:39:51 [INFO]: Epoch 002 - training loss: 0.8036, validation loss: 0.1190
2024-05-25 04:39:52 [INFO]: Epoch 003 - training loss: 0.6896, validation loss: 0.1037
2024-05-25 04:39:52 [INFO]: Epoch 004 - training loss: 0.6469, validation loss: 0.0775
2024-05-25 04:39:53 [INFO]: Epoch 005 - training loss: 0.6220, validation loss: 0.0717
2024-05-25 04:39:53 [INFO]: Epoch 006 - training loss: 0.5963, validation loss: 0.0836
2024-05-25 04:39:54 [INFO]: Epoch 007 - training loss: 0.5810, validation loss: 0.0753
2024-05-25 04:39:54 [INFO]: Epoch 008 - training loss: 0.5645, validation loss: 0.0688
2024-05-25 04:39:55 [INFO]: Epoch 009 - training loss: 0.5579, validation loss: 0.0642
2024-05-25 04:39:55 [INFO]: Epoch 010 - training loss: 0.5562, validation loss: 0.0557
2024-05-25 04:39:56 [INFO]: Epoch 011 - training loss: 0.5529, validation loss: 0.0710
2024-05-25 04:39:56 [INFO]: Epoch 012 - training loss: 0.5420, validation loss: 0.0523
2024-05-25 04:39:57 [INFO]: Epoch 013 - training loss: 0.5211, validation loss: 0.0524
2024-05-25 04:39:57 [INFO]: Epoch 014 - training loss: 0.5133, validation loss: 0.0507
2024-05-25 04:39:58 [INFO]: Epoch 015 - training loss: 0.5170, validation loss: 0.0485
2024-05-25 04:39:58 [INFO]: Epoch 016 - training loss: 0.4749, validation loss: 0.0556
2024-05-25 04:39:59 [INFO]: Epoch 017 - training loss: 0.4920, validation loss: 0.0409
2024-05-25 04:39:59 [INFO]: Epoch 018 - training loss: 0.4632, validation loss: 0.0586
2024-05-25 04:40:00 [INFO]: Epoch 019 - training loss: 0.4542, validation loss: 0.0452
2024-05-25 04:40:00 [INFO]: Epoch 020 - training loss: 0.4370, validation loss: 0.0530
2024-05-25 04:40:01 [INFO]: Epoch 021 - training loss: 0.4627, validation loss: 0.0539
2024-05-25 04:40:01 [INFO]: Epoch 022 - training loss: 0.4438, validation loss: 0.0755
2024-05-25 04:40:02 [INFO]: Epoch 023 - training loss: 0.4521, validation loss: 0.0482
2024-05-25 04:40:02 [INFO]: Epoch 024 - training loss: 0.4313, validation loss: 0.0475
2024-05-25 04:40:03 [INFO]: Epoch 025 - training loss: 0.4099, validation loss: 0.0337
2024-05-25 04:40:03 [INFO]: Epoch 026 - training loss: 0.4146, validation loss: 0.0386
2024-05-25 04:40:04 [INFO]: Epoch 027 - training loss: 0.3962, validation loss: 0.0457
2024-05-25 04:40:04 [INFO]: Epoch 028 - training loss: 0.4032, validation loss: 0.0388
2024-05-25 04:40:05 [INFO]: Epoch 029 - training loss: 0.4013, validation loss: 0.0407
2024-05-25 04:40:05 [INFO]: Epoch 030 - training loss: 0.3921, validation loss: 0.0373
2024-05-25 04:40:06 [INFO]: Epoch 031 - training loss: 0.3895, validation loss: 0.0358
2024-05-25 04:40:06 [INFO]: Epoch 032 - training loss: 0.3833, validation loss: 0.0382
2024-05-25 04:40:07 [INFO]: Epoch 033 - training loss: 0.3756, validation loss: 0.0416
2024-05-25 04:40:07 [INFO]: Epoch 034 - training loss: 0.3829, validation loss: 0.0343
2024-05-25 04:40:08 [INFO]: Epoch 035 - training loss: 0.3746, validation loss: 0.0363
2024-05-25 04:40:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:40:08 [INFO]: Finished training. The best model is from epoch#25.
2024-05-25 04:40:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_ettm1/20240525_T043950/SAITS.pypots
2024-05-25 04:40:08 [INFO]: SAITS on ETTm1: MAE=0.1858, MSE=0.0631
2024-05-25 04:40:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-25 04:40:08 [INFO]: Using the given device: cuda:0
2024-05-25 04:40:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T044008
2024-05-25 04:40:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T044008/tensorboard
2024-05-25 04:40:08 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 04:40:08 [INFO]: Epoch 001 - training loss: 1.1535, validation loss: 0.2965
2024-05-25 04:40:08 [INFO]: Epoch 002 - training loss: 0.6581, validation loss: 0.1377
2024-05-25 04:40:09 [INFO]: Epoch 003 - training loss: 0.5365, validation loss: 0.1160
2024-05-25 04:40:09 [INFO]: Epoch 004 - training loss: 0.4767, validation loss: 0.0898
2024-05-25 04:40:09 [INFO]: Epoch 005 - training loss: 0.4406, validation loss: 0.0766
2024-05-25 04:40:09 [INFO]: Epoch 006 - training loss: 0.4202, validation loss: 0.0647
2024-05-25 04:40:09 [INFO]: Epoch 007 - training loss: 0.4037, validation loss: 0.0589
2024-05-25 04:40:10 [INFO]: Epoch 008 - training loss: 0.3841, validation loss: 0.0555
2024-05-25 04:40:10 [INFO]: Epoch 009 - training loss: 0.3763, validation loss: 0.0559
2024-05-25 04:40:10 [INFO]: Epoch 010 - training loss: 0.3650, validation loss: 0.0524
2024-05-25 04:40:10 [INFO]: Epoch 011 - training loss: 0.3525, validation loss: 0.0498
2024-05-25 04:40:10 [INFO]: Epoch 012 - training loss: 0.3491, validation loss: 0.0497
2024-05-25 04:40:11 [INFO]: Epoch 013 - training loss: 0.3389, validation loss: 0.0469
2024-05-25 04:40:11 [INFO]: Epoch 014 - training loss: 0.3351, validation loss: 0.0444
2024-05-25 04:40:11 [INFO]: Epoch 015 - training loss: 0.3279, validation loss: 0.0502
2024-05-25 04:40:11 [INFO]: Epoch 016 - training loss: 0.3251, validation loss: 0.0454
2024-05-25 04:40:11 [INFO]: Epoch 017 - training loss: 0.3210, validation loss: 0.0447
2024-05-25 04:40:12 [INFO]: Epoch 018 - training loss: 0.3237, validation loss: 0.0418
2024-05-25 04:40:12 [INFO]: Epoch 019 - training loss: 0.3084, validation loss: 0.0404
2024-05-25 04:40:12 [INFO]: Epoch 020 - training loss: 0.2994, validation loss: 0.0368
2024-05-25 04:40:12 [INFO]: Epoch 021 - training loss: 0.2942, validation loss: 0.0385
2024-05-25 04:40:12 [INFO]: Epoch 022 - training loss: 0.2991, validation loss: 0.0420
2024-05-25 04:40:13 [INFO]: Epoch 023 - training loss: 0.3040, validation loss: 0.0404
2024-05-25 04:40:13 [INFO]: Epoch 024 - training loss: 0.2950, validation loss: 0.0389
2024-05-25 04:40:13 [INFO]: Epoch 025 - training loss: 0.2846, validation loss: 0.0406
2024-05-25 04:40:13 [INFO]: Epoch 026 - training loss: 0.2878, validation loss: 0.0388
2024-05-25 04:40:13 [INFO]: Epoch 027 - training loss: 0.2868, validation loss: 0.0336
2024-05-25 04:40:14 [INFO]: Epoch 028 - training loss: 0.2731, validation loss: 0.0363
2024-05-25 04:40:14 [INFO]: Epoch 029 - training loss: 0.2768, validation loss: 0.0347
2024-05-25 04:40:14 [INFO]: Epoch 030 - training loss: 0.2740, validation loss: 0.0365
2024-05-25 04:40:14 [INFO]: Epoch 031 - training loss: 0.2683, validation loss: 0.0345
2024-05-25 04:40:14 [INFO]: Epoch 032 - training loss: 0.2664, validation loss: 0.0321
2024-05-25 04:40:14 [INFO]: Epoch 033 - training loss: 0.2650, validation loss: 0.0327
2024-05-25 04:40:15 [INFO]: Epoch 034 - training loss: 0.2633, validation loss: 0.0332
2024-05-25 04:40:15 [INFO]: Epoch 035 - training loss: 0.2579, validation loss: 0.0307
2024-05-25 04:40:15 [INFO]: Epoch 036 - training loss: 0.2600, validation loss: 0.0328
2024-05-25 04:40:15 [INFO]: Epoch 037 - training loss: 0.2564, validation loss: 0.0325
2024-05-25 04:40:15 [INFO]: Epoch 038 - training loss: 0.2535, validation loss: 0.0320
2024-05-25 04:40:16 [INFO]: Epoch 039 - training loss: 0.2504, validation loss: 0.0294
2024-05-25 04:40:16 [INFO]: Epoch 040 - training loss: 0.2521, validation loss: 0.0352
2024-05-25 04:40:16 [INFO]: Epoch 041 - training loss: 0.2575, validation loss: 0.0329
2024-05-25 04:40:16 [INFO]: Epoch 042 - training loss: 0.2572, validation loss: 0.0316
2024-05-25 04:40:16 [INFO]: Epoch 043 - training loss: 0.2427, validation loss: 0.0296
2024-05-25 04:40:17 [INFO]: Epoch 044 - training loss: 0.2439, validation loss: 0.0286
2024-05-25 04:40:17 [INFO]: Epoch 045 - training loss: 0.2497, validation loss: 0.0292
2024-05-25 04:40:17 [INFO]: Epoch 046 - training loss: 0.2424, validation loss: 0.0359
2024-05-25 04:40:17 [INFO]: Epoch 047 - training loss: 0.2491, validation loss: 0.0304
2024-05-25 04:40:17 [INFO]: Epoch 048 - training loss: 0.2428, validation loss: 0.0311
2024-05-25 04:40:18 [INFO]: Epoch 049 - training loss: 0.2423, validation loss: 0.0289
2024-05-25 04:40:18 [INFO]: Epoch 050 - training loss: 0.2323, validation loss: 0.0283
2024-05-25 04:40:18 [INFO]: Epoch 051 - training loss: 0.2305, validation loss: 0.0290
2024-05-25 04:40:18 [INFO]: Epoch 052 - training loss: 0.2308, validation loss: 0.0275
2024-05-25 04:40:18 [INFO]: Epoch 053 - training loss: 0.2315, validation loss: 0.0292
2024-05-25 04:40:19 [INFO]: Epoch 054 - training loss: 0.2307, validation loss: 0.0281
2024-05-25 04:40:19 [INFO]: Epoch 055 - training loss: 0.2255, validation loss: 0.0281
2024-05-25 04:40:19 [INFO]: Epoch 056 - training loss: 0.2311, validation loss: 0.0272
2024-05-25 04:40:19 [INFO]: Epoch 057 - training loss: 0.2278, validation loss: 0.0288
2024-05-25 04:40:19 [INFO]: Epoch 058 - training loss: 0.2277, validation loss: 0.0271
2024-05-25 04:40:20 [INFO]: Epoch 059 - training loss: 0.2250, validation loss: 0.0265
2024-05-25 04:40:20 [INFO]: Epoch 060 - training loss: 0.2197, validation loss: 0.0250
2024-05-25 04:40:20 [INFO]: Epoch 061 - training loss: 0.2177, validation loss: 0.0274
2024-05-25 04:40:20 [INFO]: Epoch 062 - training loss: 0.2203, validation loss: 0.0268
2024-05-25 04:40:20 [INFO]: Epoch 063 - training loss: 0.2234, validation loss: 0.0277
2024-05-25 04:40:21 [INFO]: Epoch 064 - training loss: 0.2262, validation loss: 0.0296
2024-05-25 04:40:21 [INFO]: Epoch 065 - training loss: 0.2229, validation loss: 0.0277
2024-05-25 04:40:21 [INFO]: Epoch 066 - training loss: 0.2150, validation loss: 0.0305
2024-05-25 04:40:21 [INFO]: Epoch 067 - training loss: 0.2199, validation loss: 0.0311
2024-05-25 04:40:21 [INFO]: Epoch 068 - training loss: 0.2268, validation loss: 0.0253
2024-05-25 04:40:22 [INFO]: Epoch 069 - training loss: 0.2111, validation loss: 0.0259
2024-05-25 04:40:22 [INFO]: Epoch 070 - training loss: 0.2084, validation loss: 0.0260
2024-05-25 04:40:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:40:22 [INFO]: Finished training. The best model is from epoch#60.
2024-05-25 04:40:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_ettm1/20240525_T044008/Transformer.pypots
2024-05-25 04:40:22 [INFO]: Transformer on ETTm1: MAE=0.1321, MSE=0.0361
2024-05-25 04:40:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-25 04:40:22 [INFO]: Using the given device: cuda:0
2024-05-25 04:40:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T044022
2024-05-25 04:40:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T044022/tensorboard
2024-05-25 04:40:22 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 04:40:22 [INFO]: Epoch 001 - training loss: 0.1370, validation loss: 0.0537
2024-05-25 04:40:22 [INFO]: Epoch 002 - training loss: 0.0608, validation loss: 0.0440
2024-05-25 04:40:23 [INFO]: Epoch 003 - training loss: 0.0489, validation loss: 0.0360
2024-05-25 04:40:23 [INFO]: Epoch 004 - training loss: 0.0421, validation loss: 0.0348
2024-05-25 04:40:23 [INFO]: Epoch 005 - training loss: 0.0393, validation loss: 0.0308
2024-05-25 04:40:23 [INFO]: Epoch 006 - training loss: 0.0447, validation loss: 0.0322
2024-05-25 04:40:23 [INFO]: Epoch 007 - training loss: 0.0514, validation loss: 0.0351
2024-05-25 04:40:24 [INFO]: Epoch 008 - training loss: 0.0360, validation loss: 0.0277
2024-05-25 04:40:24 [INFO]: Epoch 009 - training loss: 0.0313, validation loss: 0.0283
2024-05-25 04:40:24 [INFO]: Epoch 010 - training loss: 0.0285, validation loss: 0.0255
2024-05-25 04:40:24 [INFO]: Epoch 011 - training loss: 0.0282, validation loss: 0.0242
2024-05-25 04:40:24 [INFO]: Epoch 012 - training loss: 0.0265, validation loss: 0.0234
2024-05-25 04:40:25 [INFO]: Epoch 013 - training loss: 0.0252, validation loss: 0.0228
2024-05-25 04:40:25 [INFO]: Epoch 014 - training loss: 0.0263, validation loss: 0.0235
2024-05-25 04:40:25 [INFO]: Epoch 015 - training loss: 0.0257, validation loss: 0.0228
2024-05-25 04:40:25 [INFO]: Epoch 016 - training loss: 0.0258, validation loss: 0.0231
2024-05-25 04:40:25 [INFO]: Epoch 017 - training loss: 0.0251, validation loss: 0.0226
2024-05-25 04:40:26 [INFO]: Epoch 018 - training loss: 0.0244, validation loss: 0.0228
2024-05-25 04:40:26 [INFO]: Epoch 019 - training loss: 0.0222, validation loss: 0.0230
2024-05-25 04:40:26 [INFO]: Epoch 020 - training loss: 0.0236, validation loss: 0.0227
2024-05-25 04:40:26 [INFO]: Epoch 021 - training loss: 0.0239, validation loss: 0.0234
2024-05-25 04:40:26 [INFO]: Epoch 022 - training loss: 0.0293, validation loss: 0.0327
2024-05-25 04:40:26 [INFO]: Epoch 023 - training loss: 0.0561, validation loss: 0.0283
2024-05-25 04:40:27 [INFO]: Epoch 024 - training loss: 0.0320, validation loss: 0.0252
2024-05-25 04:40:27 [INFO]: Epoch 025 - training loss: 0.0260, validation loss: 0.0230
2024-05-25 04:40:27 [INFO]: Epoch 026 - training loss: 0.0243, validation loss: 0.0228
2024-05-25 04:40:27 [INFO]: Epoch 027 - training loss: 0.0222, validation loss: 0.0229
2024-05-25 04:40:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:40:27 [INFO]: Finished training. The best model is from epoch#17.
2024-05-25 04:40:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240525_T044022/TimesNet.pypots
2024-05-25 04:40:27 [INFO]: TimesNet on ETTm1: MAE=0.1030, MSE=0.0232
2024-05-25 04:40:27 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-25 04:40:27 [INFO]: Using the given device: cuda:0
2024-05-25 04:40:27 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027
2024-05-25 04:40:27 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/tensorboard
2024-05-25 04:40:27 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 04:40:29 [INFO]: Epoch 001 - training loss: 0.6736, validation loss: 0.4815
2024-05-25 04:40:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch1_loss0.4814635440707207.pypots
2024-05-25 04:40:31 [INFO]: Epoch 002 - training loss: 0.4396, validation loss: 0.3765
2024-05-25 04:40:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch2_loss0.37654976546764374.pypots
2024-05-25 04:40:34 [INFO]: Epoch 003 - training loss: 0.4345, validation loss: 0.3483
2024-05-25 04:40:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch3_loss0.34832559525966644.pypots
2024-05-25 04:40:36 [INFO]: Epoch 004 - training loss: 0.3493, validation loss: 0.3155
2024-05-25 04:40:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch4_loss0.3154735341668129.pypots
2024-05-25 04:40:38 [INFO]: Epoch 005 - training loss: 0.3310, validation loss: 0.3178
2024-05-25 04:40:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch5_loss0.3178325593471527.pypots
2024-05-25 04:40:40 [INFO]: Epoch 006 - training loss: 0.3380, validation loss: 0.2921
2024-05-25 04:40:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch6_loss0.29213374853134155.pypots
2024-05-25 04:40:42 [INFO]: Epoch 007 - training loss: 0.2619, validation loss: 0.2742
2024-05-25 04:40:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch7_loss0.27418214082717896.pypots
2024-05-25 04:40:44 [INFO]: Epoch 008 - training loss: 0.2718, validation loss: 0.2641
2024-05-25 04:40:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch8_loss0.2641271576285362.pypots
2024-05-25 04:40:46 [INFO]: Epoch 009 - training loss: 0.2514, validation loss: 0.2550
2024-05-25 04:40:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch9_loss0.25499144941568375.pypots
2024-05-25 04:40:48 [INFO]: Epoch 010 - training loss: 0.2571, validation loss: 0.2553
2024-05-25 04:40:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch10_loss0.2553311139345169.pypots
2024-05-25 04:40:50 [INFO]: Epoch 011 - training loss: 0.2660, validation loss: 0.2615
2024-05-25 04:40:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch11_loss0.26153259724378586.pypots
2024-05-25 04:40:52 [INFO]: Epoch 012 - training loss: 0.2361, validation loss: 0.2394
2024-05-25 04:40:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch12_loss0.23942037299275398.pypots
2024-05-25 04:40:54 [INFO]: Epoch 013 - training loss: 0.2287, validation loss: 0.2346
2024-05-25 04:40:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch13_loss0.2346487082540989.pypots
2024-05-25 04:40:56 [INFO]: Epoch 014 - training loss: 0.2205, validation loss: 0.2331
2024-05-25 04:40:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch14_loss0.2330671027302742.pypots
2024-05-25 04:40:58 [INFO]: Epoch 015 - training loss: 0.2360, validation loss: 0.2208
2024-05-25 04:40:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch15_loss0.22079212963581085.pypots
2024-05-25 04:41:00 [INFO]: Epoch 016 - training loss: 0.2392, validation loss: 0.2202
2024-05-25 04:41:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch16_loss0.22015801444649696.pypots
2024-05-25 04:41:02 [INFO]: Epoch 017 - training loss: 0.2375, validation loss: 0.2384
2024-05-25 04:41:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch17_loss0.23835007473826408.pypots
2024-05-25 04:41:04 [INFO]: Epoch 018 - training loss: 0.2108, validation loss: 0.2130
2024-05-25 04:41:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch18_loss0.21298407763242722.pypots
2024-05-25 04:41:06 [INFO]: Epoch 019 - training loss: 0.2006, validation loss: 0.2066
2024-05-25 04:41:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch19_loss0.20662140846252441.pypots
2024-05-25 04:41:08 [INFO]: Epoch 020 - training loss: 0.2283, validation loss: 0.2088
2024-05-25 04:41:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch20_loss0.20879587531089783.pypots
2024-05-25 04:41:11 [INFO]: Epoch 021 - training loss: 0.1979, validation loss: 0.1995
2024-05-25 04:41:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch21_loss0.19954640418291092.pypots
2024-05-25 04:41:13 [INFO]: Epoch 022 - training loss: 0.1910, validation loss: 0.1959
2024-05-25 04:41:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch22_loss0.19589824229478836.pypots
2024-05-25 04:41:15 [INFO]: Epoch 023 - training loss: 0.1763, validation loss: 0.1860
2024-05-25 04:41:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch23_loss0.18596621602773666.pypots
2024-05-25 04:41:17 [INFO]: Epoch 024 - training loss: 0.1870, validation loss: 0.1793
2024-05-25 04:41:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch24_loss0.1793445274233818.pypots
2024-05-25 04:41:19 [INFO]: Epoch 025 - training loss: 0.1979, validation loss: 0.1833
2024-05-25 04:41:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch25_loss0.1832979954779148.pypots
2024-05-25 04:41:21 [INFO]: Epoch 026 - training loss: 0.1833, validation loss: 0.1776
2024-05-25 04:41:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch26_loss0.17763645574450493.pypots
2024-05-25 04:41:23 [INFO]: Epoch 027 - training loss: 0.1814, validation loss: 0.1726
2024-05-25 04:41:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch27_loss0.1725683994591236.pypots
2024-05-25 04:41:25 [INFO]: Epoch 028 - training loss: 0.1596, validation loss: 0.1659
2024-05-25 04:41:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch28_loss0.16588810086250305.pypots
2024-05-25 04:41:27 [INFO]: Epoch 029 - training loss: 0.1557, validation loss: 0.1686
2024-05-25 04:41:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch29_loss0.1686413176357746.pypots
2024-05-25 04:41:29 [INFO]: Epoch 030 - training loss: 0.1884, validation loss: 0.1965
2024-05-25 04:41:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch30_loss0.19650032371282578.pypots
2024-05-25 04:41:31 [INFO]: Epoch 031 - training loss: 0.2535, validation loss: 0.2183
2024-05-25 04:41:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch31_loss0.21831797808408737.pypots
2024-05-25 04:41:33 [INFO]: Epoch 032 - training loss: 0.2197, validation loss: 0.1892
2024-05-25 04:41:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch32_loss0.1892187036573887.pypots
2024-05-25 04:41:35 [INFO]: Epoch 033 - training loss: 0.2040, validation loss: 0.1853
2024-05-25 04:41:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch33_loss0.18527235463261604.pypots
2024-05-25 04:41:37 [INFO]: Epoch 034 - training loss: 0.2068, validation loss: 0.1920
2024-05-25 04:41:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch34_loss0.1920136995613575.pypots
2024-05-25 04:41:39 [INFO]: Epoch 035 - training loss: 0.2144, validation loss: 0.1805
2024-05-25 04:41:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch35_loss0.18045565858483315.pypots
2024-05-25 04:41:41 [INFO]: Epoch 036 - training loss: 0.2111, validation loss: 0.1765
2024-05-25 04:41:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch36_loss0.17649805173277855.pypots
2024-05-25 04:41:43 [INFO]: Epoch 037 - training loss: 0.1831, validation loss: 0.1697
2024-05-25 04:41:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch37_loss0.16967886686325073.pypots
2024-05-25 04:41:45 [INFO]: Epoch 038 - training loss: 0.1939, validation loss: 0.1781
2024-05-25 04:41:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI_epoch38_loss0.1780504398047924.pypots
2024-05-25 04:41:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:41:45 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 04:41:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240525_T044027/CSDI.pypots
2024-05-25 04:42:01 [INFO]: CSDI on ETTm1: MAE=0.2082, MSE=0.0972
2024-05-25 04:42:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-25 04:42:01 [INFO]: Using the given device: cuda:0
2024-05-25 04:42:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T044201
2024-05-25 04:42:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T044201/tensorboard
2024-05-25 04:42:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 04:42:02 [INFO]: Epoch 001 - training loss: 23047.7960, validation loss: 0.9499
2024-05-25 04:42:02 [INFO]: Epoch 002 - training loss: 20802.8687, validation loss: 0.9444
2024-05-25 04:42:02 [INFO]: Epoch 003 - training loss: 18956.6656, validation loss: 0.9313
2024-05-25 04:42:02 [INFO]: Epoch 004 - training loss: 17018.7313, validation loss: 0.9093
2024-05-25 04:42:02 [INFO]: Epoch 005 - training loss: 15147.5364, validation loss: 0.8529
2024-05-25 04:42:02 [INFO]: Epoch 006 - training loss: 13867.8372, validation loss: 0.7495
2024-05-25 04:42:02 [INFO]: Epoch 007 - training loss: 12831.4230, validation loss: 0.6390
2024-05-25 04:42:02 [INFO]: Epoch 008 - training loss: 11959.3658, validation loss: 0.5494
2024-05-25 04:42:03 [INFO]: Epoch 009 - training loss: 11384.3457, validation loss: 0.4992
2024-05-25 04:42:03 [INFO]: Epoch 010 - training loss: 10986.8497, validation loss: 0.4751
2024-05-25 04:42:03 [INFO]: Epoch 011 - training loss: 10706.0281, validation loss: 0.4647
2024-05-25 04:42:03 [INFO]: Epoch 012 - training loss: 10427.7465, validation loss: 0.4536
2024-05-25 04:42:03 [INFO]: Epoch 013 - training loss: 10310.9587, validation loss: 0.4384
2024-05-25 04:42:03 [INFO]: Epoch 014 - training loss: 10158.4952, validation loss: 0.4297
2024-05-25 04:42:03 [INFO]: Epoch 015 - training loss: 10066.1097, validation loss: 0.4048
2024-05-25 04:42:04 [INFO]: Epoch 016 - training loss: 9947.7618, validation loss: 0.3933
2024-05-25 04:42:04 [INFO]: Epoch 017 - training loss: 9898.9096, validation loss: 0.3794
2024-05-25 04:42:04 [INFO]: Epoch 018 - training loss: 9835.7416, validation loss: 0.3651
2024-05-25 04:42:04 [INFO]: Epoch 019 - training loss: 9814.3193, validation loss: 0.3564
2024-05-25 04:42:04 [INFO]: Epoch 020 - training loss: 9744.1247, validation loss: 0.3427
2024-05-25 04:42:04 [INFO]: Epoch 021 - training loss: 9690.2081, validation loss: 0.3303
2024-05-25 04:42:04 [INFO]: Epoch 022 - training loss: 9676.8650, validation loss: 0.3241
2024-05-25 04:42:05 [INFO]: Epoch 023 - training loss: 9635.3476, validation loss: 0.3097
2024-05-25 04:42:05 [INFO]: Epoch 024 - training loss: 9608.6180, validation loss: 0.2919
2024-05-25 04:42:05 [INFO]: Epoch 025 - training loss: 9595.1721, validation loss: 0.2864
2024-05-25 04:42:05 [INFO]: Epoch 026 - training loss: 9570.6951, validation loss: 0.2804
2024-05-25 04:42:05 [INFO]: Epoch 027 - training loss: 9562.8104, validation loss: 0.2696
2024-05-25 04:42:05 [INFO]: Epoch 028 - training loss: 9541.0176, validation loss: 0.2545
2024-05-25 04:42:05 [INFO]: Epoch 029 - training loss: 9515.0161, validation loss: 0.2477
2024-05-25 04:42:06 [INFO]: Epoch 030 - training loss: 9516.6726, validation loss: 0.2453
2024-05-25 04:42:06 [INFO]: Epoch 031 - training loss: 9498.4551, validation loss: 0.2356
2024-05-25 04:42:06 [INFO]: Epoch 032 - training loss: 9482.2665, validation loss: 0.2245
2024-05-25 04:42:06 [INFO]: Epoch 033 - training loss: 9484.3408, validation loss: 0.2164
2024-05-25 04:42:06 [INFO]: Epoch 034 - training loss: 9480.3209, validation loss: 0.2091
2024-05-25 04:42:06 [INFO]: Epoch 035 - training loss: 9458.4019, validation loss: 0.2008
2024-05-25 04:42:06 [INFO]: Epoch 036 - training loss: 9449.1742, validation loss: 0.1961
2024-05-25 04:42:07 [INFO]: Epoch 037 - training loss: 9441.9289, validation loss: 0.1950
2024-05-25 04:42:07 [INFO]: Epoch 038 - training loss: 9433.2511, validation loss: 0.1882
2024-05-25 04:42:07 [INFO]: Epoch 039 - training loss: 9426.9001, validation loss: 0.1845
2024-05-25 04:42:07 [INFO]: Epoch 040 - training loss: 9431.6971, validation loss: 0.1786
2024-05-25 04:42:07 [INFO]: Epoch 041 - training loss: 9417.4702, validation loss: 0.1739
2024-05-25 04:42:07 [INFO]: Epoch 042 - training loss: 9419.2903, validation loss: 0.1704
2024-05-25 04:42:07 [INFO]: Epoch 043 - training loss: 9407.6302, validation loss: 0.1684
2024-05-25 04:42:08 [INFO]: Epoch 044 - training loss: 9402.3401, validation loss: 0.1650
2024-05-25 04:42:08 [INFO]: Epoch 045 - training loss: 9398.0447, validation loss: 0.1628
2024-05-25 04:42:08 [INFO]: Epoch 046 - training loss: 9398.8893, validation loss: 0.1585
2024-05-25 04:42:08 [INFO]: Epoch 047 - training loss: 9400.0176, validation loss: 0.1592
2024-05-25 04:42:08 [INFO]: Epoch 048 - training loss: 9387.2003, validation loss: 0.1623
2024-05-25 04:42:08 [INFO]: Epoch 049 - training loss: 9389.7880, validation loss: 0.1568
2024-05-25 04:42:08 [INFO]: Epoch 050 - training loss: 9381.3429, validation loss: 0.1515
2024-05-25 04:42:09 [INFO]: Epoch 051 - training loss: 9378.5859, validation loss: 0.1495
2024-05-25 04:42:09 [INFO]: Epoch 052 - training loss: 9379.6381, validation loss: 0.1479
2024-05-25 04:42:09 [INFO]: Epoch 053 - training loss: 9377.3369, validation loss: 0.1441
2024-05-25 04:42:09 [INFO]: Epoch 054 - training loss: 9372.5427, validation loss: 0.1430
2024-05-25 04:42:09 [INFO]: Epoch 055 - training loss: 9371.8879, validation loss: 0.1422
2024-05-25 04:42:09 [INFO]: Epoch 056 - training loss: 9366.8336, validation loss: 0.1423
2024-05-25 04:42:09 [INFO]: Epoch 057 - training loss: 9379.1996, validation loss: 0.1384
2024-05-25 04:42:10 [INFO]: Epoch 058 - training loss: 9364.9333, validation loss: 0.1353
2024-05-25 04:42:10 [INFO]: Epoch 059 - training loss: 9360.9505, validation loss: 0.1351
2024-05-25 04:42:10 [INFO]: Epoch 060 - training loss: 9363.3707, validation loss: 0.1351
2024-05-25 04:42:10 [INFO]: Epoch 061 - training loss: 9356.2851, validation loss: 0.1310
2024-05-25 04:42:10 [INFO]: Epoch 062 - training loss: 9355.4227, validation loss: 0.1296
2024-05-25 04:42:10 [INFO]: Epoch 063 - training loss: 9353.0224, validation loss: 0.1297
2024-05-25 04:42:11 [INFO]: Epoch 064 - training loss: 9356.2875, validation loss: 0.1272
2024-05-25 04:42:11 [INFO]: Epoch 065 - training loss: 9350.8682, validation loss: 0.1252
2024-05-25 04:42:11 [INFO]: Epoch 066 - training loss: 9352.8859, validation loss: 0.1254
2024-05-25 04:42:11 [INFO]: Epoch 067 - training loss: 9348.9465, validation loss: 0.1238
2024-05-25 04:42:11 [INFO]: Epoch 068 - training loss: 9346.7758, validation loss: 0.1226
2024-05-25 04:42:11 [INFO]: Epoch 069 - training loss: 9345.6457, validation loss: 0.1179
2024-05-25 04:42:11 [INFO]: Epoch 070 - training loss: 9344.9248, validation loss: 0.1189
2024-05-25 04:42:12 [INFO]: Epoch 071 - training loss: 9349.8290, validation loss: 0.1188
2024-05-25 04:42:12 [INFO]: Epoch 072 - training loss: 9342.5132, validation loss: 0.1165
2024-05-25 04:42:12 [INFO]: Epoch 073 - training loss: 9343.0087, validation loss: 0.1171
2024-05-25 04:42:12 [INFO]: Epoch 074 - training loss: 9340.6788, validation loss: 0.1172
2024-05-25 04:42:12 [INFO]: Epoch 075 - training loss: 9340.4722, validation loss: 0.1140
2024-05-25 04:42:12 [INFO]: Epoch 076 - training loss: 9337.0632, validation loss: 0.1139
2024-05-25 04:42:12 [INFO]: Epoch 077 - training loss: 9342.1517, validation loss: 0.1131
2024-05-25 04:42:13 [INFO]: Epoch 078 - training loss: 9336.9702, validation loss: 0.1121
2024-05-25 04:42:13 [INFO]: Epoch 079 - training loss: 9336.2634, validation loss: 0.1125
2024-05-25 04:42:13 [INFO]: Epoch 080 - training loss: 9333.3482, validation loss: 0.1097
2024-05-25 04:42:13 [INFO]: Epoch 081 - training loss: 9334.0613, validation loss: 0.1096
2024-05-25 04:42:13 [INFO]: Epoch 082 - training loss: 9333.9943, validation loss: 0.1086
2024-05-25 04:42:13 [INFO]: Epoch 083 - training loss: 9334.8188, validation loss: 0.1072
2024-05-25 04:42:13 [INFO]: Epoch 084 - training loss: 9337.4930, validation loss: 0.1119
2024-05-25 04:42:14 [INFO]: Epoch 085 - training loss: 9331.5966, validation loss: 0.1069
2024-05-25 04:42:14 [INFO]: Epoch 086 - training loss: 9331.4642, validation loss: 0.1089
2024-05-25 04:42:14 [INFO]: Epoch 087 - training loss: 9331.0942, validation loss: 0.1079
2024-05-25 04:42:14 [INFO]: Epoch 088 - training loss: 9329.3517, validation loss: 0.1063
2024-05-25 04:42:14 [INFO]: Epoch 089 - training loss: 9328.3952, validation loss: 0.1057
2024-05-25 04:42:14 [INFO]: Epoch 090 - training loss: 9327.0015, validation loss: 0.1054
2024-05-25 04:42:14 [INFO]: Epoch 091 - training loss: 9327.4442, validation loss: 0.1045
2024-05-25 04:42:15 [INFO]: Epoch 092 - training loss: 9325.8811, validation loss: 0.1040
2024-05-25 04:42:15 [INFO]: Epoch 093 - training loss: 9328.3662, validation loss: 0.1021
2024-05-25 04:42:15 [INFO]: Epoch 094 - training loss: 9326.3844, validation loss: 0.1028
2024-05-25 04:42:15 [INFO]: Epoch 095 - training loss: 9329.1194, validation loss: 0.1021
2024-05-25 04:42:15 [INFO]: Epoch 096 - training loss: 9323.9796, validation loss: 0.1005
2024-05-25 04:42:15 [INFO]: Epoch 097 - training loss: 9324.6047, validation loss: 0.1009
2024-05-25 04:42:15 [INFO]: Epoch 098 - training loss: 9323.4343, validation loss: 0.0999
2024-05-25 04:42:16 [INFO]: Epoch 099 - training loss: 9323.0457, validation loss: 0.0993
2024-05-25 04:42:16 [INFO]: Epoch 100 - training loss: 9322.1416, validation loss: 0.1011
2024-05-25 04:42:16 [INFO]: Epoch 101 - training loss: 9323.0673, validation loss: 0.0993
2024-05-25 04:42:16 [INFO]: Epoch 102 - training loss: 9323.2304, validation loss: 0.0993
2024-05-25 04:42:16 [INFO]: Epoch 103 - training loss: 9320.6401, validation loss: 0.0968
2024-05-25 04:42:16 [INFO]: Epoch 104 - training loss: 9324.1884, validation loss: 0.0977
2024-05-25 04:42:16 [INFO]: Epoch 105 - training loss: 9322.3538, validation loss: 0.0959
2024-05-25 04:42:17 [INFO]: Epoch 106 - training loss: 9321.5320, validation loss: 0.0968
2024-05-25 04:42:17 [INFO]: Epoch 107 - training loss: 9320.4991, validation loss: 0.0952
2024-05-25 04:42:17 [INFO]: Epoch 108 - training loss: 9321.6027, validation loss: 0.0944
2024-05-25 04:42:17 [INFO]: Epoch 109 - training loss: 9322.9640, validation loss: 0.0944
2024-05-25 04:42:17 [INFO]: Epoch 110 - training loss: 9318.1475, validation loss: 0.0943
2024-05-25 04:42:17 [INFO]: Epoch 111 - training loss: 9322.4623, validation loss: 0.0935
2024-05-25 04:42:17 [INFO]: Epoch 112 - training loss: 9318.4051, validation loss: 0.0925
2024-05-25 04:42:18 [INFO]: Epoch 113 - training loss: 9318.6660, validation loss: 0.0924
2024-05-25 04:42:18 [INFO]: Epoch 114 - training loss: 9317.0474, validation loss: 0.0932
2024-05-25 04:42:18 [INFO]: Epoch 115 - training loss: 9317.7218, validation loss: 0.0905
2024-05-25 04:42:18 [INFO]: Epoch 116 - training loss: 9316.5691, validation loss: 0.0921
2024-05-25 04:42:18 [INFO]: Epoch 117 - training loss: 9316.7448, validation loss: 0.0905
2024-05-25 04:42:18 [INFO]: Epoch 118 - training loss: 9320.5321, validation loss: 0.0938
2024-05-25 04:42:19 [INFO]: Epoch 119 - training loss: 9316.8839, validation loss: 0.0923
2024-05-25 04:42:19 [INFO]: Epoch 120 - training loss: 9317.8552, validation loss: 0.0886
2024-05-25 04:42:19 [INFO]: Epoch 121 - training loss: 9319.3508, validation loss: 0.0888
2024-05-25 04:42:19 [INFO]: Epoch 122 - training loss: 9314.9231, validation loss: 0.0886
2024-05-25 04:42:19 [INFO]: Epoch 123 - training loss: 9316.5014, validation loss: 0.0869
2024-05-25 04:42:19 [INFO]: Epoch 124 - training loss: 9314.3932, validation loss: 0.0890
2024-05-25 04:42:19 [INFO]: Epoch 125 - training loss: 9314.5302, validation loss: 0.0881
2024-05-25 04:42:20 [INFO]: Epoch 126 - training loss: 9316.4744, validation loss: 0.0869
2024-05-25 04:42:20 [INFO]: Epoch 127 - training loss: 9314.8708, validation loss: 0.0906
2024-05-25 04:42:20 [INFO]: Epoch 128 - training loss: 9313.7595, validation loss: 0.0864
2024-05-25 04:42:20 [INFO]: Epoch 129 - training loss: 9315.3830, validation loss: 0.0857
2024-05-25 04:42:20 [INFO]: Epoch 130 - training loss: 9314.6650, validation loss: 0.0857
2024-05-25 04:42:20 [INFO]: Epoch 131 - training loss: 9313.9910, validation loss: 0.0854
2024-05-25 04:42:20 [INFO]: Epoch 132 - training loss: 9313.0590, validation loss: 0.0846
2024-05-25 04:42:21 [INFO]: Epoch 133 - training loss: 9313.5834, validation loss: 0.0849
2024-05-25 04:42:21 [INFO]: Epoch 134 - training loss: 9313.0680, validation loss: 0.0845
2024-05-25 04:42:21 [INFO]: Epoch 135 - training loss: 9313.6002, validation loss: 0.0855
2024-05-25 04:42:21 [INFO]: Epoch 136 - training loss: 9313.1494, validation loss: 0.0848
2024-05-25 04:42:21 [INFO]: Epoch 137 - training loss: 9314.2902, validation loss: 0.0841
2024-05-25 04:42:21 [INFO]: Epoch 138 - training loss: 9314.0944, validation loss: 0.0832
2024-05-25 04:42:21 [INFO]: Epoch 139 - training loss: 9313.5421, validation loss: 0.0833
2024-05-25 04:42:22 [INFO]: Epoch 140 - training loss: 9312.6798, validation loss: 0.0838
2024-05-25 04:42:22 [INFO]: Epoch 141 - training loss: 9312.4307, validation loss: 0.0845
2024-05-25 04:42:22 [INFO]: Epoch 142 - training loss: 9311.8664, validation loss: 0.0809
2024-05-25 04:42:22 [INFO]: Epoch 143 - training loss: 9311.3693, validation loss: 0.0826
2024-05-25 04:42:22 [INFO]: Epoch 144 - training loss: 9310.7343, validation loss: 0.0832
2024-05-25 04:42:22 [INFO]: Epoch 145 - training loss: 9310.0986, validation loss: 0.0826
2024-05-25 04:42:22 [INFO]: Epoch 146 - training loss: 9310.0224, validation loss: 0.0822
2024-05-25 04:42:23 [INFO]: Epoch 147 - training loss: 9309.3953, validation loss: 0.0825
2024-05-25 04:42:23 [INFO]: Epoch 148 - training loss: 9310.2768, validation loss: 0.0820
2024-05-25 04:42:23 [INFO]: Epoch 149 - training loss: 9309.9823, validation loss: 0.0811
2024-05-25 04:42:23 [INFO]: Epoch 150 - training loss: 9310.8286, validation loss: 0.0813
2024-05-25 04:42:23 [INFO]: Epoch 151 - training loss: 9310.0402, validation loss: 0.0803
2024-05-25 04:42:23 [INFO]: Epoch 152 - training loss: 9311.2441, validation loss: 0.0809
2024-05-25 04:42:23 [INFO]: Epoch 153 - training loss: 9310.5427, validation loss: 0.0798
2024-05-25 04:42:24 [INFO]: Epoch 154 - training loss: 9309.8061, validation loss: 0.0805
2024-05-25 04:42:24 [INFO]: Epoch 155 - training loss: 9310.7081, validation loss: 0.0779
2024-05-25 04:42:24 [INFO]: Epoch 156 - training loss: 9309.1516, validation loss: 0.0803
2024-05-25 04:42:24 [INFO]: Epoch 157 - training loss: 9310.8712, validation loss: 0.0779
2024-05-25 04:42:24 [INFO]: Epoch 158 - training loss: 9308.7505, validation loss: 0.0798
2024-05-25 04:42:24 [INFO]: Epoch 159 - training loss: 9308.5663, validation loss: 0.0786
2024-05-25 04:42:24 [INFO]: Epoch 160 - training loss: 9307.1520, validation loss: 0.0777
2024-05-25 04:42:25 [INFO]: Epoch 161 - training loss: 9309.3114, validation loss: 0.0794
2024-05-25 04:42:25 [INFO]: Epoch 162 - training loss: 9307.6564, validation loss: 0.0796
2024-05-25 04:42:25 [INFO]: Epoch 163 - training loss: 9311.2020, validation loss: 0.0779
2024-05-25 04:42:25 [INFO]: Epoch 164 - training loss: 9308.4088, validation loss: 0.0782
2024-05-25 04:42:25 [INFO]: Epoch 165 - training loss: 9307.7612, validation loss: 0.0766
2024-05-25 04:42:25 [INFO]: Epoch 166 - training loss: 9307.0794, validation loss: 0.0777
2024-05-25 04:42:25 [INFO]: Epoch 167 - training loss: 9308.6452, validation loss: 0.0789
2024-05-25 04:42:26 [INFO]: Epoch 168 - training loss: 9307.7247, validation loss: 0.0787
2024-05-25 04:42:26 [INFO]: Epoch 169 - training loss: 9308.5451, validation loss: 0.0807
2024-05-25 04:42:26 [INFO]: Epoch 170 - training loss: 9307.7399, validation loss: 0.0778
2024-05-25 04:42:26 [INFO]: Epoch 171 - training loss: 9306.3734, validation loss: 0.0764
2024-05-25 04:42:26 [INFO]: Epoch 172 - training loss: 9306.9260, validation loss: 0.0769
2024-05-25 04:42:26 [INFO]: Epoch 173 - training loss: 9307.2035, validation loss: 0.0779
2024-05-25 04:42:26 [INFO]: Epoch 174 - training loss: 9305.9861, validation loss: 0.0757
2024-05-25 04:42:27 [INFO]: Epoch 175 - training loss: 9306.6854, validation loss: 0.0770
2024-05-25 04:42:27 [INFO]: Epoch 176 - training loss: 9308.0083, validation loss: 0.0763
2024-05-25 04:42:27 [INFO]: Epoch 177 - training loss: 9308.3003, validation loss: 0.0753
2024-05-25 04:42:27 [INFO]: Epoch 178 - training loss: 9307.3698, validation loss: 0.0767
2024-05-25 04:42:27 [INFO]: Epoch 179 - training loss: 9307.0311, validation loss: 0.0744
2024-05-25 04:42:27 [INFO]: Epoch 180 - training loss: 9306.2776, validation loss: 0.0736
2024-05-25 04:42:27 [INFO]: Epoch 181 - training loss: 9306.6676, validation loss: 0.0736
2024-05-25 04:42:28 [INFO]: Epoch 182 - training loss: 9307.5349, validation loss: 0.0738
2024-05-25 04:42:28 [INFO]: Epoch 183 - training loss: 9307.1306, validation loss: 0.0747
2024-05-25 04:42:28 [INFO]: Epoch 184 - training loss: 9305.9713, validation loss: 0.0734
2024-05-25 04:42:28 [INFO]: Epoch 185 - training loss: 9306.6276, validation loss: 0.0737
2024-05-25 04:42:28 [INFO]: Epoch 186 - training loss: 9306.0172, validation loss: 0.0741
2024-05-25 04:42:28 [INFO]: Epoch 187 - training loss: 9306.0043, validation loss: 0.0741
2024-05-25 04:42:28 [INFO]: Epoch 188 - training loss: 9306.0231, validation loss: 0.0736
2024-05-25 04:42:29 [INFO]: Epoch 189 - training loss: 9304.7363, validation loss: 0.0741
2024-05-25 04:42:29 [INFO]: Epoch 190 - training loss: 9306.1623, validation loss: 0.0738
2024-05-25 04:42:29 [INFO]: Epoch 191 - training loss: 9305.3839, validation loss: 0.0723
2024-05-25 04:42:29 [INFO]: Epoch 192 - training loss: 9305.5908, validation loss: 0.0771
2024-05-25 04:42:29 [INFO]: Epoch 193 - training loss: 9305.1085, validation loss: 0.0729
2024-05-25 04:42:29 [INFO]: Epoch 194 - training loss: 9305.4885, validation loss: 0.0726
2024-05-25 04:42:29 [INFO]: Epoch 195 - training loss: 9304.6173, validation loss: 0.0725
2024-05-25 04:42:30 [INFO]: Epoch 196 - training loss: 9305.6510, validation loss: 0.0723
2024-05-25 04:42:30 [INFO]: Epoch 197 - training loss: 9306.6446, validation loss: 0.0737
2024-05-25 04:42:30 [INFO]: Epoch 198 - training loss: 9304.0877, validation loss: 0.0732
2024-05-25 04:42:30 [INFO]: Epoch 199 - training loss: 9304.5271, validation loss: 0.0740
2024-05-25 04:42:30 [INFO]: Epoch 200 - training loss: 9304.6583, validation loss: 0.0722
2024-05-25 04:42:30 [INFO]: Epoch 201 - training loss: 9304.3901, validation loss: 0.0732
2024-05-25 04:42:30 [INFO]: Epoch 202 - training loss: 9303.8511, validation loss: 0.0724
2024-05-25 04:42:31 [INFO]: Epoch 203 - training loss: 9304.2977, validation loss: 0.0718
2024-05-25 04:42:31 [INFO]: Epoch 204 - training loss: 9304.2933, validation loss: 0.0725
2024-05-25 04:42:31 [INFO]: Epoch 205 - training loss: 9304.6564, validation loss: 0.0735
2024-05-25 04:42:31 [INFO]: Epoch 206 - training loss: 9306.0168, validation loss: 0.0707
2024-05-25 04:42:31 [INFO]: Epoch 207 - training loss: 9305.2081, validation loss: 0.0713
2024-05-25 04:42:31 [INFO]: Epoch 208 - training loss: 9306.0496, validation loss: 0.0726
2024-05-25 04:42:31 [INFO]: Epoch 209 - training loss: 9303.9030, validation loss: 0.0754
2024-05-25 04:42:32 [INFO]: Epoch 210 - training loss: 9303.6417, validation loss: 0.0718
2024-05-25 04:42:32 [INFO]: Epoch 211 - training loss: 9304.8435, validation loss: 0.0705
2024-05-25 04:42:32 [INFO]: Epoch 212 - training loss: 9303.7805, validation loss: 0.0746
2024-05-25 04:42:32 [INFO]: Epoch 213 - training loss: 9304.7512, validation loss: 0.0709
2024-05-25 04:42:32 [INFO]: Epoch 214 - training loss: 9303.4524, validation loss: 0.0716
2024-05-25 04:42:32 [INFO]: Epoch 215 - training loss: 9303.3127, validation loss: 0.0717
2024-05-25 04:42:32 [INFO]: Epoch 216 - training loss: 9302.9902, validation loss: 0.0704
2024-05-25 04:42:33 [INFO]: Epoch 217 - training loss: 9303.0076, validation loss: 0.0717
2024-05-25 04:42:33 [INFO]: Epoch 218 - training loss: 9303.6277, validation loss: 0.0709
2024-05-25 04:42:33 [INFO]: Epoch 219 - training loss: 9303.9898, validation loss: 0.0704
2024-05-25 04:42:33 [INFO]: Epoch 220 - training loss: 9303.5714, validation loss: 0.0712
2024-05-25 04:42:33 [INFO]: Epoch 221 - training loss: 9302.7537, validation loss: 0.0709
2024-05-25 04:42:33 [INFO]: Epoch 222 - training loss: 9301.5909, validation loss: 0.0713
2024-05-25 04:42:33 [INFO]: Epoch 223 - training loss: 9302.5775, validation loss: 0.0701
2024-05-25 04:42:34 [INFO]: Epoch 224 - training loss: 9302.6953, validation loss: 0.0695
2024-05-25 04:42:34 [INFO]: Epoch 225 - training loss: 9302.9191, validation loss: 0.0704
2024-05-25 04:42:34 [INFO]: Epoch 226 - training loss: 9303.0960, validation loss: 0.0715
2024-05-25 04:42:34 [INFO]: Epoch 227 - training loss: 9302.8620, validation loss: 0.0698
2024-05-25 04:42:34 [INFO]: Epoch 228 - training loss: 9302.6182, validation loss: 0.0708
2024-05-25 04:42:34 [INFO]: Epoch 229 - training loss: 9302.9986, validation loss: 0.0704
2024-05-25 04:42:34 [INFO]: Epoch 230 - training loss: 9308.6614, validation loss: 0.0695
2024-05-25 04:42:35 [INFO]: Epoch 231 - training loss: 9305.1439, validation loss: 0.0703
2024-05-25 04:42:35 [INFO]: Epoch 232 - training loss: 9304.1196, validation loss: 0.0738
2024-05-25 04:42:35 [INFO]: Epoch 233 - training loss: 9302.4829, validation loss: 0.0694
2024-05-25 04:42:35 [INFO]: Epoch 234 - training loss: 9302.4518, validation loss: 0.0694
2024-05-25 04:42:35 [INFO]: Epoch 235 - training loss: 9301.6609, validation loss: 0.0693
2024-05-25 04:42:35 [INFO]: Epoch 236 - training loss: 9302.1245, validation loss: 0.0702
2024-05-25 04:42:36 [INFO]: Epoch 237 - training loss: 9301.4548, validation loss: 0.0705
2024-05-25 04:42:36 [INFO]: Epoch 238 - training loss: 9301.7431, validation loss: 0.0687
2024-05-25 04:42:36 [INFO]: Epoch 239 - training loss: 9302.9244, validation loss: 0.0685
2024-05-25 04:42:36 [INFO]: Epoch 240 - training loss: 9302.7812, validation loss: 0.0687
2024-05-25 04:42:36 [INFO]: Epoch 241 - training loss: 9303.7368, validation loss: 0.0691
2024-05-25 04:42:36 [INFO]: Epoch 242 - training loss: 9303.4699, validation loss: 0.0685
2024-05-25 04:42:36 [INFO]: Epoch 243 - training loss: 9302.8750, validation loss: 0.0684
2024-05-25 04:42:37 [INFO]: Epoch 244 - training loss: 9301.4311, validation loss: 0.0687
2024-05-25 04:42:37 [INFO]: Epoch 245 - training loss: 9302.0221, validation loss: 0.0687
2024-05-25 04:42:37 [INFO]: Epoch 246 - training loss: 9301.9877, validation loss: 0.0677
2024-05-25 04:42:37 [INFO]: Epoch 247 - training loss: 9302.0432, validation loss: 0.0684
2024-05-25 04:42:37 [INFO]: Epoch 248 - training loss: 9302.2684, validation loss: 0.0680
2024-05-25 04:42:37 [INFO]: Epoch 249 - training loss: 9302.6351, validation loss: 0.0693
2024-05-25 04:42:37 [INFO]: Epoch 250 - training loss: 9302.4869, validation loss: 0.0677
2024-05-25 04:42:38 [INFO]: Epoch 251 - training loss: 9302.0379, validation loss: 0.0686
2024-05-25 04:42:38 [INFO]: Epoch 252 - training loss: 9301.0771, validation loss: 0.0684
2024-05-25 04:42:38 [INFO]: Epoch 253 - training loss: 9302.8600, validation loss: 0.0691
2024-05-25 04:42:38 [INFO]: Epoch 254 - training loss: 9302.3352, validation loss: 0.0687
2024-05-25 04:42:38 [INFO]: Epoch 255 - training loss: 9301.3328, validation loss: 0.0681
2024-05-25 04:42:38 [INFO]: Epoch 256 - training loss: 9301.2996, validation loss: 0.0685
2024-05-25 04:42:38 [INFO]: Epoch 257 - training loss: 9302.5273, validation loss: 0.0684
2024-05-25 04:42:39 [INFO]: Epoch 258 - training loss: 9301.5233, validation loss: 0.0712
2024-05-25 04:42:39 [INFO]: Epoch 259 - training loss: 9302.1553, validation loss: 0.0692
2024-05-25 04:42:39 [INFO]: Epoch 260 - training loss: 9302.3250, validation loss: 0.0690
2024-05-25 04:42:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:42:39 [INFO]: Finished training. The best model is from epoch#250.
2024-05-25 04:42:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240525_T044201/GPVAE.pypots
2024-05-25 04:42:39 [INFO]: GP-VAE on ETTm1: MAE=0.2574, MSE=0.1436
2024-05-25 04:42:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-25 04:42:39 [INFO]: Using the given device: cuda:0
2024-05-25 04:42:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T044239
2024-05-25 04:42:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T044239/tensorboard
2024-05-25 04:42:39 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 04:42:50 [INFO]: Epoch 001 - generator training loss: 0.5972, discriminator training loss: 0.3201, validation loss: 0.3037
2024-05-25 04:42:59 [INFO]: Epoch 002 - generator training loss: 0.0552, discriminator training loss: 0.2084, validation loss: 0.0926
2024-05-25 04:43:09 [INFO]: Epoch 003 - generator training loss: -0.0654, discriminator training loss: 0.1984, validation loss: 0.0613
2024-05-25 04:43:18 [INFO]: Epoch 004 - generator training loss: -0.0828, discriminator training loss: 0.1966, validation loss: 0.0472
2024-05-25 04:43:27 [INFO]: Epoch 005 - generator training loss: -0.0928, discriminator training loss: 0.1947, validation loss: 0.0412
2024-05-25 04:43:37 [INFO]: Epoch 006 - generator training loss: -0.0865, discriminator training loss: 0.1885, validation loss: 0.0391
2024-05-25 04:43:46 [INFO]: Epoch 007 - generator training loss: -0.0793, discriminator training loss: 0.1801, validation loss: 0.0377
2024-05-25 04:43:55 [INFO]: Epoch 008 - generator training loss: -0.0752, discriminator training loss: 0.1726, validation loss: 0.0365
2024-05-25 04:44:04 [INFO]: Epoch 009 - generator training loss: -0.0635, discriminator training loss: 0.1611, validation loss: 0.0359
2024-05-25 04:44:14 [INFO]: Epoch 010 - generator training loss: -0.0500, discriminator training loss: 0.1442, validation loss: 0.0342
2024-05-25 04:44:23 [INFO]: Epoch 011 - generator training loss: -0.0414, discriminator training loss: 0.1310, validation loss: 0.0348
2024-05-25 04:44:32 [INFO]: Epoch 012 - generator training loss: -0.0290, discriminator training loss: 0.1154, validation loss: 0.0334
2024-05-25 04:44:42 [INFO]: Epoch 013 - generator training loss: -0.0251, discriminator training loss: 0.1085, validation loss: 0.0333
2024-05-25 04:44:51 [INFO]: Epoch 014 - generator training loss: -0.0199, discriminator training loss: 0.0992, validation loss: 0.0337
2024-05-25 04:45:01 [INFO]: Epoch 015 - generator training loss: -0.0150, discriminator training loss: 0.0928, validation loss: 0.0328
2024-05-25 04:45:10 [INFO]: Epoch 016 - generator training loss: -0.0135, discriminator training loss: 0.0869, validation loss: 0.0324
2024-05-25 04:45:19 [INFO]: Epoch 017 - generator training loss: -0.0148, discriminator training loss: 0.0861, validation loss: 0.0315
2024-05-25 04:45:29 [INFO]: Epoch 018 - generator training loss: -0.0109, discriminator training loss: 0.0814, validation loss: 0.0317
2024-05-25 04:45:38 [INFO]: Epoch 019 - generator training loss: -0.0141, discriminator training loss: 0.0823, validation loss: 0.0311
2024-05-25 04:45:48 [INFO]: Epoch 020 - generator training loss: -0.0148, discriminator training loss: 0.0807, validation loss: 0.0304
2024-05-25 04:45:57 [INFO]: Epoch 021 - generator training loss: -0.0140, discriminator training loss: 0.0809, validation loss: 0.0311
2024-05-25 04:46:07 [INFO]: Epoch 022 - generator training loss: -0.0128, discriminator training loss: 0.0790, validation loss: 0.0304
2024-05-25 04:46:16 [INFO]: Epoch 023 - generator training loss: -0.0132, discriminator training loss: 0.0781, validation loss: 0.0304
2024-05-25 04:46:25 [INFO]: Epoch 024 - generator training loss: -0.0124, discriminator training loss: 0.0761, validation loss: 0.0304
2024-05-25 04:46:35 [INFO]: Epoch 025 - generator training loss: -0.0126, discriminator training loss: 0.0741, validation loss: 0.0316
2024-05-25 04:46:44 [INFO]: Epoch 026 - generator training loss: -0.0148, discriminator training loss: 0.0746, validation loss: 0.0307
2024-05-25 04:46:53 [INFO]: Epoch 027 - generator training loss: -0.0114, discriminator training loss: 0.0756, validation loss: 0.0297
2024-05-25 04:47:03 [INFO]: Epoch 028 - generator training loss: -0.0113, discriminator training loss: 0.0748, validation loss: 0.0296
2024-05-25 04:47:12 [INFO]: Epoch 029 - generator training loss: -0.0142, discriminator training loss: 0.0753, validation loss: 0.0290
2024-05-25 04:47:21 [INFO]: Epoch 030 - generator training loss: -0.0142, discriminator training loss: 0.0743, validation loss: 0.0294
2024-05-25 04:47:31 [INFO]: Epoch 031 - generator training loss: -0.0155, discriminator training loss: 0.0749, validation loss: 0.0290
2024-05-25 04:47:40 [INFO]: Epoch 032 - generator training loss: -0.0141, discriminator training loss: 0.0751, validation loss: 0.0285
2024-05-25 04:47:50 [INFO]: Epoch 033 - generator training loss: -0.0122, discriminator training loss: 0.0725, validation loss: 0.0285
2024-05-25 04:47:59 [INFO]: Epoch 034 - generator training loss: -0.0127, discriminator training loss: 0.0719, validation loss: 0.0275
2024-05-25 04:48:08 [INFO]: Epoch 035 - generator training loss: -0.0129, discriminator training loss: 0.0751, validation loss: 0.0295
2024-05-25 04:48:18 [INFO]: Epoch 036 - generator training loss: -0.0139, discriminator training loss: 0.0745, validation loss: 0.0285
2024-05-25 04:48:27 [INFO]: Epoch 037 - generator training loss: -0.0138, discriminator training loss: 0.0723, validation loss: 0.0279
2024-05-25 04:48:37 [INFO]: Epoch 038 - generator training loss: -0.0141, discriminator training loss: 0.0711, validation loss: 0.0282
2024-05-25 04:48:46 [INFO]: Epoch 039 - generator training loss: -0.0142, discriminator training loss: 0.0725, validation loss: 0.0274
2024-05-25 04:48:55 [INFO]: Epoch 040 - generator training loss: -0.0143, discriminator training loss: 0.0706, validation loss: 0.0275
2024-05-25 04:49:05 [INFO]: Epoch 041 - generator training loss: -0.0150, discriminator training loss: 0.0728, validation loss: 0.0282
2024-05-25 04:49:14 [INFO]: Epoch 042 - generator training loss: -0.0143, discriminator training loss: 0.0720, validation loss: 0.0270
2024-05-25 04:49:24 [INFO]: Epoch 043 - generator training loss: -0.0152, discriminator training loss: 0.0722, validation loss: 0.0277
2024-05-25 04:49:33 [INFO]: Epoch 044 - generator training loss: -0.0155, discriminator training loss: 0.0714, validation loss: 0.0278
2024-05-25 04:49:43 [INFO]: Epoch 045 - generator training loss: -0.0186, discriminator training loss: 0.0696, validation loss: 0.0273
2024-05-25 04:49:52 [INFO]: Epoch 046 - generator training loss: -0.0165, discriminator training loss: 0.0738, validation loss: 0.0284
2024-05-25 04:50:01 [INFO]: Epoch 047 - generator training loss: -0.0185, discriminator training loss: 0.0686, validation loss: 0.0269
2024-05-25 04:50:11 [INFO]: Epoch 048 - generator training loss: -0.0183, discriminator training loss: 0.0711, validation loss: 0.0268
2024-05-25 04:50:20 [INFO]: Epoch 049 - generator training loss: -0.0189, discriminator training loss: 0.0706, validation loss: 0.0268
2024-05-25 04:50:29 [INFO]: Epoch 050 - generator training loss: -0.0156, discriminator training loss: 0.0702, validation loss: 0.0261
2024-05-25 04:50:39 [INFO]: Epoch 051 - generator training loss: -0.0151, discriminator training loss: 0.0708, validation loss: 0.0284
2024-05-25 04:50:48 [INFO]: Epoch 052 - generator training loss: -0.0169, discriminator training loss: 0.0696, validation loss: 0.0269
2024-05-25 04:50:57 [INFO]: Epoch 053 - generator training loss: -0.0192, discriminator training loss: 0.0702, validation loss: 0.0259
2024-05-25 04:51:07 [INFO]: Epoch 054 - generator training loss: -0.0184, discriminator training loss: 0.0700, validation loss: 0.0258
2024-05-25 04:51:16 [INFO]: Epoch 055 - generator training loss: -0.0178, discriminator training loss: 0.0704, validation loss: 0.0256
2024-05-25 04:51:25 [INFO]: Epoch 056 - generator training loss: -0.0191, discriminator training loss: 0.0678, validation loss: 0.0264
2024-05-25 04:51:35 [INFO]: Epoch 057 - generator training loss: -0.0218, discriminator training loss: 0.0704, validation loss: 0.0252
2024-05-25 04:51:44 [INFO]: Epoch 058 - generator training loss: -0.0194, discriminator training loss: 0.0689, validation loss: 0.0253
2024-05-25 04:51:53 [INFO]: Epoch 059 - generator training loss: -0.0196, discriminator training loss: 0.0692, validation loss: 0.0252
2024-05-25 04:52:03 [INFO]: Epoch 060 - generator training loss: -0.0214, discriminator training loss: 0.0675, validation loss: 0.0262
2024-05-25 04:52:12 [INFO]: Epoch 061 - generator training loss: -0.0186, discriminator training loss: 0.0683, validation loss: 0.0252
2024-05-25 04:52:22 [INFO]: Epoch 062 - generator training loss: -0.0185, discriminator training loss: 0.0689, validation loss: 0.0248
2024-05-25 04:52:31 [INFO]: Epoch 063 - generator training loss: -0.0220, discriminator training loss: 0.0659, validation loss: 0.0241
2024-05-25 04:52:41 [INFO]: Epoch 064 - generator training loss: -0.0225, discriminator training loss: 0.0695, validation loss: 0.0238
2024-05-25 04:52:50 [INFO]: Epoch 065 - generator training loss: -0.0204, discriminator training loss: 0.0681, validation loss: 0.0236
2024-05-25 04:52:59 [INFO]: Epoch 066 - generator training loss: -0.0227, discriminator training loss: 0.0677, validation loss: 0.0234
2024-05-25 04:53:09 [INFO]: Epoch 067 - generator training loss: -0.0192, discriminator training loss: 0.0681, validation loss: 0.0234
2024-05-25 04:53:18 [INFO]: Epoch 068 - generator training loss: -0.0217, discriminator training loss: 0.0677, validation loss: 0.0232
2024-05-25 04:53:27 [INFO]: Epoch 069 - generator training loss: -0.0213, discriminator training loss: 0.0674, validation loss: 0.0223
2024-05-25 04:53:37 [INFO]: Epoch 070 - generator training loss: -0.0247, discriminator training loss: 0.0698, validation loss: 0.0225
2024-05-25 04:53:46 [INFO]: Epoch 071 - generator training loss: -0.0213, discriminator training loss: 0.0719, validation loss: 0.0224
2024-05-25 04:53:55 [INFO]: Epoch 072 - generator training loss: -0.0209, discriminator training loss: 0.0656, validation loss: 0.0221
2024-05-25 04:54:05 [INFO]: Epoch 073 - generator training loss: -0.0218, discriminator training loss: 0.0671, validation loss: 0.0222
2024-05-25 04:54:14 [INFO]: Epoch 074 - generator training loss: -0.0227, discriminator training loss: 0.0675, validation loss: 0.0217
2024-05-25 04:54:24 [INFO]: Epoch 075 - generator training loss: -0.0227, discriminator training loss: 0.0680, validation loss: 0.0216
2024-05-25 04:54:33 [INFO]: Epoch 076 - generator training loss: -0.0221, discriminator training loss: 0.0677, validation loss: 0.0217
2024-05-25 04:54:42 [INFO]: Epoch 077 - generator training loss: -0.0245, discriminator training loss: 0.0674, validation loss: 0.0217
2024-05-25 04:54:52 [INFO]: Epoch 078 - generator training loss: -0.0244, discriminator training loss: 0.0693, validation loss: 0.0221
2024-05-25 04:55:01 [INFO]: Epoch 079 - generator training loss: -0.0204, discriminator training loss: 0.0678, validation loss: 0.0218
2024-05-25 04:55:11 [INFO]: Epoch 080 - generator training loss: -0.0218, discriminator training loss: 0.0669, validation loss: 0.0216
2024-05-25 04:55:20 [INFO]: Epoch 081 - generator training loss: -0.0261, discriminator training loss: 0.0669, validation loss: 0.0217
2024-05-25 04:55:29 [INFO]: Epoch 082 - generator training loss: -0.0226, discriminator training loss: 0.0673, validation loss: 0.0216
2024-05-25 04:55:39 [INFO]: Epoch 083 - generator training loss: -0.0228, discriminator training loss: 0.0661, validation loss: 0.0215
2024-05-25 04:55:48 [INFO]: Epoch 084 - generator training loss: -0.0220, discriminator training loss: 0.0674, validation loss: 0.0217
2024-05-25 04:55:58 [INFO]: Epoch 085 - generator training loss: -0.0227, discriminator training loss: 0.0666, validation loss: 0.0216
2024-05-25 04:56:07 [INFO]: Epoch 086 - generator training loss: -0.0224, discriminator training loss: 0.0656, validation loss: 0.0214
2024-05-25 04:56:17 [INFO]: Epoch 087 - generator training loss: -0.0242, discriminator training loss: 0.0682, validation loss: 0.0213
2024-05-25 04:56:26 [INFO]: Epoch 088 - generator training loss: -0.0232, discriminator training loss: 0.0690, validation loss: 0.0214
2024-05-25 04:56:35 [INFO]: Epoch 089 - generator training loss: -0.0228, discriminator training loss: 0.0681, validation loss: 0.0214
2024-05-25 04:56:45 [INFO]: Epoch 090 - generator training loss: -0.0240, discriminator training loss: 0.0670, validation loss: 0.0213
2024-05-25 04:56:54 [INFO]: Epoch 091 - generator training loss: -0.0245, discriminator training loss: 0.0655, validation loss: 0.0212
2024-05-25 04:57:03 [INFO]: Epoch 092 - generator training loss: -0.0220, discriminator training loss: 0.0665, validation loss: 0.0214
2024-05-25 04:57:13 [INFO]: Epoch 093 - generator training loss: -0.0234, discriminator training loss: 0.0673, validation loss: 0.0216
2024-05-25 04:57:22 [INFO]: Epoch 094 - generator training loss: -0.0218, discriminator training loss: 0.0651, validation loss: 0.0210
2024-05-25 04:57:32 [INFO]: Epoch 095 - generator training loss: -0.0203, discriminator training loss: 0.0662, validation loss: 0.0212
2024-05-25 04:57:41 [INFO]: Epoch 096 - generator training loss: -0.0225, discriminator training loss: 0.0658, validation loss: 0.0210
2024-05-25 04:57:50 [INFO]: Epoch 097 - generator training loss: -0.0215, discriminator training loss: 0.0676, validation loss: 0.0213
2024-05-25 04:58:00 [INFO]: Epoch 098 - generator training loss: -0.0228, discriminator training loss: 0.0693, validation loss: 0.0213
2024-05-25 04:58:09 [INFO]: Epoch 099 - generator training loss: -0.0229, discriminator training loss: 0.0673, validation loss: 0.0209
2024-05-25 04:58:18 [INFO]: Epoch 100 - generator training loss: -0.0219, discriminator training loss: 0.0662, validation loss: 0.0208
2024-05-25 04:58:28 [INFO]: Epoch 101 - generator training loss: -0.0245, discriminator training loss: 0.0650, validation loss: 0.0212
2024-05-25 04:58:37 [INFO]: Epoch 102 - generator training loss: -0.0226, discriminator training loss: 0.0659, validation loss: 0.0213
2024-05-25 04:58:46 [INFO]: Epoch 103 - generator training loss: -0.0237, discriminator training loss: 0.0665, validation loss: 0.0209
2024-05-25 04:58:56 [INFO]: Epoch 104 - generator training loss: -0.0237, discriminator training loss: 0.0644, validation loss: 0.0210
2024-05-25 04:59:05 [INFO]: Epoch 105 - generator training loss: -0.0255, discriminator training loss: 0.0667, validation loss: 0.0207
2024-05-25 04:59:15 [INFO]: Epoch 106 - generator training loss: -0.0271, discriminator training loss: 0.0679, validation loss: 0.0207
2024-05-25 04:59:24 [INFO]: Epoch 107 - generator training loss: -0.0241, discriminator training loss: 0.0662, validation loss: 0.0208
2024-05-25 04:59:34 [INFO]: Epoch 108 - generator training loss: -0.0252, discriminator training loss: 0.0643, validation loss: 0.0206
2024-05-25 04:59:43 [INFO]: Epoch 109 - generator training loss: -0.0245, discriminator training loss: 0.0662, validation loss: 0.0210
2024-05-25 04:59:52 [INFO]: Epoch 110 - generator training loss: -0.0233, discriminator training loss: 0.0645, validation loss: 0.0211
2024-05-25 05:00:02 [INFO]: Epoch 111 - generator training loss: -0.0232, discriminator training loss: 0.0657, validation loss: 0.0219
2024-05-25 05:00:11 [INFO]: Epoch 112 - generator training loss: -0.0242, discriminator training loss: 0.0662, validation loss: 0.0208
2024-05-25 05:00:20 [INFO]: Epoch 113 - generator training loss: -0.0239, discriminator training loss: 0.0667, validation loss: 0.0213
2024-05-25 05:00:30 [INFO]: Epoch 114 - generator training loss: -0.0246, discriminator training loss: 0.0654, validation loss: 0.0222
2024-05-25 05:00:39 [INFO]: Epoch 115 - generator training loss: -0.0217, discriminator training loss: 0.0658, validation loss: 0.0216
2024-05-25 05:00:48 [INFO]: Epoch 116 - generator training loss: -0.0231, discriminator training loss: 0.0658, validation loss: 0.0216
2024-05-25 05:00:58 [INFO]: Epoch 117 - generator training loss: -0.0244, discriminator training loss: 0.0664, validation loss: 0.0211
2024-05-25 05:01:07 [INFO]: Epoch 118 - generator training loss: -0.0253, discriminator training loss: 0.0656, validation loss: 0.0203
2024-05-25 05:01:17 [INFO]: Epoch 119 - generator training loss: -0.0249, discriminator training loss: 0.0643, validation loss: 0.0202
2024-05-25 05:01:26 [INFO]: Epoch 120 - generator training loss: -0.0268, discriminator training loss: 0.0674, validation loss: 0.0200
2024-05-25 05:01:36 [INFO]: Epoch 121 - generator training loss: -0.0257, discriminator training loss: 0.0669, validation loss: 0.0202
2024-05-25 05:01:45 [INFO]: Epoch 122 - generator training loss: -0.0267, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-25 05:01:54 [INFO]: Epoch 123 - generator training loss: -0.0259, discriminator training loss: 0.0670, validation loss: 0.0190
2024-05-25 05:02:04 [INFO]: Epoch 124 - generator training loss: -0.0249, discriminator training loss: 0.0665, validation loss: 0.0188
2024-05-25 05:02:13 [INFO]: Epoch 125 - generator training loss: -0.0251, discriminator training loss: 0.0659, validation loss: 0.0189
2024-05-25 05:02:23 [INFO]: Epoch 126 - generator training loss: -0.0269, discriminator training loss: 0.0670, validation loss: 0.0210
2024-05-25 05:02:32 [INFO]: Epoch 127 - generator training loss: -0.0271, discriminator training loss: 0.0670, validation loss: 0.0189
2024-05-25 05:02:42 [INFO]: Epoch 128 - generator training loss: -0.0268, discriminator training loss: 0.0644, validation loss: 0.0187
2024-05-25 05:02:51 [INFO]: Epoch 129 - generator training loss: -0.0265, discriminator training loss: 0.0642, validation loss: 0.0185
2024-05-25 05:03:00 [INFO]: Epoch 130 - generator training loss: -0.0264, discriminator training loss: 0.0666, validation loss: 0.0185
2024-05-25 05:03:10 [INFO]: Epoch 131 - generator training loss: -0.0274, discriminator training loss: 0.0649, validation loss: 0.0188
2024-05-25 05:03:19 [INFO]: Epoch 132 - generator training loss: -0.0292, discriminator training loss: 0.0680, validation loss: 0.0184
2024-05-25 05:03:28 [INFO]: Epoch 133 - generator training loss: -0.0262, discriminator training loss: 0.0657, validation loss: 0.0185
2024-05-25 05:03:38 [INFO]: Epoch 134 - generator training loss: -0.0271, discriminator training loss: 0.0666, validation loss: 0.0183
2024-05-25 05:03:47 [INFO]: Epoch 135 - generator training loss: -0.0263, discriminator training loss: 0.0666, validation loss: 0.0184
2024-05-25 05:03:57 [INFO]: Epoch 136 - generator training loss: -0.0290, discriminator training loss: 0.0676, validation loss: 0.0185
2024-05-25 05:04:06 [INFO]: Epoch 137 - generator training loss: -0.0270, discriminator training loss: 0.0664, validation loss: 0.0184
2024-05-25 05:04:15 [INFO]: Epoch 138 - generator training loss: -0.0271, discriminator training loss: 0.0635, validation loss: 0.0183
2024-05-25 05:04:25 [INFO]: Epoch 139 - generator training loss: -0.0289, discriminator training loss: 0.0644, validation loss: 0.0183
2024-05-25 05:04:34 [INFO]: Epoch 140 - generator training loss: -0.0282, discriminator training loss: 0.0675, validation loss: 0.0181
2024-05-25 05:04:43 [INFO]: Epoch 141 - generator training loss: -0.0246, discriminator training loss: 0.0657, validation loss: 0.0187
2024-05-25 05:04:53 [INFO]: Epoch 142 - generator training loss: -0.0278, discriminator training loss: 0.0653, validation loss: 0.0185
2024-05-25 05:05:02 [INFO]: Epoch 143 - generator training loss: -0.0275, discriminator training loss: 0.0656, validation loss: 0.0182
2024-05-25 05:05:12 [INFO]: Epoch 144 - generator training loss: -0.0278, discriminator training loss: 0.0667, validation loss: 0.0190
2024-05-25 05:05:21 [INFO]: Epoch 145 - generator training loss: -0.0259, discriminator training loss: 0.0668, validation loss: 0.0180
2024-05-25 05:05:31 [INFO]: Epoch 146 - generator training loss: -0.0291, discriminator training loss: 0.0668, validation loss: 0.0183
2024-05-25 05:05:40 [INFO]: Epoch 147 - generator training loss: -0.0269, discriminator training loss: 0.0666, validation loss: 0.0182
2024-05-25 05:05:49 [INFO]: Epoch 148 - generator training loss: -0.0295, discriminator training loss: 0.0646, validation loss: 0.0190
2024-05-25 05:05:58 [INFO]: Epoch 149 - generator training loss: -0.0289, discriminator training loss: 0.0655, validation loss: 0.0185
2024-05-25 05:06:08 [INFO]: Epoch 150 - generator training loss: -0.0269, discriminator training loss: 0.0645, validation loss: 0.0184
2024-05-25 05:06:17 [INFO]: Epoch 151 - generator training loss: -0.0281, discriminator training loss: 0.0647, validation loss: 0.0184
2024-05-25 05:06:26 [INFO]: Epoch 152 - generator training loss: -0.0276, discriminator training loss: 0.0657, validation loss: 0.0180
2024-05-25 05:06:36 [INFO]: Epoch 153 - generator training loss: -0.0264, discriminator training loss: 0.0651, validation loss: 0.0182
2024-05-25 05:06:45 [INFO]: Epoch 154 - generator training loss: -0.0262, discriminator training loss: 0.0656, validation loss: 0.0187
2024-05-25 05:06:54 [INFO]: Epoch 155 - generator training loss: -0.0267, discriminator training loss: 0.0648, validation loss: 0.0181
2024-05-25 05:07:04 [INFO]: Epoch 156 - generator training loss: -0.0251, discriminator training loss: 0.0639, validation loss: 0.0183
2024-05-25 05:07:13 [INFO]: Epoch 157 - generator training loss: -0.0313, discriminator training loss: 0.0666, validation loss: 0.0181
2024-05-25 05:07:22 [INFO]: Epoch 158 - generator training loss: -0.0261, discriminator training loss: 0.0645, validation loss: 0.0184
2024-05-25 05:07:32 [INFO]: Epoch 159 - generator training loss: -0.0254, discriminator training loss: 0.0640, validation loss: 0.0182
2024-05-25 05:07:41 [INFO]: Epoch 160 - generator training loss: -0.0269, discriminator training loss: 0.0631, validation loss: 0.0183
2024-05-25 05:07:50 [INFO]: Epoch 161 - generator training loss: -0.0299, discriminator training loss: 0.0652, validation loss: 0.0183
2024-05-25 05:08:00 [INFO]: Epoch 162 - generator training loss: -0.0273, discriminator training loss: 0.0643, validation loss: 0.0186
2024-05-25 05:08:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:08:00 [INFO]: Finished training. The best model is from epoch#152.
2024-05-25 05:08:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_ettm1/20240525_T044239/USGAN.pypots
2024-05-25 05:08:01 [INFO]: US-GAN on ETTm1: MAE=0.1353, MSE=0.0476
2024-05-25 05:08:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-25 05:08:01 [INFO]: Using the given device: cuda:0
2024-05-25 05:08:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T050801
2024-05-25 05:08:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T050801/tensorboard
2024-05-25 05:08:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 05:08:09 [INFO]: Epoch 001 - training loss: 1.3436, validation loss: 0.3047
2024-05-25 05:08:15 [INFO]: Epoch 002 - training loss: 0.9173, validation loss: 0.0888
2024-05-25 05:08:21 [INFO]: Epoch 003 - training loss: 0.7356, validation loss: 0.0537
2024-05-25 05:08:28 [INFO]: Epoch 004 - training loss: 0.6610, validation loss: 0.0448
2024-05-25 05:08:34 [INFO]: Epoch 005 - training loss: 0.6145, validation loss: 0.0383
2024-05-25 05:08:40 [INFO]: Epoch 006 - training loss: 0.5946, validation loss: 0.0388
2024-05-25 05:08:46 [INFO]: Epoch 007 - training loss: 0.5569, validation loss: 0.0363
2024-05-25 05:08:53 [INFO]: Epoch 008 - training loss: 0.5347, validation loss: 0.0347
2024-05-25 05:08:59 [INFO]: Epoch 009 - training loss: 0.5131, validation loss: 0.0330
2024-05-25 05:09:05 [INFO]: Epoch 010 - training loss: 0.4859, validation loss: 0.0319
2024-05-25 05:09:11 [INFO]: Epoch 011 - training loss: 0.4779, validation loss: 0.0299
2024-05-25 05:09:18 [INFO]: Epoch 012 - training loss: 0.4626, validation loss: 0.0297
2024-05-25 05:09:24 [INFO]: Epoch 013 - training loss: 0.4612, validation loss: 0.0281
2024-05-25 05:09:30 [INFO]: Epoch 014 - training loss: 0.4378, validation loss: 0.0271
2024-05-25 05:09:36 [INFO]: Epoch 015 - training loss: 0.4244, validation loss: 0.0265
2024-05-25 05:09:42 [INFO]: Epoch 016 - training loss: 0.4127, validation loss: 0.0246
2024-05-25 05:09:49 [INFO]: Epoch 017 - training loss: 0.4001, validation loss: 0.0251
2024-05-25 05:09:55 [INFO]: Epoch 018 - training loss: 0.3970, validation loss: 0.0240
2024-05-25 05:10:01 [INFO]: Epoch 019 - training loss: 0.3899, validation loss: 0.0237
2024-05-25 05:10:07 [INFO]: Epoch 020 - training loss: 0.3817, validation loss: 0.0227
2024-05-25 05:10:14 [INFO]: Epoch 021 - training loss: 0.3818, validation loss: 0.0232
2024-05-25 05:10:20 [INFO]: Epoch 022 - training loss: 0.3856, validation loss: 0.0231
2024-05-25 05:10:26 [INFO]: Epoch 023 - training loss: 0.3825, validation loss: 0.0230
2024-05-25 05:10:32 [INFO]: Epoch 024 - training loss: 0.3892, validation loss: 0.0235
2024-05-25 05:10:39 [INFO]: Epoch 025 - training loss: 0.3801, validation loss: 0.0230
2024-05-25 05:10:45 [INFO]: Epoch 026 - training loss: 0.3782, validation loss: 0.0229
2024-05-25 05:10:51 [INFO]: Epoch 027 - training loss: 0.3801, validation loss: 0.0226
2024-05-25 05:10:57 [INFO]: Epoch 028 - training loss: 0.3801, validation loss: 0.0232
2024-05-25 05:11:04 [INFO]: Epoch 029 - training loss: 0.3788, validation loss: 0.0223
2024-05-25 05:11:10 [INFO]: Epoch 030 - training loss: 0.3676, validation loss: 0.0243
2024-05-25 05:11:16 [INFO]: Epoch 031 - training loss: 0.4058, validation loss: 0.0248
2024-05-25 05:11:22 [INFO]: Epoch 032 - training loss: 0.3962, validation loss: 0.0234
2024-05-25 05:11:29 [INFO]: Epoch 033 - training loss: 0.3844, validation loss: 0.0237
2024-05-25 05:11:35 [INFO]: Epoch 034 - training loss: 0.3864, validation loss: 0.0223
2024-05-25 05:11:41 [INFO]: Epoch 035 - training loss: 0.3808, validation loss: 0.0229
2024-05-25 05:11:47 [INFO]: Epoch 036 - training loss: 0.3741, validation loss: 0.0229
2024-05-25 05:11:54 [INFO]: Epoch 037 - training loss: 0.3820, validation loss: 0.0225
2024-05-25 05:12:00 [INFO]: Epoch 038 - training loss: 0.3787, validation loss: 0.0226
2024-05-25 05:12:06 [INFO]: Epoch 039 - training loss: 0.3789, validation loss: 0.0229
2024-05-25 05:12:12 [INFO]: Epoch 040 - training loss: 0.3732, validation loss: 0.0227
2024-05-25 05:12:19 [INFO]: Epoch 041 - training loss: 0.3719, validation loss: 0.0225
2024-05-25 05:12:25 [INFO]: Epoch 042 - training loss: 0.3743, validation loss: 0.0226
2024-05-25 05:12:31 [INFO]: Epoch 043 - training loss: 0.4031, validation loss: 0.0246
2024-05-25 05:12:37 [INFO]: Epoch 044 - training loss: 0.3854, validation loss: 0.0243
2024-05-25 05:12:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:12:37 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 05:12:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_ettm1/20240525_T050801/BRITS.pypots
2024-05-25 05:12:38 [INFO]: BRITS on ETTm1: MAE=0.1349, MSE=0.0530
2024-05-25 05:12:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-25 05:12:38 [INFO]: Using the given device: cuda:0
2024-05-25 05:12:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238
2024-05-25 05:12:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/tensorboard
2024-05-25 05:12:38 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 05:12:40 [INFO]: Epoch 001 - training loss: 1.3577, validation loss: 1.2432
2024-05-25 05:12:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch1_loss1.2432440966367722.pypots
2024-05-25 05:12:40 [INFO]: Epoch 002 - training loss: 1.0638, validation loss: 1.1124
2024-05-25 05:12:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch2_loss1.1124015301465988.pypots
2024-05-25 05:12:41 [INFO]: Epoch 003 - training loss: 1.0287, validation loss: 1.0563
2024-05-25 05:12:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch3_loss1.0562718361616135.pypots
2024-05-25 05:12:41 [INFO]: Epoch 004 - training loss: 0.9563, validation loss: 1.0299
2024-05-25 05:12:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch4_loss1.0299038589000702.pypots
2024-05-25 05:12:41 [INFO]: Epoch 005 - training loss: 0.9522, validation loss: 1.0164
2024-05-25 05:12:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch5_loss1.016396939754486.pypots
2024-05-25 05:12:41 [INFO]: Epoch 006 - training loss: 0.9189, validation loss: 1.0065
2024-05-25 05:12:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch6_loss1.0064895302057266.pypots
2024-05-25 05:12:41 [INFO]: Epoch 007 - training loss: 0.9414, validation loss: 1.0009
2024-05-25 05:12:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch7_loss1.0009397864341736.pypots
2024-05-25 05:12:42 [INFO]: Epoch 008 - training loss: 0.9149, validation loss: 1.0001
2024-05-25 05:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch8_loss1.0000591427087784.pypots
2024-05-25 05:12:42 [INFO]: Epoch 009 - training loss: 0.9204, validation loss: 0.9965
2024-05-25 05:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch9_loss0.9965335875749588.pypots
2024-05-25 05:12:42 [INFO]: Epoch 010 - training loss: 0.9254, validation loss: 0.9914
2024-05-25 05:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch10_loss0.9914422631263733.pypots
2024-05-25 05:12:42 [INFO]: Epoch 011 - training loss: 0.8971, validation loss: 0.9893
2024-05-25 05:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch11_loss0.9892981797456741.pypots
2024-05-25 05:12:42 [INFO]: Epoch 012 - training loss: 0.8817, validation loss: 0.9820
2024-05-25 05:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch12_loss0.981957197189331.pypots
2024-05-25 05:12:43 [INFO]: Epoch 013 - training loss: 0.8886, validation loss: 0.9756
2024-05-25 05:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch13_loss0.9756444692611694.pypots
2024-05-25 05:12:43 [INFO]: Epoch 014 - training loss: 0.8896, validation loss: 0.9680
2024-05-25 05:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch14_loss0.9679512977600098.pypots
2024-05-25 05:12:43 [INFO]: Epoch 015 - training loss: 0.8746, validation loss: 0.9687
2024-05-25 05:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch15_loss0.9686754196882248.pypots
2024-05-25 05:12:43 [INFO]: Epoch 016 - training loss: 0.8994, validation loss: 0.9647
2024-05-25 05:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch16_loss0.9646716564893723.pypots
2024-05-25 05:12:43 [INFO]: Epoch 017 - training loss: 0.8752, validation loss: 0.9592
2024-05-25 05:12:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch17_loss0.9592400044202805.pypots
2024-05-25 05:12:44 [INFO]: Epoch 018 - training loss: 0.8590, validation loss: 0.9559
2024-05-25 05:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch18_loss0.9559250771999359.pypots
2024-05-25 05:12:44 [INFO]: Epoch 019 - training loss: 0.8749, validation loss: 0.9519
2024-05-25 05:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch19_loss0.9518892467021942.pypots
2024-05-25 05:12:44 [INFO]: Epoch 020 - training loss: 0.8783, validation loss: 0.9502
2024-05-25 05:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch20_loss0.9502257406711578.pypots
2024-05-25 05:12:44 [INFO]: Epoch 021 - training loss: 0.8853, validation loss: 0.9482
2024-05-25 05:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch21_loss0.9482270926237106.pypots
2024-05-25 05:12:44 [INFO]: Epoch 022 - training loss: 0.8483, validation loss: 0.9482
2024-05-25 05:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch22_loss0.9481633901596069.pypots
2024-05-25 05:12:45 [INFO]: Epoch 023 - training loss: 0.8588, validation loss: 0.9455
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch23_loss0.9455062001943588.pypots
2024-05-25 05:12:45 [INFO]: Epoch 024 - training loss: 0.8521, validation loss: 0.9420
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch24_loss0.9420429468154907.pypots
2024-05-25 05:12:45 [INFO]: Epoch 025 - training loss: 0.8263, validation loss: 0.9401
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch25_loss0.9400655031204224.pypots
2024-05-25 05:12:45 [INFO]: Epoch 026 - training loss: 0.8539, validation loss: 0.9367
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch26_loss0.9367120712995529.pypots
2024-05-25 05:12:45 [INFO]: Epoch 027 - training loss: 0.8413, validation loss: 0.9332
2024-05-25 05:12:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch27_loss0.9331638514995575.pypots
2024-05-25 05:12:46 [INFO]: Epoch 028 - training loss: 0.8474, validation loss: 0.9296
2024-05-25 05:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch28_loss0.9295795112848282.pypots
2024-05-25 05:12:46 [INFO]: Epoch 029 - training loss: 0.8294, validation loss: 0.9248
2024-05-25 05:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch29_loss0.924830436706543.pypots
2024-05-25 05:12:46 [INFO]: Epoch 030 - training loss: 0.8173, validation loss: 0.9207
2024-05-25 05:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch30_loss0.9207374453544617.pypots
2024-05-25 05:12:46 [INFO]: Epoch 031 - training loss: 0.8197, validation loss: 0.9181
2024-05-25 05:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch31_loss0.9181228429079056.pypots
2024-05-25 05:12:46 [INFO]: Epoch 032 - training loss: 0.8237, validation loss: 0.9154
2024-05-25 05:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch32_loss0.9154149442911148.pypots
2024-05-25 05:12:47 [INFO]: Epoch 033 - training loss: 0.8116, validation loss: 0.9098
2024-05-25 05:12:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch33_loss0.9098176211118698.pypots
2024-05-25 05:12:47 [INFO]: Epoch 034 - training loss: 0.8030, validation loss: 0.9065
2024-05-25 05:12:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch34_loss0.9065030664205551.pypots
2024-05-25 05:12:47 [INFO]: Epoch 035 - training loss: 0.8232, validation loss: 0.9044
2024-05-25 05:12:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch35_loss0.9044131338596344.pypots
2024-05-25 05:12:47 [INFO]: Epoch 036 - training loss: 0.8274, validation loss: 0.9003
2024-05-25 05:12:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch36_loss0.9003079533576965.pypots
2024-05-25 05:12:47 [INFO]: Epoch 037 - training loss: 0.8155, validation loss: 0.8984
2024-05-25 05:12:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch37_loss0.8984464257955551.pypots
2024-05-25 05:12:48 [INFO]: Epoch 038 - training loss: 0.8254, validation loss: 0.8939
2024-05-25 05:12:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch38_loss0.893947184085846.pypots
2024-05-25 05:12:48 [INFO]: Epoch 039 - training loss: 0.8323, validation loss: 0.8885
2024-05-25 05:12:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch39_loss0.8884796649217606.pypots
2024-05-25 05:12:48 [INFO]: Epoch 040 - training loss: 0.8219, validation loss: 0.8873
2024-05-25 05:12:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch40_loss0.8872671276330948.pypots
2024-05-25 05:12:48 [INFO]: Epoch 041 - training loss: 0.8289, validation loss: 0.8849
2024-05-25 05:12:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch41_loss0.8848573267459869.pypots
2024-05-25 05:12:48 [INFO]: Epoch 042 - training loss: 0.8072, validation loss: 0.8829
2024-05-25 05:12:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch42_loss0.882941871881485.pypots
2024-05-25 05:12:49 [INFO]: Epoch 043 - training loss: 0.8053, validation loss: 0.8793
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch43_loss0.8792969882488251.pypots
2024-05-25 05:12:49 [INFO]: Epoch 044 - training loss: 0.8083, validation loss: 0.8776
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch44_loss0.8776445537805557.pypots
2024-05-25 05:12:49 [INFO]: Epoch 045 - training loss: 0.8142, validation loss: 0.8767
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch45_loss0.8766775727272034.pypots
2024-05-25 05:12:49 [INFO]: Epoch 046 - training loss: 0.8004, validation loss: 0.8748
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch46_loss0.8747767210006714.pypots
2024-05-25 05:12:49 [INFO]: Epoch 047 - training loss: 0.7960, validation loss: 0.8721
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch47_loss0.8720950782299042.pypots
2024-05-25 05:12:49 [INFO]: Epoch 048 - training loss: 0.8163, validation loss: 0.8727
2024-05-25 05:12:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch48_loss0.8726716041564941.pypots
2024-05-25 05:12:50 [INFO]: Epoch 049 - training loss: 0.8065, validation loss: 0.8676
2024-05-25 05:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch49_loss0.867622584104538.pypots
2024-05-25 05:12:50 [INFO]: Epoch 050 - training loss: 0.8152, validation loss: 0.8717
2024-05-25 05:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch50_loss0.8717105537652969.pypots
2024-05-25 05:12:50 [INFO]: Epoch 051 - training loss: 0.8127, validation loss: 0.8705
2024-05-25 05:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch51_loss0.8705263882875443.pypots
2024-05-25 05:12:50 [INFO]: Epoch 052 - training loss: 0.7941, validation loss: 0.8680
2024-05-25 05:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch52_loss0.8680068403482437.pypots
2024-05-25 05:12:50 [INFO]: Epoch 053 - training loss: 0.7947, validation loss: 0.8655
2024-05-25 05:12:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch53_loss0.8654926121234894.pypots
2024-05-25 05:12:51 [INFO]: Epoch 054 - training loss: 0.7980, validation loss: 0.8644
2024-05-25 05:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch54_loss0.8644081056118011.pypots
2024-05-25 05:12:51 [INFO]: Epoch 055 - training loss: 0.7897, validation loss: 0.8626
2024-05-25 05:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch55_loss0.8625689148902893.pypots
2024-05-25 05:12:51 [INFO]: Epoch 056 - training loss: 0.7990, validation loss: 0.8610
2024-05-25 05:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch56_loss0.8610044121742249.pypots
2024-05-25 05:12:51 [INFO]: Epoch 057 - training loss: 0.8503, validation loss: 0.8601
2024-05-25 05:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch57_loss0.8601407110691071.pypots
2024-05-25 05:12:51 [INFO]: Epoch 058 - training loss: 0.8090, validation loss: 0.8571
2024-05-25 05:12:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch58_loss0.857087641954422.pypots
2024-05-25 05:12:52 [INFO]: Epoch 059 - training loss: 0.8215, validation loss: 0.8580
2024-05-25 05:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch59_loss0.8579747229814529.pypots
2024-05-25 05:12:52 [INFO]: Epoch 060 - training loss: 0.8009, validation loss: 0.8577
2024-05-25 05:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch60_loss0.8577142357826233.pypots
2024-05-25 05:12:52 [INFO]: Epoch 061 - training loss: 0.8001, validation loss: 0.8575
2024-05-25 05:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch61_loss0.8575334846973419.pypots
2024-05-25 05:12:52 [INFO]: Epoch 062 - training loss: 0.7848, validation loss: 0.8574
2024-05-25 05:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch62_loss0.8573975116014481.pypots
2024-05-25 05:12:52 [INFO]: Epoch 063 - training loss: 0.7801, validation loss: 0.8541
2024-05-25 05:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch63_loss0.8540932834148407.pypots
2024-05-25 05:12:53 [INFO]: Epoch 064 - training loss: 0.8089, validation loss: 0.8571
2024-05-25 05:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch64_loss0.8571245074272156.pypots
2024-05-25 05:12:53 [INFO]: Epoch 065 - training loss: 0.7899, validation loss: 0.8558
2024-05-25 05:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch65_loss0.8557510226964951.pypots
2024-05-25 05:12:53 [INFO]: Epoch 066 - training loss: 0.7821, validation loss: 0.8562
2024-05-25 05:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch66_loss0.8561581522226334.pypots
2024-05-25 05:12:53 [INFO]: Epoch 067 - training loss: 0.7914, validation loss: 0.8542
2024-05-25 05:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch67_loss0.8541613221168518.pypots
2024-05-25 05:12:53 [INFO]: Epoch 068 - training loss: 0.8215, validation loss: 0.8572
2024-05-25 05:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch68_loss0.8571754842996597.pypots
2024-05-25 05:12:54 [INFO]: Epoch 069 - training loss: 0.8155, validation loss: 0.8535
2024-05-25 05:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch69_loss0.8535147458314896.pypots
2024-05-25 05:12:54 [INFO]: Epoch 070 - training loss: 0.7961, validation loss: 0.8552
2024-05-25 05:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch70_loss0.8552124500274658.pypots
2024-05-25 05:12:54 [INFO]: Epoch 071 - training loss: 0.8039, validation loss: 0.8537
2024-05-25 05:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch71_loss0.8537298440933228.pypots
2024-05-25 05:12:54 [INFO]: Epoch 072 - training loss: 0.8002, validation loss: 0.8528
2024-05-25 05:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch72_loss0.8527749329805374.pypots
2024-05-25 05:12:54 [INFO]: Epoch 073 - training loss: 0.7938, validation loss: 0.8531
2024-05-25 05:12:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch73_loss0.8531483113765717.pypots
2024-05-25 05:12:55 [INFO]: Epoch 074 - training loss: 0.7888, validation loss: 0.8531
2024-05-25 05:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch74_loss0.853121891617775.pypots
2024-05-25 05:12:55 [INFO]: Epoch 075 - training loss: 0.7971, validation loss: 0.8550
2024-05-25 05:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch75_loss0.8549760282039642.pypots
2024-05-25 05:12:55 [INFO]: Epoch 076 - training loss: 0.7746, validation loss: 0.8505
2024-05-25 05:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch76_loss0.8504610061645508.pypots
2024-05-25 05:12:55 [INFO]: Epoch 077 - training loss: 0.7959, validation loss: 0.8529
2024-05-25 05:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch77_loss0.852884978055954.pypots
2024-05-25 05:12:55 [INFO]: Epoch 078 - training loss: 0.8041, validation loss: 0.8533
2024-05-25 05:12:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch78_loss0.8532752841711044.pypots
2024-05-25 05:12:56 [INFO]: Epoch 079 - training loss: 0.8182, validation loss: 0.8509
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch79_loss0.8509148210287094.pypots
2024-05-25 05:12:56 [INFO]: Epoch 080 - training loss: 0.8092, validation loss: 0.8563
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch80_loss0.8563088476657867.pypots
2024-05-25 05:12:56 [INFO]: Epoch 081 - training loss: 0.7990, validation loss: 0.8557
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch81_loss0.8556873798370361.pypots
2024-05-25 05:12:56 [INFO]: Epoch 082 - training loss: 0.8568, validation loss: 0.8519
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch82_loss0.8519376367330551.pypots
2024-05-25 05:12:56 [INFO]: Epoch 083 - training loss: 0.8147, validation loss: 0.8537
2024-05-25 05:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch83_loss0.8537144064903259.pypots
2024-05-25 05:12:57 [INFO]: Epoch 084 - training loss: 0.7966, validation loss: 0.8531
2024-05-25 05:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch84_loss0.8531115502119064.pypots
2024-05-25 05:12:57 [INFO]: Epoch 085 - training loss: 0.7787, validation loss: 0.8496
2024-05-25 05:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch85_loss0.8496412634849548.pypots
2024-05-25 05:12:57 [INFO]: Epoch 086 - training loss: 0.8154, validation loss: 0.8507
2024-05-25 05:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch86_loss0.8506998866796494.pypots
2024-05-25 05:12:57 [INFO]: Epoch 087 - training loss: 0.7900, validation loss: 0.8505
2024-05-25 05:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch87_loss0.8504858165979385.pypots
2024-05-25 05:12:57 [INFO]: Epoch 088 - training loss: 0.8031, validation loss: 0.8497
2024-05-25 05:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch88_loss0.8496832996606827.pypots
2024-05-25 05:12:58 [INFO]: Epoch 089 - training loss: 0.7654, validation loss: 0.8519
2024-05-25 05:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch89_loss0.8519253581762314.pypots
2024-05-25 05:12:58 [INFO]: Epoch 090 - training loss: 0.8069, validation loss: 0.8514
2024-05-25 05:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch90_loss0.8514396101236343.pypots
2024-05-25 05:12:58 [INFO]: Epoch 091 - training loss: 0.7976, validation loss: 0.8499
2024-05-25 05:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch91_loss0.8499245792627335.pypots
2024-05-25 05:12:58 [INFO]: Epoch 092 - training loss: 0.7828, validation loss: 0.8502
2024-05-25 05:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch92_loss0.8501809984445572.pypots
2024-05-25 05:12:58 [INFO]: Epoch 093 - training loss: 0.8151, validation loss: 0.8432
2024-05-25 05:12:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch93_loss0.84318508207798.pypots
2024-05-25 05:12:59 [INFO]: Epoch 094 - training loss: 0.8193, validation loss: 0.8510
2024-05-25 05:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch94_loss0.8510261923074722.pypots
2024-05-25 05:12:59 [INFO]: Epoch 095 - training loss: 0.7865, validation loss: 0.8496
2024-05-25 05:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch95_loss0.8495887964963913.pypots
2024-05-25 05:12:59 [INFO]: Epoch 096 - training loss: 0.7836, validation loss: 0.8490
2024-05-25 05:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch96_loss0.8490101397037506.pypots
2024-05-25 05:12:59 [INFO]: Epoch 097 - training loss: 0.7941, validation loss: 0.8502
2024-05-25 05:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch97_loss0.8501639813184738.pypots
2024-05-25 05:12:59 [INFO]: Epoch 098 - training loss: 0.7749, validation loss: 0.8478
2024-05-25 05:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch98_loss0.8477786034345627.pypots
2024-05-25 05:13:00 [INFO]: Epoch 099 - training loss: 0.7727, validation loss: 0.8493
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch99_loss0.849291667342186.pypots
2024-05-25 05:13:00 [INFO]: Epoch 100 - training loss: 0.7990, validation loss: 0.8477
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch100_loss0.8476777970790863.pypots
2024-05-25 05:13:00 [INFO]: Epoch 101 - training loss: 0.7900, validation loss: 0.8502
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch101_loss0.850231796503067.pypots
2024-05-25 05:13:00 [INFO]: Epoch 102 - training loss: 0.7587, validation loss: 0.8488
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch102_loss0.8488283753395081.pypots
2024-05-25 05:13:00 [INFO]: Epoch 103 - training loss: 0.8003, validation loss: 0.8476
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN_epoch103_loss0.8475897908210754.pypots
2024-05-25 05:13:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:13:00 [INFO]: Finished training. The best model is from epoch#93.
2024-05-25 05:13:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240525_T051238/MRNN.pypots
2024-05-25 05:13:01 [INFO]: MRNN on ETTm1: MAE=0.6904, MSE=1.1878
2024-05-25 05:13:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-25 05:13:01 [INFO]: Using the given device: cpu
2024-05-25 05:13:01 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 05:13:01 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-25 05:13:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-25 05:13:01 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 05:13:01 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-25 05:13:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-25 05:13:01 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 05:13:01 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-25 05:13:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-25 05:13:01 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 05:13:01 [INFO]: Using the given device: cuda:0
2024-05-25 05:13:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T051301
2024-05-25 05:13:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T051301/tensorboard
2024-05-25 05:13:01 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 05:13:01 [INFO]: Epoch 001 - training loss: 1.1607, validation loss: 0.2409
2024-05-25 05:13:02 [INFO]: Epoch 002 - training loss: 0.8123, validation loss: 0.1646
2024-05-25 05:13:02 [INFO]: Epoch 003 - training loss: 0.7279, validation loss: 0.0996
2024-05-25 05:13:03 [INFO]: Epoch 004 - training loss: 0.6740, validation loss: 0.0861
2024-05-25 05:13:03 [INFO]: Epoch 005 - training loss: 0.6459, validation loss: 0.1179
2024-05-25 05:13:04 [INFO]: Epoch 006 - training loss: 0.6447, validation loss: 0.0793
2024-05-25 05:13:04 [INFO]: Epoch 007 - training loss: 0.6087, validation loss: 0.0627
2024-05-25 05:13:05 [INFO]: Epoch 008 - training loss: 0.5938, validation loss: 0.0739
2024-05-25 05:13:05 [INFO]: Epoch 009 - training loss: 0.5818, validation loss: 0.0633
2024-05-25 05:13:06 [INFO]: Epoch 010 - training loss: 0.5798, validation loss: 0.0587
2024-05-25 05:13:06 [INFO]: Epoch 011 - training loss: 0.5738, validation loss: 0.0693
2024-05-25 05:13:07 [INFO]: Epoch 012 - training loss: 0.5528, validation loss: 0.0664
2024-05-25 05:13:07 [INFO]: Epoch 013 - training loss: 0.5471, validation loss: 0.0645
2024-05-25 05:13:08 [INFO]: Epoch 014 - training loss: 0.5460, validation loss: 0.0545
2024-05-25 05:13:08 [INFO]: Epoch 015 - training loss: 0.5368, validation loss: 0.0508
2024-05-25 05:13:09 [INFO]: Epoch 016 - training loss: 0.5430, validation loss: 0.0595
2024-05-25 05:13:09 [INFO]: Epoch 017 - training loss: 0.5297, validation loss: 0.0441
2024-05-25 05:13:10 [INFO]: Epoch 018 - training loss: 0.5382, validation loss: 0.0559
2024-05-25 05:13:10 [INFO]: Epoch 019 - training loss: 0.5392, validation loss: 0.0566
2024-05-25 05:13:11 [INFO]: Epoch 020 - training loss: 0.5243, validation loss: 0.0502
2024-05-25 05:13:11 [INFO]: Epoch 021 - training loss: 0.5054, validation loss: 0.0488
2024-05-25 05:13:12 [INFO]: Epoch 022 - training loss: 0.5031, validation loss: 0.0394
2024-05-25 05:13:12 [INFO]: Epoch 023 - training loss: 0.4934, validation loss: 0.0450
2024-05-25 05:13:13 [INFO]: Epoch 024 - training loss: 0.4953, validation loss: 0.0443
2024-05-25 05:13:13 [INFO]: Epoch 025 - training loss: 0.5008, validation loss: 0.0551
2024-05-25 05:13:14 [INFO]: Epoch 026 - training loss: 0.4885, validation loss: 0.0478
2024-05-25 05:13:14 [INFO]: Epoch 027 - training loss: 0.4974, validation loss: 0.0476
2024-05-25 05:13:15 [INFO]: Epoch 028 - training loss: 0.4958, validation loss: 0.0561
2024-05-25 05:13:15 [INFO]: Epoch 029 - training loss: 0.4871, validation loss: 0.0569
2024-05-25 05:13:16 [INFO]: Epoch 030 - training loss: 0.4796, validation loss: 0.0576
2024-05-25 05:13:16 [INFO]: Epoch 031 - training loss: 0.4654, validation loss: 0.0376
2024-05-25 05:13:17 [INFO]: Epoch 032 - training loss: 0.4652, validation loss: 0.0382
2024-05-25 05:13:17 [INFO]: Epoch 033 - training loss: 0.4632, validation loss: 0.0516
2024-05-25 05:13:18 [INFO]: Epoch 034 - training loss: 0.4811, validation loss: 0.0448
2024-05-25 05:13:18 [INFO]: Epoch 035 - training loss: 0.4763, validation loss: 0.0460
2024-05-25 05:13:19 [INFO]: Epoch 036 - training loss: 0.4742, validation loss: 0.0426
2024-05-25 05:13:19 [INFO]: Epoch 037 - training loss: 0.4728, validation loss: 0.0405
2024-05-25 05:13:20 [INFO]: Epoch 038 - training loss: 0.4647, validation loss: 0.0415
2024-05-25 05:13:20 [INFO]: Epoch 039 - training loss: 0.4475, validation loss: 0.0510
2024-05-25 05:13:21 [INFO]: Epoch 040 - training loss: 0.4576, validation loss: 0.0385
2024-05-25 05:13:21 [INFO]: Epoch 041 - training loss: 0.4560, validation loss: 0.0360
2024-05-25 05:13:22 [INFO]: Epoch 042 - training loss: 0.4441, validation loss: 0.0421
2024-05-25 05:13:22 [INFO]: Epoch 043 - training loss: 0.4436, validation loss: 0.0400
2024-05-25 05:13:23 [INFO]: Epoch 044 - training loss: 0.4529, validation loss: 0.0328
2024-05-25 05:13:23 [INFO]: Epoch 045 - training loss: 0.4476, validation loss: 0.0335
2024-05-25 05:13:24 [INFO]: Epoch 046 - training loss: 0.4360, validation loss: 0.0463
2024-05-25 05:13:24 [INFO]: Epoch 047 - training loss: 0.4392, validation loss: 0.0575
2024-05-25 05:13:25 [INFO]: Epoch 048 - training loss: 0.4626, validation loss: 0.0517
2024-05-25 05:13:25 [INFO]: Epoch 049 - training loss: 0.4307, validation loss: 0.0373
2024-05-25 05:13:25 [INFO]: Epoch 050 - training loss: 0.4483, validation loss: 0.0426
2024-05-25 05:13:26 [INFO]: Epoch 051 - training loss: 0.4215, validation loss: 0.0322
2024-05-25 05:13:26 [INFO]: Epoch 052 - training loss: 0.4177, validation loss: 0.0335
2024-05-25 05:13:27 [INFO]: Epoch 053 - training loss: 0.4232, validation loss: 0.0418
2024-05-25 05:13:27 [INFO]: Epoch 054 - training loss: 0.4202, validation loss: 0.0437
2024-05-25 05:13:28 [INFO]: Epoch 055 - training loss: 0.4150, validation loss: 0.0373
2024-05-25 05:13:28 [INFO]: Epoch 056 - training loss: 0.4220, validation loss: 0.0353
2024-05-25 05:13:29 [INFO]: Epoch 057 - training loss: 0.4134, validation loss: 0.0344
2024-05-25 05:13:29 [INFO]: Epoch 058 - training loss: 0.3990, validation loss: 0.0324
2024-05-25 05:13:30 [INFO]: Epoch 059 - training loss: 0.3989, validation loss: 0.0431
2024-05-25 05:13:30 [INFO]: Epoch 060 - training loss: 0.4043, validation loss: 0.0357
2024-05-25 05:13:31 [INFO]: Epoch 061 - training loss: 0.4086, validation loss: 0.0311
2024-05-25 05:13:31 [INFO]: Epoch 062 - training loss: 0.3950, validation loss: 0.0310
2024-05-25 05:13:32 [INFO]: Epoch 063 - training loss: 0.3992, validation loss: 0.0516
2024-05-25 05:13:32 [INFO]: Epoch 064 - training loss: 0.3935, validation loss: 0.0286
2024-05-25 05:13:33 [INFO]: Epoch 065 - training loss: 0.3931, validation loss: 0.0367
2024-05-25 05:13:33 [INFO]: Epoch 066 - training loss: 0.3900, validation loss: 0.0278
2024-05-25 05:13:34 [INFO]: Epoch 067 - training loss: 0.3847, validation loss: 0.0440
2024-05-25 05:13:34 [INFO]: Epoch 068 - training loss: 0.4191, validation loss: 0.0470
2024-05-25 05:13:35 [INFO]: Epoch 069 - training loss: 0.4050, validation loss: 0.0361
2024-05-25 05:13:35 [INFO]: Epoch 070 - training loss: 0.3967, validation loss: 0.0318
2024-05-25 05:13:36 [INFO]: Epoch 071 - training loss: 0.3877, validation loss: 0.0308
2024-05-25 05:13:36 [INFO]: Epoch 072 - training loss: 0.3785, validation loss: 0.0405
2024-05-25 05:13:37 [INFO]: Epoch 073 - training loss: 0.3831, validation loss: 0.0355
2024-05-25 05:13:37 [INFO]: Epoch 074 - training loss: 0.3879, validation loss: 0.0360
2024-05-25 05:13:38 [INFO]: Epoch 075 - training loss: 0.3821, validation loss: 0.0311
2024-05-25 05:13:38 [INFO]: Epoch 076 - training loss: 0.3726, validation loss: 0.0304
2024-05-25 05:13:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:13:38 [INFO]: Finished training. The best model is from epoch#66.
2024-05-25 05:13:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_ettm1/20240525_T051301/SAITS.pypots
2024-05-25 05:13:38 [INFO]: SAITS on ETTm1: MAE=0.1373, MSE=0.0379
2024-05-25 05:13:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-25 05:13:38 [INFO]: Using the given device: cuda:0
2024-05-25 05:13:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T051338
2024-05-25 05:13:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T051338/tensorboard
2024-05-25 05:13:39 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 05:13:39 [INFO]: Epoch 001 - training loss: 1.1976, validation loss: 0.3229
2024-05-25 05:13:39 [INFO]: Epoch 002 - training loss: 0.6846, validation loss: 0.1362
2024-05-25 05:13:39 [INFO]: Epoch 003 - training loss: 0.5324, validation loss: 0.1010
2024-05-25 05:13:39 [INFO]: Epoch 004 - training loss: 0.4735, validation loss: 0.0797
2024-05-25 05:13:40 [INFO]: Epoch 005 - training loss: 0.4419, validation loss: 0.0723
2024-05-25 05:13:40 [INFO]: Epoch 006 - training loss: 0.4228, validation loss: 0.0657
2024-05-25 05:13:40 [INFO]: Epoch 007 - training loss: 0.3970, validation loss: 0.0619
2024-05-25 05:13:40 [INFO]: Epoch 008 - training loss: 0.3942, validation loss: 0.0569
2024-05-25 05:13:40 [INFO]: Epoch 009 - training loss: 0.3794, validation loss: 0.0599
2024-05-25 05:13:41 [INFO]: Epoch 010 - training loss: 0.3716, validation loss: 0.0518
2024-05-25 05:13:41 [INFO]: Epoch 011 - training loss: 0.3618, validation loss: 0.0516
2024-05-25 05:13:41 [INFO]: Epoch 012 - training loss: 0.3549, validation loss: 0.0481
2024-05-25 05:13:41 [INFO]: Epoch 013 - training loss: 0.3419, validation loss: 0.0466
2024-05-25 05:13:41 [INFO]: Epoch 014 - training loss: 0.3368, validation loss: 0.0485
2024-05-25 05:13:41 [INFO]: Epoch 015 - training loss: 0.3308, validation loss: 0.0490
2024-05-25 05:13:42 [INFO]: Epoch 016 - training loss: 0.3329, validation loss: 0.0464
2024-05-25 05:13:42 [INFO]: Epoch 017 - training loss: 0.3313, validation loss: 0.0450
2024-05-25 05:13:42 [INFO]: Epoch 018 - training loss: 0.3205, validation loss: 0.0418
2024-05-25 05:13:42 [INFO]: Epoch 019 - training loss: 0.3218, validation loss: 0.0485
2024-05-25 05:13:42 [INFO]: Epoch 020 - training loss: 0.3250, validation loss: 0.0411
2024-05-25 05:13:43 [INFO]: Epoch 021 - training loss: 0.3045, validation loss: 0.0406
2024-05-25 05:13:43 [INFO]: Epoch 022 - training loss: 0.3011, validation loss: 0.0392
2024-05-25 05:13:43 [INFO]: Epoch 023 - training loss: 0.2997, validation loss: 0.0400
2024-05-25 05:13:43 [INFO]: Epoch 024 - training loss: 0.2926, validation loss: 0.0385
2024-05-25 05:13:43 [INFO]: Epoch 025 - training loss: 0.2945, validation loss: 0.0358
2024-05-25 05:13:44 [INFO]: Epoch 026 - training loss: 0.2836, validation loss: 0.0368
2024-05-25 05:13:44 [INFO]: Epoch 027 - training loss: 0.2849, validation loss: 0.0386
2024-05-25 05:13:44 [INFO]: Epoch 028 - training loss: 0.2862, validation loss: 0.0448
2024-05-25 05:13:44 [INFO]: Epoch 029 - training loss: 0.2858, validation loss: 0.0344
2024-05-25 05:13:44 [INFO]: Epoch 030 - training loss: 0.2719, validation loss: 0.0328
2024-05-25 05:13:45 [INFO]: Epoch 031 - training loss: 0.2718, validation loss: 0.0324
2024-05-25 05:13:45 [INFO]: Epoch 032 - training loss: 0.2710, validation loss: 0.0345
2024-05-25 05:13:45 [INFO]: Epoch 033 - training loss: 0.2678, validation loss: 0.0304
2024-05-25 05:13:45 [INFO]: Epoch 034 - training loss: 0.2587, validation loss: 0.0334
2024-05-25 05:13:45 [INFO]: Epoch 035 - training loss: 0.2616, validation loss: 0.0318
2024-05-25 05:13:46 [INFO]: Epoch 036 - training loss: 0.2590, validation loss: 0.0298
2024-05-25 05:13:46 [INFO]: Epoch 037 - training loss: 0.2605, validation loss: 0.0367
2024-05-25 05:13:46 [INFO]: Epoch 038 - training loss: 0.2635, validation loss: 0.0331
2024-05-25 05:13:46 [INFO]: Epoch 039 - training loss: 0.2657, validation loss: 0.0313
2024-05-25 05:13:46 [INFO]: Epoch 040 - training loss: 0.2517, validation loss: 0.0354
2024-05-25 05:13:47 [INFO]: Epoch 041 - training loss: 0.2580, validation loss: 0.0322
2024-05-25 05:13:47 [INFO]: Epoch 042 - training loss: 0.2540, validation loss: 0.0315
2024-05-25 05:13:47 [INFO]: Epoch 043 - training loss: 0.2597, validation loss: 0.0326
2024-05-25 05:13:47 [INFO]: Epoch 044 - training loss: 0.2654, validation loss: 0.0312
2024-05-25 05:13:47 [INFO]: Epoch 045 - training loss: 0.2542, validation loss: 0.0315
2024-05-25 05:13:48 [INFO]: Epoch 046 - training loss: 0.2542, validation loss: 0.0291
2024-05-25 05:13:48 [INFO]: Epoch 047 - training loss: 0.2426, validation loss: 0.0298
2024-05-25 05:13:48 [INFO]: Epoch 048 - training loss: 0.2447, validation loss: 0.0304
2024-05-25 05:13:48 [INFO]: Epoch 049 - training loss: 0.2477, validation loss: 0.0281
2024-05-25 05:13:48 [INFO]: Epoch 050 - training loss: 0.2334, validation loss: 0.0283
2024-05-25 05:13:49 [INFO]: Epoch 051 - training loss: 0.2337, validation loss: 0.0288
2024-05-25 05:13:49 [INFO]: Epoch 052 - training loss: 0.2321, validation loss: 0.0315
2024-05-25 05:13:49 [INFO]: Epoch 053 - training loss: 0.2446, validation loss: 0.0334
2024-05-25 05:13:49 [INFO]: Epoch 054 - training loss: 0.2357, validation loss: 0.0306
2024-05-25 05:13:49 [INFO]: Epoch 055 - training loss: 0.2305, validation loss: 0.0297
2024-05-25 05:13:50 [INFO]: Epoch 056 - training loss: 0.2296, validation loss: 0.0283
2024-05-25 05:13:50 [INFO]: Epoch 057 - training loss: 0.2366, validation loss: 0.0279
2024-05-25 05:13:50 [INFO]: Epoch 058 - training loss: 0.2277, validation loss: 0.0271
2024-05-25 05:13:50 [INFO]: Epoch 059 - training loss: 0.2274, validation loss: 0.0278
2024-05-25 05:13:50 [INFO]: Epoch 060 - training loss: 0.2256, validation loss: 0.0266
2024-05-25 05:13:51 [INFO]: Epoch 061 - training loss: 0.2194, validation loss: 0.0272
2024-05-25 05:13:51 [INFO]: Epoch 062 - training loss: 0.2188, validation loss: 0.0294
2024-05-25 05:13:51 [INFO]: Epoch 063 - training loss: 0.2228, validation loss: 0.0262
2024-05-25 05:13:51 [INFO]: Epoch 064 - training loss: 0.2162, validation loss: 0.0315
2024-05-25 05:13:51 [INFO]: Epoch 065 - training loss: 0.2255, validation loss: 0.0276
2024-05-25 05:13:52 [INFO]: Epoch 066 - training loss: 0.2170, validation loss: 0.0282
2024-05-25 05:13:52 [INFO]: Epoch 067 - training loss: 0.2220, validation loss: 0.0262
2024-05-25 05:13:52 [INFO]: Epoch 068 - training loss: 0.2154, validation loss: 0.0282
2024-05-25 05:13:52 [INFO]: Epoch 069 - training loss: 0.2173, validation loss: 0.0272
2024-05-25 05:13:52 [INFO]: Epoch 070 - training loss: 0.2232, validation loss: 0.0285
2024-05-25 05:13:53 [INFO]: Epoch 071 - training loss: 0.2214, validation loss: 0.0267
2024-05-25 05:13:53 [INFO]: Epoch 072 - training loss: 0.2160, validation loss: 0.0249
2024-05-25 05:13:53 [INFO]: Epoch 073 - training loss: 0.2074, validation loss: 0.0239
2024-05-25 05:13:53 [INFO]: Epoch 074 - training loss: 0.2111, validation loss: 0.0262
2024-05-25 05:13:53 [INFO]: Epoch 075 - training loss: 0.2138, validation loss: 0.0291
2024-05-25 05:13:54 [INFO]: Epoch 076 - training loss: 0.2121, validation loss: 0.0257
2024-05-25 05:13:54 [INFO]: Epoch 077 - training loss: 0.2023, validation loss: 0.0279
2024-05-25 05:13:54 [INFO]: Epoch 078 - training loss: 0.2027, validation loss: 0.0247
2024-05-25 05:13:54 [INFO]: Epoch 079 - training loss: 0.2004, validation loss: 0.0292
2024-05-25 05:13:54 [INFO]: Epoch 080 - training loss: 0.2096, validation loss: 0.0286
2024-05-25 05:13:55 [INFO]: Epoch 081 - training loss: 0.2089, validation loss: 0.0280
2024-05-25 05:13:55 [INFO]: Epoch 082 - training loss: 0.2105, validation loss: 0.0272
2024-05-25 05:13:55 [INFO]: Epoch 083 - training loss: 0.2084, validation loss: 0.0256
2024-05-25 05:13:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:13:55 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 05:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_ettm1/20240525_T051338/Transformer.pypots
2024-05-25 05:13:55 [INFO]: Transformer on ETTm1: MAE=0.1336, MSE=0.0362
2024-05-25 05:13:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-25 05:13:55 [INFO]: Using the given device: cuda:0
2024-05-25 05:13:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T051355
2024-05-25 05:13:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T051355/tensorboard
2024-05-25 05:13:55 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 05:13:55 [INFO]: Epoch 001 - training loss: 0.1566, validation loss: 0.0594
2024-05-25 05:13:56 [INFO]: Epoch 002 - training loss: 0.0675, validation loss: 0.0442
2024-05-25 05:13:56 [INFO]: Epoch 003 - training loss: 0.0504, validation loss: 0.0360
2024-05-25 05:13:56 [INFO]: Epoch 004 - training loss: 0.0425, validation loss: 0.0322
2024-05-25 05:13:56 [INFO]: Epoch 005 - training loss: 0.0384, validation loss: 0.0290
2024-05-25 05:13:56 [INFO]: Epoch 006 - training loss: 0.0334, validation loss: 0.0276
2024-05-25 05:13:57 [INFO]: Epoch 007 - training loss: 0.0312, validation loss: 0.0256
2024-05-25 05:13:57 [INFO]: Epoch 008 - training loss: 0.0329, validation loss: 0.0276
2024-05-25 05:13:57 [INFO]: Epoch 009 - training loss: 0.0385, validation loss: 0.0282
2024-05-25 05:13:57 [INFO]: Epoch 010 - training loss: 0.0367, validation loss: 0.0274
2024-05-25 05:13:57 [INFO]: Epoch 011 - training loss: 0.0294, validation loss: 0.0242
2024-05-25 05:13:58 [INFO]: Epoch 012 - training loss: 0.0256, validation loss: 0.0233
2024-05-25 05:13:58 [INFO]: Epoch 013 - training loss: 0.0246, validation loss: 0.0229
2024-05-25 05:13:58 [INFO]: Epoch 014 - training loss: 0.0256, validation loss: 0.0244
2024-05-25 05:13:58 [INFO]: Epoch 015 - training loss: 0.0294, validation loss: 0.0243
2024-05-25 05:13:58 [INFO]: Epoch 016 - training loss: 0.0270, validation loss: 0.0228
2024-05-25 05:13:58 [INFO]: Epoch 017 - training loss: 0.0248, validation loss: 0.0235
2024-05-25 05:13:59 [INFO]: Epoch 018 - training loss: 0.0248, validation loss: 0.0251
2024-05-25 05:13:59 [INFO]: Epoch 019 - training loss: 0.0251, validation loss: 0.0224
2024-05-25 05:13:59 [INFO]: Epoch 020 - training loss: 0.0237, validation loss: 0.0238
2024-05-25 05:13:59 [INFO]: Epoch 021 - training loss: 0.0259, validation loss: 0.0265
2024-05-25 05:13:59 [INFO]: Epoch 022 - training loss: 0.0284, validation loss: 0.0241
2024-05-25 05:14:00 [INFO]: Epoch 023 - training loss: 0.0279, validation loss: 0.0225
2024-05-25 05:14:00 [INFO]: Epoch 024 - training loss: 0.0231, validation loss: 0.0239
2024-05-25 05:14:00 [INFO]: Epoch 025 - training loss: 0.0207, validation loss: 0.0222
2024-05-25 05:14:00 [INFO]: Epoch 026 - training loss: 0.0194, validation loss: 0.0226
2024-05-25 05:14:00 [INFO]: Epoch 027 - training loss: 0.0195, validation loss: 0.0228
2024-05-25 05:14:01 [INFO]: Epoch 028 - training loss: 0.0197, validation loss: 0.0218
2024-05-25 05:14:01 [INFO]: Epoch 029 - training loss: 0.0195, validation loss: 0.0222
2024-05-25 05:14:01 [INFO]: Epoch 030 - training loss: 0.0183, validation loss: 0.0217
2024-05-25 05:14:01 [INFO]: Epoch 031 - training loss: 0.0184, validation loss: 0.0214
2024-05-25 05:14:01 [INFO]: Epoch 032 - training loss: 0.0189, validation loss: 0.0218
2024-05-25 05:14:02 [INFO]: Epoch 033 - training loss: 0.0181, validation loss: 0.0225
2024-05-25 05:14:02 [INFO]: Epoch 034 - training loss: 0.0211, validation loss: 0.0262
2024-05-25 05:14:02 [INFO]: Epoch 035 - training loss: 0.0218, validation loss: 0.0233
2024-05-25 05:14:02 [INFO]: Epoch 036 - training loss: 0.0183, validation loss: 0.0231
2024-05-25 05:14:02 [INFO]: Epoch 037 - training loss: 0.0193, validation loss: 0.0231
2024-05-25 05:14:02 [INFO]: Epoch 038 - training loss: 0.0194, validation loss: 0.0228
2024-05-25 05:14:03 [INFO]: Epoch 039 - training loss: 0.0209, validation loss: 0.0238
2024-05-25 05:14:03 [INFO]: Epoch 040 - training loss: 0.0183, validation loss: 0.0220
2024-05-25 05:14:03 [INFO]: Epoch 041 - training loss: 0.0162, validation loss: 0.0228
2024-05-25 05:14:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:14:03 [INFO]: Finished training. The best model is from epoch#31.
2024-05-25 05:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240525_T051355/TimesNet.pypots
2024-05-25 05:14:03 [INFO]: TimesNet on ETTm1: MAE=0.1014, MSE=0.0220
2024-05-25 05:14:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-25 05:14:03 [INFO]: Using the given device: cuda:0
2024-05-25 05:14:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403
2024-05-25 05:14:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/tensorboard
2024-05-25 05:14:03 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 05:14:05 [INFO]: Epoch 001 - training loss: 0.7208, validation loss: 0.4563
2024-05-25 05:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch1_loss0.45631837844848633.pypots
2024-05-25 05:14:07 [INFO]: Epoch 002 - training loss: 0.4754, validation loss: 0.3981
2024-05-25 05:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch2_loss0.3980775624513626.pypots
2024-05-25 05:14:09 [INFO]: Epoch 003 - training loss: 0.3397, validation loss: 0.3282
2024-05-25 05:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch3_loss0.3281962648034096.pypots
2024-05-25 05:14:11 [INFO]: Epoch 004 - training loss: 0.3045, validation loss: 0.2995
2024-05-25 05:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch4_loss0.2995443344116211.pypots
2024-05-25 05:14:13 [INFO]: Epoch 005 - training loss: 0.3431, validation loss: 0.2911
2024-05-25 05:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch5_loss0.2910778522491455.pypots
2024-05-25 05:14:15 [INFO]: Epoch 006 - training loss: 0.3883, validation loss: 0.3279
2024-05-25 05:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch6_loss0.32792457938194275.pypots
2024-05-25 05:14:18 [INFO]: Epoch 007 - training loss: 0.3367, validation loss: 0.3174
2024-05-25 05:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch7_loss0.317360021173954.pypots
2024-05-25 05:14:20 [INFO]: Epoch 008 - training loss: 0.3636, validation loss: 0.2906
2024-05-25 05:14:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch8_loss0.29055921733379364.pypots
2024-05-25 05:14:22 [INFO]: Epoch 009 - training loss: 0.2779, validation loss: 0.2619
2024-05-25 05:14:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch9_loss0.2619192972779274.pypots
2024-05-25 05:14:24 [INFO]: Epoch 010 - training loss: 0.2723, validation loss: 0.2516
2024-05-25 05:14:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch10_loss0.2515856884419918.pypots
2024-05-25 05:14:26 [INFO]: Epoch 011 - training loss: 0.2857, validation loss: 0.2560
2024-05-25 05:14:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch11_loss0.25603701919317245.pypots
2024-05-25 05:14:28 [INFO]: Epoch 012 - training loss: 0.2267, validation loss: 0.2415
2024-05-25 05:14:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch12_loss0.2414853200316429.pypots
2024-05-25 05:14:30 [INFO]: Epoch 013 - training loss: 0.2379, validation loss: 0.2397
2024-05-25 05:14:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch13_loss0.23974155634641647.pypots
2024-05-25 05:14:32 [INFO]: Epoch 014 - training loss: 0.2614, validation loss: 0.2434
2024-05-25 05:14:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch14_loss0.2434290461242199.pypots
2024-05-25 05:14:34 [INFO]: Epoch 015 - training loss: 0.2494, validation loss: 0.2302
2024-05-25 05:14:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch15_loss0.23024697601795197.pypots
2024-05-25 05:14:36 [INFO]: Epoch 016 - training loss: 0.3317, validation loss: 0.2611
2024-05-25 05:14:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch16_loss0.26108527183532715.pypots
2024-05-25 05:14:38 [INFO]: Epoch 017 - training loss: 0.2925, validation loss: 0.2729
2024-05-25 05:14:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch17_loss0.272880882024765.pypots
2024-05-25 05:14:40 [INFO]: Epoch 018 - training loss: 0.3065, validation loss: 0.2457
2024-05-25 05:14:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch18_loss0.245718851685524.pypots
2024-05-25 05:14:42 [INFO]: Epoch 019 - training loss: 0.2710, validation loss: 0.2333
2024-05-25 05:14:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch19_loss0.23328585177659988.pypots
2024-05-25 05:14:44 [INFO]: Epoch 020 - training loss: 0.2326, validation loss: 0.2190
2024-05-25 05:14:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch20_loss0.2190045677125454.pypots
2024-05-25 05:14:46 [INFO]: Epoch 021 - training loss: 0.2300, validation loss: 0.2370
2024-05-25 05:14:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch21_loss0.2370425909757614.pypots
2024-05-25 05:14:48 [INFO]: Epoch 022 - training loss: 0.2270, validation loss: 0.2200
2024-05-25 05:14:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch22_loss0.21999350935220718.pypots
2024-05-25 05:14:50 [INFO]: Epoch 023 - training loss: 0.2056, validation loss: 0.2006
2024-05-25 05:14:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch23_loss0.2006474956870079.pypots
2024-05-25 05:14:52 [INFO]: Epoch 024 - training loss: 0.1968, validation loss: 0.1954
2024-05-25 05:14:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch24_loss0.1954081691801548.pypots
2024-05-25 05:14:55 [INFO]: Epoch 025 - training loss: 0.2094, validation loss: 0.1999
2024-05-25 05:14:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch25_loss0.1999397799372673.pypots
2024-05-25 05:14:57 [INFO]: Epoch 026 - training loss: 0.2259, validation loss: 0.1959
2024-05-25 05:14:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch26_loss0.19590665772557259.pypots
2024-05-25 05:14:59 [INFO]: Epoch 027 - training loss: 0.2446, validation loss: 0.2017
2024-05-25 05:14:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch27_loss0.2017158679664135.pypots
2024-05-25 05:15:01 [INFO]: Epoch 028 - training loss: 0.2708, validation loss: 0.2062
2024-05-25 05:15:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch28_loss0.20620577037334442.pypots
2024-05-25 05:15:03 [INFO]: Epoch 029 - training loss: 0.2180, validation loss: 0.2060
2024-05-25 05:15:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch29_loss0.2059660330414772.pypots
2024-05-25 05:15:05 [INFO]: Epoch 030 - training loss: 0.1852, validation loss: 0.1926
2024-05-25 05:15:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch30_loss0.19261503592133522.pypots
2024-05-25 05:15:07 [INFO]: Epoch 031 - training loss: 0.1983, validation loss: 0.1943
2024-05-25 05:15:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch31_loss0.19430601596832275.pypots
2024-05-25 05:15:09 [INFO]: Epoch 032 - training loss: 0.2273, validation loss: 0.1975
2024-05-25 05:15:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch32_loss0.19745474308729172.pypots
2024-05-25 05:15:11 [INFO]: Epoch 033 - training loss: 0.2039, validation loss: 0.1840
2024-05-25 05:15:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch33_loss0.18404123187065125.pypots
2024-05-25 05:15:13 [INFO]: Epoch 034 - training loss: 0.1893, validation loss: 0.1926
2024-05-25 05:15:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch34_loss0.1926034539937973.pypots
2024-05-25 05:15:15 [INFO]: Epoch 035 - training loss: 0.2173, validation loss: 0.1817
2024-05-25 05:15:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch35_loss0.18173746019601822.pypots
2024-05-25 05:15:17 [INFO]: Epoch 036 - training loss: 0.2105, validation loss: 0.1867
2024-05-25 05:15:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch36_loss0.18672339990735054.pypots
2024-05-25 05:15:19 [INFO]: Epoch 037 - training loss: 0.2051, validation loss: 0.1746
2024-05-25 05:15:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch37_loss0.17464709281921387.pypots
2024-05-25 05:15:21 [INFO]: Epoch 038 - training loss: 0.1469, validation loss: 0.1654
2024-05-25 05:15:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch38_loss0.1653822846710682.pypots
2024-05-25 05:15:23 [INFO]: Epoch 039 - training loss: 0.2168, validation loss: 0.1687
2024-05-25 05:15:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch39_loss0.16873824223876.pypots
2024-05-25 05:15:25 [INFO]: Epoch 040 - training loss: 0.2678, validation loss: 0.1875
2024-05-25 05:15:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch40_loss0.18745378032326698.pypots
2024-05-25 05:15:27 [INFO]: Epoch 041 - training loss: 0.2140, validation loss: 0.1860
2024-05-25 05:15:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch41_loss0.18595276400446892.pypots
2024-05-25 05:15:29 [INFO]: Epoch 042 - training loss: 0.2014, validation loss: 0.1773
2024-05-25 05:15:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch42_loss0.17730383202433586.pypots
2024-05-25 05:15:31 [INFO]: Epoch 043 - training loss: 0.1821, validation loss: 0.1689
2024-05-25 05:15:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch43_loss0.16890398785471916.pypots
2024-05-25 05:15:34 [INFO]: Epoch 044 - training loss: 0.1744, validation loss: 0.1615
2024-05-25 05:15:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch44_loss0.16151801496744156.pypots
2024-05-25 05:15:36 [INFO]: Epoch 045 - training loss: 0.1816, validation loss: 0.1622
2024-05-25 05:15:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch45_loss0.1621670238673687.pypots
2024-05-25 05:15:38 [INFO]: Epoch 046 - training loss: 0.1630, validation loss: 0.1587
2024-05-25 05:15:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch46_loss0.15874836593866348.pypots
2024-05-25 05:15:40 [INFO]: Epoch 047 - training loss: 0.2233, validation loss: 0.1695
2024-05-25 05:15:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch47_loss0.16952156648039818.pypots
2024-05-25 05:15:42 [INFO]: Epoch 048 - training loss: 0.2050, validation loss: 0.1822
2024-05-25 05:15:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch48_loss0.1821514256298542.pypots
2024-05-25 05:15:44 [INFO]: Epoch 049 - training loss: 0.1962, validation loss: 0.1745
2024-05-25 05:15:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch49_loss0.17451999709010124.pypots
2024-05-25 05:15:46 [INFO]: Epoch 050 - training loss: 0.1848, validation loss: 0.1695
2024-05-25 05:15:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch50_loss0.16951575130224228.pypots
2024-05-25 05:15:48 [INFO]: Epoch 051 - training loss: 0.1717, validation loss: 0.1602
2024-05-25 05:15:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch51_loss0.16023410111665726.pypots
2024-05-25 05:15:50 [INFO]: Epoch 052 - training loss: 0.1475, validation loss: 0.1568
2024-05-25 05:15:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch52_loss0.1568184830248356.pypots
2024-05-25 05:15:52 [INFO]: Epoch 053 - training loss: 0.1629, validation loss: 0.1495
2024-05-25 05:15:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch53_loss0.14952781423926353.pypots
2024-05-25 05:15:54 [INFO]: Epoch 054 - training loss: 0.1582, validation loss: 0.1481
2024-05-25 05:15:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch54_loss0.14813188463449478.pypots
2024-05-25 05:15:56 [INFO]: Epoch 055 - training loss: 0.1478, validation loss: 0.1485
2024-05-25 05:15:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch55_loss0.14846619963645935.pypots
2024-05-25 05:15:58 [INFO]: Epoch 056 - training loss: 0.1575, validation loss: 0.1466
2024-05-25 05:15:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch56_loss0.146636750549078.pypots
2024-05-25 05:16:00 [INFO]: Epoch 057 - training loss: 0.1650, validation loss: 0.1483
2024-05-25 05:16:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch57_loss0.14832568168640137.pypots
2024-05-25 05:16:02 [INFO]: Epoch 058 - training loss: 0.1487, validation loss: 0.1409
2024-05-25 05:16:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch58_loss0.14091378077864647.pypots
2024-05-25 05:16:04 [INFO]: Epoch 059 - training loss: 0.1647, validation loss: 0.1426
2024-05-25 05:16:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch59_loss0.1426033228635788.pypots
2024-05-25 05:16:06 [INFO]: Epoch 060 - training loss: 0.1519, validation loss: 0.1508
2024-05-25 05:16:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch60_loss0.15083762630820274.pypots
2024-05-25 05:16:08 [INFO]: Epoch 061 - training loss: 0.1454, validation loss: 0.1484
2024-05-25 05:16:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch61_loss0.14843234047293663.pypots
2024-05-25 05:16:11 [INFO]: Epoch 062 - training loss: 0.1643, validation loss: 0.1449
2024-05-25 05:16:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch62_loss0.14488929137587547.pypots
2024-05-25 05:16:13 [INFO]: Epoch 063 - training loss: 0.1547, validation loss: 0.1408
2024-05-25 05:16:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch63_loss0.14075661450624466.pypots
2024-05-25 05:16:15 [INFO]: Epoch 064 - training loss: 0.1493, validation loss: 0.1407
2024-05-25 05:16:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch64_loss0.14074622467160225.pypots
2024-05-25 05:16:17 [INFO]: Epoch 065 - training loss: 0.1782, validation loss: 0.1447
2024-05-25 05:16:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch65_loss0.14469243213534355.pypots
2024-05-25 05:16:19 [INFO]: Epoch 066 - training loss: 0.1452, validation loss: 0.1495
2024-05-25 05:16:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch66_loss0.14951282739639282.pypots
2024-05-25 05:16:21 [INFO]: Epoch 067 - training loss: 0.1587, validation loss: 0.1461
2024-05-25 05:16:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch67_loss0.1460748314857483.pypots
2024-05-25 05:16:23 [INFO]: Epoch 068 - training loss: 0.1506, validation loss: 0.1419
2024-05-25 05:16:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch68_loss0.14188531786203384.pypots
2024-05-25 05:16:25 [INFO]: Epoch 069 - training loss: 0.1723, validation loss: 0.1401
2024-05-25 05:16:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch69_loss0.14007726311683655.pypots
2024-05-25 05:16:27 [INFO]: Epoch 070 - training loss: 0.1375, validation loss: 0.1356
2024-05-25 05:16:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch70_loss0.13561448082327843.pypots
2024-05-25 05:16:29 [INFO]: Epoch 071 - training loss: 0.1770, validation loss: 0.1828
2024-05-25 05:16:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch71_loss0.18275998532772064.pypots
2024-05-25 05:16:31 [INFO]: Epoch 072 - training loss: 0.1985, validation loss: 0.1818
2024-05-25 05:16:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch72_loss0.18179909139871597.pypots
2024-05-25 05:16:33 [INFO]: Epoch 073 - training loss: 0.1790, validation loss: 0.1563
2024-05-25 05:16:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch73_loss0.15630316361784935.pypots
2024-05-25 05:16:35 [INFO]: Epoch 074 - training loss: 0.1715, validation loss: 0.1515
2024-05-25 05:16:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch74_loss0.1515319086611271.pypots
2024-05-25 05:16:37 [INFO]: Epoch 075 - training loss: 0.1718, validation loss: 0.1404
2024-05-25 05:16:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch75_loss0.1404152624309063.pypots
2024-05-25 05:16:39 [INFO]: Epoch 076 - training loss: 0.1324, validation loss: 0.1412
2024-05-25 05:16:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch76_loss0.14116448163986206.pypots
2024-05-25 05:16:41 [INFO]: Epoch 077 - training loss: 0.1710, validation loss: 0.1468
2024-05-25 05:16:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch77_loss0.14682289212942123.pypots
2024-05-25 05:16:43 [INFO]: Epoch 078 - training loss: 0.1370, validation loss: 0.1573
2024-05-25 05:16:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch78_loss0.15733994916081429.pypots
2024-05-25 05:16:45 [INFO]: Epoch 079 - training loss: 0.1666, validation loss: 0.1504
2024-05-25 05:16:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch79_loss0.15038597211241722.pypots
2024-05-25 05:16:47 [INFO]: Epoch 080 - training loss: 0.1393, validation loss: 0.1513
2024-05-25 05:16:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI_epoch80_loss0.15134436637163162.pypots
2024-05-25 05:16:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:16:47 [INFO]: Finished training. The best model is from epoch#70.
2024-05-25 05:16:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240525_T051403/CSDI.pypots
2024-05-25 05:17:03 [INFO]: CSDI on ETTm1: MAE=0.1424, MSE=0.0469
2024-05-25 05:17:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-25 05:17:03 [INFO]: Using the given device: cuda:0
2024-05-25 05:17:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T051703
2024-05-25 05:17:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T051703/tensorboard
2024-05-25 05:17:03 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 05:17:04 [INFO]: Epoch 001 - training loss: 23893.2013, validation loss: 0.9542
2024-05-25 05:17:04 [INFO]: Epoch 002 - training loss: 21770.4624, validation loss: 0.9481
2024-05-25 05:17:04 [INFO]: Epoch 003 - training loss: 19728.8523, validation loss: 0.9378
2024-05-25 05:17:04 [INFO]: Epoch 004 - training loss: 17736.6808, validation loss: 0.9099
2024-05-25 05:17:04 [INFO]: Epoch 005 - training loss: 15968.3309, validation loss: 0.8528
2024-05-25 05:17:04 [INFO]: Epoch 006 - training loss: 14195.8718, validation loss: 0.7597
2024-05-25 05:17:04 [INFO]: Epoch 007 - training loss: 12910.2325, validation loss: 0.6669
2024-05-25 05:17:05 [INFO]: Epoch 008 - training loss: 12020.6019, validation loss: 0.6032
2024-05-25 05:17:05 [INFO]: Epoch 009 - training loss: 11419.0904, validation loss: 0.5166
2024-05-25 05:17:05 [INFO]: Epoch 010 - training loss: 10995.7839, validation loss: 0.4703
2024-05-25 05:17:05 [INFO]: Epoch 011 - training loss: 10750.2671, validation loss: 0.4568
2024-05-25 05:17:05 [INFO]: Epoch 012 - training loss: 10387.2914, validation loss: 0.4373
2024-05-25 05:17:05 [INFO]: Epoch 013 - training loss: 10243.0059, validation loss: 0.4207
2024-05-25 05:17:05 [INFO]: Epoch 014 - training loss: 10143.8203, validation loss: 0.4063
2024-05-25 05:17:06 [INFO]: Epoch 015 - training loss: 10068.9198, validation loss: 0.3901
2024-05-25 05:17:06 [INFO]: Epoch 016 - training loss: 9903.5068, validation loss: 0.3738
2024-05-25 05:17:06 [INFO]: Epoch 017 - training loss: 9865.3439, validation loss: 0.3635
2024-05-25 05:17:06 [INFO]: Epoch 018 - training loss: 9809.6053, validation loss: 0.3492
2024-05-25 05:17:06 [INFO]: Epoch 019 - training loss: 9814.7988, validation loss: 0.3367
2024-05-25 05:17:06 [INFO]: Epoch 020 - training loss: 9716.5234, validation loss: 0.3219
2024-05-25 05:17:06 [INFO]: Epoch 021 - training loss: 9659.4083, validation loss: 0.3097
2024-05-25 05:17:07 [INFO]: Epoch 022 - training loss: 9647.1403, validation loss: 0.3070
2024-05-25 05:17:07 [INFO]: Epoch 023 - training loss: 9610.1827, validation loss: 0.2929
2024-05-25 05:17:07 [INFO]: Epoch 024 - training loss: 9610.1404, validation loss: 0.2761
2024-05-25 05:17:07 [INFO]: Epoch 025 - training loss: 9563.0405, validation loss: 0.2646
2024-05-25 05:17:07 [INFO]: Epoch 026 - training loss: 9562.0566, validation loss: 0.2499
2024-05-25 05:17:07 [INFO]: Epoch 027 - training loss: 9533.6464, validation loss: 0.2383
2024-05-25 05:17:07 [INFO]: Epoch 028 - training loss: 9536.6938, validation loss: 0.2320
2024-05-25 05:17:08 [INFO]: Epoch 029 - training loss: 9504.2043, validation loss: 0.2223
2024-05-25 05:17:08 [INFO]: Epoch 030 - training loss: 9500.1653, validation loss: 0.2144
2024-05-25 05:17:08 [INFO]: Epoch 031 - training loss: 9478.8696, validation loss: 0.2052
2024-05-25 05:17:08 [INFO]: Epoch 032 - training loss: 9475.0833, validation loss: 0.2026
2024-05-25 05:17:08 [INFO]: Epoch 033 - training loss: 9485.9807, validation loss: 0.1890
2024-05-25 05:17:08 [INFO]: Epoch 034 - training loss: 9454.8589, validation loss: 0.1873
2024-05-25 05:17:08 [INFO]: Epoch 035 - training loss: 9456.2369, validation loss: 0.1840
2024-05-25 05:17:09 [INFO]: Epoch 036 - training loss: 9437.8048, validation loss: 0.1808
2024-05-25 05:17:09 [INFO]: Epoch 037 - training loss: 9438.6500, validation loss: 0.1751
2024-05-25 05:17:09 [INFO]: Epoch 038 - training loss: 9426.2367, validation loss: 0.1757
2024-05-25 05:17:09 [INFO]: Epoch 039 - training loss: 9419.4766, validation loss: 0.1760
2024-05-25 05:17:09 [INFO]: Epoch 040 - training loss: 9415.8418, validation loss: 0.1703
2024-05-25 05:17:09 [INFO]: Epoch 041 - training loss: 9414.2518, validation loss: 0.1680
2024-05-25 05:17:09 [INFO]: Epoch 042 - training loss: 9407.4816, validation loss: 0.1641
2024-05-25 05:17:10 [INFO]: Epoch 043 - training loss: 9404.5836, validation loss: 0.1612
2024-05-25 05:17:10 [INFO]: Epoch 044 - training loss: 9399.1640, validation loss: 0.1612
2024-05-25 05:17:10 [INFO]: Epoch 045 - training loss: 9395.3953, validation loss: 0.1590
2024-05-25 05:17:10 [INFO]: Epoch 046 - training loss: 9395.1873, validation loss: 0.1591
2024-05-25 05:17:10 [INFO]: Epoch 047 - training loss: 9385.8380, validation loss: 0.1565
2024-05-25 05:17:10 [INFO]: Epoch 048 - training loss: 9387.5660, validation loss: 0.1533
2024-05-25 05:17:10 [INFO]: Epoch 049 - training loss: 9394.2714, validation loss: 0.1529
2024-05-25 05:17:11 [INFO]: Epoch 050 - training loss: 9384.2316, validation loss: 0.1508
2024-05-25 05:17:11 [INFO]: Epoch 051 - training loss: 9375.7582, validation loss: 0.1474
2024-05-25 05:17:11 [INFO]: Epoch 052 - training loss: 9373.2151, validation loss: 0.1498
2024-05-25 05:17:11 [INFO]: Epoch 053 - training loss: 9373.0632, validation loss: 0.1475
2024-05-25 05:17:11 [INFO]: Epoch 054 - training loss: 9367.5467, validation loss: 0.1477
2024-05-25 05:17:11 [INFO]: Epoch 055 - training loss: 9369.7819, validation loss: 0.1453
2024-05-25 05:17:11 [INFO]: Epoch 056 - training loss: 9366.6812, validation loss: 0.1416
2024-05-25 05:17:12 [INFO]: Epoch 057 - training loss: 9362.9092, validation loss: 0.1414
2024-05-25 05:17:12 [INFO]: Epoch 058 - training loss: 9368.7335, validation loss: 0.1414
2024-05-25 05:17:12 [INFO]: Epoch 059 - training loss: 9361.8052, validation loss: 0.1398
2024-05-25 05:17:12 [INFO]: Epoch 060 - training loss: 9359.0538, validation loss: 0.1397
2024-05-25 05:17:12 [INFO]: Epoch 061 - training loss: 9355.0848, validation loss: 0.1407
2024-05-25 05:17:12 [INFO]: Epoch 062 - training loss: 9353.5706, validation loss: 0.1385
2024-05-25 05:17:12 [INFO]: Epoch 063 - training loss: 9351.5694, validation loss: 0.1354
2024-05-25 05:17:13 [INFO]: Epoch 064 - training loss: 9352.1352, validation loss: 0.1355
2024-05-25 05:17:13 [INFO]: Epoch 065 - training loss: 9351.8420, validation loss: 0.1410
2024-05-25 05:17:13 [INFO]: Epoch 066 - training loss: 9350.6403, validation loss: 0.1355
2024-05-25 05:17:13 [INFO]: Epoch 067 - training loss: 9350.6040, validation loss: 0.1353
2024-05-25 05:17:13 [INFO]: Epoch 068 - training loss: 9348.9936, validation loss: 0.1317
2024-05-25 05:17:13 [INFO]: Epoch 069 - training loss: 9351.9197, validation loss: 0.1322
2024-05-25 05:17:13 [INFO]: Epoch 070 - training loss: 9348.7774, validation loss: 0.1300
2024-05-25 05:17:14 [INFO]: Epoch 071 - training loss: 9344.8913, validation loss: 0.1285
2024-05-25 05:17:14 [INFO]: Epoch 072 - training loss: 9348.6593, validation loss: 0.1286
2024-05-25 05:17:14 [INFO]: Epoch 073 - training loss: 9344.0432, validation loss: 0.1271
2024-05-25 05:17:14 [INFO]: Epoch 074 - training loss: 9341.8228, validation loss: 0.1250
2024-05-25 05:17:14 [INFO]: Epoch 075 - training loss: 9341.2982, validation loss: 0.1257
2024-05-25 05:17:14 [INFO]: Epoch 076 - training loss: 9339.2587, validation loss: 0.1243
2024-05-25 05:17:14 [INFO]: Epoch 077 - training loss: 9336.6082, validation loss: 0.1259
2024-05-25 05:17:15 [INFO]: Epoch 078 - training loss: 9337.2404, validation loss: 0.1222
2024-05-25 05:17:15 [INFO]: Epoch 079 - training loss: 9335.2475, validation loss: 0.1222
2024-05-25 05:17:15 [INFO]: Epoch 080 - training loss: 9334.5098, validation loss: 0.1222
2024-05-25 05:17:15 [INFO]: Epoch 081 - training loss: 9334.5977, validation loss: 0.1209
2024-05-25 05:17:15 [INFO]: Epoch 082 - training loss: 9332.9958, validation loss: 0.1198
2024-05-25 05:17:15 [INFO]: Epoch 083 - training loss: 9333.3649, validation loss: 0.1188
2024-05-25 05:17:16 [INFO]: Epoch 084 - training loss: 9331.5032, validation loss: 0.1180
2024-05-25 05:17:16 [INFO]: Epoch 085 - training loss: 9334.1508, validation loss: 0.1166
2024-05-25 05:17:16 [INFO]: Epoch 086 - training loss: 9332.9582, validation loss: 0.1169
2024-05-25 05:17:16 [INFO]: Epoch 087 - training loss: 9331.0045, validation loss: 0.1160
2024-05-25 05:17:16 [INFO]: Epoch 088 - training loss: 9329.3441, validation loss: 0.1154
2024-05-25 05:17:16 [INFO]: Epoch 089 - training loss: 9329.7461, validation loss: 0.1147
2024-05-25 05:17:16 [INFO]: Epoch 090 - training loss: 9327.5267, validation loss: 0.1138
2024-05-25 05:17:17 [INFO]: Epoch 091 - training loss: 9327.2424, validation loss: 0.1130
2024-05-25 05:17:17 [INFO]: Epoch 092 - training loss: 9328.5516, validation loss: 0.1115
2024-05-25 05:17:17 [INFO]: Epoch 093 - training loss: 9325.4858, validation loss: 0.1123
2024-05-25 05:17:17 [INFO]: Epoch 094 - training loss: 9327.0248, validation loss: 0.1120
2024-05-25 05:17:17 [INFO]: Epoch 095 - training loss: 9325.7491, validation loss: 0.1105
2024-05-25 05:17:17 [INFO]: Epoch 096 - training loss: 9325.0286, validation loss: 0.1097
2024-05-25 05:17:17 [INFO]: Epoch 097 - training loss: 9325.0161, validation loss: 0.1089
2024-05-25 05:17:18 [INFO]: Epoch 098 - training loss: 9327.9625, validation loss: 0.1083
2024-05-25 05:17:18 [INFO]: Epoch 099 - training loss: 9326.1093, validation loss: 0.1083
2024-05-25 05:17:18 [INFO]: Epoch 100 - training loss: 9323.7641, validation loss: 0.1072
2024-05-25 05:17:18 [INFO]: Epoch 101 - training loss: 9323.5574, validation loss: 0.1078
2024-05-25 05:17:18 [INFO]: Epoch 102 - training loss: 9323.1724, validation loss: 0.1064
2024-05-25 05:17:18 [INFO]: Epoch 103 - training loss: 9322.6336, validation loss: 0.1059
2024-05-25 05:17:18 [INFO]: Epoch 104 - training loss: 9323.0246, validation loss: 0.1053
2024-05-25 05:17:19 [INFO]: Epoch 105 - training loss: 9321.7123, validation loss: 0.1047
2024-05-25 05:17:19 [INFO]: Epoch 106 - training loss: 9320.0966, validation loss: 0.1055
2024-05-25 05:17:19 [INFO]: Epoch 107 - training loss: 9320.5389, validation loss: 0.1038
2024-05-25 05:17:19 [INFO]: Epoch 108 - training loss: 9320.3945, validation loss: 0.1038
2024-05-25 05:17:19 [INFO]: Epoch 109 - training loss: 9318.6553, validation loss: 0.1016
2024-05-25 05:17:19 [INFO]: Epoch 110 - training loss: 9320.4742, validation loss: 0.1016
2024-05-25 05:17:19 [INFO]: Epoch 111 - training loss: 9319.3422, validation loss: 0.1017
2024-05-25 05:17:20 [INFO]: Epoch 112 - training loss: 9318.9123, validation loss: 0.1009
2024-05-25 05:17:20 [INFO]: Epoch 113 - training loss: 9317.9049, validation loss: 0.1008
2024-05-25 05:17:20 [INFO]: Epoch 114 - training loss: 9317.3066, validation loss: 0.1012
2024-05-25 05:17:20 [INFO]: Epoch 115 - training loss: 9318.8833, validation loss: 0.1003
2024-05-25 05:17:20 [INFO]: Epoch 116 - training loss: 9316.9193, validation loss: 0.0993
2024-05-25 05:17:20 [INFO]: Epoch 117 - training loss: 9317.8923, validation loss: 0.0986
2024-05-25 05:17:20 [INFO]: Epoch 118 - training loss: 9316.5807, validation loss: 0.0981
2024-05-25 05:17:21 [INFO]: Epoch 119 - training loss: 9316.4014, validation loss: 0.0975
2024-05-25 05:17:21 [INFO]: Epoch 120 - training loss: 9315.1659, validation loss: 0.0977
2024-05-25 05:17:21 [INFO]: Epoch 121 - training loss: 9316.6041, validation loss: 0.0966
2024-05-25 05:17:21 [INFO]: Epoch 122 - training loss: 9315.4496, validation loss: 0.0962
2024-05-25 05:17:21 [INFO]: Epoch 123 - training loss: 9316.8098, validation loss: 0.0948
2024-05-25 05:17:21 [INFO]: Epoch 124 - training loss: 9314.8601, validation loss: 0.0965
2024-05-25 05:17:21 [INFO]: Epoch 125 - training loss: 9314.9424, validation loss: 0.0939
2024-05-25 05:17:22 [INFO]: Epoch 126 - training loss: 9314.9386, validation loss: 0.0946
2024-05-25 05:17:22 [INFO]: Epoch 127 - training loss: 9316.4647, validation loss: 0.0944
2024-05-25 05:17:22 [INFO]: Epoch 128 - training loss: 9315.5892, validation loss: 0.0937
2024-05-25 05:17:22 [INFO]: Epoch 129 - training loss: 9314.5076, validation loss: 0.0927
2024-05-25 05:17:22 [INFO]: Epoch 130 - training loss: 9314.3234, validation loss: 0.0942
2024-05-25 05:17:22 [INFO]: Epoch 131 - training loss: 9313.4143, validation loss: 0.0927
2024-05-25 05:17:22 [INFO]: Epoch 132 - training loss: 9314.0237, validation loss: 0.0927
2024-05-25 05:17:23 [INFO]: Epoch 133 - training loss: 9313.8078, validation loss: 0.0911
2024-05-25 05:17:23 [INFO]: Epoch 134 - training loss: 9313.0850, validation loss: 0.0918
2024-05-25 05:17:23 [INFO]: Epoch 135 - training loss: 9313.5057, validation loss: 0.0924
2024-05-25 05:17:23 [INFO]: Epoch 136 - training loss: 9311.9891, validation loss: 0.0902
2024-05-25 05:17:23 [INFO]: Epoch 137 - training loss: 9316.3415, validation loss: 0.0912
2024-05-25 05:17:23 [INFO]: Epoch 138 - training loss: 9313.2310, validation loss: 0.0903
2024-05-25 05:17:23 [INFO]: Epoch 139 - training loss: 9313.1810, validation loss: 0.0894
2024-05-25 05:17:24 [INFO]: Epoch 140 - training loss: 9310.9039, validation loss: 0.0887
2024-05-25 05:17:24 [INFO]: Epoch 141 - training loss: 9311.2937, validation loss: 0.0894
2024-05-25 05:17:24 [INFO]: Epoch 142 - training loss: 9311.9768, validation loss: 0.0895
2024-05-25 05:17:24 [INFO]: Epoch 143 - training loss: 9311.6636, validation loss: 0.0886
2024-05-25 05:17:24 [INFO]: Epoch 144 - training loss: 9311.9330, validation loss: 0.0874
2024-05-25 05:17:24 [INFO]: Epoch 145 - training loss: 9311.3747, validation loss: 0.0877
2024-05-25 05:17:24 [INFO]: Epoch 146 - training loss: 9312.7018, validation loss: 0.0880
2024-05-25 05:17:25 [INFO]: Epoch 147 - training loss: 9309.9962, validation loss: 0.0864
2024-05-25 05:17:25 [INFO]: Epoch 148 - training loss: 9310.7521, validation loss: 0.0873
2024-05-25 05:17:25 [INFO]: Epoch 149 - training loss: 9310.8163, validation loss: 0.0853
2024-05-25 05:17:25 [INFO]: Epoch 150 - training loss: 9309.2744, validation loss: 0.0867
2024-05-25 05:17:25 [INFO]: Epoch 151 - training loss: 9312.0200, validation loss: 0.0864
2024-05-25 05:17:25 [INFO]: Epoch 152 - training loss: 9309.6637, validation loss: 0.0871
2024-05-25 05:17:25 [INFO]: Epoch 153 - training loss: 9309.3829, validation loss: 0.0845
2024-05-25 05:17:26 [INFO]: Epoch 154 - training loss: 9309.2131, validation loss: 0.0851
2024-05-25 05:17:26 [INFO]: Epoch 155 - training loss: 9309.2957, validation loss: 0.0841
2024-05-25 05:17:26 [INFO]: Epoch 156 - training loss: 9309.0411, validation loss: 0.0845
2024-05-25 05:17:26 [INFO]: Epoch 157 - training loss: 9308.4280, validation loss: 0.0851
2024-05-25 05:17:26 [INFO]: Epoch 158 - training loss: 9308.3696, validation loss: 0.0841
2024-05-25 05:17:26 [INFO]: Epoch 159 - training loss: 9308.5558, validation loss: 0.0838
2024-05-25 05:17:26 [INFO]: Epoch 160 - training loss: 9308.9144, validation loss: 0.0837
2024-05-25 05:17:27 [INFO]: Epoch 161 - training loss: 9309.4673, validation loss: 0.0836
2024-05-25 05:17:27 [INFO]: Epoch 162 - training loss: 9308.0308, validation loss: 0.0835
2024-05-25 05:17:27 [INFO]: Epoch 163 - training loss: 9308.3782, validation loss: 0.0829
2024-05-25 05:17:27 [INFO]: Epoch 164 - training loss: 9307.6156, validation loss: 0.0831
2024-05-25 05:17:27 [INFO]: Epoch 165 - training loss: 9307.2848, validation loss: 0.0828
2024-05-25 05:17:27 [INFO]: Epoch 166 - training loss: 9309.5376, validation loss: 0.0825
2024-05-25 05:17:27 [INFO]: Epoch 167 - training loss: 9308.4785, validation loss: 0.0829
2024-05-25 05:17:28 [INFO]: Epoch 168 - training loss: 9307.5081, validation loss: 0.0806
2024-05-25 05:17:28 [INFO]: Epoch 169 - training loss: 9308.0128, validation loss: 0.0822
2024-05-25 05:17:28 [INFO]: Epoch 170 - training loss: 9308.0411, validation loss: 0.0808
2024-05-25 05:17:28 [INFO]: Epoch 171 - training loss: 9307.7607, validation loss: 0.0807
2024-05-25 05:17:28 [INFO]: Epoch 172 - training loss: 9307.4146, validation loss: 0.0811
2024-05-25 05:17:28 [INFO]: Epoch 173 - training loss: 9306.7281, validation loss: 0.0810
2024-05-25 05:17:28 [INFO]: Epoch 174 - training loss: 9306.4134, validation loss: 0.0812
2024-05-25 05:17:29 [INFO]: Epoch 175 - training loss: 9313.0853, validation loss: 0.0793
2024-05-25 05:17:29 [INFO]: Epoch 176 - training loss: 9306.5673, validation loss: 0.0797
2024-05-25 05:17:29 [INFO]: Epoch 177 - training loss: 9306.7794, validation loss: 0.0807
2024-05-25 05:17:29 [INFO]: Epoch 178 - training loss: 9306.1420, validation loss: 0.0801
2024-05-25 05:17:29 [INFO]: Epoch 179 - training loss: 9306.5115, validation loss: 0.0802
2024-05-25 05:17:29 [INFO]: Epoch 180 - training loss: 9306.9141, validation loss: 0.0791
2024-05-25 05:17:29 [INFO]: Epoch 181 - training loss: 9304.9261, validation loss: 0.0800
2024-05-25 05:17:30 [INFO]: Epoch 182 - training loss: 9306.4085, validation loss: 0.0782
2024-05-25 05:17:30 [INFO]: Epoch 183 - training loss: 9305.3199, validation loss: 0.0793
2024-05-25 05:17:30 [INFO]: Epoch 184 - training loss: 9307.1678, validation loss: 0.0777
2024-05-25 05:17:30 [INFO]: Epoch 185 - training loss: 9306.1417, validation loss: 0.0793
2024-05-25 05:17:30 [INFO]: Epoch 186 - training loss: 9307.4269, validation loss: 0.0776
2024-05-25 05:17:30 [INFO]: Epoch 187 - training loss: 9306.4423, validation loss: 0.0789
2024-05-25 05:17:30 [INFO]: Epoch 188 - training loss: 9304.9093, validation loss: 0.0796
2024-05-25 05:17:30 [INFO]: Epoch 189 - training loss: 9306.3330, validation loss: 0.0784
2024-05-25 05:17:31 [INFO]: Epoch 190 - training loss: 9305.1790, validation loss: 0.0784
2024-05-25 05:17:31 [INFO]: Epoch 191 - training loss: 9304.8503, validation loss: 0.0772
2024-05-25 05:17:31 [INFO]: Epoch 192 - training loss: 9304.9897, validation loss: 0.0773
2024-05-25 05:17:31 [INFO]: Epoch 193 - training loss: 9304.9567, validation loss: 0.0771
2024-05-25 05:17:31 [INFO]: Epoch 194 - training loss: 9305.0148, validation loss: 0.0772
2024-05-25 05:17:31 [INFO]: Epoch 195 - training loss: 9305.3119, validation loss: 0.0756
2024-05-25 05:17:31 [INFO]: Epoch 196 - training loss: 9304.8019, validation loss: 0.0761
2024-05-25 05:17:32 [INFO]: Epoch 197 - training loss: 9305.1815, validation loss: 0.0778
2024-05-25 05:17:32 [INFO]: Epoch 198 - training loss: 9305.4899, validation loss: 0.0767
2024-05-25 05:17:32 [INFO]: Epoch 199 - training loss: 9304.4962, validation loss: 0.0769
2024-05-25 05:17:32 [INFO]: Epoch 200 - training loss: 9304.4596, validation loss: 0.0794
2024-05-25 05:17:32 [INFO]: Epoch 201 - training loss: 9304.6283, validation loss: 0.0757
2024-05-25 05:17:32 [INFO]: Epoch 202 - training loss: 9304.8403, validation loss: 0.0749
2024-05-25 05:17:32 [INFO]: Epoch 203 - training loss: 9306.0569, validation loss: 0.0749
2024-05-25 05:17:33 [INFO]: Epoch 204 - training loss: 9304.8946, validation loss: 0.0738
2024-05-25 05:17:33 [INFO]: Epoch 205 - training loss: 9304.7305, validation loss: 0.0745
2024-05-25 05:17:33 [INFO]: Epoch 206 - training loss: 9304.9449, validation loss: 0.0749
2024-05-25 05:17:33 [INFO]: Epoch 207 - training loss: 9304.1903, validation loss: 0.0759
2024-05-25 05:17:33 [INFO]: Epoch 208 - training loss: 9304.6575, validation loss: 0.0766
2024-05-25 05:17:33 [INFO]: Epoch 209 - training loss: 9303.3779, validation loss: 0.0759
2024-05-25 05:17:33 [INFO]: Epoch 210 - training loss: 9304.1705, validation loss: 0.0740
2024-05-25 05:17:34 [INFO]: Epoch 211 - training loss: 9304.8052, validation loss: 0.0764
2024-05-25 05:17:34 [INFO]: Epoch 212 - training loss: 9304.5834, validation loss: 0.0743
2024-05-25 05:17:34 [INFO]: Epoch 213 - training loss: 9303.3588, validation loss: 0.0743
2024-05-25 05:17:34 [INFO]: Epoch 214 - training loss: 9303.6458, validation loss: 0.0748
2024-05-25 05:17:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:17:34 [INFO]: Finished training. The best model is from epoch#204.
2024-05-25 05:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240525_T051703/GPVAE.pypots
2024-05-25 05:17:34 [INFO]: GP-VAE on ETTm1: MAE=0.2710, MSE=0.1498
2024-05-25 05:17:34 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-25 05:17:34 [INFO]: Using the given device: cuda:0
2024-05-25 05:17:34 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T051734
2024-05-25 05:17:34 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T051734/tensorboard
2024-05-25 05:17:34 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 05:17:45 [INFO]: Epoch 001 - generator training loss: 0.5485, discriminator training loss: 0.3254, validation loss: 0.2716
2024-05-25 05:17:55 [INFO]: Epoch 002 - generator training loss: 0.0226, discriminator training loss: 0.2065, validation loss: 0.0917
2024-05-25 05:18:04 [INFO]: Epoch 003 - generator training loss: -0.0717, discriminator training loss: 0.1996, validation loss: 0.0551
2024-05-25 05:18:14 [INFO]: Epoch 004 - generator training loss: -0.0790, discriminator training loss: 0.1934, validation loss: 0.0462
2024-05-25 05:18:23 [INFO]: Epoch 005 - generator training loss: -0.0890, discriminator training loss: 0.1918, validation loss: 0.0416
2024-05-25 05:18:32 [INFO]: Epoch 006 - generator training loss: -0.0830, discriminator training loss: 0.1889, validation loss: 0.0387
2024-05-25 05:18:42 [INFO]: Epoch 007 - generator training loss: -0.0764, discriminator training loss: 0.1781, validation loss: 0.0380
2024-05-25 05:18:51 [INFO]: Epoch 008 - generator training loss: -0.0706, discriminator training loss: 0.1685, validation loss: 0.0374
2024-05-25 05:19:00 [INFO]: Epoch 009 - generator training loss: -0.0541, discriminator training loss: 0.1516, validation loss: 0.0356
2024-05-25 05:19:10 [INFO]: Epoch 010 - generator training loss: -0.0411, discriminator training loss: 0.1337, validation loss: 0.0374
2024-05-25 05:19:19 [INFO]: Epoch 011 - generator training loss: -0.0315, discriminator training loss: 0.1193, validation loss: 0.0363
2024-05-25 05:19:29 [INFO]: Epoch 012 - generator training loss: -0.0232, discriminator training loss: 0.1068, validation loss: 0.0349
2024-05-25 05:19:38 [INFO]: Epoch 013 - generator training loss: -0.0160, discriminator training loss: 0.0968, validation loss: 0.0350
2024-05-25 05:19:47 [INFO]: Epoch 014 - generator training loss: -0.0134, discriminator training loss: 0.0915, validation loss: 0.0341
2024-05-25 05:19:57 [INFO]: Epoch 015 - generator training loss: -0.0133, discriminator training loss: 0.0856, validation loss: 0.0329
2024-05-25 05:20:06 [INFO]: Epoch 016 - generator training loss: -0.0085, discriminator training loss: 0.0837, validation loss: 0.0337
2024-05-25 05:20:15 [INFO]: Epoch 017 - generator training loss: -0.0088, discriminator training loss: 0.0809, validation loss: 0.0334
2024-05-25 05:20:25 [INFO]: Epoch 018 - generator training loss: -0.0081, discriminator training loss: 0.0802, validation loss: 0.0324
2024-05-25 05:20:34 [INFO]: Epoch 019 - generator training loss: -0.0104, discriminator training loss: 0.0798, validation loss: 0.0328
2024-05-25 05:20:43 [INFO]: Epoch 020 - generator training loss: -0.0121, discriminator training loss: 0.0775, validation loss: 0.0324
2024-05-25 05:20:52 [INFO]: Epoch 021 - generator training loss: -0.0063, discriminator training loss: 0.0752, validation loss: 0.0325
2024-05-25 05:21:02 [INFO]: Epoch 022 - generator training loss: -0.0111, discriminator training loss: 0.0761, validation loss: 0.0333
2024-05-25 05:21:11 [INFO]: Epoch 023 - generator training loss: -0.0124, discriminator training loss: 0.0751, validation loss: 0.0318
2024-05-25 05:21:21 [INFO]: Epoch 024 - generator training loss: -0.0107, discriminator training loss: 0.0750, validation loss: 0.0300
2024-05-25 05:21:30 [INFO]: Epoch 025 - generator training loss: -0.0157, discriminator training loss: 0.0750, validation loss: 0.0305
2024-05-25 05:21:39 [INFO]: Epoch 026 - generator training loss: -0.0124, discriminator training loss: 0.0747, validation loss: 0.0302
2024-05-25 05:21:49 [INFO]: Epoch 027 - generator training loss: -0.0120, discriminator training loss: 0.0752, validation loss: 0.0310
2024-05-25 05:21:58 [INFO]: Epoch 028 - generator training loss: -0.0115, discriminator training loss: 0.0759, validation loss: 0.0306
2024-05-25 05:22:08 [INFO]: Epoch 029 - generator training loss: -0.0157, discriminator training loss: 0.0762, validation loss: 0.0296
2024-05-25 05:22:17 [INFO]: Epoch 030 - generator training loss: -0.0109, discriminator training loss: 0.0735, validation loss: 0.0291
2024-05-25 05:22:26 [INFO]: Epoch 031 - generator training loss: -0.0137, discriminator training loss: 0.0725, validation loss: 0.0297
2024-05-25 05:22:36 [INFO]: Epoch 032 - generator training loss: -0.0141, discriminator training loss: 0.0724, validation loss: 0.0287
2024-05-25 05:22:45 [INFO]: Epoch 033 - generator training loss: -0.0153, discriminator training loss: 0.0718, validation loss: 0.0287
2024-05-25 05:22:54 [INFO]: Epoch 034 - generator training loss: -0.0147, discriminator training loss: 0.0713, validation loss: 0.0280
2024-05-25 05:23:04 [INFO]: Epoch 035 - generator training loss: -0.0161, discriminator training loss: 0.0714, validation loss: 0.0284
2024-05-25 05:23:13 [INFO]: Epoch 036 - generator training loss: -0.0146, discriminator training loss: 0.0711, validation loss: 0.0276
2024-05-25 05:23:23 [INFO]: Epoch 037 - generator training loss: -0.0186, discriminator training loss: 0.0716, validation loss: 0.0276
2024-05-25 05:23:32 [INFO]: Epoch 038 - generator training loss: -0.0155, discriminator training loss: 0.0706, validation loss: 0.0261
2024-05-25 05:23:41 [INFO]: Epoch 039 - generator training loss: -0.0178, discriminator training loss: 0.0732, validation loss: 0.0256
2024-05-25 05:23:51 [INFO]: Epoch 040 - generator training loss: -0.0178, discriminator training loss: 0.0716, validation loss: 0.0264
2024-05-25 05:24:00 [INFO]: Epoch 041 - generator training loss: -0.0159, discriminator training loss: 0.0710, validation loss: 0.0253
2024-05-25 05:24:09 [INFO]: Epoch 042 - generator training loss: -0.0185, discriminator training loss: 0.0705, validation loss: 0.0247
2024-05-25 05:24:19 [INFO]: Epoch 043 - generator training loss: -0.0176, discriminator training loss: 0.0711, validation loss: 0.0259
2024-05-25 05:24:28 [INFO]: Epoch 044 - generator training loss: -0.0162, discriminator training loss: 0.0706, validation loss: 0.0252
2024-05-25 05:24:38 [INFO]: Epoch 045 - generator training loss: -0.0180, discriminator training loss: 0.0695, validation loss: 0.0253
2024-05-25 05:24:47 [INFO]: Epoch 046 - generator training loss: -0.0189, discriminator training loss: 0.0703, validation loss: 0.0249
2024-05-25 05:24:56 [INFO]: Epoch 047 - generator training loss: -0.0187, discriminator training loss: 0.0689, validation loss: 0.0243
2024-05-25 05:25:06 [INFO]: Epoch 048 - generator training loss: -0.0171, discriminator training loss: 0.0711, validation loss: 0.0236
2024-05-25 05:25:15 [INFO]: Epoch 049 - generator training loss: -0.0196, discriminator training loss: 0.0717, validation loss: 0.0241
2024-05-25 05:25:25 [INFO]: Epoch 050 - generator training loss: -0.0177, discriminator training loss: 0.0720, validation loss: 0.0234
2024-05-25 05:25:34 [INFO]: Epoch 051 - generator training loss: -0.0216, discriminator training loss: 0.0699, validation loss: 0.0229
2024-05-25 05:25:43 [INFO]: Epoch 052 - generator training loss: -0.0186, discriminator training loss: 0.0688, validation loss: 0.0228
2024-05-25 05:25:53 [INFO]: Epoch 053 - generator training loss: -0.0237, discriminator training loss: 0.0692, validation loss: 0.0231
2024-05-25 05:26:02 [INFO]: Epoch 054 - generator training loss: -0.0196, discriminator training loss: 0.0702, validation loss: 0.0227
2024-05-25 05:26:11 [INFO]: Epoch 055 - generator training loss: -0.0201, discriminator training loss: 0.0685, validation loss: 0.0234
2024-05-25 05:26:21 [INFO]: Epoch 056 - generator training loss: -0.0223, discriminator training loss: 0.0706, validation loss: 0.0226
2024-05-25 05:26:30 [INFO]: Epoch 057 - generator training loss: -0.0199, discriminator training loss: 0.0681, validation loss: 0.0224
2024-05-25 05:26:40 [INFO]: Epoch 058 - generator training loss: -0.0234, discriminator training loss: 0.0683, validation loss: 0.0219
2024-05-25 05:26:49 [INFO]: Epoch 059 - generator training loss: -0.0207, discriminator training loss: 0.0703, validation loss: 0.0215
2024-05-25 05:26:58 [INFO]: Epoch 060 - generator training loss: -0.0211, discriminator training loss: 0.0680, validation loss: 0.0215
2024-05-25 05:27:08 [INFO]: Epoch 061 - generator training loss: -0.0227, discriminator training loss: 0.0687, validation loss: 0.0218
2024-05-25 05:27:17 [INFO]: Epoch 062 - generator training loss: -0.0220, discriminator training loss: 0.0678, validation loss: 0.0214
2024-05-25 05:27:27 [INFO]: Epoch 063 - generator training loss: -0.0214, discriminator training loss: 0.0711, validation loss: 0.0211
2024-05-25 05:27:36 [INFO]: Epoch 064 - generator training loss: -0.0200, discriminator training loss: 0.0667, validation loss: 0.0213
2024-05-25 05:27:45 [INFO]: Epoch 065 - generator training loss: -0.0222, discriminator training loss: 0.0683, validation loss: 0.0218
2024-05-25 05:27:54 [INFO]: Epoch 066 - generator training loss: -0.0180, discriminator training loss: 0.0684, validation loss: 0.0214
2024-05-25 05:28:04 [INFO]: Epoch 067 - generator training loss: -0.0191, discriminator training loss: 0.0666, validation loss: 0.0233
2024-05-25 05:28:13 [INFO]: Epoch 068 - generator training loss: -0.0220, discriminator training loss: 0.0674, validation loss: 0.0208
2024-05-25 05:28:23 [INFO]: Epoch 069 - generator training loss: -0.0227, discriminator training loss: 0.0667, validation loss: 0.0209
2024-05-25 05:28:32 [INFO]: Epoch 070 - generator training loss: -0.0212, discriminator training loss: 0.0670, validation loss: 0.0214
2024-05-25 05:28:41 [INFO]: Epoch 071 - generator training loss: -0.0233, discriminator training loss: 0.0710, validation loss: 0.0201
2024-05-25 05:28:51 [INFO]: Epoch 072 - generator training loss: -0.0226, discriminator training loss: 0.0702, validation loss: 0.0201
2024-05-25 05:29:00 [INFO]: Epoch 073 - generator training loss: -0.0199, discriminator training loss: 0.0676, validation loss: 0.0202
2024-05-25 05:29:10 [INFO]: Epoch 074 - generator training loss: -0.0237, discriminator training loss: 0.0678, validation loss: 0.0199
2024-05-25 05:29:19 [INFO]: Epoch 075 - generator training loss: -0.0220, discriminator training loss: 0.0696, validation loss: 0.0198
2024-05-25 05:29:28 [INFO]: Epoch 076 - generator training loss: -0.0234, discriminator training loss: 0.0677, validation loss: 0.0204
2024-05-25 05:29:38 [INFO]: Epoch 077 - generator training loss: -0.0225, discriminator training loss: 0.0675, validation loss: 0.0199
2024-05-25 05:29:47 [INFO]: Epoch 078 - generator training loss: -0.0225, discriminator training loss: 0.0697, validation loss: 0.0196
2024-05-25 05:29:56 [INFO]: Epoch 079 - generator training loss: -0.0228, discriminator training loss: 0.0672, validation loss: 0.0197
2024-05-25 05:30:06 [INFO]: Epoch 080 - generator training loss: -0.0230, discriminator training loss: 0.0668, validation loss: 0.0196
2024-05-25 05:30:15 [INFO]: Epoch 081 - generator training loss: -0.0232, discriminator training loss: 0.0676, validation loss: 0.0193
2024-05-25 05:30:24 [INFO]: Epoch 082 - generator training loss: -0.0226, discriminator training loss: 0.0678, validation loss: 0.0203
2024-05-25 05:30:34 [INFO]: Epoch 083 - generator training loss: -0.0238, discriminator training loss: 0.0691, validation loss: 0.0192
2024-05-25 05:30:43 [INFO]: Epoch 084 - generator training loss: -0.0243, discriminator training loss: 0.0676, validation loss: 0.0197
2024-05-25 05:30:53 [INFO]: Epoch 085 - generator training loss: -0.0246, discriminator training loss: 0.0676, validation loss: 0.0193
2024-05-25 05:31:02 [INFO]: Epoch 086 - generator training loss: -0.0240, discriminator training loss: 0.0657, validation loss: 0.0195
2024-05-25 05:31:11 [INFO]: Epoch 087 - generator training loss: -0.0225, discriminator training loss: 0.0649, validation loss: 0.0192
2024-05-25 05:31:21 [INFO]: Epoch 088 - generator training loss: -0.0236, discriminator training loss: 0.0673, validation loss: 0.0193
2024-05-25 05:31:30 [INFO]: Epoch 089 - generator training loss: -0.0214, discriminator training loss: 0.0674, validation loss: 0.0195
2024-05-25 05:31:40 [INFO]: Epoch 090 - generator training loss: -0.0256, discriminator training loss: 0.0654, validation loss: 0.0195
2024-05-25 05:31:49 [INFO]: Epoch 091 - generator training loss: -0.0252, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-25 05:31:59 [INFO]: Epoch 092 - generator training loss: -0.0228, discriminator training loss: 0.0664, validation loss: 0.0191
2024-05-25 05:32:08 [INFO]: Epoch 093 - generator training loss: -0.0243, discriminator training loss: 0.0649, validation loss: 0.0188
2024-05-25 05:32:17 [INFO]: Epoch 094 - generator training loss: -0.0249, discriminator training loss: 0.0655, validation loss: 0.0192
2024-05-25 05:32:27 [INFO]: Epoch 095 - generator training loss: -0.0255, discriminator training loss: 0.0662, validation loss: 0.0194
2024-05-25 05:32:36 [INFO]: Epoch 096 - generator training loss: -0.0251, discriminator training loss: 0.0658, validation loss: 0.0192
2024-05-25 05:32:45 [INFO]: Epoch 097 - generator training loss: -0.0259, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-25 05:32:55 [INFO]: Epoch 098 - generator training loss: -0.0248, discriminator training loss: 0.0667, validation loss: 0.0188
2024-05-25 05:33:04 [INFO]: Epoch 099 - generator training loss: -0.0241, discriminator training loss: 0.0665, validation loss: 0.0186
2024-05-25 05:33:13 [INFO]: Epoch 100 - generator training loss: -0.0254, discriminator training loss: 0.0687, validation loss: 0.0186
2024-05-25 05:33:23 [INFO]: Epoch 101 - generator training loss: -0.0229, discriminator training loss: 0.0676, validation loss: 0.0191
2024-05-25 05:33:32 [INFO]: Epoch 102 - generator training loss: -0.0235, discriminator training loss: 0.0666, validation loss: 0.0202
2024-05-25 05:33:42 [INFO]: Epoch 103 - generator training loss: -0.0246, discriminator training loss: 0.0644, validation loss: 0.0190
2024-05-25 05:33:51 [INFO]: Epoch 104 - generator training loss: -0.0247, discriminator training loss: 0.0660, validation loss: 0.0185
2024-05-25 05:34:00 [INFO]: Epoch 105 - generator training loss: -0.0280, discriminator training loss: 0.0660, validation loss: 0.0187
2024-05-25 05:34:10 [INFO]: Epoch 106 - generator training loss: -0.0258, discriminator training loss: 0.0657, validation loss: 0.0184
2024-05-25 05:34:19 [INFO]: Epoch 107 - generator training loss: -0.0252, discriminator training loss: 0.0683, validation loss: 0.0189
2024-05-25 05:34:29 [INFO]: Epoch 108 - generator training loss: -0.0244, discriminator training loss: 0.0659, validation loss: 0.0182
2024-05-25 05:34:38 [INFO]: Epoch 109 - generator training loss: -0.0273, discriminator training loss: 0.0630, validation loss: 0.0182
2024-05-25 05:34:48 [INFO]: Epoch 110 - generator training loss: -0.0275, discriminator training loss: 0.0660, validation loss: 0.0187
2024-05-25 05:34:57 [INFO]: Epoch 111 - generator training loss: -0.0264, discriminator training loss: 0.0669, validation loss: 0.0182
2024-05-25 05:35:06 [INFO]: Epoch 112 - generator training loss: -0.0256, discriminator training loss: 0.0671, validation loss: 0.0184
2024-05-25 05:35:15 [INFO]: Epoch 113 - generator training loss: -0.0264, discriminator training loss: 0.0672, validation loss: 0.0185
2024-05-25 05:35:24 [INFO]: Epoch 114 - generator training loss: -0.0266, discriminator training loss: 0.0675, validation loss: 0.0182
2024-05-25 05:35:33 [INFO]: Epoch 115 - generator training loss: -0.0278, discriminator training loss: 0.0673, validation loss: 0.0191
2024-05-25 05:35:43 [INFO]: Epoch 116 - generator training loss: -0.0241, discriminator training loss: 0.0651, validation loss: 0.0186
2024-05-25 05:35:52 [INFO]: Epoch 117 - generator training loss: -0.0273, discriminator training loss: 0.0645, validation loss: 0.0187
2024-05-25 05:36:01 [INFO]: Epoch 118 - generator training loss: -0.0262, discriminator training loss: 0.0656, validation loss: 0.0181
2024-05-25 05:36:11 [INFO]: Epoch 119 - generator training loss: -0.0256, discriminator training loss: 0.0662, validation loss: 0.0185
2024-05-25 05:36:20 [INFO]: Epoch 120 - generator training loss: -0.0258, discriminator training loss: 0.0663, validation loss: 0.0192
2024-05-25 05:36:30 [INFO]: Epoch 121 - generator training loss: -0.0252, discriminator training loss: 0.0666, validation loss: 0.0193
2024-05-25 05:36:39 [INFO]: Epoch 122 - generator training loss: -0.0263, discriminator training loss: 0.0628, validation loss: 0.0189
2024-05-25 05:36:48 [INFO]: Epoch 123 - generator training loss: -0.0270, discriminator training loss: 0.0671, validation loss: 0.0179
2024-05-25 05:36:58 [INFO]: Epoch 124 - generator training loss: -0.0257, discriminator training loss: 0.0631, validation loss: 0.0185
2024-05-25 05:37:07 [INFO]: Epoch 125 - generator training loss: -0.0285, discriminator training loss: 0.0649, validation loss: 0.0181
2024-05-25 05:37:16 [INFO]: Epoch 126 - generator training loss: -0.0279, discriminator training loss: 0.0677, validation loss: 0.0180
2024-05-25 05:37:26 [INFO]: Epoch 127 - generator training loss: -0.0252, discriminator training loss: 0.0676, validation loss: 0.0187
2024-05-25 05:37:35 [INFO]: Epoch 128 - generator training loss: -0.0283, discriminator training loss: 0.0652, validation loss: 0.0181
2024-05-25 05:37:45 [INFO]: Epoch 129 - generator training loss: -0.0277, discriminator training loss: 0.0669, validation loss: 0.0180
2024-05-25 05:37:54 [INFO]: Epoch 130 - generator training loss: -0.0272, discriminator training loss: 0.0647, validation loss: 0.0185
2024-05-25 05:38:04 [INFO]: Epoch 131 - generator training loss: -0.0281, discriminator training loss: 0.0643, validation loss: 0.0183
2024-05-25 05:38:13 [INFO]: Epoch 132 - generator training loss: -0.0278, discriminator training loss: 0.0653, validation loss: 0.0179
2024-05-25 05:38:22 [INFO]: Epoch 133 - generator training loss: -0.0259, discriminator training loss: 0.0657, validation loss: 0.0187
2024-05-25 05:38:32 [INFO]: Epoch 134 - generator training loss: -0.0270, discriminator training loss: 0.0667, validation loss: 0.0194
2024-05-25 05:38:41 [INFO]: Epoch 135 - generator training loss: -0.0254, discriminator training loss: 0.0660, validation loss: 0.0197
2024-05-25 05:38:51 [INFO]: Epoch 136 - generator training loss: -0.0273, discriminator training loss: 0.0663, validation loss: 0.0186
2024-05-25 05:39:00 [INFO]: Epoch 137 - generator training loss: -0.0244, discriminator training loss: 0.0650, validation loss: 0.0177
2024-05-25 05:39:09 [INFO]: Epoch 138 - generator training loss: -0.0267, discriminator training loss: 0.0648, validation loss: 0.0177
2024-05-25 05:39:19 [INFO]: Epoch 139 - generator training loss: -0.0252, discriminator training loss: 0.0659, validation loss: 0.0182
2024-05-25 05:39:28 [INFO]: Epoch 140 - generator training loss: -0.0260, discriminator training loss: 0.0651, validation loss: 0.0179
2024-05-25 05:39:38 [INFO]: Epoch 141 - generator training loss: -0.0259, discriminator training loss: 0.0652, validation loss: 0.0186
2024-05-25 05:39:47 [INFO]: Epoch 142 - generator training loss: -0.0276, discriminator training loss: 0.0655, validation loss: 0.0182
2024-05-25 05:39:56 [INFO]: Epoch 143 - generator training loss: -0.0265, discriminator training loss: 0.0625, validation loss: 0.0183
2024-05-25 05:40:06 [INFO]: Epoch 144 - generator training loss: -0.0253, discriminator training loss: 0.0647, validation loss: 0.0183
2024-05-25 05:40:15 [INFO]: Epoch 145 - generator training loss: -0.0270, discriminator training loss: 0.0646, validation loss: 0.0182
2024-05-25 05:40:24 [INFO]: Epoch 146 - generator training loss: -0.0264, discriminator training loss: 0.0644, validation loss: 0.0184
2024-05-25 05:40:34 [INFO]: Epoch 147 - generator training loss: -0.0261, discriminator training loss: 0.0642, validation loss: 0.0189
2024-05-25 05:40:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:40:34 [INFO]: Finished training. The best model is from epoch#137.
2024-05-25 05:40:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_ettm1/20240525_T051734/USGAN.pypots
2024-05-25 05:40:35 [INFO]: US-GAN on ETTm1: MAE=0.1509, MSE=0.0573
2024-05-25 05:40:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 05:40:35 [INFO]: Using the given device: cuda:0
2024-05-25 05:40:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T054035
2024-05-25 05:40:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T054035/tensorboard
2024-05-25 05:40:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 05:40:43 [INFO]: Epoch 001 - training loss: 1.2728, validation loss: 0.2610
2024-05-25 05:40:49 [INFO]: Epoch 002 - training loss: 0.8825, validation loss: 0.0853
2024-05-25 05:40:55 [INFO]: Epoch 003 - training loss: 0.6993, validation loss: 0.0555
2024-05-25 05:41:01 [INFO]: Epoch 004 - training loss: 0.6119, validation loss: 0.0435
2024-05-25 05:41:08 [INFO]: Epoch 005 - training loss: 0.5673, validation loss: 0.0398
2024-05-25 05:41:14 [INFO]: Epoch 006 - training loss: 0.5434, validation loss: 0.0383
2024-05-25 05:41:20 [INFO]: Epoch 007 - training loss: 0.5084, validation loss: 0.0379
2024-05-25 05:41:27 [INFO]: Epoch 008 - training loss: 0.5188, validation loss: 0.0346
2024-05-25 05:41:33 [INFO]: Epoch 009 - training loss: 0.4666, validation loss: 0.0326
2024-05-25 05:41:39 [INFO]: Epoch 010 - training loss: 0.4410, validation loss: 0.0298
2024-05-25 05:41:45 [INFO]: Epoch 011 - training loss: 0.4313, validation loss: 0.0293
2024-05-25 05:41:51 [INFO]: Epoch 012 - training loss: 0.4275, validation loss: 0.0272
2024-05-25 05:41:58 [INFO]: Epoch 013 - training loss: 0.4116, validation loss: 0.0263
2024-05-25 05:42:04 [INFO]: Epoch 014 - training loss: 0.4053, validation loss: 0.0252
2024-05-25 05:42:10 [INFO]: Epoch 015 - training loss: 0.3961, validation loss: 0.0248
2024-05-25 05:42:16 [INFO]: Epoch 016 - training loss: 0.3959, validation loss: 0.0243
2024-05-25 05:42:23 [INFO]: Epoch 017 - training loss: 0.3801, validation loss: 0.0253
2024-05-25 05:42:29 [INFO]: Epoch 018 - training loss: 0.4421, validation loss: 0.0267
2024-05-25 05:42:35 [INFO]: Epoch 019 - training loss: 0.4037, validation loss: 0.0242
2024-05-25 05:42:41 [INFO]: Epoch 020 - training loss: 0.3889, validation loss: 0.0235
2024-05-25 05:42:47 [INFO]: Epoch 021 - training loss: 0.3940, validation loss: 0.0233
2024-05-25 05:42:53 [INFO]: Epoch 022 - training loss: 0.3840, validation loss: 0.0230
2024-05-25 05:43:00 [INFO]: Epoch 023 - training loss: 0.3874, validation loss: 0.0231
2024-05-25 05:43:06 [INFO]: Epoch 024 - training loss: 0.3810, validation loss: 0.0232
2024-05-25 05:43:12 [INFO]: Epoch 025 - training loss: 0.3785, validation loss: 0.0230
2024-05-25 05:43:18 [INFO]: Epoch 026 - training loss: 0.3798, validation loss: 0.0228
2024-05-25 05:43:25 [INFO]: Epoch 027 - training loss: 0.4406, validation loss: 0.0233
2024-05-25 05:43:31 [INFO]: Epoch 028 - training loss: 0.4210, validation loss: 0.0237
2024-05-25 05:43:37 [INFO]: Epoch 029 - training loss: 0.3956, validation loss: 0.0241
2024-05-25 05:43:43 [INFO]: Epoch 030 - training loss: 0.3912, validation loss: 0.0247
2024-05-25 05:43:50 [INFO]: Epoch 031 - training loss: 0.3923, validation loss: 0.0240
2024-05-25 05:43:56 [INFO]: Epoch 032 - training loss: 0.3867, validation loss: 0.0232
2024-05-25 05:44:02 [INFO]: Epoch 033 - training loss: 0.3766, validation loss: 0.0229
2024-05-25 05:44:08 [INFO]: Epoch 034 - training loss: 0.3761, validation loss: 0.0236
2024-05-25 05:44:15 [INFO]: Epoch 035 - training loss: 0.3759, validation loss: 0.0231
2024-05-25 05:44:21 [INFO]: Epoch 036 - training loss: 0.3738, validation loss: 0.0229
2024-05-25 05:44:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:44:21 [INFO]: Finished training. The best model is from epoch#26.
2024-05-25 05:44:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_ettm1/20240525_T054035/BRITS.pypots
2024-05-25 05:44:22 [INFO]: BRITS on ETTm1: MAE=0.1204, MSE=0.0445
2024-05-25 05:44:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 05:44:22 [INFO]: Using the given device: cuda:0
2024-05-25 05:44:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422
2024-05-25 05:44:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/tensorboard
2024-05-25 05:44:22 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 05:44:24 [INFO]: Epoch 001 - training loss: 1.4263, validation loss: 1.2577
2024-05-25 05:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch1_loss1.2576803267002106.pypots
2024-05-25 05:44:24 [INFO]: Epoch 002 - training loss: 1.0569, validation loss: 1.1180
2024-05-25 05:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch2_loss1.1180384159088135.pypots
2024-05-25 05:44:24 [INFO]: Epoch 003 - training loss: 0.9816, validation loss: 1.0458
2024-05-25 05:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch3_loss1.045792430639267.pypots
2024-05-25 05:44:24 [INFO]: Epoch 004 - training loss: 0.9632, validation loss: 1.0174
2024-05-25 05:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch4_loss1.017380565404892.pypots
2024-05-25 05:44:25 [INFO]: Epoch 005 - training loss: 0.9448, validation loss: 1.0054
2024-05-25 05:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch5_loss1.0054291933774948.pypots
2024-05-25 05:44:25 [INFO]: Epoch 006 - training loss: 0.9308, validation loss: 0.9989
2024-05-25 05:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch6_loss0.9988566786050797.pypots
2024-05-25 05:44:25 [INFO]: Epoch 007 - training loss: 0.9067, validation loss: 0.9933
2024-05-25 05:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch7_loss0.9932726323604584.pypots
2024-05-25 05:44:25 [INFO]: Epoch 008 - training loss: 0.9121, validation loss: 0.9895
2024-05-25 05:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch8_loss0.9895301461219788.pypots
2024-05-25 05:44:25 [INFO]: Epoch 009 - training loss: 0.9438, validation loss: 0.9882
2024-05-25 05:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch9_loss0.988171249628067.pypots
2024-05-25 05:44:26 [INFO]: Epoch 010 - training loss: 0.9209, validation loss: 0.9840
2024-05-25 05:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch10_loss0.9840495437383652.pypots
2024-05-25 05:44:26 [INFO]: Epoch 011 - training loss: 0.9016, validation loss: 0.9841
2024-05-25 05:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch11_loss0.9841267168521881.pypots
2024-05-25 05:44:26 [INFO]: Epoch 012 - training loss: 0.9293, validation loss: 0.9823
2024-05-25 05:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch12_loss0.9822783768177032.pypots
2024-05-25 05:44:26 [INFO]: Epoch 013 - training loss: 0.8659, validation loss: 0.9796
2024-05-25 05:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch13_loss0.9795903265476227.pypots
2024-05-25 05:44:26 [INFO]: Epoch 014 - training loss: 0.8992, validation loss: 0.9807
2024-05-25 05:44:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch14_loss0.980743408203125.pypots
2024-05-25 05:44:27 [INFO]: Epoch 015 - training loss: 0.8594, validation loss: 0.9754
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch15_loss0.9753751456737518.pypots
2024-05-25 05:44:27 [INFO]: Epoch 016 - training loss: 0.8671, validation loss: 0.9730
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch16_loss0.9730117917060852.pypots
2024-05-25 05:44:27 [INFO]: Epoch 017 - training loss: 0.8620, validation loss: 0.9706
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch17_loss0.9705879092216492.pypots
2024-05-25 05:44:27 [INFO]: Epoch 018 - training loss: 0.8609, validation loss: 0.9675
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch18_loss0.9674501121044159.pypots
2024-05-25 05:44:27 [INFO]: Epoch 019 - training loss: 0.8452, validation loss: 0.9680
2024-05-25 05:44:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch19_loss0.967958077788353.pypots
2024-05-25 05:44:28 [INFO]: Epoch 020 - training loss: 0.9071, validation loss: 0.9660
2024-05-25 05:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch20_loss0.9660248458385468.pypots
2024-05-25 05:44:28 [INFO]: Epoch 021 - training loss: 0.8784, validation loss: 0.9589
2024-05-25 05:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch21_loss0.9589067995548248.pypots
2024-05-25 05:44:28 [INFO]: Epoch 022 - training loss: 0.8382, validation loss: 0.9599
2024-05-25 05:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch22_loss0.9598746746778488.pypots
2024-05-25 05:44:28 [INFO]: Epoch 023 - training loss: 0.8533, validation loss: 0.9550
2024-05-25 05:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch23_loss0.9549654424190521.pypots
2024-05-25 05:44:28 [INFO]: Epoch 024 - training loss: 0.8531, validation loss: 0.9518
2024-05-25 05:44:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch24_loss0.9518455564975739.pypots
2024-05-25 05:44:29 [INFO]: Epoch 025 - training loss: 0.8740, validation loss: 0.9464
2024-05-25 05:44:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch25_loss0.9464221894741058.pypots
2024-05-25 05:44:29 [INFO]: Epoch 026 - training loss: 0.8172, validation loss: 0.9450
2024-05-25 05:44:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch26_loss0.94503054022789.pypots
2024-05-25 05:44:29 [INFO]: Epoch 027 - training loss: 0.8788, validation loss: 0.9458
2024-05-25 05:44:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch27_loss0.9458449631929398.pypots
2024-05-25 05:44:29 [INFO]: Epoch 028 - training loss: 0.8323, validation loss: 0.9383
2024-05-25 05:44:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch28_loss0.9382675588130951.pypots
2024-05-25 05:44:29 [INFO]: Epoch 029 - training loss: 0.8182, validation loss: 0.9373
2024-05-25 05:44:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch29_loss0.9373363703489304.pypots
2024-05-25 05:44:30 [INFO]: Epoch 030 - training loss: 0.8212, validation loss: 0.9358
2024-05-25 05:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch30_loss0.9357988238334656.pypots
2024-05-25 05:44:30 [INFO]: Epoch 031 - training loss: 0.8244, validation loss: 0.9339
2024-05-25 05:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch31_loss0.9338793605566025.pypots
2024-05-25 05:44:30 [INFO]: Epoch 032 - training loss: 0.8321, validation loss: 0.9274
2024-05-25 05:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch32_loss0.9274416863918304.pypots
2024-05-25 05:44:30 [INFO]: Epoch 033 - training loss: 0.8290, validation loss: 0.9240
2024-05-25 05:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch33_loss0.9239649474620819.pypots
2024-05-25 05:44:30 [INFO]: Epoch 034 - training loss: 0.8111, validation loss: 0.9260
2024-05-25 05:44:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch34_loss0.9260037541389465.pypots
2024-05-25 05:44:31 [INFO]: Epoch 035 - training loss: 0.8245, validation loss: 0.9218
2024-05-25 05:44:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch35_loss0.9218164682388306.pypots
2024-05-25 05:44:31 [INFO]: Epoch 036 - training loss: 0.8246, validation loss: 0.9163
2024-05-25 05:44:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch36_loss0.9162878096103668.pypots
2024-05-25 05:44:31 [INFO]: Epoch 037 - training loss: 0.8334, validation loss: 0.9133
2024-05-25 05:44:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch37_loss0.9132983088493347.pypots
2024-05-25 05:44:31 [INFO]: Epoch 038 - training loss: 0.8246, validation loss: 0.9110
2024-05-25 05:44:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch38_loss0.9109574556350708.pypots
2024-05-25 05:44:31 [INFO]: Epoch 039 - training loss: 0.8250, validation loss: 0.9094
2024-05-25 05:44:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch39_loss0.9094488024711609.pypots
2024-05-25 05:44:32 [INFO]: Epoch 040 - training loss: 0.8385, validation loss: 0.9088
2024-05-25 05:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch40_loss0.908827155828476.pypots
2024-05-25 05:44:32 [INFO]: Epoch 041 - training loss: 0.8269, validation loss: 0.9080
2024-05-25 05:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch41_loss0.9080488234758377.pypots
2024-05-25 05:44:32 [INFO]: Epoch 042 - training loss: 0.8154, validation loss: 0.9040
2024-05-25 05:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch42_loss0.9039742350578308.pypots
2024-05-25 05:44:32 [INFO]: Epoch 043 - training loss: 0.8280, validation loss: 0.9023
2024-05-25 05:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch43_loss0.9023373126983643.pypots
2024-05-25 05:44:32 [INFO]: Epoch 044 - training loss: 0.8173, validation loss: 0.8988
2024-05-25 05:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch44_loss0.8988325595855713.pypots
2024-05-25 05:44:33 [INFO]: Epoch 045 - training loss: 0.8141, validation loss: 0.8960
2024-05-25 05:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch45_loss0.8960153609514236.pypots
2024-05-25 05:44:33 [INFO]: Epoch 046 - training loss: 0.8261, validation loss: 0.8992
2024-05-25 05:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch46_loss0.8991693407297134.pypots
2024-05-25 05:44:33 [INFO]: Epoch 047 - training loss: 0.8598, validation loss: 0.9037
2024-05-25 05:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch47_loss0.9037062227725983.pypots
2024-05-25 05:44:33 [INFO]: Epoch 048 - training loss: 0.8060, validation loss: 0.9001
2024-05-25 05:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch48_loss0.9000726640224457.pypots
2024-05-25 05:44:33 [INFO]: Epoch 049 - training loss: 0.8158, validation loss: 0.8932
2024-05-25 05:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch49_loss0.8931572437286377.pypots
2024-05-25 05:44:33 [INFO]: Epoch 050 - training loss: 0.8385, validation loss: 0.8981
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch50_loss0.8981212824583054.pypots
2024-05-25 05:44:34 [INFO]: Epoch 051 - training loss: 0.8489, validation loss: 0.8940
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch51_loss0.8940346539020538.pypots
2024-05-25 05:44:34 [INFO]: Epoch 052 - training loss: 0.8061, validation loss: 0.8939
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch52_loss0.8939090669155121.pypots
2024-05-25 05:44:34 [INFO]: Epoch 053 - training loss: 0.8293, validation loss: 0.8883
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch53_loss0.8882651329040527.pypots
2024-05-25 05:44:34 [INFO]: Epoch 054 - training loss: 0.8335, validation loss: 0.8901
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch54_loss0.8900811970233917.pypots
2024-05-25 05:44:34 [INFO]: Epoch 055 - training loss: 0.8076, validation loss: 0.8894
2024-05-25 05:44:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch55_loss0.8894301503896713.pypots
2024-05-25 05:44:35 [INFO]: Epoch 056 - training loss: 0.7847, validation loss: 0.8905
2024-05-25 05:44:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch56_loss0.8905056118965149.pypots
2024-05-25 05:44:35 [INFO]: Epoch 057 - training loss: 0.8088, validation loss: 0.8897
2024-05-25 05:44:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch57_loss0.8897402137517929.pypots
2024-05-25 05:44:35 [INFO]: Epoch 058 - training loss: 0.7962, validation loss: 0.8893
2024-05-25 05:44:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch58_loss0.8893128037452698.pypots
2024-05-25 05:44:35 [INFO]: Epoch 059 - training loss: 0.8054, validation loss: 0.8861
2024-05-25 05:44:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch59_loss0.8861000537872314.pypots
2024-05-25 05:44:35 [INFO]: Epoch 060 - training loss: 0.8057, validation loss: 0.8875
2024-05-25 05:44:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch60_loss0.8874873667955399.pypots
2024-05-25 05:44:36 [INFO]: Epoch 061 - training loss: 0.8006, validation loss: 0.8885
2024-05-25 05:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch61_loss0.8885466903448105.pypots
2024-05-25 05:44:36 [INFO]: Epoch 062 - training loss: 0.8247, validation loss: 0.8860
2024-05-25 05:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch62_loss0.8859937638044357.pypots
2024-05-25 05:44:36 [INFO]: Epoch 063 - training loss: 0.8228, validation loss: 0.8842
2024-05-25 05:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch63_loss0.8842095285654068.pypots
2024-05-25 05:44:36 [INFO]: Epoch 064 - training loss: 0.8216, validation loss: 0.8887
2024-05-25 05:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch64_loss0.8887205719947815.pypots
2024-05-25 05:44:36 [INFO]: Epoch 065 - training loss: 0.8093, validation loss: 0.8875
2024-05-25 05:44:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch65_loss0.8874748945236206.pypots
2024-05-25 05:44:37 [INFO]: Epoch 066 - training loss: 0.8191, validation loss: 0.8916
2024-05-25 05:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch66_loss0.8916362673044205.pypots
2024-05-25 05:44:37 [INFO]: Epoch 067 - training loss: 0.7845, validation loss: 0.8887
2024-05-25 05:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch67_loss0.8887160569429398.pypots
2024-05-25 05:44:37 [INFO]: Epoch 068 - training loss: 0.8237, validation loss: 0.8883
2024-05-25 05:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch68_loss0.8882694989442825.pypots
2024-05-25 05:44:37 [INFO]: Epoch 069 - training loss: 0.7939, validation loss: 0.8910
2024-05-25 05:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch69_loss0.8910348862409592.pypots
2024-05-25 05:44:37 [INFO]: Epoch 070 - training loss: 0.8011, validation loss: 0.8847
2024-05-25 05:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch70_loss0.8847146779298782.pypots
2024-05-25 05:44:38 [INFO]: Epoch 071 - training loss: 0.8065, validation loss: 0.8841
2024-05-25 05:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch71_loss0.884103536605835.pypots
2024-05-25 05:44:38 [INFO]: Epoch 072 - training loss: 0.8056, validation loss: 0.8834
2024-05-25 05:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch72_loss0.8834047019481659.pypots
2024-05-25 05:44:38 [INFO]: Epoch 073 - training loss: 0.7917, validation loss: 0.8828
2024-05-25 05:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch73_loss0.8828487545251846.pypots
2024-05-25 05:44:38 [INFO]: Epoch 074 - training loss: 0.7961, validation loss: 0.8851
2024-05-25 05:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch74_loss0.8850899934768677.pypots
2024-05-25 05:44:38 [INFO]: Epoch 075 - training loss: 0.8115, validation loss: 0.8827
2024-05-25 05:44:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch75_loss0.8827463835477829.pypots
2024-05-25 05:44:39 [INFO]: Epoch 076 - training loss: 0.8144, validation loss: 0.8848
2024-05-25 05:44:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch76_loss0.884838655591011.pypots
2024-05-25 05:44:39 [INFO]: Epoch 077 - training loss: 0.8075, validation loss: 0.8828
2024-05-25 05:44:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch77_loss0.8827787786722183.pypots
2024-05-25 05:44:39 [INFO]: Epoch 078 - training loss: 0.8012, validation loss: 0.8876
2024-05-25 05:44:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch78_loss0.8875935524702072.pypots
2024-05-25 05:44:39 [INFO]: Epoch 079 - training loss: 0.7765, validation loss: 0.8864
2024-05-25 05:44:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch79_loss0.8863831460475922.pypots
2024-05-25 05:44:39 [INFO]: Epoch 080 - training loss: 0.8192, validation loss: 0.8840
2024-05-25 05:44:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch80_loss0.8839665204286575.pypots
2024-05-25 05:44:40 [INFO]: Epoch 081 - training loss: 0.8195, validation loss: 0.8870
2024-05-25 05:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch81_loss0.8870235830545425.pypots
2024-05-25 05:44:40 [INFO]: Epoch 082 - training loss: 0.8007, validation loss: 0.8854
2024-05-25 05:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch82_loss0.8854482024908066.pypots
2024-05-25 05:44:40 [INFO]: Epoch 083 - training loss: 0.7841, validation loss: 0.8817
2024-05-25 05:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch83_loss0.8817441761493683.pypots
2024-05-25 05:44:40 [INFO]: Epoch 084 - training loss: 0.8059, validation loss: 0.8821
2024-05-25 05:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch84_loss0.8821309357881546.pypots
2024-05-25 05:44:40 [INFO]: Epoch 085 - training loss: 0.7871, validation loss: 0.8836
2024-05-25 05:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch85_loss0.8835771232843399.pypots
2024-05-25 05:44:41 [INFO]: Epoch 086 - training loss: 0.7989, validation loss: 0.8790
2024-05-25 05:44:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch86_loss0.87904092669487.pypots
2024-05-25 05:44:41 [INFO]: Epoch 087 - training loss: 0.7748, validation loss: 0.8808
2024-05-25 05:44:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch87_loss0.8808236718177795.pypots
2024-05-25 05:44:41 [INFO]: Epoch 088 - training loss: 0.8152, validation loss: 0.8787
2024-05-25 05:44:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch88_loss0.8787141442298889.pypots
2024-05-25 05:44:41 [INFO]: Epoch 089 - training loss: 0.7951, validation loss: 0.8768
2024-05-25 05:44:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch89_loss0.8768094629049301.pypots
2024-05-25 05:44:41 [INFO]: Epoch 090 - training loss: 0.8037, validation loss: 0.8730
2024-05-25 05:44:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch90_loss0.8729974329471588.pypots
2024-05-25 05:44:42 [INFO]: Epoch 091 - training loss: 0.7894, validation loss: 0.8801
2024-05-25 05:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch91_loss0.8801064640283585.pypots
2024-05-25 05:44:42 [INFO]: Epoch 092 - training loss: 0.7865, validation loss: 0.8784
2024-05-25 05:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch92_loss0.878436729311943.pypots
2024-05-25 05:44:42 [INFO]: Epoch 093 - training loss: 0.7710, validation loss: 0.8753
2024-05-25 05:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch93_loss0.8753061890602112.pypots
2024-05-25 05:44:42 [INFO]: Epoch 094 - training loss: 0.7981, validation loss: 0.8779
2024-05-25 05:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch94_loss0.8779313564300537.pypots
2024-05-25 05:44:42 [INFO]: Epoch 095 - training loss: 0.8084, validation loss: 0.8719
2024-05-25 05:44:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch95_loss0.8719040751457214.pypots
2024-05-25 05:44:43 [INFO]: Epoch 096 - training loss: 0.8007, validation loss: 0.8749
2024-05-25 05:44:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch96_loss0.8748661428689957.pypots
2024-05-25 05:44:43 [INFO]: Epoch 097 - training loss: 0.8034, validation loss: 0.8705
2024-05-25 05:44:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch97_loss0.8705112338066101.pypots
2024-05-25 05:44:43 [INFO]: Epoch 098 - training loss: 0.7976, validation loss: 0.8693
2024-05-25 05:44:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch98_loss0.869316965341568.pypots
2024-05-25 05:44:43 [INFO]: Epoch 099 - training loss: 0.7809, validation loss: 0.8714
2024-05-25 05:44:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch99_loss0.8713586926460266.pypots
2024-05-25 05:44:43 [INFO]: Epoch 100 - training loss: 0.7978, validation loss: 0.8725
2024-05-25 05:44:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch100_loss0.8725415766239166.pypots
2024-05-25 05:44:44 [INFO]: Epoch 101 - training loss: 0.8017, validation loss: 0.8678
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch101_loss0.8677862882614136.pypots
2024-05-25 05:44:44 [INFO]: Epoch 102 - training loss: 0.7914, validation loss: 0.8701
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch102_loss0.8700813800096512.pypots
2024-05-25 05:44:44 [INFO]: Epoch 103 - training loss: 0.7724, validation loss: 0.8705
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch103_loss0.8704798370599747.pypots
2024-05-25 05:44:44 [INFO]: Epoch 104 - training loss: 0.7930, validation loss: 0.8665
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch104_loss0.866457387804985.pypots
2024-05-25 05:44:44 [INFO]: Epoch 105 - training loss: 0.7892, validation loss: 0.8707
2024-05-25 05:44:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch105_loss0.8707269132137299.pypots
2024-05-25 05:44:45 [INFO]: Epoch 106 - training loss: 0.7686, validation loss: 0.8685
2024-05-25 05:44:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch106_loss0.8685135245323181.pypots
2024-05-25 05:44:45 [INFO]: Epoch 107 - training loss: 0.8019, validation loss: 0.8674
2024-05-25 05:44:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch107_loss0.8674145638942719.pypots
2024-05-25 05:44:45 [INFO]: Epoch 108 - training loss: 0.7721, validation loss: 0.8663
2024-05-25 05:44:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch108_loss0.8663470894098282.pypots
2024-05-25 05:44:45 [INFO]: Epoch 109 - training loss: 0.7770, validation loss: 0.8713
2024-05-25 05:44:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch109_loss0.8713317066431046.pypots
2024-05-25 05:44:45 [INFO]: Epoch 110 - training loss: 0.8119, validation loss: 0.8662
2024-05-25 05:44:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch110_loss0.8662268817424774.pypots
2024-05-25 05:44:46 [INFO]: Epoch 111 - training loss: 0.7992, validation loss: 0.8649
2024-05-25 05:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch111_loss0.8649128526449203.pypots
2024-05-25 05:44:46 [INFO]: Epoch 112 - training loss: 0.7881, validation loss: 0.8680
2024-05-25 05:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch112_loss0.8679825365543365.pypots
2024-05-25 05:44:46 [INFO]: Epoch 113 - training loss: 0.7902, validation loss: 0.8646
2024-05-25 05:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch113_loss0.8645671010017395.pypots
2024-05-25 05:44:46 [INFO]: Epoch 114 - training loss: 0.8288, validation loss: 0.8635
2024-05-25 05:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch114_loss0.8634691089391708.pypots
2024-05-25 05:44:46 [INFO]: Epoch 115 - training loss: 0.8128, validation loss: 0.8613
2024-05-25 05:44:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch115_loss0.8613101691007614.pypots
2024-05-25 05:44:47 [INFO]: Epoch 116 - training loss: 0.8270, validation loss: 0.8649
2024-05-25 05:44:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch116_loss0.864874929189682.pypots
2024-05-25 05:44:47 [INFO]: Epoch 117 - training loss: 0.7827, validation loss: 0.8634
2024-05-25 05:44:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch117_loss0.8634423762559891.pypots
2024-05-25 05:44:47 [INFO]: Epoch 118 - training loss: 0.7718, validation loss: 0.8632
2024-05-25 05:44:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch118_loss0.8632433265447617.pypots
2024-05-25 05:44:47 [INFO]: Epoch 119 - training loss: 0.8155, validation loss: 0.8673
2024-05-25 05:44:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch119_loss0.8672686964273453.pypots
2024-05-25 05:44:47 [INFO]: Epoch 120 - training loss: 0.7799, validation loss: 0.8619
2024-05-25 05:44:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch120_loss0.8619307577610016.pypots
2024-05-25 05:44:48 [INFO]: Epoch 121 - training loss: 0.7917, validation loss: 0.8627
2024-05-25 05:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch121_loss0.8626907616853714.pypots
2024-05-25 05:44:48 [INFO]: Epoch 122 - training loss: 0.7895, validation loss: 0.8580
2024-05-25 05:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch122_loss0.858014389872551.pypots
2024-05-25 05:44:48 [INFO]: Epoch 123 - training loss: 0.7809, validation loss: 0.8602
2024-05-25 05:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch123_loss0.8601500689983368.pypots
2024-05-25 05:44:48 [INFO]: Epoch 124 - training loss: 0.7588, validation loss: 0.8573
2024-05-25 05:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch124_loss0.8572943359613419.pypots
2024-05-25 05:44:48 [INFO]: Epoch 125 - training loss: 0.7775, validation loss: 0.8651
2024-05-25 05:44:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch125_loss0.8650558441877365.pypots
2024-05-25 05:44:49 [INFO]: Epoch 126 - training loss: 0.8002, validation loss: 0.8592
2024-05-25 05:44:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch126_loss0.8591536730527878.pypots
2024-05-25 05:44:49 [INFO]: Epoch 127 - training loss: 0.7693, validation loss: 0.8549
2024-05-25 05:44:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch127_loss0.8549250364303589.pypots
2024-05-25 05:44:49 [INFO]: Epoch 128 - training loss: 0.7749, validation loss: 0.8567
2024-05-25 05:44:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch128_loss0.856720894575119.pypots
2024-05-25 05:44:49 [INFO]: Epoch 129 - training loss: 0.7683, validation loss: 0.8552
2024-05-25 05:44:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch129_loss0.8551744222640991.pypots
2024-05-25 05:44:49 [INFO]: Epoch 130 - training loss: 0.7856, validation loss: 0.8572
2024-05-25 05:44:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch130_loss0.8572188019752502.pypots
2024-05-25 05:44:50 [INFO]: Epoch 131 - training loss: 0.7848, validation loss: 0.8520
2024-05-25 05:44:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch131_loss0.8519509732723236.pypots
2024-05-25 05:44:50 [INFO]: Epoch 132 - training loss: 0.7790, validation loss: 0.8543
2024-05-25 05:44:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch132_loss0.8542662709951401.pypots
2024-05-25 05:44:50 [INFO]: Epoch 133 - training loss: 0.7629, validation loss: 0.8550
2024-05-25 05:44:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch133_loss0.85504549741745.pypots
2024-05-25 05:44:50 [INFO]: Epoch 134 - training loss: 0.7734, validation loss: 0.8516
2024-05-25 05:44:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch134_loss0.8515857756137848.pypots
2024-05-25 05:44:50 [INFO]: Epoch 135 - training loss: 0.8205, validation loss: 0.8579
2024-05-25 05:44:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch135_loss0.8579275757074356.pypots
2024-05-25 05:44:51 [INFO]: Epoch 136 - training loss: 0.7994, validation loss: 0.8475
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch136_loss0.8475328683853149.pypots
2024-05-25 05:44:51 [INFO]: Epoch 137 - training loss: 0.7905, validation loss: 0.8498
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch137_loss0.8497938513755798.pypots
2024-05-25 05:44:51 [INFO]: Epoch 138 - training loss: 0.7807, validation loss: 0.8482
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch138_loss0.8481893390417099.pypots
2024-05-25 05:44:51 [INFO]: Epoch 139 - training loss: 0.8119, validation loss: 0.8491
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch139_loss0.8491444885730743.pypots
2024-05-25 05:44:51 [INFO]: Epoch 140 - training loss: 0.7562, validation loss: 0.8503
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch140_loss0.850333958864212.pypots
2024-05-25 05:44:51 [INFO]: Epoch 141 - training loss: 0.7733, validation loss: 0.8466
2024-05-25 05:44:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch141_loss0.8466299474239349.pypots
2024-05-25 05:44:52 [INFO]: Epoch 142 - training loss: 0.7976, validation loss: 0.8472
2024-05-25 05:44:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch142_loss0.8471735715866089.pypots
2024-05-25 05:44:52 [INFO]: Epoch 143 - training loss: 0.7813, validation loss: 0.8439
2024-05-25 05:44:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch143_loss0.8438806682825089.pypots
2024-05-25 05:44:52 [INFO]: Epoch 144 - training loss: 0.8002, validation loss: 0.8424
2024-05-25 05:44:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch144_loss0.8423729538917542.pypots
2024-05-25 05:44:52 [INFO]: Epoch 145 - training loss: 0.7780, validation loss: 0.8456
2024-05-25 05:44:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch145_loss0.8455621898174286.pypots
2024-05-25 05:44:52 [INFO]: Epoch 146 - training loss: 0.7749, validation loss: 0.8387
2024-05-25 05:44:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch146_loss0.838724285364151.pypots
2024-05-25 05:44:53 [INFO]: Epoch 147 - training loss: 0.7725, validation loss: 0.8456
2024-05-25 05:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch147_loss0.8455672115087509.pypots
2024-05-25 05:44:53 [INFO]: Epoch 148 - training loss: 0.7834, validation loss: 0.8447
2024-05-25 05:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch148_loss0.8446821570396423.pypots
2024-05-25 05:44:53 [INFO]: Epoch 149 - training loss: 0.7654, validation loss: 0.8390
2024-05-25 05:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch149_loss0.8390015959739685.pypots
2024-05-25 05:44:53 [INFO]: Epoch 150 - training loss: 0.7924, validation loss: 0.8406
2024-05-25 05:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch150_loss0.8406430035829544.pypots
2024-05-25 05:44:53 [INFO]: Epoch 151 - training loss: 0.7859, validation loss: 0.8417
2024-05-25 05:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch151_loss0.841703861951828.pypots
2024-05-25 05:44:54 [INFO]: Epoch 152 - training loss: 0.7560, validation loss: 0.8420
2024-05-25 05:44:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch152_loss0.8419886827468872.pypots
2024-05-25 05:44:54 [INFO]: Epoch 153 - training loss: 0.7814, validation loss: 0.8380
2024-05-25 05:44:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch153_loss0.8379905968904495.pypots
2024-05-25 05:44:54 [INFO]: Epoch 154 - training loss: 0.7935, validation loss: 0.8379
2024-05-25 05:44:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch154_loss0.8379223942756653.pypots
2024-05-25 05:44:54 [INFO]: Epoch 155 - training loss: 0.7824, validation loss: 0.8415
2024-05-25 05:44:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch155_loss0.8415480554103851.pypots
2024-05-25 05:44:54 [INFO]: Epoch 156 - training loss: 0.7940, validation loss: 0.8371
2024-05-25 05:44:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch156_loss0.8371127545833588.pypots
2024-05-25 05:44:55 [INFO]: Epoch 157 - training loss: 0.7664, validation loss: 0.8418
2024-05-25 05:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch157_loss0.8417889326810837.pypots
2024-05-25 05:44:55 [INFO]: Epoch 158 - training loss: 0.7859, validation loss: 0.8353
2024-05-25 05:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch158_loss0.8353360444307327.pypots
2024-05-25 05:44:55 [INFO]: Epoch 159 - training loss: 0.7743, validation loss: 0.8355
2024-05-25 05:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch159_loss0.8354806452989578.pypots
2024-05-25 05:44:55 [INFO]: Epoch 160 - training loss: 0.7833, validation loss: 0.8403
2024-05-25 05:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch160_loss0.8403291702270508.pypots
2024-05-25 05:44:55 [INFO]: Epoch 161 - training loss: 0.7670, validation loss: 0.8388
2024-05-25 05:44:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch161_loss0.838825523853302.pypots
2024-05-25 05:44:56 [INFO]: Epoch 162 - training loss: 0.7613, validation loss: 0.8365
2024-05-25 05:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch162_loss0.8365418761968613.pypots
2024-05-25 05:44:56 [INFO]: Epoch 163 - training loss: 0.7822, validation loss: 0.8322
2024-05-25 05:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch163_loss0.8321641534566879.pypots
2024-05-25 05:44:56 [INFO]: Epoch 164 - training loss: 0.7916, validation loss: 0.8313
2024-05-25 05:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch164_loss0.8312894850969315.pypots
2024-05-25 05:44:56 [INFO]: Epoch 165 - training loss: 0.8320, validation loss: 0.8303
2024-05-25 05:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch165_loss0.8302791714668274.pypots
2024-05-25 05:44:56 [INFO]: Epoch 166 - training loss: 0.8130, validation loss: 0.8305
2024-05-25 05:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch166_loss0.8304606229066849.pypots
2024-05-25 05:44:57 [INFO]: Epoch 167 - training loss: 0.7974, validation loss: 0.8357
2024-05-25 05:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch167_loss0.8356501460075378.pypots
2024-05-25 05:44:57 [INFO]: Epoch 168 - training loss: 0.7927, validation loss: 0.8348
2024-05-25 05:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch168_loss0.8348306864500046.pypots
2024-05-25 05:44:57 [INFO]: Epoch 169 - training loss: 0.7734, validation loss: 0.8370
2024-05-25 05:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch169_loss0.8369710594415665.pypots
2024-05-25 05:44:57 [INFO]: Epoch 170 - training loss: 0.7959, validation loss: 0.8321
2024-05-25 05:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch170_loss0.8320877403020859.pypots
2024-05-25 05:44:57 [INFO]: Epoch 171 - training loss: 0.7742, validation loss: 0.8331
2024-05-25 05:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch171_loss0.8330789655447006.pypots
2024-05-25 05:44:58 [INFO]: Epoch 172 - training loss: 0.7773, validation loss: 0.8305
2024-05-25 05:44:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch172_loss0.8305067718029022.pypots
2024-05-25 05:44:58 [INFO]: Epoch 173 - training loss: 0.7612, validation loss: 0.8315
2024-05-25 05:44:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch173_loss0.8314574658870697.pypots
2024-05-25 05:44:58 [INFO]: Epoch 174 - training loss: 0.7633, validation loss: 0.8300
2024-05-25 05:44:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch174_loss0.8300371319055557.pypots
2024-05-25 05:44:58 [INFO]: Epoch 175 - training loss: 0.7720, validation loss: 0.8299
2024-05-25 05:44:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch175_loss0.8299312144517899.pypots
2024-05-25 05:44:58 [INFO]: Epoch 176 - training loss: 0.7852, validation loss: 0.8314
2024-05-25 05:44:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch176_loss0.831364631652832.pypots
2024-05-25 05:44:59 [INFO]: Epoch 177 - training loss: 0.7922, validation loss: 0.8294
2024-05-25 05:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch177_loss0.829432874917984.pypots
2024-05-25 05:44:59 [INFO]: Epoch 178 - training loss: 0.7948, validation loss: 0.8256
2024-05-25 05:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch178_loss0.8255557417869568.pypots
2024-05-25 05:44:59 [INFO]: Epoch 179 - training loss: 0.7572, validation loss: 0.8304
2024-05-25 05:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch179_loss0.8303512036800385.pypots
2024-05-25 05:44:59 [INFO]: Epoch 180 - training loss: 0.7631, validation loss: 0.8284
2024-05-25 05:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch180_loss0.8284289240837097.pypots
2024-05-25 05:44:59 [INFO]: Epoch 181 - training loss: 0.8202, validation loss: 0.8313
2024-05-25 05:44:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch181_loss0.8313236683607101.pypots
2024-05-25 05:45:00 [INFO]: Epoch 182 - training loss: 0.7943, validation loss: 0.8240
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch182_loss0.8239840269088745.pypots
2024-05-25 05:45:00 [INFO]: Epoch 183 - training loss: 0.7908, validation loss: 0.8264
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch183_loss0.826411172747612.pypots
2024-05-25 05:45:00 [INFO]: Epoch 184 - training loss: 0.7615, validation loss: 0.8249
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch184_loss0.8249056488275528.pypots
2024-05-25 05:45:00 [INFO]: Epoch 185 - training loss: 0.7903, validation loss: 0.8287
2024-05-25 05:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch185_loss0.8287046402692795.pypots
2024-05-25 05:45:01 [INFO]: Epoch 186 - training loss: 0.8250, validation loss: 0.8266
2024-05-25 05:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch186_loss0.8265671730041504.pypots
2024-05-25 05:45:01 [INFO]: Epoch 187 - training loss: 0.7878, validation loss: 0.8244
2024-05-25 05:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch187_loss0.8244154453277588.pypots
2024-05-25 05:45:01 [INFO]: Epoch 188 - training loss: 0.7818, validation loss: 0.8236
2024-05-25 05:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch188_loss0.8235826939344406.pypots
2024-05-25 05:45:01 [INFO]: Epoch 189 - training loss: 0.7870, validation loss: 0.8304
2024-05-25 05:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch189_loss0.8303501904010773.pypots
2024-05-25 05:45:01 [INFO]: Epoch 190 - training loss: 0.8178, validation loss: 0.8261
2024-05-25 05:45:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch190_loss0.8260727375745773.pypots
2024-05-25 05:45:02 [INFO]: Epoch 191 - training loss: 0.7714, validation loss: 0.8234
2024-05-25 05:45:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch191_loss0.8234192579984665.pypots
2024-05-25 05:45:02 [INFO]: Epoch 192 - training loss: 0.8242, validation loss: 0.8255
2024-05-25 05:45:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch192_loss0.8255257606506348.pypots
2024-05-25 05:45:02 [INFO]: Epoch 193 - training loss: 0.7803, validation loss: 0.8285
2024-05-25 05:45:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch193_loss0.8285284042358398.pypots
2024-05-25 05:45:02 [INFO]: Epoch 194 - training loss: 0.7576, validation loss: 0.8241
2024-05-25 05:45:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch194_loss0.8241086900234222.pypots
2024-05-25 05:45:02 [INFO]: Epoch 195 - training loss: 0.7939, validation loss: 0.8216
2024-05-25 05:45:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch195_loss0.8215721696615219.pypots
2024-05-25 05:45:03 [INFO]: Epoch 196 - training loss: 0.7724, validation loss: 0.8198
2024-05-25 05:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch196_loss0.8197706490755081.pypots
2024-05-25 05:45:03 [INFO]: Epoch 197 - training loss: 0.7994, validation loss: 0.8199
2024-05-25 05:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch197_loss0.8199456185102463.pypots
2024-05-25 05:45:03 [INFO]: Epoch 198 - training loss: 0.7914, validation loss: 0.8224
2024-05-25 05:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch198_loss0.8223776668310165.pypots
2024-05-25 05:45:03 [INFO]: Epoch 199 - training loss: 0.7812, validation loss: 0.8255
2024-05-25 05:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch199_loss0.8254913985729218.pypots
2024-05-25 05:45:03 [INFO]: Epoch 200 - training loss: 0.7816, validation loss: 0.8200
2024-05-25 05:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch200_loss0.81997250020504.pypots
2024-05-25 05:45:04 [INFO]: Epoch 201 - training loss: 0.7806, validation loss: 0.8196
2024-05-25 05:45:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch201_loss0.8195947557687759.pypots
2024-05-25 05:45:04 [INFO]: Epoch 202 - training loss: 0.7846, validation loss: 0.8203
2024-05-25 05:45:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch202_loss0.820277526974678.pypots
2024-05-25 05:45:04 [INFO]: Epoch 203 - training loss: 0.7895, validation loss: 0.8228
2024-05-25 05:45:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch203_loss0.8228139281272888.pypots
2024-05-25 05:45:04 [INFO]: Epoch 204 - training loss: 0.7970, validation loss: 0.8188
2024-05-25 05:45:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch204_loss0.818835973739624.pypots
2024-05-25 05:45:04 [INFO]: Epoch 205 - training loss: 0.8053, validation loss: 0.8200
2024-05-25 05:45:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch205_loss0.8199629932641983.pypots
2024-05-25 05:45:05 [INFO]: Epoch 206 - training loss: 0.7968, validation loss: 0.8191
2024-05-25 05:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch206_loss0.8190620392560959.pypots
2024-05-25 05:45:05 [INFO]: Epoch 207 - training loss: 0.7720, validation loss: 0.8176
2024-05-25 05:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch207_loss0.8175762891769409.pypots
2024-05-25 05:45:05 [INFO]: Epoch 208 - training loss: 0.7749, validation loss: 0.8165
2024-05-25 05:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch208_loss0.8165212273597717.pypots
2024-05-25 05:45:05 [INFO]: Epoch 209 - training loss: 0.7691, validation loss: 0.8171
2024-05-25 05:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch209_loss0.8170657604932785.pypots
2024-05-25 05:45:05 [INFO]: Epoch 210 - training loss: 0.7790, validation loss: 0.8168
2024-05-25 05:45:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch210_loss0.8168074488639832.pypots
2024-05-25 05:45:06 [INFO]: Epoch 211 - training loss: 0.8011, validation loss: 0.8217
2024-05-25 05:45:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch211_loss0.8217078000307083.pypots
2024-05-25 05:45:06 [INFO]: Epoch 212 - training loss: 0.8000, validation loss: 0.8148
2024-05-25 05:45:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch212_loss0.81479811668396.pypots
2024-05-25 05:45:06 [INFO]: Epoch 213 - training loss: 0.7878, validation loss: 0.8134
2024-05-25 05:45:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch213_loss0.8134079724550247.pypots
2024-05-25 05:45:06 [INFO]: Epoch 214 - training loss: 0.7590, validation loss: 0.8198
2024-05-25 05:45:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch214_loss0.8198440968990326.pypots
2024-05-25 05:45:06 [INFO]: Epoch 215 - training loss: 0.7677, validation loss: 0.8134
2024-05-25 05:45:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch215_loss0.8134180158376694.pypots
2024-05-25 05:45:07 [INFO]: Epoch 216 - training loss: 0.7656, validation loss: 0.8184
2024-05-25 05:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch216_loss0.8184152394533157.pypots
2024-05-25 05:45:07 [INFO]: Epoch 217 - training loss: 0.7663, validation loss: 0.8185
2024-05-25 05:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch217_loss0.818532720208168.pypots
2024-05-25 05:45:07 [INFO]: Epoch 218 - training loss: 0.7832, validation loss: 0.8166
2024-05-25 05:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch218_loss0.8165793716907501.pypots
2024-05-25 05:45:07 [INFO]: Epoch 219 - training loss: 0.7529, validation loss: 0.8149
2024-05-25 05:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch219_loss0.814947709441185.pypots
2024-05-25 05:45:07 [INFO]: Epoch 220 - training loss: 0.7576, validation loss: 0.8151
2024-05-25 05:45:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch220_loss0.8150636106729507.pypots
2024-05-25 05:45:08 [INFO]: Epoch 221 - training loss: 0.7813, validation loss: 0.8110
2024-05-25 05:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch221_loss0.810979574918747.pypots
2024-05-25 05:45:08 [INFO]: Epoch 222 - training loss: 0.7599, validation loss: 0.8117
2024-05-25 05:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch222_loss0.8117304891347885.pypots
2024-05-25 05:45:08 [INFO]: Epoch 223 - training loss: 0.7680, validation loss: 0.8125
2024-05-25 05:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch223_loss0.8125309497117996.pypots
2024-05-25 05:45:08 [INFO]: Epoch 224 - training loss: 0.7887, validation loss: 0.8123
2024-05-25 05:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch224_loss0.812259167432785.pypots
2024-05-25 05:45:08 [INFO]: Epoch 225 - training loss: 0.7856, validation loss: 0.8140
2024-05-25 05:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch225_loss0.8140375763177872.pypots
2024-05-25 05:45:09 [INFO]: Epoch 226 - training loss: 0.7738, validation loss: 0.8103
2024-05-25 05:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch226_loss0.8103422969579697.pypots
2024-05-25 05:45:09 [INFO]: Epoch 227 - training loss: 0.7889, validation loss: 0.8100
2024-05-25 05:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch227_loss0.8099797070026398.pypots
2024-05-25 05:45:09 [INFO]: Epoch 228 - training loss: 0.7799, validation loss: 0.8108
2024-05-25 05:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch228_loss0.8108473420143127.pypots
2024-05-25 05:45:09 [INFO]: Epoch 229 - training loss: 0.7665, validation loss: 0.8124
2024-05-25 05:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch229_loss0.812382847070694.pypots
2024-05-25 05:45:09 [INFO]: Epoch 230 - training loss: 0.7739, validation loss: 0.8104
2024-05-25 05:45:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch230_loss0.810409352183342.pypots
2024-05-25 05:45:10 [INFO]: Epoch 231 - training loss: 0.7784, validation loss: 0.8093
2024-05-25 05:45:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch231_loss0.8092920631170273.pypots
2024-05-25 05:45:10 [INFO]: Epoch 232 - training loss: 0.7735, validation loss: 0.8108
2024-05-25 05:45:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch232_loss0.8108367174863815.pypots
2024-05-25 05:45:10 [INFO]: Epoch 233 - training loss: 0.7790, validation loss: 0.8130
2024-05-25 05:45:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch233_loss0.8130245506763458.pypots
2024-05-25 05:45:10 [INFO]: Epoch 234 - training loss: 0.7606, validation loss: 0.8105
2024-05-25 05:45:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch234_loss0.8105088621377945.pypots
2024-05-25 05:45:10 [INFO]: Epoch 235 - training loss: 0.7822, validation loss: 0.8057
2024-05-25 05:45:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch235_loss0.8056925684213638.pypots
2024-05-25 05:45:11 [INFO]: Epoch 236 - training loss: 0.7703, validation loss: 0.8139
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch236_loss0.813930943608284.pypots
2024-05-25 05:45:11 [INFO]: Epoch 237 - training loss: 0.7738, validation loss: 0.8071
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch237_loss0.8071073442697525.pypots
2024-05-25 05:45:11 [INFO]: Epoch 238 - training loss: 0.7909, validation loss: 0.8079
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch238_loss0.8078732788562775.pypots
2024-05-25 05:45:11 [INFO]: Epoch 239 - training loss: 0.7849, validation loss: 0.8092
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch239_loss0.8091912120580673.pypots
2024-05-25 05:45:11 [INFO]: Epoch 240 - training loss: 0.7784, validation loss: 0.8065
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch240_loss0.8065071702003479.pypots
2024-05-25 05:45:11 [INFO]: Epoch 241 - training loss: 0.7759, validation loss: 0.8055
2024-05-25 05:45:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch241_loss0.8055328279733658.pypots
2024-05-25 05:45:12 [INFO]: Epoch 242 - training loss: 0.7697, validation loss: 0.8061
2024-05-25 05:45:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch242_loss0.8061134815216064.pypots
2024-05-25 05:45:12 [INFO]: Epoch 243 - training loss: 0.7882, validation loss: 0.8055
2024-05-25 05:45:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch243_loss0.8054643273353577.pypots
2024-05-25 05:45:12 [INFO]: Epoch 244 - training loss: 0.7749, validation loss: 0.8049
2024-05-25 05:45:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch244_loss0.8049305230379105.pypots
2024-05-25 05:45:12 [INFO]: Epoch 245 - training loss: 0.7906, validation loss: 0.8027
2024-05-25 05:45:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch245_loss0.8026520758867264.pypots
2024-05-25 05:45:12 [INFO]: Epoch 246 - training loss: 0.7649, validation loss: 0.8102
2024-05-25 05:45:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch246_loss0.810235321521759.pypots
2024-05-25 05:45:13 [INFO]: Epoch 247 - training loss: 0.7760, validation loss: 0.8085
2024-05-25 05:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch247_loss0.8085062205791473.pypots
2024-05-25 05:45:13 [INFO]: Epoch 248 - training loss: 0.7764, validation loss: 0.8055
2024-05-25 05:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch248_loss0.8055398762226105.pypots
2024-05-25 05:45:13 [INFO]: Epoch 249 - training loss: 0.7786, validation loss: 0.8060
2024-05-25 05:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch249_loss0.8059505969285965.pypots
2024-05-25 05:45:13 [INFO]: Epoch 250 - training loss: 0.7949, validation loss: 0.8078
2024-05-25 05:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch250_loss0.8078163266181946.pypots
2024-05-25 05:45:13 [INFO]: Epoch 251 - training loss: 0.7781, validation loss: 0.8035
2024-05-25 05:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch251_loss0.8034788072109222.pypots
2024-05-25 05:45:14 [INFO]: Epoch 252 - training loss: 0.7797, validation loss: 0.8039
2024-05-25 05:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch252_loss0.8039093315601349.pypots
2024-05-25 05:45:14 [INFO]: Epoch 253 - training loss: 0.7806, validation loss: 0.8011
2024-05-25 05:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch253_loss0.8010613918304443.pypots
2024-05-25 05:45:14 [INFO]: Epoch 254 - training loss: 0.7999, validation loss: 0.8067
2024-05-25 05:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch254_loss0.8067097365856171.pypots
2024-05-25 05:45:14 [INFO]: Epoch 255 - training loss: 0.7805, validation loss: 0.8027
2024-05-25 05:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch255_loss0.8027288317680359.pypots
2024-05-25 05:45:14 [INFO]: Epoch 256 - training loss: 0.8053, validation loss: 0.8015
2024-05-25 05:45:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch256_loss0.8014556765556335.pypots
2024-05-25 05:45:15 [INFO]: Epoch 257 - training loss: 0.7804, validation loss: 0.7990
2024-05-25 05:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch257_loss0.7990234345197678.pypots
2024-05-25 05:45:15 [INFO]: Epoch 258 - training loss: 0.7799, validation loss: 0.8015
2024-05-25 05:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch258_loss0.8014697581529617.pypots
2024-05-25 05:45:15 [INFO]: Epoch 259 - training loss: 0.7781, validation loss: 0.8022
2024-05-25 05:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch259_loss0.8022298663854599.pypots
2024-05-25 05:45:15 [INFO]: Epoch 260 - training loss: 0.7705, validation loss: 0.8019
2024-05-25 05:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch260_loss0.8018510788679123.pypots
2024-05-25 05:45:15 [INFO]: Epoch 261 - training loss: 0.7775, validation loss: 0.8019
2024-05-25 05:45:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch261_loss0.8019222021102905.pypots
2024-05-25 05:45:16 [INFO]: Epoch 262 - training loss: 0.7502, validation loss: 0.8024
2024-05-25 05:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch262_loss0.8024039715528488.pypots
2024-05-25 05:45:16 [INFO]: Epoch 263 - training loss: 0.7636, validation loss: 0.8023
2024-05-25 05:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch263_loss0.8023455142974854.pypots
2024-05-25 05:45:16 [INFO]: Epoch 264 - training loss: 0.7821, validation loss: 0.8018
2024-05-25 05:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch264_loss0.801819384098053.pypots
2024-05-25 05:45:16 [INFO]: Epoch 265 - training loss: 0.8204, validation loss: 0.8069
2024-05-25 05:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch265_loss0.8069091439247131.pypots
2024-05-25 05:45:16 [INFO]: Epoch 266 - training loss: 0.7698, validation loss: 0.8038
2024-05-25 05:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch266_loss0.8038331121206284.pypots
2024-05-25 05:45:17 [INFO]: Epoch 267 - training loss: 0.7780, validation loss: 0.8033
2024-05-25 05:45:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN_epoch267_loss0.8032996505498886.pypots
2024-05-25 05:45:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:45:17 [INFO]: Finished training. The best model is from epoch#257.
2024-05-25 05:45:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240525_T054422/MRNN.pypots
2024-05-25 05:45:17 [INFO]: MRNN on ETTm1: MAE=0.6228, MSE=0.9976
2024-05-25 05:45:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 05:45:17 [INFO]: Using the given device: cpu
2024-05-25 05:45:17 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 05:45:17 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 05:45:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 05:45:17 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 05:45:17 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 05:45:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 05:45:17 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 05:45:17 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 05:45:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 05:45:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 05:45:17 [INFO]: Using the given device: cuda:0
2024-05-25 05:45:17 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T054517
2024-05-25 05:45:17 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T054517/tensorboard
2024-05-25 05:45:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 05:45:18 [INFO]: Epoch 001 - training loss: 1.1467, validation loss: 0.2826
2024-05-25 05:45:18 [INFO]: Epoch 002 - training loss: 0.8722, validation loss: 0.1253
2024-05-25 05:45:19 [INFO]: Epoch 003 - training loss: 0.7748, validation loss: 0.0938
2024-05-25 05:45:19 [INFO]: Epoch 004 - training loss: 0.7258, validation loss: 0.0769
2024-05-25 05:45:20 [INFO]: Epoch 005 - training loss: 0.7101, validation loss: 0.0847
2024-05-25 05:45:20 [INFO]: Epoch 006 - training loss: 0.6933, validation loss: 0.0808
2024-05-25 05:45:21 [INFO]: Epoch 007 - training loss: 0.6571, validation loss: 0.0696
2024-05-25 05:45:21 [INFO]: Epoch 008 - training loss: 0.6512, validation loss: 0.0566
2024-05-25 05:45:22 [INFO]: Epoch 009 - training loss: 0.6289, validation loss: 0.0659
2024-05-25 05:45:22 [INFO]: Epoch 010 - training loss: 0.6087, validation loss: 0.0578
2024-05-25 05:45:23 [INFO]: Epoch 011 - training loss: 0.6082, validation loss: 0.0595
2024-05-25 05:45:23 [INFO]: Epoch 012 - training loss: 0.6053, validation loss: 0.0590
2024-05-25 05:45:24 [INFO]: Epoch 013 - training loss: 0.5914, validation loss: 0.0743
2024-05-25 05:45:24 [INFO]: Epoch 014 - training loss: 0.5961, validation loss: 0.0474
2024-05-25 05:45:25 [INFO]: Epoch 015 - training loss: 0.6063, validation loss: 0.0501
2024-05-25 05:45:25 [INFO]: Epoch 016 - training loss: 0.5874, validation loss: 0.0507
2024-05-25 05:45:26 [INFO]: Epoch 017 - training loss: 0.5850, validation loss: 0.0625
2024-05-25 05:45:26 [INFO]: Epoch 018 - training loss: 0.5785, validation loss: 0.0693
2024-05-25 05:45:27 [INFO]: Epoch 019 - training loss: 0.5629, validation loss: 0.0495
2024-05-25 05:45:27 [INFO]: Epoch 020 - training loss: 0.5479, validation loss: 0.0432
2024-05-25 05:45:28 [INFO]: Epoch 021 - training loss: 0.5532, validation loss: 0.0596
2024-05-25 05:45:28 [INFO]: Epoch 022 - training loss: 0.5524, validation loss: 0.0524
2024-05-25 05:45:29 [INFO]: Epoch 023 - training loss: 0.5505, validation loss: 0.0570
2024-05-25 05:45:29 [INFO]: Epoch 024 - training loss: 0.5618, validation loss: 0.0488
2024-05-25 05:45:30 [INFO]: Epoch 025 - training loss: 0.5417, validation loss: 0.0437
2024-05-25 05:45:30 [INFO]: Epoch 026 - training loss: 0.5262, validation loss: 0.0413
2024-05-25 05:45:31 [INFO]: Epoch 027 - training loss: 0.5240, validation loss: 0.0421
2024-05-25 05:45:31 [INFO]: Epoch 028 - training loss: 0.5396, validation loss: 0.0411
2024-05-25 05:45:31 [INFO]: Epoch 029 - training loss: 0.5231, validation loss: 0.0357
2024-05-25 05:45:32 [INFO]: Epoch 030 - training loss: 0.5074, validation loss: 0.0474
2024-05-25 05:45:32 [INFO]: Epoch 031 - training loss: 0.5061, validation loss: 0.0390
2024-05-25 05:45:33 [INFO]: Epoch 032 - training loss: 0.5087, validation loss: 0.0377
2024-05-25 05:45:33 [INFO]: Epoch 033 - training loss: 0.5158, validation loss: 0.0352
2024-05-25 05:45:34 [INFO]: Epoch 034 - training loss: 0.5246, validation loss: 0.0367
2024-05-25 05:45:34 [INFO]: Epoch 035 - training loss: 0.5255, validation loss: 0.0607
2024-05-25 05:45:35 [INFO]: Epoch 036 - training loss: 0.5165, validation loss: 0.0427
2024-05-25 05:45:35 [INFO]: Epoch 037 - training loss: 0.4945, validation loss: 0.0427
2024-05-25 05:45:36 [INFO]: Epoch 038 - training loss: 0.4912, validation loss: 0.0377
2024-05-25 05:45:36 [INFO]: Epoch 039 - training loss: 0.4966, validation loss: 0.0426
2024-05-25 05:45:37 [INFO]: Epoch 040 - training loss: 0.4879, validation loss: 0.0357
2024-05-25 05:45:37 [INFO]: Epoch 041 - training loss: 0.4996, validation loss: 0.0336
2024-05-25 05:45:38 [INFO]: Epoch 042 - training loss: 0.4874, validation loss: 0.0411
2024-05-25 05:45:38 [INFO]: Epoch 043 - training loss: 0.4829, validation loss: 0.0343
2024-05-25 05:45:39 [INFO]: Epoch 044 - training loss: 0.4806, validation loss: 0.0407
2024-05-25 05:45:39 [INFO]: Epoch 045 - training loss: 0.4815, validation loss: 0.0419
2024-05-25 05:45:40 [INFO]: Epoch 046 - training loss: 0.4876, validation loss: 0.0411
2024-05-25 05:45:40 [INFO]: Epoch 047 - training loss: 0.4744, validation loss: 0.0385
2024-05-25 05:45:41 [INFO]: Epoch 048 - training loss: 0.4719, validation loss: 0.0340
2024-05-25 05:45:41 [INFO]: Epoch 049 - training loss: 0.4967, validation loss: 0.0340
2024-05-25 05:45:42 [INFO]: Epoch 050 - training loss: 0.4762, validation loss: 0.0457
2024-05-25 05:45:42 [INFO]: Epoch 051 - training loss: 0.4664, validation loss: 0.0313
2024-05-25 05:45:43 [INFO]: Epoch 052 - training loss: 0.4592, validation loss: 0.0394
2024-05-25 05:45:43 [INFO]: Epoch 053 - training loss: 0.4637, validation loss: 0.0333
2024-05-25 05:45:44 [INFO]: Epoch 054 - training loss: 0.4605, validation loss: 0.0453
2024-05-25 05:45:44 [INFO]: Epoch 055 - training loss: 0.4493, validation loss: 0.0424
2024-05-25 05:45:45 [INFO]: Epoch 056 - training loss: 0.4450, validation loss: 0.0392
2024-05-25 05:45:45 [INFO]: Epoch 057 - training loss: 0.4533, validation loss: 0.0375
2024-05-25 05:45:46 [INFO]: Epoch 058 - training loss: 0.4512, validation loss: 0.0402
2024-05-25 05:45:46 [INFO]: Epoch 059 - training loss: 0.4462, validation loss: 0.0577
2024-05-25 05:45:47 [INFO]: Epoch 060 - training loss: 0.4536, validation loss: 0.0429
2024-05-25 05:45:47 [INFO]: Epoch 061 - training loss: 0.4397, validation loss: 0.0336
2024-05-25 05:45:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:45:47 [INFO]: Finished training. The best model is from epoch#51.
2024-05-25 05:45:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_ettm1/20240525_T054517/SAITS.pypots
2024-05-25 05:45:47 [INFO]: SAITS on ETTm1: MAE=0.1442, MSE=0.0418
2024-05-25 05:45:47 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 05:45:47 [INFO]: Using the given device: cuda:0
2024-05-25 05:45:47 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T054547
2024-05-25 05:45:47 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T054547/tensorboard
2024-05-25 05:45:47 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 05:45:48 [INFO]: Epoch 001 - training loss: 1.1760, validation loss: 0.3260
2024-05-25 05:45:48 [INFO]: Epoch 002 - training loss: 0.6509, validation loss: 0.1489
2024-05-25 05:45:48 [INFO]: Epoch 003 - training loss: 0.5241, validation loss: 0.1028
2024-05-25 05:45:48 [INFO]: Epoch 004 - training loss: 0.4701, validation loss: 0.0827
2024-05-25 05:45:48 [INFO]: Epoch 005 - training loss: 0.4336, validation loss: 0.0729
2024-05-25 05:45:49 [INFO]: Epoch 006 - training loss: 0.4068, validation loss: 0.0675
2024-05-25 05:45:49 [INFO]: Epoch 007 - training loss: 0.3952, validation loss: 0.0608
2024-05-25 05:45:49 [INFO]: Epoch 008 - training loss: 0.3818, validation loss: 0.0623
2024-05-25 05:45:49 [INFO]: Epoch 009 - training loss: 0.3817, validation loss: 0.0548
2024-05-25 05:45:49 [INFO]: Epoch 010 - training loss: 0.3633, validation loss: 0.0568
2024-05-25 05:45:50 [INFO]: Epoch 011 - training loss: 0.3518, validation loss: 0.0517
2024-05-25 05:45:50 [INFO]: Epoch 012 - training loss: 0.3461, validation loss: 0.0489
2024-05-25 05:45:50 [INFO]: Epoch 013 - training loss: 0.3475, validation loss: 0.0475
2024-05-25 05:45:50 [INFO]: Epoch 014 - training loss: 0.3381, validation loss: 0.0488
2024-05-25 05:45:50 [INFO]: Epoch 015 - training loss: 0.3247, validation loss: 0.0426
2024-05-25 05:45:51 [INFO]: Epoch 016 - training loss: 0.3144, validation loss: 0.0416
2024-05-25 05:45:51 [INFO]: Epoch 017 - training loss: 0.3086, validation loss: 0.0407
2024-05-25 05:45:51 [INFO]: Epoch 018 - training loss: 0.3008, validation loss: 0.0391
2024-05-25 05:45:51 [INFO]: Epoch 019 - training loss: 0.3018, validation loss: 0.0419
2024-05-25 05:45:51 [INFO]: Epoch 020 - training loss: 0.2974, validation loss: 0.0443
2024-05-25 05:45:52 [INFO]: Epoch 021 - training loss: 0.3006, validation loss: 0.0443
2024-05-25 05:45:52 [INFO]: Epoch 022 - training loss: 0.2953, validation loss: 0.0377
2024-05-25 05:45:52 [INFO]: Epoch 023 - training loss: 0.2910, validation loss: 0.0433
2024-05-25 05:45:52 [INFO]: Epoch 024 - training loss: 0.2941, validation loss: 0.0395
2024-05-25 05:45:52 [INFO]: Epoch 025 - training loss: 0.2885, validation loss: 0.0362
2024-05-25 05:45:53 [INFO]: Epoch 026 - training loss: 0.2790, validation loss: 0.0348
2024-05-25 05:45:53 [INFO]: Epoch 027 - training loss: 0.2759, validation loss: 0.0339
2024-05-25 05:45:53 [INFO]: Epoch 028 - training loss: 0.2776, validation loss: 0.0359
2024-05-25 05:45:53 [INFO]: Epoch 029 - training loss: 0.2710, validation loss: 0.0364
2024-05-25 05:45:53 [INFO]: Epoch 030 - training loss: 0.2689, validation loss: 0.0356
2024-05-25 05:45:54 [INFO]: Epoch 031 - training loss: 0.2683, validation loss: 0.0341
2024-05-25 05:45:54 [INFO]: Epoch 032 - training loss: 0.2700, validation loss: 0.0360
2024-05-25 05:45:54 [INFO]: Epoch 033 - training loss: 0.2659, validation loss: 0.0344
2024-05-25 05:45:54 [INFO]: Epoch 034 - training loss: 0.2658, validation loss: 0.0317
2024-05-25 05:45:54 [INFO]: Epoch 035 - training loss: 0.2568, validation loss: 0.0305
2024-05-25 05:45:55 [INFO]: Epoch 036 - training loss: 0.2534, validation loss: 0.0329
2024-05-25 05:45:55 [INFO]: Epoch 037 - training loss: 0.2580, validation loss: 0.0298
2024-05-25 05:45:55 [INFO]: Epoch 038 - training loss: 0.2492, validation loss: 0.0401
2024-05-25 05:45:55 [INFO]: Epoch 039 - training loss: 0.2670, validation loss: 0.0327
2024-05-25 05:45:55 [INFO]: Epoch 040 - training loss: 0.2518, validation loss: 0.0301
2024-05-25 05:45:56 [INFO]: Epoch 041 - training loss: 0.2489, validation loss: 0.0311
2024-05-25 05:45:56 [INFO]: Epoch 042 - training loss: 0.2428, validation loss: 0.0319
2024-05-25 05:45:56 [INFO]: Epoch 043 - training loss: 0.2473, validation loss: 0.0304
2024-05-25 05:45:56 [INFO]: Epoch 044 - training loss: 0.2431, validation loss: 0.0274
2024-05-25 05:45:56 [INFO]: Epoch 045 - training loss: 0.2396, validation loss: 0.0284
2024-05-25 05:45:57 [INFO]: Epoch 046 - training loss: 0.2369, validation loss: 0.0297
2024-05-25 05:45:57 [INFO]: Epoch 047 - training loss: 0.2401, validation loss: 0.0290
2024-05-25 05:45:57 [INFO]: Epoch 048 - training loss: 0.2404, validation loss: 0.0331
2024-05-25 05:45:57 [INFO]: Epoch 049 - training loss: 0.2491, validation loss: 0.0305
2024-05-25 05:45:57 [INFO]: Epoch 050 - training loss: 0.2343, validation loss: 0.0273
2024-05-25 05:45:58 [INFO]: Epoch 051 - training loss: 0.2322, validation loss: 0.0260
2024-05-25 05:45:58 [INFO]: Epoch 052 - training loss: 0.2239, validation loss: 0.0261
2024-05-25 05:45:58 [INFO]: Epoch 053 - training loss: 0.2280, validation loss: 0.0273
2024-05-25 05:45:58 [INFO]: Epoch 054 - training loss: 0.2317, validation loss: 0.0272
2024-05-25 05:45:58 [INFO]: Epoch 055 - training loss: 0.2259, validation loss: 0.0259
2024-05-25 05:45:59 [INFO]: Epoch 056 - training loss: 0.2228, validation loss: 0.0274
2024-05-25 05:45:59 [INFO]: Epoch 057 - training loss: 0.2208, validation loss: 0.0288
2024-05-25 05:45:59 [INFO]: Epoch 058 - training loss: 0.2288, validation loss: 0.0281
2024-05-25 05:45:59 [INFO]: Epoch 059 - training loss: 0.2205, validation loss: 0.0293
2024-05-25 05:45:59 [INFO]: Epoch 060 - training loss: 0.2319, validation loss: 0.0333
2024-05-25 05:46:00 [INFO]: Epoch 061 - training loss: 0.2602, validation loss: 0.0285
2024-05-25 05:46:00 [INFO]: Epoch 062 - training loss: 0.2348, validation loss: 0.0260
2024-05-25 05:46:00 [INFO]: Epoch 063 - training loss: 0.2194, validation loss: 0.0247
2024-05-25 05:46:00 [INFO]: Epoch 064 - training loss: 0.2142, validation loss: 0.0249
2024-05-25 05:46:00 [INFO]: Epoch 065 - training loss: 0.2112, validation loss: 0.0242
2024-05-25 05:46:00 [INFO]: Epoch 066 - training loss: 0.2157, validation loss: 0.0263
2024-05-25 05:46:01 [INFO]: Epoch 067 - training loss: 0.2154, validation loss: 0.0252
2024-05-25 05:46:01 [INFO]: Epoch 068 - training loss: 0.2090, validation loss: 0.0253
2024-05-25 05:46:01 [INFO]: Epoch 069 - training loss: 0.2095, validation loss: 0.0283
2024-05-25 05:46:01 [INFO]: Epoch 070 - training loss: 0.2107, validation loss: 0.0258
2024-05-25 05:46:01 [INFO]: Epoch 071 - training loss: 0.2097, validation loss: 0.0250
2024-05-25 05:46:02 [INFO]: Epoch 072 - training loss: 0.2027, validation loss: 0.0250
2024-05-25 05:46:02 [INFO]: Epoch 073 - training loss: 0.2104, validation loss: 0.0261
2024-05-25 05:46:02 [INFO]: Epoch 074 - training loss: 0.2100, validation loss: 0.0304
2024-05-25 05:46:02 [INFO]: Epoch 075 - training loss: 0.2170, validation loss: 0.0259
2024-05-25 05:46:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:46:02 [INFO]: Finished training. The best model is from epoch#65.
2024-05-25 05:46:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_ettm1/20240525_T054547/Transformer.pypots
2024-05-25 05:46:02 [INFO]: Transformer on ETTm1: MAE=0.1364, MSE=0.0372
2024-05-25 05:46:02 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 05:46:02 [INFO]: Using the given device: cuda:0
2024-05-25 05:46:02 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T054602
2024-05-25 05:46:02 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T054602/tensorboard
2024-05-25 05:46:03 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 05:46:03 [INFO]: Epoch 001 - training loss: 0.1427, validation loss: 0.0553
2024-05-25 05:46:03 [INFO]: Epoch 002 - training loss: 0.0625, validation loss: 0.0422
2024-05-25 05:46:03 [INFO]: Epoch 003 - training loss: 0.0486, validation loss: 0.0328
2024-05-25 05:46:03 [INFO]: Epoch 004 - training loss: 0.0419, validation loss: 0.0319
2024-05-25 05:46:03 [INFO]: Epoch 005 - training loss: 0.0371, validation loss: 0.0271
2024-05-25 05:46:04 [INFO]: Epoch 006 - training loss: 0.0342, validation loss: 0.0274
2024-05-25 05:46:04 [INFO]: Epoch 007 - training loss: 0.0340, validation loss: 0.0258
2024-05-25 05:46:04 [INFO]: Epoch 008 - training loss: 0.0340, validation loss: 0.0262
2024-05-25 05:46:04 [INFO]: Epoch 009 - training loss: 0.0306, validation loss: 0.0248
2024-05-25 05:46:04 [INFO]: Epoch 010 - training loss: 0.0298, validation loss: 0.0254
2024-05-25 05:46:05 [INFO]: Epoch 011 - training loss: 0.0275, validation loss: 0.0247
2024-05-25 05:46:05 [INFO]: Epoch 012 - training loss: 0.0284, validation loss: 0.0243
2024-05-25 05:46:05 [INFO]: Epoch 013 - training loss: 0.0255, validation loss: 0.0226
2024-05-25 05:46:05 [INFO]: Epoch 014 - training loss: 0.0237, validation loss: 0.0229
2024-05-25 05:46:05 [INFO]: Epoch 015 - training loss: 0.0236, validation loss: 0.0225
2024-05-25 05:46:06 [INFO]: Epoch 016 - training loss: 0.0240, validation loss: 0.0224
2024-05-25 05:46:06 [INFO]: Epoch 017 - training loss: 0.0249, validation loss: 0.0224
2024-05-25 05:46:06 [INFO]: Epoch 018 - training loss: 0.0227, validation loss: 0.0218
2024-05-25 05:46:06 [INFO]: Epoch 019 - training loss: 0.0219, validation loss: 0.0213
2024-05-25 05:46:06 [INFO]: Epoch 020 - training loss: 0.0216, validation loss: 0.0228
2024-05-25 05:46:07 [INFO]: Epoch 021 - training loss: 0.0215, validation loss: 0.0221
2024-05-25 05:46:07 [INFO]: Epoch 022 - training loss: 0.0244, validation loss: 0.0233
2024-05-25 05:46:07 [INFO]: Epoch 023 - training loss: 0.0232, validation loss: 0.0238
2024-05-25 05:46:07 [INFO]: Epoch 024 - training loss: 0.0217, validation loss: 0.0220
2024-05-25 05:46:07 [INFO]: Epoch 025 - training loss: 0.0238, validation loss: 0.0241
2024-05-25 05:46:08 [INFO]: Epoch 026 - training loss: 0.0258, validation loss: 0.0227
2024-05-25 05:46:08 [INFO]: Epoch 027 - training loss: 0.0213, validation loss: 0.0225
2024-05-25 05:46:08 [INFO]: Epoch 028 - training loss: 0.0226, validation loss: 0.0239
2024-05-25 05:46:08 [INFO]: Epoch 029 - training loss: 0.0198, validation loss: 0.0221
2024-05-25 05:46:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:46:08 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 05:46:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240525_T054602/TimesNet.pypots
2024-05-25 05:46:08 [INFO]: TimesNet on ETTm1: MAE=0.1001, MSE=0.0223
2024-05-25 05:46:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 05:46:08 [INFO]: Using the given device: cuda:0
2024-05-25 05:46:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608
2024-05-25 05:46:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/tensorboard
2024-05-25 05:46:08 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 05:46:10 [INFO]: Epoch 001 - training loss: 0.6708, validation loss: 0.4517
2024-05-25 05:46:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch1_loss0.4517466574907303.pypots
2024-05-25 05:46:12 [INFO]: Epoch 002 - training loss: 0.3945, validation loss: 0.3831
2024-05-25 05:46:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch2_loss0.38306593149900436.pypots
2024-05-25 05:46:14 [INFO]: Epoch 003 - training loss: 0.3767, validation loss: 0.3528
2024-05-25 05:46:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch3_loss0.3527778461575508.pypots
2024-05-25 05:46:16 [INFO]: Epoch 004 - training loss: 0.3702, validation loss: 0.3188
2024-05-25 05:46:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch4_loss0.31879159808158875.pypots
2024-05-25 05:46:18 [INFO]: Epoch 005 - training loss: 0.3133, validation loss: 0.2932
2024-05-25 05:46:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch5_loss0.2931998148560524.pypots
2024-05-25 05:46:21 [INFO]: Epoch 006 - training loss: 0.2628, validation loss: 0.2811
2024-05-25 05:46:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch6_loss0.2811296135187149.pypots
2024-05-25 05:46:23 [INFO]: Epoch 007 - training loss: 0.3398, validation loss: 0.2748
2024-05-25 05:46:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch7_loss0.2748357132077217.pypots
2024-05-25 05:46:25 [INFO]: Epoch 008 - training loss: 0.2510, validation loss: 0.2623
2024-05-25 05:46:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch8_loss0.26233240962028503.pypots
2024-05-25 05:46:27 [INFO]: Epoch 009 - training loss: 0.2562, validation loss: 0.2614
2024-05-25 05:46:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch9_loss0.26137664914131165.pypots
2024-05-25 05:46:29 [INFO]: Epoch 010 - training loss: 0.2596, validation loss: 0.2547
2024-05-25 05:46:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch10_loss0.2546914182603359.pypots
2024-05-25 05:46:31 [INFO]: Epoch 011 - training loss: 0.2546, validation loss: 0.2827
2024-05-25 05:46:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch11_loss0.28268877416849136.pypots
2024-05-25 05:46:33 [INFO]: Epoch 012 - training loss: 0.2743, validation loss: 0.2558
2024-05-25 05:46:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch12_loss0.25578146055340767.pypots
2024-05-25 05:46:35 [INFO]: Epoch 013 - training loss: 0.2299, validation loss: 0.2399
2024-05-25 05:46:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch13_loss0.23994205519557.pypots
2024-05-25 05:46:37 [INFO]: Epoch 014 - training loss: 0.2302, validation loss: 0.2331
2024-05-25 05:46:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch14_loss0.23306206241250038.pypots
2024-05-25 05:46:39 [INFO]: Epoch 015 - training loss: 0.2196, validation loss: 0.2344
2024-05-25 05:46:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch15_loss0.23441386967897415.pypots
2024-05-25 05:46:41 [INFO]: Epoch 016 - training loss: 0.2392, validation loss: 0.2244
2024-05-25 05:46:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch16_loss0.22444500029087067.pypots
2024-05-25 05:46:43 [INFO]: Epoch 017 - training loss: 0.2238, validation loss: 0.2283
2024-05-25 05:46:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch17_loss0.22833791375160217.pypots
2024-05-25 05:46:45 [INFO]: Epoch 018 - training loss: 0.2195, validation loss: 0.2128
2024-05-25 05:46:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch18_loss0.21278079226613045.pypots
2024-05-25 05:46:47 [INFO]: Epoch 019 - training loss: 0.2791, validation loss: 0.2156
2024-05-25 05:46:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch19_loss0.2155729904770851.pypots
2024-05-25 05:46:49 [INFO]: Epoch 020 - training loss: 0.2164, validation loss: 0.2240
2024-05-25 05:46:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch20_loss0.22399085015058517.pypots
2024-05-25 05:46:51 [INFO]: Epoch 021 - training loss: 0.2260, validation loss: 0.2535
2024-05-25 05:46:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch21_loss0.2534935735166073.pypots
2024-05-25 05:46:53 [INFO]: Epoch 022 - training loss: 0.2320, validation loss: 0.2345
2024-05-25 05:46:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch22_loss0.23452425748109818.pypots
2024-05-25 05:46:55 [INFO]: Epoch 023 - training loss: 0.2036, validation loss: 0.2071
2024-05-25 05:46:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch23_loss0.20714674144983292.pypots
2024-05-25 05:46:58 [INFO]: Epoch 024 - training loss: 0.1889, validation loss: 0.1880
2024-05-25 05:46:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch24_loss0.18797394633293152.pypots
2024-05-25 05:47:00 [INFO]: Epoch 025 - training loss: 0.2182, validation loss: 0.1832
2024-05-25 05:47:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch25_loss0.1832238733768463.pypots
2024-05-25 05:47:02 [INFO]: Epoch 026 - training loss: 0.2169, validation loss: 0.1930
2024-05-25 05:47:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch26_loss0.19298942759633064.pypots
2024-05-25 05:47:04 [INFO]: Epoch 027 - training loss: 0.2027, validation loss: 0.1852
2024-05-25 05:47:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch27_loss0.18520081788301468.pypots
2024-05-25 05:47:06 [INFO]: Epoch 028 - training loss: 0.2023, validation loss: 0.1907
2024-05-25 05:47:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch28_loss0.19071799144148827.pypots
2024-05-25 05:47:08 [INFO]: Epoch 029 - training loss: 0.1766, validation loss: 0.1827
2024-05-25 05:47:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch29_loss0.18272635340690613.pypots
2024-05-25 05:47:10 [INFO]: Epoch 030 - training loss: 0.1624, validation loss: 0.1740
2024-05-25 05:47:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch30_loss0.17397316545248032.pypots
2024-05-25 05:47:12 [INFO]: Epoch 031 - training loss: 0.1898, validation loss: 0.1703
2024-05-25 05:47:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch31_loss0.17032039538025856.pypots
2024-05-25 05:47:14 [INFO]: Epoch 032 - training loss: 0.1706, validation loss: 0.1716
2024-05-25 05:47:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch32_loss0.17157724127173424.pypots
2024-05-25 05:47:16 [INFO]: Epoch 033 - training loss: 0.1704, validation loss: 0.1723
2024-05-25 05:47:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch33_loss0.17226262018084526.pypots
2024-05-25 05:47:18 [INFO]: Epoch 034 - training loss: 0.2170, validation loss: 0.1772
2024-05-25 05:47:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch34_loss0.17720800265669823.pypots
2024-05-25 05:47:20 [INFO]: Epoch 035 - training loss: 0.1989, validation loss: 0.1817
2024-05-25 05:47:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch35_loss0.18173916637897491.pypots
2024-05-25 05:47:22 [INFO]: Epoch 036 - training loss: 0.1862, validation loss: 0.1673
2024-05-25 05:47:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch36_loss0.16733771935105324.pypots
2024-05-25 05:47:24 [INFO]: Epoch 037 - training loss: 0.2080, validation loss: 0.1625
2024-05-25 05:47:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch37_loss0.16245494037866592.pypots
2024-05-25 05:47:26 [INFO]: Epoch 038 - training loss: 0.2117, validation loss: 0.1676
2024-05-25 05:47:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch38_loss0.16761983186006546.pypots
2024-05-25 05:47:28 [INFO]: Epoch 039 - training loss: 0.1682, validation loss: 0.1764
2024-05-25 05:47:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch39_loss0.1763981282711029.pypots
2024-05-25 05:47:30 [INFO]: Epoch 040 - training loss: 0.1779, validation loss: 0.1640
2024-05-25 05:47:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch40_loss0.1640344150364399.pypots
2024-05-25 05:47:32 [INFO]: Epoch 041 - training loss: 0.1662, validation loss: 0.1769
2024-05-25 05:47:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch41_loss0.17690692096948624.pypots
2024-05-25 05:47:34 [INFO]: Epoch 042 - training loss: 0.1700, validation loss: 0.1804
2024-05-25 05:47:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch42_loss0.1803792640566826.pypots
2024-05-25 05:47:37 [INFO]: Epoch 043 - training loss: 0.1785, validation loss: 0.1656
2024-05-25 05:47:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch43_loss0.1656218357384205.pypots
2024-05-25 05:47:39 [INFO]: Epoch 044 - training loss: 0.1597, validation loss: 0.1672
2024-05-25 05:47:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch44_loss0.16717494651675224.pypots
2024-05-25 05:47:41 [INFO]: Epoch 045 - training loss: 0.1889, validation loss: 0.1600
2024-05-25 05:47:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch45_loss0.1600121483206749.pypots
2024-05-25 05:47:43 [INFO]: Epoch 046 - training loss: 0.1680, validation loss: 0.1611
2024-05-25 05:47:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch46_loss0.1610758900642395.pypots
2024-05-25 05:47:45 [INFO]: Epoch 047 - training loss: 0.1757, validation loss: 0.1819
2024-05-25 05:47:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch47_loss0.18190943077206612.pypots
2024-05-25 05:47:47 [INFO]: Epoch 048 - training loss: 0.1876, validation loss: 0.1627
2024-05-25 05:47:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch48_loss0.16271311044692993.pypots
2024-05-25 05:47:49 [INFO]: Epoch 049 - training loss: 0.1673, validation loss: 0.1513
2024-05-25 05:47:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch49_loss0.1513015292584896.pypots
2024-05-25 05:47:51 [INFO]: Epoch 050 - training loss: 0.1492, validation loss: 0.1475
2024-05-25 05:47:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch50_loss0.14750272408127785.pypots
2024-05-25 05:47:53 [INFO]: Epoch 051 - training loss: 0.1842, validation loss: 0.1484
2024-05-25 05:47:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch51_loss0.14840740710496902.pypots
2024-05-25 05:47:55 [INFO]: Epoch 052 - training loss: 0.2197, validation loss: 0.1639
2024-05-25 05:47:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch52_loss0.16392351686954498.pypots
2024-05-25 05:47:57 [INFO]: Epoch 053 - training loss: 0.1904, validation loss: 0.1759
2024-05-25 05:47:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch53_loss0.17592502757906914.pypots
2024-05-25 05:47:59 [INFO]: Epoch 054 - training loss: 0.1484, validation loss: 0.1575
2024-05-25 05:47:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch54_loss0.15746789798140526.pypots
2024-05-25 05:48:01 [INFO]: Epoch 055 - training loss: 0.1630, validation loss: 0.1485
2024-05-25 05:48:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch55_loss0.14848027750849724.pypots
2024-05-25 05:48:03 [INFO]: Epoch 056 - training loss: 0.1352, validation loss: 0.1513
2024-05-25 05:48:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch56_loss0.15130333974957466.pypots
2024-05-25 05:48:05 [INFO]: Epoch 057 - training loss: 0.1418, validation loss: 0.1523
2024-05-25 05:48:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch57_loss0.15230068936944008.pypots
2024-05-25 05:48:07 [INFO]: Epoch 058 - training loss: 0.1566, validation loss: 0.1556
2024-05-25 05:48:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch58_loss0.15562735497951508.pypots
2024-05-25 05:48:09 [INFO]: Epoch 059 - training loss: 0.1770, validation loss: 0.1457
2024-05-25 05:48:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch59_loss0.1456988789141178.pypots
2024-05-25 05:48:11 [INFO]: Epoch 060 - training loss: 0.1344, validation loss: 0.1457
2024-05-25 05:48:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch60_loss0.14565325155854225.pypots
2024-05-25 05:48:14 [INFO]: Epoch 061 - training loss: 0.1424, validation loss: 0.1424
2024-05-25 05:48:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch61_loss0.14244519546627998.pypots
2024-05-25 05:48:16 [INFO]: Epoch 062 - training loss: 0.1682, validation loss: 0.1496
2024-05-25 05:48:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch62_loss0.149575874209404.pypots
2024-05-25 05:48:18 [INFO]: Epoch 063 - training loss: 0.1757, validation loss: 0.1601
2024-05-25 05:48:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch63_loss0.16014758497476578.pypots
2024-05-25 05:48:20 [INFO]: Epoch 064 - training loss: 0.1720, validation loss: 0.1649
2024-05-25 05:48:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch64_loss0.1649167835712433.pypots
2024-05-25 05:48:22 [INFO]: Epoch 065 - training loss: 0.1829, validation loss: 0.1642
2024-05-25 05:48:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch65_loss0.16416260600090027.pypots
2024-05-25 05:48:24 [INFO]: Epoch 066 - training loss: 0.1882, validation loss: 0.1531
2024-05-25 05:48:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch66_loss0.15310100838541985.pypots
2024-05-25 05:48:26 [INFO]: Epoch 067 - training loss: 0.1593, validation loss: 0.1532
2024-05-25 05:48:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch67_loss0.15319528058171272.pypots
2024-05-25 05:48:28 [INFO]: Epoch 068 - training loss: 0.1606, validation loss: 0.1459
2024-05-25 05:48:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch68_loss0.14587797969579697.pypots
2024-05-25 05:48:30 [INFO]: Epoch 069 - training loss: 0.1616, validation loss: 0.1406
2024-05-25 05:48:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch69_loss0.14055712893605232.pypots
2024-05-25 05:48:32 [INFO]: Epoch 070 - training loss: 0.1407, validation loss: 0.1377
2024-05-25 05:48:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch70_loss0.1377308927476406.pypots
2024-05-25 05:48:34 [INFO]: Epoch 071 - training loss: 0.1554, validation loss: 0.1384
2024-05-25 05:48:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch71_loss0.1383861042559147.pypots
2024-05-25 05:48:36 [INFO]: Epoch 072 - training loss: 0.1231, validation loss: 0.1406
2024-05-25 05:48:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch72_loss0.14055008441209793.pypots
2024-05-25 05:48:38 [INFO]: Epoch 073 - training loss: 0.1690, validation loss: 0.1395
2024-05-25 05:48:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch73_loss0.1395452581346035.pypots
2024-05-25 05:48:40 [INFO]: Epoch 074 - training loss: 0.1459, validation loss: 0.1482
2024-05-25 05:48:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch74_loss0.1481507308781147.pypots
2024-05-25 05:48:42 [INFO]: Epoch 075 - training loss: 0.1812, validation loss: 0.1480
2024-05-25 05:48:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch75_loss0.14795511960983276.pypots
2024-05-25 05:48:44 [INFO]: Epoch 076 - training loss: 0.1302, validation loss: 0.1509
2024-05-25 05:48:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch76_loss0.1509227454662323.pypots
2024-05-25 05:48:46 [INFO]: Epoch 077 - training loss: 0.1397, validation loss: 0.1417
2024-05-25 05:48:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch77_loss0.1416623741388321.pypots
2024-05-25 05:48:48 [INFO]: Epoch 078 - training loss: 0.1400, validation loss: 0.1351
2024-05-25 05:48:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch78_loss0.13510267436504364.pypots
2024-05-25 05:48:50 [INFO]: Epoch 079 - training loss: 0.1749, validation loss: 0.1363
2024-05-25 05:48:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch79_loss0.1362525299191475.pypots
2024-05-25 05:48:53 [INFO]: Epoch 080 - training loss: 0.1540, validation loss: 0.1482
2024-05-25 05:48:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch80_loss0.14823267236351967.pypots
2024-05-25 05:48:55 [INFO]: Epoch 081 - training loss: 0.1460, validation loss: 0.1428
2024-05-25 05:48:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch81_loss0.1427878886461258.pypots
2024-05-25 05:48:57 [INFO]: Epoch 082 - training loss: 0.2030, validation loss: 0.1476
2024-05-25 05:48:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch82_loss0.14759347215294838.pypots
2024-05-25 05:48:59 [INFO]: Epoch 083 - training loss: 0.1677, validation loss: 0.1558
2024-05-25 05:48:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch83_loss0.15577470511198044.pypots
2024-05-25 05:49:01 [INFO]: Epoch 084 - training loss: 0.1682, validation loss: 0.1468
2024-05-25 05:49:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch84_loss0.1467762365937233.pypots
2024-05-25 05:49:03 [INFO]: Epoch 085 - training loss: 0.1464, validation loss: 0.1417
2024-05-25 05:49:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch85_loss0.14165351539850235.pypots
2024-05-25 05:49:05 [INFO]: Epoch 086 - training loss: 0.1598, validation loss: 0.1455
2024-05-25 05:49:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch86_loss0.14551667124032974.pypots
2024-05-25 05:49:07 [INFO]: Epoch 087 - training loss: 0.1445, validation loss: 0.1401
2024-05-25 05:49:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch87_loss0.14005360007286072.pypots
2024-05-25 05:49:09 [INFO]: Epoch 088 - training loss: 0.1573, validation loss: 0.1381
2024-05-25 05:49:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI_epoch88_loss0.13813742995262146.pypots
2024-05-25 05:49:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:49:09 [INFO]: Finished training. The best model is from epoch#78.
2024-05-25 05:49:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240525_T054608/CSDI.pypots
2024-05-25 05:49:25 [INFO]: CSDI on ETTm1: MAE=0.1215, MSE=0.0336
2024-05-25 05:49:25 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 05:49:25 [INFO]: Using the given device: cuda:0
2024-05-25 05:49:25 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T054925
2024-05-25 05:49:25 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T054925/tensorboard
2024-05-25 05:49:25 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 05:49:25 [INFO]: Epoch 001 - training loss: 23766.6942, validation loss: 0.9687
2024-05-25 05:49:25 [INFO]: Epoch 002 - training loss: 21435.8907, validation loss: 0.9596
2024-05-25 05:49:25 [INFO]: Epoch 003 - training loss: 19424.8809, validation loss: 0.9431
2024-05-25 05:49:25 [INFO]: Epoch 004 - training loss: 17356.3691, validation loss: 0.9237
2024-05-25 05:49:26 [INFO]: Epoch 005 - training loss: 15539.9671, validation loss: 0.8732
2024-05-25 05:49:26 [INFO]: Epoch 006 - training loss: 14008.8906, validation loss: 0.7853
2024-05-25 05:49:26 [INFO]: Epoch 007 - training loss: 12756.7083, validation loss: 0.6923
2024-05-25 05:49:26 [INFO]: Epoch 008 - training loss: 11959.1945, validation loss: 0.6172
2024-05-25 05:49:26 [INFO]: Epoch 009 - training loss: 11441.5618, validation loss: 0.5430
2024-05-25 05:49:26 [INFO]: Epoch 010 - training loss: 11131.9548, validation loss: 0.4921
2024-05-25 05:49:26 [INFO]: Epoch 011 - training loss: 10706.8009, validation loss: 0.4739
2024-05-25 05:49:27 [INFO]: Epoch 012 - training loss: 10482.7239, validation loss: 0.4503
2024-05-25 05:49:27 [INFO]: Epoch 013 - training loss: 10286.5778, validation loss: 0.4245
2024-05-25 05:49:27 [INFO]: Epoch 014 - training loss: 10201.4971, validation loss: 0.3931
2024-05-25 05:49:27 [INFO]: Epoch 015 - training loss: 10057.7765, validation loss: 0.3633
2024-05-25 05:49:27 [INFO]: Epoch 016 - training loss: 9944.3287, validation loss: 0.3377
2024-05-25 05:49:27 [INFO]: Epoch 017 - training loss: 9938.9332, validation loss: 0.3200
2024-05-25 05:49:27 [INFO]: Epoch 018 - training loss: 9839.6775, validation loss: 0.3018
2024-05-25 05:49:28 [INFO]: Epoch 019 - training loss: 9774.1428, validation loss: 0.2953
2024-05-25 05:49:28 [INFO]: Epoch 020 - training loss: 9733.4497, validation loss: 0.2862
2024-05-25 05:49:28 [INFO]: Epoch 021 - training loss: 9697.2899, validation loss: 0.2717
2024-05-25 05:49:28 [INFO]: Epoch 022 - training loss: 9670.6496, validation loss: 0.2638
2024-05-25 05:49:28 [INFO]: Epoch 023 - training loss: 9645.0236, validation loss: 0.2544
2024-05-25 05:49:28 [INFO]: Epoch 024 - training loss: 9602.0518, validation loss: 0.2442
2024-05-25 05:49:28 [INFO]: Epoch 025 - training loss: 9567.2487, validation loss: 0.2352
2024-05-25 05:49:29 [INFO]: Epoch 026 - training loss: 9545.9828, validation loss: 0.2306
2024-05-25 05:49:29 [INFO]: Epoch 027 - training loss: 9534.1771, validation loss: 0.2263
2024-05-25 05:49:29 [INFO]: Epoch 028 - training loss: 9519.1034, validation loss: 0.2197
2024-05-25 05:49:29 [INFO]: Epoch 029 - training loss: 9502.9818, validation loss: 0.2144
2024-05-25 05:49:29 [INFO]: Epoch 030 - training loss: 9499.8359, validation loss: 0.2093
2024-05-25 05:49:29 [INFO]: Epoch 031 - training loss: 9519.0012, validation loss: 0.2047
2024-05-25 05:49:29 [INFO]: Epoch 032 - training loss: 9473.3453, validation loss: 0.2015
2024-05-25 05:49:30 [INFO]: Epoch 033 - training loss: 9459.7620, validation loss: 0.1953
2024-05-25 05:49:30 [INFO]: Epoch 034 - training loss: 9454.1135, validation loss: 0.1943
2024-05-25 05:49:30 [INFO]: Epoch 035 - training loss: 9442.2778, validation loss: 0.1895
2024-05-25 05:49:30 [INFO]: Epoch 036 - training loss: 9440.7863, validation loss: 0.1819
2024-05-25 05:49:30 [INFO]: Epoch 037 - training loss: 9432.9427, validation loss: 0.1777
2024-05-25 05:49:30 [INFO]: Epoch 038 - training loss: 9431.8516, validation loss: 0.1744
2024-05-25 05:49:30 [INFO]: Epoch 039 - training loss: 9427.0717, validation loss: 0.1699
2024-05-25 05:49:31 [INFO]: Epoch 040 - training loss: 9434.0281, validation loss: 0.1664
2024-05-25 05:49:31 [INFO]: Epoch 041 - training loss: 9404.8509, validation loss: 0.1648
2024-05-25 05:49:31 [INFO]: Epoch 042 - training loss: 9400.5758, validation loss: 0.1622
2024-05-25 05:49:31 [INFO]: Epoch 043 - training loss: 9406.1226, validation loss: 0.1579
2024-05-25 05:49:31 [INFO]: Epoch 044 - training loss: 9392.3525, validation loss: 0.1522
2024-05-25 05:49:31 [INFO]: Epoch 045 - training loss: 9393.6403, validation loss: 0.1514
2024-05-25 05:49:31 [INFO]: Epoch 046 - training loss: 9389.2524, validation loss: 0.1510
2024-05-25 05:49:32 [INFO]: Epoch 047 - training loss: 9385.6926, validation loss: 0.1457
2024-05-25 05:49:32 [INFO]: Epoch 048 - training loss: 9385.1447, validation loss: 0.1460
2024-05-25 05:49:32 [INFO]: Epoch 049 - training loss: 9380.7584, validation loss: 0.1430
2024-05-25 05:49:32 [INFO]: Epoch 050 - training loss: 9374.1317, validation loss: 0.1425
2024-05-25 05:49:32 [INFO]: Epoch 051 - training loss: 9377.6128, validation loss: 0.1402
2024-05-25 05:49:32 [INFO]: Epoch 052 - training loss: 9369.4802, validation loss: 0.1373
2024-05-25 05:49:33 [INFO]: Epoch 053 - training loss: 9371.9905, validation loss: 0.1365
2024-05-25 05:49:33 [INFO]: Epoch 054 - training loss: 9366.0865, validation loss: 0.1343
2024-05-25 05:49:33 [INFO]: Epoch 055 - training loss: 9361.4105, validation loss: 0.1353
2024-05-25 05:49:33 [INFO]: Epoch 056 - training loss: 9359.7662, validation loss: 0.1340
2024-05-25 05:49:33 [INFO]: Epoch 057 - training loss: 9358.9286, validation loss: 0.1317
2024-05-25 05:49:33 [INFO]: Epoch 058 - training loss: 9360.3436, validation loss: 0.1293
2024-05-25 05:49:33 [INFO]: Epoch 059 - training loss: 9356.4581, validation loss: 0.1283
2024-05-25 05:49:34 [INFO]: Epoch 060 - training loss: 9356.1141, validation loss: 0.1270
2024-05-25 05:49:34 [INFO]: Epoch 061 - training loss: 9351.2447, validation loss: 0.1266
2024-05-25 05:49:34 [INFO]: Epoch 062 - training loss: 9352.9194, validation loss: 0.1238
2024-05-25 05:49:34 [INFO]: Epoch 063 - training loss: 9348.3213, validation loss: 0.1239
2024-05-25 05:49:34 [INFO]: Epoch 064 - training loss: 9346.5472, validation loss: 0.1250
2024-05-25 05:49:34 [INFO]: Epoch 065 - training loss: 9351.5108, validation loss: 0.1238
2024-05-25 05:49:34 [INFO]: Epoch 066 - training loss: 9347.1304, validation loss: 0.1202
2024-05-25 05:49:35 [INFO]: Epoch 067 - training loss: 9347.4980, validation loss: 0.1210
2024-05-25 05:49:35 [INFO]: Epoch 068 - training loss: 9344.2062, validation loss: 0.1175
2024-05-25 05:49:35 [INFO]: Epoch 069 - training loss: 9344.0215, validation loss: 0.1179
2024-05-25 05:49:35 [INFO]: Epoch 070 - training loss: 9342.8290, validation loss: 0.1160
2024-05-25 05:49:35 [INFO]: Epoch 071 - training loss: 9340.6131, validation loss: 0.1170
2024-05-25 05:49:35 [INFO]: Epoch 072 - training loss: 9339.9847, validation loss: 0.1135
2024-05-25 05:49:35 [INFO]: Epoch 073 - training loss: 9338.9367, validation loss: 0.1142
2024-05-25 05:49:36 [INFO]: Epoch 074 - training loss: 9337.6056, validation loss: 0.1124
2024-05-25 05:49:36 [INFO]: Epoch 075 - training loss: 9336.6838, validation loss: 0.1124
2024-05-25 05:49:36 [INFO]: Epoch 076 - training loss: 9337.3195, validation loss: 0.1109
2024-05-25 05:49:36 [INFO]: Epoch 077 - training loss: 9339.2310, validation loss: 0.1105
2024-05-25 05:49:36 [INFO]: Epoch 078 - training loss: 9335.4548, validation loss: 0.1105
2024-05-25 05:49:36 [INFO]: Epoch 079 - training loss: 9333.4362, validation loss: 0.1094
2024-05-25 05:49:36 [INFO]: Epoch 080 - training loss: 9333.8121, validation loss: 0.1071
2024-05-25 05:49:37 [INFO]: Epoch 081 - training loss: 9333.2639, validation loss: 0.1077
2024-05-25 05:49:37 [INFO]: Epoch 082 - training loss: 9331.4858, validation loss: 0.1083
2024-05-25 05:49:37 [INFO]: Epoch 083 - training loss: 9329.7787, validation loss: 0.1071
2024-05-25 05:49:37 [INFO]: Epoch 084 - training loss: 9330.1689, validation loss: 0.1061
2024-05-25 05:49:37 [INFO]: Epoch 085 - training loss: 9333.0126, validation loss: 0.1064
2024-05-25 05:49:37 [INFO]: Epoch 086 - training loss: 9328.9691, validation loss: 0.1062
2024-05-25 05:49:37 [INFO]: Epoch 087 - training loss: 9331.9473, validation loss: 0.1048
2024-05-25 05:49:38 [INFO]: Epoch 088 - training loss: 9328.4819, validation loss: 0.1053
2024-05-25 05:49:38 [INFO]: Epoch 089 - training loss: 9325.5956, validation loss: 0.1053
2024-05-25 05:49:38 [INFO]: Epoch 090 - training loss: 9328.6941, validation loss: 0.1048
2024-05-25 05:49:38 [INFO]: Epoch 091 - training loss: 9325.5220, validation loss: 0.1037
2024-05-25 05:49:38 [INFO]: Epoch 092 - training loss: 9326.6794, validation loss: 0.1024
2024-05-25 05:49:38 [INFO]: Epoch 093 - training loss: 9328.7890, validation loss: 0.1009
2024-05-25 05:49:38 [INFO]: Epoch 094 - training loss: 9325.2327, validation loss: 0.1026
2024-05-25 05:49:39 [INFO]: Epoch 095 - training loss: 9323.4595, validation loss: 0.0986
2024-05-25 05:49:39 [INFO]: Epoch 096 - training loss: 9323.3467, validation loss: 0.1006
2024-05-25 05:49:39 [INFO]: Epoch 097 - training loss: 9324.1512, validation loss: 0.0993
2024-05-25 05:49:39 [INFO]: Epoch 098 - training loss: 9322.3468, validation loss: 0.0993
2024-05-25 05:49:39 [INFO]: Epoch 099 - training loss: 9322.3346, validation loss: 0.0981
2024-05-25 05:49:39 [INFO]: Epoch 100 - training loss: 9320.0920, validation loss: 0.0983
2024-05-25 05:49:39 [INFO]: Epoch 101 - training loss: 9320.9113, validation loss: 0.0985
2024-05-25 05:49:40 [INFO]: Epoch 102 - training loss: 9321.9263, validation loss: 0.0985
2024-05-25 05:49:40 [INFO]: Epoch 103 - training loss: 9320.3660, validation loss: 0.0970
2024-05-25 05:49:40 [INFO]: Epoch 104 - training loss: 9318.2894, validation loss: 0.0965
2024-05-25 05:49:40 [INFO]: Epoch 105 - training loss: 9319.0407, validation loss: 0.0964
2024-05-25 05:49:40 [INFO]: Epoch 106 - training loss: 9321.5115, validation loss: 0.0941
2024-05-25 05:49:40 [INFO]: Epoch 107 - training loss: 9319.1992, validation loss: 0.0953
2024-05-25 05:49:40 [INFO]: Epoch 108 - training loss: 9319.9328, validation loss: 0.0937
2024-05-25 05:49:41 [INFO]: Epoch 109 - training loss: 9320.1196, validation loss: 0.0942
2024-05-25 05:49:41 [INFO]: Epoch 110 - training loss: 9316.9801, validation loss: 0.0955
2024-05-25 05:49:41 [INFO]: Epoch 111 - training loss: 9319.2457, validation loss: 0.0901
2024-05-25 05:49:41 [INFO]: Epoch 112 - training loss: 9320.0434, validation loss: 0.0924
2024-05-25 05:49:41 [INFO]: Epoch 113 - training loss: 9316.9954, validation loss: 0.0925
2024-05-25 05:49:41 [INFO]: Epoch 114 - training loss: 9314.8728, validation loss: 0.0912
2024-05-25 05:49:41 [INFO]: Epoch 115 - training loss: 9317.3510, validation loss: 0.0920
2024-05-25 05:49:42 [INFO]: Epoch 116 - training loss: 9316.8951, validation loss: 0.0899
2024-05-25 05:49:42 [INFO]: Epoch 117 - training loss: 9316.7974, validation loss: 0.0905
2024-05-25 05:49:42 [INFO]: Epoch 118 - training loss: 9315.4022, validation loss: 0.0898
2024-05-25 05:49:42 [INFO]: Epoch 119 - training loss: 9314.7914, validation loss: 0.0892
2024-05-25 05:49:42 [INFO]: Epoch 120 - training loss: 9314.7050, validation loss: 0.0886
2024-05-25 05:49:42 [INFO]: Epoch 121 - training loss: 9315.8770, validation loss: 0.0883
2024-05-25 05:49:42 [INFO]: Epoch 122 - training loss: 9314.8633, validation loss: 0.0888
2024-05-25 05:49:43 [INFO]: Epoch 123 - training loss: 9315.1758, validation loss: 0.0872
2024-05-25 05:49:43 [INFO]: Epoch 124 - training loss: 9312.8669, validation loss: 0.0887
2024-05-25 05:49:43 [INFO]: Epoch 125 - training loss: 9313.2891, validation loss: 0.0878
2024-05-25 05:49:43 [INFO]: Epoch 126 - training loss: 9313.9440, validation loss: 0.0871
2024-05-25 05:49:43 [INFO]: Epoch 127 - training loss: 9313.4428, validation loss: 0.0860
2024-05-25 05:49:43 [INFO]: Epoch 128 - training loss: 9314.2485, validation loss: 0.0860
2024-05-25 05:49:43 [INFO]: Epoch 129 - training loss: 9312.8792, validation loss: 0.0865
2024-05-25 05:49:44 [INFO]: Epoch 130 - training loss: 9315.2709, validation loss: 0.0863
2024-05-25 05:49:44 [INFO]: Epoch 131 - training loss: 9314.1997, validation loss: 0.0834
2024-05-25 05:49:44 [INFO]: Epoch 132 - training loss: 9311.2625, validation loss: 0.0857
2024-05-25 05:49:44 [INFO]: Epoch 133 - training loss: 9312.0759, validation loss: 0.0839
2024-05-25 05:49:44 [INFO]: Epoch 134 - training loss: 9312.1211, validation loss: 0.0850
2024-05-25 05:49:45 [INFO]: Epoch 135 - training loss: 9312.2769, validation loss: 0.0829
2024-05-25 05:49:45 [INFO]: Epoch 136 - training loss: 9312.2846, validation loss: 0.0830
2024-05-25 05:49:45 [INFO]: Epoch 137 - training loss: 9312.9951, validation loss: 0.0836
2024-05-25 05:49:45 [INFO]: Epoch 138 - training loss: 9310.9373, validation loss: 0.0856
2024-05-25 05:49:45 [INFO]: Epoch 139 - training loss: 9311.5248, validation loss: 0.0854
2024-05-25 05:49:45 [INFO]: Epoch 140 - training loss: 9309.7314, validation loss: 0.0819
2024-05-25 05:49:45 [INFO]: Epoch 141 - training loss: 9309.9106, validation loss: 0.0822
2024-05-25 05:49:46 [INFO]: Epoch 142 - training loss: 9311.8389, validation loss: 0.0807
2024-05-25 05:49:46 [INFO]: Epoch 143 - training loss: 9310.6688, validation loss: 0.0816
2024-05-25 05:49:46 [INFO]: Epoch 144 - training loss: 9309.1946, validation loss: 0.0819
2024-05-25 05:49:46 [INFO]: Epoch 145 - training loss: 9310.2834, validation loss: 0.0809
2024-05-25 05:49:46 [INFO]: Epoch 146 - training loss: 9310.3614, validation loss: 0.0821
2024-05-25 05:49:46 [INFO]: Epoch 147 - training loss: 9311.8696, validation loss: 0.0808
2024-05-25 05:49:46 [INFO]: Epoch 148 - training loss: 9310.0062, validation loss: 0.0807
2024-05-25 05:49:47 [INFO]: Epoch 149 - training loss: 9309.8886, validation loss: 0.0815
2024-05-25 05:49:47 [INFO]: Epoch 150 - training loss: 9310.6827, validation loss: 0.0811
2024-05-25 05:49:47 [INFO]: Epoch 151 - training loss: 9309.2990, validation loss: 0.0806
2024-05-25 05:49:47 [INFO]: Epoch 152 - training loss: 9309.9710, validation loss: 0.0793
2024-05-25 05:49:47 [INFO]: Epoch 153 - training loss: 9308.2139, validation loss: 0.0800
2024-05-25 05:49:47 [INFO]: Epoch 154 - training loss: 9308.9215, validation loss: 0.0803
2024-05-25 05:49:47 [INFO]: Epoch 155 - training loss: 9308.4794, validation loss: 0.0809
2024-05-25 05:49:48 [INFO]: Epoch 156 - training loss: 9309.2944, validation loss: 0.0786
2024-05-25 05:49:48 [INFO]: Epoch 157 - training loss: 9308.9684, validation loss: 0.0779
2024-05-25 05:49:48 [INFO]: Epoch 158 - training loss: 9306.8629, validation loss: 0.0794
2024-05-25 05:49:48 [INFO]: Epoch 159 - training loss: 9308.4552, validation loss: 0.0786
2024-05-25 05:49:48 [INFO]: Epoch 160 - training loss: 9309.4180, validation loss: 0.0792
2024-05-25 05:49:48 [INFO]: Epoch 161 - training loss: 9307.4912, validation loss: 0.0793
2024-05-25 05:49:48 [INFO]: Epoch 162 - training loss: 9309.8204, validation loss: 0.0788
2024-05-25 05:49:49 [INFO]: Epoch 163 - training loss: 9310.1342, validation loss: 0.0776
2024-05-25 05:49:49 [INFO]: Epoch 164 - training loss: 9309.4196, validation loss: 0.0813
2024-05-25 05:49:49 [INFO]: Epoch 165 - training loss: 9307.5017, validation loss: 0.0784
2024-05-25 05:49:49 [INFO]: Epoch 166 - training loss: 9307.0963, validation loss: 0.0783
2024-05-25 05:49:49 [INFO]: Epoch 167 - training loss: 9306.2301, validation loss: 0.0778
2024-05-25 05:49:49 [INFO]: Epoch 168 - training loss: 9307.4891, validation loss: 0.0766
2024-05-25 05:49:49 [INFO]: Epoch 169 - training loss: 9308.4207, validation loss: 0.0770
2024-05-25 05:49:49 [INFO]: Epoch 170 - training loss: 9306.4412, validation loss: 0.0768
2024-05-25 05:49:50 [INFO]: Epoch 171 - training loss: 9306.6326, validation loss: 0.0773
2024-05-25 05:49:50 [INFO]: Epoch 172 - training loss: 9306.1213, validation loss: 0.0770
2024-05-25 05:49:50 [INFO]: Epoch 173 - training loss: 9306.4083, validation loss: 0.0783
2024-05-25 05:49:50 [INFO]: Epoch 174 - training loss: 9306.3105, validation loss: 0.0764
2024-05-25 05:49:50 [INFO]: Epoch 175 - training loss: 9306.2001, validation loss: 0.0763
2024-05-25 05:49:50 [INFO]: Epoch 176 - training loss: 9305.8485, validation loss: 0.0772
2024-05-25 05:49:50 [INFO]: Epoch 177 - training loss: 9306.5024, validation loss: 0.0776
2024-05-25 05:49:51 [INFO]: Epoch 178 - training loss: 9305.9373, validation loss: 0.0773
2024-05-25 05:49:51 [INFO]: Epoch 179 - training loss: 9304.7615, validation loss: 0.0752
2024-05-25 05:49:51 [INFO]: Epoch 180 - training loss: 9305.0115, validation loss: 0.0759
2024-05-25 05:49:51 [INFO]: Epoch 181 - training loss: 9304.7509, validation loss: 0.0755
2024-05-25 05:49:51 [INFO]: Epoch 182 - training loss: 9304.7939, validation loss: 0.0751
2024-05-25 05:49:51 [INFO]: Epoch 183 - training loss: 9304.2126, validation loss: 0.0748
2024-05-25 05:49:51 [INFO]: Epoch 184 - training loss: 9305.0994, validation loss: 0.0738
2024-05-25 05:49:52 [INFO]: Epoch 185 - training loss: 9304.6118, validation loss: 0.0747
2024-05-25 05:49:52 [INFO]: Epoch 186 - training loss: 9305.1746, validation loss: 0.0738
2024-05-25 05:49:52 [INFO]: Epoch 187 - training loss: 9305.9506, validation loss: 0.0757
2024-05-25 05:49:52 [INFO]: Epoch 188 - training loss: 9304.4627, validation loss: 0.0742
2024-05-25 05:49:52 [INFO]: Epoch 189 - training loss: 9305.4924, validation loss: 0.0752
2024-05-25 05:49:52 [INFO]: Epoch 190 - training loss: 9304.6623, validation loss: 0.0754
2024-05-25 05:49:52 [INFO]: Epoch 191 - training loss: 9304.8011, validation loss: 0.0736
2024-05-25 05:49:53 [INFO]: Epoch 192 - training loss: 9304.3241, validation loss: 0.0729
2024-05-25 05:49:53 [INFO]: Epoch 193 - training loss: 9304.8110, validation loss: 0.0732
2024-05-25 05:49:53 [INFO]: Epoch 194 - training loss: 9304.0887, validation loss: 0.0731
2024-05-25 05:49:53 [INFO]: Epoch 195 - training loss: 9305.0701, validation loss: 0.0725
2024-05-25 05:49:53 [INFO]: Epoch 196 - training loss: 9304.0785, validation loss: 0.0739
2024-05-25 05:49:53 [INFO]: Epoch 197 - training loss: 9305.0463, validation loss: 0.0714
2024-05-25 05:49:53 [INFO]: Epoch 198 - training loss: 9304.1492, validation loss: 0.0723
2024-05-25 05:49:54 [INFO]: Epoch 199 - training loss: 9304.7574, validation loss: 0.0724
2024-05-25 05:49:54 [INFO]: Epoch 200 - training loss: 9304.7499, validation loss: 0.0726
2024-05-25 05:49:54 [INFO]: Epoch 201 - training loss: 9303.2174, validation loss: 0.0730
2024-05-25 05:49:54 [INFO]: Epoch 202 - training loss: 9303.9317, validation loss: 0.0721
2024-05-25 05:49:54 [INFO]: Epoch 203 - training loss: 9303.2061, validation loss: 0.0736
2024-05-25 05:49:54 [INFO]: Epoch 204 - training loss: 9304.0132, validation loss: 0.0729
2024-05-25 05:49:54 [INFO]: Epoch 205 - training loss: 9303.0280, validation loss: 0.0729
2024-05-25 05:49:55 [INFO]: Epoch 206 - training loss: 9303.8358, validation loss: 0.0724
2024-05-25 05:49:55 [INFO]: Epoch 207 - training loss: 9303.7682, validation loss: 0.0729
2024-05-25 05:49:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:49:55 [INFO]: Finished training. The best model is from epoch#197.
2024-05-25 05:49:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240525_T054925/GPVAE.pypots
2024-05-25 05:49:55 [INFO]: GP-VAE on ETTm1: MAE=0.2705, MSE=0.1602
2024-05-25 05:49:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 05:49:55 [INFO]: Using the given device: cuda:0
2024-05-25 05:49:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T054955
2024-05-25 05:49:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T054955/tensorboard
2024-05-25 05:49:55 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 05:50:06 [INFO]: Epoch 001 - generator training loss: 0.5879, discriminator training loss: 0.3211, validation loss: 0.2804
2024-05-25 05:50:15 [INFO]: Epoch 002 - generator training loss: 0.0393, discriminator training loss: 0.2102, validation loss: 0.0966
2024-05-25 05:50:25 [INFO]: Epoch 003 - generator training loss: -0.0561, discriminator training loss: 0.1977, validation loss: 0.0589
2024-05-25 05:50:34 [INFO]: Epoch 004 - generator training loss: -0.0793, discriminator training loss: 0.1962, validation loss: 0.0498
2024-05-25 05:50:43 [INFO]: Epoch 005 - generator training loss: -0.0818, discriminator training loss: 0.1896, validation loss: 0.0438
2024-05-25 05:50:53 [INFO]: Epoch 006 - generator training loss: -0.0831, discriminator training loss: 0.1849, validation loss: 0.0412
2024-05-25 05:51:02 [INFO]: Epoch 007 - generator training loss: -0.0686, discriminator training loss: 0.1721, validation loss: 0.0405
2024-05-25 05:51:12 [INFO]: Epoch 008 - generator training loss: -0.0593, discriminator training loss: 0.1617, validation loss: 0.0386
2024-05-25 05:51:21 [INFO]: Epoch 009 - generator training loss: -0.0471, discriminator training loss: 0.1432, validation loss: 0.0371
2024-05-25 05:51:31 [INFO]: Epoch 010 - generator training loss: -0.0335, discriminator training loss: 0.1279, validation loss: 0.0366
2024-05-25 05:51:40 [INFO]: Epoch 011 - generator training loss: -0.0231, discriminator training loss: 0.1134, validation loss: 0.0357
2024-05-25 05:51:49 [INFO]: Epoch 012 - generator training loss: -0.0198, discriminator training loss: 0.1031, validation loss: 0.0350
2024-05-25 05:51:59 [INFO]: Epoch 013 - generator training loss: -0.0117, discriminator training loss: 0.0940, validation loss: 0.0347
2024-05-25 05:52:08 [INFO]: Epoch 014 - generator training loss: -0.0089, discriminator training loss: 0.0885, validation loss: 0.0339
2024-05-25 05:52:17 [INFO]: Epoch 015 - generator training loss: -0.0099, discriminator training loss: 0.0835, validation loss: 0.0340
2024-05-25 05:52:27 [INFO]: Epoch 016 - generator training loss: -0.0079, discriminator training loss: 0.0813, validation loss: 0.0338
2024-05-25 05:52:36 [INFO]: Epoch 017 - generator training loss: -0.0099, discriminator training loss: 0.0809, validation loss: 0.0330
2024-05-25 05:52:46 [INFO]: Epoch 018 - generator training loss: -0.0083, discriminator training loss: 0.0801, validation loss: 0.0324
2024-05-25 05:52:55 [INFO]: Epoch 019 - generator training loss: -0.0077, discriminator training loss: 0.0764, validation loss: 0.0323
2024-05-25 05:53:04 [INFO]: Epoch 020 - generator training loss: -0.0083, discriminator training loss: 0.0762, validation loss: 0.0320
2024-05-25 05:53:14 [INFO]: Epoch 021 - generator training loss: -0.0082, discriminator training loss: 0.0749, validation loss: 0.0318
2024-05-25 05:53:23 [INFO]: Epoch 022 - generator training loss: -0.0099, discriminator training loss: 0.0759, validation loss: 0.0317
2024-05-25 05:53:33 [INFO]: Epoch 023 - generator training loss: -0.0076, discriminator training loss: 0.0749, validation loss: 0.0314
2024-05-25 05:53:42 [INFO]: Epoch 024 - generator training loss: -0.0088, discriminator training loss: 0.0742, validation loss: 0.0319
2024-05-25 05:53:51 [INFO]: Epoch 025 - generator training loss: -0.0115, discriminator training loss: 0.0731, validation loss: 0.0337
2024-05-25 05:54:01 [INFO]: Epoch 026 - generator training loss: -0.0076, discriminator training loss: 0.0751, validation loss: 0.0322
2024-05-25 05:54:10 [INFO]: Epoch 027 - generator training loss: -0.0136, discriminator training loss: 0.0751, validation loss: 0.0304
2024-05-25 05:54:20 [INFO]: Epoch 028 - generator training loss: -0.0102, discriminator training loss: 0.0725, validation loss: 0.0302
2024-05-25 05:54:29 [INFO]: Epoch 029 - generator training loss: -0.0082, discriminator training loss: 0.0745, validation loss: 0.0301
2024-05-25 05:54:39 [INFO]: Epoch 030 - generator training loss: -0.0114, discriminator training loss: 0.0729, validation loss: 0.0296
2024-05-25 05:54:48 [INFO]: Epoch 031 - generator training loss: -0.0123, discriminator training loss: 0.0734, validation loss: 0.0293
2024-05-25 05:54:57 [INFO]: Epoch 032 - generator training loss: -0.0105, discriminator training loss: 0.0720, validation loss: 0.0296
2024-05-25 05:55:07 [INFO]: Epoch 033 - generator training loss: -0.0120, discriminator training loss: 0.0723, validation loss: 0.0295
2024-05-25 05:55:16 [INFO]: Epoch 034 - generator training loss: -0.0143, discriminator training loss: 0.0708, validation loss: 0.0292
2024-05-25 05:55:25 [INFO]: Epoch 035 - generator training loss: -0.0119, discriminator training loss: 0.0728, validation loss: 0.0296
2024-05-25 05:55:35 [INFO]: Epoch 036 - generator training loss: -0.0130, discriminator training loss: 0.0735, validation loss: 0.0290
2024-05-25 05:55:44 [INFO]: Epoch 037 - generator training loss: -0.0087, discriminator training loss: 0.0713, validation loss: 0.0285
2024-05-25 05:55:54 [INFO]: Epoch 038 - generator training loss: -0.0109, discriminator training loss: 0.0691, validation loss: 0.0286
2024-05-25 05:56:03 [INFO]: Epoch 039 - generator training loss: -0.0137, discriminator training loss: 0.0702, validation loss: 0.0285
2024-05-25 05:56:12 [INFO]: Epoch 040 - generator training loss: -0.0132, discriminator training loss: 0.0710, validation loss: 0.0283
2024-05-25 05:56:22 [INFO]: Epoch 041 - generator training loss: -0.0128, discriminator training loss: 0.0701, validation loss: 0.0277
2024-05-25 05:56:31 [INFO]: Epoch 042 - generator training loss: -0.0126, discriminator training loss: 0.0697, validation loss: 0.0294
2024-05-25 05:56:41 [INFO]: Epoch 043 - generator training loss: -0.0111, discriminator training loss: 0.0700, validation loss: 0.0275
2024-05-25 05:56:50 [INFO]: Epoch 044 - generator training loss: -0.0138, discriminator training loss: 0.0707, validation loss: 0.0271
2024-05-25 05:56:59 [INFO]: Epoch 045 - generator training loss: -0.0160, discriminator training loss: 0.0723, validation loss: 0.0268
2024-05-25 05:57:09 [INFO]: Epoch 046 - generator training loss: -0.0144, discriminator training loss: 0.0710, validation loss: 0.0280
2024-05-25 05:57:18 [INFO]: Epoch 047 - generator training loss: -0.0163, discriminator training loss: 0.0688, validation loss: 0.0270
2024-05-25 05:57:27 [INFO]: Epoch 048 - generator training loss: -0.0179, discriminator training loss: 0.0726, validation loss: 0.0264
2024-05-25 05:57:37 [INFO]: Epoch 049 - generator training loss: -0.0148, discriminator training loss: 0.0681, validation loss: 0.0264
2024-05-25 05:57:46 [INFO]: Epoch 050 - generator training loss: -0.0202, discriminator training loss: 0.0696, validation loss: 0.0252
2024-05-25 05:57:56 [INFO]: Epoch 051 - generator training loss: -0.0180, discriminator training loss: 0.0716, validation loss: 0.0253
2024-05-25 05:58:05 [INFO]: Epoch 052 - generator training loss: -0.0164, discriminator training loss: 0.0704, validation loss: 0.0254
2024-05-25 05:58:15 [INFO]: Epoch 053 - generator training loss: -0.0199, discriminator training loss: 0.0698, validation loss: 0.0246
2024-05-25 05:58:24 [INFO]: Epoch 054 - generator training loss: -0.0170, discriminator training loss: 0.0704, validation loss: 0.0248
2024-05-25 05:58:33 [INFO]: Epoch 055 - generator training loss: -0.0193, discriminator training loss: 0.0684, validation loss: 0.0280
2024-05-25 05:58:43 [INFO]: Epoch 056 - generator training loss: -0.0196, discriminator training loss: 0.0675, validation loss: 0.0241
2024-05-25 05:58:52 [INFO]: Epoch 057 - generator training loss: -0.0199, discriminator training loss: 0.0675, validation loss: 0.0239
2024-05-25 05:59:01 [INFO]: Epoch 058 - generator training loss: -0.0215, discriminator training loss: 0.0690, validation loss: 0.0234
2024-05-25 05:59:11 [INFO]: Epoch 059 - generator training loss: -0.0209, discriminator training loss: 0.0702, validation loss: 0.0238
2024-05-25 05:59:20 [INFO]: Epoch 060 - generator training loss: -0.0195, discriminator training loss: 0.0682, validation loss: 0.0230
2024-05-25 05:59:29 [INFO]: Epoch 061 - generator training loss: -0.0207, discriminator training loss: 0.0682, validation loss: 0.0227
2024-05-25 05:59:39 [INFO]: Epoch 062 - generator training loss: -0.0205, discriminator training loss: 0.0697, validation loss: 0.0225
2024-05-25 05:59:48 [INFO]: Epoch 063 - generator training loss: -0.0189, discriminator training loss: 0.0681, validation loss: 0.0242
2024-05-25 05:59:58 [INFO]: Epoch 064 - generator training loss: -0.0191, discriminator training loss: 0.0684, validation loss: 0.0227
2024-05-25 06:00:07 [INFO]: Epoch 065 - generator training loss: -0.0209, discriminator training loss: 0.0675, validation loss: 0.0221
2024-05-25 06:00:17 [INFO]: Epoch 066 - generator training loss: -0.0209, discriminator training loss: 0.0687, validation loss: 0.0225
2024-05-25 06:00:26 [INFO]: Epoch 067 - generator training loss: -0.0174, discriminator training loss: 0.0677, validation loss: 0.0217
2024-05-25 06:00:35 [INFO]: Epoch 068 - generator training loss: -0.0220, discriminator training loss: 0.0694, validation loss: 0.0221
2024-05-25 06:00:45 [INFO]: Epoch 069 - generator training loss: -0.0208, discriminator training loss: 0.0677, validation loss: 0.0219
2024-05-25 06:00:54 [INFO]: Epoch 070 - generator training loss: -0.0213, discriminator training loss: 0.0668, validation loss: 0.0216
2024-05-25 06:01:04 [INFO]: Epoch 071 - generator training loss: -0.0215, discriminator training loss: 0.0701, validation loss: 0.0212
2024-05-25 06:01:13 [INFO]: Epoch 072 - generator training loss: -0.0220, discriminator training loss: 0.0685, validation loss: 0.0212
2024-05-25 06:01:23 [INFO]: Epoch 073 - generator training loss: -0.0214, discriminator training loss: 0.0686, validation loss: 0.0212
2024-05-25 06:01:32 [INFO]: Epoch 074 - generator training loss: -0.0202, discriminator training loss: 0.0677, validation loss: 0.0212
2024-05-25 06:01:41 [INFO]: Epoch 075 - generator training loss: -0.0219, discriminator training loss: 0.0696, validation loss: 0.0205
2024-05-25 06:01:51 [INFO]: Epoch 076 - generator training loss: -0.0192, discriminator training loss: 0.0673, validation loss: 0.0213
2024-05-25 06:02:00 [INFO]: Epoch 077 - generator training loss: -0.0203, discriminator training loss: 0.0660, validation loss: 0.0211
2024-05-25 06:02:09 [INFO]: Epoch 078 - generator training loss: -0.0208, discriminator training loss: 0.0666, validation loss: 0.0206
2024-05-25 06:02:19 [INFO]: Epoch 079 - generator training loss: -0.0208, discriminator training loss: 0.0667, validation loss: 0.0206
2024-05-25 06:02:28 [INFO]: Epoch 080 - generator training loss: -0.0223, discriminator training loss: 0.0663, validation loss: 0.0202
2024-05-25 06:02:38 [INFO]: Epoch 081 - generator training loss: -0.0225, discriminator training loss: 0.0692, validation loss: 0.0206
2024-05-25 06:02:47 [INFO]: Epoch 082 - generator training loss: -0.0224, discriminator training loss: 0.0683, validation loss: 0.0205
2024-05-25 06:02:56 [INFO]: Epoch 083 - generator training loss: -0.0229, discriminator training loss: 0.0661, validation loss: 0.0201
2024-05-25 06:03:06 [INFO]: Epoch 084 - generator training loss: -0.0234, discriminator training loss: 0.0659, validation loss: 0.0205
2024-05-25 06:03:15 [INFO]: Epoch 085 - generator training loss: -0.0244, discriminator training loss: 0.0661, validation loss: 0.0201
2024-05-25 06:03:25 [INFO]: Epoch 086 - generator training loss: -0.0237, discriminator training loss: 0.0672, validation loss: 0.0205
2024-05-25 06:03:34 [INFO]: Epoch 087 - generator training loss: -0.0226, discriminator training loss: 0.0682, validation loss: 0.0200
2024-05-25 06:03:43 [INFO]: Epoch 088 - generator training loss: -0.0223, discriminator training loss: 0.0660, validation loss: 0.0200
2024-05-25 06:03:53 [INFO]: Epoch 089 - generator training loss: -0.0230, discriminator training loss: 0.0666, validation loss: 0.0204
2024-05-25 06:04:02 [INFO]: Epoch 090 - generator training loss: -0.0237, discriminator training loss: 0.0652, validation loss: 0.0199
2024-05-25 06:04:12 [INFO]: Epoch 091 - generator training loss: -0.0241, discriminator training loss: 0.0663, validation loss: 0.0197
2024-05-25 06:04:21 [INFO]: Epoch 092 - generator training loss: -0.0220, discriminator training loss: 0.0686, validation loss: 0.0201
2024-05-25 06:04:31 [INFO]: Epoch 093 - generator training loss: -0.0247, discriminator training loss: 0.0656, validation loss: 0.0199
2024-05-25 06:04:40 [INFO]: Epoch 094 - generator training loss: -0.0232, discriminator training loss: 0.0674, validation loss: 0.0197
2024-05-25 06:04:49 [INFO]: Epoch 095 - generator training loss: -0.0247, discriminator training loss: 0.0653, validation loss: 0.0198
2024-05-25 06:04:59 [INFO]: Epoch 096 - generator training loss: -0.0240, discriminator training loss: 0.0655, validation loss: 0.0203
2024-05-25 06:05:08 [INFO]: Epoch 097 - generator training loss: -0.0251, discriminator training loss: 0.0693, validation loss: 0.0198
2024-05-25 06:05:17 [INFO]: Epoch 098 - generator training loss: -0.0253, discriminator training loss: 0.0668, validation loss: 0.0193
2024-05-25 06:05:27 [INFO]: Epoch 099 - generator training loss: -0.0246, discriminator training loss: 0.0682, validation loss: 0.0200
2024-05-25 06:05:36 [INFO]: Epoch 100 - generator training loss: -0.0262, discriminator training loss: 0.0674, validation loss: 0.0197
2024-05-25 06:05:45 [INFO]: Epoch 101 - generator training loss: -0.0240, discriminator training loss: 0.0672, validation loss: 0.0197
2024-05-25 06:05:55 [INFO]: Epoch 102 - generator training loss: -0.0246, discriminator training loss: 0.0657, validation loss: 0.0200
2024-05-25 06:06:04 [INFO]: Epoch 103 - generator training loss: -0.0236, discriminator training loss: 0.0650, validation loss: 0.0197
2024-05-25 06:06:13 [INFO]: Epoch 104 - generator training loss: -0.0242, discriminator training loss: 0.0659, validation loss: 0.0192
2024-05-25 06:06:23 [INFO]: Epoch 105 - generator training loss: -0.0277, discriminator training loss: 0.0668, validation loss: 0.0195
2024-05-25 06:06:32 [INFO]: Epoch 106 - generator training loss: -0.0237, discriminator training loss: 0.0645, validation loss: 0.0195
2024-05-25 06:06:42 [INFO]: Epoch 107 - generator training loss: -0.0248, discriminator training loss: 0.0663, validation loss: 0.0193
2024-05-25 06:06:51 [INFO]: Epoch 108 - generator training loss: -0.0250, discriminator training loss: 0.0664, validation loss: 0.0190
2024-05-25 06:07:00 [INFO]: Epoch 109 - generator training loss: -0.0248, discriminator training loss: 0.0652, validation loss: 0.0195
2024-05-25 06:07:10 [INFO]: Epoch 110 - generator training loss: -0.0245, discriminator training loss: 0.0661, validation loss: 0.0194
2024-05-25 06:07:19 [INFO]: Epoch 111 - generator training loss: -0.0258, discriminator training loss: 0.0664, validation loss: 0.0194
2024-05-25 06:07:29 [INFO]: Epoch 112 - generator training loss: -0.0247, discriminator training loss: 0.0668, validation loss: 0.0196
2024-05-25 06:07:38 [INFO]: Epoch 113 - generator training loss: -0.0241, discriminator training loss: 0.0651, validation loss: 0.0189
2024-05-25 06:07:48 [INFO]: Epoch 114 - generator training loss: -0.0274, discriminator training loss: 0.0659, validation loss: 0.0190
2024-05-25 06:07:57 [INFO]: Epoch 115 - generator training loss: -0.0236, discriminator training loss: 0.0658, validation loss: 0.0194
2024-05-25 06:08:07 [INFO]: Epoch 116 - generator training loss: -0.0257, discriminator training loss: 0.0654, validation loss: 0.0196
2024-05-25 06:08:16 [INFO]: Epoch 117 - generator training loss: -0.0245, discriminator training loss: 0.0665, validation loss: 0.0190
2024-05-25 06:08:25 [INFO]: Epoch 118 - generator training loss: -0.0254, discriminator training loss: 0.0677, validation loss: 0.0200
2024-05-25 06:08:35 [INFO]: Epoch 119 - generator training loss: -0.0236, discriminator training loss: 0.0646, validation loss: 0.0196
2024-05-25 06:08:44 [INFO]: Epoch 120 - generator training loss: -0.0257, discriminator training loss: 0.0647, validation loss: 0.0188
2024-05-25 06:08:53 [INFO]: Epoch 121 - generator training loss: -0.0253, discriminator training loss: 0.0647, validation loss: 0.0189
2024-05-25 06:09:03 [INFO]: Epoch 122 - generator training loss: -0.0248, discriminator training loss: 0.0666, validation loss: 0.0192
2024-05-25 06:09:12 [INFO]: Epoch 123 - generator training loss: -0.0256, discriminator training loss: 0.0660, validation loss: 0.0191
2024-05-25 06:09:21 [INFO]: Epoch 124 - generator training loss: -0.0263, discriminator training loss: 0.0660, validation loss: 0.0187
2024-05-25 06:09:31 [INFO]: Epoch 125 - generator training loss: -0.0248, discriminator training loss: 0.0645, validation loss: 0.0191
2024-05-25 06:09:40 [INFO]: Epoch 126 - generator training loss: -0.0258, discriminator training loss: 0.0635, validation loss: 0.0197
2024-05-25 06:09:50 [INFO]: Epoch 127 - generator training loss: -0.0264, discriminator training loss: 0.0649, validation loss: 0.0189
2024-05-25 06:09:59 [INFO]: Epoch 128 - generator training loss: -0.0255, discriminator training loss: 0.0642, validation loss: 0.0190
2024-05-25 06:10:08 [INFO]: Epoch 129 - generator training loss: -0.0275, discriminator training loss: 0.0654, validation loss: 0.0190
2024-05-25 06:10:18 [INFO]: Epoch 130 - generator training loss: -0.0273, discriminator training loss: 0.0668, validation loss: 0.0188
2024-05-25 06:10:27 [INFO]: Epoch 131 - generator training loss: -0.0265, discriminator training loss: 0.0646, validation loss: 0.0188
2024-05-25 06:10:37 [INFO]: Epoch 132 - generator training loss: -0.0253, discriminator training loss: 0.0662, validation loss: 0.0191
2024-05-25 06:10:46 [INFO]: Epoch 133 - generator training loss: -0.0272, discriminator training loss: 0.0647, validation loss: 0.0186
2024-05-25 06:10:55 [INFO]: Epoch 134 - generator training loss: -0.0296, discriminator training loss: 0.0668, validation loss: 0.0187
2024-05-25 06:11:05 [INFO]: Epoch 135 - generator training loss: -0.0273, discriminator training loss: 0.0674, validation loss: 0.0191
2024-05-25 06:11:14 [INFO]: Epoch 136 - generator training loss: -0.0271, discriminator training loss: 0.0668, validation loss: 0.0188
2024-05-25 06:11:24 [INFO]: Epoch 137 - generator training loss: -0.0264, discriminator training loss: 0.0664, validation loss: 0.0185
2024-05-25 06:11:33 [INFO]: Epoch 138 - generator training loss: -0.0269, discriminator training loss: 0.0668, validation loss: 0.0189
2024-05-25 06:11:43 [INFO]: Epoch 139 - generator training loss: -0.0264, discriminator training loss: 0.0663, validation loss: 0.0190
2024-05-25 06:11:52 [INFO]: Epoch 140 - generator training loss: -0.0271, discriminator training loss: 0.0643, validation loss: 0.0191
2024-05-25 06:12:01 [INFO]: Epoch 141 - generator training loss: -0.0253, discriminator training loss: 0.0649, validation loss: 0.0198
2024-05-25 06:12:10 [INFO]: Epoch 142 - generator training loss: -0.0255, discriminator training loss: 0.0643, validation loss: 0.0192
2024-05-25 06:12:20 [INFO]: Epoch 143 - generator training loss: -0.0290, discriminator training loss: 0.0652, validation loss: 0.0191
2024-05-25 06:12:29 [INFO]: Epoch 144 - generator training loss: -0.0261, discriminator training loss: 0.0645, validation loss: 0.0188
2024-05-25 06:12:39 [INFO]: Epoch 145 - generator training loss: -0.0272, discriminator training loss: 0.0628, validation loss: 0.0186
2024-05-25 06:12:48 [INFO]: Epoch 146 - generator training loss: -0.0292, discriminator training loss: 0.0649, validation loss: 0.0188
2024-05-25 06:12:57 [INFO]: Epoch 147 - generator training loss: -0.0268, discriminator training loss: 0.0648, validation loss: 0.0187
2024-05-25 06:12:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:12:57 [INFO]: Finished training. The best model is from epoch#137.
2024-05-25 06:12:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_ettm1/20240525_T054955/USGAN.pypots
2024-05-25 06:12:58 [INFO]: US-GAN on ETTm1: MAE=0.1408, MSE=0.0512
2024-05-25 06:12:58 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 06:12:58 [INFO]: Using the given device: cuda:0
2024-05-25 06:12:58 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T061258
2024-05-25 06:12:58 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T061258/tensorboard
2024-05-25 06:12:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 06:13:06 [INFO]: Epoch 001 - training loss: 1.3474, validation loss: 0.2949
2024-05-25 06:13:13 [INFO]: Epoch 002 - training loss: 0.9005, validation loss: 0.0894
2024-05-25 06:13:19 [INFO]: Epoch 003 - training loss: 0.7127, validation loss: 0.0544
2024-05-25 06:13:25 [INFO]: Epoch 004 - training loss: 0.6368, validation loss: 0.0440
2024-05-25 06:13:31 [INFO]: Epoch 005 - training loss: 0.5858, validation loss: 0.0387
2024-05-25 06:13:38 [INFO]: Epoch 006 - training loss: 0.5540, validation loss: 0.0392
2024-05-25 06:13:44 [INFO]: Epoch 007 - training loss: 0.5224, validation loss: 0.0346
2024-05-25 06:13:50 [INFO]: Epoch 008 - training loss: 0.5136, validation loss: 0.0331
2024-05-25 06:13:56 [INFO]: Epoch 009 - training loss: 0.4794, validation loss: 0.0311
2024-05-25 06:14:03 [INFO]: Epoch 010 - training loss: 0.4707, validation loss: 0.0305
2024-05-25 06:14:09 [INFO]: Epoch 011 - training loss: 0.4436, validation loss: 0.0299
2024-05-25 06:14:15 [INFO]: Epoch 012 - training loss: 0.4280, validation loss: 0.0283
2024-05-25 06:14:21 [INFO]: Epoch 013 - training loss: 0.4162, validation loss: 0.0275
2024-05-25 06:14:28 [INFO]: Epoch 014 - training loss: 0.4116, validation loss: 0.0258
2024-05-25 06:14:34 [INFO]: Epoch 015 - training loss: 0.4019, validation loss: 0.0254
2024-05-25 06:14:40 [INFO]: Epoch 016 - training loss: 0.3987, validation loss: 0.0246
2024-05-25 06:14:46 [INFO]: Epoch 017 - training loss: 0.3938, validation loss: 0.0239
2024-05-25 06:14:52 [INFO]: Epoch 018 - training loss: 0.3975, validation loss: 0.0232
2024-05-25 06:14:59 [INFO]: Epoch 019 - training loss: 0.3960, validation loss: 0.0240
2024-05-25 06:15:05 [INFO]: Epoch 020 - training loss: 0.3974, validation loss: 0.0234
2024-05-25 06:15:11 [INFO]: Epoch 021 - training loss: 0.3888, validation loss: 0.0235
2024-05-25 06:15:17 [INFO]: Epoch 022 - training loss: 0.3821, validation loss: 0.0226
2024-05-25 06:15:24 [INFO]: Epoch 023 - training loss: 0.3832, validation loss: 0.0227
2024-05-25 06:15:30 [INFO]: Epoch 024 - training loss: 0.3797, validation loss: 0.0230
2024-05-25 06:15:36 [INFO]: Epoch 025 - training loss: 0.3835, validation loss: 0.0226
2024-05-25 06:15:42 [INFO]: Epoch 026 - training loss: 0.3812, validation loss: 0.0227
2024-05-25 06:15:49 [INFO]: Epoch 027 - training loss: 0.3786, validation loss: 0.0227
2024-05-25 06:15:55 [INFO]: Epoch 028 - training loss: 0.3772, validation loss: 0.0230
2024-05-25 06:16:01 [INFO]: Epoch 029 - training loss: 0.3834, validation loss: 0.0223
2024-05-25 06:16:07 [INFO]: Epoch 030 - training loss: 0.3730, validation loss: 0.0231
2024-05-25 06:16:13 [INFO]: Epoch 031 - training loss: 0.3874, validation loss: 0.0225
2024-05-25 06:16:20 [INFO]: Epoch 032 - training loss: 0.3845, validation loss: 0.0235
2024-05-25 06:16:26 [INFO]: Epoch 033 - training loss: 0.3816, validation loss: 0.0233
2024-05-25 06:16:32 [INFO]: Epoch 034 - training loss: 0.4228, validation loss: 0.0234
2024-05-25 06:16:38 [INFO]: Epoch 035 - training loss: 0.3898, validation loss: 0.0235
2024-05-25 06:16:45 [INFO]: Epoch 036 - training loss: 0.3771, validation loss: 0.0228
2024-05-25 06:16:51 [INFO]: Epoch 037 - training loss: 0.3725, validation loss: 0.0229
2024-05-25 06:16:57 [INFO]: Epoch 038 - training loss: 0.3713, validation loss: 0.0225
2024-05-25 06:17:03 [INFO]: Epoch 039 - training loss: 0.3795, validation loss: 0.0226
2024-05-25 06:17:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:17:03 [INFO]: Finished training. The best model is from epoch#29.
2024-05-25 06:17:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_ettm1/20240525_T061258/BRITS.pypots
2024-05-25 06:17:04 [INFO]: BRITS on ETTm1: MAE=0.1231, MSE=0.0465
2024-05-25 06:17:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 06:17:04 [INFO]: Using the given device: cuda:0
2024-05-25 06:17:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704
2024-05-25 06:17:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/tensorboard
2024-05-25 06:17:04 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 06:17:06 [INFO]: Epoch 001 - training loss: 1.3911, validation loss: 1.2605
2024-05-25 06:17:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch1_loss1.2604736983776093.pypots
2024-05-25 06:17:07 [INFO]: Epoch 002 - training loss: 1.0569, validation loss: 1.1237
2024-05-25 06:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch2_loss1.1237109452486038.pypots
2024-05-25 06:17:07 [INFO]: Epoch 003 - training loss: 1.0120, validation loss: 1.0545
2024-05-25 06:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch3_loss1.0545163303613663.pypots
2024-05-25 06:17:07 [INFO]: Epoch 004 - training loss: 0.9775, validation loss: 1.0308
2024-05-25 06:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch4_loss1.0308227241039276.pypots
2024-05-25 06:17:07 [INFO]: Epoch 005 - training loss: 0.9600, validation loss: 1.0204
2024-05-25 06:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch5_loss1.020385518670082.pypots
2024-05-25 06:17:07 [INFO]: Epoch 006 - training loss: 0.9412, validation loss: 1.0072
2024-05-25 06:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch6_loss1.007202759385109.pypots
2024-05-25 06:17:08 [INFO]: Epoch 007 - training loss: 0.9421, validation loss: 0.9982
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch7_loss0.9981658011674881.pypots
2024-05-25 06:17:08 [INFO]: Epoch 008 - training loss: 0.9305, validation loss: 0.9953
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch8_loss0.995310440659523.pypots
2024-05-25 06:17:08 [INFO]: Epoch 009 - training loss: 0.9242, validation loss: 0.9942
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch9_loss0.9941919147968292.pypots
2024-05-25 06:17:08 [INFO]: Epoch 010 - training loss: 0.9137, validation loss: 0.9900
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch10_loss0.9899510741233826.pypots
2024-05-25 06:17:08 [INFO]: Epoch 011 - training loss: 0.9274, validation loss: 0.9862
2024-05-25 06:17:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch11_loss0.9861781746149063.pypots
2024-05-25 06:17:09 [INFO]: Epoch 012 - training loss: 0.8907, validation loss: 0.9838
2024-05-25 06:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch12_loss0.983833447098732.pypots
2024-05-25 06:17:09 [INFO]: Epoch 013 - training loss: 0.8866, validation loss: 0.9794
2024-05-25 06:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch13_loss0.979403480887413.pypots
2024-05-25 06:17:09 [INFO]: Epoch 014 - training loss: 0.9210, validation loss: 0.9782
2024-05-25 06:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch14_loss0.9782029688358307.pypots
2024-05-25 06:17:09 [INFO]: Epoch 015 - training loss: 0.8891, validation loss: 0.9723
2024-05-25 06:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch15_loss0.972281351685524.pypots
2024-05-25 06:17:09 [INFO]: Epoch 016 - training loss: 0.8531, validation loss: 0.9691
2024-05-25 06:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch16_loss0.9691311419010162.pypots
2024-05-25 06:17:10 [INFO]: Epoch 017 - training loss: 0.8704, validation loss: 0.9631
2024-05-25 06:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch17_loss0.9631143063306808.pypots
2024-05-25 06:17:10 [INFO]: Epoch 018 - training loss: 0.8538, validation loss: 0.9608
2024-05-25 06:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch18_loss0.9607720375061035.pypots
2024-05-25 06:17:10 [INFO]: Epoch 019 - training loss: 0.8551, validation loss: 0.9598
2024-05-25 06:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch19_loss0.9597964882850647.pypots
2024-05-25 06:17:10 [INFO]: Epoch 020 - training loss: 0.8528, validation loss: 0.9563
2024-05-25 06:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch20_loss0.9562875926494598.pypots
2024-05-25 06:17:10 [INFO]: Epoch 021 - training loss: 0.8557, validation loss: 0.9559
2024-05-25 06:17:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch21_loss0.9558935016393661.pypots
2024-05-25 06:17:11 [INFO]: Epoch 022 - training loss: 0.8574, validation loss: 0.9502
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch22_loss0.9502235651016235.pypots
2024-05-25 06:17:11 [INFO]: Epoch 023 - training loss: 0.8697, validation loss: 0.9477
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch23_loss0.9477089047431946.pypots
2024-05-25 06:17:11 [INFO]: Epoch 024 - training loss: 0.8246, validation loss: 0.9438
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch24_loss0.9437900185585022.pypots
2024-05-25 06:17:11 [INFO]: Epoch 025 - training loss: 0.8559, validation loss: 0.9427
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch25_loss0.9427119493484497.pypots
2024-05-25 06:17:11 [INFO]: Epoch 026 - training loss: 0.8469, validation loss: 0.9382
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch26_loss0.93824402987957.pypots
2024-05-25 06:17:11 [INFO]: Epoch 027 - training loss: 0.8685, validation loss: 0.9356
2024-05-25 06:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch27_loss0.9356110244989395.pypots
2024-05-25 06:17:12 [INFO]: Epoch 028 - training loss: 0.8170, validation loss: 0.9343
2024-05-25 06:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch28_loss0.9343492239713669.pypots
2024-05-25 06:17:12 [INFO]: Epoch 029 - training loss: 0.8180, validation loss: 0.9318
2024-05-25 06:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch29_loss0.9317710846662521.pypots
2024-05-25 06:17:12 [INFO]: Epoch 030 - training loss: 0.8497, validation loss: 0.9288
2024-05-25 06:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch30_loss0.9288441389799118.pypots
2024-05-25 06:17:12 [INFO]: Epoch 031 - training loss: 0.8321, validation loss: 0.9271
2024-05-25 06:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch31_loss0.9271017462015152.pypots
2024-05-25 06:17:12 [INFO]: Epoch 032 - training loss: 0.8356, validation loss: 0.9240
2024-05-25 06:17:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch32_loss0.9239586442708969.pypots
2024-05-25 06:17:13 [INFO]: Epoch 033 - training loss: 0.8177, validation loss: 0.9205
2024-05-25 06:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch33_loss0.9205425977706909.pypots
2024-05-25 06:17:13 [INFO]: Epoch 034 - training loss: 0.8308, validation loss: 0.9190
2024-05-25 06:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch34_loss0.9190299957990646.pypots
2024-05-25 06:17:13 [INFO]: Epoch 035 - training loss: 0.8267, validation loss: 0.9177
2024-05-25 06:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch35_loss0.9177407622337341.pypots
2024-05-25 06:17:13 [INFO]: Epoch 036 - training loss: 0.8568, validation loss: 0.9179
2024-05-25 06:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch36_loss0.9178654253482819.pypots
2024-05-25 06:17:13 [INFO]: Epoch 037 - training loss: 0.8513, validation loss: 0.9154
2024-05-25 06:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch37_loss0.915368378162384.pypots
2024-05-25 06:17:14 [INFO]: Epoch 038 - training loss: 0.8184, validation loss: 0.9128
2024-05-25 06:17:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch38_loss0.9128439724445343.pypots
2024-05-25 06:17:14 [INFO]: Epoch 039 - training loss: 0.8261, validation loss: 0.9116
2024-05-25 06:17:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch39_loss0.9115832597017288.pypots
2024-05-25 06:17:14 [INFO]: Epoch 040 - training loss: 0.8400, validation loss: 0.9092
2024-05-25 06:17:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch40_loss0.9092012792825699.pypots
2024-05-25 06:17:14 [INFO]: Epoch 041 - training loss: 0.8161, validation loss: 0.9066
2024-05-25 06:17:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch41_loss0.9066315144300461.pypots
2024-05-25 06:17:14 [INFO]: Epoch 042 - training loss: 0.8366, validation loss: 0.9043
2024-05-25 06:17:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch42_loss0.9042527973651886.pypots
2024-05-25 06:17:15 [INFO]: Epoch 043 - training loss: 0.8604, validation loss: 0.9038
2024-05-25 06:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch43_loss0.9037817865610123.pypots
2024-05-25 06:17:15 [INFO]: Epoch 044 - training loss: 0.8188, validation loss: 0.9012
2024-05-25 06:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch44_loss0.901193231344223.pypots
2024-05-25 06:17:15 [INFO]: Epoch 045 - training loss: 0.8100, validation loss: 0.9001
2024-05-25 06:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch45_loss0.9001016318798065.pypots
2024-05-25 06:17:15 [INFO]: Epoch 046 - training loss: 0.8063, validation loss: 0.8995
2024-05-25 06:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch46_loss0.8994884788990021.pypots
2024-05-25 06:17:15 [INFO]: Epoch 047 - training loss: 0.7897, validation loss: 0.8980
2024-05-25 06:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch47_loss0.8979723155498505.pypots
2024-05-25 06:17:16 [INFO]: Epoch 048 - training loss: 0.8147, validation loss: 0.8971
2024-05-25 06:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch48_loss0.8971259295940399.pypots
2024-05-25 06:17:16 [INFO]: Epoch 049 - training loss: 0.8084, validation loss: 0.8949
2024-05-25 06:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch49_loss0.8949499428272247.pypots
2024-05-25 06:17:16 [INFO]: Epoch 050 - training loss: 0.8181, validation loss: 0.8935
2024-05-25 06:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch50_loss0.8934948444366455.pypots
2024-05-25 06:17:16 [INFO]: Epoch 051 - training loss: 0.8136, validation loss: 0.8899
2024-05-25 06:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch51_loss0.8898839503526688.pypots
2024-05-25 06:17:16 [INFO]: Epoch 052 - training loss: 0.8242, validation loss: 0.8935
2024-05-25 06:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch52_loss0.8934945911169052.pypots
2024-05-25 06:17:17 [INFO]: Epoch 053 - training loss: 0.8205, validation loss: 0.8892
2024-05-25 06:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch53_loss0.8892486840486526.pypots
2024-05-25 06:17:17 [INFO]: Epoch 054 - training loss: 0.8009, validation loss: 0.8887
2024-05-25 06:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch54_loss0.8887126445770264.pypots
2024-05-25 06:17:17 [INFO]: Epoch 055 - training loss: 0.7985, validation loss: 0.8886
2024-05-25 06:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch55_loss0.8885879814624786.pypots
2024-05-25 06:17:17 [INFO]: Epoch 056 - training loss: 0.8064, validation loss: 0.8865
2024-05-25 06:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch56_loss0.8864640444517136.pypots
2024-05-25 06:17:17 [INFO]: Epoch 057 - training loss: 0.7937, validation loss: 0.8838
2024-05-25 06:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch57_loss0.8838113844394684.pypots
2024-05-25 06:17:18 [INFO]: Epoch 058 - training loss: 0.8050, validation loss: 0.8848
2024-05-25 06:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch58_loss0.8847730606794357.pypots
2024-05-25 06:17:18 [INFO]: Epoch 059 - training loss: 0.8071, validation loss: 0.8836
2024-05-25 06:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch59_loss0.8835899978876114.pypots
2024-05-25 06:17:18 [INFO]: Epoch 060 - training loss: 0.8115, validation loss: 0.8827
2024-05-25 06:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch60_loss0.8826842904090881.pypots
2024-05-25 06:17:18 [INFO]: Epoch 061 - training loss: 0.8107, validation loss: 0.8822
2024-05-25 06:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch61_loss0.8821674436330795.pypots
2024-05-25 06:17:18 [INFO]: Epoch 062 - training loss: 0.7878, validation loss: 0.8819
2024-05-25 06:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch62_loss0.8819135129451752.pypots
2024-05-25 06:17:19 [INFO]: Epoch 063 - training loss: 0.8114, validation loss: 0.8791
2024-05-25 06:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch63_loss0.8791036158800125.pypots
2024-05-25 06:17:19 [INFO]: Epoch 064 - training loss: 0.7946, validation loss: 0.8768
2024-05-25 06:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch64_loss0.8768178671598434.pypots
2024-05-25 06:17:19 [INFO]: Epoch 065 - training loss: 0.8125, validation loss: 0.8763
2024-05-25 06:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch65_loss0.8762940615415573.pypots
2024-05-25 06:17:19 [INFO]: Epoch 066 - training loss: 0.8291, validation loss: 0.8731
2024-05-25 06:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch66_loss0.8730998337268829.pypots
2024-05-25 06:17:19 [INFO]: Epoch 067 - training loss: 0.7850, validation loss: 0.8725
2024-05-25 06:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch67_loss0.8724737912416458.pypots
2024-05-25 06:17:20 [INFO]: Epoch 068 - training loss: 0.7817, validation loss: 0.8696
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch68_loss0.8695519268512726.pypots
2024-05-25 06:17:20 [INFO]: Epoch 069 - training loss: 0.8052, validation loss: 0.8738
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch69_loss0.8738050609827042.pypots
2024-05-25 06:17:20 [INFO]: Epoch 070 - training loss: 0.8278, validation loss: 0.8709
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch70_loss0.8709344863891602.pypots
2024-05-25 06:17:20 [INFO]: Epoch 071 - training loss: 0.7726, validation loss: 0.8677
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch71_loss0.8676698952913284.pypots
2024-05-25 06:17:20 [INFO]: Epoch 072 - training loss: 0.7873, validation loss: 0.8718
2024-05-25 06:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch72_loss0.8718288093805313.pypots
2024-05-25 06:17:21 [INFO]: Epoch 073 - training loss: 0.8123, validation loss: 0.8648
2024-05-25 06:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch73_loss0.86478690803051.pypots
2024-05-25 06:17:21 [INFO]: Epoch 074 - training loss: 0.7777, validation loss: 0.8627
2024-05-25 06:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch74_loss0.8626702129840851.pypots
2024-05-25 06:17:21 [INFO]: Epoch 075 - training loss: 0.7986, validation loss: 0.8638
2024-05-25 06:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch75_loss0.8638309091329575.pypots
2024-05-25 06:17:21 [INFO]: Epoch 076 - training loss: 0.7822, validation loss: 0.8623
2024-05-25 06:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch76_loss0.8622955083847046.pypots
2024-05-25 06:17:21 [INFO]: Epoch 077 - training loss: 0.7871, validation loss: 0.8636
2024-05-25 06:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch77_loss0.8635834753513336.pypots
2024-05-25 06:17:22 [INFO]: Epoch 078 - training loss: 0.7857, validation loss: 0.8633
2024-05-25 06:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch78_loss0.8632993996143341.pypots
2024-05-25 06:17:22 [INFO]: Epoch 079 - training loss: 0.8136, validation loss: 0.8620
2024-05-25 06:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch79_loss0.8619533777236938.pypots
2024-05-25 06:17:22 [INFO]: Epoch 080 - training loss: 0.8166, validation loss: 0.8574
2024-05-25 06:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch80_loss0.8573647439479828.pypots
2024-05-25 06:17:22 [INFO]: Epoch 081 - training loss: 0.7946, validation loss: 0.8572
2024-05-25 06:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch81_loss0.8572045862674713.pypots
2024-05-25 06:17:22 [INFO]: Epoch 082 - training loss: 0.7817, validation loss: 0.8633
2024-05-25 06:17:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch82_loss0.8632614016532898.pypots
2024-05-25 06:17:23 [INFO]: Epoch 083 - training loss: 0.8018, validation loss: 0.8610
2024-05-25 06:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch83_loss0.8609903305768967.pypots
2024-05-25 06:17:23 [INFO]: Epoch 084 - training loss: 0.7943, validation loss: 0.8586
2024-05-25 06:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch84_loss0.8586280345916748.pypots
2024-05-25 06:17:23 [INFO]: Epoch 085 - training loss: 0.7960, validation loss: 0.8555
2024-05-25 06:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch85_loss0.8554833382368088.pypots
2024-05-25 06:17:23 [INFO]: Epoch 086 - training loss: 0.7905, validation loss: 0.8568
2024-05-25 06:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch86_loss0.8568241000175476.pypots
2024-05-25 06:17:23 [INFO]: Epoch 087 - training loss: 0.7836, validation loss: 0.8562
2024-05-25 06:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch87_loss0.8561685979366302.pypots
2024-05-25 06:17:24 [INFO]: Epoch 088 - training loss: 0.7686, validation loss: 0.8521
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch88_loss0.852066233754158.pypots
2024-05-25 06:17:24 [INFO]: Epoch 089 - training loss: 0.8002, validation loss: 0.8594
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch89_loss0.859379768371582.pypots
2024-05-25 06:17:24 [INFO]: Epoch 090 - training loss: 0.8139, validation loss: 0.8531
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch90_loss0.8531037420034409.pypots
2024-05-25 06:17:24 [INFO]: Epoch 091 - training loss: 0.7796, validation loss: 0.8550
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch91_loss0.8550003618001938.pypots
2024-05-25 06:17:24 [INFO]: Epoch 092 - training loss: 0.7937, validation loss: 0.8548
2024-05-25 06:17:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch92_loss0.8547567278146744.pypots
2024-05-25 06:17:25 [INFO]: Epoch 093 - training loss: 0.7970, validation loss: 0.8548
2024-05-25 06:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch93_loss0.8547741025686264.pypots
2024-05-25 06:17:25 [INFO]: Epoch 094 - training loss: 0.7923, validation loss: 0.8522
2024-05-25 06:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch94_loss0.8522303551435471.pypots
2024-05-25 06:17:25 [INFO]: Epoch 095 - training loss: 0.8028, validation loss: 0.8495
2024-05-25 06:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch95_loss0.8495127409696579.pypots
2024-05-25 06:17:25 [INFO]: Epoch 096 - training loss: 0.8010, validation loss: 0.8515
2024-05-25 06:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch96_loss0.8514575660228729.pypots
2024-05-25 06:17:25 [INFO]: Epoch 097 - training loss: 0.8039, validation loss: 0.8547
2024-05-25 06:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch97_loss0.8546538800001144.pypots
2024-05-25 06:17:26 [INFO]: Epoch 098 - training loss: 0.7800, validation loss: 0.8515
2024-05-25 06:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch98_loss0.8514619022607803.pypots
2024-05-25 06:17:26 [INFO]: Epoch 099 - training loss: 0.7993, validation loss: 0.8518
2024-05-25 06:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch99_loss0.8517756760120392.pypots
2024-05-25 06:17:26 [INFO]: Epoch 100 - training loss: 0.7736, validation loss: 0.8498
2024-05-25 06:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch100_loss0.8497501462697983.pypots
2024-05-25 06:17:26 [INFO]: Epoch 101 - training loss: 0.7920, validation loss: 0.8493
2024-05-25 06:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch101_loss0.8492557853460312.pypots
2024-05-25 06:17:26 [INFO]: Epoch 102 - training loss: 0.7968, validation loss: 0.8495
2024-05-25 06:17:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch102_loss0.8495008498430252.pypots
2024-05-25 06:17:27 [INFO]: Epoch 103 - training loss: 0.7759, validation loss: 0.8479
2024-05-25 06:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch103_loss0.8478793054819107.pypots
2024-05-25 06:17:27 [INFO]: Epoch 104 - training loss: 0.7918, validation loss: 0.8485
2024-05-25 06:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch104_loss0.8484885096549988.pypots
2024-05-25 06:17:27 [INFO]: Epoch 105 - training loss: 0.7965, validation loss: 0.8482
2024-05-25 06:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch105_loss0.8482269495725632.pypots
2024-05-25 06:17:27 [INFO]: Epoch 106 - training loss: 0.7656, validation loss: 0.8434
2024-05-25 06:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch106_loss0.8433647900819778.pypots
2024-05-25 06:17:27 [INFO]: Epoch 107 - training loss: 0.8340, validation loss: 0.8477
2024-05-25 06:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch107_loss0.8477193713188171.pypots
2024-05-25 06:17:28 [INFO]: Epoch 108 - training loss: 0.8037, validation loss: 0.8464
2024-05-25 06:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch108_loss0.8463766127824783.pypots
2024-05-25 06:17:28 [INFO]: Epoch 109 - training loss: 0.7869, validation loss: 0.8432
2024-05-25 06:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch109_loss0.8432070463895798.pypots
2024-05-25 06:17:28 [INFO]: Epoch 110 - training loss: 0.7800, validation loss: 0.8427
2024-05-25 06:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch110_loss0.8427412956953049.pypots
2024-05-25 06:17:28 [INFO]: Epoch 111 - training loss: 0.8238, validation loss: 0.8459
2024-05-25 06:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch111_loss0.8458958566188812.pypots
2024-05-25 06:17:28 [INFO]: Epoch 112 - training loss: 0.7929, validation loss: 0.8464
2024-05-25 06:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch112_loss0.8463907986879349.pypots
2024-05-25 06:17:29 [INFO]: Epoch 113 - training loss: 0.7902, validation loss: 0.8413
2024-05-25 06:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch113_loss0.8412527441978455.pypots
2024-05-25 06:17:29 [INFO]: Epoch 114 - training loss: 0.7860, validation loss: 0.8420
2024-05-25 06:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch114_loss0.8420181125402451.pypots
2024-05-25 06:17:29 [INFO]: Epoch 115 - training loss: 0.7888, validation loss: 0.8415
2024-05-25 06:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch115_loss0.841490313410759.pypots
2024-05-25 06:17:29 [INFO]: Epoch 116 - training loss: 0.7878, validation loss: 0.8422
2024-05-25 06:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch116_loss0.8421970009803772.pypots
2024-05-25 06:17:29 [INFO]: Epoch 117 - training loss: 0.7754, validation loss: 0.8392
2024-05-25 06:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch117_loss0.8391590118408203.pypots
2024-05-25 06:17:30 [INFO]: Epoch 118 - training loss: 0.7837, validation loss: 0.8416
2024-05-25 06:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch118_loss0.8416387140750885.pypots
2024-05-25 06:17:30 [INFO]: Epoch 119 - training loss: 0.8020, validation loss: 0.8426
2024-05-25 06:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch119_loss0.8425928354263306.pypots
2024-05-25 06:17:30 [INFO]: Epoch 120 - training loss: 0.7916, validation loss: 0.8440
2024-05-25 06:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch120_loss0.8440258204936981.pypots
2024-05-25 06:17:30 [INFO]: Epoch 121 - training loss: 0.7975, validation loss: 0.8408
2024-05-25 06:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch121_loss0.840819388628006.pypots
2024-05-25 06:17:30 [INFO]: Epoch 122 - training loss: 0.8222, validation loss: 0.8341
2024-05-25 06:17:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch122_loss0.8340725004673004.pypots
2024-05-25 06:17:31 [INFO]: Epoch 123 - training loss: 0.8085, validation loss: 0.8375
2024-05-25 06:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch123_loss0.8374811708927155.pypots
2024-05-25 06:17:31 [INFO]: Epoch 124 - training loss: 0.7618, validation loss: 0.8361
2024-05-25 06:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch124_loss0.8360567837953568.pypots
2024-05-25 06:17:31 [INFO]: Epoch 125 - training loss: 0.7747, validation loss: 0.8422
2024-05-25 06:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch125_loss0.8421997874975204.pypots
2024-05-25 06:17:31 [INFO]: Epoch 126 - training loss: 0.7814, validation loss: 0.8378
2024-05-25 06:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch126_loss0.837842583656311.pypots
2024-05-25 06:17:31 [INFO]: Epoch 127 - training loss: 0.7799, validation loss: 0.8404
2024-05-25 06:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch127_loss0.8403739631175995.pypots
2024-05-25 06:17:32 [INFO]: Epoch 128 - training loss: 0.7719, validation loss: 0.8334
2024-05-25 06:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch128_loss0.8334030658006668.pypots
2024-05-25 06:17:32 [INFO]: Epoch 129 - training loss: 0.7826, validation loss: 0.8318
2024-05-25 06:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch129_loss0.8317881524562836.pypots
2024-05-25 06:17:32 [INFO]: Epoch 130 - training loss: 0.8015, validation loss: 0.8362
2024-05-25 06:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch130_loss0.8362268507480621.pypots
2024-05-25 06:17:32 [INFO]: Epoch 131 - training loss: 0.7848, validation loss: 0.8349
2024-05-25 06:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch131_loss0.8348814249038696.pypots
2024-05-25 06:17:32 [INFO]: Epoch 132 - training loss: 0.7884, validation loss: 0.8381
2024-05-25 06:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch132_loss0.8380975425243378.pypots
2024-05-25 06:17:33 [INFO]: Epoch 133 - training loss: 0.7883, validation loss: 0.8312
2024-05-25 06:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch133_loss0.8311891853809357.pypots
2024-05-25 06:17:33 [INFO]: Epoch 134 - training loss: 0.7854, validation loss: 0.8358
2024-05-25 06:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch134_loss0.8357998877763748.pypots
2024-05-25 06:17:33 [INFO]: Epoch 135 - training loss: 0.7784, validation loss: 0.8334
2024-05-25 06:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch135_loss0.8334230184555054.pypots
2024-05-25 06:17:33 [INFO]: Epoch 136 - training loss: 0.7596, validation loss: 0.8322
2024-05-25 06:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch136_loss0.8321765512228012.pypots
2024-05-25 06:17:33 [INFO]: Epoch 137 - training loss: 0.7874, validation loss: 0.8366
2024-05-25 06:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch137_loss0.8366096317768097.pypots
2024-05-25 06:17:34 [INFO]: Epoch 138 - training loss: 0.7613, validation loss: 0.8295
2024-05-25 06:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch138_loss0.8295448869466782.pypots
2024-05-25 06:17:34 [INFO]: Epoch 139 - training loss: 0.7838, validation loss: 0.8325
2024-05-25 06:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch139_loss0.8324769884347916.pypots
2024-05-25 06:17:34 [INFO]: Epoch 140 - training loss: 0.7753, validation loss: 0.8310
2024-05-25 06:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch140_loss0.8310319781303406.pypots
2024-05-25 06:17:34 [INFO]: Epoch 141 - training loss: 0.7888, validation loss: 0.8310
2024-05-25 06:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch141_loss0.8310022801160812.pypots
2024-05-25 06:17:34 [INFO]: Epoch 142 - training loss: 0.7642, validation loss: 0.8308
2024-05-25 06:17:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch142_loss0.8308387249708176.pypots
2024-05-25 06:17:35 [INFO]: Epoch 143 - training loss: 0.7819, validation loss: 0.8304
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch143_loss0.8303581178188324.pypots
2024-05-25 06:17:35 [INFO]: Epoch 144 - training loss: 0.7850, validation loss: 0.8287
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch144_loss0.8286810368299484.pypots
2024-05-25 06:17:35 [INFO]: Epoch 145 - training loss: 0.7764, validation loss: 0.8259
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch145_loss0.8258501142263412.pypots
2024-05-25 06:17:35 [INFO]: Epoch 146 - training loss: 0.7672, validation loss: 0.8296
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch146_loss0.8295513540506363.pypots
2024-05-25 06:17:35 [INFO]: Epoch 147 - training loss: 0.7812, validation loss: 0.8253
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch147_loss0.825310692191124.pypots
2024-05-25 06:17:35 [INFO]: Epoch 148 - training loss: 0.7969, validation loss: 0.8285
2024-05-25 06:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch148_loss0.8284943401813507.pypots
2024-05-25 06:17:36 [INFO]: Epoch 149 - training loss: 0.7755, validation loss: 0.8294
2024-05-25 06:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch149_loss0.8294331133365631.pypots
2024-05-25 06:17:36 [INFO]: Epoch 150 - training loss: 0.7786, validation loss: 0.8290
2024-05-25 06:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch150_loss0.8290483206510544.pypots
2024-05-25 06:17:36 [INFO]: Epoch 151 - training loss: 0.8253, validation loss: 0.8234
2024-05-25 06:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch151_loss0.8234263956546783.pypots
2024-05-25 06:17:36 [INFO]: Epoch 152 - training loss: 0.7931, validation loss: 0.8275
2024-05-25 06:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch152_loss0.8275040686130524.pypots
2024-05-25 06:17:36 [INFO]: Epoch 153 - training loss: 0.7718, validation loss: 0.8217
2024-05-25 06:17:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch153_loss0.8216594010591507.pypots
2024-05-25 06:17:37 [INFO]: Epoch 154 - training loss: 0.7869, validation loss: 0.8267
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch154_loss0.8266696184873581.pypots
2024-05-25 06:17:37 [INFO]: Epoch 155 - training loss: 0.7609, validation loss: 0.8272
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch155_loss0.8272041976451874.pypots
2024-05-25 06:17:37 [INFO]: Epoch 156 - training loss: 0.7914, validation loss: 0.8261
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch156_loss0.826079398393631.pypots
2024-05-25 06:17:37 [INFO]: Epoch 157 - training loss: 0.7582, validation loss: 0.8252
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch157_loss0.8251758515834808.pypots
2024-05-25 06:17:37 [INFO]: Epoch 158 - training loss: 0.8127, validation loss: 0.8230
2024-05-25 06:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch158_loss0.8229934722185135.pypots
2024-05-25 06:17:38 [INFO]: Epoch 159 - training loss: 0.7995, validation loss: 0.8228
2024-05-25 06:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch159_loss0.8227960616350174.pypots
2024-05-25 06:17:38 [INFO]: Epoch 160 - training loss: 0.7663, validation loss: 0.8269
2024-05-25 06:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch160_loss0.826910212635994.pypots
2024-05-25 06:17:38 [INFO]: Epoch 161 - training loss: 0.7761, validation loss: 0.8244
2024-05-25 06:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch161_loss0.8243888914585114.pypots
2024-05-25 06:17:38 [INFO]: Epoch 162 - training loss: 0.7628, validation loss: 0.8192
2024-05-25 06:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch162_loss0.819187119603157.pypots
2024-05-25 06:17:38 [INFO]: Epoch 163 - training loss: 0.7811, validation loss: 0.8186
2024-05-25 06:17:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch163_loss0.8185577094554901.pypots
2024-05-25 06:17:39 [INFO]: Epoch 164 - training loss: 0.7856, validation loss: 0.8192
2024-05-25 06:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch164_loss0.8191574662923813.pypots
2024-05-25 06:17:39 [INFO]: Epoch 165 - training loss: 0.7683, validation loss: 0.8170
2024-05-25 06:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch165_loss0.8170434832572937.pypots
2024-05-25 06:17:39 [INFO]: Epoch 166 - training loss: 0.7803, validation loss: 0.8189
2024-05-25 06:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch166_loss0.818851426243782.pypots
2024-05-25 06:17:39 [INFO]: Epoch 167 - training loss: 0.7887, validation loss: 0.8167
2024-05-25 06:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch167_loss0.8167118579149246.pypots
2024-05-25 06:17:39 [INFO]: Epoch 168 - training loss: 0.7868, validation loss: 0.8193
2024-05-25 06:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch168_loss0.8192706406116486.pypots
2024-05-25 06:17:40 [INFO]: Epoch 169 - training loss: 0.7877, validation loss: 0.8149
2024-05-25 06:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch169_loss0.8148525953292847.pypots
2024-05-25 06:17:40 [INFO]: Epoch 170 - training loss: 0.7852, validation loss: 0.8188
2024-05-25 06:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch170_loss0.8188216835260391.pypots
2024-05-25 06:17:40 [INFO]: Epoch 171 - training loss: 0.7924, validation loss: 0.8171
2024-05-25 06:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch171_loss0.8170961290597916.pypots
2024-05-25 06:17:40 [INFO]: Epoch 172 - training loss: 0.7941, validation loss: 0.8176
2024-05-25 06:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch172_loss0.8176009804010391.pypots
2024-05-25 06:17:40 [INFO]: Epoch 173 - training loss: 0.7754, validation loss: 0.8146
2024-05-25 06:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch173_loss0.8145959973335266.pypots
2024-05-25 06:17:41 [INFO]: Epoch 174 - training loss: 0.7860, validation loss: 0.8191
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch174_loss0.8191123604774475.pypots
2024-05-25 06:17:41 [INFO]: Epoch 175 - training loss: 0.7732, validation loss: 0.8125
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch175_loss0.812539279460907.pypots
2024-05-25 06:17:41 [INFO]: Epoch 176 - training loss: 0.7747, validation loss: 0.8163
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch176_loss0.8162613213062286.pypots
2024-05-25 06:17:41 [INFO]: Epoch 177 - training loss: 0.7849, validation loss: 0.8153
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch177_loss0.8152510672807693.pypots
2024-05-25 06:17:41 [INFO]: Epoch 178 - training loss: 0.7684, validation loss: 0.8164
2024-05-25 06:17:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch178_loss0.8163770139217377.pypots
2024-05-25 06:17:42 [INFO]: Epoch 179 - training loss: 0.7861, validation loss: 0.8155
2024-05-25 06:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch179_loss0.8154569864273071.pypots
2024-05-25 06:17:42 [INFO]: Epoch 180 - training loss: 0.7896, validation loss: 0.8162
2024-05-25 06:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch180_loss0.8161770552396774.pypots
2024-05-25 06:17:42 [INFO]: Epoch 181 - training loss: 0.7740, validation loss: 0.8134
2024-05-25 06:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch181_loss0.8134187310934067.pypots
2024-05-25 06:17:42 [INFO]: Epoch 182 - training loss: 0.7950, validation loss: 0.8141
2024-05-25 06:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch182_loss0.8140732049942017.pypots
2024-05-25 06:17:42 [INFO]: Epoch 183 - training loss: 0.7864, validation loss: 0.8109
2024-05-25 06:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch183_loss0.8108667135238647.pypots
2024-05-25 06:17:43 [INFO]: Epoch 184 - training loss: 0.7819, validation loss: 0.8159
2024-05-25 06:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch184_loss0.8158975541591644.pypots
2024-05-25 06:17:43 [INFO]: Epoch 185 - training loss: 0.7851, validation loss: 0.8101
2024-05-25 06:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch185_loss0.8101339638233185.pypots
2024-05-25 06:17:43 [INFO]: Epoch 186 - training loss: 0.8135, validation loss: 0.8108
2024-05-25 06:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch186_loss0.8107802420854568.pypots
2024-05-25 06:17:43 [INFO]: Epoch 187 - training loss: 0.7976, validation loss: 0.8117
2024-05-25 06:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch187_loss0.8117313981056213.pypots
2024-05-25 06:17:43 [INFO]: Epoch 188 - training loss: 0.7839, validation loss: 0.8111
2024-05-25 06:17:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch188_loss0.8110684454441071.pypots
2024-05-25 06:17:44 [INFO]: Epoch 189 - training loss: 0.8173, validation loss: 0.8124
2024-05-25 06:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch189_loss0.8123958259820938.pypots
2024-05-25 06:17:44 [INFO]: Epoch 190 - training loss: 0.8136, validation loss: 0.8106
2024-05-25 06:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch190_loss0.8105633705854416.pypots
2024-05-25 06:17:44 [INFO]: Epoch 191 - training loss: 0.7678, validation loss: 0.8108
2024-05-25 06:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch191_loss0.8107520639896393.pypots
2024-05-25 06:17:44 [INFO]: Epoch 192 - training loss: 0.7805, validation loss: 0.8125
2024-05-25 06:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch192_loss0.8124704658985138.pypots
2024-05-25 06:17:44 [INFO]: Epoch 193 - training loss: 0.7764, validation loss: 0.8100
2024-05-25 06:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch193_loss0.8100182265043259.pypots
2024-05-25 06:17:45 [INFO]: Epoch 194 - training loss: 0.7986, validation loss: 0.8072
2024-05-25 06:17:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch194_loss0.8072059154510498.pypots
2024-05-25 06:17:45 [INFO]: Epoch 195 - training loss: 0.7892, validation loss: 0.8124
2024-05-25 06:17:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch195_loss0.8123662322759628.pypots
2024-05-25 06:17:45 [INFO]: Epoch 196 - training loss: 0.7858, validation loss: 0.8091
2024-05-25 06:17:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch196_loss0.8091015815734863.pypots
2024-05-25 06:17:45 [INFO]: Epoch 197 - training loss: 0.7676, validation loss: 0.8081
2024-05-25 06:17:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch197_loss0.808054506778717.pypots
2024-05-25 06:17:45 [INFO]: Epoch 198 - training loss: 0.8145, validation loss: 0.8085
2024-05-25 06:17:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch198_loss0.8084655106067657.pypots
2024-05-25 06:17:46 [INFO]: Epoch 199 - training loss: 0.8235, validation loss: 0.8067
2024-05-25 06:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch199_loss0.8067408055067062.pypots
2024-05-25 06:17:46 [INFO]: Epoch 200 - training loss: 0.7750, validation loss: 0.8106
2024-05-25 06:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch200_loss0.8106372207403183.pypots
2024-05-25 06:17:46 [INFO]: Epoch 201 - training loss: 0.7869, validation loss: 0.8101
2024-05-25 06:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch201_loss0.8101275116205215.pypots
2024-05-25 06:17:46 [INFO]: Epoch 202 - training loss: 0.8158, validation loss: 0.8093
2024-05-25 06:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch202_loss0.8092863857746124.pypots
2024-05-25 06:17:46 [INFO]: Epoch 203 - training loss: 0.7865, validation loss: 0.8066
2024-05-25 06:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch203_loss0.806553453207016.pypots
2024-05-25 06:17:47 [INFO]: Epoch 204 - training loss: 0.7926, validation loss: 0.8064
2024-05-25 06:17:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch204_loss0.8063979595899582.pypots
2024-05-25 06:17:47 [INFO]: Epoch 205 - training loss: 0.7805, validation loss: 0.8089
2024-05-25 06:17:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch205_loss0.80888232588768.pypots
2024-05-25 06:17:47 [INFO]: Epoch 206 - training loss: 0.7912, validation loss: 0.8061
2024-05-25 06:17:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch206_loss0.806125819683075.pypots
2024-05-25 06:17:47 [INFO]: Epoch 207 - training loss: 0.8224, validation loss: 0.8091
2024-05-25 06:17:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch207_loss0.8091033101081848.pypots
2024-05-25 06:17:47 [INFO]: Epoch 208 - training loss: 0.7701, validation loss: 0.8058
2024-05-25 06:17:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch208_loss0.8058191388845444.pypots
2024-05-25 06:17:48 [INFO]: Epoch 209 - training loss: 0.7941, validation loss: 0.8076
2024-05-25 06:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch209_loss0.8075916469097137.pypots
2024-05-25 06:17:48 [INFO]: Epoch 210 - training loss: 0.7919, validation loss: 0.8064
2024-05-25 06:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch210_loss0.8063919097185135.pypots
2024-05-25 06:17:48 [INFO]: Epoch 211 - training loss: 0.7779, validation loss: 0.8031
2024-05-25 06:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch211_loss0.8030548542737961.pypots
2024-05-25 06:17:48 [INFO]: Epoch 212 - training loss: 0.7576, validation loss: 0.8062
2024-05-25 06:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch212_loss0.8061669021844864.pypots
2024-05-25 06:17:48 [INFO]: Epoch 213 - training loss: 0.7953, validation loss: 0.8062
2024-05-25 06:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch213_loss0.8061771094799042.pypots
2024-05-25 06:17:49 [INFO]: Epoch 214 - training loss: 0.7855, validation loss: 0.8075
2024-05-25 06:17:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch214_loss0.8074936419725418.pypots
2024-05-25 06:17:49 [INFO]: Epoch 215 - training loss: 0.7828, validation loss: 0.8035
2024-05-25 06:17:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch215_loss0.8034788072109222.pypots
2024-05-25 06:17:49 [INFO]: Epoch 216 - training loss: 0.7864, validation loss: 0.8029
2024-05-25 06:17:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch216_loss0.8029314428567886.pypots
2024-05-25 06:17:49 [INFO]: Epoch 217 - training loss: 0.7818, validation loss: 0.8047
2024-05-25 06:17:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch217_loss0.8047045469284058.pypots
2024-05-25 06:17:49 [INFO]: Epoch 218 - training loss: 0.7790, validation loss: 0.8046
2024-05-25 06:17:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch218_loss0.8046105802059174.pypots
2024-05-25 06:17:50 [INFO]: Epoch 219 - training loss: 0.7872, validation loss: 0.8088
2024-05-25 06:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch219_loss0.8087975233793259.pypots
2024-05-25 06:17:50 [INFO]: Epoch 220 - training loss: 0.7655, validation loss: 0.8036
2024-05-25 06:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch220_loss0.8036315143108368.pypots
2024-05-25 06:17:50 [INFO]: Epoch 221 - training loss: 0.7861, validation loss: 0.8019
2024-05-25 06:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch221_loss0.8018962144851685.pypots
2024-05-25 06:17:50 [INFO]: Epoch 222 - training loss: 0.7563, validation loss: 0.8010
2024-05-25 06:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch222_loss0.8010054379701614.pypots
2024-05-25 06:17:50 [INFO]: Epoch 223 - training loss: 0.7778, validation loss: 0.8024
2024-05-25 06:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch223_loss0.8024255782365799.pypots
2024-05-25 06:17:51 [INFO]: Epoch 224 - training loss: 0.7922, validation loss: 0.8030
2024-05-25 06:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch224_loss0.8029929101467133.pypots
2024-05-25 06:17:51 [INFO]: Epoch 225 - training loss: 0.7855, validation loss: 0.8032
2024-05-25 06:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch225_loss0.8032263964414597.pypots
2024-05-25 06:17:51 [INFO]: Epoch 226 - training loss: 0.7527, validation loss: 0.8012
2024-05-25 06:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch226_loss0.8011754900217056.pypots
2024-05-25 06:17:51 [INFO]: Epoch 227 - training loss: 0.7614, validation loss: 0.8032
2024-05-25 06:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch227_loss0.8031821995973587.pypots
2024-05-25 06:17:51 [INFO]: Epoch 228 - training loss: 0.7719, validation loss: 0.8041
2024-05-25 06:17:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch228_loss0.8040731996297836.pypots
2024-05-25 06:17:52 [INFO]: Epoch 229 - training loss: 0.7802, validation loss: 0.7993
2024-05-25 06:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch229_loss0.7992833703756332.pypots
2024-05-25 06:17:52 [INFO]: Epoch 230 - training loss: 0.7802, validation loss: 0.8031
2024-05-25 06:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch230_loss0.8031235486268997.pypots
2024-05-25 06:17:52 [INFO]: Epoch 231 - training loss: 0.7715, validation loss: 0.8012
2024-05-25 06:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch231_loss0.8011967539787292.pypots
2024-05-25 06:17:52 [INFO]: Epoch 232 - training loss: 0.7599, validation loss: 0.8019
2024-05-25 06:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch232_loss0.8018941134214401.pypots
2024-05-25 06:17:52 [INFO]: Epoch 233 - training loss: 0.7659, validation loss: 0.7972
2024-05-25 06:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch233_loss0.7972457110881805.pypots
2024-05-25 06:17:53 [INFO]: Epoch 234 - training loss: 0.7762, validation loss: 0.7972
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch234_loss0.7971808612346649.pypots
2024-05-25 06:17:53 [INFO]: Epoch 235 - training loss: 0.7908, validation loss: 0.7992
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch235_loss0.799190104007721.pypots
2024-05-25 06:17:53 [INFO]: Epoch 236 - training loss: 0.7512, validation loss: 0.8002
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch236_loss0.8002015650272369.pypots
2024-05-25 06:17:53 [INFO]: Epoch 237 - training loss: 0.7829, validation loss: 0.7995
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch237_loss0.7994540929794312.pypots
2024-05-25 06:17:53 [INFO]: Epoch 238 - training loss: 0.7750, validation loss: 0.7985
2024-05-25 06:17:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch238_loss0.7984981685876846.pypots
2024-05-25 06:17:54 [INFO]: Epoch 239 - training loss: 0.7666, validation loss: 0.7981
2024-05-25 06:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch239_loss0.7980809807777405.pypots
2024-05-25 06:17:54 [INFO]: Epoch 240 - training loss: 0.7747, validation loss: 0.7967
2024-05-25 06:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch240_loss0.7967448532581329.pypots
2024-05-25 06:17:54 [INFO]: Epoch 241 - training loss: 0.7807, validation loss: 0.7985
2024-05-25 06:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch241_loss0.7984939813613892.pypots
2024-05-25 06:17:54 [INFO]: Epoch 242 - training loss: 0.7818, validation loss: 0.7995
2024-05-25 06:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch242_loss0.7994647175073624.pypots
2024-05-25 06:17:54 [INFO]: Epoch 243 - training loss: 0.8112, validation loss: 0.7962
2024-05-25 06:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch243_loss0.7962015867233276.pypots
2024-05-25 06:17:55 [INFO]: Epoch 244 - training loss: 0.7757, validation loss: 0.7984
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch244_loss0.7983558624982834.pypots
2024-05-25 06:17:55 [INFO]: Epoch 245 - training loss: 0.7852, validation loss: 0.7954
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch245_loss0.795409694314003.pypots
2024-05-25 06:17:55 [INFO]: Epoch 246 - training loss: 0.7725, validation loss: 0.7958
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch246_loss0.795844316482544.pypots
2024-05-25 06:17:55 [INFO]: Epoch 247 - training loss: 0.8205, validation loss: 0.7980
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch247_loss0.7980322986841202.pypots
2024-05-25 06:17:55 [INFO]: Epoch 248 - training loss: 0.7574, validation loss: 0.7948
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch248_loss0.7948459386825562.pypots
2024-05-25 06:17:55 [INFO]: Epoch 249 - training loss: 0.8006, validation loss: 0.7994
2024-05-25 06:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch249_loss0.7994299978017807.pypots
2024-05-25 06:17:56 [INFO]: Epoch 250 - training loss: 0.7663, validation loss: 0.7940
2024-05-25 06:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch250_loss0.7939921766519547.pypots
2024-05-25 06:17:56 [INFO]: Epoch 251 - training loss: 0.7866, validation loss: 0.7946
2024-05-25 06:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch251_loss0.7945570945739746.pypots
2024-05-25 06:17:56 [INFO]: Epoch 252 - training loss: 0.7832, validation loss: 0.7960
2024-05-25 06:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch252_loss0.7960173338651657.pypots
2024-05-25 06:17:56 [INFO]: Epoch 253 - training loss: 0.7612, validation loss: 0.7926
2024-05-25 06:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch253_loss0.7926190048456192.pypots
2024-05-25 06:17:56 [INFO]: Epoch 254 - training loss: 0.7929, validation loss: 0.7925
2024-05-25 06:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch254_loss0.7924704849720001.pypots
2024-05-25 06:17:57 [INFO]: Epoch 255 - training loss: 0.7866, validation loss: 0.7965
2024-05-25 06:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch255_loss0.7965295165777206.pypots
2024-05-25 06:17:57 [INFO]: Epoch 256 - training loss: 0.7615, validation loss: 0.7947
2024-05-25 06:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch256_loss0.794730007648468.pypots
2024-05-25 06:17:57 [INFO]: Epoch 257 - training loss: 0.7772, validation loss: 0.7950
2024-05-25 06:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch257_loss0.7949682176113129.pypots
2024-05-25 06:17:57 [INFO]: Epoch 258 - training loss: 0.7587, validation loss: 0.7937
2024-05-25 06:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch258_loss0.7937263697385788.pypots
2024-05-25 06:17:57 [INFO]: Epoch 259 - training loss: 0.7559, validation loss: 0.7924
2024-05-25 06:17:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch259_loss0.7924485802650452.pypots
2024-05-25 06:17:58 [INFO]: Epoch 260 - training loss: 0.7566, validation loss: 0.7955
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch260_loss0.795480415225029.pypots
2024-05-25 06:17:58 [INFO]: Epoch 261 - training loss: 0.7712, validation loss: 0.7919
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch261_loss0.7919349819421768.pypots
2024-05-25 06:17:58 [INFO]: Epoch 262 - training loss: 0.7699, validation loss: 0.7918
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch262_loss0.7918197214603424.pypots
2024-05-25 06:17:58 [INFO]: Epoch 263 - training loss: 0.8064, validation loss: 0.7881
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch263_loss0.7881104648113251.pypots
2024-05-25 06:17:58 [INFO]: Epoch 264 - training loss: 0.7629, validation loss: 0.7922
2024-05-25 06:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch264_loss0.7921707779169083.pypots
2024-05-25 06:17:59 [INFO]: Epoch 265 - training loss: 0.7845, validation loss: 0.7936
2024-05-25 06:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch265_loss0.7936437129974365.pypots
2024-05-25 06:17:59 [INFO]: Epoch 266 - training loss: 0.7698, validation loss: 0.7903
2024-05-25 06:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch266_loss0.7903471887111664.pypots
2024-05-25 06:17:59 [INFO]: Epoch 267 - training loss: 0.7865, validation loss: 0.7924
2024-05-25 06:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch267_loss0.7924265563488007.pypots
2024-05-25 06:17:59 [INFO]: Epoch 268 - training loss: 0.7608, validation loss: 0.7937
2024-05-25 06:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch268_loss0.7937078177928925.pypots
2024-05-25 06:17:59 [INFO]: Epoch 269 - training loss: 0.7956, validation loss: 0.7924
2024-05-25 06:17:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch269_loss0.7924216538667679.pypots
2024-05-25 06:18:00 [INFO]: Epoch 270 - training loss: 0.7862, validation loss: 0.7930
2024-05-25 06:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch270_loss0.7930280417203903.pypots
2024-05-25 06:18:00 [INFO]: Epoch 271 - training loss: 0.7836, validation loss: 0.7912
2024-05-25 06:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch271_loss0.7912386357784271.pypots
2024-05-25 06:18:00 [INFO]: Epoch 272 - training loss: 0.7681, validation loss: 0.7936
2024-05-25 06:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch272_loss0.7936361581087112.pypots
2024-05-25 06:18:00 [INFO]: Epoch 273 - training loss: 0.7693, validation loss: 0.7936
2024-05-25 06:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN_epoch273_loss0.7935619354248047.pypots
2024-05-25 06:18:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:18:00 [INFO]: Finished training. The best model is from epoch#263.
2024-05-25 06:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240525_T061704/MRNN.pypots
2024-05-25 06:18:01 [INFO]: MRNN on ETTm1: MAE=0.6494, MSE=1.0239
2024-05-25 06:18:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 06:18:01 [INFO]: Using the given device: cpu
2024-05-25 06:18:01 [INFO]: LOCF on ETTm1: MAE=0.1332, MSE=0.0720
2024-05-25 06:18:01 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 06:18:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 06:18:01 [INFO]: Median on ETTm1: MAE=0.6670, MSE=0.8617
2024-05-25 06:18:01 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 06:18:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 06:18:01 [INFO]: Mean on ETTm1: MAE=0.6734, MSE=0.8444
2024-05-25 06:18:01 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 06:18:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 06:18:01 [INFO]: 
SAITS on data/ettm1: MAE=0.163±0.019128104138762547, MSE=0.051±0.009668389722014082
Transformer on data/ettm1: MAE=0.138±0.009523180151258538, MSE=0.038±0.0036590326837260432
TimesNet on data/ettm1: MAE=0.102±0.0011687740674067035, MSE=0.023±0.0005075955600916284
CSDI on data/ettm1: MAE=0.154±0.029410594586875508, MSE=0.057±0.02286421595142184
GPVAE on data/ettm1: MAE=0.262±0.007355377370655136, MSE=0.145±0.00953896856848462
USGAN on data/ettm1: MAE=0.142±0.005069424867972377, MSE=0.051±0.0036575059287881503
BRITS on data/ettm1: MAE=0.126±0.004944150166108102, MSE=0.047±0.002991322803230278
MRNN on data/ettm1: MAE=0.658±0.024276814638157743, MSE=1.090±0.07078937049423875
LOCF on data/ettm1: MAE=0.133±0.0, MSE=0.072±0.0
Median on data/ettm1: MAE=0.667±0.0, MSE=0.862±0.0
Mean on data/ettm1: MAE=0.673±0.0, MSE=0.844±1.1102230246251565e-16