2024-05-24 21:01:08 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 21:01:09 [INFO]: Using the given device: cuda:0
2024-05-24 21:01:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240524_T210109
2024-05-24 21:01:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240524_T210109/tensorboard
2024-05-24 21:01:09 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 21:01:19 [INFO]: Epoch 001 - training loss: 1.0459, validation loss: 0.5090
2024-05-24 21:01:20 [INFO]: Epoch 002 - training loss: 0.7545, validation loss: 0.3868
2024-05-24 21:01:21 [INFO]: Epoch 003 - training loss: 0.6485, validation loss: 0.3034
2024-05-24 21:01:21 [INFO]: Epoch 004 - training loss: 0.5737, validation loss: 0.2618
2024-05-24 21:01:22 [INFO]: Epoch 005 - training loss: 0.5215, validation loss: 0.2356
2024-05-24 21:01:22 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2232
2024-05-24 21:01:23 [INFO]: Epoch 007 - training loss: 0.4537, validation loss: 0.2131
2024-05-24 21:01:24 [INFO]: Epoch 008 - training loss: 0.4332, validation loss: 0.2041
2024-05-24 21:01:24 [INFO]: Epoch 009 - training loss: 0.4178, validation loss: 0.1996
2024-05-24 21:01:25 [INFO]: Epoch 010 - training loss: 0.4060, validation loss: 0.1943
2024-05-24 21:01:25 [INFO]: Epoch 011 - training loss: 0.3963, validation loss: 0.1898
2024-05-24 21:01:26 [INFO]: Epoch 012 - training loss: 0.3889, validation loss: 0.1878
2024-05-24 21:01:26 [INFO]: Epoch 013 - training loss: 0.3802, validation loss: 0.1831
2024-05-24 21:01:27 [INFO]: Epoch 014 - training loss: 0.3733, validation loss: 0.1798
2024-05-24 21:01:28 [INFO]: Epoch 015 - training loss: 0.3679, validation loss: 0.1747
2024-05-24 21:01:28 [INFO]: Epoch 016 - training loss: 0.3603, validation loss: 0.1725
2024-05-24 21:01:29 [INFO]: Epoch 017 - training loss: 0.3538, validation loss: 0.1696
2024-05-24 21:01:29 [INFO]: Epoch 018 - training loss: 0.3494, validation loss: 0.1682
2024-05-24 21:01:30 [INFO]: Epoch 019 - training loss: 0.3459, validation loss: 0.1661
2024-05-24 21:01:31 [INFO]: Epoch 020 - training loss: 0.3411, validation loss: 0.1627
2024-05-24 21:01:31 [INFO]: Epoch 021 - training loss: 0.3365, validation loss: 0.1604
2024-05-24 21:01:32 [INFO]: Epoch 022 - training loss: 0.3318, validation loss: 0.1591
2024-05-24 21:01:32 [INFO]: Epoch 023 - training loss: 0.3287, validation loss: 0.1555
2024-05-24 21:01:33 [INFO]: Epoch 024 - training loss: 0.3255, validation loss: 0.1541
2024-05-24 21:01:34 [INFO]: Epoch 025 - training loss: 0.3236, validation loss: 0.1515
2024-05-24 21:01:34 [INFO]: Epoch 026 - training loss: 0.3190, validation loss: 0.1522
2024-05-24 21:01:35 [INFO]: Epoch 027 - training loss: 0.3149, validation loss: 0.1488
2024-05-24 21:01:35 [INFO]: Epoch 028 - training loss: 0.3126, validation loss: 0.1472
2024-05-24 21:01:36 [INFO]: Epoch 029 - training loss: 0.3105, validation loss: 0.1457
2024-05-24 21:01:37 [INFO]: Epoch 030 - training loss: 0.3085, validation loss: 0.1456
2024-05-24 21:01:37 [INFO]: Epoch 031 - training loss: 0.3055, validation loss: 0.1436
2024-05-24 21:01:38 [INFO]: Epoch 032 - training loss: 0.3032, validation loss: 0.1414
2024-05-24 21:01:38 [INFO]: Epoch 033 - training loss: 0.3012, validation loss: 0.1406
2024-05-24 21:01:39 [INFO]: Epoch 034 - training loss: 0.2979, validation loss: 0.1381
2024-05-24 21:01:40 [INFO]: Epoch 035 - training loss: 0.2947, validation loss: 0.1386
2024-05-24 21:01:40 [INFO]: Epoch 036 - training loss: 0.2927, validation loss: 0.1364
2024-05-24 21:01:41 [INFO]: Epoch 037 - training loss: 0.2914, validation loss: 0.1353
2024-05-24 21:01:41 [INFO]: Epoch 038 - training loss: 0.2910, validation loss: 0.1344
2024-05-24 21:01:42 [INFO]: Epoch 039 - training loss: 0.2880, validation loss: 0.1318
2024-05-24 21:01:43 [INFO]: Epoch 040 - training loss: 0.2851, validation loss: 0.1313
2024-05-24 21:01:43 [INFO]: Epoch 041 - training loss: 0.2840, validation loss: 0.1296
2024-05-24 21:01:44 [INFO]: Epoch 042 - training loss: 0.2822, validation loss: 0.1285
2024-05-24 21:01:44 [INFO]: Epoch 043 - training loss: 0.2807, validation loss: 0.1285
2024-05-24 21:01:45 [INFO]: Epoch 044 - training loss: 0.2792, validation loss: 0.1274
2024-05-24 21:01:46 [INFO]: Epoch 045 - training loss: 0.2771, validation loss: 0.1252
2024-05-24 21:01:46 [INFO]: Epoch 046 - training loss: 0.2748, validation loss: 0.1245
2024-05-24 21:01:47 [INFO]: Epoch 047 - training loss: 0.2719, validation loss: 0.1237
2024-05-24 21:01:47 [INFO]: Epoch 048 - training loss: 0.2720, validation loss: 0.1230
2024-05-24 21:01:48 [INFO]: Epoch 049 - training loss: 0.2699, validation loss: 0.1223
2024-05-24 21:01:49 [INFO]: Epoch 050 - training loss: 0.2681, validation loss: 0.1211
2024-05-24 21:01:49 [INFO]: Epoch 051 - training loss: 0.2674, validation loss: 0.1210
2024-05-24 21:01:50 [INFO]: Epoch 052 - training loss: 0.2683, validation loss: 0.1196
2024-05-24 21:01:50 [INFO]: Epoch 053 - training loss: 0.2644, validation loss: 0.1177
2024-05-24 21:01:51 [INFO]: Epoch 054 - training loss: 0.2620, validation loss: 0.1187
2024-05-24 21:01:52 [INFO]: Epoch 055 - training loss: 0.2612, validation loss: 0.1177
2024-05-24 21:01:52 [INFO]: Epoch 056 - training loss: 0.2589, validation loss: 0.1160
2024-05-24 21:01:53 [INFO]: Epoch 057 - training loss: 0.2584, validation loss: 0.1155
2024-05-24 21:01:53 [INFO]: Epoch 058 - training loss: 0.2568, validation loss: 0.1142
2024-05-24 21:01:54 [INFO]: Epoch 059 - training loss: 0.2552, validation loss: 0.1136
2024-05-24 21:01:55 [INFO]: Epoch 060 - training loss: 0.2535, validation loss: 0.1143
2024-05-24 21:01:55 [INFO]: Epoch 061 - training loss: 0.2525, validation loss: 0.1133
2024-05-24 21:01:56 [INFO]: Epoch 062 - training loss: 0.2503, validation loss: 0.1132
2024-05-24 21:01:56 [INFO]: Epoch 063 - training loss: 0.2495, validation loss: 0.1121
2024-05-24 21:01:57 [INFO]: Epoch 064 - training loss: 0.2489, validation loss: 0.1122
2024-05-24 21:01:58 [INFO]: Epoch 065 - training loss: 0.2484, validation loss: 0.1107
2024-05-24 21:01:58 [INFO]: Epoch 066 - training loss: 0.2458, validation loss: 0.1110
2024-05-24 21:01:59 [INFO]: Epoch 067 - training loss: 0.2448, validation loss: 0.1094
2024-05-24 21:01:59 [INFO]: Epoch 068 - training loss: 0.2429, validation loss: 0.1093
2024-05-24 21:02:00 [INFO]: Epoch 069 - training loss: 0.2419, validation loss: 0.1073
2024-05-24 21:02:01 [INFO]: Epoch 070 - training loss: 0.2406, validation loss: 0.1087
2024-05-24 21:02:01 [INFO]: Epoch 071 - training loss: 0.2396, validation loss: 0.1074
2024-05-24 21:02:02 [INFO]: Epoch 072 - training loss: 0.2391, validation loss: 0.1076
2024-05-24 21:02:02 [INFO]: Epoch 073 - training loss: 0.2386, validation loss: 0.1082
2024-05-24 21:02:03 [INFO]: Epoch 074 - training loss: 0.2356, validation loss: 0.1070
2024-05-24 21:02:04 [INFO]: Epoch 075 - training loss: 0.2350, validation loss: 0.1075
2024-05-24 21:02:04 [INFO]: Epoch 076 - training loss: 0.2345, validation loss: 0.1057
2024-05-24 21:02:05 [INFO]: Epoch 077 - training loss: 0.2325, validation loss: 0.1066
2024-05-24 21:02:05 [INFO]: Epoch 078 - training loss: 0.2319, validation loss: 0.1051
2024-05-24 21:02:06 [INFO]: Epoch 079 - training loss: 0.2303, validation loss: 0.1062
2024-05-24 21:02:07 [INFO]: Epoch 080 - training loss: 0.2302, validation loss: 0.1052
2024-05-24 21:02:07 [INFO]: Epoch 081 - training loss: 0.2293, validation loss: 0.1050
2024-05-24 21:02:08 [INFO]: Epoch 082 - training loss: 0.2270, validation loss: 0.1045
2024-05-24 21:02:08 [INFO]: Epoch 083 - training loss: 0.2266, validation loss: 0.1044
2024-05-24 21:02:09 [INFO]: Epoch 084 - training loss: 0.2256, validation loss: 0.1044
2024-05-24 21:02:10 [INFO]: Epoch 085 - training loss: 0.2256, validation loss: 0.1037
2024-05-24 21:02:10 [INFO]: Epoch 086 - training loss: 0.2244, validation loss: 0.1035
2024-05-24 21:02:11 [INFO]: Epoch 087 - training loss: 0.2237, validation loss: 0.1033
2024-05-24 21:02:11 [INFO]: Epoch 088 - training loss: 0.2221, validation loss: 0.1033
2024-05-24 21:02:12 [INFO]: Epoch 089 - training loss: 0.2208, validation loss: 0.1016
2024-05-24 21:02:13 [INFO]: Epoch 090 - training loss: 0.2202, validation loss: 0.1023
2024-05-24 21:02:13 [INFO]: Epoch 091 - training loss: 0.2202, validation loss: 0.1023
2024-05-24 21:02:14 [INFO]: Epoch 092 - training loss: 0.2192, validation loss: 0.1023
2024-05-24 21:02:14 [INFO]: Epoch 093 - training loss: 0.2191, validation loss: 0.1013
2024-05-24 21:02:15 [INFO]: Epoch 094 - training loss: 0.2178, validation loss: 0.1011
2024-05-24 21:02:16 [INFO]: Epoch 095 - training loss: 0.2161, validation loss: 0.1005
2024-05-24 21:02:16 [INFO]: Epoch 096 - training loss: 0.2175, validation loss: 0.1042
2024-05-24 21:02:17 [INFO]: Epoch 097 - training loss: 0.2184, validation loss: 0.1012
2024-05-24 21:02:17 [INFO]: Epoch 098 - training loss: 0.2157, validation loss: 0.1012
2024-05-24 21:02:18 [INFO]: Epoch 099 - training loss: 0.2145, validation loss: 0.1002
2024-05-24 21:02:18 [INFO]: Epoch 100 - training loss: 0.2124, validation loss: 0.0992
2024-05-24 21:02:19 [INFO]: Epoch 101 - training loss: 0.2126, validation loss: 0.1004
2024-05-24 21:02:20 [INFO]: Epoch 102 - training loss: 0.2125, validation loss: 0.0988
2024-05-24 21:02:20 [INFO]: Epoch 103 - training loss: 0.2111, validation loss: 0.0991
2024-05-24 21:02:21 [INFO]: Epoch 104 - training loss: 0.2099, validation loss: 0.0996
2024-05-24 21:02:21 [INFO]: Epoch 105 - training loss: 0.2091, validation loss: 0.0987
2024-05-24 21:02:22 [INFO]: Epoch 106 - training loss: 0.2084, validation loss: 0.0992
2024-05-24 21:02:23 [INFO]: Epoch 107 - training loss: 0.2087, validation loss: 0.0982
2024-05-24 21:02:23 [INFO]: Epoch 108 - training loss: 0.2088, validation loss: 0.0984
2024-05-24 21:02:24 [INFO]: Epoch 109 - training loss: 0.2073, validation loss: 0.0984
2024-05-24 21:02:24 [INFO]: Epoch 110 - training loss: 0.2069, validation loss: 0.0977
2024-05-24 21:02:25 [INFO]: Epoch 111 - training loss: 0.2064, validation loss: 0.0984
2024-05-24 21:02:26 [INFO]: Epoch 112 - training loss: 0.2055, validation loss: 0.0972
2024-05-24 21:02:26 [INFO]: Epoch 113 - training loss: 0.2047, validation loss: 0.0969
2024-05-24 21:02:27 [INFO]: Epoch 114 - training loss: 0.2040, validation loss: 0.0980
2024-05-24 21:02:27 [INFO]: Epoch 115 - training loss: 0.2035, validation loss: 0.0964
2024-05-24 21:02:28 [INFO]: Epoch 116 - training loss: 0.2029, validation loss: 0.0979
2024-05-24 21:02:29 [INFO]: Epoch 117 - training loss: 0.2029, validation loss: 0.0962
2024-05-24 21:02:29 [INFO]: Epoch 118 - training loss: 0.2031, validation loss: 0.0965
2024-05-24 21:02:30 [INFO]: Epoch 119 - training loss: 0.2035, validation loss: 0.0970
2024-05-24 21:02:30 [INFO]: Epoch 120 - training loss: 0.2015, validation loss: 0.0969
2024-05-24 21:02:31 [INFO]: Epoch 121 - training loss: 0.2004, validation loss: 0.0954
2024-05-24 21:02:32 [INFO]: Epoch 122 - training loss: 0.1993, validation loss: 0.0961
2024-05-24 21:02:32 [INFO]: Epoch 123 - training loss: 0.1991, validation loss: 0.0967
2024-05-24 21:02:33 [INFO]: Epoch 124 - training loss: 0.1985, validation loss: 0.0959
2024-05-24 21:02:33 [INFO]: Epoch 125 - training loss: 0.1977, validation loss: 0.0964
2024-05-24 21:02:34 [INFO]: Epoch 126 - training loss: 0.1974, validation loss: 0.0951
2024-05-24 21:02:35 [INFO]: Epoch 127 - training loss: 0.1979, validation loss: 0.0959
2024-05-24 21:02:35 [INFO]: Epoch 128 - training loss: 0.1959, validation loss: 0.0957
2024-05-24 21:02:36 [INFO]: Epoch 129 - training loss: 0.1959, validation loss: 0.0944
2024-05-24 21:02:36 [INFO]: Epoch 130 - training loss: 0.1977, validation loss: 0.0946
2024-05-24 21:02:37 [INFO]: Epoch 131 - training loss: 0.1956, validation loss: 0.0945
2024-05-24 21:02:38 [INFO]: Epoch 132 - training loss: 0.1945, validation loss: 0.0943
2024-05-24 21:02:38 [INFO]: Epoch 133 - training loss: 0.1940, validation loss: 0.0943
2024-05-24 21:02:39 [INFO]: Epoch 134 - training loss: 0.1939, validation loss: 0.0937
2024-05-24 21:02:39 [INFO]: Epoch 135 - training loss: 0.1927, validation loss: 0.0952
2024-05-24 21:02:40 [INFO]: Epoch 136 - training loss: 0.1922, validation loss: 0.0934
2024-05-24 21:02:41 [INFO]: Epoch 137 - training loss: 0.1920, validation loss: 0.0939
2024-05-24 21:02:41 [INFO]: Epoch 138 - training loss: 0.1921, validation loss: 0.0926
2024-05-24 21:02:42 [INFO]: Epoch 139 - training loss: 0.1912, validation loss: 0.0937
2024-05-24 21:02:42 [INFO]: Epoch 140 - training loss: 0.1913, validation loss: 0.0935
2024-05-24 21:02:43 [INFO]: Epoch 141 - training loss: 0.1912, validation loss: 0.0935
2024-05-24 21:02:44 [INFO]: Epoch 142 - training loss: 0.1915, validation loss: 0.0928
2024-05-24 21:02:44 [INFO]: Epoch 143 - training loss: 0.1906, validation loss: 0.0940
2024-05-24 21:02:45 [INFO]: Epoch 144 - training loss: 0.1905, validation loss: 0.0931
2024-05-24 21:02:45 [INFO]: Epoch 145 - training loss: 0.1894, validation loss: 0.0929
2024-05-24 21:02:46 [INFO]: Epoch 146 - training loss: 0.1888, validation loss: 0.0930
2024-05-24 21:02:47 [INFO]: Epoch 147 - training loss: 0.1879, validation loss: 0.0926
2024-05-24 21:02:47 [INFO]: Epoch 148 - training loss: 0.1869, validation loss: 0.0922
2024-05-24 21:02:48 [INFO]: Epoch 149 - training loss: 0.1875, validation loss: 0.0928
2024-05-24 21:02:48 [INFO]: Epoch 150 - training loss: 0.1865, validation loss: 0.0920
2024-05-24 21:02:49 [INFO]: Epoch 151 - training loss: 0.1861, validation loss: 0.0934
2024-05-24 21:02:50 [INFO]: Epoch 152 - training loss: 0.1847, validation loss: 0.0924
2024-05-24 21:02:50 [INFO]: Epoch 153 - training loss: 0.1852, validation loss: 0.0928
2024-05-24 21:02:51 [INFO]: Epoch 154 - training loss: 0.1849, validation loss: 0.0913
2024-05-24 21:02:51 [INFO]: Epoch 155 - training loss: 0.1844, validation loss: 0.0906
2024-05-24 21:02:52 [INFO]: Epoch 156 - training loss: 0.1841, validation loss: 0.0913
2024-05-24 21:02:53 [INFO]: Epoch 157 - training loss: 0.1832, validation loss: 0.0911
2024-05-24 21:02:53 [INFO]: Epoch 158 - training loss: 0.1835, validation loss: 0.0919
2024-05-24 21:02:54 [INFO]: Epoch 159 - training loss: 0.1829, validation loss: 0.0912
2024-05-24 21:02:54 [INFO]: Epoch 160 - training loss: 0.1825, validation loss: 0.0910
2024-05-24 21:02:55 [INFO]: Epoch 161 - training loss: 0.1836, validation loss: 0.0906
2024-05-24 21:02:56 [INFO]: Epoch 162 - training loss: 0.1844, validation loss: 0.0921
2024-05-24 21:02:56 [INFO]: Epoch 163 - training loss: 0.1831, validation loss: 0.0916
2024-05-24 21:02:57 [INFO]: Epoch 164 - training loss: 0.1827, validation loss: 0.0914
2024-05-24 21:02:57 [INFO]: Epoch 165 - training loss: 0.1808, validation loss: 0.0905
2024-05-24 21:02:58 [INFO]: Epoch 166 - training loss: 0.1800, validation loss: 0.0918
2024-05-24 21:02:58 [INFO]: Epoch 167 - training loss: 0.1801, validation loss: 0.0918
2024-05-24 21:02:59 [INFO]: Epoch 168 - training loss: 0.1794, validation loss: 0.0894
2024-05-24 21:03:00 [INFO]: Epoch 169 - training loss: 0.1796, validation loss: 0.0904
2024-05-24 21:03:00 [INFO]: Epoch 170 - training loss: 0.1788, validation loss: 0.0903
2024-05-24 21:03:01 [INFO]: Epoch 171 - training loss: 0.1785, validation loss: 0.0906
2024-05-24 21:03:01 [INFO]: Epoch 172 - training loss: 0.1775, validation loss: 0.0893
2024-05-24 21:03:02 [INFO]: Epoch 173 - training loss: 0.1774, validation loss: 0.0916
2024-05-24 21:03:03 [INFO]: Epoch 174 - training loss: 0.1773, validation loss: 0.0897
2024-05-24 21:03:03 [INFO]: Epoch 175 - training loss: 0.1765, validation loss: 0.0904
2024-05-24 21:03:04 [INFO]: Epoch 176 - training loss: 0.1759, validation loss: 0.0906
2024-05-24 21:03:04 [INFO]: Epoch 177 - training loss: 0.1765, validation loss: 0.0905
2024-05-24 21:03:05 [INFO]: Epoch 178 - training loss: 0.1765, validation loss: 0.0895
2024-05-24 21:03:06 [INFO]: Epoch 179 - training loss: 0.1760, validation loss: 0.0893
2024-05-24 21:03:06 [INFO]: Epoch 180 - training loss: 0.1749, validation loss: 0.0897
2024-05-24 21:03:07 [INFO]: Epoch 181 - training loss: 0.1751, validation loss: 0.0881
2024-05-24 21:03:07 [INFO]: Epoch 182 - training loss: 0.1758, validation loss: 0.0904
2024-05-24 21:03:08 [INFO]: Epoch 183 - training loss: 0.1743, validation loss: 0.0885
2024-05-24 21:03:09 [INFO]: Epoch 184 - training loss: 0.1741, validation loss: 0.0895
2024-05-24 21:03:09 [INFO]: Epoch 185 - training loss: 0.1737, validation loss: 0.0884
2024-05-24 21:03:10 [INFO]: Epoch 186 - training loss: 0.1744, validation loss: 0.0902
2024-05-24 21:03:10 [INFO]: Epoch 187 - training loss: 0.1739, validation loss: 0.0897
2024-05-24 21:03:11 [INFO]: Epoch 188 - training loss: 0.1725, validation loss: 0.0884
2024-05-24 21:03:12 [INFO]: Epoch 189 - training loss: 0.1718, validation loss: 0.0885
2024-05-24 21:03:12 [INFO]: Epoch 190 - training loss: 0.1711, validation loss: 0.0883
2024-05-24 21:03:13 [INFO]: Epoch 191 - training loss: 0.1713, validation loss: 0.0869
2024-05-24 21:03:13 [INFO]: Epoch 192 - training loss: 0.1706, validation loss: 0.0886
2024-05-24 21:03:14 [INFO]: Epoch 193 - training loss: 0.1704, validation loss: 0.0879
2024-05-24 21:03:15 [INFO]: Epoch 194 - training loss: 0.1708, validation loss: 0.0882
2024-05-24 21:03:15 [INFO]: Epoch 195 - training loss: 0.1709, validation loss: 0.0892
2024-05-24 21:03:16 [INFO]: Epoch 196 - training loss: 0.1707, validation loss: 0.0890
2024-05-24 21:03:16 [INFO]: Epoch 197 - training loss: 0.1702, validation loss: 0.0876
2024-05-24 21:03:17 [INFO]: Epoch 198 - training loss: 0.1708, validation loss: 0.0875
2024-05-24 21:03:18 [INFO]: Epoch 199 - training loss: 0.1696, validation loss: 0.0869
2024-05-24 21:03:18 [INFO]: Epoch 200 - training loss: 0.1702, validation loss: 0.0873
2024-05-24 21:03:19 [INFO]: Epoch 201 - training loss: 0.1693, validation loss: 0.0882
2024-05-24 21:03:19 [INFO]: Epoch 202 - training loss: 0.1694, validation loss: 0.0879
2024-05-24 21:03:20 [INFO]: Epoch 203 - training loss: 0.1683, validation loss: 0.0884
2024-05-24 21:03:21 [INFO]: Epoch 204 - training loss: 0.1674, validation loss: 0.0876
2024-05-24 21:03:21 [INFO]: Epoch 205 - training loss: 0.1680, validation loss: 0.0887
2024-05-24 21:03:22 [INFO]: Epoch 206 - training loss: 0.1689, validation loss: 0.0877
2024-05-24 21:03:22 [INFO]: Epoch 207 - training loss: 0.1686, validation loss: 0.0879
2024-05-24 21:03:23 [INFO]: Epoch 208 - training loss: 0.1665, validation loss: 0.0885
2024-05-24 21:03:24 [INFO]: Epoch 209 - training loss: 0.1676, validation loss: 0.0886
2024-05-24 21:03:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:03:24 [INFO]: Finished training. The best model is from epoch#199.
2024-05-24 21:03:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240524_T210109/SAITS.pypots
2024-05-24 21:03:24 [INFO]: SAITS on Air-Quality: MAE=0.1477, MSE=0.0994
2024-05-24 21:03:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-24 21:03:24 [INFO]: Using the given device: cuda:0
2024-05-24 21:03:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240524_T210324
2024-05-24 21:03:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240524_T210324/tensorboard
2024-05-24 21:03:24 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 21:03:24 [INFO]: Epoch 001 - training loss: 0.8828, validation loss: 0.4413
2024-05-24 21:03:24 [INFO]: Epoch 002 - training loss: 0.5459, validation loss: 0.3099
2024-05-24 21:03:25 [INFO]: Epoch 003 - training loss: 0.4531, validation loss: 0.2613
2024-05-24 21:03:25 [INFO]: Epoch 004 - training loss: 0.4081, validation loss: 0.2399
2024-05-24 21:03:25 [INFO]: Epoch 005 - training loss: 0.3785, validation loss: 0.2236
2024-05-24 21:03:25 [INFO]: Epoch 006 - training loss: 0.3573, validation loss: 0.2120
2024-05-24 21:03:26 [INFO]: Epoch 007 - training loss: 0.3416, validation loss: 0.2065
2024-05-24 21:03:26 [INFO]: Epoch 008 - training loss: 0.3297, validation loss: 0.1983
2024-05-24 21:03:26 [INFO]: Epoch 009 - training loss: 0.3203, validation loss: 0.1919
2024-05-24 21:03:26 [INFO]: Epoch 010 - training loss: 0.3130, validation loss: 0.1878
2024-05-24 21:03:27 [INFO]: Epoch 011 - training loss: 0.3051, validation loss: 0.1831
2024-05-24 21:03:27 [INFO]: Epoch 012 - training loss: 0.2984, validation loss: 0.1782
2024-05-24 21:03:27 [INFO]: Epoch 013 - training loss: 0.2944, validation loss: 0.1750
2024-05-24 21:03:27 [INFO]: Epoch 014 - training loss: 0.2899, validation loss: 0.1720
2024-05-24 21:03:28 [INFO]: Epoch 015 - training loss: 0.2856, validation loss: 0.1711
2024-05-24 21:03:28 [INFO]: Epoch 016 - training loss: 0.2813, validation loss: 0.1665
2024-05-24 21:03:28 [INFO]: Epoch 017 - training loss: 0.2755, validation loss: 0.1637
2024-05-24 21:03:28 [INFO]: Epoch 018 - training loss: 0.2746, validation loss: 0.1631
2024-05-24 21:03:29 [INFO]: Epoch 019 - training loss: 0.2701, validation loss: 0.1601
2024-05-24 21:03:29 [INFO]: Epoch 020 - training loss: 0.2675, validation loss: 0.1578
2024-05-24 21:03:29 [INFO]: Epoch 021 - training loss: 0.2628, validation loss: 0.1548
2024-05-24 21:03:29 [INFO]: Epoch 022 - training loss: 0.2616, validation loss: 0.1543
2024-05-24 21:03:30 [INFO]: Epoch 023 - training loss: 0.2583, validation loss: 0.1522
2024-05-24 21:03:30 [INFO]: Epoch 024 - training loss: 0.2542, validation loss: 0.1500
2024-05-24 21:03:30 [INFO]: Epoch 025 - training loss: 0.2506, validation loss: 0.1497
2024-05-24 21:03:30 [INFO]: Epoch 026 - training loss: 0.2502, validation loss: 0.1466
2024-05-24 21:03:31 [INFO]: Epoch 027 - training loss: 0.2474, validation loss: 0.1469
2024-05-24 21:03:31 [INFO]: Epoch 028 - training loss: 0.2434, validation loss: 0.1466
2024-05-24 21:03:31 [INFO]: Epoch 029 - training loss: 0.2414, validation loss: 0.1448
2024-05-24 21:03:31 [INFO]: Epoch 030 - training loss: 0.2394, validation loss: 0.1419
2024-05-24 21:03:32 [INFO]: Epoch 031 - training loss: 0.2372, validation loss: 0.1433
2024-05-24 21:03:32 [INFO]: Epoch 032 - training loss: 0.2386, validation loss: 0.1423
2024-05-24 21:03:32 [INFO]: Epoch 033 - training loss: 0.2367, validation loss: 0.1421
2024-05-24 21:03:32 [INFO]: Epoch 034 - training loss: 0.2350, validation loss: 0.1415
2024-05-24 21:03:33 [INFO]: Epoch 035 - training loss: 0.2298, validation loss: 0.1406
2024-05-24 21:03:33 [INFO]: Epoch 036 - training loss: 0.2271, validation loss: 0.1381
2024-05-24 21:03:33 [INFO]: Epoch 037 - training loss: 0.2265, validation loss: 0.1390
2024-05-24 21:03:33 [INFO]: Epoch 038 - training loss: 0.2253, validation loss: 0.1374
2024-05-24 21:03:34 [INFO]: Epoch 039 - training loss: 0.2228, validation loss: 0.1365
2024-05-24 21:03:34 [INFO]: Epoch 040 - training loss: 0.2211, validation loss: 0.1371
2024-05-24 21:03:34 [INFO]: Epoch 041 - training loss: 0.2203, validation loss: 0.1360
2024-05-24 21:03:34 [INFO]: Epoch 042 - training loss: 0.2195, validation loss: 0.1363
2024-05-24 21:03:35 [INFO]: Epoch 043 - training loss: 0.2180, validation loss: 0.1349
2024-05-24 21:03:35 [INFO]: Epoch 044 - training loss: 0.2169, validation loss: 0.1348
2024-05-24 21:03:35 [INFO]: Epoch 045 - training loss: 0.2161, validation loss: 0.1335
2024-05-24 21:03:35 [INFO]: Epoch 046 - training loss: 0.2129, validation loss: 0.1333
2024-05-24 21:03:36 [INFO]: Epoch 047 - training loss: 0.2128, validation loss: 0.1315
2024-05-24 21:03:36 [INFO]: Epoch 048 - training loss: 0.2109, validation loss: 0.1335
2024-05-24 21:03:36 [INFO]: Epoch 049 - training loss: 0.2101, validation loss: 0.1308
2024-05-24 21:03:36 [INFO]: Epoch 050 - training loss: 0.2071, validation loss: 0.1304
2024-05-24 21:03:37 [INFO]: Epoch 051 - training loss: 0.2059, validation loss: 0.1302
2024-05-24 21:03:37 [INFO]: Epoch 052 - training loss: 0.2054, validation loss: 0.1314
2024-05-24 21:03:37 [INFO]: Epoch 053 - training loss: 0.2041, validation loss: 0.1306
2024-05-24 21:03:37 [INFO]: Epoch 054 - training loss: 0.2053, validation loss: 0.1294
2024-05-24 21:03:37 [INFO]: Epoch 055 - training loss: 0.2041, validation loss: 0.1317
2024-05-24 21:03:38 [INFO]: Epoch 056 - training loss: 0.2021, validation loss: 0.1271
2024-05-24 21:03:38 [INFO]: Epoch 057 - training loss: 0.1989, validation loss: 0.1278
2024-05-24 21:03:38 [INFO]: Epoch 058 - training loss: 0.1976, validation loss: 0.1267
2024-05-24 21:03:38 [INFO]: Epoch 059 - training loss: 0.1963, validation loss: 0.1264
2024-05-24 21:03:39 [INFO]: Epoch 060 - training loss: 0.1955, validation loss: 0.1277
2024-05-24 21:03:39 [INFO]: Epoch 061 - training loss: 0.1941, validation loss: 0.1271
2024-05-24 21:03:39 [INFO]: Epoch 062 - training loss: 0.1924, validation loss: 0.1262
2024-05-24 21:03:39 [INFO]: Epoch 063 - training loss: 0.1914, validation loss: 0.1265
2024-05-24 21:03:40 [INFO]: Epoch 064 - training loss: 0.1905, validation loss: 0.1249
2024-05-24 21:03:40 [INFO]: Epoch 065 - training loss: 0.1918, validation loss: 0.1250
2024-05-24 21:03:40 [INFO]: Epoch 066 - training loss: 0.1899, validation loss: 0.1246
2024-05-24 21:03:40 [INFO]: Epoch 067 - training loss: 0.1911, validation loss: 0.1252
2024-05-24 21:03:41 [INFO]: Epoch 068 - training loss: 0.1892, validation loss: 0.1229
2024-05-24 21:03:41 [INFO]: Epoch 069 - training loss: 0.1884, validation loss: 0.1222
2024-05-24 21:03:41 [INFO]: Epoch 070 - training loss: 0.1870, validation loss: 0.1231
2024-05-24 21:03:41 [INFO]: Epoch 071 - training loss: 0.1880, validation loss: 0.1216
2024-05-24 21:03:42 [INFO]: Epoch 072 - training loss: 0.1861, validation loss: 0.1231
2024-05-24 21:03:42 [INFO]: Epoch 073 - training loss: 0.1844, validation loss: 0.1237
2024-05-24 21:03:42 [INFO]: Epoch 074 - training loss: 0.1828, validation loss: 0.1223
2024-05-24 21:03:42 [INFO]: Epoch 075 - training loss: 0.1815, validation loss: 0.1233
2024-05-24 21:03:43 [INFO]: Epoch 076 - training loss: 0.1804, validation loss: 0.1198
2024-05-24 21:03:43 [INFO]: Epoch 077 - training loss: 0.1795, validation loss: 0.1214
2024-05-24 21:03:43 [INFO]: Epoch 078 - training loss: 0.1813, validation loss: 0.1220
2024-05-24 21:03:43 [INFO]: Epoch 079 - training loss: 0.1812, validation loss: 0.1210
2024-05-24 21:03:44 [INFO]: Epoch 080 - training loss: 0.1808, validation loss: 0.1204
2024-05-24 21:03:44 [INFO]: Epoch 081 - training loss: 0.1771, validation loss: 0.1209
2024-05-24 21:03:44 [INFO]: Epoch 082 - training loss: 0.1767, validation loss: 0.1190
2024-05-24 21:03:44 [INFO]: Epoch 083 - training loss: 0.1767, validation loss: 0.1222
2024-05-24 21:03:45 [INFO]: Epoch 084 - training loss: 0.1749, validation loss: 0.1202
2024-05-24 21:03:45 [INFO]: Epoch 085 - training loss: 0.1730, validation loss: 0.1201
2024-05-24 21:03:45 [INFO]: Epoch 086 - training loss: 0.1733, validation loss: 0.1190
2024-05-24 21:03:45 [INFO]: Epoch 087 - training loss: 0.1741, validation loss: 0.1172
2024-05-24 21:03:46 [INFO]: Epoch 088 - training loss: 0.1719, validation loss: 0.1196
2024-05-24 21:03:46 [INFO]: Epoch 089 - training loss: 0.1708, validation loss: 0.1163
2024-05-24 21:03:46 [INFO]: Epoch 090 - training loss: 0.1694, validation loss: 0.1175
2024-05-24 21:03:46 [INFO]: Epoch 091 - training loss: 0.1698, validation loss: 0.1178
2024-05-24 21:03:47 [INFO]: Epoch 092 - training loss: 0.1698, validation loss: 0.1176
2024-05-24 21:03:47 [INFO]: Epoch 093 - training loss: 0.1700, validation loss: 0.1180
2024-05-24 21:03:47 [INFO]: Epoch 094 - training loss: 0.1678, validation loss: 0.1179
2024-05-24 21:03:47 [INFO]: Epoch 095 - training loss: 0.1677, validation loss: 0.1142
2024-05-24 21:03:48 [INFO]: Epoch 096 - training loss: 0.1710, validation loss: 0.1160
2024-05-24 21:03:48 [INFO]: Epoch 097 - training loss: 0.1685, validation loss: 0.1159
2024-05-24 21:03:48 [INFO]: Epoch 098 - training loss: 0.1655, validation loss: 0.1166
2024-05-24 21:03:48 [INFO]: Epoch 099 - training loss: 0.1653, validation loss: 0.1152
2024-05-24 21:03:49 [INFO]: Epoch 100 - training loss: 0.1645, validation loss: 0.1172
2024-05-24 21:03:49 [INFO]: Epoch 101 - training loss: 0.1632, validation loss: 0.1163
2024-05-24 21:03:49 [INFO]: Epoch 102 - training loss: 0.1625, validation loss: 0.1156
2024-05-24 21:03:49 [INFO]: Epoch 103 - training loss: 0.1620, validation loss: 0.1163
2024-05-24 21:03:50 [INFO]: Epoch 104 - training loss: 0.1599, validation loss: 0.1147
2024-05-24 21:03:50 [INFO]: Epoch 105 - training loss: 0.1595, validation loss: 0.1203
2024-05-24 21:03:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:03:50 [INFO]: Finished training. The best model is from epoch#95.
2024-05-24 21:03:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240524_T210324/Transformer.pypots
2024-05-24 21:03:50 [INFO]: Transformer on Air-Quality: MAE=0.1710, MSE=0.1245
2024-05-24 21:03:50 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-24 21:03:50 [INFO]: Using the given device: cuda:0
2024-05-24 21:03:50 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240524_T210350
2024-05-24 21:03:50 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240524_T210350/tensorboard
2024-05-24 21:03:50 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 21:03:56 [INFO]: Epoch 001 - training loss: 0.3081, validation loss: 0.2595
2024-05-24 21:03:57 [INFO]: Epoch 002 - training loss: 0.2448, validation loss: 0.2223
2024-05-24 21:03:57 [INFO]: Epoch 003 - training loss: 0.1870, validation loss: 0.2092
2024-05-24 21:03:58 [INFO]: Epoch 004 - training loss: 0.1605, validation loss: 0.1945
2024-05-24 21:03:58 [INFO]: Epoch 005 - training loss: 0.1467, validation loss: 0.1934
2024-05-24 21:03:58 [INFO]: Epoch 006 - training loss: 0.1449, validation loss: 0.1881
2024-05-24 21:03:59 [INFO]: Epoch 007 - training loss: 0.1361, validation loss: 0.1912
2024-05-24 21:03:59 [INFO]: Epoch 008 - training loss: 0.1241, validation loss: 0.1822
2024-05-24 21:04:00 [INFO]: Epoch 009 - training loss: 0.1140, validation loss: 0.1798
2024-05-24 21:04:00 [INFO]: Epoch 010 - training loss: 0.1111, validation loss: 0.1805
2024-05-24 21:04:01 [INFO]: Epoch 011 - training loss: 0.1025, validation loss: 0.2020
2024-05-24 21:04:01 [INFO]: Epoch 012 - training loss: 0.0947, validation loss: 0.2040
2024-05-24 21:04:02 [INFO]: Epoch 013 - training loss: 0.0936, validation loss: 0.1933
2024-05-24 21:04:02 [INFO]: Epoch 014 - training loss: 0.0988, validation loss: 0.1686
2024-05-24 21:04:03 [INFO]: Epoch 015 - training loss: 0.1079, validation loss: 0.1726
2024-05-24 21:04:03 [INFO]: Epoch 016 - training loss: 0.0885, validation loss: 0.1731
2024-05-24 21:04:03 [INFO]: Epoch 017 - training loss: 0.0772, validation loss: 0.1814
2024-05-24 21:04:04 [INFO]: Epoch 018 - training loss: 0.0753, validation loss: 0.1559
2024-05-24 21:04:04 [INFO]: Epoch 019 - training loss: 0.0818, validation loss: 0.1820
2024-05-24 21:04:05 [INFO]: Epoch 020 - training loss: 0.0837, validation loss: 0.1668
2024-05-24 21:04:05 [INFO]: Epoch 021 - training loss: 0.0769, validation loss: 0.1581
2024-05-24 21:04:06 [INFO]: Epoch 022 - training loss: 0.0697, validation loss: 0.1690
2024-05-24 21:04:06 [INFO]: Epoch 023 - training loss: 0.0678, validation loss: 0.1587
2024-05-24 21:04:07 [INFO]: Epoch 024 - training loss: 0.0683, validation loss: 0.1620
2024-05-24 21:04:07 [INFO]: Epoch 025 - training loss: 0.0636, validation loss: 0.1564
2024-05-24 21:04:08 [INFO]: Epoch 026 - training loss: 0.0632, validation loss: 0.1629
2024-05-24 21:04:08 [INFO]: Epoch 027 - training loss: 0.0637, validation loss: 0.1563
2024-05-24 21:04:08 [INFO]: Epoch 028 - training loss: 0.0603, validation loss: 0.1609
2024-05-24 21:04:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:04:08 [INFO]: Finished training. The best model is from epoch#18.
2024-05-24 21:04:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240524_T210350/TimesNet.pypots
2024-05-24 21:04:09 [INFO]: TimesNet on Air-Quality: MAE=0.1739, MSE=0.1543
2024-05-24 21:04:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-24 21:04:09 [INFO]: Using the given device: cuda:0
2024-05-24 21:04:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409
2024-05-24 21:04:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/tensorboard
2024-05-24 21:04:09 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-24 21:04:26 [INFO]: Epoch 001 - training loss: 0.5106, validation loss: 0.3525
2024-05-24 21:04:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch1_loss0.3525235325098038.pypots
2024-05-24 21:04:43 [INFO]: Epoch 002 - training loss: 0.3007, validation loss: 0.2651
2024-05-24 21:04:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch2_loss0.26513437628746034.pypots
2024-05-24 21:05:00 [INFO]: Epoch 003 - training loss: 0.2306, validation loss: 0.2244
2024-05-24 21:05:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch3_loss0.22435559928417206.pypots
2024-05-24 21:05:16 [INFO]: Epoch 004 - training loss: 0.2365, validation loss: 0.2011
2024-05-24 21:05:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch4_loss0.2011231541633606.pypots
2024-05-24 21:05:33 [INFO]: Epoch 005 - training loss: 0.1962, validation loss: 0.1770
2024-05-24 21:05:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch5_loss0.17699370682239532.pypots
2024-05-24 21:05:49 [INFO]: Epoch 006 - training loss: 0.1749, validation loss: 0.1710
2024-05-24 21:05:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch6_loss0.17099900990724565.pypots
2024-05-24 21:06:06 [INFO]: Epoch 007 - training loss: 0.1632, validation loss: 0.1659
2024-05-24 21:06:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch7_loss0.16593238115310668.pypots
2024-05-24 21:06:23 [INFO]: Epoch 008 - training loss: 0.1664, validation loss: 0.1613
2024-05-24 21:06:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch8_loss0.16132583171129228.pypots
2024-05-24 21:06:39 [INFO]: Epoch 009 - training loss: 0.1724, validation loss: 0.1612
2024-05-24 21:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch9_loss0.16115860193967818.pypots
2024-05-24 21:06:56 [INFO]: Epoch 010 - training loss: 0.1475, validation loss: 0.1498
2024-05-24 21:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch10_loss0.14975624829530715.pypots
2024-05-24 21:07:13 [INFO]: Epoch 011 - training loss: 0.1475, validation loss: 0.1520
2024-05-24 21:07:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch11_loss0.15199828147888184.pypots
2024-05-24 21:07:29 [INFO]: Epoch 012 - training loss: 0.1602, validation loss: 0.1479
2024-05-24 21:07:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch12_loss0.147896908223629.pypots
2024-05-24 21:07:46 [INFO]: Epoch 013 - training loss: 0.1574, validation loss: 0.1510
2024-05-24 21:07:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch13_loss0.1509658947587013.pypots
2024-05-24 21:08:02 [INFO]: Epoch 014 - training loss: 0.1561, validation loss: 0.1501
2024-05-24 21:08:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch14_loss0.1501109629869461.pypots
2024-05-24 21:08:19 [INFO]: Epoch 015 - training loss: 0.1553, validation loss: 0.1462
2024-05-24 21:08:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch15_loss0.14617260843515395.pypots
2024-05-24 21:08:36 [INFO]: Epoch 016 - training loss: 0.1497, validation loss: 0.1401
2024-05-24 21:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch16_loss0.14005740955471993.pypots
2024-05-24 21:08:52 [INFO]: Epoch 017 - training loss: 0.1725, validation loss: 0.1423
2024-05-24 21:08:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch17_loss0.14227190539240836.pypots
2024-05-24 21:09:09 [INFO]: Epoch 018 - training loss: 0.1502, validation loss: 0.1373
2024-05-24 21:09:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch18_loss0.13725375905632972.pypots
2024-05-24 21:09:26 [INFO]: Epoch 019 - training loss: 0.1479, validation loss: 0.1401
2024-05-24 21:09:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch19_loss0.14007427915930748.pypots
2024-05-24 21:09:42 [INFO]: Epoch 020 - training loss: 0.1363, validation loss: 0.1388
2024-05-24 21:09:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch20_loss0.13877694979310035.pypots
2024-05-24 21:09:59 [INFO]: Epoch 021 - training loss: 0.1379, validation loss: 0.1447
2024-05-24 21:09:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch21_loss0.14469181671738623.pypots
2024-05-24 21:10:16 [INFO]: Epoch 022 - training loss: 0.1472, validation loss: 0.1344
2024-05-24 21:10:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch22_loss0.1344135157763958.pypots
2024-05-24 21:10:32 [INFO]: Epoch 023 - training loss: 0.1440, validation loss: 0.1419
2024-05-24 21:10:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch23_loss0.14193384796380998.pypots
2024-05-24 21:10:49 [INFO]: Epoch 024 - training loss: 0.1501, validation loss: 0.1403
2024-05-24 21:10:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch24_loss0.1403094820678234.pypots
2024-05-24 21:11:05 [INFO]: Epoch 025 - training loss: 0.1313, validation loss: 0.1345
2024-05-24 21:11:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch25_loss0.1345141552388668.pypots
2024-05-24 21:11:22 [INFO]: Epoch 026 - training loss: 0.1350, validation loss: 0.1336
2024-05-24 21:11:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch26_loss0.13363618329167365.pypots
2024-05-24 21:11:39 [INFO]: Epoch 027 - training loss: 0.1480, validation loss: 0.1366
2024-05-24 21:11:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch27_loss0.13663698509335517.pypots
2024-05-24 21:11:55 [INFO]: Epoch 028 - training loss: 0.1466, validation loss: 0.1344
2024-05-24 21:11:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch28_loss0.13437560945749283.pypots
2024-05-24 21:12:12 [INFO]: Epoch 029 - training loss: 0.1265, validation loss: 0.1291
2024-05-24 21:12:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch29_loss0.12905925810337066.pypots
2024-05-24 21:12:29 [INFO]: Epoch 030 - training loss: 0.1254, validation loss: 0.1311
2024-05-24 21:12:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch30_loss0.13113854601979255.pypots
2024-05-24 21:12:45 [INFO]: Epoch 031 - training loss: 0.1264, validation loss: 0.1307
2024-05-24 21:12:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch31_loss0.13070255517959595.pypots
2024-05-24 21:13:02 [INFO]: Epoch 032 - training loss: 0.1318, validation loss: 0.1305
2024-05-24 21:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch32_loss0.13045546114444734.pypots
2024-05-24 21:13:18 [INFO]: Epoch 033 - training loss: 0.1333, validation loss: 0.1273
2024-05-24 21:13:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch33_loss0.12731735557317733.pypots
2024-05-24 21:13:35 [INFO]: Epoch 034 - training loss: 0.1186, validation loss: 0.1268
2024-05-24 21:13:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch34_loss0.12679990157485008.pypots
2024-05-24 21:13:52 [INFO]: Epoch 035 - training loss: 0.1280, validation loss: 0.1261
2024-05-24 21:13:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch35_loss0.1261082924902439.pypots
2024-05-24 21:14:08 [INFO]: Epoch 036 - training loss: 0.1297, validation loss: 0.1266
2024-05-24 21:14:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch36_loss0.12663367316126822.pypots
2024-05-24 21:14:25 [INFO]: Epoch 037 - training loss: 0.1227, validation loss: 0.1260
2024-05-24 21:14:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch37_loss0.12597286850214004.pypots
2024-05-24 21:14:42 [INFO]: Epoch 038 - training loss: 0.1398, validation loss: 0.1256
2024-05-24 21:14:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch38_loss0.12564641386270523.pypots
2024-05-24 21:14:58 [INFO]: Epoch 039 - training loss: 0.1263, validation loss: 0.1265
2024-05-24 21:14:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch39_loss0.12653853073716165.pypots
2024-05-24 21:15:15 [INFO]: Epoch 040 - training loss: 0.1247, validation loss: 0.1226
2024-05-24 21:15:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch40_loss0.12255043163895607.pypots
2024-05-24 21:15:31 [INFO]: Epoch 041 - training loss: 0.1306, validation loss: 0.1264
2024-05-24 21:15:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch41_loss0.12638212889432907.pypots
2024-05-24 21:15:48 [INFO]: Epoch 042 - training loss: 0.1194, validation loss: 0.1244
2024-05-24 21:15:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch42_loss0.12444545850157737.pypots
2024-05-24 21:16:05 [INFO]: Epoch 043 - training loss: 0.1215, validation loss: 0.1229
2024-05-24 21:16:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch43_loss0.12286254987120629.pypots
2024-05-24 21:16:21 [INFO]: Epoch 044 - training loss: 0.1275, validation loss: 0.1222
2024-05-24 21:16:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch44_loss0.12219160422682762.pypots
2024-05-24 21:16:38 [INFO]: Epoch 045 - training loss: 0.1241, validation loss: 0.1239
2024-05-24 21:16:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch45_loss0.12388570383191108.pypots
2024-05-24 21:16:55 [INFO]: Epoch 046 - training loss: 0.1382, validation loss: 0.1237
2024-05-24 21:16:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch46_loss0.12365744933485985.pypots
2024-05-24 21:17:11 [INFO]: Epoch 047 - training loss: 0.1219, validation loss: 0.1240
2024-05-24 21:17:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch47_loss0.12395449802279472.pypots
2024-05-24 21:17:28 [INFO]: Epoch 048 - training loss: 0.1270, validation loss: 0.1216
2024-05-24 21:17:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch48_loss0.12158849760890007.pypots
2024-05-24 21:17:44 [INFO]: Epoch 049 - training loss: 0.1238, validation loss: 0.1208
2024-05-24 21:17:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch49_loss0.12080155462026596.pypots
2024-05-24 21:18:01 [INFO]: Epoch 050 - training loss: 0.1214, validation loss: 0.1224
2024-05-24 21:18:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch50_loss0.12237891629338264.pypots
2024-05-24 21:18:18 [INFO]: Epoch 051 - training loss: 0.1165, validation loss: 0.1240
2024-05-24 21:18:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch51_loss0.1240496277809143.pypots
2024-05-24 21:18:34 [INFO]: Epoch 052 - training loss: 0.1126, validation loss: 0.1202
2024-05-24 21:18:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch52_loss0.12015196904540063.pypots
2024-05-24 21:18:51 [INFO]: Epoch 053 - training loss: 0.1291, validation loss: 0.1207
2024-05-24 21:18:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch53_loss0.1207000769674778.pypots
2024-05-24 21:19:08 [INFO]: Epoch 054 - training loss: 0.1230, validation loss: 0.1182
2024-05-24 21:19:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch54_loss0.11820696964859963.pypots
2024-05-24 21:19:24 [INFO]: Epoch 055 - training loss: 0.1199, validation loss: 0.1193
2024-05-24 21:19:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch55_loss0.1192560389637947.pypots
2024-05-24 21:19:41 [INFO]: Epoch 056 - training loss: 0.1060, validation loss: 0.1181
2024-05-24 21:19:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch56_loss0.11805989518761635.pypots
2024-05-24 21:19:58 [INFO]: Epoch 057 - training loss: 0.1102, validation loss: 0.1196
2024-05-24 21:19:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch57_loss0.11957129538059234.pypots
2024-05-24 21:20:14 [INFO]: Epoch 058 - training loss: 0.1201, validation loss: 0.1193
2024-05-24 21:20:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch58_loss0.11934472247958183.pypots
2024-05-24 21:20:31 [INFO]: Epoch 059 - training loss: 0.1221, validation loss: 0.1188
2024-05-24 21:20:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch59_loss0.11884134188294411.pypots
2024-05-24 21:20:47 [INFO]: Epoch 060 - training loss: 0.1210, validation loss: 0.1163
2024-05-24 21:20:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch60_loss0.11627988591790199.pypots
2024-05-24 21:21:04 [INFO]: Epoch 061 - training loss: 0.1067, validation loss: 0.1185
2024-05-24 21:21:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch61_loss0.11847766935825348.pypots
2024-05-24 21:21:21 [INFO]: Epoch 062 - training loss: 0.1170, validation loss: 0.1172
2024-05-24 21:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch62_loss0.11719014272093772.pypots
2024-05-24 21:21:37 [INFO]: Epoch 063 - training loss: 0.1132, validation loss: 0.1191
2024-05-24 21:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch63_loss0.11913528516888619.pypots
2024-05-24 21:21:54 [INFO]: Epoch 064 - training loss: 0.1051, validation loss: 0.1178
2024-05-24 21:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch64_loss0.11782714426517486.pypots
2024-05-24 21:22:11 [INFO]: Epoch 065 - training loss: 0.1173, validation loss: 0.1173
2024-05-24 21:22:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch65_loss0.11726163700222969.pypots
2024-05-24 21:22:27 [INFO]: Epoch 066 - training loss: 0.1002, validation loss: 0.1175
2024-05-24 21:22:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch66_loss0.11747252494096756.pypots
2024-05-24 21:22:44 [INFO]: Epoch 067 - training loss: 0.1140, validation loss: 0.1162
2024-05-24 21:22:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch67_loss0.11622327491641045.pypots
2024-05-24 21:23:00 [INFO]: Epoch 068 - training loss: 0.1204, validation loss: 0.1170
2024-05-24 21:23:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch68_loss0.11703585907816887.pypots
2024-05-24 21:23:17 [INFO]: Epoch 069 - training loss: 0.1075, validation loss: 0.1136
2024-05-24 21:23:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch69_loss0.11362638995051384.pypots
2024-05-24 21:23:34 [INFO]: Epoch 070 - training loss: 0.1168, validation loss: 0.1145
2024-05-24 21:23:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch70_loss0.11449030563235282.pypots
2024-05-24 21:23:50 [INFO]: Epoch 071 - training loss: 0.1091, validation loss: 0.1166
2024-05-24 21:23:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch71_loss0.11660709381103515.pypots
2024-05-24 21:24:07 [INFO]: Epoch 072 - training loss: 0.1109, validation loss: 0.1141
2024-05-24 21:24:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch72_loss0.11410475000739098.pypots
2024-05-24 21:24:24 [INFO]: Epoch 073 - training loss: 0.1149, validation loss: 0.1144
2024-05-24 21:24:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch73_loss0.1143993891775608.pypots
2024-05-24 21:24:40 [INFO]: Epoch 074 - training loss: 0.1158, validation loss: 0.1163
2024-05-24 21:24:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch74_loss0.11631755530834198.pypots
2024-05-24 21:24:57 [INFO]: Epoch 075 - training loss: 0.1038, validation loss: 0.1123
2024-05-24 21:24:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch75_loss0.1123079501092434.pypots
2024-05-24 21:25:13 [INFO]: Epoch 076 - training loss: 0.1252, validation loss: 0.1168
2024-05-24 21:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch76_loss0.11679521724581718.pypots
2024-05-24 21:25:30 [INFO]: Epoch 077 - training loss: 0.1112, validation loss: 0.1161
2024-05-24 21:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch77_loss0.11610812470316886.pypots
2024-05-24 21:25:47 [INFO]: Epoch 078 - training loss: 0.1038, validation loss: 0.1131
2024-05-24 21:25:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch78_loss0.11309951692819595.pypots
2024-05-24 21:26:03 [INFO]: Epoch 079 - training loss: 0.1133, validation loss: 0.1148
2024-05-24 21:26:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch79_loss0.1148316890001297.pypots
2024-05-24 21:26:20 [INFO]: Epoch 080 - training loss: 0.1192, validation loss: 0.1143
2024-05-24 21:26:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch80_loss0.11428994834423065.pypots
2024-05-24 21:26:37 [INFO]: Epoch 081 - training loss: 0.1048, validation loss: 0.1119
2024-05-24 21:26:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch81_loss0.11186766922473908.pypots
2024-05-24 21:26:53 [INFO]: Epoch 082 - training loss: 0.1105, validation loss: 0.1189
2024-05-24 21:26:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch82_loss0.11894733309745789.pypots
2024-05-24 21:27:10 [INFO]: Epoch 083 - training loss: 0.1166, validation loss: 0.1112
2024-05-24 21:27:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch83_loss0.11121646836400031.pypots
2024-05-24 21:27:26 [INFO]: Epoch 084 - training loss: 0.1198, validation loss: 0.1121
2024-05-24 21:27:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch84_loss0.11214475706219673.pypots
2024-05-24 21:27:43 [INFO]: Epoch 085 - training loss: 0.1034, validation loss: 0.1113
2024-05-24 21:27:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch85_loss0.11128282621502876.pypots
2024-05-24 21:28:00 [INFO]: Epoch 086 - training loss: 0.1000, validation loss: 0.1125
2024-05-24 21:28:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch86_loss0.11254290789365769.pypots
2024-05-24 21:28:16 [INFO]: Epoch 087 - training loss: 0.1092, validation loss: 0.1160
2024-05-24 21:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch87_loss0.11597911193966866.pypots
2024-05-24 21:28:33 [INFO]: Epoch 088 - training loss: 0.1173, validation loss: 0.1114
2024-05-24 21:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch88_loss0.11141589060425758.pypots
2024-05-24 21:28:50 [INFO]: Epoch 089 - training loss: 0.1118, validation loss: 0.1135
2024-05-24 21:28:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch89_loss0.11353119686245919.pypots
2024-05-24 21:29:06 [INFO]: Epoch 090 - training loss: 0.1146, validation loss: 0.1131
2024-05-24 21:29:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch90_loss0.11305903047323226.pypots
2024-05-24 21:29:23 [INFO]: Epoch 091 - training loss: 0.1149, validation loss: 0.1098
2024-05-24 21:29:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch91_loss0.10984600260853768.pypots
2024-05-24 21:29:40 [INFO]: Epoch 092 - training loss: 0.1149, validation loss: 0.1123
2024-05-24 21:29:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch92_loss0.11233218759298325.pypots
2024-05-24 21:29:56 [INFO]: Epoch 093 - training loss: 0.1009, validation loss: 0.1087
2024-05-24 21:29:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch93_loss0.10870943367481231.pypots
2024-05-24 21:30:13 [INFO]: Epoch 094 - training loss: 0.0952, validation loss: 0.1103
2024-05-24 21:30:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch94_loss0.11033621355891228.pypots
2024-05-24 21:30:29 [INFO]: Epoch 095 - training loss: 0.1142, validation loss: 0.1130
2024-05-24 21:30:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch95_loss0.11303140446543694.pypots
2024-05-24 21:30:46 [INFO]: Epoch 096 - training loss: 0.1004, validation loss: 0.1099
2024-05-24 21:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch96_loss0.10985108911991119.pypots
2024-05-24 21:31:03 [INFO]: Epoch 097 - training loss: 0.1029, validation loss: 0.1092
2024-05-24 21:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch97_loss0.10921090468764305.pypots
2024-05-24 21:31:19 [INFO]: Epoch 098 - training loss: 0.1354, validation loss: 0.1157
2024-05-24 21:31:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch98_loss0.11565777733922004.pypots
2024-05-24 21:31:36 [INFO]: Epoch 099 - training loss: 0.1070, validation loss: 0.1094
2024-05-24 21:31:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch99_loss0.10944381728768349.pypots
2024-05-24 21:31:53 [INFO]: Epoch 100 - training loss: 0.1099, validation loss: 0.1110
2024-05-24 21:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch100_loss0.11096837371587753.pypots
2024-05-24 21:32:09 [INFO]: Epoch 101 - training loss: 0.1146, validation loss: 0.1069
2024-05-24 21:32:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch101_loss0.1069426842033863.pypots
2024-05-24 21:32:26 [INFO]: Epoch 102 - training loss: 0.0966, validation loss: 0.1095
2024-05-24 21:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch102_loss0.10949810072779656.pypots
2024-05-24 21:32:42 [INFO]: Epoch 103 - training loss: 0.1158, validation loss: 0.1089
2024-05-24 21:32:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch103_loss0.10885948538780213.pypots
2024-05-24 21:32:59 [INFO]: Epoch 104 - training loss: 0.1147, validation loss: 0.1087
2024-05-24 21:32:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch104_loss0.10871723666787148.pypots
2024-05-24 21:33:16 [INFO]: Epoch 105 - training loss: 0.0983, validation loss: 0.1088
2024-05-24 21:33:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch105_loss0.10880431681871414.pypots
2024-05-24 21:33:32 [INFO]: Epoch 106 - training loss: 0.1107, validation loss: 0.1082
2024-05-24 21:33:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch106_loss0.10816232487559319.pypots
2024-05-24 21:33:49 [INFO]: Epoch 107 - training loss: 0.1150, validation loss: 0.1072
2024-05-24 21:33:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch107_loss0.10723944306373596.pypots
2024-05-24 21:34:06 [INFO]: Epoch 108 - training loss: 0.1026, validation loss: 0.1090
2024-05-24 21:34:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch108_loss0.10902641490101814.pypots
2024-05-24 21:34:22 [INFO]: Epoch 109 - training loss: 0.1128, validation loss: 0.1094
2024-05-24 21:34:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch109_loss0.10940354466438293.pypots
2024-05-24 21:34:39 [INFO]: Epoch 110 - training loss: 0.1097, validation loss: 0.1080
2024-05-24 21:34:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch110_loss0.1079897090792656.pypots
2024-05-24 21:34:55 [INFO]: Epoch 111 - training loss: 0.1099, validation loss: 0.1058
2024-05-24 21:34:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch111_loss0.10579015463590621.pypots
2024-05-24 21:35:12 [INFO]: Epoch 112 - training loss: 0.1065, validation loss: 0.1077
2024-05-24 21:35:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch112_loss0.10774672403931618.pypots
2024-05-24 21:35:29 [INFO]: Epoch 113 - training loss: 0.1001, validation loss: 0.1084
2024-05-24 21:35:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch113_loss0.10843575820326805.pypots
2024-05-24 21:35:45 [INFO]: Epoch 114 - training loss: 0.1027, validation loss: 0.1090
2024-05-24 21:35:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch114_loss0.10897794961929322.pypots
2024-05-24 21:36:02 [INFO]: Epoch 115 - training loss: 0.1002, validation loss: 0.1054
2024-05-24 21:36:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch115_loss0.10538186728954316.pypots
2024-05-24 21:36:19 [INFO]: Epoch 116 - training loss: 0.1048, validation loss: 0.1085
2024-05-24 21:36:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch116_loss0.10850897282361985.pypots
2024-05-24 21:36:35 [INFO]: Epoch 117 - training loss: 0.1058, validation loss: 0.1052
2024-05-24 21:36:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch117_loss0.10517491847276687.pypots
2024-05-24 21:36:52 [INFO]: Epoch 118 - training loss: 0.1106, validation loss: 0.1069
2024-05-24 21:36:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch118_loss0.10689020305871963.pypots
2024-05-24 21:37:09 [INFO]: Epoch 119 - training loss: 0.1126, validation loss: 0.1043
2024-05-24 21:37:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch119_loss0.10430903807282448.pypots
2024-05-24 21:37:25 [INFO]: Epoch 120 - training loss: 0.1088, validation loss: 0.1047
2024-05-24 21:37:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch120_loss0.10470813438296318.pypots
2024-05-24 21:37:42 [INFO]: Epoch 121 - training loss: 0.1065, validation loss: 0.1060
2024-05-24 21:37:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch121_loss0.10596872344613076.pypots
2024-05-24 21:37:58 [INFO]: Epoch 122 - training loss: 0.1038, validation loss: 0.1049
2024-05-24 21:37:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch122_loss0.10491234809160233.pypots
2024-05-24 21:38:15 [INFO]: Epoch 123 - training loss: 0.0964, validation loss: 0.1064
2024-05-24 21:38:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch123_loss0.1063992515206337.pypots
2024-05-24 21:38:32 [INFO]: Epoch 124 - training loss: 0.1070, validation loss: 0.1124
2024-05-24 21:38:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch124_loss0.11240541636943817.pypots
2024-05-24 21:38:48 [INFO]: Epoch 125 - training loss: 0.1125, validation loss: 0.1046
2024-05-24 21:38:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch125_loss0.10462147742509842.pypots
2024-05-24 21:39:05 [INFO]: Epoch 126 - training loss: 0.1197, validation loss: 0.1041
2024-05-24 21:39:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch126_loss0.1041203074157238.pypots
2024-05-24 21:39:22 [INFO]: Epoch 127 - training loss: 0.1109, validation loss: 0.1078
2024-05-24 21:39:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch127_loss0.10779722779989243.pypots
2024-05-24 21:39:38 [INFO]: Epoch 128 - training loss: 0.1049, validation loss: 0.1056
2024-05-24 21:39:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch128_loss0.10560529008507728.pypots
2024-05-24 21:39:55 [INFO]: Epoch 129 - training loss: 0.1060, validation loss: 0.1070
2024-05-24 21:39:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch129_loss0.10695087760686875.pypots
2024-05-24 21:40:11 [INFO]: Epoch 130 - training loss: 0.0977, validation loss: 0.1035
2024-05-24 21:40:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch130_loss0.10352372825145721.pypots
2024-05-24 21:40:28 [INFO]: Epoch 131 - training loss: 0.0980, validation loss: 0.1081
2024-05-24 21:40:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch131_loss0.10814346298575402.pypots
2024-05-24 21:40:45 [INFO]: Epoch 132 - training loss: 0.1031, validation loss: 0.1034
2024-05-24 21:40:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch132_loss0.10338075757026673.pypots
2024-05-24 21:41:01 [INFO]: Epoch 133 - training loss: 0.1114, validation loss: 0.1073
2024-05-24 21:41:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch133_loss0.10734876692295074.pypots
2024-05-24 21:41:18 [INFO]: Epoch 134 - training loss: 0.1119, validation loss: 0.1071
2024-05-24 21:41:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch134_loss0.10708951652050018.pypots
2024-05-24 21:41:35 [INFO]: Epoch 135 - training loss: 0.1052, validation loss: 0.1045
2024-05-24 21:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch135_loss0.10453474074602127.pypots
2024-05-24 21:41:51 [INFO]: Epoch 136 - training loss: 0.0890, validation loss: 0.1032
2024-05-24 21:41:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch136_loss0.10323920175433159.pypots
2024-05-24 21:42:08 [INFO]: Epoch 137 - training loss: 0.0977, validation loss: 0.1037
2024-05-24 21:42:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch137_loss0.10368601381778716.pypots
2024-05-24 21:42:24 [INFO]: Epoch 138 - training loss: 0.0963, validation loss: 0.1039
2024-05-24 21:42:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch138_loss0.10390913113951683.pypots
2024-05-24 21:42:41 [INFO]: Epoch 139 - training loss: 0.1044, validation loss: 0.1042
2024-05-24 21:42:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch139_loss0.10420799553394318.pypots
2024-05-24 21:42:58 [INFO]: Epoch 140 - training loss: 0.0940, validation loss: 0.1057
2024-05-24 21:42:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch140_loss0.10573938935995102.pypots
2024-05-24 21:43:14 [INFO]: Epoch 141 - training loss: 0.1019, validation loss: 0.1042
2024-05-24 21:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch141_loss0.10418806597590446.pypots
2024-05-24 21:43:31 [INFO]: Epoch 142 - training loss: 0.1116, validation loss: 0.1034
2024-05-24 21:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch142_loss0.10337686613202095.pypots
2024-05-24 21:43:48 [INFO]: Epoch 143 - training loss: 0.1071, validation loss: 0.1026
2024-05-24 21:43:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch143_loss0.10264011472463608.pypots
2024-05-24 21:44:04 [INFO]: Epoch 144 - training loss: 0.0961, validation loss: 0.1036
2024-05-24 21:44:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch144_loss0.10356678217649459.pypots
2024-05-24 21:44:21 [INFO]: Epoch 145 - training loss: 0.1042, validation loss: 0.1036
2024-05-24 21:44:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch145_loss0.10357862636446953.pypots
2024-05-24 21:44:38 [INFO]: Epoch 146 - training loss: 0.1096, validation loss: 0.1034
2024-05-24 21:44:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch146_loss0.10338979810476304.pypots
2024-05-24 21:44:54 [INFO]: Epoch 147 - training loss: 0.0948, validation loss: 0.1019
2024-05-24 21:44:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch147_loss0.10189886614680291.pypots
2024-05-24 21:45:11 [INFO]: Epoch 148 - training loss: 0.1074, validation loss: 0.1037
2024-05-24 21:45:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch148_loss0.10367467030882835.pypots
2024-05-24 21:45:27 [INFO]: Epoch 149 - training loss: 0.0981, validation loss: 0.1034
2024-05-24 21:45:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch149_loss0.10344623401761055.pypots
2024-05-24 21:45:44 [INFO]: Epoch 150 - training loss: 0.0974, validation loss: 0.1068
2024-05-24 21:45:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch150_loss0.10682650431990623.pypots
2024-05-24 21:46:01 [INFO]: Epoch 151 - training loss: 0.1028, validation loss: 0.1017
2024-05-24 21:46:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch151_loss0.10171891301870346.pypots
2024-05-24 21:46:17 [INFO]: Epoch 152 - training loss: 0.1026, validation loss: 0.1043
2024-05-24 21:46:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch152_loss0.10433842092752457.pypots
2024-05-24 21:46:34 [INFO]: Epoch 153 - training loss: 0.1016, validation loss: 0.1056
2024-05-24 21:46:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch153_loss0.10557732433080673.pypots
2024-05-24 21:46:51 [INFO]: Epoch 154 - training loss: 0.1145, validation loss: 0.1024
2024-05-24 21:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch154_loss0.10242463424801826.pypots
2024-05-24 21:47:07 [INFO]: Epoch 155 - training loss: 0.1046, validation loss: 0.1037
2024-05-24 21:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch155_loss0.10374915674328804.pypots
2024-05-24 21:47:24 [INFO]: Epoch 156 - training loss: 0.0992, validation loss: 0.1007
2024-05-24 21:47:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch156_loss0.10065550804138183.pypots
2024-05-24 21:47:40 [INFO]: Epoch 157 - training loss: 0.1036, validation loss: 0.1036
2024-05-24 21:47:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch157_loss0.10355897024273872.pypots
2024-05-24 21:47:57 [INFO]: Epoch 158 - training loss: 0.0946, validation loss: 0.1022
2024-05-24 21:47:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch158_loss0.10219142809510232.pypots
2024-05-24 21:48:14 [INFO]: Epoch 159 - training loss: 0.0831, validation loss: 0.1012
2024-05-24 21:48:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch159_loss0.10119652301073075.pypots
2024-05-24 21:48:30 [INFO]: Epoch 160 - training loss: 0.0984, validation loss: 0.1030
2024-05-24 21:48:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch160_loss0.10297599509358406.pypots
2024-05-24 21:48:47 [INFO]: Epoch 161 - training loss: 0.1037, validation loss: 0.1036
2024-05-24 21:48:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch161_loss0.10361334457993507.pypots
2024-05-24 21:49:04 [INFO]: Epoch 162 - training loss: 0.1034, validation loss: 0.1023
2024-05-24 21:49:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch162_loss0.1023235522210598.pypots
2024-05-24 21:49:20 [INFO]: Epoch 163 - training loss: 0.1004, validation loss: 0.1021
2024-05-24 21:49:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch163_loss0.10212452486157417.pypots
2024-05-24 21:49:37 [INFO]: Epoch 164 - training loss: 0.1057, validation loss: 0.1017
2024-05-24 21:49:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch164_loss0.10172610357403755.pypots
2024-05-24 21:49:53 [INFO]: Epoch 165 - training loss: 0.0971, validation loss: 0.1028
2024-05-24 21:49:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch165_loss0.10281693041324616.pypots
2024-05-24 21:50:10 [INFO]: Epoch 166 - training loss: 0.0966, validation loss: 0.1043
2024-05-24 21:50:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI_epoch166_loss0.10433337241411209.pypots
2024-05-24 21:50:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:50:10 [INFO]: Finished training. The best model is from epoch#156.
2024-05-24 21:50:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240524_T210409/CSDI.pypots
2024-05-24 21:52:30 [INFO]: CSDI on Air-Quality: MAE=0.1004, MSE=0.0999
2024-05-24 21:52:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-24 21:52:30 [INFO]: Using the given device: cuda:0
2024-05-24 21:52:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240524_T215230
2024-05-24 21:52:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240524_T215230/tensorboard
2024-05-24 21:52:30 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-24 21:52:32 [INFO]: Epoch 001 - training loss: 62830.8675, validation loss: 0.6381
2024-05-24 21:52:33 [INFO]: Epoch 002 - training loss: 41940.1771, validation loss: 0.5703
2024-05-24 21:52:33 [INFO]: Epoch 003 - training loss: 41632.7504, validation loss: 0.5404
2024-05-24 21:52:33 [INFO]: Epoch 004 - training loss: 41526.2043, validation loss: 0.4818
2024-05-24 21:52:34 [INFO]: Epoch 005 - training loss: 41446.7921, validation loss: 0.4600
2024-05-24 21:52:34 [INFO]: Epoch 006 - training loss: 41373.4523, validation loss: 0.4024
2024-05-24 21:52:34 [INFO]: Epoch 007 - training loss: 41322.5570, validation loss: 0.3486
2024-05-24 21:52:34 [INFO]: Epoch 008 - training loss: 41292.8961, validation loss: 0.3521
2024-05-24 21:52:35 [INFO]: Epoch 009 - training loss: 41277.5674, validation loss: 0.3130
2024-05-24 21:52:35 [INFO]: Epoch 010 - training loss: 41234.6997, validation loss: 0.3114
2024-05-24 21:52:35 [INFO]: Epoch 011 - training loss: 41219.3024, validation loss: 0.3028
2024-05-24 21:52:36 [INFO]: Epoch 012 - training loss: 41223.5093, validation loss: 0.3025
2024-05-24 21:52:36 [INFO]: Epoch 013 - training loss: 41217.8675, validation loss: 0.3136
2024-05-24 21:52:36 [INFO]: Epoch 014 - training loss: 41227.3814, validation loss: 0.3301
2024-05-24 21:52:37 [INFO]: Epoch 015 - training loss: 41181.2935, validation loss: 0.2759
2024-05-24 21:52:37 [INFO]: Epoch 016 - training loss: 41149.9909, validation loss: 0.2766
2024-05-24 21:52:37 [INFO]: Epoch 017 - training loss: 41137.2360, validation loss: 0.2779
2024-05-24 21:52:38 [INFO]: Epoch 018 - training loss: 41119.5166, validation loss: 0.2557
2024-05-24 21:52:38 [INFO]: Epoch 019 - training loss: 41115.9381, validation loss: 0.2522
2024-05-24 21:52:38 [INFO]: Epoch 020 - training loss: 41105.0608, validation loss: 0.2528
2024-05-24 21:52:39 [INFO]: Epoch 021 - training loss: 41106.0391, validation loss: 0.2500
2024-05-24 21:52:39 [INFO]: Epoch 022 - training loss: 41092.7271, validation loss: 0.2508
2024-05-24 21:52:39 [INFO]: Epoch 023 - training loss: 41089.0791, validation loss: 0.2415
2024-05-24 21:52:40 [INFO]: Epoch 024 - training loss: 41088.1236, validation loss: 0.2435
2024-05-24 21:52:40 [INFO]: Epoch 025 - training loss: 41084.1794, validation loss: 0.2381
2024-05-24 21:52:40 [INFO]: Epoch 026 - training loss: 41082.7468, validation loss: 0.2570
2024-05-24 21:52:40 [INFO]: Epoch 027 - training loss: 41162.1492, validation loss: 0.2642
2024-05-24 21:52:41 [INFO]: Epoch 028 - training loss: 41204.5569, validation loss: 0.2724
2024-05-24 21:52:41 [INFO]: Epoch 029 - training loss: 41142.8187, validation loss: 0.2398
2024-05-24 21:52:41 [INFO]: Epoch 030 - training loss: 41084.7814, validation loss: 0.2449
2024-05-24 21:52:42 [INFO]: Epoch 031 - training loss: 41107.5765, validation loss: 0.2471
2024-05-24 21:52:42 [INFO]: Epoch 032 - training loss: 41073.7953, validation loss: 0.2267
2024-05-24 21:52:42 [INFO]: Epoch 033 - training loss: 41055.3371, validation loss: 0.2464
2024-05-24 21:52:43 [INFO]: Epoch 034 - training loss: 41050.5987, validation loss: 0.2315
2024-05-24 21:52:43 [INFO]: Epoch 035 - training loss: 41071.6973, validation loss: 0.2280
2024-05-24 21:52:43 [INFO]: Epoch 036 - training loss: 41056.8455, validation loss: 0.2239
2024-05-24 21:52:44 [INFO]: Epoch 037 - training loss: 41043.1544, validation loss: 0.2195
2024-05-24 21:52:44 [INFO]: Epoch 038 - training loss: 41034.2179, validation loss: 0.2161
2024-05-24 21:52:44 [INFO]: Epoch 039 - training loss: 41032.4369, validation loss: 0.2125
2024-05-24 21:52:44 [INFO]: Epoch 040 - training loss: 41031.7465, validation loss: 0.2094
2024-05-24 21:52:45 [INFO]: Epoch 041 - training loss: 41026.0595, validation loss: 0.2183
2024-05-24 21:52:45 [INFO]: Epoch 042 - training loss: 41039.6661, validation loss: 0.2550
2024-05-24 21:52:45 [INFO]: Epoch 043 - training loss: 41037.6619, validation loss: 0.2158
2024-05-24 21:52:46 [INFO]: Epoch 044 - training loss: 41041.1304, validation loss: 0.2258
2024-05-24 21:52:46 [INFO]: Epoch 045 - training loss: 41046.7251, validation loss: 0.2226
2024-05-24 21:52:46 [INFO]: Epoch 046 - training loss: 41052.8313, validation loss: 0.2303
2024-05-24 21:52:47 [INFO]: Epoch 047 - training loss: 41069.5166, validation loss: 0.2385
2024-05-24 21:52:47 [INFO]: Epoch 048 - training loss: 41075.5979, validation loss: 0.2237
2024-05-24 21:52:47 [INFO]: Epoch 049 - training loss: 41070.7209, validation loss: 0.2241
2024-05-24 21:52:48 [INFO]: Epoch 050 - training loss: 41059.7105, validation loss: 0.2118
2024-05-24 21:52:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 21:52:48 [INFO]: Finished training. The best model is from epoch#40.
2024-05-24 21:52:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240524_T215230/GPVAE.pypots
2024-05-24 21:52:48 [INFO]: GP-VAE on Air-Quality: MAE=0.2862, MSE=0.2325
2024-05-24 21:52:48 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-24 21:52:48 [INFO]: Using the given device: cuda:0
2024-05-24 21:52:48 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240524_T215248
2024-05-24 21:52:48 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240524_T215248/tensorboard
2024-05-24 21:52:48 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-24 21:52:53 [INFO]: Epoch 001 - generator training loss: 0.5252, discriminator training loss: 0.3736, validation loss: 0.4864
2024-05-24 21:52:58 [INFO]: Epoch 002 - generator training loss: 0.1491, discriminator training loss: 0.2418, validation loss: 0.3742
2024-05-24 21:53:02 [INFO]: Epoch 003 - generator training loss: 0.1002, discriminator training loss: 0.2381, validation loss: 0.3039
2024-05-24 21:53:06 [INFO]: Epoch 004 - generator training loss: 0.0619, discriminator training loss: 0.2369, validation loss: 0.2594
2024-05-24 21:53:10 [INFO]: Epoch 005 - generator training loss: 0.0366, discriminator training loss: 0.2362, validation loss: 0.2326
2024-05-24 21:53:14 [INFO]: Epoch 006 - generator training loss: 0.0212, discriminator training loss: 0.2350, validation loss: 0.2139
2024-05-24 21:53:18 [INFO]: Epoch 007 - generator training loss: 0.0075, discriminator training loss: 0.2339, validation loss: 0.2007
2024-05-24 21:53:22 [INFO]: Epoch 008 - generator training loss: -0.0034, discriminator training loss: 0.2329, validation loss: 0.1895
2024-05-24 21:53:26 [INFO]: Epoch 009 - generator training loss: -0.0103, discriminator training loss: 0.2314, validation loss: 0.1801
2024-05-24 21:53:30 [INFO]: Epoch 010 - generator training loss: -0.0192, discriminator training loss: 0.2301, validation loss: 0.1729
2024-05-24 21:53:34 [INFO]: Epoch 011 - generator training loss: -0.0227, discriminator training loss: 0.2287, validation loss: 0.1663
2024-05-24 21:53:38 [INFO]: Epoch 012 - generator training loss: -0.0300, discriminator training loss: 0.2266, validation loss: 0.1597
2024-05-24 21:53:43 [INFO]: Epoch 013 - generator training loss: -0.0341, discriminator training loss: 0.2253, validation loss: 0.1558
2024-05-24 21:53:47 [INFO]: Epoch 014 - generator training loss: -0.0381, discriminator training loss: 0.2233, validation loss: 0.1511
2024-05-24 21:53:51 [INFO]: Epoch 015 - generator training loss: -0.0412, discriminator training loss: 0.2223, validation loss: 0.1478
2024-05-24 21:53:55 [INFO]: Epoch 016 - generator training loss: -0.0429, discriminator training loss: 0.2206, validation loss: 0.1440
2024-05-24 21:53:59 [INFO]: Epoch 017 - generator training loss: -0.0455, discriminator training loss: 0.2193, validation loss: 0.1403
2024-05-24 21:54:03 [INFO]: Epoch 018 - generator training loss: -0.0472, discriminator training loss: 0.2176, validation loss: 0.1372
2024-05-24 21:54:07 [INFO]: Epoch 019 - generator training loss: -0.0479, discriminator training loss: 0.2158, validation loss: 0.1344
2024-05-24 21:54:11 [INFO]: Epoch 020 - generator training loss: -0.0501, discriminator training loss: 0.2141, validation loss: 0.1319
2024-05-24 21:54:15 [INFO]: Epoch 021 - generator training loss: -0.0503, discriminator training loss: 0.2124, validation loss: 0.1298
2024-05-24 21:54:19 [INFO]: Epoch 022 - generator training loss: -0.0515, discriminator training loss: 0.2108, validation loss: 0.1274
2024-05-24 21:54:23 [INFO]: Epoch 023 - generator training loss: -0.0528, discriminator training loss: 0.2091, validation loss: 0.1252
2024-05-24 21:54:28 [INFO]: Epoch 024 - generator training loss: -0.0534, discriminator training loss: 0.2075, validation loss: 0.1232
2024-05-24 21:54:32 [INFO]: Epoch 025 - generator training loss: -0.0534, discriminator training loss: 0.2056, validation loss: 0.1218
2024-05-24 21:54:36 [INFO]: Epoch 026 - generator training loss: -0.0541, discriminator training loss: 0.2038, validation loss: 0.1200
2024-05-24 21:54:40 [INFO]: Epoch 027 - generator training loss: -0.0542, discriminator training loss: 0.2021, validation loss: 0.1187
2024-05-24 21:54:44 [INFO]: Epoch 028 - generator training loss: -0.0543, discriminator training loss: 0.2003, validation loss: 0.1164
2024-05-24 21:54:48 [INFO]: Epoch 029 - generator training loss: -0.0542, discriminator training loss: 0.1985, validation loss: 0.1143
2024-05-24 21:54:52 [INFO]: Epoch 030 - generator training loss: -0.0543, discriminator training loss: 0.1971, validation loss: 0.1142
2024-05-24 21:54:56 [INFO]: Epoch 031 - generator training loss: -0.0544, discriminator training loss: 0.1951, validation loss: 0.1125
2024-05-24 21:55:00 [INFO]: Epoch 032 - generator training loss: -0.0544, discriminator training loss: 0.1934, validation loss: 0.1114
2024-05-24 21:55:04 [INFO]: Epoch 033 - generator training loss: -0.0537, discriminator training loss: 0.1917, validation loss: 0.1092
2024-05-24 21:55:08 [INFO]: Epoch 034 - generator training loss: -0.0524, discriminator training loss: 0.1899, validation loss: 0.1085
2024-05-24 21:55:13 [INFO]: Epoch 035 - generator training loss: -0.0532, discriminator training loss: 0.1884, validation loss: 0.1079
2024-05-24 21:55:17 [INFO]: Epoch 036 - generator training loss: -0.0525, discriminator training loss: 0.1866, validation loss: 0.1062
2024-05-24 21:55:21 [INFO]: Epoch 037 - generator training loss: -0.0525, discriminator training loss: 0.1848, validation loss: 0.1051
2024-05-24 21:55:25 [INFO]: Epoch 038 - generator training loss: -0.0510, discriminator training loss: 0.1835, validation loss: 0.1042
2024-05-24 21:55:29 [INFO]: Epoch 039 - generator training loss: -0.0512, discriminator training loss: 0.1815, validation loss: 0.1027
2024-05-24 21:55:33 [INFO]: Epoch 040 - generator training loss: -0.0513, discriminator training loss: 0.1799, validation loss: 0.1018
2024-05-24 21:55:37 [INFO]: Epoch 041 - generator training loss: -0.0502, discriminator training loss: 0.1785, validation loss: 0.1012
2024-05-24 21:55:41 [INFO]: Epoch 042 - generator training loss: -0.0505, discriminator training loss: 0.1770, validation loss: 0.1009
2024-05-24 21:55:45 [INFO]: Epoch 043 - generator training loss: -0.0479, discriminator training loss: 0.1755, validation loss: 0.0993
2024-05-24 21:55:49 [INFO]: Epoch 044 - generator training loss: -0.0496, discriminator training loss: 0.1740, validation loss: 0.0988
2024-05-24 21:55:54 [INFO]: Epoch 045 - generator training loss: -0.0480, discriminator training loss: 0.1727, validation loss: 0.0977
2024-05-24 21:55:58 [INFO]: Epoch 046 - generator training loss: -0.0485, discriminator training loss: 0.1716, validation loss: 0.0972
2024-05-24 21:56:02 [INFO]: Epoch 047 - generator training loss: -0.0467, discriminator training loss: 0.1702, validation loss: 0.0965
2024-05-24 21:56:06 [INFO]: Epoch 048 - generator training loss: -0.0474, discriminator training loss: 0.1688, validation loss: 0.0956
2024-05-24 21:56:10 [INFO]: Epoch 049 - generator training loss: -0.0480, discriminator training loss: 0.1674, validation loss: 0.0949
2024-05-24 21:56:14 [INFO]: Epoch 050 - generator training loss: -0.0459, discriminator training loss: 0.1662, validation loss: 0.0944
2024-05-24 21:56:18 [INFO]: Epoch 051 - generator training loss: -0.0453, discriminator training loss: 0.1651, validation loss: 0.0939
2024-05-24 21:56:22 [INFO]: Epoch 052 - generator training loss: -0.0463, discriminator training loss: 0.1640, validation loss: 0.0929
2024-05-24 21:56:26 [INFO]: Epoch 053 - generator training loss: -0.0437, discriminator training loss: 0.1630, validation loss: 0.0924
2024-05-24 21:56:30 [INFO]: Epoch 054 - generator training loss: -0.0459, discriminator training loss: 0.1620, validation loss: 0.0920
2024-05-24 21:56:34 [INFO]: Epoch 055 - generator training loss: -0.0452, discriminator training loss: 0.1608, validation loss: 0.0916
2024-05-24 21:56:39 [INFO]: Epoch 056 - generator training loss: -0.0450, discriminator training loss: 0.1596, validation loss: 0.0908
2024-05-24 21:56:43 [INFO]: Epoch 057 - generator training loss: -0.0447, discriminator training loss: 0.1589, validation loss: 0.0903
2024-05-24 21:56:47 [INFO]: Epoch 058 - generator training loss: -0.0443, discriminator training loss: 0.1581, validation loss: 0.0899
2024-05-24 21:56:51 [INFO]: Epoch 059 - generator training loss: -0.0440, discriminator training loss: 0.1572, validation loss: 0.0896
2024-05-24 21:56:55 [INFO]: Epoch 060 - generator training loss: -0.0429, discriminator training loss: 0.1562, validation loss: 0.0892
2024-05-24 21:56:59 [INFO]: Epoch 061 - generator training loss: -0.0437, discriminator training loss: 0.1554, validation loss: 0.0886
2024-05-24 21:57:03 [INFO]: Epoch 062 - generator training loss: -0.0435, discriminator training loss: 0.1550, validation loss: 0.0883
2024-05-24 21:57:07 [INFO]: Epoch 063 - generator training loss: -0.0430, discriminator training loss: 0.1540, validation loss: 0.0879
2024-05-24 21:57:11 [INFO]: Epoch 064 - generator training loss: -0.0433, discriminator training loss: 0.1534, validation loss: 0.0877
2024-05-24 21:57:15 [INFO]: Epoch 065 - generator training loss: -0.0425, discriminator training loss: 0.1525, validation loss: 0.0868
2024-05-24 21:57:19 [INFO]: Epoch 066 - generator training loss: -0.0423, discriminator training loss: 0.1514, validation loss: 0.0871
2024-05-24 21:57:24 [INFO]: Epoch 067 - generator training loss: -0.0424, discriminator training loss: 0.1507, validation loss: 0.0870
2024-05-24 21:57:28 [INFO]: Epoch 068 - generator training loss: -0.0424, discriminator training loss: 0.1505, validation loss: 0.0861
2024-05-24 21:57:32 [INFO]: Epoch 069 - generator training loss: -0.0432, discriminator training loss: 0.1498, validation loss: 0.0857
2024-05-24 21:57:36 [INFO]: Epoch 070 - generator training loss: -0.0422, discriminator training loss: 0.1495, validation loss: 0.0855
2024-05-24 21:57:40 [INFO]: Epoch 071 - generator training loss: -0.0424, discriminator training loss: 0.1488, validation loss: 0.0868
2024-05-24 21:57:44 [INFO]: Epoch 072 - generator training loss: -0.0413, discriminator training loss: 0.1485, validation loss: 0.0855
2024-05-24 21:57:48 [INFO]: Epoch 073 - generator training loss: -0.0412, discriminator training loss: 0.1479, validation loss: 0.0852
2024-05-24 21:57:52 [INFO]: Epoch 074 - generator training loss: -0.0419, discriminator training loss: 0.1471, validation loss: 0.0850
2024-05-24 21:57:56 [INFO]: Epoch 075 - generator training loss: -0.0423, discriminator training loss: 0.1468, validation loss: 0.0838
2024-05-24 21:58:00 [INFO]: Epoch 076 - generator training loss: -0.0413, discriminator training loss: 0.1461, validation loss: 0.0841
2024-05-24 21:58:04 [INFO]: Epoch 077 - generator training loss: -0.0415, discriminator training loss: 0.1460, validation loss: 0.0844
2024-05-24 21:58:09 [INFO]: Epoch 078 - generator training loss: -0.0422, discriminator training loss: 0.1455, validation loss: 0.0837
2024-05-24 21:58:13 [INFO]: Epoch 079 - generator training loss: -0.0408, discriminator training loss: 0.1449, validation loss: 0.0832
2024-05-24 21:58:17 [INFO]: Epoch 080 - generator training loss: -0.0419, discriminator training loss: 0.1444, validation loss: 0.0832
2024-05-24 21:58:21 [INFO]: Epoch 081 - generator training loss: -0.0414, discriminator training loss: 0.1437, validation loss: 0.0829
2024-05-24 21:58:25 [INFO]: Epoch 082 - generator training loss: -0.0417, discriminator training loss: 0.1433, validation loss: 0.0837
2024-05-24 21:58:29 [INFO]: Epoch 083 - generator training loss: -0.0417, discriminator training loss: 0.1429, validation loss: 0.0832
2024-05-24 21:58:33 [INFO]: Epoch 084 - generator training loss: -0.0422, discriminator training loss: 0.1430, validation loss: 0.0832
2024-05-24 21:58:37 [INFO]: Epoch 085 - generator training loss: -0.0417, discriminator training loss: 0.1427, validation loss: 0.0832
2024-05-24 21:58:41 [INFO]: Epoch 086 - generator training loss: -0.0408, discriminator training loss: 0.1419, validation loss: 0.0827
2024-05-24 21:58:45 [INFO]: Epoch 087 - generator training loss: -0.0418, discriminator training loss: 0.1417, validation loss: 0.0820
2024-05-24 21:58:49 [INFO]: Epoch 088 - generator training loss: -0.0409, discriminator training loss: 0.1410, validation loss: 0.0817
2024-05-24 21:58:54 [INFO]: Epoch 089 - generator training loss: -0.0423, discriminator training loss: 0.1411, validation loss: 0.0817
2024-05-24 21:58:58 [INFO]: Epoch 090 - generator training loss: -0.0397, discriminator training loss: 0.1409, validation loss: 0.0822
2024-05-24 21:59:02 [INFO]: Epoch 091 - generator training loss: -0.0413, discriminator training loss: 0.1405, validation loss: 0.0817
2024-05-24 21:59:06 [INFO]: Epoch 092 - generator training loss: -0.0416, discriminator training loss: 0.1405, validation loss: 0.0812
2024-05-24 21:59:10 [INFO]: Epoch 093 - generator training loss: -0.0418, discriminator training loss: 0.1397, validation loss: 0.0815
2024-05-24 21:59:14 [INFO]: Epoch 094 - generator training loss: -0.0420, discriminator training loss: 0.1397, validation loss: 0.0803
2024-05-24 21:59:18 [INFO]: Epoch 095 - generator training loss: -0.0422, discriminator training loss: 0.1393, validation loss: 0.0809
2024-05-24 21:59:22 [INFO]: Epoch 096 - generator training loss: -0.0434, discriminator training loss: 0.1392, validation loss: 0.0812
2024-05-24 21:59:26 [INFO]: Epoch 097 - generator training loss: -0.0423, discriminator training loss: 0.1387, validation loss: 0.0801
2024-05-24 21:59:30 [INFO]: Epoch 098 - generator training loss: -0.0429, discriminator training loss: 0.1384, validation loss: 0.0803
2024-05-24 21:59:34 [INFO]: Epoch 099 - generator training loss: -0.0430, discriminator training loss: 0.1383, validation loss: 0.0808
2024-05-24 21:59:38 [INFO]: Epoch 100 - generator training loss: -0.0420, discriminator training loss: 0.1381, validation loss: 0.0810
2024-05-24 21:59:43 [INFO]: Epoch 101 - generator training loss: -0.0425, discriminator training loss: 0.1381, validation loss: 0.0802
2024-05-24 21:59:47 [INFO]: Epoch 102 - generator training loss: -0.0429, discriminator training loss: 0.1374, validation loss: 0.0791
2024-05-24 21:59:51 [INFO]: Epoch 103 - generator training loss: -0.0424, discriminator training loss: 0.1377, validation loss: 0.0799
2024-05-24 21:59:55 [INFO]: Epoch 104 - generator training loss: -0.0430, discriminator training loss: 0.1373, validation loss: 0.0793
2024-05-24 21:59:59 [INFO]: Epoch 105 - generator training loss: -0.0434, discriminator training loss: 0.1372, validation loss: 0.0794
2024-05-24 22:00:03 [INFO]: Epoch 106 - generator training loss: -0.0434, discriminator training loss: 0.1370, validation loss: 0.0796
2024-05-24 22:00:07 [INFO]: Epoch 107 - generator training loss: -0.0412, discriminator training loss: 0.1369, validation loss: 0.0797
2024-05-24 22:00:11 [INFO]: Epoch 108 - generator training loss: -0.0422, discriminator training loss: 0.1364, validation loss: 0.0805
2024-05-24 22:00:15 [INFO]: Epoch 109 - generator training loss: -0.0433, discriminator training loss: 0.1364, validation loss: 0.0792
2024-05-24 22:00:19 [INFO]: Epoch 110 - generator training loss: -0.0437, discriminator training loss: 0.1363, validation loss: 0.0796
2024-05-24 22:00:24 [INFO]: Epoch 111 - generator training loss: -0.0439, discriminator training loss: 0.1359, validation loss: 0.0786
2024-05-24 22:00:28 [INFO]: Epoch 112 - generator training loss: -0.0437, discriminator training loss: 0.1355, validation loss: 0.0794
2024-05-24 22:00:32 [INFO]: Epoch 113 - generator training loss: -0.0437, discriminator training loss: 0.1355, validation loss: 0.0789
2024-05-24 22:00:36 [INFO]: Epoch 114 - generator training loss: -0.0439, discriminator training loss: 0.1355, validation loss: 0.0798
2024-05-24 22:00:40 [INFO]: Epoch 115 - generator training loss: -0.0428, discriminator training loss: 0.1354, validation loss: 0.0787
2024-05-24 22:00:44 [INFO]: Epoch 116 - generator training loss: -0.0439, discriminator training loss: 0.1349, validation loss: 0.0791
2024-05-24 22:00:48 [INFO]: Epoch 117 - generator training loss: -0.0438, discriminator training loss: 0.1346, validation loss: 0.0783
2024-05-24 22:00:52 [INFO]: Epoch 118 - generator training loss: -0.0446, discriminator training loss: 0.1343, validation loss: 0.0783
2024-05-24 22:00:56 [INFO]: Epoch 119 - generator training loss: -0.0448, discriminator training loss: 0.1347, validation loss: 0.0786
2024-05-24 22:01:00 [INFO]: Epoch 120 - generator training loss: -0.0446, discriminator training loss: 0.1342, validation loss: 0.0779
2024-05-24 22:01:05 [INFO]: Epoch 121 - generator training loss: -0.0448, discriminator training loss: 0.1346, validation loss: 0.0786
2024-05-24 22:01:09 [INFO]: Epoch 122 - generator training loss: -0.0434, discriminator training loss: 0.1343, validation loss: 0.0789
2024-05-24 22:01:13 [INFO]: Epoch 123 - generator training loss: -0.0443, discriminator training loss: 0.1336, validation loss: 0.0777
2024-05-24 22:01:17 [INFO]: Epoch 124 - generator training loss: -0.0447, discriminator training loss: 0.1334, validation loss: 0.0786
2024-05-24 22:01:21 [INFO]: Epoch 125 - generator training loss: -0.0454, discriminator training loss: 0.1337, validation loss: 0.0780
2024-05-24 22:01:25 [INFO]: Epoch 126 - generator training loss: -0.0447, discriminator training loss: 0.1338, validation loss: 0.0777
2024-05-24 22:01:29 [INFO]: Epoch 127 - generator training loss: -0.0447, discriminator training loss: 0.1332, validation loss: 0.0780
2024-05-24 22:01:33 [INFO]: Epoch 128 - generator training loss: -0.0447, discriminator training loss: 0.1333, validation loss: 0.0792
2024-05-24 22:01:37 [INFO]: Epoch 129 - generator training loss: -0.0452, discriminator training loss: 0.1334, validation loss: 0.0782
2024-05-24 22:01:41 [INFO]: Epoch 130 - generator training loss: -0.0460, discriminator training loss: 0.1329, validation loss: 0.0780
2024-05-24 22:01:45 [INFO]: Epoch 131 - generator training loss: -0.0456, discriminator training loss: 0.1330, validation loss: 0.0782
2024-05-24 22:01:49 [INFO]: Epoch 132 - generator training loss: -0.0454, discriminator training loss: 0.1329, validation loss: 0.0775
2024-05-24 22:01:54 [INFO]: Epoch 133 - generator training loss: -0.0453, discriminator training loss: 0.1329, validation loss: 0.0780
2024-05-24 22:01:58 [INFO]: Epoch 134 - generator training loss: -0.0451, discriminator training loss: 0.1329, validation loss: 0.0770
2024-05-24 22:02:02 [INFO]: Epoch 135 - generator training loss: -0.0453, discriminator training loss: 0.1325, validation loss: 0.0789
2024-05-24 22:02:06 [INFO]: Epoch 136 - generator training loss: -0.0452, discriminator training loss: 0.1324, validation loss: 0.0786
2024-05-24 22:02:10 [INFO]: Epoch 137 - generator training loss: -0.0460, discriminator training loss: 0.1320, validation loss: 0.0777
2024-05-24 22:02:14 [INFO]: Epoch 138 - generator training loss: -0.0463, discriminator training loss: 0.1323, validation loss: 0.0785
2024-05-24 22:02:18 [INFO]: Epoch 139 - generator training loss: -0.0460, discriminator training loss: 0.1324, validation loss: 0.0775
2024-05-24 22:02:22 [INFO]: Epoch 140 - generator training loss: -0.0458, discriminator training loss: 0.1320, validation loss: 0.0783
2024-05-24 22:02:26 [INFO]: Epoch 141 - generator training loss: -0.0456, discriminator training loss: 0.1320, validation loss: 0.0785
2024-05-24 22:02:30 [INFO]: Epoch 142 - generator training loss: -0.0455, discriminator training loss: 0.1320, validation loss: 0.0783
2024-05-24 22:02:34 [INFO]: Epoch 143 - generator training loss: -0.0455, discriminator training loss: 0.1317, validation loss: 0.0779
2024-05-24 22:02:39 [INFO]: Epoch 144 - generator training loss: -0.0456, discriminator training loss: 0.1320, validation loss: 0.0773
2024-05-24 22:02:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:02:39 [INFO]: Finished training. The best model is from epoch#134.
2024-05-24 22:02:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240524_T215248/USGAN.pypots
2024-05-24 22:02:39 [INFO]: US-GAN on Air-Quality: MAE=0.1408, MSE=0.0909
2024-05-24 22:02:39 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-24 22:02:39 [INFO]: Using the given device: cuda:0
2024-05-24 22:02:39 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240524_T220239
2024-05-24 22:02:39 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240524_T220239/tensorboard
2024-05-24 22:02:39 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-24 22:02:43 [INFO]: Epoch 001 - training loss: 1.4190, validation loss: 0.9384
2024-05-24 22:02:46 [INFO]: Epoch 002 - training loss: 1.1491, validation loss: 0.6903
2024-05-24 22:02:48 [INFO]: Epoch 003 - training loss: 0.9563, validation loss: 0.5772
2024-05-24 22:02:51 [INFO]: Epoch 004 - training loss: 0.8447, validation loss: 0.5086
2024-05-24 22:02:54 [INFO]: Epoch 005 - training loss: 0.7711, validation loss: 0.4600
2024-05-24 22:02:57 [INFO]: Epoch 006 - training loss: 0.7118, validation loss: 0.4213
2024-05-24 22:03:00 [INFO]: Epoch 007 - training loss: 0.6668, validation loss: 0.3912
2024-05-24 22:03:03 [INFO]: Epoch 008 - training loss: 0.6334, validation loss: 0.3668
2024-05-24 22:03:05 [INFO]: Epoch 009 - training loss: 0.6066, validation loss: 0.3470
2024-05-24 22:03:08 [INFO]: Epoch 010 - training loss: 0.5850, validation loss: 0.3312
2024-05-24 22:03:11 [INFO]: Epoch 011 - training loss: 0.5669, validation loss: 0.3170
2024-05-24 22:03:14 [INFO]: Epoch 012 - training loss: 0.5520, validation loss: 0.3051
2024-05-24 22:03:16 [INFO]: Epoch 013 - training loss: 0.5393, validation loss: 0.2953
2024-05-24 22:03:19 [INFO]: Epoch 014 - training loss: 0.5268, validation loss: 0.2859
2024-05-24 22:03:22 [INFO]: Epoch 015 - training loss: 0.5168, validation loss: 0.2782
2024-05-24 22:03:25 [INFO]: Epoch 016 - training loss: 0.5061, validation loss: 0.2716
2024-05-24 22:03:28 [INFO]: Epoch 017 - training loss: 0.4965, validation loss: 0.2650
2024-05-24 22:03:30 [INFO]: Epoch 018 - training loss: 0.4881, validation loss: 0.2587
2024-05-24 22:03:33 [INFO]: Epoch 019 - training loss: 0.4825, validation loss: 0.2534
2024-05-24 22:03:36 [INFO]: Epoch 020 - training loss: 0.4743, validation loss: 0.2487
2024-05-24 22:03:39 [INFO]: Epoch 021 - training loss: 0.4655, validation loss: 0.2431
2024-05-24 22:03:42 [INFO]: Epoch 022 - training loss: 0.4591, validation loss: 0.2390
2024-05-24 22:03:44 [INFO]: Epoch 023 - training loss: 0.4535, validation loss: 0.2345
2024-05-24 22:03:47 [INFO]: Epoch 024 - training loss: 0.4473, validation loss: 0.2299
2024-05-24 22:03:50 [INFO]: Epoch 025 - training loss: 0.4415, validation loss: 0.2257
2024-05-24 22:03:53 [INFO]: Epoch 026 - training loss: 0.4347, validation loss: 0.2220
2024-05-24 22:03:56 [INFO]: Epoch 027 - training loss: 0.4302, validation loss: 0.2179
2024-05-24 22:03:58 [INFO]: Epoch 028 - training loss: 0.4247, validation loss: 0.2145
2024-05-24 22:04:01 [INFO]: Epoch 029 - training loss: 0.4199, validation loss: 0.2108
2024-05-24 22:04:04 [INFO]: Epoch 030 - training loss: 0.4158, validation loss: 0.2077
2024-05-24 22:04:07 [INFO]: Epoch 031 - training loss: 0.4106, validation loss: 0.2038
2024-05-24 22:04:10 [INFO]: Epoch 032 - training loss: 0.4064, validation loss: 0.2009
2024-05-24 22:04:12 [INFO]: Epoch 033 - training loss: 0.4020, validation loss: 0.1982
2024-05-24 22:04:15 [INFO]: Epoch 034 - training loss: 0.3981, validation loss: 0.1946
2024-05-24 22:04:18 [INFO]: Epoch 035 - training loss: 0.3933, validation loss: 0.1915
2024-05-24 22:04:21 [INFO]: Epoch 036 - training loss: 0.3902, validation loss: 0.1891
2024-05-24 22:04:23 [INFO]: Epoch 037 - training loss: 0.3869, validation loss: 0.1857
2024-05-24 22:04:26 [INFO]: Epoch 038 - training loss: 0.3833, validation loss: 0.1825
2024-05-24 22:04:29 [INFO]: Epoch 039 - training loss: 0.3786, validation loss: 0.1797
2024-05-24 22:04:32 [INFO]: Epoch 040 - training loss: 0.3753, validation loss: 0.1771
2024-05-24 22:04:35 [INFO]: Epoch 041 - training loss: 0.3722, validation loss: 0.1745
2024-05-24 22:04:37 [INFO]: Epoch 042 - training loss: 0.3700, validation loss: 0.1723
2024-05-24 22:04:40 [INFO]: Epoch 043 - training loss: 0.3664, validation loss: 0.1707
2024-05-24 22:04:43 [INFO]: Epoch 044 - training loss: 0.3636, validation loss: 0.1678
2024-05-24 22:04:46 [INFO]: Epoch 045 - training loss: 0.3605, validation loss: 0.1653
2024-05-24 22:04:49 [INFO]: Epoch 046 - training loss: 0.3585, validation loss: 0.1629
2024-05-24 22:04:51 [INFO]: Epoch 047 - training loss: 0.3557, validation loss: 0.1612
2024-05-24 22:04:54 [INFO]: Epoch 048 - training loss: 0.3530, validation loss: 0.1590
2024-05-24 22:04:57 [INFO]: Epoch 049 - training loss: 0.3513, validation loss: 0.1572
2024-05-24 22:05:00 [INFO]: Epoch 050 - training loss: 0.3480, validation loss: 0.1552
2024-05-24 22:05:03 [INFO]: Epoch 051 - training loss: 0.3458, validation loss: 0.1536
2024-05-24 22:05:05 [INFO]: Epoch 052 - training loss: 0.3439, validation loss: 0.1518
2024-05-24 22:05:08 [INFO]: Epoch 053 - training loss: 0.3414, validation loss: 0.1502
2024-05-24 22:05:11 [INFO]: Epoch 054 - training loss: 0.3398, validation loss: 0.1489
2024-05-24 22:05:14 [INFO]: Epoch 055 - training loss: 0.3374, validation loss: 0.1472
2024-05-24 22:05:17 [INFO]: Epoch 056 - training loss: 0.3358, validation loss: 0.1458
2024-05-24 22:05:19 [INFO]: Epoch 057 - training loss: 0.3334, validation loss: 0.1446
2024-05-24 22:05:22 [INFO]: Epoch 058 - training loss: 0.3320, validation loss: 0.1434
2024-05-24 22:05:25 [INFO]: Epoch 059 - training loss: 0.3299, validation loss: 0.1418
2024-05-24 22:05:28 [INFO]: Epoch 060 - training loss: 0.3294, validation loss: 0.1406
2024-05-24 22:05:31 [INFO]: Epoch 061 - training loss: 0.3265, validation loss: 0.1391
2024-05-24 22:05:33 [INFO]: Epoch 062 - training loss: 0.3247, validation loss: 0.1379
2024-05-24 22:05:36 [INFO]: Epoch 063 - training loss: 0.3232, validation loss: 0.1368
2024-05-24 22:05:39 [INFO]: Epoch 064 - training loss: 0.3225, validation loss: 0.1361
2024-05-24 22:05:42 [INFO]: Epoch 065 - training loss: 0.3216, validation loss: 0.1347
2024-05-24 22:05:45 [INFO]: Epoch 066 - training loss: 0.3196, validation loss: 0.1341
2024-05-24 22:05:47 [INFO]: Epoch 067 - training loss: 0.3186, validation loss: 0.1330
2024-05-24 22:05:50 [INFO]: Epoch 068 - training loss: 0.3171, validation loss: 0.1320
2024-05-24 22:05:53 [INFO]: Epoch 069 - training loss: 0.3158, validation loss: 0.1311
2024-05-24 22:05:56 [INFO]: Epoch 070 - training loss: 0.3139, validation loss: 0.1304
2024-05-24 22:05:59 [INFO]: Epoch 071 - training loss: 0.3143, validation loss: 0.1295
2024-05-24 22:06:01 [INFO]: Epoch 072 - training loss: 0.3119, validation loss: 0.1282
2024-05-24 22:06:04 [INFO]: Epoch 073 - training loss: 0.3111, validation loss: 0.1276
2024-05-24 22:06:07 [INFO]: Epoch 074 - training loss: 0.3100, validation loss: 0.1268
2024-05-24 22:06:10 [INFO]: Epoch 075 - training loss: 0.3086, validation loss: 0.1261
2024-05-24 22:06:12 [INFO]: Epoch 076 - training loss: 0.3074, validation loss: 0.1255
2024-05-24 22:06:15 [INFO]: Epoch 077 - training loss: 0.3064, validation loss: 0.1246
2024-05-24 22:06:18 [INFO]: Epoch 078 - training loss: 0.3048, validation loss: 0.1239
2024-05-24 22:06:21 [INFO]: Epoch 079 - training loss: 0.3039, validation loss: 0.1233
2024-05-24 22:06:24 [INFO]: Epoch 080 - training loss: 0.3026, validation loss: 0.1224
2024-05-24 22:06:26 [INFO]: Epoch 081 - training loss: 0.3025, validation loss: 0.1220
2024-05-24 22:06:29 [INFO]: Epoch 082 - training loss: 0.3016, validation loss: 0.1210
2024-05-24 22:06:32 [INFO]: Epoch 083 - training loss: 0.3008, validation loss: 0.1206
2024-05-24 22:06:35 [INFO]: Epoch 084 - training loss: 0.3003, validation loss: 0.1199
2024-05-24 22:06:38 [INFO]: Epoch 085 - training loss: 0.2988, validation loss: 0.1192
2024-05-24 22:06:40 [INFO]: Epoch 086 - training loss: 0.2982, validation loss: 0.1184
2024-05-24 22:06:43 [INFO]: Epoch 087 - training loss: 0.2974, validation loss: 0.1180
2024-05-24 22:06:46 [INFO]: Epoch 088 - training loss: 0.2967, validation loss: 0.1174
2024-05-24 22:06:49 [INFO]: Epoch 089 - training loss: 0.2966, validation loss: 0.1168
2024-05-24 22:06:52 [INFO]: Epoch 090 - training loss: 0.2945, validation loss: 0.1162
2024-05-24 22:06:54 [INFO]: Epoch 091 - training loss: 0.2943, validation loss: 0.1158
2024-05-24 22:06:57 [INFO]: Epoch 092 - training loss: 0.2934, validation loss: 0.1152
2024-05-24 22:07:00 [INFO]: Epoch 093 - training loss: 0.2927, validation loss: 0.1146
2024-05-24 22:07:03 [INFO]: Epoch 094 - training loss: 0.2920, validation loss: 0.1140
2024-05-24 22:07:06 [INFO]: Epoch 095 - training loss: 0.2912, validation loss: 0.1136
2024-05-24 22:07:08 [INFO]: Epoch 096 - training loss: 0.2904, validation loss: 0.1131
2024-05-24 22:07:11 [INFO]: Epoch 097 - training loss: 0.2905, validation loss: 0.1125
2024-05-24 22:07:14 [INFO]: Epoch 098 - training loss: 0.2900, validation loss: 0.1118
2024-05-24 22:07:17 [INFO]: Epoch 099 - training loss: 0.2891, validation loss: 0.1115
2024-05-24 22:07:20 [INFO]: Epoch 100 - training loss: 0.2885, validation loss: 0.1111
2024-05-24 22:07:22 [INFO]: Epoch 101 - training loss: 0.2869, validation loss: 0.1104
2024-05-24 22:07:25 [INFO]: Epoch 102 - training loss: 0.2871, validation loss: 0.1099
2024-05-24 22:07:28 [INFO]: Epoch 103 - training loss: 0.2858, validation loss: 0.1095
2024-05-24 22:07:31 [INFO]: Epoch 104 - training loss: 0.2854, validation loss: 0.1091
2024-05-24 22:07:33 [INFO]: Epoch 105 - training loss: 0.2854, validation loss: 0.1086
2024-05-24 22:07:36 [INFO]: Epoch 106 - training loss: 0.2841, validation loss: 0.1081
2024-05-24 22:07:39 [INFO]: Epoch 107 - training loss: 0.2836, validation loss: 0.1077
2024-05-24 22:07:42 [INFO]: Epoch 108 - training loss: 0.2836, validation loss: 0.1073
2024-05-24 22:07:45 [INFO]: Epoch 109 - training loss: 0.2825, validation loss: 0.1069
2024-05-24 22:07:47 [INFO]: Epoch 110 - training loss: 0.2820, validation loss: 0.1063
2024-05-24 22:07:50 [INFO]: Epoch 111 - training loss: 0.2811, validation loss: 0.1061
2024-05-24 22:07:53 [INFO]: Epoch 112 - training loss: 0.2808, validation loss: 0.1057
2024-05-24 22:07:56 [INFO]: Epoch 113 - training loss: 0.2801, validation loss: 0.1052
2024-05-24 22:07:59 [INFO]: Epoch 114 - training loss: 0.2800, validation loss: 0.1048
2024-05-24 22:08:01 [INFO]: Epoch 115 - training loss: 0.2797, validation loss: 0.1044
2024-05-24 22:08:04 [INFO]: Epoch 116 - training loss: 0.2789, validation loss: 0.1041
2024-05-24 22:08:07 [INFO]: Epoch 117 - training loss: 0.2783, validation loss: 0.1037
2024-05-24 22:08:10 [INFO]: Epoch 118 - training loss: 0.2779, validation loss: 0.1032
2024-05-24 22:08:13 [INFO]: Epoch 119 - training loss: 0.2768, validation loss: 0.1030
2024-05-24 22:08:15 [INFO]: Epoch 120 - training loss: 0.2766, validation loss: 0.1026
2024-05-24 22:08:18 [INFO]: Epoch 121 - training loss: 0.2765, validation loss: 0.1020
2024-05-24 22:08:21 [INFO]: Epoch 122 - training loss: 0.2762, validation loss: 0.1018
2024-05-24 22:08:24 [INFO]: Epoch 123 - training loss: 0.2753, validation loss: 0.1014
2024-05-24 22:08:27 [INFO]: Epoch 124 - training loss: 0.2750, validation loss: 0.1012
2024-05-24 22:08:29 [INFO]: Epoch 125 - training loss: 0.2744, validation loss: 0.1006
2024-05-24 22:08:32 [INFO]: Epoch 126 - training loss: 0.2736, validation loss: 0.1005
2024-05-24 22:08:35 [INFO]: Epoch 127 - training loss: 0.2731, validation loss: 0.1000
2024-05-24 22:08:38 [INFO]: Epoch 128 - training loss: 0.2725, validation loss: 0.0996
2024-05-24 22:08:40 [INFO]: Epoch 129 - training loss: 0.2723, validation loss: 0.0992
2024-05-24 22:08:43 [INFO]: Epoch 130 - training loss: 0.2727, validation loss: 0.0988
2024-05-24 22:08:46 [INFO]: Epoch 131 - training loss: 0.2717, validation loss: 0.0985
2024-05-24 22:08:49 [INFO]: Epoch 132 - training loss: 0.2709, validation loss: 0.0983
2024-05-24 22:08:52 [INFO]: Epoch 133 - training loss: 0.2706, validation loss: 0.0981
2024-05-24 22:08:54 [INFO]: Epoch 134 - training loss: 0.2706, validation loss: 0.0977
2024-05-24 22:08:57 [INFO]: Epoch 135 - training loss: 0.2696, validation loss: 0.0975
2024-05-24 22:09:00 [INFO]: Epoch 136 - training loss: 0.2694, validation loss: 0.0969
2024-05-24 22:09:03 [INFO]: Epoch 137 - training loss: 0.2691, validation loss: 0.0966
2024-05-24 22:09:06 [INFO]: Epoch 138 - training loss: 0.2696, validation loss: 0.0964
2024-05-24 22:09:08 [INFO]: Epoch 139 - training loss: 0.2684, validation loss: 0.0961
2024-05-24 22:09:11 [INFO]: Epoch 140 - training loss: 0.2679, validation loss: 0.0957
2024-05-24 22:09:14 [INFO]: Epoch 141 - training loss: 0.2675, validation loss: 0.0954
2024-05-24 22:09:17 [INFO]: Epoch 142 - training loss: 0.2675, validation loss: 0.0951
2024-05-24 22:09:20 [INFO]: Epoch 143 - training loss: 0.2669, validation loss: 0.0948
2024-05-24 22:09:23 [INFO]: Epoch 144 - training loss: 0.2662, validation loss: 0.0945
2024-05-24 22:09:25 [INFO]: Epoch 145 - training loss: 0.2664, validation loss: 0.0944
2024-05-24 22:09:28 [INFO]: Epoch 146 - training loss: 0.2657, validation loss: 0.0939
2024-05-24 22:09:31 [INFO]: Epoch 147 - training loss: 0.2652, validation loss: 0.0937
2024-05-24 22:09:34 [INFO]: Epoch 148 - training loss: 0.2651, validation loss: 0.0933
2024-05-24 22:09:36 [INFO]: Epoch 149 - training loss: 0.2653, validation loss: 0.0930
2024-05-24 22:09:39 [INFO]: Epoch 150 - training loss: 0.2643, validation loss: 0.0928
2024-05-24 22:09:42 [INFO]: Epoch 151 - training loss: 0.2641, validation loss: 0.0925
2024-05-24 22:09:45 [INFO]: Epoch 152 - training loss: 0.2640, validation loss: 0.0922
2024-05-24 22:09:48 [INFO]: Epoch 153 - training loss: 0.2635, validation loss: 0.0920
2024-05-24 22:09:50 [INFO]: Epoch 154 - training loss: 0.2630, validation loss: 0.0917
2024-05-24 22:09:53 [INFO]: Epoch 155 - training loss: 0.2629, validation loss: 0.0916
2024-05-24 22:09:56 [INFO]: Epoch 156 - training loss: 0.2623, validation loss: 0.0914
2024-05-24 22:09:59 [INFO]: Epoch 157 - training loss: 0.2621, validation loss: 0.0909
2024-05-24 22:10:02 [INFO]: Epoch 158 - training loss: 0.2623, validation loss: 0.0909
2024-05-24 22:10:04 [INFO]: Epoch 159 - training loss: 0.2612, validation loss: 0.0907
2024-05-24 22:10:07 [INFO]: Epoch 160 - training loss: 0.2613, validation loss: 0.0903
2024-05-24 22:10:10 [INFO]: Epoch 161 - training loss: 0.2612, validation loss: 0.0901
2024-05-24 22:10:13 [INFO]: Epoch 162 - training loss: 0.2606, validation loss: 0.0898
2024-05-24 22:10:16 [INFO]: Epoch 163 - training loss: 0.2603, validation loss: 0.0897
2024-05-24 22:10:18 [INFO]: Epoch 164 - training loss: 0.2598, validation loss: 0.0892
2024-05-24 22:10:21 [INFO]: Epoch 165 - training loss: 0.2598, validation loss: 0.0890
2024-05-24 22:10:24 [INFO]: Epoch 166 - training loss: 0.2591, validation loss: 0.0890
2024-05-24 22:10:27 [INFO]: Epoch 167 - training loss: 0.2590, validation loss: 0.0888
2024-05-24 22:10:29 [INFO]: Epoch 168 - training loss: 0.2588, validation loss: 0.0884
2024-05-24 22:10:32 [INFO]: Epoch 169 - training loss: 0.2581, validation loss: 0.0883
2024-05-24 22:10:35 [INFO]: Epoch 170 - training loss: 0.2579, validation loss: 0.0882
2024-05-24 22:10:38 [INFO]: Epoch 171 - training loss: 0.2576, validation loss: 0.0880
2024-05-24 22:10:41 [INFO]: Epoch 172 - training loss: 0.2580, validation loss: 0.0879
2024-05-24 22:10:43 [INFO]: Epoch 173 - training loss: 0.2575, validation loss: 0.0876
2024-05-24 22:10:46 [INFO]: Epoch 174 - training loss: 0.2572, validation loss: 0.0872
2024-05-24 22:10:49 [INFO]: Epoch 175 - training loss: 0.2565, validation loss: 0.0871
2024-05-24 22:10:52 [INFO]: Epoch 176 - training loss: 0.2572, validation loss: 0.0869
2024-05-24 22:10:55 [INFO]: Epoch 177 - training loss: 0.2563, validation loss: 0.0867
2024-05-24 22:10:57 [INFO]: Epoch 178 - training loss: 0.2564, validation loss: 0.0866
2024-05-24 22:11:00 [INFO]: Epoch 179 - training loss: 0.2559, validation loss: 0.0863
2024-05-24 22:11:03 [INFO]: Epoch 180 - training loss: 0.2558, validation loss: 0.0861
2024-05-24 22:11:06 [INFO]: Epoch 181 - training loss: 0.2547, validation loss: 0.0860
2024-05-24 22:11:09 [INFO]: Epoch 182 - training loss: 0.2554, validation loss: 0.0858
2024-05-24 22:11:11 [INFO]: Epoch 183 - training loss: 0.2548, validation loss: 0.0857
2024-05-24 22:11:14 [INFO]: Epoch 184 - training loss: 0.2543, validation loss: 0.0855
2024-05-24 22:11:17 [INFO]: Epoch 185 - training loss: 0.2547, validation loss: 0.0853
2024-05-24 22:11:20 [INFO]: Epoch 186 - training loss: 0.2540, validation loss: 0.0850
2024-05-24 22:11:23 [INFO]: Epoch 187 - training loss: 0.2539, validation loss: 0.0848
2024-05-24 22:11:25 [INFO]: Epoch 188 - training loss: 0.2542, validation loss: 0.0847
2024-05-24 22:11:28 [INFO]: Epoch 189 - training loss: 0.2532, validation loss: 0.0845
2024-05-24 22:11:31 [INFO]: Epoch 190 - training loss: 0.2531, validation loss: 0.0842
2024-05-24 22:11:34 [INFO]: Epoch 191 - training loss: 0.2529, validation loss: 0.0841
2024-05-24 22:11:37 [INFO]: Epoch 192 - training loss: 0.2526, validation loss: 0.0839
2024-05-24 22:11:39 [INFO]: Epoch 193 - training loss: 0.2525, validation loss: 0.0839
2024-05-24 22:11:42 [INFO]: Epoch 194 - training loss: 0.2524, validation loss: 0.0838
2024-05-24 22:11:45 [INFO]: Epoch 195 - training loss: 0.2518, validation loss: 0.0835
2024-05-24 22:11:48 [INFO]: Epoch 196 - training loss: 0.2520, validation loss: 0.0833
2024-05-24 22:11:51 [INFO]: Epoch 197 - training loss: 0.2515, validation loss: 0.0832
2024-05-24 22:11:53 [INFO]: Epoch 198 - training loss: 0.2516, validation loss: 0.0831
2024-05-24 22:11:56 [INFO]: Epoch 199 - training loss: 0.2517, validation loss: 0.0828
2024-05-24 22:11:59 [INFO]: Epoch 200 - training loss: 0.2512, validation loss: 0.0828
2024-05-24 22:12:02 [INFO]: Epoch 201 - training loss: 0.2513, validation loss: 0.0827
2024-05-24 22:12:05 [INFO]: Epoch 202 - training loss: 0.2513, validation loss: 0.0825
2024-05-24 22:12:07 [INFO]: Epoch 203 - training loss: 0.2501, validation loss: 0.0824
2024-05-24 22:12:10 [INFO]: Epoch 204 - training loss: 0.2504, validation loss: 0.0822
2024-05-24 22:12:13 [INFO]: Epoch 205 - training loss: 0.2498, validation loss: 0.0820
2024-05-24 22:12:16 [INFO]: Epoch 206 - training loss: 0.2497, validation loss: 0.0818
2024-05-24 22:12:18 [INFO]: Epoch 207 - training loss: 0.2501, validation loss: 0.0815
2024-05-24 22:12:21 [INFO]: Epoch 208 - training loss: 0.2500, validation loss: 0.0815
2024-05-24 22:12:24 [INFO]: Epoch 209 - training loss: 0.2491, validation loss: 0.0814
2024-05-24 22:12:27 [INFO]: Epoch 210 - training loss: 0.2490, validation loss: 0.0815
2024-05-24 22:12:30 [INFO]: Epoch 211 - training loss: 0.2500, validation loss: 0.0812
2024-05-24 22:12:32 [INFO]: Epoch 212 - training loss: 0.2490, validation loss: 0.0809
2024-05-24 22:12:35 [INFO]: Epoch 213 - training loss: 0.2480, validation loss: 0.0807
2024-05-24 22:12:38 [INFO]: Epoch 214 - training loss: 0.2483, validation loss: 0.0806
2024-05-24 22:12:41 [INFO]: Epoch 215 - training loss: 0.2480, validation loss: 0.0806
2024-05-24 22:12:44 [INFO]: Epoch 216 - training loss: 0.2482, validation loss: 0.0805
2024-05-24 22:12:46 [INFO]: Epoch 217 - training loss: 0.2472, validation loss: 0.0802
2024-05-24 22:12:49 [INFO]: Epoch 218 - training loss: 0.2477, validation loss: 0.0804
2024-05-24 22:12:52 [INFO]: Epoch 219 - training loss: 0.2470, validation loss: 0.0802
2024-05-24 22:12:55 [INFO]: Epoch 220 - training loss: 0.2471, validation loss: 0.0798
2024-05-24 22:12:58 [INFO]: Epoch 221 - training loss: 0.2470, validation loss: 0.0798
2024-05-24 22:13:00 [INFO]: Epoch 222 - training loss: 0.2468, validation loss: 0.0797
2024-05-24 22:13:03 [INFO]: Epoch 223 - training loss: 0.2468, validation loss: 0.0795
2024-05-24 22:13:06 [INFO]: Epoch 224 - training loss: 0.2464, validation loss: 0.0795
2024-05-24 22:13:09 [INFO]: Epoch 225 - training loss: 0.2464, validation loss: 0.0794
2024-05-24 22:13:12 [INFO]: Epoch 226 - training loss: 0.2457, validation loss: 0.0792
2024-05-24 22:13:14 [INFO]: Epoch 227 - training loss: 0.2455, validation loss: 0.0792
2024-05-24 22:13:17 [INFO]: Epoch 228 - training loss: 0.2461, validation loss: 0.0789
2024-05-24 22:13:20 [INFO]: Epoch 229 - training loss: 0.2451, validation loss: 0.0789
2024-05-24 22:13:23 [INFO]: Epoch 230 - training loss: 0.2459, validation loss: 0.0790
2024-05-24 22:13:26 [INFO]: Epoch 231 - training loss: 0.2457, validation loss: 0.0785
2024-05-24 22:13:28 [INFO]: Epoch 232 - training loss: 0.2447, validation loss: 0.0787
2024-05-24 22:13:31 [INFO]: Epoch 233 - training loss: 0.2442, validation loss: 0.0784
2024-05-24 22:13:34 [INFO]: Epoch 234 - training loss: 0.2446, validation loss: 0.0784
2024-05-24 22:13:37 [INFO]: Epoch 235 - training loss: 0.2440, validation loss: 0.0780
2024-05-24 22:13:40 [INFO]: Epoch 236 - training loss: 0.2443, validation loss: 0.0780
2024-05-24 22:13:42 [INFO]: Epoch 237 - training loss: 0.2438, validation loss: 0.0782
2024-05-24 22:13:45 [INFO]: Epoch 238 - training loss: 0.2440, validation loss: 0.0779
2024-05-24 22:13:48 [INFO]: Epoch 239 - training loss: 0.2439, validation loss: 0.0778
2024-05-24 22:13:51 [INFO]: Epoch 240 - training loss: 0.2439, validation loss: 0.0777
2024-05-24 22:13:54 [INFO]: Epoch 241 - training loss: 0.2437, validation loss: 0.0776
2024-05-24 22:13:56 [INFO]: Epoch 242 - training loss: 0.2436, validation loss: 0.0776
2024-05-24 22:13:59 [INFO]: Epoch 243 - training loss: 0.2440, validation loss: 0.0773
2024-05-24 22:14:02 [INFO]: Epoch 244 - training loss: 0.2431, validation loss: 0.0771
2024-05-24 22:14:05 [INFO]: Epoch 245 - training loss: 0.2428, validation loss: 0.0770
2024-05-24 22:14:07 [INFO]: Epoch 246 - training loss: 0.2424, validation loss: 0.0770
2024-05-24 22:14:10 [INFO]: Epoch 247 - training loss: 0.2426, validation loss: 0.0770
2024-05-24 22:14:13 [INFO]: Epoch 248 - training loss: 0.2421, validation loss: 0.0769
2024-05-24 22:14:16 [INFO]: Epoch 249 - training loss: 0.2421, validation loss: 0.0770
2024-05-24 22:14:19 [INFO]: Epoch 250 - training loss: 0.2421, validation loss: 0.0766
2024-05-24 22:14:21 [INFO]: Epoch 251 - training loss: 0.2418, validation loss: 0.0765
2024-05-24 22:14:24 [INFO]: Epoch 252 - training loss: 0.2416, validation loss: 0.0764
2024-05-24 22:14:27 [INFO]: Epoch 253 - training loss: 0.2413, validation loss: 0.0765
2024-05-24 22:14:30 [INFO]: Epoch 254 - training loss: 0.2415, validation loss: 0.0763
2024-05-24 22:14:33 [INFO]: Epoch 255 - training loss: 0.2413, validation loss: 0.0760
2024-05-24 22:14:35 [INFO]: Epoch 256 - training loss: 0.2411, validation loss: 0.0760
2024-05-24 22:14:38 [INFO]: Epoch 257 - training loss: 0.2412, validation loss: 0.0759
2024-05-24 22:14:41 [INFO]: Epoch 258 - training loss: 0.2409, validation loss: 0.0758
2024-05-24 22:14:44 [INFO]: Epoch 259 - training loss: 0.2403, validation loss: 0.0758
2024-05-24 22:14:47 [INFO]: Epoch 260 - training loss: 0.2406, validation loss: 0.0758
2024-05-24 22:14:49 [INFO]: Epoch 261 - training loss: 0.2411, validation loss: 0.0757
2024-05-24 22:14:52 [INFO]: Epoch 262 - training loss: 0.2399, validation loss: 0.0757
2024-05-24 22:14:55 [INFO]: Epoch 263 - training loss: 0.2405, validation loss: 0.0757
2024-05-24 22:14:58 [INFO]: Epoch 264 - training loss: 0.2398, validation loss: 0.0754
2024-05-24 22:15:00 [INFO]: Epoch 265 - training loss: 0.2407, validation loss: 0.0755
2024-05-24 22:15:03 [INFO]: Epoch 266 - training loss: 0.2394, validation loss: 0.0754
2024-05-24 22:15:06 [INFO]: Epoch 267 - training loss: 0.2394, validation loss: 0.0752
2024-05-24 22:15:09 [INFO]: Epoch 268 - training loss: 0.2394, validation loss: 0.0751
2024-05-24 22:15:12 [INFO]: Epoch 269 - training loss: 0.2391, validation loss: 0.0751
2024-05-24 22:15:15 [INFO]: Epoch 270 - training loss: 0.2394, validation loss: 0.0749
2024-05-24 22:15:17 [INFO]: Epoch 271 - training loss: 0.2392, validation loss: 0.0749
2024-05-24 22:15:20 [INFO]: Epoch 272 - training loss: 0.2390, validation loss: 0.0748
2024-05-24 22:15:23 [INFO]: Epoch 273 - training loss: 0.2387, validation loss: 0.0747
2024-05-24 22:15:26 [INFO]: Epoch 274 - training loss: 0.2386, validation loss: 0.0749
2024-05-24 22:15:29 [INFO]: Epoch 275 - training loss: 0.2385, validation loss: 0.0746
2024-05-24 22:15:31 [INFO]: Epoch 276 - training loss: 0.2383, validation loss: 0.0746
2024-05-24 22:15:34 [INFO]: Epoch 277 - training loss: 0.2385, validation loss: 0.0744
2024-05-24 22:15:37 [INFO]: Epoch 278 - training loss: 0.2378, validation loss: 0.0744
2024-05-24 22:15:40 [INFO]: Epoch 279 - training loss: 0.2378, validation loss: 0.0744
2024-05-24 22:15:42 [INFO]: Epoch 280 - training loss: 0.2380, validation loss: 0.0742
2024-05-24 22:15:45 [INFO]: Epoch 281 - training loss: 0.2382, validation loss: 0.0742
2024-05-24 22:15:48 [INFO]: Epoch 282 - training loss: 0.2373, validation loss: 0.0743
2024-05-24 22:15:51 [INFO]: Epoch 283 - training loss: 0.2376, validation loss: 0.0740
2024-05-24 22:15:54 [INFO]: Epoch 284 - training loss: 0.2370, validation loss: 0.0741
2024-05-24 22:15:56 [INFO]: Epoch 285 - training loss: 0.2374, validation loss: 0.0738
2024-05-24 22:15:59 [INFO]: Epoch 286 - training loss: 0.2368, validation loss: 0.0739
2024-05-24 22:16:02 [INFO]: Epoch 287 - training loss: 0.2372, validation loss: 0.0738
2024-05-24 22:16:05 [INFO]: Epoch 288 - training loss: 0.2367, validation loss: 0.0737
2024-05-24 22:16:08 [INFO]: Epoch 289 - training loss: 0.2374, validation loss: 0.0736
2024-05-24 22:16:10 [INFO]: Epoch 290 - training loss: 0.2369, validation loss: 0.0736
2024-05-24 22:16:13 [INFO]: Epoch 291 - training loss: 0.2366, validation loss: 0.0739
2024-05-24 22:16:16 [INFO]: Epoch 292 - training loss: 0.2362, validation loss: 0.0734
2024-05-24 22:16:19 [INFO]: Epoch 293 - training loss: 0.2363, validation loss: 0.0735
2024-05-24 22:16:22 [INFO]: Epoch 294 - training loss: 0.2362, validation loss: 0.0736
2024-05-24 22:16:24 [INFO]: Epoch 295 - training loss: 0.2359, validation loss: 0.0734
2024-05-24 22:16:27 [INFO]: Epoch 296 - training loss: 0.2358, validation loss: 0.0733
2024-05-24 22:16:30 [INFO]: Epoch 297 - training loss: 0.2362, validation loss: 0.0733
2024-05-24 22:16:33 [INFO]: Epoch 298 - training loss: 0.2357, validation loss: 0.0731
2024-05-24 22:16:35 [INFO]: Epoch 299 - training loss: 0.2358, validation loss: 0.0731
2024-05-24 22:16:38 [INFO]: Epoch 300 - training loss: 0.2356, validation loss: 0.0733
2024-05-24 22:16:38 [INFO]: Finished training. The best model is from epoch#298.
2024-05-24 22:16:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240524_T220239/BRITS.pypots
2024-05-24 22:16:39 [INFO]: BRITS on Air-Quality: MAE=0.1371, MSE=0.0950
2024-05-24 22:16:39 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-24 22:16:39 [INFO]: Using the given device: cuda:0
2024-05-24 22:16:39 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639
2024-05-24 22:16:39 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/tensorboard
2024-05-24 22:16:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-24 22:16:44 [INFO]: Epoch 001 - training loss: 1.4348, validation loss: 0.8103
2024-05-24 22:16:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch1_loss0.8103061437606811.pypots
2024-05-24 22:16:48 [INFO]: Epoch 002 - training loss: 1.0547, validation loss: 0.7494
2024-05-24 22:16:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch2_loss0.7494273006916046.pypots
2024-05-24 22:16:51 [INFO]: Epoch 003 - training loss: 0.9782, validation loss: 0.7277
2024-05-24 22:16:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch3_loss0.727734050154686.pypots
2024-05-24 22:16:55 [INFO]: Epoch 004 - training loss: 0.9661, validation loss: 0.7141
2024-05-24 22:16:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch4_loss0.7140811860561371.pypots
2024-05-24 22:16:59 [INFO]: Epoch 005 - training loss: 0.9284, validation loss: 0.7054
2024-05-24 22:16:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch5_loss0.7053565055131912.pypots
2024-05-24 22:17:03 [INFO]: Epoch 006 - training loss: 0.9448, validation loss: 0.6983
2024-05-24 22:17:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch6_loss0.6983151406049728.pypots
2024-05-24 22:17:07 [INFO]: Epoch 007 - training loss: 0.9202, validation loss: 0.6924
2024-05-24 22:17:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch7_loss0.6923993349075317.pypots
2024-05-24 22:17:11 [INFO]: Epoch 008 - training loss: 0.9249, validation loss: 0.6892
2024-05-24 22:17:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch8_loss0.6892468184232712.pypots
2024-05-24 22:17:14 [INFO]: Epoch 009 - training loss: 0.9116, validation loss: 0.6865
2024-05-24 22:17:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch9_loss0.6865129351615906.pypots
2024-05-24 22:17:18 [INFO]: Epoch 010 - training loss: 0.9014, validation loss: 0.6830
2024-05-24 22:17:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch10_loss0.6829844653606415.pypots
2024-05-24 22:17:22 [INFO]: Epoch 011 - training loss: 0.8953, validation loss: 0.6814
2024-05-24 22:17:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch11_loss0.6814293026924133.pypots
2024-05-24 22:17:26 [INFO]: Epoch 012 - training loss: 0.8883, validation loss: 0.6803
2024-05-24 22:17:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch12_loss0.6803210884332657.pypots
2024-05-24 22:17:30 [INFO]: Epoch 013 - training loss: 0.8931, validation loss: 0.6790
2024-05-24 22:17:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch13_loss0.6789777606725693.pypots
2024-05-24 22:17:34 [INFO]: Epoch 014 - training loss: 0.8878, validation loss: 0.6778
2024-05-24 22:17:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch14_loss0.6777962505817413.pypots
2024-05-24 22:17:38 [INFO]: Epoch 015 - training loss: 0.8815, validation loss: 0.6773
2024-05-24 22:17:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch15_loss0.6773464918136597.pypots
2024-05-24 22:17:41 [INFO]: Epoch 016 - training loss: 0.8757, validation loss: 0.6766
2024-05-24 22:17:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch16_loss0.676567342877388.pypots
2024-05-24 22:17:45 [INFO]: Epoch 017 - training loss: 0.8754, validation loss: 0.6768
2024-05-24 22:17:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch17_loss0.6768105804920197.pypots
2024-05-24 22:17:49 [INFO]: Epoch 018 - training loss: 0.8727, validation loss: 0.6758
2024-05-24 22:17:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch18_loss0.675839501619339.pypots
2024-05-24 22:17:53 [INFO]: Epoch 019 - training loss: 0.8759, validation loss: 0.6756
2024-05-24 22:17:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch19_loss0.6755771040916443.pypots
2024-05-24 22:17:57 [INFO]: Epoch 020 - training loss: 0.8610, validation loss: 0.6760
2024-05-24 22:17:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch20_loss0.6759908944368362.pypots
2024-05-24 22:18:01 [INFO]: Epoch 021 - training loss: 0.8548, validation loss: 0.6755
2024-05-24 22:18:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch21_loss0.6755208790302276.pypots
2024-05-24 22:18:05 [INFO]: Epoch 022 - training loss: 0.8573, validation loss: 0.6760
2024-05-24 22:18:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch22_loss0.6759892612695694.pypots
2024-05-24 22:18:08 [INFO]: Epoch 023 - training loss: 0.8542, validation loss: 0.6745
2024-05-24 22:18:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch23_loss0.6744690597057342.pypots
2024-05-24 22:18:12 [INFO]: Epoch 024 - training loss: 0.8665, validation loss: 0.6754
2024-05-24 22:18:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch24_loss0.6753782570362091.pypots
2024-05-24 22:18:16 [INFO]: Epoch 025 - training loss: 0.8563, validation loss: 0.6746
2024-05-24 22:18:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch25_loss0.6746343940496444.pypots
2024-05-24 22:18:20 [INFO]: Epoch 026 - training loss: 0.8501, validation loss: 0.6740
2024-05-24 22:18:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch26_loss0.6739942520856858.pypots
2024-05-24 22:18:24 [INFO]: Epoch 027 - training loss: 0.8469, validation loss: 0.6759
2024-05-24 22:18:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch27_loss0.6759162724018097.pypots
2024-05-24 22:18:28 [INFO]: Epoch 028 - training loss: 0.8404, validation loss: 0.6768
2024-05-24 22:18:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch28_loss0.6768311381340026.pypots
2024-05-24 22:18:31 [INFO]: Epoch 029 - training loss: 0.8397, validation loss: 0.6743
2024-05-24 22:18:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch29_loss0.6742982059717179.pypots
2024-05-24 22:18:35 [INFO]: Epoch 030 - training loss: 0.8345, validation loss: 0.6754
2024-05-24 22:18:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch30_loss0.6754102021455765.pypots
2024-05-24 22:18:39 [INFO]: Epoch 031 - training loss: 0.8446, validation loss: 0.6753
2024-05-24 22:18:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch31_loss0.6752724051475525.pypots
2024-05-24 22:18:43 [INFO]: Epoch 032 - training loss: 0.8351, validation loss: 0.6777
2024-05-24 22:18:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch32_loss0.6777237504720688.pypots
2024-05-24 22:18:47 [INFO]: Epoch 033 - training loss: 0.8333, validation loss: 0.6778
2024-05-24 22:18:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch33_loss0.6778175413608551.pypots
2024-05-24 22:18:51 [INFO]: Epoch 034 - training loss: 0.8361, validation loss: 0.6782
2024-05-24 22:18:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch34_loss0.6781924575567245.pypots
2024-05-24 22:18:55 [INFO]: Epoch 035 - training loss: 0.8233, validation loss: 0.6800
2024-05-24 22:18:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch35_loss0.6799700081348419.pypots
2024-05-24 22:18:58 [INFO]: Epoch 036 - training loss: 0.8170, validation loss: 0.6767
2024-05-24 22:18:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN_epoch36_loss0.6767026662826539.pypots
2024-05-24 22:18:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:18:58 [INFO]: Finished training. The best model is from epoch#26.
2024-05-24 22:18:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240524_T221639/MRNN.pypots
2024-05-24 22:18:59 [INFO]: MRNN on Air-Quality: MAE=0.5158, MSE=0.5922
2024-05-24 22:18:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-24 22:18:59 [INFO]: Using the given device: cpu
2024-05-24 22:18:59 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2148
2024-05-24 22:18:59 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-24 22:18:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-24 22:18:59 [INFO]: Median on Air-Quality: MAE=0.6653, MSE=0.9982
2024-05-24 22:18:59 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-24 22:18:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-24 22:18:59 [INFO]: Mean on Air-Quality: MAE=0.6953, MSE=0.9349
2024-05-24 22:18:59 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-24 22:18:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-24 22:18:59 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 22:19:00 [INFO]: Using the given device: cuda:0
2024-05-24 22:19:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240524_T221900
2024-05-24 22:19:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240524_T221900/tensorboard
2024-05-24 22:19:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 22:19:01 [INFO]: Epoch 001 - training loss: 1.0387, validation loss: 0.5162
2024-05-24 22:19:01 [INFO]: Epoch 002 - training loss: 0.7426, validation loss: 0.3932
2024-05-24 22:19:02 [INFO]: Epoch 003 - training loss: 0.6367, validation loss: 0.3133
2024-05-24 22:19:03 [INFO]: Epoch 004 - training loss: 0.5663, validation loss: 0.2720
2024-05-24 22:19:03 [INFO]: Epoch 005 - training loss: 0.5163, validation loss: 0.2452
2024-05-24 22:19:04 [INFO]: Epoch 006 - training loss: 0.4810, validation loss: 0.2291
2024-05-24 22:19:05 [INFO]: Epoch 007 - training loss: 0.4545, validation loss: 0.2165
2024-05-24 22:19:05 [INFO]: Epoch 008 - training loss: 0.4359, validation loss: 0.2087
2024-05-24 22:19:06 [INFO]: Epoch 009 - training loss: 0.4207, validation loss: 0.2017
2024-05-24 22:19:06 [INFO]: Epoch 010 - training loss: 0.4076, validation loss: 0.1952
2024-05-24 22:19:07 [INFO]: Epoch 011 - training loss: 0.3968, validation loss: 0.1917
2024-05-24 22:19:08 [INFO]: Epoch 012 - training loss: 0.3881, validation loss: 0.1853
2024-05-24 22:19:08 [INFO]: Epoch 013 - training loss: 0.3803, validation loss: 0.1829
2024-05-24 22:19:09 [INFO]: Epoch 014 - training loss: 0.3732, validation loss: 0.1786
2024-05-24 22:19:09 [INFO]: Epoch 015 - training loss: 0.3659, validation loss: 0.1762
2024-05-24 22:19:10 [INFO]: Epoch 016 - training loss: 0.3604, validation loss: 0.1722
2024-05-24 22:19:11 [INFO]: Epoch 017 - training loss: 0.3536, validation loss: 0.1696
2024-05-24 22:19:11 [INFO]: Epoch 018 - training loss: 0.3496, validation loss: 0.1664
2024-05-24 22:19:12 [INFO]: Epoch 019 - training loss: 0.3443, validation loss: 0.1662
2024-05-24 22:19:13 [INFO]: Epoch 020 - training loss: 0.3415, validation loss: 0.1629
2024-05-24 22:19:13 [INFO]: Epoch 021 - training loss: 0.3372, validation loss: 0.1602
2024-05-24 22:19:14 [INFO]: Epoch 022 - training loss: 0.3318, validation loss: 0.1590
2024-05-24 22:19:14 [INFO]: Epoch 023 - training loss: 0.3283, validation loss: 0.1575
2024-05-24 22:19:15 [INFO]: Epoch 024 - training loss: 0.3245, validation loss: 0.1550
2024-05-24 22:19:16 [INFO]: Epoch 025 - training loss: 0.3217, validation loss: 0.1550
2024-05-24 22:19:16 [INFO]: Epoch 026 - training loss: 0.3218, validation loss: 0.1532
2024-05-24 22:19:17 [INFO]: Epoch 027 - training loss: 0.3175, validation loss: 0.1508
2024-05-24 22:19:17 [INFO]: Epoch 028 - training loss: 0.3135, validation loss: 0.1479
2024-05-24 22:19:18 [INFO]: Epoch 029 - training loss: 0.3095, validation loss: 0.1484
2024-05-24 22:19:19 [INFO]: Epoch 030 - training loss: 0.3093, validation loss: 0.1454
2024-05-24 22:19:19 [INFO]: Epoch 031 - training loss: 0.3053, validation loss: 0.1438
2024-05-24 22:19:20 [INFO]: Epoch 032 - training loss: 0.3029, validation loss: 0.1420
2024-05-24 22:19:20 [INFO]: Epoch 033 - training loss: 0.3005, validation loss: 0.1407
2024-05-24 22:19:21 [INFO]: Epoch 034 - training loss: 0.2986, validation loss: 0.1397
2024-05-24 22:19:22 [INFO]: Epoch 035 - training loss: 0.2955, validation loss: 0.1384
2024-05-24 22:19:22 [INFO]: Epoch 036 - training loss: 0.2940, validation loss: 0.1357
2024-05-24 22:19:23 [INFO]: Epoch 037 - training loss: 0.2907, validation loss: 0.1358
2024-05-24 22:19:23 [INFO]: Epoch 038 - training loss: 0.2884, validation loss: 0.1355
2024-05-24 22:19:24 [INFO]: Epoch 039 - training loss: 0.2869, validation loss: 0.1323
2024-05-24 22:19:25 [INFO]: Epoch 040 - training loss: 0.2848, validation loss: 0.1313
2024-05-24 22:19:25 [INFO]: Epoch 041 - training loss: 0.2828, validation loss: 0.1309
2024-05-24 22:19:26 [INFO]: Epoch 042 - training loss: 0.2807, validation loss: 0.1295
2024-05-24 22:19:26 [INFO]: Epoch 043 - training loss: 0.2797, validation loss: 0.1289
2024-05-24 22:19:27 [INFO]: Epoch 044 - training loss: 0.2773, validation loss: 0.1281
2024-05-24 22:19:28 [INFO]: Epoch 045 - training loss: 0.2755, validation loss: 0.1268
2024-05-24 22:19:28 [INFO]: Epoch 046 - training loss: 0.2744, validation loss: 0.1252
2024-05-24 22:19:29 [INFO]: Epoch 047 - training loss: 0.2741, validation loss: 0.1245
2024-05-24 22:19:29 [INFO]: Epoch 048 - training loss: 0.2716, validation loss: 0.1233
2024-05-24 22:19:30 [INFO]: Epoch 049 - training loss: 0.2699, validation loss: 0.1229
2024-05-24 22:19:31 [INFO]: Epoch 050 - training loss: 0.2673, validation loss: 0.1234
2024-05-24 22:19:31 [INFO]: Epoch 051 - training loss: 0.2654, validation loss: 0.1217
2024-05-24 22:19:32 [INFO]: Epoch 052 - training loss: 0.2642, validation loss: 0.1209
2024-05-24 22:19:33 [INFO]: Epoch 053 - training loss: 0.2630, validation loss: 0.1198
2024-05-24 22:19:33 [INFO]: Epoch 054 - training loss: 0.2627, validation loss: 0.1202
2024-05-24 22:19:34 [INFO]: Epoch 055 - training loss: 0.2606, validation loss: 0.1186
2024-05-24 22:19:34 [INFO]: Epoch 056 - training loss: 0.2593, validation loss: 0.1180
2024-05-24 22:19:35 [INFO]: Epoch 057 - training loss: 0.2575, validation loss: 0.1174
2024-05-24 22:19:36 [INFO]: Epoch 058 - training loss: 0.2555, validation loss: 0.1163
2024-05-24 22:19:36 [INFO]: Epoch 059 - training loss: 0.2535, validation loss: 0.1162
2024-05-24 22:19:37 [INFO]: Epoch 060 - training loss: 0.2532, validation loss: 0.1165
2024-05-24 22:19:37 [INFO]: Epoch 061 - training loss: 0.2521, validation loss: 0.1154
2024-05-24 22:19:38 [INFO]: Epoch 062 - training loss: 0.2508, validation loss: 0.1155
2024-05-24 22:19:39 [INFO]: Epoch 063 - training loss: 0.2498, validation loss: 0.1133
2024-05-24 22:19:39 [INFO]: Epoch 064 - training loss: 0.2483, validation loss: 0.1137
2024-05-24 22:19:40 [INFO]: Epoch 065 - training loss: 0.2467, validation loss: 0.1140
2024-05-24 22:19:40 [INFO]: Epoch 066 - training loss: 0.2449, validation loss: 0.1135
2024-05-24 22:19:41 [INFO]: Epoch 067 - training loss: 0.2441, validation loss: 0.1129
2024-05-24 22:19:42 [INFO]: Epoch 068 - training loss: 0.2440, validation loss: 0.1122
2024-05-24 22:19:42 [INFO]: Epoch 069 - training loss: 0.2416, validation loss: 0.1122
2024-05-24 22:19:43 [INFO]: Epoch 070 - training loss: 0.2403, validation loss: 0.1115
2024-05-24 22:19:43 [INFO]: Epoch 071 - training loss: 0.2398, validation loss: 0.1117
2024-05-24 22:19:44 [INFO]: Epoch 072 - training loss: 0.2388, validation loss: 0.1106
2024-05-24 22:19:45 [INFO]: Epoch 073 - training loss: 0.2371, validation loss: 0.1100
2024-05-24 22:19:45 [INFO]: Epoch 074 - training loss: 0.2354, validation loss: 0.1111
2024-05-24 22:19:46 [INFO]: Epoch 075 - training loss: 0.2350, validation loss: 0.1096
2024-05-24 22:19:46 [INFO]: Epoch 076 - training loss: 0.2336, validation loss: 0.1085
2024-05-24 22:19:47 [INFO]: Epoch 077 - training loss: 0.2330, validation loss: 0.1084
2024-05-24 22:19:48 [INFO]: Epoch 078 - training loss: 0.2313, validation loss: 0.1089
2024-05-24 22:19:48 [INFO]: Epoch 079 - training loss: 0.2305, validation loss: 0.1072
2024-05-24 22:19:49 [INFO]: Epoch 080 - training loss: 0.2299, validation loss: 0.1072
2024-05-24 22:19:49 [INFO]: Epoch 081 - training loss: 0.2287, validation loss: 0.1070
2024-05-24 22:19:50 [INFO]: Epoch 082 - training loss: 0.2275, validation loss: 0.1066
2024-05-24 22:19:51 [INFO]: Epoch 083 - training loss: 0.2264, validation loss: 0.1069
2024-05-24 22:19:51 [INFO]: Epoch 084 - training loss: 0.2259, validation loss: 0.1071
2024-05-24 22:19:52 [INFO]: Epoch 085 - training loss: 0.2268, validation loss: 0.1053
2024-05-24 22:19:52 [INFO]: Epoch 086 - training loss: 0.2248, validation loss: 0.1059
2024-05-24 22:19:53 [INFO]: Epoch 087 - training loss: 0.2233, validation loss: 0.1057
2024-05-24 22:19:54 [INFO]: Epoch 088 - training loss: 0.2222, validation loss: 0.1057
2024-05-24 22:19:54 [INFO]: Epoch 089 - training loss: 0.2213, validation loss: 0.1048
2024-05-24 22:19:55 [INFO]: Epoch 090 - training loss: 0.2202, validation loss: 0.1048
2024-05-24 22:19:55 [INFO]: Epoch 091 - training loss: 0.2203, validation loss: 0.1046
2024-05-24 22:19:56 [INFO]: Epoch 092 - training loss: 0.2197, validation loss: 0.1042
2024-05-24 22:19:57 [INFO]: Epoch 093 - training loss: 0.2187, validation loss: 0.1048
2024-05-24 22:19:57 [INFO]: Epoch 094 - training loss: 0.2177, validation loss: 0.1041
2024-05-24 22:19:58 [INFO]: Epoch 095 - training loss: 0.2173, validation loss: 0.1034
2024-05-24 22:19:58 [INFO]: Epoch 096 - training loss: 0.2164, validation loss: 0.1027
2024-05-24 22:19:59 [INFO]: Epoch 097 - training loss: 0.2162, validation loss: 0.1031
2024-05-24 22:20:00 [INFO]: Epoch 098 - training loss: 0.2157, validation loss: 0.1028
2024-05-24 22:20:00 [INFO]: Epoch 099 - training loss: 0.2142, validation loss: 0.1036
2024-05-24 22:20:01 [INFO]: Epoch 100 - training loss: 0.2135, validation loss: 0.1012
2024-05-24 22:20:01 [INFO]: Epoch 101 - training loss: 0.2133, validation loss: 0.1020
2024-05-24 22:20:02 [INFO]: Epoch 102 - training loss: 0.2137, validation loss: 0.1016
2024-05-24 22:20:03 [INFO]: Epoch 103 - training loss: 0.2122, validation loss: 0.1024
2024-05-24 22:20:03 [INFO]: Epoch 104 - training loss: 0.2112, validation loss: 0.1019
2024-05-24 22:20:04 [INFO]: Epoch 105 - training loss: 0.2105, validation loss: 0.1004
2024-05-24 22:20:04 [INFO]: Epoch 106 - training loss: 0.2099, validation loss: 0.1004
2024-05-24 22:20:05 [INFO]: Epoch 107 - training loss: 0.2099, validation loss: 0.1005
2024-05-24 22:20:06 [INFO]: Epoch 108 - training loss: 0.2082, validation loss: 0.1022
2024-05-24 22:20:06 [INFO]: Epoch 109 - training loss: 0.2074, validation loss: 0.1002
2024-05-24 22:20:07 [INFO]: Epoch 110 - training loss: 0.2084, validation loss: 0.1007
2024-05-24 22:20:07 [INFO]: Epoch 111 - training loss: 0.2079, validation loss: 0.0993
2024-05-24 22:20:08 [INFO]: Epoch 112 - training loss: 0.2066, validation loss: 0.1003
2024-05-24 22:20:09 [INFO]: Epoch 113 - training loss: 0.2063, validation loss: 0.0991
2024-05-24 22:20:09 [INFO]: Epoch 114 - training loss: 0.2049, validation loss: 0.0987
2024-05-24 22:20:10 [INFO]: Epoch 115 - training loss: 0.2043, validation loss: 0.1004
2024-05-24 22:20:10 [INFO]: Epoch 116 - training loss: 0.2039, validation loss: 0.0991
2024-05-24 22:20:11 [INFO]: Epoch 117 - training loss: 0.2025, validation loss: 0.0988
2024-05-24 22:20:12 [INFO]: Epoch 118 - training loss: 0.2030, validation loss: 0.0990
2024-05-24 22:20:12 [INFO]: Epoch 119 - training loss: 0.2027, validation loss: 0.0986
2024-05-24 22:20:13 [INFO]: Epoch 120 - training loss: 0.2004, validation loss: 0.0981
2024-05-24 22:20:13 [INFO]: Epoch 121 - training loss: 0.2019, validation loss: 0.0993
2024-05-24 22:20:14 [INFO]: Epoch 122 - training loss: 0.2009, validation loss: 0.0975
2024-05-24 22:20:15 [INFO]: Epoch 123 - training loss: 0.2000, validation loss: 0.0971
2024-05-24 22:20:15 [INFO]: Epoch 124 - training loss: 0.2000, validation loss: 0.0983
2024-05-24 22:20:16 [INFO]: Epoch 125 - training loss: 0.1991, validation loss: 0.0983
2024-05-24 22:20:16 [INFO]: Epoch 126 - training loss: 0.1980, validation loss: 0.0989
2024-05-24 22:20:17 [INFO]: Epoch 127 - training loss: 0.1983, validation loss: 0.0995
2024-05-24 22:20:18 [INFO]: Epoch 128 - training loss: 0.1974, validation loss: 0.0982
2024-05-24 22:20:18 [INFO]: Epoch 129 - training loss: 0.1976, validation loss: 0.0977
2024-05-24 22:20:19 [INFO]: Epoch 130 - training loss: 0.1970, validation loss: 0.0969
2024-05-24 22:20:19 [INFO]: Epoch 131 - training loss: 0.1960, validation loss: 0.0969
2024-05-24 22:20:20 [INFO]: Epoch 132 - training loss: 0.1955, validation loss: 0.0973
2024-05-24 22:20:21 [INFO]: Epoch 133 - training loss: 0.1959, validation loss: 0.0987
2024-05-24 22:20:21 [INFO]: Epoch 134 - training loss: 0.1947, validation loss: 0.0965
2024-05-24 22:20:22 [INFO]: Epoch 135 - training loss: 0.1938, validation loss: 0.0962
2024-05-24 22:20:22 [INFO]: Epoch 136 - training loss: 0.1933, validation loss: 0.0957
2024-05-24 22:20:23 [INFO]: Epoch 137 - training loss: 0.1928, validation loss: 0.0977
2024-05-24 22:20:24 [INFO]: Epoch 138 - training loss: 0.1922, validation loss: 0.0961
2024-05-24 22:20:24 [INFO]: Epoch 139 - training loss: 0.1923, validation loss: 0.0981
2024-05-24 22:20:25 [INFO]: Epoch 140 - training loss: 0.1924, validation loss: 0.0960
2024-05-24 22:20:25 [INFO]: Epoch 141 - training loss: 0.1920, validation loss: 0.0978
2024-05-24 22:20:26 [INFO]: Epoch 142 - training loss: 0.1913, validation loss: 0.0958
2024-05-24 22:20:27 [INFO]: Epoch 143 - training loss: 0.1903, validation loss: 0.0960
2024-05-24 22:20:27 [INFO]: Epoch 144 - training loss: 0.1906, validation loss: 0.0954
2024-05-24 22:20:28 [INFO]: Epoch 145 - training loss: 0.1895, validation loss: 0.0965
2024-05-24 22:20:28 [INFO]: Epoch 146 - training loss: 0.1893, validation loss: 0.0957
2024-05-24 22:20:29 [INFO]: Epoch 147 - training loss: 0.1886, validation loss: 0.0959
2024-05-24 22:20:30 [INFO]: Epoch 148 - training loss: 0.1894, validation loss: 0.0962
2024-05-24 22:20:30 [INFO]: Epoch 149 - training loss: 0.1896, validation loss: 0.0960
2024-05-24 22:20:31 [INFO]: Epoch 150 - training loss: 0.1875, validation loss: 0.0943
2024-05-24 22:20:32 [INFO]: Epoch 151 - training loss: 0.1871, validation loss: 0.0951
2024-05-24 22:20:32 [INFO]: Epoch 152 - training loss: 0.1864, validation loss: 0.0953
2024-05-24 22:20:33 [INFO]: Epoch 153 - training loss: 0.1872, validation loss: 0.0957
2024-05-24 22:20:33 [INFO]: Epoch 154 - training loss: 0.1855, validation loss: 0.0947
2024-05-24 22:20:34 [INFO]: Epoch 155 - training loss: 0.1858, validation loss: 0.0945
2024-05-24 22:20:35 [INFO]: Epoch 156 - training loss: 0.1854, validation loss: 0.0947
2024-05-24 22:20:35 [INFO]: Epoch 157 - training loss: 0.1845, validation loss: 0.0948
2024-05-24 22:20:36 [INFO]: Epoch 158 - training loss: 0.1845, validation loss: 0.0945
2024-05-24 22:20:36 [INFO]: Epoch 159 - training loss: 0.1836, validation loss: 0.0943
2024-05-24 22:20:37 [INFO]: Epoch 160 - training loss: 0.1829, validation loss: 0.0942
2024-05-24 22:20:38 [INFO]: Epoch 161 - training loss: 0.1820, validation loss: 0.0939
2024-05-24 22:20:38 [INFO]: Epoch 162 - training loss: 0.1833, validation loss: 0.0947
2024-05-24 22:20:39 [INFO]: Epoch 163 - training loss: 0.1830, validation loss: 0.0942
2024-05-24 22:20:39 [INFO]: Epoch 164 - training loss: 0.1821, validation loss: 0.0939
2024-05-24 22:20:40 [INFO]: Epoch 165 - training loss: 0.1816, validation loss: 0.0943
2024-05-24 22:20:41 [INFO]: Epoch 166 - training loss: 0.1824, validation loss: 0.0946
2024-05-24 22:20:41 [INFO]: Epoch 167 - training loss: 0.1829, validation loss: 0.0934
2024-05-24 22:20:42 [INFO]: Epoch 168 - training loss: 0.1815, validation loss: 0.0946
2024-05-24 22:20:42 [INFO]: Epoch 169 - training loss: 0.1801, validation loss: 0.0950
2024-05-24 22:20:43 [INFO]: Epoch 170 - training loss: 0.1810, validation loss: 0.0935
2024-05-24 22:20:44 [INFO]: Epoch 171 - training loss: 0.1806, validation loss: 0.0947
2024-05-24 22:20:44 [INFO]: Epoch 172 - training loss: 0.1796, validation loss: 0.0931
2024-05-24 22:20:45 [INFO]: Epoch 173 - training loss: 0.1794, validation loss: 0.0928
2024-05-24 22:20:45 [INFO]: Epoch 174 - training loss: 0.1785, validation loss: 0.0925
2024-05-24 22:20:46 [INFO]: Epoch 175 - training loss: 0.1771, validation loss: 0.0929
2024-05-24 22:20:47 [INFO]: Epoch 176 - training loss: 0.1770, validation loss: 0.0933
2024-05-24 22:20:47 [INFO]: Epoch 177 - training loss: 0.1776, validation loss: 0.0941
2024-05-24 22:20:48 [INFO]: Epoch 178 - training loss: 0.1778, validation loss: 0.0938
2024-05-24 22:20:48 [INFO]: Epoch 179 - training loss: 0.1767, validation loss: 0.0927
2024-05-24 22:20:49 [INFO]: Epoch 180 - training loss: 0.1767, validation loss: 0.0926
2024-05-24 22:20:50 [INFO]: Epoch 181 - training loss: 0.1771, validation loss: 0.0926
2024-05-24 22:20:50 [INFO]: Epoch 182 - training loss: 0.1762, validation loss: 0.0927
2024-05-24 22:20:51 [INFO]: Epoch 183 - training loss: 0.1762, validation loss: 0.0928
2024-05-24 22:20:51 [INFO]: Epoch 184 - training loss: 0.1751, validation loss: 0.0930
2024-05-24 22:20:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:20:51 [INFO]: Finished training. The best model is from epoch#174.
2024-05-24 22:20:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240524_T221900/SAITS.pypots
2024-05-24 22:20:52 [INFO]: SAITS on Air-Quality: MAE=0.1502, MSE=0.1019
2024-05-24 22:20:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-24 22:20:52 [INFO]: Using the given device: cuda:0
2024-05-24 22:20:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240524_T222052
2024-05-24 22:20:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240524_T222052/tensorboard
2024-05-24 22:20:52 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 22:20:52 [INFO]: Epoch 001 - training loss: 0.8920, validation loss: 0.4475
2024-05-24 22:20:52 [INFO]: Epoch 002 - training loss: 0.5519, validation loss: 0.3246
2024-05-24 22:20:52 [INFO]: Epoch 003 - training loss: 0.4640, validation loss: 0.2630
2024-05-24 22:20:53 [INFO]: Epoch 004 - training loss: 0.4130, validation loss: 0.2421
2024-05-24 22:20:53 [INFO]: Epoch 005 - training loss: 0.3835, validation loss: 0.2284
2024-05-24 22:20:53 [INFO]: Epoch 006 - training loss: 0.3598, validation loss: 0.2166
2024-05-24 22:20:53 [INFO]: Epoch 007 - training loss: 0.3443, validation loss: 0.2107
2024-05-24 22:20:54 [INFO]: Epoch 008 - training loss: 0.3340, validation loss: 0.2009
2024-05-24 22:20:54 [INFO]: Epoch 009 - training loss: 0.3262, validation loss: 0.1960
2024-05-24 22:20:54 [INFO]: Epoch 010 - training loss: 0.3125, validation loss: 0.1901
2024-05-24 22:20:54 [INFO]: Epoch 011 - training loss: 0.3081, validation loss: 0.1887
2024-05-24 22:20:55 [INFO]: Epoch 012 - training loss: 0.3029, validation loss: 0.1802
2024-05-24 22:20:55 [INFO]: Epoch 013 - training loss: 0.2968, validation loss: 0.1804
2024-05-24 22:20:55 [INFO]: Epoch 014 - training loss: 0.2899, validation loss: 0.1747
2024-05-24 22:20:55 [INFO]: Epoch 015 - training loss: 0.2867, validation loss: 0.1739
2024-05-24 22:20:56 [INFO]: Epoch 016 - training loss: 0.2799, validation loss: 0.1689
2024-05-24 22:20:56 [INFO]: Epoch 017 - training loss: 0.2763, validation loss: 0.1667
2024-05-24 22:20:56 [INFO]: Epoch 018 - training loss: 0.2739, validation loss: 0.1656
2024-05-24 22:20:56 [INFO]: Epoch 019 - training loss: 0.2704, validation loss: 0.1643
2024-05-24 22:20:57 [INFO]: Epoch 020 - training loss: 0.2660, validation loss: 0.1592
2024-05-24 22:20:57 [INFO]: Epoch 021 - training loss: 0.2618, validation loss: 0.1576
2024-05-24 22:20:57 [INFO]: Epoch 022 - training loss: 0.2596, validation loss: 0.1559
2024-05-24 22:20:57 [INFO]: Epoch 023 - training loss: 0.2586, validation loss: 0.1553
2024-05-24 22:20:58 [INFO]: Epoch 024 - training loss: 0.2524, validation loss: 0.1536
2024-05-24 22:20:58 [INFO]: Epoch 025 - training loss: 0.2512, validation loss: 0.1521
2024-05-24 22:20:58 [INFO]: Epoch 026 - training loss: 0.2507, validation loss: 0.1510
2024-05-24 22:20:58 [INFO]: Epoch 027 - training loss: 0.2465, validation loss: 0.1491
2024-05-24 22:20:59 [INFO]: Epoch 028 - training loss: 0.2459, validation loss: 0.1476
2024-05-24 22:20:59 [INFO]: Epoch 029 - training loss: 0.2425, validation loss: 0.1474
2024-05-24 22:20:59 [INFO]: Epoch 030 - training loss: 0.2418, validation loss: 0.1458
2024-05-24 22:20:59 [INFO]: Epoch 031 - training loss: 0.2440, validation loss: 0.1467
2024-05-24 22:21:00 [INFO]: Epoch 032 - training loss: 0.2360, validation loss: 0.1439
2024-05-24 22:21:00 [INFO]: Epoch 033 - training loss: 0.2324, validation loss: 0.1428
2024-05-24 22:21:00 [INFO]: Epoch 034 - training loss: 0.2342, validation loss: 0.1440
2024-05-24 22:21:00 [INFO]: Epoch 035 - training loss: 0.2297, validation loss: 0.1408
2024-05-24 22:21:01 [INFO]: Epoch 036 - training loss: 0.2284, validation loss: 0.1408
2024-05-24 22:21:01 [INFO]: Epoch 037 - training loss: 0.2268, validation loss: 0.1403
2024-05-24 22:21:01 [INFO]: Epoch 038 - training loss: 0.2273, validation loss: 0.1386
2024-05-24 22:21:01 [INFO]: Epoch 039 - training loss: 0.2226, validation loss: 0.1376
2024-05-24 22:21:02 [INFO]: Epoch 040 - training loss: 0.2222, validation loss: 0.1370
2024-05-24 22:21:02 [INFO]: Epoch 041 - training loss: 0.2200, validation loss: 0.1379
2024-05-24 22:21:02 [INFO]: Epoch 042 - training loss: 0.2181, validation loss: 0.1374
2024-05-24 22:21:02 [INFO]: Epoch 043 - training loss: 0.2179, validation loss: 0.1349
2024-05-24 22:21:03 [INFO]: Epoch 044 - training loss: 0.2153, validation loss: 0.1383
2024-05-24 22:21:03 [INFO]: Epoch 045 - training loss: 0.2140, validation loss: 0.1348
2024-05-24 22:21:03 [INFO]: Epoch 046 - training loss: 0.2128, validation loss: 0.1339
2024-05-24 22:21:03 [INFO]: Epoch 047 - training loss: 0.2105, validation loss: 0.1330
2024-05-24 22:21:04 [INFO]: Epoch 048 - training loss: 0.2099, validation loss: 0.1351
2024-05-24 22:21:04 [INFO]: Epoch 049 - training loss: 0.2105, validation loss: 0.1330
2024-05-24 22:21:04 [INFO]: Epoch 050 - training loss: 0.2101, validation loss: 0.1348
2024-05-24 22:21:04 [INFO]: Epoch 051 - training loss: 0.2093, validation loss: 0.1325
2024-05-24 22:21:05 [INFO]: Epoch 052 - training loss: 0.2059, validation loss: 0.1310
2024-05-24 22:21:05 [INFO]: Epoch 053 - training loss: 0.2041, validation loss: 0.1299
2024-05-24 22:21:05 [INFO]: Epoch 054 - training loss: 0.2021, validation loss: 0.1293
2024-05-24 22:21:05 [INFO]: Epoch 055 - training loss: 0.2009, validation loss: 0.1298
2024-05-24 22:21:06 [INFO]: Epoch 056 - training loss: 0.1984, validation loss: 0.1294
2024-05-24 22:21:06 [INFO]: Epoch 057 - training loss: 0.1981, validation loss: 0.1287
2024-05-24 22:21:06 [INFO]: Epoch 058 - training loss: 0.1989, validation loss: 0.1308
2024-05-24 22:21:06 [INFO]: Epoch 059 - training loss: 0.2001, validation loss: 0.1270
2024-05-24 22:21:07 [INFO]: Epoch 060 - training loss: 0.1969, validation loss: 0.1261
2024-05-24 22:21:07 [INFO]: Epoch 061 - training loss: 0.1972, validation loss: 0.1273
2024-05-24 22:21:07 [INFO]: Epoch 062 - training loss: 0.1958, validation loss: 0.1282
2024-05-24 22:21:07 [INFO]: Epoch 063 - training loss: 0.1929, validation loss: 0.1256
2024-05-24 22:21:08 [INFO]: Epoch 064 - training loss: 0.1936, validation loss: 0.1267
2024-05-24 22:21:08 [INFO]: Epoch 065 - training loss: 0.1916, validation loss: 0.1246
2024-05-24 22:21:08 [INFO]: Epoch 066 - training loss: 0.1901, validation loss: 0.1253
2024-05-24 22:21:08 [INFO]: Epoch 067 - training loss: 0.1898, validation loss: 0.1275
2024-05-24 22:21:09 [INFO]: Epoch 068 - training loss: 0.1871, validation loss: 0.1241
2024-05-24 22:21:09 [INFO]: Epoch 069 - training loss: 0.1895, validation loss: 0.1227
2024-05-24 22:21:09 [INFO]: Epoch 070 - training loss: 0.1880, validation loss: 0.1238
2024-05-24 22:21:09 [INFO]: Epoch 071 - training loss: 0.1874, validation loss: 0.1239
2024-05-24 22:21:10 [INFO]: Epoch 072 - training loss: 0.1838, validation loss: 0.1232
2024-05-24 22:21:10 [INFO]: Epoch 073 - training loss: 0.1828, validation loss: 0.1226
2024-05-24 22:21:10 [INFO]: Epoch 074 - training loss: 0.1821, validation loss: 0.1228
2024-05-24 22:21:10 [INFO]: Epoch 075 - training loss: 0.1826, validation loss: 0.1218
2024-05-24 22:21:11 [INFO]: Epoch 076 - training loss: 0.1823, validation loss: 0.1210
2024-05-24 22:21:11 [INFO]: Epoch 077 - training loss: 0.1824, validation loss: 0.1227
2024-05-24 22:21:11 [INFO]: Epoch 078 - training loss: 0.1819, validation loss: 0.1230
2024-05-24 22:21:11 [INFO]: Epoch 079 - training loss: 0.1804, validation loss: 0.1219
2024-05-24 22:21:12 [INFO]: Epoch 080 - training loss: 0.1793, validation loss: 0.1204
2024-05-24 22:21:12 [INFO]: Epoch 081 - training loss: 0.1785, validation loss: 0.1189
2024-05-24 22:21:12 [INFO]: Epoch 082 - training loss: 0.1755, validation loss: 0.1195
2024-05-24 22:21:12 [INFO]: Epoch 083 - training loss: 0.1758, validation loss: 0.1187
2024-05-24 22:21:13 [INFO]: Epoch 084 - training loss: 0.1736, validation loss: 0.1204
2024-05-24 22:21:13 [INFO]: Epoch 085 - training loss: 0.1726, validation loss: 0.1193
2024-05-24 22:21:13 [INFO]: Epoch 086 - training loss: 0.1715, validation loss: 0.1183
2024-05-24 22:21:13 [INFO]: Epoch 087 - training loss: 0.1715, validation loss: 0.1178
2024-05-24 22:21:14 [INFO]: Epoch 088 - training loss: 0.1701, validation loss: 0.1185
2024-05-24 22:21:14 [INFO]: Epoch 089 - training loss: 0.1687, validation loss: 0.1188
2024-05-24 22:21:14 [INFO]: Epoch 090 - training loss: 0.1683, validation loss: 0.1170
2024-05-24 22:21:15 [INFO]: Epoch 091 - training loss: 0.1697, validation loss: 0.1168
2024-05-24 22:21:15 [INFO]: Epoch 092 - training loss: 0.1697, validation loss: 0.1164
2024-05-24 22:21:15 [INFO]: Epoch 093 - training loss: 0.1697, validation loss: 0.1184
2024-05-24 22:21:15 [INFO]: Epoch 094 - training loss: 0.1680, validation loss: 0.1178
2024-05-24 22:21:16 [INFO]: Epoch 095 - training loss: 0.1725, validation loss: 0.1164
2024-05-24 22:21:16 [INFO]: Epoch 096 - training loss: 0.1708, validation loss: 0.1175
2024-05-24 22:21:16 [INFO]: Epoch 097 - training loss: 0.1666, validation loss: 0.1184
2024-05-24 22:21:16 [INFO]: Epoch 098 - training loss: 0.1662, validation loss: 0.1165
2024-05-24 22:21:17 [INFO]: Epoch 099 - training loss: 0.1633, validation loss: 0.1175
2024-05-24 22:21:17 [INFO]: Epoch 100 - training loss: 0.1628, validation loss: 0.1154
2024-05-24 22:21:17 [INFO]: Epoch 101 - training loss: 0.1627, validation loss: 0.1167
2024-05-24 22:21:17 [INFO]: Epoch 102 - training loss: 0.1624, validation loss: 0.1143
2024-05-24 22:21:18 [INFO]: Epoch 103 - training loss: 0.1615, validation loss: 0.1156
2024-05-24 22:21:18 [INFO]: Epoch 104 - training loss: 0.1600, validation loss: 0.1157
2024-05-24 22:21:18 [INFO]: Epoch 105 - training loss: 0.1601, validation loss: 0.1159
2024-05-24 22:21:18 [INFO]: Epoch 106 - training loss: 0.1613, validation loss: 0.1160
2024-05-24 22:21:19 [INFO]: Epoch 107 - training loss: 0.1613, validation loss: 0.1146
2024-05-24 22:21:19 [INFO]: Epoch 108 - training loss: 0.1616, validation loss: 0.1175
2024-05-24 22:21:19 [INFO]: Epoch 109 - training loss: 0.1603, validation loss: 0.1152
2024-05-24 22:21:19 [INFO]: Epoch 110 - training loss: 0.1591, validation loss: 0.1150
2024-05-24 22:21:20 [INFO]: Epoch 111 - training loss: 0.1567, validation loss: 0.1144
2024-05-24 22:21:20 [INFO]: Epoch 112 - training loss: 0.1563, validation loss: 0.1131
2024-05-24 22:21:20 [INFO]: Epoch 113 - training loss: 0.1579, validation loss: 0.1142
2024-05-24 22:21:20 [INFO]: Epoch 114 - training loss: 0.1558, validation loss: 0.1143
2024-05-24 22:21:21 [INFO]: Epoch 115 - training loss: 0.1547, validation loss: 0.1149
2024-05-24 22:21:21 [INFO]: Epoch 116 - training loss: 0.1543, validation loss: 0.1145
2024-05-24 22:21:21 [INFO]: Epoch 117 - training loss: 0.1545, validation loss: 0.1145
2024-05-24 22:21:21 [INFO]: Epoch 118 - training loss: 0.1574, validation loss: 0.1142
2024-05-24 22:21:22 [INFO]: Epoch 119 - training loss: 0.1515, validation loss: 0.1136
2024-05-24 22:21:22 [INFO]: Epoch 120 - training loss: 0.1504, validation loss: 0.1132
2024-05-24 22:21:22 [INFO]: Epoch 121 - training loss: 0.1500, validation loss: 0.1140
2024-05-24 22:21:22 [INFO]: Epoch 122 - training loss: 0.1510, validation loss: 0.1135
2024-05-24 22:21:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:21:22 [INFO]: Finished training. The best model is from epoch#112.
2024-05-24 22:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240524_T222052/Transformer.pypots
2024-05-24 22:21:22 [INFO]: Transformer on Air-Quality: MAE=0.1667, MSE=0.1187
2024-05-24 22:21:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-24 22:21:22 [INFO]: Using the given device: cuda:0
2024-05-24 22:21:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240524_T222122
2024-05-24 22:21:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240524_T222122/tensorboard
2024-05-24 22:21:23 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 22:21:23 [INFO]: Epoch 001 - training loss: 0.3027, validation loss: 0.2619
2024-05-24 22:21:24 [INFO]: Epoch 002 - training loss: 0.2711, validation loss: 0.2458
2024-05-24 22:21:24 [INFO]: Epoch 003 - training loss: 0.2116, validation loss: 0.2116
2024-05-24 22:21:25 [INFO]: Epoch 004 - training loss: 0.1637, validation loss: 0.2047
2024-05-24 22:21:25 [INFO]: Epoch 005 - training loss: 0.1481, validation loss: 0.1936
2024-05-24 22:21:26 [INFO]: Epoch 006 - training loss: 0.1350, validation loss: 0.1935
2024-05-24 22:21:26 [INFO]: Epoch 007 - training loss: 0.1350, validation loss: 0.1881
2024-05-24 22:21:27 [INFO]: Epoch 008 - training loss: 0.1276, validation loss: 0.1938
2024-05-24 22:21:27 [INFO]: Epoch 009 - training loss: 0.1221, validation loss: 0.1889
2024-05-24 22:21:28 [INFO]: Epoch 010 - training loss: 0.1129, validation loss: 0.1897
2024-05-24 22:21:28 [INFO]: Epoch 011 - training loss: 0.1033, validation loss: 0.1989
2024-05-24 22:21:28 [INFO]: Epoch 012 - training loss: 0.1022, validation loss: 0.2037
2024-05-24 22:21:29 [INFO]: Epoch 013 - training loss: 0.0992, validation loss: 0.2203
2024-05-24 22:21:29 [INFO]: Epoch 014 - training loss: 0.0951, validation loss: 0.1758
2024-05-24 22:21:30 [INFO]: Epoch 015 - training loss: 0.0917, validation loss: 0.1821
2024-05-24 22:21:30 [INFO]: Epoch 016 - training loss: 0.0898, validation loss: 0.1816
2024-05-24 22:21:31 [INFO]: Epoch 017 - training loss: 0.0890, validation loss: 0.1780
2024-05-24 22:21:31 [INFO]: Epoch 018 - training loss: 0.0839, validation loss: 0.1658
2024-05-24 22:21:32 [INFO]: Epoch 019 - training loss: 0.0839, validation loss: 0.1673
2024-05-24 22:21:32 [INFO]: Epoch 020 - training loss: 0.0751, validation loss: 0.1696
2024-05-24 22:21:33 [INFO]: Epoch 021 - training loss: 0.0745, validation loss: 0.1719
2024-05-24 22:21:33 [INFO]: Epoch 022 - training loss: 0.0706, validation loss: 0.1670
2024-05-24 22:21:33 [INFO]: Epoch 023 - training loss: 0.0685, validation loss: 0.1639
2024-05-24 22:21:34 [INFO]: Epoch 024 - training loss: 0.0663, validation loss: 0.1611
2024-05-24 22:21:34 [INFO]: Epoch 025 - training loss: 0.0661, validation loss: 0.1579
2024-05-24 22:21:35 [INFO]: Epoch 026 - training loss: 0.0655, validation loss: 0.1639
2024-05-24 22:21:35 [INFO]: Epoch 027 - training loss: 0.0641, validation loss: 0.1579
2024-05-24 22:21:36 [INFO]: Epoch 028 - training loss: 0.0616, validation loss: 0.1561
2024-05-24 22:21:36 [INFO]: Epoch 029 - training loss: 0.0584, validation loss: 0.1584
2024-05-24 22:21:37 [INFO]: Epoch 030 - training loss: 0.0576, validation loss: 0.1521
2024-05-24 22:21:37 [INFO]: Epoch 031 - training loss: 0.0558, validation loss: 0.1528
2024-05-24 22:21:38 [INFO]: Epoch 032 - training loss: 0.0578, validation loss: 0.1558
2024-05-24 22:21:38 [INFO]: Epoch 033 - training loss: 0.0574, validation loss: 0.1491
2024-05-24 22:21:38 [INFO]: Epoch 034 - training loss: 0.0570, validation loss: 0.1568
2024-05-24 22:21:39 [INFO]: Epoch 035 - training loss: 0.0574, validation loss: 0.1530
2024-05-24 22:21:39 [INFO]: Epoch 036 - training loss: 0.0522, validation loss: 0.1491
2024-05-24 22:21:40 [INFO]: Epoch 037 - training loss: 0.0505, validation loss: 0.1507
2024-05-24 22:21:40 [INFO]: Epoch 038 - training loss: 0.0540, validation loss: 0.1501
2024-05-24 22:21:41 [INFO]: Epoch 039 - training loss: 0.0596, validation loss: 0.1489
2024-05-24 22:21:41 [INFO]: Epoch 040 - training loss: 0.0557, validation loss: 0.1544
2024-05-24 22:21:42 [INFO]: Epoch 041 - training loss: 0.0534, validation loss: 0.1484
2024-05-24 22:21:42 [INFO]: Epoch 042 - training loss: 0.0526, validation loss: 0.1479
2024-05-24 22:21:43 [INFO]: Epoch 043 - training loss: 0.0467, validation loss: 0.1436
2024-05-24 22:21:43 [INFO]: Epoch 044 - training loss: 0.0451, validation loss: 0.1520
2024-05-24 22:21:43 [INFO]: Epoch 045 - training loss: 0.0493, validation loss: 0.1419
2024-05-24 22:21:44 [INFO]: Epoch 046 - training loss: 0.0465, validation loss: 0.1436
2024-05-24 22:21:44 [INFO]: Epoch 047 - training loss: 0.0441, validation loss: 0.1464
2024-05-24 22:21:45 [INFO]: Epoch 048 - training loss: 0.0454, validation loss: 0.1531
2024-05-24 22:21:45 [INFO]: Epoch 049 - training loss: 0.0458, validation loss: 0.1416
2024-05-24 22:21:46 [INFO]: Epoch 050 - training loss: 0.0414, validation loss: 0.1450
2024-05-24 22:21:46 [INFO]: Epoch 051 - training loss: 0.0413, validation loss: 0.1415
2024-05-24 22:21:47 [INFO]: Epoch 052 - training loss: 0.0442, validation loss: 0.1435
2024-05-24 22:21:47 [INFO]: Epoch 053 - training loss: 0.0460, validation loss: 0.1424
2024-05-24 22:21:48 [INFO]: Epoch 054 - training loss: 0.0488, validation loss: 0.1449
2024-05-24 22:21:48 [INFO]: Epoch 055 - training loss: 0.0478, validation loss: 0.1401
2024-05-24 22:21:48 [INFO]: Epoch 056 - training loss: 0.0456, validation loss: 0.1397
2024-05-24 22:21:49 [INFO]: Epoch 057 - training loss: 0.0402, validation loss: 0.1380
2024-05-24 22:21:49 [INFO]: Epoch 058 - training loss: 0.0431, validation loss: 0.1412
2024-05-24 22:21:50 [INFO]: Epoch 059 - training loss: 0.0426, validation loss: 0.1446
2024-05-24 22:21:50 [INFO]: Epoch 060 - training loss: 0.0421, validation loss: 0.1415
2024-05-24 22:21:51 [INFO]: Epoch 061 - training loss: 0.0397, validation loss: 0.1417
2024-05-24 22:21:51 [INFO]: Epoch 062 - training loss: 0.0380, validation loss: 0.1357
2024-05-24 22:21:52 [INFO]: Epoch 063 - training loss: 0.0353, validation loss: 0.1379
2024-05-24 22:21:52 [INFO]: Epoch 064 - training loss: 0.0374, validation loss: 0.1394
2024-05-24 22:21:53 [INFO]: Epoch 065 - training loss: 0.0369, validation loss: 0.1357
2024-05-24 22:21:53 [INFO]: Epoch 066 - training loss: 0.0332, validation loss: 0.1348
2024-05-24 22:21:53 [INFO]: Epoch 067 - training loss: 0.0319, validation loss: 0.1355
2024-05-24 22:21:54 [INFO]: Epoch 068 - training loss: 0.0333, validation loss: 0.1353
2024-05-24 22:21:54 [INFO]: Epoch 069 - training loss: 0.0311, validation loss: 0.1369
2024-05-24 22:21:55 [INFO]: Epoch 070 - training loss: 0.0316, validation loss: 0.1350
2024-05-24 22:21:55 [INFO]: Epoch 071 - training loss: 0.0325, validation loss: 0.1369
2024-05-24 22:21:56 [INFO]: Epoch 072 - training loss: 0.0307, validation loss: 0.1364
2024-05-24 22:21:56 [INFO]: Epoch 073 - training loss: 0.0315, validation loss: 0.1362
2024-05-24 22:21:57 [INFO]: Epoch 074 - training loss: 0.0315, validation loss: 0.1340
2024-05-24 22:21:57 [INFO]: Epoch 075 - training loss: 0.0314, validation loss: 0.1378
2024-05-24 22:21:58 [INFO]: Epoch 076 - training loss: 0.0312, validation loss: 0.1334
2024-05-24 22:21:58 [INFO]: Epoch 077 - training loss: 0.0319, validation loss: 0.1335
2024-05-24 22:21:58 [INFO]: Epoch 078 - training loss: 0.0346, validation loss: 0.1374
2024-05-24 22:21:59 [INFO]: Epoch 079 - training loss: 0.0346, validation loss: 0.1324
2024-05-24 22:21:59 [INFO]: Epoch 080 - training loss: 0.0327, validation loss: 0.1368
2024-05-24 22:22:00 [INFO]: Epoch 081 - training loss: 0.0302, validation loss: 0.1322
2024-05-24 22:22:00 [INFO]: Epoch 082 - training loss: 0.0273, validation loss: 0.1349
2024-05-24 22:22:01 [INFO]: Epoch 083 - training loss: 0.0266, validation loss: 0.1335
2024-05-24 22:22:01 [INFO]: Epoch 084 - training loss: 0.0255, validation loss: 0.1327
2024-05-24 22:22:02 [INFO]: Epoch 085 - training loss: 0.0259, validation loss: 0.1329
2024-05-24 22:22:02 [INFO]: Epoch 086 - training loss: 0.0271, validation loss: 0.1348
2024-05-24 22:22:03 [INFO]: Epoch 087 - training loss: 0.0278, validation loss: 0.1351
2024-05-24 22:22:03 [INFO]: Epoch 088 - training loss: 0.0291, validation loss: 0.1373
2024-05-24 22:22:03 [INFO]: Epoch 089 - training loss: 0.0306, validation loss: 0.1312
2024-05-24 22:22:04 [INFO]: Epoch 090 - training loss: 0.0289, validation loss: 0.1353
2024-05-24 22:22:04 [INFO]: Epoch 091 - training loss: 0.0407, validation loss: 0.1372
2024-05-24 22:22:05 [INFO]: Epoch 092 - training loss: 0.0353, validation loss: 0.1341
2024-05-24 22:22:05 [INFO]: Epoch 093 - training loss: 0.0326, validation loss: 0.1349
2024-05-24 22:22:06 [INFO]: Epoch 094 - training loss: 0.0306, validation loss: 0.1330
2024-05-24 22:22:06 [INFO]: Epoch 095 - training loss: 0.0278, validation loss: 0.1343
2024-05-24 22:22:07 [INFO]: Epoch 096 - training loss: 0.0284, validation loss: 0.1329
2024-05-24 22:22:07 [INFO]: Epoch 097 - training loss: 0.0299, validation loss: 0.1372
2024-05-24 22:22:08 [INFO]: Epoch 098 - training loss: 0.0292, validation loss: 0.1326
2024-05-24 22:22:08 [INFO]: Epoch 099 - training loss: 0.0246, validation loss: 0.1335
2024-05-24 22:22:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:22:08 [INFO]: Finished training. The best model is from epoch#89.
2024-05-24 22:22:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240524_T222122/TimesNet.pypots
2024-05-24 22:22:08 [INFO]: TimesNet on Air-Quality: MAE=0.1624, MSE=0.1426
2024-05-24 22:22:08 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-24 22:22:08 [INFO]: Using the given device: cuda:0
2024-05-24 22:22:08 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208
2024-05-24 22:22:08 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/tensorboard
2024-05-24 22:22:08 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-24 22:22:25 [INFO]: Epoch 001 - training loss: 0.5396, validation loss: 0.3639
2024-05-24 22:22:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch1_loss0.3638724058866501.pypots
2024-05-24 22:22:42 [INFO]: Epoch 002 - training loss: 0.3173, validation loss: 0.2739
2024-05-24 22:22:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch2_loss0.27390762567520144.pypots
2024-05-24 22:22:58 [INFO]: Epoch 003 - training loss: 0.2652, validation loss: 0.2393
2024-05-24 22:22:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch3_loss0.23929809778928757.pypots
2024-05-24 22:23:15 [INFO]: Epoch 004 - training loss: 0.2420, validation loss: 0.2103
2024-05-24 22:23:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch4_loss0.21033689230680466.pypots
2024-05-24 22:23:31 [INFO]: Epoch 005 - training loss: 0.2154, validation loss: 0.1972
2024-05-24 22:23:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch5_loss0.19721849709749223.pypots
2024-05-24 22:23:48 [INFO]: Epoch 006 - training loss: 0.1906, validation loss: 0.1861
2024-05-24 22:23:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch6_loss0.1861143097281456.pypots
2024-05-24 22:24:05 [INFO]: Epoch 007 - training loss: 0.1755, validation loss: 0.1732
2024-05-24 22:24:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch7_loss0.17319778800010682.pypots
2024-05-24 22:24:21 [INFO]: Epoch 008 - training loss: 0.1693, validation loss: 0.1728
2024-05-24 22:24:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch8_loss0.17284324169158935.pypots
2024-05-24 22:24:38 [INFO]: Epoch 009 - training loss: 0.1820, validation loss: 0.1569
2024-05-24 22:24:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch9_loss0.1568552389740944.pypots
2024-05-24 22:24:55 [INFO]: Epoch 010 - training loss: 0.1901, validation loss: 0.1585
2024-05-24 22:24:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch10_loss0.1585047349333763.pypots
2024-05-24 22:25:11 [INFO]: Epoch 011 - training loss: 0.1650, validation loss: 0.1524
2024-05-24 22:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch11_loss0.15236374735832214.pypots
2024-05-24 22:25:28 [INFO]: Epoch 012 - training loss: 0.1578, validation loss: 0.1521
2024-05-24 22:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch12_loss0.15205664187669754.pypots
2024-05-24 22:25:44 [INFO]: Epoch 013 - training loss: 0.1453, validation loss: 0.1440
2024-05-24 22:25:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch13_loss0.14403466880321503.pypots
2024-05-24 22:26:01 [INFO]: Epoch 014 - training loss: 0.1634, validation loss: 0.1462
2024-05-24 22:26:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch14_loss0.1461738020181656.pypots
2024-05-24 22:26:18 [INFO]: Epoch 015 - training loss: 0.1554, validation loss: 0.1428
2024-05-24 22:26:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch15_loss0.14283957630395888.pypots
2024-05-24 22:26:34 [INFO]: Epoch 016 - training loss: 0.1821, validation loss: 0.1482
2024-05-24 22:26:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch16_loss0.14818267673254013.pypots
2024-05-24 22:26:51 [INFO]: Epoch 017 - training loss: 0.1520, validation loss: 0.1437
2024-05-24 22:26:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch17_loss0.14370863884687424.pypots
2024-05-24 22:27:08 [INFO]: Epoch 018 - training loss: 0.1455, validation loss: 0.1445
2024-05-24 22:27:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch18_loss0.14445266574621202.pypots
2024-05-24 22:27:24 [INFO]: Epoch 019 - training loss: 0.1441, validation loss: 0.1431
2024-05-24 22:27:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch19_loss0.1431112542748451.pypots
2024-05-24 22:27:41 [INFO]: Epoch 020 - training loss: 0.1382, validation loss: 0.1424
2024-05-24 22:27:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch20_loss0.14242432489991189.pypots
2024-05-24 22:27:57 [INFO]: Epoch 021 - training loss: 0.1501, validation loss: 0.1389
2024-05-24 22:27:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch21_loss0.13889118060469627.pypots
2024-05-24 22:28:14 [INFO]: Epoch 022 - training loss: 0.1529, validation loss: 0.1394
2024-05-24 22:28:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch22_loss0.13942176178097726.pypots
2024-05-24 22:28:31 [INFO]: Epoch 023 - training loss: 0.1330, validation loss: 0.1344
2024-05-24 22:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch23_loss0.1344118483364582.pypots
2024-05-24 22:28:47 [INFO]: Epoch 024 - training loss: 0.1377, validation loss: 0.1376
2024-05-24 22:28:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch24_loss0.13758309185504913.pypots
2024-05-24 22:29:04 [INFO]: Epoch 025 - training loss: 0.1510, validation loss: 0.1376
2024-05-24 22:29:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch25_loss0.13764379769563675.pypots
2024-05-24 22:29:21 [INFO]: Epoch 026 - training loss: 0.1435, validation loss: 0.1360
2024-05-24 22:29:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch26_loss0.13604194149374962.pypots
2024-05-24 22:29:37 [INFO]: Epoch 027 - training loss: 0.1366, validation loss: 0.1369
2024-05-24 22:29:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch27_loss0.1369032643735409.pypots
2024-05-24 22:29:54 [INFO]: Epoch 028 - training loss: 0.1348, validation loss: 0.1364
2024-05-24 22:29:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch28_loss0.13636366203427314.pypots
2024-05-24 22:30:10 [INFO]: Epoch 029 - training loss: 0.1405, validation loss: 0.1367
2024-05-24 22:30:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch29_loss0.13672161623835563.pypots
2024-05-24 22:30:27 [INFO]: Epoch 030 - training loss: 0.1316, validation loss: 0.1344
2024-05-24 22:30:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch30_loss0.1343870773911476.pypots
2024-05-24 22:30:44 [INFO]: Epoch 031 - training loss: 0.1274, validation loss: 0.1314
2024-05-24 22:30:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch31_loss0.1314445659518242.pypots
2024-05-24 22:31:00 [INFO]: Epoch 032 - training loss: 0.1403, validation loss: 0.1341
2024-05-24 22:31:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch32_loss0.13406075909733772.pypots
2024-05-24 22:31:17 [INFO]: Epoch 033 - training loss: 0.1449, validation loss: 0.1393
2024-05-24 22:31:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch33_loss0.1393363818526268.pypots
2024-05-24 22:31:34 [INFO]: Epoch 034 - training loss: 0.1423, validation loss: 0.1320
2024-05-24 22:31:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch34_loss0.13203711360692977.pypots
2024-05-24 22:31:50 [INFO]: Epoch 035 - training loss: 0.1263, validation loss: 0.1314
2024-05-24 22:31:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch35_loss0.13141321018338203.pypots
2024-05-24 22:32:07 [INFO]: Epoch 036 - training loss: 0.1268, validation loss: 0.1291
2024-05-24 22:32:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch36_loss0.1291274033486843.pypots
2024-05-24 22:32:23 [INFO]: Epoch 037 - training loss: 0.1423, validation loss: 0.1286
2024-05-24 22:32:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch37_loss0.12859973236918448.pypots
2024-05-24 22:32:40 [INFO]: Epoch 038 - training loss: 0.1328, validation loss: 0.1272
2024-05-24 22:32:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch38_loss0.1271980658173561.pypots
2024-05-24 22:32:57 [INFO]: Epoch 039 - training loss: 0.1317, validation loss: 0.1274
2024-05-24 22:32:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch39_loss0.127385975420475.pypots
2024-05-24 22:33:13 [INFO]: Epoch 040 - training loss: 0.1215, validation loss: 0.1304
2024-05-24 22:33:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch40_loss0.13036201223731042.pypots
2024-05-24 22:33:30 [INFO]: Epoch 041 - training loss: 0.1461, validation loss: 0.1329
2024-05-24 22:33:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch41_loss0.13285321667790412.pypots
2024-05-24 22:33:47 [INFO]: Epoch 042 - training loss: 0.1171, validation loss: 0.1268
2024-05-24 22:33:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch42_loss0.12680887728929519.pypots
2024-05-24 22:34:03 [INFO]: Epoch 043 - training loss: 0.1234, validation loss: 0.1251
2024-05-24 22:34:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch43_loss0.12506693452596665.pypots
2024-05-24 22:34:20 [INFO]: Epoch 044 - training loss: 0.1291, validation loss: 0.1291
2024-05-24 22:34:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch44_loss0.12913696542382241.pypots
2024-05-24 22:34:36 [INFO]: Epoch 045 - training loss: 0.1191, validation loss: 0.1240
2024-05-24 22:34:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch45_loss0.12395921796560287.pypots
2024-05-24 22:34:53 [INFO]: Epoch 046 - training loss: 0.1428, validation loss: 0.1264
2024-05-24 22:34:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch46_loss0.12636775970458985.pypots
2024-05-24 22:35:10 [INFO]: Epoch 047 - training loss: 0.1309, validation loss: 0.1228
2024-05-24 22:35:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch47_loss0.1228456161916256.pypots
2024-05-24 22:35:26 [INFO]: Epoch 048 - training loss: 0.1326, validation loss: 0.1233
2024-05-24 22:35:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch48_loss0.1232519157230854.pypots
2024-05-24 22:35:43 [INFO]: Epoch 049 - training loss: 0.1373, validation loss: 0.1231
2024-05-24 22:35:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch49_loss0.12307819724082947.pypots
2024-05-24 22:36:00 [INFO]: Epoch 050 - training loss: 0.1234, validation loss: 0.1257
2024-05-24 22:36:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch50_loss0.12566930204629898.pypots
2024-05-24 22:36:16 [INFO]: Epoch 051 - training loss: 0.1136, validation loss: 0.1285
2024-05-24 22:36:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch51_loss0.12853608131408692.pypots
2024-05-24 22:36:33 [INFO]: Epoch 052 - training loss: 0.1333, validation loss: 0.1245
2024-05-24 22:36:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch52_loss0.12451797276735306.pypots
2024-05-24 22:36:49 [INFO]: Epoch 053 - training loss: 0.1256, validation loss: 0.1206
2024-05-24 22:36:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch53_loss0.12055967152118682.pypots
2024-05-24 22:37:06 [INFO]: Epoch 054 - training loss: 0.1160, validation loss: 0.1204
2024-05-24 22:37:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch54_loss0.12038168013095855.pypots
2024-05-24 22:37:23 [INFO]: Epoch 055 - training loss: 0.1311, validation loss: 0.1208
2024-05-24 22:37:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch55_loss0.12075242400169373.pypots
2024-05-24 22:37:39 [INFO]: Epoch 056 - training loss: 0.1147, validation loss: 0.1193
2024-05-24 22:37:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch56_loss0.11932233050465584.pypots
2024-05-24 22:37:56 [INFO]: Epoch 057 - training loss: 0.1245, validation loss: 0.1215
2024-05-24 22:37:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch57_loss0.12152920365333557.pypots
2024-05-24 22:38:13 [INFO]: Epoch 058 - training loss: 0.1129, validation loss: 0.1214
2024-05-24 22:38:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch58_loss0.12139073759317398.pypots
2024-05-24 22:38:29 [INFO]: Epoch 059 - training loss: 0.1152, validation loss: 0.1184
2024-05-24 22:38:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch59_loss0.1184087075293064.pypots
2024-05-24 22:38:46 [INFO]: Epoch 060 - training loss: 0.1208, validation loss: 0.1262
2024-05-24 22:38:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch60_loss0.12617190852761268.pypots
2024-05-24 22:39:02 [INFO]: Epoch 061 - training loss: 0.1313, validation loss: 0.1202
2024-05-24 22:39:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch61_loss0.12016967386007309.pypots
2024-05-24 22:39:19 [INFO]: Epoch 062 - training loss: 0.1209, validation loss: 0.1195
2024-05-24 22:39:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch62_loss0.11950872614979743.pypots
2024-05-24 22:39:36 [INFO]: Epoch 063 - training loss: 0.1124, validation loss: 0.1189
2024-05-24 22:39:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch63_loss0.11885243579745293.pypots
2024-05-24 22:39:52 [INFO]: Epoch 064 - training loss: 0.1134, validation loss: 0.1212
2024-05-24 22:39:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch64_loss0.1211583971977234.pypots
2024-05-24 22:40:09 [INFO]: Epoch 065 - training loss: 0.1232, validation loss: 0.1199
2024-05-24 22:40:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch65_loss0.11992664709687233.pypots
2024-05-24 22:40:26 [INFO]: Epoch 066 - training loss: 0.1191, validation loss: 0.1211
2024-05-24 22:40:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch66_loss0.1210680864751339.pypots
2024-05-24 22:40:42 [INFO]: Epoch 067 - training loss: 0.1331, validation loss: 0.1191
2024-05-24 22:40:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch67_loss0.11905532628297806.pypots
2024-05-24 22:40:59 [INFO]: Epoch 068 - training loss: 0.1105, validation loss: 0.1279
2024-05-24 22:40:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch68_loss0.12787804156541824.pypots
2024-05-24 22:41:15 [INFO]: Epoch 069 - training loss: 0.1153, validation loss: 0.1157
2024-05-24 22:41:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch69_loss0.11571449637413025.pypots
2024-05-24 22:41:32 [INFO]: Epoch 070 - training loss: 0.1276, validation loss: 0.1164
2024-05-24 22:41:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch70_loss0.11639505326747894.pypots
2024-05-24 22:41:49 [INFO]: Epoch 071 - training loss: 0.1096, validation loss: 0.1171
2024-05-24 22:41:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch71_loss0.11712795421481133.pypots
2024-05-24 22:42:05 [INFO]: Epoch 072 - training loss: 0.1190, validation loss: 0.1181
2024-05-24 22:42:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch72_loss0.11808199137449264.pypots
2024-05-24 22:42:22 [INFO]: Epoch 073 - training loss: 0.1339, validation loss: 0.1178
2024-05-24 22:42:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch73_loss0.11777804270386696.pypots
2024-05-24 22:42:39 [INFO]: Epoch 074 - training loss: 0.1126, validation loss: 0.1167
2024-05-24 22:42:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch74_loss0.11674309819936753.pypots
2024-05-24 22:42:55 [INFO]: Epoch 075 - training loss: 0.1138, validation loss: 0.1129
2024-05-24 22:42:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch75_loss0.11292427778244019.pypots
2024-05-24 22:43:12 [INFO]: Epoch 076 - training loss: 0.1200, validation loss: 0.1160
2024-05-24 22:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch76_loss0.1159698948264122.pypots
2024-05-24 22:43:28 [INFO]: Epoch 077 - training loss: 0.1255, validation loss: 0.1345
2024-05-24 22:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch77_loss0.1344510667026043.pypots
2024-05-24 22:43:45 [INFO]: Epoch 078 - training loss: 0.1461, validation loss: 0.1309
2024-05-24 22:43:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch78_loss0.13085870295763016.pypots
2024-05-24 22:44:02 [INFO]: Epoch 079 - training loss: 0.1335, validation loss: 0.1234
2024-05-24 22:44:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch79_loss0.12338465452194214.pypots
2024-05-24 22:44:18 [INFO]: Epoch 080 - training loss: 0.1256, validation loss: 0.1235
2024-05-24 22:44:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch80_loss0.12345021739602088.pypots
2024-05-24 22:44:35 [INFO]: Epoch 081 - training loss: 0.1048, validation loss: 0.1185
2024-05-24 22:44:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch81_loss0.11851828172802925.pypots
2024-05-24 22:44:52 [INFO]: Epoch 082 - training loss: 0.1214, validation loss: 0.1139
2024-05-24 22:44:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch82_loss0.11389994993805885.pypots
2024-05-24 22:45:08 [INFO]: Epoch 083 - training loss: 0.1098, validation loss: 0.1199
2024-05-24 22:45:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch83_loss0.11989956125617027.pypots
2024-05-24 22:45:25 [INFO]: Epoch 084 - training loss: 0.1181, validation loss: 0.1153
2024-05-24 22:45:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch84_loss0.11529377326369286.pypots
2024-05-24 22:45:41 [INFO]: Epoch 085 - training loss: 0.1303, validation loss: 0.1173
2024-05-24 22:45:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI_epoch85_loss0.11726046800613403.pypots
2024-05-24 22:45:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:45:41 [INFO]: Finished training. The best model is from epoch#75.
2024-05-24 22:45:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240524_T222208/CSDI.pypots
2024-05-24 22:48:02 [INFO]: CSDI on Air-Quality: MAE=0.1195, MSE=0.2297
2024-05-24 22:48:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-24 22:48:02 [INFO]: Using the given device: cuda:0
2024-05-24 22:48:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240524_T224802
2024-05-24 22:48:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240524_T224802/tensorboard
2024-05-24 22:48:02 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-24 22:48:02 [INFO]: Epoch 001 - training loss: 63487.1885, validation loss: 0.6332
2024-05-24 22:48:02 [INFO]: Epoch 002 - training loss: 41954.6140, validation loss: 0.5735
2024-05-24 22:48:03 [INFO]: Epoch 003 - training loss: 41662.1034, validation loss: 0.5559
2024-05-24 22:48:03 [INFO]: Epoch 004 - training loss: 41527.4304, validation loss: 0.4727
2024-05-24 22:48:03 [INFO]: Epoch 005 - training loss: 41433.4902, validation loss: 0.4280
2024-05-24 22:48:04 [INFO]: Epoch 006 - training loss: 41358.3913, validation loss: 0.3766
2024-05-24 22:48:04 [INFO]: Epoch 007 - training loss: 41326.1645, validation loss: 0.3483
2024-05-24 22:48:04 [INFO]: Epoch 008 - training loss: 41297.8124, validation loss: 0.3758
2024-05-24 22:48:05 [INFO]: Epoch 009 - training loss: 41299.9572, validation loss: 0.3187
2024-05-24 22:48:05 [INFO]: Epoch 010 - training loss: 41237.8821, validation loss: 0.3084
2024-05-24 22:48:05 [INFO]: Epoch 011 - training loss: 41213.9734, validation loss: 0.3108
2024-05-24 22:48:06 [INFO]: Epoch 012 - training loss: 41207.2099, validation loss: 0.3005
2024-05-24 22:48:06 [INFO]: Epoch 013 - training loss: 41189.0745, validation loss: 0.2850
2024-05-24 22:48:06 [INFO]: Epoch 014 - training loss: 41174.7146, validation loss: 0.3001
2024-05-24 22:48:07 [INFO]: Epoch 015 - training loss: 41233.7555, validation loss: 0.2982
2024-05-24 22:48:07 [INFO]: Epoch 016 - training loss: 41175.4429, validation loss: 0.2977
2024-05-24 22:48:07 [INFO]: Epoch 017 - training loss: 41150.5080, validation loss: 0.2666
2024-05-24 22:48:08 [INFO]: Epoch 018 - training loss: 41134.5201, validation loss: 0.2649
2024-05-24 22:48:08 [INFO]: Epoch 019 - training loss: 41123.3546, validation loss: 0.2576
2024-05-24 22:48:08 [INFO]: Epoch 020 - training loss: 41120.0812, validation loss: 0.2583
2024-05-24 22:48:09 [INFO]: Epoch 021 - training loss: 41118.3419, validation loss: 0.2579
2024-05-24 22:48:09 [INFO]: Epoch 022 - training loss: 41110.3670, validation loss: 0.2500
2024-05-24 22:48:09 [INFO]: Epoch 023 - training loss: 41091.0544, validation loss: 0.2413
2024-05-24 22:48:10 [INFO]: Epoch 024 - training loss: 41091.9225, validation loss: 0.2541
2024-05-24 22:48:10 [INFO]: Epoch 025 - training loss: 41094.7629, validation loss: 0.2486
2024-05-24 22:48:10 [INFO]: Epoch 026 - training loss: 41078.7203, validation loss: 0.2430
2024-05-24 22:48:11 [INFO]: Epoch 027 - training loss: 41085.8550, validation loss: 0.2336
2024-05-24 22:48:11 [INFO]: Epoch 028 - training loss: 41089.2648, validation loss: 0.2438
2024-05-24 22:48:11 [INFO]: Epoch 029 - training loss: 41094.8325, validation loss: 0.2596
2024-05-24 22:48:12 [INFO]: Epoch 030 - training loss: 41277.8239, validation loss: 0.2706
2024-05-24 22:48:12 [INFO]: Epoch 031 - training loss: 41138.9230, validation loss: 0.2378
2024-05-24 22:48:12 [INFO]: Epoch 032 - training loss: 41082.0794, validation loss: 0.2374
2024-05-24 22:48:13 [INFO]: Epoch 033 - training loss: 41089.8385, validation loss: 0.2353
2024-05-24 22:48:13 [INFO]: Epoch 034 - training loss: 41078.7721, validation loss: 0.2363
2024-05-24 22:48:13 [INFO]: Epoch 035 - training loss: 41072.9278, validation loss: 0.2220
2024-05-24 22:48:14 [INFO]: Epoch 036 - training loss: 41058.0200, validation loss: 0.2249
2024-05-24 22:48:14 [INFO]: Epoch 037 - training loss: 41053.8403, validation loss: 0.2185
2024-05-24 22:48:14 [INFO]: Epoch 038 - training loss: 41042.9321, validation loss: 0.2142
2024-05-24 22:48:15 [INFO]: Epoch 039 - training loss: 41042.1755, validation loss: 0.2184
2024-05-24 22:48:15 [INFO]: Epoch 040 - training loss: 41049.9013, validation loss: 0.2197
2024-05-24 22:48:15 [INFO]: Epoch 041 - training loss: 41044.5354, validation loss: 0.2183
2024-05-24 22:48:16 [INFO]: Epoch 042 - training loss: 41032.9544, validation loss: 0.2156
2024-05-24 22:48:16 [INFO]: Epoch 043 - training loss: 41039.1594, validation loss: 0.2118
2024-05-24 22:48:16 [INFO]: Epoch 044 - training loss: 41039.4256, validation loss: 0.2235
2024-05-24 22:48:17 [INFO]: Epoch 045 - training loss: 41049.9362, validation loss: 0.2179
2024-05-24 22:48:17 [INFO]: Epoch 046 - training loss: 41036.8591, validation loss: 0.2209
2024-05-24 22:48:17 [INFO]: Epoch 047 - training loss: 41034.1146, validation loss: 0.2181
2024-05-24 22:48:18 [INFO]: Epoch 048 - training loss: 41047.7354, validation loss: 0.2103
2024-05-24 22:48:18 [INFO]: Epoch 049 - training loss: 41023.1787, validation loss: 0.2121
2024-05-24 22:48:18 [INFO]: Epoch 050 - training loss: 41027.4608, validation loss: 0.2248
2024-05-24 22:48:19 [INFO]: Epoch 051 - training loss: 41034.0369, validation loss: 0.2144
2024-05-24 22:48:19 [INFO]: Epoch 052 - training loss: 41014.0001, validation loss: 0.2086
2024-05-24 22:48:19 [INFO]: Epoch 053 - training loss: 41013.1363, validation loss: 0.2062
2024-05-24 22:48:20 [INFO]: Epoch 054 - training loss: 41013.6228, validation loss: 0.2038
2024-05-24 22:48:20 [INFO]: Epoch 055 - training loss: 41012.0602, validation loss: 0.2034
2024-05-24 22:48:20 [INFO]: Epoch 056 - training loss: 41013.2212, validation loss: 0.2023
2024-05-24 22:48:21 [INFO]: Epoch 057 - training loss: 41010.8815, validation loss: 0.2049
2024-05-24 22:48:21 [INFO]: Epoch 058 - training loss: 41013.0479, validation loss: 0.1974
2024-05-24 22:48:21 [INFO]: Epoch 059 - training loss: 41004.8886, validation loss: 0.2025
2024-05-24 22:48:22 [INFO]: Epoch 060 - training loss: 41016.3759, validation loss: 0.2088
2024-05-24 22:48:22 [INFO]: Epoch 061 - training loss: 41028.6170, validation loss: 0.2246
2024-05-24 22:48:22 [INFO]: Epoch 062 - training loss: 41030.9433, validation loss: 0.2142
2024-05-24 22:48:23 [INFO]: Epoch 063 - training loss: 41032.0106, validation loss: 0.2163
2024-05-24 22:48:23 [INFO]: Epoch 064 - training loss: 41049.5454, validation loss: 0.2032
2024-05-24 22:48:23 [INFO]: Epoch 065 - training loss: 41008.0016, validation loss: 0.1956
2024-05-24 22:48:24 [INFO]: Epoch 066 - training loss: 41004.8666, validation loss: 0.1978
2024-05-24 22:48:24 [INFO]: Epoch 067 - training loss: 41003.2480, validation loss: 0.1983
2024-05-24 22:48:24 [INFO]: Epoch 068 - training loss: 40999.9531, validation loss: 0.1959
2024-05-24 22:48:25 [INFO]: Epoch 069 - training loss: 40994.7044, validation loss: 0.1929
2024-05-24 22:48:25 [INFO]: Epoch 070 - training loss: 40996.7377, validation loss: 0.2045
2024-05-24 22:48:25 [INFO]: Epoch 071 - training loss: 40998.6888, validation loss: 0.2053
2024-05-24 22:48:26 [INFO]: Epoch 072 - training loss: 41005.2231, validation loss: 0.2033
2024-05-24 22:48:26 [INFO]: Epoch 073 - training loss: 40999.4418, validation loss: 0.1985
2024-05-24 22:48:26 [INFO]: Epoch 074 - training loss: 40997.5314, validation loss: 0.2065
2024-05-24 22:48:27 [INFO]: Epoch 075 - training loss: 40992.6130, validation loss: 0.2035
2024-05-24 22:48:27 [INFO]: Epoch 076 - training loss: 41002.0891, validation loss: 0.2038
2024-05-24 22:48:27 [INFO]: Epoch 077 - training loss: 40994.3313, validation loss: 0.1995
2024-05-24 22:48:28 [INFO]: Epoch 078 - training loss: 41007.4498, validation loss: 0.2058
2024-05-24 22:48:28 [INFO]: Epoch 079 - training loss: 41016.9006, validation loss: 0.2096
2024-05-24 22:48:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:48:28 [INFO]: Finished training. The best model is from epoch#69.
2024-05-24 22:48:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240524_T224802/GPVAE.pypots
2024-05-24 22:48:28 [INFO]: GP-VAE on Air-Quality: MAE=0.2863, MSE=0.2301
2024-05-24 22:48:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-24 22:48:28 [INFO]: Using the given device: cuda:0
2024-05-24 22:48:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240524_T224828
2024-05-24 22:48:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240524_T224828/tensorboard
2024-05-24 22:48:28 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-24 22:48:33 [INFO]: Epoch 001 - generator training loss: 0.5213, discriminator training loss: 0.3836, validation loss: 0.5020
2024-05-24 22:48:37 [INFO]: Epoch 002 - generator training loss: 0.1486, discriminator training loss: 0.2420, validation loss: 0.3769
2024-05-24 22:48:41 [INFO]: Epoch 003 - generator training loss: 0.0979, discriminator training loss: 0.2377, validation loss: 0.3074
2024-05-24 22:48:45 [INFO]: Epoch 004 - generator training loss: 0.0589, discriminator training loss: 0.2369, validation loss: 0.2664
2024-05-24 22:48:49 [INFO]: Epoch 005 - generator training loss: 0.0350, discriminator training loss: 0.2362, validation loss: 0.2386
2024-05-24 22:48:54 [INFO]: Epoch 006 - generator training loss: 0.0168, discriminator training loss: 0.2351, validation loss: 0.2200
2024-05-24 22:48:58 [INFO]: Epoch 007 - generator training loss: 0.0049, discriminator training loss: 0.2343, validation loss: 0.2051
2024-05-24 22:49:02 [INFO]: Epoch 008 - generator training loss: -0.0044, discriminator training loss: 0.2330, validation loss: 0.1945
2024-05-24 22:49:06 [INFO]: Epoch 009 - generator training loss: -0.0128, discriminator training loss: 0.2315, validation loss: 0.1854
2024-05-24 22:49:10 [INFO]: Epoch 010 - generator training loss: -0.0159, discriminator training loss: 0.2303, validation loss: 0.1784
2024-05-24 22:49:14 [INFO]: Epoch 011 - generator training loss: -0.0238, discriminator training loss: 0.2287, validation loss: 0.1715
2024-05-24 22:49:18 [INFO]: Epoch 012 - generator training loss: -0.0277, discriminator training loss: 0.2271, validation loss: 0.1659
2024-05-24 22:49:22 [INFO]: Epoch 013 - generator training loss: -0.0299, discriminator training loss: 0.2254, validation loss: 0.1609
2024-05-24 22:49:26 [INFO]: Epoch 014 - generator training loss: -0.0343, discriminator training loss: 0.2237, validation loss: 0.1566
2024-05-24 22:49:30 [INFO]: Epoch 015 - generator training loss: -0.0360, discriminator training loss: 0.2222, validation loss: 0.1524
2024-05-24 22:49:34 [INFO]: Epoch 016 - generator training loss: -0.0387, discriminator training loss: 0.2206, validation loss: 0.1489
2024-05-24 22:49:39 [INFO]: Epoch 017 - generator training loss: -0.0406, discriminator training loss: 0.2190, validation loss: 0.1453
2024-05-24 22:49:43 [INFO]: Epoch 018 - generator training loss: -0.0406, discriminator training loss: 0.2174, validation loss: 0.1417
2024-05-24 22:49:47 [INFO]: Epoch 019 - generator training loss: -0.0426, discriminator training loss: 0.2153, validation loss: 0.1381
2024-05-24 22:49:51 [INFO]: Epoch 020 - generator training loss: -0.0456, discriminator training loss: 0.2138, validation loss: 0.1354
2024-05-24 22:49:55 [INFO]: Epoch 021 - generator training loss: -0.0465, discriminator training loss: 0.2120, validation loss: 0.1325
2024-05-24 22:49:59 [INFO]: Epoch 022 - generator training loss: -0.0453, discriminator training loss: 0.2103, validation loss: 0.1296
2024-05-24 22:50:03 [INFO]: Epoch 023 - generator training loss: -0.0491, discriminator training loss: 0.2084, validation loss: 0.1273
2024-05-24 22:50:07 [INFO]: Epoch 024 - generator training loss: -0.0476, discriminator training loss: 0.2066, validation loss: 0.1253
2024-05-24 22:50:11 [INFO]: Epoch 025 - generator training loss: -0.0487, discriminator training loss: 0.2047, validation loss: 0.1232
2024-05-24 22:50:16 [INFO]: Epoch 026 - generator training loss: -0.0495, discriminator training loss: 0.2030, validation loss: 0.1208
2024-05-24 22:50:20 [INFO]: Epoch 027 - generator training loss: -0.0510, discriminator training loss: 0.2011, validation loss: 0.1187
2024-05-24 22:50:24 [INFO]: Epoch 028 - generator training loss: -0.0498, discriminator training loss: 0.1993, validation loss: 0.1176
2024-05-24 22:50:28 [INFO]: Epoch 029 - generator training loss: -0.0511, discriminator training loss: 0.1977, validation loss: 0.1153
2024-05-24 22:50:32 [INFO]: Epoch 030 - generator training loss: -0.0512, discriminator training loss: 0.1959, validation loss: 0.1143
2024-05-24 22:50:36 [INFO]: Epoch 031 - generator training loss: -0.0514, discriminator training loss: 0.1941, validation loss: 0.1122
2024-05-24 22:50:40 [INFO]: Epoch 032 - generator training loss: -0.0509, discriminator training loss: 0.1925, validation loss: 0.1108
2024-05-24 22:50:44 [INFO]: Epoch 033 - generator training loss: -0.0506, discriminator training loss: 0.1909, validation loss: 0.1098
2024-05-24 22:50:48 [INFO]: Epoch 034 - generator training loss: -0.0490, discriminator training loss: 0.1891, validation loss: 0.1087
2024-05-24 22:50:52 [INFO]: Epoch 035 - generator training loss: -0.0489, discriminator training loss: 0.1877, validation loss: 0.1070
2024-05-24 22:50:57 [INFO]: Epoch 036 - generator training loss: -0.0487, discriminator training loss: 0.1862, validation loss: 0.1056
2024-05-24 22:51:01 [INFO]: Epoch 037 - generator training loss: -0.0494, discriminator training loss: 0.1843, validation loss: 0.1046
2024-05-24 22:51:05 [INFO]: Epoch 038 - generator training loss: -0.0489, discriminator training loss: 0.1827, validation loss: 0.1035
2024-05-24 22:51:09 [INFO]: Epoch 039 - generator training loss: -0.0491, discriminator training loss: 0.1813, validation loss: 0.1020
2024-05-24 22:51:13 [INFO]: Epoch 040 - generator training loss: -0.0493, discriminator training loss: 0.1802, validation loss: 0.1011
2024-05-24 22:51:17 [INFO]: Epoch 041 - generator training loss: -0.0469, discriminator training loss: 0.1784, validation loss: 0.0997
2024-05-24 22:51:21 [INFO]: Epoch 042 - generator training loss: -0.0471, discriminator training loss: 0.1770, validation loss: 0.0987
2024-05-24 22:51:25 [INFO]: Epoch 043 - generator training loss: -0.0477, discriminator training loss: 0.1758, validation loss: 0.0978
2024-05-24 22:51:29 [INFO]: Epoch 044 - generator training loss: -0.0476, discriminator training loss: 0.1746, validation loss: 0.0972
2024-05-24 22:51:34 [INFO]: Epoch 045 - generator training loss: -0.0473, discriminator training loss: 0.1728, validation loss: 0.0964
2024-05-24 22:51:38 [INFO]: Epoch 046 - generator training loss: -0.0468, discriminator training loss: 0.1720, validation loss: 0.0952
2024-05-24 22:51:42 [INFO]: Epoch 047 - generator training loss: -0.0454, discriminator training loss: 0.1705, validation loss: 0.0951
2024-05-24 22:51:46 [INFO]: Epoch 048 - generator training loss: -0.0459, discriminator training loss: 0.1696, validation loss: 0.0936
2024-05-24 22:51:50 [INFO]: Epoch 049 - generator training loss: -0.0460, discriminator training loss: 0.1683, validation loss: 0.0927
2024-05-24 22:51:54 [INFO]: Epoch 050 - generator training loss: -0.0465, discriminator training loss: 0.1669, validation loss: 0.0920
2024-05-24 22:51:58 [INFO]: Epoch 051 - generator training loss: -0.0467, discriminator training loss: 0.1658, validation loss: 0.0911
2024-05-24 22:52:02 [INFO]: Epoch 052 - generator training loss: -0.0469, discriminator training loss: 0.1651, validation loss: 0.0902
2024-05-24 22:52:06 [INFO]: Epoch 053 - generator training loss: -0.0458, discriminator training loss: 0.1642, validation loss: 0.0897
2024-05-24 22:52:11 [INFO]: Epoch 054 - generator training loss: -0.0463, discriminator training loss: 0.1629, validation loss: 0.0894
2024-05-24 22:52:15 [INFO]: Epoch 055 - generator training loss: -0.0447, discriminator training loss: 0.1621, validation loss: 0.0881
2024-05-24 22:52:19 [INFO]: Epoch 056 - generator training loss: -0.0454, discriminator training loss: 0.1613, validation loss: 0.0879
2024-05-24 22:52:23 [INFO]: Epoch 057 - generator training loss: -0.0453, discriminator training loss: 0.1604, validation loss: 0.0871
2024-05-24 22:52:27 [INFO]: Epoch 058 - generator training loss: -0.0450, discriminator training loss: 0.1594, validation loss: 0.0860
2024-05-24 22:52:31 [INFO]: Epoch 059 - generator training loss: -0.0446, discriminator training loss: 0.1585, validation loss: 0.0853
2024-05-24 22:52:35 [INFO]: Epoch 060 - generator training loss: -0.0447, discriminator training loss: 0.1575, validation loss: 0.0850
2024-05-24 22:52:39 [INFO]: Epoch 061 - generator training loss: -0.0443, discriminator training loss: 0.1568, validation loss: 0.0843
2024-05-24 22:52:43 [INFO]: Epoch 062 - generator training loss: -0.0450, discriminator training loss: 0.1562, validation loss: 0.0843
2024-05-24 22:52:47 [INFO]: Epoch 063 - generator training loss: -0.0449, discriminator training loss: 0.1553, validation loss: 0.0832
2024-05-24 22:52:51 [INFO]: Epoch 064 - generator training loss: -0.0437, discriminator training loss: 0.1545, validation loss: 0.0825
2024-05-24 22:52:56 [INFO]: Epoch 065 - generator training loss: -0.0440, discriminator training loss: 0.1537, validation loss: 0.0822
2024-05-24 22:53:00 [INFO]: Epoch 066 - generator training loss: -0.0439, discriminator training loss: 0.1528, validation loss: 0.0819
2024-05-24 22:53:04 [INFO]: Epoch 067 - generator training loss: -0.0430, discriminator training loss: 0.1526, validation loss: 0.0814
2024-05-24 22:53:08 [INFO]: Epoch 068 - generator training loss: -0.0441, discriminator training loss: 0.1516, validation loss: 0.0810
2024-05-24 22:53:12 [INFO]: Epoch 069 - generator training loss: -0.0437, discriminator training loss: 0.1509, validation loss: 0.0802
2024-05-24 22:53:16 [INFO]: Epoch 070 - generator training loss: -0.0434, discriminator training loss: 0.1509, validation loss: 0.0797
2024-05-24 22:53:20 [INFO]: Epoch 071 - generator training loss: -0.0430, discriminator training loss: 0.1506, validation loss: 0.0798
2024-05-24 22:53:24 [INFO]: Epoch 072 - generator training loss: -0.0423, discriminator training loss: 0.1495, validation loss: 0.0800
2024-05-24 22:53:28 [INFO]: Epoch 073 - generator training loss: -0.0428, discriminator training loss: 0.1489, validation loss: 0.0791
2024-05-24 22:53:33 [INFO]: Epoch 074 - generator training loss: -0.0425, discriminator training loss: 0.1483, validation loss: 0.0786
2024-05-24 22:53:37 [INFO]: Epoch 075 - generator training loss: -0.0419, discriminator training loss: 0.1481, validation loss: 0.0780
2024-05-24 22:53:41 [INFO]: Epoch 076 - generator training loss: -0.0435, discriminator training loss: 0.1481, validation loss: 0.0776
2024-05-24 22:53:45 [INFO]: Epoch 077 - generator training loss: -0.0419, discriminator training loss: 0.1468, validation loss: 0.0781
2024-05-24 22:53:49 [INFO]: Epoch 078 - generator training loss: -0.0424, discriminator training loss: 0.1465, validation loss: 0.0771
2024-05-24 22:53:53 [INFO]: Epoch 079 - generator training loss: -0.0431, discriminator training loss: 0.1460, validation loss: 0.0767
2024-05-24 22:53:57 [INFO]: Epoch 080 - generator training loss: -0.0432, discriminator training loss: 0.1456, validation loss: 0.0762
2024-05-24 22:54:01 [INFO]: Epoch 081 - generator training loss: -0.0422, discriminator training loss: 0.1452, validation loss: 0.0763
2024-05-24 22:54:05 [INFO]: Epoch 082 - generator training loss: -0.0427, discriminator training loss: 0.1449, validation loss: 0.0755
2024-05-24 22:54:10 [INFO]: Epoch 083 - generator training loss: -0.0432, discriminator training loss: 0.1443, validation loss: 0.0751
2024-05-24 22:54:14 [INFO]: Epoch 084 - generator training loss: -0.0433, discriminator training loss: 0.1441, validation loss: 0.0750
2024-05-24 22:54:18 [INFO]: Epoch 085 - generator training loss: -0.0435, discriminator training loss: 0.1439, validation loss: 0.0744
2024-05-24 22:54:22 [INFO]: Epoch 086 - generator training loss: -0.0421, discriminator training loss: 0.1432, validation loss: 0.0755
2024-05-24 22:54:26 [INFO]: Epoch 087 - generator training loss: -0.0431, discriminator training loss: 0.1428, validation loss: 0.0749
2024-05-24 22:54:30 [INFO]: Epoch 088 - generator training loss: -0.0436, discriminator training loss: 0.1426, validation loss: 0.0750
2024-05-24 22:54:34 [INFO]: Epoch 089 - generator training loss: -0.0434, discriminator training loss: 0.1424, validation loss: 0.0738
2024-05-24 22:54:38 [INFO]: Epoch 090 - generator training loss: -0.0430, discriminator training loss: 0.1419, validation loss: 0.0732
2024-05-24 22:54:42 [INFO]: Epoch 091 - generator training loss: -0.0434, discriminator training loss: 0.1420, validation loss: 0.0736
2024-05-24 22:54:46 [INFO]: Epoch 092 - generator training loss: -0.0433, discriminator training loss: 0.1412, validation loss: 0.0731
2024-05-24 22:54:51 [INFO]: Epoch 093 - generator training loss: -0.0427, discriminator training loss: 0.1408, validation loss: 0.0735
2024-05-24 22:54:55 [INFO]: Epoch 094 - generator training loss: -0.0427, discriminator training loss: 0.1406, validation loss: 0.0738
2024-05-24 22:54:59 [INFO]: Epoch 095 - generator training loss: -0.0408, discriminator training loss: 0.1404, validation loss: 0.0735
2024-05-24 22:55:03 [INFO]: Epoch 096 - generator training loss: -0.0425, discriminator training loss: 0.1403, validation loss: 0.0725
2024-05-24 22:55:07 [INFO]: Epoch 097 - generator training loss: -0.0436, discriminator training loss: 0.1397, validation loss: 0.0726
2024-05-24 22:55:11 [INFO]: Epoch 098 - generator training loss: -0.0432, discriminator training loss: 0.1396, validation loss: 0.0720
2024-05-24 22:55:15 [INFO]: Epoch 099 - generator training loss: -0.0440, discriminator training loss: 0.1392, validation loss: 0.0718
2024-05-24 22:55:19 [INFO]: Epoch 100 - generator training loss: -0.0438, discriminator training loss: 0.1390, validation loss: 0.0715
2024-05-24 22:55:23 [INFO]: Epoch 101 - generator training loss: -0.0441, discriminator training loss: 0.1389, validation loss: 0.0727
2024-05-24 22:55:27 [INFO]: Epoch 102 - generator training loss: -0.0445, discriminator training loss: 0.1388, validation loss: 0.0714
2024-05-24 22:55:32 [INFO]: Epoch 103 - generator training loss: -0.0445, discriminator training loss: 0.1386, validation loss: 0.0713
2024-05-24 22:55:36 [INFO]: Epoch 104 - generator training loss: -0.0445, discriminator training loss: 0.1384, validation loss: 0.0715
2024-05-24 22:55:40 [INFO]: Epoch 105 - generator training loss: -0.0435, discriminator training loss: 0.1378, validation loss: 0.0714
2024-05-24 22:55:44 [INFO]: Epoch 106 - generator training loss: -0.0446, discriminator training loss: 0.1378, validation loss: 0.0703
2024-05-24 22:55:48 [INFO]: Epoch 107 - generator training loss: -0.0443, discriminator training loss: 0.1380, validation loss: 0.0710
2024-05-24 22:55:52 [INFO]: Epoch 108 - generator training loss: -0.0445, discriminator training loss: 0.1375, validation loss: 0.0713
2024-05-24 22:55:56 [INFO]: Epoch 109 - generator training loss: -0.0441, discriminator training loss: 0.1370, validation loss: 0.0710
2024-05-24 22:56:00 [INFO]: Epoch 110 - generator training loss: -0.0434, discriminator training loss: 0.1367, validation loss: 0.0720
2024-05-24 22:56:04 [INFO]: Epoch 111 - generator training loss: -0.0435, discriminator training loss: 0.1372, validation loss: 0.0710
2024-05-24 22:56:09 [INFO]: Epoch 112 - generator training loss: -0.0441, discriminator training loss: 0.1366, validation loss: 0.0705
2024-05-24 22:56:13 [INFO]: Epoch 113 - generator training loss: -0.0448, discriminator training loss: 0.1362, validation loss: 0.0697
2024-05-24 22:56:17 [INFO]: Epoch 114 - generator training loss: -0.0451, discriminator training loss: 0.1363, validation loss: 0.0701
2024-05-24 22:56:21 [INFO]: Epoch 115 - generator training loss: -0.0455, discriminator training loss: 0.1364, validation loss: 0.0708
2024-05-24 22:56:25 [INFO]: Epoch 116 - generator training loss: -0.0454, discriminator training loss: 0.1361, validation loss: 0.0697
2024-05-24 22:56:29 [INFO]: Epoch 117 - generator training loss: -0.0453, discriminator training loss: 0.1358, validation loss: 0.0701
2024-05-24 22:56:33 [INFO]: Epoch 118 - generator training loss: -0.0449, discriminator training loss: 0.1356, validation loss: 0.0701
2024-05-24 22:56:37 [INFO]: Epoch 119 - generator training loss: -0.0447, discriminator training loss: 0.1352, validation loss: 0.0701
2024-05-24 22:56:41 [INFO]: Epoch 120 - generator training loss: -0.0447, discriminator training loss: 0.1352, validation loss: 0.0697
2024-05-24 22:56:46 [INFO]: Epoch 121 - generator training loss: -0.0454, discriminator training loss: 0.1356, validation loss: 0.0696
2024-05-24 22:56:50 [INFO]: Epoch 122 - generator training loss: -0.0458, discriminator training loss: 0.1350, validation loss: 0.0700
2024-05-24 22:56:54 [INFO]: Epoch 123 - generator training loss: -0.0455, discriminator training loss: 0.1349, validation loss: 0.0694
2024-05-24 22:56:58 [INFO]: Epoch 124 - generator training loss: -0.0454, discriminator training loss: 0.1350, validation loss: 0.0699
2024-05-24 22:57:02 [INFO]: Epoch 125 - generator training loss: -0.0452, discriminator training loss: 0.1346, validation loss: 0.0698
2024-05-24 22:57:06 [INFO]: Epoch 126 - generator training loss: -0.0454, discriminator training loss: 0.1345, validation loss: 0.0688
2024-05-24 22:57:10 [INFO]: Epoch 127 - generator training loss: -0.0450, discriminator training loss: 0.1343, validation loss: 0.0691
2024-05-24 22:57:14 [INFO]: Epoch 128 - generator training loss: -0.0449, discriminator training loss: 0.1345, validation loss: 0.0697
2024-05-24 22:57:18 [INFO]: Epoch 129 - generator training loss: -0.0446, discriminator training loss: 0.1342, validation loss: 0.0715
2024-05-24 22:57:22 [INFO]: Epoch 130 - generator training loss: -0.0441, discriminator training loss: 0.1339, validation loss: 0.0692
2024-05-24 22:57:27 [INFO]: Epoch 131 - generator training loss: -0.0453, discriminator training loss: 0.1341, validation loss: 0.0703
2024-05-24 22:57:31 [INFO]: Epoch 132 - generator training loss: -0.0462, discriminator training loss: 0.1338, validation loss: 0.0695
2024-05-24 22:57:35 [INFO]: Epoch 133 - generator training loss: -0.0464, discriminator training loss: 0.1338, validation loss: 0.0691
2024-05-24 22:57:39 [INFO]: Epoch 134 - generator training loss: -0.0465, discriminator training loss: 0.1340, validation loss: 0.0698
2024-05-24 22:57:43 [INFO]: Epoch 135 - generator training loss: -0.0471, discriminator training loss: 0.1335, validation loss: 0.0688
2024-05-24 22:57:47 [INFO]: Epoch 136 - generator training loss: -0.0468, discriminator training loss: 0.1334, validation loss: 0.0689
2024-05-24 22:57:51 [INFO]: Epoch 137 - generator training loss: -0.0475, discriminator training loss: 0.1330, validation loss: 0.0681
2024-05-24 22:57:55 [INFO]: Epoch 138 - generator training loss: -0.0473, discriminator training loss: 0.1332, validation loss: 0.0683
2024-05-24 22:57:59 [INFO]: Epoch 139 - generator training loss: -0.0476, discriminator training loss: 0.1330, validation loss: 0.0683
2024-05-24 22:58:04 [INFO]: Epoch 140 - generator training loss: -0.0474, discriminator training loss: 0.1330, validation loss: 0.0680
2024-05-24 22:58:08 [INFO]: Epoch 141 - generator training loss: -0.0476, discriminator training loss: 0.1328, validation loss: 0.0683
2024-05-24 22:58:12 [INFO]: Epoch 142 - generator training loss: -0.0477, discriminator training loss: 0.1329, validation loss: 0.0683
2024-05-24 22:58:16 [INFO]: Epoch 143 - generator training loss: -0.0474, discriminator training loss: 0.1330, validation loss: 0.0681
2024-05-24 22:58:20 [INFO]: Epoch 144 - generator training loss: -0.0474, discriminator training loss: 0.1324, validation loss: 0.0678
2024-05-24 22:58:24 [INFO]: Epoch 145 - generator training loss: -0.0470, discriminator training loss: 0.1322, validation loss: 0.0674
2024-05-24 22:58:28 [INFO]: Epoch 146 - generator training loss: -0.0481, discriminator training loss: 0.1325, validation loss: 0.0676
2024-05-24 22:58:32 [INFO]: Epoch 147 - generator training loss: -0.0483, discriminator training loss: 0.1321, validation loss: 0.0676
2024-05-24 22:58:36 [INFO]: Epoch 148 - generator training loss: -0.0481, discriminator training loss: 0.1325, validation loss: 0.0673
2024-05-24 22:58:40 [INFO]: Epoch 149 - generator training loss: -0.0475, discriminator training loss: 0.1319, validation loss: 0.0684
2024-05-24 22:58:44 [INFO]: Epoch 150 - generator training loss: -0.0486, discriminator training loss: 0.1318, validation loss: 0.0673
2024-05-24 22:58:49 [INFO]: Epoch 151 - generator training loss: -0.0481, discriminator training loss: 0.1320, validation loss: 0.0682
2024-05-24 22:58:53 [INFO]: Epoch 152 - generator training loss: -0.0486, discriminator training loss: 0.1319, validation loss: 0.0680
2024-05-24 22:58:57 [INFO]: Epoch 153 - generator training loss: -0.0489, discriminator training loss: 0.1316, validation loss: 0.0676
2024-05-24 22:59:01 [INFO]: Epoch 154 - generator training loss: -0.0488, discriminator training loss: 0.1315, validation loss: 0.0684
2024-05-24 22:59:05 [INFO]: Epoch 155 - generator training loss: -0.0482, discriminator training loss: 0.1314, validation loss: 0.0680
2024-05-24 22:59:09 [INFO]: Epoch 156 - generator training loss: -0.0486, discriminator training loss: 0.1312, validation loss: 0.0678
2024-05-24 22:59:13 [INFO]: Epoch 157 - generator training loss: -0.0487, discriminator training loss: 0.1313, validation loss: 0.0676
2024-05-24 22:59:17 [INFO]: Epoch 158 - generator training loss: -0.0489, discriminator training loss: 0.1312, validation loss: 0.0681
2024-05-24 22:59:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 22:59:17 [INFO]: Finished training. The best model is from epoch#148.
2024-05-24 22:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240524_T224828/USGAN.pypots
2024-05-24 22:59:18 [INFO]: US-GAN on Air-Quality: MAE=0.1402, MSE=0.0835
2024-05-24 22:59:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-24 22:59:18 [INFO]: Using the given device: cuda:0
2024-05-24 22:59:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240524_T225918
2024-05-24 22:59:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240524_T225918/tensorboard
2024-05-24 22:59:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-24 22:59:22 [INFO]: Epoch 001 - training loss: 1.4190, validation loss: 0.9280
2024-05-24 22:59:25 [INFO]: Epoch 002 - training loss: 1.1453, validation loss: 0.6929
2024-05-24 22:59:27 [INFO]: Epoch 003 - training loss: 0.9538, validation loss: 0.5809
2024-05-24 22:59:30 [INFO]: Epoch 004 - training loss: 0.8427, validation loss: 0.5117
2024-05-24 22:59:33 [INFO]: Epoch 005 - training loss: 0.7660, validation loss: 0.4612
2024-05-24 22:59:36 [INFO]: Epoch 006 - training loss: 0.7107, validation loss: 0.4228
2024-05-24 22:59:39 [INFO]: Epoch 007 - training loss: 0.6643, validation loss: 0.3941
2024-05-24 22:59:41 [INFO]: Epoch 008 - training loss: 0.6310, validation loss: 0.3688
2024-05-24 22:59:44 [INFO]: Epoch 009 - training loss: 0.6064, validation loss: 0.3498
2024-05-24 22:59:47 [INFO]: Epoch 010 - training loss: 0.5848, validation loss: 0.3326
2024-05-24 22:59:50 [INFO]: Epoch 011 - training loss: 0.5668, validation loss: 0.3179
2024-05-24 22:59:53 [INFO]: Epoch 012 - training loss: 0.5512, validation loss: 0.3058
2024-05-24 22:59:55 [INFO]: Epoch 013 - training loss: 0.5395, validation loss: 0.2947
2024-05-24 22:59:58 [INFO]: Epoch 014 - training loss: 0.5280, validation loss: 0.2853
2024-05-24 23:00:01 [INFO]: Epoch 015 - training loss: 0.5167, validation loss: 0.2765
2024-05-24 23:00:04 [INFO]: Epoch 016 - training loss: 0.5059, validation loss: 0.2688
2024-05-24 23:00:07 [INFO]: Epoch 017 - training loss: 0.4969, validation loss: 0.2623
2024-05-24 23:00:09 [INFO]: Epoch 018 - training loss: 0.4873, validation loss: 0.2564
2024-05-24 23:00:12 [INFO]: Epoch 019 - training loss: 0.4807, validation loss: 0.2507
2024-05-24 23:00:15 [INFO]: Epoch 020 - training loss: 0.4731, validation loss: 0.2453
2024-05-24 23:00:18 [INFO]: Epoch 021 - training loss: 0.4663, validation loss: 0.2404
2024-05-24 23:00:21 [INFO]: Epoch 022 - training loss: 0.4597, validation loss: 0.2359
2024-05-24 23:00:23 [INFO]: Epoch 023 - training loss: 0.4531, validation loss: 0.2314
2024-05-24 23:00:26 [INFO]: Epoch 024 - training loss: 0.4476, validation loss: 0.2270
2024-05-24 23:00:29 [INFO]: Epoch 025 - training loss: 0.4409, validation loss: 0.2231
2024-05-24 23:00:32 [INFO]: Epoch 026 - training loss: 0.4356, validation loss: 0.2190
2024-05-24 23:00:35 [INFO]: Epoch 027 - training loss: 0.4309, validation loss: 0.2158
2024-05-24 23:00:38 [INFO]: Epoch 028 - training loss: 0.4251, validation loss: 0.2119
2024-05-24 23:00:40 [INFO]: Epoch 029 - training loss: 0.4196, validation loss: 0.2086
2024-05-24 23:00:43 [INFO]: Epoch 030 - training loss: 0.4164, validation loss: 0.2053
2024-05-24 23:00:46 [INFO]: Epoch 031 - training loss: 0.4106, validation loss: 0.2020
2024-05-24 23:00:49 [INFO]: Epoch 032 - training loss: 0.4074, validation loss: 0.1993
2024-05-24 23:00:52 [INFO]: Epoch 033 - training loss: 0.4028, validation loss: 0.1957
2024-05-24 23:00:54 [INFO]: Epoch 034 - training loss: 0.3982, validation loss: 0.1931
2024-05-24 23:00:57 [INFO]: Epoch 035 - training loss: 0.3946, validation loss: 0.1901
2024-05-24 23:01:00 [INFO]: Epoch 036 - training loss: 0.3900, validation loss: 0.1875
2024-05-24 23:01:03 [INFO]: Epoch 037 - training loss: 0.3866, validation loss: 0.1848
2024-05-24 23:01:06 [INFO]: Epoch 038 - training loss: 0.3835, validation loss: 0.1826
2024-05-24 23:01:09 [INFO]: Epoch 039 - training loss: 0.3797, validation loss: 0.1804
2024-05-24 23:01:11 [INFO]: Epoch 040 - training loss: 0.3762, validation loss: 0.1781
2024-05-24 23:01:14 [INFO]: Epoch 041 - training loss: 0.3733, validation loss: 0.1755
2024-05-24 23:01:17 [INFO]: Epoch 042 - training loss: 0.3703, validation loss: 0.1737
2024-05-24 23:01:20 [INFO]: Epoch 043 - training loss: 0.3672, validation loss: 0.1712
2024-05-24 23:01:23 [INFO]: Epoch 044 - training loss: 0.3651, validation loss: 0.1696
2024-05-24 23:01:25 [INFO]: Epoch 045 - training loss: 0.3610, validation loss: 0.1675
2024-05-24 23:01:28 [INFO]: Epoch 046 - training loss: 0.3589, validation loss: 0.1657
2024-05-24 23:01:31 [INFO]: Epoch 047 - training loss: 0.3567, validation loss: 0.1638
2024-05-24 23:01:34 [INFO]: Epoch 048 - training loss: 0.3534, validation loss: 0.1620
2024-05-24 23:01:37 [INFO]: Epoch 049 - training loss: 0.3510, validation loss: 0.1607
2024-05-24 23:01:39 [INFO]: Epoch 050 - training loss: 0.3485, validation loss: 0.1588
2024-05-24 23:01:42 [INFO]: Epoch 051 - training loss: 0.3464, validation loss: 0.1573
2024-05-24 23:01:45 [INFO]: Epoch 052 - training loss: 0.3435, validation loss: 0.1560
2024-05-24 23:01:48 [INFO]: Epoch 053 - training loss: 0.3429, validation loss: 0.1544
2024-05-24 23:01:51 [INFO]: Epoch 054 - training loss: 0.3401, validation loss: 0.1530
2024-05-24 23:01:53 [INFO]: Epoch 055 - training loss: 0.3382, validation loss: 0.1518
2024-05-24 23:01:56 [INFO]: Epoch 056 - training loss: 0.3360, validation loss: 0.1504
2024-05-24 23:01:59 [INFO]: Epoch 057 - training loss: 0.3343, validation loss: 0.1492
2024-05-24 23:02:02 [INFO]: Epoch 058 - training loss: 0.3336, validation loss: 0.1478
2024-05-24 23:02:05 [INFO]: Epoch 059 - training loss: 0.3307, validation loss: 0.1465
2024-05-24 23:02:07 [INFO]: Epoch 060 - training loss: 0.3296, validation loss: 0.1455
2024-05-24 23:02:10 [INFO]: Epoch 061 - training loss: 0.3272, validation loss: 0.1442
2024-05-24 23:02:13 [INFO]: Epoch 062 - training loss: 0.3263, validation loss: 0.1431
2024-05-24 23:02:16 [INFO]: Epoch 063 - training loss: 0.3241, validation loss: 0.1421
2024-05-24 23:02:19 [INFO]: Epoch 064 - training loss: 0.3228, validation loss: 0.1408
2024-05-24 23:02:21 [INFO]: Epoch 065 - training loss: 0.3215, validation loss: 0.1403
2024-05-24 23:02:24 [INFO]: Epoch 066 - training loss: 0.3194, validation loss: 0.1387
2024-05-24 23:02:27 [INFO]: Epoch 067 - training loss: 0.3187, validation loss: 0.1382
2024-05-24 23:02:30 [INFO]: Epoch 068 - training loss: 0.3171, validation loss: 0.1369
2024-05-24 23:02:33 [INFO]: Epoch 069 - training loss: 0.3164, validation loss: 0.1360
2024-05-24 23:02:35 [INFO]: Epoch 070 - training loss: 0.3151, validation loss: 0.1349
2024-05-24 23:02:38 [INFO]: Epoch 071 - training loss: 0.3134, validation loss: 0.1339
2024-05-24 23:02:41 [INFO]: Epoch 072 - training loss: 0.3123, validation loss: 0.1333
2024-05-24 23:02:44 [INFO]: Epoch 073 - training loss: 0.3110, validation loss: 0.1320
2024-05-24 23:02:47 [INFO]: Epoch 074 - training loss: 0.3096, validation loss: 0.1313
2024-05-24 23:02:50 [INFO]: Epoch 075 - training loss: 0.3090, validation loss: 0.1310
2024-05-24 23:02:52 [INFO]: Epoch 076 - training loss: 0.3076, validation loss: 0.1300
2024-05-24 23:02:55 [INFO]: Epoch 077 - training loss: 0.3069, validation loss: 0.1290
2024-05-24 23:02:58 [INFO]: Epoch 078 - training loss: 0.3061, validation loss: 0.1281
2024-05-24 23:03:01 [INFO]: Epoch 079 - training loss: 0.3049, validation loss: 0.1275
2024-05-24 23:03:04 [INFO]: Epoch 080 - training loss: 0.3037, validation loss: 0.1265
2024-05-24 23:03:06 [INFO]: Epoch 081 - training loss: 0.3031, validation loss: 0.1257
2024-05-24 23:03:09 [INFO]: Epoch 082 - training loss: 0.3020, validation loss: 0.1254
2024-05-24 23:03:12 [INFO]: Epoch 083 - training loss: 0.3022, validation loss: 0.1243
2024-05-24 23:03:15 [INFO]: Epoch 084 - training loss: 0.3003, validation loss: 0.1238
2024-05-24 23:03:18 [INFO]: Epoch 085 - training loss: 0.2989, validation loss: 0.1230
2024-05-24 23:03:21 [INFO]: Epoch 086 - training loss: 0.2982, validation loss: 0.1222
2024-05-24 23:03:23 [INFO]: Epoch 087 - training loss: 0.2972, validation loss: 0.1219
2024-05-24 23:03:26 [INFO]: Epoch 088 - training loss: 0.2964, validation loss: 0.1210
2024-05-24 23:03:29 [INFO]: Epoch 089 - training loss: 0.2957, validation loss: 0.1205
2024-05-24 23:03:32 [INFO]: Epoch 090 - training loss: 0.2956, validation loss: 0.1199
2024-05-24 23:03:35 [INFO]: Epoch 091 - training loss: 0.2940, validation loss: 0.1191
2024-05-24 23:03:37 [INFO]: Epoch 092 - training loss: 0.2938, validation loss: 0.1185
2024-05-24 23:03:40 [INFO]: Epoch 093 - training loss: 0.2934, validation loss: 0.1178
2024-05-24 23:03:43 [INFO]: Epoch 094 - training loss: 0.2924, validation loss: 0.1172
2024-05-24 23:03:46 [INFO]: Epoch 095 - training loss: 0.2914, validation loss: 0.1168
2024-05-24 23:03:49 [INFO]: Epoch 096 - training loss: 0.2906, validation loss: 0.1162
2024-05-24 23:03:51 [INFO]: Epoch 097 - training loss: 0.2902, validation loss: 0.1155
2024-05-24 23:03:54 [INFO]: Epoch 098 - training loss: 0.2895, validation loss: 0.1149
2024-05-24 23:03:57 [INFO]: Epoch 099 - training loss: 0.2893, validation loss: 0.1145
2024-05-24 23:04:00 [INFO]: Epoch 100 - training loss: 0.2879, validation loss: 0.1140
2024-05-24 23:04:03 [INFO]: Epoch 101 - training loss: 0.2867, validation loss: 0.1134
2024-05-24 23:04:05 [INFO]: Epoch 102 - training loss: 0.2869, validation loss: 0.1129
2024-05-24 23:04:08 [INFO]: Epoch 103 - training loss: 0.2862, validation loss: 0.1124
2024-05-24 23:04:11 [INFO]: Epoch 104 - training loss: 0.2860, validation loss: 0.1117
2024-05-24 23:04:14 [INFO]: Epoch 105 - training loss: 0.2851, validation loss: 0.1115
2024-05-24 23:04:17 [INFO]: Epoch 106 - training loss: 0.2845, validation loss: 0.1111
2024-05-24 23:04:19 [INFO]: Epoch 107 - training loss: 0.2845, validation loss: 0.1105
2024-05-24 23:04:22 [INFO]: Epoch 108 - training loss: 0.2833, validation loss: 0.1098
2024-05-24 23:04:25 [INFO]: Epoch 109 - training loss: 0.2827, validation loss: 0.1093
2024-05-24 23:04:28 [INFO]: Epoch 110 - training loss: 0.2828, validation loss: 0.1091
2024-05-24 23:04:31 [INFO]: Epoch 111 - training loss: 0.2814, validation loss: 0.1087
2024-05-24 23:04:33 [INFO]: Epoch 112 - training loss: 0.2808, validation loss: 0.1080
2024-05-24 23:04:36 [INFO]: Epoch 113 - training loss: 0.2807, validation loss: 0.1077
2024-05-24 23:04:39 [INFO]: Epoch 114 - training loss: 0.2802, validation loss: 0.1075
2024-05-24 23:04:42 [INFO]: Epoch 115 - training loss: 0.2793, validation loss: 0.1067
2024-05-24 23:04:45 [INFO]: Epoch 116 - training loss: 0.2799, validation loss: 0.1066
2024-05-24 23:04:48 [INFO]: Epoch 117 - training loss: 0.2786, validation loss: 0.1060
2024-05-24 23:04:50 [INFO]: Epoch 118 - training loss: 0.2779, validation loss: 0.1055
2024-05-24 23:04:53 [INFO]: Epoch 119 - training loss: 0.2783, validation loss: 0.1053
2024-05-24 23:04:56 [INFO]: Epoch 120 - training loss: 0.2771, validation loss: 0.1049
2024-05-24 23:04:59 [INFO]: Epoch 121 - training loss: 0.2766, validation loss: 0.1044
2024-05-24 23:05:02 [INFO]: Epoch 122 - training loss: 0.2752, validation loss: 0.1041
2024-05-24 23:05:04 [INFO]: Epoch 123 - training loss: 0.2755, validation loss: 0.1038
2024-05-24 23:05:07 [INFO]: Epoch 124 - training loss: 0.2754, validation loss: 0.1033
2024-05-24 23:05:10 [INFO]: Epoch 125 - training loss: 0.2746, validation loss: 0.1029
2024-05-24 23:05:13 [INFO]: Epoch 126 - training loss: 0.2737, validation loss: 0.1025
2024-05-24 23:05:16 [INFO]: Epoch 127 - training loss: 0.2738, validation loss: 0.1021
2024-05-24 23:05:18 [INFO]: Epoch 128 - training loss: 0.2730, validation loss: 0.1019
2024-05-24 23:05:21 [INFO]: Epoch 129 - training loss: 0.2730, validation loss: 0.1015
2024-05-24 23:05:24 [INFO]: Epoch 130 - training loss: 0.2725, validation loss: 0.1012
2024-05-24 23:05:27 [INFO]: Epoch 131 - training loss: 0.2715, validation loss: 0.1009
2024-05-24 23:05:30 [INFO]: Epoch 132 - training loss: 0.2711, validation loss: 0.1005
2024-05-24 23:05:33 [INFO]: Epoch 133 - training loss: 0.2709, validation loss: 0.1003
2024-05-24 23:05:35 [INFO]: Epoch 134 - training loss: 0.2705, validation loss: 0.0999
2024-05-24 23:05:38 [INFO]: Epoch 135 - training loss: 0.2698, validation loss: 0.0994
2024-05-24 23:05:41 [INFO]: Epoch 136 - training loss: 0.2698, validation loss: 0.0990
2024-05-24 23:05:44 [INFO]: Epoch 137 - training loss: 0.2693, validation loss: 0.0986
2024-05-24 23:05:47 [INFO]: Epoch 138 - training loss: 0.2692, validation loss: 0.0984
2024-05-24 23:05:49 [INFO]: Epoch 139 - training loss: 0.2690, validation loss: 0.0983
2024-05-24 23:05:52 [INFO]: Epoch 140 - training loss: 0.2680, validation loss: 0.0979
2024-05-24 23:05:55 [INFO]: Epoch 141 - training loss: 0.2682, validation loss: 0.0974
2024-05-24 23:05:58 [INFO]: Epoch 142 - training loss: 0.2685, validation loss: 0.0972
2024-05-24 23:06:01 [INFO]: Epoch 143 - training loss: 0.2667, validation loss: 0.0967
2024-05-24 23:06:03 [INFO]: Epoch 144 - training loss: 0.2665, validation loss: 0.0967
2024-05-24 23:06:06 [INFO]: Epoch 145 - training loss: 0.2665, validation loss: 0.0964
2024-05-24 23:06:09 [INFO]: Epoch 146 - training loss: 0.2653, validation loss: 0.0960
2024-05-24 23:06:12 [INFO]: Epoch 147 - training loss: 0.2654, validation loss: 0.0956
2024-05-24 23:06:15 [INFO]: Epoch 148 - training loss: 0.2650, validation loss: 0.0956
2024-05-24 23:06:17 [INFO]: Epoch 149 - training loss: 0.2648, validation loss: 0.0953
2024-05-24 23:06:20 [INFO]: Epoch 150 - training loss: 0.2644, validation loss: 0.0947
2024-05-24 23:06:23 [INFO]: Epoch 151 - training loss: 0.2642, validation loss: 0.0947
2024-05-24 23:06:26 [INFO]: Epoch 152 - training loss: 0.2640, validation loss: 0.0944
2024-05-24 23:06:29 [INFO]: Epoch 153 - training loss: 0.2634, validation loss: 0.0940
2024-05-24 23:06:31 [INFO]: Epoch 154 - training loss: 0.2629, validation loss: 0.0938
2024-05-24 23:06:34 [INFO]: Epoch 155 - training loss: 0.2628, validation loss: 0.0934
2024-05-24 23:06:37 [INFO]: Epoch 156 - training loss: 0.2626, validation loss: 0.0933
2024-05-24 23:06:40 [INFO]: Epoch 157 - training loss: 0.2630, validation loss: 0.0931
2024-05-24 23:06:43 [INFO]: Epoch 158 - training loss: 0.2615, validation loss: 0.0930
2024-05-24 23:06:45 [INFO]: Epoch 159 - training loss: 0.2621, validation loss: 0.0924
2024-05-24 23:06:48 [INFO]: Epoch 160 - training loss: 0.2611, validation loss: 0.0923
2024-05-24 23:06:51 [INFO]: Epoch 161 - training loss: 0.2609, validation loss: 0.0918
2024-05-24 23:06:54 [INFO]: Epoch 162 - training loss: 0.2608, validation loss: 0.0916
2024-05-24 23:06:57 [INFO]: Epoch 163 - training loss: 0.2610, validation loss: 0.0915
2024-05-24 23:07:00 [INFO]: Epoch 164 - training loss: 0.2601, validation loss: 0.0912
2024-05-24 23:07:02 [INFO]: Epoch 165 - training loss: 0.2596, validation loss: 0.0911
2024-05-24 23:07:05 [INFO]: Epoch 166 - training loss: 0.2590, validation loss: 0.0908
2024-05-24 23:07:08 [INFO]: Epoch 167 - training loss: 0.2598, validation loss: 0.0906
2024-05-24 23:07:11 [INFO]: Epoch 168 - training loss: 0.2592, validation loss: 0.0902
2024-05-24 23:07:14 [INFO]: Epoch 169 - training loss: 0.2583, validation loss: 0.0901
2024-05-24 23:07:16 [INFO]: Epoch 170 - training loss: 0.2582, validation loss: 0.0899
2024-05-24 23:07:19 [INFO]: Epoch 171 - training loss: 0.2582, validation loss: 0.0899
2024-05-24 23:07:22 [INFO]: Epoch 172 - training loss: 0.2575, validation loss: 0.0895
2024-05-24 23:07:25 [INFO]: Epoch 173 - training loss: 0.2577, validation loss: 0.0893
2024-05-24 23:07:28 [INFO]: Epoch 174 - training loss: 0.2571, validation loss: 0.0891
2024-05-24 23:07:30 [INFO]: Epoch 175 - training loss: 0.2565, validation loss: 0.0890
2024-05-24 23:07:33 [INFO]: Epoch 176 - training loss: 0.2566, validation loss: 0.0887
2024-05-24 23:07:36 [INFO]: Epoch 177 - training loss: 0.2563, validation loss: 0.0885
2024-05-24 23:07:39 [INFO]: Epoch 178 - training loss: 0.2565, validation loss: 0.0881
2024-05-24 23:07:42 [INFO]: Epoch 179 - training loss: 0.2560, validation loss: 0.0880
2024-05-24 23:07:45 [INFO]: Epoch 180 - training loss: 0.2555, validation loss: 0.0879
2024-05-24 23:07:47 [INFO]: Epoch 181 - training loss: 0.2556, validation loss: 0.0878
2024-05-24 23:07:50 [INFO]: Epoch 182 - training loss: 0.2549, validation loss: 0.0874
2024-05-24 23:07:53 [INFO]: Epoch 183 - training loss: 0.2550, validation loss: 0.0874
2024-05-24 23:07:56 [INFO]: Epoch 184 - training loss: 0.2546, validation loss: 0.0873
2024-05-24 23:07:59 [INFO]: Epoch 185 - training loss: 0.2542, validation loss: 0.0868
2024-05-24 23:08:01 [INFO]: Epoch 186 - training loss: 0.2543, validation loss: 0.0868
2024-05-24 23:08:04 [INFO]: Epoch 187 - training loss: 0.2538, validation loss: 0.0866
2024-05-24 23:08:07 [INFO]: Epoch 188 - training loss: 0.2536, validation loss: 0.0863
2024-05-24 23:08:10 [INFO]: Epoch 189 - training loss: 0.2539, validation loss: 0.0862
2024-05-24 23:08:13 [INFO]: Epoch 190 - training loss: 0.2533, validation loss: 0.0861
2024-05-24 23:08:15 [INFO]: Epoch 191 - training loss: 0.2529, validation loss: 0.0857
2024-05-24 23:08:18 [INFO]: Epoch 192 - training loss: 0.2527, validation loss: 0.0857
2024-05-24 23:08:21 [INFO]: Epoch 193 - training loss: 0.2527, validation loss: 0.0855
2024-05-24 23:08:24 [INFO]: Epoch 194 - training loss: 0.2529, validation loss: 0.0854
2024-05-24 23:08:27 [INFO]: Epoch 195 - training loss: 0.2522, validation loss: 0.0851
2024-05-24 23:08:29 [INFO]: Epoch 196 - training loss: 0.2517, validation loss: 0.0850
2024-05-24 23:08:32 [INFO]: Epoch 197 - training loss: 0.2516, validation loss: 0.0849
2024-05-24 23:08:35 [INFO]: Epoch 198 - training loss: 0.2516, validation loss: 0.0847
2024-05-24 23:08:38 [INFO]: Epoch 199 - training loss: 0.2517, validation loss: 0.0844
2024-05-24 23:08:41 [INFO]: Epoch 200 - training loss: 0.2511, validation loss: 0.0845
2024-05-24 23:08:43 [INFO]: Epoch 201 - training loss: 0.2508, validation loss: 0.0843
2024-05-24 23:08:46 [INFO]: Epoch 202 - training loss: 0.2510, validation loss: 0.0839
2024-05-24 23:08:49 [INFO]: Epoch 203 - training loss: 0.2502, validation loss: 0.0839
2024-05-24 23:08:52 [INFO]: Epoch 204 - training loss: 0.2505, validation loss: 0.0838
2024-05-24 23:08:55 [INFO]: Epoch 205 - training loss: 0.2505, validation loss: 0.0836
2024-05-24 23:08:58 [INFO]: Epoch 206 - training loss: 0.2494, validation loss: 0.0834
2024-05-24 23:09:00 [INFO]: Epoch 207 - training loss: 0.2492, validation loss: 0.0834
2024-05-24 23:09:03 [INFO]: Epoch 208 - training loss: 0.2494, validation loss: 0.0833
2024-05-24 23:09:06 [INFO]: Epoch 209 - training loss: 0.2495, validation loss: 0.0832
2024-05-24 23:09:09 [INFO]: Epoch 210 - training loss: 0.2494, validation loss: 0.0830
2024-05-24 23:09:12 [INFO]: Epoch 211 - training loss: 0.2493, validation loss: 0.0826
2024-05-24 23:09:14 [INFO]: Epoch 212 - training loss: 0.2496, validation loss: 0.0827
2024-05-24 23:09:17 [INFO]: Epoch 213 - training loss: 0.2484, validation loss: 0.0827
2024-05-24 23:09:20 [INFO]: Epoch 214 - training loss: 0.2479, validation loss: 0.0823
2024-05-24 23:09:23 [INFO]: Epoch 215 - training loss: 0.2478, validation loss: 0.0821
2024-05-24 23:09:26 [INFO]: Epoch 216 - training loss: 0.2476, validation loss: 0.0821
2024-05-24 23:09:28 [INFO]: Epoch 217 - training loss: 0.2479, validation loss: 0.0819
2024-05-24 23:09:31 [INFO]: Epoch 218 - training loss: 0.2471, validation loss: 0.0819
2024-05-24 23:09:34 [INFO]: Epoch 219 - training loss: 0.2468, validation loss: 0.0817
2024-05-24 23:09:37 [INFO]: Epoch 220 - training loss: 0.2472, validation loss: 0.0816
2024-05-24 23:09:40 [INFO]: Epoch 221 - training loss: 0.2470, validation loss: 0.0816
2024-05-24 23:09:42 [INFO]: Epoch 222 - training loss: 0.2472, validation loss: 0.0814
2024-05-24 23:09:45 [INFO]: Epoch 223 - training loss: 0.2462, validation loss: 0.0813
2024-05-24 23:09:48 [INFO]: Epoch 224 - training loss: 0.2460, validation loss: 0.0811
2024-05-24 23:09:51 [INFO]: Epoch 225 - training loss: 0.2461, validation loss: 0.0810
2024-05-24 23:09:54 [INFO]: Epoch 226 - training loss: 0.2463, validation loss: 0.0808
2024-05-24 23:09:57 [INFO]: Epoch 227 - training loss: 0.2455, validation loss: 0.0808
2024-05-24 23:09:59 [INFO]: Epoch 228 - training loss: 0.2453, validation loss: 0.0805
2024-05-24 23:10:02 [INFO]: Epoch 229 - training loss: 0.2454, validation loss: 0.0804
2024-05-24 23:10:05 [INFO]: Epoch 230 - training loss: 0.2450, validation loss: 0.0805
2024-05-24 23:10:08 [INFO]: Epoch 231 - training loss: 0.2446, validation loss: 0.0804
2024-05-24 23:10:11 [INFO]: Epoch 232 - training loss: 0.2448, validation loss: 0.0801
2024-05-24 23:10:13 [INFO]: Epoch 233 - training loss: 0.2447, validation loss: 0.0801
2024-05-24 23:10:16 [INFO]: Epoch 234 - training loss: 0.2451, validation loss: 0.0799
2024-05-24 23:10:19 [INFO]: Epoch 235 - training loss: 0.2445, validation loss: 0.0798
2024-05-24 23:10:22 [INFO]: Epoch 236 - training loss: 0.2439, validation loss: 0.0797
2024-05-24 23:10:25 [INFO]: Epoch 237 - training loss: 0.2445, validation loss: 0.0796
2024-05-24 23:10:27 [INFO]: Epoch 238 - training loss: 0.2441, validation loss: 0.0796
2024-05-24 23:10:30 [INFO]: Epoch 239 - training loss: 0.2441, validation loss: 0.0792
2024-05-24 23:10:33 [INFO]: Epoch 240 - training loss: 0.2439, validation loss: 0.0792
2024-05-24 23:10:36 [INFO]: Epoch 241 - training loss: 0.2434, validation loss: 0.0791
2024-05-24 23:10:39 [INFO]: Epoch 242 - training loss: 0.2434, validation loss: 0.0790
2024-05-24 23:10:41 [INFO]: Epoch 243 - training loss: 0.2430, validation loss: 0.0791
2024-05-24 23:10:44 [INFO]: Epoch 244 - training loss: 0.2429, validation loss: 0.0789
2024-05-24 23:10:47 [INFO]: Epoch 245 - training loss: 0.2427, validation loss: 0.0788
2024-05-24 23:10:50 [INFO]: Epoch 246 - training loss: 0.2428, validation loss: 0.0787
2024-05-24 23:10:53 [INFO]: Epoch 247 - training loss: 0.2423, validation loss: 0.0784
2024-05-24 23:10:55 [INFO]: Epoch 248 - training loss: 0.2425, validation loss: 0.0786
2024-05-24 23:10:58 [INFO]: Epoch 249 - training loss: 0.2417, validation loss: 0.0785
2024-05-24 23:11:01 [INFO]: Epoch 250 - training loss: 0.2417, validation loss: 0.0784
2024-05-24 23:11:04 [INFO]: Epoch 251 - training loss: 0.2419, validation loss: 0.0782
2024-05-24 23:11:07 [INFO]: Epoch 252 - training loss: 0.2416, validation loss: 0.0782
2024-05-24 23:11:10 [INFO]: Epoch 253 - training loss: 0.2411, validation loss: 0.0780
2024-05-24 23:11:12 [INFO]: Epoch 254 - training loss: 0.2417, validation loss: 0.0781
2024-05-24 23:11:15 [INFO]: Epoch 255 - training loss: 0.2413, validation loss: 0.0778
2024-05-24 23:11:18 [INFO]: Epoch 256 - training loss: 0.2416, validation loss: 0.0778
2024-05-24 23:11:21 [INFO]: Epoch 257 - training loss: 0.2410, validation loss: 0.0776
2024-05-24 23:11:24 [INFO]: Epoch 258 - training loss: 0.2411, validation loss: 0.0777
2024-05-24 23:11:26 [INFO]: Epoch 259 - training loss: 0.2410, validation loss: 0.0776
2024-05-24 23:11:29 [INFO]: Epoch 260 - training loss: 0.2406, validation loss: 0.0774
2024-05-24 23:11:32 [INFO]: Epoch 261 - training loss: 0.2404, validation loss: 0.0772
2024-05-24 23:11:35 [INFO]: Epoch 262 - training loss: 0.2396, validation loss: 0.0772
2024-05-24 23:11:38 [INFO]: Epoch 263 - training loss: 0.2401, validation loss: 0.0772
2024-05-24 23:11:40 [INFO]: Epoch 264 - training loss: 0.2403, validation loss: 0.0771
2024-05-24 23:11:43 [INFO]: Epoch 265 - training loss: 0.2397, validation loss: 0.0769
2024-05-24 23:11:46 [INFO]: Epoch 266 - training loss: 0.2397, validation loss: 0.0770
2024-05-24 23:11:49 [INFO]: Epoch 267 - training loss: 0.2395, validation loss: 0.0769
2024-05-24 23:11:52 [INFO]: Epoch 268 - training loss: 0.2395, validation loss: 0.0768
2024-05-24 23:11:55 [INFO]: Epoch 269 - training loss: 0.2388, validation loss: 0.0766
2024-05-24 23:11:57 [INFO]: Epoch 270 - training loss: 0.2393, validation loss: 0.0767
2024-05-24 23:12:00 [INFO]: Epoch 271 - training loss: 0.2389, validation loss: 0.0766
2024-05-24 23:12:03 [INFO]: Epoch 272 - training loss: 0.2398, validation loss: 0.0765
2024-05-24 23:12:06 [INFO]: Epoch 273 - training loss: 0.2386, validation loss: 0.0764
2024-05-24 23:12:09 [INFO]: Epoch 274 - training loss: 0.2387, validation loss: 0.0763
2024-05-24 23:12:11 [INFO]: Epoch 275 - training loss: 0.2380, validation loss: 0.0764
2024-05-24 23:12:14 [INFO]: Epoch 276 - training loss: 0.2379, validation loss: 0.0763
2024-05-24 23:12:17 [INFO]: Epoch 277 - training loss: 0.2380, validation loss: 0.0762
2024-05-24 23:12:20 [INFO]: Epoch 278 - training loss: 0.2378, validation loss: 0.0760
2024-05-24 23:12:23 [INFO]: Epoch 279 - training loss: 0.2377, validation loss: 0.0762
2024-05-24 23:12:25 [INFO]: Epoch 280 - training loss: 0.2381, validation loss: 0.0761
2024-05-24 23:12:28 [INFO]: Epoch 281 - training loss: 0.2384, validation loss: 0.0760
2024-05-24 23:12:31 [INFO]: Epoch 282 - training loss: 0.2377, validation loss: 0.0759
2024-05-24 23:12:34 [INFO]: Epoch 283 - training loss: 0.2377, validation loss: 0.0757
2024-05-24 23:12:37 [INFO]: Epoch 284 - training loss: 0.2375, validation loss: 0.0756
2024-05-24 23:12:39 [INFO]: Epoch 285 - training loss: 0.2371, validation loss: 0.0757
2024-05-24 23:12:42 [INFO]: Epoch 286 - training loss: 0.2369, validation loss: 0.0756
2024-05-24 23:12:45 [INFO]: Epoch 287 - training loss: 0.2372, validation loss: 0.0756
2024-05-24 23:12:48 [INFO]: Epoch 288 - training loss: 0.2368, validation loss: 0.0755
2024-05-24 23:12:51 [INFO]: Epoch 289 - training loss: 0.2369, validation loss: 0.0753
2024-05-24 23:12:53 [INFO]: Epoch 290 - training loss: 0.2365, validation loss: 0.0755
2024-05-24 23:12:56 [INFO]: Epoch 291 - training loss: 0.2363, validation loss: 0.0754
2024-05-24 23:12:59 [INFO]: Epoch 292 - training loss: 0.2362, validation loss: 0.0753
2024-05-24 23:13:02 [INFO]: Epoch 293 - training loss: 0.2360, validation loss: 0.0752
2024-05-24 23:13:05 [INFO]: Epoch 294 - training loss: 0.2361, validation loss: 0.0752
2024-05-24 23:13:08 [INFO]: Epoch 295 - training loss: 0.2356, validation loss: 0.0751
2024-05-24 23:13:10 [INFO]: Epoch 296 - training loss: 0.2358, validation loss: 0.0750
2024-05-24 23:13:13 [INFO]: Epoch 297 - training loss: 0.2358, validation loss: 0.0749
2024-05-24 23:13:16 [INFO]: Epoch 298 - training loss: 0.2354, validation loss: 0.0750
2024-05-24 23:13:19 [INFO]: Epoch 299 - training loss: 0.2357, validation loss: 0.0748
2024-05-24 23:13:22 [INFO]: Epoch 300 - training loss: 0.2357, validation loss: 0.0748
2024-05-24 23:13:22 [INFO]: Finished training. The best model is from epoch#299.
2024-05-24 23:13:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240524_T225918/BRITS.pypots
2024-05-24 23:13:22 [INFO]: BRITS on Air-Quality: MAE=0.1364, MSE=0.0944
2024-05-24 23:13:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-24 23:13:22 [INFO]: Using the given device: cuda:0
2024-05-24 23:13:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322
2024-05-24 23:13:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/tensorboard
2024-05-24 23:13:22 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-24 23:13:27 [INFO]: Epoch 001 - training loss: 1.4886, validation loss: 0.8036
2024-05-24 23:13:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch1_loss0.8036398738622665.pypots
2024-05-24 23:13:31 [INFO]: Epoch 002 - training loss: 1.0455, validation loss: 0.7456
2024-05-24 23:13:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch2_loss0.7455884218215942.pypots
2024-05-24 23:13:35 [INFO]: Epoch 003 - training loss: 0.9834, validation loss: 0.7275
2024-05-24 23:13:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch3_loss0.7274597674608231.pypots
2024-05-24 23:13:39 [INFO]: Epoch 004 - training loss: 0.9442, validation loss: 0.7136
2024-05-24 23:13:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch4_loss0.7135972231626511.pypots
2024-05-24 23:13:42 [INFO]: Epoch 005 - training loss: 0.9313, validation loss: 0.7048
2024-05-24 23:13:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch5_loss0.7047702491283416.pypots
2024-05-24 23:13:46 [INFO]: Epoch 006 - training loss: 0.9269, validation loss: 0.6977
2024-05-24 23:13:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch6_loss0.6977119356393814.pypots
2024-05-24 23:13:50 [INFO]: Epoch 007 - training loss: 0.9247, validation loss: 0.6928
2024-05-24 23:13:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch7_loss0.6927919596433639.pypots
2024-05-24 23:13:54 [INFO]: Epoch 008 - training loss: 0.9071, validation loss: 0.6882
2024-05-24 23:13:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch8_loss0.6881953984498977.pypots
2024-05-24 23:13:58 [INFO]: Epoch 009 - training loss: 0.9010, validation loss: 0.6848
2024-05-24 23:13:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch9_loss0.6848095536231995.pypots
2024-05-24 23:14:02 [INFO]: Epoch 010 - training loss: 0.8963, validation loss: 0.6832
2024-05-24 23:14:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch10_loss0.6831670194864273.pypots
2024-05-24 23:14:06 [INFO]: Epoch 011 - training loss: 0.8964, validation loss: 0.6821
2024-05-24 23:14:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch11_loss0.6821489661931992.pypots
2024-05-24 23:14:09 [INFO]: Epoch 012 - training loss: 0.8902, validation loss: 0.6803
2024-05-24 23:14:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch12_loss0.6802768886089325.pypots
2024-05-24 23:14:13 [INFO]: Epoch 013 - training loss: 0.8801, validation loss: 0.6796
2024-05-24 23:14:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch13_loss0.679621496796608.pypots
2024-05-24 23:14:17 [INFO]: Epoch 014 - training loss: 0.8854, validation loss: 0.6784
2024-05-24 23:14:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch14_loss0.6784246921539306.pypots
2024-05-24 23:14:21 [INFO]: Epoch 015 - training loss: 0.8850, validation loss: 0.6793
2024-05-24 23:14:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch15_loss0.6792680084705353.pypots
2024-05-24 23:14:25 [INFO]: Epoch 016 - training loss: 0.8686, validation loss: 0.6775
2024-05-24 23:14:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch16_loss0.6775104492902756.pypots
2024-05-24 23:14:29 [INFO]: Epoch 017 - training loss: 0.8717, validation loss: 0.6768
2024-05-24 23:14:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch17_loss0.6767718702554703.pypots
2024-05-24 23:14:33 [INFO]: Epoch 018 - training loss: 0.8812, validation loss: 0.6766
2024-05-24 23:14:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch18_loss0.6765517115592956.pypots
2024-05-24 23:14:36 [INFO]: Epoch 019 - training loss: 0.8680, validation loss: 0.6770
2024-05-24 23:14:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch19_loss0.6769592493772507.pypots
2024-05-24 23:14:40 [INFO]: Epoch 020 - training loss: 0.8656, validation loss: 0.6745
2024-05-24 23:14:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch20_loss0.6744892746210098.pypots
2024-05-24 23:14:44 [INFO]: Epoch 021 - training loss: 0.8565, validation loss: 0.6769
2024-05-24 23:14:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch21_loss0.6768750101327896.pypots
2024-05-24 23:14:48 [INFO]: Epoch 022 - training loss: 0.8464, validation loss: 0.6748
2024-05-24 23:14:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch22_loss0.6748445063829422.pypots
2024-05-24 23:14:52 [INFO]: Epoch 023 - training loss: 0.8508, validation loss: 0.6757
2024-05-24 23:14:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch23_loss0.6757445454597473.pypots
2024-05-24 23:14:56 [INFO]: Epoch 024 - training loss: 0.8508, validation loss: 0.6755
2024-05-24 23:14:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch24_loss0.6755117654800415.pypots
2024-05-24 23:15:00 [INFO]: Epoch 025 - training loss: 0.8535, validation loss: 0.6760
2024-05-24 23:15:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch25_loss0.6759966254234314.pypots
2024-05-24 23:15:04 [INFO]: Epoch 026 - training loss: 0.8530, validation loss: 0.6759
2024-05-24 23:15:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch26_loss0.6759026557207107.pypots
2024-05-24 23:15:07 [INFO]: Epoch 027 - training loss: 0.8398, validation loss: 0.6769
2024-05-24 23:15:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch27_loss0.676870372891426.pypots
2024-05-24 23:15:11 [INFO]: Epoch 028 - training loss: 0.8460, validation loss: 0.6761
2024-05-24 23:15:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch28_loss0.676070562005043.pypots
2024-05-24 23:15:15 [INFO]: Epoch 029 - training loss: 0.8652, validation loss: 0.6763
2024-05-24 23:15:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch29_loss0.6762933909893036.pypots
2024-05-24 23:15:19 [INFO]: Epoch 030 - training loss: 0.8319, validation loss: 0.6768
2024-05-24 23:15:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN_epoch30_loss0.6768027544021606.pypots
2024-05-24 23:15:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:15:19 [INFO]: Finished training. The best model is from epoch#20.
2024-05-24 23:15:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240524_T231322/MRNN.pypots
2024-05-24 23:15:20 [INFO]: MRNN on Air-Quality: MAE=0.5174, MSE=0.5914
2024-05-24 23:15:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-24 23:15:20 [INFO]: Using the given device: cpu
2024-05-24 23:15:20 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2148
2024-05-24 23:15:20 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-24 23:15:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-24 23:15:20 [INFO]: Median on Air-Quality: MAE=0.6653, MSE=0.9982
2024-05-24 23:15:20 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-24 23:15:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-24 23:15:20 [INFO]: Mean on Air-Quality: MAE=0.6953, MSE=0.9349
2024-05-24 23:15:20 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-24 23:15:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-24 23:15:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-24 23:15:20 [INFO]: Using the given device: cuda:0
2024-05-24 23:15:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240524_T231520
2024-05-24 23:15:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240524_T231520/tensorboard
2024-05-24 23:15:20 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 23:15:21 [INFO]: Epoch 001 - training loss: 1.0432, validation loss: 0.5197
2024-05-24 23:15:21 [INFO]: Epoch 002 - training loss: 0.7533, validation loss: 0.3836
2024-05-24 23:15:22 [INFO]: Epoch 003 - training loss: 0.6508, validation loss: 0.3070
2024-05-24 23:15:22 [INFO]: Epoch 004 - training loss: 0.5812, validation loss: 0.2670
2024-05-24 23:15:23 [INFO]: Epoch 005 - training loss: 0.5288, validation loss: 0.2436
2024-05-24 23:15:24 [INFO]: Epoch 006 - training loss: 0.4907, validation loss: 0.2267
2024-05-24 23:15:24 [INFO]: Epoch 007 - training loss: 0.4614, validation loss: 0.2166
2024-05-24 23:15:25 [INFO]: Epoch 008 - training loss: 0.4396, validation loss: 0.2057
2024-05-24 23:15:25 [INFO]: Epoch 009 - training loss: 0.4240, validation loss: 0.2003
2024-05-24 23:15:26 [INFO]: Epoch 010 - training loss: 0.4122, validation loss: 0.1944
2024-05-24 23:15:27 [INFO]: Epoch 011 - training loss: 0.4020, validation loss: 0.1879
2024-05-24 23:15:27 [INFO]: Epoch 012 - training loss: 0.3919, validation loss: 0.1833
2024-05-24 23:15:28 [INFO]: Epoch 013 - training loss: 0.3837, validation loss: 0.1819
2024-05-24 23:15:28 [INFO]: Epoch 014 - training loss: 0.3754, validation loss: 0.1786
2024-05-24 23:15:29 [INFO]: Epoch 015 - training loss: 0.3682, validation loss: 0.1744
2024-05-24 23:15:30 [INFO]: Epoch 016 - training loss: 0.3630, validation loss: 0.1717
2024-05-24 23:15:30 [INFO]: Epoch 017 - training loss: 0.3570, validation loss: 0.1682
2024-05-24 23:15:31 [INFO]: Epoch 018 - training loss: 0.3522, validation loss: 0.1671
2024-05-24 23:15:31 [INFO]: Epoch 019 - training loss: 0.3466, validation loss: 0.1628
2024-05-24 23:15:32 [INFO]: Epoch 020 - training loss: 0.3433, validation loss: 0.1624
2024-05-24 23:15:33 [INFO]: Epoch 021 - training loss: 0.3376, validation loss: 0.1605
2024-05-24 23:15:33 [INFO]: Epoch 022 - training loss: 0.3332, validation loss: 0.1575
2024-05-24 23:15:34 [INFO]: Epoch 023 - training loss: 0.3294, validation loss: 0.1559
2024-05-24 23:15:34 [INFO]: Epoch 024 - training loss: 0.3266, validation loss: 0.1553
2024-05-24 23:15:35 [INFO]: Epoch 025 - training loss: 0.3233, validation loss: 0.1540
2024-05-24 23:15:36 [INFO]: Epoch 026 - training loss: 0.3198, validation loss: 0.1521
2024-05-24 23:15:36 [INFO]: Epoch 027 - training loss: 0.3166, validation loss: 0.1505
2024-05-24 23:15:37 [INFO]: Epoch 028 - training loss: 0.3135, validation loss: 0.1497
2024-05-24 23:15:38 [INFO]: Epoch 029 - training loss: 0.3106, validation loss: 0.1473
2024-05-24 23:15:38 [INFO]: Epoch 030 - training loss: 0.3083, validation loss: 0.1470
2024-05-24 23:15:39 [INFO]: Epoch 031 - training loss: 0.3050, validation loss: 0.1451
2024-05-24 23:15:39 [INFO]: Epoch 032 - training loss: 0.3036, validation loss: 0.1439
2024-05-24 23:15:40 [INFO]: Epoch 033 - training loss: 0.3002, validation loss: 0.1425
2024-05-24 23:15:41 [INFO]: Epoch 034 - training loss: 0.2985, validation loss: 0.1427
2024-05-24 23:15:41 [INFO]: Epoch 035 - training loss: 0.2965, validation loss: 0.1396
2024-05-24 23:15:42 [INFO]: Epoch 036 - training loss: 0.2944, validation loss: 0.1390
2024-05-24 23:15:42 [INFO]: Epoch 037 - training loss: 0.2916, validation loss: 0.1372
2024-05-24 23:15:43 [INFO]: Epoch 038 - training loss: 0.2899, validation loss: 0.1365
2024-05-24 23:15:44 [INFO]: Epoch 039 - training loss: 0.2883, validation loss: 0.1362
2024-05-24 23:15:44 [INFO]: Epoch 040 - training loss: 0.2858, validation loss: 0.1343
2024-05-24 23:15:45 [INFO]: Epoch 041 - training loss: 0.2840, validation loss: 0.1343
2024-05-24 23:15:45 [INFO]: Epoch 042 - training loss: 0.2822, validation loss: 0.1332
2024-05-24 23:15:46 [INFO]: Epoch 043 - training loss: 0.2814, validation loss: 0.1315
2024-05-24 23:15:47 [INFO]: Epoch 044 - training loss: 0.2793, validation loss: 0.1302
2024-05-24 23:15:47 [INFO]: Epoch 045 - training loss: 0.2768, validation loss: 0.1305
2024-05-24 23:15:48 [INFO]: Epoch 046 - training loss: 0.2741, validation loss: 0.1294
2024-05-24 23:15:48 [INFO]: Epoch 047 - training loss: 0.2751, validation loss: 0.1293
2024-05-24 23:15:49 [INFO]: Epoch 048 - training loss: 0.2722, validation loss: 0.1267
2024-05-24 23:15:50 [INFO]: Epoch 049 - training loss: 0.2712, validation loss: 0.1276
2024-05-24 23:15:50 [INFO]: Epoch 050 - training loss: 0.2691, validation loss: 0.1266
2024-05-24 23:15:51 [INFO]: Epoch 051 - training loss: 0.2671, validation loss: 0.1252
2024-05-24 23:15:51 [INFO]: Epoch 052 - training loss: 0.2645, validation loss: 0.1243
2024-05-24 23:15:52 [INFO]: Epoch 053 - training loss: 0.2636, validation loss: 0.1234
2024-05-24 23:15:53 [INFO]: Epoch 054 - training loss: 0.2619, validation loss: 0.1224
2024-05-24 23:15:53 [INFO]: Epoch 055 - training loss: 0.2613, validation loss: 0.1221
2024-05-24 23:15:54 [INFO]: Epoch 056 - training loss: 0.2599, validation loss: 0.1222
2024-05-24 23:15:54 [INFO]: Epoch 057 - training loss: 0.2573, validation loss: 0.1204
2024-05-24 23:15:55 [INFO]: Epoch 058 - training loss: 0.2551, validation loss: 0.1197
2024-05-24 23:15:56 [INFO]: Epoch 059 - training loss: 0.2541, validation loss: 0.1180
2024-05-24 23:15:56 [INFO]: Epoch 060 - training loss: 0.2524, validation loss: 0.1164
2024-05-24 23:15:57 [INFO]: Epoch 061 - training loss: 0.2510, validation loss: 0.1171
2024-05-24 23:15:57 [INFO]: Epoch 062 - training loss: 0.2499, validation loss: 0.1169
2024-05-24 23:15:58 [INFO]: Epoch 063 - training loss: 0.2485, validation loss: 0.1158
2024-05-24 23:15:59 [INFO]: Epoch 064 - training loss: 0.2465, validation loss: 0.1158
2024-05-24 23:15:59 [INFO]: Epoch 065 - training loss: 0.2455, validation loss: 0.1145
2024-05-24 23:16:00 [INFO]: Epoch 066 - training loss: 0.2444, validation loss: 0.1136
2024-05-24 23:16:00 [INFO]: Epoch 067 - training loss: 0.2436, validation loss: 0.1124
2024-05-24 23:16:01 [INFO]: Epoch 068 - training loss: 0.2414, validation loss: 0.1132
2024-05-24 23:16:02 [INFO]: Epoch 069 - training loss: 0.2404, validation loss: 0.1129
2024-05-24 23:16:02 [INFO]: Epoch 070 - training loss: 0.2387, validation loss: 0.1129
2024-05-24 23:16:03 [INFO]: Epoch 071 - training loss: 0.2380, validation loss: 0.1119
2024-05-24 23:16:03 [INFO]: Epoch 072 - training loss: 0.2368, validation loss: 0.1111
2024-05-24 23:16:04 [INFO]: Epoch 073 - training loss: 0.2348, validation loss: 0.1098
2024-05-24 23:16:05 [INFO]: Epoch 074 - training loss: 0.2339, validation loss: 0.1096
2024-05-24 23:16:05 [INFO]: Epoch 075 - training loss: 0.2330, validation loss: 0.1092
2024-05-24 23:16:06 [INFO]: Epoch 076 - training loss: 0.2322, validation loss: 0.1087
2024-05-24 23:16:06 [INFO]: Epoch 077 - training loss: 0.2332, validation loss: 0.1097
2024-05-24 23:16:07 [INFO]: Epoch 078 - training loss: 0.2311, validation loss: 0.1099
2024-05-24 23:16:08 [INFO]: Epoch 079 - training loss: 0.2293, validation loss: 0.1073
2024-05-24 23:16:08 [INFO]: Epoch 080 - training loss: 0.2280, validation loss: 0.1072
2024-05-24 23:16:09 [INFO]: Epoch 081 - training loss: 0.2276, validation loss: 0.1071
2024-05-24 23:16:09 [INFO]: Epoch 082 - training loss: 0.2282, validation loss: 0.1072
2024-05-24 23:16:10 [INFO]: Epoch 083 - training loss: 0.2277, validation loss: 0.1073
2024-05-24 23:16:11 [INFO]: Epoch 084 - training loss: 0.2250, validation loss: 0.1076
2024-05-24 23:16:11 [INFO]: Epoch 085 - training loss: 0.2240, validation loss: 0.1062
2024-05-24 23:16:12 [INFO]: Epoch 086 - training loss: 0.2230, validation loss: 0.1058
2024-05-24 23:16:12 [INFO]: Epoch 087 - training loss: 0.2228, validation loss: 0.1056
2024-05-24 23:16:13 [INFO]: Epoch 088 - training loss: 0.2229, validation loss: 0.1046
2024-05-24 23:16:14 [INFO]: Epoch 089 - training loss: 0.2207, validation loss: 0.1049
2024-05-24 23:16:14 [INFO]: Epoch 090 - training loss: 0.2190, validation loss: 0.1046
2024-05-24 23:16:15 [INFO]: Epoch 091 - training loss: 0.2193, validation loss: 0.1044
2024-05-24 23:16:15 [INFO]: Epoch 092 - training loss: 0.2179, validation loss: 0.1054
2024-05-24 23:16:16 [INFO]: Epoch 093 - training loss: 0.2167, validation loss: 0.1042
2024-05-24 23:16:17 [INFO]: Epoch 094 - training loss: 0.2172, validation loss: 0.1035
2024-05-24 23:16:17 [INFO]: Epoch 095 - training loss: 0.2166, validation loss: 0.1040
2024-05-24 23:16:18 [INFO]: Epoch 096 - training loss: 0.2145, validation loss: 0.1031
2024-05-24 23:16:18 [INFO]: Epoch 097 - training loss: 0.2152, validation loss: 0.1028
2024-05-24 23:16:19 [INFO]: Epoch 098 - training loss: 0.2139, validation loss: 0.1038
2024-05-24 23:16:20 [INFO]: Epoch 099 - training loss: 0.2126, validation loss: 0.1031
2024-05-24 23:16:20 [INFO]: Epoch 100 - training loss: 0.2132, validation loss: 0.1024
2024-05-24 23:16:21 [INFO]: Epoch 101 - training loss: 0.2141, validation loss: 0.1019
2024-05-24 23:16:21 [INFO]: Epoch 102 - training loss: 0.2126, validation loss: 0.1025
2024-05-24 23:16:22 [INFO]: Epoch 103 - training loss: 0.2107, validation loss: 0.1028
2024-05-24 23:16:23 [INFO]: Epoch 104 - training loss: 0.2095, validation loss: 0.1025
2024-05-24 23:16:23 [INFO]: Epoch 105 - training loss: 0.2091, validation loss: 0.1023
2024-05-24 23:16:24 [INFO]: Epoch 106 - training loss: 0.2083, validation loss: 0.1024
2024-05-24 23:16:24 [INFO]: Epoch 107 - training loss: 0.2085, validation loss: 0.1021
2024-05-24 23:16:25 [INFO]: Epoch 108 - training loss: 0.2085, validation loss: 0.1011
2024-05-24 23:16:26 [INFO]: Epoch 109 - training loss: 0.2075, validation loss: 0.1016
2024-05-24 23:16:26 [INFO]: Epoch 110 - training loss: 0.2067, validation loss: 0.1019
2024-05-24 23:16:27 [INFO]: Epoch 111 - training loss: 0.2053, validation loss: 0.1015
2024-05-24 23:16:27 [INFO]: Epoch 112 - training loss: 0.2050, validation loss: 0.1008
2024-05-24 23:16:28 [INFO]: Epoch 113 - training loss: 0.2036, validation loss: 0.1006
2024-05-24 23:16:29 [INFO]: Epoch 114 - training loss: 0.2035, validation loss: 0.1006
2024-05-24 23:16:29 [INFO]: Epoch 115 - training loss: 0.2036, validation loss: 0.1007
2024-05-24 23:16:30 [INFO]: Epoch 116 - training loss: 0.2026, validation loss: 0.0999
2024-05-24 23:16:30 [INFO]: Epoch 117 - training loss: 0.2025, validation loss: 0.1014
2024-05-24 23:16:31 [INFO]: Epoch 118 - training loss: 0.2014, validation loss: 0.1009
2024-05-24 23:16:32 [INFO]: Epoch 119 - training loss: 0.2014, validation loss: 0.1004
2024-05-24 23:16:32 [INFO]: Epoch 120 - training loss: 0.2007, validation loss: 0.1003
2024-05-24 23:16:33 [INFO]: Epoch 121 - training loss: 0.2001, validation loss: 0.1012
2024-05-24 23:16:33 [INFO]: Epoch 122 - training loss: 0.1996, validation loss: 0.0990
2024-05-24 23:16:34 [INFO]: Epoch 123 - training loss: 0.1989, validation loss: 0.0996
2024-05-24 23:16:35 [INFO]: Epoch 124 - training loss: 0.1986, validation loss: 0.0978
2024-05-24 23:16:35 [INFO]: Epoch 125 - training loss: 0.1980, validation loss: 0.0972
2024-05-24 23:16:36 [INFO]: Epoch 126 - training loss: 0.1969, validation loss: 0.0992
2024-05-24 23:16:36 [INFO]: Epoch 127 - training loss: 0.1968, validation loss: 0.0982
2024-05-24 23:16:37 [INFO]: Epoch 128 - training loss: 0.1964, validation loss: 0.0977
2024-05-24 23:16:38 [INFO]: Epoch 129 - training loss: 0.1960, validation loss: 0.0991
2024-05-24 23:16:38 [INFO]: Epoch 130 - training loss: 0.1955, validation loss: 0.0997
2024-05-24 23:16:39 [INFO]: Epoch 131 - training loss: 0.1965, validation loss: 0.0991
2024-05-24 23:16:39 [INFO]: Epoch 132 - training loss: 0.1961, validation loss: 0.0986
2024-05-24 23:16:40 [INFO]: Epoch 133 - training loss: 0.1937, validation loss: 0.0979
2024-05-24 23:16:41 [INFO]: Epoch 134 - training loss: 0.1933, validation loss: 0.0971
2024-05-24 23:16:41 [INFO]: Epoch 135 - training loss: 0.1923, validation loss: 0.0973
2024-05-24 23:16:42 [INFO]: Epoch 136 - training loss: 0.1914, validation loss: 0.0984
2024-05-24 23:16:42 [INFO]: Epoch 137 - training loss: 0.1920, validation loss: 0.0979
2024-05-24 23:16:43 [INFO]: Epoch 138 - training loss: 0.1912, validation loss: 0.0973
2024-05-24 23:16:44 [INFO]: Epoch 139 - training loss: 0.1913, validation loss: 0.0969
2024-05-24 23:16:44 [INFO]: Epoch 140 - training loss: 0.1910, validation loss: 0.0976
2024-05-24 23:16:45 [INFO]: Epoch 141 - training loss: 0.1902, validation loss: 0.0974
2024-05-24 23:16:45 [INFO]: Epoch 142 - training loss: 0.1910, validation loss: 0.0976
2024-05-24 23:16:46 [INFO]: Epoch 143 - training loss: 0.1904, validation loss: 0.0981
2024-05-24 23:16:47 [INFO]: Epoch 144 - training loss: 0.1888, validation loss: 0.0963
2024-05-24 23:16:47 [INFO]: Epoch 145 - training loss: 0.1883, validation loss: 0.0969
2024-05-24 23:16:48 [INFO]: Epoch 146 - training loss: 0.1885, validation loss: 0.0973
2024-05-24 23:16:48 [INFO]: Epoch 147 - training loss: 0.1889, validation loss: 0.0980
2024-05-24 23:16:49 [INFO]: Epoch 148 - training loss: 0.1897, validation loss: 0.0966
2024-05-24 23:16:50 [INFO]: Epoch 149 - training loss: 0.1876, validation loss: 0.0962
2024-05-24 23:16:50 [INFO]: Epoch 150 - training loss: 0.1865, validation loss: 0.0961
2024-05-24 23:16:51 [INFO]: Epoch 151 - training loss: 0.1859, validation loss: 0.0968
2024-05-24 23:16:51 [INFO]: Epoch 152 - training loss: 0.1853, validation loss: 0.0971
2024-05-24 23:16:52 [INFO]: Epoch 153 - training loss: 0.1857, validation loss: 0.0974
2024-05-24 23:16:53 [INFO]: Epoch 154 - training loss: 0.1854, validation loss: 0.0961
2024-05-24 23:16:53 [INFO]: Epoch 155 - training loss: 0.1835, validation loss: 0.0957
2024-05-24 23:16:54 [INFO]: Epoch 156 - training loss: 0.1827, validation loss: 0.0960
2024-05-24 23:16:54 [INFO]: Epoch 157 - training loss: 0.1846, validation loss: 0.0950
2024-05-24 23:16:55 [INFO]: Epoch 158 - training loss: 0.1843, validation loss: 0.0955
2024-05-24 23:16:56 [INFO]: Epoch 159 - training loss: 0.1836, validation loss: 0.0959
2024-05-24 23:16:56 [INFO]: Epoch 160 - training loss: 0.1817, validation loss: 0.0946
2024-05-24 23:16:57 [INFO]: Epoch 161 - training loss: 0.1821, validation loss: 0.0959
2024-05-24 23:16:57 [INFO]: Epoch 162 - training loss: 0.1824, validation loss: 0.0955
2024-05-24 23:16:58 [INFO]: Epoch 163 - training loss: 0.1827, validation loss: 0.0948
2024-05-24 23:16:59 [INFO]: Epoch 164 - training loss: 0.1816, validation loss: 0.0953
2024-05-24 23:16:59 [INFO]: Epoch 165 - training loss: 0.1813, validation loss: 0.0945
2024-05-24 23:17:00 [INFO]: Epoch 166 - training loss: 0.1811, validation loss: 0.0958
2024-05-24 23:17:00 [INFO]: Epoch 167 - training loss: 0.1811, validation loss: 0.0952
2024-05-24 23:17:01 [INFO]: Epoch 168 - training loss: 0.1817, validation loss: 0.0935
2024-05-24 23:17:02 [INFO]: Epoch 169 - training loss: 0.1805, validation loss: 0.0940
2024-05-24 23:17:02 [INFO]: Epoch 170 - training loss: 0.1783, validation loss: 0.0944
2024-05-24 23:17:03 [INFO]: Epoch 171 - training loss: 0.1777, validation loss: 0.0942
2024-05-24 23:17:03 [INFO]: Epoch 172 - training loss: 0.1773, validation loss: 0.0943
2024-05-24 23:17:04 [INFO]: Epoch 173 - training loss: 0.1784, validation loss: 0.0946
2024-05-24 23:17:05 [INFO]: Epoch 174 - training loss: 0.1773, validation loss: 0.0948
2024-05-24 23:17:05 [INFO]: Epoch 175 - training loss: 0.1766, validation loss: 0.0942
2024-05-24 23:17:06 [INFO]: Epoch 176 - training loss: 0.1763, validation loss: 0.0930
2024-05-24 23:17:06 [INFO]: Epoch 177 - training loss: 0.1759, validation loss: 0.0940
2024-05-24 23:17:07 [INFO]: Epoch 178 - training loss: 0.1760, validation loss: 0.0942
2024-05-24 23:17:08 [INFO]: Epoch 179 - training loss: 0.1769, validation loss: 0.0926
2024-05-24 23:17:08 [INFO]: Epoch 180 - training loss: 0.1749, validation loss: 0.0944
2024-05-24 23:17:09 [INFO]: Epoch 181 - training loss: 0.1754, validation loss: 0.0936
2024-05-24 23:17:09 [INFO]: Epoch 182 - training loss: 0.1750, validation loss: 0.0922
2024-05-24 23:17:10 [INFO]: Epoch 183 - training loss: 0.1740, validation loss: 0.0933
2024-05-24 23:17:11 [INFO]: Epoch 184 - training loss: 0.1745, validation loss: 0.0943
2024-05-24 23:17:11 [INFO]: Epoch 185 - training loss: 0.1764, validation loss: 0.0929
2024-05-24 23:17:12 [INFO]: Epoch 186 - training loss: 0.1757, validation loss: 0.0936
2024-05-24 23:17:12 [INFO]: Epoch 187 - training loss: 0.1747, validation loss: 0.0929
2024-05-24 23:17:13 [INFO]: Epoch 188 - training loss: 0.1725, validation loss: 0.0935
2024-05-24 23:17:14 [INFO]: Epoch 189 - training loss: 0.1721, validation loss: 0.0920
2024-05-24 23:17:14 [INFO]: Epoch 190 - training loss: 0.1714, validation loss: 0.0929
2024-05-24 23:17:15 [INFO]: Epoch 191 - training loss: 0.1719, validation loss: 0.0948
2024-05-24 23:17:15 [INFO]: Epoch 192 - training loss: 0.1716, validation loss: 0.0922
2024-05-24 23:17:16 [INFO]: Epoch 193 - training loss: 0.1714, validation loss: 0.0928
2024-05-24 23:17:17 [INFO]: Epoch 194 - training loss: 0.1714, validation loss: 0.0928
2024-05-24 23:17:17 [INFO]: Epoch 195 - training loss: 0.1695, validation loss: 0.0937
2024-05-24 23:17:18 [INFO]: Epoch 196 - training loss: 0.1693, validation loss: 0.0919
2024-05-24 23:17:18 [INFO]: Epoch 197 - training loss: 0.1708, validation loss: 0.0936
2024-05-24 23:17:19 [INFO]: Epoch 198 - training loss: 0.1699, validation loss: 0.0922
2024-05-24 23:17:20 [INFO]: Epoch 199 - training loss: 0.1701, validation loss: 0.0926
2024-05-24 23:17:20 [INFO]: Epoch 200 - training loss: 0.1710, validation loss: 0.0923
2024-05-24 23:17:21 [INFO]: Epoch 201 - training loss: 0.1689, validation loss: 0.0945
2024-05-24 23:17:21 [INFO]: Epoch 202 - training loss: 0.1680, validation loss: 0.0914
2024-05-24 23:17:22 [INFO]: Epoch 203 - training loss: 0.1673, validation loss: 0.0929
2024-05-24 23:17:23 [INFO]: Epoch 204 - training loss: 0.1676, validation loss: 0.0922
2024-05-24 23:17:23 [INFO]: Epoch 205 - training loss: 0.1682, validation loss: 0.0933
2024-05-24 23:17:24 [INFO]: Epoch 206 - training loss: 0.1671, validation loss: 0.0909
2024-05-24 23:17:24 [INFO]: Epoch 207 - training loss: 0.1673, validation loss: 0.0929
2024-05-24 23:17:25 [INFO]: Epoch 208 - training loss: 0.1669, validation loss: 0.0911
2024-05-24 23:17:26 [INFO]: Epoch 209 - training loss: 0.1660, validation loss: 0.0927
2024-05-24 23:17:26 [INFO]: Epoch 210 - training loss: 0.1671, validation loss: 0.0927
2024-05-24 23:17:27 [INFO]: Epoch 211 - training loss: 0.1671, validation loss: 0.0926
2024-05-24 23:17:27 [INFO]: Epoch 212 - training loss: 0.1650, validation loss: 0.0917
2024-05-24 23:17:28 [INFO]: Epoch 213 - training loss: 0.1647, validation loss: 0.0917
2024-05-24 23:17:29 [INFO]: Epoch 214 - training loss: 0.1643, validation loss: 0.0928
2024-05-24 23:17:29 [INFO]: Epoch 215 - training loss: 0.1645, validation loss: 0.0921
2024-05-24 23:17:30 [INFO]: Epoch 216 - training loss: 0.1647, validation loss: 0.0925
2024-05-24 23:17:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:17:30 [INFO]: Finished training. The best model is from epoch#206.
2024-05-24 23:17:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240524_T231520/SAITS.pypots
2024-05-24 23:17:30 [INFO]: SAITS on Air-Quality: MAE=0.1473, MSE=0.0986
2024-05-24 23:17:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-24 23:17:30 [INFO]: Using the given device: cuda:0
2024-05-24 23:17:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240524_T231730
2024-05-24 23:17:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240524_T231730/tensorboard
2024-05-24 23:17:30 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 23:17:30 [INFO]: Epoch 001 - training loss: 0.8840, validation loss: 0.4430
2024-05-24 23:17:31 [INFO]: Epoch 002 - training loss: 0.5521, validation loss: 0.3258
2024-05-24 23:17:31 [INFO]: Epoch 003 - training loss: 0.4632, validation loss: 0.2721
2024-05-24 23:17:31 [INFO]: Epoch 004 - training loss: 0.4165, validation loss: 0.2403
2024-05-24 23:17:31 [INFO]: Epoch 005 - training loss: 0.3861, validation loss: 0.2276
2024-05-24 23:17:32 [INFO]: Epoch 006 - training loss: 0.3617, validation loss: 0.2160
2024-05-24 23:17:32 [INFO]: Epoch 007 - training loss: 0.3458, validation loss: 0.2064
2024-05-24 23:17:32 [INFO]: Epoch 008 - training loss: 0.3329, validation loss: 0.1985
2024-05-24 23:17:32 [INFO]: Epoch 009 - training loss: 0.3245, validation loss: 0.1943
2024-05-24 23:17:33 [INFO]: Epoch 010 - training loss: 0.3170, validation loss: 0.1875
2024-05-24 23:17:33 [INFO]: Epoch 011 - training loss: 0.3077, validation loss: 0.1842
2024-05-24 23:17:33 [INFO]: Epoch 012 - training loss: 0.3005, validation loss: 0.1777
2024-05-24 23:17:33 [INFO]: Epoch 013 - training loss: 0.2956, validation loss: 0.1766
2024-05-24 23:17:34 [INFO]: Epoch 014 - training loss: 0.2896, validation loss: 0.1733
2024-05-24 23:17:34 [INFO]: Epoch 015 - training loss: 0.2854, validation loss: 0.1692
2024-05-24 23:17:34 [INFO]: Epoch 016 - training loss: 0.2817, validation loss: 0.1678
2024-05-24 23:17:34 [INFO]: Epoch 017 - training loss: 0.2767, validation loss: 0.1652
2024-05-24 23:17:35 [INFO]: Epoch 018 - training loss: 0.2723, validation loss: 0.1630
2024-05-24 23:17:35 [INFO]: Epoch 019 - training loss: 0.2697, validation loss: 0.1598
2024-05-24 23:17:35 [INFO]: Epoch 020 - training loss: 0.2676, validation loss: 0.1588
2024-05-24 23:17:35 [INFO]: Epoch 021 - training loss: 0.2649, validation loss: 0.1560
2024-05-24 23:17:36 [INFO]: Epoch 022 - training loss: 0.2647, validation loss: 0.1545
2024-05-24 23:17:36 [INFO]: Epoch 023 - training loss: 0.2583, validation loss: 0.1525
2024-05-24 23:17:36 [INFO]: Epoch 024 - training loss: 0.2536, validation loss: 0.1502
2024-05-24 23:17:36 [INFO]: Epoch 025 - training loss: 0.2498, validation loss: 0.1499
2024-05-24 23:17:37 [INFO]: Epoch 026 - training loss: 0.2487, validation loss: 0.1484
2024-05-24 23:17:37 [INFO]: Epoch 027 - training loss: 0.2469, validation loss: 0.1485
2024-05-24 23:17:37 [INFO]: Epoch 028 - training loss: 0.2437, validation loss: 0.1473
2024-05-24 23:17:37 [INFO]: Epoch 029 - training loss: 0.2406, validation loss: 0.1479
2024-05-24 23:17:38 [INFO]: Epoch 030 - training loss: 0.2398, validation loss: 0.1460
2024-05-24 23:17:38 [INFO]: Epoch 031 - training loss: 0.2384, validation loss: 0.1470
2024-05-24 23:17:38 [INFO]: Epoch 032 - training loss: 0.2409, validation loss: 0.1436
2024-05-24 23:17:38 [INFO]: Epoch 033 - training loss: 0.2354, validation loss: 0.1419
2024-05-24 23:17:39 [INFO]: Epoch 034 - training loss: 0.2324, validation loss: 0.1431
2024-05-24 23:17:39 [INFO]: Epoch 035 - training loss: 0.2302, validation loss: 0.1415
2024-05-24 23:17:39 [INFO]: Epoch 036 - training loss: 0.2282, validation loss: 0.1406
2024-05-24 23:17:39 [INFO]: Epoch 037 - training loss: 0.2274, validation loss: 0.1402
2024-05-24 23:17:40 [INFO]: Epoch 038 - training loss: 0.2236, validation loss: 0.1388
2024-05-24 23:17:40 [INFO]: Epoch 039 - training loss: 0.2228, validation loss: 0.1382
2024-05-24 23:17:40 [INFO]: Epoch 040 - training loss: 0.2221, validation loss: 0.1367
2024-05-24 23:17:40 [INFO]: Epoch 041 - training loss: 0.2196, validation loss: 0.1371
2024-05-24 23:17:41 [INFO]: Epoch 042 - training loss: 0.2198, validation loss: 0.1362
2024-05-24 23:17:41 [INFO]: Epoch 043 - training loss: 0.2186, validation loss: 0.1352
2024-05-24 23:17:41 [INFO]: Epoch 044 - training loss: 0.2155, validation loss: 0.1353
2024-05-24 23:17:41 [INFO]: Epoch 045 - training loss: 0.2141, validation loss: 0.1344
2024-05-24 23:17:42 [INFO]: Epoch 046 - training loss: 0.2130, validation loss: 0.1361
2024-05-24 23:17:42 [INFO]: Epoch 047 - training loss: 0.2114, validation loss: 0.1345
2024-05-24 23:17:42 [INFO]: Epoch 048 - training loss: 0.2110, validation loss: 0.1327
2024-05-24 23:17:42 [INFO]: Epoch 049 - training loss: 0.2093, validation loss: 0.1330
2024-05-24 23:17:43 [INFO]: Epoch 050 - training loss: 0.2073, validation loss: 0.1315
2024-05-24 23:17:43 [INFO]: Epoch 051 - training loss: 0.2066, validation loss: 0.1324
2024-05-24 23:17:43 [INFO]: Epoch 052 - training loss: 0.2068, validation loss: 0.1307
2024-05-24 23:17:43 [INFO]: Epoch 053 - training loss: 0.2051, validation loss: 0.1316
2024-05-24 23:17:44 [INFO]: Epoch 054 - training loss: 0.2036, validation loss: 0.1298
2024-05-24 23:17:44 [INFO]: Epoch 055 - training loss: 0.2037, validation loss: 0.1306
2024-05-24 23:17:44 [INFO]: Epoch 056 - training loss: 0.2024, validation loss: 0.1292
2024-05-24 23:17:44 [INFO]: Epoch 057 - training loss: 0.2030, validation loss: 0.1317
2024-05-24 23:17:45 [INFO]: Epoch 058 - training loss: 0.2019, validation loss: 0.1288
2024-05-24 23:17:45 [INFO]: Epoch 059 - training loss: 0.1977, validation loss: 0.1296
2024-05-24 23:17:45 [INFO]: Epoch 060 - training loss: 0.1970, validation loss: 0.1276
2024-05-24 23:17:45 [INFO]: Epoch 061 - training loss: 0.1953, validation loss: 0.1262
2024-05-24 23:17:46 [INFO]: Epoch 062 - training loss: 0.1940, validation loss: 0.1265
2024-05-24 23:17:46 [INFO]: Epoch 063 - training loss: 0.1940, validation loss: 0.1270
2024-05-24 23:17:46 [INFO]: Epoch 064 - training loss: 0.1929, validation loss: 0.1276
2024-05-24 23:17:46 [INFO]: Epoch 065 - training loss: 0.1948, validation loss: 0.1275
2024-05-24 23:17:47 [INFO]: Epoch 066 - training loss: 0.1951, validation loss: 0.1255
2024-05-24 23:17:47 [INFO]: Epoch 067 - training loss: 0.1910, validation loss: 0.1263
2024-05-24 23:17:47 [INFO]: Epoch 068 - training loss: 0.1906, validation loss: 0.1264
2024-05-24 23:17:47 [INFO]: Epoch 069 - training loss: 0.1876, validation loss: 0.1233
2024-05-24 23:17:48 [INFO]: Epoch 070 - training loss: 0.1866, validation loss: 0.1239
2024-05-24 23:17:48 [INFO]: Epoch 071 - training loss: 0.1851, validation loss: 0.1236
2024-05-24 23:17:48 [INFO]: Epoch 072 - training loss: 0.1873, validation loss: 0.1249
2024-05-24 23:17:48 [INFO]: Epoch 073 - training loss: 0.1854, validation loss: 0.1232
2024-05-24 23:17:49 [INFO]: Epoch 074 - training loss: 0.1847, validation loss: 0.1234
2024-05-24 23:17:49 [INFO]: Epoch 075 - training loss: 0.1819, validation loss: 0.1238
2024-05-24 23:17:49 [INFO]: Epoch 076 - training loss: 0.1804, validation loss: 0.1225
2024-05-24 23:17:49 [INFO]: Epoch 077 - training loss: 0.1819, validation loss: 0.1215
2024-05-24 23:17:50 [INFO]: Epoch 078 - training loss: 0.1816, validation loss: 0.1230
2024-05-24 23:17:50 [INFO]: Epoch 079 - training loss: 0.1805, validation loss: 0.1224
2024-05-24 23:17:50 [INFO]: Epoch 080 - training loss: 0.1766, validation loss: 0.1214
2024-05-24 23:17:50 [INFO]: Epoch 081 - training loss: 0.1787, validation loss: 0.1208
2024-05-24 23:17:51 [INFO]: Epoch 082 - training loss: 0.1771, validation loss: 0.1211
2024-05-24 23:17:51 [INFO]: Epoch 083 - training loss: 0.1769, validation loss: 0.1196
2024-05-24 23:17:51 [INFO]: Epoch 084 - training loss: 0.1785, validation loss: 0.1205
2024-05-24 23:17:51 [INFO]: Epoch 085 - training loss: 0.1747, validation loss: 0.1191
2024-05-24 23:17:52 [INFO]: Epoch 086 - training loss: 0.1735, validation loss: 0.1207
2024-05-24 23:17:52 [INFO]: Epoch 087 - training loss: 0.1716, validation loss: 0.1192
2024-05-24 23:17:52 [INFO]: Epoch 088 - training loss: 0.1703, validation loss: 0.1199
2024-05-24 23:17:52 [INFO]: Epoch 089 - training loss: 0.1701, validation loss: 0.1191
2024-05-24 23:17:53 [INFO]: Epoch 090 - training loss: 0.1711, validation loss: 0.1184
2024-05-24 23:17:53 [INFO]: Epoch 091 - training loss: 0.1715, validation loss: 0.1182
2024-05-24 23:17:53 [INFO]: Epoch 092 - training loss: 0.1693, validation loss: 0.1194
2024-05-24 23:17:53 [INFO]: Epoch 093 - training loss: 0.1709, validation loss: 0.1185
2024-05-24 23:17:54 [INFO]: Epoch 094 - training loss: 0.1684, validation loss: 0.1188
2024-05-24 23:17:54 [INFO]: Epoch 095 - training loss: 0.1677, validation loss: 0.1166
2024-05-24 23:17:54 [INFO]: Epoch 096 - training loss: 0.1699, validation loss: 0.1179
2024-05-24 23:17:54 [INFO]: Epoch 097 - training loss: 0.1663, validation loss: 0.1186
2024-05-24 23:17:55 [INFO]: Epoch 098 - training loss: 0.1650, validation loss: 0.1189
2024-05-24 23:17:55 [INFO]: Epoch 099 - training loss: 0.1634, validation loss: 0.1176
2024-05-24 23:17:55 [INFO]: Epoch 100 - training loss: 0.1646, validation loss: 0.1177
2024-05-24 23:17:56 [INFO]: Epoch 101 - training loss: 0.1637, validation loss: 0.1185
2024-05-24 23:17:56 [INFO]: Epoch 102 - training loss: 0.1634, validation loss: 0.1202
2024-05-24 23:17:56 [INFO]: Epoch 103 - training loss: 0.1623, validation loss: 0.1162
2024-05-24 23:17:56 [INFO]: Epoch 104 - training loss: 0.1605, validation loss: 0.1170
2024-05-24 23:17:57 [INFO]: Epoch 105 - training loss: 0.1624, validation loss: 0.1171
2024-05-24 23:17:57 [INFO]: Epoch 106 - training loss: 0.1606, validation loss: 0.1165
2024-05-24 23:17:57 [INFO]: Epoch 107 - training loss: 0.1612, validation loss: 0.1170
2024-05-24 23:17:57 [INFO]: Epoch 108 - training loss: 0.1610, validation loss: 0.1158
2024-05-24 23:17:58 [INFO]: Epoch 109 - training loss: 0.1598, validation loss: 0.1170
2024-05-24 23:17:58 [INFO]: Epoch 110 - training loss: 0.1573, validation loss: 0.1172
2024-05-24 23:17:58 [INFO]: Epoch 111 - training loss: 0.1556, validation loss: 0.1153
2024-05-24 23:17:58 [INFO]: Epoch 112 - training loss: 0.1576, validation loss: 0.1157
2024-05-24 23:17:59 [INFO]: Epoch 113 - training loss: 0.1564, validation loss: 0.1137
2024-05-24 23:17:59 [INFO]: Epoch 114 - training loss: 0.1576, validation loss: 0.1158
2024-05-24 23:17:59 [INFO]: Epoch 115 - training loss: 0.1572, validation loss: 0.1190
2024-05-24 23:17:59 [INFO]: Epoch 116 - training loss: 0.1557, validation loss: 0.1166
2024-05-24 23:18:00 [INFO]: Epoch 117 - training loss: 0.1568, validation loss: 0.1161
2024-05-24 23:18:00 [INFO]: Epoch 118 - training loss: 0.1563, validation loss: 0.1163
2024-05-24 23:18:00 [INFO]: Epoch 119 - training loss: 0.1582, validation loss: 0.1167
2024-05-24 23:18:00 [INFO]: Epoch 120 - training loss: 0.1536, validation loss: 0.1151
2024-05-24 23:18:01 [INFO]: Epoch 121 - training loss: 0.1556, validation loss: 0.1146
2024-05-24 23:18:01 [INFO]: Epoch 122 - training loss: 0.1560, validation loss: 0.1142
2024-05-24 23:18:01 [INFO]: Epoch 123 - training loss: 0.1533, validation loss: 0.1153
2024-05-24 23:18:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:18:01 [INFO]: Finished training. The best model is from epoch#113.
2024-05-24 23:18:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240524_T231730/Transformer.pypots
2024-05-24 23:18:01 [INFO]: Transformer on Air-Quality: MAE=0.1655, MSE=0.1182
2024-05-24 23:18:01 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-24 23:18:01 [INFO]: Using the given device: cuda:0
2024-05-24 23:18:01 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240524_T231801
2024-05-24 23:18:01 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240524_T231801/tensorboard
2024-05-24 23:18:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 23:18:02 [INFO]: Epoch 001 - training loss: 0.3254, validation loss: 0.2702
2024-05-24 23:18:02 [INFO]: Epoch 002 - training loss: 0.2565, validation loss: 0.2305
2024-05-24 23:18:03 [INFO]: Epoch 003 - training loss: 0.1919, validation loss: 0.2163
2024-05-24 23:18:03 [INFO]: Epoch 004 - training loss: 0.1606, validation loss: 0.2016
2024-05-24 23:18:04 [INFO]: Epoch 005 - training loss: 0.1465, validation loss: 0.2019
2024-05-24 23:18:04 [INFO]: Epoch 006 - training loss: 0.1404, validation loss: 0.1887
2024-05-24 23:18:05 [INFO]: Epoch 007 - training loss: 0.1353, validation loss: 0.2027
2024-05-24 23:18:05 [INFO]: Epoch 008 - training loss: 0.1332, validation loss: 0.1843
2024-05-24 23:18:06 [INFO]: Epoch 009 - training loss: 0.1246, validation loss: 0.1847
2024-05-24 23:18:06 [INFO]: Epoch 010 - training loss: 0.1260, validation loss: 0.1839
2024-05-24 23:18:07 [INFO]: Epoch 011 - training loss: 0.1071, validation loss: 0.1868
2024-05-24 23:18:07 [INFO]: Epoch 012 - training loss: 0.1054, validation loss: 0.1750
2024-05-24 23:18:07 [INFO]: Epoch 013 - training loss: 0.1049, validation loss: 0.1813
2024-05-24 23:18:08 [INFO]: Epoch 014 - training loss: 0.0926, validation loss: 0.1744
2024-05-24 23:18:08 [INFO]: Epoch 015 - training loss: 0.0867, validation loss: 0.1802
2024-05-24 23:18:09 [INFO]: Epoch 016 - training loss: 0.0839, validation loss: 0.1771
2024-05-24 23:18:09 [INFO]: Epoch 017 - training loss: 0.0884, validation loss: 0.1795
2024-05-24 23:18:10 [INFO]: Epoch 018 - training loss: 0.0853, validation loss: 0.1714
2024-05-24 23:18:10 [INFO]: Epoch 019 - training loss: 0.0788, validation loss: 0.1777
2024-05-24 23:18:11 [INFO]: Epoch 020 - training loss: 0.0801, validation loss: 0.1703
2024-05-24 23:18:11 [INFO]: Epoch 021 - training loss: 0.0813, validation loss: 0.1717
2024-05-24 23:18:12 [INFO]: Epoch 022 - training loss: 0.0788, validation loss: 0.1663
2024-05-24 23:18:12 [INFO]: Epoch 023 - training loss: 0.0721, validation loss: 0.1779
2024-05-24 23:18:12 [INFO]: Epoch 024 - training loss: 0.0669, validation loss: 0.1679
2024-05-24 23:18:13 [INFO]: Epoch 025 - training loss: 0.0636, validation loss: 0.1649
2024-05-24 23:18:13 [INFO]: Epoch 026 - training loss: 0.0625, validation loss: 0.1662
2024-05-24 23:18:14 [INFO]: Epoch 027 - training loss: 0.0623, validation loss: 0.1620
2024-05-24 23:18:14 [INFO]: Epoch 028 - training loss: 0.0606, validation loss: 0.1665
2024-05-24 23:18:15 [INFO]: Epoch 029 - training loss: 0.0582, validation loss: 0.1551
2024-05-24 23:18:15 [INFO]: Epoch 030 - training loss: 0.0611, validation loss: 0.1631
2024-05-24 23:18:16 [INFO]: Epoch 031 - training loss: 0.0627, validation loss: 0.1538
2024-05-24 23:18:16 [INFO]: Epoch 032 - training loss: 0.0608, validation loss: 0.1635
2024-05-24 23:18:17 [INFO]: Epoch 033 - training loss: 0.0581, validation loss: 0.1499
2024-05-24 23:18:17 [INFO]: Epoch 034 - training loss: 0.0571, validation loss: 0.1622
2024-05-24 23:18:18 [INFO]: Epoch 035 - training loss: 0.0564, validation loss: 0.1528
2024-05-24 23:18:18 [INFO]: Epoch 036 - training loss: 0.0513, validation loss: 0.1527
2024-05-24 23:18:18 [INFO]: Epoch 037 - training loss: 0.0510, validation loss: 0.1499
2024-05-24 23:18:19 [INFO]: Epoch 038 - training loss: 0.0502, validation loss: 0.1525
2024-05-24 23:18:19 [INFO]: Epoch 039 - training loss: 0.0492, validation loss: 0.1453
2024-05-24 23:18:20 [INFO]: Epoch 040 - training loss: 0.0473, validation loss: 0.1492
2024-05-24 23:18:20 [INFO]: Epoch 041 - training loss: 0.0453, validation loss: 0.1501
2024-05-24 23:18:21 [INFO]: Epoch 042 - training loss: 0.0462, validation loss: 0.1491
2024-05-24 23:18:21 [INFO]: Epoch 043 - training loss: 0.0468, validation loss: 0.1462
2024-05-24 23:18:22 [INFO]: Epoch 044 - training loss: 0.0472, validation loss: 0.1528
2024-05-24 23:18:22 [INFO]: Epoch 045 - training loss: 0.0466, validation loss: 0.1389
2024-05-24 23:18:23 [INFO]: Epoch 046 - training loss: 0.0421, validation loss: 0.1418
2024-05-24 23:18:23 [INFO]: Epoch 047 - training loss: 0.0430, validation loss: 0.1450
2024-05-24 23:18:23 [INFO]: Epoch 048 - training loss: 0.0419, validation loss: 0.1424
2024-05-24 23:18:24 [INFO]: Epoch 049 - training loss: 0.0448, validation loss: 0.1425
2024-05-24 23:18:24 [INFO]: Epoch 050 - training loss: 0.0432, validation loss: 0.1435
2024-05-24 23:18:25 [INFO]: Epoch 051 - training loss: 0.0435, validation loss: 0.1399
2024-05-24 23:18:25 [INFO]: Epoch 052 - training loss: 0.0435, validation loss: 0.1428
2024-05-24 23:18:26 [INFO]: Epoch 053 - training loss: 0.0406, validation loss: 0.1404
2024-05-24 23:18:26 [INFO]: Epoch 054 - training loss: 0.0421, validation loss: 0.1399
2024-05-24 23:18:27 [INFO]: Epoch 055 - training loss: 0.0414, validation loss: 0.1374
2024-05-24 23:18:27 [INFO]: Epoch 056 - training loss: 0.0404, validation loss: 0.1413
2024-05-24 23:18:28 [INFO]: Epoch 057 - training loss: 0.0394, validation loss: 0.1392
2024-05-24 23:18:28 [INFO]: Epoch 058 - training loss: 0.0418, validation loss: 0.1415
2024-05-24 23:18:28 [INFO]: Epoch 059 - training loss: 0.0400, validation loss: 0.1357
2024-05-24 23:18:29 [INFO]: Epoch 060 - training loss: 0.0393, validation loss: 0.1380
2024-05-24 23:18:29 [INFO]: Epoch 061 - training loss: 0.0366, validation loss: 0.1328
2024-05-24 23:18:30 [INFO]: Epoch 062 - training loss: 0.0364, validation loss: 0.1374
2024-05-24 23:18:30 [INFO]: Epoch 063 - training loss: 0.0376, validation loss: 0.1368
2024-05-24 23:18:31 [INFO]: Epoch 064 - training loss: 0.0369, validation loss: 0.1398
2024-05-24 23:18:31 [INFO]: Epoch 065 - training loss: 0.0411, validation loss: 0.1383
2024-05-24 23:18:32 [INFO]: Epoch 066 - training loss: 0.0372, validation loss: 0.1401
2024-05-24 23:18:32 [INFO]: Epoch 067 - training loss: 0.0348, validation loss: 0.1346
2024-05-24 23:18:33 [INFO]: Epoch 068 - training loss: 0.0351, validation loss: 0.1329
2024-05-24 23:18:33 [INFO]: Epoch 069 - training loss: 0.0342, validation loss: 0.1448
2024-05-24 23:18:33 [INFO]: Epoch 070 - training loss: 0.0339, validation loss: 0.1353
2024-05-24 23:18:34 [INFO]: Epoch 071 - training loss: 0.0341, validation loss: 0.1330
2024-05-24 23:18:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:18:34 [INFO]: Finished training. The best model is from epoch#61.
2024-05-24 23:18:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240524_T231801/TimesNet.pypots
2024-05-24 23:18:34 [INFO]: TimesNet on Air-Quality: MAE=0.1635, MSE=0.1437
2024-05-24 23:18:34 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-24 23:18:34 [INFO]: Using the given device: cuda:0
2024-05-24 23:18:34 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834
2024-05-24 23:18:34 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/tensorboard
2024-05-24 23:18:34 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-24 23:18:51 [INFO]: Epoch 001 - training loss: 0.4852, validation loss: 0.3324
2024-05-24 23:18:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch1_loss0.3323536038398743.pypots
2024-05-24 23:19:07 [INFO]: Epoch 002 - training loss: 0.2830, validation loss: 0.2721
2024-05-24 23:19:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch2_loss0.27209832668304446.pypots
2024-05-24 23:19:24 [INFO]: Epoch 003 - training loss: 0.2657, validation loss: 0.2440
2024-05-24 23:19:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch3_loss0.24402629137039183.pypots
2024-05-24 23:19:41 [INFO]: Epoch 004 - training loss: 0.2454, validation loss: 0.2098
2024-05-24 23:19:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch4_loss0.20978208631277084.pypots
2024-05-24 23:19:57 [INFO]: Epoch 005 - training loss: 0.1860, validation loss: 0.1861
2024-05-24 23:19:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch5_loss0.18614569902420045.pypots
2024-05-24 23:20:14 [INFO]: Epoch 006 - training loss: 0.1969, validation loss: 0.1851
2024-05-24 23:20:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch6_loss0.1851210594177246.pypots
2024-05-24 23:20:31 [INFO]: Epoch 007 - training loss: 0.1782, validation loss: 0.1666
2024-05-24 23:20:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch7_loss0.16659972071647644.pypots
2024-05-24 23:20:47 [INFO]: Epoch 008 - training loss: 0.1664, validation loss: 0.1615
2024-05-24 23:20:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch8_loss0.16152426302433015.pypots
2024-05-24 23:21:04 [INFO]: Epoch 009 - training loss: 0.1639, validation loss: 0.1640
2024-05-24 23:21:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch9_loss0.1640472173690796.pypots
2024-05-24 23:21:21 [INFO]: Epoch 010 - training loss: 0.1608, validation loss: 0.1556
2024-05-24 23:21:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch10_loss0.15564662963151932.pypots
2024-05-24 23:21:37 [INFO]: Epoch 011 - training loss: 0.1553, validation loss: 0.1529
2024-05-24 23:21:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch11_loss0.15289946794509887.pypots
2024-05-24 23:21:54 [INFO]: Epoch 012 - training loss: 0.1568, validation loss: 0.1515
2024-05-24 23:21:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch12_loss0.15152328908443452.pypots
2024-05-24 23:22:11 [INFO]: Epoch 013 - training loss: 0.1642, validation loss: 0.1475
2024-05-24 23:22:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch13_loss0.14752781838178636.pypots
2024-05-24 23:22:27 [INFO]: Epoch 014 - training loss: 0.1528, validation loss: 0.1463
2024-05-24 23:22:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch14_loss0.14629045873880386.pypots
2024-05-24 23:22:44 [INFO]: Epoch 015 - training loss: 0.1616, validation loss: 0.1424
2024-05-24 23:22:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch15_loss0.1424375019967556.pypots
2024-05-24 23:23:00 [INFO]: Epoch 016 - training loss: 0.1556, validation loss: 0.1428
2024-05-24 23:23:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch16_loss0.14279165416955947.pypots
2024-05-24 23:23:17 [INFO]: Epoch 017 - training loss: 0.1548, validation loss: 0.1387
2024-05-24 23:23:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch17_loss0.13869540840387345.pypots
2024-05-24 23:23:34 [INFO]: Epoch 018 - training loss: 0.1546, validation loss: 0.1432
2024-05-24 23:23:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch18_loss0.1431661270558834.pypots
2024-05-24 23:23:50 [INFO]: Epoch 019 - training loss: 0.1431, validation loss: 0.1433
2024-05-24 23:23:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch19_loss0.1432892896234989.pypots
2024-05-24 23:24:07 [INFO]: Epoch 020 - training loss: 0.1465, validation loss: 0.1418
2024-05-24 23:24:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch20_loss0.14182563349604607.pypots
2024-05-24 23:24:24 [INFO]: Epoch 021 - training loss: 0.1369, validation loss: 0.1377
2024-05-24 23:24:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch21_loss0.13767269402742385.pypots
2024-05-24 23:24:40 [INFO]: Epoch 022 - training loss: 0.1369, validation loss: 0.1379
2024-05-24 23:24:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch22_loss0.13787918537855148.pypots
2024-05-24 23:24:57 [INFO]: Epoch 023 - training loss: 0.1403, validation loss: 0.1361
2024-05-24 23:24:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch23_loss0.13613400608301163.pypots
2024-05-24 23:25:14 [INFO]: Epoch 024 - training loss: 0.1494, validation loss: 0.1367
2024-05-24 23:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch24_loss0.13666596338152887.pypots
2024-05-24 23:25:30 [INFO]: Epoch 025 - training loss: 0.1374, validation loss: 0.1347
2024-05-24 23:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch25_loss0.13473776429891587.pypots
2024-05-24 23:25:47 [INFO]: Epoch 026 - training loss: 0.1303, validation loss: 0.1325
2024-05-24 23:25:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch26_loss0.13246045261621475.pypots
2024-05-24 23:26:03 [INFO]: Epoch 027 - training loss: 0.1372, validation loss: 0.1309
2024-05-24 23:26:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch27_loss0.13092312589287758.pypots
2024-05-24 23:26:20 [INFO]: Epoch 028 - training loss: 0.1434, validation loss: 0.1308
2024-05-24 23:26:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch28_loss0.13083242774009704.pypots
2024-05-24 23:26:37 [INFO]: Epoch 029 - training loss: 0.1349, validation loss: 0.1314
2024-05-24 23:26:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch29_loss0.1313713952898979.pypots
2024-05-24 23:26:53 [INFO]: Epoch 030 - training loss: 0.1305, validation loss: 0.1334
2024-05-24 23:26:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch30_loss0.13335871398448945.pypots
2024-05-24 23:27:10 [INFO]: Epoch 031 - training loss: 0.1271, validation loss: 0.1324
2024-05-24 23:27:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch31_loss0.1324368715286255.pypots
2024-05-24 23:27:27 [INFO]: Epoch 032 - training loss: 0.1261, validation loss: 0.1286
2024-05-24 23:27:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch32_loss0.12861570566892624.pypots
2024-05-24 23:27:43 [INFO]: Epoch 033 - training loss: 0.1121, validation loss: 0.1308
2024-05-24 23:27:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch33_loss0.13080334663391113.pypots
2024-05-24 23:28:00 [INFO]: Epoch 034 - training loss: 0.1294, validation loss: 0.1296
2024-05-24 23:28:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch34_loss0.12957288920879365.pypots
2024-05-24 23:28:17 [INFO]: Epoch 035 - training loss: 0.1284, validation loss: 0.1260
2024-05-24 23:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch35_loss0.12598388493061066.pypots
2024-05-24 23:28:33 [INFO]: Epoch 036 - training loss: 0.1341, validation loss: 0.1285
2024-05-24 23:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch36_loss0.12853777781128883.pypots
2024-05-24 23:28:50 [INFO]: Epoch 037 - training loss: 0.1170, validation loss: 0.1266
2024-05-24 23:28:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch37_loss0.12655928283929824.pypots
2024-05-24 23:29:07 [INFO]: Epoch 038 - training loss: 0.1322, validation loss: 0.1252
2024-05-24 23:29:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch38_loss0.12520064413547516.pypots
2024-05-24 23:29:23 [INFO]: Epoch 039 - training loss: 0.1316, validation loss: 0.1295
2024-05-24 23:29:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch39_loss0.1295095205307007.pypots
2024-05-24 23:29:40 [INFO]: Epoch 040 - training loss: 0.1225, validation loss: 0.1266
2024-05-24 23:29:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch40_loss0.12663934454321862.pypots
2024-05-24 23:29:56 [INFO]: Epoch 041 - training loss: 0.1167, validation loss: 0.1289
2024-05-24 23:29:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch41_loss0.12894806936383246.pypots
2024-05-24 23:30:13 [INFO]: Epoch 042 - training loss: 0.1308, validation loss: 0.1289
2024-05-24 23:30:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch42_loss0.12890084236860275.pypots
2024-05-24 23:30:30 [INFO]: Epoch 043 - training loss: 0.1278, validation loss: 0.1258
2024-05-24 23:30:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch43_loss0.12580715417861937.pypots
2024-05-24 23:30:46 [INFO]: Epoch 044 - training loss: 0.1314, validation loss: 0.1240
2024-05-24 23:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch44_loss0.12401747480034828.pypots
2024-05-24 23:31:03 [INFO]: Epoch 045 - training loss: 0.1219, validation loss: 0.1251
2024-05-24 23:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch45_loss0.12513965144753456.pypots
2024-05-24 23:31:20 [INFO]: Epoch 046 - training loss: 0.1357, validation loss: 0.1298
2024-05-24 23:31:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch46_loss0.12976631596684457.pypots
2024-05-24 23:31:36 [INFO]: Epoch 047 - training loss: 0.1227, validation loss: 0.1245
2024-05-24 23:31:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch47_loss0.12448500543832779.pypots
2024-05-24 23:31:53 [INFO]: Epoch 048 - training loss: 0.1135, validation loss: 0.1234
2024-05-24 23:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch48_loss0.12338086813688279.pypots
2024-05-24 23:32:10 [INFO]: Epoch 049 - training loss: 0.1283, validation loss: 0.1226
2024-05-24 23:32:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch49_loss0.12264809012413025.pypots
2024-05-24 23:32:26 [INFO]: Epoch 050 - training loss: 0.1210, validation loss: 0.1202
2024-05-24 23:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch50_loss0.12016808614134789.pypots
2024-05-24 23:32:43 [INFO]: Epoch 051 - training loss: 0.1102, validation loss: 0.1222
2024-05-24 23:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch51_loss0.12216789647936821.pypots
2024-05-24 23:32:59 [INFO]: Epoch 052 - training loss: 0.1313, validation loss: 0.1235
2024-05-24 23:33:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch52_loss0.12350521311163902.pypots
2024-05-24 23:33:16 [INFO]: Epoch 053 - training loss: 0.1223, validation loss: 0.1202
2024-05-24 23:33:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch53_loss0.12022087946534157.pypots
2024-05-24 23:33:33 [INFO]: Epoch 054 - training loss: 0.1376, validation loss: 0.1258
2024-05-24 23:33:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch54_loss0.1258277975022793.pypots
2024-05-24 23:33:49 [INFO]: Epoch 055 - training loss: 0.1207, validation loss: 0.1187
2024-05-24 23:33:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch55_loss0.11871069967746735.pypots
2024-05-24 23:34:06 [INFO]: Epoch 056 - training loss: 0.1155, validation loss: 0.1213
2024-05-24 23:34:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch56_loss0.12134017422795296.pypots
2024-05-24 23:34:23 [INFO]: Epoch 057 - training loss: 0.1092, validation loss: 0.1191
2024-05-24 23:34:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch57_loss0.11906049102544784.pypots
2024-05-24 23:34:39 [INFO]: Epoch 058 - training loss: 0.1240, validation loss: 0.1200
2024-05-24 23:34:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch58_loss0.12001524195075035.pypots
2024-05-24 23:34:56 [INFO]: Epoch 059 - training loss: 0.1040, validation loss: 0.1211
2024-05-24 23:34:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch59_loss0.12113521471619607.pypots
2024-05-24 23:35:13 [INFO]: Epoch 060 - training loss: 0.1123, validation loss: 0.1221
2024-05-24 23:35:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch60_loss0.12207906693220139.pypots
2024-05-24 23:35:29 [INFO]: Epoch 061 - training loss: 0.1201, validation loss: 0.1191
2024-05-24 23:35:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch61_loss0.11908387541770935.pypots
2024-05-24 23:35:46 [INFO]: Epoch 062 - training loss: 0.1191, validation loss: 0.1196
2024-05-24 23:35:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch62_loss0.11956812888383865.pypots
2024-05-24 23:36:03 [INFO]: Epoch 063 - training loss: 0.1188, validation loss: 0.1182
2024-05-24 23:36:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch63_loss0.11821329221129417.pypots
2024-05-24 23:36:19 [INFO]: Epoch 064 - training loss: 0.1235, validation loss: 0.1175
2024-05-24 23:36:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch64_loss0.11747998967766762.pypots
2024-05-24 23:36:36 [INFO]: Epoch 065 - training loss: 0.1177, validation loss: 0.1203
2024-05-24 23:36:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch65_loss0.12034515514969826.pypots
2024-05-24 23:36:52 [INFO]: Epoch 066 - training loss: 0.1212, validation loss: 0.1218
2024-05-24 23:36:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch66_loss0.12182858288288116.pypots
2024-05-24 23:37:09 [INFO]: Epoch 067 - training loss: 0.1115, validation loss: 0.1180
2024-05-24 23:37:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch67_loss0.11801786124706268.pypots
2024-05-24 23:37:26 [INFO]: Epoch 068 - training loss: 0.1032, validation loss: 0.1163
2024-05-24 23:37:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch68_loss0.11634964570403099.pypots
2024-05-24 23:37:42 [INFO]: Epoch 069 - training loss: 0.1238, validation loss: 0.1160
2024-05-24 23:37:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch69_loss0.11602162942290306.pypots
2024-05-24 23:37:59 [INFO]: Epoch 070 - training loss: 0.1042, validation loss: 0.1200
2024-05-24 23:37:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch70_loss0.12004409357905388.pypots
2024-05-24 23:38:16 [INFO]: Epoch 071 - training loss: 0.1257, validation loss: 0.1173
2024-05-24 23:38:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch71_loss0.11728081554174423.pypots
2024-05-24 23:38:32 [INFO]: Epoch 072 - training loss: 0.1105, validation loss: 0.1158
2024-05-24 23:38:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch72_loss0.11578278541564942.pypots
2024-05-24 23:38:49 [INFO]: Epoch 073 - training loss: 0.1158, validation loss: 0.1179
2024-05-24 23:38:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch73_loss0.11794823482632637.pypots
2024-05-24 23:39:06 [INFO]: Epoch 074 - training loss: 0.1179, validation loss: 0.1179
2024-05-24 23:39:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch74_loss0.11786122322082519.pypots
2024-05-24 23:39:22 [INFO]: Epoch 075 - training loss: 0.1022, validation loss: 0.1150
2024-05-24 23:39:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch75_loss0.11498928219079971.pypots
2024-05-24 23:39:39 [INFO]: Epoch 076 - training loss: 0.1078, validation loss: 0.1180
2024-05-24 23:39:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch76_loss0.11799872368574142.pypots
2024-05-24 23:39:55 [INFO]: Epoch 077 - training loss: 0.1264, validation loss: 0.1140
2024-05-24 23:39:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch77_loss0.11403633877635003.pypots
2024-05-24 23:40:12 [INFO]: Epoch 078 - training loss: 0.1267, validation loss: 0.1164
2024-05-24 23:40:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch78_loss0.1163725033402443.pypots
2024-05-24 23:40:29 [INFO]: Epoch 079 - training loss: 0.1105, validation loss: 0.1143
2024-05-24 23:40:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch79_loss0.11429497823119164.pypots
2024-05-24 23:40:45 [INFO]: Epoch 080 - training loss: 0.1043, validation loss: 0.1155
2024-05-24 23:40:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch80_loss0.11552314534783363.pypots
2024-05-24 23:41:02 [INFO]: Epoch 081 - training loss: 0.1149, validation loss: 0.1166
2024-05-24 23:41:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch81_loss0.11659271791577339.pypots
2024-05-24 23:41:19 [INFO]: Epoch 082 - training loss: 0.1095, validation loss: 0.1169
2024-05-24 23:41:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch82_loss0.11689123362302781.pypots
2024-05-24 23:41:35 [INFO]: Epoch 083 - training loss: 0.1286, validation loss: 0.1168
2024-05-24 23:41:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch83_loss0.11676027625799179.pypots
2024-05-24 23:41:52 [INFO]: Epoch 084 - training loss: 0.1162, validation loss: 0.1167
2024-05-24 23:41:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch84_loss0.11670536696910858.pypots
2024-05-24 23:42:09 [INFO]: Epoch 085 - training loss: 0.1113, validation loss: 0.1151
2024-05-24 23:42:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch85_loss0.11513576284050941.pypots
2024-05-24 23:42:25 [INFO]: Epoch 086 - training loss: 0.1153, validation loss: 0.1135
2024-05-24 23:42:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch86_loss0.11346133276820183.pypots
2024-05-24 23:42:42 [INFO]: Epoch 087 - training loss: 0.1157, validation loss: 0.1140
2024-05-24 23:42:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch87_loss0.11401343941688538.pypots
2024-05-24 23:42:58 [INFO]: Epoch 088 - training loss: 0.1057, validation loss: 0.1146
2024-05-24 23:42:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch88_loss0.11461630463600159.pypots
2024-05-24 23:43:15 [INFO]: Epoch 089 - training loss: 0.1071, validation loss: 0.1128
2024-05-24 23:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch89_loss0.11282369121909142.pypots
2024-05-24 23:43:32 [INFO]: Epoch 090 - training loss: 0.1227, validation loss: 0.1144
2024-05-24 23:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch90_loss0.11440350785851479.pypots
2024-05-24 23:43:48 [INFO]: Epoch 091 - training loss: 0.1076, validation loss: 0.1192
2024-05-24 23:43:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch91_loss0.11916936039924622.pypots
2024-05-24 23:44:05 [INFO]: Epoch 092 - training loss: 0.1079, validation loss: 0.1121
2024-05-24 23:44:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch92_loss0.11205252036452293.pypots
2024-05-24 23:44:22 [INFO]: Epoch 093 - training loss: 0.1053, validation loss: 0.1114
2024-05-24 23:44:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch93_loss0.11142788976430892.pypots
2024-05-24 23:44:38 [INFO]: Epoch 094 - training loss: 0.1192, validation loss: 0.1111
2024-05-24 23:44:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch94_loss0.11109314113855362.pypots
2024-05-24 23:44:55 [INFO]: Epoch 095 - training loss: 0.1125, validation loss: 0.1130
2024-05-24 23:44:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch95_loss0.11295839101076126.pypots
2024-05-24 23:45:12 [INFO]: Epoch 096 - training loss: 0.1099, validation loss: 0.1136
2024-05-24 23:45:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch96_loss0.11362074613571167.pypots
2024-05-24 23:45:28 [INFO]: Epoch 097 - training loss: 0.1191, validation loss: 0.1134
2024-05-24 23:45:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch97_loss0.11336313486099243.pypots
2024-05-24 23:45:45 [INFO]: Epoch 098 - training loss: 0.1057, validation loss: 0.1096
2024-05-24 23:45:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch98_loss0.10958972200751305.pypots
2024-05-24 23:46:01 [INFO]: Epoch 099 - training loss: 0.1104, validation loss: 0.1151
2024-05-24 23:46:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch99_loss0.11514764055609703.pypots
2024-05-24 23:46:18 [INFO]: Epoch 100 - training loss: 0.1081, validation loss: 0.1108
2024-05-24 23:46:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch100_loss0.11076110303401947.pypots
2024-05-24 23:46:35 [INFO]: Epoch 101 - training loss: 0.1120, validation loss: 0.1152
2024-05-24 23:46:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch101_loss0.11520036458969116.pypots
2024-05-24 23:46:51 [INFO]: Epoch 102 - training loss: 0.0983, validation loss: 0.1126
2024-05-24 23:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch102_loss0.11262651458382607.pypots
2024-05-24 23:47:08 [INFO]: Epoch 103 - training loss: 0.1075, validation loss: 0.1084
2024-05-24 23:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch103_loss0.10835880041122437.pypots
2024-05-24 23:47:25 [INFO]: Epoch 104 - training loss: 0.1141, validation loss: 0.1104
2024-05-24 23:47:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch104_loss0.11037694290280342.pypots
2024-05-24 23:47:41 [INFO]: Epoch 105 - training loss: 0.1175, validation loss: 0.1123
2024-05-24 23:47:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch105_loss0.11229376122355461.pypots
2024-05-24 23:47:58 [INFO]: Epoch 106 - training loss: 0.1032, validation loss: 0.1095
2024-05-24 23:47:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch106_loss0.10949553772807122.pypots
2024-05-24 23:48:15 [INFO]: Epoch 107 - training loss: 0.1127, validation loss: 0.1090
2024-05-24 23:48:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch107_loss0.10900420024991035.pypots
2024-05-24 23:48:31 [INFO]: Epoch 108 - training loss: 0.1061, validation loss: 0.1106
2024-05-24 23:48:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch108_loss0.11063972935080528.pypots
2024-05-24 23:48:48 [INFO]: Epoch 109 - training loss: 0.1125, validation loss: 0.1121
2024-05-24 23:48:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch109_loss0.11209245920181274.pypots
2024-05-24 23:49:04 [INFO]: Epoch 110 - training loss: 0.1099, validation loss: 0.1103
2024-05-24 23:49:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch110_loss0.11027568802237511.pypots
2024-05-24 23:49:21 [INFO]: Epoch 111 - training loss: 0.1063, validation loss: 0.1085
2024-05-24 23:49:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch111_loss0.10845731571316719.pypots
2024-05-24 23:49:38 [INFO]: Epoch 112 - training loss: 0.1130, validation loss: 0.1064
2024-05-24 23:49:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch112_loss0.10638194531202316.pypots
2024-05-24 23:49:54 [INFO]: Epoch 113 - training loss: 0.1018, validation loss: 0.1062
2024-05-24 23:49:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch113_loss0.10616453960537911.pypots
2024-05-24 23:50:11 [INFO]: Epoch 114 - training loss: 0.0976, validation loss: 0.1099
2024-05-24 23:50:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch114_loss0.10988933742046356.pypots
2024-05-24 23:50:28 [INFO]: Epoch 115 - training loss: 0.1080, validation loss: 0.1089
2024-05-24 23:50:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch115_loss0.10890162587165833.pypots
2024-05-24 23:50:44 [INFO]: Epoch 116 - training loss: 0.1102, validation loss: 0.1125
2024-05-24 23:50:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch116_loss0.1124542236328125.pypots
2024-05-24 23:51:01 [INFO]: Epoch 117 - training loss: 0.0998, validation loss: 0.1089
2024-05-24 23:51:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch117_loss0.10888176038861275.pypots
2024-05-24 23:51:18 [INFO]: Epoch 118 - training loss: 0.1144, validation loss: 0.1075
2024-05-24 23:51:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch118_loss0.10754231736063957.pypots
2024-05-24 23:51:34 [INFO]: Epoch 119 - training loss: 0.0995, validation loss: 0.1065
2024-05-24 23:51:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch119_loss0.1065114714205265.pypots
2024-05-24 23:51:51 [INFO]: Epoch 120 - training loss: 0.1104, validation loss: 0.1061
2024-05-24 23:51:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch120_loss0.10606380477547646.pypots
2024-05-24 23:52:07 [INFO]: Epoch 121 - training loss: 0.1074, validation loss: 0.1100
2024-05-24 23:52:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch121_loss0.10999888256192207.pypots
2024-05-24 23:52:24 [INFO]: Epoch 122 - training loss: 0.0919, validation loss: 0.1061
2024-05-24 23:52:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch122_loss0.10605697631835938.pypots
2024-05-24 23:52:41 [INFO]: Epoch 123 - training loss: 0.1128, validation loss: 0.1077
2024-05-24 23:52:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch123_loss0.10769097656011581.pypots
2024-05-24 23:52:57 [INFO]: Epoch 124 - training loss: 0.1037, validation loss: 0.1086
2024-05-24 23:52:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch124_loss0.1085776410996914.pypots
2024-05-24 23:53:14 [INFO]: Epoch 125 - training loss: 0.1016, validation loss: 0.1072
2024-05-24 23:53:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch125_loss0.1071938470005989.pypots
2024-05-24 23:53:31 [INFO]: Epoch 126 - training loss: 0.1006, validation loss: 0.1057
2024-05-24 23:53:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch126_loss0.10573424249887467.pypots
2024-05-24 23:53:47 [INFO]: Epoch 127 - training loss: 0.1085, validation loss: 0.1043
2024-05-24 23:53:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch127_loss0.10427099913358688.pypots
2024-05-24 23:54:04 [INFO]: Epoch 128 - training loss: 0.1083, validation loss: 0.1052
2024-05-24 23:54:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch128_loss0.10520130246877671.pypots
2024-05-24 23:54:21 [INFO]: Epoch 129 - training loss: 0.1086, validation loss: 0.1083
2024-05-24 23:54:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch129_loss0.10833676606416702.pypots
2024-05-24 23:54:37 [INFO]: Epoch 130 - training loss: 0.1030, validation loss: 0.1053
2024-05-24 23:54:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch130_loss0.10534952208399773.pypots
2024-05-24 23:54:54 [INFO]: Epoch 131 - training loss: 0.1055, validation loss: 0.1064
2024-05-24 23:54:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch131_loss0.10639316216111183.pypots
2024-05-24 23:55:10 [INFO]: Epoch 132 - training loss: 0.1051, validation loss: 0.1087
2024-05-24 23:55:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch132_loss0.10871111303567886.pypots
2024-05-24 23:55:27 [INFO]: Epoch 133 - training loss: 0.1215, validation loss: 0.1060
2024-05-24 23:55:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch133_loss0.10599794834852219.pypots
2024-05-24 23:55:44 [INFO]: Epoch 134 - training loss: 0.1026, validation loss: 0.1051
2024-05-24 23:55:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch134_loss0.10510315224528313.pypots
2024-05-24 23:56:00 [INFO]: Epoch 135 - training loss: 0.1080, validation loss: 0.1062
2024-05-24 23:56:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch135_loss0.10618753358721733.pypots
2024-05-24 23:56:17 [INFO]: Epoch 136 - training loss: 0.1044, validation loss: 0.1063
2024-05-24 23:56:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch136_loss0.10626968517899513.pypots
2024-05-24 23:56:34 [INFO]: Epoch 137 - training loss: 0.1066, validation loss: 0.1040
2024-05-24 23:56:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch137_loss0.10396096780896187.pypots
2024-05-24 23:56:50 [INFO]: Epoch 138 - training loss: 0.1027, validation loss: 0.1066
2024-05-24 23:56:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch138_loss0.10661986991763114.pypots
2024-05-24 23:57:07 [INFO]: Epoch 139 - training loss: 0.1056, validation loss: 0.1071
2024-05-24 23:57:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch139_loss0.10706272795796394.pypots
2024-05-24 23:57:24 [INFO]: Epoch 140 - training loss: 0.1017, validation loss: 0.1107
2024-05-24 23:57:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch140_loss0.11066877767443657.pypots
2024-05-24 23:57:40 [INFO]: Epoch 141 - training loss: 0.1058, validation loss: 0.1052
2024-05-24 23:57:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch141_loss0.10524668097496033.pypots
2024-05-24 23:57:57 [INFO]: Epoch 142 - training loss: 0.1051, validation loss: 0.1037
2024-05-24 23:57:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch142_loss0.10371897593140603.pypots
2024-05-24 23:58:13 [INFO]: Epoch 143 - training loss: 0.0958, validation loss: 0.1046
2024-05-24 23:58:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch143_loss0.1045589916408062.pypots
2024-05-24 23:58:30 [INFO]: Epoch 144 - training loss: 0.0924, validation loss: 0.1045
2024-05-24 23:58:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch144_loss0.10448606610298157.pypots
2024-05-24 23:58:47 [INFO]: Epoch 145 - training loss: 0.1000, validation loss: 0.1070
2024-05-24 23:58:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch145_loss0.10700735598802566.pypots
2024-05-24 23:59:03 [INFO]: Epoch 146 - training loss: 0.0987, validation loss: 0.1034
2024-05-24 23:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch146_loss0.10339676737785339.pypots
2024-05-24 23:59:20 [INFO]: Epoch 147 - training loss: 0.1100, validation loss: 0.1072
2024-05-24 23:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch147_loss0.10723053216934204.pypots
2024-05-24 23:59:37 [INFO]: Epoch 148 - training loss: 0.1079, validation loss: 0.1052
2024-05-24 23:59:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch148_loss0.10516081377863884.pypots
2024-05-24 23:59:53 [INFO]: Epoch 149 - training loss: 0.1008, validation loss: 0.1045
2024-05-24 23:59:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch149_loss0.10449352785944939.pypots
2024-05-25 00:00:10 [INFO]: Epoch 150 - training loss: 0.1106, validation loss: 0.1067
2024-05-25 00:00:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch150_loss0.10665360316634179.pypots
2024-05-25 00:00:27 [INFO]: Epoch 151 - training loss: 0.1039, validation loss: 0.1094
2024-05-25 00:00:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch151_loss0.10936706662178039.pypots
2024-05-25 00:00:43 [INFO]: Epoch 152 - training loss: 0.1064, validation loss: 0.1032
2024-05-25 00:00:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch152_loss0.10321494713425636.pypots
2024-05-25 00:01:00 [INFO]: Epoch 153 - training loss: 0.0970, validation loss: 0.1040
2024-05-25 00:01:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch153_loss0.1039717435836792.pypots
2024-05-25 00:01:16 [INFO]: Epoch 154 - training loss: 0.1164, validation loss: 0.1030
2024-05-25 00:01:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch154_loss0.10296384990215302.pypots
2024-05-25 00:01:33 [INFO]: Epoch 155 - training loss: 0.0962, validation loss: 0.1049
2024-05-25 00:01:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch155_loss0.10494074448943139.pypots
2024-05-25 00:01:50 [INFO]: Epoch 156 - training loss: 0.1027, validation loss: 0.1030
2024-05-25 00:01:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch156_loss0.10304881408810615.pypots
2024-05-25 00:02:06 [INFO]: Epoch 157 - training loss: 0.1113, validation loss: 0.1070
2024-05-25 00:02:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch157_loss0.10700673088431359.pypots
2024-05-25 00:02:23 [INFO]: Epoch 158 - training loss: 0.1001, validation loss: 0.1083
2024-05-25 00:02:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch158_loss0.10833097323775291.pypots
2024-05-25 00:02:40 [INFO]: Epoch 159 - training loss: 0.1059, validation loss: 0.1050
2024-05-25 00:02:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch159_loss0.10501100495457649.pypots
2024-05-25 00:02:56 [INFO]: Epoch 160 - training loss: 0.1107, validation loss: 0.1054
2024-05-25 00:02:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch160_loss0.10538513660430908.pypots
2024-05-25 00:03:13 [INFO]: Epoch 161 - training loss: 0.1062, validation loss: 0.1036
2024-05-25 00:03:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch161_loss0.10358951315283775.pypots
2024-05-25 00:03:30 [INFO]: Epoch 162 - training loss: 0.1068, validation loss: 0.1038
2024-05-25 00:03:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch162_loss0.1037737749516964.pypots
2024-05-25 00:03:46 [INFO]: Epoch 163 - training loss: 0.0984, validation loss: 0.1032
2024-05-25 00:03:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch163_loss0.10323264002799988.pypots
2024-05-25 00:04:03 [INFO]: Epoch 164 - training loss: 0.1129, validation loss: 0.1031
2024-05-25 00:04:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI_epoch164_loss0.10313447713851928.pypots
2024-05-25 00:04:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:04:03 [INFO]: Finished training. The best model is from epoch#154.
2024-05-25 00:04:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240524_T231834/CSDI.pypots
2024-05-25 00:06:23 [INFO]: CSDI on Air-Quality: MAE=0.0968, MSE=0.0794
2024-05-25 00:06:23 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 00:06:23 [INFO]: Using the given device: cuda:0
2024-05-25 00:06:23 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T000623
2024-05-25 00:06:23 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T000623/tensorboard
2024-05-25 00:06:23 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 00:06:23 [INFO]: Epoch 001 - training loss: 63251.2012, validation loss: 0.6457
2024-05-25 00:06:24 [INFO]: Epoch 002 - training loss: 41926.6826, validation loss: 0.5666
2024-05-25 00:06:24 [INFO]: Epoch 003 - training loss: 41650.5810, validation loss: 0.5778
2024-05-25 00:06:24 [INFO]: Epoch 004 - training loss: 41523.8576, validation loss: 0.4732
2024-05-25 00:06:25 [INFO]: Epoch 005 - training loss: 41416.9576, validation loss: 0.4256
2024-05-25 00:06:25 [INFO]: Epoch 006 - training loss: 41359.3848, validation loss: 0.3809
2024-05-25 00:06:25 [INFO]: Epoch 007 - training loss: 41330.8464, validation loss: 0.3366
2024-05-25 00:06:26 [INFO]: Epoch 008 - training loss: 41287.8620, validation loss: 0.3226
2024-05-25 00:06:26 [INFO]: Epoch 009 - training loss: 41265.4168, validation loss: 0.3192
2024-05-25 00:06:26 [INFO]: Epoch 010 - training loss: 41229.6076, validation loss: 0.3052
2024-05-25 00:06:27 [INFO]: Epoch 011 - training loss: 41224.1577, validation loss: 0.3139
2024-05-25 00:06:27 [INFO]: Epoch 012 - training loss: 41213.8668, validation loss: 0.3386
2024-05-25 00:06:27 [INFO]: Epoch 013 - training loss: 41222.5052, validation loss: 0.2887
2024-05-25 00:06:28 [INFO]: Epoch 014 - training loss: 41193.1962, validation loss: 0.2760
2024-05-25 00:06:28 [INFO]: Epoch 015 - training loss: 41174.5969, validation loss: 0.2840
2024-05-25 00:06:28 [INFO]: Epoch 016 - training loss: 41175.3783, validation loss: 0.2789
2024-05-25 00:06:29 [INFO]: Epoch 017 - training loss: 41145.6916, validation loss: 0.2655
2024-05-25 00:06:29 [INFO]: Epoch 018 - training loss: 41131.5276, validation loss: 0.2569
2024-05-25 00:06:29 [INFO]: Epoch 019 - training loss: 41120.3291, validation loss: 0.2654
2024-05-25 00:06:30 [INFO]: Epoch 020 - training loss: 41154.0891, validation loss: 0.2792
2024-05-25 00:06:30 [INFO]: Epoch 021 - training loss: 41141.4306, validation loss: 0.2549
2024-05-25 00:06:30 [INFO]: Epoch 022 - training loss: 41118.6043, validation loss: 0.2494
2024-05-25 00:06:31 [INFO]: Epoch 023 - training loss: 41125.2934, validation loss: 0.2561
2024-05-25 00:06:31 [INFO]: Epoch 024 - training loss: 41102.0281, validation loss: 0.2498
2024-05-25 00:06:31 [INFO]: Epoch 025 - training loss: 41099.1147, validation loss: 0.2516
2024-05-25 00:06:32 [INFO]: Epoch 026 - training loss: 41105.3843, validation loss: 0.2333
2024-05-25 00:06:32 [INFO]: Epoch 027 - training loss: 41109.4161, validation loss: 0.2502
2024-05-25 00:06:32 [INFO]: Epoch 028 - training loss: 41088.4486, validation loss: 0.2404
2024-05-25 00:06:33 [INFO]: Epoch 029 - training loss: 41067.9878, validation loss: 0.2564
2024-05-25 00:06:33 [INFO]: Epoch 030 - training loss: 41075.3880, validation loss: 0.2299
2024-05-25 00:06:33 [INFO]: Epoch 031 - training loss: 41064.7011, validation loss: 0.2254
2024-05-25 00:06:34 [INFO]: Epoch 032 - training loss: 41059.9617, validation loss: 0.2354
2024-05-25 00:06:34 [INFO]: Epoch 033 - training loss: 41074.0009, validation loss: 0.2680
2024-05-25 00:06:34 [INFO]: Epoch 034 - training loss: 41079.7011, validation loss: 0.2301
2024-05-25 00:06:35 [INFO]: Epoch 035 - training loss: 41129.6965, validation loss: 0.2406
2024-05-25 00:06:35 [INFO]: Epoch 036 - training loss: 41105.5521, validation loss: 0.2272
2024-05-25 00:06:35 [INFO]: Epoch 037 - training loss: 41086.4880, validation loss: 0.2416
2024-05-25 00:06:36 [INFO]: Epoch 038 - training loss: 41073.8945, validation loss: 0.2276
2024-05-25 00:06:36 [INFO]: Epoch 039 - training loss: 41045.5233, validation loss: 0.2174
2024-05-25 00:06:36 [INFO]: Epoch 040 - training loss: 41036.3125, validation loss: 0.2377
2024-05-25 00:06:37 [INFO]: Epoch 041 - training loss: 41075.4146, validation loss: 0.2206
2024-05-25 00:06:37 [INFO]: Epoch 042 - training loss: 41037.3708, validation loss: 0.2135
2024-05-25 00:06:37 [INFO]: Epoch 043 - training loss: 41026.9000, validation loss: 0.2123
2024-05-25 00:06:38 [INFO]: Epoch 044 - training loss: 41026.1736, validation loss: 0.2127
2024-05-25 00:06:38 [INFO]: Epoch 045 - training loss: 41022.8741, validation loss: 0.2096
2024-05-25 00:06:38 [INFO]: Epoch 046 - training loss: 41022.9797, validation loss: 0.2106
2024-05-25 00:06:39 [INFO]: Epoch 047 - training loss: 41027.1383, validation loss: 0.2221
2024-05-25 00:06:39 [INFO]: Epoch 048 - training loss: 41024.4688, validation loss: 0.2076
2024-05-25 00:06:39 [INFO]: Epoch 049 - training loss: 41013.7076, validation loss: 0.2038
2024-05-25 00:06:40 [INFO]: Epoch 050 - training loss: 41032.2527, validation loss: 0.2318
2024-05-25 00:06:40 [INFO]: Epoch 051 - training loss: 41029.8372, validation loss: 0.2075
2024-05-25 00:06:40 [INFO]: Epoch 052 - training loss: 41022.8083, validation loss: 0.2139
2024-05-25 00:06:41 [INFO]: Epoch 053 - training loss: 41024.1885, validation loss: 0.2198
2024-05-25 00:06:41 [INFO]: Epoch 054 - training loss: 41035.8086, validation loss: 0.2071
2024-05-25 00:06:41 [INFO]: Epoch 055 - training loss: 41073.3436, validation loss: 0.2313
2024-05-25 00:06:42 [INFO]: Epoch 056 - training loss: 41137.5571, validation loss: 0.2387
2024-05-25 00:06:42 [INFO]: Epoch 057 - training loss: 41087.5394, validation loss: 0.2153
2024-05-25 00:06:42 [INFO]: Epoch 058 - training loss: 41067.1097, validation loss: 0.2089
2024-05-25 00:06:42 [INFO]: Epoch 059 - training loss: 41055.7365, validation loss: 0.2108
2024-05-25 00:06:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:06:42 [INFO]: Finished training. The best model is from epoch#49.
2024-05-25 00:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T000623/GPVAE.pypots
2024-05-25 00:06:43 [INFO]: GP-VAE on Air-Quality: MAE=0.2885, MSE=0.2297
2024-05-25 00:06:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 00:06:43 [INFO]: Using the given device: cuda:0
2024-05-25 00:06:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T000643
2024-05-25 00:06:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T000643/tensorboard
2024-05-25 00:06:43 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 00:06:48 [INFO]: Epoch 001 - generator training loss: 0.5352, discriminator training loss: 0.3735, validation loss: 0.5111
2024-05-25 00:06:52 [INFO]: Epoch 002 - generator training loss: 0.1495, discriminator training loss: 0.2419, validation loss: 0.3819
2024-05-25 00:06:56 [INFO]: Epoch 003 - generator training loss: 0.0955, discriminator training loss: 0.2382, validation loss: 0.3057
2024-05-25 00:07:00 [INFO]: Epoch 004 - generator training loss: 0.0532, discriminator training loss: 0.2372, validation loss: 0.2604
2024-05-25 00:07:04 [INFO]: Epoch 005 - generator training loss: 0.0276, discriminator training loss: 0.2362, validation loss: 0.2316
2024-05-25 00:07:08 [INFO]: Epoch 006 - generator training loss: 0.0096, discriminator training loss: 0.2354, validation loss: 0.2130
2024-05-25 00:07:12 [INFO]: Epoch 007 - generator training loss: -0.0046, discriminator training loss: 0.2343, validation loss: 0.1988
2024-05-25 00:07:16 [INFO]: Epoch 008 - generator training loss: -0.0131, discriminator training loss: 0.2334, validation loss: 0.1895
2024-05-25 00:07:21 [INFO]: Epoch 009 - generator training loss: -0.0197, discriminator training loss: 0.2317, validation loss: 0.1802
2024-05-25 00:07:25 [INFO]: Epoch 010 - generator training loss: -0.0266, discriminator training loss: 0.2305, validation loss: 0.1723
2024-05-25 00:07:29 [INFO]: Epoch 011 - generator training loss: -0.0301, discriminator training loss: 0.2292, validation loss: 0.1660
2024-05-25 00:07:33 [INFO]: Epoch 012 - generator training loss: -0.0344, discriminator training loss: 0.2276, validation loss: 0.1611
2024-05-25 00:07:37 [INFO]: Epoch 013 - generator training loss: -0.0373, discriminator training loss: 0.2261, validation loss: 0.1562
2024-05-25 00:07:41 [INFO]: Epoch 014 - generator training loss: -0.0422, discriminator training loss: 0.2241, validation loss: 0.1516
2024-05-25 00:07:45 [INFO]: Epoch 015 - generator training loss: -0.0440, discriminator training loss: 0.2224, validation loss: 0.1482
2024-05-25 00:07:49 [INFO]: Epoch 016 - generator training loss: -0.0473, discriminator training loss: 0.2213, validation loss: 0.1448
2024-05-25 00:07:54 [INFO]: Epoch 017 - generator training loss: -0.0456, discriminator training loss: 0.2192, validation loss: 0.1409
2024-05-25 00:07:58 [INFO]: Epoch 018 - generator training loss: -0.0488, discriminator training loss: 0.2178, validation loss: 0.1384
2024-05-25 00:08:02 [INFO]: Epoch 019 - generator training loss: -0.0497, discriminator training loss: 0.2161, validation loss: 0.1355
2024-05-25 00:08:06 [INFO]: Epoch 020 - generator training loss: -0.0525, discriminator training loss: 0.2145, validation loss: 0.1330
2024-05-25 00:08:10 [INFO]: Epoch 021 - generator training loss: -0.0529, discriminator training loss: 0.2129, validation loss: 0.1303
2024-05-25 00:08:14 [INFO]: Epoch 022 - generator training loss: -0.0542, discriminator training loss: 0.2110, validation loss: 0.1285
2024-05-25 00:08:18 [INFO]: Epoch 023 - generator training loss: -0.0528, discriminator training loss: 0.2092, validation loss: 0.1261
2024-05-25 00:08:22 [INFO]: Epoch 024 - generator training loss: -0.0554, discriminator training loss: 0.2074, validation loss: 0.1239
2024-05-25 00:08:26 [INFO]: Epoch 025 - generator training loss: -0.0549, discriminator training loss: 0.2058, validation loss: 0.1219
2024-05-25 00:08:31 [INFO]: Epoch 026 - generator training loss: -0.0556, discriminator training loss: 0.2037, validation loss: 0.1203
2024-05-25 00:08:35 [INFO]: Epoch 027 - generator training loss: -0.0540, discriminator training loss: 0.2018, validation loss: 0.1181
2024-05-25 00:08:39 [INFO]: Epoch 028 - generator training loss: -0.0549, discriminator training loss: 0.2002, validation loss: 0.1167
2024-05-25 00:08:43 [INFO]: Epoch 029 - generator training loss: -0.0531, discriminator training loss: 0.1986, validation loss: 0.1154
2024-05-25 00:08:47 [INFO]: Epoch 030 - generator training loss: -0.0551, discriminator training loss: 0.1968, validation loss: 0.1133
2024-05-25 00:08:51 [INFO]: Epoch 031 - generator training loss: -0.0546, discriminator training loss: 0.1949, validation loss: 0.1115
2024-05-25 00:08:55 [INFO]: Epoch 032 - generator training loss: -0.0529, discriminator training loss: 0.1936, validation loss: 0.1107
2024-05-25 00:09:00 [INFO]: Epoch 033 - generator training loss: -0.0544, discriminator training loss: 0.1917, validation loss: 0.1092
2024-05-25 00:09:04 [INFO]: Epoch 034 - generator training loss: -0.0541, discriminator training loss: 0.1902, validation loss: 0.1074
2024-05-25 00:09:08 [INFO]: Epoch 035 - generator training loss: -0.0523, discriminator training loss: 0.1885, validation loss: 0.1066
2024-05-25 00:09:12 [INFO]: Epoch 036 - generator training loss: -0.0532, discriminator training loss: 0.1872, validation loss: 0.1052
2024-05-25 00:09:16 [INFO]: Epoch 037 - generator training loss: -0.0526, discriminator training loss: 0.1853, validation loss: 0.1041
2024-05-25 00:09:20 [INFO]: Epoch 038 - generator training loss: -0.0525, discriminator training loss: 0.1838, validation loss: 0.1028
2024-05-25 00:09:24 [INFO]: Epoch 039 - generator training loss: -0.0525, discriminator training loss: 0.1824, validation loss: 0.1019
2024-05-25 00:09:28 [INFO]: Epoch 040 - generator training loss: -0.0519, discriminator training loss: 0.1810, validation loss: 0.1010
2024-05-25 00:09:32 [INFO]: Epoch 041 - generator training loss: -0.0511, discriminator training loss: 0.1794, validation loss: 0.0998
2024-05-25 00:09:37 [INFO]: Epoch 042 - generator training loss: -0.0519, discriminator training loss: 0.1781, validation loss: 0.0982
2024-05-25 00:09:41 [INFO]: Epoch 043 - generator training loss: -0.0511, discriminator training loss: 0.1766, validation loss: 0.0976
2024-05-25 00:09:45 [INFO]: Epoch 044 - generator training loss: -0.0505, discriminator training loss: 0.1753, validation loss: 0.0969
2024-05-25 00:09:49 [INFO]: Epoch 045 - generator training loss: -0.0506, discriminator training loss: 0.1741, validation loss: 0.0960
2024-05-25 00:09:53 [INFO]: Epoch 046 - generator training loss: -0.0501, discriminator training loss: 0.1724, validation loss: 0.0946
2024-05-25 00:09:57 [INFO]: Epoch 047 - generator training loss: -0.0500, discriminator training loss: 0.1712, validation loss: 0.0936
2024-05-25 00:10:01 [INFO]: Epoch 048 - generator training loss: -0.0493, discriminator training loss: 0.1698, validation loss: 0.0931
2024-05-25 00:10:06 [INFO]: Epoch 049 - generator training loss: -0.0486, discriminator training loss: 0.1688, validation loss: 0.0923
2024-05-25 00:10:10 [INFO]: Epoch 050 - generator training loss: -0.0471, discriminator training loss: 0.1676, validation loss: 0.0918
2024-05-25 00:10:14 [INFO]: Epoch 051 - generator training loss: -0.0477, discriminator training loss: 0.1665, validation loss: 0.0911
2024-05-25 00:10:18 [INFO]: Epoch 052 - generator training loss: -0.0475, discriminator training loss: 0.1654, validation loss: 0.0906
2024-05-25 00:10:22 [INFO]: Epoch 053 - generator training loss: -0.0475, discriminator training loss: 0.1641, validation loss: 0.0895
2024-05-25 00:10:26 [INFO]: Epoch 054 - generator training loss: -0.0477, discriminator training loss: 0.1630, validation loss: 0.0888
2024-05-25 00:10:30 [INFO]: Epoch 055 - generator training loss: -0.0479, discriminator training loss: 0.1621, validation loss: 0.0880
2024-05-25 00:10:34 [INFO]: Epoch 056 - generator training loss: -0.0473, discriminator training loss: 0.1614, validation loss: 0.0875
2024-05-25 00:10:38 [INFO]: Epoch 057 - generator training loss: -0.0468, discriminator training loss: 0.1601, validation loss: 0.0866
2024-05-25 00:10:43 [INFO]: Epoch 058 - generator training loss: -0.0468, discriminator training loss: 0.1591, validation loss: 0.0862
2024-05-25 00:10:47 [INFO]: Epoch 059 - generator training loss: -0.0459, discriminator training loss: 0.1583, validation loss: 0.0859
2024-05-25 00:10:51 [INFO]: Epoch 060 - generator training loss: -0.0457, discriminator training loss: 0.1575, validation loss: 0.0847
2024-05-25 00:10:55 [INFO]: Epoch 061 - generator training loss: -0.0461, discriminator training loss: 0.1567, validation loss: 0.0848
2024-05-25 00:10:59 [INFO]: Epoch 062 - generator training loss: -0.0462, discriminator training loss: 0.1557, validation loss: 0.0844
2024-05-25 00:11:03 [INFO]: Epoch 063 - generator training loss: -0.0450, discriminator training loss: 0.1549, validation loss: 0.0838
2024-05-25 00:11:07 [INFO]: Epoch 064 - generator training loss: -0.0447, discriminator training loss: 0.1544, validation loss: 0.0831
2024-05-25 00:11:12 [INFO]: Epoch 065 - generator training loss: -0.0449, discriminator training loss: 0.1535, validation loss: 0.0826
2024-05-25 00:11:16 [INFO]: Epoch 066 - generator training loss: -0.0455, discriminator training loss: 0.1525, validation loss: 0.0821
2024-05-25 00:11:20 [INFO]: Epoch 067 - generator training loss: -0.0453, discriminator training loss: 0.1522, validation loss: 0.0818
2024-05-25 00:11:24 [INFO]: Epoch 068 - generator training loss: -0.0453, discriminator training loss: 0.1512, validation loss: 0.0814
2024-05-25 00:11:28 [INFO]: Epoch 069 - generator training loss: -0.0446, discriminator training loss: 0.1505, validation loss: 0.0808
2024-05-25 00:11:32 [INFO]: Epoch 070 - generator training loss: -0.0453, discriminator training loss: 0.1499, validation loss: 0.0806
2024-05-25 00:11:36 [INFO]: Epoch 071 - generator training loss: -0.0440, discriminator training loss: 0.1495, validation loss: 0.0806
2024-05-25 00:11:40 [INFO]: Epoch 072 - generator training loss: -0.0443, discriminator training loss: 0.1487, validation loss: 0.0796
2024-05-25 00:11:44 [INFO]: Epoch 073 - generator training loss: -0.0442, discriminator training loss: 0.1484, validation loss: 0.0799
2024-05-25 00:11:49 [INFO]: Epoch 074 - generator training loss: -0.0447, discriminator training loss: 0.1478, validation loss: 0.0788
2024-05-25 00:11:53 [INFO]: Epoch 075 - generator training loss: -0.0443, discriminator training loss: 0.1475, validation loss: 0.0791
2024-05-25 00:11:57 [INFO]: Epoch 076 - generator training loss: -0.0440, discriminator training loss: 0.1470, validation loss: 0.0787
2024-05-25 00:12:01 [INFO]: Epoch 077 - generator training loss: -0.0428, discriminator training loss: 0.1464, validation loss: 0.0800
2024-05-25 00:12:05 [INFO]: Epoch 078 - generator training loss: -0.0425, discriminator training loss: 0.1459, validation loss: 0.0789
2024-05-25 00:12:09 [INFO]: Epoch 079 - generator training loss: -0.0429, discriminator training loss: 0.1456, validation loss: 0.0786
2024-05-25 00:12:13 [INFO]: Epoch 080 - generator training loss: -0.0431, discriminator training loss: 0.1451, validation loss: 0.0775
2024-05-25 00:12:18 [INFO]: Epoch 081 - generator training loss: -0.0442, discriminator training loss: 0.1449, validation loss: 0.0774
2024-05-25 00:12:22 [INFO]: Epoch 082 - generator training loss: -0.0434, discriminator training loss: 0.1442, validation loss: 0.0772
2024-05-25 00:12:26 [INFO]: Epoch 083 - generator training loss: -0.0444, discriminator training loss: 0.1438, validation loss: 0.0765
2024-05-25 00:12:30 [INFO]: Epoch 084 - generator training loss: -0.0437, discriminator training loss: 0.1434, validation loss: 0.0772
2024-05-25 00:12:34 [INFO]: Epoch 085 - generator training loss: -0.0435, discriminator training loss: 0.1431, validation loss: 0.0762
2024-05-25 00:12:38 [INFO]: Epoch 086 - generator training loss: -0.0447, discriminator training loss: 0.1428, validation loss: 0.0767
2024-05-25 00:12:42 [INFO]: Epoch 087 - generator training loss: -0.0440, discriminator training loss: 0.1421, validation loss: 0.0763
2024-05-25 00:12:46 [INFO]: Epoch 088 - generator training loss: -0.0441, discriminator training loss: 0.1420, validation loss: 0.0764
2024-05-25 00:12:50 [INFO]: Epoch 089 - generator training loss: -0.0444, discriminator training loss: 0.1414, validation loss: 0.0754
2024-05-25 00:12:55 [INFO]: Epoch 090 - generator training loss: -0.0439, discriminator training loss: 0.1411, validation loss: 0.0761
2024-05-25 00:12:59 [INFO]: Epoch 091 - generator training loss: -0.0450, discriminator training loss: 0.1407, validation loss: 0.0755
2024-05-25 00:13:03 [INFO]: Epoch 092 - generator training loss: -0.0443, discriminator training loss: 0.1405, validation loss: 0.0749
2024-05-25 00:13:07 [INFO]: Epoch 093 - generator training loss: -0.0431, discriminator training loss: 0.1402, validation loss: 0.0753
2024-05-25 00:13:11 [INFO]: Epoch 094 - generator training loss: -0.0421, discriminator training loss: 0.1399, validation loss: 0.0751
2024-05-25 00:13:15 [INFO]: Epoch 095 - generator training loss: -0.0434, discriminator training loss: 0.1395, validation loss: 0.0744
2024-05-25 00:13:19 [INFO]: Epoch 096 - generator training loss: -0.0442, discriminator training loss: 0.1393, validation loss: 0.0736
2024-05-25 00:13:23 [INFO]: Epoch 097 - generator training loss: -0.0447, discriminator training loss: 0.1396, validation loss: 0.0739
2024-05-25 00:13:28 [INFO]: Epoch 098 - generator training loss: -0.0448, discriminator training loss: 0.1388, validation loss: 0.0741
2024-05-25 00:13:32 [INFO]: Epoch 099 - generator training loss: -0.0448, discriminator training loss: 0.1387, validation loss: 0.0741
2024-05-25 00:13:36 [INFO]: Epoch 100 - generator training loss: -0.0450, discriminator training loss: 0.1382, validation loss: 0.0736
2024-05-25 00:13:40 [INFO]: Epoch 101 - generator training loss: -0.0451, discriminator training loss: 0.1377, validation loss: 0.0737
2024-05-25 00:13:44 [INFO]: Epoch 102 - generator training loss: -0.0453, discriminator training loss: 0.1380, validation loss: 0.0737
2024-05-25 00:13:48 [INFO]: Epoch 103 - generator training loss: -0.0448, discriminator training loss: 0.1375, validation loss: 0.0734
2024-05-25 00:13:52 [INFO]: Epoch 104 - generator training loss: -0.0445, discriminator training loss: 0.1376, validation loss: 0.0728
2024-05-25 00:13:56 [INFO]: Epoch 105 - generator training loss: -0.0457, discriminator training loss: 0.1367, validation loss: 0.0735
2024-05-25 00:14:01 [INFO]: Epoch 106 - generator training loss: -0.0447, discriminator training loss: 0.1370, validation loss: 0.0733
2024-05-25 00:14:05 [INFO]: Epoch 107 - generator training loss: -0.0450, discriminator training loss: 0.1372, validation loss: 0.0731
2024-05-25 00:14:09 [INFO]: Epoch 108 - generator training loss: -0.0461, discriminator training loss: 0.1367, validation loss: 0.0725
2024-05-25 00:14:13 [INFO]: Epoch 109 - generator training loss: -0.0456, discriminator training loss: 0.1362, validation loss: 0.0721
2024-05-25 00:14:17 [INFO]: Epoch 110 - generator training loss: -0.0448, discriminator training loss: 0.1359, validation loss: 0.0728
2024-05-25 00:14:21 [INFO]: Epoch 111 - generator training loss: -0.0453, discriminator training loss: 0.1362, validation loss: 0.0736
2024-05-25 00:14:25 [INFO]: Epoch 112 - generator training loss: -0.0426, discriminator training loss: 0.1359, validation loss: 0.0729
2024-05-25 00:14:29 [INFO]: Epoch 113 - generator training loss: -0.0442, discriminator training loss: 0.1358, validation loss: 0.0730
2024-05-25 00:14:34 [INFO]: Epoch 114 - generator training loss: -0.0448, discriminator training loss: 0.1353, validation loss: 0.0723
2024-05-25 00:14:38 [INFO]: Epoch 115 - generator training loss: -0.0452, discriminator training loss: 0.1355, validation loss: 0.0717
2024-05-25 00:14:42 [INFO]: Epoch 116 - generator training loss: -0.0466, discriminator training loss: 0.1352, validation loss: 0.0713
2024-05-25 00:14:46 [INFO]: Epoch 117 - generator training loss: -0.0465, discriminator training loss: 0.1351, validation loss: 0.0718
2024-05-25 00:14:50 [INFO]: Epoch 118 - generator training loss: -0.0462, discriminator training loss: 0.1352, validation loss: 0.0728
2024-05-25 00:14:54 [INFO]: Epoch 119 - generator training loss: -0.0457, discriminator training loss: 0.1346, validation loss: 0.0723
2024-05-25 00:14:58 [INFO]: Epoch 120 - generator training loss: -0.0460, discriminator training loss: 0.1345, validation loss: 0.0714
2024-05-25 00:15:02 [INFO]: Epoch 121 - generator training loss: -0.0466, discriminator training loss: 0.1344, validation loss: 0.0716
2024-05-25 00:15:07 [INFO]: Epoch 122 - generator training loss: -0.0465, discriminator training loss: 0.1337, validation loss: 0.0713
2024-05-25 00:15:11 [INFO]: Epoch 123 - generator training loss: -0.0468, discriminator training loss: 0.1343, validation loss: 0.0711
2024-05-25 00:15:15 [INFO]: Epoch 124 - generator training loss: -0.0470, discriminator training loss: 0.1339, validation loss: 0.0722
2024-05-25 00:15:19 [INFO]: Epoch 125 - generator training loss: -0.0473, discriminator training loss: 0.1342, validation loss: 0.0720
2024-05-25 00:15:23 [INFO]: Epoch 126 - generator training loss: -0.0465, discriminator training loss: 0.1339, validation loss: 0.0710
2024-05-25 00:15:27 [INFO]: Epoch 127 - generator training loss: -0.0462, discriminator training loss: 0.1334, validation loss: 0.0709
2024-05-25 00:15:31 [INFO]: Epoch 128 - generator training loss: -0.0463, discriminator training loss: 0.1337, validation loss: 0.0720
2024-05-25 00:15:35 [INFO]: Epoch 129 - generator training loss: -0.0469, discriminator training loss: 0.1333, validation loss: 0.0713
2024-05-25 00:15:39 [INFO]: Epoch 130 - generator training loss: -0.0463, discriminator training loss: 0.1333, validation loss: 0.0719
2024-05-25 00:15:44 [INFO]: Epoch 131 - generator training loss: -0.0471, discriminator training loss: 0.1333, validation loss: 0.0715
2024-05-25 00:15:48 [INFO]: Epoch 132 - generator training loss: -0.0473, discriminator training loss: 0.1332, validation loss: 0.0716
2024-05-25 00:15:52 [INFO]: Epoch 133 - generator training loss: -0.0476, discriminator training loss: 0.1326, validation loss: 0.0711
2024-05-25 00:15:56 [INFO]: Epoch 134 - generator training loss: -0.0472, discriminator training loss: 0.1332, validation loss: 0.0710
2024-05-25 00:16:00 [INFO]: Epoch 135 - generator training loss: -0.0475, discriminator training loss: 0.1326, validation loss: 0.0713
2024-05-25 00:16:04 [INFO]: Epoch 136 - generator training loss: -0.0474, discriminator training loss: 0.1327, validation loss: 0.0711
2024-05-25 00:16:08 [INFO]: Epoch 137 - generator training loss: -0.0469, discriminator training loss: 0.1324, validation loss: 0.0697
2024-05-25 00:16:12 [INFO]: Epoch 138 - generator training loss: -0.0431, discriminator training loss: 0.1327, validation loss: 0.0720
2024-05-25 00:16:17 [INFO]: Epoch 139 - generator training loss: -0.0455, discriminator training loss: 0.1326, validation loss: 0.0692
2024-05-25 00:16:21 [INFO]: Epoch 140 - generator training loss: -0.0465, discriminator training loss: 0.1322, validation loss: 0.0710
2024-05-25 00:16:25 [INFO]: Epoch 141 - generator training loss: -0.0470, discriminator training loss: 0.1323, validation loss: 0.0708
2024-05-25 00:16:29 [INFO]: Epoch 142 - generator training loss: -0.0480, discriminator training loss: 0.1318, validation loss: 0.0697
2024-05-25 00:16:33 [INFO]: Epoch 143 - generator training loss: -0.0480, discriminator training loss: 0.1319, validation loss: 0.0698
2024-05-25 00:16:37 [INFO]: Epoch 144 - generator training loss: -0.0479, discriminator training loss: 0.1318, validation loss: 0.0703
2024-05-25 00:16:41 [INFO]: Epoch 145 - generator training loss: -0.0486, discriminator training loss: 0.1319, validation loss: 0.0703
2024-05-25 00:16:46 [INFO]: Epoch 146 - generator training loss: -0.0479, discriminator training loss: 0.1321, validation loss: 0.0696
2024-05-25 00:16:50 [INFO]: Epoch 147 - generator training loss: -0.0484, discriminator training loss: 0.1316, validation loss: 0.0709
2024-05-25 00:16:54 [INFO]: Epoch 148 - generator training loss: -0.0482, discriminator training loss: 0.1318, validation loss: 0.0700
2024-05-25 00:16:58 [INFO]: Epoch 149 - generator training loss: -0.0488, discriminator training loss: 0.1313, validation loss: 0.0704
2024-05-25 00:16:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:16:58 [INFO]: Finished training. The best model is from epoch#139.
2024-05-25 00:16:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T000643/USGAN.pypots
2024-05-25 00:16:59 [INFO]: US-GAN on Air-Quality: MAE=0.1397, MSE=0.0847
2024-05-25 00:16:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 00:16:59 [INFO]: Using the given device: cuda:0
2024-05-25 00:16:59 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T001659
2024-05-25 00:16:59 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T001659/tensorboard
2024-05-25 00:16:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 00:17:02 [INFO]: Epoch 001 - training loss: 1.3942, validation loss: 0.9378
2024-05-25 00:17:05 [INFO]: Epoch 002 - training loss: 1.1304, validation loss: 0.7037
2024-05-25 00:17:08 [INFO]: Epoch 003 - training loss: 0.9430, validation loss: 0.5960
2024-05-25 00:17:11 [INFO]: Epoch 004 - training loss: 0.8346, validation loss: 0.5244
2024-05-25 00:17:13 [INFO]: Epoch 005 - training loss: 0.7624, validation loss: 0.4758
2024-05-25 00:17:16 [INFO]: Epoch 006 - training loss: 0.7077, validation loss: 0.4370
2024-05-25 00:17:19 [INFO]: Epoch 007 - training loss: 0.6646, validation loss: 0.4039
2024-05-25 00:17:22 [INFO]: Epoch 008 - training loss: 0.6322, validation loss: 0.3777
2024-05-25 00:17:25 [INFO]: Epoch 009 - training loss: 0.6036, validation loss: 0.3547
2024-05-25 00:17:28 [INFO]: Epoch 010 - training loss: 0.5825, validation loss: 0.3369
2024-05-25 00:17:30 [INFO]: Epoch 011 - training loss: 0.5648, validation loss: 0.3212
2024-05-25 00:17:33 [INFO]: Epoch 012 - training loss: 0.5492, validation loss: 0.3079
2024-05-25 00:17:36 [INFO]: Epoch 013 - training loss: 0.5361, validation loss: 0.2964
2024-05-25 00:17:39 [INFO]: Epoch 014 - training loss: 0.5240, validation loss: 0.2871
2024-05-25 00:17:42 [INFO]: Epoch 015 - training loss: 0.5127, validation loss: 0.2784
2024-05-25 00:17:44 [INFO]: Epoch 016 - training loss: 0.5041, validation loss: 0.2707
2024-05-25 00:17:47 [INFO]: Epoch 017 - training loss: 0.4945, validation loss: 0.2638
2024-05-25 00:17:50 [INFO]: Epoch 018 - training loss: 0.4859, validation loss: 0.2576
2024-05-25 00:17:53 [INFO]: Epoch 019 - training loss: 0.4786, validation loss: 0.2519
2024-05-25 00:17:56 [INFO]: Epoch 020 - training loss: 0.4700, validation loss: 0.2469
2024-05-25 00:17:58 [INFO]: Epoch 021 - training loss: 0.4633, validation loss: 0.2420
2024-05-25 00:18:01 [INFO]: Epoch 022 - training loss: 0.4581, validation loss: 0.2367
2024-05-25 00:18:04 [INFO]: Epoch 023 - training loss: 0.4513, validation loss: 0.2325
2024-05-25 00:18:07 [INFO]: Epoch 024 - training loss: 0.4452, validation loss: 0.2287
2024-05-25 00:18:10 [INFO]: Epoch 025 - training loss: 0.4394, validation loss: 0.2243
2024-05-25 00:18:12 [INFO]: Epoch 026 - training loss: 0.4343, validation loss: 0.2202
2024-05-25 00:18:15 [INFO]: Epoch 027 - training loss: 0.4280, validation loss: 0.2168
2024-05-25 00:18:18 [INFO]: Epoch 028 - training loss: 0.4225, validation loss: 0.2131
2024-05-25 00:18:21 [INFO]: Epoch 029 - training loss: 0.4184, validation loss: 0.2097
2024-05-25 00:18:24 [INFO]: Epoch 030 - training loss: 0.4131, validation loss: 0.2061
2024-05-25 00:18:27 [INFO]: Epoch 031 - training loss: 0.4090, validation loss: 0.2029
2024-05-25 00:18:29 [INFO]: Epoch 032 - training loss: 0.4045, validation loss: 0.1997
2024-05-25 00:18:32 [INFO]: Epoch 033 - training loss: 0.4007, validation loss: 0.1964
2024-05-25 00:18:35 [INFO]: Epoch 034 - training loss: 0.3975, validation loss: 0.1936
2024-05-25 00:18:38 [INFO]: Epoch 035 - training loss: 0.3925, validation loss: 0.1907
2024-05-25 00:18:41 [INFO]: Epoch 036 - training loss: 0.3878, validation loss: 0.1879
2024-05-25 00:18:43 [INFO]: Epoch 037 - training loss: 0.3852, validation loss: 0.1851
2024-05-25 00:18:46 [INFO]: Epoch 038 - training loss: 0.3823, validation loss: 0.1827
2024-05-25 00:18:49 [INFO]: Epoch 039 - training loss: 0.3772, validation loss: 0.1799
2024-05-25 00:18:52 [INFO]: Epoch 040 - training loss: 0.3752, validation loss: 0.1773
2024-05-25 00:18:55 [INFO]: Epoch 041 - training loss: 0.3726, validation loss: 0.1745
2024-05-25 00:18:57 [INFO]: Epoch 042 - training loss: 0.3690, validation loss: 0.1726
2024-05-25 00:19:00 [INFO]: Epoch 043 - training loss: 0.3653, validation loss: 0.1704
2024-05-25 00:19:03 [INFO]: Epoch 044 - training loss: 0.3633, validation loss: 0.1682
2024-05-25 00:19:06 [INFO]: Epoch 045 - training loss: 0.3598, validation loss: 0.1663
2024-05-25 00:19:09 [INFO]: Epoch 046 - training loss: 0.3579, validation loss: 0.1638
2024-05-25 00:19:11 [INFO]: Epoch 047 - training loss: 0.3555, validation loss: 0.1621
2024-05-25 00:19:14 [INFO]: Epoch 048 - training loss: 0.3526, validation loss: 0.1603
2024-05-25 00:19:17 [INFO]: Epoch 049 - training loss: 0.3503, validation loss: 0.1586
2024-05-25 00:19:20 [INFO]: Epoch 050 - training loss: 0.3481, validation loss: 0.1570
2024-05-25 00:19:23 [INFO]: Epoch 051 - training loss: 0.3458, validation loss: 0.1553
2024-05-25 00:19:26 [INFO]: Epoch 052 - training loss: 0.3440, validation loss: 0.1537
2024-05-25 00:19:28 [INFO]: Epoch 053 - training loss: 0.3412, validation loss: 0.1522
2024-05-25 00:19:31 [INFO]: Epoch 054 - training loss: 0.3396, validation loss: 0.1509
2024-05-25 00:19:34 [INFO]: Epoch 055 - training loss: 0.3389, validation loss: 0.1496
2024-05-25 00:19:37 [INFO]: Epoch 056 - training loss: 0.3360, validation loss: 0.1479
2024-05-25 00:19:40 [INFO]: Epoch 057 - training loss: 0.3337, validation loss: 0.1468
2024-05-25 00:19:42 [INFO]: Epoch 058 - training loss: 0.3310, validation loss: 0.1459
2024-05-25 00:19:45 [INFO]: Epoch 059 - training loss: 0.3297, validation loss: 0.1446
2024-05-25 00:19:48 [INFO]: Epoch 060 - training loss: 0.3286, validation loss: 0.1432
2024-05-25 00:19:51 [INFO]: Epoch 061 - training loss: 0.3268, validation loss: 0.1422
2024-05-25 00:19:54 [INFO]: Epoch 062 - training loss: 0.3254, validation loss: 0.1413
2024-05-25 00:19:56 [INFO]: Epoch 063 - training loss: 0.3238, validation loss: 0.1399
2024-05-25 00:19:59 [INFO]: Epoch 064 - training loss: 0.3216, validation loss: 0.1390
2024-05-25 00:20:02 [INFO]: Epoch 065 - training loss: 0.3208, validation loss: 0.1381
2024-05-25 00:20:05 [INFO]: Epoch 066 - training loss: 0.3195, validation loss: 0.1370
2024-05-25 00:20:08 [INFO]: Epoch 067 - training loss: 0.3182, validation loss: 0.1364
2024-05-25 00:20:10 [INFO]: Epoch 068 - training loss: 0.3166, validation loss: 0.1351
2024-05-25 00:20:13 [INFO]: Epoch 069 - training loss: 0.3155, validation loss: 0.1340
2024-05-25 00:20:16 [INFO]: Epoch 070 - training loss: 0.3141, validation loss: 0.1337
2024-05-25 00:20:19 [INFO]: Epoch 071 - training loss: 0.3129, validation loss: 0.1325
2024-05-25 00:20:22 [INFO]: Epoch 072 - training loss: 0.3119, validation loss: 0.1318
2024-05-25 00:20:25 [INFO]: Epoch 073 - training loss: 0.3108, validation loss: 0.1310
2024-05-25 00:20:27 [INFO]: Epoch 074 - training loss: 0.3095, validation loss: 0.1298
2024-05-25 00:20:30 [INFO]: Epoch 075 - training loss: 0.3082, validation loss: 0.1294
2024-05-25 00:20:33 [INFO]: Epoch 076 - training loss: 0.3076, validation loss: 0.1284
2024-05-25 00:20:36 [INFO]: Epoch 077 - training loss: 0.3066, validation loss: 0.1276
2024-05-25 00:20:39 [INFO]: Epoch 078 - training loss: 0.3058, validation loss: 0.1270
2024-05-25 00:20:41 [INFO]: Epoch 079 - training loss: 0.3049, validation loss: 0.1261
2024-05-25 00:20:44 [INFO]: Epoch 080 - training loss: 0.3035, validation loss: 0.1254
2024-05-25 00:20:47 [INFO]: Epoch 081 - training loss: 0.3027, validation loss: 0.1247
2024-05-25 00:20:50 [INFO]: Epoch 082 - training loss: 0.3015, validation loss: 0.1242
2024-05-25 00:20:53 [INFO]: Epoch 083 - training loss: 0.3010, validation loss: 0.1234
2024-05-25 00:20:56 [INFO]: Epoch 084 - training loss: 0.2992, validation loss: 0.1228
2024-05-25 00:20:58 [INFO]: Epoch 085 - training loss: 0.2995, validation loss: 0.1220
2024-05-25 00:21:01 [INFO]: Epoch 086 - training loss: 0.2986, validation loss: 0.1215
2024-05-25 00:21:04 [INFO]: Epoch 087 - training loss: 0.2972, validation loss: 0.1208
2024-05-25 00:21:07 [INFO]: Epoch 088 - training loss: 0.2962, validation loss: 0.1201
2024-05-25 00:21:10 [INFO]: Epoch 089 - training loss: 0.2957, validation loss: 0.1195
2024-05-25 00:21:12 [INFO]: Epoch 090 - training loss: 0.2947, validation loss: 0.1190
2024-05-25 00:21:15 [INFO]: Epoch 091 - training loss: 0.2943, validation loss: 0.1184
2024-05-25 00:21:18 [INFO]: Epoch 092 - training loss: 0.2930, validation loss: 0.1177
2024-05-25 00:21:21 [INFO]: Epoch 093 - training loss: 0.2928, validation loss: 0.1169
2024-05-25 00:21:24 [INFO]: Epoch 094 - training loss: 0.2911, validation loss: 0.1166
2024-05-25 00:21:26 [INFO]: Epoch 095 - training loss: 0.2914, validation loss: 0.1159
2024-05-25 00:21:29 [INFO]: Epoch 096 - training loss: 0.2908, validation loss: 0.1154
2024-05-25 00:21:32 [INFO]: Epoch 097 - training loss: 0.2904, validation loss: 0.1150
2024-05-25 00:21:35 [INFO]: Epoch 098 - training loss: 0.2889, validation loss: 0.1142
2024-05-25 00:21:38 [INFO]: Epoch 099 - training loss: 0.2890, validation loss: 0.1138
2024-05-25 00:21:40 [INFO]: Epoch 100 - training loss: 0.2877, validation loss: 0.1133
2024-05-25 00:21:43 [INFO]: Epoch 101 - training loss: 0.2874, validation loss: 0.1129
2024-05-25 00:21:46 [INFO]: Epoch 102 - training loss: 0.2870, validation loss: 0.1123
2024-05-25 00:21:49 [INFO]: Epoch 103 - training loss: 0.2861, validation loss: 0.1116
2024-05-25 00:21:52 [INFO]: Epoch 104 - training loss: 0.2859, validation loss: 0.1111
2024-05-25 00:21:54 [INFO]: Epoch 105 - training loss: 0.2846, validation loss: 0.1106
2024-05-25 00:21:57 [INFO]: Epoch 106 - training loss: 0.2838, validation loss: 0.1101
2024-05-25 00:22:00 [INFO]: Epoch 107 - training loss: 0.2841, validation loss: 0.1097
2024-05-25 00:22:03 [INFO]: Epoch 108 - training loss: 0.2828, validation loss: 0.1091
2024-05-25 00:22:06 [INFO]: Epoch 109 - training loss: 0.2822, validation loss: 0.1086
2024-05-25 00:22:09 [INFO]: Epoch 110 - training loss: 0.2821, validation loss: 0.1082
2024-05-25 00:22:11 [INFO]: Epoch 111 - training loss: 0.2814, validation loss: 0.1077
2024-05-25 00:22:14 [INFO]: Epoch 112 - training loss: 0.2807, validation loss: 0.1074
2024-05-25 00:22:17 [INFO]: Epoch 113 - training loss: 0.2798, validation loss: 0.1069
2024-05-25 00:22:20 [INFO]: Epoch 114 - training loss: 0.2792, validation loss: 0.1065
2024-05-25 00:22:23 [INFO]: Epoch 115 - training loss: 0.2796, validation loss: 0.1060
2024-05-25 00:22:25 [INFO]: Epoch 116 - training loss: 0.2786, validation loss: 0.1058
2024-05-25 00:22:28 [INFO]: Epoch 117 - training loss: 0.2784, validation loss: 0.1051
2024-05-25 00:22:31 [INFO]: Epoch 118 - training loss: 0.2776, validation loss: 0.1046
2024-05-25 00:22:34 [INFO]: Epoch 119 - training loss: 0.2770, validation loss: 0.1044
2024-05-25 00:22:37 [INFO]: Epoch 120 - training loss: 0.2766, validation loss: 0.1040
2024-05-25 00:22:40 [INFO]: Epoch 121 - training loss: 0.2765, validation loss: 0.1035
2024-05-25 00:22:42 [INFO]: Epoch 122 - training loss: 0.2757, validation loss: 0.1033
2024-05-25 00:22:45 [INFO]: Epoch 123 - training loss: 0.2752, validation loss: 0.1028
2024-05-25 00:22:48 [INFO]: Epoch 124 - training loss: 0.2748, validation loss: 0.1026
2024-05-25 00:22:51 [INFO]: Epoch 125 - training loss: 0.2743, validation loss: 0.1021
2024-05-25 00:22:54 [INFO]: Epoch 126 - training loss: 0.2735, validation loss: 0.1017
2024-05-25 00:22:56 [INFO]: Epoch 127 - training loss: 0.2736, validation loss: 0.1013
2024-05-25 00:22:59 [INFO]: Epoch 128 - training loss: 0.2727, validation loss: 0.1009
2024-05-25 00:23:02 [INFO]: Epoch 129 - training loss: 0.2726, validation loss: 0.1008
2024-05-25 00:23:05 [INFO]: Epoch 130 - training loss: 0.2719, validation loss: 0.1003
2024-05-25 00:23:08 [INFO]: Epoch 131 - training loss: 0.2718, validation loss: 0.1000
2024-05-25 00:23:10 [INFO]: Epoch 132 - training loss: 0.2707, validation loss: 0.0997
2024-05-25 00:23:13 [INFO]: Epoch 133 - training loss: 0.2705, validation loss: 0.0995
2024-05-25 00:23:16 [INFO]: Epoch 134 - training loss: 0.2701, validation loss: 0.0990
2024-05-25 00:23:19 [INFO]: Epoch 135 - training loss: 0.2696, validation loss: 0.0989
2024-05-25 00:23:22 [INFO]: Epoch 136 - training loss: 0.2701, validation loss: 0.0982
2024-05-25 00:23:24 [INFO]: Epoch 137 - training loss: 0.2688, validation loss: 0.0980
2024-05-25 00:23:27 [INFO]: Epoch 138 - training loss: 0.2683, validation loss: 0.0978
2024-05-25 00:23:30 [INFO]: Epoch 139 - training loss: 0.2686, validation loss: 0.0974
2024-05-25 00:23:33 [INFO]: Epoch 140 - training loss: 0.2682, validation loss: 0.0972
2024-05-25 00:23:36 [INFO]: Epoch 141 - training loss: 0.2676, validation loss: 0.0969
2024-05-25 00:23:38 [INFO]: Epoch 142 - training loss: 0.2678, validation loss: 0.0965
2024-05-25 00:23:41 [INFO]: Epoch 143 - training loss: 0.2666, validation loss: 0.0962
2024-05-25 00:23:44 [INFO]: Epoch 144 - training loss: 0.2661, validation loss: 0.0958
2024-05-25 00:23:47 [INFO]: Epoch 145 - training loss: 0.2664, validation loss: 0.0956
2024-05-25 00:23:50 [INFO]: Epoch 146 - training loss: 0.2661, validation loss: 0.0953
2024-05-25 00:23:53 [INFO]: Epoch 147 - training loss: 0.2656, validation loss: 0.0950
2024-05-25 00:23:55 [INFO]: Epoch 148 - training loss: 0.2646, validation loss: 0.0948
2024-05-25 00:23:58 [INFO]: Epoch 149 - training loss: 0.2644, validation loss: 0.0946
2024-05-25 00:24:01 [INFO]: Epoch 150 - training loss: 0.2641, validation loss: 0.0944
2024-05-25 00:24:04 [INFO]: Epoch 151 - training loss: 0.2637, validation loss: 0.0940
2024-05-25 00:24:07 [INFO]: Epoch 152 - training loss: 0.2635, validation loss: 0.0938
2024-05-25 00:24:09 [INFO]: Epoch 153 - training loss: 0.2632, validation loss: 0.0936
2024-05-25 00:24:12 [INFO]: Epoch 154 - training loss: 0.2630, validation loss: 0.0932
2024-05-25 00:24:15 [INFO]: Epoch 155 - training loss: 0.2622, validation loss: 0.0930
2024-05-25 00:24:18 [INFO]: Epoch 156 - training loss: 0.2627, validation loss: 0.0927
2024-05-25 00:24:21 [INFO]: Epoch 157 - training loss: 0.2618, validation loss: 0.0924
2024-05-25 00:24:23 [INFO]: Epoch 158 - training loss: 0.2617, validation loss: 0.0921
2024-05-25 00:24:26 [INFO]: Epoch 159 - training loss: 0.2619, validation loss: 0.0919
2024-05-25 00:24:29 [INFO]: Epoch 160 - training loss: 0.2606, validation loss: 0.0916
2024-05-25 00:24:32 [INFO]: Epoch 161 - training loss: 0.2608, validation loss: 0.0914
2024-05-25 00:24:35 [INFO]: Epoch 162 - training loss: 0.2604, validation loss: 0.0912
2024-05-25 00:24:38 [INFO]: Epoch 163 - training loss: 0.2598, validation loss: 0.0911
2024-05-25 00:24:40 [INFO]: Epoch 164 - training loss: 0.2596, validation loss: 0.0906
2024-05-25 00:24:43 [INFO]: Epoch 165 - training loss: 0.2596, validation loss: 0.0906
2024-05-25 00:24:46 [INFO]: Epoch 166 - training loss: 0.2590, validation loss: 0.0902
2024-05-25 00:24:49 [INFO]: Epoch 167 - training loss: 0.2591, validation loss: 0.0900
2024-05-25 00:24:52 [INFO]: Epoch 168 - training loss: 0.2591, validation loss: 0.0899
2024-05-25 00:24:54 [INFO]: Epoch 169 - training loss: 0.2591, validation loss: 0.0898
2024-05-25 00:24:57 [INFO]: Epoch 170 - training loss: 0.2584, validation loss: 0.0895
2024-05-25 00:25:00 [INFO]: Epoch 171 - training loss: 0.2578, validation loss: 0.0892
2024-05-25 00:25:03 [INFO]: Epoch 172 - training loss: 0.2580, validation loss: 0.0890
2024-05-25 00:25:06 [INFO]: Epoch 173 - training loss: 0.2574, validation loss: 0.0888
2024-05-25 00:25:08 [INFO]: Epoch 174 - training loss: 0.2572, validation loss: 0.0887
2024-05-25 00:25:11 [INFO]: Epoch 175 - training loss: 0.2571, validation loss: 0.0884
2024-05-25 00:25:14 [INFO]: Epoch 176 - training loss: 0.2566, validation loss: 0.0883
2024-05-25 00:25:17 [INFO]: Epoch 177 - training loss: 0.2563, validation loss: 0.0882
2024-05-25 00:25:20 [INFO]: Epoch 178 - training loss: 0.2558, validation loss: 0.0878
2024-05-25 00:25:23 [INFO]: Epoch 179 - training loss: 0.2553, validation loss: 0.0876
2024-05-25 00:25:25 [INFO]: Epoch 180 - training loss: 0.2557, validation loss: 0.0875
2024-05-25 00:25:28 [INFO]: Epoch 181 - training loss: 0.2550, validation loss: 0.0873
2024-05-25 00:25:31 [INFO]: Epoch 182 - training loss: 0.2549, validation loss: 0.0871
2024-05-25 00:25:34 [INFO]: Epoch 183 - training loss: 0.2549, validation loss: 0.0869
2024-05-25 00:25:37 [INFO]: Epoch 184 - training loss: 0.2549, validation loss: 0.0867
2024-05-25 00:25:39 [INFO]: Epoch 185 - training loss: 0.2543, validation loss: 0.0867
2024-05-25 00:25:42 [INFO]: Epoch 186 - training loss: 0.2543, validation loss: 0.0863
2024-05-25 00:25:45 [INFO]: Epoch 187 - training loss: 0.2536, validation loss: 0.0860
2024-05-25 00:25:48 [INFO]: Epoch 188 - training loss: 0.2535, validation loss: 0.0860
2024-05-25 00:25:51 [INFO]: Epoch 189 - training loss: 0.2534, validation loss: 0.0858
2024-05-25 00:25:53 [INFO]: Epoch 190 - training loss: 0.2531, validation loss: 0.0857
2024-05-25 00:25:56 [INFO]: Epoch 191 - training loss: 0.2529, validation loss: 0.0856
2024-05-25 00:25:59 [INFO]: Epoch 192 - training loss: 0.2530, validation loss: 0.0853
2024-05-25 00:26:02 [INFO]: Epoch 193 - training loss: 0.2527, validation loss: 0.0852
2024-05-25 00:26:05 [INFO]: Epoch 194 - training loss: 0.2522, validation loss: 0.0852
2024-05-25 00:26:07 [INFO]: Epoch 195 - training loss: 0.2517, validation loss: 0.0848
2024-05-25 00:26:10 [INFO]: Epoch 196 - training loss: 0.2524, validation loss: 0.0847
2024-05-25 00:26:13 [INFO]: Epoch 197 - training loss: 0.2518, validation loss: 0.0845
2024-05-25 00:26:16 [INFO]: Epoch 198 - training loss: 0.2513, validation loss: 0.0843
2024-05-25 00:26:19 [INFO]: Epoch 199 - training loss: 0.2509, validation loss: 0.0841
2024-05-25 00:26:21 [INFO]: Epoch 200 - training loss: 0.2506, validation loss: 0.0840
2024-05-25 00:26:24 [INFO]: Epoch 201 - training loss: 0.2506, validation loss: 0.0840
2024-05-25 00:26:27 [INFO]: Epoch 202 - training loss: 0.2508, validation loss: 0.0838
2024-05-25 00:26:30 [INFO]: Epoch 203 - training loss: 0.2501, validation loss: 0.0836
2024-05-25 00:26:33 [INFO]: Epoch 204 - training loss: 0.2505, validation loss: 0.0836
2024-05-25 00:26:36 [INFO]: Epoch 205 - training loss: 0.2497, validation loss: 0.0833
2024-05-25 00:26:38 [INFO]: Epoch 206 - training loss: 0.2503, validation loss: 0.0832
2024-05-25 00:26:41 [INFO]: Epoch 207 - training loss: 0.2499, validation loss: 0.0830
2024-05-25 00:26:44 [INFO]: Epoch 208 - training loss: 0.2497, validation loss: 0.0829
2024-05-25 00:26:47 [INFO]: Epoch 209 - training loss: 0.2489, validation loss: 0.0827
2024-05-25 00:26:50 [INFO]: Epoch 210 - training loss: 0.2483, validation loss: 0.0827
2024-05-25 00:26:52 [INFO]: Epoch 211 - training loss: 0.2484, validation loss: 0.0825
2024-05-25 00:26:55 [INFO]: Epoch 212 - training loss: 0.2482, validation loss: 0.0824
2024-05-25 00:26:58 [INFO]: Epoch 213 - training loss: 0.2483, validation loss: 0.0823
2024-05-25 00:27:01 [INFO]: Epoch 214 - training loss: 0.2482, validation loss: 0.0821
2024-05-25 00:27:04 [INFO]: Epoch 215 - training loss: 0.2482, validation loss: 0.0819
2024-05-25 00:27:06 [INFO]: Epoch 216 - training loss: 0.2478, validation loss: 0.0817
2024-05-25 00:27:09 [INFO]: Epoch 217 - training loss: 0.2476, validation loss: 0.0818
2024-05-25 00:27:12 [INFO]: Epoch 218 - training loss: 0.2470, validation loss: 0.0815
2024-05-25 00:27:15 [INFO]: Epoch 219 - training loss: 0.2471, validation loss: 0.0813
2024-05-25 00:27:18 [INFO]: Epoch 220 - training loss: 0.2475, validation loss: 0.0813
2024-05-25 00:27:21 [INFO]: Epoch 221 - training loss: 0.2469, validation loss: 0.0810
2024-05-25 00:27:23 [INFO]: Epoch 222 - training loss: 0.2463, validation loss: 0.0810
2024-05-25 00:27:26 [INFO]: Epoch 223 - training loss: 0.2464, validation loss: 0.0809
2024-05-25 00:27:29 [INFO]: Epoch 224 - training loss: 0.2463, validation loss: 0.0809
2024-05-25 00:27:32 [INFO]: Epoch 225 - training loss: 0.2457, validation loss: 0.0806
2024-05-25 00:27:35 [INFO]: Epoch 226 - training loss: 0.2461, validation loss: 0.0806
2024-05-25 00:27:37 [INFO]: Epoch 227 - training loss: 0.2458, validation loss: 0.0804
2024-05-25 00:27:40 [INFO]: Epoch 228 - training loss: 0.2453, validation loss: 0.0802
2024-05-25 00:27:43 [INFO]: Epoch 229 - training loss: 0.2453, validation loss: 0.0804
2024-05-25 00:27:46 [INFO]: Epoch 230 - training loss: 0.2449, validation loss: 0.0801
2024-05-25 00:27:49 [INFO]: Epoch 231 - training loss: 0.2449, validation loss: 0.0799
2024-05-25 00:27:51 [INFO]: Epoch 232 - training loss: 0.2452, validation loss: 0.0799
2024-05-25 00:27:54 [INFO]: Epoch 233 - training loss: 0.2451, validation loss: 0.0798
2024-05-25 00:27:57 [INFO]: Epoch 234 - training loss: 0.2451, validation loss: 0.0796
2024-05-25 00:28:00 [INFO]: Epoch 235 - training loss: 0.2441, validation loss: 0.0794
2024-05-25 00:28:03 [INFO]: Epoch 236 - training loss: 0.2437, validation loss: 0.0798
2024-05-25 00:28:05 [INFO]: Epoch 237 - training loss: 0.2443, validation loss: 0.0794
2024-05-25 00:28:08 [INFO]: Epoch 238 - training loss: 0.2438, validation loss: 0.0793
2024-05-25 00:28:11 [INFO]: Epoch 239 - training loss: 0.2435, validation loss: 0.0793
2024-05-25 00:28:14 [INFO]: Epoch 240 - training loss: 0.2437, validation loss: 0.0793
2024-05-25 00:28:17 [INFO]: Epoch 241 - training loss: 0.2442, validation loss: 0.0790
2024-05-25 00:28:20 [INFO]: Epoch 242 - training loss: 0.2430, validation loss: 0.0790
2024-05-25 00:28:22 [INFO]: Epoch 243 - training loss: 0.2428, validation loss: 0.0788
2024-05-25 00:28:25 [INFO]: Epoch 244 - training loss: 0.2429, validation loss: 0.0787
2024-05-25 00:28:28 [INFO]: Epoch 245 - training loss: 0.2425, validation loss: 0.0787
2024-05-25 00:28:31 [INFO]: Epoch 246 - training loss: 0.2429, validation loss: 0.0786
2024-05-25 00:28:34 [INFO]: Epoch 247 - training loss: 0.2424, validation loss: 0.0786
2024-05-25 00:28:36 [INFO]: Epoch 248 - training loss: 0.2421, validation loss: 0.0782
2024-05-25 00:28:39 [INFO]: Epoch 249 - training loss: 0.2421, validation loss: 0.0783
2024-05-25 00:28:42 [INFO]: Epoch 250 - training loss: 0.2421, validation loss: 0.0782
2024-05-25 00:28:45 [INFO]: Epoch 251 - training loss: 0.2415, validation loss: 0.0782
2024-05-25 00:28:48 [INFO]: Epoch 252 - training loss: 0.2420, validation loss: 0.0781
2024-05-25 00:28:51 [INFO]: Epoch 253 - training loss: 0.2415, validation loss: 0.0780
2024-05-25 00:28:53 [INFO]: Epoch 254 - training loss: 0.2419, validation loss: 0.0780
2024-05-25 00:28:56 [INFO]: Epoch 255 - training loss: 0.2412, validation loss: 0.0778
2024-05-25 00:28:59 [INFO]: Epoch 256 - training loss: 0.2408, validation loss: 0.0777
2024-05-25 00:29:02 [INFO]: Epoch 257 - training loss: 0.2409, validation loss: 0.0776
2024-05-25 00:29:05 [INFO]: Epoch 258 - training loss: 0.2407, validation loss: 0.0775
2024-05-25 00:29:07 [INFO]: Epoch 259 - training loss: 0.2412, validation loss: 0.0775
2024-05-25 00:29:10 [INFO]: Epoch 260 - training loss: 0.2404, validation loss: 0.0773
2024-05-25 00:29:13 [INFO]: Epoch 261 - training loss: 0.2405, validation loss: 0.0773
2024-05-25 00:29:16 [INFO]: Epoch 262 - training loss: 0.2397, validation loss: 0.0773
2024-05-25 00:29:19 [INFO]: Epoch 263 - training loss: 0.2397, validation loss: 0.0772
2024-05-25 00:29:21 [INFO]: Epoch 264 - training loss: 0.2400, validation loss: 0.0771
2024-05-25 00:29:24 [INFO]: Epoch 265 - training loss: 0.2396, validation loss: 0.0772
2024-05-25 00:29:27 [INFO]: Epoch 266 - training loss: 0.2400, validation loss: 0.0768
2024-05-25 00:29:30 [INFO]: Epoch 267 - training loss: 0.2392, validation loss: 0.0768
2024-05-25 00:29:33 [INFO]: Epoch 268 - training loss: 0.2395, validation loss: 0.0768
2024-05-25 00:29:35 [INFO]: Epoch 269 - training loss: 0.2397, validation loss: 0.0768
2024-05-25 00:29:38 [INFO]: Epoch 270 - training loss: 0.2386, validation loss: 0.0767
2024-05-25 00:29:41 [INFO]: Epoch 271 - training loss: 0.2390, validation loss: 0.0765
2024-05-25 00:29:44 [INFO]: Epoch 272 - training loss: 0.2393, validation loss: 0.0765
2024-05-25 00:29:47 [INFO]: Epoch 273 - training loss: 0.2385, validation loss: 0.0765
2024-05-25 00:29:49 [INFO]: Epoch 274 - training loss: 0.2387, validation loss: 0.0763
2024-05-25 00:29:52 [INFO]: Epoch 275 - training loss: 0.2388, validation loss: 0.0765
2024-05-25 00:29:55 [INFO]: Epoch 276 - training loss: 0.2381, validation loss: 0.0763
2024-05-25 00:29:58 [INFO]: Epoch 277 - training loss: 0.2382, validation loss: 0.0762
2024-05-25 00:30:01 [INFO]: Epoch 278 - training loss: 0.2385, validation loss: 0.0762
2024-05-25 00:30:04 [INFO]: Epoch 279 - training loss: 0.2377, validation loss: 0.0761
2024-05-25 00:30:06 [INFO]: Epoch 280 - training loss: 0.2375, validation loss: 0.0760
2024-05-25 00:30:09 [INFO]: Epoch 281 - training loss: 0.2372, validation loss: 0.0760
2024-05-25 00:30:12 [INFO]: Epoch 282 - training loss: 0.2377, validation loss: 0.0758
2024-05-25 00:30:15 [INFO]: Epoch 283 - training loss: 0.2370, validation loss: 0.0759
2024-05-25 00:30:18 [INFO]: Epoch 284 - training loss: 0.2375, validation loss: 0.0757
2024-05-25 00:30:20 [INFO]: Epoch 285 - training loss: 0.2372, validation loss: 0.0757
2024-05-25 00:30:23 [INFO]: Epoch 286 - training loss: 0.2370, validation loss: 0.0757
2024-05-25 00:30:26 [INFO]: Epoch 287 - training loss: 0.2368, validation loss: 0.0757
2024-05-25 00:30:29 [INFO]: Epoch 288 - training loss: 0.2369, validation loss: 0.0757
2024-05-25 00:30:32 [INFO]: Epoch 289 - training loss: 0.2364, validation loss: 0.0756
2024-05-25 00:30:34 [INFO]: Epoch 290 - training loss: 0.2364, validation loss: 0.0755
2024-05-25 00:30:37 [INFO]: Epoch 291 - training loss: 0.2362, validation loss: 0.0754
2024-05-25 00:30:40 [INFO]: Epoch 292 - training loss: 0.2361, validation loss: 0.0753
2024-05-25 00:30:43 [INFO]: Epoch 293 - training loss: 0.2362, validation loss: 0.0751
2024-05-25 00:30:46 [INFO]: Epoch 294 - training loss: 0.2366, validation loss: 0.0753
2024-05-25 00:30:49 [INFO]: Epoch 295 - training loss: 0.2362, validation loss: 0.0752
2024-05-25 00:30:51 [INFO]: Epoch 296 - training loss: 0.2359, validation loss: 0.0751
2024-05-25 00:30:54 [INFO]: Epoch 297 - training loss: 0.2359, validation loss: 0.0752
2024-05-25 00:30:57 [INFO]: Epoch 298 - training loss: 0.2360, validation loss: 0.0750
2024-05-25 00:31:00 [INFO]: Epoch 299 - training loss: 0.2354, validation loss: 0.0750
2024-05-25 00:31:03 [INFO]: Epoch 300 - training loss: 0.2356, validation loss: 0.0750
2024-05-25 00:31:03 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 00:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T001659/BRITS.pypots
2024-05-25 00:31:03 [INFO]: BRITS on Air-Quality: MAE=0.1368, MSE=0.0954
2024-05-25 00:31:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 00:31:03 [INFO]: Using the given device: cuda:0
2024-05-25 00:31:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103
2024-05-25 00:31:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/tensorboard
2024-05-25 00:31:03 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 00:31:08 [INFO]: Epoch 001 - training loss: 1.3888, validation loss: 0.8030
2024-05-25 00:31:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch1_loss0.8029874116182327.pypots
2024-05-25 00:31:12 [INFO]: Epoch 002 - training loss: 1.0395, validation loss: 0.7469
2024-05-25 00:31:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch2_loss0.7468589842319489.pypots
2024-05-25 00:31:16 [INFO]: Epoch 003 - training loss: 0.9651, validation loss: 0.7270
2024-05-25 00:31:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch3_loss0.7269712328910828.pypots
2024-05-25 00:31:20 [INFO]: Epoch 004 - training loss: 0.9429, validation loss: 0.7127
2024-05-25 00:31:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch4_loss0.7127098053693771.pypots
2024-05-25 00:31:23 [INFO]: Epoch 005 - training loss: 0.9242, validation loss: 0.7051
2024-05-25 00:31:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch5_loss0.7050573736429214.pypots
2024-05-25 00:31:27 [INFO]: Epoch 006 - training loss: 0.9215, validation loss: 0.6977
2024-05-25 00:31:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch6_loss0.6976564973592758.pypots
2024-05-25 00:31:31 [INFO]: Epoch 007 - training loss: 0.9244, validation loss: 0.6932
2024-05-25 00:31:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch7_loss0.6932384669780731.pypots
2024-05-25 00:31:35 [INFO]: Epoch 008 - training loss: 0.8955, validation loss: 0.6902
2024-05-25 00:31:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch8_loss0.690186369419098.pypots
2024-05-25 00:31:39 [INFO]: Epoch 009 - training loss: 0.9028, validation loss: 0.6877
2024-05-25 00:31:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch9_loss0.6877003401517868.pypots
2024-05-25 00:31:43 [INFO]: Epoch 010 - training loss: 0.8925, validation loss: 0.6851
2024-05-25 00:31:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch10_loss0.6851129204034805.pypots
2024-05-25 00:31:47 [INFO]: Epoch 011 - training loss: 0.9068, validation loss: 0.6823
2024-05-25 00:31:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch11_loss0.682300579547882.pypots
2024-05-25 00:31:50 [INFO]: Epoch 012 - training loss: 0.8873, validation loss: 0.6810
2024-05-25 00:31:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch12_loss0.6809638410806655.pypots
2024-05-25 00:31:54 [INFO]: Epoch 013 - training loss: 0.9027, validation loss: 0.6807
2024-05-25 00:31:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch13_loss0.6807435363531112.pypots
2024-05-25 00:31:58 [INFO]: Epoch 014 - training loss: 0.8981, validation loss: 0.6796
2024-05-25 00:31:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch14_loss0.6795763820409775.pypots
2024-05-25 00:32:02 [INFO]: Epoch 015 - training loss: 0.8921, validation loss: 0.6782
2024-05-25 00:32:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch15_loss0.6781632423400878.pypots
2024-05-25 00:32:06 [INFO]: Epoch 016 - training loss: 0.8677, validation loss: 0.6785
2024-05-25 00:32:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch16_loss0.6784923106431962.pypots
2024-05-25 00:32:10 [INFO]: Epoch 017 - training loss: 0.8579, validation loss: 0.6769
2024-05-25 00:32:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch17_loss0.676899766921997.pypots
2024-05-25 00:32:14 [INFO]: Epoch 018 - training loss: 0.8607, validation loss: 0.6779
2024-05-25 00:32:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch18_loss0.677942281961441.pypots
2024-05-25 00:32:17 [INFO]: Epoch 019 - training loss: 0.8611, validation loss: 0.6774
2024-05-25 00:32:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch19_loss0.6773505121469497.pypots
2024-05-25 00:32:21 [INFO]: Epoch 020 - training loss: 0.8504, validation loss: 0.6751
2024-05-25 00:32:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch20_loss0.6750645488500595.pypots
2024-05-25 00:32:25 [INFO]: Epoch 021 - training loss: 0.8748, validation loss: 0.6754
2024-05-25 00:32:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch21_loss0.6753760546445846.pypots
2024-05-25 00:32:29 [INFO]: Epoch 022 - training loss: 0.8755, validation loss: 0.6756
2024-05-25 00:32:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch22_loss0.6756162375211716.pypots
2024-05-25 00:32:33 [INFO]: Epoch 023 - training loss: 0.8394, validation loss: 0.6750
2024-05-25 00:32:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch23_loss0.6750150591135025.pypots
2024-05-25 00:32:37 [INFO]: Epoch 024 - training loss: 0.8500, validation loss: 0.6759
2024-05-25 00:32:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch24_loss0.6759036034345627.pypots
2024-05-25 00:32:41 [INFO]: Epoch 025 - training loss: 0.8721, validation loss: 0.6745
2024-05-25 00:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch25_loss0.6745131313800812.pypots
2024-05-25 00:32:44 [INFO]: Epoch 026 - training loss: 0.8506, validation loss: 0.6744
2024-05-25 00:32:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch26_loss0.6744164973497391.pypots
2024-05-25 00:32:48 [INFO]: Epoch 027 - training loss: 0.8624, validation loss: 0.6758
2024-05-25 00:32:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch27_loss0.6757870048284531.pypots
2024-05-25 00:32:52 [INFO]: Epoch 028 - training loss: 0.8527, validation loss: 0.6783
2024-05-25 00:32:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch28_loss0.6783077597618103.pypots
2024-05-25 00:32:56 [INFO]: Epoch 029 - training loss: 0.8352, validation loss: 0.6757
2024-05-25 00:32:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch29_loss0.6756582707166672.pypots
2024-05-25 00:33:00 [INFO]: Epoch 030 - training loss: 0.8291, validation loss: 0.6758
2024-05-25 00:33:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch30_loss0.675775557756424.pypots
2024-05-25 00:33:04 [INFO]: Epoch 031 - training loss: 0.8345, validation loss: 0.6759
2024-05-25 00:33:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch31_loss0.6758606225252152.pypots
2024-05-25 00:33:08 [INFO]: Epoch 032 - training loss: 0.8420, validation loss: 0.6761
2024-05-25 00:33:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch32_loss0.6761250913143158.pypots
2024-05-25 00:33:11 [INFO]: Epoch 033 - training loss: 0.8501, validation loss: 0.6776
2024-05-25 00:33:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch33_loss0.6775859236717224.pypots
2024-05-25 00:33:15 [INFO]: Epoch 034 - training loss: 0.8468, validation loss: 0.6769
2024-05-25 00:33:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch34_loss0.6769431084394455.pypots
2024-05-25 00:33:19 [INFO]: Epoch 035 - training loss: 0.8290, validation loss: 0.6816
2024-05-25 00:33:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch35_loss0.6815640538930893.pypots
2024-05-25 00:33:23 [INFO]: Epoch 036 - training loss: 0.8171, validation loss: 0.6764
2024-05-25 00:33:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN_epoch36_loss0.6764049082994461.pypots
2024-05-25 00:33:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:33:23 [INFO]: Finished training. The best model is from epoch#26.
2024-05-25 00:33:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T003103/MRNN.pypots
2024-05-25 00:33:24 [INFO]: MRNN on Air-Quality: MAE=0.5165, MSE=0.5918
2024-05-25 00:33:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 00:33:24 [INFO]: Using the given device: cpu
2024-05-25 00:33:24 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2148
2024-05-25 00:33:24 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 00:33:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 00:33:24 [INFO]: Median on Air-Quality: MAE=0.6653, MSE=0.9982
2024-05-25 00:33:24 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 00:33:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 00:33:24 [INFO]: Mean on Air-Quality: MAE=0.6953, MSE=0.9349
2024-05-25 00:33:24 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 00:33:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 00:33:24 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 00:33:24 [INFO]: Using the given device: cuda:0
2024-05-25 00:33:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T003324
2024-05-25 00:33:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T003324/tensorboard
2024-05-25 00:33:24 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 00:33:25 [INFO]: Epoch 001 - training loss: 1.0407, validation loss: 0.5213
2024-05-25 00:33:25 [INFO]: Epoch 002 - training loss: 0.7565, validation loss: 0.3901
2024-05-25 00:33:26 [INFO]: Epoch 003 - training loss: 0.6503, validation loss: 0.3117
2024-05-25 00:33:27 [INFO]: Epoch 004 - training loss: 0.5788, validation loss: 0.2667
2024-05-25 00:33:27 [INFO]: Epoch 005 - training loss: 0.5262, validation loss: 0.2458
2024-05-25 00:33:28 [INFO]: Epoch 006 - training loss: 0.4884, validation loss: 0.2287
2024-05-25 00:33:28 [INFO]: Epoch 007 - training loss: 0.4600, validation loss: 0.2185
2024-05-25 00:33:29 [INFO]: Epoch 008 - training loss: 0.4407, validation loss: 0.2087
2024-05-25 00:33:30 [INFO]: Epoch 009 - training loss: 0.4259, validation loss: 0.2029
2024-05-25 00:33:30 [INFO]: Epoch 010 - training loss: 0.4123, validation loss: 0.1971
2024-05-25 00:33:31 [INFO]: Epoch 011 - training loss: 0.4020, validation loss: 0.1905
2024-05-25 00:33:31 [INFO]: Epoch 012 - training loss: 0.3929, validation loss: 0.1870
2024-05-25 00:33:32 [INFO]: Epoch 013 - training loss: 0.3848, validation loss: 0.1820
2024-05-25 00:33:33 [INFO]: Epoch 014 - training loss: 0.3758, validation loss: 0.1795
2024-05-25 00:33:33 [INFO]: Epoch 015 - training loss: 0.3702, validation loss: 0.1760
2024-05-25 00:33:34 [INFO]: Epoch 016 - training loss: 0.3645, validation loss: 0.1736
2024-05-25 00:33:34 [INFO]: Epoch 017 - training loss: 0.3589, validation loss: 0.1718
2024-05-25 00:33:35 [INFO]: Epoch 018 - training loss: 0.3523, validation loss: 0.1665
2024-05-25 00:33:36 [INFO]: Epoch 019 - training loss: 0.3471, validation loss: 0.1655
2024-05-25 00:33:36 [INFO]: Epoch 020 - training loss: 0.3425, validation loss: 0.1622
2024-05-25 00:33:37 [INFO]: Epoch 021 - training loss: 0.3394, validation loss: 0.1601
2024-05-25 00:33:37 [INFO]: Epoch 022 - training loss: 0.3329, validation loss: 0.1571
2024-05-25 00:33:38 [INFO]: Epoch 023 - training loss: 0.3287, validation loss: 0.1556
2024-05-25 00:33:39 [INFO]: Epoch 024 - training loss: 0.3282, validation loss: 0.1532
2024-05-25 00:33:39 [INFO]: Epoch 025 - training loss: 0.3227, validation loss: 0.1544
2024-05-25 00:33:40 [INFO]: Epoch 026 - training loss: 0.3198, validation loss: 0.1501
2024-05-25 00:33:40 [INFO]: Epoch 027 - training loss: 0.3170, validation loss: 0.1503
2024-05-25 00:33:41 [INFO]: Epoch 028 - training loss: 0.3134, validation loss: 0.1483
2024-05-25 00:33:42 [INFO]: Epoch 029 - training loss: 0.3112, validation loss: 0.1458
2024-05-25 00:33:42 [INFO]: Epoch 030 - training loss: 0.3074, validation loss: 0.1444
2024-05-25 00:33:43 [INFO]: Epoch 031 - training loss: 0.3051, validation loss: 0.1428
2024-05-25 00:33:43 [INFO]: Epoch 032 - training loss: 0.3035, validation loss: 0.1412
2024-05-25 00:33:44 [INFO]: Epoch 033 - training loss: 0.3003, validation loss: 0.1392
2024-05-25 00:33:45 [INFO]: Epoch 034 - training loss: 0.3006, validation loss: 0.1389
2024-05-25 00:33:45 [INFO]: Epoch 035 - training loss: 0.2969, validation loss: 0.1376
2024-05-25 00:33:46 [INFO]: Epoch 036 - training loss: 0.2945, validation loss: 0.1370
2024-05-25 00:33:47 [INFO]: Epoch 037 - training loss: 0.2904, validation loss: 0.1360
2024-05-25 00:33:47 [INFO]: Epoch 038 - training loss: 0.2888, validation loss: 0.1330
2024-05-25 00:33:48 [INFO]: Epoch 039 - training loss: 0.2889, validation loss: 0.1321
2024-05-25 00:33:48 [INFO]: Epoch 040 - training loss: 0.2883, validation loss: 0.1305
2024-05-25 00:33:49 [INFO]: Epoch 041 - training loss: 0.2879, validation loss: 0.1314
2024-05-25 00:33:50 [INFO]: Epoch 042 - training loss: 0.2837, validation loss: 0.1291
2024-05-25 00:33:50 [INFO]: Epoch 043 - training loss: 0.2809, validation loss: 0.1275
2024-05-25 00:33:51 [INFO]: Epoch 044 - training loss: 0.2786, validation loss: 0.1269
2024-05-25 00:33:51 [INFO]: Epoch 045 - training loss: 0.2779, validation loss: 0.1251
2024-05-25 00:33:52 [INFO]: Epoch 046 - training loss: 0.2764, validation loss: 0.1252
2024-05-25 00:33:53 [INFO]: Epoch 047 - training loss: 0.2741, validation loss: 0.1231
2024-05-25 00:33:53 [INFO]: Epoch 048 - training loss: 0.2717, validation loss: 0.1224
2024-05-25 00:33:54 [INFO]: Epoch 049 - training loss: 0.2710, validation loss: 0.1217
2024-05-25 00:33:54 [INFO]: Epoch 050 - training loss: 0.2685, validation loss: 0.1212
2024-05-25 00:33:55 [INFO]: Epoch 051 - training loss: 0.2678, validation loss: 0.1197
2024-05-25 00:33:56 [INFO]: Epoch 052 - training loss: 0.2658, validation loss: 0.1181
2024-05-25 00:33:56 [INFO]: Epoch 053 - training loss: 0.2643, validation loss: 0.1194
2024-05-25 00:33:57 [INFO]: Epoch 054 - training loss: 0.2637, validation loss: 0.1181
2024-05-25 00:33:57 [INFO]: Epoch 055 - training loss: 0.2625, validation loss: 0.1163
2024-05-25 00:33:58 [INFO]: Epoch 056 - training loss: 0.2606, validation loss: 0.1159
2024-05-25 00:33:59 [INFO]: Epoch 057 - training loss: 0.2603, validation loss: 0.1149
2024-05-25 00:33:59 [INFO]: Epoch 058 - training loss: 0.2574, validation loss: 0.1150
2024-05-25 00:34:00 [INFO]: Epoch 059 - training loss: 0.2564, validation loss: 0.1147
2024-05-25 00:34:00 [INFO]: Epoch 060 - training loss: 0.2542, validation loss: 0.1140
2024-05-25 00:34:01 [INFO]: Epoch 061 - training loss: 0.2530, validation loss: 0.1132
2024-05-25 00:34:02 [INFO]: Epoch 062 - training loss: 0.2521, validation loss: 0.1122
2024-05-25 00:34:02 [INFO]: Epoch 063 - training loss: 0.2506, validation loss: 0.1127
2024-05-25 00:34:03 [INFO]: Epoch 064 - training loss: 0.2500, validation loss: 0.1112
2024-05-25 00:34:03 [INFO]: Epoch 065 - training loss: 0.2488, validation loss: 0.1105
2024-05-25 00:34:04 [INFO]: Epoch 066 - training loss: 0.2475, validation loss: 0.1114
2024-05-25 00:34:05 [INFO]: Epoch 067 - training loss: 0.2458, validation loss: 0.1097
2024-05-25 00:34:05 [INFO]: Epoch 068 - training loss: 0.2458, validation loss: 0.1108
2024-05-25 00:34:06 [INFO]: Epoch 069 - training loss: 0.2445, validation loss: 0.1103
2024-05-25 00:34:06 [INFO]: Epoch 070 - training loss: 0.2432, validation loss: 0.1098
2024-05-25 00:34:07 [INFO]: Epoch 071 - training loss: 0.2415, validation loss: 0.1091
2024-05-25 00:34:08 [INFO]: Epoch 072 - training loss: 0.2405, validation loss: 0.1089
2024-05-25 00:34:08 [INFO]: Epoch 073 - training loss: 0.2400, validation loss: 0.1079
2024-05-25 00:34:09 [INFO]: Epoch 074 - training loss: 0.2387, validation loss: 0.1080
2024-05-25 00:34:09 [INFO]: Epoch 075 - training loss: 0.2369, validation loss: 0.1079
2024-05-25 00:34:10 [INFO]: Epoch 076 - training loss: 0.2353, validation loss: 0.1080
2024-05-25 00:34:11 [INFO]: Epoch 077 - training loss: 0.2340, validation loss: 0.1068
2024-05-25 00:34:11 [INFO]: Epoch 078 - training loss: 0.2331, validation loss: 0.1067
2024-05-25 00:34:12 [INFO]: Epoch 079 - training loss: 0.2322, validation loss: 0.1063
2024-05-25 00:34:12 [INFO]: Epoch 080 - training loss: 0.2323, validation loss: 0.1064
2024-05-25 00:34:13 [INFO]: Epoch 081 - training loss: 0.2315, validation loss: 0.1063
2024-05-25 00:34:14 [INFO]: Epoch 082 - training loss: 0.2296, validation loss: 0.1060
2024-05-25 00:34:14 [INFO]: Epoch 083 - training loss: 0.2286, validation loss: 0.1052
2024-05-25 00:34:15 [INFO]: Epoch 084 - training loss: 0.2276, validation loss: 0.1063
2024-05-25 00:34:15 [INFO]: Epoch 085 - training loss: 0.2269, validation loss: 0.1040
2024-05-25 00:34:16 [INFO]: Epoch 086 - training loss: 0.2260, validation loss: 0.1044
2024-05-25 00:34:17 [INFO]: Epoch 087 - training loss: 0.2258, validation loss: 0.1055
2024-05-25 00:34:17 [INFO]: Epoch 088 - training loss: 0.2247, validation loss: 0.1031
2024-05-25 00:34:18 [INFO]: Epoch 089 - training loss: 0.2232, validation loss: 0.1040
2024-05-25 00:34:18 [INFO]: Epoch 090 - training loss: 0.2229, validation loss: 0.1051
2024-05-25 00:34:19 [INFO]: Epoch 091 - training loss: 0.2228, validation loss: 0.1041
2024-05-25 00:34:20 [INFO]: Epoch 092 - training loss: 0.2210, validation loss: 0.1035
2024-05-25 00:34:20 [INFO]: Epoch 093 - training loss: 0.2202, validation loss: 0.1030
2024-05-25 00:34:21 [INFO]: Epoch 094 - training loss: 0.2206, validation loss: 0.1030
2024-05-25 00:34:22 [INFO]: Epoch 095 - training loss: 0.2192, validation loss: 0.1029
2024-05-25 00:34:22 [INFO]: Epoch 096 - training loss: 0.2180, validation loss: 0.1023
2024-05-25 00:34:23 [INFO]: Epoch 097 - training loss: 0.2175, validation loss: 0.1024
2024-05-25 00:34:23 [INFO]: Epoch 098 - training loss: 0.2167, validation loss: 0.1018
2024-05-25 00:34:24 [INFO]: Epoch 099 - training loss: 0.2153, validation loss: 0.1020
2024-05-25 00:34:25 [INFO]: Epoch 100 - training loss: 0.2156, validation loss: 0.1019
2024-05-25 00:34:25 [INFO]: Epoch 101 - training loss: 0.2150, validation loss: 0.1035
2024-05-25 00:34:26 [INFO]: Epoch 102 - training loss: 0.2158, validation loss: 0.1012
2024-05-25 00:34:26 [INFO]: Epoch 103 - training loss: 0.2134, validation loss: 0.1036
2024-05-25 00:34:27 [INFO]: Epoch 104 - training loss: 0.2116, validation loss: 0.1012
2024-05-25 00:34:28 [INFO]: Epoch 105 - training loss: 0.2117, validation loss: 0.1008
2024-05-25 00:34:28 [INFO]: Epoch 106 - training loss: 0.2117, validation loss: 0.1008
2024-05-25 00:34:29 [INFO]: Epoch 107 - training loss: 0.2103, validation loss: 0.1007
2024-05-25 00:34:29 [INFO]: Epoch 108 - training loss: 0.2099, validation loss: 0.1008
2024-05-25 00:34:30 [INFO]: Epoch 109 - training loss: 0.2092, validation loss: 0.1006
2024-05-25 00:34:31 [INFO]: Epoch 110 - training loss: 0.2092, validation loss: 0.0985
2024-05-25 00:34:31 [INFO]: Epoch 111 - training loss: 0.2086, validation loss: 0.1004
2024-05-25 00:34:32 [INFO]: Epoch 112 - training loss: 0.2083, validation loss: 0.0992
2024-05-25 00:34:32 [INFO]: Epoch 113 - training loss: 0.2076, validation loss: 0.0985
2024-05-25 00:34:33 [INFO]: Epoch 114 - training loss: 0.2072, validation loss: 0.0989
2024-05-25 00:34:34 [INFO]: Epoch 115 - training loss: 0.2049, validation loss: 0.0989
2024-05-25 00:34:34 [INFO]: Epoch 116 - training loss: 0.2046, validation loss: 0.0991
2024-05-25 00:34:35 [INFO]: Epoch 117 - training loss: 0.2040, validation loss: 0.0991
2024-05-25 00:34:35 [INFO]: Epoch 118 - training loss: 0.2053, validation loss: 0.1002
2024-05-25 00:34:36 [INFO]: Epoch 119 - training loss: 0.2033, validation loss: 0.0977
2024-05-25 00:34:37 [INFO]: Epoch 120 - training loss: 0.2033, validation loss: 0.0989
2024-05-25 00:34:37 [INFO]: Epoch 121 - training loss: 0.2025, validation loss: 0.0975
2024-05-25 00:34:38 [INFO]: Epoch 122 - training loss: 0.2012, validation loss: 0.0985
2024-05-25 00:34:38 [INFO]: Epoch 123 - training loss: 0.2005, validation loss: 0.0986
2024-05-25 00:34:39 [INFO]: Epoch 124 - training loss: 0.2007, validation loss: 0.0979
2024-05-25 00:34:40 [INFO]: Epoch 125 - training loss: 0.2002, validation loss: 0.0982
2024-05-25 00:34:40 [INFO]: Epoch 126 - training loss: 0.1996, validation loss: 0.0968
2024-05-25 00:34:41 [INFO]: Epoch 127 - training loss: 0.1994, validation loss: 0.0967
2024-05-25 00:34:41 [INFO]: Epoch 128 - training loss: 0.1988, validation loss: 0.0987
2024-05-25 00:34:42 [INFO]: Epoch 129 - training loss: 0.1970, validation loss: 0.0974
2024-05-25 00:34:43 [INFO]: Epoch 130 - training loss: 0.1970, validation loss: 0.0971
2024-05-25 00:34:43 [INFO]: Epoch 131 - training loss: 0.1971, validation loss: 0.0971
2024-05-25 00:34:44 [INFO]: Epoch 132 - training loss: 0.1960, validation loss: 0.0967
2024-05-25 00:34:44 [INFO]: Epoch 133 - training loss: 0.1965, validation loss: 0.0977
2024-05-25 00:34:45 [INFO]: Epoch 134 - training loss: 0.1953, validation loss: 0.0980
2024-05-25 00:34:46 [INFO]: Epoch 135 - training loss: 0.1948, validation loss: 0.0967
2024-05-25 00:34:46 [INFO]: Epoch 136 - training loss: 0.1938, validation loss: 0.0968
2024-05-25 00:34:47 [INFO]: Epoch 137 - training loss: 0.1935, validation loss: 0.0963
2024-05-25 00:34:47 [INFO]: Epoch 138 - training loss: 0.1930, validation loss: 0.0970
2024-05-25 00:34:48 [INFO]: Epoch 139 - training loss: 0.1929, validation loss: 0.0967
2024-05-25 00:34:49 [INFO]: Epoch 140 - training loss: 0.1925, validation loss: 0.0966
2024-05-25 00:34:49 [INFO]: Epoch 141 - training loss: 0.1925, validation loss: 0.0960
2024-05-25 00:34:50 [INFO]: Epoch 142 - training loss: 0.1916, validation loss: 0.0956
2024-05-25 00:34:50 [INFO]: Epoch 143 - training loss: 0.1910, validation loss: 0.0954
2024-05-25 00:34:51 [INFO]: Epoch 144 - training loss: 0.1906, validation loss: 0.0959
2024-05-25 00:34:52 [INFO]: Epoch 145 - training loss: 0.1898, validation loss: 0.0956
2024-05-25 00:34:52 [INFO]: Epoch 146 - training loss: 0.1903, validation loss: 0.0955
2024-05-25 00:34:53 [INFO]: Epoch 147 - training loss: 0.1907, validation loss: 0.0956
2024-05-25 00:34:53 [INFO]: Epoch 148 - training loss: 0.1893, validation loss: 0.0957
2024-05-25 00:34:54 [INFO]: Epoch 149 - training loss: 0.1889, validation loss: 0.0948
2024-05-25 00:34:55 [INFO]: Epoch 150 - training loss: 0.1879, validation loss: 0.0965
2024-05-25 00:34:55 [INFO]: Epoch 151 - training loss: 0.1869, validation loss: 0.0954
2024-05-25 00:34:56 [INFO]: Epoch 152 - training loss: 0.1871, validation loss: 0.0946
2024-05-25 00:34:57 [INFO]: Epoch 153 - training loss: 0.1876, validation loss: 0.0946
2024-05-25 00:34:57 [INFO]: Epoch 154 - training loss: 0.1860, validation loss: 0.0948
2024-05-25 00:34:58 [INFO]: Epoch 155 - training loss: 0.1862, validation loss: 0.0954
2024-05-25 00:34:58 [INFO]: Epoch 156 - training loss: 0.1861, validation loss: 0.0940
2024-05-25 00:34:59 [INFO]: Epoch 157 - training loss: 0.1889, validation loss: 0.0944
2024-05-25 00:35:00 [INFO]: Epoch 158 - training loss: 0.1855, validation loss: 0.0939
2024-05-25 00:35:00 [INFO]: Epoch 159 - training loss: 0.1853, validation loss: 0.0943
2024-05-25 00:35:01 [INFO]: Epoch 160 - training loss: 0.1840, validation loss: 0.0950
2024-05-25 00:35:01 [INFO]: Epoch 161 - training loss: 0.1834, validation loss: 0.0936
2024-05-25 00:35:02 [INFO]: Epoch 162 - training loss: 0.1836, validation loss: 0.0954
2024-05-25 00:35:03 [INFO]: Epoch 163 - training loss: 0.1821, validation loss: 0.0948
2024-05-25 00:35:03 [INFO]: Epoch 164 - training loss: 0.1836, validation loss: 0.0944
2024-05-25 00:35:04 [INFO]: Epoch 165 - training loss: 0.1843, validation loss: 0.0930
2024-05-25 00:35:04 [INFO]: Epoch 166 - training loss: 0.1825, validation loss: 0.0936
2024-05-25 00:35:05 [INFO]: Epoch 167 - training loss: 0.1825, validation loss: 0.0943
2024-05-25 00:35:06 [INFO]: Epoch 168 - training loss: 0.1804, validation loss: 0.0932
2024-05-25 00:35:06 [INFO]: Epoch 169 - training loss: 0.1801, validation loss: 0.0934
2024-05-25 00:35:07 [INFO]: Epoch 170 - training loss: 0.1799, validation loss: 0.0935
2024-05-25 00:35:07 [INFO]: Epoch 171 - training loss: 0.1793, validation loss: 0.0928
2024-05-25 00:35:08 [INFO]: Epoch 172 - training loss: 0.1795, validation loss: 0.0933
2024-05-25 00:35:09 [INFO]: Epoch 173 - training loss: 0.1784, validation loss: 0.0930
2024-05-25 00:35:09 [INFO]: Epoch 174 - training loss: 0.1789, validation loss: 0.0928
2024-05-25 00:35:10 [INFO]: Epoch 175 - training loss: 0.1782, validation loss: 0.0924
2024-05-25 00:35:10 [INFO]: Epoch 176 - training loss: 0.1784, validation loss: 0.0926
2024-05-25 00:35:11 [INFO]: Epoch 177 - training loss: 0.1777, validation loss: 0.0921
2024-05-25 00:35:12 [INFO]: Epoch 178 - training loss: 0.1778, validation loss: 0.0931
2024-05-25 00:35:12 [INFO]: Epoch 179 - training loss: 0.1780, validation loss: 0.0932
2024-05-25 00:35:13 [INFO]: Epoch 180 - training loss: 0.1774, validation loss: 0.0919
2024-05-25 00:35:13 [INFO]: Epoch 181 - training loss: 0.1774, validation loss: 0.0928
2024-05-25 00:35:14 [INFO]: Epoch 182 - training loss: 0.1767, validation loss: 0.0932
2024-05-25 00:35:15 [INFO]: Epoch 183 - training loss: 0.1761, validation loss: 0.0915
2024-05-25 00:35:15 [INFO]: Epoch 184 - training loss: 0.1756, validation loss: 0.0920
2024-05-25 00:35:16 [INFO]: Epoch 185 - training loss: 0.1744, validation loss: 0.0919
2024-05-25 00:35:16 [INFO]: Epoch 186 - training loss: 0.1742, validation loss: 0.0930
2024-05-25 00:35:17 [INFO]: Epoch 187 - training loss: 0.1744, validation loss: 0.0915
2024-05-25 00:35:18 [INFO]: Epoch 188 - training loss: 0.1741, validation loss: 0.0921
2024-05-25 00:35:18 [INFO]: Epoch 189 - training loss: 0.1736, validation loss: 0.0935
2024-05-25 00:35:19 [INFO]: Epoch 190 - training loss: 0.1732, validation loss: 0.0926
2024-05-25 00:35:19 [INFO]: Epoch 191 - training loss: 0.1717, validation loss: 0.0921
2024-05-25 00:35:20 [INFO]: Epoch 192 - training loss: 0.1725, validation loss: 0.0922
2024-05-25 00:35:21 [INFO]: Epoch 193 - training loss: 0.1718, validation loss: 0.0927
2024-05-25 00:35:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:35:21 [INFO]: Finished training. The best model is from epoch#183.
2024-05-25 00:35:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T003324/SAITS.pypots
2024-05-25 00:35:21 [INFO]: SAITS on Air-Quality: MAE=0.1488, MSE=0.0997
2024-05-25 00:35:21 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 00:35:21 [INFO]: Using the given device: cuda:0
2024-05-25 00:35:21 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T003521
2024-05-25 00:35:21 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T003521/tensorboard
2024-05-25 00:35:21 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 00:35:21 [INFO]: Epoch 001 - training loss: 0.8967, validation loss: 0.4672
2024-05-25 00:35:21 [INFO]: Epoch 002 - training loss: 0.5585, validation loss: 0.3313
2024-05-25 00:35:22 [INFO]: Epoch 003 - training loss: 0.4615, validation loss: 0.2687
2024-05-25 00:35:22 [INFO]: Epoch 004 - training loss: 0.4174, validation loss: 0.2436
2024-05-25 00:35:22 [INFO]: Epoch 005 - training loss: 0.3861, validation loss: 0.2282
2024-05-25 00:35:22 [INFO]: Epoch 006 - training loss: 0.3625, validation loss: 0.2197
2024-05-25 00:35:23 [INFO]: Epoch 007 - training loss: 0.3482, validation loss: 0.2087
2024-05-25 00:35:23 [INFO]: Epoch 008 - training loss: 0.3359, validation loss: 0.2017
2024-05-25 00:35:23 [INFO]: Epoch 009 - training loss: 0.3251, validation loss: 0.1953
2024-05-25 00:35:23 [INFO]: Epoch 010 - training loss: 0.3175, validation loss: 0.1915
2024-05-25 00:35:24 [INFO]: Epoch 011 - training loss: 0.3082, validation loss: 0.1844
2024-05-25 00:35:24 [INFO]: Epoch 012 - training loss: 0.3018, validation loss: 0.1808
2024-05-25 00:35:24 [INFO]: Epoch 013 - training loss: 0.2962, validation loss: 0.1786
2024-05-25 00:35:24 [INFO]: Epoch 014 - training loss: 0.2933, validation loss: 0.1746
2024-05-25 00:35:25 [INFO]: Epoch 015 - training loss: 0.2856, validation loss: 0.1702
2024-05-25 00:35:25 [INFO]: Epoch 016 - training loss: 0.2810, validation loss: 0.1657
2024-05-25 00:35:25 [INFO]: Epoch 017 - training loss: 0.2770, validation loss: 0.1656
2024-05-25 00:35:25 [INFO]: Epoch 018 - training loss: 0.2733, validation loss: 0.1607
2024-05-25 00:35:26 [INFO]: Epoch 019 - training loss: 0.2720, validation loss: 0.1611
2024-05-25 00:35:26 [INFO]: Epoch 020 - training loss: 0.2679, validation loss: 0.1581
2024-05-25 00:35:26 [INFO]: Epoch 021 - training loss: 0.2634, validation loss: 0.1569
2024-05-25 00:35:26 [INFO]: Epoch 022 - training loss: 0.2641, validation loss: 0.1550
2024-05-25 00:35:27 [INFO]: Epoch 023 - training loss: 0.2594, validation loss: 0.1537
2024-05-25 00:35:27 [INFO]: Epoch 024 - training loss: 0.2545, validation loss: 0.1517
2024-05-25 00:35:27 [INFO]: Epoch 025 - training loss: 0.2532, validation loss: 0.1509
2024-05-25 00:35:27 [INFO]: Epoch 026 - training loss: 0.2482, validation loss: 0.1508
2024-05-25 00:35:28 [INFO]: Epoch 027 - training loss: 0.2469, validation loss: 0.1483
2024-05-25 00:35:28 [INFO]: Epoch 028 - training loss: 0.2480, validation loss: 0.1461
2024-05-25 00:35:28 [INFO]: Epoch 029 - training loss: 0.2434, validation loss: 0.1489
2024-05-25 00:35:28 [INFO]: Epoch 030 - training loss: 0.2428, validation loss: 0.1444
2024-05-25 00:35:29 [INFO]: Epoch 031 - training loss: 0.2410, validation loss: 0.1443
2024-05-25 00:35:29 [INFO]: Epoch 032 - training loss: 0.2347, validation loss: 0.1443
2024-05-25 00:35:29 [INFO]: Epoch 033 - training loss: 0.2335, validation loss: 0.1428
2024-05-25 00:35:29 [INFO]: Epoch 034 - training loss: 0.2318, validation loss: 0.1424
2024-05-25 00:35:30 [INFO]: Epoch 035 - training loss: 0.2315, validation loss: 0.1423
2024-05-25 00:35:30 [INFO]: Epoch 036 - training loss: 0.2303, validation loss: 0.1428
2024-05-25 00:35:30 [INFO]: Epoch 037 - training loss: 0.2274, validation loss: 0.1396
2024-05-25 00:35:30 [INFO]: Epoch 038 - training loss: 0.2262, validation loss: 0.1382
2024-05-25 00:35:31 [INFO]: Epoch 039 - training loss: 0.2228, validation loss: 0.1381
2024-05-25 00:35:31 [INFO]: Epoch 040 - training loss: 0.2222, validation loss: 0.1394
2024-05-25 00:35:31 [INFO]: Epoch 041 - training loss: 0.2215, validation loss: 0.1379
2024-05-25 00:35:32 [INFO]: Epoch 042 - training loss: 0.2210, validation loss: 0.1359
2024-05-25 00:35:32 [INFO]: Epoch 043 - training loss: 0.2214, validation loss: 0.1363
2024-05-25 00:35:32 [INFO]: Epoch 044 - training loss: 0.2163, validation loss: 0.1381
2024-05-25 00:35:32 [INFO]: Epoch 045 - training loss: 0.2154, validation loss: 0.1343
2024-05-25 00:35:33 [INFO]: Epoch 046 - training loss: 0.2136, validation loss: 0.1346
2024-05-25 00:35:33 [INFO]: Epoch 047 - training loss: 0.2133, validation loss: 0.1352
2024-05-25 00:35:33 [INFO]: Epoch 048 - training loss: 0.2123, validation loss: 0.1334
2024-05-25 00:35:33 [INFO]: Epoch 049 - training loss: 0.2099, validation loss: 0.1322
2024-05-25 00:35:34 [INFO]: Epoch 050 - training loss: 0.2087, validation loss: 0.1330
2024-05-25 00:35:34 [INFO]: Epoch 051 - training loss: 0.2075, validation loss: 0.1332
2024-05-25 00:35:34 [INFO]: Epoch 052 - training loss: 0.2086, validation loss: 0.1321
2024-05-25 00:35:34 [INFO]: Epoch 053 - training loss: 0.2074, validation loss: 0.1312
2024-05-25 00:35:35 [INFO]: Epoch 054 - training loss: 0.2039, validation loss: 0.1303
2024-05-25 00:35:35 [INFO]: Epoch 055 - training loss: 0.2031, validation loss: 0.1303
2024-05-25 00:35:35 [INFO]: Epoch 056 - training loss: 0.2018, validation loss: 0.1290
2024-05-25 00:35:35 [INFO]: Epoch 057 - training loss: 0.2021, validation loss: 0.1272
2024-05-25 00:35:36 [INFO]: Epoch 058 - training loss: 0.2025, validation loss: 0.1278
2024-05-25 00:35:36 [INFO]: Epoch 059 - training loss: 0.1984, validation loss: 0.1301
2024-05-25 00:35:36 [INFO]: Epoch 060 - training loss: 0.1968, validation loss: 0.1284
2024-05-25 00:35:36 [INFO]: Epoch 061 - training loss: 0.1936, validation loss: 0.1293
2024-05-25 00:35:37 [INFO]: Epoch 062 - training loss: 0.1928, validation loss: 0.1269
2024-05-25 00:35:37 [INFO]: Epoch 063 - training loss: 0.1928, validation loss: 0.1274
2024-05-25 00:35:37 [INFO]: Epoch 064 - training loss: 0.1929, validation loss: 0.1294
2024-05-25 00:35:37 [INFO]: Epoch 065 - training loss: 0.1933, validation loss: 0.1237
2024-05-25 00:35:38 [INFO]: Epoch 066 - training loss: 0.1964, validation loss: 0.1254
2024-05-25 00:35:38 [INFO]: Epoch 067 - training loss: 0.1930, validation loss: 0.1263
2024-05-25 00:35:38 [INFO]: Epoch 068 - training loss: 0.1902, validation loss: 0.1271
2024-05-25 00:35:38 [INFO]: Epoch 069 - training loss: 0.1885, validation loss: 0.1269
2024-05-25 00:35:39 [INFO]: Epoch 070 - training loss: 0.1867, validation loss: 0.1249
2024-05-25 00:35:39 [INFO]: Epoch 071 - training loss: 0.1873, validation loss: 0.1254
2024-05-25 00:35:39 [INFO]: Epoch 072 - training loss: 0.1850, validation loss: 0.1239
2024-05-25 00:35:39 [INFO]: Epoch 073 - training loss: 0.1850, validation loss: 0.1257
2024-05-25 00:35:40 [INFO]: Epoch 074 - training loss: 0.1857, validation loss: 0.1234
2024-05-25 00:35:40 [INFO]: Epoch 075 - training loss: 0.1823, validation loss: 0.1233
2024-05-25 00:35:40 [INFO]: Epoch 076 - training loss: 0.1805, validation loss: 0.1218
2024-05-25 00:35:40 [INFO]: Epoch 077 - training loss: 0.1804, validation loss: 0.1235
2024-05-25 00:35:41 [INFO]: Epoch 078 - training loss: 0.1817, validation loss: 0.1219
2024-05-25 00:35:41 [INFO]: Epoch 079 - training loss: 0.1783, validation loss: 0.1230
2024-05-25 00:35:41 [INFO]: Epoch 080 - training loss: 0.1786, validation loss: 0.1220
2024-05-25 00:35:41 [INFO]: Epoch 081 - training loss: 0.1769, validation loss: 0.1202
2024-05-25 00:35:42 [INFO]: Epoch 082 - training loss: 0.1749, validation loss: 0.1216
2024-05-25 00:35:42 [INFO]: Epoch 083 - training loss: 0.1757, validation loss: 0.1215
2024-05-25 00:35:42 [INFO]: Epoch 084 - training loss: 0.1752, validation loss: 0.1205
2024-05-25 00:35:42 [INFO]: Epoch 085 - training loss: 0.1764, validation loss: 0.1207
2024-05-25 00:35:43 [INFO]: Epoch 086 - training loss: 0.1736, validation loss: 0.1206
2024-05-25 00:35:43 [INFO]: Epoch 087 - training loss: 0.1733, validation loss: 0.1196
2024-05-25 00:35:43 [INFO]: Epoch 088 - training loss: 0.1741, validation loss: 0.1195
2024-05-25 00:35:43 [INFO]: Epoch 089 - training loss: 0.1705, validation loss: 0.1199
2024-05-25 00:35:44 [INFO]: Epoch 090 - training loss: 0.1691, validation loss: 0.1203
2024-05-25 00:35:44 [INFO]: Epoch 091 - training loss: 0.1687, validation loss: 0.1203
2024-05-25 00:35:44 [INFO]: Epoch 092 - training loss: 0.1671, validation loss: 0.1198
2024-05-25 00:35:44 [INFO]: Epoch 093 - training loss: 0.1668, validation loss: 0.1181
2024-05-25 00:35:45 [INFO]: Epoch 094 - training loss: 0.1665, validation loss: 0.1191
2024-05-25 00:35:45 [INFO]: Epoch 095 - training loss: 0.1665, validation loss: 0.1180
2024-05-25 00:35:45 [INFO]: Epoch 096 - training loss: 0.1673, validation loss: 0.1189
2024-05-25 00:35:45 [INFO]: Epoch 097 - training loss: 0.1661, validation loss: 0.1190
2024-05-25 00:35:46 [INFO]: Epoch 098 - training loss: 0.1658, validation loss: 0.1189
2024-05-25 00:35:46 [INFO]: Epoch 099 - training loss: 0.1650, validation loss: 0.1182
2024-05-25 00:35:46 [INFO]: Epoch 100 - training loss: 0.1628, validation loss: 0.1179
2024-05-25 00:35:46 [INFO]: Epoch 101 - training loss: 0.1626, validation loss: 0.1169
2024-05-25 00:35:47 [INFO]: Epoch 102 - training loss: 0.1627, validation loss: 0.1176
2024-05-25 00:35:47 [INFO]: Epoch 103 - training loss: 0.1632, validation loss: 0.1192
2024-05-25 00:35:47 [INFO]: Epoch 104 - training loss: 0.1609, validation loss: 0.1178
2024-05-25 00:35:47 [INFO]: Epoch 105 - training loss: 0.1592, validation loss: 0.1177
2024-05-25 00:35:48 [INFO]: Epoch 106 - training loss: 0.1596, validation loss: 0.1163
2024-05-25 00:35:48 [INFO]: Epoch 107 - training loss: 0.1597, validation loss: 0.1157
2024-05-25 00:35:48 [INFO]: Epoch 108 - training loss: 0.1588, validation loss: 0.1165
2024-05-25 00:35:48 [INFO]: Epoch 109 - training loss: 0.1583, validation loss: 0.1160
2024-05-25 00:35:49 [INFO]: Epoch 110 - training loss: 0.1596, validation loss: 0.1160
2024-05-25 00:35:49 [INFO]: Epoch 111 - training loss: 0.1587, validation loss: 0.1157
2024-05-25 00:35:49 [INFO]: Epoch 112 - training loss: 0.1588, validation loss: 0.1149
2024-05-25 00:35:49 [INFO]: Epoch 113 - training loss: 0.1565, validation loss: 0.1167
2024-05-25 00:35:50 [INFO]: Epoch 114 - training loss: 0.1568, validation loss: 0.1163
2024-05-25 00:35:50 [INFO]: Epoch 115 - training loss: 0.1586, validation loss: 0.1173
2024-05-25 00:35:50 [INFO]: Epoch 116 - training loss: 0.1567, validation loss: 0.1172
2024-05-25 00:35:50 [INFO]: Epoch 117 - training loss: 0.1571, validation loss: 0.1151
2024-05-25 00:35:51 [INFO]: Epoch 118 - training loss: 0.1564, validation loss: 0.1170
2024-05-25 00:35:51 [INFO]: Epoch 119 - training loss: 0.1534, validation loss: 0.1145
2024-05-25 00:35:51 [INFO]: Epoch 120 - training loss: 0.1532, validation loss: 0.1163
2024-05-25 00:35:51 [INFO]: Epoch 121 - training loss: 0.1524, validation loss: 0.1153
2024-05-25 00:35:52 [INFO]: Epoch 122 - training loss: 0.1525, validation loss: 0.1133
2024-05-25 00:35:52 [INFO]: Epoch 123 - training loss: 0.1535, validation loss: 0.1132
2024-05-25 00:35:52 [INFO]: Epoch 124 - training loss: 0.1516, validation loss: 0.1155
2024-05-25 00:35:52 [INFO]: Epoch 125 - training loss: 0.1502, validation loss: 0.1151
2024-05-25 00:35:53 [INFO]: Epoch 126 - training loss: 0.1484, validation loss: 0.1151
2024-05-25 00:35:53 [INFO]: Epoch 127 - training loss: 0.1487, validation loss: 0.1152
2024-05-25 00:35:53 [INFO]: Epoch 128 - training loss: 0.1501, validation loss: 0.1147
2024-05-25 00:35:53 [INFO]: Epoch 129 - training loss: 0.1499, validation loss: 0.1163
2024-05-25 00:35:54 [INFO]: Epoch 130 - training loss: 0.1513, validation loss: 0.1133
2024-05-25 00:35:54 [INFO]: Epoch 131 - training loss: 0.1490, validation loss: 0.1158
2024-05-25 00:35:54 [INFO]: Epoch 132 - training loss: 0.1474, validation loss: 0.1127
2024-05-25 00:35:54 [INFO]: Epoch 133 - training loss: 0.1469, validation loss: 0.1158
2024-05-25 00:35:55 [INFO]: Epoch 134 - training loss: 0.1469, validation loss: 0.1139
2024-05-25 00:35:55 [INFO]: Epoch 135 - training loss: 0.1443, validation loss: 0.1150
2024-05-25 00:35:55 [INFO]: Epoch 136 - training loss: 0.1448, validation loss: 0.1128
2024-05-25 00:35:55 [INFO]: Epoch 137 - training loss: 0.1445, validation loss: 0.1138
2024-05-25 00:35:56 [INFO]: Epoch 138 - training loss: 0.1427, validation loss: 0.1129
2024-05-25 00:35:56 [INFO]: Epoch 139 - training loss: 0.1437, validation loss: 0.1140
2024-05-25 00:35:56 [INFO]: Epoch 140 - training loss: 0.1429, validation loss: 0.1122
2024-05-25 00:35:56 [INFO]: Epoch 141 - training loss: 0.1421, validation loss: 0.1153
2024-05-25 00:35:57 [INFO]: Epoch 142 - training loss: 0.1442, validation loss: 0.1124
2024-05-25 00:35:57 [INFO]: Epoch 143 - training loss: 0.1443, validation loss: 0.1129
2024-05-25 00:35:57 [INFO]: Epoch 144 - training loss: 0.1436, validation loss: 0.1141
2024-05-25 00:35:57 [INFO]: Epoch 145 - training loss: 0.1438, validation loss: 0.1130
2024-05-25 00:35:58 [INFO]: Epoch 146 - training loss: 0.1424, validation loss: 0.1146
2024-05-25 00:35:58 [INFO]: Epoch 147 - training loss: 0.1428, validation loss: 0.1116
2024-05-25 00:35:58 [INFO]: Epoch 148 - training loss: 0.1450, validation loss: 0.1137
2024-05-25 00:35:58 [INFO]: Epoch 149 - training loss: 0.1412, validation loss: 0.1141
2024-05-25 00:35:59 [INFO]: Epoch 150 - training loss: 0.1399, validation loss: 0.1134
2024-05-25 00:35:59 [INFO]: Epoch 151 - training loss: 0.1402, validation loss: 0.1174
2024-05-25 00:35:59 [INFO]: Epoch 152 - training loss: 0.1483, validation loss: 0.1163
2024-05-25 00:35:59 [INFO]: Epoch 153 - training loss: 0.1422, validation loss: 0.1145
2024-05-25 00:36:00 [INFO]: Epoch 154 - training loss: 0.1387, validation loss: 0.1129
2024-05-25 00:36:00 [INFO]: Epoch 155 - training loss: 0.1384, validation loss: 0.1126
2024-05-25 00:36:00 [INFO]: Epoch 156 - training loss: 0.1363, validation loss: 0.1138
2024-05-25 00:36:00 [INFO]: Epoch 157 - training loss: 0.1367, validation loss: 0.1133
2024-05-25 00:36:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:36:00 [INFO]: Finished training. The best model is from epoch#147.
2024-05-25 00:36:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T003521/Transformer.pypots
2024-05-25 00:36:00 [INFO]: Transformer on Air-Quality: MAE=0.1626, MSE=0.1146
2024-05-25 00:36:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 00:36:00 [INFO]: Using the given device: cuda:0
2024-05-25 00:36:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T003600
2024-05-25 00:36:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T003600/tensorboard
2024-05-25 00:36:01 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 00:36:01 [INFO]: Epoch 001 - training loss: 0.3014, validation loss: 0.2980
2024-05-25 00:36:02 [INFO]: Epoch 002 - training loss: 0.2396, validation loss: 0.2271
2024-05-25 00:36:02 [INFO]: Epoch 003 - training loss: 0.2113, validation loss: 0.2093
2024-05-25 00:36:03 [INFO]: Epoch 004 - training loss: 0.1659, validation loss: 0.1993
2024-05-25 00:36:03 [INFO]: Epoch 005 - training loss: 0.1460, validation loss: 0.1898
2024-05-25 00:36:04 [INFO]: Epoch 006 - training loss: 0.1332, validation loss: 0.1994
2024-05-25 00:36:04 [INFO]: Epoch 007 - training loss: 0.1234, validation loss: 0.1889
2024-05-25 00:36:05 [INFO]: Epoch 008 - training loss: 0.1157, validation loss: 0.2005
2024-05-25 00:36:05 [INFO]: Epoch 009 - training loss: 0.1085, validation loss: 0.2144
2024-05-25 00:36:05 [INFO]: Epoch 010 - training loss: 0.1047, validation loss: 0.2170
2024-05-25 00:36:06 [INFO]: Epoch 011 - training loss: 0.1068, validation loss: 0.1881
2024-05-25 00:36:06 [INFO]: Epoch 012 - training loss: 0.1177, validation loss: 0.1899
2024-05-25 00:36:07 [INFO]: Epoch 013 - training loss: 0.1020, validation loss: 0.2035
2024-05-25 00:36:07 [INFO]: Epoch 014 - training loss: 0.0949, validation loss: 0.1852
2024-05-25 00:36:08 [INFO]: Epoch 015 - training loss: 0.0908, validation loss: 0.1753
2024-05-25 00:36:08 [INFO]: Epoch 016 - training loss: 0.0910, validation loss: 0.1801
2024-05-25 00:36:09 [INFO]: Epoch 017 - training loss: 0.0845, validation loss: 0.1891
2024-05-25 00:36:09 [INFO]: Epoch 018 - training loss: 0.0871, validation loss: 0.1740
2024-05-25 00:36:10 [INFO]: Epoch 019 - training loss: 0.0840, validation loss: 0.1745
2024-05-25 00:36:10 [INFO]: Epoch 020 - training loss: 0.0759, validation loss: 0.1692
2024-05-25 00:36:10 [INFO]: Epoch 021 - training loss: 0.0753, validation loss: 0.1697
2024-05-25 00:36:11 [INFO]: Epoch 022 - training loss: 0.0733, validation loss: 0.1717
2024-05-25 00:36:11 [INFO]: Epoch 023 - training loss: 0.0682, validation loss: 0.1646
2024-05-25 00:36:12 [INFO]: Epoch 024 - training loss: 0.0643, validation loss: 0.1629
2024-05-25 00:36:12 [INFO]: Epoch 025 - training loss: 0.0612, validation loss: 0.1617
2024-05-25 00:36:13 [INFO]: Epoch 026 - training loss: 0.0597, validation loss: 0.1636
2024-05-25 00:36:13 [INFO]: Epoch 027 - training loss: 0.0582, validation loss: 0.1612
2024-05-25 00:36:14 [INFO]: Epoch 028 - training loss: 0.0592, validation loss: 0.1581
2024-05-25 00:36:14 [INFO]: Epoch 029 - training loss: 0.0577, validation loss: 0.1548
2024-05-25 00:36:15 [INFO]: Epoch 030 - training loss: 0.0559, validation loss: 0.1544
2024-05-25 00:36:15 [INFO]: Epoch 031 - training loss: 0.0558, validation loss: 0.1535
2024-05-25 00:36:15 [INFO]: Epoch 032 - training loss: 0.0587, validation loss: 0.1513
2024-05-25 00:36:16 [INFO]: Epoch 033 - training loss: 0.0591, validation loss: 0.1571
2024-05-25 00:36:16 [INFO]: Epoch 034 - training loss: 0.0590, validation loss: 0.1559
2024-05-25 00:36:17 [INFO]: Epoch 035 - training loss: 0.0607, validation loss: 0.1436
2024-05-25 00:36:17 [INFO]: Epoch 036 - training loss: 0.0551, validation loss: 0.1540
2024-05-25 00:36:18 [INFO]: Epoch 037 - training loss: 0.0527, validation loss: 0.1394
2024-05-25 00:36:18 [INFO]: Epoch 038 - training loss: 0.0544, validation loss: 0.1537
2024-05-25 00:36:19 [INFO]: Epoch 039 - training loss: 0.0580, validation loss: 0.1416
2024-05-25 00:36:19 [INFO]: Epoch 040 - training loss: 0.0538, validation loss: 0.1435
2024-05-25 00:36:20 [INFO]: Epoch 041 - training loss: 0.0555, validation loss: 0.1448
2024-05-25 00:36:20 [INFO]: Epoch 042 - training loss: 0.0502, validation loss: 0.1430
2024-05-25 00:36:20 [INFO]: Epoch 043 - training loss: 0.0490, validation loss: 0.1517
2024-05-25 00:36:21 [INFO]: Epoch 044 - training loss: 0.0491, validation loss: 0.1433
2024-05-25 00:36:21 [INFO]: Epoch 045 - training loss: 0.0449, validation loss: 0.1406
2024-05-25 00:36:22 [INFO]: Epoch 046 - training loss: 0.0453, validation loss: 0.1438
2024-05-25 00:36:22 [INFO]: Epoch 047 - training loss: 0.0413, validation loss: 0.1420
2024-05-25 00:36:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:36:22 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 00:36:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T003600/TimesNet.pypots
2024-05-25 00:36:23 [INFO]: TimesNet on Air-Quality: MAE=0.1663, MSE=0.1493
2024-05-25 00:36:23 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 00:36:23 [INFO]: Using the given device: cuda:0
2024-05-25 00:36:23 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623
2024-05-25 00:36:23 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/tensorboard
2024-05-25 00:36:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 00:36:39 [INFO]: Epoch 001 - training loss: 0.5242, validation loss: 0.3596
2024-05-25 00:36:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch1_loss0.35962619483470915.pypots
2024-05-25 00:36:56 [INFO]: Epoch 002 - training loss: 0.3195, validation loss: 0.2754
2024-05-25 00:36:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch2_loss0.2753752410411835.pypots
2024-05-25 00:37:13 [INFO]: Epoch 003 - training loss: 0.2476, validation loss: 0.2405
2024-05-25 00:37:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch3_loss0.24049231112003328.pypots
2024-05-25 00:37:29 [INFO]: Epoch 004 - training loss: 0.2376, validation loss: 0.2165
2024-05-25 00:37:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch4_loss0.21645023673772812.pypots
2024-05-25 00:37:46 [INFO]: Epoch 005 - training loss: 0.2048, validation loss: 0.1974
2024-05-25 00:37:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch5_loss0.19742434322834015.pypots
2024-05-25 00:38:02 [INFO]: Epoch 006 - training loss: 0.1984, validation loss: 0.1796
2024-05-25 00:38:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch6_loss0.1795729234814644.pypots
2024-05-25 00:38:19 [INFO]: Epoch 007 - training loss: 0.1852, validation loss: 0.1712
2024-05-25 00:38:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch7_loss0.17120506316423417.pypots
2024-05-25 00:38:36 [INFO]: Epoch 008 - training loss: 0.1632, validation loss: 0.1615
2024-05-25 00:38:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch8_loss0.16148737967014312.pypots
2024-05-25 00:38:52 [INFO]: Epoch 009 - training loss: 0.1669, validation loss: 0.1529
2024-05-25 00:38:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch9_loss0.15290464758872985.pypots
2024-05-25 00:39:09 [INFO]: Epoch 010 - training loss: 0.1634, validation loss: 0.1625
2024-05-25 00:39:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch10_loss0.16250566840171815.pypots
2024-05-25 00:39:26 [INFO]: Epoch 011 - training loss: 0.1649, validation loss: 0.1497
2024-05-25 00:39:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch11_loss0.14971142262220383.pypots
2024-05-25 00:39:42 [INFO]: Epoch 012 - training loss: 0.1564, validation loss: 0.1559
2024-05-25 00:39:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch12_loss0.15589872151613235.pypots
2024-05-25 00:39:59 [INFO]: Epoch 013 - training loss: 0.1583, validation loss: 0.1481
2024-05-25 00:39:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch13_loss0.14810795933008195.pypots
2024-05-25 00:40:16 [INFO]: Epoch 014 - training loss: 0.1500, validation loss: 0.1518
2024-05-25 00:40:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch14_loss0.15177160501480103.pypots
2024-05-25 00:40:32 [INFO]: Epoch 015 - training loss: 0.1626, validation loss: 0.1445
2024-05-25 00:40:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch15_loss0.14449433982372284.pypots
2024-05-25 00:40:49 [INFO]: Epoch 016 - training loss: 0.1536, validation loss: 0.1406
2024-05-25 00:40:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch16_loss0.14061998054385186.pypots
2024-05-25 00:41:05 [INFO]: Epoch 017 - training loss: 0.1529, validation loss: 0.1469
2024-05-25 00:41:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch17_loss0.14687034785747527.pypots
2024-05-25 00:41:22 [INFO]: Epoch 018 - training loss: 0.1542, validation loss: 0.1380
2024-05-25 00:41:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch18_loss0.1380227081477642.pypots
2024-05-25 00:41:39 [INFO]: Epoch 019 - training loss: 0.1502, validation loss: 0.1382
2024-05-25 00:41:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch19_loss0.13823626190423965.pypots
2024-05-25 00:41:55 [INFO]: Epoch 020 - training loss: 0.1352, validation loss: 0.1396
2024-05-25 00:41:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch20_loss0.13960022553801538.pypots
2024-05-25 00:42:12 [INFO]: Epoch 021 - training loss: 0.1569, validation loss: 0.1381
2024-05-25 00:42:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch21_loss0.13806573376059533.pypots
2024-05-25 00:42:29 [INFO]: Epoch 022 - training loss: 0.1521, validation loss: 0.1386
2024-05-25 00:42:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch22_loss0.13863385394215583.pypots
2024-05-25 00:42:45 [INFO]: Epoch 023 - training loss: 0.1572, validation loss: 0.1330
2024-05-25 00:42:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch23_loss0.13299229964613915.pypots
2024-05-25 00:43:02 [INFO]: Epoch 024 - training loss: 0.1426, validation loss: 0.1321
2024-05-25 00:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch24_loss0.1321261517703533.pypots
2024-05-25 00:43:18 [INFO]: Epoch 025 - training loss: 0.1525, validation loss: 0.1341
2024-05-25 00:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch25_loss0.13411307483911514.pypots
2024-05-25 00:43:35 [INFO]: Epoch 026 - training loss: 0.1489, validation loss: 0.1333
2024-05-25 00:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch26_loss0.133328939974308.pypots
2024-05-25 00:43:52 [INFO]: Epoch 027 - training loss: 0.1399, validation loss: 0.1346
2024-05-25 00:43:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch27_loss0.1346498265862465.pypots
2024-05-25 00:44:08 [INFO]: Epoch 028 - training loss: 0.1337, validation loss: 0.1456
2024-05-25 00:44:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch28_loss0.14558805972337724.pypots
2024-05-25 00:44:25 [INFO]: Epoch 029 - training loss: 0.1278, validation loss: 0.1307
2024-05-25 00:44:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch29_loss0.13073597922921182.pypots
2024-05-25 00:44:42 [INFO]: Epoch 030 - training loss: 0.1218, validation loss: 0.1293
2024-05-25 00:44:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch30_loss0.12932103574275972.pypots
2024-05-25 00:44:58 [INFO]: Epoch 031 - training loss: 0.1308, validation loss: 0.1312
2024-05-25 00:44:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch31_loss0.1311888076364994.pypots
2024-05-25 00:45:15 [INFO]: Epoch 032 - training loss: 0.1295, validation loss: 0.1298
2024-05-25 00:45:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch32_loss0.12983001470565797.pypots
2024-05-25 00:45:32 [INFO]: Epoch 033 - training loss: 0.1368, validation loss: 0.1280
2024-05-25 00:45:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch33_loss0.12796951755881308.pypots
2024-05-25 00:45:48 [INFO]: Epoch 034 - training loss: 0.1136, validation loss: 0.1363
2024-05-25 00:45:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch34_loss0.13625314980745315.pypots
2024-05-25 00:46:05 [INFO]: Epoch 035 - training loss: 0.1324, validation loss: 0.1296
2024-05-25 00:46:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch35_loss0.12957871854305267.pypots
2024-05-25 00:46:21 [INFO]: Epoch 036 - training loss: 0.1293, validation loss: 0.1292
2024-05-25 00:46:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch36_loss0.12918346151709556.pypots
2024-05-25 00:46:38 [INFO]: Epoch 037 - training loss: 0.1325, validation loss: 0.1325
2024-05-25 00:46:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch37_loss0.13245324045419693.pypots
2024-05-25 00:46:55 [INFO]: Epoch 038 - training loss: 0.1334, validation loss: 0.1293
2024-05-25 00:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch38_loss0.12931061610579492.pypots
2024-05-25 00:47:11 [INFO]: Epoch 039 - training loss: 0.1430, validation loss: 0.1248
2024-05-25 00:47:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch39_loss0.12480616718530654.pypots
2024-05-25 00:47:28 [INFO]: Epoch 040 - training loss: 0.1237, validation loss: 0.1286
2024-05-25 00:47:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch40_loss0.12863433510065078.pypots
2024-05-25 00:47:45 [INFO]: Epoch 041 - training loss: 0.1367, validation loss: 0.1261
2024-05-25 00:47:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch41_loss0.12609900012612343.pypots
2024-05-25 00:48:01 [INFO]: Epoch 042 - training loss: 0.1324, validation loss: 0.1272
2024-05-25 00:48:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch42_loss0.12715549394488335.pypots
2024-05-25 00:48:18 [INFO]: Epoch 043 - training loss: 0.1309, validation loss: 0.1231
2024-05-25 00:48:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch43_loss0.1230510413646698.pypots
2024-05-25 00:48:35 [INFO]: Epoch 044 - training loss: 0.1215, validation loss: 0.1259
2024-05-25 00:48:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch44_loss0.1259318321943283.pypots
2024-05-25 00:48:51 [INFO]: Epoch 045 - training loss: 0.1367, validation loss: 0.1246
2024-05-25 00:48:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch45_loss0.1245713211596012.pypots
2024-05-25 00:49:08 [INFO]: Epoch 046 - training loss: 0.1211, validation loss: 0.1306
2024-05-25 00:49:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch46_loss0.13061418682336806.pypots
2024-05-25 00:49:24 [INFO]: Epoch 047 - training loss: 0.1257, validation loss: 0.1237
2024-05-25 00:49:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch47_loss0.12370911166071892.pypots
2024-05-25 00:49:41 [INFO]: Epoch 048 - training loss: 0.1210, validation loss: 0.1240
2024-05-25 00:49:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch48_loss0.12404735758900642.pypots
2024-05-25 00:49:58 [INFO]: Epoch 049 - training loss: 0.1140, validation loss: 0.1248
2024-05-25 00:49:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch49_loss0.12480232268571853.pypots
2024-05-25 00:50:14 [INFO]: Epoch 050 - training loss: 0.1296, validation loss: 0.1263
2024-05-25 00:50:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch50_loss0.12630897387862206.pypots
2024-05-25 00:50:31 [INFO]: Epoch 051 - training loss: 0.1409, validation loss: 0.1255
2024-05-25 00:50:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch51_loss0.12554465904831885.pypots
2024-05-25 00:50:48 [INFO]: Epoch 052 - training loss: 0.1203, validation loss: 0.1222
2024-05-25 00:50:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch52_loss0.12220367044210434.pypots
2024-05-25 00:51:04 [INFO]: Epoch 053 - training loss: 0.1282, validation loss: 0.1208
2024-05-25 00:51:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch53_loss0.1207930363714695.pypots
2024-05-25 00:51:21 [INFO]: Epoch 054 - training loss: 0.1285, validation loss: 0.1215
2024-05-25 00:51:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch54_loss0.12154731750488282.pypots
2024-05-25 00:51:37 [INFO]: Epoch 055 - training loss: 0.1159, validation loss: 0.1198
2024-05-25 00:51:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch55_loss0.11979709193110466.pypots
2024-05-25 00:51:54 [INFO]: Epoch 056 - training loss: 0.1124, validation loss: 0.1245
2024-05-25 00:51:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch56_loss0.12448368221521378.pypots
2024-05-25 00:52:11 [INFO]: Epoch 057 - training loss: 0.1072, validation loss: 0.1234
2024-05-25 00:52:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch57_loss0.12344625517725945.pypots
2024-05-25 00:52:27 [INFO]: Epoch 058 - training loss: 0.1170, validation loss: 0.1213
2024-05-25 00:52:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch58_loss0.12128280028700829.pypots
2024-05-25 00:52:44 [INFO]: Epoch 059 - training loss: 0.1199, validation loss: 0.1227
2024-05-25 00:52:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch59_loss0.1226879172027111.pypots
2024-05-25 00:53:01 [INFO]: Epoch 060 - training loss: 0.1221, validation loss: 0.1205
2024-05-25 00:53:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch60_loss0.12049265578389168.pypots
2024-05-25 00:53:17 [INFO]: Epoch 061 - training loss: 0.1110, validation loss: 0.1183
2024-05-25 00:53:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch61_loss0.1182837575674057.pypots
2024-05-25 00:53:34 [INFO]: Epoch 062 - training loss: 0.1198, validation loss: 0.1200
2024-05-25 00:53:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch62_loss0.12003288865089416.pypots
2024-05-25 00:53:50 [INFO]: Epoch 063 - training loss: 0.1254, validation loss: 0.1193
2024-05-25 00:53:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch63_loss0.11934656128287316.pypots
2024-05-25 00:54:07 [INFO]: Epoch 064 - training loss: 0.1304, validation loss: 0.1178
2024-05-25 00:54:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch64_loss0.11775001287460327.pypots
2024-05-25 00:54:24 [INFO]: Epoch 065 - training loss: 0.1151, validation loss: 0.1181
2024-05-25 00:54:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch65_loss0.11810288280248642.pypots
2024-05-25 00:54:40 [INFO]: Epoch 066 - training loss: 0.1189, validation loss: 0.1169
2024-05-25 00:54:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch66_loss0.11692332774400711.pypots
2024-05-25 00:54:57 [INFO]: Epoch 067 - training loss: 0.1216, validation loss: 0.1166
2024-05-25 00:54:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch67_loss0.11661277338862419.pypots
2024-05-25 00:55:14 [INFO]: Epoch 068 - training loss: 0.1195, validation loss: 0.1169
2024-05-25 00:55:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch68_loss0.11693885326385497.pypots
2024-05-25 00:55:30 [INFO]: Epoch 069 - training loss: 0.1132, validation loss: 0.1170
2024-05-25 00:55:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch69_loss0.1170491635799408.pypots
2024-05-25 00:55:47 [INFO]: Epoch 070 - training loss: 0.1200, validation loss: 0.1164
2024-05-25 00:55:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch70_loss0.11641013398766517.pypots
2024-05-25 00:56:04 [INFO]: Epoch 071 - training loss: 0.1137, validation loss: 0.1177
2024-05-25 00:56:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch71_loss0.11769804805517196.pypots
2024-05-25 00:56:20 [INFO]: Epoch 072 - training loss: 0.1305, validation loss: 0.1161
2024-05-25 00:56:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch72_loss0.11610793620347977.pypots
2024-05-25 00:56:37 [INFO]: Epoch 073 - training loss: 0.1154, validation loss: 0.1160
2024-05-25 00:56:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch73_loss0.11598150879144668.pypots
2024-05-25 00:56:53 [INFO]: Epoch 074 - training loss: 0.1104, validation loss: 0.1140
2024-05-25 00:56:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch74_loss0.1139588326215744.pypots
2024-05-25 00:57:10 [INFO]: Epoch 075 - training loss: 0.1149, validation loss: 0.1184
2024-05-25 00:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch75_loss0.11840650364756584.pypots
2024-05-25 00:57:27 [INFO]: Epoch 076 - training loss: 0.1122, validation loss: 0.1135
2024-05-25 00:57:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch76_loss0.11350322216749191.pypots
2024-05-25 00:57:43 [INFO]: Epoch 077 - training loss: 0.1103, validation loss: 0.1140
2024-05-25 00:57:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch77_loss0.11404476463794708.pypots
2024-05-25 00:58:00 [INFO]: Epoch 078 - training loss: 0.1199, validation loss: 0.1139
2024-05-25 00:58:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch78_loss0.11394193843007087.pypots
2024-05-25 00:58:17 [INFO]: Epoch 079 - training loss: 0.1166, validation loss: 0.1139
2024-05-25 00:58:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch79_loss0.11388393715023995.pypots
2024-05-25 00:58:33 [INFO]: Epoch 080 - training loss: 0.1226, validation loss: 0.1159
2024-05-25 00:58:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch80_loss0.1158722072839737.pypots
2024-05-25 00:58:50 [INFO]: Epoch 081 - training loss: 0.1091, validation loss: 0.1206
2024-05-25 00:58:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch81_loss0.12060180976986885.pypots
2024-05-25 00:59:07 [INFO]: Epoch 082 - training loss: 0.1232, validation loss: 0.1159
2024-05-25 00:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch82_loss0.11590347737073899.pypots
2024-05-25 00:59:23 [INFO]: Epoch 083 - training loss: 0.1118, validation loss: 0.1127
2024-05-25 00:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch83_loss0.11271764785051346.pypots
2024-05-25 00:59:40 [INFO]: Epoch 084 - training loss: 0.1165, validation loss: 0.1114
2024-05-25 00:59:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch84_loss0.11142642349004746.pypots
2024-05-25 00:59:56 [INFO]: Epoch 085 - training loss: 0.1165, validation loss: 0.1114
2024-05-25 00:59:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch85_loss0.11139517426490783.pypots
2024-05-25 01:00:13 [INFO]: Epoch 086 - training loss: 0.1145, validation loss: 0.1153
2024-05-25 01:00:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch86_loss0.11527508571743965.pypots
2024-05-25 01:00:30 [INFO]: Epoch 087 - training loss: 0.1106, validation loss: 0.1115
2024-05-25 01:00:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch87_loss0.11154985427856445.pypots
2024-05-25 01:00:46 [INFO]: Epoch 088 - training loss: 0.1051, validation loss: 0.1098
2024-05-25 01:00:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch88_loss0.10980119779706002.pypots
2024-05-25 01:01:03 [INFO]: Epoch 089 - training loss: 0.1201, validation loss: 0.1151
2024-05-25 01:01:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch89_loss0.11507342159748077.pypots
2024-05-25 01:01:20 [INFO]: Epoch 090 - training loss: 0.1092, validation loss: 0.1163
2024-05-25 01:01:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch90_loss0.11633721739053726.pypots
2024-05-25 01:01:36 [INFO]: Epoch 091 - training loss: 0.1171, validation loss: 0.1167
2024-05-25 01:01:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch91_loss0.11670280694961548.pypots
2024-05-25 01:01:53 [INFO]: Epoch 092 - training loss: 0.1114, validation loss: 0.1104
2024-05-25 01:01:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch92_loss0.11037093177437782.pypots
2024-05-25 01:02:10 [INFO]: Epoch 093 - training loss: 0.1066, validation loss: 0.1119
2024-05-25 01:02:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch93_loss0.11192449852824211.pypots
2024-05-25 01:02:26 [INFO]: Epoch 094 - training loss: 0.1112, validation loss: 0.1136
2024-05-25 01:02:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch94_loss0.11363631635904312.pypots
2024-05-25 01:02:43 [INFO]: Epoch 095 - training loss: 0.0993, validation loss: 0.1079
2024-05-25 01:02:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch95_loss0.10790763050317764.pypots
2024-05-25 01:02:59 [INFO]: Epoch 096 - training loss: 0.1067, validation loss: 0.1096
2024-05-25 01:02:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch96_loss0.10962850674986839.pypots
2024-05-25 01:03:16 [INFO]: Epoch 097 - training loss: 0.1149, validation loss: 0.1094
2024-05-25 01:03:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch97_loss0.10941824689507484.pypots
2024-05-25 01:03:33 [INFO]: Epoch 098 - training loss: 0.1167, validation loss: 0.1107
2024-05-25 01:03:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch98_loss0.11066561192274094.pypots
2024-05-25 01:03:49 [INFO]: Epoch 099 - training loss: 0.1185, validation loss: 0.1109
2024-05-25 01:03:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch99_loss0.1108947180211544.pypots
2024-05-25 01:04:06 [INFO]: Epoch 100 - training loss: 0.1269, validation loss: 0.1093
2024-05-25 01:04:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch100_loss0.10929581597447395.pypots
2024-05-25 01:04:23 [INFO]: Epoch 101 - training loss: 0.1172, validation loss: 0.1077
2024-05-25 01:04:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch101_loss0.10770260319113731.pypots
2024-05-25 01:04:39 [INFO]: Epoch 102 - training loss: 0.1155, validation loss: 0.1072
2024-05-25 01:04:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch102_loss0.10719227567315101.pypots
2024-05-25 01:04:56 [INFO]: Epoch 103 - training loss: 0.1088, validation loss: 0.1083
2024-05-25 01:04:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch103_loss0.10825910791754723.pypots
2024-05-25 01:05:13 [INFO]: Epoch 104 - training loss: 0.1151, validation loss: 0.1098
2024-05-25 01:05:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch104_loss0.10976460054516793.pypots
2024-05-25 01:05:29 [INFO]: Epoch 105 - training loss: 0.1084, validation loss: 0.1063
2024-05-25 01:05:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch105_loss0.1062687799334526.pypots
2024-05-25 01:05:46 [INFO]: Epoch 106 - training loss: 0.0937, validation loss: 0.1066
2024-05-25 01:05:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch106_loss0.10658361837267875.pypots
2024-05-25 01:06:02 [INFO]: Epoch 107 - training loss: 0.1006, validation loss: 0.1105
2024-05-25 01:06:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch107_loss0.11048967391252518.pypots
2024-05-25 01:06:19 [INFO]: Epoch 108 - training loss: 0.1144, validation loss: 0.1066
2024-05-25 01:06:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch108_loss0.10663659572601318.pypots
2024-05-25 01:06:36 [INFO]: Epoch 109 - training loss: 0.1110, validation loss: 0.1092
2024-05-25 01:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch109_loss0.10918361991643906.pypots
2024-05-25 01:06:52 [INFO]: Epoch 110 - training loss: 0.1091, validation loss: 0.1104
2024-05-25 01:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch110_loss0.11038672178983688.pypots
2024-05-25 01:07:09 [INFO]: Epoch 111 - training loss: 0.1047, validation loss: 0.1089
2024-05-25 01:07:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch111_loss0.10893915742635726.pypots
2024-05-25 01:07:26 [INFO]: Epoch 112 - training loss: 0.1126, validation loss: 0.1089
2024-05-25 01:07:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch112_loss0.10890705361962319.pypots
2024-05-25 01:07:42 [INFO]: Epoch 113 - training loss: 0.1025, validation loss: 0.1083
2024-05-25 01:07:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch113_loss0.10832262635231019.pypots
2024-05-25 01:07:59 [INFO]: Epoch 114 - training loss: 0.1020, validation loss: 0.1094
2024-05-25 01:07:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch114_loss0.10940808430314064.pypots
2024-05-25 01:08:16 [INFO]: Epoch 115 - training loss: 0.1097, validation loss: 0.1073
2024-05-25 01:08:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI_epoch115_loss0.1072573147714138.pypots
2024-05-25 01:08:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:08:16 [INFO]: Finished training. The best model is from epoch#105.
2024-05-25 01:08:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T003623/CSDI.pypots
2024-05-25 01:10:36 [INFO]: CSDI on Air-Quality: MAE=0.1045, MSE=0.3025
2024-05-25 01:10:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 01:10:36 [INFO]: Using the given device: cuda:0
2024-05-25 01:10:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T011036
2024-05-25 01:10:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T011036/tensorboard
2024-05-25 01:10:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 01:10:36 [INFO]: Epoch 001 - training loss: 64105.3555, validation loss: 0.6393
2024-05-25 01:10:37 [INFO]: Epoch 002 - training loss: 42017.2992, validation loss: 0.5818
2024-05-25 01:10:37 [INFO]: Epoch 003 - training loss: 41651.7383, validation loss: 0.5408
2024-05-25 01:10:37 [INFO]: Epoch 004 - training loss: 41512.4060, validation loss: 0.4649
2024-05-25 01:10:38 [INFO]: Epoch 005 - training loss: 41436.8925, validation loss: 0.4158
2024-05-25 01:10:38 [INFO]: Epoch 006 - training loss: 41433.2054, validation loss: 0.4559
2024-05-25 01:10:38 [INFO]: Epoch 007 - training loss: 41376.9132, validation loss: 0.3672
2024-05-25 01:10:39 [INFO]: Epoch 008 - training loss: 41305.6306, validation loss: 0.3426
2024-05-25 01:10:39 [INFO]: Epoch 009 - training loss: 41262.9198, validation loss: 0.3186
2024-05-25 01:10:39 [INFO]: Epoch 010 - training loss: 41232.6374, validation loss: 0.3085
2024-05-25 01:10:40 [INFO]: Epoch 011 - training loss: 41225.9873, validation loss: 0.3472
2024-05-25 01:10:40 [INFO]: Epoch 012 - training loss: 41242.3310, validation loss: 0.3311
2024-05-25 01:10:40 [INFO]: Epoch 013 - training loss: 41198.4890, validation loss: 0.3169
2024-05-25 01:10:41 [INFO]: Epoch 014 - training loss: 41182.1701, validation loss: 0.2863
2024-05-25 01:10:41 [INFO]: Epoch 015 - training loss: 41171.6324, validation loss: 0.3036
2024-05-25 01:10:41 [INFO]: Epoch 016 - training loss: 41199.9238, validation loss: 0.3061
2024-05-25 01:10:42 [INFO]: Epoch 017 - training loss: 41232.4628, validation loss: 0.3047
2024-05-25 01:10:42 [INFO]: Epoch 018 - training loss: 41165.2653, validation loss: 0.2710
2024-05-25 01:10:42 [INFO]: Epoch 019 - training loss: 41129.3861, validation loss: 0.2630
2024-05-25 01:10:43 [INFO]: Epoch 020 - training loss: 41117.2697, validation loss: 0.2558
2024-05-25 01:10:43 [INFO]: Epoch 021 - training loss: 41111.9991, validation loss: 0.2575
2024-05-25 01:10:43 [INFO]: Epoch 022 - training loss: 41104.7099, validation loss: 0.2620
2024-05-25 01:10:44 [INFO]: Epoch 023 - training loss: 41139.2817, validation loss: 0.2716
2024-05-25 01:10:44 [INFO]: Epoch 024 - training loss: 41130.3071, validation loss: 0.2706
2024-05-25 01:10:44 [INFO]: Epoch 025 - training loss: 41119.4797, validation loss: 0.2473
2024-05-25 01:10:45 [INFO]: Epoch 026 - training loss: 41090.6683, validation loss: 0.2453
2024-05-25 01:10:45 [INFO]: Epoch 027 - training loss: 41096.2574, validation loss: 0.2466
2024-05-25 01:10:45 [INFO]: Epoch 028 - training loss: 41097.6052, validation loss: 0.2409
2024-05-25 01:10:46 [INFO]: Epoch 029 - training loss: 41077.2140, validation loss: 0.2452
2024-05-25 01:10:46 [INFO]: Epoch 030 - training loss: 41069.6195, validation loss: 0.2299
2024-05-25 01:10:46 [INFO]: Epoch 031 - training loss: 41065.2442, validation loss: 0.2400
2024-05-25 01:10:47 [INFO]: Epoch 032 - training loss: 41061.7412, validation loss: 0.2405
2024-05-25 01:10:47 [INFO]: Epoch 033 - training loss: 41058.2277, validation loss: 0.2442
2024-05-25 01:10:47 [INFO]: Epoch 034 - training loss: 41065.6016, validation loss: 0.2451
2024-05-25 01:10:48 [INFO]: Epoch 035 - training loss: 41055.6447, validation loss: 0.2426
2024-05-25 01:10:48 [INFO]: Epoch 036 - training loss: 41071.4860, validation loss: 0.2474
2024-05-25 01:10:48 [INFO]: Epoch 037 - training loss: 41068.7775, validation loss: 0.2291
2024-05-25 01:10:49 [INFO]: Epoch 038 - training loss: 41051.0671, validation loss: 0.2208
2024-05-25 01:10:49 [INFO]: Epoch 039 - training loss: 41035.2619, validation loss: 0.2190
2024-05-25 01:10:49 [INFO]: Epoch 040 - training loss: 41034.2078, validation loss: 0.2155
2024-05-25 01:10:50 [INFO]: Epoch 041 - training loss: 41029.8636, validation loss: 0.2166
2024-05-25 01:10:50 [INFO]: Epoch 042 - training loss: 41033.7338, validation loss: 0.2580
2024-05-25 01:10:50 [INFO]: Epoch 043 - training loss: 41098.1238, validation loss: 0.2427
2024-05-25 01:10:51 [INFO]: Epoch 044 - training loss: 41067.9547, validation loss: 0.2339
2024-05-25 01:10:51 [INFO]: Epoch 045 - training loss: 41117.3229, validation loss: 0.2787
2024-05-25 01:10:51 [INFO]: Epoch 046 - training loss: 41134.9595, validation loss: 0.2305
2024-05-25 01:10:51 [INFO]: Epoch 047 - training loss: 41062.0595, validation loss: 0.2267
2024-05-25 01:10:52 [INFO]: Epoch 048 - training loss: 41054.0396, validation loss: 0.2156
2024-05-25 01:10:52 [INFO]: Epoch 049 - training loss: 41034.2318, validation loss: 0.2124
2024-05-25 01:10:52 [INFO]: Epoch 050 - training loss: 41022.8673, validation loss: 0.2109
2024-05-25 01:10:53 [INFO]: Epoch 051 - training loss: 41017.5962, validation loss: 0.2045
2024-05-25 01:10:53 [INFO]: Epoch 052 - training loss: 41013.2863, validation loss: 0.2021
2024-05-25 01:10:53 [INFO]: Epoch 053 - training loss: 41008.6908, validation loss: 0.2049
2024-05-25 01:10:54 [INFO]: Epoch 054 - training loss: 41006.9630, validation loss: 0.2022
2024-05-25 01:10:54 [INFO]: Epoch 055 - training loss: 41007.7410, validation loss: 0.2029
2024-05-25 01:10:54 [INFO]: Epoch 056 - training loss: 41010.5848, validation loss: 0.2077
2024-05-25 01:10:55 [INFO]: Epoch 057 - training loss: 41015.1762, validation loss: 0.2049
2024-05-25 01:10:55 [INFO]: Epoch 058 - training loss: 41009.8838, validation loss: 0.2085
2024-05-25 01:10:55 [INFO]: Epoch 059 - training loss: 41013.8163, validation loss: 0.2048
2024-05-25 01:10:56 [INFO]: Epoch 060 - training loss: 41015.5266, validation loss: 0.2139
2024-05-25 01:10:56 [INFO]: Epoch 061 - training loss: 41010.9530, validation loss: 0.2020
2024-05-25 01:10:56 [INFO]: Epoch 062 - training loss: 41001.5033, validation loss: 0.2030
2024-05-25 01:10:57 [INFO]: Epoch 063 - training loss: 41010.5467, validation loss: 0.2035
2024-05-25 01:10:57 [INFO]: Epoch 064 - training loss: 41005.0399, validation loss: 0.2156
2024-05-25 01:10:57 [INFO]: Epoch 065 - training loss: 41010.5107, validation loss: 0.2041
2024-05-25 01:10:58 [INFO]: Epoch 066 - training loss: 41001.6516, validation loss: 0.2039
2024-05-25 01:10:58 [INFO]: Epoch 067 - training loss: 40992.2465, validation loss: 0.2036
2024-05-25 01:10:58 [INFO]: Epoch 068 - training loss: 40988.3968, validation loss: 0.2153
2024-05-25 01:10:59 [INFO]: Epoch 069 - training loss: 41009.7323, validation loss: 0.2277
2024-05-25 01:10:59 [INFO]: Epoch 070 - training loss: 41086.3338, validation loss: 0.2100
2024-05-25 01:10:59 [INFO]: Epoch 071 - training loss: 41036.2933, validation loss: 0.2060
2024-05-25 01:10:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:10:59 [INFO]: Finished training. The best model is from epoch#61.
2024-05-25 01:10:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T011036/GPVAE.pypots
2024-05-25 01:10:59 [INFO]: GP-VAE on Air-Quality: MAE=0.2728, MSE=0.2169
2024-05-25 01:10:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 01:10:59 [INFO]: Using the given device: cuda:0
2024-05-25 01:10:59 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T011059
2024-05-25 01:10:59 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T011059/tensorboard
2024-05-25 01:10:59 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 01:11:04 [INFO]: Epoch 001 - generator training loss: 0.5352, discriminator training loss: 0.3843, validation loss: 0.5109
2024-05-25 01:11:09 [INFO]: Epoch 002 - generator training loss: 0.1550, discriminator training loss: 0.2421, validation loss: 0.3766
2024-05-25 01:11:13 [INFO]: Epoch 003 - generator training loss: 0.0993, discriminator training loss: 0.2377, validation loss: 0.3038
2024-05-25 01:11:17 [INFO]: Epoch 004 - generator training loss: 0.0589, discriminator training loss: 0.2368, validation loss: 0.2635
2024-05-25 01:11:21 [INFO]: Epoch 005 - generator training loss: 0.0354, discriminator training loss: 0.2360, validation loss: 0.2378
2024-05-25 01:11:25 [INFO]: Epoch 006 - generator training loss: 0.0177, discriminator training loss: 0.2354, validation loss: 0.2173
2024-05-25 01:11:29 [INFO]: Epoch 007 - generator training loss: 0.0091, discriminator training loss: 0.2337, validation loss: 0.2041
2024-05-25 01:11:33 [INFO]: Epoch 008 - generator training loss: -0.0029, discriminator training loss: 0.2326, validation loss: 0.1930
2024-05-25 01:11:37 [INFO]: Epoch 009 - generator training loss: -0.0072, discriminator training loss: 0.2319, validation loss: 0.1845
2024-05-25 01:11:41 [INFO]: Epoch 010 - generator training loss: -0.0092, discriminator training loss: 0.2302, validation loss: 0.1779
2024-05-25 01:11:45 [INFO]: Epoch 011 - generator training loss: -0.0225, discriminator training loss: 0.2286, validation loss: 0.1707
2024-05-25 01:11:50 [INFO]: Epoch 012 - generator training loss: -0.0266, discriminator training loss: 0.2270, validation loss: 0.1654
2024-05-25 01:11:54 [INFO]: Epoch 013 - generator training loss: -0.0299, discriminator training loss: 0.2255, validation loss: 0.1607
2024-05-25 01:11:58 [INFO]: Epoch 014 - generator training loss: -0.0327, discriminator training loss: 0.2238, validation loss: 0.1561
2024-05-25 01:12:02 [INFO]: Epoch 015 - generator training loss: -0.0369, discriminator training loss: 0.2226, validation loss: 0.1519
2024-05-25 01:12:06 [INFO]: Epoch 016 - generator training loss: -0.0377, discriminator training loss: 0.2209, validation loss: 0.1481
2024-05-25 01:12:10 [INFO]: Epoch 017 - generator training loss: -0.0406, discriminator training loss: 0.2196, validation loss: 0.1446
2024-05-25 01:12:14 [INFO]: Epoch 018 - generator training loss: -0.0412, discriminator training loss: 0.2182, validation loss: 0.1411
2024-05-25 01:12:18 [INFO]: Epoch 019 - generator training loss: -0.0443, discriminator training loss: 0.2167, validation loss: 0.1383
2024-05-25 01:12:22 [INFO]: Epoch 020 - generator training loss: -0.0456, discriminator training loss: 0.2151, validation loss: 0.1360
2024-05-25 01:12:27 [INFO]: Epoch 021 - generator training loss: -0.0460, discriminator training loss: 0.2134, validation loss: 0.1336
2024-05-25 01:12:31 [INFO]: Epoch 022 - generator training loss: -0.0469, discriminator training loss: 0.2117, validation loss: 0.1316
2024-05-25 01:12:35 [INFO]: Epoch 023 - generator training loss: -0.0478, discriminator training loss: 0.2100, validation loss: 0.1292
2024-05-25 01:12:39 [INFO]: Epoch 024 - generator training loss: -0.0489, discriminator training loss: 0.2083, validation loss: 0.1268
2024-05-25 01:12:43 [INFO]: Epoch 025 - generator training loss: -0.0503, discriminator training loss: 0.2067, validation loss: 0.1244
2024-05-25 01:12:47 [INFO]: Epoch 026 - generator training loss: -0.0499, discriminator training loss: 0.2048, validation loss: 0.1232
2024-05-25 01:12:51 [INFO]: Epoch 027 - generator training loss: -0.0507, discriminator training loss: 0.2031, validation loss: 0.1210
2024-05-25 01:12:55 [INFO]: Epoch 028 - generator training loss: -0.0500, discriminator training loss: 0.2013, validation loss: 0.1202
2024-05-25 01:12:59 [INFO]: Epoch 029 - generator training loss: -0.0504, discriminator training loss: 0.1999, validation loss: 0.1182
2024-05-25 01:13:04 [INFO]: Epoch 030 - generator training loss: -0.0507, discriminator training loss: 0.1981, validation loss: 0.1166
2024-05-25 01:13:08 [INFO]: Epoch 031 - generator training loss: -0.0504, discriminator training loss: 0.1963, validation loss: 0.1150
2024-05-25 01:13:12 [INFO]: Epoch 032 - generator training loss: -0.0500, discriminator training loss: 0.1947, validation loss: 0.1139
2024-05-25 01:13:16 [INFO]: Epoch 033 - generator training loss: -0.0486, discriminator training loss: 0.1930, validation loss: 0.1126
2024-05-25 01:13:20 [INFO]: Epoch 034 - generator training loss: -0.0501, discriminator training loss: 0.1914, validation loss: 0.1112
2024-05-25 01:13:24 [INFO]: Epoch 035 - generator training loss: -0.0497, discriminator training loss: 0.1900, validation loss: 0.1102
2024-05-25 01:13:28 [INFO]: Epoch 036 - generator training loss: -0.0498, discriminator training loss: 0.1884, validation loss: 0.1084
2024-05-25 01:13:32 [INFO]: Epoch 037 - generator training loss: -0.0493, discriminator training loss: 0.1867, validation loss: 0.1072
2024-05-25 01:13:36 [INFO]: Epoch 038 - generator training loss: -0.0492, discriminator training loss: 0.1852, validation loss: 0.1060
2024-05-25 01:13:40 [INFO]: Epoch 039 - generator training loss: -0.0484, discriminator training loss: 0.1836, validation loss: 0.1050
2024-05-25 01:13:45 [INFO]: Epoch 040 - generator training loss: -0.0485, discriminator training loss: 0.1823, validation loss: 0.1039
2024-05-25 01:13:49 [INFO]: Epoch 041 - generator training loss: -0.0483, discriminator training loss: 0.1808, validation loss: 0.1029
2024-05-25 01:13:53 [INFO]: Epoch 042 - generator training loss: -0.0476, discriminator training loss: 0.1794, validation loss: 0.1018
2024-05-25 01:13:57 [INFO]: Epoch 043 - generator training loss: -0.0472, discriminator training loss: 0.1780, validation loss: 0.1008
2024-05-25 01:14:01 [INFO]: Epoch 044 - generator training loss: -0.0467, discriminator training loss: 0.1765, validation loss: 0.0994
2024-05-25 01:14:05 [INFO]: Epoch 045 - generator training loss: -0.0461, discriminator training loss: 0.1752, validation loss: 0.0990
2024-05-25 01:14:09 [INFO]: Epoch 046 - generator training loss: -0.0464, discriminator training loss: 0.1736, validation loss: 0.0976
2024-05-25 01:14:13 [INFO]: Epoch 047 - generator training loss: -0.0464, discriminator training loss: 0.1725, validation loss: 0.0972
2024-05-25 01:14:17 [INFO]: Epoch 048 - generator training loss: -0.0458, discriminator training loss: 0.1713, validation loss: 0.0957
2024-05-25 01:14:21 [INFO]: Epoch 049 - generator training loss: -0.0452, discriminator training loss: 0.1703, validation loss: 0.0948
2024-05-25 01:14:26 [INFO]: Epoch 050 - generator training loss: -0.0458, discriminator training loss: 0.1689, validation loss: 0.0938
2024-05-25 01:14:30 [INFO]: Epoch 051 - generator training loss: -0.0439, discriminator training loss: 0.1678, validation loss: 0.0928
2024-05-25 01:14:34 [INFO]: Epoch 052 - generator training loss: -0.0450, discriminator training loss: 0.1669, validation loss: 0.0918
2024-05-25 01:14:38 [INFO]: Epoch 053 - generator training loss: -0.0446, discriminator training loss: 0.1656, validation loss: 0.0912
2024-05-25 01:14:42 [INFO]: Epoch 054 - generator training loss: -0.0422, discriminator training loss: 0.1645, validation loss: 0.0903
2024-05-25 01:14:46 [INFO]: Epoch 055 - generator training loss: -0.0444, discriminator training loss: 0.1633, validation loss: 0.0898
2024-05-25 01:14:50 [INFO]: Epoch 056 - generator training loss: -0.0438, discriminator training loss: 0.1627, validation loss: 0.0889
2024-05-25 01:14:54 [INFO]: Epoch 057 - generator training loss: -0.0442, discriminator training loss: 0.1614, validation loss: 0.0882
2024-05-25 01:14:58 [INFO]: Epoch 058 - generator training loss: -0.0439, discriminator training loss: 0.1608, validation loss: 0.0874
2024-05-25 01:15:03 [INFO]: Epoch 059 - generator training loss: -0.0432, discriminator training loss: 0.1597, validation loss: 0.0867
2024-05-25 01:15:07 [INFO]: Epoch 060 - generator training loss: -0.0439, discriminator training loss: 0.1589, validation loss: 0.0858
2024-05-25 01:15:11 [INFO]: Epoch 061 - generator training loss: -0.0435, discriminator training loss: 0.1580, validation loss: 0.0850
2024-05-25 01:15:15 [INFO]: Epoch 062 - generator training loss: -0.0433, discriminator training loss: 0.1571, validation loss: 0.0850
2024-05-25 01:15:19 [INFO]: Epoch 063 - generator training loss: -0.0434, discriminator training loss: 0.1562, validation loss: 0.0843
2024-05-25 01:15:23 [INFO]: Epoch 064 - generator training loss: -0.0433, discriminator training loss: 0.1556, validation loss: 0.0833
2024-05-25 01:15:27 [INFO]: Epoch 065 - generator training loss: -0.0429, discriminator training loss: 0.1548, validation loss: 0.0835
2024-05-25 01:15:31 [INFO]: Epoch 066 - generator training loss: -0.0431, discriminator training loss: 0.1540, validation loss: 0.0830
2024-05-25 01:15:35 [INFO]: Epoch 067 - generator training loss: -0.0433, discriminator training loss: 0.1537, validation loss: 0.0822
2024-05-25 01:15:40 [INFO]: Epoch 068 - generator training loss: -0.0421, discriminator training loss: 0.1523, validation loss: 0.0820
2024-05-25 01:15:44 [INFO]: Epoch 069 - generator training loss: -0.0423, discriminator training loss: 0.1520, validation loss: 0.0812
2024-05-25 01:15:48 [INFO]: Epoch 070 - generator training loss: -0.0420, discriminator training loss: 0.1510, validation loss: 0.0806
2024-05-25 01:15:52 [INFO]: Epoch 071 - generator training loss: -0.0423, discriminator training loss: 0.1508, validation loss: 0.0803
2024-05-25 01:15:56 [INFO]: Epoch 072 - generator training loss: -0.0427, discriminator training loss: 0.1503, validation loss: 0.0798
2024-05-25 01:16:00 [INFO]: Epoch 073 - generator training loss: -0.0419, discriminator training loss: 0.1496, validation loss: 0.0799
2024-05-25 01:16:04 [INFO]: Epoch 074 - generator training loss: -0.0418, discriminator training loss: 0.1488, validation loss: 0.0793
2024-05-25 01:16:08 [INFO]: Epoch 075 - generator training loss: -0.0418, discriminator training loss: 0.1486, validation loss: 0.0790
2024-05-25 01:16:12 [INFO]: Epoch 076 - generator training loss: -0.0426, discriminator training loss: 0.1483, validation loss: 0.0787
2024-05-25 01:16:16 [INFO]: Epoch 077 - generator training loss: -0.0430, discriminator training loss: 0.1476, validation loss: 0.0784
2024-05-25 01:16:20 [INFO]: Epoch 078 - generator training loss: -0.0414, discriminator training loss: 0.1472, validation loss: 0.0786
2024-05-25 01:16:25 [INFO]: Epoch 079 - generator training loss: -0.0428, discriminator training loss: 0.1464, validation loss: 0.0780
2024-05-25 01:16:29 [INFO]: Epoch 080 - generator training loss: -0.0428, discriminator training loss: 0.1461, validation loss: 0.0774
2024-05-25 01:16:33 [INFO]: Epoch 081 - generator training loss: -0.0425, discriminator training loss: 0.1458, validation loss: 0.0770
2024-05-25 01:16:37 [INFO]: Epoch 082 - generator training loss: -0.0435, discriminator training loss: 0.1453, validation loss: 0.0765
2024-05-25 01:16:41 [INFO]: Epoch 083 - generator training loss: -0.0433, discriminator training loss: 0.1449, validation loss: 0.0767
2024-05-25 01:16:45 [INFO]: Epoch 084 - generator training loss: -0.0418, discriminator training loss: 0.1446, validation loss: 0.0772
2024-05-25 01:16:49 [INFO]: Epoch 085 - generator training loss: -0.0422, discriminator training loss: 0.1438, validation loss: 0.0756
2024-05-25 01:16:53 [INFO]: Epoch 086 - generator training loss: -0.0426, discriminator training loss: 0.1439, validation loss: 0.0755
2024-05-25 01:16:57 [INFO]: Epoch 087 - generator training loss: -0.0431, discriminator training loss: 0.1433, validation loss: 0.0751
2024-05-25 01:17:02 [INFO]: Epoch 088 - generator training loss: -0.0429, discriminator training loss: 0.1430, validation loss: 0.0757
2024-05-25 01:17:06 [INFO]: Epoch 089 - generator training loss: -0.0431, discriminator training loss: 0.1425, validation loss: 0.0748
2024-05-25 01:17:10 [INFO]: Epoch 090 - generator training loss: -0.0432, discriminator training loss: 0.1419, validation loss: 0.0744
2024-05-25 01:17:14 [INFO]: Epoch 091 - generator training loss: -0.0437, discriminator training loss: 0.1420, validation loss: 0.0742
2024-05-25 01:17:18 [INFO]: Epoch 092 - generator training loss: -0.0430, discriminator training loss: 0.1413, validation loss: 0.0743
2024-05-25 01:17:22 [INFO]: Epoch 093 - generator training loss: -0.0434, discriminator training loss: 0.1413, validation loss: 0.0740
2024-05-25 01:17:26 [INFO]: Epoch 094 - generator training loss: -0.0431, discriminator training loss: 0.1414, validation loss: 0.0744
2024-05-25 01:17:30 [INFO]: Epoch 095 - generator training loss: -0.0429, discriminator training loss: 0.1407, validation loss: 0.0735
2024-05-25 01:17:34 [INFO]: Epoch 096 - generator training loss: -0.0426, discriminator training loss: 0.1404, validation loss: 0.0734
2024-05-25 01:17:39 [INFO]: Epoch 097 - generator training loss: -0.0429, discriminator training loss: 0.1404, validation loss: 0.0738
2024-05-25 01:17:43 [INFO]: Epoch 098 - generator training loss: -0.0429, discriminator training loss: 0.1398, validation loss: 0.0725
2024-05-25 01:17:47 [INFO]: Epoch 099 - generator training loss: -0.0426, discriminator training loss: 0.1393, validation loss: 0.0728
2024-05-25 01:17:51 [INFO]: Epoch 100 - generator training loss: -0.0432, discriminator training loss: 0.1392, validation loss: 0.0728
2024-05-25 01:17:55 [INFO]: Epoch 101 - generator training loss: -0.0430, discriminator training loss: 0.1387, validation loss: 0.0723
2024-05-25 01:17:59 [INFO]: Epoch 102 - generator training loss: -0.0430, discriminator training loss: 0.1389, validation loss: 0.0718
2024-05-25 01:18:03 [INFO]: Epoch 103 - generator training loss: -0.0436, discriminator training loss: 0.1384, validation loss: 0.0732
2024-05-25 01:18:07 [INFO]: Epoch 104 - generator training loss: -0.0427, discriminator training loss: 0.1383, validation loss: 0.0719
2024-05-25 01:18:11 [INFO]: Epoch 105 - generator training loss: -0.0432, discriminator training loss: 0.1382, validation loss: 0.0710
2024-05-25 01:18:15 [INFO]: Epoch 106 - generator training loss: -0.0445, discriminator training loss: 0.1382, validation loss: 0.0718
2024-05-25 01:18:20 [INFO]: Epoch 107 - generator training loss: -0.0442, discriminator training loss: 0.1376, validation loss: 0.0718
2024-05-25 01:18:24 [INFO]: Epoch 108 - generator training loss: -0.0432, discriminator training loss: 0.1378, validation loss: 0.0714
2024-05-25 01:18:28 [INFO]: Epoch 109 - generator training loss: -0.0444, discriminator training loss: 0.1374, validation loss: 0.0715
2024-05-25 01:18:32 [INFO]: Epoch 110 - generator training loss: -0.0443, discriminator training loss: 0.1370, validation loss: 0.0708
2024-05-25 01:18:36 [INFO]: Epoch 111 - generator training loss: -0.0424, discriminator training loss: 0.1367, validation loss: 0.0718
2024-05-25 01:18:40 [INFO]: Epoch 112 - generator training loss: -0.0436, discriminator training loss: 0.1368, validation loss: 0.0713
2024-05-25 01:18:44 [INFO]: Epoch 113 - generator training loss: -0.0439, discriminator training loss: 0.1365, validation loss: 0.0709
2024-05-25 01:18:48 [INFO]: Epoch 114 - generator training loss: -0.0445, discriminator training loss: 0.1366, validation loss: 0.0706
2024-05-25 01:18:52 [INFO]: Epoch 115 - generator training loss: -0.0448, discriminator training loss: 0.1361, validation loss: 0.0704
2024-05-25 01:18:56 [INFO]: Epoch 116 - generator training loss: -0.0453, discriminator training loss: 0.1362, validation loss: 0.0713
2024-05-25 01:19:00 [INFO]: Epoch 117 - generator training loss: -0.0453, discriminator training loss: 0.1361, validation loss: 0.0698
2024-05-25 01:19:05 [INFO]: Epoch 118 - generator training loss: -0.0446, discriminator training loss: 0.1358, validation loss: 0.0703
2024-05-25 01:19:09 [INFO]: Epoch 119 - generator training loss: -0.0455, discriminator training loss: 0.1356, validation loss: 0.0703
2024-05-25 01:19:13 [INFO]: Epoch 120 - generator training loss: -0.0451, discriminator training loss: 0.1352, validation loss: 0.0698
2024-05-25 01:19:17 [INFO]: Epoch 121 - generator training loss: -0.0455, discriminator training loss: 0.1355, validation loss: 0.0702
2024-05-25 01:19:21 [INFO]: Epoch 122 - generator training loss: -0.0452, discriminator training loss: 0.1351, validation loss: 0.0704
2024-05-25 01:19:25 [INFO]: Epoch 123 - generator training loss: -0.0457, discriminator training loss: 0.1350, validation loss: 0.0699
2024-05-25 01:19:29 [INFO]: Epoch 124 - generator training loss: -0.0461, discriminator training loss: 0.1346, validation loss: 0.0698
2024-05-25 01:19:33 [INFO]: Epoch 125 - generator training loss: -0.0454, discriminator training loss: 0.1348, validation loss: 0.0695
2024-05-25 01:19:37 [INFO]: Epoch 126 - generator training loss: -0.0459, discriminator training loss: 0.1345, validation loss: 0.0695
2024-05-25 01:19:42 [INFO]: Epoch 127 - generator training loss: -0.0458, discriminator training loss: 0.1346, validation loss: 0.0693
2024-05-25 01:19:46 [INFO]: Epoch 128 - generator training loss: -0.0459, discriminator training loss: 0.1343, validation loss: 0.0693
2024-05-25 01:19:50 [INFO]: Epoch 129 - generator training loss: -0.0463, discriminator training loss: 0.1345, validation loss: 0.0694
2024-05-25 01:19:54 [INFO]: Epoch 130 - generator training loss: -0.0459, discriminator training loss: 0.1339, validation loss: 0.0691
2024-05-25 01:19:58 [INFO]: Epoch 131 - generator training loss: -0.0467, discriminator training loss: 0.1342, validation loss: 0.0690
2024-05-25 01:20:02 [INFO]: Epoch 132 - generator training loss: -0.0468, discriminator training loss: 0.1334, validation loss: 0.0686
2024-05-25 01:20:06 [INFO]: Epoch 133 - generator training loss: -0.0462, discriminator training loss: 0.1338, validation loss: 0.0686
2024-05-25 01:20:10 [INFO]: Epoch 134 - generator training loss: -0.0469, discriminator training loss: 0.1336, validation loss: 0.0695
2024-05-25 01:20:14 [INFO]: Epoch 135 - generator training loss: -0.0461, discriminator training loss: 0.1337, validation loss: 0.0691
2024-05-25 01:20:19 [INFO]: Epoch 136 - generator training loss: -0.0465, discriminator training loss: 0.1333, validation loss: 0.0684
2024-05-25 01:20:23 [INFO]: Epoch 137 - generator training loss: -0.0476, discriminator training loss: 0.1334, validation loss: 0.0687
2024-05-25 01:20:27 [INFO]: Epoch 138 - generator training loss: -0.0467, discriminator training loss: 0.1332, validation loss: 0.0677
2024-05-25 01:20:31 [INFO]: Epoch 139 - generator training loss: -0.0467, discriminator training loss: 0.1331, validation loss: 0.0698
2024-05-25 01:20:35 [INFO]: Epoch 140 - generator training loss: -0.0464, discriminator training loss: 0.1331, validation loss: 0.0693
2024-05-25 01:20:39 [INFO]: Epoch 141 - generator training loss: -0.0473, discriminator training loss: 0.1327, validation loss: 0.0677
2024-05-25 01:20:43 [INFO]: Epoch 142 - generator training loss: -0.0468, discriminator training loss: 0.1323, validation loss: 0.0689
2024-05-25 01:20:47 [INFO]: Epoch 143 - generator training loss: -0.0471, discriminator training loss: 0.1328, validation loss: 0.0680
2024-05-25 01:20:51 [INFO]: Epoch 144 - generator training loss: -0.0470, discriminator training loss: 0.1327, validation loss: 0.0732
2024-05-25 01:20:55 [INFO]: Epoch 145 - generator training loss: -0.0448, discriminator training loss: 0.1321, validation loss: 0.0684
2024-05-25 01:21:00 [INFO]: Epoch 146 - generator training loss: -0.0459, discriminator training loss: 0.1325, validation loss: 0.0677
2024-05-25 01:21:04 [INFO]: Epoch 147 - generator training loss: -0.0471, discriminator training loss: 0.1325, validation loss: 0.0678
2024-05-25 01:21:08 [INFO]: Epoch 148 - generator training loss: -0.0474, discriminator training loss: 0.1325, validation loss: 0.0678
2024-05-25 01:21:12 [INFO]: Epoch 149 - generator training loss: -0.0476, discriminator training loss: 0.1320, validation loss: 0.0678
2024-05-25 01:21:16 [INFO]: Epoch 150 - generator training loss: -0.0478, discriminator training loss: 0.1319, validation loss: 0.0673
2024-05-25 01:21:20 [INFO]: Epoch 151 - generator training loss: -0.0477, discriminator training loss: 0.1317, validation loss: 0.0682
2024-05-25 01:21:24 [INFO]: Epoch 152 - generator training loss: -0.0480, discriminator training loss: 0.1316, validation loss: 0.0676
2024-05-25 01:21:28 [INFO]: Epoch 153 - generator training loss: -0.0476, discriminator training loss: 0.1317, validation loss: 0.0677
2024-05-25 01:21:32 [INFO]: Epoch 154 - generator training loss: -0.0478, discriminator training loss: 0.1320, validation loss: 0.0675
2024-05-25 01:21:37 [INFO]: Epoch 155 - generator training loss: -0.0481, discriminator training loss: 0.1321, validation loss: 0.0676
2024-05-25 01:21:41 [INFO]: Epoch 156 - generator training loss: -0.0483, discriminator training loss: 0.1316, validation loss: 0.0672
2024-05-25 01:21:45 [INFO]: Epoch 157 - generator training loss: -0.0487, discriminator training loss: 0.1317, validation loss: 0.0675
2024-05-25 01:21:49 [INFO]: Epoch 158 - generator training loss: -0.0466, discriminator training loss: 0.1317, validation loss: 0.0692
2024-05-25 01:21:53 [INFO]: Epoch 159 - generator training loss: -0.0465, discriminator training loss: 0.1313, validation loss: 0.0678
2024-05-25 01:21:57 [INFO]: Epoch 160 - generator training loss: -0.0477, discriminator training loss: 0.1317, validation loss: 0.0675
2024-05-25 01:22:01 [INFO]: Epoch 161 - generator training loss: -0.0484, discriminator training loss: 0.1312, validation loss: 0.0674
2024-05-25 01:22:05 [INFO]: Epoch 162 - generator training loss: -0.0484, discriminator training loss: 0.1311, validation loss: 0.0678
2024-05-25 01:22:09 [INFO]: Epoch 163 - generator training loss: -0.0492, discriminator training loss: 0.1315, validation loss: 0.0668
2024-05-25 01:22:14 [INFO]: Epoch 164 - generator training loss: -0.0484, discriminator training loss: 0.1309, validation loss: 0.0667
2024-05-25 01:22:18 [INFO]: Epoch 165 - generator training loss: -0.0491, discriminator training loss: 0.1307, validation loss: 0.0668
2024-05-25 01:22:22 [INFO]: Epoch 166 - generator training loss: -0.0488, discriminator training loss: 0.1308, validation loss: 0.0666
2024-05-25 01:22:26 [INFO]: Epoch 167 - generator training loss: -0.0491, discriminator training loss: 0.1305, validation loss: 0.0666
2024-05-25 01:22:30 [INFO]: Epoch 168 - generator training loss: -0.0491, discriminator training loss: 0.1308, validation loss: 0.0667
2024-05-25 01:22:34 [INFO]: Epoch 169 - generator training loss: -0.0490, discriminator training loss: 0.1308, validation loss: 0.0668
2024-05-25 01:22:38 [INFO]: Epoch 170 - generator training loss: -0.0492, discriminator training loss: 0.1306, validation loss: 0.0681
2024-05-25 01:22:42 [INFO]: Epoch 171 - generator training loss: -0.0484, discriminator training loss: 0.1305, validation loss: 0.0669
2024-05-25 01:22:46 [INFO]: Epoch 172 - generator training loss: -0.0482, discriminator training loss: 0.1304, validation loss: 0.0677
2024-05-25 01:22:50 [INFO]: Epoch 173 - generator training loss: -0.0490, discriminator training loss: 0.1303, validation loss: 0.0660
2024-05-25 01:22:55 [INFO]: Epoch 174 - generator training loss: -0.0491, discriminator training loss: 0.1303, validation loss: 0.0661
2024-05-25 01:22:59 [INFO]: Epoch 175 - generator training loss: -0.0490, discriminator training loss: 0.1302, validation loss: 0.0672
2024-05-25 01:23:03 [INFO]: Epoch 176 - generator training loss: -0.0490, discriminator training loss: 0.1303, validation loss: 0.0656
2024-05-25 01:23:07 [INFO]: Epoch 177 - generator training loss: -0.0499, discriminator training loss: 0.1300, validation loss: 0.0662
2024-05-25 01:23:11 [INFO]: Epoch 178 - generator training loss: -0.0500, discriminator training loss: 0.1303, validation loss: 0.0660
2024-05-25 01:23:15 [INFO]: Epoch 179 - generator training loss: -0.0505, discriminator training loss: 0.1298, validation loss: 0.0660
2024-05-25 01:23:19 [INFO]: Epoch 180 - generator training loss: -0.0509, discriminator training loss: 0.1303, validation loss: 0.0663
2024-05-25 01:23:23 [INFO]: Epoch 181 - generator training loss: -0.0499, discriminator training loss: 0.1296, validation loss: 0.0656
2024-05-25 01:23:27 [INFO]: Epoch 182 - generator training loss: -0.0500, discriminator training loss: 0.1297, validation loss: 0.0657
2024-05-25 01:23:31 [INFO]: Epoch 183 - generator training loss: -0.0503, discriminator training loss: 0.1297, validation loss: 0.0659
2024-05-25 01:23:35 [INFO]: Epoch 184 - generator training loss: -0.0499, discriminator training loss: 0.1298, validation loss: 0.0659
2024-05-25 01:23:40 [INFO]: Epoch 185 - generator training loss: -0.0508, discriminator training loss: 0.1296, validation loss: 0.0665
2024-05-25 01:23:44 [INFO]: Epoch 186 - generator training loss: -0.0504, discriminator training loss: 0.1297, validation loss: 0.0652
2024-05-25 01:23:48 [INFO]: Epoch 187 - generator training loss: -0.0508, discriminator training loss: 0.1292, validation loss: 0.0660
2024-05-25 01:23:52 [INFO]: Epoch 188 - generator training loss: -0.0494, discriminator training loss: 0.1297, validation loss: 0.0665
2024-05-25 01:23:56 [INFO]: Epoch 189 - generator training loss: -0.0502, discriminator training loss: 0.1293, validation loss: 0.0654
2024-05-25 01:24:00 [INFO]: Epoch 190 - generator training loss: -0.0506, discriminator training loss: 0.1295, validation loss: 0.0667
2024-05-25 01:24:04 [INFO]: Epoch 191 - generator training loss: -0.0510, discriminator training loss: 0.1293, validation loss: 0.0664
2024-05-25 01:24:08 [INFO]: Epoch 192 - generator training loss: -0.0501, discriminator training loss: 0.1296, validation loss: 0.0660
2024-05-25 01:24:12 [INFO]: Epoch 193 - generator training loss: -0.0506, discriminator training loss: 0.1292, validation loss: 0.0681
2024-05-25 01:24:17 [INFO]: Epoch 194 - generator training loss: -0.0506, discriminator training loss: 0.1291, validation loss: 0.0658
2024-05-25 01:24:21 [INFO]: Epoch 195 - generator training loss: -0.0506, discriminator training loss: 0.1292, validation loss: 0.0668
2024-05-25 01:24:25 [INFO]: Epoch 196 - generator training loss: -0.0505, discriminator training loss: 0.1288, validation loss: 0.0668
2024-05-25 01:24:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:24:25 [INFO]: Finished training. The best model is from epoch#186.
2024-05-25 01:24:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T011059/USGAN.pypots
2024-05-25 01:24:25 [INFO]: US-GAN on Air-Quality: MAE=0.1399, MSE=0.0855
2024-05-25 01:24:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 01:24:25 [INFO]: Using the given device: cuda:0
2024-05-25 01:24:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T012425
2024-05-25 01:24:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T012425/tensorboard
2024-05-25 01:24:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 01:24:29 [INFO]: Epoch 001 - training loss: 1.4024, validation loss: 0.9155
2024-05-25 01:24:32 [INFO]: Epoch 002 - training loss: 1.1328, validation loss: 0.6857
2024-05-25 01:24:35 [INFO]: Epoch 003 - training loss: 0.9435, validation loss: 0.5780
2024-05-25 01:24:38 [INFO]: Epoch 004 - training loss: 0.8359, validation loss: 0.5098
2024-05-25 01:24:40 [INFO]: Epoch 005 - training loss: 0.7616, validation loss: 0.4617
2024-05-25 01:24:43 [INFO]: Epoch 006 - training loss: 0.7066, validation loss: 0.4249
2024-05-25 01:24:46 [INFO]: Epoch 007 - training loss: 0.6630, validation loss: 0.3955
2024-05-25 01:24:49 [INFO]: Epoch 008 - training loss: 0.6286, validation loss: 0.3728
2024-05-25 01:24:52 [INFO]: Epoch 009 - training loss: 0.6014, validation loss: 0.3517
2024-05-25 01:24:54 [INFO]: Epoch 010 - training loss: 0.5802, validation loss: 0.3364
2024-05-25 01:24:57 [INFO]: Epoch 011 - training loss: 0.5628, validation loss: 0.3225
2024-05-25 01:25:00 [INFO]: Epoch 012 - training loss: 0.5479, validation loss: 0.3093
2024-05-25 01:25:03 [INFO]: Epoch 013 - training loss: 0.5339, validation loss: 0.2979
2024-05-25 01:25:06 [INFO]: Epoch 014 - training loss: 0.5239, validation loss: 0.2891
2024-05-25 01:25:08 [INFO]: Epoch 015 - training loss: 0.5125, validation loss: 0.2805
2024-05-25 01:25:11 [INFO]: Epoch 016 - training loss: 0.5018, validation loss: 0.2729
2024-05-25 01:25:14 [INFO]: Epoch 017 - training loss: 0.4947, validation loss: 0.2660
2024-05-25 01:25:17 [INFO]: Epoch 018 - training loss: 0.4845, validation loss: 0.2594
2024-05-25 01:25:20 [INFO]: Epoch 019 - training loss: 0.4763, validation loss: 0.2539
2024-05-25 01:25:23 [INFO]: Epoch 020 - training loss: 0.4694, validation loss: 0.2484
2024-05-25 01:25:25 [INFO]: Epoch 021 - training loss: 0.4623, validation loss: 0.2431
2024-05-25 01:25:28 [INFO]: Epoch 022 - training loss: 0.4560, validation loss: 0.2385
2024-05-25 01:25:31 [INFO]: Epoch 023 - training loss: 0.4498, validation loss: 0.2336
2024-05-25 01:25:34 [INFO]: Epoch 024 - training loss: 0.4432, validation loss: 0.2295
2024-05-25 01:25:37 [INFO]: Epoch 025 - training loss: 0.4367, validation loss: 0.2252
2024-05-25 01:25:39 [INFO]: Epoch 026 - training loss: 0.4319, validation loss: 0.2211
2024-05-25 01:25:42 [INFO]: Epoch 027 - training loss: 0.4259, validation loss: 0.2169
2024-05-25 01:25:45 [INFO]: Epoch 028 - training loss: 0.4214, validation loss: 0.2136
2024-05-25 01:25:48 [INFO]: Epoch 029 - training loss: 0.4162, validation loss: 0.2102
2024-05-25 01:25:51 [INFO]: Epoch 030 - training loss: 0.4116, validation loss: 0.2064
2024-05-25 01:25:53 [INFO]: Epoch 031 - training loss: 0.4073, validation loss: 0.2037
2024-05-25 01:25:56 [INFO]: Epoch 032 - training loss: 0.4038, validation loss: 0.2005
2024-05-25 01:25:59 [INFO]: Epoch 033 - training loss: 0.3991, validation loss: 0.1970
2024-05-25 01:26:02 [INFO]: Epoch 034 - training loss: 0.3955, validation loss: 0.1943
2024-05-25 01:26:05 [INFO]: Epoch 035 - training loss: 0.3909, validation loss: 0.1906
2024-05-25 01:26:07 [INFO]: Epoch 036 - training loss: 0.3866, validation loss: 0.1884
2024-05-25 01:26:10 [INFO]: Epoch 037 - training loss: 0.3835, validation loss: 0.1852
2024-05-25 01:26:13 [INFO]: Epoch 038 - training loss: 0.3801, validation loss: 0.1827
2024-05-25 01:26:16 [INFO]: Epoch 039 - training loss: 0.3783, validation loss: 0.1805
2024-05-25 01:26:19 [INFO]: Epoch 040 - training loss: 0.3730, validation loss: 0.1779
2024-05-25 01:26:21 [INFO]: Epoch 041 - training loss: 0.3698, validation loss: 0.1754
2024-05-25 01:26:24 [INFO]: Epoch 042 - training loss: 0.3670, validation loss: 0.1734
2024-05-25 01:26:27 [INFO]: Epoch 043 - training loss: 0.3636, validation loss: 0.1711
2024-05-25 01:26:30 [INFO]: Epoch 044 - training loss: 0.3608, validation loss: 0.1692
2024-05-25 01:26:33 [INFO]: Epoch 045 - training loss: 0.3582, validation loss: 0.1673
2024-05-25 01:26:35 [INFO]: Epoch 046 - training loss: 0.3562, validation loss: 0.1657
2024-05-25 01:26:38 [INFO]: Epoch 047 - training loss: 0.3536, validation loss: 0.1636
2024-05-25 01:26:41 [INFO]: Epoch 048 - training loss: 0.3505, validation loss: 0.1615
2024-05-25 01:26:44 [INFO]: Epoch 049 - training loss: 0.3493, validation loss: 0.1603
2024-05-25 01:26:47 [INFO]: Epoch 050 - training loss: 0.3462, validation loss: 0.1578
2024-05-25 01:26:50 [INFO]: Epoch 051 - training loss: 0.3440, validation loss: 0.1563
2024-05-25 01:26:52 [INFO]: Epoch 052 - training loss: 0.3419, validation loss: 0.1553
2024-05-25 01:26:55 [INFO]: Epoch 053 - training loss: 0.3395, validation loss: 0.1534
2024-05-25 01:26:58 [INFO]: Epoch 054 - training loss: 0.3375, validation loss: 0.1520
2024-05-25 01:27:01 [INFO]: Epoch 055 - training loss: 0.3353, validation loss: 0.1508
2024-05-25 01:27:04 [INFO]: Epoch 056 - training loss: 0.3348, validation loss: 0.1496
2024-05-25 01:27:06 [INFO]: Epoch 057 - training loss: 0.3319, validation loss: 0.1479
2024-05-25 01:27:09 [INFO]: Epoch 058 - training loss: 0.3299, validation loss: 0.1468
2024-05-25 01:27:12 [INFO]: Epoch 059 - training loss: 0.3304, validation loss: 0.1460
2024-05-25 01:27:15 [INFO]: Epoch 060 - training loss: 0.3270, validation loss: 0.1443
2024-05-25 01:27:18 [INFO]: Epoch 061 - training loss: 0.3255, validation loss: 0.1429
2024-05-25 01:27:20 [INFO]: Epoch 062 - training loss: 0.3235, validation loss: 0.1418
2024-05-25 01:27:23 [INFO]: Epoch 063 - training loss: 0.3217, validation loss: 0.1407
2024-05-25 01:27:26 [INFO]: Epoch 064 - training loss: 0.3207, validation loss: 0.1399
2024-05-25 01:27:29 [INFO]: Epoch 065 - training loss: 0.3202, validation loss: 0.1388
2024-05-25 01:27:32 [INFO]: Epoch 066 - training loss: 0.3181, validation loss: 0.1377
2024-05-25 01:27:34 [INFO]: Epoch 067 - training loss: 0.3169, validation loss: 0.1369
2024-05-25 01:27:37 [INFO]: Epoch 068 - training loss: 0.3158, validation loss: 0.1357
2024-05-25 01:27:40 [INFO]: Epoch 069 - training loss: 0.3144, validation loss: 0.1352
2024-05-25 01:27:43 [INFO]: Epoch 070 - training loss: 0.3136, validation loss: 0.1339
2024-05-25 01:27:46 [INFO]: Epoch 071 - training loss: 0.3127, validation loss: 0.1330
2024-05-25 01:27:48 [INFO]: Epoch 072 - training loss: 0.3110, validation loss: 0.1323
2024-05-25 01:27:51 [INFO]: Epoch 073 - training loss: 0.3095, validation loss: 0.1314
2024-05-25 01:27:54 [INFO]: Epoch 074 - training loss: 0.3084, validation loss: 0.1307
2024-05-25 01:27:57 [INFO]: Epoch 075 - training loss: 0.3079, validation loss: 0.1296
2024-05-25 01:28:00 [INFO]: Epoch 076 - training loss: 0.3061, validation loss: 0.1288
2024-05-25 01:28:02 [INFO]: Epoch 077 - training loss: 0.3056, validation loss: 0.1279
2024-05-25 01:28:05 [INFO]: Epoch 078 - training loss: 0.3047, validation loss: 0.1273
2024-05-25 01:28:08 [INFO]: Epoch 079 - training loss: 0.3041, validation loss: 0.1264
2024-05-25 01:28:11 [INFO]: Epoch 080 - training loss: 0.3027, validation loss: 0.1256
2024-05-25 01:28:14 [INFO]: Epoch 081 - training loss: 0.3024, validation loss: 0.1250
2024-05-25 01:28:16 [INFO]: Epoch 082 - training loss: 0.3006, validation loss: 0.1240
2024-05-25 01:28:19 [INFO]: Epoch 083 - training loss: 0.3007, validation loss: 0.1233
2024-05-25 01:28:22 [INFO]: Epoch 084 - training loss: 0.2986, validation loss: 0.1226
2024-05-25 01:28:25 [INFO]: Epoch 085 - training loss: 0.2988, validation loss: 0.1220
2024-05-25 01:28:28 [INFO]: Epoch 086 - training loss: 0.2980, validation loss: 0.1214
2024-05-25 01:28:31 [INFO]: Epoch 087 - training loss: 0.2969, validation loss: 0.1208
2024-05-25 01:28:33 [INFO]: Epoch 088 - training loss: 0.2954, validation loss: 0.1199
2024-05-25 01:28:36 [INFO]: Epoch 089 - training loss: 0.2950, validation loss: 0.1194
2024-05-25 01:28:39 [INFO]: Epoch 090 - training loss: 0.2941, validation loss: 0.1189
2024-05-25 01:28:42 [INFO]: Epoch 091 - training loss: 0.2941, validation loss: 0.1181
2024-05-25 01:28:45 [INFO]: Epoch 092 - training loss: 0.2928, validation loss: 0.1175
2024-05-25 01:28:47 [INFO]: Epoch 093 - training loss: 0.2923, validation loss: 0.1169
2024-05-25 01:28:50 [INFO]: Epoch 094 - training loss: 0.2911, validation loss: 0.1164
2024-05-25 01:28:53 [INFO]: Epoch 095 - training loss: 0.2909, validation loss: 0.1158
2024-05-25 01:28:56 [INFO]: Epoch 096 - training loss: 0.2901, validation loss: 0.1151
2024-05-25 01:28:59 [INFO]: Epoch 097 - training loss: 0.2898, validation loss: 0.1146
2024-05-25 01:29:01 [INFO]: Epoch 098 - training loss: 0.2883, validation loss: 0.1141
2024-05-25 01:29:04 [INFO]: Epoch 099 - training loss: 0.2879, validation loss: 0.1135
2024-05-25 01:29:07 [INFO]: Epoch 100 - training loss: 0.2876, validation loss: 0.1128
2024-05-25 01:29:10 [INFO]: Epoch 101 - training loss: 0.2868, validation loss: 0.1123
2024-05-25 01:29:13 [INFO]: Epoch 102 - training loss: 0.2867, validation loss: 0.1119
2024-05-25 01:29:15 [INFO]: Epoch 103 - training loss: 0.2859, validation loss: 0.1114
2024-05-25 01:29:18 [INFO]: Epoch 104 - training loss: 0.2853, validation loss: 0.1107
2024-05-25 01:29:21 [INFO]: Epoch 105 - training loss: 0.2843, validation loss: 0.1102
2024-05-25 01:29:24 [INFO]: Epoch 106 - training loss: 0.2837, validation loss: 0.1098
2024-05-25 01:29:27 [INFO]: Epoch 107 - training loss: 0.2834, validation loss: 0.1094
2024-05-25 01:29:29 [INFO]: Epoch 108 - training loss: 0.2831, validation loss: 0.1088
2024-05-25 01:29:32 [INFO]: Epoch 109 - training loss: 0.2825, validation loss: 0.1084
2024-05-25 01:29:35 [INFO]: Epoch 110 - training loss: 0.2820, validation loss: 0.1079
2024-05-25 01:29:38 [INFO]: Epoch 111 - training loss: 0.2810, validation loss: 0.1075
2024-05-25 01:29:41 [INFO]: Epoch 112 - training loss: 0.2807, validation loss: 0.1069
2024-05-25 01:29:44 [INFO]: Epoch 113 - training loss: 0.2795, validation loss: 0.1067
2024-05-25 01:29:46 [INFO]: Epoch 114 - training loss: 0.2794, validation loss: 0.1063
2024-05-25 01:29:49 [INFO]: Epoch 115 - training loss: 0.2790, validation loss: 0.1058
2024-05-25 01:29:52 [INFO]: Epoch 116 - training loss: 0.2786, validation loss: 0.1054
2024-05-25 01:29:55 [INFO]: Epoch 117 - training loss: 0.2779, validation loss: 0.1049
2024-05-25 01:29:58 [INFO]: Epoch 118 - training loss: 0.2776, validation loss: 0.1045
2024-05-25 01:30:00 [INFO]: Epoch 119 - training loss: 0.2770, validation loss: 0.1042
2024-05-25 01:30:03 [INFO]: Epoch 120 - training loss: 0.2768, validation loss: 0.1038
2024-05-25 01:30:06 [INFO]: Epoch 121 - training loss: 0.2757, validation loss: 0.1032
2024-05-25 01:30:09 [INFO]: Epoch 122 - training loss: 0.2754, validation loss: 0.1030
2024-05-25 01:30:12 [INFO]: Epoch 123 - training loss: 0.2746, validation loss: 0.1026
2024-05-25 01:30:14 [INFO]: Epoch 124 - training loss: 0.2747, validation loss: 0.1021
2024-05-25 01:30:17 [INFO]: Epoch 125 - training loss: 0.2740, validation loss: 0.1018
2024-05-25 01:30:20 [INFO]: Epoch 126 - training loss: 0.2740, validation loss: 0.1014
2024-05-25 01:30:23 [INFO]: Epoch 127 - training loss: 0.2728, validation loss: 0.1012
2024-05-25 01:30:26 [INFO]: Epoch 128 - training loss: 0.2728, validation loss: 0.1007
2024-05-25 01:30:28 [INFO]: Epoch 129 - training loss: 0.2728, validation loss: 0.1002
2024-05-25 01:30:31 [INFO]: Epoch 130 - training loss: 0.2717, validation loss: 0.1000
2024-05-25 01:30:34 [INFO]: Epoch 131 - training loss: 0.2711, validation loss: 0.0995
2024-05-25 01:30:37 [INFO]: Epoch 132 - training loss: 0.2711, validation loss: 0.0992
2024-05-25 01:30:40 [INFO]: Epoch 133 - training loss: 0.2705, validation loss: 0.0989
2024-05-25 01:30:42 [INFO]: Epoch 134 - training loss: 0.2706, validation loss: 0.0986
2024-05-25 01:30:45 [INFO]: Epoch 135 - training loss: 0.2697, validation loss: 0.0982
2024-05-25 01:30:48 [INFO]: Epoch 136 - training loss: 0.2694, validation loss: 0.0978
2024-05-25 01:30:51 [INFO]: Epoch 137 - training loss: 0.2690, validation loss: 0.0975
2024-05-25 01:30:54 [INFO]: Epoch 138 - training loss: 0.2687, validation loss: 0.0972
2024-05-25 01:30:56 [INFO]: Epoch 139 - training loss: 0.2686, validation loss: 0.0969
2024-05-25 01:30:59 [INFO]: Epoch 140 - training loss: 0.2682, validation loss: 0.0965
2024-05-25 01:31:02 [INFO]: Epoch 141 - training loss: 0.2672, validation loss: 0.0963
2024-05-25 01:31:05 [INFO]: Epoch 142 - training loss: 0.2668, validation loss: 0.0959
2024-05-25 01:31:08 [INFO]: Epoch 143 - training loss: 0.2669, validation loss: 0.0957
2024-05-25 01:31:11 [INFO]: Epoch 144 - training loss: 0.2666, validation loss: 0.0952
2024-05-25 01:31:13 [INFO]: Epoch 145 - training loss: 0.2661, validation loss: 0.0951
2024-05-25 01:31:16 [INFO]: Epoch 146 - training loss: 0.2653, validation loss: 0.0947
2024-05-25 01:31:19 [INFO]: Epoch 147 - training loss: 0.2649, validation loss: 0.0944
2024-05-25 01:31:22 [INFO]: Epoch 148 - training loss: 0.2650, validation loss: 0.0940
2024-05-25 01:31:25 [INFO]: Epoch 149 - training loss: 0.2647, validation loss: 0.0938
2024-05-25 01:31:27 [INFO]: Epoch 150 - training loss: 0.2642, validation loss: 0.0936
2024-05-25 01:31:30 [INFO]: Epoch 151 - training loss: 0.2639, validation loss: 0.0932
2024-05-25 01:31:33 [INFO]: Epoch 152 - training loss: 0.2632, validation loss: 0.0930
2024-05-25 01:31:36 [INFO]: Epoch 153 - training loss: 0.2635, validation loss: 0.0928
2024-05-25 01:31:39 [INFO]: Epoch 154 - training loss: 0.2630, validation loss: 0.0925
2024-05-25 01:31:41 [INFO]: Epoch 155 - training loss: 0.2622, validation loss: 0.0923
2024-05-25 01:31:44 [INFO]: Epoch 156 - training loss: 0.2621, validation loss: 0.0921
2024-05-25 01:31:47 [INFO]: Epoch 157 - training loss: 0.2617, validation loss: 0.0917
2024-05-25 01:31:50 [INFO]: Epoch 158 - training loss: 0.2612, validation loss: 0.0915
2024-05-25 01:31:53 [INFO]: Epoch 159 - training loss: 0.2608, validation loss: 0.0915
2024-05-25 01:31:55 [INFO]: Epoch 160 - training loss: 0.2611, validation loss: 0.0910
2024-05-25 01:31:58 [INFO]: Epoch 161 - training loss: 0.2609, validation loss: 0.0908
2024-05-25 01:32:01 [INFO]: Epoch 162 - training loss: 0.2601, validation loss: 0.0904
2024-05-25 01:32:04 [INFO]: Epoch 163 - training loss: 0.2602, validation loss: 0.0901
2024-05-25 01:32:07 [INFO]: Epoch 164 - training loss: 0.2597, validation loss: 0.0898
2024-05-25 01:32:09 [INFO]: Epoch 165 - training loss: 0.2591, validation loss: 0.0899
2024-05-25 01:32:12 [INFO]: Epoch 166 - training loss: 0.2595, validation loss: 0.0897
2024-05-25 01:32:15 [INFO]: Epoch 167 - training loss: 0.2593, validation loss: 0.0894
2024-05-25 01:32:18 [INFO]: Epoch 168 - training loss: 0.2590, validation loss: 0.0891
2024-05-25 01:32:21 [INFO]: Epoch 169 - training loss: 0.2584, validation loss: 0.0889
2024-05-25 01:32:23 [INFO]: Epoch 170 - training loss: 0.2583, validation loss: 0.0887
2024-05-25 01:32:26 [INFO]: Epoch 171 - training loss: 0.2577, validation loss: 0.0884
2024-05-25 01:32:29 [INFO]: Epoch 172 - training loss: 0.2578, validation loss: 0.0883
2024-05-25 01:32:32 [INFO]: Epoch 173 - training loss: 0.2566, validation loss: 0.0880
2024-05-25 01:32:35 [INFO]: Epoch 174 - training loss: 0.2576, validation loss: 0.0878
2024-05-25 01:32:37 [INFO]: Epoch 175 - training loss: 0.2570, validation loss: 0.0875
2024-05-25 01:32:40 [INFO]: Epoch 176 - training loss: 0.2569, validation loss: 0.0874
2024-05-25 01:32:43 [INFO]: Epoch 177 - training loss: 0.2562, validation loss: 0.0872
2024-05-25 01:32:46 [INFO]: Epoch 178 - training loss: 0.2566, validation loss: 0.0869
2024-05-25 01:32:49 [INFO]: Epoch 179 - training loss: 0.2554, validation loss: 0.0868
2024-05-25 01:32:52 [INFO]: Epoch 180 - training loss: 0.2552, validation loss: 0.0866
2024-05-25 01:32:54 [INFO]: Epoch 181 - training loss: 0.2550, validation loss: 0.0865
2024-05-25 01:32:57 [INFO]: Epoch 182 - training loss: 0.2549, validation loss: 0.0863
2024-05-25 01:33:00 [INFO]: Epoch 183 - training loss: 0.2546, validation loss: 0.0859
2024-05-25 01:33:03 [INFO]: Epoch 184 - training loss: 0.2548, validation loss: 0.0858
2024-05-25 01:33:06 [INFO]: Epoch 185 - training loss: 0.2540, validation loss: 0.0857
2024-05-25 01:33:08 [INFO]: Epoch 186 - training loss: 0.2541, validation loss: 0.0855
2024-05-25 01:33:11 [INFO]: Epoch 187 - training loss: 0.2536, validation loss: 0.0852
2024-05-25 01:33:14 [INFO]: Epoch 188 - training loss: 0.2534, validation loss: 0.0852
2024-05-25 01:33:17 [INFO]: Epoch 189 - training loss: 0.2532, validation loss: 0.0850
2024-05-25 01:33:20 [INFO]: Epoch 190 - training loss: 0.2528, validation loss: 0.0847
2024-05-25 01:33:22 [INFO]: Epoch 191 - training loss: 0.2529, validation loss: 0.0847
2024-05-25 01:33:25 [INFO]: Epoch 192 - training loss: 0.2524, validation loss: 0.0844
2024-05-25 01:33:28 [INFO]: Epoch 193 - training loss: 0.2519, validation loss: 0.0845
2024-05-25 01:33:31 [INFO]: Epoch 194 - training loss: 0.2524, validation loss: 0.0840
2024-05-25 01:33:34 [INFO]: Epoch 195 - training loss: 0.2523, validation loss: 0.0838
2024-05-25 01:33:36 [INFO]: Epoch 196 - training loss: 0.2520, validation loss: 0.0836
2024-05-25 01:33:39 [INFO]: Epoch 197 - training loss: 0.2513, validation loss: 0.0837
2024-05-25 01:33:42 [INFO]: Epoch 198 - training loss: 0.2514, validation loss: 0.0834
2024-05-25 01:33:45 [INFO]: Epoch 199 - training loss: 0.2508, validation loss: 0.0832
2024-05-25 01:33:48 [INFO]: Epoch 200 - training loss: 0.2505, validation loss: 0.0830
2024-05-25 01:33:50 [INFO]: Epoch 201 - training loss: 0.2510, validation loss: 0.0829
2024-05-25 01:33:53 [INFO]: Epoch 202 - training loss: 0.2505, validation loss: 0.0827
2024-05-25 01:33:56 [INFO]: Epoch 203 - training loss: 0.2501, validation loss: 0.0826
2024-05-25 01:33:59 [INFO]: Epoch 204 - training loss: 0.2498, validation loss: 0.0825
2024-05-25 01:34:02 [INFO]: Epoch 205 - training loss: 0.2496, validation loss: 0.0822
2024-05-25 01:34:04 [INFO]: Epoch 206 - training loss: 0.2497, validation loss: 0.0821
2024-05-25 01:34:07 [INFO]: Epoch 207 - training loss: 0.2493, validation loss: 0.0820
2024-05-25 01:34:10 [INFO]: Epoch 208 - training loss: 0.2491, validation loss: 0.0817
2024-05-25 01:34:13 [INFO]: Epoch 209 - training loss: 0.2490, validation loss: 0.0817
2024-05-25 01:34:16 [INFO]: Epoch 210 - training loss: 0.2488, validation loss: 0.0816
2024-05-25 01:34:19 [INFO]: Epoch 211 - training loss: 0.2490, validation loss: 0.0815
2024-05-25 01:34:21 [INFO]: Epoch 212 - training loss: 0.2487, validation loss: 0.0813
2024-05-25 01:34:24 [INFO]: Epoch 213 - training loss: 0.2482, validation loss: 0.0810
2024-05-25 01:34:27 [INFO]: Epoch 214 - training loss: 0.2480, validation loss: 0.0810
2024-05-25 01:34:30 [INFO]: Epoch 215 - training loss: 0.2481, validation loss: 0.0809
2024-05-25 01:34:33 [INFO]: Epoch 216 - training loss: 0.2473, validation loss: 0.0807
2024-05-25 01:34:35 [INFO]: Epoch 217 - training loss: 0.2478, validation loss: 0.0804
2024-05-25 01:34:38 [INFO]: Epoch 218 - training loss: 0.2475, validation loss: 0.0805
2024-05-25 01:34:41 [INFO]: Epoch 219 - training loss: 0.2472, validation loss: 0.0805
2024-05-25 01:34:44 [INFO]: Epoch 220 - training loss: 0.2466, validation loss: 0.0801
2024-05-25 01:34:47 [INFO]: Epoch 221 - training loss: 0.2464, validation loss: 0.0802
2024-05-25 01:34:49 [INFO]: Epoch 222 - training loss: 0.2461, validation loss: 0.0800
2024-05-25 01:34:52 [INFO]: Epoch 223 - training loss: 0.2463, validation loss: 0.0798
2024-05-25 01:34:55 [INFO]: Epoch 224 - training loss: 0.2459, validation loss: 0.0795
2024-05-25 01:34:58 [INFO]: Epoch 225 - training loss: 0.2460, validation loss: 0.0796
2024-05-25 01:35:01 [INFO]: Epoch 226 - training loss: 0.2454, validation loss: 0.0794
2024-05-25 01:35:03 [INFO]: Epoch 227 - training loss: 0.2456, validation loss: 0.0794
2024-05-25 01:35:06 [INFO]: Epoch 228 - training loss: 0.2456, validation loss: 0.0790
2024-05-25 01:35:09 [INFO]: Epoch 229 - training loss: 0.2454, validation loss: 0.0790
2024-05-25 01:35:12 [INFO]: Epoch 230 - training loss: 0.2454, validation loss: 0.0789
2024-05-25 01:35:15 [INFO]: Epoch 231 - training loss: 0.2451, validation loss: 0.0787
2024-05-25 01:35:18 [INFO]: Epoch 232 - training loss: 0.2450, validation loss: 0.0787
2024-05-25 01:35:20 [INFO]: Epoch 233 - training loss: 0.2443, validation loss: 0.0785
2024-05-25 01:35:23 [INFO]: Epoch 234 - training loss: 0.2445, validation loss: 0.0784
2024-05-25 01:35:26 [INFO]: Epoch 235 - training loss: 0.2443, validation loss: 0.0786
2024-05-25 01:35:29 [INFO]: Epoch 236 - training loss: 0.2446, validation loss: 0.0783
2024-05-25 01:35:32 [INFO]: Epoch 237 - training loss: 0.2442, validation loss: 0.0781
2024-05-25 01:35:34 [INFO]: Epoch 238 - training loss: 0.2437, validation loss: 0.0781
2024-05-25 01:35:37 [INFO]: Epoch 239 - training loss: 0.2435, validation loss: 0.0779
2024-05-25 01:35:40 [INFO]: Epoch 240 - training loss: 0.2434, validation loss: 0.0779
2024-05-25 01:35:43 [INFO]: Epoch 241 - training loss: 0.2429, validation loss: 0.0780
2024-05-25 01:35:46 [INFO]: Epoch 242 - training loss: 0.2432, validation loss: 0.0777
2024-05-25 01:35:48 [INFO]: Epoch 243 - training loss: 0.2431, validation loss: 0.0775
2024-05-25 01:35:51 [INFO]: Epoch 244 - training loss: 0.2427, validation loss: 0.0774
2024-05-25 01:35:54 [INFO]: Epoch 245 - training loss: 0.2423, validation loss: 0.0775
2024-05-25 01:35:57 [INFO]: Epoch 246 - training loss: 0.2430, validation loss: 0.0773
2024-05-25 01:36:00 [INFO]: Epoch 247 - training loss: 0.2422, validation loss: 0.0771
2024-05-25 01:36:02 [INFO]: Epoch 248 - training loss: 0.2429, validation loss: 0.0769
2024-05-25 01:36:05 [INFO]: Epoch 249 - training loss: 0.2420, validation loss: 0.0769
2024-05-25 01:36:08 [INFO]: Epoch 250 - training loss: 0.2418, validation loss: 0.0769
2024-05-25 01:36:11 [INFO]: Epoch 251 - training loss: 0.2418, validation loss: 0.0769
2024-05-25 01:36:14 [INFO]: Epoch 252 - training loss: 0.2417, validation loss: 0.0767
2024-05-25 01:36:16 [INFO]: Epoch 253 - training loss: 0.2412, validation loss: 0.0767
2024-05-25 01:36:19 [INFO]: Epoch 254 - training loss: 0.2408, validation loss: 0.0764
2024-05-25 01:36:22 [INFO]: Epoch 255 - training loss: 0.2413, validation loss: 0.0765
2024-05-25 01:36:25 [INFO]: Epoch 256 - training loss: 0.2409, validation loss: 0.0764
2024-05-25 01:36:28 [INFO]: Epoch 257 - training loss: 0.2407, validation loss: 0.0762
2024-05-25 01:36:30 [INFO]: Epoch 258 - training loss: 0.2405, validation loss: 0.0763
2024-05-25 01:36:33 [INFO]: Epoch 259 - training loss: 0.2404, validation loss: 0.0761
2024-05-25 01:36:36 [INFO]: Epoch 260 - training loss: 0.2398, validation loss: 0.0760
2024-05-25 01:36:39 [INFO]: Epoch 261 - training loss: 0.2398, validation loss: 0.0760
2024-05-25 01:36:42 [INFO]: Epoch 262 - training loss: 0.2399, validation loss: 0.0761
2024-05-25 01:36:44 [INFO]: Epoch 263 - training loss: 0.2404, validation loss: 0.0758
2024-05-25 01:36:47 [INFO]: Epoch 264 - training loss: 0.2401, validation loss: 0.0756
2024-05-25 01:36:50 [INFO]: Epoch 265 - training loss: 0.2404, validation loss: 0.0758
2024-05-25 01:36:53 [INFO]: Epoch 266 - training loss: 0.2392, validation loss: 0.0754
2024-05-25 01:36:56 [INFO]: Epoch 267 - training loss: 0.2391, validation loss: 0.0756
2024-05-25 01:36:59 [INFO]: Epoch 268 - training loss: 0.2393, validation loss: 0.0753
2024-05-25 01:37:01 [INFO]: Epoch 269 - training loss: 0.2400, validation loss: 0.0754
2024-05-25 01:37:04 [INFO]: Epoch 270 - training loss: 0.2401, validation loss: 0.0752
2024-05-25 01:37:07 [INFO]: Epoch 271 - training loss: 0.2391, validation loss: 0.0751
2024-05-25 01:37:10 [INFO]: Epoch 272 - training loss: 0.2384, validation loss: 0.0751
2024-05-25 01:37:13 [INFO]: Epoch 273 - training loss: 0.2385, validation loss: 0.0748
2024-05-25 01:37:15 [INFO]: Epoch 274 - training loss: 0.2387, validation loss: 0.0748
2024-05-25 01:37:18 [INFO]: Epoch 275 - training loss: 0.2382, validation loss: 0.0748
2024-05-25 01:37:21 [INFO]: Epoch 276 - training loss: 0.2382, validation loss: 0.0747
2024-05-25 01:37:24 [INFO]: Epoch 277 - training loss: 0.2381, validation loss: 0.0748
2024-05-25 01:37:27 [INFO]: Epoch 278 - training loss: 0.2379, validation loss: 0.0747
2024-05-25 01:37:29 [INFO]: Epoch 279 - training loss: 0.2383, validation loss: 0.0746
2024-05-25 01:37:32 [INFO]: Epoch 280 - training loss: 0.2380, validation loss: 0.0743
2024-05-25 01:37:35 [INFO]: Epoch 281 - training loss: 0.2375, validation loss: 0.0744
2024-05-25 01:37:38 [INFO]: Epoch 282 - training loss: 0.2372, validation loss: 0.0744
2024-05-25 01:37:41 [INFO]: Epoch 283 - training loss: 0.2377, validation loss: 0.0742
2024-05-25 01:37:43 [INFO]: Epoch 284 - training loss: 0.2373, validation loss: 0.0742
2024-05-25 01:37:46 [INFO]: Epoch 285 - training loss: 0.2369, validation loss: 0.0742
2024-05-25 01:37:49 [INFO]: Epoch 286 - training loss: 0.2373, validation loss: 0.0741
2024-05-25 01:37:52 [INFO]: Epoch 287 - training loss: 0.2370, validation loss: 0.0741
2024-05-25 01:37:55 [INFO]: Epoch 288 - training loss: 0.2367, validation loss: 0.0740
2024-05-25 01:37:57 [INFO]: Epoch 289 - training loss: 0.2365, validation loss: 0.0741
2024-05-25 01:38:00 [INFO]: Epoch 290 - training loss: 0.2367, validation loss: 0.0739
2024-05-25 01:38:03 [INFO]: Epoch 291 - training loss: 0.2369, validation loss: 0.0741
2024-05-25 01:38:06 [INFO]: Epoch 292 - training loss: 0.2363, validation loss: 0.0738
2024-05-25 01:38:09 [INFO]: Epoch 293 - training loss: 0.2361, validation loss: 0.0739
2024-05-25 01:38:11 [INFO]: Epoch 294 - training loss: 0.2353, validation loss: 0.0737
2024-05-25 01:38:14 [INFO]: Epoch 295 - training loss: 0.2360, validation loss: 0.0737
2024-05-25 01:38:17 [INFO]: Epoch 296 - training loss: 0.2356, validation loss: 0.0736
2024-05-25 01:38:20 [INFO]: Epoch 297 - training loss: 0.2359, validation loss: 0.0735
2024-05-25 01:38:23 [INFO]: Epoch 298 - training loss: 0.2353, validation loss: 0.0735
2024-05-25 01:38:25 [INFO]: Epoch 299 - training loss: 0.2351, validation loss: 0.0734
2024-05-25 01:38:28 [INFO]: Epoch 300 - training loss: 0.2350, validation loss: 0.0735
2024-05-25 01:38:28 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 01:38:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T012425/BRITS.pypots
2024-05-25 01:38:29 [INFO]: BRITS on Air-Quality: MAE=0.1371, MSE=0.0947
2024-05-25 01:38:29 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 01:38:29 [INFO]: Using the given device: cuda:0
2024-05-25 01:38:29 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829
2024-05-25 01:38:29 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/tensorboard
2024-05-25 01:38:29 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 01:38:34 [INFO]: Epoch 001 - training loss: 1.4598, validation loss: 0.8032
2024-05-25 01:38:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch1_loss0.8032126128673553.pypots
2024-05-25 01:38:38 [INFO]: Epoch 002 - training loss: 1.0560, validation loss: 0.7470
2024-05-25 01:38:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch2_loss0.7470373272895813.pypots
2024-05-25 01:38:41 [INFO]: Epoch 003 - training loss: 0.9818, validation loss: 0.7267
2024-05-25 01:38:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch3_loss0.7267081826925278.pypots
2024-05-25 01:38:45 [INFO]: Epoch 004 - training loss: 0.9501, validation loss: 0.7143
2024-05-25 01:38:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch4_loss0.7142506033182144.pypots
2024-05-25 01:38:49 [INFO]: Epoch 005 - training loss: 0.9407, validation loss: 0.7057
2024-05-25 01:38:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch5_loss0.7057037234306336.pypots
2024-05-25 01:38:53 [INFO]: Epoch 006 - training loss: 0.9233, validation loss: 0.6997
2024-05-25 01:38:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch6_loss0.6997360289096832.pypots
2024-05-25 01:38:57 [INFO]: Epoch 007 - training loss: 0.9290, validation loss: 0.6940
2024-05-25 01:38:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch7_loss0.6939855873584747.pypots
2024-05-25 01:39:01 [INFO]: Epoch 008 - training loss: 0.9030, validation loss: 0.6904
2024-05-25 01:39:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch8_loss0.6903820246458053.pypots
2024-05-25 01:39:05 [INFO]: Epoch 009 - training loss: 0.9191, validation loss: 0.6870
2024-05-25 01:39:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch9_loss0.6870201379060745.pypots
2024-05-25 01:39:08 [INFO]: Epoch 010 - training loss: 0.9189, validation loss: 0.6845
2024-05-25 01:39:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch10_loss0.6844878524541855.pypots
2024-05-25 01:39:12 [INFO]: Epoch 011 - training loss: 0.9000, validation loss: 0.6823
2024-05-25 01:39:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch11_loss0.6823456406593322.pypots
2024-05-25 01:39:16 [INFO]: Epoch 012 - training loss: 0.9171, validation loss: 0.6812
2024-05-25 01:39:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch12_loss0.6812326103448868.pypots
2024-05-25 01:39:20 [INFO]: Epoch 013 - training loss: 0.8907, validation loss: 0.6805
2024-05-25 01:39:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch13_loss0.6804862082004547.pypots
2024-05-25 01:39:24 [INFO]: Epoch 014 - training loss: 0.8827, validation loss: 0.6787
2024-05-25 01:39:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch14_loss0.6786907643079758.pypots
2024-05-25 01:39:28 [INFO]: Epoch 015 - training loss: 0.8880, validation loss: 0.6783
2024-05-25 01:39:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch15_loss0.6782591938972473.pypots
2024-05-25 01:39:32 [INFO]: Epoch 016 - training loss: 0.8674, validation loss: 0.6786
2024-05-25 01:39:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch16_loss0.6785921066999435.pypots
2024-05-25 01:39:36 [INFO]: Epoch 017 - training loss: 0.8766, validation loss: 0.6800
2024-05-25 01:39:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch17_loss0.6799570828676224.pypots
2024-05-25 01:39:39 [INFO]: Epoch 018 - training loss: 0.8699, validation loss: 0.6770
2024-05-25 01:39:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch18_loss0.6770403861999512.pypots
2024-05-25 01:39:43 [INFO]: Epoch 019 - training loss: 0.8789, validation loss: 0.6769
2024-05-25 01:39:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch19_loss0.6768672347068787.pypots
2024-05-25 01:39:47 [INFO]: Epoch 020 - training loss: 0.8661, validation loss: 0.6778
2024-05-25 01:39:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch20_loss0.6777786999940872.pypots
2024-05-25 01:39:51 [INFO]: Epoch 021 - training loss: 0.8596, validation loss: 0.6757
2024-05-25 01:39:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch21_loss0.6757007032632828.pypots
2024-05-25 01:39:55 [INFO]: Epoch 022 - training loss: 0.8556, validation loss: 0.6759
2024-05-25 01:39:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch22_loss0.6758550584316254.pypots
2024-05-25 01:39:59 [INFO]: Epoch 023 - training loss: 0.8788, validation loss: 0.6751
2024-05-25 01:39:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch23_loss0.6750779926776886.pypots
2024-05-25 01:40:03 [INFO]: Epoch 024 - training loss: 0.8631, validation loss: 0.6754
2024-05-25 01:40:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch24_loss0.6753653854131698.pypots
2024-05-25 01:40:06 [INFO]: Epoch 025 - training loss: 0.8646, validation loss: 0.6759
2024-05-25 01:40:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch25_loss0.6759063631296158.pypots
2024-05-25 01:40:10 [INFO]: Epoch 026 - training loss: 0.8711, validation loss: 0.6752
2024-05-25 01:40:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch26_loss0.67518290579319.pypots
2024-05-25 01:40:14 [INFO]: Epoch 027 - training loss: 0.8651, validation loss: 0.6780
2024-05-25 01:40:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch27_loss0.6779567211866379.pypots
2024-05-25 01:40:18 [INFO]: Epoch 028 - training loss: 0.8601, validation loss: 0.6765
2024-05-25 01:40:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch28_loss0.6765003114938736.pypots
2024-05-25 01:40:22 [INFO]: Epoch 029 - training loss: 0.8548, validation loss: 0.6765
2024-05-25 01:40:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch29_loss0.6764839619398118.pypots
2024-05-25 01:40:26 [INFO]: Epoch 030 - training loss: 0.8412, validation loss: 0.6746
2024-05-25 01:40:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch30_loss0.6746396720409393.pypots
2024-05-25 01:40:30 [INFO]: Epoch 031 - training loss: 0.8686, validation loss: 0.6753
2024-05-25 01:40:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch31_loss0.675345566868782.pypots
2024-05-25 01:40:33 [INFO]: Epoch 032 - training loss: 0.8437, validation loss: 0.6762
2024-05-25 01:40:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch32_loss0.6762341260910034.pypots
2024-05-25 01:40:37 [INFO]: Epoch 033 - training loss: 0.8395, validation loss: 0.6766
2024-05-25 01:40:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch33_loss0.676625519990921.pypots
2024-05-25 01:40:41 [INFO]: Epoch 034 - training loss: 0.8256, validation loss: 0.6797
2024-05-25 01:40:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch34_loss0.6796947389841079.pypots
2024-05-25 01:40:45 [INFO]: Epoch 035 - training loss: 0.8465, validation loss: 0.6780
2024-05-25 01:40:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch35_loss0.6779896706342697.pypots
2024-05-25 01:40:49 [INFO]: Epoch 036 - training loss: 0.8330, validation loss: 0.6778
2024-05-25 01:40:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch36_loss0.6777651160955429.pypots
2024-05-25 01:40:53 [INFO]: Epoch 037 - training loss: 0.8327, validation loss: 0.6777
2024-05-25 01:40:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch37_loss0.6777251571416855.pypots
2024-05-25 01:40:57 [INFO]: Epoch 038 - training loss: 0.8229, validation loss: 0.6777
2024-05-25 01:40:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch38_loss0.6777113497257232.pypots
2024-05-25 01:41:00 [INFO]: Epoch 039 - training loss: 0.8252, validation loss: 0.6802
2024-05-25 01:41:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch39_loss0.6801616370677948.pypots
2024-05-25 01:41:04 [INFO]: Epoch 040 - training loss: 0.8310, validation loss: 0.6793
2024-05-25 01:41:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN_epoch40_loss0.6792931497097016.pypots
2024-05-25 01:41:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:41:04 [INFO]: Finished training. The best model is from epoch#30.
2024-05-25 01:41:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T013829/MRNN.pypots
2024-05-25 01:41:05 [INFO]: MRNN on Air-Quality: MAE=0.5172, MSE=0.5943
2024-05-25 01:41:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 01:41:05 [INFO]: Using the given device: cpu
2024-05-25 01:41:05 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2148
2024-05-25 01:41:05 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 01:41:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 01:41:05 [INFO]: Median on Air-Quality: MAE=0.6653, MSE=0.9982
2024-05-25 01:41:05 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 01:41:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 01:41:05 [INFO]: Mean on Air-Quality: MAE=0.6953, MSE=0.9349
2024-05-25 01:41:05 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 01:41:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 01:41:05 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 01:41:05 [INFO]: Using the given device: cuda:0
2024-05-25 01:41:05 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T014105
2024-05-25 01:41:05 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T014105/tensorboard
2024-05-25 01:41:05 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 01:41:06 [INFO]: Epoch 001 - training loss: 1.0448, validation loss: 0.5042
2024-05-25 01:41:07 [INFO]: Epoch 002 - training loss: 0.7462, validation loss: 0.3788
2024-05-25 01:41:07 [INFO]: Epoch 003 - training loss: 0.6399, validation loss: 0.3014
2024-05-25 01:41:08 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.2618
2024-05-25 01:41:08 [INFO]: Epoch 005 - training loss: 0.5139, validation loss: 0.2388
2024-05-25 01:41:09 [INFO]: Epoch 006 - training loss: 0.4757, validation loss: 0.2243
2024-05-25 01:41:10 [INFO]: Epoch 007 - training loss: 0.4511, validation loss: 0.2135
2024-05-25 01:41:10 [INFO]: Epoch 008 - training loss: 0.4304, validation loss: 0.2055
2024-05-25 01:41:11 [INFO]: Epoch 009 - training loss: 0.4162, validation loss: 0.1988
2024-05-25 01:41:11 [INFO]: Epoch 010 - training loss: 0.4022, validation loss: 0.1940
2024-05-25 01:41:12 [INFO]: Epoch 011 - training loss: 0.3934, validation loss: 0.1882
2024-05-25 01:41:13 [INFO]: Epoch 012 - training loss: 0.3855, validation loss: 0.1843
2024-05-25 01:41:13 [INFO]: Epoch 013 - training loss: 0.3755, validation loss: 0.1810
2024-05-25 01:41:14 [INFO]: Epoch 014 - training loss: 0.3694, validation loss: 0.1776
2024-05-25 01:41:14 [INFO]: Epoch 015 - training loss: 0.3643, validation loss: 0.1746
2024-05-25 01:41:15 [INFO]: Epoch 016 - training loss: 0.3570, validation loss: 0.1708
2024-05-25 01:41:16 [INFO]: Epoch 017 - training loss: 0.3535, validation loss: 0.1694
2024-05-25 01:41:16 [INFO]: Epoch 018 - training loss: 0.3477, validation loss: 0.1653
2024-05-25 01:41:17 [INFO]: Epoch 019 - training loss: 0.3429, validation loss: 0.1642
2024-05-25 01:41:17 [INFO]: Epoch 020 - training loss: 0.3387, validation loss: 0.1618
2024-05-25 01:41:18 [INFO]: Epoch 021 - training loss: 0.3342, validation loss: 0.1585
2024-05-25 01:41:19 [INFO]: Epoch 022 - training loss: 0.3320, validation loss: 0.1571
2024-05-25 01:41:19 [INFO]: Epoch 023 - training loss: 0.3264, validation loss: 0.1555
2024-05-25 01:41:20 [INFO]: Epoch 024 - training loss: 0.3234, validation loss: 0.1543
2024-05-25 01:41:20 [INFO]: Epoch 025 - training loss: 0.3204, validation loss: 0.1519
2024-05-25 01:41:21 [INFO]: Epoch 026 - training loss: 0.3180, validation loss: 0.1508
2024-05-25 01:41:22 [INFO]: Epoch 027 - training loss: 0.3146, validation loss: 0.1481
2024-05-25 01:41:22 [INFO]: Epoch 028 - training loss: 0.3115, validation loss: 0.1478
2024-05-25 01:41:23 [INFO]: Epoch 029 - training loss: 0.3101, validation loss: 0.1455
2024-05-25 01:41:23 [INFO]: Epoch 030 - training loss: 0.3067, validation loss: 0.1463
2024-05-25 01:41:24 [INFO]: Epoch 031 - training loss: 0.3054, validation loss: 0.1437
2024-05-25 01:41:25 [INFO]: Epoch 032 - training loss: 0.3014, validation loss: 0.1422
2024-05-25 01:41:25 [INFO]: Epoch 033 - training loss: 0.2992, validation loss: 0.1401
2024-05-25 01:41:26 [INFO]: Epoch 034 - training loss: 0.2982, validation loss: 0.1389
2024-05-25 01:41:26 [INFO]: Epoch 035 - training loss: 0.2959, validation loss: 0.1377
2024-05-25 01:41:27 [INFO]: Epoch 036 - training loss: 0.2932, validation loss: 0.1369
2024-05-25 01:41:28 [INFO]: Epoch 037 - training loss: 0.2904, validation loss: 0.1353
2024-05-25 01:41:28 [INFO]: Epoch 038 - training loss: 0.2891, validation loss: 0.1343
2024-05-25 01:41:29 [INFO]: Epoch 039 - training loss: 0.2879, validation loss: 0.1332
2024-05-25 01:41:29 [INFO]: Epoch 040 - training loss: 0.2857, validation loss: 0.1321
2024-05-25 01:41:30 [INFO]: Epoch 041 - training loss: 0.2835, validation loss: 0.1308
2024-05-25 01:41:31 [INFO]: Epoch 042 - training loss: 0.2816, validation loss: 0.1304
2024-05-25 01:41:31 [INFO]: Epoch 043 - training loss: 0.2801, validation loss: 0.1292
2024-05-25 01:41:32 [INFO]: Epoch 044 - training loss: 0.2794, validation loss: 0.1284
2024-05-25 01:41:33 [INFO]: Epoch 045 - training loss: 0.2768, validation loss: 0.1270
2024-05-25 01:41:33 [INFO]: Epoch 046 - training loss: 0.2744, validation loss: 0.1262
2024-05-25 01:41:34 [INFO]: Epoch 047 - training loss: 0.2728, validation loss: 0.1262
2024-05-25 01:41:34 [INFO]: Epoch 048 - training loss: 0.2720, validation loss: 0.1245
2024-05-25 01:41:35 [INFO]: Epoch 049 - training loss: 0.2707, validation loss: 0.1237
2024-05-25 01:41:36 [INFO]: Epoch 050 - training loss: 0.2694, validation loss: 0.1224
2024-05-25 01:41:36 [INFO]: Epoch 051 - training loss: 0.2681, validation loss: 0.1220
2024-05-25 01:41:37 [INFO]: Epoch 052 - training loss: 0.2670, validation loss: 0.1208
2024-05-25 01:41:37 [INFO]: Epoch 053 - training loss: 0.2639, validation loss: 0.1203
2024-05-25 01:41:38 [INFO]: Epoch 054 - training loss: 0.2639, validation loss: 0.1208
2024-05-25 01:41:39 [INFO]: Epoch 055 - training loss: 0.2625, validation loss: 0.1193
2024-05-25 01:41:39 [INFO]: Epoch 056 - training loss: 0.2593, validation loss: 0.1185
2024-05-25 01:41:40 [INFO]: Epoch 057 - training loss: 0.2585, validation loss: 0.1175
2024-05-25 01:41:40 [INFO]: Epoch 058 - training loss: 0.2578, validation loss: 0.1181
2024-05-25 01:41:41 [INFO]: Epoch 059 - training loss: 0.2562, validation loss: 0.1174
2024-05-25 01:41:42 [INFO]: Epoch 060 - training loss: 0.2543, validation loss: 0.1160
2024-05-25 01:41:42 [INFO]: Epoch 061 - training loss: 0.2533, validation loss: 0.1151
2024-05-25 01:41:43 [INFO]: Epoch 062 - training loss: 0.2525, validation loss: 0.1154
2024-05-25 01:41:43 [INFO]: Epoch 063 - training loss: 0.2508, validation loss: 0.1150
2024-05-25 01:41:44 [INFO]: Epoch 064 - training loss: 0.2488, validation loss: 0.1143
2024-05-25 01:41:45 [INFO]: Epoch 065 - training loss: 0.2479, validation loss: 0.1148
2024-05-25 01:41:45 [INFO]: Epoch 066 - training loss: 0.2475, validation loss: 0.1140
2024-05-25 01:41:46 [INFO]: Epoch 067 - training loss: 0.2456, validation loss: 0.1136
2024-05-25 01:41:46 [INFO]: Epoch 068 - training loss: 0.2449, validation loss: 0.1120
2024-05-25 01:41:47 [INFO]: Epoch 069 - training loss: 0.2447, validation loss: 0.1134
2024-05-25 01:41:48 [INFO]: Epoch 070 - training loss: 0.2438, validation loss: 0.1114
2024-05-25 01:41:48 [INFO]: Epoch 071 - training loss: 0.2412, validation loss: 0.1118
2024-05-25 01:41:49 [INFO]: Epoch 072 - training loss: 0.2393, validation loss: 0.1119
2024-05-25 01:41:49 [INFO]: Epoch 073 - training loss: 0.2386, validation loss: 0.1110
2024-05-25 01:41:50 [INFO]: Epoch 074 - training loss: 0.2373, validation loss: 0.1104
2024-05-25 01:41:51 [INFO]: Epoch 075 - training loss: 0.2371, validation loss: 0.1097
2024-05-25 01:41:51 [INFO]: Epoch 076 - training loss: 0.2345, validation loss: 0.1096
2024-05-25 01:41:52 [INFO]: Epoch 077 - training loss: 0.2346, validation loss: 0.1090
2024-05-25 01:41:52 [INFO]: Epoch 078 - training loss: 0.2335, validation loss: 0.1095
2024-05-25 01:41:53 [INFO]: Epoch 079 - training loss: 0.2318, validation loss: 0.1093
2024-05-25 01:41:54 [INFO]: Epoch 080 - training loss: 0.2314, validation loss: 0.1086
2024-05-25 01:41:54 [INFO]: Epoch 081 - training loss: 0.2294, validation loss: 0.1079
2024-05-25 01:41:55 [INFO]: Epoch 082 - training loss: 0.2298, validation loss: 0.1078
2024-05-25 01:41:55 [INFO]: Epoch 083 - training loss: 0.2290, validation loss: 0.1078
2024-05-25 01:41:56 [INFO]: Epoch 084 - training loss: 0.2269, validation loss: 0.1076
2024-05-25 01:41:57 [INFO]: Epoch 085 - training loss: 0.2280, validation loss: 0.1066
2024-05-25 01:41:57 [INFO]: Epoch 086 - training loss: 0.2249, validation loss: 0.1063
2024-05-25 01:41:58 [INFO]: Epoch 087 - training loss: 0.2245, validation loss: 0.1064
2024-05-25 01:41:58 [INFO]: Epoch 088 - training loss: 0.2242, validation loss: 0.1072
2024-05-25 01:41:59 [INFO]: Epoch 089 - training loss: 0.2226, validation loss: 0.1053
2024-05-25 01:42:00 [INFO]: Epoch 090 - training loss: 0.2222, validation loss: 0.1054
2024-05-25 01:42:00 [INFO]: Epoch 091 - training loss: 0.2221, validation loss: 0.1054
2024-05-25 01:42:01 [INFO]: Epoch 092 - training loss: 0.2218, validation loss: 0.1055
2024-05-25 01:42:01 [INFO]: Epoch 093 - training loss: 0.2201, validation loss: 0.1049
2024-05-25 01:42:02 [INFO]: Epoch 094 - training loss: 0.2190, validation loss: 0.1042
2024-05-25 01:42:03 [INFO]: Epoch 095 - training loss: 0.2180, validation loss: 0.1050
2024-05-25 01:42:03 [INFO]: Epoch 096 - training loss: 0.2173, validation loss: 0.1053
2024-05-25 01:42:04 [INFO]: Epoch 097 - training loss: 0.2173, validation loss: 0.1042
2024-05-25 01:42:04 [INFO]: Epoch 098 - training loss: 0.2165, validation loss: 0.1026
2024-05-25 01:42:05 [INFO]: Epoch 099 - training loss: 0.2160, validation loss: 0.1049
2024-05-25 01:42:06 [INFO]: Epoch 100 - training loss: 0.2149, validation loss: 0.1034
2024-05-25 01:42:06 [INFO]: Epoch 101 - training loss: 0.2137, validation loss: 0.1034
2024-05-25 01:42:07 [INFO]: Epoch 102 - training loss: 0.2131, validation loss: 0.1032
2024-05-25 01:42:07 [INFO]: Epoch 103 - training loss: 0.2121, validation loss: 0.1028
2024-05-25 01:42:08 [INFO]: Epoch 104 - training loss: 0.2122, validation loss: 0.1023
2024-05-25 01:42:09 [INFO]: Epoch 105 - training loss: 0.2110, validation loss: 0.1028
2024-05-25 01:42:09 [INFO]: Epoch 106 - training loss: 0.2109, validation loss: 0.1030
2024-05-25 01:42:10 [INFO]: Epoch 107 - training loss: 0.2100, validation loss: 0.1017
2024-05-25 01:42:10 [INFO]: Epoch 108 - training loss: 0.2101, validation loss: 0.1025
2024-05-25 01:42:11 [INFO]: Epoch 109 - training loss: 0.2100, validation loss: 0.1030
2024-05-25 01:42:12 [INFO]: Epoch 110 - training loss: 0.2096, validation loss: 0.1029
2024-05-25 01:42:12 [INFO]: Epoch 111 - training loss: 0.2082, validation loss: 0.1019
2024-05-25 01:42:13 [INFO]: Epoch 112 - training loss: 0.2072, validation loss: 0.1019
2024-05-25 01:42:13 [INFO]: Epoch 113 - training loss: 0.2096, validation loss: 0.1012
2024-05-25 01:42:14 [INFO]: Epoch 114 - training loss: 0.2071, validation loss: 0.1014
2024-05-25 01:42:15 [INFO]: Epoch 115 - training loss: 0.2053, validation loss: 0.1012
2024-05-25 01:42:15 [INFO]: Epoch 116 - training loss: 0.2050, validation loss: 0.1013
2024-05-25 01:42:16 [INFO]: Epoch 117 - training loss: 0.2045, validation loss: 0.1009
2024-05-25 01:42:16 [INFO]: Epoch 118 - training loss: 0.2031, validation loss: 0.1018
2024-05-25 01:42:17 [INFO]: Epoch 119 - training loss: 0.2029, validation loss: 0.1006
2024-05-25 01:42:18 [INFO]: Epoch 120 - training loss: 0.2025, validation loss: 0.1031
2024-05-25 01:42:18 [INFO]: Epoch 121 - training loss: 0.2015, validation loss: 0.1008
2024-05-25 01:42:19 [INFO]: Epoch 122 - training loss: 0.2005, validation loss: 0.1017
2024-05-25 01:42:19 [INFO]: Epoch 123 - training loss: 0.2023, validation loss: 0.1008
2024-05-25 01:42:20 [INFO]: Epoch 124 - training loss: 0.2006, validation loss: 0.0997
2024-05-25 01:42:21 [INFO]: Epoch 125 - training loss: 0.1996, validation loss: 0.1001
2024-05-25 01:42:21 [INFO]: Epoch 126 - training loss: 0.1991, validation loss: 0.0993
2024-05-25 01:42:22 [INFO]: Epoch 127 - training loss: 0.1985, validation loss: 0.0997
2024-05-25 01:42:22 [INFO]: Epoch 128 - training loss: 0.1980, validation loss: 0.0991
2024-05-25 01:42:23 [INFO]: Epoch 129 - training loss: 0.1972, validation loss: 0.0989
2024-05-25 01:42:24 [INFO]: Epoch 130 - training loss: 0.1974, validation loss: 0.0994
2024-05-25 01:42:24 [INFO]: Epoch 131 - training loss: 0.1970, validation loss: 0.0987
2024-05-25 01:42:25 [INFO]: Epoch 132 - training loss: 0.1968, validation loss: 0.0984
2024-05-25 01:42:25 [INFO]: Epoch 133 - training loss: 0.1959, validation loss: 0.0983
2024-05-25 01:42:26 [INFO]: Epoch 134 - training loss: 0.1959, validation loss: 0.0989
2024-05-25 01:42:27 [INFO]: Epoch 135 - training loss: 0.1959, validation loss: 0.0988
2024-05-25 01:42:27 [INFO]: Epoch 136 - training loss: 0.1958, validation loss: 0.0974
2024-05-25 01:42:28 [INFO]: Epoch 137 - training loss: 0.1941, validation loss: 0.0988
2024-05-25 01:42:28 [INFO]: Epoch 138 - training loss: 0.1934, validation loss: 0.0987
2024-05-25 01:42:29 [INFO]: Epoch 139 - training loss: 0.1937, validation loss: 0.0970
2024-05-25 01:42:30 [INFO]: Epoch 140 - training loss: 0.1925, validation loss: 0.0978
2024-05-25 01:42:30 [INFO]: Epoch 141 - training loss: 0.1922, validation loss: 0.0979
2024-05-25 01:42:31 [INFO]: Epoch 142 - training loss: 0.1926, validation loss: 0.0976
2024-05-25 01:42:31 [INFO]: Epoch 143 - training loss: 0.1921, validation loss: 0.0976
2024-05-25 01:42:32 [INFO]: Epoch 144 - training loss: 0.1925, validation loss: 0.0983
2024-05-25 01:42:33 [INFO]: Epoch 145 - training loss: 0.1915, validation loss: 0.0969
2024-05-25 01:42:33 [INFO]: Epoch 146 - training loss: 0.1898, validation loss: 0.0972
2024-05-25 01:42:34 [INFO]: Epoch 147 - training loss: 0.1909, validation loss: 0.0965
2024-05-25 01:42:34 [INFO]: Epoch 148 - training loss: 0.1901, validation loss: 0.0978
2024-05-25 01:42:35 [INFO]: Epoch 149 - training loss: 0.1898, validation loss: 0.0963
2024-05-25 01:42:36 [INFO]: Epoch 150 - training loss: 0.1884, validation loss: 0.0975
2024-05-25 01:42:36 [INFO]: Epoch 151 - training loss: 0.1887, validation loss: 0.0967
2024-05-25 01:42:37 [INFO]: Epoch 152 - training loss: 0.1886, validation loss: 0.0969
2024-05-25 01:42:37 [INFO]: Epoch 153 - training loss: 0.1876, validation loss: 0.0971
2024-05-25 01:42:38 [INFO]: Epoch 154 - training loss: 0.1893, validation loss: 0.0969
2024-05-25 01:42:39 [INFO]: Epoch 155 - training loss: 0.1877, validation loss: 0.0982
2024-05-25 01:42:39 [INFO]: Epoch 156 - training loss: 0.1872, validation loss: 0.0969
2024-05-25 01:42:40 [INFO]: Epoch 157 - training loss: 0.1854, validation loss: 0.0966
2024-05-25 01:42:40 [INFO]: Epoch 158 - training loss: 0.1870, validation loss: 0.0962
2024-05-25 01:42:41 [INFO]: Epoch 159 - training loss: 0.1843, validation loss: 0.0965
2024-05-25 01:42:42 [INFO]: Epoch 160 - training loss: 0.1852, validation loss: 0.0960
2024-05-25 01:42:42 [INFO]: Epoch 161 - training loss: 0.1851, validation loss: 0.0958
2024-05-25 01:42:43 [INFO]: Epoch 162 - training loss: 0.1843, validation loss: 0.0960
2024-05-25 01:42:43 [INFO]: Epoch 163 - training loss: 0.1838, validation loss: 0.0956
2024-05-25 01:42:44 [INFO]: Epoch 164 - training loss: 0.1830, validation loss: 0.0959
2024-05-25 01:42:45 [INFO]: Epoch 165 - training loss: 0.1821, validation loss: 0.0952
2024-05-25 01:42:45 [INFO]: Epoch 166 - training loss: 0.1817, validation loss: 0.0950
2024-05-25 01:42:46 [INFO]: Epoch 167 - training loss: 0.1813, validation loss: 0.0945
2024-05-25 01:42:46 [INFO]: Epoch 168 - training loss: 0.1808, validation loss: 0.0963
2024-05-25 01:42:47 [INFO]: Epoch 169 - training loss: 0.1811, validation loss: 0.0947
2024-05-25 01:42:48 [INFO]: Epoch 170 - training loss: 0.1805, validation loss: 0.0943
2024-05-25 01:42:48 [INFO]: Epoch 171 - training loss: 0.1812, validation loss: 0.0939
2024-05-25 01:42:49 [INFO]: Epoch 172 - training loss: 0.1809, validation loss: 0.0955
2024-05-25 01:42:49 [INFO]: Epoch 173 - training loss: 0.1808, validation loss: 0.0944
2024-05-25 01:42:50 [INFO]: Epoch 174 - training loss: 0.1805, validation loss: 0.0939
2024-05-25 01:42:51 [INFO]: Epoch 175 - training loss: 0.1790, validation loss: 0.0950
2024-05-25 01:42:51 [INFO]: Epoch 176 - training loss: 0.1781, validation loss: 0.0943
2024-05-25 01:42:52 [INFO]: Epoch 177 - training loss: 0.1782, validation loss: 0.0948
2024-05-25 01:42:52 [INFO]: Epoch 178 - training loss: 0.1777, validation loss: 0.0945
2024-05-25 01:42:53 [INFO]: Epoch 179 - training loss: 0.1788, validation loss: 0.0944
2024-05-25 01:42:54 [INFO]: Epoch 180 - training loss: 0.1773, validation loss: 0.0936
2024-05-25 01:42:54 [INFO]: Epoch 181 - training loss: 0.1777, validation loss: 0.0947
2024-05-25 01:42:55 [INFO]: Epoch 182 - training loss: 0.1773, validation loss: 0.0938
2024-05-25 01:42:55 [INFO]: Epoch 183 - training loss: 0.1767, validation loss: 0.0954
2024-05-25 01:42:56 [INFO]: Epoch 184 - training loss: 0.1775, validation loss: 0.0936
2024-05-25 01:42:57 [INFO]: Epoch 185 - training loss: 0.1758, validation loss: 0.0940
2024-05-25 01:42:57 [INFO]: Epoch 186 - training loss: 0.1753, validation loss: 0.0947
2024-05-25 01:42:58 [INFO]: Epoch 187 - training loss: 0.1755, validation loss: 0.0945
2024-05-25 01:42:58 [INFO]: Epoch 188 - training loss: 0.1752, validation loss: 0.0938
2024-05-25 01:42:59 [INFO]: Epoch 189 - training loss: 0.1756, validation loss: 0.0940
2024-05-25 01:43:00 [INFO]: Epoch 190 - training loss: 0.1759, validation loss: 0.0947
2024-05-25 01:43:00 [INFO]: Epoch 191 - training loss: 0.1752, validation loss: 0.0941
2024-05-25 01:43:01 [INFO]: Epoch 192 - training loss: 0.1741, validation loss: 0.0949
2024-05-25 01:43:01 [INFO]: Epoch 193 - training loss: 0.1732, validation loss: 0.0933
2024-05-25 01:43:02 [INFO]: Epoch 194 - training loss: 0.1731, validation loss: 0.0943
2024-05-25 01:43:03 [INFO]: Epoch 195 - training loss: 0.1742, validation loss: 0.0936
2024-05-25 01:43:03 [INFO]: Epoch 196 - training loss: 0.1733, validation loss: 0.0930
2024-05-25 01:43:04 [INFO]: Epoch 197 - training loss: 0.1728, validation loss: 0.0930
2024-05-25 01:43:04 [INFO]: Epoch 198 - training loss: 0.1729, validation loss: 0.0935
2024-05-25 01:43:05 [INFO]: Epoch 199 - training loss: 0.1712, validation loss: 0.0941
2024-05-25 01:43:06 [INFO]: Epoch 200 - training loss: 0.1711, validation loss: 0.0928
2024-05-25 01:43:06 [INFO]: Epoch 201 - training loss: 0.1717, validation loss: 0.0928
2024-05-25 01:43:07 [INFO]: Epoch 202 - training loss: 0.1722, validation loss: 0.0929
2024-05-25 01:43:07 [INFO]: Epoch 203 - training loss: 0.1719, validation loss: 0.0927
2024-05-25 01:43:08 [INFO]: Epoch 204 - training loss: 0.1708, validation loss: 0.0934
2024-05-25 01:43:09 [INFO]: Epoch 205 - training loss: 0.1712, validation loss: 0.0927
2024-05-25 01:43:09 [INFO]: Epoch 206 - training loss: 0.1697, validation loss: 0.0938
2024-05-25 01:43:10 [INFO]: Epoch 207 - training loss: 0.1699, validation loss: 0.0930
2024-05-25 01:43:10 [INFO]: Epoch 208 - training loss: 0.1693, validation loss: 0.0927
2024-05-25 01:43:11 [INFO]: Epoch 209 - training loss: 0.1703, validation loss: 0.0919
2024-05-25 01:43:12 [INFO]: Epoch 210 - training loss: 0.1693, validation loss: 0.0919
2024-05-25 01:43:12 [INFO]: Epoch 211 - training loss: 0.1677, validation loss: 0.0921
2024-05-25 01:43:13 [INFO]: Epoch 212 - training loss: 0.1669, validation loss: 0.0928
2024-05-25 01:43:13 [INFO]: Epoch 213 - training loss: 0.1675, validation loss: 0.0926
2024-05-25 01:43:14 [INFO]: Epoch 214 - training loss: 0.1684, validation loss: 0.0936
2024-05-25 01:43:15 [INFO]: Epoch 215 - training loss: 0.1676, validation loss: 0.0925
2024-05-25 01:43:15 [INFO]: Epoch 216 - training loss: 0.1674, validation loss: 0.0935
2024-05-25 01:43:16 [INFO]: Epoch 217 - training loss: 0.1679, validation loss: 0.0918
2024-05-25 01:43:17 [INFO]: Epoch 218 - training loss: 0.1667, validation loss: 0.0928
2024-05-25 01:43:17 [INFO]: Epoch 219 - training loss: 0.1654, validation loss: 0.0919
2024-05-25 01:43:18 [INFO]: Epoch 220 - training loss: 0.1656, validation loss: 0.0918
2024-05-25 01:43:18 [INFO]: Epoch 221 - training loss: 0.1648, validation loss: 0.0925
2024-05-25 01:43:19 [INFO]: Epoch 222 - training loss: 0.1660, validation loss: 0.0917
2024-05-25 01:43:20 [INFO]: Epoch 223 - training loss: 0.1652, validation loss: 0.0909
2024-05-25 01:43:20 [INFO]: Epoch 224 - training loss: 0.1656, validation loss: 0.0929
2024-05-25 01:43:21 [INFO]: Epoch 225 - training loss: 0.1649, validation loss: 0.0916
2024-05-25 01:43:21 [INFO]: Epoch 226 - training loss: 0.1646, validation loss: 0.0919
2024-05-25 01:43:22 [INFO]: Epoch 227 - training loss: 0.1647, validation loss: 0.0917
2024-05-25 01:43:23 [INFO]: Epoch 228 - training loss: 0.1643, validation loss: 0.0924
2024-05-25 01:43:23 [INFO]: Epoch 229 - training loss: 0.1632, validation loss: 0.0929
2024-05-25 01:43:24 [INFO]: Epoch 230 - training loss: 0.1646, validation loss: 0.0921
2024-05-25 01:43:24 [INFO]: Epoch 231 - training loss: 0.1630, validation loss: 0.0912
2024-05-25 01:43:25 [INFO]: Epoch 232 - training loss: 0.1629, validation loss: 0.0921
2024-05-25 01:43:26 [INFO]: Epoch 233 - training loss: 0.1619, validation loss: 0.0929
2024-05-25 01:43:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:43:26 [INFO]: Finished training. The best model is from epoch#223.
2024-05-25 01:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T014105/SAITS.pypots
2024-05-25 01:43:26 [INFO]: SAITS on Air-Quality: MAE=0.1485, MSE=0.0991
2024-05-25 01:43:26 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 01:43:26 [INFO]: Using the given device: cuda:0
2024-05-25 01:43:26 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T014326
2024-05-25 01:43:26 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T014326/tensorboard
2024-05-25 01:43:26 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 01:43:26 [INFO]: Epoch 001 - training loss: 0.9021, validation loss: 0.4588
2024-05-25 01:43:26 [INFO]: Epoch 002 - training loss: 0.5596, validation loss: 0.3226
2024-05-25 01:43:27 [INFO]: Epoch 003 - training loss: 0.4621, validation loss: 0.2695
2024-05-25 01:43:27 [INFO]: Epoch 004 - training loss: 0.4145, validation loss: 0.2445
2024-05-25 01:43:27 [INFO]: Epoch 005 - training loss: 0.3851, validation loss: 0.2253
2024-05-25 01:43:27 [INFO]: Epoch 006 - training loss: 0.3644, validation loss: 0.2154
2024-05-25 01:43:28 [INFO]: Epoch 007 - training loss: 0.3472, validation loss: 0.2070
2024-05-25 01:43:28 [INFO]: Epoch 008 - training loss: 0.3335, validation loss: 0.2001
2024-05-25 01:43:28 [INFO]: Epoch 009 - training loss: 0.3235, validation loss: 0.1959
2024-05-25 01:43:28 [INFO]: Epoch 010 - training loss: 0.3149, validation loss: 0.1877
2024-05-25 01:43:29 [INFO]: Epoch 011 - training loss: 0.3079, validation loss: 0.1854
2024-05-25 01:43:29 [INFO]: Epoch 012 - training loss: 0.3014, validation loss: 0.1823
2024-05-25 01:43:29 [INFO]: Epoch 013 - training loss: 0.2971, validation loss: 0.1787
2024-05-25 01:43:29 [INFO]: Epoch 014 - training loss: 0.2903, validation loss: 0.1706
2024-05-25 01:43:30 [INFO]: Epoch 015 - training loss: 0.2872, validation loss: 0.1724
2024-05-25 01:43:30 [INFO]: Epoch 016 - training loss: 0.2833, validation loss: 0.1670
2024-05-25 01:43:30 [INFO]: Epoch 017 - training loss: 0.2766, validation loss: 0.1635
2024-05-25 01:43:30 [INFO]: Epoch 018 - training loss: 0.2736, validation loss: 0.1641
2024-05-25 01:43:31 [INFO]: Epoch 019 - training loss: 0.2694, validation loss: 0.1603
2024-05-25 01:43:31 [INFO]: Epoch 020 - training loss: 0.2682, validation loss: 0.1581
2024-05-25 01:43:31 [INFO]: Epoch 021 - training loss: 0.2620, validation loss: 0.1561
2024-05-25 01:43:31 [INFO]: Epoch 022 - training loss: 0.2613, validation loss: 0.1553
2024-05-25 01:43:32 [INFO]: Epoch 023 - training loss: 0.2577, validation loss: 0.1521
2024-05-25 01:43:32 [INFO]: Epoch 024 - training loss: 0.2534, validation loss: 0.1514
2024-05-25 01:43:32 [INFO]: Epoch 025 - training loss: 0.2500, validation loss: 0.1499
2024-05-25 01:43:32 [INFO]: Epoch 026 - training loss: 0.2491, validation loss: 0.1484
2024-05-25 01:43:33 [INFO]: Epoch 027 - training loss: 0.2462, validation loss: 0.1470
2024-05-25 01:43:33 [INFO]: Epoch 028 - training loss: 0.2449, validation loss: 0.1471
2024-05-25 01:43:33 [INFO]: Epoch 029 - training loss: 0.2428, validation loss: 0.1473
2024-05-25 01:43:33 [INFO]: Epoch 030 - training loss: 0.2400, validation loss: 0.1456
2024-05-25 01:43:34 [INFO]: Epoch 031 - training loss: 0.2406, validation loss: 0.1438
2024-05-25 01:43:34 [INFO]: Epoch 032 - training loss: 0.2356, validation loss: 0.1432
2024-05-25 01:43:34 [INFO]: Epoch 033 - training loss: 0.2318, validation loss: 0.1409
2024-05-25 01:43:34 [INFO]: Epoch 034 - training loss: 0.2313, validation loss: 0.1425
2024-05-25 01:43:35 [INFO]: Epoch 035 - training loss: 0.2304, validation loss: 0.1413
2024-05-25 01:43:35 [INFO]: Epoch 036 - training loss: 0.2279, validation loss: 0.1405
2024-05-25 01:43:35 [INFO]: Epoch 037 - training loss: 0.2257, validation loss: 0.1414
2024-05-25 01:43:35 [INFO]: Epoch 038 - training loss: 0.2238, validation loss: 0.1397
2024-05-25 01:43:36 [INFO]: Epoch 039 - training loss: 0.2245, validation loss: 0.1392
2024-05-25 01:43:36 [INFO]: Epoch 040 - training loss: 0.2218, validation loss: 0.1376
2024-05-25 01:43:36 [INFO]: Epoch 041 - training loss: 0.2212, validation loss: 0.1367
2024-05-25 01:43:36 [INFO]: Epoch 042 - training loss: 0.2184, validation loss: 0.1361
2024-05-25 01:43:37 [INFO]: Epoch 043 - training loss: 0.2167, validation loss: 0.1358
2024-05-25 01:43:37 [INFO]: Epoch 044 - training loss: 0.2162, validation loss: 0.1341
2024-05-25 01:43:37 [INFO]: Epoch 045 - training loss: 0.2168, validation loss: 0.1368
2024-05-25 01:43:37 [INFO]: Epoch 046 - training loss: 0.2141, validation loss: 0.1351
2024-05-25 01:43:38 [INFO]: Epoch 047 - training loss: 0.2109, validation loss: 0.1339
2024-05-25 01:43:38 [INFO]: Epoch 048 - training loss: 0.2095, validation loss: 0.1329
2024-05-25 01:43:38 [INFO]: Epoch 049 - training loss: 0.2113, validation loss: 0.1343
2024-05-25 01:43:38 [INFO]: Epoch 050 - training loss: 0.2078, validation loss: 0.1317
2024-05-25 01:43:39 [INFO]: Epoch 051 - training loss: 0.2060, validation loss: 0.1322
2024-05-25 01:43:39 [INFO]: Epoch 052 - training loss: 0.2049, validation loss: 0.1316
2024-05-25 01:43:39 [INFO]: Epoch 053 - training loss: 0.2051, validation loss: 0.1309
2024-05-25 01:43:39 [INFO]: Epoch 054 - training loss: 0.2046, validation loss: 0.1308
2024-05-25 01:43:40 [INFO]: Epoch 055 - training loss: 0.2041, validation loss: 0.1303
2024-05-25 01:43:40 [INFO]: Epoch 056 - training loss: 0.2012, validation loss: 0.1272
2024-05-25 01:43:40 [INFO]: Epoch 057 - training loss: 0.1989, validation loss: 0.1286
2024-05-25 01:43:40 [INFO]: Epoch 058 - training loss: 0.1983, validation loss: 0.1269
2024-05-25 01:43:41 [INFO]: Epoch 059 - training loss: 0.1962, validation loss: 0.1281
2024-05-25 01:43:41 [INFO]: Epoch 060 - training loss: 0.1949, validation loss: 0.1267
2024-05-25 01:43:41 [INFO]: Epoch 061 - training loss: 0.1947, validation loss: 0.1269
2024-05-25 01:43:41 [INFO]: Epoch 062 - training loss: 0.1938, validation loss: 0.1259
2024-05-25 01:43:42 [INFO]: Epoch 063 - training loss: 0.1925, validation loss: 0.1269
2024-05-25 01:43:42 [INFO]: Epoch 064 - training loss: 0.1921, validation loss: 0.1258
2024-05-25 01:43:42 [INFO]: Epoch 065 - training loss: 0.1910, validation loss: 0.1243
2024-05-25 01:43:42 [INFO]: Epoch 066 - training loss: 0.1905, validation loss: 0.1243
2024-05-25 01:43:43 [INFO]: Epoch 067 - training loss: 0.1891, validation loss: 0.1237
2024-05-25 01:43:43 [INFO]: Epoch 068 - training loss: 0.1901, validation loss: 0.1222
2024-05-25 01:43:43 [INFO]: Epoch 069 - training loss: 0.1878, validation loss: 0.1252
2024-05-25 01:43:43 [INFO]: Epoch 070 - training loss: 0.1855, validation loss: 0.1229
2024-05-25 01:43:44 [INFO]: Epoch 071 - training loss: 0.1856, validation loss: 0.1224
2024-05-25 01:43:44 [INFO]: Epoch 072 - training loss: 0.1847, validation loss: 0.1211
2024-05-25 01:43:44 [INFO]: Epoch 073 - training loss: 0.1865, validation loss: 0.1228
2024-05-25 01:43:44 [INFO]: Epoch 074 - training loss: 0.1818, validation loss: 0.1211
2024-05-25 01:43:45 [INFO]: Epoch 075 - training loss: 0.1801, validation loss: 0.1204
2024-05-25 01:43:45 [INFO]: Epoch 076 - training loss: 0.1817, validation loss: 0.1218
2024-05-25 01:43:45 [INFO]: Epoch 077 - training loss: 0.1803, validation loss: 0.1205
2024-05-25 01:43:45 [INFO]: Epoch 078 - training loss: 0.1786, validation loss: 0.1214
2024-05-25 01:43:46 [INFO]: Epoch 079 - training loss: 0.1787, validation loss: 0.1204
2024-05-25 01:43:46 [INFO]: Epoch 080 - training loss: 0.1791, validation loss: 0.1194
2024-05-25 01:43:46 [INFO]: Epoch 081 - training loss: 0.1765, validation loss: 0.1197
2024-05-25 01:43:46 [INFO]: Epoch 082 - training loss: 0.1790, validation loss: 0.1207
2024-05-25 01:43:47 [INFO]: Epoch 083 - training loss: 0.1820, validation loss: 0.1172
2024-05-25 01:43:47 [INFO]: Epoch 084 - training loss: 0.1778, validation loss: 0.1209
2024-05-25 01:43:47 [INFO]: Epoch 085 - training loss: 0.1753, validation loss: 0.1180
2024-05-25 01:43:47 [INFO]: Epoch 086 - training loss: 0.1729, validation loss: 0.1187
2024-05-25 01:43:48 [INFO]: Epoch 087 - training loss: 0.1743, validation loss: 0.1175
2024-05-25 01:43:48 [INFO]: Epoch 088 - training loss: 0.1734, validation loss: 0.1205
2024-05-25 01:43:48 [INFO]: Epoch 089 - training loss: 0.1719, validation loss: 0.1189
2024-05-25 01:43:48 [INFO]: Epoch 090 - training loss: 0.1697, validation loss: 0.1179
2024-05-25 01:43:49 [INFO]: Epoch 091 - training loss: 0.1687, validation loss: 0.1176
2024-05-25 01:43:49 [INFO]: Epoch 092 - training loss: 0.1680, validation loss: 0.1165
2024-05-25 01:43:49 [INFO]: Epoch 093 - training loss: 0.1676, validation loss: 0.1169
2024-05-25 01:43:49 [INFO]: Epoch 094 - training loss: 0.1661, validation loss: 0.1175
2024-05-25 01:43:50 [INFO]: Epoch 095 - training loss: 0.1656, validation loss: 0.1161
2024-05-25 01:43:50 [INFO]: Epoch 096 - training loss: 0.1666, validation loss: 0.1149
2024-05-25 01:43:50 [INFO]: Epoch 097 - training loss: 0.1649, validation loss: 0.1169
2024-05-25 01:43:50 [INFO]: Epoch 098 - training loss: 0.1641, validation loss: 0.1169
2024-05-25 01:43:51 [INFO]: Epoch 099 - training loss: 0.1645, validation loss: 0.1146
2024-05-25 01:43:51 [INFO]: Epoch 100 - training loss: 0.1644, validation loss: 0.1144
2024-05-25 01:43:51 [INFO]: Epoch 101 - training loss: 0.1621, validation loss: 0.1149
2024-05-25 01:43:51 [INFO]: Epoch 102 - training loss: 0.1612, validation loss: 0.1161
2024-05-25 01:43:52 [INFO]: Epoch 103 - training loss: 0.1610, validation loss: 0.1159
2024-05-25 01:43:52 [INFO]: Epoch 104 - training loss: 0.1607, validation loss: 0.1126
2024-05-25 01:43:52 [INFO]: Epoch 105 - training loss: 0.1595, validation loss: 0.1128
2024-05-25 01:43:52 [INFO]: Epoch 106 - training loss: 0.1590, validation loss: 0.1160
2024-05-25 01:43:53 [INFO]: Epoch 107 - training loss: 0.1584, validation loss: 0.1152
2024-05-25 01:43:53 [INFO]: Epoch 108 - training loss: 0.1595, validation loss: 0.1141
2024-05-25 01:43:53 [INFO]: Epoch 109 - training loss: 0.1593, validation loss: 0.1143
2024-05-25 01:43:53 [INFO]: Epoch 110 - training loss: 0.1579, validation loss: 0.1146
2024-05-25 01:43:54 [INFO]: Epoch 111 - training loss: 0.1581, validation loss: 0.1146
2024-05-25 01:43:54 [INFO]: Epoch 112 - training loss: 0.1564, validation loss: 0.1114
2024-05-25 01:43:54 [INFO]: Epoch 113 - training loss: 0.1567, validation loss: 0.1132
2024-05-25 01:43:54 [INFO]: Epoch 114 - training loss: 0.1577, validation loss: 0.1133
2024-05-25 01:43:55 [INFO]: Epoch 115 - training loss: 0.1591, validation loss: 0.1124
2024-05-25 01:43:55 [INFO]: Epoch 116 - training loss: 0.1581, validation loss: 0.1124
2024-05-25 01:43:55 [INFO]: Epoch 117 - training loss: 0.1559, validation loss: 0.1138
2024-05-25 01:43:55 [INFO]: Epoch 118 - training loss: 0.1560, validation loss: 0.1119
2024-05-25 01:43:56 [INFO]: Epoch 119 - training loss: 0.1540, validation loss: 0.1123
2024-05-25 01:43:56 [INFO]: Epoch 120 - training loss: 0.1522, validation loss: 0.1138
2024-05-25 01:43:56 [INFO]: Epoch 121 - training loss: 0.1558, validation loss: 0.1146
2024-05-25 01:43:56 [INFO]: Epoch 122 - training loss: 0.1518, validation loss: 0.1112
2024-05-25 01:43:57 [INFO]: Epoch 123 - training loss: 0.1527, validation loss: 0.1117
2024-05-25 01:43:57 [INFO]: Epoch 124 - training loss: 0.1503, validation loss: 0.1122
2024-05-25 01:43:57 [INFO]: Epoch 125 - training loss: 0.1481, validation loss: 0.1124
2024-05-25 01:43:57 [INFO]: Epoch 126 - training loss: 0.1476, validation loss: 0.1120
2024-05-25 01:43:58 [INFO]: Epoch 127 - training loss: 0.1476, validation loss: 0.1124
2024-05-25 01:43:58 [INFO]: Epoch 128 - training loss: 0.1496, validation loss: 0.1121
2024-05-25 01:43:58 [INFO]: Epoch 129 - training loss: 0.1477, validation loss: 0.1129
2024-05-25 01:43:58 [INFO]: Epoch 130 - training loss: 0.1477, validation loss: 0.1114
2024-05-25 01:43:59 [INFO]: Epoch 131 - training loss: 0.1477, validation loss: 0.1134
2024-05-25 01:43:59 [INFO]: Epoch 132 - training loss: 0.1464, validation loss: 0.1132
2024-05-25 01:43:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:43:59 [INFO]: Finished training. The best model is from epoch#122.
2024-05-25 01:43:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T014326/Transformer.pypots
2024-05-25 01:43:59 [INFO]: Transformer on Air-Quality: MAE=0.1658, MSE=0.1173
2024-05-25 01:43:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 01:43:59 [INFO]: Using the given device: cuda:0
2024-05-25 01:43:59 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T014359
2024-05-25 01:43:59 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T014359/tensorboard
2024-05-25 01:43:59 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 01:44:00 [INFO]: Epoch 001 - training loss: 0.3132, validation loss: 0.2649
2024-05-25 01:44:00 [INFO]: Epoch 002 - training loss: 0.2514, validation loss: 0.2319
2024-05-25 01:44:01 [INFO]: Epoch 003 - training loss: 0.1992, validation loss: 0.2129
2024-05-25 01:44:01 [INFO]: Epoch 004 - training loss: 0.1802, validation loss: 0.2063
2024-05-25 01:44:02 [INFO]: Epoch 005 - training loss: 0.1549, validation loss: 0.1984
2024-05-25 01:44:02 [INFO]: Epoch 006 - training loss: 0.1425, validation loss: 0.1962
2024-05-25 01:44:03 [INFO]: Epoch 007 - training loss: 0.1352, validation loss: 0.1906
2024-05-25 01:44:03 [INFO]: Epoch 008 - training loss: 0.1289, validation loss: 0.1890
2024-05-25 01:44:04 [INFO]: Epoch 009 - training loss: 0.1148, validation loss: 0.1916
2024-05-25 01:44:04 [INFO]: Epoch 010 - training loss: 0.1048, validation loss: 0.1853
2024-05-25 01:44:05 [INFO]: Epoch 011 - training loss: 0.1025, validation loss: 0.2092
2024-05-25 01:44:05 [INFO]: Epoch 012 - training loss: 0.0999, validation loss: 0.2109
2024-05-25 01:44:05 [INFO]: Epoch 013 - training loss: 0.0959, validation loss: 0.2152
2024-05-25 01:44:06 [INFO]: Epoch 014 - training loss: 0.0909, validation loss: 0.1900
2024-05-25 01:44:06 [INFO]: Epoch 015 - training loss: 0.0893, validation loss: 0.2149
2024-05-25 01:44:07 [INFO]: Epoch 016 - training loss: 0.0846, validation loss: 0.1926
2024-05-25 01:44:07 [INFO]: Epoch 017 - training loss: 0.0847, validation loss: 0.1954
2024-05-25 01:44:08 [INFO]: Epoch 018 - training loss: 0.0794, validation loss: 0.1920
2024-05-25 01:44:08 [INFO]: Epoch 019 - training loss: 0.0827, validation loss: 0.2004
2024-05-25 01:44:09 [INFO]: Epoch 020 - training loss: 0.0773, validation loss: 0.1948
2024-05-25 01:44:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:44:09 [INFO]: Finished training. The best model is from epoch#10.
2024-05-25 01:44:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T014359/TimesNet.pypots
2024-05-25 01:44:09 [INFO]: TimesNet on Air-Quality: MAE=0.1799, MSE=0.1727
2024-05-25 01:44:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 01:44:09 [INFO]: Using the given device: cuda:0
2024-05-25 01:44:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409
2024-05-25 01:44:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/tensorboard
2024-05-25 01:44:09 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 01:44:26 [INFO]: Epoch 001 - training loss: 0.4974, validation loss: 0.3200
2024-05-25 01:44:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch1_loss0.3200372368097305.pypots
2024-05-25 01:44:42 [INFO]: Epoch 002 - training loss: 0.3007, validation loss: 0.2664
2024-05-25 01:44:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch2_loss0.26639968901872635.pypots
2024-05-25 01:44:59 [INFO]: Epoch 003 - training loss: 0.2554, validation loss: 0.2499
2024-05-25 01:44:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch3_loss0.24987658560276033.pypots
2024-05-25 01:45:16 [INFO]: Epoch 004 - training loss: 0.2359, validation loss: 0.2293
2024-05-25 01:45:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch4_loss0.22931426763534546.pypots
2024-05-25 01:45:32 [INFO]: Epoch 005 - training loss: 0.2409, validation loss: 0.2158
2024-05-25 01:45:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch5_loss0.2158142790198326.pypots
2024-05-25 01:45:49 [INFO]: Epoch 006 - training loss: 0.1989, validation loss: 0.1924
2024-05-25 01:45:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch6_loss0.19236742705106735.pypots
2024-05-25 01:46:06 [INFO]: Epoch 007 - training loss: 0.1929, validation loss: 0.1790
2024-05-25 01:46:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch7_loss0.17896509915590286.pypots
2024-05-25 01:46:22 [INFO]: Epoch 008 - training loss: 0.1800, validation loss: 0.1687
2024-05-25 01:46:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch8_loss0.16869079917669297.pypots
2024-05-25 01:46:39 [INFO]: Epoch 009 - training loss: 0.1704, validation loss: 0.1656
2024-05-25 01:46:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch9_loss0.1655633494257927.pypots
2024-05-25 01:46:56 [INFO]: Epoch 010 - training loss: 0.1633, validation loss: 0.1653
2024-05-25 01:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch10_loss0.16527465283870696.pypots
2024-05-25 01:47:12 [INFO]: Epoch 011 - training loss: 0.1721, validation loss: 0.1664
2024-05-25 01:47:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch11_loss0.16643225848674775.pypots
2024-05-25 01:47:29 [INFO]: Epoch 012 - training loss: 0.1612, validation loss: 0.1572
2024-05-25 01:47:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch12_loss0.15715272724628448.pypots
2024-05-25 01:47:46 [INFO]: Epoch 013 - training loss: 0.1633, validation loss: 0.1598
2024-05-25 01:47:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch13_loss0.15984901785850525.pypots
2024-05-25 01:48:02 [INFO]: Epoch 014 - training loss: 0.1758, validation loss: 0.1569
2024-05-25 01:48:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch14_loss0.15690215229988097.pypots
2024-05-25 01:48:19 [INFO]: Epoch 015 - training loss: 0.1658, validation loss: 0.1519
2024-05-25 01:48:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch15_loss0.15193625688552856.pypots
2024-05-25 01:48:36 [INFO]: Epoch 016 - training loss: 0.1602, validation loss: 0.1490
2024-05-25 01:48:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch16_loss0.14903389066457748.pypots
2024-05-25 01:48:52 [INFO]: Epoch 017 - training loss: 0.1580, validation loss: 0.1453
2024-05-25 01:48:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch17_loss0.14525824338197707.pypots
2024-05-25 01:49:09 [INFO]: Epoch 018 - training loss: 0.1512, validation loss: 0.1497
2024-05-25 01:49:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch18_loss0.1497138798236847.pypots
2024-05-25 01:49:26 [INFO]: Epoch 019 - training loss: 0.1406, validation loss: 0.1446
2024-05-25 01:49:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch19_loss0.144562166929245.pypots
2024-05-25 01:49:42 [INFO]: Epoch 020 - training loss: 0.1249, validation loss: 0.1409
2024-05-25 01:49:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch20_loss0.14094004333019255.pypots
2024-05-25 01:49:59 [INFO]: Epoch 021 - training loss: 0.1468, validation loss: 0.1484
2024-05-25 01:49:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch21_loss0.14843342900276185.pypots
2024-05-25 01:50:16 [INFO]: Epoch 022 - training loss: 0.1537, validation loss: 0.1430
2024-05-25 01:50:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch22_loss0.14301778376102448.pypots
2024-05-25 01:50:32 [INFO]: Epoch 023 - training loss: 0.1377, validation loss: 0.1400
2024-05-25 01:50:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch23_loss0.1400424472987652.pypots
2024-05-25 01:50:49 [INFO]: Epoch 024 - training loss: 0.1368, validation loss: 0.1372
2024-05-25 01:50:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch24_loss0.1371976152062416.pypots
2024-05-25 01:51:06 [INFO]: Epoch 025 - training loss: 0.1526, validation loss: 0.1402
2024-05-25 01:51:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch25_loss0.14019231051206588.pypots
2024-05-25 01:51:22 [INFO]: Epoch 026 - training loss: 0.1497, validation loss: 0.1374
2024-05-25 01:51:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch26_loss0.13744593858718873.pypots
2024-05-25 01:51:39 [INFO]: Epoch 027 - training loss: 0.1453, validation loss: 0.1326
2024-05-25 01:51:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch27_loss0.132559984177351.pypots
2024-05-25 01:51:56 [INFO]: Epoch 028 - training loss: 0.1407, validation loss: 0.1324
2024-05-25 01:51:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch28_loss0.1323700450360775.pypots
2024-05-25 01:52:12 [INFO]: Epoch 029 - training loss: 0.1424, validation loss: 0.1314
2024-05-25 01:52:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch29_loss0.13138891831040383.pypots
2024-05-25 01:52:29 [INFO]: Epoch 030 - training loss: 0.1283, validation loss: 0.1334
2024-05-25 01:52:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch30_loss0.13335249349474906.pypots
2024-05-25 01:52:46 [INFO]: Epoch 031 - training loss: 0.1294, validation loss: 0.1311
2024-05-25 01:52:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch31_loss0.13113081604242324.pypots
2024-05-25 01:53:02 [INFO]: Epoch 032 - training loss: 0.1375, validation loss: 0.1336
2024-05-25 01:53:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch32_loss0.1336424395442009.pypots
2024-05-25 01:53:19 [INFO]: Epoch 033 - training loss: 0.1174, validation loss: 0.1317
2024-05-25 01:53:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch33_loss0.1316716566681862.pypots
2024-05-25 01:53:36 [INFO]: Epoch 034 - training loss: 0.1357, validation loss: 0.1344
2024-05-25 01:53:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch34_loss0.1343570679426193.pypots
2024-05-25 01:53:52 [INFO]: Epoch 035 - training loss: 0.1443, validation loss: 0.1306
2024-05-25 01:53:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch35_loss0.13059249371290207.pypots
2024-05-25 01:54:09 [INFO]: Epoch 036 - training loss: 0.1190, validation loss: 0.1280
2024-05-25 01:54:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch36_loss0.12799111753702164.pypots
2024-05-25 01:54:26 [INFO]: Epoch 037 - training loss: 0.1288, validation loss: 0.1299
2024-05-25 01:54:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch37_loss0.129920095205307.pypots
2024-05-25 01:54:42 [INFO]: Epoch 038 - training loss: 0.1415, validation loss: 0.1276
2024-05-25 01:54:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch38_loss0.12755703553557396.pypots
2024-05-25 01:54:59 [INFO]: Epoch 039 - training loss: 0.1231, validation loss: 0.1337
2024-05-25 01:54:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch39_loss0.13373101130127907.pypots
2024-05-25 01:55:16 [INFO]: Epoch 040 - training loss: 0.1359, validation loss: 0.1352
2024-05-25 01:55:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch40_loss0.1352037988603115.pypots
2024-05-25 01:55:32 [INFO]: Epoch 041 - training loss: 0.1439, validation loss: 0.1281
2024-05-25 01:55:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch41_loss0.12808364480733872.pypots
2024-05-25 01:55:49 [INFO]: Epoch 042 - training loss: 0.1246, validation loss: 0.1267
2024-05-25 01:55:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch42_loss0.12671518698334694.pypots
2024-05-25 01:56:06 [INFO]: Epoch 043 - training loss: 0.1430, validation loss: 0.1272
2024-05-25 01:56:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch43_loss0.12720632553100586.pypots
2024-05-25 01:56:22 [INFO]: Epoch 044 - training loss: 0.1167, validation loss: 0.1253
2024-05-25 01:56:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch44_loss0.1253312796354294.pypots
2024-05-25 01:56:39 [INFO]: Epoch 045 - training loss: 0.1311, validation loss: 0.1263
2024-05-25 01:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch45_loss0.1263174220919609.pypots
2024-05-25 01:56:56 [INFO]: Epoch 046 - training loss: 0.1297, validation loss: 0.1315
2024-05-25 01:56:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch46_loss0.13146814182400704.pypots
2024-05-25 01:57:12 [INFO]: Epoch 047 - training loss: 0.1235, validation loss: 0.1272
2024-05-25 01:57:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch47_loss0.12724524289369582.pypots
2024-05-25 01:57:29 [INFO]: Epoch 048 - training loss: 0.1345, validation loss: 0.1260
2024-05-25 01:57:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch48_loss0.12597787007689476.pypots
2024-05-25 01:57:46 [INFO]: Epoch 049 - training loss: 0.1106, validation loss: 0.1241
2024-05-25 01:57:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch49_loss0.12408758252859116.pypots
2024-05-25 01:58:02 [INFO]: Epoch 050 - training loss: 0.1088, validation loss: 0.1216
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch50_loss0.12163764014840125.pypots
2024-05-25 01:58:19 [INFO]: Epoch 051 - training loss: 0.1110, validation loss: 0.1257
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch51_loss0.1256917603313923.pypots
2024-05-25 01:58:36 [INFO]: Epoch 052 - training loss: 0.1183, validation loss: 0.1244
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch52_loss0.12440996766090393.pypots
2024-05-25 01:58:52 [INFO]: Epoch 053 - training loss: 0.1127, validation loss: 0.1221
2024-05-25 01:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch53_loss0.12214451432228088.pypots
2024-05-25 01:59:09 [INFO]: Epoch 054 - training loss: 0.1345, validation loss: 0.1228
2024-05-25 01:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch54_loss0.12278872728347778.pypots
2024-05-25 01:59:26 [INFO]: Epoch 055 - training loss: 0.1235, validation loss: 0.1282
2024-05-25 01:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch55_loss0.12818328887224198.pypots
2024-05-25 01:59:42 [INFO]: Epoch 056 - training loss: 0.1463, validation loss: 0.1232
2024-05-25 01:59:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch56_loss0.12323743849992752.pypots
2024-05-25 01:59:59 [INFO]: Epoch 057 - training loss: 0.1065, validation loss: 0.1193
2024-05-25 01:59:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch57_loss0.11931509971618652.pypots
2024-05-25 02:00:16 [INFO]: Epoch 058 - training loss: 0.1175, validation loss: 0.1249
2024-05-25 02:00:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch58_loss0.12493219375610351.pypots
2024-05-25 02:00:32 [INFO]: Epoch 059 - training loss: 0.1235, validation loss: 0.1213
2024-05-25 02:00:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch59_loss0.12127244547009468.pypots
2024-05-25 02:00:49 [INFO]: Epoch 060 - training loss: 0.1131, validation loss: 0.1213
2024-05-25 02:00:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch60_loss0.1213085763156414.pypots
2024-05-25 02:01:06 [INFO]: Epoch 061 - training loss: 0.1114, validation loss: 0.1196
2024-05-25 02:01:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch61_loss0.11964625343680382.pypots
2024-05-25 02:01:22 [INFO]: Epoch 062 - training loss: 0.1145, validation loss: 0.1181
2024-05-25 02:01:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch62_loss0.11805196702480317.pypots
2024-05-25 02:01:39 [INFO]: Epoch 063 - training loss: 0.1365, validation loss: 0.1218
2024-05-25 02:01:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch63_loss0.12175238877534866.pypots
2024-05-25 02:01:56 [INFO]: Epoch 064 - training loss: 0.1150, validation loss: 0.1176
2024-05-25 02:01:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch64_loss0.11756770163774491.pypots
2024-05-25 02:02:12 [INFO]: Epoch 065 - training loss: 0.1121, validation loss: 0.1184
2024-05-25 02:02:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch65_loss0.11841768845915794.pypots
2024-05-25 02:02:29 [INFO]: Epoch 066 - training loss: 0.1219, validation loss: 0.1165
2024-05-25 02:02:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch66_loss0.11654551178216935.pypots
2024-05-25 02:02:46 [INFO]: Epoch 067 - training loss: 0.1089, validation loss: 0.1179
2024-05-25 02:02:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch67_loss0.11790753081440926.pypots
2024-05-25 02:03:02 [INFO]: Epoch 068 - training loss: 0.1199, validation loss: 0.1174
2024-05-25 02:03:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch68_loss0.11738205775618553.pypots
2024-05-25 02:03:19 [INFO]: Epoch 069 - training loss: 0.1127, validation loss: 0.1169
2024-05-25 02:03:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch69_loss0.11690402552485465.pypots
2024-05-25 02:03:36 [INFO]: Epoch 070 - training loss: 0.1237, validation loss: 0.1184
2024-05-25 02:03:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch70_loss0.11840946897864342.pypots
2024-05-25 02:03:52 [INFO]: Epoch 071 - training loss: 0.1198, validation loss: 0.1163
2024-05-25 02:03:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch71_loss0.11626928076148033.pypots
2024-05-25 02:04:09 [INFO]: Epoch 072 - training loss: 0.1123, validation loss: 0.1184
2024-05-25 02:04:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch72_loss0.11844297870993614.pypots
2024-05-25 02:04:26 [INFO]: Epoch 073 - training loss: 0.1027, validation loss: 0.1173
2024-05-25 02:04:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch73_loss0.11725625172257423.pypots
2024-05-25 02:04:42 [INFO]: Epoch 074 - training loss: 0.1275, validation loss: 0.1160
2024-05-25 02:04:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch74_loss0.1160096399486065.pypots
2024-05-25 02:04:59 [INFO]: Epoch 075 - training loss: 0.1016, validation loss: 0.1172
2024-05-25 02:04:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch75_loss0.11715117543935775.pypots
2024-05-25 02:05:16 [INFO]: Epoch 076 - training loss: 0.1149, validation loss: 0.1162
2024-05-25 02:05:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch76_loss0.11617639809846877.pypots
2024-05-25 02:05:32 [INFO]: Epoch 077 - training loss: 0.1227, validation loss: 0.1158
2024-05-25 02:05:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch77_loss0.11582620590925216.pypots
2024-05-25 02:05:49 [INFO]: Epoch 078 - training loss: 0.1127, validation loss: 0.1156
2024-05-25 02:05:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch78_loss0.11564363837242127.pypots
2024-05-25 02:06:06 [INFO]: Epoch 079 - training loss: 0.0995, validation loss: 0.1152
2024-05-25 02:06:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch79_loss0.11523419842123986.pypots
2024-05-25 02:06:22 [INFO]: Epoch 080 - training loss: 0.1125, validation loss: 0.1167
2024-05-25 02:06:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch80_loss0.11669970601797104.pypots
2024-05-25 02:06:39 [INFO]: Epoch 081 - training loss: 0.1274, validation loss: 0.1164
2024-05-25 02:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch81_loss0.11636805608868599.pypots
2024-05-25 02:06:56 [INFO]: Epoch 082 - training loss: 0.1124, validation loss: 0.1130
2024-05-25 02:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch82_loss0.11296744868159295.pypots
2024-05-25 02:07:12 [INFO]: Epoch 083 - training loss: 0.1133, validation loss: 0.1134
2024-05-25 02:07:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch83_loss0.1134136900305748.pypots
2024-05-25 02:07:29 [INFO]: Epoch 084 - training loss: 0.1159, validation loss: 0.1121
2024-05-25 02:07:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch84_loss0.11205366477370263.pypots
2024-05-25 02:07:46 [INFO]: Epoch 085 - training loss: 0.1226, validation loss: 0.1147
2024-05-25 02:07:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch85_loss0.1147189937531948.pypots
2024-05-25 02:08:02 [INFO]: Epoch 086 - training loss: 0.1139, validation loss: 0.1145
2024-05-25 02:08:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch86_loss0.11450615748763085.pypots
2024-05-25 02:08:19 [INFO]: Epoch 087 - training loss: 0.1073, validation loss: 0.1121
2024-05-25 02:08:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch87_loss0.1120887778699398.pypots
2024-05-25 02:08:36 [INFO]: Epoch 088 - training loss: 0.0998, validation loss: 0.1109
2024-05-25 02:08:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch88_loss0.11088436245918273.pypots
2024-05-25 02:08:52 [INFO]: Epoch 089 - training loss: 0.1171, validation loss: 0.1110
2024-05-25 02:08:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch89_loss0.11095220595598221.pypots
2024-05-25 02:09:09 [INFO]: Epoch 090 - training loss: 0.1085, validation loss: 0.1107
2024-05-25 02:09:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch90_loss0.11074290052056313.pypots
2024-05-25 02:09:26 [INFO]: Epoch 091 - training loss: 0.1018, validation loss: 0.1109
2024-05-25 02:09:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch91_loss0.11092895567417145.pypots
2024-05-25 02:09:42 [INFO]: Epoch 092 - training loss: 0.1002, validation loss: 0.1175
2024-05-25 02:09:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch92_loss0.1174611933529377.pypots
2024-05-25 02:09:59 [INFO]: Epoch 093 - training loss: 0.1007, validation loss: 0.1126
2024-05-25 02:09:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch93_loss0.11255375295877457.pypots
2024-05-25 02:10:16 [INFO]: Epoch 094 - training loss: 0.1043, validation loss: 0.1092
2024-05-25 02:10:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch94_loss0.1092071458697319.pypots
2024-05-25 02:10:32 [INFO]: Epoch 095 - training loss: 0.1161, validation loss: 0.1097
2024-05-25 02:10:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch95_loss0.10971155911684036.pypots
2024-05-25 02:10:49 [INFO]: Epoch 096 - training loss: 0.1024, validation loss: 0.1140
2024-05-25 02:10:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch96_loss0.11402690038084984.pypots
2024-05-25 02:11:06 [INFO]: Epoch 097 - training loss: 0.1204, validation loss: 0.1094
2024-05-25 02:11:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch97_loss0.1093918152153492.pypots
2024-05-25 02:11:22 [INFO]: Epoch 098 - training loss: 0.1048, validation loss: 0.1101
2024-05-25 02:11:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch98_loss0.11011943444609643.pypots
2024-05-25 02:11:39 [INFO]: Epoch 099 - training loss: 0.1244, validation loss: 0.1097
2024-05-25 02:11:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch99_loss0.10970480442047119.pypots
2024-05-25 02:11:56 [INFO]: Epoch 100 - training loss: 0.1157, validation loss: 0.1151
2024-05-25 02:11:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch100_loss0.11505039632320405.pypots
2024-05-25 02:12:12 [INFO]: Epoch 101 - training loss: 0.1139, validation loss: 0.1130
2024-05-25 02:12:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch101_loss0.11296943798661233.pypots
2024-05-25 02:12:29 [INFO]: Epoch 102 - training loss: 0.1037, validation loss: 0.1103
2024-05-25 02:12:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch102_loss0.11029275879263878.pypots
2024-05-25 02:12:46 [INFO]: Epoch 103 - training loss: 0.0940, validation loss: 0.1081
2024-05-25 02:12:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch103_loss0.10811117216944695.pypots
2024-05-25 02:13:02 [INFO]: Epoch 104 - training loss: 0.1032, validation loss: 0.1084
2024-05-25 02:13:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch104_loss0.10841405391693115.pypots
2024-05-25 02:13:19 [INFO]: Epoch 105 - training loss: 0.0946, validation loss: 0.1085
2024-05-25 02:13:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch105_loss0.10847159177064895.pypots
2024-05-25 02:13:36 [INFO]: Epoch 106 - training loss: 0.1075, validation loss: 0.1090
2024-05-25 02:13:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch106_loss0.10901274010539055.pypots
2024-05-25 02:13:52 [INFO]: Epoch 107 - training loss: 0.1034, validation loss: 0.1076
2024-05-25 02:13:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch107_loss0.10764669179916382.pypots
2024-05-25 02:14:09 [INFO]: Epoch 108 - training loss: 0.1096, validation loss: 0.1107
2024-05-25 02:14:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch108_loss0.11071374341845512.pypots
2024-05-25 02:14:26 [INFO]: Epoch 109 - training loss: 0.0992, validation loss: 0.1090
2024-05-25 02:14:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch109_loss0.1089662604033947.pypots
2024-05-25 02:14:42 [INFO]: Epoch 110 - training loss: 0.0992, validation loss: 0.1098
2024-05-25 02:14:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch110_loss0.10984131470322608.pypots
2024-05-25 02:14:59 [INFO]: Epoch 111 - training loss: 0.1022, validation loss: 0.1077
2024-05-25 02:14:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch111_loss0.1077414557337761.pypots
2024-05-25 02:15:16 [INFO]: Epoch 112 - training loss: 0.1101, validation loss: 0.1091
2024-05-25 02:15:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch112_loss0.10906066969037057.pypots
2024-05-25 02:15:33 [INFO]: Epoch 113 - training loss: 0.1121, validation loss: 0.1078
2024-05-25 02:15:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch113_loss0.10778018459677696.pypots
2024-05-25 02:15:49 [INFO]: Epoch 114 - training loss: 0.1050, validation loss: 0.1056
2024-05-25 02:15:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch114_loss0.10564296245574951.pypots
2024-05-25 02:16:06 [INFO]: Epoch 115 - training loss: 0.1045, validation loss: 0.1073
2024-05-25 02:16:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch115_loss0.10730211436748505.pypots
2024-05-25 02:16:23 [INFO]: Epoch 116 - training loss: 0.1023, validation loss: 0.1066
2024-05-25 02:16:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch116_loss0.1066187709569931.pypots
2024-05-25 02:16:39 [INFO]: Epoch 117 - training loss: 0.1082, validation loss: 0.1103
2024-05-25 02:16:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch117_loss0.11025940105319024.pypots
2024-05-25 02:16:56 [INFO]: Epoch 118 - training loss: 0.1219, validation loss: 0.1069
2024-05-25 02:16:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch118_loss0.10691074356436729.pypots
2024-05-25 02:17:13 [INFO]: Epoch 119 - training loss: 0.1108, validation loss: 0.1095
2024-05-25 02:17:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch119_loss0.10950848460197449.pypots
2024-05-25 02:17:29 [INFO]: Epoch 120 - training loss: 0.1103, validation loss: 0.1079
2024-05-25 02:17:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch120_loss0.1079097107052803.pypots
2024-05-25 02:17:46 [INFO]: Epoch 121 - training loss: 0.1118, validation loss: 0.1164
2024-05-25 02:17:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch121_loss0.11640993058681488.pypots
2024-05-25 02:18:03 [INFO]: Epoch 122 - training loss: 0.0996, validation loss: 0.1088
2024-05-25 02:18:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch122_loss0.10883714184165001.pypots
2024-05-25 02:18:19 [INFO]: Epoch 123 - training loss: 0.1040, validation loss: 0.1051
2024-05-25 02:18:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch123_loss0.1051205538213253.pypots
2024-05-25 02:18:36 [INFO]: Epoch 124 - training loss: 0.1017, validation loss: 0.1066
2024-05-25 02:18:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch124_loss0.10657108351588249.pypots
2024-05-25 02:18:53 [INFO]: Epoch 125 - training loss: 0.1003, validation loss: 0.1064
2024-05-25 02:18:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch125_loss0.10636197775602341.pypots
2024-05-25 02:19:09 [INFO]: Epoch 126 - training loss: 0.0971, validation loss: 0.1056
2024-05-25 02:19:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch126_loss0.10562494397163391.pypots
2024-05-25 02:19:26 [INFO]: Epoch 127 - training loss: 0.0975, validation loss: 0.1069
2024-05-25 02:19:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch127_loss0.10685953646898269.pypots
2024-05-25 02:19:43 [INFO]: Epoch 128 - training loss: 0.1123, validation loss: 0.1062
2024-05-25 02:19:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch128_loss0.1062117338180542.pypots
2024-05-25 02:19:59 [INFO]: Epoch 129 - training loss: 0.1022, validation loss: 0.1070
2024-05-25 02:19:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch129_loss0.10703073889017105.pypots
2024-05-25 02:20:16 [INFO]: Epoch 130 - training loss: 0.1026, validation loss: 0.1052
2024-05-25 02:20:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch130_loss0.1052005060017109.pypots
2024-05-25 02:20:33 [INFO]: Epoch 131 - training loss: 0.1123, validation loss: 0.1120
2024-05-25 02:20:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch131_loss0.11200995966792107.pypots
2024-05-25 02:20:49 [INFO]: Epoch 132 - training loss: 0.1119, validation loss: 0.1058
2024-05-25 02:20:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch132_loss0.10575776025652886.pypots
2024-05-25 02:21:06 [INFO]: Epoch 133 - training loss: 0.1111, validation loss: 0.1056
2024-05-25 02:21:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI_epoch133_loss0.1055756688117981.pypots
2024-05-25 02:21:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:21:06 [INFO]: Finished training. The best model is from epoch#123.
2024-05-25 02:21:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T014409/CSDI.pypots
2024-05-25 02:23:26 [INFO]: CSDI on Air-Quality: MAE=0.1026, MSE=0.1360
2024-05-25 02:23:26 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 02:23:26 [INFO]: Using the given device: cuda:0
2024-05-25 02:23:26 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T022326
2024-05-25 02:23:26 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T022326/tensorboard
2024-05-25 02:23:26 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 02:23:27 [INFO]: Epoch 001 - training loss: 65194.9696, validation loss: 0.6669
2024-05-25 02:23:27 [INFO]: Epoch 002 - training loss: 41970.7636, validation loss: 0.5791
2024-05-25 02:23:27 [INFO]: Epoch 003 - training loss: 41658.8394, validation loss: 0.5360
2024-05-25 02:23:28 [INFO]: Epoch 004 - training loss: 41526.2912, validation loss: 0.5187
2024-05-25 02:23:28 [INFO]: Epoch 005 - training loss: 41444.0093, validation loss: 0.4589
2024-05-25 02:23:28 [INFO]: Epoch 006 - training loss: 41411.9290, validation loss: 0.4493
2024-05-25 02:23:29 [INFO]: Epoch 007 - training loss: 41421.7216, validation loss: 0.4548
2024-05-25 02:23:29 [INFO]: Epoch 008 - training loss: 41337.6771, validation loss: 0.3616
2024-05-25 02:23:29 [INFO]: Epoch 009 - training loss: 41280.9685, validation loss: 0.3341
2024-05-25 02:23:30 [INFO]: Epoch 010 - training loss: 41233.9988, validation loss: 0.3091
2024-05-25 02:23:30 [INFO]: Epoch 011 - training loss: 41217.4973, validation loss: 0.3405
2024-05-25 02:23:30 [INFO]: Epoch 012 - training loss: 41212.3251, validation loss: 0.3014
2024-05-25 02:23:31 [INFO]: Epoch 013 - training loss: 41202.5408, validation loss: 0.2999
2024-05-25 02:23:31 [INFO]: Epoch 014 - training loss: 41193.8170, validation loss: 0.2952
2024-05-25 02:23:31 [INFO]: Epoch 015 - training loss: 41179.0710, validation loss: 0.2868
2024-05-25 02:23:32 [INFO]: Epoch 016 - training loss: 41156.5528, validation loss: 0.2907
2024-05-25 02:23:32 [INFO]: Epoch 017 - training loss: 41165.2374, validation loss: 0.2722
2024-05-25 02:23:32 [INFO]: Epoch 018 - training loss: 41148.1318, validation loss: 0.2717
2024-05-25 02:23:33 [INFO]: Epoch 019 - training loss: 41132.6690, validation loss: 0.2898
2024-05-25 02:23:33 [INFO]: Epoch 020 - training loss: 41125.7828, validation loss: 0.2620
2024-05-25 02:23:33 [INFO]: Epoch 021 - training loss: 41119.4369, validation loss: 0.2633
2024-05-25 02:23:34 [INFO]: Epoch 022 - training loss: 41105.5145, validation loss: 0.2598
2024-05-25 02:23:34 [INFO]: Epoch 023 - training loss: 41108.9126, validation loss: 0.2622
2024-05-25 02:23:34 [INFO]: Epoch 024 - training loss: 41102.0482, validation loss: 0.2684
2024-05-25 02:23:35 [INFO]: Epoch 025 - training loss: 41118.7088, validation loss: 0.2651
2024-05-25 02:23:35 [INFO]: Epoch 026 - training loss: 41096.4194, validation loss: 0.2552
2024-05-25 02:23:35 [INFO]: Epoch 027 - training loss: 41150.8921, validation loss: 0.2723
2024-05-25 02:23:36 [INFO]: Epoch 028 - training loss: 41112.4285, validation loss: 0.2531
2024-05-25 02:23:36 [INFO]: Epoch 029 - training loss: 41090.7966, validation loss: 0.2504
2024-05-25 02:23:36 [INFO]: Epoch 030 - training loss: 41088.2364, validation loss: 0.2541
2024-05-25 02:23:37 [INFO]: Epoch 031 - training loss: 41112.5971, validation loss: 0.2361
2024-05-25 02:23:37 [INFO]: Epoch 032 - training loss: 41070.3025, validation loss: 0.2358
2024-05-25 02:23:37 [INFO]: Epoch 033 - training loss: 41057.2907, validation loss: 0.2320
2024-05-25 02:23:38 [INFO]: Epoch 034 - training loss: 41057.3066, validation loss: 0.2272
2024-05-25 02:23:38 [INFO]: Epoch 035 - training loss: 41049.7490, validation loss: 0.2331
2024-05-25 02:23:38 [INFO]: Epoch 036 - training loss: 41073.3657, validation loss: 0.2478
2024-05-25 02:23:39 [INFO]: Epoch 037 - training loss: 41084.9816, validation loss: 0.2540
2024-05-25 02:23:39 [INFO]: Epoch 038 - training loss: 41064.5218, validation loss: 0.2376
2024-05-25 02:23:39 [INFO]: Epoch 039 - training loss: 41070.4718, validation loss: 0.2408
2024-05-25 02:23:40 [INFO]: Epoch 040 - training loss: 41062.5946, validation loss: 0.2480
2024-05-25 02:23:40 [INFO]: Epoch 041 - training loss: 41071.0924, validation loss: 0.2345
2024-05-25 02:23:40 [INFO]: Epoch 042 - training loss: 41044.3688, validation loss: 0.2278
2024-05-25 02:23:40 [INFO]: Epoch 043 - training loss: 41051.4398, validation loss: 0.2236
2024-05-25 02:23:41 [INFO]: Epoch 044 - training loss: 41043.5848, validation loss: 0.2183
2024-05-25 02:23:41 [INFO]: Epoch 045 - training loss: 41033.3668, validation loss: 0.2251
2024-05-25 02:23:41 [INFO]: Epoch 046 - training loss: 41031.6412, validation loss: 0.2191
2024-05-25 02:23:42 [INFO]: Epoch 047 - training loss: 41030.4557, validation loss: 0.2247
2024-05-25 02:23:42 [INFO]: Epoch 048 - training loss: 41037.8840, validation loss: 0.2266
2024-05-25 02:23:42 [INFO]: Epoch 049 - training loss: 41083.5615, validation loss: 0.2499
2024-05-25 02:23:43 [INFO]: Epoch 050 - training loss: 41071.0903, validation loss: 0.2335
2024-05-25 02:23:43 [INFO]: Epoch 051 - training loss: 41029.7530, validation loss: 0.2112
2024-05-25 02:23:43 [INFO]: Epoch 052 - training loss: 41019.6775, validation loss: 0.2207
2024-05-25 02:23:44 [INFO]: Epoch 053 - training loss: 41029.2105, validation loss: 0.2120
2024-05-25 02:23:44 [INFO]: Epoch 054 - training loss: 41012.2176, validation loss: 0.2155
2024-05-25 02:23:44 [INFO]: Epoch 055 - training loss: 41013.9443, validation loss: 0.2211
2024-05-25 02:23:45 [INFO]: Epoch 056 - training loss: 41014.0444, validation loss: 0.2048
2024-05-25 02:23:45 [INFO]: Epoch 057 - training loss: 41005.7104, validation loss: 0.2074
2024-05-25 02:23:45 [INFO]: Epoch 058 - training loss: 41008.0774, validation loss: 0.2129
2024-05-25 02:23:46 [INFO]: Epoch 059 - training loss: 41016.8189, validation loss: 0.2064
2024-05-25 02:23:46 [INFO]: Epoch 060 - training loss: 41069.5949, validation loss: 0.2249
2024-05-25 02:23:46 [INFO]: Epoch 061 - training loss: 41054.0734, validation loss: 0.2042
2024-05-25 02:23:47 [INFO]: Epoch 062 - training loss: 41031.1856, validation loss: 0.2096
2024-05-25 02:23:47 [INFO]: Epoch 063 - training loss: 41009.4345, validation loss: 0.2069
2024-05-25 02:23:47 [INFO]: Epoch 064 - training loss: 41016.8501, validation loss: 0.2127
2024-05-25 02:23:48 [INFO]: Epoch 065 - training loss: 41014.7749, validation loss: 0.2146
2024-05-25 02:23:48 [INFO]: Epoch 066 - training loss: 41001.8102, validation loss: 0.2003
2024-05-25 02:23:48 [INFO]: Epoch 067 - training loss: 40995.1801, validation loss: 0.1978
2024-05-25 02:23:49 [INFO]: Epoch 068 - training loss: 41005.3861, validation loss: 0.2045
2024-05-25 02:23:49 [INFO]: Epoch 069 - training loss: 41019.8492, validation loss: 0.2099
2024-05-25 02:23:49 [INFO]: Epoch 070 - training loss: 40999.1503, validation loss: 0.1998
2024-05-25 02:23:50 [INFO]: Epoch 071 - training loss: 40996.0723, validation loss: 0.2127
2024-05-25 02:23:50 [INFO]: Epoch 072 - training loss: 40997.7441, validation loss: 0.2036
2024-05-25 02:23:50 [INFO]: Epoch 073 - training loss: 40996.3436, validation loss: 0.2023
2024-05-25 02:23:51 [INFO]: Epoch 074 - training loss: 40997.8738, validation loss: 0.2149
2024-05-25 02:23:51 [INFO]: Epoch 075 - training loss: 41019.1262, validation loss: 0.3123
2024-05-25 02:23:51 [INFO]: Epoch 076 - training loss: 41169.1056, validation loss: 0.2290
2024-05-25 02:23:52 [INFO]: Epoch 077 - training loss: 41065.7455, validation loss: 0.2079
2024-05-25 02:23:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:23:52 [INFO]: Finished training. The best model is from epoch#67.
2024-05-25 02:23:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T022326/GPVAE.pypots
2024-05-25 02:23:52 [INFO]: GP-VAE on Air-Quality: MAE=0.2771, MSE=0.2220
2024-05-25 02:23:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 02:23:52 [INFO]: Using the given device: cuda:0
2024-05-25 02:23:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T022352
2024-05-25 02:23:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T022352/tensorboard
2024-05-25 02:23:52 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 02:23:57 [INFO]: Epoch 001 - generator training loss: 0.5134, discriminator training loss: 0.3720, validation loss: 0.5020
2024-05-25 02:24:01 [INFO]: Epoch 002 - generator training loss: 0.1502, discriminator training loss: 0.2420, validation loss: 0.3697
2024-05-25 02:24:05 [INFO]: Epoch 003 - generator training loss: 0.1009, discriminator training loss: 0.2380, validation loss: 0.3051
2024-05-25 02:24:09 [INFO]: Epoch 004 - generator training loss: 0.0626, discriminator training loss: 0.2370, validation loss: 0.2637
2024-05-25 02:24:13 [INFO]: Epoch 005 - generator training loss: 0.0331, discriminator training loss: 0.2358, validation loss: 0.2336
2024-05-25 02:24:17 [INFO]: Epoch 006 - generator training loss: 0.0155, discriminator training loss: 0.2351, validation loss: 0.2151
2024-05-25 02:24:21 [INFO]: Epoch 007 - generator training loss: 0.0068, discriminator training loss: 0.2338, validation loss: 0.2012
2024-05-25 02:24:25 [INFO]: Epoch 008 - generator training loss: -0.0060, discriminator training loss: 0.2329, validation loss: 0.1900
2024-05-25 02:24:29 [INFO]: Epoch 009 - generator training loss: -0.0113, discriminator training loss: 0.2315, validation loss: 0.1814
2024-05-25 02:24:34 [INFO]: Epoch 010 - generator training loss: -0.0160, discriminator training loss: 0.2301, validation loss: 0.1747
2024-05-25 02:24:38 [INFO]: Epoch 011 - generator training loss: -0.0240, discriminator training loss: 0.2287, validation loss: 0.1678
2024-05-25 02:24:42 [INFO]: Epoch 012 - generator training loss: -0.0257, discriminator training loss: 0.2270, validation loss: 0.1629
2024-05-25 02:24:46 [INFO]: Epoch 013 - generator training loss: -0.0317, discriminator training loss: 0.2254, validation loss: 0.1583
2024-05-25 02:24:50 [INFO]: Epoch 014 - generator training loss: -0.0342, discriminator training loss: 0.2241, validation loss: 0.1545
2024-05-25 02:24:54 [INFO]: Epoch 015 - generator training loss: -0.0347, discriminator training loss: 0.2222, validation loss: 0.1502
2024-05-25 02:24:58 [INFO]: Epoch 016 - generator training loss: -0.0363, discriminator training loss: 0.2212, validation loss: 0.1466
2024-05-25 02:25:02 [INFO]: Epoch 017 - generator training loss: -0.0405, discriminator training loss: 0.2194, validation loss: 0.1435
2024-05-25 02:25:06 [INFO]: Epoch 018 - generator training loss: -0.0431, discriminator training loss: 0.2178, validation loss: 0.1402
2024-05-25 02:25:10 [INFO]: Epoch 019 - generator training loss: -0.0413, discriminator training loss: 0.2163, validation loss: 0.1372
2024-05-25 02:25:15 [INFO]: Epoch 020 - generator training loss: -0.0454, discriminator training loss: 0.2146, validation loss: 0.1339
2024-05-25 02:25:19 [INFO]: Epoch 021 - generator training loss: -0.0452, discriminator training loss: 0.2131, validation loss: 0.1316
2024-05-25 02:25:23 [INFO]: Epoch 022 - generator training loss: -0.0460, discriminator training loss: 0.2117, validation loss: 0.1296
2024-05-25 02:25:27 [INFO]: Epoch 023 - generator training loss: -0.0473, discriminator training loss: 0.2101, validation loss: 0.1272
2024-05-25 02:25:31 [INFO]: Epoch 024 - generator training loss: -0.0488, discriminator training loss: 0.2080, validation loss: 0.1247
2024-05-25 02:25:35 [INFO]: Epoch 025 - generator training loss: -0.0475, discriminator training loss: 0.2064, validation loss: 0.1227
2024-05-25 02:25:39 [INFO]: Epoch 026 - generator training loss: -0.0482, discriminator training loss: 0.2047, validation loss: 0.1204
2024-05-25 02:25:43 [INFO]: Epoch 027 - generator training loss: -0.0494, discriminator training loss: 0.2031, validation loss: 0.1182
2024-05-25 02:25:47 [INFO]: Epoch 028 - generator training loss: -0.0466, discriminator training loss: 0.2015, validation loss: 0.1170
2024-05-25 02:25:51 [INFO]: Epoch 029 - generator training loss: -0.0498, discriminator training loss: 0.1994, validation loss: 0.1157
2024-05-25 02:25:55 [INFO]: Epoch 030 - generator training loss: -0.0488, discriminator training loss: 0.1977, validation loss: 0.1136
2024-05-25 02:26:00 [INFO]: Epoch 031 - generator training loss: -0.0505, discriminator training loss: 0.1960, validation loss: 0.1120
2024-05-25 02:26:04 [INFO]: Epoch 032 - generator training loss: -0.0511, discriminator training loss: 0.1944, validation loss: 0.1103
2024-05-25 02:26:08 [INFO]: Epoch 033 - generator training loss: -0.0502, discriminator training loss: 0.1926, validation loss: 0.1088
2024-05-25 02:26:12 [INFO]: Epoch 034 - generator training loss: -0.0505, discriminator training loss: 0.1908, validation loss: 0.1081
2024-05-25 02:26:16 [INFO]: Epoch 035 - generator training loss: -0.0498, discriminator training loss: 0.1890, validation loss: 0.1066
2024-05-25 02:26:20 [INFO]: Epoch 036 - generator training loss: -0.0496, discriminator training loss: 0.1875, validation loss: 0.1056
2024-05-25 02:26:24 [INFO]: Epoch 037 - generator training loss: -0.0486, discriminator training loss: 0.1859, validation loss: 0.1046
2024-05-25 02:26:28 [INFO]: Epoch 038 - generator training loss: -0.0485, discriminator training loss: 0.1844, validation loss: 0.1029
2024-05-25 02:26:32 [INFO]: Epoch 039 - generator training loss: -0.0484, discriminator training loss: 0.1828, validation loss: 0.1019
2024-05-25 02:26:36 [INFO]: Epoch 040 - generator training loss: -0.0477, discriminator training loss: 0.1811, validation loss: 0.1012
2024-05-25 02:26:41 [INFO]: Epoch 041 - generator training loss: -0.0480, discriminator training loss: 0.1796, validation loss: 0.1001
2024-05-25 02:26:45 [INFO]: Epoch 042 - generator training loss: -0.0468, discriminator training loss: 0.1781, validation loss: 0.0996
2024-05-25 02:26:49 [INFO]: Epoch 043 - generator training loss: -0.0461, discriminator training loss: 0.1769, validation loss: 0.0995
2024-05-25 02:26:53 [INFO]: Epoch 044 - generator training loss: -0.0462, discriminator training loss: 0.1754, validation loss: 0.0981
2024-05-25 02:26:57 [INFO]: Epoch 045 - generator training loss: -0.0462, discriminator training loss: 0.1744, validation loss: 0.0975
2024-05-25 02:27:01 [INFO]: Epoch 046 - generator training loss: -0.0443, discriminator training loss: 0.1726, validation loss: 0.0970
2024-05-25 02:27:05 [INFO]: Epoch 047 - generator training loss: -0.0448, discriminator training loss: 0.1714, validation loss: 0.0960
2024-05-25 02:27:09 [INFO]: Epoch 048 - generator training loss: -0.0443, discriminator training loss: 0.1702, validation loss: 0.0950
2024-05-25 02:27:13 [INFO]: Epoch 049 - generator training loss: -0.0450, discriminator training loss: 0.1688, validation loss: 0.0946
2024-05-25 02:27:17 [INFO]: Epoch 050 - generator training loss: -0.0450, discriminator training loss: 0.1679, validation loss: 0.0933
2024-05-25 02:27:21 [INFO]: Epoch 051 - generator training loss: -0.0442, discriminator training loss: 0.1664, validation loss: 0.0922
2024-05-25 02:27:26 [INFO]: Epoch 052 - generator training loss: -0.0444, discriminator training loss: 0.1653, validation loss: 0.0921
2024-05-25 02:27:30 [INFO]: Epoch 053 - generator training loss: -0.0434, discriminator training loss: 0.1645, validation loss: 0.0918
2024-05-25 02:27:34 [INFO]: Epoch 054 - generator training loss: -0.0435, discriminator training loss: 0.1633, validation loss: 0.0911
2024-05-25 02:27:38 [INFO]: Epoch 055 - generator training loss: -0.0432, discriminator training loss: 0.1624, validation loss: 0.0915
2024-05-25 02:27:42 [INFO]: Epoch 056 - generator training loss: -0.0433, discriminator training loss: 0.1611, validation loss: 0.0894
2024-05-25 02:27:46 [INFO]: Epoch 057 - generator training loss: -0.0434, discriminator training loss: 0.1602, validation loss: 0.0903
2024-05-25 02:27:50 [INFO]: Epoch 058 - generator training loss: -0.0428, discriminator training loss: 0.1593, validation loss: 0.0883
2024-05-25 02:27:54 [INFO]: Epoch 059 - generator training loss: -0.0419, discriminator training loss: 0.1584, validation loss: 0.0887
2024-05-25 02:27:58 [INFO]: Epoch 060 - generator training loss: -0.0427, discriminator training loss: 0.1578, validation loss: 0.0870
2024-05-25 02:28:02 [INFO]: Epoch 061 - generator training loss: -0.0424, discriminator training loss: 0.1569, validation loss: 0.0872
2024-05-25 02:28:06 [INFO]: Epoch 062 - generator training loss: -0.0417, discriminator training loss: 0.1563, validation loss: 0.0865
2024-05-25 02:28:11 [INFO]: Epoch 063 - generator training loss: -0.0424, discriminator training loss: 0.1553, validation loss: 0.0855
2024-05-25 02:28:15 [INFO]: Epoch 064 - generator training loss: -0.0415, discriminator training loss: 0.1541, validation loss: 0.0851
2024-05-25 02:28:19 [INFO]: Epoch 065 - generator training loss: -0.0417, discriminator training loss: 0.1536, validation loss: 0.0855
2024-05-25 02:28:23 [INFO]: Epoch 066 - generator training loss: -0.0415, discriminator training loss: 0.1529, validation loss: 0.0844
2024-05-25 02:28:27 [INFO]: Epoch 067 - generator training loss: -0.0413, discriminator training loss: 0.1525, validation loss: 0.0846
2024-05-25 02:28:31 [INFO]: Epoch 068 - generator training loss: -0.0417, discriminator training loss: 0.1519, validation loss: 0.0856
2024-05-25 02:28:35 [INFO]: Epoch 069 - generator training loss: -0.0413, discriminator training loss: 0.1511, validation loss: 0.0828
2024-05-25 02:28:39 [INFO]: Epoch 070 - generator training loss: -0.0401, discriminator training loss: 0.1506, validation loss: 0.0839
2024-05-25 02:28:43 [INFO]: Epoch 071 - generator training loss: -0.0410, discriminator training loss: 0.1500, validation loss: 0.0823
2024-05-25 02:28:47 [INFO]: Epoch 072 - generator training loss: -0.0416, discriminator training loss: 0.1494, validation loss: 0.0819
2024-05-25 02:28:52 [INFO]: Epoch 073 - generator training loss: -0.0406, discriminator training loss: 0.1491, validation loss: 0.0819
2024-05-25 02:28:56 [INFO]: Epoch 074 - generator training loss: -0.0405, discriminator training loss: 0.1487, validation loss: 0.0813
2024-05-25 02:29:00 [INFO]: Epoch 075 - generator training loss: -0.0413, discriminator training loss: 0.1479, validation loss: 0.0818
2024-05-25 02:29:04 [INFO]: Epoch 076 - generator training loss: -0.0403, discriminator training loss: 0.1477, validation loss: 0.0806
2024-05-25 02:29:08 [INFO]: Epoch 077 - generator training loss: -0.0406, discriminator training loss: 0.1470, validation loss: 0.0801
2024-05-25 02:29:12 [INFO]: Epoch 078 - generator training loss: -0.0412, discriminator training loss: 0.1464, validation loss: 0.0825
2024-05-25 02:29:16 [INFO]: Epoch 079 - generator training loss: -0.0410, discriminator training loss: 0.1461, validation loss: 0.0814
2024-05-25 02:29:20 [INFO]: Epoch 080 - generator training loss: -0.0413, discriminator training loss: 0.1458, validation loss: 0.0798
2024-05-25 02:29:24 [INFO]: Epoch 081 - generator training loss: -0.0404, discriminator training loss: 0.1454, validation loss: 0.0795
2024-05-25 02:29:28 [INFO]: Epoch 082 - generator training loss: -0.0407, discriminator training loss: 0.1447, validation loss: 0.0793
2024-05-25 02:29:33 [INFO]: Epoch 083 - generator training loss: -0.0407, discriminator training loss: 0.1447, validation loss: 0.0783
2024-05-25 02:29:37 [INFO]: Epoch 084 - generator training loss: -0.0412, discriminator training loss: 0.1438, validation loss: 0.0797
2024-05-25 02:29:41 [INFO]: Epoch 085 - generator training loss: -0.0413, discriminator training loss: 0.1436, validation loss: 0.0783
2024-05-25 02:29:45 [INFO]: Epoch 086 - generator training loss: -0.0422, discriminator training loss: 0.1433, validation loss: 0.0779
2024-05-25 02:29:49 [INFO]: Epoch 087 - generator training loss: -0.0407, discriminator training loss: 0.1431, validation loss: 0.0782
2024-05-25 02:29:53 [INFO]: Epoch 088 - generator training loss: -0.0409, discriminator training loss: 0.1427, validation loss: 0.0788
2024-05-25 02:29:57 [INFO]: Epoch 089 - generator training loss: -0.0405, discriminator training loss: 0.1420, validation loss: 0.0776
2024-05-25 02:30:01 [INFO]: Epoch 090 - generator training loss: -0.0413, discriminator training loss: 0.1423, validation loss: 0.0776
2024-05-25 02:30:05 [INFO]: Epoch 091 - generator training loss: -0.0402, discriminator training loss: 0.1416, validation loss: 0.0772
2024-05-25 02:30:09 [INFO]: Epoch 092 - generator training loss: -0.0419, discriminator training loss: 0.1412, validation loss: 0.0757
2024-05-25 02:30:13 [INFO]: Epoch 093 - generator training loss: -0.0412, discriminator training loss: 0.1414, validation loss: 0.0760
2024-05-25 02:30:17 [INFO]: Epoch 094 - generator training loss: -0.0424, discriminator training loss: 0.1411, validation loss: 0.0753
2024-05-25 02:30:22 [INFO]: Epoch 095 - generator training loss: -0.0420, discriminator training loss: 0.1407, validation loss: 0.0763
2024-05-25 02:30:26 [INFO]: Epoch 096 - generator training loss: -0.0410, discriminator training loss: 0.1398, validation loss: 0.0758
2024-05-25 02:30:30 [INFO]: Epoch 097 - generator training loss: -0.0388, discriminator training loss: 0.1398, validation loss: 0.0780
2024-05-25 02:30:34 [INFO]: Epoch 098 - generator training loss: -0.0394, discriminator training loss: 0.1396, validation loss: 0.0764
2024-05-25 02:30:38 [INFO]: Epoch 099 - generator training loss: -0.0415, discriminator training loss: 0.1394, validation loss: 0.0753
2024-05-25 02:30:42 [INFO]: Epoch 100 - generator training loss: -0.0421, discriminator training loss: 0.1394, validation loss: 0.0759
2024-05-25 02:30:46 [INFO]: Epoch 101 - generator training loss: -0.0420, discriminator training loss: 0.1392, validation loss: 0.0757
2024-05-25 02:30:50 [INFO]: Epoch 102 - generator training loss: -0.0411, discriminator training loss: 0.1390, validation loss: 0.0747
2024-05-25 02:30:54 [INFO]: Epoch 103 - generator training loss: -0.0422, discriminator training loss: 0.1387, validation loss: 0.0737
2024-05-25 02:30:58 [INFO]: Epoch 104 - generator training loss: -0.0427, discriminator training loss: 0.1384, validation loss: 0.0742
2024-05-25 02:31:03 [INFO]: Epoch 105 - generator training loss: -0.0430, discriminator training loss: 0.1383, validation loss: 0.0737
2024-05-25 02:31:07 [INFO]: Epoch 106 - generator training loss: -0.0427, discriminator training loss: 0.1379, validation loss: 0.0741
2024-05-25 02:31:11 [INFO]: Epoch 107 - generator training loss: -0.0430, discriminator training loss: 0.1376, validation loss: 0.0736
2024-05-25 02:31:15 [INFO]: Epoch 108 - generator training loss: -0.0428, discriminator training loss: 0.1378, validation loss: 0.0728
2024-05-25 02:31:19 [INFO]: Epoch 109 - generator training loss: -0.0422, discriminator training loss: 0.1373, validation loss: 0.0742
2024-05-25 02:31:23 [INFO]: Epoch 110 - generator training loss: -0.0423, discriminator training loss: 0.1371, validation loss: 0.0738
2024-05-25 02:31:27 [INFO]: Epoch 111 - generator training loss: -0.0433, discriminator training loss: 0.1372, validation loss: 0.0737
2024-05-25 02:31:31 [INFO]: Epoch 112 - generator training loss: -0.0429, discriminator training loss: 0.1367, validation loss: 0.0729
2024-05-25 02:31:35 [INFO]: Epoch 113 - generator training loss: -0.0433, discriminator training loss: 0.1367, validation loss: 0.0734
2024-05-25 02:31:39 [INFO]: Epoch 114 - generator training loss: -0.0432, discriminator training loss: 0.1365, validation loss: 0.0726
2024-05-25 02:31:44 [INFO]: Epoch 115 - generator training loss: -0.0432, discriminator training loss: 0.1365, validation loss: 0.0753
2024-05-25 02:31:48 [INFO]: Epoch 116 - generator training loss: -0.0433, discriminator training loss: 0.1366, validation loss: 0.0726
2024-05-25 02:31:52 [INFO]: Epoch 117 - generator training loss: -0.0431, discriminator training loss: 0.1357, validation loss: 0.0732
2024-05-25 02:31:56 [INFO]: Epoch 118 - generator training loss: -0.0423, discriminator training loss: 0.1358, validation loss: 0.0751
2024-05-25 02:32:00 [INFO]: Epoch 119 - generator training loss: -0.0427, discriminator training loss: 0.1356, validation loss: 0.0723
2024-05-25 02:32:04 [INFO]: Epoch 120 - generator training loss: -0.0440, discriminator training loss: 0.1357, validation loss: 0.0720
2024-05-25 02:32:08 [INFO]: Epoch 121 - generator training loss: -0.0440, discriminator training loss: 0.1351, validation loss: 0.0725
2024-05-25 02:32:12 [INFO]: Epoch 122 - generator training loss: -0.0441, discriminator training loss: 0.1350, validation loss: 0.0717
2024-05-25 02:32:16 [INFO]: Epoch 123 - generator training loss: -0.0441, discriminator training loss: 0.1353, validation loss: 0.0720
2024-05-25 02:32:20 [INFO]: Epoch 124 - generator training loss: -0.0376, discriminator training loss: 0.1352, validation loss: 0.0730
2024-05-25 02:32:24 [INFO]: Epoch 125 - generator training loss: -0.0410, discriminator training loss: 0.1347, validation loss: 0.0729
2024-05-25 02:32:29 [INFO]: Epoch 126 - generator training loss: -0.0437, discriminator training loss: 0.1351, validation loss: 0.0727
2024-05-25 02:32:33 [INFO]: Epoch 127 - generator training loss: -0.0435, discriminator training loss: 0.1346, validation loss: 0.0714
2024-05-25 02:32:37 [INFO]: Epoch 128 - generator training loss: -0.0437, discriminator training loss: 0.1347, validation loss: 0.0713
2024-05-25 02:32:41 [INFO]: Epoch 129 - generator training loss: -0.0439, discriminator training loss: 0.1341, validation loss: 0.0709
2024-05-25 02:32:45 [INFO]: Epoch 130 - generator training loss: -0.0450, discriminator training loss: 0.1342, validation loss: 0.0713
2024-05-25 02:32:49 [INFO]: Epoch 131 - generator training loss: -0.0447, discriminator training loss: 0.1345, validation loss: 0.0707
2024-05-25 02:32:53 [INFO]: Epoch 132 - generator training loss: -0.0450, discriminator training loss: 0.1343, validation loss: 0.0706
2024-05-25 02:32:57 [INFO]: Epoch 133 - generator training loss: -0.0449, discriminator training loss: 0.1338, validation loss: 0.0705
2024-05-25 02:33:01 [INFO]: Epoch 134 - generator training loss: -0.0450, discriminator training loss: 0.1338, validation loss: 0.0702
2024-05-25 02:33:05 [INFO]: Epoch 135 - generator training loss: -0.0449, discriminator training loss: 0.1336, validation loss: 0.0706
2024-05-25 02:33:10 [INFO]: Epoch 136 - generator training loss: -0.0454, discriminator training loss: 0.1334, validation loss: 0.0709
2024-05-25 02:33:14 [INFO]: Epoch 137 - generator training loss: -0.0445, discriminator training loss: 0.1338, validation loss: 0.0717
2024-05-25 02:33:18 [INFO]: Epoch 138 - generator training loss: -0.0446, discriminator training loss: 0.1336, validation loss: 0.0698
2024-05-25 02:33:22 [INFO]: Epoch 139 - generator training loss: -0.0438, discriminator training loss: 0.1331, validation loss: 0.0715
2024-05-25 02:33:26 [INFO]: Epoch 140 - generator training loss: -0.0409, discriminator training loss: 0.1330, validation loss: 0.0710
2024-05-25 02:33:30 [INFO]: Epoch 141 - generator training loss: -0.0445, discriminator training loss: 0.1330, validation loss: 0.0710
2024-05-25 02:33:34 [INFO]: Epoch 142 - generator training loss: -0.0445, discriminator training loss: 0.1332, validation loss: 0.0710
2024-05-25 02:33:38 [INFO]: Epoch 143 - generator training loss: -0.0449, discriminator training loss: 0.1329, validation loss: 0.0707
2024-05-25 02:33:42 [INFO]: Epoch 144 - generator training loss: -0.0455, discriminator training loss: 0.1327, validation loss: 0.0701
2024-05-25 02:33:46 [INFO]: Epoch 145 - generator training loss: -0.0458, discriminator training loss: 0.1327, validation loss: 0.0714
2024-05-25 02:33:50 [INFO]: Epoch 146 - generator training loss: -0.0452, discriminator training loss: 0.1325, validation loss: 0.0704
2024-05-25 02:33:55 [INFO]: Epoch 147 - generator training loss: -0.0458, discriminator training loss: 0.1325, validation loss: 0.0693
2024-05-25 02:33:59 [INFO]: Epoch 148 - generator training loss: -0.0462, discriminator training loss: 0.1323, validation loss: 0.0701
2024-05-25 02:34:03 [INFO]: Epoch 149 - generator training loss: -0.0466, discriminator training loss: 0.1327, validation loss: 0.0701
2024-05-25 02:34:07 [INFO]: Epoch 150 - generator training loss: -0.0474, discriminator training loss: 0.1316, validation loss: 0.0716
2024-05-25 02:34:11 [INFO]: Epoch 151 - generator training loss: -0.0439, discriminator training loss: 0.1322, validation loss: 0.0712
2024-05-25 02:34:15 [INFO]: Epoch 152 - generator training loss: -0.0440, discriminator training loss: 0.1320, validation loss: 0.0698
2024-05-25 02:34:19 [INFO]: Epoch 153 - generator training loss: -0.0460, discriminator training loss: 0.1321, validation loss: 0.0685
2024-05-25 02:34:23 [INFO]: Epoch 154 - generator training loss: -0.0470, discriminator training loss: 0.1319, validation loss: 0.0682
2024-05-25 02:34:27 [INFO]: Epoch 155 - generator training loss: -0.0470, discriminator training loss: 0.1314, validation loss: 0.0682
2024-05-25 02:34:31 [INFO]: Epoch 156 - generator training loss: -0.0479, discriminator training loss: 0.1317, validation loss: 0.0677
2024-05-25 02:34:36 [INFO]: Epoch 157 - generator training loss: -0.0471, discriminator training loss: 0.1318, validation loss: 0.0688
2024-05-25 02:34:40 [INFO]: Epoch 158 - generator training loss: -0.0480, discriminator training loss: 0.1315, validation loss: 0.0685
2024-05-25 02:34:44 [INFO]: Epoch 159 - generator training loss: -0.0482, discriminator training loss: 0.1313, validation loss: 0.0688
2024-05-25 02:34:48 [INFO]: Epoch 160 - generator training loss: -0.0478, discriminator training loss: 0.1316, validation loss: 0.0681
2024-05-25 02:34:52 [INFO]: Epoch 161 - generator training loss: -0.0482, discriminator training loss: 0.1315, validation loss: 0.0685
2024-05-25 02:34:56 [INFO]: Epoch 162 - generator training loss: -0.0484, discriminator training loss: 0.1310, validation loss: 0.0682
2024-05-25 02:35:00 [INFO]: Epoch 163 - generator training loss: -0.0478, discriminator training loss: 0.1312, validation loss: 0.0690
2024-05-25 02:35:04 [INFO]: Epoch 164 - generator training loss: -0.0482, discriminator training loss: 0.1309, validation loss: 0.0683
2024-05-25 02:35:08 [INFO]: Epoch 165 - generator training loss: -0.0481, discriminator training loss: 0.1314, validation loss: 0.0694
2024-05-25 02:35:12 [INFO]: Epoch 166 - generator training loss: -0.0470, discriminator training loss: 0.1310, validation loss: 0.0706
2024-05-25 02:35:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:35:12 [INFO]: Finished training. The best model is from epoch#156.
2024-05-25 02:35:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T022352/USGAN.pypots
2024-05-25 02:35:13 [INFO]: US-GAN on Air-Quality: MAE=0.1414, MSE=0.0874
2024-05-25 02:35:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 02:35:13 [INFO]: Using the given device: cuda:0
2024-05-25 02:35:13 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T023513
2024-05-25 02:35:13 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T023513/tensorboard
2024-05-25 02:35:13 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 02:35:17 [INFO]: Epoch 001 - training loss: 1.4020, validation loss: 0.9318
2024-05-25 02:35:19 [INFO]: Epoch 002 - training loss: 1.1324, validation loss: 0.6898
2024-05-25 02:35:22 [INFO]: Epoch 003 - training loss: 0.9412, validation loss: 0.5739
2024-05-25 02:35:25 [INFO]: Epoch 004 - training loss: 0.8304, validation loss: 0.5015
2024-05-25 02:35:28 [INFO]: Epoch 005 - training loss: 0.7526, validation loss: 0.4537
2024-05-25 02:35:31 [INFO]: Epoch 006 - training loss: 0.6992, validation loss: 0.4154
2024-05-25 02:35:34 [INFO]: Epoch 007 - training loss: 0.6553, validation loss: 0.3856
2024-05-25 02:35:36 [INFO]: Epoch 008 - training loss: 0.6226, validation loss: 0.3602
2024-05-25 02:35:39 [INFO]: Epoch 009 - training loss: 0.5974, validation loss: 0.3414
2024-05-25 02:35:42 [INFO]: Epoch 010 - training loss: 0.5764, validation loss: 0.3248
2024-05-25 02:35:45 [INFO]: Epoch 011 - training loss: 0.5594, validation loss: 0.3113
2024-05-25 02:35:48 [INFO]: Epoch 012 - training loss: 0.5478, validation loss: 0.2996
2024-05-25 02:35:50 [INFO]: Epoch 013 - training loss: 0.5342, validation loss: 0.2904
2024-05-25 02:35:53 [INFO]: Epoch 014 - training loss: 0.5217, validation loss: 0.2805
2024-05-25 02:35:56 [INFO]: Epoch 015 - training loss: 0.5124, validation loss: 0.2739
2024-05-25 02:35:59 [INFO]: Epoch 016 - training loss: 0.5023, validation loss: 0.2665
2024-05-25 02:36:02 [INFO]: Epoch 017 - training loss: 0.4936, validation loss: 0.2607
2024-05-25 02:36:04 [INFO]: Epoch 018 - training loss: 0.4864, validation loss: 0.2546
2024-05-25 02:36:07 [INFO]: Epoch 019 - training loss: 0.4767, validation loss: 0.2493
2024-05-25 02:36:10 [INFO]: Epoch 020 - training loss: 0.4699, validation loss: 0.2446
2024-05-25 02:36:13 [INFO]: Epoch 021 - training loss: 0.4641, validation loss: 0.2393
2024-05-25 02:36:16 [INFO]: Epoch 022 - training loss: 0.4568, validation loss: 0.2350
2024-05-25 02:36:19 [INFO]: Epoch 023 - training loss: 0.4510, validation loss: 0.2312
2024-05-25 02:36:21 [INFO]: Epoch 024 - training loss: 0.4445, validation loss: 0.2267
2024-05-25 02:36:24 [INFO]: Epoch 025 - training loss: 0.4385, validation loss: 0.2228
2024-05-25 02:36:27 [INFO]: Epoch 026 - training loss: 0.4336, validation loss: 0.2192
2024-05-25 02:36:30 [INFO]: Epoch 027 - training loss: 0.4280, validation loss: 0.2154
2024-05-25 02:36:33 [INFO]: Epoch 028 - training loss: 0.4222, validation loss: 0.2119
2024-05-25 02:36:35 [INFO]: Epoch 029 - training loss: 0.4183, validation loss: 0.2089
2024-05-25 02:36:38 [INFO]: Epoch 030 - training loss: 0.4136, validation loss: 0.2052
2024-05-25 02:36:41 [INFO]: Epoch 031 - training loss: 0.4086, validation loss: 0.2021
2024-05-25 02:36:44 [INFO]: Epoch 032 - training loss: 0.4048, validation loss: 0.1994
2024-05-25 02:36:47 [INFO]: Epoch 033 - training loss: 0.4002, validation loss: 0.1962
2024-05-25 02:36:49 [INFO]: Epoch 034 - training loss: 0.3970, validation loss: 0.1931
2024-05-25 02:36:52 [INFO]: Epoch 035 - training loss: 0.3922, validation loss: 0.1901
2024-05-25 02:36:55 [INFO]: Epoch 036 - training loss: 0.3885, validation loss: 0.1875
2024-05-25 02:36:58 [INFO]: Epoch 037 - training loss: 0.3851, validation loss: 0.1852
2024-05-25 02:37:01 [INFO]: Epoch 038 - training loss: 0.3821, validation loss: 0.1825
2024-05-25 02:37:03 [INFO]: Epoch 039 - training loss: 0.3785, validation loss: 0.1794
2024-05-25 02:37:06 [INFO]: Epoch 040 - training loss: 0.3753, validation loss: 0.1772
2024-05-25 02:37:09 [INFO]: Epoch 041 - training loss: 0.3722, validation loss: 0.1745
2024-05-25 02:37:12 [INFO]: Epoch 042 - training loss: 0.3681, validation loss: 0.1728
2024-05-25 02:37:15 [INFO]: Epoch 043 - training loss: 0.3658, validation loss: 0.1697
2024-05-25 02:37:17 [INFO]: Epoch 044 - training loss: 0.3624, validation loss: 0.1682
2024-05-25 02:37:20 [INFO]: Epoch 045 - training loss: 0.3598, validation loss: 0.1657
2024-05-25 02:37:23 [INFO]: Epoch 046 - training loss: 0.3566, validation loss: 0.1638
2024-05-25 02:37:26 [INFO]: Epoch 047 - training loss: 0.3556, validation loss: 0.1618
2024-05-25 02:37:29 [INFO]: Epoch 048 - training loss: 0.3521, validation loss: 0.1598
2024-05-25 02:37:32 [INFO]: Epoch 049 - training loss: 0.3508, validation loss: 0.1582
2024-05-25 02:37:34 [INFO]: Epoch 050 - training loss: 0.3466, validation loss: 0.1564
2024-05-25 02:37:37 [INFO]: Epoch 051 - training loss: 0.3447, validation loss: 0.1545
2024-05-25 02:37:40 [INFO]: Epoch 052 - training loss: 0.3427, validation loss: 0.1530
2024-05-25 02:37:43 [INFO]: Epoch 053 - training loss: 0.3404, validation loss: 0.1515
2024-05-25 02:37:46 [INFO]: Epoch 054 - training loss: 0.3379, validation loss: 0.1498
2024-05-25 02:37:48 [INFO]: Epoch 055 - training loss: 0.3365, validation loss: 0.1487
2024-05-25 02:37:51 [INFO]: Epoch 056 - training loss: 0.3360, validation loss: 0.1474
2024-05-25 02:37:54 [INFO]: Epoch 057 - training loss: 0.3338, validation loss: 0.1458
2024-05-25 02:37:57 [INFO]: Epoch 058 - training loss: 0.3321, validation loss: 0.1440
2024-05-25 02:38:00 [INFO]: Epoch 059 - training loss: 0.3298, validation loss: 0.1429
2024-05-25 02:38:02 [INFO]: Epoch 060 - training loss: 0.3277, validation loss: 0.1420
2024-05-25 02:38:05 [INFO]: Epoch 061 - training loss: 0.3270, validation loss: 0.1409
2024-05-25 02:38:08 [INFO]: Epoch 062 - training loss: 0.3251, validation loss: 0.1397
2024-05-25 02:38:11 [INFO]: Epoch 063 - training loss: 0.3236, validation loss: 0.1386
2024-05-25 02:38:14 [INFO]: Epoch 064 - training loss: 0.3216, validation loss: 0.1376
2024-05-25 02:38:17 [INFO]: Epoch 065 - training loss: 0.3199, validation loss: 0.1367
2024-05-25 02:38:19 [INFO]: Epoch 066 - training loss: 0.3191, validation loss: 0.1357
2024-05-25 02:38:22 [INFO]: Epoch 067 - training loss: 0.3181, validation loss: 0.1347
2024-05-25 02:38:25 [INFO]: Epoch 068 - training loss: 0.3161, validation loss: 0.1338
2024-05-25 02:38:28 [INFO]: Epoch 069 - training loss: 0.3152, validation loss: 0.1331
2024-05-25 02:38:31 [INFO]: Epoch 070 - training loss: 0.3152, validation loss: 0.1324
2024-05-25 02:38:33 [INFO]: Epoch 071 - training loss: 0.3126, validation loss: 0.1312
2024-05-25 02:38:36 [INFO]: Epoch 072 - training loss: 0.3121, validation loss: 0.1304
2024-05-25 02:38:39 [INFO]: Epoch 073 - training loss: 0.3101, validation loss: 0.1296
2024-05-25 02:38:42 [INFO]: Epoch 074 - training loss: 0.3093, validation loss: 0.1288
2024-05-25 02:38:45 [INFO]: Epoch 075 - training loss: 0.3087, validation loss: 0.1280
2024-05-25 02:38:47 [INFO]: Epoch 076 - training loss: 0.3066, validation loss: 0.1276
2024-05-25 02:38:50 [INFO]: Epoch 077 - training loss: 0.3064, validation loss: 0.1264
2024-05-25 02:38:53 [INFO]: Epoch 078 - training loss: 0.3055, validation loss: 0.1259
2024-05-25 02:38:56 [INFO]: Epoch 079 - training loss: 0.3042, validation loss: 0.1251
2024-05-25 02:38:59 [INFO]: Epoch 080 - training loss: 0.3032, validation loss: 0.1246
2024-05-25 02:39:01 [INFO]: Epoch 081 - training loss: 0.3020, validation loss: 0.1237
2024-05-25 02:39:04 [INFO]: Epoch 082 - training loss: 0.3016, validation loss: 0.1230
2024-05-25 02:39:07 [INFO]: Epoch 083 - training loss: 0.3004, validation loss: 0.1224
2024-05-25 02:39:10 [INFO]: Epoch 084 - training loss: 0.2991, validation loss: 0.1217
2024-05-25 02:39:13 [INFO]: Epoch 085 - training loss: 0.2988, validation loss: 0.1212
2024-05-25 02:39:15 [INFO]: Epoch 086 - training loss: 0.2978, validation loss: 0.1207
2024-05-25 02:39:18 [INFO]: Epoch 087 - training loss: 0.2977, validation loss: 0.1200
2024-05-25 02:39:21 [INFO]: Epoch 088 - training loss: 0.2977, validation loss: 0.1191
2024-05-25 02:39:24 [INFO]: Epoch 089 - training loss: 0.2958, validation loss: 0.1188
2024-05-25 02:39:27 [INFO]: Epoch 090 - training loss: 0.2949, validation loss: 0.1182
2024-05-25 02:39:30 [INFO]: Epoch 091 - training loss: 0.2949, validation loss: 0.1175
2024-05-25 02:39:32 [INFO]: Epoch 092 - training loss: 0.2929, validation loss: 0.1171
2024-05-25 02:39:35 [INFO]: Epoch 093 - training loss: 0.2929, validation loss: 0.1165
2024-05-25 02:39:38 [INFO]: Epoch 094 - training loss: 0.2926, validation loss: 0.1159
2024-05-25 02:39:41 [INFO]: Epoch 095 - training loss: 0.2918, validation loss: 0.1154
2024-05-25 02:39:44 [INFO]: Epoch 096 - training loss: 0.2903, validation loss: 0.1148
2024-05-25 02:39:46 [INFO]: Epoch 097 - training loss: 0.2895, validation loss: 0.1143
2024-05-25 02:39:49 [INFO]: Epoch 098 - training loss: 0.2893, validation loss: 0.1138
2024-05-25 02:39:52 [INFO]: Epoch 099 - training loss: 0.2896, validation loss: 0.1131
2024-05-25 02:39:55 [INFO]: Epoch 100 - training loss: 0.2883, validation loss: 0.1128
2024-05-25 02:39:58 [INFO]: Epoch 101 - training loss: 0.2873, validation loss: 0.1123
2024-05-25 02:40:00 [INFO]: Epoch 102 - training loss: 0.2871, validation loss: 0.1117
2024-05-25 02:40:03 [INFO]: Epoch 103 - training loss: 0.2859, validation loss: 0.1113
2024-05-25 02:40:06 [INFO]: Epoch 104 - training loss: 0.2851, validation loss: 0.1108
2024-05-25 02:40:09 [INFO]: Epoch 105 - training loss: 0.2854, validation loss: 0.1104
2024-05-25 02:40:12 [INFO]: Epoch 106 - training loss: 0.2841, validation loss: 0.1100
2024-05-25 02:40:15 [INFO]: Epoch 107 - training loss: 0.2832, validation loss: 0.1093
2024-05-25 02:40:17 [INFO]: Epoch 108 - training loss: 0.2830, validation loss: 0.1089
2024-05-25 02:40:20 [INFO]: Epoch 109 - training loss: 0.2822, validation loss: 0.1084
2024-05-25 02:40:23 [INFO]: Epoch 110 - training loss: 0.2817, validation loss: 0.1079
2024-05-25 02:40:26 [INFO]: Epoch 111 - training loss: 0.2811, validation loss: 0.1076
2024-05-25 02:40:29 [INFO]: Epoch 112 - training loss: 0.2813, validation loss: 0.1072
2024-05-25 02:40:31 [INFO]: Epoch 113 - training loss: 0.2805, validation loss: 0.1067
2024-05-25 02:40:34 [INFO]: Epoch 114 - training loss: 0.2792, validation loss: 0.1062
2024-05-25 02:40:37 [INFO]: Epoch 115 - training loss: 0.2790, validation loss: 0.1060
2024-05-25 02:40:40 [INFO]: Epoch 116 - training loss: 0.2791, validation loss: 0.1055
2024-05-25 02:40:43 [INFO]: Epoch 117 - training loss: 0.2783, validation loss: 0.1050
2024-05-25 02:40:45 [INFO]: Epoch 118 - training loss: 0.2773, validation loss: 0.1047
2024-05-25 02:40:48 [INFO]: Epoch 119 - training loss: 0.2770, validation loss: 0.1042
2024-05-25 02:40:51 [INFO]: Epoch 120 - training loss: 0.2766, validation loss: 0.1039
2024-05-25 02:40:54 [INFO]: Epoch 121 - training loss: 0.2763, validation loss: 0.1035
2024-05-25 02:40:57 [INFO]: Epoch 122 - training loss: 0.2763, validation loss: 0.1029
2024-05-25 02:40:59 [INFO]: Epoch 123 - training loss: 0.2752, validation loss: 0.1028
2024-05-25 02:41:02 [INFO]: Epoch 124 - training loss: 0.2751, validation loss: 0.1024
2024-05-25 02:41:05 [INFO]: Epoch 125 - training loss: 0.2747, validation loss: 0.1022
2024-05-25 02:41:08 [INFO]: Epoch 126 - training loss: 0.2735, validation loss: 0.1017
2024-05-25 02:41:11 [INFO]: Epoch 127 - training loss: 0.2741, validation loss: 0.1012
2024-05-25 02:41:13 [INFO]: Epoch 128 - training loss: 0.2727, validation loss: 0.1009
2024-05-25 02:41:16 [INFO]: Epoch 129 - training loss: 0.2725, validation loss: 0.1007
2024-05-25 02:41:19 [INFO]: Epoch 130 - training loss: 0.2720, validation loss: 0.1002
2024-05-25 02:41:22 [INFO]: Epoch 131 - training loss: 0.2715, validation loss: 0.1001
2024-05-25 02:41:25 [INFO]: Epoch 132 - training loss: 0.2715, validation loss: 0.0997
2024-05-25 02:41:28 [INFO]: Epoch 133 - training loss: 0.2703, validation loss: 0.0992
2024-05-25 02:41:30 [INFO]: Epoch 134 - training loss: 0.2699, validation loss: 0.0989
2024-05-25 02:41:33 [INFO]: Epoch 135 - training loss: 0.2702, validation loss: 0.0987
2024-05-25 02:41:36 [INFO]: Epoch 136 - training loss: 0.2695, validation loss: 0.0982
2024-05-25 02:41:39 [INFO]: Epoch 137 - training loss: 0.2691, validation loss: 0.0979
2024-05-25 02:41:42 [INFO]: Epoch 138 - training loss: 0.2692, validation loss: 0.0977
2024-05-25 02:41:44 [INFO]: Epoch 139 - training loss: 0.2686, validation loss: 0.0973
2024-05-25 02:41:47 [INFO]: Epoch 140 - training loss: 0.2683, validation loss: 0.0968
2024-05-25 02:41:50 [INFO]: Epoch 141 - training loss: 0.2670, validation loss: 0.0967
2024-05-25 02:41:53 [INFO]: Epoch 142 - training loss: 0.2675, validation loss: 0.0965
2024-05-25 02:41:56 [INFO]: Epoch 143 - training loss: 0.2669, validation loss: 0.0962
2024-05-25 02:41:59 [INFO]: Epoch 144 - training loss: 0.2664, validation loss: 0.0959
2024-05-25 02:42:01 [INFO]: Epoch 145 - training loss: 0.2658, validation loss: 0.0956
2024-05-25 02:42:04 [INFO]: Epoch 146 - training loss: 0.2656, validation loss: 0.0954
2024-05-25 02:42:07 [INFO]: Epoch 147 - training loss: 0.2661, validation loss: 0.0950
2024-05-25 02:42:10 [INFO]: Epoch 148 - training loss: 0.2653, validation loss: 0.0947
2024-05-25 02:42:13 [INFO]: Epoch 149 - training loss: 0.2649, validation loss: 0.0945
2024-05-25 02:42:15 [INFO]: Epoch 150 - training loss: 0.2641, validation loss: 0.0942
2024-05-25 02:42:18 [INFO]: Epoch 151 - training loss: 0.2643, validation loss: 0.0940
2024-05-25 02:42:21 [INFO]: Epoch 152 - training loss: 0.2637, validation loss: 0.0937
2024-05-25 02:42:24 [INFO]: Epoch 153 - training loss: 0.2631, validation loss: 0.0935
2024-05-25 02:42:27 [INFO]: Epoch 154 - training loss: 0.2631, validation loss: 0.0932
2024-05-25 02:42:29 [INFO]: Epoch 155 - training loss: 0.2625, validation loss: 0.0931
2024-05-25 02:42:32 [INFO]: Epoch 156 - training loss: 0.2630, validation loss: 0.0928
2024-05-25 02:42:35 [INFO]: Epoch 157 - training loss: 0.2618, validation loss: 0.0923
2024-05-25 02:42:38 [INFO]: Epoch 158 - training loss: 0.2619, validation loss: 0.0921
2024-05-25 02:42:41 [INFO]: Epoch 159 - training loss: 0.2620, validation loss: 0.0921
2024-05-25 02:42:43 [INFO]: Epoch 160 - training loss: 0.2615, validation loss: 0.0916
2024-05-25 02:42:46 [INFO]: Epoch 161 - training loss: 0.2611, validation loss: 0.0915
2024-05-25 02:42:49 [INFO]: Epoch 162 - training loss: 0.2605, validation loss: 0.0913
2024-05-25 02:42:52 [INFO]: Epoch 163 - training loss: 0.2601, validation loss: 0.0910
2024-05-25 02:42:55 [INFO]: Epoch 164 - training loss: 0.2598, validation loss: 0.0909
2024-05-25 02:42:57 [INFO]: Epoch 165 - training loss: 0.2599, validation loss: 0.0905
2024-05-25 02:43:00 [INFO]: Epoch 166 - training loss: 0.2597, validation loss: 0.0903
2024-05-25 02:43:03 [INFO]: Epoch 167 - training loss: 0.2595, validation loss: 0.0902
2024-05-25 02:43:06 [INFO]: Epoch 168 - training loss: 0.2589, validation loss: 0.0898
2024-05-25 02:43:09 [INFO]: Epoch 169 - training loss: 0.2589, validation loss: 0.0897
2024-05-25 02:43:12 [INFO]: Epoch 170 - training loss: 0.2583, validation loss: 0.0896
2024-05-25 02:43:14 [INFO]: Epoch 171 - training loss: 0.2586, validation loss: 0.0895
2024-05-25 02:43:17 [INFO]: Epoch 172 - training loss: 0.2579, validation loss: 0.0891
2024-05-25 02:43:20 [INFO]: Epoch 173 - training loss: 0.2575, validation loss: 0.0888
2024-05-25 02:43:23 [INFO]: Epoch 174 - training loss: 0.2573, validation loss: 0.0888
2024-05-25 02:43:26 [INFO]: Epoch 175 - training loss: 0.2568, validation loss: 0.0886
2024-05-25 02:43:28 [INFO]: Epoch 176 - training loss: 0.2563, validation loss: 0.0883
2024-05-25 02:43:31 [INFO]: Epoch 177 - training loss: 0.2561, validation loss: 0.0883
2024-05-25 02:43:34 [INFO]: Epoch 178 - training loss: 0.2559, validation loss: 0.0879
2024-05-25 02:43:37 [INFO]: Epoch 179 - training loss: 0.2564, validation loss: 0.0877
2024-05-25 02:43:40 [INFO]: Epoch 180 - training loss: 0.2559, validation loss: 0.0878
2024-05-25 02:43:43 [INFO]: Epoch 181 - training loss: 0.2556, validation loss: 0.0875
2024-05-25 02:43:45 [INFO]: Epoch 182 - training loss: 0.2549, validation loss: 0.0872
2024-05-25 02:43:48 [INFO]: Epoch 183 - training loss: 0.2551, validation loss: 0.0869
2024-05-25 02:43:51 [INFO]: Epoch 184 - training loss: 0.2549, validation loss: 0.0868
2024-05-25 02:43:54 [INFO]: Epoch 185 - training loss: 0.2541, validation loss: 0.0866
2024-05-25 02:43:57 [INFO]: Epoch 186 - training loss: 0.2542, validation loss: 0.0866
2024-05-25 02:43:59 [INFO]: Epoch 187 - training loss: 0.2544, validation loss: 0.0864
2024-05-25 02:44:02 [INFO]: Epoch 188 - training loss: 0.2535, validation loss: 0.0861
2024-05-25 02:44:05 [INFO]: Epoch 189 - training loss: 0.2535, validation loss: 0.0859
2024-05-25 02:44:08 [INFO]: Epoch 190 - training loss: 0.2532, validation loss: 0.0859
2024-05-25 02:44:11 [INFO]: Epoch 191 - training loss: 0.2529, validation loss: 0.0855
2024-05-25 02:44:13 [INFO]: Epoch 192 - training loss: 0.2535, validation loss: 0.0855
2024-05-25 02:44:16 [INFO]: Epoch 193 - training loss: 0.2521, validation loss: 0.0854
2024-05-25 02:44:19 [INFO]: Epoch 194 - training loss: 0.2529, validation loss: 0.0853
2024-05-25 02:44:22 [INFO]: Epoch 195 - training loss: 0.2530, validation loss: 0.0851
2024-05-25 02:44:25 [INFO]: Epoch 196 - training loss: 0.2519, validation loss: 0.0850
2024-05-25 02:44:27 [INFO]: Epoch 197 - training loss: 0.2523, validation loss: 0.0847
2024-05-25 02:44:30 [INFO]: Epoch 198 - training loss: 0.2513, validation loss: 0.0845
2024-05-25 02:44:33 [INFO]: Epoch 199 - training loss: 0.2509, validation loss: 0.0845
2024-05-25 02:44:36 [INFO]: Epoch 200 - training loss: 0.2506, validation loss: 0.0843
2024-05-25 02:44:39 [INFO]: Epoch 201 - training loss: 0.2506, validation loss: 0.0843
2024-05-25 02:44:42 [INFO]: Epoch 202 - training loss: 0.2502, validation loss: 0.0839
2024-05-25 02:44:44 [INFO]: Epoch 203 - training loss: 0.2506, validation loss: 0.0838
2024-05-25 02:44:47 [INFO]: Epoch 204 - training loss: 0.2499, validation loss: 0.0836
2024-05-25 02:44:50 [INFO]: Epoch 205 - training loss: 0.2502, validation loss: 0.0836
2024-05-25 02:44:53 [INFO]: Epoch 206 - training loss: 0.2499, validation loss: 0.0833
2024-05-25 02:44:56 [INFO]: Epoch 207 - training loss: 0.2496, validation loss: 0.0832
2024-05-25 02:44:58 [INFO]: Epoch 208 - training loss: 0.2497, validation loss: 0.0832
2024-05-25 02:45:01 [INFO]: Epoch 209 - training loss: 0.2490, validation loss: 0.0830
2024-05-25 02:45:04 [INFO]: Epoch 210 - training loss: 0.2491, validation loss: 0.0829
2024-05-25 02:45:07 [INFO]: Epoch 211 - training loss: 0.2491, validation loss: 0.0825
2024-05-25 02:45:10 [INFO]: Epoch 212 - training loss: 0.2490, validation loss: 0.0824
2024-05-25 02:45:12 [INFO]: Epoch 213 - training loss: 0.2485, validation loss: 0.0824
2024-05-25 02:45:15 [INFO]: Epoch 214 - training loss: 0.2483, validation loss: 0.0823
2024-05-25 02:45:18 [INFO]: Epoch 215 - training loss: 0.2482, validation loss: 0.0820
2024-05-25 02:45:21 [INFO]: Epoch 216 - training loss: 0.2480, validation loss: 0.0821
2024-05-25 02:45:24 [INFO]: Epoch 217 - training loss: 0.2476, validation loss: 0.0820
2024-05-25 02:45:26 [INFO]: Epoch 218 - training loss: 0.2477, validation loss: 0.0817
2024-05-25 02:45:29 [INFO]: Epoch 219 - training loss: 0.2476, validation loss: 0.0816
2024-05-25 02:45:32 [INFO]: Epoch 220 - training loss: 0.2477, validation loss: 0.0814
2024-05-25 02:45:35 [INFO]: Epoch 221 - training loss: 0.2467, validation loss: 0.0813
2024-05-25 02:45:38 [INFO]: Epoch 222 - training loss: 0.2463, validation loss: 0.0813
2024-05-25 02:45:40 [INFO]: Epoch 223 - training loss: 0.2464, validation loss: 0.0811
2024-05-25 02:45:43 [INFO]: Epoch 224 - training loss: 0.2459, validation loss: 0.0810
2024-05-25 02:45:46 [INFO]: Epoch 225 - training loss: 0.2459, validation loss: 0.0810
2024-05-25 02:45:49 [INFO]: Epoch 226 - training loss: 0.2460, validation loss: 0.0809
2024-05-25 02:45:52 [INFO]: Epoch 227 - training loss: 0.2458, validation loss: 0.0807
2024-05-25 02:45:55 [INFO]: Epoch 228 - training loss: 0.2453, validation loss: 0.0804
2024-05-25 02:45:57 [INFO]: Epoch 229 - training loss: 0.2455, validation loss: 0.0805
2024-05-25 02:46:00 [INFO]: Epoch 230 - training loss: 0.2454, validation loss: 0.0804
2024-05-25 02:46:03 [INFO]: Epoch 231 - training loss: 0.2451, validation loss: 0.0802
2024-05-25 02:46:06 [INFO]: Epoch 232 - training loss: 0.2448, validation loss: 0.0801
2024-05-25 02:46:09 [INFO]: Epoch 233 - training loss: 0.2451, validation loss: 0.0800
2024-05-25 02:46:11 [INFO]: Epoch 234 - training loss: 0.2448, validation loss: 0.0800
2024-05-25 02:46:14 [INFO]: Epoch 235 - training loss: 0.2444, validation loss: 0.0799
2024-05-25 02:46:17 [INFO]: Epoch 236 - training loss: 0.2442, validation loss: 0.0798
2024-05-25 02:46:20 [INFO]: Epoch 237 - training loss: 0.2437, validation loss: 0.0796
2024-05-25 02:46:23 [INFO]: Epoch 238 - training loss: 0.2443, validation loss: 0.0796
2024-05-25 02:46:25 [INFO]: Epoch 239 - training loss: 0.2440, validation loss: 0.0794
2024-05-25 02:46:28 [INFO]: Epoch 240 - training loss: 0.2435, validation loss: 0.0793
2024-05-25 02:46:31 [INFO]: Epoch 241 - training loss: 0.2430, validation loss: 0.0792
2024-05-25 02:46:34 [INFO]: Epoch 242 - training loss: 0.2429, validation loss: 0.0791
2024-05-25 02:46:37 [INFO]: Epoch 243 - training loss: 0.2432, validation loss: 0.0789
2024-05-25 02:46:39 [INFO]: Epoch 244 - training loss: 0.2429, validation loss: 0.0789
2024-05-25 02:46:42 [INFO]: Epoch 245 - training loss: 0.2435, validation loss: 0.0789
2024-05-25 02:46:45 [INFO]: Epoch 246 - training loss: 0.2426, validation loss: 0.0787
2024-05-25 02:46:48 [INFO]: Epoch 247 - training loss: 0.2427, validation loss: 0.0785
2024-05-25 02:46:51 [INFO]: Epoch 248 - training loss: 0.2426, validation loss: 0.0786
2024-05-25 02:46:54 [INFO]: Epoch 249 - training loss: 0.2422, validation loss: 0.0784
2024-05-25 02:46:56 [INFO]: Epoch 250 - training loss: 0.2420, validation loss: 0.0784
2024-05-25 02:46:59 [INFO]: Epoch 251 - training loss: 0.2420, validation loss: 0.0782
2024-05-25 02:47:02 [INFO]: Epoch 252 - training loss: 0.2413, validation loss: 0.0782
2024-05-25 02:47:05 [INFO]: Epoch 253 - training loss: 0.2412, validation loss: 0.0782
2024-05-25 02:47:08 [INFO]: Epoch 254 - training loss: 0.2417, validation loss: 0.0781
2024-05-25 02:47:10 [INFO]: Epoch 255 - training loss: 0.2412, validation loss: 0.0780
2024-05-25 02:47:13 [INFO]: Epoch 256 - training loss: 0.2411, validation loss: 0.0779
2024-05-25 02:47:16 [INFO]: Epoch 257 - training loss: 0.2406, validation loss: 0.0780
2024-05-25 02:47:19 [INFO]: Epoch 258 - training loss: 0.2406, validation loss: 0.0777
2024-05-25 02:47:22 [INFO]: Epoch 259 - training loss: 0.2403, validation loss: 0.0777
2024-05-25 02:47:24 [INFO]: Epoch 260 - training loss: 0.2402, validation loss: 0.0774
2024-05-25 02:47:27 [INFO]: Epoch 261 - training loss: 0.2405, validation loss: 0.0774
2024-05-25 02:47:30 [INFO]: Epoch 262 - training loss: 0.2400, validation loss: 0.0775
2024-05-25 02:47:33 [INFO]: Epoch 263 - training loss: 0.2402, validation loss: 0.0774
2024-05-25 02:47:36 [INFO]: Epoch 264 - training loss: 0.2397, validation loss: 0.0772
2024-05-25 02:47:38 [INFO]: Epoch 265 - training loss: 0.2399, validation loss: 0.0771
2024-05-25 02:47:41 [INFO]: Epoch 266 - training loss: 0.2398, validation loss: 0.0772
2024-05-25 02:47:44 [INFO]: Epoch 267 - training loss: 0.2399, validation loss: 0.0769
2024-05-25 02:47:47 [INFO]: Epoch 268 - training loss: 0.2397, validation loss: 0.0770
2024-05-25 02:47:50 [INFO]: Epoch 269 - training loss: 0.2391, validation loss: 0.0769
2024-05-25 02:47:53 [INFO]: Epoch 270 - training loss: 0.2394, validation loss: 0.0768
2024-05-25 02:47:55 [INFO]: Epoch 271 - training loss: 0.2394, validation loss: 0.0767
2024-05-25 02:47:58 [INFO]: Epoch 272 - training loss: 0.2386, validation loss: 0.0766
2024-05-25 02:48:01 [INFO]: Epoch 273 - training loss: 0.2388, validation loss: 0.0765
2024-05-25 02:48:04 [INFO]: Epoch 274 - training loss: 0.2386, validation loss: 0.0769
2024-05-25 02:48:07 [INFO]: Epoch 275 - training loss: 0.2391, validation loss: 0.0764
2024-05-25 02:48:09 [INFO]: Epoch 276 - training loss: 0.2383, validation loss: 0.0764
2024-05-25 02:48:12 [INFO]: Epoch 277 - training loss: 0.2382, validation loss: 0.0764
2024-05-25 02:48:15 [INFO]: Epoch 278 - training loss: 0.2379, validation loss: 0.0762
2024-05-25 02:48:18 [INFO]: Epoch 279 - training loss: 0.2379, validation loss: 0.0761
2024-05-25 02:48:21 [INFO]: Epoch 280 - training loss: 0.2381, validation loss: 0.0762
2024-05-25 02:48:23 [INFO]: Epoch 281 - training loss: 0.2379, validation loss: 0.0760
2024-05-25 02:48:26 [INFO]: Epoch 282 - training loss: 0.2376, validation loss: 0.0761
2024-05-25 02:48:29 [INFO]: Epoch 283 - training loss: 0.2375, validation loss: 0.0761
2024-05-25 02:48:32 [INFO]: Epoch 284 - training loss: 0.2374, validation loss: 0.0761
2024-05-25 02:48:35 [INFO]: Epoch 285 - training loss: 0.2374, validation loss: 0.0759
2024-05-25 02:48:38 [INFO]: Epoch 286 - training loss: 0.2372, validation loss: 0.0759
2024-05-25 02:48:40 [INFO]: Epoch 287 - training loss: 0.2370, validation loss: 0.0757
2024-05-25 02:48:43 [INFO]: Epoch 288 - training loss: 0.2378, validation loss: 0.0758
2024-05-25 02:48:46 [INFO]: Epoch 289 - training loss: 0.2368, validation loss: 0.0755
2024-05-25 02:48:49 [INFO]: Epoch 290 - training loss: 0.2368, validation loss: 0.0758
2024-05-25 02:48:52 [INFO]: Epoch 291 - training loss: 0.2368, validation loss: 0.0755
2024-05-25 02:48:54 [INFO]: Epoch 292 - training loss: 0.2363, validation loss: 0.0756
2024-05-25 02:48:57 [INFO]: Epoch 293 - training loss: 0.2364, validation loss: 0.0755
2024-05-25 02:49:00 [INFO]: Epoch 294 - training loss: 0.2365, validation loss: 0.0754
2024-05-25 02:49:03 [INFO]: Epoch 295 - training loss: 0.2364, validation loss: 0.0752
2024-05-25 02:49:06 [INFO]: Epoch 296 - training loss: 0.2361, validation loss: 0.0751
2024-05-25 02:49:08 [INFO]: Epoch 297 - training loss: 0.2355, validation loss: 0.0752
2024-05-25 02:49:11 [INFO]: Epoch 298 - training loss: 0.2353, validation loss: 0.0751
2024-05-25 02:49:14 [INFO]: Epoch 299 - training loss: 0.2359, validation loss: 0.0752
2024-05-25 02:49:17 [INFO]: Epoch 300 - training loss: 0.2357, validation loss: 0.0751
2024-05-25 02:49:17 [INFO]: Finished training. The best model is from epoch#296.
2024-05-25 02:49:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T023513/BRITS.pypots
2024-05-25 02:49:18 [INFO]: BRITS on Air-Quality: MAE=0.1366, MSE=0.0948
2024-05-25 02:49:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 02:49:18 [INFO]: Using the given device: cuda:0
2024-05-25 02:49:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918
2024-05-25 02:49:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/tensorboard
2024-05-25 02:49:18 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 02:49:22 [INFO]: Epoch 001 - training loss: 1.4621, validation loss: 0.8140
2024-05-25 02:49:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch1_loss0.8140392452478409.pypots
2024-05-25 02:49:26 [INFO]: Epoch 002 - training loss: 1.0401, validation loss: 0.7529
2024-05-25 02:49:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch2_loss0.7528635889291764.pypots
2024-05-25 02:49:30 [INFO]: Epoch 003 - training loss: 0.9702, validation loss: 0.7289
2024-05-25 02:49:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch3_loss0.7289319276809693.pypots
2024-05-25 02:49:34 [INFO]: Epoch 004 - training loss: 0.9552, validation loss: 0.7165
2024-05-25 02:49:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch4_loss0.7165314435958863.pypots
2024-05-25 02:49:38 [INFO]: Epoch 005 - training loss: 0.9602, validation loss: 0.7071
2024-05-25 02:49:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch5_loss0.7071451246738434.pypots
2024-05-25 02:49:42 [INFO]: Epoch 006 - training loss: 0.9344, validation loss: 0.7005
2024-05-25 02:49:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch6_loss0.7004939556121826.pypots
2024-05-25 02:49:45 [INFO]: Epoch 007 - training loss: 0.9144, validation loss: 0.6951
2024-05-25 02:49:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch7_loss0.6951095908880234.pypots
2024-05-25 02:49:49 [INFO]: Epoch 008 - training loss: 0.9277, validation loss: 0.6909
2024-05-25 02:49:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch8_loss0.6909381538629532.pypots
2024-05-25 02:49:53 [INFO]: Epoch 009 - training loss: 0.9101, validation loss: 0.6879
2024-05-25 02:49:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch9_loss0.6878811985254287.pypots
2024-05-25 02:49:57 [INFO]: Epoch 010 - training loss: 0.8920, validation loss: 0.6849
2024-05-25 02:49:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch10_loss0.684876126050949.pypots
2024-05-25 02:50:01 [INFO]: Epoch 011 - training loss: 0.8920, validation loss: 0.6840
2024-05-25 02:50:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch11_loss0.6839593917131424.pypots
2024-05-25 02:50:05 [INFO]: Epoch 012 - training loss: 0.8926, validation loss: 0.6819
2024-05-25 02:50:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch12_loss0.6818553775548934.pypots
2024-05-25 02:50:09 [INFO]: Epoch 013 - training loss: 0.8890, validation loss: 0.6809
2024-05-25 02:50:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch13_loss0.6808709621429443.pypots
2024-05-25 02:50:12 [INFO]: Epoch 014 - training loss: 0.8897, validation loss: 0.6799
2024-05-25 02:50:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch14_loss0.6799242585897446.pypots
2024-05-25 02:50:16 [INFO]: Epoch 015 - training loss: 0.8880, validation loss: 0.6784
2024-05-25 02:50:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch15_loss0.6783601939678192.pypots
2024-05-25 02:50:20 [INFO]: Epoch 016 - training loss: 0.8793, validation loss: 0.6782
2024-05-25 02:50:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch16_loss0.6781746566295623.pypots
2024-05-25 02:50:24 [INFO]: Epoch 017 - training loss: 0.8760, validation loss: 0.6768
2024-05-25 02:50:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch17_loss0.6768451035022736.pypots
2024-05-25 02:50:28 [INFO]: Epoch 018 - training loss: 0.8729, validation loss: 0.6765
2024-05-25 02:50:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch18_loss0.6764866888523102.pypots
2024-05-25 02:50:32 [INFO]: Epoch 019 - training loss: 0.8876, validation loss: 0.6780
2024-05-25 02:50:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch19_loss0.677982035279274.pypots
2024-05-25 02:50:36 [INFO]: Epoch 020 - training loss: 0.8712, validation loss: 0.6768
2024-05-25 02:50:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch20_loss0.6767516911029816.pypots
2024-05-25 02:50:40 [INFO]: Epoch 021 - training loss: 0.8719, validation loss: 0.6764
2024-05-25 02:50:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch21_loss0.6764137595891953.pypots
2024-05-25 02:50:43 [INFO]: Epoch 022 - training loss: 0.8634, validation loss: 0.6764
2024-05-25 02:50:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch22_loss0.6763521820306778.pypots
2024-05-25 02:50:47 [INFO]: Epoch 023 - training loss: 0.8754, validation loss: 0.6769
2024-05-25 02:50:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch23_loss0.6768869012594223.pypots
2024-05-25 02:50:51 [INFO]: Epoch 024 - training loss: 0.8670, validation loss: 0.6764
2024-05-25 02:50:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch24_loss0.6763780534267425.pypots
2024-05-25 02:50:55 [INFO]: Epoch 025 - training loss: 0.8699, validation loss: 0.6752
2024-05-25 02:50:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch25_loss0.6752134054899216.pypots
2024-05-25 02:50:59 [INFO]: Epoch 026 - training loss: 0.8929, validation loss: 0.6749
2024-05-25 02:50:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch26_loss0.6748652577400207.pypots
2024-05-25 02:51:03 [INFO]: Epoch 027 - training loss: 0.8662, validation loss: 0.6763
2024-05-25 02:51:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch27_loss0.6763294219970704.pypots
2024-05-25 02:51:07 [INFO]: Epoch 028 - training loss: 0.8707, validation loss: 0.6772
2024-05-25 02:51:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch28_loss0.6771506577730179.pypots
2024-05-25 02:51:10 [INFO]: Epoch 029 - training loss: 0.8631, validation loss: 0.6782
2024-05-25 02:51:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch29_loss0.6782311916351318.pypots
2024-05-25 02:51:14 [INFO]: Epoch 030 - training loss: 0.8483, validation loss: 0.6763
2024-05-25 02:51:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch30_loss0.6763251394033432.pypots
2024-05-25 02:51:18 [INFO]: Epoch 031 - training loss: 0.8426, validation loss: 0.6765
2024-05-25 02:51:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch31_loss0.676491168141365.pypots
2024-05-25 02:51:22 [INFO]: Epoch 032 - training loss: 0.8480, validation loss: 0.6766
2024-05-25 02:51:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch32_loss0.6765823155641556.pypots
2024-05-25 02:51:26 [INFO]: Epoch 033 - training loss: 0.8480, validation loss: 0.6759
2024-05-25 02:51:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch33_loss0.6759197562932968.pypots
2024-05-25 02:51:30 [INFO]: Epoch 034 - training loss: 0.8466, validation loss: 0.6769
2024-05-25 02:51:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch34_loss0.6769037574529648.pypots
2024-05-25 02:51:34 [INFO]: Epoch 035 - training loss: 0.8284, validation loss: 0.6767
2024-05-25 02:51:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch35_loss0.6766688257455826.pypots
2024-05-25 02:51:37 [INFO]: Epoch 036 - training loss: 0.8362, validation loss: 0.6774
2024-05-25 02:51:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN_epoch36_loss0.6773793786764145.pypots
2024-05-25 02:51:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:51:37 [INFO]: Finished training. The best model is from epoch#26.
2024-05-25 02:51:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T024918/MRNN.pypots
2024-05-25 02:51:38 [INFO]: MRNN on Air-Quality: MAE=0.5154, MSE=0.5919
2024-05-25 02:51:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 02:51:38 [INFO]: Using the given device: cpu
2024-05-25 02:51:38 [INFO]: LOCF on Air-Quality: MAE=0.1979, MSE=0.2148
2024-05-25 02:51:38 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 02:51:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 02:51:38 [INFO]: Median on Air-Quality: MAE=0.6653, MSE=0.9982
2024-05-25 02:51:38 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 02:51:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 02:51:38 [INFO]: Mean on Air-Quality: MAE=0.6953, MSE=0.9349
2024-05-25 02:51:38 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 02:51:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 02:51:38 [INFO]: 
SAITS on data/air_quality: MAE=0.148±0.000995350941752011, MSE=0.100±0.001150107705320916
Transformer on data/air_quality: MAE=0.166±0.002701925155642929, MSE=0.119±0.0032543340543239718
TimesNet on data/air_quality: MAE=0.169±0.006692331536544737, MSE=0.153±0.010919957063884423
CSDI on data/air_quality: MAE=0.105±0.007784667219893642, MSE=0.169±0.08414030471549643
GPVAE on data/air_quality: MAE=0.282±0.006111382773811057, MSE=0.226±0.005868015544500657
USGAN on data/air_quality: MAE=0.140±0.0006336359181160961, MSE=0.086±0.002571944420720472
BRITS on data/air_quality: MAE=0.137±0.00029356950246621326, MSE=0.095±0.0003251371282550084
MRNN on data/air_quality: MAE=0.516±0.0007627950269480258, MSE=0.592±0.0010182325919921886
LOCF on data/air_quality: MAE=0.198±0.0, MSE=0.215±2.7755575615628914e-17
Median on data/air_quality: MAE=0.665±0.0, MSE=0.998±1.1102230246251565e-16
Mean on data/air_quality: MAE=0.695±0.0, MSE=0.935±0.0