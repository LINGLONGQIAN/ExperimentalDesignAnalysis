2024-05-24 23:09:02 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 23:09:02 [INFO]: Using the given device: cuda:0
2024-05-24 23:09:02 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T230902
2024-05-24 23:09:02 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T230902/tensorboard
2024-05-24 23:09:02 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:09:04 [INFO]: Epoch 001 - training loss: 1.2468, validation loss: 0.3185
2024-05-24 23:09:04 [INFO]: Epoch 002 - training loss: 0.9269, validation loss: 0.1601
2024-05-24 23:09:05 [INFO]: Epoch 003 - training loss: 0.8444, validation loss: 0.1163
2024-05-24 23:09:05 [INFO]: Epoch 004 - training loss: 0.7731, validation loss: 0.1081
2024-05-24 23:09:06 [INFO]: Epoch 005 - training loss: 0.7351, validation loss: 0.0811
2024-05-24 23:09:06 [INFO]: Epoch 006 - training loss: 0.6964, validation loss: 0.0784
2024-05-24 23:09:07 [INFO]: Epoch 007 - training loss: 0.6848, validation loss: 0.0819
2024-05-24 23:09:07 [INFO]: Epoch 008 - training loss: 0.6694, validation loss: 0.0760
2024-05-24 23:09:08 [INFO]: Epoch 009 - training loss: 0.6566, validation loss: 0.0607
2024-05-24 23:09:08 [INFO]: Epoch 010 - training loss: 0.6425, validation loss: 0.0751
2024-05-24 23:09:09 [INFO]: Epoch 011 - training loss: 0.6404, validation loss: 0.0921
2024-05-24 23:09:09 [INFO]: Epoch 012 - training loss: 0.6279, validation loss: 0.0808
2024-05-24 23:09:10 [INFO]: Epoch 013 - training loss: 0.6372, validation loss: 0.0627
2024-05-24 23:09:10 [INFO]: Epoch 014 - training loss: 0.6112, validation loss: 0.0535
2024-05-24 23:09:11 [INFO]: Epoch 015 - training loss: 0.6000, validation loss: 0.0684
2024-05-24 23:09:11 [INFO]: Epoch 016 - training loss: 0.5969, validation loss: 0.0687
2024-05-24 23:09:12 [INFO]: Epoch 017 - training loss: 0.6071, validation loss: 0.0637
2024-05-24 23:09:12 [INFO]: Epoch 018 - training loss: 0.5789, validation loss: 0.0558
2024-05-24 23:09:13 [INFO]: Epoch 019 - training loss: 0.5683, validation loss: 0.0739
2024-05-24 23:09:13 [INFO]: Epoch 020 - training loss: 0.5684, validation loss: 0.0607
2024-05-24 23:09:14 [INFO]: Epoch 021 - training loss: 0.5595, validation loss: 0.0559
2024-05-24 23:09:14 [INFO]: Epoch 022 - training loss: 0.5435, validation loss: 0.0449
2024-05-24 23:09:15 [INFO]: Epoch 023 - training loss: 0.5457, validation loss: 0.1456
2024-05-24 23:09:15 [INFO]: Epoch 024 - training loss: 0.5726, validation loss: 0.0447
2024-05-24 23:09:16 [INFO]: Epoch 025 - training loss: 0.5468, validation loss: 0.0674
2024-05-24 23:09:16 [INFO]: Epoch 026 - training loss: 0.5219, validation loss: 0.0442
2024-05-24 23:09:17 [INFO]: Epoch 027 - training loss: 0.5175, validation loss: 0.0453
2024-05-24 23:09:17 [INFO]: Epoch 028 - training loss: 0.5107, validation loss: 0.0556
2024-05-24 23:09:18 [INFO]: Epoch 029 - training loss: 0.5164, validation loss: 0.0408
2024-05-24 23:09:18 [INFO]: Epoch 030 - training loss: 0.5066, validation loss: 0.0548
2024-05-24 23:09:19 [INFO]: Epoch 031 - training loss: 0.4962, validation loss: 0.0475
2024-05-24 23:09:19 [INFO]: Epoch 032 - training loss: 0.4971, validation loss: 0.0551
2024-05-24 23:09:20 [INFO]: Epoch 033 - training loss: 0.5007, validation loss: 0.0468
2024-05-24 23:09:20 [INFO]: Epoch 034 - training loss: 0.5036, validation loss: 0.0407
2024-05-24 23:09:21 [INFO]: Epoch 035 - training loss: 0.4864, validation loss: 0.0552
2024-05-24 23:09:21 [INFO]: Epoch 036 - training loss: 0.5089, validation loss: 0.0609
2024-05-24 23:09:22 [INFO]: Epoch 037 - training loss: 0.4978, validation loss: 0.0625
2024-05-24 23:09:22 [INFO]: Epoch 038 - training loss: 0.5034, validation loss: 0.0450
2024-05-24 23:09:23 [INFO]: Epoch 039 - training loss: 0.4812, validation loss: 0.0551
2024-05-24 23:09:23 [INFO]: Epoch 040 - training loss: 0.4825, validation loss: 0.0456
2024-05-24 23:09:24 [INFO]: Epoch 041 - training loss: 0.4698, validation loss: 0.0420
2024-05-24 23:09:24 [INFO]: Epoch 042 - training loss: 0.4733, validation loss: 0.0492
2024-05-24 23:09:25 [INFO]: Epoch 043 - training loss: 0.4732, validation loss: 0.0524
2024-05-24 23:09:25 [INFO]: Epoch 044 - training loss: 0.4662, validation loss: 0.0469
2024-05-24 23:09:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:09:25 [INFO]: Finished training. The best model is from epoch#34.
2024-05-24 23:09:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/SAITS_ettm1/20240524_T230902/SAITS.pypots
2024-05-24 23:09:25 [INFO]: SAITS on ETTm1: MAE=0.1653, MSE=0.0516
2024-05-24 23:09:25 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-24 23:09:25 [INFO]: Using the given device: cuda:0
2024-05-24 23:09:25 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T230925
2024-05-24 23:09:25 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T230925/tensorboard
2024-05-24 23:09:25 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:09:26 [INFO]: Epoch 001 - training loss: 1.1965, validation loss: 0.3466
2024-05-24 23:09:26 [INFO]: Epoch 002 - training loss: 0.7746, validation loss: 0.1881
2024-05-24 23:09:26 [INFO]: Epoch 003 - training loss: 0.6397, validation loss: 0.1497
2024-05-24 23:09:26 [INFO]: Epoch 004 - training loss: 0.5697, validation loss: 0.1217
2024-05-24 23:09:27 [INFO]: Epoch 005 - training loss: 0.5254, validation loss: 0.0967
2024-05-24 23:09:27 [INFO]: Epoch 006 - training loss: 0.4943, validation loss: 0.0912
2024-05-24 23:09:27 [INFO]: Epoch 007 - training loss: 0.4658, validation loss: 0.0787
2024-05-24 23:09:27 [INFO]: Epoch 008 - training loss: 0.4456, validation loss: 0.0721
2024-05-24 23:09:27 [INFO]: Epoch 009 - training loss: 0.4281, validation loss: 0.0683
2024-05-24 23:09:28 [INFO]: Epoch 010 - training loss: 0.4095, validation loss: 0.0606
2024-05-24 23:09:28 [INFO]: Epoch 011 - training loss: 0.3973, validation loss: 0.0568
2024-05-24 23:09:28 [INFO]: Epoch 012 - training loss: 0.3924, validation loss: 0.0602
2024-05-24 23:09:28 [INFO]: Epoch 013 - training loss: 0.3848, validation loss: 0.0553
2024-05-24 23:09:28 [INFO]: Epoch 014 - training loss: 0.3795, validation loss: 0.0572
2024-05-24 23:09:29 [INFO]: Epoch 015 - training loss: 0.3693, validation loss: 0.0534
2024-05-24 23:09:29 [INFO]: Epoch 016 - training loss: 0.3670, validation loss: 0.0547
2024-05-24 23:09:29 [INFO]: Epoch 017 - training loss: 0.3600, validation loss: 0.0613
2024-05-24 23:09:29 [INFO]: Epoch 018 - training loss: 0.3571, validation loss: 0.0536
2024-05-24 23:09:30 [INFO]: Epoch 019 - training loss: 0.3499, validation loss: 0.0498
2024-05-24 23:09:30 [INFO]: Epoch 020 - training loss: 0.3414, validation loss: 0.0478
2024-05-24 23:09:30 [INFO]: Epoch 021 - training loss: 0.3339, validation loss: 0.0497
2024-05-24 23:09:30 [INFO]: Epoch 022 - training loss: 0.3352, validation loss: 0.0484
2024-05-24 23:09:30 [INFO]: Epoch 023 - training loss: 0.3333, validation loss: 0.0440
2024-05-24 23:09:31 [INFO]: Epoch 024 - training loss: 0.3245, validation loss: 0.0459
2024-05-24 23:09:31 [INFO]: Epoch 025 - training loss: 0.3143, validation loss: 0.0423
2024-05-24 23:09:31 [INFO]: Epoch 026 - training loss: 0.3130, validation loss: 0.0423
2024-05-24 23:09:31 [INFO]: Epoch 027 - training loss: 0.3151, validation loss: 0.0423
2024-05-24 23:09:31 [INFO]: Epoch 028 - training loss: 0.3091, validation loss: 0.0429
2024-05-24 23:09:32 [INFO]: Epoch 029 - training loss: 0.3056, validation loss: 0.0381
2024-05-24 23:09:32 [INFO]: Epoch 030 - training loss: 0.3007, validation loss: 0.0395
2024-05-24 23:09:32 [INFO]: Epoch 031 - training loss: 0.2929, validation loss: 0.0379
2024-05-24 23:09:32 [INFO]: Epoch 032 - training loss: 0.2888, validation loss: 0.0371
2024-05-24 23:09:32 [INFO]: Epoch 033 - training loss: 0.2924, validation loss: 0.0348
2024-05-24 23:09:33 [INFO]: Epoch 034 - training loss: 0.2826, validation loss: 0.0370
2024-05-24 23:09:33 [INFO]: Epoch 035 - training loss: 0.2801, validation loss: 0.0407
2024-05-24 23:09:33 [INFO]: Epoch 036 - training loss: 0.2852, validation loss: 0.0413
2024-05-24 23:09:33 [INFO]: Epoch 037 - training loss: 0.2819, validation loss: 0.0361
2024-05-24 23:09:34 [INFO]: Epoch 038 - training loss: 0.2785, validation loss: 0.0392
2024-05-24 23:09:34 [INFO]: Epoch 039 - training loss: 0.2876, validation loss: 0.0514
2024-05-24 23:09:34 [INFO]: Epoch 040 - training loss: 0.2935, validation loss: 0.0380
2024-05-24 23:09:34 [INFO]: Epoch 041 - training loss: 0.2659, validation loss: 0.0339
2024-05-24 23:09:34 [INFO]: Epoch 042 - training loss: 0.2647, validation loss: 0.0338
2024-05-24 23:09:35 [INFO]: Epoch 043 - training loss: 0.2647, validation loss: 0.0341
2024-05-24 23:09:35 [INFO]: Epoch 044 - training loss: 0.2600, validation loss: 0.0359
2024-05-24 23:09:35 [INFO]: Epoch 045 - training loss: 0.2656, validation loss: 0.0344
2024-05-24 23:09:35 [INFO]: Epoch 046 - training loss: 0.2693, validation loss: 0.0336
2024-05-24 23:09:35 [INFO]: Epoch 047 - training loss: 0.2622, validation loss: 0.0349
2024-05-24 23:09:36 [INFO]: Epoch 048 - training loss: 0.2671, validation loss: 0.0357
2024-05-24 23:09:36 [INFO]: Epoch 049 - training loss: 0.2544, validation loss: 0.0340
2024-05-24 23:09:36 [INFO]: Epoch 050 - training loss: 0.2493, validation loss: 0.0301
2024-05-24 23:09:36 [INFO]: Epoch 051 - training loss: 0.2543, validation loss: 0.0314
2024-05-24 23:09:37 [INFO]: Epoch 052 - training loss: 0.2510, validation loss: 0.0333
2024-05-24 23:09:37 [INFO]: Epoch 053 - training loss: 0.2478, validation loss: 0.0344
2024-05-24 23:09:37 [INFO]: Epoch 054 - training loss: 0.2465, validation loss: 0.0296
2024-05-24 23:09:37 [INFO]: Epoch 055 - training loss: 0.2403, validation loss: 0.0303
2024-05-24 23:09:37 [INFO]: Epoch 056 - training loss: 0.2414, validation loss: 0.0287
2024-05-24 23:09:38 [INFO]: Epoch 057 - training loss: 0.2411, validation loss: 0.0325
2024-05-24 23:09:38 [INFO]: Epoch 058 - training loss: 0.2453, validation loss: 0.0290
2024-05-24 23:09:38 [INFO]: Epoch 059 - training loss: 0.2402, validation loss: 0.0283
2024-05-24 23:09:38 [INFO]: Epoch 060 - training loss: 0.2379, validation loss: 0.0299
2024-05-24 23:09:38 [INFO]: Epoch 061 - training loss: 0.2360, validation loss: 0.0293
2024-05-24 23:09:39 [INFO]: Epoch 062 - training loss: 0.2366, validation loss: 0.0327
2024-05-24 23:09:39 [INFO]: Epoch 063 - training loss: 0.2425, validation loss: 0.0338
2024-05-24 23:09:39 [INFO]: Epoch 064 - training loss: 0.2345, validation loss: 0.0277
2024-05-24 23:09:39 [INFO]: Epoch 065 - training loss: 0.2339, validation loss: 0.0294
2024-05-24 23:09:40 [INFO]: Epoch 066 - training loss: 0.2286, validation loss: 0.0265
2024-05-24 23:09:40 [INFO]: Epoch 067 - training loss: 0.2261, validation loss: 0.0311
2024-05-24 23:09:40 [INFO]: Epoch 068 - training loss: 0.2341, validation loss: 0.0302
2024-05-24 23:09:40 [INFO]: Epoch 069 - training loss: 0.2271, validation loss: 0.0310
2024-05-24 23:09:40 [INFO]: Epoch 070 - training loss: 0.2233, validation loss: 0.0282
2024-05-24 23:09:41 [INFO]: Epoch 071 - training loss: 0.2230, validation loss: 0.0259
2024-05-24 23:09:41 [INFO]: Epoch 072 - training loss: 0.2268, validation loss: 0.0290
2024-05-24 23:09:41 [INFO]: Epoch 073 - training loss: 0.2258, validation loss: 0.0283
2024-05-24 23:09:41 [INFO]: Epoch 074 - training loss: 0.2203, validation loss: 0.0316
2024-05-24 23:09:41 [INFO]: Epoch 075 - training loss: 0.2262, validation loss: 0.0272
2024-05-24 23:09:42 [INFO]: Epoch 076 - training loss: 0.2266, validation loss: 0.0280
2024-05-24 23:09:42 [INFO]: Epoch 077 - training loss: 0.2197, validation loss: 0.0261
2024-05-24 23:09:42 [INFO]: Epoch 078 - training loss: 0.2187, validation loss: 0.0267
2024-05-24 23:09:42 [INFO]: Epoch 079 - training loss: 0.2173, validation loss: 0.0303
2024-05-24 23:09:42 [INFO]: Epoch 080 - training loss: 0.2148, validation loss: 0.0277
2024-05-24 23:09:43 [INFO]: Epoch 081 - training loss: 0.2114, validation loss: 0.0297
2024-05-24 23:09:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:09:43 [INFO]: Finished training. The best model is from epoch#71.
2024-05-24 23:09:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/Transformer_ettm1/20240524_T230925/Transformer.pypots
2024-05-24 23:09:43 [INFO]: Transformer on ETTm1: MAE=0.1319, MSE=0.0347
2024-05-24 23:09:43 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-24 23:09:43 [INFO]: Using the given device: cuda:0
2024-05-24 23:09:43 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T230943
2024-05-24 23:09:43 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T230943/tensorboard
2024-05-24 23:09:43 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:09:44 [INFO]: Epoch 001 - training loss: 0.1635, validation loss: 0.0516
2024-05-24 23:09:44 [INFO]: Epoch 002 - training loss: 0.0726, validation loss: 0.0470
2024-05-24 23:09:44 [INFO]: Epoch 003 - training loss: 0.0685, validation loss: 0.0412
2024-05-24 23:09:44 [INFO]: Epoch 004 - training loss: 0.0561, validation loss: 0.0402
2024-05-24 23:09:44 [INFO]: Epoch 005 - training loss: 0.0532, validation loss: 0.0362
2024-05-24 23:09:45 [INFO]: Epoch 006 - training loss: 0.0511, validation loss: 0.0376
2024-05-24 23:09:45 [INFO]: Epoch 007 - training loss: 0.0514, validation loss: 0.0368
2024-05-24 23:09:45 [INFO]: Epoch 008 - training loss: 0.0536, validation loss: 0.0375
2024-05-24 23:09:45 [INFO]: Epoch 009 - training loss: 0.0568, validation loss: 0.0363
2024-05-24 23:09:45 [INFO]: Epoch 010 - training loss: 0.0511, validation loss: 0.0365
2024-05-24 23:09:46 [INFO]: Epoch 011 - training loss: 0.0519, validation loss: 0.0359
2024-05-24 23:09:46 [INFO]: Epoch 012 - training loss: 0.0486, validation loss: 0.0336
2024-05-24 23:09:46 [INFO]: Epoch 013 - training loss: 0.0496, validation loss: 0.0361
2024-05-24 23:09:46 [INFO]: Epoch 014 - training loss: 0.0501, validation loss: 0.0391
2024-05-24 23:09:47 [INFO]: Epoch 015 - training loss: 0.0507, validation loss: 0.0352
2024-05-24 23:09:47 [INFO]: Epoch 016 - training loss: 0.0472, validation loss: 0.0336
2024-05-24 23:09:47 [INFO]: Epoch 017 - training loss: 0.0475, validation loss: 0.0321
2024-05-24 23:09:47 [INFO]: Epoch 018 - training loss: 0.0490, validation loss: 0.0330
2024-05-24 23:09:47 [INFO]: Epoch 019 - training loss: 0.0475, validation loss: 0.0340
2024-05-24 23:09:48 [INFO]: Epoch 020 - training loss: 0.0460, validation loss: 0.0362
2024-05-24 23:09:48 [INFO]: Epoch 021 - training loss: 0.0446, validation loss: 0.0336
2024-05-24 23:09:48 [INFO]: Epoch 022 - training loss: 0.0455, validation loss: 0.0369
2024-05-24 23:09:48 [INFO]: Epoch 023 - training loss: 0.0458, validation loss: 0.0324
2024-05-24 23:09:48 [INFO]: Epoch 024 - training loss: 0.0465, validation loss: 0.0354
2024-05-24 23:09:49 [INFO]: Epoch 025 - training loss: 0.0554, validation loss: 0.0353
2024-05-24 23:09:49 [INFO]: Epoch 026 - training loss: 0.0588, validation loss: 0.0411
2024-05-24 23:09:49 [INFO]: Epoch 027 - training loss: 0.0577, validation loss: 0.0342
2024-05-24 23:09:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:09:49 [INFO]: Finished training. The best model is from epoch#17.
2024-05-24 23:09:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/TimesNet_ettm1/20240524_T230943/TimesNet.pypots
2024-05-24 23:09:49 [INFO]: TimesNet on ETTm1: MAE=0.1297, MSE=0.0356
2024-05-24 23:09:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-24 23:09:49 [INFO]: Using the given device: cuda:0
2024-05-24 23:09:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949
2024-05-24 23:09:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/tensorboard
2024-05-24 23:09:49 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:09:51 [INFO]: Epoch 001 - training loss: 0.6686, validation loss: 0.4731
2024-05-24 23:09:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch1_loss0.47308364510536194.pypots
2024-05-24 23:09:53 [INFO]: Epoch 002 - training loss: 0.3733, validation loss: 0.3656
2024-05-24 23:09:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch2_loss0.36563944816589355.pypots
2024-05-24 23:09:55 [INFO]: Epoch 003 - training loss: 0.3360, validation loss: 0.3283
2024-05-24 23:09:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch3_loss0.3282969370484352.pypots
2024-05-24 23:09:58 [INFO]: Epoch 004 - training loss: 0.3343, validation loss: 0.3055
2024-05-24 23:09:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch4_loss0.30546943843364716.pypots
2024-05-24 23:10:00 [INFO]: Epoch 005 - training loss: 0.2706, validation loss: 0.3012
2024-05-24 23:10:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch5_loss0.30121663957834244.pypots
2024-05-24 23:10:02 [INFO]: Epoch 006 - training loss: 0.3307, validation loss: 0.3312
2024-05-24 23:10:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch6_loss0.33122117817401886.pypots
2024-05-24 23:10:04 [INFO]: Epoch 007 - training loss: 0.3004, validation loss: 0.2986
2024-05-24 23:10:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch7_loss0.2986336275935173.pypots
2024-05-24 23:10:06 [INFO]: Epoch 008 - training loss: 0.2912, validation loss: 0.2842
2024-05-24 23:10:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch8_loss0.284234918653965.pypots
2024-05-24 23:10:08 [INFO]: Epoch 009 - training loss: 0.3231, validation loss: 0.2785
2024-05-24 23:10:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch9_loss0.27845431864261627.pypots
2024-05-24 23:10:10 [INFO]: Epoch 010 - training loss: 0.3005, validation loss: 0.2764
2024-05-24 23:10:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch10_loss0.276358425617218.pypots
2024-05-24 23:10:12 [INFO]: Epoch 011 - training loss: 0.2847, validation loss: 0.2578
2024-05-24 23:10:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch11_loss0.2577534504234791.pypots
2024-05-24 23:10:14 [INFO]: Epoch 012 - training loss: 0.2395, validation loss: 0.2517
2024-05-24 23:10:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch12_loss0.2517057731747627.pypots
2024-05-24 23:10:16 [INFO]: Epoch 013 - training loss: 0.2159, validation loss: 0.2415
2024-05-24 23:10:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch13_loss0.24154625460505486.pypots
2024-05-24 23:10:18 [INFO]: Epoch 014 - training loss: 0.2873, validation loss: 0.2375
2024-05-24 23:10:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch14_loss0.2375122494995594.pypots
2024-05-24 23:10:20 [INFO]: Epoch 015 - training loss: 0.2747, validation loss: 0.2467
2024-05-24 23:10:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch15_loss0.24670607596635818.pypots
2024-05-24 23:10:22 [INFO]: Epoch 016 - training loss: 0.2699, validation loss: 0.2411
2024-05-24 23:10:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch16_loss0.24107537418603897.pypots
2024-05-24 23:10:24 [INFO]: Epoch 017 - training loss: 0.2682, validation loss: 0.2429
2024-05-24 23:10:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch17_loss0.2428569719195366.pypots
2024-05-24 23:10:27 [INFO]: Epoch 018 - training loss: 0.2936, validation loss: 0.2515
2024-05-24 23:10:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch18_loss0.25148380920290947.pypots
2024-05-24 23:10:29 [INFO]: Epoch 019 - training loss: 0.3578, validation loss: 0.2634
2024-05-24 23:10:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch19_loss0.2633858621120453.pypots
2024-05-24 23:10:31 [INFO]: Epoch 020 - training loss: 0.2278, validation loss: 0.2391
2024-05-24 23:10:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch20_loss0.2391362451016903.pypots
2024-05-24 23:10:33 [INFO]: Epoch 021 - training loss: 0.2374, validation loss: 0.2285
2024-05-24 23:10:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch21_loss0.2284979596734047.pypots
2024-05-24 23:10:35 [INFO]: Epoch 022 - training loss: 0.2441, validation loss: 0.2217
2024-05-24 23:10:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch22_loss0.22167189046740532.pypots
2024-05-24 23:10:37 [INFO]: Epoch 023 - training loss: 0.2295, validation loss: 0.2268
2024-05-24 23:10:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch23_loss0.22680652886629105.pypots
2024-05-24 23:10:39 [INFO]: Epoch 024 - training loss: 0.1953, validation loss: 0.2106
2024-05-24 23:10:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch24_loss0.21057236194610596.pypots
2024-05-24 23:10:41 [INFO]: Epoch 025 - training loss: 0.2159, validation loss: 0.2095
2024-05-24 23:10:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch25_loss0.20954474806785583.pypots
2024-05-24 23:10:43 [INFO]: Epoch 026 - training loss: 0.2277, validation loss: 0.2197
2024-05-24 23:10:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch26_loss0.21971559524536133.pypots
2024-05-24 23:10:45 [INFO]: Epoch 027 - training loss: 0.2229, validation loss: 0.2102
2024-05-24 23:10:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch27_loss0.2101850025355816.pypots
2024-05-24 23:10:47 [INFO]: Epoch 028 - training loss: 0.1919, validation loss: 0.2020
2024-05-24 23:10:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch28_loss0.2019732967019081.pypots
2024-05-24 23:10:49 [INFO]: Epoch 029 - training loss: 0.2492, validation loss: 0.1979
2024-05-24 23:10:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch29_loss0.19793789833784103.pypots
2024-05-24 23:10:51 [INFO]: Epoch 030 - training loss: 0.2188, validation loss: 0.1921
2024-05-24 23:10:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch30_loss0.19209162145853043.pypots
2024-05-24 23:10:54 [INFO]: Epoch 031 - training loss: 0.1918, validation loss: 0.1994
2024-05-24 23:10:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch31_loss0.19939598813652992.pypots
2024-05-24 23:10:56 [INFO]: Epoch 032 - training loss: 0.1883, validation loss: 0.2006
2024-05-24 23:10:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch32_loss0.2005630098283291.pypots
2024-05-24 23:10:58 [INFO]: Epoch 033 - training loss: 0.2224, validation loss: 0.1823
2024-05-24 23:10:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch33_loss0.18228557333350182.pypots
2024-05-24 23:11:00 [INFO]: Epoch 034 - training loss: 0.2023, validation loss: 0.1846
2024-05-24 23:11:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch34_loss0.18460660055279732.pypots
2024-05-24 23:11:02 [INFO]: Epoch 035 - training loss: 0.2110, validation loss: 0.1878
2024-05-24 23:11:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch35_loss0.18780497089028358.pypots
2024-05-24 23:11:04 [INFO]: Epoch 036 - training loss: 0.1857, validation loss: 0.1822
2024-05-24 23:11:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch36_loss0.18215427920222282.pypots
2024-05-24 23:11:06 [INFO]: Epoch 037 - training loss: 0.2122, validation loss: 0.1818
2024-05-24 23:11:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch37_loss0.18180057778954506.pypots
2024-05-24 23:11:08 [INFO]: Epoch 038 - training loss: 0.2113, validation loss: 0.1781
2024-05-24 23:11:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch38_loss0.17812204733490944.pypots
2024-05-24 23:11:11 [INFO]: Epoch 039 - training loss: 0.1901, validation loss: 0.1750
2024-05-24 23:11:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch39_loss0.17501839622855186.pypots
2024-05-24 23:11:13 [INFO]: Epoch 040 - training loss: 0.1679, validation loss: 0.1701
2024-05-24 23:11:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch40_loss0.17005938664078712.pypots
2024-05-24 23:11:15 [INFO]: Epoch 041 - training loss: 0.1999, validation loss: 0.1719
2024-05-24 23:11:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch41_loss0.1718798391520977.pypots
2024-05-24 23:11:17 [INFO]: Epoch 042 - training loss: 0.2065, validation loss: 0.1690
2024-05-24 23:11:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch42_loss0.16900412365794182.pypots
2024-05-24 23:11:19 [INFO]: Epoch 043 - training loss: 0.1789, validation loss: 0.1746
2024-05-24 23:11:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch43_loss0.17464615404605865.pypots
2024-05-24 23:11:21 [INFO]: Epoch 044 - training loss: 0.1657, validation loss: 0.1643
2024-05-24 23:11:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch44_loss0.16433638706803322.pypots
2024-05-24 23:11:23 [INFO]: Epoch 045 - training loss: 0.1829, validation loss: 0.1642
2024-05-24 23:11:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch45_loss0.16418984904885292.pypots
2024-05-24 23:11:25 [INFO]: Epoch 046 - training loss: 0.1776, validation loss: 0.1712
2024-05-24 23:11:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch46_loss0.17122546583414078.pypots
2024-05-24 23:11:28 [INFO]: Epoch 047 - training loss: 0.1922, validation loss: 0.1756
2024-05-24 23:11:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch47_loss0.17561085894703865.pypots
2024-05-24 23:11:30 [INFO]: Epoch 048 - training loss: 0.1670, validation loss: 0.2241
2024-05-24 23:11:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch48_loss0.22410793229937553.pypots
2024-05-24 23:11:32 [INFO]: Epoch 049 - training loss: 0.2330, validation loss: 0.1976
2024-05-24 23:11:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch49_loss0.19761772081255913.pypots
2024-05-24 23:11:34 [INFO]: Epoch 050 - training loss: 0.1756, validation loss: 0.1741
2024-05-24 23:11:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch50_loss0.17410484701395035.pypots
2024-05-24 23:11:36 [INFO]: Epoch 051 - training loss: 0.1781, validation loss: 0.1679
2024-05-24 23:11:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch51_loss0.16785603389143944.pypots
2024-05-24 23:11:38 [INFO]: Epoch 052 - training loss: 0.1956, validation loss: 0.1700
2024-05-24 23:11:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch52_loss0.17004191130399704.pypots
2024-05-24 23:11:40 [INFO]: Epoch 053 - training loss: 0.1745, validation loss: 0.1679
2024-05-24 23:11:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch53_loss0.16785512119531631.pypots
2024-05-24 23:11:42 [INFO]: Epoch 054 - training loss: 0.1635, validation loss: 0.1650
2024-05-24 23:11:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch54_loss0.16499297693371773.pypots
2024-05-24 23:11:44 [INFO]: Epoch 055 - training loss: 0.2325, validation loss: 0.1625
2024-05-24 23:11:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch55_loss0.16251646727323532.pypots
2024-05-24 23:11:46 [INFO]: Epoch 056 - training loss: 0.2062, validation loss: 0.1578
2024-05-24 23:11:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch56_loss0.15781884640455246.pypots
2024-05-24 23:11:48 [INFO]: Epoch 057 - training loss: 0.1628, validation loss: 0.1603
2024-05-24 23:11:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch57_loss0.16028139740228653.pypots
2024-05-24 23:11:51 [INFO]: Epoch 058 - training loss: 0.1798, validation loss: 0.1565
2024-05-24 23:11:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch58_loss0.1565234735608101.pypots
2024-05-24 23:11:53 [INFO]: Epoch 059 - training loss: 0.2051, validation loss: 0.1665
2024-05-24 23:11:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch59_loss0.1665373146533966.pypots
2024-05-24 23:11:55 [INFO]: Epoch 060 - training loss: 0.2377, validation loss: 0.1733
2024-05-24 23:11:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch60_loss0.17331984639167786.pypots
2024-05-24 23:11:57 [INFO]: Epoch 061 - training loss: 0.1986, validation loss: 0.1693
2024-05-24 23:11:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch61_loss0.1693425066769123.pypots
2024-05-24 23:11:59 [INFO]: Epoch 062 - training loss: 0.1612, validation loss: 0.1599
2024-05-24 23:12:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch62_loss0.1599244773387909.pypots
2024-05-24 23:12:02 [INFO]: Epoch 063 - training loss: 0.2729, validation loss: 0.1693
2024-05-24 23:12:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch63_loss0.1693192683160305.pypots
2024-05-24 23:12:04 [INFO]: Epoch 064 - training loss: 0.1669, validation loss: 0.1650
2024-05-24 23:12:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch64_loss0.16500519216060638.pypots
2024-05-24 23:12:06 [INFO]: Epoch 065 - training loss: 0.1760, validation loss: 0.1581
2024-05-24 23:12:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch65_loss0.15813620388507843.pypots
2024-05-24 23:12:08 [INFO]: Epoch 066 - training loss: 0.1765, validation loss: 0.1512
2024-05-24 23:12:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch66_loss0.15122026950120926.pypots
2024-05-24 23:12:10 [INFO]: Epoch 067 - training loss: 0.1643, validation loss: 0.1520
2024-05-24 23:12:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch67_loss0.15195057168602943.pypots
2024-05-24 23:12:12 [INFO]: Epoch 068 - training loss: 0.1671, validation loss: 0.1476
2024-05-24 23:12:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch68_loss0.14760911837220192.pypots
2024-05-24 23:12:14 [INFO]: Epoch 069 - training loss: 0.1570, validation loss: 0.1462
2024-05-24 23:12:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch69_loss0.1461670845746994.pypots
2024-05-24 23:12:16 [INFO]: Epoch 070 - training loss: 0.1534, validation loss: 0.1547
2024-05-24 23:12:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch70_loss0.1547205150127411.pypots
2024-05-24 23:12:18 [INFO]: Epoch 071 - training loss: 0.1672, validation loss: 0.1464
2024-05-24 23:12:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch71_loss0.1464470960199833.pypots
2024-05-24 23:12:20 [INFO]: Epoch 072 - training loss: 0.1966, validation loss: 0.1458
2024-05-24 23:12:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch72_loss0.1458033211529255.pypots
2024-05-24 23:12:22 [INFO]: Epoch 073 - training loss: 0.1756, validation loss: 0.1479
2024-05-24 23:12:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch73_loss0.14787176996469498.pypots
2024-05-24 23:12:24 [INFO]: Epoch 074 - training loss: 0.1716, validation loss: 0.1461
2024-05-24 23:12:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch74_loss0.14608069136738777.pypots
2024-05-24 23:12:26 [INFO]: Epoch 075 - training loss: 0.1583, validation loss: 0.1400
2024-05-24 23:12:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch75_loss0.14002351462841034.pypots
2024-05-24 23:12:29 [INFO]: Epoch 076 - training loss: 0.1955, validation loss: 0.1464
2024-05-24 23:12:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch76_loss0.14642269164323807.pypots
2024-05-24 23:12:31 [INFO]: Epoch 077 - training loss: 0.1876, validation loss: 0.1601
2024-05-24 23:12:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch77_loss0.16009028255939484.pypots
2024-05-24 23:12:33 [INFO]: Epoch 078 - training loss: 0.2395, validation loss: 0.1555
2024-05-24 23:12:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch78_loss0.1554974429309368.pypots
2024-05-24 23:12:35 [INFO]: Epoch 079 - training loss: 0.1793, validation loss: 0.1531
2024-05-24 23:12:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch79_loss0.1531127206981182.pypots
2024-05-24 23:12:37 [INFO]: Epoch 080 - training loss: 0.1619, validation loss: 0.1461
2024-05-24 23:12:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch80_loss0.14610470831394196.pypots
2024-05-24 23:12:39 [INFO]: Epoch 081 - training loss: 0.1538, validation loss: 0.1423
2024-05-24 23:12:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch81_loss0.14234133437275887.pypots
2024-05-24 23:12:41 [INFO]: Epoch 082 - training loss: 0.1549, validation loss: 0.1407
2024-05-24 23:12:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch82_loss0.14066966250538826.pypots
2024-05-24 23:12:43 [INFO]: Epoch 083 - training loss: 0.1883, validation loss: 0.1447
2024-05-24 23:12:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch83_loss0.14468467608094215.pypots
2024-05-24 23:12:45 [INFO]: Epoch 084 - training loss: 0.1808, validation loss: 0.1492
2024-05-24 23:12:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch84_loss0.14921168610453606.pypots
2024-05-24 23:12:47 [INFO]: Epoch 085 - training loss: 0.1844, validation loss: 0.1471
2024-05-24 23:12:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI_epoch85_loss0.14714999496936798.pypots
2024-05-24 23:12:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:12:47 [INFO]: Finished training. The best model is from epoch#75.
2024-05-24 23:12:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_ettm1/20240524_T230949/CSDI.pypots
2024-05-24 23:13:03 [INFO]: CSDI on ETTm1: MAE=0.2567, MSE=0.6862
2024-05-24 23:13:03 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-24 23:13:03 [INFO]: Using the given device: cuda:0
2024-05-24 23:13:03 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T231303
2024-05-24 23:13:03 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T231303/tensorboard
2024-05-24 23:13:03 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 23:13:03 [INFO]: Epoch 001 - training loss: 24083.3436, validation loss: 0.9488
2024-05-24 23:13:03 [INFO]: Epoch 002 - training loss: 22056.4506, validation loss: 0.9410
2024-05-24 23:13:04 [INFO]: Epoch 003 - training loss: 20063.2849, validation loss: 0.9401
2024-05-24 23:13:04 [INFO]: Epoch 004 - training loss: 18207.3533, validation loss: 0.9418
2024-05-24 23:13:04 [INFO]: Epoch 005 - training loss: 16370.4146, validation loss: 0.9249
2024-05-24 23:13:04 [INFO]: Epoch 006 - training loss: 14656.6592, validation loss: 0.8969
2024-05-24 23:13:04 [INFO]: Epoch 007 - training loss: 13254.3358, validation loss: 0.8376
2024-05-24 23:13:04 [INFO]: Epoch 008 - training loss: 12432.2925, validation loss: 0.7295
2024-05-24 23:13:04 [INFO]: Epoch 009 - training loss: 11703.8852, validation loss: 0.6063
2024-05-24 23:13:04 [INFO]: Epoch 010 - training loss: 11145.7921, validation loss: 0.5228
2024-05-24 23:13:05 [INFO]: Epoch 011 - training loss: 10945.6033, validation loss: 0.4798
2024-05-24 23:13:05 [INFO]: Epoch 012 - training loss: 10613.0707, validation loss: 0.4616
2024-05-24 23:13:05 [INFO]: Epoch 013 - training loss: 10339.8313, validation loss: 0.4506
2024-05-24 23:13:05 [INFO]: Epoch 014 - training loss: 10215.2817, validation loss: 0.4357
2024-05-24 23:13:05 [INFO]: Epoch 015 - training loss: 10058.6454, validation loss: 0.4242
2024-05-24 23:13:05 [INFO]: Epoch 016 - training loss: 9978.6666, validation loss: 0.4048
2024-05-24 23:13:05 [INFO]: Epoch 017 - training loss: 9922.0870, validation loss: 0.3822
2024-05-24 23:13:05 [INFO]: Epoch 018 - training loss: 9826.9868, validation loss: 0.3615
2024-05-24 23:13:05 [INFO]: Epoch 019 - training loss: 9760.3073, validation loss: 0.3476
2024-05-24 23:13:06 [INFO]: Epoch 020 - training loss: 9697.8321, validation loss: 0.3231
2024-05-24 23:13:06 [INFO]: Epoch 021 - training loss: 9677.8566, validation loss: 0.3092
2024-05-24 23:13:06 [INFO]: Epoch 022 - training loss: 9633.5461, validation loss: 0.2968
2024-05-24 23:13:06 [INFO]: Epoch 023 - training loss: 9591.4211, validation loss: 0.2852
2024-05-24 23:13:06 [INFO]: Epoch 024 - training loss: 9574.0809, validation loss: 0.2767
2024-05-24 23:13:06 [INFO]: Epoch 025 - training loss: 9555.1124, validation loss: 0.2730
2024-05-24 23:13:06 [INFO]: Epoch 026 - training loss: 9504.5457, validation loss: 0.2623
2024-05-24 23:13:06 [INFO]: Epoch 027 - training loss: 9494.7432, validation loss: 0.2515
2024-05-24 23:13:07 [INFO]: Epoch 028 - training loss: 9473.0742, validation loss: 0.2486
2024-05-24 23:13:07 [INFO]: Epoch 029 - training loss: 9454.6694, validation loss: 0.2446
2024-05-24 23:13:07 [INFO]: Epoch 030 - training loss: 9433.6197, validation loss: 0.2381
2024-05-24 23:13:07 [INFO]: Epoch 031 - training loss: 9420.9429, validation loss: 0.2336
2024-05-24 23:13:07 [INFO]: Epoch 032 - training loss: 9461.9442, validation loss: 0.2289
2024-05-24 23:13:07 [INFO]: Epoch 033 - training loss: 9398.6543, validation loss: 0.2252
2024-05-24 23:13:07 [INFO]: Epoch 034 - training loss: 9383.0738, validation loss: 0.2203
2024-05-24 23:13:07 [INFO]: Epoch 035 - training loss: 9378.4552, validation loss: 0.2178
2024-05-24 23:13:08 [INFO]: Epoch 036 - training loss: 9365.4737, validation loss: 0.2145
2024-05-24 23:13:08 [INFO]: Epoch 037 - training loss: 9362.6429, validation loss: 0.2119
2024-05-24 23:13:08 [INFO]: Epoch 038 - training loss: 9355.4808, validation loss: 0.2077
2024-05-24 23:13:08 [INFO]: Epoch 039 - training loss: 9349.0417, validation loss: 0.2049
2024-05-24 23:13:08 [INFO]: Epoch 040 - training loss: 9339.9869, validation loss: 0.2014
2024-05-24 23:13:08 [INFO]: Epoch 041 - training loss: 9338.6960, validation loss: 0.1992
2024-05-24 23:13:08 [INFO]: Epoch 042 - training loss: 9329.6506, validation loss: 0.1934
2024-05-24 23:13:08 [INFO]: Epoch 043 - training loss: 9324.5646, validation loss: 0.1877
2024-05-24 23:13:09 [INFO]: Epoch 044 - training loss: 9317.5249, validation loss: 0.1870
2024-05-24 23:13:09 [INFO]: Epoch 045 - training loss: 9325.8671, validation loss: 0.1852
2024-05-24 23:13:09 [INFO]: Epoch 046 - training loss: 9317.2643, validation loss: 0.1807
2024-05-24 23:13:09 [INFO]: Epoch 047 - training loss: 9315.5867, validation loss: 0.1799
2024-05-24 23:13:09 [INFO]: Epoch 048 - training loss: 9307.4523, validation loss: 0.1788
2024-05-24 23:13:09 [INFO]: Epoch 049 - training loss: 9304.3364, validation loss: 0.1733
2024-05-24 23:13:09 [INFO]: Epoch 050 - training loss: 9300.7966, validation loss: 0.1809
2024-05-24 23:13:09 [INFO]: Epoch 051 - training loss: 9293.4349, validation loss: 0.1721
2024-05-24 23:13:09 [INFO]: Epoch 052 - training loss: 9292.8303, validation loss: 0.1701
2024-05-24 23:13:10 [INFO]: Epoch 053 - training loss: 9287.0213, validation loss: 0.1661
2024-05-24 23:13:10 [INFO]: Epoch 054 - training loss: 9284.8373, validation loss: 0.1643
2024-05-24 23:13:10 [INFO]: Epoch 055 - training loss: 9283.2830, validation loss: 0.1606
2024-05-24 23:13:10 [INFO]: Epoch 056 - training loss: 9281.9049, validation loss: 0.1626
2024-05-24 23:13:10 [INFO]: Epoch 057 - training loss: 9282.9023, validation loss: 0.1607
2024-05-24 23:13:10 [INFO]: Epoch 058 - training loss: 9279.8933, validation loss: 0.1577
2024-05-24 23:13:10 [INFO]: Epoch 059 - training loss: 9272.8727, validation loss: 0.1556
2024-05-24 23:13:10 [INFO]: Epoch 060 - training loss: 9276.0360, validation loss: 0.1547
2024-05-24 23:13:11 [INFO]: Epoch 061 - training loss: 9272.0414, validation loss: 0.1539
2024-05-24 23:13:11 [INFO]: Epoch 062 - training loss: 9271.5858, validation loss: 0.1504
2024-05-24 23:13:11 [INFO]: Epoch 063 - training loss: 9266.2983, validation loss: 0.1503
2024-05-24 23:13:11 [INFO]: Epoch 064 - training loss: 9264.8050, validation loss: 0.1496
2024-05-24 23:13:11 [INFO]: Epoch 065 - training loss: 9265.5933, validation loss: 0.1469
2024-05-24 23:13:11 [INFO]: Epoch 066 - training loss: 9267.4098, validation loss: 0.1482
2024-05-24 23:13:11 [INFO]: Epoch 067 - training loss: 9284.9491, validation loss: 0.1447
2024-05-24 23:13:11 [INFO]: Epoch 068 - training loss: 9261.8376, validation loss: 0.1437
2024-05-24 23:13:12 [INFO]: Epoch 069 - training loss: 9260.1038, validation loss: 0.1499
2024-05-24 23:13:12 [INFO]: Epoch 070 - training loss: 9253.1052, validation loss: 0.1440
2024-05-24 23:13:12 [INFO]: Epoch 071 - training loss: 9260.4919, validation loss: 0.1441
2024-05-24 23:13:12 [INFO]: Epoch 072 - training loss: 9252.0815, validation loss: 0.1417
2024-05-24 23:13:12 [INFO]: Epoch 073 - training loss: 9253.1608, validation loss: 0.1427
2024-05-24 23:13:12 [INFO]: Epoch 074 - training loss: 9251.3859, validation loss: 0.1413
2024-05-24 23:13:12 [INFO]: Epoch 075 - training loss: 9250.1674, validation loss: 0.1402
2024-05-24 23:13:12 [INFO]: Epoch 076 - training loss: 9251.5645, validation loss: 0.1383
2024-05-24 23:13:13 [INFO]: Epoch 077 - training loss: 9254.2736, validation loss: 0.1381
2024-05-24 23:13:13 [INFO]: Epoch 078 - training loss: 9246.9381, validation loss: 0.1385
2024-05-24 23:13:13 [INFO]: Epoch 079 - training loss: 9245.6044, validation loss: 0.1389
2024-05-24 23:13:13 [INFO]: Epoch 080 - training loss: 9246.0495, validation loss: 0.1354
2024-05-24 23:13:13 [INFO]: Epoch 081 - training loss: 9244.3843, validation loss: 0.1346
2024-05-24 23:13:13 [INFO]: Epoch 082 - training loss: 9245.7897, validation loss: 0.1336
2024-05-24 23:13:13 [INFO]: Epoch 083 - training loss: 9247.0838, validation loss: 0.1356
2024-05-24 23:13:13 [INFO]: Epoch 084 - training loss: 9238.5029, validation loss: 0.1337
2024-05-24 23:13:13 [INFO]: Epoch 085 - training loss: 9239.5654, validation loss: 0.1342
2024-05-24 23:13:14 [INFO]: Epoch 086 - training loss: 9239.6709, validation loss: 0.1317
2024-05-24 23:13:14 [INFO]: Epoch 087 - training loss: 9240.9642, validation loss: 0.1322
2024-05-24 23:13:14 [INFO]: Epoch 088 - training loss: 9239.4706, validation loss: 0.1323
2024-05-24 23:13:14 [INFO]: Epoch 089 - training loss: 9236.9732, validation loss: 0.1309
2024-05-24 23:13:14 [INFO]: Epoch 090 - training loss: 9238.3209, validation loss: 0.1301
2024-05-24 23:13:14 [INFO]: Epoch 091 - training loss: 9237.9983, validation loss: 0.1288
2024-05-24 23:13:14 [INFO]: Epoch 092 - training loss: 9237.5501, validation loss: 0.1290
2024-05-24 23:13:14 [INFO]: Epoch 093 - training loss: 9238.5775, validation loss: 0.1285
2024-05-24 23:13:15 [INFO]: Epoch 094 - training loss: 9236.6537, validation loss: 0.1282
2024-05-24 23:13:15 [INFO]: Epoch 095 - training loss: 9235.6722, validation loss: 0.1268
2024-05-24 23:13:15 [INFO]: Epoch 096 - training loss: 9234.9108, validation loss: 0.1270
2024-05-24 23:13:15 [INFO]: Epoch 097 - training loss: 9234.1467, validation loss: 0.1270
2024-05-24 23:13:15 [INFO]: Epoch 098 - training loss: 9232.0412, validation loss: 0.1275
2024-05-24 23:13:15 [INFO]: Epoch 099 - training loss: 9231.4484, validation loss: 0.1241
2024-05-24 23:13:15 [INFO]: Epoch 100 - training loss: 9231.2361, validation loss: 0.1246
2024-05-24 23:13:15 [INFO]: Epoch 101 - training loss: 9232.3940, validation loss: 0.1242
2024-05-24 23:13:16 [INFO]: Epoch 102 - training loss: 9232.9372, validation loss: 0.1230
2024-05-24 23:13:16 [INFO]: Epoch 103 - training loss: 9231.0536, validation loss: 0.1228
2024-05-24 23:13:16 [INFO]: Epoch 104 - training loss: 9231.1147, validation loss: 0.1234
2024-05-24 23:13:16 [INFO]: Epoch 105 - training loss: 9233.1248, validation loss: 0.1213
2024-05-24 23:13:16 [INFO]: Epoch 106 - training loss: 9231.2412, validation loss: 0.1239
2024-05-24 23:13:16 [INFO]: Epoch 107 - training loss: 9232.1460, validation loss: 0.1209
2024-05-24 23:13:16 [INFO]: Epoch 108 - training loss: 9234.1299, validation loss: 0.1200
2024-05-24 23:13:16 [INFO]: Epoch 109 - training loss: 9229.5206, validation loss: 0.1197
2024-05-24 23:13:17 [INFO]: Epoch 110 - training loss: 9229.8505, validation loss: 0.1199
2024-05-24 23:13:17 [INFO]: Epoch 111 - training loss: 9228.3845, validation loss: 0.1177
2024-05-24 23:13:17 [INFO]: Epoch 112 - training loss: 9226.2260, validation loss: 0.1165
2024-05-24 23:13:17 [INFO]: Epoch 113 - training loss: 9226.8610, validation loss: 0.1181
2024-05-24 23:13:17 [INFO]: Epoch 114 - training loss: 9224.9450, validation loss: 0.1171
2024-05-24 23:13:17 [INFO]: Epoch 115 - training loss: 9225.6826, validation loss: 0.1162
2024-05-24 23:13:17 [INFO]: Epoch 116 - training loss: 9226.9276, validation loss: 0.1171
2024-05-24 23:13:17 [INFO]: Epoch 117 - training loss: 9227.6485, validation loss: 0.1153
2024-05-24 23:13:17 [INFO]: Epoch 118 - training loss: 9225.6673, validation loss: 0.1146
2024-05-24 23:13:18 [INFO]: Epoch 119 - training loss: 9225.4261, validation loss: 0.1131
2024-05-24 23:13:18 [INFO]: Epoch 120 - training loss: 9223.4429, validation loss: 0.1152
2024-05-24 23:13:18 [INFO]: Epoch 121 - training loss: 9232.5275, validation loss: 0.1151
2024-05-24 23:13:18 [INFO]: Epoch 122 - training loss: 9226.3328, validation loss: 0.1123
2024-05-24 23:13:18 [INFO]: Epoch 123 - training loss: 9227.4697, validation loss: 0.1129
2024-05-24 23:13:18 [INFO]: Epoch 124 - training loss: 9223.6204, validation loss: 0.1126
2024-05-24 23:13:18 [INFO]: Epoch 125 - training loss: 9223.0312, validation loss: 0.1108
2024-05-24 23:13:18 [INFO]: Epoch 126 - training loss: 9220.9916, validation loss: 0.1100
2024-05-24 23:13:19 [INFO]: Epoch 127 - training loss: 9222.0352, validation loss: 0.1139
2024-05-24 23:13:19 [INFO]: Epoch 128 - training loss: 9222.7244, validation loss: 0.1103
2024-05-24 23:13:19 [INFO]: Epoch 129 - training loss: 9221.7109, validation loss: 0.1103
2024-05-24 23:13:19 [INFO]: Epoch 130 - training loss: 9221.2817, validation loss: 0.1087
2024-05-24 23:13:19 [INFO]: Epoch 131 - training loss: 9220.5887, validation loss: 0.1091
2024-05-24 23:13:19 [INFO]: Epoch 132 - training loss: 9222.9990, validation loss: 0.1095
2024-05-24 23:13:19 [INFO]: Epoch 133 - training loss: 9222.7849, validation loss: 0.1078
2024-05-24 23:13:19 [INFO]: Epoch 134 - training loss: 9222.1570, validation loss: 0.1096
2024-05-24 23:13:20 [INFO]: Epoch 135 - training loss: 9221.9033, validation loss: 0.1081
2024-05-24 23:13:20 [INFO]: Epoch 136 - training loss: 9224.0444, validation loss: 0.1067
2024-05-24 23:13:20 [INFO]: Epoch 137 - training loss: 9220.8545, validation loss: 0.1067
2024-05-24 23:13:20 [INFO]: Epoch 138 - training loss: 9220.5021, validation loss: 0.1068
2024-05-24 23:13:20 [INFO]: Epoch 139 - training loss: 9218.9611, validation loss: 0.1066
2024-05-24 23:13:20 [INFO]: Epoch 140 - training loss: 9218.6241, validation loss: 0.1066
2024-05-24 23:13:20 [INFO]: Epoch 141 - training loss: 9219.8854, validation loss: 0.1072
2024-05-24 23:13:20 [INFO]: Epoch 142 - training loss: 9218.9897, validation loss: 0.1071
2024-05-24 23:13:20 [INFO]: Epoch 143 - training loss: 9217.8322, validation loss: 0.1032
2024-05-24 23:13:21 [INFO]: Epoch 144 - training loss: 9219.0165, validation loss: 0.1047
2024-05-24 23:13:21 [INFO]: Epoch 145 - training loss: 9219.8104, validation loss: 0.1048
2024-05-24 23:13:21 [INFO]: Epoch 146 - training loss: 9218.0667, validation loss: 0.1041
2024-05-24 23:13:21 [INFO]: Epoch 147 - training loss: 9219.1159, validation loss: 0.1031
2024-05-24 23:13:21 [INFO]: Epoch 148 - training loss: 9219.5643, validation loss: 0.1009
2024-05-24 23:13:21 [INFO]: Epoch 149 - training loss: 9218.1465, validation loss: 0.1028
2024-05-24 23:13:21 [INFO]: Epoch 150 - training loss: 9217.7883, validation loss: 0.1030
2024-05-24 23:13:21 [INFO]: Epoch 151 - training loss: 9216.9758, validation loss: 0.1017
2024-05-24 23:13:22 [INFO]: Epoch 152 - training loss: 9219.0430, validation loss: 0.1012
2024-05-24 23:13:22 [INFO]: Epoch 153 - training loss: 9217.1338, validation loss: 0.1003
2024-05-24 23:13:22 [INFO]: Epoch 154 - training loss: 9216.8307, validation loss: 0.1000
2024-05-24 23:13:22 [INFO]: Epoch 155 - training loss: 9214.8292, validation loss: 0.0998
2024-05-24 23:13:22 [INFO]: Epoch 156 - training loss: 9215.8368, validation loss: 0.0995
2024-05-24 23:13:22 [INFO]: Epoch 157 - training loss: 9216.4434, validation loss: 0.0994
2024-05-24 23:13:22 [INFO]: Epoch 158 - training loss: 9214.8854, validation loss: 0.0986
2024-05-24 23:13:22 [INFO]: Epoch 159 - training loss: 9215.0259, validation loss: 0.0985
2024-05-24 23:13:23 [INFO]: Epoch 160 - training loss: 9215.5400, validation loss: 0.0988
2024-05-24 23:13:23 [INFO]: Epoch 161 - training loss: 9215.3976, validation loss: 0.0997
2024-05-24 23:13:23 [INFO]: Epoch 162 - training loss: 9213.6947, validation loss: 0.0973
2024-05-24 23:13:23 [INFO]: Epoch 163 - training loss: 9214.5135, validation loss: 0.0997
2024-05-24 23:13:23 [INFO]: Epoch 164 - training loss: 9214.1436, validation loss: 0.0977
2024-05-24 23:13:23 [INFO]: Epoch 165 - training loss: 9215.0604, validation loss: 0.0979
2024-05-24 23:13:23 [INFO]: Epoch 166 - training loss: 9215.0312, validation loss: 0.0972
2024-05-24 23:13:23 [INFO]: Epoch 167 - training loss: 9213.4158, validation loss: 0.0956
2024-05-24 23:13:23 [INFO]: Epoch 168 - training loss: 9215.4789, validation loss: 0.0985
2024-05-24 23:13:24 [INFO]: Epoch 169 - training loss: 9215.1711, validation loss: 0.0965
2024-05-24 23:13:24 [INFO]: Epoch 170 - training loss: 9213.4329, validation loss: 0.0963
2024-05-24 23:13:24 [INFO]: Epoch 171 - training loss: 9213.8837, validation loss: 0.0939
2024-05-24 23:13:24 [INFO]: Epoch 172 - training loss: 9213.1658, validation loss: 0.0941
2024-05-24 23:13:24 [INFO]: Epoch 173 - training loss: 9213.5075, validation loss: 0.0955
2024-05-24 23:13:24 [INFO]: Epoch 174 - training loss: 9212.2404, validation loss: 0.0955
2024-05-24 23:13:24 [INFO]: Epoch 175 - training loss: 9214.8473, validation loss: 0.0936
2024-05-24 23:13:24 [INFO]: Epoch 176 - training loss: 9212.5304, validation loss: 0.0922
2024-05-24 23:13:25 [INFO]: Epoch 177 - training loss: 9213.9730, validation loss: 0.0939
2024-05-24 23:13:25 [INFO]: Epoch 178 - training loss: 9211.9237, validation loss: 0.0933
2024-05-24 23:13:25 [INFO]: Epoch 179 - training loss: 9213.8751, validation loss: 0.0932
2024-05-24 23:13:25 [INFO]: Epoch 180 - training loss: 9212.8115, validation loss: 0.0920
2024-05-24 23:13:25 [INFO]: Epoch 181 - training loss: 9212.6335, validation loss: 0.0931
2024-05-24 23:13:25 [INFO]: Epoch 182 - training loss: 9213.0895, validation loss: 0.0941
2024-05-24 23:13:25 [INFO]: Epoch 183 - training loss: 9213.6046, validation loss: 0.0920
2024-05-24 23:13:25 [INFO]: Epoch 184 - training loss: 9211.9117, validation loss: 0.0913
2024-05-24 23:13:26 [INFO]: Epoch 185 - training loss: 9212.5677, validation loss: 0.0920
2024-05-24 23:13:26 [INFO]: Epoch 186 - training loss: 9213.2081, validation loss: 0.0914
2024-05-24 23:13:26 [INFO]: Epoch 187 - training loss: 9212.0496, validation loss: 0.0924
2024-05-24 23:13:26 [INFO]: Epoch 188 - training loss: 9212.8339, validation loss: 0.0905
2024-05-24 23:13:26 [INFO]: Epoch 189 - training loss: 9213.1495, validation loss: 0.0915
2024-05-24 23:13:26 [INFO]: Epoch 190 - training loss: 9212.1707, validation loss: 0.0907
2024-05-24 23:13:26 [INFO]: Epoch 191 - training loss: 9212.1497, validation loss: 0.0891
2024-05-24 23:13:26 [INFO]: Epoch 192 - training loss: 9210.0228, validation loss: 0.0902
2024-05-24 23:13:27 [INFO]: Epoch 193 - training loss: 9211.5823, validation loss: 0.0906
2024-05-24 23:13:27 [INFO]: Epoch 194 - training loss: 9212.2271, validation loss: 0.0906
2024-05-24 23:13:27 [INFO]: Epoch 195 - training loss: 9212.7378, validation loss: 0.0882
2024-05-24 23:13:27 [INFO]: Epoch 196 - training loss: 9212.3635, validation loss: 0.0893
2024-05-24 23:13:27 [INFO]: Epoch 197 - training loss: 9211.2299, validation loss: 0.0900
2024-05-24 23:13:27 [INFO]: Epoch 198 - training loss: 9212.5769, validation loss: 0.0885
2024-05-24 23:13:27 [INFO]: Epoch 199 - training loss: 9210.7161, validation loss: 0.0927
2024-05-24 23:13:27 [INFO]: Epoch 200 - training loss: 9210.3084, validation loss: 0.0883
2024-05-24 23:13:27 [INFO]: Epoch 201 - training loss: 9210.6277, validation loss: 0.0877
2024-05-24 23:13:28 [INFO]: Epoch 202 - training loss: 9211.5417, validation loss: 0.0918
2024-05-24 23:13:28 [INFO]: Epoch 203 - training loss: 9210.8453, validation loss: 0.0882
2024-05-24 23:13:28 [INFO]: Epoch 204 - training loss: 9210.4309, validation loss: 0.0887
2024-05-24 23:13:28 [INFO]: Epoch 205 - training loss: 9210.3516, validation loss: 0.0878
2024-05-24 23:13:28 [INFO]: Epoch 206 - training loss: 9210.8301, validation loss: 0.0909
2024-05-24 23:13:28 [INFO]: Epoch 207 - training loss: 9210.2228, validation loss: 0.0878
2024-05-24 23:13:28 [INFO]: Epoch 208 - training loss: 9209.3174, validation loss: 0.0879
2024-05-24 23:13:28 [INFO]: Epoch 209 - training loss: 9210.6756, validation loss: 0.0873
2024-05-24 23:13:29 [INFO]: Epoch 210 - training loss: 9211.1628, validation loss: 0.0877
2024-05-24 23:13:29 [INFO]: Epoch 211 - training loss: 9210.0876, validation loss: 0.0886
2024-05-24 23:13:29 [INFO]: Epoch 212 - training loss: 9210.9067, validation loss: 0.0862
2024-05-24 23:13:29 [INFO]: Epoch 213 - training loss: 9209.3412, validation loss: 0.0883
2024-05-24 23:13:29 [INFO]: Epoch 214 - training loss: 9210.4464, validation loss: 0.0865
2024-05-24 23:13:29 [INFO]: Epoch 215 - training loss: 9210.2504, validation loss: 0.0861
2024-05-24 23:13:29 [INFO]: Epoch 216 - training loss: 9209.7231, validation loss: 0.0882
2024-05-24 23:13:29 [INFO]: Epoch 217 - training loss: 9208.5986, validation loss: 0.0851
2024-05-24 23:13:30 [INFO]: Epoch 218 - training loss: 9209.8274, validation loss: 0.0860
2024-05-24 23:13:30 [INFO]: Epoch 219 - training loss: 9207.8439, validation loss: 0.0853
2024-05-24 23:13:30 [INFO]: Epoch 220 - training loss: 9210.4255, validation loss: 0.0852
2024-05-24 23:13:30 [INFO]: Epoch 221 - training loss: 9209.8976, validation loss: 0.0858
2024-05-24 23:13:30 [INFO]: Epoch 222 - training loss: 9209.8204, validation loss: 0.0850
2024-05-24 23:13:30 [INFO]: Epoch 223 - training loss: 9209.9883, validation loss: 0.0864
2024-05-24 23:13:30 [INFO]: Epoch 224 - training loss: 9208.7474, validation loss: 0.0856
2024-05-24 23:13:30 [INFO]: Epoch 225 - training loss: 9209.5920, validation loss: 0.0851
2024-05-24 23:13:30 [INFO]: Epoch 226 - training loss: 9208.8647, validation loss: 0.0854
2024-05-24 23:13:31 [INFO]: Epoch 227 - training loss: 9209.8112, validation loss: 0.0847
2024-05-24 23:13:31 [INFO]: Epoch 228 - training loss: 9208.9055, validation loss: 0.0883
2024-05-24 23:13:31 [INFO]: Epoch 229 - training loss: 9208.5207, validation loss: 0.0847
2024-05-24 23:13:31 [INFO]: Epoch 230 - training loss: 9209.2814, validation loss: 0.0855
2024-05-24 23:13:31 [INFO]: Epoch 231 - training loss: 9209.7602, validation loss: 0.0856
2024-05-24 23:13:31 [INFO]: Epoch 232 - training loss: 9208.8380, validation loss: 0.0836
2024-05-24 23:13:31 [INFO]: Epoch 233 - training loss: 9210.1752, validation loss: 0.0848
2024-05-24 23:13:31 [INFO]: Epoch 234 - training loss: 9209.8805, validation loss: 0.0839
2024-05-24 23:13:32 [INFO]: Epoch 235 - training loss: 9207.5797, validation loss: 0.0863
2024-05-24 23:13:32 [INFO]: Epoch 236 - training loss: 9207.3679, validation loss: 0.0855
2024-05-24 23:13:32 [INFO]: Epoch 237 - training loss: 9208.4161, validation loss: 0.0836
2024-05-24 23:13:32 [INFO]: Epoch 238 - training loss: 9209.8965, validation loss: 0.0829
2024-05-24 23:13:32 [INFO]: Epoch 239 - training loss: 9208.2330, validation loss: 0.0833
2024-05-24 23:13:32 [INFO]: Epoch 240 - training loss: 9208.3281, validation loss: 0.0826
2024-05-24 23:13:32 [INFO]: Epoch 241 - training loss: 9209.1872, validation loss: 0.0834
2024-05-24 23:13:32 [INFO]: Epoch 242 - training loss: 9209.3488, validation loss: 0.0841
2024-05-24 23:13:33 [INFO]: Epoch 243 - training loss: 9209.1127, validation loss: 0.0851
2024-05-24 23:13:33 [INFO]: Epoch 244 - training loss: 9208.8021, validation loss: 0.0810
2024-05-24 23:13:33 [INFO]: Epoch 245 - training loss: 9206.3132, validation loss: 0.0821
2024-05-24 23:13:33 [INFO]: Epoch 246 - training loss: 9208.2584, validation loss: 0.0852
2024-05-24 23:13:33 [INFO]: Epoch 247 - training loss: 9208.2361, validation loss: 0.0822
2024-05-24 23:13:33 [INFO]: Epoch 248 - training loss: 9206.2359, validation loss: 0.0820
2024-05-24 23:13:33 [INFO]: Epoch 249 - training loss: 9207.7665, validation loss: 0.0826
2024-05-24 23:13:33 [INFO]: Epoch 250 - training loss: 9209.2336, validation loss: 0.0835
2024-05-24 23:13:34 [INFO]: Epoch 251 - training loss: 9208.0286, validation loss: 0.0831
2024-05-24 23:13:34 [INFO]: Epoch 252 - training loss: 9208.7317, validation loss: 0.0848
2024-05-24 23:13:34 [INFO]: Epoch 253 - training loss: 9208.4662, validation loss: 0.0810
2024-05-24 23:13:34 [INFO]: Epoch 254 - training loss: 9208.2576, validation loss: 0.0861
2024-05-24 23:13:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:13:34 [INFO]: Finished training. The best model is from epoch#244.
2024-05-24 23:13:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/GPVAE_ettm1/20240524_T231303/GPVAE.pypots
2024-05-24 23:13:34 [INFO]: GP-VAE on ETTm1: MAE=0.2987, MSE=0.1967
2024-05-24 23:13:34 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-24 23:13:34 [INFO]: Using the given device: cuda:0
2024-05-24 23:13:34 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T231334
2024-05-24 23:13:34 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T231334/tensorboard
2024-05-24 23:13:34 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 23:13:44 [INFO]: Epoch 001 - generator training loss: 0.4441, discriminator training loss: 0.5454, validation loss: 0.3549
2024-05-24 23:13:53 [INFO]: Epoch 002 - generator training loss: -0.0528, discriminator training loss: 0.4757, validation loss: 0.1200
2024-05-24 23:14:02 [INFO]: Epoch 003 - generator training loss: -0.1591, discriminator training loss: 0.4380, validation loss: 0.0656
2024-05-24 23:14:11 [INFO]: Epoch 004 - generator training loss: -0.1554, discriminator training loss: 0.3802, validation loss: 0.0560
2024-05-24 23:14:19 [INFO]: Epoch 005 - generator training loss: -0.1133, discriminator training loss: 0.3052, validation loss: 0.0478
2024-05-24 23:14:28 [INFO]: Epoch 006 - generator training loss: -0.0763, discriminator training loss: 0.2399, validation loss: 0.0456
2024-05-24 23:14:37 [INFO]: Epoch 007 - generator training loss: -0.0561, discriminator training loss: 0.2029, validation loss: 0.0441
2024-05-24 23:14:46 [INFO]: Epoch 008 - generator training loss: -0.0527, discriminator training loss: 0.1883, validation loss: 0.0428
2024-05-24 23:14:54 [INFO]: Epoch 009 - generator training loss: -0.0512, discriminator training loss: 0.1815, validation loss: 0.0394
2024-05-24 23:15:03 [INFO]: Epoch 010 - generator training loss: -0.0507, discriminator training loss: 0.1774, validation loss: 0.0395
2024-05-24 23:15:12 [INFO]: Epoch 011 - generator training loss: -0.0562, discriminator training loss: 0.1749, validation loss: 0.0391
2024-05-24 23:15:21 [INFO]: Epoch 012 - generator training loss: -0.0552, discriminator training loss: 0.1738, validation loss: 0.0378
2024-05-24 23:15:29 [INFO]: Epoch 013 - generator training loss: -0.0555, discriminator training loss: 0.1764, validation loss: 0.0373
2024-05-24 23:15:38 [INFO]: Epoch 014 - generator training loss: -0.0552, discriminator training loss: 0.1720, validation loss: 0.0370
2024-05-24 23:15:47 [INFO]: Epoch 015 - generator training loss: -0.0592, discriminator training loss: 0.1736, validation loss: 0.0350
2024-05-24 23:15:56 [INFO]: Epoch 016 - generator training loss: -0.0581, discriminator training loss: 0.1733, validation loss: 0.0357
2024-05-24 23:16:04 [INFO]: Epoch 017 - generator training loss: -0.0563, discriminator training loss: 0.1704, validation loss: 0.0356
2024-05-24 23:16:13 [INFO]: Epoch 018 - generator training loss: -0.0567, discriminator training loss: 0.1707, validation loss: 0.0346
2024-05-24 23:16:22 [INFO]: Epoch 019 - generator training loss: -0.0592, discriminator training loss: 0.1711, validation loss: 0.0337
2024-05-24 23:16:31 [INFO]: Epoch 020 - generator training loss: -0.0604, discriminator training loss: 0.1718, validation loss: 0.0350
2024-05-24 23:16:40 [INFO]: Epoch 021 - generator training loss: -0.0584, discriminator training loss: 0.1718, validation loss: 0.0330
2024-05-24 23:16:48 [INFO]: Epoch 022 - generator training loss: -0.0595, discriminator training loss: 0.1699, validation loss: 0.0359
2024-05-24 23:16:57 [INFO]: Epoch 023 - generator training loss: -0.0611, discriminator training loss: 0.1687, validation loss: 0.0346
2024-05-24 23:17:06 [INFO]: Epoch 024 - generator training loss: -0.0609, discriminator training loss: 0.1688, validation loss: 0.0335
2024-05-24 23:17:15 [INFO]: Epoch 025 - generator training loss: -0.0599, discriminator training loss: 0.1694, validation loss: 0.0339
2024-05-24 23:17:23 [INFO]: Epoch 026 - generator training loss: -0.0655, discriminator training loss: 0.1696, validation loss: 0.0326
2024-05-24 23:17:32 [INFO]: Epoch 027 - generator training loss: -0.0592, discriminator training loss: 0.1681, validation loss: 0.0317
2024-05-24 23:17:41 [INFO]: Epoch 028 - generator training loss: -0.0621, discriminator training loss: 0.1668, validation loss: 0.0334
2024-05-24 23:17:50 [INFO]: Epoch 029 - generator training loss: -0.0640, discriminator training loss: 0.1676, validation loss: 0.0345
2024-05-24 23:17:58 [INFO]: Epoch 030 - generator training loss: -0.0560, discriminator training loss: 0.1686, validation loss: 0.0317
2024-05-24 23:18:07 [INFO]: Epoch 031 - generator training loss: -0.0611, discriminator training loss: 0.1679, validation loss: 0.0308
2024-05-24 23:18:16 [INFO]: Epoch 032 - generator training loss: -0.0654, discriminator training loss: 0.1685, validation loss: 0.0307
2024-05-24 23:18:25 [INFO]: Epoch 033 - generator training loss: -0.0603, discriminator training loss: 0.1685, validation loss: 0.0300
2024-05-24 23:18:33 [INFO]: Epoch 034 - generator training loss: -0.0683, discriminator training loss: 0.1686, validation loss: 0.0300
2024-05-24 23:18:42 [INFO]: Epoch 035 - generator training loss: -0.0626, discriminator training loss: 0.1672, validation loss: 0.0309
2024-05-24 23:18:51 [INFO]: Epoch 036 - generator training loss: -0.0651, discriminator training loss: 0.1669, validation loss: 0.0299
2024-05-24 23:19:00 [INFO]: Epoch 037 - generator training loss: -0.0646, discriminator training loss: 0.1678, validation loss: 0.0298
2024-05-24 23:19:08 [INFO]: Epoch 038 - generator training loss: -0.0663, discriminator training loss: 0.1664, validation loss: 0.0287
2024-05-24 23:19:17 [INFO]: Epoch 039 - generator training loss: -0.0692, discriminator training loss: 0.1686, validation loss: 0.0286
2024-05-24 23:19:26 [INFO]: Epoch 040 - generator training loss: -0.0634, discriminator training loss: 0.1676, validation loss: 0.0287
2024-05-24 23:19:35 [INFO]: Epoch 041 - generator training loss: -0.0698, discriminator training loss: 0.1653, validation loss: 0.0278
2024-05-24 23:19:43 [INFO]: Epoch 042 - generator training loss: -0.0694, discriminator training loss: 0.1655, validation loss: 0.0289
2024-05-24 23:19:52 [INFO]: Epoch 043 - generator training loss: -0.0663, discriminator training loss: 0.1659, validation loss: 0.0281
2024-05-24 23:20:01 [INFO]: Epoch 044 - generator training loss: -0.0641, discriminator training loss: 0.1669, validation loss: 0.0284
2024-05-24 23:20:10 [INFO]: Epoch 045 - generator training loss: -0.0595, discriminator training loss: 0.1670, validation loss: 0.0296
2024-05-24 23:20:19 [INFO]: Epoch 046 - generator training loss: -0.0644, discriminator training loss: 0.1653, validation loss: 0.0311
2024-05-24 23:20:27 [INFO]: Epoch 047 - generator training loss: -0.0604, discriminator training loss: 0.1671, validation loss: 0.0307
2024-05-24 23:20:36 [INFO]: Epoch 048 - generator training loss: -0.0646, discriminator training loss: 0.1677, validation loss: 0.0297
2024-05-24 23:20:45 [INFO]: Epoch 049 - generator training loss: -0.0663, discriminator training loss: 0.1663, validation loss: 0.0286
2024-05-24 23:20:54 [INFO]: Epoch 050 - generator training loss: -0.0664, discriminator training loss: 0.1652, validation loss: 0.0274
2024-05-24 23:21:02 [INFO]: Epoch 051 - generator training loss: -0.0695, discriminator training loss: 0.1663, validation loss: 0.0279
2024-05-24 23:21:11 [INFO]: Epoch 052 - generator training loss: -0.0642, discriminator training loss: 0.1671, validation loss: 0.0272
2024-05-24 23:21:20 [INFO]: Epoch 053 - generator training loss: -0.0674, discriminator training loss: 0.1656, validation loss: 0.0280
2024-05-24 23:21:28 [INFO]: Epoch 054 - generator training loss: -0.0644, discriminator training loss: 0.1644, validation loss: 0.0282
2024-05-24 23:21:37 [INFO]: Epoch 055 - generator training loss: -0.0702, discriminator training loss: 0.1665, validation loss: 0.0281
2024-05-24 23:21:46 [INFO]: Epoch 056 - generator training loss: -0.0686, discriminator training loss: 0.1653, validation loss: 0.0278
2024-05-24 23:21:55 [INFO]: Epoch 057 - generator training loss: -0.0666, discriminator training loss: 0.1650, validation loss: 0.0274
2024-05-24 23:22:03 [INFO]: Epoch 058 - generator training loss: -0.0671, discriminator training loss: 0.1647, validation loss: 0.0274
2024-05-24 23:22:12 [INFO]: Epoch 059 - generator training loss: -0.0677, discriminator training loss: 0.1640, validation loss: 0.0269
2024-05-24 23:22:21 [INFO]: Epoch 060 - generator training loss: -0.0695, discriminator training loss: 0.1641, validation loss: 0.0271
2024-05-24 23:22:30 [INFO]: Epoch 061 - generator training loss: -0.0686, discriminator training loss: 0.1646, validation loss: 0.0273
2024-05-24 23:22:39 [INFO]: Epoch 062 - generator training loss: -0.0710, discriminator training loss: 0.1638, validation loss: 0.0265
2024-05-24 23:22:47 [INFO]: Epoch 063 - generator training loss: -0.0661, discriminator training loss: 0.1640, validation loss: 0.0269
2024-05-24 23:22:56 [INFO]: Epoch 064 - generator training loss: -0.0692, discriminator training loss: 0.1659, validation loss: 0.0270
2024-05-24 23:23:05 [INFO]: Epoch 065 - generator training loss: -0.0650, discriminator training loss: 0.1635, validation loss: 0.0269
2024-05-24 23:23:14 [INFO]: Epoch 066 - generator training loss: -0.0689, discriminator training loss: 0.1640, validation loss: 0.0268
2024-05-24 23:23:23 [INFO]: Epoch 067 - generator training loss: -0.0691, discriminator training loss: 0.1643, validation loss: 0.0265
2024-05-24 23:23:31 [INFO]: Epoch 068 - generator training loss: -0.0720, discriminator training loss: 0.1633, validation loss: 0.0267
2024-05-24 23:23:40 [INFO]: Epoch 069 - generator training loss: -0.0693, discriminator training loss: 0.1629, validation loss: 0.0257
2024-05-24 23:23:49 [INFO]: Epoch 070 - generator training loss: -0.0679, discriminator training loss: 0.1636, validation loss: 0.0266
2024-05-24 23:23:57 [INFO]: Epoch 071 - generator training loss: -0.0687, discriminator training loss: 0.1644, validation loss: 0.0262
2024-05-24 23:24:06 [INFO]: Epoch 072 - generator training loss: -0.0707, discriminator training loss: 0.1653, validation loss: 0.0256
2024-05-24 23:24:15 [INFO]: Epoch 073 - generator training loss: -0.0696, discriminator training loss: 0.1646, validation loss: 0.0255
2024-05-24 23:24:24 [INFO]: Epoch 074 - generator training loss: -0.0719, discriminator training loss: 0.1641, validation loss: 0.0259
2024-05-24 23:24:32 [INFO]: Epoch 075 - generator training loss: -0.0690, discriminator training loss: 0.1633, validation loss: 0.0255
2024-05-24 23:24:41 [INFO]: Epoch 076 - generator training loss: -0.0689, discriminator training loss: 0.1613, validation loss: 0.0250
2024-05-24 23:24:50 [INFO]: Epoch 077 - generator training loss: -0.0720, discriminator training loss: 0.1631, validation loss: 0.0253
2024-05-24 23:24:59 [INFO]: Epoch 078 - generator training loss: -0.0725, discriminator training loss: 0.1623, validation loss: 0.0244
2024-05-24 23:25:07 [INFO]: Epoch 079 - generator training loss: -0.0725, discriminator training loss: 0.1641, validation loss: 0.0254
2024-05-24 23:25:16 [INFO]: Epoch 080 - generator training loss: -0.0726, discriminator training loss: 0.1620, validation loss: 0.0244
2024-05-24 23:25:25 [INFO]: Epoch 081 - generator training loss: -0.0734, discriminator training loss: 0.1616, validation loss: 0.0240
2024-05-24 23:25:34 [INFO]: Epoch 082 - generator training loss: -0.0728, discriminator training loss: 0.1641, validation loss: 0.0252
2024-05-24 23:25:42 [INFO]: Epoch 083 - generator training loss: -0.0726, discriminator training loss: 0.1653, validation loss: 0.0244
2024-05-24 23:25:51 [INFO]: Epoch 084 - generator training loss: -0.0710, discriminator training loss: 0.1635, validation loss: 0.0242
2024-05-24 23:26:00 [INFO]: Epoch 085 - generator training loss: -0.0725, discriminator training loss: 0.1628, validation loss: 0.0246
2024-05-24 23:26:09 [INFO]: Epoch 086 - generator training loss: -0.0743, discriminator training loss: 0.1609, validation loss: 0.0240
2024-05-24 23:26:17 [INFO]: Epoch 087 - generator training loss: -0.0732, discriminator training loss: 0.1614, validation loss: 0.0241
2024-05-24 23:26:26 [INFO]: Epoch 088 - generator training loss: -0.0738, discriminator training loss: 0.1615, validation loss: 0.0235
2024-05-24 23:26:35 [INFO]: Epoch 089 - generator training loss: -0.0733, discriminator training loss: 0.1621, validation loss: 0.0239
2024-05-24 23:26:44 [INFO]: Epoch 090 - generator training loss: -0.0709, discriminator training loss: 0.1613, validation loss: 0.0236
2024-05-24 23:26:52 [INFO]: Epoch 091 - generator training loss: -0.0733, discriminator training loss: 0.1605, validation loss: 0.0235
2024-05-24 23:27:01 [INFO]: Epoch 092 - generator training loss: -0.0734, discriminator training loss: 0.1601, validation loss: 0.0239
2024-05-24 23:27:10 [INFO]: Epoch 093 - generator training loss: -0.0759, discriminator training loss: 0.1633, validation loss: 0.0237
2024-05-24 23:27:18 [INFO]: Epoch 094 - generator training loss: -0.0733, discriminator training loss: 0.1610, validation loss: 0.0242
2024-05-24 23:27:27 [INFO]: Epoch 095 - generator training loss: -0.0710, discriminator training loss: 0.1613, validation loss: 0.0240
2024-05-24 23:27:36 [INFO]: Epoch 096 - generator training loss: -0.0735, discriminator training loss: 0.1623, validation loss: 0.0237
2024-05-24 23:27:44 [INFO]: Epoch 097 - generator training loss: -0.0722, discriminator training loss: 0.1622, validation loss: 0.0237
2024-05-24 23:27:53 [INFO]: Epoch 098 - generator training loss: -0.0700, discriminator training loss: 0.1634, validation loss: 0.0239
2024-05-24 23:28:02 [INFO]: Epoch 099 - generator training loss: -0.0728, discriminator training loss: 0.1612, validation loss: 0.0229
2024-05-24 23:28:11 [INFO]: Epoch 100 - generator training loss: -0.0754, discriminator training loss: 0.1594, validation loss: 0.0237
2024-05-24 23:28:19 [INFO]: Epoch 101 - generator training loss: -0.0731, discriminator training loss: 0.1592, validation loss: 0.0237
2024-05-24 23:28:28 [INFO]: Epoch 102 - generator training loss: -0.0710, discriminator training loss: 0.1593, validation loss: 0.0243
2024-05-24 23:28:37 [INFO]: Epoch 103 - generator training loss: -0.0691, discriminator training loss: 0.1607, validation loss: 0.0268
2024-05-24 23:28:45 [INFO]: Epoch 104 - generator training loss: -0.0698, discriminator training loss: 0.1579, validation loss: 0.0252
2024-05-24 23:28:54 [INFO]: Epoch 105 - generator training loss: -0.0727, discriminator training loss: 0.1587, validation loss: 0.0248
2024-05-24 23:29:03 [INFO]: Epoch 106 - generator training loss: -0.0745, discriminator training loss: 0.1590, validation loss: 0.0239
2024-05-24 23:29:12 [INFO]: Epoch 107 - generator training loss: -0.0729, discriminator training loss: 0.1611, validation loss: 0.0236
2024-05-24 23:29:20 [INFO]: Epoch 108 - generator training loss: -0.0706, discriminator training loss: 0.1598, validation loss: 0.0231
2024-05-24 23:29:29 [INFO]: Epoch 109 - generator training loss: -0.0743, discriminator training loss: 0.1587, validation loss: 0.0294
2024-05-24 23:29:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:29:29 [INFO]: Finished training. The best model is from epoch#99.
2024-05-24 23:29:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/USGAN_ettm1/20240524_T231334/USGAN.pypots
2024-05-24 23:29:30 [INFO]: US-GAN on ETTm1: MAE=0.1699, MSE=0.0684
2024-05-24 23:29:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-24 23:29:30 [INFO]: Using the given device: cuda:0
2024-05-24 23:29:30 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T232930
2024-05-24 23:29:30 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T232930/tensorboard
2024-05-24 23:29:30 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:29:38 [INFO]: Epoch 001 - training loss: 1.3053, validation loss: 0.2857
2024-05-24 23:29:44 [INFO]: Epoch 002 - training loss: 0.8960, validation loss: 0.0868
2024-05-24 23:29:49 [INFO]: Epoch 003 - training loss: 0.7086, validation loss: 0.0581
2024-05-24 23:29:55 [INFO]: Epoch 004 - training loss: 0.6383, validation loss: 0.0469
2024-05-24 23:30:01 [INFO]: Epoch 005 - training loss: 0.6066, validation loss: 0.0422
2024-05-24 23:30:07 [INFO]: Epoch 006 - training loss: 0.5701, validation loss: 0.0382
2024-05-24 23:30:13 [INFO]: Epoch 007 - training loss: 0.5459, validation loss: 0.0361
2024-05-24 23:30:18 [INFO]: Epoch 008 - training loss: 0.5214, validation loss: 0.0355
2024-05-24 23:30:24 [INFO]: Epoch 009 - training loss: 0.5004, validation loss: 0.0344
2024-05-24 23:30:30 [INFO]: Epoch 010 - training loss: 0.5134, validation loss: 0.0355
2024-05-24 23:30:36 [INFO]: Epoch 011 - training loss: 0.4868, validation loss: 0.0358
2024-05-24 23:30:42 [INFO]: Epoch 012 - training loss: 0.4692, validation loss: 0.0368
2024-05-24 23:30:47 [INFO]: Epoch 013 - training loss: 0.4551, validation loss: 0.0323
2024-05-24 23:30:53 [INFO]: Epoch 014 - training loss: 0.4379, validation loss: 0.0329
2024-05-24 23:30:59 [INFO]: Epoch 015 - training loss: 0.4252, validation loss: 0.0304
2024-05-24 23:31:05 [INFO]: Epoch 016 - training loss: 0.4206, validation loss: 0.0294
2024-05-24 23:31:10 [INFO]: Epoch 017 - training loss: 0.4285, validation loss: 0.0292
2024-05-24 23:31:16 [INFO]: Epoch 018 - training loss: 0.4267, validation loss: 0.0293
2024-05-24 23:31:22 [INFO]: Epoch 019 - training loss: 0.4167, validation loss: 0.0292
2024-05-24 23:31:28 [INFO]: Epoch 020 - training loss: 0.4108, validation loss: 0.0281
2024-05-24 23:31:34 [INFO]: Epoch 021 - training loss: 0.3992, validation loss: 0.0282
2024-05-24 23:31:39 [INFO]: Epoch 022 - training loss: 0.4073, validation loss: 0.0275
2024-05-24 23:31:45 [INFO]: Epoch 023 - training loss: 0.4026, validation loss: 0.0272
2024-05-24 23:31:51 [INFO]: Epoch 024 - training loss: 0.3999, validation loss: 0.0273
2024-05-24 23:31:57 [INFO]: Epoch 025 - training loss: 0.3975, validation loss: 0.0274
2024-05-24 23:32:03 [INFO]: Epoch 026 - training loss: 0.4017, validation loss: 0.0275
2024-05-24 23:32:08 [INFO]: Epoch 027 - training loss: 0.3973, validation loss: 0.0281
2024-05-24 23:32:14 [INFO]: Epoch 028 - training loss: 0.4039, validation loss: 0.0271
2024-05-24 23:32:20 [INFO]: Epoch 029 - training loss: 0.3978, validation loss: 0.0271
2024-05-24 23:32:26 [INFO]: Epoch 030 - training loss: 0.3917, validation loss: 0.0271
2024-05-24 23:32:32 [INFO]: Epoch 031 - training loss: 0.3919, validation loss: 0.0269
2024-05-24 23:32:37 [INFO]: Epoch 032 - training loss: 0.4511, validation loss: 0.0280
2024-05-24 23:32:43 [INFO]: Epoch 033 - training loss: 0.4226, validation loss: 0.0299
2024-05-24 23:32:49 [INFO]: Epoch 034 - training loss: 0.4056, validation loss: 0.0282
2024-05-24 23:32:55 [INFO]: Epoch 035 - training loss: 0.3979, validation loss: 0.0276
2024-05-24 23:33:01 [INFO]: Epoch 036 - training loss: 0.4156, validation loss: 0.0273
2024-05-24 23:33:06 [INFO]: Epoch 037 - training loss: 0.3971, validation loss: 0.0275
2024-05-24 23:33:12 [INFO]: Epoch 038 - training loss: 0.3929, validation loss: 0.0270
2024-05-24 23:33:18 [INFO]: Epoch 039 - training loss: 0.3935, validation loss: 0.0273
2024-05-24 23:33:24 [INFO]: Epoch 040 - training loss: 0.3904, validation loss: 0.0271
2024-05-24 23:33:29 [INFO]: Epoch 041 - training loss: 0.4039, validation loss: 0.0268
2024-05-24 23:33:35 [INFO]: Epoch 042 - training loss: 0.3966, validation loss: 0.0272
2024-05-24 23:33:41 [INFO]: Epoch 043 - training loss: 0.3950, validation loss: 0.0268
2024-05-24 23:33:47 [INFO]: Epoch 044 - training loss: 0.3896, validation loss: 0.0271
2024-05-24 23:33:53 [INFO]: Epoch 045 - training loss: 0.3874, validation loss: 0.0270
2024-05-24 23:33:59 [INFO]: Epoch 046 - training loss: 0.4000, validation loss: 0.0280
2024-05-24 23:34:05 [INFO]: Epoch 047 - training loss: 0.3857, validation loss: 0.0268
2024-05-24 23:34:10 [INFO]: Epoch 048 - training loss: 0.3951, validation loss: 0.0267
2024-05-24 23:34:17 [INFO]: Epoch 049 - training loss: 0.4421, validation loss: 0.0272
2024-05-24 23:34:22 [INFO]: Epoch 050 - training loss: 0.4152, validation loss: 0.0294
2024-05-24 23:34:28 [INFO]: Epoch 051 - training loss: 0.4011, validation loss: 0.0284
2024-05-24 23:34:34 [INFO]: Epoch 052 - training loss: 0.3954, validation loss: 0.0279
2024-05-24 23:34:40 [INFO]: Epoch 053 - training loss: 0.3906, validation loss: 0.0262
2024-05-24 23:34:46 [INFO]: Epoch 054 - training loss: 0.3872, validation loss: 0.0267
2024-05-24 23:34:51 [INFO]: Epoch 055 - training loss: 0.3809, validation loss: 0.0264
2024-05-24 23:34:57 [INFO]: Epoch 056 - training loss: 0.3908, validation loss: 0.0264
2024-05-24 23:35:03 [INFO]: Epoch 057 - training loss: 0.3924, validation loss: 0.0264
2024-05-24 23:35:09 [INFO]: Epoch 058 - training loss: 0.3886, validation loss: 0.0265
2024-05-24 23:35:15 [INFO]: Epoch 059 - training loss: 0.4005, validation loss: 0.0269
2024-05-24 23:35:21 [INFO]: Epoch 060 - training loss: 0.3993, validation loss: 0.0279
2024-05-24 23:35:27 [INFO]: Epoch 061 - training loss: 0.3891, validation loss: 0.0270
2024-05-24 23:35:32 [INFO]: Epoch 062 - training loss: 0.3817, validation loss: 0.0265
2024-05-24 23:35:38 [INFO]: Epoch 063 - training loss: 0.3855, validation loss: 0.0273
2024-05-24 23:35:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:35:38 [INFO]: Finished training. The best model is from epoch#53.
2024-05-24 23:35:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/BRITS_ettm1/20240524_T232930/BRITS.pypots
2024-05-24 23:35:39 [INFO]: BRITS on ETTm1: MAE=0.1403, MSE=0.0549
2024-05-24 23:35:39 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-24 23:35:39 [INFO]: Using the given device: cuda:0
2024-05-24 23:35:39 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539
2024-05-24 23:35:39 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/tensorboard
2024-05-24 23:35:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:35:41 [INFO]: Epoch 001 - training loss: 1.4767, validation loss: 1.2732
2024-05-24 23:35:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch1_loss1.2731989324092865.pypots
2024-05-24 23:35:41 [INFO]: Epoch 002 - training loss: 1.0095, validation loss: 1.1501
2024-05-24 23:35:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch2_loss1.150068312883377.pypots
2024-05-24 23:35:42 [INFO]: Epoch 003 - training loss: 0.9372, validation loss: 1.0785
2024-05-24 23:35:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch3_loss1.0785433948040009.pypots
2024-05-24 23:35:42 [INFO]: Epoch 004 - training loss: 0.9282, validation loss: 1.0430
2024-05-24 23:35:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch4_loss1.042980745434761.pypots
2024-05-24 23:35:42 [INFO]: Epoch 005 - training loss: 0.8832, validation loss: 1.0304
2024-05-24 23:35:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch5_loss1.0304385274648666.pypots
2024-05-24 23:35:42 [INFO]: Epoch 006 - training loss: 0.8761, validation loss: 1.0098
2024-05-24 23:35:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch6_loss1.0097501277923584.pypots
2024-05-24 23:35:42 [INFO]: Epoch 007 - training loss: 0.8694, validation loss: 1.0024
2024-05-24 23:35:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch7_loss1.0024226903915405.pypots
2024-05-24 23:35:43 [INFO]: Epoch 008 - training loss: 0.8604, validation loss: 1.0012
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch8_loss1.0012023746967316.pypots
2024-05-24 23:35:43 [INFO]: Epoch 009 - training loss: 0.8631, validation loss: 0.9978
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch9_loss0.9977975785732269.pypots
2024-05-24 23:35:43 [INFO]: Epoch 010 - training loss: 0.8650, validation loss: 0.9923
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch10_loss0.9923251122236252.pypots
2024-05-24 23:35:43 [INFO]: Epoch 011 - training loss: 0.8910, validation loss: 0.9925
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch11_loss0.9925035387277603.pypots
2024-05-24 23:35:43 [INFO]: Epoch 012 - training loss: 0.8554, validation loss: 0.9886
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch12_loss0.9886439144611359.pypots
2024-05-24 23:35:43 [INFO]: Epoch 013 - training loss: 0.8507, validation loss: 0.9853
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch13_loss0.9852550327777863.pypots
2024-05-24 23:35:44 [INFO]: Epoch 014 - training loss: 0.8321, validation loss: 0.9844
2024-05-24 23:35:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch14_loss0.9843681901693344.pypots
2024-05-24 23:35:44 [INFO]: Epoch 015 - training loss: 0.8215, validation loss: 0.9840
2024-05-24 23:35:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch15_loss0.9839723706245422.pypots
2024-05-24 23:35:44 [INFO]: Epoch 016 - training loss: 0.7963, validation loss: 0.9784
2024-05-24 23:35:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch16_loss0.9783972799777985.pypots
2024-05-24 23:35:44 [INFO]: Epoch 017 - training loss: 0.8016, validation loss: 0.9773
2024-05-24 23:35:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch17_loss0.9773220121860504.pypots
2024-05-24 23:35:44 [INFO]: Epoch 018 - training loss: 0.8377, validation loss: 0.9781
2024-05-24 23:35:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch18_loss0.9780966639518738.pypots
2024-05-24 23:35:45 [INFO]: Epoch 019 - training loss: 0.7882, validation loss: 0.9764
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch19_loss0.9763737618923187.pypots
2024-05-24 23:35:45 [INFO]: Epoch 020 - training loss: 0.8027, validation loss: 0.9709
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch20_loss0.9708939790725708.pypots
2024-05-24 23:35:45 [INFO]: Epoch 021 - training loss: 0.7977, validation loss: 0.9697
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch21_loss0.9696860611438751.pypots
2024-05-24 23:35:45 [INFO]: Epoch 022 - training loss: 0.7987, validation loss: 0.9642
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch22_loss0.9641673713922501.pypots
2024-05-24 23:35:45 [INFO]: Epoch 023 - training loss: 0.8257, validation loss: 0.9596
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch23_loss0.9595645219087601.pypots
2024-05-24 23:35:45 [INFO]: Epoch 024 - training loss: 0.8373, validation loss: 0.9607
2024-05-24 23:35:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch24_loss0.9606938064098358.pypots
2024-05-24 23:35:46 [INFO]: Epoch 025 - training loss: 0.8442, validation loss: 0.9590
2024-05-24 23:35:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch25_loss0.9590440541505814.pypots
2024-05-24 23:35:46 [INFO]: Epoch 026 - training loss: 0.8157, validation loss: 0.9531
2024-05-24 23:35:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch26_loss0.9530901163816452.pypots
2024-05-24 23:35:46 [INFO]: Epoch 027 - training loss: 0.7820, validation loss: 0.9536
2024-05-24 23:35:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch27_loss0.9536273777484894.pypots
2024-05-24 23:35:46 [INFO]: Epoch 028 - training loss: 0.7807, validation loss: 0.9494
2024-05-24 23:35:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch28_loss0.949383407831192.pypots
2024-05-24 23:35:46 [INFO]: Epoch 029 - training loss: 0.7755, validation loss: 0.9484
2024-05-24 23:35:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch29_loss0.9483858346939087.pypots
2024-05-24 23:35:47 [INFO]: Epoch 030 - training loss: 0.7695, validation loss: 0.9482
2024-05-24 23:35:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch30_loss0.9481881111860275.pypots
2024-05-24 23:35:47 [INFO]: Epoch 031 - training loss: 0.7704, validation loss: 0.9434
2024-05-24 23:35:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch31_loss0.9434216171503067.pypots
2024-05-24 23:35:47 [INFO]: Epoch 032 - training loss: 0.7759, validation loss: 0.9427
2024-05-24 23:35:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch32_loss0.9426957219839096.pypots
2024-05-24 23:35:47 [INFO]: Epoch 033 - training loss: 0.7656, validation loss: 0.9415
2024-05-24 23:35:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch33_loss0.9414601475000381.pypots
2024-05-24 23:35:47 [INFO]: Epoch 034 - training loss: 0.7799, validation loss: 0.9376
2024-05-24 23:35:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch34_loss0.9376022219657898.pypots
2024-05-24 23:35:48 [INFO]: Epoch 035 - training loss: 0.7466, validation loss: 0.9301
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch35_loss0.930078774690628.pypots
2024-05-24 23:35:48 [INFO]: Epoch 036 - training loss: 0.7700, validation loss: 0.9287
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch36_loss0.9286554306745529.pypots
2024-05-24 23:35:48 [INFO]: Epoch 037 - training loss: 0.7711, validation loss: 0.9287
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch37_loss0.9287415444850922.pypots
2024-05-24 23:35:48 [INFO]: Epoch 038 - training loss: 0.7646, validation loss: 0.9276
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch38_loss0.9276003688573837.pypots
2024-05-24 23:35:48 [INFO]: Epoch 039 - training loss: 0.7655, validation loss: 0.9244
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch39_loss0.924384206533432.pypots
2024-05-24 23:35:48 [INFO]: Epoch 040 - training loss: 0.7632, validation loss: 0.9231
2024-05-24 23:35:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch40_loss0.9231452196836472.pypots
2024-05-24 23:35:49 [INFO]: Epoch 041 - training loss: 0.7391, validation loss: 0.9223
2024-05-24 23:35:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch41_loss0.9223139435052872.pypots
2024-05-24 23:35:49 [INFO]: Epoch 042 - training loss: 0.7395, validation loss: 0.9191
2024-05-24 23:35:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch42_loss0.9191131293773651.pypots
2024-05-24 23:35:49 [INFO]: Epoch 043 - training loss: 0.7596, validation loss: 0.9154
2024-05-24 23:35:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch43_loss0.9154150485992432.pypots
2024-05-24 23:35:49 [INFO]: Epoch 044 - training loss: 0.7672, validation loss: 0.9124
2024-05-24 23:35:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch44_loss0.9124114513397217.pypots
2024-05-24 23:35:49 [INFO]: Epoch 045 - training loss: 0.7463, validation loss: 0.9153
2024-05-24 23:35:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch45_loss0.9152781665325165.pypots
2024-05-24 23:35:50 [INFO]: Epoch 046 - training loss: 0.7636, validation loss: 0.9140
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch46_loss0.9140347242355347.pypots
2024-05-24 23:35:50 [INFO]: Epoch 047 - training loss: 0.7523, validation loss: 0.9090
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch47_loss0.9090109169483185.pypots
2024-05-24 23:35:50 [INFO]: Epoch 048 - training loss: 0.7575, validation loss: 0.9068
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch48_loss0.9068275392055511.pypots
2024-05-24 23:35:50 [INFO]: Epoch 049 - training loss: 0.7674, validation loss: 0.9080
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch49_loss0.9080065041780472.pypots
2024-05-24 23:35:50 [INFO]: Epoch 050 - training loss: 0.7470, validation loss: 0.9051
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch50_loss0.9051180332899094.pypots
2024-05-24 23:35:50 [INFO]: Epoch 051 - training loss: 0.7489, validation loss: 0.9033
2024-05-24 23:35:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch51_loss0.9033291041851044.pypots
2024-05-24 23:35:51 [INFO]: Epoch 052 - training loss: 0.7386, validation loss: 0.9027
2024-05-24 23:35:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch52_loss0.9026705622673035.pypots
2024-05-24 23:35:51 [INFO]: Epoch 053 - training loss: 0.7466, validation loss: 0.9058
2024-05-24 23:35:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch53_loss0.9058142602443695.pypots
2024-05-24 23:35:51 [INFO]: Epoch 054 - training loss: 0.7681, validation loss: 0.9046
2024-05-24 23:35:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch54_loss0.9045893847942352.pypots
2024-05-24 23:35:51 [INFO]: Epoch 055 - training loss: 0.7584, validation loss: 0.9005
2024-05-24 23:35:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch55_loss0.9005334377288818.pypots
2024-05-24 23:35:51 [INFO]: Epoch 056 - training loss: 0.7360, validation loss: 0.9017
2024-05-24 23:35:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch56_loss0.9016523063182831.pypots
2024-05-24 23:35:52 [INFO]: Epoch 057 - training loss: 0.7579, validation loss: 0.9001
2024-05-24 23:35:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch57_loss0.9001289904117584.pypots
2024-05-24 23:35:52 [INFO]: Epoch 058 - training loss: 0.7439, validation loss: 0.8974
2024-05-24 23:35:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch58_loss0.8974276632070541.pypots
2024-05-24 23:35:52 [INFO]: Epoch 059 - training loss: 0.7313, validation loss: 0.8967
2024-05-24 23:35:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch59_loss0.8966671526432037.pypots
2024-05-24 23:35:52 [INFO]: Epoch 060 - training loss: 0.7215, validation loss: 0.8917
2024-05-24 23:35:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch60_loss0.8917480558156967.pypots
2024-05-24 23:35:52 [INFO]: Epoch 061 - training loss: 0.7720, validation loss: 0.8904
2024-05-24 23:35:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch61_loss0.8904445618391037.pypots
2024-05-24 23:35:53 [INFO]: Epoch 062 - training loss: 0.7624, validation loss: 0.8957
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch62_loss0.8957430422306061.pypots
2024-05-24 23:35:53 [INFO]: Epoch 063 - training loss: 0.7343, validation loss: 0.8901
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch63_loss0.890080064535141.pypots
2024-05-24 23:35:53 [INFO]: Epoch 064 - training loss: 0.7438, validation loss: 0.8911
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch64_loss0.8910710513591766.pypots
2024-05-24 23:35:53 [INFO]: Epoch 065 - training loss: 0.7453, validation loss: 0.8899
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch65_loss0.8899365663528442.pypots
2024-05-24 23:35:53 [INFO]: Epoch 066 - training loss: 0.7521, validation loss: 0.8885
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch66_loss0.888538658618927.pypots
2024-05-24 23:35:53 [INFO]: Epoch 067 - training loss: 0.7550, validation loss: 0.8915
2024-05-24 23:35:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch67_loss0.8914936184883118.pypots
2024-05-24 23:35:54 [INFO]: Epoch 068 - training loss: 0.7932, validation loss: 0.8903
2024-05-24 23:35:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch68_loss0.8903118818998337.pypots
2024-05-24 23:35:54 [INFO]: Epoch 069 - training loss: 0.7469, validation loss: 0.8851
2024-05-24 23:35:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch69_loss0.8851242065429688.pypots
2024-05-24 23:35:54 [INFO]: Epoch 070 - training loss: 0.7330, validation loss: 0.8868
2024-05-24 23:35:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch70_loss0.8867758959531784.pypots
2024-05-24 23:35:54 [INFO]: Epoch 071 - training loss: 0.7302, validation loss: 0.8878
2024-05-24 23:35:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch71_loss0.8878335356712341.pypots
2024-05-24 23:35:54 [INFO]: Epoch 072 - training loss: 0.7412, validation loss: 0.8880
2024-05-24 23:35:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch72_loss0.8880392014980316.pypots
2024-05-24 23:35:55 [INFO]: Epoch 073 - training loss: 0.7415, validation loss: 0.8883
2024-05-24 23:35:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch73_loss0.888327345252037.pypots
2024-05-24 23:35:55 [INFO]: Epoch 074 - training loss: 0.7345, validation loss: 0.8846
2024-05-24 23:35:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch74_loss0.8845585882663727.pypots
2024-05-24 23:35:55 [INFO]: Epoch 075 - training loss: 0.7548, validation loss: 0.8851
2024-05-24 23:35:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch75_loss0.8850837498903275.pypots
2024-05-24 23:35:55 [INFO]: Epoch 076 - training loss: 0.7211, validation loss: 0.8863
2024-05-24 23:35:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch76_loss0.8863176107406616.pypots
2024-05-24 23:35:55 [INFO]: Epoch 077 - training loss: 0.7212, validation loss: 0.8870
2024-05-24 23:35:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch77_loss0.8869811594486237.pypots
2024-05-24 23:35:56 [INFO]: Epoch 078 - training loss: 0.7397, validation loss: 0.8843
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch78_loss0.8843193054199219.pypots
2024-05-24 23:35:56 [INFO]: Epoch 079 - training loss: 0.7074, validation loss: 0.8870
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch79_loss0.8870041072368622.pypots
2024-05-24 23:35:56 [INFO]: Epoch 080 - training loss: 0.7359, validation loss: 0.8821
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch80_loss0.8820590227842331.pypots
2024-05-24 23:35:56 [INFO]: Epoch 081 - training loss: 0.7174, validation loss: 0.8838
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch81_loss0.883784294128418.pypots
2024-05-24 23:35:56 [INFO]: Epoch 082 - training loss: 0.7413, validation loss: 0.8807
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch82_loss0.8806686699390411.pypots
2024-05-24 23:35:56 [INFO]: Epoch 083 - training loss: 0.7182, validation loss: 0.8791
2024-05-24 23:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch83_loss0.879068598151207.pypots
2024-05-24 23:35:57 [INFO]: Epoch 084 - training loss: 0.7487, validation loss: 0.8801
2024-05-24 23:35:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch84_loss0.8800970911979675.pypots
2024-05-24 23:35:57 [INFO]: Epoch 085 - training loss: 0.7357, validation loss: 0.8791
2024-05-24 23:35:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch85_loss0.8791026175022125.pypots
2024-05-24 23:35:57 [INFO]: Epoch 086 - training loss: 0.7346, validation loss: 0.8820
2024-05-24 23:35:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch86_loss0.8820256143808365.pypots
2024-05-24 23:35:57 [INFO]: Epoch 087 - training loss: 0.7386, validation loss: 0.8778
2024-05-24 23:35:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch87_loss0.8778227716684341.pypots
2024-05-24 23:35:57 [INFO]: Epoch 088 - training loss: 0.7412, validation loss: 0.8753
2024-05-24 23:35:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch88_loss0.8753360956907272.pypots
2024-05-24 23:35:58 [INFO]: Epoch 089 - training loss: 0.7541, validation loss: 0.8745
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch89_loss0.8744914084672928.pypots
2024-05-24 23:35:58 [INFO]: Epoch 090 - training loss: 0.7427, validation loss: 0.8752
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch90_loss0.8751604110002518.pypots
2024-05-24 23:35:58 [INFO]: Epoch 091 - training loss: 0.7269, validation loss: 0.8751
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch91_loss0.8751365840435028.pypots
2024-05-24 23:35:58 [INFO]: Epoch 092 - training loss: 0.7199, validation loss: 0.8740
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch92_loss0.8740179389715195.pypots
2024-05-24 23:35:58 [INFO]: Epoch 093 - training loss: 0.7661, validation loss: 0.8743
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch93_loss0.8742540329694748.pypots
2024-05-24 23:35:58 [INFO]: Epoch 094 - training loss: 0.7415, validation loss: 0.8727
2024-05-24 23:35:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch94_loss0.8727007508277893.pypots
2024-05-24 23:35:59 [INFO]: Epoch 095 - training loss: 0.7344, validation loss: 0.8696
2024-05-24 23:35:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch95_loss0.8695809245109558.pypots
2024-05-24 23:35:59 [INFO]: Epoch 096 - training loss: 0.7441, validation loss: 0.8684
2024-05-24 23:35:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch96_loss0.8683638274669647.pypots
2024-05-24 23:35:59 [INFO]: Epoch 097 - training loss: 0.7224, validation loss: 0.8688
2024-05-24 23:35:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch97_loss0.8688406348228455.pypots
2024-05-24 23:35:59 [INFO]: Epoch 098 - training loss: 0.7248, validation loss: 0.8668
2024-05-24 23:35:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch98_loss0.866797149181366.pypots
2024-05-24 23:35:59 [INFO]: Epoch 099 - training loss: 0.7589, validation loss: 0.8699
2024-05-24 23:35:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch99_loss0.8698571622371674.pypots
2024-05-24 23:36:00 [INFO]: Epoch 100 - training loss: 0.7306, validation loss: 0.8656
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch100_loss0.8656238168478012.pypots
2024-05-24 23:36:00 [INFO]: Epoch 101 - training loss: 0.7337, validation loss: 0.8701
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch101_loss0.8701385408639908.pypots
2024-05-24 23:36:00 [INFO]: Epoch 102 - training loss: 0.7144, validation loss: 0.8656
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch102_loss0.8656233698129654.pypots
2024-05-24 23:36:00 [INFO]: Epoch 103 - training loss: 0.7308, validation loss: 0.8669
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch103_loss0.8668598234653473.pypots
2024-05-24 23:36:00 [INFO]: Epoch 104 - training loss: 0.7436, validation loss: 0.8649
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch104_loss0.8648800849914551.pypots
2024-05-24 23:36:01 [INFO]: Epoch 105 - training loss: 0.7401, validation loss: 0.8666
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch105_loss0.866607278585434.pypots
2024-05-24 23:36:01 [INFO]: Epoch 106 - training loss: 0.7340, validation loss: 0.8661
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch106_loss0.8660929650068283.pypots
2024-05-24 23:36:01 [INFO]: Epoch 107 - training loss: 0.7282, validation loss: 0.8639
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch107_loss0.8638908416032791.pypots
2024-05-24 23:36:01 [INFO]: Epoch 108 - training loss: 0.7126, validation loss: 0.8619
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch108_loss0.8618516325950623.pypots
2024-05-24 23:36:01 [INFO]: Epoch 109 - training loss: 0.7626, validation loss: 0.8632
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch109_loss0.8631554543972015.pypots
2024-05-24 23:36:01 [INFO]: Epoch 110 - training loss: 0.7292, validation loss: 0.8570
2024-05-24 23:36:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch110_loss0.85700723528862.pypots
2024-05-24 23:36:02 [INFO]: Epoch 111 - training loss: 0.7255, validation loss: 0.8572
2024-05-24 23:36:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch111_loss0.8572106659412384.pypots
2024-05-24 23:36:02 [INFO]: Epoch 112 - training loss: 0.7215, validation loss: 0.8595
2024-05-24 23:36:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch112_loss0.8595020920038223.pypots
2024-05-24 23:36:02 [INFO]: Epoch 113 - training loss: 0.7270, validation loss: 0.8556
2024-05-24 23:36:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch113_loss0.8556486070156097.pypots
2024-05-24 23:36:02 [INFO]: Epoch 114 - training loss: 0.7262, validation loss: 0.8574
2024-05-24 23:36:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch114_loss0.8573850095272064.pypots
2024-05-24 23:36:02 [INFO]: Epoch 115 - training loss: 0.7157, validation loss: 0.8548
2024-05-24 23:36:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch115_loss0.8548113405704498.pypots
2024-05-24 23:36:03 [INFO]: Epoch 116 - training loss: 0.7460, validation loss: 0.8545
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch116_loss0.8544532656669617.pypots
2024-05-24 23:36:03 [INFO]: Epoch 117 - training loss: 0.7164, validation loss: 0.8543
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch117_loss0.8542549312114716.pypots
2024-05-24 23:36:03 [INFO]: Epoch 118 - training loss: 0.7135, validation loss: 0.8540
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch118_loss0.8540166914463043.pypots
2024-05-24 23:36:03 [INFO]: Epoch 119 - training loss: 0.7217, validation loss: 0.8551
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch119_loss0.8551015108823776.pypots
2024-05-24 23:36:03 [INFO]: Epoch 120 - training loss: 0.7392, validation loss: 0.8506
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch120_loss0.8505834490060806.pypots
2024-05-24 23:36:03 [INFO]: Epoch 121 - training loss: 0.7594, validation loss: 0.8506
2024-05-24 23:36:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch121_loss0.850565642118454.pypots
2024-05-24 23:36:04 [INFO]: Epoch 122 - training loss: 0.7071, validation loss: 0.8516
2024-05-24 23:36:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch122_loss0.85161392390728.pypots
2024-05-24 23:36:04 [INFO]: Epoch 123 - training loss: 0.7305, validation loss: 0.8521
2024-05-24 23:36:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch123_loss0.852133184671402.pypots
2024-05-24 23:36:04 [INFO]: Epoch 124 - training loss: 0.7232, validation loss: 0.8471
2024-05-24 23:36:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch124_loss0.8470599949359894.pypots
2024-05-24 23:36:04 [INFO]: Epoch 125 - training loss: 0.7359, validation loss: 0.8476
2024-05-24 23:36:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch125_loss0.8476412147283554.pypots
2024-05-24 23:36:04 [INFO]: Epoch 126 - training loss: 0.7170, validation loss: 0.8483
2024-05-24 23:36:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch126_loss0.8483193665742874.pypots
2024-05-24 23:36:05 [INFO]: Epoch 127 - training loss: 0.7569, validation loss: 0.8459
2024-05-24 23:36:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch127_loss0.8458552956581116.pypots
2024-05-24 23:36:05 [INFO]: Epoch 128 - training loss: 0.7285, validation loss: 0.8411
2024-05-24 23:36:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch128_loss0.8410571068525314.pypots
2024-05-24 23:36:05 [INFO]: Epoch 129 - training loss: 0.7260, validation loss: 0.8429
2024-05-24 23:36:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch129_loss0.8428735285997391.pypots
2024-05-24 23:36:05 [INFO]: Epoch 130 - training loss: 0.7195, validation loss: 0.8432
2024-05-24 23:36:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch130_loss0.843229204416275.pypots
2024-05-24 23:36:05 [INFO]: Epoch 131 - training loss: 0.7392, validation loss: 0.8409
2024-05-24 23:36:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch131_loss0.8409106880426407.pypots
2024-05-24 23:36:06 [INFO]: Epoch 132 - training loss: 0.7018, validation loss: 0.8394
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch132_loss0.8394348472356796.pypots
2024-05-24 23:36:06 [INFO]: Epoch 133 - training loss: 0.7279, validation loss: 0.8403
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch133_loss0.840276226401329.pypots
2024-05-24 23:36:06 [INFO]: Epoch 134 - training loss: 0.7351, validation loss: 0.8387
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch134_loss0.838678166270256.pypots
2024-05-24 23:36:06 [INFO]: Epoch 135 - training loss: 0.7279, validation loss: 0.8380
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch135_loss0.837964728474617.pypots
2024-05-24 23:36:06 [INFO]: Epoch 136 - training loss: 0.7122, validation loss: 0.8364
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch136_loss0.8363908231258392.pypots
2024-05-24 23:36:06 [INFO]: Epoch 137 - training loss: 0.7309, validation loss: 0.8372
2024-05-24 23:36:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch137_loss0.8371794372797012.pypots
2024-05-24 23:36:07 [INFO]: Epoch 138 - training loss: 0.7185, validation loss: 0.8326
2024-05-24 23:36:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch138_loss0.8325857669115067.pypots
2024-05-24 23:36:07 [INFO]: Epoch 139 - training loss: 0.7405, validation loss: 0.8336
2024-05-24 23:36:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch139_loss0.8336337506771088.pypots
2024-05-24 23:36:07 [INFO]: Epoch 140 - training loss: 0.7197, validation loss: 0.8340
2024-05-24 23:36:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch140_loss0.8339948356151581.pypots
2024-05-24 23:36:07 [INFO]: Epoch 141 - training loss: 0.7381, validation loss: 0.8326
2024-05-24 23:36:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch141_loss0.8325754404067993.pypots
2024-05-24 23:36:07 [INFO]: Epoch 142 - training loss: 0.7347, validation loss: 0.8325
2024-05-24 23:36:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch142_loss0.8324524909257889.pypots
2024-05-24 23:36:08 [INFO]: Epoch 143 - training loss: 0.7359, validation loss: 0.8314
2024-05-24 23:36:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch143_loss0.8313600122928619.pypots
2024-05-24 23:36:08 [INFO]: Epoch 144 - training loss: 0.7227, validation loss: 0.8332
2024-05-24 23:36:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch144_loss0.833241656422615.pypots
2024-05-24 23:36:08 [INFO]: Epoch 145 - training loss: 0.7016, validation loss: 0.8283
2024-05-24 23:36:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch145_loss0.8283354341983795.pypots
2024-05-24 23:36:08 [INFO]: Epoch 146 - training loss: 0.7229, validation loss: 0.8340
2024-05-24 23:36:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch146_loss0.8339913636445999.pypots
2024-05-24 23:36:08 [INFO]: Epoch 147 - training loss: 0.7130, validation loss: 0.8288
2024-05-24 23:36:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch147_loss0.8287782967090607.pypots
2024-05-24 23:36:09 [INFO]: Epoch 148 - training loss: 0.7226, validation loss: 0.8291
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch148_loss0.8290531635284424.pypots
2024-05-24 23:36:09 [INFO]: Epoch 149 - training loss: 0.7388, validation loss: 0.8286
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch149_loss0.8286246806383133.pypots
2024-05-24 23:36:09 [INFO]: Epoch 150 - training loss: 0.7002, validation loss: 0.8279
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch150_loss0.8279428631067276.pypots
2024-05-24 23:36:09 [INFO]: Epoch 151 - training loss: 0.7178, validation loss: 0.8289
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch151_loss0.828862726688385.pypots
2024-05-24 23:36:09 [INFO]: Epoch 152 - training loss: 0.7318, validation loss: 0.8265
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch152_loss0.826454684138298.pypots
2024-05-24 23:36:09 [INFO]: Epoch 153 - training loss: 0.7046, validation loss: 0.8250
2024-05-24 23:36:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch153_loss0.8249828219413757.pypots
2024-05-24 23:36:10 [INFO]: Epoch 154 - training loss: 0.7164, validation loss: 0.8241
2024-05-24 23:36:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch154_loss0.8241487592458725.pypots
2024-05-24 23:36:10 [INFO]: Epoch 155 - training loss: 0.7127, validation loss: 0.8243
2024-05-24 23:36:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch155_loss0.82432059943676.pypots
2024-05-24 23:36:10 [INFO]: Epoch 156 - training loss: 0.7323, validation loss: 0.8231
2024-05-24 23:36:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch156_loss0.8231200128793716.pypots
2024-05-24 23:36:10 [INFO]: Epoch 157 - training loss: 0.7144, validation loss: 0.8237
2024-05-24 23:36:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch157_loss0.8237016797065735.pypots
2024-05-24 23:36:10 [INFO]: Epoch 158 - training loss: 0.7307, validation loss: 0.8256
2024-05-24 23:36:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch158_loss0.8255886882543564.pypots
2024-05-24 23:36:11 [INFO]: Epoch 159 - training loss: 0.7218, validation loss: 0.8218
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch159_loss0.8218269348144531.pypots
2024-05-24 23:36:11 [INFO]: Epoch 160 - training loss: 0.7161, validation loss: 0.8220
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch160_loss0.8220016360282898.pypots
2024-05-24 23:36:11 [INFO]: Epoch 161 - training loss: 0.7206, validation loss: 0.8247
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch161_loss0.8246782571077347.pypots
2024-05-24 23:36:11 [INFO]: Epoch 162 - training loss: 0.7211, validation loss: 0.8204
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch162_loss0.8203913420438766.pypots
2024-05-24 23:36:11 [INFO]: Epoch 163 - training loss: 0.7338, validation loss: 0.8190
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch163_loss0.8190356642007828.pypots
2024-05-24 23:36:11 [INFO]: Epoch 164 - training loss: 0.7331, validation loss: 0.8175
2024-05-24 23:36:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch164_loss0.8175217658281326.pypots
2024-05-24 23:36:12 [INFO]: Epoch 165 - training loss: 0.7175, validation loss: 0.8207
2024-05-24 23:36:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch165_loss0.8206530511379242.pypots
2024-05-24 23:36:12 [INFO]: Epoch 166 - training loss: 0.7246, validation loss: 0.8205
2024-05-24 23:36:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch166_loss0.8205115497112274.pypots
2024-05-24 23:36:12 [INFO]: Epoch 167 - training loss: 0.7422, validation loss: 0.8171
2024-05-24 23:36:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch167_loss0.8170716166496277.pypots
2024-05-24 23:36:12 [INFO]: Epoch 168 - training loss: 0.7328, validation loss: 0.8151
2024-05-24 23:36:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch168_loss0.8151213973760605.pypots
2024-05-24 23:36:12 [INFO]: Epoch 169 - training loss: 0.7239, validation loss: 0.8135
2024-05-24 23:36:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch169_loss0.8135303407907486.pypots
2024-05-24 23:36:13 [INFO]: Epoch 170 - training loss: 0.7209, validation loss: 0.8166
2024-05-24 23:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch170_loss0.8165668845176697.pypots
2024-05-24 23:36:13 [INFO]: Epoch 171 - training loss: 0.7283, validation loss: 0.8148
2024-05-24 23:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch171_loss0.8147930651903152.pypots
2024-05-24 23:36:13 [INFO]: Epoch 172 - training loss: 0.7194, validation loss: 0.8150
2024-05-24 23:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch172_loss0.814993143081665.pypots
2024-05-24 23:36:13 [INFO]: Epoch 173 - training loss: 0.7177, validation loss: 0.8172
2024-05-24 23:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch173_loss0.8171848654747009.pypots
2024-05-24 23:36:13 [INFO]: Epoch 174 - training loss: 0.7345, validation loss: 0.8171
2024-05-24 23:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch174_loss0.8171386420726776.pypots
2024-05-24 23:36:14 [INFO]: Epoch 175 - training loss: 0.7048, validation loss: 0.8145
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch175_loss0.8144976794719696.pypots
2024-05-24 23:36:14 [INFO]: Epoch 176 - training loss: 0.7273, validation loss: 0.8146
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch176_loss0.8145736455917358.pypots
2024-05-24 23:36:14 [INFO]: Epoch 177 - training loss: 0.7229, validation loss: 0.8155
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch177_loss0.8155321925878525.pypots
2024-05-24 23:36:14 [INFO]: Epoch 178 - training loss: 0.7446, validation loss: 0.8114
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch178_loss0.8114048987627029.pypots
2024-05-24 23:36:14 [INFO]: Epoch 179 - training loss: 0.7576, validation loss: 0.8080
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch179_loss0.8079600036144257.pypots
2024-05-24 23:36:14 [INFO]: Epoch 180 - training loss: 0.7269, validation loss: 0.8134
2024-05-24 23:36:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch180_loss0.8134415596723557.pypots
2024-05-24 23:36:15 [INFO]: Epoch 181 - training loss: 0.7494, validation loss: 0.8099
2024-05-24 23:36:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch181_loss0.8098752647638321.pypots
2024-05-24 23:36:15 [INFO]: Epoch 182 - training loss: 0.7195, validation loss: 0.8116
2024-05-24 23:36:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch182_loss0.8115857541561127.pypots
2024-05-24 23:36:15 [INFO]: Epoch 183 - training loss: 0.7134, validation loss: 0.8093
2024-05-24 23:36:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch183_loss0.8092613965272903.pypots
2024-05-24 23:36:15 [INFO]: Epoch 184 - training loss: 0.7148, validation loss: 0.8102
2024-05-24 23:36:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch184_loss0.8101591467857361.pypots
2024-05-24 23:36:15 [INFO]: Epoch 185 - training loss: 0.7190, validation loss: 0.8108
2024-05-24 23:36:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch185_loss0.8108368813991547.pypots
2024-05-24 23:36:16 [INFO]: Epoch 186 - training loss: 0.7012, validation loss: 0.8106
2024-05-24 23:36:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch186_loss0.8106028735637665.pypots
2024-05-24 23:36:16 [INFO]: Epoch 187 - training loss: 0.7402, validation loss: 0.8119
2024-05-24 23:36:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch187_loss0.8119384199380875.pypots
2024-05-24 23:36:16 [INFO]: Epoch 188 - training loss: 0.7144, validation loss: 0.8088
2024-05-24 23:36:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch188_loss0.8087757229804993.pypots
2024-05-24 23:36:16 [INFO]: Epoch 189 - training loss: 0.6986, validation loss: 0.8110
2024-05-24 23:36:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN_epoch189_loss0.8109520226716995.pypots
2024-05-24 23:36:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:36:16 [INFO]: Finished training. The best model is from epoch#179.
2024-05-24 23:36:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_ettm1/20240524_T233539/MRNN.pypots
2024-05-24 23:36:16 [INFO]: MRNN on ETTm1: MAE=0.6324, MSE=1.1212
2024-05-24 23:36:16 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-24 23:36:16 [INFO]: Using the given device: cpu
2024-05-24 23:36:16 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-24 23:36:16 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-24 23:36:16 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-24 23:36:16 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-24 23:36:16 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-24 23:36:16 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-24 23:36:16 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-24 23:36:16 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-24 23:36:16 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-24 23:36:17 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 23:36:17 [INFO]: Using the given device: cuda:0
2024-05-24 23:36:17 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T233617
2024-05-24 23:36:17 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T233617/tensorboard
2024-05-24 23:36:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:36:17 [INFO]: Epoch 001 - training loss: 1.1594, validation loss: 0.2946
2024-05-24 23:36:18 [INFO]: Epoch 002 - training loss: 0.8709, validation loss: 0.1555
2024-05-24 23:36:18 [INFO]: Epoch 003 - training loss: 0.7797, validation loss: 0.1308
2024-05-24 23:36:19 [INFO]: Epoch 004 - training loss: 0.7146, validation loss: 0.0903
2024-05-24 23:36:19 [INFO]: Epoch 005 - training loss: 0.6855, validation loss: 0.0848
2024-05-24 23:36:20 [INFO]: Epoch 006 - training loss: 0.6717, validation loss: 0.0775
2024-05-24 23:36:20 [INFO]: Epoch 007 - training loss: 0.6538, validation loss: 0.0818
2024-05-24 23:36:21 [INFO]: Epoch 008 - training loss: 0.6241, validation loss: 0.0878
2024-05-24 23:36:21 [INFO]: Epoch 009 - training loss: 0.6056, validation loss: 0.0682
2024-05-24 23:36:22 [INFO]: Epoch 010 - training loss: 0.5893, validation loss: 0.0638
2024-05-24 23:36:22 [INFO]: Epoch 011 - training loss: 0.5754, validation loss: 0.0655
2024-05-24 23:36:23 [INFO]: Epoch 012 - training loss: 0.5794, validation loss: 0.0734
2024-05-24 23:36:23 [INFO]: Epoch 013 - training loss: 0.5638, validation loss: 0.0686
2024-05-24 23:36:24 [INFO]: Epoch 014 - training loss: 0.5493, validation loss: 0.0720
2024-05-24 23:36:24 [INFO]: Epoch 015 - training loss: 0.5533, validation loss: 0.0649
2024-05-24 23:36:25 [INFO]: Epoch 016 - training loss: 0.5382, validation loss: 0.0592
2024-05-24 23:36:25 [INFO]: Epoch 017 - training loss: 0.5217, validation loss: 0.0670
2024-05-24 23:36:26 [INFO]: Epoch 018 - training loss: 0.5208, validation loss: 0.0621
2024-05-24 23:36:26 [INFO]: Epoch 019 - training loss: 0.5155, validation loss: 0.0540
2024-05-24 23:36:27 [INFO]: Epoch 020 - training loss: 0.5023, validation loss: 0.0580
2024-05-24 23:36:27 [INFO]: Epoch 021 - training loss: 0.4981, validation loss: 0.0526
2024-05-24 23:36:28 [INFO]: Epoch 022 - training loss: 0.4946, validation loss: 0.0556
2024-05-24 23:36:28 [INFO]: Epoch 023 - training loss: 0.5056, validation loss: 0.0576
2024-05-24 23:36:29 [INFO]: Epoch 024 - training loss: 0.4857, validation loss: 0.0765
2024-05-24 23:36:29 [INFO]: Epoch 025 - training loss: 0.4854, validation loss: 0.0622
2024-05-24 23:36:30 [INFO]: Epoch 026 - training loss: 0.5050, validation loss: 0.0511
2024-05-24 23:36:30 [INFO]: Epoch 027 - training loss: 0.4785, validation loss: 0.0545
2024-05-24 23:36:31 [INFO]: Epoch 028 - training loss: 0.4767, validation loss: 0.0607
2024-05-24 23:36:31 [INFO]: Epoch 029 - training loss: 0.4593, validation loss: 0.0433
2024-05-24 23:36:32 [INFO]: Epoch 030 - training loss: 0.4694, validation loss: 0.0435
2024-05-24 23:36:32 [INFO]: Epoch 031 - training loss: 0.4479, validation loss: 0.0419
2024-05-24 23:36:33 [INFO]: Epoch 032 - training loss: 0.4379, validation loss: 0.0396
2024-05-24 23:36:33 [INFO]: Epoch 033 - training loss: 0.4406, validation loss: 0.0494
2024-05-24 23:36:34 [INFO]: Epoch 034 - training loss: 0.4404, validation loss: 0.0483
2024-05-24 23:36:34 [INFO]: Epoch 035 - training loss: 0.4333, validation loss: 0.0429
2024-05-24 23:36:35 [INFO]: Epoch 036 - training loss: 0.4300, validation loss: 0.0554
2024-05-24 23:36:35 [INFO]: Epoch 037 - training loss: 0.4199, validation loss: 0.0470
2024-05-24 23:36:36 [INFO]: Epoch 038 - training loss: 0.4184, validation loss: 0.0411
2024-05-24 23:36:36 [INFO]: Epoch 039 - training loss: 0.4165, validation loss: 0.0484
2024-05-24 23:36:37 [INFO]: Epoch 040 - training loss: 0.4053, validation loss: 0.0387
2024-05-24 23:36:38 [INFO]: Epoch 041 - training loss: 0.4129, validation loss: 0.0453
2024-05-24 23:36:38 [INFO]: Epoch 042 - training loss: 0.4174, validation loss: 0.0630
2024-05-24 23:36:39 [INFO]: Epoch 043 - training loss: 0.3997, validation loss: 0.0464
2024-05-24 23:36:39 [INFO]: Epoch 044 - training loss: 0.4022, validation loss: 0.0370
2024-05-24 23:36:40 [INFO]: Epoch 045 - training loss: 0.3761, validation loss: 0.0377
2024-05-24 23:36:40 [INFO]: Epoch 046 - training loss: 0.3757, validation loss: 0.0426
2024-05-24 23:36:41 [INFO]: Epoch 047 - training loss: 0.3677, validation loss: 0.0374
2024-05-24 23:36:41 [INFO]: Epoch 048 - training loss: 0.3831, validation loss: 0.0381
2024-05-24 23:36:42 [INFO]: Epoch 049 - training loss: 0.3697, validation loss: 0.0356
2024-05-24 23:36:42 [INFO]: Epoch 050 - training loss: 0.3631, validation loss: 0.0424
2024-05-24 23:36:43 [INFO]: Epoch 051 - training loss: 0.3699, validation loss: 0.0337
2024-05-24 23:36:43 [INFO]: Epoch 052 - training loss: 0.3568, validation loss: 0.0342
2024-05-24 23:36:44 [INFO]: Epoch 053 - training loss: 0.3544, validation loss: 0.0374
2024-05-24 23:36:44 [INFO]: Epoch 054 - training loss: 0.3398, validation loss: 0.0334
2024-05-24 23:36:45 [INFO]: Epoch 055 - training loss: 0.3448, validation loss: 0.0431
2024-05-24 23:36:45 [INFO]: Epoch 056 - training loss: 0.3290, validation loss: 0.0444
2024-05-24 23:36:46 [INFO]: Epoch 057 - training loss: 0.3279, validation loss: 0.0369
2024-05-24 23:36:46 [INFO]: Epoch 058 - training loss: 0.3207, validation loss: 0.0319
2024-05-24 23:36:47 [INFO]: Epoch 059 - training loss: 0.3090, validation loss: 0.0372
2024-05-24 23:36:47 [INFO]: Epoch 060 - training loss: 0.3048, validation loss: 0.0466
2024-05-24 23:36:48 [INFO]: Epoch 061 - training loss: 0.3067, validation loss: 0.0382
2024-05-24 23:36:48 [INFO]: Epoch 062 - training loss: 0.3027, validation loss: 0.0304
2024-05-24 23:36:49 [INFO]: Epoch 063 - training loss: 0.2975, validation loss: 0.0422
2024-05-24 23:36:49 [INFO]: Epoch 064 - training loss: 0.3106, validation loss: 0.0589
2024-05-24 23:36:50 [INFO]: Epoch 065 - training loss: 0.3164, validation loss: 0.0322
2024-05-24 23:36:50 [INFO]: Epoch 066 - training loss: 0.2977, validation loss: 0.0321
2024-05-24 23:36:51 [INFO]: Epoch 067 - training loss: 0.2912, validation loss: 0.0343
2024-05-24 23:36:51 [INFO]: Epoch 068 - training loss: 0.2904, validation loss: 0.0379
2024-05-24 23:36:52 [INFO]: Epoch 069 - training loss: 0.2931, validation loss: 0.0341
2024-05-24 23:36:52 [INFO]: Epoch 070 - training loss: 0.2949, validation loss: 0.0321
2024-05-24 23:36:53 [INFO]: Epoch 071 - training loss: 0.2811, validation loss: 0.0418
2024-05-24 23:36:53 [INFO]: Epoch 072 - training loss: 0.2781, validation loss: 0.0307
2024-05-24 23:36:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:36:53 [INFO]: Finished training. The best model is from epoch#62.
2024-05-24 23:36:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/SAITS_ettm1/20240524_T233617/SAITS.pypots
2024-05-24 23:36:53 [INFO]: SAITS on ETTm1: MAE=0.1325, MSE=0.0348
2024-05-24 23:36:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-24 23:36:53 [INFO]: Using the given device: cuda:0
2024-05-24 23:36:53 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T233653
2024-05-24 23:36:53 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T233653/tensorboard
2024-05-24 23:36:53 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:36:54 [INFO]: Epoch 001 - training loss: 1.3791, validation loss: 0.3942
2024-05-24 23:36:54 [INFO]: Epoch 002 - training loss: 0.7824, validation loss: 0.1899
2024-05-24 23:36:54 [INFO]: Epoch 003 - training loss: 0.6716, validation loss: 0.1442
2024-05-24 23:36:54 [INFO]: Epoch 004 - training loss: 0.5892, validation loss: 0.1141
2024-05-24 23:36:55 [INFO]: Epoch 005 - training loss: 0.5230, validation loss: 0.0900
2024-05-24 23:36:55 [INFO]: Epoch 006 - training loss: 0.4914, validation loss: 0.0809
2024-05-24 23:36:55 [INFO]: Epoch 007 - training loss: 0.4679, validation loss: 0.0747
2024-05-24 23:36:55 [INFO]: Epoch 008 - training loss: 0.4509, validation loss: 0.0724
2024-05-24 23:36:55 [INFO]: Epoch 009 - training loss: 0.4322, validation loss: 0.0653
2024-05-24 23:36:56 [INFO]: Epoch 010 - training loss: 0.4189, validation loss: 0.0649
2024-05-24 23:36:56 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.0580
2024-05-24 23:36:56 [INFO]: Epoch 012 - training loss: 0.4004, validation loss: 0.0571
2024-05-24 23:36:56 [INFO]: Epoch 013 - training loss: 0.3880, validation loss: 0.0570
2024-05-24 23:36:56 [INFO]: Epoch 014 - training loss: 0.3772, validation loss: 0.0553
2024-05-24 23:36:57 [INFO]: Epoch 015 - training loss: 0.3807, validation loss: 0.0527
2024-05-24 23:36:57 [INFO]: Epoch 016 - training loss: 0.3679, validation loss: 0.0559
2024-05-24 23:36:57 [INFO]: Epoch 017 - training loss: 0.3677, validation loss: 0.0475
2024-05-24 23:36:57 [INFO]: Epoch 018 - training loss: 0.3555, validation loss: 0.0472
2024-05-24 23:36:58 [INFO]: Epoch 019 - training loss: 0.3525, validation loss: 0.0471
2024-05-24 23:36:58 [INFO]: Epoch 020 - training loss: 0.3434, validation loss: 0.0479
2024-05-24 23:36:58 [INFO]: Epoch 021 - training loss: 0.3388, validation loss: 0.0494
2024-05-24 23:36:58 [INFO]: Epoch 022 - training loss: 0.3297, validation loss: 0.0437
2024-05-24 23:36:58 [INFO]: Epoch 023 - training loss: 0.3299, validation loss: 0.0440
2024-05-24 23:36:59 [INFO]: Epoch 024 - training loss: 0.3231, validation loss: 0.0465
2024-05-24 23:36:59 [INFO]: Epoch 025 - training loss: 0.3224, validation loss: 0.0436
2024-05-24 23:36:59 [INFO]: Epoch 026 - training loss: 0.3157, validation loss: 0.0405
2024-05-24 23:36:59 [INFO]: Epoch 027 - training loss: 0.3068, validation loss: 0.0443
2024-05-24 23:36:59 [INFO]: Epoch 028 - training loss: 0.3093, validation loss: 0.0409
2024-05-24 23:37:00 [INFO]: Epoch 029 - training loss: 0.3038, validation loss: 0.0383
2024-05-24 23:37:00 [INFO]: Epoch 030 - training loss: 0.2989, validation loss: 0.0391
2024-05-24 23:37:00 [INFO]: Epoch 031 - training loss: 0.2964, validation loss: 0.0427
2024-05-24 23:37:00 [INFO]: Epoch 032 - training loss: 0.3108, validation loss: 0.0431
2024-05-24 23:37:01 [INFO]: Epoch 033 - training loss: 0.2995, validation loss: 0.0386
2024-05-24 23:37:01 [INFO]: Epoch 034 - training loss: 0.2930, validation loss: 0.0366
2024-05-24 23:37:01 [INFO]: Epoch 035 - training loss: 0.2881, validation loss: 0.0425
2024-05-24 23:37:01 [INFO]: Epoch 036 - training loss: 0.2934, validation loss: 0.0390
2024-05-24 23:37:01 [INFO]: Epoch 037 - training loss: 0.2839, validation loss: 0.0386
2024-05-24 23:37:02 [INFO]: Epoch 038 - training loss: 0.2860, validation loss: 0.0391
2024-05-24 23:37:02 [INFO]: Epoch 039 - training loss: 0.2858, validation loss: 0.0348
2024-05-24 23:37:02 [INFO]: Epoch 040 - training loss: 0.2701, validation loss: 0.0366
2024-05-24 23:37:02 [INFO]: Epoch 041 - training loss: 0.2713, validation loss: 0.0322
2024-05-24 23:37:03 [INFO]: Epoch 042 - training loss: 0.2681, validation loss: 0.0319
2024-05-24 23:37:03 [INFO]: Epoch 043 - training loss: 0.2676, validation loss: 0.0332
2024-05-24 23:37:03 [INFO]: Epoch 044 - training loss: 0.2660, validation loss: 0.0381
2024-05-24 23:37:03 [INFO]: Epoch 045 - training loss: 0.2655, validation loss: 0.0360
2024-05-24 23:37:03 [INFO]: Epoch 046 - training loss: 0.2587, validation loss: 0.0324
2024-05-24 23:37:04 [INFO]: Epoch 047 - training loss: 0.2595, validation loss: 0.0336
2024-05-24 23:37:04 [INFO]: Epoch 048 - training loss: 0.2547, validation loss: 0.0337
2024-05-24 23:37:04 [INFO]: Epoch 049 - training loss: 0.2509, validation loss: 0.0342
2024-05-24 23:37:04 [INFO]: Epoch 050 - training loss: 0.2533, validation loss: 0.0293
2024-05-24 23:37:04 [INFO]: Epoch 051 - training loss: 0.2507, validation loss: 0.0321
2024-05-24 23:37:05 [INFO]: Epoch 052 - training loss: 0.2491, validation loss: 0.0304
2024-05-24 23:37:05 [INFO]: Epoch 053 - training loss: 0.2440, validation loss: 0.0305
2024-05-24 23:37:05 [INFO]: Epoch 054 - training loss: 0.2500, validation loss: 0.0290
2024-05-24 23:37:05 [INFO]: Epoch 055 - training loss: 0.2453, validation loss: 0.0304
2024-05-24 23:37:06 [INFO]: Epoch 056 - training loss: 0.2504, validation loss: 0.0287
2024-05-24 23:37:06 [INFO]: Epoch 057 - training loss: 0.2425, validation loss: 0.0300
2024-05-24 23:37:06 [INFO]: Epoch 058 - training loss: 0.2351, validation loss: 0.0273
2024-05-24 23:37:06 [INFO]: Epoch 059 - training loss: 0.2340, validation loss: 0.0279
2024-05-24 23:37:06 [INFO]: Epoch 060 - training loss: 0.2318, validation loss: 0.0298
2024-05-24 23:37:07 [INFO]: Epoch 061 - training loss: 0.2316, validation loss: 0.0279
2024-05-24 23:37:07 [INFO]: Epoch 062 - training loss: 0.2328, validation loss: 0.0281
2024-05-24 23:37:07 [INFO]: Epoch 063 - training loss: 0.2317, validation loss: 0.0443
2024-05-24 23:37:07 [INFO]: Epoch 064 - training loss: 0.2563, validation loss: 0.0334
2024-05-24 23:37:08 [INFO]: Epoch 065 - training loss: 0.2443, validation loss: 0.0280
2024-05-24 23:37:08 [INFO]: Epoch 066 - training loss: 0.2353, validation loss: 0.0278
2024-05-24 23:37:08 [INFO]: Epoch 067 - training loss: 0.2319, validation loss: 0.0326
2024-05-24 23:37:08 [INFO]: Epoch 068 - training loss: 0.2351, validation loss: 0.0283
2024-05-24 23:37:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:37:08 [INFO]: Finished training. The best model is from epoch#58.
2024-05-24 23:37:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/Transformer_ettm1/20240524_T233653/Transformer.pypots
2024-05-24 23:37:08 [INFO]: Transformer on ETTm1: MAE=0.1520, MSE=0.0427
2024-05-24 23:37:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-24 23:37:08 [INFO]: Using the given device: cuda:0
2024-05-24 23:37:08 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T233708
2024-05-24 23:37:08 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T233708/tensorboard
2024-05-24 23:37:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:37:09 [INFO]: Epoch 001 - training loss: 0.1599, validation loss: 0.0558
2024-05-24 23:37:09 [INFO]: Epoch 002 - training loss: 0.0697, validation loss: 0.0404
2024-05-24 23:37:09 [INFO]: Epoch 003 - training loss: 0.0557, validation loss: 0.0370
2024-05-24 23:37:09 [INFO]: Epoch 004 - training loss: 0.0559, validation loss: 0.0374
2024-05-24 23:37:09 [INFO]: Epoch 005 - training loss: 0.0544, validation loss: 0.0393
2024-05-24 23:37:10 [INFO]: Epoch 006 - training loss: 0.0536, validation loss: 0.0374
2024-05-24 23:37:10 [INFO]: Epoch 007 - training loss: 0.0543, validation loss: 0.0375
2024-05-24 23:37:10 [INFO]: Epoch 008 - training loss: 0.0528, validation loss: 0.0365
2024-05-24 23:37:10 [INFO]: Epoch 009 - training loss: 0.0528, validation loss: 0.0367
2024-05-24 23:37:11 [INFO]: Epoch 010 - training loss: 0.0499, validation loss: 0.0359
2024-05-24 23:37:11 [INFO]: Epoch 011 - training loss: 0.0493, validation loss: 0.0368
2024-05-24 23:37:11 [INFO]: Epoch 012 - training loss: 0.0511, validation loss: 0.0392
2024-05-24 23:37:11 [INFO]: Epoch 013 - training loss: 0.0562, validation loss: 0.0334
2024-05-24 23:37:11 [INFO]: Epoch 014 - training loss: 0.0525, validation loss: 0.0342
2024-05-24 23:37:12 [INFO]: Epoch 015 - training loss: 0.0507, validation loss: 0.0357
2024-05-24 23:37:12 [INFO]: Epoch 016 - training loss: 0.0535, validation loss: 0.0413
2024-05-24 23:37:12 [INFO]: Epoch 017 - training loss: 0.0707, validation loss: 0.0364
2024-05-24 23:37:12 [INFO]: Epoch 018 - training loss: 0.0524, validation loss: 0.0369
2024-05-24 23:37:12 [INFO]: Epoch 019 - training loss: 0.0501, validation loss: 0.0340
2024-05-24 23:37:13 [INFO]: Epoch 020 - training loss: 0.0504, validation loss: 0.0339
2024-05-24 23:37:13 [INFO]: Epoch 021 - training loss: 0.0494, validation loss: 0.0346
2024-05-24 23:37:13 [INFO]: Epoch 022 - training loss: 0.0465, validation loss: 0.0337
2024-05-24 23:37:13 [INFO]: Epoch 023 - training loss: 0.0484, validation loss: 0.0321
2024-05-24 23:37:13 [INFO]: Epoch 024 - training loss: 0.0472, validation loss: 0.0322
2024-05-24 23:37:14 [INFO]: Epoch 025 - training loss: 0.0507, validation loss: 0.0399
2024-05-24 23:37:14 [INFO]: Epoch 026 - training loss: 0.0607, validation loss: 0.0360
2024-05-24 23:37:14 [INFO]: Epoch 027 - training loss: 0.0471, validation loss: 0.0351
2024-05-24 23:37:14 [INFO]: Epoch 028 - training loss: 0.0475, validation loss: 0.0356
2024-05-24 23:37:15 [INFO]: Epoch 029 - training loss: 0.0509, validation loss: 0.0360
2024-05-24 23:37:15 [INFO]: Epoch 030 - training loss: 0.0453, validation loss: 0.0313
2024-05-24 23:37:15 [INFO]: Epoch 031 - training loss: 0.0428, validation loss: 0.0334
2024-05-24 23:37:15 [INFO]: Epoch 032 - training loss: 0.0446, validation loss: 0.0330
2024-05-24 23:37:15 [INFO]: Epoch 033 - training loss: 0.0439, validation loss: 0.0358
2024-05-24 23:37:16 [INFO]: Epoch 034 - training loss: 0.0424, validation loss: 0.0316
2024-05-24 23:37:16 [INFO]: Epoch 035 - training loss: 0.0455, validation loss: 0.0342
2024-05-24 23:37:16 [INFO]: Epoch 036 - training loss: 0.0495, validation loss: 0.0336
2024-05-24 23:37:16 [INFO]: Epoch 037 - training loss: 0.0451, validation loss: 0.0314
2024-05-24 23:37:16 [INFO]: Epoch 038 - training loss: 0.0402, validation loss: 0.0301
2024-05-24 23:37:17 [INFO]: Epoch 039 - training loss: 0.0404, validation loss: 0.0291
2024-05-24 23:37:17 [INFO]: Epoch 040 - training loss: 0.0403, validation loss: 0.0307
2024-05-24 23:37:17 [INFO]: Epoch 041 - training loss: 0.0418, validation loss: 0.0302
2024-05-24 23:37:17 [INFO]: Epoch 042 - training loss: 0.0461, validation loss: 0.0295
2024-05-24 23:37:17 [INFO]: Epoch 043 - training loss: 0.0454, validation loss: 0.0312
2024-05-24 23:37:18 [INFO]: Epoch 044 - training loss: 0.0410, validation loss: 0.0318
2024-05-24 23:37:18 [INFO]: Epoch 045 - training loss: 0.0409, validation loss: 0.0298
2024-05-24 23:37:18 [INFO]: Epoch 046 - training loss: 0.0388, validation loss: 0.0297
2024-05-24 23:37:18 [INFO]: Epoch 047 - training loss: 0.0425, validation loss: 0.0321
2024-05-24 23:37:18 [INFO]: Epoch 048 - training loss: 0.0448, validation loss: 0.0313
2024-05-24 23:37:19 [INFO]: Epoch 049 - training loss: 0.0398, validation loss: 0.0300
2024-05-24 23:37:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:37:19 [INFO]: Finished training. The best model is from epoch#39.
2024-05-24 23:37:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/TimesNet_ettm1/20240524_T233708/TimesNet.pypots
2024-05-24 23:37:19 [INFO]: TimesNet on ETTm1: MAE=0.1256, MSE=0.0328
2024-05-24 23:37:19 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-24 23:37:19 [INFO]: Using the given device: cuda:0
2024-05-24 23:37:19 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719
2024-05-24 23:37:19 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/tensorboard
2024-05-24 23:37:19 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:37:21 [INFO]: Epoch 001 - training loss: 0.7235, validation loss: 0.4368
2024-05-24 23:37:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch1_loss0.4367804750800133.pypots
2024-05-24 23:37:23 [INFO]: Epoch 002 - training loss: 0.4117, validation loss: 0.3943
2024-05-24 23:37:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch2_loss0.3943055272102356.pypots
2024-05-24 23:37:25 [INFO]: Epoch 003 - training loss: 0.3580, validation loss: 0.3385
2024-05-24 23:37:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch3_loss0.33852915465831757.pypots
2024-05-24 23:37:27 [INFO]: Epoch 004 - training loss: 0.3497, validation loss: 0.3580
2024-05-24 23:37:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch4_loss0.35802341997623444.pypots
2024-05-24 23:37:29 [INFO]: Epoch 005 - training loss: 0.3250, validation loss: 0.3396
2024-05-24 23:37:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch5_loss0.3396376222372055.pypots
2024-05-24 23:37:31 [INFO]: Epoch 006 - training loss: 0.2827, validation loss: 0.3195
2024-05-24 23:37:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch6_loss0.3194552809000015.pypots
2024-05-24 23:37:33 [INFO]: Epoch 007 - training loss: 0.2628, validation loss: 0.2972
2024-05-24 23:37:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch7_loss0.2972334027290344.pypots
2024-05-24 23:37:35 [INFO]: Epoch 008 - training loss: 0.2807, validation loss: 0.2883
2024-05-24 23:37:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch8_loss0.2883305326104164.pypots
2024-05-24 23:37:37 [INFO]: Epoch 009 - training loss: 0.2859, validation loss: 0.2722
2024-05-24 23:37:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch9_loss0.27219919860363007.pypots
2024-05-24 23:37:40 [INFO]: Epoch 010 - training loss: 0.2667, validation loss: 0.2808
2024-05-24 23:37:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch10_loss0.28083157539367676.pypots
2024-05-24 23:37:42 [INFO]: Epoch 011 - training loss: 0.2406, validation loss: 0.2703
2024-05-24 23:37:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch11_loss0.2703007832169533.pypots
2024-05-24 23:37:44 [INFO]: Epoch 012 - training loss: 0.2838, validation loss: 0.2720
2024-05-24 23:37:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch12_loss0.2719719260931015.pypots
2024-05-24 23:37:46 [INFO]: Epoch 013 - training loss: 0.2666, validation loss: 0.2862
2024-05-24 23:37:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch13_loss0.28619377315044403.pypots
2024-05-24 23:37:48 [INFO]: Epoch 014 - training loss: 0.2723, validation loss: 0.2517
2024-05-24 23:37:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch14_loss0.25174450874328613.pypots
2024-05-24 23:37:50 [INFO]: Epoch 015 - training loss: 0.2459, validation loss: 0.2472
2024-05-24 23:37:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch15_loss0.2472093664109707.pypots
2024-05-24 23:37:52 [INFO]: Epoch 016 - training loss: 0.3009, validation loss: 0.2657
2024-05-24 23:37:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch16_loss0.265726275742054.pypots
2024-05-24 23:37:54 [INFO]: Epoch 017 - training loss: 0.2252, validation loss: 0.2554
2024-05-24 23:37:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch17_loss0.2554359696805477.pypots
2024-05-24 23:37:56 [INFO]: Epoch 018 - training loss: 0.2241, validation loss: 0.2489
2024-05-24 23:37:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch18_loss0.24889761582016945.pypots
2024-05-24 23:37:58 [INFO]: Epoch 019 - training loss: 0.2478, validation loss: 0.2643
2024-05-24 23:37:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch19_loss0.26429351419210434.pypots
2024-05-24 23:38:00 [INFO]: Epoch 020 - training loss: 0.2279, validation loss: 0.2389
2024-05-24 23:38:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch20_loss0.23892735689878464.pypots
2024-05-24 23:38:02 [INFO]: Epoch 021 - training loss: 0.2884, validation loss: 0.2292
2024-05-24 23:38:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch21_loss0.22917864471673965.pypots
2024-05-24 23:38:04 [INFO]: Epoch 022 - training loss: 0.2398, validation loss: 0.2305
2024-05-24 23:38:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch22_loss0.23051511496305466.pypots
2024-05-24 23:38:07 [INFO]: Epoch 023 - training loss: 0.2221, validation loss: 0.2201
2024-05-24 23:38:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch23_loss0.22009655460715294.pypots
2024-05-24 23:38:09 [INFO]: Epoch 024 - training loss: 0.2346, validation loss: 0.2080
2024-05-24 23:38:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch24_loss0.20796196535229683.pypots
2024-05-24 23:38:11 [INFO]: Epoch 025 - training loss: 0.2139, validation loss: 0.2052
2024-05-24 23:38:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch25_loss0.2052493393421173.pypots
2024-05-24 23:38:13 [INFO]: Epoch 026 - training loss: 0.2892, validation loss: 0.2043
2024-05-24 23:38:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch26_loss0.204306960105896.pypots
2024-05-24 23:38:15 [INFO]: Epoch 027 - training loss: 0.2502, validation loss: 0.2021
2024-05-24 23:38:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch27_loss0.2021477334201336.pypots
2024-05-24 23:38:17 [INFO]: Epoch 028 - training loss: 0.2100, validation loss: 0.2102
2024-05-24 23:38:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch28_loss0.2102171964943409.pypots
2024-05-24 23:38:19 [INFO]: Epoch 029 - training loss: 0.2139, validation loss: 0.1998
2024-05-24 23:38:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch29_loss0.19975998625159264.pypots
2024-05-24 23:38:21 [INFO]: Epoch 030 - training loss: 0.2026, validation loss: 0.1932
2024-05-24 23:38:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch30_loss0.1932440735399723.pypots
2024-05-24 23:38:23 [INFO]: Epoch 031 - training loss: 0.2041, validation loss: 0.1867
2024-05-24 23:38:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch31_loss0.18665898963809013.pypots
2024-05-24 23:38:25 [INFO]: Epoch 032 - training loss: 0.1905, validation loss: 0.1825
2024-05-24 23:38:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch32_loss0.18249954283237457.pypots
2024-05-24 23:38:27 [INFO]: Epoch 033 - training loss: 0.2138, validation loss: 0.1883
2024-05-24 23:38:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch33_loss0.18825114145874977.pypots
2024-05-24 23:38:29 [INFO]: Epoch 034 - training loss: 0.2100, validation loss: 0.1848
2024-05-24 23:38:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch34_loss0.18482986092567444.pypots
2024-05-24 23:38:31 [INFO]: Epoch 035 - training loss: 0.2120, validation loss: 0.1754
2024-05-24 23:38:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch35_loss0.17540878430008888.pypots
2024-05-24 23:38:34 [INFO]: Epoch 036 - training loss: 0.1962, validation loss: 0.1733
2024-05-24 23:38:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch36_loss0.17326494306325912.pypots
2024-05-24 23:38:36 [INFO]: Epoch 037 - training loss: 0.1856, validation loss: 0.1843
2024-05-24 23:38:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch37_loss0.18430458009243011.pypots
2024-05-24 23:38:38 [INFO]: Epoch 038 - training loss: 0.2015, validation loss: 0.1813
2024-05-24 23:38:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch38_loss0.18125491216778755.pypots
2024-05-24 23:38:40 [INFO]: Epoch 039 - training loss: 0.1884, validation loss: 0.1718
2024-05-24 23:38:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch39_loss0.1718445122241974.pypots
2024-05-24 23:38:42 [INFO]: Epoch 040 - training loss: 0.1904, validation loss: 0.1820
2024-05-24 23:38:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch40_loss0.182031087577343.pypots
2024-05-24 23:38:44 [INFO]: Epoch 041 - training loss: 0.1758, validation loss: 0.1650
2024-05-24 23:38:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch41_loss0.16498367115855217.pypots
2024-05-24 23:38:46 [INFO]: Epoch 042 - training loss: 0.1631, validation loss: 0.1678
2024-05-24 23:38:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch42_loss0.1677791178226471.pypots
2024-05-24 23:38:48 [INFO]: Epoch 043 - training loss: 0.1708, validation loss: 0.1609
2024-05-24 23:38:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch43_loss0.16089287027716637.pypots
2024-05-24 23:38:50 [INFO]: Epoch 044 - training loss: 0.1754, validation loss: 0.1563
2024-05-24 23:38:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch44_loss0.15632998198270798.pypots
2024-05-24 23:38:52 [INFO]: Epoch 045 - training loss: 0.1585, validation loss: 0.1583
2024-05-24 23:38:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch45_loss0.15834620967507362.pypots
2024-05-24 23:38:54 [INFO]: Epoch 046 - training loss: 0.1494, validation loss: 0.1546
2024-05-24 23:38:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch46_loss0.1545811891555786.pypots
2024-05-24 23:38:56 [INFO]: Epoch 047 - training loss: 0.1336, validation loss: 0.1536
2024-05-24 23:38:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch47_loss0.15356113016605377.pypots
2024-05-24 23:38:58 [INFO]: Epoch 048 - training loss: 0.1678, validation loss: 0.1523
2024-05-24 23:38:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch48_loss0.152286097407341.pypots
2024-05-24 23:39:00 [INFO]: Epoch 049 - training loss: 0.1749, validation loss: 0.1545
2024-05-24 23:39:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch49_loss0.15449265018105507.pypots
2024-05-24 23:39:03 [INFO]: Epoch 050 - training loss: 0.1786, validation loss: 0.2279
2024-05-24 23:39:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch50_loss0.22787145897746086.pypots
2024-05-24 23:39:05 [INFO]: Epoch 051 - training loss: 0.2270, validation loss: 0.1997
2024-05-24 23:39:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch51_loss0.19974661618471146.pypots
2024-05-24 23:39:07 [INFO]: Epoch 052 - training loss: 0.2234, validation loss: 0.2053
2024-05-24 23:39:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch52_loss0.2052670158445835.pypots
2024-05-24 23:39:09 [INFO]: Epoch 053 - training loss: 0.2136, validation loss: 0.1670
2024-05-24 23:39:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch53_loss0.16703104227781296.pypots
2024-05-24 23:39:11 [INFO]: Epoch 054 - training loss: 0.1561, validation loss: 0.1586
2024-05-24 23:39:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch54_loss0.1586218997836113.pypots
2024-05-24 23:39:13 [INFO]: Epoch 055 - training loss: 0.1939, validation loss: 0.1579
2024-05-24 23:39:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch55_loss0.15793754905462265.pypots
2024-05-24 23:39:15 [INFO]: Epoch 056 - training loss: 0.1810, validation loss: 0.1643
2024-05-24 23:39:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch56_loss0.16425210982561111.pypots
2024-05-24 23:39:17 [INFO]: Epoch 057 - training loss: 0.1761, validation loss: 0.1548
2024-05-24 23:39:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch57_loss0.15481529384851456.pypots
2024-05-24 23:39:19 [INFO]: Epoch 058 - training loss: 0.2011, validation loss: 0.2040
2024-05-24 23:39:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI_epoch58_loss0.20397251844406128.pypots
2024-05-24 23:39:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:39:19 [INFO]: Finished training. The best model is from epoch#48.
2024-05-24 23:39:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_ettm1/20240524_T233719/CSDI.pypots
2024-05-24 23:39:35 [INFO]: CSDI on ETTm1: MAE=0.2875, MSE=0.9644
2024-05-24 23:39:35 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-24 23:39:35 [INFO]: Using the given device: cuda:0
2024-05-24 23:39:35 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T233935
2024-05-24 23:39:35 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T233935/tensorboard
2024-05-24 23:39:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 23:39:35 [INFO]: Epoch 001 - training loss: 23292.8943, validation loss: 0.9608
2024-05-24 23:39:35 [INFO]: Epoch 002 - training loss: 21282.3678, validation loss: 0.9568
2024-05-24 23:39:35 [INFO]: Epoch 003 - training loss: 19360.8119, validation loss: 0.9551
2024-05-24 23:39:35 [INFO]: Epoch 004 - training loss: 17515.1178, validation loss: 0.9577
2024-05-24 23:39:36 [INFO]: Epoch 005 - training loss: 15671.9468, validation loss: 0.9495
2024-05-24 23:39:36 [INFO]: Epoch 006 - training loss: 14116.8726, validation loss: 0.9266
2024-05-24 23:39:36 [INFO]: Epoch 007 - training loss: 12951.7819, validation loss: 0.8715
2024-05-24 23:39:36 [INFO]: Epoch 008 - training loss: 12280.0278, validation loss: 0.7781
2024-05-24 23:39:36 [INFO]: Epoch 009 - training loss: 11379.4012, validation loss: 0.6611
2024-05-24 23:39:36 [INFO]: Epoch 010 - training loss: 10983.5120, validation loss: 0.5564
2024-05-24 23:39:36 [INFO]: Epoch 011 - training loss: 10691.7365, validation loss: 0.5063
2024-05-24 23:39:36 [INFO]: Epoch 012 - training loss: 10406.9106, validation loss: 0.4891
2024-05-24 23:39:37 [INFO]: Epoch 013 - training loss: 10220.2468, validation loss: 0.4783
2024-05-24 23:39:37 [INFO]: Epoch 014 - training loss: 10139.7191, validation loss: 0.4744
2024-05-24 23:39:37 [INFO]: Epoch 015 - training loss: 9991.0337, validation loss: 0.4664
2024-05-24 23:39:37 [INFO]: Epoch 016 - training loss: 9908.7125, validation loss: 0.4531
2024-05-24 23:39:37 [INFO]: Epoch 017 - training loss: 9809.6379, validation loss: 0.4469
2024-05-24 23:39:37 [INFO]: Epoch 018 - training loss: 9790.4168, validation loss: 0.4442
2024-05-24 23:39:37 [INFO]: Epoch 019 - training loss: 9720.7532, validation loss: 0.4356
2024-05-24 23:39:37 [INFO]: Epoch 020 - training loss: 9690.5916, validation loss: 0.4239
2024-05-24 23:39:38 [INFO]: Epoch 021 - training loss: 9634.5634, validation loss: 0.4117
2024-05-24 23:39:38 [INFO]: Epoch 022 - training loss: 9594.0432, validation loss: 0.3947
2024-05-24 23:39:38 [INFO]: Epoch 023 - training loss: 9574.1281, validation loss: 0.3738
2024-05-24 23:39:38 [INFO]: Epoch 024 - training loss: 9533.3844, validation loss: 0.3582
2024-05-24 23:39:38 [INFO]: Epoch 025 - training loss: 9510.2643, validation loss: 0.3393
2024-05-24 23:39:38 [INFO]: Epoch 026 - training loss: 9494.0834, validation loss: 0.3229
2024-05-24 23:39:38 [INFO]: Epoch 027 - training loss: 9469.4338, validation loss: 0.3077
2024-05-24 23:39:38 [INFO]: Epoch 028 - training loss: 9451.0132, validation loss: 0.2924
2024-05-24 23:39:39 [INFO]: Epoch 029 - training loss: 9454.2783, validation loss: 0.2829
2024-05-24 23:39:39 [INFO]: Epoch 030 - training loss: 9417.7004, validation loss: 0.2729
2024-05-24 23:39:39 [INFO]: Epoch 031 - training loss: 9416.0540, validation loss: 0.2663
2024-05-24 23:39:39 [INFO]: Epoch 032 - training loss: 9397.4320, validation loss: 0.2600
2024-05-24 23:39:39 [INFO]: Epoch 033 - training loss: 9388.9352, validation loss: 0.2553
2024-05-24 23:39:39 [INFO]: Epoch 034 - training loss: 9384.2429, validation loss: 0.2548
2024-05-24 23:39:39 [INFO]: Epoch 035 - training loss: 9370.3044, validation loss: 0.2530
2024-05-24 23:39:39 [INFO]: Epoch 036 - training loss: 9364.0233, validation loss: 0.2450
2024-05-24 23:39:40 [INFO]: Epoch 037 - training loss: 9352.2233, validation loss: 0.2417
2024-05-24 23:39:40 [INFO]: Epoch 038 - training loss: 9358.8291, validation loss: 0.2409
2024-05-24 23:39:40 [INFO]: Epoch 039 - training loss: 9345.2425, validation loss: 0.2360
2024-05-24 23:39:40 [INFO]: Epoch 040 - training loss: 9364.6961, validation loss: 0.2320
2024-05-24 23:39:40 [INFO]: Epoch 041 - training loss: 9328.8948, validation loss: 0.2307
2024-05-24 23:39:40 [INFO]: Epoch 042 - training loss: 9327.4515, validation loss: 0.2256
2024-05-24 23:39:40 [INFO]: Epoch 043 - training loss: 9323.9931, validation loss: 0.2238
2024-05-24 23:39:40 [INFO]: Epoch 044 - training loss: 9315.1335, validation loss: 0.2213
2024-05-24 23:39:41 [INFO]: Epoch 045 - training loss: 9317.6734, validation loss: 0.2190
2024-05-24 23:39:41 [INFO]: Epoch 046 - training loss: 9312.1765, validation loss: 0.2148
2024-05-24 23:39:41 [INFO]: Epoch 047 - training loss: 9306.2693, validation loss: 0.2116
2024-05-24 23:39:41 [INFO]: Epoch 048 - training loss: 9302.0842, validation loss: 0.2090
2024-05-24 23:39:41 [INFO]: Epoch 049 - training loss: 9301.8636, validation loss: 0.2036
2024-05-24 23:39:41 [INFO]: Epoch 050 - training loss: 9299.8809, validation loss: 0.1986
2024-05-24 23:39:41 [INFO]: Epoch 051 - training loss: 9293.8162, validation loss: 0.2010
2024-05-24 23:39:41 [INFO]: Epoch 052 - training loss: 9288.1271, validation loss: 0.1982
2024-05-24 23:39:42 [INFO]: Epoch 053 - training loss: 9285.9611, validation loss: 0.1954
2024-05-24 23:39:42 [INFO]: Epoch 054 - training loss: 9283.7206, validation loss: 0.1911
2024-05-24 23:39:42 [INFO]: Epoch 055 - training loss: 9282.2635, validation loss: 0.1889
2024-05-24 23:39:42 [INFO]: Epoch 056 - training loss: 9276.9919, validation loss: 0.1855
2024-05-24 23:39:42 [INFO]: Epoch 057 - training loss: 9275.4680, validation loss: 0.1821
2024-05-24 23:39:42 [INFO]: Epoch 058 - training loss: 9275.3007, validation loss: 0.1785
2024-05-24 23:39:42 [INFO]: Epoch 059 - training loss: 9273.7144, validation loss: 0.1747
2024-05-24 23:39:42 [INFO]: Epoch 060 - training loss: 9271.7463, validation loss: 0.1707
2024-05-24 23:39:42 [INFO]: Epoch 061 - training loss: 9269.0954, validation loss: 0.1700
2024-05-24 23:39:43 [INFO]: Epoch 062 - training loss: 9267.1110, validation loss: 0.1665
2024-05-24 23:39:43 [INFO]: Epoch 063 - training loss: 9266.9061, validation loss: 0.1622
2024-05-24 23:39:43 [INFO]: Epoch 064 - training loss: 9272.5322, validation loss: 0.1607
2024-05-24 23:39:43 [INFO]: Epoch 065 - training loss: 9261.6003, validation loss: 0.1578
2024-05-24 23:39:43 [INFO]: Epoch 066 - training loss: 9261.2961, validation loss: 0.1560
2024-05-24 23:39:43 [INFO]: Epoch 067 - training loss: 9257.0516, validation loss: 0.1515
2024-05-24 23:39:43 [INFO]: Epoch 068 - training loss: 9256.1251, validation loss: 0.1519
2024-05-24 23:39:44 [INFO]: Epoch 069 - training loss: 9259.5055, validation loss: 0.1496
2024-05-24 23:39:44 [INFO]: Epoch 070 - training loss: 9262.6313, validation loss: 0.1463
2024-05-24 23:39:44 [INFO]: Epoch 071 - training loss: 9253.1185, validation loss: 0.1453
2024-05-24 23:39:44 [INFO]: Epoch 072 - training loss: 9252.2424, validation loss: 0.1435
2024-05-24 23:39:44 [INFO]: Epoch 073 - training loss: 9251.7467, validation loss: 0.1456
2024-05-24 23:39:44 [INFO]: Epoch 074 - training loss: 9251.2877, validation loss: 0.1409
2024-05-24 23:39:44 [INFO]: Epoch 075 - training loss: 9254.2532, validation loss: 0.1365
2024-05-24 23:39:44 [INFO]: Epoch 076 - training loss: 9249.6361, validation loss: 0.1353
2024-05-24 23:39:44 [INFO]: Epoch 077 - training loss: 9245.8334, validation loss: 0.1365
2024-05-24 23:39:45 [INFO]: Epoch 078 - training loss: 9244.1609, validation loss: 0.1343
2024-05-24 23:39:45 [INFO]: Epoch 079 - training loss: 9244.4746, validation loss: 0.1339
2024-05-24 23:39:45 [INFO]: Epoch 080 - training loss: 9247.0844, validation loss: 0.1349
2024-05-24 23:39:45 [INFO]: Epoch 081 - training loss: 9245.6487, validation loss: 0.1341
2024-05-24 23:39:45 [INFO]: Epoch 082 - training loss: 9243.8148, validation loss: 0.1314
2024-05-24 23:39:45 [INFO]: Epoch 083 - training loss: 9241.6570, validation loss: 0.1339
2024-05-24 23:39:45 [INFO]: Epoch 084 - training loss: 9243.5486, validation loss: 0.1305
2024-05-24 23:39:45 [INFO]: Epoch 085 - training loss: 9240.5762, validation loss: 0.1311
2024-05-24 23:39:46 [INFO]: Epoch 086 - training loss: 9238.0508, validation loss: 0.1296
2024-05-24 23:39:46 [INFO]: Epoch 087 - training loss: 9238.3613, validation loss: 0.1287
2024-05-24 23:39:46 [INFO]: Epoch 088 - training loss: 9238.8900, validation loss: 0.1263
2024-05-24 23:39:46 [INFO]: Epoch 089 - training loss: 9237.5336, validation loss: 0.1280
2024-05-24 23:39:46 [INFO]: Epoch 090 - training loss: 9238.3844, validation loss: 0.1282
2024-05-24 23:39:46 [INFO]: Epoch 091 - training loss: 9236.2489, validation loss: 0.1265
2024-05-24 23:39:46 [INFO]: Epoch 092 - training loss: 9237.5955, validation loss: 0.1243
2024-05-24 23:39:46 [INFO]: Epoch 093 - training loss: 9236.8580, validation loss: 0.1246
2024-05-24 23:39:47 [INFO]: Epoch 094 - training loss: 9235.1370, validation loss: 0.1240
2024-05-24 23:39:47 [INFO]: Epoch 095 - training loss: 9234.2447, validation loss: 0.1228
2024-05-24 23:39:47 [INFO]: Epoch 096 - training loss: 9233.0692, validation loss: 0.1231
2024-05-24 23:39:47 [INFO]: Epoch 097 - training loss: 9231.8876, validation loss: 0.1217
2024-05-24 23:39:47 [INFO]: Epoch 098 - training loss: 9232.9252, validation loss: 0.1208
2024-05-24 23:39:47 [INFO]: Epoch 099 - training loss: 9232.0345, validation loss: 0.1214
2024-05-24 23:39:47 [INFO]: Epoch 100 - training loss: 9230.8479, validation loss: 0.1189
2024-05-24 23:39:47 [INFO]: Epoch 101 - training loss: 9230.9164, validation loss: 0.1189
2024-05-24 23:39:48 [INFO]: Epoch 102 - training loss: 9230.3287, validation loss: 0.1189
2024-05-24 23:39:48 [INFO]: Epoch 103 - training loss: 9231.5956, validation loss: 0.1174
2024-05-24 23:39:48 [INFO]: Epoch 104 - training loss: 9229.2482, validation loss: 0.1183
2024-05-24 23:39:48 [INFO]: Epoch 105 - training loss: 9228.6273, validation loss: 0.1152
2024-05-24 23:39:48 [INFO]: Epoch 106 - training loss: 9229.6500, validation loss: 0.1165
2024-05-24 23:39:48 [INFO]: Epoch 107 - training loss: 9227.7196, validation loss: 0.1155
2024-05-24 23:39:48 [INFO]: Epoch 108 - training loss: 9227.9523, validation loss: 0.1170
2024-05-24 23:39:48 [INFO]: Epoch 109 - training loss: 9228.8727, validation loss: 0.1157
2024-05-24 23:39:49 [INFO]: Epoch 110 - training loss: 9229.9393, validation loss: 0.1140
2024-05-24 23:39:49 [INFO]: Epoch 111 - training loss: 9226.6758, validation loss: 0.1147
2024-05-24 23:39:49 [INFO]: Epoch 112 - training loss: 9226.8093, validation loss: 0.1124
2024-05-24 23:39:49 [INFO]: Epoch 113 - training loss: 9227.0117, validation loss: 0.1135
2024-05-24 23:39:49 [INFO]: Epoch 114 - training loss: 9223.6327, validation loss: 0.1123
2024-05-24 23:39:49 [INFO]: Epoch 115 - training loss: 9227.1567, validation loss: 0.1115
2024-05-24 23:39:49 [INFO]: Epoch 116 - training loss: 9225.8659, validation loss: 0.1141
2024-05-24 23:39:49 [INFO]: Epoch 117 - training loss: 9226.0788, validation loss: 0.1102
2024-05-24 23:39:50 [INFO]: Epoch 118 - training loss: 9225.0992, validation loss: 0.1117
2024-05-24 23:39:50 [INFO]: Epoch 119 - training loss: 9222.6919, validation loss: 0.1121
2024-05-24 23:39:50 [INFO]: Epoch 120 - training loss: 9225.6204, validation loss: 0.1109
2024-05-24 23:39:50 [INFO]: Epoch 121 - training loss: 9224.2082, validation loss: 0.1101
2024-05-24 23:39:50 [INFO]: Epoch 122 - training loss: 9226.1791, validation loss: 0.1089
2024-05-24 23:39:50 [INFO]: Epoch 123 - training loss: 9223.7108, validation loss: 0.1097
2024-05-24 23:39:50 [INFO]: Epoch 124 - training loss: 9223.5061, validation loss: 0.1071
2024-05-24 23:39:50 [INFO]: Epoch 125 - training loss: 9222.9298, validation loss: 0.1100
2024-05-24 23:39:51 [INFO]: Epoch 126 - training loss: 9222.1129, validation loss: 0.1087
2024-05-24 23:39:51 [INFO]: Epoch 127 - training loss: 9221.4177, validation loss: 0.1068
2024-05-24 23:39:51 [INFO]: Epoch 128 - training loss: 9225.2494, validation loss: 0.1087
2024-05-24 23:39:51 [INFO]: Epoch 129 - training loss: 9221.1918, validation loss: 0.1070
2024-05-24 23:39:51 [INFO]: Epoch 130 - training loss: 9223.7610, validation loss: 0.1053
2024-05-24 23:39:51 [INFO]: Epoch 131 - training loss: 9221.2280, validation loss: 0.1078
2024-05-24 23:39:51 [INFO]: Epoch 132 - training loss: 9220.5994, validation loss: 0.1053
2024-05-24 23:39:51 [INFO]: Epoch 133 - training loss: 9220.9058, validation loss: 0.1062
2024-05-24 23:39:52 [INFO]: Epoch 134 - training loss: 9224.8228, validation loss: 0.1042
2024-05-24 23:39:52 [INFO]: Epoch 135 - training loss: 9220.4911, validation loss: 0.1043
2024-05-24 23:39:52 [INFO]: Epoch 136 - training loss: 9218.3409, validation loss: 0.1056
2024-05-24 23:39:52 [INFO]: Epoch 137 - training loss: 9218.4364, validation loss: 0.1041
2024-05-24 23:39:52 [INFO]: Epoch 138 - training loss: 9221.6658, validation loss: 0.1036
2024-05-24 23:39:52 [INFO]: Epoch 139 - training loss: 9218.4730, validation loss: 0.1054
2024-05-24 23:39:52 [INFO]: Epoch 140 - training loss: 9219.8653, validation loss: 0.1032
2024-05-24 23:39:52 [INFO]: Epoch 141 - training loss: 9220.2060, validation loss: 0.1037
2024-05-24 23:39:53 [INFO]: Epoch 142 - training loss: 9220.0801, validation loss: 0.1033
2024-05-24 23:39:53 [INFO]: Epoch 143 - training loss: 9219.4883, validation loss: 0.1030
2024-05-24 23:39:53 [INFO]: Epoch 144 - training loss: 9216.2215, validation loss: 0.1009
2024-05-24 23:39:53 [INFO]: Epoch 145 - training loss: 9216.7442, validation loss: 0.1025
2024-05-24 23:39:53 [INFO]: Epoch 146 - training loss: 9216.8883, validation loss: 0.1021
2024-05-24 23:39:53 [INFO]: Epoch 147 - training loss: 9217.5814, validation loss: 0.1013
2024-05-24 23:39:53 [INFO]: Epoch 148 - training loss: 9217.0311, validation loss: 0.1022
2024-05-24 23:39:53 [INFO]: Epoch 149 - training loss: 9215.6207, validation loss: 0.0986
2024-05-24 23:39:54 [INFO]: Epoch 150 - training loss: 9216.0342, validation loss: 0.0995
2024-05-24 23:39:54 [INFO]: Epoch 151 - training loss: 9217.3649, validation loss: 0.1010
2024-05-24 23:39:54 [INFO]: Epoch 152 - training loss: 9216.0007, validation loss: 0.1007
2024-05-24 23:39:54 [INFO]: Epoch 153 - training loss: 9217.1332, validation loss: 0.0965
2024-05-24 23:39:54 [INFO]: Epoch 154 - training loss: 9216.9350, validation loss: 0.1003
2024-05-24 23:39:54 [INFO]: Epoch 155 - training loss: 9215.5157, validation loss: 0.0965
2024-05-24 23:39:54 [INFO]: Epoch 156 - training loss: 9216.1417, validation loss: 0.0977
2024-05-24 23:39:54 [INFO]: Epoch 157 - training loss: 9215.8068, validation loss: 0.0979
2024-05-24 23:39:55 [INFO]: Epoch 158 - training loss: 9215.5638, validation loss: 0.0981
2024-05-24 23:39:55 [INFO]: Epoch 159 - training loss: 9215.0396, validation loss: 0.0980
2024-05-24 23:39:55 [INFO]: Epoch 160 - training loss: 9215.1085, validation loss: 0.0951
2024-05-24 23:39:55 [INFO]: Epoch 161 - training loss: 9214.9756, validation loss: 0.0973
2024-05-24 23:39:55 [INFO]: Epoch 162 - training loss: 9213.7916, validation loss: 0.0966
2024-05-24 23:39:55 [INFO]: Epoch 163 - training loss: 9215.4739, validation loss: 0.0961
2024-05-24 23:39:55 [INFO]: Epoch 164 - training loss: 9214.8557, validation loss: 0.0971
2024-05-24 23:39:55 [INFO]: Epoch 165 - training loss: 9215.0417, validation loss: 0.0973
2024-05-24 23:39:56 [INFO]: Epoch 166 - training loss: 9214.2262, validation loss: 0.0939
2024-05-24 23:39:56 [INFO]: Epoch 167 - training loss: 9214.0818, validation loss: 0.0948
2024-05-24 23:39:56 [INFO]: Epoch 168 - training loss: 9216.3123, validation loss: 0.0954
2024-05-24 23:39:56 [INFO]: Epoch 169 - training loss: 9213.2828, validation loss: 0.0947
2024-05-24 23:39:56 [INFO]: Epoch 170 - training loss: 9215.7750, validation loss: 0.0952
2024-05-24 23:39:56 [INFO]: Epoch 171 - training loss: 9213.4963, validation loss: 0.0946
2024-05-24 23:39:56 [INFO]: Epoch 172 - training loss: 9214.2796, validation loss: 0.0939
2024-05-24 23:39:56 [INFO]: Epoch 173 - training loss: 9214.8278, validation loss: 0.0946
2024-05-24 23:39:57 [INFO]: Epoch 174 - training loss: 9213.6801, validation loss: 0.0915
2024-05-24 23:39:57 [INFO]: Epoch 175 - training loss: 9212.6411, validation loss: 0.0940
2024-05-24 23:39:57 [INFO]: Epoch 176 - training loss: 9212.6544, validation loss: 0.0926
2024-05-24 23:39:57 [INFO]: Epoch 177 - training loss: 9213.0043, validation loss: 0.0935
2024-05-24 23:39:57 [INFO]: Epoch 178 - training loss: 9213.6890, validation loss: 0.0935
2024-05-24 23:39:57 [INFO]: Epoch 179 - training loss: 9212.9352, validation loss: 0.0932
2024-05-24 23:39:57 [INFO]: Epoch 180 - training loss: 9213.5017, validation loss: 0.0925
2024-05-24 23:39:57 [INFO]: Epoch 181 - training loss: 9213.6167, validation loss: 0.0935
2024-05-24 23:39:58 [INFO]: Epoch 182 - training loss: 9212.8314, validation loss: 0.0923
2024-05-24 23:39:58 [INFO]: Epoch 183 - training loss: 9212.4592, validation loss: 0.0946
2024-05-24 23:39:58 [INFO]: Epoch 184 - training loss: 9212.7136, validation loss: 0.0925
2024-05-24 23:39:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:39:58 [INFO]: Finished training. The best model is from epoch#174.
2024-05-24 23:39:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/GPVAE_ettm1/20240524_T233935/GPVAE.pypots
2024-05-24 23:39:58 [INFO]: GP-VAE on ETTm1: MAE=0.3012, MSE=0.1867
2024-05-24 23:39:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-24 23:39:58 [INFO]: Using the given device: cuda:0
2024-05-24 23:39:58 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T233958
2024-05-24 23:39:58 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T233958/tensorboard
2024-05-24 23:39:58 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 23:40:08 [INFO]: Epoch 001 - generator training loss: 0.3876, discriminator training loss: 0.5383, validation loss: 0.3167
2024-05-24 23:40:17 [INFO]: Epoch 002 - generator training loss: -0.0553, discriminator training loss: 0.4699, validation loss: 0.1267
2024-05-24 23:40:26 [INFO]: Epoch 003 - generator training loss: -0.1585, discriminator training loss: 0.4309, validation loss: 0.0730
2024-05-24 23:40:35 [INFO]: Epoch 004 - generator training loss: -0.1413, discriminator training loss: 0.3645, validation loss: 0.0561
2024-05-24 23:40:43 [INFO]: Epoch 005 - generator training loss: -0.1017, discriminator training loss: 0.2892, validation loss: 0.0517
2024-05-24 23:40:52 [INFO]: Epoch 006 - generator training loss: -0.0678, discriminator training loss: 0.2290, validation loss: 0.0473
2024-05-24 23:41:01 [INFO]: Epoch 007 - generator training loss: -0.0589, discriminator training loss: 0.1989, validation loss: 0.0431
2024-05-24 23:41:10 [INFO]: Epoch 008 - generator training loss: -0.0558, discriminator training loss: 0.1868, validation loss: 0.0406
2024-05-24 23:41:19 [INFO]: Epoch 009 - generator training loss: -0.0528, discriminator training loss: 0.1820, validation loss: 0.0401
2024-05-24 23:41:27 [INFO]: Epoch 010 - generator training loss: -0.0562, discriminator training loss: 0.1771, validation loss: 0.0380
2024-05-24 23:41:36 [INFO]: Epoch 011 - generator training loss: -0.0590, discriminator training loss: 0.1772, validation loss: 0.0370
2024-05-24 23:41:45 [INFO]: Epoch 012 - generator training loss: -0.0570, discriminator training loss: 0.1751, validation loss: 0.0367
2024-05-24 23:41:54 [INFO]: Epoch 013 - generator training loss: -0.0532, discriminator training loss: 0.1737, validation loss: 0.0370
2024-05-24 23:42:03 [INFO]: Epoch 014 - generator training loss: -0.0598, discriminator training loss: 0.1732, validation loss: 0.0346
2024-05-24 23:42:11 [INFO]: Epoch 015 - generator training loss: -0.0580, discriminator training loss: 0.1741, validation loss: 0.0346
2024-05-24 23:42:20 [INFO]: Epoch 016 - generator training loss: -0.0601, discriminator training loss: 0.1720, validation loss: 0.0343
2024-05-24 23:42:29 [INFO]: Epoch 017 - generator training loss: -0.0611, discriminator training loss: 0.1713, validation loss: 0.0334
2024-05-24 23:42:37 [INFO]: Epoch 018 - generator training loss: -0.0631, discriminator training loss: 0.1714, validation loss: 0.0330
2024-05-24 23:42:46 [INFO]: Epoch 019 - generator training loss: -0.0610, discriminator training loss: 0.1720, validation loss: 0.0328
2024-05-24 23:42:55 [INFO]: Epoch 020 - generator training loss: -0.0644, discriminator training loss: 0.1712, validation loss: 0.0338
2024-05-24 23:43:04 [INFO]: Epoch 021 - generator training loss: -0.0599, discriminator training loss: 0.1707, validation loss: 0.0324
2024-05-24 23:43:12 [INFO]: Epoch 022 - generator training loss: -0.0616, discriminator training loss: 0.1684, validation loss: 0.0324
2024-05-24 23:43:21 [INFO]: Epoch 023 - generator training loss: -0.0626, discriminator training loss: 0.1687, validation loss: 0.0315
2024-05-24 23:43:30 [INFO]: Epoch 024 - generator training loss: -0.0642, discriminator training loss: 0.1672, validation loss: 0.0313
2024-05-24 23:43:39 [INFO]: Epoch 025 - generator training loss: -0.0633, discriminator training loss: 0.1710, validation loss: 0.0308
2024-05-24 23:43:48 [INFO]: Epoch 026 - generator training loss: -0.0670, discriminator training loss: 0.1691, validation loss: 0.0311
2024-05-24 23:43:56 [INFO]: Epoch 027 - generator training loss: -0.0674, discriminator training loss: 0.1700, validation loss: 0.0300
2024-05-24 23:44:05 [INFO]: Epoch 028 - generator training loss: -0.0673, discriminator training loss: 0.1706, validation loss: 0.0299
2024-05-24 23:44:14 [INFO]: Epoch 029 - generator training loss: -0.0639, discriminator training loss: 0.1705, validation loss: 0.0308
2024-05-24 23:44:23 [INFO]: Epoch 030 - generator training loss: -0.0623, discriminator training loss: 0.1664, validation loss: 0.0302
2024-05-24 23:44:31 [INFO]: Epoch 031 - generator training loss: -0.0665, discriminator training loss: 0.1684, validation loss: 0.0303
2024-05-24 23:44:40 [INFO]: Epoch 032 - generator training loss: -0.0632, discriminator training loss: 0.1706, validation loss: 0.0299
2024-05-24 23:44:49 [INFO]: Epoch 033 - generator training loss: -0.0644, discriminator training loss: 0.1680, validation loss: 0.0296
2024-05-24 23:44:58 [INFO]: Epoch 034 - generator training loss: -0.0652, discriminator training loss: 0.1668, validation loss: 0.0287
2024-05-24 23:45:07 [INFO]: Epoch 035 - generator training loss: -0.0683, discriminator training loss: 0.1669, validation loss: 0.0289
2024-05-24 23:45:15 [INFO]: Epoch 036 - generator training loss: -0.0686, discriminator training loss: 0.1675, validation loss: 0.0289
2024-05-24 23:45:24 [INFO]: Epoch 037 - generator training loss: -0.0678, discriminator training loss: 0.1660, validation loss: 0.0287
2024-05-24 23:45:33 [INFO]: Epoch 038 - generator training loss: -0.0653, discriminator training loss: 0.1648, validation loss: 0.0286
2024-05-24 23:45:41 [INFO]: Epoch 039 - generator training loss: -0.0662, discriminator training loss: 0.1652, validation loss: 0.0285
2024-05-24 23:45:50 [INFO]: Epoch 040 - generator training loss: -0.0698, discriminator training loss: 0.1670, validation loss: 0.0292
2024-05-24 23:45:59 [INFO]: Epoch 041 - generator training loss: -0.0684, discriminator training loss: 0.1668, validation loss: 0.0285
2024-05-24 23:46:07 [INFO]: Epoch 042 - generator training loss: -0.0686, discriminator training loss: 0.1668, validation loss: 0.0278
2024-05-24 23:46:16 [INFO]: Epoch 043 - generator training loss: -0.0690, discriminator training loss: 0.1677, validation loss: 0.0281
2024-05-24 23:46:25 [INFO]: Epoch 044 - generator training loss: -0.0689, discriminator training loss: 0.1673, validation loss: 0.0280
2024-05-24 23:46:34 [INFO]: Epoch 045 - generator training loss: -0.0684, discriminator training loss: 0.1663, validation loss: 0.0284
2024-05-24 23:46:42 [INFO]: Epoch 046 - generator training loss: -0.0665, discriminator training loss: 0.1684, validation loss: 0.0289
2024-05-24 23:46:51 [INFO]: Epoch 047 - generator training loss: -0.0635, discriminator training loss: 0.1664, validation loss: 0.0279
2024-05-24 23:47:00 [INFO]: Epoch 048 - generator training loss: -0.0693, discriminator training loss: 0.1676, validation loss: 0.0272
2024-05-24 23:47:09 [INFO]: Epoch 049 - generator training loss: -0.0649, discriminator training loss: 0.1665, validation loss: 0.0272
2024-05-24 23:47:17 [INFO]: Epoch 050 - generator training loss: -0.0683, discriminator training loss: 0.1648, validation loss: 0.0272
2024-05-24 23:47:26 [INFO]: Epoch 051 - generator training loss: -0.0701, discriminator training loss: 0.1637, validation loss: 0.0277
2024-05-24 23:47:35 [INFO]: Epoch 052 - generator training loss: -0.0705, discriminator training loss: 0.1661, validation loss: 0.0267
2024-05-24 23:47:44 [INFO]: Epoch 053 - generator training loss: -0.0691, discriminator training loss: 0.1661, validation loss: 0.0270
2024-05-24 23:47:52 [INFO]: Epoch 054 - generator training loss: -0.0712, discriminator training loss: 0.1639, validation loss: 0.0268
2024-05-24 23:48:01 [INFO]: Epoch 055 - generator training loss: -0.0685, discriminator training loss: 0.1660, validation loss: 0.0271
2024-05-24 23:48:10 [INFO]: Epoch 056 - generator training loss: -0.0682, discriminator training loss: 0.1671, validation loss: 0.0269
2024-05-24 23:48:19 [INFO]: Epoch 057 - generator training loss: -0.0694, discriminator training loss: 0.1649, validation loss: 0.0269
2024-05-24 23:48:27 [INFO]: Epoch 058 - generator training loss: -0.0674, discriminator training loss: 0.1667, validation loss: 0.0264
2024-05-24 23:48:36 [INFO]: Epoch 059 - generator training loss: -0.0686, discriminator training loss: 0.1661, validation loss: 0.0264
2024-05-24 23:48:45 [INFO]: Epoch 060 - generator training loss: -0.0718, discriminator training loss: 0.1629, validation loss: 0.0270
2024-05-24 23:48:53 [INFO]: Epoch 061 - generator training loss: -0.0682, discriminator training loss: 0.1648, validation loss: 0.0259
2024-05-24 23:49:02 [INFO]: Epoch 062 - generator training loss: -0.0702, discriminator training loss: 0.1651, validation loss: 0.0255
2024-05-24 23:49:11 [INFO]: Epoch 063 - generator training loss: -0.0688, discriminator training loss: 0.1668, validation loss: 0.0264
2024-05-24 23:49:19 [INFO]: Epoch 064 - generator training loss: -0.0686, discriminator training loss: 0.1668, validation loss: 0.0258
2024-05-24 23:49:28 [INFO]: Epoch 065 - generator training loss: -0.0713, discriminator training loss: 0.1621, validation loss: 0.0259
2024-05-24 23:49:37 [INFO]: Epoch 066 - generator training loss: -0.0726, discriminator training loss: 0.1647, validation loss: 0.0257
2024-05-24 23:49:45 [INFO]: Epoch 067 - generator training loss: -0.0681, discriminator training loss: 0.1651, validation loss: 0.0251
2024-05-24 23:49:54 [INFO]: Epoch 068 - generator training loss: -0.0698, discriminator training loss: 0.1614, validation loss: 0.0263
2024-05-24 23:50:03 [INFO]: Epoch 069 - generator training loss: -0.0730, discriminator training loss: 0.1644, validation loss: 0.0269
2024-05-24 23:50:11 [INFO]: Epoch 070 - generator training loss: -0.0708, discriminator training loss: 0.1642, validation loss: 0.0271
2024-05-24 23:50:20 [INFO]: Epoch 071 - generator training loss: -0.0701, discriminator training loss: 0.1632, validation loss: 0.0268
2024-05-24 23:50:29 [INFO]: Epoch 072 - generator training loss: -0.0639, discriminator training loss: 0.1623, validation loss: 0.0267
2024-05-24 23:50:37 [INFO]: Epoch 073 - generator training loss: -0.0682, discriminator training loss: 0.1627, validation loss: 0.0260
2024-05-24 23:50:46 [INFO]: Epoch 074 - generator training loss: -0.0679, discriminator training loss: 0.1635, validation loss: 0.0260
2024-05-24 23:50:55 [INFO]: Epoch 075 - generator training loss: -0.0685, discriminator training loss: 0.1628, validation loss: 0.0258
2024-05-24 23:51:03 [INFO]: Epoch 076 - generator training loss: -0.0697, discriminator training loss: 0.1618, validation loss: 0.0250
2024-05-24 23:51:12 [INFO]: Epoch 077 - generator training loss: -0.0714, discriminator training loss: 0.1614, validation loss: 0.0253
2024-05-24 23:51:21 [INFO]: Epoch 078 - generator training loss: -0.0726, discriminator training loss: 0.1632, validation loss: 0.0246
2024-05-24 23:51:29 [INFO]: Epoch 079 - generator training loss: -0.0692, discriminator training loss: 0.1626, validation loss: 0.0249
2024-05-24 23:51:38 [INFO]: Epoch 080 - generator training loss: -0.0691, discriminator training loss: 0.1637, validation loss: 0.0250
2024-05-24 23:51:46 [INFO]: Epoch 081 - generator training loss: -0.0712, discriminator training loss: 0.1630, validation loss: 0.0254
2024-05-24 23:51:55 [INFO]: Epoch 082 - generator training loss: -0.0712, discriminator training loss: 0.1622, validation loss: 0.0249
2024-05-24 23:52:04 [INFO]: Epoch 083 - generator training loss: -0.0677, discriminator training loss: 0.1612, validation loss: 0.0251
2024-05-24 23:52:13 [INFO]: Epoch 084 - generator training loss: -0.0688, discriminator training loss: 0.1619, validation loss: 0.0252
2024-05-24 23:52:22 [INFO]: Epoch 085 - generator training loss: -0.0710, discriminator training loss: 0.1610, validation loss: 0.0248
2024-05-24 23:52:31 [INFO]: Epoch 086 - generator training loss: -0.0710, discriminator training loss: 0.1597, validation loss: 0.0249
2024-05-24 23:52:39 [INFO]: Epoch 087 - generator training loss: -0.0732, discriminator training loss: 0.1598, validation loss: 0.0247
2024-05-24 23:52:48 [INFO]: Epoch 088 - generator training loss: -0.0722, discriminator training loss: 0.1640, validation loss: 0.0250
2024-05-24 23:52:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:52:48 [INFO]: Finished training. The best model is from epoch#78.
2024-05-24 23:52:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/USGAN_ettm1/20240524_T233958/USGAN.pypots
2024-05-24 23:52:49 [INFO]: US-GAN on ETTm1: MAE=0.1453, MSE=0.0561
2024-05-24 23:52:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-24 23:52:49 [INFO]: Using the given device: cuda:0
2024-05-24 23:52:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T235249
2024-05-24 23:52:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T235249/tensorboard
2024-05-24 23:52:49 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 23:52:57 [INFO]: Epoch 001 - training loss: 1.3849, validation loss: 0.3468
2024-05-24 23:53:02 [INFO]: Epoch 002 - training loss: 0.9339, validation loss: 0.1150
2024-05-24 23:53:08 [INFO]: Epoch 003 - training loss: 0.7551, validation loss: 0.0646
2024-05-24 23:53:14 [INFO]: Epoch 004 - training loss: 0.6975, validation loss: 0.0494
2024-05-24 23:53:20 [INFO]: Epoch 005 - training loss: 0.6631, validation loss: 0.0478
2024-05-24 23:53:26 [INFO]: Epoch 006 - training loss: 0.6046, validation loss: 0.0495
2024-05-24 23:53:32 [INFO]: Epoch 007 - training loss: 0.5714, validation loss: 0.0404
2024-05-24 23:53:38 [INFO]: Epoch 008 - training loss: 0.5407, validation loss: 0.0375
2024-05-24 23:53:44 [INFO]: Epoch 009 - training loss: 0.5190, validation loss: 0.0364
2024-05-24 23:53:49 [INFO]: Epoch 010 - training loss: 0.5026, validation loss: 0.0344
2024-05-24 23:53:55 [INFO]: Epoch 011 - training loss: 0.4861, validation loss: 0.0328
2024-05-24 23:54:01 [INFO]: Epoch 012 - training loss: 0.4846, validation loss: 0.0322
2024-05-24 23:54:07 [INFO]: Epoch 013 - training loss: 0.4645, validation loss: 0.0312
2024-05-24 23:54:13 [INFO]: Epoch 014 - training loss: 0.4480, validation loss: 0.0303
2024-05-24 23:54:19 [INFO]: Epoch 015 - training loss: 0.4345, validation loss: 0.0303
2024-05-24 23:54:24 [INFO]: Epoch 016 - training loss: 0.4538, validation loss: 0.0303
2024-05-24 23:54:30 [INFO]: Epoch 017 - training loss: 0.4277, validation loss: 0.0294
2024-05-24 23:54:36 [INFO]: Epoch 018 - training loss: 0.4337, validation loss: 0.0290
2024-05-24 23:54:42 [INFO]: Epoch 019 - training loss: 0.4321, validation loss: 0.0303
2024-05-24 23:54:48 [INFO]: Epoch 020 - training loss: 0.4238, validation loss: 0.0291
2024-05-24 23:54:54 [INFO]: Epoch 021 - training loss: 0.4191, validation loss: 0.0291
2024-05-24 23:54:59 [INFO]: Epoch 022 - training loss: 0.4112, validation loss: 0.0281
2024-05-24 23:55:05 [INFO]: Epoch 023 - training loss: 0.4115, validation loss: 0.0270
2024-05-24 23:55:11 [INFO]: Epoch 024 - training loss: 0.4018, validation loss: 0.0270
2024-05-24 23:55:17 [INFO]: Epoch 025 - training loss: 0.4050, validation loss: 0.0270
2024-05-24 23:55:23 [INFO]: Epoch 026 - training loss: 0.3977, validation loss: 0.0269
2024-05-24 23:55:29 [INFO]: Epoch 027 - training loss: 0.4069, validation loss: 0.0273
2024-05-24 23:55:35 [INFO]: Epoch 028 - training loss: 0.3943, validation loss: 0.0276
2024-05-24 23:55:40 [INFO]: Epoch 029 - training loss: 0.4105, validation loss: 0.0267
2024-05-24 23:55:46 [INFO]: Epoch 030 - training loss: 0.4056, validation loss: 0.0271
2024-05-24 23:55:52 [INFO]: Epoch 031 - training loss: 0.4028, validation loss: 0.0282
2024-05-24 23:55:58 [INFO]: Epoch 032 - training loss: 0.4079, validation loss: 0.0272
2024-05-24 23:56:04 [INFO]: Epoch 033 - training loss: 0.3986, validation loss: 0.0263
2024-05-24 23:56:10 [INFO]: Epoch 034 - training loss: 0.4537, validation loss: 0.0269
2024-05-24 23:56:16 [INFO]: Epoch 035 - training loss: 0.4028, validation loss: 0.0272
2024-05-24 23:56:21 [INFO]: Epoch 036 - training loss: 0.3955, validation loss: 0.0268
2024-05-24 23:56:27 [INFO]: Epoch 037 - training loss: 0.3925, validation loss: 0.0264
2024-05-24 23:56:33 [INFO]: Epoch 038 - training loss: 0.4013, validation loss: 0.0269
2024-05-24 23:56:39 [INFO]: Epoch 039 - training loss: 0.3975, validation loss: 0.0271
2024-05-24 23:56:45 [INFO]: Epoch 040 - training loss: 0.3975, validation loss: 0.0265
2024-05-24 23:56:51 [INFO]: Epoch 041 - training loss: 0.4040, validation loss: 0.0263
2024-05-24 23:56:57 [INFO]: Epoch 042 - training loss: 0.3977, validation loss: 0.0270
2024-05-24 23:57:02 [INFO]: Epoch 043 - training loss: 0.3943, validation loss: 0.0272
2024-05-24 23:57:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:57:02 [INFO]: Finished training. The best model is from epoch#33.
2024-05-24 23:57:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/BRITS_ettm1/20240524_T235249/BRITS.pypots
2024-05-24 23:57:03 [INFO]: BRITS on ETTm1: MAE=0.1335, MSE=0.0505
2024-05-24 23:57:03 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-24 23:57:03 [INFO]: Using the given device: cuda:0
2024-05-24 23:57:03 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703
2024-05-24 23:57:03 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/tensorboard
2024-05-24 23:57:03 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 23:57:05 [INFO]: Epoch 001 - training loss: 1.3653, validation loss: 1.2543
2024-05-24 23:57:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch1_loss1.2542967349290848.pypots
2024-05-24 23:57:06 [INFO]: Epoch 002 - training loss: 0.9978, validation loss: 1.1320
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch2_loss1.1319563835859299.pypots
2024-05-24 23:57:06 [INFO]: Epoch 003 - training loss: 0.9168, validation loss: 1.0645
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch3_loss1.0644788593053818.pypots
2024-05-24 23:57:06 [INFO]: Epoch 004 - training loss: 0.9041, validation loss: 1.0303
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch4_loss1.030252918601036.pypots
2024-05-24 23:57:06 [INFO]: Epoch 005 - training loss: 0.8773, validation loss: 1.0130
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch5_loss1.0129692405462265.pypots
2024-05-24 23:57:06 [INFO]: Epoch 006 - training loss: 0.8666, validation loss: 1.0049
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch6_loss1.00491002202034.pypots
2024-05-24 23:57:06 [INFO]: Epoch 007 - training loss: 0.8722, validation loss: 0.9983
2024-05-24 23:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch7_loss0.9983070641756058.pypots
2024-05-24 23:57:07 [INFO]: Epoch 008 - training loss: 0.8604, validation loss: 1.0022
2024-05-24 23:57:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch8_loss1.0022334307432175.pypots
2024-05-24 23:57:07 [INFO]: Epoch 009 - training loss: 0.8449, validation loss: 1.0021
2024-05-24 23:57:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch9_loss1.0021275728940964.pypots
2024-05-24 23:57:07 [INFO]: Epoch 010 - training loss: 0.8495, validation loss: 0.9960
2024-05-24 23:57:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch10_loss0.9960445463657379.pypots
2024-05-24 23:57:07 [INFO]: Epoch 011 - training loss: 0.8302, validation loss: 1.0000
2024-05-24 23:57:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch11_loss1.0000404715538025.pypots
2024-05-24 23:57:07 [INFO]: Epoch 012 - training loss: 0.8547, validation loss: 0.9987
2024-05-24 23:57:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch12_loss0.998735174536705.pypots
2024-05-24 23:57:08 [INFO]: Epoch 013 - training loss: 0.8174, validation loss: 0.9971
2024-05-24 23:57:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch13_loss0.9971152693033218.pypots
2024-05-24 23:57:08 [INFO]: Epoch 014 - training loss: 0.7933, validation loss: 0.9957
2024-05-24 23:57:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch14_loss0.9957301169633865.pypots
2024-05-24 23:57:08 [INFO]: Epoch 015 - training loss: 0.8010, validation loss: 0.9919
2024-05-24 23:57:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch15_loss0.991880863904953.pypots
2024-05-24 23:57:08 [INFO]: Epoch 016 - training loss: 0.8284, validation loss: 0.9894
2024-05-24 23:57:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch16_loss0.98943230509758.pypots
2024-05-24 23:57:08 [INFO]: Epoch 017 - training loss: 0.8520, validation loss: 0.9855
2024-05-24 23:57:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch17_loss0.9855051040649414.pypots
2024-05-24 23:57:09 [INFO]: Epoch 018 - training loss: 0.8171, validation loss: 0.9846
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch18_loss0.9846139699220657.pypots
2024-05-24 23:57:09 [INFO]: Epoch 019 - training loss: 0.8191, validation loss: 0.9811
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch19_loss0.9811285436153412.pypots
2024-05-24 23:57:09 [INFO]: Epoch 020 - training loss: 0.8058, validation loss: 0.9730
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch20_loss0.9729904681444168.pypots
2024-05-24 23:57:09 [INFO]: Epoch 021 - training loss: 0.7919, validation loss: 0.9659
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch21_loss0.9659297168254852.pypots
2024-05-24 23:57:09 [INFO]: Epoch 022 - training loss: 0.7742, validation loss: 0.9605
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch22_loss0.9604930579662323.pypots
2024-05-24 23:57:09 [INFO]: Epoch 023 - training loss: 0.7662, validation loss: 0.9570
2024-05-24 23:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch23_loss0.9570416659116745.pypots
2024-05-24 23:57:10 [INFO]: Epoch 024 - training loss: 0.7800, validation loss: 0.9543
2024-05-24 23:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch24_loss0.9542793929576874.pypots
2024-05-24 23:57:10 [INFO]: Epoch 025 - training loss: 0.7903, validation loss: 0.9501
2024-05-24 23:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch25_loss0.9501221776008606.pypots
2024-05-24 23:57:10 [INFO]: Epoch 026 - training loss: 0.7784, validation loss: 0.9452
2024-05-24 23:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch26_loss0.9452032744884491.pypots
2024-05-24 23:57:10 [INFO]: Epoch 027 - training loss: 0.7773, validation loss: 0.9401
2024-05-24 23:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch27_loss0.9400831013917923.pypots
2024-05-24 23:57:10 [INFO]: Epoch 028 - training loss: 0.7754, validation loss: 0.9361
2024-05-24 23:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch28_loss0.9361183643341064.pypots
2024-05-24 23:57:11 [INFO]: Epoch 029 - training loss: 0.7661, validation loss: 0.9356
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch29_loss0.9356294274330139.pypots
2024-05-24 23:57:11 [INFO]: Epoch 030 - training loss: 0.7596, validation loss: 0.9327
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch30_loss0.9326911717653275.pypots
2024-05-24 23:57:11 [INFO]: Epoch 031 - training loss: 0.7747, validation loss: 0.9326
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch31_loss0.9326003938913345.pypots
2024-05-24 23:57:11 [INFO]: Epoch 032 - training loss: 0.7751, validation loss: 0.9254
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch32_loss0.9253738224506378.pypots
2024-05-24 23:57:11 [INFO]: Epoch 033 - training loss: 0.7725, validation loss: 0.9250
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch33_loss0.924978956580162.pypots
2024-05-24 23:57:11 [INFO]: Epoch 034 - training loss: 0.7809, validation loss: 0.9208
2024-05-24 23:57:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch34_loss0.920775517821312.pypots
2024-05-24 23:57:12 [INFO]: Epoch 035 - training loss: 0.7696, validation loss: 0.9198
2024-05-24 23:57:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch35_loss0.9198233932256699.pypots
2024-05-24 23:57:12 [INFO]: Epoch 036 - training loss: 0.7499, validation loss: 0.9157
2024-05-24 23:57:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch36_loss0.9157278090715408.pypots
2024-05-24 23:57:12 [INFO]: Epoch 037 - training loss: 0.7640, validation loss: 0.9156
2024-05-24 23:57:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch37_loss0.9155564308166504.pypots
2024-05-24 23:57:12 [INFO]: Epoch 038 - training loss: 0.7651, validation loss: 0.9153
2024-05-24 23:57:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch38_loss0.9153186529874802.pypots
2024-05-24 23:57:12 [INFO]: Epoch 039 - training loss: 0.7708, validation loss: 0.9096
2024-05-24 23:57:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch39_loss0.9095699936151505.pypots
2024-05-24 23:57:13 [INFO]: Epoch 040 - training loss: 0.7629, validation loss: 0.9102
2024-05-24 23:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch40_loss0.9102398157119751.pypots
2024-05-24 23:57:13 [INFO]: Epoch 041 - training loss: 0.7438, validation loss: 0.9076
2024-05-24 23:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch41_loss0.9075668454170227.pypots
2024-05-24 23:57:13 [INFO]: Epoch 042 - training loss: 0.7575, validation loss: 0.9068
2024-05-24 23:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch42_loss0.9068426638841629.pypots
2024-05-24 23:57:13 [INFO]: Epoch 043 - training loss: 0.7524, validation loss: 0.9080
2024-05-24 23:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch43_loss0.9079742878675461.pypots
2024-05-24 23:57:13 [INFO]: Epoch 044 - training loss: 0.7455, validation loss: 0.9035
2024-05-24 23:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch44_loss0.90352663397789.pypots
2024-05-24 23:57:14 [INFO]: Epoch 045 - training loss: 0.7509, validation loss: 0.9048
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch45_loss0.9048313200473785.pypots
2024-05-24 23:57:14 [INFO]: Epoch 046 - training loss: 0.7531, validation loss: 0.9006
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch46_loss0.9005721658468246.pypots
2024-05-24 23:57:14 [INFO]: Epoch 047 - training loss: 0.7473, validation loss: 0.9029
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch47_loss0.9029258489608765.pypots
2024-05-24 23:57:14 [INFO]: Epoch 048 - training loss: 0.7581, validation loss: 0.9005
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch48_loss0.9004891514778137.pypots
2024-05-24 23:57:14 [INFO]: Epoch 049 - training loss: 0.7478, validation loss: 0.8988
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch49_loss0.8987579196691513.pypots
2024-05-24 23:57:14 [INFO]: Epoch 050 - training loss: 0.7404, validation loss: 0.8969
2024-05-24 23:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch50_loss0.8968679308891296.pypots
2024-05-24 23:57:15 [INFO]: Epoch 051 - training loss: 0.7444, validation loss: 0.8968
2024-05-24 23:57:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch51_loss0.896762028336525.pypots
2024-05-24 23:57:15 [INFO]: Epoch 052 - training loss: 0.7462, validation loss: 0.8949
2024-05-24 23:57:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch52_loss0.8949172496795654.pypots
2024-05-24 23:57:15 [INFO]: Epoch 053 - training loss: 0.7311, validation loss: 0.8931
2024-05-24 23:57:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch53_loss0.8931061327457428.pypots
2024-05-24 23:57:15 [INFO]: Epoch 054 - training loss: 0.7559, validation loss: 0.8904
2024-05-24 23:57:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch54_loss0.8903897851705551.pypots
2024-05-24 23:57:15 [INFO]: Epoch 055 - training loss: 0.7358, validation loss: 0.8917
2024-05-24 23:57:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch55_loss0.8916559964418411.pypots
2024-05-24 23:57:16 [INFO]: Epoch 056 - training loss: 0.7384, validation loss: 0.8916
2024-05-24 23:57:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch56_loss0.8916026800870895.pypots
2024-05-24 23:57:16 [INFO]: Epoch 057 - training loss: 0.7432, validation loss: 0.8902
2024-05-24 23:57:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch57_loss0.8901950269937515.pypots
2024-05-24 23:57:16 [INFO]: Epoch 058 - training loss: 0.7501, validation loss: 0.8873
2024-05-24 23:57:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch58_loss0.8873385936021805.pypots
2024-05-24 23:57:16 [INFO]: Epoch 059 - training loss: 0.7440, validation loss: 0.8866
2024-05-24 23:57:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch59_loss0.8865845948457718.pypots
2024-05-24 23:57:16 [INFO]: Epoch 060 - training loss: 0.7253, validation loss: 0.8882
2024-05-24 23:57:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch60_loss0.8881933838129044.pypots
2024-05-24 23:57:17 [INFO]: Epoch 061 - training loss: 0.7218, validation loss: 0.8858
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch61_loss0.8857870399951935.pypots
2024-05-24 23:57:17 [INFO]: Epoch 062 - training loss: 0.7355, validation loss: 0.8883
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch62_loss0.8882809430360794.pypots
2024-05-24 23:57:17 [INFO]: Epoch 063 - training loss: 0.7424, validation loss: 0.8862
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch63_loss0.886172816157341.pypots
2024-05-24 23:57:17 [INFO]: Epoch 064 - training loss: 0.7386, validation loss: 0.8838
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch64_loss0.8837630301713943.pypots
2024-05-24 23:57:17 [INFO]: Epoch 065 - training loss: 0.7412, validation loss: 0.8821
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch65_loss0.8820715844631195.pypots
2024-05-24 23:57:17 [INFO]: Epoch 066 - training loss: 0.7430, validation loss: 0.8813
2024-05-24 23:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch66_loss0.8812808394432068.pypots
2024-05-24 23:57:18 [INFO]: Epoch 067 - training loss: 0.7407, validation loss: 0.8814
2024-05-24 23:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch67_loss0.8813591748476028.pypots
2024-05-24 23:57:18 [INFO]: Epoch 068 - training loss: 0.7357, validation loss: 0.8821
2024-05-24 23:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch68_loss0.8820979446172714.pypots
2024-05-24 23:57:18 [INFO]: Epoch 069 - training loss: 0.7348, validation loss: 0.8844
2024-05-24 23:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch69_loss0.8843928128480911.pypots
2024-05-24 23:57:18 [INFO]: Epoch 070 - training loss: 0.7482, validation loss: 0.8782
2024-05-24 23:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch70_loss0.8781998306512833.pypots
2024-05-24 23:57:18 [INFO]: Epoch 071 - training loss: 0.7361, validation loss: 0.8807
2024-05-24 23:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch71_loss0.8807282894849777.pypots
2024-05-24 23:57:19 [INFO]: Epoch 072 - training loss: 0.7443, validation loss: 0.8828
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch72_loss0.8828096687793732.pypots
2024-05-24 23:57:19 [INFO]: Epoch 073 - training loss: 0.7497, validation loss: 0.8802
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch73_loss0.8801703304052353.pypots
2024-05-24 23:57:19 [INFO]: Epoch 074 - training loss: 0.7502, validation loss: 0.8827
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch74_loss0.8826734125614166.pypots
2024-05-24 23:57:19 [INFO]: Epoch 075 - training loss: 0.7559, validation loss: 0.8799
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch75_loss0.8799250721931458.pypots
2024-05-24 23:57:19 [INFO]: Epoch 076 - training loss: 0.7634, validation loss: 0.8822
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch76_loss0.8821738213300705.pypots
2024-05-24 23:57:19 [INFO]: Epoch 077 - training loss: 0.7677, validation loss: 0.8809
2024-05-24 23:57:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch77_loss0.8809269368648529.pypots
2024-05-24 23:57:20 [INFO]: Epoch 078 - training loss: 0.7602, validation loss: 0.8830
2024-05-24 23:57:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch78_loss0.8830171674489975.pypots
2024-05-24 23:57:20 [INFO]: Epoch 079 - training loss: 0.7286, validation loss: 0.8816
2024-05-24 23:57:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch79_loss0.8815926313400269.pypots
2024-05-24 23:57:20 [INFO]: Epoch 080 - training loss: 0.7645, validation loss: 0.8798
2024-05-24 23:57:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN_epoch80_loss0.8798192143440247.pypots
2024-05-24 23:57:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:57:20 [INFO]: Finished training. The best model is from epoch#70.
2024-05-24 23:57:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_ettm1/20240524_T235703/MRNN.pypots
2024-05-24 23:57:20 [INFO]: MRNN on ETTm1: MAE=0.8356, MSE=1.5359
2024-05-24 23:57:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-24 23:57:20 [INFO]: Using the given device: cpu
2024-05-24 23:57:20 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-24 23:57:20 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-24 23:57:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-24 23:57:20 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-24 23:57:20 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-24 23:57:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-24 23:57:20 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-24 23:57:20 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-24 23:57:20 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-24 23:57:20 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-24 23:57:20 [INFO]: Using the given device: cuda:0
2024-05-24 23:57:20 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T235720
2024-05-24 23:57:20 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T235720/tensorboard
2024-05-24 23:57:21 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 23:57:21 [INFO]: Epoch 001 - training loss: 1.2032, validation loss: 0.3174
2024-05-24 23:57:22 [INFO]: Epoch 002 - training loss: 0.8670, validation loss: 0.1700
2024-05-24 23:57:22 [INFO]: Epoch 003 - training loss: 0.7544, validation loss: 0.1584
2024-05-24 23:57:23 [INFO]: Epoch 004 - training loss: 0.6823, validation loss: 0.1014
2024-05-24 23:57:23 [INFO]: Epoch 005 - training loss: 0.6537, validation loss: 0.1088
2024-05-24 23:57:24 [INFO]: Epoch 006 - training loss: 0.6030, validation loss: 0.0908
2024-05-24 23:57:24 [INFO]: Epoch 007 - training loss: 0.5905, validation loss: 0.1013
2024-05-24 23:57:25 [INFO]: Epoch 008 - training loss: 0.5701, validation loss: 0.0799
2024-05-24 23:57:25 [INFO]: Epoch 009 - training loss: 0.5735, validation loss: 0.0812
2024-05-24 23:57:26 [INFO]: Epoch 010 - training loss: 0.5698, validation loss: 0.0770
2024-05-24 23:57:26 [INFO]: Epoch 011 - training loss: 0.5427, validation loss: 0.0863
2024-05-24 23:57:27 [INFO]: Epoch 012 - training loss: 0.5247, validation loss: 0.0837
2024-05-24 23:57:27 [INFO]: Epoch 013 - training loss: 0.5193, validation loss: 0.0833
2024-05-24 23:57:28 [INFO]: Epoch 014 - training loss: 0.4990, validation loss: 0.0700
2024-05-24 23:57:28 [INFO]: Epoch 015 - training loss: 0.5040, validation loss: 0.0662
2024-05-24 23:57:29 [INFO]: Epoch 016 - training loss: 0.4941, validation loss: 0.0631
2024-05-24 23:57:29 [INFO]: Epoch 017 - training loss: 0.4874, validation loss: 0.0685
2024-05-24 23:57:30 [INFO]: Epoch 018 - training loss: 0.4816, validation loss: 0.0580
2024-05-24 23:57:30 [INFO]: Epoch 019 - training loss: 0.4568, validation loss: 0.0617
2024-05-24 23:57:31 [INFO]: Epoch 020 - training loss: 0.4550, validation loss: 0.0707
2024-05-24 23:57:31 [INFO]: Epoch 021 - training loss: 0.4726, validation loss: 0.0596
2024-05-24 23:57:32 [INFO]: Epoch 022 - training loss: 0.4555, validation loss: 0.0456
2024-05-24 23:57:32 [INFO]: Epoch 023 - training loss: 0.4510, validation loss: 0.0758
2024-05-24 23:57:33 [INFO]: Epoch 024 - training loss: 0.4416, validation loss: 0.0568
2024-05-24 23:57:33 [INFO]: Epoch 025 - training loss: 0.4300, validation loss: 0.0516
2024-05-24 23:57:34 [INFO]: Epoch 026 - training loss: 0.4527, validation loss: 0.0674
2024-05-24 23:57:34 [INFO]: Epoch 027 - training loss: 0.4421, validation loss: 0.0631
2024-05-24 23:57:35 [INFO]: Epoch 028 - training loss: 0.4380, validation loss: 0.0526
2024-05-24 23:57:35 [INFO]: Epoch 029 - training loss: 0.4172, validation loss: 0.0641
2024-05-24 23:57:36 [INFO]: Epoch 030 - training loss: 0.4275, validation loss: 0.0454
2024-05-24 23:57:36 [INFO]: Epoch 031 - training loss: 0.4024, validation loss: 0.0445
2024-05-24 23:57:37 [INFO]: Epoch 032 - training loss: 0.4051, validation loss: 0.0459
2024-05-24 23:57:37 [INFO]: Epoch 033 - training loss: 0.3926, validation loss: 0.0621
2024-05-24 23:57:38 [INFO]: Epoch 034 - training loss: 0.3882, validation loss: 0.0409
2024-05-24 23:57:38 [INFO]: Epoch 035 - training loss: 0.3855, validation loss: 0.0592
2024-05-24 23:57:39 [INFO]: Epoch 036 - training loss: 0.3817, validation loss: 0.0393
2024-05-24 23:57:39 [INFO]: Epoch 037 - training loss: 0.3820, validation loss: 0.0389
2024-05-24 23:57:40 [INFO]: Epoch 038 - training loss: 0.4101, validation loss: 0.0474
2024-05-24 23:57:40 [INFO]: Epoch 039 - training loss: 0.4119, validation loss: 0.0677
2024-05-24 23:57:41 [INFO]: Epoch 040 - training loss: 0.3965, validation loss: 0.0424
2024-05-24 23:57:41 [INFO]: Epoch 041 - training loss: 0.3872, validation loss: 0.0470
2024-05-24 23:57:42 [INFO]: Epoch 042 - training loss: 0.3758, validation loss: 0.0445
2024-05-24 23:57:42 [INFO]: Epoch 043 - training loss: 0.3643, validation loss: 0.0454
2024-05-24 23:57:43 [INFO]: Epoch 044 - training loss: 0.3580, validation loss: 0.0435
2024-05-24 23:57:43 [INFO]: Epoch 045 - training loss: 0.3660, validation loss: 0.0508
2024-05-24 23:57:44 [INFO]: Epoch 046 - training loss: 0.3557, validation loss: 0.0373
2024-05-24 23:57:44 [INFO]: Epoch 047 - training loss: 0.3587, validation loss: 0.0483
2024-05-24 23:57:45 [INFO]: Epoch 048 - training loss: 0.3507, validation loss: 0.0395
2024-05-24 23:57:46 [INFO]: Epoch 049 - training loss: 0.3477, validation loss: 0.0373
2024-05-24 23:57:46 [INFO]: Epoch 050 - training loss: 0.3396, validation loss: 0.0433
2024-05-24 23:57:47 [INFO]: Epoch 051 - training loss: 0.3398, validation loss: 0.0488
2024-05-24 23:57:47 [INFO]: Epoch 052 - training loss: 0.3429, validation loss: 0.0360
2024-05-24 23:57:48 [INFO]: Epoch 053 - training loss: 0.3365, validation loss: 0.0378
2024-05-24 23:57:48 [INFO]: Epoch 054 - training loss: 0.3436, validation loss: 0.0350
2024-05-24 23:57:49 [INFO]: Epoch 055 - training loss: 0.3332, validation loss: 0.0331
2024-05-24 23:57:49 [INFO]: Epoch 056 - training loss: 0.3457, validation loss: 0.0461
2024-05-24 23:57:50 [INFO]: Epoch 057 - training loss: 0.3386, validation loss: 0.0374
2024-05-24 23:57:50 [INFO]: Epoch 058 - training loss: 0.3330, validation loss: 0.0398
2024-05-24 23:57:51 [INFO]: Epoch 059 - training loss: 0.3324, validation loss: 0.0379
2024-05-24 23:57:51 [INFO]: Epoch 060 - training loss: 0.3174, validation loss: 0.0367
2024-05-24 23:57:52 [INFO]: Epoch 061 - training loss: 0.3183, validation loss: 0.0385
2024-05-24 23:57:52 [INFO]: Epoch 062 - training loss: 0.3215, validation loss: 0.0384
2024-05-24 23:57:53 [INFO]: Epoch 063 - training loss: 0.3251, validation loss: 0.0342
2024-05-24 23:57:53 [INFO]: Epoch 064 - training loss: 0.3267, validation loss: 0.0422
2024-05-24 23:57:54 [INFO]: Epoch 065 - training loss: 0.3231, validation loss: 0.0415
2024-05-24 23:57:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:57:54 [INFO]: Finished training. The best model is from epoch#55.
2024-05-24 23:57:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/SAITS_ettm1/20240524_T235720/SAITS.pypots
2024-05-24 23:57:54 [INFO]: SAITS on ETTm1: MAE=0.1577, MSE=0.0506
2024-05-24 23:57:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-24 23:57:54 [INFO]: Using the given device: cuda:0
2024-05-24 23:57:54 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T235754
2024-05-24 23:57:54 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T235754/tensorboard
2024-05-24 23:57:54 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 23:57:54 [INFO]: Epoch 001 - training loss: 1.1994, validation loss: 0.3902
2024-05-24 23:57:54 [INFO]: Epoch 002 - training loss: 0.7654, validation loss: 0.1775
2024-05-24 23:57:54 [INFO]: Epoch 003 - training loss: 0.6342, validation loss: 0.1313
2024-05-24 23:57:55 [INFO]: Epoch 004 - training loss: 0.5555, validation loss: 0.1029
2024-05-24 23:57:55 [INFO]: Epoch 005 - training loss: 0.5206, validation loss: 0.0883
2024-05-24 23:57:55 [INFO]: Epoch 006 - training loss: 0.4862, validation loss: 0.0859
2024-05-24 23:57:55 [INFO]: Epoch 007 - training loss: 0.4625, validation loss: 0.0799
2024-05-24 23:57:56 [INFO]: Epoch 008 - training loss: 0.4398, validation loss: 0.0731
2024-05-24 23:57:56 [INFO]: Epoch 009 - training loss: 0.4287, validation loss: 0.0625
2024-05-24 23:57:56 [INFO]: Epoch 010 - training loss: 0.4129, validation loss: 0.0695
2024-05-24 23:57:56 [INFO]: Epoch 011 - training loss: 0.4115, validation loss: 0.0584
2024-05-24 23:57:56 [INFO]: Epoch 012 - training loss: 0.3967, validation loss: 0.0577
2024-05-24 23:57:57 [INFO]: Epoch 013 - training loss: 0.3825, validation loss: 0.0557
2024-05-24 23:57:57 [INFO]: Epoch 014 - training loss: 0.3775, validation loss: 0.0586
2024-05-24 23:57:57 [INFO]: Epoch 015 - training loss: 0.3704, validation loss: 0.0485
2024-05-24 23:57:57 [INFO]: Epoch 016 - training loss: 0.3647, validation loss: 0.0515
2024-05-24 23:57:58 [INFO]: Epoch 017 - training loss: 0.3553, validation loss: 0.0471
2024-05-24 23:57:58 [INFO]: Epoch 018 - training loss: 0.3534, validation loss: 0.0531
2024-05-24 23:57:58 [INFO]: Epoch 019 - training loss: 0.3534, validation loss: 0.0468
2024-05-24 23:57:58 [INFO]: Epoch 020 - training loss: 0.3427, validation loss: 0.0453
2024-05-24 23:57:58 [INFO]: Epoch 021 - training loss: 0.3373, validation loss: 0.0443
2024-05-24 23:57:59 [INFO]: Epoch 022 - training loss: 0.3369, validation loss: 0.0485
2024-05-24 23:57:59 [INFO]: Epoch 023 - training loss: 0.3291, validation loss: 0.0432
2024-05-24 23:57:59 [INFO]: Epoch 024 - training loss: 0.3288, validation loss: 0.0457
2024-05-24 23:57:59 [INFO]: Epoch 025 - training loss: 0.3235, validation loss: 0.0486
2024-05-24 23:57:59 [INFO]: Epoch 026 - training loss: 0.3242, validation loss: 0.0480
2024-05-24 23:58:00 [INFO]: Epoch 027 - training loss: 0.3182, validation loss: 0.0454
2024-05-24 23:58:00 [INFO]: Epoch 028 - training loss: 0.3161, validation loss: 0.0391
2024-05-24 23:58:00 [INFO]: Epoch 029 - training loss: 0.3113, validation loss: 0.0409
2024-05-24 23:58:00 [INFO]: Epoch 030 - training loss: 0.3143, validation loss: 0.0395
2024-05-24 23:58:01 [INFO]: Epoch 031 - training loss: 0.2992, validation loss: 0.0369
2024-05-24 23:58:01 [INFO]: Epoch 032 - training loss: 0.2939, validation loss: 0.0398
2024-05-24 23:58:01 [INFO]: Epoch 033 - training loss: 0.2935, validation loss: 0.0380
2024-05-24 23:58:01 [INFO]: Epoch 034 - training loss: 0.2876, validation loss: 0.0383
2024-05-24 23:58:01 [INFO]: Epoch 035 - training loss: 0.2955, validation loss: 0.0356
2024-05-24 23:58:02 [INFO]: Epoch 036 - training loss: 0.2893, validation loss: 0.0381
2024-05-24 23:58:02 [INFO]: Epoch 037 - training loss: 0.2889, validation loss: 0.0329
2024-05-24 23:58:02 [INFO]: Epoch 038 - training loss: 0.2864, validation loss: 0.0369
2024-05-24 23:58:02 [INFO]: Epoch 039 - training loss: 0.2915, validation loss: 0.0366
2024-05-24 23:58:02 [INFO]: Epoch 040 - training loss: 0.2791, validation loss: 0.0327
2024-05-24 23:58:03 [INFO]: Epoch 041 - training loss: 0.2678, validation loss: 0.0331
2024-05-24 23:58:03 [INFO]: Epoch 042 - training loss: 0.2649, validation loss: 0.0362
2024-05-24 23:58:03 [INFO]: Epoch 043 - training loss: 0.2677, validation loss: 0.0316
2024-05-24 23:58:03 [INFO]: Epoch 044 - training loss: 0.2613, validation loss: 0.0323
2024-05-24 23:58:04 [INFO]: Epoch 045 - training loss: 0.2611, validation loss: 0.0328
2024-05-24 23:58:04 [INFO]: Epoch 046 - training loss: 0.2580, validation loss: 0.0324
2024-05-24 23:58:04 [INFO]: Epoch 047 - training loss: 0.2601, validation loss: 0.0347
2024-05-24 23:58:04 [INFO]: Epoch 048 - training loss: 0.2585, validation loss: 0.0318
2024-05-24 23:58:04 [INFO]: Epoch 049 - training loss: 0.2514, validation loss: 0.0293
2024-05-24 23:58:05 [INFO]: Epoch 050 - training loss: 0.2486, validation loss: 0.0332
2024-05-24 23:58:05 [INFO]: Epoch 051 - training loss: 0.2523, validation loss: 0.0320
2024-05-24 23:58:05 [INFO]: Epoch 052 - training loss: 0.2497, validation loss: 0.0318
2024-05-24 23:58:05 [INFO]: Epoch 053 - training loss: 0.2438, validation loss: 0.0300
2024-05-24 23:58:06 [INFO]: Epoch 054 - training loss: 0.2521, validation loss: 0.0286
2024-05-24 23:58:06 [INFO]: Epoch 055 - training loss: 0.2408, validation loss: 0.0297
2024-05-24 23:58:06 [INFO]: Epoch 056 - training loss: 0.2409, validation loss: 0.0276
2024-05-24 23:58:06 [INFO]: Epoch 057 - training loss: 0.2380, validation loss: 0.0297
2024-05-24 23:58:06 [INFO]: Epoch 058 - training loss: 0.2362, validation loss: 0.0286
2024-05-24 23:58:07 [INFO]: Epoch 059 - training loss: 0.2370, validation loss: 0.0278
2024-05-24 23:58:07 [INFO]: Epoch 060 - training loss: 0.2316, validation loss: 0.0281
2024-05-24 23:58:07 [INFO]: Epoch 061 - training loss: 0.2345, validation loss: 0.0304
2024-05-24 23:58:07 [INFO]: Epoch 062 - training loss: 0.2507, validation loss: 0.0352
2024-05-24 23:58:07 [INFO]: Epoch 063 - training loss: 0.2461, validation loss: 0.0282
2024-05-24 23:58:08 [INFO]: Epoch 064 - training loss: 0.2330, validation loss: 0.0295
2024-05-24 23:58:08 [INFO]: Epoch 065 - training loss: 0.2326, validation loss: 0.0292
2024-05-24 23:58:08 [INFO]: Epoch 066 - training loss: 0.2269, validation loss: 0.0297
2024-05-24 23:58:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:58:08 [INFO]: Finished training. The best model is from epoch#56.
2024-05-24 23:58:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/Transformer_ettm1/20240524_T235754/Transformer.pypots
2024-05-24 23:58:08 [INFO]: Transformer on ETTm1: MAE=0.1400, MSE=0.0372
2024-05-24 23:58:08 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-24 23:58:08 [INFO]: Using the given device: cuda:0
2024-05-24 23:58:08 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T235808
2024-05-24 23:58:08 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T235808/tensorboard
2024-05-24 23:58:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 23:58:09 [INFO]: Epoch 001 - training loss: 0.1721, validation loss: 0.0662
2024-05-24 23:58:09 [INFO]: Epoch 002 - training loss: 0.0721, validation loss: 0.0436
2024-05-24 23:58:09 [INFO]: Epoch 003 - training loss: 0.0586, validation loss: 0.0393
2024-05-24 23:58:09 [INFO]: Epoch 004 - training loss: 0.0551, validation loss: 0.0410
2024-05-24 23:58:09 [INFO]: Epoch 005 - training loss: 0.0550, validation loss: 0.0367
2024-05-24 23:58:10 [INFO]: Epoch 006 - training loss: 0.0548, validation loss: 0.0361
2024-05-24 23:58:10 [INFO]: Epoch 007 - training loss: 0.0532, validation loss: 0.0366
2024-05-24 23:58:10 [INFO]: Epoch 008 - training loss: 0.0525, validation loss: 0.0354
2024-05-24 23:58:10 [INFO]: Epoch 009 - training loss: 0.0507, validation loss: 0.0341
2024-05-24 23:58:10 [INFO]: Epoch 010 - training loss: 0.0495, validation loss: 0.0352
2024-05-24 23:58:11 [INFO]: Epoch 011 - training loss: 0.0518, validation loss: 0.0361
2024-05-24 23:58:11 [INFO]: Epoch 012 - training loss: 0.0526, validation loss: 0.0391
2024-05-24 23:58:11 [INFO]: Epoch 013 - training loss: 0.0538, validation loss: 0.0357
2024-05-24 23:58:11 [INFO]: Epoch 014 - training loss: 0.0531, validation loss: 0.0409
2024-05-24 23:58:12 [INFO]: Epoch 015 - training loss: 0.0573, validation loss: 0.0403
2024-05-24 23:58:12 [INFO]: Epoch 016 - training loss: 0.0498, validation loss: 0.0357
2024-05-24 23:58:12 [INFO]: Epoch 017 - training loss: 0.0490, validation loss: 0.0317
2024-05-24 23:58:12 [INFO]: Epoch 018 - training loss: 0.0474, validation loss: 0.0330
2024-05-24 23:58:12 [INFO]: Epoch 019 - training loss: 0.0461, validation loss: 0.0317
2024-05-24 23:58:13 [INFO]: Epoch 020 - training loss: 0.0464, validation loss: 0.0348
2024-05-24 23:58:13 [INFO]: Epoch 021 - training loss: 0.0475, validation loss: 0.0333
2024-05-24 23:58:13 [INFO]: Epoch 022 - training loss: 0.0473, validation loss: 0.0348
2024-05-24 23:58:13 [INFO]: Epoch 023 - training loss: 0.0451, validation loss: 0.0324
2024-05-24 23:58:13 [INFO]: Epoch 024 - training loss: 0.0450, validation loss: 0.0308
2024-05-24 23:58:14 [INFO]: Epoch 025 - training loss: 0.0453, validation loss: 0.0324
2024-05-24 23:58:14 [INFO]: Epoch 026 - training loss: 0.0459, validation loss: 0.0316
2024-05-24 23:58:14 [INFO]: Epoch 027 - training loss: 0.0438, validation loss: 0.0319
2024-05-24 23:58:14 [INFO]: Epoch 028 - training loss: 0.0422, validation loss: 0.0315
2024-05-24 23:58:14 [INFO]: Epoch 029 - training loss: 0.0440, validation loss: 0.0339
2024-05-24 23:58:15 [INFO]: Epoch 030 - training loss: 0.0475, validation loss: 0.0303
2024-05-24 23:58:15 [INFO]: Epoch 031 - training loss: 0.0437, validation loss: 0.0319
2024-05-24 23:58:15 [INFO]: Epoch 032 - training loss: 0.0428, validation loss: 0.0300
2024-05-24 23:58:15 [INFO]: Epoch 033 - training loss: 0.0446, validation loss: 0.0312
2024-05-24 23:58:16 [INFO]: Epoch 034 - training loss: 0.0434, validation loss: 0.0331
2024-05-24 23:58:16 [INFO]: Epoch 035 - training loss: 0.0433, validation loss: 0.0337
2024-05-24 23:58:16 [INFO]: Epoch 036 - training loss: 0.0406, validation loss: 0.0311
2024-05-24 23:58:16 [INFO]: Epoch 037 - training loss: 0.0411, validation loss: 0.0298
2024-05-24 23:58:16 [INFO]: Epoch 038 - training loss: 0.0402, validation loss: 0.0296
2024-05-24 23:58:17 [INFO]: Epoch 039 - training loss: 0.0418, validation loss: 0.0311
2024-05-24 23:58:17 [INFO]: Epoch 040 - training loss: 0.0462, validation loss: 0.0315
2024-05-24 23:58:17 [INFO]: Epoch 041 - training loss: 0.0454, validation loss: 0.0296
2024-05-24 23:58:17 [INFO]: Epoch 042 - training loss: 0.0425, validation loss: 0.0286
2024-05-24 23:58:17 [INFO]: Epoch 043 - training loss: 0.0428, validation loss: 0.0298
2024-05-24 23:58:18 [INFO]: Epoch 044 - training loss: 0.0402, validation loss: 0.0303
2024-05-24 23:58:18 [INFO]: Epoch 045 - training loss: 0.0409, validation loss: 0.0291
2024-05-24 23:58:18 [INFO]: Epoch 046 - training loss: 0.0400, validation loss: 0.0291
2024-05-24 23:58:18 [INFO]: Epoch 047 - training loss: 0.0388, validation loss: 0.0285
2024-05-24 23:58:18 [INFO]: Epoch 048 - training loss: 0.0380, validation loss: 0.0276
2024-05-24 23:58:19 [INFO]: Epoch 049 - training loss: 0.0391, validation loss: 0.0283
2024-05-24 23:58:19 [INFO]: Epoch 050 - training loss: 0.0410, validation loss: 0.0280
2024-05-24 23:58:19 [INFO]: Epoch 051 - training loss: 0.0419, validation loss: 0.0308
2024-05-24 23:58:19 [INFO]: Epoch 052 - training loss: 0.0432, validation loss: 0.0308
2024-05-24 23:58:20 [INFO]: Epoch 053 - training loss: 0.0379, validation loss: 0.0278
2024-05-24 23:58:20 [INFO]: Epoch 054 - training loss: 0.0394, validation loss: 0.0297
2024-05-24 23:58:20 [INFO]: Epoch 055 - training loss: 0.0393, validation loss: 0.0266
2024-05-24 23:58:20 [INFO]: Epoch 056 - training loss: 0.0407, validation loss: 0.0270
2024-05-24 23:58:20 [INFO]: Epoch 057 - training loss: 0.0394, validation loss: 0.0270
2024-05-24 23:58:21 [INFO]: Epoch 058 - training loss: 0.0375, validation loss: 0.0274
2024-05-24 23:58:21 [INFO]: Epoch 059 - training loss: 0.0408, validation loss: 0.0286
2024-05-24 23:58:21 [INFO]: Epoch 060 - training loss: 0.0385, validation loss: 0.0278
2024-05-24 23:58:21 [INFO]: Epoch 061 - training loss: 0.0365, validation loss: 0.0263
2024-05-24 23:58:21 [INFO]: Epoch 062 - training loss: 0.0359, validation loss: 0.0264
2024-05-24 23:58:22 [INFO]: Epoch 063 - training loss: 0.0371, validation loss: 0.0262
2024-05-24 23:58:22 [INFO]: Epoch 064 - training loss: 0.0356, validation loss: 0.0264
2024-05-24 23:58:22 [INFO]: Epoch 065 - training loss: 0.0355, validation loss: 0.0261
2024-05-24 23:58:22 [INFO]: Epoch 066 - training loss: 0.0359, validation loss: 0.0269
2024-05-24 23:58:22 [INFO]: Epoch 067 - training loss: 0.0363, validation loss: 0.0275
2024-05-24 23:58:23 [INFO]: Epoch 068 - training loss: 0.0361, validation loss: 0.0274
2024-05-24 23:58:23 [INFO]: Epoch 069 - training loss: 0.0375, validation loss: 0.0269
2024-05-24 23:58:23 [INFO]: Epoch 070 - training loss: 0.0389, validation loss: 0.0268
2024-05-24 23:58:23 [INFO]: Epoch 071 - training loss: 0.0358, validation loss: 0.0264
2024-05-24 23:58:24 [INFO]: Epoch 072 - training loss: 0.0360, validation loss: 0.0271
2024-05-24 23:58:24 [INFO]: Epoch 073 - training loss: 0.0357, validation loss: 0.0272
2024-05-24 23:58:24 [INFO]: Epoch 074 - training loss: 0.0351, validation loss: 0.0264
2024-05-24 23:58:24 [INFO]: Epoch 075 - training loss: 0.0339, validation loss: 0.0277
2024-05-24 23:58:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:58:24 [INFO]: Finished training. The best model is from epoch#65.
2024-05-24 23:58:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/TimesNet_ettm1/20240524_T235808/TimesNet.pypots
2024-05-24 23:58:24 [INFO]: TimesNet on ETTm1: MAE=0.1224, MSE=0.0323
2024-05-24 23:58:24 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-24 23:58:24 [INFO]: Using the given device: cuda:0
2024-05-24 23:58:24 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824
2024-05-24 23:58:24 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/tensorboard
2024-05-24 23:58:24 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 23:58:26 [INFO]: Epoch 001 - training loss: 0.7030, validation loss: 0.4458
2024-05-24 23:58:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch1_loss0.44584931433200836.pypots
2024-05-24 23:58:28 [INFO]: Epoch 002 - training loss: 0.3815, validation loss: 0.3653
2024-05-24 23:58:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch2_loss0.3652917966246605.pypots
2024-05-24 23:58:30 [INFO]: Epoch 003 - training loss: 0.3379, validation loss: 0.3735
2024-05-24 23:58:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch3_loss0.37348028272390366.pypots
2024-05-24 23:58:33 [INFO]: Epoch 004 - training loss: 0.3466, validation loss: 0.3186
2024-05-24 23:58:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch4_loss0.31857892870903015.pypots
2024-05-24 23:58:35 [INFO]: Epoch 005 - training loss: 0.3043, validation loss: 0.3043
2024-05-24 23:58:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch5_loss0.30432356894016266.pypots
2024-05-24 23:58:37 [INFO]: Epoch 006 - training loss: 0.2866, validation loss: 0.2796
2024-05-24 23:58:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch6_loss0.2795695513486862.pypots
2024-05-24 23:58:39 [INFO]: Epoch 007 - training loss: 0.3193, validation loss: 0.3984
2024-05-24 23:58:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch7_loss0.3983698710799217.pypots
2024-05-24 23:58:41 [INFO]: Epoch 008 - training loss: 0.4051, validation loss: 0.3118
2024-05-24 23:58:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch8_loss0.31175386905670166.pypots
2024-05-24 23:58:43 [INFO]: Epoch 009 - training loss: 0.2736, validation loss: 0.2960
2024-05-24 23:58:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch9_loss0.29601960629224777.pypots
2024-05-24 23:58:45 [INFO]: Epoch 010 - training loss: 0.3060, validation loss: 0.3072
2024-05-24 23:58:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch10_loss0.30723807215690613.pypots
2024-05-24 23:58:47 [INFO]: Epoch 011 - training loss: 0.2912, validation loss: 0.2965
2024-05-24 23:58:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch11_loss0.29654505103826523.pypots
2024-05-24 23:58:49 [INFO]: Epoch 012 - training loss: 0.2256, validation loss: 0.2735
2024-05-24 23:58:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch12_loss0.27351608127355576.pypots
2024-05-24 23:58:51 [INFO]: Epoch 013 - training loss: 0.2518, validation loss: 0.2741
2024-05-24 23:58:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch13_loss0.27409371733665466.pypots
2024-05-24 23:58:53 [INFO]: Epoch 014 - training loss: 0.2288, validation loss: 0.2639
2024-05-24 23:58:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch14_loss0.2638746500015259.pypots
2024-05-24 23:58:55 [INFO]: Epoch 015 - training loss: 0.2264, validation loss: 0.2571
2024-05-24 23:58:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch15_loss0.25708938390016556.pypots
2024-05-24 23:58:57 [INFO]: Epoch 016 - training loss: 0.2418, validation loss: 0.2657
2024-05-24 23:58:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch16_loss0.26568973809480667.pypots
2024-05-24 23:59:00 [INFO]: Epoch 017 - training loss: 0.2696, validation loss: 0.2562
2024-05-24 23:59:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch17_loss0.25621695071458817.pypots
2024-05-24 23:59:02 [INFO]: Epoch 018 - training loss: 0.2434, validation loss: 0.2293
2024-05-24 23:59:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch18_loss0.22934415563941002.pypots
2024-05-24 23:59:04 [INFO]: Epoch 019 - training loss: 0.2247, validation loss: 0.2296
2024-05-24 23:59:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch19_loss0.22956563904881477.pypots
2024-05-24 23:59:06 [INFO]: Epoch 020 - training loss: 0.2437, validation loss: 0.2286
2024-05-24 23:59:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch20_loss0.2286434881389141.pypots
2024-05-24 23:59:08 [INFO]: Epoch 021 - training loss: 0.2148, validation loss: 0.2193
2024-05-24 23:59:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch21_loss0.21925777941942215.pypots
2024-05-24 23:59:10 [INFO]: Epoch 022 - training loss: 0.2066, validation loss: 0.2244
2024-05-24 23:59:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch22_loss0.22437868267297745.pypots
2024-05-24 23:59:12 [INFO]: Epoch 023 - training loss: 0.2309, validation loss: 0.2050
2024-05-24 23:59:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch23_loss0.20500019937753677.pypots
2024-05-24 23:59:14 [INFO]: Epoch 024 - training loss: 0.1995, validation loss: 0.1981
2024-05-24 23:59:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch24_loss0.1981443278491497.pypots
2024-05-24 23:59:16 [INFO]: Epoch 025 - training loss: 0.2382, validation loss: 0.1984
2024-05-24 23:59:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch25_loss0.198362335562706.pypots
2024-05-24 23:59:18 [INFO]: Epoch 026 - training loss: 0.1920, validation loss: 0.1967
2024-05-24 23:59:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch26_loss0.19666507840156555.pypots
2024-05-24 23:59:20 [INFO]: Epoch 027 - training loss: 0.2071, validation loss: 0.1854
2024-05-24 23:59:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch27_loss0.18544934689998627.pypots
2024-05-24 23:59:22 [INFO]: Epoch 028 - training loss: 0.2153, validation loss: 0.1881
2024-05-24 23:59:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch28_loss0.18807975947856903.pypots
2024-05-24 23:59:24 [INFO]: Epoch 029 - training loss: 0.2337, validation loss: 0.1931
2024-05-24 23:59:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch29_loss0.1930798813700676.pypots
2024-05-24 23:59:27 [INFO]: Epoch 030 - training loss: 0.2723, validation loss: 0.1901
2024-05-24 23:59:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch30_loss0.19008218497037888.pypots
2024-05-24 23:59:29 [INFO]: Epoch 031 - training loss: 0.2120, validation loss: 0.1765
2024-05-24 23:59:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch31_loss0.17647574841976166.pypots
2024-05-24 23:59:31 [INFO]: Epoch 032 - training loss: 0.1764, validation loss: 0.1776
2024-05-24 23:59:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch32_loss0.17760131508111954.pypots
2024-05-24 23:59:33 [INFO]: Epoch 033 - training loss: 0.1869, validation loss: 0.1723
2024-05-24 23:59:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch33_loss0.1723068468272686.pypots
2024-05-24 23:59:35 [INFO]: Epoch 034 - training loss: 0.2689, validation loss: 0.1830
2024-05-24 23:59:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch34_loss0.18298331275582314.pypots
2024-05-24 23:59:37 [INFO]: Epoch 035 - training loss: 0.1738, validation loss: 0.1710
2024-05-24 23:59:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch35_loss0.17098859325051308.pypots
2024-05-24 23:59:39 [INFO]: Epoch 036 - training loss: 0.2576, validation loss: 0.1714
2024-05-24 23:59:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch36_loss0.1713550090789795.pypots
2024-05-24 23:59:41 [INFO]: Epoch 037 - training loss: 0.1876, validation loss: 0.1761
2024-05-24 23:59:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch37_loss0.17608637735247612.pypots
2024-05-24 23:59:43 [INFO]: Epoch 038 - training loss: 0.2376, validation loss: 0.1656
2024-05-24 23:59:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch38_loss0.16557396575808525.pypots
2024-05-24 23:59:45 [INFO]: Epoch 039 - training loss: 0.1821, validation loss: 0.1637
2024-05-24 23:59:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch39_loss0.1636749431490898.pypots
2024-05-24 23:59:47 [INFO]: Epoch 040 - training loss: 0.2019, validation loss: 0.1640
2024-05-24 23:59:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch40_loss0.16396621242165565.pypots
2024-05-24 23:59:49 [INFO]: Epoch 041 - training loss: 0.1840, validation loss: 0.1634
2024-05-24 23:59:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch41_loss0.16337357461452484.pypots
2024-05-24 23:59:51 [INFO]: Epoch 042 - training loss: 0.1843, validation loss: 0.1602
2024-05-24 23:59:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch42_loss0.1602180078625679.pypots
2024-05-24 23:59:54 [INFO]: Epoch 043 - training loss: 0.1871, validation loss: 0.1596
2024-05-24 23:59:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch43_loss0.15964233875274658.pypots
2024-05-24 23:59:56 [INFO]: Epoch 044 - training loss: 0.1980, validation loss: 0.1925
2024-05-24 23:59:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch44_loss0.19253156334161758.pypots
2024-05-24 23:59:58 [INFO]: Epoch 045 - training loss: 0.2083, validation loss: 0.1875
2024-05-24 23:59:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch45_loss0.1875343956053257.pypots
2024-05-25 00:00:00 [INFO]: Epoch 046 - training loss: 0.2159, validation loss: 0.1727
2024-05-25 00:00:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch46_loss0.17267543822526932.pypots
2024-05-25 00:00:02 [INFO]: Epoch 047 - training loss: 0.1956, validation loss: 0.1644
2024-05-25 00:00:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch47_loss0.16436878219246864.pypots
2024-05-25 00:00:04 [INFO]: Epoch 048 - training loss: 0.2274, validation loss: 0.1713
2024-05-25 00:00:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch48_loss0.17125869914889336.pypots
2024-05-25 00:00:06 [INFO]: Epoch 049 - training loss: 0.2160, validation loss: 0.1739
2024-05-25 00:00:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch49_loss0.17389390245079994.pypots
2024-05-25 00:00:08 [INFO]: Epoch 050 - training loss: 0.1926, validation loss: 0.1602
2024-05-25 00:00:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch50_loss0.1602102294564247.pypots
2024-05-25 00:00:10 [INFO]: Epoch 051 - training loss: 0.1898, validation loss: 0.1498
2024-05-25 00:00:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch51_loss0.14975452423095703.pypots
2024-05-25 00:00:12 [INFO]: Epoch 052 - training loss: 0.1875, validation loss: 0.1546
2024-05-25 00:00:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch52_loss0.15455835685133934.pypots
2024-05-25 00:00:14 [INFO]: Epoch 053 - training loss: 0.1834, validation loss: 0.1658
2024-05-25 00:00:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch53_loss0.16577153280377388.pypots
2024-05-25 00:00:16 [INFO]: Epoch 054 - training loss: 0.1642, validation loss: 0.1505
2024-05-25 00:00:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch54_loss0.15047195181250572.pypots
2024-05-25 00:00:18 [INFO]: Epoch 055 - training loss: 0.2054, validation loss: 0.1461
2024-05-25 00:00:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch55_loss0.14610398933291435.pypots
2024-05-25 00:00:20 [INFO]: Epoch 056 - training loss: 0.2149, validation loss: 0.1434
2024-05-25 00:00:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch56_loss0.14337535202503204.pypots
2024-05-25 00:00:23 [INFO]: Epoch 057 - training loss: 0.1834, validation loss: 0.1490
2024-05-25 00:00:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch57_loss0.14896398037672043.pypots
2024-05-25 00:00:25 [INFO]: Epoch 058 - training loss: 0.1828, validation loss: 0.1454
2024-05-25 00:00:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch58_loss0.14535290747880936.pypots
2024-05-25 00:00:27 [INFO]: Epoch 059 - training loss: 0.1824, validation loss: 0.1419
2024-05-25 00:00:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch59_loss0.14191735908389091.pypots
2024-05-25 00:00:29 [INFO]: Epoch 060 - training loss: 0.1675, validation loss: 0.1398
2024-05-25 00:00:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch60_loss0.13982906192541122.pypots
2024-05-25 00:00:31 [INFO]: Epoch 061 - training loss: 0.1783, validation loss: 0.1399
2024-05-25 00:00:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch61_loss0.13988832384347916.pypots
2024-05-25 00:00:33 [INFO]: Epoch 062 - training loss: 0.1651, validation loss: 0.1405
2024-05-25 00:00:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch62_loss0.14053770527243614.pypots
2024-05-25 00:00:35 [INFO]: Epoch 063 - training loss: 0.1711, validation loss: 0.1381
2024-05-25 00:00:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch63_loss0.13813555613160133.pypots
2024-05-25 00:00:37 [INFO]: Epoch 064 - training loss: 0.2040, validation loss: 0.1392
2024-05-25 00:00:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch64_loss0.13919886946678162.pypots
2024-05-25 00:00:39 [INFO]: Epoch 065 - training loss: 0.1778, validation loss: 0.1460
2024-05-25 00:00:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch65_loss0.14595367014408112.pypots
2024-05-25 00:00:41 [INFO]: Epoch 066 - training loss: 0.1385, validation loss: 0.1395
2024-05-25 00:00:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch66_loss0.1394762247800827.pypots
2024-05-25 00:00:43 [INFO]: Epoch 067 - training loss: 0.1632, validation loss: 0.1346
2024-05-25 00:00:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch67_loss0.13455859385430813.pypots
2024-05-25 00:00:45 [INFO]: Epoch 068 - training loss: 0.2411, validation loss: 0.1423
2024-05-25 00:00:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch68_loss0.14234425872564316.pypots
2024-05-25 00:00:47 [INFO]: Epoch 069 - training loss: 0.1449, validation loss: 0.1341
2024-05-25 00:00:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch69_loss0.13410957716405392.pypots
2024-05-25 00:00:50 [INFO]: Epoch 070 - training loss: 0.1662, validation loss: 0.1335
2024-05-25 00:00:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch70_loss0.13354241661727428.pypots
2024-05-25 00:00:52 [INFO]: Epoch 071 - training loss: 0.1728, validation loss: 0.1329
2024-05-25 00:00:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch71_loss0.1328920405358076.pypots
2024-05-25 00:00:54 [INFO]: Epoch 072 - training loss: 0.1681, validation loss: 0.1323
2024-05-25 00:00:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch72_loss0.13228750973939896.pypots
2024-05-25 00:00:56 [INFO]: Epoch 073 - training loss: 0.1569, validation loss: 0.1302
2024-05-25 00:00:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch73_loss0.13023427315056324.pypots
2024-05-25 00:00:58 [INFO]: Epoch 074 - training loss: 0.2023, validation loss: 0.1323
2024-05-25 00:00:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch74_loss0.13228870928287506.pypots
2024-05-25 00:01:00 [INFO]: Epoch 075 - training loss: 0.1779, validation loss: 0.1356
2024-05-25 00:01:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch75_loss0.13557544723153114.pypots
2024-05-25 00:01:02 [INFO]: Epoch 076 - training loss: 0.1483, validation loss: 0.1321
2024-05-25 00:01:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch76_loss0.13214120268821716.pypots
2024-05-25 00:01:04 [INFO]: Epoch 077 - training loss: 0.1604, validation loss: 0.1315
2024-05-25 00:01:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch77_loss0.13151472061872482.pypots
2024-05-25 00:01:06 [INFO]: Epoch 078 - training loss: 0.1616, validation loss: 0.1344
2024-05-25 00:01:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch78_loss0.13439391180872917.pypots
2024-05-25 00:01:08 [INFO]: Epoch 079 - training loss: 0.1741, validation loss: 0.1353
2024-05-25 00:01:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch79_loss0.13531047105789185.pypots
2024-05-25 00:01:10 [INFO]: Epoch 080 - training loss: 0.1685, validation loss: 0.1338
2024-05-25 00:01:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch80_loss0.13377939350903034.pypots
2024-05-25 00:01:12 [INFO]: Epoch 081 - training loss: 0.2282, validation loss: 0.1400
2024-05-25 00:01:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch81_loss0.13999539986252785.pypots
2024-05-25 00:01:14 [INFO]: Epoch 082 - training loss: 0.1640, validation loss: 0.1406
2024-05-25 00:01:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch82_loss0.1406077966094017.pypots
2024-05-25 00:01:17 [INFO]: Epoch 083 - training loss: 0.1451, validation loss: 0.1389
2024-05-25 00:01:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI_epoch83_loss0.13889050111174583.pypots
2024-05-25 00:01:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:01:17 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 00:01:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_ettm1/20240524_T235824/CSDI.pypots
2024-05-25 00:01:32 [INFO]: CSDI on ETTm1: MAE=0.1917, MSE=0.3313
2024-05-25 00:01:32 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-25 00:01:32 [INFO]: Using the given device: cuda:0
2024-05-25 00:01:32 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240525_T000132
2024-05-25 00:01:32 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240525_T000132/tensorboard
2024-05-25 00:01:32 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 00:01:33 [INFO]: Epoch 001 - training loss: 23502.1493, validation loss: 0.9664
2024-05-25 00:01:33 [INFO]: Epoch 002 - training loss: 21499.0028, validation loss: 0.9561
2024-05-25 00:01:33 [INFO]: Epoch 003 - training loss: 19377.3470, validation loss: 0.9422
2024-05-25 00:01:33 [INFO]: Epoch 004 - training loss: 17420.0656, validation loss: 0.9197
2024-05-25 00:01:33 [INFO]: Epoch 005 - training loss: 15839.6638, validation loss: 0.8844
2024-05-25 00:01:33 [INFO]: Epoch 006 - training loss: 14017.7653, validation loss: 0.8084
2024-05-25 00:01:33 [INFO]: Epoch 007 - training loss: 12944.3000, validation loss: 0.6857
2024-05-25 00:01:33 [INFO]: Epoch 008 - training loss: 12017.0456, validation loss: 0.5879
2024-05-25 00:01:34 [INFO]: Epoch 009 - training loss: 11499.3098, validation loss: 0.5464
2024-05-25 00:01:34 [INFO]: Epoch 010 - training loss: 10973.1829, validation loss: 0.5110
2024-05-25 00:01:34 [INFO]: Epoch 011 - training loss: 10703.8190, validation loss: 0.4868
2024-05-25 00:01:34 [INFO]: Epoch 012 - training loss: 10421.2120, validation loss: 0.4800
2024-05-25 00:01:34 [INFO]: Epoch 013 - training loss: 10276.7355, validation loss: 0.4734
2024-05-25 00:01:34 [INFO]: Epoch 014 - training loss: 10114.1820, validation loss: 0.4693
2024-05-25 00:01:34 [INFO]: Epoch 015 - training loss: 10077.3016, validation loss: 0.4657
2024-05-25 00:01:35 [INFO]: Epoch 016 - training loss: 9968.1741, validation loss: 0.4601
2024-05-25 00:01:35 [INFO]: Epoch 017 - training loss: 9828.5169, validation loss: 0.4526
2024-05-25 00:01:35 [INFO]: Epoch 018 - training loss: 9798.5845, validation loss: 0.4468
2024-05-25 00:01:35 [INFO]: Epoch 019 - training loss: 9719.4944, validation loss: 0.4380
2024-05-25 00:01:35 [INFO]: Epoch 020 - training loss: 9685.6315, validation loss: 0.4256
2024-05-25 00:01:35 [INFO]: Epoch 021 - training loss: 9717.9357, validation loss: 0.4157
2024-05-25 00:01:35 [INFO]: Epoch 022 - training loss: 9631.8273, validation loss: 0.3991
2024-05-25 00:01:35 [INFO]: Epoch 023 - training loss: 9576.3655, validation loss: 0.3853
2024-05-25 00:01:36 [INFO]: Epoch 024 - training loss: 9542.1366, validation loss: 0.3718
2024-05-25 00:01:36 [INFO]: Epoch 025 - training loss: 9522.7321, validation loss: 0.3563
2024-05-25 00:01:36 [INFO]: Epoch 026 - training loss: 9500.5381, validation loss: 0.3439
2024-05-25 00:01:36 [INFO]: Epoch 027 - training loss: 9462.5161, validation loss: 0.3246
2024-05-25 00:01:36 [INFO]: Epoch 028 - training loss: 9448.4682, validation loss: 0.3124
2024-05-25 00:01:36 [INFO]: Epoch 029 - training loss: 9452.8464, validation loss: 0.2970
2024-05-25 00:01:36 [INFO]: Epoch 030 - training loss: 9441.0306, validation loss: 0.2838
2024-05-25 00:01:36 [INFO]: Epoch 031 - training loss: 9464.0948, validation loss: 0.2748
2024-05-25 00:01:37 [INFO]: Epoch 032 - training loss: 9423.7773, validation loss: 0.2676
2024-05-25 00:01:37 [INFO]: Epoch 033 - training loss: 9378.4521, validation loss: 0.2615
2024-05-25 00:01:37 [INFO]: Epoch 034 - training loss: 9372.6341, validation loss: 0.2576
2024-05-25 00:01:37 [INFO]: Epoch 035 - training loss: 9441.5856, validation loss: 0.2533
2024-05-25 00:01:37 [INFO]: Epoch 036 - training loss: 9369.7206, validation loss: 0.2509
2024-05-25 00:01:37 [INFO]: Epoch 037 - training loss: 9357.3260, validation loss: 0.2445
2024-05-25 00:01:37 [INFO]: Epoch 038 - training loss: 9349.7515, validation loss: 0.2432
2024-05-25 00:01:37 [INFO]: Epoch 039 - training loss: 9359.8336, validation loss: 0.2382
2024-05-25 00:01:38 [INFO]: Epoch 040 - training loss: 9349.1554, validation loss: 0.2346
2024-05-25 00:01:38 [INFO]: Epoch 041 - training loss: 9329.6202, validation loss: 0.2311
2024-05-25 00:01:38 [INFO]: Epoch 042 - training loss: 9322.0405, validation loss: 0.2248
2024-05-25 00:01:38 [INFO]: Epoch 043 - training loss: 9318.0880, validation loss: 0.2251
2024-05-25 00:01:38 [INFO]: Epoch 044 - training loss: 9341.3533, validation loss: 0.2233
2024-05-25 00:01:38 [INFO]: Epoch 045 - training loss: 9318.9253, validation loss: 0.2188
2024-05-25 00:01:38 [INFO]: Epoch 046 - training loss: 9313.7510, validation loss: 0.2159
2024-05-25 00:01:38 [INFO]: Epoch 047 - training loss: 9303.5953, validation loss: 0.2139
2024-05-25 00:01:39 [INFO]: Epoch 048 - training loss: 9295.4715, validation loss: 0.2123
2024-05-25 00:01:39 [INFO]: Epoch 049 - training loss: 9296.1588, validation loss: 0.2114
2024-05-25 00:01:39 [INFO]: Epoch 050 - training loss: 9292.9073, validation loss: 0.2071
2024-05-25 00:01:39 [INFO]: Epoch 051 - training loss: 9288.0405, validation loss: 0.2034
2024-05-25 00:01:39 [INFO]: Epoch 052 - training loss: 9292.1317, validation loss: 0.2027
2024-05-25 00:01:39 [INFO]: Epoch 053 - training loss: 9285.0815, validation loss: 0.1992
2024-05-25 00:01:39 [INFO]: Epoch 054 - training loss: 9289.7028, validation loss: 0.1951
2024-05-25 00:01:39 [INFO]: Epoch 055 - training loss: 9280.8779, validation loss: 0.1908
2024-05-25 00:01:40 [INFO]: Epoch 056 - training loss: 9279.5363, validation loss: 0.1878
2024-05-25 00:01:40 [INFO]: Epoch 057 - training loss: 9288.0380, validation loss: 0.1862
2024-05-25 00:01:40 [INFO]: Epoch 058 - training loss: 9275.3014, validation loss: 0.1835
2024-05-25 00:01:40 [INFO]: Epoch 059 - training loss: 9272.6655, validation loss: 0.1802
2024-05-25 00:01:40 [INFO]: Epoch 060 - training loss: 9269.3036, validation loss: 0.1785
2024-05-25 00:01:40 [INFO]: Epoch 061 - training loss: 9268.0016, validation loss: 0.1782
2024-05-25 00:01:40 [INFO]: Epoch 062 - training loss: 9267.3727, validation loss: 0.1729
2024-05-25 00:01:40 [INFO]: Epoch 063 - training loss: 9266.6070, validation loss: 0.1698
2024-05-25 00:01:41 [INFO]: Epoch 064 - training loss: 9263.3654, validation loss: 0.1697
2024-05-25 00:01:41 [INFO]: Epoch 065 - training loss: 9260.1842, validation loss: 0.1652
2024-05-25 00:01:41 [INFO]: Epoch 066 - training loss: 9259.6804, validation loss: 0.1638
2024-05-25 00:01:41 [INFO]: Epoch 067 - training loss: 9260.1164, validation loss: 0.1620
2024-05-25 00:01:41 [INFO]: Epoch 068 - training loss: 9256.7967, validation loss: 0.1614
2024-05-25 00:01:41 [INFO]: Epoch 069 - training loss: 9258.2500, validation loss: 0.1576
2024-05-25 00:01:41 [INFO]: Epoch 070 - training loss: 9254.6061, validation loss: 0.1567
2024-05-25 00:01:42 [INFO]: Epoch 071 - training loss: 9253.3417, validation loss: 0.1542
2024-05-25 00:01:42 [INFO]: Epoch 072 - training loss: 9252.8459, validation loss: 0.1523
2024-05-25 00:01:42 [INFO]: Epoch 073 - training loss: 9260.7452, validation loss: 0.1523
2024-05-25 00:01:42 [INFO]: Epoch 074 - training loss: 9249.4564, validation loss: 0.1495
2024-05-25 00:01:42 [INFO]: Epoch 075 - training loss: 9248.5499, validation loss: 0.1481
2024-05-25 00:01:42 [INFO]: Epoch 076 - training loss: 9245.5161, validation loss: 0.1470
2024-05-25 00:01:42 [INFO]: Epoch 077 - training loss: 9244.5160, validation loss: 0.1461
2024-05-25 00:01:42 [INFO]: Epoch 078 - training loss: 9247.6806, validation loss: 0.1456
2024-05-25 00:01:43 [INFO]: Epoch 079 - training loss: 9245.3774, validation loss: 0.1444
2024-05-25 00:01:43 [INFO]: Epoch 080 - training loss: 9248.1170, validation loss: 0.1407
2024-05-25 00:01:43 [INFO]: Epoch 081 - training loss: 9247.2842, validation loss: 0.1417
2024-05-25 00:01:43 [INFO]: Epoch 082 - training loss: 9243.5444, validation loss: 0.1412
2024-05-25 00:01:43 [INFO]: Epoch 083 - training loss: 9241.5576, validation loss: 0.1391
2024-05-25 00:01:43 [INFO]: Epoch 084 - training loss: 9242.2156, validation loss: 0.1384
2024-05-25 00:01:43 [INFO]: Epoch 085 - training loss: 9238.6407, validation loss: 0.1375
2024-05-25 00:01:43 [INFO]: Epoch 086 - training loss: 9240.0034, validation loss: 0.1370
2024-05-25 00:01:44 [INFO]: Epoch 087 - training loss: 9239.9738, validation loss: 0.1358
2024-05-25 00:01:44 [INFO]: Epoch 088 - training loss: 9237.2362, validation loss: 0.1354
2024-05-25 00:01:44 [INFO]: Epoch 089 - training loss: 9236.7552, validation loss: 0.1363
2024-05-25 00:01:44 [INFO]: Epoch 090 - training loss: 9236.0304, validation loss: 0.1333
2024-05-25 00:01:44 [INFO]: Epoch 091 - training loss: 9238.6199, validation loss: 0.1351
2024-05-25 00:01:44 [INFO]: Epoch 092 - training loss: 9236.8108, validation loss: 0.1331
2024-05-25 00:01:44 [INFO]: Epoch 093 - training loss: 9235.0890, validation loss: 0.1312
2024-05-25 00:01:44 [INFO]: Epoch 094 - training loss: 9235.0837, validation loss: 0.1313
2024-05-25 00:01:45 [INFO]: Epoch 095 - training loss: 9234.7322, validation loss: 0.1280
2024-05-25 00:01:45 [INFO]: Epoch 096 - training loss: 9233.2586, validation loss: 0.1298
2024-05-25 00:01:45 [INFO]: Epoch 097 - training loss: 9239.9391, validation loss: 0.1296
2024-05-25 00:01:45 [INFO]: Epoch 098 - training loss: 9232.5481, validation loss: 0.1281
2024-05-25 00:01:45 [INFO]: Epoch 099 - training loss: 9231.5640, validation loss: 0.1274
2024-05-25 00:01:45 [INFO]: Epoch 100 - training loss: 9232.1863, validation loss: 0.1257
2024-05-25 00:01:45 [INFO]: Epoch 101 - training loss: 9230.0564, validation loss: 0.1253
2024-05-25 00:01:45 [INFO]: Epoch 102 - training loss: 9230.2852, validation loss: 0.1256
2024-05-25 00:01:46 [INFO]: Epoch 103 - training loss: 9235.3130, validation loss: 0.1256
2024-05-25 00:01:46 [INFO]: Epoch 104 - training loss: 9232.5399, validation loss: 0.1258
2024-05-25 00:01:46 [INFO]: Epoch 105 - training loss: 9231.0806, validation loss: 0.1227
2024-05-25 00:01:46 [INFO]: Epoch 106 - training loss: 9229.8380, validation loss: 0.1232
2024-05-25 00:01:46 [INFO]: Epoch 107 - training loss: 9230.4723, validation loss: 0.1209
2024-05-25 00:01:46 [INFO]: Epoch 108 - training loss: 9229.7149, validation loss: 0.1207
2024-05-25 00:01:46 [INFO]: Epoch 109 - training loss: 9228.8328, validation loss: 0.1202
2024-05-25 00:01:46 [INFO]: Epoch 110 - training loss: 9230.2335, validation loss: 0.1213
2024-05-25 00:01:47 [INFO]: Epoch 111 - training loss: 9226.5978, validation loss: 0.1196
2024-05-25 00:01:47 [INFO]: Epoch 112 - training loss: 9226.4502, validation loss: 0.1191
2024-05-25 00:01:47 [INFO]: Epoch 113 - training loss: 9227.6790, validation loss: 0.1198
2024-05-25 00:01:47 [INFO]: Epoch 114 - training loss: 9223.2781, validation loss: 0.1162
2024-05-25 00:01:47 [INFO]: Epoch 115 - training loss: 9224.4188, validation loss: 0.1168
2024-05-25 00:01:47 [INFO]: Epoch 116 - training loss: 9225.0453, validation loss: 0.1185
2024-05-25 00:01:47 [INFO]: Epoch 117 - training loss: 9224.9770, validation loss: 0.1170
2024-05-25 00:01:47 [INFO]: Epoch 118 - training loss: 9226.4888, validation loss: 0.1163
2024-05-25 00:01:48 [INFO]: Epoch 119 - training loss: 9224.3082, validation loss: 0.1143
2024-05-25 00:01:48 [INFO]: Epoch 120 - training loss: 9227.3365, validation loss: 0.1143
2024-05-25 00:01:48 [INFO]: Epoch 121 - training loss: 9222.7509, validation loss: 0.1131
2024-05-25 00:01:48 [INFO]: Epoch 122 - training loss: 9222.3054, validation loss: 0.1125
2024-05-25 00:01:48 [INFO]: Epoch 123 - training loss: 9221.7517, validation loss: 0.1141
2024-05-25 00:01:48 [INFO]: Epoch 124 - training loss: 9222.1957, validation loss: 0.1131
2024-05-25 00:01:49 [INFO]: Epoch 125 - training loss: 9221.9507, validation loss: 0.1115
2024-05-25 00:01:49 [INFO]: Epoch 126 - training loss: 9222.7906, validation loss: 0.1121
2024-05-25 00:01:49 [INFO]: Epoch 127 - training loss: 9221.4396, validation loss: 0.1113
2024-05-25 00:01:49 [INFO]: Epoch 128 - training loss: 9222.4945, validation loss: 0.1106
2024-05-25 00:01:49 [INFO]: Epoch 129 - training loss: 9222.5153, validation loss: 0.1123
2024-05-25 00:01:49 [INFO]: Epoch 130 - training loss: 9220.8878, validation loss: 0.1100
2024-05-25 00:01:49 [INFO]: Epoch 131 - training loss: 9222.0372, validation loss: 0.1082
2024-05-25 00:01:49 [INFO]: Epoch 132 - training loss: 9220.8593, validation loss: 0.1091
2024-05-25 00:01:50 [INFO]: Epoch 133 - training loss: 9220.4157, validation loss: 0.1064
2024-05-25 00:01:50 [INFO]: Epoch 134 - training loss: 9221.4481, validation loss: 0.1089
2024-05-25 00:01:50 [INFO]: Epoch 135 - training loss: 9223.8597, validation loss: 0.1067
2024-05-25 00:01:50 [INFO]: Epoch 136 - training loss: 9218.0513, validation loss: 0.1092
2024-05-25 00:01:50 [INFO]: Epoch 137 - training loss: 9220.3215, validation loss: 0.1050
2024-05-25 00:01:50 [INFO]: Epoch 138 - training loss: 9218.8799, validation loss: 0.1063
2024-05-25 00:01:50 [INFO]: Epoch 139 - training loss: 9217.9763, validation loss: 0.1070
2024-05-25 00:01:50 [INFO]: Epoch 140 - training loss: 9218.0498, validation loss: 0.1046
2024-05-25 00:01:51 [INFO]: Epoch 141 - training loss: 9219.9512, validation loss: 0.1055
2024-05-25 00:01:51 [INFO]: Epoch 142 - training loss: 9217.3092, validation loss: 0.1037
2024-05-25 00:01:51 [INFO]: Epoch 143 - training loss: 9217.0681, validation loss: 0.1055
2024-05-25 00:01:51 [INFO]: Epoch 144 - training loss: 9217.7514, validation loss: 0.1060
2024-05-25 00:01:51 [INFO]: Epoch 145 - training loss: 9218.0456, validation loss: 0.1046
2024-05-25 00:01:51 [INFO]: Epoch 146 - training loss: 9222.3911, validation loss: 0.1033
2024-05-25 00:01:51 [INFO]: Epoch 147 - training loss: 9218.3889, validation loss: 0.1016
2024-05-25 00:01:51 [INFO]: Epoch 148 - training loss: 9218.5020, validation loss: 0.1017
2024-05-25 00:01:52 [INFO]: Epoch 149 - training loss: 9217.9149, validation loss: 0.1009
2024-05-25 00:01:52 [INFO]: Epoch 150 - training loss: 9217.9315, validation loss: 0.1029
2024-05-25 00:01:52 [INFO]: Epoch 151 - training loss: 9216.2192, validation loss: 0.1034
2024-05-25 00:01:52 [INFO]: Epoch 152 - training loss: 9230.5322, validation loss: 0.1012
2024-05-25 00:01:52 [INFO]: Epoch 153 - training loss: 9215.9604, validation loss: 0.1003
2024-05-25 00:01:52 [INFO]: Epoch 154 - training loss: 9217.7745, validation loss: 0.1011
2024-05-25 00:01:52 [INFO]: Epoch 155 - training loss: 9215.5288, validation loss: 0.1016
2024-05-25 00:01:52 [INFO]: Epoch 156 - training loss: 9215.4561, validation loss: 0.0993
2024-05-25 00:01:53 [INFO]: Epoch 157 - training loss: 9216.1045, validation loss: 0.1008
2024-05-25 00:01:53 [INFO]: Epoch 158 - training loss: 9215.2773, validation loss: 0.0993
2024-05-25 00:01:53 [INFO]: Epoch 159 - training loss: 9214.7860, validation loss: 0.0992
2024-05-25 00:01:53 [INFO]: Epoch 160 - training loss: 9215.5124, validation loss: 0.0984
2024-05-25 00:01:53 [INFO]: Epoch 161 - training loss: 9214.2775, validation loss: 0.1011
2024-05-25 00:01:53 [INFO]: Epoch 162 - training loss: 9215.3823, validation loss: 0.1006
2024-05-25 00:01:53 [INFO]: Epoch 163 - training loss: 9214.8915, validation loss: 0.0974
2024-05-25 00:01:53 [INFO]: Epoch 164 - training loss: 9214.0992, validation loss: 0.0977
2024-05-25 00:01:54 [INFO]: Epoch 165 - training loss: 9214.8163, validation loss: 0.1013
2024-05-25 00:01:54 [INFO]: Epoch 166 - training loss: 9212.9529, validation loss: 0.0970
2024-05-25 00:01:54 [INFO]: Epoch 167 - training loss: 9214.9246, validation loss: 0.0971
2024-05-25 00:01:54 [INFO]: Epoch 168 - training loss: 9213.0601, validation loss: 0.0955
2024-05-25 00:01:54 [INFO]: Epoch 169 - training loss: 9213.7513, validation loss: 0.0991
2024-05-25 00:01:54 [INFO]: Epoch 170 - training loss: 9213.0708, validation loss: 0.0955
2024-05-25 00:01:54 [INFO]: Epoch 171 - training loss: 9214.1428, validation loss: 0.0962
2024-05-25 00:01:55 [INFO]: Epoch 172 - training loss: 9215.1782, validation loss: 0.0961
2024-05-25 00:01:55 [INFO]: Epoch 173 - training loss: 9213.7431, validation loss: 0.0966
2024-05-25 00:01:55 [INFO]: Epoch 174 - training loss: 9214.3879, validation loss: 0.0937
2024-05-25 00:01:55 [INFO]: Epoch 175 - training loss: 9213.4794, validation loss: 0.0953
2024-05-25 00:01:55 [INFO]: Epoch 176 - training loss: 9212.3119, validation loss: 0.0954
2024-05-25 00:01:55 [INFO]: Epoch 177 - training loss: 9213.2677, validation loss: 0.0947
2024-05-25 00:01:55 [INFO]: Epoch 178 - training loss: 9213.8649, validation loss: 0.0933
2024-05-25 00:01:55 [INFO]: Epoch 179 - training loss: 9213.5363, validation loss: 0.0938
2024-05-25 00:01:56 [INFO]: Epoch 180 - training loss: 9212.4040, validation loss: 0.0930
2024-05-25 00:01:56 [INFO]: Epoch 181 - training loss: 9209.4602, validation loss: 0.0940
2024-05-25 00:01:56 [INFO]: Epoch 182 - training loss: 9212.6595, validation loss: 0.0937
2024-05-25 00:01:56 [INFO]: Epoch 183 - training loss: 9212.5004, validation loss: 0.0944
2024-05-25 00:01:56 [INFO]: Epoch 184 - training loss: 9214.2956, validation loss: 0.0933
2024-05-25 00:01:56 [INFO]: Epoch 185 - training loss: 9212.7878, validation loss: 0.0924
2024-05-25 00:01:56 [INFO]: Epoch 186 - training loss: 9215.7368, validation loss: 0.0909
2024-05-25 00:01:56 [INFO]: Epoch 187 - training loss: 9211.5643, validation loss: 0.0903
2024-05-25 00:01:57 [INFO]: Epoch 188 - training loss: 9211.6874, validation loss: 0.0933
2024-05-25 00:01:57 [INFO]: Epoch 189 - training loss: 9211.6560, validation loss: 0.0907
2024-05-25 00:01:57 [INFO]: Epoch 190 - training loss: 9211.1715, validation loss: 0.0919
2024-05-25 00:01:57 [INFO]: Epoch 191 - training loss: 9210.8927, validation loss: 0.0906
2024-05-25 00:01:57 [INFO]: Epoch 192 - training loss: 9211.7319, validation loss: 0.0926
2024-05-25 00:01:57 [INFO]: Epoch 193 - training loss: 9211.4426, validation loss: 0.0904
2024-05-25 00:01:57 [INFO]: Epoch 194 - training loss: 9209.8563, validation loss: 0.0906
2024-05-25 00:01:57 [INFO]: Epoch 195 - training loss: 9213.0929, validation loss: 0.0905
2024-05-25 00:01:58 [INFO]: Epoch 196 - training loss: 9210.1336, validation loss: 0.0921
2024-05-25 00:01:58 [INFO]: Epoch 197 - training loss: 9210.5464, validation loss: 0.0901
2024-05-25 00:01:58 [INFO]: Epoch 198 - training loss: 9209.5500, validation loss: 0.0890
2024-05-25 00:01:58 [INFO]: Epoch 199 - training loss: 9210.9685, validation loss: 0.0916
2024-05-25 00:01:58 [INFO]: Epoch 200 - training loss: 9210.1928, validation loss: 0.0888
2024-05-25 00:01:58 [INFO]: Epoch 201 - training loss: 9211.3709, validation loss: 0.0909
2024-05-25 00:01:58 [INFO]: Epoch 202 - training loss: 9211.6815, validation loss: 0.0901
2024-05-25 00:01:58 [INFO]: Epoch 203 - training loss: 9212.1454, validation loss: 0.0913
2024-05-25 00:01:59 [INFO]: Epoch 204 - training loss: 9210.8367, validation loss: 0.0897
2024-05-25 00:01:59 [INFO]: Epoch 205 - training loss: 9210.2010, validation loss: 0.0888
2024-05-25 00:01:59 [INFO]: Epoch 206 - training loss: 9210.0211, validation loss: 0.0897
2024-05-25 00:01:59 [INFO]: Epoch 207 - training loss: 9209.6066, validation loss: 0.0879
2024-05-25 00:01:59 [INFO]: Epoch 208 - training loss: 9208.4554, validation loss: 0.0881
2024-05-25 00:01:59 [INFO]: Epoch 209 - training loss: 9209.9578, validation loss: 0.0896
2024-05-25 00:01:59 [INFO]: Epoch 210 - training loss: 9209.7936, validation loss: 0.0895
2024-05-25 00:01:59 [INFO]: Epoch 211 - training loss: 9211.2319, validation loss: 0.0865
2024-05-25 00:02:00 [INFO]: Epoch 212 - training loss: 9209.4988, validation loss: 0.0888
2024-05-25 00:02:00 [INFO]: Epoch 213 - training loss: 9209.4805, validation loss: 0.0889
2024-05-25 00:02:00 [INFO]: Epoch 214 - training loss: 9210.2479, validation loss: 0.0885
2024-05-25 00:02:00 [INFO]: Epoch 215 - training loss: 9208.3785, validation loss: 0.0872
2024-05-25 00:02:00 [INFO]: Epoch 216 - training loss: 9209.3326, validation loss: 0.0875
2024-05-25 00:02:00 [INFO]: Epoch 217 - training loss: 9208.5103, validation loss: 0.0879
2024-05-25 00:02:00 [INFO]: Epoch 218 - training loss: 9210.1773, validation loss: 0.0876
2024-05-25 00:02:00 [INFO]: Epoch 219 - training loss: 9208.9478, validation loss: 0.0857
2024-05-25 00:02:01 [INFO]: Epoch 220 - training loss: 9209.3946, validation loss: 0.0865
2024-05-25 00:02:01 [INFO]: Epoch 221 - training loss: 9208.9355, validation loss: 0.0877
2024-05-25 00:02:01 [INFO]: Epoch 222 - training loss: 9210.5308, validation loss: 0.0848
2024-05-25 00:02:01 [INFO]: Epoch 223 - training loss: 9208.4832, validation loss: 0.0867
2024-05-25 00:02:01 [INFO]: Epoch 224 - training loss: 9207.4970, validation loss: 0.0860
2024-05-25 00:02:01 [INFO]: Epoch 225 - training loss: 9207.8712, validation loss: 0.0875
2024-05-25 00:02:01 [INFO]: Epoch 226 - training loss: 9208.9747, validation loss: 0.0871
2024-05-25 00:02:01 [INFO]: Epoch 227 - training loss: 9210.2453, validation loss: 0.0856
2024-05-25 00:02:02 [INFO]: Epoch 228 - training loss: 9209.3201, validation loss: 0.0857
2024-05-25 00:02:02 [INFO]: Epoch 229 - training loss: 9208.6635, validation loss: 0.0862
2024-05-25 00:02:02 [INFO]: Epoch 230 - training loss: 9208.4757, validation loss: 0.0846
2024-05-25 00:02:02 [INFO]: Epoch 231 - training loss: 9209.0710, validation loss: 0.0867
2024-05-25 00:02:02 [INFO]: Epoch 232 - training loss: 9209.0118, validation loss: 0.0861
2024-05-25 00:02:02 [INFO]: Epoch 233 - training loss: 9208.4672, validation loss: 0.0856
2024-05-25 00:02:02 [INFO]: Epoch 234 - training loss: 9208.2493, validation loss: 0.0846
2024-05-25 00:02:02 [INFO]: Epoch 235 - training loss: 9207.1653, validation loss: 0.0837
2024-05-25 00:02:03 [INFO]: Epoch 236 - training loss: 9207.5535, validation loss: 0.0862
2024-05-25 00:02:03 [INFO]: Epoch 237 - training loss: 9209.4131, validation loss: 0.0857
2024-05-25 00:02:03 [INFO]: Epoch 238 - training loss: 9208.9135, validation loss: 0.0852
2024-05-25 00:02:03 [INFO]: Epoch 239 - training loss: 9208.8983, validation loss: 0.0822
2024-05-25 00:02:03 [INFO]: Epoch 240 - training loss: 9209.1885, validation loss: 0.0835
2024-05-25 00:02:03 [INFO]: Epoch 241 - training loss: 9207.9278, validation loss: 0.0855
2024-05-25 00:02:03 [INFO]: Epoch 242 - training loss: 9209.2283, validation loss: 0.0849
2024-05-25 00:02:04 [INFO]: Epoch 243 - training loss: 9208.7614, validation loss: 0.0859
2024-05-25 00:02:04 [INFO]: Epoch 244 - training loss: 9207.7090, validation loss: 0.0840
2024-05-25 00:02:04 [INFO]: Epoch 245 - training loss: 9206.5138, validation loss: 0.0842
2024-05-25 00:02:04 [INFO]: Epoch 246 - training loss: 9207.7247, validation loss: 0.0852
2024-05-25 00:02:04 [INFO]: Epoch 247 - training loss: 9207.8478, validation loss: 0.0831
2024-05-25 00:02:04 [INFO]: Epoch 248 - training loss: 9207.4575, validation loss: 0.0829
2024-05-25 00:02:04 [INFO]: Epoch 249 - training loss: 9206.4360, validation loss: 0.0839
2024-05-25 00:02:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:02:04 [INFO]: Finished training. The best model is from epoch#239.
2024-05-25 00:02:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/GPVAE_ettm1/20240525_T000132/GPVAE.pypots
2024-05-25 00:02:04 [INFO]: GP-VAE on ETTm1: MAE=0.3002, MSE=0.1872
2024-05-25 00:02:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-25 00:02:04 [INFO]: Using the given device: cuda:0
2024-05-25 00:02:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240525_T000204
2024-05-25 00:02:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240525_T000204/tensorboard
2024-05-25 00:02:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 00:02:15 [INFO]: Epoch 001 - generator training loss: 0.4475, discriminator training loss: 0.5461, validation loss: 0.3102
2024-05-25 00:02:24 [INFO]: Epoch 002 - generator training loss: -0.0462, discriminator training loss: 0.4763, validation loss: 0.1252
2024-05-25 00:02:32 [INFO]: Epoch 003 - generator training loss: -0.1671, discriminator training loss: 0.4437, validation loss: 0.0766
2024-05-25 00:02:41 [INFO]: Epoch 004 - generator training loss: -0.1605, discriminator training loss: 0.3898, validation loss: 0.0586
2024-05-25 00:02:50 [INFO]: Epoch 005 - generator training loss: -0.1183, discriminator training loss: 0.3159, validation loss: 0.0534
2024-05-25 00:02:59 [INFO]: Epoch 006 - generator training loss: -0.0821, discriminator training loss: 0.2513, validation loss: 0.0466
2024-05-25 00:03:08 [INFO]: Epoch 007 - generator training loss: -0.0580, discriminator training loss: 0.2078, validation loss: 0.0446
2024-05-25 00:03:16 [INFO]: Epoch 008 - generator training loss: -0.0530, discriminator training loss: 0.1899, validation loss: 0.0439
2024-05-25 00:03:25 [INFO]: Epoch 009 - generator training loss: -0.0511, discriminator training loss: 0.1827, validation loss: 0.0414
2024-05-25 00:03:34 [INFO]: Epoch 010 - generator training loss: -0.0495, discriminator training loss: 0.1791, validation loss: 0.0417
2024-05-25 00:03:42 [INFO]: Epoch 011 - generator training loss: -0.0530, discriminator training loss: 0.1774, validation loss: 0.0395
2024-05-25 00:03:51 [INFO]: Epoch 012 - generator training loss: -0.0512, discriminator training loss: 0.1748, validation loss: 0.0378
2024-05-25 00:04:00 [INFO]: Epoch 013 - generator training loss: -0.0582, discriminator training loss: 0.1735, validation loss: 0.0379
2024-05-25 00:04:09 [INFO]: Epoch 014 - generator training loss: -0.0553, discriminator training loss: 0.1748, validation loss: 0.0371
2024-05-25 00:04:17 [INFO]: Epoch 015 - generator training loss: -0.0548, discriminator training loss: 0.1734, validation loss: 0.0370
2024-05-25 00:04:26 [INFO]: Epoch 016 - generator training loss: -0.0581, discriminator training loss: 0.1709, validation loss: 0.0353
2024-05-25 00:04:35 [INFO]: Epoch 017 - generator training loss: -0.0570, discriminator training loss: 0.1703, validation loss: 0.0361
2024-05-25 00:04:44 [INFO]: Epoch 018 - generator training loss: -0.0565, discriminator training loss: 0.1705, validation loss: 0.0361
2024-05-25 00:04:52 [INFO]: Epoch 019 - generator training loss: -0.0593, discriminator training loss: 0.1719, validation loss: 0.0361
2024-05-25 00:05:01 [INFO]: Epoch 020 - generator training loss: -0.0566, discriminator training loss: 0.1731, validation loss: 0.0346
2024-05-25 00:05:10 [INFO]: Epoch 021 - generator training loss: -0.0628, discriminator training loss: 0.1719, validation loss: 0.0341
2024-05-25 00:05:19 [INFO]: Epoch 022 - generator training loss: -0.0570, discriminator training loss: 0.1692, validation loss: 0.0344
2024-05-25 00:05:28 [INFO]: Epoch 023 - generator training loss: -0.0594, discriminator training loss: 0.1706, validation loss: 0.0342
2024-05-25 00:05:36 [INFO]: Epoch 024 - generator training loss: -0.0574, discriminator training loss: 0.1690, validation loss: 0.0344
2024-05-25 00:05:45 [INFO]: Epoch 025 - generator training loss: -0.0603, discriminator training loss: 0.1669, validation loss: 0.0340
2024-05-25 00:05:54 [INFO]: Epoch 026 - generator training loss: -0.0638, discriminator training loss: 0.1689, validation loss: 0.0336
2024-05-25 00:06:03 [INFO]: Epoch 027 - generator training loss: -0.0590, discriminator training loss: 0.1671, validation loss: 0.0329
2024-05-25 00:06:12 [INFO]: Epoch 028 - generator training loss: -0.0606, discriminator training loss: 0.1684, validation loss: 0.0333
2024-05-25 00:06:20 [INFO]: Epoch 029 - generator training loss: -0.0601, discriminator training loss: 0.1699, validation loss: 0.0325
2024-05-25 00:06:29 [INFO]: Epoch 030 - generator training loss: -0.0604, discriminator training loss: 0.1677, validation loss: 0.0324
2024-05-25 00:06:38 [INFO]: Epoch 031 - generator training loss: -0.0621, discriminator training loss: 0.1672, validation loss: 0.0317
2024-05-25 00:06:46 [INFO]: Epoch 032 - generator training loss: -0.0649, discriminator training loss: 0.1674, validation loss: 0.0322
2024-05-25 00:06:55 [INFO]: Epoch 033 - generator training loss: -0.0631, discriminator training loss: 0.1673, validation loss: 0.0314
2024-05-25 00:07:04 [INFO]: Epoch 034 - generator training loss: -0.0640, discriminator training loss: 0.1694, validation loss: 0.0318
2024-05-25 00:07:13 [INFO]: Epoch 035 - generator training loss: -0.0637, discriminator training loss: 0.1690, validation loss: 0.0316
2024-05-25 00:07:21 [INFO]: Epoch 036 - generator training loss: -0.0664, discriminator training loss: 0.1700, validation loss: 0.0299
2024-05-25 00:07:30 [INFO]: Epoch 037 - generator training loss: -0.0696, discriminator training loss: 0.1681, validation loss: 0.0317
2024-05-25 00:07:39 [INFO]: Epoch 038 - generator training loss: -0.0649, discriminator training loss: 0.1677, validation loss: 0.0303
2024-05-25 00:07:48 [INFO]: Epoch 039 - generator training loss: -0.0667, discriminator training loss: 0.1675, validation loss: 0.0291
2024-05-25 00:07:57 [INFO]: Epoch 040 - generator training loss: -0.0662, discriminator training loss: 0.1669, validation loss: 0.0291
2024-05-25 00:08:05 [INFO]: Epoch 041 - generator training loss: -0.0651, discriminator training loss: 0.1670, validation loss: 0.0285
2024-05-25 00:08:14 [INFO]: Epoch 042 - generator training loss: -0.0695, discriminator training loss: 0.1685, validation loss: 0.0294
2024-05-25 00:08:23 [INFO]: Epoch 043 - generator training loss: -0.0677, discriminator training loss: 0.1672, validation loss: 0.0292
2024-05-25 00:08:32 [INFO]: Epoch 044 - generator training loss: -0.0677, discriminator training loss: 0.1671, validation loss: 0.0289
2024-05-25 00:08:40 [INFO]: Epoch 045 - generator training loss: -0.0713, discriminator training loss: 0.1693, validation loss: 0.0281
2024-05-25 00:08:49 [INFO]: Epoch 046 - generator training loss: -0.0681, discriminator training loss: 0.1661, validation loss: 0.0278
2024-05-25 00:08:58 [INFO]: Epoch 047 - generator training loss: -0.0687, discriminator training loss: 0.1665, validation loss: 0.0277
2024-05-25 00:09:07 [INFO]: Epoch 048 - generator training loss: -0.0683, discriminator training loss: 0.1665, validation loss: 0.0276
2024-05-25 00:09:16 [INFO]: Epoch 049 - generator training loss: -0.0665, discriminator training loss: 0.1678, validation loss: 0.0274
2024-05-25 00:09:24 [INFO]: Epoch 050 - generator training loss: -0.0695, discriminator training loss: 0.1645, validation loss: 0.0270
2024-05-25 00:09:33 [INFO]: Epoch 051 - generator training loss: -0.0685, discriminator training loss: 0.1654, validation loss: 0.0266
2024-05-25 00:09:42 [INFO]: Epoch 052 - generator training loss: -0.0693, discriminator training loss: 0.1663, validation loss: 0.0270
2024-05-25 00:09:51 [INFO]: Epoch 053 - generator training loss: -0.0654, discriminator training loss: 0.1651, validation loss: 0.0274
2024-05-25 00:09:59 [INFO]: Epoch 054 - generator training loss: -0.0720, discriminator training loss: 0.1692, validation loss: 0.0271
2024-05-25 00:10:08 [INFO]: Epoch 055 - generator training loss: -0.0688, discriminator training loss: 0.1660, validation loss: 0.0270
2024-05-25 00:10:17 [INFO]: Epoch 056 - generator training loss: -0.0703, discriminator training loss: 0.1654, validation loss: 0.0264
2024-05-25 00:10:26 [INFO]: Epoch 057 - generator training loss: -0.0689, discriminator training loss: 0.1656, validation loss: 0.0264
2024-05-25 00:10:34 [INFO]: Epoch 058 - generator training loss: -0.0698, discriminator training loss: 0.1673, validation loss: 0.0263
2024-05-25 00:10:43 [INFO]: Epoch 059 - generator training loss: -0.0684, discriminator training loss: 0.1649, validation loss: 0.0255
2024-05-25 00:10:52 [INFO]: Epoch 060 - generator training loss: -0.0732, discriminator training loss: 0.1655, validation loss: 0.0260
2024-05-25 00:11:01 [INFO]: Epoch 061 - generator training loss: -0.0682, discriminator training loss: 0.1645, validation loss: 0.0257
2024-05-25 00:11:09 [INFO]: Epoch 062 - generator training loss: -0.0714, discriminator training loss: 0.1653, validation loss: 0.0255
2024-05-25 00:11:18 [INFO]: Epoch 063 - generator training loss: -0.0722, discriminator training loss: 0.1636, validation loss: 0.0259
2024-05-25 00:11:27 [INFO]: Epoch 064 - generator training loss: -0.0706, discriminator training loss: 0.1656, validation loss: 0.0251
2024-05-25 00:11:36 [INFO]: Epoch 065 - generator training loss: -0.0727, discriminator training loss: 0.1644, validation loss: 0.0252
2024-05-25 00:11:44 [INFO]: Epoch 066 - generator training loss: -0.0719, discriminator training loss: 0.1644, validation loss: 0.0253
2024-05-25 00:11:53 [INFO]: Epoch 067 - generator training loss: -0.0700, discriminator training loss: 0.1647, validation loss: 0.0251
2024-05-25 00:12:02 [INFO]: Epoch 068 - generator training loss: -0.0726, discriminator training loss: 0.1661, validation loss: 0.0248
2024-05-25 00:12:11 [INFO]: Epoch 069 - generator training loss: -0.0717, discriminator training loss: 0.1640, validation loss: 0.0253
2024-05-25 00:12:20 [INFO]: Epoch 070 - generator training loss: -0.0700, discriminator training loss: 0.1640, validation loss: 0.0253
2024-05-25 00:12:29 [INFO]: Epoch 071 - generator training loss: -0.0728, discriminator training loss: 0.1647, validation loss: 0.0246
2024-05-25 00:12:37 [INFO]: Epoch 072 - generator training loss: -0.0656, discriminator training loss: 0.1634, validation loss: 0.0246
2024-05-25 00:12:46 [INFO]: Epoch 073 - generator training loss: -0.0715, discriminator training loss: 0.1628, validation loss: 0.0249
2024-05-25 00:12:55 [INFO]: Epoch 074 - generator training loss: -0.0731, discriminator training loss: 0.1610, validation loss: 0.0244
2024-05-25 00:13:03 [INFO]: Epoch 075 - generator training loss: -0.0719, discriminator training loss: 0.1624, validation loss: 0.0251
2024-05-25 00:13:12 [INFO]: Epoch 076 - generator training loss: -0.0710, discriminator training loss: 0.1624, validation loss: 0.0254
2024-05-25 00:13:21 [INFO]: Epoch 077 - generator training loss: -0.0726, discriminator training loss: 0.1638, validation loss: 0.0247
2024-05-25 00:13:30 [INFO]: Epoch 078 - generator training loss: -0.0698, discriminator training loss: 0.1630, validation loss: 0.0247
2024-05-25 00:13:38 [INFO]: Epoch 079 - generator training loss: -0.0724, discriminator training loss: 0.1634, validation loss: 0.0254
2024-05-25 00:13:47 [INFO]: Epoch 080 - generator training loss: -0.0683, discriminator training loss: 0.1629, validation loss: 0.0245
2024-05-25 00:13:56 [INFO]: Epoch 081 - generator training loss: -0.0717, discriminator training loss: 0.1635, validation loss: 0.0241
2024-05-25 00:14:05 [INFO]: Epoch 082 - generator training loss: -0.0703, discriminator training loss: 0.1630, validation loss: 0.0252
2024-05-25 00:14:13 [INFO]: Epoch 083 - generator training loss: -0.0688, discriminator training loss: 0.1633, validation loss: 0.0258
2024-05-25 00:14:22 [INFO]: Epoch 084 - generator training loss: -0.0717, discriminator training loss: 0.1621, validation loss: 0.0238
2024-05-25 00:14:31 [INFO]: Epoch 085 - generator training loss: -0.0706, discriminator training loss: 0.1596, validation loss: 0.0247
2024-05-25 00:14:40 [INFO]: Epoch 086 - generator training loss: -0.0716, discriminator training loss: 0.1625, validation loss: 0.0242
2024-05-25 00:14:48 [INFO]: Epoch 087 - generator training loss: -0.0735, discriminator training loss: 0.1634, validation loss: 0.0243
2024-05-25 00:14:57 [INFO]: Epoch 088 - generator training loss: -0.0699, discriminator training loss: 0.1638, validation loss: 0.0250
2024-05-25 00:15:06 [INFO]: Epoch 089 - generator training loss: -0.0728, discriminator training loss: 0.1633, validation loss: 0.0247
2024-05-25 00:15:15 [INFO]: Epoch 090 - generator training loss: -0.0708, discriminator training loss: 0.1617, validation loss: 0.0244
2024-05-25 00:15:23 [INFO]: Epoch 091 - generator training loss: -0.0752, discriminator training loss: 0.1622, validation loss: 0.0248
2024-05-25 00:15:32 [INFO]: Epoch 092 - generator training loss: -0.0692, discriminator training loss: 0.1603, validation loss: 0.0247
2024-05-25 00:15:41 [INFO]: Epoch 093 - generator training loss: -0.0741, discriminator training loss: 0.1615, validation loss: 0.0242
2024-05-25 00:15:50 [INFO]: Epoch 094 - generator training loss: -0.0699, discriminator training loss: 0.1616, validation loss: 0.0242
2024-05-25 00:15:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:15:50 [INFO]: Finished training. The best model is from epoch#84.
2024-05-25 00:15:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/USGAN_ettm1/20240525_T000204/USGAN.pypots
2024-05-25 00:15:51 [INFO]: US-GAN on ETTm1: MAE=0.1552, MSE=0.0606
2024-05-25 00:15:51 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-25 00:15:51 [INFO]: Using the given device: cuda:0
2024-05-25 00:15:51 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240525_T001551
2024-05-25 00:15:51 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240525_T001551/tensorboard
2024-05-25 00:15:51 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 00:15:58 [INFO]: Epoch 001 - training loss: 1.3281, validation loss: 0.2851
2024-05-25 00:16:04 [INFO]: Epoch 002 - training loss: 0.9039, validation loss: 0.0950
2024-05-25 00:16:10 [INFO]: Epoch 003 - training loss: 0.7226, validation loss: 0.0598
2024-05-25 00:16:16 [INFO]: Epoch 004 - training loss: 0.6563, validation loss: 0.0463
2024-05-25 00:16:21 [INFO]: Epoch 005 - training loss: 0.6006, validation loss: 0.0421
2024-05-25 00:16:27 [INFO]: Epoch 006 - training loss: 0.5967, validation loss: 0.0415
2024-05-25 00:16:33 [INFO]: Epoch 007 - training loss: 0.6074, validation loss: 0.0371
2024-05-25 00:16:39 [INFO]: Epoch 008 - training loss: 0.5533, validation loss: 0.0391
2024-05-25 00:16:45 [INFO]: Epoch 009 - training loss: 0.5144, validation loss: 0.0361
2024-05-25 00:16:51 [INFO]: Epoch 010 - training loss: 0.4854, validation loss: 0.0345
2024-05-25 00:16:56 [INFO]: Epoch 011 - training loss: 0.4698, validation loss: 0.0338
2024-05-25 00:17:02 [INFO]: Epoch 012 - training loss: 0.4581, validation loss: 0.0324
2024-05-25 00:17:08 [INFO]: Epoch 013 - training loss: 0.4377, validation loss: 0.0325
2024-05-25 00:17:14 [INFO]: Epoch 014 - training loss: 0.4348, validation loss: 0.0307
2024-05-25 00:17:20 [INFO]: Epoch 015 - training loss: 0.4285, validation loss: 0.0305
2024-05-25 00:17:26 [INFO]: Epoch 016 - training loss: 0.4223, validation loss: 0.0297
2024-05-25 00:17:31 [INFO]: Epoch 017 - training loss: 0.4302, validation loss: 0.0306
2024-05-25 00:17:37 [INFO]: Epoch 018 - training loss: 0.4340, validation loss: 0.0315
2024-05-25 00:17:43 [INFO]: Epoch 019 - training loss: 0.4196, validation loss: 0.0293
2024-05-25 00:17:49 [INFO]: Epoch 020 - training loss: 0.4132, validation loss: 0.0283
2024-05-25 00:17:55 [INFO]: Epoch 021 - training loss: 0.4091, validation loss: 0.0275
2024-05-25 00:18:01 [INFO]: Epoch 022 - training loss: 0.4052, validation loss: 0.0271
2024-05-25 00:18:06 [INFO]: Epoch 023 - training loss: 0.4031, validation loss: 0.0273
2024-05-25 00:18:12 [INFO]: Epoch 024 - training loss: 0.4081, validation loss: 0.0271
2024-05-25 00:18:18 [INFO]: Epoch 025 - training loss: 0.4127, validation loss: 0.0269
2024-05-25 00:18:24 [INFO]: Epoch 026 - training loss: 0.4051, validation loss: 0.0266
2024-05-25 00:18:30 [INFO]: Epoch 027 - training loss: 0.4050, validation loss: 0.0270
2024-05-25 00:18:36 [INFO]: Epoch 028 - training loss: 0.3958, validation loss: 0.0262
2024-05-25 00:18:41 [INFO]: Epoch 029 - training loss: 0.4031, validation loss: 0.0264
2024-05-25 00:18:47 [INFO]: Epoch 030 - training loss: 0.3974, validation loss: 0.0268
2024-05-25 00:18:53 [INFO]: Epoch 031 - training loss: 0.4009, validation loss: 0.0266
2024-05-25 00:18:59 [INFO]: Epoch 032 - training loss: 0.4107, validation loss: 0.0275
2024-05-25 00:19:05 [INFO]: Epoch 033 - training loss: 0.3981, validation loss: 0.0262
2024-05-25 00:19:10 [INFO]: Epoch 034 - training loss: 0.4087, validation loss: 0.0271
2024-05-25 00:19:16 [INFO]: Epoch 035 - training loss: 0.4072, validation loss: 0.0273
2024-05-25 00:19:22 [INFO]: Epoch 036 - training loss: 0.4095, validation loss: 0.0264
2024-05-25 00:19:28 [INFO]: Epoch 037 - training loss: 0.3986, validation loss: 0.0266
2024-05-25 00:19:34 [INFO]: Epoch 038 - training loss: 0.3991, validation loss: 0.0265
2024-05-25 00:19:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:19:34 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 00:19:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/BRITS_ettm1/20240525_T001551/BRITS.pypots
2024-05-25 00:19:35 [INFO]: BRITS on ETTm1: MAE=0.1370, MSE=0.0572
2024-05-25 00:19:35 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-25 00:19:35 [INFO]: Using the given device: cuda:0
2024-05-25 00:19:35 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935
2024-05-25 00:19:35 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/tensorboard
2024-05-25 00:19:35 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 00:19:36 [INFO]: Epoch 001 - training loss: 1.3998, validation loss: 1.3155
2024-05-25 00:19:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch1_loss1.3155040740966797.pypots
2024-05-25 00:19:37 [INFO]: Epoch 002 - training loss: 1.0277, validation loss: 1.1618
2024-05-25 00:19:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch2_loss1.1618172377347946.pypots
2024-05-25 00:19:37 [INFO]: Epoch 003 - training loss: 0.9408, validation loss: 1.0593
2024-05-25 00:19:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch3_loss1.0592990517616272.pypots
2024-05-25 00:19:37 [INFO]: Epoch 004 - training loss: 0.9048, validation loss: 1.0258
2024-05-25 00:19:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch4_loss1.0258176177740097.pypots
2024-05-25 00:19:37 [INFO]: Epoch 005 - training loss: 0.9129, validation loss: 1.0117
2024-05-25 00:19:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch5_loss1.011716142296791.pypots
2024-05-25 00:19:37 [INFO]: Epoch 006 - training loss: 0.8767, validation loss: 1.0046
2024-05-25 00:19:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch6_loss1.0046101957559586.pypots
2024-05-25 00:19:37 [INFO]: Epoch 007 - training loss: 0.8609, validation loss: 0.9967
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch7_loss0.9966569244861603.pypots
2024-05-25 00:19:38 [INFO]: Epoch 008 - training loss: 0.8502, validation loss: 0.9874
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch8_loss0.9873821884393692.pypots
2024-05-25 00:19:38 [INFO]: Epoch 009 - training loss: 0.8663, validation loss: 0.9810
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch9_loss0.9810042083263397.pypots
2024-05-25 00:19:38 [INFO]: Epoch 010 - training loss: 0.8713, validation loss: 0.9784
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch10_loss0.978428065776825.pypots
2024-05-25 00:19:38 [INFO]: Epoch 011 - training loss: 0.8417, validation loss: 0.9722
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch11_loss0.9721637964248657.pypots
2024-05-25 00:19:38 [INFO]: Epoch 012 - training loss: 0.8335, validation loss: 0.9698
2024-05-25 00:19:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch12_loss0.9697843194007874.pypots
2024-05-25 00:19:39 [INFO]: Epoch 013 - training loss: 0.8278, validation loss: 0.9672
2024-05-25 00:19:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch13_loss0.9672213643789291.pypots
2024-05-25 00:19:39 [INFO]: Epoch 014 - training loss: 0.8533, validation loss: 0.9669
2024-05-25 00:19:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch14_loss0.9668607413768768.pypots
2024-05-25 00:19:39 [INFO]: Epoch 015 - training loss: 0.8402, validation loss: 0.9651
2024-05-25 00:19:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch15_loss0.9651452600955963.pypots
2024-05-25 00:19:39 [INFO]: Epoch 016 - training loss: 0.8394, validation loss: 0.9635
2024-05-25 00:19:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch16_loss0.9634550958871841.pypots
2024-05-25 00:19:39 [INFO]: Epoch 017 - training loss: 0.8345, validation loss: 0.9620
2024-05-25 00:19:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch17_loss0.961991474032402.pypots
2024-05-25 00:19:40 [INFO]: Epoch 018 - training loss: 0.8196, validation loss: 0.9585
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch18_loss0.9584504663944244.pypots
2024-05-25 00:19:40 [INFO]: Epoch 019 - training loss: 0.8108, validation loss: 0.9549
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch19_loss0.9548535495996475.pypots
2024-05-25 00:19:40 [INFO]: Epoch 020 - training loss: 0.8034, validation loss: 0.9543
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch20_loss0.954306423664093.pypots
2024-05-25 00:19:40 [INFO]: Epoch 021 - training loss: 0.7972, validation loss: 0.9504
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch21_loss0.9504434466362.pypots
2024-05-25 00:19:40 [INFO]: Epoch 022 - training loss: 0.7868, validation loss: 0.9482
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch22_loss0.9482424706220627.pypots
2024-05-25 00:19:40 [INFO]: Epoch 023 - training loss: 0.7928, validation loss: 0.9462
2024-05-25 00:19:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch23_loss0.946190282702446.pypots
2024-05-25 00:19:41 [INFO]: Epoch 024 - training loss: 0.8017, validation loss: 0.9456
2024-05-25 00:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch24_loss0.9456461519002914.pypots
2024-05-25 00:19:41 [INFO]: Epoch 025 - training loss: 0.7892, validation loss: 0.9454
2024-05-25 00:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch25_loss0.9454495757818222.pypots
2024-05-25 00:19:41 [INFO]: Epoch 026 - training loss: 0.7889, validation loss: 0.9427
2024-05-25 00:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch26_loss0.9426892399787903.pypots
2024-05-25 00:19:41 [INFO]: Epoch 027 - training loss: 0.7635, validation loss: 0.9399
2024-05-25 00:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch27_loss0.9399275034666061.pypots
2024-05-25 00:19:41 [INFO]: Epoch 028 - training loss: 0.7737, validation loss: 0.9373
2024-05-25 00:19:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch28_loss0.9372604191303253.pypots
2024-05-25 00:19:42 [INFO]: Epoch 029 - training loss: 0.7892, validation loss: 0.9341
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch29_loss0.9341052919626236.pypots
2024-05-25 00:19:42 [INFO]: Epoch 030 - training loss: 0.7927, validation loss: 0.9325
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch30_loss0.9325481355190277.pypots
2024-05-25 00:19:42 [INFO]: Epoch 031 - training loss: 0.7699, validation loss: 0.9279
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch31_loss0.9279477894306183.pypots
2024-05-25 00:19:42 [INFO]: Epoch 032 - training loss: 0.7790, validation loss: 0.9240
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch32_loss0.9240184277296066.pypots
2024-05-25 00:19:42 [INFO]: Epoch 033 - training loss: 0.7595, validation loss: 0.9212
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch33_loss0.9211999326944351.pypots
2024-05-25 00:19:43 [INFO]: Epoch 034 - training loss: 0.7669, validation loss: 0.9178
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch34_loss0.9177827090024948.pypots
2024-05-25 00:19:43 [INFO]: Epoch 035 - training loss: 0.7809, validation loss: 0.9138
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch35_loss0.9138438403606415.pypots
2024-05-25 00:19:43 [INFO]: Epoch 036 - training loss: 0.7866, validation loss: 0.9137
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch36_loss0.9137410670518875.pypots
2024-05-25 00:19:43 [INFO]: Epoch 037 - training loss: 0.7950, validation loss: 0.9105
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch37_loss0.9105478674173355.pypots
2024-05-25 00:19:43 [INFO]: Epoch 038 - training loss: 0.7636, validation loss: 0.9067
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch38_loss0.9067390859127045.pypots
2024-05-25 00:19:43 [INFO]: Epoch 039 - training loss: 0.7753, validation loss: 0.9049
2024-05-25 00:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch39_loss0.9048850685358047.pypots
2024-05-25 00:19:44 [INFO]: Epoch 040 - training loss: 0.7531, validation loss: 0.9027
2024-05-25 00:19:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch40_loss0.9027364701032639.pypots
2024-05-25 00:19:44 [INFO]: Epoch 041 - training loss: 0.7456, validation loss: 0.8997
2024-05-25 00:19:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch41_loss0.8996836096048355.pypots
2024-05-25 00:19:44 [INFO]: Epoch 042 - training loss: 0.7619, validation loss: 0.8986
2024-05-25 00:19:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch42_loss0.8985844850540161.pypots
2024-05-25 00:19:44 [INFO]: Epoch 043 - training loss: 0.7426, validation loss: 0.8980
2024-05-25 00:19:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch43_loss0.8979876935482025.pypots
2024-05-25 00:19:44 [INFO]: Epoch 044 - training loss: 0.7878, validation loss: 0.8969
2024-05-25 00:19:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch44_loss0.8968886733055115.pypots
2024-05-25 00:19:45 [INFO]: Epoch 045 - training loss: 0.7364, validation loss: 0.8940
2024-05-25 00:19:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch45_loss0.8939931839704514.pypots
2024-05-25 00:19:45 [INFO]: Epoch 046 - training loss: 0.7667, validation loss: 0.8940
2024-05-25 00:19:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch46_loss0.894003301858902.pypots
2024-05-25 00:19:45 [INFO]: Epoch 047 - training loss: 0.7555, validation loss: 0.8902
2024-05-25 00:19:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch47_loss0.8901769816875458.pypots
2024-05-25 00:19:45 [INFO]: Epoch 048 - training loss: 0.7611, validation loss: 0.8912
2024-05-25 00:19:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch48_loss0.8912109583616257.pypots
2024-05-25 00:19:45 [INFO]: Epoch 049 - training loss: 0.7388, validation loss: 0.8872
2024-05-25 00:19:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch49_loss0.8872367143630981.pypots
2024-05-25 00:19:46 [INFO]: Epoch 050 - training loss: 0.7427, validation loss: 0.8879
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch50_loss0.8879383206367493.pypots
2024-05-25 00:19:46 [INFO]: Epoch 051 - training loss: 0.7755, validation loss: 0.8868
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch51_loss0.88681460916996.pypots
2024-05-25 00:19:46 [INFO]: Epoch 052 - training loss: 0.7487, validation loss: 0.8826
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch52_loss0.8825605362653732.pypots
2024-05-25 00:19:46 [INFO]: Epoch 053 - training loss: 0.7474, validation loss: 0.8810
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch53_loss0.8809711039066315.pypots
2024-05-25 00:19:46 [INFO]: Epoch 054 - training loss: 0.7327, validation loss: 0.8813
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch54_loss0.8812508434057236.pypots
2024-05-25 00:19:46 [INFO]: Epoch 055 - training loss: 0.7445, validation loss: 0.8797
2024-05-25 00:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch55_loss0.8796721398830414.pypots
2024-05-25 00:19:47 [INFO]: Epoch 056 - training loss: 0.7431, validation loss: 0.8791
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch56_loss0.8791043311357498.pypots
2024-05-25 00:19:47 [INFO]: Epoch 057 - training loss: 0.7402, validation loss: 0.8759
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch57_loss0.8759193569421768.pypots
2024-05-25 00:19:47 [INFO]: Epoch 058 - training loss: 0.7910, validation loss: 0.8771
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch58_loss0.8770792782306671.pypots
2024-05-25 00:19:47 [INFO]: Epoch 059 - training loss: 0.7563, validation loss: 0.8792
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch59_loss0.8791795521974564.pypots
2024-05-25 00:19:47 [INFO]: Epoch 060 - training loss: 0.7476, validation loss: 0.8749
2024-05-25 00:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch60_loss0.8749235421419144.pypots
2024-05-25 00:19:48 [INFO]: Epoch 061 - training loss: 0.7439, validation loss: 0.8773
2024-05-25 00:19:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch61_loss0.8773425817489624.pypots
2024-05-25 00:19:48 [INFO]: Epoch 062 - training loss: 0.7463, validation loss: 0.8764
2024-05-25 00:19:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch62_loss0.8763945996761322.pypots
2024-05-25 00:19:48 [INFO]: Epoch 063 - training loss: 0.7395, validation loss: 0.8713
2024-05-25 00:19:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch63_loss0.8712713122367859.pypots
2024-05-25 00:19:48 [INFO]: Epoch 064 - training loss: 0.7668, validation loss: 0.8752
2024-05-25 00:19:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch64_loss0.8751823604106903.pypots
2024-05-25 00:19:48 [INFO]: Epoch 065 - training loss: 0.7538, validation loss: 0.8748
2024-05-25 00:19:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch65_loss0.8748438954353333.pypots
2024-05-25 00:19:49 [INFO]: Epoch 066 - training loss: 0.7338, validation loss: 0.8744
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch66_loss0.8744072914123535.pypots
2024-05-25 00:19:49 [INFO]: Epoch 067 - training loss: 0.7476, validation loss: 0.8711
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch67_loss0.8711175173521042.pypots
2024-05-25 00:19:49 [INFO]: Epoch 068 - training loss: 0.7530, validation loss: 0.8738
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch68_loss0.8738100528717041.pypots
2024-05-25 00:19:49 [INFO]: Epoch 069 - training loss: 0.7350, validation loss: 0.8729
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch69_loss0.8729230910539627.pypots
2024-05-25 00:19:49 [INFO]: Epoch 070 - training loss: 0.7368, validation loss: 0.8712
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch70_loss0.8711661249399185.pypots
2024-05-25 00:19:49 [INFO]: Epoch 071 - training loss: 0.7839, validation loss: 0.8699
2024-05-25 00:19:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch71_loss0.8699236810207367.pypots
2024-05-25 00:19:50 [INFO]: Epoch 072 - training loss: 0.7298, validation loss: 0.8744
2024-05-25 00:19:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch72_loss0.8743895888328552.pypots
2024-05-25 00:19:50 [INFO]: Epoch 073 - training loss: 0.7413, validation loss: 0.8716
2024-05-25 00:19:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch73_loss0.8716024607419968.pypots
2024-05-25 00:19:50 [INFO]: Epoch 074 - training loss: 0.7378, validation loss: 0.8638
2024-05-25 00:19:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch74_loss0.8637811690568924.pypots
2024-05-25 00:19:50 [INFO]: Epoch 075 - training loss: 0.7470, validation loss: 0.8673
2024-05-25 00:19:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch75_loss0.8673239350318909.pypots
2024-05-25 00:19:50 [INFO]: Epoch 076 - training loss: 0.7206, validation loss: 0.8657
2024-05-25 00:19:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch76_loss0.8657390624284744.pypots
2024-05-25 00:19:51 [INFO]: Epoch 077 - training loss: 0.7262, validation loss: 0.8674
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch77_loss0.8673882633447647.pypots
2024-05-25 00:19:51 [INFO]: Epoch 078 - training loss: 0.7422, validation loss: 0.8662
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch78_loss0.8662480562925339.pypots
2024-05-25 00:19:51 [INFO]: Epoch 079 - training loss: 0.7317, validation loss: 0.8646
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch79_loss0.864578515291214.pypots
2024-05-25 00:19:51 [INFO]: Epoch 080 - training loss: 0.7426, validation loss: 0.8637
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch80_loss0.8637003153562546.pypots
2024-05-25 00:19:51 [INFO]: Epoch 081 - training loss: 0.7248, validation loss: 0.8621
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch81_loss0.8620524406433105.pypots
2024-05-25 00:19:51 [INFO]: Epoch 082 - training loss: 0.7350, validation loss: 0.8611
2024-05-25 00:19:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch82_loss0.861122265458107.pypots
2024-05-25 00:19:52 [INFO]: Epoch 083 - training loss: 0.7240, validation loss: 0.8618
2024-05-25 00:19:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch83_loss0.8618274629116058.pypots
2024-05-25 00:19:52 [INFO]: Epoch 084 - training loss: 0.7315, validation loss: 0.8590
2024-05-25 00:19:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch84_loss0.8589534163475037.pypots
2024-05-25 00:19:52 [INFO]: Epoch 085 - training loss: 0.7316, validation loss: 0.8594
2024-05-25 00:19:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch85_loss0.8593509644269943.pypots
2024-05-25 00:19:52 [INFO]: Epoch 086 - training loss: 0.7309, validation loss: 0.8595
2024-05-25 00:19:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch86_loss0.8594932556152344.pypots
2024-05-25 00:19:52 [INFO]: Epoch 087 - training loss: 0.7478, validation loss: 0.8602
2024-05-25 00:19:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch87_loss0.8602495491504669.pypots
2024-05-25 00:19:53 [INFO]: Epoch 088 - training loss: 0.7721, validation loss: 0.8582
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch88_loss0.8582213521003723.pypots
2024-05-25 00:19:53 [INFO]: Epoch 089 - training loss: 0.7453, validation loss: 0.8519
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch89_loss0.8519069999456406.pypots
2024-05-25 00:19:53 [INFO]: Epoch 090 - training loss: 0.7440, validation loss: 0.8557
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch90_loss0.8557364791631699.pypots
2024-05-25 00:19:53 [INFO]: Epoch 091 - training loss: 0.7429, validation loss: 0.8601
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch91_loss0.8601331561803818.pypots
2024-05-25 00:19:53 [INFO]: Epoch 092 - training loss: 0.7422, validation loss: 0.8522
2024-05-25 00:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch92_loss0.852202981710434.pypots
2024-05-25 00:19:54 [INFO]: Epoch 093 - training loss: 0.7348, validation loss: 0.8568
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch93_loss0.8568266183137894.pypots
2024-05-25 00:19:54 [INFO]: Epoch 094 - training loss: 0.7316, validation loss: 0.8561
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch94_loss0.8561436682939529.pypots
2024-05-25 00:19:54 [INFO]: Epoch 095 - training loss: 0.7391, validation loss: 0.8544
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch95_loss0.8544296771287918.pypots
2024-05-25 00:19:54 [INFO]: Epoch 096 - training loss: 0.7782, validation loss: 0.8543
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch96_loss0.8543463796377182.pypots
2024-05-25 00:19:54 [INFO]: Epoch 097 - training loss: 0.7522, validation loss: 0.8556
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch97_loss0.8556399047374725.pypots
2024-05-25 00:19:54 [INFO]: Epoch 098 - training loss: 0.7288, validation loss: 0.8554
2024-05-25 00:19:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch98_loss0.855433389544487.pypots
2024-05-25 00:19:55 [INFO]: Epoch 099 - training loss: 0.7335, validation loss: 0.8522
2024-05-25 00:19:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN_epoch99_loss0.852226659655571.pypots
2024-05-25 00:19:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:19:55 [INFO]: Finished training. The best model is from epoch#89.
2024-05-25 00:19:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_ettm1/20240525_T001935/MRNN.pypots
2024-05-25 00:19:55 [INFO]: MRNN on ETTm1: MAE=0.7281, MSE=1.2336
2024-05-25 00:19:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-25 00:19:55 [INFO]: Using the given device: cpu
2024-05-25 00:19:55 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 00:19:55 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-25 00:19:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-25 00:19:55 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 00:19:55 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-25 00:19:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-25 00:19:55 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 00:19:55 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-25 00:19:55 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-25 00:19:55 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 00:19:55 [INFO]: Using the given device: cuda:0
2024-05-25 00:19:55 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240525_T001955
2024-05-25 00:19:55 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240525_T001955/tensorboard
2024-05-25 00:19:55 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 00:19:56 [INFO]: Epoch 001 - training loss: 1.2267, validation loss: 0.3564
2024-05-25 00:19:56 [INFO]: Epoch 002 - training loss: 0.9228, validation loss: 0.1953
2024-05-25 00:19:57 [INFO]: Epoch 003 - training loss: 0.7882, validation loss: 0.1217
2024-05-25 00:19:57 [INFO]: Epoch 004 - training loss: 0.7232, validation loss: 0.1331
2024-05-25 00:19:58 [INFO]: Epoch 005 - training loss: 0.6863, validation loss: 0.0893
2024-05-25 00:19:58 [INFO]: Epoch 006 - training loss: 0.6681, validation loss: 0.0967
2024-05-25 00:19:59 [INFO]: Epoch 007 - training loss: 0.6613, validation loss: 0.0959
2024-05-25 00:19:59 [INFO]: Epoch 008 - training loss: 0.6313, validation loss: 0.1008
2024-05-25 00:20:00 [INFO]: Epoch 009 - training loss: 0.6220, validation loss: 0.0852
2024-05-25 00:20:00 [INFO]: Epoch 010 - training loss: 0.6150, validation loss: 0.1177
2024-05-25 00:20:01 [INFO]: Epoch 011 - training loss: 0.6098, validation loss: 0.0861
2024-05-25 00:20:01 [INFO]: Epoch 012 - training loss: 0.5871, validation loss: 0.0742
2024-05-25 00:20:02 [INFO]: Epoch 013 - training loss: 0.5747, validation loss: 0.0599
2024-05-25 00:20:02 [INFO]: Epoch 014 - training loss: 0.5774, validation loss: 0.0834
2024-05-25 00:20:03 [INFO]: Epoch 015 - training loss: 0.5716, validation loss: 0.0654
2024-05-25 00:20:03 [INFO]: Epoch 016 - training loss: 0.5608, validation loss: 0.0659
2024-05-25 00:20:04 [INFO]: Epoch 017 - training loss: 0.5538, validation loss: 0.0653
2024-05-25 00:20:04 [INFO]: Epoch 018 - training loss: 0.5647, validation loss: 0.0665
2024-05-25 00:20:05 [INFO]: Epoch 019 - training loss: 0.5416, validation loss: 0.0663
2024-05-25 00:20:05 [INFO]: Epoch 020 - training loss: 0.5549, validation loss: 0.0961
2024-05-25 00:20:06 [INFO]: Epoch 021 - training loss: 0.5542, validation loss: 0.0885
2024-05-25 00:20:06 [INFO]: Epoch 022 - training loss: 0.5317, validation loss: 0.0567
2024-05-25 00:20:07 [INFO]: Epoch 023 - training loss: 0.5255, validation loss: 0.0608
2024-05-25 00:20:07 [INFO]: Epoch 024 - training loss: 0.5270, validation loss: 0.0537
2024-05-25 00:20:08 [INFO]: Epoch 025 - training loss: 0.5106, validation loss: 0.0746
2024-05-25 00:20:08 [INFO]: Epoch 026 - training loss: 0.5054, validation loss: 0.0533
2024-05-25 00:20:09 [INFO]: Epoch 027 - training loss: 0.4939, validation loss: 0.0490
2024-05-25 00:20:09 [INFO]: Epoch 028 - training loss: 0.4929, validation loss: 0.0633
2024-05-25 00:20:10 [INFO]: Epoch 029 - training loss: 0.4891, validation loss: 0.0472
2024-05-25 00:20:10 [INFO]: Epoch 030 - training loss: 0.4970, validation loss: 0.0538
2024-05-25 00:20:11 [INFO]: Epoch 031 - training loss: 0.4951, validation loss: 0.0529
2024-05-25 00:20:11 [INFO]: Epoch 032 - training loss: 0.4977, validation loss: 0.0435
2024-05-25 00:20:12 [INFO]: Epoch 033 - training loss: 0.4997, validation loss: 0.0500
2024-05-25 00:20:12 [INFO]: Epoch 034 - training loss: 0.4759, validation loss: 0.0466
2024-05-25 00:20:13 [INFO]: Epoch 035 - training loss: 0.4766, validation loss: 0.0556
2024-05-25 00:20:14 [INFO]: Epoch 036 - training loss: 0.4731, validation loss: 0.0429
2024-05-25 00:20:14 [INFO]: Epoch 037 - training loss: 0.4580, validation loss: 0.0717
2024-05-25 00:20:15 [INFO]: Epoch 038 - training loss: 0.4664, validation loss: 0.0445
2024-05-25 00:20:15 [INFO]: Epoch 039 - training loss: 0.4578, validation loss: 0.0481
2024-05-25 00:20:16 [INFO]: Epoch 040 - training loss: 0.4542, validation loss: 0.0447
2024-05-25 00:20:16 [INFO]: Epoch 041 - training loss: 0.4489, validation loss: 0.0494
2024-05-25 00:20:17 [INFO]: Epoch 042 - training loss: 0.4503, validation loss: 0.0399
2024-05-25 00:20:17 [INFO]: Epoch 043 - training loss: 0.4481, validation loss: 0.0621
2024-05-25 00:20:18 [INFO]: Epoch 044 - training loss: 0.4422, validation loss: 0.0382
2024-05-25 00:20:18 [INFO]: Epoch 045 - training loss: 0.4434, validation loss: 0.0445
2024-05-25 00:20:19 [INFO]: Epoch 046 - training loss: 0.4432, validation loss: 0.0406
2024-05-25 00:20:19 [INFO]: Epoch 047 - training loss: 0.4442, validation loss: 0.0472
2024-05-25 00:20:20 [INFO]: Epoch 048 - training loss: 0.4402, validation loss: 0.0374
2024-05-25 00:20:20 [INFO]: Epoch 049 - training loss: 0.4299, validation loss: 0.0423
2024-05-25 00:20:21 [INFO]: Epoch 050 - training loss: 0.4242, validation loss: 0.0383
2024-05-25 00:20:21 [INFO]: Epoch 051 - training loss: 0.4287, validation loss: 0.0450
2024-05-25 00:20:22 [INFO]: Epoch 052 - training loss: 0.4265, validation loss: 0.0372
2024-05-25 00:20:22 [INFO]: Epoch 053 - training loss: 0.4106, validation loss: 0.0342
2024-05-25 00:20:23 [INFO]: Epoch 054 - training loss: 0.3930, validation loss: 0.0361
2024-05-25 00:20:23 [INFO]: Epoch 055 - training loss: 0.3851, validation loss: 0.0327
2024-05-25 00:20:24 [INFO]: Epoch 056 - training loss: 0.3847, validation loss: 0.0632
2024-05-25 00:20:24 [INFO]: Epoch 057 - training loss: 0.3803, validation loss: 0.0461
2024-05-25 00:20:25 [INFO]: Epoch 058 - training loss: 0.3751, validation loss: 0.0418
2024-05-25 00:20:25 [INFO]: Epoch 059 - training loss: 0.3740, validation loss: 0.0400
2024-05-25 00:20:26 [INFO]: Epoch 060 - training loss: 0.3643, validation loss: 0.0430
2024-05-25 00:20:26 [INFO]: Epoch 061 - training loss: 0.3569, validation loss: 0.0333
2024-05-25 00:20:27 [INFO]: Epoch 062 - training loss: 0.3541, validation loss: 0.0438
2024-05-25 00:20:27 [INFO]: Epoch 063 - training loss: 0.3593, validation loss: 0.0313
2024-05-25 00:20:28 [INFO]: Epoch 064 - training loss: 0.3394, validation loss: 0.0339
2024-05-25 00:20:28 [INFO]: Epoch 065 - training loss: 0.3435, validation loss: 0.0361
2024-05-25 00:20:29 [INFO]: Epoch 066 - training loss: 0.3330, validation loss: 0.0355
2024-05-25 00:20:29 [INFO]: Epoch 067 - training loss: 0.3315, validation loss: 0.0355
2024-05-25 00:20:30 [INFO]: Epoch 068 - training loss: 0.3322, validation loss: 0.0312
2024-05-25 00:20:30 [INFO]: Epoch 069 - training loss: 0.3241, validation loss: 0.0379
2024-05-25 00:20:31 [INFO]: Epoch 070 - training loss: 0.3273, validation loss: 0.0333
2024-05-25 00:20:31 [INFO]: Epoch 071 - training loss: 0.3193, validation loss: 0.0353
2024-05-25 00:20:32 [INFO]: Epoch 072 - training loss: 0.3108, validation loss: 0.0346
2024-05-25 00:20:32 [INFO]: Epoch 073 - training loss: 0.3120, validation loss: 0.0322
2024-05-25 00:20:33 [INFO]: Epoch 074 - training loss: 0.3073, validation loss: 0.0340
2024-05-25 00:20:33 [INFO]: Epoch 075 - training loss: 0.3077, validation loss: 0.0409
2024-05-25 00:20:34 [INFO]: Epoch 076 - training loss: 0.3004, validation loss: 0.0407
2024-05-25 00:20:34 [INFO]: Epoch 077 - training loss: 0.3009, validation loss: 0.0390
2024-05-25 00:20:35 [INFO]: Epoch 078 - training loss: 0.3164, validation loss: 0.0531
2024-05-25 00:20:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:20:35 [INFO]: Finished training. The best model is from epoch#68.
2024-05-25 00:20:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/SAITS_ettm1/20240525_T001955/SAITS.pypots
2024-05-25 00:20:35 [INFO]: SAITS on ETTm1: MAE=0.1574, MSE=0.0497
2024-05-25 00:20:35 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-25 00:20:35 [INFO]: Using the given device: cuda:0
2024-05-25 00:20:35 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240525_T002035
2024-05-25 00:20:35 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240525_T002035/tensorboard
2024-05-25 00:20:35 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 00:20:35 [INFO]: Epoch 001 - training loss: 1.2112, validation loss: 0.4114
2024-05-25 00:20:36 [INFO]: Epoch 002 - training loss: 0.7535, validation loss: 0.1713
2024-05-25 00:20:36 [INFO]: Epoch 003 - training loss: 0.6134, validation loss: 0.1393
2024-05-25 00:20:36 [INFO]: Epoch 004 - training loss: 0.5519, validation loss: 0.1068
2024-05-25 00:20:36 [INFO]: Epoch 005 - training loss: 0.5077, validation loss: 0.0974
2024-05-25 00:20:36 [INFO]: Epoch 006 - training loss: 0.4871, validation loss: 0.0899
2024-05-25 00:20:37 [INFO]: Epoch 007 - training loss: 0.4664, validation loss: 0.0792
2024-05-25 00:20:37 [INFO]: Epoch 008 - training loss: 0.4611, validation loss: 0.0792
2024-05-25 00:20:37 [INFO]: Epoch 009 - training loss: 0.4583, validation loss: 0.0699
2024-05-25 00:20:37 [INFO]: Epoch 010 - training loss: 0.4254, validation loss: 0.0687
2024-05-25 00:20:37 [INFO]: Epoch 011 - training loss: 0.4163, validation loss: 0.0664
2024-05-25 00:20:38 [INFO]: Epoch 012 - training loss: 0.3974, validation loss: 0.0571
2024-05-25 00:20:38 [INFO]: Epoch 013 - training loss: 0.3871, validation loss: 0.0562
2024-05-25 00:20:38 [INFO]: Epoch 014 - training loss: 0.3829, validation loss: 0.0550
2024-05-25 00:20:38 [INFO]: Epoch 015 - training loss: 0.3805, validation loss: 0.0564
2024-05-25 00:20:39 [INFO]: Epoch 016 - training loss: 0.3764, validation loss: 0.0543
2024-05-25 00:20:39 [INFO]: Epoch 017 - training loss: 0.3612, validation loss: 0.0529
2024-05-25 00:20:39 [INFO]: Epoch 018 - training loss: 0.3570, validation loss: 0.0581
2024-05-25 00:20:39 [INFO]: Epoch 019 - training loss: 0.3512, validation loss: 0.0472
2024-05-25 00:20:39 [INFO]: Epoch 020 - training loss: 0.3489, validation loss: 0.0483
2024-05-25 00:20:40 [INFO]: Epoch 021 - training loss: 0.3501, validation loss: 0.0475
2024-05-25 00:20:40 [INFO]: Epoch 022 - training loss: 0.3382, validation loss: 0.0524
2024-05-25 00:20:40 [INFO]: Epoch 023 - training loss: 0.3332, validation loss: 0.0467
2024-05-25 00:20:40 [INFO]: Epoch 024 - training loss: 0.3271, validation loss: 0.0501
2024-05-25 00:20:41 [INFO]: Epoch 025 - training loss: 0.3372, validation loss: 0.0484
2024-05-25 00:20:41 [INFO]: Epoch 026 - training loss: 0.3218, validation loss: 0.0460
2024-05-25 00:20:41 [INFO]: Epoch 027 - training loss: 0.3205, validation loss: 0.0396
2024-05-25 00:20:41 [INFO]: Epoch 028 - training loss: 0.3107, validation loss: 0.0425
2024-05-25 00:20:41 [INFO]: Epoch 029 - training loss: 0.3121, validation loss: 0.0397
2024-05-25 00:20:42 [INFO]: Epoch 030 - training loss: 0.3038, validation loss: 0.0392
2024-05-25 00:20:42 [INFO]: Epoch 031 - training loss: 0.3043, validation loss: 0.0444
2024-05-25 00:20:42 [INFO]: Epoch 032 - training loss: 0.3032, validation loss: 0.0389
2024-05-25 00:20:42 [INFO]: Epoch 033 - training loss: 0.2984, validation loss: 0.0381
2024-05-25 00:20:42 [INFO]: Epoch 034 - training loss: 0.2955, validation loss: 0.0397
2024-05-25 00:20:43 [INFO]: Epoch 035 - training loss: 0.2931, validation loss: 0.0460
2024-05-25 00:20:43 [INFO]: Epoch 036 - training loss: 0.2898, validation loss: 0.0365
2024-05-25 00:20:43 [INFO]: Epoch 037 - training loss: 0.2876, validation loss: 0.0372
2024-05-25 00:20:43 [INFO]: Epoch 038 - training loss: 0.2818, validation loss: 0.0368
2024-05-25 00:20:44 [INFO]: Epoch 039 - training loss: 0.2789, validation loss: 0.0377
2024-05-25 00:20:44 [INFO]: Epoch 040 - training loss: 0.2735, validation loss: 0.0332
2024-05-25 00:20:44 [INFO]: Epoch 041 - training loss: 0.2744, validation loss: 0.0339
2024-05-25 00:20:44 [INFO]: Epoch 042 - training loss: 0.2731, validation loss: 0.0333
2024-05-25 00:20:44 [INFO]: Epoch 043 - training loss: 0.2724, validation loss: 0.0352
2024-05-25 00:20:45 [INFO]: Epoch 044 - training loss: 0.2691, validation loss: 0.0331
2024-05-25 00:20:45 [INFO]: Epoch 045 - training loss: 0.2626, validation loss: 0.0348
2024-05-25 00:20:45 [INFO]: Epoch 046 - training loss: 0.2652, validation loss: 0.0353
2024-05-25 00:20:45 [INFO]: Epoch 047 - training loss: 0.2689, validation loss: 0.0344
2024-05-25 00:20:45 [INFO]: Epoch 048 - training loss: 0.2615, validation loss: 0.0304
2024-05-25 00:20:46 [INFO]: Epoch 049 - training loss: 0.2575, validation loss: 0.0299
2024-05-25 00:20:46 [INFO]: Epoch 050 - training loss: 0.2604, validation loss: 0.0320
2024-05-25 00:20:46 [INFO]: Epoch 051 - training loss: 0.2511, validation loss: 0.0298
2024-05-25 00:20:46 [INFO]: Epoch 052 - training loss: 0.2523, validation loss: 0.0336
2024-05-25 00:20:47 [INFO]: Epoch 053 - training loss: 0.2523, validation loss: 0.0367
2024-05-25 00:20:47 [INFO]: Epoch 054 - training loss: 0.2544, validation loss: 0.0348
2024-05-25 00:20:47 [INFO]: Epoch 055 - training loss: 0.2518, validation loss: 0.0323
2024-05-25 00:20:47 [INFO]: Epoch 056 - training loss: 0.2461, validation loss: 0.0288
2024-05-25 00:20:47 [INFO]: Epoch 057 - training loss: 0.2415, validation loss: 0.0306
2024-05-25 00:20:48 [INFO]: Epoch 058 - training loss: 0.2468, validation loss: 0.0307
2024-05-25 00:20:48 [INFO]: Epoch 059 - training loss: 0.2390, validation loss: 0.0285
2024-05-25 00:20:48 [INFO]: Epoch 060 - training loss: 0.2347, validation loss: 0.0289
2024-05-25 00:20:48 [INFO]: Epoch 061 - training loss: 0.2359, validation loss: 0.0281
2024-05-25 00:20:49 [INFO]: Epoch 062 - training loss: 0.2295, validation loss: 0.0308
2024-05-25 00:20:49 [INFO]: Epoch 063 - training loss: 0.2439, validation loss: 0.0319
2024-05-25 00:20:49 [INFO]: Epoch 064 - training loss: 0.2406, validation loss: 0.0281
2024-05-25 00:20:49 [INFO]: Epoch 065 - training loss: 0.2356, validation loss: 0.0280
2024-05-25 00:20:49 [INFO]: Epoch 066 - training loss: 0.2291, validation loss: 0.0355
2024-05-25 00:20:50 [INFO]: Epoch 067 - training loss: 0.2343, validation loss: 0.0275
2024-05-25 00:20:50 [INFO]: Epoch 068 - training loss: 0.2259, validation loss: 0.0259
2024-05-25 00:20:50 [INFO]: Epoch 069 - training loss: 0.2212, validation loss: 0.0315
2024-05-25 00:20:50 [INFO]: Epoch 070 - training loss: 0.2277, validation loss: 0.0290
2024-05-25 00:20:50 [INFO]: Epoch 071 - training loss: 0.2250, validation loss: 0.0292
2024-05-25 00:20:51 [INFO]: Epoch 072 - training loss: 0.2259, validation loss: 0.0280
2024-05-25 00:20:51 [INFO]: Epoch 073 - training loss: 0.2223, validation loss: 0.0281
2024-05-25 00:20:51 [INFO]: Epoch 074 - training loss: 0.2233, validation loss: 0.0280
2024-05-25 00:20:51 [INFO]: Epoch 075 - training loss: 0.2277, validation loss: 0.0319
2024-05-25 00:20:52 [INFO]: Epoch 076 - training loss: 0.2257, validation loss: 0.0277
2024-05-25 00:20:52 [INFO]: Epoch 077 - training loss: 0.2207, validation loss: 0.0277
2024-05-25 00:20:52 [INFO]: Epoch 078 - training loss: 0.2220, validation loss: 0.0260
2024-05-25 00:20:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:20:52 [INFO]: Finished training. The best model is from epoch#68.
2024-05-25 00:20:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/Transformer_ettm1/20240525_T002035/Transformer.pypots
2024-05-25 00:20:52 [INFO]: Transformer on ETTm1: MAE=0.1346, MSE=0.0376
2024-05-25 00:20:52 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-25 00:20:52 [INFO]: Using the given device: cuda:0
2024-05-25 00:20:52 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240525_T002052
2024-05-25 00:20:52 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240525_T002052/tensorboard
2024-05-25 00:20:52 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 00:20:52 [INFO]: Epoch 001 - training loss: 0.1446, validation loss: 0.0551
2024-05-25 00:20:53 [INFO]: Epoch 002 - training loss: 0.0684, validation loss: 0.0427
2024-05-25 00:20:53 [INFO]: Epoch 003 - training loss: 0.0587, validation loss: 0.0394
2024-05-25 00:20:53 [INFO]: Epoch 004 - training loss: 0.0625, validation loss: 0.0414
2024-05-25 00:20:53 [INFO]: Epoch 005 - training loss: 0.0616, validation loss: 0.0405
2024-05-25 00:20:53 [INFO]: Epoch 006 - training loss: 0.0564, validation loss: 0.0366
2024-05-25 00:20:54 [INFO]: Epoch 007 - training loss: 0.0523, validation loss: 0.0364
2024-05-25 00:20:54 [INFO]: Epoch 008 - training loss: 0.0525, validation loss: 0.0355
2024-05-25 00:20:54 [INFO]: Epoch 009 - training loss: 0.0521, validation loss: 0.0364
2024-05-25 00:20:54 [INFO]: Epoch 010 - training loss: 0.0540, validation loss: 0.0373
2024-05-25 00:20:55 [INFO]: Epoch 011 - training loss: 0.0523, validation loss: 0.0351
2024-05-25 00:20:55 [INFO]: Epoch 012 - training loss: 0.0527, validation loss: 0.0352
2024-05-25 00:20:55 [INFO]: Epoch 013 - training loss: 0.0484, validation loss: 0.0336
2024-05-25 00:20:55 [INFO]: Epoch 014 - training loss: 0.0475, validation loss: 0.0353
2024-05-25 00:20:55 [INFO]: Epoch 015 - training loss: 0.0504, validation loss: 0.0340
2024-05-25 00:20:56 [INFO]: Epoch 016 - training loss: 0.0496, validation loss: 0.0337
2024-05-25 00:20:56 [INFO]: Epoch 017 - training loss: 0.0475, validation loss: 0.0386
2024-05-25 00:20:56 [INFO]: Epoch 018 - training loss: 0.0531, validation loss: 0.0402
2024-05-25 00:20:56 [INFO]: Epoch 019 - training loss: 0.0534, validation loss: 0.0352
2024-05-25 00:20:56 [INFO]: Epoch 020 - training loss: 0.0496, validation loss: 0.0355
2024-05-25 00:20:57 [INFO]: Epoch 021 - training loss: 0.0457, validation loss: 0.0313
2024-05-25 00:20:57 [INFO]: Epoch 022 - training loss: 0.0482, validation loss: 0.0364
2024-05-25 00:20:57 [INFO]: Epoch 023 - training loss: 0.0518, validation loss: 0.0350
2024-05-25 00:20:57 [INFO]: Epoch 024 - training loss: 0.0451, validation loss: 0.0332
2024-05-25 00:20:58 [INFO]: Epoch 025 - training loss: 0.0439, validation loss: 0.0305
2024-05-25 00:20:58 [INFO]: Epoch 026 - training loss: 0.0465, validation loss: 0.0339
2024-05-25 00:20:58 [INFO]: Epoch 027 - training loss: 0.0484, validation loss: 0.0316
2024-05-25 00:20:58 [INFO]: Epoch 028 - training loss: 0.0473, validation loss: 0.0312
2024-05-25 00:20:58 [INFO]: Epoch 029 - training loss: 0.0442, validation loss: 0.0314
2024-05-25 00:20:59 [INFO]: Epoch 030 - training loss: 0.0436, validation loss: 0.0308
2024-05-25 00:20:59 [INFO]: Epoch 031 - training loss: 0.0423, validation loss: 0.0313
2024-05-25 00:20:59 [INFO]: Epoch 032 - training loss: 0.0417, validation loss: 0.0301
2024-05-25 00:20:59 [INFO]: Epoch 033 - training loss: 0.0415, validation loss: 0.0304
2024-05-25 00:20:59 [INFO]: Epoch 034 - training loss: 0.0411, validation loss: 0.0336
2024-05-25 00:21:00 [INFO]: Epoch 035 - training loss: 0.0411, validation loss: 0.0312
2024-05-25 00:21:00 [INFO]: Epoch 036 - training loss: 0.0419, validation loss: 0.0321
2024-05-25 00:21:00 [INFO]: Epoch 037 - training loss: 0.0439, validation loss: 0.0307
2024-05-25 00:21:00 [INFO]: Epoch 038 - training loss: 0.0457, validation loss: 0.0299
2024-05-25 00:21:00 [INFO]: Epoch 039 - training loss: 0.0416, validation loss: 0.0303
2024-05-25 00:21:01 [INFO]: Epoch 040 - training loss: 0.0397, validation loss: 0.0295
2024-05-25 00:21:01 [INFO]: Epoch 041 - training loss: 0.0394, validation loss: 0.0303
2024-05-25 00:21:01 [INFO]: Epoch 042 - training loss: 0.0409, validation loss: 0.0311
2024-05-25 00:21:01 [INFO]: Epoch 043 - training loss: 0.0425, validation loss: 0.0304
2024-05-25 00:21:02 [INFO]: Epoch 044 - training loss: 0.0444, validation loss: 0.0318
2024-05-25 00:21:02 [INFO]: Epoch 045 - training loss: 0.0416, validation loss: 0.0283
2024-05-25 00:21:02 [INFO]: Epoch 046 - training loss: 0.0405, validation loss: 0.0291
2024-05-25 00:21:02 [INFO]: Epoch 047 - training loss: 0.0405, validation loss: 0.0284
2024-05-25 00:21:02 [INFO]: Epoch 048 - training loss: 0.0391, validation loss: 0.0274
2024-05-25 00:21:03 [INFO]: Epoch 049 - training loss: 0.0372, validation loss: 0.0279
2024-05-25 00:21:03 [INFO]: Epoch 050 - training loss: 0.0387, validation loss: 0.0283
2024-05-25 00:21:03 [INFO]: Epoch 051 - training loss: 0.0398, validation loss: 0.0295
2024-05-25 00:21:03 [INFO]: Epoch 052 - training loss: 0.0436, validation loss: 0.0281
2024-05-25 00:21:03 [INFO]: Epoch 053 - training loss: 0.0400, validation loss: 0.0296
2024-05-25 00:21:04 [INFO]: Epoch 054 - training loss: 0.0400, validation loss: 0.0288
2024-05-25 00:21:04 [INFO]: Epoch 055 - training loss: 0.0402, validation loss: 0.0288
2024-05-25 00:21:04 [INFO]: Epoch 056 - training loss: 0.0400, validation loss: 0.0285
2024-05-25 00:21:04 [INFO]: Epoch 057 - training loss: 0.0397, validation loss: 0.0273
2024-05-25 00:21:04 [INFO]: Epoch 058 - training loss: 0.0389, validation loss: 0.0273
2024-05-25 00:21:05 [INFO]: Epoch 059 - training loss: 0.0382, validation loss: 0.0269
2024-05-25 00:21:05 [INFO]: Epoch 060 - training loss: 0.0369, validation loss: 0.0267
2024-05-25 00:21:05 [INFO]: Epoch 061 - training loss: 0.0384, validation loss: 0.0275
2024-05-25 00:21:05 [INFO]: Epoch 062 - training loss: 0.0419, validation loss: 0.0272
2024-05-25 00:21:05 [INFO]: Epoch 063 - training loss: 0.0383, validation loss: 0.0281
2024-05-25 00:21:06 [INFO]: Epoch 064 - training loss: 0.0351, validation loss: 0.0264
2024-05-25 00:21:06 [INFO]: Epoch 065 - training loss: 0.0345, validation loss: 0.0260
2024-05-25 00:21:06 [INFO]: Epoch 066 - training loss: 0.0361, validation loss: 0.0263
2024-05-25 00:21:06 [INFO]: Epoch 067 - training loss: 0.0414, validation loss: 0.0266
2024-05-25 00:21:07 [INFO]: Epoch 068 - training loss: 0.0379, validation loss: 0.0255
2024-05-25 00:21:07 [INFO]: Epoch 069 - training loss: 0.0368, validation loss: 0.0268
2024-05-25 00:21:07 [INFO]: Epoch 070 - training loss: 0.0353, validation loss: 0.0256
2024-05-25 00:21:07 [INFO]: Epoch 071 - training loss: 0.0349, validation loss: 0.0256
2024-05-25 00:21:07 [INFO]: Epoch 072 - training loss: 0.0380, validation loss: 0.0277
2024-05-25 00:21:08 [INFO]: Epoch 073 - training loss: 0.0391, validation loss: 0.0271
2024-05-25 00:21:08 [INFO]: Epoch 074 - training loss: 0.0359, validation loss: 0.0258
2024-05-25 00:21:08 [INFO]: Epoch 075 - training loss: 0.0351, validation loss: 0.0253
2024-05-25 00:21:08 [INFO]: Epoch 076 - training loss: 0.0345, validation loss: 0.0251
2024-05-25 00:21:08 [INFO]: Epoch 077 - training loss: 0.0343, validation loss: 0.0255
2024-05-25 00:21:09 [INFO]: Epoch 078 - training loss: 0.0335, validation loss: 0.0255
2024-05-25 00:21:09 [INFO]: Epoch 079 - training loss: 0.0343, validation loss: 0.0258
2024-05-25 00:21:09 [INFO]: Epoch 080 - training loss: 0.0326, validation loss: 0.0263
2024-05-25 00:21:09 [INFO]: Epoch 081 - training loss: 0.0323, validation loss: 0.0250
2024-05-25 00:21:09 [INFO]: Epoch 082 - training loss: 0.0331, validation loss: 0.0267
2024-05-25 00:21:10 [INFO]: Epoch 083 - training loss: 0.0351, validation loss: 0.0250
2024-05-25 00:21:10 [INFO]: Epoch 084 - training loss: 0.0326, validation loss: 0.0248
2024-05-25 00:21:10 [INFO]: Epoch 085 - training loss: 0.0338, validation loss: 0.0248
2024-05-25 00:21:10 [INFO]: Epoch 086 - training loss: 0.0339, validation loss: 0.0255
2024-05-25 00:21:11 [INFO]: Epoch 087 - training loss: 0.0342, validation loss: 0.0246
2024-05-25 00:21:11 [INFO]: Epoch 088 - training loss: 0.0361, validation loss: 0.0252
2024-05-25 00:21:11 [INFO]: Epoch 089 - training loss: 0.0370, validation loss: 0.0268
2024-05-25 00:21:11 [INFO]: Epoch 090 - training loss: 0.0337, validation loss: 0.0250
2024-05-25 00:21:11 [INFO]: Epoch 091 - training loss: 0.0339, validation loss: 0.0245
2024-05-25 00:21:12 [INFO]: Epoch 092 - training loss: 0.0361, validation loss: 0.0247
2024-05-25 00:21:12 [INFO]: Epoch 093 - training loss: 0.0344, validation loss: 0.0248
2024-05-25 00:21:12 [INFO]: Epoch 094 - training loss: 0.0366, validation loss: 0.0243
2024-05-25 00:21:12 [INFO]: Epoch 095 - training loss: 0.0396, validation loss: 0.0248
2024-05-25 00:21:12 [INFO]: Epoch 096 - training loss: 0.0369, validation loss: 0.0253
2024-05-25 00:21:13 [INFO]: Epoch 097 - training loss: 0.0369, validation loss: 0.0259
2024-05-25 00:21:13 [INFO]: Epoch 098 - training loss: 0.0348, validation loss: 0.0255
2024-05-25 00:21:13 [INFO]: Epoch 099 - training loss: 0.0362, validation loss: 0.0266
2024-05-25 00:21:13 [INFO]: Epoch 100 - training loss: 0.0377, validation loss: 0.0258
2024-05-25 00:21:13 [INFO]: Epoch 101 - training loss: 0.0356, validation loss: 0.0255
2024-05-25 00:21:14 [INFO]: Epoch 102 - training loss: 0.0324, validation loss: 0.0248
2024-05-25 00:21:14 [INFO]: Epoch 103 - training loss: 0.0349, validation loss: 0.0246
2024-05-25 00:21:14 [INFO]: Epoch 104 - training loss: 0.0337, validation loss: 0.0239
2024-05-25 00:21:14 [INFO]: Epoch 105 - training loss: 0.0348, validation loss: 0.0267
2024-05-25 00:21:15 [INFO]: Epoch 106 - training loss: 0.0380, validation loss: 0.0254
2024-05-25 00:21:15 [INFO]: Epoch 107 - training loss: 0.0357, validation loss: 0.0246
2024-05-25 00:21:15 [INFO]: Epoch 108 - training loss: 0.0334, validation loss: 0.0242
2024-05-25 00:21:15 [INFO]: Epoch 109 - training loss: 0.0341, validation loss: 0.0253
2024-05-25 00:21:15 [INFO]: Epoch 110 - training loss: 0.0323, validation loss: 0.0243
2024-05-25 00:21:16 [INFO]: Epoch 111 - training loss: 0.0311, validation loss: 0.0229
2024-05-25 00:21:16 [INFO]: Epoch 112 - training loss: 0.0302, validation loss: 0.0240
2024-05-25 00:21:16 [INFO]: Epoch 113 - training loss: 0.0318, validation loss: 0.0240
2024-05-25 00:21:16 [INFO]: Epoch 114 - training loss: 0.0346, validation loss: 0.0234
2024-05-25 00:21:16 [INFO]: Epoch 115 - training loss: 0.0315, validation loss: 0.0232
2024-05-25 00:21:17 [INFO]: Epoch 116 - training loss: 0.0307, validation loss: 0.0232
2024-05-25 00:21:17 [INFO]: Epoch 117 - training loss: 0.0319, validation loss: 0.0237
2024-05-25 00:21:17 [INFO]: Epoch 118 - training loss: 0.0322, validation loss: 0.0243
2024-05-25 00:21:17 [INFO]: Epoch 119 - training loss: 0.0312, validation loss: 0.0235
2024-05-25 00:21:17 [INFO]: Epoch 120 - training loss: 0.0306, validation loss: 0.0232
2024-05-25 00:21:18 [INFO]: Epoch 121 - training loss: 0.0315, validation loss: 0.0243
2024-05-25 00:21:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:21:18 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 00:21:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/TimesNet_ettm1/20240525_T002052/TimesNet.pypots
2024-05-25 00:21:18 [INFO]: TimesNet on ETTm1: MAE=0.1121, MSE=0.0272
2024-05-25 00:21:18 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-25 00:21:18 [INFO]: Using the given device: cuda:0
2024-05-25 00:21:18 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118
2024-05-25 00:21:18 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/tensorboard
2024-05-25 00:21:18 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 00:21:20 [INFO]: Epoch 001 - training loss: 0.6950, validation loss: 0.4389
2024-05-25 00:21:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch1_loss0.4388744607567787.pypots
2024-05-25 00:21:22 [INFO]: Epoch 002 - training loss: 0.3465, validation loss: 0.3585
2024-05-25 00:21:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch2_loss0.3584524616599083.pypots
2024-05-25 00:21:24 [INFO]: Epoch 003 - training loss: 0.3229, validation loss: 0.3410
2024-05-25 00:21:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch3_loss0.3410283699631691.pypots
2024-05-25 00:21:26 [INFO]: Epoch 004 - training loss: 0.3604, validation loss: 0.3396
2024-05-25 00:21:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch4_loss0.3395739272236824.pypots
2024-05-25 00:21:28 [INFO]: Epoch 005 - training loss: 0.2971, validation loss: 0.2994
2024-05-25 00:21:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch5_loss0.2993692681193352.pypots
2024-05-25 00:21:30 [INFO]: Epoch 006 - training loss: 0.3294, validation loss: 0.3106
2024-05-25 00:21:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch6_loss0.3105785474181175.pypots
2024-05-25 00:21:32 [INFO]: Epoch 007 - training loss: 0.2664, validation loss: 0.2864
2024-05-25 00:21:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch7_loss0.2863842770457268.pypots
2024-05-25 00:21:34 [INFO]: Epoch 008 - training loss: 0.2842, validation loss: 0.2727
2024-05-25 00:21:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch8_loss0.27274417132139206.pypots
2024-05-25 00:21:36 [INFO]: Epoch 009 - training loss: 0.2762, validation loss: 0.2910
2024-05-25 00:21:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch9_loss0.29096464067697525.pypots
2024-05-25 00:21:38 [INFO]: Epoch 010 - training loss: 0.3026, validation loss: 0.3102
2024-05-25 00:21:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch10_loss0.31019604206085205.pypots
2024-05-25 00:21:41 [INFO]: Epoch 011 - training loss: 0.2933, validation loss: 0.2995
2024-05-25 00:21:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch11_loss0.29954908043146133.pypots
2024-05-25 00:21:43 [INFO]: Epoch 012 - training loss: 0.2402, validation loss: 0.2568
2024-05-25 00:21:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch12_loss0.25683392584323883.pypots
2024-05-25 00:21:45 [INFO]: Epoch 013 - training loss: 0.2652, validation loss: 0.2472
2024-05-25 00:21:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch13_loss0.247174222022295.pypots
2024-05-25 00:21:47 [INFO]: Epoch 014 - training loss: 0.2672, validation loss: 0.2411
2024-05-25 00:21:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch14_loss0.2411414571106434.pypots
2024-05-25 00:21:49 [INFO]: Epoch 015 - training loss: 0.2822, validation loss: 0.2744
2024-05-25 00:21:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch15_loss0.27439243346452713.pypots
2024-05-25 00:21:51 [INFO]: Epoch 016 - training loss: 0.2796, validation loss: 0.2722
2024-05-25 00:21:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch16_loss0.2721504271030426.pypots
2024-05-25 00:21:53 [INFO]: Epoch 017 - training loss: 0.2230, validation loss: 0.2430
2024-05-25 00:21:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch17_loss0.24302472546696663.pypots
2024-05-25 00:21:55 [INFO]: Epoch 018 - training loss: 0.3047, validation loss: 0.2334
2024-05-25 00:21:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch18_loss0.23337315395474434.pypots
2024-05-25 00:21:57 [INFO]: Epoch 019 - training loss: 0.2375, validation loss: 0.2376
2024-05-25 00:21:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch19_loss0.2375553622841835.pypots
2024-05-25 00:21:59 [INFO]: Epoch 020 - training loss: 0.2285, validation loss: 0.2224
2024-05-25 00:21:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch20_loss0.22236882522702217.pypots
2024-05-25 00:22:01 [INFO]: Epoch 021 - training loss: 0.2343, validation loss: 0.2129
2024-05-25 00:22:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch21_loss0.21294989809393883.pypots
2024-05-25 00:22:03 [INFO]: Epoch 022 - training loss: 0.2162, validation loss: 0.2189
2024-05-25 00:22:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch22_loss0.21889293566346169.pypots
2024-05-25 00:22:06 [INFO]: Epoch 023 - training loss: 0.2224, validation loss: 0.2076
2024-05-25 00:22:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch23_loss0.20760298147797585.pypots
2024-05-25 00:22:08 [INFO]: Epoch 024 - training loss: 0.2284, validation loss: 0.1972
2024-05-25 00:22:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch24_loss0.19724437594413757.pypots
2024-05-25 00:22:10 [INFO]: Epoch 025 - training loss: 0.2108, validation loss: 0.2023
2024-05-25 00:22:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch25_loss0.20225688070058823.pypots
2024-05-25 00:22:12 [INFO]: Epoch 026 - training loss: 0.2014, validation loss: 0.1987
2024-05-25 00:22:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch26_loss0.1987360306084156.pypots
2024-05-25 00:22:14 [INFO]: Epoch 027 - training loss: 0.2081, validation loss: 0.2084
2024-05-25 00:22:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch27_loss0.2084374763071537.pypots
2024-05-25 00:22:16 [INFO]: Epoch 028 - training loss: 0.2114, validation loss: 0.2056
2024-05-25 00:22:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch28_loss0.20555484667420387.pypots
2024-05-25 00:22:18 [INFO]: Epoch 029 - training loss: 0.2385, validation loss: 0.2465
2024-05-25 00:22:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch29_loss0.24649007245898247.pypots
2024-05-25 00:22:20 [INFO]: Epoch 030 - training loss: 0.2199, validation loss: 0.2003
2024-05-25 00:22:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch30_loss0.20033854618668556.pypots
2024-05-25 00:22:22 [INFO]: Epoch 031 - training loss: 0.2682, validation loss: 0.1891
2024-05-25 00:22:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch31_loss0.18912632018327713.pypots
2024-05-25 00:22:24 [INFO]: Epoch 032 - training loss: 0.1786, validation loss: 0.1837
2024-05-25 00:22:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch32_loss0.1836860552430153.pypots
2024-05-25 00:22:26 [INFO]: Epoch 033 - training loss: 0.2024, validation loss: 0.1887
2024-05-25 00:22:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch33_loss0.18870218098163605.pypots
2024-05-25 00:22:28 [INFO]: Epoch 034 - training loss: 0.1819, validation loss: 0.1819
2024-05-25 00:22:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch34_loss0.18186745420098305.pypots
2024-05-25 00:22:30 [INFO]: Epoch 035 - training loss: 0.2025, validation loss: 0.1765
2024-05-25 00:22:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch35_loss0.17645453661680222.pypots
2024-05-25 00:22:33 [INFO]: Epoch 036 - training loss: 0.1734, validation loss: 0.1721
2024-05-25 00:22:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch36_loss0.172122985124588.pypots
2024-05-25 00:22:35 [INFO]: Epoch 037 - training loss: 0.1923, validation loss: 0.1738
2024-05-25 00:22:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch37_loss0.17384827882051468.pypots
2024-05-25 00:22:37 [INFO]: Epoch 038 - training loss: 0.1963, validation loss: 0.1730
2024-05-25 00:22:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch38_loss0.17300790175795555.pypots
2024-05-25 00:22:39 [INFO]: Epoch 039 - training loss: 0.1903, validation loss: 0.1699
2024-05-25 00:22:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch39_loss0.1698872484266758.pypots
2024-05-25 00:22:41 [INFO]: Epoch 040 - training loss: 0.1887, validation loss: 0.1692
2024-05-25 00:22:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch40_loss0.16921110823750496.pypots
2024-05-25 00:22:43 [INFO]: Epoch 041 - training loss: 0.1874, validation loss: 0.1827
2024-05-25 00:22:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch41_loss0.1826731190085411.pypots
2024-05-25 00:22:45 [INFO]: Epoch 042 - training loss: 0.2155, validation loss: 0.1711
2024-05-25 00:22:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch42_loss0.17111754417419434.pypots
2024-05-25 00:22:47 [INFO]: Epoch 043 - training loss: 0.1832, validation loss: 0.1746
2024-05-25 00:22:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch43_loss0.1745607852935791.pypots
2024-05-25 00:22:49 [INFO]: Epoch 044 - training loss: 0.2349, validation loss: 0.1739
2024-05-25 00:22:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch44_loss0.17386744543910027.pypots
2024-05-25 00:22:51 [INFO]: Epoch 045 - training loss: 0.2202, validation loss: 0.1796
2024-05-25 00:22:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch45_loss0.17957210913300514.pypots
2024-05-25 00:22:53 [INFO]: Epoch 046 - training loss: 0.1989, validation loss: 0.1792
2024-05-25 00:22:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch46_loss0.1792033612728119.pypots
2024-05-25 00:22:55 [INFO]: Epoch 047 - training loss: 0.2465, validation loss: 0.1729
2024-05-25 00:22:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch47_loss0.17292902991175652.pypots
2024-05-25 00:22:57 [INFO]: Epoch 048 - training loss: 0.1873, validation loss: 0.1613
2024-05-25 00:22:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch48_loss0.1612815409898758.pypots
2024-05-25 00:22:59 [INFO]: Epoch 049 - training loss: 0.1694, validation loss: 0.1595
2024-05-25 00:22:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch49_loss0.15948179364204407.pypots
2024-05-25 00:23:02 [INFO]: Epoch 050 - training loss: 0.1558, validation loss: 0.1582
2024-05-25 00:23:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch50_loss0.1582215018570423.pypots
2024-05-25 00:23:04 [INFO]: Epoch 051 - training loss: 0.1744, validation loss: 0.1630
2024-05-25 00:23:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch51_loss0.16302138939499855.pypots
2024-05-25 00:23:06 [INFO]: Epoch 052 - training loss: 0.1717, validation loss: 0.1583
2024-05-25 00:23:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch52_loss0.15833667665719986.pypots
2024-05-25 00:23:08 [INFO]: Epoch 053 - training loss: 0.1629, validation loss: 0.1540
2024-05-25 00:23:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch53_loss0.15401380881667137.pypots
2024-05-25 00:23:10 [INFO]: Epoch 054 - training loss: 0.1665, validation loss: 0.1538
2024-05-25 00:23:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch54_loss0.15375439450144768.pypots
2024-05-25 00:23:12 [INFO]: Epoch 055 - training loss: 0.1560, validation loss: 0.1481
2024-05-25 00:23:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch55_loss0.148081436753273.pypots
2024-05-25 00:23:14 [INFO]: Epoch 056 - training loss: 0.1502, validation loss: 0.1475
2024-05-25 00:23:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch56_loss0.14749734476208687.pypots
2024-05-25 00:23:16 [INFO]: Epoch 057 - training loss: 0.2237, validation loss: 0.1491
2024-05-25 00:23:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch57_loss0.14913199096918106.pypots
2024-05-25 00:23:18 [INFO]: Epoch 058 - training loss: 0.1750, validation loss: 0.1531
2024-05-25 00:23:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch58_loss0.15308118239045143.pypots
2024-05-25 00:23:20 [INFO]: Epoch 059 - training loss: 0.2061, validation loss: 0.2022
2024-05-25 00:23:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch59_loss0.20216597244143486.pypots
2024-05-25 00:23:22 [INFO]: Epoch 060 - training loss: 0.1904, validation loss: 0.1557
2024-05-25 00:23:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch60_loss0.15567883476614952.pypots
2024-05-25 00:23:24 [INFO]: Epoch 061 - training loss: 0.2303, validation loss: 0.1464
2024-05-25 00:23:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch61_loss0.14636792987585068.pypots
2024-05-25 00:23:26 [INFO]: Epoch 062 - training loss: 0.1642, validation loss: 0.1517
2024-05-25 00:23:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch62_loss0.15171337500214577.pypots
2024-05-25 00:23:29 [INFO]: Epoch 063 - training loss: 0.1495, validation loss: 0.1465
2024-05-25 00:23:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch63_loss0.14647267758846283.pypots
2024-05-25 00:23:31 [INFO]: Epoch 064 - training loss: 0.1755, validation loss: 0.1459
2024-05-25 00:23:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch64_loss0.14585444331169128.pypots
2024-05-25 00:23:33 [INFO]: Epoch 065 - training loss: 0.1778, validation loss: 0.1571
2024-05-25 00:23:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch65_loss0.15709704160690308.pypots
2024-05-25 00:23:35 [INFO]: Epoch 066 - training loss: 0.1963, validation loss: 0.1616
2024-05-25 00:23:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch66_loss0.16163795441389084.pypots
2024-05-25 00:23:37 [INFO]: Epoch 067 - training loss: 0.1969, validation loss: 0.2048
2024-05-25 00:23:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch67_loss0.20477817207574844.pypots
2024-05-25 00:23:39 [INFO]: Epoch 068 - training loss: 0.2090, validation loss: 0.1778
2024-05-25 00:23:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch68_loss0.17779530212283134.pypots
2024-05-25 00:23:41 [INFO]: Epoch 069 - training loss: 0.1894, validation loss: 0.1636
2024-05-25 00:23:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch69_loss0.16356631368398666.pypots
2024-05-25 00:23:43 [INFO]: Epoch 070 - training loss: 0.1905, validation loss: 0.1579
2024-05-25 00:23:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch70_loss0.15790344774723053.pypots
2024-05-25 00:23:45 [INFO]: Epoch 071 - training loss: 0.2147, validation loss: 0.1538
2024-05-25 00:23:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch71_loss0.15381190180778503.pypots
2024-05-25 00:23:47 [INFO]: Epoch 072 - training loss: 0.1757, validation loss: 0.1458
2024-05-25 00:23:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch72_loss0.14575232565402985.pypots
2024-05-25 00:23:49 [INFO]: Epoch 073 - training loss: 0.1764, validation loss: 0.1492
2024-05-25 00:23:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch73_loss0.1492069810628891.pypots
2024-05-25 00:23:51 [INFO]: Epoch 074 - training loss: 0.1788, validation loss: 0.1526
2024-05-25 00:23:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch74_loss0.15258179977536201.pypots
2024-05-25 00:23:53 [INFO]: Epoch 075 - training loss: 0.1845, validation loss: 0.1616
2024-05-25 00:23:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch75_loss0.16163235157728195.pypots
2024-05-25 00:23:56 [INFO]: Epoch 076 - training loss: 0.1570, validation loss: 0.1431
2024-05-25 00:23:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch76_loss0.14305531233549118.pypots
2024-05-25 00:23:58 [INFO]: Epoch 077 - training loss: 0.1621, validation loss: 0.1451
2024-05-25 00:23:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch77_loss0.14509844034910202.pypots
2024-05-25 00:24:00 [INFO]: Epoch 078 - training loss: 0.2124, validation loss: 0.1414
2024-05-25 00:24:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch78_loss0.14139679819345474.pypots
2024-05-25 00:24:02 [INFO]: Epoch 079 - training loss: 0.2141, validation loss: 0.1563
2024-05-25 00:24:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch79_loss0.15634684637188911.pypots
2024-05-25 00:24:04 [INFO]: Epoch 080 - training loss: 0.2200, validation loss: 0.1528
2024-05-25 00:24:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch80_loss0.15280277281999588.pypots
2024-05-25 00:24:06 [INFO]: Epoch 081 - training loss: 0.1750, validation loss: 0.1577
2024-05-25 00:24:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch81_loss0.15767300873994827.pypots
2024-05-25 00:24:08 [INFO]: Epoch 082 - training loss: 0.1695, validation loss: 0.1527
2024-05-25 00:24:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch82_loss0.15268512442708015.pypots
2024-05-25 00:24:10 [INFO]: Epoch 083 - training loss: 0.1894, validation loss: 0.1441
2024-05-25 00:24:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch83_loss0.14411495625972748.pypots
2024-05-25 00:24:12 [INFO]: Epoch 084 - training loss: 0.1593, validation loss: 0.1606
2024-05-25 00:24:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch84_loss0.1605832576751709.pypots
2024-05-25 00:24:14 [INFO]: Epoch 085 - training loss: 0.1694, validation loss: 0.1436
2024-05-25 00:24:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch85_loss0.14364660158753395.pypots
2024-05-25 00:24:16 [INFO]: Epoch 086 - training loss: 0.1622, validation loss: 0.1395
2024-05-25 00:24:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch86_loss0.1395341455936432.pypots
2024-05-25 00:24:18 [INFO]: Epoch 087 - training loss: 0.1778, validation loss: 0.1378
2024-05-25 00:24:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch87_loss0.13780684396624565.pypots
2024-05-25 00:24:20 [INFO]: Epoch 088 - training loss: 0.1423, validation loss: 0.1385
2024-05-25 00:24:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch88_loss0.13851938024163246.pypots
2024-05-25 00:24:22 [INFO]: Epoch 089 - training loss: 0.1424, validation loss: 0.1385
2024-05-25 00:24:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch89_loss0.1385137215256691.pypots
2024-05-25 00:24:25 [INFO]: Epoch 090 - training loss: 0.1686, validation loss: 0.1367
2024-05-25 00:24:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch90_loss0.13673745840787888.pypots
2024-05-25 00:24:27 [INFO]: Epoch 091 - training loss: 0.1658, validation loss: 0.1366
2024-05-25 00:24:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch91_loss0.13662132248282433.pypots
2024-05-25 00:24:29 [INFO]: Epoch 092 - training loss: 0.2127, validation loss: 0.1476
2024-05-25 00:24:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch92_loss0.14759282395243645.pypots
2024-05-25 00:24:31 [INFO]: Epoch 093 - training loss: 0.1614, validation loss: 0.1490
2024-05-25 00:24:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch93_loss0.14897123724222183.pypots
2024-05-25 00:24:33 [INFO]: Epoch 094 - training loss: 0.1966, validation loss: 0.1396
2024-05-25 00:24:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch94_loss0.13959886506199837.pypots
2024-05-25 00:24:35 [INFO]: Epoch 095 - training loss: 0.1721, validation loss: 0.1414
2024-05-25 00:24:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch95_loss0.14138439297676086.pypots
2024-05-25 00:24:37 [INFO]: Epoch 096 - training loss: 0.1728, validation loss: 0.1459
2024-05-25 00:24:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch96_loss0.14593101292848587.pypots
2024-05-25 00:24:39 [INFO]: Epoch 097 - training loss: 0.1557, validation loss: 0.1421
2024-05-25 00:24:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch97_loss0.14209778979420662.pypots
2024-05-25 00:24:41 [INFO]: Epoch 098 - training loss: 0.1684, validation loss: 0.1396
2024-05-25 00:24:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch98_loss0.1395818442106247.pypots
2024-05-25 00:24:43 [INFO]: Epoch 099 - training loss: 0.1561, validation loss: 0.1306
2024-05-25 00:24:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch99_loss0.1305932868272066.pypots
2024-05-25 00:24:45 [INFO]: Epoch 100 - training loss: 0.1670, validation loss: 0.1420
2024-05-25 00:24:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch100_loss0.1420065201818943.pypots
2024-05-25 00:24:47 [INFO]: Epoch 101 - training loss: 0.1589, validation loss: 0.1541
2024-05-25 00:24:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch101_loss0.15409529581665993.pypots
2024-05-25 00:24:49 [INFO]: Epoch 102 - training loss: 0.1752, validation loss: 0.1344
2024-05-25 00:24:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch102_loss0.134393023326993.pypots
2024-05-25 00:24:52 [INFO]: Epoch 103 - training loss: 0.1493, validation loss: 0.1330
2024-05-25 00:24:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch103_loss0.1329784169793129.pypots
2024-05-25 00:24:54 [INFO]: Epoch 104 - training loss: 0.1326, validation loss: 0.1280
2024-05-25 00:24:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch104_loss0.12795239128172398.pypots
2024-05-25 00:24:56 [INFO]: Epoch 105 - training loss: 0.1644, validation loss: 0.1295
2024-05-25 00:24:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch105_loss0.12949148751795292.pypots
2024-05-25 00:24:58 [INFO]: Epoch 106 - training loss: 0.1707, validation loss: 0.1280
2024-05-25 00:24:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch106_loss0.12797649018466473.pypots
2024-05-25 00:25:00 [INFO]: Epoch 107 - training loss: 0.1915, validation loss: 0.1276
2024-05-25 00:25:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch107_loss0.12755392491817474.pypots
2024-05-25 00:25:02 [INFO]: Epoch 108 - training loss: 0.2340, validation loss: 0.1422
2024-05-25 00:25:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch108_loss0.14224205166101456.pypots
2024-05-25 00:25:04 [INFO]: Epoch 109 - training loss: 0.1965, validation loss: 0.1459
2024-05-25 00:25:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch109_loss0.14589109271764755.pypots
2024-05-25 00:25:06 [INFO]: Epoch 110 - training loss: 0.1607, validation loss: 0.1521
2024-05-25 00:25:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch110_loss0.15207234770059586.pypots
2024-05-25 00:25:08 [INFO]: Epoch 111 - training loss: 0.1859, validation loss: 0.1435
2024-05-25 00:25:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch111_loss0.1435447596013546.pypots
2024-05-25 00:25:10 [INFO]: Epoch 112 - training loss: 0.1603, validation loss: 0.1440
2024-05-25 00:25:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch112_loss0.14399651065468788.pypots
2024-05-25 00:25:12 [INFO]: Epoch 113 - training loss: 0.1304, validation loss: 0.1313
2024-05-25 00:25:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch113_loss0.1313057504594326.pypots
2024-05-25 00:25:14 [INFO]: Epoch 114 - training loss: 0.1588, validation loss: 0.1301
2024-05-25 00:25:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch114_loss0.1301395744085312.pypots
2024-05-25 00:25:16 [INFO]: Epoch 115 - training loss: 0.1837, validation loss: 0.1336
2024-05-25 00:25:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch115_loss0.1335611417889595.pypots
2024-05-25 00:25:19 [INFO]: Epoch 116 - training loss: 0.2056, validation loss: 0.1335
2024-05-25 00:25:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch116_loss0.13352425582706928.pypots
2024-05-25 00:25:21 [INFO]: Epoch 117 - training loss: 0.2028, validation loss: 0.1320
2024-05-25 00:25:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI_epoch117_loss0.131985392421484.pypots
2024-05-25 00:25:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:25:21 [INFO]: Finished training. The best model is from epoch#107.
2024-05-25 00:25:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_ettm1/20240525_T002118/CSDI.pypots
2024-05-25 00:25:36 [INFO]: CSDI on ETTm1: MAE=0.1429, MSE=0.0465
2024-05-25 00:25:36 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-25 00:25:36 [INFO]: Using the given device: cuda:0
2024-05-25 00:25:36 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240525_T002536
2024-05-25 00:25:36 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240525_T002536/tensorboard
2024-05-25 00:25:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 00:25:36 [INFO]: Epoch 001 - training loss: 24185.7908, validation loss: 0.9431
2024-05-25 00:25:37 [INFO]: Epoch 002 - training loss: 22236.0787, validation loss: 0.9440
2024-05-25 00:25:37 [INFO]: Epoch 003 - training loss: 20187.8812, validation loss: 0.9433
2024-05-25 00:25:37 [INFO]: Epoch 004 - training loss: 18452.8300, validation loss: 0.9301
2024-05-25 00:25:37 [INFO]: Epoch 005 - training loss: 16136.0926, validation loss: 0.9072
2024-05-25 00:25:37 [INFO]: Epoch 006 - training loss: 14592.1664, validation loss: 0.8482
2024-05-25 00:25:37 [INFO]: Epoch 007 - training loss: 13354.8670, validation loss: 0.7365
2024-05-25 00:25:37 [INFO]: Epoch 008 - training loss: 12268.8502, validation loss: 0.6072
2024-05-25 00:25:37 [INFO]: Epoch 009 - training loss: 11740.8184, validation loss: 0.5523
2024-05-25 00:25:38 [INFO]: Epoch 010 - training loss: 11140.8251, validation loss: 0.5339
2024-05-25 00:25:38 [INFO]: Epoch 011 - training loss: 10743.0538, validation loss: 0.5118
2024-05-25 00:25:38 [INFO]: Epoch 012 - training loss: 10542.2737, validation loss: 0.4993
2024-05-25 00:25:38 [INFO]: Epoch 013 - training loss: 10345.8770, validation loss: 0.4793
2024-05-25 00:25:38 [INFO]: Epoch 014 - training loss: 10136.1763, validation loss: 0.4677
2024-05-25 00:25:38 [INFO]: Epoch 015 - training loss: 10053.2372, validation loss: 0.4586
2024-05-25 00:25:38 [INFO]: Epoch 016 - training loss: 9920.9573, validation loss: 0.4413
2024-05-25 00:25:38 [INFO]: Epoch 017 - training loss: 9936.8226, validation loss: 0.4258
2024-05-25 00:25:39 [INFO]: Epoch 018 - training loss: 9799.4929, validation loss: 0.4128
2024-05-25 00:25:39 [INFO]: Epoch 019 - training loss: 9764.6974, validation loss: 0.3979
2024-05-25 00:25:39 [INFO]: Epoch 020 - training loss: 9678.5390, validation loss: 0.3796
2024-05-25 00:25:39 [INFO]: Epoch 021 - training loss: 9674.5483, validation loss: 0.3697
2024-05-25 00:25:39 [INFO]: Epoch 022 - training loss: 9611.0730, validation loss: 0.3601
2024-05-25 00:25:39 [INFO]: Epoch 023 - training loss: 9555.7672, validation loss: 0.3494
2024-05-25 00:25:39 [INFO]: Epoch 024 - training loss: 9535.4714, validation loss: 0.3460
2024-05-25 00:25:39 [INFO]: Epoch 025 - training loss: 9517.2693, validation loss: 0.3330
2024-05-25 00:25:40 [INFO]: Epoch 026 - training loss: 9484.6913, validation loss: 0.3227
2024-05-25 00:25:40 [INFO]: Epoch 027 - training loss: 9465.1074, validation loss: 0.3152
2024-05-25 00:25:40 [INFO]: Epoch 028 - training loss: 9457.4709, validation loss: 0.3063
2024-05-25 00:25:40 [INFO]: Epoch 029 - training loss: 9453.9692, validation loss: 0.2949
2024-05-25 00:25:40 [INFO]: Epoch 030 - training loss: 9430.0608, validation loss: 0.2866
2024-05-25 00:25:40 [INFO]: Epoch 031 - training loss: 9403.6549, validation loss: 0.2825
2024-05-25 00:25:40 [INFO]: Epoch 032 - training loss: 9393.8314, validation loss: 0.2702
2024-05-25 00:25:40 [INFO]: Epoch 033 - training loss: 9406.6833, validation loss: 0.2649
2024-05-25 00:25:41 [INFO]: Epoch 034 - training loss: 9377.0502, validation loss: 0.2559
2024-05-25 00:25:41 [INFO]: Epoch 035 - training loss: 9397.4089, validation loss: 0.2468
2024-05-25 00:25:41 [INFO]: Epoch 036 - training loss: 9359.0003, validation loss: 0.2408
2024-05-25 00:25:41 [INFO]: Epoch 037 - training loss: 9377.7842, validation loss: 0.2437
2024-05-25 00:25:41 [INFO]: Epoch 038 - training loss: 9350.1475, validation loss: 0.2255
2024-05-25 00:25:41 [INFO]: Epoch 039 - training loss: 9339.1920, validation loss: 0.2203
2024-05-25 00:25:41 [INFO]: Epoch 040 - training loss: 9339.7764, validation loss: 0.2118
2024-05-25 00:25:41 [INFO]: Epoch 041 - training loss: 9329.3230, validation loss: 0.2067
2024-05-25 00:25:42 [INFO]: Epoch 042 - training loss: 9336.9685, validation loss: 0.2001
2024-05-25 00:25:42 [INFO]: Epoch 043 - training loss: 9316.6484, validation loss: 0.1946
2024-05-25 00:25:42 [INFO]: Epoch 044 - training loss: 9310.9607, validation loss: 0.1895
2024-05-25 00:25:42 [INFO]: Epoch 045 - training loss: 9306.7482, validation loss: 0.1867
2024-05-25 00:25:42 [INFO]: Epoch 046 - training loss: 9311.9650, validation loss: 0.1813
2024-05-25 00:25:42 [INFO]: Epoch 047 - training loss: 9302.0495, validation loss: 0.1804
2024-05-25 00:25:42 [INFO]: Epoch 048 - training loss: 9306.4155, validation loss: 0.1791
2024-05-25 00:25:42 [INFO]: Epoch 049 - training loss: 9293.4763, validation loss: 0.1744
2024-05-25 00:25:43 [INFO]: Epoch 050 - training loss: 9292.4445, validation loss: 0.1743
2024-05-25 00:25:43 [INFO]: Epoch 051 - training loss: 9289.4421, validation loss: 0.1711
2024-05-25 00:25:43 [INFO]: Epoch 052 - training loss: 9286.1046, validation loss: 0.1696
2024-05-25 00:25:43 [INFO]: Epoch 053 - training loss: 9281.5128, validation loss: 0.1664
2024-05-25 00:25:43 [INFO]: Epoch 054 - training loss: 9280.2971, validation loss: 0.1645
2024-05-25 00:25:43 [INFO]: Epoch 055 - training loss: 9277.8862, validation loss: 0.1625
2024-05-25 00:25:43 [INFO]: Epoch 056 - training loss: 9279.3581, validation loss: 0.1587
2024-05-25 00:25:43 [INFO]: Epoch 057 - training loss: 9275.2557, validation loss: 0.1568
2024-05-25 00:25:44 [INFO]: Epoch 058 - training loss: 9275.7188, validation loss: 0.1563
2024-05-25 00:25:44 [INFO]: Epoch 059 - training loss: 9273.3887, validation loss: 0.1546
2024-05-25 00:25:44 [INFO]: Epoch 060 - training loss: 9266.3663, validation loss: 0.1514
2024-05-25 00:25:44 [INFO]: Epoch 061 - training loss: 9267.7322, validation loss: 0.1508
2024-05-25 00:25:44 [INFO]: Epoch 062 - training loss: 9265.3112, validation loss: 0.1498
2024-05-25 00:25:44 [INFO]: Epoch 063 - training loss: 9262.0891, validation loss: 0.1485
2024-05-25 00:25:44 [INFO]: Epoch 064 - training loss: 9260.5780, validation loss: 0.1470
2024-05-25 00:25:44 [INFO]: Epoch 065 - training loss: 9259.0649, validation loss: 0.1477
2024-05-25 00:25:45 [INFO]: Epoch 066 - training loss: 9255.3638, validation loss: 0.1452
2024-05-25 00:25:45 [INFO]: Epoch 067 - training loss: 9257.3727, validation loss: 0.1449
2024-05-25 00:25:45 [INFO]: Epoch 068 - training loss: 9256.5654, validation loss: 0.1456
2024-05-25 00:25:45 [INFO]: Epoch 069 - training loss: 9261.2745, validation loss: 0.1449
2024-05-25 00:25:45 [INFO]: Epoch 070 - training loss: 9273.1196, validation loss: 0.1427
2024-05-25 00:25:45 [INFO]: Epoch 071 - training loss: 9251.5358, validation loss: 0.1415
2024-05-25 00:25:45 [INFO]: Epoch 072 - training loss: 9256.6435, validation loss: 0.1421
2024-05-25 00:25:45 [INFO]: Epoch 073 - training loss: 9250.4418, validation loss: 0.1389
2024-05-25 00:25:46 [INFO]: Epoch 074 - training loss: 9247.4515, validation loss: 0.1389
2024-05-25 00:25:46 [INFO]: Epoch 075 - training loss: 9244.9134, validation loss: 0.1368
2024-05-25 00:25:46 [INFO]: Epoch 076 - training loss: 9249.1879, validation loss: 0.1355
2024-05-25 00:25:46 [INFO]: Epoch 077 - training loss: 9244.7393, validation loss: 0.1420
2024-05-25 00:25:46 [INFO]: Epoch 078 - training loss: 9245.9888, validation loss: 0.1361
2024-05-25 00:25:46 [INFO]: Epoch 079 - training loss: 9244.0150, validation loss: 0.1339
2024-05-25 00:25:46 [INFO]: Epoch 080 - training loss: 9243.5206, validation loss: 0.1327
2024-05-25 00:25:46 [INFO]: Epoch 081 - training loss: 9243.1146, validation loss: 0.1323
2024-05-25 00:25:47 [INFO]: Epoch 082 - training loss: 9242.4041, validation loss: 0.1314
2024-05-25 00:25:47 [INFO]: Epoch 083 - training loss: 9241.8297, validation loss: 0.1300
2024-05-25 00:25:47 [INFO]: Epoch 084 - training loss: 9241.1112, validation loss: 0.1306
2024-05-25 00:25:47 [INFO]: Epoch 085 - training loss: 9239.3162, validation loss: 0.1277
2024-05-25 00:25:47 [INFO]: Epoch 086 - training loss: 9238.5112, validation loss: 0.1278
2024-05-25 00:25:47 [INFO]: Epoch 087 - training loss: 9238.2743, validation loss: 0.1279
2024-05-25 00:25:47 [INFO]: Epoch 088 - training loss: 9238.2240, validation loss: 0.1276
2024-05-25 00:25:47 [INFO]: Epoch 089 - training loss: 9264.8004, validation loss: 0.1257
2024-05-25 00:25:48 [INFO]: Epoch 090 - training loss: 9238.7748, validation loss: 0.1272
2024-05-25 00:25:48 [INFO]: Epoch 091 - training loss: 9234.1750, validation loss: 0.1263
2024-05-25 00:25:48 [INFO]: Epoch 092 - training loss: 9236.9882, validation loss: 0.1246
2024-05-25 00:25:48 [INFO]: Epoch 093 - training loss: 9233.5383, validation loss: 0.1249
2024-05-25 00:25:48 [INFO]: Epoch 094 - training loss: 9233.5452, validation loss: 0.1243
2024-05-25 00:25:48 [INFO]: Epoch 095 - training loss: 9232.3137, validation loss: 0.1217
2024-05-25 00:25:48 [INFO]: Epoch 096 - training loss: 9231.8637, validation loss: 0.1225
2024-05-25 00:25:48 [INFO]: Epoch 097 - training loss: 9231.9158, validation loss: 0.1228
2024-05-25 00:25:49 [INFO]: Epoch 098 - training loss: 9231.9343, validation loss: 0.1206
2024-05-25 00:25:49 [INFO]: Epoch 099 - training loss: 9229.5334, validation loss: 0.1189
2024-05-25 00:25:49 [INFO]: Epoch 100 - training loss: 9229.7038, validation loss: 0.1201
2024-05-25 00:25:49 [INFO]: Epoch 101 - training loss: 9230.2298, validation loss: 0.1203
2024-05-25 00:25:49 [INFO]: Epoch 102 - training loss: 9231.1789, validation loss: 0.1213
2024-05-25 00:25:49 [INFO]: Epoch 103 - training loss: 9228.6581, validation loss: 0.1170
2024-05-25 00:25:49 [INFO]: Epoch 104 - training loss: 9231.0528, validation loss: 0.1190
2024-05-25 00:25:49 [INFO]: Epoch 105 - training loss: 9230.9863, validation loss: 0.1185
2024-05-25 00:25:50 [INFO]: Epoch 106 - training loss: 9228.3751, validation loss: 0.1168
2024-05-25 00:25:50 [INFO]: Epoch 107 - training loss: 9229.4888, validation loss: 0.1169
2024-05-25 00:25:50 [INFO]: Epoch 108 - training loss: 9227.3648, validation loss: 0.1177
2024-05-25 00:25:50 [INFO]: Epoch 109 - training loss: 9227.0200, validation loss: 0.1157
2024-05-25 00:25:50 [INFO]: Epoch 110 - training loss: 9228.6182, validation loss: 0.1174
2024-05-25 00:25:50 [INFO]: Epoch 111 - training loss: 9225.7673, validation loss: 0.1152
2024-05-25 00:25:50 [INFO]: Epoch 112 - training loss: 9230.5139, validation loss: 0.1167
2024-05-25 00:25:50 [INFO]: Epoch 113 - training loss: 9227.7596, validation loss: 0.1132
2024-05-25 00:25:51 [INFO]: Epoch 114 - training loss: 9225.6376, validation loss: 0.1134
2024-05-25 00:25:51 [INFO]: Epoch 115 - training loss: 9223.6831, validation loss: 0.1126
2024-05-25 00:25:51 [INFO]: Epoch 116 - training loss: 9225.1102, validation loss: 0.1137
2024-05-25 00:25:51 [INFO]: Epoch 117 - training loss: 9223.2167, validation loss: 0.1117
2024-05-25 00:25:51 [INFO]: Epoch 118 - training loss: 9223.3464, validation loss: 0.1119
2024-05-25 00:25:51 [INFO]: Epoch 119 - training loss: 9226.0560, validation loss: 0.1092
2024-05-25 00:25:51 [INFO]: Epoch 120 - training loss: 9223.1381, validation loss: 0.1111
2024-05-25 00:25:51 [INFO]: Epoch 121 - training loss: 9225.7502, validation loss: 0.1106
2024-05-25 00:25:52 [INFO]: Epoch 122 - training loss: 9221.8150, validation loss: 0.1099
2024-05-25 00:25:52 [INFO]: Epoch 123 - training loss: 9221.2079, validation loss: 0.1071
2024-05-25 00:25:52 [INFO]: Epoch 124 - training loss: 9221.8191, validation loss: 0.1109
2024-05-25 00:25:52 [INFO]: Epoch 125 - training loss: 9221.8102, validation loss: 0.1105
2024-05-25 00:25:52 [INFO]: Epoch 126 - training loss: 9223.1561, validation loss: 0.1057
2024-05-25 00:25:52 [INFO]: Epoch 127 - training loss: 9222.1041, validation loss: 0.1105
2024-05-25 00:25:52 [INFO]: Epoch 128 - training loss: 9223.0588, validation loss: 0.1072
2024-05-25 00:25:52 [INFO]: Epoch 129 - training loss: 9220.4900, validation loss: 0.1059
2024-05-25 00:25:53 [INFO]: Epoch 130 - training loss: 9221.5576, validation loss: 0.1069
2024-05-25 00:25:53 [INFO]: Epoch 131 - training loss: 9221.4805, validation loss: 0.1058
2024-05-25 00:25:53 [INFO]: Epoch 132 - training loss: 9220.8179, validation loss: 0.1062
2024-05-25 00:25:53 [INFO]: Epoch 133 - training loss: 9221.7351, validation loss: 0.1042
2024-05-25 00:25:53 [INFO]: Epoch 134 - training loss: 9219.0751, validation loss: 0.1042
2024-05-25 00:25:53 [INFO]: Epoch 135 - training loss: 9217.6727, validation loss: 0.1056
2024-05-25 00:25:53 [INFO]: Epoch 136 - training loss: 9218.5275, validation loss: 0.1038
2024-05-25 00:25:53 [INFO]: Epoch 137 - training loss: 9219.5006, validation loss: 0.1038
2024-05-25 00:25:54 [INFO]: Epoch 138 - training loss: 9218.2919, validation loss: 0.1040
2024-05-25 00:25:54 [INFO]: Epoch 139 - training loss: 9218.7698, validation loss: 0.1023
2024-05-25 00:25:54 [INFO]: Epoch 140 - training loss: 9219.8152, validation loss: 0.1018
2024-05-25 00:25:54 [INFO]: Epoch 141 - training loss: 9217.6594, validation loss: 0.1025
2024-05-25 00:25:54 [INFO]: Epoch 142 - training loss: 9216.8291, validation loss: 0.1000
2024-05-25 00:25:54 [INFO]: Epoch 143 - training loss: 9218.6588, validation loss: 0.1030
2024-05-25 00:25:54 [INFO]: Epoch 144 - training loss: 9217.8739, validation loss: 0.1008
2024-05-25 00:25:54 [INFO]: Epoch 145 - training loss: 9217.2960, validation loss: 0.0999
2024-05-25 00:25:55 [INFO]: Epoch 146 - training loss: 9217.0515, validation loss: 0.1014
2024-05-25 00:25:55 [INFO]: Epoch 147 - training loss: 9218.1744, validation loss: 0.1006
2024-05-25 00:25:55 [INFO]: Epoch 148 - training loss: 9216.3115, validation loss: 0.1015
2024-05-25 00:25:55 [INFO]: Epoch 149 - training loss: 9215.9998, validation loss: 0.0985
2024-05-25 00:25:55 [INFO]: Epoch 150 - training loss: 9216.0815, validation loss: 0.1007
2024-05-25 00:25:55 [INFO]: Epoch 151 - training loss: 9215.9825, validation loss: 0.0984
2024-05-25 00:25:55 [INFO]: Epoch 152 - training loss: 9216.2994, validation loss: 0.0995
2024-05-25 00:25:55 [INFO]: Epoch 153 - training loss: 9217.4403, validation loss: 0.0969
2024-05-25 00:25:56 [INFO]: Epoch 154 - training loss: 9216.5780, validation loss: 0.0998
2024-05-25 00:25:56 [INFO]: Epoch 155 - training loss: 9216.9044, validation loss: 0.0986
2024-05-25 00:25:56 [INFO]: Epoch 156 - training loss: 9215.0287, validation loss: 0.0964
2024-05-25 00:25:56 [INFO]: Epoch 157 - training loss: 9214.3022, validation loss: 0.0982
2024-05-25 00:25:56 [INFO]: Epoch 158 - training loss: 9215.0782, validation loss: 0.0970
2024-05-25 00:25:56 [INFO]: Epoch 159 - training loss: 9215.0089, validation loss: 0.0983
2024-05-25 00:25:56 [INFO]: Epoch 160 - training loss: 9215.6749, validation loss: 0.0953
2024-05-25 00:25:56 [INFO]: Epoch 161 - training loss: 9218.6080, validation loss: 0.0966
2024-05-25 00:25:57 [INFO]: Epoch 162 - training loss: 9216.8407, validation loss: 0.0938
2024-05-25 00:25:57 [INFO]: Epoch 163 - training loss: 9214.0844, validation loss: 0.0969
2024-05-25 00:25:57 [INFO]: Epoch 164 - training loss: 9213.9850, validation loss: 0.0955
2024-05-25 00:25:57 [INFO]: Epoch 165 - training loss: 9214.8798, validation loss: 0.0926
2024-05-25 00:25:57 [INFO]: Epoch 166 - training loss: 9215.4620, validation loss: 0.0974
2024-05-25 00:25:57 [INFO]: Epoch 167 - training loss: 9213.7036, validation loss: 0.0945
2024-05-25 00:25:57 [INFO]: Epoch 168 - training loss: 9213.2225, validation loss: 0.0948
2024-05-25 00:25:57 [INFO]: Epoch 169 - training loss: 9214.3231, validation loss: 0.0946
2024-05-25 00:25:58 [INFO]: Epoch 170 - training loss: 9214.1839, validation loss: 0.0940
2024-05-25 00:25:58 [INFO]: Epoch 171 - training loss: 9214.2659, validation loss: 0.0925
2024-05-25 00:25:58 [INFO]: Epoch 172 - training loss: 9213.1107, validation loss: 0.0941
2024-05-25 00:25:58 [INFO]: Epoch 173 - training loss: 9213.1895, validation loss: 0.0929
2024-05-25 00:25:58 [INFO]: Epoch 174 - training loss: 9213.9322, validation loss: 0.0941
2024-05-25 00:25:58 [INFO]: Epoch 175 - training loss: 9212.0815, validation loss: 0.0939
2024-05-25 00:25:58 [INFO]: Epoch 176 - training loss: 9213.0029, validation loss: 0.0927
2024-05-25 00:25:58 [INFO]: Epoch 177 - training loss: 9212.2714, validation loss: 0.0932
2024-05-25 00:25:59 [INFO]: Epoch 178 - training loss: 9215.3154, validation loss: 0.0924
2024-05-25 00:25:59 [INFO]: Epoch 179 - training loss: 9214.2947, validation loss: 0.0923
2024-05-25 00:25:59 [INFO]: Epoch 180 - training loss: 9211.5698, validation loss: 0.0930
2024-05-25 00:25:59 [INFO]: Epoch 181 - training loss: 9212.3636, validation loss: 0.0901
2024-05-25 00:25:59 [INFO]: Epoch 182 - training loss: 9211.3539, validation loss: 0.0927
2024-05-25 00:25:59 [INFO]: Epoch 183 - training loss: 9211.7146, validation loss: 0.0919
2024-05-25 00:25:59 [INFO]: Epoch 184 - training loss: 9211.7440, validation loss: 0.0908
2024-05-25 00:25:59 [INFO]: Epoch 185 - training loss: 9211.7525, validation loss: 0.0892
2024-05-25 00:26:00 [INFO]: Epoch 186 - training loss: 9211.8409, validation loss: 0.0916
2024-05-25 00:26:00 [INFO]: Epoch 187 - training loss: 9212.2338, validation loss: 0.0890
2024-05-25 00:26:00 [INFO]: Epoch 188 - training loss: 9213.8457, validation loss: 0.0894
2024-05-25 00:26:00 [INFO]: Epoch 189 - training loss: 9211.1329, validation loss: 0.0899
2024-05-25 00:26:00 [INFO]: Epoch 190 - training loss: 9212.1425, validation loss: 0.0915
2024-05-25 00:26:00 [INFO]: Epoch 191 - training loss: 9210.3533, validation loss: 0.0893
2024-05-25 00:26:00 [INFO]: Epoch 192 - training loss: 9212.3206, validation loss: 0.0890
2024-05-25 00:26:00 [INFO]: Epoch 193 - training loss: 9212.3825, validation loss: 0.0898
2024-05-25 00:26:01 [INFO]: Epoch 194 - training loss: 9211.9890, validation loss: 0.0907
2024-05-25 00:26:01 [INFO]: Epoch 195 - training loss: 9210.7081, validation loss: 0.0913
2024-05-25 00:26:01 [INFO]: Epoch 196 - training loss: 9212.2203, validation loss: 0.0879
2024-05-25 00:26:01 [INFO]: Epoch 197 - training loss: 9214.3068, validation loss: 0.0912
2024-05-25 00:26:01 [INFO]: Epoch 198 - training loss: 9212.9350, validation loss: 0.0892
2024-05-25 00:26:01 [INFO]: Epoch 199 - training loss: 9211.0694, validation loss: 0.0900
2024-05-25 00:26:01 [INFO]: Epoch 200 - training loss: 9208.7206, validation loss: 0.0883
2024-05-25 00:26:01 [INFO]: Epoch 201 - training loss: 9213.0093, validation loss: 0.0926
2024-05-25 00:26:02 [INFO]: Epoch 202 - training loss: 9213.4365, validation loss: 0.0881
2024-05-25 00:26:02 [INFO]: Epoch 203 - training loss: 9210.0613, validation loss: 0.0893
2024-05-25 00:26:02 [INFO]: Epoch 204 - training loss: 9209.8705, validation loss: 0.0875
2024-05-25 00:26:02 [INFO]: Epoch 205 - training loss: 9209.8558, validation loss: 0.0885
2024-05-25 00:26:02 [INFO]: Epoch 206 - training loss: 9209.9138, validation loss: 0.0873
2024-05-25 00:26:02 [INFO]: Epoch 207 - training loss: 9209.8821, validation loss: 0.0877
2024-05-25 00:26:02 [INFO]: Epoch 208 - training loss: 9210.0356, validation loss: 0.0864
2024-05-25 00:26:02 [INFO]: Epoch 209 - training loss: 9208.7674, validation loss: 0.0856
2024-05-25 00:26:03 [INFO]: Epoch 210 - training loss: 9210.3616, validation loss: 0.0881
2024-05-25 00:26:03 [INFO]: Epoch 211 - training loss: 9208.4888, validation loss: 0.0881
2024-05-25 00:26:03 [INFO]: Epoch 212 - training loss: 9210.7296, validation loss: 0.0858
2024-05-25 00:26:03 [INFO]: Epoch 213 - training loss: 9210.2120, validation loss: 0.0880
2024-05-25 00:26:03 [INFO]: Epoch 214 - training loss: 9209.0082, validation loss: 0.0880
2024-05-25 00:26:03 [INFO]: Epoch 215 - training loss: 9207.9698, validation loss: 0.0872
2024-05-25 00:26:03 [INFO]: Epoch 216 - training loss: 9211.5900, validation loss: 0.0897
2024-05-25 00:26:03 [INFO]: Epoch 217 - training loss: 9211.2472, validation loss: 0.0863
2024-05-25 00:26:04 [INFO]: Epoch 218 - training loss: 9209.2405, validation loss: 0.0878
2024-05-25 00:26:04 [INFO]: Epoch 219 - training loss: 9208.2563, validation loss: 0.0889
2024-05-25 00:26:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:26:04 [INFO]: Finished training. The best model is from epoch#209.
2024-05-25 00:26:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/GPVAE_ettm1/20240525_T002536/GPVAE.pypots
2024-05-25 00:26:04 [INFO]: GP-VAE on ETTm1: MAE=0.2922, MSE=0.1824
2024-05-25 00:26:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-25 00:26:04 [INFO]: Using the given device: cuda:0
2024-05-25 00:26:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240525_T002604
2024-05-25 00:26:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240525_T002604/tensorboard
2024-05-25 00:26:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 00:26:14 [INFO]: Epoch 001 - generator training loss: 0.4360, discriminator training loss: 0.5409, validation loss: 0.3634
2024-05-25 00:26:23 [INFO]: Epoch 002 - generator training loss: -0.0519, discriminator training loss: 0.4775, validation loss: 0.1233
2024-05-25 00:26:32 [INFO]: Epoch 003 - generator training loss: -0.1655, discriminator training loss: 0.4409, validation loss: 0.0705
2024-05-25 00:26:40 [INFO]: Epoch 004 - generator training loss: -0.1611, discriminator training loss: 0.3854, validation loss: 0.0592
2024-05-25 00:26:49 [INFO]: Epoch 005 - generator training loss: -0.1223, discriminator training loss: 0.3132, validation loss: 0.0480
2024-05-25 00:26:58 [INFO]: Epoch 006 - generator training loss: -0.0860, discriminator training loss: 0.2492, validation loss: 0.0438
2024-05-25 00:27:07 [INFO]: Epoch 007 - generator training loss: -0.0622, discriminator training loss: 0.2091, validation loss: 0.0418
2024-05-25 00:27:15 [INFO]: Epoch 008 - generator training loss: -0.0573, discriminator training loss: 0.1913, validation loss: 0.0392
2024-05-25 00:27:24 [INFO]: Epoch 009 - generator training loss: -0.0606, discriminator training loss: 0.1830, validation loss: 0.0384
2024-05-25 00:27:33 [INFO]: Epoch 010 - generator training loss: -0.0542, discriminator training loss: 0.1770, validation loss: 0.0378
2024-05-25 00:27:42 [INFO]: Epoch 011 - generator training loss: -0.0588, discriminator training loss: 0.1739, validation loss: 0.0369
2024-05-25 00:27:50 [INFO]: Epoch 012 - generator training loss: -0.0589, discriminator training loss: 0.1758, validation loss: 0.0358
2024-05-25 00:27:59 [INFO]: Epoch 013 - generator training loss: -0.0570, discriminator training loss: 0.1715, validation loss: 0.0353
2024-05-25 00:28:08 [INFO]: Epoch 014 - generator training loss: -0.0567, discriminator training loss: 0.1727, validation loss: 0.0363
2024-05-25 00:28:17 [INFO]: Epoch 015 - generator training loss: -0.0605, discriminator training loss: 0.1727, validation loss: 0.0352
2024-05-25 00:28:25 [INFO]: Epoch 016 - generator training loss: -0.0572, discriminator training loss: 0.1725, validation loss: 0.0342
2024-05-25 00:28:34 [INFO]: Epoch 017 - generator training loss: -0.0587, discriminator training loss: 0.1714, validation loss: 0.0343
2024-05-25 00:28:43 [INFO]: Epoch 018 - generator training loss: -0.0629, discriminator training loss: 0.1706, validation loss: 0.0335
2024-05-25 00:28:52 [INFO]: Epoch 019 - generator training loss: -0.0624, discriminator training loss: 0.1693, validation loss: 0.0338
2024-05-25 00:29:01 [INFO]: Epoch 020 - generator training loss: -0.0580, discriminator training loss: 0.1690, validation loss: 0.0333
2024-05-25 00:29:10 [INFO]: Epoch 021 - generator training loss: -0.0584, discriminator training loss: 0.1694, validation loss: 0.0323
2024-05-25 00:29:18 [INFO]: Epoch 022 - generator training loss: -0.0622, discriminator training loss: 0.1700, validation loss: 0.0340
2024-05-25 00:29:27 [INFO]: Epoch 023 - generator training loss: -0.0631, discriminator training loss: 0.1694, validation loss: 0.0325
2024-05-25 00:29:36 [INFO]: Epoch 024 - generator training loss: -0.0595, discriminator training loss: 0.1680, validation loss: 0.0324
2024-05-25 00:29:44 [INFO]: Epoch 025 - generator training loss: -0.0631, discriminator training loss: 0.1704, validation loss: 0.0313
2024-05-25 00:29:53 [INFO]: Epoch 026 - generator training loss: -0.0625, discriminator training loss: 0.1671, validation loss: 0.0311
2024-05-25 00:30:02 [INFO]: Epoch 027 - generator training loss: -0.0643, discriminator training loss: 0.1697, validation loss: 0.0305
2024-05-25 00:30:11 [INFO]: Epoch 028 - generator training loss: -0.0642, discriminator training loss: 0.1685, validation loss: 0.0308
2024-05-25 00:30:19 [INFO]: Epoch 029 - generator training loss: -0.0641, discriminator training loss: 0.1664, validation loss: 0.0303
2024-05-25 00:30:28 [INFO]: Epoch 030 - generator training loss: -0.0664, discriminator training loss: 0.1681, validation loss: 0.0299
2024-05-25 00:30:37 [INFO]: Epoch 031 - generator training loss: -0.0644, discriminator training loss: 0.1686, validation loss: 0.0298
2024-05-25 00:30:46 [INFO]: Epoch 032 - generator training loss: -0.0663, discriminator training loss: 0.1675, validation loss: 0.0299
2024-05-25 00:30:54 [INFO]: Epoch 033 - generator training loss: -0.0685, discriminator training loss: 0.1683, validation loss: 0.0306
2024-05-25 00:31:03 [INFO]: Epoch 034 - generator training loss: -0.0649, discriminator training loss: 0.1686, validation loss: 0.0298
2024-05-25 00:31:12 [INFO]: Epoch 035 - generator training loss: -0.0675, discriminator training loss: 0.1687, validation loss: 0.0302
2024-05-25 00:31:21 [INFO]: Epoch 036 - generator training loss: -0.0637, discriminator training loss: 0.1705, validation loss: 0.0301
2024-05-25 00:31:30 [INFO]: Epoch 037 - generator training loss: -0.0637, discriminator training loss: 0.1669, validation loss: 0.0308
2024-05-25 00:31:38 [INFO]: Epoch 038 - generator training loss: -0.0631, discriminator training loss: 0.1651, validation loss: 0.0293
2024-05-25 00:31:47 [INFO]: Epoch 039 - generator training loss: -0.0685, discriminator training loss: 0.1673, validation loss: 0.0288
2024-05-25 00:31:56 [INFO]: Epoch 040 - generator training loss: -0.0639, discriminator training loss: 0.1668, validation loss: 0.0289
2024-05-25 00:32:05 [INFO]: Epoch 041 - generator training loss: -0.0675, discriminator training loss: 0.1685, validation loss: 0.0285
2024-05-25 00:32:14 [INFO]: Epoch 042 - generator training loss: -0.0656, discriminator training loss: 0.1661, validation loss: 0.0295
2024-05-25 00:32:22 [INFO]: Epoch 043 - generator training loss: -0.0699, discriminator training loss: 0.1644, validation loss: 0.0283
2024-05-25 00:32:31 [INFO]: Epoch 044 - generator training loss: -0.0684, discriminator training loss: 0.1658, validation loss: 0.0278
2024-05-25 00:32:40 [INFO]: Epoch 045 - generator training loss: -0.0710, discriminator training loss: 0.1646, validation loss: 0.0278
2024-05-25 00:32:49 [INFO]: Epoch 046 - generator training loss: -0.0703, discriminator training loss: 0.1676, validation loss: 0.0283
2024-05-25 00:32:57 [INFO]: Epoch 047 - generator training loss: -0.0676, discriminator training loss: 0.1671, validation loss: 0.0275
2024-05-25 00:33:06 [INFO]: Epoch 048 - generator training loss: -0.0711, discriminator training loss: 0.1658, validation loss: 0.0277
2024-05-25 00:33:15 [INFO]: Epoch 049 - generator training loss: -0.0688, discriminator training loss: 0.1649, validation loss: 0.0280
2024-05-25 00:33:24 [INFO]: Epoch 050 - generator training loss: -0.0692, discriminator training loss: 0.1662, validation loss: 0.0277
2024-05-25 00:33:32 [INFO]: Epoch 051 - generator training loss: -0.0713, discriminator training loss: 0.1659, validation loss: 0.0274
2024-05-25 00:33:41 [INFO]: Epoch 052 - generator training loss: -0.0682, discriminator training loss: 0.1656, validation loss: 0.0270
2024-05-25 00:33:50 [INFO]: Epoch 053 - generator training loss: -0.0747, discriminator training loss: 0.1649, validation loss: 0.0264
2024-05-25 00:33:58 [INFO]: Epoch 054 - generator training loss: -0.0687, discriminator training loss: 0.1675, validation loss: 0.0262
2024-05-25 00:34:07 [INFO]: Epoch 055 - generator training loss: -0.0679, discriminator training loss: 0.1677, validation loss: 0.0266
2024-05-25 00:34:16 [INFO]: Epoch 056 - generator training loss: -0.0705, discriminator training loss: 0.1639, validation loss: 0.0260
2024-05-25 00:34:25 [INFO]: Epoch 057 - generator training loss: -0.0679, discriminator training loss: 0.1647, validation loss: 0.0265
2024-05-25 00:34:34 [INFO]: Epoch 058 - generator training loss: -0.0696, discriminator training loss: 0.1650, validation loss: 0.0259
2024-05-25 00:34:42 [INFO]: Epoch 059 - generator training loss: -0.0726, discriminator training loss: 0.1642, validation loss: 0.0261
2024-05-25 00:34:51 [INFO]: Epoch 060 - generator training loss: -0.0690, discriminator training loss: 0.1651, validation loss: 0.0268
2024-05-25 00:35:00 [INFO]: Epoch 061 - generator training loss: -0.0680, discriminator training loss: 0.1635, validation loss: 0.0262
2024-05-25 00:35:09 [INFO]: Epoch 062 - generator training loss: -0.0683, discriminator training loss: 0.1643, validation loss: 0.0257
2024-05-25 00:35:18 [INFO]: Epoch 063 - generator training loss: -0.0696, discriminator training loss: 0.1639, validation loss: 0.0258
2024-05-25 00:35:26 [INFO]: Epoch 064 - generator training loss: -0.0713, discriminator training loss: 0.1640, validation loss: 0.0255
2024-05-25 00:35:35 [INFO]: Epoch 065 - generator training loss: -0.0720, discriminator training loss: 0.1633, validation loss: 0.0252
2024-05-25 00:35:44 [INFO]: Epoch 066 - generator training loss: -0.0649, discriminator training loss: 0.1629, validation loss: 0.0259
2024-05-25 00:35:53 [INFO]: Epoch 067 - generator training loss: -0.0670, discriminator training loss: 0.1656, validation loss: 0.0258
2024-05-25 00:36:01 [INFO]: Epoch 068 - generator training loss: -0.0702, discriminator training loss: 0.1624, validation loss: 0.0250
2024-05-25 00:36:10 [INFO]: Epoch 069 - generator training loss: -0.0721, discriminator training loss: 0.1635, validation loss: 0.0255
2024-05-25 00:36:19 [INFO]: Epoch 070 - generator training loss: -0.0712, discriminator training loss: 0.1651, validation loss: 0.0249
2024-05-25 00:36:28 [INFO]: Epoch 071 - generator training loss: -0.0674, discriminator training loss: 0.1637, validation loss: 0.0245
2024-05-25 00:36:36 [INFO]: Epoch 072 - generator training loss: -0.0728, discriminator training loss: 0.1640, validation loss: 0.0246
2024-05-25 00:36:45 [INFO]: Epoch 073 - generator training loss: -0.0719, discriminator training loss: 0.1629, validation loss: 0.0249
2024-05-25 00:36:54 [INFO]: Epoch 074 - generator training loss: -0.0715, discriminator training loss: 0.1644, validation loss: 0.0247
2024-05-25 00:37:03 [INFO]: Epoch 075 - generator training loss: -0.0692, discriminator training loss: 0.1617, validation loss: 0.0246
2024-05-25 00:37:11 [INFO]: Epoch 076 - generator training loss: -0.0737, discriminator training loss: 0.1621, validation loss: 0.0246
2024-05-25 00:37:20 [INFO]: Epoch 077 - generator training loss: -0.0697, discriminator training loss: 0.1613, validation loss: 0.0247
2024-05-25 00:37:29 [INFO]: Epoch 078 - generator training loss: -0.0709, discriminator training loss: 0.1638, validation loss: 0.0306
2024-05-25 00:37:38 [INFO]: Epoch 079 - generator training loss: -0.0703, discriminator training loss: 0.1630, validation loss: 0.0257
2024-05-25 00:37:46 [INFO]: Epoch 080 - generator training loss: -0.0734, discriminator training loss: 0.1631, validation loss: 0.0263
2024-05-25 00:37:55 [INFO]: Epoch 081 - generator training loss: -0.0707, discriminator training loss: 0.1624, validation loss: 0.0242
2024-05-25 00:38:04 [INFO]: Epoch 082 - generator training loss: -0.0716, discriminator training loss: 0.1623, validation loss: 0.0248
2024-05-25 00:38:13 [INFO]: Epoch 083 - generator training loss: -0.0719, discriminator training loss: 0.1599, validation loss: 0.0242
2024-05-25 00:38:21 [INFO]: Epoch 084 - generator training loss: -0.0721, discriminator training loss: 0.1615, validation loss: 0.0250
2024-05-25 00:38:30 [INFO]: Epoch 085 - generator training loss: -0.0717, discriminator training loss: 0.1605, validation loss: 0.0243
2024-05-25 00:38:39 [INFO]: Epoch 086 - generator training loss: -0.0740, discriminator training loss: 0.1629, validation loss: 0.0241
2024-05-25 00:38:48 [INFO]: Epoch 087 - generator training loss: -0.0710, discriminator training loss: 0.1606, validation loss: 0.0243
2024-05-25 00:38:56 [INFO]: Epoch 088 - generator training loss: -0.0728, discriminator training loss: 0.1605, validation loss: 0.0243
2024-05-25 00:39:05 [INFO]: Epoch 089 - generator training loss: -0.0720, discriminator training loss: 0.1599, validation loss: 0.0250
2024-05-25 00:39:14 [INFO]: Epoch 090 - generator training loss: -0.0703, discriminator training loss: 0.1629, validation loss: 0.0242
2024-05-25 00:39:23 [INFO]: Epoch 091 - generator training loss: -0.0715, discriminator training loss: 0.1623, validation loss: 0.0254
2024-05-25 00:39:31 [INFO]: Epoch 092 - generator training loss: -0.0684, discriminator training loss: 0.1624, validation loss: 0.0243
2024-05-25 00:39:40 [INFO]: Epoch 093 - generator training loss: -0.0707, discriminator training loss: 0.1591, validation loss: 0.0248
2024-05-25 00:39:49 [INFO]: Epoch 094 - generator training loss: -0.0689, discriminator training loss: 0.1608, validation loss: 0.0235
2024-05-25 00:39:57 [INFO]: Epoch 095 - generator training loss: -0.0711, discriminator training loss: 0.1612, validation loss: 0.0242
2024-05-25 00:40:06 [INFO]: Epoch 096 - generator training loss: -0.0724, discriminator training loss: 0.1599, validation loss: 0.0240
2024-05-25 00:40:15 [INFO]: Epoch 097 - generator training loss: -0.0723, discriminator training loss: 0.1590, validation loss: 0.0242
2024-05-25 00:40:24 [INFO]: Epoch 098 - generator training loss: -0.0725, discriminator training loss: 0.1597, validation loss: 0.0234
2024-05-25 00:40:32 [INFO]: Epoch 099 - generator training loss: -0.0727, discriminator training loss: 0.1589, validation loss: 0.0234
2024-05-25 00:40:41 [INFO]: Epoch 100 - generator training loss: -0.0690, discriminator training loss: 0.1592, validation loss: 0.0247
2024-05-25 00:40:50 [INFO]: Epoch 101 - generator training loss: -0.0725, discriminator training loss: 0.1587, validation loss: 0.0239
2024-05-25 00:40:59 [INFO]: Epoch 102 - generator training loss: -0.0702, discriminator training loss: 0.1612, validation loss: 0.0235
2024-05-25 00:41:07 [INFO]: Epoch 103 - generator training loss: -0.0691, discriminator training loss: 0.1609, validation loss: 0.0252
2024-05-25 00:41:16 [INFO]: Epoch 104 - generator training loss: -0.0668, discriminator training loss: 0.1607, validation loss: 0.0282
2024-05-25 00:41:25 [INFO]: Epoch 105 - generator training loss: -0.0666, discriminator training loss: 0.1614, validation loss: 0.0268
2024-05-25 00:41:33 [INFO]: Epoch 106 - generator training loss: -0.0690, discriminator training loss: 0.1602, validation loss: 0.0253
2024-05-25 00:41:42 [INFO]: Epoch 107 - generator training loss: -0.0708, discriminator training loss: 0.1585, validation loss: 0.0242
2024-05-25 00:41:51 [INFO]: Epoch 108 - generator training loss: -0.0717, discriminator training loss: 0.1592, validation loss: 0.0235
2024-05-25 00:41:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:41:51 [INFO]: Finished training. The best model is from epoch#98.
2024-05-25 00:41:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/USGAN_ettm1/20240525_T002604/USGAN.pypots
2024-05-25 00:41:52 [INFO]: US-GAN on ETTm1: MAE=0.1677, MSE=0.0700
2024-05-25 00:41:52 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 00:41:52 [INFO]: Using the given device: cuda:0
2024-05-25 00:41:52 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T004152
2024-05-25 00:41:52 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T004152/tensorboard
2024-05-25 00:41:52 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 00:41:59 [INFO]: Epoch 001 - training loss: 1.3110, validation loss: 0.3145
2024-05-25 00:42:05 [INFO]: Epoch 002 - training loss: 0.9160, validation loss: 0.1105
2024-05-25 00:42:11 [INFO]: Epoch 003 - training loss: 0.7399, validation loss: 0.0645
2024-05-25 00:42:17 [INFO]: Epoch 004 - training loss: 0.7363, validation loss: 0.0564
2024-05-25 00:42:22 [INFO]: Epoch 005 - training loss: 0.6264, validation loss: 0.0514
2024-05-25 00:42:28 [INFO]: Epoch 006 - training loss: 0.5835, validation loss: 0.0443
2024-05-25 00:42:34 [INFO]: Epoch 007 - training loss: 0.5577, validation loss: 0.0395
2024-05-25 00:42:40 [INFO]: Epoch 008 - training loss: 0.5325, validation loss: 0.0371
2024-05-25 00:42:46 [INFO]: Epoch 009 - training loss: 0.5061, validation loss: 0.0338
2024-05-25 00:42:51 [INFO]: Epoch 010 - training loss: 0.4797, validation loss: 0.0323
2024-05-25 00:42:57 [INFO]: Epoch 011 - training loss: 0.4843, validation loss: 0.0318
2024-05-25 00:43:03 [INFO]: Epoch 012 - training loss: 0.4742, validation loss: 0.0316
2024-05-25 00:43:09 [INFO]: Epoch 013 - training loss: 0.4488, validation loss: 0.0311
2024-05-25 00:43:15 [INFO]: Epoch 014 - training loss: 0.4350, validation loss: 0.0316
2024-05-25 00:43:21 [INFO]: Epoch 015 - training loss: 0.4250, validation loss: 0.0303
2024-05-25 00:43:26 [INFO]: Epoch 016 - training loss: 0.4177, validation loss: 0.0297
2024-05-25 00:43:32 [INFO]: Epoch 017 - training loss: 0.4116, validation loss: 0.0294
2024-05-25 00:43:38 [INFO]: Epoch 018 - training loss: 0.4306, validation loss: 0.0303
2024-05-25 00:43:44 [INFO]: Epoch 019 - training loss: 0.4131, validation loss: 0.0281
2024-05-25 00:43:50 [INFO]: Epoch 020 - training loss: 0.4043, validation loss: 0.0323
2024-05-25 00:43:55 [INFO]: Epoch 021 - training loss: 0.4225, validation loss: 0.0287
2024-05-25 00:44:01 [INFO]: Epoch 022 - training loss: 0.4092, validation loss: 0.0280
2024-05-25 00:44:07 [INFO]: Epoch 023 - training loss: 0.4064, validation loss: 0.0291
2024-05-25 00:44:13 [INFO]: Epoch 024 - training loss: 0.4067, validation loss: 0.0275
2024-05-25 00:44:19 [INFO]: Epoch 025 - training loss: 0.4002, validation loss: 0.0273
2024-05-25 00:44:25 [INFO]: Epoch 026 - training loss: 0.4135, validation loss: 0.0277
2024-05-25 00:44:30 [INFO]: Epoch 027 - training loss: 0.3997, validation loss: 0.0271
2024-05-25 00:44:36 [INFO]: Epoch 028 - training loss: 0.4111, validation loss: 0.0269
2024-05-25 00:44:42 [INFO]: Epoch 029 - training loss: 0.4045, validation loss: 0.0270
2024-05-25 00:44:48 [INFO]: Epoch 030 - training loss: 0.3952, validation loss: 0.0274
2024-05-25 00:44:54 [INFO]: Epoch 031 - training loss: 0.4063, validation loss: 0.0274
2024-05-25 00:45:00 [INFO]: Epoch 032 - training loss: 0.4005, validation loss: 0.0275
2024-05-25 00:45:06 [INFO]: Epoch 033 - training loss: 0.3999, validation loss: 0.0272
2024-05-25 00:45:11 [INFO]: Epoch 034 - training loss: 0.4047, validation loss: 0.0268
2024-05-25 00:45:17 [INFO]: Epoch 035 - training loss: 0.3953, validation loss: 0.0269
2024-05-25 00:45:23 [INFO]: Epoch 036 - training loss: 0.3956, validation loss: 0.0265
2024-05-25 00:45:29 [INFO]: Epoch 037 - training loss: 0.3949, validation loss: 0.0270
2024-05-25 00:45:35 [INFO]: Epoch 038 - training loss: 0.3977, validation loss: 0.0267
2024-05-25 00:45:40 [INFO]: Epoch 039 - training loss: 0.3927, validation loss: 0.0265
2024-05-25 00:45:46 [INFO]: Epoch 040 - training loss: 0.4072, validation loss: 0.0291
2024-05-25 00:45:52 [INFO]: Epoch 041 - training loss: 0.4066, validation loss: 0.0269
2024-05-25 00:45:58 [INFO]: Epoch 042 - training loss: 0.4026, validation loss: 0.0269
2024-05-25 00:46:04 [INFO]: Epoch 043 - training loss: 0.3951, validation loss: 0.0267
2024-05-25 00:46:10 [INFO]: Epoch 044 - training loss: 0.3977, validation loss: 0.0276
2024-05-25 00:46:16 [INFO]: Epoch 045 - training loss: 0.3955, validation loss: 0.0266
2024-05-25 00:46:21 [INFO]: Epoch 046 - training loss: 0.3956, validation loss: 0.0268
2024-05-25 00:46:27 [INFO]: Epoch 047 - training loss: 0.3963, validation loss: 0.0266
2024-05-25 00:46:33 [INFO]: Epoch 048 - training loss: 0.3916, validation loss: 0.0271
2024-05-25 00:46:39 [INFO]: Epoch 049 - training loss: 0.3990, validation loss: 0.0276
2024-05-25 00:46:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:46:39 [INFO]: Finished training. The best model is from epoch#39.
2024-05-25 00:46:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/BRITS_ettm1/20240525_T004152/BRITS.pypots
2024-05-25 00:46:40 [INFO]: BRITS on ETTm1: MAE=0.1409, MSE=0.0571
2024-05-25 00:46:40 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 00:46:40 [INFO]: Using the given device: cuda:0
2024-05-25 00:46:40 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640
2024-05-25 00:46:40 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/tensorboard
2024-05-25 00:46:40 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 00:46:42 [INFO]: Epoch 001 - training loss: 1.4182, validation loss: 1.2640
2024-05-25 00:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch1_loss1.2640119791030884.pypots
2024-05-25 00:46:42 [INFO]: Epoch 002 - training loss: 1.0411, validation loss: 1.1160
2024-05-25 00:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch2_loss1.1159813851118088.pypots
2024-05-25 00:46:42 [INFO]: Epoch 003 - training loss: 0.9106, validation loss: 1.0409
2024-05-25 00:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch3_loss1.0409283936023712.pypots
2024-05-25 00:46:42 [INFO]: Epoch 004 - training loss: 0.9124, validation loss: 1.0065
2024-05-25 00:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch4_loss1.0065415054559708.pypots
2024-05-25 00:46:42 [INFO]: Epoch 005 - training loss: 0.8811, validation loss: 0.9929
2024-05-25 00:46:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch5_loss0.9929328113794327.pypots
2024-05-25 00:46:43 [INFO]: Epoch 006 - training loss: 0.8730, validation loss: 0.9871
2024-05-25 00:46:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch6_loss0.9870796203613281.pypots
2024-05-25 00:46:43 [INFO]: Epoch 007 - training loss: 0.8653, validation loss: 0.9788
2024-05-25 00:46:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch7_loss0.9788359105587006.pypots
2024-05-25 00:46:43 [INFO]: Epoch 008 - training loss: 0.8635, validation loss: 0.9732
2024-05-25 00:46:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch8_loss0.9732227027416229.pypots
2024-05-25 00:46:43 [INFO]: Epoch 009 - training loss: 0.8594, validation loss: 0.9706
2024-05-25 00:46:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch9_loss0.9705735296010971.pypots
2024-05-25 00:46:43 [INFO]: Epoch 010 - training loss: 0.8480, validation loss: 0.9675
2024-05-25 00:46:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch10_loss0.967451274394989.pypots
2024-05-25 00:46:44 [INFO]: Epoch 011 - training loss: 0.8592, validation loss: 0.9627
2024-05-25 00:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch11_loss0.9627192467451096.pypots
2024-05-25 00:46:44 [INFO]: Epoch 012 - training loss: 0.8538, validation loss: 0.9661
2024-05-25 00:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch12_loss0.9660979062318802.pypots
2024-05-25 00:46:44 [INFO]: Epoch 013 - training loss: 0.8029, validation loss: 0.9690
2024-05-25 00:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch13_loss0.9689537733793259.pypots
2024-05-25 00:46:44 [INFO]: Epoch 014 - training loss: 0.8295, validation loss: 0.9630
2024-05-25 00:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch14_loss0.9629655182361603.pypots
2024-05-25 00:46:44 [INFO]: Epoch 015 - training loss: 0.8065, validation loss: 0.9635
2024-05-25 00:46:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch15_loss0.9635183066129684.pypots
2024-05-25 00:46:45 [INFO]: Epoch 016 - training loss: 0.8271, validation loss: 0.9659
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch16_loss0.96585913002491.pypots
2024-05-25 00:46:45 [INFO]: Epoch 017 - training loss: 0.7948, validation loss: 0.9659
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch17_loss0.9659455865621567.pypots
2024-05-25 00:46:45 [INFO]: Epoch 018 - training loss: 0.8047, validation loss: 0.9602
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch18_loss0.9601934850215912.pypots
2024-05-25 00:46:45 [INFO]: Epoch 019 - training loss: 0.8041, validation loss: 0.9587
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch19_loss0.9586914330720901.pypots
2024-05-25 00:46:45 [INFO]: Epoch 020 - training loss: 0.7975, validation loss: 0.9564
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch20_loss0.9563716351985931.pypots
2024-05-25 00:46:45 [INFO]: Epoch 021 - training loss: 0.7941, validation loss: 0.9523
2024-05-25 00:46:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch21_loss0.9522906839847565.pypots
2024-05-25 00:46:46 [INFO]: Epoch 022 - training loss: 0.7660, validation loss: 0.9466
2024-05-25 00:46:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch22_loss0.9465814232826233.pypots
2024-05-25 00:46:46 [INFO]: Epoch 023 - training loss: 0.7972, validation loss: 0.9433
2024-05-25 00:46:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch23_loss0.9432560354471207.pypots
2024-05-25 00:46:46 [INFO]: Epoch 024 - training loss: 0.7773, validation loss: 0.9397
2024-05-25 00:46:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch24_loss0.9397379457950592.pypots
2024-05-25 00:46:46 [INFO]: Epoch 025 - training loss: 0.7590, validation loss: 0.9383
2024-05-25 00:46:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch25_loss0.938254103064537.pypots
2024-05-25 00:46:46 [INFO]: Epoch 026 - training loss: 0.7642, validation loss: 0.9371
2024-05-25 00:46:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch26_loss0.9370674043893814.pypots
2024-05-25 00:46:47 [INFO]: Epoch 027 - training loss: 0.7502, validation loss: 0.9335
2024-05-25 00:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch27_loss0.9334853440523148.pypots
2024-05-25 00:46:47 [INFO]: Epoch 028 - training loss: 0.7664, validation loss: 0.9295
2024-05-25 00:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch28_loss0.9294771105051041.pypots
2024-05-25 00:46:47 [INFO]: Epoch 029 - training loss: 0.7768, validation loss: 0.9262
2024-05-25 00:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch29_loss0.9262121021747589.pypots
2024-05-25 00:46:47 [INFO]: Epoch 030 - training loss: 0.7626, validation loss: 0.9225
2024-05-25 00:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch30_loss0.9224856048822403.pypots
2024-05-25 00:46:47 [INFO]: Epoch 031 - training loss: 0.7492, validation loss: 0.9197
2024-05-25 00:46:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch31_loss0.9197126626968384.pypots
2024-05-25 00:46:48 [INFO]: Epoch 032 - training loss: 0.7550, validation loss: 0.9178
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch32_loss0.9177519232034683.pypots
2024-05-25 00:46:48 [INFO]: Epoch 033 - training loss: 0.7634, validation loss: 0.9165
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch33_loss0.9164742082357407.pypots
2024-05-25 00:46:48 [INFO]: Epoch 034 - training loss: 0.7715, validation loss: 0.9115
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch34_loss0.9115340411663055.pypots
2024-05-25 00:46:48 [INFO]: Epoch 035 - training loss: 0.7689, validation loss: 0.9100
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch35_loss0.9100176841020584.pypots
2024-05-25 00:46:48 [INFO]: Epoch 036 - training loss: 0.7820, validation loss: 0.9091
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch36_loss0.9091341346502304.pypots
2024-05-25 00:46:48 [INFO]: Epoch 037 - training loss: 0.7825, validation loss: 0.9044
2024-05-25 00:46:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch37_loss0.9044238328933716.pypots
2024-05-25 00:46:49 [INFO]: Epoch 038 - training loss: 0.7585, validation loss: 0.9012
2024-05-25 00:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch38_loss0.9012480527162552.pypots
2024-05-25 00:46:49 [INFO]: Epoch 039 - training loss: 0.7576, validation loss: 0.9010
2024-05-25 00:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch39_loss0.9010222405195236.pypots
2024-05-25 00:46:49 [INFO]: Epoch 040 - training loss: 0.7961, validation loss: 0.8979
2024-05-25 00:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch40_loss0.8979128748178482.pypots
2024-05-25 00:46:49 [INFO]: Epoch 041 - training loss: 0.7632, validation loss: 0.8933
2024-05-25 00:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch41_loss0.8932525515556335.pypots
2024-05-25 00:46:49 [INFO]: Epoch 042 - training loss: 0.7969, validation loss: 0.8914
2024-05-25 00:46:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch42_loss0.8913577944040298.pypots
2024-05-25 00:46:50 [INFO]: Epoch 043 - training loss: 0.7708, validation loss: 0.8899
2024-05-25 00:46:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch43_loss0.8898932784795761.pypots
2024-05-25 00:46:50 [INFO]: Epoch 044 - training loss: 0.7370, validation loss: 0.8876
2024-05-25 00:46:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch44_loss0.8876432031393051.pypots
2024-05-25 00:46:50 [INFO]: Epoch 045 - training loss: 0.7568, validation loss: 0.8870
2024-05-25 00:46:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch45_loss0.8870259374380112.pypots
2024-05-25 00:46:50 [INFO]: Epoch 046 - training loss: 0.7541, validation loss: 0.8841
2024-05-25 00:46:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch46_loss0.8841179311275482.pypots
2024-05-25 00:46:50 [INFO]: Epoch 047 - training loss: 0.7920, validation loss: 0.8866
2024-05-25 00:46:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch47_loss0.886568084359169.pypots
2024-05-25 00:46:51 [INFO]: Epoch 048 - training loss: 0.7592, validation loss: 0.8821
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch48_loss0.882138654589653.pypots
2024-05-25 00:46:51 [INFO]: Epoch 049 - training loss: 0.7636, validation loss: 0.8842
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch49_loss0.8841512203216553.pypots
2024-05-25 00:46:51 [INFO]: Epoch 050 - training loss: 0.7612, validation loss: 0.8827
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch50_loss0.8826688081026077.pypots
2024-05-25 00:46:51 [INFO]: Epoch 051 - training loss: 0.7603, validation loss: 0.8818
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch51_loss0.8817866146564484.pypots
2024-05-25 00:46:51 [INFO]: Epoch 052 - training loss: 0.7926, validation loss: 0.8778
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch52_loss0.877773717045784.pypots
2024-05-25 00:46:51 [INFO]: Epoch 053 - training loss: 0.7503, validation loss: 0.8758
2024-05-25 00:46:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch53_loss0.8757954835891724.pypots
2024-05-25 00:46:52 [INFO]: Epoch 054 - training loss: 0.7594, validation loss: 0.8768
2024-05-25 00:46:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch54_loss0.876802384853363.pypots
2024-05-25 00:46:52 [INFO]: Epoch 055 - training loss: 0.7483, validation loss: 0.8761
2024-05-25 00:46:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch55_loss0.8761136531829834.pypots
2024-05-25 00:46:52 [INFO]: Epoch 056 - training loss: 0.7246, validation loss: 0.8752
2024-05-25 00:46:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch56_loss0.8751870840787888.pypots
2024-05-25 00:46:52 [INFO]: Epoch 057 - training loss: 0.7355, validation loss: 0.8745
2024-05-25 00:46:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch57_loss0.8744959235191345.pypots
2024-05-25 00:46:52 [INFO]: Epoch 058 - training loss: 0.7242, validation loss: 0.8748
2024-05-25 00:46:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch58_loss0.8748388737440109.pypots
2024-05-25 00:46:53 [INFO]: Epoch 059 - training loss: 0.7451, validation loss: 0.8747
2024-05-25 00:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch59_loss0.8747246116399765.pypots
2024-05-25 00:46:53 [INFO]: Epoch 060 - training loss: 0.7499, validation loss: 0.8744
2024-05-25 00:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch60_loss0.8744284510612488.pypots
2024-05-25 00:46:53 [INFO]: Epoch 061 - training loss: 0.7492, validation loss: 0.8753
2024-05-25 00:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch61_loss0.8752691596746445.pypots
2024-05-25 00:46:53 [INFO]: Epoch 062 - training loss: 0.7346, validation loss: 0.8731
2024-05-25 00:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch62_loss0.8731119334697723.pypots
2024-05-25 00:46:53 [INFO]: Epoch 063 - training loss: 0.7227, validation loss: 0.8759
2024-05-25 00:46:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch63_loss0.8759308010339737.pypots
2024-05-25 00:46:54 [INFO]: Epoch 064 - training loss: 0.7626, validation loss: 0.8724
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch64_loss0.8723660409450531.pypots
2024-05-25 00:46:54 [INFO]: Epoch 065 - training loss: 0.7896, validation loss: 0.8691
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch65_loss0.8690814077854156.pypots
2024-05-25 00:46:54 [INFO]: Epoch 066 - training loss: 0.7418, validation loss: 0.8674
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch66_loss0.8673731833696365.pypots
2024-05-25 00:46:54 [INFO]: Epoch 067 - training loss: 0.7436, validation loss: 0.8691
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch67_loss0.8691496700048447.pypots
2024-05-25 00:46:54 [INFO]: Epoch 068 - training loss: 0.7169, validation loss: 0.8672
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch68_loss0.8672187179327011.pypots
2024-05-25 00:46:54 [INFO]: Epoch 069 - training loss: 0.7589, validation loss: 0.8670
2024-05-25 00:46:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch69_loss0.8670260459184647.pypots
2024-05-25 00:46:55 [INFO]: Epoch 070 - training loss: 0.7267, validation loss: 0.8668
2024-05-25 00:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch70_loss0.8667643368244171.pypots
2024-05-25 00:46:55 [INFO]: Epoch 071 - training loss: 0.7410, validation loss: 0.8650
2024-05-25 00:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch71_loss0.8649975657463074.pypots
2024-05-25 00:46:55 [INFO]: Epoch 072 - training loss: 0.7080, validation loss: 0.8673
2024-05-25 00:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch72_loss0.8672598004341125.pypots
2024-05-25 00:46:55 [INFO]: Epoch 073 - training loss: 0.7397, validation loss: 0.8676
2024-05-25 00:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch73_loss0.8676353693008423.pypots
2024-05-25 00:46:55 [INFO]: Epoch 074 - training loss: 0.7428, validation loss: 0.8655
2024-05-25 00:46:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch74_loss0.8654579669237137.pypots
2024-05-25 00:46:56 [INFO]: Epoch 075 - training loss: 0.7492, validation loss: 0.8647
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch75_loss0.8646932244300842.pypots
2024-05-25 00:46:56 [INFO]: Epoch 076 - training loss: 0.7359, validation loss: 0.8608
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch76_loss0.8608043193817139.pypots
2024-05-25 00:46:56 [INFO]: Epoch 077 - training loss: 0.7682, validation loss: 0.8652
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch77_loss0.8652421981096268.pypots
2024-05-25 00:46:56 [INFO]: Epoch 078 - training loss: 0.7347, validation loss: 0.8577
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch78_loss0.8576695621013641.pypots
2024-05-25 00:46:56 [INFO]: Epoch 079 - training loss: 0.7504, validation loss: 0.8630
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch79_loss0.8630174100399017.pypots
2024-05-25 00:46:56 [INFO]: Epoch 080 - training loss: 0.7354, validation loss: 0.8621
2024-05-25 00:46:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch80_loss0.8621481508016586.pypots
2024-05-25 00:46:57 [INFO]: Epoch 081 - training loss: 0.7327, validation loss: 0.8637
2024-05-25 00:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch81_loss0.8636886328458786.pypots
2024-05-25 00:46:57 [INFO]: Epoch 082 - training loss: 0.7341, validation loss: 0.8611
2024-05-25 00:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch82_loss0.8610821068286896.pypots
2024-05-25 00:46:57 [INFO]: Epoch 083 - training loss: 0.7315, validation loss: 0.8595
2024-05-25 00:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch83_loss0.8594528585672379.pypots
2024-05-25 00:46:57 [INFO]: Epoch 084 - training loss: 0.7519, validation loss: 0.8605
2024-05-25 00:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch84_loss0.860531359910965.pypots
2024-05-25 00:46:57 [INFO]: Epoch 085 - training loss: 0.7214, validation loss: 0.8607
2024-05-25 00:46:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch85_loss0.8606642931699753.pypots
2024-05-25 00:46:58 [INFO]: Epoch 086 - training loss: 0.7200, validation loss: 0.8583
2024-05-25 00:46:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch86_loss0.8582651764154434.pypots
2024-05-25 00:46:58 [INFO]: Epoch 087 - training loss: 0.7208, validation loss: 0.8611
2024-05-25 00:46:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch87_loss0.8611341267824173.pypots
2024-05-25 00:46:58 [INFO]: Epoch 088 - training loss: 0.7421, validation loss: 0.8608
2024-05-25 00:46:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN_epoch88_loss0.860779419541359.pypots
2024-05-25 00:46:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:46:58 [INFO]: Finished training. The best model is from epoch#78.
2024-05-25 00:46:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_ettm1/20240525_T004640/MRNN.pypots
2024-05-25 00:46:58 [INFO]: MRNN on ETTm1: MAE=0.7880, MSE=1.4585
2024-05-25 00:46:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 00:46:58 [INFO]: Using the given device: cpu
2024-05-25 00:46:58 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 00:46:58 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 00:46:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 00:46:58 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 00:46:58 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 00:46:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 00:46:58 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 00:46:58 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 00:46:58 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 00:46:58 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 00:46:58 [INFO]: Using the given device: cuda:0
2024-05-25 00:46:58 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T004658
2024-05-25 00:46:58 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T004658/tensorboard
2024-05-25 00:46:58 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 00:46:59 [INFO]: Epoch 001 - training loss: 1.1980, validation loss: 0.2658
2024-05-25 00:46:59 [INFO]: Epoch 002 - training loss: 0.9438, validation loss: 0.1503
2024-05-25 00:47:00 [INFO]: Epoch 003 - training loss: 0.8344, validation loss: 0.1102
2024-05-25 00:47:00 [INFO]: Epoch 004 - training loss: 0.7810, validation loss: 0.1038
2024-05-25 00:47:01 [INFO]: Epoch 005 - training loss: 0.7421, validation loss: 0.1021
2024-05-25 00:47:02 [INFO]: Epoch 006 - training loss: 0.7252, validation loss: 0.0771
2024-05-25 00:47:02 [INFO]: Epoch 007 - training loss: 0.6988, validation loss: 0.0911
2024-05-25 00:47:03 [INFO]: Epoch 008 - training loss: 0.6869, validation loss: 0.0909
2024-05-25 00:47:03 [INFO]: Epoch 009 - training loss: 0.6672, validation loss: 0.0811
2024-05-25 00:47:04 [INFO]: Epoch 010 - training loss: 0.6615, validation loss: 0.0871
2024-05-25 00:47:04 [INFO]: Epoch 011 - training loss: 0.6491, validation loss: 0.0761
2024-05-25 00:47:05 [INFO]: Epoch 012 - training loss: 0.6452, validation loss: 0.0864
2024-05-25 00:47:05 [INFO]: Epoch 013 - training loss: 0.6258, validation loss: 0.0726
2024-05-25 00:47:06 [INFO]: Epoch 014 - training loss: 0.6154, validation loss: 0.0683
2024-05-25 00:47:06 [INFO]: Epoch 015 - training loss: 0.6280, validation loss: 0.0647
2024-05-25 00:47:07 [INFO]: Epoch 016 - training loss: 0.6053, validation loss: 0.0769
2024-05-25 00:47:07 [INFO]: Epoch 017 - training loss: 0.5896, validation loss: 0.0776
2024-05-25 00:47:08 [INFO]: Epoch 018 - training loss: 0.5993, validation loss: 0.0601
2024-05-25 00:47:08 [INFO]: Epoch 019 - training loss: 0.6126, validation loss: 0.0926
2024-05-25 00:47:09 [INFO]: Epoch 020 - training loss: 0.6032, validation loss: 0.0623
2024-05-25 00:47:09 [INFO]: Epoch 021 - training loss: 0.5805, validation loss: 0.0622
2024-05-25 00:47:10 [INFO]: Epoch 022 - training loss: 0.5720, validation loss: 0.0616
2024-05-25 00:47:10 [INFO]: Epoch 023 - training loss: 0.5965, validation loss: 0.0591
2024-05-25 00:47:11 [INFO]: Epoch 024 - training loss: 0.5618, validation loss: 0.0562
2024-05-25 00:47:11 [INFO]: Epoch 025 - training loss: 0.5712, validation loss: 0.0792
2024-05-25 00:47:12 [INFO]: Epoch 026 - training loss: 0.5811, validation loss: 0.0704
2024-05-25 00:47:12 [INFO]: Epoch 027 - training loss: 0.5542, validation loss: 0.0623
2024-05-25 00:47:13 [INFO]: Epoch 028 - training loss: 0.5596, validation loss: 0.0443
2024-05-25 00:47:13 [INFO]: Epoch 029 - training loss: 0.5477, validation loss: 0.0564
2024-05-25 00:47:14 [INFO]: Epoch 030 - training loss: 0.5605, validation loss: 0.0635
2024-05-25 00:47:14 [INFO]: Epoch 031 - training loss: 0.5444, validation loss: 0.0754
2024-05-25 00:47:15 [INFO]: Epoch 032 - training loss: 0.5374, validation loss: 0.0619
2024-05-25 00:47:15 [INFO]: Epoch 033 - training loss: 0.5319, validation loss: 0.0468
2024-05-25 00:47:16 [INFO]: Epoch 034 - training loss: 0.5203, validation loss: 0.0393
2024-05-25 00:47:16 [INFO]: Epoch 035 - training loss: 0.5225, validation loss: 0.0498
2024-05-25 00:47:17 [INFO]: Epoch 036 - training loss: 0.5217, validation loss: 0.0516
2024-05-25 00:47:17 [INFO]: Epoch 037 - training loss: 0.5032, validation loss: 0.0390
2024-05-25 00:47:18 [INFO]: Epoch 038 - training loss: 0.5030, validation loss: 0.0375
2024-05-25 00:47:18 [INFO]: Epoch 039 - training loss: 0.5106, validation loss: 0.0528
2024-05-25 00:47:19 [INFO]: Epoch 040 - training loss: 0.5303, validation loss: 0.0485
2024-05-25 00:47:19 [INFO]: Epoch 041 - training loss: 0.5260, validation loss: 0.0701
2024-05-25 00:47:20 [INFO]: Epoch 042 - training loss: 0.5098, validation loss: 0.0481
2024-05-25 00:47:20 [INFO]: Epoch 043 - training loss: 0.5245, validation loss: 0.0494
2024-05-25 00:47:21 [INFO]: Epoch 044 - training loss: 0.5090, validation loss: 0.0481
2024-05-25 00:47:21 [INFO]: Epoch 045 - training loss: 0.4953, validation loss: 0.0502
2024-05-25 00:47:22 [INFO]: Epoch 046 - training loss: 0.4811, validation loss: 0.0509
2024-05-25 00:47:22 [INFO]: Epoch 047 - training loss: 0.4845, validation loss: 0.0396
2024-05-25 00:47:23 [INFO]: Epoch 048 - training loss: 0.4852, validation loss: 0.0381
2024-05-25 00:47:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:47:23 [INFO]: Finished training. The best model is from epoch#38.
2024-05-25 00:47:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/SAITS_ettm1/20240525_T004658/SAITS.pypots
2024-05-25 00:47:23 [INFO]: SAITS on ETTm1: MAE=0.1589, MSE=0.0513
2024-05-25 00:47:23 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 00:47:23 [INFO]: Using the given device: cuda:0
2024-05-25 00:47:23 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T004723
2024-05-25 00:47:23 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T004723/tensorboard
2024-05-25 00:47:23 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 00:47:23 [INFO]: Epoch 001 - training loss: 1.2503, validation loss: 0.3489
2024-05-25 00:47:23 [INFO]: Epoch 002 - training loss: 0.7670, validation loss: 0.1890
2024-05-25 00:47:24 [INFO]: Epoch 003 - training loss: 0.6231, validation loss: 0.1392
2024-05-25 00:47:24 [INFO]: Epoch 004 - training loss: 0.5477, validation loss: 0.1025
2024-05-25 00:47:24 [INFO]: Epoch 005 - training loss: 0.5080, validation loss: 0.0885
2024-05-25 00:47:24 [INFO]: Epoch 006 - training loss: 0.4743, validation loss: 0.0904
2024-05-25 00:47:25 [INFO]: Epoch 007 - training loss: 0.4611, validation loss: 0.0740
2024-05-25 00:47:25 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.0732
2024-05-25 00:47:25 [INFO]: Epoch 009 - training loss: 0.4170, validation loss: 0.0632
2024-05-25 00:47:25 [INFO]: Epoch 010 - training loss: 0.4108, validation loss: 0.0648
2024-05-25 00:47:26 [INFO]: Epoch 011 - training loss: 0.4047, validation loss: 0.0598
2024-05-25 00:47:26 [INFO]: Epoch 012 - training loss: 0.3930, validation loss: 0.0551
2024-05-25 00:47:26 [INFO]: Epoch 013 - training loss: 0.3831, validation loss: 0.0533
2024-05-25 00:47:26 [INFO]: Epoch 014 - training loss: 0.3813, validation loss: 0.0577
2024-05-25 00:47:26 [INFO]: Epoch 015 - training loss: 0.3865, validation loss: 0.0632
2024-05-25 00:47:27 [INFO]: Epoch 016 - training loss: 0.3700, validation loss: 0.0518
2024-05-25 00:47:27 [INFO]: Epoch 017 - training loss: 0.3568, validation loss: 0.0516
2024-05-25 00:47:27 [INFO]: Epoch 018 - training loss: 0.3531, validation loss: 0.0535
2024-05-25 00:47:27 [INFO]: Epoch 019 - training loss: 0.3660, validation loss: 0.0504
2024-05-25 00:47:27 [INFO]: Epoch 020 - training loss: 0.3379, validation loss: 0.0483
2024-05-25 00:47:28 [INFO]: Epoch 021 - training loss: 0.3409, validation loss: 0.0465
2024-05-25 00:47:28 [INFO]: Epoch 022 - training loss: 0.3380, validation loss: 0.0493
2024-05-25 00:47:28 [INFO]: Epoch 023 - training loss: 0.3374, validation loss: 0.0462
2024-05-25 00:47:28 [INFO]: Epoch 024 - training loss: 0.3327, validation loss: 0.0438
2024-05-25 00:47:29 [INFO]: Epoch 025 - training loss: 0.3286, validation loss: 0.0429
2024-05-25 00:47:29 [INFO]: Epoch 026 - training loss: 0.3231, validation loss: 0.0441
2024-05-25 00:47:29 [INFO]: Epoch 027 - training loss: 0.3140, validation loss: 0.0386
2024-05-25 00:47:29 [INFO]: Epoch 028 - training loss: 0.3134, validation loss: 0.0411
2024-05-25 00:47:29 [INFO]: Epoch 029 - training loss: 0.3053, validation loss: 0.0381
2024-05-25 00:47:30 [INFO]: Epoch 030 - training loss: 0.2996, validation loss: 0.0402
2024-05-25 00:47:30 [INFO]: Epoch 031 - training loss: 0.2982, validation loss: 0.0421
2024-05-25 00:47:30 [INFO]: Epoch 032 - training loss: 0.2956, validation loss: 0.0405
2024-05-25 00:47:30 [INFO]: Epoch 033 - training loss: 0.2952, validation loss: 0.0391
2024-05-25 00:47:31 [INFO]: Epoch 034 - training loss: 0.2949, validation loss: 0.0349
2024-05-25 00:47:31 [INFO]: Epoch 035 - training loss: 0.2888, validation loss: 0.0359
2024-05-25 00:47:31 [INFO]: Epoch 036 - training loss: 0.2851, validation loss: 0.0350
2024-05-25 00:47:31 [INFO]: Epoch 037 - training loss: 0.2836, validation loss: 0.0316
2024-05-25 00:47:31 [INFO]: Epoch 038 - training loss: 0.2801, validation loss: 0.0373
2024-05-25 00:47:32 [INFO]: Epoch 039 - training loss: 0.2793, validation loss: 0.0353
2024-05-25 00:47:32 [INFO]: Epoch 040 - training loss: 0.2853, validation loss: 0.0368
2024-05-25 00:47:32 [INFO]: Epoch 041 - training loss: 0.2864, validation loss: 0.0339
2024-05-25 00:47:32 [INFO]: Epoch 042 - training loss: 0.2740, validation loss: 0.0317
2024-05-25 00:47:32 [INFO]: Epoch 043 - training loss: 0.2664, validation loss: 0.0328
2024-05-25 00:47:33 [INFO]: Epoch 044 - training loss: 0.2649, validation loss: 0.0388
2024-05-25 00:47:33 [INFO]: Epoch 045 - training loss: 0.2673, validation loss: 0.0379
2024-05-25 00:47:33 [INFO]: Epoch 046 - training loss: 0.2680, validation loss: 0.0321
2024-05-25 00:47:33 [INFO]: Epoch 047 - training loss: 0.2565, validation loss: 0.0340
2024-05-25 00:47:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:47:33 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 00:47:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/Transformer_ettm1/20240525_T004723/Transformer.pypots
2024-05-25 00:47:33 [INFO]: Transformer on ETTm1: MAE=0.1639, MSE=0.0523
2024-05-25 00:47:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 00:47:33 [INFO]: Using the given device: cuda:0
2024-05-25 00:47:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T004733
2024-05-25 00:47:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T004733/tensorboard
2024-05-25 00:47:34 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 00:47:34 [INFO]: Epoch 001 - training loss: 0.1676, validation loss: 0.0598
2024-05-25 00:47:34 [INFO]: Epoch 002 - training loss: 0.0737, validation loss: 0.0440
2024-05-25 00:47:34 [INFO]: Epoch 003 - training loss: 0.0663, validation loss: 0.0400
2024-05-25 00:47:34 [INFO]: Epoch 004 - training loss: 0.0552, validation loss: 0.0380
2024-05-25 00:47:35 [INFO]: Epoch 005 - training loss: 0.0538, validation loss: 0.0375
2024-05-25 00:47:35 [INFO]: Epoch 006 - training loss: 0.0578, validation loss: 0.0422
2024-05-25 00:47:35 [INFO]: Epoch 007 - training loss: 0.0592, validation loss: 0.0381
2024-05-25 00:47:35 [INFO]: Epoch 008 - training loss: 0.0524, validation loss: 0.0360
2024-05-25 00:47:35 [INFO]: Epoch 009 - training loss: 0.0526, validation loss: 0.0338
2024-05-25 00:47:36 [INFO]: Epoch 010 - training loss: 0.0503, validation loss: 0.0353
2024-05-25 00:47:36 [INFO]: Epoch 011 - training loss: 0.0531, validation loss: 0.0366
2024-05-25 00:47:36 [INFO]: Epoch 012 - training loss: 0.0549, validation loss: 0.0371
2024-05-25 00:47:36 [INFO]: Epoch 013 - training loss: 0.0542, validation loss: 0.0354
2024-05-25 00:47:37 [INFO]: Epoch 014 - training loss: 0.0531, validation loss: 0.0380
2024-05-25 00:47:37 [INFO]: Epoch 015 - training loss: 0.0600, validation loss: 0.0372
2024-05-25 00:47:37 [INFO]: Epoch 016 - training loss: 0.0519, validation loss: 0.0345
2024-05-25 00:47:37 [INFO]: Epoch 017 - training loss: 0.0490, validation loss: 0.0348
2024-05-25 00:47:37 [INFO]: Epoch 018 - training loss: 0.0470, validation loss: 0.0339
2024-05-25 00:47:38 [INFO]: Epoch 019 - training loss: 0.0478, validation loss: 0.0323
2024-05-25 00:47:38 [INFO]: Epoch 020 - training loss: 0.0463, validation loss: 0.0360
2024-05-25 00:47:38 [INFO]: Epoch 021 - training loss: 0.0466, validation loss: 0.0331
2024-05-25 00:47:38 [INFO]: Epoch 022 - training loss: 0.0443, validation loss: 0.0346
2024-05-25 00:47:38 [INFO]: Epoch 023 - training loss: 0.0452, validation loss: 0.0335
2024-05-25 00:47:39 [INFO]: Epoch 024 - training loss: 0.0452, validation loss: 0.0329
2024-05-25 00:47:39 [INFO]: Epoch 025 - training loss: 0.0434, validation loss: 0.0310
2024-05-25 00:47:39 [INFO]: Epoch 026 - training loss: 0.0407, validation loss: 0.0306
2024-05-25 00:47:39 [INFO]: Epoch 027 - training loss: 0.0437, validation loss: 0.0297
2024-05-25 00:47:39 [INFO]: Epoch 028 - training loss: 0.0419, validation loss: 0.0310
2024-05-25 00:47:40 [INFO]: Epoch 029 - training loss: 0.0433, validation loss: 0.0299
2024-05-25 00:47:40 [INFO]: Epoch 030 - training loss: 0.0434, validation loss: 0.0324
2024-05-25 00:47:40 [INFO]: Epoch 031 - training loss: 0.0427, validation loss: 0.0321
2024-05-25 00:47:40 [INFO]: Epoch 032 - training loss: 0.0461, validation loss: 0.0322
2024-05-25 00:47:40 [INFO]: Epoch 033 - training loss: 0.0472, validation loss: 0.0316
2024-05-25 00:47:41 [INFO]: Epoch 034 - training loss: 0.0441, validation loss: 0.0299
2024-05-25 00:47:41 [INFO]: Epoch 035 - training loss: 0.0436, validation loss: 0.0311
2024-05-25 00:47:41 [INFO]: Epoch 036 - training loss: 0.0426, validation loss: 0.0321
2024-05-25 00:47:41 [INFO]: Epoch 037 - training loss: 0.0421, validation loss: 0.0304
2024-05-25 00:47:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:47:41 [INFO]: Finished training. The best model is from epoch#27.
2024-05-25 00:47:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/TimesNet_ettm1/20240525_T004733/TimesNet.pypots
2024-05-25 00:47:41 [INFO]: TimesNet on ETTm1: MAE=0.1215, MSE=0.0320
2024-05-25 00:47:41 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 00:47:41 [INFO]: Using the given device: cuda:0
2024-05-25 00:47:41 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741
2024-05-25 00:47:41 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/tensorboard
2024-05-25 00:47:42 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 00:47:44 [INFO]: Epoch 001 - training loss: 0.7133, validation loss: 0.4605
2024-05-25 00:47:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch1_loss0.46047593653202057.pypots
2024-05-25 00:47:46 [INFO]: Epoch 002 - training loss: 0.4176, validation loss: 0.3680
2024-05-25 00:47:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch2_loss0.3680235370993614.pypots
2024-05-25 00:47:48 [INFO]: Epoch 003 - training loss: 0.3275, validation loss: 0.3363
2024-05-25 00:47:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch3_loss0.3363158702850342.pypots
2024-05-25 00:47:50 [INFO]: Epoch 004 - training loss: 0.2956, validation loss: 0.3239
2024-05-25 00:47:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch4_loss0.32385145872831345.pypots
2024-05-25 00:47:52 [INFO]: Epoch 005 - training loss: 0.3251, validation loss: 0.3082
2024-05-25 00:47:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch5_loss0.30815520137548447.pypots
2024-05-25 00:47:54 [INFO]: Epoch 006 - training loss: 0.3032, validation loss: 0.3053
2024-05-25 00:47:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch6_loss0.30533695966005325.pypots
2024-05-25 00:47:56 [INFO]: Epoch 007 - training loss: 0.2992, validation loss: 0.3494
2024-05-25 00:47:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch7_loss0.34939219802618027.pypots
2024-05-25 00:47:58 [INFO]: Epoch 008 - training loss: 0.3632, validation loss: 0.2839
2024-05-25 00:47:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch8_loss0.28386272490024567.pypots
2024-05-25 00:48:00 [INFO]: Epoch 009 - training loss: 0.2738, validation loss: 0.2779
2024-05-25 00:48:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch9_loss0.277889683842659.pypots
2024-05-25 00:48:02 [INFO]: Epoch 010 - training loss: 0.3429, validation loss: 0.2654
2024-05-25 00:48:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch10_loss0.2654094025492668.pypots
2024-05-25 00:48:04 [INFO]: Epoch 011 - training loss: 0.2635, validation loss: 0.2551
2024-05-25 00:48:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch11_loss0.255131371319294.pypots
2024-05-25 00:48:06 [INFO]: Epoch 012 - training loss: 0.2259, validation loss: 0.2435
2024-05-25 00:48:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch12_loss0.24350635707378387.pypots
2024-05-25 00:48:08 [INFO]: Epoch 013 - training loss: 0.2510, validation loss: 0.2451
2024-05-25 00:48:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch13_loss0.24507500603795052.pypots
2024-05-25 00:48:11 [INFO]: Epoch 014 - training loss: 0.2012, validation loss: 0.2307
2024-05-25 00:48:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch14_loss0.2307029888033867.pypots
2024-05-25 00:48:13 [INFO]: Epoch 015 - training loss: 0.2393, validation loss: 0.2313
2024-05-25 00:48:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch15_loss0.23134884610772133.pypots
2024-05-25 00:48:15 [INFO]: Epoch 016 - training loss: 0.2696, validation loss: 0.2312
2024-05-25 00:48:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch16_loss0.23118264228105545.pypots
2024-05-25 00:48:17 [INFO]: Epoch 017 - training loss: 0.2543, validation loss: 0.2512
2024-05-25 00:48:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch17_loss0.2512235753238201.pypots
2024-05-25 00:48:19 [INFO]: Epoch 018 - training loss: 0.2465, validation loss: 0.2383
2024-05-25 00:48:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch18_loss0.23830513283610344.pypots
2024-05-25 00:48:21 [INFO]: Epoch 019 - training loss: 0.2083, validation loss: 0.2234
2024-05-25 00:48:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch19_loss0.22342891618609428.pypots
2024-05-25 00:48:23 [INFO]: Epoch 020 - training loss: 0.2125, validation loss: 0.1981
2024-05-25 00:48:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch20_loss0.1980825699865818.pypots
2024-05-25 00:48:25 [INFO]: Epoch 021 - training loss: 0.2615, validation loss: 0.1965
2024-05-25 00:48:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch21_loss0.19654531031847.pypots
2024-05-25 00:48:27 [INFO]: Epoch 022 - training loss: 0.2023, validation loss: 0.1972
2024-05-25 00:48:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch22_loss0.19719095155596733.pypots
2024-05-25 00:48:29 [INFO]: Epoch 023 - training loss: 0.2089, validation loss: 0.2005
2024-05-25 00:48:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch23_loss0.200463704764843.pypots
2024-05-25 00:48:31 [INFO]: Epoch 024 - training loss: 0.1971, validation loss: 0.1930
2024-05-25 00:48:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch24_loss0.1930331066250801.pypots
2024-05-25 00:48:33 [INFO]: Epoch 025 - training loss: 0.2054, validation loss: 0.1934
2024-05-25 00:48:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch25_loss0.19339950382709503.pypots
2024-05-25 00:48:35 [INFO]: Epoch 026 - training loss: 0.2151, validation loss: 0.1891
2024-05-25 00:48:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch26_loss0.18906297162175179.pypots
2024-05-25 00:48:37 [INFO]: Epoch 027 - training loss: 0.2037, validation loss: 0.1898
2024-05-25 00:48:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch27_loss0.18980716168880463.pypots
2024-05-25 00:48:40 [INFO]: Epoch 028 - training loss: 0.2509, validation loss: 0.1907
2024-05-25 00:48:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch28_loss0.19072509184479713.pypots
2024-05-25 00:48:42 [INFO]: Epoch 029 - training loss: 0.2165, validation loss: 0.2033
2024-05-25 00:48:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch29_loss0.20328181982040405.pypots
2024-05-25 00:48:44 [INFO]: Epoch 030 - training loss: 0.2015, validation loss: 0.1931
2024-05-25 00:48:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch30_loss0.19308877736330032.pypots
2024-05-25 00:48:46 [INFO]: Epoch 031 - training loss: 0.2267, validation loss: 0.1798
2024-05-25 00:48:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch31_loss0.1797870136797428.pypots
2024-05-25 00:48:48 [INFO]: Epoch 032 - training loss: 0.2079, validation loss: 0.1877
2024-05-25 00:48:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch32_loss0.18767542392015457.pypots
2024-05-25 00:48:50 [INFO]: Epoch 033 - training loss: 0.1847, validation loss: 0.1741
2024-05-25 00:48:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch33_loss0.17408547177910805.pypots
2024-05-25 00:48:52 [INFO]: Epoch 034 - training loss: 0.2125, validation loss: 0.1702
2024-05-25 00:48:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch34_loss0.17018894851207733.pypots
2024-05-25 00:48:54 [INFO]: Epoch 035 - training loss: 0.1548, validation loss: 0.1662
2024-05-25 00:48:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch35_loss0.16624822095036507.pypots
2024-05-25 00:48:56 [INFO]: Epoch 036 - training loss: 0.2090, validation loss: 0.1954
2024-05-25 00:48:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch36_loss0.19541573151946068.pypots
2024-05-25 00:48:58 [INFO]: Epoch 037 - training loss: 0.2599, validation loss: 0.2265
2024-05-25 00:48:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch37_loss0.22650441899895668.pypots
2024-05-25 00:49:01 [INFO]: Epoch 038 - training loss: 0.2482, validation loss: 0.2021
2024-05-25 00:49:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch38_loss0.2021176852285862.pypots
2024-05-25 00:49:03 [INFO]: Epoch 039 - training loss: 0.2219, validation loss: 0.1728
2024-05-25 00:49:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch39_loss0.1727578528225422.pypots
2024-05-25 00:49:05 [INFO]: Epoch 040 - training loss: 0.1796, validation loss: 0.1691
2024-05-25 00:49:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch40_loss0.16905030608177185.pypots
2024-05-25 00:49:07 [INFO]: Epoch 041 - training loss: 0.1712, validation loss: 0.1640
2024-05-25 00:49:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch41_loss0.16401996836066246.pypots
2024-05-25 00:49:09 [INFO]: Epoch 042 - training loss: 0.1568, validation loss: 0.1625
2024-05-25 00:49:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch42_loss0.1624910570681095.pypots
2024-05-25 00:49:11 [INFO]: Epoch 043 - training loss: 0.1912, validation loss: 0.1635
2024-05-25 00:49:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch43_loss0.1634841226041317.pypots
2024-05-25 00:49:13 [INFO]: Epoch 044 - training loss: 0.1912, validation loss: 0.1606
2024-05-25 00:49:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch44_loss0.16064612567424774.pypots
2024-05-25 00:49:15 [INFO]: Epoch 045 - training loss: 0.1575, validation loss: 0.1621
2024-05-25 00:49:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch45_loss0.16205847635865211.pypots
2024-05-25 00:49:17 [INFO]: Epoch 046 - training loss: 0.2401, validation loss: 0.1648
2024-05-25 00:49:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch46_loss0.16480445489287376.pypots
2024-05-25 00:49:19 [INFO]: Epoch 047 - training loss: 0.1728, validation loss: 0.1861
2024-05-25 00:49:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch47_loss0.18612443283200264.pypots
2024-05-25 00:49:21 [INFO]: Epoch 048 - training loss: 0.2051, validation loss: 0.1632
2024-05-25 00:49:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch48_loss0.16318723186850548.pypots
2024-05-25 00:49:23 [INFO]: Epoch 049 - training loss: 0.1717, validation loss: 0.1742
2024-05-25 00:49:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch49_loss0.17419835180044174.pypots
2024-05-25 00:49:25 [INFO]: Epoch 050 - training loss: 0.2117, validation loss: 0.1700
2024-05-25 00:49:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch50_loss0.16999218240380287.pypots
2024-05-25 00:49:28 [INFO]: Epoch 051 - training loss: 0.1900, validation loss: 0.1608
2024-05-25 00:49:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch51_loss0.16076796129345894.pypots
2024-05-25 00:49:30 [INFO]: Epoch 052 - training loss: 0.1919, validation loss: 0.1569
2024-05-25 00:49:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch52_loss0.1568807028234005.pypots
2024-05-25 00:49:32 [INFO]: Epoch 053 - training loss: 0.1799, validation loss: 0.1538
2024-05-25 00:49:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch53_loss0.15378042683005333.pypots
2024-05-25 00:49:34 [INFO]: Epoch 054 - training loss: 0.1975, validation loss: 0.1516
2024-05-25 00:49:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch54_loss0.15159497782588005.pypots
2024-05-25 00:49:36 [INFO]: Epoch 055 - training loss: 0.1969, validation loss: 0.1537
2024-05-25 00:49:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch55_loss0.1536904163658619.pypots
2024-05-25 00:49:38 [INFO]: Epoch 056 - training loss: 0.2386, validation loss: 0.1658
2024-05-25 00:49:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch56_loss0.1657887026667595.pypots
2024-05-25 00:49:40 [INFO]: Epoch 057 - training loss: 0.1756, validation loss: 0.1633
2024-05-25 00:49:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch57_loss0.1632971353828907.pypots
2024-05-25 00:49:42 [INFO]: Epoch 058 - training loss: 0.2316, validation loss: 0.1564
2024-05-25 00:49:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch58_loss0.15640239417552948.pypots
2024-05-25 00:49:44 [INFO]: Epoch 059 - training loss: 0.1807, validation loss: 0.1561
2024-05-25 00:49:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch59_loss0.15612619370222092.pypots
2024-05-25 00:49:46 [INFO]: Epoch 060 - training loss: 0.1898, validation loss: 0.1750
2024-05-25 00:49:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch60_loss0.17495012655854225.pypots
2024-05-25 00:49:48 [INFO]: Epoch 061 - training loss: 0.2015, validation loss: 0.1637
2024-05-25 00:49:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch61_loss0.1636941283941269.pypots
2024-05-25 00:49:50 [INFO]: Epoch 062 - training loss: 0.2274, validation loss: 0.1582
2024-05-25 00:49:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch62_loss0.15820778533816338.pypots
2024-05-25 00:49:52 [INFO]: Epoch 063 - training loss: 0.1959, validation loss: 0.1533
2024-05-25 00:49:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch63_loss0.15332618355751038.pypots
2024-05-25 00:49:54 [INFO]: Epoch 064 - training loss: 0.1565, validation loss: 0.1531
2024-05-25 00:49:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI_epoch64_loss0.153097465634346.pypots
2024-05-25 00:49:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:49:54 [INFO]: Finished training. The best model is from epoch#54.
2024-05-25 00:49:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_ettm1/20240525_T004741/CSDI.pypots
2024-05-25 00:50:10 [INFO]: CSDI on ETTm1: MAE=0.4121, MSE=3.5889
2024-05-25 00:50:10 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 00:50:10 [INFO]: Using the given device: cuda:0
2024-05-25 00:50:10 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T005010
2024-05-25 00:50:10 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T005010/tensorboard
2024-05-25 00:50:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 00:50:10 [INFO]: Epoch 001 - training loss: 24358.8650, validation loss: 0.9435
2024-05-25 00:50:10 [INFO]: Epoch 002 - training loss: 22334.0646, validation loss: 0.9416
2024-05-25 00:50:11 [INFO]: Epoch 003 - training loss: 20322.0858, validation loss: 0.9431
2024-05-25 00:50:11 [INFO]: Epoch 004 - training loss: 18158.3994, validation loss: 0.9402
2024-05-25 00:50:11 [INFO]: Epoch 005 - training loss: 16257.2992, validation loss: 0.9403
2024-05-25 00:50:11 [INFO]: Epoch 006 - training loss: 14790.1185, validation loss: 0.9162
2024-05-25 00:50:11 [INFO]: Epoch 007 - training loss: 13310.4176, validation loss: 0.8772
2024-05-25 00:50:11 [INFO]: Epoch 008 - training loss: 12355.8185, validation loss: 0.8211
2024-05-25 00:50:11 [INFO]: Epoch 009 - training loss: 11663.7902, validation loss: 0.7264
2024-05-25 00:50:11 [INFO]: Epoch 010 - training loss: 11180.6073, validation loss: 0.6333
2024-05-25 00:50:12 [INFO]: Epoch 011 - training loss: 10813.6501, validation loss: 0.5660
2024-05-25 00:50:12 [INFO]: Epoch 012 - training loss: 10499.1252, validation loss: 0.5091
2024-05-25 00:50:12 [INFO]: Epoch 013 - training loss: 10415.8990, validation loss: 0.4951
2024-05-25 00:50:12 [INFO]: Epoch 014 - training loss: 10318.4054, validation loss: 0.4818
2024-05-25 00:50:12 [INFO]: Epoch 015 - training loss: 10181.2560, validation loss: 0.4671
2024-05-25 00:50:12 [INFO]: Epoch 016 - training loss: 9935.5685, validation loss: 0.4444
2024-05-25 00:50:12 [INFO]: Epoch 017 - training loss: 9900.2941, validation loss: 0.4347
2024-05-25 00:50:12 [INFO]: Epoch 018 - training loss: 9796.2603, validation loss: 0.4082
2024-05-25 00:50:13 [INFO]: Epoch 019 - training loss: 9759.4376, validation loss: 0.3866
2024-05-25 00:50:13 [INFO]: Epoch 020 - training loss: 9693.3830, validation loss: 0.3597
2024-05-25 00:50:13 [INFO]: Epoch 021 - training loss: 9627.1660, validation loss: 0.3416
2024-05-25 00:50:13 [INFO]: Epoch 022 - training loss: 9596.8531, validation loss: 0.3280
2024-05-25 00:50:13 [INFO]: Epoch 023 - training loss: 9560.5604, validation loss: 0.3141
2024-05-25 00:50:13 [INFO]: Epoch 024 - training loss: 9561.4622, validation loss: 0.3044
2024-05-25 00:50:13 [INFO]: Epoch 025 - training loss: 9513.6435, validation loss: 0.2884
2024-05-25 00:50:13 [INFO]: Epoch 026 - training loss: 9490.4236, validation loss: 0.2767
2024-05-25 00:50:14 [INFO]: Epoch 027 - training loss: 9468.9422, validation loss: 0.2720
2024-05-25 00:50:14 [INFO]: Epoch 028 - training loss: 9456.0342, validation loss: 0.2614
2024-05-25 00:50:14 [INFO]: Epoch 029 - training loss: 9433.6114, validation loss: 0.2569
2024-05-25 00:50:14 [INFO]: Epoch 030 - training loss: 9434.8604, validation loss: 0.2554
2024-05-25 00:50:14 [INFO]: Epoch 031 - training loss: 9409.8211, validation loss: 0.2444
2024-05-25 00:50:14 [INFO]: Epoch 032 - training loss: 9402.6660, validation loss: 0.2448
2024-05-25 00:50:14 [INFO]: Epoch 033 - training loss: 9392.3300, validation loss: 0.2332
2024-05-25 00:50:14 [INFO]: Epoch 034 - training loss: 9380.6297, validation loss: 0.2278
2024-05-25 00:50:15 [INFO]: Epoch 035 - training loss: 9369.6075, validation loss: 0.2237
2024-05-25 00:50:15 [INFO]: Epoch 036 - training loss: 9364.4589, validation loss: 0.2221
2024-05-25 00:50:15 [INFO]: Epoch 037 - training loss: 9366.3494, validation loss: 0.2157
2024-05-25 00:50:15 [INFO]: Epoch 038 - training loss: 9346.7054, validation loss: 0.2110
2024-05-25 00:50:15 [INFO]: Epoch 039 - training loss: 9344.0391, validation loss: 0.2099
2024-05-25 00:50:15 [INFO]: Epoch 040 - training loss: 9336.2407, validation loss: 0.2036
2024-05-25 00:50:15 [INFO]: Epoch 041 - training loss: 9329.0969, validation loss: 0.1961
2024-05-25 00:50:15 [INFO]: Epoch 042 - training loss: 9324.8306, validation loss: 0.1983
2024-05-25 00:50:15 [INFO]: Epoch 043 - training loss: 9324.4721, validation loss: 0.1925
2024-05-25 00:50:16 [INFO]: Epoch 044 - training loss: 9321.1968, validation loss: 0.1868
2024-05-25 00:50:16 [INFO]: Epoch 045 - training loss: 9311.5016, validation loss: 0.1836
2024-05-25 00:50:16 [INFO]: Epoch 046 - training loss: 9314.3865, validation loss: 0.1797
2024-05-25 00:50:16 [INFO]: Epoch 047 - training loss: 9304.2475, validation loss: 0.1781
2024-05-25 00:50:16 [INFO]: Epoch 048 - training loss: 9299.5146, validation loss: 0.1751
2024-05-25 00:50:16 [INFO]: Epoch 049 - training loss: 9301.9979, validation loss: 0.1708
2024-05-25 00:50:16 [INFO]: Epoch 050 - training loss: 9295.5611, validation loss: 0.1716
2024-05-25 00:50:16 [INFO]: Epoch 051 - training loss: 9291.7189, validation loss: 0.1657
2024-05-25 00:50:17 [INFO]: Epoch 052 - training loss: 9288.1116, validation loss: 0.1646
2024-05-25 00:50:17 [INFO]: Epoch 053 - training loss: 9286.1878, validation loss: 0.1600
2024-05-25 00:50:17 [INFO]: Epoch 054 - training loss: 9289.1513, validation loss: 0.1580
2024-05-25 00:50:17 [INFO]: Epoch 055 - training loss: 9278.4991, validation loss: 0.1556
2024-05-25 00:50:17 [INFO]: Epoch 056 - training loss: 9281.4383, validation loss: 0.1528
2024-05-25 00:50:17 [INFO]: Epoch 057 - training loss: 9281.2169, validation loss: 0.1526
2024-05-25 00:50:17 [INFO]: Epoch 058 - training loss: 9275.9680, validation loss: 0.1506
2024-05-25 00:50:17 [INFO]: Epoch 059 - training loss: 9277.8853, validation loss: 0.1467
2024-05-25 00:50:18 [INFO]: Epoch 060 - training loss: 9269.1364, validation loss: 0.1451
2024-05-25 00:50:18 [INFO]: Epoch 061 - training loss: 9269.7247, validation loss: 0.1452
2024-05-25 00:50:18 [INFO]: Epoch 062 - training loss: 9266.1169, validation loss: 0.1425
2024-05-25 00:50:18 [INFO]: Epoch 063 - training loss: 9262.2955, validation loss: 0.1436
2024-05-25 00:50:18 [INFO]: Epoch 064 - training loss: 9261.8685, validation loss: 0.1402
2024-05-25 00:50:18 [INFO]: Epoch 065 - training loss: 9264.9567, validation loss: 0.1425
2024-05-25 00:50:18 [INFO]: Epoch 066 - training loss: 9261.7382, validation loss: 0.1396
2024-05-25 00:50:18 [INFO]: Epoch 067 - training loss: 9255.8106, validation loss: 0.1416
2024-05-25 00:50:19 [INFO]: Epoch 068 - training loss: 9256.3502, validation loss: 0.1372
2024-05-25 00:50:19 [INFO]: Epoch 069 - training loss: 9255.6342, validation loss: 0.1376
2024-05-25 00:50:19 [INFO]: Epoch 070 - training loss: 9254.8962, validation loss: 0.1340
2024-05-25 00:50:19 [INFO]: Epoch 071 - training loss: 9253.8612, validation loss: 0.1353
2024-05-25 00:50:19 [INFO]: Epoch 072 - training loss: 9251.6688, validation loss: 0.1353
2024-05-25 00:50:19 [INFO]: Epoch 073 - training loss: 9249.4453, validation loss: 0.1313
2024-05-25 00:50:19 [INFO]: Epoch 074 - training loss: 9253.2280, validation loss: 0.1320
2024-05-25 00:50:19 [INFO]: Epoch 075 - training loss: 9251.6521, validation loss: 0.1331
2024-05-25 00:50:19 [INFO]: Epoch 076 - training loss: 9247.5751, validation loss: 0.1307
2024-05-25 00:50:20 [INFO]: Epoch 077 - training loss: 9247.0607, validation loss: 0.1330
2024-05-25 00:50:20 [INFO]: Epoch 078 - training loss: 9245.9468, validation loss: 0.1309
2024-05-25 00:50:20 [INFO]: Epoch 079 - training loss: 9245.3951, validation loss: 0.1302
2024-05-25 00:50:20 [INFO]: Epoch 080 - training loss: 9244.9230, validation loss: 0.1288
2024-05-25 00:50:20 [INFO]: Epoch 081 - training loss: 9245.6832, validation loss: 0.1272
2024-05-25 00:50:20 [INFO]: Epoch 082 - training loss: 9241.8864, validation loss: 0.1264
2024-05-25 00:50:20 [INFO]: Epoch 083 - training loss: 9255.9108, validation loss: 0.1268
2024-05-25 00:50:20 [INFO]: Epoch 084 - training loss: 9238.9958, validation loss: 0.1246
2024-05-25 00:50:21 [INFO]: Epoch 085 - training loss: 9244.1959, validation loss: 0.1263
2024-05-25 00:50:21 [INFO]: Epoch 086 - training loss: 9240.6831, validation loss: 0.1231
2024-05-25 00:50:21 [INFO]: Epoch 087 - training loss: 9237.7130, validation loss: 0.1246
2024-05-25 00:50:21 [INFO]: Epoch 088 - training loss: 9239.0621, validation loss: 0.1233
2024-05-25 00:50:21 [INFO]: Epoch 089 - training loss: 9237.3473, validation loss: 0.1248
2024-05-25 00:50:21 [INFO]: Epoch 090 - training loss: 9237.4592, validation loss: 0.1217
2024-05-25 00:50:21 [INFO]: Epoch 091 - training loss: 9238.0319, validation loss: 0.1218
2024-05-25 00:50:21 [INFO]: Epoch 092 - training loss: 9233.9759, validation loss: 0.1205
2024-05-25 00:50:22 [INFO]: Epoch 093 - training loss: 9234.9259, validation loss: 0.1202
2024-05-25 00:50:22 [INFO]: Epoch 094 - training loss: 9234.2761, validation loss: 0.1203
2024-05-25 00:50:22 [INFO]: Epoch 095 - training loss: 9234.4623, validation loss: 0.1189
2024-05-25 00:50:22 [INFO]: Epoch 096 - training loss: 9235.4988, validation loss: 0.1196
2024-05-25 00:50:22 [INFO]: Epoch 097 - training loss: 9235.0677, validation loss: 0.1174
2024-05-25 00:50:22 [INFO]: Epoch 098 - training loss: 9235.1360, validation loss: 0.1182
2024-05-25 00:50:22 [INFO]: Epoch 099 - training loss: 9231.8153, validation loss: 0.1177
2024-05-25 00:50:22 [INFO]: Epoch 100 - training loss: 9236.3307, validation loss: 0.1168
2024-05-25 00:50:23 [INFO]: Epoch 101 - training loss: 9229.7477, validation loss: 0.1153
2024-05-25 00:50:23 [INFO]: Epoch 102 - training loss: 9231.8217, validation loss: 0.1160
2024-05-25 00:50:23 [INFO]: Epoch 103 - training loss: 9230.2531, validation loss: 0.1166
2024-05-25 00:50:23 [INFO]: Epoch 104 - training loss: 9235.7721, validation loss: 0.1136
2024-05-25 00:50:23 [INFO]: Epoch 105 - training loss: 9229.6133, validation loss: 0.1145
2024-05-25 00:50:23 [INFO]: Epoch 106 - training loss: 9227.5151, validation loss: 0.1132
2024-05-25 00:50:23 [INFO]: Epoch 107 - training loss: 9228.9601, validation loss: 0.1130
2024-05-25 00:50:23 [INFO]: Epoch 108 - training loss: 9231.9442, validation loss: 0.1124
2024-05-25 00:50:24 [INFO]: Epoch 109 - training loss: 9227.4102, validation loss: 0.1121
2024-05-25 00:50:24 [INFO]: Epoch 110 - training loss: 9225.7783, validation loss: 0.1108
2024-05-25 00:50:24 [INFO]: Epoch 111 - training loss: 9225.6007, validation loss: 0.1118
2024-05-25 00:50:24 [INFO]: Epoch 112 - training loss: 9226.9454, validation loss: 0.1119
2024-05-25 00:50:24 [INFO]: Epoch 113 - training loss: 9226.1616, validation loss: 0.1101
2024-05-25 00:50:24 [INFO]: Epoch 114 - training loss: 9226.6661, validation loss: 0.1127
2024-05-25 00:50:24 [INFO]: Epoch 115 - training loss: 9225.1790, validation loss: 0.1078
2024-05-25 00:50:24 [INFO]: Epoch 116 - training loss: 9224.9729, validation loss: 0.1091
2024-05-25 00:50:24 [INFO]: Epoch 117 - training loss: 9226.7675, validation loss: 0.1105
2024-05-25 00:50:25 [INFO]: Epoch 118 - training loss: 9225.8759, validation loss: 0.1081
2024-05-25 00:50:25 [INFO]: Epoch 119 - training loss: 9224.4034, validation loss: 0.1098
2024-05-25 00:50:25 [INFO]: Epoch 120 - training loss: 9224.1278, validation loss: 0.1066
2024-05-25 00:50:25 [INFO]: Epoch 121 - training loss: 9226.9904, validation loss: 0.1074
2024-05-25 00:50:25 [INFO]: Epoch 122 - training loss: 9222.7094, validation loss: 0.1074
2024-05-25 00:50:25 [INFO]: Epoch 123 - training loss: 9224.3705, validation loss: 0.1057
2024-05-25 00:50:25 [INFO]: Epoch 124 - training loss: 9222.6393, validation loss: 0.1088
2024-05-25 00:50:25 [INFO]: Epoch 125 - training loss: 9222.6199, validation loss: 0.1069
2024-05-25 00:50:26 [INFO]: Epoch 126 - training loss: 9223.6779, validation loss: 0.1063
2024-05-25 00:50:26 [INFO]: Epoch 127 - training loss: 9220.6567, validation loss: 0.1063
2024-05-25 00:50:26 [INFO]: Epoch 128 - training loss: 9222.8175, validation loss: 0.1047
2024-05-25 00:50:26 [INFO]: Epoch 129 - training loss: 9220.6088, validation loss: 0.1052
2024-05-25 00:50:26 [INFO]: Epoch 130 - training loss: 9222.3221, validation loss: 0.1026
2024-05-25 00:50:26 [INFO]: Epoch 131 - training loss: 9222.1559, validation loss: 0.1055
2024-05-25 00:50:26 [INFO]: Epoch 132 - training loss: 9220.9367, validation loss: 0.1031
2024-05-25 00:50:26 [INFO]: Epoch 133 - training loss: 9220.0269, validation loss: 0.1030
2024-05-25 00:50:27 [INFO]: Epoch 134 - training loss: 9221.2719, validation loss: 0.1029
2024-05-25 00:50:27 [INFO]: Epoch 135 - training loss: 9218.4453, validation loss: 0.1030
2024-05-25 00:50:27 [INFO]: Epoch 136 - training loss: 9218.7283, validation loss: 0.1020
2024-05-25 00:50:27 [INFO]: Epoch 137 - training loss: 9221.3973, validation loss: 0.1015
2024-05-25 00:50:27 [INFO]: Epoch 138 - training loss: 9218.4369, validation loss: 0.1033
2024-05-25 00:50:27 [INFO]: Epoch 139 - training loss: 9220.2366, validation loss: 0.1017
2024-05-25 00:50:27 [INFO]: Epoch 140 - training loss: 9220.0159, validation loss: 0.0983
2024-05-25 00:50:27 [INFO]: Epoch 141 - training loss: 9220.1473, validation loss: 0.1028
2024-05-25 00:50:28 [INFO]: Epoch 142 - training loss: 9219.5038, validation loss: 0.0996
2024-05-25 00:50:28 [INFO]: Epoch 143 - training loss: 9222.0057, validation loss: 0.1011
2024-05-25 00:50:28 [INFO]: Epoch 144 - training loss: 9217.7572, validation loss: 0.0990
2024-05-25 00:50:28 [INFO]: Epoch 145 - training loss: 9218.6089, validation loss: 0.0984
2024-05-25 00:50:28 [INFO]: Epoch 146 - training loss: 9218.4557, validation loss: 0.1005
2024-05-25 00:50:28 [INFO]: Epoch 147 - training loss: 9218.4423, validation loss: 0.0974
2024-05-25 00:50:28 [INFO]: Epoch 148 - training loss: 9217.0011, validation loss: 0.1042
2024-05-25 00:50:28 [INFO]: Epoch 149 - training loss: 9217.7750, validation loss: 0.0997
2024-05-25 00:50:29 [INFO]: Epoch 150 - training loss: 9217.4109, validation loss: 0.0966
2024-05-25 00:50:29 [INFO]: Epoch 151 - training loss: 9215.0978, validation loss: 0.1008
2024-05-25 00:50:29 [INFO]: Epoch 152 - training loss: 9215.5359, validation loss: 0.0944
2024-05-25 00:50:29 [INFO]: Epoch 153 - training loss: 9216.6249, validation loss: 0.0961
2024-05-25 00:50:29 [INFO]: Epoch 154 - training loss: 9216.3021, validation loss: 0.0971
2024-05-25 00:50:29 [INFO]: Epoch 155 - training loss: 9215.5688, validation loss: 0.0970
2024-05-25 00:50:29 [INFO]: Epoch 156 - training loss: 9217.4186, validation loss: 0.0958
2024-05-25 00:50:29 [INFO]: Epoch 157 - training loss: 9215.0781, validation loss: 0.0945
2024-05-25 00:50:30 [INFO]: Epoch 158 - training loss: 9215.1709, validation loss: 0.0955
2024-05-25 00:50:30 [INFO]: Epoch 159 - training loss: 9216.0019, validation loss: 0.0948
2024-05-25 00:50:30 [INFO]: Epoch 160 - training loss: 9215.2090, validation loss: 0.0943
2024-05-25 00:50:30 [INFO]: Epoch 161 - training loss: 9214.4844, validation loss: 0.0930
2024-05-25 00:50:30 [INFO]: Epoch 162 - training loss: 9215.2982, validation loss: 0.0931
2024-05-25 00:50:30 [INFO]: Epoch 163 - training loss: 9214.5099, validation loss: 0.0941
2024-05-25 00:50:30 [INFO]: Epoch 164 - training loss: 9214.4016, validation loss: 0.0917
2024-05-25 00:50:30 [INFO]: Epoch 165 - training loss: 9213.8517, validation loss: 0.0934
2024-05-25 00:50:31 [INFO]: Epoch 166 - training loss: 9213.5992, validation loss: 0.0932
2024-05-25 00:50:31 [INFO]: Epoch 167 - training loss: 9213.2539, validation loss: 0.0925
2024-05-25 00:50:31 [INFO]: Epoch 168 - training loss: 9213.7631, validation loss: 0.0926
2024-05-25 00:50:31 [INFO]: Epoch 169 - training loss: 9213.1321, validation loss: 0.0934
2024-05-25 00:50:31 [INFO]: Epoch 170 - training loss: 9214.7077, validation loss: 0.0920
2024-05-25 00:50:31 [INFO]: Epoch 171 - training loss: 9213.4688, validation loss: 0.0905
2024-05-25 00:50:31 [INFO]: Epoch 172 - training loss: 9213.8582, validation loss: 0.0922
2024-05-25 00:50:31 [INFO]: Epoch 173 - training loss: 9213.3735, validation loss: 0.0907
2024-05-25 00:50:32 [INFO]: Epoch 174 - training loss: 9213.4372, validation loss: 0.0916
2024-05-25 00:50:32 [INFO]: Epoch 175 - training loss: 9212.5837, validation loss: 0.0901
2024-05-25 00:50:32 [INFO]: Epoch 176 - training loss: 9212.6052, validation loss: 0.0893
2024-05-25 00:50:32 [INFO]: Epoch 177 - training loss: 9213.2639, validation loss: 0.0910
2024-05-25 00:50:32 [INFO]: Epoch 178 - training loss: 9212.4494, validation loss: 0.0895
2024-05-25 00:50:32 [INFO]: Epoch 179 - training loss: 9215.4603, validation loss: 0.0874
2024-05-25 00:50:32 [INFO]: Epoch 180 - training loss: 9211.6313, validation loss: 0.0934
2024-05-25 00:50:32 [INFO]: Epoch 181 - training loss: 9213.0722, validation loss: 0.0906
2024-05-25 00:50:32 [INFO]: Epoch 182 - training loss: 9212.2343, validation loss: 0.0905
2024-05-25 00:50:33 [INFO]: Epoch 183 - training loss: 9213.7270, validation loss: 0.0898
2024-05-25 00:50:33 [INFO]: Epoch 184 - training loss: 9212.1664, validation loss: 0.0901
2024-05-25 00:50:33 [INFO]: Epoch 185 - training loss: 9211.9371, validation loss: 0.0888
2024-05-25 00:50:33 [INFO]: Epoch 186 - training loss: 9211.9326, validation loss: 0.0914
2024-05-25 00:50:33 [INFO]: Epoch 187 - training loss: 9212.1895, validation loss: 0.0900
2024-05-25 00:50:33 [INFO]: Epoch 188 - training loss: 9213.4189, validation loss: 0.0880
2024-05-25 00:50:33 [INFO]: Epoch 189 - training loss: 9214.3440, validation loss: 0.0872
2024-05-25 00:50:33 [INFO]: Epoch 190 - training loss: 9212.9349, validation loss: 0.0901
2024-05-25 00:50:34 [INFO]: Epoch 191 - training loss: 9211.8257, validation loss: 0.0881
2024-05-25 00:50:34 [INFO]: Epoch 192 - training loss: 9212.2369, validation loss: 0.0880
2024-05-25 00:50:34 [INFO]: Epoch 193 - training loss: 9210.5616, validation loss: 0.0877
2024-05-25 00:50:34 [INFO]: Epoch 194 - training loss: 9210.6207, validation loss: 0.0893
2024-05-25 00:50:34 [INFO]: Epoch 195 - training loss: 9211.3007, validation loss: 0.0865
2024-05-25 00:50:34 [INFO]: Epoch 196 - training loss: 9211.8919, validation loss: 0.0861
2024-05-25 00:50:34 [INFO]: Epoch 197 - training loss: 9211.1012, validation loss: 0.0891
2024-05-25 00:50:34 [INFO]: Epoch 198 - training loss: 9212.6814, validation loss: 0.0875
2024-05-25 00:50:35 [INFO]: Epoch 199 - training loss: 9210.7851, validation loss: 0.0853
2024-05-25 00:50:35 [INFO]: Epoch 200 - training loss: 9210.0635, validation loss: 0.0869
2024-05-25 00:50:35 [INFO]: Epoch 201 - training loss: 9211.4024, validation loss: 0.0861
2024-05-25 00:50:35 [INFO]: Epoch 202 - training loss: 9210.1464, validation loss: 0.0858
2024-05-25 00:50:35 [INFO]: Epoch 203 - training loss: 9211.5958, validation loss: 0.0905
2024-05-25 00:50:35 [INFO]: Epoch 204 - training loss: 9209.0908, validation loss: 0.0872
2024-05-25 00:50:35 [INFO]: Epoch 205 - training loss: 9210.4897, validation loss: 0.0849
2024-05-25 00:50:35 [INFO]: Epoch 206 - training loss: 9210.3980, validation loss: 0.0862
2024-05-25 00:50:36 [INFO]: Epoch 207 - training loss: 9210.1241, validation loss: 0.0863
2024-05-25 00:50:36 [INFO]: Epoch 208 - training loss: 9210.5049, validation loss: 0.0839
2024-05-25 00:50:36 [INFO]: Epoch 209 - training loss: 9211.2329, validation loss: 0.0870
2024-05-25 00:50:36 [INFO]: Epoch 210 - training loss: 9209.8331, validation loss: 0.0888
2024-05-25 00:50:36 [INFO]: Epoch 211 - training loss: 9208.7631, validation loss: 0.0852
2024-05-25 00:50:36 [INFO]: Epoch 212 - training loss: 9210.0948, validation loss: 0.0857
2024-05-25 00:50:36 [INFO]: Epoch 213 - training loss: 9209.6895, validation loss: 0.0861
2024-05-25 00:50:36 [INFO]: Epoch 214 - training loss: 9208.3696, validation loss: 0.0841
2024-05-25 00:50:37 [INFO]: Epoch 215 - training loss: 9209.1282, validation loss: 0.0869
2024-05-25 00:50:37 [INFO]: Epoch 216 - training loss: 9211.0680, validation loss: 0.0839
2024-05-25 00:50:37 [INFO]: Epoch 217 - training loss: 9209.2700, validation loss: 0.0848
2024-05-25 00:50:37 [INFO]: Epoch 218 - training loss: 9208.7290, validation loss: 0.0841
2024-05-25 00:50:37 [INFO]: Epoch 219 - training loss: 9210.7866, validation loss: 0.0843
2024-05-25 00:50:37 [INFO]: Epoch 220 - training loss: 9207.4321, validation loss: 0.0861
2024-05-25 00:50:37 [INFO]: Epoch 221 - training loss: 9209.3367, validation loss: 0.0851
2024-05-25 00:50:37 [INFO]: Epoch 222 - training loss: 9208.5995, validation loss: 0.0840
2024-05-25 00:50:37 [INFO]: Epoch 223 - training loss: 9207.7624, validation loss: 0.0869
2024-05-25 00:50:38 [INFO]: Epoch 224 - training loss: 9210.9379, validation loss: 0.0835
2024-05-25 00:50:38 [INFO]: Epoch 225 - training loss: 9208.8965, validation loss: 0.0838
2024-05-25 00:50:38 [INFO]: Epoch 226 - training loss: 9208.1411, validation loss: 0.0834
2024-05-25 00:50:38 [INFO]: Epoch 227 - training loss: 9209.0292, validation loss: 0.0871
2024-05-25 00:50:38 [INFO]: Epoch 228 - training loss: 9212.1830, validation loss: 0.0843
2024-05-25 00:50:38 [INFO]: Epoch 229 - training loss: 9208.7927, validation loss: 0.0844
2024-05-25 00:50:38 [INFO]: Epoch 230 - training loss: 9209.1533, validation loss: 0.0834
2024-05-25 00:50:38 [INFO]: Epoch 231 - training loss: 9210.1137, validation loss: 0.0865
2024-05-25 00:50:39 [INFO]: Epoch 232 - training loss: 9208.9556, validation loss: 0.0817
2024-05-25 00:50:39 [INFO]: Epoch 233 - training loss: 9209.6446, validation loss: 0.0847
2024-05-25 00:50:39 [INFO]: Epoch 234 - training loss: 9208.1166, validation loss: 0.0825
2024-05-25 00:50:39 [INFO]: Epoch 235 - training loss: 9208.0333, validation loss: 0.0848
2024-05-25 00:50:39 [INFO]: Epoch 236 - training loss: 9205.3885, validation loss: 0.0836
2024-05-25 00:50:39 [INFO]: Epoch 237 - training loss: 9208.2508, validation loss: 0.0820
2024-05-25 00:50:39 [INFO]: Epoch 238 - training loss: 9209.6890, validation loss: 0.0830
2024-05-25 00:50:39 [INFO]: Epoch 239 - training loss: 9209.8925, validation loss: 0.0829
2024-05-25 00:50:40 [INFO]: Epoch 240 - training loss: 9209.2684, validation loss: 0.0841
2024-05-25 00:50:40 [INFO]: Epoch 241 - training loss: 9206.2689, validation loss: 0.0801
2024-05-25 00:50:40 [INFO]: Epoch 242 - training loss: 9207.6564, validation loss: 0.0834
2024-05-25 00:50:40 [INFO]: Epoch 243 - training loss: 9208.1627, validation loss: 0.0831
2024-05-25 00:50:40 [INFO]: Epoch 244 - training loss: 9208.7338, validation loss: 0.0828
2024-05-25 00:50:40 [INFO]: Epoch 245 - training loss: 9207.9139, validation loss: 0.0842
2024-05-25 00:50:40 [INFO]: Epoch 246 - training loss: 9206.7644, validation loss: 0.0831
2024-05-25 00:50:40 [INFO]: Epoch 247 - training loss: 9209.5385, validation loss: 0.0832
2024-05-25 00:50:41 [INFO]: Epoch 248 - training loss: 9207.3553, validation loss: 0.0816
2024-05-25 00:50:41 [INFO]: Epoch 249 - training loss: 9207.4778, validation loss: 0.0851
2024-05-25 00:50:41 [INFO]: Epoch 250 - training loss: 9209.2593, validation loss: 0.0820
2024-05-25 00:50:41 [INFO]: Epoch 251 - training loss: 9208.6267, validation loss: 0.0807
2024-05-25 00:50:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:50:41 [INFO]: Finished training. The best model is from epoch#241.
2024-05-25 00:50:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/GPVAE_ettm1/20240525_T005010/GPVAE.pypots
2024-05-25 00:50:41 [INFO]: GP-VAE on ETTm1: MAE=0.2837, MSE=0.1720
2024-05-25 00:50:41 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 00:50:41 [INFO]: Using the given device: cuda:0
2024-05-25 00:50:41 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T005041
2024-05-25 00:50:41 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T005041/tensorboard
2024-05-25 00:50:41 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 00:50:51 [INFO]: Epoch 001 - generator training loss: 0.4617, discriminator training loss: 0.5451, validation loss: 0.3282
2024-05-25 00:51:00 [INFO]: Epoch 002 - generator training loss: -0.0433, discriminator training loss: 0.4756, validation loss: 0.1509
2024-05-25 00:51:08 [INFO]: Epoch 003 - generator training loss: -0.1515, discriminator training loss: 0.4324, validation loss: 0.0796
2024-05-25 00:51:17 [INFO]: Epoch 004 - generator training loss: -0.1481, discriminator training loss: 0.3719, validation loss: 0.0602
2024-05-25 00:51:26 [INFO]: Epoch 005 - generator training loss: -0.1074, discriminator training loss: 0.2959, validation loss: 0.0498
2024-05-25 00:51:34 [INFO]: Epoch 006 - generator training loss: -0.0754, discriminator training loss: 0.2334, validation loss: 0.0464
2024-05-25 00:51:43 [INFO]: Epoch 007 - generator training loss: -0.0580, discriminator training loss: 0.2002, validation loss: 0.0441
2024-05-25 00:51:51 [INFO]: Epoch 008 - generator training loss: -0.0532, discriminator training loss: 0.1849, validation loss: 0.0408
2024-05-25 00:52:00 [INFO]: Epoch 009 - generator training loss: -0.0514, discriminator training loss: 0.1806, validation loss: 0.0402
2024-05-25 00:52:09 [INFO]: Epoch 010 - generator training loss: -0.0578, discriminator training loss: 0.1770, validation loss: 0.0389
2024-05-25 00:52:17 [INFO]: Epoch 011 - generator training loss: -0.0568, discriminator training loss: 0.1757, validation loss: 0.0377
2024-05-25 00:52:26 [INFO]: Epoch 012 - generator training loss: -0.0521, discriminator training loss: 0.1733, validation loss: 0.0370
2024-05-25 00:52:34 [INFO]: Epoch 013 - generator training loss: -0.0602, discriminator training loss: 0.1753, validation loss: 0.0363
2024-05-25 00:52:43 [INFO]: Epoch 014 - generator training loss: -0.0564, discriminator training loss: 0.1735, validation loss: 0.0356
2024-05-25 00:52:52 [INFO]: Epoch 015 - generator training loss: -0.0596, discriminator training loss: 0.1708, validation loss: 0.0353
2024-05-25 00:53:00 [INFO]: Epoch 016 - generator training loss: -0.0601, discriminator training loss: 0.1699, validation loss: 0.0355
2024-05-25 00:53:09 [INFO]: Epoch 017 - generator training loss: -0.0613, discriminator training loss: 0.1723, validation loss: 0.0355
2024-05-25 00:53:17 [INFO]: Epoch 018 - generator training loss: -0.0615, discriminator training loss: 0.1714, validation loss: 0.0343
2024-05-25 00:53:26 [INFO]: Epoch 019 - generator training loss: -0.0589, discriminator training loss: 0.1693, validation loss: 0.0341
2024-05-25 00:53:35 [INFO]: Epoch 020 - generator training loss: -0.0616, discriminator training loss: 0.1718, validation loss: 0.0345
2024-05-25 00:53:44 [INFO]: Epoch 021 - generator training loss: -0.0567, discriminator training loss: 0.1713, validation loss: 0.0342
2024-05-25 00:53:52 [INFO]: Epoch 022 - generator training loss: -0.0606, discriminator training loss: 0.1714, validation loss: 0.0364
2024-05-25 00:54:01 [INFO]: Epoch 023 - generator training loss: -0.0587, discriminator training loss: 0.1686, validation loss: 0.0343
2024-05-25 00:54:09 [INFO]: Epoch 024 - generator training loss: -0.0570, discriminator training loss: 0.1699, validation loss: 0.0342
2024-05-25 00:54:18 [INFO]: Epoch 025 - generator training loss: -0.0598, discriminator training loss: 0.1671, validation loss: 0.0333
2024-05-25 00:54:26 [INFO]: Epoch 026 - generator training loss: -0.0613, discriminator training loss: 0.1719, validation loss: 0.0329
2024-05-25 00:54:35 [INFO]: Epoch 027 - generator training loss: -0.0590, discriminator training loss: 0.1697, validation loss: 0.0327
2024-05-25 00:54:44 [INFO]: Epoch 028 - generator training loss: -0.0623, discriminator training loss: 0.1693, validation loss: 0.0328
2024-05-25 00:54:52 [INFO]: Epoch 029 - generator training loss: -0.0609, discriminator training loss: 0.1684, validation loss: 0.0330
2024-05-25 00:55:01 [INFO]: Epoch 030 - generator training loss: -0.0583, discriminator training loss: 0.1697, validation loss: 0.0326
2024-05-25 00:55:09 [INFO]: Epoch 031 - generator training loss: -0.0631, discriminator training loss: 0.1664, validation loss: 0.0320
2024-05-25 00:55:18 [INFO]: Epoch 032 - generator training loss: -0.0625, discriminator training loss: 0.1665, validation loss: 0.0324
2024-05-25 00:55:26 [INFO]: Epoch 033 - generator training loss: -0.0634, discriminator training loss: 0.1665, validation loss: 0.0324
2024-05-25 00:55:35 [INFO]: Epoch 034 - generator training loss: -0.0663, discriminator training loss: 0.1654, validation loss: 0.0317
2024-05-25 00:55:44 [INFO]: Epoch 035 - generator training loss: -0.0638, discriminator training loss: 0.1675, validation loss: 0.0322
2024-05-25 00:55:52 [INFO]: Epoch 036 - generator training loss: -0.0660, discriminator training loss: 0.1673, validation loss: 0.0313
2024-05-25 00:56:01 [INFO]: Epoch 037 - generator training loss: -0.0659, discriminator training loss: 0.1647, validation loss: 0.0315
2024-05-25 00:56:10 [INFO]: Epoch 038 - generator training loss: -0.0632, discriminator training loss: 0.1666, validation loss: 0.0309
2024-05-25 00:56:19 [INFO]: Epoch 039 - generator training loss: -0.0651, discriminator training loss: 0.1672, validation loss: 0.0313
2024-05-25 00:56:27 [INFO]: Epoch 040 - generator training loss: -0.0632, discriminator training loss: 0.1652, validation loss: 0.0309
2024-05-25 00:56:36 [INFO]: Epoch 041 - generator training loss: -0.0685, discriminator training loss: 0.1685, validation loss: 0.0308
2024-05-25 00:56:45 [INFO]: Epoch 042 - generator training loss: -0.0638, discriminator training loss: 0.1668, validation loss: 0.0309
2024-05-25 00:56:54 [INFO]: Epoch 043 - generator training loss: -0.0646, discriminator training loss: 0.1657, validation loss: 0.0305
2024-05-25 00:57:03 [INFO]: Epoch 044 - generator training loss: -0.0648, discriminator training loss: 0.1665, validation loss: 0.0302
2024-05-25 00:57:11 [INFO]: Epoch 045 - generator training loss: -0.0669, discriminator training loss: 0.1639, validation loss: 0.0300
2024-05-25 00:57:20 [INFO]: Epoch 046 - generator training loss: -0.0700, discriminator training loss: 0.1674, validation loss: 0.0296
2024-05-25 00:57:29 [INFO]: Epoch 047 - generator training loss: -0.0661, discriminator training loss: 0.1682, validation loss: 0.0295
2024-05-25 00:57:38 [INFO]: Epoch 048 - generator training loss: -0.0674, discriminator training loss: 0.1664, validation loss: 0.0298
2024-05-25 00:57:47 [INFO]: Epoch 049 - generator training loss: -0.0668, discriminator training loss: 0.1672, validation loss: 0.0291
2024-05-25 00:57:55 [INFO]: Epoch 050 - generator training loss: -0.0617, discriminator training loss: 0.1690, validation loss: 0.0302
2024-05-25 00:58:04 [INFO]: Epoch 051 - generator training loss: -0.0662, discriminator training loss: 0.1655, validation loss: 0.0296
2024-05-25 00:58:13 [INFO]: Epoch 052 - generator training loss: -0.0677, discriminator training loss: 0.1669, validation loss: 0.0289
2024-05-25 00:58:22 [INFO]: Epoch 053 - generator training loss: -0.0676, discriminator training loss: 0.1646, validation loss: 0.0309
2024-05-25 00:58:30 [INFO]: Epoch 054 - generator training loss: -0.0655, discriminator training loss: 0.1654, validation loss: 0.0296
2024-05-25 00:58:39 [INFO]: Epoch 055 - generator training loss: -0.0683, discriminator training loss: 0.1645, validation loss: 0.0297
2024-05-25 00:58:48 [INFO]: Epoch 056 - generator training loss: -0.0663, discriminator training loss: 0.1656, validation loss: 0.0282
2024-05-25 00:58:57 [INFO]: Epoch 057 - generator training loss: -0.0667, discriminator training loss: 0.1666, validation loss: 0.0291
2024-05-25 00:59:06 [INFO]: Epoch 058 - generator training loss: -0.0679, discriminator training loss: 0.1641, validation loss: 0.0286
2024-05-25 00:59:15 [INFO]: Epoch 059 - generator training loss: -0.0696, discriminator training loss: 0.1660, validation loss: 0.0283
2024-05-25 00:59:23 [INFO]: Epoch 060 - generator training loss: -0.0656, discriminator training loss: 0.1645, validation loss: 0.0283
2024-05-25 00:59:32 [INFO]: Epoch 061 - generator training loss: -0.0692, discriminator training loss: 0.1649, validation loss: 0.0283
2024-05-25 00:59:41 [INFO]: Epoch 062 - generator training loss: -0.0660, discriminator training loss: 0.1633, validation loss: 0.0280
2024-05-25 00:59:50 [INFO]: Epoch 063 - generator training loss: -0.0677, discriminator training loss: 0.1633, validation loss: 0.0284
2024-05-25 00:59:59 [INFO]: Epoch 064 - generator training loss: -0.0689, discriminator training loss: 0.1643, validation loss: 0.0278
2024-05-25 01:00:08 [INFO]: Epoch 065 - generator training loss: -0.0697, discriminator training loss: 0.1653, validation loss: 0.0281
2024-05-25 01:00:17 [INFO]: Epoch 066 - generator training loss: -0.0702, discriminator training loss: 0.1633, validation loss: 0.0276
2024-05-25 01:00:26 [INFO]: Epoch 067 - generator training loss: -0.0692, discriminator training loss: 0.1654, validation loss: 0.0275
2024-05-25 01:00:35 [INFO]: Epoch 068 - generator training loss: -0.0687, discriminator training loss: 0.1644, validation loss: 0.0273
2024-05-25 01:00:44 [INFO]: Epoch 069 - generator training loss: -0.0689, discriminator training loss: 0.1634, validation loss: 0.0281
2024-05-25 01:00:53 [INFO]: Epoch 070 - generator training loss: -0.0708, discriminator training loss: 0.1626, validation loss: 0.0275
2024-05-25 01:01:02 [INFO]: Epoch 071 - generator training loss: -0.0698, discriminator training loss: 0.1639, validation loss: 0.0299
2024-05-25 01:01:11 [INFO]: Epoch 072 - generator training loss: -0.0686, discriminator training loss: 0.1628, validation loss: 0.0292
2024-05-25 01:01:19 [INFO]: Epoch 073 - generator training loss: -0.0680, discriminator training loss: 0.1638, validation loss: 0.0273
2024-05-25 01:01:28 [INFO]: Epoch 074 - generator training loss: -0.0726, discriminator training loss: 0.1649, validation loss: 0.0278
2024-05-25 01:01:37 [INFO]: Epoch 075 - generator training loss: -0.0699, discriminator training loss: 0.1638, validation loss: 0.0270
2024-05-25 01:01:46 [INFO]: Epoch 076 - generator training loss: -0.0696, discriminator training loss: 0.1629, validation loss: 0.0275
2024-05-25 01:01:55 [INFO]: Epoch 077 - generator training loss: -0.0738, discriminator training loss: 0.1626, validation loss: 0.0276
2024-05-25 01:02:04 [INFO]: Epoch 078 - generator training loss: -0.0667, discriminator training loss: 0.1633, validation loss: 0.0279
2024-05-25 01:02:13 [INFO]: Epoch 079 - generator training loss: -0.0723, discriminator training loss: 0.1601, validation loss: 0.0274
2024-05-25 01:02:22 [INFO]: Epoch 080 - generator training loss: -0.0665, discriminator training loss: 0.1651, validation loss: 0.0275
2024-05-25 01:02:30 [INFO]: Epoch 081 - generator training loss: -0.0675, discriminator training loss: 0.1635, validation loss: 0.0272
2024-05-25 01:02:39 [INFO]: Epoch 082 - generator training loss: -0.0709, discriminator training loss: 0.1605, validation loss: 0.0260
2024-05-25 01:02:48 [INFO]: Epoch 083 - generator training loss: -0.0675, discriminator training loss: 0.1624, validation loss: 0.0299
2024-05-25 01:02:57 [INFO]: Epoch 084 - generator training loss: -0.0702, discriminator training loss: 0.1627, validation loss: 0.0276
2024-05-25 01:03:06 [INFO]: Epoch 085 - generator training loss: -0.0695, discriminator training loss: 0.1606, validation loss: 0.0264
2024-05-25 01:03:15 [INFO]: Epoch 086 - generator training loss: -0.0740, discriminator training loss: 0.1620, validation loss: 0.0272
2024-05-25 01:03:24 [INFO]: Epoch 087 - generator training loss: -0.0705, discriminator training loss: 0.1621, validation loss: 0.0260
2024-05-25 01:03:32 [INFO]: Epoch 088 - generator training loss: -0.0728, discriminator training loss: 0.1631, validation loss: 0.0260
2024-05-25 01:03:41 [INFO]: Epoch 089 - generator training loss: -0.0695, discriminator training loss: 0.1608, validation loss: 0.0255
2024-05-25 01:03:50 [INFO]: Epoch 090 - generator training loss: -0.0722, discriminator training loss: 0.1597, validation loss: 0.0258
2024-05-25 01:03:59 [INFO]: Epoch 091 - generator training loss: -0.0709, discriminator training loss: 0.1614, validation loss: 0.0258
2024-05-25 01:04:08 [INFO]: Epoch 092 - generator training loss: -0.0692, discriminator training loss: 0.1614, validation loss: 0.0261
2024-05-25 01:04:16 [INFO]: Epoch 093 - generator training loss: -0.0738, discriminator training loss: 0.1602, validation loss: 0.0258
2024-05-25 01:04:25 [INFO]: Epoch 094 - generator training loss: -0.0683, discriminator training loss: 0.1601, validation loss: 0.0253
2024-05-25 01:04:34 [INFO]: Epoch 095 - generator training loss: -0.0749, discriminator training loss: 0.1632, validation loss: 0.0264
2024-05-25 01:04:43 [INFO]: Epoch 096 - generator training loss: -0.0705, discriminator training loss: 0.1614, validation loss: 0.0254
2024-05-25 01:04:51 [INFO]: Epoch 097 - generator training loss: -0.0714, discriminator training loss: 0.1593, validation loss: 0.0245
2024-05-25 01:05:00 [INFO]: Epoch 098 - generator training loss: -0.0722, discriminator training loss: 0.1602, validation loss: 0.0247
2024-05-25 01:05:09 [INFO]: Epoch 099 - generator training loss: -0.0709, discriminator training loss: 0.1600, validation loss: 0.0251
2024-05-25 01:05:18 [INFO]: Epoch 100 - generator training loss: -0.0703, discriminator training loss: 0.1586, validation loss: 0.0249
2024-05-25 01:05:27 [INFO]: Epoch 101 - generator training loss: -0.0725, discriminator training loss: 0.1581, validation loss: 0.0244
2024-05-25 01:05:36 [INFO]: Epoch 102 - generator training loss: -0.0695, discriminator training loss: 0.1606, validation loss: 0.0250
2024-05-25 01:05:45 [INFO]: Epoch 103 - generator training loss: -0.0709, discriminator training loss: 0.1590, validation loss: 0.0241
2024-05-25 01:05:53 [INFO]: Epoch 104 - generator training loss: -0.0734, discriminator training loss: 0.1583, validation loss: 0.0239
2024-05-25 01:06:02 [INFO]: Epoch 105 - generator training loss: -0.0716, discriminator training loss: 0.1590, validation loss: 0.0238
2024-05-25 01:06:11 [INFO]: Epoch 106 - generator training loss: -0.0735, discriminator training loss: 0.1582, validation loss: 0.0238
2024-05-25 01:06:20 [INFO]: Epoch 107 - generator training loss: -0.0734, discriminator training loss: 0.1586, validation loss: 0.0243
2024-05-25 01:06:29 [INFO]: Epoch 108 - generator training loss: -0.0724, discriminator training loss: 0.1587, validation loss: 0.0240
2024-05-25 01:06:38 [INFO]: Epoch 109 - generator training loss: -0.0716, discriminator training loss: 0.1596, validation loss: 0.0246
2024-05-25 01:06:46 [INFO]: Epoch 110 - generator training loss: -0.0703, discriminator training loss: 0.1595, validation loss: 0.0260
2024-05-25 01:06:55 [INFO]: Epoch 111 - generator training loss: -0.0705, discriminator training loss: 0.1577, validation loss: 0.0245
2024-05-25 01:07:04 [INFO]: Epoch 112 - generator training loss: -0.0727, discriminator training loss: 0.1575, validation loss: 0.0236
2024-05-25 01:07:13 [INFO]: Epoch 113 - generator training loss: -0.0723, discriminator training loss: 0.1588, validation loss: 0.0251
2024-05-25 01:07:22 [INFO]: Epoch 114 - generator training loss: -0.0694, discriminator training loss: 0.1578, validation loss: 0.0242
2024-05-25 01:07:30 [INFO]: Epoch 115 - generator training loss: -0.0699, discriminator training loss: 0.1564, validation loss: 0.0245
2024-05-25 01:07:39 [INFO]: Epoch 116 - generator training loss: -0.0740, discriminator training loss: 0.1561, validation loss: 0.0243
2024-05-25 01:07:48 [INFO]: Epoch 117 - generator training loss: -0.0725, discriminator training loss: 0.1590, validation loss: 0.0248
2024-05-25 01:07:57 [INFO]: Epoch 118 - generator training loss: -0.0742, discriminator training loss: 0.1592, validation loss: 0.0238
2024-05-25 01:08:06 [INFO]: Epoch 119 - generator training loss: -0.0734, discriminator training loss: 0.1580, validation loss: 0.0238
2024-05-25 01:08:14 [INFO]: Epoch 120 - generator training loss: -0.0712, discriminator training loss: 0.1575, validation loss: 0.0240
2024-05-25 01:08:23 [INFO]: Epoch 121 - generator training loss: -0.0708, discriminator training loss: 0.1571, validation loss: 0.0270
2024-05-25 01:08:32 [INFO]: Epoch 122 - generator training loss: -0.0700, discriminator training loss: 0.1574, validation loss: 0.0258
2024-05-25 01:08:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:08:32 [INFO]: Finished training. The best model is from epoch#112.
2024-05-25 01:08:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/USGAN_ettm1/20240525_T005041/USGAN.pypots
2024-05-25 01:08:33 [INFO]: US-GAN on ETTm1: MAE=0.1697, MSE=0.0730
2024-05-25 01:08:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 01:08:33 [INFO]: Using the given device: cuda:0
2024-05-25 01:08:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T010833
2024-05-25 01:08:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T010833/tensorboard
2024-05-25 01:08:33 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 01:08:41 [INFO]: Epoch 001 - training loss: 1.3164, validation loss: 0.3758
2024-05-25 01:08:47 [INFO]: Epoch 002 - training loss: 0.8999, validation loss: 0.1176
2024-05-25 01:08:52 [INFO]: Epoch 003 - training loss: 0.7329, validation loss: 0.0622
2024-05-25 01:08:58 [INFO]: Epoch 004 - training loss: 0.6769, validation loss: 0.0517
2024-05-25 01:09:04 [INFO]: Epoch 005 - training loss: 0.6125, validation loss: 0.0491
2024-05-25 01:09:10 [INFO]: Epoch 006 - training loss: 0.5691, validation loss: 0.0423
2024-05-25 01:09:16 [INFO]: Epoch 007 - training loss: 0.5414, validation loss: 0.0387
2024-05-25 01:09:22 [INFO]: Epoch 008 - training loss: 0.5163, validation loss: 0.0363
2024-05-25 01:09:27 [INFO]: Epoch 009 - training loss: 0.4932, validation loss: 0.0350
2024-05-25 01:09:33 [INFO]: Epoch 010 - training loss: 0.4760, validation loss: 0.0340
2024-05-25 01:09:39 [INFO]: Epoch 011 - training loss: 0.4513, validation loss: 0.0321
2024-05-25 01:09:45 [INFO]: Epoch 012 - training loss: 0.4390, validation loss: 0.0302
2024-05-25 01:09:51 [INFO]: Epoch 013 - training loss: 0.4325, validation loss: 0.0296
2024-05-25 01:09:57 [INFO]: Epoch 014 - training loss: 0.4289, validation loss: 0.0299
2024-05-25 01:10:03 [INFO]: Epoch 015 - training loss: 0.4207, validation loss: 0.0299
2024-05-25 01:10:09 [INFO]: Epoch 016 - training loss: 0.4242, validation loss: 0.0284
2024-05-25 01:10:14 [INFO]: Epoch 017 - training loss: 0.4123, validation loss: 0.0281
2024-05-25 01:10:20 [INFO]: Epoch 018 - training loss: 0.4074, validation loss: 0.0274
2024-05-25 01:10:26 [INFO]: Epoch 019 - training loss: 0.4056, validation loss: 0.0277
2024-05-25 01:10:32 [INFO]: Epoch 020 - training loss: 0.4063, validation loss: 0.0277
2024-05-25 01:10:38 [INFO]: Epoch 021 - training loss: 0.4098, validation loss: 0.0270
2024-05-25 01:10:44 [INFO]: Epoch 022 - training loss: 0.3996, validation loss: 0.0268
2024-05-25 01:10:50 [INFO]: Epoch 023 - training loss: 0.3990, validation loss: 0.0269
2024-05-25 01:10:55 [INFO]: Epoch 024 - training loss: 0.4016, validation loss: 0.0270
2024-05-25 01:11:01 [INFO]: Epoch 025 - training loss: 0.4000, validation loss: 0.0270
2024-05-25 01:11:07 [INFO]: Epoch 026 - training loss: 0.4153, validation loss: 0.0277
2024-05-25 01:11:13 [INFO]: Epoch 027 - training loss: 0.4086, validation loss: 0.0290
2024-05-25 01:11:19 [INFO]: Epoch 028 - training loss: 0.4417, validation loss: 0.0286
2024-05-25 01:11:25 [INFO]: Epoch 029 - training loss: 0.4119, validation loss: 0.0276
2024-05-25 01:11:31 [INFO]: Epoch 030 - training loss: 0.4128, validation loss: 0.0276
2024-05-25 01:11:37 [INFO]: Epoch 031 - training loss: 0.4063, validation loss: 0.0269
2024-05-25 01:11:43 [INFO]: Epoch 032 - training loss: 0.4129, validation loss: 0.0267
2024-05-25 01:11:49 [INFO]: Epoch 033 - training loss: 0.4039, validation loss: 0.0271
2024-05-25 01:11:55 [INFO]: Epoch 034 - training loss: 0.3977, validation loss: 0.0265
2024-05-25 01:12:01 [INFO]: Epoch 035 - training loss: 0.3951, validation loss: 0.0267
2024-05-25 01:12:07 [INFO]: Epoch 036 - training loss: 0.4033, validation loss: 0.0275
2024-05-25 01:12:13 [INFO]: Epoch 037 - training loss: 0.3940, validation loss: 0.0352
2024-05-25 01:12:18 [INFO]: Epoch 038 - training loss: 0.4169, validation loss: 0.0290
2024-05-25 01:12:24 [INFO]: Epoch 039 - training loss: 0.4058, validation loss: 0.0268
2024-05-25 01:12:30 [INFO]: Epoch 040 - training loss: 0.3963, validation loss: 0.0268
2024-05-25 01:12:36 [INFO]: Epoch 041 - training loss: 0.4041, validation loss: 0.0267
2024-05-25 01:12:42 [INFO]: Epoch 042 - training loss: 0.3934, validation loss: 0.0264
2024-05-25 01:12:48 [INFO]: Epoch 043 - training loss: 0.3971, validation loss: 0.0262
2024-05-25 01:12:54 [INFO]: Epoch 044 - training loss: 0.3911, validation loss: 0.0268
2024-05-25 01:13:00 [INFO]: Epoch 045 - training loss: 0.4051, validation loss: 0.0262
2024-05-25 01:13:06 [INFO]: Epoch 046 - training loss: 0.4039, validation loss: 0.0263
2024-05-25 01:13:12 [INFO]: Epoch 047 - training loss: 0.3919, validation loss: 0.0265
2024-05-25 01:13:18 [INFO]: Epoch 048 - training loss: 0.3937, validation loss: 0.0262
2024-05-25 01:13:24 [INFO]: Epoch 049 - training loss: 0.3886, validation loss: 0.0263
2024-05-25 01:13:29 [INFO]: Epoch 050 - training loss: 0.3902, validation loss: 0.0264
2024-05-25 01:13:35 [INFO]: Epoch 051 - training loss: 0.3892, validation loss: 0.0264
2024-05-25 01:13:41 [INFO]: Epoch 052 - training loss: 0.3938, validation loss: 0.0272
2024-05-25 01:13:47 [INFO]: Epoch 053 - training loss: 0.3878, validation loss: 0.0258
2024-05-25 01:13:53 [INFO]: Epoch 054 - training loss: 0.3884, validation loss: 0.0263
2024-05-25 01:13:59 [INFO]: Epoch 055 - training loss: 0.3857, validation loss: 0.0273
2024-05-25 01:14:05 [INFO]: Epoch 056 - training loss: 0.4159, validation loss: 0.0275
2024-05-25 01:14:11 [INFO]: Epoch 057 - training loss: 0.3941, validation loss: 0.0271
2024-05-25 01:14:17 [INFO]: Epoch 058 - training loss: 0.4208, validation loss: 0.0292
2024-05-25 01:14:23 [INFO]: Epoch 059 - training loss: 0.4025, validation loss: 0.0280
2024-05-25 01:14:29 [INFO]: Epoch 060 - training loss: 0.3962, validation loss: 0.0268
2024-05-25 01:14:35 [INFO]: Epoch 061 - training loss: 0.3919, validation loss: 0.0269
2024-05-25 01:14:40 [INFO]: Epoch 062 - training loss: 0.4000, validation loss: 0.0263
2024-05-25 01:14:46 [INFO]: Epoch 063 - training loss: 0.3978, validation loss: 0.0268
2024-05-25 01:14:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:14:46 [INFO]: Finished training. The best model is from epoch#53.
2024-05-25 01:14:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/BRITS_ettm1/20240525_T010833/BRITS.pypots
2024-05-25 01:14:47 [INFO]: BRITS on ETTm1: MAE=0.1417, MSE=0.0583
2024-05-25 01:14:47 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 01:14:47 [INFO]: Using the given device: cuda:0
2024-05-25 01:14:47 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447
2024-05-25 01:14:47 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/tensorboard
2024-05-25 01:14:47 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 01:14:49 [INFO]: Epoch 001 - training loss: 1.2850, validation loss: 1.1688
2024-05-25 01:14:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch1_loss1.1687687188386917.pypots
2024-05-25 01:14:49 [INFO]: Epoch 002 - training loss: 0.9429, validation loss: 1.0536
2024-05-25 01:14:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch2_loss1.0536000281572342.pypots
2024-05-25 01:14:50 [INFO]: Epoch 003 - training loss: 0.9136, validation loss: 1.0141
2024-05-25 01:14:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch3_loss1.0140884816646576.pypots
2024-05-25 01:14:50 [INFO]: Epoch 004 - training loss: 0.8914, validation loss: 1.0002
2024-05-25 01:14:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch4_loss1.0001612305641174.pypots
2024-05-25 01:14:50 [INFO]: Epoch 005 - training loss: 0.8837, validation loss: 0.9882
2024-05-25 01:14:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch5_loss0.9881964772939682.pypots
2024-05-25 01:14:50 [INFO]: Epoch 006 - training loss: 0.8876, validation loss: 0.9834
2024-05-25 01:14:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch6_loss0.9833621978759766.pypots
2024-05-25 01:14:50 [INFO]: Epoch 007 - training loss: 0.8953, validation loss: 0.9789
2024-05-25 01:14:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch7_loss0.9788541793823242.pypots
2024-05-25 01:14:51 [INFO]: Epoch 008 - training loss: 0.8775, validation loss: 0.9758
2024-05-25 01:14:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch8_loss0.9757625460624695.pypots
2024-05-25 01:14:51 [INFO]: Epoch 009 - training loss: 0.8816, validation loss: 0.9730
2024-05-25 01:14:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch9_loss0.9729700684547424.pypots
2024-05-25 01:14:51 [INFO]: Epoch 010 - training loss: 0.8805, validation loss: 0.9735
2024-05-25 01:14:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch10_loss0.9734962433576584.pypots
2024-05-25 01:14:51 [INFO]: Epoch 011 - training loss: 0.8883, validation loss: 0.9704
2024-05-25 01:14:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch11_loss0.9704097509384155.pypots
2024-05-25 01:14:51 [INFO]: Epoch 012 - training loss: 0.8331, validation loss: 0.9682
2024-05-25 01:14:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch12_loss0.9682390689849854.pypots
2024-05-25 01:14:52 [INFO]: Epoch 013 - training loss: 0.8354, validation loss: 0.9678
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch13_loss0.9677768647670746.pypots
2024-05-25 01:14:52 [INFO]: Epoch 014 - training loss: 0.8159, validation loss: 0.9689
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch14_loss0.9688917100429535.pypots
2024-05-25 01:14:52 [INFO]: Epoch 015 - training loss: 0.8075, validation loss: 0.9678
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch15_loss0.9677699953317642.pypots
2024-05-25 01:14:52 [INFO]: Epoch 016 - training loss: 0.8108, validation loss: 0.9670
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch16_loss0.967043936252594.pypots
2024-05-25 01:14:52 [INFO]: Epoch 017 - training loss: 0.7967, validation loss: 0.9647
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch17_loss0.9647485762834549.pypots
2024-05-25 01:14:52 [INFO]: Epoch 018 - training loss: 0.8311, validation loss: 0.9636
2024-05-25 01:14:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch18_loss0.9636149704456329.pypots
2024-05-25 01:14:53 [INFO]: Epoch 019 - training loss: 0.7957, validation loss: 0.9663
2024-05-25 01:14:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch19_loss0.9663159251213074.pypots
2024-05-25 01:14:53 [INFO]: Epoch 020 - training loss: 0.8813, validation loss: 0.9651
2024-05-25 01:14:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch20_loss0.9650847464799881.pypots
2024-05-25 01:14:53 [INFO]: Epoch 021 - training loss: 0.8201, validation loss: 0.9644
2024-05-25 01:14:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch21_loss0.9644119590520859.pypots
2024-05-25 01:14:53 [INFO]: Epoch 022 - training loss: 0.7982, validation loss: 0.9681
2024-05-25 01:14:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch22_loss0.9681060612201691.pypots
2024-05-25 01:14:53 [INFO]: Epoch 023 - training loss: 0.8159, validation loss: 0.9631
2024-05-25 01:14:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch23_loss0.9631134867668152.pypots
2024-05-25 01:14:54 [INFO]: Epoch 024 - training loss: 0.7930, validation loss: 0.9596
2024-05-25 01:14:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch24_loss0.9595563560724258.pypots
2024-05-25 01:14:54 [INFO]: Epoch 025 - training loss: 0.7981, validation loss: 0.9602
2024-05-25 01:14:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch25_loss0.9602246135473251.pypots
2024-05-25 01:14:54 [INFO]: Epoch 026 - training loss: 0.7823, validation loss: 0.9574
2024-05-25 01:14:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch26_loss0.9574364274740219.pypots
2024-05-25 01:14:54 [INFO]: Epoch 027 - training loss: 0.7844, validation loss: 0.9540
2024-05-25 01:14:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch27_loss0.9539829790592194.pypots
2024-05-25 01:14:54 [INFO]: Epoch 028 - training loss: 0.7952, validation loss: 0.9554
2024-05-25 01:14:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch28_loss0.9553659856319427.pypots
2024-05-25 01:14:55 [INFO]: Epoch 029 - training loss: 0.7725, validation loss: 0.9528
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch29_loss0.9527704268693924.pypots
2024-05-25 01:14:55 [INFO]: Epoch 030 - training loss: 0.7885, validation loss: 0.9493
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch30_loss0.9492534846067429.pypots
2024-05-25 01:14:55 [INFO]: Epoch 031 - training loss: 0.7981, validation loss: 0.9525
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch31_loss0.9524606019258499.pypots
2024-05-25 01:14:55 [INFO]: Epoch 032 - training loss: 0.7595, validation loss: 0.9455
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch32_loss0.9455410987138748.pypots
2024-05-25 01:14:55 [INFO]: Epoch 033 - training loss: 0.7753, validation loss: 0.9426
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch33_loss0.9426025450229645.pypots
2024-05-25 01:14:55 [INFO]: Epoch 034 - training loss: 0.7654, validation loss: 0.9402
2024-05-25 01:14:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch34_loss0.9402037560939789.pypots
2024-05-25 01:14:56 [INFO]: Epoch 035 - training loss: 0.7695, validation loss: 0.9387
2024-05-25 01:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch35_loss0.9387107640504837.pypots
2024-05-25 01:14:56 [INFO]: Epoch 036 - training loss: 0.7521, validation loss: 0.9379
2024-05-25 01:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch36_loss0.9379031658172607.pypots
2024-05-25 01:14:56 [INFO]: Epoch 037 - training loss: 0.7408, validation loss: 0.9375
2024-05-25 01:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch37_loss0.9375274330377579.pypots
2024-05-25 01:14:56 [INFO]: Epoch 038 - training loss: 0.8043, validation loss: 0.9383
2024-05-25 01:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch38_loss0.938300833106041.pypots
2024-05-25 01:14:56 [INFO]: Epoch 039 - training loss: 0.7518, validation loss: 0.9364
2024-05-25 01:14:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch39_loss0.9363884925842285.pypots
2024-05-25 01:14:57 [INFO]: Epoch 040 - training loss: 0.7590, validation loss: 0.9366
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch40_loss0.9366233795881271.pypots
2024-05-25 01:14:57 [INFO]: Epoch 041 - training loss: 0.7660, validation loss: 0.9342
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch41_loss0.9341510087251663.pypots
2024-05-25 01:14:57 [INFO]: Epoch 042 - training loss: 0.7420, validation loss: 0.9264
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch42_loss0.9263668805360794.pypots
2024-05-25 01:14:57 [INFO]: Epoch 043 - training loss: 0.7596, validation loss: 0.9257
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch43_loss0.9256972968578339.pypots
2024-05-25 01:14:57 [INFO]: Epoch 044 - training loss: 0.7724, validation loss: 0.9275
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch44_loss0.9275367558002472.pypots
2024-05-25 01:14:57 [INFO]: Epoch 045 - training loss: 0.7710, validation loss: 0.9229
2024-05-25 01:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch45_loss0.9229239821434021.pypots
2024-05-25 01:14:58 [INFO]: Epoch 046 - training loss: 0.7459, validation loss: 0.9221
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch46_loss0.9220781028270721.pypots
2024-05-25 01:14:58 [INFO]: Epoch 047 - training loss: 0.7706, validation loss: 0.9134
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch47_loss0.9134120047092438.pypots
2024-05-25 01:14:58 [INFO]: Epoch 048 - training loss: 0.7575, validation loss: 0.9204
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch48_loss0.9204270988702774.pypots
2024-05-25 01:14:58 [INFO]: Epoch 049 - training loss: 0.7335, validation loss: 0.9148
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch49_loss0.9147980213165283.pypots
2024-05-25 01:14:58 [INFO]: Epoch 050 - training loss: 0.7857, validation loss: 0.9104
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch50_loss0.9104476124048233.pypots
2024-05-25 01:14:59 [INFO]: Epoch 051 - training loss: 0.7727, validation loss: 0.9090
2024-05-25 01:14:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch51_loss0.9090283662080765.pypots
2024-05-25 01:14:59 [INFO]: Epoch 052 - training loss: 0.7538, validation loss: 0.9080
2024-05-25 01:14:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch52_loss0.9079503864049911.pypots
2024-05-25 01:14:59 [INFO]: Epoch 053 - training loss: 0.7348, validation loss: 0.9067
2024-05-25 01:14:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch53_loss0.906737670302391.pypots
2024-05-25 01:14:59 [INFO]: Epoch 054 - training loss: 0.7462, validation loss: 0.9033
2024-05-25 01:14:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch54_loss0.9033085256814957.pypots
2024-05-25 01:14:59 [INFO]: Epoch 055 - training loss: 0.7417, validation loss: 0.9021
2024-05-25 01:14:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch55_loss0.902087926864624.pypots
2024-05-25 01:15:00 [INFO]: Epoch 056 - training loss: 0.7499, validation loss: 0.8999
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch56_loss0.8998703062534332.pypots
2024-05-25 01:15:00 [INFO]: Epoch 057 - training loss: 0.7261, validation loss: 0.9026
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch57_loss0.9025984555482864.pypots
2024-05-25 01:15:00 [INFO]: Epoch 058 - training loss: 0.7629, validation loss: 0.8999
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch58_loss0.8998700529336929.pypots
2024-05-25 01:15:00 [INFO]: Epoch 059 - training loss: 0.7293, validation loss: 0.9058
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch59_loss0.905751496553421.pypots
2024-05-25 01:15:00 [INFO]: Epoch 060 - training loss: 0.7562, validation loss: 0.8984
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch60_loss0.8984376788139343.pypots
2024-05-25 01:15:00 [INFO]: Epoch 061 - training loss: 0.7380, validation loss: 0.8998
2024-05-25 01:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch61_loss0.8997673690319061.pypots
2024-05-25 01:15:01 [INFO]: Epoch 062 - training loss: 0.7377, validation loss: 0.8979
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch62_loss0.8978735357522964.pypots
2024-05-25 01:15:01 [INFO]: Epoch 063 - training loss: 0.7370, validation loss: 0.8948
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch63_loss0.8948124945163727.pypots
2024-05-25 01:15:01 [INFO]: Epoch 064 - training loss: 0.7371, validation loss: 0.8975
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch64_loss0.8975343853235245.pypots
2024-05-25 01:15:01 [INFO]: Epoch 065 - training loss: 0.7385, validation loss: 0.8946
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch65_loss0.8946376740932465.pypots
2024-05-25 01:15:01 [INFO]: Epoch 066 - training loss: 0.7342, validation loss: 0.8904
2024-05-25 01:15:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch66_loss0.890412449836731.pypots
2024-05-25 01:15:02 [INFO]: Epoch 067 - training loss: 0.7273, validation loss: 0.8878
2024-05-25 01:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch67_loss0.8877620548009872.pypots
2024-05-25 01:15:02 [INFO]: Epoch 068 - training loss: 0.7504, validation loss: 0.8894
2024-05-25 01:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch68_loss0.8893647789955139.pypots
2024-05-25 01:15:02 [INFO]: Epoch 069 - training loss: 0.7200, validation loss: 0.8888
2024-05-25 01:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch69_loss0.8888231366872787.pypots
2024-05-25 01:15:02 [INFO]: Epoch 070 - training loss: 0.7501, validation loss: 0.8869
2024-05-25 01:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch70_loss0.8869286924600601.pypots
2024-05-25 01:15:02 [INFO]: Epoch 071 - training loss: 0.7336, validation loss: 0.8831
2024-05-25 01:15:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch71_loss0.8831061571836472.pypots
2024-05-25 01:15:03 [INFO]: Epoch 072 - training loss: 0.7219, validation loss: 0.8807
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch72_loss0.8806757032871246.pypots
2024-05-25 01:15:03 [INFO]: Epoch 073 - training loss: 0.7209, validation loss: 0.8817
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch73_loss0.8816579729318619.pypots
2024-05-25 01:15:03 [INFO]: Epoch 074 - training loss: 0.7317, validation loss: 0.8792
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch74_loss0.879233717918396.pypots
2024-05-25 01:15:03 [INFO]: Epoch 075 - training loss: 0.7631, validation loss: 0.8767
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch75_loss0.8767024129629135.pypots
2024-05-25 01:15:03 [INFO]: Epoch 076 - training loss: 0.7207, validation loss: 0.8768
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch76_loss0.8768424540758133.pypots
2024-05-25 01:15:03 [INFO]: Epoch 077 - training loss: 0.7263, validation loss: 0.8748
2024-05-25 01:15:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch77_loss0.8747638612985611.pypots
2024-05-25 01:15:04 [INFO]: Epoch 078 - training loss: 0.7318, validation loss: 0.8723
2024-05-25 01:15:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch78_loss0.8723401427268982.pypots
2024-05-25 01:15:04 [INFO]: Epoch 079 - training loss: 0.7426, validation loss: 0.8743
2024-05-25 01:15:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch79_loss0.8743073344230652.pypots
2024-05-25 01:15:04 [INFO]: Epoch 080 - training loss: 0.7147, validation loss: 0.8757
2024-05-25 01:15:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch80_loss0.8756674230098724.pypots
2024-05-25 01:15:04 [INFO]: Epoch 081 - training loss: 0.7123, validation loss: 0.8713
2024-05-25 01:15:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch81_loss0.871348038315773.pypots
2024-05-25 01:15:04 [INFO]: Epoch 082 - training loss: 0.7377, validation loss: 0.8683
2024-05-25 01:15:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch82_loss0.868331104516983.pypots
2024-05-25 01:15:05 [INFO]: Epoch 083 - training loss: 0.7300, validation loss: 0.8700
2024-05-25 01:15:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch83_loss0.8700003921985626.pypots
2024-05-25 01:15:05 [INFO]: Epoch 084 - training loss: 0.7104, validation loss: 0.8698
2024-05-25 01:15:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch84_loss0.8697615712881088.pypots
2024-05-25 01:15:05 [INFO]: Epoch 085 - training loss: 0.7638, validation loss: 0.8683
2024-05-25 01:15:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch85_loss0.868290513753891.pypots
2024-05-25 01:15:05 [INFO]: Epoch 086 - training loss: 0.7478, validation loss: 0.8693
2024-05-25 01:15:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch86_loss0.8692545592784882.pypots
2024-05-25 01:15:05 [INFO]: Epoch 087 - training loss: 0.7388, validation loss: 0.8637
2024-05-25 01:15:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch87_loss0.8637442141771317.pypots
2024-05-25 01:15:06 [INFO]: Epoch 088 - training loss: 0.7316, validation loss: 0.8643
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch88_loss0.864343672990799.pypots
2024-05-25 01:15:06 [INFO]: Epoch 089 - training loss: 0.7249, validation loss: 0.8629
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch89_loss0.8628867864608765.pypots
2024-05-25 01:15:06 [INFO]: Epoch 090 - training loss: 0.7334, validation loss: 0.8638
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch90_loss0.8638338446617126.pypots
2024-05-25 01:15:06 [INFO]: Epoch 091 - training loss: 0.7314, validation loss: 0.8643
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch91_loss0.8643116801977158.pypots
2024-05-25 01:15:06 [INFO]: Epoch 092 - training loss: 0.7444, validation loss: 0.8655
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch92_loss0.8655299246311188.pypots
2024-05-25 01:15:06 [INFO]: Epoch 093 - training loss: 0.7399, validation loss: 0.8594
2024-05-25 01:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch93_loss0.8593722134828568.pypots
2024-05-25 01:15:07 [INFO]: Epoch 094 - training loss: 0.7256, validation loss: 0.8582
2024-05-25 01:15:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch94_loss0.8581804186105728.pypots
2024-05-25 01:15:07 [INFO]: Epoch 095 - training loss: 0.7304, validation loss: 0.8574
2024-05-25 01:15:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch95_loss0.8573771566152573.pypots
2024-05-25 01:15:07 [INFO]: Epoch 096 - training loss: 0.7396, validation loss: 0.8600
2024-05-25 01:15:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch96_loss0.859951376914978.pypots
2024-05-25 01:15:07 [INFO]: Epoch 097 - training loss: 0.7483, validation loss: 0.8570
2024-05-25 01:15:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch97_loss0.8570470362901688.pypots
2024-05-25 01:15:07 [INFO]: Epoch 098 - training loss: 0.7411, validation loss: 0.8534
2024-05-25 01:15:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch98_loss0.8533728569746017.pypots
2024-05-25 01:15:08 [INFO]: Epoch 099 - training loss: 0.7255, validation loss: 0.8543
2024-05-25 01:15:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch99_loss0.8542691916227341.pypots
2024-05-25 01:15:08 [INFO]: Epoch 100 - training loss: 0.7203, validation loss: 0.8515
2024-05-25 01:15:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch100_loss0.85151706635952.pypots
2024-05-25 01:15:08 [INFO]: Epoch 101 - training loss: 0.7381, validation loss: 0.8510
2024-05-25 01:15:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch101_loss0.8510214239358902.pypots
2024-05-25 01:15:08 [INFO]: Epoch 102 - training loss: 0.7399, validation loss: 0.8558
2024-05-25 01:15:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch102_loss0.8557786494493484.pypots
2024-05-25 01:15:08 [INFO]: Epoch 103 - training loss: 0.7317, validation loss: 0.8529
2024-05-25 01:15:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch103_loss0.852863147854805.pypots
2024-05-25 01:15:09 [INFO]: Epoch 104 - training loss: 0.7567, validation loss: 0.8484
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch104_loss0.8483911454677582.pypots
2024-05-25 01:15:09 [INFO]: Epoch 105 - training loss: 0.7642, validation loss: 0.8493
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch105_loss0.8493174761533737.pypots
2024-05-25 01:15:09 [INFO]: Epoch 106 - training loss: 0.7193, validation loss: 0.8489
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch106_loss0.8488826602697372.pypots
2024-05-25 01:15:09 [INFO]: Epoch 107 - training loss: 0.7150, validation loss: 0.8470
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch107_loss0.8470229059457779.pypots
2024-05-25 01:15:09 [INFO]: Epoch 108 - training loss: 0.7487, validation loss: 0.8453
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch108_loss0.8452665358781815.pypots
2024-05-25 01:15:09 [INFO]: Epoch 109 - training loss: 0.7007, validation loss: 0.8443
2024-05-25 01:15:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch109_loss0.8442669808864594.pypots
2024-05-25 01:15:10 [INFO]: Epoch 110 - training loss: 0.7198, validation loss: 0.8444
2024-05-25 01:15:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch110_loss0.8444380909204483.pypots
2024-05-25 01:15:10 [INFO]: Epoch 111 - training loss: 0.7155, validation loss: 0.8418
2024-05-25 01:15:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch111_loss0.841834619641304.pypots
2024-05-25 01:15:10 [INFO]: Epoch 112 - training loss: 0.7411, validation loss: 0.8423
2024-05-25 01:15:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch112_loss0.842263251543045.pypots
2024-05-25 01:15:10 [INFO]: Epoch 113 - training loss: 0.7225, validation loss: 0.8389
2024-05-25 01:15:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch113_loss0.8388741314411163.pypots
2024-05-25 01:15:10 [INFO]: Epoch 114 - training loss: 0.7257, validation loss: 0.8363
2024-05-25 01:15:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch114_loss0.836266502737999.pypots
2024-05-25 01:15:11 [INFO]: Epoch 115 - training loss: 0.7227, validation loss: 0.8356
2024-05-25 01:15:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch115_loss0.8356355875730515.pypots
2024-05-25 01:15:11 [INFO]: Epoch 116 - training loss: 0.7081, validation loss: 0.8406
2024-05-25 01:15:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch116_loss0.840586706995964.pypots
2024-05-25 01:15:11 [INFO]: Epoch 117 - training loss: 0.7175, validation loss: 0.8383
2024-05-25 01:15:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch117_loss0.8383450508117676.pypots
2024-05-25 01:15:11 [INFO]: Epoch 118 - training loss: 0.7320, validation loss: 0.8360
2024-05-25 01:15:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch118_loss0.8359743505716324.pypots
2024-05-25 01:15:11 [INFO]: Epoch 119 - training loss: 0.7398, validation loss: 0.8345
2024-05-25 01:15:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch119_loss0.8345061242580414.pypots
2024-05-25 01:15:12 [INFO]: Epoch 120 - training loss: 0.7399, validation loss: 0.8324
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch120_loss0.8323835581541061.pypots
2024-05-25 01:15:12 [INFO]: Epoch 121 - training loss: 0.7249, validation loss: 0.8331
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch121_loss0.8331213444471359.pypots
2024-05-25 01:15:12 [INFO]: Epoch 122 - training loss: 0.7362, validation loss: 0.8278
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch122_loss0.8278414458036423.pypots
2024-05-25 01:15:12 [INFO]: Epoch 123 - training loss: 0.7313, validation loss: 0.8317
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch123_loss0.8316683322191238.pypots
2024-05-25 01:15:12 [INFO]: Epoch 124 - training loss: 0.7275, validation loss: 0.8329
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch124_loss0.832931861281395.pypots
2024-05-25 01:15:12 [INFO]: Epoch 125 - training loss: 0.7125, validation loss: 0.8291
2024-05-25 01:15:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch125_loss0.8291068226099014.pypots
2024-05-25 01:15:13 [INFO]: Epoch 126 - training loss: 0.7274, validation loss: 0.8263
2024-05-25 01:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch126_loss0.8263435363769531.pypots
2024-05-25 01:15:13 [INFO]: Epoch 127 - training loss: 0.7415, validation loss: 0.8277
2024-05-25 01:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch127_loss0.8277197182178497.pypots
2024-05-25 01:15:13 [INFO]: Epoch 128 - training loss: 0.7296, validation loss: 0.8309
2024-05-25 01:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch128_loss0.8308707624673843.pypots
2024-05-25 01:15:13 [INFO]: Epoch 129 - training loss: 0.7275, validation loss: 0.8262
2024-05-25 01:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch129_loss0.8262154161930084.pypots
2024-05-25 01:15:13 [INFO]: Epoch 130 - training loss: 0.7083, validation loss: 0.8277
2024-05-25 01:15:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch130_loss0.8277297019958496.pypots
2024-05-25 01:15:14 [INFO]: Epoch 131 - training loss: 0.7284, validation loss: 0.8226
2024-05-25 01:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch131_loss0.8225690126419067.pypots
2024-05-25 01:15:14 [INFO]: Epoch 132 - training loss: 0.7335, validation loss: 0.8270
2024-05-25 01:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch132_loss0.8269810080528259.pypots
2024-05-25 01:15:14 [INFO]: Epoch 133 - training loss: 0.7512, validation loss: 0.8256
2024-05-25 01:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch133_loss0.825636550784111.pypots
2024-05-25 01:15:14 [INFO]: Epoch 134 - training loss: 0.7104, validation loss: 0.8195
2024-05-25 01:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch134_loss0.8194588422775269.pypots
2024-05-25 01:15:14 [INFO]: Epoch 135 - training loss: 0.7225, validation loss: 0.8206
2024-05-25 01:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch135_loss0.8205681294202805.pypots
2024-05-25 01:15:15 [INFO]: Epoch 136 - training loss: 0.7081, validation loss: 0.8216
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch136_loss0.8215803951025009.pypots
2024-05-25 01:15:15 [INFO]: Epoch 137 - training loss: 0.7279, validation loss: 0.8212
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch137_loss0.8211524486541748.pypots
2024-05-25 01:15:15 [INFO]: Epoch 138 - training loss: 0.7104, validation loss: 0.8211
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch138_loss0.8210846483707428.pypots
2024-05-25 01:15:15 [INFO]: Epoch 139 - training loss: 0.7282, validation loss: 0.8164
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch139_loss0.8164139986038208.pypots
2024-05-25 01:15:15 [INFO]: Epoch 140 - training loss: 0.7153, validation loss: 0.8185
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch140_loss0.8185306340456009.pypots
2024-05-25 01:15:15 [INFO]: Epoch 141 - training loss: 0.7207, validation loss: 0.8202
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch141_loss0.8201649785041809.pypots
2024-05-25 01:15:16 [INFO]: Epoch 142 - training loss: 0.7252, validation loss: 0.8218
2024-05-25 01:15:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch142_loss0.82179956138134.pypots
2024-05-25 01:15:16 [INFO]: Epoch 143 - training loss: 0.6977, validation loss: 0.8176
2024-05-25 01:15:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch143_loss0.8175977915525436.pypots
2024-05-25 01:15:16 [INFO]: Epoch 144 - training loss: 0.7339, validation loss: 0.8193
2024-05-25 01:15:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch144_loss0.8192840218544006.pypots
2024-05-25 01:15:16 [INFO]: Epoch 145 - training loss: 0.7217, validation loss: 0.8120
2024-05-25 01:15:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch145_loss0.8120140880346298.pypots
2024-05-25 01:15:16 [INFO]: Epoch 146 - training loss: 0.7396, validation loss: 0.8111
2024-05-25 01:15:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch146_loss0.8110675811767578.pypots
2024-05-25 01:15:17 [INFO]: Epoch 147 - training loss: 0.7583, validation loss: 0.8135
2024-05-25 01:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch147_loss0.8134845793247223.pypots
2024-05-25 01:15:17 [INFO]: Epoch 148 - training loss: 0.7182, validation loss: 0.8126
2024-05-25 01:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch148_loss0.8125578016042709.pypots
2024-05-25 01:15:17 [INFO]: Epoch 149 - training loss: 0.7294, validation loss: 0.8126
2024-05-25 01:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch149_loss0.8126010298728943.pypots
2024-05-25 01:15:17 [INFO]: Epoch 150 - training loss: 0.7192, validation loss: 0.8119
2024-05-25 01:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch150_loss0.8118688315153122.pypots
2024-05-25 01:15:17 [INFO]: Epoch 151 - training loss: 0.7256, validation loss: 0.8104
2024-05-25 01:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch151_loss0.810403048992157.pypots
2024-05-25 01:15:18 [INFO]: Epoch 152 - training loss: 0.7157, validation loss: 0.8091
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch152_loss0.809113398194313.pypots
2024-05-25 01:15:18 [INFO]: Epoch 153 - training loss: 0.7155, validation loss: 0.8085
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch153_loss0.8084768503904343.pypots
2024-05-25 01:15:18 [INFO]: Epoch 154 - training loss: 0.7218, validation loss: 0.8102
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch154_loss0.8102343827486038.pypots
2024-05-25 01:15:18 [INFO]: Epoch 155 - training loss: 0.7204, validation loss: 0.8101
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch155_loss0.8101155310869217.pypots
2024-05-25 01:15:18 [INFO]: Epoch 156 - training loss: 0.7165, validation loss: 0.8108
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch156_loss0.8107640594244003.pypots
2024-05-25 01:15:18 [INFO]: Epoch 157 - training loss: 0.7071, validation loss: 0.8102
2024-05-25 01:15:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch157_loss0.8101532310247421.pypots
2024-05-25 01:15:19 [INFO]: Epoch 158 - training loss: 0.7167, validation loss: 0.8084
2024-05-25 01:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch158_loss0.8084379881620407.pypots
2024-05-25 01:15:19 [INFO]: Epoch 159 - training loss: 0.7092, validation loss: 0.8075
2024-05-25 01:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch159_loss0.8075213730335236.pypots
2024-05-25 01:15:19 [INFO]: Epoch 160 - training loss: 0.7026, validation loss: 0.8089
2024-05-25 01:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch160_loss0.8089365363121033.pypots
2024-05-25 01:15:19 [INFO]: Epoch 161 - training loss: 0.7261, validation loss: 0.8084
2024-05-25 01:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch161_loss0.8084081560373306.pypots
2024-05-25 01:15:19 [INFO]: Epoch 162 - training loss: 0.7422, validation loss: 0.8060
2024-05-25 01:15:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch162_loss0.8059650510549545.pypots
2024-05-25 01:15:20 [INFO]: Epoch 163 - training loss: 0.7241, validation loss: 0.8031
2024-05-25 01:15:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch163_loss0.8030833154916763.pypots
2024-05-25 01:15:20 [INFO]: Epoch 164 - training loss: 0.6973, validation loss: 0.8095
2024-05-25 01:15:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch164_loss0.8094998300075531.pypots
2024-05-25 01:15:20 [INFO]: Epoch 165 - training loss: 0.7497, validation loss: 0.8057
2024-05-25 01:15:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch165_loss0.8056740760803223.pypots
2024-05-25 01:15:20 [INFO]: Epoch 166 - training loss: 0.7064, validation loss: 0.8063
2024-05-25 01:15:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch166_loss0.8062502294778824.pypots
2024-05-25 01:15:20 [INFO]: Epoch 167 - training loss: 0.7020, validation loss: 0.8090
2024-05-25 01:15:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch167_loss0.8090469837188721.pypots
2024-05-25 01:15:21 [INFO]: Epoch 168 - training loss: 0.7239, validation loss: 0.8090
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch168_loss0.8090023994445801.pypots
2024-05-25 01:15:21 [INFO]: Epoch 169 - training loss: 0.7385, validation loss: 0.8097
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch169_loss0.8097230494022369.pypots
2024-05-25 01:15:21 [INFO]: Epoch 170 - training loss: 0.7324, validation loss: 0.8062
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch170_loss0.8061788231134415.pypots
2024-05-25 01:15:21 [INFO]: Epoch 171 - training loss: 0.7261, validation loss: 0.8041
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch171_loss0.8040952384471893.pypots
2024-05-25 01:15:21 [INFO]: Epoch 172 - training loss: 0.7303, validation loss: 0.8079
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch172_loss0.8079195469617844.pypots
2024-05-25 01:15:21 [INFO]: Epoch 173 - training loss: 0.7202, validation loss: 0.8083
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN_epoch173_loss0.808260589838028.pypots
2024-05-25 01:15:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:15:21 [INFO]: Finished training. The best model is from epoch#163.
2024-05-25 01:15:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_ettm1/20240525_T011447/MRNN.pypots
2024-05-25 01:15:22 [INFO]: MRNN on ETTm1: MAE=0.6159, MSE=1.0067
2024-05-25 01:15:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 01:15:22 [INFO]: Using the given device: cpu
2024-05-25 01:15:22 [INFO]: LOCF on ETTm1: MAE=0.1420, MSE=0.0788
2024-05-25 01:15:22 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 01:15:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 01:15:22 [INFO]: Median on ETTm1: MAE=0.6533, MSE=0.8148
2024-05-25 01:15:22 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 01:15:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 01:15:22 [INFO]: Mean on ETTm1: MAE=0.6593, MSE=0.7994
2024-05-25 01:15:22 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 01:15:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 01:15:22 [INFO]: 
SAITS on data/ettm1: MAE=0.154±0.01127716600690691, MSE=0.048±0.006432648636841634
Transformer on data/ettm1: MAE=0.145±0.011927716684960451, MSE=0.041±0.0062732001624544
TimesNet on data/ettm1: MAE=0.122±0.005831910719004152, MSE=0.032±0.0027286458719713727
CSDI on data/ettm1: MAE=0.258±0.09192961306724194, MSE=1.123±1.2713993578951048
GPVAE on data/ettm1: MAE=0.295±0.0065567121621071854, MSE=0.185±0.008005541903900019
USGAN on data/ettm1: MAE=0.162±0.009789708163311941, MSE=0.066±0.00626175983662342
BRITS on data/ettm1: MAE=0.139±0.003045425852087441, MSE=0.056±0.002793686935862166
MRNN on data/ettm1: MAE=0.720±0.08550216321854923, MSE=1.271±0.1995004627263265
LOCF on data/ettm1: MAE=0.142±0.0, MSE=0.079±0.0
Median on data/ettm1: MAE=0.653±0.0, MSE=0.815±1.1102230246251565e-16
Mean on data/ettm1: MAE=0.659±0.0, MSE=0.799±0.0

