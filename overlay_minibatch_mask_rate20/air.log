2024-05-24 23:01:45 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 23:01:46 [INFO]: Using the given device: cuda:0
2024-05-24 23:01:46 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T230146
2024-05-24 23:01:46 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T230146/tensorboard
2024-05-24 23:01:46 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-24 23:01:48 [INFO]: Epoch 001 - training loss: 1.0553, validation loss: 0.5297
2024-05-24 23:01:48 [INFO]: Epoch 002 - training loss: 0.7635, validation loss: 0.4092
2024-05-24 23:01:49 [INFO]: Epoch 003 - training loss: 0.6584, validation loss: 0.3313
2024-05-24 23:01:50 [INFO]: Epoch 004 - training loss: 0.5806, validation loss: 0.2888
2024-05-24 23:01:50 [INFO]: Epoch 005 - training loss: 0.5245, validation loss: 0.2651
2024-05-24 23:01:51 [INFO]: Epoch 006 - training loss: 0.4864, validation loss: 0.2532
2024-05-24 23:01:52 [INFO]: Epoch 007 - training loss: 0.4623, validation loss: 0.2406
2024-05-24 23:01:52 [INFO]: Epoch 008 - training loss: 0.4413, validation loss: 0.2364
2024-05-24 23:01:53 [INFO]: Epoch 009 - training loss: 0.4270, validation loss: 0.2305
2024-05-24 23:01:54 [INFO]: Epoch 010 - training loss: 0.4174, validation loss: 0.2273
2024-05-24 23:01:54 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2214
2024-05-24 23:01:55 [INFO]: Epoch 012 - training loss: 0.3985, validation loss: 0.2161
2024-05-24 23:01:56 [INFO]: Epoch 013 - training loss: 0.3904, validation loss: 0.2125
2024-05-24 23:01:56 [INFO]: Epoch 014 - training loss: 0.3820, validation loss: 0.2117
2024-05-24 23:01:57 [INFO]: Epoch 015 - training loss: 0.3771, validation loss: 0.2084
2024-05-24 23:01:58 [INFO]: Epoch 016 - training loss: 0.3711, validation loss: 0.2062
2024-05-24 23:01:58 [INFO]: Epoch 017 - training loss: 0.3668, validation loss: 0.2024
2024-05-24 23:01:59 [INFO]: Epoch 018 - training loss: 0.3616, validation loss: 0.2014
2024-05-24 23:02:00 [INFO]: Epoch 019 - training loss: 0.3577, validation loss: 0.1987
2024-05-24 23:02:00 [INFO]: Epoch 020 - training loss: 0.3528, validation loss: 0.1968
2024-05-24 23:02:01 [INFO]: Epoch 021 - training loss: 0.3494, validation loss: 0.1961
2024-05-24 23:02:01 [INFO]: Epoch 022 - training loss: 0.3467, validation loss: 0.1941
2024-05-24 23:02:02 [INFO]: Epoch 023 - training loss: 0.3431, validation loss: 0.1932
2024-05-24 23:02:03 [INFO]: Epoch 024 - training loss: 0.3402, validation loss: 0.1899
2024-05-24 23:02:03 [INFO]: Epoch 025 - training loss: 0.3383, validation loss: 0.1898
2024-05-24 23:02:04 [INFO]: Epoch 026 - training loss: 0.3358, validation loss: 0.1890
2024-05-24 23:02:05 [INFO]: Epoch 027 - training loss: 0.3330, validation loss: 0.1873
2024-05-24 23:02:05 [INFO]: Epoch 028 - training loss: 0.3305, validation loss: 0.1855
2024-05-24 23:02:06 [INFO]: Epoch 029 - training loss: 0.3271, validation loss: 0.1840
2024-05-24 23:02:07 [INFO]: Epoch 030 - training loss: 0.3263, validation loss: 0.1836
2024-05-24 23:02:07 [INFO]: Epoch 031 - training loss: 0.3231, validation loss: 0.1825
2024-05-24 23:02:08 [INFO]: Epoch 032 - training loss: 0.3209, validation loss: 0.1809
2024-05-24 23:02:09 [INFO]: Epoch 033 - training loss: 0.3195, validation loss: 0.1784
2024-05-24 23:02:09 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1792
2024-05-24 23:02:10 [INFO]: Epoch 035 - training loss: 0.3184, validation loss: 0.1794
2024-05-24 23:02:11 [INFO]: Epoch 036 - training loss: 0.3155, validation loss: 0.1775
2024-05-24 23:02:11 [INFO]: Epoch 037 - training loss: 0.3136, validation loss: 0.1755
2024-05-24 23:02:12 [INFO]: Epoch 038 - training loss: 0.3093, validation loss: 0.1762
2024-05-24 23:02:13 [INFO]: Epoch 039 - training loss: 0.3089, validation loss: 0.1737
2024-05-24 23:02:13 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1723
2024-05-24 23:02:14 [INFO]: Epoch 041 - training loss: 0.3044, validation loss: 0.1721
2024-05-24 23:02:15 [INFO]: Epoch 042 - training loss: 0.3020, validation loss: 0.1712
2024-05-24 23:02:15 [INFO]: Epoch 043 - training loss: 0.3017, validation loss: 0.1699
2024-05-24 23:02:16 [INFO]: Epoch 044 - training loss: 0.3007, validation loss: 0.1696
2024-05-24 23:02:17 [INFO]: Epoch 045 - training loss: 0.2979, validation loss: 0.1701
2024-05-24 23:02:17 [INFO]: Epoch 046 - training loss: 0.2987, validation loss: 0.1680
2024-05-24 23:02:18 [INFO]: Epoch 047 - training loss: 0.2973, validation loss: 0.1669
2024-05-24 23:02:19 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1671
2024-05-24 23:02:19 [INFO]: Epoch 049 - training loss: 0.2940, validation loss: 0.1663
2024-05-24 23:02:20 [INFO]: Epoch 050 - training loss: 0.2912, validation loss: 0.1657
2024-05-24 23:02:21 [INFO]: Epoch 051 - training loss: 0.2916, validation loss: 0.1652
2024-05-24 23:02:21 [INFO]: Epoch 052 - training loss: 0.2898, validation loss: 0.1638
2024-05-24 23:02:22 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.1632
2024-05-24 23:02:22 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1635
2024-05-24 23:02:23 [INFO]: Epoch 055 - training loss: 0.2848, validation loss: 0.1619
2024-05-24 23:02:24 [INFO]: Epoch 056 - training loss: 0.2838, validation loss: 0.1614
2024-05-24 23:02:24 [INFO]: Epoch 057 - training loss: 0.2823, validation loss: 0.1597
2024-05-24 23:02:25 [INFO]: Epoch 058 - training loss: 0.2823, validation loss: 0.1595
2024-05-24 23:02:26 [INFO]: Epoch 059 - training loss: 0.2805, validation loss: 0.1590
2024-05-24 23:02:26 [INFO]: Epoch 060 - training loss: 0.2808, validation loss: 0.1592
2024-05-24 23:02:27 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1586
2024-05-24 23:02:28 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1571
2024-05-24 23:02:28 [INFO]: Epoch 063 - training loss: 0.2755, validation loss: 0.1571
2024-05-24 23:02:29 [INFO]: Epoch 064 - training loss: 0.2749, validation loss: 0.1549
2024-05-24 23:02:30 [INFO]: Epoch 065 - training loss: 0.2727, validation loss: 0.1564
2024-05-24 23:02:30 [INFO]: Epoch 066 - training loss: 0.2715, validation loss: 0.1554
2024-05-24 23:02:31 [INFO]: Epoch 067 - training loss: 0.2702, validation loss: 0.1546
2024-05-24 23:02:32 [INFO]: Epoch 068 - training loss: 0.2703, validation loss: 0.1538
2024-05-24 23:02:32 [INFO]: Epoch 069 - training loss: 0.2677, validation loss: 0.1537
2024-05-24 23:02:33 [INFO]: Epoch 070 - training loss: 0.2671, validation loss: 0.1540
2024-05-24 23:02:34 [INFO]: Epoch 071 - training loss: 0.2658, validation loss: 0.1532
2024-05-24 23:02:34 [INFO]: Epoch 072 - training loss: 0.2657, validation loss: 0.1516
2024-05-24 23:02:35 [INFO]: Epoch 073 - training loss: 0.2662, validation loss: 0.1508
2024-05-24 23:02:36 [INFO]: Epoch 074 - training loss: 0.2638, validation loss: 0.1512
2024-05-24 23:02:36 [INFO]: Epoch 075 - training loss: 0.2623, validation loss: 0.1507
2024-05-24 23:02:37 [INFO]: Epoch 076 - training loss: 0.2615, validation loss: 0.1500
2024-05-24 23:02:38 [INFO]: Epoch 077 - training loss: 0.2610, validation loss: 0.1500
2024-05-24 23:02:38 [INFO]: Epoch 078 - training loss: 0.2611, validation loss: 0.1505
2024-05-24 23:02:39 [INFO]: Epoch 079 - training loss: 0.2603, validation loss: 0.1495
2024-05-24 23:02:40 [INFO]: Epoch 080 - training loss: 0.2574, validation loss: 0.1487
2024-05-24 23:02:40 [INFO]: Epoch 081 - training loss: 0.2578, validation loss: 0.1480
2024-05-24 23:02:41 [INFO]: Epoch 082 - training loss: 0.2576, validation loss: 0.1487
2024-05-24 23:02:41 [INFO]: Epoch 083 - training loss: 0.2562, validation loss: 0.1473
2024-05-24 23:02:42 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1468
2024-05-24 23:02:43 [INFO]: Epoch 085 - training loss: 0.2534, validation loss: 0.1468
2024-05-24 23:02:44 [INFO]: Epoch 086 - training loss: 0.2533, validation loss: 0.1454
2024-05-24 23:02:44 [INFO]: Epoch 087 - training loss: 0.2540, validation loss: 0.1459
2024-05-24 23:02:45 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1456
2024-05-24 23:02:46 [INFO]: Epoch 089 - training loss: 0.2516, validation loss: 0.1450
2024-05-24 23:02:46 [INFO]: Epoch 090 - training loss: 0.2504, validation loss: 0.1442
2024-05-24 23:02:47 [INFO]: Epoch 091 - training loss: 0.2500, validation loss: 0.1445
2024-05-24 23:02:48 [INFO]: Epoch 092 - training loss: 0.2496, validation loss: 0.1437
2024-05-24 23:02:48 [INFO]: Epoch 093 - training loss: 0.2492, validation loss: 0.1445
2024-05-24 23:02:49 [INFO]: Epoch 094 - training loss: 0.2472, validation loss: 0.1435
2024-05-24 23:02:49 [INFO]: Epoch 095 - training loss: 0.2475, validation loss: 0.1432
2024-05-24 23:02:50 [INFO]: Epoch 096 - training loss: 0.2469, validation loss: 0.1437
2024-05-24 23:02:51 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1427
2024-05-24 23:02:51 [INFO]: Epoch 098 - training loss: 0.2459, validation loss: 0.1427
2024-05-24 23:02:52 [INFO]: Epoch 099 - training loss: 0.2448, validation loss: 0.1429
2024-05-24 23:02:53 [INFO]: Epoch 100 - training loss: 0.2465, validation loss: 0.1428
2024-05-24 23:02:53 [INFO]: Epoch 101 - training loss: 0.2451, validation loss: 0.1415
2024-05-24 23:02:54 [INFO]: Epoch 102 - training loss: 0.2440, validation loss: 0.1414
2024-05-24 23:02:55 [INFO]: Epoch 103 - training loss: 0.2429, validation loss: 0.1411
2024-05-24 23:02:55 [INFO]: Epoch 104 - training loss: 0.2426, validation loss: 0.1412
2024-05-24 23:02:56 [INFO]: Epoch 105 - training loss: 0.2430, validation loss: 0.1401
2024-05-24 23:02:57 [INFO]: Epoch 106 - training loss: 0.2420, validation loss: 0.1402
2024-05-24 23:02:57 [INFO]: Epoch 107 - training loss: 0.2417, validation loss: 0.1409
2024-05-24 23:02:58 [INFO]: Epoch 108 - training loss: 0.2405, validation loss: 0.1395
2024-05-24 23:02:59 [INFO]: Epoch 109 - training loss: 0.2401, validation loss: 0.1406
2024-05-24 23:02:59 [INFO]: Epoch 110 - training loss: 0.2409, validation loss: 0.1395
2024-05-24 23:03:00 [INFO]: Epoch 111 - training loss: 0.2396, validation loss: 0.1405
2024-05-24 23:03:01 [INFO]: Epoch 112 - training loss: 0.2383, validation loss: 0.1390
2024-05-24 23:03:01 [INFO]: Epoch 113 - training loss: 0.2368, validation loss: 0.1387
2024-05-24 23:03:02 [INFO]: Epoch 114 - training loss: 0.2371, validation loss: 0.1393
2024-05-24 23:03:03 [INFO]: Epoch 115 - training loss: 0.2379, validation loss: 0.1389
2024-05-24 23:03:03 [INFO]: Epoch 116 - training loss: 0.2376, validation loss: 0.1388
2024-05-24 23:03:04 [INFO]: Epoch 117 - training loss: 0.2352, validation loss: 0.1386
2024-05-24 23:03:05 [INFO]: Epoch 118 - training loss: 0.2349, validation loss: 0.1382
2024-05-24 23:03:05 [INFO]: Epoch 119 - training loss: 0.2340, validation loss: 0.1377
2024-05-24 23:03:06 [INFO]: Epoch 120 - training loss: 0.2331, validation loss: 0.1374
2024-05-24 23:03:07 [INFO]: Epoch 121 - training loss: 0.2324, validation loss: 0.1373
2024-05-24 23:03:07 [INFO]: Epoch 122 - training loss: 0.2342, validation loss: 0.1374
2024-05-24 23:03:08 [INFO]: Epoch 123 - training loss: 0.2347, validation loss: 0.1369
2024-05-24 23:03:08 [INFO]: Epoch 124 - training loss: 0.2320, validation loss: 0.1368
2024-05-24 23:03:09 [INFO]: Epoch 125 - training loss: 0.2323, validation loss: 0.1372
2024-05-24 23:03:10 [INFO]: Epoch 126 - training loss: 0.2313, validation loss: 0.1363
2024-05-24 23:03:10 [INFO]: Epoch 127 - training loss: 0.2326, validation loss: 0.1376
2024-05-24 23:03:11 [INFO]: Epoch 128 - training loss: 0.2309, validation loss: 0.1376
2024-05-24 23:03:12 [INFO]: Epoch 129 - training loss: 0.2301, validation loss: 0.1368
2024-05-24 23:03:12 [INFO]: Epoch 130 - training loss: 0.2300, validation loss: 0.1358
2024-05-24 23:03:13 [INFO]: Epoch 131 - training loss: 0.2298, validation loss: 0.1363
2024-05-24 23:03:14 [INFO]: Epoch 132 - training loss: 0.2300, validation loss: 0.1358
2024-05-24 23:03:14 [INFO]: Epoch 133 - training loss: 0.2289, validation loss: 0.1360
2024-05-24 23:03:15 [INFO]: Epoch 134 - training loss: 0.2279, validation loss: 0.1356
2024-05-24 23:03:16 [INFO]: Epoch 135 - training loss: 0.2270, validation loss: 0.1348
2024-05-24 23:03:16 [INFO]: Epoch 136 - training loss: 0.2283, validation loss: 0.1365
2024-05-24 23:03:17 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1350
2024-05-24 23:03:18 [INFO]: Epoch 138 - training loss: 0.2264, validation loss: 0.1346
2024-05-24 23:03:18 [INFO]: Epoch 139 - training loss: 0.2248, validation loss: 0.1344
2024-05-24 23:03:19 [INFO]: Epoch 140 - training loss: 0.2258, validation loss: 0.1338
2024-05-24 23:03:20 [INFO]: Epoch 141 - training loss: 0.2263, validation loss: 0.1345
2024-05-24 23:03:20 [INFO]: Epoch 142 - training loss: 0.2249, validation loss: 0.1339
2024-05-24 23:03:21 [INFO]: Epoch 143 - training loss: 0.2246, validation loss: 0.1331
2024-05-24 23:03:22 [INFO]: Epoch 144 - training loss: 0.2235, validation loss: 0.1325
2024-05-24 23:03:22 [INFO]: Epoch 145 - training loss: 0.2238, validation loss: 0.1338
2024-05-24 23:03:23 [INFO]: Epoch 146 - training loss: 0.2232, validation loss: 0.1327
2024-05-24 23:03:24 [INFO]: Epoch 147 - training loss: 0.2249, validation loss: 0.1334
2024-05-24 23:03:24 [INFO]: Epoch 148 - training loss: 0.2224, validation loss: 0.1337
2024-05-24 23:03:25 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1324
2024-05-24 23:03:26 [INFO]: Epoch 150 - training loss: 0.2233, validation loss: 0.1325
2024-05-24 23:03:26 [INFO]: Epoch 151 - training loss: 0.2229, validation loss: 0.1319
2024-05-24 23:03:27 [INFO]: Epoch 152 - training loss: 0.2216, validation loss: 0.1320
2024-05-24 23:03:27 [INFO]: Epoch 153 - training loss: 0.2202, validation loss: 0.1317
2024-05-24 23:03:28 [INFO]: Epoch 154 - training loss: 0.2205, validation loss: 0.1321
2024-05-24 23:03:29 [INFO]: Epoch 155 - training loss: 0.2218, validation loss: 0.1314
2024-05-24 23:03:29 [INFO]: Epoch 156 - training loss: 0.2193, validation loss: 0.1316
2024-05-24 23:03:30 [INFO]: Epoch 157 - training loss: 0.2194, validation loss: 0.1314
2024-05-24 23:03:31 [INFO]: Epoch 158 - training loss: 0.2200, validation loss: 0.1314
2024-05-24 23:03:31 [INFO]: Epoch 159 - training loss: 0.2189, validation loss: 0.1314
2024-05-24 23:03:32 [INFO]: Epoch 160 - training loss: 0.2198, validation loss: 0.1316
2024-05-24 23:03:33 [INFO]: Epoch 161 - training loss: 0.2194, validation loss: 0.1309
2024-05-24 23:03:33 [INFO]: Epoch 162 - training loss: 0.2226, validation loss: 0.1310
2024-05-24 23:03:34 [INFO]: Epoch 163 - training loss: 0.2193, validation loss: 0.1303
2024-05-24 23:03:35 [INFO]: Epoch 164 - training loss: 0.2169, validation loss: 0.1302
2024-05-24 23:03:35 [INFO]: Epoch 165 - training loss: 0.2175, validation loss: 0.1304
2024-05-24 23:03:36 [INFO]: Epoch 166 - training loss: 0.2180, validation loss: 0.1299
2024-05-24 23:03:37 [INFO]: Epoch 167 - training loss: 0.2169, validation loss: 0.1302
2024-05-24 23:03:37 [INFO]: Epoch 168 - training loss: 0.2165, validation loss: 0.1299
2024-05-24 23:03:38 [INFO]: Epoch 169 - training loss: 0.2167, validation loss: 0.1295
2024-05-24 23:03:39 [INFO]: Epoch 170 - training loss: 0.2166, validation loss: 0.1296
2024-05-24 23:03:39 [INFO]: Epoch 171 - training loss: 0.2167, validation loss: 0.1295
2024-05-24 23:03:40 [INFO]: Epoch 172 - training loss: 0.2182, validation loss: 0.1299
2024-05-24 23:03:41 [INFO]: Epoch 173 - training loss: 0.2148, validation loss: 0.1291
2024-05-24 23:03:41 [INFO]: Epoch 174 - training loss: 0.2140, validation loss: 0.1285
2024-05-24 23:03:42 [INFO]: Epoch 175 - training loss: 0.2138, validation loss: 0.1302
2024-05-24 23:03:43 [INFO]: Epoch 176 - training loss: 0.2145, validation loss: 0.1290
2024-05-24 23:03:43 [INFO]: Epoch 177 - training loss: 0.2137, validation loss: 0.1286
2024-05-24 23:03:44 [INFO]: Epoch 178 - training loss: 0.2150, validation loss: 0.1292
2024-05-24 23:03:45 [INFO]: Epoch 179 - training loss: 0.2127, validation loss: 0.1281
2024-05-24 23:03:45 [INFO]: Epoch 180 - training loss: 0.2136, validation loss: 0.1290
2024-05-24 23:03:46 [INFO]: Epoch 181 - training loss: 0.2144, validation loss: 0.1293
2024-05-24 23:03:46 [INFO]: Epoch 182 - training loss: 0.2185, validation loss: 0.1276
2024-05-24 23:03:47 [INFO]: Epoch 183 - training loss: 0.2131, validation loss: 0.1275
2024-05-24 23:03:48 [INFO]: Epoch 184 - training loss: 0.2124, validation loss: 0.1275
2024-05-24 23:03:48 [INFO]: Epoch 185 - training loss: 0.2115, validation loss: 0.1281
2024-05-24 23:03:49 [INFO]: Epoch 186 - training loss: 0.2123, validation loss: 0.1274
2024-05-24 23:03:50 [INFO]: Epoch 187 - training loss: 0.2111, validation loss: 0.1268
2024-05-24 23:03:50 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1271
2024-05-24 23:03:51 [INFO]: Epoch 189 - training loss: 0.2110, validation loss: 0.1267
2024-05-24 23:03:52 [INFO]: Epoch 190 - training loss: 0.2115, validation loss: 0.1278
2024-05-24 23:03:52 [INFO]: Epoch 191 - training loss: 0.2106, validation loss: 0.1257
2024-05-24 23:03:53 [INFO]: Epoch 192 - training loss: 0.2101, validation loss: 0.1259
2024-05-24 23:03:54 [INFO]: Epoch 193 - training loss: 0.2090, validation loss: 0.1261
2024-05-24 23:03:54 [INFO]: Epoch 194 - training loss: 0.2087, validation loss: 0.1272
2024-05-24 23:03:55 [INFO]: Epoch 195 - training loss: 0.2099, validation loss: 0.1267
2024-05-24 23:03:56 [INFO]: Epoch 196 - training loss: 0.2092, validation loss: 0.1269
2024-05-24 23:03:56 [INFO]: Epoch 197 - training loss: 0.2090, validation loss: 0.1262
2024-05-24 23:03:57 [INFO]: Epoch 198 - training loss: 0.2077, validation loss: 0.1265
2024-05-24 23:03:58 [INFO]: Epoch 199 - training loss: 0.2083, validation loss: 0.1268
2024-05-24 23:03:58 [INFO]: Epoch 200 - training loss: 0.2076, validation loss: 0.1262
2024-05-24 23:03:59 [INFO]: Epoch 201 - training loss: 0.2080, validation loss: 0.1260
2024-05-24 23:03:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:03:59 [INFO]: Finished training. The best model is from epoch#191.
2024-05-24 23:03:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/SAITS_air_quality/20240524_T230146/SAITS.pypots
2024-05-24 23:03:59 [INFO]: SAITS on Air-Quality: MAE=0.1535, MSE=0.1152
2024-05-24 23:03:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-24 23:03:59 [INFO]: Using the given device: cuda:0
2024-05-24 23:03:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T230359
2024-05-24 23:03:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T230359/tensorboard
2024-05-24 23:03:59 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-24 23:04:00 [INFO]: Epoch 001 - training loss: 0.9047, validation loss: 0.4832
2024-05-24 23:04:00 [INFO]: Epoch 002 - training loss: 0.5774, validation loss: 0.3589
2024-05-24 23:04:00 [INFO]: Epoch 003 - training loss: 0.4859, validation loss: 0.3018
2024-05-24 23:04:00 [INFO]: Epoch 004 - training loss: 0.4403, validation loss: 0.2751
2024-05-24 23:04:01 [INFO]: Epoch 005 - training loss: 0.4114, validation loss: 0.2609
2024-05-24 23:04:01 [INFO]: Epoch 006 - training loss: 0.3912, validation loss: 0.2474
2024-05-24 23:04:01 [INFO]: Epoch 007 - training loss: 0.3802, validation loss: 0.2408
2024-05-24 23:04:02 [INFO]: Epoch 008 - training loss: 0.3639, validation loss: 0.2385
2024-05-24 23:04:02 [INFO]: Epoch 009 - training loss: 0.3565, validation loss: 0.2291
2024-05-24 23:04:02 [INFO]: Epoch 010 - training loss: 0.3472, validation loss: 0.2242
2024-05-24 23:04:03 [INFO]: Epoch 011 - training loss: 0.3413, validation loss: 0.2246
2024-05-24 23:04:03 [INFO]: Epoch 012 - training loss: 0.3351, validation loss: 0.2191
2024-05-24 23:04:03 [INFO]: Epoch 013 - training loss: 0.3286, validation loss: 0.2140
2024-05-24 23:04:04 [INFO]: Epoch 014 - training loss: 0.3277, validation loss: 0.2111
2024-05-24 23:04:04 [INFO]: Epoch 015 - training loss: 0.3256, validation loss: 0.2099
2024-05-24 23:04:04 [INFO]: Epoch 016 - training loss: 0.3215, validation loss: 0.2042
2024-05-24 23:04:04 [INFO]: Epoch 017 - training loss: 0.3157, validation loss: 0.2005
2024-05-24 23:04:05 [INFO]: Epoch 018 - training loss: 0.3107, validation loss: 0.1984
2024-05-24 23:04:05 [INFO]: Epoch 019 - training loss: 0.3103, validation loss: 0.1962
2024-05-24 23:04:05 [INFO]: Epoch 020 - training loss: 0.3084, validation loss: 0.1947
2024-05-24 23:04:06 [INFO]: Epoch 021 - training loss: 0.3043, validation loss: 0.1938
2024-05-24 23:04:06 [INFO]: Epoch 022 - training loss: 0.3011, validation loss: 0.1917
2024-05-24 23:04:06 [INFO]: Epoch 023 - training loss: 0.2992, validation loss: 0.1908
2024-05-24 23:04:07 [INFO]: Epoch 024 - training loss: 0.2992, validation loss: 0.1891
2024-05-24 23:04:07 [INFO]: Epoch 025 - training loss: 0.2959, validation loss: 0.1876
2024-05-24 23:04:07 [INFO]: Epoch 026 - training loss: 0.2920, validation loss: 0.1891
2024-05-24 23:04:07 [INFO]: Epoch 027 - training loss: 0.2894, validation loss: 0.1874
2024-05-24 23:04:08 [INFO]: Epoch 028 - training loss: 0.2901, validation loss: 0.1870
2024-05-24 23:04:08 [INFO]: Epoch 029 - training loss: 0.2869, validation loss: 0.1867
2024-05-24 23:04:08 [INFO]: Epoch 030 - training loss: 0.2859, validation loss: 0.1872
2024-05-24 23:04:09 [INFO]: Epoch 031 - training loss: 0.2854, validation loss: 0.1854
2024-05-24 23:04:09 [INFO]: Epoch 032 - training loss: 0.2846, validation loss: 0.1831
2024-05-24 23:04:09 [INFO]: Epoch 033 - training loss: 0.2821, validation loss: 0.1828
2024-05-24 23:04:10 [INFO]: Epoch 034 - training loss: 0.2827, validation loss: 0.1867
2024-05-24 23:04:10 [INFO]: Epoch 035 - training loss: 0.2791, validation loss: 0.1849
2024-05-24 23:04:10 [INFO]: Epoch 036 - training loss: 0.2817, validation loss: 0.1822
2024-05-24 23:04:11 [INFO]: Epoch 037 - training loss: 0.2775, validation loss: 0.1847
2024-05-24 23:04:11 [INFO]: Epoch 038 - training loss: 0.2732, validation loss: 0.1805
2024-05-24 23:04:11 [INFO]: Epoch 039 - training loss: 0.2741, validation loss: 0.1812
2024-05-24 23:04:11 [INFO]: Epoch 040 - training loss: 0.2731, validation loss: 0.1800
2024-05-24 23:04:12 [INFO]: Epoch 041 - training loss: 0.2719, validation loss: 0.1795
2024-05-24 23:04:12 [INFO]: Epoch 042 - training loss: 0.2707, validation loss: 0.1786
2024-05-24 23:04:12 [INFO]: Epoch 043 - training loss: 0.2718, validation loss: 0.1789
2024-05-24 23:04:13 [INFO]: Epoch 044 - training loss: 0.2674, validation loss: 0.1776
2024-05-24 23:04:13 [INFO]: Epoch 045 - training loss: 0.2672, validation loss: 0.1764
2024-05-24 23:04:13 [INFO]: Epoch 046 - training loss: 0.2723, validation loss: 0.1781
2024-05-24 23:04:14 [INFO]: Epoch 047 - training loss: 0.2688, validation loss: 0.1775
2024-05-24 23:04:14 [INFO]: Epoch 048 - training loss: 0.2661, validation loss: 0.1770
2024-05-24 23:04:14 [INFO]: Epoch 049 - training loss: 0.2641, validation loss: 0.1756
2024-05-24 23:04:15 [INFO]: Epoch 050 - training loss: 0.2631, validation loss: 0.1761
2024-05-24 23:04:15 [INFO]: Epoch 051 - training loss: 0.2612, validation loss: 0.1753
2024-05-24 23:04:15 [INFO]: Epoch 052 - training loss: 0.2603, validation loss: 0.1727
2024-05-24 23:04:15 [INFO]: Epoch 053 - training loss: 0.2587, validation loss: 0.1769
2024-05-24 23:04:16 [INFO]: Epoch 054 - training loss: 0.2611, validation loss: 0.1755
2024-05-24 23:04:16 [INFO]: Epoch 055 - training loss: 0.2613, validation loss: 0.1762
2024-05-24 23:04:16 [INFO]: Epoch 056 - training loss: 0.2575, validation loss: 0.1718
2024-05-24 23:04:17 [INFO]: Epoch 057 - training loss: 0.2565, validation loss: 0.1745
2024-05-24 23:04:17 [INFO]: Epoch 058 - training loss: 0.2586, validation loss: 0.1752
2024-05-24 23:04:17 [INFO]: Epoch 059 - training loss: 0.2552, validation loss: 0.1722
2024-05-24 23:04:18 [INFO]: Epoch 060 - training loss: 0.2540, validation loss: 0.1711
2024-05-24 23:04:18 [INFO]: Epoch 061 - training loss: 0.2557, validation loss: 0.1732
2024-05-24 23:04:18 [INFO]: Epoch 062 - training loss: 0.2552, validation loss: 0.1738
2024-05-24 23:04:18 [INFO]: Epoch 063 - training loss: 0.2559, validation loss: 0.1732
2024-05-24 23:04:19 [INFO]: Epoch 064 - training loss: 0.2533, validation loss: 0.1700
2024-05-24 23:04:19 [INFO]: Epoch 065 - training loss: 0.2508, validation loss: 0.1676
2024-05-24 23:04:19 [INFO]: Epoch 066 - training loss: 0.2501, validation loss: 0.1703
2024-05-24 23:04:20 [INFO]: Epoch 067 - training loss: 0.2482, validation loss: 0.1698
2024-05-24 23:04:20 [INFO]: Epoch 068 - training loss: 0.2486, validation loss: 0.1732
2024-05-24 23:04:20 [INFO]: Epoch 069 - training loss: 0.2505, validation loss: 0.1694
2024-05-24 23:04:21 [INFO]: Epoch 070 - training loss: 0.2492, validation loss: 0.1710
2024-05-24 23:04:21 [INFO]: Epoch 071 - training loss: 0.2479, validation loss: 0.1662
2024-05-24 23:04:21 [INFO]: Epoch 072 - training loss: 0.2471, validation loss: 0.1684
2024-05-24 23:04:22 [INFO]: Epoch 073 - training loss: 0.2443, validation loss: 0.1655
2024-05-24 23:04:22 [INFO]: Epoch 074 - training loss: 0.2435, validation loss: 0.1672
2024-05-24 23:04:22 [INFO]: Epoch 075 - training loss: 0.2463, validation loss: 0.1683
2024-05-24 23:04:22 [INFO]: Epoch 076 - training loss: 0.2440, validation loss: 0.1659
2024-05-24 23:04:23 [INFO]: Epoch 077 - training loss: 0.2415, validation loss: 0.1673
2024-05-24 23:04:23 [INFO]: Epoch 078 - training loss: 0.2421, validation loss: 0.1687
2024-05-24 23:04:23 [INFO]: Epoch 079 - training loss: 0.2419, validation loss: 0.1660
2024-05-24 23:04:24 [INFO]: Epoch 080 - training loss: 0.2422, validation loss: 0.1677
2024-05-24 23:04:24 [INFO]: Epoch 081 - training loss: 0.2440, validation loss: 0.1661
2024-05-24 23:04:24 [INFO]: Epoch 082 - training loss: 0.2444, validation loss: 0.1683
2024-05-24 23:04:25 [INFO]: Epoch 083 - training loss: 0.2401, validation loss: 0.1635
2024-05-24 23:04:25 [INFO]: Epoch 084 - training loss: 0.2394, validation loss: 0.1634
2024-05-24 23:04:25 [INFO]: Epoch 085 - training loss: 0.2380, validation loss: 0.1640
2024-05-24 23:04:26 [INFO]: Epoch 086 - training loss: 0.2387, validation loss: 0.1651
2024-05-24 23:04:26 [INFO]: Epoch 087 - training loss: 0.2360, validation loss: 0.1652
2024-05-24 23:04:26 [INFO]: Epoch 088 - training loss: 0.2344, validation loss: 0.1631
2024-05-24 23:04:26 [INFO]: Epoch 089 - training loss: 0.2375, validation loss: 0.1669
2024-05-24 23:04:27 [INFO]: Epoch 090 - training loss: 0.2376, validation loss: 0.1643
2024-05-24 23:04:27 [INFO]: Epoch 091 - training loss: 0.2336, validation loss: 0.1618
2024-05-24 23:04:27 [INFO]: Epoch 092 - training loss: 0.2328, validation loss: 0.1635
2024-05-24 23:04:28 [INFO]: Epoch 093 - training loss: 0.2338, validation loss: 0.1616
2024-05-24 23:04:28 [INFO]: Epoch 094 - training loss: 0.2331, validation loss: 0.1625
2024-05-24 23:04:28 [INFO]: Epoch 095 - training loss: 0.2322, validation loss: 0.1620
2024-05-24 23:04:29 [INFO]: Epoch 096 - training loss: 0.2323, validation loss: 0.1611
2024-05-24 23:04:29 [INFO]: Epoch 097 - training loss: 0.2333, validation loss: 0.1608
2024-05-24 23:04:29 [INFO]: Epoch 098 - training loss: 0.2304, validation loss: 0.1605
2024-05-24 23:04:30 [INFO]: Epoch 099 - training loss: 0.2299, validation loss: 0.1611
2024-05-24 23:04:30 [INFO]: Epoch 100 - training loss: 0.2287, validation loss: 0.1588
2024-05-24 23:04:30 [INFO]: Epoch 101 - training loss: 0.2287, validation loss: 0.1623
2024-05-24 23:04:30 [INFO]: Epoch 102 - training loss: 0.2326, validation loss: 0.1628
2024-05-24 23:04:31 [INFO]: Epoch 103 - training loss: 0.2328, validation loss: 0.1620
2024-05-24 23:04:31 [INFO]: Epoch 104 - training loss: 0.2286, validation loss: 0.1586
2024-05-24 23:04:31 [INFO]: Epoch 105 - training loss: 0.2283, validation loss: 0.1582
2024-05-24 23:04:32 [INFO]: Epoch 106 - training loss: 0.2264, validation loss: 0.1599
2024-05-24 23:04:32 [INFO]: Epoch 107 - training loss: 0.2258, validation loss: 0.1593
2024-05-24 23:04:32 [INFO]: Epoch 108 - training loss: 0.2261, validation loss: 0.1601
2024-05-24 23:04:33 [INFO]: Epoch 109 - training loss: 0.2261, validation loss: 0.1584
2024-05-24 23:04:33 [INFO]: Epoch 110 - training loss: 0.2250, validation loss: 0.1578
2024-05-24 23:04:33 [INFO]: Epoch 111 - training loss: 0.2233, validation loss: 0.1574
2024-05-24 23:04:33 [INFO]: Epoch 112 - training loss: 0.2239, validation loss: 0.1583
2024-05-24 23:04:34 [INFO]: Epoch 113 - training loss: 0.2234, validation loss: 0.1570
2024-05-24 23:04:34 [INFO]: Epoch 114 - training loss: 0.2238, validation loss: 0.1584
2024-05-24 23:04:34 [INFO]: Epoch 115 - training loss: 0.2245, validation loss: 0.1575
2024-05-24 23:04:35 [INFO]: Epoch 116 - training loss: 0.2241, validation loss: 0.1568
2024-05-24 23:04:35 [INFO]: Epoch 117 - training loss: 0.2209, validation loss: 0.1574
2024-05-24 23:04:35 [INFO]: Epoch 118 - training loss: 0.2201, validation loss: 0.1564
2024-05-24 23:04:36 [INFO]: Epoch 119 - training loss: 0.2222, validation loss: 0.1576
2024-05-24 23:04:36 [INFO]: Epoch 120 - training loss: 0.2246, validation loss: 0.1581
2024-05-24 23:04:36 [INFO]: Epoch 121 - training loss: 0.2194, validation loss: 0.1552
2024-05-24 23:04:37 [INFO]: Epoch 122 - training loss: 0.2209, validation loss: 0.1581
2024-05-24 23:04:37 [INFO]: Epoch 123 - training loss: 0.2179, validation loss: 0.1565
2024-05-24 23:04:37 [INFO]: Epoch 124 - training loss: 0.2188, validation loss: 0.1561
2024-05-24 23:04:37 [INFO]: Epoch 125 - training loss: 0.2203, validation loss: 0.1551
2024-05-24 23:04:38 [INFO]: Epoch 126 - training loss: 0.2169, validation loss: 0.1551
2024-05-24 23:04:38 [INFO]: Epoch 127 - training loss: 0.2175, validation loss: 0.1542
2024-05-24 23:04:38 [INFO]: Epoch 128 - training loss: 0.2160, validation loss: 0.1541
2024-05-24 23:04:39 [INFO]: Epoch 129 - training loss: 0.2156, validation loss: 0.1530
2024-05-24 23:04:39 [INFO]: Epoch 130 - training loss: 0.2165, validation loss: 0.1537
2024-05-24 23:04:39 [INFO]: Epoch 131 - training loss: 0.2157, validation loss: 0.1555
2024-05-24 23:04:40 [INFO]: Epoch 132 - training loss: 0.2154, validation loss: 0.1543
2024-05-24 23:04:40 [INFO]: Epoch 133 - training loss: 0.2153, validation loss: 0.1533
2024-05-24 23:04:40 [INFO]: Epoch 134 - training loss: 0.2151, validation loss: 0.1534
2024-05-24 23:04:41 [INFO]: Epoch 135 - training loss: 0.2159, validation loss: 0.1530
2024-05-24 23:04:41 [INFO]: Epoch 136 - training loss: 0.2170, validation loss: 0.1534
2024-05-24 23:04:41 [INFO]: Epoch 137 - training loss: 0.2134, validation loss: 0.1527
2024-05-24 23:04:41 [INFO]: Epoch 138 - training loss: 0.2132, validation loss: 0.1535
2024-05-24 23:04:42 [INFO]: Epoch 139 - training loss: 0.2132, validation loss: 0.1531
2024-05-24 23:04:42 [INFO]: Epoch 140 - training loss: 0.2140, validation loss: 0.1530
2024-05-24 23:04:42 [INFO]: Epoch 141 - training loss: 0.2127, validation loss: 0.1527
2024-05-24 23:04:43 [INFO]: Epoch 142 - training loss: 0.2120, validation loss: 0.1513
2024-05-24 23:04:43 [INFO]: Epoch 143 - training loss: 0.2147, validation loss: 0.1528
2024-05-24 23:04:43 [INFO]: Epoch 144 - training loss: 0.2126, validation loss: 0.1520
2024-05-24 23:04:44 [INFO]: Epoch 145 - training loss: 0.2122, validation loss: 0.1502
2024-05-24 23:04:44 [INFO]: Epoch 146 - training loss: 0.2117, validation loss: 0.1509
2024-05-24 23:04:44 [INFO]: Epoch 147 - training loss: 0.2103, validation loss: 0.1523
2024-05-24 23:04:45 [INFO]: Epoch 148 - training loss: 0.2142, validation loss: 0.1510
2024-05-24 23:04:45 [INFO]: Epoch 149 - training loss: 0.2114, validation loss: 0.1522
2024-05-24 23:04:45 [INFO]: Epoch 150 - training loss: 0.2120, validation loss: 0.1505
2024-05-24 23:04:45 [INFO]: Epoch 151 - training loss: 0.2118, validation loss: 0.1501
2024-05-24 23:04:46 [INFO]: Epoch 152 - training loss: 0.2090, validation loss: 0.1521
2024-05-24 23:04:46 [INFO]: Epoch 153 - training loss: 0.2087, validation loss: 0.1497
2024-05-24 23:04:46 [INFO]: Epoch 154 - training loss: 0.2099, validation loss: 0.1510
2024-05-24 23:04:47 [INFO]: Epoch 155 - training loss: 0.2093, validation loss: 0.1504
2024-05-24 23:04:47 [INFO]: Epoch 156 - training loss: 0.2087, validation loss: 0.1491
2024-05-24 23:04:47 [INFO]: Epoch 157 - training loss: 0.2096, validation loss: 0.1535
2024-05-24 23:04:48 [INFO]: Epoch 158 - training loss: 0.2073, validation loss: 0.1497
2024-05-24 23:04:48 [INFO]: Epoch 159 - training loss: 0.2063, validation loss: 0.1480
2024-05-24 23:04:48 [INFO]: Epoch 160 - training loss: 0.2066, validation loss: 0.1491
2024-05-24 23:04:49 [INFO]: Epoch 161 - training loss: 0.2056, validation loss: 0.1479
2024-05-24 23:04:49 [INFO]: Epoch 162 - training loss: 0.2051, validation loss: 0.1507
2024-05-24 23:04:49 [INFO]: Epoch 163 - training loss: 0.2078, validation loss: 0.1492
2024-05-24 23:04:49 [INFO]: Epoch 164 - training loss: 0.2077, validation loss: 0.1500
2024-05-24 23:04:50 [INFO]: Epoch 165 - training loss: 0.2058, validation loss: 0.1482
2024-05-24 23:04:50 [INFO]: Epoch 166 - training loss: 0.2050, validation loss: 0.1499
2024-05-24 23:04:50 [INFO]: Epoch 167 - training loss: 0.2059, validation loss: 0.1475
2024-05-24 23:04:51 [INFO]: Epoch 168 - training loss: 0.2067, validation loss: 0.1478
2024-05-24 23:04:51 [INFO]: Epoch 169 - training loss: 0.2063, validation loss: 0.1500
2024-05-24 23:04:51 [INFO]: Epoch 170 - training loss: 0.2078, validation loss: 0.1496
2024-05-24 23:04:52 [INFO]: Epoch 171 - training loss: 0.2064, validation loss: 0.1480
2024-05-24 23:04:52 [INFO]: Epoch 172 - training loss: 0.2045, validation loss: 0.1467
2024-05-24 23:04:52 [INFO]: Epoch 173 - training loss: 0.2061, validation loss: 0.1473
2024-05-24 23:04:52 [INFO]: Epoch 174 - training loss: 0.2050, validation loss: 0.1485
2024-05-24 23:04:53 [INFO]: Epoch 175 - training loss: 0.2032, validation loss: 0.1471
2024-05-24 23:04:53 [INFO]: Epoch 176 - training loss: 0.2025, validation loss: 0.1484
2024-05-24 23:04:53 [INFO]: Epoch 177 - training loss: 0.2015, validation loss: 0.1470
2024-05-24 23:04:54 [INFO]: Epoch 178 - training loss: 0.2008, validation loss: 0.1478
2024-05-24 23:04:54 [INFO]: Epoch 179 - training loss: 0.2005, validation loss: 0.1464
2024-05-24 23:04:54 [INFO]: Epoch 180 - training loss: 0.2009, validation loss: 0.1459
2024-05-24 23:04:55 [INFO]: Epoch 181 - training loss: 0.1997, validation loss: 0.1474
2024-05-24 23:04:55 [INFO]: Epoch 182 - training loss: 0.1994, validation loss: 0.1463
2024-05-24 23:04:55 [INFO]: Epoch 183 - training loss: 0.2002, validation loss: 0.1459
2024-05-24 23:04:56 [INFO]: Epoch 184 - training loss: 0.1992, validation loss: 0.1456
2024-05-24 23:04:56 [INFO]: Epoch 185 - training loss: 0.1979, validation loss: 0.1446
2024-05-24 23:04:56 [INFO]: Epoch 186 - training loss: 0.1994, validation loss: 0.1475
2024-05-24 23:04:56 [INFO]: Epoch 187 - training loss: 0.1998, validation loss: 0.1462
2024-05-24 23:04:57 [INFO]: Epoch 188 - training loss: 0.1983, validation loss: 0.1454
2024-05-24 23:04:57 [INFO]: Epoch 189 - training loss: 0.1980, validation loss: 0.1458
2024-05-24 23:04:57 [INFO]: Epoch 190 - training loss: 0.1976, validation loss: 0.1459
2024-05-24 23:04:58 [INFO]: Epoch 191 - training loss: 0.1996, validation loss: 0.1455
2024-05-24 23:04:58 [INFO]: Epoch 192 - training loss: 0.2002, validation loss: 0.1448
2024-05-24 23:04:58 [INFO]: Epoch 193 - training loss: 0.1993, validation loss: 0.1443
2024-05-24 23:04:59 [INFO]: Epoch 194 - training loss: 0.1984, validation loss: 0.1456
2024-05-24 23:04:59 [INFO]: Epoch 195 - training loss: 0.1966, validation loss: 0.1437
2024-05-24 23:04:59 [INFO]: Epoch 196 - training loss: 0.1971, validation loss: 0.1445
2024-05-24 23:05:00 [INFO]: Epoch 197 - training loss: 0.1960, validation loss: 0.1445
2024-05-24 23:05:00 [INFO]: Epoch 198 - training loss: 0.1977, validation loss: 0.1442
2024-05-24 23:05:00 [INFO]: Epoch 199 - training loss: 0.1967, validation loss: 0.1441
2024-05-24 23:05:00 [INFO]: Epoch 200 - training loss: 0.1961, validation loss: 0.1456
2024-05-24 23:05:01 [INFO]: Epoch 201 - training loss: 0.1968, validation loss: 0.1443
2024-05-24 23:05:01 [INFO]: Epoch 202 - training loss: 0.1968, validation loss: 0.1446
2024-05-24 23:05:01 [INFO]: Epoch 203 - training loss: 0.1952, validation loss: 0.1443
2024-05-24 23:05:02 [INFO]: Epoch 204 - training loss: 0.1946, validation loss: 0.1452
2024-05-24 23:05:02 [INFO]: Epoch 205 - training loss: 0.1955, validation loss: 0.1449
2024-05-24 23:05:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:05:02 [INFO]: Finished training. The best model is from epoch#195.
2024-05-24 23:05:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/Transformer_air_quality/20240524_T230359/Transformer.pypots
2024-05-24 23:05:02 [INFO]: Transformer on Air-Quality: MAE=0.1642, MSE=0.1283
2024-05-24 23:05:02 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-24 23:05:02 [INFO]: Using the given device: cuda:0
2024-05-24 23:05:02 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T230502
2024-05-24 23:05:02 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T230502/tensorboard
2024-05-24 23:05:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-24 23:05:03 [INFO]: Epoch 001 - training loss: 0.2906, validation loss: 0.2698
2024-05-24 23:05:04 [INFO]: Epoch 002 - training loss: 0.2237, validation loss: 0.2347
2024-05-24 23:05:04 [INFO]: Epoch 003 - training loss: 0.2020, validation loss: 0.2207
2024-05-24 23:05:05 [INFO]: Epoch 004 - training loss: 0.1813, validation loss: 0.2086
2024-05-24 23:05:05 [INFO]: Epoch 005 - training loss: 0.1792, validation loss: 0.2062
2024-05-24 23:05:06 [INFO]: Epoch 006 - training loss: 0.1697, validation loss: 0.1943
2024-05-24 23:05:07 [INFO]: Epoch 007 - training loss: 0.1709, validation loss: 0.1876
2024-05-24 23:05:07 [INFO]: Epoch 008 - training loss: 0.1495, validation loss: 0.1863
2024-05-24 23:05:08 [INFO]: Epoch 009 - training loss: 0.1513, validation loss: 0.1874
2024-05-24 23:05:08 [INFO]: Epoch 010 - training loss: 0.1590, validation loss: 0.1828
2024-05-24 23:05:09 [INFO]: Epoch 011 - training loss: 0.1517, validation loss: 0.1775
2024-05-24 23:05:09 [INFO]: Epoch 012 - training loss: 0.1401, validation loss: 0.1752
2024-05-24 23:05:10 [INFO]: Epoch 013 - training loss: 0.1468, validation loss: 0.1755
2024-05-24 23:05:10 [INFO]: Epoch 014 - training loss: 0.1396, validation loss: 0.1769
2024-05-24 23:05:11 [INFO]: Epoch 015 - training loss: 0.1462, validation loss: 0.1837
2024-05-24 23:05:11 [INFO]: Epoch 016 - training loss: 0.1434, validation loss: 0.1793
2024-05-24 23:05:12 [INFO]: Epoch 017 - training loss: 0.1527, validation loss: 0.1822
2024-05-24 23:05:12 [INFO]: Epoch 018 - training loss: 0.1394, validation loss: 0.1732
2024-05-24 23:05:13 [INFO]: Epoch 019 - training loss: 0.1251, validation loss: 0.1744
2024-05-24 23:05:13 [INFO]: Epoch 020 - training loss: 0.1383, validation loss: 0.1775
2024-05-24 23:05:14 [INFO]: Epoch 021 - training loss: 0.1252, validation loss: 0.1733
2024-05-24 23:05:14 [INFO]: Epoch 022 - training loss: 0.1386, validation loss: 0.1753
2024-05-24 23:05:15 [INFO]: Epoch 023 - training loss: 0.1383, validation loss: 0.1702
2024-05-24 23:05:15 [INFO]: Epoch 024 - training loss: 0.1443, validation loss: 0.1692
2024-05-24 23:05:16 [INFO]: Epoch 025 - training loss: 0.1258, validation loss: 0.1662
2024-05-24 23:05:16 [INFO]: Epoch 026 - training loss: 0.1163, validation loss: 0.1654
2024-05-24 23:05:17 [INFO]: Epoch 027 - training loss: 0.1109, validation loss: 0.1692
2024-05-24 23:05:17 [INFO]: Epoch 028 - training loss: 0.1205, validation loss: 0.1662
2024-05-24 23:05:18 [INFO]: Epoch 029 - training loss: 0.1138, validation loss: 0.1673
2024-05-24 23:05:18 [INFO]: Epoch 030 - training loss: 0.1082, validation loss: 0.1647
2024-05-24 23:05:19 [INFO]: Epoch 031 - training loss: 0.1138, validation loss: 0.1605
2024-05-24 23:05:19 [INFO]: Epoch 032 - training loss: 0.1208, validation loss: 0.1634
2024-05-24 23:05:20 [INFO]: Epoch 033 - training loss: 0.1535, validation loss: 0.1700
2024-05-24 23:05:20 [INFO]: Epoch 034 - training loss: 0.1197, validation loss: 0.1679
2024-05-24 23:05:21 [INFO]: Epoch 035 - training loss: 0.1143, validation loss: 0.1663
2024-05-24 23:05:21 [INFO]: Epoch 036 - training loss: 0.1011, validation loss: 0.1687
2024-05-24 23:05:22 [INFO]: Epoch 037 - training loss: 0.1070, validation loss: 0.1683
2024-05-24 23:05:23 [INFO]: Epoch 038 - training loss: 0.1200, validation loss: 0.1634
2024-05-24 23:05:23 [INFO]: Epoch 039 - training loss: 0.1280, validation loss: 0.1616
2024-05-24 23:05:24 [INFO]: Epoch 040 - training loss: 0.1015, validation loss: 0.1607
2024-05-24 23:05:24 [INFO]: Epoch 041 - training loss: 0.1012, validation loss: 0.1611
2024-05-24 23:05:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:05:24 [INFO]: Finished training. The best model is from epoch#31.
2024-05-24 23:05:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/TimesNet_air_quality/20240524_T230502/TimesNet.pypots
2024-05-24 23:05:24 [INFO]: TimesNet on Air-Quality: MAE=0.1668, MSE=0.1591
2024-05-24 23:05:24 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-24 23:05:24 [INFO]: Using the given device: cuda:0
2024-05-24 23:05:24 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524
2024-05-24 23:05:24 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/tensorboard
2024-05-24 23:05:24 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-24 23:05:41 [INFO]: Epoch 001 - training loss: 0.5308, validation loss: 0.3429
2024-05-24 23:05:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch1_loss0.3429050952196121.pypots
2024-05-24 23:05:58 [INFO]: Epoch 002 - training loss: 0.2979, validation loss: 0.2951
2024-05-24 23:05:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch2_loss0.29514912962913514.pypots
2024-05-24 23:06:15 [INFO]: Epoch 003 - training loss: 0.2764, validation loss: 0.2508
2024-05-24 23:06:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch3_loss0.2507718726992607.pypots
2024-05-24 23:06:32 [INFO]: Epoch 004 - training loss: 0.2658, validation loss: 0.2163
2024-05-24 23:06:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch4_loss0.21631492376327516.pypots
2024-05-24 23:06:49 [INFO]: Epoch 005 - training loss: 0.2227, validation loss: 0.1939
2024-05-24 23:06:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch5_loss0.19392276406288148.pypots
2024-05-24 23:07:06 [INFO]: Epoch 006 - training loss: 0.2317, validation loss: 0.1767
2024-05-24 23:07:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch6_loss0.17666486501693726.pypots
2024-05-24 23:07:22 [INFO]: Epoch 007 - training loss: 0.2056, validation loss: 0.1786
2024-05-24 23:07:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch7_loss0.17855396419763564.pypots
2024-05-24 23:07:39 [INFO]: Epoch 008 - training loss: 0.1898, validation loss: 0.1624
2024-05-24 23:07:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch8_loss0.162447889149189.pypots
2024-05-24 23:07:56 [INFO]: Epoch 009 - training loss: 0.1934, validation loss: 0.1727
2024-05-24 23:07:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch9_loss0.17266112715005874.pypots
2024-05-24 23:08:13 [INFO]: Epoch 010 - training loss: 0.1944, validation loss: 0.1598
2024-05-24 23:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch10_loss0.15981415063142776.pypots
2024-05-24 23:08:30 [INFO]: Epoch 011 - training loss: 0.1702, validation loss: 0.1543
2024-05-24 23:08:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch11_loss0.154275082051754.pypots
2024-05-24 23:08:47 [INFO]: Epoch 012 - training loss: 0.1669, validation loss: 0.1490
2024-05-24 23:08:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch12_loss0.1489578053355217.pypots
2024-05-24 23:09:03 [INFO]: Epoch 013 - training loss: 0.1642, validation loss: 0.1561
2024-05-24 23:09:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch13_loss0.15606947839260102.pypots
2024-05-24 23:09:20 [INFO]: Epoch 014 - training loss: 0.1923, validation loss: 0.1532
2024-05-24 23:09:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch14_loss0.15324065685272217.pypots
2024-05-24 23:09:37 [INFO]: Epoch 015 - training loss: 0.1790, validation loss: 0.1468
2024-05-24 23:09:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch15_loss0.14683637768030167.pypots
2024-05-24 23:09:54 [INFO]: Epoch 016 - training loss: 0.1616, validation loss: 0.1424
2024-05-24 23:09:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch16_loss0.1423882856965065.pypots
2024-05-24 23:10:11 [INFO]: Epoch 017 - training loss: 0.1468, validation loss: 0.1393
2024-05-24 23:10:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch17_loss0.139252108335495.pypots
2024-05-24 23:10:28 [INFO]: Epoch 018 - training loss: 0.1653, validation loss: 0.1426
2024-05-24 23:10:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch18_loss0.14261538460850715.pypots
2024-05-24 23:10:44 [INFO]: Epoch 019 - training loss: 0.1548, validation loss: 0.1401
2024-05-24 23:10:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch19_loss0.1400989219546318.pypots
2024-05-24 23:11:01 [INFO]: Epoch 020 - training loss: 0.1519, validation loss: 0.1376
2024-05-24 23:11:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch20_loss0.1376037783920765.pypots
2024-05-24 23:11:18 [INFO]: Epoch 021 - training loss: 0.1573, validation loss: 0.1441
2024-05-24 23:11:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch21_loss0.1441466525197029.pypots
2024-05-24 23:11:35 [INFO]: Epoch 022 - training loss: 0.1620, validation loss: 0.1388
2024-05-24 23:11:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch22_loss0.13883838579058647.pypots
2024-05-24 23:11:52 [INFO]: Epoch 023 - training loss: 0.1552, validation loss: 0.1364
2024-05-24 23:11:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch23_loss0.1364361487329006.pypots
2024-05-24 23:12:09 [INFO]: Epoch 024 - training loss: 0.1479, validation loss: 0.1338
2024-05-24 23:12:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch24_loss0.1338106282055378.pypots
2024-05-24 23:12:26 [INFO]: Epoch 025 - training loss: 0.1502, validation loss: 0.1333
2024-05-24 23:12:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch25_loss0.1332806184887886.pypots
2024-05-24 23:12:43 [INFO]: Epoch 026 - training loss: 0.1401, validation loss: 0.1319
2024-05-24 23:12:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch26_loss0.13191487714648248.pypots
2024-05-24 23:12:59 [INFO]: Epoch 027 - training loss: 0.1586, validation loss: 0.1368
2024-05-24 23:12:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch27_loss0.1367981731891632.pypots
2024-05-24 23:13:16 [INFO]: Epoch 028 - training loss: 0.1596, validation loss: 0.1357
2024-05-24 23:13:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch28_loss0.1357427380979061.pypots
2024-05-24 23:13:33 [INFO]: Epoch 029 - training loss: 0.1466, validation loss: 0.1351
2024-05-24 23:13:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch29_loss0.13508501872420312.pypots
2024-05-24 23:13:50 [INFO]: Epoch 030 - training loss: 0.1564, validation loss: 0.1348
2024-05-24 23:13:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch30_loss0.13480543047189714.pypots
2024-05-24 23:14:07 [INFO]: Epoch 031 - training loss: 0.1312, validation loss: 0.1311
2024-05-24 23:14:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch31_loss0.13106374442577362.pypots
2024-05-24 23:14:24 [INFO]: Epoch 032 - training loss: 0.1510, validation loss: 0.1285
2024-05-24 23:14:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch32_loss0.12853246852755545.pypots
2024-05-24 23:14:40 [INFO]: Epoch 033 - training loss: 0.1283, validation loss: 0.1296
2024-05-24 23:14:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch33_loss0.12963838055729865.pypots
2024-05-24 23:14:57 [INFO]: Epoch 034 - training loss: 0.1389, validation loss: 0.1302
2024-05-24 23:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch34_loss0.1302200198173523.pypots
2024-05-24 23:15:14 [INFO]: Epoch 035 - training loss: 0.1412, validation loss: 0.1288
2024-05-24 23:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch35_loss0.12879118993878363.pypots
2024-05-24 23:15:31 [INFO]: Epoch 036 - training loss: 0.1379, validation loss: 0.1309
2024-05-24 23:15:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch36_loss0.13090614527463912.pypots
2024-05-24 23:15:48 [INFO]: Epoch 037 - training loss: 0.1320, validation loss: 0.1256
2024-05-24 23:15:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch37_loss0.12562449276447296.pypots
2024-05-24 23:16:05 [INFO]: Epoch 038 - training loss: 0.1335, validation loss: 0.1341
2024-05-24 23:16:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch38_loss0.13412986248731612.pypots
2024-05-24 23:16:21 [INFO]: Epoch 039 - training loss: 0.1269, validation loss: 0.1291
2024-05-24 23:16:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch39_loss0.12912893891334534.pypots
2024-05-24 23:16:38 [INFO]: Epoch 040 - training loss: 0.1348, validation loss: 0.1272
2024-05-24 23:16:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch40_loss0.1271613731980324.pypots
2024-05-24 23:16:55 [INFO]: Epoch 041 - training loss: 0.1353, validation loss: 0.1343
2024-05-24 23:16:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch41_loss0.13434548079967498.pypots
2024-05-24 23:17:12 [INFO]: Epoch 042 - training loss: 0.1338, validation loss: 0.1212
2024-05-24 23:17:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch42_loss0.12123639807105065.pypots
2024-05-24 23:17:29 [INFO]: Epoch 043 - training loss: 0.1312, validation loss: 0.1208
2024-05-24 23:17:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch43_loss0.12075304612517357.pypots
2024-05-24 23:17:46 [INFO]: Epoch 044 - training loss: 0.1246, validation loss: 0.1216
2024-05-24 23:17:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch44_loss0.12158441469073296.pypots
2024-05-24 23:18:02 [INFO]: Epoch 045 - training loss: 0.1349, validation loss: 0.1216
2024-05-24 23:18:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch45_loss0.12160057425498963.pypots
2024-05-24 23:18:19 [INFO]: Epoch 046 - training loss: 0.1352, validation loss: 0.1201
2024-05-24 23:18:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch46_loss0.12011608481407166.pypots
2024-05-24 23:18:36 [INFO]: Epoch 047 - training loss: 0.1239, validation loss: 0.1195
2024-05-24 23:18:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch47_loss0.11946909055113793.pypots
2024-05-24 23:18:53 [INFO]: Epoch 048 - training loss: 0.1258, validation loss: 0.1190
2024-05-24 23:18:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch48_loss0.11897042915225028.pypots
2024-05-24 23:19:10 [INFO]: Epoch 049 - training loss: 0.1357, validation loss: 0.1195
2024-05-24 23:19:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch49_loss0.11949982419610024.pypots
2024-05-24 23:19:27 [INFO]: Epoch 050 - training loss: 0.1302, validation loss: 0.1190
2024-05-24 23:19:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch50_loss0.11896070688962937.pypots
2024-05-24 23:19:43 [INFO]: Epoch 051 - training loss: 0.1306, validation loss: 0.1230
2024-05-24 23:19:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch51_loss0.12299706414341927.pypots
2024-05-24 23:20:00 [INFO]: Epoch 052 - training loss: 0.1297, validation loss: 0.1188
2024-05-24 23:20:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch52_loss0.1187864325940609.pypots
2024-05-24 23:20:17 [INFO]: Epoch 053 - training loss: 0.1039, validation loss: 0.1173
2024-05-24 23:20:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch53_loss0.11725916415452957.pypots
2024-05-24 23:20:34 [INFO]: Epoch 054 - training loss: 0.1318, validation loss: 0.1154
2024-05-24 23:20:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch54_loss0.11539733409881592.pypots
2024-05-24 23:20:51 [INFO]: Epoch 055 - training loss: 0.1402, validation loss: 0.1153
2024-05-24 23:20:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch55_loss0.11534436419606209.pypots
2024-05-24 23:21:08 [INFO]: Epoch 056 - training loss: 0.1314, validation loss: 0.1193
2024-05-24 23:21:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch56_loss0.1192567341029644.pypots
2024-05-24 23:21:24 [INFO]: Epoch 057 - training loss: 0.1278, validation loss: 0.1150
2024-05-24 23:21:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch57_loss0.11503581628203392.pypots
2024-05-24 23:21:41 [INFO]: Epoch 058 - training loss: 0.1262, validation loss: 0.1199
2024-05-24 23:21:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch58_loss0.11994896978139877.pypots
2024-05-24 23:21:58 [INFO]: Epoch 059 - training loss: 0.1281, validation loss: 0.1190
2024-05-24 23:21:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch59_loss0.11901541650295258.pypots
2024-05-24 23:22:15 [INFO]: Epoch 060 - training loss: 0.1048, validation loss: 0.1135
2024-05-24 23:22:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch60_loss0.1135475568473339.pypots
2024-05-24 23:22:32 [INFO]: Epoch 061 - training loss: 0.1332, validation loss: 0.1176
2024-05-24 23:22:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch61_loss0.1176333524286747.pypots
2024-05-24 23:22:49 [INFO]: Epoch 062 - training loss: 0.1424, validation loss: 0.1242
2024-05-24 23:22:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch62_loss0.1241637907922268.pypots
2024-05-24 23:23:05 [INFO]: Epoch 063 - training loss: 0.1181, validation loss: 0.1167
2024-05-24 23:23:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch63_loss0.11666319817304611.pypots
2024-05-24 23:23:22 [INFO]: Epoch 064 - training loss: 0.1218, validation loss: 0.1140
2024-05-24 23:23:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch64_loss0.11397403329610825.pypots
2024-05-24 23:23:39 [INFO]: Epoch 065 - training loss: 0.1154, validation loss: 0.1126
2024-05-24 23:23:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch65_loss0.11257006898522377.pypots
2024-05-24 23:23:56 [INFO]: Epoch 066 - training loss: 0.1211, validation loss: 0.1121
2024-05-24 23:23:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch66_loss0.1121179960668087.pypots
2024-05-24 23:24:13 [INFO]: Epoch 067 - training loss: 0.1100, validation loss: 0.1120
2024-05-24 23:24:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch67_loss0.11199785098433494.pypots
2024-05-24 23:24:30 [INFO]: Epoch 068 - training loss: 0.1194, validation loss: 0.1094
2024-05-24 23:24:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch68_loss0.10942794978618622.pypots
2024-05-24 23:24:46 [INFO]: Epoch 069 - training loss: 0.1312, validation loss: 0.1103
2024-05-24 23:24:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch69_loss0.11028221771121025.pypots
2024-05-24 23:25:03 [INFO]: Epoch 070 - training loss: 0.1136, validation loss: 0.1142
2024-05-24 23:25:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch70_loss0.11415894255042076.pypots
2024-05-24 23:25:20 [INFO]: Epoch 071 - training loss: 0.1294, validation loss: 0.1128
2024-05-24 23:25:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch71_loss0.11277914345264435.pypots
2024-05-24 23:25:37 [INFO]: Epoch 072 - training loss: 0.1112, validation loss: 0.1150
2024-05-24 23:25:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch72_loss0.11503156647086143.pypots
2024-05-24 23:25:54 [INFO]: Epoch 073 - training loss: 0.1263, validation loss: 0.1100
2024-05-24 23:25:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch73_loss0.10998791232705116.pypots
2024-05-24 23:26:11 [INFO]: Epoch 074 - training loss: 0.1270, validation loss: 0.1081
2024-05-24 23:26:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch74_loss0.1081387884914875.pypots
2024-05-24 23:26:27 [INFO]: Epoch 075 - training loss: 0.1198, validation loss: 0.1080
2024-05-24 23:26:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch75_loss0.10802290067076684.pypots
2024-05-24 23:26:44 [INFO]: Epoch 076 - training loss: 0.1274, validation loss: 0.1085
2024-05-24 23:26:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch76_loss0.10851053595542907.pypots
2024-05-24 23:27:01 [INFO]: Epoch 077 - training loss: 0.1176, validation loss: 0.1083
2024-05-24 23:27:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch77_loss0.10833204537630081.pypots
2024-05-24 23:27:18 [INFO]: Epoch 078 - training loss: 0.1333, validation loss: 0.1117
2024-05-24 23:27:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch78_loss0.11171633005142212.pypots
2024-05-24 23:27:35 [INFO]: Epoch 079 - training loss: 0.1154, validation loss: 0.1084
2024-05-24 23:27:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch79_loss0.10836397483944893.pypots
2024-05-24 23:27:52 [INFO]: Epoch 080 - training loss: 0.1139, validation loss: 0.1115
2024-05-24 23:27:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch80_loss0.11145844757556915.pypots
2024-05-24 23:28:08 [INFO]: Epoch 081 - training loss: 0.1276, validation loss: 0.1098
2024-05-24 23:28:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch81_loss0.10976941585540771.pypots
2024-05-24 23:28:25 [INFO]: Epoch 082 - training loss: 0.1223, validation loss: 0.1079
2024-05-24 23:28:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch82_loss0.10792788416147232.pypots
2024-05-24 23:28:42 [INFO]: Epoch 083 - training loss: 0.1132, validation loss: 0.1074
2024-05-24 23:28:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch83_loss0.10742975249886513.pypots
2024-05-24 23:28:59 [INFO]: Epoch 084 - training loss: 0.1144, validation loss: 0.1086
2024-05-24 23:28:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch84_loss0.10855870172381402.pypots
2024-05-24 23:29:16 [INFO]: Epoch 085 - training loss: 0.1153, validation loss: 0.1087
2024-05-24 23:29:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch85_loss0.10868489667773247.pypots
2024-05-24 23:29:33 [INFO]: Epoch 086 - training loss: 0.1172, validation loss: 0.1075
2024-05-24 23:29:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch86_loss0.10751609727740288.pypots
2024-05-24 23:29:49 [INFO]: Epoch 087 - training loss: 0.1186, validation loss: 0.1070
2024-05-24 23:29:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch87_loss0.10702716112136841.pypots
2024-05-24 23:30:06 [INFO]: Epoch 088 - training loss: 0.1156, validation loss: 0.1061
2024-05-24 23:30:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch88_loss0.1060706302523613.pypots
2024-05-24 23:30:23 [INFO]: Epoch 089 - training loss: 0.1127, validation loss: 0.1084
2024-05-24 23:30:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch89_loss0.10836905762553214.pypots
2024-05-24 23:30:40 [INFO]: Epoch 090 - training loss: 0.1092, validation loss: 0.1066
2024-05-24 23:30:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch90_loss0.10658616870641709.pypots
2024-05-24 23:30:57 [INFO]: Epoch 091 - training loss: 0.1108, validation loss: 0.1113
2024-05-24 23:30:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch91_loss0.11130327880382537.pypots
2024-05-24 23:31:14 [INFO]: Epoch 092 - training loss: 0.1222, validation loss: 0.1089
2024-05-24 23:31:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch92_loss0.10894781649112702.pypots
2024-05-24 23:31:30 [INFO]: Epoch 093 - training loss: 0.1089, validation loss: 0.1085
2024-05-24 23:31:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch93_loss0.10854514390230179.pypots
2024-05-24 23:31:47 [INFO]: Epoch 094 - training loss: 0.1011, validation loss: 0.1090
2024-05-24 23:31:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch94_loss0.1089511476457119.pypots
2024-05-24 23:32:04 [INFO]: Epoch 095 - training loss: 0.1186, validation loss: 0.1054
2024-05-24 23:32:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch95_loss0.10541430413722992.pypots
2024-05-24 23:32:21 [INFO]: Epoch 096 - training loss: 0.1190, validation loss: 0.1059
2024-05-24 23:32:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch96_loss0.10593458190560341.pypots
2024-05-24 23:32:38 [INFO]: Epoch 097 - training loss: 0.1113, validation loss: 0.1122
2024-05-24 23:32:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch97_loss0.11220169961452484.pypots
2024-05-24 23:32:55 [INFO]: Epoch 098 - training loss: 0.1215, validation loss: 0.1065
2024-05-24 23:32:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch98_loss0.10650171712040901.pypots
2024-05-24 23:33:12 [INFO]: Epoch 099 - training loss: 0.1089, validation loss: 0.1063
2024-05-24 23:33:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch99_loss0.10625875666737557.pypots
2024-05-24 23:33:28 [INFO]: Epoch 100 - training loss: 0.1133, validation loss: 0.1123
2024-05-24 23:33:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch100_loss0.11226532384753227.pypots
2024-05-24 23:33:45 [INFO]: Epoch 101 - training loss: 0.1287, validation loss: 0.1079
2024-05-24 23:33:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch101_loss0.10788607522845269.pypots
2024-05-24 23:34:02 [INFO]: Epoch 102 - training loss: 0.1173, validation loss: 0.1051
2024-05-24 23:34:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch102_loss0.10508181229233741.pypots
2024-05-24 23:34:19 [INFO]: Epoch 103 - training loss: 0.1185, validation loss: 0.1061
2024-05-24 23:34:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch103_loss0.10608032867312431.pypots
2024-05-24 23:34:36 [INFO]: Epoch 104 - training loss: 0.1107, validation loss: 0.1048
2024-05-24 23:34:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch104_loss0.1048029527068138.pypots
2024-05-24 23:34:53 [INFO]: Epoch 105 - training loss: 0.1194, validation loss: 0.1054
2024-05-24 23:34:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch105_loss0.10537872985005378.pypots
2024-05-24 23:35:09 [INFO]: Epoch 106 - training loss: 0.1303, validation loss: 0.1062
2024-05-24 23:35:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch106_loss0.10624504536390304.pypots
2024-05-24 23:35:26 [INFO]: Epoch 107 - training loss: 0.1042, validation loss: 0.1047
2024-05-24 23:35:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch107_loss0.10470268055796624.pypots
2024-05-24 23:35:43 [INFO]: Epoch 108 - training loss: 0.1188, validation loss: 0.1068
2024-05-24 23:35:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch108_loss0.10675101280212403.pypots
2024-05-24 23:36:00 [INFO]: Epoch 109 - training loss: 0.1278, validation loss: 0.1092
2024-05-24 23:36:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch109_loss0.10924590900540351.pypots
2024-05-24 23:36:17 [INFO]: Epoch 110 - training loss: 0.1104, validation loss: 0.1046
2024-05-24 23:36:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch110_loss0.10457545891404152.pypots
2024-05-24 23:36:34 [INFO]: Epoch 111 - training loss: 0.1046, validation loss: 0.1084
2024-05-24 23:36:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch111_loss0.10839173123240471.pypots
2024-05-24 23:36:50 [INFO]: Epoch 112 - training loss: 0.1142, validation loss: 0.1040
2024-05-24 23:36:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch112_loss0.10396294295787811.pypots
2024-05-24 23:37:07 [INFO]: Epoch 113 - training loss: 0.1112, validation loss: 0.1026
2024-05-24 23:37:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch113_loss0.1026091992855072.pypots
2024-05-24 23:37:24 [INFO]: Epoch 114 - training loss: 0.1247, validation loss: 0.1032
2024-05-24 23:37:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch114_loss0.10316826030611992.pypots
2024-05-24 23:37:41 [INFO]: Epoch 115 - training loss: 0.1066, validation loss: 0.1052
2024-05-24 23:37:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch115_loss0.10519916787743569.pypots
2024-05-24 23:37:58 [INFO]: Epoch 116 - training loss: 0.0998, validation loss: 0.1054
2024-05-24 23:37:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch116_loss0.10540182888507843.pypots
2024-05-24 23:38:15 [INFO]: Epoch 117 - training loss: 0.1219, validation loss: 0.1051
2024-05-24 23:38:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch117_loss0.10510041192173958.pypots
2024-05-24 23:38:32 [INFO]: Epoch 118 - training loss: 0.1061, validation loss: 0.1054
2024-05-24 23:38:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch118_loss0.10537489876151085.pypots
2024-05-24 23:38:48 [INFO]: Epoch 119 - training loss: 0.1135, validation loss: 0.1037
2024-05-24 23:38:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch119_loss0.10373446717858315.pypots
2024-05-24 23:39:05 [INFO]: Epoch 120 - training loss: 0.1061, validation loss: 0.1035
2024-05-24 23:39:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch120_loss0.10350550711154938.pypots
2024-05-24 23:39:22 [INFO]: Epoch 121 - training loss: 0.1099, validation loss: 0.1097
2024-05-24 23:39:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch121_loss0.1096788264811039.pypots
2024-05-24 23:39:39 [INFO]: Epoch 122 - training loss: 0.1230, validation loss: 0.1051
2024-05-24 23:39:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch122_loss0.10512761175632476.pypots
2024-05-24 23:39:56 [INFO]: Epoch 123 - training loss: 0.1139, validation loss: 0.1071
2024-05-24 23:39:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI_epoch123_loss0.10706788375973701.pypots
2024-05-24 23:39:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:39:56 [INFO]: Finished training. The best model is from epoch#113.
2024-05-24 23:39:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/CSDI_air_quality/20240524_T230524/CSDI.pypots
2024-05-24 23:42:16 [INFO]: CSDI on Air-Quality: MAE=0.1138, MSE=0.2758
2024-05-24 23:42:16 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-24 23:42:16 [INFO]: Using the given device: cuda:0
2024-05-24 23:42:16 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T234216
2024-05-24 23:42:16 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T234216/tensorboard
2024-05-24 23:42:16 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-24 23:42:17 [INFO]: Epoch 001 - training loss: 64217.6746, validation loss: 0.6868
2024-05-24 23:42:17 [INFO]: Epoch 002 - training loss: 42067.4876, validation loss: 0.6081
2024-05-24 23:42:17 [INFO]: Epoch 003 - training loss: 41758.7539, validation loss: 0.5666
2024-05-24 23:42:18 [INFO]: Epoch 004 - training loss: 41631.6898, validation loss: 0.4894
2024-05-24 23:42:18 [INFO]: Epoch 005 - training loss: 41535.0664, validation loss: 0.4449
2024-05-24 23:42:18 [INFO]: Epoch 006 - training loss: 41478.4815, validation loss: 0.3956
2024-05-24 23:42:19 [INFO]: Epoch 007 - training loss: 41434.7536, validation loss: 0.4097
2024-05-24 23:42:19 [INFO]: Epoch 008 - training loss: 41440.2462, validation loss: 0.3832
2024-05-24 23:42:19 [INFO]: Epoch 009 - training loss: 41384.6733, validation loss: 0.3620
2024-05-24 23:42:20 [INFO]: Epoch 010 - training loss: 41380.4194, validation loss: 0.3749
2024-05-24 23:42:20 [INFO]: Epoch 011 - training loss: 41352.9314, validation loss: 0.3538
2024-05-24 23:42:20 [INFO]: Epoch 012 - training loss: 41356.4957, validation loss: 0.3614
2024-05-24 23:42:21 [INFO]: Epoch 013 - training loss: 41328.1361, validation loss: 0.3558
2024-05-24 23:42:21 [INFO]: Epoch 014 - training loss: 41384.9637, validation loss: 0.4360
2024-05-24 23:42:21 [INFO]: Epoch 015 - training loss: 41334.5479, validation loss: 0.3270
2024-05-24 23:42:21 [INFO]: Epoch 016 - training loss: 41296.0352, validation loss: 0.3456
2024-05-24 23:42:22 [INFO]: Epoch 017 - training loss: 41293.1207, validation loss: 0.3194
2024-05-24 23:42:22 [INFO]: Epoch 018 - training loss: 41282.0304, validation loss: 0.3168
2024-05-24 23:42:22 [INFO]: Epoch 019 - training loss: 41259.1110, validation loss: 0.3097
2024-05-24 23:42:23 [INFO]: Epoch 020 - training loss: 41252.3030, validation loss: 0.3365
2024-05-24 23:42:23 [INFO]: Epoch 021 - training loss: 41249.9018, validation loss: 0.3026
2024-05-24 23:42:23 [INFO]: Epoch 022 - training loss: 41248.2567, validation loss: 0.3059
2024-05-24 23:42:24 [INFO]: Epoch 023 - training loss: 41302.6528, validation loss: 0.3507
2024-05-24 23:42:24 [INFO]: Epoch 024 - training loss: 41338.2700, validation loss: 0.3057
2024-05-24 23:42:24 [INFO]: Epoch 025 - training loss: 41267.2836, validation loss: 0.2968
2024-05-24 23:42:25 [INFO]: Epoch 026 - training loss: 41237.7798, validation loss: 0.2929
2024-05-24 23:42:25 [INFO]: Epoch 027 - training loss: 41236.1191, validation loss: 0.2895
2024-05-24 23:42:25 [INFO]: Epoch 028 - training loss: 41222.3139, validation loss: 0.2899
2024-05-24 23:42:25 [INFO]: Epoch 029 - training loss: 41215.1153, validation loss: 0.2915
2024-05-24 23:42:26 [INFO]: Epoch 030 - training loss: 41221.5511, validation loss: 0.2931
2024-05-24 23:42:26 [INFO]: Epoch 031 - training loss: 41213.4692, validation loss: 0.2804
2024-05-24 23:42:26 [INFO]: Epoch 032 - training loss: 41209.8251, validation loss: 0.2859
2024-05-24 23:42:27 [INFO]: Epoch 033 - training loss: 41215.1968, validation loss: 0.2895
2024-05-24 23:42:27 [INFO]: Epoch 034 - training loss: 41218.0697, validation loss: 0.2951
2024-05-24 23:42:27 [INFO]: Epoch 035 - training loss: 41220.5043, validation loss: 0.3269
2024-05-24 23:42:28 [INFO]: Epoch 036 - training loss: 41233.4200, validation loss: 0.2920
2024-05-24 23:42:28 [INFO]: Epoch 037 - training loss: 41202.6700, validation loss: 0.2850
2024-05-24 23:42:28 [INFO]: Epoch 038 - training loss: 41207.4277, validation loss: 0.2878
2024-05-24 23:42:29 [INFO]: Epoch 039 - training loss: 41192.1276, validation loss: 0.2717
2024-05-24 23:42:29 [INFO]: Epoch 040 - training loss: 41183.5282, validation loss: 0.2718
2024-05-24 23:42:29 [INFO]: Epoch 041 - training loss: 41179.0033, validation loss: 0.2593
2024-05-24 23:42:29 [INFO]: Epoch 042 - training loss: 41179.8339, validation loss: 0.2631
2024-05-24 23:42:30 [INFO]: Epoch 043 - training loss: 41187.7759, validation loss: 0.2545
2024-05-24 23:42:30 [INFO]: Epoch 044 - training loss: 41198.3362, validation loss: 0.2799
2024-05-24 23:42:30 [INFO]: Epoch 045 - training loss: 41192.5768, validation loss: 0.2642
2024-05-24 23:42:31 [INFO]: Epoch 046 - training loss: 41191.6882, validation loss: 0.2786
2024-05-24 23:42:31 [INFO]: Epoch 047 - training loss: 41183.8759, validation loss: 0.2747
2024-05-24 23:42:31 [INFO]: Epoch 048 - training loss: 41179.4133, validation loss: 0.2654
2024-05-24 23:42:32 [INFO]: Epoch 049 - training loss: 41186.8371, validation loss: 0.2620
2024-05-24 23:42:32 [INFO]: Epoch 050 - training loss: 41252.6250, validation loss: 0.3027
2024-05-24 23:42:32 [INFO]: Epoch 051 - training loss: 41207.1360, validation loss: 0.2810
2024-05-24 23:42:33 [INFO]: Epoch 052 - training loss: 41188.2034, validation loss: 0.2678
2024-05-24 23:42:33 [INFO]: Epoch 053 - training loss: 41182.8725, validation loss: 0.2609
2024-05-24 23:42:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:42:33 [INFO]: Finished training. The best model is from epoch#43.
2024-05-24 23:42:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/GPVAE_air_quality/20240524_T234216/GPVAE.pypots
2024-05-24 23:42:33 [INFO]: GP-VAE on Air-Quality: MAE=0.3069, MSE=0.2584
2024-05-24 23:42:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-24 23:42:33 [INFO]: Using the given device: cuda:0
2024-05-24 23:42:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T234233
2024-05-24 23:42:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T234233/tensorboard
2024-05-24 23:42:33 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-24 23:42:38 [INFO]: Epoch 001 - generator training loss: 0.6092, discriminator training loss: 0.2867, validation loss: 0.5253
2024-05-24 23:42:42 [INFO]: Epoch 002 - generator training loss: 0.2965, discriminator training loss: 0.0670, validation loss: 0.4033
2024-05-24 23:42:46 [INFO]: Epoch 003 - generator training loss: 0.2190, discriminator training loss: 0.0630, validation loss: 0.3337
2024-05-24 23:42:50 [INFO]: Epoch 004 - generator training loss: 0.1847, discriminator training loss: 0.0622, validation loss: 0.2932
2024-05-24 23:42:54 [INFO]: Epoch 005 - generator training loss: 0.1575, discriminator training loss: 0.0615, validation loss: 0.2653
2024-05-24 23:42:58 [INFO]: Epoch 006 - generator training loss: 0.1378, discriminator training loss: 0.0613, validation loss: 0.2474
2024-05-24 23:43:02 [INFO]: Epoch 007 - generator training loss: 0.1271, discriminator training loss: 0.0609, validation loss: 0.2334
2024-05-24 23:43:06 [INFO]: Epoch 008 - generator training loss: 0.1158, discriminator training loss: 0.0600, validation loss: 0.2233
2024-05-24 23:43:11 [INFO]: Epoch 009 - generator training loss: 0.1089, discriminator training loss: 0.0596, validation loss: 0.2148
2024-05-24 23:43:15 [INFO]: Epoch 010 - generator training loss: 0.1019, discriminator training loss: 0.0585, validation loss: 0.2080
2024-05-24 23:43:19 [INFO]: Epoch 011 - generator training loss: 0.1001, discriminator training loss: 0.0576, validation loss: 0.2016
2024-05-24 23:43:23 [INFO]: Epoch 012 - generator training loss: 0.0910, discriminator training loss: 0.0569, validation loss: 0.1970
2024-05-24 23:43:27 [INFO]: Epoch 013 - generator training loss: 0.0885, discriminator training loss: 0.0554, validation loss: 0.1931
2024-05-24 23:43:31 [INFO]: Epoch 014 - generator training loss: 0.0883, discriminator training loss: 0.0537, validation loss: 0.1897
2024-05-24 23:43:35 [INFO]: Epoch 015 - generator training loss: 0.0827, discriminator training loss: 0.0522, validation loss: 0.1859
2024-05-24 23:43:39 [INFO]: Epoch 016 - generator training loss: 0.0811, discriminator training loss: 0.0507, validation loss: 0.1834
2024-05-24 23:43:43 [INFO]: Epoch 017 - generator training loss: 0.0801, discriminator training loss: 0.0485, validation loss: 0.1812
2024-05-24 23:43:47 [INFO]: Epoch 018 - generator training loss: 0.0780, discriminator training loss: 0.0476, validation loss: 0.1791
2024-05-24 23:43:51 [INFO]: Epoch 019 - generator training loss: 0.0783, discriminator training loss: 0.0462, validation loss: 0.1765
2024-05-24 23:43:55 [INFO]: Epoch 020 - generator training loss: 0.0754, discriminator training loss: 0.0459, validation loss: 0.1755
2024-05-24 23:43:59 [INFO]: Epoch 021 - generator training loss: 0.0739, discriminator training loss: 0.0450, validation loss: 0.1736
2024-05-24 23:44:03 [INFO]: Epoch 022 - generator training loss: 0.0755, discriminator training loss: 0.0440, validation loss: 0.1718
2024-05-24 23:44:07 [INFO]: Epoch 023 - generator training loss: 0.0713, discriminator training loss: 0.0434, validation loss: 0.1705
2024-05-24 23:44:11 [INFO]: Epoch 024 - generator training loss: 0.0705, discriminator training loss: 0.0425, validation loss: 0.1695
2024-05-24 23:44:16 [INFO]: Epoch 025 - generator training loss: 0.0696, discriminator training loss: 0.0416, validation loss: 0.1672
2024-05-24 23:44:20 [INFO]: Epoch 026 - generator training loss: 0.0683, discriminator training loss: 0.0412, validation loss: 0.1663
2024-05-24 23:44:24 [INFO]: Epoch 027 - generator training loss: 0.0676, discriminator training loss: 0.0402, validation loss: 0.1657
2024-05-24 23:44:28 [INFO]: Epoch 028 - generator training loss: 0.0679, discriminator training loss: 0.0396, validation loss: 0.1643
2024-05-24 23:44:32 [INFO]: Epoch 029 - generator training loss: 0.0665, discriminator training loss: 0.0384, validation loss: 0.1635
2024-05-24 23:44:36 [INFO]: Epoch 030 - generator training loss: 0.0665, discriminator training loss: 0.0375, validation loss: 0.1627
2024-05-24 23:44:40 [INFO]: Epoch 031 - generator training loss: 0.0674, discriminator training loss: 0.0370, validation loss: 0.1625
2024-05-24 23:44:44 [INFO]: Epoch 032 - generator training loss: 0.0637, discriminator training loss: 0.0364, validation loss: 0.1609
2024-05-24 23:44:48 [INFO]: Epoch 033 - generator training loss: 0.0629, discriminator training loss: 0.0357, validation loss: 0.1598
2024-05-24 23:44:52 [INFO]: Epoch 034 - generator training loss: 0.0621, discriminator training loss: 0.0346, validation loss: 0.1589
2024-05-24 23:44:56 [INFO]: Epoch 035 - generator training loss: 0.0620, discriminator training loss: 0.0339, validation loss: 0.1589
2024-05-24 23:45:00 [INFO]: Epoch 036 - generator training loss: 0.0607, discriminator training loss: 0.0330, validation loss: 0.1576
2024-05-24 23:45:04 [INFO]: Epoch 037 - generator training loss: 0.0600, discriminator training loss: 0.0323, validation loss: 0.1567
2024-05-24 23:45:08 [INFO]: Epoch 038 - generator training loss: 0.0604, discriminator training loss: 0.0316, validation loss: 0.1570
2024-05-24 23:45:12 [INFO]: Epoch 039 - generator training loss: 0.0592, discriminator training loss: 0.0316, validation loss: 0.1562
2024-05-24 23:45:17 [INFO]: Epoch 040 - generator training loss: 0.0585, discriminator training loss: 0.0308, validation loss: 0.1548
2024-05-24 23:45:21 [INFO]: Epoch 041 - generator training loss: 0.0584, discriminator training loss: 0.0301, validation loss: 0.1540
2024-05-24 23:45:25 [INFO]: Epoch 042 - generator training loss: 0.0598, discriminator training loss: 0.0291, validation loss: 0.1544
2024-05-24 23:45:29 [INFO]: Epoch 043 - generator training loss: 0.0572, discriminator training loss: 0.0289, validation loss: 0.1538
2024-05-24 23:45:33 [INFO]: Epoch 044 - generator training loss: 0.0570, discriminator training loss: 0.0285, validation loss: 0.1529
2024-05-24 23:45:37 [INFO]: Epoch 045 - generator training loss: 0.0555, discriminator training loss: 0.0277, validation loss: 0.1515
2024-05-24 23:45:41 [INFO]: Epoch 046 - generator training loss: 0.0556, discriminator training loss: 0.0273, validation loss: 0.1515
2024-05-24 23:45:45 [INFO]: Epoch 047 - generator training loss: 0.0551, discriminator training loss: 0.0266, validation loss: 0.1520
2024-05-24 23:45:49 [INFO]: Epoch 048 - generator training loss: 0.0544, discriminator training loss: 0.0263, validation loss: 0.1510
2024-05-24 23:45:53 [INFO]: Epoch 049 - generator training loss: 0.0545, discriminator training loss: 0.0258, validation loss: 0.1506
2024-05-24 23:45:57 [INFO]: Epoch 050 - generator training loss: 0.0538, discriminator training loss: 0.0254, validation loss: 0.1502
2024-05-24 23:46:01 [INFO]: Epoch 051 - generator training loss: 0.0545, discriminator training loss: 0.0250, validation loss: 0.1498
2024-05-24 23:46:05 [INFO]: Epoch 052 - generator training loss: 0.0538, discriminator training loss: 0.0246, validation loss: 0.1493
2024-05-24 23:46:09 [INFO]: Epoch 053 - generator training loss: 0.0543, discriminator training loss: 0.0242, validation loss: 0.1489
2024-05-24 23:46:13 [INFO]: Epoch 054 - generator training loss: 0.0522, discriminator training loss: 0.0239, validation loss: 0.1489
2024-05-24 23:46:17 [INFO]: Epoch 055 - generator training loss: 0.0533, discriminator training loss: 0.0237, validation loss: 0.1488
2024-05-24 23:46:22 [INFO]: Epoch 056 - generator training loss: 0.0517, discriminator training loss: 0.0233, validation loss: 0.1482
2024-05-24 23:46:26 [INFO]: Epoch 057 - generator training loss: 0.0517, discriminator training loss: 0.0229, validation loss: 0.1478
2024-05-24 23:46:30 [INFO]: Epoch 058 - generator training loss: 0.0518, discriminator training loss: 0.0228, validation loss: 0.1479
2024-05-24 23:46:34 [INFO]: Epoch 059 - generator training loss: 0.0510, discriminator training loss: 0.0223, validation loss: 0.1462
2024-05-24 23:46:38 [INFO]: Epoch 060 - generator training loss: 0.0510, discriminator training loss: 0.0222, validation loss: 0.1469
2024-05-24 23:46:42 [INFO]: Epoch 061 - generator training loss: 0.0505, discriminator training loss: 0.0217, validation loss: 0.1469
2024-05-24 23:46:46 [INFO]: Epoch 062 - generator training loss: 0.0499, discriminator training loss: 0.0215, validation loss: 0.1464
2024-05-24 23:46:50 [INFO]: Epoch 063 - generator training loss: 0.0498, discriminator training loss: 0.0211, validation loss: 0.1465
2024-05-24 23:46:54 [INFO]: Epoch 064 - generator training loss: 0.0500, discriminator training loss: 0.0209, validation loss: 0.1470
2024-05-24 23:46:58 [INFO]: Epoch 065 - generator training loss: 0.0498, discriminator training loss: 0.0205, validation loss: 0.1453
2024-05-24 23:47:02 [INFO]: Epoch 066 - generator training loss: 0.0485, discriminator training loss: 0.0205, validation loss: 0.1461
2024-05-24 23:47:06 [INFO]: Epoch 067 - generator training loss: 0.0481, discriminator training loss: 0.0203, validation loss: 0.1454
2024-05-24 23:47:10 [INFO]: Epoch 068 - generator training loss: 0.0501, discriminator training loss: 0.0200, validation loss: 0.1457
2024-05-24 23:47:14 [INFO]: Epoch 069 - generator training loss: 0.0492, discriminator training loss: 0.0197, validation loss: 0.1455
2024-05-24 23:47:18 [INFO]: Epoch 070 - generator training loss: 0.0479, discriminator training loss: 0.0198, validation loss: 0.1452
2024-05-24 23:47:22 [INFO]: Epoch 071 - generator training loss: 0.0467, discriminator training loss: 0.0193, validation loss: 0.1456
2024-05-24 23:47:27 [INFO]: Epoch 072 - generator training loss: 0.0465, discriminator training loss: 0.0190, validation loss: 0.1445
2024-05-24 23:47:31 [INFO]: Epoch 073 - generator training loss: 0.0462, discriminator training loss: 0.0189, validation loss: 0.1455
2024-05-24 23:47:35 [INFO]: Epoch 074 - generator training loss: 0.0461, discriminator training loss: 0.0187, validation loss: 0.1445
2024-05-24 23:47:39 [INFO]: Epoch 075 - generator training loss: 0.0454, discriminator training loss: 0.0188, validation loss: 0.1445
2024-05-24 23:47:43 [INFO]: Epoch 076 - generator training loss: 0.0454, discriminator training loss: 0.0184, validation loss: 0.1451
2024-05-24 23:47:47 [INFO]: Epoch 077 - generator training loss: 0.0449, discriminator training loss: 0.0184, validation loss: 0.1448
2024-05-24 23:47:51 [INFO]: Epoch 078 - generator training loss: 0.0459, discriminator training loss: 0.0180, validation loss: 0.1460
2024-05-24 23:47:55 [INFO]: Epoch 079 - generator training loss: 0.0450, discriminator training loss: 0.0177, validation loss: 0.1447
2024-05-24 23:47:59 [INFO]: Epoch 080 - generator training loss: 0.0452, discriminator training loss: 0.0176, validation loss: 0.1447
2024-05-24 23:48:03 [INFO]: Epoch 081 - generator training loss: 0.0448, discriminator training loss: 0.0176, validation loss: 0.1454
2024-05-24 23:48:07 [INFO]: Epoch 082 - generator training loss: 0.0440, discriminator training loss: 0.0173, validation loss: 0.1443
2024-05-24 23:48:11 [INFO]: Epoch 083 - generator training loss: 0.0437, discriminator training loss: 0.0173, validation loss: 0.1442
2024-05-24 23:48:15 [INFO]: Epoch 084 - generator training loss: 0.0450, discriminator training loss: 0.0172, validation loss: 0.1439
2024-05-24 23:48:19 [INFO]: Epoch 085 - generator training loss: 0.0437, discriminator training loss: 0.0171, validation loss: 0.1438
2024-05-24 23:48:23 [INFO]: Epoch 086 - generator training loss: 0.0434, discriminator training loss: 0.0170, validation loss: 0.1455
2024-05-24 23:48:28 [INFO]: Epoch 087 - generator training loss: 0.0433, discriminator training loss: 0.0168, validation loss: 0.1442
2024-05-24 23:48:32 [INFO]: Epoch 088 - generator training loss: 0.0433, discriminator training loss: 0.0168, validation loss: 0.1443
2024-05-24 23:48:36 [INFO]: Epoch 089 - generator training loss: 0.0424, discriminator training loss: 0.0164, validation loss: 0.1443
2024-05-24 23:48:40 [INFO]: Epoch 090 - generator training loss: 0.0429, discriminator training loss: 0.0164, validation loss: 0.1443
2024-05-24 23:48:44 [INFO]: Epoch 091 - generator training loss: 0.0416, discriminator training loss: 0.0163, validation loss: 0.1444
2024-05-24 23:48:48 [INFO]: Epoch 092 - generator training loss: 0.0416, discriminator training loss: 0.0162, validation loss: 0.1453
2024-05-24 23:48:52 [INFO]: Epoch 093 - generator training loss: 0.0414, discriminator training loss: 0.0162, validation loss: 0.1452
2024-05-24 23:48:56 [INFO]: Epoch 094 - generator training loss: 0.0416, discriminator training loss: 0.0160, validation loss: 0.1445
2024-05-24 23:49:00 [INFO]: Epoch 095 - generator training loss: 0.0415, discriminator training loss: 0.0159, validation loss: 0.1448
2024-05-24 23:49:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 23:49:00 [INFO]: Finished training. The best model is from epoch#85.
2024-05-24 23:49:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/USGAN_air_quality/20240524_T234233/USGAN.pypots
2024-05-24 23:49:01 [INFO]: US-GAN on Air-Quality: MAE=0.2120, MSE=0.1378
2024-05-24 23:49:01 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-24 23:49:01 [INFO]: Using the given device: cuda:0
2024-05-24 23:49:01 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234901
2024-05-24 23:49:01 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234901/tensorboard
2024-05-24 23:49:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-24 23:49:04 [INFO]: Epoch 001 - training loss: 1.4080, validation loss: 0.9600
2024-05-24 23:49:07 [INFO]: Epoch 002 - training loss: 1.1331, validation loss: 0.7191
2024-05-24 23:49:10 [INFO]: Epoch 003 - training loss: 0.9417, validation loss: 0.6091
2024-05-24 23:49:13 [INFO]: Epoch 004 - training loss: 0.8333, validation loss: 0.5406
2024-05-24 23:49:15 [INFO]: Epoch 005 - training loss: 0.7590, validation loss: 0.4888
2024-05-24 23:49:18 [INFO]: Epoch 006 - training loss: 0.7011, validation loss: 0.4504
2024-05-24 23:49:21 [INFO]: Epoch 007 - training loss: 0.6574, validation loss: 0.4190
2024-05-24 23:49:24 [INFO]: Epoch 008 - training loss: 0.6233, validation loss: 0.3942
2024-05-24 23:49:27 [INFO]: Epoch 009 - training loss: 0.5961, validation loss: 0.3738
2024-05-24 23:49:29 [INFO]: Epoch 010 - training loss: 0.5749, validation loss: 0.3571
2024-05-24 23:49:32 [INFO]: Epoch 011 - training loss: 0.5568, validation loss: 0.3433
2024-05-24 23:49:35 [INFO]: Epoch 012 - training loss: 0.5406, validation loss: 0.3307
2024-05-24 23:49:38 [INFO]: Epoch 013 - training loss: 0.5282, validation loss: 0.3205
2024-05-24 23:49:41 [INFO]: Epoch 014 - training loss: 0.5149, validation loss: 0.3115
2024-05-24 23:49:43 [INFO]: Epoch 015 - training loss: 0.5049, validation loss: 0.3038
2024-05-24 23:49:46 [INFO]: Epoch 016 - training loss: 0.4956, validation loss: 0.2965
2024-05-24 23:49:49 [INFO]: Epoch 017 - training loss: 0.4864, validation loss: 0.2905
2024-05-24 23:49:52 [INFO]: Epoch 018 - training loss: 0.4787, validation loss: 0.2846
2024-05-24 23:49:55 [INFO]: Epoch 019 - training loss: 0.4707, validation loss: 0.2793
2024-05-24 23:49:58 [INFO]: Epoch 020 - training loss: 0.4619, validation loss: 0.2746
2024-05-24 23:50:00 [INFO]: Epoch 021 - training loss: 0.4547, validation loss: 0.2702
2024-05-24 23:50:03 [INFO]: Epoch 022 - training loss: 0.4491, validation loss: 0.2656
2024-05-24 23:50:06 [INFO]: Epoch 023 - training loss: 0.4422, validation loss: 0.2620
2024-05-24 23:50:09 [INFO]: Epoch 024 - training loss: 0.4361, validation loss: 0.2574
2024-05-24 23:50:11 [INFO]: Epoch 025 - training loss: 0.4301, validation loss: 0.2542
2024-05-24 23:50:14 [INFO]: Epoch 026 - training loss: 0.4252, validation loss: 0.2505
2024-05-24 23:50:17 [INFO]: Epoch 027 - training loss: 0.4192, validation loss: 0.2472
2024-05-24 23:50:20 [INFO]: Epoch 028 - training loss: 0.4146, validation loss: 0.2442
2024-05-24 23:50:23 [INFO]: Epoch 029 - training loss: 0.4095, validation loss: 0.2412
2024-05-24 23:50:25 [INFO]: Epoch 030 - training loss: 0.4050, validation loss: 0.2382
2024-05-24 23:50:28 [INFO]: Epoch 031 - training loss: 0.4003, validation loss: 0.2350
2024-05-24 23:50:31 [INFO]: Epoch 032 - training loss: 0.3955, validation loss: 0.2319
2024-05-24 23:50:34 [INFO]: Epoch 033 - training loss: 0.3922, validation loss: 0.2293
2024-05-24 23:50:37 [INFO]: Epoch 034 - training loss: 0.3878, validation loss: 0.2265
2024-05-24 23:50:39 [INFO]: Epoch 035 - training loss: 0.3836, validation loss: 0.2233
2024-05-24 23:50:42 [INFO]: Epoch 036 - training loss: 0.3803, validation loss: 0.2211
2024-05-24 23:50:45 [INFO]: Epoch 037 - training loss: 0.3761, validation loss: 0.2186
2024-05-24 23:50:48 [INFO]: Epoch 038 - training loss: 0.3730, validation loss: 0.2164
2024-05-24 23:50:51 [INFO]: Epoch 039 - training loss: 0.3697, validation loss: 0.2139
2024-05-24 23:50:53 [INFO]: Epoch 040 - training loss: 0.3657, validation loss: 0.2111
2024-05-24 23:50:56 [INFO]: Epoch 041 - training loss: 0.3636, validation loss: 0.2088
2024-05-24 23:50:59 [INFO]: Epoch 042 - training loss: 0.3604, validation loss: 0.2069
2024-05-24 23:51:02 [INFO]: Epoch 043 - training loss: 0.3570, validation loss: 0.2043
2024-05-24 23:51:05 [INFO]: Epoch 044 - training loss: 0.3546, validation loss: 0.2024
2024-05-24 23:51:07 [INFO]: Epoch 045 - training loss: 0.3523, validation loss: 0.2004
2024-05-24 23:51:10 [INFO]: Epoch 046 - training loss: 0.3496, validation loss: 0.1979
2024-05-24 23:51:13 [INFO]: Epoch 047 - training loss: 0.3473, validation loss: 0.1962
2024-05-24 23:51:16 [INFO]: Epoch 048 - training loss: 0.3442, validation loss: 0.1943
2024-05-24 23:51:19 [INFO]: Epoch 049 - training loss: 0.3418, validation loss: 0.1926
2024-05-24 23:51:21 [INFO]: Epoch 050 - training loss: 0.3391, validation loss: 0.1908
2024-05-24 23:51:24 [INFO]: Epoch 051 - training loss: 0.3365, validation loss: 0.1893
2024-05-24 23:51:27 [INFO]: Epoch 052 - training loss: 0.3351, validation loss: 0.1875
2024-05-24 23:51:30 [INFO]: Epoch 053 - training loss: 0.3323, validation loss: 0.1861
2024-05-24 23:51:33 [INFO]: Epoch 054 - training loss: 0.3302, validation loss: 0.1845
2024-05-24 23:51:35 [INFO]: Epoch 055 - training loss: 0.3286, validation loss: 0.1830
2024-05-24 23:51:38 [INFO]: Epoch 056 - training loss: 0.3277, validation loss: 0.1822
2024-05-24 23:51:41 [INFO]: Epoch 057 - training loss: 0.3251, validation loss: 0.1800
2024-05-24 23:51:44 [INFO]: Epoch 058 - training loss: 0.3238, validation loss: 0.1790
2024-05-24 23:51:47 [INFO]: Epoch 059 - training loss: 0.3215, validation loss: 0.1778
2024-05-24 23:51:49 [INFO]: Epoch 060 - training loss: 0.3201, validation loss: 0.1765
2024-05-24 23:51:52 [INFO]: Epoch 061 - training loss: 0.3182, validation loss: 0.1757
2024-05-24 23:51:55 [INFO]: Epoch 062 - training loss: 0.3162, validation loss: 0.1745
2024-05-24 23:51:58 [INFO]: Epoch 063 - training loss: 0.3155, validation loss: 0.1734
2024-05-24 23:52:01 [INFO]: Epoch 064 - training loss: 0.3135, validation loss: 0.1723
2024-05-24 23:52:03 [INFO]: Epoch 065 - training loss: 0.3121, validation loss: 0.1714
2024-05-24 23:52:06 [INFO]: Epoch 066 - training loss: 0.3114, validation loss: 0.1705
2024-05-24 23:52:09 [INFO]: Epoch 067 - training loss: 0.3089, validation loss: 0.1695
2024-05-24 23:52:12 [INFO]: Epoch 068 - training loss: 0.3078, validation loss: 0.1688
2024-05-24 23:52:15 [INFO]: Epoch 069 - training loss: 0.3073, validation loss: 0.1682
2024-05-24 23:52:17 [INFO]: Epoch 070 - training loss: 0.3059, validation loss: 0.1668
2024-05-24 23:52:20 [INFO]: Epoch 071 - training loss: 0.3055, validation loss: 0.1665
2024-05-24 23:52:23 [INFO]: Epoch 072 - training loss: 0.3031, validation loss: 0.1650
2024-05-24 23:52:26 [INFO]: Epoch 073 - training loss: 0.3021, validation loss: 0.1645
2024-05-24 23:52:29 [INFO]: Epoch 074 - training loss: 0.3008, validation loss: 0.1638
2024-05-24 23:52:31 [INFO]: Epoch 075 - training loss: 0.2998, validation loss: 0.1629
2024-05-24 23:52:34 [INFO]: Epoch 076 - training loss: 0.2990, validation loss: 0.1624
2024-05-24 23:52:37 [INFO]: Epoch 077 - training loss: 0.2980, validation loss: 0.1620
2024-05-24 23:52:40 [INFO]: Epoch 078 - training loss: 0.2968, validation loss: 0.1612
2024-05-24 23:52:43 [INFO]: Epoch 079 - training loss: 0.2961, validation loss: 0.1604
2024-05-24 23:52:45 [INFO]: Epoch 080 - training loss: 0.2947, validation loss: 0.1600
2024-05-24 23:52:48 [INFO]: Epoch 081 - training loss: 0.2935, validation loss: 0.1592
2024-05-24 23:52:51 [INFO]: Epoch 082 - training loss: 0.2931, validation loss: 0.1588
2024-05-24 23:52:54 [INFO]: Epoch 083 - training loss: 0.2921, validation loss: 0.1579
2024-05-24 23:52:56 [INFO]: Epoch 084 - training loss: 0.2913, validation loss: 0.1577
2024-05-24 23:52:59 [INFO]: Epoch 085 - training loss: 0.2904, validation loss: 0.1567
2024-05-24 23:53:02 [INFO]: Epoch 086 - training loss: 0.2899, validation loss: 0.1561
2024-05-24 23:53:05 [INFO]: Epoch 087 - training loss: 0.2890, validation loss: 0.1556
2024-05-24 23:53:08 [INFO]: Epoch 088 - training loss: 0.2887, validation loss: 0.1552
2024-05-24 23:53:10 [INFO]: Epoch 089 - training loss: 0.2872, validation loss: 0.1548
2024-05-24 23:53:13 [INFO]: Epoch 090 - training loss: 0.2868, validation loss: 0.1542
2024-05-24 23:53:16 [INFO]: Epoch 091 - training loss: 0.2860, validation loss: 0.1535
2024-05-24 23:53:19 [INFO]: Epoch 092 - training loss: 0.2856, validation loss: 0.1533
2024-05-24 23:53:22 [INFO]: Epoch 093 - training loss: 0.2848, validation loss: 0.1525
2024-05-24 23:53:24 [INFO]: Epoch 094 - training loss: 0.2837, validation loss: 0.1521
2024-05-24 23:53:27 [INFO]: Epoch 095 - training loss: 0.2827, validation loss: 0.1513
2024-05-24 23:53:30 [INFO]: Epoch 096 - training loss: 0.2826, validation loss: 0.1508
2024-05-24 23:53:33 [INFO]: Epoch 097 - training loss: 0.2814, validation loss: 0.1505
2024-05-24 23:53:36 [INFO]: Epoch 098 - training loss: 0.2810, validation loss: 0.1502
2024-05-24 23:53:38 [INFO]: Epoch 099 - training loss: 0.2807, validation loss: 0.1496
2024-05-24 23:53:41 [INFO]: Epoch 100 - training loss: 0.2795, validation loss: 0.1492
2024-05-24 23:53:44 [INFO]: Epoch 101 - training loss: 0.2791, validation loss: 0.1486
2024-05-24 23:53:47 [INFO]: Epoch 102 - training loss: 0.2791, validation loss: 0.1484
2024-05-24 23:53:50 [INFO]: Epoch 103 - training loss: 0.2780, validation loss: 0.1480
2024-05-24 23:53:52 [INFO]: Epoch 104 - training loss: 0.2776, validation loss: 0.1477
2024-05-24 23:53:55 [INFO]: Epoch 105 - training loss: 0.2772, validation loss: 0.1473
2024-05-24 23:53:58 [INFO]: Epoch 106 - training loss: 0.2762, validation loss: 0.1469
2024-05-24 23:54:01 [INFO]: Epoch 107 - training loss: 0.2749, validation loss: 0.1464
2024-05-24 23:54:04 [INFO]: Epoch 108 - training loss: 0.2746, validation loss: 0.1459
2024-05-24 23:54:06 [INFO]: Epoch 109 - training loss: 0.2743, validation loss: 0.1456
2024-05-24 23:54:09 [INFO]: Epoch 110 - training loss: 0.2735, validation loss: 0.1452
2024-05-24 23:54:12 [INFO]: Epoch 111 - training loss: 0.2736, validation loss: 0.1449
2024-05-24 23:54:15 [INFO]: Epoch 112 - training loss: 0.2730, validation loss: 0.1447
2024-05-24 23:54:18 [INFO]: Epoch 113 - training loss: 0.2725, validation loss: 0.1442
2024-05-24 23:54:20 [INFO]: Epoch 114 - training loss: 0.2726, validation loss: 0.1441
2024-05-24 23:54:23 [INFO]: Epoch 115 - training loss: 0.2719, validation loss: 0.1435
2024-05-24 23:54:26 [INFO]: Epoch 116 - training loss: 0.2707, validation loss: 0.1430
2024-05-24 23:54:29 [INFO]: Epoch 117 - training loss: 0.2701, validation loss: 0.1427
2024-05-24 23:54:32 [INFO]: Epoch 118 - training loss: 0.2696, validation loss: 0.1425
2024-05-24 23:54:34 [INFO]: Epoch 119 - training loss: 0.2696, validation loss: 0.1422
2024-05-24 23:54:37 [INFO]: Epoch 120 - training loss: 0.2688, validation loss: 0.1417
2024-05-24 23:54:40 [INFO]: Epoch 121 - training loss: 0.2681, validation loss: 0.1416
2024-05-24 23:54:43 [INFO]: Epoch 122 - training loss: 0.2685, validation loss: 0.1412
2024-05-24 23:54:46 [INFO]: Epoch 123 - training loss: 0.2671, validation loss: 0.1407
2024-05-24 23:54:48 [INFO]: Epoch 124 - training loss: 0.2674, validation loss: 0.1404
2024-05-24 23:54:51 [INFO]: Epoch 125 - training loss: 0.2673, validation loss: 0.1402
2024-05-24 23:54:54 [INFO]: Epoch 126 - training loss: 0.2665, validation loss: 0.1401
2024-05-24 23:54:57 [INFO]: Epoch 127 - training loss: 0.2655, validation loss: 0.1399
2024-05-24 23:55:00 [INFO]: Epoch 128 - training loss: 0.2648, validation loss: 0.1392
2024-05-24 23:55:02 [INFO]: Epoch 129 - training loss: 0.2643, validation loss: 0.1391
2024-05-24 23:55:05 [INFO]: Epoch 130 - training loss: 0.2638, validation loss: 0.1388
2024-05-24 23:55:08 [INFO]: Epoch 131 - training loss: 0.2641, validation loss: 0.1385
2024-05-24 23:55:11 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1383
2024-05-24 23:55:14 [INFO]: Epoch 133 - training loss: 0.2630, validation loss: 0.1379
2024-05-24 23:55:16 [INFO]: Epoch 134 - training loss: 0.2628, validation loss: 0.1379
2024-05-24 23:55:19 [INFO]: Epoch 135 - training loss: 0.2621, validation loss: 0.1371
2024-05-24 23:55:22 [INFO]: Epoch 136 - training loss: 0.2620, validation loss: 0.1372
2024-05-24 23:55:25 [INFO]: Epoch 137 - training loss: 0.2614, validation loss: 0.1371
2024-05-24 23:55:27 [INFO]: Epoch 138 - training loss: 0.2608, validation loss: 0.1366
2024-05-24 23:55:30 [INFO]: Epoch 139 - training loss: 0.2606, validation loss: 0.1363
2024-05-24 23:55:33 [INFO]: Epoch 140 - training loss: 0.2609, validation loss: 0.1361
2024-05-24 23:55:36 [INFO]: Epoch 141 - training loss: 0.2602, validation loss: 0.1359
2024-05-24 23:55:39 [INFO]: Epoch 142 - training loss: 0.2593, validation loss: 0.1356
2024-05-24 23:55:41 [INFO]: Epoch 143 - training loss: 0.2587, validation loss: 0.1353
2024-05-24 23:55:44 [INFO]: Epoch 144 - training loss: 0.2582, validation loss: 0.1353
2024-05-24 23:55:47 [INFO]: Epoch 145 - training loss: 0.2585, validation loss: 0.1349
2024-05-24 23:55:50 [INFO]: Epoch 146 - training loss: 0.2586, validation loss: 0.1347
2024-05-24 23:55:53 [INFO]: Epoch 147 - training loss: 0.2576, validation loss: 0.1345
2024-05-24 23:55:56 [INFO]: Epoch 148 - training loss: 0.2582, validation loss: 0.1341
2024-05-24 23:55:58 [INFO]: Epoch 149 - training loss: 0.2579, validation loss: 0.1341
2024-05-24 23:56:01 [INFO]: Epoch 150 - training loss: 0.2565, validation loss: 0.1338
2024-05-24 23:56:04 [INFO]: Epoch 151 - training loss: 0.2566, validation loss: 0.1335
2024-05-24 23:56:07 [INFO]: Epoch 152 - training loss: 0.2557, validation loss: 0.1332
2024-05-24 23:56:10 [INFO]: Epoch 153 - training loss: 0.2554, validation loss: 0.1331
2024-05-24 23:56:12 [INFO]: Epoch 154 - training loss: 0.2555, validation loss: 0.1327
2024-05-24 23:56:15 [INFO]: Epoch 155 - training loss: 0.2549, validation loss: 0.1326
2024-05-24 23:56:18 [INFO]: Epoch 156 - training loss: 0.2551, validation loss: 0.1326
2024-05-24 23:56:21 [INFO]: Epoch 157 - training loss: 0.2547, validation loss: 0.1323
2024-05-24 23:56:24 [INFO]: Epoch 158 - training loss: 0.2541, validation loss: 0.1321
2024-05-24 23:56:26 [INFO]: Epoch 159 - training loss: 0.2539, validation loss: 0.1319
2024-05-24 23:56:29 [INFO]: Epoch 160 - training loss: 0.2533, validation loss: 0.1319
2024-05-24 23:56:32 [INFO]: Epoch 161 - training loss: 0.2527, validation loss: 0.1316
2024-05-24 23:56:35 [INFO]: Epoch 162 - training loss: 0.2525, validation loss: 0.1313
2024-05-24 23:56:38 [INFO]: Epoch 163 - training loss: 0.2528, validation loss: 0.1311
2024-05-24 23:56:40 [INFO]: Epoch 164 - training loss: 0.2525, validation loss: 0.1311
2024-05-24 23:56:43 [INFO]: Epoch 165 - training loss: 0.2524, validation loss: 0.1309
2024-05-24 23:56:46 [INFO]: Epoch 166 - training loss: 0.2517, validation loss: 0.1306
2024-05-24 23:56:49 [INFO]: Epoch 167 - training loss: 0.2514, validation loss: 0.1306
2024-05-24 23:56:51 [INFO]: Epoch 168 - training loss: 0.2515, validation loss: 0.1303
2024-05-24 23:56:54 [INFO]: Epoch 169 - training loss: 0.2502, validation loss: 0.1302
2024-05-24 23:56:57 [INFO]: Epoch 170 - training loss: 0.2510, validation loss: 0.1300
2024-05-24 23:57:00 [INFO]: Epoch 171 - training loss: 0.2505, validation loss: 0.1297
2024-05-24 23:57:03 [INFO]: Epoch 172 - training loss: 0.2499, validation loss: 0.1296
2024-05-24 23:57:05 [INFO]: Epoch 173 - training loss: 0.2497, validation loss: 0.1296
2024-05-24 23:57:08 [INFO]: Epoch 174 - training loss: 0.2497, validation loss: 0.1293
2024-05-24 23:57:11 [INFO]: Epoch 175 - training loss: 0.2494, validation loss: 0.1292
2024-05-24 23:57:14 [INFO]: Epoch 176 - training loss: 0.2488, validation loss: 0.1290
2024-05-24 23:57:17 [INFO]: Epoch 177 - training loss: 0.2491, validation loss: 0.1288
2024-05-24 23:57:19 [INFO]: Epoch 178 - training loss: 0.2483, validation loss: 0.1288
2024-05-24 23:57:22 [INFO]: Epoch 179 - training loss: 0.2491, validation loss: 0.1287
2024-05-24 23:57:25 [INFO]: Epoch 180 - training loss: 0.2484, validation loss: 0.1283
2024-05-24 23:57:28 [INFO]: Epoch 181 - training loss: 0.2481, validation loss: 0.1283
2024-05-24 23:57:31 [INFO]: Epoch 182 - training loss: 0.2477, validation loss: 0.1281
2024-05-24 23:57:33 [INFO]: Epoch 183 - training loss: 0.2483, validation loss: 0.1279
2024-05-24 23:57:36 [INFO]: Epoch 184 - training loss: 0.2471, validation loss: 0.1280
2024-05-24 23:57:39 [INFO]: Epoch 185 - training loss: 0.2471, validation loss: 0.1277
2024-05-24 23:57:42 [INFO]: Epoch 186 - training loss: 0.2466, validation loss: 0.1277
2024-05-24 23:57:45 [INFO]: Epoch 187 - training loss: 0.2467, validation loss: 0.1275
2024-05-24 23:57:47 [INFO]: Epoch 188 - training loss: 0.2462, validation loss: 0.1273
2024-05-24 23:57:50 [INFO]: Epoch 189 - training loss: 0.2460, validation loss: 0.1274
2024-05-24 23:57:53 [INFO]: Epoch 190 - training loss: 0.2462, validation loss: 0.1270
2024-05-24 23:57:56 [INFO]: Epoch 191 - training loss: 0.2454, validation loss: 0.1268
2024-05-24 23:57:59 [INFO]: Epoch 192 - training loss: 0.2453, validation loss: 0.1268
2024-05-24 23:58:02 [INFO]: Epoch 193 - training loss: 0.2450, validation loss: 0.1267
2024-05-24 23:58:04 [INFO]: Epoch 194 - training loss: 0.2452, validation loss: 0.1265
2024-05-24 23:58:07 [INFO]: Epoch 195 - training loss: 0.2451, validation loss: 0.1265
2024-05-24 23:58:10 [INFO]: Epoch 196 - training loss: 0.2446, validation loss: 0.1261
2024-05-24 23:58:13 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.1262
2024-05-24 23:58:16 [INFO]: Epoch 198 - training loss: 0.2442, validation loss: 0.1259
2024-05-24 23:58:18 [INFO]: Epoch 199 - training loss: 0.2437, validation loss: 0.1260
2024-05-24 23:58:21 [INFO]: Epoch 200 - training loss: 0.2444, validation loss: 0.1259
2024-05-24 23:58:24 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1258
2024-05-24 23:58:27 [INFO]: Epoch 202 - training loss: 0.2433, validation loss: 0.1256
2024-05-24 23:58:30 [INFO]: Epoch 203 - training loss: 0.2431, validation loss: 0.1254
2024-05-24 23:58:32 [INFO]: Epoch 204 - training loss: 0.2426, validation loss: 0.1254
2024-05-24 23:58:35 [INFO]: Epoch 205 - training loss: 0.2425, validation loss: 0.1254
2024-05-24 23:58:38 [INFO]: Epoch 206 - training loss: 0.2423, validation loss: 0.1251
2024-05-24 23:58:41 [INFO]: Epoch 207 - training loss: 0.2430, validation loss: 0.1253
2024-05-24 23:58:44 [INFO]: Epoch 208 - training loss: 0.2420, validation loss: 0.1251
2024-05-24 23:58:46 [INFO]: Epoch 209 - training loss: 0.2420, validation loss: 0.1248
2024-05-24 23:58:49 [INFO]: Epoch 210 - training loss: 0.2415, validation loss: 0.1250
2024-05-24 23:58:52 [INFO]: Epoch 211 - training loss: 0.2419, validation loss: 0.1246
2024-05-24 23:58:55 [INFO]: Epoch 212 - training loss: 0.2413, validation loss: 0.1248
2024-05-24 23:58:58 [INFO]: Epoch 213 - training loss: 0.2410, validation loss: 0.1244
2024-05-24 23:59:00 [INFO]: Epoch 214 - training loss: 0.2413, validation loss: 0.1246
2024-05-24 23:59:03 [INFO]: Epoch 215 - training loss: 0.2408, validation loss: 0.1243
2024-05-24 23:59:06 [INFO]: Epoch 216 - training loss: 0.2403, validation loss: 0.1243
2024-05-24 23:59:09 [INFO]: Epoch 217 - training loss: 0.2409, validation loss: 0.1243
2024-05-24 23:59:12 [INFO]: Epoch 218 - training loss: 0.2408, validation loss: 0.1240
2024-05-24 23:59:14 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1240
2024-05-24 23:59:17 [INFO]: Epoch 220 - training loss: 0.2398, validation loss: 0.1240
2024-05-24 23:59:20 [INFO]: Epoch 221 - training loss: 0.2395, validation loss: 0.1239
2024-05-24 23:59:23 [INFO]: Epoch 222 - training loss: 0.2399, validation loss: 0.1237
2024-05-24 23:59:26 [INFO]: Epoch 223 - training loss: 0.2401, validation loss: 0.1237
2024-05-24 23:59:28 [INFO]: Epoch 224 - training loss: 0.2395, validation loss: 0.1234
2024-05-24 23:59:31 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.1238
2024-05-24 23:59:34 [INFO]: Epoch 226 - training loss: 0.2387, validation loss: 0.1234
2024-05-24 23:59:37 [INFO]: Epoch 227 - training loss: 0.2392, validation loss: 0.1234
2024-05-24 23:59:40 [INFO]: Epoch 228 - training loss: 0.2387, validation loss: 0.1235
2024-05-24 23:59:42 [INFO]: Epoch 229 - training loss: 0.2389, validation loss: 0.1233
2024-05-24 23:59:45 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1233
2024-05-24 23:59:48 [INFO]: Epoch 231 - training loss: 0.2382, validation loss: 0.1230
2024-05-24 23:59:51 [INFO]: Epoch 232 - training loss: 0.2379, validation loss: 0.1232
2024-05-24 23:59:54 [INFO]: Epoch 233 - training loss: 0.2379, validation loss: 0.1230
2024-05-24 23:59:56 [INFO]: Epoch 234 - training loss: 0.2375, validation loss: 0.1230
2024-05-24 23:59:59 [INFO]: Epoch 235 - training loss: 0.2380, validation loss: 0.1228
2024-05-25 00:00:02 [INFO]: Epoch 236 - training loss: 0.2372, validation loss: 0.1229
2024-05-25 00:00:05 [INFO]: Epoch 237 - training loss: 0.2370, validation loss: 0.1225
2024-05-25 00:00:08 [INFO]: Epoch 238 - training loss: 0.2367, validation loss: 0.1227
2024-05-25 00:00:10 [INFO]: Epoch 239 - training loss: 0.2375, validation loss: 0.1225
2024-05-25 00:00:13 [INFO]: Epoch 240 - training loss: 0.2369, validation loss: 0.1224
2024-05-25 00:00:16 [INFO]: Epoch 241 - training loss: 0.2362, validation loss: 0.1225
2024-05-25 00:00:19 [INFO]: Epoch 242 - training loss: 0.2363, validation loss: 0.1224
2024-05-25 00:00:22 [INFO]: Epoch 243 - training loss: 0.2362, validation loss: 0.1227
2024-05-25 00:00:24 [INFO]: Epoch 244 - training loss: 0.2360, validation loss: 0.1222
2024-05-25 00:00:27 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1222
2024-05-25 00:00:30 [INFO]: Epoch 246 - training loss: 0.2361, validation loss: 0.1222
2024-05-25 00:00:33 [INFO]: Epoch 247 - training loss: 0.2359, validation loss: 0.1219
2024-05-25 00:00:36 [INFO]: Epoch 248 - training loss: 0.2358, validation loss: 0.1221
2024-05-25 00:00:38 [INFO]: Epoch 249 - training loss: 0.2354, validation loss: 0.1218
2024-05-25 00:00:41 [INFO]: Epoch 250 - training loss: 0.2353, validation loss: 0.1220
2024-05-25 00:00:44 [INFO]: Epoch 251 - training loss: 0.2355, validation loss: 0.1219
2024-05-25 00:00:47 [INFO]: Epoch 252 - training loss: 0.2351, validation loss: 0.1217
2024-05-25 00:00:50 [INFO]: Epoch 253 - training loss: 0.2353, validation loss: 0.1218
2024-05-25 00:00:52 [INFO]: Epoch 254 - training loss: 0.2350, validation loss: 0.1218
2024-05-25 00:00:55 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1216
2024-05-25 00:00:58 [INFO]: Epoch 256 - training loss: 0.2343, validation loss: 0.1217
2024-05-25 00:01:01 [INFO]: Epoch 257 - training loss: 0.2343, validation loss: 0.1216
2024-05-25 00:01:04 [INFO]: Epoch 258 - training loss: 0.2343, validation loss: 0.1214
2024-05-25 00:01:06 [INFO]: Epoch 259 - training loss: 0.2341, validation loss: 0.1214
2024-05-25 00:01:09 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.1215
2024-05-25 00:01:12 [INFO]: Epoch 261 - training loss: 0.2336, validation loss: 0.1215
2024-05-25 00:01:15 [INFO]: Epoch 262 - training loss: 0.2340, validation loss: 0.1213
2024-05-25 00:01:17 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1212
2024-05-25 00:01:20 [INFO]: Epoch 264 - training loss: 0.2335, validation loss: 0.1212
2024-05-25 00:01:23 [INFO]: Epoch 265 - training loss: 0.2331, validation loss: 0.1213
2024-05-25 00:01:26 [INFO]: Epoch 266 - training loss: 0.2340, validation loss: 0.1213
2024-05-25 00:01:29 [INFO]: Epoch 267 - training loss: 0.2331, validation loss: 0.1210
2024-05-25 00:01:31 [INFO]: Epoch 268 - training loss: 0.2328, validation loss: 0.1210
2024-05-25 00:01:34 [INFO]: Epoch 269 - training loss: 0.2326, validation loss: 0.1210
2024-05-25 00:01:37 [INFO]: Epoch 270 - training loss: 0.2331, validation loss: 0.1208
2024-05-25 00:01:40 [INFO]: Epoch 271 - training loss: 0.2329, validation loss: 0.1211
2024-05-25 00:01:43 [INFO]: Epoch 272 - training loss: 0.2329, validation loss: 0.1210
2024-05-25 00:01:45 [INFO]: Epoch 273 - training loss: 0.2328, validation loss: 0.1209
2024-05-25 00:01:48 [INFO]: Epoch 274 - training loss: 0.2321, validation loss: 0.1207
2024-05-25 00:01:51 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.1207
2024-05-25 00:01:54 [INFO]: Epoch 276 - training loss: 0.2323, validation loss: 0.1205
2024-05-25 00:01:57 [INFO]: Epoch 277 - training loss: 0.2316, validation loss: 0.1208
2024-05-25 00:01:59 [INFO]: Epoch 278 - training loss: 0.2318, validation loss: 0.1206
2024-05-25 00:02:02 [INFO]: Epoch 279 - training loss: 0.2319, validation loss: 0.1206
2024-05-25 00:02:05 [INFO]: Epoch 280 - training loss: 0.2321, validation loss: 0.1206
2024-05-25 00:02:08 [INFO]: Epoch 281 - training loss: 0.2314, validation loss: 0.1205
2024-05-25 00:02:11 [INFO]: Epoch 282 - training loss: 0.2311, validation loss: 0.1205
2024-05-25 00:02:13 [INFO]: Epoch 283 - training loss: 0.2317, validation loss: 0.1206
2024-05-25 00:02:16 [INFO]: Epoch 284 - training loss: 0.2313, validation loss: 0.1203
2024-05-25 00:02:19 [INFO]: Epoch 285 - training loss: 0.2312, validation loss: 0.1203
2024-05-25 00:02:22 [INFO]: Epoch 286 - training loss: 0.2314, validation loss: 0.1205
2024-05-25 00:02:25 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.1206
2024-05-25 00:02:27 [INFO]: Epoch 288 - training loss: 0.2310, validation loss: 0.1203
2024-05-25 00:02:30 [INFO]: Epoch 289 - training loss: 0.2306, validation loss: 0.1202
2024-05-25 00:02:33 [INFO]: Epoch 290 - training loss: 0.2309, validation loss: 0.1204
2024-05-25 00:02:36 [INFO]: Epoch 291 - training loss: 0.2305, validation loss: 0.1205
2024-05-25 00:02:38 [INFO]: Epoch 292 - training loss: 0.2303, validation loss: 0.1204
2024-05-25 00:02:41 [INFO]: Epoch 293 - training loss: 0.2311, validation loss: 0.1200
2024-05-25 00:02:44 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.1201
2024-05-25 00:02:47 [INFO]: Epoch 295 - training loss: 0.2298, validation loss: 0.1200
2024-05-25 00:02:50 [INFO]: Epoch 296 - training loss: 0.2298, validation loss: 0.1201
2024-05-25 00:02:52 [INFO]: Epoch 297 - training loss: 0.2301, validation loss: 0.1201
2024-05-25 00:02:55 [INFO]: Epoch 298 - training loss: 0.2299, validation loss: 0.1200
2024-05-25 00:02:58 [INFO]: Epoch 299 - training loss: 0.2300, validation loss: 0.1201
2024-05-25 00:03:01 [INFO]: Epoch 300 - training loss: 0.2297, validation loss: 0.1199
2024-05-25 00:03:01 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 00:03:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/BRITS_air_quality/20240524_T234901/BRITS.pypots
2024-05-25 00:03:01 [INFO]: BRITS on Air-Quality: MAE=0.1527, MSE=0.1111
2024-05-25 00:03:01 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 00:03:01 [INFO]: Using the given device: cuda:0
2024-05-25 00:03:01 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301
2024-05-25 00:03:01 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/tensorboard
2024-05-25 00:03:01 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 00:03:06 [INFO]: Epoch 001 - training loss: 1.4891, validation loss: 0.7919
2024-05-25 00:03:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch1_loss0.7918755382299423.pypots
2024-05-25 00:03:10 [INFO]: Epoch 002 - training loss: 1.0599, validation loss: 0.7418
2024-05-25 00:03:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch2_loss0.7417923390865326.pypots
2024-05-25 00:03:14 [INFO]: Epoch 003 - training loss: 0.9887, validation loss: 0.7231
2024-05-25 00:03:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch3_loss0.7230743199586869.pypots
2024-05-25 00:03:18 [INFO]: Epoch 004 - training loss: 0.9649, validation loss: 0.7126
2024-05-25 00:03:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch4_loss0.7125854879617691.pypots
2024-05-25 00:03:21 [INFO]: Epoch 005 - training loss: 0.9660, validation loss: 0.7046
2024-05-25 00:03:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch5_loss0.7045801252126693.pypots
2024-05-25 00:03:25 [INFO]: Epoch 006 - training loss: 0.9429, validation loss: 0.6983
2024-05-25 00:03:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch6_loss0.6982919365167618.pypots
2024-05-25 00:03:29 [INFO]: Epoch 007 - training loss: 0.9381, validation loss: 0.6939
2024-05-25 00:03:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch7_loss0.6938633471727371.pypots
2024-05-25 00:03:33 [INFO]: Epoch 008 - training loss: 0.9245, validation loss: 0.6906
2024-05-25 00:03:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch8_loss0.6906174540519714.pypots
2024-05-25 00:03:37 [INFO]: Epoch 009 - training loss: 0.9335, validation loss: 0.6895
2024-05-25 00:03:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch9_loss0.6895469695329666.pypots
2024-05-25 00:03:41 [INFO]: Epoch 010 - training loss: 0.9299, validation loss: 0.6867
2024-05-25 00:03:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch10_loss0.6867426216602326.pypots
2024-05-25 00:03:44 [INFO]: Epoch 011 - training loss: 0.9163, validation loss: 0.6840
2024-05-25 00:03:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch11_loss0.6839549541473389.pypots
2024-05-25 00:03:48 [INFO]: Epoch 012 - training loss: 0.9096, validation loss: 0.6855
2024-05-25 00:03:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch12_loss0.6855258047580719.pypots
2024-05-25 00:03:52 [INFO]: Epoch 013 - training loss: 0.8974, validation loss: 0.6824
2024-05-25 00:03:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch13_loss0.6823999017477036.pypots
2024-05-25 00:03:56 [INFO]: Epoch 014 - training loss: 0.9033, validation loss: 0.6818
2024-05-25 00:03:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch14_loss0.6817941159009934.pypots
2024-05-25 00:04:00 [INFO]: Epoch 015 - training loss: 0.9040, validation loss: 0.6824
2024-05-25 00:04:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch15_loss0.6823501050472259.pypots
2024-05-25 00:04:03 [INFO]: Epoch 016 - training loss: 0.9413, validation loss: 0.6821
2024-05-25 00:04:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch16_loss0.6820817977190018.pypots
2024-05-25 00:04:07 [INFO]: Epoch 017 - training loss: 0.8966, validation loss: 0.6825
2024-05-25 00:04:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch17_loss0.6824858993291855.pypots
2024-05-25 00:04:11 [INFO]: Epoch 018 - training loss: 0.9272, validation loss: 0.6814
2024-05-25 00:04:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch18_loss0.6814116030931473.pypots
2024-05-25 00:04:15 [INFO]: Epoch 019 - training loss: 0.9170, validation loss: 0.6809
2024-05-25 00:04:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch19_loss0.6808760374784469.pypots
2024-05-25 00:04:19 [INFO]: Epoch 020 - training loss: 0.8905, validation loss: 0.6824
2024-05-25 00:04:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch20_loss0.6824229270219803.pypots
2024-05-25 00:04:23 [INFO]: Epoch 021 - training loss: 0.8748, validation loss: 0.6841
2024-05-25 00:04:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch21_loss0.6841186583042145.pypots
2024-05-25 00:04:26 [INFO]: Epoch 022 - training loss: 0.8791, validation loss: 0.6828
2024-05-25 00:04:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch22_loss0.6827650547027588.pypots
2024-05-25 00:04:30 [INFO]: Epoch 023 - training loss: 0.8792, validation loss: 0.6847
2024-05-25 00:04:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch23_loss0.6847184598445892.pypots
2024-05-25 00:04:34 [INFO]: Epoch 024 - training loss: 0.8860, validation loss: 0.6857
2024-05-25 00:04:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch24_loss0.6856635302305222.pypots
2024-05-25 00:04:38 [INFO]: Epoch 025 - training loss: 0.9169, validation loss: 0.6885
2024-05-25 00:04:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch25_loss0.6884577095508575.pypots
2024-05-25 00:04:42 [INFO]: Epoch 026 - training loss: 0.8558, validation loss: 0.6870
2024-05-25 00:04:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch26_loss0.6870193719863892.pypots
2024-05-25 00:04:46 [INFO]: Epoch 027 - training loss: 0.8677, validation loss: 0.6871
2024-05-25 00:04:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch27_loss0.6870807051658631.pypots
2024-05-25 00:04:49 [INFO]: Epoch 028 - training loss: 0.8637, validation loss: 0.6889
2024-05-25 00:04:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch28_loss0.6888938575983048.pypots
2024-05-25 00:04:53 [INFO]: Epoch 029 - training loss: 0.8632, validation loss: 0.6878
2024-05-25 00:04:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN_epoch29_loss0.6877638012170791.pypots
2024-05-25 00:04:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:04:53 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 00:04:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_0/MRNN_air_quality/20240525_T000301/MRNN.pypots
2024-05-25 00:04:54 [INFO]: MRNN on Air-Quality: MAE=0.5256, MSE=0.6195
2024-05-25 00:04:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 00:04:54 [INFO]: Using the given device: cpu
2024-05-25 00:04:54 [INFO]: LOCF on Air-Quality: MAE=0.2195, MSE=0.2798
2024-05-25 00:04:54 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 00:04:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 00:04:54 [INFO]: Median on Air-Quality: MAE=0.6624, MSE=1.0025
2024-05-25 00:04:54 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 00:04:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 00:04:54 [INFO]: Mean on Air-Quality: MAE=0.6941, MSE=0.9443
2024-05-25 00:04:54 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 00:04:54 [INFO]: Successfully saved to overlay_postmask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 00:04:54 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 00:04:54 [INFO]: Using the given device: cuda:0
2024-05-25 00:04:54 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240525_T000454
2024-05-25 00:04:54 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240525_T000454/tensorboard
2024-05-25 00:04:54 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 00:04:55 [INFO]: Epoch 001 - training loss: 1.0523, validation loss: 0.5265
2024-05-25 00:04:56 [INFO]: Epoch 002 - training loss: 0.7487, validation loss: 0.4105
2024-05-25 00:04:56 [INFO]: Epoch 003 - training loss: 0.6404, validation loss: 0.3401
2024-05-25 00:04:57 [INFO]: Epoch 004 - training loss: 0.5674, validation loss: 0.2940
2024-05-25 00:04:58 [INFO]: Epoch 005 - training loss: 0.5196, validation loss: 0.2662
2024-05-25 00:04:58 [INFO]: Epoch 006 - training loss: 0.4823, validation loss: 0.2526
2024-05-25 00:04:59 [INFO]: Epoch 007 - training loss: 0.4580, validation loss: 0.2431
2024-05-25 00:05:00 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2374
2024-05-25 00:05:00 [INFO]: Epoch 009 - training loss: 0.4272, validation loss: 0.2309
2024-05-25 00:05:01 [INFO]: Epoch 010 - training loss: 0.4143, validation loss: 0.2251
2024-05-25 00:05:02 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2223
2024-05-25 00:05:02 [INFO]: Epoch 012 - training loss: 0.3965, validation loss: 0.2172
2024-05-25 00:05:03 [INFO]: Epoch 013 - training loss: 0.3883, validation loss: 0.2124
2024-05-25 00:05:04 [INFO]: Epoch 014 - training loss: 0.3823, validation loss: 0.2093
2024-05-25 00:05:04 [INFO]: Epoch 015 - training loss: 0.3757, validation loss: 0.2078
2024-05-25 00:05:05 [INFO]: Epoch 016 - training loss: 0.3702, validation loss: 0.2068
2024-05-25 00:05:06 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2037
2024-05-25 00:05:06 [INFO]: Epoch 018 - training loss: 0.3615, validation loss: 0.2008
2024-05-25 00:05:07 [INFO]: Epoch 019 - training loss: 0.3570, validation loss: 0.1992
2024-05-25 00:05:08 [INFO]: Epoch 020 - training loss: 0.3546, validation loss: 0.1987
2024-05-25 00:05:08 [INFO]: Epoch 021 - training loss: 0.3499, validation loss: 0.1967
2024-05-25 00:05:09 [INFO]: Epoch 022 - training loss: 0.3454, validation loss: 0.1936
2024-05-25 00:05:10 [INFO]: Epoch 023 - training loss: 0.3427, validation loss: 0.1919
2024-05-25 00:05:10 [INFO]: Epoch 024 - training loss: 0.3414, validation loss: 0.1905
2024-05-25 00:05:11 [INFO]: Epoch 025 - training loss: 0.3380, validation loss: 0.1887
2024-05-25 00:05:12 [INFO]: Epoch 026 - training loss: 0.3342, validation loss: 0.1871
2024-05-25 00:05:12 [INFO]: Epoch 027 - training loss: 0.3314, validation loss: 0.1858
2024-05-25 00:05:13 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1837
2024-05-25 00:05:14 [INFO]: Epoch 029 - training loss: 0.3257, validation loss: 0.1838
2024-05-25 00:05:14 [INFO]: Epoch 030 - training loss: 0.3240, validation loss: 0.1815
2024-05-25 00:05:15 [INFO]: Epoch 031 - training loss: 0.3250, validation loss: 0.1811
2024-05-25 00:05:16 [INFO]: Epoch 032 - training loss: 0.3188, validation loss: 0.1779
2024-05-25 00:05:16 [INFO]: Epoch 033 - training loss: 0.3169, validation loss: 0.1765
2024-05-25 00:05:17 [INFO]: Epoch 034 - training loss: 0.3155, validation loss: 0.1755
2024-05-25 00:05:18 [INFO]: Epoch 035 - training loss: 0.3129, validation loss: 0.1747
2024-05-25 00:05:18 [INFO]: Epoch 036 - training loss: 0.3135, validation loss: 0.1752
2024-05-25 00:05:19 [INFO]: Epoch 037 - training loss: 0.3126, validation loss: 0.1714
2024-05-25 00:05:20 [INFO]: Epoch 038 - training loss: 0.3109, validation loss: 0.1713
2024-05-25 00:05:20 [INFO]: Epoch 039 - training loss: 0.3076, validation loss: 0.1701
2024-05-25 00:05:21 [INFO]: Epoch 040 - training loss: 0.3047, validation loss: 0.1695
2024-05-25 00:05:22 [INFO]: Epoch 041 - training loss: 0.3030, validation loss: 0.1679
2024-05-25 00:05:22 [INFO]: Epoch 042 - training loss: 0.3013, validation loss: 0.1673
2024-05-25 00:05:23 [INFO]: Epoch 043 - training loss: 0.2995, validation loss: 0.1669
2024-05-25 00:05:24 [INFO]: Epoch 044 - training loss: 0.2991, validation loss: 0.1643
2024-05-25 00:05:24 [INFO]: Epoch 045 - training loss: 0.2965, validation loss: 0.1637
2024-05-25 00:05:25 [INFO]: Epoch 046 - training loss: 0.2948, validation loss: 0.1643
2024-05-25 00:05:25 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1619
2024-05-25 00:05:26 [INFO]: Epoch 048 - training loss: 0.2938, validation loss: 0.1622
2024-05-25 00:05:27 [INFO]: Epoch 049 - training loss: 0.2918, validation loss: 0.1607
2024-05-25 00:05:27 [INFO]: Epoch 050 - training loss: 0.2892, validation loss: 0.1605
2024-05-25 00:05:28 [INFO]: Epoch 051 - training loss: 0.2883, validation loss: 0.1599
2024-05-25 00:05:29 [INFO]: Epoch 052 - training loss: 0.2890, validation loss: 0.1601
2024-05-25 00:05:29 [INFO]: Epoch 053 - training loss: 0.2858, validation loss: 0.1578
2024-05-25 00:05:30 [INFO]: Epoch 054 - training loss: 0.2831, validation loss: 0.1579
2024-05-25 00:05:31 [INFO]: Epoch 055 - training loss: 0.2827, validation loss: 0.1559
2024-05-25 00:05:31 [INFO]: Epoch 056 - training loss: 0.2811, validation loss: 0.1558
2024-05-25 00:05:32 [INFO]: Epoch 057 - training loss: 0.2813, validation loss: 0.1558
2024-05-25 00:05:33 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1554
2024-05-25 00:05:33 [INFO]: Epoch 059 - training loss: 0.2772, validation loss: 0.1553
2024-05-25 00:05:34 [INFO]: Epoch 060 - training loss: 0.2767, validation loss: 0.1546
2024-05-25 00:05:35 [INFO]: Epoch 061 - training loss: 0.2749, validation loss: 0.1522
2024-05-25 00:05:35 [INFO]: Epoch 062 - training loss: 0.2736, validation loss: 0.1529
2024-05-25 00:05:36 [INFO]: Epoch 063 - training loss: 0.2728, validation loss: 0.1521
2024-05-25 00:05:37 [INFO]: Epoch 064 - training loss: 0.2727, validation loss: 0.1523
2024-05-25 00:05:37 [INFO]: Epoch 065 - training loss: 0.2708, validation loss: 0.1519
2024-05-25 00:05:38 [INFO]: Epoch 066 - training loss: 0.2712, validation loss: 0.1504
2024-05-25 00:05:39 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1506
2024-05-25 00:05:39 [INFO]: Epoch 068 - training loss: 0.2677, validation loss: 0.1511
2024-05-25 00:05:40 [INFO]: Epoch 069 - training loss: 0.2675, validation loss: 0.1499
2024-05-25 00:05:41 [INFO]: Epoch 070 - training loss: 0.2661, validation loss: 0.1504
2024-05-25 00:05:41 [INFO]: Epoch 071 - training loss: 0.2646, validation loss: 0.1500
2024-05-25 00:05:42 [INFO]: Epoch 072 - training loss: 0.2643, validation loss: 0.1494
2024-05-25 00:05:43 [INFO]: Epoch 073 - training loss: 0.2628, validation loss: 0.1489
2024-05-25 00:05:43 [INFO]: Epoch 074 - training loss: 0.2637, validation loss: 0.1492
2024-05-25 00:05:44 [INFO]: Epoch 075 - training loss: 0.2620, validation loss: 0.1492
2024-05-25 00:05:45 [INFO]: Epoch 076 - training loss: 0.2606, validation loss: 0.1471
2024-05-25 00:05:45 [INFO]: Epoch 077 - training loss: 0.2600, validation loss: 0.1470
2024-05-25 00:05:46 [INFO]: Epoch 078 - training loss: 0.2598, validation loss: 0.1474
2024-05-25 00:05:47 [INFO]: Epoch 079 - training loss: 0.2579, validation loss: 0.1477
2024-05-25 00:05:47 [INFO]: Epoch 080 - training loss: 0.2581, validation loss: 0.1472
2024-05-25 00:05:48 [INFO]: Epoch 081 - training loss: 0.2571, validation loss: 0.1463
2024-05-25 00:05:49 [INFO]: Epoch 082 - training loss: 0.2586, validation loss: 0.1455
2024-05-25 00:05:49 [INFO]: Epoch 083 - training loss: 0.2565, validation loss: 0.1450
2024-05-25 00:05:50 [INFO]: Epoch 084 - training loss: 0.2552, validation loss: 0.1453
2024-05-25 00:05:51 [INFO]: Epoch 085 - training loss: 0.2535, validation loss: 0.1449
2024-05-25 00:05:51 [INFO]: Epoch 086 - training loss: 0.2543, validation loss: 0.1437
2024-05-25 00:05:52 [INFO]: Epoch 087 - training loss: 0.2549, validation loss: 0.1438
2024-05-25 00:05:53 [INFO]: Epoch 088 - training loss: 0.2536, validation loss: 0.1441
2024-05-25 00:05:53 [INFO]: Epoch 089 - training loss: 0.2529, validation loss: 0.1437
2024-05-25 00:05:54 [INFO]: Epoch 090 - training loss: 0.2516, validation loss: 0.1437
2024-05-25 00:05:55 [INFO]: Epoch 091 - training loss: 0.2501, validation loss: 0.1435
2024-05-25 00:05:55 [INFO]: Epoch 092 - training loss: 0.2503, validation loss: 0.1426
2024-05-25 00:05:56 [INFO]: Epoch 093 - training loss: 0.2494, validation loss: 0.1419
2024-05-25 00:05:57 [INFO]: Epoch 094 - training loss: 0.2493, validation loss: 0.1422
2024-05-25 00:05:57 [INFO]: Epoch 095 - training loss: 0.2473, validation loss: 0.1412
2024-05-25 00:05:58 [INFO]: Epoch 096 - training loss: 0.2472, validation loss: 0.1408
2024-05-25 00:05:59 [INFO]: Epoch 097 - training loss: 0.2464, validation loss: 0.1415
2024-05-25 00:05:59 [INFO]: Epoch 098 - training loss: 0.2456, validation loss: 0.1407
2024-05-25 00:06:00 [INFO]: Epoch 099 - training loss: 0.2460, validation loss: 0.1423
2024-05-25 00:06:01 [INFO]: Epoch 100 - training loss: 0.2476, validation loss: 0.1404
2024-05-25 00:06:01 [INFO]: Epoch 101 - training loss: 0.2470, validation loss: 0.1395
2024-05-25 00:06:02 [INFO]: Epoch 102 - training loss: 0.2435, validation loss: 0.1402
2024-05-25 00:06:03 [INFO]: Epoch 103 - training loss: 0.2436, validation loss: 0.1398
2024-05-25 00:06:03 [INFO]: Epoch 104 - training loss: 0.2447, validation loss: 0.1389
2024-05-25 00:06:04 [INFO]: Epoch 105 - training loss: 0.2421, validation loss: 0.1391
2024-05-25 00:06:05 [INFO]: Epoch 106 - training loss: 0.2409, validation loss: 0.1390
2024-05-25 00:06:05 [INFO]: Epoch 107 - training loss: 0.2407, validation loss: 0.1381
2024-05-25 00:06:06 [INFO]: Epoch 108 - training loss: 0.2409, validation loss: 0.1384
2024-05-25 00:06:07 [INFO]: Epoch 109 - training loss: 0.2410, validation loss: 0.1376
2024-05-25 00:06:07 [INFO]: Epoch 110 - training loss: 0.2391, validation loss: 0.1380
2024-05-25 00:06:08 [INFO]: Epoch 111 - training loss: 0.2389, validation loss: 0.1383
2024-05-25 00:06:09 [INFO]: Epoch 112 - training loss: 0.2381, validation loss: 0.1364
2024-05-25 00:06:09 [INFO]: Epoch 113 - training loss: 0.2385, validation loss: 0.1374
2024-05-25 00:06:10 [INFO]: Epoch 114 - training loss: 0.2376, validation loss: 0.1376
2024-05-25 00:06:11 [INFO]: Epoch 115 - training loss: 0.2377, validation loss: 0.1371
2024-05-25 00:06:11 [INFO]: Epoch 116 - training loss: 0.2378, validation loss: 0.1374
2024-05-25 00:06:12 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1359
2024-05-25 00:06:13 [INFO]: Epoch 118 - training loss: 0.2361, validation loss: 0.1366
2024-05-25 00:06:13 [INFO]: Epoch 119 - training loss: 0.2348, validation loss: 0.1354
2024-05-25 00:06:14 [INFO]: Epoch 120 - training loss: 0.2341, validation loss: 0.1366
2024-05-25 00:06:15 [INFO]: Epoch 121 - training loss: 0.2349, validation loss: 0.1362
2024-05-25 00:06:15 [INFO]: Epoch 122 - training loss: 0.2343, validation loss: 0.1364
2024-05-25 00:06:16 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1346
2024-05-25 00:06:17 [INFO]: Epoch 124 - training loss: 0.2333, validation loss: 0.1356
2024-05-25 00:06:17 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1345
2024-05-25 00:06:18 [INFO]: Epoch 126 - training loss: 0.2326, validation loss: 0.1345
2024-05-25 00:06:19 [INFO]: Epoch 127 - training loss: 0.2316, validation loss: 0.1345
2024-05-25 00:06:19 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1345
2024-05-25 00:06:20 [INFO]: Epoch 129 - training loss: 0.2310, validation loss: 0.1342
2024-05-25 00:06:21 [INFO]: Epoch 130 - training loss: 0.2315, validation loss: 0.1338
2024-05-25 00:06:21 [INFO]: Epoch 131 - training loss: 0.2317, validation loss: 0.1330
2024-05-25 00:06:22 [INFO]: Epoch 132 - training loss: 0.2294, validation loss: 0.1338
2024-05-25 00:06:23 [INFO]: Epoch 133 - training loss: 0.2293, validation loss: 0.1323
2024-05-25 00:06:23 [INFO]: Epoch 134 - training loss: 0.2284, validation loss: 0.1331
2024-05-25 00:06:24 [INFO]: Epoch 135 - training loss: 0.2281, validation loss: 0.1333
2024-05-25 00:06:25 [INFO]: Epoch 136 - training loss: 0.2271, validation loss: 0.1331
2024-05-25 00:06:25 [INFO]: Epoch 137 - training loss: 0.2285, validation loss: 0.1325
2024-05-25 00:06:26 [INFO]: Epoch 138 - training loss: 0.2276, validation loss: 0.1325
2024-05-25 00:06:26 [INFO]: Epoch 139 - training loss: 0.2265, validation loss: 0.1353
2024-05-25 00:06:27 [INFO]: Epoch 140 - training loss: 0.2281, validation loss: 0.1320
2024-05-25 00:06:28 [INFO]: Epoch 141 - training loss: 0.2259, validation loss: 0.1329
2024-05-25 00:06:28 [INFO]: Epoch 142 - training loss: 0.2259, validation loss: 0.1318
2024-05-25 00:06:29 [INFO]: Epoch 143 - training loss: 0.2263, validation loss: 0.1335
2024-05-25 00:06:30 [INFO]: Epoch 144 - training loss: 0.2262, validation loss: 0.1317
2024-05-25 00:06:30 [INFO]: Epoch 145 - training loss: 0.2249, validation loss: 0.1309
2024-05-25 00:06:31 [INFO]: Epoch 146 - training loss: 0.2247, validation loss: 0.1308
2024-05-25 00:06:32 [INFO]: Epoch 147 - training loss: 0.2255, validation loss: 0.1328
2024-05-25 00:06:32 [INFO]: Epoch 148 - training loss: 0.2254, validation loss: 0.1305
2024-05-25 00:06:33 [INFO]: Epoch 149 - training loss: 0.2231, validation loss: 0.1300
2024-05-25 00:06:34 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1302
2024-05-25 00:06:34 [INFO]: Epoch 151 - training loss: 0.2232, validation loss: 0.1304
2024-05-25 00:06:35 [INFO]: Epoch 152 - training loss: 0.2210, validation loss: 0.1310
2024-05-25 00:06:36 [INFO]: Epoch 153 - training loss: 0.2219, validation loss: 0.1297
2024-05-25 00:06:36 [INFO]: Epoch 154 - training loss: 0.2209, validation loss: 0.1295
2024-05-25 00:06:37 [INFO]: Epoch 155 - training loss: 0.2200, validation loss: 0.1292
2024-05-25 00:06:38 [INFO]: Epoch 156 - training loss: 0.2209, validation loss: 0.1295
2024-05-25 00:06:38 [INFO]: Epoch 157 - training loss: 0.2214, validation loss: 0.1286
2024-05-25 00:06:39 [INFO]: Epoch 158 - training loss: 0.2212, validation loss: 0.1291
2024-05-25 00:06:40 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1308
2024-05-25 00:06:40 [INFO]: Epoch 160 - training loss: 0.2208, validation loss: 0.1281
2024-05-25 00:06:41 [INFO]: Epoch 161 - training loss: 0.2209, validation loss: 0.1293
2024-05-25 00:06:42 [INFO]: Epoch 162 - training loss: 0.2197, validation loss: 0.1279
2024-05-25 00:06:42 [INFO]: Epoch 163 - training loss: 0.2177, validation loss: 0.1267
2024-05-25 00:06:43 [INFO]: Epoch 164 - training loss: 0.2188, validation loss: 0.1283
2024-05-25 00:06:44 [INFO]: Epoch 165 - training loss: 0.2185, validation loss: 0.1278
2024-05-25 00:06:44 [INFO]: Epoch 166 - training loss: 0.2178, validation loss: 0.1282
2024-05-25 00:06:45 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1267
2024-05-25 00:06:46 [INFO]: Epoch 168 - training loss: 0.2167, validation loss: 0.1266
2024-05-25 00:06:46 [INFO]: Epoch 169 - training loss: 0.2170, validation loss: 0.1281
2024-05-25 00:06:47 [INFO]: Epoch 170 - training loss: 0.2157, validation loss: 0.1274
2024-05-25 00:06:48 [INFO]: Epoch 171 - training loss: 0.2165, validation loss: 0.1261
2024-05-25 00:06:48 [INFO]: Epoch 172 - training loss: 0.2148, validation loss: 0.1271
2024-05-25 00:06:49 [INFO]: Epoch 173 - training loss: 0.2154, validation loss: 0.1265
2024-05-25 00:06:50 [INFO]: Epoch 174 - training loss: 0.2147, validation loss: 0.1273
2024-05-25 00:06:50 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1268
2024-05-25 00:06:51 [INFO]: Epoch 176 - training loss: 0.2173, validation loss: 0.1263
2024-05-25 00:06:52 [INFO]: Epoch 177 - training loss: 0.2144, validation loss: 0.1258
2024-05-25 00:06:52 [INFO]: Epoch 178 - training loss: 0.2132, validation loss: 0.1265
2024-05-25 00:06:53 [INFO]: Epoch 179 - training loss: 0.2135, validation loss: 0.1254
2024-05-25 00:06:54 [INFO]: Epoch 180 - training loss: 0.2134, validation loss: 0.1267
2024-05-25 00:06:54 [INFO]: Epoch 181 - training loss: 0.2130, validation loss: 0.1257
2024-05-25 00:06:55 [INFO]: Epoch 182 - training loss: 0.2127, validation loss: 0.1250
2024-05-25 00:06:56 [INFO]: Epoch 183 - training loss: 0.2129, validation loss: 0.1271
2024-05-25 00:06:56 [INFO]: Epoch 184 - training loss: 0.2135, validation loss: 0.1247
2024-05-25 00:06:57 [INFO]: Epoch 185 - training loss: 0.2138, validation loss: 0.1252
2024-05-25 00:06:58 [INFO]: Epoch 186 - training loss: 0.2129, validation loss: 0.1252
2024-05-25 00:06:58 [INFO]: Epoch 187 - training loss: 0.2122, validation loss: 0.1247
2024-05-25 00:06:59 [INFO]: Epoch 188 - training loss: 0.2111, validation loss: 0.1255
2024-05-25 00:07:00 [INFO]: Epoch 189 - training loss: 0.2111, validation loss: 0.1242
2024-05-25 00:07:00 [INFO]: Epoch 190 - training loss: 0.2102, validation loss: 0.1241
2024-05-25 00:07:01 [INFO]: Epoch 191 - training loss: 0.2100, validation loss: 0.1241
2024-05-25 00:07:02 [INFO]: Epoch 192 - training loss: 0.2100, validation loss: 0.1242
2024-05-25 00:07:02 [INFO]: Epoch 193 - training loss: 0.2098, validation loss: 0.1227
2024-05-25 00:07:03 [INFO]: Epoch 194 - training loss: 0.2097, validation loss: 0.1241
2024-05-25 00:07:04 [INFO]: Epoch 195 - training loss: 0.2103, validation loss: 0.1240
2024-05-25 00:07:04 [INFO]: Epoch 196 - training loss: 0.2094, validation loss: 0.1240
2024-05-25 00:07:05 [INFO]: Epoch 197 - training loss: 0.2080, validation loss: 0.1245
2024-05-25 00:07:06 [INFO]: Epoch 198 - training loss: 0.2084, validation loss: 0.1237
2024-05-25 00:07:06 [INFO]: Epoch 199 - training loss: 0.2109, validation loss: 0.1248
2024-05-25 00:07:07 [INFO]: Epoch 200 - training loss: 0.2096, validation loss: 0.1235
2024-05-25 00:07:08 [INFO]: Epoch 201 - training loss: 0.2081, validation loss: 0.1238
2024-05-25 00:07:08 [INFO]: Epoch 202 - training loss: 0.2077, validation loss: 0.1235
2024-05-25 00:07:09 [INFO]: Epoch 203 - training loss: 0.2075, validation loss: 0.1229
2024-05-25 00:07:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:07:09 [INFO]: Finished training. The best model is from epoch#193.
2024-05-25 00:07:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/SAITS_air_quality/20240525_T000454/SAITS.pypots
2024-05-25 00:07:09 [INFO]: SAITS on Air-Quality: MAE=0.1513, MSE=0.1129
2024-05-25 00:07:09 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 00:07:09 [INFO]: Using the given device: cuda:0
2024-05-25 00:07:09 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240525_T000709
2024-05-25 00:07:09 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240525_T000709/tensorboard
2024-05-25 00:07:09 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 00:07:10 [INFO]: Epoch 001 - training loss: 0.9189, validation loss: 0.4697
2024-05-25 00:07:10 [INFO]: Epoch 002 - training loss: 0.5748, validation loss: 0.3607
2024-05-25 00:07:10 [INFO]: Epoch 003 - training loss: 0.4868, validation loss: 0.2975
2024-05-25 00:07:11 [INFO]: Epoch 004 - training loss: 0.4388, validation loss: 0.2748
2024-05-25 00:07:11 [INFO]: Epoch 005 - training loss: 0.4109, validation loss: 0.2622
2024-05-25 00:07:11 [INFO]: Epoch 006 - training loss: 0.3930, validation loss: 0.2501
2024-05-25 00:07:11 [INFO]: Epoch 007 - training loss: 0.3756, validation loss: 0.2447
2024-05-25 00:07:12 [INFO]: Epoch 008 - training loss: 0.3660, validation loss: 0.2379
2024-05-25 00:07:12 [INFO]: Epoch 009 - training loss: 0.3564, validation loss: 0.2323
2024-05-25 00:07:12 [INFO]: Epoch 010 - training loss: 0.3498, validation loss: 0.2268
2024-05-25 00:07:13 [INFO]: Epoch 011 - training loss: 0.3442, validation loss: 0.2259
2024-05-25 00:07:13 [INFO]: Epoch 012 - training loss: 0.3393, validation loss: 0.2185
2024-05-25 00:07:13 [INFO]: Epoch 013 - training loss: 0.3316, validation loss: 0.2134
2024-05-25 00:07:14 [INFO]: Epoch 014 - training loss: 0.3282, validation loss: 0.2104
2024-05-25 00:07:14 [INFO]: Epoch 015 - training loss: 0.3238, validation loss: 0.2091
2024-05-25 00:07:14 [INFO]: Epoch 016 - training loss: 0.3199, validation loss: 0.2073
2024-05-25 00:07:15 [INFO]: Epoch 017 - training loss: 0.3141, validation loss: 0.2024
2024-05-25 00:07:15 [INFO]: Epoch 018 - training loss: 0.3104, validation loss: 0.2000
2024-05-25 00:07:15 [INFO]: Epoch 019 - training loss: 0.3078, validation loss: 0.1969
2024-05-25 00:07:16 [INFO]: Epoch 020 - training loss: 0.3043, validation loss: 0.1952
2024-05-25 00:07:16 [INFO]: Epoch 021 - training loss: 0.3035, validation loss: 0.1943
2024-05-25 00:07:16 [INFO]: Epoch 022 - training loss: 0.3023, validation loss: 0.1900
2024-05-25 00:07:16 [INFO]: Epoch 023 - training loss: 0.3023, validation loss: 0.1902
2024-05-25 00:07:17 [INFO]: Epoch 024 - training loss: 0.2963, validation loss: 0.1889
2024-05-25 00:07:17 [INFO]: Epoch 025 - training loss: 0.2941, validation loss: 0.1881
2024-05-25 00:07:17 [INFO]: Epoch 026 - training loss: 0.2932, validation loss: 0.1868
2024-05-25 00:07:18 [INFO]: Epoch 027 - training loss: 0.2908, validation loss: 0.1885
2024-05-25 00:07:18 [INFO]: Epoch 028 - training loss: 0.2882, validation loss: 0.1845
2024-05-25 00:07:18 [INFO]: Epoch 029 - training loss: 0.2862, validation loss: 0.1858
2024-05-25 00:07:19 [INFO]: Epoch 030 - training loss: 0.2875, validation loss: 0.1819
2024-05-25 00:07:19 [INFO]: Epoch 031 - training loss: 0.2886, validation loss: 0.1856
2024-05-25 00:07:19 [INFO]: Epoch 032 - training loss: 0.2827, validation loss: 0.1818
2024-05-25 00:07:20 [INFO]: Epoch 033 - training loss: 0.2807, validation loss: 0.1833
2024-05-25 00:07:20 [INFO]: Epoch 034 - training loss: 0.2808, validation loss: 0.1827
2024-05-25 00:07:20 [INFO]: Epoch 035 - training loss: 0.2782, validation loss: 0.1803
2024-05-25 00:07:21 [INFO]: Epoch 036 - training loss: 0.2742, validation loss: 0.1808
2024-05-25 00:07:21 [INFO]: Epoch 037 - training loss: 0.2769, validation loss: 0.1800
2024-05-25 00:07:21 [INFO]: Epoch 038 - training loss: 0.2759, validation loss: 0.1796
2024-05-25 00:07:21 [INFO]: Epoch 039 - training loss: 0.2724, validation loss: 0.1820
2024-05-25 00:07:22 [INFO]: Epoch 040 - training loss: 0.2724, validation loss: 0.1790
2024-05-25 00:07:22 [INFO]: Epoch 041 - training loss: 0.2706, validation loss: 0.1755
2024-05-25 00:07:22 [INFO]: Epoch 042 - training loss: 0.2713, validation loss: 0.1777
2024-05-25 00:07:23 [INFO]: Epoch 043 - training loss: 0.2703, validation loss: 0.1763
2024-05-25 00:07:23 [INFO]: Epoch 044 - training loss: 0.2695, validation loss: 0.1767
2024-05-25 00:07:23 [INFO]: Epoch 045 - training loss: 0.2672, validation loss: 0.1750
2024-05-25 00:07:24 [INFO]: Epoch 046 - training loss: 0.2641, validation loss: 0.1767
2024-05-25 00:07:24 [INFO]: Epoch 047 - training loss: 0.2675, validation loss: 0.1766
2024-05-25 00:07:24 [INFO]: Epoch 048 - training loss: 0.2669, validation loss: 0.1754
2024-05-25 00:07:25 [INFO]: Epoch 049 - training loss: 0.2638, validation loss: 0.1756
2024-05-25 00:07:25 [INFO]: Epoch 050 - training loss: 0.2633, validation loss: 0.1764
2024-05-25 00:07:25 [INFO]: Epoch 051 - training loss: 0.2635, validation loss: 0.1733
2024-05-25 00:07:25 [INFO]: Epoch 052 - training loss: 0.2605, validation loss: 0.1714
2024-05-25 00:07:26 [INFO]: Epoch 053 - training loss: 0.2635, validation loss: 0.1731
2024-05-25 00:07:26 [INFO]: Epoch 054 - training loss: 0.2592, validation loss: 0.1735
2024-05-25 00:07:26 [INFO]: Epoch 055 - training loss: 0.2571, validation loss: 0.1751
2024-05-25 00:07:27 [INFO]: Epoch 056 - training loss: 0.2579, validation loss: 0.1733
2024-05-25 00:07:27 [INFO]: Epoch 057 - training loss: 0.2561, validation loss: 0.1697
2024-05-25 00:07:27 [INFO]: Epoch 058 - training loss: 0.2556, validation loss: 0.1735
2024-05-25 00:07:28 [INFO]: Epoch 059 - training loss: 0.2545, validation loss: 0.1697
2024-05-25 00:07:28 [INFO]: Epoch 060 - training loss: 0.2519, validation loss: 0.1707
2024-05-25 00:07:28 [INFO]: Epoch 061 - training loss: 0.2528, validation loss: 0.1709
2024-05-25 00:07:29 [INFO]: Epoch 062 - training loss: 0.2551, validation loss: 0.1727
2024-05-25 00:07:29 [INFO]: Epoch 063 - training loss: 0.2538, validation loss: 0.1686
2024-05-25 00:07:29 [INFO]: Epoch 064 - training loss: 0.2517, validation loss: 0.1694
2024-05-25 00:07:30 [INFO]: Epoch 065 - training loss: 0.2500, validation loss: 0.1692
2024-05-25 00:07:30 [INFO]: Epoch 066 - training loss: 0.2532, validation loss: 0.1691
2024-05-25 00:07:30 [INFO]: Epoch 067 - training loss: 0.2499, validation loss: 0.1671
2024-05-25 00:07:30 [INFO]: Epoch 068 - training loss: 0.2480, validation loss: 0.1674
2024-05-25 00:07:31 [INFO]: Epoch 069 - training loss: 0.2477, validation loss: 0.1703
2024-05-25 00:07:31 [INFO]: Epoch 070 - training loss: 0.2479, validation loss: 0.1662
2024-05-25 00:07:31 [INFO]: Epoch 071 - training loss: 0.2476, validation loss: 0.1648
2024-05-25 00:07:32 [INFO]: Epoch 072 - training loss: 0.2514, validation loss: 0.1689
2024-05-25 00:07:32 [INFO]: Epoch 073 - training loss: 0.2475, validation loss: 0.1664
2024-05-25 00:07:32 [INFO]: Epoch 074 - training loss: 0.2438, validation loss: 0.1643
2024-05-25 00:07:33 [INFO]: Epoch 075 - training loss: 0.2463, validation loss: 0.1662
2024-05-25 00:07:33 [INFO]: Epoch 076 - training loss: 0.2435, validation loss: 0.1638
2024-05-25 00:07:33 [INFO]: Epoch 077 - training loss: 0.2422, validation loss: 0.1631
2024-05-25 00:07:34 [INFO]: Epoch 078 - training loss: 0.2441, validation loss: 0.1664
2024-05-25 00:07:34 [INFO]: Epoch 079 - training loss: 0.2409, validation loss: 0.1667
2024-05-25 00:07:34 [INFO]: Epoch 080 - training loss: 0.2393, validation loss: 0.1667
2024-05-25 00:07:35 [INFO]: Epoch 081 - training loss: 0.2395, validation loss: 0.1626
2024-05-25 00:07:35 [INFO]: Epoch 082 - training loss: 0.2402, validation loss: 0.1653
2024-05-25 00:07:35 [INFO]: Epoch 083 - training loss: 0.2406, validation loss: 0.1671
2024-05-25 00:07:35 [INFO]: Epoch 084 - training loss: 0.2384, validation loss: 0.1646
2024-05-25 00:07:36 [INFO]: Epoch 085 - training loss: 0.2364, validation loss: 0.1637
2024-05-25 00:07:36 [INFO]: Epoch 086 - training loss: 0.2357, validation loss: 0.1610
2024-05-25 00:07:36 [INFO]: Epoch 087 - training loss: 0.2339, validation loss: 0.1619
2024-05-25 00:07:37 [INFO]: Epoch 088 - training loss: 0.2347, validation loss: 0.1614
2024-05-25 00:07:37 [INFO]: Epoch 089 - training loss: 0.2345, validation loss: 0.1619
2024-05-25 00:07:37 [INFO]: Epoch 090 - training loss: 0.2353, validation loss: 0.1613
2024-05-25 00:07:38 [INFO]: Epoch 091 - training loss: 0.2311, validation loss: 0.1609
2024-05-25 00:07:38 [INFO]: Epoch 092 - training loss: 0.2333, validation loss: 0.1600
2024-05-25 00:07:38 [INFO]: Epoch 093 - training loss: 0.2331, validation loss: 0.1607
2024-05-25 00:07:39 [INFO]: Epoch 094 - training loss: 0.2316, validation loss: 0.1608
2024-05-25 00:07:39 [INFO]: Epoch 095 - training loss: 0.2357, validation loss: 0.1619
2024-05-25 00:07:39 [INFO]: Epoch 096 - training loss: 0.2330, validation loss: 0.1606
2024-05-25 00:07:40 [INFO]: Epoch 097 - training loss: 0.2316, validation loss: 0.1608
2024-05-25 00:07:40 [INFO]: Epoch 098 - training loss: 0.2302, validation loss: 0.1621
2024-05-25 00:07:40 [INFO]: Epoch 099 - training loss: 0.2301, validation loss: 0.1620
2024-05-25 00:07:40 [INFO]: Epoch 100 - training loss: 0.2290, validation loss: 0.1603
2024-05-25 00:07:41 [INFO]: Epoch 101 - training loss: 0.2271, validation loss: 0.1582
2024-05-25 00:07:41 [INFO]: Epoch 102 - training loss: 0.2278, validation loss: 0.1583
2024-05-25 00:07:41 [INFO]: Epoch 103 - training loss: 0.2320, validation loss: 0.1586
2024-05-25 00:07:42 [INFO]: Epoch 104 - training loss: 0.2284, validation loss: 0.1578
2024-05-25 00:07:42 [INFO]: Epoch 105 - training loss: 0.2287, validation loss: 0.1584
2024-05-25 00:07:42 [INFO]: Epoch 106 - training loss: 0.2294, validation loss: 0.1573
2024-05-25 00:07:43 [INFO]: Epoch 107 - training loss: 0.2258, validation loss: 0.1566
2024-05-25 00:07:43 [INFO]: Epoch 108 - training loss: 0.2245, validation loss: 0.1591
2024-05-25 00:07:43 [INFO]: Epoch 109 - training loss: 0.2262, validation loss: 0.1582
2024-05-25 00:07:44 [INFO]: Epoch 110 - training loss: 0.2229, validation loss: 0.1595
2024-05-25 00:07:44 [INFO]: Epoch 111 - training loss: 0.2222, validation loss: 0.1566
2024-05-25 00:07:44 [INFO]: Epoch 112 - training loss: 0.2227, validation loss: 0.1566
2024-05-25 00:07:45 [INFO]: Epoch 113 - training loss: 0.2228, validation loss: 0.1576
2024-05-25 00:07:45 [INFO]: Epoch 114 - training loss: 0.2218, validation loss: 0.1555
2024-05-25 00:07:45 [INFO]: Epoch 115 - training loss: 0.2233, validation loss: 0.1579
2024-05-25 00:07:45 [INFO]: Epoch 116 - training loss: 0.2209, validation loss: 0.1565
2024-05-25 00:07:46 [INFO]: Epoch 117 - training loss: 0.2210, validation loss: 0.1575
2024-05-25 00:07:46 [INFO]: Epoch 118 - training loss: 0.2207, validation loss: 0.1537
2024-05-25 00:07:46 [INFO]: Epoch 119 - training loss: 0.2190, validation loss: 0.1569
2024-05-25 00:07:47 [INFO]: Epoch 120 - training loss: 0.2221, validation loss: 0.1553
2024-05-25 00:07:47 [INFO]: Epoch 121 - training loss: 0.2202, validation loss: 0.1546
2024-05-25 00:07:47 [INFO]: Epoch 122 - training loss: 0.2195, validation loss: 0.1539
2024-05-25 00:07:48 [INFO]: Epoch 123 - training loss: 0.2191, validation loss: 0.1555
2024-05-25 00:07:48 [INFO]: Epoch 124 - training loss: 0.2198, validation loss: 0.1583
2024-05-25 00:07:48 [INFO]: Epoch 125 - training loss: 0.2242, validation loss: 0.1533
2024-05-25 00:07:49 [INFO]: Epoch 126 - training loss: 0.2192, validation loss: 0.1557
2024-05-25 00:07:49 [INFO]: Epoch 127 - training loss: 0.2177, validation loss: 0.1539
2024-05-25 00:07:49 [INFO]: Epoch 128 - training loss: 0.2148, validation loss: 0.1537
2024-05-25 00:07:50 [INFO]: Epoch 129 - training loss: 0.2173, validation loss: 0.1563
2024-05-25 00:07:50 [INFO]: Epoch 130 - training loss: 0.2192, validation loss: 0.1526
2024-05-25 00:07:50 [INFO]: Epoch 131 - training loss: 0.2175, validation loss: 0.1530
2024-05-25 00:07:50 [INFO]: Epoch 132 - training loss: 0.2163, validation loss: 0.1562
2024-05-25 00:07:51 [INFO]: Epoch 133 - training loss: 0.2145, validation loss: 0.1521
2024-05-25 00:07:51 [INFO]: Epoch 134 - training loss: 0.2131, validation loss: 0.1519
2024-05-25 00:07:51 [INFO]: Epoch 135 - training loss: 0.2148, validation loss: 0.1530
2024-05-25 00:07:52 [INFO]: Epoch 136 - training loss: 0.2156, validation loss: 0.1528
2024-05-25 00:07:52 [INFO]: Epoch 137 - training loss: 0.2147, validation loss: 0.1547
2024-05-25 00:07:52 [INFO]: Epoch 138 - training loss: 0.2167, validation loss: 0.1520
2024-05-25 00:07:53 [INFO]: Epoch 139 - training loss: 0.2135, validation loss: 0.1532
2024-05-25 00:07:53 [INFO]: Epoch 140 - training loss: 0.2116, validation loss: 0.1518
2024-05-25 00:07:53 [INFO]: Epoch 141 - training loss: 0.2142, validation loss: 0.1535
2024-05-25 00:07:54 [INFO]: Epoch 142 - training loss: 0.2155, validation loss: 0.1520
2024-05-25 00:07:54 [INFO]: Epoch 143 - training loss: 0.2136, validation loss: 0.1507
2024-05-25 00:07:54 [INFO]: Epoch 144 - training loss: 0.2131, validation loss: 0.1510
2024-05-25 00:07:55 [INFO]: Epoch 145 - training loss: 0.2106, validation loss: 0.1506
2024-05-25 00:07:55 [INFO]: Epoch 146 - training loss: 0.2095, validation loss: 0.1515
2024-05-25 00:07:55 [INFO]: Epoch 147 - training loss: 0.2094, validation loss: 0.1502
2024-05-25 00:07:55 [INFO]: Epoch 148 - training loss: 0.2106, validation loss: 0.1511
2024-05-25 00:07:56 [INFO]: Epoch 149 - training loss: 0.2092, validation loss: 0.1520
2024-05-25 00:07:56 [INFO]: Epoch 150 - training loss: 0.2105, validation loss: 0.1517
2024-05-25 00:07:56 [INFO]: Epoch 151 - training loss: 0.2107, validation loss: 0.1495
2024-05-25 00:07:57 [INFO]: Epoch 152 - training loss: 0.2121, validation loss: 0.1489
2024-05-25 00:07:57 [INFO]: Epoch 153 - training loss: 0.2093, validation loss: 0.1495
2024-05-25 00:07:57 [INFO]: Epoch 154 - training loss: 0.2079, validation loss: 0.1504
2024-05-25 00:07:58 [INFO]: Epoch 155 - training loss: 0.2085, validation loss: 0.1502
2024-05-25 00:07:58 [INFO]: Epoch 156 - training loss: 0.2093, validation loss: 0.1491
2024-05-25 00:07:58 [INFO]: Epoch 157 - training loss: 0.2074, validation loss: 0.1500
2024-05-25 00:07:59 [INFO]: Epoch 158 - training loss: 0.2053, validation loss: 0.1493
2024-05-25 00:07:59 [INFO]: Epoch 159 - training loss: 0.2066, validation loss: 0.1482
2024-05-25 00:07:59 [INFO]: Epoch 160 - training loss: 0.2064, validation loss: 0.1483
2024-05-25 00:08:00 [INFO]: Epoch 161 - training loss: 0.2057, validation loss: 0.1495
2024-05-25 00:08:00 [INFO]: Epoch 162 - training loss: 0.2060, validation loss: 0.1511
2024-05-25 00:08:00 [INFO]: Epoch 163 - training loss: 0.2069, validation loss: 0.1468
2024-05-25 00:08:00 [INFO]: Epoch 164 - training loss: 0.2087, validation loss: 0.1492
2024-05-25 00:08:01 [INFO]: Epoch 165 - training loss: 0.2052, validation loss: 0.1475
2024-05-25 00:08:01 [INFO]: Epoch 166 - training loss: 0.2048, validation loss: 0.1490
2024-05-25 00:08:01 [INFO]: Epoch 167 - training loss: 0.2042, validation loss: 0.1480
2024-05-25 00:08:02 [INFO]: Epoch 168 - training loss: 0.2051, validation loss: 0.1467
2024-05-25 00:08:02 [INFO]: Epoch 169 - training loss: 0.2035, validation loss: 0.1483
2024-05-25 00:08:02 [INFO]: Epoch 170 - training loss: 0.2035, validation loss: 0.1490
2024-05-25 00:08:03 [INFO]: Epoch 171 - training loss: 0.2044, validation loss: 0.1474
2024-05-25 00:08:03 [INFO]: Epoch 172 - training loss: 0.2026, validation loss: 0.1466
2024-05-25 00:08:03 [INFO]: Epoch 173 - training loss: 0.2012, validation loss: 0.1464
2024-05-25 00:08:04 [INFO]: Epoch 174 - training loss: 0.2011, validation loss: 0.1467
2024-05-25 00:08:04 [INFO]: Epoch 175 - training loss: 0.2050, validation loss: 0.1468
2024-05-25 00:08:04 [INFO]: Epoch 176 - training loss: 0.2049, validation loss: 0.1455
2024-05-25 00:08:04 [INFO]: Epoch 177 - training loss: 0.2023, validation loss: 0.1473
2024-05-25 00:08:05 [INFO]: Epoch 178 - training loss: 0.2017, validation loss: 0.1462
2024-05-25 00:08:05 [INFO]: Epoch 179 - training loss: 0.1994, validation loss: 0.1468
2024-05-25 00:08:05 [INFO]: Epoch 180 - training loss: 0.2003, validation loss: 0.1471
2024-05-25 00:08:06 [INFO]: Epoch 181 - training loss: 0.2021, validation loss: 0.1457
2024-05-25 00:08:06 [INFO]: Epoch 182 - training loss: 0.1982, validation loss: 0.1466
2024-05-25 00:08:06 [INFO]: Epoch 183 - training loss: 0.1990, validation loss: 0.1474
2024-05-25 00:08:07 [INFO]: Epoch 184 - training loss: 0.2001, validation loss: 0.1455
2024-05-25 00:08:07 [INFO]: Epoch 185 - training loss: 0.1998, validation loss: 0.1465
2024-05-25 00:08:07 [INFO]: Epoch 186 - training loss: 0.1986, validation loss: 0.1459
2024-05-25 00:08:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:08:07 [INFO]: Finished training. The best model is from epoch#176.
2024-05-25 00:08:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/Transformer_air_quality/20240525_T000709/Transformer.pypots
2024-05-25 00:08:07 [INFO]: Transformer on Air-Quality: MAE=0.1659, MSE=0.1301
2024-05-25 00:08:07 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 00:08:07 [INFO]: Using the given device: cuda:0
2024-05-25 00:08:07 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240525_T000807
2024-05-25 00:08:07 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240525_T000807/tensorboard
2024-05-25 00:08:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 00:08:08 [INFO]: Epoch 001 - training loss: 0.3099, validation loss: 0.2782
2024-05-25 00:08:09 [INFO]: Epoch 002 - training loss: 0.2210, validation loss: 0.2370
2024-05-25 00:08:09 [INFO]: Epoch 003 - training loss: 0.1952, validation loss: 0.2163
2024-05-25 00:08:10 [INFO]: Epoch 004 - training loss: 0.1748, validation loss: 0.2021
2024-05-25 00:08:10 [INFO]: Epoch 005 - training loss: 0.1696, validation loss: 0.1994
2024-05-25 00:08:11 [INFO]: Epoch 006 - training loss: 0.1554, validation loss: 0.1913
2024-05-25 00:08:11 [INFO]: Epoch 007 - training loss: 0.1502, validation loss: 0.1844
2024-05-25 00:08:12 [INFO]: Epoch 008 - training loss: 0.1559, validation loss: 0.1855
2024-05-25 00:08:13 [INFO]: Epoch 009 - training loss: 0.1617, validation loss: 0.1987
2024-05-25 00:08:13 [INFO]: Epoch 010 - training loss: 0.1535, validation loss: 0.1808
2024-05-25 00:08:14 [INFO]: Epoch 011 - training loss: 0.1352, validation loss: 0.1780
2024-05-25 00:08:14 [INFO]: Epoch 012 - training loss: 0.1361, validation loss: 0.1740
2024-05-25 00:08:15 [INFO]: Epoch 013 - training loss: 0.1331, validation loss: 0.1767
2024-05-25 00:08:15 [INFO]: Epoch 014 - training loss: 0.1352, validation loss: 0.1762
2024-05-25 00:08:16 [INFO]: Epoch 015 - training loss: 0.1275, validation loss: 0.1713
2024-05-25 00:08:16 [INFO]: Epoch 016 - training loss: 0.1249, validation loss: 0.1715
2024-05-25 00:08:17 [INFO]: Epoch 017 - training loss: 0.1426, validation loss: 0.1703
2024-05-25 00:08:17 [INFO]: Epoch 018 - training loss: 0.1280, validation loss: 0.1654
2024-05-25 00:08:18 [INFO]: Epoch 019 - training loss: 0.1339, validation loss: 0.1668
2024-05-25 00:08:18 [INFO]: Epoch 020 - training loss: 0.1420, validation loss: 0.1670
2024-05-25 00:08:19 [INFO]: Epoch 021 - training loss: 0.1396, validation loss: 0.1671
2024-05-25 00:08:19 [INFO]: Epoch 022 - training loss: 0.1248, validation loss: 0.1729
2024-05-25 00:08:20 [INFO]: Epoch 023 - training loss: 0.1236, validation loss: 0.1639
2024-05-25 00:08:20 [INFO]: Epoch 024 - training loss: 0.1233, validation loss: 0.1671
2024-05-25 00:08:21 [INFO]: Epoch 025 - training loss: 0.1266, validation loss: 0.1629
2024-05-25 00:08:21 [INFO]: Epoch 026 - training loss: 0.1344, validation loss: 0.1673
2024-05-25 00:08:22 [INFO]: Epoch 027 - training loss: 0.1183, validation loss: 0.1678
2024-05-25 00:08:22 [INFO]: Epoch 028 - training loss: 0.1193, validation loss: 0.1669
2024-05-25 00:08:23 [INFO]: Epoch 029 - training loss: 0.1199, validation loss: 0.1644
2024-05-25 00:08:23 [INFO]: Epoch 030 - training loss: 0.1096, validation loss: 0.1633
2024-05-25 00:08:24 [INFO]: Epoch 031 - training loss: 0.1231, validation loss: 0.1635
2024-05-25 00:08:24 [INFO]: Epoch 032 - training loss: 0.1218, validation loss: 0.1590
2024-05-25 00:08:25 [INFO]: Epoch 033 - training loss: 0.1125, validation loss: 0.1623
2024-05-25 00:08:25 [INFO]: Epoch 034 - training loss: 0.1265, validation loss: 0.1600
2024-05-25 00:08:26 [INFO]: Epoch 035 - training loss: 0.1068, validation loss: 0.1627
2024-05-25 00:08:27 [INFO]: Epoch 036 - training loss: 0.1150, validation loss: 0.1609
2024-05-25 00:08:27 [INFO]: Epoch 037 - training loss: 0.1258, validation loss: 0.1608
2024-05-25 00:08:28 [INFO]: Epoch 038 - training loss: 0.1055, validation loss: 0.1614
2024-05-25 00:08:28 [INFO]: Epoch 039 - training loss: 0.1063, validation loss: 0.1577
2024-05-25 00:08:29 [INFO]: Epoch 040 - training loss: 0.1225, validation loss: 0.1596
2024-05-25 00:08:29 [INFO]: Epoch 041 - training loss: 0.1184, validation loss: 0.1599
2024-05-25 00:08:30 [INFO]: Epoch 042 - training loss: 0.1054, validation loss: 0.1601
2024-05-25 00:08:30 [INFO]: Epoch 043 - training loss: 0.1138, validation loss: 0.1635
2024-05-25 00:08:31 [INFO]: Epoch 044 - training loss: 0.1124, validation loss: 0.1593
2024-05-25 00:08:31 [INFO]: Epoch 045 - training loss: 0.1173, validation loss: 0.1585
2024-05-25 00:08:32 [INFO]: Epoch 046 - training loss: 0.0993, validation loss: 0.1634
2024-05-25 00:08:32 [INFO]: Epoch 047 - training loss: 0.1191, validation loss: 0.1632
2024-05-25 00:08:33 [INFO]: Epoch 048 - training loss: 0.1111, validation loss: 0.1619
2024-05-25 00:08:33 [INFO]: Epoch 049 - training loss: 0.0976, validation loss: 0.1556
2024-05-25 00:08:34 [INFO]: Epoch 050 - training loss: 0.0981, validation loss: 0.1581
2024-05-25 00:08:34 [INFO]: Epoch 051 - training loss: 0.0957, validation loss: 0.1607
2024-05-25 00:08:35 [INFO]: Epoch 052 - training loss: 0.1018, validation loss: 0.1553
2024-05-25 00:08:35 [INFO]: Epoch 053 - training loss: 0.1031, validation loss: 0.1545
2024-05-25 00:08:36 [INFO]: Epoch 054 - training loss: 0.1040, validation loss: 0.1568
2024-05-25 00:08:36 [INFO]: Epoch 055 - training loss: 0.0900, validation loss: 0.1574
2024-05-25 00:08:37 [INFO]: Epoch 056 - training loss: 0.0909, validation loss: 0.1586
2024-05-25 00:08:37 [INFO]: Epoch 057 - training loss: 0.1216, validation loss: 0.1534
2024-05-25 00:08:38 [INFO]: Epoch 058 - training loss: 0.0958, validation loss: 0.1594
2024-05-25 00:08:38 [INFO]: Epoch 059 - training loss: 0.1012, validation loss: 0.1562
2024-05-25 00:08:39 [INFO]: Epoch 060 - training loss: 0.1294, validation loss: 0.1624
2024-05-25 00:08:39 [INFO]: Epoch 061 - training loss: 0.1013, validation loss: 0.1586
2024-05-25 00:08:40 [INFO]: Epoch 062 - training loss: 0.1024, validation loss: 0.1531
2024-05-25 00:08:41 [INFO]: Epoch 063 - training loss: 0.0916, validation loss: 0.1604
2024-05-25 00:08:41 [INFO]: Epoch 064 - training loss: 0.0994, validation loss: 0.1557
2024-05-25 00:08:42 [INFO]: Epoch 065 - training loss: 0.0974, validation loss: 0.1549
2024-05-25 00:08:42 [INFO]: Epoch 066 - training loss: 0.1011, validation loss: 0.1539
2024-05-25 00:08:43 [INFO]: Epoch 067 - training loss: 0.0916, validation loss: 0.1518
2024-05-25 00:08:43 [INFO]: Epoch 068 - training loss: 0.0971, validation loss: 0.1525
2024-05-25 00:08:44 [INFO]: Epoch 069 - training loss: 0.0977, validation loss: 0.1545
2024-05-25 00:08:44 [INFO]: Epoch 070 - training loss: 0.0988, validation loss: 0.1547
2024-05-25 00:08:45 [INFO]: Epoch 071 - training loss: 0.1021, validation loss: 0.1542
2024-05-25 00:08:45 [INFO]: Epoch 072 - training loss: 0.0869, validation loss: 0.1542
2024-05-25 00:08:46 [INFO]: Epoch 073 - training loss: 0.0920, validation loss: 0.1545
2024-05-25 00:08:46 [INFO]: Epoch 074 - training loss: 0.1178, validation loss: 0.1531
2024-05-25 00:08:47 [INFO]: Epoch 075 - training loss: 0.1066, validation loss: 0.1532
2024-05-25 00:08:47 [INFO]: Epoch 076 - training loss: 0.0982, validation loss: 0.1560
2024-05-25 00:08:48 [INFO]: Epoch 077 - training loss: 0.0905, validation loss: 0.1588
2024-05-25 00:08:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:08:48 [INFO]: Finished training. The best model is from epoch#67.
2024-05-25 00:08:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/TimesNet_air_quality/20240525_T000807/TimesNet.pypots
2024-05-25 00:08:48 [INFO]: TimesNet on Air-Quality: MAE=0.1599, MSE=0.1542
2024-05-25 00:08:48 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 00:08:48 [INFO]: Using the given device: cuda:0
2024-05-25 00:08:48 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848
2024-05-25 00:08:48 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/tensorboard
2024-05-25 00:08:48 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 00:09:05 [INFO]: Epoch 001 - training loss: 0.4921, validation loss: 0.3412
2024-05-25 00:09:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch1_loss0.34118997752666474.pypots
2024-05-25 00:09:22 [INFO]: Epoch 002 - training loss: 0.3265, validation loss: 0.2747
2024-05-25 00:09:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch2_loss0.2747210532426834.pypots
2024-05-25 00:09:38 [INFO]: Epoch 003 - training loss: 0.2727, validation loss: 0.2745
2024-05-25 00:09:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch3_loss0.274495929479599.pypots
2024-05-25 00:09:55 [INFO]: Epoch 004 - training loss: 0.2743, validation loss: 0.2265
2024-05-25 00:09:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch4_loss0.22652676403522493.pypots
2024-05-25 00:10:12 [INFO]: Epoch 005 - training loss: 0.2183, validation loss: 0.2002
2024-05-25 00:10:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch5_loss0.2001591518521309.pypots
2024-05-25 00:10:29 [INFO]: Epoch 006 - training loss: 0.1967, validation loss: 0.1777
2024-05-25 00:10:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch6_loss0.17773105651140214.pypots
2024-05-25 00:10:45 [INFO]: Epoch 007 - training loss: 0.1862, validation loss: 0.1720
2024-05-25 00:10:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch7_loss0.17204928547143936.pypots
2024-05-25 00:11:02 [INFO]: Epoch 008 - training loss: 0.1887, validation loss: 0.1662
2024-05-25 00:11:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch8_loss0.166182741522789.pypots
2024-05-25 00:11:19 [INFO]: Epoch 009 - training loss: 0.1774, validation loss: 0.1575
2024-05-25 00:11:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch9_loss0.1574898898601532.pypots
2024-05-25 00:11:36 [INFO]: Epoch 010 - training loss: 0.1754, validation loss: 0.1647
2024-05-25 00:11:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch10_loss0.1647108167409897.pypots
2024-05-25 00:11:53 [INFO]: Epoch 011 - training loss: 0.1814, validation loss: 0.1551
2024-05-25 00:11:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch11_loss0.15514872670173646.pypots
2024-05-25 00:12:09 [INFO]: Epoch 012 - training loss: 0.1667, validation loss: 0.1491
2024-05-25 00:12:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch12_loss0.14910234957933427.pypots
2024-05-25 00:12:26 [INFO]: Epoch 013 - training loss: 0.1638, validation loss: 0.1460
2024-05-25 00:12:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch13_loss0.14602395594120027.pypots
2024-05-25 00:12:43 [INFO]: Epoch 014 - training loss: 0.1746, validation loss: 0.1453
2024-05-25 00:12:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch14_loss0.14525429904460907.pypots
2024-05-25 00:13:00 [INFO]: Epoch 015 - training loss: 0.1792, validation loss: 0.1522
2024-05-25 00:13:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch15_loss0.15222782492637635.pypots
2024-05-25 00:13:16 [INFO]: Epoch 016 - training loss: 0.1589, validation loss: 0.1495
2024-05-25 00:13:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch16_loss0.14945028871297836.pypots
2024-05-25 00:13:33 [INFO]: Epoch 017 - training loss: 0.1617, validation loss: 0.1419
2024-05-25 00:13:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch17_loss0.1418689452111721.pypots
2024-05-25 00:13:50 [INFO]: Epoch 018 - training loss: 0.1565, validation loss: 0.1391
2024-05-25 00:13:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch18_loss0.13910333886742593.pypots
2024-05-25 00:14:07 [INFO]: Epoch 019 - training loss: 0.1551, validation loss: 0.1394
2024-05-25 00:14:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch19_loss0.13938076347112655.pypots
2024-05-25 00:14:24 [INFO]: Epoch 020 - training loss: 0.1497, validation loss: 0.1429
2024-05-25 00:14:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch20_loss0.14292335510253906.pypots
2024-05-25 00:14:40 [INFO]: Epoch 021 - training loss: 0.1661, validation loss: 0.1365
2024-05-25 00:14:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch21_loss0.1365406408905983.pypots
2024-05-25 00:14:57 [INFO]: Epoch 022 - training loss: 0.1493, validation loss: 0.1348
2024-05-25 00:14:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch22_loss0.1347752921283245.pypots
2024-05-25 00:15:14 [INFO]: Epoch 023 - training loss: 0.1528, validation loss: 0.1332
2024-05-25 00:15:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch23_loss0.13322340622544288.pypots
2024-05-25 00:15:31 [INFO]: Epoch 024 - training loss: 0.1599, validation loss: 0.1381
2024-05-25 00:15:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch24_loss0.1380827859044075.pypots
2024-05-25 00:15:47 [INFO]: Epoch 025 - training loss: 0.1608, validation loss: 0.1315
2024-05-25 00:15:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch25_loss0.13151310607790948.pypots
2024-05-25 00:16:04 [INFO]: Epoch 026 - training loss: 0.1386, validation loss: 0.1367
2024-05-25 00:16:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch26_loss0.136742439866066.pypots
2024-05-25 00:16:21 [INFO]: Epoch 027 - training loss: 0.1547, validation loss: 0.1305
2024-05-25 00:16:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch27_loss0.13051652610301973.pypots
2024-05-25 00:16:38 [INFO]: Epoch 028 - training loss: 0.1388, validation loss: 0.1303
2024-05-25 00:16:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch28_loss0.13034346625208854.pypots
2024-05-25 00:16:54 [INFO]: Epoch 029 - training loss: 0.1428, validation loss: 0.1330
2024-05-25 00:16:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch29_loss0.13300968408584596.pypots
2024-05-25 00:17:11 [INFO]: Epoch 030 - training loss: 0.1395, validation loss: 0.1277
2024-05-25 00:17:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch30_loss0.12769432961940766.pypots
2024-05-25 00:17:28 [INFO]: Epoch 031 - training loss: 0.1644, validation loss: 0.1251
2024-05-25 00:17:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch31_loss0.12511463984847068.pypots
2024-05-25 00:17:45 [INFO]: Epoch 032 - training loss: 0.1395, validation loss: 0.1232
2024-05-25 00:17:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch32_loss0.1231793411076069.pypots
2024-05-25 00:18:02 [INFO]: Epoch 033 - training loss: 0.1326, validation loss: 0.1283
2024-05-25 00:18:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch33_loss0.12834875136613846.pypots
2024-05-25 00:18:18 [INFO]: Epoch 034 - training loss: 0.1333, validation loss: 0.1278
2024-05-25 00:18:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch34_loss0.1277794636785984.pypots
2024-05-25 00:18:35 [INFO]: Epoch 035 - training loss: 0.1318, validation loss: 0.1336
2024-05-25 00:18:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch35_loss0.1336232155561447.pypots
2024-05-25 00:18:52 [INFO]: Epoch 036 - training loss: 0.1378, validation loss: 0.1235
2024-05-25 00:18:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch36_loss0.12347870767116546.pypots
2024-05-25 00:19:09 [INFO]: Epoch 037 - training loss: 0.1272, validation loss: 0.1253
2024-05-25 00:19:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch37_loss0.125323273986578.pypots
2024-05-25 00:19:25 [INFO]: Epoch 038 - training loss: 0.1243, validation loss: 0.1226
2024-05-25 00:19:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch38_loss0.12260765805840493.pypots
2024-05-25 00:19:42 [INFO]: Epoch 039 - training loss: 0.1362, validation loss: 0.1253
2024-05-25 00:19:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch39_loss0.12530539631843568.pypots
2024-05-25 00:19:59 [INFO]: Epoch 040 - training loss: 0.1130, validation loss: 0.1196
2024-05-25 00:19:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch40_loss0.11960114389657975.pypots
2024-05-25 00:20:16 [INFO]: Epoch 041 - training loss: 0.1340, validation loss: 0.1201
2024-05-25 00:20:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch41_loss0.12005503699183465.pypots
2024-05-25 00:20:33 [INFO]: Epoch 042 - training loss: 0.1405, validation loss: 0.1265
2024-05-25 00:20:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch42_loss0.12651796042919158.pypots
2024-05-25 00:20:49 [INFO]: Epoch 043 - training loss: 0.1360, validation loss: 0.1216
2024-05-25 00:20:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch43_loss0.12163273468613625.pypots
2024-05-25 00:21:06 [INFO]: Epoch 044 - training loss: 0.1287, validation loss: 0.1154
2024-05-25 00:21:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch44_loss0.115399070084095.pypots
2024-05-25 00:21:23 [INFO]: Epoch 045 - training loss: 0.1284, validation loss: 0.1173
2024-05-25 00:21:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch45_loss0.11726027205586434.pypots
2024-05-25 00:21:40 [INFO]: Epoch 046 - training loss: 0.1281, validation loss: 0.1189
2024-05-25 00:21:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch46_loss0.1188618890941143.pypots
2024-05-25 00:21:56 [INFO]: Epoch 047 - training loss: 0.1295, validation loss: 0.1163
2024-05-25 00:21:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch47_loss0.11625193059444427.pypots
2024-05-25 00:22:13 [INFO]: Epoch 048 - training loss: 0.1532, validation loss: 0.1146
2024-05-25 00:22:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch48_loss0.11462043598294258.pypots
2024-05-25 00:22:30 [INFO]: Epoch 049 - training loss: 0.1307, validation loss: 0.1169
2024-05-25 00:22:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch49_loss0.11687267795205117.pypots
2024-05-25 00:22:47 [INFO]: Epoch 050 - training loss: 0.1320, validation loss: 0.1257
2024-05-25 00:22:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch50_loss0.12571173459291457.pypots
2024-05-25 00:23:03 [INFO]: Epoch 051 - training loss: 0.1169, validation loss: 0.1162
2024-05-25 00:23:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch51_loss0.11617602184414863.pypots
2024-05-25 00:23:20 [INFO]: Epoch 052 - training loss: 0.1396, validation loss: 0.1146
2024-05-25 00:23:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch52_loss0.1145737737417221.pypots
2024-05-25 00:23:37 [INFO]: Epoch 053 - training loss: 0.1200, validation loss: 0.1164
2024-05-25 00:23:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch53_loss0.11641011983156205.pypots
2024-05-25 00:23:54 [INFO]: Epoch 054 - training loss: 0.1248, validation loss: 0.1152
2024-05-25 00:23:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch54_loss0.1152448371052742.pypots
2024-05-25 00:24:11 [INFO]: Epoch 055 - training loss: 0.1272, validation loss: 0.1142
2024-05-25 00:24:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch55_loss0.11419299989938736.pypots
2024-05-25 00:24:27 [INFO]: Epoch 056 - training loss: 0.1275, validation loss: 0.1111
2024-05-25 00:24:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch56_loss0.11108247563242912.pypots
2024-05-25 00:24:44 [INFO]: Epoch 057 - training loss: 0.1218, validation loss: 0.1124
2024-05-25 00:24:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch57_loss0.11237600073218346.pypots
2024-05-25 00:25:01 [INFO]: Epoch 058 - training loss: 0.1274, validation loss: 0.1123
2024-05-25 00:25:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch58_loss0.11227242127060891.pypots
2024-05-25 00:25:18 [INFO]: Epoch 059 - training loss: 0.1299, validation loss: 0.1139
2024-05-25 00:25:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch59_loss0.11389204114675522.pypots
2024-05-25 00:25:35 [INFO]: Epoch 060 - training loss: 0.1242, validation loss: 0.1109
2024-05-25 00:25:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch60_loss0.11092663332819938.pypots
2024-05-25 00:25:51 [INFO]: Epoch 061 - training loss: 0.1100, validation loss: 0.1111
2024-05-25 00:25:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch61_loss0.11109462454915046.pypots
2024-05-25 00:26:08 [INFO]: Epoch 062 - training loss: 0.1289, validation loss: 0.1111
2024-05-25 00:26:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch62_loss0.11110580265522003.pypots
2024-05-25 00:26:25 [INFO]: Epoch 063 - training loss: 0.1236, validation loss: 0.1180
2024-05-25 00:26:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch63_loss0.11800543144345284.pypots
2024-05-25 00:26:42 [INFO]: Epoch 064 - training loss: 0.1274, validation loss: 0.1238
2024-05-25 00:26:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch64_loss0.12375149577856064.pypots
2024-05-25 00:26:59 [INFO]: Epoch 065 - training loss: 0.1232, validation loss: 0.1106
2024-05-25 00:26:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch65_loss0.11064855530858039.pypots
2024-05-25 00:27:15 [INFO]: Epoch 066 - training loss: 0.1338, validation loss: 0.1101
2024-05-25 00:27:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch66_loss0.11011174023151397.pypots
2024-05-25 00:27:32 [INFO]: Epoch 067 - training loss: 0.1228, validation loss: 0.1113
2024-05-25 00:27:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch67_loss0.11126933693885803.pypots
2024-05-25 00:27:49 [INFO]: Epoch 068 - training loss: 0.1284, validation loss: 0.1112
2024-05-25 00:27:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch68_loss0.11124227792024613.pypots
2024-05-25 00:28:06 [INFO]: Epoch 069 - training loss: 0.1241, validation loss: 0.1094
2024-05-25 00:28:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch69_loss0.10944627746939659.pypots
2024-05-25 00:28:22 [INFO]: Epoch 070 - training loss: 0.1233, validation loss: 0.1096
2024-05-25 00:28:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch70_loss0.10964790433645248.pypots
2024-05-25 00:28:39 [INFO]: Epoch 071 - training loss: 0.1243, validation loss: 0.1105
2024-05-25 00:28:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch71_loss0.1104545310139656.pypots
2024-05-25 00:28:56 [INFO]: Epoch 072 - training loss: 0.1160, validation loss: 0.1089
2024-05-25 00:28:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch72_loss0.10885087475180626.pypots
2024-05-25 00:29:13 [INFO]: Epoch 073 - training loss: 0.1201, validation loss: 0.1105
2024-05-25 00:29:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch73_loss0.11054953262209892.pypots
2024-05-25 00:29:30 [INFO]: Epoch 074 - training loss: 0.1349, validation loss: 0.1126
2024-05-25 00:29:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch74_loss0.11258915811777115.pypots
2024-05-25 00:29:46 [INFO]: Epoch 075 - training loss: 0.1203, validation loss: 0.1117
2024-05-25 00:29:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch75_loss0.11168272718787194.pypots
2024-05-25 00:30:03 [INFO]: Epoch 076 - training loss: 0.1314, validation loss: 0.1096
2024-05-25 00:30:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch76_loss0.10964715406298638.pypots
2024-05-25 00:30:20 [INFO]: Epoch 077 - training loss: 0.1227, validation loss: 0.1079
2024-05-25 00:30:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch77_loss0.10791131407022476.pypots
2024-05-25 00:30:37 [INFO]: Epoch 078 - training loss: 0.1132, validation loss: 0.1069
2024-05-25 00:30:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch78_loss0.10685898661613465.pypots
2024-05-25 00:30:54 [INFO]: Epoch 079 - training loss: 0.1219, validation loss: 0.1094
2024-05-25 00:30:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch79_loss0.10944252759218216.pypots
2024-05-25 00:31:11 [INFO]: Epoch 080 - training loss: 0.1046, validation loss: 0.1065
2024-05-25 00:31:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch80_loss0.10648194998502732.pypots
2024-05-25 00:31:27 [INFO]: Epoch 081 - training loss: 0.1192, validation loss: 0.1082
2024-05-25 00:31:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch81_loss0.10815479457378388.pypots
2024-05-25 00:31:44 [INFO]: Epoch 082 - training loss: 0.1094, validation loss: 0.1070
2024-05-25 00:31:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch82_loss0.10704234838485718.pypots
2024-05-25 00:32:01 [INFO]: Epoch 083 - training loss: 0.1017, validation loss: 0.1083
2024-05-25 00:32:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch83_loss0.10825039595365524.pypots
2024-05-25 00:32:18 [INFO]: Epoch 084 - training loss: 0.1344, validation loss: 0.1058
2024-05-25 00:32:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch84_loss0.10584677830338478.pypots
2024-05-25 00:32:35 [INFO]: Epoch 085 - training loss: 0.1193, validation loss: 0.1082
2024-05-25 00:32:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch85_loss0.10819119587540627.pypots
2024-05-25 00:32:51 [INFO]: Epoch 086 - training loss: 0.1208, validation loss: 0.1096
2024-05-25 00:32:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch86_loss0.10961652174592018.pypots
2024-05-25 00:33:08 [INFO]: Epoch 087 - training loss: 0.1181, validation loss: 0.1117
2024-05-25 00:33:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch87_loss0.11174144521355629.pypots
2024-05-25 00:33:25 [INFO]: Epoch 088 - training loss: 0.1272, validation loss: 0.1052
2024-05-25 00:33:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch88_loss0.10520300939679146.pypots
2024-05-25 00:33:42 [INFO]: Epoch 089 - training loss: 0.1200, validation loss: 0.1048
2024-05-25 00:33:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch89_loss0.10481003671884537.pypots
2024-05-25 00:33:59 [INFO]: Epoch 090 - training loss: 0.1106, validation loss: 0.1082
2024-05-25 00:33:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch90_loss0.10822248086333275.pypots
2024-05-25 00:34:15 [INFO]: Epoch 091 - training loss: 0.1201, validation loss: 0.1070
2024-05-25 00:34:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch91_loss0.10696985125541687.pypots
2024-05-25 00:34:32 [INFO]: Epoch 092 - training loss: 0.1037, validation loss: 0.1050
2024-05-25 00:34:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch92_loss0.1050318032503128.pypots
2024-05-25 00:34:49 [INFO]: Epoch 093 - training loss: 0.1274, validation loss: 0.1085
2024-05-25 00:34:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch93_loss0.10845305696129799.pypots
2024-05-25 00:35:06 [INFO]: Epoch 094 - training loss: 0.1183, validation loss: 0.1090
2024-05-25 00:35:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch94_loss0.10902711451053619.pypots
2024-05-25 00:35:23 [INFO]: Epoch 095 - training loss: 0.1199, validation loss: 0.1077
2024-05-25 00:35:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch95_loss0.10772719755768775.pypots
2024-05-25 00:35:39 [INFO]: Epoch 096 - training loss: 0.1246, validation loss: 0.1062
2024-05-25 00:35:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch96_loss0.1061818316578865.pypots
2024-05-25 00:35:56 [INFO]: Epoch 097 - training loss: 0.1073, validation loss: 0.1062
2024-05-25 00:35:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch97_loss0.10618818402290345.pypots
2024-05-25 00:36:13 [INFO]: Epoch 098 - training loss: 0.1183, validation loss: 0.1051
2024-05-25 00:36:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch98_loss0.10505484417080879.pypots
2024-05-25 00:36:30 [INFO]: Epoch 099 - training loss: 0.1272, validation loss: 0.1069
2024-05-25 00:36:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI_epoch99_loss0.10687664300203323.pypots
2024-05-25 00:36:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:36:30 [INFO]: Finished training. The best model is from epoch#89.
2024-05-25 00:36:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/CSDI_air_quality/20240525_T000848/CSDI.pypots
2024-05-25 00:38:50 [INFO]: CSDI on Air-Quality: MAE=0.1105, MSE=0.1416
2024-05-25 00:38:50 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 00:38:50 [INFO]: Using the given device: cuda:0
2024-05-25 00:38:50 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T003850
2024-05-25 00:38:50 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T003850/tensorboard
2024-05-25 00:38:50 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 00:38:50 [INFO]: Epoch 001 - training loss: 63891.6010, validation loss: 0.6781
2024-05-25 00:38:51 [INFO]: Epoch 002 - training loss: 42053.1801, validation loss: 0.6013
2024-05-25 00:38:51 [INFO]: Epoch 003 - training loss: 41762.2091, validation loss: 0.5534
2024-05-25 00:38:51 [INFO]: Epoch 004 - training loss: 41629.8811, validation loss: 0.4813
2024-05-25 00:38:52 [INFO]: Epoch 005 - training loss: 41556.5926, validation loss: 0.5148
2024-05-25 00:38:52 [INFO]: Epoch 006 - training loss: 41540.4242, validation loss: 0.5116
2024-05-25 00:38:52 [INFO]: Epoch 007 - training loss: 41481.2545, validation loss: 0.4218
2024-05-25 00:38:53 [INFO]: Epoch 008 - training loss: 41433.1720, validation loss: 0.3963
2024-05-25 00:38:53 [INFO]: Epoch 009 - training loss: 41394.7928, validation loss: 0.3737
2024-05-25 00:38:53 [INFO]: Epoch 010 - training loss: 41392.1088, validation loss: 0.3742
2024-05-25 00:38:53 [INFO]: Epoch 011 - training loss: 41356.0395, validation loss: 0.3694
2024-05-25 00:38:54 [INFO]: Epoch 012 - training loss: 41357.1351, validation loss: 0.3573
2024-05-25 00:38:54 [INFO]: Epoch 013 - training loss: 41336.1153, validation loss: 0.3598
2024-05-25 00:38:54 [INFO]: Epoch 014 - training loss: 41374.7622, validation loss: 0.3538
2024-05-25 00:38:55 [INFO]: Epoch 015 - training loss: 41363.2486, validation loss: 0.3624
2024-05-25 00:38:55 [INFO]: Epoch 016 - training loss: 41316.2574, validation loss: 0.3226
2024-05-25 00:38:55 [INFO]: Epoch 017 - training loss: 41282.7691, validation loss: 0.3305
2024-05-25 00:38:56 [INFO]: Epoch 018 - training loss: 41272.5435, validation loss: 0.3104
2024-05-25 00:38:56 [INFO]: Epoch 019 - training loss: 41264.2815, validation loss: 0.3201
2024-05-25 00:38:56 [INFO]: Epoch 020 - training loss: 41266.2823, validation loss: 0.3035
2024-05-25 00:38:57 [INFO]: Epoch 021 - training loss: 41261.2332, validation loss: 0.3003
2024-05-25 00:38:57 [INFO]: Epoch 022 - training loss: 41322.6902, validation loss: 0.3369
2024-05-25 00:38:57 [INFO]: Epoch 023 - training loss: 41267.3840, validation loss: 0.3064
2024-05-25 00:38:58 [INFO]: Epoch 024 - training loss: 41234.4397, validation loss: 0.2998
2024-05-25 00:38:58 [INFO]: Epoch 025 - training loss: 41225.4116, validation loss: 0.2967
2024-05-25 00:38:58 [INFO]: Epoch 026 - training loss: 41225.1917, validation loss: 0.2789
2024-05-25 00:38:59 [INFO]: Epoch 027 - training loss: 41263.0600, validation loss: 0.2937
2024-05-25 00:38:59 [INFO]: Epoch 028 - training loss: 41312.5055, validation loss: 0.3172
2024-05-25 00:38:59 [INFO]: Epoch 029 - training loss: 41295.4567, validation loss: 0.3005
2024-05-25 00:39:00 [INFO]: Epoch 030 - training loss: 41266.9077, validation loss: 0.3036
2024-05-25 00:39:00 [INFO]: Epoch 031 - training loss: 41227.6331, validation loss: 0.3167
2024-05-25 00:39:00 [INFO]: Epoch 032 - training loss: 41220.8170, validation loss: 0.2776
2024-05-25 00:39:01 [INFO]: Epoch 033 - training loss: 41209.7374, validation loss: 0.2753
2024-05-25 00:39:01 [INFO]: Epoch 034 - training loss: 41197.4821, validation loss: 0.2669
2024-05-25 00:39:01 [INFO]: Epoch 035 - training loss: 41204.6075, validation loss: 0.2763
2024-05-25 00:39:02 [INFO]: Epoch 036 - training loss: 41197.6636, validation loss: 0.2740
2024-05-25 00:39:02 [INFO]: Epoch 037 - training loss: 41188.0674, validation loss: 0.2892
2024-05-25 00:39:02 [INFO]: Epoch 038 - training loss: 41183.2416, validation loss: 0.2722
2024-05-25 00:39:03 [INFO]: Epoch 039 - training loss: 41189.5162, validation loss: 0.2980
2024-05-25 00:39:03 [INFO]: Epoch 040 - training loss: 41215.8562, validation loss: 0.2959
2024-05-25 00:39:03 [INFO]: Epoch 041 - training loss: 41258.5916, validation loss: 0.2881
2024-05-25 00:39:04 [INFO]: Epoch 042 - training loss: 41231.8322, validation loss: 0.3116
2024-05-25 00:39:04 [INFO]: Epoch 043 - training loss: 41239.4544, validation loss: 0.2786
2024-05-25 00:39:04 [INFO]: Epoch 044 - training loss: 41189.4171, validation loss: 0.2734
2024-05-25 00:39:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:39:04 [INFO]: Finished training. The best model is from epoch#34.
2024-05-25 00:39:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/GPVAE_air_quality/20240525_T003850/GPVAE.pypots
2024-05-25 00:39:04 [INFO]: GP-VAE on Air-Quality: MAE=0.3139, MSE=0.2709
2024-05-25 00:39:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 00:39:04 [INFO]: Using the given device: cuda:0
2024-05-25 00:39:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T003904
2024-05-25 00:39:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T003904/tensorboard
2024-05-25 00:39:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 00:39:09 [INFO]: Epoch 001 - generator training loss: 0.6122, discriminator training loss: 0.2918, validation loss: 0.5338
2024-05-25 00:39:13 [INFO]: Epoch 002 - generator training loss: 0.2934, discriminator training loss: 0.0673, validation loss: 0.4077
2024-05-25 00:39:17 [INFO]: Epoch 003 - generator training loss: 0.2200, discriminator training loss: 0.0630, validation loss: 0.3386
2024-05-25 00:39:22 [INFO]: Epoch 004 - generator training loss: 0.1799, discriminator training loss: 0.0621, validation loss: 0.2966
2024-05-25 00:39:26 [INFO]: Epoch 005 - generator training loss: 0.1548, discriminator training loss: 0.0612, validation loss: 0.2707
2024-05-25 00:39:30 [INFO]: Epoch 006 - generator training loss: 0.1356, discriminator training loss: 0.0611, validation loss: 0.2505
2024-05-25 00:39:34 [INFO]: Epoch 007 - generator training loss: 0.1216, discriminator training loss: 0.0606, validation loss: 0.2349
2024-05-25 00:39:38 [INFO]: Epoch 008 - generator training loss: 0.1106, discriminator training loss: 0.0603, validation loss: 0.2236
2024-05-25 00:39:42 [INFO]: Epoch 009 - generator training loss: 0.1062, discriminator training loss: 0.0594, validation loss: 0.2148
2024-05-25 00:39:46 [INFO]: Epoch 010 - generator training loss: 0.0961, discriminator training loss: 0.0587, validation loss: 0.2074
2024-05-25 00:39:50 [INFO]: Epoch 011 - generator training loss: 0.0920, discriminator training loss: 0.0579, validation loss: 0.2024
2024-05-25 00:39:54 [INFO]: Epoch 012 - generator training loss: 0.0878, discriminator training loss: 0.0566, validation loss: 0.1968
2024-05-25 00:39:59 [INFO]: Epoch 013 - generator training loss: 0.0842, discriminator training loss: 0.0555, validation loss: 0.1924
2024-05-25 00:40:03 [INFO]: Epoch 014 - generator training loss: 0.0812, discriminator training loss: 0.0536, validation loss: 0.1884
2024-05-25 00:40:07 [INFO]: Epoch 015 - generator training loss: 0.0795, discriminator training loss: 0.0515, validation loss: 0.1861
2024-05-25 00:40:11 [INFO]: Epoch 016 - generator training loss: 0.0773, discriminator training loss: 0.0498, validation loss: 0.1826
2024-05-25 00:40:15 [INFO]: Epoch 017 - generator training loss: 0.0748, discriminator training loss: 0.0482, validation loss: 0.1793
2024-05-25 00:40:19 [INFO]: Epoch 018 - generator training loss: 0.0734, discriminator training loss: 0.0485, validation loss: 0.1775
2024-05-25 00:40:23 [INFO]: Epoch 019 - generator training loss: 0.0710, discriminator training loss: 0.0467, validation loss: 0.1753
2024-05-25 00:40:27 [INFO]: Epoch 020 - generator training loss: 0.0701, discriminator training loss: 0.0455, validation loss: 0.1735
2024-05-25 00:40:32 [INFO]: Epoch 021 - generator training loss: 0.0694, discriminator training loss: 0.0446, validation loss: 0.1714
2024-05-25 00:40:36 [INFO]: Epoch 022 - generator training loss: 0.0670, discriminator training loss: 0.0443, validation loss: 0.1694
2024-05-25 00:40:40 [INFO]: Epoch 023 - generator training loss: 0.0645, discriminator training loss: 0.0438, validation loss: 0.1678
2024-05-25 00:40:44 [INFO]: Epoch 024 - generator training loss: 0.0633, discriminator training loss: 0.0427, validation loss: 0.1662
2024-05-25 00:40:48 [INFO]: Epoch 025 - generator training loss: 0.0632, discriminator training loss: 0.0418, validation loss: 0.1661
2024-05-25 00:40:52 [INFO]: Epoch 026 - generator training loss: 0.0616, discriminator training loss: 0.0411, validation loss: 0.1642
2024-05-25 00:40:56 [INFO]: Epoch 027 - generator training loss: 0.0596, discriminator training loss: 0.0407, validation loss: 0.1627
2024-05-25 00:41:01 [INFO]: Epoch 028 - generator training loss: 0.0605, discriminator training loss: 0.0402, validation loss: 0.1616
2024-05-25 00:41:05 [INFO]: Epoch 029 - generator training loss: 0.0591, discriminator training loss: 0.0391, validation loss: 0.1604
2024-05-25 00:41:09 [INFO]: Epoch 030 - generator training loss: 0.0582, discriminator training loss: 0.0381, validation loss: 0.1598
2024-05-25 00:41:13 [INFO]: Epoch 031 - generator training loss: 0.0569, discriminator training loss: 0.0374, validation loss: 0.1582
2024-05-25 00:41:17 [INFO]: Epoch 032 - generator training loss: 0.0569, discriminator training loss: 0.0361, validation loss: 0.1578
2024-05-25 00:41:22 [INFO]: Epoch 033 - generator training loss: 0.0559, discriminator training loss: 0.0353, validation loss: 0.1572
2024-05-25 00:41:26 [INFO]: Epoch 034 - generator training loss: 0.0560, discriminator training loss: 0.0345, validation loss: 0.1563
2024-05-25 00:41:30 [INFO]: Epoch 035 - generator training loss: 0.0549, discriminator training loss: 0.0339, validation loss: 0.1551
2024-05-25 00:41:34 [INFO]: Epoch 036 - generator training loss: 0.0547, discriminator training loss: 0.0331, validation loss: 0.1541
2024-05-25 00:41:39 [INFO]: Epoch 037 - generator training loss: 0.0545, discriminator training loss: 0.0324, validation loss: 0.1540
2024-05-25 00:41:43 [INFO]: Epoch 038 - generator training loss: 0.0551, discriminator training loss: 0.0320, validation loss: 0.1529
2024-05-25 00:41:47 [INFO]: Epoch 039 - generator training loss: 0.0537, discriminator training loss: 0.0310, validation loss: 0.1525
2024-05-25 00:41:52 [INFO]: Epoch 040 - generator training loss: 0.0533, discriminator training loss: 0.0306, validation loss: 0.1517
2024-05-25 00:41:56 [INFO]: Epoch 041 - generator training loss: 0.0534, discriminator training loss: 0.0296, validation loss: 0.1512
2024-05-25 00:42:00 [INFO]: Epoch 042 - generator training loss: 0.0541, discriminator training loss: 0.0292, validation loss: 0.1503
2024-05-25 00:42:05 [INFO]: Epoch 043 - generator training loss: 0.0523, discriminator training loss: 0.0287, validation loss: 0.1499
2024-05-25 00:42:09 [INFO]: Epoch 044 - generator training loss: 0.0521, discriminator training loss: 0.0279, validation loss: 0.1497
2024-05-25 00:42:13 [INFO]: Epoch 045 - generator training loss: 0.0516, discriminator training loss: 0.0276, validation loss: 0.1492
2024-05-25 00:42:18 [INFO]: Epoch 046 - generator training loss: 0.0524, discriminator training loss: 0.0270, validation loss: 0.1482
2024-05-25 00:42:22 [INFO]: Epoch 047 - generator training loss: 0.0508, discriminator training loss: 0.0266, validation loss: 0.1476
2024-05-25 00:42:26 [INFO]: Epoch 048 - generator training loss: 0.0502, discriminator training loss: 0.0259, validation loss: 0.1478
2024-05-25 00:42:30 [INFO]: Epoch 049 - generator training loss: 0.0500, discriminator training loss: 0.0258, validation loss: 0.1476
2024-05-25 00:42:34 [INFO]: Epoch 050 - generator training loss: 0.0498, discriminator training loss: 0.0249, validation loss: 0.1468
2024-05-25 00:42:39 [INFO]: Epoch 051 - generator training loss: 0.0492, discriminator training loss: 0.0247, validation loss: 0.1458
2024-05-25 00:42:43 [INFO]: Epoch 052 - generator training loss: 0.0491, discriminator training loss: 0.0244, validation loss: 0.1449
2024-05-25 00:42:47 [INFO]: Epoch 053 - generator training loss: 0.0489, discriminator training loss: 0.0240, validation loss: 0.1455
2024-05-25 00:42:51 [INFO]: Epoch 054 - generator training loss: 0.0491, discriminator training loss: 0.0236, validation loss: 0.1459
2024-05-25 00:42:56 [INFO]: Epoch 055 - generator training loss: 0.0479, discriminator training loss: 0.0233, validation loss: 0.1450
2024-05-25 00:43:00 [INFO]: Epoch 056 - generator training loss: 0.0474, discriminator training loss: 0.0230, validation loss: 0.1442
2024-05-25 00:43:04 [INFO]: Epoch 057 - generator training loss: 0.0475, discriminator training loss: 0.0228, validation loss: 0.1438
2024-05-25 00:43:09 [INFO]: Epoch 058 - generator training loss: 0.0469, discriminator training loss: 0.0223, validation loss: 0.1437
2024-05-25 00:43:13 [INFO]: Epoch 059 - generator training loss: 0.0463, discriminator training loss: 0.0221, validation loss: 0.1435
2024-05-25 00:43:18 [INFO]: Epoch 060 - generator training loss: 0.0469, discriminator training loss: 0.0218, validation loss: 0.1440
2024-05-25 00:43:22 [INFO]: Epoch 061 - generator training loss: 0.0463, discriminator training loss: 0.0215, validation loss: 0.1425
2024-05-25 00:43:26 [INFO]: Epoch 062 - generator training loss: 0.0453, discriminator training loss: 0.0213, validation loss: 0.1434
2024-05-25 00:43:30 [INFO]: Epoch 063 - generator training loss: 0.0451, discriminator training loss: 0.0211, validation loss: 0.1425
2024-05-25 00:43:34 [INFO]: Epoch 064 - generator training loss: 0.0449, discriminator training loss: 0.0209, validation loss: 0.1431
2024-05-25 00:43:38 [INFO]: Epoch 065 - generator training loss: 0.0454, discriminator training loss: 0.0205, validation loss: 0.1417
2024-05-25 00:43:43 [INFO]: Epoch 066 - generator training loss: 0.0449, discriminator training loss: 0.0204, validation loss: 0.1426
2024-05-25 00:43:47 [INFO]: Epoch 067 - generator training loss: 0.0441, discriminator training loss: 0.0201, validation loss: 0.1414
2024-05-25 00:43:51 [INFO]: Epoch 068 - generator training loss: 0.0452, discriminator training loss: 0.0200, validation loss: 0.1421
2024-05-25 00:43:55 [INFO]: Epoch 069 - generator training loss: 0.0438, discriminator training loss: 0.0200, validation loss: 0.1425
2024-05-25 00:44:00 [INFO]: Epoch 070 - generator training loss: 0.0434, discriminator training loss: 0.0195, validation loss: 0.1411
2024-05-25 00:44:04 [INFO]: Epoch 071 - generator training loss: 0.0427, discriminator training loss: 0.0192, validation loss: 0.1413
2024-05-25 00:44:08 [INFO]: Epoch 072 - generator training loss: 0.0432, discriminator training loss: 0.0188, validation loss: 0.1413
2024-05-25 00:44:13 [INFO]: Epoch 073 - generator training loss: 0.0423, discriminator training loss: 0.0187, validation loss: 0.1414
2024-05-25 00:44:17 [INFO]: Epoch 074 - generator training loss: 0.0424, discriminator training loss: 0.0186, validation loss: 0.1405
2024-05-25 00:44:21 [INFO]: Epoch 075 - generator training loss: 0.0419, discriminator training loss: 0.0187, validation loss: 0.1414
2024-05-25 00:44:26 [INFO]: Epoch 076 - generator training loss: 0.0418, discriminator training loss: 0.0184, validation loss: 0.1414
2024-05-25 00:44:30 [INFO]: Epoch 077 - generator training loss: 0.0422, discriminator training loss: 0.0180, validation loss: 0.1415
2024-05-25 00:44:34 [INFO]: Epoch 078 - generator training loss: 0.0415, discriminator training loss: 0.0180, validation loss: 0.1413
2024-05-25 00:44:38 [INFO]: Epoch 079 - generator training loss: 0.0411, discriminator training loss: 0.0180, validation loss: 0.1422
2024-05-25 00:44:42 [INFO]: Epoch 080 - generator training loss: 0.0412, discriminator training loss: 0.0179, validation loss: 0.1418
2024-05-25 00:44:47 [INFO]: Epoch 081 - generator training loss: 0.0406, discriminator training loss: 0.0176, validation loss: 0.1414
2024-05-25 00:44:51 [INFO]: Epoch 082 - generator training loss: 0.0409, discriminator training loss: 0.0175, validation loss: 0.1417
2024-05-25 00:44:55 [INFO]: Epoch 083 - generator training loss: 0.0403, discriminator training loss: 0.0175, validation loss: 0.1409
2024-05-25 00:45:00 [INFO]: Epoch 084 - generator training loss: 0.0410, discriminator training loss: 0.0173, validation loss: 0.1406
2024-05-25 00:45:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 00:45:00 [INFO]: Finished training. The best model is from epoch#74.
2024-05-25 00:45:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/USGAN_air_quality/20240525_T003904/USGAN.pypots
2024-05-25 00:45:00 [INFO]: US-GAN on Air-Quality: MAE=0.2064, MSE=0.1322
2024-05-25 00:45:00 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 00:45:00 [INFO]: Using the given device: cuda:0
2024-05-25 00:45:00 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T004500
2024-05-25 00:45:00 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T004500/tensorboard
2024-05-25 00:45:00 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 00:45:04 [INFO]: Epoch 001 - training loss: 1.4251, validation loss: 0.9605
2024-05-25 00:45:07 [INFO]: Epoch 002 - training loss: 1.1412, validation loss: 0.7179
2024-05-25 00:45:10 [INFO]: Epoch 003 - training loss: 0.9452, validation loss: 0.6072
2024-05-25 00:45:13 [INFO]: Epoch 004 - training loss: 0.8383, validation loss: 0.5407
2024-05-25 00:45:16 [INFO]: Epoch 005 - training loss: 0.7612, validation loss: 0.4946
2024-05-25 00:45:19 [INFO]: Epoch 006 - training loss: 0.7017, validation loss: 0.4561
2024-05-25 00:45:22 [INFO]: Epoch 007 - training loss: 0.6574, validation loss: 0.4259
2024-05-25 00:45:25 [INFO]: Epoch 008 - training loss: 0.6232, validation loss: 0.4008
2024-05-25 00:45:28 [INFO]: Epoch 009 - training loss: 0.5952, validation loss: 0.3807
2024-05-25 00:45:30 [INFO]: Epoch 010 - training loss: 0.5752, validation loss: 0.3642
2024-05-25 00:45:33 [INFO]: Epoch 011 - training loss: 0.5561, validation loss: 0.3494
2024-05-25 00:45:36 [INFO]: Epoch 012 - training loss: 0.5422, validation loss: 0.3372
2024-05-25 00:45:39 [INFO]: Epoch 013 - training loss: 0.5275, validation loss: 0.3265
2024-05-25 00:45:42 [INFO]: Epoch 014 - training loss: 0.5180, validation loss: 0.3179
2024-05-25 00:45:45 [INFO]: Epoch 015 - training loss: 0.5057, validation loss: 0.3096
2024-05-25 00:45:48 [INFO]: Epoch 016 - training loss: 0.4966, validation loss: 0.3025
2024-05-25 00:45:50 [INFO]: Epoch 017 - training loss: 0.4875, validation loss: 0.2963
2024-05-25 00:45:53 [INFO]: Epoch 018 - training loss: 0.4802, validation loss: 0.2904
2024-05-25 00:45:56 [INFO]: Epoch 019 - training loss: 0.4717, validation loss: 0.2847
2024-05-25 00:45:59 [INFO]: Epoch 020 - training loss: 0.4661, validation loss: 0.2795
2024-05-25 00:46:02 [INFO]: Epoch 021 - training loss: 0.4572, validation loss: 0.2750
2024-05-25 00:46:04 [INFO]: Epoch 022 - training loss: 0.4510, validation loss: 0.2707
2024-05-25 00:46:07 [INFO]: Epoch 023 - training loss: 0.4442, validation loss: 0.2665
2024-05-25 00:46:10 [INFO]: Epoch 024 - training loss: 0.4396, validation loss: 0.2626
2024-05-25 00:46:13 [INFO]: Epoch 025 - training loss: 0.4330, validation loss: 0.2590
2024-05-25 00:46:16 [INFO]: Epoch 026 - training loss: 0.4280, validation loss: 0.2549
2024-05-25 00:46:18 [INFO]: Epoch 027 - training loss: 0.4224, validation loss: 0.2520
2024-05-25 00:46:21 [INFO]: Epoch 028 - training loss: 0.4183, validation loss: 0.2487
2024-05-25 00:46:24 [INFO]: Epoch 029 - training loss: 0.4137, validation loss: 0.2454
2024-05-25 00:46:27 [INFO]: Epoch 030 - training loss: 0.4080, validation loss: 0.2423
2024-05-25 00:46:30 [INFO]: Epoch 031 - training loss: 0.4034, validation loss: 0.2393
2024-05-25 00:46:33 [INFO]: Epoch 032 - training loss: 0.4005, validation loss: 0.2364
2024-05-25 00:46:35 [INFO]: Epoch 033 - training loss: 0.3954, validation loss: 0.2333
2024-05-25 00:46:38 [INFO]: Epoch 034 - training loss: 0.3908, validation loss: 0.2305
2024-05-25 00:46:41 [INFO]: Epoch 035 - training loss: 0.3874, validation loss: 0.2282
2024-05-25 00:46:44 [INFO]: Epoch 036 - training loss: 0.3832, validation loss: 0.2256
2024-05-25 00:46:47 [INFO]: Epoch 037 - training loss: 0.3796, validation loss: 0.2227
2024-05-25 00:46:49 [INFO]: Epoch 038 - training loss: 0.3755, validation loss: 0.2205
2024-05-25 00:46:52 [INFO]: Epoch 039 - training loss: 0.3729, validation loss: 0.2183
2024-05-25 00:46:55 [INFO]: Epoch 040 - training loss: 0.3689, validation loss: 0.2158
2024-05-25 00:46:58 [INFO]: Epoch 041 - training loss: 0.3655, validation loss: 0.2128
2024-05-25 00:47:01 [INFO]: Epoch 042 - training loss: 0.3625, validation loss: 0.2106
2024-05-25 00:47:03 [INFO]: Epoch 043 - training loss: 0.3602, validation loss: 0.2083
2024-05-25 00:47:06 [INFO]: Epoch 044 - training loss: 0.3575, validation loss: 0.2063
2024-05-25 00:47:09 [INFO]: Epoch 045 - training loss: 0.3544, validation loss: 0.2040
2024-05-25 00:47:12 [INFO]: Epoch 046 - training loss: 0.3512, validation loss: 0.2017
2024-05-25 00:47:15 [INFO]: Epoch 047 - training loss: 0.3483, validation loss: 0.1998
2024-05-25 00:47:17 [INFO]: Epoch 048 - training loss: 0.3465, validation loss: 0.1976
2024-05-25 00:47:20 [INFO]: Epoch 049 - training loss: 0.3444, validation loss: 0.1960
2024-05-25 00:47:23 [INFO]: Epoch 050 - training loss: 0.3420, validation loss: 0.1936
2024-05-25 00:47:26 [INFO]: Epoch 051 - training loss: 0.3394, validation loss: 0.1922
2024-05-25 00:47:29 [INFO]: Epoch 052 - training loss: 0.3373, validation loss: 0.1906
2024-05-25 00:47:32 [INFO]: Epoch 053 - training loss: 0.3342, validation loss: 0.1889
2024-05-25 00:47:34 [INFO]: Epoch 054 - training loss: 0.3327, validation loss: 0.1874
2024-05-25 00:47:37 [INFO]: Epoch 055 - training loss: 0.3309, validation loss: 0.1860
2024-05-25 00:47:40 [INFO]: Epoch 056 - training loss: 0.3283, validation loss: 0.1845
2024-05-25 00:47:43 [INFO]: Epoch 057 - training loss: 0.3281, validation loss: 0.1836
2024-05-25 00:47:46 [INFO]: Epoch 058 - training loss: 0.3252, validation loss: 0.1813
2024-05-25 00:47:49 [INFO]: Epoch 059 - training loss: 0.3232, validation loss: 0.1804
2024-05-25 00:47:51 [INFO]: Epoch 060 - training loss: 0.3220, validation loss: 0.1792
2024-05-25 00:47:54 [INFO]: Epoch 061 - training loss: 0.3201, validation loss: 0.1782
2024-05-25 00:47:57 [INFO]: Epoch 062 - training loss: 0.3178, validation loss: 0.1773
2024-05-25 00:48:00 [INFO]: Epoch 063 - training loss: 0.3167, validation loss: 0.1763
2024-05-25 00:48:03 [INFO]: Epoch 064 - training loss: 0.3154, validation loss: 0.1751
2024-05-25 00:48:06 [INFO]: Epoch 065 - training loss: 0.3152, validation loss: 0.1745
2024-05-25 00:48:09 [INFO]: Epoch 066 - training loss: 0.3121, validation loss: 0.1727
2024-05-25 00:48:12 [INFO]: Epoch 067 - training loss: 0.3104, validation loss: 0.1721
2024-05-25 00:48:14 [INFO]: Epoch 068 - training loss: 0.3089, validation loss: 0.1716
2024-05-25 00:48:17 [INFO]: Epoch 069 - training loss: 0.3083, validation loss: 0.1704
2024-05-25 00:48:20 [INFO]: Epoch 070 - training loss: 0.3065, validation loss: 0.1696
2024-05-25 00:48:23 [INFO]: Epoch 071 - training loss: 0.3056, validation loss: 0.1690
2024-05-25 00:48:26 [INFO]: Epoch 072 - training loss: 0.3042, validation loss: 0.1681
2024-05-25 00:48:29 [INFO]: Epoch 073 - training loss: 0.3034, validation loss: 0.1674
2024-05-25 00:48:32 [INFO]: Epoch 074 - training loss: 0.3023, validation loss: 0.1665
2024-05-25 00:48:35 [INFO]: Epoch 075 - training loss: 0.3013, validation loss: 0.1660
2024-05-25 00:48:38 [INFO]: Epoch 076 - training loss: 0.3004, validation loss: 0.1655
2024-05-25 00:48:40 [INFO]: Epoch 077 - training loss: 0.2987, validation loss: 0.1648
2024-05-25 00:48:43 [INFO]: Epoch 078 - training loss: 0.2979, validation loss: 0.1641
2024-05-25 00:48:46 [INFO]: Epoch 079 - training loss: 0.2967, validation loss: 0.1634
2024-05-25 00:48:49 [INFO]: Epoch 080 - training loss: 0.2956, validation loss: 0.1627
2024-05-25 00:48:52 [INFO]: Epoch 081 - training loss: 0.2950, validation loss: 0.1622
2024-05-25 00:48:54 [INFO]: Epoch 082 - training loss: 0.2942, validation loss: 0.1616
2024-05-25 00:48:57 [INFO]: Epoch 083 - training loss: 0.2933, validation loss: 0.1607
2024-05-25 00:49:00 [INFO]: Epoch 084 - training loss: 0.2918, validation loss: 0.1602
2024-05-25 00:49:03 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1597
2024-05-25 00:49:06 [INFO]: Epoch 086 - training loss: 0.2906, validation loss: 0.1592
2024-05-25 00:49:09 [INFO]: Epoch 087 - training loss: 0.2897, validation loss: 0.1586
2024-05-25 00:49:11 [INFO]: Epoch 088 - training loss: 0.2888, validation loss: 0.1582
2024-05-25 00:49:14 [INFO]: Epoch 089 - training loss: 0.2875, validation loss: 0.1571
2024-05-25 00:49:17 [INFO]: Epoch 090 - training loss: 0.2874, validation loss: 0.1570
2024-05-25 00:49:20 [INFO]: Epoch 091 - training loss: 0.2865, validation loss: 0.1565
2024-05-25 00:49:23 [INFO]: Epoch 092 - training loss: 0.2860, validation loss: 0.1559
2024-05-25 00:49:25 [INFO]: Epoch 093 - training loss: 0.2852, validation loss: 0.1554
2024-05-25 00:49:28 [INFO]: Epoch 094 - training loss: 0.2838, validation loss: 0.1546
2024-05-25 00:49:31 [INFO]: Epoch 095 - training loss: 0.2831, validation loss: 0.1542
2024-05-25 00:49:34 [INFO]: Epoch 096 - training loss: 0.2833, validation loss: 0.1539
2024-05-25 00:49:37 [INFO]: Epoch 097 - training loss: 0.2826, validation loss: 0.1534
2024-05-25 00:49:40 [INFO]: Epoch 098 - training loss: 0.2817, validation loss: 0.1528
2024-05-25 00:49:42 [INFO]: Epoch 099 - training loss: 0.2814, validation loss: 0.1523
2024-05-25 00:49:45 [INFO]: Epoch 100 - training loss: 0.2806, validation loss: 0.1517
2024-05-25 00:49:48 [INFO]: Epoch 101 - training loss: 0.2795, validation loss: 0.1515
2024-05-25 00:49:51 [INFO]: Epoch 102 - training loss: 0.2794, validation loss: 0.1508
2024-05-25 00:49:54 [INFO]: Epoch 103 - training loss: 0.2783, validation loss: 0.1505
2024-05-25 00:49:57 [INFO]: Epoch 104 - training loss: 0.2772, validation loss: 0.1502
2024-05-25 00:50:00 [INFO]: Epoch 105 - training loss: 0.2769, validation loss: 0.1497
2024-05-25 00:50:02 [INFO]: Epoch 106 - training loss: 0.2768, validation loss: 0.1492
2024-05-25 00:50:05 [INFO]: Epoch 107 - training loss: 0.2756, validation loss: 0.1487
2024-05-25 00:50:08 [INFO]: Epoch 108 - training loss: 0.2753, validation loss: 0.1484
2024-05-25 00:50:11 [INFO]: Epoch 109 - training loss: 0.2748, validation loss: 0.1481
2024-05-25 00:50:14 [INFO]: Epoch 110 - training loss: 0.2743, validation loss: 0.1476
2024-05-25 00:50:17 [INFO]: Epoch 111 - training loss: 0.2739, validation loss: 0.1472
2024-05-25 00:50:20 [INFO]: Epoch 112 - training loss: 0.2733, validation loss: 0.1467
2024-05-25 00:50:23 [INFO]: Epoch 113 - training loss: 0.2732, validation loss: 0.1465
2024-05-25 00:50:26 [INFO]: Epoch 114 - training loss: 0.2718, validation loss: 0.1463
2024-05-25 00:50:29 [INFO]: Epoch 115 - training loss: 0.2718, validation loss: 0.1458
2024-05-25 00:50:31 [INFO]: Epoch 116 - training loss: 0.2707, validation loss: 0.1456
2024-05-25 00:50:34 [INFO]: Epoch 117 - training loss: 0.2705, validation loss: 0.1452
2024-05-25 00:50:37 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1447
2024-05-25 00:50:40 [INFO]: Epoch 119 - training loss: 0.2699, validation loss: 0.1444
2024-05-25 00:50:43 [INFO]: Epoch 120 - training loss: 0.2689, validation loss: 0.1440
2024-05-25 00:50:46 [INFO]: Epoch 121 - training loss: 0.2684, validation loss: 0.1439
2024-05-25 00:50:49 [INFO]: Epoch 122 - training loss: 0.2680, validation loss: 0.1436
2024-05-25 00:50:52 [INFO]: Epoch 123 - training loss: 0.2679, validation loss: 0.1433
2024-05-25 00:50:55 [INFO]: Epoch 124 - training loss: 0.2674, validation loss: 0.1427
2024-05-25 00:50:57 [INFO]: Epoch 125 - training loss: 0.2662, validation loss: 0.1426
2024-05-25 00:51:00 [INFO]: Epoch 126 - training loss: 0.2669, validation loss: 0.1423
2024-05-25 00:51:03 [INFO]: Epoch 127 - training loss: 0.2656, validation loss: 0.1418
2024-05-25 00:51:06 [INFO]: Epoch 128 - training loss: 0.2649, validation loss: 0.1417
2024-05-25 00:51:09 [INFO]: Epoch 129 - training loss: 0.2645, validation loss: 0.1415
2024-05-25 00:51:12 [INFO]: Epoch 130 - training loss: 0.2653, validation loss: 0.1410
2024-05-25 00:51:15 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1409
2024-05-25 00:51:18 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1404
2024-05-25 00:51:21 [INFO]: Epoch 133 - training loss: 0.2630, validation loss: 0.1401
2024-05-25 00:51:24 [INFO]: Epoch 134 - training loss: 0.2627, validation loss: 0.1400
2024-05-25 00:51:27 [INFO]: Epoch 135 - training loss: 0.2618, validation loss: 0.1395
2024-05-25 00:51:30 [INFO]: Epoch 136 - training loss: 0.2619, validation loss: 0.1392
2024-05-25 00:51:33 [INFO]: Epoch 137 - training loss: 0.2618, validation loss: 0.1391
2024-05-25 00:51:36 [INFO]: Epoch 138 - training loss: 0.2611, validation loss: 0.1388
2024-05-25 00:51:38 [INFO]: Epoch 139 - training loss: 0.2610, validation loss: 0.1386
2024-05-25 00:51:41 [INFO]: Epoch 140 - training loss: 0.2603, validation loss: 0.1381
2024-05-25 00:51:44 [INFO]: Epoch 141 - training loss: 0.2601, validation loss: 0.1379
2024-05-25 00:51:47 [INFO]: Epoch 142 - training loss: 0.2593, validation loss: 0.1377
2024-05-25 00:51:50 [INFO]: Epoch 143 - training loss: 0.2597, validation loss: 0.1375
2024-05-25 00:51:53 [INFO]: Epoch 144 - training loss: 0.2586, validation loss: 0.1371
2024-05-25 00:51:56 [INFO]: Epoch 145 - training loss: 0.2591, validation loss: 0.1369
2024-05-25 00:51:59 [INFO]: Epoch 146 - training loss: 0.2584, validation loss: 0.1366
2024-05-25 00:52:02 [INFO]: Epoch 147 - training loss: 0.2578, validation loss: 0.1365
2024-05-25 00:52:05 [INFO]: Epoch 148 - training loss: 0.2575, validation loss: 0.1364
2024-05-25 00:52:08 [INFO]: Epoch 149 - training loss: 0.2572, validation loss: 0.1361
2024-05-25 00:52:11 [INFO]: Epoch 150 - training loss: 0.2573, validation loss: 0.1356
2024-05-25 00:52:14 [INFO]: Epoch 151 - training loss: 0.2562, validation loss: 0.1356
2024-05-25 00:52:17 [INFO]: Epoch 152 - training loss: 0.2563, validation loss: 0.1354
2024-05-25 00:52:20 [INFO]: Epoch 153 - training loss: 0.2559, validation loss: 0.1350
2024-05-25 00:52:23 [INFO]: Epoch 154 - training loss: 0.2558, validation loss: 0.1350
2024-05-25 00:52:25 [INFO]: Epoch 155 - training loss: 0.2553, validation loss: 0.1348
2024-05-25 00:52:28 [INFO]: Epoch 156 - training loss: 0.2554, validation loss: 0.1347
2024-05-25 00:52:31 [INFO]: Epoch 157 - training loss: 0.2545, validation loss: 0.1343
2024-05-25 00:52:34 [INFO]: Epoch 158 - training loss: 0.2539, validation loss: 0.1340
2024-05-25 00:52:37 [INFO]: Epoch 159 - training loss: 0.2542, validation loss: 0.1340
2024-05-25 00:52:40 [INFO]: Epoch 160 - training loss: 0.2539, validation loss: 0.1336
2024-05-25 00:52:43 [INFO]: Epoch 161 - training loss: 0.2537, validation loss: 0.1336
2024-05-25 00:52:46 [INFO]: Epoch 162 - training loss: 0.2532, validation loss: 0.1332
2024-05-25 00:52:49 [INFO]: Epoch 163 - training loss: 0.2530, validation loss: 0.1331
2024-05-25 00:52:52 [INFO]: Epoch 164 - training loss: 0.2524, validation loss: 0.1331
2024-05-25 00:52:55 [INFO]: Epoch 165 - training loss: 0.2526, validation loss: 0.1329
2024-05-25 00:52:58 [INFO]: Epoch 166 - training loss: 0.2519, validation loss: 0.1325
2024-05-25 00:53:01 [INFO]: Epoch 167 - training loss: 0.2513, validation loss: 0.1326
2024-05-25 00:53:04 [INFO]: Epoch 168 - training loss: 0.2517, validation loss: 0.1323
2024-05-25 00:53:07 [INFO]: Epoch 169 - training loss: 0.2511, validation loss: 0.1320
2024-05-25 00:53:10 [INFO]: Epoch 170 - training loss: 0.2502, validation loss: 0.1322
2024-05-25 00:53:13 [INFO]: Epoch 171 - training loss: 0.2506, validation loss: 0.1318
2024-05-25 00:53:15 [INFO]: Epoch 172 - training loss: 0.2501, validation loss: 0.1317
2024-05-25 00:53:18 [INFO]: Epoch 173 - training loss: 0.2501, validation loss: 0.1315
2024-05-25 00:53:21 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1314
2024-05-25 00:53:24 [INFO]: Epoch 175 - training loss: 0.2493, validation loss: 0.1310
2024-05-25 00:53:27 [INFO]: Epoch 176 - training loss: 0.2491, validation loss: 0.1310
2024-05-25 00:53:30 [INFO]: Epoch 177 - training loss: 0.2494, validation loss: 0.1309
2024-05-25 00:53:33 [INFO]: Epoch 178 - training loss: 0.2489, validation loss: 0.1307
2024-05-25 00:53:36 [INFO]: Epoch 179 - training loss: 0.2484, validation loss: 0.1306
2024-05-25 00:53:39 [INFO]: Epoch 180 - training loss: 0.2486, validation loss: 0.1304
2024-05-25 00:53:42 [INFO]: Epoch 181 - training loss: 0.2484, validation loss: 0.1303
2024-05-25 00:53:45 [INFO]: Epoch 182 - training loss: 0.2480, validation loss: 0.1301
2024-05-25 00:53:48 [INFO]: Epoch 183 - training loss: 0.2472, validation loss: 0.1302
2024-05-25 00:53:51 [INFO]: Epoch 184 - training loss: 0.2473, validation loss: 0.1298
2024-05-25 00:53:54 [INFO]: Epoch 185 - training loss: 0.2476, validation loss: 0.1296
2024-05-25 00:53:57 [INFO]: Epoch 186 - training loss: 0.2463, validation loss: 0.1295
2024-05-25 00:53:59 [INFO]: Epoch 187 - training loss: 0.2473, validation loss: 0.1295
2024-05-25 00:54:02 [INFO]: Epoch 188 - training loss: 0.2466, validation loss: 0.1294
2024-05-25 00:54:05 [INFO]: Epoch 189 - training loss: 0.2460, validation loss: 0.1290
2024-05-25 00:54:08 [INFO]: Epoch 190 - training loss: 0.2463, validation loss: 0.1291
2024-05-25 00:54:11 [INFO]: Epoch 191 - training loss: 0.2459, validation loss: 0.1290
2024-05-25 00:54:14 [INFO]: Epoch 192 - training loss: 0.2455, validation loss: 0.1289
2024-05-25 00:54:17 [INFO]: Epoch 193 - training loss: 0.2456, validation loss: 0.1289
2024-05-25 00:54:20 [INFO]: Epoch 194 - training loss: 0.2450, validation loss: 0.1285
2024-05-25 00:54:23 [INFO]: Epoch 195 - training loss: 0.2459, validation loss: 0.1284
2024-05-25 00:54:26 [INFO]: Epoch 196 - training loss: 0.2451, validation loss: 0.1285
2024-05-25 00:54:29 [INFO]: Epoch 197 - training loss: 0.2445, validation loss: 0.1284
2024-05-25 00:54:32 [INFO]: Epoch 198 - training loss: 0.2442, validation loss: 0.1282
2024-05-25 00:54:34 [INFO]: Epoch 199 - training loss: 0.2448, validation loss: 0.1280
2024-05-25 00:54:37 [INFO]: Epoch 200 - training loss: 0.2439, validation loss: 0.1278
2024-05-25 00:54:40 [INFO]: Epoch 201 - training loss: 0.2442, validation loss: 0.1279
2024-05-25 00:54:43 [INFO]: Epoch 202 - training loss: 0.2435, validation loss: 0.1278
2024-05-25 00:54:46 [INFO]: Epoch 203 - training loss: 0.2434, validation loss: 0.1274
2024-05-25 00:54:49 [INFO]: Epoch 204 - training loss: 0.2443, validation loss: 0.1275
2024-05-25 00:54:51 [INFO]: Epoch 205 - training loss: 0.2432, validation loss: 0.1273
2024-05-25 00:54:54 [INFO]: Epoch 206 - training loss: 0.2428, validation loss: 0.1273
2024-05-25 00:54:57 [INFO]: Epoch 207 - training loss: 0.2429, validation loss: 0.1272
2024-05-25 00:55:00 [INFO]: Epoch 208 - training loss: 0.2425, validation loss: 0.1271
2024-05-25 00:55:03 [INFO]: Epoch 209 - training loss: 0.2421, validation loss: 0.1269
2024-05-25 00:55:06 [INFO]: Epoch 210 - training loss: 0.2418, validation loss: 0.1270
2024-05-25 00:55:09 [INFO]: Epoch 211 - training loss: 0.2420, validation loss: 0.1268
2024-05-25 00:55:12 [INFO]: Epoch 212 - training loss: 0.2418, validation loss: 0.1268
2024-05-25 00:55:15 [INFO]: Epoch 213 - training loss: 0.2421, validation loss: 0.1267
2024-05-25 00:55:17 [INFO]: Epoch 214 - training loss: 0.2412, validation loss: 0.1265
2024-05-25 00:55:20 [INFO]: Epoch 215 - training loss: 0.2412, validation loss: 0.1265
2024-05-25 00:55:23 [INFO]: Epoch 216 - training loss: 0.2409, validation loss: 0.1265
2024-05-25 00:55:26 [INFO]: Epoch 217 - training loss: 0.2405, validation loss: 0.1264
2024-05-25 00:55:29 [INFO]: Epoch 218 - training loss: 0.2405, validation loss: 0.1264
2024-05-25 00:55:32 [INFO]: Epoch 219 - training loss: 0.2406, validation loss: 0.1260
2024-05-25 00:55:35 [INFO]: Epoch 220 - training loss: 0.2400, validation loss: 0.1261
2024-05-25 00:55:38 [INFO]: Epoch 221 - training loss: 0.2400, validation loss: 0.1260
2024-05-25 00:55:41 [INFO]: Epoch 222 - training loss: 0.2402, validation loss: 0.1261
2024-05-25 00:55:43 [INFO]: Epoch 223 - training loss: 0.2395, validation loss: 0.1258
2024-05-25 00:55:46 [INFO]: Epoch 224 - training loss: 0.2399, validation loss: 0.1258
2024-05-25 00:55:49 [INFO]: Epoch 225 - training loss: 0.2393, validation loss: 0.1259
2024-05-25 00:55:52 [INFO]: Epoch 226 - training loss: 0.2391, validation loss: 0.1257
2024-05-25 00:55:55 [INFO]: Epoch 227 - training loss: 0.2387, validation loss: 0.1256
2024-05-25 00:55:58 [INFO]: Epoch 228 - training loss: 0.2391, validation loss: 0.1255
2024-05-25 00:56:01 [INFO]: Epoch 229 - training loss: 0.2388, validation loss: 0.1254
2024-05-25 00:56:04 [INFO]: Epoch 230 - training loss: 0.2385, validation loss: 0.1253
2024-05-25 00:56:06 [INFO]: Epoch 231 - training loss: 0.2391, validation loss: 0.1254
2024-05-25 00:56:09 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.1250
2024-05-25 00:56:12 [INFO]: Epoch 233 - training loss: 0.2387, validation loss: 0.1252
2024-05-25 00:56:15 [INFO]: Epoch 234 - training loss: 0.2376, validation loss: 0.1250
2024-05-25 00:56:18 [INFO]: Epoch 235 - training loss: 0.2378, validation loss: 0.1249
2024-05-25 00:56:21 [INFO]: Epoch 236 - training loss: 0.2379, validation loss: 0.1249
2024-05-25 00:56:24 [INFO]: Epoch 237 - training loss: 0.2378, validation loss: 0.1248
2024-05-25 00:56:27 [INFO]: Epoch 238 - training loss: 0.2380, validation loss: 0.1247
2024-05-25 00:56:30 [INFO]: Epoch 239 - training loss: 0.2373, validation loss: 0.1245
2024-05-25 00:56:33 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.1246
2024-05-25 00:56:36 [INFO]: Epoch 241 - training loss: 0.2366, validation loss: 0.1245
2024-05-25 00:56:39 [INFO]: Epoch 242 - training loss: 0.2366, validation loss: 0.1245
2024-05-25 00:56:42 [INFO]: Epoch 243 - training loss: 0.2364, validation loss: 0.1244
2024-05-25 00:56:45 [INFO]: Epoch 244 - training loss: 0.2363, validation loss: 0.1244
2024-05-25 00:56:47 [INFO]: Epoch 245 - training loss: 0.2360, validation loss: 0.1241
2024-05-25 00:56:50 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.1242
2024-05-25 00:56:53 [INFO]: Epoch 247 - training loss: 0.2362, validation loss: 0.1244
2024-05-25 00:56:56 [INFO]: Epoch 248 - training loss: 0.2363, validation loss: 0.1242
2024-05-25 00:56:59 [INFO]: Epoch 249 - training loss: 0.2356, validation loss: 0.1240
2024-05-25 00:57:02 [INFO]: Epoch 250 - training loss: 0.2358, validation loss: 0.1240
2024-05-25 00:57:05 [INFO]: Epoch 251 - training loss: 0.2353, validation loss: 0.1240
2024-05-25 00:57:08 [INFO]: Epoch 252 - training loss: 0.2354, validation loss: 0.1240
2024-05-25 00:57:11 [INFO]: Epoch 253 - training loss: 0.2350, validation loss: 0.1239
2024-05-25 00:57:14 [INFO]: Epoch 254 - training loss: 0.2349, validation loss: 0.1238
2024-05-25 00:57:17 [INFO]: Epoch 255 - training loss: 0.2348, validation loss: 0.1239
2024-05-25 00:57:20 [INFO]: Epoch 256 - training loss: 0.2346, validation loss: 0.1235
2024-05-25 00:57:23 [INFO]: Epoch 257 - training loss: 0.2345, validation loss: 0.1236
2024-05-25 00:57:26 [INFO]: Epoch 258 - training loss: 0.2348, validation loss: 0.1236
2024-05-25 00:57:29 [INFO]: Epoch 259 - training loss: 0.2342, validation loss: 0.1236
2024-05-25 00:57:31 [INFO]: Epoch 260 - training loss: 0.2343, validation loss: 0.1233
2024-05-25 00:57:34 [INFO]: Epoch 261 - training loss: 0.2339, validation loss: 0.1235
2024-05-25 00:57:37 [INFO]: Epoch 262 - training loss: 0.2337, validation loss: 0.1233
2024-05-25 00:57:40 [INFO]: Epoch 263 - training loss: 0.2342, validation loss: 0.1233
2024-05-25 00:57:43 [INFO]: Epoch 264 - training loss: 0.2335, validation loss: 0.1234
2024-05-25 00:57:46 [INFO]: Epoch 265 - training loss: 0.2338, validation loss: 0.1234
2024-05-25 00:57:49 [INFO]: Epoch 266 - training loss: 0.2330, validation loss: 0.1231
2024-05-25 00:57:52 [INFO]: Epoch 267 - training loss: 0.2331, validation loss: 0.1231
2024-05-25 00:57:55 [INFO]: Epoch 268 - training loss: 0.2330, validation loss: 0.1233
2024-05-25 00:57:58 [INFO]: Epoch 269 - training loss: 0.2332, validation loss: 0.1232
2024-05-25 00:58:01 [INFO]: Epoch 270 - training loss: 0.2330, validation loss: 0.1229
2024-05-25 00:58:04 [INFO]: Epoch 271 - training loss: 0.2322, validation loss: 0.1229
2024-05-25 00:58:07 [INFO]: Epoch 272 - training loss: 0.2327, validation loss: 0.1231
2024-05-25 00:58:10 [INFO]: Epoch 273 - training loss: 0.2323, validation loss: 0.1229
2024-05-25 00:58:13 [INFO]: Epoch 274 - training loss: 0.2328, validation loss: 0.1230
2024-05-25 00:58:15 [INFO]: Epoch 275 - training loss: 0.2323, validation loss: 0.1233
2024-05-25 00:58:18 [INFO]: Epoch 276 - training loss: 0.2321, validation loss: 0.1229
2024-05-25 00:58:21 [INFO]: Epoch 277 - training loss: 0.2320, validation loss: 0.1228
2024-05-25 00:58:24 [INFO]: Epoch 278 - training loss: 0.2314, validation loss: 0.1228
2024-05-25 00:58:27 [INFO]: Epoch 279 - training loss: 0.2320, validation loss: 0.1227
2024-05-25 00:58:30 [INFO]: Epoch 280 - training loss: 0.2313, validation loss: 0.1227
2024-05-25 00:58:33 [INFO]: Epoch 281 - training loss: 0.2313, validation loss: 0.1228
2024-05-25 00:58:36 [INFO]: Epoch 282 - training loss: 0.2316, validation loss: 0.1227
2024-05-25 00:58:39 [INFO]: Epoch 283 - training loss: 0.2316, validation loss: 0.1227
2024-05-25 00:58:42 [INFO]: Epoch 284 - training loss: 0.2313, validation loss: 0.1225
2024-05-25 00:58:45 [INFO]: Epoch 285 - training loss: 0.2310, validation loss: 0.1225
2024-05-25 00:58:48 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1227
2024-05-25 00:58:51 [INFO]: Epoch 287 - training loss: 0.2312, validation loss: 0.1224
2024-05-25 00:58:54 [INFO]: Epoch 288 - training loss: 0.2312, validation loss: 0.1225
2024-05-25 00:58:56 [INFO]: Epoch 289 - training loss: 0.2306, validation loss: 0.1225
2024-05-25 00:58:59 [INFO]: Epoch 290 - training loss: 0.2303, validation loss: 0.1225
2024-05-25 00:59:02 [INFO]: Epoch 291 - training loss: 0.2302, validation loss: 0.1222
2024-05-25 00:59:05 [INFO]: Epoch 292 - training loss: 0.2300, validation loss: 0.1221
2024-05-25 00:59:08 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.1224
2024-05-25 00:59:11 [INFO]: Epoch 294 - training loss: 0.2301, validation loss: 0.1223
2024-05-25 00:59:14 [INFO]: Epoch 295 - training loss: 0.2299, validation loss: 0.1223
2024-05-25 00:59:17 [INFO]: Epoch 296 - training loss: 0.2300, validation loss: 0.1225
2024-05-25 00:59:20 [INFO]: Epoch 297 - training loss: 0.2299, validation loss: 0.1223
2024-05-25 00:59:23 [INFO]: Epoch 298 - training loss: 0.2292, validation loss: 0.1223
2024-05-25 00:59:26 [INFO]: Epoch 299 - training loss: 0.2301, validation loss: 0.1221
2024-05-25 00:59:29 [INFO]: Epoch 300 - training loss: 0.2300, validation loss: 0.1221
2024-05-25 00:59:29 [INFO]: Finished training. The best model is from epoch#292.
2024-05-25 00:59:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/BRITS_air_quality/20240525_T004500/BRITS.pypots
2024-05-25 00:59:29 [INFO]: BRITS on Air-Quality: MAE=0.1533, MSE=0.1125
2024-05-25 00:59:29 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 00:59:29 [INFO]: Using the given device: cuda:0
2024-05-25 00:59:29 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929
2024-05-25 00:59:29 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/tensorboard
2024-05-25 00:59:29 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 00:59:34 [INFO]: Epoch 001 - training loss: 1.4393, validation loss: 0.7976
2024-05-25 00:59:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch1_loss0.7975986808538437.pypots
2024-05-25 00:59:38 [INFO]: Epoch 002 - training loss: 1.0468, validation loss: 0.7431
2024-05-25 00:59:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch2_loss0.7431069374084472.pypots
2024-05-25 00:59:42 [INFO]: Epoch 003 - training loss: 0.9881, validation loss: 0.7225
2024-05-25 00:59:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch3_loss0.7225010603666305.pypots
2024-05-25 00:59:46 [INFO]: Epoch 004 - training loss: 0.9640, validation loss: 0.7114
2024-05-25 00:59:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch4_loss0.7113910526037216.pypots
2024-05-25 00:59:50 [INFO]: Epoch 005 - training loss: 0.9602, validation loss: 0.7033
2024-05-25 00:59:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch5_loss0.7033038675785065.pypots
2024-05-25 00:59:54 [INFO]: Epoch 006 - training loss: 0.9341, validation loss: 0.6968
2024-05-25 00:59:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch6_loss0.6968025118112564.pypots
2024-05-25 00:59:58 [INFO]: Epoch 007 - training loss: 0.9397, validation loss: 0.6924
2024-05-25 00:59:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch7_loss0.692393884062767.pypots
2024-05-25 01:00:02 [INFO]: Epoch 008 - training loss: 0.9103, validation loss: 0.6896
2024-05-25 01:00:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch8_loss0.6895886957645416.pypots
2024-05-25 01:00:06 [INFO]: Epoch 009 - training loss: 0.9261, validation loss: 0.6866
2024-05-25 01:00:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch9_loss0.6866278231143952.pypots
2024-05-25 01:00:10 [INFO]: Epoch 010 - training loss: 0.9316, validation loss: 0.6866
2024-05-25 01:00:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch10_loss0.6865955024957657.pypots
2024-05-25 01:00:14 [INFO]: Epoch 011 - training loss: 0.9133, validation loss: 0.6841
2024-05-25 01:00:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch11_loss0.6840896099805832.pypots
2024-05-25 01:00:18 [INFO]: Epoch 012 - training loss: 0.9052, validation loss: 0.6832
2024-05-25 01:00:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch12_loss0.6831880748271942.pypots
2024-05-25 01:00:22 [INFO]: Epoch 013 - training loss: 0.9132, validation loss: 0.6811
2024-05-25 01:00:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch13_loss0.6810644209384918.pypots
2024-05-25 01:00:26 [INFO]: Epoch 014 - training loss: 0.9074, validation loss: 0.6811
2024-05-25 01:00:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch14_loss0.6811100095510483.pypots
2024-05-25 01:00:30 [INFO]: Epoch 015 - training loss: 0.9209, validation loss: 0.6821
2024-05-25 01:00:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch15_loss0.6820649594068527.pypots
2024-05-25 01:00:34 [INFO]: Epoch 016 - training loss: 0.9653, validation loss: 0.6832
2024-05-25 01:00:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch16_loss0.6831641227006913.pypots
2024-05-25 01:00:38 [INFO]: Epoch 017 - training loss: 0.8996, validation loss: 0.6805
2024-05-25 01:00:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch17_loss0.6804683834314347.pypots
2024-05-25 01:00:42 [INFO]: Epoch 018 - training loss: 0.8877, validation loss: 0.6815
2024-05-25 01:00:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch18_loss0.6815120965242386.pypots
2024-05-25 01:00:46 [INFO]: Epoch 019 - training loss: 0.9188, validation loss: 0.6823
2024-05-25 01:00:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch19_loss0.6823048323392868.pypots
2024-05-25 01:00:50 [INFO]: Epoch 020 - training loss: 0.8972, validation loss: 0.6800
2024-05-25 01:00:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch20_loss0.6800054490566254.pypots
2024-05-25 01:00:54 [INFO]: Epoch 021 - training loss: 0.8819, validation loss: 0.6827
2024-05-25 01:00:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch21_loss0.6827197819948196.pypots
2024-05-25 01:00:58 [INFO]: Epoch 022 - training loss: 0.8789, validation loss: 0.6824
2024-05-25 01:00:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch22_loss0.6824076145887374.pypots
2024-05-25 01:01:02 [INFO]: Epoch 023 - training loss: 0.8696, validation loss: 0.6816
2024-05-25 01:01:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch23_loss0.6815812647342682.pypots
2024-05-25 01:01:05 [INFO]: Epoch 024 - training loss: 0.8811, validation loss: 0.6806
2024-05-25 01:01:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch24_loss0.6805819123983383.pypots
2024-05-25 01:01:09 [INFO]: Epoch 025 - training loss: 0.8894, validation loss: 0.6857
2024-05-25 01:01:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch25_loss0.6857094675302505.pypots
2024-05-25 01:01:13 [INFO]: Epoch 026 - training loss: 0.8834, validation loss: 0.6816
2024-05-25 01:01:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch26_loss0.6815864771604538.pypots
2024-05-25 01:01:17 [INFO]: Epoch 027 - training loss: 0.8845, validation loss: 0.6853
2024-05-25 01:01:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch27_loss0.6853493630886078.pypots
2024-05-25 01:01:21 [INFO]: Epoch 028 - training loss: 0.8665, validation loss: 0.6863
2024-05-25 01:01:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch28_loss0.6862677544355392.pypots
2024-05-25 01:01:25 [INFO]: Epoch 029 - training loss: 0.8710, validation loss: 0.6864
2024-05-25 01:01:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch29_loss0.6863516926765442.pypots
2024-05-25 01:01:29 [INFO]: Epoch 030 - training loss: 0.8510, validation loss: 0.6880
2024-05-25 01:01:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN_epoch30_loss0.6879797101020813.pypots
2024-05-25 01:01:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:01:29 [INFO]: Finished training. The best model is from epoch#20.
2024-05-25 01:01:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_1/MRNN_air_quality/20240525_T005929/MRNN.pypots
2024-05-25 01:01:30 [INFO]: MRNN on Air-Quality: MAE=0.5257, MSE=0.6194
2024-05-25 01:01:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 01:01:30 [INFO]: Using the given device: cpu
2024-05-25 01:01:30 [INFO]: LOCF on Air-Quality: MAE=0.2195, MSE=0.2798
2024-05-25 01:01:30 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 01:01:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 01:01:30 [INFO]: Median on Air-Quality: MAE=0.6624, MSE=1.0025
2024-05-25 01:01:30 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 01:01:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 01:01:30 [INFO]: Mean on Air-Quality: MAE=0.6941, MSE=0.9443
2024-05-25 01:01:30 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 01:01:30 [INFO]: Successfully saved to overlay_postmask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 01:01:30 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 01:01:30 [INFO]: Using the given device: cuda:0
2024-05-25 01:01:30 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T010130
2024-05-25 01:01:30 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T010130/tensorboard
2024-05-25 01:01:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 01:01:31 [INFO]: Epoch 001 - training loss: 1.0583, validation loss: 0.5376
2024-05-25 01:01:32 [INFO]: Epoch 002 - training loss: 0.7601, validation loss: 0.4069
2024-05-25 01:01:33 [INFO]: Epoch 003 - training loss: 0.6514, validation loss: 0.3295
2024-05-25 01:01:33 [INFO]: Epoch 004 - training loss: 0.5814, validation loss: 0.2883
2024-05-25 01:01:34 [INFO]: Epoch 005 - training loss: 0.5266, validation loss: 0.2656
2024-05-25 01:01:35 [INFO]: Epoch 006 - training loss: 0.4869, validation loss: 0.2501
2024-05-25 01:01:35 [INFO]: Epoch 007 - training loss: 0.4604, validation loss: 0.2401
2024-05-25 01:01:36 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2331
2024-05-25 01:01:37 [INFO]: Epoch 009 - training loss: 0.4256, validation loss: 0.2259
2024-05-25 01:01:37 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.2214
2024-05-25 01:01:38 [INFO]: Epoch 011 - training loss: 0.4031, validation loss: 0.2212
2024-05-25 01:01:39 [INFO]: Epoch 012 - training loss: 0.3973, validation loss: 0.2149
2024-05-25 01:01:39 [INFO]: Epoch 013 - training loss: 0.3884, validation loss: 0.2125
2024-05-25 01:01:40 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2103
2024-05-25 01:01:41 [INFO]: Epoch 015 - training loss: 0.3764, validation loss: 0.2066
2024-05-25 01:01:41 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2048
2024-05-25 01:01:42 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2027
2024-05-25 01:01:43 [INFO]: Epoch 018 - training loss: 0.3589, validation loss: 0.2011
2024-05-25 01:01:43 [INFO]: Epoch 019 - training loss: 0.3567, validation loss: 0.1987
2024-05-25 01:01:44 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.1978
2024-05-25 01:01:45 [INFO]: Epoch 021 - training loss: 0.3495, validation loss: 0.1974
2024-05-25 01:01:45 [INFO]: Epoch 022 - training loss: 0.3464, validation loss: 0.1946
2024-05-25 01:01:46 [INFO]: Epoch 023 - training loss: 0.3426, validation loss: 0.1934
2024-05-25 01:01:47 [INFO]: Epoch 024 - training loss: 0.3398, validation loss: 0.1913
2024-05-25 01:01:47 [INFO]: Epoch 025 - training loss: 0.3379, validation loss: 0.1894
2024-05-25 01:01:48 [INFO]: Epoch 026 - training loss: 0.3340, validation loss: 0.1882
2024-05-25 01:01:49 [INFO]: Epoch 027 - training loss: 0.3309, validation loss: 0.1884
2024-05-25 01:01:50 [INFO]: Epoch 028 - training loss: 0.3291, validation loss: 0.1866
2024-05-25 01:01:50 [INFO]: Epoch 029 - training loss: 0.3272, validation loss: 0.1855
2024-05-25 01:01:51 [INFO]: Epoch 030 - training loss: 0.3262, validation loss: 0.1840
2024-05-25 01:01:52 [INFO]: Epoch 031 - training loss: 0.3233, validation loss: 0.1834
2024-05-25 01:01:52 [INFO]: Epoch 032 - training loss: 0.3205, validation loss: 0.1815
2024-05-25 01:01:53 [INFO]: Epoch 033 - training loss: 0.3174, validation loss: 0.1809
2024-05-25 01:01:54 [INFO]: Epoch 034 - training loss: 0.3168, validation loss: 0.1804
2024-05-25 01:01:54 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1787
2024-05-25 01:01:55 [INFO]: Epoch 036 - training loss: 0.3139, validation loss: 0.1785
2024-05-25 01:01:56 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1777
2024-05-25 01:01:56 [INFO]: Epoch 038 - training loss: 0.3087, validation loss: 0.1768
2024-05-25 01:01:57 [INFO]: Epoch 039 - training loss: 0.3077, validation loss: 0.1755
2024-05-25 01:01:58 [INFO]: Epoch 040 - training loss: 0.3052, validation loss: 0.1735
2024-05-25 01:01:58 [INFO]: Epoch 041 - training loss: 0.3049, validation loss: 0.1726
2024-05-25 01:01:59 [INFO]: Epoch 042 - training loss: 0.3030, validation loss: 0.1739
2024-05-25 01:02:00 [INFO]: Epoch 043 - training loss: 0.2999, validation loss: 0.1712
2024-05-25 01:02:01 [INFO]: Epoch 044 - training loss: 0.2980, validation loss: 0.1711
2024-05-25 01:02:01 [INFO]: Epoch 045 - training loss: 0.2969, validation loss: 0.1704
2024-05-25 01:02:02 [INFO]: Epoch 046 - training loss: 0.2958, validation loss: 0.1700
2024-05-25 01:02:03 [INFO]: Epoch 047 - training loss: 0.2951, validation loss: 0.1690
2024-05-25 01:02:03 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.1674
2024-05-25 01:02:04 [INFO]: Epoch 049 - training loss: 0.2917, validation loss: 0.1660
2024-05-25 01:02:05 [INFO]: Epoch 050 - training loss: 0.2899, validation loss: 0.1657
2024-05-25 01:02:05 [INFO]: Epoch 051 - training loss: 0.2899, validation loss: 0.1667
2024-05-25 01:02:06 [INFO]: Epoch 052 - training loss: 0.2872, validation loss: 0.1649
2024-05-25 01:02:07 [INFO]: Epoch 053 - training loss: 0.2862, validation loss: 0.1638
2024-05-25 01:02:07 [INFO]: Epoch 054 - training loss: 0.2844, validation loss: 0.1634
2024-05-25 01:02:08 [INFO]: Epoch 055 - training loss: 0.2833, validation loss: 0.1622
2024-05-25 01:02:09 [INFO]: Epoch 056 - training loss: 0.2819, validation loss: 0.1618
2024-05-25 01:02:09 [INFO]: Epoch 057 - training loss: 0.2801, validation loss: 0.1616
2024-05-25 01:02:10 [INFO]: Epoch 058 - training loss: 0.2806, validation loss: 0.1604
2024-05-25 01:02:11 [INFO]: Epoch 059 - training loss: 0.2782, validation loss: 0.1606
2024-05-25 01:02:11 [INFO]: Epoch 060 - training loss: 0.2775, validation loss: 0.1579
2024-05-25 01:02:12 [INFO]: Epoch 061 - training loss: 0.2769, validation loss: 0.1591
2024-05-25 01:02:13 [INFO]: Epoch 062 - training loss: 0.2763, validation loss: 0.1589
2024-05-25 01:02:14 [INFO]: Epoch 063 - training loss: 0.2737, validation loss: 0.1571
2024-05-25 01:02:14 [INFO]: Epoch 064 - training loss: 0.2731, validation loss: 0.1570
2024-05-25 01:02:15 [INFO]: Epoch 065 - training loss: 0.2720, validation loss: 0.1577
2024-05-25 01:02:16 [INFO]: Epoch 066 - training loss: 0.2711, validation loss: 0.1565
2024-05-25 01:02:16 [INFO]: Epoch 067 - training loss: 0.2689, validation loss: 0.1553
2024-05-25 01:02:17 [INFO]: Epoch 068 - training loss: 0.2695, validation loss: 0.1558
2024-05-25 01:02:18 [INFO]: Epoch 069 - training loss: 0.2678, validation loss: 0.1538
2024-05-25 01:02:18 [INFO]: Epoch 070 - training loss: 0.2666, validation loss: 0.1535
2024-05-25 01:02:19 [INFO]: Epoch 071 - training loss: 0.2660, validation loss: 0.1539
2024-05-25 01:02:20 [INFO]: Epoch 072 - training loss: 0.2634, validation loss: 0.1535
2024-05-25 01:02:20 [INFO]: Epoch 073 - training loss: 0.2636, validation loss: 0.1520
2024-05-25 01:02:21 [INFO]: Epoch 074 - training loss: 0.2633, validation loss: 0.1526
2024-05-25 01:02:22 [INFO]: Epoch 075 - training loss: 0.2642, validation loss: 0.1513
2024-05-25 01:02:22 [INFO]: Epoch 076 - training loss: 0.2623, validation loss: 0.1514
2024-05-25 01:02:23 [INFO]: Epoch 077 - training loss: 0.2614, validation loss: 0.1502
2024-05-25 01:02:24 [INFO]: Epoch 078 - training loss: 0.2602, validation loss: 0.1506
2024-05-25 01:02:24 [INFO]: Epoch 079 - training loss: 0.2586, validation loss: 0.1488
2024-05-25 01:02:25 [INFO]: Epoch 080 - training loss: 0.2579, validation loss: 0.1494
2024-05-25 01:02:26 [INFO]: Epoch 081 - training loss: 0.2580, validation loss: 0.1488
2024-05-25 01:02:27 [INFO]: Epoch 082 - training loss: 0.2568, validation loss: 0.1486
2024-05-25 01:02:27 [INFO]: Epoch 083 - training loss: 0.2568, validation loss: 0.1482
2024-05-25 01:02:28 [INFO]: Epoch 084 - training loss: 0.2546, validation loss: 0.1483
2024-05-25 01:02:29 [INFO]: Epoch 085 - training loss: 0.2549, validation loss: 0.1478
2024-05-25 01:02:29 [INFO]: Epoch 086 - training loss: 0.2542, validation loss: 0.1467
2024-05-25 01:02:30 [INFO]: Epoch 087 - training loss: 0.2531, validation loss: 0.1476
2024-05-25 01:02:31 [INFO]: Epoch 088 - training loss: 0.2528, validation loss: 0.1469
2024-05-25 01:02:31 [INFO]: Epoch 089 - training loss: 0.2546, validation loss: 0.1476
2024-05-25 01:02:32 [INFO]: Epoch 090 - training loss: 0.2554, validation loss: 0.1468
2024-05-25 01:02:33 [INFO]: Epoch 091 - training loss: 0.2537, validation loss: 0.1461
2024-05-25 01:02:33 [INFO]: Epoch 092 - training loss: 0.2504, validation loss: 0.1453
2024-05-25 01:02:34 [INFO]: Epoch 093 - training loss: 0.2499, validation loss: 0.1445
2024-05-25 01:02:35 [INFO]: Epoch 094 - training loss: 0.2475, validation loss: 0.1439
2024-05-25 01:02:35 [INFO]: Epoch 095 - training loss: 0.2495, validation loss: 0.1441
2024-05-25 01:02:36 [INFO]: Epoch 096 - training loss: 0.2477, validation loss: 0.1443
2024-05-25 01:02:37 [INFO]: Epoch 097 - training loss: 0.2486, validation loss: 0.1439
2024-05-25 01:02:37 [INFO]: Epoch 098 - training loss: 0.2481, validation loss: 0.1433
2024-05-25 01:02:38 [INFO]: Epoch 099 - training loss: 0.2469, validation loss: 0.1440
2024-05-25 01:02:39 [INFO]: Epoch 100 - training loss: 0.2461, validation loss: 0.1442
2024-05-25 01:02:39 [INFO]: Epoch 101 - training loss: 0.2441, validation loss: 0.1430
2024-05-25 01:02:40 [INFO]: Epoch 102 - training loss: 0.2441, validation loss: 0.1424
2024-05-25 01:02:41 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1425
2024-05-25 01:02:42 [INFO]: Epoch 104 - training loss: 0.2431, validation loss: 0.1424
2024-05-25 01:02:42 [INFO]: Epoch 105 - training loss: 0.2420, validation loss: 0.1421
2024-05-25 01:02:43 [INFO]: Epoch 106 - training loss: 0.2424, validation loss: 0.1416
2024-05-25 01:02:44 [INFO]: Epoch 107 - training loss: 0.2429, validation loss: 0.1411
2024-05-25 01:02:44 [INFO]: Epoch 108 - training loss: 0.2408, validation loss: 0.1412
2024-05-25 01:02:45 [INFO]: Epoch 109 - training loss: 0.2405, validation loss: 0.1415
2024-05-25 01:02:46 [INFO]: Epoch 110 - training loss: 0.2413, validation loss: 0.1401
2024-05-25 01:02:46 [INFO]: Epoch 111 - training loss: 0.2403, validation loss: 0.1405
2024-05-25 01:02:47 [INFO]: Epoch 112 - training loss: 0.2391, validation loss: 0.1398
2024-05-25 01:02:48 [INFO]: Epoch 113 - training loss: 0.2380, validation loss: 0.1393
2024-05-25 01:02:48 [INFO]: Epoch 114 - training loss: 0.2379, validation loss: 0.1396
2024-05-25 01:02:49 [INFO]: Epoch 115 - training loss: 0.2371, validation loss: 0.1394
2024-05-25 01:02:50 [INFO]: Epoch 116 - training loss: 0.2375, validation loss: 0.1399
2024-05-25 01:02:50 [INFO]: Epoch 117 - training loss: 0.2364, validation loss: 0.1395
2024-05-25 01:02:51 [INFO]: Epoch 118 - training loss: 0.2363, validation loss: 0.1388
2024-05-25 01:02:52 [INFO]: Epoch 119 - training loss: 0.2359, validation loss: 0.1393
2024-05-25 01:02:52 [INFO]: Epoch 120 - training loss: 0.2355, validation loss: 0.1390
2024-05-25 01:02:53 [INFO]: Epoch 121 - training loss: 0.2352, validation loss: 0.1385
2024-05-25 01:02:54 [INFO]: Epoch 122 - training loss: 0.2337, validation loss: 0.1386
2024-05-25 01:02:55 [INFO]: Epoch 123 - training loss: 0.2352, validation loss: 0.1371
2024-05-25 01:02:55 [INFO]: Epoch 124 - training loss: 0.2332, validation loss: 0.1373
2024-05-25 01:02:56 [INFO]: Epoch 125 - training loss: 0.2322, validation loss: 0.1375
2024-05-25 01:02:57 [INFO]: Epoch 126 - training loss: 0.2339, validation loss: 0.1380
2024-05-25 01:02:57 [INFO]: Epoch 127 - training loss: 0.2322, validation loss: 0.1365
2024-05-25 01:02:58 [INFO]: Epoch 128 - training loss: 0.2318, validation loss: 0.1365
2024-05-25 01:02:59 [INFO]: Epoch 129 - training loss: 0.2311, validation loss: 0.1368
2024-05-25 01:02:59 [INFO]: Epoch 130 - training loss: 0.2313, validation loss: 0.1369
2024-05-25 01:03:00 [INFO]: Epoch 131 - training loss: 0.2307, validation loss: 0.1358
2024-05-25 01:03:01 [INFO]: Epoch 132 - training loss: 0.2310, validation loss: 0.1374
2024-05-25 01:03:01 [INFO]: Epoch 133 - training loss: 0.2316, validation loss: 0.1357
2024-05-25 01:03:02 [INFO]: Epoch 134 - training loss: 0.2314, validation loss: 0.1361
2024-05-25 01:03:03 [INFO]: Epoch 135 - training loss: 0.2316, validation loss: 0.1358
2024-05-25 01:03:03 [INFO]: Epoch 136 - training loss: 0.2300, validation loss: 0.1349
2024-05-25 01:03:04 [INFO]: Epoch 137 - training loss: 0.2279, validation loss: 0.1349
2024-05-25 01:03:05 [INFO]: Epoch 138 - training loss: 0.2282, validation loss: 0.1347
2024-05-25 01:03:05 [INFO]: Epoch 139 - training loss: 0.2269, validation loss: 0.1343
2024-05-25 01:03:06 [INFO]: Epoch 140 - training loss: 0.2270, validation loss: 0.1343
2024-05-25 01:03:07 [INFO]: Epoch 141 - training loss: 0.2264, validation loss: 0.1338
2024-05-25 01:03:08 [INFO]: Epoch 142 - training loss: 0.2261, validation loss: 0.1341
2024-05-25 01:03:08 [INFO]: Epoch 143 - training loss: 0.2271, validation loss: 0.1335
2024-05-25 01:03:09 [INFO]: Epoch 144 - training loss: 0.2249, validation loss: 0.1330
2024-05-25 01:03:10 [INFO]: Epoch 145 - training loss: 0.2253, validation loss: 0.1336
2024-05-25 01:03:10 [INFO]: Epoch 146 - training loss: 0.2257, validation loss: 0.1334
2024-05-25 01:03:11 [INFO]: Epoch 147 - training loss: 0.2259, validation loss: 0.1322
2024-05-25 01:03:12 [INFO]: Epoch 148 - training loss: 0.2236, validation loss: 0.1332
2024-05-25 01:03:12 [INFO]: Epoch 149 - training loss: 0.2237, validation loss: 0.1329
2024-05-25 01:03:13 [INFO]: Epoch 150 - training loss: 0.2228, validation loss: 0.1321
2024-05-25 01:03:14 [INFO]: Epoch 151 - training loss: 0.2239, validation loss: 0.1327
2024-05-25 01:03:14 [INFO]: Epoch 152 - training loss: 0.2236, validation loss: 0.1332
2024-05-25 01:03:15 [INFO]: Epoch 153 - training loss: 0.2220, validation loss: 0.1327
2024-05-25 01:03:16 [INFO]: Epoch 154 - training loss: 0.2220, validation loss: 0.1322
2024-05-25 01:03:16 [INFO]: Epoch 155 - training loss: 0.2223, validation loss: 0.1325
2024-05-25 01:03:17 [INFO]: Epoch 156 - training loss: 0.2210, validation loss: 0.1321
2024-05-25 01:03:18 [INFO]: Epoch 157 - training loss: 0.2198, validation loss: 0.1310
2024-05-25 01:03:18 [INFO]: Epoch 158 - training loss: 0.2209, validation loss: 0.1310
2024-05-25 01:03:19 [INFO]: Epoch 159 - training loss: 0.2207, validation loss: 0.1334
2024-05-25 01:03:20 [INFO]: Epoch 160 - training loss: 0.2221, validation loss: 0.1309
2024-05-25 01:03:20 [INFO]: Epoch 161 - training loss: 0.2219, validation loss: 0.1314
2024-05-25 01:03:21 [INFO]: Epoch 162 - training loss: 0.2190, validation loss: 0.1304
2024-05-25 01:03:22 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1310
2024-05-25 01:03:22 [INFO]: Epoch 164 - training loss: 0.2182, validation loss: 0.1297
2024-05-25 01:03:23 [INFO]: Epoch 165 - training loss: 0.2172, validation loss: 0.1303
2024-05-25 01:03:24 [INFO]: Epoch 166 - training loss: 0.2183, validation loss: 0.1296
2024-05-25 01:03:24 [INFO]: Epoch 167 - training loss: 0.2172, validation loss: 0.1295
2024-05-25 01:03:25 [INFO]: Epoch 168 - training loss: 0.2168, validation loss: 0.1296
2024-05-25 01:03:26 [INFO]: Epoch 169 - training loss: 0.2154, validation loss: 0.1297
2024-05-25 01:03:26 [INFO]: Epoch 170 - training loss: 0.2180, validation loss: 0.1306
2024-05-25 01:03:27 [INFO]: Epoch 171 - training loss: 0.2191, validation loss: 0.1308
2024-05-25 01:03:28 [INFO]: Epoch 172 - training loss: 0.2160, validation loss: 0.1291
2024-05-25 01:03:28 [INFO]: Epoch 173 - training loss: 0.2156, validation loss: 0.1294
2024-05-25 01:03:29 [INFO]: Epoch 174 - training loss: 0.2161, validation loss: 0.1292
2024-05-25 01:03:30 [INFO]: Epoch 175 - training loss: 0.2172, validation loss: 0.1299
2024-05-25 01:03:30 [INFO]: Epoch 176 - training loss: 0.2168, validation loss: 0.1286
2024-05-25 01:03:31 [INFO]: Epoch 177 - training loss: 0.2155, validation loss: 0.1293
2024-05-25 01:03:32 [INFO]: Epoch 178 - training loss: 0.2153, validation loss: 0.1276
2024-05-25 01:03:32 [INFO]: Epoch 179 - training loss: 0.2154, validation loss: 0.1277
2024-05-25 01:03:33 [INFO]: Epoch 180 - training loss: 0.2150, validation loss: 0.1277
2024-05-25 01:03:34 [INFO]: Epoch 181 - training loss: 0.2138, validation loss: 0.1278
2024-05-25 01:03:34 [INFO]: Epoch 182 - training loss: 0.2141, validation loss: 0.1275
2024-05-25 01:03:35 [INFO]: Epoch 183 - training loss: 0.2168, validation loss: 0.1286
2024-05-25 01:03:36 [INFO]: Epoch 184 - training loss: 0.2151, validation loss: 0.1268
2024-05-25 01:03:37 [INFO]: Epoch 185 - training loss: 0.2122, validation loss: 0.1280
2024-05-25 01:03:37 [INFO]: Epoch 186 - training loss: 0.2107, validation loss: 0.1269
2024-05-25 01:03:38 [INFO]: Epoch 187 - training loss: 0.2119, validation loss: 0.1275
2024-05-25 01:03:39 [INFO]: Epoch 188 - training loss: 0.2108, validation loss: 0.1273
2024-05-25 01:03:39 [INFO]: Epoch 189 - training loss: 0.2114, validation loss: 0.1267
2024-05-25 01:03:40 [INFO]: Epoch 190 - training loss: 0.2101, validation loss: 0.1273
2024-05-25 01:03:41 [INFO]: Epoch 191 - training loss: 0.2097, validation loss: 0.1261
2024-05-25 01:03:41 [INFO]: Epoch 192 - training loss: 0.2103, validation loss: 0.1257
2024-05-25 01:03:42 [INFO]: Epoch 193 - training loss: 0.2093, validation loss: 0.1262
2024-05-25 01:03:43 [INFO]: Epoch 194 - training loss: 0.2090, validation loss: 0.1262
2024-05-25 01:03:43 [INFO]: Epoch 195 - training loss: 0.2095, validation loss: 0.1252
2024-05-25 01:03:44 [INFO]: Epoch 196 - training loss: 0.2085, validation loss: 0.1256
2024-05-25 01:03:45 [INFO]: Epoch 197 - training loss: 0.2081, validation loss: 0.1263
2024-05-25 01:03:45 [INFO]: Epoch 198 - training loss: 0.2082, validation loss: 0.1255
2024-05-25 01:03:46 [INFO]: Epoch 199 - training loss: 0.2085, validation loss: 0.1271
2024-05-25 01:03:47 [INFO]: Epoch 200 - training loss: 0.2082, validation loss: 0.1248
2024-05-25 01:03:48 [INFO]: Epoch 201 - training loss: 0.2074, validation loss: 0.1252
2024-05-25 01:03:48 [INFO]: Epoch 202 - training loss: 0.2080, validation loss: 0.1275
2024-05-25 01:03:49 [INFO]: Epoch 203 - training loss: 0.2088, validation loss: 0.1252
2024-05-25 01:03:50 [INFO]: Epoch 204 - training loss: 0.2086, validation loss: 0.1258
2024-05-25 01:03:50 [INFO]: Epoch 205 - training loss: 0.2076, validation loss: 0.1242
2024-05-25 01:03:51 [INFO]: Epoch 206 - training loss: 0.2065, validation loss: 0.1244
2024-05-25 01:03:52 [INFO]: Epoch 207 - training loss: 0.2068, validation loss: 0.1240
2024-05-25 01:03:52 [INFO]: Epoch 208 - training loss: 0.2066, validation loss: 0.1235
2024-05-25 01:03:53 [INFO]: Epoch 209 - training loss: 0.2068, validation loss: 0.1245
2024-05-25 01:03:54 [INFO]: Epoch 210 - training loss: 0.2062, validation loss: 0.1250
2024-05-25 01:03:54 [INFO]: Epoch 211 - training loss: 0.2058, validation loss: 0.1243
2024-05-25 01:03:55 [INFO]: Epoch 212 - training loss: 0.2061, validation loss: 0.1251
2024-05-25 01:03:56 [INFO]: Epoch 213 - training loss: 0.2058, validation loss: 0.1243
2024-05-25 01:03:56 [INFO]: Epoch 214 - training loss: 0.2043, validation loss: 0.1239
2024-05-25 01:03:57 [INFO]: Epoch 215 - training loss: 0.2044, validation loss: 0.1240
2024-05-25 01:03:58 [INFO]: Epoch 216 - training loss: 0.2053, validation loss: 0.1236
2024-05-25 01:03:58 [INFO]: Epoch 217 - training loss: 0.2028, validation loss: 0.1244
2024-05-25 01:03:59 [INFO]: Epoch 218 - training loss: 0.2035, validation loss: 0.1244
2024-05-25 01:03:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:03:59 [INFO]: Finished training. The best model is from epoch#208.
2024-05-25 01:03:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/SAITS_air_quality/20240525_T010130/SAITS.pypots
2024-05-25 01:03:59 [INFO]: SAITS on Air-Quality: MAE=0.1529, MSE=0.1118
2024-05-25 01:03:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 01:03:59 [INFO]: Using the given device: cuda:0
2024-05-25 01:03:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T010359
2024-05-25 01:03:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T010359/tensorboard
2024-05-25 01:03:59 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 01:04:00 [INFO]: Epoch 001 - training loss: 0.9214, validation loss: 0.4822
2024-05-25 01:04:00 [INFO]: Epoch 002 - training loss: 0.5784, validation loss: 0.3568
2024-05-25 01:04:00 [INFO]: Epoch 003 - training loss: 0.4886, validation loss: 0.2950
2024-05-25 01:04:01 [INFO]: Epoch 004 - training loss: 0.4400, validation loss: 0.2719
2024-05-25 01:04:01 [INFO]: Epoch 005 - training loss: 0.4119, validation loss: 0.2575
2024-05-25 01:04:01 [INFO]: Epoch 006 - training loss: 0.3930, validation loss: 0.2489
2024-05-25 01:04:02 [INFO]: Epoch 007 - training loss: 0.3802, validation loss: 0.2450
2024-05-25 01:04:02 [INFO]: Epoch 008 - training loss: 0.3716, validation loss: 0.2367
2024-05-25 01:04:02 [INFO]: Epoch 009 - training loss: 0.3568, validation loss: 0.2332
2024-05-25 01:04:03 [INFO]: Epoch 010 - training loss: 0.3486, validation loss: 0.2270
2024-05-25 01:04:03 [INFO]: Epoch 011 - training loss: 0.3432, validation loss: 0.2238
2024-05-25 01:04:03 [INFO]: Epoch 012 - training loss: 0.3366, validation loss: 0.2203
2024-05-25 01:04:04 [INFO]: Epoch 013 - training loss: 0.3364, validation loss: 0.2155
2024-05-25 01:04:04 [INFO]: Epoch 014 - training loss: 0.3329, validation loss: 0.2131
2024-05-25 01:04:04 [INFO]: Epoch 015 - training loss: 0.3224, validation loss: 0.2091
2024-05-25 01:04:05 [INFO]: Epoch 016 - training loss: 0.3192, validation loss: 0.2086
2024-05-25 01:04:05 [INFO]: Epoch 017 - training loss: 0.3185, validation loss: 0.2038
2024-05-25 01:04:05 [INFO]: Epoch 018 - training loss: 0.3131, validation loss: 0.2042
2024-05-25 01:04:06 [INFO]: Epoch 019 - training loss: 0.3119, validation loss: 0.1998
2024-05-25 01:04:06 [INFO]: Epoch 020 - training loss: 0.3068, validation loss: 0.1967
2024-05-25 01:04:06 [INFO]: Epoch 021 - training loss: 0.3047, validation loss: 0.1941
2024-05-25 01:04:07 [INFO]: Epoch 022 - training loss: 0.3015, validation loss: 0.1925
2024-05-25 01:04:07 [INFO]: Epoch 023 - training loss: 0.2980, validation loss: 0.1914
2024-05-25 01:04:07 [INFO]: Epoch 024 - training loss: 0.2968, validation loss: 0.1894
2024-05-25 01:04:08 [INFO]: Epoch 025 - training loss: 0.2955, validation loss: 0.1909
2024-05-25 01:04:08 [INFO]: Epoch 026 - training loss: 0.2950, validation loss: 0.1906
2024-05-25 01:04:08 [INFO]: Epoch 027 - training loss: 0.2941, validation loss: 0.1890
2024-05-25 01:04:09 [INFO]: Epoch 028 - training loss: 0.2913, validation loss: 0.1905
2024-05-25 01:04:09 [INFO]: Epoch 029 - training loss: 0.2905, validation loss: 0.1850
2024-05-25 01:04:09 [INFO]: Epoch 030 - training loss: 0.2854, validation loss: 0.1849
2024-05-25 01:04:09 [INFO]: Epoch 031 - training loss: 0.2884, validation loss: 0.1830
2024-05-25 01:04:10 [INFO]: Epoch 032 - training loss: 0.2848, validation loss: 0.1824
2024-05-25 01:04:10 [INFO]: Epoch 033 - training loss: 0.2853, validation loss: 0.1822
2024-05-25 01:04:10 [INFO]: Epoch 034 - training loss: 0.2825, validation loss: 0.1822
2024-05-25 01:04:11 [INFO]: Epoch 035 - training loss: 0.2801, validation loss: 0.1838
2024-05-25 01:04:11 [INFO]: Epoch 036 - training loss: 0.2786, validation loss: 0.1810
2024-05-25 01:04:11 [INFO]: Epoch 037 - training loss: 0.2766, validation loss: 0.1826
2024-05-25 01:04:12 [INFO]: Epoch 038 - training loss: 0.2758, validation loss: 0.1812
2024-05-25 01:04:12 [INFO]: Epoch 039 - training loss: 0.2762, validation loss: 0.1850
2024-05-25 01:04:12 [INFO]: Epoch 040 - training loss: 0.2759, validation loss: 0.1786
2024-05-25 01:04:13 [INFO]: Epoch 041 - training loss: 0.2746, validation loss: 0.1790
2024-05-25 01:04:13 [INFO]: Epoch 042 - training loss: 0.2730, validation loss: 0.1793
2024-05-25 01:04:13 [INFO]: Epoch 043 - training loss: 0.2706, validation loss: 0.1768
2024-05-25 01:04:14 [INFO]: Epoch 044 - training loss: 0.2709, validation loss: 0.1806
2024-05-25 01:04:14 [INFO]: Epoch 045 - training loss: 0.2683, validation loss: 0.1787
2024-05-25 01:04:14 [INFO]: Epoch 046 - training loss: 0.2743, validation loss: 0.1748
2024-05-25 01:04:15 [INFO]: Epoch 047 - training loss: 0.2705, validation loss: 0.1774
2024-05-25 01:04:15 [INFO]: Epoch 048 - training loss: 0.2672, validation loss: 0.1754
2024-05-25 01:04:15 [INFO]: Epoch 049 - training loss: 0.2643, validation loss: 0.1776
2024-05-25 01:04:16 [INFO]: Epoch 050 - training loss: 0.2669, validation loss: 0.1755
2024-05-25 01:04:16 [INFO]: Epoch 051 - training loss: 0.2630, validation loss: 0.1743
2024-05-25 01:04:16 [INFO]: Epoch 052 - training loss: 0.2610, validation loss: 0.1736
2024-05-25 01:04:17 [INFO]: Epoch 053 - training loss: 0.2597, validation loss: 0.1731
2024-05-25 01:04:17 [INFO]: Epoch 054 - training loss: 0.2596, validation loss: 0.1765
2024-05-25 01:04:17 [INFO]: Epoch 055 - training loss: 0.2606, validation loss: 0.1743
2024-05-25 01:04:18 [INFO]: Epoch 056 - training loss: 0.2608, validation loss: 0.1774
2024-05-25 01:04:18 [INFO]: Epoch 057 - training loss: 0.2610, validation loss: 0.1722
2024-05-25 01:04:18 [INFO]: Epoch 058 - training loss: 0.2575, validation loss: 0.1720
2024-05-25 01:04:19 [INFO]: Epoch 059 - training loss: 0.2575, validation loss: 0.1713
2024-05-25 01:04:19 [INFO]: Epoch 060 - training loss: 0.2565, validation loss: 0.1717
2024-05-25 01:04:19 [INFO]: Epoch 061 - training loss: 0.2537, validation loss: 0.1734
2024-05-25 01:04:20 [INFO]: Epoch 062 - training loss: 0.2520, validation loss: 0.1705
2024-05-25 01:04:20 [INFO]: Epoch 063 - training loss: 0.2526, validation loss: 0.1716
2024-05-25 01:04:20 [INFO]: Epoch 064 - training loss: 0.2530, validation loss: 0.1713
2024-05-25 01:04:20 [INFO]: Epoch 065 - training loss: 0.2510, validation loss: 0.1706
2024-05-25 01:04:21 [INFO]: Epoch 066 - training loss: 0.2499, validation loss: 0.1691
2024-05-25 01:04:21 [INFO]: Epoch 067 - training loss: 0.2483, validation loss: 0.1693
2024-05-25 01:04:21 [INFO]: Epoch 068 - training loss: 0.2480, validation loss: 0.1680
2024-05-25 01:04:22 [INFO]: Epoch 069 - training loss: 0.2492, validation loss: 0.1702
2024-05-25 01:04:22 [INFO]: Epoch 070 - training loss: 0.2514, validation loss: 0.1709
2024-05-25 01:04:22 [INFO]: Epoch 071 - training loss: 0.2492, validation loss: 0.1662
2024-05-25 01:04:23 [INFO]: Epoch 072 - training loss: 0.2478, validation loss: 0.1671
2024-05-25 01:04:23 [INFO]: Epoch 073 - training loss: 0.2471, validation loss: 0.1683
2024-05-25 01:04:23 [INFO]: Epoch 074 - training loss: 0.2464, validation loss: 0.1645
2024-05-25 01:04:24 [INFO]: Epoch 075 - training loss: 0.2480, validation loss: 0.1664
2024-05-25 01:04:24 [INFO]: Epoch 076 - training loss: 0.2454, validation loss: 0.1659
2024-05-25 01:04:24 [INFO]: Epoch 077 - training loss: 0.2454, validation loss: 0.1651
2024-05-25 01:04:25 [INFO]: Epoch 078 - training loss: 0.2472, validation loss: 0.1655
2024-05-25 01:04:25 [INFO]: Epoch 079 - training loss: 0.2445, validation loss: 0.1665
2024-05-25 01:04:25 [INFO]: Epoch 080 - training loss: 0.2424, validation loss: 0.1672
2024-05-25 01:04:26 [INFO]: Epoch 081 - training loss: 0.2406, validation loss: 0.1656
2024-05-25 01:04:26 [INFO]: Epoch 082 - training loss: 0.2394, validation loss: 0.1665
2024-05-25 01:04:26 [INFO]: Epoch 083 - training loss: 0.2400, validation loss: 0.1653
2024-05-25 01:04:27 [INFO]: Epoch 084 - training loss: 0.2419, validation loss: 0.1652
2024-05-25 01:04:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:04:27 [INFO]: Finished training. The best model is from epoch#74.
2024-05-25 01:04:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/Transformer_air_quality/20240525_T010359/Transformer.pypots
2024-05-25 01:04:27 [INFO]: Transformer on Air-Quality: MAE=0.1832, MSE=0.1488
2024-05-25 01:04:27 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 01:04:27 [INFO]: Using the given device: cuda:0
2024-05-25 01:04:27 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T010427
2024-05-25 01:04:27 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T010427/tensorboard
2024-05-25 01:04:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 01:04:28 [INFO]: Epoch 001 - training loss: 0.2821, validation loss: 0.2806
2024-05-25 01:04:28 [INFO]: Epoch 002 - training loss: 0.2128, validation loss: 0.2427
2024-05-25 01:04:29 [INFO]: Epoch 003 - training loss: 0.1821, validation loss: 0.2124
2024-05-25 01:04:29 [INFO]: Epoch 004 - training loss: 0.1933, validation loss: 0.2066
2024-05-25 01:04:30 [INFO]: Epoch 005 - training loss: 0.1841, validation loss: 0.1986
2024-05-25 01:04:30 [INFO]: Epoch 006 - training loss: 0.1641, validation loss: 0.1944
2024-05-25 01:04:31 [INFO]: Epoch 007 - training loss: 0.1668, validation loss: 0.1891
2024-05-25 01:04:31 [INFO]: Epoch 008 - training loss: 0.1565, validation loss: 0.1882
2024-05-25 01:04:32 [INFO]: Epoch 009 - training loss: 0.1408, validation loss: 0.1823
2024-05-25 01:04:33 [INFO]: Epoch 010 - training loss: 0.1508, validation loss: 0.1775
2024-05-25 01:04:33 [INFO]: Epoch 011 - training loss: 0.1467, validation loss: 0.1750
2024-05-25 01:04:34 [INFO]: Epoch 012 - training loss: 0.1376, validation loss: 0.1757
2024-05-25 01:04:34 [INFO]: Epoch 013 - training loss: 0.1429, validation loss: 0.1760
2024-05-25 01:04:35 [INFO]: Epoch 014 - training loss: 0.1293, validation loss: 0.1737
2024-05-25 01:04:35 [INFO]: Epoch 015 - training loss: 0.1306, validation loss: 0.1746
2024-05-25 01:04:36 [INFO]: Epoch 016 - training loss: 0.1608, validation loss: 0.1715
2024-05-25 01:04:36 [INFO]: Epoch 017 - training loss: 0.1448, validation loss: 0.1735
2024-05-25 01:04:37 [INFO]: Epoch 018 - training loss: 0.1272, validation loss: 0.1685
2024-05-25 01:04:37 [INFO]: Epoch 019 - training loss: 0.1208, validation loss: 0.1739
2024-05-25 01:04:38 [INFO]: Epoch 020 - training loss: 0.1185, validation loss: 0.1718
2024-05-25 01:04:38 [INFO]: Epoch 021 - training loss: 0.1117, validation loss: 0.1659
2024-05-25 01:04:39 [INFO]: Epoch 022 - training loss: 0.1303, validation loss: 0.1663
2024-05-25 01:04:40 [INFO]: Epoch 023 - training loss: 0.1361, validation loss: 0.1626
2024-05-25 01:04:40 [INFO]: Epoch 024 - training loss: 0.1314, validation loss: 0.1654
2024-05-25 01:04:41 [INFO]: Epoch 025 - training loss: 0.1241, validation loss: 0.1637
2024-05-25 01:04:41 [INFO]: Epoch 026 - training loss: 0.1165, validation loss: 0.1657
2024-05-25 01:04:42 [INFO]: Epoch 027 - training loss: 0.1316, validation loss: 0.1644
2024-05-25 01:04:42 [INFO]: Epoch 028 - training loss: 0.1134, validation loss: 0.1628
2024-05-25 01:04:43 [INFO]: Epoch 029 - training loss: 0.1092, validation loss: 0.1665
2024-05-25 01:04:43 [INFO]: Epoch 030 - training loss: 0.1197, validation loss: 0.1637
2024-05-25 01:04:44 [INFO]: Epoch 031 - training loss: 0.1278, validation loss: 0.1610
2024-05-25 01:04:44 [INFO]: Epoch 032 - training loss: 0.1125, validation loss: 0.1591
2024-05-25 01:04:45 [INFO]: Epoch 033 - training loss: 0.1011, validation loss: 0.1609
2024-05-25 01:04:45 [INFO]: Epoch 034 - training loss: 0.1138, validation loss: 0.1632
2024-05-25 01:04:46 [INFO]: Epoch 035 - training loss: 0.1118, validation loss: 0.1611
2024-05-25 01:04:47 [INFO]: Epoch 036 - training loss: 0.1166, validation loss: 0.1657
2024-05-25 01:04:47 [INFO]: Epoch 037 - training loss: 0.1230, validation loss: 0.1648
2024-05-25 01:04:48 [INFO]: Epoch 038 - training loss: 0.1257, validation loss: 0.1671
2024-05-25 01:04:48 [INFO]: Epoch 039 - training loss: 0.1087, validation loss: 0.1624
2024-05-25 01:04:49 [INFO]: Epoch 040 - training loss: 0.1158, validation loss: 0.1593
2024-05-25 01:04:49 [INFO]: Epoch 041 - training loss: 0.1079, validation loss: 0.1598
2024-05-25 01:04:50 [INFO]: Epoch 042 - training loss: 0.1126, validation loss: 0.1623
2024-05-25 01:04:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:04:50 [INFO]: Finished training. The best model is from epoch#32.
2024-05-25 01:04:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/TimesNet_air_quality/20240525_T010427/TimesNet.pypots
2024-05-25 01:04:50 [INFO]: TimesNet on Air-Quality: MAE=0.1667, MSE=0.1622
2024-05-25 01:04:50 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 01:04:50 [INFO]: Using the given device: cuda:0
2024-05-25 01:04:50 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450
2024-05-25 01:04:50 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/tensorboard
2024-05-25 01:04:50 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 01:05:07 [INFO]: Epoch 001 - training loss: 0.5050, validation loss: 0.3335
2024-05-25 01:05:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch1_loss0.3334577471017838.pypots
2024-05-25 01:05:24 [INFO]: Epoch 002 - training loss: 0.3134, validation loss: 0.2796
2024-05-25 01:05:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch2_loss0.27955818772315977.pypots
2024-05-25 01:05:41 [INFO]: Epoch 003 - training loss: 0.2612, validation loss: 0.2333
2024-05-25 01:05:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch3_loss0.23328881710767746.pypots
2024-05-25 01:05:58 [INFO]: Epoch 004 - training loss: 0.2203, validation loss: 0.2113
2024-05-25 01:05:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch4_loss0.2113170862197876.pypots
2024-05-25 01:06:15 [INFO]: Epoch 005 - training loss: 0.1929, validation loss: 0.1788
2024-05-25 01:06:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch5_loss0.17878127247095107.pypots
2024-05-25 01:06:31 [INFO]: Epoch 006 - training loss: 0.1940, validation loss: 0.1701
2024-05-25 01:06:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch6_loss0.17009786665439605.pypots
2024-05-25 01:06:48 [INFO]: Epoch 007 - training loss: 0.1724, validation loss: 0.1658
2024-05-25 01:06:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch7_loss0.1658209055662155.pypots
2024-05-25 01:07:05 [INFO]: Epoch 008 - training loss: 0.1921, validation loss: 0.1579
2024-05-25 01:07:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch8_loss0.15790409594774246.pypots
2024-05-25 01:07:22 [INFO]: Epoch 009 - training loss: 0.1609, validation loss: 0.1637
2024-05-25 01:07:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch9_loss0.16369540691375734.pypots
2024-05-25 01:07:39 [INFO]: Epoch 010 - training loss: 0.1666, validation loss: 0.1553
2024-05-25 01:07:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch10_loss0.15526228696107863.pypots
2024-05-25 01:07:56 [INFO]: Epoch 011 - training loss: 0.1737, validation loss: 0.1560
2024-05-25 01:07:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch11_loss0.155985489487648.pypots
2024-05-25 01:08:13 [INFO]: Epoch 012 - training loss: 0.1797, validation loss: 0.1457
2024-05-25 01:08:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch12_loss0.14574535116553305.pypots
2024-05-25 01:08:30 [INFO]: Epoch 013 - training loss: 0.1752, validation loss: 0.1556
2024-05-25 01:08:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch13_loss0.1556147888302803.pypots
2024-05-25 01:08:47 [INFO]: Epoch 014 - training loss: 0.1523, validation loss: 0.1439
2024-05-25 01:08:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch14_loss0.14387289211153984.pypots
2024-05-25 01:09:04 [INFO]: Epoch 015 - training loss: 0.1706, validation loss: 0.1479
2024-05-25 01:09:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch15_loss0.14794684201478958.pypots
2024-05-25 01:09:20 [INFO]: Epoch 016 - training loss: 0.1729, validation loss: 0.1400
2024-05-25 01:09:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch16_loss0.14003109484910964.pypots
2024-05-25 01:09:37 [INFO]: Epoch 017 - training loss: 0.1554, validation loss: 0.1375
2024-05-25 01:09:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch17_loss0.13753389716148376.pypots
2024-05-25 01:09:54 [INFO]: Epoch 018 - training loss: 0.1816, validation loss: 0.1417
2024-05-25 01:09:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch18_loss0.14165830612182617.pypots
2024-05-25 01:10:11 [INFO]: Epoch 019 - training loss: 0.1466, validation loss: 0.1393
2024-05-25 01:10:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch19_loss0.13925047665834428.pypots
2024-05-25 01:10:28 [INFO]: Epoch 020 - training loss: 0.1436, validation loss: 0.1364
2024-05-25 01:10:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch20_loss0.13643341287970542.pypots
2024-05-25 01:10:45 [INFO]: Epoch 021 - training loss: 0.1561, validation loss: 0.1396
2024-05-25 01:10:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch21_loss0.13955359533429146.pypots
2024-05-25 01:11:02 [INFO]: Epoch 022 - training loss: 0.1650, validation loss: 0.1333
2024-05-25 01:11:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch22_loss0.13329369202256203.pypots
2024-05-25 01:11:19 [INFO]: Epoch 023 - training loss: 0.1552, validation loss: 0.1334
2024-05-25 01:11:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch23_loss0.13337803930044173.pypots
2024-05-25 01:11:36 [INFO]: Epoch 024 - training loss: 0.1645, validation loss: 0.1314
2024-05-25 01:11:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch24_loss0.13136840760707855.pypots
2024-05-25 01:11:53 [INFO]: Epoch 025 - training loss: 0.1562, validation loss: 0.1336
2024-05-25 01:11:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch25_loss0.13364828899502754.pypots
2024-05-25 01:12:09 [INFO]: Epoch 026 - training loss: 0.1478, validation loss: 0.1295
2024-05-25 01:12:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch26_loss0.12951779663562774.pypots
2024-05-25 01:12:26 [INFO]: Epoch 027 - training loss: 0.1404, validation loss: 0.1324
2024-05-25 01:12:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch27_loss0.13241273984313012.pypots
2024-05-25 01:12:43 [INFO]: Epoch 028 - training loss: 0.1505, validation loss: 0.1601
2024-05-25 01:12:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch28_loss0.16008552461862563.pypots
2024-05-25 01:13:00 [INFO]: Epoch 029 - training loss: 0.1529, validation loss: 0.1317
2024-05-25 01:13:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch29_loss0.13168056234717368.pypots
2024-05-25 01:13:17 [INFO]: Epoch 030 - training loss: 0.1421, validation loss: 0.1297
2024-05-25 01:13:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch30_loss0.12971183210611342.pypots
2024-05-25 01:13:34 [INFO]: Epoch 031 - training loss: 0.1429, validation loss: 0.1295
2024-05-25 01:13:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch31_loss0.12945500314235686.pypots
2024-05-25 01:13:51 [INFO]: Epoch 032 - training loss: 0.1405, validation loss: 0.1232
2024-05-25 01:13:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch32_loss0.12316166013479232.pypots
2024-05-25 01:14:08 [INFO]: Epoch 033 - training loss: 0.1277, validation loss: 0.1246
2024-05-25 01:14:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch33_loss0.12457380741834641.pypots
2024-05-25 01:14:25 [INFO]: Epoch 034 - training loss: 0.1410, validation loss: 0.1234
2024-05-25 01:14:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch34_loss0.12339311614632606.pypots
2024-05-25 01:14:42 [INFO]: Epoch 035 - training loss: 0.1294, validation loss: 0.1219
2024-05-25 01:14:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch35_loss0.1218681052327156.pypots
2024-05-25 01:14:58 [INFO]: Epoch 036 - training loss: 0.1377, validation loss: 0.1233
2024-05-25 01:14:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch36_loss0.12325001582503319.pypots
2024-05-25 01:15:15 [INFO]: Epoch 037 - training loss: 0.1440, validation loss: 0.1221
2024-05-25 01:15:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch37_loss0.12207636758685111.pypots
2024-05-25 01:15:32 [INFO]: Epoch 038 - training loss: 0.1279, validation loss: 0.1205
2024-05-25 01:15:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch38_loss0.12050301805138589.pypots
2024-05-25 01:15:49 [INFO]: Epoch 039 - training loss: 0.1335, validation loss: 0.1259
2024-05-25 01:15:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch39_loss0.12594210878014564.pypots
2024-05-25 01:16:06 [INFO]: Epoch 040 - training loss: 0.1170, validation loss: 0.1253
2024-05-25 01:16:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch40_loss0.12534528523683547.pypots
2024-05-25 01:16:23 [INFO]: Epoch 041 - training loss: 0.1495, validation loss: 0.1199
2024-05-25 01:16:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch41_loss0.11992261707782745.pypots
2024-05-25 01:16:40 [INFO]: Epoch 042 - training loss: 0.1275, validation loss: 0.1176
2024-05-25 01:16:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch42_loss0.11764521896839142.pypots
2024-05-25 01:16:57 [INFO]: Epoch 043 - training loss: 0.1267, validation loss: 0.1186
2024-05-25 01:16:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch43_loss0.11864441931247711.pypots
2024-05-25 01:17:14 [INFO]: Epoch 044 - training loss: 0.1260, validation loss: 0.1164
2024-05-25 01:17:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch44_loss0.11642614379525185.pypots
2024-05-25 01:17:31 [INFO]: Epoch 045 - training loss: 0.1323, validation loss: 0.1145
2024-05-25 01:17:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch45_loss0.11447458788752556.pypots
2024-05-25 01:17:48 [INFO]: Epoch 046 - training loss: 0.1247, validation loss: 0.1167
2024-05-25 01:17:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch46_loss0.11674521490931511.pypots
2024-05-25 01:18:04 [INFO]: Epoch 047 - training loss: 0.1162, validation loss: 0.1154
2024-05-25 01:18:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch47_loss0.11540337353944778.pypots
2024-05-25 01:18:21 [INFO]: Epoch 048 - training loss: 0.1233, validation loss: 0.1144
2024-05-25 01:18:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch48_loss0.11439861431717872.pypots
2024-05-25 01:18:38 [INFO]: Epoch 049 - training loss: 0.1417, validation loss: 0.1169
2024-05-25 01:18:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch49_loss0.11694971323013306.pypots
2024-05-25 01:18:55 [INFO]: Epoch 050 - training loss: 0.1216, validation loss: 0.1128
2024-05-25 01:18:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch50_loss0.11276663914322853.pypots
2024-05-25 01:19:12 [INFO]: Epoch 051 - training loss: 0.1183, validation loss: 0.1181
2024-05-25 01:19:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch51_loss0.11808398962020875.pypots
2024-05-25 01:19:29 [INFO]: Epoch 052 - training loss: 0.1312, validation loss: 0.1157
2024-05-25 01:19:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch52_loss0.11565804183483124.pypots
2024-05-25 01:19:46 [INFO]: Epoch 053 - training loss: 0.1309, validation loss: 0.1136
2024-05-25 01:19:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch53_loss0.11358610317111015.pypots
2024-05-25 01:20:03 [INFO]: Epoch 054 - training loss: 0.1271, validation loss: 0.1137
2024-05-25 01:20:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch54_loss0.11368359923362732.pypots
2024-05-25 01:20:20 [INFO]: Epoch 055 - training loss: 0.1321, validation loss: 0.1115
2024-05-25 01:20:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch55_loss0.1115331619977951.pypots
2024-05-25 01:20:37 [INFO]: Epoch 056 - training loss: 0.1165, validation loss: 0.1241
2024-05-25 01:20:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch56_loss0.12413871809840202.pypots
2024-05-25 01:20:54 [INFO]: Epoch 057 - training loss: 0.1335, validation loss: 0.1118
2024-05-25 01:20:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch57_loss0.11180134117603302.pypots
2024-05-25 01:21:10 [INFO]: Epoch 058 - training loss: 0.1241, validation loss: 0.1127
2024-05-25 01:21:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch58_loss0.1126880630850792.pypots
2024-05-25 01:21:27 [INFO]: Epoch 059 - training loss: 0.1207, validation loss: 0.1118
2024-05-25 01:21:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch59_loss0.11178787052631378.pypots
2024-05-25 01:21:44 [INFO]: Epoch 060 - training loss: 0.1131, validation loss: 0.1102
2024-05-25 01:21:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch60_loss0.11017348766326904.pypots
2024-05-25 01:22:01 [INFO]: Epoch 061 - training loss: 0.1239, validation loss: 0.1098
2024-05-25 01:22:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch61_loss0.10979840755462647.pypots
2024-05-25 01:22:18 [INFO]: Epoch 062 - training loss: 0.1173, validation loss: 0.1122
2024-05-25 01:22:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch62_loss0.11222132071852683.pypots
2024-05-25 01:22:35 [INFO]: Epoch 063 - training loss: 0.1171, validation loss: 0.1091
2024-05-25 01:22:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch63_loss0.1091128021478653.pypots
2024-05-25 01:22:52 [INFO]: Epoch 064 - training loss: 0.1223, validation loss: 0.1102
2024-05-25 01:22:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch64_loss0.11020258590579032.pypots
2024-05-25 01:23:09 [INFO]: Epoch 065 - training loss: 0.1187, validation loss: 0.1095
2024-05-25 01:23:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch65_loss0.10951866433024407.pypots
2024-05-25 01:23:26 [INFO]: Epoch 066 - training loss: 0.1231, validation loss: 0.1111
2024-05-25 01:23:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch66_loss0.11108388453722.pypots
2024-05-25 01:23:43 [INFO]: Epoch 067 - training loss: 0.1042, validation loss: 0.1088
2024-05-25 01:23:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch67_loss0.10876706838607789.pypots
2024-05-25 01:24:00 [INFO]: Epoch 068 - training loss: 0.1188, validation loss: 0.1091
2024-05-25 01:24:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch68_loss0.10909640789031982.pypots
2024-05-25 01:24:16 [INFO]: Epoch 069 - training loss: 0.1078, validation loss: 0.1131
2024-05-25 01:24:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch69_loss0.11308962628245353.pypots
2024-05-25 01:24:33 [INFO]: Epoch 070 - training loss: 0.1185, validation loss: 0.1081
2024-05-25 01:24:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch70_loss0.10811034962534904.pypots
2024-05-25 01:24:50 [INFO]: Epoch 071 - training loss: 0.1053, validation loss: 0.1092
2024-05-25 01:24:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch71_loss0.10916120931506157.pypots
2024-05-25 01:25:07 [INFO]: Epoch 072 - training loss: 0.1114, validation loss: 0.1195
2024-05-25 01:25:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch72_loss0.11946741864085197.pypots
2024-05-25 01:25:24 [INFO]: Epoch 073 - training loss: 0.1302, validation loss: 0.1143
2024-05-25 01:25:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch73_loss0.11434356197714805.pypots
2024-05-25 01:25:41 [INFO]: Epoch 074 - training loss: 0.1222, validation loss: 0.1089
2024-05-25 01:25:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch74_loss0.10893319249153137.pypots
2024-05-25 01:25:58 [INFO]: Epoch 075 - training loss: 0.1175, validation loss: 0.1111
2024-05-25 01:25:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch75_loss0.11109112724661827.pypots
2024-05-25 01:26:15 [INFO]: Epoch 076 - training loss: 0.1185, validation loss: 0.1095
2024-05-25 01:26:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch76_loss0.10945866852998734.pypots
2024-05-25 01:26:32 [INFO]: Epoch 077 - training loss: 0.1203, validation loss: 0.1125
2024-05-25 01:26:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch77_loss0.1125347450375557.pypots
2024-05-25 01:26:49 [INFO]: Epoch 078 - training loss: 0.1356, validation loss: 0.1071
2024-05-25 01:26:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch78_loss0.10707528740167618.pypots
2024-05-25 01:27:06 [INFO]: Epoch 079 - training loss: 0.1114, validation loss: 0.1082
2024-05-25 01:27:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch79_loss0.1081735834479332.pypots
2024-05-25 01:27:22 [INFO]: Epoch 080 - training loss: 0.1157, validation loss: 0.1064
2024-05-25 01:27:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch80_loss0.10640235096216202.pypots
2024-05-25 01:27:39 [INFO]: Epoch 081 - training loss: 0.1223, validation loss: 0.1082
2024-05-25 01:27:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch81_loss0.10818838626146317.pypots
2024-05-25 01:27:56 [INFO]: Epoch 082 - training loss: 0.1186, validation loss: 0.1069
2024-05-25 01:27:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch82_loss0.10686056837439536.pypots
2024-05-25 01:28:13 [INFO]: Epoch 083 - training loss: 0.1153, validation loss: 0.1124
2024-05-25 01:28:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch83_loss0.11243363842368126.pypots
2024-05-25 01:28:30 [INFO]: Epoch 084 - training loss: 0.1203, validation loss: 0.1062
2024-05-25 01:28:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch84_loss0.1061604492366314.pypots
2024-05-25 01:28:47 [INFO]: Epoch 085 - training loss: 0.1186, validation loss: 0.1053
2024-05-25 01:28:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch85_loss0.10526925697922707.pypots
2024-05-25 01:29:04 [INFO]: Epoch 086 - training loss: 0.1163, validation loss: 0.1059
2024-05-25 01:29:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch86_loss0.1058990515768528.pypots
2024-05-25 01:29:21 [INFO]: Epoch 087 - training loss: 0.1173, validation loss: 0.1068
2024-05-25 01:29:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch87_loss0.10675901621580124.pypots
2024-05-25 01:29:38 [INFO]: Epoch 088 - training loss: 0.1137, validation loss: 0.1076
2024-05-25 01:29:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch88_loss0.10757317915558814.pypots
2024-05-25 01:29:55 [INFO]: Epoch 089 - training loss: 0.1019, validation loss: 0.1058
2024-05-25 01:29:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch89_loss0.10577671378850936.pypots
2024-05-25 01:30:12 [INFO]: Epoch 090 - training loss: 0.1181, validation loss: 0.1043
2024-05-25 01:30:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch90_loss0.10433050692081451.pypots
2024-05-25 01:30:29 [INFO]: Epoch 091 - training loss: 0.1037, validation loss: 0.1083
2024-05-25 01:30:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch91_loss0.10831202194094658.pypots
2024-05-25 01:30:46 [INFO]: Epoch 092 - training loss: 0.1150, validation loss: 0.1056
2024-05-25 01:30:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch92_loss0.10557745471596718.pypots
2024-05-25 01:31:02 [INFO]: Epoch 093 - training loss: 0.1077, validation loss: 0.1083
2024-05-25 01:31:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch93_loss0.10830141082406045.pypots
2024-05-25 01:31:19 [INFO]: Epoch 094 - training loss: 0.1102, validation loss: 0.1065
2024-05-25 01:31:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch94_loss0.10647940784692764.pypots
2024-05-25 01:31:36 [INFO]: Epoch 095 - training loss: 0.1054, validation loss: 0.1078
2024-05-25 01:31:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch95_loss0.1078443855047226.pypots
2024-05-25 01:31:53 [INFO]: Epoch 096 - training loss: 0.1198, validation loss: 0.1069
2024-05-25 01:31:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch96_loss0.10685746893286704.pypots
2024-05-25 01:32:10 [INFO]: Epoch 097 - training loss: 0.1268, validation loss: 0.1168
2024-05-25 01:32:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch97_loss0.11675136610865593.pypots
2024-05-25 01:32:27 [INFO]: Epoch 098 - training loss: 0.1133, validation loss: 0.1076
2024-05-25 01:32:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch98_loss0.10757806524634361.pypots
2024-05-25 01:32:44 [INFO]: Epoch 099 - training loss: 0.1063, validation loss: 0.1052
2024-05-25 01:32:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch99_loss0.10516836941242218.pypots
2024-05-25 01:33:01 [INFO]: Epoch 100 - training loss: 0.1122, validation loss: 0.1050
2024-05-25 01:33:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI_epoch100_loss0.10499034523963928.pypots
2024-05-25 01:33:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:33:01 [INFO]: Finished training. The best model is from epoch#90.
2024-05-25 01:33:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/CSDI_air_quality/20240525_T010450/CSDI.pypots
2024-05-25 01:35:22 [INFO]: CSDI on Air-Quality: MAE=0.1109, MSE=0.1146
2024-05-25 01:35:22 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 01:35:22 [INFO]: Using the given device: cuda:0
2024-05-25 01:35:22 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T013522
2024-05-25 01:35:22 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T013522/tensorboard
2024-05-25 01:35:22 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 01:35:22 [INFO]: Epoch 001 - training loss: 63526.1071, validation loss: 0.7129
2024-05-25 01:35:22 [INFO]: Epoch 002 - training loss: 42071.4864, validation loss: 0.5909
2024-05-25 01:35:23 [INFO]: Epoch 003 - training loss: 41754.8727, validation loss: 0.5756
2024-05-25 01:35:23 [INFO]: Epoch 004 - training loss: 41651.8824, validation loss: 0.5354
2024-05-25 01:35:23 [INFO]: Epoch 005 - training loss: 41549.4554, validation loss: 0.4613
2024-05-25 01:35:24 [INFO]: Epoch 006 - training loss: 41566.7031, validation loss: 0.4691
2024-05-25 01:35:24 [INFO]: Epoch 007 - training loss: 41516.8675, validation loss: 0.4364
2024-05-25 01:35:24 [INFO]: Epoch 008 - training loss: 41428.1305, validation loss: 0.3916
2024-05-25 01:35:25 [INFO]: Epoch 009 - training loss: 41396.2593, validation loss: 0.3764
2024-05-25 01:35:25 [INFO]: Epoch 010 - training loss: 41390.3436, validation loss: 0.4092
2024-05-25 01:35:26 [INFO]: Epoch 011 - training loss: 41386.1175, validation loss: 0.4035
2024-05-25 01:35:26 [INFO]: Epoch 012 - training loss: 41367.2358, validation loss: 0.3543
2024-05-25 01:35:26 [INFO]: Epoch 013 - training loss: 41329.0201, validation loss: 0.3338
2024-05-25 01:35:27 [INFO]: Epoch 014 - training loss: 41313.8487, validation loss: 0.3378
2024-05-25 01:35:27 [INFO]: Epoch 015 - training loss: 41314.4019, validation loss: 0.3821
2024-05-25 01:35:27 [INFO]: Epoch 016 - training loss: 41340.4275, validation loss: 0.3317
2024-05-25 01:35:28 [INFO]: Epoch 017 - training loss: 41307.9598, validation loss: 0.3145
2024-05-25 01:35:28 [INFO]: Epoch 018 - training loss: 41285.5574, validation loss: 0.3196
2024-05-25 01:35:28 [INFO]: Epoch 019 - training loss: 41268.1780, validation loss: 0.3093
2024-05-25 01:35:29 [INFO]: Epoch 020 - training loss: 41259.0566, validation loss: 0.3044
2024-05-25 01:35:29 [INFO]: Epoch 021 - training loss: 41259.7568, validation loss: 0.3369
2024-05-25 01:35:29 [INFO]: Epoch 022 - training loss: 41270.2937, validation loss: 0.3218
2024-05-25 01:35:30 [INFO]: Epoch 023 - training loss: 41258.2956, validation loss: 0.2991
2024-05-25 01:35:30 [INFO]: Epoch 024 - training loss: 41238.2106, validation loss: 0.2912
2024-05-25 01:35:31 [INFO]: Epoch 025 - training loss: 41260.9291, validation loss: 0.3148
2024-05-25 01:35:31 [INFO]: Epoch 026 - training loss: 41230.6107, validation loss: 0.3036
2024-05-25 01:35:31 [INFO]: Epoch 027 - training loss: 41235.2588, validation loss: 0.3132
2024-05-25 01:35:32 [INFO]: Epoch 028 - training loss: 41246.5349, validation loss: 0.3434
2024-05-25 01:35:32 [INFO]: Epoch 029 - training loss: 41269.1470, validation loss: 0.3054
2024-05-25 01:35:32 [INFO]: Epoch 030 - training loss: 41228.6541, validation loss: 0.2962
2024-05-25 01:35:33 [INFO]: Epoch 031 - training loss: 41220.1658, validation loss: 0.2957
2024-05-25 01:35:33 [INFO]: Epoch 032 - training loss: 41207.4032, validation loss: 0.2850
2024-05-25 01:35:33 [INFO]: Epoch 033 - training loss: 41200.5875, validation loss: 0.2859
2024-05-25 01:35:34 [INFO]: Epoch 034 - training loss: 41194.0803, validation loss: 0.2825
2024-05-25 01:35:34 [INFO]: Epoch 035 - training loss: 41195.9944, validation loss: 0.2899
2024-05-25 01:35:34 [INFO]: Epoch 036 - training loss: 41202.1842, validation loss: 0.2857
2024-05-25 01:35:35 [INFO]: Epoch 037 - training loss: 41209.9404, validation loss: 0.3105
2024-05-25 01:35:35 [INFO]: Epoch 038 - training loss: 41257.0250, validation loss: 0.3152
2024-05-25 01:35:35 [INFO]: Epoch 039 - training loss: 41225.4453, validation loss: 0.2808
2024-05-25 01:35:36 [INFO]: Epoch 040 - training loss: 41197.7899, validation loss: 0.2751
2024-05-25 01:35:36 [INFO]: Epoch 041 - training loss: 41192.0434, validation loss: 0.2612
2024-05-25 01:35:36 [INFO]: Epoch 042 - training loss: 41182.3927, validation loss: 0.2753
2024-05-25 01:35:37 [INFO]: Epoch 043 - training loss: 41191.3439, validation loss: 0.2573
2024-05-25 01:35:37 [INFO]: Epoch 044 - training loss: 41241.4528, validation loss: 0.2698
2024-05-25 01:35:37 [INFO]: Epoch 045 - training loss: 41210.7242, validation loss: 0.2812
2024-05-25 01:35:38 [INFO]: Epoch 046 - training loss: 41209.5029, validation loss: 0.2814
2024-05-25 01:35:38 [INFO]: Epoch 047 - training loss: 41207.1220, validation loss: 0.2666
2024-05-25 01:35:39 [INFO]: Epoch 048 - training loss: 41182.3070, validation loss: 0.2803
2024-05-25 01:35:39 [INFO]: Epoch 049 - training loss: 41181.1794, validation loss: 0.2693
2024-05-25 01:35:39 [INFO]: Epoch 050 - training loss: 41176.9567, validation loss: 0.2751
2024-05-25 01:35:40 [INFO]: Epoch 051 - training loss: 41175.6343, validation loss: 0.2683
2024-05-25 01:35:40 [INFO]: Epoch 052 - training loss: 41180.8845, validation loss: 0.2578
2024-05-25 01:35:40 [INFO]: Epoch 053 - training loss: 41181.6657, validation loss: 0.2700
2024-05-25 01:35:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:35:40 [INFO]: Finished training. The best model is from epoch#43.
2024-05-25 01:35:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/GPVAE_air_quality/20240525_T013522/GPVAE.pypots
2024-05-25 01:35:40 [INFO]: GP-VAE on Air-Quality: MAE=0.3078, MSE=0.2640
2024-05-25 01:35:40 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 01:35:40 [INFO]: Using the given device: cuda:0
2024-05-25 01:35:40 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T013540
2024-05-25 01:35:40 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T013540/tensorboard
2024-05-25 01:35:40 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 01:35:46 [INFO]: Epoch 001 - generator training loss: 0.5896, discriminator training loss: 0.2935, validation loss: 0.5176
2024-05-25 01:35:50 [INFO]: Epoch 002 - generator training loss: 0.2820, discriminator training loss: 0.0672, validation loss: 0.3976
2024-05-25 01:35:54 [INFO]: Epoch 003 - generator training loss: 0.2093, discriminator training loss: 0.0636, validation loss: 0.3329
2024-05-25 01:35:59 [INFO]: Epoch 004 - generator training loss: 0.1724, discriminator training loss: 0.0622, validation loss: 0.2937
2024-05-25 01:36:03 [INFO]: Epoch 005 - generator training loss: 0.1479, discriminator training loss: 0.0622, validation loss: 0.2661
2024-05-25 01:36:07 [INFO]: Epoch 006 - generator training loss: 0.1295, discriminator training loss: 0.0613, validation loss: 0.2482
2024-05-25 01:36:12 [INFO]: Epoch 007 - generator training loss: 0.1196, discriminator training loss: 0.0602, validation loss: 0.2337
2024-05-25 01:36:16 [INFO]: Epoch 008 - generator training loss: 0.1068, discriminator training loss: 0.0599, validation loss: 0.2239
2024-05-25 01:36:20 [INFO]: Epoch 009 - generator training loss: 0.0999, discriminator training loss: 0.0602, validation loss: 0.2157
2024-05-25 01:36:24 [INFO]: Epoch 010 - generator training loss: 0.0931, discriminator training loss: 0.0593, validation loss: 0.2092
2024-05-25 01:36:29 [INFO]: Epoch 011 - generator training loss: 0.0881, discriminator training loss: 0.0586, validation loss: 0.2032
2024-05-25 01:36:33 [INFO]: Epoch 012 - generator training loss: 0.0863, discriminator training loss: 0.0569, validation loss: 0.1976
2024-05-25 01:36:37 [INFO]: Epoch 013 - generator training loss: 0.0816, discriminator training loss: 0.0563, validation loss: 0.1940
2024-05-25 01:36:42 [INFO]: Epoch 014 - generator training loss: 0.0794, discriminator training loss: 0.0537, validation loss: 0.1896
2024-05-25 01:36:46 [INFO]: Epoch 015 - generator training loss: 0.0774, discriminator training loss: 0.0523, validation loss: 0.1868
2024-05-25 01:36:50 [INFO]: Epoch 016 - generator training loss: 0.0741, discriminator training loss: 0.0505, validation loss: 0.1835
2024-05-25 01:36:55 [INFO]: Epoch 017 - generator training loss: 0.0725, discriminator training loss: 0.0486, validation loss: 0.1806
2024-05-25 01:36:59 [INFO]: Epoch 018 - generator training loss: 0.0713, discriminator training loss: 0.0476, validation loss: 0.1778
2024-05-25 01:37:03 [INFO]: Epoch 019 - generator training loss: 0.0682, discriminator training loss: 0.0465, validation loss: 0.1759
2024-05-25 01:37:07 [INFO]: Epoch 020 - generator training loss: 0.0671, discriminator training loss: 0.0456, validation loss: 0.1738
2024-05-25 01:37:12 [INFO]: Epoch 021 - generator training loss: 0.0655, discriminator training loss: 0.0446, validation loss: 0.1719
2024-05-25 01:37:16 [INFO]: Epoch 022 - generator training loss: 0.0637, discriminator training loss: 0.0441, validation loss: 0.1714
2024-05-25 01:37:20 [INFO]: Epoch 023 - generator training loss: 0.0623, discriminator training loss: 0.0435, validation loss: 0.1693
2024-05-25 01:37:25 [INFO]: Epoch 024 - generator training loss: 0.0607, discriminator training loss: 0.0436, validation loss: 0.1677
2024-05-25 01:37:29 [INFO]: Epoch 025 - generator training loss: 0.0609, discriminator training loss: 0.0419, validation loss: 0.1660
2024-05-25 01:37:33 [INFO]: Epoch 026 - generator training loss: 0.0612, discriminator training loss: 0.0410, validation loss: 0.1650
2024-05-25 01:37:38 [INFO]: Epoch 027 - generator training loss: 0.0604, discriminator training loss: 0.0404, validation loss: 0.1636
2024-05-25 01:37:42 [INFO]: Epoch 028 - generator training loss: 0.0575, discriminator training loss: 0.0394, validation loss: 0.1631
2024-05-25 01:37:46 [INFO]: Epoch 029 - generator training loss: 0.0572, discriminator training loss: 0.0391, validation loss: 0.1621
2024-05-25 01:37:51 [INFO]: Epoch 030 - generator training loss: 0.0568, discriminator training loss: 0.0378, validation loss: 0.1612
2024-05-25 01:37:55 [INFO]: Epoch 031 - generator training loss: 0.0565, discriminator training loss: 0.0370, validation loss: 0.1605
2024-05-25 01:37:59 [INFO]: Epoch 032 - generator training loss: 0.0562, discriminator training loss: 0.0363, validation loss: 0.1595
2024-05-25 01:38:04 [INFO]: Epoch 033 - generator training loss: 0.0577, discriminator training loss: 0.0354, validation loss: 0.1583
2024-05-25 01:38:08 [INFO]: Epoch 034 - generator training loss: 0.0555, discriminator training loss: 0.0348, validation loss: 0.1581
2024-05-25 01:38:12 [INFO]: Epoch 035 - generator training loss: 0.0550, discriminator training loss: 0.0336, validation loss: 0.1570
2024-05-25 01:38:17 [INFO]: Epoch 036 - generator training loss: 0.0545, discriminator training loss: 0.0331, validation loss: 0.1560
2024-05-25 01:38:21 [INFO]: Epoch 037 - generator training loss: 0.0539, discriminator training loss: 0.0323, validation loss: 0.1562
2024-05-25 01:38:25 [INFO]: Epoch 038 - generator training loss: 0.0535, discriminator training loss: 0.0319, validation loss: 0.1554
2024-05-25 01:38:29 [INFO]: Epoch 039 - generator training loss: 0.0536, discriminator training loss: 0.0308, validation loss: 0.1544
2024-05-25 01:38:34 [INFO]: Epoch 040 - generator training loss: 0.0538, discriminator training loss: 0.0304, validation loss: 0.1541
2024-05-25 01:38:38 [INFO]: Epoch 041 - generator training loss: 0.0528, discriminator training loss: 0.0297, validation loss: 0.1529
2024-05-25 01:38:42 [INFO]: Epoch 042 - generator training loss: 0.0514, discriminator training loss: 0.0292, validation loss: 0.1525
2024-05-25 01:38:47 [INFO]: Epoch 043 - generator training loss: 0.0518, discriminator training loss: 0.0285, validation loss: 0.1522
2024-05-25 01:38:51 [INFO]: Epoch 044 - generator training loss: 0.0516, discriminator training loss: 0.0279, validation loss: 0.1514
2024-05-25 01:38:55 [INFO]: Epoch 045 - generator training loss: 0.0506, discriminator training loss: 0.0273, validation loss: 0.1509
2024-05-25 01:39:00 [INFO]: Epoch 046 - generator training loss: 0.0501, discriminator training loss: 0.0270, validation loss: 0.1503
2024-05-25 01:39:04 [INFO]: Epoch 047 - generator training loss: 0.0496, discriminator training loss: 0.0266, validation loss: 0.1488
2024-05-25 01:39:08 [INFO]: Epoch 048 - generator training loss: 0.0491, discriminator training loss: 0.0262, validation loss: 0.1492
2024-05-25 01:39:13 [INFO]: Epoch 049 - generator training loss: 0.0491, discriminator training loss: 0.0255, validation loss: 0.1487
2024-05-25 01:39:17 [INFO]: Epoch 050 - generator training loss: 0.0488, discriminator training loss: 0.0250, validation loss: 0.1484
2024-05-25 01:39:21 [INFO]: Epoch 051 - generator training loss: 0.0482, discriminator training loss: 0.0247, validation loss: 0.1478
2024-05-25 01:39:25 [INFO]: Epoch 052 - generator training loss: 0.0488, discriminator training loss: 0.0246, validation loss: 0.1471
2024-05-25 01:39:30 [INFO]: Epoch 053 - generator training loss: 0.0485, discriminator training loss: 0.0239, validation loss: 0.1466
2024-05-25 01:39:34 [INFO]: Epoch 054 - generator training loss: 0.0477, discriminator training loss: 0.0235, validation loss: 0.1468
2024-05-25 01:39:39 [INFO]: Epoch 055 - generator training loss: 0.0469, discriminator training loss: 0.0231, validation loss: 0.1466
2024-05-25 01:39:43 [INFO]: Epoch 056 - generator training loss: 0.0477, discriminator training loss: 0.0229, validation loss: 0.1465
2024-05-25 01:39:47 [INFO]: Epoch 057 - generator training loss: 0.0483, discriminator training loss: 0.0225, validation loss: 0.1464
2024-05-25 01:39:51 [INFO]: Epoch 058 - generator training loss: 0.0473, discriminator training loss: 0.0224, validation loss: 0.1455
2024-05-25 01:39:56 [INFO]: Epoch 059 - generator training loss: 0.0470, discriminator training loss: 0.0222, validation loss: 0.1462
2024-05-25 01:40:00 [INFO]: Epoch 060 - generator training loss: 0.0456, discriminator training loss: 0.0216, validation loss: 0.1459
2024-05-25 01:40:04 [INFO]: Epoch 061 - generator training loss: 0.0449, discriminator training loss: 0.0215, validation loss: 0.1454
2024-05-25 01:40:08 [INFO]: Epoch 062 - generator training loss: 0.0442, discriminator training loss: 0.0213, validation loss: 0.1448
2024-05-25 01:40:12 [INFO]: Epoch 063 - generator training loss: 0.0445, discriminator training loss: 0.0209, validation loss: 0.1457
2024-05-25 01:40:16 [INFO]: Epoch 064 - generator training loss: 0.0456, discriminator training loss: 0.0207, validation loss: 0.1447
2024-05-25 01:40:20 [INFO]: Epoch 065 - generator training loss: 0.0439, discriminator training loss: 0.0207, validation loss: 0.1447
2024-05-25 01:40:25 [INFO]: Epoch 066 - generator training loss: 0.0436, discriminator training loss: 0.0204, validation loss: 0.1436
2024-05-25 01:40:29 [INFO]: Epoch 067 - generator training loss: 0.0443, discriminator training loss: 0.0199, validation loss: 0.1443
2024-05-25 01:40:33 [INFO]: Epoch 068 - generator training loss: 0.0436, discriminator training loss: 0.0197, validation loss: 0.1441
2024-05-25 01:40:38 [INFO]: Epoch 069 - generator training loss: 0.0430, discriminator training loss: 0.0196, validation loss: 0.1437
2024-05-25 01:40:42 [INFO]: Epoch 070 - generator training loss: 0.0427, discriminator training loss: 0.0194, validation loss: 0.1443
2024-05-25 01:40:46 [INFO]: Epoch 071 - generator training loss: 0.0423, discriminator training loss: 0.0190, validation loss: 0.1436
2024-05-25 01:40:51 [INFO]: Epoch 072 - generator training loss: 0.0420, discriminator training loss: 0.0190, validation loss: 0.1439
2024-05-25 01:40:55 [INFO]: Epoch 073 - generator training loss: 0.0423, discriminator training loss: 0.0188, validation loss: 0.1431
2024-05-25 01:40:59 [INFO]: Epoch 074 - generator training loss: 0.0416, discriminator training loss: 0.0188, validation loss: 0.1442
2024-05-25 01:41:04 [INFO]: Epoch 075 - generator training loss: 0.0432, discriminator training loss: 0.0186, validation loss: 0.1429
2024-05-25 01:41:08 [INFO]: Epoch 076 - generator training loss: 0.0412, discriminator training loss: 0.0182, validation loss: 0.1432
2024-05-25 01:41:12 [INFO]: Epoch 077 - generator training loss: 0.0408, discriminator training loss: 0.0178, validation loss: 0.1429
2024-05-25 01:41:17 [INFO]: Epoch 078 - generator training loss: 0.0406, discriminator training loss: 0.0179, validation loss: 0.1430
2024-05-25 01:41:21 [INFO]: Epoch 079 - generator training loss: 0.0409, discriminator training loss: 0.0176, validation loss: 0.1430
2024-05-25 01:41:25 [INFO]: Epoch 080 - generator training loss: 0.0406, discriminator training loss: 0.0175, validation loss: 0.1417
2024-05-25 01:41:29 [INFO]: Epoch 081 - generator training loss: 0.0406, discriminator training loss: 0.0175, validation loss: 0.1421
2024-05-25 01:41:34 [INFO]: Epoch 082 - generator training loss: 0.0397, discriminator training loss: 0.0174, validation loss: 0.1426
2024-05-25 01:41:38 [INFO]: Epoch 083 - generator training loss: 0.0395, discriminator training loss: 0.0171, validation loss: 0.1427
2024-05-25 01:41:42 [INFO]: Epoch 084 - generator training loss: 0.0395, discriminator training loss: 0.0170, validation loss: 0.1437
2024-05-25 01:41:47 [INFO]: Epoch 085 - generator training loss: 0.0397, discriminator training loss: 0.0170, validation loss: 0.1419
2024-05-25 01:41:51 [INFO]: Epoch 086 - generator training loss: 0.0388, discriminator training loss: 0.0168, validation loss: 0.1417
2024-05-25 01:41:55 [INFO]: Epoch 087 - generator training loss: 0.0390, discriminator training loss: 0.0166, validation loss: 0.1429
2024-05-25 01:42:00 [INFO]: Epoch 088 - generator training loss: 0.0392, discriminator training loss: 0.0165, validation loss: 0.1422
2024-05-25 01:42:04 [INFO]: Epoch 089 - generator training loss: 0.0383, discriminator training loss: 0.0163, validation loss: 0.1431
2024-05-25 01:42:08 [INFO]: Epoch 090 - generator training loss: 0.0387, discriminator training loss: 0.0163, validation loss: 0.1423
2024-05-25 01:42:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:42:08 [INFO]: Finished training. The best model is from epoch#80.
2024-05-25 01:42:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/USGAN_air_quality/20240525_T013540/USGAN.pypots
2024-05-25 01:42:09 [INFO]: US-GAN on Air-Quality: MAE=0.2066, MSE=0.1328
2024-05-25 01:42:09 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 01:42:09 [INFO]: Using the given device: cuda:0
2024-05-25 01:42:09 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T014209
2024-05-25 01:42:09 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T014209/tensorboard
2024-05-25 01:42:09 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 01:42:13 [INFO]: Epoch 001 - training loss: 1.4077, validation loss: 0.9567
2024-05-25 01:42:16 [INFO]: Epoch 002 - training loss: 1.1301, validation loss: 0.7199
2024-05-25 01:42:19 [INFO]: Epoch 003 - training loss: 0.9424, validation loss: 0.6124
2024-05-25 01:42:22 [INFO]: Epoch 004 - training loss: 0.8310, validation loss: 0.5460
2024-05-25 01:42:24 [INFO]: Epoch 005 - training loss: 0.7582, validation loss: 0.4954
2024-05-25 01:42:27 [INFO]: Epoch 006 - training loss: 0.7015, validation loss: 0.4582
2024-05-25 01:42:30 [INFO]: Epoch 007 - training loss: 0.6584, validation loss: 0.4275
2024-05-25 01:42:33 [INFO]: Epoch 008 - training loss: 0.6245, validation loss: 0.4024
2024-05-25 01:42:36 [INFO]: Epoch 009 - training loss: 0.5984, validation loss: 0.3818
2024-05-25 01:42:39 [INFO]: Epoch 010 - training loss: 0.5752, validation loss: 0.3644
2024-05-25 01:42:42 [INFO]: Epoch 011 - training loss: 0.5583, validation loss: 0.3497
2024-05-25 01:42:45 [INFO]: Epoch 012 - training loss: 0.5413, validation loss: 0.3378
2024-05-25 01:42:48 [INFO]: Epoch 013 - training loss: 0.5280, validation loss: 0.3267
2024-05-25 01:42:51 [INFO]: Epoch 014 - training loss: 0.5167, validation loss: 0.3174
2024-05-25 01:42:54 [INFO]: Epoch 015 - training loss: 0.5075, validation loss: 0.3099
2024-05-25 01:42:57 [INFO]: Epoch 016 - training loss: 0.4958, validation loss: 0.3022
2024-05-25 01:43:00 [INFO]: Epoch 017 - training loss: 0.4869, validation loss: 0.2953
2024-05-25 01:43:03 [INFO]: Epoch 018 - training loss: 0.4782, validation loss: 0.2893
2024-05-25 01:43:06 [INFO]: Epoch 019 - training loss: 0.4704, validation loss: 0.2840
2024-05-25 01:43:08 [INFO]: Epoch 020 - training loss: 0.4626, validation loss: 0.2792
2024-05-25 01:43:11 [INFO]: Epoch 021 - training loss: 0.4568, validation loss: 0.2745
2024-05-25 01:43:14 [INFO]: Epoch 022 - training loss: 0.4496, validation loss: 0.2702
2024-05-25 01:43:17 [INFO]: Epoch 023 - training loss: 0.4433, validation loss: 0.2659
2024-05-25 01:43:20 [INFO]: Epoch 024 - training loss: 0.4371, validation loss: 0.2623
2024-05-25 01:43:23 [INFO]: Epoch 025 - training loss: 0.4321, validation loss: 0.2583
2024-05-25 01:43:26 [INFO]: Epoch 026 - training loss: 0.4265, validation loss: 0.2551
2024-05-25 01:43:29 [INFO]: Epoch 027 - training loss: 0.4217, validation loss: 0.2517
2024-05-25 01:43:32 [INFO]: Epoch 028 - training loss: 0.4166, validation loss: 0.2483
2024-05-25 01:43:35 [INFO]: Epoch 029 - training loss: 0.4108, validation loss: 0.2450
2024-05-25 01:43:38 [INFO]: Epoch 030 - training loss: 0.4075, validation loss: 0.2421
2024-05-25 01:43:41 [INFO]: Epoch 031 - training loss: 0.4033, validation loss: 0.2393
2024-05-25 01:43:44 [INFO]: Epoch 032 - training loss: 0.3973, validation loss: 0.2361
2024-05-25 01:43:47 [INFO]: Epoch 033 - training loss: 0.3940, validation loss: 0.2329
2024-05-25 01:43:49 [INFO]: Epoch 034 - training loss: 0.3904, validation loss: 0.2301
2024-05-25 01:43:52 [INFO]: Epoch 035 - training loss: 0.3851, validation loss: 0.2278
2024-05-25 01:43:55 [INFO]: Epoch 036 - training loss: 0.3811, validation loss: 0.2254
2024-05-25 01:43:58 [INFO]: Epoch 037 - training loss: 0.3778, validation loss: 0.2225
2024-05-25 01:44:01 [INFO]: Epoch 038 - training loss: 0.3746, validation loss: 0.2202
2024-05-25 01:44:04 [INFO]: Epoch 039 - training loss: 0.3720, validation loss: 0.2176
2024-05-25 01:44:07 [INFO]: Epoch 040 - training loss: 0.3680, validation loss: 0.2153
2024-05-25 01:44:10 [INFO]: Epoch 041 - training loss: 0.3640, validation loss: 0.2128
2024-05-25 01:44:13 [INFO]: Epoch 042 - training loss: 0.3618, validation loss: 0.2105
2024-05-25 01:44:16 [INFO]: Epoch 043 - training loss: 0.3581, validation loss: 0.2089
2024-05-25 01:44:19 [INFO]: Epoch 044 - training loss: 0.3551, validation loss: 0.2060
2024-05-25 01:44:22 [INFO]: Epoch 045 - training loss: 0.3525, validation loss: 0.2041
2024-05-25 01:44:25 [INFO]: Epoch 046 - training loss: 0.3498, validation loss: 0.2025
2024-05-25 01:44:28 [INFO]: Epoch 047 - training loss: 0.3480, validation loss: 0.2004
2024-05-25 01:44:31 [INFO]: Epoch 048 - training loss: 0.3453, validation loss: 0.1983
2024-05-25 01:44:34 [INFO]: Epoch 049 - training loss: 0.3425, validation loss: 0.1964
2024-05-25 01:44:36 [INFO]: Epoch 050 - training loss: 0.3408, validation loss: 0.1947
2024-05-25 01:44:39 [INFO]: Epoch 051 - training loss: 0.3374, validation loss: 0.1930
2024-05-25 01:44:42 [INFO]: Epoch 052 - training loss: 0.3359, validation loss: 0.1917
2024-05-25 01:44:45 [INFO]: Epoch 053 - training loss: 0.3344, validation loss: 0.1899
2024-05-25 01:44:48 [INFO]: Epoch 054 - training loss: 0.3320, validation loss: 0.1888
2024-05-25 01:44:51 [INFO]: Epoch 055 - training loss: 0.3286, validation loss: 0.1870
2024-05-25 01:44:54 [INFO]: Epoch 056 - training loss: 0.3275, validation loss: 0.1860
2024-05-25 01:44:57 [INFO]: Epoch 057 - training loss: 0.3257, validation loss: 0.1842
2024-05-25 01:45:00 [INFO]: Epoch 058 - training loss: 0.3238, validation loss: 0.1833
2024-05-25 01:45:03 [INFO]: Epoch 059 - training loss: 0.3217, validation loss: 0.1819
2024-05-25 01:45:06 [INFO]: Epoch 060 - training loss: 0.3207, validation loss: 0.1808
2024-05-25 01:45:09 [INFO]: Epoch 061 - training loss: 0.3192, validation loss: 0.1797
2024-05-25 01:45:12 [INFO]: Epoch 062 - training loss: 0.3169, validation loss: 0.1786
2024-05-25 01:45:15 [INFO]: Epoch 063 - training loss: 0.3146, validation loss: 0.1775
2024-05-25 01:45:17 [INFO]: Epoch 064 - training loss: 0.3136, validation loss: 0.1765
2024-05-25 01:45:20 [INFO]: Epoch 065 - training loss: 0.3122, validation loss: 0.1758
2024-05-25 01:45:23 [INFO]: Epoch 066 - training loss: 0.3110, validation loss: 0.1747
2024-05-25 01:45:26 [INFO]: Epoch 067 - training loss: 0.3096, validation loss: 0.1739
2024-05-25 01:45:29 [INFO]: Epoch 068 - training loss: 0.3090, validation loss: 0.1727
2024-05-25 01:45:32 [INFO]: Epoch 069 - training loss: 0.3071, validation loss: 0.1717
2024-05-25 01:45:35 [INFO]: Epoch 070 - training loss: 0.3060, validation loss: 0.1711
2024-05-25 01:45:38 [INFO]: Epoch 071 - training loss: 0.3050, validation loss: 0.1703
2024-05-25 01:45:41 [INFO]: Epoch 072 - training loss: 0.3038, validation loss: 0.1695
2024-05-25 01:45:44 [INFO]: Epoch 073 - training loss: 0.3023, validation loss: 0.1686
2024-05-25 01:45:47 [INFO]: Epoch 074 - training loss: 0.3014, validation loss: 0.1679
2024-05-25 01:45:50 [INFO]: Epoch 075 - training loss: 0.3007, validation loss: 0.1671
2024-05-25 01:45:53 [INFO]: Epoch 076 - training loss: 0.2991, validation loss: 0.1663
2024-05-25 01:45:56 [INFO]: Epoch 077 - training loss: 0.2982, validation loss: 0.1656
2024-05-25 01:45:59 [INFO]: Epoch 078 - training loss: 0.2978, validation loss: 0.1649
2024-05-25 01:46:02 [INFO]: Epoch 079 - training loss: 0.2966, validation loss: 0.1641
2024-05-25 01:46:05 [INFO]: Epoch 080 - training loss: 0.2955, validation loss: 0.1634
2024-05-25 01:46:08 [INFO]: Epoch 081 - training loss: 0.2951, validation loss: 0.1627
2024-05-25 01:46:10 [INFO]: Epoch 082 - training loss: 0.2938, validation loss: 0.1623
2024-05-25 01:46:13 [INFO]: Epoch 083 - training loss: 0.2925, validation loss: 0.1615
2024-05-25 01:46:16 [INFO]: Epoch 084 - training loss: 0.2918, validation loss: 0.1609
2024-05-25 01:46:19 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1603
2024-05-25 01:46:22 [INFO]: Epoch 086 - training loss: 0.2904, validation loss: 0.1599
2024-05-25 01:46:25 [INFO]: Epoch 087 - training loss: 0.2892, validation loss: 0.1589
2024-05-25 01:46:28 [INFO]: Epoch 088 - training loss: 0.2887, validation loss: 0.1587
2024-05-25 01:46:31 [INFO]: Epoch 089 - training loss: 0.2878, validation loss: 0.1581
2024-05-25 01:46:34 [INFO]: Epoch 090 - training loss: 0.2868, validation loss: 0.1574
2024-05-25 01:46:37 [INFO]: Epoch 091 - training loss: 0.2866, validation loss: 0.1569
2024-05-25 01:46:40 [INFO]: Epoch 092 - training loss: 0.2856, validation loss: 0.1564
2024-05-25 01:46:43 [INFO]: Epoch 093 - training loss: 0.2851, validation loss: 0.1558
2024-05-25 01:46:46 [INFO]: Epoch 094 - training loss: 0.2841, validation loss: 0.1554
2024-05-25 01:46:49 [INFO]: Epoch 095 - training loss: 0.2835, validation loss: 0.1547
2024-05-25 01:46:52 [INFO]: Epoch 096 - training loss: 0.2821, validation loss: 0.1542
2024-05-25 01:46:55 [INFO]: Epoch 097 - training loss: 0.2815, validation loss: 0.1538
2024-05-25 01:46:58 [INFO]: Epoch 098 - training loss: 0.2814, validation loss: 0.1535
2024-05-25 01:47:00 [INFO]: Epoch 099 - training loss: 0.2801, validation loss: 0.1529
2024-05-25 01:47:03 [INFO]: Epoch 100 - training loss: 0.2796, validation loss: 0.1526
2024-05-25 01:47:06 [INFO]: Epoch 101 - training loss: 0.2794, validation loss: 0.1520
2024-05-25 01:47:09 [INFO]: Epoch 102 - training loss: 0.2786, validation loss: 0.1515
2024-05-25 01:47:12 [INFO]: Epoch 103 - training loss: 0.2786, validation loss: 0.1511
2024-05-25 01:47:15 [INFO]: Epoch 104 - training loss: 0.2772, validation loss: 0.1506
2024-05-25 01:47:18 [INFO]: Epoch 105 - training loss: 0.2771, validation loss: 0.1503
2024-05-25 01:47:21 [INFO]: Epoch 106 - training loss: 0.2759, validation loss: 0.1498
2024-05-25 01:47:24 [INFO]: Epoch 107 - training loss: 0.2755, validation loss: 0.1495
2024-05-25 01:47:27 [INFO]: Epoch 108 - training loss: 0.2754, validation loss: 0.1490
2024-05-25 01:47:30 [INFO]: Epoch 109 - training loss: 0.2741, validation loss: 0.1488
2024-05-25 01:47:33 [INFO]: Epoch 110 - training loss: 0.2738, validation loss: 0.1483
2024-05-25 01:47:35 [INFO]: Epoch 111 - training loss: 0.2734, validation loss: 0.1479
2024-05-25 01:47:38 [INFO]: Epoch 112 - training loss: 0.2732, validation loss: 0.1476
2024-05-25 01:47:41 [INFO]: Epoch 113 - training loss: 0.2724, validation loss: 0.1473
2024-05-25 01:47:44 [INFO]: Epoch 114 - training loss: 0.2719, validation loss: 0.1469
2024-05-25 01:47:47 [INFO]: Epoch 115 - training loss: 0.2716, validation loss: 0.1465
2024-05-25 01:47:50 [INFO]: Epoch 116 - training loss: 0.2706, validation loss: 0.1460
2024-05-25 01:47:53 [INFO]: Epoch 117 - training loss: 0.2703, validation loss: 0.1458
2024-05-25 01:47:56 [INFO]: Epoch 118 - training loss: 0.2698, validation loss: 0.1454
2024-05-25 01:47:59 [INFO]: Epoch 119 - training loss: 0.2689, validation loss: 0.1453
2024-05-25 01:48:02 [INFO]: Epoch 120 - training loss: 0.2689, validation loss: 0.1448
2024-05-25 01:48:05 [INFO]: Epoch 121 - training loss: 0.2682, validation loss: 0.1444
2024-05-25 01:48:08 [INFO]: Epoch 122 - training loss: 0.2683, validation loss: 0.1443
2024-05-25 01:48:11 [INFO]: Epoch 123 - training loss: 0.2686, validation loss: 0.1439
2024-05-25 01:48:14 [INFO]: Epoch 124 - training loss: 0.2667, validation loss: 0.1435
2024-05-25 01:48:17 [INFO]: Epoch 125 - training loss: 0.2665, validation loss: 0.1432
2024-05-25 01:48:19 [INFO]: Epoch 126 - training loss: 0.2663, validation loss: 0.1429
2024-05-25 01:48:22 [INFO]: Epoch 127 - training loss: 0.2662, validation loss: 0.1426
2024-05-25 01:48:25 [INFO]: Epoch 128 - training loss: 0.2655, validation loss: 0.1422
2024-05-25 01:48:28 [INFO]: Epoch 129 - training loss: 0.2650, validation loss: 0.1419
2024-05-25 01:48:31 [INFO]: Epoch 130 - training loss: 0.2639, validation loss: 0.1416
2024-05-25 01:48:34 [INFO]: Epoch 131 - training loss: 0.2638, validation loss: 0.1413
2024-05-25 01:48:37 [INFO]: Epoch 132 - training loss: 0.2635, validation loss: 0.1410
2024-05-25 01:48:40 [INFO]: Epoch 133 - training loss: 0.2630, validation loss: 0.1409
2024-05-25 01:48:43 [INFO]: Epoch 134 - training loss: 0.2623, validation loss: 0.1405
2024-05-25 01:48:46 [INFO]: Epoch 135 - training loss: 0.2619, validation loss: 0.1403
2024-05-25 01:48:49 [INFO]: Epoch 136 - training loss: 0.2621, validation loss: 0.1398
2024-05-25 01:48:52 [INFO]: Epoch 137 - training loss: 0.2619, validation loss: 0.1397
2024-05-25 01:48:55 [INFO]: Epoch 138 - training loss: 0.2607, validation loss: 0.1395
2024-05-25 01:48:58 [INFO]: Epoch 139 - training loss: 0.2610, validation loss: 0.1392
2024-05-25 01:49:00 [INFO]: Epoch 140 - training loss: 0.2601, validation loss: 0.1392
2024-05-25 01:49:03 [INFO]: Epoch 141 - training loss: 0.2596, validation loss: 0.1387
2024-05-25 01:49:06 [INFO]: Epoch 142 - training loss: 0.2598, validation loss: 0.1387
2024-05-25 01:49:09 [INFO]: Epoch 143 - training loss: 0.2595, validation loss: 0.1383
2024-05-25 01:49:12 [INFO]: Epoch 144 - training loss: 0.2589, validation loss: 0.1379
2024-05-25 01:49:15 [INFO]: Epoch 145 - training loss: 0.2589, validation loss: 0.1377
2024-05-25 01:49:18 [INFO]: Epoch 146 - training loss: 0.2586, validation loss: 0.1375
2024-05-25 01:49:21 [INFO]: Epoch 147 - training loss: 0.2580, validation loss: 0.1374
2024-05-25 01:49:24 [INFO]: Epoch 148 - training loss: 0.2574, validation loss: 0.1372
2024-05-25 01:49:27 [INFO]: Epoch 149 - training loss: 0.2573, validation loss: 0.1369
2024-05-25 01:49:30 [INFO]: Epoch 150 - training loss: 0.2563, validation loss: 0.1364
2024-05-25 01:49:33 [INFO]: Epoch 151 - training loss: 0.2565, validation loss: 0.1365
2024-05-25 01:49:36 [INFO]: Epoch 152 - training loss: 0.2567, validation loss: 0.1363
2024-05-25 01:49:38 [INFO]: Epoch 153 - training loss: 0.2553, validation loss: 0.1361
2024-05-25 01:49:41 [INFO]: Epoch 154 - training loss: 0.2554, validation loss: 0.1358
2024-05-25 01:49:44 [INFO]: Epoch 155 - training loss: 0.2552, validation loss: 0.1357
2024-05-25 01:49:47 [INFO]: Epoch 156 - training loss: 0.2552, validation loss: 0.1354
2024-05-25 01:49:50 [INFO]: Epoch 157 - training loss: 0.2550, validation loss: 0.1352
2024-05-25 01:49:53 [INFO]: Epoch 158 - training loss: 0.2539, validation loss: 0.1348
2024-05-25 01:49:56 [INFO]: Epoch 159 - training loss: 0.2543, validation loss: 0.1349
2024-05-25 01:49:59 [INFO]: Epoch 160 - training loss: 0.2539, validation loss: 0.1346
2024-05-25 01:50:02 [INFO]: Epoch 161 - training loss: 0.2532, validation loss: 0.1345
2024-05-25 01:50:05 [INFO]: Epoch 162 - training loss: 0.2533, validation loss: 0.1342
2024-05-25 01:50:08 [INFO]: Epoch 163 - training loss: 0.2528, validation loss: 0.1341
2024-05-25 01:50:11 [INFO]: Epoch 164 - training loss: 0.2525, validation loss: 0.1340
2024-05-25 01:50:14 [INFO]: Epoch 165 - training loss: 0.2524, validation loss: 0.1338
2024-05-25 01:50:17 [INFO]: Epoch 166 - training loss: 0.2523, validation loss: 0.1337
2024-05-25 01:50:20 [INFO]: Epoch 167 - training loss: 0.2516, validation loss: 0.1333
2024-05-25 01:50:23 [INFO]: Epoch 168 - training loss: 0.2513, validation loss: 0.1333
2024-05-25 01:50:25 [INFO]: Epoch 169 - training loss: 0.2508, validation loss: 0.1331
2024-05-25 01:50:28 [INFO]: Epoch 170 - training loss: 0.2515, validation loss: 0.1329
2024-05-25 01:50:31 [INFO]: Epoch 171 - training loss: 0.2508, validation loss: 0.1327
2024-05-25 01:50:34 [INFO]: Epoch 172 - training loss: 0.2502, validation loss: 0.1325
2024-05-25 01:50:37 [INFO]: Epoch 173 - training loss: 0.2503, validation loss: 0.1326
2024-05-25 01:50:40 [INFO]: Epoch 174 - training loss: 0.2500, validation loss: 0.1324
2024-05-25 01:50:43 [INFO]: Epoch 175 - training loss: 0.2494, validation loss: 0.1322
2024-05-25 01:50:46 [INFO]: Epoch 176 - training loss: 0.2494, validation loss: 0.1323
2024-05-25 01:50:49 [INFO]: Epoch 177 - training loss: 0.2484, validation loss: 0.1320
2024-05-25 01:50:52 [INFO]: Epoch 178 - training loss: 0.2486, validation loss: 0.1318
2024-05-25 01:50:55 [INFO]: Epoch 179 - training loss: 0.2486, validation loss: 0.1317
2024-05-25 01:50:58 [INFO]: Epoch 180 - training loss: 0.2482, validation loss: 0.1316
2024-05-25 01:51:01 [INFO]: Epoch 181 - training loss: 0.2481, validation loss: 0.1315
2024-05-25 01:51:03 [INFO]: Epoch 182 - training loss: 0.2478, validation loss: 0.1311
2024-05-25 01:51:06 [INFO]: Epoch 183 - training loss: 0.2475, validation loss: 0.1310
2024-05-25 01:51:09 [INFO]: Epoch 184 - training loss: 0.2474, validation loss: 0.1308
2024-05-25 01:51:12 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1311
2024-05-25 01:51:15 [INFO]: Epoch 186 - training loss: 0.2473, validation loss: 0.1306
2024-05-25 01:51:18 [INFO]: Epoch 187 - training loss: 0.2472, validation loss: 0.1307
2024-05-25 01:51:21 [INFO]: Epoch 188 - training loss: 0.2463, validation loss: 0.1304
2024-05-25 01:51:24 [INFO]: Epoch 189 - training loss: 0.2466, validation loss: 0.1304
2024-05-25 01:51:27 [INFO]: Epoch 190 - training loss: 0.2460, validation loss: 0.1301
2024-05-25 01:51:30 [INFO]: Epoch 191 - training loss: 0.2458, validation loss: 0.1299
2024-05-25 01:51:33 [INFO]: Epoch 192 - training loss: 0.2454, validation loss: 0.1300
2024-05-25 01:51:36 [INFO]: Epoch 193 - training loss: 0.2456, validation loss: 0.1300
2024-05-25 01:51:39 [INFO]: Epoch 194 - training loss: 0.2450, validation loss: 0.1297
2024-05-25 01:51:42 [INFO]: Epoch 195 - training loss: 0.2450, validation loss: 0.1296
2024-05-25 01:51:45 [INFO]: Epoch 196 - training loss: 0.2447, validation loss: 0.1294
2024-05-25 01:51:47 [INFO]: Epoch 197 - training loss: 0.2445, validation loss: 0.1294
2024-05-25 01:51:50 [INFO]: Epoch 198 - training loss: 0.2441, validation loss: 0.1294
2024-05-25 01:51:53 [INFO]: Epoch 199 - training loss: 0.2446, validation loss: 0.1290
2024-05-25 01:51:56 [INFO]: Epoch 200 - training loss: 0.2436, validation loss: 0.1292
2024-05-25 01:51:59 [INFO]: Epoch 201 - training loss: 0.2437, validation loss: 0.1290
2024-05-25 01:52:02 [INFO]: Epoch 202 - training loss: 0.2432, validation loss: 0.1289
2024-05-25 01:52:05 [INFO]: Epoch 203 - training loss: 0.2433, validation loss: 0.1288
2024-05-25 01:52:08 [INFO]: Epoch 204 - training loss: 0.2431, validation loss: 0.1285
2024-05-25 01:52:11 [INFO]: Epoch 205 - training loss: 0.2427, validation loss: 0.1284
2024-05-25 01:52:14 [INFO]: Epoch 206 - training loss: 0.2429, validation loss: 0.1285
2024-05-25 01:52:17 [INFO]: Epoch 207 - training loss: 0.2425, validation loss: 0.1283
2024-05-25 01:52:20 [INFO]: Epoch 208 - training loss: 0.2422, validation loss: 0.1283
2024-05-25 01:52:23 [INFO]: Epoch 209 - training loss: 0.2424, validation loss: 0.1281
2024-05-25 01:52:26 [INFO]: Epoch 210 - training loss: 0.2419, validation loss: 0.1279
2024-05-25 01:52:28 [INFO]: Epoch 211 - training loss: 0.2421, validation loss: 0.1281
2024-05-25 01:52:31 [INFO]: Epoch 212 - training loss: 0.2418, validation loss: 0.1279
2024-05-25 01:52:34 [INFO]: Epoch 213 - training loss: 0.2416, validation loss: 0.1279
2024-05-25 01:52:37 [INFO]: Epoch 214 - training loss: 0.2416, validation loss: 0.1278
2024-05-25 01:52:40 [INFO]: Epoch 215 - training loss: 0.2412, validation loss: 0.1278
2024-05-25 01:52:43 [INFO]: Epoch 216 - training loss: 0.2412, validation loss: 0.1275
2024-05-25 01:52:46 [INFO]: Epoch 217 - training loss: 0.2407, validation loss: 0.1274
2024-05-25 01:52:49 [INFO]: Epoch 218 - training loss: 0.2405, validation loss: 0.1272
2024-05-25 01:52:52 [INFO]: Epoch 219 - training loss: 0.2405, validation loss: 0.1273
2024-05-25 01:52:55 [INFO]: Epoch 220 - training loss: 0.2404, validation loss: 0.1272
2024-05-25 01:52:58 [INFO]: Epoch 221 - training loss: 0.2404, validation loss: 0.1271
2024-05-25 01:53:01 [INFO]: Epoch 222 - training loss: 0.2397, validation loss: 0.1271
2024-05-25 01:53:04 [INFO]: Epoch 223 - training loss: 0.2398, validation loss: 0.1272
2024-05-25 01:53:07 [INFO]: Epoch 224 - training loss: 0.2403, validation loss: 0.1268
2024-05-25 01:53:10 [INFO]: Epoch 225 - training loss: 0.2395, validation loss: 0.1268
2024-05-25 01:53:13 [INFO]: Epoch 226 - training loss: 0.2394, validation loss: 0.1267
2024-05-25 01:53:15 [INFO]: Epoch 227 - training loss: 0.2390, validation loss: 0.1266
2024-05-25 01:53:18 [INFO]: Epoch 228 - training loss: 0.2388, validation loss: 0.1266
2024-05-25 01:53:21 [INFO]: Epoch 229 - training loss: 0.2389, validation loss: 0.1267
2024-05-25 01:53:24 [INFO]: Epoch 230 - training loss: 0.2389, validation loss: 0.1265
2024-05-25 01:53:27 [INFO]: Epoch 231 - training loss: 0.2389, validation loss: 0.1264
2024-05-25 01:53:30 [INFO]: Epoch 232 - training loss: 0.2386, validation loss: 0.1264
2024-05-25 01:53:33 [INFO]: Epoch 233 - training loss: 0.2381, validation loss: 0.1263
2024-05-25 01:53:36 [INFO]: Epoch 234 - training loss: 0.2379, validation loss: 0.1263
2024-05-25 01:53:39 [INFO]: Epoch 235 - training loss: 0.2380, validation loss: 0.1259
2024-05-25 01:53:42 [INFO]: Epoch 236 - training loss: 0.2383, validation loss: 0.1264
2024-05-25 01:53:45 [INFO]: Epoch 237 - training loss: 0.2374, validation loss: 0.1260
2024-05-25 01:53:48 [INFO]: Epoch 238 - training loss: 0.2377, validation loss: 0.1259
2024-05-25 01:53:51 [INFO]: Epoch 239 - training loss: 0.2368, validation loss: 0.1257
2024-05-25 01:53:53 [INFO]: Epoch 240 - training loss: 0.2371, validation loss: 0.1257
2024-05-25 01:53:56 [INFO]: Epoch 241 - training loss: 0.2365, validation loss: 0.1255
2024-05-25 01:53:59 [INFO]: Epoch 242 - training loss: 0.2368, validation loss: 0.1255
2024-05-25 01:54:02 [INFO]: Epoch 243 - training loss: 0.2360, validation loss: 0.1256
2024-05-25 01:54:05 [INFO]: Epoch 244 - training loss: 0.2363, validation loss: 0.1258
2024-05-25 01:54:08 [INFO]: Epoch 245 - training loss: 0.2359, validation loss: 0.1256
2024-05-25 01:54:11 [INFO]: Epoch 246 - training loss: 0.2359, validation loss: 0.1255
2024-05-25 01:54:14 [INFO]: Epoch 247 - training loss: 0.2360, validation loss: 0.1255
2024-05-25 01:54:17 [INFO]: Epoch 248 - training loss: 0.2361, validation loss: 0.1254
2024-05-25 01:54:20 [INFO]: Epoch 249 - training loss: 0.2359, validation loss: 0.1250
2024-05-25 01:54:23 [INFO]: Epoch 250 - training loss: 0.2359, validation loss: 0.1253
2024-05-25 01:54:26 [INFO]: Epoch 251 - training loss: 0.2355, validation loss: 0.1252
2024-05-25 01:54:29 [INFO]: Epoch 252 - training loss: 0.2350, validation loss: 0.1252
2024-05-25 01:54:32 [INFO]: Epoch 253 - training loss: 0.2352, validation loss: 0.1251
2024-05-25 01:54:34 [INFO]: Epoch 254 - training loss: 0.2353, validation loss: 0.1252
2024-05-25 01:54:37 [INFO]: Epoch 255 - training loss: 0.2345, validation loss: 0.1250
2024-05-25 01:54:40 [INFO]: Epoch 256 - training loss: 0.2348, validation loss: 0.1249
2024-05-25 01:54:43 [INFO]: Epoch 257 - training loss: 0.2342, validation loss: 0.1250
2024-05-25 01:54:46 [INFO]: Epoch 258 - training loss: 0.2347, validation loss: 0.1248
2024-05-25 01:54:49 [INFO]: Epoch 259 - training loss: 0.2342, validation loss: 0.1247
2024-05-25 01:54:52 [INFO]: Epoch 260 - training loss: 0.2342, validation loss: 0.1249
2024-05-25 01:54:55 [INFO]: Epoch 261 - training loss: 0.2339, validation loss: 0.1246
2024-05-25 01:54:57 [INFO]: Epoch 262 - training loss: 0.2336, validation loss: 0.1247
2024-05-25 01:55:00 [INFO]: Epoch 263 - training loss: 0.2337, validation loss: 0.1247
2024-05-25 01:55:03 [INFO]: Epoch 264 - training loss: 0.2340, validation loss: 0.1247
2024-05-25 01:55:06 [INFO]: Epoch 265 - training loss: 0.2335, validation loss: 0.1246
2024-05-25 01:55:09 [INFO]: Epoch 266 - training loss: 0.2331, validation loss: 0.1246
2024-05-25 01:55:12 [INFO]: Epoch 267 - training loss: 0.2335, validation loss: 0.1244
2024-05-25 01:55:15 [INFO]: Epoch 268 - training loss: 0.2331, validation loss: 0.1244
2024-05-25 01:55:18 [INFO]: Epoch 269 - training loss: 0.2328, validation loss: 0.1242
2024-05-25 01:55:21 [INFO]: Epoch 270 - training loss: 0.2327, validation loss: 0.1243
2024-05-25 01:55:24 [INFO]: Epoch 271 - training loss: 0.2320, validation loss: 0.1242
2024-05-25 01:55:27 [INFO]: Epoch 272 - training loss: 0.2327, validation loss: 0.1242
2024-05-25 01:55:30 [INFO]: Epoch 273 - training loss: 0.2337, validation loss: 0.1244
2024-05-25 01:55:33 [INFO]: Epoch 274 - training loss: 0.2326, validation loss: 0.1243
2024-05-25 01:55:36 [INFO]: Epoch 275 - training loss: 0.2318, validation loss: 0.1240
2024-05-25 01:55:38 [INFO]: Epoch 276 - training loss: 0.2326, validation loss: 0.1240
2024-05-25 01:55:41 [INFO]: Epoch 277 - training loss: 0.2324, validation loss: 0.1240
2024-05-25 01:55:44 [INFO]: Epoch 278 - training loss: 0.2316, validation loss: 0.1242
2024-05-25 01:55:47 [INFO]: Epoch 279 - training loss: 0.2321, validation loss: 0.1241
2024-05-25 01:55:50 [INFO]: Epoch 280 - training loss: 0.2316, validation loss: 0.1238
2024-05-25 01:55:53 [INFO]: Epoch 281 - training loss: 0.2313, validation loss: 0.1240
2024-05-25 01:55:56 [INFO]: Epoch 282 - training loss: 0.2315, validation loss: 0.1237
2024-05-25 01:55:59 [INFO]: Epoch 283 - training loss: 0.2316, validation loss: 0.1238
2024-05-25 01:56:02 [INFO]: Epoch 284 - training loss: 0.2310, validation loss: 0.1238
2024-05-25 01:56:05 [INFO]: Epoch 285 - training loss: 0.2314, validation loss: 0.1239
2024-05-25 01:56:08 [INFO]: Epoch 286 - training loss: 0.2318, validation loss: 0.1236
2024-05-25 01:56:11 [INFO]: Epoch 287 - training loss: 0.2310, validation loss: 0.1235
2024-05-25 01:56:14 [INFO]: Epoch 288 - training loss: 0.2306, validation loss: 0.1237
2024-05-25 01:56:17 [INFO]: Epoch 289 - training loss: 0.2303, validation loss: 0.1237
2024-05-25 01:56:19 [INFO]: Epoch 290 - training loss: 0.2308, validation loss: 0.1235
2024-05-25 01:56:22 [INFO]: Epoch 291 - training loss: 0.2311, validation loss: 0.1234
2024-05-25 01:56:25 [INFO]: Epoch 292 - training loss: 0.2306, validation loss: 0.1237
2024-05-25 01:56:28 [INFO]: Epoch 293 - training loss: 0.2305, validation loss: 0.1234
2024-05-25 01:56:31 [INFO]: Epoch 294 - training loss: 0.2299, validation loss: 0.1234
2024-05-25 01:56:34 [INFO]: Epoch 295 - training loss: 0.2300, validation loss: 0.1235
2024-05-25 01:56:37 [INFO]: Epoch 296 - training loss: 0.2297, validation loss: 0.1237
2024-05-25 01:56:40 [INFO]: Epoch 297 - training loss: 0.2295, validation loss: 0.1236
2024-05-25 01:56:43 [INFO]: Epoch 298 - training loss: 0.2301, validation loss: 0.1234
2024-05-25 01:56:46 [INFO]: Epoch 299 - training loss: 0.2297, validation loss: 0.1233
2024-05-25 01:56:49 [INFO]: Epoch 300 - training loss: 0.2299, validation loss: 0.1234
2024-05-25 01:56:49 [INFO]: Finished training. The best model is from epoch#299.
2024-05-25 01:56:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/BRITS_air_quality/20240525_T014209/BRITS.pypots
2024-05-25 01:56:49 [INFO]: BRITS on Air-Quality: MAE=0.1533, MSE=0.1104
2024-05-25 01:56:49 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 01:56:49 [INFO]: Using the given device: cuda:0
2024-05-25 01:56:49 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649
2024-05-25 01:56:49 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/tensorboard
2024-05-25 01:56:49 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 01:56:54 [INFO]: Epoch 001 - training loss: 1.3450, validation loss: 0.7993
2024-05-25 01:56:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch1_loss0.7993260025978088.pypots
2024-05-25 01:56:58 [INFO]: Epoch 002 - training loss: 1.0500, validation loss: 0.7474
2024-05-25 01:56:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch2_loss0.747395595908165.pypots
2024-05-25 01:57:02 [INFO]: Epoch 003 - training loss: 0.9803, validation loss: 0.7226
2024-05-25 01:57:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch3_loss0.722607308626175.pypots
2024-05-25 01:57:06 [INFO]: Epoch 004 - training loss: 0.9615, validation loss: 0.7112
2024-05-25 01:57:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch4_loss0.7111722648143768.pypots
2024-05-25 01:57:10 [INFO]: Epoch 005 - training loss: 0.9430, validation loss: 0.7031
2024-05-25 01:57:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch5_loss0.7031474411487579.pypots
2024-05-25 01:57:14 [INFO]: Epoch 006 - training loss: 0.9310, validation loss: 0.6974
2024-05-25 01:57:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch6_loss0.6974342048168183.pypots
2024-05-25 01:57:18 [INFO]: Epoch 007 - training loss: 0.9540, validation loss: 0.6932
2024-05-25 01:57:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch7_loss0.6931914448738098.pypots
2024-05-25 01:57:22 [INFO]: Epoch 008 - training loss: 0.9714, validation loss: 0.6889
2024-05-25 01:57:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch8_loss0.688922968506813.pypots
2024-05-25 01:57:26 [INFO]: Epoch 009 - training loss: 0.9656, validation loss: 0.6872
2024-05-25 01:57:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch9_loss0.6872412234544754.pypots
2024-05-25 01:57:30 [INFO]: Epoch 010 - training loss: 0.9515, validation loss: 0.6842
2024-05-25 01:57:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch10_loss0.6842393994331359.pypots
2024-05-25 01:57:34 [INFO]: Epoch 011 - training loss: 0.9154, validation loss: 0.6829
2024-05-25 01:57:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch11_loss0.6829355448484421.pypots
2024-05-25 01:57:38 [INFO]: Epoch 012 - training loss: 0.9231, validation loss: 0.6836
2024-05-25 01:57:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch12_loss0.6836084216833115.pypots
2024-05-25 01:57:42 [INFO]: Epoch 013 - training loss: 0.9132, validation loss: 0.6815
2024-05-25 01:57:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch13_loss0.6815258502960205.pypots
2024-05-25 01:57:46 [INFO]: Epoch 014 - training loss: 0.9045, validation loss: 0.6810
2024-05-25 01:57:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch14_loss0.6810428738594055.pypots
2024-05-25 01:57:50 [INFO]: Epoch 015 - training loss: 0.9052, validation loss: 0.6815
2024-05-25 01:57:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch15_loss0.6814728617668152.pypots
2024-05-25 01:57:54 [INFO]: Epoch 016 - training loss: 0.8900, validation loss: 0.6804
2024-05-25 01:57:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch16_loss0.6803599059581756.pypots
2024-05-25 01:57:58 [INFO]: Epoch 017 - training loss: 0.8879, validation loss: 0.6791
2024-05-25 01:57:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch17_loss0.6790649682283402.pypots
2024-05-25 01:58:02 [INFO]: Epoch 018 - training loss: 0.9027, validation loss: 0.6815
2024-05-25 01:58:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch18_loss0.681521725654602.pypots
2024-05-25 01:58:06 [INFO]: Epoch 019 - training loss: 0.8867, validation loss: 0.6813
2024-05-25 01:58:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch19_loss0.681281128525734.pypots
2024-05-25 01:58:10 [INFO]: Epoch 020 - training loss: 0.9063, validation loss: 0.6825
2024-05-25 01:58:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch20_loss0.6825087755918503.pypots
2024-05-25 01:58:14 [INFO]: Epoch 021 - training loss: 0.9035, validation loss: 0.6808
2024-05-25 01:58:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch21_loss0.6807570964097976.pypots
2024-05-25 01:58:18 [INFO]: Epoch 022 - training loss: 0.8909, validation loss: 0.6823
2024-05-25 01:58:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch22_loss0.6822516232728958.pypots
2024-05-25 01:58:22 [INFO]: Epoch 023 - training loss: 0.8914, validation loss: 0.6851
2024-05-25 01:58:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch23_loss0.6850942939519882.pypots
2024-05-25 01:58:26 [INFO]: Epoch 024 - training loss: 0.8817, validation loss: 0.6840
2024-05-25 01:58:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch24_loss0.6840245604515076.pypots
2024-05-25 01:58:30 [INFO]: Epoch 025 - training loss: 0.8877, validation loss: 0.6867
2024-05-25 01:58:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch25_loss0.6867420464754105.pypots
2024-05-25 01:58:34 [INFO]: Epoch 026 - training loss: 0.8896, validation loss: 0.6871
2024-05-25 01:58:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch26_loss0.6870952010154724.pypots
2024-05-25 01:58:38 [INFO]: Epoch 027 - training loss: 0.8781, validation loss: 0.6877
2024-05-25 01:58:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN_epoch27_loss0.6877407133579254.pypots
2024-05-25 01:58:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:58:38 [INFO]: Finished training. The best model is from epoch#17.
2024-05-25 01:58:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_2/MRNN_air_quality/20240525_T015649/MRNN.pypots
2024-05-25 01:58:38 [INFO]: MRNN on Air-Quality: MAE=0.5264, MSE=0.6188
2024-05-25 01:58:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 01:58:38 [INFO]: Using the given device: cpu
2024-05-25 01:58:38 [INFO]: LOCF on Air-Quality: MAE=0.2195, MSE=0.2798
2024-05-25 01:58:38 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 01:58:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 01:58:38 [INFO]: Median on Air-Quality: MAE=0.6624, MSE=1.0025
2024-05-25 01:58:38 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 01:58:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 01:58:38 [INFO]: Mean on Air-Quality: MAE=0.6941, MSE=0.9443
2024-05-25 01:58:38 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 01:58:38 [INFO]: Successfully saved to overlay_postmask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 01:58:38 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 01:58:38 [INFO]: Using the given device: cuda:0
2024-05-25 01:58:38 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T015838
2024-05-25 01:58:38 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T015838/tensorboard
2024-05-25 01:58:39 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 01:58:39 [INFO]: Epoch 001 - training loss: 1.0581, validation loss: 0.5383
2024-05-25 01:58:40 [INFO]: Epoch 002 - training loss: 0.7659, validation loss: 0.4131
2024-05-25 01:58:41 [INFO]: Epoch 003 - training loss: 0.6562, validation loss: 0.3315
2024-05-25 01:58:41 [INFO]: Epoch 004 - training loss: 0.5811, validation loss: 0.2931
2024-05-25 01:58:42 [INFO]: Epoch 005 - training loss: 0.5251, validation loss: 0.2665
2024-05-25 01:58:43 [INFO]: Epoch 006 - training loss: 0.4870, validation loss: 0.2529
2024-05-25 01:58:43 [INFO]: Epoch 007 - training loss: 0.4609, validation loss: 0.2415
2024-05-25 01:58:44 [INFO]: Epoch 008 - training loss: 0.4427, validation loss: 0.2351
2024-05-25 01:58:45 [INFO]: Epoch 009 - training loss: 0.4277, validation loss: 0.2296
2024-05-25 01:58:46 [INFO]: Epoch 010 - training loss: 0.4169, validation loss: 0.2243
2024-05-25 01:58:46 [INFO]: Epoch 011 - training loss: 0.4063, validation loss: 0.2200
2024-05-25 01:58:47 [INFO]: Epoch 012 - training loss: 0.3972, validation loss: 0.2149
2024-05-25 01:58:48 [INFO]: Epoch 013 - training loss: 0.3888, validation loss: 0.2138
2024-05-25 01:58:48 [INFO]: Epoch 014 - training loss: 0.3837, validation loss: 0.2100
2024-05-25 01:58:49 [INFO]: Epoch 015 - training loss: 0.3769, validation loss: 0.2092
2024-05-25 01:58:50 [INFO]: Epoch 016 - training loss: 0.3714, validation loss: 0.2071
2024-05-25 01:58:50 [INFO]: Epoch 017 - training loss: 0.3659, validation loss: 0.2037
2024-05-25 01:58:51 [INFO]: Epoch 018 - training loss: 0.3608, validation loss: 0.2004
2024-05-25 01:58:52 [INFO]: Epoch 019 - training loss: 0.3571, validation loss: 0.1978
2024-05-25 01:58:52 [INFO]: Epoch 020 - training loss: 0.3527, validation loss: 0.1966
2024-05-25 01:58:53 [INFO]: Epoch 021 - training loss: 0.3471, validation loss: 0.1946
2024-05-25 01:58:54 [INFO]: Epoch 022 - training loss: 0.3453, validation loss: 0.1928
2024-05-25 01:58:54 [INFO]: Epoch 023 - training loss: 0.3424, validation loss: 0.1939
2024-05-25 01:58:55 [INFO]: Epoch 024 - training loss: 0.3394, validation loss: 0.1913
2024-05-25 01:58:56 [INFO]: Epoch 025 - training loss: 0.3368, validation loss: 0.1884
2024-05-25 01:58:57 [INFO]: Epoch 026 - training loss: 0.3322, validation loss: 0.1875
2024-05-25 01:58:57 [INFO]: Epoch 027 - training loss: 0.3302, validation loss: 0.1862
2024-05-25 01:58:58 [INFO]: Epoch 028 - training loss: 0.3279, validation loss: 0.1849
2024-05-25 01:58:59 [INFO]: Epoch 029 - training loss: 0.3269, validation loss: 0.1832
2024-05-25 01:58:59 [INFO]: Epoch 030 - training loss: 0.3236, validation loss: 0.1808
2024-05-25 01:59:00 [INFO]: Epoch 031 - training loss: 0.3215, validation loss: 0.1795
2024-05-25 01:59:01 [INFO]: Epoch 032 - training loss: 0.3223, validation loss: 0.1795
2024-05-25 01:59:01 [INFO]: Epoch 033 - training loss: 0.3180, validation loss: 0.1776
2024-05-25 01:59:02 [INFO]: Epoch 034 - training loss: 0.3156, validation loss: 0.1763
2024-05-25 01:59:03 [INFO]: Epoch 035 - training loss: 0.3136, validation loss: 0.1748
2024-05-25 01:59:03 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1732
2024-05-25 01:59:04 [INFO]: Epoch 037 - training loss: 0.3111, validation loss: 0.1711
2024-05-25 01:59:05 [INFO]: Epoch 038 - training loss: 0.3082, validation loss: 0.1712
2024-05-25 01:59:05 [INFO]: Epoch 039 - training loss: 0.3080, validation loss: 0.1692
2024-05-25 01:59:06 [INFO]: Epoch 040 - training loss: 0.3068, validation loss: 0.1678
2024-05-25 01:59:07 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1678
2024-05-25 01:59:08 [INFO]: Epoch 042 - training loss: 0.3023, validation loss: 0.1662
2024-05-25 01:59:08 [INFO]: Epoch 043 - training loss: 0.3011, validation loss: 0.1652
2024-05-25 01:59:09 [INFO]: Epoch 044 - training loss: 0.2989, validation loss: 0.1635
2024-05-25 01:59:10 [INFO]: Epoch 045 - training loss: 0.2970, validation loss: 0.1630
2024-05-25 01:59:10 [INFO]: Epoch 046 - training loss: 0.2965, validation loss: 0.1626
2024-05-25 01:59:11 [INFO]: Epoch 047 - training loss: 0.2948, validation loss: 0.1612
2024-05-25 01:59:12 [INFO]: Epoch 048 - training loss: 0.2932, validation loss: 0.1602
2024-05-25 01:59:12 [INFO]: Epoch 049 - training loss: 0.2919, validation loss: 0.1592
2024-05-25 01:59:13 [INFO]: Epoch 050 - training loss: 0.2913, validation loss: 0.1586
2024-05-25 01:59:14 [INFO]: Epoch 051 - training loss: 0.2896, validation loss: 0.1593
2024-05-25 01:59:14 [INFO]: Epoch 052 - training loss: 0.2874, validation loss: 0.1565
2024-05-25 01:59:15 [INFO]: Epoch 053 - training loss: 0.2869, validation loss: 0.1570
2024-05-25 01:59:16 [INFO]: Epoch 054 - training loss: 0.2864, validation loss: 0.1564
2024-05-25 01:59:16 [INFO]: Epoch 055 - training loss: 0.2857, validation loss: 0.1556
2024-05-25 01:59:17 [INFO]: Epoch 056 - training loss: 0.2834, validation loss: 0.1540
2024-05-25 01:59:18 [INFO]: Epoch 057 - training loss: 0.2809, validation loss: 0.1533
2024-05-25 01:59:19 [INFO]: Epoch 058 - training loss: 0.2803, validation loss: 0.1543
2024-05-25 01:59:19 [INFO]: Epoch 059 - training loss: 0.2798, validation loss: 0.1533
2024-05-25 01:59:20 [INFO]: Epoch 060 - training loss: 0.2790, validation loss: 0.1530
2024-05-25 01:59:21 [INFO]: Epoch 061 - training loss: 0.2776, validation loss: 0.1526
2024-05-25 01:59:21 [INFO]: Epoch 062 - training loss: 0.2767, validation loss: 0.1519
2024-05-25 01:59:22 [INFO]: Epoch 063 - training loss: 0.2773, validation loss: 0.1511
2024-05-25 01:59:23 [INFO]: Epoch 064 - training loss: 0.2752, validation loss: 0.1517
2024-05-25 01:59:24 [INFO]: Epoch 065 - training loss: 0.2743, validation loss: 0.1502
2024-05-25 01:59:24 [INFO]: Epoch 066 - training loss: 0.2718, validation loss: 0.1504
2024-05-25 01:59:25 [INFO]: Epoch 067 - training loss: 0.2700, validation loss: 0.1506
2024-05-25 01:59:26 [INFO]: Epoch 068 - training loss: 0.2696, validation loss: 0.1501
2024-05-25 01:59:26 [INFO]: Epoch 069 - training loss: 0.2690, validation loss: 0.1482
2024-05-25 01:59:27 [INFO]: Epoch 070 - training loss: 0.2688, validation loss: 0.1485
2024-05-25 01:59:28 [INFO]: Epoch 071 - training loss: 0.2663, validation loss: 0.1487
2024-05-25 01:59:28 [INFO]: Epoch 072 - training loss: 0.2647, validation loss: 0.1489
2024-05-25 01:59:29 [INFO]: Epoch 073 - training loss: 0.2648, validation loss: 0.1474
2024-05-25 01:59:30 [INFO]: Epoch 074 - training loss: 0.2642, validation loss: 0.1482
2024-05-25 01:59:30 [INFO]: Epoch 075 - training loss: 0.2643, validation loss: 0.1473
2024-05-25 01:59:31 [INFO]: Epoch 076 - training loss: 0.2632, validation loss: 0.1477
2024-05-25 01:59:32 [INFO]: Epoch 077 - training loss: 0.2623, validation loss: 0.1464
2024-05-25 01:59:32 [INFO]: Epoch 078 - training loss: 0.2622, validation loss: 0.1465
2024-05-25 01:59:33 [INFO]: Epoch 079 - training loss: 0.2613, validation loss: 0.1465
2024-05-25 01:59:34 [INFO]: Epoch 080 - training loss: 0.2599, validation loss: 0.1453
2024-05-25 01:59:34 [INFO]: Epoch 081 - training loss: 0.2586, validation loss: 0.1466
2024-05-25 01:59:35 [INFO]: Epoch 082 - training loss: 0.2578, validation loss: 0.1443
2024-05-25 01:59:36 [INFO]: Epoch 083 - training loss: 0.2577, validation loss: 0.1445
2024-05-25 01:59:37 [INFO]: Epoch 084 - training loss: 0.2559, validation loss: 0.1447
2024-05-25 01:59:37 [INFO]: Epoch 085 - training loss: 0.2556, validation loss: 0.1438
2024-05-25 01:59:38 [INFO]: Epoch 086 - training loss: 0.2547, validation loss: 0.1435
2024-05-25 01:59:39 [INFO]: Epoch 087 - training loss: 0.2541, validation loss: 0.1439
2024-05-25 01:59:39 [INFO]: Epoch 088 - training loss: 0.2544, validation loss: 0.1436
2024-05-25 01:59:40 [INFO]: Epoch 089 - training loss: 0.2524, validation loss: 0.1437
2024-05-25 01:59:41 [INFO]: Epoch 090 - training loss: 0.2514, validation loss: 0.1431
2024-05-25 01:59:41 [INFO]: Epoch 091 - training loss: 0.2517, validation loss: 0.1428
2024-05-25 01:59:42 [INFO]: Epoch 092 - training loss: 0.2498, validation loss: 0.1415
2024-05-25 01:59:43 [INFO]: Epoch 093 - training loss: 0.2496, validation loss: 0.1416
2024-05-25 01:59:43 [INFO]: Epoch 094 - training loss: 0.2490, validation loss: 0.1417
2024-05-25 01:59:44 [INFO]: Epoch 095 - training loss: 0.2486, validation loss: 0.1407
2024-05-25 01:59:45 [INFO]: Epoch 096 - training loss: 0.2481, validation loss: 0.1417
2024-05-25 01:59:45 [INFO]: Epoch 097 - training loss: 0.2492, validation loss: 0.1418
2024-05-25 01:59:46 [INFO]: Epoch 098 - training loss: 0.2497, validation loss: 0.1402
2024-05-25 01:59:47 [INFO]: Epoch 099 - training loss: 0.2462, validation loss: 0.1404
2024-05-25 01:59:48 [INFO]: Epoch 100 - training loss: 0.2448, validation loss: 0.1402
2024-05-25 01:59:48 [INFO]: Epoch 101 - training loss: 0.2454, validation loss: 0.1406
2024-05-25 01:59:49 [INFO]: Epoch 102 - training loss: 0.2443, validation loss: 0.1402
2024-05-25 01:59:50 [INFO]: Epoch 103 - training loss: 0.2437, validation loss: 0.1392
2024-05-25 01:59:50 [INFO]: Epoch 104 - training loss: 0.2432, validation loss: 0.1385
2024-05-25 01:59:51 [INFO]: Epoch 105 - training loss: 0.2429, validation loss: 0.1389
2024-05-25 01:59:52 [INFO]: Epoch 106 - training loss: 0.2430, validation loss: 0.1383
2024-05-25 01:59:52 [INFO]: Epoch 107 - training loss: 0.2430, validation loss: 0.1386
2024-05-25 01:59:53 [INFO]: Epoch 108 - training loss: 0.2458, validation loss: 0.1386
2024-05-25 01:59:54 [INFO]: Epoch 109 - training loss: 0.2415, validation loss: 0.1381
2024-05-25 01:59:54 [INFO]: Epoch 110 - training loss: 0.2437, validation loss: 0.1381
2024-05-25 01:59:55 [INFO]: Epoch 111 - training loss: 0.2404, validation loss: 0.1374
2024-05-25 01:59:56 [INFO]: Epoch 112 - training loss: 0.2382, validation loss: 0.1377
2024-05-25 01:59:56 [INFO]: Epoch 113 - training loss: 0.2407, validation loss: 0.1365
2024-05-25 01:59:57 [INFO]: Epoch 114 - training loss: 0.2383, validation loss: 0.1360
2024-05-25 01:59:58 [INFO]: Epoch 115 - training loss: 0.2384, validation loss: 0.1364
2024-05-25 01:59:58 [INFO]: Epoch 116 - training loss: 0.2383, validation loss: 0.1354
2024-05-25 01:59:59 [INFO]: Epoch 117 - training loss: 0.2398, validation loss: 0.1365
2024-05-25 02:00:00 [INFO]: Epoch 118 - training loss: 0.2380, validation loss: 0.1352
2024-05-25 02:00:01 [INFO]: Epoch 119 - training loss: 0.2366, validation loss: 0.1352
2024-05-25 02:00:01 [INFO]: Epoch 120 - training loss: 0.2358, validation loss: 0.1359
2024-05-25 02:00:02 [INFO]: Epoch 121 - training loss: 0.2358, validation loss: 0.1355
2024-05-25 02:00:03 [INFO]: Epoch 122 - training loss: 0.2340, validation loss: 0.1344
2024-05-25 02:00:03 [INFO]: Epoch 123 - training loss: 0.2345, validation loss: 0.1343
2024-05-25 02:00:04 [INFO]: Epoch 124 - training loss: 0.2336, validation loss: 0.1348
2024-05-25 02:00:05 [INFO]: Epoch 125 - training loss: 0.2339, validation loss: 0.1349
2024-05-25 02:00:05 [INFO]: Epoch 126 - training loss: 0.2329, validation loss: 0.1349
2024-05-25 02:00:06 [INFO]: Epoch 127 - training loss: 0.2338, validation loss: 0.1348
2024-05-25 02:00:07 [INFO]: Epoch 128 - training loss: 0.2339, validation loss: 0.1339
2024-05-25 02:00:07 [INFO]: Epoch 129 - training loss: 0.2318, validation loss: 0.1335
2024-05-25 02:00:08 [INFO]: Epoch 130 - training loss: 0.2305, validation loss: 0.1336
2024-05-25 02:00:09 [INFO]: Epoch 131 - training loss: 0.2310, validation loss: 0.1328
2024-05-25 02:00:09 [INFO]: Epoch 132 - training loss: 0.2303, validation loss: 0.1326
2024-05-25 02:00:10 [INFO]: Epoch 133 - training loss: 0.2295, validation loss: 0.1318
2024-05-25 02:00:11 [INFO]: Epoch 134 - training loss: 0.2306, validation loss: 0.1319
2024-05-25 02:00:12 [INFO]: Epoch 135 - training loss: 0.2296, validation loss: 0.1318
2024-05-25 02:00:12 [INFO]: Epoch 136 - training loss: 0.2286, validation loss: 0.1325
2024-05-25 02:00:13 [INFO]: Epoch 137 - training loss: 0.2277, validation loss: 0.1317
2024-05-25 02:00:14 [INFO]: Epoch 138 - training loss: 0.2286, validation loss: 0.1317
2024-05-25 02:00:14 [INFO]: Epoch 139 - training loss: 0.2281, validation loss: 0.1320
2024-05-25 02:00:15 [INFO]: Epoch 140 - training loss: 0.2268, validation loss: 0.1329
2024-05-25 02:00:16 [INFO]: Epoch 141 - training loss: 0.2287, validation loss: 0.1320
2024-05-25 02:00:16 [INFO]: Epoch 142 - training loss: 0.2293, validation loss: 0.1321
2024-05-25 02:00:17 [INFO]: Epoch 143 - training loss: 0.2273, validation loss: 0.1306
2024-05-25 02:00:18 [INFO]: Epoch 144 - training loss: 0.2264, validation loss: 0.1311
2024-05-25 02:00:18 [INFO]: Epoch 145 - training loss: 0.2261, validation loss: 0.1318
2024-05-25 02:00:19 [INFO]: Epoch 146 - training loss: 0.2251, validation loss: 0.1318
2024-05-25 02:00:20 [INFO]: Epoch 147 - training loss: 0.2251, validation loss: 0.1317
2024-05-25 02:00:20 [INFO]: Epoch 148 - training loss: 0.2252, validation loss: 0.1301
2024-05-25 02:00:21 [INFO]: Epoch 149 - training loss: 0.2239, validation loss: 0.1311
2024-05-25 02:00:22 [INFO]: Epoch 150 - training loss: 0.2239, validation loss: 0.1292
2024-05-25 02:00:23 [INFO]: Epoch 151 - training loss: 0.2231, validation loss: 0.1298
2024-05-25 02:00:23 [INFO]: Epoch 152 - training loss: 0.2238, validation loss: 0.1309
2024-05-25 02:00:24 [INFO]: Epoch 153 - training loss: 0.2231, validation loss: 0.1296
2024-05-25 02:00:25 [INFO]: Epoch 154 - training loss: 0.2222, validation loss: 0.1292
2024-05-25 02:00:25 [INFO]: Epoch 155 - training loss: 0.2226, validation loss: 0.1295
2024-05-25 02:00:26 [INFO]: Epoch 156 - training loss: 0.2233, validation loss: 0.1298
2024-05-25 02:00:27 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1286
2024-05-25 02:00:27 [INFO]: Epoch 158 - training loss: 0.2210, validation loss: 0.1286
2024-05-25 02:00:28 [INFO]: Epoch 159 - training loss: 0.2199, validation loss: 0.1285
2024-05-25 02:00:29 [INFO]: Epoch 160 - training loss: 0.2199, validation loss: 0.1288
2024-05-25 02:00:29 [INFO]: Epoch 161 - training loss: 0.2184, validation loss: 0.1280
2024-05-25 02:00:30 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1274
2024-05-25 02:00:31 [INFO]: Epoch 163 - training loss: 0.2192, validation loss: 0.1276
2024-05-25 02:00:31 [INFO]: Epoch 164 - training loss: 0.2183, validation loss: 0.1271
2024-05-25 02:00:32 [INFO]: Epoch 165 - training loss: 0.2191, validation loss: 0.1268
2024-05-25 02:00:33 [INFO]: Epoch 166 - training loss: 0.2186, validation loss: 0.1270
2024-05-25 02:00:34 [INFO]: Epoch 167 - training loss: 0.2187, validation loss: 0.1279
2024-05-25 02:00:34 [INFO]: Epoch 168 - training loss: 0.2189, validation loss: 0.1278
2024-05-25 02:00:35 [INFO]: Epoch 169 - training loss: 0.2199, validation loss: 0.1276
2024-05-25 02:00:36 [INFO]: Epoch 170 - training loss: 0.2197, validation loss: 0.1287
2024-05-25 02:00:36 [INFO]: Epoch 171 - training loss: 0.2192, validation loss: 0.1259
2024-05-25 02:00:37 [INFO]: Epoch 172 - training loss: 0.2170, validation loss: 0.1269
2024-05-25 02:00:38 [INFO]: Epoch 173 - training loss: 0.2166, validation loss: 0.1255
2024-05-25 02:00:38 [INFO]: Epoch 174 - training loss: 0.2158, validation loss: 0.1254
2024-05-25 02:00:39 [INFO]: Epoch 175 - training loss: 0.2165, validation loss: 0.1251
2024-05-25 02:00:40 [INFO]: Epoch 176 - training loss: 0.2151, validation loss: 0.1263
2024-05-25 02:00:40 [INFO]: Epoch 177 - training loss: 0.2152, validation loss: 0.1272
2024-05-25 02:00:41 [INFO]: Epoch 178 - training loss: 0.2144, validation loss: 0.1262
2024-05-25 02:00:42 [INFO]: Epoch 179 - training loss: 0.2138, validation loss: 0.1255
2024-05-25 02:00:42 [INFO]: Epoch 180 - training loss: 0.2133, validation loss: 0.1248
2024-05-25 02:00:43 [INFO]: Epoch 181 - training loss: 0.2127, validation loss: 0.1249
2024-05-25 02:00:44 [INFO]: Epoch 182 - training loss: 0.2139, validation loss: 0.1261
2024-05-25 02:00:44 [INFO]: Epoch 183 - training loss: 0.2137, validation loss: 0.1251
2024-05-25 02:00:45 [INFO]: Epoch 184 - training loss: 0.2129, validation loss: 0.1251
2024-05-25 02:00:46 [INFO]: Epoch 185 - training loss: 0.2127, validation loss: 0.1253
2024-05-25 02:00:47 [INFO]: Epoch 186 - training loss: 0.2124, validation loss: 0.1256
2024-05-25 02:00:47 [INFO]: Epoch 187 - training loss: 0.2135, validation loss: 0.1251
2024-05-25 02:00:48 [INFO]: Epoch 188 - training loss: 0.2121, validation loss: 0.1268
2024-05-25 02:00:49 [INFO]: Epoch 189 - training loss: 0.2123, validation loss: 0.1235
2024-05-25 02:00:49 [INFO]: Epoch 190 - training loss: 0.2118, validation loss: 0.1240
2024-05-25 02:00:50 [INFO]: Epoch 191 - training loss: 0.2109, validation loss: 0.1245
2024-05-25 02:00:51 [INFO]: Epoch 192 - training loss: 0.2110, validation loss: 0.1261
2024-05-25 02:00:51 [INFO]: Epoch 193 - training loss: 0.2114, validation loss: 0.1242
2024-05-25 02:00:52 [INFO]: Epoch 194 - training loss: 0.2116, validation loss: 0.1238
2024-05-25 02:00:53 [INFO]: Epoch 195 - training loss: 0.2112, validation loss: 0.1240
2024-05-25 02:00:53 [INFO]: Epoch 196 - training loss: 0.2101, validation loss: 0.1237
2024-05-25 02:00:54 [INFO]: Epoch 197 - training loss: 0.2093, validation loss: 0.1237
2024-05-25 02:00:55 [INFO]: Epoch 198 - training loss: 0.2091, validation loss: 0.1242
2024-05-25 02:00:56 [INFO]: Epoch 199 - training loss: 0.2087, validation loss: 0.1239
2024-05-25 02:00:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:00:56 [INFO]: Finished training. The best model is from epoch#189.
2024-05-25 02:00:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/SAITS_air_quality/20240525_T015838/SAITS.pypots
2024-05-25 02:00:56 [INFO]: SAITS on Air-Quality: MAE=0.1532, MSE=0.1144
2024-05-25 02:00:56 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 02:00:56 [INFO]: Using the given device: cuda:0
2024-05-25 02:00:56 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T020056
2024-05-25 02:00:56 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T020056/tensorboard
2024-05-25 02:00:56 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 02:00:56 [INFO]: Epoch 001 - training loss: 0.9132, validation loss: 0.4850
2024-05-25 02:00:57 [INFO]: Epoch 002 - training loss: 0.5785, validation loss: 0.3648
2024-05-25 02:00:57 [INFO]: Epoch 003 - training loss: 0.4876, validation loss: 0.3044
2024-05-25 02:00:57 [INFO]: Epoch 004 - training loss: 0.4394, validation loss: 0.2769
2024-05-25 02:00:58 [INFO]: Epoch 005 - training loss: 0.4127, validation loss: 0.2606
2024-05-25 02:00:58 [INFO]: Epoch 006 - training loss: 0.3935, validation loss: 0.2496
2024-05-25 02:00:58 [INFO]: Epoch 007 - training loss: 0.3798, validation loss: 0.2428
2024-05-25 02:00:59 [INFO]: Epoch 008 - training loss: 0.3659, validation loss: 0.2368
2024-05-25 02:00:59 [INFO]: Epoch 009 - training loss: 0.3550, validation loss: 0.2332
2024-05-25 02:00:59 [INFO]: Epoch 010 - training loss: 0.3492, validation loss: 0.2268
2024-05-25 02:01:00 [INFO]: Epoch 011 - training loss: 0.3419, validation loss: 0.2234
2024-05-25 02:01:00 [INFO]: Epoch 012 - training loss: 0.3373, validation loss: 0.2201
2024-05-25 02:01:00 [INFO]: Epoch 013 - training loss: 0.3320, validation loss: 0.2160
2024-05-25 02:01:01 [INFO]: Epoch 014 - training loss: 0.3312, validation loss: 0.2116
2024-05-25 02:01:01 [INFO]: Epoch 015 - training loss: 0.3251, validation loss: 0.2109
2024-05-25 02:01:01 [INFO]: Epoch 016 - training loss: 0.3189, validation loss: 0.2077
2024-05-25 02:01:02 [INFO]: Epoch 017 - training loss: 0.3155, validation loss: 0.2060
2024-05-25 02:01:02 [INFO]: Epoch 018 - training loss: 0.3111, validation loss: 0.2005
2024-05-25 02:01:02 [INFO]: Epoch 019 - training loss: 0.3094, validation loss: 0.1992
2024-05-25 02:01:03 [INFO]: Epoch 020 - training loss: 0.3078, validation loss: 0.1947
2024-05-25 02:01:03 [INFO]: Epoch 021 - training loss: 0.3064, validation loss: 0.1964
2024-05-25 02:01:03 [INFO]: Epoch 022 - training loss: 0.3032, validation loss: 0.1928
2024-05-25 02:01:04 [INFO]: Epoch 023 - training loss: 0.3017, validation loss: 0.1921
2024-05-25 02:01:04 [INFO]: Epoch 024 - training loss: 0.2998, validation loss: 0.1915
2024-05-25 02:01:04 [INFO]: Epoch 025 - training loss: 0.2967, validation loss: 0.1878
2024-05-25 02:01:04 [INFO]: Epoch 026 - training loss: 0.2935, validation loss: 0.1900
2024-05-25 02:01:05 [INFO]: Epoch 027 - training loss: 0.2943, validation loss: 0.1878
2024-05-25 02:01:05 [INFO]: Epoch 028 - training loss: 0.2903, validation loss: 0.1869
2024-05-25 02:01:05 [INFO]: Epoch 029 - training loss: 0.2874, validation loss: 0.1860
2024-05-25 02:01:06 [INFO]: Epoch 030 - training loss: 0.2877, validation loss: 0.1832
2024-05-25 02:01:06 [INFO]: Epoch 031 - training loss: 0.2850, validation loss: 0.1836
2024-05-25 02:01:06 [INFO]: Epoch 032 - training loss: 0.2841, validation loss: 0.1851
2024-05-25 02:01:07 [INFO]: Epoch 033 - training loss: 0.2847, validation loss: 0.1820
2024-05-25 02:01:07 [INFO]: Epoch 034 - training loss: 0.2820, validation loss: 0.1813
2024-05-25 02:01:07 [INFO]: Epoch 035 - training loss: 0.2839, validation loss: 0.1845
2024-05-25 02:01:08 [INFO]: Epoch 036 - training loss: 0.2789, validation loss: 0.1812
2024-05-25 02:01:08 [INFO]: Epoch 037 - training loss: 0.2789, validation loss: 0.1831
2024-05-25 02:01:08 [INFO]: Epoch 038 - training loss: 0.2779, validation loss: 0.1804
2024-05-25 02:01:09 [INFO]: Epoch 039 - training loss: 0.2753, validation loss: 0.1797
2024-05-25 02:01:09 [INFO]: Epoch 040 - training loss: 0.2728, validation loss: 0.1801
2024-05-25 02:01:09 [INFO]: Epoch 041 - training loss: 0.2734, validation loss: 0.1815
2024-05-25 02:01:10 [INFO]: Epoch 042 - training loss: 0.2721, validation loss: 0.1776
2024-05-25 02:01:10 [INFO]: Epoch 043 - training loss: 0.2695, validation loss: 0.1782
2024-05-25 02:01:10 [INFO]: Epoch 044 - training loss: 0.2704, validation loss: 0.1789
2024-05-25 02:01:11 [INFO]: Epoch 045 - training loss: 0.2748, validation loss: 0.1758
2024-05-25 02:01:11 [INFO]: Epoch 046 - training loss: 0.2707, validation loss: 0.1745
2024-05-25 02:01:11 [INFO]: Epoch 047 - training loss: 0.2674, validation loss: 0.1774
2024-05-25 02:01:12 [INFO]: Epoch 048 - training loss: 0.2642, validation loss: 0.1764
2024-05-25 02:01:12 [INFO]: Epoch 049 - training loss: 0.2654, validation loss: 0.1740
2024-05-25 02:01:12 [INFO]: Epoch 050 - training loss: 0.2654, validation loss: 0.1760
2024-05-25 02:01:13 [INFO]: Epoch 051 - training loss: 0.2644, validation loss: 0.1739
2024-05-25 02:01:13 [INFO]: Epoch 052 - training loss: 0.2621, validation loss: 0.1753
2024-05-25 02:01:13 [INFO]: Epoch 053 - training loss: 0.2598, validation loss: 0.1740
2024-05-25 02:01:14 [INFO]: Epoch 054 - training loss: 0.2610, validation loss: 0.1745
2024-05-25 02:01:14 [INFO]: Epoch 055 - training loss: 0.2597, validation loss: 0.1724
2024-05-25 02:01:14 [INFO]: Epoch 056 - training loss: 0.2611, validation loss: 0.1741
2024-05-25 02:01:15 [INFO]: Epoch 057 - training loss: 0.2586, validation loss: 0.1720
2024-05-25 02:01:15 [INFO]: Epoch 058 - training loss: 0.2607, validation loss: 0.1725
2024-05-25 02:01:15 [INFO]: Epoch 059 - training loss: 0.2561, validation loss: 0.1707
2024-05-25 02:01:15 [INFO]: Epoch 060 - training loss: 0.2531, validation loss: 0.1706
2024-05-25 02:01:16 [INFO]: Epoch 061 - training loss: 0.2532, validation loss: 0.1704
2024-05-25 02:01:16 [INFO]: Epoch 062 - training loss: 0.2528, validation loss: 0.1689
2024-05-25 02:01:16 [INFO]: Epoch 063 - training loss: 0.2536, validation loss: 0.1709
2024-05-25 02:01:17 [INFO]: Epoch 064 - training loss: 0.2522, validation loss: 0.1690
2024-05-25 02:01:17 [INFO]: Epoch 065 - training loss: 0.2507, validation loss: 0.1686
2024-05-25 02:01:17 [INFO]: Epoch 066 - training loss: 0.2509, validation loss: 0.1677
2024-05-25 02:01:18 [INFO]: Epoch 067 - training loss: 0.2506, validation loss: 0.1697
2024-05-25 02:01:18 [INFO]: Epoch 068 - training loss: 0.2496, validation loss: 0.1723
2024-05-25 02:01:18 [INFO]: Epoch 069 - training loss: 0.2532, validation loss: 0.1654
2024-05-25 02:01:19 [INFO]: Epoch 070 - training loss: 0.2496, validation loss: 0.1680
2024-05-25 02:01:19 [INFO]: Epoch 071 - training loss: 0.2453, validation loss: 0.1675
2024-05-25 02:01:19 [INFO]: Epoch 072 - training loss: 0.2458, validation loss: 0.1663
2024-05-25 02:01:20 [INFO]: Epoch 073 - training loss: 0.2442, validation loss: 0.1683
2024-05-25 02:01:20 [INFO]: Epoch 074 - training loss: 0.2441, validation loss: 0.1671
2024-05-25 02:01:20 [INFO]: Epoch 075 - training loss: 0.2431, validation loss: 0.1653
2024-05-25 02:01:21 [INFO]: Epoch 076 - training loss: 0.2415, validation loss: 0.1654
2024-05-25 02:01:21 [INFO]: Epoch 077 - training loss: 0.2420, validation loss: 0.1642
2024-05-25 02:01:21 [INFO]: Epoch 078 - training loss: 0.2414, validation loss: 0.1647
2024-05-25 02:01:22 [INFO]: Epoch 079 - training loss: 0.2399, validation loss: 0.1688
2024-05-25 02:01:22 [INFO]: Epoch 080 - training loss: 0.2411, validation loss: 0.1652
2024-05-25 02:01:22 [INFO]: Epoch 081 - training loss: 0.2406, validation loss: 0.1644
2024-05-25 02:01:23 [INFO]: Epoch 082 - training loss: 0.2398, validation loss: 0.1653
2024-05-25 02:01:23 [INFO]: Epoch 083 - training loss: 0.2400, validation loss: 0.1628
2024-05-25 02:01:23 [INFO]: Epoch 084 - training loss: 0.2401, validation loss: 0.1634
2024-05-25 02:01:24 [INFO]: Epoch 085 - training loss: 0.2385, validation loss: 0.1644
2024-05-25 02:01:24 [INFO]: Epoch 086 - training loss: 0.2384, validation loss: 0.1650
2024-05-25 02:01:24 [INFO]: Epoch 087 - training loss: 0.2371, validation loss: 0.1626
2024-05-25 02:01:24 [INFO]: Epoch 088 - training loss: 0.2353, validation loss: 0.1617
2024-05-25 02:01:25 [INFO]: Epoch 089 - training loss: 0.2357, validation loss: 0.1643
2024-05-25 02:01:25 [INFO]: Epoch 090 - training loss: 0.2354, validation loss: 0.1623
2024-05-25 02:01:25 [INFO]: Epoch 091 - training loss: 0.2333, validation loss: 0.1621
2024-05-25 02:01:26 [INFO]: Epoch 092 - training loss: 0.2339, validation loss: 0.1646
2024-05-25 02:01:26 [INFO]: Epoch 093 - training loss: 0.2345, validation loss: 0.1616
2024-05-25 02:01:26 [INFO]: Epoch 094 - training loss: 0.2335, validation loss: 0.1610
2024-05-25 02:01:27 [INFO]: Epoch 095 - training loss: 0.2383, validation loss: 0.1619
2024-05-25 02:01:27 [INFO]: Epoch 096 - training loss: 0.2332, validation loss: 0.1628
2024-05-25 02:01:27 [INFO]: Epoch 097 - training loss: 0.2299, validation loss: 0.1606
2024-05-25 02:01:28 [INFO]: Epoch 098 - training loss: 0.2287, validation loss: 0.1605
2024-05-25 02:01:28 [INFO]: Epoch 099 - training loss: 0.2306, validation loss: 0.1603
2024-05-25 02:01:28 [INFO]: Epoch 100 - training loss: 0.2309, validation loss: 0.1596
2024-05-25 02:01:29 [INFO]: Epoch 101 - training loss: 0.2298, validation loss: 0.1613
2024-05-25 02:01:29 [INFO]: Epoch 102 - training loss: 0.2311, validation loss: 0.1586
2024-05-25 02:01:29 [INFO]: Epoch 103 - training loss: 0.2293, validation loss: 0.1608
2024-05-25 02:01:30 [INFO]: Epoch 104 - training loss: 0.2276, validation loss: 0.1588
2024-05-25 02:01:30 [INFO]: Epoch 105 - training loss: 0.2263, validation loss: 0.1573
2024-05-25 02:01:30 [INFO]: Epoch 106 - training loss: 0.2261, validation loss: 0.1570
2024-05-25 02:01:31 [INFO]: Epoch 107 - training loss: 0.2265, validation loss: 0.1578
2024-05-25 02:01:31 [INFO]: Epoch 108 - training loss: 0.2232, validation loss: 0.1577
2024-05-25 02:01:31 [INFO]: Epoch 109 - training loss: 0.2245, validation loss: 0.1573
2024-05-25 02:01:32 [INFO]: Epoch 110 - training loss: 0.2247, validation loss: 0.1569
2024-05-25 02:01:32 [INFO]: Epoch 111 - training loss: 0.2235, validation loss: 0.1569
2024-05-25 02:01:32 [INFO]: Epoch 112 - training loss: 0.2267, validation loss: 0.1562
2024-05-25 02:01:33 [INFO]: Epoch 113 - training loss: 0.2249, validation loss: 0.1579
2024-05-25 02:01:33 [INFO]: Epoch 114 - training loss: 0.2221, validation loss: 0.1576
2024-05-25 02:01:33 [INFO]: Epoch 115 - training loss: 0.2245, validation loss: 0.1550
2024-05-25 02:01:34 [INFO]: Epoch 116 - training loss: 0.2239, validation loss: 0.1551
2024-05-25 02:01:34 [INFO]: Epoch 117 - training loss: 0.2226, validation loss: 0.1545
2024-05-25 02:01:34 [INFO]: Epoch 118 - training loss: 0.2210, validation loss: 0.1558
2024-05-25 02:01:35 [INFO]: Epoch 119 - training loss: 0.2226, validation loss: 0.1552
2024-05-25 02:01:35 [INFO]: Epoch 120 - training loss: 0.2210, validation loss: 0.1566
2024-05-25 02:01:35 [INFO]: Epoch 121 - training loss: 0.2189, validation loss: 0.1553
2024-05-25 02:01:36 [INFO]: Epoch 122 - training loss: 0.2196, validation loss: 0.1542
2024-05-25 02:01:36 [INFO]: Epoch 123 - training loss: 0.2179, validation loss: 0.1562
2024-05-25 02:01:36 [INFO]: Epoch 124 - training loss: 0.2181, validation loss: 0.1558
2024-05-25 02:01:36 [INFO]: Epoch 125 - training loss: 0.2172, validation loss: 0.1554
2024-05-25 02:01:37 [INFO]: Epoch 126 - training loss: 0.2183, validation loss: 0.1536
2024-05-25 02:01:37 [INFO]: Epoch 127 - training loss: 0.2167, validation loss: 0.1545
2024-05-25 02:01:37 [INFO]: Epoch 128 - training loss: 0.2200, validation loss: 0.1551
2024-05-25 02:01:38 [INFO]: Epoch 129 - training loss: 0.2204, validation loss: 0.1538
2024-05-25 02:01:38 [INFO]: Epoch 130 - training loss: 0.2197, validation loss: 0.1530
2024-05-25 02:01:38 [INFO]: Epoch 131 - training loss: 0.2161, validation loss: 0.1532
2024-05-25 02:01:39 [INFO]: Epoch 132 - training loss: 0.2171, validation loss: 0.1546
2024-05-25 02:01:39 [INFO]: Epoch 133 - training loss: 0.2182, validation loss: 0.1545
2024-05-25 02:01:39 [INFO]: Epoch 134 - training loss: 0.2164, validation loss: 0.1535
2024-05-25 02:01:40 [INFO]: Epoch 135 - training loss: 0.2127, validation loss: 0.1531
2024-05-25 02:01:40 [INFO]: Epoch 136 - training loss: 0.2151, validation loss: 0.1530
2024-05-25 02:01:40 [INFO]: Epoch 137 - training loss: 0.2128, validation loss: 0.1528
2024-05-25 02:01:41 [INFO]: Epoch 138 - training loss: 0.2126, validation loss: 0.1524
2024-05-25 02:01:41 [INFO]: Epoch 139 - training loss: 0.2121, validation loss: 0.1526
2024-05-25 02:01:41 [INFO]: Epoch 140 - training loss: 0.2122, validation loss: 0.1546
2024-05-25 02:01:42 [INFO]: Epoch 141 - training loss: 0.2144, validation loss: 0.1522
2024-05-25 02:01:42 [INFO]: Epoch 142 - training loss: 0.2132, validation loss: 0.1511
2024-05-25 02:01:42 [INFO]: Epoch 143 - training loss: 0.2127, validation loss: 0.1509
2024-05-25 02:01:43 [INFO]: Epoch 144 - training loss: 0.2101, validation loss: 0.1526
2024-05-25 02:01:43 [INFO]: Epoch 145 - training loss: 0.2096, validation loss: 0.1522
2024-05-25 02:01:43 [INFO]: Epoch 146 - training loss: 0.2097, validation loss: 0.1515
2024-05-25 02:01:44 [INFO]: Epoch 147 - training loss: 0.2100, validation loss: 0.1522
2024-05-25 02:01:44 [INFO]: Epoch 148 - training loss: 0.2103, validation loss: 0.1507
2024-05-25 02:01:44 [INFO]: Epoch 149 - training loss: 0.2082, validation loss: 0.1498
2024-05-25 02:01:45 [INFO]: Epoch 150 - training loss: 0.2077, validation loss: 0.1529
2024-05-25 02:01:45 [INFO]: Epoch 151 - training loss: 0.2086, validation loss: 0.1502
2024-05-25 02:01:45 [INFO]: Epoch 152 - training loss: 0.2071, validation loss: 0.1502
2024-05-25 02:01:46 [INFO]: Epoch 153 - training loss: 0.2072, validation loss: 0.1500
2024-05-25 02:01:46 [INFO]: Epoch 154 - training loss: 0.2074, validation loss: 0.1503
2024-05-25 02:01:46 [INFO]: Epoch 155 - training loss: 0.2081, validation loss: 0.1507
2024-05-25 02:01:47 [INFO]: Epoch 156 - training loss: 0.2071, validation loss: 0.1511
2024-05-25 02:01:47 [INFO]: Epoch 157 - training loss: 0.2068, validation loss: 0.1499
2024-05-25 02:01:47 [INFO]: Epoch 158 - training loss: 0.2078, validation loss: 0.1491
2024-05-25 02:01:48 [INFO]: Epoch 159 - training loss: 0.2085, validation loss: 0.1482
2024-05-25 02:01:48 [INFO]: Epoch 160 - training loss: 0.2085, validation loss: 0.1490
2024-05-25 02:01:48 [INFO]: Epoch 161 - training loss: 0.2073, validation loss: 0.1482
2024-05-25 02:01:49 [INFO]: Epoch 162 - training loss: 0.2051, validation loss: 0.1489
2024-05-25 02:01:49 [INFO]: Epoch 163 - training loss: 0.2051, validation loss: 0.1477
2024-05-25 02:01:49 [INFO]: Epoch 164 - training loss: 0.2041, validation loss: 0.1480
2024-05-25 02:01:50 [INFO]: Epoch 165 - training loss: 0.2045, validation loss: 0.1495
2024-05-25 02:01:50 [INFO]: Epoch 166 - training loss: 0.2043, validation loss: 0.1484
2024-05-25 02:01:50 [INFO]: Epoch 167 - training loss: 0.2050, validation loss: 0.1490
2024-05-25 02:01:50 [INFO]: Epoch 168 - training loss: 0.2044, validation loss: 0.1471
2024-05-25 02:01:51 [INFO]: Epoch 169 - training loss: 0.2047, validation loss: 0.1469
2024-05-25 02:01:51 [INFO]: Epoch 170 - training loss: 0.2031, validation loss: 0.1469
2024-05-25 02:01:51 [INFO]: Epoch 171 - training loss: 0.2028, validation loss: 0.1470
2024-05-25 02:01:52 [INFO]: Epoch 172 - training loss: 0.2033, validation loss: 0.1462
2024-05-25 02:01:52 [INFO]: Epoch 173 - training loss: 0.2045, validation loss: 0.1479
2024-05-25 02:01:52 [INFO]: Epoch 174 - training loss: 0.2037, validation loss: 0.1457
2024-05-25 02:01:53 [INFO]: Epoch 175 - training loss: 0.2068, validation loss: 0.1473
2024-05-25 02:01:53 [INFO]: Epoch 176 - training loss: 0.2022, validation loss: 0.1452
2024-05-25 02:01:53 [INFO]: Epoch 177 - training loss: 0.2046, validation loss: 0.1465
2024-05-25 02:01:54 [INFO]: Epoch 178 - training loss: 0.2035, validation loss: 0.1464
2024-05-25 02:01:54 [INFO]: Epoch 179 - training loss: 0.2048, validation loss: 0.1474
2024-05-25 02:01:54 [INFO]: Epoch 180 - training loss: 0.2018, validation loss: 0.1472
2024-05-25 02:01:55 [INFO]: Epoch 181 - training loss: 0.1998, validation loss: 0.1479
2024-05-25 02:01:55 [INFO]: Epoch 182 - training loss: 0.1999, validation loss: 0.1461
2024-05-25 02:01:55 [INFO]: Epoch 183 - training loss: 0.2022, validation loss: 0.1479
2024-05-25 02:01:56 [INFO]: Epoch 184 - training loss: 0.2026, validation loss: 0.1470
2024-05-25 02:01:56 [INFO]: Epoch 185 - training loss: 0.1986, validation loss: 0.1443
2024-05-25 02:01:56 [INFO]: Epoch 186 - training loss: 0.1986, validation loss: 0.1461
2024-05-25 02:01:57 [INFO]: Epoch 187 - training loss: 0.1991, validation loss: 0.1457
2024-05-25 02:01:57 [INFO]: Epoch 188 - training loss: 0.1977, validation loss: 0.1472
2024-05-25 02:01:57 [INFO]: Epoch 189 - training loss: 0.1966, validation loss: 0.1458
2024-05-25 02:01:58 [INFO]: Epoch 190 - training loss: 0.1976, validation loss: 0.1453
2024-05-25 02:01:58 [INFO]: Epoch 191 - training loss: 0.1975, validation loss: 0.1447
2024-05-25 02:01:58 [INFO]: Epoch 192 - training loss: 0.1991, validation loss: 0.1456
2024-05-25 02:01:59 [INFO]: Epoch 193 - training loss: 0.1997, validation loss: 0.1459
2024-05-25 02:01:59 [INFO]: Epoch 194 - training loss: 0.1996, validation loss: 0.1453
2024-05-25 02:01:59 [INFO]: Epoch 195 - training loss: 0.1967, validation loss: 0.1451
2024-05-25 02:01:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:01:59 [INFO]: Finished training. The best model is from epoch#185.
2024-05-25 02:01:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/Transformer_air_quality/20240525_T020056/Transformer.pypots
2024-05-25 02:01:59 [INFO]: Transformer on Air-Quality: MAE=0.1645, MSE=0.1289
2024-05-25 02:01:59 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 02:01:59 [INFO]: Using the given device: cuda:0
2024-05-25 02:01:59 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T020159
2024-05-25 02:01:59 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T020159/tensorboard
2024-05-25 02:02:00 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 02:02:00 [INFO]: Epoch 001 - training loss: 0.3003, validation loss: 0.2673
2024-05-25 02:02:01 [INFO]: Epoch 002 - training loss: 0.2183, validation loss: 0.2337
2024-05-25 02:02:01 [INFO]: Epoch 003 - training loss: 0.2025, validation loss: 0.2189
2024-05-25 02:02:02 [INFO]: Epoch 004 - training loss: 0.1942, validation loss: 0.2063
2024-05-25 02:02:02 [INFO]: Epoch 005 - training loss: 0.1786, validation loss: 0.1948
2024-05-25 02:02:03 [INFO]: Epoch 006 - training loss: 0.1554, validation loss: 0.1931
2024-05-25 02:02:04 [INFO]: Epoch 007 - training loss: 0.1466, validation loss: 0.1952
2024-05-25 02:02:04 [INFO]: Epoch 008 - training loss: 0.1506, validation loss: 0.1872
2024-05-25 02:02:05 [INFO]: Epoch 009 - training loss: 0.1708, validation loss: 0.1881
2024-05-25 02:02:05 [INFO]: Epoch 010 - training loss: 0.1401, validation loss: 0.1837
2024-05-25 02:02:06 [INFO]: Epoch 011 - training loss: 0.1344, validation loss: 0.1790
2024-05-25 02:02:06 [INFO]: Epoch 012 - training loss: 0.1355, validation loss: 0.1758
2024-05-25 02:02:07 [INFO]: Epoch 013 - training loss: 0.1320, validation loss: 0.1767
2024-05-25 02:02:07 [INFO]: Epoch 014 - training loss: 0.1108, validation loss: 0.1770
2024-05-25 02:02:08 [INFO]: Epoch 015 - training loss: 0.1739, validation loss: 0.1781
2024-05-25 02:02:08 [INFO]: Epoch 016 - training loss: 0.1288, validation loss: 0.1707
2024-05-25 02:02:09 [INFO]: Epoch 017 - training loss: 0.1362, validation loss: 0.1703
2024-05-25 02:02:09 [INFO]: Epoch 018 - training loss: 0.1292, validation loss: 0.1695
2024-05-25 02:02:10 [INFO]: Epoch 019 - training loss: 0.1354, validation loss: 0.1710
2024-05-25 02:02:10 [INFO]: Epoch 020 - training loss: 0.1203, validation loss: 0.1733
2024-05-25 02:02:11 [INFO]: Epoch 021 - training loss: 0.1309, validation loss: 0.1833
2024-05-25 02:02:11 [INFO]: Epoch 022 - training loss: 0.1249, validation loss: 0.1761
2024-05-25 02:02:12 [INFO]: Epoch 023 - training loss: 0.1040, validation loss: 0.1659
2024-05-25 02:02:12 [INFO]: Epoch 024 - training loss: 0.1132, validation loss: 0.1618
2024-05-25 02:02:13 [INFO]: Epoch 025 - training loss: 0.1368, validation loss: 0.1623
2024-05-25 02:02:14 [INFO]: Epoch 026 - training loss: 0.1235, validation loss: 0.1630
2024-05-25 02:02:14 [INFO]: Epoch 027 - training loss: 0.1210, validation loss: 0.1650
2024-05-25 02:02:15 [INFO]: Epoch 028 - training loss: 0.1102, validation loss: 0.1637
2024-05-25 02:02:15 [INFO]: Epoch 029 - training loss: 0.1118, validation loss: 0.1611
2024-05-25 02:02:16 [INFO]: Epoch 030 - training loss: 0.1231, validation loss: 0.1609
2024-05-25 02:02:16 [INFO]: Epoch 031 - training loss: 0.1133, validation loss: 0.1591
2024-05-25 02:02:17 [INFO]: Epoch 032 - training loss: 0.1045, validation loss: 0.1607
2024-05-25 02:02:17 [INFO]: Epoch 033 - training loss: 0.1203, validation loss: 0.1605
2024-05-25 02:02:18 [INFO]: Epoch 034 - training loss: 0.1142, validation loss: 0.1577
2024-05-25 02:02:18 [INFO]: Epoch 035 - training loss: 0.1092, validation loss: 0.1587
2024-05-25 02:02:19 [INFO]: Epoch 036 - training loss: 0.1104, validation loss: 0.1622
2024-05-25 02:02:19 [INFO]: Epoch 037 - training loss: 0.1172, validation loss: 0.1594
2024-05-25 02:02:20 [INFO]: Epoch 038 - training loss: 0.1190, validation loss: 0.1622
2024-05-25 02:02:20 [INFO]: Epoch 039 - training loss: 0.1089, validation loss: 0.1619
2024-05-25 02:02:21 [INFO]: Epoch 040 - training loss: 0.1064, validation loss: 0.1607
2024-05-25 02:02:21 [INFO]: Epoch 041 - training loss: 0.0941, validation loss: 0.1619
2024-05-25 02:02:22 [INFO]: Epoch 042 - training loss: 0.1110, validation loss: 0.1574
2024-05-25 02:02:22 [INFO]: Epoch 043 - training loss: 0.1179, validation loss: 0.1571
2024-05-25 02:02:23 [INFO]: Epoch 044 - training loss: 0.0988, validation loss: 0.1604
2024-05-25 02:02:23 [INFO]: Epoch 045 - training loss: 0.1152, validation loss: 0.1574
2024-05-25 02:02:24 [INFO]: Epoch 046 - training loss: 0.1181, validation loss: 0.1555
2024-05-25 02:02:24 [INFO]: Epoch 047 - training loss: 0.1002, validation loss: 0.1563
2024-05-25 02:02:25 [INFO]: Epoch 048 - training loss: 0.1066, validation loss: 0.1588
2024-05-25 02:02:26 [INFO]: Epoch 049 - training loss: 0.0946, validation loss: 0.1565
2024-05-25 02:02:26 [INFO]: Epoch 050 - training loss: 0.0987, validation loss: 0.1538
2024-05-25 02:02:27 [INFO]: Epoch 051 - training loss: 0.1057, validation loss: 0.1538
2024-05-25 02:02:27 [INFO]: Epoch 052 - training loss: 0.0935, validation loss: 0.1546
2024-05-25 02:02:28 [INFO]: Epoch 053 - training loss: 0.0952, validation loss: 0.1538
2024-05-25 02:02:28 [INFO]: Epoch 054 - training loss: 0.0980, validation loss: 0.1543
2024-05-25 02:02:29 [INFO]: Epoch 055 - training loss: 0.0931, validation loss: 0.1574
2024-05-25 02:02:29 [INFO]: Epoch 056 - training loss: 0.1032, validation loss: 0.1553
2024-05-25 02:02:30 [INFO]: Epoch 057 - training loss: 0.1008, validation loss: 0.1566
2024-05-25 02:02:30 [INFO]: Epoch 058 - training loss: 0.1020, validation loss: 0.1632
2024-05-25 02:02:31 [INFO]: Epoch 059 - training loss: 0.1166, validation loss: 0.1582
2024-05-25 02:02:31 [INFO]: Epoch 060 - training loss: 0.1137, validation loss: 0.1516
2024-05-25 02:02:32 [INFO]: Epoch 061 - training loss: 0.0971, validation loss: 0.1529
2024-05-25 02:02:32 [INFO]: Epoch 062 - training loss: 0.0912, validation loss: 0.1551
2024-05-25 02:02:33 [INFO]: Epoch 063 - training loss: 0.1043, validation loss: 0.1611
2024-05-25 02:02:34 [INFO]: Epoch 064 - training loss: 0.0912, validation loss: 0.1607
2024-05-25 02:02:34 [INFO]: Epoch 065 - training loss: 0.0962, validation loss: 0.1574
2024-05-25 02:02:35 [INFO]: Epoch 066 - training loss: 0.0928, validation loss: 0.1571
2024-05-25 02:02:35 [INFO]: Epoch 067 - training loss: 0.1140, validation loss: 0.1575
2024-05-25 02:02:36 [INFO]: Epoch 068 - training loss: 0.0967, validation loss: 0.1552
2024-05-25 02:02:36 [INFO]: Epoch 069 - training loss: 0.0954, validation loss: 0.1595
2024-05-25 02:02:37 [INFO]: Epoch 070 - training loss: 0.1037, validation loss: 0.1591
2024-05-25 02:02:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:02:37 [INFO]: Finished training. The best model is from epoch#60.
2024-05-25 02:02:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/TimesNet_air_quality/20240525_T020159/TimesNet.pypots
2024-05-25 02:02:37 [INFO]: TimesNet on Air-Quality: MAE=0.1641, MSE=0.1529
2024-05-25 02:02:37 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 02:02:37 [INFO]: Using the given device: cuda:0
2024-05-25 02:02:37 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237
2024-05-25 02:02:37 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/tensorboard
2024-05-25 02:02:37 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 02:02:54 [INFO]: Epoch 001 - training loss: 0.4939, validation loss: 0.3536
2024-05-25 02:02:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch1_loss0.35356742441654204.pypots
2024-05-25 02:03:11 [INFO]: Epoch 002 - training loss: 0.3021, validation loss: 0.2820
2024-05-25 02:03:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch2_loss0.2820043176412582.pypots
2024-05-25 02:03:28 [INFO]: Epoch 003 - training loss: 0.3058, validation loss: 0.2501
2024-05-25 02:03:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch3_loss0.2501389101147652.pypots
2024-05-25 02:03:45 [INFO]: Epoch 004 - training loss: 0.2395, validation loss: 0.2168
2024-05-25 02:03:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch4_loss0.2168051853775978.pypots
2024-05-25 02:04:01 [INFO]: Epoch 005 - training loss: 0.2118, validation loss: 0.1963
2024-05-25 02:04:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch5_loss0.19633710980415345.pypots
2024-05-25 02:04:18 [INFO]: Epoch 006 - training loss: 0.2100, validation loss: 0.1802
2024-05-25 02:04:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch6_loss0.1801997974514961.pypots
2024-05-25 02:04:35 [INFO]: Epoch 007 - training loss: 0.1898, validation loss: 0.1758
2024-05-25 02:04:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch7_loss0.17580899894237517.pypots
2024-05-25 02:04:52 [INFO]: Epoch 008 - training loss: 0.1831, validation loss: 0.1749
2024-05-25 02:04:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch8_loss0.17490060925483703.pypots
2024-05-25 02:05:09 [INFO]: Epoch 009 - training loss: 0.1845, validation loss: 0.1573
2024-05-25 02:05:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch9_loss0.15730858445167542.pypots
2024-05-25 02:05:26 [INFO]: Epoch 010 - training loss: 0.1847, validation loss: 0.1635
2024-05-25 02:05:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch10_loss0.1634877383708954.pypots
2024-05-25 02:05:43 [INFO]: Epoch 011 - training loss: 0.1768, validation loss: 0.1515
2024-05-25 02:05:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch11_loss0.15148182064294816.pypots
2024-05-25 02:06:00 [INFO]: Epoch 012 - training loss: 0.1574, validation loss: 0.1618
2024-05-25 02:06:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch12_loss0.16176340878009796.pypots
2024-05-25 02:06:17 [INFO]: Epoch 013 - training loss: 0.1698, validation loss: 0.1484
2024-05-25 02:06:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch13_loss0.14838583320379256.pypots
2024-05-25 02:06:33 [INFO]: Epoch 014 - training loss: 0.1717, validation loss: 0.1440
2024-05-25 02:06:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch14_loss0.14395554438233377.pypots
2024-05-25 02:06:50 [INFO]: Epoch 015 - training loss: 0.1632, validation loss: 0.1445
2024-05-25 02:06:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch15_loss0.14446968138217925.pypots
2024-05-25 02:07:07 [INFO]: Epoch 016 - training loss: 0.1622, validation loss: 0.1497
2024-05-25 02:07:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch16_loss0.14968533515930177.pypots
2024-05-25 02:07:24 [INFO]: Epoch 017 - training loss: 0.1721, validation loss: 0.1425
2024-05-25 02:07:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch17_loss0.14245202988386155.pypots
2024-05-25 02:07:41 [INFO]: Epoch 018 - training loss: 0.1593, validation loss: 0.1411
2024-05-25 02:07:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch18_loss0.1411141499876976.pypots
2024-05-25 02:07:58 [INFO]: Epoch 019 - training loss: 0.1685, validation loss: 0.1436
2024-05-25 02:07:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch19_loss0.143646764755249.pypots
2024-05-25 02:08:15 [INFO]: Epoch 020 - training loss: 0.1745, validation loss: 0.1412
2024-05-25 02:08:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch20_loss0.14120495840907096.pypots
2024-05-25 02:08:32 [INFO]: Epoch 021 - training loss: 0.1551, validation loss: 0.1387
2024-05-25 02:08:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch21_loss0.13868968486785888.pypots
2024-05-25 02:08:49 [INFO]: Epoch 022 - training loss: 0.1635, validation loss: 0.1397
2024-05-25 02:08:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch22_loss0.13973837420344354.pypots
2024-05-25 02:09:06 [INFO]: Epoch 023 - training loss: 0.1649, validation loss: 0.1354
2024-05-25 02:09:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch23_loss0.1353700801730156.pypots
2024-05-25 02:09:22 [INFO]: Epoch 024 - training loss: 0.1519, validation loss: 0.1378
2024-05-25 02:09:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch24_loss0.13779978677630425.pypots
2024-05-25 02:09:39 [INFO]: Epoch 025 - training loss: 0.1672, validation loss: 0.1373
2024-05-25 02:09:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch25_loss0.13730944842100143.pypots
2024-05-25 02:09:56 [INFO]: Epoch 026 - training loss: 0.1534, validation loss: 0.1345
2024-05-25 02:09:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch26_loss0.1344904713332653.pypots
2024-05-25 02:10:13 [INFO]: Epoch 027 - training loss: 0.1462, validation loss: 0.1321
2024-05-25 02:10:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch27_loss0.1321244329214096.pypots
2024-05-25 02:10:30 [INFO]: Epoch 028 - training loss: 0.1479, validation loss: 0.1319
2024-05-25 02:10:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch28_loss0.13186962977051736.pypots
2024-05-25 02:10:47 [INFO]: Epoch 029 - training loss: 0.1572, validation loss: 0.1295
2024-05-25 02:10:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch29_loss0.12954134568572045.pypots
2024-05-25 02:11:04 [INFO]: Epoch 030 - training loss: 0.1413, validation loss: 0.1307
2024-05-25 02:11:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch30_loss0.13072662129998208.pypots
2024-05-25 02:11:21 [INFO]: Epoch 031 - training loss: 0.1353, validation loss: 0.1290
2024-05-25 02:11:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch31_loss0.12899754494428634.pypots
2024-05-25 02:11:37 [INFO]: Epoch 032 - training loss: 0.1382, validation loss: 0.1292
2024-05-25 02:11:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch32_loss0.12919052317738533.pypots
2024-05-25 02:11:54 [INFO]: Epoch 033 - training loss: 0.1333, validation loss: 0.1274
2024-05-25 02:11:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch33_loss0.12739669755101204.pypots
2024-05-25 02:12:11 [INFO]: Epoch 034 - training loss: 0.1533, validation loss: 0.1291
2024-05-25 02:12:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch34_loss0.12914079204201698.pypots
2024-05-25 02:12:28 [INFO]: Epoch 035 - training loss: 0.1464, validation loss: 0.1264
2024-05-25 02:12:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch35_loss0.12642851695418358.pypots
2024-05-25 02:12:45 [INFO]: Epoch 036 - training loss: 0.1490, validation loss: 0.1299
2024-05-25 02:12:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch36_loss0.12986205220222474.pypots
2024-05-25 02:13:02 [INFO]: Epoch 037 - training loss: 0.1351, validation loss: 0.1321
2024-05-25 02:13:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch37_loss0.13212366700172423.pypots
2024-05-25 02:13:19 [INFO]: Epoch 038 - training loss: 0.1332, validation loss: 0.1306
2024-05-25 02:13:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch38_loss0.13055453225970268.pypots
2024-05-25 02:13:36 [INFO]: Epoch 039 - training loss: 0.1421, validation loss: 0.1245
2024-05-25 02:13:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch39_loss0.12448968216776848.pypots
2024-05-25 02:13:53 [INFO]: Epoch 040 - training loss: 0.1423, validation loss: 0.1220
2024-05-25 02:13:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch40_loss0.12203134819865227.pypots
2024-05-25 02:14:10 [INFO]: Epoch 041 - training loss: 0.1429, validation loss: 0.1209
2024-05-25 02:14:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch41_loss0.12092196643352508.pypots
2024-05-25 02:14:26 [INFO]: Epoch 042 - training loss: 0.1440, validation loss: 0.1212
2024-05-25 02:14:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch42_loss0.12124081924557686.pypots
2024-05-25 02:14:43 [INFO]: Epoch 043 - training loss: 0.1380, validation loss: 0.1221
2024-05-25 02:14:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch43_loss0.12210492938756942.pypots
2024-05-25 02:15:00 [INFO]: Epoch 044 - training loss: 0.1293, validation loss: 0.1212
2024-05-25 02:15:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch44_loss0.12121898457407951.pypots
2024-05-25 02:15:17 [INFO]: Epoch 045 - training loss: 0.1338, validation loss: 0.1220
2024-05-25 02:15:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch45_loss0.12196137905120849.pypots
2024-05-25 02:15:34 [INFO]: Epoch 046 - training loss: 0.1315, validation loss: 0.1197
2024-05-25 02:15:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch46_loss0.11970280483365059.pypots
2024-05-25 02:15:51 [INFO]: Epoch 047 - training loss: 0.1473, validation loss: 0.1193
2024-05-25 02:15:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch47_loss0.11929421424865723.pypots
2024-05-25 02:16:08 [INFO]: Epoch 048 - training loss: 0.1384, validation loss: 0.1229
2024-05-25 02:16:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch48_loss0.12285380437970161.pypots
2024-05-25 02:16:25 [INFO]: Epoch 049 - training loss: 0.1227, validation loss: 0.1173
2024-05-25 02:16:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch49_loss0.1173348106443882.pypots
2024-05-25 02:16:42 [INFO]: Epoch 050 - training loss: 0.1291, validation loss: 0.1192
2024-05-25 02:16:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch50_loss0.11915819495916366.pypots
2024-05-25 02:16:58 [INFO]: Epoch 051 - training loss: 0.1451, validation loss: 0.1223
2024-05-25 02:16:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch51_loss0.1223376102745533.pypots
2024-05-25 02:17:15 [INFO]: Epoch 052 - training loss: 0.1351, validation loss: 0.1185
2024-05-25 02:17:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch52_loss0.11846603080630302.pypots
2024-05-25 02:17:32 [INFO]: Epoch 053 - training loss: 0.1167, validation loss: 0.1195
2024-05-25 02:17:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch53_loss0.11947818845510483.pypots
2024-05-25 02:17:49 [INFO]: Epoch 054 - training loss: 0.1310, validation loss: 0.1157
2024-05-25 02:17:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch54_loss0.11570754498243332.pypots
2024-05-25 02:18:06 [INFO]: Epoch 055 - training loss: 0.1255, validation loss: 0.1176
2024-05-25 02:18:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch55_loss0.11757392659783364.pypots
2024-05-25 02:18:23 [INFO]: Epoch 056 - training loss: 0.1218, validation loss: 0.1221
2024-05-25 02:18:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch56_loss0.12207258567214012.pypots
2024-05-25 02:18:40 [INFO]: Epoch 057 - training loss: 0.1307, validation loss: 0.1165
2024-05-25 02:18:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch57_loss0.11654442623257637.pypots
2024-05-25 02:18:57 [INFO]: Epoch 058 - training loss: 0.1325, validation loss: 0.1175
2024-05-25 02:18:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch58_loss0.11750862896442413.pypots
2024-05-25 02:19:13 [INFO]: Epoch 059 - training loss: 0.1348, validation loss: 0.1168
2024-05-25 02:19:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch59_loss0.11683065518736839.pypots
2024-05-25 02:19:30 [INFO]: Epoch 060 - training loss: 0.1322, validation loss: 0.1123
2024-05-25 02:19:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch60_loss0.11227954030036927.pypots
2024-05-25 02:19:47 [INFO]: Epoch 061 - training loss: 0.1191, validation loss: 0.1133
2024-05-25 02:19:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch61_loss0.11334010437130929.pypots
2024-05-25 02:20:04 [INFO]: Epoch 062 - training loss: 0.1270, validation loss: 0.1155
2024-05-25 02:20:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch62_loss0.11554551124572754.pypots
2024-05-25 02:20:21 [INFO]: Epoch 063 - training loss: 0.1381, validation loss: 0.1128
2024-05-25 02:20:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch63_loss0.11275803223252297.pypots
2024-05-25 02:20:38 [INFO]: Epoch 064 - training loss: 0.1493, validation loss: 0.1139
2024-05-25 02:20:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch64_loss0.11390632912516593.pypots
2024-05-25 02:20:55 [INFO]: Epoch 065 - training loss: 0.1230, validation loss: 0.1121
2024-05-25 02:20:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch65_loss0.11214123144745827.pypots
2024-05-25 02:21:12 [INFO]: Epoch 066 - training loss: 0.1162, validation loss: 0.1113
2024-05-25 02:21:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch66_loss0.11129906252026558.pypots
2024-05-25 02:21:29 [INFO]: Epoch 067 - training loss: 0.1068, validation loss: 0.1176
2024-05-25 02:21:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch67_loss0.11763767451047898.pypots
2024-05-25 02:21:45 [INFO]: Epoch 068 - training loss: 0.1088, validation loss: 0.1100
2024-05-25 02:21:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch68_loss0.11004278808832169.pypots
2024-05-25 02:22:02 [INFO]: Epoch 069 - training loss: 0.1232, validation loss: 0.1123
2024-05-25 02:22:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch69_loss0.1122888445854187.pypots
2024-05-25 02:22:19 [INFO]: Epoch 070 - training loss: 0.1261, validation loss: 0.1138
2024-05-25 02:22:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch70_loss0.11384595856070519.pypots
2024-05-25 02:22:36 [INFO]: Epoch 071 - training loss: 0.1143, validation loss: 0.1124
2024-05-25 02:22:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch71_loss0.11242474541068077.pypots
2024-05-25 02:22:53 [INFO]: Epoch 072 - training loss: 0.1234, validation loss: 0.1105
2024-05-25 02:22:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch72_loss0.11051143035292625.pypots
2024-05-25 02:23:10 [INFO]: Epoch 073 - training loss: 0.1309, validation loss: 0.1147
2024-05-25 02:23:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch73_loss0.11473114266991616.pypots
2024-05-25 02:23:27 [INFO]: Epoch 074 - training loss: 0.1133, validation loss: 0.1087
2024-05-25 02:23:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch74_loss0.10867123827338218.pypots
2024-05-25 02:23:44 [INFO]: Epoch 075 - training loss: 0.1269, validation loss: 0.1085
2024-05-25 02:23:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch75_loss0.10849213749170303.pypots
2024-05-25 02:24:01 [INFO]: Epoch 076 - training loss: 0.1142, validation loss: 0.1104
2024-05-25 02:24:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch76_loss0.11037084832787514.pypots
2024-05-25 02:24:17 [INFO]: Epoch 077 - training loss: 0.1369, validation loss: 0.1113
2024-05-25 02:24:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch77_loss0.11129845678806305.pypots
2024-05-25 02:24:34 [INFO]: Epoch 078 - training loss: 0.1231, validation loss: 0.1101
2024-05-25 02:24:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch78_loss0.1101423218846321.pypots
2024-05-25 02:24:51 [INFO]: Epoch 079 - training loss: 0.1182, validation loss: 0.1078
2024-05-25 02:24:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch79_loss0.10776098519563675.pypots
2024-05-25 02:25:08 [INFO]: Epoch 080 - training loss: 0.1160, validation loss: 0.1106
2024-05-25 02:25:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch80_loss0.11056997105479241.pypots
2024-05-25 02:25:25 [INFO]: Epoch 081 - training loss: 0.1135, validation loss: 0.1074
2024-05-25 02:25:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch81_loss0.10743611678481102.pypots
2024-05-25 02:25:42 [INFO]: Epoch 082 - training loss: 0.1135, validation loss: 0.1087
2024-05-25 02:25:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch82_loss0.1086815856397152.pypots
2024-05-25 02:25:59 [INFO]: Epoch 083 - training loss: 0.1090, validation loss: 0.1080
2024-05-25 02:25:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch83_loss0.10796252563595772.pypots
2024-05-25 02:26:16 [INFO]: Epoch 084 - training loss: 0.1160, validation loss: 0.1073
2024-05-25 02:26:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch84_loss0.10734253898262977.pypots
2024-05-25 02:26:33 [INFO]: Epoch 085 - training loss: 0.1142, validation loss: 0.1066
2024-05-25 02:26:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch85_loss0.10658861398696899.pypots
2024-05-25 02:26:49 [INFO]: Epoch 086 - training loss: 0.1167, validation loss: 0.1086
2024-05-25 02:26:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch86_loss0.10864876061677933.pypots
2024-05-25 02:27:06 [INFO]: Epoch 087 - training loss: 0.1234, validation loss: 0.1082
2024-05-25 02:27:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch87_loss0.10824443846940994.pypots
2024-05-25 02:27:23 [INFO]: Epoch 088 - training loss: 0.1032, validation loss: 0.1072
2024-05-25 02:27:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch88_loss0.1071534015238285.pypots
2024-05-25 02:27:40 [INFO]: Epoch 089 - training loss: 0.1159, validation loss: 0.1076
2024-05-25 02:27:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch89_loss0.10761385411024094.pypots
2024-05-25 02:27:57 [INFO]: Epoch 090 - training loss: 0.1241, validation loss: 0.1101
2024-05-25 02:27:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch90_loss0.11007330119609833.pypots
2024-05-25 02:28:14 [INFO]: Epoch 091 - training loss: 0.1161, validation loss: 0.1056
2024-05-25 02:28:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch91_loss0.10561429262161255.pypots
2024-05-25 02:28:31 [INFO]: Epoch 092 - training loss: 0.1188, validation loss: 0.1072
2024-05-25 02:28:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch92_loss0.10721801817417145.pypots
2024-05-25 02:28:48 [INFO]: Epoch 093 - training loss: 0.1276, validation loss: 0.1064
2024-05-25 02:28:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch93_loss0.10637843757867813.pypots
2024-05-25 02:29:05 [INFO]: Epoch 094 - training loss: 0.1203, validation loss: 0.1070
2024-05-25 02:29:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch94_loss0.10698622688651085.pypots
2024-05-25 02:29:21 [INFO]: Epoch 095 - training loss: 0.1252, validation loss: 0.1132
2024-05-25 02:29:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch95_loss0.11316637769341469.pypots
2024-05-25 02:29:38 [INFO]: Epoch 096 - training loss: 0.1115, validation loss: 0.1045
2024-05-25 02:29:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch96_loss0.10447244867682456.pypots
2024-05-25 02:29:55 [INFO]: Epoch 097 - training loss: 0.1139, validation loss: 0.1053
2024-05-25 02:29:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch97_loss0.10529734939336777.pypots
2024-05-25 02:30:12 [INFO]: Epoch 098 - training loss: 0.1151, validation loss: 0.1078
2024-05-25 02:30:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch98_loss0.1077529326081276.pypots
2024-05-25 02:30:29 [INFO]: Epoch 099 - training loss: 0.1057, validation loss: 0.1057
2024-05-25 02:30:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch99_loss0.10565729960799217.pypots
2024-05-25 02:30:46 [INFO]: Epoch 100 - training loss: 0.1165, validation loss: 0.1053
2024-05-25 02:30:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch100_loss0.10534947142004966.pypots
2024-05-25 02:31:03 [INFO]: Epoch 101 - training loss: 0.1031, validation loss: 0.1057
2024-05-25 02:31:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch101_loss0.10566295236349106.pypots
2024-05-25 02:31:20 [INFO]: Epoch 102 - training loss: 0.1101, validation loss: 0.1054
2024-05-25 02:31:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch102_loss0.10544108971953392.pypots
2024-05-25 02:31:37 [INFO]: Epoch 103 - training loss: 0.1241, validation loss: 0.1124
2024-05-25 02:31:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch103_loss0.11235920339822769.pypots
2024-05-25 02:31:53 [INFO]: Epoch 104 - training loss: 0.1147, validation loss: 0.1088
2024-05-25 02:31:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch104_loss0.10875978693366051.pypots
2024-05-25 02:32:10 [INFO]: Epoch 105 - training loss: 0.1089, validation loss: 0.1072
2024-05-25 02:32:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch105_loss0.107233577221632.pypots
2024-05-25 02:32:27 [INFO]: Epoch 106 - training loss: 0.1095, validation loss: 0.1111
2024-05-25 02:32:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI_epoch106_loss0.1111013039946556.pypots
2024-05-25 02:32:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:32:27 [INFO]: Finished training. The best model is from epoch#96.
2024-05-25 02:32:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/CSDI_air_quality/20240525_T020237/CSDI.pypots
2024-05-25 02:34:48 [INFO]: CSDI on Air-Quality: MAE=0.1113, MSE=0.1328
2024-05-25 02:34:48 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 02:34:48 [INFO]: Using the given device: cuda:0
2024-05-25 02:34:48 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T023448
2024-05-25 02:34:48 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T023448/tensorboard
2024-05-25 02:34:48 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 02:34:48 [INFO]: Epoch 001 - training loss: 63186.8986, validation loss: 0.6900
2024-05-25 02:34:48 [INFO]: Epoch 002 - training loss: 42069.3730, validation loss: 0.5945
2024-05-25 02:34:49 [INFO]: Epoch 003 - training loss: 41769.2387, validation loss: 0.5560
2024-05-25 02:34:49 [INFO]: Epoch 004 - training loss: 41654.0012, validation loss: 0.5088
2024-05-25 02:34:50 [INFO]: Epoch 005 - training loss: 41556.2455, validation loss: 0.4757
2024-05-25 02:34:50 [INFO]: Epoch 006 - training loss: 41512.7970, validation loss: 0.4344
2024-05-25 02:34:50 [INFO]: Epoch 007 - training loss: 41470.4227, validation loss: 0.4335
2024-05-25 02:34:51 [INFO]: Epoch 008 - training loss: 41443.6674, validation loss: 0.3738
2024-05-25 02:34:51 [INFO]: Epoch 009 - training loss: 41405.6680, validation loss: 0.3694
2024-05-25 02:34:51 [INFO]: Epoch 010 - training loss: 41395.2079, validation loss: 0.3956
2024-05-25 02:34:52 [INFO]: Epoch 011 - training loss: 41361.7208, validation loss: 0.3515
2024-05-25 02:34:52 [INFO]: Epoch 012 - training loss: 41345.0690, validation loss: 0.3857
2024-05-25 02:34:52 [INFO]: Epoch 013 - training loss: 41340.7474, validation loss: 0.3456
2024-05-25 02:34:53 [INFO]: Epoch 014 - training loss: 41340.0790, validation loss: 0.3319
2024-05-25 02:34:53 [INFO]: Epoch 015 - training loss: 41300.4742, validation loss: 0.3189
2024-05-25 02:34:54 [INFO]: Epoch 016 - training loss: 41293.1703, validation loss: 0.3430
2024-05-25 02:34:54 [INFO]: Epoch 017 - training loss: 41278.8692, validation loss: 0.3225
2024-05-25 02:34:54 [INFO]: Epoch 018 - training loss: 41272.8349, validation loss: 0.3174
2024-05-25 02:34:55 [INFO]: Epoch 019 - training loss: 41302.0771, validation loss: 0.3151
2024-05-25 02:34:55 [INFO]: Epoch 020 - training loss: 41282.6712, validation loss: 0.2993
2024-05-25 02:34:55 [INFO]: Epoch 021 - training loss: 41272.5054, validation loss: 0.3207
2024-05-25 02:34:56 [INFO]: Epoch 022 - training loss: 41264.9446, validation loss: 0.3048
2024-05-25 02:34:56 [INFO]: Epoch 023 - training loss: 41267.2457, validation loss: 0.3745
2024-05-25 02:34:56 [INFO]: Epoch 024 - training loss: 41317.7117, validation loss: 0.3104
2024-05-25 02:34:57 [INFO]: Epoch 025 - training loss: 41275.1892, validation loss: 0.3243
2024-05-25 02:34:57 [INFO]: Epoch 026 - training loss: 41243.6178, validation loss: 0.3085
2024-05-25 02:34:58 [INFO]: Epoch 027 - training loss: 41224.0778, validation loss: 0.2988
2024-05-25 02:34:58 [INFO]: Epoch 028 - training loss: 41215.8229, validation loss: 0.2840
2024-05-25 02:34:58 [INFO]: Epoch 029 - training loss: 41214.4822, validation loss: 0.2907
2024-05-25 02:34:59 [INFO]: Epoch 030 - training loss: 41237.3144, validation loss: 0.3074
2024-05-25 02:34:59 [INFO]: Epoch 031 - training loss: 41219.4653, validation loss: 0.2953
2024-05-25 02:34:59 [INFO]: Epoch 032 - training loss: 41207.7054, validation loss: 0.2738
2024-05-25 02:35:00 [INFO]: Epoch 033 - training loss: 41200.6063, validation loss: 0.3021
2024-05-25 02:35:00 [INFO]: Epoch 034 - training loss: 41216.7277, validation loss: 0.3114
2024-05-25 02:35:01 [INFO]: Epoch 035 - training loss: 41206.3176, validation loss: 0.2684
2024-05-25 02:35:01 [INFO]: Epoch 036 - training loss: 41196.2211, validation loss: 0.2941
2024-05-25 02:35:01 [INFO]: Epoch 037 - training loss: 41202.0616, validation loss: 0.2925
2024-05-25 02:35:02 [INFO]: Epoch 038 - training loss: 41198.0679, validation loss: 0.2735
2024-05-25 02:35:02 [INFO]: Epoch 039 - training loss: 41196.8579, validation loss: 0.2684
2024-05-25 02:35:02 [INFO]: Epoch 040 - training loss: 41196.9044, validation loss: 0.2954
2024-05-25 02:35:03 [INFO]: Epoch 041 - training loss: 41251.6988, validation loss: 0.2829
2024-05-25 02:35:03 [INFO]: Epoch 042 - training loss: 41208.2917, validation loss: 0.2945
2024-05-25 02:35:03 [INFO]: Epoch 043 - training loss: 41210.5812, validation loss: 0.2748
2024-05-25 02:35:04 [INFO]: Epoch 044 - training loss: 41192.2212, validation loss: 0.2905
2024-05-25 02:35:04 [INFO]: Epoch 045 - training loss: 41188.8245, validation loss: 0.2713
2024-05-25 02:35:05 [INFO]: Epoch 046 - training loss: 41182.7331, validation loss: 0.2662
2024-05-25 02:35:05 [INFO]: Epoch 047 - training loss: 41171.9287, validation loss: 0.2730
2024-05-25 02:35:05 [INFO]: Epoch 048 - training loss: 41166.4683, validation loss: 0.2573
2024-05-25 02:35:06 [INFO]: Epoch 049 - training loss: 41164.6165, validation loss: 0.2625
2024-05-25 02:35:06 [INFO]: Epoch 050 - training loss: 41170.5379, validation loss: 0.2844
2024-05-25 02:35:06 [INFO]: Epoch 051 - training loss: 41166.4894, validation loss: 0.2695
2024-05-25 02:35:07 [INFO]: Epoch 052 - training loss: 41161.5168, validation loss: 0.2642
2024-05-25 02:35:07 [INFO]: Epoch 053 - training loss: 41159.9579, validation loss: 0.2650
2024-05-25 02:35:07 [INFO]: Epoch 054 - training loss: 41164.6852, validation loss: 0.2777
2024-05-25 02:35:08 [INFO]: Epoch 055 - training loss: 41186.7727, validation loss: 0.2679
2024-05-25 02:35:08 [INFO]: Epoch 056 - training loss: 41183.9184, validation loss: 0.2668
2024-05-25 02:35:08 [INFO]: Epoch 057 - training loss: 41220.5323, validation loss: 0.3019
2024-05-25 02:35:09 [INFO]: Epoch 058 - training loss: 41224.2484, validation loss: 0.2785
2024-05-25 02:35:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:35:09 [INFO]: Finished training. The best model is from epoch#48.
2024-05-25 02:35:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/GPVAE_air_quality/20240525_T023448/GPVAE.pypots
2024-05-25 02:35:09 [INFO]: GP-VAE on Air-Quality: MAE=0.3094, MSE=0.2675
2024-05-25 02:35:09 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 02:35:09 [INFO]: Using the given device: cuda:0
2024-05-25 02:35:09 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T023509
2024-05-25 02:35:09 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T023509/tensorboard
2024-05-25 02:35:09 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 02:35:14 [INFO]: Epoch 001 - generator training loss: 0.5938, discriminator training loss: 0.2925, validation loss: 0.5198
2024-05-25 02:35:18 [INFO]: Epoch 002 - generator training loss: 0.2838, discriminator training loss: 0.0676, validation loss: 0.3935
2024-05-25 02:35:23 [INFO]: Epoch 003 - generator training loss: 0.2109, discriminator training loss: 0.0636, validation loss: 0.3298
2024-05-25 02:35:27 [INFO]: Epoch 004 - generator training loss: 0.1730, discriminator training loss: 0.0626, validation loss: 0.2912
2024-05-25 02:35:31 [INFO]: Epoch 005 - generator training loss: 0.1490, discriminator training loss: 0.0617, validation loss: 0.2655
2024-05-25 02:35:36 [INFO]: Epoch 006 - generator training loss: 0.1315, discriminator training loss: 0.0615, validation loss: 0.2468
2024-05-25 02:35:40 [INFO]: Epoch 007 - generator training loss: 0.1183, discriminator training loss: 0.0611, validation loss: 0.2330
2024-05-25 02:35:44 [INFO]: Epoch 008 - generator training loss: 0.1083, discriminator training loss: 0.0601, validation loss: 0.2224
2024-05-25 02:35:49 [INFO]: Epoch 009 - generator training loss: 0.0999, discriminator training loss: 0.0592, validation loss: 0.2137
2024-05-25 02:35:53 [INFO]: Epoch 010 - generator training loss: 0.0932, discriminator training loss: 0.0586, validation loss: 0.2063
2024-05-25 02:35:57 [INFO]: Epoch 011 - generator training loss: 0.0885, discriminator training loss: 0.0577, validation loss: 0.2001
2024-05-25 02:36:02 [INFO]: Epoch 012 - generator training loss: 0.0832, discriminator training loss: 0.0571, validation loss: 0.1956
2024-05-25 02:36:06 [INFO]: Epoch 013 - generator training loss: 0.0794, discriminator training loss: 0.0552, validation loss: 0.1912
2024-05-25 02:36:10 [INFO]: Epoch 014 - generator training loss: 0.0774, discriminator training loss: 0.0537, validation loss: 0.1872
2024-05-25 02:36:15 [INFO]: Epoch 015 - generator training loss: 0.0743, discriminator training loss: 0.0522, validation loss: 0.1833
2024-05-25 02:36:19 [INFO]: Epoch 016 - generator training loss: 0.0713, discriminator training loss: 0.0505, validation loss: 0.1803
2024-05-25 02:36:23 [INFO]: Epoch 017 - generator training loss: 0.0697, discriminator training loss: 0.0486, validation loss: 0.1778
2024-05-25 02:36:28 [INFO]: Epoch 018 - generator training loss: 0.0673, discriminator training loss: 0.0476, validation loss: 0.1756
2024-05-25 02:36:32 [INFO]: Epoch 019 - generator training loss: 0.0660, discriminator training loss: 0.0462, validation loss: 0.1734
2024-05-25 02:36:36 [INFO]: Epoch 020 - generator training loss: 0.0645, discriminator training loss: 0.0455, validation loss: 0.1713
2024-05-25 02:36:40 [INFO]: Epoch 021 - generator training loss: 0.0630, discriminator training loss: 0.0447, validation loss: 0.1693
2024-05-25 02:36:45 [INFO]: Epoch 022 - generator training loss: 0.0622, discriminator training loss: 0.0441, validation loss: 0.1677
2024-05-25 02:36:49 [INFO]: Epoch 023 - generator training loss: 0.0603, discriminator training loss: 0.0430, validation loss: 0.1662
2024-05-25 02:36:54 [INFO]: Epoch 024 - generator training loss: 0.0609, discriminator training loss: 0.0418, validation loss: 0.1648
2024-05-25 02:36:58 [INFO]: Epoch 025 - generator training loss: 0.0599, discriminator training loss: 0.0417, validation loss: 0.1646
2024-05-25 02:37:02 [INFO]: Epoch 026 - generator training loss: 0.0580, discriminator training loss: 0.0406, validation loss: 0.1628
2024-05-25 02:37:07 [INFO]: Epoch 027 - generator training loss: 0.0572, discriminator training loss: 0.0400, validation loss: 0.1620
2024-05-25 02:37:11 [INFO]: Epoch 028 - generator training loss: 0.0566, discriminator training loss: 0.0389, validation loss: 0.1601
2024-05-25 02:37:15 [INFO]: Epoch 029 - generator training loss: 0.0558, discriminator training loss: 0.0382, validation loss: 0.1598
2024-05-25 02:37:19 [INFO]: Epoch 030 - generator training loss: 0.0554, discriminator training loss: 0.0373, validation loss: 0.1591
2024-05-25 02:37:24 [INFO]: Epoch 031 - generator training loss: 0.0548, discriminator training loss: 0.0368, validation loss: 0.1582
2024-05-25 02:37:28 [INFO]: Epoch 032 - generator training loss: 0.0545, discriminator training loss: 0.0359, validation loss: 0.1576
2024-05-25 02:37:32 [INFO]: Epoch 033 - generator training loss: 0.0536, discriminator training loss: 0.0351, validation loss: 0.1570
2024-05-25 02:37:37 [INFO]: Epoch 034 - generator training loss: 0.0536, discriminator training loss: 0.0343, validation loss: 0.1555
2024-05-25 02:37:41 [INFO]: Epoch 035 - generator training loss: 0.0541, discriminator training loss: 0.0332, validation loss: 0.1552
2024-05-25 02:37:45 [INFO]: Epoch 036 - generator training loss: 0.0526, discriminator training loss: 0.0331, validation loss: 0.1544
2024-05-25 02:37:50 [INFO]: Epoch 037 - generator training loss: 0.0522, discriminator training loss: 0.0325, validation loss: 0.1541
2024-05-25 02:37:54 [INFO]: Epoch 038 - generator training loss: 0.0515, discriminator training loss: 0.0316, validation loss: 0.1535
2024-05-25 02:37:58 [INFO]: Epoch 039 - generator training loss: 0.0539, discriminator training loss: 0.0308, validation loss: 0.1533
2024-05-25 02:38:03 [INFO]: Epoch 040 - generator training loss: 0.0515, discriminator training loss: 0.0300, validation loss: 0.1524
2024-05-25 02:38:07 [INFO]: Epoch 041 - generator training loss: 0.0505, discriminator training loss: 0.0298, validation loss: 0.1514
2024-05-25 02:38:11 [INFO]: Epoch 042 - generator training loss: 0.0514, discriminator training loss: 0.0296, validation loss: 0.1512
2024-05-25 02:38:16 [INFO]: Epoch 043 - generator training loss: 0.0505, discriminator training loss: 0.0286, validation loss: 0.1502
2024-05-25 02:38:20 [INFO]: Epoch 044 - generator training loss: 0.0500, discriminator training loss: 0.0284, validation loss: 0.1509
2024-05-25 02:38:24 [INFO]: Epoch 045 - generator training loss: 0.0493, discriminator training loss: 0.0277, validation loss: 0.1499
2024-05-25 02:38:29 [INFO]: Epoch 046 - generator training loss: 0.0494, discriminator training loss: 0.0273, validation loss: 0.1489
2024-05-25 02:38:33 [INFO]: Epoch 047 - generator training loss: 0.0495, discriminator training loss: 0.0266, validation loss: 0.1487
2024-05-25 02:38:37 [INFO]: Epoch 048 - generator training loss: 0.0497, discriminator training loss: 0.0265, validation loss: 0.1489
2024-05-25 02:38:42 [INFO]: Epoch 049 - generator training loss: 0.0489, discriminator training loss: 0.0260, validation loss: 0.1476
2024-05-25 02:38:46 [INFO]: Epoch 050 - generator training loss: 0.0482, discriminator training loss: 0.0254, validation loss: 0.1476
2024-05-25 02:38:50 [INFO]: Epoch 051 - generator training loss: 0.0480, discriminator training loss: 0.0249, validation loss: 0.1460
2024-05-25 02:38:54 [INFO]: Epoch 052 - generator training loss: 0.0477, discriminator training loss: 0.0247, validation loss: 0.1464
2024-05-25 02:38:58 [INFO]: Epoch 053 - generator training loss: 0.0481, discriminator training loss: 0.0243, validation loss: 0.1464
2024-05-25 02:39:03 [INFO]: Epoch 054 - generator training loss: 0.0472, discriminator training loss: 0.0238, validation loss: 0.1462
2024-05-25 02:39:07 [INFO]: Epoch 055 - generator training loss: 0.0470, discriminator training loss: 0.0235, validation loss: 0.1456
2024-05-25 02:39:11 [INFO]: Epoch 056 - generator training loss: 0.0463, discriminator training loss: 0.0230, validation loss: 0.1450
2024-05-25 02:39:16 [INFO]: Epoch 057 - generator training loss: 0.0458, discriminator training loss: 0.0229, validation loss: 0.1447
2024-05-25 02:39:20 [INFO]: Epoch 058 - generator training loss: 0.0458, discriminator training loss: 0.0226, validation loss: 0.1448
2024-05-25 02:39:25 [INFO]: Epoch 059 - generator training loss: 0.0463, discriminator training loss: 0.0221, validation loss: 0.1446
2024-05-25 02:39:29 [INFO]: Epoch 060 - generator training loss: 0.0453, discriminator training loss: 0.0217, validation loss: 0.1444
2024-05-25 02:39:33 [INFO]: Epoch 061 - generator training loss: 0.0447, discriminator training loss: 0.0213, validation loss: 0.1434
2024-05-25 02:39:37 [INFO]: Epoch 062 - generator training loss: 0.0444, discriminator training loss: 0.0216, validation loss: 0.1435
2024-05-25 02:39:42 [INFO]: Epoch 063 - generator training loss: 0.0440, discriminator training loss: 0.0215, validation loss: 0.1426
2024-05-25 02:39:46 [INFO]: Epoch 064 - generator training loss: 0.0434, discriminator training loss: 0.0212, validation loss: 0.1427
2024-05-25 02:39:50 [INFO]: Epoch 065 - generator training loss: 0.0456, discriminator training loss: 0.0203, validation loss: 0.1432
2024-05-25 02:39:55 [INFO]: Epoch 066 - generator training loss: 0.0444, discriminator training loss: 0.0206, validation loss: 0.1427
2024-05-25 02:39:59 [INFO]: Epoch 067 - generator training loss: 0.0433, discriminator training loss: 0.0204, validation loss: 0.1414
2024-05-25 02:40:03 [INFO]: Epoch 068 - generator training loss: 0.0433, discriminator training loss: 0.0199, validation loss: 0.1409
2024-05-25 02:40:08 [INFO]: Epoch 069 - generator training loss: 0.0427, discriminator training loss: 0.0195, validation loss: 0.1411
2024-05-25 02:40:12 [INFO]: Epoch 070 - generator training loss: 0.0424, discriminator training loss: 0.0195, validation loss: 0.1420
2024-05-25 02:40:16 [INFO]: Epoch 071 - generator training loss: 0.0424, discriminator training loss: 0.0194, validation loss: 0.1411
2024-05-25 02:40:21 [INFO]: Epoch 072 - generator training loss: 0.0421, discriminator training loss: 0.0190, validation loss: 0.1404
2024-05-25 02:40:25 [INFO]: Epoch 073 - generator training loss: 0.0416, discriminator training loss: 0.0188, validation loss: 0.1408
2024-05-25 02:40:29 [INFO]: Epoch 074 - generator training loss: 0.0410, discriminator training loss: 0.0188, validation loss: 0.1405
2024-05-25 02:40:34 [INFO]: Epoch 075 - generator training loss: 0.0410, discriminator training loss: 0.0185, validation loss: 0.1412
2024-05-25 02:40:38 [INFO]: Epoch 076 - generator training loss: 0.0407, discriminator training loss: 0.0184, validation loss: 0.1400
2024-05-25 02:40:42 [INFO]: Epoch 077 - generator training loss: 0.0415, discriminator training loss: 0.0182, validation loss: 0.1402
2024-05-25 02:40:47 [INFO]: Epoch 078 - generator training loss: 0.0411, discriminator training loss: 0.0178, validation loss: 0.1395
2024-05-25 02:40:51 [INFO]: Epoch 079 - generator training loss: 0.0406, discriminator training loss: 0.0181, validation loss: 0.1402
2024-05-25 02:40:55 [INFO]: Epoch 080 - generator training loss: 0.0399, discriminator training loss: 0.0178, validation loss: 0.1391
2024-05-25 02:41:00 [INFO]: Epoch 081 - generator training loss: 0.0397, discriminator training loss: 0.0176, validation loss: 0.1390
2024-05-25 02:41:04 [INFO]: Epoch 082 - generator training loss: 0.0396, discriminator training loss: 0.0173, validation loss: 0.1394
2024-05-25 02:41:08 [INFO]: Epoch 083 - generator training loss: 0.0393, discriminator training loss: 0.0172, validation loss: 0.1395
2024-05-25 02:41:13 [INFO]: Epoch 084 - generator training loss: 0.0387, discriminator training loss: 0.0172, validation loss: 0.1382
2024-05-25 02:41:17 [INFO]: Epoch 085 - generator training loss: 0.0386, discriminator training loss: 0.0171, validation loss: 0.1399
2024-05-25 02:41:21 [INFO]: Epoch 086 - generator training loss: 0.0387, discriminator training loss: 0.0172, validation loss: 0.1389
2024-05-25 02:41:26 [INFO]: Epoch 087 - generator training loss: 0.0385, discriminator training loss: 0.0168, validation loss: 0.1392
2024-05-25 02:41:30 [INFO]: Epoch 088 - generator training loss: 0.0384, discriminator training loss: 0.0167, validation loss: 0.1390
2024-05-25 02:41:34 [INFO]: Epoch 089 - generator training loss: 0.0381, discriminator training loss: 0.0166, validation loss: 0.1384
2024-05-25 02:41:39 [INFO]: Epoch 090 - generator training loss: 0.0378, discriminator training loss: 0.0164, validation loss: 0.1386
2024-05-25 02:41:43 [INFO]: Epoch 091 - generator training loss: 0.0380, discriminator training loss: 0.0164, validation loss: 0.1385
2024-05-25 02:41:47 [INFO]: Epoch 092 - generator training loss: 0.0387, discriminator training loss: 0.0161, validation loss: 0.1396
2024-05-25 02:41:52 [INFO]: Epoch 093 - generator training loss: 0.0376, discriminator training loss: 0.0162, validation loss: 0.1383
2024-05-25 02:41:56 [INFO]: Epoch 094 - generator training loss: 0.0370, discriminator training loss: 0.0161, validation loss: 0.1391
2024-05-25 02:41:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:41:56 [INFO]: Finished training. The best model is from epoch#84.
2024-05-25 02:41:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/USGAN_air_quality/20240525_T023509/USGAN.pypots
2024-05-25 02:41:57 [INFO]: US-GAN on Air-Quality: MAE=0.2056, MSE=0.1332
2024-05-25 02:41:57 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 02:41:57 [INFO]: Using the given device: cuda:0
2024-05-25 02:41:57 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T024157
2024-05-25 02:41:57 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T024157/tensorboard
2024-05-25 02:41:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 02:42:00 [INFO]: Epoch 001 - training loss: 1.3953, validation loss: 0.9385
2024-05-25 02:42:03 [INFO]: Epoch 002 - training loss: 1.1283, validation loss: 0.7076
2024-05-25 02:42:06 [INFO]: Epoch 003 - training loss: 0.9364, validation loss: 0.5978
2024-05-25 02:42:09 [INFO]: Epoch 004 - training loss: 0.8278, validation loss: 0.5314
2024-05-25 02:42:12 [INFO]: Epoch 005 - training loss: 0.7554, validation loss: 0.4856
2024-05-25 02:42:15 [INFO]: Epoch 006 - training loss: 0.7023, validation loss: 0.4470
2024-05-25 02:42:18 [INFO]: Epoch 007 - training loss: 0.6591, validation loss: 0.4170
2024-05-25 02:42:21 [INFO]: Epoch 008 - training loss: 0.6230, validation loss: 0.3922
2024-05-25 02:42:24 [INFO]: Epoch 009 - training loss: 0.5955, validation loss: 0.3714
2024-05-25 02:42:27 [INFO]: Epoch 010 - training loss: 0.5758, validation loss: 0.3549
2024-05-25 02:42:30 [INFO]: Epoch 011 - training loss: 0.5569, validation loss: 0.3410
2024-05-25 02:42:33 [INFO]: Epoch 012 - training loss: 0.5421, validation loss: 0.3293
2024-05-25 02:42:36 [INFO]: Epoch 013 - training loss: 0.5299, validation loss: 0.3191
2024-05-25 02:42:39 [INFO]: Epoch 014 - training loss: 0.5152, validation loss: 0.3107
2024-05-25 02:42:41 [INFO]: Epoch 015 - training loss: 0.5054, validation loss: 0.3032
2024-05-25 02:42:44 [INFO]: Epoch 016 - training loss: 0.4975, validation loss: 0.2961
2024-05-25 02:42:47 [INFO]: Epoch 017 - training loss: 0.4875, validation loss: 0.2897
2024-05-25 02:42:50 [INFO]: Epoch 018 - training loss: 0.4781, validation loss: 0.2844
2024-05-25 02:42:53 [INFO]: Epoch 019 - training loss: 0.4707, validation loss: 0.2789
2024-05-25 02:42:56 [INFO]: Epoch 020 - training loss: 0.4627, validation loss: 0.2749
2024-05-25 02:42:59 [INFO]: Epoch 021 - training loss: 0.4556, validation loss: 0.2697
2024-05-25 02:43:02 [INFO]: Epoch 022 - training loss: 0.4493, validation loss: 0.2657
2024-05-25 02:43:05 [INFO]: Epoch 023 - training loss: 0.4434, validation loss: 0.2615
2024-05-25 02:43:08 [INFO]: Epoch 024 - training loss: 0.4362, validation loss: 0.2574
2024-05-25 02:43:11 [INFO]: Epoch 025 - training loss: 0.4312, validation loss: 0.2535
2024-05-25 02:43:14 [INFO]: Epoch 026 - training loss: 0.4253, validation loss: 0.2500
2024-05-25 02:43:17 [INFO]: Epoch 027 - training loss: 0.4199, validation loss: 0.2467
2024-05-25 02:43:20 [INFO]: Epoch 028 - training loss: 0.4150, validation loss: 0.2436
2024-05-25 02:43:23 [INFO]: Epoch 029 - training loss: 0.4099, validation loss: 0.2398
2024-05-25 02:43:26 [INFO]: Epoch 030 - training loss: 0.4055, validation loss: 0.2366
2024-05-25 02:43:28 [INFO]: Epoch 031 - training loss: 0.4005, validation loss: 0.2335
2024-05-25 02:43:31 [INFO]: Epoch 032 - training loss: 0.3967, validation loss: 0.2305
2024-05-25 02:43:34 [INFO]: Epoch 033 - training loss: 0.3926, validation loss: 0.2272
2024-05-25 02:43:37 [INFO]: Epoch 034 - training loss: 0.3885, validation loss: 0.2247
2024-05-25 02:43:40 [INFO]: Epoch 035 - training loss: 0.3840, validation loss: 0.2221
2024-05-25 02:43:43 [INFO]: Epoch 036 - training loss: 0.3807, validation loss: 0.2188
2024-05-25 02:43:46 [INFO]: Epoch 037 - training loss: 0.3773, validation loss: 0.2167
2024-05-25 02:43:49 [INFO]: Epoch 038 - training loss: 0.3727, validation loss: 0.2139
2024-05-25 02:43:52 [INFO]: Epoch 039 - training loss: 0.3696, validation loss: 0.2116
2024-05-25 02:43:55 [INFO]: Epoch 040 - training loss: 0.3668, validation loss: 0.2091
2024-05-25 02:43:58 [INFO]: Epoch 041 - training loss: 0.3627, validation loss: 0.2070
2024-05-25 02:44:01 [INFO]: Epoch 042 - training loss: 0.3595, validation loss: 0.2046
2024-05-25 02:44:04 [INFO]: Epoch 043 - training loss: 0.3567, validation loss: 0.2027
2024-05-25 02:44:06 [INFO]: Epoch 044 - training loss: 0.3544, validation loss: 0.2010
2024-05-25 02:44:09 [INFO]: Epoch 045 - training loss: 0.3518, validation loss: 0.1987
2024-05-25 02:44:12 [INFO]: Epoch 046 - training loss: 0.3487, validation loss: 0.1968
2024-05-25 02:44:15 [INFO]: Epoch 047 - training loss: 0.3464, validation loss: 0.1949
2024-05-25 02:44:18 [INFO]: Epoch 048 - training loss: 0.3433, validation loss: 0.1935
2024-05-25 02:44:21 [INFO]: Epoch 049 - training loss: 0.3413, validation loss: 0.1917
2024-05-25 02:44:24 [INFO]: Epoch 050 - training loss: 0.3379, validation loss: 0.1901
2024-05-25 02:44:27 [INFO]: Epoch 051 - training loss: 0.3363, validation loss: 0.1880
2024-05-25 02:44:30 [INFO]: Epoch 052 - training loss: 0.3350, validation loss: 0.1871
2024-05-25 02:44:33 [INFO]: Epoch 053 - training loss: 0.3320, validation loss: 0.1856
2024-05-25 02:44:36 [INFO]: Epoch 054 - training loss: 0.3302, validation loss: 0.1839
2024-05-25 02:44:39 [INFO]: Epoch 055 - training loss: 0.3276, validation loss: 0.1826
2024-05-25 02:44:42 [INFO]: Epoch 056 - training loss: 0.3263, validation loss: 0.1812
2024-05-25 02:44:45 [INFO]: Epoch 057 - training loss: 0.3237, validation loss: 0.1798
2024-05-25 02:44:47 [INFO]: Epoch 058 - training loss: 0.3226, validation loss: 0.1788
2024-05-25 02:44:50 [INFO]: Epoch 059 - training loss: 0.3208, validation loss: 0.1776
2024-05-25 02:44:53 [INFO]: Epoch 060 - training loss: 0.3185, validation loss: 0.1762
2024-05-25 02:44:56 [INFO]: Epoch 061 - training loss: 0.3172, validation loss: 0.1754
2024-05-25 02:44:59 [INFO]: Epoch 062 - training loss: 0.3158, validation loss: 0.1741
2024-05-25 02:45:02 [INFO]: Epoch 063 - training loss: 0.3146, validation loss: 0.1733
2024-05-25 02:45:05 [INFO]: Epoch 064 - training loss: 0.3135, validation loss: 0.1721
2024-05-25 02:45:08 [INFO]: Epoch 065 - training loss: 0.3110, validation loss: 0.1712
2024-05-25 02:45:11 [INFO]: Epoch 066 - training loss: 0.3100, validation loss: 0.1703
2024-05-25 02:45:14 [INFO]: Epoch 067 - training loss: 0.3079, validation loss: 0.1694
2024-05-25 02:45:17 [INFO]: Epoch 068 - training loss: 0.3070, validation loss: 0.1686
2024-05-25 02:45:20 [INFO]: Epoch 069 - training loss: 0.3056, validation loss: 0.1672
2024-05-25 02:45:23 [INFO]: Epoch 070 - training loss: 0.3044, validation loss: 0.1666
2024-05-25 02:45:26 [INFO]: Epoch 071 - training loss: 0.3029, validation loss: 0.1657
2024-05-25 02:45:28 [INFO]: Epoch 072 - training loss: 0.3020, validation loss: 0.1652
2024-05-25 02:45:31 [INFO]: Epoch 073 - training loss: 0.3007, validation loss: 0.1644
2024-05-25 02:45:34 [INFO]: Epoch 074 - training loss: 0.3002, validation loss: 0.1636
2024-05-25 02:45:37 [INFO]: Epoch 075 - training loss: 0.2991, validation loss: 0.1627
2024-05-25 02:45:40 [INFO]: Epoch 076 - training loss: 0.2975, validation loss: 0.1618
2024-05-25 02:45:43 [INFO]: Epoch 077 - training loss: 0.2974, validation loss: 0.1613
2024-05-25 02:45:46 [INFO]: Epoch 078 - training loss: 0.2961, validation loss: 0.1609
2024-05-25 02:45:49 [INFO]: Epoch 079 - training loss: 0.2956, validation loss: 0.1601
2024-05-25 02:45:52 [INFO]: Epoch 080 - training loss: 0.2943, validation loss: 0.1592
2024-05-25 02:45:55 [INFO]: Epoch 081 - training loss: 0.2936, validation loss: 0.1585
2024-05-25 02:45:58 [INFO]: Epoch 082 - training loss: 0.2929, validation loss: 0.1578
2024-05-25 02:46:01 [INFO]: Epoch 083 - training loss: 0.2918, validation loss: 0.1573
2024-05-25 02:46:04 [INFO]: Epoch 084 - training loss: 0.2906, validation loss: 0.1567
2024-05-25 02:46:06 [INFO]: Epoch 085 - training loss: 0.2898, validation loss: 0.1560
2024-05-25 02:46:09 [INFO]: Epoch 086 - training loss: 0.2894, validation loss: 0.1557
2024-05-25 02:46:12 [INFO]: Epoch 087 - training loss: 0.2877, validation loss: 0.1551
2024-05-25 02:46:15 [INFO]: Epoch 088 - training loss: 0.2873, validation loss: 0.1547
2024-05-25 02:46:18 [INFO]: Epoch 089 - training loss: 0.2868, validation loss: 0.1543
2024-05-25 02:46:20 [INFO]: Epoch 090 - training loss: 0.2866, validation loss: 0.1535
2024-05-25 02:46:23 [INFO]: Epoch 091 - training loss: 0.2849, validation loss: 0.1531
2024-05-25 02:46:26 [INFO]: Epoch 092 - training loss: 0.2844, validation loss: 0.1527
2024-05-25 02:46:29 [INFO]: Epoch 093 - training loss: 0.2837, validation loss: 0.1523
2024-05-25 02:46:32 [INFO]: Epoch 094 - training loss: 0.2825, validation loss: 0.1519
2024-05-25 02:46:35 [INFO]: Epoch 095 - training loss: 0.2824, validation loss: 0.1513
2024-05-25 02:46:38 [INFO]: Epoch 096 - training loss: 0.2814, validation loss: 0.1508
2024-05-25 02:46:41 [INFO]: Epoch 097 - training loss: 0.2817, validation loss: 0.1501
2024-05-25 02:46:44 [INFO]: Epoch 098 - training loss: 0.2804, validation loss: 0.1502
2024-05-25 02:46:47 [INFO]: Epoch 099 - training loss: 0.2798, validation loss: 0.1496
2024-05-25 02:46:50 [INFO]: Epoch 100 - training loss: 0.2794, validation loss: 0.1491
2024-05-25 02:46:53 [INFO]: Epoch 101 - training loss: 0.2790, validation loss: 0.1488
2024-05-25 02:46:56 [INFO]: Epoch 102 - training loss: 0.2781, validation loss: 0.1482
2024-05-25 02:46:59 [INFO]: Epoch 103 - training loss: 0.2777, validation loss: 0.1477
2024-05-25 02:47:02 [INFO]: Epoch 104 - training loss: 0.2771, validation loss: 0.1474
2024-05-25 02:47:04 [INFO]: Epoch 105 - training loss: 0.2762, validation loss: 0.1472
2024-05-25 02:47:07 [INFO]: Epoch 106 - training loss: 0.2753, validation loss: 0.1467
2024-05-25 02:47:10 [INFO]: Epoch 107 - training loss: 0.2747, validation loss: 0.1463
2024-05-25 02:47:13 [INFO]: Epoch 108 - training loss: 0.2744, validation loss: 0.1460
2024-05-25 02:47:16 [INFO]: Epoch 109 - training loss: 0.2740, validation loss: 0.1456
2024-05-25 02:47:19 [INFO]: Epoch 110 - training loss: 0.2737, validation loss: 0.1453
2024-05-25 02:47:22 [INFO]: Epoch 111 - training loss: 0.2727, validation loss: 0.1450
2024-05-25 02:47:25 [INFO]: Epoch 112 - training loss: 0.2724, validation loss: 0.1446
2024-05-25 02:47:28 [INFO]: Epoch 113 - training loss: 0.2716, validation loss: 0.1443
2024-05-25 02:47:31 [INFO]: Epoch 114 - training loss: 0.2707, validation loss: 0.1438
2024-05-25 02:47:34 [INFO]: Epoch 115 - training loss: 0.2705, validation loss: 0.1435
2024-05-25 02:47:37 [INFO]: Epoch 116 - training loss: 0.2696, validation loss: 0.1431
2024-05-25 02:47:40 [INFO]: Epoch 117 - training loss: 0.2695, validation loss: 0.1430
2024-05-25 02:47:43 [INFO]: Epoch 118 - training loss: 0.2690, validation loss: 0.1427
2024-05-25 02:47:45 [INFO]: Epoch 119 - training loss: 0.2692, validation loss: 0.1423
2024-05-25 02:47:48 [INFO]: Epoch 120 - training loss: 0.2684, validation loss: 0.1419
2024-05-25 02:47:51 [INFO]: Epoch 121 - training loss: 0.2678, validation loss: 0.1416
2024-05-25 02:47:54 [INFO]: Epoch 122 - training loss: 0.2668, validation loss: 0.1414
2024-05-25 02:47:57 [INFO]: Epoch 123 - training loss: 0.2667, validation loss: 0.1409
2024-05-25 02:48:00 [INFO]: Epoch 124 - training loss: 0.2662, validation loss: 0.1409
2024-05-25 02:48:03 [INFO]: Epoch 125 - training loss: 0.2663, validation loss: 0.1405
2024-05-25 02:48:06 [INFO]: Epoch 126 - training loss: 0.2651, validation loss: 0.1402
2024-05-25 02:48:09 [INFO]: Epoch 127 - training loss: 0.2655, validation loss: 0.1400
2024-05-25 02:48:12 [INFO]: Epoch 128 - training loss: 0.2650, validation loss: 0.1396
2024-05-25 02:48:15 [INFO]: Epoch 129 - training loss: 0.2644, validation loss: 0.1392
2024-05-25 02:48:18 [INFO]: Epoch 130 - training loss: 0.2636, validation loss: 0.1389
2024-05-25 02:48:21 [INFO]: Epoch 131 - training loss: 0.2633, validation loss: 0.1388
2024-05-25 02:48:24 [INFO]: Epoch 132 - training loss: 0.2634, validation loss: 0.1385
2024-05-25 02:48:26 [INFO]: Epoch 133 - training loss: 0.2624, validation loss: 0.1382
2024-05-25 02:48:29 [INFO]: Epoch 134 - training loss: 0.2617, validation loss: 0.1379
2024-05-25 02:48:32 [INFO]: Epoch 135 - training loss: 0.2619, validation loss: 0.1378
2024-05-25 02:48:35 [INFO]: Epoch 136 - training loss: 0.2615, validation loss: 0.1376
2024-05-25 02:48:38 [INFO]: Epoch 137 - training loss: 0.2616, validation loss: 0.1373
2024-05-25 02:48:41 [INFO]: Epoch 138 - training loss: 0.2608, validation loss: 0.1370
2024-05-25 02:48:44 [INFO]: Epoch 139 - training loss: 0.2608, validation loss: 0.1370
2024-05-25 02:48:47 [INFO]: Epoch 140 - training loss: 0.2594, validation loss: 0.1365
2024-05-25 02:48:50 [INFO]: Epoch 141 - training loss: 0.2592, validation loss: 0.1363
2024-05-25 02:48:53 [INFO]: Epoch 142 - training loss: 0.2590, validation loss: 0.1363
2024-05-25 02:48:56 [INFO]: Epoch 143 - training loss: 0.2587, validation loss: 0.1360
2024-05-25 02:48:59 [INFO]: Epoch 144 - training loss: 0.2581, validation loss: 0.1355
2024-05-25 02:49:02 [INFO]: Epoch 145 - training loss: 0.2579, validation loss: 0.1356
2024-05-25 02:49:05 [INFO]: Epoch 146 - training loss: 0.2577, validation loss: 0.1352
2024-05-25 02:49:08 [INFO]: Epoch 147 - training loss: 0.2571, validation loss: 0.1349
2024-05-25 02:49:10 [INFO]: Epoch 148 - training loss: 0.2568, validation loss: 0.1346
2024-05-25 02:49:13 [INFO]: Epoch 149 - training loss: 0.2572, validation loss: 0.1345
2024-05-25 02:49:16 [INFO]: Epoch 150 - training loss: 0.2564, validation loss: 0.1344
2024-05-25 02:49:19 [INFO]: Epoch 151 - training loss: 0.2558, validation loss: 0.1340
2024-05-25 02:49:22 [INFO]: Epoch 152 - training loss: 0.2555, validation loss: 0.1338
2024-05-25 02:49:25 [INFO]: Epoch 153 - training loss: 0.2549, validation loss: 0.1338
2024-05-25 02:49:28 [INFO]: Epoch 154 - training loss: 0.2552, validation loss: 0.1335
2024-05-25 02:49:31 [INFO]: Epoch 155 - training loss: 0.2548, validation loss: 0.1332
2024-05-25 02:49:34 [INFO]: Epoch 156 - training loss: 0.2547, validation loss: 0.1331
2024-05-25 02:49:37 [INFO]: Epoch 157 - training loss: 0.2542, validation loss: 0.1331
2024-05-25 02:49:40 [INFO]: Epoch 158 - training loss: 0.2542, validation loss: 0.1328
2024-05-25 02:49:43 [INFO]: Epoch 159 - training loss: 0.2533, validation loss: 0.1326
2024-05-25 02:49:46 [INFO]: Epoch 160 - training loss: 0.2529, validation loss: 0.1322
2024-05-25 02:49:49 [INFO]: Epoch 161 - training loss: 0.2525, validation loss: 0.1321
2024-05-25 02:49:51 [INFO]: Epoch 162 - training loss: 0.2521, validation loss: 0.1319
2024-05-25 02:49:54 [INFO]: Epoch 163 - training loss: 0.2523, validation loss: 0.1318
2024-05-25 02:49:57 [INFO]: Epoch 164 - training loss: 0.2523, validation loss: 0.1317
2024-05-25 02:50:00 [INFO]: Epoch 165 - training loss: 0.2519, validation loss: 0.1314
2024-05-25 02:50:03 [INFO]: Epoch 166 - training loss: 0.2512, validation loss: 0.1311
2024-05-25 02:50:06 [INFO]: Epoch 167 - training loss: 0.2508, validation loss: 0.1311
2024-05-25 02:50:09 [INFO]: Epoch 168 - training loss: 0.2503, validation loss: 0.1310
2024-05-25 02:50:12 [INFO]: Epoch 169 - training loss: 0.2500, validation loss: 0.1308
2024-05-25 02:50:15 [INFO]: Epoch 170 - training loss: 0.2504, validation loss: 0.1307
2024-05-25 02:50:18 [INFO]: Epoch 171 - training loss: 0.2499, validation loss: 0.1304
2024-05-25 02:50:21 [INFO]: Epoch 172 - training loss: 0.2492, validation loss: 0.1302
2024-05-25 02:50:24 [INFO]: Epoch 173 - training loss: 0.2490, validation loss: 0.1302
2024-05-25 02:50:27 [INFO]: Epoch 174 - training loss: 0.2491, validation loss: 0.1300
2024-05-25 02:50:30 [INFO]: Epoch 175 - training loss: 0.2493, validation loss: 0.1301
2024-05-25 02:50:32 [INFO]: Epoch 176 - training loss: 0.2488, validation loss: 0.1297
2024-05-25 02:50:35 [INFO]: Epoch 177 - training loss: 0.2486, validation loss: 0.1294
2024-05-25 02:50:38 [INFO]: Epoch 178 - training loss: 0.2480, validation loss: 0.1296
2024-05-25 02:50:41 [INFO]: Epoch 179 - training loss: 0.2487, validation loss: 0.1293
2024-05-25 02:50:44 [INFO]: Epoch 180 - training loss: 0.2479, validation loss: 0.1292
2024-05-25 02:50:47 [INFO]: Epoch 181 - training loss: 0.2475, validation loss: 0.1291
2024-05-25 02:50:50 [INFO]: Epoch 182 - training loss: 0.2470, validation loss: 0.1290
2024-05-25 02:50:53 [INFO]: Epoch 183 - training loss: 0.2471, validation loss: 0.1288
2024-05-25 02:50:56 [INFO]: Epoch 184 - training loss: 0.2464, validation loss: 0.1286
2024-05-25 02:50:59 [INFO]: Epoch 185 - training loss: 0.2461, validation loss: 0.1285
2024-05-25 02:51:02 [INFO]: Epoch 186 - training loss: 0.2461, validation loss: 0.1283
2024-05-25 02:51:05 [INFO]: Epoch 187 - training loss: 0.2460, validation loss: 0.1284
2024-05-25 02:51:08 [INFO]: Epoch 188 - training loss: 0.2458, validation loss: 0.1281
2024-05-25 02:51:11 [INFO]: Epoch 189 - training loss: 0.2456, validation loss: 0.1280
2024-05-25 02:51:13 [INFO]: Epoch 190 - training loss: 0.2454, validation loss: 0.1278
2024-05-25 02:51:16 [INFO]: Epoch 191 - training loss: 0.2451, validation loss: 0.1278
2024-05-25 02:51:19 [INFO]: Epoch 192 - training loss: 0.2447, validation loss: 0.1278
2024-05-25 02:51:22 [INFO]: Epoch 193 - training loss: 0.2444, validation loss: 0.1276
2024-05-25 02:51:25 [INFO]: Epoch 194 - training loss: 0.2446, validation loss: 0.1275
2024-05-25 02:51:28 [INFO]: Epoch 195 - training loss: 0.2443, validation loss: 0.1272
2024-05-25 02:51:31 [INFO]: Epoch 196 - training loss: 0.2441, validation loss: 0.1273
2024-05-25 02:51:34 [INFO]: Epoch 197 - training loss: 0.2442, validation loss: 0.1271
2024-05-25 02:51:37 [INFO]: Epoch 198 - training loss: 0.2437, validation loss: 0.1272
2024-05-25 02:51:40 [INFO]: Epoch 199 - training loss: 0.2440, validation loss: 0.1270
2024-05-25 02:51:43 [INFO]: Epoch 200 - training loss: 0.2432, validation loss: 0.1269
2024-05-25 02:51:46 [INFO]: Epoch 201 - training loss: 0.2430, validation loss: 0.1267
2024-05-25 02:51:49 [INFO]: Epoch 202 - training loss: 0.2423, validation loss: 0.1267
2024-05-25 02:51:52 [INFO]: Epoch 203 - training loss: 0.2425, validation loss: 0.1265
2024-05-25 02:51:54 [INFO]: Epoch 204 - training loss: 0.2421, validation loss: 0.1264
2024-05-25 02:51:57 [INFO]: Epoch 205 - training loss: 0.2420, validation loss: 0.1265
2024-05-25 02:52:00 [INFO]: Epoch 206 - training loss: 0.2420, validation loss: 0.1262
2024-05-25 02:52:03 [INFO]: Epoch 207 - training loss: 0.2421, validation loss: 0.1261
2024-05-25 02:52:06 [INFO]: Epoch 208 - training loss: 0.2413, validation loss: 0.1261
2024-05-25 02:52:09 [INFO]: Epoch 209 - training loss: 0.2412, validation loss: 0.1263
2024-05-25 02:52:12 [INFO]: Epoch 210 - training loss: 0.2410, validation loss: 0.1259
2024-05-25 02:52:15 [INFO]: Epoch 211 - training loss: 0.2411, validation loss: 0.1260
2024-05-25 02:52:18 [INFO]: Epoch 212 - training loss: 0.2409, validation loss: 0.1257
2024-05-25 02:52:21 [INFO]: Epoch 213 - training loss: 0.2406, validation loss: 0.1258
2024-05-25 02:52:24 [INFO]: Epoch 214 - training loss: 0.2407, validation loss: 0.1256
2024-05-25 02:52:27 [INFO]: Epoch 215 - training loss: 0.2404, validation loss: 0.1255
2024-05-25 02:52:30 [INFO]: Epoch 216 - training loss: 0.2405, validation loss: 0.1254
2024-05-25 02:52:33 [INFO]: Epoch 217 - training loss: 0.2402, validation loss: 0.1254
2024-05-25 02:52:36 [INFO]: Epoch 218 - training loss: 0.2403, validation loss: 0.1253
2024-05-25 02:52:38 [INFO]: Epoch 219 - training loss: 0.2394, validation loss: 0.1252
2024-05-25 02:52:41 [INFO]: Epoch 220 - training loss: 0.2395, validation loss: 0.1250
2024-05-25 02:52:44 [INFO]: Epoch 221 - training loss: 0.2394, validation loss: 0.1252
2024-05-25 02:52:47 [INFO]: Epoch 222 - training loss: 0.2391, validation loss: 0.1251
2024-05-25 02:52:50 [INFO]: Epoch 223 - training loss: 0.2386, validation loss: 0.1249
2024-05-25 02:52:53 [INFO]: Epoch 224 - training loss: 0.2389, validation loss: 0.1248
2024-05-25 02:52:56 [INFO]: Epoch 225 - training loss: 0.2385, validation loss: 0.1247
2024-05-25 02:52:59 [INFO]: Epoch 226 - training loss: 0.2387, validation loss: 0.1246
2024-05-25 02:53:02 [INFO]: Epoch 227 - training loss: 0.2381, validation loss: 0.1245
2024-05-25 02:53:05 [INFO]: Epoch 228 - training loss: 0.2383, validation loss: 0.1247
2024-05-25 02:53:08 [INFO]: Epoch 229 - training loss: 0.2378, validation loss: 0.1244
2024-05-25 02:53:11 [INFO]: Epoch 230 - training loss: 0.2373, validation loss: 0.1243
2024-05-25 02:53:14 [INFO]: Epoch 231 - training loss: 0.2378, validation loss: 0.1242
2024-05-25 02:53:17 [INFO]: Epoch 232 - training loss: 0.2376, validation loss: 0.1242
2024-05-25 02:53:19 [INFO]: Epoch 233 - training loss: 0.2375, validation loss: 0.1241
2024-05-25 02:53:22 [INFO]: Epoch 234 - training loss: 0.2374, validation loss: 0.1241
2024-05-25 02:53:25 [INFO]: Epoch 235 - training loss: 0.2368, validation loss: 0.1243
2024-05-25 02:53:28 [INFO]: Epoch 236 - training loss: 0.2370, validation loss: 0.1239
2024-05-25 02:53:31 [INFO]: Epoch 237 - training loss: 0.2366, validation loss: 0.1241
2024-05-25 02:53:34 [INFO]: Epoch 238 - training loss: 0.2368, validation loss: 0.1238
2024-05-25 02:53:37 [INFO]: Epoch 239 - training loss: 0.2368, validation loss: 0.1238
2024-05-25 02:53:39 [INFO]: Epoch 240 - training loss: 0.2362, validation loss: 0.1237
2024-05-25 02:53:42 [INFO]: Epoch 241 - training loss: 0.2367, validation loss: 0.1237
2024-05-25 02:53:45 [INFO]: Epoch 242 - training loss: 0.2363, validation loss: 0.1237
2024-05-25 02:53:48 [INFO]: Epoch 243 - training loss: 0.2354, validation loss: 0.1234
2024-05-25 02:53:51 [INFO]: Epoch 244 - training loss: 0.2356, validation loss: 0.1236
2024-05-25 02:53:54 [INFO]: Epoch 245 - training loss: 0.2354, validation loss: 0.1235
2024-05-25 02:53:57 [INFO]: Epoch 246 - training loss: 0.2355, validation loss: 0.1234
2024-05-25 02:54:00 [INFO]: Epoch 247 - training loss: 0.2348, validation loss: 0.1233
2024-05-25 02:54:03 [INFO]: Epoch 248 - training loss: 0.2354, validation loss: 0.1233
2024-05-25 02:54:06 [INFO]: Epoch 249 - training loss: 0.2354, validation loss: 0.1233
2024-05-25 02:54:09 [INFO]: Epoch 250 - training loss: 0.2356, validation loss: 0.1232
2024-05-25 02:54:12 [INFO]: Epoch 251 - training loss: 0.2352, validation loss: 0.1231
2024-05-25 02:54:15 [INFO]: Epoch 252 - training loss: 0.2343, validation loss: 0.1231
2024-05-25 02:54:18 [INFO]: Epoch 253 - training loss: 0.2343, validation loss: 0.1228
2024-05-25 02:54:21 [INFO]: Epoch 254 - training loss: 0.2342, validation loss: 0.1230
2024-05-25 02:54:24 [INFO]: Epoch 255 - training loss: 0.2341, validation loss: 0.1229
2024-05-25 02:54:26 [INFO]: Epoch 256 - training loss: 0.2336, validation loss: 0.1229
2024-05-25 02:54:29 [INFO]: Epoch 257 - training loss: 0.2339, validation loss: 0.1229
2024-05-25 02:54:32 [INFO]: Epoch 258 - training loss: 0.2337, validation loss: 0.1231
2024-05-25 02:54:35 [INFO]: Epoch 259 - training loss: 0.2338, validation loss: 0.1225
2024-05-25 02:54:38 [INFO]: Epoch 260 - training loss: 0.2340, validation loss: 0.1225
2024-05-25 02:54:41 [INFO]: Epoch 261 - training loss: 0.2335, validation loss: 0.1225
2024-05-25 02:54:44 [INFO]: Epoch 262 - training loss: 0.2331, validation loss: 0.1225
2024-05-25 02:54:47 [INFO]: Epoch 263 - training loss: 0.2331, validation loss: 0.1224
2024-05-25 02:54:50 [INFO]: Epoch 264 - training loss: 0.2338, validation loss: 0.1225
2024-05-25 02:54:53 [INFO]: Epoch 265 - training loss: 0.2329, validation loss: 0.1224
2024-05-25 02:54:56 [INFO]: Epoch 266 - training loss: 0.2328, validation loss: 0.1223
2024-05-25 02:54:59 [INFO]: Epoch 267 - training loss: 0.2327, validation loss: 0.1223
2024-05-25 02:55:02 [INFO]: Epoch 268 - training loss: 0.2330, validation loss: 0.1222
2024-05-25 02:55:04 [INFO]: Epoch 269 - training loss: 0.2325, validation loss: 0.1222
2024-05-25 02:55:07 [INFO]: Epoch 270 - training loss: 0.2318, validation loss: 0.1222
2024-05-25 02:55:10 [INFO]: Epoch 271 - training loss: 0.2321, validation loss: 0.1222
2024-05-25 02:55:13 [INFO]: Epoch 272 - training loss: 0.2325, validation loss: 0.1222
2024-05-25 02:55:16 [INFO]: Epoch 273 - training loss: 0.2323, validation loss: 0.1220
2024-05-25 02:55:19 [INFO]: Epoch 274 - training loss: 0.2316, validation loss: 0.1222
2024-05-25 02:55:22 [INFO]: Epoch 275 - training loss: 0.2315, validation loss: 0.1221
2024-05-25 02:55:25 [INFO]: Epoch 276 - training loss: 0.2315, validation loss: 0.1221
2024-05-25 02:55:28 [INFO]: Epoch 277 - training loss: 0.2318, validation loss: 0.1218
2024-05-25 02:55:31 [INFO]: Epoch 278 - training loss: 0.2315, validation loss: 0.1221
2024-05-25 02:55:34 [INFO]: Epoch 279 - training loss: 0.2315, validation loss: 0.1217
2024-05-25 02:55:37 [INFO]: Epoch 280 - training loss: 0.2310, validation loss: 0.1219
2024-05-25 02:55:40 [INFO]: Epoch 281 - training loss: 0.2310, validation loss: 0.1216
2024-05-25 02:55:43 [INFO]: Epoch 282 - training loss: 0.2310, validation loss: 0.1219
2024-05-25 02:55:45 [INFO]: Epoch 283 - training loss: 0.2310, validation loss: 0.1217
2024-05-25 02:55:48 [INFO]: Epoch 284 - training loss: 0.2306, validation loss: 0.1218
2024-05-25 02:55:51 [INFO]: Epoch 285 - training loss: 0.2309, validation loss: 0.1218
2024-05-25 02:55:54 [INFO]: Epoch 286 - training loss: 0.2304, validation loss: 0.1216
2024-05-25 02:55:57 [INFO]: Epoch 287 - training loss: 0.2298, validation loss: 0.1218
2024-05-25 02:56:00 [INFO]: Epoch 288 - training loss: 0.2304, validation loss: 0.1218
2024-05-25 02:56:03 [INFO]: Epoch 289 - training loss: 0.2304, validation loss: 0.1216
2024-05-25 02:56:06 [INFO]: Epoch 290 - training loss: 0.2299, validation loss: 0.1213
2024-05-25 02:56:09 [INFO]: Epoch 291 - training loss: 0.2302, validation loss: 0.1215
2024-05-25 02:56:12 [INFO]: Epoch 292 - training loss: 0.2302, validation loss: 0.1215
2024-05-25 02:56:15 [INFO]: Epoch 293 - training loss: 0.2302, validation loss: 0.1214
2024-05-25 02:56:18 [INFO]: Epoch 294 - training loss: 0.2293, validation loss: 0.1214
2024-05-25 02:56:21 [INFO]: Epoch 295 - training loss: 0.2295, validation loss: 0.1214
2024-05-25 02:56:24 [INFO]: Epoch 296 - training loss: 0.2299, validation loss: 0.1214
2024-05-25 02:56:27 [INFO]: Epoch 297 - training loss: 0.2294, validation loss: 0.1212
2024-05-25 02:56:29 [INFO]: Epoch 298 - training loss: 0.2292, validation loss: 0.1213
2024-05-25 02:56:32 [INFO]: Epoch 299 - training loss: 0.2290, validation loss: 0.1216
2024-05-25 02:56:35 [INFO]: Epoch 300 - training loss: 0.2289, validation loss: 0.1215
2024-05-25 02:56:35 [INFO]: Finished training. The best model is from epoch#297.
2024-05-25 02:56:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/BRITS_air_quality/20240525_T024157/BRITS.pypots
2024-05-25 02:56:36 [INFO]: BRITS on Air-Quality: MAE=0.1530, MSE=0.1102
2024-05-25 02:56:36 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 02:56:36 [INFO]: Using the given device: cuda:0
2024-05-25 02:56:36 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636
2024-05-25 02:56:36 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/tensorboard
2024-05-25 02:56:36 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 02:56:41 [INFO]: Epoch 001 - training loss: 1.4313, validation loss: 0.7851
2024-05-25 02:56:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch1_loss0.7850603878498077.pypots
2024-05-25 02:56:45 [INFO]: Epoch 002 - training loss: 1.0503, validation loss: 0.7401
2024-05-25 02:56:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch2_loss0.7401066094636917.pypots
2024-05-25 02:56:49 [INFO]: Epoch 003 - training loss: 0.9852, validation loss: 0.7202
2024-05-25 02:56:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch3_loss0.7201847702264785.pypots
2024-05-25 02:56:53 [INFO]: Epoch 004 - training loss: 0.9724, validation loss: 0.7102
2024-05-25 02:56:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch4_loss0.7101860523223877.pypots
2024-05-25 02:56:57 [INFO]: Epoch 005 - training loss: 0.9611, validation loss: 0.7034
2024-05-25 02:56:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch5_loss0.7033843368291854.pypots
2024-05-25 02:57:01 [INFO]: Epoch 006 - training loss: 0.9747, validation loss: 0.6963
2024-05-25 02:57:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch6_loss0.6962860316038132.pypots
2024-05-25 02:57:05 [INFO]: Epoch 007 - training loss: 0.9594, validation loss: 0.6917
2024-05-25 02:57:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch7_loss0.6917395025491715.pypots
2024-05-25 02:57:09 [INFO]: Epoch 008 - training loss: 0.9374, validation loss: 0.6883
2024-05-25 02:57:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch8_loss0.688290485739708.pypots
2024-05-25 02:57:13 [INFO]: Epoch 009 - training loss: 0.9374, validation loss: 0.6862
2024-05-25 02:57:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch9_loss0.686200088262558.pypots
2024-05-25 02:57:17 [INFO]: Epoch 010 - training loss: 0.9174, validation loss: 0.6847
2024-05-25 02:57:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch10_loss0.6846948325634002.pypots
2024-05-25 02:57:21 [INFO]: Epoch 011 - training loss: 0.9277, validation loss: 0.6846
2024-05-25 02:57:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch11_loss0.684623858332634.pypots
2024-05-25 02:57:25 [INFO]: Epoch 012 - training loss: 0.9150, validation loss: 0.6820
2024-05-25 02:57:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch12_loss0.6820199429988861.pypots
2024-05-25 02:57:28 [INFO]: Epoch 013 - training loss: 0.8999, validation loss: 0.6813
2024-05-25 02:57:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch13_loss0.6812726020812988.pypots
2024-05-25 02:57:32 [INFO]: Epoch 014 - training loss: 0.9170, validation loss: 0.6820
2024-05-25 02:57:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch14_loss0.6819725066423417.pypots
2024-05-25 02:57:36 [INFO]: Epoch 015 - training loss: 0.9256, validation loss: 0.6812
2024-05-25 02:57:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch15_loss0.6812217921018601.pypots
2024-05-25 02:57:40 [INFO]: Epoch 016 - training loss: 0.9043, validation loss: 0.6816
2024-05-25 02:57:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch16_loss0.6816424995660781.pypots
2024-05-25 02:57:44 [INFO]: Epoch 017 - training loss: 0.8999, validation loss: 0.6809
2024-05-25 02:57:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch17_loss0.6809155642986298.pypots
2024-05-25 02:57:48 [INFO]: Epoch 018 - training loss: 0.9206, validation loss: 0.6808
2024-05-25 02:57:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch18_loss0.6807505995035171.pypots
2024-05-25 02:57:52 [INFO]: Epoch 019 - training loss: 0.9150, validation loss: 0.6803
2024-05-25 02:57:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch19_loss0.680262279510498.pypots
2024-05-25 02:57:56 [INFO]: Epoch 020 - training loss: 0.8995, validation loss: 0.6833
2024-05-25 02:57:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch20_loss0.6832617193460464.pypots
2024-05-25 02:58:00 [INFO]: Epoch 021 - training loss: 0.8798, validation loss: 0.6843
2024-05-25 02:58:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch21_loss0.6842856079339981.pypots
2024-05-25 02:58:04 [INFO]: Epoch 022 - training loss: 0.8905, validation loss: 0.6831
2024-05-25 02:58:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch22_loss0.6830812126398087.pypots
2024-05-25 02:58:08 [INFO]: Epoch 023 - training loss: 0.8716, validation loss: 0.6844
2024-05-25 02:58:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch23_loss0.6843624472618103.pypots
2024-05-25 02:58:12 [INFO]: Epoch 024 - training loss: 0.8734, validation loss: 0.6852
2024-05-25 02:58:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch24_loss0.6852211356163025.pypots
2024-05-25 02:58:16 [INFO]: Epoch 025 - training loss: 0.8658, validation loss: 0.6865
2024-05-25 02:58:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch25_loss0.6864867359399796.pypots
2024-05-25 02:58:20 [INFO]: Epoch 026 - training loss: 0.8771, validation loss: 0.6883
2024-05-25 02:58:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch26_loss0.6882748633623124.pypots
2024-05-25 02:58:24 [INFO]: Epoch 027 - training loss: 0.8651, validation loss: 0.6915
2024-05-25 02:58:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch27_loss0.6915157437324524.pypots
2024-05-25 02:58:28 [INFO]: Epoch 028 - training loss: 0.8565, validation loss: 0.6919
2024-05-25 02:58:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch28_loss0.6918979257345199.pypots
2024-05-25 02:58:32 [INFO]: Epoch 029 - training loss: 0.8784, validation loss: 0.6910
2024-05-25 02:58:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN_epoch29_loss0.6909815639257431.pypots
2024-05-25 02:58:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:58:32 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 02:58:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_3/MRNN_air_quality/20240525_T025636/MRNN.pypots
2024-05-25 02:58:33 [INFO]: MRNN on Air-Quality: MAE=0.5283, MSE=0.6225
2024-05-25 02:58:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 02:58:33 [INFO]: Using the given device: cpu
2024-05-25 02:58:33 [INFO]: LOCF on Air-Quality: MAE=0.2195, MSE=0.2798
2024-05-25 02:58:33 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 02:58:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 02:58:33 [INFO]: Median on Air-Quality: MAE=0.6624, MSE=1.0025
2024-05-25 02:58:33 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 02:58:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 02:58:33 [INFO]: Mean on Air-Quality: MAE=0.6941, MSE=0.9443
2024-05-25 02:58:33 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 02:58:33 [INFO]: Successfully saved to overlay_postmask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 02:58:33 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 02:58:33 [INFO]: Using the given device: cuda:0
2024-05-25 02:58:33 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T025833
2024-05-25 02:58:33 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T025833/tensorboard
2024-05-25 02:58:33 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 02:58:34 [INFO]: Epoch 001 - training loss: 1.0577, validation loss: 0.5159
2024-05-25 02:58:34 [INFO]: Epoch 002 - training loss: 0.7519, validation loss: 0.4013
2024-05-25 02:58:35 [INFO]: Epoch 003 - training loss: 0.6445, validation loss: 0.3254
2024-05-25 02:58:36 [INFO]: Epoch 004 - training loss: 0.5712, validation loss: 0.2864
2024-05-25 02:58:36 [INFO]: Epoch 005 - training loss: 0.5166, validation loss: 0.2657
2024-05-25 02:58:37 [INFO]: Epoch 006 - training loss: 0.4809, validation loss: 0.2493
2024-05-25 02:58:38 [INFO]: Epoch 007 - training loss: 0.4559, validation loss: 0.2407
2024-05-25 02:58:39 [INFO]: Epoch 008 - training loss: 0.4394, validation loss: 0.2318
2024-05-25 02:58:39 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2273
2024-05-25 02:58:40 [INFO]: Epoch 010 - training loss: 0.4137, validation loss: 0.2222
2024-05-25 02:58:41 [INFO]: Epoch 011 - training loss: 0.4040, validation loss: 0.2186
2024-05-25 02:58:41 [INFO]: Epoch 012 - training loss: 0.3968, validation loss: 0.2151
2024-05-25 02:58:42 [INFO]: Epoch 013 - training loss: 0.3900, validation loss: 0.2129
2024-05-25 02:58:43 [INFO]: Epoch 014 - training loss: 0.3818, validation loss: 0.2091
2024-05-25 02:58:43 [INFO]: Epoch 015 - training loss: 0.3748, validation loss: 0.2078
2024-05-25 02:58:44 [INFO]: Epoch 016 - training loss: 0.3699, validation loss: 0.2046
2024-05-25 02:58:45 [INFO]: Epoch 017 - training loss: 0.3650, validation loss: 0.2013
2024-05-25 02:58:45 [INFO]: Epoch 018 - training loss: 0.3607, validation loss: 0.1988
2024-05-25 02:58:46 [INFO]: Epoch 019 - training loss: 0.3554, validation loss: 0.1971
2024-05-25 02:58:47 [INFO]: Epoch 020 - training loss: 0.3525, validation loss: 0.1956
2024-05-25 02:58:47 [INFO]: Epoch 021 - training loss: 0.3506, validation loss: 0.1932
2024-05-25 02:58:48 [INFO]: Epoch 022 - training loss: 0.3457, validation loss: 0.1921
2024-05-25 02:58:49 [INFO]: Epoch 023 - training loss: 0.3429, validation loss: 0.1923
2024-05-25 02:58:49 [INFO]: Epoch 024 - training loss: 0.3403, validation loss: 0.1908
2024-05-25 02:58:50 [INFO]: Epoch 025 - training loss: 0.3363, validation loss: 0.1883
2024-05-25 02:58:51 [INFO]: Epoch 026 - training loss: 0.3337, validation loss: 0.1854
2024-05-25 02:58:52 [INFO]: Epoch 027 - training loss: 0.3325, validation loss: 0.1844
2024-05-25 02:58:52 [INFO]: Epoch 028 - training loss: 0.3295, validation loss: 0.1839
2024-05-25 02:58:53 [INFO]: Epoch 029 - training loss: 0.3267, validation loss: 0.1820
2024-05-25 02:58:54 [INFO]: Epoch 030 - training loss: 0.3243, validation loss: 0.1801
2024-05-25 02:58:54 [INFO]: Epoch 031 - training loss: 0.3238, validation loss: 0.1798
2024-05-25 02:58:55 [INFO]: Epoch 032 - training loss: 0.3214, validation loss: 0.1784
2024-05-25 02:58:56 [INFO]: Epoch 033 - training loss: 0.3188, validation loss: 0.1764
2024-05-25 02:58:56 [INFO]: Epoch 034 - training loss: 0.3190, validation loss: 0.1766
2024-05-25 02:58:57 [INFO]: Epoch 035 - training loss: 0.3165, validation loss: 0.1756
2024-05-25 02:58:58 [INFO]: Epoch 036 - training loss: 0.3132, validation loss: 0.1724
2024-05-25 02:58:58 [INFO]: Epoch 037 - training loss: 0.3106, validation loss: 0.1739
2024-05-25 02:58:59 [INFO]: Epoch 038 - training loss: 0.3112, validation loss: 0.1715
2024-05-25 02:59:00 [INFO]: Epoch 039 - training loss: 0.3074, validation loss: 0.1698
2024-05-25 02:59:00 [INFO]: Epoch 040 - training loss: 0.3064, validation loss: 0.1693
2024-05-25 02:59:01 [INFO]: Epoch 041 - training loss: 0.3042, validation loss: 0.1692
2024-05-25 02:59:02 [INFO]: Epoch 042 - training loss: 0.3039, validation loss: 0.1679
2024-05-25 02:59:02 [INFO]: Epoch 043 - training loss: 0.3016, validation loss: 0.1661
2024-05-25 02:59:03 [INFO]: Epoch 044 - training loss: 0.3005, validation loss: 0.1649
2024-05-25 02:59:04 [INFO]: Epoch 045 - training loss: 0.2986, validation loss: 0.1644
2024-05-25 02:59:05 [INFO]: Epoch 046 - training loss: 0.2966, validation loss: 0.1640
2024-05-25 02:59:05 [INFO]: Epoch 047 - training loss: 0.2961, validation loss: 0.1629
2024-05-25 02:59:06 [INFO]: Epoch 048 - training loss: 0.2933, validation loss: 0.1623
2024-05-25 02:59:07 [INFO]: Epoch 049 - training loss: 0.2921, validation loss: 0.1617
2024-05-25 02:59:07 [INFO]: Epoch 050 - training loss: 0.2923, validation loss: 0.1602
2024-05-25 02:59:08 [INFO]: Epoch 051 - training loss: 0.2902, validation loss: 0.1602
2024-05-25 02:59:09 [INFO]: Epoch 052 - training loss: 0.2900, validation loss: 0.1590
2024-05-25 02:59:09 [INFO]: Epoch 053 - training loss: 0.2884, validation loss: 0.1594
2024-05-25 02:59:10 [INFO]: Epoch 054 - training loss: 0.2873, validation loss: 0.1590
2024-05-25 02:59:11 [INFO]: Epoch 055 - training loss: 0.2860, validation loss: 0.1579
2024-05-25 02:59:11 [INFO]: Epoch 056 - training loss: 0.2849, validation loss: 0.1576
2024-05-25 02:59:12 [INFO]: Epoch 057 - training loss: 0.2830, validation loss: 0.1564
2024-05-25 02:59:13 [INFO]: Epoch 058 - training loss: 0.2808, validation loss: 0.1577
2024-05-25 02:59:13 [INFO]: Epoch 059 - training loss: 0.2801, validation loss: 0.1562
2024-05-25 02:59:14 [INFO]: Epoch 060 - training loss: 0.2789, validation loss: 0.1551
2024-05-25 02:59:15 [INFO]: Epoch 061 - training loss: 0.2787, validation loss: 0.1546
2024-05-25 02:59:15 [INFO]: Epoch 062 - training loss: 0.2778, validation loss: 0.1537
2024-05-25 02:59:16 [INFO]: Epoch 063 - training loss: 0.2762, validation loss: 0.1535
2024-05-25 02:59:17 [INFO]: Epoch 064 - training loss: 0.2746, validation loss: 0.1531
2024-05-25 02:59:17 [INFO]: Epoch 065 - training loss: 0.2737, validation loss: 0.1521
2024-05-25 02:59:18 [INFO]: Epoch 066 - training loss: 0.2737, validation loss: 0.1530
2024-05-25 02:59:19 [INFO]: Epoch 067 - training loss: 0.2739, validation loss: 0.1529
2024-05-25 02:59:20 [INFO]: Epoch 068 - training loss: 0.2715, validation loss: 0.1501
2024-05-25 02:59:20 [INFO]: Epoch 069 - training loss: 0.2714, validation loss: 0.1501
2024-05-25 02:59:21 [INFO]: Epoch 070 - training loss: 0.2691, validation loss: 0.1510
2024-05-25 02:59:22 [INFO]: Epoch 071 - training loss: 0.2676, validation loss: 0.1497
2024-05-25 02:59:22 [INFO]: Epoch 072 - training loss: 0.2661, validation loss: 0.1493
2024-05-25 02:59:23 [INFO]: Epoch 073 - training loss: 0.2639, validation loss: 0.1498
2024-05-25 02:59:24 [INFO]: Epoch 074 - training loss: 0.2653, validation loss: 0.1488
2024-05-25 02:59:24 [INFO]: Epoch 075 - training loss: 0.2641, validation loss: 0.1483
2024-05-25 02:59:25 [INFO]: Epoch 076 - training loss: 0.2634, validation loss: 0.1485
2024-05-25 02:59:26 [INFO]: Epoch 077 - training loss: 0.2620, validation loss: 0.1487
2024-05-25 02:59:26 [INFO]: Epoch 078 - training loss: 0.2618, validation loss: 0.1472
2024-05-25 02:59:27 [INFO]: Epoch 079 - training loss: 0.2604, validation loss: 0.1479
2024-05-25 02:59:28 [INFO]: Epoch 080 - training loss: 0.2604, validation loss: 0.1462
2024-05-25 02:59:28 [INFO]: Epoch 081 - training loss: 0.2587, validation loss: 0.1465
2024-05-25 02:59:29 [INFO]: Epoch 082 - training loss: 0.2592, validation loss: 0.1459
2024-05-25 02:59:30 [INFO]: Epoch 083 - training loss: 0.2564, validation loss: 0.1455
2024-05-25 02:59:30 [INFO]: Epoch 084 - training loss: 0.2569, validation loss: 0.1445
2024-05-25 02:59:31 [INFO]: Epoch 085 - training loss: 0.2557, validation loss: 0.1453
2024-05-25 02:59:32 [INFO]: Epoch 086 - training loss: 0.2550, validation loss: 0.1448
2024-05-25 02:59:33 [INFO]: Epoch 087 - training loss: 0.2537, validation loss: 0.1448
2024-05-25 02:59:33 [INFO]: Epoch 088 - training loss: 0.2543, validation loss: 0.1448
2024-05-25 02:59:34 [INFO]: Epoch 089 - training loss: 0.2531, validation loss: 0.1433
2024-05-25 02:59:35 [INFO]: Epoch 090 - training loss: 0.2522, validation loss: 0.1433
2024-05-25 02:59:35 [INFO]: Epoch 091 - training loss: 0.2519, validation loss: 0.1434
2024-05-25 02:59:36 [INFO]: Epoch 092 - training loss: 0.2510, validation loss: 0.1425
2024-05-25 02:59:37 [INFO]: Epoch 093 - training loss: 0.2503, validation loss: 0.1429
2024-05-25 02:59:37 [INFO]: Epoch 094 - training loss: 0.2513, validation loss: 0.1425
2024-05-25 02:59:38 [INFO]: Epoch 095 - training loss: 0.2496, validation loss: 0.1426
2024-05-25 02:59:39 [INFO]: Epoch 096 - training loss: 0.2489, validation loss: 0.1417
2024-05-25 02:59:39 [INFO]: Epoch 097 - training loss: 0.2482, validation loss: 0.1418
2024-05-25 02:59:40 [INFO]: Epoch 098 - training loss: 0.2477, validation loss: 0.1408
2024-05-25 02:59:41 [INFO]: Epoch 099 - training loss: 0.2476, validation loss: 0.1412
2024-05-25 02:59:41 [INFO]: Epoch 100 - training loss: 0.2466, validation loss: 0.1403
2024-05-25 02:59:42 [INFO]: Epoch 101 - training loss: 0.2450, validation loss: 0.1398
2024-05-25 02:59:43 [INFO]: Epoch 102 - training loss: 0.2445, validation loss: 0.1400
2024-05-25 02:59:43 [INFO]: Epoch 103 - training loss: 0.2440, validation loss: 0.1404
2024-05-25 02:59:44 [INFO]: Epoch 104 - training loss: 0.2453, validation loss: 0.1402
2024-05-25 02:59:45 [INFO]: Epoch 105 - training loss: 0.2436, validation loss: 0.1389
2024-05-25 02:59:46 [INFO]: Epoch 106 - training loss: 0.2441, validation loss: 0.1391
2024-05-25 02:59:46 [INFO]: Epoch 107 - training loss: 0.2435, validation loss: 0.1398
2024-05-25 02:59:47 [INFO]: Epoch 108 - training loss: 0.2432, validation loss: 0.1386
2024-05-25 02:59:48 [INFO]: Epoch 109 - training loss: 0.2434, validation loss: 0.1385
2024-05-25 02:59:48 [INFO]: Epoch 110 - training loss: 0.2421, validation loss: 0.1383
2024-05-25 02:59:49 [INFO]: Epoch 111 - training loss: 0.2409, validation loss: 0.1377
2024-05-25 02:59:50 [INFO]: Epoch 112 - training loss: 0.2412, validation loss: 0.1379
2024-05-25 02:59:50 [INFO]: Epoch 113 - training loss: 0.2408, validation loss: 0.1372
2024-05-25 02:59:51 [INFO]: Epoch 114 - training loss: 0.2399, validation loss: 0.1368
2024-05-25 02:59:52 [INFO]: Epoch 115 - training loss: 0.2381, validation loss: 0.1368
2024-05-25 02:59:52 [INFO]: Epoch 116 - training loss: 0.2388, validation loss: 0.1367
2024-05-25 02:59:53 [INFO]: Epoch 117 - training loss: 0.2371, validation loss: 0.1359
2024-05-25 02:59:54 [INFO]: Epoch 118 - training loss: 0.2366, validation loss: 0.1362
2024-05-25 02:59:54 [INFO]: Epoch 119 - training loss: 0.2355, validation loss: 0.1367
2024-05-25 02:59:55 [INFO]: Epoch 120 - training loss: 0.2362, validation loss: 0.1361
2024-05-25 02:59:56 [INFO]: Epoch 121 - training loss: 0.2361, validation loss: 0.1358
2024-05-25 02:59:56 [INFO]: Epoch 122 - training loss: 0.2360, validation loss: 0.1365
2024-05-25 02:59:57 [INFO]: Epoch 123 - training loss: 0.2349, validation loss: 0.1364
2024-05-25 02:59:58 [INFO]: Epoch 124 - training loss: 0.2348, validation loss: 0.1350
2024-05-25 02:59:58 [INFO]: Epoch 125 - training loss: 0.2341, validation loss: 0.1363
2024-05-25 02:59:59 [INFO]: Epoch 126 - training loss: 0.2354, validation loss: 0.1346
2024-05-25 03:00:00 [INFO]: Epoch 127 - training loss: 0.2337, validation loss: 0.1344
2024-05-25 03:00:01 [INFO]: Epoch 128 - training loss: 0.2329, validation loss: 0.1347
2024-05-25 03:00:01 [INFO]: Epoch 129 - training loss: 0.2333, validation loss: 0.1348
2024-05-25 03:00:02 [INFO]: Epoch 130 - training loss: 0.2341, validation loss: 0.1342
2024-05-25 03:00:03 [INFO]: Epoch 131 - training loss: 0.2325, validation loss: 0.1345
2024-05-25 03:00:03 [INFO]: Epoch 132 - training loss: 0.2311, validation loss: 0.1331
2024-05-25 03:00:04 [INFO]: Epoch 133 - training loss: 0.2306, validation loss: 0.1334
2024-05-25 03:00:05 [INFO]: Epoch 134 - training loss: 0.2297, validation loss: 0.1335
2024-05-25 03:00:05 [INFO]: Epoch 135 - training loss: 0.2297, validation loss: 0.1332
2024-05-25 03:00:06 [INFO]: Epoch 136 - training loss: 0.2297, validation loss: 0.1329
2024-05-25 03:00:07 [INFO]: Epoch 137 - training loss: 0.2281, validation loss: 0.1327
2024-05-25 03:00:07 [INFO]: Epoch 138 - training loss: 0.2300, validation loss: 0.1316
2024-05-25 03:00:08 [INFO]: Epoch 139 - training loss: 0.2288, validation loss: 0.1322
2024-05-25 03:00:09 [INFO]: Epoch 140 - training loss: 0.2273, validation loss: 0.1319
2024-05-25 03:00:09 [INFO]: Epoch 141 - training loss: 0.2274, validation loss: 0.1314
2024-05-25 03:00:10 [INFO]: Epoch 142 - training loss: 0.2268, validation loss: 0.1306
2024-05-25 03:00:11 [INFO]: Epoch 143 - training loss: 0.2261, validation loss: 0.1312
2024-05-25 03:00:11 [INFO]: Epoch 144 - training loss: 0.2279, validation loss: 0.1307
2024-05-25 03:00:12 [INFO]: Epoch 145 - training loss: 0.2274, validation loss: 0.1309
2024-05-25 03:00:13 [INFO]: Epoch 146 - training loss: 0.2263, validation loss: 0.1313
2024-05-25 03:00:14 [INFO]: Epoch 147 - training loss: 0.2261, validation loss: 0.1310
2024-05-25 03:00:14 [INFO]: Epoch 148 - training loss: 0.2253, validation loss: 0.1297
2024-05-25 03:00:15 [INFO]: Epoch 149 - training loss: 0.2252, validation loss: 0.1307
2024-05-25 03:00:16 [INFO]: Epoch 150 - training loss: 0.2249, validation loss: 0.1299
2024-05-25 03:00:16 [INFO]: Epoch 151 - training loss: 0.2233, validation loss: 0.1298
2024-05-25 03:00:17 [INFO]: Epoch 152 - training loss: 0.2223, validation loss: 0.1301
2024-05-25 03:00:18 [INFO]: Epoch 153 - training loss: 0.2226, validation loss: 0.1292
2024-05-25 03:00:18 [INFO]: Epoch 154 - training loss: 0.2231, validation loss: 0.1300
2024-05-25 03:00:19 [INFO]: Epoch 155 - training loss: 0.2234, validation loss: 0.1291
2024-05-25 03:00:20 [INFO]: Epoch 156 - training loss: 0.2232, validation loss: 0.1286
2024-05-25 03:00:20 [INFO]: Epoch 157 - training loss: 0.2230, validation loss: 0.1286
2024-05-25 03:00:21 [INFO]: Epoch 158 - training loss: 0.2223, validation loss: 0.1288
2024-05-25 03:00:22 [INFO]: Epoch 159 - training loss: 0.2220, validation loss: 0.1290
2024-05-25 03:00:22 [INFO]: Epoch 160 - training loss: 0.2216, validation loss: 0.1281
2024-05-25 03:00:23 [INFO]: Epoch 161 - training loss: 0.2205, validation loss: 0.1286
2024-05-25 03:00:24 [INFO]: Epoch 162 - training loss: 0.2194, validation loss: 0.1281
2024-05-25 03:00:24 [INFO]: Epoch 163 - training loss: 0.2200, validation loss: 0.1284
2024-05-25 03:00:25 [INFO]: Epoch 164 - training loss: 0.2196, validation loss: 0.1282
2024-05-25 03:00:26 [INFO]: Epoch 165 - training loss: 0.2193, validation loss: 0.1279
2024-05-25 03:00:27 [INFO]: Epoch 166 - training loss: 0.2188, validation loss: 0.1271
2024-05-25 03:00:27 [INFO]: Epoch 167 - training loss: 0.2192, validation loss: 0.1281
2024-05-25 03:00:28 [INFO]: Epoch 168 - training loss: 0.2193, validation loss: 0.1268
2024-05-25 03:00:29 [INFO]: Epoch 169 - training loss: 0.2179, validation loss: 0.1268
2024-05-25 03:00:29 [INFO]: Epoch 170 - training loss: 0.2175, validation loss: 0.1260
2024-05-25 03:00:30 [INFO]: Epoch 171 - training loss: 0.2189, validation loss: 0.1267
2024-05-25 03:00:31 [INFO]: Epoch 172 - training loss: 0.2196, validation loss: 0.1265
2024-05-25 03:00:31 [INFO]: Epoch 173 - training loss: 0.2185, validation loss: 0.1270
2024-05-25 03:00:32 [INFO]: Epoch 174 - training loss: 0.2177, validation loss: 0.1258
2024-05-25 03:00:33 [INFO]: Epoch 175 - training loss: 0.2159, validation loss: 0.1267
2024-05-25 03:00:33 [INFO]: Epoch 176 - training loss: 0.2154, validation loss: 0.1266
2024-05-25 03:00:34 [INFO]: Epoch 177 - training loss: 0.2148, validation loss: 0.1259
2024-05-25 03:00:35 [INFO]: Epoch 178 - training loss: 0.2154, validation loss: 0.1259
2024-05-25 03:00:35 [INFO]: Epoch 179 - training loss: 0.2153, validation loss: 0.1255
2024-05-25 03:00:36 [INFO]: Epoch 180 - training loss: 0.2138, validation loss: 0.1252
2024-05-25 03:00:37 [INFO]: Epoch 181 - training loss: 0.2146, validation loss: 0.1250
2024-05-25 03:00:37 [INFO]: Epoch 182 - training loss: 0.2162, validation loss: 0.1258
2024-05-25 03:00:38 [INFO]: Epoch 183 - training loss: 0.2150, validation loss: 0.1253
2024-05-25 03:00:39 [INFO]: Epoch 184 - training loss: 0.2136, validation loss: 0.1253
2024-05-25 03:00:39 [INFO]: Epoch 185 - training loss: 0.2119, validation loss: 0.1251
2024-05-25 03:00:40 [INFO]: Epoch 186 - training loss: 0.2125, validation loss: 0.1250
2024-05-25 03:00:41 [INFO]: Epoch 187 - training loss: 0.2136, validation loss: 0.1247
2024-05-25 03:00:41 [INFO]: Epoch 188 - training loss: 0.2139, validation loss: 0.1247
2024-05-25 03:00:42 [INFO]: Epoch 189 - training loss: 0.2124, validation loss: 0.1244
2024-05-25 03:00:43 [INFO]: Epoch 190 - training loss: 0.2135, validation loss: 0.1246
2024-05-25 03:00:44 [INFO]: Epoch 191 - training loss: 0.2114, validation loss: 0.1240
2024-05-25 03:00:44 [INFO]: Epoch 192 - training loss: 0.2109, validation loss: 0.1231
2024-05-25 03:00:45 [INFO]: Epoch 193 - training loss: 0.2103, validation loss: 0.1232
2024-05-25 03:00:46 [INFO]: Epoch 194 - training loss: 0.2104, validation loss: 0.1239
2024-05-25 03:00:46 [INFO]: Epoch 195 - training loss: 0.2111, validation loss: 0.1230
2024-05-25 03:00:47 [INFO]: Epoch 196 - training loss: 0.2109, validation loss: 0.1237
2024-05-25 03:00:48 [INFO]: Epoch 197 - training loss: 0.2110, validation loss: 0.1233
2024-05-25 03:00:48 [INFO]: Epoch 198 - training loss: 0.2101, validation loss: 0.1248
2024-05-25 03:00:49 [INFO]: Epoch 199 - training loss: 0.2112, validation loss: 0.1229
2024-05-25 03:00:50 [INFO]: Epoch 200 - training loss: 0.2092, validation loss: 0.1228
2024-05-25 03:00:50 [INFO]: Epoch 201 - training loss: 0.2102, validation loss: 0.1229
2024-05-25 03:00:51 [INFO]: Epoch 202 - training loss: 0.2095, validation loss: 0.1230
2024-05-25 03:00:52 [INFO]: Epoch 203 - training loss: 0.2087, validation loss: 0.1220
2024-05-25 03:00:52 [INFO]: Epoch 204 - training loss: 0.2087, validation loss: 0.1230
2024-05-25 03:00:53 [INFO]: Epoch 205 - training loss: 0.2082, validation loss: 0.1224
2024-05-25 03:00:54 [INFO]: Epoch 206 - training loss: 0.2075, validation loss: 0.1219
2024-05-25 03:00:54 [INFO]: Epoch 207 - training loss: 0.2080, validation loss: 0.1223
2024-05-25 03:00:55 [INFO]: Epoch 208 - training loss: 0.2076, validation loss: 0.1231
2024-05-25 03:00:56 [INFO]: Epoch 209 - training loss: 0.2080, validation loss: 0.1217
2024-05-25 03:00:56 [INFO]: Epoch 210 - training loss: 0.2058, validation loss: 0.1219
2024-05-25 03:00:57 [INFO]: Epoch 211 - training loss: 0.2068, validation loss: 0.1220
2024-05-25 03:00:58 [INFO]: Epoch 212 - training loss: 0.2070, validation loss: 0.1220
2024-05-25 03:00:58 [INFO]: Epoch 213 - training loss: 0.2068, validation loss: 0.1209
2024-05-25 03:00:59 [INFO]: Epoch 214 - training loss: 0.2068, validation loss: 0.1211
2024-05-25 03:01:00 [INFO]: Epoch 215 - training loss: 0.2060, validation loss: 0.1217
2024-05-25 03:01:00 [INFO]: Epoch 216 - training loss: 0.2061, validation loss: 0.1212
2024-05-25 03:01:01 [INFO]: Epoch 217 - training loss: 0.2082, validation loss: 0.1222
2024-05-25 03:01:02 [INFO]: Epoch 218 - training loss: 0.2070, validation loss: 0.1211
2024-05-25 03:01:02 [INFO]: Epoch 219 - training loss: 0.2063, validation loss: 0.1206
2024-05-25 03:01:03 [INFO]: Epoch 220 - training loss: 0.2057, validation loss: 0.1206
2024-05-25 03:01:04 [INFO]: Epoch 221 - training loss: 0.2040, validation loss: 0.1206
2024-05-25 03:01:04 [INFO]: Epoch 222 - training loss: 0.2035, validation loss: 0.1195
2024-05-25 03:01:05 [INFO]: Epoch 223 - training loss: 0.2042, validation loss: 0.1201
2024-05-25 03:01:06 [INFO]: Epoch 224 - training loss: 0.2030, validation loss: 0.1212
2024-05-25 03:01:06 [INFO]: Epoch 225 - training loss: 0.2021, validation loss: 0.1203
2024-05-25 03:01:07 [INFO]: Epoch 226 - training loss: 0.2044, validation loss: 0.1200
2024-05-25 03:01:08 [INFO]: Epoch 227 - training loss: 0.2049, validation loss: 0.1202
2024-05-25 03:01:08 [INFO]: Epoch 228 - training loss: 0.2053, validation loss: 0.1205
2024-05-25 03:01:09 [INFO]: Epoch 229 - training loss: 0.2030, validation loss: 0.1194
2024-05-25 03:01:10 [INFO]: Epoch 230 - training loss: 0.2033, validation loss: 0.1193
2024-05-25 03:01:10 [INFO]: Epoch 231 - training loss: 0.2021, validation loss: 0.1190
2024-05-25 03:01:11 [INFO]: Epoch 232 - training loss: 0.2057, validation loss: 0.1205
2024-05-25 03:01:12 [INFO]: Epoch 233 - training loss: 0.2039, validation loss: 0.1193
2024-05-25 03:01:12 [INFO]: Epoch 234 - training loss: 0.2029, validation loss: 0.1197
2024-05-25 03:01:13 [INFO]: Epoch 235 - training loss: 0.2034, validation loss: 0.1195
2024-05-25 03:01:14 [INFO]: Epoch 236 - training loss: 0.2030, validation loss: 0.1197
2024-05-25 03:01:14 [INFO]: Epoch 237 - training loss: 0.2053, validation loss: 0.1196
2024-05-25 03:01:15 [INFO]: Epoch 238 - training loss: 0.2017, validation loss: 0.1190
2024-05-25 03:01:16 [INFO]: Epoch 239 - training loss: 0.2000, validation loss: 0.1187
2024-05-25 03:01:17 [INFO]: Epoch 240 - training loss: 0.1992, validation loss: 0.1185
2024-05-25 03:01:17 [INFO]: Epoch 241 - training loss: 0.2003, validation loss: 0.1189
2024-05-25 03:01:18 [INFO]: Epoch 242 - training loss: 0.2003, validation loss: 0.1194
2024-05-25 03:01:19 [INFO]: Epoch 243 - training loss: 0.1990, validation loss: 0.1188
2024-05-25 03:01:19 [INFO]: Epoch 244 - training loss: 0.1987, validation loss: 0.1190
2024-05-25 03:01:20 [INFO]: Epoch 245 - training loss: 0.1997, validation loss: 0.1195
2024-05-25 03:01:21 [INFO]: Epoch 246 - training loss: 0.1992, validation loss: 0.1187
2024-05-25 03:01:21 [INFO]: Epoch 247 - training loss: 0.1991, validation loss: 0.1193
2024-05-25 03:01:22 [INFO]: Epoch 248 - training loss: 0.2003, validation loss: 0.1192
2024-05-25 03:01:23 [INFO]: Epoch 249 - training loss: 0.2012, validation loss: 0.1184
2024-05-25 03:01:23 [INFO]: Epoch 250 - training loss: 0.1989, validation loss: 0.1183
2024-05-25 03:01:24 [INFO]: Epoch 251 - training loss: 0.1988, validation loss: 0.1178
2024-05-25 03:01:25 [INFO]: Epoch 252 - training loss: 0.1990, validation loss: 0.1190
2024-05-25 03:01:25 [INFO]: Epoch 253 - training loss: 0.1981, validation loss: 0.1197
2024-05-25 03:01:26 [INFO]: Epoch 254 - training loss: 0.1985, validation loss: 0.1185
2024-05-25 03:01:27 [INFO]: Epoch 255 - training loss: 0.1968, validation loss: 0.1183
2024-05-25 03:01:27 [INFO]: Epoch 256 - training loss: 0.1969, validation loss: 0.1179
2024-05-25 03:01:28 [INFO]: Epoch 257 - training loss: 0.1978, validation loss: 0.1179
2024-05-25 03:01:29 [INFO]: Epoch 258 - training loss: 0.1974, validation loss: 0.1188
2024-05-25 03:01:30 [INFO]: Epoch 259 - training loss: 0.1981, validation loss: 0.1179
2024-05-25 03:01:30 [INFO]: Epoch 260 - training loss: 0.1976, validation loss: 0.1182
2024-05-25 03:01:31 [INFO]: Epoch 261 - training loss: 0.1976, validation loss: 0.1175
2024-05-25 03:01:32 [INFO]: Epoch 262 - training loss: 0.1972, validation loss: 0.1178
2024-05-25 03:01:32 [INFO]: Epoch 263 - training loss: 0.1974, validation loss: 0.1174
2024-05-25 03:01:33 [INFO]: Epoch 264 - training loss: 0.1961, validation loss: 0.1173
2024-05-25 03:01:34 [INFO]: Epoch 265 - training loss: 0.1955, validation loss: 0.1185
2024-05-25 03:01:34 [INFO]: Epoch 266 - training loss: 0.1956, validation loss: 0.1176
2024-05-25 03:01:35 [INFO]: Epoch 267 - training loss: 0.1948, validation loss: 0.1180
2024-05-25 03:01:36 [INFO]: Epoch 268 - training loss: 0.1955, validation loss: 0.1176
2024-05-25 03:01:36 [INFO]: Epoch 269 - training loss: 0.1939, validation loss: 0.1180
2024-05-25 03:01:37 [INFO]: Epoch 270 - training loss: 0.1947, validation loss: 0.1177
2024-05-25 03:01:38 [INFO]: Epoch 271 - training loss: 0.1951, validation loss: 0.1173
2024-05-25 03:01:38 [INFO]: Epoch 272 - training loss: 0.1959, validation loss: 0.1180
2024-05-25 03:01:39 [INFO]: Epoch 273 - training loss: 0.1972, validation loss: 0.1188
2024-05-25 03:01:40 [INFO]: Epoch 274 - training loss: 0.1996, validation loss: 0.1168
2024-05-25 03:01:40 [INFO]: Epoch 275 - training loss: 0.1951, validation loss: 0.1170
2024-05-25 03:01:41 [INFO]: Epoch 276 - training loss: 0.1939, validation loss: 0.1171
2024-05-25 03:01:42 [INFO]: Epoch 277 - training loss: 0.1934, validation loss: 0.1166
2024-05-25 03:01:43 [INFO]: Epoch 278 - training loss: 0.1924, validation loss: 0.1170
2024-05-25 03:01:43 [INFO]: Epoch 279 - training loss: 0.1929, validation loss: 0.1170
2024-05-25 03:01:44 [INFO]: Epoch 280 - training loss: 0.1923, validation loss: 0.1164
2024-05-25 03:01:45 [INFO]: Epoch 281 - training loss: 0.1917, validation loss: 0.1178
2024-05-25 03:01:45 [INFO]: Epoch 282 - training loss: 0.1930, validation loss: 0.1172
2024-05-25 03:01:46 [INFO]: Epoch 283 - training loss: 0.1930, validation loss: 0.1173
2024-05-25 03:01:47 [INFO]: Epoch 284 - training loss: 0.1927, validation loss: 0.1177
2024-05-25 03:01:47 [INFO]: Epoch 285 - training loss: 0.1938, validation loss: 0.1189
2024-05-25 03:01:48 [INFO]: Epoch 286 - training loss: 0.1934, validation loss: 0.1184
2024-05-25 03:01:49 [INFO]: Epoch 287 - training loss: 0.1922, validation loss: 0.1182
2024-05-25 03:01:49 [INFO]: Epoch 288 - training loss: 0.1923, validation loss: 0.1175
2024-05-25 03:01:50 [INFO]: Epoch 289 - training loss: 0.1902, validation loss: 0.1180
2024-05-25 03:01:51 [INFO]: Epoch 290 - training loss: 0.1907, validation loss: 0.1171
2024-05-25 03:01:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:01:51 [INFO]: Finished training. The best model is from epoch#280.
2024-05-25 03:01:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/SAITS_air_quality/20240525_T025833/SAITS.pypots
2024-05-25 03:01:51 [INFO]: SAITS on Air-Quality: MAE=0.1451, MSE=0.1069
2024-05-25 03:01:51 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 03:01:51 [INFO]: Using the given device: cuda:0
2024-05-25 03:01:51 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T030151
2024-05-25 03:01:51 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T030151/tensorboard
2024-05-25 03:01:51 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:01:51 [INFO]: Epoch 001 - training loss: 0.9118, validation loss: 0.4794
2024-05-25 03:01:52 [INFO]: Epoch 002 - training loss: 0.5865, validation loss: 0.3686
2024-05-25 03:01:52 [INFO]: Epoch 003 - training loss: 0.4927, validation loss: 0.3042
2024-05-25 03:01:52 [INFO]: Epoch 004 - training loss: 0.4406, validation loss: 0.2726
2024-05-25 03:01:53 [INFO]: Epoch 005 - training loss: 0.4135, validation loss: 0.2647
2024-05-25 03:01:53 [INFO]: Epoch 006 - training loss: 0.3948, validation loss: 0.2488
2024-05-25 03:01:53 [INFO]: Epoch 007 - training loss: 0.3799, validation loss: 0.2431
2024-05-25 03:01:54 [INFO]: Epoch 008 - training loss: 0.3681, validation loss: 0.2377
2024-05-25 03:01:54 [INFO]: Epoch 009 - training loss: 0.3601, validation loss: 0.2327
2024-05-25 03:01:54 [INFO]: Epoch 010 - training loss: 0.3481, validation loss: 0.2273
2024-05-25 03:01:55 [INFO]: Epoch 011 - training loss: 0.3412, validation loss: 0.2227
2024-05-25 03:01:55 [INFO]: Epoch 012 - training loss: 0.3358, validation loss: 0.2188
2024-05-25 03:01:55 [INFO]: Epoch 013 - training loss: 0.3335, validation loss: 0.2178
2024-05-25 03:01:56 [INFO]: Epoch 014 - training loss: 0.3299, validation loss: 0.2158
2024-05-25 03:01:56 [INFO]: Epoch 015 - training loss: 0.3239, validation loss: 0.2117
2024-05-25 03:01:56 [INFO]: Epoch 016 - training loss: 0.3195, validation loss: 0.2086
2024-05-25 03:01:56 [INFO]: Epoch 017 - training loss: 0.3181, validation loss: 0.2060
2024-05-25 03:01:57 [INFO]: Epoch 018 - training loss: 0.3143, validation loss: 0.2044
2024-05-25 03:01:57 [INFO]: Epoch 019 - training loss: 0.3102, validation loss: 0.2019
2024-05-25 03:01:57 [INFO]: Epoch 020 - training loss: 0.3062, validation loss: 0.1998
2024-05-25 03:01:58 [INFO]: Epoch 021 - training loss: 0.3037, validation loss: 0.1958
2024-05-25 03:01:58 [INFO]: Epoch 022 - training loss: 0.3020, validation loss: 0.1969
2024-05-25 03:01:58 [INFO]: Epoch 023 - training loss: 0.3005, validation loss: 0.1924
2024-05-25 03:01:59 [INFO]: Epoch 024 - training loss: 0.3000, validation loss: 0.1907
2024-05-25 03:01:59 [INFO]: Epoch 025 - training loss: 0.2963, validation loss: 0.1909
2024-05-25 03:01:59 [INFO]: Epoch 026 - training loss: 0.2931, validation loss: 0.1901
2024-05-25 03:02:00 [INFO]: Epoch 027 - training loss: 0.2929, validation loss: 0.1891
2024-05-25 03:02:00 [INFO]: Epoch 028 - training loss: 0.2980, validation loss: 0.1857
2024-05-25 03:02:00 [INFO]: Epoch 029 - training loss: 0.2914, validation loss: 0.1865
2024-05-25 03:02:01 [INFO]: Epoch 030 - training loss: 0.2850, validation loss: 0.1879
2024-05-25 03:02:01 [INFO]: Epoch 031 - training loss: 0.2852, validation loss: 0.1850
2024-05-25 03:02:01 [INFO]: Epoch 032 - training loss: 0.2818, validation loss: 0.1830
2024-05-25 03:02:02 [INFO]: Epoch 033 - training loss: 0.2833, validation loss: 0.1831
2024-05-25 03:02:02 [INFO]: Epoch 034 - training loss: 0.2812, validation loss: 0.1844
2024-05-25 03:02:02 [INFO]: Epoch 035 - training loss: 0.2801, validation loss: 0.1812
2024-05-25 03:02:03 [INFO]: Epoch 036 - training loss: 0.2792, validation loss: 0.1835
2024-05-25 03:02:03 [INFO]: Epoch 037 - training loss: 0.2761, validation loss: 0.1815
2024-05-25 03:02:03 [INFO]: Epoch 038 - training loss: 0.2780, validation loss: 0.1822
2024-05-25 03:02:04 [INFO]: Epoch 039 - training loss: 0.2767, validation loss: 0.1806
2024-05-25 03:02:04 [INFO]: Epoch 040 - training loss: 0.2752, validation loss: 0.1790
2024-05-25 03:02:04 [INFO]: Epoch 041 - training loss: 0.2752, validation loss: 0.1792
2024-05-25 03:02:05 [INFO]: Epoch 042 - training loss: 0.2702, validation loss: 0.1809
2024-05-25 03:02:05 [INFO]: Epoch 043 - training loss: 0.2711, validation loss: 0.1804
2024-05-25 03:02:05 [INFO]: Epoch 044 - training loss: 0.2696, validation loss: 0.1787
2024-05-25 03:02:06 [INFO]: Epoch 045 - training loss: 0.2684, validation loss: 0.1759
2024-05-25 03:02:06 [INFO]: Epoch 046 - training loss: 0.2665, validation loss: 0.1783
2024-05-25 03:02:06 [INFO]: Epoch 047 - training loss: 0.2664, validation loss: 0.1739
2024-05-25 03:02:07 [INFO]: Epoch 048 - training loss: 0.2652, validation loss: 0.1759
2024-05-25 03:02:07 [INFO]: Epoch 049 - training loss: 0.2660, validation loss: 0.1755
2024-05-25 03:02:07 [INFO]: Epoch 050 - training loss: 0.2659, validation loss: 0.1748
2024-05-25 03:02:07 [INFO]: Epoch 051 - training loss: 0.2635, validation loss: 0.1772
2024-05-25 03:02:08 [INFO]: Epoch 052 - training loss: 0.2628, validation loss: 0.1781
2024-05-25 03:02:08 [INFO]: Epoch 053 - training loss: 0.2631, validation loss: 0.1775
2024-05-25 03:02:08 [INFO]: Epoch 054 - training loss: 0.2616, validation loss: 0.1776
2024-05-25 03:02:09 [INFO]: Epoch 055 - training loss: 0.2584, validation loss: 0.1726
2024-05-25 03:02:09 [INFO]: Epoch 056 - training loss: 0.2577, validation loss: 0.1715
2024-05-25 03:02:09 [INFO]: Epoch 057 - training loss: 0.2567, validation loss: 0.1741
2024-05-25 03:02:10 [INFO]: Epoch 058 - training loss: 0.2573, validation loss: 0.1736
2024-05-25 03:02:10 [INFO]: Epoch 059 - training loss: 0.2563, validation loss: 0.1726
2024-05-25 03:02:10 [INFO]: Epoch 060 - training loss: 0.2629, validation loss: 0.1756
2024-05-25 03:02:11 [INFO]: Epoch 061 - training loss: 0.2570, validation loss: 0.1721
2024-05-25 03:02:11 [INFO]: Epoch 062 - training loss: 0.2545, validation loss: 0.1712
2024-05-25 03:02:11 [INFO]: Epoch 063 - training loss: 0.2537, validation loss: 0.1713
2024-05-25 03:02:12 [INFO]: Epoch 064 - training loss: 0.2514, validation loss: 0.1724
2024-05-25 03:02:12 [INFO]: Epoch 065 - training loss: 0.2502, validation loss: 0.1711
2024-05-25 03:02:12 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1712
2024-05-25 03:02:13 [INFO]: Epoch 067 - training loss: 0.2513, validation loss: 0.1682
2024-05-25 03:02:13 [INFO]: Epoch 068 - training loss: 0.2500, validation loss: 0.1710
2024-05-25 03:02:13 [INFO]: Epoch 069 - training loss: 0.2473, validation loss: 0.1696
2024-05-25 03:02:14 [INFO]: Epoch 070 - training loss: 0.2463, validation loss: 0.1702
2024-05-25 03:02:14 [INFO]: Epoch 071 - training loss: 0.2478, validation loss: 0.1681
2024-05-25 03:02:14 [INFO]: Epoch 072 - training loss: 0.2462, validation loss: 0.1711
2024-05-25 03:02:15 [INFO]: Epoch 073 - training loss: 0.2475, validation loss: 0.1688
2024-05-25 03:02:15 [INFO]: Epoch 074 - training loss: 0.2459, validation loss: 0.1685
2024-05-25 03:02:15 [INFO]: Epoch 075 - training loss: 0.2456, validation loss: 0.1675
2024-05-25 03:02:16 [INFO]: Epoch 076 - training loss: 0.2434, validation loss: 0.1718
2024-05-25 03:02:16 [INFO]: Epoch 077 - training loss: 0.2439, validation loss: 0.1678
2024-05-25 03:02:16 [INFO]: Epoch 078 - training loss: 0.2419, validation loss: 0.1677
2024-05-25 03:02:17 [INFO]: Epoch 079 - training loss: 0.2412, validation loss: 0.1669
2024-05-25 03:02:17 [INFO]: Epoch 080 - training loss: 0.2394, validation loss: 0.1679
2024-05-25 03:02:17 [INFO]: Epoch 081 - training loss: 0.2406, validation loss: 0.1683
2024-05-25 03:02:18 [INFO]: Epoch 082 - training loss: 0.2397, validation loss: 0.1679
2024-05-25 03:02:18 [INFO]: Epoch 083 - training loss: 0.2394, validation loss: 0.1653
2024-05-25 03:02:18 [INFO]: Epoch 084 - training loss: 0.2404, validation loss: 0.1655
2024-05-25 03:02:19 [INFO]: Epoch 085 - training loss: 0.2381, validation loss: 0.1656
2024-05-25 03:02:19 [INFO]: Epoch 086 - training loss: 0.2421, validation loss: 0.1645
2024-05-25 03:02:19 [INFO]: Epoch 087 - training loss: 0.2414, validation loss: 0.1652
2024-05-25 03:02:19 [INFO]: Epoch 088 - training loss: 0.2354, validation loss: 0.1664
2024-05-25 03:02:20 [INFO]: Epoch 089 - training loss: 0.2365, validation loss: 0.1634
2024-05-25 03:02:20 [INFO]: Epoch 090 - training loss: 0.2372, validation loss: 0.1676
2024-05-25 03:02:20 [INFO]: Epoch 091 - training loss: 0.2390, validation loss: 0.1646
2024-05-25 03:02:21 [INFO]: Epoch 092 - training loss: 0.2331, validation loss: 0.1630
2024-05-25 03:02:21 [INFO]: Epoch 093 - training loss: 0.2344, validation loss: 0.1634
2024-05-25 03:02:21 [INFO]: Epoch 094 - training loss: 0.2338, validation loss: 0.1643
2024-05-25 03:02:22 [INFO]: Epoch 095 - training loss: 0.2333, validation loss: 0.1619
2024-05-25 03:02:22 [INFO]: Epoch 096 - training loss: 0.2313, validation loss: 0.1617
2024-05-25 03:02:22 [INFO]: Epoch 097 - training loss: 0.2315, validation loss: 0.1625
2024-05-25 03:02:23 [INFO]: Epoch 098 - training loss: 0.2324, validation loss: 0.1616
2024-05-25 03:02:23 [INFO]: Epoch 099 - training loss: 0.2325, validation loss: 0.1621
2024-05-25 03:02:23 [INFO]: Epoch 100 - training loss: 0.2356, validation loss: 0.1618
2024-05-25 03:02:24 [INFO]: Epoch 101 - training loss: 0.2322, validation loss: 0.1626
2024-05-25 03:02:24 [INFO]: Epoch 102 - training loss: 0.2288, validation loss: 0.1602
2024-05-25 03:02:24 [INFO]: Epoch 103 - training loss: 0.2298, validation loss: 0.1607
2024-05-25 03:02:25 [INFO]: Epoch 104 - training loss: 0.2306, validation loss: 0.1601
2024-05-25 03:02:25 [INFO]: Epoch 105 - training loss: 0.2262, validation loss: 0.1610
2024-05-25 03:02:25 [INFO]: Epoch 106 - training loss: 0.2256, validation loss: 0.1626
2024-05-25 03:02:26 [INFO]: Epoch 107 - training loss: 0.2270, validation loss: 0.1588
2024-05-25 03:02:26 [INFO]: Epoch 108 - training loss: 0.2256, validation loss: 0.1596
2024-05-25 03:02:26 [INFO]: Epoch 109 - training loss: 0.2269, validation loss: 0.1582
2024-05-25 03:02:27 [INFO]: Epoch 110 - training loss: 0.2249, validation loss: 0.1589
2024-05-25 03:02:27 [INFO]: Epoch 111 - training loss: 0.2228, validation loss: 0.1599
2024-05-25 03:02:27 [INFO]: Epoch 112 - training loss: 0.2238, validation loss: 0.1615
2024-05-25 03:02:28 [INFO]: Epoch 113 - training loss: 0.2250, validation loss: 0.1578
2024-05-25 03:02:28 [INFO]: Epoch 114 - training loss: 0.2285, validation loss: 0.1594
2024-05-25 03:02:28 [INFO]: Epoch 115 - training loss: 0.2265, validation loss: 0.1603
2024-05-25 03:02:28 [INFO]: Epoch 116 - training loss: 0.2235, validation loss: 0.1589
2024-05-25 03:02:29 [INFO]: Epoch 117 - training loss: 0.2234, validation loss: 0.1588
2024-05-25 03:02:29 [INFO]: Epoch 118 - training loss: 0.2216, validation loss: 0.1563
2024-05-25 03:02:29 [INFO]: Epoch 119 - training loss: 0.2211, validation loss: 0.1577
2024-05-25 03:02:30 [INFO]: Epoch 120 - training loss: 0.2224, validation loss: 0.1553
2024-05-25 03:02:30 [INFO]: Epoch 121 - training loss: 0.2238, validation loss: 0.1561
2024-05-25 03:02:30 [INFO]: Epoch 122 - training loss: 0.2207, validation loss: 0.1566
2024-05-25 03:02:31 [INFO]: Epoch 123 - training loss: 0.2182, validation loss: 0.1553
2024-05-25 03:02:31 [INFO]: Epoch 124 - training loss: 0.2183, validation loss: 0.1559
2024-05-25 03:02:31 [INFO]: Epoch 125 - training loss: 0.2192, validation loss: 0.1572
2024-05-25 03:02:32 [INFO]: Epoch 126 - training loss: 0.2199, validation loss: 0.1563
2024-05-25 03:02:32 [INFO]: Epoch 127 - training loss: 0.2193, validation loss: 0.1587
2024-05-25 03:02:32 [INFO]: Epoch 128 - training loss: 0.2187, validation loss: 0.1555
2024-05-25 03:02:33 [INFO]: Epoch 129 - training loss: 0.2181, validation loss: 0.1546
2024-05-25 03:02:33 [INFO]: Epoch 130 - training loss: 0.2158, validation loss: 0.1552
2024-05-25 03:02:33 [INFO]: Epoch 131 - training loss: 0.2145, validation loss: 0.1555
2024-05-25 03:02:34 [INFO]: Epoch 132 - training loss: 0.2151, validation loss: 0.1538
2024-05-25 03:02:34 [INFO]: Epoch 133 - training loss: 0.2171, validation loss: 0.1537
2024-05-25 03:02:34 [INFO]: Epoch 134 - training loss: 0.2177, validation loss: 0.1554
2024-05-25 03:02:35 [INFO]: Epoch 135 - training loss: 0.2147, validation loss: 0.1544
2024-05-25 03:02:35 [INFO]: Epoch 136 - training loss: 0.2155, validation loss: 0.1535
2024-05-25 03:02:35 [INFO]: Epoch 137 - training loss: 0.2155, validation loss: 0.1546
2024-05-25 03:02:36 [INFO]: Epoch 138 - training loss: 0.2132, validation loss: 0.1532
2024-05-25 03:02:36 [INFO]: Epoch 139 - training loss: 0.2141, validation loss: 0.1533
2024-05-25 03:02:36 [INFO]: Epoch 140 - training loss: 0.2139, validation loss: 0.1535
2024-05-25 03:02:37 [INFO]: Epoch 141 - training loss: 0.2112, validation loss: 0.1524
2024-05-25 03:02:37 [INFO]: Epoch 142 - training loss: 0.2115, validation loss: 0.1532
2024-05-25 03:02:37 [INFO]: Epoch 143 - training loss: 0.2110, validation loss: 0.1517
2024-05-25 03:02:38 [INFO]: Epoch 144 - training loss: 0.2106, validation loss: 0.1522
2024-05-25 03:02:38 [INFO]: Epoch 145 - training loss: 0.2112, validation loss: 0.1522
2024-05-25 03:02:38 [INFO]: Epoch 146 - training loss: 0.2117, validation loss: 0.1540
2024-05-25 03:02:39 [INFO]: Epoch 147 - training loss: 0.2119, validation loss: 0.1521
2024-05-25 03:02:39 [INFO]: Epoch 148 - training loss: 0.2107, validation loss: 0.1537
2024-05-25 03:02:39 [INFO]: Epoch 149 - training loss: 0.2104, validation loss: 0.1515
2024-05-25 03:02:40 [INFO]: Epoch 150 - training loss: 0.2107, validation loss: 0.1536
2024-05-25 03:02:40 [INFO]: Epoch 151 - training loss: 0.2107, validation loss: 0.1534
2024-05-25 03:02:40 [INFO]: Epoch 152 - training loss: 0.2115, validation loss: 0.1513
2024-05-25 03:02:40 [INFO]: Epoch 153 - training loss: 0.2104, validation loss: 0.1520
2024-05-25 03:02:41 [INFO]: Epoch 154 - training loss: 0.2095, validation loss: 0.1528
2024-05-25 03:02:41 [INFO]: Epoch 155 - training loss: 0.2094, validation loss: 0.1519
2024-05-25 03:02:41 [INFO]: Epoch 156 - training loss: 0.2138, validation loss: 0.1545
2024-05-25 03:02:42 [INFO]: Epoch 157 - training loss: 0.2103, validation loss: 0.1494
2024-05-25 03:02:42 [INFO]: Epoch 158 - training loss: 0.2095, validation loss: 0.1506
2024-05-25 03:02:42 [INFO]: Epoch 159 - training loss: 0.2081, validation loss: 0.1500
2024-05-25 03:02:43 [INFO]: Epoch 160 - training loss: 0.2047, validation loss: 0.1517
2024-05-25 03:02:43 [INFO]: Epoch 161 - training loss: 0.2064, validation loss: 0.1502
2024-05-25 03:02:43 [INFO]: Epoch 162 - training loss: 0.2053, validation loss: 0.1507
2024-05-25 03:02:44 [INFO]: Epoch 163 - training loss: 0.2061, validation loss: 0.1490
2024-05-25 03:02:44 [INFO]: Epoch 164 - training loss: 0.2059, validation loss: 0.1492
2024-05-25 03:02:44 [INFO]: Epoch 165 - training loss: 0.2045, validation loss: 0.1497
2024-05-25 03:02:45 [INFO]: Epoch 166 - training loss: 0.2044, validation loss: 0.1488
2024-05-25 03:02:45 [INFO]: Epoch 167 - training loss: 0.2066, validation loss: 0.1483
2024-05-25 03:02:45 [INFO]: Epoch 168 - training loss: 0.2042, validation loss: 0.1495
2024-05-25 03:02:46 [INFO]: Epoch 169 - training loss: 0.2032, validation loss: 0.1503
2024-05-25 03:02:46 [INFO]: Epoch 170 - training loss: 0.2057, validation loss: 0.1493
2024-05-25 03:02:46 [INFO]: Epoch 171 - training loss: 0.2059, validation loss: 0.1492
2024-05-25 03:02:47 [INFO]: Epoch 172 - training loss: 0.2048, validation loss: 0.1465
2024-05-25 03:02:47 [INFO]: Epoch 173 - training loss: 0.2053, validation loss: 0.1474
2024-05-25 03:02:47 [INFO]: Epoch 174 - training loss: 0.2041, validation loss: 0.1485
2024-05-25 03:02:48 [INFO]: Epoch 175 - training loss: 0.2042, validation loss: 0.1499
2024-05-25 03:02:48 [INFO]: Epoch 176 - training loss: 0.2030, validation loss: 0.1476
2024-05-25 03:02:48 [INFO]: Epoch 177 - training loss: 0.2020, validation loss: 0.1486
2024-05-25 03:02:49 [INFO]: Epoch 178 - training loss: 0.2014, validation loss: 0.1465
2024-05-25 03:02:49 [INFO]: Epoch 179 - training loss: 0.2022, validation loss: 0.1481
2024-05-25 03:02:49 [INFO]: Epoch 180 - training loss: 0.2016, validation loss: 0.1472
2024-05-25 03:02:50 [INFO]: Epoch 181 - training loss: 0.2022, validation loss: 0.1467
2024-05-25 03:02:50 [INFO]: Epoch 182 - training loss: 0.2022, validation loss: 0.1472
2024-05-25 03:02:50 [INFO]: Epoch 183 - training loss: 0.2019, validation loss: 0.1461
2024-05-25 03:02:51 [INFO]: Epoch 184 - training loss: 0.1996, validation loss: 0.1468
2024-05-25 03:02:51 [INFO]: Epoch 185 - training loss: 0.2011, validation loss: 0.1465
2024-05-25 03:02:51 [INFO]: Epoch 186 - training loss: 0.1986, validation loss: 0.1476
2024-05-25 03:02:52 [INFO]: Epoch 187 - training loss: 0.2004, validation loss: 0.1461
2024-05-25 03:02:52 [INFO]: Epoch 188 - training loss: 0.1997, validation loss: 0.1444
2024-05-25 03:02:52 [INFO]: Epoch 189 - training loss: 0.1991, validation loss: 0.1450
2024-05-25 03:02:52 [INFO]: Epoch 190 - training loss: 0.1983, validation loss: 0.1459
2024-05-25 03:02:53 [INFO]: Epoch 191 - training loss: 0.1976, validation loss: 0.1452
2024-05-25 03:02:53 [INFO]: Epoch 192 - training loss: 0.1973, validation loss: 0.1456
2024-05-25 03:02:53 [INFO]: Epoch 193 - training loss: 0.1966, validation loss: 0.1453
2024-05-25 03:02:54 [INFO]: Epoch 194 - training loss: 0.1993, validation loss: 0.1446
2024-05-25 03:02:54 [INFO]: Epoch 195 - training loss: 0.1986, validation loss: 0.1456
2024-05-25 03:02:54 [INFO]: Epoch 196 - training loss: 0.2008, validation loss: 0.1437
2024-05-25 03:02:55 [INFO]: Epoch 197 - training loss: 0.1995, validation loss: 0.1455
2024-05-25 03:02:55 [INFO]: Epoch 198 - training loss: 0.1986, validation loss: 0.1451
2024-05-25 03:02:55 [INFO]: Epoch 199 - training loss: 0.1981, validation loss: 0.1460
2024-05-25 03:02:56 [INFO]: Epoch 200 - training loss: 0.1965, validation loss: 0.1434
2024-05-25 03:02:56 [INFO]: Epoch 201 - training loss: 0.1954, validation loss: 0.1438
2024-05-25 03:02:56 [INFO]: Epoch 202 - training loss: 0.1953, validation loss: 0.1440
2024-05-25 03:02:57 [INFO]: Epoch 203 - training loss: 0.1943, validation loss: 0.1440
2024-05-25 03:02:57 [INFO]: Epoch 204 - training loss: 0.1942, validation loss: 0.1435
2024-05-25 03:02:57 [INFO]: Epoch 205 - training loss: 0.1941, validation loss: 0.1434
2024-05-25 03:02:58 [INFO]: Epoch 206 - training loss: 0.1940, validation loss: 0.1450
2024-05-25 03:02:58 [INFO]: Epoch 207 - training loss: 0.1939, validation loss: 0.1428
2024-05-25 03:02:58 [INFO]: Epoch 208 - training loss: 0.1926, validation loss: 0.1441
2024-05-25 03:02:59 [INFO]: Epoch 209 - training loss: 0.1969, validation loss: 0.1455
2024-05-25 03:02:59 [INFO]: Epoch 210 - training loss: 0.1954, validation loss: 0.1443
2024-05-25 03:02:59 [INFO]: Epoch 211 - training loss: 0.1930, validation loss: 0.1452
2024-05-25 03:03:00 [INFO]: Epoch 212 - training loss: 0.1921, validation loss: 0.1437
2024-05-25 03:03:00 [INFO]: Epoch 213 - training loss: 0.1945, validation loss: 0.1450
2024-05-25 03:03:00 [INFO]: Epoch 214 - training loss: 0.1933, validation loss: 0.1445
2024-05-25 03:03:01 [INFO]: Epoch 215 - training loss: 0.1942, validation loss: 0.1434
2024-05-25 03:03:01 [INFO]: Epoch 216 - training loss: 0.1946, validation loss: 0.1439
2024-05-25 03:03:01 [INFO]: Epoch 217 - training loss: 0.1918, validation loss: 0.1425
2024-05-25 03:03:02 [INFO]: Epoch 218 - training loss: 0.1925, validation loss: 0.1431
2024-05-25 03:03:02 [INFO]: Epoch 219 - training loss: 0.1930, validation loss: 0.1435
2024-05-25 03:03:02 [INFO]: Epoch 220 - training loss: 0.1930, validation loss: 0.1412
2024-05-25 03:03:03 [INFO]: Epoch 221 - training loss: 0.1926, validation loss: 0.1432
2024-05-25 03:03:03 [INFO]: Epoch 222 - training loss: 0.1926, validation loss: 0.1435
2024-05-25 03:03:03 [INFO]: Epoch 223 - training loss: 0.1932, validation loss: 0.1416
2024-05-25 03:03:03 [INFO]: Epoch 224 - training loss: 0.1913, validation loss: 0.1421
2024-05-25 03:03:04 [INFO]: Epoch 225 - training loss: 0.1909, validation loss: 0.1428
2024-05-25 03:03:04 [INFO]: Epoch 226 - training loss: 0.1897, validation loss: 0.1434
2024-05-25 03:03:04 [INFO]: Epoch 227 - training loss: 0.1923, validation loss: 0.1420
2024-05-25 03:03:05 [INFO]: Epoch 228 - training loss: 0.1917, validation loss: 0.1418
2024-05-25 03:03:05 [INFO]: Epoch 229 - training loss: 0.1899, validation loss: 0.1422
2024-05-25 03:03:05 [INFO]: Epoch 230 - training loss: 0.1911, validation loss: 0.1411
2024-05-25 03:03:06 [INFO]: Epoch 231 - training loss: 0.1921, validation loss: 0.1411
2024-05-25 03:03:06 [INFO]: Epoch 232 - training loss: 0.1898, validation loss: 0.1414
2024-05-25 03:03:06 [INFO]: Epoch 233 - training loss: 0.1938, validation loss: 0.1431
2024-05-25 03:03:07 [INFO]: Epoch 234 - training loss: 0.1937, validation loss: 0.1422
2024-05-25 03:03:07 [INFO]: Epoch 235 - training loss: 0.1888, validation loss: 0.1426
2024-05-25 03:03:07 [INFO]: Epoch 236 - training loss: 0.1867, validation loss: 0.1412
2024-05-25 03:03:08 [INFO]: Epoch 237 - training loss: 0.1867, validation loss: 0.1404
2024-05-25 03:03:08 [INFO]: Epoch 238 - training loss: 0.1875, validation loss: 0.1411
2024-05-25 03:03:08 [INFO]: Epoch 239 - training loss: 0.1893, validation loss: 0.1406
2024-05-25 03:03:09 [INFO]: Epoch 240 - training loss: 0.1888, validation loss: 0.1398
2024-05-25 03:03:09 [INFO]: Epoch 241 - training loss: 0.1896, validation loss: 0.1414
2024-05-25 03:03:09 [INFO]: Epoch 242 - training loss: 0.1877, validation loss: 0.1407
2024-05-25 03:03:10 [INFO]: Epoch 243 - training loss: 0.1879, validation loss: 0.1407
2024-05-25 03:03:10 [INFO]: Epoch 244 - training loss: 0.1866, validation loss: 0.1403
2024-05-25 03:03:10 [INFO]: Epoch 245 - training loss: 0.1875, validation loss: 0.1398
2024-05-25 03:03:11 [INFO]: Epoch 246 - training loss: 0.1859, validation loss: 0.1394
2024-05-25 03:03:11 [INFO]: Epoch 247 - training loss: 0.1880, validation loss: 0.1413
2024-05-25 03:03:11 [INFO]: Epoch 248 - training loss: 0.1876, validation loss: 0.1410
2024-05-25 03:03:12 [INFO]: Epoch 249 - training loss: 0.1849, validation loss: 0.1408
2024-05-25 03:03:12 [INFO]: Epoch 250 - training loss: 0.1853, validation loss: 0.1395
2024-05-25 03:03:12 [INFO]: Epoch 251 - training loss: 0.1854, validation loss: 0.1399
2024-05-25 03:03:12 [INFO]: Epoch 252 - training loss: 0.1856, validation loss: 0.1395
2024-05-25 03:03:13 [INFO]: Epoch 253 - training loss: 0.1876, validation loss: 0.1399
2024-05-25 03:03:13 [INFO]: Epoch 254 - training loss: 0.1877, validation loss: 0.1406
2024-05-25 03:03:13 [INFO]: Epoch 255 - training loss: 0.1849, validation loss: 0.1394
2024-05-25 03:03:14 [INFO]: Epoch 256 - training loss: 0.1850, validation loss: 0.1393
2024-05-25 03:03:14 [INFO]: Epoch 257 - training loss: 0.1847, validation loss: 0.1399
2024-05-25 03:03:14 [INFO]: Epoch 258 - training loss: 0.1859, validation loss: 0.1392
2024-05-25 03:03:15 [INFO]: Epoch 259 - training loss: 0.1848, validation loss: 0.1398
2024-05-25 03:03:15 [INFO]: Epoch 260 - training loss: 0.1866, validation loss: 0.1398
2024-05-25 03:03:15 [INFO]: Epoch 261 - training loss: 0.1835, validation loss: 0.1384
2024-05-25 03:03:16 [INFO]: Epoch 262 - training loss: 0.1827, validation loss: 0.1389
2024-05-25 03:03:16 [INFO]: Epoch 263 - training loss: 0.1829, validation loss: 0.1395
2024-05-25 03:03:16 [INFO]: Epoch 264 - training loss: 0.1823, validation loss: 0.1397
2024-05-25 03:03:17 [INFO]: Epoch 265 - training loss: 0.1849, validation loss: 0.1379
2024-05-25 03:03:17 [INFO]: Epoch 266 - training loss: 0.1847, validation loss: 0.1386
2024-05-25 03:03:17 [INFO]: Epoch 267 - training loss: 0.1838, validation loss: 0.1378
2024-05-25 03:03:18 [INFO]: Epoch 268 - training loss: 0.1851, validation loss: 0.1374
2024-05-25 03:03:18 [INFO]: Epoch 269 - training loss: 0.1830, validation loss: 0.1399
2024-05-25 03:03:18 [INFO]: Epoch 270 - training loss: 0.1818, validation loss: 0.1381
2024-05-25 03:03:19 [INFO]: Epoch 271 - training loss: 0.1834, validation loss: 0.1384
2024-05-25 03:03:19 [INFO]: Epoch 272 - training loss: 0.1829, validation loss: 0.1378
2024-05-25 03:03:19 [INFO]: Epoch 273 - training loss: 0.1818, validation loss: 0.1386
2024-05-25 03:03:20 [INFO]: Epoch 274 - training loss: 0.1807, validation loss: 0.1368
2024-05-25 03:03:20 [INFO]: Epoch 275 - training loss: 0.1812, validation loss: 0.1378
2024-05-25 03:03:20 [INFO]: Epoch 276 - training loss: 0.1808, validation loss: 0.1374
2024-05-25 03:03:21 [INFO]: Epoch 277 - training loss: 0.1806, validation loss: 0.1375
2024-05-25 03:03:21 [INFO]: Epoch 278 - training loss: 0.1801, validation loss: 0.1367
2024-05-25 03:03:21 [INFO]: Epoch 279 - training loss: 0.1818, validation loss: 0.1367
2024-05-25 03:03:22 [INFO]: Epoch 280 - training loss: 0.1800, validation loss: 0.1374
2024-05-25 03:03:22 [INFO]: Epoch 281 - training loss: 0.1795, validation loss: 0.1365
2024-05-25 03:03:22 [INFO]: Epoch 282 - training loss: 0.1841, validation loss: 0.1371
2024-05-25 03:03:23 [INFO]: Epoch 283 - training loss: 0.1841, validation loss: 0.1369
2024-05-25 03:03:23 [INFO]: Epoch 284 - training loss: 0.1813, validation loss: 0.1373
2024-05-25 03:03:23 [INFO]: Epoch 285 - training loss: 0.1813, validation loss: 0.1370
2024-05-25 03:03:24 [INFO]: Epoch 286 - training loss: 0.1795, validation loss: 0.1362
2024-05-25 03:03:24 [INFO]: Epoch 287 - training loss: 0.1795, validation loss: 0.1365
2024-05-25 03:03:24 [INFO]: Epoch 288 - training loss: 0.1785, validation loss: 0.1361
2024-05-25 03:03:25 [INFO]: Epoch 289 - training loss: 0.1798, validation loss: 0.1376
2024-05-25 03:03:25 [INFO]: Epoch 290 - training loss: 0.1805, validation loss: 0.1359
2024-05-25 03:03:25 [INFO]: Epoch 291 - training loss: 0.1791, validation loss: 0.1351
2024-05-25 03:03:25 [INFO]: Epoch 292 - training loss: 0.1787, validation loss: 0.1361
2024-05-25 03:03:26 [INFO]: Epoch 293 - training loss: 0.1768, validation loss: 0.1357
2024-05-25 03:03:26 [INFO]: Epoch 294 - training loss: 0.1769, validation loss: 0.1353
2024-05-25 03:03:26 [INFO]: Epoch 295 - training loss: 0.1780, validation loss: 0.1372
2024-05-25 03:03:27 [INFO]: Epoch 296 - training loss: 0.1780, validation loss: 0.1361
2024-05-25 03:03:27 [INFO]: Epoch 297 - training loss: 0.1798, validation loss: 0.1352
2024-05-25 03:03:27 [INFO]: Epoch 298 - training loss: 0.1833, validation loss: 0.1351
2024-05-25 03:03:28 [INFO]: Epoch 299 - training loss: 0.1789, validation loss: 0.1355
2024-05-25 03:03:28 [INFO]: Epoch 300 - training loss: 0.1782, validation loss: 0.1367
2024-05-25 03:03:28 [INFO]: Finished training. The best model is from epoch#291.
2024-05-25 03:03:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/Transformer_air_quality/20240525_T030151/Transformer.pypots
2024-05-25 03:03:28 [INFO]: Transformer on Air-Quality: MAE=0.1609, MSE=0.1209
2024-05-25 03:03:28 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 03:03:28 [INFO]: Using the given device: cuda:0
2024-05-25 03:03:28 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T030328
2024-05-25 03:03:28 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T030328/tensorboard
2024-05-25 03:03:29 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:03:29 [INFO]: Epoch 001 - training loss: 0.2949, validation loss: 0.2579
2024-05-25 03:03:30 [INFO]: Epoch 002 - training loss: 0.2236, validation loss: 0.2395
2024-05-25 03:03:30 [INFO]: Epoch 003 - training loss: 0.2019, validation loss: 0.2132
2024-05-25 03:03:31 [INFO]: Epoch 004 - training loss: 0.2040, validation loss: 0.2060
2024-05-25 03:03:31 [INFO]: Epoch 005 - training loss: 0.1622, validation loss: 0.2039
2024-05-25 03:03:32 [INFO]: Epoch 006 - training loss: 0.1707, validation loss: 0.1960
2024-05-25 03:03:32 [INFO]: Epoch 007 - training loss: 0.1526, validation loss: 0.1909
2024-05-25 03:03:33 [INFO]: Epoch 008 - training loss: 0.1588, validation loss: 0.1894
2024-05-25 03:03:33 [INFO]: Epoch 009 - training loss: 0.1676, validation loss: 0.1959
2024-05-25 03:03:34 [INFO]: Epoch 010 - training loss: 0.1786, validation loss: 0.1908
2024-05-25 03:03:35 [INFO]: Epoch 011 - training loss: 0.1473, validation loss: 0.1827
2024-05-25 03:03:35 [INFO]: Epoch 012 - training loss: 0.1492, validation loss: 0.1789
2024-05-25 03:03:36 [INFO]: Epoch 013 - training loss: 0.1517, validation loss: 0.1787
2024-05-25 03:03:36 [INFO]: Epoch 014 - training loss: 0.1377, validation loss: 0.1726
2024-05-25 03:03:37 [INFO]: Epoch 015 - training loss: 0.1394, validation loss: 0.1736
2024-05-25 03:03:37 [INFO]: Epoch 016 - training loss: 0.1220, validation loss: 0.1717
2024-05-25 03:03:38 [INFO]: Epoch 017 - training loss: 0.1337, validation loss: 0.1701
2024-05-25 03:03:38 [INFO]: Epoch 018 - training loss: 0.1392, validation loss: 0.1710
2024-05-25 03:03:39 [INFO]: Epoch 019 - training loss: 0.1291, validation loss: 0.1663
2024-05-25 03:03:39 [INFO]: Epoch 020 - training loss: 0.1454, validation loss: 0.1663
2024-05-25 03:03:40 [INFO]: Epoch 021 - training loss: 0.1193, validation loss: 0.1717
2024-05-25 03:03:40 [INFO]: Epoch 022 - training loss: 0.1529, validation loss: 0.1697
2024-05-25 03:03:41 [INFO]: Epoch 023 - training loss: 0.1282, validation loss: 0.1645
2024-05-25 03:03:42 [INFO]: Epoch 024 - training loss: 0.1362, validation loss: 0.1648
2024-05-25 03:03:42 [INFO]: Epoch 025 - training loss: 0.1213, validation loss: 0.1613
2024-05-25 03:03:43 [INFO]: Epoch 026 - training loss: 0.1352, validation loss: 0.1666
2024-05-25 03:03:43 [INFO]: Epoch 027 - training loss: 0.1373, validation loss: 0.1646
2024-05-25 03:03:44 [INFO]: Epoch 028 - training loss: 0.1213, validation loss: 0.1642
2024-05-25 03:03:44 [INFO]: Epoch 029 - training loss: 0.1121, validation loss: 0.1628
2024-05-25 03:03:45 [INFO]: Epoch 030 - training loss: 0.1036, validation loss: 0.1624
2024-05-25 03:03:45 [INFO]: Epoch 031 - training loss: 0.1164, validation loss: 0.1630
2024-05-25 03:03:46 [INFO]: Epoch 032 - training loss: 0.1317, validation loss: 0.1589
2024-05-25 03:03:46 [INFO]: Epoch 033 - training loss: 0.1146, validation loss: 0.1607
2024-05-25 03:03:47 [INFO]: Epoch 034 - training loss: 0.1369, validation loss: 0.1728
2024-05-25 03:03:47 [INFO]: Epoch 035 - training loss: 0.1233, validation loss: 0.1610
2024-05-25 03:03:48 [INFO]: Epoch 036 - training loss: 0.0927, validation loss: 0.1642
2024-05-25 03:03:49 [INFO]: Epoch 037 - training loss: 0.1194, validation loss: 0.1643
2024-05-25 03:03:49 [INFO]: Epoch 038 - training loss: 0.1210, validation loss: 0.1615
2024-05-25 03:03:50 [INFO]: Epoch 039 - training loss: 0.1132, validation loss: 0.1623
2024-05-25 03:03:50 [INFO]: Epoch 040 - training loss: 0.1196, validation loss: 0.1603
2024-05-25 03:03:51 [INFO]: Epoch 041 - training loss: 0.1083, validation loss: 0.1567
2024-05-25 03:03:51 [INFO]: Epoch 042 - training loss: 0.1324, validation loss: 0.1612
2024-05-25 03:03:52 [INFO]: Epoch 043 - training loss: 0.1279, validation loss: 0.1586
2024-05-25 03:03:52 [INFO]: Epoch 044 - training loss: 0.1069, validation loss: 0.1559
2024-05-25 03:03:53 [INFO]: Epoch 045 - training loss: 0.1079, validation loss: 0.1582
2024-05-25 03:03:53 [INFO]: Epoch 046 - training loss: 0.0961, validation loss: 0.1570
2024-05-25 03:03:54 [INFO]: Epoch 047 - training loss: 0.1073, validation loss: 0.1567
2024-05-25 03:03:54 [INFO]: Epoch 048 - training loss: 0.0938, validation loss: 0.1576
2024-05-25 03:03:55 [INFO]: Epoch 049 - training loss: 0.1044, validation loss: 0.1541
2024-05-25 03:03:55 [INFO]: Epoch 050 - training loss: 0.0945, validation loss: 0.1556
2024-05-25 03:03:56 [INFO]: Epoch 051 - training loss: 0.1104, validation loss: 0.1546
2024-05-25 03:03:57 [INFO]: Epoch 052 - training loss: 0.1044, validation loss: 0.1584
2024-05-25 03:03:57 [INFO]: Epoch 053 - training loss: 0.1084, validation loss: 0.1542
2024-05-25 03:03:58 [INFO]: Epoch 054 - training loss: 0.0959, validation loss: 0.1532
2024-05-25 03:03:58 [INFO]: Epoch 055 - training loss: 0.1003, validation loss: 0.1557
2024-05-25 03:03:59 [INFO]: Epoch 056 - training loss: 0.0934, validation loss: 0.1542
2024-05-25 03:03:59 [INFO]: Epoch 057 - training loss: 0.0903, validation loss: 0.1528
2024-05-25 03:04:00 [INFO]: Epoch 058 - training loss: 0.1029, validation loss: 0.1560
2024-05-25 03:04:00 [INFO]: Epoch 059 - training loss: 0.1042, validation loss: 0.1558
2024-05-25 03:04:01 [INFO]: Epoch 060 - training loss: 0.1075, validation loss: 0.1592
2024-05-25 03:04:01 [INFO]: Epoch 061 - training loss: 0.0998, validation loss: 0.1608
2024-05-25 03:04:02 [INFO]: Epoch 062 - training loss: 0.1158, validation loss: 0.1543
2024-05-25 03:04:02 [INFO]: Epoch 063 - training loss: 0.0984, validation loss: 0.1552
2024-05-25 03:04:03 [INFO]: Epoch 064 - training loss: 0.0985, validation loss: 0.1557
2024-05-25 03:04:04 [INFO]: Epoch 065 - training loss: 0.1006, validation loss: 0.1522
2024-05-25 03:04:04 [INFO]: Epoch 066 - training loss: 0.1054, validation loss: 0.1558
2024-05-25 03:04:05 [INFO]: Epoch 067 - training loss: 0.0937, validation loss: 0.1519
2024-05-25 03:04:05 [INFO]: Epoch 068 - training loss: 0.0989, validation loss: 0.1518
2024-05-25 03:04:06 [INFO]: Epoch 069 - training loss: 0.0973, validation loss: 0.1492
2024-05-25 03:04:06 [INFO]: Epoch 070 - training loss: 0.0976, validation loss: 0.1513
2024-05-25 03:04:07 [INFO]: Epoch 071 - training loss: 0.0947, validation loss: 0.1512
2024-05-25 03:04:07 [INFO]: Epoch 072 - training loss: 0.0986, validation loss: 0.1495
2024-05-25 03:04:08 [INFO]: Epoch 073 - training loss: 0.0864, validation loss: 0.1491
2024-05-25 03:04:08 [INFO]: Epoch 074 - training loss: 0.0997, validation loss: 0.1524
2024-05-25 03:04:09 [INFO]: Epoch 075 - training loss: 0.1061, validation loss: 0.1533
2024-05-25 03:04:09 [INFO]: Epoch 076 - training loss: 0.0917, validation loss: 0.1714
2024-05-25 03:04:10 [INFO]: Epoch 077 - training loss: 0.1036, validation loss: 0.1596
2024-05-25 03:04:11 [INFO]: Epoch 078 - training loss: 0.1055, validation loss: 0.1517
2024-05-25 03:04:11 [INFO]: Epoch 079 - training loss: 0.1151, validation loss: 0.1522
2024-05-25 03:04:12 [INFO]: Epoch 080 - training loss: 0.0893, validation loss: 0.1540
2024-05-25 03:04:12 [INFO]: Epoch 081 - training loss: 0.0911, validation loss: 0.1502
2024-05-25 03:04:13 [INFO]: Epoch 082 - training loss: 0.0906, validation loss: 0.1527
2024-05-25 03:04:13 [INFO]: Epoch 083 - training loss: 0.1056, validation loss: 0.1478
2024-05-25 03:04:14 [INFO]: Epoch 084 - training loss: 0.0985, validation loss: 0.1491
2024-05-25 03:04:14 [INFO]: Epoch 085 - training loss: 0.0855, validation loss: 0.1483
2024-05-25 03:04:15 [INFO]: Epoch 086 - training loss: 0.1035, validation loss: 0.1475
2024-05-25 03:04:15 [INFO]: Epoch 087 - training loss: 0.0913, validation loss: 0.1509
2024-05-25 03:04:16 [INFO]: Epoch 088 - training loss: 0.0822, validation loss: 0.1491
2024-05-25 03:04:16 [INFO]: Epoch 089 - training loss: 0.0871, validation loss: 0.1519
2024-05-25 03:04:17 [INFO]: Epoch 090 - training loss: 0.0977, validation loss: 0.1470
2024-05-25 03:04:18 [INFO]: Epoch 091 - training loss: 0.0894, validation loss: 0.1462
2024-05-25 03:04:18 [INFO]: Epoch 092 - training loss: 0.0963, validation loss: 0.1499
2024-05-25 03:04:19 [INFO]: Epoch 093 - training loss: 0.0937, validation loss: 0.1500
2024-05-25 03:04:19 [INFO]: Epoch 094 - training loss: 0.0990, validation loss: 0.1526
2024-05-25 03:04:20 [INFO]: Epoch 095 - training loss: 0.0985, validation loss: 0.1531
2024-05-25 03:04:20 [INFO]: Epoch 096 - training loss: 0.0956, validation loss: 0.1475
2024-05-25 03:04:21 [INFO]: Epoch 097 - training loss: 0.0829, validation loss: 0.1561
2024-05-25 03:04:21 [INFO]: Epoch 098 - training loss: 0.1109, validation loss: 0.1501
2024-05-25 03:04:22 [INFO]: Epoch 099 - training loss: 0.0847, validation loss: 0.1516
2024-05-25 03:04:22 [INFO]: Epoch 100 - training loss: 0.0886, validation loss: 0.1476
2024-05-25 03:04:23 [INFO]: Epoch 101 - training loss: 0.0935, validation loss: 0.1495
2024-05-25 03:04:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:04:23 [INFO]: Finished training. The best model is from epoch#91.
2024-05-25 03:04:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/TimesNet_air_quality/20240525_T030328/TimesNet.pypots
2024-05-25 03:04:23 [INFO]: TimesNet on Air-Quality: MAE=0.1578, MSE=0.1529
2024-05-25 03:04:23 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 03:04:23 [INFO]: Using the given device: cuda:0
2024-05-25 03:04:23 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423
2024-05-25 03:04:23 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/tensorboard
2024-05-25 03:04:23 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:04:40 [INFO]: Epoch 001 - training loss: 0.4592, validation loss: 0.3341
2024-05-25 03:04:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch1_loss0.33408900499343874.pypots
2024-05-25 03:04:57 [INFO]: Epoch 002 - training loss: 0.2941, validation loss: 0.2919
2024-05-25 03:04:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch2_loss0.2919412523508072.pypots
2024-05-25 03:05:14 [INFO]: Epoch 003 - training loss: 0.2686, validation loss: 0.2421
2024-05-25 03:05:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch3_loss0.2421487957239151.pypots
2024-05-25 03:05:31 [INFO]: Epoch 004 - training loss: 0.2441, validation loss: 0.2180
2024-05-25 03:05:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch4_loss0.21801288723945617.pypots
2024-05-25 03:05:48 [INFO]: Epoch 005 - training loss: 0.2186, validation loss: 0.2028
2024-05-25 03:05:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch5_loss0.20280229896306992.pypots
2024-05-25 03:06:05 [INFO]: Epoch 006 - training loss: 0.2103, validation loss: 0.1868
2024-05-25 03:06:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch6_loss0.18680716454982757.pypots
2024-05-25 03:06:22 [INFO]: Epoch 007 - training loss: 0.2115, validation loss: 0.1786
2024-05-25 03:06:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch7_loss0.17863765954971314.pypots
2024-05-25 03:06:38 [INFO]: Epoch 008 - training loss: 0.1826, validation loss: 0.1681
2024-05-25 03:06:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch8_loss0.16811113506555558.pypots
2024-05-25 03:06:55 [INFO]: Epoch 009 - training loss: 0.1886, validation loss: 0.1589
2024-05-25 03:06:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch9_loss0.15890471041202545.pypots
2024-05-25 03:07:12 [INFO]: Epoch 010 - training loss: 0.1716, validation loss: 0.1571
2024-05-25 03:07:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch10_loss0.15707593262195588.pypots
2024-05-25 03:07:29 [INFO]: Epoch 011 - training loss: 0.1802, validation loss: 0.1553
2024-05-25 03:07:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch11_loss0.15534242987632751.pypots
2024-05-25 03:07:46 [INFO]: Epoch 012 - training loss: 0.1573, validation loss: 0.1542
2024-05-25 03:07:46 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch12_loss0.15422922670841216.pypots
2024-05-25 03:08:03 [INFO]: Epoch 013 - training loss: 0.1640, validation loss: 0.1486
2024-05-25 03:08:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch13_loss0.14862944334745407.pypots
2024-05-25 03:08:20 [INFO]: Epoch 014 - training loss: 0.1724, validation loss: 0.1460
2024-05-25 03:08:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch14_loss0.14599977135658265.pypots
2024-05-25 03:08:37 [INFO]: Epoch 015 - training loss: 0.1729, validation loss: 0.1446
2024-05-25 03:08:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch15_loss0.1446448676288128.pypots
2024-05-25 03:08:54 [INFO]: Epoch 016 - training loss: 0.1660, validation loss: 0.1461
2024-05-25 03:08:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch16_loss0.14610404521226883.pypots
2024-05-25 03:09:10 [INFO]: Epoch 017 - training loss: 0.1611, validation loss: 0.1472
2024-05-25 03:09:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch17_loss0.14717385321855544.pypots
2024-05-25 03:09:27 [INFO]: Epoch 018 - training loss: 0.1563, validation loss: 0.1434
2024-05-25 03:09:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch18_loss0.1433981515467167.pypots
2024-05-25 03:09:44 [INFO]: Epoch 019 - training loss: 0.1474, validation loss: 0.1371
2024-05-25 03:09:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch19_loss0.13709728568792343.pypots
2024-05-25 03:10:01 [INFO]: Epoch 020 - training loss: 0.1515, validation loss: 0.1377
2024-05-25 03:10:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch20_loss0.13766279444098473.pypots
2024-05-25 03:10:18 [INFO]: Epoch 021 - training loss: 0.1567, validation loss: 0.1349
2024-05-25 03:10:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch21_loss0.1349273830652237.pypots
2024-05-25 03:10:35 [INFO]: Epoch 022 - training loss: 0.1654, validation loss: 0.1383
2024-05-25 03:10:35 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch22_loss0.1383413404226303.pypots
2024-05-25 03:10:52 [INFO]: Epoch 023 - training loss: 0.1486, validation loss: 0.1333
2024-05-25 03:10:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch23_loss0.1333185203373432.pypots
2024-05-25 03:11:09 [INFO]: Epoch 024 - training loss: 0.1582, validation loss: 0.1309
2024-05-25 03:11:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch24_loss0.1309318132698536.pypots
2024-05-25 03:11:26 [INFO]: Epoch 025 - training loss: 0.1563, validation loss: 0.1336
2024-05-25 03:11:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch25_loss0.13359492048621177.pypots
2024-05-25 03:11:43 [INFO]: Epoch 026 - training loss: 0.1376, validation loss: 0.1308
2024-05-25 03:11:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch26_loss0.13082783594727515.pypots
2024-05-25 03:12:00 [INFO]: Epoch 027 - training loss: 0.1619, validation loss: 0.1316
2024-05-25 03:12:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch27_loss0.13163969069719314.pypots
2024-05-25 03:12:16 [INFO]: Epoch 028 - training loss: 0.1355, validation loss: 0.1338
2024-05-25 03:12:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch28_loss0.133772299438715.pypots
2024-05-25 03:12:33 [INFO]: Epoch 029 - training loss: 0.1516, validation loss: 0.1302
2024-05-25 03:12:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch29_loss0.13022083789110184.pypots
2024-05-25 03:12:50 [INFO]: Epoch 030 - training loss: 0.1346, validation loss: 0.1279
2024-05-25 03:12:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch30_loss0.1279110826551914.pypots
2024-05-25 03:13:07 [INFO]: Epoch 031 - training loss: 0.1493, validation loss: 0.1336
2024-05-25 03:13:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch31_loss0.13360806778073311.pypots
2024-05-25 03:13:24 [INFO]: Epoch 032 - training loss: 0.1489, validation loss: 0.1318
2024-05-25 03:13:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch32_loss0.13182294964790345.pypots
2024-05-25 03:13:41 [INFO]: Epoch 033 - training loss: 0.1543, validation loss: 0.1263
2024-05-25 03:13:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch33_loss0.12630595043301582.pypots
2024-05-25 03:13:58 [INFO]: Epoch 034 - training loss: 0.1262, validation loss: 0.1263
2024-05-25 03:13:58 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch34_loss0.1263423204421997.pypots
2024-05-25 03:14:15 [INFO]: Epoch 035 - training loss: 0.1485, validation loss: 0.1246
2024-05-25 03:14:15 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch35_loss0.12459334805607795.pypots
2024-05-25 03:14:32 [INFO]: Epoch 036 - training loss: 0.1342, validation loss: 0.1265
2024-05-25 03:14:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch36_loss0.1264740251004696.pypots
2024-05-25 03:14:49 [INFO]: Epoch 037 - training loss: 0.1464, validation loss: 0.1228
2024-05-25 03:14:49 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch37_loss0.12275680154561996.pypots
2024-05-25 03:15:06 [INFO]: Epoch 038 - training loss: 0.1358, validation loss: 0.1252
2024-05-25 03:15:06 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch38_loss0.12523754313588142.pypots
2024-05-25 03:15:22 [INFO]: Epoch 039 - training loss: 0.1389, validation loss: 0.1222
2024-05-25 03:15:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch39_loss0.12224042490124702.pypots
2024-05-25 03:15:39 [INFO]: Epoch 040 - training loss: 0.1202, validation loss: 0.1237
2024-05-25 03:15:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch40_loss0.12372355088591576.pypots
2024-05-25 03:15:56 [INFO]: Epoch 041 - training loss: 0.1332, validation loss: 0.1240
2024-05-25 03:15:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch41_loss0.12403232082724572.pypots
2024-05-25 03:16:13 [INFO]: Epoch 042 - training loss: 0.1227, validation loss: 0.1215
2024-05-25 03:16:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch42_loss0.12146001309156418.pypots
2024-05-25 03:16:30 [INFO]: Epoch 043 - training loss: 0.1348, validation loss: 0.1253
2024-05-25 03:16:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch43_loss0.12525169774889947.pypots
2024-05-25 03:16:47 [INFO]: Epoch 044 - training loss: 0.1219, validation loss: 0.1207
2024-05-25 03:16:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch44_loss0.1207030512392521.pypots
2024-05-25 03:17:04 [INFO]: Epoch 045 - training loss: 0.1246, validation loss: 0.1187
2024-05-25 03:17:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch45_loss0.1187035359442234.pypots
2024-05-25 03:17:21 [INFO]: Epoch 046 - training loss: 0.1327, validation loss: 0.1186
2024-05-25 03:17:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch46_loss0.11856852993369102.pypots
2024-05-25 03:17:38 [INFO]: Epoch 047 - training loss: 0.1247, validation loss: 0.1201
2024-05-25 03:17:38 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch47_loss0.1200787752866745.pypots
2024-05-25 03:17:55 [INFO]: Epoch 048 - training loss: 0.1323, validation loss: 0.1207
2024-05-25 03:17:55 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch48_loss0.12073022425174713.pypots
2024-05-25 03:18:11 [INFO]: Epoch 049 - training loss: 0.1207, validation loss: 0.1179
2024-05-25 03:18:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch49_loss0.11789486110210419.pypots
2024-05-25 03:18:28 [INFO]: Epoch 050 - training loss: 0.1240, validation loss: 0.1190
2024-05-25 03:18:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch50_loss0.11902965605258942.pypots
2024-05-25 03:18:45 [INFO]: Epoch 051 - training loss: 0.1254, validation loss: 0.1154
2024-05-25 03:18:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch51_loss0.11535218954086304.pypots
2024-05-25 03:19:02 [INFO]: Epoch 052 - training loss: 0.1300, validation loss: 0.1154
2024-05-25 03:19:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch52_loss0.11542562991380692.pypots
2024-05-25 03:19:19 [INFO]: Epoch 053 - training loss: 0.1179, validation loss: 0.1141
2024-05-25 03:19:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch53_loss0.11410017535090447.pypots
2024-05-25 03:19:36 [INFO]: Epoch 054 - training loss: 0.1313, validation loss: 0.1160
2024-05-25 03:19:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch54_loss0.11601053550839424.pypots
2024-05-25 03:19:53 [INFO]: Epoch 055 - training loss: 0.1128, validation loss: 0.1120
2024-05-25 03:19:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch55_loss0.11199433878064155.pypots
2024-05-25 03:20:10 [INFO]: Epoch 056 - training loss: 0.1127, validation loss: 0.1138
2024-05-25 03:20:10 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch56_loss0.11380891501903534.pypots
2024-05-25 03:20:27 [INFO]: Epoch 057 - training loss: 0.1331, validation loss: 0.1149
2024-05-25 03:20:27 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch57_loss0.11490545272827149.pypots
2024-05-25 03:20:44 [INFO]: Epoch 058 - training loss: 0.1180, validation loss: 0.1142
2024-05-25 03:20:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch58_loss0.11415671035647393.pypots
2024-05-25 03:21:01 [INFO]: Epoch 059 - training loss: 0.1269, validation loss: 0.1143
2024-05-25 03:21:01 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch59_loss0.11428930833935738.pypots
2024-05-25 03:21:18 [INFO]: Epoch 060 - training loss: 0.1134, validation loss: 0.1112
2024-05-25 03:21:18 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch60_loss0.11123844310641288.pypots
2024-05-25 03:21:34 [INFO]: Epoch 061 - training loss: 0.1196, validation loss: 0.1130
2024-05-25 03:21:34 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch61_loss0.11302640214562416.pypots
2024-05-25 03:21:51 [INFO]: Epoch 062 - training loss: 0.1140, validation loss: 0.1162
2024-05-25 03:21:51 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch62_loss0.11615209579467774.pypots
2024-05-25 03:22:08 [INFO]: Epoch 063 - training loss: 0.1373, validation loss: 0.1162
2024-05-25 03:22:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch63_loss0.11624119132757187.pypots
2024-05-25 03:22:25 [INFO]: Epoch 064 - training loss: 0.1285, validation loss: 0.1111
2024-05-25 03:22:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch64_loss0.11112130284309388.pypots
2024-05-25 03:22:42 [INFO]: Epoch 065 - training loss: 0.1307, validation loss: 0.1161
2024-05-25 03:22:42 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch65_loss0.11607376262545585.pypots
2024-05-25 03:22:59 [INFO]: Epoch 066 - training loss: 0.1219, validation loss: 0.1101
2024-05-25 03:22:59 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch66_loss0.11008278802037239.pypots
2024-05-25 03:23:16 [INFO]: Epoch 067 - training loss: 0.1191, validation loss: 0.1098
2024-05-25 03:23:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch67_loss0.10977542549371719.pypots
2024-05-25 03:23:33 [INFO]: Epoch 068 - training loss: 0.1346, validation loss: 0.1099
2024-05-25 03:23:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch68_loss0.10987522825598717.pypots
2024-05-25 03:23:50 [INFO]: Epoch 069 - training loss: 0.1010, validation loss: 0.1112
2024-05-25 03:23:50 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch69_loss0.11118503361940384.pypots
2024-05-25 03:24:07 [INFO]: Epoch 070 - training loss: 0.1304, validation loss: 0.1097
2024-05-25 03:24:07 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch70_loss0.1096743531525135.pypots
2024-05-25 03:24:24 [INFO]: Epoch 071 - training loss: 0.1316, validation loss: 0.1117
2024-05-25 03:24:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch71_loss0.11173909008502961.pypots
2024-05-25 03:24:40 [INFO]: Epoch 072 - training loss: 0.1040, validation loss: 0.1103
2024-05-25 03:24:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch72_loss0.11025018617510796.pypots
2024-05-25 03:24:57 [INFO]: Epoch 073 - training loss: 0.1149, validation loss: 0.1147
2024-05-25 03:24:57 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch73_loss0.11465193480253219.pypots
2024-05-25 03:25:14 [INFO]: Epoch 074 - training loss: 0.1116, validation loss: 0.1140
2024-05-25 03:25:14 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch74_loss0.11395395621657371.pypots
2024-05-25 03:25:31 [INFO]: Epoch 075 - training loss: 0.1132, validation loss: 0.1082
2024-05-25 03:25:31 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch75_loss0.10816957354545594.pypots
2024-05-25 03:25:48 [INFO]: Epoch 076 - training loss: 0.1147, validation loss: 0.1085
2024-05-25 03:25:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch76_loss0.10851653665304184.pypots
2024-05-25 03:26:05 [INFO]: Epoch 077 - training loss: 0.1170, validation loss: 0.1101
2024-05-25 03:26:05 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch77_loss0.110125682502985.pypots
2024-05-25 03:26:22 [INFO]: Epoch 078 - training loss: 0.1382, validation loss: 0.1089
2024-05-25 03:26:22 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch78_loss0.1089219756424427.pypots
2024-05-25 03:26:39 [INFO]: Epoch 079 - training loss: 0.1216, validation loss: 0.1095
2024-05-25 03:26:39 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch79_loss0.1094506099820137.pypots
2024-05-25 03:26:56 [INFO]: Epoch 080 - training loss: 0.1144, validation loss: 0.1098
2024-05-25 03:26:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch80_loss0.10977891385555268.pypots
2024-05-25 03:27:13 [INFO]: Epoch 081 - training loss: 0.1114, validation loss: 0.1078
2024-05-25 03:27:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch81_loss0.10775467902421951.pypots
2024-05-25 03:27:30 [INFO]: Epoch 082 - training loss: 0.1086, validation loss: 0.1141
2024-05-25 03:27:30 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch82_loss0.11407242268323899.pypots
2024-05-25 03:27:47 [INFO]: Epoch 083 - training loss: 0.1173, validation loss: 0.1104
2024-05-25 03:27:47 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch83_loss0.11036691814661026.pypots
2024-05-25 03:28:03 [INFO]: Epoch 084 - training loss: 0.1202, validation loss: 0.1110
2024-05-25 03:28:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch84_loss0.11101177781820297.pypots
2024-05-25 03:28:20 [INFO]: Epoch 085 - training loss: 0.1180, validation loss: 0.1082
2024-05-25 03:28:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch85_loss0.10822534859180451.pypots
2024-05-25 03:28:37 [INFO]: Epoch 086 - training loss: 0.1205, validation loss: 0.1073
2024-05-25 03:28:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch86_loss0.10731453150510788.pypots
2024-05-25 03:28:54 [INFO]: Epoch 087 - training loss: 0.1235, validation loss: 0.1051
2024-05-25 03:28:54 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch87_loss0.10510880500078201.pypots
2024-05-25 03:29:11 [INFO]: Epoch 088 - training loss: 0.1099, validation loss: 0.1060
2024-05-25 03:29:11 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch88_loss0.10597767829895019.pypots
2024-05-25 03:29:28 [INFO]: Epoch 089 - training loss: 0.1105, validation loss: 0.1068
2024-05-25 03:29:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch89_loss0.10678662732243538.pypots
2024-05-25 03:29:45 [INFO]: Epoch 090 - training loss: 0.1160, validation loss: 0.1061
2024-05-25 03:29:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch90_loss0.10610932484269142.pypots
2024-05-25 03:30:02 [INFO]: Epoch 091 - training loss: 0.1288, validation loss: 0.1093
2024-05-25 03:30:02 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch91_loss0.10932793095707893.pypots
2024-05-25 03:30:19 [INFO]: Epoch 092 - training loss: 0.1170, validation loss: 0.1052
2024-05-25 03:30:19 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch92_loss0.10515174642205238.pypots
2024-05-25 03:30:36 [INFO]: Epoch 093 - training loss: 0.1088, validation loss: 0.1089
2024-05-25 03:30:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch93_loss0.10893425866961479.pypots
2024-05-25 03:30:52 [INFO]: Epoch 094 - training loss: 0.1103, validation loss: 0.1058
2024-05-25 03:30:53 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch94_loss0.10581593811511994.pypots
2024-05-25 03:31:09 [INFO]: Epoch 095 - training loss: 0.1197, validation loss: 0.1090
2024-05-25 03:31:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch95_loss0.10903292596340179.pypots
2024-05-25 03:31:26 [INFO]: Epoch 096 - training loss: 0.1094, validation loss: 0.1082
2024-05-25 03:31:26 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch96_loss0.10820129066705704.pypots
2024-05-25 03:31:43 [INFO]: Epoch 097 - training loss: 0.1064, validation loss: 0.1053
2024-05-25 03:31:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI_epoch97_loss0.10529169291257859.pypots
2024-05-25 03:31:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:31:43 [INFO]: Finished training. The best model is from epoch#87.
2024-05-25 03:31:43 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/CSDI_air_quality/20240525_T030423/CSDI.pypots
2024-05-25 03:34:04 [INFO]: CSDI on Air-Quality: MAE=0.1089, MSE=0.1202
2024-05-25 03:34:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 03:34:04 [INFO]: Using the given device: cuda:0
2024-05-25 03:34:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T033404
2024-05-25 03:34:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T033404/tensorboard
2024-05-25 03:34:04 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:34:04 [INFO]: Epoch 001 - training loss: 61959.6787, validation loss: 0.6672
2024-05-25 03:34:04 [INFO]: Epoch 002 - training loss: 42046.1395, validation loss: 0.5865
2024-05-25 03:34:05 [INFO]: Epoch 003 - training loss: 41736.7428, validation loss: 0.5364
2024-05-25 03:34:05 [INFO]: Epoch 004 - training loss: 41607.1189, validation loss: 0.4768
2024-05-25 03:34:06 [INFO]: Epoch 005 - training loss: 41568.3268, validation loss: 0.4288
2024-05-25 03:34:06 [INFO]: Epoch 006 - training loss: 41527.5842, validation loss: 0.4649
2024-05-25 03:34:06 [INFO]: Epoch 007 - training loss: 41462.2648, validation loss: 0.3860
2024-05-25 03:34:07 [INFO]: Epoch 008 - training loss: 41430.3721, validation loss: 0.3924
2024-05-25 03:34:07 [INFO]: Epoch 009 - training loss: 41398.2713, validation loss: 0.3800
2024-05-25 03:34:07 [INFO]: Epoch 010 - training loss: 41353.3420, validation loss: 0.3529
2024-05-25 03:34:07 [INFO]: Epoch 011 - training loss: 41337.9620, validation loss: 0.3487
2024-05-25 03:34:08 [INFO]: Epoch 012 - training loss: 41355.1834, validation loss: 0.3499
2024-05-25 03:34:08 [INFO]: Epoch 013 - training loss: 41326.1385, validation loss: 0.3485
2024-05-25 03:34:08 [INFO]: Epoch 014 - training loss: 41305.5965, validation loss: 0.3423
2024-05-25 03:34:09 [INFO]: Epoch 015 - training loss: 41296.1536, validation loss: 0.3408
2024-05-25 03:34:09 [INFO]: Epoch 016 - training loss: 41295.5163, validation loss: 0.3444
2024-05-25 03:34:10 [INFO]: Epoch 017 - training loss: 41275.3196, validation loss: 0.3088
2024-05-25 03:34:10 [INFO]: Epoch 018 - training loss: 41260.5357, validation loss: 0.3396
2024-05-25 03:34:10 [INFO]: Epoch 019 - training loss: 41267.6942, validation loss: 0.3099
2024-05-25 03:34:11 [INFO]: Epoch 020 - training loss: 41274.9062, validation loss: 0.3321
2024-05-25 03:34:11 [INFO]: Epoch 021 - training loss: 41262.0284, validation loss: 0.3014
2024-05-25 03:34:11 [INFO]: Epoch 022 - training loss: 41325.2341, validation loss: 0.3145
2024-05-25 03:34:12 [INFO]: Epoch 023 - training loss: 41347.6396, validation loss: 0.3349
2024-05-25 03:34:12 [INFO]: Epoch 024 - training loss: 41301.9165, validation loss: 0.3076
2024-05-25 03:34:12 [INFO]: Epoch 025 - training loss: 41255.2319, validation loss: 0.3099
2024-05-25 03:34:13 [INFO]: Epoch 026 - training loss: 41252.2865, validation loss: 0.3049
2024-05-25 03:34:13 [INFO]: Epoch 027 - training loss: 41230.7525, validation loss: 0.2934
2024-05-25 03:34:14 [INFO]: Epoch 028 - training loss: 41222.0686, validation loss: 0.2838
2024-05-25 03:34:14 [INFO]: Epoch 029 - training loss: 41212.2170, validation loss: 0.2858
2024-05-25 03:34:14 [INFO]: Epoch 030 - training loss: 41206.4044, validation loss: 0.2783
2024-05-25 03:34:15 [INFO]: Epoch 031 - training loss: 41208.2438, validation loss: 0.2721
2024-05-25 03:34:15 [INFO]: Epoch 032 - training loss: 41209.5888, validation loss: 0.2944
2024-05-25 03:34:15 [INFO]: Epoch 033 - training loss: 41224.5896, validation loss: 0.2850
2024-05-25 03:34:16 [INFO]: Epoch 034 - training loss: 41217.7325, validation loss: 0.2899
2024-05-25 03:34:16 [INFO]: Epoch 035 - training loss: 41224.0946, validation loss: 0.2689
2024-05-25 03:34:16 [INFO]: Epoch 036 - training loss: 41204.2852, validation loss: 0.3060
2024-05-25 03:34:17 [INFO]: Epoch 037 - training loss: 41215.8485, validation loss: 0.3159
2024-05-25 03:34:17 [INFO]: Epoch 038 - training loss: 41218.7277, validation loss: 0.3084
2024-05-25 03:34:18 [INFO]: Epoch 039 - training loss: 41209.4008, validation loss: 0.2904
2024-05-25 03:34:18 [INFO]: Epoch 040 - training loss: 41186.7067, validation loss: 0.2707
2024-05-25 03:34:18 [INFO]: Epoch 041 - training loss: 41191.2629, validation loss: 0.2889
2024-05-25 03:34:19 [INFO]: Epoch 042 - training loss: 41189.2759, validation loss: 0.2760
2024-05-25 03:34:19 [INFO]: Epoch 043 - training loss: 41183.3655, validation loss: 0.2713
2024-05-25 03:34:19 [INFO]: Epoch 044 - training loss: 41175.3299, validation loss: 0.2577
2024-05-25 03:34:20 [INFO]: Epoch 045 - training loss: 41174.7296, validation loss: 0.2586
2024-05-25 03:34:20 [INFO]: Epoch 046 - training loss: 41174.0796, validation loss: 0.2662
2024-05-25 03:34:20 [INFO]: Epoch 047 - training loss: 41172.1850, validation loss: 0.2712
2024-05-25 03:34:21 [INFO]: Epoch 048 - training loss: 41176.5000, validation loss: 0.2671
2024-05-25 03:34:21 [INFO]: Epoch 049 - training loss: 41178.0532, validation loss: 0.2557
2024-05-25 03:34:21 [INFO]: Epoch 050 - training loss: 41171.9449, validation loss: 0.2661
2024-05-25 03:34:22 [INFO]: Epoch 051 - training loss: 41213.0430, validation loss: 0.2826
2024-05-25 03:34:22 [INFO]: Epoch 052 - training loss: 41200.1549, validation loss: 0.2974
2024-05-25 03:34:23 [INFO]: Epoch 053 - training loss: 41227.3772, validation loss: 0.2723
2024-05-25 03:34:23 [INFO]: Epoch 054 - training loss: 41175.4634, validation loss: 0.2574
2024-05-25 03:34:23 [INFO]: Epoch 055 - training loss: 41166.5444, validation loss: 0.2571
2024-05-25 03:34:24 [INFO]: Epoch 056 - training loss: 41170.5589, validation loss: 0.2897
2024-05-25 03:34:24 [INFO]: Epoch 057 - training loss: 41190.7755, validation loss: 0.2914
2024-05-25 03:34:24 [INFO]: Epoch 058 - training loss: 41168.8613, validation loss: 0.2746
2024-05-25 03:34:25 [INFO]: Epoch 059 - training loss: 41165.3955, validation loss: 0.2566
2024-05-25 03:34:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:34:25 [INFO]: Finished training. The best model is from epoch#49.
2024-05-25 03:34:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/GPVAE_air_quality/20240525_T033404/GPVAE.pypots
2024-05-25 03:34:25 [INFO]: GP-VAE on Air-Quality: MAE=0.2985, MSE=0.2540
2024-05-25 03:34:25 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 03:34:25 [INFO]: Using the given device: cuda:0
2024-05-25 03:34:25 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T033425
2024-05-25 03:34:25 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T033425/tensorboard
2024-05-25 03:34:25 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:34:30 [INFO]: Epoch 001 - generator training loss: 0.6296, discriminator training loss: 0.2983, validation loss: 0.5442
2024-05-25 03:34:34 [INFO]: Epoch 002 - generator training loss: 0.3013, discriminator training loss: 0.0677, validation loss: 0.4091
2024-05-25 03:34:39 [INFO]: Epoch 003 - generator training loss: 0.2212, discriminator training loss: 0.0631, validation loss: 0.3401
2024-05-25 03:34:43 [INFO]: Epoch 004 - generator training loss: 0.1817, discriminator training loss: 0.0619, validation loss: 0.2971
2024-05-25 03:34:47 [INFO]: Epoch 005 - generator training loss: 0.1574, discriminator training loss: 0.0616, validation loss: 0.2699
2024-05-25 03:34:51 [INFO]: Epoch 006 - generator training loss: 0.1397, discriminator training loss: 0.0610, validation loss: 0.2514
2024-05-25 03:34:56 [INFO]: Epoch 007 - generator training loss: 0.1282, discriminator training loss: 0.0604, validation loss: 0.2370
2024-05-25 03:35:00 [INFO]: Epoch 008 - generator training loss: 0.1118, discriminator training loss: 0.0603, validation loss: 0.2252
2024-05-25 03:35:04 [INFO]: Epoch 009 - generator training loss: 0.1045, discriminator training loss: 0.0591, validation loss: 0.2173
2024-05-25 03:35:09 [INFO]: Epoch 010 - generator training loss: 0.0960, discriminator training loss: 0.0589, validation loss: 0.2103
2024-05-25 03:35:13 [INFO]: Epoch 011 - generator training loss: 0.0915, discriminator training loss: 0.0576, validation loss: 0.2048
2024-05-25 03:35:17 [INFO]: Epoch 012 - generator training loss: 0.0863, discriminator training loss: 0.0562, validation loss: 0.1994
2024-05-25 03:35:22 [INFO]: Epoch 013 - generator training loss: 0.0826, discriminator training loss: 0.0552, validation loss: 0.1951
2024-05-25 03:35:26 [INFO]: Epoch 014 - generator training loss: 0.0793, discriminator training loss: 0.0534, validation loss: 0.1910
2024-05-25 03:35:30 [INFO]: Epoch 015 - generator training loss: 0.0787, discriminator training loss: 0.0512, validation loss: 0.1881
2024-05-25 03:35:34 [INFO]: Epoch 016 - generator training loss: 0.0739, discriminator training loss: 0.0497, validation loss: 0.1853
2024-05-25 03:35:39 [INFO]: Epoch 017 - generator training loss: 0.0740, discriminator training loss: 0.0475, validation loss: 0.1823
2024-05-25 03:35:43 [INFO]: Epoch 018 - generator training loss: 0.0716, discriminator training loss: 0.0465, validation loss: 0.1799
2024-05-25 03:35:47 [INFO]: Epoch 019 - generator training loss: 0.0696, discriminator training loss: 0.0455, validation loss: 0.1776
2024-05-25 03:35:52 [INFO]: Epoch 020 - generator training loss: 0.0677, discriminator training loss: 0.0445, validation loss: 0.1748
2024-05-25 03:35:56 [INFO]: Epoch 021 - generator training loss: 0.0651, discriminator training loss: 0.0443, validation loss: 0.1740
2024-05-25 03:36:01 [INFO]: Epoch 022 - generator training loss: 0.0645, discriminator training loss: 0.0435, validation loss: 0.1715
2024-05-25 03:36:05 [INFO]: Epoch 023 - generator training loss: 0.0631, discriminator training loss: 0.0425, validation loss: 0.1711
2024-05-25 03:36:09 [INFO]: Epoch 024 - generator training loss: 0.0614, discriminator training loss: 0.0420, validation loss: 0.1686
2024-05-25 03:36:13 [INFO]: Epoch 025 - generator training loss: 0.0604, discriminator training loss: 0.0411, validation loss: 0.1671
2024-05-25 03:36:18 [INFO]: Epoch 026 - generator training loss: 0.0602, discriminator training loss: 0.0408, validation loss: 0.1666
2024-05-25 03:36:22 [INFO]: Epoch 027 - generator training loss: 0.0578, discriminator training loss: 0.0398, validation loss: 0.1652
2024-05-25 03:36:26 [INFO]: Epoch 028 - generator training loss: 0.0571, discriminator training loss: 0.0393, validation loss: 0.1640
2024-05-25 03:36:31 [INFO]: Epoch 029 - generator training loss: 0.0565, discriminator training loss: 0.0386, validation loss: 0.1633
2024-05-25 03:36:35 [INFO]: Epoch 030 - generator training loss: 0.0562, discriminator training loss: 0.0375, validation loss: 0.1623
2024-05-25 03:36:39 [INFO]: Epoch 031 - generator training loss: 0.0557, discriminator training loss: 0.0368, validation loss: 0.1608
2024-05-25 03:36:44 [INFO]: Epoch 032 - generator training loss: 0.0544, discriminator training loss: 0.0363, validation loss: 0.1597
2024-05-25 03:36:48 [INFO]: Epoch 033 - generator training loss: 0.0557, discriminator training loss: 0.0355, validation loss: 0.1593
2024-05-25 03:36:52 [INFO]: Epoch 034 - generator training loss: 0.0547, discriminator training loss: 0.0346, validation loss: 0.1587
2024-05-25 03:36:57 [INFO]: Epoch 035 - generator training loss: 0.0533, discriminator training loss: 0.0338, validation loss: 0.1578
2024-05-25 03:37:01 [INFO]: Epoch 036 - generator training loss: 0.0538, discriminator training loss: 0.0331, validation loss: 0.1568
2024-05-25 03:37:05 [INFO]: Epoch 037 - generator training loss: 0.0525, discriminator training loss: 0.0324, validation loss: 0.1569
2024-05-25 03:37:09 [INFO]: Epoch 038 - generator training loss: 0.0536, discriminator training loss: 0.0317, validation loss: 0.1557
2024-05-25 03:37:14 [INFO]: Epoch 039 - generator training loss: 0.0520, discriminator training loss: 0.0311, validation loss: 0.1553
2024-05-25 03:37:18 [INFO]: Epoch 040 - generator training loss: 0.0514, discriminator training loss: 0.0306, validation loss: 0.1551
2024-05-25 03:37:22 [INFO]: Epoch 041 - generator training loss: 0.0509, discriminator training loss: 0.0302, validation loss: 0.1548
2024-05-25 03:37:27 [INFO]: Epoch 042 - generator training loss: 0.0506, discriminator training loss: 0.0295, validation loss: 0.1540
2024-05-25 03:37:31 [INFO]: Epoch 043 - generator training loss: 0.0502, discriminator training loss: 0.0290, validation loss: 0.1529
2024-05-25 03:37:35 [INFO]: Epoch 044 - generator training loss: 0.0496, discriminator training loss: 0.0283, validation loss: 0.1539
2024-05-25 03:37:40 [INFO]: Epoch 045 - generator training loss: 0.0482, discriminator training loss: 0.0280, validation loss: 0.1528
2024-05-25 03:37:44 [INFO]: Epoch 046 - generator training loss: 0.0474, discriminator training loss: 0.0274, validation loss: 0.1531
2024-05-25 03:37:48 [INFO]: Epoch 047 - generator training loss: 0.0468, discriminator training loss: 0.0268, validation loss: 0.1524
2024-05-25 03:37:52 [INFO]: Epoch 048 - generator training loss: 0.0469, discriminator training loss: 0.0263, validation loss: 0.1516
2024-05-25 03:37:56 [INFO]: Epoch 049 - generator training loss: 0.0464, discriminator training loss: 0.0258, validation loss: 0.1518
2024-05-25 03:38:01 [INFO]: Epoch 050 - generator training loss: 0.0466, discriminator training loss: 0.0259, validation loss: 0.1500
2024-05-25 03:38:05 [INFO]: Epoch 051 - generator training loss: 0.0471, discriminator training loss: 0.0251, validation loss: 0.1501
2024-05-25 03:38:09 [INFO]: Epoch 052 - generator training loss: 0.0453, discriminator training loss: 0.0247, validation loss: 0.1499
2024-05-25 03:38:14 [INFO]: Epoch 053 - generator training loss: 0.0457, discriminator training loss: 0.0243, validation loss: 0.1491
2024-05-25 03:38:18 [INFO]: Epoch 054 - generator training loss: 0.0472, discriminator training loss: 0.0238, validation loss: 0.1488
2024-05-25 03:38:22 [INFO]: Epoch 055 - generator training loss: 0.0444, discriminator training loss: 0.0235, validation loss: 0.1491
2024-05-25 03:38:27 [INFO]: Epoch 056 - generator training loss: 0.0442, discriminator training loss: 0.0231, validation loss: 0.1483
2024-05-25 03:38:31 [INFO]: Epoch 057 - generator training loss: 0.0441, discriminator training loss: 0.0229, validation loss: 0.1477
2024-05-25 03:38:35 [INFO]: Epoch 058 - generator training loss: 0.0438, discriminator training loss: 0.0226, validation loss: 0.1470
2024-05-25 03:38:39 [INFO]: Epoch 059 - generator training loss: 0.0438, discriminator training loss: 0.0222, validation loss: 0.1479
2024-05-25 03:38:44 [INFO]: Epoch 060 - generator training loss: 0.0432, discriminator training loss: 0.0221, validation loss: 0.1470
2024-05-25 03:38:48 [INFO]: Epoch 061 - generator training loss: 0.0427, discriminator training loss: 0.0217, validation loss: 0.1468
2024-05-25 03:38:52 [INFO]: Epoch 062 - generator training loss: 0.0418, discriminator training loss: 0.0217, validation loss: 0.1461
2024-05-25 03:38:57 [INFO]: Epoch 063 - generator training loss: 0.0423, discriminator training loss: 0.0212, validation loss: 0.1462
2024-05-25 03:39:01 [INFO]: Epoch 064 - generator training loss: 0.0421, discriminator training loss: 0.0210, validation loss: 0.1464
2024-05-25 03:39:05 [INFO]: Epoch 065 - generator training loss: 0.0422, discriminator training loss: 0.0208, validation loss: 0.1470
2024-05-25 03:39:10 [INFO]: Epoch 066 - generator training loss: 0.0424, discriminator training loss: 0.0207, validation loss: 0.1458
2024-05-25 03:39:14 [INFO]: Epoch 067 - generator training loss: 0.0411, discriminator training loss: 0.0202, validation loss: 0.1459
2024-05-25 03:39:18 [INFO]: Epoch 068 - generator training loss: 0.0408, discriminator training loss: 0.0201, validation loss: 0.1453
2024-05-25 03:39:23 [INFO]: Epoch 069 - generator training loss: 0.0417, discriminator training loss: 0.0197, validation loss: 0.1466
2024-05-25 03:39:27 [INFO]: Epoch 070 - generator training loss: 0.0406, discriminator training loss: 0.0196, validation loss: 0.1449
2024-05-25 03:39:31 [INFO]: Epoch 071 - generator training loss: 0.0410, discriminator training loss: 0.0192, validation loss: 0.1445
2024-05-25 03:39:36 [INFO]: Epoch 072 - generator training loss: 0.0402, discriminator training loss: 0.0190, validation loss: 0.1449
2024-05-25 03:39:40 [INFO]: Epoch 073 - generator training loss: 0.0416, discriminator training loss: 0.0188, validation loss: 0.1442
2024-05-25 03:39:44 [INFO]: Epoch 074 - generator training loss: 0.0413, discriminator training loss: 0.0187, validation loss: 0.1453
2024-05-25 03:39:48 [INFO]: Epoch 075 - generator training loss: 0.0396, discriminator training loss: 0.0188, validation loss: 0.1453
2024-05-25 03:39:53 [INFO]: Epoch 076 - generator training loss: 0.0405, discriminator training loss: 0.0185, validation loss: 0.1452
2024-05-25 03:39:57 [INFO]: Epoch 077 - generator training loss: 0.0390, discriminator training loss: 0.0184, validation loss: 0.1449
2024-05-25 03:40:01 [INFO]: Epoch 078 - generator training loss: 0.0390, discriminator training loss: 0.0182, validation loss: 0.1450
2024-05-25 03:40:06 [INFO]: Epoch 079 - generator training loss: 0.0391, discriminator training loss: 0.0179, validation loss: 0.1451
2024-05-25 03:40:10 [INFO]: Epoch 080 - generator training loss: 0.0384, discriminator training loss: 0.0177, validation loss: 0.1450
2024-05-25 03:40:14 [INFO]: Epoch 081 - generator training loss: 0.0389, discriminator training loss: 0.0177, validation loss: 0.1450
2024-05-25 03:40:19 [INFO]: Epoch 082 - generator training loss: 0.0380, discriminator training loss: 0.0175, validation loss: 0.1447
2024-05-25 03:40:23 [INFO]: Epoch 083 - generator training loss: 0.0380, discriminator training loss: 0.0174, validation loss: 0.1462
2024-05-25 03:40:23 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:40:23 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 03:40:23 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/USGAN_air_quality/20240525_T033425/USGAN.pypots
2024-05-25 03:40:24 [INFO]: US-GAN on Air-Quality: MAE=0.2056, MSE=0.1351
2024-05-25 03:40:24 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 03:40:24 [INFO]: Using the given device: cuda:0
2024-05-25 03:40:24 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T034024
2024-05-25 03:40:24 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T034024/tensorboard
2024-05-25 03:40:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:40:27 [INFO]: Epoch 001 - training loss: 1.3898, validation loss: 0.9453
2024-05-25 03:40:30 [INFO]: Epoch 002 - training loss: 1.1177, validation loss: 0.7088
2024-05-25 03:40:33 [INFO]: Epoch 003 - training loss: 0.9295, validation loss: 0.6000
2024-05-25 03:40:36 [INFO]: Epoch 004 - training loss: 0.8209, validation loss: 0.5336
2024-05-25 03:40:39 [INFO]: Epoch 005 - training loss: 0.7460, validation loss: 0.4881
2024-05-25 03:40:42 [INFO]: Epoch 006 - training loss: 0.6924, validation loss: 0.4499
2024-05-25 03:40:45 [INFO]: Epoch 007 - training loss: 0.6494, validation loss: 0.4199
2024-05-25 03:40:48 [INFO]: Epoch 008 - training loss: 0.6177, validation loss: 0.3942
2024-05-25 03:40:51 [INFO]: Epoch 009 - training loss: 0.5910, validation loss: 0.3748
2024-05-25 03:40:54 [INFO]: Epoch 010 - training loss: 0.5704, validation loss: 0.3578
2024-05-25 03:40:57 [INFO]: Epoch 011 - training loss: 0.5520, validation loss: 0.3442
2024-05-25 03:41:00 [INFO]: Epoch 012 - training loss: 0.5371, validation loss: 0.3327
2024-05-25 03:41:03 [INFO]: Epoch 013 - training loss: 0.5247, validation loss: 0.3222
2024-05-25 03:41:06 [INFO]: Epoch 014 - training loss: 0.5130, validation loss: 0.3137
2024-05-25 03:41:09 [INFO]: Epoch 015 - training loss: 0.5035, validation loss: 0.3061
2024-05-25 03:41:12 [INFO]: Epoch 016 - training loss: 0.4943, validation loss: 0.2988
2024-05-25 03:41:14 [INFO]: Epoch 017 - training loss: 0.4835, validation loss: 0.2927
2024-05-25 03:41:17 [INFO]: Epoch 018 - training loss: 0.4768, validation loss: 0.2871
2024-05-25 03:41:20 [INFO]: Epoch 019 - training loss: 0.4681, validation loss: 0.2819
2024-05-25 03:41:23 [INFO]: Epoch 020 - training loss: 0.4607, validation loss: 0.2770
2024-05-25 03:41:26 [INFO]: Epoch 021 - training loss: 0.4547, validation loss: 0.2726
2024-05-25 03:41:29 [INFO]: Epoch 022 - training loss: 0.4472, validation loss: 0.2681
2024-05-25 03:41:32 [INFO]: Epoch 023 - training loss: 0.4413, validation loss: 0.2642
2024-05-25 03:41:35 [INFO]: Epoch 024 - training loss: 0.4354, validation loss: 0.2603
2024-05-25 03:41:38 [INFO]: Epoch 025 - training loss: 0.4301, validation loss: 0.2562
2024-05-25 03:41:41 [INFO]: Epoch 026 - training loss: 0.4241, validation loss: 0.2527
2024-05-25 03:41:44 [INFO]: Epoch 027 - training loss: 0.4189, validation loss: 0.2494
2024-05-25 03:41:47 [INFO]: Epoch 028 - training loss: 0.4142, validation loss: 0.2459
2024-05-25 03:41:50 [INFO]: Epoch 029 - training loss: 0.4090, validation loss: 0.2433
2024-05-25 03:41:53 [INFO]: Epoch 030 - training loss: 0.4049, validation loss: 0.2399
2024-05-25 03:41:56 [INFO]: Epoch 031 - training loss: 0.4001, validation loss: 0.2370
2024-05-25 03:41:59 [INFO]: Epoch 032 - training loss: 0.3963, validation loss: 0.2343
2024-05-25 03:42:01 [INFO]: Epoch 033 - training loss: 0.3919, validation loss: 0.2312
2024-05-25 03:42:04 [INFO]: Epoch 034 - training loss: 0.3886, validation loss: 0.2287
2024-05-25 03:42:07 [INFO]: Epoch 035 - training loss: 0.3839, validation loss: 0.2266
2024-05-25 03:42:10 [INFO]: Epoch 036 - training loss: 0.3797, validation loss: 0.2233
2024-05-25 03:42:13 [INFO]: Epoch 037 - training loss: 0.3775, validation loss: 0.2211
2024-05-25 03:42:16 [INFO]: Epoch 038 - training loss: 0.3725, validation loss: 0.2183
2024-05-25 03:42:19 [INFO]: Epoch 039 - training loss: 0.3691, validation loss: 0.2161
2024-05-25 03:42:22 [INFO]: Epoch 040 - training loss: 0.3661, validation loss: 0.2136
2024-05-25 03:42:25 [INFO]: Epoch 041 - training loss: 0.3625, validation loss: 0.2113
2024-05-25 03:42:28 [INFO]: Epoch 042 - training loss: 0.3604, validation loss: 0.2091
2024-05-25 03:42:31 [INFO]: Epoch 043 - training loss: 0.3575, validation loss: 0.2066
2024-05-25 03:42:34 [INFO]: Epoch 044 - training loss: 0.3546, validation loss: 0.2042
2024-05-25 03:42:37 [INFO]: Epoch 045 - training loss: 0.3520, validation loss: 0.2022
2024-05-25 03:42:40 [INFO]: Epoch 046 - training loss: 0.3485, validation loss: 0.2001
2024-05-25 03:42:43 [INFO]: Epoch 047 - training loss: 0.3470, validation loss: 0.1986
2024-05-25 03:42:45 [INFO]: Epoch 048 - training loss: 0.3450, validation loss: 0.1960
2024-05-25 03:42:48 [INFO]: Epoch 049 - training loss: 0.3418, validation loss: 0.1941
2024-05-25 03:42:51 [INFO]: Epoch 050 - training loss: 0.3388, validation loss: 0.1926
2024-05-25 03:42:54 [INFO]: Epoch 051 - training loss: 0.3370, validation loss: 0.1911
2024-05-25 03:42:57 [INFO]: Epoch 052 - training loss: 0.3351, validation loss: 0.1889
2024-05-25 03:43:00 [INFO]: Epoch 053 - training loss: 0.3332, validation loss: 0.1872
2024-05-25 03:43:03 [INFO]: Epoch 054 - training loss: 0.3308, validation loss: 0.1860
2024-05-25 03:43:06 [INFO]: Epoch 055 - training loss: 0.3290, validation loss: 0.1847
2024-05-25 03:43:09 [INFO]: Epoch 056 - training loss: 0.3273, validation loss: 0.1827
2024-05-25 03:43:12 [INFO]: Epoch 057 - training loss: 0.3255, validation loss: 0.1813
2024-05-25 03:43:15 [INFO]: Epoch 058 - training loss: 0.3231, validation loss: 0.1801
2024-05-25 03:43:18 [INFO]: Epoch 059 - training loss: 0.3218, validation loss: 0.1792
2024-05-25 03:43:21 [INFO]: Epoch 060 - training loss: 0.3197, validation loss: 0.1778
2024-05-25 03:43:24 [INFO]: Epoch 061 - training loss: 0.3187, validation loss: 0.1761
2024-05-25 03:43:27 [INFO]: Epoch 062 - training loss: 0.3165, validation loss: 0.1749
2024-05-25 03:43:29 [INFO]: Epoch 063 - training loss: 0.3155, validation loss: 0.1740
2024-05-25 03:43:32 [INFO]: Epoch 064 - training loss: 0.3133, validation loss: 0.1730
2024-05-25 03:43:35 [INFO]: Epoch 065 - training loss: 0.3123, validation loss: 0.1722
2024-05-25 03:43:38 [INFO]: Epoch 066 - training loss: 0.3113, validation loss: 0.1709
2024-05-25 03:43:41 [INFO]: Epoch 067 - training loss: 0.3096, validation loss: 0.1700
2024-05-25 03:43:44 [INFO]: Epoch 068 - training loss: 0.3077, validation loss: 0.1691
2024-05-25 03:43:47 [INFO]: Epoch 069 - training loss: 0.3064, validation loss: 0.1683
2024-05-25 03:43:50 [INFO]: Epoch 070 - training loss: 0.3057, validation loss: 0.1669
2024-05-25 03:43:53 [INFO]: Epoch 071 - training loss: 0.3047, validation loss: 0.1662
2024-05-25 03:43:56 [INFO]: Epoch 072 - training loss: 0.3032, validation loss: 0.1653
2024-05-25 03:43:59 [INFO]: Epoch 073 - training loss: 0.3021, validation loss: 0.1645
2024-05-25 03:44:02 [INFO]: Epoch 074 - training loss: 0.3017, validation loss: 0.1639
2024-05-25 03:44:05 [INFO]: Epoch 075 - training loss: 0.3000, validation loss: 0.1629
2024-05-25 03:44:07 [INFO]: Epoch 076 - training loss: 0.2992, validation loss: 0.1622
2024-05-25 03:44:10 [INFO]: Epoch 077 - training loss: 0.2977, validation loss: 0.1617
2024-05-25 03:44:13 [INFO]: Epoch 078 - training loss: 0.2970, validation loss: 0.1610
2024-05-25 03:44:16 [INFO]: Epoch 079 - training loss: 0.2958, validation loss: 0.1601
2024-05-25 03:44:19 [INFO]: Epoch 080 - training loss: 0.2957, validation loss: 0.1594
2024-05-25 03:44:22 [INFO]: Epoch 081 - training loss: 0.2946, validation loss: 0.1590
2024-05-25 03:44:25 [INFO]: Epoch 082 - training loss: 0.2939, validation loss: 0.1583
2024-05-25 03:44:28 [INFO]: Epoch 083 - training loss: 0.2932, validation loss: 0.1576
2024-05-25 03:44:31 [INFO]: Epoch 084 - training loss: 0.2914, validation loss: 0.1571
2024-05-25 03:44:34 [INFO]: Epoch 085 - training loss: 0.2909, validation loss: 0.1564
2024-05-25 03:44:37 [INFO]: Epoch 086 - training loss: 0.2894, validation loss: 0.1558
2024-05-25 03:44:40 [INFO]: Epoch 087 - training loss: 0.2897, validation loss: 0.1553
2024-05-25 03:44:43 [INFO]: Epoch 088 - training loss: 0.2881, validation loss: 0.1549
2024-05-25 03:44:45 [INFO]: Epoch 089 - training loss: 0.2871, validation loss: 0.1543
2024-05-25 03:44:48 [INFO]: Epoch 090 - training loss: 0.2869, validation loss: 0.1538
2024-05-25 03:44:51 [INFO]: Epoch 091 - training loss: 0.2863, validation loss: 0.1532
2024-05-25 03:44:54 [INFO]: Epoch 092 - training loss: 0.2858, validation loss: 0.1525
2024-05-25 03:44:57 [INFO]: Epoch 093 - training loss: 0.2841, validation loss: 0.1522
2024-05-25 03:45:00 [INFO]: Epoch 094 - training loss: 0.2840, validation loss: 0.1515
2024-05-25 03:45:03 [INFO]: Epoch 095 - training loss: 0.2829, validation loss: 0.1511
2024-05-25 03:45:06 [INFO]: Epoch 096 - training loss: 0.2827, validation loss: 0.1509
2024-05-25 03:45:09 [INFO]: Epoch 097 - training loss: 0.2821, validation loss: 0.1503
2024-05-25 03:45:11 [INFO]: Epoch 098 - training loss: 0.2808, validation loss: 0.1498
2024-05-25 03:45:14 [INFO]: Epoch 099 - training loss: 0.2806, validation loss: 0.1495
2024-05-25 03:45:17 [INFO]: Epoch 100 - training loss: 0.2794, validation loss: 0.1488
2024-05-25 03:45:20 [INFO]: Epoch 101 - training loss: 0.2792, validation loss: 0.1485
2024-05-25 03:45:23 [INFO]: Epoch 102 - training loss: 0.2783, validation loss: 0.1481
2024-05-25 03:45:26 [INFO]: Epoch 103 - training loss: 0.2775, validation loss: 0.1477
2024-05-25 03:45:29 [INFO]: Epoch 104 - training loss: 0.2771, validation loss: 0.1472
2024-05-25 03:45:32 [INFO]: Epoch 105 - training loss: 0.2767, validation loss: 0.1469
2024-05-25 03:45:35 [INFO]: Epoch 106 - training loss: 0.2763, validation loss: 0.1465
2024-05-25 03:45:38 [INFO]: Epoch 107 - training loss: 0.2758, validation loss: 0.1462
2024-05-25 03:45:41 [INFO]: Epoch 108 - training loss: 0.2746, validation loss: 0.1459
2024-05-25 03:45:44 [INFO]: Epoch 109 - training loss: 0.2747, validation loss: 0.1454
2024-05-25 03:45:47 [INFO]: Epoch 110 - training loss: 0.2741, validation loss: 0.1452
2024-05-25 03:45:50 [INFO]: Epoch 111 - training loss: 0.2734, validation loss: 0.1448
2024-05-25 03:45:53 [INFO]: Epoch 112 - training loss: 0.2726, validation loss: 0.1442
2024-05-25 03:45:55 [INFO]: Epoch 113 - training loss: 0.2726, validation loss: 0.1441
2024-05-25 03:45:58 [INFO]: Epoch 114 - training loss: 0.2715, validation loss: 0.1438
2024-05-25 03:46:01 [INFO]: Epoch 115 - training loss: 0.2710, validation loss: 0.1435
2024-05-25 03:46:04 [INFO]: Epoch 116 - training loss: 0.2707, validation loss: 0.1431
2024-05-25 03:46:07 [INFO]: Epoch 117 - training loss: 0.2699, validation loss: 0.1427
2024-05-25 03:46:10 [INFO]: Epoch 118 - training loss: 0.2700, validation loss: 0.1425
2024-05-25 03:46:13 [INFO]: Epoch 119 - training loss: 0.2691, validation loss: 0.1420
2024-05-25 03:46:16 [INFO]: Epoch 120 - training loss: 0.2694, validation loss: 0.1417
2024-05-25 03:46:19 [INFO]: Epoch 121 - training loss: 0.2681, validation loss: 0.1415
2024-05-25 03:46:22 [INFO]: Epoch 122 - training loss: 0.2680, validation loss: 0.1410
2024-05-25 03:46:25 [INFO]: Epoch 123 - training loss: 0.2678, validation loss: 0.1408
2024-05-25 03:46:28 [INFO]: Epoch 124 - training loss: 0.2666, validation loss: 0.1406
2024-05-25 03:46:31 [INFO]: Epoch 125 - training loss: 0.2662, validation loss: 0.1404
2024-05-25 03:46:34 [INFO]: Epoch 126 - training loss: 0.2657, validation loss: 0.1399
2024-05-25 03:46:37 [INFO]: Epoch 127 - training loss: 0.2657, validation loss: 0.1397
2024-05-25 03:46:39 [INFO]: Epoch 128 - training loss: 0.2656, validation loss: 0.1394
2024-05-25 03:46:42 [INFO]: Epoch 129 - training loss: 0.2646, validation loss: 0.1391
2024-05-25 03:46:45 [INFO]: Epoch 130 - training loss: 0.2642, validation loss: 0.1389
2024-05-25 03:46:48 [INFO]: Epoch 131 - training loss: 0.2642, validation loss: 0.1384
2024-05-25 03:46:51 [INFO]: Epoch 132 - training loss: 0.2632, validation loss: 0.1383
2024-05-25 03:46:54 [INFO]: Epoch 133 - training loss: 0.2630, validation loss: 0.1382
2024-05-25 03:46:57 [INFO]: Epoch 134 - training loss: 0.2624, validation loss: 0.1378
2024-05-25 03:47:00 [INFO]: Epoch 135 - training loss: 0.2617, validation loss: 0.1375
2024-05-25 03:47:03 [INFO]: Epoch 136 - training loss: 0.2622, validation loss: 0.1371
2024-05-25 03:47:06 [INFO]: Epoch 137 - training loss: 0.2618, validation loss: 0.1371
2024-05-25 03:47:09 [INFO]: Epoch 138 - training loss: 0.2618, validation loss: 0.1368
2024-05-25 03:47:12 [INFO]: Epoch 139 - training loss: 0.2607, validation loss: 0.1366
2024-05-25 03:47:15 [INFO]: Epoch 140 - training loss: 0.2598, validation loss: 0.1362
2024-05-25 03:47:18 [INFO]: Epoch 141 - training loss: 0.2596, validation loss: 0.1361
2024-05-25 03:47:20 [INFO]: Epoch 142 - training loss: 0.2600, validation loss: 0.1357
2024-05-25 03:47:23 [INFO]: Epoch 143 - training loss: 0.2589, validation loss: 0.1355
2024-05-25 03:47:26 [INFO]: Epoch 144 - training loss: 0.2587, validation loss: 0.1352
2024-05-25 03:47:29 [INFO]: Epoch 145 - training loss: 0.2586, validation loss: 0.1351
2024-05-25 03:47:32 [INFO]: Epoch 146 - training loss: 0.2578, validation loss: 0.1349
2024-05-25 03:47:35 [INFO]: Epoch 147 - training loss: 0.2575, validation loss: 0.1344
2024-05-25 03:47:38 [INFO]: Epoch 148 - training loss: 0.2577, validation loss: 0.1342
2024-05-25 03:47:41 [INFO]: Epoch 149 - training loss: 0.2573, validation loss: 0.1340
2024-05-25 03:47:44 [INFO]: Epoch 150 - training loss: 0.2569, validation loss: 0.1339
2024-05-25 03:47:47 [INFO]: Epoch 151 - training loss: 0.2576, validation loss: 0.1336
2024-05-25 03:47:50 [INFO]: Epoch 152 - training loss: 0.2568, validation loss: 0.1334
2024-05-25 03:47:53 [INFO]: Epoch 153 - training loss: 0.2556, validation loss: 0.1333
2024-05-25 03:47:56 [INFO]: Epoch 154 - training loss: 0.2555, validation loss: 0.1331
2024-05-25 03:47:59 [INFO]: Epoch 155 - training loss: 0.2553, validation loss: 0.1332
2024-05-25 03:48:02 [INFO]: Epoch 156 - training loss: 0.2550, validation loss: 0.1327
2024-05-25 03:48:04 [INFO]: Epoch 157 - training loss: 0.2548, validation loss: 0.1325
2024-05-25 03:48:07 [INFO]: Epoch 158 - training loss: 0.2546, validation loss: 0.1324
2024-05-25 03:48:10 [INFO]: Epoch 159 - training loss: 0.2538, validation loss: 0.1321
2024-05-25 03:48:13 [INFO]: Epoch 160 - training loss: 0.2531, validation loss: 0.1320
2024-05-25 03:48:16 [INFO]: Epoch 161 - training loss: 0.2530, validation loss: 0.1318
2024-05-25 03:48:19 [INFO]: Epoch 162 - training loss: 0.2526, validation loss: 0.1317
2024-05-25 03:48:22 [INFO]: Epoch 163 - training loss: 0.2529, validation loss: 0.1315
2024-05-25 03:48:25 [INFO]: Epoch 164 - training loss: 0.2527, validation loss: 0.1313
2024-05-25 03:48:28 [INFO]: Epoch 165 - training loss: 0.2521, validation loss: 0.1311
2024-05-25 03:48:31 [INFO]: Epoch 166 - training loss: 0.2518, validation loss: 0.1308
2024-05-25 03:48:34 [INFO]: Epoch 167 - training loss: 0.2517, validation loss: 0.1308
2024-05-25 03:48:37 [INFO]: Epoch 168 - training loss: 0.2514, validation loss: 0.1303
2024-05-25 03:48:40 [INFO]: Epoch 169 - training loss: 0.2509, validation loss: 0.1305
2024-05-25 03:48:43 [INFO]: Epoch 170 - training loss: 0.2506, validation loss: 0.1302
2024-05-25 03:48:45 [INFO]: Epoch 171 - training loss: 0.2504, validation loss: 0.1302
2024-05-25 03:48:48 [INFO]: Epoch 172 - training loss: 0.2501, validation loss: 0.1297
2024-05-25 03:48:51 [INFO]: Epoch 173 - training loss: 0.2498, validation loss: 0.1297
2024-05-25 03:48:54 [INFO]: Epoch 174 - training loss: 0.2498, validation loss: 0.1296
2024-05-25 03:48:57 [INFO]: Epoch 175 - training loss: 0.2493, validation loss: 0.1293
2024-05-25 03:49:00 [INFO]: Epoch 176 - training loss: 0.2494, validation loss: 0.1294
2024-05-25 03:49:03 [INFO]: Epoch 177 - training loss: 0.2496, validation loss: 0.1290
2024-05-25 03:49:06 [INFO]: Epoch 178 - training loss: 0.2492, validation loss: 0.1289
2024-05-25 03:49:09 [INFO]: Epoch 179 - training loss: 0.2488, validation loss: 0.1288
2024-05-25 03:49:12 [INFO]: Epoch 180 - training loss: 0.2481, validation loss: 0.1286
2024-05-25 03:49:15 [INFO]: Epoch 181 - training loss: 0.2483, validation loss: 0.1286
2024-05-25 03:49:18 [INFO]: Epoch 182 - training loss: 0.2482, validation loss: 0.1286
2024-05-25 03:49:21 [INFO]: Epoch 183 - training loss: 0.2478, validation loss: 0.1283
2024-05-25 03:49:24 [INFO]: Epoch 184 - training loss: 0.2469, validation loss: 0.1283
2024-05-25 03:49:26 [INFO]: Epoch 185 - training loss: 0.2469, validation loss: 0.1280
2024-05-25 03:49:29 [INFO]: Epoch 186 - training loss: 0.2471, validation loss: 0.1278
2024-05-25 03:49:32 [INFO]: Epoch 187 - training loss: 0.2467, validation loss: 0.1277
2024-05-25 03:49:35 [INFO]: Epoch 188 - training loss: 0.2467, validation loss: 0.1277
2024-05-25 03:49:38 [INFO]: Epoch 189 - training loss: 0.2470, validation loss: 0.1274
2024-05-25 03:49:41 [INFO]: Epoch 190 - training loss: 0.2465, validation loss: 0.1272
2024-05-25 03:49:44 [INFO]: Epoch 191 - training loss: 0.2461, validation loss: 0.1273
2024-05-25 03:49:47 [INFO]: Epoch 192 - training loss: 0.2460, validation loss: 0.1270
2024-05-25 03:49:50 [INFO]: Epoch 193 - training loss: 0.2452, validation loss: 0.1268
2024-05-25 03:49:53 [INFO]: Epoch 194 - training loss: 0.2454, validation loss: 0.1269
2024-05-25 03:49:56 [INFO]: Epoch 195 - training loss: 0.2449, validation loss: 0.1266
2024-05-25 03:49:59 [INFO]: Epoch 196 - training loss: 0.2446, validation loss: 0.1266
2024-05-25 03:50:02 [INFO]: Epoch 197 - training loss: 0.2444, validation loss: 0.1264
2024-05-25 03:50:05 [INFO]: Epoch 198 - training loss: 0.2445, validation loss: 0.1265
2024-05-25 03:50:08 [INFO]: Epoch 199 - training loss: 0.2440, validation loss: 0.1262
2024-05-25 03:50:10 [INFO]: Epoch 200 - training loss: 0.2438, validation loss: 0.1263
2024-05-25 03:50:13 [INFO]: Epoch 201 - training loss: 0.2436, validation loss: 0.1260
2024-05-25 03:50:16 [INFO]: Epoch 202 - training loss: 0.2434, validation loss: 0.1261
2024-05-25 03:50:19 [INFO]: Epoch 203 - training loss: 0.2429, validation loss: 0.1261
2024-05-25 03:50:22 [INFO]: Epoch 204 - training loss: 0.2429, validation loss: 0.1260
2024-05-25 03:50:25 [INFO]: Epoch 205 - training loss: 0.2429, validation loss: 0.1257
2024-05-25 03:50:28 [INFO]: Epoch 206 - training loss: 0.2427, validation loss: 0.1255
2024-05-25 03:50:31 [INFO]: Epoch 207 - training loss: 0.2426, validation loss: 0.1254
2024-05-25 03:50:34 [INFO]: Epoch 208 - training loss: 0.2422, validation loss: 0.1254
2024-05-25 03:50:37 [INFO]: Epoch 209 - training loss: 0.2423, validation loss: 0.1252
2024-05-25 03:50:40 [INFO]: Epoch 210 - training loss: 0.2420, validation loss: 0.1251
2024-05-25 03:50:43 [INFO]: Epoch 211 - training loss: 0.2421, validation loss: 0.1251
2024-05-25 03:50:46 [INFO]: Epoch 212 - training loss: 0.2415, validation loss: 0.1250
2024-05-25 03:50:49 [INFO]: Epoch 213 - training loss: 0.2417, validation loss: 0.1250
2024-05-25 03:50:52 [INFO]: Epoch 214 - training loss: 0.2409, validation loss: 0.1249
2024-05-25 03:50:54 [INFO]: Epoch 215 - training loss: 0.2411, validation loss: 0.1245
2024-05-25 03:50:57 [INFO]: Epoch 216 - training loss: 0.2409, validation loss: 0.1247
2024-05-25 03:51:00 [INFO]: Epoch 217 - training loss: 0.2402, validation loss: 0.1246
2024-05-25 03:51:03 [INFO]: Epoch 218 - training loss: 0.2406, validation loss: 0.1243
2024-05-25 03:51:06 [INFO]: Epoch 219 - training loss: 0.2403, validation loss: 0.1244
2024-05-25 03:51:09 [INFO]: Epoch 220 - training loss: 0.2401, validation loss: 0.1242
2024-05-25 03:51:12 [INFO]: Epoch 221 - training loss: 0.2403, validation loss: 0.1241
2024-05-25 03:51:15 [INFO]: Epoch 222 - training loss: 0.2400, validation loss: 0.1244
2024-05-25 03:51:18 [INFO]: Epoch 223 - training loss: 0.2394, validation loss: 0.1242
2024-05-25 03:51:21 [INFO]: Epoch 224 - training loss: 0.2391, validation loss: 0.1242
2024-05-25 03:51:24 [INFO]: Epoch 225 - training loss: 0.2391, validation loss: 0.1238
2024-05-25 03:51:27 [INFO]: Epoch 226 - training loss: 0.2392, validation loss: 0.1239
2024-05-25 03:51:30 [INFO]: Epoch 227 - training loss: 0.2386, validation loss: 0.1238
2024-05-25 03:51:33 [INFO]: Epoch 228 - training loss: 0.2390, validation loss: 0.1237
2024-05-25 03:51:35 [INFO]: Epoch 229 - training loss: 0.2391, validation loss: 0.1236
2024-05-25 03:51:38 [INFO]: Epoch 230 - training loss: 0.2384, validation loss: 0.1236
2024-05-25 03:51:41 [INFO]: Epoch 231 - training loss: 0.2383, validation loss: 0.1233
2024-05-25 03:51:44 [INFO]: Epoch 232 - training loss: 0.2383, validation loss: 0.1233
2024-05-25 03:51:47 [INFO]: Epoch 233 - training loss: 0.2384, validation loss: 0.1232
2024-05-25 03:51:50 [INFO]: Epoch 234 - training loss: 0.2381, validation loss: 0.1234
2024-05-25 03:51:53 [INFO]: Epoch 235 - training loss: 0.2380, validation loss: 0.1233
2024-05-25 03:51:56 [INFO]: Epoch 236 - training loss: 0.2373, validation loss: 0.1231
2024-05-25 03:51:59 [INFO]: Epoch 237 - training loss: 0.2377, validation loss: 0.1230
2024-05-25 03:52:02 [INFO]: Epoch 238 - training loss: 0.2373, validation loss: 0.1228
2024-05-25 03:52:05 [INFO]: Epoch 239 - training loss: 0.2370, validation loss: 0.1228
2024-05-25 03:52:08 [INFO]: Epoch 240 - training loss: 0.2367, validation loss: 0.1230
2024-05-25 03:52:11 [INFO]: Epoch 241 - training loss: 0.2372, validation loss: 0.1227
2024-05-25 03:52:14 [INFO]: Epoch 242 - training loss: 0.2372, validation loss: 0.1228
2024-05-25 03:52:17 [INFO]: Epoch 243 - training loss: 0.2365, validation loss: 0.1224
2024-05-25 03:52:19 [INFO]: Epoch 244 - training loss: 0.2359, validation loss: 0.1225
2024-05-25 03:52:22 [INFO]: Epoch 245 - training loss: 0.2360, validation loss: 0.1224
2024-05-25 03:52:25 [INFO]: Epoch 246 - training loss: 0.2357, validation loss: 0.1225
2024-05-25 03:52:28 [INFO]: Epoch 247 - training loss: 0.2357, validation loss: 0.1224
2024-05-25 03:52:31 [INFO]: Epoch 248 - training loss: 0.2360, validation loss: 0.1224
2024-05-25 03:52:34 [INFO]: Epoch 249 - training loss: 0.2357, validation loss: 0.1225
2024-05-25 03:52:37 [INFO]: Epoch 250 - training loss: 0.2355, validation loss: 0.1223
2024-05-25 03:52:40 [INFO]: Epoch 251 - training loss: 0.2353, validation loss: 0.1221
2024-05-25 03:52:43 [INFO]: Epoch 252 - training loss: 0.2352, validation loss: 0.1224
2024-05-25 03:52:45 [INFO]: Epoch 253 - training loss: 0.2353, validation loss: 0.1221
2024-05-25 03:52:48 [INFO]: Epoch 254 - training loss: 0.2351, validation loss: 0.1222
2024-05-25 03:52:51 [INFO]: Epoch 255 - training loss: 0.2350, validation loss: 0.1221
2024-05-25 03:52:54 [INFO]: Epoch 256 - training loss: 0.2345, validation loss: 0.1219
2024-05-25 03:52:57 [INFO]: Epoch 257 - training loss: 0.2344, validation loss: 0.1218
2024-05-25 03:53:00 [INFO]: Epoch 258 - training loss: 0.2347, validation loss: 0.1217
2024-05-25 03:53:03 [INFO]: Epoch 259 - training loss: 0.2342, validation loss: 0.1216
2024-05-25 03:53:06 [INFO]: Epoch 260 - training loss: 0.2343, validation loss: 0.1215
2024-05-25 03:53:09 [INFO]: Epoch 261 - training loss: 0.2338, validation loss: 0.1217
2024-05-25 03:53:12 [INFO]: Epoch 262 - training loss: 0.2335, validation loss: 0.1217
2024-05-25 03:53:15 [INFO]: Epoch 263 - training loss: 0.2338, validation loss: 0.1215
2024-05-25 03:53:18 [INFO]: Epoch 264 - training loss: 0.2337, validation loss: 0.1216
2024-05-25 03:53:21 [INFO]: Epoch 265 - training loss: 0.2333, validation loss: 0.1215
2024-05-25 03:53:24 [INFO]: Epoch 266 - training loss: 0.2333, validation loss: 0.1216
2024-05-25 03:53:26 [INFO]: Epoch 267 - training loss: 0.2336, validation loss: 0.1214
2024-05-25 03:53:29 [INFO]: Epoch 268 - training loss: 0.2327, validation loss: 0.1213
2024-05-25 03:53:32 [INFO]: Epoch 269 - training loss: 0.2332, validation loss: 0.1214
2024-05-25 03:53:35 [INFO]: Epoch 270 - training loss: 0.2324, validation loss: 0.1212
2024-05-25 03:53:38 [INFO]: Epoch 271 - training loss: 0.2327, validation loss: 0.1212
2024-05-25 03:53:41 [INFO]: Epoch 272 - training loss: 0.2328, validation loss: 0.1213
2024-05-25 03:53:44 [INFO]: Epoch 273 - training loss: 0.2321, validation loss: 0.1213
2024-05-25 03:53:47 [INFO]: Epoch 274 - training loss: 0.2332, validation loss: 0.1212
2024-05-25 03:53:50 [INFO]: Epoch 275 - training loss: 0.2321, validation loss: 0.1210
2024-05-25 03:53:53 [INFO]: Epoch 276 - training loss: 0.2319, validation loss: 0.1208
2024-05-25 03:53:56 [INFO]: Epoch 277 - training loss: 0.2319, validation loss: 0.1210
2024-05-25 03:53:59 [INFO]: Epoch 278 - training loss: 0.2314, validation loss: 0.1210
2024-05-25 03:54:02 [INFO]: Epoch 279 - training loss: 0.2313, validation loss: 0.1209
2024-05-25 03:54:05 [INFO]: Epoch 280 - training loss: 0.2319, validation loss: 0.1207
2024-05-25 03:54:08 [INFO]: Epoch 281 - training loss: 0.2320, validation loss: 0.1207
2024-05-25 03:54:11 [INFO]: Epoch 282 - training loss: 0.2318, validation loss: 0.1207
2024-05-25 03:54:13 [INFO]: Epoch 283 - training loss: 0.2309, validation loss: 0.1207
2024-05-25 03:54:16 [INFO]: Epoch 284 - training loss: 0.2309, validation loss: 0.1207
2024-05-25 03:54:19 [INFO]: Epoch 285 - training loss: 0.2315, validation loss: 0.1207
2024-05-25 03:54:22 [INFO]: Epoch 286 - training loss: 0.2307, validation loss: 0.1207
2024-05-25 03:54:25 [INFO]: Epoch 287 - training loss: 0.2312, validation loss: 0.1205
2024-05-25 03:54:28 [INFO]: Epoch 288 - training loss: 0.2311, validation loss: 0.1206
2024-05-25 03:54:31 [INFO]: Epoch 289 - training loss: 0.2305, validation loss: 0.1203
2024-05-25 03:54:34 [INFO]: Epoch 290 - training loss: 0.2301, validation loss: 0.1205
2024-05-25 03:54:37 [INFO]: Epoch 291 - training loss: 0.2306, validation loss: 0.1203
2024-05-25 03:54:40 [INFO]: Epoch 292 - training loss: 0.2300, validation loss: 0.1202
2024-05-25 03:54:43 [INFO]: Epoch 293 - training loss: 0.2300, validation loss: 0.1203
2024-05-25 03:54:46 [INFO]: Epoch 294 - training loss: 0.2300, validation loss: 0.1202
2024-05-25 03:54:49 [INFO]: Epoch 295 - training loss: 0.2296, validation loss: 0.1203
2024-05-25 03:54:52 [INFO]: Epoch 296 - training loss: 0.2296, validation loss: 0.1202
2024-05-25 03:54:54 [INFO]: Epoch 297 - training loss: 0.2296, validation loss: 0.1202
2024-05-25 03:54:57 [INFO]: Epoch 298 - training loss: 0.2294, validation loss: 0.1203
2024-05-25 03:55:00 [INFO]: Epoch 299 - training loss: 0.2296, validation loss: 0.1202
2024-05-25 03:55:03 [INFO]: Epoch 300 - training loss: 0.2292, validation loss: 0.1201
2024-05-25 03:55:03 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 03:55:03 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/BRITS_air_quality/20240525_T034024/BRITS.pypots
2024-05-25 03:55:04 [INFO]: BRITS on Air-Quality: MAE=0.1524, MSE=0.1099
2024-05-25 03:55:04 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 03:55:04 [INFO]: Using the given device: cuda:0
2024-05-25 03:55:04 [INFO]: Model files will be saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504
2024-05-25 03:55:04 [INFO]: Tensorboard file will be saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/tensorboard
2024-05-25 03:55:04 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 03:55:09 [INFO]: Epoch 001 - training loss: 1.3987, validation loss: 0.8046
2024-05-25 03:55:09 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch1_loss0.8045931339263916.pypots
2024-05-25 03:55:13 [INFO]: Epoch 002 - training loss: 1.0515, validation loss: 0.7433
2024-05-25 03:55:13 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch2_loss0.7432984203100205.pypots
2024-05-25 03:55:17 [INFO]: Epoch 003 - training loss: 0.9846, validation loss: 0.7247
2024-05-25 03:55:17 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch3_loss0.7247129797935485.pypots
2024-05-25 03:55:21 [INFO]: Epoch 004 - training loss: 0.9697, validation loss: 0.7128
2024-05-25 03:55:21 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch4_loss0.7127901166677475.pypots
2024-05-25 03:55:25 [INFO]: Epoch 005 - training loss: 0.9521, validation loss: 0.7033
2024-05-25 03:55:25 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch5_loss0.7033478528261184.pypots
2024-05-25 03:55:29 [INFO]: Epoch 006 - training loss: 0.9418, validation loss: 0.6972
2024-05-25 03:55:29 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch6_loss0.6972323805093765.pypots
2024-05-25 03:55:33 [INFO]: Epoch 007 - training loss: 0.9493, validation loss: 0.6943
2024-05-25 03:55:33 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch7_loss0.6943160712718963.pypots
2024-05-25 03:55:37 [INFO]: Epoch 008 - training loss: 0.9138, validation loss: 0.6909
2024-05-25 03:55:37 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch8_loss0.6908520370721817.pypots
2024-05-25 03:55:41 [INFO]: Epoch 009 - training loss: 0.9216, validation loss: 0.6878
2024-05-25 03:55:41 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch9_loss0.6878037840127945.pypots
2024-05-25 03:55:45 [INFO]: Epoch 010 - training loss: 0.9062, validation loss: 0.6862
2024-05-25 03:55:45 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch10_loss0.6862350106239319.pypots
2024-05-25 03:55:48 [INFO]: Epoch 011 - training loss: 0.9103, validation loss: 0.6853
2024-05-25 03:55:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch11_loss0.6852603912353515.pypots
2024-05-25 03:55:52 [INFO]: Epoch 012 - training loss: 0.9128, validation loss: 0.6837
2024-05-25 03:55:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch12_loss0.6836945295333863.pypots
2024-05-25 03:55:56 [INFO]: Epoch 013 - training loss: 0.9186, validation loss: 0.6821
2024-05-25 03:55:56 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch13_loss0.6821340382099151.pypots
2024-05-25 03:56:00 [INFO]: Epoch 014 - training loss: 0.8943, validation loss: 0.6822
2024-05-25 03:56:00 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch14_loss0.6821641385555267.pypots
2024-05-25 03:56:04 [INFO]: Epoch 015 - training loss: 0.8926, validation loss: 0.6825
2024-05-25 03:56:04 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch15_loss0.6825432658195496.pypots
2024-05-25 03:56:08 [INFO]: Epoch 016 - training loss: 0.8894, validation loss: 0.6838
2024-05-25 03:56:08 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch16_loss0.6838187485933304.pypots
2024-05-25 03:56:12 [INFO]: Epoch 017 - training loss: 0.8891, validation loss: 0.6817
2024-05-25 03:56:12 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch17_loss0.6817297726869583.pypots
2024-05-25 03:56:16 [INFO]: Epoch 018 - training loss: 0.8823, validation loss: 0.6818
2024-05-25 03:56:16 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch18_loss0.681797206401825.pypots
2024-05-25 03:56:20 [INFO]: Epoch 019 - training loss: 0.8830, validation loss: 0.6829
2024-05-25 03:56:20 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch19_loss0.6829404264688492.pypots
2024-05-25 03:56:24 [INFO]: Epoch 020 - training loss: 0.9083, validation loss: 0.6840
2024-05-25 03:56:24 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch20_loss0.6840262830257415.pypots
2024-05-25 03:56:28 [INFO]: Epoch 021 - training loss: 0.8943, validation loss: 0.6852
2024-05-25 03:56:28 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch21_loss0.6852002888917923.pypots
2024-05-25 03:56:32 [INFO]: Epoch 022 - training loss: 0.8890, validation loss: 0.6833
2024-05-25 03:56:32 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch22_loss0.6833422034978867.pypots
2024-05-25 03:56:36 [INFO]: Epoch 023 - training loss: 0.8644, validation loss: 0.6835
2024-05-25 03:56:36 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch23_loss0.68348248898983.pypots
2024-05-25 03:56:40 [INFO]: Epoch 024 - training loss: 0.8715, validation loss: 0.6882
2024-05-25 03:56:40 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch24_loss0.6881781458854676.pypots
2024-05-25 03:56:44 [INFO]: Epoch 025 - training loss: 0.8645, validation loss: 0.6919
2024-05-25 03:56:44 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch25_loss0.6918707460165023.pypots
2024-05-25 03:56:48 [INFO]: Epoch 026 - training loss: 0.8736, validation loss: 0.6860
2024-05-25 03:56:48 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch26_loss0.6859761506319046.pypots
2024-05-25 03:56:52 [INFO]: Epoch 027 - training loss: 0.8631, validation loss: 0.6915
2024-05-25 03:56:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN_epoch27_loss0.6914831340312958.pypots
2024-05-25 03:56:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:56:52 [INFO]: Finished training. The best model is from epoch#17.
2024-05-25 03:56:52 [INFO]: Saved the model to overlay_postmask_saved_results/round_4/MRNN_air_quality/20240525_T035504/MRNN.pypots
2024-05-25 03:56:53 [INFO]: MRNN on Air-Quality: MAE=0.5278, MSE=0.6237
2024-05-25 03:56:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 03:56:53 [INFO]: Using the given device: cpu
2024-05-25 03:56:53 [INFO]: LOCF on Air-Quality: MAE=0.2195, MSE=0.2798
2024-05-25 03:56:53 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 03:56:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 03:56:53 [INFO]: Median on Air-Quality: MAE=0.6624, MSE=1.0025
2024-05-25 03:56:53 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 03:56:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 03:56:53 [INFO]: Mean on Air-Quality: MAE=0.6941, MSE=0.9443
2024-05-25 03:56:53 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 03:56:53 [INFO]: Successfully saved to overlay_postmask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 03:56:53 [INFO]: 
SAITS on data/air_quality: MAE=0.151±0.003139551825415447, MSE=0.112±0.0029326552949935445
Transformer on data/air_quality: MAE=0.168±0.007923369928419452, MSE=0.131±0.00928982557215666
TimesNet on data/air_quality: MAE=0.163±0.0036341772117972466, MSE=0.156±0.0037576164729079564
CSDI on data/air_quality: MAE=0.111±0.0015769005047967806, MSE=0.157±0.060143772450578656
GPVAE on data/air_quality: MAE=0.307±0.005001109207218825, MSE=0.263±0.006091339142321338
USGAN on data/air_quality: MAE=0.207±0.0024091350050853377, MSE=0.134±0.002060200089194926
BRITS on data/air_quality: MAE=0.153±0.00034701143104466094, MSE=0.111±0.0009122947359241336
MRNN on data/air_quality: MAE=0.527±0.0011016334329453112, MSE=0.621±0.0019239874589669207
LOCF on data/air_quality: MAE=0.220±2.7755575615628914e-17, MSE=0.280±0.0
Median on data/air_quality: MAE=0.662±0.0, MSE=1.002±0.0
Mean on data/air_quality: MAE=0.694±0.0, MSE=0.944±0.0

