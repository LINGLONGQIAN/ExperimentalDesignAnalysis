2024-05-22 16:21:44 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 16:21:45 [INFO]: Using the given device: cuda:0
2024-05-22 16:21:45 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/SAITS_ettm1/20240522_T162145
2024-05-22 16:21:45 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/SAITS_ettm1/20240522_T162145/tensorboard
2024-05-22 16:21:45 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 16:21:54 [INFO]: Epoch 001 - training loss: 1.2277, validation loss: 0.2812
2024-05-22 16:21:55 [INFO]: Epoch 002 - training loss: 0.9071, validation loss: 0.1330
2024-05-22 16:21:55 [INFO]: Epoch 003 - training loss: 0.8244, validation loss: 0.0924
2024-05-22 16:21:56 [INFO]: Epoch 004 - training loss: 0.7444, validation loss: 0.0876
2024-05-22 16:21:56 [INFO]: Epoch 005 - training loss: 0.7051, validation loss: 0.0799
2024-05-22 16:21:57 [INFO]: Epoch 006 - training loss: 0.6679, validation loss: 0.0684
2024-05-22 16:21:57 [INFO]: Epoch 007 - training loss: 0.6548, validation loss: 0.0677
2024-05-22 16:21:58 [INFO]: Epoch 008 - training loss: 0.6365, validation loss: 0.0799
2024-05-22 16:21:58 [INFO]: Epoch 009 - training loss: 0.6242, validation loss: 0.0577
2024-05-22 16:21:59 [INFO]: Epoch 010 - training loss: 0.6161, validation loss: 0.0780
2024-05-22 16:21:59 [INFO]: Epoch 011 - training loss: 0.6075, validation loss: 0.0666
2024-05-22 16:22:00 [INFO]: Epoch 012 - training loss: 0.5914, validation loss: 0.0539
2024-05-22 16:22:00 [INFO]: Epoch 013 - training loss: 0.5911, validation loss: 0.0525
2024-05-22 16:22:01 [INFO]: Epoch 014 - training loss: 0.5701, validation loss: 0.0471
2024-05-22 16:22:01 [INFO]: Epoch 015 - training loss: 0.5672, validation loss: 0.0575
2024-05-22 16:22:02 [INFO]: Epoch 016 - training loss: 0.5606, validation loss: 0.0503
2024-05-22 16:22:02 [INFO]: Epoch 017 - training loss: 0.5683, validation loss: 0.0528
2024-05-22 16:22:03 [INFO]: Epoch 018 - training loss: 0.5499, validation loss: 0.0555
2024-05-22 16:22:03 [INFO]: Epoch 019 - training loss: 0.5365, validation loss: 0.0801
2024-05-22 16:22:04 [INFO]: Epoch 020 - training loss: 0.5470, validation loss: 0.0590
2024-05-22 16:22:04 [INFO]: Epoch 021 - training loss: 0.5392, validation loss: 0.0442
2024-05-22 16:22:05 [INFO]: Epoch 022 - training loss: 0.5278, validation loss: 0.0372
2024-05-22 16:22:05 [INFO]: Epoch 023 - training loss: 0.5280, validation loss: 0.1316
2024-05-22 16:22:06 [INFO]: Epoch 024 - training loss: 0.5619, validation loss: 0.0455
2024-05-22 16:22:06 [INFO]: Epoch 025 - training loss: 0.5379, validation loss: 0.0565
2024-05-22 16:22:07 [INFO]: Epoch 026 - training loss: 0.5040, validation loss: 0.0381
2024-05-22 16:22:07 [INFO]: Epoch 027 - training loss: 0.5039, validation loss: 0.0408
2024-05-22 16:22:08 [INFO]: Epoch 028 - training loss: 0.4975, validation loss: 0.0450
2024-05-22 16:22:08 [INFO]: Epoch 029 - training loss: 0.5040, validation loss: 0.0398
2024-05-22 16:22:09 [INFO]: Epoch 030 - training loss: 0.4927, validation loss: 0.0393
2024-05-22 16:22:09 [INFO]: Epoch 031 - training loss: 0.4840, validation loss: 0.0394
2024-05-22 16:22:10 [INFO]: Epoch 032 - training loss: 0.4825, validation loss: 0.0443
2024-05-22 16:22:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:22:10 [INFO]: Finished training. The best model is from epoch#22.
2024-05-22 16:22:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/SAITS_ettm1/20240522_T162145/SAITS.pypots
2024-05-22 16:22:10 [INFO]: SAITS on ETTm1: MAE=0.1676, MSE=0.0519
2024-05-22 16:22:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-22 16:22:10 [INFO]: Using the given device: cuda:0
2024-05-22 16:22:10 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/Transformer_ettm1/20240522_T162210
2024-05-22 16:22:10 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/Transformer_ettm1/20240522_T162210/tensorboard
2024-05-22 16:22:10 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 16:22:10 [INFO]: Epoch 001 - training loss: 1.1806, validation loss: 0.3260
2024-05-22 16:22:11 [INFO]: Epoch 002 - training loss: 0.7375, validation loss: 0.1596
2024-05-22 16:22:11 [INFO]: Epoch 003 - training loss: 0.5935, validation loss: 0.1180
2024-05-22 16:22:11 [INFO]: Epoch 004 - training loss: 0.5434, validation loss: 0.0906
2024-05-22 16:22:11 [INFO]: Epoch 005 - training loss: 0.4916, validation loss: 0.0861
2024-05-22 16:22:11 [INFO]: Epoch 006 - training loss: 0.4745, validation loss: 0.0665
2024-05-22 16:22:12 [INFO]: Epoch 007 - training loss: 0.4390, validation loss: 0.0610
2024-05-22 16:22:12 [INFO]: Epoch 008 - training loss: 0.4179, validation loss: 0.0569
2024-05-22 16:22:12 [INFO]: Epoch 009 - training loss: 0.4106, validation loss: 0.0573
2024-05-22 16:22:12 [INFO]: Epoch 010 - training loss: 0.4045, validation loss: 0.0506
2024-05-22 16:22:12 [INFO]: Epoch 011 - training loss: 0.3879, validation loss: 0.0597
2024-05-22 16:22:13 [INFO]: Epoch 012 - training loss: 0.3772, validation loss: 0.0491
2024-05-22 16:22:13 [INFO]: Epoch 013 - training loss: 0.3688, validation loss: 0.0538
2024-05-22 16:22:13 [INFO]: Epoch 014 - training loss: 0.3683, validation loss: 0.0488
2024-05-22 16:22:13 [INFO]: Epoch 015 - training loss: 0.3567, validation loss: 0.0523
2024-05-22 16:22:13 [INFO]: Epoch 016 - training loss: 0.3495, validation loss: 0.0424
2024-05-22 16:22:14 [INFO]: Epoch 017 - training loss: 0.3360, validation loss: 0.0392
2024-05-22 16:22:14 [INFO]: Epoch 018 - training loss: 0.3413, validation loss: 0.0442
2024-05-22 16:22:14 [INFO]: Epoch 019 - training loss: 0.3329, validation loss: 0.0392
2024-05-22 16:22:14 [INFO]: Epoch 020 - training loss: 0.3253, validation loss: 0.0407
2024-05-22 16:22:15 [INFO]: Epoch 021 - training loss: 0.3246, validation loss: 0.0380
2024-05-22 16:22:15 [INFO]: Epoch 022 - training loss: 0.3140, validation loss: 0.0405
2024-05-22 16:22:15 [INFO]: Epoch 023 - training loss: 0.3131, validation loss: 0.0326
2024-05-22 16:22:15 [INFO]: Epoch 024 - training loss: 0.3081, validation loss: 0.0321
2024-05-22 16:22:15 [INFO]: Epoch 025 - training loss: 0.3049, validation loss: 0.0327
2024-05-22 16:22:16 [INFO]: Epoch 026 - training loss: 0.3081, validation loss: 0.0322
2024-05-22 16:22:16 [INFO]: Epoch 027 - training loss: 0.3019, validation loss: 0.0378
2024-05-22 16:22:16 [INFO]: Epoch 028 - training loss: 0.3038, validation loss: 0.0303
2024-05-22 16:22:16 [INFO]: Epoch 029 - training loss: 0.2929, validation loss: 0.0358
2024-05-22 16:22:16 [INFO]: Epoch 030 - training loss: 0.2905, validation loss: 0.0317
2024-05-22 16:22:17 [INFO]: Epoch 031 - training loss: 0.2868, validation loss: 0.0300
2024-05-22 16:22:17 [INFO]: Epoch 032 - training loss: 0.2854, validation loss: 0.0316
2024-05-22 16:22:17 [INFO]: Epoch 033 - training loss: 0.2781, validation loss: 0.0278
2024-05-22 16:22:17 [INFO]: Epoch 034 - training loss: 0.2809, validation loss: 0.0350
2024-05-22 16:22:17 [INFO]: Epoch 035 - training loss: 0.2807, validation loss: 0.0275
2024-05-22 16:22:18 [INFO]: Epoch 036 - training loss: 0.2699, validation loss: 0.0290
2024-05-22 16:22:18 [INFO]: Epoch 037 - training loss: 0.2646, validation loss: 0.0268
2024-05-22 16:22:18 [INFO]: Epoch 038 - training loss: 0.2715, validation loss: 0.0260
2024-05-22 16:22:18 [INFO]: Epoch 039 - training loss: 0.2667, validation loss: 0.0277
2024-05-22 16:22:18 [INFO]: Epoch 040 - training loss: 0.2585, validation loss: 0.0268
2024-05-22 16:22:19 [INFO]: Epoch 041 - training loss: 0.2603, validation loss: 0.0261
2024-05-22 16:22:19 [INFO]: Epoch 042 - training loss: 0.2552, validation loss: 0.0264
2024-05-22 16:22:19 [INFO]: Epoch 043 - training loss: 0.2502, validation loss: 0.0255
2024-05-22 16:22:19 [INFO]: Epoch 044 - training loss: 0.2494, validation loss: 0.0256
2024-05-22 16:22:20 [INFO]: Epoch 045 - training loss: 0.2525, validation loss: 0.0254
2024-05-22 16:22:20 [INFO]: Epoch 046 - training loss: 0.2513, validation loss: 0.0261
2024-05-22 16:22:20 [INFO]: Epoch 047 - training loss: 0.2477, validation loss: 0.0244
2024-05-22 16:22:20 [INFO]: Epoch 048 - training loss: 0.2428, validation loss: 0.0229
2024-05-22 16:22:20 [INFO]: Epoch 049 - training loss: 0.2374, validation loss: 0.0220
2024-05-22 16:22:21 [INFO]: Epoch 050 - training loss: 0.2371, validation loss: 0.0255
2024-05-22 16:22:21 [INFO]: Epoch 051 - training loss: 0.2492, validation loss: 0.0322
2024-05-22 16:22:21 [INFO]: Epoch 052 - training loss: 0.2474, validation loss: 0.0253
2024-05-22 16:22:21 [INFO]: Epoch 053 - training loss: 0.2280, validation loss: 0.0206
2024-05-22 16:22:21 [INFO]: Epoch 054 - training loss: 0.2265, validation loss: 0.0225
2024-05-22 16:22:22 [INFO]: Epoch 055 - training loss: 0.2293, validation loss: 0.0218
2024-05-22 16:22:22 [INFO]: Epoch 056 - training loss: 0.2254, validation loss: 0.0229
2024-05-22 16:22:22 [INFO]: Epoch 057 - training loss: 0.2239, validation loss: 0.0267
2024-05-22 16:22:22 [INFO]: Epoch 058 - training loss: 0.2386, validation loss: 0.0288
2024-05-22 16:22:22 [INFO]: Epoch 059 - training loss: 0.2409, validation loss: 0.0292
2024-05-22 16:22:23 [INFO]: Epoch 060 - training loss: 0.2492, validation loss: 0.0300
2024-05-22 16:22:23 [INFO]: Epoch 061 - training loss: 0.2283, validation loss: 0.0235
2024-05-22 16:22:23 [INFO]: Epoch 062 - training loss: 0.2269, validation loss: 0.0205
2024-05-22 16:22:23 [INFO]: Epoch 063 - training loss: 0.2274, validation loss: 0.0248
2024-05-22 16:22:24 [INFO]: Epoch 064 - training loss: 0.2270, validation loss: 0.0230
2024-05-22 16:22:24 [INFO]: Epoch 065 - training loss: 0.2240, validation loss: 0.0229
2024-05-22 16:22:24 [INFO]: Epoch 066 - training loss: 0.2233, validation loss: 0.0205
2024-05-22 16:22:24 [INFO]: Epoch 067 - training loss: 0.2132, validation loss: 0.0204
2024-05-22 16:22:24 [INFO]: Epoch 068 - training loss: 0.2141, validation loss: 0.0187
2024-05-22 16:22:25 [INFO]: Epoch 069 - training loss: 0.2118, validation loss: 0.0205
2024-05-22 16:22:25 [INFO]: Epoch 070 - training loss: 0.2159, validation loss: 0.0201
2024-05-22 16:22:25 [INFO]: Epoch 071 - training loss: 0.2123, validation loss: 0.0217
2024-05-22 16:22:25 [INFO]: Epoch 072 - training loss: 0.2128, validation loss: 0.0206
2024-05-22 16:22:26 [INFO]: Epoch 073 - training loss: 0.2106, validation loss: 0.0223
2024-05-22 16:22:26 [INFO]: Epoch 074 - training loss: 0.2144, validation loss: 0.0227
2024-05-22 16:22:26 [INFO]: Epoch 075 - training loss: 0.2141, validation loss: 0.0224
2024-05-22 16:22:26 [INFO]: Epoch 076 - training loss: 0.2091, validation loss: 0.0223
2024-05-22 16:22:26 [INFO]: Epoch 077 - training loss: 0.2143, validation loss: 0.0233
2024-05-22 16:22:27 [INFO]: Epoch 078 - training loss: 0.2087, validation loss: 0.0208
2024-05-22 16:22:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:22:27 [INFO]: Finished training. The best model is from epoch#68.
2024-05-22 16:22:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/Transformer_ettm1/20240522_T162210/Transformer.pypots
2024-05-22 16:22:27 [INFO]: Transformer on ETTm1: MAE=0.1292, MSE=0.0326
2024-05-22 16:22:27 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-22 16:22:27 [INFO]: Using the given device: cuda:0
2024-05-22 16:22:27 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_ettm1/20240522_T162227
2024-05-22 16:22:27 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_ettm1/20240522_T162227/tensorboard
2024-05-22 16:22:27 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 16:22:33 [INFO]: Epoch 001 - training loss: 0.1632, validation loss: 0.0560
2024-05-22 16:22:34 [INFO]: Epoch 002 - training loss: 0.0720, validation loss: 0.0390
2024-05-22 16:22:34 [INFO]: Epoch 003 - training loss: 0.0570, validation loss: 0.0334
2024-05-22 16:22:34 [INFO]: Epoch 004 - training loss: 0.0491, validation loss: 0.0318
2024-05-22 16:22:34 [INFO]: Epoch 005 - training loss: 0.0477, validation loss: 0.0310
2024-05-22 16:22:34 [INFO]: Epoch 006 - training loss: 0.0456, validation loss: 0.0305
2024-05-22 16:22:35 [INFO]: Epoch 007 - training loss: 0.0479, validation loss: 0.0294
2024-05-22 16:22:35 [INFO]: Epoch 008 - training loss: 0.0477, validation loss: 0.0298
2024-05-22 16:22:35 [INFO]: Epoch 009 - training loss: 0.0434, validation loss: 0.0309
2024-05-22 16:22:35 [INFO]: Epoch 010 - training loss: 0.0446, validation loss: 0.0313
2024-05-22 16:22:35 [INFO]: Epoch 011 - training loss: 0.0474, validation loss: 0.0314
2024-05-22 16:22:36 [INFO]: Epoch 012 - training loss: 0.0509, validation loss: 0.0325
2024-05-22 16:22:36 [INFO]: Epoch 013 - training loss: 0.0474, validation loss: 0.0307
2024-05-22 16:22:36 [INFO]: Epoch 014 - training loss: 0.0459, validation loss: 0.0268
2024-05-22 16:22:36 [INFO]: Epoch 015 - training loss: 0.0438, validation loss: 0.0293
2024-05-22 16:22:36 [INFO]: Epoch 016 - training loss: 0.0453, validation loss: 0.0283
2024-05-22 16:22:37 [INFO]: Epoch 017 - training loss: 0.0463, validation loss: 0.0325
2024-05-22 16:22:37 [INFO]: Epoch 018 - training loss: 0.0499, validation loss: 0.0297
2024-05-22 16:22:37 [INFO]: Epoch 019 - training loss: 0.0442, validation loss: 0.0278
2024-05-22 16:22:37 [INFO]: Epoch 020 - training loss: 0.0414, validation loss: 0.0273
2024-05-22 16:22:37 [INFO]: Epoch 021 - training loss: 0.0398, validation loss: 0.0277
2024-05-22 16:22:38 [INFO]: Epoch 022 - training loss: 0.0402, validation loss: 0.0292
2024-05-22 16:22:38 [INFO]: Epoch 023 - training loss: 0.0443, validation loss: 0.0295
2024-05-22 16:22:38 [INFO]: Epoch 024 - training loss: 0.0436, validation loss: 0.0270
2024-05-22 16:22:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:22:38 [INFO]: Finished training. The best model is from epoch#14.
2024-05-22 16:22:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/TimesNet_ettm1/20240522_T162227/TimesNet.pypots
2024-05-22 16:22:38 [INFO]: TimesNet on ETTm1: MAE=0.1193, MSE=0.0306
2024-05-22 16:22:38 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-22 16:22:38 [INFO]: Using the given device: cuda:0
2024-05-22 16:22:38 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238
2024-05-22 16:22:38 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/tensorboard
2024-05-22 16:22:38 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 16:22:41 [INFO]: Epoch 001 - training loss: 0.7410, validation loss: 0.4928
2024-05-22 16:22:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch1_loss0.4928409084677696.pypots
2024-05-22 16:22:43 [INFO]: Epoch 002 - training loss: 0.3566, validation loss: 0.3593
2024-05-22 16:22:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch2_loss0.35931649804115295.pypots
2024-05-22 16:22:45 [INFO]: Epoch 003 - training loss: 0.3485, validation loss: 0.3355
2024-05-22 16:22:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch3_loss0.33549507707357407.pypots
2024-05-22 16:22:47 [INFO]: Epoch 004 - training loss: 0.3130, validation loss: 0.3231
2024-05-22 16:22:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch4_loss0.3230731561779976.pypots
2024-05-22 16:22:50 [INFO]: Epoch 005 - training loss: 0.2822, validation loss: 0.3026
2024-05-22 16:22:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch5_loss0.30256473273038864.pypots
2024-05-22 16:22:52 [INFO]: Epoch 006 - training loss: 0.3273, validation loss: 0.3407
2024-05-22 16:22:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch6_loss0.34074800461530685.pypots
2024-05-22 16:22:54 [INFO]: Epoch 007 - training loss: 0.2697, validation loss: 0.2983
2024-05-22 16:22:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch7_loss0.29825402796268463.pypots
2024-05-22 16:22:56 [INFO]: Epoch 008 - training loss: 0.2629, validation loss: 0.2700
2024-05-22 16:22:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch8_loss0.27004073560237885.pypots
2024-05-22 16:22:58 [INFO]: Epoch 009 - training loss: 0.3137, validation loss: 0.2932
2024-05-22 16:22:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch9_loss0.29315683245658875.pypots
2024-05-22 16:23:00 [INFO]: Epoch 010 - training loss: 0.2725, validation loss: 0.2714
2024-05-22 16:23:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch10_loss0.27142540365457535.pypots
2024-05-22 16:23:02 [INFO]: Epoch 011 - training loss: 0.2677, validation loss: 0.2663
2024-05-22 16:23:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch11_loss0.2662723660469055.pypots
2024-05-22 16:23:04 [INFO]: Epoch 012 - training loss: 0.2498, validation loss: 0.2469
2024-05-22 16:23:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch12_loss0.24687328189611435.pypots
2024-05-22 16:23:06 [INFO]: Epoch 013 - training loss: 0.2321, validation loss: 0.2283
2024-05-22 16:23:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch13_loss0.22830496355891228.pypots
2024-05-22 16:23:08 [INFO]: Epoch 014 - training loss: 0.2957, validation loss: 0.2241
2024-05-22 16:23:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch14_loss0.2241474911570549.pypots
2024-05-22 16:23:10 [INFO]: Epoch 015 - training loss: 0.2236, validation loss: 0.2178
2024-05-22 16:23:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch15_loss0.21779097989201546.pypots
2024-05-22 16:23:12 [INFO]: Epoch 016 - training loss: 0.2675, validation loss: 0.2111
2024-05-22 16:23:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch16_loss0.2111021913588047.pypots
2024-05-22 16:23:14 [INFO]: Epoch 017 - training loss: 0.2155, validation loss: 0.2092
2024-05-22 16:23:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch17_loss0.20924772322177887.pypots
2024-05-22 16:23:16 [INFO]: Epoch 018 - training loss: 0.2140, validation loss: 0.2013
2024-05-22 16:23:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch18_loss0.20131609216332436.pypots
2024-05-22 16:23:18 [INFO]: Epoch 019 - training loss: 0.2152, validation loss: 0.1987
2024-05-22 16:23:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch19_loss0.19874555245041847.pypots
2024-05-22 16:23:20 [INFO]: Epoch 020 - training loss: 0.2251, validation loss: 0.1924
2024-05-22 16:23:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch20_loss0.19237728044390678.pypots
2024-05-22 16:23:23 [INFO]: Epoch 021 - training loss: 0.2005, validation loss: 0.1862
2024-05-22 16:23:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch21_loss0.18616858497262.pypots
2024-05-22 16:23:25 [INFO]: Epoch 022 - training loss: 0.2315, validation loss: 0.1856
2024-05-22 16:23:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch22_loss0.18562442064285278.pypots
2024-05-22 16:23:27 [INFO]: Epoch 023 - training loss: 0.2043, validation loss: 0.2023
2024-05-22 16:23:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch23_loss0.20228809863328934.pypots
2024-05-22 16:23:29 [INFO]: Epoch 024 - training loss: 0.1847, validation loss: 0.1959
2024-05-22 16:23:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch24_loss0.19590802118182182.pypots
2024-05-22 16:23:31 [INFO]: Epoch 025 - training loss: 0.1936, validation loss: 0.1778
2024-05-22 16:23:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch25_loss0.17776456847786903.pypots
2024-05-22 16:23:33 [INFO]: Epoch 026 - training loss: 0.1843, validation loss: 0.1844
2024-05-22 16:23:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch26_loss0.18435343727469444.pypots
2024-05-22 16:23:35 [INFO]: Epoch 027 - training loss: 0.2415, validation loss: 0.2058
2024-05-22 16:23:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch27_loss0.2058006152510643.pypots
2024-05-22 16:23:37 [INFO]: Epoch 028 - training loss: 0.2177, validation loss: 0.1843
2024-05-22 16:23:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch28_loss0.18432063609361649.pypots
2024-05-22 16:23:39 [INFO]: Epoch 029 - training loss: 0.1947, validation loss: 0.1703
2024-05-22 16:23:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch29_loss0.1703135445713997.pypots
2024-05-22 16:23:41 [INFO]: Epoch 030 - training loss: 0.1799, validation loss: 0.1688
2024-05-22 16:23:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch30_loss0.16884026676416397.pypots
2024-05-22 16:23:43 [INFO]: Epoch 031 - training loss: 0.2051, validation loss: 0.2331
2024-05-22 16:23:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch31_loss0.23311835899949074.pypots
2024-05-22 16:23:45 [INFO]: Epoch 032 - training loss: 0.1949, validation loss: 0.1813
2024-05-22 16:23:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch32_loss0.18130895495414734.pypots
2024-05-22 16:23:47 [INFO]: Epoch 033 - training loss: 0.2448, validation loss: 0.1697
2024-05-22 16:23:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch33_loss0.16967063769698143.pypots
2024-05-22 16:23:49 [INFO]: Epoch 034 - training loss: 0.1978, validation loss: 0.1688
2024-05-22 16:23:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch34_loss0.16881991922855377.pypots
2024-05-22 16:23:51 [INFO]: Epoch 035 - training loss: 0.1962, validation loss: 0.1729
2024-05-22 16:23:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch35_loss0.17293787747621536.pypots
2024-05-22 16:23:53 [INFO]: Epoch 036 - training loss: 0.2134, validation loss: 0.1660
2024-05-22 16:23:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch36_loss0.16596536338329315.pypots
2024-05-22 16:23:56 [INFO]: Epoch 037 - training loss: 0.2030, validation loss: 0.1833
2024-05-22 16:23:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch37_loss0.18325672671198845.pypots
2024-05-22 16:23:58 [INFO]: Epoch 038 - training loss: 0.1503, validation loss: 0.1689
2024-05-22 16:23:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch38_loss0.16886359825730324.pypots
2024-05-22 16:24:00 [INFO]: Epoch 039 - training loss: 0.1829, validation loss: 0.1575
2024-05-22 16:24:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch39_loss0.1575186401605606.pypots
2024-05-22 16:24:02 [INFO]: Epoch 040 - training loss: 0.1730, validation loss: 0.1530
2024-05-22 16:24:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch40_loss0.15295211225748062.pypots
2024-05-22 16:24:04 [INFO]: Epoch 041 - training loss: 0.2253, validation loss: 0.1598
2024-05-22 16:24:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch41_loss0.1598050892353058.pypots
2024-05-22 16:24:06 [INFO]: Epoch 042 - training loss: 0.1821, validation loss: 0.1532
2024-05-22 16:24:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch42_loss0.15319016948342323.pypots
2024-05-22 16:24:08 [INFO]: Epoch 043 - training loss: 0.1770, validation loss: 0.1512
2024-05-22 16:24:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch43_loss0.15122412517666817.pypots
2024-05-22 16:24:10 [INFO]: Epoch 044 - training loss: 0.1886, validation loss: 0.1477
2024-05-22 16:24:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch44_loss0.14768321439623833.pypots
2024-05-22 16:24:12 [INFO]: Epoch 045 - training loss: 0.1694, validation loss: 0.1487
2024-05-22 16:24:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch45_loss0.1487237513065338.pypots
2024-05-22 16:24:14 [INFO]: Epoch 046 - training loss: 0.1710, validation loss: 0.1437
2024-05-22 16:24:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch46_loss0.14368831738829613.pypots
2024-05-22 16:24:16 [INFO]: Epoch 047 - training loss: 0.1678, validation loss: 0.1479
2024-05-22 16:24:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch47_loss0.147918950766325.pypots
2024-05-22 16:24:18 [INFO]: Epoch 048 - training loss: 0.1463, validation loss: 0.1488
2024-05-22 16:24:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch48_loss0.14877281710505486.pypots
2024-05-22 16:24:20 [INFO]: Epoch 049 - training loss: 0.1563, validation loss: 0.1460
2024-05-22 16:24:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch49_loss0.1460210345685482.pypots
2024-05-22 16:24:23 [INFO]: Epoch 050 - training loss: 0.1686, validation loss: 0.1406
2024-05-22 16:24:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch50_loss0.1405985690653324.pypots
2024-05-22 16:24:25 [INFO]: Epoch 051 - training loss: 0.1605, validation loss: 0.1438
2024-05-22 16:24:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch51_loss0.14375660568475723.pypots
2024-05-22 16:24:27 [INFO]: Epoch 052 - training loss: 0.1787, validation loss: 0.1466
2024-05-22 16:24:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch52_loss0.14658305421471596.pypots
2024-05-22 16:24:29 [INFO]: Epoch 053 - training loss: 0.1757, validation loss: 0.2857
2024-05-22 16:24:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch53_loss0.28574326261878014.pypots
2024-05-22 16:24:31 [INFO]: Epoch 054 - training loss: 0.2451, validation loss: 0.2455
2024-05-22 16:24:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch54_loss0.24545544758439064.pypots
2024-05-22 16:24:33 [INFO]: Epoch 055 - training loss: 0.2201, validation loss: 0.2075
2024-05-22 16:24:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch55_loss0.20748884603381157.pypots
2024-05-22 16:24:35 [INFO]: Epoch 056 - training loss: 0.2291, validation loss: 0.1864
2024-05-22 16:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch56_loss0.18638263270258904.pypots
2024-05-22 16:24:37 [INFO]: Epoch 057 - training loss: 0.1809, validation loss: 0.1709
2024-05-22 16:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch57_loss0.17089815437793732.pypots
2024-05-22 16:24:39 [INFO]: Epoch 058 - training loss: 0.1673, validation loss: 0.1651
2024-05-22 16:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch58_loss0.1651359423995018.pypots
2024-05-22 16:24:41 [INFO]: Epoch 059 - training loss: 0.1965, validation loss: 0.1674
2024-05-22 16:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch59_loss0.16743426769971848.pypots
2024-05-22 16:24:43 [INFO]: Epoch 060 - training loss: 0.2085, validation loss: 0.1588
2024-05-22 16:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI_epoch60_loss0.15876704454421997.pypots
2024-05-22 16:24:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:24:43 [INFO]: Finished training. The best model is from epoch#50.
2024-05-22 16:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/20240522_T162238/CSDI.pypots
2024-05-22 16:24:59 [INFO]: CSDI on ETTm1: MAE=0.2113, MSE=0.3120
2024-05-22 16:24:59 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-22 16:24:59 [INFO]: Using the given device: cuda:0
2024-05-22 16:24:59 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_ettm1/20240522_T162459
2024-05-22 16:24:59 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_ettm1/20240522_T162459/tensorboard
2024-05-22 16:24:59 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 16:25:01 [INFO]: Epoch 001 - training loss: 23852.1212, validation loss: 0.9566
2024-05-22 16:25:01 [INFO]: Epoch 002 - training loss: 21775.7399, validation loss: 0.9571
2024-05-22 16:25:01 [INFO]: Epoch 003 - training loss: 19618.1423, validation loss: 0.9489
2024-05-22 16:25:01 [INFO]: Epoch 004 - training loss: 17583.0386, validation loss: 0.9331
2024-05-22 16:25:01 [INFO]: Epoch 005 - training loss: 15474.9775, validation loss: 0.8948
2024-05-22 16:25:01 [INFO]: Epoch 006 - training loss: 13909.6788, validation loss: 0.8209
2024-05-22 16:25:01 [INFO]: Epoch 007 - training loss: 12887.9719, validation loss: 0.7352
2024-05-22 16:25:02 [INFO]: Epoch 008 - training loss: 11928.9999, validation loss: 0.6459
2024-05-22 16:25:02 [INFO]: Epoch 009 - training loss: 11296.7264, validation loss: 0.5806
2024-05-22 16:25:02 [INFO]: Epoch 010 - training loss: 10962.9103, validation loss: 0.5436
2024-05-22 16:25:02 [INFO]: Epoch 011 - training loss: 10583.9213, validation loss: 0.5264
2024-05-22 16:25:02 [INFO]: Epoch 012 - training loss: 10422.6508, validation loss: 0.5057
2024-05-22 16:25:02 [INFO]: Epoch 013 - training loss: 10215.4812, validation loss: 0.4937
2024-05-22 16:25:02 [INFO]: Epoch 014 - training loss: 10097.8284, validation loss: 0.4833
2024-05-22 16:25:02 [INFO]: Epoch 015 - training loss: 9974.3077, validation loss: 0.4583
2024-05-22 16:25:02 [INFO]: Epoch 016 - training loss: 9900.7244, validation loss: 0.4430
2024-05-22 16:25:03 [INFO]: Epoch 017 - training loss: 9851.4273, validation loss: 0.4251
2024-05-22 16:25:03 [INFO]: Epoch 018 - training loss: 9870.5089, validation loss: 0.4028
2024-05-22 16:25:03 [INFO]: Epoch 019 - training loss: 9723.4734, validation loss: 0.3829
2024-05-22 16:25:03 [INFO]: Epoch 020 - training loss: 9697.5732, validation loss: 0.3523
2024-05-22 16:25:03 [INFO]: Epoch 021 - training loss: 9632.6409, validation loss: 0.3278
2024-05-22 16:25:03 [INFO]: Epoch 022 - training loss: 9603.9720, validation loss: 0.3090
2024-05-22 16:25:03 [INFO]: Epoch 023 - training loss: 9618.4467, validation loss: 0.2961
2024-05-22 16:25:03 [INFO]: Epoch 024 - training loss: 9560.7799, validation loss: 0.2823
2024-05-22 16:25:03 [INFO]: Epoch 025 - training loss: 9537.1572, validation loss: 0.2638
2024-05-22 16:25:04 [INFO]: Epoch 026 - training loss: 9512.5359, validation loss: 0.2510
2024-05-22 16:25:04 [INFO]: Epoch 027 - training loss: 9521.1998, validation loss: 0.2413
2024-05-22 16:25:04 [INFO]: Epoch 028 - training loss: 9477.2968, validation loss: 0.2341
2024-05-22 16:25:04 [INFO]: Epoch 029 - training loss: 9485.2626, validation loss: 0.2291
2024-05-22 16:25:04 [INFO]: Epoch 030 - training loss: 9453.8397, validation loss: 0.2176
2024-05-22 16:25:04 [INFO]: Epoch 031 - training loss: 9452.5214, validation loss: 0.2114
2024-05-22 16:25:04 [INFO]: Epoch 032 - training loss: 9433.5562, validation loss: 0.2082
2024-05-22 16:25:04 [INFO]: Epoch 033 - training loss: 9431.4490, validation loss: 0.2049
2024-05-22 16:25:04 [INFO]: Epoch 034 - training loss: 9417.4526, validation loss: 0.2004
2024-05-22 16:25:04 [INFO]: Epoch 035 - training loss: 9410.9401, validation loss: 0.1946
2024-05-22 16:25:05 [INFO]: Epoch 036 - training loss: 9401.5659, validation loss: 0.1885
2024-05-22 16:25:05 [INFO]: Epoch 037 - training loss: 9396.0024, validation loss: 0.1857
2024-05-22 16:25:05 [INFO]: Epoch 038 - training loss: 9389.8495, validation loss: 0.1830
2024-05-22 16:25:05 [INFO]: Epoch 039 - training loss: 9384.8588, validation loss: 0.1775
2024-05-22 16:25:05 [INFO]: Epoch 040 - training loss: 9378.8278, validation loss: 0.1727
2024-05-22 16:25:05 [INFO]: Epoch 041 - training loss: 9377.0312, validation loss: 0.1711
2024-05-22 16:25:05 [INFO]: Epoch 042 - training loss: 9371.8159, validation loss: 0.1685
2024-05-22 16:25:05 [INFO]: Epoch 043 - training loss: 9368.0097, validation loss: 0.1687
2024-05-22 16:25:05 [INFO]: Epoch 044 - training loss: 9362.3470, validation loss: 0.1587
2024-05-22 16:25:06 [INFO]: Epoch 045 - training loss: 9359.9709, validation loss: 0.1570
2024-05-22 16:25:06 [INFO]: Epoch 046 - training loss: 9356.2221, validation loss: 0.1510
2024-05-22 16:25:06 [INFO]: Epoch 047 - training loss: 9354.1407, validation loss: 0.1515
2024-05-22 16:25:06 [INFO]: Epoch 048 - training loss: 9347.4786, validation loss: 0.1480
2024-05-22 16:25:06 [INFO]: Epoch 049 - training loss: 9349.0330, validation loss: 0.1460
2024-05-22 16:25:06 [INFO]: Epoch 050 - training loss: 9346.3743, validation loss: 0.1445
2024-05-22 16:25:06 [INFO]: Epoch 051 - training loss: 9341.2061, validation loss: 0.1415
2024-05-22 16:25:06 [INFO]: Epoch 052 - training loss: 9336.0168, validation loss: 0.1404
2024-05-22 16:25:06 [INFO]: Epoch 053 - training loss: 9337.3879, validation loss: 0.1365
2024-05-22 16:25:07 [INFO]: Epoch 054 - training loss: 9333.5013, validation loss: 0.1377
2024-05-22 16:25:07 [INFO]: Epoch 055 - training loss: 9332.0172, validation loss: 0.1347
2024-05-22 16:25:07 [INFO]: Epoch 056 - training loss: 9327.8151, validation loss: 0.1332
2024-05-22 16:25:07 [INFO]: Epoch 057 - training loss: 9328.9406, validation loss: 0.1312
2024-05-22 16:25:07 [INFO]: Epoch 058 - training loss: 9331.3410, validation loss: 0.1309
2024-05-22 16:25:07 [INFO]: Epoch 059 - training loss: 9325.4701, validation loss: 0.1268
2024-05-22 16:25:07 [INFO]: Epoch 060 - training loss: 9324.0435, validation loss: 0.1258
2024-05-22 16:25:07 [INFO]: Epoch 061 - training loss: 9323.9547, validation loss: 0.1256
2024-05-22 16:25:07 [INFO]: Epoch 062 - training loss: 9319.8807, validation loss: 0.1239
2024-05-22 16:25:08 [INFO]: Epoch 063 - training loss: 9318.4581, validation loss: 0.1226
2024-05-22 16:25:08 [INFO]: Epoch 064 - training loss: 9320.6260, validation loss: 0.1220
2024-05-22 16:25:08 [INFO]: Epoch 065 - training loss: 9316.0195, validation loss: 0.1213
2024-05-22 16:25:08 [INFO]: Epoch 066 - training loss: 9317.9187, validation loss: 0.1196
2024-05-22 16:25:08 [INFO]: Epoch 067 - training loss: 9312.8778, validation loss: 0.1191
2024-05-22 16:25:08 [INFO]: Epoch 068 - training loss: 9312.8660, validation loss: 0.1182
2024-05-22 16:25:08 [INFO]: Epoch 069 - training loss: 9312.8695, validation loss: 0.1173
2024-05-22 16:25:08 [INFO]: Epoch 070 - training loss: 9309.4867, validation loss: 0.1175
2024-05-22 16:25:08 [INFO]: Epoch 071 - training loss: 9312.7844, validation loss: 0.1152
2024-05-22 16:25:09 [INFO]: Epoch 072 - training loss: 9310.3504, validation loss: 0.1153
2024-05-22 16:25:09 [INFO]: Epoch 073 - training loss: 9309.9349, validation loss: 0.1135
2024-05-22 16:25:09 [INFO]: Epoch 074 - training loss: 9305.0256, validation loss: 0.1134
2024-05-22 16:25:09 [INFO]: Epoch 075 - training loss: 9306.4179, validation loss: 0.1122
2024-05-22 16:25:09 [INFO]: Epoch 076 - training loss: 9305.3748, validation loss: 0.1123
2024-05-22 16:25:09 [INFO]: Epoch 077 - training loss: 9304.1256, validation loss: 0.1110
2024-05-22 16:25:09 [INFO]: Epoch 078 - training loss: 9301.9992, validation loss: 0.1105
2024-05-22 16:25:09 [INFO]: Epoch 079 - training loss: 9307.1612, validation loss: 0.1094
2024-05-22 16:25:09 [INFO]: Epoch 080 - training loss: 9300.9836, validation loss: 0.1095
2024-05-22 16:25:09 [INFO]: Epoch 081 - training loss: 9302.3069, validation loss: 0.1079
2024-05-22 16:25:10 [INFO]: Epoch 082 - training loss: 9299.5587, validation loss: 0.1076
2024-05-22 16:25:10 [INFO]: Epoch 083 - training loss: 9300.0876, validation loss: 0.1068
2024-05-22 16:25:10 [INFO]: Epoch 084 - training loss: 9299.0091, validation loss: 0.1070
2024-05-22 16:25:10 [INFO]: Epoch 085 - training loss: 9300.2191, validation loss: 0.1073
2024-05-22 16:25:10 [INFO]: Epoch 086 - training loss: 9298.3697, validation loss: 0.1064
2024-05-22 16:25:10 [INFO]: Epoch 087 - training loss: 9300.6915, validation loss: 0.1040
2024-05-22 16:25:10 [INFO]: Epoch 088 - training loss: 9299.0031, validation loss: 0.1056
2024-05-22 16:25:10 [INFO]: Epoch 089 - training loss: 9298.6624, validation loss: 0.1035
2024-05-22 16:25:10 [INFO]: Epoch 090 - training loss: 9294.6215, validation loss: 0.1038
2024-05-22 16:25:11 [INFO]: Epoch 091 - training loss: 9293.6650, validation loss: 0.1043
2024-05-22 16:25:11 [INFO]: Epoch 092 - training loss: 9293.5112, validation loss: 0.1034
2024-05-22 16:25:11 [INFO]: Epoch 093 - training loss: 9295.6512, validation loss: 0.1027
2024-05-22 16:25:11 [INFO]: Epoch 094 - training loss: 9293.2284, validation loss: 0.1007
2024-05-22 16:25:11 [INFO]: Epoch 095 - training loss: 9294.5135, validation loss: 0.1011
2024-05-22 16:25:11 [INFO]: Epoch 096 - training loss: 9292.4332, validation loss: 0.1016
2024-05-22 16:25:11 [INFO]: Epoch 097 - training loss: 9293.2180, validation loss: 0.0997
2024-05-22 16:25:11 [INFO]: Epoch 098 - training loss: 9292.5037, validation loss: 0.0998
2024-05-22 16:25:11 [INFO]: Epoch 099 - training loss: 9291.7223, validation loss: 0.0992
2024-05-22 16:25:12 [INFO]: Epoch 100 - training loss: 9291.2690, validation loss: 0.0986
2024-05-22 16:25:12 [INFO]: Epoch 101 - training loss: 9289.4497, validation loss: 0.0984
2024-05-22 16:25:12 [INFO]: Epoch 102 - training loss: 9288.4400, validation loss: 0.0983
2024-05-22 16:25:12 [INFO]: Epoch 103 - training loss: 9288.3657, validation loss: 0.0981
2024-05-22 16:25:12 [INFO]: Epoch 104 - training loss: 9289.0649, validation loss: 0.0981
2024-05-22 16:25:12 [INFO]: Epoch 105 - training loss: 9288.5618, validation loss: 0.0980
2024-05-22 16:25:12 [INFO]: Epoch 106 - training loss: 9288.2247, validation loss: 0.0965
2024-05-22 16:25:12 [INFO]: Epoch 107 - training loss: 9288.0425, validation loss: 0.0981
2024-05-22 16:25:12 [INFO]: Epoch 108 - training loss: 9287.6729, validation loss: 0.0967
2024-05-22 16:25:13 [INFO]: Epoch 109 - training loss: 9289.2612, validation loss: 0.0950
2024-05-22 16:25:13 [INFO]: Epoch 110 - training loss: 9287.8290, validation loss: 0.0955
2024-05-22 16:25:13 [INFO]: Epoch 111 - training loss: 9285.8539, validation loss: 0.0932
2024-05-22 16:25:13 [INFO]: Epoch 112 - training loss: 9287.0275, validation loss: 0.0946
2024-05-22 16:25:13 [INFO]: Epoch 113 - training loss: 9286.3804, validation loss: 0.0943
2024-05-22 16:25:13 [INFO]: Epoch 114 - training loss: 9286.1848, validation loss: 0.0952
2024-05-22 16:25:13 [INFO]: Epoch 115 - training loss: 9284.5455, validation loss: 0.0935
2024-05-22 16:25:13 [INFO]: Epoch 116 - training loss: 9285.0630, validation loss: 0.0932
2024-05-22 16:25:13 [INFO]: Epoch 117 - training loss: 9286.8657, validation loss: 0.0929
2024-05-22 16:25:13 [INFO]: Epoch 118 - training loss: 9287.2503, validation loss: 0.0922
2024-05-22 16:25:14 [INFO]: Epoch 119 - training loss: 9284.1255, validation loss: 0.0930
2024-05-22 16:25:14 [INFO]: Epoch 120 - training loss: 9284.6879, validation loss: 0.0913
2024-05-22 16:25:14 [INFO]: Epoch 121 - training loss: 9285.2727, validation loss: 0.0902
2024-05-22 16:25:14 [INFO]: Epoch 122 - training loss: 9283.7380, validation loss: 0.0899
2024-05-22 16:25:14 [INFO]: Epoch 123 - training loss: 9283.6440, validation loss: 0.0910
2024-05-22 16:25:14 [INFO]: Epoch 124 - training loss: 9282.6155, validation loss: 0.0896
2024-05-22 16:25:14 [INFO]: Epoch 125 - training loss: 9282.1768, validation loss: 0.0900
2024-05-22 16:25:14 [INFO]: Epoch 126 - training loss: 9283.8093, validation loss: 0.0895
2024-05-22 16:25:14 [INFO]: Epoch 127 - training loss: 9282.3906, validation loss: 0.0918
2024-05-22 16:25:15 [INFO]: Epoch 128 - training loss: 9282.0281, validation loss: 0.0878
2024-05-22 16:25:15 [INFO]: Epoch 129 - training loss: 9282.2720, validation loss: 0.0904
2024-05-22 16:25:15 [INFO]: Epoch 130 - training loss: 9282.4033, validation loss: 0.0888
2024-05-22 16:25:15 [INFO]: Epoch 131 - training loss: 9282.0438, validation loss: 0.0879
2024-05-22 16:25:15 [INFO]: Epoch 132 - training loss: 9280.3334, validation loss: 0.0882
2024-05-22 16:25:15 [INFO]: Epoch 133 - training loss: 9282.7549, validation loss: 0.0871
2024-05-22 16:25:15 [INFO]: Epoch 134 - training loss: 9281.0097, validation loss: 0.0870
2024-05-22 16:25:15 [INFO]: Epoch 135 - training loss: 9280.4244, validation loss: 0.0874
2024-05-22 16:25:15 [INFO]: Epoch 136 - training loss: 9279.3077, validation loss: 0.0860
2024-05-22 16:25:16 [INFO]: Epoch 137 - training loss: 9281.0767, validation loss: 0.0846
2024-05-22 16:25:16 [INFO]: Epoch 138 - training loss: 9281.0223, validation loss: 0.0867
2024-05-22 16:25:16 [INFO]: Epoch 139 - training loss: 9279.5134, validation loss: 0.0863
2024-05-22 16:25:16 [INFO]: Epoch 140 - training loss: 9280.7198, validation loss: 0.0859
2024-05-22 16:25:16 [INFO]: Epoch 141 - training loss: 9279.4286, validation loss: 0.0848
2024-05-22 16:25:16 [INFO]: Epoch 142 - training loss: 9278.1235, validation loss: 0.0854
2024-05-22 16:25:16 [INFO]: Epoch 143 - training loss: 9277.7073, validation loss: 0.0851
2024-05-22 16:25:16 [INFO]: Epoch 144 - training loss: 9278.6990, validation loss: 0.0846
2024-05-22 16:25:16 [INFO]: Epoch 145 - training loss: 9277.7531, validation loss: 0.0853
2024-05-22 16:25:17 [INFO]: Epoch 146 - training loss: 9279.3614, validation loss: 0.0844
2024-05-22 16:25:17 [INFO]: Epoch 147 - training loss: 9279.8054, validation loss: 0.0853
2024-05-22 16:25:17 [INFO]: Epoch 148 - training loss: 9277.1322, validation loss: 0.0838
2024-05-22 16:25:17 [INFO]: Epoch 149 - training loss: 9278.2723, validation loss: 0.0823
2024-05-22 16:25:17 [INFO]: Epoch 150 - training loss: 9278.4471, validation loss: 0.0835
2024-05-22 16:25:17 [INFO]: Epoch 151 - training loss: 9279.3492, validation loss: 0.0836
2024-05-22 16:25:17 [INFO]: Epoch 152 - training loss: 9279.1862, validation loss: 0.0827
2024-05-22 16:25:17 [INFO]: Epoch 153 - training loss: 9278.7482, validation loss: 0.0826
2024-05-22 16:25:17 [INFO]: Epoch 154 - training loss: 9278.0927, validation loss: 0.0820
2024-05-22 16:25:17 [INFO]: Epoch 155 - training loss: 9276.8849, validation loss: 0.0831
2024-05-22 16:25:18 [INFO]: Epoch 156 - training loss: 9276.6427, validation loss: 0.0829
2024-05-22 16:25:18 [INFO]: Epoch 157 - training loss: 9277.2191, validation loss: 0.0820
2024-05-22 16:25:18 [INFO]: Epoch 158 - training loss: 9278.1424, validation loss: 0.0815
2024-05-22 16:25:18 [INFO]: Epoch 159 - training loss: 9276.5128, validation loss: 0.0816
2024-05-22 16:25:18 [INFO]: Epoch 160 - training loss: 9276.7594, validation loss: 0.0835
2024-05-22 16:25:18 [INFO]: Epoch 161 - training loss: 9276.0385, validation loss: 0.0817
2024-05-22 16:25:18 [INFO]: Epoch 162 - training loss: 9275.5347, validation loss: 0.0826
2024-05-22 16:25:18 [INFO]: Epoch 163 - training loss: 9275.7017, validation loss: 0.0820
2024-05-22 16:25:18 [INFO]: Epoch 164 - training loss: 9276.3425, validation loss: 0.0799
2024-05-22 16:25:19 [INFO]: Epoch 165 - training loss: 9275.3170, validation loss: 0.0810
2024-05-22 16:25:19 [INFO]: Epoch 166 - training loss: 9275.9221, validation loss: 0.0814
2024-05-22 16:25:19 [INFO]: Epoch 167 - training loss: 9274.5176, validation loss: 0.0801
2024-05-22 16:25:19 [INFO]: Epoch 168 - training loss: 9276.2328, validation loss: 0.0784
2024-05-22 16:25:19 [INFO]: Epoch 169 - training loss: 9274.8096, validation loss: 0.0787
2024-05-22 16:25:19 [INFO]: Epoch 170 - training loss: 9276.4635, validation loss: 0.0787
2024-05-22 16:25:19 [INFO]: Epoch 171 - training loss: 9277.7350, validation loss: 0.0806
2024-05-22 16:25:19 [INFO]: Epoch 172 - training loss: 9275.3472, validation loss: 0.0786
2024-05-22 16:25:19 [INFO]: Epoch 173 - training loss: 9274.8069, validation loss: 0.0786
2024-05-22 16:25:20 [INFO]: Epoch 174 - training loss: 9274.0740, validation loss: 0.0787
2024-05-22 16:25:20 [INFO]: Epoch 175 - training loss: 9276.9996, validation loss: 0.0808
2024-05-22 16:25:20 [INFO]: Epoch 176 - training loss: 9274.8044, validation loss: 0.0791
2024-05-22 16:25:20 [INFO]: Epoch 177 - training loss: 9274.5383, validation loss: 0.0794
2024-05-22 16:25:20 [INFO]: Epoch 178 - training loss: 9273.3782, validation loss: 0.0797
2024-05-22 16:25:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:25:20 [INFO]: Finished training. The best model is from epoch#168.
2024-05-22 16:25:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/GPVAE_ettm1/20240522_T162459/GPVAE.pypots
2024-05-22 16:25:20 [INFO]: GP-VAE on ETTm1: MAE=0.2999, MSE=0.1831
2024-05-22 16:25:20 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-22 16:25:20 [INFO]: Using the given device: cuda:0
2024-05-22 16:25:20 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/USGAN_ettm1/20240522_T162520
2024-05-22 16:25:20 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/USGAN_ettm1/20240522_T162520/tensorboard
2024-05-22 16:25:20 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 16:25:29 [INFO]: Epoch 001 - generator training loss: 0.5366, discriminator training loss: 0.4152, validation loss: 0.3633
2024-05-22 16:25:37 [INFO]: Epoch 002 - generator training loss: 0.0446, discriminator training loss: 0.3254, validation loss: 0.1270
2024-05-22 16:25:44 [INFO]: Epoch 003 - generator training loss: -0.1154, discriminator training loss: 0.3130, validation loss: 0.0621
2024-05-22 16:25:52 [INFO]: Epoch 004 - generator training loss: -0.1366, discriminator training loss: 0.2974, validation loss: 0.0490
2024-05-22 16:25:59 [INFO]: Epoch 005 - generator training loss: -0.1270, discriminator training loss: 0.2758, validation loss: 0.0406
2024-05-22 16:26:06 [INFO]: Epoch 006 - generator training loss: -0.1075, discriminator training loss: 0.2472, validation loss: 0.0385
2024-05-22 16:26:13 [INFO]: Epoch 007 - generator training loss: -0.0827, discriminator training loss: 0.2131, validation loss: 0.0353
2024-05-22 16:26:21 [INFO]: Epoch 008 - generator training loss: -0.0622, discriminator training loss: 0.1822, validation loss: 0.0339
2024-05-22 16:26:28 [INFO]: Epoch 009 - generator training loss: -0.0497, discriminator training loss: 0.1596, validation loss: 0.0332
2024-05-22 16:26:35 [INFO]: Epoch 010 - generator training loss: -0.0426, discriminator training loss: 0.1421, validation loss: 0.0321
2024-05-22 16:26:42 [INFO]: Epoch 011 - generator training loss: -0.0340, discriminator training loss: 0.1347, validation loss: 0.0321
2024-05-22 16:26:50 [INFO]: Epoch 012 - generator training loss: -0.0343, discriminator training loss: 0.1282, validation loss: 0.0311
2024-05-22 16:26:57 [INFO]: Epoch 013 - generator training loss: -0.0357, discriminator training loss: 0.1255, validation loss: 0.0306
2024-05-22 16:27:04 [INFO]: Epoch 014 - generator training loss: -0.0339, discriminator training loss: 0.1225, validation loss: 0.0304
2024-05-22 16:27:11 [INFO]: Epoch 015 - generator training loss: -0.0343, discriminator training loss: 0.1227, validation loss: 0.0294
2024-05-22 16:27:19 [INFO]: Epoch 016 - generator training loss: -0.0365, discriminator training loss: 0.1209, validation loss: 0.0296
2024-05-22 16:27:26 [INFO]: Epoch 017 - generator training loss: -0.0354, discriminator training loss: 0.1189, validation loss: 0.0287
2024-05-22 16:27:33 [INFO]: Epoch 018 - generator training loss: -0.0370, discriminator training loss: 0.1181, validation loss: 0.0287
2024-05-22 16:27:40 [INFO]: Epoch 019 - generator training loss: -0.0326, discriminator training loss: 0.1193, validation loss: 0.0293
2024-05-22 16:27:48 [INFO]: Epoch 020 - generator training loss: -0.0338, discriminator training loss: 0.1172, validation loss: 0.0284
2024-05-22 16:27:55 [INFO]: Epoch 021 - generator training loss: -0.0355, discriminator training loss: 0.1165, validation loss: 0.0279
2024-05-22 16:28:02 [INFO]: Epoch 022 - generator training loss: -0.0350, discriminator training loss: 0.1143, validation loss: 0.0287
2024-05-22 16:28:10 [INFO]: Epoch 023 - generator training loss: -0.0329, discriminator training loss: 0.1159, validation loss: 0.0277
2024-05-22 16:28:17 [INFO]: Epoch 024 - generator training loss: -0.0368, discriminator training loss: 0.1157, validation loss: 0.0272
2024-05-22 16:28:24 [INFO]: Epoch 025 - generator training loss: -0.0364, discriminator training loss: 0.1166, validation loss: 0.0269
2024-05-22 16:28:32 [INFO]: Epoch 026 - generator training loss: -0.0376, discriminator training loss: 0.1134, validation loss: 0.0265
2024-05-22 16:28:39 [INFO]: Epoch 027 - generator training loss: -0.0360, discriminator training loss: 0.1118, validation loss: 0.0260
2024-05-22 16:28:46 [INFO]: Epoch 028 - generator training loss: -0.0364, discriminator training loss: 0.1151, validation loss: 0.0266
2024-05-22 16:28:54 [INFO]: Epoch 029 - generator training loss: -0.0344, discriminator training loss: 0.1134, validation loss: 0.0265
2024-05-22 16:29:01 [INFO]: Epoch 030 - generator training loss: -0.0374, discriminator training loss: 0.1114, validation loss: 0.0263
2024-05-22 16:29:08 [INFO]: Epoch 031 - generator training loss: -0.0385, discriminator training loss: 0.1117, validation loss: 0.0257
2024-05-22 16:29:15 [INFO]: Epoch 032 - generator training loss: -0.0387, discriminator training loss: 0.1116, validation loss: 0.0265
2024-05-22 16:29:23 [INFO]: Epoch 033 - generator training loss: -0.0369, discriminator training loss: 0.1123, validation loss: 0.0251
2024-05-22 16:29:30 [INFO]: Epoch 034 - generator training loss: -0.0387, discriminator training loss: 0.1132, validation loss: 0.0255
2024-05-22 16:29:38 [INFO]: Epoch 035 - generator training loss: -0.0382, discriminator training loss: 0.1105, validation loss: 0.0249
2024-05-22 16:29:45 [INFO]: Epoch 036 - generator training loss: -0.0381, discriminator training loss: 0.1102, validation loss: 0.0248
2024-05-22 16:29:52 [INFO]: Epoch 037 - generator training loss: -0.0394, discriminator training loss: 0.1137, validation loss: 0.0246
2024-05-22 16:30:00 [INFO]: Epoch 038 - generator training loss: -0.0386, discriminator training loss: 0.1108, validation loss: 0.0244
2024-05-22 16:30:07 [INFO]: Epoch 039 - generator training loss: -0.0417, discriminator training loss: 0.1117, validation loss: 0.0243
2024-05-22 16:30:15 [INFO]: Epoch 040 - generator training loss: -0.0380, discriminator training loss: 0.1118, validation loss: 0.0241
2024-05-22 16:30:22 [INFO]: Epoch 041 - generator training loss: -0.0396, discriminator training loss: 0.1121, validation loss: 0.0241
2024-05-22 16:30:29 [INFO]: Epoch 042 - generator training loss: -0.0406, discriminator training loss: 0.1133, validation loss: 0.0244
2024-05-22 16:30:37 [INFO]: Epoch 043 - generator training loss: -0.0381, discriminator training loss: 0.1128, validation loss: 0.0240
2024-05-22 16:30:44 [INFO]: Epoch 044 - generator training loss: -0.0409, discriminator training loss: 0.1118, validation loss: 0.0244
2024-05-22 16:30:51 [INFO]: Epoch 045 - generator training loss: -0.0403, discriminator training loss: 0.1119, validation loss: 0.0237
2024-05-22 16:30:59 [INFO]: Epoch 046 - generator training loss: -0.0418, discriminator training loss: 0.1105, validation loss: 0.0247
2024-05-22 16:31:06 [INFO]: Epoch 047 - generator training loss: -0.0441, discriminator training loss: 0.1114, validation loss: 0.0232
2024-05-22 16:31:13 [INFO]: Epoch 048 - generator training loss: -0.0399, discriminator training loss: 0.1093, validation loss: 0.0237
2024-05-22 16:31:20 [INFO]: Epoch 049 - generator training loss: -0.0420, discriminator training loss: 0.1113, validation loss: 0.0237
2024-05-22 16:31:28 [INFO]: Epoch 050 - generator training loss: -0.0412, discriminator training loss: 0.1125, validation loss: 0.0230
2024-05-22 16:31:35 [INFO]: Epoch 051 - generator training loss: -0.0428, discriminator training loss: 0.1093, validation loss: 0.0239
2024-05-22 16:31:42 [INFO]: Epoch 052 - generator training loss: -0.0431, discriminator training loss: 0.1115, validation loss: 0.0232
2024-05-22 16:31:49 [INFO]: Epoch 053 - generator training loss: -0.0422, discriminator training loss: 0.1101, validation loss: 0.0230
2024-05-22 16:31:57 [INFO]: Epoch 054 - generator training loss: -0.0411, discriminator training loss: 0.1091, validation loss: 0.0228
2024-05-22 16:32:04 [INFO]: Epoch 055 - generator training loss: -0.0418, discriminator training loss: 0.1077, validation loss: 0.0226
2024-05-22 16:32:11 [INFO]: Epoch 056 - generator training loss: -0.0428, discriminator training loss: 0.1080, validation loss: 0.0229
2024-05-22 16:32:18 [INFO]: Epoch 057 - generator training loss: -0.0415, discriminator training loss: 0.1085, validation loss: 0.0222
2024-05-22 16:32:26 [INFO]: Epoch 058 - generator training loss: -0.0439, discriminator training loss: 0.1080, validation loss: 0.0228
2024-05-22 16:32:33 [INFO]: Epoch 059 - generator training loss: -0.0433, discriminator training loss: 0.1098, validation loss: 0.0227
2024-05-22 16:32:40 [INFO]: Epoch 060 - generator training loss: -0.0386, discriminator training loss: 0.1081, validation loss: 0.0229
2024-05-22 16:32:47 [INFO]: Epoch 061 - generator training loss: -0.0455, discriminator training loss: 0.1087, validation loss: 0.0218
2024-05-22 16:32:55 [INFO]: Epoch 062 - generator training loss: -0.0452, discriminator training loss: 0.1091, validation loss: 0.0217
2024-05-22 16:33:02 [INFO]: Epoch 063 - generator training loss: -0.0423, discriminator training loss: 0.1082, validation loss: 0.0220
2024-05-22 16:33:09 [INFO]: Epoch 064 - generator training loss: -0.0426, discriminator training loss: 0.1095, validation loss: 0.0225
2024-05-22 16:33:17 [INFO]: Epoch 065 - generator training loss: -0.0413, discriminator training loss: 0.1109, validation loss: 0.0212
2024-05-22 16:33:24 [INFO]: Epoch 066 - generator training loss: -0.0411, discriminator training loss: 0.1091, validation loss: 0.0218
2024-05-22 16:33:31 [INFO]: Epoch 067 - generator training loss: -0.0414, discriminator training loss: 0.1069, validation loss: 0.0212
2024-05-22 16:33:39 [INFO]: Epoch 068 - generator training loss: -0.0435, discriminator training loss: 0.1079, validation loss: 0.0213
2024-05-22 16:33:46 [INFO]: Epoch 069 - generator training loss: -0.0441, discriminator training loss: 0.1083, validation loss: 0.0210
2024-05-22 16:33:53 [INFO]: Epoch 070 - generator training loss: -0.0429, discriminator training loss: 0.1090, validation loss: 0.0211
2024-05-22 16:34:00 [INFO]: Epoch 071 - generator training loss: -0.0453, discriminator training loss: 0.1067, validation loss: 0.0211
2024-05-22 16:34:07 [INFO]: Epoch 072 - generator training loss: -0.0436, discriminator training loss: 0.1078, validation loss: 0.0212
2024-05-22 16:34:15 [INFO]: Epoch 073 - generator training loss: -0.0472, discriminator training loss: 0.1119, validation loss: 0.0209
2024-05-22 16:34:22 [INFO]: Epoch 074 - generator training loss: -0.0455, discriminator training loss: 0.1076, validation loss: 0.0211
2024-05-22 16:34:29 [INFO]: Epoch 075 - generator training loss: -0.0427, discriminator training loss: 0.1082, validation loss: 0.0212
2024-05-22 16:34:37 [INFO]: Epoch 076 - generator training loss: -0.0471, discriminator training loss: 0.1088, validation loss: 0.0204
2024-05-22 16:34:44 [INFO]: Epoch 077 - generator training loss: -0.0453, discriminator training loss: 0.1083, validation loss: 0.0202
2024-05-22 16:34:51 [INFO]: Epoch 078 - generator training loss: -0.0461, discriminator training loss: 0.1079, validation loss: 0.0203
2024-05-22 16:34:58 [INFO]: Epoch 079 - generator training loss: -0.0439, discriminator training loss: 0.1086, validation loss: 0.0204
2024-05-22 16:35:06 [INFO]: Epoch 080 - generator training loss: -0.0423, discriminator training loss: 0.1089, validation loss: 0.0204
2024-05-22 16:35:13 [INFO]: Epoch 081 - generator training loss: -0.0473, discriminator training loss: 0.1102, validation loss: 0.0200
2024-05-22 16:35:20 [INFO]: Epoch 082 - generator training loss: -0.0442, discriminator training loss: 0.1072, validation loss: 0.0203
2024-05-22 16:35:28 [INFO]: Epoch 083 - generator training loss: -0.0452, discriminator training loss: 0.1079, validation loss: 0.0200
2024-05-22 16:35:35 [INFO]: Epoch 084 - generator training loss: -0.0476, discriminator training loss: 0.1076, validation loss: 0.0202
2024-05-22 16:35:42 [INFO]: Epoch 085 - generator training loss: -0.0483, discriminator training loss: 0.1083, validation loss: 0.0196
2024-05-22 16:35:50 [INFO]: Epoch 086 - generator training loss: -0.0469, discriminator training loss: 0.1064, validation loss: 0.0195
2024-05-22 16:35:57 [INFO]: Epoch 087 - generator training loss: -0.0482, discriminator training loss: 0.1062, validation loss: 0.0194
2024-05-22 16:36:04 [INFO]: Epoch 088 - generator training loss: -0.0499, discriminator training loss: 0.1051, validation loss: 0.0193
2024-05-22 16:36:11 [INFO]: Epoch 089 - generator training loss: -0.0500, discriminator training loss: 0.1072, validation loss: 0.0189
2024-05-22 16:36:19 [INFO]: Epoch 090 - generator training loss: -0.0463, discriminator training loss: 0.1064, validation loss: 0.0188
2024-05-22 16:36:26 [INFO]: Epoch 091 - generator training loss: -0.0462, discriminator training loss: 0.1057, validation loss: 0.0191
2024-05-22 16:36:33 [INFO]: Epoch 092 - generator training loss: -0.0494, discriminator training loss: 0.1083, validation loss: 0.0189
2024-05-22 16:36:40 [INFO]: Epoch 093 - generator training loss: -0.0491, discriminator training loss: 0.1075, validation loss: 0.0190
2024-05-22 16:36:48 [INFO]: Epoch 094 - generator training loss: -0.0476, discriminator training loss: 0.1074, validation loss: 0.0190
2024-05-22 16:36:55 [INFO]: Epoch 095 - generator training loss: -0.0480, discriminator training loss: 0.1055, validation loss: 0.0198
2024-05-22 16:37:02 [INFO]: Epoch 096 - generator training loss: -0.0474, discriminator training loss: 0.1057, validation loss: 0.0196
2024-05-22 16:37:09 [INFO]: Epoch 097 - generator training loss: -0.0475, discriminator training loss: 0.1057, validation loss: 0.0193
2024-05-22 16:37:17 [INFO]: Epoch 098 - generator training loss: -0.0473, discriminator training loss: 0.1035, validation loss: 0.0187
2024-05-22 16:37:24 [INFO]: Epoch 099 - generator training loss: -0.0473, discriminator training loss: 0.1051, validation loss: 0.0189
2024-05-22 16:37:31 [INFO]: Epoch 100 - generator training loss: -0.0475, discriminator training loss: 0.1054, validation loss: 0.0185
2024-05-22 16:37:38 [INFO]: Epoch 101 - generator training loss: -0.0465, discriminator training loss: 0.1057, validation loss: 0.0185
2024-05-22 16:37:46 [INFO]: Epoch 102 - generator training loss: -0.0484, discriminator training loss: 0.1047, validation loss: 0.0187
2024-05-22 16:37:53 [INFO]: Epoch 103 - generator training loss: -0.0479, discriminator training loss: 0.1049, validation loss: 0.0188
2024-05-22 16:38:00 [INFO]: Epoch 104 - generator training loss: -0.0507, discriminator training loss: 0.1058, validation loss: 0.0187
2024-05-22 16:38:08 [INFO]: Epoch 105 - generator training loss: -0.0460, discriminator training loss: 0.1061, validation loss: 0.0191
2024-05-22 16:38:15 [INFO]: Epoch 106 - generator training loss: -0.0464, discriminator training loss: 0.1058, validation loss: 0.0187
2024-05-22 16:38:22 [INFO]: Epoch 107 - generator training loss: -0.0494, discriminator training loss: 0.1059, validation loss: 0.0186
2024-05-22 16:38:29 [INFO]: Epoch 108 - generator training loss: -0.0474, discriminator training loss: 0.1061, validation loss: 0.0186
2024-05-22 16:38:37 [INFO]: Epoch 109 - generator training loss: -0.0494, discriminator training loss: 0.1044, validation loss: 0.0191
2024-05-22 16:38:44 [INFO]: Epoch 110 - generator training loss: -0.0472, discriminator training loss: 0.1036, validation loss: 0.0206
2024-05-22 16:38:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:38:44 [INFO]: Finished training. The best model is from epoch#100.
2024-05-22 16:38:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/USGAN_ettm1/20240522_T162520/USGAN.pypots
2024-05-22 16:38:45 [INFO]: US-GAN on ETTm1: MAE=0.1412, MSE=0.0465
2024-05-22 16:38:45 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-22 16:38:45 [INFO]: Using the given device: cuda:0
2024-05-22 16:38:45 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/BRITS_ettm1/20240522_T163845
2024-05-22 16:38:45 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/BRITS_ettm1/20240522_T163845/tensorboard
2024-05-22 16:38:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 16:38:51 [INFO]: Epoch 001 - training loss: 1.3193, validation loss: 0.2596
2024-05-22 16:38:56 [INFO]: Epoch 002 - training loss: 0.8574, validation loss: 0.0760
2024-05-22 16:39:00 [INFO]: Epoch 003 - training loss: 0.7164, validation loss: 0.0496
2024-05-22 16:39:05 [INFO]: Epoch 004 - training loss: 0.6273, validation loss: 0.0417
2024-05-22 16:39:10 [INFO]: Epoch 005 - training loss: 0.5925, validation loss: 0.0379
2024-05-22 16:39:15 [INFO]: Epoch 006 - training loss: 0.5597, validation loss: 0.0371
2024-05-22 16:39:20 [INFO]: Epoch 007 - training loss: 0.5264, validation loss: 0.0352
2024-05-22 16:39:25 [INFO]: Epoch 008 - training loss: 0.4991, validation loss: 0.0317
2024-05-22 16:39:29 [INFO]: Epoch 009 - training loss: 0.4694, validation loss: 0.0311
2024-05-22 16:39:34 [INFO]: Epoch 010 - training loss: 0.4535, validation loss: 0.0275
2024-05-22 16:39:39 [INFO]: Epoch 011 - training loss: 0.4438, validation loss: 0.0254
2024-05-22 16:39:44 [INFO]: Epoch 012 - training loss: 0.4348, validation loss: 0.0252
2024-05-22 16:39:49 [INFO]: Epoch 013 - training loss: 0.4231, validation loss: 0.0239
2024-05-22 16:39:53 [INFO]: Epoch 014 - training loss: 0.4341, validation loss: 0.0239
2024-05-22 16:39:58 [INFO]: Epoch 015 - training loss: 0.4115, validation loss: 0.0241
2024-05-22 16:40:03 [INFO]: Epoch 016 - training loss: 0.4020, validation loss: 0.0228
2024-05-22 16:40:08 [INFO]: Epoch 017 - training loss: 0.4039, validation loss: 0.0249
2024-05-22 16:40:13 [INFO]: Epoch 018 - training loss: 0.3990, validation loss: 0.0327
2024-05-22 16:40:18 [INFO]: Epoch 019 - training loss: 0.4353, validation loss: 0.0255
2024-05-22 16:40:22 [INFO]: Epoch 020 - training loss: 0.4011, validation loss: 0.0234
2024-05-22 16:40:27 [INFO]: Epoch 021 - training loss: 0.4010, validation loss: 0.0237
2024-05-22 16:40:32 [INFO]: Epoch 022 - training loss: 0.3929, validation loss: 0.0229
2024-05-22 16:40:37 [INFO]: Epoch 023 - training loss: 0.3980, validation loss: 0.0221
2024-05-22 16:40:42 [INFO]: Epoch 024 - training loss: 0.3880, validation loss: 0.0220
2024-05-22 16:40:47 [INFO]: Epoch 025 - training loss: 0.3990, validation loss: 0.0224
2024-05-22 16:40:51 [INFO]: Epoch 026 - training loss: 0.3873, validation loss: 0.0220
2024-05-22 16:40:56 [INFO]: Epoch 027 - training loss: 0.3861, validation loss: 0.0218
2024-05-22 16:41:01 [INFO]: Epoch 028 - training loss: 0.3952, validation loss: 0.0228
2024-05-22 16:41:06 [INFO]: Epoch 029 - training loss: 0.3976, validation loss: 0.0226
2024-05-22 16:41:11 [INFO]: Epoch 030 - training loss: 0.3959, validation loss: 0.0228
2024-05-22 16:41:16 [INFO]: Epoch 031 - training loss: 0.3969, validation loss: 0.0220
2024-05-22 16:41:20 [INFO]: Epoch 032 - training loss: 0.3877, validation loss: 0.0232
2024-05-22 16:41:25 [INFO]: Epoch 033 - training loss: 0.3848, validation loss: 0.0224
2024-05-22 16:41:30 [INFO]: Epoch 034 - training loss: 0.3913, validation loss: 0.0226
2024-05-22 16:41:35 [INFO]: Epoch 035 - training loss: 0.3804, validation loss: 0.0225
2024-05-22 16:41:40 [INFO]: Epoch 036 - training loss: 0.3841, validation loss: 0.0222
2024-05-22 16:41:45 [INFO]: Epoch 037 - training loss: 0.3862, validation loss: 0.0224
2024-05-22 16:41:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:41:45 [INFO]: Finished training. The best model is from epoch#27.
2024-05-22 16:41:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/BRITS_ettm1/20240522_T163845/BRITS.pypots
2024-05-22 16:41:46 [INFO]: BRITS on ETTm1: MAE=0.1317, MSE=0.0520
2024-05-22 16:41:46 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-22 16:41:46 [INFO]: Using the given device: cuda:0
2024-05-22 16:41:46 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146
2024-05-22 16:41:46 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/tensorboard
2024-05-22 16:41:46 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 16:41:47 [INFO]: Epoch 001 - training loss: 1.3810, validation loss: 1.2787
2024-05-22 16:41:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch1_loss1.278681680560112.pypots
2024-05-22 16:41:47 [INFO]: Epoch 002 - training loss: 1.0451, validation loss: 1.1467
2024-05-22 16:41:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch2_loss1.1467112451791763.pypots
2024-05-22 16:41:47 [INFO]: Epoch 003 - training loss: 1.0015, validation loss: 1.0680
2024-05-22 16:41:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch3_loss1.0679570734500885.pypots
2024-05-22 16:41:48 [INFO]: Epoch 004 - training loss: 0.9405, validation loss: 1.0281
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch4_loss1.0280894190073013.pypots
2024-05-22 16:41:48 [INFO]: Epoch 005 - training loss: 0.9364, validation loss: 1.0136
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch5_loss1.0136021375656128.pypots
2024-05-22 16:41:48 [INFO]: Epoch 006 - training loss: 0.9174, validation loss: 1.0035
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch6_loss1.0035341084003448.pypots
2024-05-22 16:41:48 [INFO]: Epoch 007 - training loss: 0.9005, validation loss: 1.0000
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch7_loss1.0000296831130981.pypots
2024-05-22 16:41:48 [INFO]: Epoch 008 - training loss: 0.8995, validation loss: 0.9982
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch8_loss0.9981851726770401.pypots
2024-05-22 16:41:48 [INFO]: Epoch 009 - training loss: 0.8751, validation loss: 0.9945
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch9_loss0.9945447146892548.pypots
2024-05-22 16:41:48 [INFO]: Epoch 010 - training loss: 0.8826, validation loss: 0.9957
2024-05-22 16:41:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch10_loss0.995712161064148.pypots
2024-05-22 16:41:49 [INFO]: Epoch 011 - training loss: 0.8828, validation loss: 0.9908
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch11_loss0.9908098876476288.pypots
2024-05-22 16:41:49 [INFO]: Epoch 012 - training loss: 0.8793, validation loss: 0.9901
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch12_loss0.9901368618011475.pypots
2024-05-22 16:41:49 [INFO]: Epoch 013 - training loss: 0.8768, validation loss: 0.9883
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch13_loss0.9882535040378571.pypots
2024-05-22 16:41:49 [INFO]: Epoch 014 - training loss: 0.8869, validation loss: 0.9864
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch14_loss0.9864463657140732.pypots
2024-05-22 16:41:49 [INFO]: Epoch 015 - training loss: 0.8657, validation loss: 0.9866
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch15_loss0.9865837097167969.pypots
2024-05-22 16:41:49 [INFO]: Epoch 016 - training loss: 0.8310, validation loss: 0.9862
2024-05-22 16:41:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch16_loss0.9861750453710556.pypots
2024-05-22 16:41:50 [INFO]: Epoch 017 - training loss: 0.8405, validation loss: 0.9835
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch17_loss0.9834577590227127.pypots
2024-05-22 16:41:50 [INFO]: Epoch 018 - training loss: 0.8578, validation loss: 0.9820
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch18_loss0.9820493161678314.pypots
2024-05-22 16:41:50 [INFO]: Epoch 019 - training loss: 0.8501, validation loss: 0.9801
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch19_loss0.9800754636526108.pypots
2024-05-22 16:41:50 [INFO]: Epoch 020 - training loss: 0.8606, validation loss: 0.9759
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch20_loss0.975888729095459.pypots
2024-05-22 16:41:50 [INFO]: Epoch 021 - training loss: 0.8410, validation loss: 0.9710
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch21_loss0.9710045903921127.pypots
2024-05-22 16:41:50 [INFO]: Epoch 022 - training loss: 0.8379, validation loss: 0.9679
2024-05-22 16:41:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch22_loss0.9679441601037979.pypots
2024-05-22 16:41:51 [INFO]: Epoch 023 - training loss: 0.8383, validation loss: 0.9635
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch23_loss0.9634635001420975.pypots
2024-05-22 16:41:51 [INFO]: Epoch 024 - training loss: 0.8257, validation loss: 0.9619
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch24_loss0.9619215130805969.pypots
2024-05-22 16:41:51 [INFO]: Epoch 025 - training loss: 0.8324, validation loss: 0.9585
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch25_loss0.9585141390562057.pypots
2024-05-22 16:41:51 [INFO]: Epoch 026 - training loss: 0.8192, validation loss: 0.9522
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch26_loss0.9521906822919846.pypots
2024-05-22 16:41:51 [INFO]: Epoch 027 - training loss: 0.8290, validation loss: 0.9474
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch27_loss0.9473976790904999.pypots
2024-05-22 16:41:51 [INFO]: Epoch 028 - training loss: 0.8275, validation loss: 0.9431
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch28_loss0.9430933147668839.pypots
2024-05-22 16:41:51 [INFO]: Epoch 029 - training loss: 0.8028, validation loss: 0.9422
2024-05-22 16:41:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch29_loss0.9422292709350586.pypots
2024-05-22 16:41:52 [INFO]: Epoch 030 - training loss: 0.8086, validation loss: 0.9392
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch30_loss0.9391919672489166.pypots
2024-05-22 16:41:52 [INFO]: Epoch 031 - training loss: 0.8144, validation loss: 0.9346
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch31_loss0.9345907270908356.pypots
2024-05-22 16:41:52 [INFO]: Epoch 032 - training loss: 0.8190, validation loss: 0.9316
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch32_loss0.93156997859478.pypots
2024-05-22 16:41:52 [INFO]: Epoch 033 - training loss: 0.7945, validation loss: 0.9277
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch33_loss0.9277414679527283.pypots
2024-05-22 16:41:52 [INFO]: Epoch 034 - training loss: 0.7963, validation loss: 0.9263
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch34_loss0.9263314306735992.pypots
2024-05-22 16:41:52 [INFO]: Epoch 035 - training loss: 0.7897, validation loss: 0.9224
2024-05-22 16:41:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch35_loss0.9224332273006439.pypots
2024-05-22 16:41:53 [INFO]: Epoch 036 - training loss: 0.8019, validation loss: 0.9175
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch36_loss0.917456328868866.pypots
2024-05-22 16:41:53 [INFO]: Epoch 037 - training loss: 0.7758, validation loss: 0.9168
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch37_loss0.9168201833963394.pypots
2024-05-22 16:41:53 [INFO]: Epoch 038 - training loss: 0.8044, validation loss: 0.9142
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch38_loss0.9141951352357864.pypots
2024-05-22 16:41:53 [INFO]: Epoch 039 - training loss: 0.7953, validation loss: 0.9113
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch39_loss0.9113461226224899.pypots
2024-05-22 16:41:53 [INFO]: Epoch 040 - training loss: 0.8355, validation loss: 0.9105
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch40_loss0.9104519337415695.pypots
2024-05-22 16:41:53 [INFO]: Epoch 041 - training loss: 0.7669, validation loss: 0.9076
2024-05-22 16:41:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch41_loss0.907648578286171.pypots
2024-05-22 16:41:53 [INFO]: Epoch 042 - training loss: 0.8504, validation loss: 0.9079
2024-05-22 16:41:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch42_loss0.9078669100999832.pypots
2024-05-22 16:41:55 [INFO]: Epoch 043 - training loss: 0.8252, validation loss: 0.9079
2024-05-22 16:41:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch43_loss0.9078990668058395.pypots
2024-05-22 16:41:56 [INFO]: Epoch 044 - training loss: 0.7890, validation loss: 0.9058
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch44_loss0.9057580232620239.pypots
2024-05-22 16:41:56 [INFO]: Epoch 045 - training loss: 0.7752, validation loss: 0.9031
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch45_loss0.9031170308589935.pypots
2024-05-22 16:41:56 [INFO]: Epoch 046 - training loss: 0.8005, validation loss: 0.9010
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch46_loss0.9009897410869598.pypots
2024-05-22 16:41:56 [INFO]: Epoch 047 - training loss: 0.7865, validation loss: 0.8996
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch47_loss0.8995916694402695.pypots
2024-05-22 16:41:56 [INFO]: Epoch 048 - training loss: 0.8017, validation loss: 0.8967
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch48_loss0.8967219740152359.pypots
2024-05-22 16:41:56 [INFO]: Epoch 049 - training loss: 0.8053, validation loss: 0.8919
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch49_loss0.8919028788805008.pypots
2024-05-22 16:41:56 [INFO]: Epoch 050 - training loss: 0.8317, validation loss: 0.8947
2024-05-22 16:41:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch50_loss0.8946700245141983.pypots
2024-05-22 16:41:57 [INFO]: Epoch 051 - training loss: 0.7972, validation loss: 0.8909
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch51_loss0.8908938616514206.pypots
2024-05-22 16:41:57 [INFO]: Epoch 052 - training loss: 0.7830, validation loss: 0.8876
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch52_loss0.8875808715820312.pypots
2024-05-22 16:41:57 [INFO]: Epoch 053 - training loss: 0.7947, validation loss: 0.8875
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch53_loss0.8874762803316116.pypots
2024-05-22 16:41:57 [INFO]: Epoch 054 - training loss: 0.7826, validation loss: 0.8866
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch54_loss0.8866346329450607.pypots
2024-05-22 16:41:57 [INFO]: Epoch 055 - training loss: 0.8008, validation loss: 0.8870
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch55_loss0.8869670331478119.pypots
2024-05-22 16:41:57 [INFO]: Epoch 056 - training loss: 0.8119, validation loss: 0.8831
2024-05-22 16:41:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch56_loss0.8831136077642441.pypots
2024-05-22 16:41:58 [INFO]: Epoch 057 - training loss: 0.7954, validation loss: 0.8820
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch57_loss0.8820465356111526.pypots
2024-05-22 16:41:58 [INFO]: Epoch 058 - training loss: 0.7874, validation loss: 0.8795
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch58_loss0.8795210719108582.pypots
2024-05-22 16:41:58 [INFO]: Epoch 059 - training loss: 0.7658, validation loss: 0.8819
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch59_loss0.8819241523742676.pypots
2024-05-22 16:41:58 [INFO]: Epoch 060 - training loss: 0.7630, validation loss: 0.8778
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch60_loss0.8778345733880997.pypots
2024-05-22 16:41:58 [INFO]: Epoch 061 - training loss: 0.7763, validation loss: 0.8786
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch61_loss0.8785704672336578.pypots
2024-05-22 16:41:58 [INFO]: Epoch 062 - training loss: 0.7711, validation loss: 0.8764
2024-05-22 16:41:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch62_loss0.8763872981071472.pypots
2024-05-22 16:41:59 [INFO]: Epoch 063 - training loss: 0.7801, validation loss: 0.8750
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch63_loss0.874982088804245.pypots
2024-05-22 16:41:59 [INFO]: Epoch 064 - training loss: 0.7748, validation loss: 0.8737
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch64_loss0.8736656159162521.pypots
2024-05-22 16:41:59 [INFO]: Epoch 065 - training loss: 0.7858, validation loss: 0.8727
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch65_loss0.8726503103971481.pypots
2024-05-22 16:41:59 [INFO]: Epoch 066 - training loss: 0.7835, validation loss: 0.8729
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch66_loss0.8729242831468582.pypots
2024-05-22 16:41:59 [INFO]: Epoch 067 - training loss: 0.7982, validation loss: 0.8734
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch67_loss0.8733617067337036.pypots
2024-05-22 16:41:59 [INFO]: Epoch 068 - training loss: 0.7722, validation loss: 0.8702
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch68_loss0.8701846599578857.pypots
2024-05-22 16:41:59 [INFO]: Epoch 069 - training loss: 0.8226, validation loss: 0.8696
2024-05-22 16:41:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch69_loss0.8695899099111557.pypots
2024-05-22 16:42:00 [INFO]: Epoch 070 - training loss: 0.7895, validation loss: 0.8734
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch70_loss0.8734475374221802.pypots
2024-05-22 16:42:00 [INFO]: Epoch 071 - training loss: 0.7586, validation loss: 0.8706
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch71_loss0.8705540746450424.pypots
2024-05-22 16:42:00 [INFO]: Epoch 072 - training loss: 0.7914, validation loss: 0.8689
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch72_loss0.8688695430755615.pypots
2024-05-22 16:42:00 [INFO]: Epoch 073 - training loss: 0.7760, validation loss: 0.8664
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch73_loss0.8664243072271347.pypots
2024-05-22 16:42:00 [INFO]: Epoch 074 - training loss: 0.7655, validation loss: 0.8663
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch74_loss0.8662951737642288.pypots
2024-05-22 16:42:00 [INFO]: Epoch 075 - training loss: 0.7536, validation loss: 0.8640
2024-05-22 16:42:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch75_loss0.8639831393957138.pypots
2024-05-22 16:42:01 [INFO]: Epoch 076 - training loss: 0.7823, validation loss: 0.8637
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch76_loss0.8636739403009415.pypots
2024-05-22 16:42:01 [INFO]: Epoch 077 - training loss: 0.7966, validation loss: 0.8645
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch77_loss0.8645049482584.pypots
2024-05-22 16:42:01 [INFO]: Epoch 078 - training loss: 0.7813, validation loss: 0.8680
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch78_loss0.8680430054664612.pypots
2024-05-22 16:42:01 [INFO]: Epoch 079 - training loss: 0.7882, validation loss: 0.8650
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch79_loss0.8649648725986481.pypots
2024-05-22 16:42:01 [INFO]: Epoch 080 - training loss: 0.7558, validation loss: 0.8641
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch80_loss0.8641375750303268.pypots
2024-05-22 16:42:01 [INFO]: Epoch 081 - training loss: 0.7482, validation loss: 0.8627
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch81_loss0.8626552671194077.pypots
2024-05-22 16:42:01 [INFO]: Epoch 082 - training loss: 0.7860, validation loss: 0.8613
2024-05-22 16:42:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch82_loss0.8613056987524033.pypots
2024-05-22 16:42:02 [INFO]: Epoch 083 - training loss: 0.7917, validation loss: 0.8615
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch83_loss0.8614852279424667.pypots
2024-05-22 16:42:02 [INFO]: Epoch 084 - training loss: 0.7974, validation loss: 0.8638
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch84_loss0.863836407661438.pypots
2024-05-22 16:42:02 [INFO]: Epoch 085 - training loss: 0.7513, validation loss: 0.8640
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch85_loss0.8639709502458572.pypots
2024-05-22 16:42:02 [INFO]: Epoch 086 - training loss: 0.7647, validation loss: 0.8596
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch86_loss0.8596268892288208.pypots
2024-05-22 16:42:02 [INFO]: Epoch 087 - training loss: 0.7786, validation loss: 0.8596
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch87_loss0.8595563173294067.pypots
2024-05-22 16:42:02 [INFO]: Epoch 088 - training loss: 0.7538, validation loss: 0.8586
2024-05-22 16:42:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch88_loss0.8585780560970306.pypots
2024-05-22 16:42:03 [INFO]: Epoch 089 - training loss: 0.7848, validation loss: 0.8631
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch89_loss0.8631025105714798.pypots
2024-05-22 16:42:03 [INFO]: Epoch 090 - training loss: 0.7822, validation loss: 0.8568
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch90_loss0.8568452149629593.pypots
2024-05-22 16:42:03 [INFO]: Epoch 091 - training loss: 0.7865, validation loss: 0.8600
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch91_loss0.8599821478128433.pypots
2024-05-22 16:42:03 [INFO]: Epoch 092 - training loss: 0.7557, validation loss: 0.8599
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch92_loss0.8599012345075607.pypots
2024-05-22 16:42:03 [INFO]: Epoch 093 - training loss: 0.7774, validation loss: 0.8581
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch93_loss0.8580970764160156.pypots
2024-05-22 16:42:03 [INFO]: Epoch 094 - training loss: 0.7818, validation loss: 0.8568
2024-05-22 16:42:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch94_loss0.8568018972873688.pypots
2024-05-22 16:42:03 [INFO]: Epoch 095 - training loss: 0.7553, validation loss: 0.8560
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch95_loss0.855976328253746.pypots
2024-05-22 16:42:04 [INFO]: Epoch 096 - training loss: 0.7738, validation loss: 0.8567
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch96_loss0.8566833734512329.pypots
2024-05-22 16:42:04 [INFO]: Epoch 097 - training loss: 0.8037, validation loss: 0.8588
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch97_loss0.8587794154882431.pypots
2024-05-22 16:42:04 [INFO]: Epoch 098 - training loss: 0.7793, validation loss: 0.8571
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch98_loss0.857149064540863.pypots
2024-05-22 16:42:04 [INFO]: Epoch 099 - training loss: 0.7801, validation loss: 0.8553
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch99_loss0.8552791178226471.pypots
2024-05-22 16:42:04 [INFO]: Epoch 100 - training loss: 0.7676, validation loss: 0.8522
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch100_loss0.8522144854068756.pypots
2024-05-22 16:42:04 [INFO]: Epoch 101 - training loss: 0.7640, validation loss: 0.8531
2024-05-22 16:42:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch101_loss0.8530832678079605.pypots
2024-05-22 16:42:05 [INFO]: Epoch 102 - training loss: 0.8110, validation loss: 0.8502
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch102_loss0.8501826226711273.pypots
2024-05-22 16:42:05 [INFO]: Epoch 103 - training loss: 0.7721, validation loss: 0.8548
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch103_loss0.8548157811164856.pypots
2024-05-22 16:42:05 [INFO]: Epoch 104 - training loss: 0.7541, validation loss: 0.8509
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch104_loss0.8508698344230652.pypots
2024-05-22 16:42:05 [INFO]: Epoch 105 - training loss: 0.7587, validation loss: 0.8509
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch105_loss0.8508905172348022.pypots
2024-05-22 16:42:05 [INFO]: Epoch 106 - training loss: 0.7781, validation loss: 0.8504
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch106_loss0.8503998816013336.pypots
2024-05-22 16:42:05 [INFO]: Epoch 107 - training loss: 0.7690, validation loss: 0.8504
2024-05-22 16:42:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch107_loss0.8503793030977249.pypots
2024-05-22 16:42:06 [INFO]: Epoch 108 - training loss: 0.7558, validation loss: 0.8491
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch108_loss0.8490752577781677.pypots
2024-05-22 16:42:06 [INFO]: Epoch 109 - training loss: 0.7668, validation loss: 0.8506
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch109_loss0.8505652099847794.pypots
2024-05-22 16:42:06 [INFO]: Epoch 110 - training loss: 0.7869, validation loss: 0.8510
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch110_loss0.8509832918643951.pypots
2024-05-22 16:42:06 [INFO]: Epoch 111 - training loss: 0.7673, validation loss: 0.8494
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch111_loss0.8494332730770111.pypots
2024-05-22 16:42:06 [INFO]: Epoch 112 - training loss: 0.7711, validation loss: 0.8481
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch112_loss0.8481217920780182.pypots
2024-05-22 16:42:06 [INFO]: Epoch 113 - training loss: 0.7655, validation loss: 0.8459
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch113_loss0.8459130674600601.pypots
2024-05-22 16:42:06 [INFO]: Epoch 114 - training loss: 0.7747, validation loss: 0.8483
2024-05-22 16:42:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch114_loss0.8482890278100967.pypots
2024-05-22 16:42:07 [INFO]: Epoch 115 - training loss: 0.7766, validation loss: 0.8484
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch115_loss0.8483691364526749.pypots
2024-05-22 16:42:07 [INFO]: Epoch 116 - training loss: 0.7843, validation loss: 0.8456
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch116_loss0.8455571830272675.pypots
2024-05-22 16:42:07 [INFO]: Epoch 117 - training loss: 0.7728, validation loss: 0.8488
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch117_loss0.8488078564405441.pypots
2024-05-22 16:42:07 [INFO]: Epoch 118 - training loss: 0.7653, validation loss: 0.8465
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch118_loss0.8465172946453094.pypots
2024-05-22 16:42:07 [INFO]: Epoch 119 - training loss: 0.7609, validation loss: 0.8455
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch119_loss0.8455088287591934.pypots
2024-05-22 16:42:07 [INFO]: Epoch 120 - training loss: 0.7621, validation loss: 0.8487
2024-05-22 16:42:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch120_loss0.8486785590648651.pypots
2024-05-22 16:42:08 [INFO]: Epoch 121 - training loss: 0.7567, validation loss: 0.8454
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch121_loss0.845350831747055.pypots
2024-05-22 16:42:08 [INFO]: Epoch 122 - training loss: 0.7551, validation loss: 0.8431
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch122_loss0.843087762594223.pypots
2024-05-22 16:42:08 [INFO]: Epoch 123 - training loss: 0.7693, validation loss: 0.8421
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch123_loss0.8420522958040237.pypots
2024-05-22 16:42:08 [INFO]: Epoch 124 - training loss: 0.7659, validation loss: 0.8441
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch124_loss0.8441265821456909.pypots
2024-05-22 16:42:08 [INFO]: Epoch 125 - training loss: 0.7729, validation loss: 0.8415
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch125_loss0.841492772102356.pypots
2024-05-22 16:42:08 [INFO]: Epoch 126 - training loss: 0.7712, validation loss: 0.8420
2024-05-22 16:42:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch126_loss0.8419772535562515.pypots
2024-05-22 16:42:09 [INFO]: Epoch 127 - training loss: 0.7622, validation loss: 0.8414
2024-05-22 16:42:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch127_loss0.8414198011159897.pypots
2024-05-22 16:42:11 [INFO]: Epoch 128 - training loss: 0.7820, validation loss: 0.8436
2024-05-22 16:42:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch128_loss0.8435574024915695.pypots
2024-05-22 16:42:11 [INFO]: Epoch 129 - training loss: 0.7762, validation loss: 0.8391
2024-05-22 16:42:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch129_loss0.839055597782135.pypots
2024-05-22 16:42:12 [INFO]: Epoch 130 - training loss: 0.7657, validation loss: 0.8432
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch130_loss0.8431775122880936.pypots
2024-05-22 16:42:12 [INFO]: Epoch 131 - training loss: 0.7652, validation loss: 0.8405
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch131_loss0.8405260443687439.pypots
2024-05-22 16:42:12 [INFO]: Epoch 132 - training loss: 0.7492, validation loss: 0.8390
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch132_loss0.8390225917100906.pypots
2024-05-22 16:42:12 [INFO]: Epoch 133 - training loss: 0.7678, validation loss: 0.8401
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch133_loss0.840072825551033.pypots
2024-05-22 16:42:12 [INFO]: Epoch 134 - training loss: 0.7641, validation loss: 0.8390
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch134_loss0.8390464633703232.pypots
2024-05-22 16:42:12 [INFO]: Epoch 135 - training loss: 0.7984, validation loss: 0.8399
2024-05-22 16:42:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch135_loss0.8398828357458115.pypots
2024-05-22 16:42:13 [INFO]: Epoch 136 - training loss: 0.7944, validation loss: 0.8394
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch136_loss0.8394331485033035.pypots
2024-05-22 16:42:13 [INFO]: Epoch 137 - training loss: 0.7830, validation loss: 0.8368
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch137_loss0.8368398100137711.pypots
2024-05-22 16:42:13 [INFO]: Epoch 138 - training loss: 0.7652, validation loss: 0.8391
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch138_loss0.8390814810991287.pypots
2024-05-22 16:42:13 [INFO]: Epoch 139 - training loss: 0.7697, validation loss: 0.8350
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch139_loss0.8350253254175186.pypots
2024-05-22 16:42:13 [INFO]: Epoch 140 - training loss: 0.7755, validation loss: 0.8372
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch140_loss0.8372371643781662.pypots
2024-05-22 16:42:13 [INFO]: Epoch 141 - training loss: 0.7705, validation loss: 0.8330
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch141_loss0.8330312818288803.pypots
2024-05-22 16:42:13 [INFO]: Epoch 142 - training loss: 0.7795, validation loss: 0.8341
2024-05-22 16:42:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch142_loss0.8341137766838074.pypots
2024-05-22 16:42:14 [INFO]: Epoch 143 - training loss: 0.7991, validation loss: 0.8359
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch143_loss0.8358729183673859.pypots
2024-05-22 16:42:14 [INFO]: Epoch 144 - training loss: 0.7797, validation loss: 0.8320
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch144_loss0.8319518119096756.pypots
2024-05-22 16:42:14 [INFO]: Epoch 145 - training loss: 0.7682, validation loss: 0.8325
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch145_loss0.8325485587120056.pypots
2024-05-22 16:42:14 [INFO]: Epoch 146 - training loss: 0.7550, validation loss: 0.8323
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch146_loss0.8322605639696121.pypots
2024-05-22 16:42:14 [INFO]: Epoch 147 - training loss: 0.7533, validation loss: 0.8299
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch147_loss0.8299332559108734.pypots
2024-05-22 16:42:14 [INFO]: Epoch 148 - training loss: 0.7589, validation loss: 0.8303
2024-05-22 16:42:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch148_loss0.8303061574697495.pypots
2024-05-22 16:42:15 [INFO]: Epoch 149 - training loss: 0.7520, validation loss: 0.8326
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch149_loss0.8325784802436829.pypots
2024-05-22 16:42:15 [INFO]: Epoch 150 - training loss: 0.7635, validation loss: 0.8334
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch150_loss0.8334038555622101.pypots
2024-05-22 16:42:15 [INFO]: Epoch 151 - training loss: 0.7591, validation loss: 0.8307
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch151_loss0.8306782245635986.pypots
2024-05-22 16:42:15 [INFO]: Epoch 152 - training loss: 0.7599, validation loss: 0.8287
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch152_loss0.8286936432123184.pypots
2024-05-22 16:42:15 [INFO]: Epoch 153 - training loss: 0.7567, validation loss: 0.8299
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch153_loss0.829903319478035.pypots
2024-05-22 16:42:15 [INFO]: Epoch 154 - training loss: 0.7522, validation loss: 0.8285
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch154_loss0.8285394906997681.pypots
2024-05-22 16:42:15 [INFO]: Epoch 155 - training loss: 0.7493, validation loss: 0.8285
2024-05-22 16:42:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch155_loss0.8284893333911896.pypots
2024-05-22 16:42:16 [INFO]: Epoch 156 - training loss: 0.7739, validation loss: 0.8261
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch156_loss0.8261088728904724.pypots
2024-05-22 16:42:16 [INFO]: Epoch 157 - training loss: 0.7760, validation loss: 0.8296
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch157_loss0.82956163585186.pypots
2024-05-22 16:42:16 [INFO]: Epoch 158 - training loss: 0.7539, validation loss: 0.8269
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch158_loss0.8268707394599915.pypots
2024-05-22 16:42:16 [INFO]: Epoch 159 - training loss: 0.7353, validation loss: 0.8265
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch159_loss0.8265224695205688.pypots
2024-05-22 16:42:16 [INFO]: Epoch 160 - training loss: 0.7673, validation loss: 0.8249
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch160_loss0.8248979598283768.pypots
2024-05-22 16:42:16 [INFO]: Epoch 161 - training loss: 0.7629, validation loss: 0.8234
2024-05-22 16:42:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch161_loss0.8233865797519684.pypots
2024-05-22 16:42:17 [INFO]: Epoch 162 - training loss: 0.7502, validation loss: 0.8268
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch162_loss0.8267675936222076.pypots
2024-05-22 16:42:17 [INFO]: Epoch 163 - training loss: 0.7697, validation loss: 0.8244
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch163_loss0.8243527859449387.pypots
2024-05-22 16:42:17 [INFO]: Epoch 164 - training loss: 0.7547, validation loss: 0.8329
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch164_loss0.8329390585422516.pypots
2024-05-22 16:42:17 [INFO]: Epoch 165 - training loss: 0.7625, validation loss: 0.8237
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch165_loss0.8236541897058487.pypots
2024-05-22 16:42:17 [INFO]: Epoch 166 - training loss: 0.7611, validation loss: 0.8227
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch166_loss0.8227468878030777.pypots
2024-05-22 16:42:17 [INFO]: Epoch 167 - training loss: 0.7754, validation loss: 0.8229
2024-05-22 16:42:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch167_loss0.822904571890831.pypots
2024-05-22 16:42:18 [INFO]: Epoch 168 - training loss: 0.7707, validation loss: 0.8216
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch168_loss0.82161945104599.pypots
2024-05-22 16:42:18 [INFO]: Epoch 169 - training loss: 0.7661, validation loss: 0.8212
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch169_loss0.8211580216884613.pypots
2024-05-22 16:42:18 [INFO]: Epoch 170 - training loss: 0.7605, validation loss: 0.8212
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch170_loss0.8211869597434998.pypots
2024-05-22 16:42:18 [INFO]: Epoch 171 - training loss: 0.7688, validation loss: 0.8196
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch171_loss0.8195542991161346.pypots
2024-05-22 16:42:18 [INFO]: Epoch 172 - training loss: 0.7708, validation loss: 0.8183
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch172_loss0.8183081448078156.pypots
2024-05-22 16:42:18 [INFO]: Epoch 173 - training loss: 0.7573, validation loss: 0.8182
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch173_loss0.8181612640619278.pypots
2024-05-22 16:42:18 [INFO]: Epoch 174 - training loss: 0.7967, validation loss: 0.8171
2024-05-22 16:42:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch174_loss0.8171223104000092.pypots
2024-05-22 16:42:19 [INFO]: Epoch 175 - training loss: 0.7767, validation loss: 0.8153
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch175_loss0.8153360038995743.pypots
2024-05-22 16:42:19 [INFO]: Epoch 176 - training loss: 0.7444, validation loss: 0.8173
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch176_loss0.817322239279747.pypots
2024-05-22 16:42:19 [INFO]: Epoch 177 - training loss: 0.7821, validation loss: 0.8213
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch177_loss0.8213236033916473.pypots
2024-05-22 16:42:19 [INFO]: Epoch 178 - training loss: 0.7794, validation loss: 0.8172
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch178_loss0.817230224609375.pypots
2024-05-22 16:42:19 [INFO]: Epoch 179 - training loss: 0.7651, validation loss: 0.8166
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch179_loss0.8166245669126511.pypots
2024-05-22 16:42:19 [INFO]: Epoch 180 - training loss: 0.7677, validation loss: 0.8155
2024-05-22 16:42:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch180_loss0.8154571056365967.pypots
2024-05-22 16:42:20 [INFO]: Epoch 181 - training loss: 0.7447, validation loss: 0.8142
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch181_loss0.8141629844903946.pypots
2024-05-22 16:42:20 [INFO]: Epoch 182 - training loss: 0.7410, validation loss: 0.8166
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch182_loss0.8165745437145233.pypots
2024-05-22 16:42:20 [INFO]: Epoch 183 - training loss: 0.7597, validation loss: 0.8151
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch183_loss0.8151484876871109.pypots
2024-05-22 16:42:20 [INFO]: Epoch 184 - training loss: 0.7543, validation loss: 0.8168
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch184_loss0.8168197870254517.pypots
2024-05-22 16:42:20 [INFO]: Epoch 185 - training loss: 0.7558, validation loss: 0.8136
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch185_loss0.8135913908481598.pypots
2024-05-22 16:42:20 [INFO]: Epoch 186 - training loss: 0.7589, validation loss: 0.8129
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch186_loss0.8129033148288727.pypots
2024-05-22 16:42:20 [INFO]: Epoch 187 - training loss: 0.7564, validation loss: 0.8125
2024-05-22 16:42:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch187_loss0.812476396560669.pypots
2024-05-22 16:42:21 [INFO]: Epoch 188 - training loss: 0.7696, validation loss: 0.8149
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch188_loss0.8149486184120178.pypots
2024-05-22 16:42:21 [INFO]: Epoch 189 - training loss: 0.7690, validation loss: 0.8151
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch189_loss0.8150962293148041.pypots
2024-05-22 16:42:21 [INFO]: Epoch 190 - training loss: 0.7563, validation loss: 0.8189
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch190_loss0.8188639134168625.pypots
2024-05-22 16:42:21 [INFO]: Epoch 191 - training loss: 0.7584, validation loss: 0.8095
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch191_loss0.8095461130142212.pypots
2024-05-22 16:42:21 [INFO]: Epoch 192 - training loss: 0.7806, validation loss: 0.8085
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch192_loss0.8084803372621536.pypots
2024-05-22 16:42:21 [INFO]: Epoch 193 - training loss: 0.7703, validation loss: 0.8092
2024-05-22 16:42:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch193_loss0.8091593682765961.pypots
2024-05-22 16:42:22 [INFO]: Epoch 194 - training loss: 0.7537, validation loss: 0.8110
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch194_loss0.8109500855207443.pypots
2024-05-22 16:42:22 [INFO]: Epoch 195 - training loss: 0.7663, validation loss: 0.8116
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch195_loss0.8115965574979782.pypots
2024-05-22 16:42:22 [INFO]: Epoch 196 - training loss: 0.7513, validation loss: 0.8066
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch196_loss0.8065594583749771.pypots
2024-05-22 16:42:22 [INFO]: Epoch 197 - training loss: 0.7346, validation loss: 0.8088
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch197_loss0.8087664544582367.pypots
2024-05-22 16:42:22 [INFO]: Epoch 198 - training loss: 0.7536, validation loss: 0.8108
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch198_loss0.8108131289482117.pypots
2024-05-22 16:42:22 [INFO]: Epoch 199 - training loss: 0.7389, validation loss: 0.8113
2024-05-22 16:42:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch199_loss0.8113479912281036.pypots
2024-05-22 16:42:23 [INFO]: Epoch 200 - training loss: 0.7697, validation loss: 0.8067
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch200_loss0.8066817373037338.pypots
2024-05-22 16:42:23 [INFO]: Epoch 201 - training loss: 0.7529, validation loss: 0.8060
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch201_loss0.8059643059968948.pypots
2024-05-22 16:42:23 [INFO]: Epoch 202 - training loss: 0.7569, validation loss: 0.8078
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch202_loss0.8077822178602219.pypots
2024-05-22 16:42:23 [INFO]: Epoch 203 - training loss: 0.7731, validation loss: 0.8053
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch203_loss0.8052891492843628.pypots
2024-05-22 16:42:23 [INFO]: Epoch 204 - training loss: 0.7743, validation loss: 0.8072
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch204_loss0.8071604818105698.pypots
2024-05-22 16:42:23 [INFO]: Epoch 205 - training loss: 0.7502, validation loss: 0.8075
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch205_loss0.8074619621038437.pypots
2024-05-22 16:42:23 [INFO]: Epoch 206 - training loss: 0.7734, validation loss: 0.8092
2024-05-22 16:42:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch206_loss0.8091843575239182.pypots
2024-05-22 16:42:24 [INFO]: Epoch 207 - training loss: 0.7530, validation loss: 0.8050
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch207_loss0.8050209283828735.pypots
2024-05-22 16:42:24 [INFO]: Epoch 208 - training loss: 0.7426, validation loss: 0.8086
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch208_loss0.8086355328559875.pypots
2024-05-22 16:42:24 [INFO]: Epoch 209 - training loss: 0.7509, validation loss: 0.8035
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch209_loss0.80353182554245.pypots
2024-05-22 16:42:24 [INFO]: Epoch 210 - training loss: 0.7708, validation loss: 0.8065
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch210_loss0.8065326362848282.pypots
2024-05-22 16:42:24 [INFO]: Epoch 211 - training loss: 0.7558, validation loss: 0.8042
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch211_loss0.8042145669460297.pypots
2024-05-22 16:42:24 [INFO]: Epoch 212 - training loss: 0.7473, validation loss: 0.8076
2024-05-22 16:42:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch212_loss0.8076049238443375.pypots
2024-05-22 16:42:25 [INFO]: Epoch 213 - training loss: 0.7431, validation loss: 0.8044
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch213_loss0.8043570071458817.pypots
2024-05-22 16:42:25 [INFO]: Epoch 214 - training loss: 0.7724, validation loss: 0.8053
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch214_loss0.8053236901760101.pypots
2024-05-22 16:42:25 [INFO]: Epoch 215 - training loss: 0.7665, validation loss: 0.8008
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch215_loss0.8008204251527786.pypots
2024-05-22 16:42:25 [INFO]: Epoch 216 - training loss: 0.7540, validation loss: 0.8035
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch216_loss0.8035143911838531.pypots
2024-05-22 16:42:25 [INFO]: Epoch 217 - training loss: 0.7569, validation loss: 0.8026
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch217_loss0.8026075661182404.pypots
2024-05-22 16:42:25 [INFO]: Epoch 218 - training loss: 0.7453, validation loss: 0.8049
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch218_loss0.804885596036911.pypots
2024-05-22 16:42:25 [INFO]: Epoch 219 - training loss: 0.7393, validation loss: 0.8002
2024-05-22 16:42:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch219_loss0.8001905083656311.pypots
2024-05-22 16:42:26 [INFO]: Epoch 220 - training loss: 0.7703, validation loss: 0.8122
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch220_loss0.8121758252382278.pypots
2024-05-22 16:42:26 [INFO]: Epoch 221 - training loss: 0.7466, validation loss: 0.8013
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch221_loss0.8012919425964355.pypots
2024-05-22 16:42:26 [INFO]: Epoch 222 - training loss: 0.7826, validation loss: 0.8005
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch222_loss0.8005053699016571.pypots
2024-05-22 16:42:26 [INFO]: Epoch 223 - training loss: 0.7480, validation loss: 0.8057
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch223_loss0.805730864405632.pypots
2024-05-22 16:42:26 [INFO]: Epoch 224 - training loss: 0.7583, validation loss: 0.8037
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch224_loss0.8037350326776505.pypots
2024-05-22 16:42:26 [INFO]: Epoch 225 - training loss: 0.7861, validation loss: 0.8049
2024-05-22 16:42:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch225_loss0.8048973828554153.pypots
2024-05-22 16:42:27 [INFO]: Epoch 226 - training loss: 0.7617, validation loss: 0.8024
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch226_loss0.8023535907268524.pypots
2024-05-22 16:42:27 [INFO]: Epoch 227 - training loss: 0.7535, validation loss: 0.8009
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch227_loss0.800924226641655.pypots
2024-05-22 16:42:27 [INFO]: Epoch 228 - training loss: 0.7524, validation loss: 0.8018
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch228_loss0.801801785826683.pypots
2024-05-22 16:42:27 [INFO]: Epoch 229 - training loss: 0.7446, validation loss: 0.7991
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch229_loss0.7990501821041107.pypots
2024-05-22 16:42:27 [INFO]: Epoch 230 - training loss: 0.7533, validation loss: 0.7997
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch230_loss0.7996608167886734.pypots
2024-05-22 16:42:27 [INFO]: Epoch 231 - training loss: 0.7574, validation loss: 0.8016
2024-05-22 16:42:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch231_loss0.8015738725662231.pypots
2024-05-22 16:42:28 [INFO]: Epoch 232 - training loss: 0.7542, validation loss: 0.8005
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch232_loss0.8004543036222458.pypots
2024-05-22 16:42:28 [INFO]: Epoch 233 - training loss: 0.7621, validation loss: 0.8000
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch233_loss0.8000447303056717.pypots
2024-05-22 16:42:28 [INFO]: Epoch 234 - training loss: 0.7593, validation loss: 0.7999
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch234_loss0.7998532354831696.pypots
2024-05-22 16:42:28 [INFO]: Epoch 235 - training loss: 0.7556, validation loss: 0.8005
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch235_loss0.8005428910255432.pypots
2024-05-22 16:42:28 [INFO]: Epoch 236 - training loss: 0.7462, validation loss: 0.7975
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch236_loss0.7974686324596405.pypots
2024-05-22 16:42:28 [INFO]: Epoch 237 - training loss: 0.7588, validation loss: 0.7998
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch237_loss0.7998247742652893.pypots
2024-05-22 16:42:28 [INFO]: Epoch 238 - training loss: 0.7779, validation loss: 0.7965
2024-05-22 16:42:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch238_loss0.796498641371727.pypots
2024-05-22 16:42:29 [INFO]: Epoch 239 - training loss: 0.7413, validation loss: 0.7982
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch239_loss0.7981675118207932.pypots
2024-05-22 16:42:29 [INFO]: Epoch 240 - training loss: 0.7391, validation loss: 0.7962
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch240_loss0.7961657494306564.pypots
2024-05-22 16:42:29 [INFO]: Epoch 241 - training loss: 0.8036, validation loss: 0.7941
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch241_loss0.7941299974918365.pypots
2024-05-22 16:42:29 [INFO]: Epoch 242 - training loss: 0.7726, validation loss: 0.7939
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch242_loss0.7938829511404037.pypots
2024-05-22 16:42:29 [INFO]: Epoch 243 - training loss: 0.7527, validation loss: 0.7962
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch243_loss0.7962106764316559.pypots
2024-05-22 16:42:29 [INFO]: Epoch 244 - training loss: 0.7514, validation loss: 0.7950
2024-05-22 16:42:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch244_loss0.7949769794940948.pypots
2024-05-22 16:42:30 [INFO]: Epoch 245 - training loss: 0.7598, validation loss: 0.7990
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch245_loss0.798990324139595.pypots
2024-05-22 16:42:30 [INFO]: Epoch 246 - training loss: 0.7645, validation loss: 0.7964
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch246_loss0.796376034617424.pypots
2024-05-22 16:42:30 [INFO]: Epoch 247 - training loss: 0.7405, validation loss: 0.7952
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch247_loss0.7951686680316925.pypots
2024-05-22 16:42:30 [INFO]: Epoch 248 - training loss: 0.7580, validation loss: 0.7983
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch248_loss0.7982657849788666.pypots
2024-05-22 16:42:30 [INFO]: Epoch 249 - training loss: 0.7356, validation loss: 0.7954
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch249_loss0.7953901290893555.pypots
2024-05-22 16:42:30 [INFO]: Epoch 250 - training loss: 0.7612, validation loss: 0.7922
2024-05-22 16:42:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch250_loss0.7922497391700745.pypots
2024-05-22 16:42:31 [INFO]: Epoch 251 - training loss: 0.7529, validation loss: 0.7955
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch251_loss0.7955262213945389.pypots
2024-05-22 16:42:31 [INFO]: Epoch 252 - training loss: 0.7404, validation loss: 0.7933
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch252_loss0.7933022379875183.pypots
2024-05-22 16:42:31 [INFO]: Epoch 253 - training loss: 0.7524, validation loss: 0.7942
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch253_loss0.7941572964191437.pypots
2024-05-22 16:42:31 [INFO]: Epoch 254 - training loss: 0.7682, validation loss: 0.7962
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch254_loss0.7961687296628952.pypots
2024-05-22 16:42:31 [INFO]: Epoch 255 - training loss: 0.7589, validation loss: 0.7928
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch255_loss0.7928045839071274.pypots
2024-05-22 16:42:31 [INFO]: Epoch 256 - training loss: 0.7332, validation loss: 0.7959
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch256_loss0.7958763539791107.pypots
2024-05-22 16:42:31 [INFO]: Epoch 257 - training loss: 0.7672, validation loss: 0.7939
2024-05-22 16:42:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch257_loss0.7939348071813583.pypots
2024-05-22 16:42:32 [INFO]: Epoch 258 - training loss: 0.7676, validation loss: 0.7942
2024-05-22 16:42:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch258_loss0.7941654026508331.pypots
2024-05-22 16:42:32 [INFO]: Epoch 259 - training loss: 0.7476, validation loss: 0.7939
2024-05-22 16:42:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch259_loss0.7938560098409653.pypots
2024-05-22 16:42:32 [INFO]: Epoch 260 - training loss: 0.7517, validation loss: 0.7943
2024-05-22 16:42:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN_epoch260_loss0.7943316102027893.pypots
2024-05-22 16:42:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:42:32 [INFO]: Finished training. The best model is from epoch#250.
2024-05-22 16:42:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/20240522_T164146/MRNN.pypots
2024-05-22 16:42:32 [INFO]: MRNN on ETTm1: MAE=0.5709, MSE=0.9506
2024-05-22 16:42:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-22 16:42:32 [INFO]: Using the given device: cpu
2024-05-22 16:42:32 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 16:42:32 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-22 16:42:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-22 16:42:32 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 16:42:32 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-22 16:42:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-22 16:42:32 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 16:42:32 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-22 16:42:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-22 16:42:32 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 16:42:33 [INFO]: Using the given device: cuda:0
2024-05-22 16:42:33 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/SAITS_ettm1/20240522_T164233
2024-05-22 16:42:33 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/SAITS_ettm1/20240522_T164233/tensorboard
2024-05-22 16:42:33 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 16:42:33 [INFO]: Epoch 001 - training loss: 1.1418, validation loss: 0.2789
2024-05-22 16:42:34 [INFO]: Epoch 002 - training loss: 0.8500, validation loss: 0.1327
2024-05-22 16:42:34 [INFO]: Epoch 003 - training loss: 0.7607, validation loss: 0.1129
2024-05-22 16:42:35 [INFO]: Epoch 004 - training loss: 0.6997, validation loss: 0.0792
2024-05-22 16:42:35 [INFO]: Epoch 005 - training loss: 0.6727, validation loss: 0.0763
2024-05-22 16:42:36 [INFO]: Epoch 006 - training loss: 0.6589, validation loss: 0.0688
2024-05-22 16:42:36 [INFO]: Epoch 007 - training loss: 0.6384, validation loss: 0.0764
2024-05-22 16:42:37 [INFO]: Epoch 008 - training loss: 0.6113, validation loss: 0.0818
2024-05-22 16:42:37 [INFO]: Epoch 009 - training loss: 0.5892, validation loss: 0.0599
2024-05-22 16:42:38 [INFO]: Epoch 010 - training loss: 0.5733, validation loss: 0.0638
2024-05-22 16:42:38 [INFO]: Epoch 011 - training loss: 0.5675, validation loss: 0.0490
2024-05-22 16:42:39 [INFO]: Epoch 012 - training loss: 0.5655, validation loss: 0.0608
2024-05-22 16:42:39 [INFO]: Epoch 013 - training loss: 0.5466, validation loss: 0.0560
2024-05-22 16:42:40 [INFO]: Epoch 014 - training loss: 0.5375, validation loss: 0.0602
2024-05-22 16:42:40 [INFO]: Epoch 015 - training loss: 0.5418, validation loss: 0.0483
2024-05-22 16:42:41 [INFO]: Epoch 016 - training loss: 0.5231, validation loss: 0.0631
2024-05-22 16:42:41 [INFO]: Epoch 017 - training loss: 0.5183, validation loss: 0.0574
2024-05-22 16:42:42 [INFO]: Epoch 018 - training loss: 0.5128, validation loss: 0.0503
2024-05-22 16:42:42 [INFO]: Epoch 019 - training loss: 0.5049, validation loss: 0.0459
2024-05-22 16:42:43 [INFO]: Epoch 020 - training loss: 0.4916, validation loss: 0.0531
2024-05-22 16:42:43 [INFO]: Epoch 021 - training loss: 0.4884, validation loss: 0.0440
2024-05-22 16:42:44 [INFO]: Epoch 022 - training loss: 0.4827, validation loss: 0.0481
2024-05-22 16:42:44 [INFO]: Epoch 023 - training loss: 0.4945, validation loss: 0.0483
2024-05-22 16:42:45 [INFO]: Epoch 024 - training loss: 0.4769, validation loss: 0.0687
2024-05-22 16:42:45 [INFO]: Epoch 025 - training loss: 0.4726, validation loss: 0.0524
2024-05-22 16:42:46 [INFO]: Epoch 026 - training loss: 0.4844, validation loss: 0.0388
2024-05-22 16:42:46 [INFO]: Epoch 027 - training loss: 0.4573, validation loss: 0.0444
2024-05-22 16:42:47 [INFO]: Epoch 028 - training loss: 0.4631, validation loss: 0.0518
2024-05-22 16:42:47 [INFO]: Epoch 029 - training loss: 0.4462, validation loss: 0.0356
2024-05-22 16:42:48 [INFO]: Epoch 030 - training loss: 0.4560, validation loss: 0.0330
2024-05-22 16:42:48 [INFO]: Epoch 031 - training loss: 0.4416, validation loss: 0.0439
2024-05-22 16:42:49 [INFO]: Epoch 032 - training loss: 0.4360, validation loss: 0.0374
2024-05-22 16:42:49 [INFO]: Epoch 033 - training loss: 0.4310, validation loss: 0.0460
2024-05-22 16:42:49 [INFO]: Epoch 034 - training loss: 0.4313, validation loss: 0.0397
2024-05-22 16:42:50 [INFO]: Epoch 035 - training loss: 0.4247, validation loss: 0.0347
2024-05-22 16:42:50 [INFO]: Epoch 036 - training loss: 0.4131, validation loss: 0.0533
2024-05-22 16:42:51 [INFO]: Epoch 037 - training loss: 0.3977, validation loss: 0.0420
2024-05-22 16:42:51 [INFO]: Epoch 038 - training loss: 0.3878, validation loss: 0.0373
2024-05-22 16:42:52 [INFO]: Epoch 039 - training loss: 0.3886, validation loss: 0.0404
2024-05-22 16:42:52 [INFO]: Epoch 040 - training loss: 0.3748, validation loss: 0.0382
2024-05-22 16:42:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:42:52 [INFO]: Finished training. The best model is from epoch#30.
2024-05-22 16:42:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/SAITS_ettm1/20240522_T164233/SAITS.pypots
2024-05-22 16:42:53 [INFO]: SAITS on ETTm1: MAE=0.1508, MSE=0.0402
2024-05-22 16:42:53 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-22 16:42:53 [INFO]: Using the given device: cuda:0
2024-05-22 16:42:53 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/Transformer_ettm1/20240522_T164253
2024-05-22 16:42:53 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/Transformer_ettm1/20240522_T164253/tensorboard
2024-05-22 16:42:53 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 16:42:54 [INFO]: Epoch 001 - training loss: 1.1837, validation loss: 0.3544
2024-05-22 16:42:54 [INFO]: Epoch 002 - training loss: 0.7484, validation loss: 0.1636
2024-05-22 16:42:54 [INFO]: Epoch 003 - training loss: 0.6169, validation loss: 0.1237
2024-05-22 16:42:54 [INFO]: Epoch 004 - training loss: 0.5451, validation loss: 0.0971
2024-05-22 16:42:55 [INFO]: Epoch 005 - training loss: 0.5009, validation loss: 0.0766
2024-05-22 16:42:55 [INFO]: Epoch 006 - training loss: 0.4743, validation loss: 0.0713
2024-05-22 16:42:55 [INFO]: Epoch 007 - training loss: 0.4569, validation loss: 0.0717
2024-05-22 16:42:55 [INFO]: Epoch 008 - training loss: 0.4309, validation loss: 0.0630
2024-05-22 16:42:55 [INFO]: Epoch 009 - training loss: 0.4098, validation loss: 0.0538
2024-05-22 16:42:56 [INFO]: Epoch 010 - training loss: 0.3980, validation loss: 0.0659
2024-05-22 16:42:56 [INFO]: Epoch 011 - training loss: 0.3890, validation loss: 0.0519
2024-05-22 16:42:56 [INFO]: Epoch 012 - training loss: 0.3797, validation loss: 0.0509
2024-05-22 16:42:56 [INFO]: Epoch 013 - training loss: 0.3738, validation loss: 0.0584
2024-05-22 16:42:56 [INFO]: Epoch 014 - training loss: 0.3631, validation loss: 0.0496
2024-05-22 16:42:57 [INFO]: Epoch 015 - training loss: 0.3523, validation loss: 0.0472
2024-05-22 16:42:57 [INFO]: Epoch 016 - training loss: 0.3566, validation loss: 0.0426
2024-05-22 16:42:57 [INFO]: Epoch 017 - training loss: 0.3408, validation loss: 0.0418
2024-05-22 16:42:57 [INFO]: Epoch 018 - training loss: 0.3332, validation loss: 0.0428
2024-05-22 16:42:57 [INFO]: Epoch 019 - training loss: 0.3294, validation loss: 0.0377
2024-05-22 16:42:58 [INFO]: Epoch 020 - training loss: 0.3216, validation loss: 0.0397
2024-05-22 16:42:58 [INFO]: Epoch 021 - training loss: 0.3211, validation loss: 0.0361
2024-05-22 16:42:58 [INFO]: Epoch 022 - training loss: 0.3164, validation loss: 0.0330
2024-05-22 16:42:58 [INFO]: Epoch 023 - training loss: 0.3157, validation loss: 0.0429
2024-05-22 16:42:58 [INFO]: Epoch 024 - training loss: 0.3127, validation loss: 0.0395
2024-05-22 16:42:59 [INFO]: Epoch 025 - training loss: 0.3055, validation loss: 0.0352
2024-05-22 16:42:59 [INFO]: Epoch 026 - training loss: 0.3041, validation loss: 0.0327
2024-05-22 16:42:59 [INFO]: Epoch 027 - training loss: 0.3009, validation loss: 0.0347
2024-05-22 16:42:59 [INFO]: Epoch 028 - training loss: 0.2990, validation loss: 0.0361
2024-05-22 16:42:59 [INFO]: Epoch 029 - training loss: 0.2934, validation loss: 0.0320
2024-05-22 16:43:00 [INFO]: Epoch 030 - training loss: 0.2872, validation loss: 0.0328
2024-05-22 16:43:00 [INFO]: Epoch 031 - training loss: 0.2861, validation loss: 0.0321
2024-05-22 16:43:00 [INFO]: Epoch 032 - training loss: 0.2798, validation loss: 0.0286
2024-05-22 16:43:00 [INFO]: Epoch 033 - training loss: 0.2843, validation loss: 0.0305
2024-05-22 16:43:00 [INFO]: Epoch 034 - training loss: 0.2783, validation loss: 0.0330
2024-05-22 16:43:01 [INFO]: Epoch 035 - training loss: 0.2790, validation loss: 0.0315
2024-05-22 16:43:01 [INFO]: Epoch 036 - training loss: 0.2889, validation loss: 0.0291
2024-05-22 16:43:01 [INFO]: Epoch 037 - training loss: 0.2702, validation loss: 0.0284
2024-05-22 16:43:01 [INFO]: Epoch 038 - training loss: 0.2655, validation loss: 0.0316
2024-05-22 16:43:01 [INFO]: Epoch 039 - training loss: 0.2727, validation loss: 0.0263
2024-05-22 16:43:02 [INFO]: Epoch 040 - training loss: 0.2609, validation loss: 0.0275
2024-05-22 16:43:02 [INFO]: Epoch 041 - training loss: 0.2574, validation loss: 0.0276
2024-05-22 16:43:02 [INFO]: Epoch 042 - training loss: 0.2555, validation loss: 0.0254
2024-05-22 16:43:02 [INFO]: Epoch 043 - training loss: 0.2539, validation loss: 0.0296
2024-05-22 16:43:02 [INFO]: Epoch 044 - training loss: 0.2554, validation loss: 0.0243
2024-05-22 16:43:03 [INFO]: Epoch 045 - training loss: 0.2482, validation loss: 0.0245
2024-05-22 16:43:03 [INFO]: Epoch 046 - training loss: 0.2453, validation loss: 0.0306
2024-05-22 16:43:03 [INFO]: Epoch 047 - training loss: 0.2510, validation loss: 0.0276
2024-05-22 16:43:03 [INFO]: Epoch 048 - training loss: 0.2505, validation loss: 0.0235
2024-05-22 16:43:03 [INFO]: Epoch 049 - training loss: 0.2478, validation loss: 0.0267
2024-05-22 16:43:04 [INFO]: Epoch 050 - training loss: 0.2470, validation loss: 0.0249
2024-05-22 16:43:04 [INFO]: Epoch 051 - training loss: 0.2393, validation loss: 0.0235
2024-05-22 16:43:04 [INFO]: Epoch 052 - training loss: 0.2353, validation loss: 0.0283
2024-05-22 16:43:04 [INFO]: Epoch 053 - training loss: 0.2381, validation loss: 0.0244
2024-05-22 16:43:04 [INFO]: Epoch 054 - training loss: 0.2330, validation loss: 0.0227
2024-05-22 16:43:05 [INFO]: Epoch 055 - training loss: 0.2297, validation loss: 0.0247
2024-05-22 16:43:05 [INFO]: Epoch 056 - training loss: 0.2299, validation loss: 0.0264
2024-05-22 16:43:05 [INFO]: Epoch 057 - training loss: 0.2316, validation loss: 0.0248
2024-05-22 16:43:05 [INFO]: Epoch 058 - training loss: 0.2290, validation loss: 0.0227
2024-05-22 16:43:06 [INFO]: Epoch 059 - training loss: 0.2265, validation loss: 0.0219
2024-05-22 16:43:06 [INFO]: Epoch 060 - training loss: 0.2285, validation loss: 0.0255
2024-05-22 16:43:06 [INFO]: Epoch 061 - training loss: 0.2277, validation loss: 0.0226
2024-05-22 16:43:06 [INFO]: Epoch 062 - training loss: 0.2245, validation loss: 0.0216
2024-05-22 16:43:06 [INFO]: Epoch 063 - training loss: 0.2259, validation loss: 0.0228
2024-05-22 16:43:07 [INFO]: Epoch 064 - training loss: 0.2271, validation loss: 0.0209
2024-05-22 16:43:07 [INFO]: Epoch 065 - training loss: 0.2266, validation loss: 0.0264
2024-05-22 16:43:07 [INFO]: Epoch 066 - training loss: 0.2241, validation loss: 0.0224
2024-05-22 16:43:07 [INFO]: Epoch 067 - training loss: 0.2188, validation loss: 0.0228
2024-05-22 16:43:07 [INFO]: Epoch 068 - training loss: 0.2159, validation loss: 0.0282
2024-05-22 16:43:08 [INFO]: Epoch 069 - training loss: 0.2232, validation loss: 0.0274
2024-05-22 16:43:08 [INFO]: Epoch 070 - training loss: 0.2312, validation loss: 0.0220
2024-05-22 16:43:08 [INFO]: Epoch 071 - training loss: 0.2163, validation loss: 0.0227
2024-05-22 16:43:08 [INFO]: Epoch 072 - training loss: 0.2112, validation loss: 0.0223
2024-05-22 16:43:08 [INFO]: Epoch 073 - training loss: 0.2166, validation loss: 0.0250
2024-05-22 16:43:09 [INFO]: Epoch 074 - training loss: 0.2242, validation loss: 0.0220
2024-05-22 16:43:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:43:09 [INFO]: Finished training. The best model is from epoch#64.
2024-05-22 16:43:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/Transformer_ettm1/20240522_T164253/Transformer.pypots
2024-05-22 16:43:10 [INFO]: Transformer on ETTm1: MAE=0.1425, MSE=0.0403
2024-05-22 16:43:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-22 16:43:10 [INFO]: Using the given device: cuda:0
2024-05-22 16:43:10 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_ettm1/20240522_T164310
2024-05-22 16:43:10 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_ettm1/20240522_T164310/tensorboard
2024-05-22 16:43:10 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 16:43:10 [INFO]: Epoch 001 - training loss: 0.1599, validation loss: 0.0518
2024-05-22 16:43:11 [INFO]: Epoch 002 - training loss: 0.0709, validation loss: 0.0437
2024-05-22 16:43:11 [INFO]: Epoch 003 - training loss: 0.0575, validation loss: 0.0382
2024-05-22 16:43:11 [INFO]: Epoch 004 - training loss: 0.0513, validation loss: 0.0326
2024-05-22 16:43:11 [INFO]: Epoch 005 - training loss: 0.0487, validation loss: 0.0344
2024-05-22 16:43:11 [INFO]: Epoch 006 - training loss: 0.0472, validation loss: 0.0336
2024-05-22 16:43:12 [INFO]: Epoch 007 - training loss: 0.0497, validation loss: 0.0312
2024-05-22 16:43:12 [INFO]: Epoch 008 - training loss: 0.0479, validation loss: 0.0332
2024-05-22 16:43:12 [INFO]: Epoch 009 - training loss: 0.0473, validation loss: 0.0301
2024-05-22 16:43:12 [INFO]: Epoch 010 - training loss: 0.0490, validation loss: 0.0300
2024-05-22 16:43:12 [INFO]: Epoch 011 - training loss: 0.0500, validation loss: 0.0322
2024-05-22 16:43:12 [INFO]: Epoch 012 - training loss: 0.0481, validation loss: 0.0355
2024-05-22 16:43:13 [INFO]: Epoch 013 - training loss: 0.0490, validation loss: 0.0335
2024-05-22 16:43:13 [INFO]: Epoch 014 - training loss: 0.0446, validation loss: 0.0311
2024-05-22 16:43:13 [INFO]: Epoch 015 - training loss: 0.0439, validation loss: 0.0295
2024-05-22 16:43:13 [INFO]: Epoch 016 - training loss: 0.0425, validation loss: 0.0289
2024-05-22 16:43:13 [INFO]: Epoch 017 - training loss: 0.0416, validation loss: 0.0284
2024-05-22 16:43:14 [INFO]: Epoch 018 - training loss: 0.0430, validation loss: 0.0291
2024-05-22 16:43:14 [INFO]: Epoch 019 - training loss: 0.0447, validation loss: 0.0295
2024-05-22 16:43:14 [INFO]: Epoch 020 - training loss: 0.0426, validation loss: 0.0285
2024-05-22 16:43:14 [INFO]: Epoch 021 - training loss: 0.0415, validation loss: 0.0270
2024-05-22 16:43:14 [INFO]: Epoch 022 - training loss: 0.0400, validation loss: 0.0275
2024-05-22 16:43:15 [INFO]: Epoch 023 - training loss: 0.0407, validation loss: 0.0276
2024-05-22 16:43:15 [INFO]: Epoch 024 - training loss: 0.0408, validation loss: 0.0273
2024-05-22 16:43:15 [INFO]: Epoch 025 - training loss: 0.0379, validation loss: 0.0262
2024-05-22 16:43:15 [INFO]: Epoch 026 - training loss: 0.0400, validation loss: 0.0261
2024-05-22 16:43:15 [INFO]: Epoch 027 - training loss: 0.0389, validation loss: 0.0259
2024-05-22 16:43:16 [INFO]: Epoch 028 - training loss: 0.0388, validation loss: 0.0254
2024-05-22 16:43:16 [INFO]: Epoch 029 - training loss: 0.0376, validation loss: 0.0257
2024-05-22 16:43:16 [INFO]: Epoch 030 - training loss: 0.0384, validation loss: 0.0280
2024-05-22 16:43:16 [INFO]: Epoch 031 - training loss: 0.0394, validation loss: 0.0269
2024-05-22 16:43:16 [INFO]: Epoch 032 - training loss: 0.0396, validation loss: 0.0272
2024-05-22 16:43:17 [INFO]: Epoch 033 - training loss: 0.0392, validation loss: 0.0259
2024-05-22 16:43:17 [INFO]: Epoch 034 - training loss: 0.0392, validation loss: 0.0267
2024-05-22 16:43:17 [INFO]: Epoch 035 - training loss: 0.0387, validation loss: 0.0259
2024-05-22 16:43:17 [INFO]: Epoch 036 - training loss: 0.0385, validation loss: 0.0262
2024-05-22 16:43:17 [INFO]: Epoch 037 - training loss: 0.0374, validation loss: 0.0252
2024-05-22 16:43:18 [INFO]: Epoch 038 - training loss: 0.0370, validation loss: 0.0266
2024-05-22 16:43:18 [INFO]: Epoch 039 - training loss: 0.0410, validation loss: 0.0259
2024-05-22 16:43:18 [INFO]: Epoch 040 - training loss: 0.0395, validation loss: 0.0252
2024-05-22 16:43:18 [INFO]: Epoch 041 - training loss: 0.0396, validation loss: 0.0263
2024-05-22 16:43:18 [INFO]: Epoch 042 - training loss: 0.0387, validation loss: 0.0261
2024-05-22 16:43:19 [INFO]: Epoch 043 - training loss: 0.0415, validation loss: 0.0252
2024-05-22 16:43:19 [INFO]: Epoch 044 - training loss: 0.0374, validation loss: 0.0261
2024-05-22 16:43:19 [INFO]: Epoch 045 - training loss: 0.0373, validation loss: 0.0258
2024-05-22 16:43:19 [INFO]: Epoch 046 - training loss: 0.0390, validation loss: 0.0246
2024-05-22 16:43:19 [INFO]: Epoch 047 - training loss: 0.0386, validation loss: 0.0255
2024-05-22 16:43:19 [INFO]: Epoch 048 - training loss: 0.0359, validation loss: 0.0252
2024-05-22 16:43:20 [INFO]: Epoch 049 - training loss: 0.0376, validation loss: 0.0237
2024-05-22 16:43:20 [INFO]: Epoch 050 - training loss: 0.0370, validation loss: 0.0242
2024-05-22 16:43:20 [INFO]: Epoch 051 - training loss: 0.0408, validation loss: 0.0288
2024-05-22 16:43:20 [INFO]: Epoch 052 - training loss: 0.0506, validation loss: 0.0274
2024-05-22 16:43:20 [INFO]: Epoch 053 - training loss: 0.0376, validation loss: 0.0261
2024-05-22 16:43:21 [INFO]: Epoch 054 - training loss: 0.0370, validation loss: 0.0250
2024-05-22 16:43:21 [INFO]: Epoch 055 - training loss: 0.0379, validation loss: 0.0257
2024-05-22 16:43:21 [INFO]: Epoch 056 - training loss: 0.0353, validation loss: 0.0242
2024-05-22 16:43:21 [INFO]: Epoch 057 - training loss: 0.0345, validation loss: 0.0235
2024-05-22 16:43:21 [INFO]: Epoch 058 - training loss: 0.0359, validation loss: 0.0235
2024-05-22 16:43:22 [INFO]: Epoch 059 - training loss: 0.0350, validation loss: 0.0283
2024-05-22 16:43:22 [INFO]: Epoch 060 - training loss: 0.0354, validation loss: 0.0242
2024-05-22 16:43:22 [INFO]: Epoch 061 - training loss: 0.0366, validation loss: 0.0252
2024-05-22 16:43:22 [INFO]: Epoch 062 - training loss: 0.0386, validation loss: 0.0253
2024-05-22 16:43:22 [INFO]: Epoch 063 - training loss: 0.0365, validation loss: 0.0255
2024-05-22 16:43:23 [INFO]: Epoch 064 - training loss: 0.0329, validation loss: 0.0233
2024-05-22 16:43:23 [INFO]: Epoch 065 - training loss: 0.0326, validation loss: 0.0217
2024-05-22 16:43:23 [INFO]: Epoch 066 - training loss: 0.0331, validation loss: 0.0234
2024-05-22 16:43:23 [INFO]: Epoch 067 - training loss: 0.0343, validation loss: 0.0235
2024-05-22 16:43:23 [INFO]: Epoch 068 - training loss: 0.0388, validation loss: 0.0249
2024-05-22 16:43:24 [INFO]: Epoch 069 - training loss: 0.0372, validation loss: 0.0246
2024-05-22 16:43:24 [INFO]: Epoch 070 - training loss: 0.0334, validation loss: 0.0230
2024-05-22 16:43:24 [INFO]: Epoch 071 - training loss: 0.0326, validation loss: 0.0220
2024-05-22 16:43:24 [INFO]: Epoch 072 - training loss: 0.0319, validation loss: 0.0225
2024-05-22 16:43:24 [INFO]: Epoch 073 - training loss: 0.0339, validation loss: 0.0232
2024-05-22 16:43:24 [INFO]: Epoch 074 - training loss: 0.0341, validation loss: 0.0223
2024-05-22 16:43:25 [INFO]: Epoch 075 - training loss: 0.0324, validation loss: 0.0230
2024-05-22 16:43:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:43:25 [INFO]: Finished training. The best model is from epoch#65.
2024-05-22 16:43:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/TimesNet_ettm1/20240522_T164310/TimesNet.pypots
2024-05-22 16:43:26 [INFO]: TimesNet on ETTm1: MAE=0.1107, MSE=0.0267
2024-05-22 16:43:26 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-22 16:43:26 [INFO]: Using the given device: cuda:0
2024-05-22 16:43:26 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326
2024-05-22 16:43:26 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/tensorboard
2024-05-22 16:43:26 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 16:43:28 [INFO]: Epoch 001 - training loss: 0.7149, validation loss: 0.4446
2024-05-22 16:43:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch1_loss0.44459544867277145.pypots
2024-05-22 16:43:30 [INFO]: Epoch 002 - training loss: 0.4087, validation loss: 0.3771
2024-05-22 16:43:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch2_loss0.37708255648612976.pypots
2024-05-22 16:43:33 [INFO]: Epoch 003 - training loss: 0.3499, validation loss: 0.3495
2024-05-22 16:43:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch3_loss0.34946247190237045.pypots
2024-05-22 16:43:35 [INFO]: Epoch 004 - training loss: 0.3520, validation loss: 0.3255
2024-05-22 16:43:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch4_loss0.3254978507757187.pypots
2024-05-22 16:43:37 [INFO]: Epoch 005 - training loss: 0.3199, validation loss: 0.3367
2024-05-22 16:43:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch5_loss0.3367287144064903.pypots
2024-05-22 16:43:39 [INFO]: Epoch 006 - training loss: 0.2815, validation loss: 0.3121
2024-05-22 16:43:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch6_loss0.312095582485199.pypots
2024-05-22 16:43:41 [INFO]: Epoch 007 - training loss: 0.2589, validation loss: 0.2841
2024-05-22 16:43:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch7_loss0.28413141518831253.pypots
2024-05-22 16:43:43 [INFO]: Epoch 008 - training loss: 0.2852, validation loss: 0.2808
2024-05-22 16:43:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch8_loss0.280785396695137.pypots
2024-05-22 16:43:45 [INFO]: Epoch 009 - training loss: 0.2813, validation loss: 0.2673
2024-05-22 16:43:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch9_loss0.26731620728969574.pypots
2024-05-22 16:43:47 [INFO]: Epoch 010 - training loss: 0.2607, validation loss: 0.2613
2024-05-22 16:43:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch10_loss0.2613457962870598.pypots
2024-05-22 16:43:49 [INFO]: Epoch 011 - training loss: 0.2341, validation loss: 0.2569
2024-05-22 16:43:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch11_loss0.2568765878677368.pypots
2024-05-22 16:43:52 [INFO]: Epoch 012 - training loss: 0.2685, validation loss: 0.2599
2024-05-22 16:43:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch12_loss0.25985299050807953.pypots
2024-05-22 16:43:54 [INFO]: Epoch 013 - training loss: 0.2491, validation loss: 0.2463
2024-05-22 16:43:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch13_loss0.24625633656978607.pypots
2024-05-22 16:43:56 [INFO]: Epoch 014 - training loss: 0.2592, validation loss: 0.2430
2024-05-22 16:43:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch14_loss0.24303903803229332.pypots
2024-05-22 16:43:58 [INFO]: Epoch 015 - training loss: 0.2288, validation loss: 0.2506
2024-05-22 16:43:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch15_loss0.25055836886167526.pypots
2024-05-22 16:44:00 [INFO]: Epoch 016 - training loss: 0.2876, validation loss: 0.2367
2024-05-22 16:44:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch16_loss0.23669365048408508.pypots
2024-05-22 16:44:02 [INFO]: Epoch 017 - training loss: 0.2165, validation loss: 0.2280
2024-05-22 16:44:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch17_loss0.22798863425850868.pypots
2024-05-22 16:44:04 [INFO]: Epoch 018 - training loss: 0.2162, validation loss: 0.2186
2024-05-22 16:44:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch18_loss0.21862608566880226.pypots
2024-05-22 16:44:07 [INFO]: Epoch 019 - training loss: 0.2240, validation loss: 0.2272
2024-05-22 16:44:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch19_loss0.22724447026848793.pypots
2024-05-22 16:44:09 [INFO]: Epoch 020 - training loss: 0.2224, validation loss: 0.2270
2024-05-22 16:44:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch20_loss0.22698292136192322.pypots
2024-05-22 16:44:11 [INFO]: Epoch 021 - training loss: 0.2780, validation loss: 0.2257
2024-05-22 16:44:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch21_loss0.225694440305233.pypots
2024-05-22 16:44:13 [INFO]: Epoch 022 - training loss: 0.2406, validation loss: 0.2111
2024-05-22 16:44:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch22_loss0.21109465137124062.pypots
2024-05-22 16:44:15 [INFO]: Epoch 023 - training loss: 0.2238, validation loss: 0.2145
2024-05-22 16:44:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch23_loss0.21445436030626297.pypots
2024-05-22 16:44:17 [INFO]: Epoch 024 - training loss: 0.2336, validation loss: 0.2063
2024-05-22 16:44:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch24_loss0.20625269412994385.pypots
2024-05-22 16:44:19 [INFO]: Epoch 025 - training loss: 0.2058, validation loss: 0.1967
2024-05-22 16:44:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch25_loss0.1966666504740715.pypots
2024-05-22 16:44:21 [INFO]: Epoch 026 - training loss: 0.2934, validation loss: 0.1911
2024-05-22 16:44:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch26_loss0.19112517684698105.pypots
2024-05-22 16:44:23 [INFO]: Epoch 027 - training loss: 0.2434, validation loss: 0.1967
2024-05-22 16:44:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch27_loss0.19667790830135345.pypots
2024-05-22 16:44:25 [INFO]: Epoch 028 - training loss: 0.1981, validation loss: 0.1913
2024-05-22 16:44:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch28_loss0.19129489734768867.pypots
2024-05-22 16:44:27 [INFO]: Epoch 029 - training loss: 0.2027, validation loss: 0.1994
2024-05-22 16:44:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch29_loss0.1994297057390213.pypots
2024-05-22 16:44:29 [INFO]: Epoch 030 - training loss: 0.2015, validation loss: 0.1899
2024-05-22 16:44:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch30_loss0.18990619108080864.pypots
2024-05-22 16:44:31 [INFO]: Epoch 031 - training loss: 0.2010, validation loss: 0.1774
2024-05-22 16:44:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch31_loss0.17742551118135452.pypots
2024-05-22 16:44:33 [INFO]: Epoch 032 - training loss: 0.1833, validation loss: 0.1783
2024-05-22 16:44:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch32_loss0.1782970353960991.pypots
2024-05-22 16:44:35 [INFO]: Epoch 033 - training loss: 0.2177, validation loss: 0.1787
2024-05-22 16:44:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch33_loss0.17868702113628387.pypots
2024-05-22 16:44:37 [INFO]: Epoch 034 - training loss: 0.2082, validation loss: 0.1767
2024-05-22 16:44:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch34_loss0.17674676328897476.pypots
2024-05-22 16:44:39 [INFO]: Epoch 035 - training loss: 0.2078, validation loss: 0.1722
2024-05-22 16:44:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch35_loss0.1721646636724472.pypots
2024-05-22 16:44:42 [INFO]: Epoch 036 - training loss: 0.1930, validation loss: 0.1703
2024-05-22 16:44:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch36_loss0.17034897208213806.pypots
2024-05-22 16:44:44 [INFO]: Epoch 037 - training loss: 0.1797, validation loss: 0.1657
2024-05-22 16:44:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch37_loss0.16570468246936798.pypots
2024-05-22 16:44:46 [INFO]: Epoch 038 - training loss: 0.1914, validation loss: 0.1592
2024-05-22 16:44:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch38_loss0.159228827804327.pypots
2024-05-22 16:44:48 [INFO]: Epoch 039 - training loss: 0.1750, validation loss: 0.1637
2024-05-22 16:44:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch39_loss0.16374025866389275.pypots
2024-05-22 16:44:50 [INFO]: Epoch 040 - training loss: 0.1809, validation loss: 0.1623
2024-05-22 16:44:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch40_loss0.16230129078030586.pypots
2024-05-22 16:44:52 [INFO]: Epoch 041 - training loss: 0.1703, validation loss: 0.1591
2024-05-22 16:44:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch41_loss0.15912137925624847.pypots
2024-05-22 16:44:54 [INFO]: Epoch 042 - training loss: 0.1563, validation loss: 0.1560
2024-05-22 16:44:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch42_loss0.15599561855196953.pypots
2024-05-22 16:44:56 [INFO]: Epoch 043 - training loss: 0.1724, validation loss: 0.1907
2024-05-22 16:44:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch43_loss0.1906880959868431.pypots
2024-05-22 16:44:58 [INFO]: Epoch 044 - training loss: 0.1908, validation loss: 0.1745
2024-05-22 16:44:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch44_loss0.17452823743224144.pypots
2024-05-22 16:45:00 [INFO]: Epoch 045 - training loss: 0.1643, validation loss: 0.1565
2024-05-22 16:45:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch45_loss0.15645280852913857.pypots
2024-05-22 16:45:02 [INFO]: Epoch 046 - training loss: 0.1496, validation loss: 0.1614
2024-05-22 16:45:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch46_loss0.1613970510661602.pypots
2024-05-22 16:45:04 [INFO]: Epoch 047 - training loss: 0.1361, validation loss: 0.1520
2024-05-22 16:45:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch47_loss0.15196257457137108.pypots
2024-05-22 16:45:06 [INFO]: Epoch 048 - training loss: 0.1661, validation loss: 0.1475
2024-05-22 16:45:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch48_loss0.1475401259958744.pypots
2024-05-22 16:45:08 [INFO]: Epoch 049 - training loss: 0.1693, validation loss: 0.1437
2024-05-22 16:45:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch49_loss0.14371081814169884.pypots
2024-05-22 16:45:10 [INFO]: Epoch 050 - training loss: 0.1661, validation loss: 0.1542
2024-05-22 16:45:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch50_loss0.15423651784658432.pypots
2024-05-22 16:45:13 [INFO]: Epoch 051 - training loss: 0.1715, validation loss: 0.1581
2024-05-22 16:45:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch51_loss0.15811072289943695.pypots
2024-05-22 16:45:15 [INFO]: Epoch 052 - training loss: 0.2045, validation loss: 0.1652
2024-05-22 16:45:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch52_loss0.16521792486310005.pypots
2024-05-22 16:45:17 [INFO]: Epoch 053 - training loss: 0.1909, validation loss: 0.1506
2024-05-22 16:45:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch53_loss0.15062670782208443.pypots
2024-05-22 16:45:19 [INFO]: Epoch 054 - training loss: 0.1470, validation loss: 0.1409
2024-05-22 16:45:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch54_loss0.14092493057250977.pypots
2024-05-22 16:45:22 [INFO]: Epoch 055 - training loss: 0.1797, validation loss: 0.1398
2024-05-22 16:45:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch55_loss0.13980680331587791.pypots
2024-05-22 16:45:24 [INFO]: Epoch 056 - training loss: 0.1637, validation loss: 0.1406
2024-05-22 16:45:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch56_loss0.14058392122387886.pypots
2024-05-22 16:45:26 [INFO]: Epoch 057 - training loss: 0.1630, validation loss: 0.1372
2024-05-22 16:45:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch57_loss0.13718437775969505.pypots
2024-05-22 16:45:28 [INFO]: Epoch 058 - training loss: 0.1737, validation loss: 0.1518
2024-05-22 16:45:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch58_loss0.1517968513071537.pypots
2024-05-22 16:45:30 [INFO]: Epoch 059 - training loss: 0.1895, validation loss: 0.1762
2024-05-22 16:45:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch59_loss0.17619846388697624.pypots
2024-05-22 16:45:32 [INFO]: Epoch 060 - training loss: 0.1749, validation loss: 0.1651
2024-05-22 16:45:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch60_loss0.1651037149131298.pypots
2024-05-22 16:45:34 [INFO]: Epoch 061 - training loss: 0.1442, validation loss: 0.1526
2024-05-22 16:45:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch61_loss0.15255439653992653.pypots
2024-05-22 16:45:36 [INFO]: Epoch 062 - training loss: 0.1692, validation loss: 0.1520
2024-05-22 16:45:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch62_loss0.15197406336665154.pypots
2024-05-22 16:45:38 [INFO]: Epoch 063 - training loss: 0.1650, validation loss: 0.1437
2024-05-22 16:45:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch63_loss0.14366106316447258.pypots
2024-05-22 16:45:40 [INFO]: Epoch 064 - training loss: 0.1789, validation loss: 0.1477
2024-05-22 16:45:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch64_loss0.14766663312911987.pypots
2024-05-22 16:45:42 [INFO]: Epoch 065 - training loss: 0.1965, validation loss: 0.1492
2024-05-22 16:45:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch65_loss0.1491752788424492.pypots
2024-05-22 16:45:44 [INFO]: Epoch 066 - training loss: 0.1659, validation loss: 0.1400
2024-05-22 16:45:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch66_loss0.14004014059901237.pypots
2024-05-22 16:45:46 [INFO]: Epoch 067 - training loss: 0.1681, validation loss: 0.1432
2024-05-22 16:45:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI_epoch67_loss0.14315764605998993.pypots
2024-05-22 16:45:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:45:47 [INFO]: Finished training. The best model is from epoch#57.
2024-05-22 16:45:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/20240522_T164326/CSDI.pypots
2024-05-22 16:46:02 [INFO]: CSDI on ETTm1: MAE=0.2758, MSE=1.6166
2024-05-22 16:46:02 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-22 16:46:02 [INFO]: Using the given device: cuda:0
2024-05-22 16:46:02 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_ettm1/20240522_T164602
2024-05-22 16:46:02 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_ettm1/20240522_T164602/tensorboard
2024-05-22 16:46:02 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 16:46:02 [INFO]: Epoch 001 - training loss: 24047.8325, validation loss: 0.9156
2024-05-22 16:46:03 [INFO]: Epoch 002 - training loss: 21779.4923, validation loss: 0.9177
2024-05-22 16:46:03 [INFO]: Epoch 003 - training loss: 19625.7601, validation loss: 0.9154
2024-05-22 16:46:03 [INFO]: Epoch 004 - training loss: 17670.9957, validation loss: 0.9076
2024-05-22 16:46:03 [INFO]: Epoch 005 - training loss: 15727.1977, validation loss: 0.8719
2024-05-22 16:46:03 [INFO]: Epoch 006 - training loss: 14144.7687, validation loss: 0.8043
2024-05-22 16:46:03 [INFO]: Epoch 007 - training loss: 12987.1253, validation loss: 0.7092
2024-05-22 16:46:03 [INFO]: Epoch 008 - training loss: 12079.1875, validation loss: 0.6270
2024-05-22 16:46:03 [INFO]: Epoch 009 - training loss: 11470.3835, validation loss: 0.5541
2024-05-22 16:46:03 [INFO]: Epoch 010 - training loss: 11134.1113, validation loss: 0.5053
2024-05-22 16:46:04 [INFO]: Epoch 011 - training loss: 10766.7590, validation loss: 0.4909
2024-05-22 16:46:04 [INFO]: Epoch 012 - training loss: 10548.7069, validation loss: 0.4758
2024-05-22 16:46:04 [INFO]: Epoch 013 - training loss: 10304.8150, validation loss: 0.4562
2024-05-22 16:46:04 [INFO]: Epoch 014 - training loss: 10189.2211, validation loss: 0.4439
2024-05-22 16:46:04 [INFO]: Epoch 015 - training loss: 10070.9992, validation loss: 0.4204
2024-05-22 16:46:04 [INFO]: Epoch 016 - training loss: 9983.0897, validation loss: 0.4026
2024-05-22 16:46:04 [INFO]: Epoch 017 - training loss: 9939.0523, validation loss: 0.3752
2024-05-22 16:46:04 [INFO]: Epoch 018 - training loss: 9842.2921, validation loss: 0.3506
2024-05-22 16:46:04 [INFO]: Epoch 019 - training loss: 9805.0024, validation loss: 0.3348
2024-05-22 16:46:05 [INFO]: Epoch 020 - training loss: 9718.0877, validation loss: 0.3181
2024-05-22 16:46:05 [INFO]: Epoch 021 - training loss: 9718.9546, validation loss: 0.3049
2024-05-22 16:46:05 [INFO]: Epoch 022 - training loss: 9660.0592, validation loss: 0.2895
2024-05-22 16:46:05 [INFO]: Epoch 023 - training loss: 9628.0494, validation loss: 0.2765
2024-05-22 16:46:05 [INFO]: Epoch 024 - training loss: 9587.3149, validation loss: 0.2686
2024-05-22 16:46:05 [INFO]: Epoch 025 - training loss: 9557.4382, validation loss: 0.2627
2024-05-22 16:46:05 [INFO]: Epoch 026 - training loss: 9541.0497, validation loss: 0.2594
2024-05-22 16:46:05 [INFO]: Epoch 027 - training loss: 9539.9166, validation loss: 0.2478
2024-05-22 16:46:05 [INFO]: Epoch 028 - training loss: 9518.4355, validation loss: 0.2427
2024-05-22 16:46:06 [INFO]: Epoch 029 - training loss: 9486.5402, validation loss: 0.2350
2024-05-22 16:46:06 [INFO]: Epoch 030 - training loss: 9484.4067, validation loss: 0.2303
2024-05-22 16:46:06 [INFO]: Epoch 031 - training loss: 9467.9316, validation loss: 0.2266
2024-05-22 16:46:06 [INFO]: Epoch 032 - training loss: 9452.3908, validation loss: 0.2229
2024-05-22 16:46:06 [INFO]: Epoch 033 - training loss: 9449.0359, validation loss: 0.2203
2024-05-22 16:46:06 [INFO]: Epoch 034 - training loss: 9434.5844, validation loss: 0.2102
2024-05-22 16:46:06 [INFO]: Epoch 035 - training loss: 9426.4786, validation loss: 0.2071
2024-05-22 16:46:06 [INFO]: Epoch 036 - training loss: 9447.5164, validation loss: 0.2067
2024-05-22 16:46:06 [INFO]: Epoch 037 - training loss: 9414.7590, validation loss: 0.2015
2024-05-22 16:46:07 [INFO]: Epoch 038 - training loss: 9406.0554, validation loss: 0.1985
2024-05-22 16:46:07 [INFO]: Epoch 039 - training loss: 9420.5812, validation loss: 0.1930
2024-05-22 16:46:07 [INFO]: Epoch 040 - training loss: 9393.8496, validation loss: 0.1882
2024-05-22 16:46:07 [INFO]: Epoch 041 - training loss: 9389.5915, validation loss: 0.1866
2024-05-22 16:46:07 [INFO]: Epoch 042 - training loss: 9390.1241, validation loss: 0.1829
2024-05-22 16:46:07 [INFO]: Epoch 043 - training loss: 9377.9577, validation loss: 0.1822
2024-05-22 16:46:07 [INFO]: Epoch 044 - training loss: 9371.0402, validation loss: 0.1780
2024-05-22 16:46:07 [INFO]: Epoch 045 - training loss: 9372.3504, validation loss: 0.1763
2024-05-22 16:46:07 [INFO]: Epoch 046 - training loss: 9370.1862, validation loss: 0.1732
2024-05-22 16:46:07 [INFO]: Epoch 047 - training loss: 9368.0693, validation loss: 0.1736
2024-05-22 16:46:08 [INFO]: Epoch 048 - training loss: 9365.4556, validation loss: 0.1666
2024-05-22 16:46:08 [INFO]: Epoch 049 - training loss: 9356.8626, validation loss: 0.1662
2024-05-22 16:46:08 [INFO]: Epoch 050 - training loss: 9352.4114, validation loss: 0.1658
2024-05-22 16:46:08 [INFO]: Epoch 051 - training loss: 9349.7554, validation loss: 0.1617
2024-05-22 16:46:08 [INFO]: Epoch 052 - training loss: 9354.5317, validation loss: 0.1599
2024-05-22 16:46:08 [INFO]: Epoch 053 - training loss: 9344.6624, validation loss: 0.1560
2024-05-22 16:46:08 [INFO]: Epoch 054 - training loss: 9342.4762, validation loss: 0.1543
2024-05-22 16:46:08 [INFO]: Epoch 055 - training loss: 9340.9552, validation loss: 0.1541
2024-05-22 16:46:08 [INFO]: Epoch 056 - training loss: 9345.9623, validation loss: 0.1536
2024-05-22 16:46:09 [INFO]: Epoch 057 - training loss: 9338.6663, validation loss: 0.1497
2024-05-22 16:46:09 [INFO]: Epoch 058 - training loss: 9333.7751, validation loss: 0.1470
2024-05-22 16:46:09 [INFO]: Epoch 059 - training loss: 9342.5750, validation loss: 0.1481
2024-05-22 16:46:09 [INFO]: Epoch 060 - training loss: 9332.5304, validation loss: 0.1493
2024-05-22 16:46:09 [INFO]: Epoch 061 - training loss: 9331.1931, validation loss: 0.1456
2024-05-22 16:46:09 [INFO]: Epoch 062 - training loss: 9327.2739, validation loss: 0.1439
2024-05-22 16:46:09 [INFO]: Epoch 063 - training loss: 9326.5862, validation loss: 0.1420
2024-05-22 16:46:09 [INFO]: Epoch 064 - training loss: 9327.4570, validation loss: 0.1439
2024-05-22 16:46:09 [INFO]: Epoch 065 - training loss: 9328.5588, validation loss: 0.1395
2024-05-22 16:46:10 [INFO]: Epoch 066 - training loss: 9321.6241, validation loss: 0.1403
2024-05-22 16:46:10 [INFO]: Epoch 067 - training loss: 9318.4511, validation loss: 0.1409
2024-05-22 16:46:10 [INFO]: Epoch 068 - training loss: 9320.6647, validation loss: 0.1400
2024-05-22 16:46:10 [INFO]: Epoch 069 - training loss: 9317.9445, validation loss: 0.1373
2024-05-22 16:46:10 [INFO]: Epoch 070 - training loss: 9315.1118, validation loss: 0.1367
2024-05-22 16:46:10 [INFO]: Epoch 071 - training loss: 9314.9516, validation loss: 0.1343
2024-05-22 16:46:10 [INFO]: Epoch 072 - training loss: 9312.3422, validation loss: 0.1356
2024-05-22 16:46:10 [INFO]: Epoch 073 - training loss: 9318.8232, validation loss: 0.1324
2024-05-22 16:46:10 [INFO]: Epoch 074 - training loss: 9315.4604, validation loss: 0.1307
2024-05-22 16:46:11 [INFO]: Epoch 075 - training loss: 9320.5259, validation loss: 0.1318
2024-05-22 16:46:11 [INFO]: Epoch 076 - training loss: 9309.2028, validation loss: 0.1294
2024-05-22 16:46:11 [INFO]: Epoch 077 - training loss: 9311.6223, validation loss: 0.1301
2024-05-22 16:46:11 [INFO]: Epoch 078 - training loss: 9308.0996, validation loss: 0.1296
2024-05-22 16:46:11 [INFO]: Epoch 079 - training loss: 9307.6386, validation loss: 0.1290
2024-05-22 16:46:11 [INFO]: Epoch 080 - training loss: 9304.7589, validation loss: 0.1269
2024-05-22 16:46:11 [INFO]: Epoch 081 - training loss: 9304.9050, validation loss: 0.1260
2024-05-22 16:46:11 [INFO]: Epoch 082 - training loss: 9305.6764, validation loss: 0.1266
2024-05-22 16:46:11 [INFO]: Epoch 083 - training loss: 9305.4573, validation loss: 0.1240
2024-05-22 16:46:12 [INFO]: Epoch 084 - training loss: 9307.8478, validation loss: 0.1225
2024-05-22 16:46:12 [INFO]: Epoch 085 - training loss: 9303.1042, validation loss: 0.1229
2024-05-22 16:46:12 [INFO]: Epoch 086 - training loss: 9301.3918, validation loss: 0.1214
2024-05-22 16:46:12 [INFO]: Epoch 087 - training loss: 9300.5527, validation loss: 0.1215
2024-05-22 16:46:12 [INFO]: Epoch 088 - training loss: 9299.2490, validation loss: 0.1198
2024-05-22 16:46:12 [INFO]: Epoch 089 - training loss: 9298.9233, validation loss: 0.1203
2024-05-22 16:46:12 [INFO]: Epoch 090 - training loss: 9301.0295, validation loss: 0.1203
2024-05-22 16:46:12 [INFO]: Epoch 091 - training loss: 9299.6174, validation loss: 0.1188
2024-05-22 16:46:12 [INFO]: Epoch 092 - training loss: 9296.2773, validation loss: 0.1191
2024-05-22 16:46:12 [INFO]: Epoch 093 - training loss: 9296.1680, validation loss: 0.1185
2024-05-22 16:46:13 [INFO]: Epoch 094 - training loss: 9297.7043, validation loss: 0.1165
2024-05-22 16:46:13 [INFO]: Epoch 095 - training loss: 9295.0685, validation loss: 0.1182
2024-05-22 16:46:13 [INFO]: Epoch 096 - training loss: 9323.9286, validation loss: 0.1150
2024-05-22 16:46:13 [INFO]: Epoch 097 - training loss: 9298.0782, validation loss: 0.1157
2024-05-22 16:46:13 [INFO]: Epoch 098 - training loss: 9296.4520, validation loss: 0.1149
2024-05-22 16:46:13 [INFO]: Epoch 099 - training loss: 9293.1493, validation loss: 0.1156
2024-05-22 16:46:13 [INFO]: Epoch 100 - training loss: 9292.4587, validation loss: 0.1133
2024-05-22 16:46:13 [INFO]: Epoch 101 - training loss: 9292.0460, validation loss: 0.1129
2024-05-22 16:46:13 [INFO]: Epoch 102 - training loss: 9292.2087, validation loss: 0.1118
2024-05-22 16:46:14 [INFO]: Epoch 103 - training loss: 9293.9505, validation loss: 0.1123
2024-05-22 16:46:14 [INFO]: Epoch 104 - training loss: 9291.2737, validation loss: 0.1107
2024-05-22 16:46:14 [INFO]: Epoch 105 - training loss: 9290.5611, validation loss: 0.1112
2024-05-22 16:46:14 [INFO]: Epoch 106 - training loss: 9292.4407, validation loss: 0.1093
2024-05-22 16:46:14 [INFO]: Epoch 107 - training loss: 9290.9089, validation loss: 0.1089
2024-05-22 16:46:14 [INFO]: Epoch 108 - training loss: 9291.5709, validation loss: 0.1073
2024-05-22 16:46:14 [INFO]: Epoch 109 - training loss: 9291.0646, validation loss: 0.1086
2024-05-22 16:46:14 [INFO]: Epoch 110 - training loss: 9289.2219, validation loss: 0.1065
2024-05-22 16:46:14 [INFO]: Epoch 111 - training loss: 9289.6191, validation loss: 0.1063
2024-05-22 16:46:15 [INFO]: Epoch 112 - training loss: 9287.5995, validation loss: 0.1076
2024-05-22 16:46:15 [INFO]: Epoch 113 - training loss: 9290.4692, validation loss: 0.1043
2024-05-22 16:46:15 [INFO]: Epoch 114 - training loss: 9288.4462, validation loss: 0.1052
2024-05-22 16:46:15 [INFO]: Epoch 115 - training loss: 9288.6017, validation loss: 0.1022
2024-05-22 16:46:15 [INFO]: Epoch 116 - training loss: 9288.0637, validation loss: 0.1048
2024-05-22 16:46:15 [INFO]: Epoch 117 - training loss: 9287.5303, validation loss: 0.1032
2024-05-22 16:46:15 [INFO]: Epoch 118 - training loss: 9288.1661, validation loss: 0.1015
2024-05-22 16:46:15 [INFO]: Epoch 119 - training loss: 9290.0310, validation loss: 0.1025
2024-05-22 16:46:15 [INFO]: Epoch 120 - training loss: 9287.7047, validation loss: 0.1029
2024-05-22 16:46:16 [INFO]: Epoch 121 - training loss: 9287.6519, validation loss: 0.0994
2024-05-22 16:46:16 [INFO]: Epoch 122 - training loss: 9285.3464, validation loss: 0.0996
2024-05-22 16:46:16 [INFO]: Epoch 123 - training loss: 9285.6891, validation loss: 0.0998
2024-05-22 16:46:16 [INFO]: Epoch 124 - training loss: 9286.3620, validation loss: 0.0988
2024-05-22 16:46:16 [INFO]: Epoch 125 - training loss: 9285.4594, validation loss: 0.1004
2024-05-22 16:46:16 [INFO]: Epoch 126 - training loss: 9285.0142, validation loss: 0.0995
2024-05-22 16:46:16 [INFO]: Epoch 127 - training loss: 9284.8718, validation loss: 0.1005
2024-05-22 16:46:16 [INFO]: Epoch 128 - training loss: 9284.2073, validation loss: 0.0967
2024-05-22 16:46:16 [INFO]: Epoch 129 - training loss: 9285.0894, validation loss: 0.0980
2024-05-22 16:46:16 [INFO]: Epoch 130 - training loss: 9284.5455, validation loss: 0.0956
2024-05-22 16:46:17 [INFO]: Epoch 131 - training loss: 9283.9887, validation loss: 0.0977
2024-05-22 16:46:17 [INFO]: Epoch 132 - training loss: 9282.8386, validation loss: 0.0954
2024-05-22 16:46:17 [INFO]: Epoch 133 - training loss: 9281.5317, validation loss: 0.0953
2024-05-22 16:46:17 [INFO]: Epoch 134 - training loss: 9286.8364, validation loss: 0.0945
2024-05-22 16:46:17 [INFO]: Epoch 135 - training loss: 9281.6035, validation loss: 0.0953
2024-05-22 16:46:17 [INFO]: Epoch 136 - training loss: 9282.6028, validation loss: 0.0947
2024-05-22 16:46:17 [INFO]: Epoch 137 - training loss: 9284.1717, validation loss: 0.0944
2024-05-22 16:46:17 [INFO]: Epoch 138 - training loss: 9282.2756, validation loss: 0.0943
2024-05-22 16:46:17 [INFO]: Epoch 139 - training loss: 9283.4334, validation loss: 0.0949
2024-05-22 16:46:18 [INFO]: Epoch 140 - training loss: 9281.0992, validation loss: 0.0923
2024-05-22 16:46:18 [INFO]: Epoch 141 - training loss: 9281.7433, validation loss: 0.0929
2024-05-22 16:46:18 [INFO]: Epoch 142 - training loss: 9281.6564, validation loss: 0.0932
2024-05-22 16:46:18 [INFO]: Epoch 143 - training loss: 9280.8387, validation loss: 0.0928
2024-05-22 16:46:18 [INFO]: Epoch 144 - training loss: 9281.3876, validation loss: 0.0921
2024-05-22 16:46:18 [INFO]: Epoch 145 - training loss: 9281.2548, validation loss: 0.0901
2024-05-22 16:46:18 [INFO]: Epoch 146 - training loss: 9281.6811, validation loss: 0.0911
2024-05-22 16:46:18 [INFO]: Epoch 147 - training loss: 9278.7500, validation loss: 0.0909
2024-05-22 16:46:18 [INFO]: Epoch 148 - training loss: 9279.7374, validation loss: 0.0901
2024-05-22 16:46:19 [INFO]: Epoch 149 - training loss: 9278.2607, validation loss: 0.0922
2024-05-22 16:46:19 [INFO]: Epoch 150 - training loss: 9278.5276, validation loss: 0.0906
2024-05-22 16:46:19 [INFO]: Epoch 151 - training loss: 9280.3745, validation loss: 0.0901
2024-05-22 16:46:19 [INFO]: Epoch 152 - training loss: 9280.9402, validation loss: 0.0908
2024-05-22 16:46:19 [INFO]: Epoch 153 - training loss: 9279.7755, validation loss: 0.0891
2024-05-22 16:46:19 [INFO]: Epoch 154 - training loss: 9278.1617, validation loss: 0.0887
2024-05-22 16:46:19 [INFO]: Epoch 155 - training loss: 9279.9516, validation loss: 0.0883
2024-05-22 16:46:19 [INFO]: Epoch 156 - training loss: 9278.5549, validation loss: 0.0885
2024-05-22 16:46:19 [INFO]: Epoch 157 - training loss: 9279.1891, validation loss: 0.0882
2024-05-22 16:46:20 [INFO]: Epoch 158 - training loss: 9279.1055, validation loss: 0.0859
2024-05-22 16:46:20 [INFO]: Epoch 159 - training loss: 9278.2347, validation loss: 0.0880
2024-05-22 16:46:20 [INFO]: Epoch 160 - training loss: 9277.2139, validation loss: 0.0872
2024-05-22 16:46:20 [INFO]: Epoch 161 - training loss: 9279.4683, validation loss: 0.0875
2024-05-22 16:46:20 [INFO]: Epoch 162 - training loss: 9278.2400, validation loss: 0.0852
2024-05-22 16:46:20 [INFO]: Epoch 163 - training loss: 9277.9509, validation loss: 0.0890
2024-05-22 16:46:20 [INFO]: Epoch 164 - training loss: 9278.0446, validation loss: 0.0863
2024-05-22 16:46:20 [INFO]: Epoch 165 - training loss: 9277.4029, validation loss: 0.0851
2024-05-22 16:46:20 [INFO]: Epoch 166 - training loss: 9276.8978, validation loss: 0.0844
2024-05-22 16:46:20 [INFO]: Epoch 167 - training loss: 9276.3771, validation loss: 0.0871
2024-05-22 16:46:21 [INFO]: Epoch 168 - training loss: 9278.5679, validation loss: 0.0857
2024-05-22 16:46:21 [INFO]: Epoch 169 - training loss: 9276.8862, validation loss: 0.0845
2024-05-22 16:46:21 [INFO]: Epoch 170 - training loss: 9276.1885, validation loss: 0.0845
2024-05-22 16:46:21 [INFO]: Epoch 171 - training loss: 9277.0813, validation loss: 0.0849
2024-05-22 16:46:21 [INFO]: Epoch 172 - training loss: 9277.4296, validation loss: 0.0854
2024-05-22 16:46:21 [INFO]: Epoch 173 - training loss: 9276.0833, validation loss: 0.0837
2024-05-22 16:46:21 [INFO]: Epoch 174 - training loss: 9275.3000, validation loss: 0.0838
2024-05-22 16:46:21 [INFO]: Epoch 175 - training loss: 9275.5757, validation loss: 0.0826
2024-05-22 16:46:21 [INFO]: Epoch 176 - training loss: 9276.2757, validation loss: 0.0825
2024-05-22 16:46:22 [INFO]: Epoch 177 - training loss: 9276.1884, validation loss: 0.0828
2024-05-22 16:46:22 [INFO]: Epoch 178 - training loss: 9274.5089, validation loss: 0.0819
2024-05-22 16:46:22 [INFO]: Epoch 179 - training loss: 9276.4634, validation loss: 0.0838
2024-05-22 16:46:22 [INFO]: Epoch 180 - training loss: 9275.9940, validation loss: 0.0818
2024-05-22 16:46:22 [INFO]: Epoch 181 - training loss: 9274.4893, validation loss: 0.0819
2024-05-22 16:46:22 [INFO]: Epoch 182 - training loss: 9276.3465, validation loss: 0.0816
2024-05-22 16:46:22 [INFO]: Epoch 183 - training loss: 9275.1985, validation loss: 0.0811
2024-05-22 16:46:22 [INFO]: Epoch 184 - training loss: 9274.9596, validation loss: 0.0812
2024-05-22 16:46:22 [INFO]: Epoch 185 - training loss: 9275.6875, validation loss: 0.0806
2024-05-22 16:46:23 [INFO]: Epoch 186 - training loss: 9274.9730, validation loss: 0.0820
2024-05-22 16:46:23 [INFO]: Epoch 187 - training loss: 9275.1723, validation loss: 0.0823
2024-05-22 16:46:23 [INFO]: Epoch 188 - training loss: 9275.0963, validation loss: 0.0830
2024-05-22 16:46:23 [INFO]: Epoch 189 - training loss: 9273.7653, validation loss: 0.0813
2024-05-22 16:46:23 [INFO]: Epoch 190 - training loss: 9275.0580, validation loss: 0.0816
2024-05-22 16:46:23 [INFO]: Epoch 191 - training loss: 9275.0495, validation loss: 0.0824
2024-05-22 16:46:23 [INFO]: Epoch 192 - training loss: 9273.9667, validation loss: 0.0811
2024-05-22 16:46:23 [INFO]: Epoch 193 - training loss: 9274.5162, validation loss: 0.0804
2024-05-22 16:46:23 [INFO]: Epoch 194 - training loss: 9273.7469, validation loss: 0.0799
2024-05-22 16:46:24 [INFO]: Epoch 195 - training loss: 9274.3258, validation loss: 0.0806
2024-05-22 16:46:24 [INFO]: Epoch 196 - training loss: 9274.2315, validation loss: 0.0793
2024-05-22 16:46:24 [INFO]: Epoch 197 - training loss: 9276.9833, validation loss: 0.0803
2024-05-22 16:46:24 [INFO]: Epoch 198 - training loss: 9273.9984, validation loss: 0.0793
2024-05-22 16:46:24 [INFO]: Epoch 199 - training loss: 9273.3324, validation loss: 0.0803
2024-05-22 16:46:24 [INFO]: Epoch 200 - training loss: 9273.8888, validation loss: 0.0795
2024-05-22 16:46:24 [INFO]: Epoch 201 - training loss: 9273.8965, validation loss: 0.0785
2024-05-22 16:46:24 [INFO]: Epoch 202 - training loss: 9275.4355, validation loss: 0.0786
2024-05-22 16:46:24 [INFO]: Epoch 203 - training loss: 9272.7828, validation loss: 0.0812
2024-05-22 16:46:25 [INFO]: Epoch 204 - training loss: 9272.6251, validation loss: 0.0804
2024-05-22 16:46:25 [INFO]: Epoch 205 - training loss: 9273.5117, validation loss: 0.0799
2024-05-22 16:46:25 [INFO]: Epoch 206 - training loss: 9273.1348, validation loss: 0.0796
2024-05-22 16:46:25 [INFO]: Epoch 207 - training loss: 9272.1165, validation loss: 0.0794
2024-05-22 16:46:25 [INFO]: Epoch 208 - training loss: 9273.2588, validation loss: 0.0773
2024-05-22 16:46:25 [INFO]: Epoch 209 - training loss: 9271.6185, validation loss: 0.0786
2024-05-22 16:46:25 [INFO]: Epoch 210 - training loss: 9273.9360, validation loss: 0.0774
2024-05-22 16:46:25 [INFO]: Epoch 211 - training loss: 9273.2405, validation loss: 0.0791
2024-05-22 16:46:25 [INFO]: Epoch 212 - training loss: 9273.4354, validation loss: 0.0801
2024-05-22 16:46:25 [INFO]: Epoch 213 - training loss: 9272.8893, validation loss: 0.0772
2024-05-22 16:46:26 [INFO]: Epoch 214 - training loss: 9273.2529, validation loss: 0.0774
2024-05-22 16:46:26 [INFO]: Epoch 215 - training loss: 9272.1739, validation loss: 0.0790
2024-05-22 16:46:26 [INFO]: Epoch 216 - training loss: 9271.9468, validation loss: 0.0775
2024-05-22 16:46:26 [INFO]: Epoch 217 - training loss: 9272.9300, validation loss: 0.0772
2024-05-22 16:46:26 [INFO]: Epoch 218 - training loss: 9272.4434, validation loss: 0.0777
2024-05-22 16:46:26 [INFO]: Epoch 219 - training loss: 9272.0463, validation loss: 0.0777
2024-05-22 16:46:26 [INFO]: Epoch 220 - training loss: 9271.5636, validation loss: 0.0766
2024-05-22 16:46:26 [INFO]: Epoch 221 - training loss: 9273.4850, validation loss: 0.0774
2024-05-22 16:46:26 [INFO]: Epoch 222 - training loss: 9271.0776, validation loss: 0.0769
2024-05-22 16:46:27 [INFO]: Epoch 223 - training loss: 9271.5179, validation loss: 0.0765
2024-05-22 16:46:27 [INFO]: Epoch 224 - training loss: 9272.1356, validation loss: 0.0768
2024-05-22 16:46:27 [INFO]: Epoch 225 - training loss: 9272.1159, validation loss: 0.0783
2024-05-22 16:46:27 [INFO]: Epoch 226 - training loss: 9272.3863, validation loss: 0.0760
2024-05-22 16:46:27 [INFO]: Epoch 227 - training loss: 9272.0018, validation loss: 0.0757
2024-05-22 16:46:27 [INFO]: Epoch 228 - training loss: 9270.8023, validation loss: 0.0773
2024-05-22 16:46:27 [INFO]: Epoch 229 - training loss: 9272.7684, validation loss: 0.0761
2024-05-22 16:46:27 [INFO]: Epoch 230 - training loss: 9271.7960, validation loss: 0.0755
2024-05-22 16:46:27 [INFO]: Epoch 231 - training loss: 9270.5222, validation loss: 0.0769
2024-05-22 16:46:28 [INFO]: Epoch 232 - training loss: 9271.4709, validation loss: 0.0769
2024-05-22 16:46:28 [INFO]: Epoch 233 - training loss: 9272.9639, validation loss: 0.0769
2024-05-22 16:46:28 [INFO]: Epoch 234 - training loss: 9272.2240, validation loss: 0.0754
2024-05-22 16:46:28 [INFO]: Epoch 235 - training loss: 9270.7664, validation loss: 0.0753
2024-05-22 16:46:28 [INFO]: Epoch 236 - training loss: 9272.3079, validation loss: 0.0751
2024-05-22 16:46:28 [INFO]: Epoch 237 - training loss: 9270.9136, validation loss: 0.0742
2024-05-22 16:46:28 [INFO]: Epoch 238 - training loss: 9271.2319, validation loss: 0.0748
2024-05-22 16:46:28 [INFO]: Epoch 239 - training loss: 9271.5584, validation loss: 0.0727
2024-05-22 16:46:28 [INFO]: Epoch 240 - training loss: 9270.7874, validation loss: 0.0789
2024-05-22 16:46:29 [INFO]: Epoch 241 - training loss: 9271.4863, validation loss: 0.0776
2024-05-22 16:46:29 [INFO]: Epoch 242 - training loss: 9272.3857, validation loss: 0.0764
2024-05-22 16:46:29 [INFO]: Epoch 243 - training loss: 9270.5097, validation loss: 0.0750
2024-05-22 16:46:29 [INFO]: Epoch 244 - training loss: 9273.3143, validation loss: 0.0776
2024-05-22 16:46:29 [INFO]: Epoch 245 - training loss: 9271.2918, validation loss: 0.0747
2024-05-22 16:46:29 [INFO]: Epoch 246 - training loss: 9269.2514, validation loss: 0.0748
2024-05-22 16:46:29 [INFO]: Epoch 247 - training loss: 9271.0217, validation loss: 0.0764
2024-05-22 16:46:29 [INFO]: Epoch 248 - training loss: 9270.4543, validation loss: 0.0752
2024-05-22 16:46:29 [INFO]: Epoch 249 - training loss: 9270.1856, validation loss: 0.0744
2024-05-22 16:46:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 16:46:29 [INFO]: Finished training. The best model is from epoch#239.
2024-05-22 16:46:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/GPVAE_ettm1/20240522_T164602/GPVAE.pypots
2024-05-22 16:46:29 [INFO]: GP-VAE on ETTm1: MAE=0.2733, MSE=0.1616
2024-05-22 16:46:29 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-22 16:46:29 [INFO]: Using the given device: cuda:0
2024-05-22 16:46:29 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/USGAN_ettm1/20240522_T164629
2024-05-22 16:46:29 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/USGAN_ettm1/20240522_T164629/tensorboard
2024-05-22 16:46:29 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 16:46:38 [INFO]: Epoch 001 - generator training loss: 0.5202, discriminator training loss: 0.4191, validation loss: 0.3815
2024-05-22 16:46:45 [INFO]: Epoch 002 - generator training loss: 0.0053, discriminator training loss: 0.3257, validation loss: 0.1008
2024-05-22 16:46:52 [INFO]: Epoch 003 - generator training loss: -0.1276, discriminator training loss: 0.3159, validation loss: 0.0620
2024-05-22 16:47:00 [INFO]: Epoch 004 - generator training loss: -0.1407, discriminator training loss: 0.3021, validation loss: 0.0453
2024-05-22 16:47:07 [INFO]: Epoch 005 - generator training loss: -0.1344, discriminator training loss: 0.2837, validation loss: 0.0412
2024-05-22 16:47:14 [INFO]: Epoch 006 - generator training loss: -0.1146, discriminator training loss: 0.2588, validation loss: 0.0381
2024-05-22 16:47:21 [INFO]: Epoch 007 - generator training loss: -0.0869, discriminator training loss: 0.2247, validation loss: 0.0368
2024-05-22 16:47:29 [INFO]: Epoch 008 - generator training loss: -0.0688, discriminator training loss: 0.1885, validation loss: 0.0348
2024-05-22 16:47:36 [INFO]: Epoch 009 - generator training loss: -0.0470, discriminator training loss: 0.1628, validation loss: 0.0343
2024-05-22 16:47:43 [INFO]: Epoch 010 - generator training loss: -0.0398, discriminator training loss: 0.1450, validation loss: 0.0329
2024-05-22 16:47:51 [INFO]: Epoch 011 - generator training loss: -0.0333, discriminator training loss: 0.1361, validation loss: 0.0326
2024-05-22 16:47:58 [INFO]: Epoch 012 - generator training loss: -0.0329, discriminator training loss: 0.1274, validation loss: 0.0314
2024-05-22 16:48:05 [INFO]: Epoch 013 - generator training loss: -0.0320, discriminator training loss: 0.1240, validation loss: 0.0318
2024-05-22 16:48:13 [INFO]: Epoch 014 - generator training loss: -0.0325, discriminator training loss: 0.1217, validation loss: 0.0308
2024-05-22 16:48:20 [INFO]: Epoch 015 - generator training loss: -0.0316, discriminator training loss: 0.1214, validation loss: 0.0306
2024-05-22 16:48:27 [INFO]: Epoch 016 - generator training loss: -0.0341, discriminator training loss: 0.1195, validation loss: 0.0299
2024-05-22 16:48:35 [INFO]: Epoch 017 - generator training loss: -0.0311, discriminator training loss: 0.1183, validation loss: 0.0295
2024-05-22 16:48:42 [INFO]: Epoch 018 - generator training loss: -0.0349, discriminator training loss: 0.1185, validation loss: 0.0302
2024-05-22 16:48:49 [INFO]: Epoch 019 - generator training loss: -0.0317, discriminator training loss: 0.1164, validation loss: 0.0293
2024-05-22 16:48:57 [INFO]: Epoch 020 - generator training loss: -0.0335, discriminator training loss: 0.1156, validation loss: 0.0294
2024-05-22 16:49:04 [INFO]: Epoch 021 - generator training loss: -0.0362, discriminator training loss: 0.1157, validation loss: 0.0287
2024-05-22 16:49:11 [INFO]: Epoch 022 - generator training loss: -0.0297, discriminator training loss: 0.1134, validation loss: 0.0290
2024-05-22 16:49:19 [INFO]: Epoch 023 - generator training loss: -0.0329, discriminator training loss: 0.1145, validation loss: 0.0285
2024-05-22 16:49:26 [INFO]: Epoch 024 - generator training loss: -0.0344, discriminator training loss: 0.1172, validation loss: 0.0285
2024-05-22 16:49:33 [INFO]: Epoch 025 - generator training loss: -0.0361, discriminator training loss: 0.1156, validation loss: 0.0274
2024-05-22 16:49:41 [INFO]: Epoch 026 - generator training loss: -0.0363, discriminator training loss: 0.1133, validation loss: 0.0274
2024-05-22 16:49:48 [INFO]: Epoch 027 - generator training loss: -0.0382, discriminator training loss: 0.1166, validation loss: 0.0270
2024-05-22 16:49:55 [INFO]: Epoch 028 - generator training loss: -0.0350, discriminator training loss: 0.1164, validation loss: 0.0264
2024-05-22 16:50:03 [INFO]: Epoch 029 - generator training loss: -0.0373, discriminator training loss: 0.1122, validation loss: 0.0265
2024-05-22 16:50:10 [INFO]: Epoch 030 - generator training loss: -0.0370, discriminator training loss: 0.1139, validation loss: 0.0264
2024-05-22 16:50:18 [INFO]: Epoch 031 - generator training loss: -0.0387, discriminator training loss: 0.1134, validation loss: 0.0255
2024-05-22 16:50:25 [INFO]: Epoch 032 - generator training loss: -0.0360, discriminator training loss: 0.1108, validation loss: 0.0266
2024-05-22 16:50:32 [INFO]: Epoch 033 - generator training loss: -0.0357, discriminator training loss: 0.1111, validation loss: 0.0263
2024-05-22 16:50:40 [INFO]: Epoch 034 - generator training loss: -0.0350, discriminator training loss: 0.1122, validation loss: 0.0251
2024-05-22 16:50:47 [INFO]: Epoch 035 - generator training loss: -0.0352, discriminator training loss: 0.1133, validation loss: 0.0248
2024-05-22 16:50:54 [INFO]: Epoch 036 - generator training loss: -0.0359, discriminator training loss: 0.1119, validation loss: 0.0244
2024-05-22 16:51:02 [INFO]: Epoch 037 - generator training loss: -0.0382, discriminator training loss: 0.1101, validation loss: 0.0242
2024-05-22 16:51:09 [INFO]: Epoch 038 - generator training loss: -0.0406, discriminator training loss: 0.1117, validation loss: 0.0242
2024-05-22 16:51:17 [INFO]: Epoch 039 - generator training loss: -0.0398, discriminator training loss: 0.1122, validation loss: 0.0245
2024-05-22 16:51:24 [INFO]: Epoch 040 - generator training loss: -0.0389, discriminator training loss: 0.1111, validation loss: 0.0236
2024-05-22 16:51:31 [INFO]: Epoch 041 - generator training loss: -0.0395, discriminator training loss: 0.1116, validation loss: 0.0235
2024-05-22 16:51:39 [INFO]: Epoch 042 - generator training loss: -0.0382, discriminator training loss: 0.1096, validation loss: 0.0231
2024-05-22 16:51:46 [INFO]: Epoch 043 - generator training loss: -0.0413, discriminator training loss: 0.1129, validation loss: 0.0229
2024-05-22 16:51:53 [INFO]: Epoch 044 - generator training loss: -0.0409, discriminator training loss: 0.1096, validation loss: 0.0230
2024-05-22 16:52:01 [INFO]: Epoch 045 - generator training loss: -0.0408, discriminator training loss: 0.1083, validation loss: 0.0226
2024-05-22 16:52:08 [INFO]: Epoch 046 - generator training loss: -0.0401, discriminator training loss: 0.1099, validation loss: 0.0229
2024-05-22 16:52:16 [INFO]: Epoch 047 - generator training loss: -0.0388, discriminator training loss: 0.1110, validation loss: 0.0223
2024-05-22 16:52:23 [INFO]: Epoch 048 - generator training loss: -0.0429, discriminator training loss: 0.1107, validation loss: 0.0223
2024-05-22 16:52:30 [INFO]: Epoch 049 - generator training loss: -0.0419, discriminator training loss: 0.1101, validation loss: 0.0225
2024-05-22 16:52:37 [INFO]: Epoch 050 - generator training loss: -0.0407, discriminator training loss: 0.1100, validation loss: 0.0222
2024-05-22 16:52:45 [INFO]: Epoch 051 - generator training loss: -0.0406, discriminator training loss: 0.1110, validation loss: 0.0221
2024-05-22 16:52:52 [INFO]: Epoch 052 - generator training loss: -0.0391, discriminator training loss: 0.1091, validation loss: 0.0224
2024-05-22 16:52:59 [INFO]: Epoch 053 - generator training loss: -0.0400, discriminator training loss: 0.1100, validation loss: 0.0218
2024-05-22 16:53:06 [INFO]: Epoch 054 - generator training loss: -0.0409, discriminator training loss: 0.1092, validation loss: 0.0219
2024-05-22 16:53:14 [INFO]: Epoch 055 - generator training loss: -0.0394, discriminator training loss: 0.1087, validation loss: 0.0216
2024-05-22 16:53:21 [INFO]: Epoch 056 - generator training loss: -0.0425, discriminator training loss: 0.1072, validation loss: 0.0218
2024-05-22 16:53:28 [INFO]: Epoch 057 - generator training loss: -0.0440, discriminator training loss: 0.1095, validation loss: 0.0212
2024-05-22 16:53:36 [INFO]: Epoch 058 - generator training loss: -0.0409, discriminator training loss: 0.1100, validation loss: 0.0220
2024-05-22 16:53:43 [INFO]: Epoch 059 - generator training loss: -0.0413, discriminator training loss: 0.1092, validation loss: 0.0219
2024-05-22 16:53:50 [INFO]: Epoch 060 - generator training loss: -0.0394, discriminator training loss: 0.1078, validation loss: 0.0216
2024-05-22 16:53:58 [INFO]: Epoch 061 - generator training loss: -0.0414, discriminator training loss: 0.1088, validation loss: 0.0215
2024-05-22 16:54:05 [INFO]: Epoch 062 - generator training loss: -0.0415, discriminator training loss: 0.1084, validation loss: 0.0210
2024-05-22 16:54:13 [INFO]: Epoch 063 - generator training loss: -0.0405, discriminator training loss: 0.1096, validation loss: 0.0213
2024-05-22 16:54:20 [INFO]: Epoch 064 - generator training loss: -0.0410, discriminator training loss: 0.1081, validation loss: 0.0213
2024-05-22 16:54:28 [INFO]: Epoch 065 - generator training loss: -0.0417, discriminator training loss: 0.1113, validation loss: 0.0211
2024-05-22 16:54:35 [INFO]: Epoch 066 - generator training loss: -0.0471, discriminator training loss: 0.1104, validation loss: 0.0206
2024-05-22 16:54:43 [INFO]: Epoch 067 - generator training loss: -0.0418, discriminator training loss: 0.1070, validation loss: 0.0206
2024-05-22 16:54:50 [INFO]: Epoch 068 - generator training loss: -0.0466, discriminator training loss: 0.1073, validation loss: 0.0209
2024-05-22 16:54:58 [INFO]: Epoch 069 - generator training loss: -0.0450, discriminator training loss: 0.1068, validation loss: 0.0207
2024-05-22 16:55:06 [INFO]: Epoch 070 - generator training loss: -0.0463, discriminator training loss: 0.1068, validation loss: 0.0203
2024-05-22 16:55:13 [INFO]: Epoch 071 - generator training loss: -0.0456, discriminator training loss: 0.1055, validation loss: 0.0201
2024-05-22 16:55:20 [INFO]: Epoch 072 - generator training loss: -0.0446, discriminator training loss: 0.1071, validation loss: 0.0208
2024-05-22 16:55:28 [INFO]: Epoch 073 - generator training loss: -0.0466, discriminator training loss: 0.1090, validation loss: 0.0208
2024-05-22 16:55:36 [INFO]: Epoch 074 - generator training loss: -0.0441, discriminator training loss: 0.1069, validation loss: 0.0203
2024-05-22 16:55:43 [INFO]: Epoch 075 - generator training loss: -0.0468, discriminator training loss: 0.1055, validation loss: 0.0200
2024-05-22 16:55:51 [INFO]: Epoch 076 - generator training loss: -0.0455, discriminator training loss: 0.1073, validation loss: 0.0197
2024-05-22 16:55:58 [INFO]: Epoch 077 - generator training loss: -0.0469, discriminator training loss: 0.1067, validation loss: 0.0197
2024-05-22 16:56:06 [INFO]: Epoch 078 - generator training loss: -0.0467, discriminator training loss: 0.1070, validation loss: 0.0199
2024-05-22 16:56:13 [INFO]: Epoch 079 - generator training loss: -0.0440, discriminator training loss: 0.1072, validation loss: 0.0215
2024-05-22 16:56:21 [INFO]: Epoch 080 - generator training loss: -0.0453, discriminator training loss: 0.1051, validation loss: 0.0201
2024-05-22 16:56:28 [INFO]: Epoch 081 - generator training loss: -0.0438, discriminator training loss: 0.1069, validation loss: 0.0200
2024-05-22 16:56:36 [INFO]: Epoch 082 - generator training loss: -0.0475, discriminator training loss: 0.1070, validation loss: 0.0204
2024-05-22 16:56:43 [INFO]: Epoch 083 - generator training loss: -0.0446, discriminator training loss: 0.1080, validation loss: 0.0215
2024-05-22 16:56:51 [INFO]: Epoch 084 - generator training loss: -0.0455, discriminator training loss: 0.1063, validation loss: 0.0200
2024-05-22 16:56:58 [INFO]: Epoch 085 - generator training loss: -0.0469, discriminator training loss: 0.1071, validation loss: 0.0198
2024-05-22 16:57:06 [INFO]: Epoch 086 - generator training loss: -0.0465, discriminator training loss: 0.1066, validation loss: 0.0198
2024-05-22 16:57:13 [INFO]: Epoch 087 - generator training loss: -0.0471, discriminator training loss: 0.1078, validation loss: 0.0193
2024-05-22 16:57:21 [INFO]: Epoch 088 - generator training loss: -0.0473, discriminator training loss: 0.1066, validation loss: 0.0194
2024-05-22 16:57:28 [INFO]: Epoch 089 - generator training loss: -0.0483, discriminator training loss: 0.1076, validation loss: 0.0191
2024-05-22 16:57:36 [INFO]: Epoch 090 - generator training loss: -0.0472, discriminator training loss: 0.1069, validation loss: 0.0193
2024-05-22 16:57:44 [INFO]: Epoch 091 - generator training loss: -0.0487, discriminator training loss: 0.1074, validation loss: 0.0190
2024-05-22 16:57:51 [INFO]: Epoch 092 - generator training loss: -0.0465, discriminator training loss: 0.1081, validation loss: 0.0188
2024-05-22 16:57:58 [INFO]: Epoch 093 - generator training loss: -0.0464, discriminator training loss: 0.1063, validation loss: 0.0202
2024-05-22 16:58:06 [INFO]: Epoch 094 - generator training loss: -0.0484, discriminator training loss: 0.1062, validation loss: 0.0188
2024-05-22 16:58:13 [INFO]: Epoch 095 - generator training loss: -0.0477, discriminator training loss: 0.1049, validation loss: 0.0191
2024-05-22 16:58:21 [INFO]: Epoch 096 - generator training loss: -0.0492, discriminator training loss: 0.1053, validation loss: 0.0187
2024-05-22 16:58:28 [INFO]: Epoch 097 - generator training loss: -0.0486, discriminator training loss: 0.1062, validation loss: 0.0190
2024-05-22 16:58:36 [INFO]: Epoch 098 - generator training loss: -0.0476, discriminator training loss: 0.1056, validation loss: 0.0188
2024-05-22 16:58:43 [INFO]: Epoch 099 - generator training loss: -0.0487, discriminator training loss: 0.1060, validation loss: 0.0188
2024-05-22 16:58:51 [INFO]: Epoch 100 - generator training loss: -0.0490, discriminator training loss: 0.1067, validation loss: 0.0188
2024-05-22 16:58:58 [INFO]: Epoch 101 - generator training loss: -0.0503, discriminator training loss: 0.1049, validation loss: 0.0189
2024-05-22 16:59:06 [INFO]: Epoch 102 - generator training loss: -0.0508, discriminator training loss: 0.1063, validation loss: 0.0185
2024-05-22 16:59:13 [INFO]: Epoch 103 - generator training loss: -0.0467, discriminator training loss: 0.1057, validation loss: 0.0188
2024-05-22 16:59:21 [INFO]: Epoch 104 - generator training loss: -0.0510, discriminator training loss: 0.1046, validation loss: 0.0187
2024-05-22 16:59:28 [INFO]: Epoch 105 - generator training loss: -0.0500, discriminator training loss: 0.1054, validation loss: 0.0188
2024-05-22 16:59:36 [INFO]: Epoch 106 - generator training loss: -0.0484, discriminator training loss: 0.1044, validation loss: 0.0185
2024-05-22 16:59:43 [INFO]: Epoch 107 - generator training loss: -0.0477, discriminator training loss: 0.1049, validation loss: 0.0186
2024-05-22 16:59:51 [INFO]: Epoch 108 - generator training loss: -0.0487, discriminator training loss: 0.1058, validation loss: 0.0187
2024-05-22 16:59:59 [INFO]: Epoch 109 - generator training loss: -0.0459, discriminator training loss: 0.1033, validation loss: 0.0188
2024-05-22 17:00:06 [INFO]: Epoch 110 - generator training loss: -0.0471, discriminator training loss: 0.1061, validation loss: 0.0182
2024-05-22 17:00:13 [INFO]: Epoch 111 - generator training loss: -0.0496, discriminator training loss: 0.1048, validation loss: 0.0185
2024-05-22 17:00:20 [INFO]: Epoch 112 - generator training loss: -0.0503, discriminator training loss: 0.1042, validation loss: 0.0182
2024-05-22 17:00:28 [INFO]: Epoch 113 - generator training loss: -0.0483, discriminator training loss: 0.1041, validation loss: 0.0179
2024-05-22 17:00:36 [INFO]: Epoch 114 - generator training loss: -0.0489, discriminator training loss: 0.1031, validation loss: 0.0193
2024-05-22 17:00:44 [INFO]: Epoch 115 - generator training loss: -0.0502, discriminator training loss: 0.1047, validation loss: 0.0182
2024-05-22 17:00:51 [INFO]: Epoch 116 - generator training loss: -0.0478, discriminator training loss: 0.1044, validation loss: 0.0185
2024-05-22 17:00:59 [INFO]: Epoch 117 - generator training loss: -0.0478, discriminator training loss: 0.1062, validation loss: 0.0185
2024-05-22 17:01:06 [INFO]: Epoch 118 - generator training loss: -0.0470, discriminator training loss: 0.1043, validation loss: 0.0181
2024-05-22 17:01:14 [INFO]: Epoch 119 - generator training loss: -0.0497, discriminator training loss: 0.1053, validation loss: 0.0191
2024-05-22 17:01:21 [INFO]: Epoch 120 - generator training loss: -0.0481, discriminator training loss: 0.1060, validation loss: 0.0184
2024-05-22 17:01:29 [INFO]: Epoch 121 - generator training loss: -0.0475, discriminator training loss: 0.1042, validation loss: 0.0184
2024-05-22 17:01:36 [INFO]: Epoch 122 - generator training loss: -0.0464, discriminator training loss: 0.1056, validation loss: 0.0196
2024-05-22 17:01:43 [INFO]: Epoch 123 - generator training loss: -0.0480, discriminator training loss: 0.1041, validation loss: 0.0182
2024-05-22 17:01:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:01:43 [INFO]: Finished training. The best model is from epoch#113.
2024-05-22 17:01:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/USGAN_ettm1/20240522_T164629/USGAN.pypots
2024-05-22 17:01:44 [INFO]: US-GAN on ETTm1: MAE=0.1442, MSE=0.0524
2024-05-22 17:01:44 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-22 17:01:44 [INFO]: Using the given device: cuda:0
2024-05-22 17:01:44 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/BRITS_ettm1/20240522_T170144
2024-05-22 17:01:44 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/BRITS_ettm1/20240522_T170144/tensorboard
2024-05-22 17:01:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 17:01:50 [INFO]: Epoch 001 - training loss: 1.3395, validation loss: 0.2585
2024-05-22 17:01:55 [INFO]: Epoch 002 - training loss: 0.8809, validation loss: 0.0858
2024-05-22 17:02:00 [INFO]: Epoch 003 - training loss: 0.7138, validation loss: 0.0509
2024-05-22 17:02:05 [INFO]: Epoch 004 - training loss: 0.6488, validation loss: 0.0398
2024-05-22 17:02:10 [INFO]: Epoch 005 - training loss: 0.6021, validation loss: 0.0368
2024-05-22 17:02:15 [INFO]: Epoch 006 - training loss: 0.5714, validation loss: 0.0331
2024-05-22 17:02:20 [INFO]: Epoch 007 - training loss: 0.5498, validation loss: 0.0329
2024-05-22 17:02:25 [INFO]: Epoch 008 - training loss: 0.5341, validation loss: 0.0306
2024-05-22 17:02:29 [INFO]: Epoch 009 - training loss: 0.5206, validation loss: 0.0342
2024-05-22 17:02:34 [INFO]: Epoch 010 - training loss: 0.4985, validation loss: 0.0332
2024-05-22 17:02:39 [INFO]: Epoch 011 - training loss: 0.4786, validation loss: 0.0286
2024-05-22 17:02:44 [INFO]: Epoch 012 - training loss: 0.4589, validation loss: 0.0273
2024-05-22 17:02:49 [INFO]: Epoch 013 - training loss: 0.4669, validation loss: 0.0282
2024-05-22 17:02:54 [INFO]: Epoch 014 - training loss: 0.4427, validation loss: 0.0270
2024-05-22 17:02:59 [INFO]: Epoch 015 - training loss: 0.4425, validation loss: 0.0270
2024-05-22 17:03:04 [INFO]: Epoch 016 - training loss: 0.4166, validation loss: 0.0248
2024-05-22 17:03:09 [INFO]: Epoch 017 - training loss: 0.4003, validation loss: 0.0235
2024-05-22 17:03:14 [INFO]: Epoch 018 - training loss: 0.3991, validation loss: 0.0227
2024-05-22 17:03:19 [INFO]: Epoch 019 - training loss: 0.3924, validation loss: 0.0223
2024-05-22 17:03:24 [INFO]: Epoch 020 - training loss: 0.3998, validation loss: 0.0218
2024-05-22 17:03:29 [INFO]: Epoch 021 - training loss: 0.3992, validation loss: 0.0223
2024-05-22 17:03:33 [INFO]: Epoch 022 - training loss: 0.3977, validation loss: 0.0228
2024-05-22 17:03:38 [INFO]: Epoch 023 - training loss: 0.4031, validation loss: 0.0225
2024-05-22 17:03:43 [INFO]: Epoch 024 - training loss: 0.4045, validation loss: 0.0225
2024-05-22 17:03:48 [INFO]: Epoch 025 - training loss: 0.4102, validation loss: 0.0227
2024-05-22 17:03:53 [INFO]: Epoch 026 - training loss: 0.4031, validation loss: 0.0230
2024-05-22 17:03:58 [INFO]: Epoch 027 - training loss: 0.3871, validation loss: 0.0215
2024-05-22 17:04:03 [INFO]: Epoch 028 - training loss: 0.3995, validation loss: 0.0222
2024-05-22 17:04:08 [INFO]: Epoch 029 - training loss: 0.4003, validation loss: 0.0220
2024-05-22 17:04:13 [INFO]: Epoch 030 - training loss: 0.3847, validation loss: 0.0220
2024-05-22 17:04:18 [INFO]: Epoch 031 - training loss: 0.3859, validation loss: 0.0218
2024-05-22 17:04:22 [INFO]: Epoch 032 - training loss: 0.3836, validation loss: 0.0217
2024-05-22 17:04:27 [INFO]: Epoch 033 - training loss: 0.3933, validation loss: 0.0223
2024-05-22 17:04:32 [INFO]: Epoch 034 - training loss: 0.3845, validation loss: 0.0218
2024-05-22 17:04:37 [INFO]: Epoch 035 - training loss: 0.3872, validation loss: 0.0214
2024-05-22 17:04:42 [INFO]: Epoch 036 - training loss: 0.3844, validation loss: 0.0217
2024-05-22 17:04:47 [INFO]: Epoch 037 - training loss: 0.3885, validation loss: 0.0215
2024-05-22 17:04:52 [INFO]: Epoch 038 - training loss: 0.3866, validation loss: 0.0220
2024-05-22 17:04:57 [INFO]: Epoch 039 - training loss: 0.3789, validation loss: 0.0213
2024-05-22 17:05:02 [INFO]: Epoch 040 - training loss: 0.3770, validation loss: 0.0217
2024-05-22 17:05:07 [INFO]: Epoch 041 - training loss: 0.3870, validation loss: 0.0221
2024-05-22 17:05:11 [INFO]: Epoch 042 - training loss: 0.3805, validation loss: 0.0347
2024-05-22 17:05:16 [INFO]: Epoch 043 - training loss: 0.4223, validation loss: 0.0229
2024-05-22 17:05:21 [INFO]: Epoch 044 - training loss: 0.3889, validation loss: 0.0230
2024-05-22 17:05:26 [INFO]: Epoch 045 - training loss: 0.3831, validation loss: 0.0221
2024-05-22 17:05:31 [INFO]: Epoch 046 - training loss: 0.3896, validation loss: 0.0217
2024-05-22 17:05:36 [INFO]: Epoch 047 - training loss: 0.3934, validation loss: 0.0225
2024-05-22 17:05:41 [INFO]: Epoch 048 - training loss: 0.3825, validation loss: 0.0217
2024-05-22 17:05:46 [INFO]: Epoch 049 - training loss: 0.3732, validation loss: 0.0218
2024-05-22 17:05:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:05:46 [INFO]: Finished training. The best model is from epoch#39.
2024-05-22 17:05:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/BRITS_ettm1/20240522_T170144/BRITS.pypots
2024-05-22 17:05:47 [INFO]: BRITS on ETTm1: MAE=0.1280, MSE=0.0479
2024-05-22 17:05:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-22 17:05:47 [INFO]: Using the given device: cuda:0
2024-05-22 17:05:47 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547
2024-05-22 17:05:47 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/tensorboard
2024-05-22 17:05:47 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 17:05:48 [INFO]: Epoch 001 - training loss: 1.3701, validation loss: 1.2455
2024-05-22 17:05:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch1_loss1.2455153465270996.pypots
2024-05-22 17:05:48 [INFO]: Epoch 002 - training loss: 1.0279, validation loss: 1.1018
2024-05-22 17:05:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch2_loss1.1017964631319046.pypots
2024-05-22 17:05:48 [INFO]: Epoch 003 - training loss: 0.9898, validation loss: 1.0406
2024-05-22 17:05:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch3_loss1.040565475821495.pypots
2024-05-22 17:05:48 [INFO]: Epoch 004 - training loss: 0.9449, validation loss: 1.0201
2024-05-22 17:05:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch4_loss1.020130306482315.pypots
2024-05-22 17:05:48 [INFO]: Epoch 005 - training loss: 0.9210, validation loss: 1.0062
2024-05-22 17:05:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch5_loss1.0061621069908142.pypots
2024-05-22 17:05:49 [INFO]: Epoch 006 - training loss: 0.9252, validation loss: 0.9980
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch6_loss0.9980464428663254.pypots
2024-05-22 17:05:49 [INFO]: Epoch 007 - training loss: 0.9390, validation loss: 0.9866
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch7_loss0.9866330623626709.pypots
2024-05-22 17:05:49 [INFO]: Epoch 008 - training loss: 0.9315, validation loss: 0.9832
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch8_loss0.983249306678772.pypots
2024-05-22 17:05:49 [INFO]: Epoch 009 - training loss: 0.9134, validation loss: 0.9774
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch9_loss0.9773801267147064.pypots
2024-05-22 17:05:49 [INFO]: Epoch 010 - training loss: 0.9272, validation loss: 0.9753
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch10_loss0.9752599596977234.pypots
2024-05-22 17:05:49 [INFO]: Epoch 011 - training loss: 0.9073, validation loss: 0.9790
2024-05-22 17:05:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch11_loss0.9790345877408981.pypots
2024-05-22 17:05:50 [INFO]: Epoch 012 - training loss: 0.8759, validation loss: 0.9799
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch12_loss0.9799028486013412.pypots
2024-05-22 17:05:50 [INFO]: Epoch 013 - training loss: 0.8728, validation loss: 0.9813
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch13_loss0.981279194355011.pypots
2024-05-22 17:05:50 [INFO]: Epoch 014 - training loss: 0.8603, validation loss: 0.9832
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch14_loss0.9832058846950531.pypots
2024-05-22 17:05:50 [INFO]: Epoch 015 - training loss: 0.8508, validation loss: 0.9796
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch15_loss0.9796246886253357.pypots
2024-05-22 17:05:50 [INFO]: Epoch 016 - training loss: 0.8522, validation loss: 0.9769
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch16_loss0.9768722355365753.pypots
2024-05-22 17:05:50 [INFO]: Epoch 017 - training loss: 0.8723, validation loss: 0.9771
2024-05-22 17:05:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch17_loss0.9770664125680923.pypots
2024-05-22 17:05:51 [INFO]: Epoch 018 - training loss: 0.8460, validation loss: 0.9741
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch18_loss0.9740792959928513.pypots
2024-05-22 17:05:51 [INFO]: Epoch 019 - training loss: 0.8256, validation loss: 0.9658
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch19_loss0.9658304452896118.pypots
2024-05-22 17:05:51 [INFO]: Epoch 020 - training loss: 0.8928, validation loss: 0.9656
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch20_loss0.9656171500682831.pypots
2024-05-22 17:05:51 [INFO]: Epoch 021 - training loss: 0.8373, validation loss: 0.9670
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch21_loss0.966969758272171.pypots
2024-05-22 17:05:51 [INFO]: Epoch 022 - training loss: 0.8291, validation loss: 0.9605
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch22_loss0.9605471193790436.pypots
2024-05-22 17:05:51 [INFO]: Epoch 023 - training loss: 0.8282, validation loss: 0.9599
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch23_loss0.9598693698644638.pypots
2024-05-22 17:05:51 [INFO]: Epoch 024 - training loss: 0.8208, validation loss: 0.9573
2024-05-22 17:05:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch24_loss0.9572712779045105.pypots
2024-05-22 17:05:52 [INFO]: Epoch 025 - training loss: 0.8175, validation loss: 0.9545
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch25_loss0.9545046836137772.pypots
2024-05-22 17:05:52 [INFO]: Epoch 026 - training loss: 0.8250, validation loss: 0.9529
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch26_loss0.9528568685054779.pypots
2024-05-22 17:05:52 [INFO]: Epoch 027 - training loss: 0.7943, validation loss: 0.9498
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch27_loss0.9498323798179626.pypots
2024-05-22 17:05:52 [INFO]: Epoch 028 - training loss: 0.8182, validation loss: 0.9517
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch28_loss0.9517080038785934.pypots
2024-05-22 17:05:52 [INFO]: Epoch 029 - training loss: 0.8230, validation loss: 0.9541
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch29_loss0.9541008025407791.pypots
2024-05-22 17:05:52 [INFO]: Epoch 030 - training loss: 0.8070, validation loss: 0.9518
2024-05-22 17:05:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch30_loss0.9517675340175629.pypots
2024-05-22 17:05:53 [INFO]: Epoch 031 - training loss: 0.8285, validation loss: 0.9468
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch31_loss0.9467949420213699.pypots
2024-05-22 17:05:53 [INFO]: Epoch 032 - training loss: 0.8008, validation loss: 0.9448
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch32_loss0.9448447376489639.pypots
2024-05-22 17:05:53 [INFO]: Epoch 033 - training loss: 0.8215, validation loss: 0.9450
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch33_loss0.9450104385614395.pypots
2024-05-22 17:05:53 [INFO]: Epoch 034 - training loss: 0.8248, validation loss: 0.9452
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch34_loss0.9452347755432129.pypots
2024-05-22 17:05:53 [INFO]: Epoch 035 - training loss: 0.8183, validation loss: 0.9429
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch35_loss0.9428642392158508.pypots
2024-05-22 17:05:53 [INFO]: Epoch 036 - training loss: 0.8112, validation loss: 0.9402
2024-05-22 17:05:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch36_loss0.9401910752058029.pypots
2024-05-22 17:05:54 [INFO]: Epoch 037 - training loss: 0.8027, validation loss: 0.9388
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch37_loss0.938787654042244.pypots
2024-05-22 17:05:54 [INFO]: Epoch 038 - training loss: 0.7826, validation loss: 0.9345
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch38_loss0.9345057606697083.pypots
2024-05-22 17:05:54 [INFO]: Epoch 039 - training loss: 0.7817, validation loss: 0.9352
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch39_loss0.9351597130298615.pypots
2024-05-22 17:05:54 [INFO]: Epoch 040 - training loss: 0.7767, validation loss: 0.9280
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch40_loss0.9279941022396088.pypots
2024-05-22 17:05:54 [INFO]: Epoch 041 - training loss: 0.7854, validation loss: 0.9296
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch41_loss0.9295617341995239.pypots
2024-05-22 17:05:54 [INFO]: Epoch 042 - training loss: 0.8056, validation loss: 0.9270
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch42_loss0.9270415008068085.pypots
2024-05-22 17:05:54 [INFO]: Epoch 043 - training loss: 0.8111, validation loss: 0.9230
2024-05-22 17:05:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch43_loss0.9230360239744186.pypots
2024-05-22 17:05:55 [INFO]: Epoch 044 - training loss: 0.7946, validation loss: 0.9161
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch44_loss0.916115015745163.pypots
2024-05-22 17:05:55 [INFO]: Epoch 045 - training loss: 0.8178, validation loss: 0.9142
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch45_loss0.9141539484262466.pypots
2024-05-22 17:05:55 [INFO]: Epoch 046 - training loss: 0.8059, validation loss: 0.9098
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch46_loss0.9097970426082611.pypots
2024-05-22 17:05:55 [INFO]: Epoch 047 - training loss: 0.7804, validation loss: 0.9068
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch47_loss0.9067569077014923.pypots
2024-05-22 17:05:55 [INFO]: Epoch 048 - training loss: 0.7885, validation loss: 0.8979
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch48_loss0.8979140222072601.pypots
2024-05-22 17:05:55 [INFO]: Epoch 049 - training loss: 0.8327, validation loss: 0.9006
2024-05-22 17:05:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch49_loss0.9006226807832718.pypots
2024-05-22 17:05:56 [INFO]: Epoch 050 - training loss: 0.8059, validation loss: 0.8922
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch50_loss0.8921840041875839.pypots
2024-05-22 17:05:56 [INFO]: Epoch 051 - training loss: 0.7951, validation loss: 0.8958
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch51_loss0.8958195745944977.pypots
2024-05-22 17:05:56 [INFO]: Epoch 052 - training loss: 0.7989, validation loss: 0.8920
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch52_loss0.8920369297266006.pypots
2024-05-22 17:05:56 [INFO]: Epoch 053 - training loss: 0.7875, validation loss: 0.8873
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch53_loss0.8872568756341934.pypots
2024-05-22 17:05:56 [INFO]: Epoch 054 - training loss: 0.7886, validation loss: 0.8883
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch54_loss0.8882743716239929.pypots
2024-05-22 17:05:56 [INFO]: Epoch 055 - training loss: 0.8012, validation loss: 0.8839
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch55_loss0.8838806599378586.pypots
2024-05-22 17:05:56 [INFO]: Epoch 056 - training loss: 0.7826, validation loss: 0.8868
2024-05-22 17:05:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch56_loss0.8867626041173935.pypots
2024-05-22 17:05:57 [INFO]: Epoch 057 - training loss: 0.7848, validation loss: 0.8831
2024-05-22 17:05:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch57_loss0.8830626010894775.pypots
2024-05-22 17:05:57 [INFO]: Epoch 058 - training loss: 0.7961, validation loss: 0.8812
2024-05-22 17:05:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch58_loss0.8812078982591629.pypots
2024-05-22 17:05:57 [INFO]: Epoch 059 - training loss: 0.7894, validation loss: 0.8785
2024-05-22 17:05:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch59_loss0.8784613758325577.pypots
2024-05-22 17:05:57 [INFO]: Epoch 060 - training loss: 0.7776, validation loss: 0.8779
2024-05-22 17:05:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch60_loss0.8779301643371582.pypots
2024-05-22 17:05:58 [INFO]: Epoch 061 - training loss: 0.7936, validation loss: 0.8776
2024-05-22 17:05:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch61_loss0.8775899410247803.pypots
2024-05-22 17:05:58 [INFO]: Epoch 062 - training loss: 0.7894, validation loss: 0.8752
2024-05-22 17:05:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch62_loss0.8751925379037857.pypots
2024-05-22 17:05:58 [INFO]: Epoch 063 - training loss: 0.8000, validation loss: 0.8731
2024-05-22 17:05:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch63_loss0.8731484115123749.pypots
2024-05-22 17:05:58 [INFO]: Epoch 064 - training loss: 0.7779, validation loss: 0.8743
2024-05-22 17:05:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch64_loss0.8743161559104919.pypots
2024-05-22 17:05:59 [INFO]: Epoch 065 - training loss: 0.7814, validation loss: 0.8718
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch65_loss0.8717707246541977.pypots
2024-05-22 17:05:59 [INFO]: Epoch 066 - training loss: 0.8018, validation loss: 0.8681
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch66_loss0.8680914789438248.pypots
2024-05-22 17:05:59 [INFO]: Epoch 067 - training loss: 0.7847, validation loss: 0.8694
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch67_loss0.8694178014993668.pypots
2024-05-22 17:05:59 [INFO]: Epoch 068 - training loss: 0.7582, validation loss: 0.8698
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch68_loss0.869806170463562.pypots
2024-05-22 17:05:59 [INFO]: Epoch 069 - training loss: 0.7664, validation loss: 0.8659
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch69_loss0.865885004401207.pypots
2024-05-22 17:05:59 [INFO]: Epoch 070 - training loss: 0.7677, validation loss: 0.8625
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch70_loss0.8624606132507324.pypots
2024-05-22 17:05:59 [INFO]: Epoch 071 - training loss: 0.7601, validation loss: 0.8632
2024-05-22 17:05:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch71_loss0.8631560951471329.pypots
2024-05-22 17:06:00 [INFO]: Epoch 072 - training loss: 0.7807, validation loss: 0.8639
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch72_loss0.8638972491025925.pypots
2024-05-22 17:06:00 [INFO]: Epoch 073 - training loss: 0.7801, validation loss: 0.8619
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch73_loss0.8618987947702408.pypots
2024-05-22 17:06:00 [INFO]: Epoch 074 - training loss: 0.7705, validation loss: 0.8624
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch74_loss0.8624259829521179.pypots
2024-05-22 17:06:00 [INFO]: Epoch 075 - training loss: 0.7602, validation loss: 0.8619
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch75_loss0.8619365245103836.pypots
2024-05-22 17:06:00 [INFO]: Epoch 076 - training loss: 0.7982, validation loss: 0.8622
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch76_loss0.8621993958950043.pypots
2024-05-22 17:06:00 [INFO]: Epoch 077 - training loss: 0.7756, validation loss: 0.8629
2024-05-22 17:06:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch77_loss0.8628983050584793.pypots
2024-05-22 17:06:01 [INFO]: Epoch 078 - training loss: 0.7675, validation loss: 0.8597
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch78_loss0.8596995323896408.pypots
2024-05-22 17:06:01 [INFO]: Epoch 079 - training loss: 0.7610, validation loss: 0.8578
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch79_loss0.8577980101108551.pypots
2024-05-22 17:06:01 [INFO]: Epoch 080 - training loss: 0.7815, validation loss: 0.8595
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch80_loss0.8595490753650665.pypots
2024-05-22 17:06:01 [INFO]: Epoch 081 - training loss: 0.7668, validation loss: 0.8596
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch81_loss0.8595717698335648.pypots
2024-05-22 17:06:01 [INFO]: Epoch 082 - training loss: 0.7791, validation loss: 0.8565
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch82_loss0.8565219938755035.pypots
2024-05-22 17:06:01 [INFO]: Epoch 083 - training loss: 0.7770, validation loss: 0.8566
2024-05-22 17:06:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch83_loss0.8565946072340012.pypots
2024-05-22 17:06:02 [INFO]: Epoch 084 - training loss: 0.7814, validation loss: 0.8572
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch84_loss0.8571853488683701.pypots
2024-05-22 17:06:02 [INFO]: Epoch 085 - training loss: 0.7787, validation loss: 0.8569
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch85_loss0.856915146112442.pypots
2024-05-22 17:06:02 [INFO]: Epoch 086 - training loss: 0.7611, validation loss: 0.8552
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch86_loss0.8551574796438217.pypots
2024-05-22 17:06:02 [INFO]: Epoch 087 - training loss: 0.7715, validation loss: 0.8580
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch87_loss0.8580418080091476.pypots
2024-05-22 17:06:02 [INFO]: Epoch 088 - training loss: 0.7518, validation loss: 0.8547
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch88_loss0.8547005355358124.pypots
2024-05-22 17:06:02 [INFO]: Epoch 089 - training loss: 0.7701, validation loss: 0.8545
2024-05-22 17:06:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch89_loss0.8544955104589462.pypots
2024-05-22 17:06:03 [INFO]: Epoch 090 - training loss: 0.7402, validation loss: 0.8571
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch90_loss0.8571131676435471.pypots
2024-05-22 17:06:03 [INFO]: Epoch 091 - training loss: 0.7778, validation loss: 0.8550
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch91_loss0.8549964725971222.pypots
2024-05-22 17:06:03 [INFO]: Epoch 092 - training loss: 0.7729, validation loss: 0.8504
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch92_loss0.8503578305244446.pypots
2024-05-22 17:06:03 [INFO]: Epoch 093 - training loss: 0.7564, validation loss: 0.8558
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch93_loss0.8558399826288223.pypots
2024-05-22 17:06:03 [INFO]: Epoch 094 - training loss: 0.7585, validation loss: 0.8532
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch94_loss0.8532402962446213.pypots
2024-05-22 17:06:03 [INFO]: Epoch 095 - training loss: 0.7656, validation loss: 0.8545
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch95_loss0.8545326590538025.pypots
2024-05-22 17:06:03 [INFO]: Epoch 096 - training loss: 0.7812, validation loss: 0.8494
2024-05-22 17:06:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch96_loss0.8494009226560593.pypots
2024-05-22 17:06:04 [INFO]: Epoch 097 - training loss: 0.7744, validation loss: 0.8494
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch97_loss0.8493531495332718.pypots
2024-05-22 17:06:04 [INFO]: Epoch 098 - training loss: 0.7643, validation loss: 0.8491
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch98_loss0.849065974354744.pypots
2024-05-22 17:06:04 [INFO]: Epoch 099 - training loss: 0.7624, validation loss: 0.8508
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch99_loss0.8508293926715851.pypots
2024-05-22 17:06:04 [INFO]: Epoch 100 - training loss: 0.7714, validation loss: 0.8519
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch100_loss0.851882666349411.pypots
2024-05-22 17:06:04 [INFO]: Epoch 101 - training loss: 0.7912, validation loss: 0.8534
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch101_loss0.8534305840730667.pypots
2024-05-22 17:06:04 [INFO]: Epoch 102 - training loss: 0.7590, validation loss: 0.8462
2024-05-22 17:06:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch102_loss0.8461783528327942.pypots
2024-05-22 17:06:05 [INFO]: Epoch 103 - training loss: 0.8090, validation loss: 0.8495
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch103_loss0.8495037406682968.pypots
2024-05-22 17:06:05 [INFO]: Epoch 104 - training loss: 0.7732, validation loss: 0.8440
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch104_loss0.8440288752317429.pypots
2024-05-22 17:06:05 [INFO]: Epoch 105 - training loss: 0.7635, validation loss: 0.8449
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch105_loss0.8449146300554276.pypots
2024-05-22 17:06:05 [INFO]: Epoch 106 - training loss: 0.7610, validation loss: 0.8459
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch106_loss0.8459490239620209.pypots
2024-05-22 17:06:05 [INFO]: Epoch 107 - training loss: 0.8074, validation loss: 0.8460
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch107_loss0.84598807990551.pypots
2024-05-22 17:06:05 [INFO]: Epoch 108 - training loss: 0.7781, validation loss: 0.8463
2024-05-22 17:06:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch108_loss0.8463262915611267.pypots
2024-05-22 17:06:06 [INFO]: Epoch 109 - training loss: 0.7666, validation loss: 0.8450
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch109_loss0.8450068086385727.pypots
2024-05-22 17:06:06 [INFO]: Epoch 110 - training loss: 0.7578, validation loss: 0.8431
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch110_loss0.8430754244327545.pypots
2024-05-22 17:06:06 [INFO]: Epoch 111 - training loss: 0.7454, validation loss: 0.8415
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch111_loss0.8415232300758362.pypots
2024-05-22 17:06:06 [INFO]: Epoch 112 - training loss: 0.7561, validation loss: 0.8428
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch112_loss0.8427897989749908.pypots
2024-05-22 17:06:06 [INFO]: Epoch 113 - training loss: 0.7695, validation loss: 0.8447
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch113_loss0.8446670323610306.pypots
2024-05-22 17:06:06 [INFO]: Epoch 114 - training loss: 0.7645, validation loss: 0.8401
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch114_loss0.8401121646165848.pypots
2024-05-22 17:06:06 [INFO]: Epoch 115 - training loss: 0.7574, validation loss: 0.8409
2024-05-22 17:06:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch115_loss0.8409370481967926.pypots
2024-05-22 17:06:07 [INFO]: Epoch 116 - training loss: 0.7637, validation loss: 0.8404
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch116_loss0.8403871953487396.pypots
2024-05-22 17:06:07 [INFO]: Epoch 117 - training loss: 0.7569, validation loss: 0.8403
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch117_loss0.8403417021036148.pypots
2024-05-22 17:06:07 [INFO]: Epoch 118 - training loss: 0.7606, validation loss: 0.8393
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch118_loss0.8393114060163498.pypots
2024-05-22 17:06:07 [INFO]: Epoch 119 - training loss: 0.7488, validation loss: 0.8361
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch119_loss0.8361018002033234.pypots
2024-05-22 17:06:07 [INFO]: Epoch 120 - training loss: 0.7697, validation loss: 0.8385
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch120_loss0.8385013490915298.pypots
2024-05-22 17:06:07 [INFO]: Epoch 121 - training loss: 0.7813, validation loss: 0.8352
2024-05-22 17:06:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch121_loss0.8351676315069199.pypots
2024-05-22 17:06:08 [INFO]: Epoch 122 - training loss: 0.7530, validation loss: 0.8366
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch122_loss0.8366290181875229.pypots
2024-05-22 17:06:08 [INFO]: Epoch 123 - training loss: 0.7419, validation loss: 0.8405
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch123_loss0.8404903560876846.pypots
2024-05-22 17:06:08 [INFO]: Epoch 124 - training loss: 0.7575, validation loss: 0.8340
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch124_loss0.8339735418558121.pypots
2024-05-22 17:06:08 [INFO]: Epoch 125 - training loss: 0.7876, validation loss: 0.8311
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch125_loss0.8311092406511307.pypots
2024-05-22 17:06:08 [INFO]: Epoch 126 - training loss: 0.7708, validation loss: 0.8302
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch126_loss0.8301510214805603.pypots
2024-05-22 17:06:08 [INFO]: Epoch 127 - training loss: 0.7651, validation loss: 0.8351
2024-05-22 17:06:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch127_loss0.8350687325000763.pypots
2024-05-22 17:06:09 [INFO]: Epoch 128 - training loss: 0.7672, validation loss: 0.8308
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch128_loss0.8308026343584061.pypots
2024-05-22 17:06:09 [INFO]: Epoch 129 - training loss: 0.7791, validation loss: 0.8338
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch129_loss0.8338369280099869.pypots
2024-05-22 17:06:09 [INFO]: Epoch 130 - training loss: 0.7465, validation loss: 0.8283
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch130_loss0.8283209055662155.pypots
2024-05-22 17:06:09 [INFO]: Epoch 131 - training loss: 0.8165, validation loss: 0.8315
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch131_loss0.8315268605947495.pypots
2024-05-22 17:06:09 [INFO]: Epoch 132 - training loss: 0.8007, validation loss: 0.8312
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch132_loss0.8312449157238007.pypots
2024-05-22 17:06:09 [INFO]: Epoch 133 - training loss: 0.8037, validation loss: 0.8283
2024-05-22 17:06:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch133_loss0.8283040225505829.pypots
2024-05-22 17:06:10 [INFO]: Epoch 134 - training loss: 0.7767, validation loss: 0.8305
2024-05-22 17:06:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch134_loss0.8304764777421951.pypots
2024-05-22 17:06:10 [INFO]: Epoch 135 - training loss: 0.7991, validation loss: 0.8250
2024-05-22 17:06:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch135_loss0.8250220417976379.pypots
2024-05-22 17:06:10 [INFO]: Epoch 136 - training loss: 0.7670, validation loss: 0.8251
2024-05-22 17:06:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch136_loss0.8251173943281174.pypots
2024-05-22 17:06:10 [INFO]: Epoch 137 - training loss: 0.7704, validation loss: 0.8247
2024-05-22 17:06:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch137_loss0.8246855735778809.pypots
2024-05-22 17:06:11 [INFO]: Epoch 138 - training loss: 0.7582, validation loss: 0.8294
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch138_loss0.8293837010860443.pypots
2024-05-22 17:06:11 [INFO]: Epoch 139 - training loss: 0.7547, validation loss: 0.8262
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch139_loss0.8261652886867523.pypots
2024-05-22 17:06:11 [INFO]: Epoch 140 - training loss: 0.7629, validation loss: 0.8291
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch140_loss0.8290638029575348.pypots
2024-05-22 17:06:11 [INFO]: Epoch 141 - training loss: 0.7496, validation loss: 0.8246
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch141_loss0.8246115446090698.pypots
2024-05-22 17:06:11 [INFO]: Epoch 142 - training loss: 0.7614, validation loss: 0.8255
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch142_loss0.8255445063114166.pypots
2024-05-22 17:06:11 [INFO]: Epoch 143 - training loss: 0.7683, validation loss: 0.8219
2024-05-22 17:06:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch143_loss0.8219152092933655.pypots
2024-05-22 17:06:12 [INFO]: Epoch 144 - training loss: 0.7624, validation loss: 0.8218
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch144_loss0.8217746019363403.pypots
2024-05-22 17:06:12 [INFO]: Epoch 145 - training loss: 0.7692, validation loss: 0.8225
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch145_loss0.8224665820598602.pypots
2024-05-22 17:06:12 [INFO]: Epoch 146 - training loss: 0.7537, validation loss: 0.8213
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch146_loss0.8213237822055817.pypots
2024-05-22 17:06:12 [INFO]: Epoch 147 - training loss: 0.7679, validation loss: 0.8291
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch147_loss0.8290693014860153.pypots
2024-05-22 17:06:12 [INFO]: Epoch 148 - training loss: 0.8103, validation loss: 0.8211
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch148_loss0.8210631459951401.pypots
2024-05-22 17:06:12 [INFO]: Epoch 149 - training loss: 0.7728, validation loss: 0.8200
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch149_loss0.8200029581785202.pypots
2024-05-22 17:06:12 [INFO]: Epoch 150 - training loss: 0.7372, validation loss: 0.8183
2024-05-22 17:06:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch150_loss0.8183192014694214.pypots
2024-05-22 17:06:13 [INFO]: Epoch 151 - training loss: 0.7483, validation loss: 0.8200
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch151_loss0.8199854791164398.pypots
2024-05-22 17:06:13 [INFO]: Epoch 152 - training loss: 0.7778, validation loss: 0.8216
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch152_loss0.8215950280427933.pypots
2024-05-22 17:06:13 [INFO]: Epoch 153 - training loss: 0.7517, validation loss: 0.8164
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch153_loss0.8163814842700958.pypots
2024-05-22 17:06:13 [INFO]: Epoch 154 - training loss: 0.7727, validation loss: 0.8172
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch154_loss0.8172387480735779.pypots
2024-05-22 17:06:13 [INFO]: Epoch 155 - training loss: 0.7728, validation loss: 0.8181
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch155_loss0.8180555105209351.pypots
2024-05-22 17:06:13 [INFO]: Epoch 156 - training loss: 0.7543, validation loss: 0.8173
2024-05-22 17:06:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch156_loss0.8173196911811829.pypots
2024-05-22 17:06:14 [INFO]: Epoch 157 - training loss: 0.7509, validation loss: 0.8174
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch157_loss0.817353218793869.pypots
2024-05-22 17:06:14 [INFO]: Epoch 158 - training loss: 0.7616, validation loss: 0.8186
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch158_loss0.8186103701591492.pypots
2024-05-22 17:06:14 [INFO]: Epoch 159 - training loss: 0.7607, validation loss: 0.8171
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch159_loss0.8171065300703049.pypots
2024-05-22 17:06:14 [INFO]: Epoch 160 - training loss: 0.7645, validation loss: 0.8172
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch160_loss0.8171958327293396.pypots
2024-05-22 17:06:14 [INFO]: Epoch 161 - training loss: 0.7621, validation loss: 0.8173
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch161_loss0.8172985017299652.pypots
2024-05-22 17:06:14 [INFO]: Epoch 162 - training loss: 0.7404, validation loss: 0.8148
2024-05-22 17:06:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch162_loss0.8148122429847717.pypots
2024-05-22 17:06:15 [INFO]: Epoch 163 - training loss: 0.7871, validation loss: 0.8131
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch163_loss0.8130830675363541.pypots
2024-05-22 17:06:15 [INFO]: Epoch 164 - training loss: 0.7770, validation loss: 0.8137
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch164_loss0.8137272298336029.pypots
2024-05-22 17:06:15 [INFO]: Epoch 165 - training loss: 0.7603, validation loss: 0.8135
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch165_loss0.8134619444608688.pypots
2024-05-22 17:06:15 [INFO]: Epoch 166 - training loss: 0.7416, validation loss: 0.8132
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch166_loss0.8132182359695435.pypots
2024-05-22 17:06:15 [INFO]: Epoch 167 - training loss: 0.7583, validation loss: 0.8123
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch167_loss0.812293291091919.pypots
2024-05-22 17:06:15 [INFO]: Epoch 168 - training loss: 0.7577, validation loss: 0.8121
2024-05-22 17:06:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch168_loss0.8121298104524612.pypots
2024-05-22 17:06:16 [INFO]: Epoch 169 - training loss: 0.7544, validation loss: 0.8131
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch169_loss0.8131207227706909.pypots
2024-05-22 17:06:16 [INFO]: Epoch 170 - training loss: 0.7389, validation loss: 0.8089
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch170_loss0.8088605105876923.pypots
2024-05-22 17:06:16 [INFO]: Epoch 171 - training loss: 0.7655, validation loss: 0.8174
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch171_loss0.817429319024086.pypots
2024-05-22 17:06:16 [INFO]: Epoch 172 - training loss: 0.7745, validation loss: 0.8137
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch172_loss0.8137202560901642.pypots
2024-05-22 17:06:16 [INFO]: Epoch 173 - training loss: 0.7405, validation loss: 0.8104
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch173_loss0.810416579246521.pypots
2024-05-22 17:06:16 [INFO]: Epoch 174 - training loss: 0.7584, validation loss: 0.8125
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch174_loss0.8125047087669373.pypots
2024-05-22 17:06:16 [INFO]: Epoch 175 - training loss: 0.7613, validation loss: 0.8072
2024-05-22 17:06:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch175_loss0.807218462228775.pypots
2024-05-22 17:06:17 [INFO]: Epoch 176 - training loss: 0.7609, validation loss: 0.8066
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch176_loss0.8065820634365082.pypots
2024-05-22 17:06:17 [INFO]: Epoch 177 - training loss: 0.7557, validation loss: 0.8111
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch177_loss0.8111290633678436.pypots
2024-05-22 17:06:17 [INFO]: Epoch 178 - training loss: 0.7716, validation loss: 0.8116
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch178_loss0.8115859478712082.pypots
2024-05-22 17:06:17 [INFO]: Epoch 179 - training loss: 0.7551, validation loss: 0.8062
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch179_loss0.8061698973178864.pypots
2024-05-22 17:06:17 [INFO]: Epoch 180 - training loss: 0.7432, validation loss: 0.8064
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch180_loss0.8063607513904572.pypots
2024-05-22 17:06:17 [INFO]: Epoch 181 - training loss: 0.7628, validation loss: 0.8080
2024-05-22 17:06:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch181_loss0.8080282807350159.pypots
2024-05-22 17:06:18 [INFO]: Epoch 182 - training loss: 0.7316, validation loss: 0.8069
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch182_loss0.8069116473197937.pypots
2024-05-22 17:06:18 [INFO]: Epoch 183 - training loss: 0.7571, validation loss: 0.8075
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch183_loss0.8075400143861771.pypots
2024-05-22 17:06:18 [INFO]: Epoch 184 - training loss: 0.7668, validation loss: 0.8057
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch184_loss0.8056654930114746.pypots
2024-05-22 17:06:18 [INFO]: Epoch 185 - training loss: 0.7646, validation loss: 0.8058
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch185_loss0.8058476150035858.pypots
2024-05-22 17:06:18 [INFO]: Epoch 186 - training loss: 0.7651, validation loss: 0.8043
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch186_loss0.8043076992034912.pypots
2024-05-22 17:06:18 [INFO]: Epoch 187 - training loss: 0.7699, validation loss: 0.8081
2024-05-22 17:06:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch187_loss0.8080772757530212.pypots
2024-05-22 17:06:19 [INFO]: Epoch 188 - training loss: 0.7721, validation loss: 0.8058
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch188_loss0.8057803958654404.pypots
2024-05-22 17:06:19 [INFO]: Epoch 189 - training loss: 0.7910, validation loss: 0.8062
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch189_loss0.8061904907226562.pypots
2024-05-22 17:06:19 [INFO]: Epoch 190 - training loss: 0.7422, validation loss: 0.8023
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch190_loss0.8022564500570297.pypots
2024-05-22 17:06:19 [INFO]: Epoch 191 - training loss: 0.7661, validation loss: 0.8025
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch191_loss0.8025401383638382.pypots
2024-05-22 17:06:19 [INFO]: Epoch 192 - training loss: 0.7601, validation loss: 0.8049
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch192_loss0.804895207285881.pypots
2024-05-22 17:06:19 [INFO]: Epoch 193 - training loss: 0.7655, validation loss: 0.8041
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch193_loss0.8040962666273117.pypots
2024-05-22 17:06:19 [INFO]: Epoch 194 - training loss: 0.7608, validation loss: 0.8039
2024-05-22 17:06:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch194_loss0.8039486110210419.pypots
2024-05-22 17:06:20 [INFO]: Epoch 195 - training loss: 0.7820, validation loss: 0.8024
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch195_loss0.8023750185966492.pypots
2024-05-22 17:06:20 [INFO]: Epoch 196 - training loss: 0.7540, validation loss: 0.8015
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch196_loss0.8014760613441467.pypots
2024-05-22 17:06:20 [INFO]: Epoch 197 - training loss: 0.7602, validation loss: 0.8023
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch197_loss0.802283987402916.pypots
2024-05-22 17:06:20 [INFO]: Epoch 198 - training loss: 0.7352, validation loss: 0.8012
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch198_loss0.8012293130159378.pypots
2024-05-22 17:06:20 [INFO]: Epoch 199 - training loss: 0.7454, validation loss: 0.8088
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch199_loss0.8087631165981293.pypots
2024-05-22 17:06:20 [INFO]: Epoch 200 - training loss: 0.7810, validation loss: 0.8029
2024-05-22 17:06:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch200_loss0.8028642535209656.pypots
2024-05-22 17:06:21 [INFO]: Epoch 201 - training loss: 0.7544, validation loss: 0.7989
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch201_loss0.798890694975853.pypots
2024-05-22 17:06:21 [INFO]: Epoch 202 - training loss: 0.7701, validation loss: 0.8017
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch202_loss0.8016667515039444.pypots
2024-05-22 17:06:21 [INFO]: Epoch 203 - training loss: 0.7427, validation loss: 0.7999
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch203_loss0.7999151200056076.pypots
2024-05-22 17:06:21 [INFO]: Epoch 204 - training loss: 0.7651, validation loss: 0.8012
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch204_loss0.8012384921312332.pypots
2024-05-22 17:06:21 [INFO]: Epoch 205 - training loss: 0.7584, validation loss: 0.8003
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch205_loss0.800346702337265.pypots
2024-05-22 17:06:21 [INFO]: Epoch 206 - training loss: 0.7684, validation loss: 0.7990
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch206_loss0.7990111410617828.pypots
2024-05-22 17:06:21 [INFO]: Epoch 207 - training loss: 0.7664, validation loss: 0.7995
2024-05-22 17:06:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch207_loss0.7994519472122192.pypots
2024-05-22 17:06:22 [INFO]: Epoch 208 - training loss: 0.7527, validation loss: 0.8018
2024-05-22 17:06:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch208_loss0.8017725795507431.pypots
2024-05-22 17:06:22 [INFO]: Epoch 209 - training loss: 0.7523, validation loss: 0.7978
2024-05-22 17:06:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch209_loss0.7977622747421265.pypots
2024-05-22 17:06:22 [INFO]: Epoch 210 - training loss: 0.7467, validation loss: 0.7982
2024-05-22 17:06:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch210_loss0.7982160747051239.pypots
2024-05-22 17:06:22 [INFO]: Epoch 211 - training loss: 0.7635, validation loss: 0.7993
2024-05-22 17:06:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch211_loss0.7992662042379379.pypots
2024-05-22 17:06:22 [INFO]: Epoch 212 - training loss: 0.7584, validation loss: 0.8003
2024-05-22 17:06:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch212_loss0.8002637326717377.pypots
2024-05-22 17:06:23 [INFO]: Epoch 213 - training loss: 0.7709, validation loss: 0.7994
2024-05-22 17:06:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch213_loss0.7994319498538971.pypots
2024-05-22 17:06:23 [INFO]: Epoch 214 - training loss: 0.7649, validation loss: 0.7978
2024-05-22 17:06:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch214_loss0.7977944314479828.pypots
2024-05-22 17:06:23 [INFO]: Epoch 215 - training loss: 0.7763, validation loss: 0.8003
2024-05-22 17:06:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch215_loss0.8003267347812653.pypots
2024-05-22 17:06:23 [INFO]: Epoch 216 - training loss: 0.7576, validation loss: 0.7993
2024-05-22 17:06:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch216_loss0.7993112355470657.pypots
2024-05-22 17:06:23 [INFO]: Epoch 217 - training loss: 0.7587, validation loss: 0.7980
2024-05-22 17:06:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch217_loss0.7979546338319778.pypots
2024-05-22 17:06:24 [INFO]: Epoch 218 - training loss: 0.7661, validation loss: 0.7947
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch218_loss0.7946608513593674.pypots
2024-05-22 17:06:24 [INFO]: Epoch 219 - training loss: 0.7756, validation loss: 0.7974
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch219_loss0.7974115312099457.pypots
2024-05-22 17:06:24 [INFO]: Epoch 220 - training loss: 0.7427, validation loss: 0.7965
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch220_loss0.7965216785669327.pypots
2024-05-22 17:06:24 [INFO]: Epoch 221 - training loss: 0.7678, validation loss: 0.7954
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch221_loss0.7953854948282242.pypots
2024-05-22 17:06:24 [INFO]: Epoch 222 - training loss: 0.7361, validation loss: 0.7979
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch222_loss0.7979487776756287.pypots
2024-05-22 17:06:24 [INFO]: Epoch 223 - training loss: 0.7512, validation loss: 0.7963
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch223_loss0.7963130325078964.pypots
2024-05-22 17:06:24 [INFO]: Epoch 224 - training loss: 0.7354, validation loss: 0.7963
2024-05-22 17:06:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch224_loss0.7963401973247528.pypots
2024-05-22 17:06:25 [INFO]: Epoch 225 - training loss: 0.7473, validation loss: 0.8026
2024-05-22 17:06:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch225_loss0.8025759011507034.pypots
2024-05-22 17:06:25 [INFO]: Epoch 226 - training loss: 0.7591, validation loss: 0.7994
2024-05-22 17:06:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch226_loss0.7994372248649597.pypots
2024-05-22 17:06:25 [INFO]: Epoch 227 - training loss: 0.7447, validation loss: 0.7962
2024-05-22 17:06:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch227_loss0.796226903796196.pypots
2024-05-22 17:06:25 [INFO]: Epoch 228 - training loss: 0.7703, validation loss: 0.7973
2024-05-22 17:06:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN_epoch228_loss0.7972821742296219.pypots
2024-05-22 17:06:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:06:25 [INFO]: Finished training. The best model is from epoch#218.
2024-05-22 17:06:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/20240522_T170547/MRNN.pypots
2024-05-22 17:06:25 [INFO]: MRNN on ETTm1: MAE=0.5925, MSE=0.9819
2024-05-22 17:06:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-22 17:06:25 [INFO]: Using the given device: cpu
2024-05-22 17:06:25 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 17:06:25 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-22 17:06:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-22 17:06:25 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 17:06:25 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-22 17:06:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-22 17:06:25 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 17:06:25 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-22 17:06:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-22 17:06:25 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 17:06:25 [INFO]: Using the given device: cuda:0
2024-05-22 17:06:25 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/SAITS_ettm1/20240522_T170625
2024-05-22 17:06:25 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/SAITS_ettm1/20240522_T170625/tensorboard
2024-05-22 17:06:25 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 17:06:26 [INFO]: Epoch 001 - training loss: 1.1822, validation loss: 0.2828
2024-05-22 17:06:26 [INFO]: Epoch 002 - training loss: 0.8421, validation loss: 0.1466
2024-05-22 17:06:27 [INFO]: Epoch 003 - training loss: 0.7267, validation loss: 0.1428
2024-05-22 17:06:27 [INFO]: Epoch 004 - training loss: 0.6638, validation loss: 0.0901
2024-05-22 17:06:28 [INFO]: Epoch 005 - training loss: 0.6313, validation loss: 0.1035
2024-05-22 17:06:28 [INFO]: Epoch 006 - training loss: 0.5843, validation loss: 0.0790
2024-05-22 17:06:29 [INFO]: Epoch 007 - training loss: 0.5717, validation loss: 0.0902
2024-05-22 17:06:29 [INFO]: Epoch 008 - training loss: 0.5551, validation loss: 0.0713
2024-05-22 17:06:30 [INFO]: Epoch 009 - training loss: 0.5615, validation loss: 0.0733
2024-05-22 17:06:30 [INFO]: Epoch 010 - training loss: 0.5518, validation loss: 0.0688
2024-05-22 17:06:31 [INFO]: Epoch 011 - training loss: 0.5260, validation loss: 0.0805
2024-05-22 17:06:31 [INFO]: Epoch 012 - training loss: 0.5114, validation loss: 0.0658
2024-05-22 17:06:32 [INFO]: Epoch 013 - training loss: 0.5060, validation loss: 0.0655
2024-05-22 17:06:32 [INFO]: Epoch 014 - training loss: 0.4871, validation loss: 0.0612
2024-05-22 17:06:33 [INFO]: Epoch 015 - training loss: 0.4919, validation loss: 0.0581
2024-05-22 17:06:33 [INFO]: Epoch 016 - training loss: 0.4851, validation loss: 0.0488
2024-05-22 17:06:34 [INFO]: Epoch 017 - training loss: 0.4806, validation loss: 0.0595
2024-05-22 17:06:34 [INFO]: Epoch 018 - training loss: 0.4730, validation loss: 0.0467
2024-05-22 17:06:35 [INFO]: Epoch 019 - training loss: 0.4463, validation loss: 0.0435
2024-05-22 17:06:35 [INFO]: Epoch 020 - training loss: 0.4426, validation loss: 0.0507
2024-05-22 17:06:36 [INFO]: Epoch 021 - training loss: 0.4607, validation loss: 0.0507
2024-05-22 17:06:36 [INFO]: Epoch 022 - training loss: 0.4434, validation loss: 0.0375
2024-05-22 17:06:37 [INFO]: Epoch 023 - training loss: 0.4363, validation loss: 0.0612
2024-05-22 17:06:37 [INFO]: Epoch 024 - training loss: 0.4294, validation loss: 0.0465
2024-05-22 17:06:38 [INFO]: Epoch 025 - training loss: 0.4172, validation loss: 0.0431
2024-05-22 17:06:38 [INFO]: Epoch 026 - training loss: 0.4414, validation loss: 0.0593
2024-05-22 17:06:39 [INFO]: Epoch 027 - training loss: 0.4297, validation loss: 0.0502
2024-05-22 17:06:39 [INFO]: Epoch 028 - training loss: 0.4260, validation loss: 0.0386
2024-05-22 17:06:40 [INFO]: Epoch 029 - training loss: 0.4042, validation loss: 0.0464
2024-05-22 17:06:40 [INFO]: Epoch 030 - training loss: 0.4088, validation loss: 0.0414
2024-05-22 17:06:41 [INFO]: Epoch 031 - training loss: 0.3891, validation loss: 0.0375
2024-05-22 17:06:41 [INFO]: Epoch 032 - training loss: 0.3933, validation loss: 0.0396
2024-05-22 17:06:42 [INFO]: Epoch 033 - training loss: 0.3835, validation loss: 0.0702
2024-05-22 17:06:43 [INFO]: Epoch 034 - training loss: 0.3830, validation loss: 0.0355
2024-05-22 17:06:43 [INFO]: Epoch 035 - training loss: 0.3770, validation loss: 0.0485
2024-05-22 17:06:43 [INFO]: Epoch 036 - training loss: 0.3706, validation loss: 0.0366
2024-05-22 17:06:44 [INFO]: Epoch 037 - training loss: 0.3749, validation loss: 0.0314
2024-05-22 17:06:45 [INFO]: Epoch 038 - training loss: 0.4010, validation loss: 0.0444
2024-05-22 17:06:45 [INFO]: Epoch 039 - training loss: 0.4041, validation loss: 0.0555
2024-05-22 17:06:46 [INFO]: Epoch 040 - training loss: 0.3859, validation loss: 0.0411
2024-05-22 17:06:46 [INFO]: Epoch 041 - training loss: 0.3787, validation loss: 0.0423
2024-05-22 17:06:47 [INFO]: Epoch 042 - training loss: 0.3658, validation loss: 0.0420
2024-05-22 17:06:47 [INFO]: Epoch 043 - training loss: 0.3559, validation loss: 0.0360
2024-05-22 17:06:48 [INFO]: Epoch 044 - training loss: 0.3499, validation loss: 0.0436
2024-05-22 17:06:48 [INFO]: Epoch 045 - training loss: 0.3567, validation loss: 0.0358
2024-05-22 17:06:48 [INFO]: Epoch 046 - training loss: 0.3416, validation loss: 0.0328
2024-05-22 17:06:49 [INFO]: Epoch 047 - training loss: 0.3538, validation loss: 0.0455
2024-05-22 17:06:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:06:49 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 17:06:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/SAITS_ettm1/20240522_T170625/SAITS.pypots
2024-05-22 17:06:49 [INFO]: SAITS on ETTm1: MAE=0.1634, MSE=0.0553
2024-05-22 17:06:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-22 17:06:49 [INFO]: Using the given device: cuda:0
2024-05-22 17:06:49 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/Transformer_ettm1/20240522_T170649
2024-05-22 17:06:49 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/Transformer_ettm1/20240522_T170649/tensorboard
2024-05-22 17:06:49 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 17:06:49 [INFO]: Epoch 001 - training loss: 1.2657, validation loss: 0.3223
2024-05-22 17:06:50 [INFO]: Epoch 002 - training loss: 0.7615, validation loss: 0.1652
2024-05-22 17:06:50 [INFO]: Epoch 003 - training loss: 0.6142, validation loss: 0.1221
2024-05-22 17:06:50 [INFO]: Epoch 004 - training loss: 0.5419, validation loss: 0.0924
2024-05-22 17:06:50 [INFO]: Epoch 005 - training loss: 0.4974, validation loss: 0.0743
2024-05-22 17:06:50 [INFO]: Epoch 006 - training loss: 0.4717, validation loss: 0.0652
2024-05-22 17:06:51 [INFO]: Epoch 007 - training loss: 0.4486, validation loss: 0.0692
2024-05-22 17:06:51 [INFO]: Epoch 008 - training loss: 0.4252, validation loss: 0.0607
2024-05-22 17:06:51 [INFO]: Epoch 009 - training loss: 0.4108, validation loss: 0.0565
2024-05-22 17:06:51 [INFO]: Epoch 010 - training loss: 0.3938, validation loss: 0.0550
2024-05-22 17:06:51 [INFO]: Epoch 011 - training loss: 0.3900, validation loss: 0.0513
2024-05-22 17:06:52 [INFO]: Epoch 012 - training loss: 0.3828, validation loss: 0.0536
2024-05-22 17:06:52 [INFO]: Epoch 013 - training loss: 0.3675, validation loss: 0.0488
2024-05-22 17:06:52 [INFO]: Epoch 014 - training loss: 0.3631, validation loss: 0.0507
2024-05-22 17:06:52 [INFO]: Epoch 015 - training loss: 0.3609, validation loss: 0.0490
2024-05-22 17:06:52 [INFO]: Epoch 016 - training loss: 0.3566, validation loss: 0.0414
2024-05-22 17:06:53 [INFO]: Epoch 017 - training loss: 0.3429, validation loss: 0.0454
2024-05-22 17:06:53 [INFO]: Epoch 018 - training loss: 0.3349, validation loss: 0.0432
2024-05-22 17:06:53 [INFO]: Epoch 019 - training loss: 0.3364, validation loss: 0.0469
2024-05-22 17:06:53 [INFO]: Epoch 020 - training loss: 0.3386, validation loss: 0.0414
2024-05-22 17:06:54 [INFO]: Epoch 021 - training loss: 0.3262, validation loss: 0.0383
2024-05-22 17:06:54 [INFO]: Epoch 022 - training loss: 0.3158, validation loss: 0.0411
2024-05-22 17:06:54 [INFO]: Epoch 023 - training loss: 0.3170, validation loss: 0.0364
2024-05-22 17:06:54 [INFO]: Epoch 024 - training loss: 0.3175, validation loss: 0.0412
2024-05-22 17:06:55 [INFO]: Epoch 025 - training loss: 0.3072, validation loss: 0.0348
2024-05-22 17:06:55 [INFO]: Epoch 026 - training loss: 0.3029, validation loss: 0.0358
2024-05-22 17:06:55 [INFO]: Epoch 027 - training loss: 0.3021, validation loss: 0.0365
2024-05-22 17:06:55 [INFO]: Epoch 028 - training loss: 0.2919, validation loss: 0.0372
2024-05-22 17:06:55 [INFO]: Epoch 029 - training loss: 0.2903, validation loss: 0.0344
2024-05-22 17:06:56 [INFO]: Epoch 030 - training loss: 0.2902, validation loss: 0.0349
2024-05-22 17:06:56 [INFO]: Epoch 031 - training loss: 0.2848, validation loss: 0.0393
2024-05-22 17:06:56 [INFO]: Epoch 032 - training loss: 0.2864, validation loss: 0.0361
2024-05-22 17:06:56 [INFO]: Epoch 033 - training loss: 0.2825, validation loss: 0.0321
2024-05-22 17:06:56 [INFO]: Epoch 034 - training loss: 0.2800, validation loss: 0.0343
2024-05-22 17:06:57 [INFO]: Epoch 035 - training loss: 0.2832, validation loss: 0.0303
2024-05-22 17:06:57 [INFO]: Epoch 036 - training loss: 0.2801, validation loss: 0.0349
2024-05-22 17:06:57 [INFO]: Epoch 037 - training loss: 0.2772, validation loss: 0.0288
2024-05-22 17:06:57 [INFO]: Epoch 038 - training loss: 0.2622, validation loss: 0.0325
2024-05-22 17:06:57 [INFO]: Epoch 039 - training loss: 0.2671, validation loss: 0.0288
2024-05-22 17:06:58 [INFO]: Epoch 040 - training loss: 0.2648, validation loss: 0.0306
2024-05-22 17:06:58 [INFO]: Epoch 041 - training loss: 0.2607, validation loss: 0.0277
2024-05-22 17:06:58 [INFO]: Epoch 042 - training loss: 0.2584, validation loss: 0.0284
2024-05-22 17:06:58 [INFO]: Epoch 043 - training loss: 0.2520, validation loss: 0.0282
2024-05-22 17:06:58 [INFO]: Epoch 044 - training loss: 0.2546, validation loss: 0.0260
2024-05-22 17:06:59 [INFO]: Epoch 045 - training loss: 0.2481, validation loss: 0.0328
2024-05-22 17:06:59 [INFO]: Epoch 046 - training loss: 0.2533, validation loss: 0.0257
2024-05-22 17:06:59 [INFO]: Epoch 047 - training loss: 0.2475, validation loss: 0.0270
2024-05-22 17:06:59 [INFO]: Epoch 048 - training loss: 0.2479, validation loss: 0.0271
2024-05-22 17:06:59 [INFO]: Epoch 049 - training loss: 0.2447, validation loss: 0.0276
2024-05-22 17:07:00 [INFO]: Epoch 050 - training loss: 0.2413, validation loss: 0.0326
2024-05-22 17:07:00 [INFO]: Epoch 051 - training loss: 0.2462, validation loss: 0.0262
2024-05-22 17:07:00 [INFO]: Epoch 052 - training loss: 0.2381, validation loss: 0.0272
2024-05-22 17:07:00 [INFO]: Epoch 053 - training loss: 0.2420, validation loss: 0.0250
2024-05-22 17:07:01 [INFO]: Epoch 054 - training loss: 0.2406, validation loss: 0.0305
2024-05-22 17:07:01 [INFO]: Epoch 055 - training loss: 0.2376, validation loss: 0.0327
2024-05-22 17:07:01 [INFO]: Epoch 056 - training loss: 0.2379, validation loss: 0.0299
2024-05-22 17:07:01 [INFO]: Epoch 057 - training loss: 0.2516, validation loss: 0.0282
2024-05-22 17:07:01 [INFO]: Epoch 058 - training loss: 0.2375, validation loss: 0.0241
2024-05-22 17:07:02 [INFO]: Epoch 059 - training loss: 0.2312, validation loss: 0.0248
2024-05-22 17:07:02 [INFO]: Epoch 060 - training loss: 0.2270, validation loss: 0.0258
2024-05-22 17:07:02 [INFO]: Epoch 061 - training loss: 0.2303, validation loss: 0.0245
2024-05-22 17:07:02 [INFO]: Epoch 062 - training loss: 0.2271, validation loss: 0.0241
2024-05-22 17:07:02 [INFO]: Epoch 063 - training loss: 0.2265, validation loss: 0.0231
2024-05-22 17:07:03 [INFO]: Epoch 064 - training loss: 0.2220, validation loss: 0.0224
2024-05-22 17:07:03 [INFO]: Epoch 065 - training loss: 0.2201, validation loss: 0.0224
2024-05-22 17:07:03 [INFO]: Epoch 066 - training loss: 0.2159, validation loss: 0.0217
2024-05-22 17:07:03 [INFO]: Epoch 067 - training loss: 0.2175, validation loss: 0.0220
2024-05-22 17:07:03 [INFO]: Epoch 068 - training loss: 0.2172, validation loss: 0.0231
2024-05-22 17:07:04 [INFO]: Epoch 069 - training loss: 0.2202, validation loss: 0.0256
2024-05-22 17:07:04 [INFO]: Epoch 070 - training loss: 0.2199, validation loss: 0.0266
2024-05-22 17:07:04 [INFO]: Epoch 071 - training loss: 0.2150, validation loss: 0.0269
2024-05-22 17:07:04 [INFO]: Epoch 072 - training loss: 0.2191, validation loss: 0.0217
2024-05-22 17:07:04 [INFO]: Epoch 073 - training loss: 0.2203, validation loss: 0.0225
2024-05-22 17:07:05 [INFO]: Epoch 074 - training loss: 0.2170, validation loss: 0.0248
2024-05-22 17:07:05 [INFO]: Epoch 075 - training loss: 0.2166, validation loss: 0.0309
2024-05-22 17:07:05 [INFO]: Epoch 076 - training loss: 0.2262, validation loss: 0.0269
2024-05-22 17:07:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:07:05 [INFO]: Finished training. The best model is from epoch#66.
2024-05-22 17:07:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/Transformer_ettm1/20240522_T170649/Transformer.pypots
2024-05-22 17:07:05 [INFO]: Transformer on ETTm1: MAE=0.1328, MSE=0.0340
2024-05-22 17:07:05 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-22 17:07:05 [INFO]: Using the given device: cuda:0
2024-05-22 17:07:05 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_ettm1/20240522_T170705
2024-05-22 17:07:05 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_ettm1/20240522_T170705/tensorboard
2024-05-22 17:07:05 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 17:07:05 [INFO]: Epoch 001 - training loss: 0.1688, validation loss: 0.0598
2024-05-22 17:07:06 [INFO]: Epoch 002 - training loss: 0.0737, validation loss: 0.0412
2024-05-22 17:07:06 [INFO]: Epoch 003 - training loss: 0.0609, validation loss: 0.0347
2024-05-22 17:07:06 [INFO]: Epoch 004 - training loss: 0.0516, validation loss: 0.0329
2024-05-22 17:07:06 [INFO]: Epoch 005 - training loss: 0.0513, validation loss: 0.0312
2024-05-22 17:07:06 [INFO]: Epoch 006 - training loss: 0.0504, validation loss: 0.0321
2024-05-22 17:07:07 [INFO]: Epoch 007 - training loss: 0.0482, validation loss: 0.0297
2024-05-22 17:07:07 [INFO]: Epoch 008 - training loss: 0.0464, validation loss: 0.0312
2024-05-22 17:07:07 [INFO]: Epoch 009 - training loss: 0.0545, validation loss: 0.0319
2024-05-22 17:07:07 [INFO]: Epoch 010 - training loss: 0.0467, validation loss: 0.0306
2024-05-22 17:07:07 [INFO]: Epoch 011 - training loss: 0.0459, validation loss: 0.0300
2024-05-22 17:07:08 [INFO]: Epoch 012 - training loss: 0.0450, validation loss: 0.0305
2024-05-22 17:07:08 [INFO]: Epoch 013 - training loss: 0.0449, validation loss: 0.0289
2024-05-22 17:07:08 [INFO]: Epoch 014 - training loss: 0.0473, validation loss: 0.0303
2024-05-22 17:07:08 [INFO]: Epoch 015 - training loss: 0.0456, validation loss: 0.0294
2024-05-22 17:07:09 [INFO]: Epoch 016 - training loss: 0.0447, validation loss: 0.0287
2024-05-22 17:07:09 [INFO]: Epoch 017 - training loss: 0.0436, validation loss: 0.0276
2024-05-22 17:07:09 [INFO]: Epoch 018 - training loss: 0.0428, validation loss: 0.0304
2024-05-22 17:07:09 [INFO]: Epoch 019 - training loss: 0.0448, validation loss: 0.0298
2024-05-22 17:07:10 [INFO]: Epoch 020 - training loss: 0.0449, validation loss: 0.0307
2024-05-22 17:07:10 [INFO]: Epoch 021 - training loss: 0.0460, validation loss: 0.0269
2024-05-22 17:07:10 [INFO]: Epoch 022 - training loss: 0.0439, validation loss: 0.0312
2024-05-22 17:07:10 [INFO]: Epoch 023 - training loss: 0.0476, validation loss: 0.0315
2024-05-22 17:07:10 [INFO]: Epoch 024 - training loss: 0.0421, validation loss: 0.0298
2024-05-22 17:07:10 [INFO]: Epoch 025 - training loss: 0.0415, validation loss: 0.0268
2024-05-22 17:07:11 [INFO]: Epoch 026 - training loss: 0.0410, validation loss: 0.0265
2024-05-22 17:07:11 [INFO]: Epoch 027 - training loss: 0.0401, validation loss: 0.0258
2024-05-22 17:07:11 [INFO]: Epoch 028 - training loss: 0.0409, validation loss: 0.0287
2024-05-22 17:07:11 [INFO]: Epoch 029 - training loss: 0.0414, validation loss: 0.0268
2024-05-22 17:07:11 [INFO]: Epoch 030 - training loss: 0.0423, validation loss: 0.0277
2024-05-22 17:07:12 [INFO]: Epoch 031 - training loss: 0.0397, validation loss: 0.0275
2024-05-22 17:07:12 [INFO]: Epoch 032 - training loss: 0.0393, validation loss: 0.0254
2024-05-22 17:07:12 [INFO]: Epoch 033 - training loss: 0.0401, validation loss: 0.0256
2024-05-22 17:07:12 [INFO]: Epoch 034 - training loss: 0.0393, validation loss: 0.0263
2024-05-22 17:07:12 [INFO]: Epoch 035 - training loss: 0.0377, validation loss: 0.0248
2024-05-22 17:07:13 [INFO]: Epoch 036 - training loss: 0.0370, validation loss: 0.0247
2024-05-22 17:07:13 [INFO]: Epoch 037 - training loss: 0.0378, validation loss: 0.0264
2024-05-22 17:07:13 [INFO]: Epoch 038 - training loss: 0.0409, validation loss: 0.0257
2024-05-22 17:07:13 [INFO]: Epoch 039 - training loss: 0.0379, validation loss: 0.0254
2024-05-22 17:07:13 [INFO]: Epoch 040 - training loss: 0.0372, validation loss: 0.0237
2024-05-22 17:07:14 [INFO]: Epoch 041 - training loss: 0.0384, validation loss: 0.0256
2024-05-22 17:07:14 [INFO]: Epoch 042 - training loss: 0.0384, validation loss: 0.0287
2024-05-22 17:07:14 [INFO]: Epoch 043 - training loss: 0.0403, validation loss: 0.0295
2024-05-22 17:07:14 [INFO]: Epoch 044 - training loss: 0.0391, validation loss: 0.0261
2024-05-22 17:07:14 [INFO]: Epoch 045 - training loss: 0.0372, validation loss: 0.0242
2024-05-22 17:07:15 [INFO]: Epoch 046 - training loss: 0.0353, validation loss: 0.0240
2024-05-22 17:07:15 [INFO]: Epoch 047 - training loss: 0.0367, validation loss: 0.0247
2024-05-22 17:07:15 [INFO]: Epoch 048 - training loss: 0.0404, validation loss: 0.0269
2024-05-22 17:07:15 [INFO]: Epoch 049 - training loss: 0.0419, validation loss: 0.0238
2024-05-22 17:07:15 [INFO]: Epoch 050 - training loss: 0.0372, validation loss: 0.0241
2024-05-22 17:07:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:07:15 [INFO]: Finished training. The best model is from epoch#40.
2024-05-22 17:07:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/TimesNet_ettm1/20240522_T170705/TimesNet.pypots
2024-05-22 17:07:16 [INFO]: TimesNet on ETTm1: MAE=0.1120, MSE=0.0268
2024-05-22 17:07:16 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-22 17:07:16 [INFO]: Using the given device: cuda:0
2024-05-22 17:07:16 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716
2024-05-22 17:07:16 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/tensorboard
2024-05-22 17:07:16 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 17:07:18 [INFO]: Epoch 001 - training loss: 0.6922, validation loss: 0.4540
2024-05-22 17:07:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch1_loss0.4539799913764.pypots
2024-05-22 17:07:20 [INFO]: Epoch 002 - training loss: 0.3944, validation loss: 0.3839
2024-05-22 17:07:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch2_loss0.3839026689529419.pypots
2024-05-22 17:07:22 [INFO]: Epoch 003 - training loss: 0.3419, validation loss: 0.3373
2024-05-22 17:07:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch3_loss0.3373376801609993.pypots
2024-05-22 17:07:24 [INFO]: Epoch 004 - training loss: 0.3292, validation loss: 0.3646
2024-05-22 17:07:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch4_loss0.3645779564976692.pypots
2024-05-22 17:07:26 [INFO]: Epoch 005 - training loss: 0.3407, validation loss: 0.3009
2024-05-22 17:07:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch5_loss0.30089959502220154.pypots
2024-05-22 17:07:28 [INFO]: Epoch 006 - training loss: 0.2664, validation loss: 0.2954
2024-05-22 17:07:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch6_loss0.2953675016760826.pypots
2024-05-22 17:07:30 [INFO]: Epoch 007 - training loss: 0.3262, validation loss: 0.3082
2024-05-22 17:07:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch7_loss0.3081936463713646.pypots
2024-05-22 17:07:32 [INFO]: Epoch 008 - training loss: 0.3053, validation loss: 0.3019
2024-05-22 17:07:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch8_loss0.3019031062722206.pypots
2024-05-22 17:07:34 [INFO]: Epoch 009 - training loss: 0.2778, validation loss: 0.2990
2024-05-22 17:07:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch9_loss0.29904282093048096.pypots
2024-05-22 17:07:36 [INFO]: Epoch 010 - training loss: 0.2859, validation loss: 0.2726
2024-05-22 17:07:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch10_loss0.2726368308067322.pypots
2024-05-22 17:07:38 [INFO]: Epoch 011 - training loss: 0.3122, validation loss: 0.2746
2024-05-22 17:07:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch11_loss0.2746334448456764.pypots
2024-05-22 17:07:40 [INFO]: Epoch 012 - training loss: 0.2373, validation loss: 0.2518
2024-05-22 17:07:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch12_loss0.2517817057669163.pypots
2024-05-22 17:07:42 [INFO]: Epoch 013 - training loss: 0.2519, validation loss: 0.2383
2024-05-22 17:07:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch13_loss0.23830688744783401.pypots
2024-05-22 17:07:45 [INFO]: Epoch 014 - training loss: 0.2903, validation loss: 0.2418
2024-05-22 17:07:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch14_loss0.2417895533144474.pypots
2024-05-22 17:07:47 [INFO]: Epoch 015 - training loss: 0.2646, validation loss: 0.2751
2024-05-22 17:07:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch15_loss0.275149330496788.pypots
2024-05-22 17:07:49 [INFO]: Epoch 016 - training loss: 0.2634, validation loss: 0.2397
2024-05-22 17:07:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch16_loss0.2396916225552559.pypots
2024-05-22 17:07:51 [INFO]: Epoch 017 - training loss: 0.2510, validation loss: 0.2328
2024-05-22 17:07:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch17_loss0.2327898144721985.pypots
2024-05-22 17:07:53 [INFO]: Epoch 018 - training loss: 0.2186, validation loss: 0.2244
2024-05-22 17:07:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch18_loss0.22444071248173714.pypots
2024-05-22 17:07:55 [INFO]: Epoch 019 - training loss: 0.2182, validation loss: 0.2324
2024-05-22 17:07:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch19_loss0.23237106576561928.pypots
2024-05-22 17:07:57 [INFO]: Epoch 020 - training loss: 0.2654, validation loss: 0.2129
2024-05-22 17:07:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch20_loss0.21285240352153778.pypots
2024-05-22 17:07:59 [INFO]: Epoch 021 - training loss: 0.2217, validation loss: 0.2032
2024-05-22 17:07:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch21_loss0.2031579725444317.pypots
2024-05-22 17:08:01 [INFO]: Epoch 022 - training loss: 0.2070, validation loss: 0.1902
2024-05-22 17:08:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch22_loss0.19022797420620918.pypots
2024-05-22 17:08:03 [INFO]: Epoch 023 - training loss: 0.2913, validation loss: 0.1861
2024-05-22 17:08:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch23_loss0.18612323328852654.pypots
2024-05-22 17:08:05 [INFO]: Epoch 024 - training loss: 0.1959, validation loss: 0.1840
2024-05-22 17:08:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch24_loss0.18397338688373566.pypots
2024-05-22 17:08:07 [INFO]: Epoch 025 - training loss: 0.2627, validation loss: 0.1920
2024-05-22 17:08:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch25_loss0.19201837852597237.pypots
2024-05-22 17:08:09 [INFO]: Epoch 026 - training loss: 0.2119, validation loss: 0.1843
2024-05-22 17:08:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch26_loss0.1843235120177269.pypots
2024-05-22 17:08:11 [INFO]: Epoch 027 - training loss: 0.1998, validation loss: 0.1881
2024-05-22 17:08:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch27_loss0.18813304230570793.pypots
2024-05-22 17:08:13 [INFO]: Epoch 028 - training loss: 0.2304, validation loss: 0.1804
2024-05-22 17:08:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch28_loss0.1803552582859993.pypots
2024-05-22 17:08:15 [INFO]: Epoch 029 - training loss: 0.1788, validation loss: 0.1716
2024-05-22 17:08:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch29_loss0.17162908241152763.pypots
2024-05-22 17:08:18 [INFO]: Epoch 030 - training loss: 0.2018, validation loss: 0.1709
2024-05-22 17:08:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch30_loss0.17093370109796524.pypots
2024-05-22 17:08:20 [INFO]: Epoch 031 - training loss: 0.2021, validation loss: 0.1878
2024-05-22 17:08:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch31_loss0.1878393553197384.pypots
2024-05-22 17:08:22 [INFO]: Epoch 032 - training loss: 0.1760, validation loss: 0.1699
2024-05-22 17:08:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch32_loss0.16991843283176422.pypots
2024-05-22 17:08:24 [INFO]: Epoch 033 - training loss: 0.2379, validation loss: 0.1650
2024-05-22 17:08:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch33_loss0.16498208045959473.pypots
2024-05-22 17:08:26 [INFO]: Epoch 034 - training loss: 0.1938, validation loss: 0.1615
2024-05-22 17:08:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch34_loss0.1615024246275425.pypots
2024-05-22 17:08:28 [INFO]: Epoch 035 - training loss: 0.1642, validation loss: 0.1600
2024-05-22 17:08:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch35_loss0.15995805338025093.pypots
2024-05-22 17:08:30 [INFO]: Epoch 036 - training loss: 0.1799, validation loss: 0.1659
2024-05-22 17:08:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch36_loss0.16589143499732018.pypots
2024-05-22 17:08:32 [INFO]: Epoch 037 - training loss: 0.1735, validation loss: 0.1768
2024-05-22 17:08:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch37_loss0.17682215943932533.pypots
2024-05-22 17:08:34 [INFO]: Epoch 038 - training loss: 0.1689, validation loss: 0.1613
2024-05-22 17:08:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch38_loss0.16133923828601837.pypots
2024-05-22 17:08:36 [INFO]: Epoch 039 - training loss: 0.1626, validation loss: 0.1571
2024-05-22 17:08:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch39_loss0.15709293633699417.pypots
2024-05-22 17:08:38 [INFO]: Epoch 040 - training loss: 0.1782, validation loss: 0.1544
2024-05-22 17:08:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch40_loss0.15442461892962456.pypots
2024-05-22 17:08:40 [INFO]: Epoch 041 - training loss: 0.1641, validation loss: 0.1520
2024-05-22 17:08:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch41_loss0.15201640129089355.pypots
2024-05-22 17:08:42 [INFO]: Epoch 042 - training loss: 0.1584, validation loss: 0.1524
2024-05-22 17:08:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch42_loss0.15240443497896194.pypots
2024-05-22 17:08:44 [INFO]: Epoch 043 - training loss: 0.1862, validation loss: 0.1514
2024-05-22 17:08:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch43_loss0.15138725191354752.pypots
2024-05-22 17:08:46 [INFO]: Epoch 044 - training loss: 0.1732, validation loss: 0.1496
2024-05-22 17:08:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch44_loss0.1496385782957077.pypots
2024-05-22 17:08:49 [INFO]: Epoch 045 - training loss: 0.1656, validation loss: 0.1512
2024-05-22 17:08:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch45_loss0.15119241178035736.pypots
2024-05-22 17:08:51 [INFO]: Epoch 046 - training loss: 0.1715, validation loss: 0.1444
2024-05-22 17:08:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch46_loss0.14444159716367722.pypots
2024-05-22 17:08:53 [INFO]: Epoch 047 - training loss: 0.1641, validation loss: 0.1438
2024-05-22 17:08:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch47_loss0.14380909875035286.pypots
2024-05-22 17:08:55 [INFO]: Epoch 048 - training loss: 0.2042, validation loss: 0.1471
2024-05-22 17:08:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch48_loss0.14707818627357483.pypots
2024-05-22 17:08:57 [INFO]: Epoch 049 - training loss: 0.1889, validation loss: 0.1574
2024-05-22 17:08:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch49_loss0.15737108513712883.pypots
2024-05-22 17:08:59 [INFO]: Epoch 050 - training loss: 0.1958, validation loss: 0.1601
2024-05-22 17:08:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch50_loss0.1600782498717308.pypots
2024-05-22 17:09:01 [INFO]: Epoch 051 - training loss: 0.1751, validation loss: 0.1579
2024-05-22 17:09:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch51_loss0.1578991562128067.pypots
2024-05-22 17:09:03 [INFO]: Epoch 052 - training loss: 0.1614, validation loss: 0.1460
2024-05-22 17:09:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch52_loss0.1460445411503315.pypots
2024-05-22 17:09:05 [INFO]: Epoch 053 - training loss: 0.1839, validation loss: 0.1413
2024-05-22 17:09:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch53_loss0.14134875312447548.pypots
2024-05-22 17:09:07 [INFO]: Epoch 054 - training loss: 0.1757, validation loss: 0.1421
2024-05-22 17:09:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch54_loss0.14207950979471207.pypots
2024-05-22 17:09:09 [INFO]: Epoch 055 - training loss: 0.1478, validation loss: 0.1457
2024-05-22 17:09:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch55_loss0.14572390541434288.pypots
2024-05-22 17:09:11 [INFO]: Epoch 056 - training loss: 0.1753, validation loss: 0.1378
2024-05-22 17:09:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch56_loss0.13782508298754692.pypots
2024-05-22 17:09:13 [INFO]: Epoch 057 - training loss: 0.1501, validation loss: 0.1372
2024-05-22 17:09:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch57_loss0.13721203058958054.pypots
2024-05-22 17:09:15 [INFO]: Epoch 058 - training loss: 0.1711, validation loss: 0.1372
2024-05-22 17:09:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch58_loss0.13722217082977295.pypots
2024-05-22 17:09:17 [INFO]: Epoch 059 - training loss: 0.2051, validation loss: 0.1462
2024-05-22 17:09:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch59_loss0.14620622992515564.pypots
2024-05-22 17:09:19 [INFO]: Epoch 060 - training loss: 0.1638, validation loss: 0.1359
2024-05-22 17:09:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch60_loss0.13594874739646912.pypots
2024-05-22 17:09:22 [INFO]: Epoch 061 - training loss: 0.1643, validation loss: 0.1362
2024-05-22 17:09:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch61_loss0.13617544248700142.pypots
2024-05-22 17:09:24 [INFO]: Epoch 062 - training loss: 0.1646, validation loss: 0.1358
2024-05-22 17:09:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch62_loss0.13577887415885925.pypots
2024-05-22 17:09:26 [INFO]: Epoch 063 - training loss: 0.1551, validation loss: 0.1357
2024-05-22 17:09:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch63_loss0.13573851436376572.pypots
2024-05-22 17:09:28 [INFO]: Epoch 064 - training loss: 0.1889, validation loss: 0.1343
2024-05-22 17:09:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch64_loss0.1343189850449562.pypots
2024-05-22 17:09:30 [INFO]: Epoch 065 - training loss: 0.1539, validation loss: 0.1385
2024-05-22 17:09:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch65_loss0.13850565254688263.pypots
2024-05-22 17:09:32 [INFO]: Epoch 066 - training loss: 0.1763, validation loss: 0.1402
2024-05-22 17:09:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch66_loss0.14022379368543625.pypots
2024-05-22 17:09:34 [INFO]: Epoch 067 - training loss: 0.1687, validation loss: 0.1306
2024-05-22 17:09:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch67_loss0.1305817998945713.pypots
2024-05-22 17:09:36 [INFO]: Epoch 068 - training loss: 0.1549, validation loss: 0.1322
2024-05-22 17:09:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch68_loss0.13221237994730473.pypots
2024-05-22 17:09:38 [INFO]: Epoch 069 - training loss: 0.1746, validation loss: 0.1342
2024-05-22 17:09:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch69_loss0.13423340022563934.pypots
2024-05-22 17:09:40 [INFO]: Epoch 070 - training loss: 0.1635, validation loss: 0.1361
2024-05-22 17:09:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch70_loss0.13605565577745438.pypots
2024-05-22 17:09:42 [INFO]: Epoch 071 - training loss: 0.1461, validation loss: 0.1312
2024-05-22 17:09:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch71_loss0.13124779053032398.pypots
2024-05-22 17:09:44 [INFO]: Epoch 072 - training loss: 0.1722, validation loss: 0.1306
2024-05-22 17:09:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch72_loss0.13056859374046326.pypots
2024-05-22 17:09:46 [INFO]: Epoch 073 - training loss: 0.1629, validation loss: 0.1340
2024-05-22 17:09:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch73_loss0.13403630815446377.pypots
2024-05-22 17:09:48 [INFO]: Epoch 074 - training loss: 0.1605, validation loss: 0.1302
2024-05-22 17:09:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch74_loss0.13022904098033905.pypots
2024-05-22 17:09:50 [INFO]: Epoch 075 - training loss: 0.1581, validation loss: 0.1278
2024-05-22 17:09:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch75_loss0.12775354832410812.pypots
2024-05-22 17:09:52 [INFO]: Epoch 076 - training loss: 0.1675, validation loss: 0.1315
2024-05-22 17:09:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch76_loss0.1315240003168583.pypots
2024-05-22 17:09:55 [INFO]: Epoch 077 - training loss: 0.1554, validation loss: 0.1315
2024-05-22 17:09:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch77_loss0.1315400842577219.pypots
2024-05-22 17:09:57 [INFO]: Epoch 078 - training loss: 0.1833, validation loss: 0.1258
2024-05-22 17:09:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch78_loss0.12583906389772892.pypots
2024-05-22 17:09:59 [INFO]: Epoch 079 - training loss: 0.1523, validation loss: 0.1246
2024-05-22 17:09:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch79_loss0.12459767051041126.pypots
2024-05-22 17:10:01 [INFO]: Epoch 080 - training loss: 0.1540, validation loss: 0.1275
2024-05-22 17:10:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch80_loss0.12750297971069813.pypots
2024-05-22 17:10:03 [INFO]: Epoch 081 - training loss: 0.1375, validation loss: 0.1263
2024-05-22 17:10:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch81_loss0.1262577846646309.pypots
2024-05-22 17:10:05 [INFO]: Epoch 082 - training loss: 0.1587, validation loss: 0.1263
2024-05-22 17:10:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch82_loss0.12626943178474903.pypots
2024-05-22 17:10:07 [INFO]: Epoch 083 - training loss: 0.1477, validation loss: 0.1259
2024-05-22 17:10:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch83_loss0.12588143907487392.pypots
2024-05-22 17:10:09 [INFO]: Epoch 084 - training loss: 0.1676, validation loss: 0.1293
2024-05-22 17:10:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch84_loss0.12931833416223526.pypots
2024-05-22 17:10:11 [INFO]: Epoch 085 - training loss: 0.1880, validation loss: 0.1274
2024-05-22 17:10:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch85_loss0.12738093361258507.pypots
2024-05-22 17:10:13 [INFO]: Epoch 086 - training loss: 0.1294, validation loss: 0.1309
2024-05-22 17:10:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch86_loss0.1308960933238268.pypots
2024-05-22 17:10:15 [INFO]: Epoch 087 - training loss: 0.1624, validation loss: 0.1280
2024-05-22 17:10:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch87_loss0.12801474332809448.pypots
2024-05-22 17:10:17 [INFO]: Epoch 088 - training loss: 0.1517, validation loss: 0.1288
2024-05-22 17:10:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch88_loss0.12875371240079403.pypots
2024-05-22 17:10:19 [INFO]: Epoch 089 - training loss: 0.1418, validation loss: 0.1262
2024-05-22 17:10:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI_epoch89_loss0.12617351487278938.pypots
2024-05-22 17:10:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:10:19 [INFO]: Finished training. The best model is from epoch#79.
2024-05-22 17:10:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/20240522_T170716/CSDI.pypots
2024-05-22 17:10:35 [INFO]: CSDI on ETTm1: MAE=0.1247, MSE=0.0420
2024-05-22 17:10:35 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-22 17:10:35 [INFO]: Using the given device: cuda:0
2024-05-22 17:10:35 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_ettm1/20240522_T171035
2024-05-22 17:10:35 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_ettm1/20240522_T171035/tensorboard
2024-05-22 17:10:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 17:10:35 [INFO]: Epoch 001 - training loss: 23624.0349, validation loss: 0.9788
2024-05-22 17:10:35 [INFO]: Epoch 002 - training loss: 21335.9905, validation loss: 0.9749
2024-05-22 17:10:35 [INFO]: Epoch 003 - training loss: 19446.4023, validation loss: 0.9651
2024-05-22 17:10:36 [INFO]: Epoch 004 - training loss: 17143.7775, validation loss: 0.9474
2024-05-22 17:10:36 [INFO]: Epoch 005 - training loss: 15336.6501, validation loss: 0.9071
2024-05-22 17:10:36 [INFO]: Epoch 006 - training loss: 13727.5601, validation loss: 0.8129
2024-05-22 17:10:36 [INFO]: Epoch 007 - training loss: 12575.1862, validation loss: 0.6746
2024-05-22 17:10:36 [INFO]: Epoch 008 - training loss: 11801.9251, validation loss: 0.5512
2024-05-22 17:10:36 [INFO]: Epoch 009 - training loss: 11318.2192, validation loss: 0.5043
2024-05-22 17:10:36 [INFO]: Epoch 010 - training loss: 10906.4118, validation loss: 0.4849
2024-05-22 17:10:36 [INFO]: Epoch 011 - training loss: 10615.0952, validation loss: 0.4744
2024-05-22 17:10:36 [INFO]: Epoch 012 - training loss: 10414.3557, validation loss: 0.4620
2024-05-22 17:10:37 [INFO]: Epoch 013 - training loss: 10244.3343, validation loss: 0.4449
2024-05-22 17:10:37 [INFO]: Epoch 014 - training loss: 10062.9628, validation loss: 0.4277
2024-05-22 17:10:37 [INFO]: Epoch 015 - training loss: 9992.0267, validation loss: 0.4051
2024-05-22 17:10:37 [INFO]: Epoch 016 - training loss: 9876.7404, validation loss: 0.3678
2024-05-22 17:10:37 [INFO]: Epoch 017 - training loss: 9822.9112, validation loss: 0.3434
2024-05-22 17:10:37 [INFO]: Epoch 018 - training loss: 9772.2263, validation loss: 0.3267
2024-05-22 17:10:37 [INFO]: Epoch 019 - training loss: 9748.7281, validation loss: 0.3097
2024-05-22 17:10:37 [INFO]: Epoch 020 - training loss: 9675.5793, validation loss: 0.3003
2024-05-22 17:10:38 [INFO]: Epoch 021 - training loss: 9642.0889, validation loss: 0.2934
2024-05-22 17:10:38 [INFO]: Epoch 022 - training loss: 9620.4119, validation loss: 0.2837
2024-05-22 17:10:38 [INFO]: Epoch 023 - training loss: 9607.7261, validation loss: 0.2722
2024-05-22 17:10:38 [INFO]: Epoch 024 - training loss: 9572.2927, validation loss: 0.2726
2024-05-22 17:10:38 [INFO]: Epoch 025 - training loss: 9567.0026, validation loss: 0.2651
2024-05-22 17:10:38 [INFO]: Epoch 026 - training loss: 9536.1558, validation loss: 0.2625
2024-05-22 17:10:38 [INFO]: Epoch 027 - training loss: 9528.9296, validation loss: 0.2548
2024-05-22 17:10:38 [INFO]: Epoch 028 - training loss: 9500.4559, validation loss: 0.2508
2024-05-22 17:10:38 [INFO]: Epoch 029 - training loss: 9479.2094, validation loss: 0.2457
2024-05-22 17:10:39 [INFO]: Epoch 030 - training loss: 9482.2137, validation loss: 0.2419
2024-05-22 17:10:39 [INFO]: Epoch 031 - training loss: 9463.9667, validation loss: 0.2365
2024-05-22 17:10:39 [INFO]: Epoch 032 - training loss: 9445.3638, validation loss: 0.2309
2024-05-22 17:10:39 [INFO]: Epoch 033 - training loss: 9445.0758, validation loss: 0.2255
2024-05-22 17:10:39 [INFO]: Epoch 034 - training loss: 9428.2928, validation loss: 0.2210
2024-05-22 17:10:39 [INFO]: Epoch 035 - training loss: 9420.2205, validation loss: 0.2159
2024-05-22 17:10:39 [INFO]: Epoch 036 - training loss: 9421.3157, validation loss: 0.2081
2024-05-22 17:10:39 [INFO]: Epoch 037 - training loss: 9413.5790, validation loss: 0.2059
2024-05-22 17:10:40 [INFO]: Epoch 038 - training loss: 9407.4023, validation loss: 0.2029
2024-05-22 17:10:40 [INFO]: Epoch 039 - training loss: 9397.3406, validation loss: 0.1982
2024-05-22 17:10:40 [INFO]: Epoch 040 - training loss: 9395.2192, validation loss: 0.1942
2024-05-22 17:10:40 [INFO]: Epoch 041 - training loss: 9384.5762, validation loss: 0.1886
2024-05-22 17:10:40 [INFO]: Epoch 042 - training loss: 9382.6669, validation loss: 0.1860
2024-05-22 17:10:40 [INFO]: Epoch 043 - training loss: 9379.0574, validation loss: 0.1809
2024-05-22 17:10:40 [INFO]: Epoch 044 - training loss: 9381.6628, validation loss: 0.1766
2024-05-22 17:10:40 [INFO]: Epoch 045 - training loss: 9369.0306, validation loss: 0.1737
2024-05-22 17:10:40 [INFO]: Epoch 046 - training loss: 9365.2052, validation loss: 0.1713
2024-05-22 17:10:41 [INFO]: Epoch 047 - training loss: 9365.7122, validation loss: 0.1666
2024-05-22 17:10:41 [INFO]: Epoch 048 - training loss: 9365.7468, validation loss: 0.1597
2024-05-22 17:10:41 [INFO]: Epoch 049 - training loss: 9354.4039, validation loss: 0.1560
2024-05-22 17:10:41 [INFO]: Epoch 050 - training loss: 9352.7187, validation loss: 0.1548
2024-05-22 17:10:41 [INFO]: Epoch 051 - training loss: 9365.6028, validation loss: 0.1516
2024-05-22 17:10:41 [INFO]: Epoch 052 - training loss: 9344.2528, validation loss: 0.1474
2024-05-22 17:10:41 [INFO]: Epoch 053 - training loss: 9341.9588, validation loss: 0.1438
2024-05-22 17:10:41 [INFO]: Epoch 054 - training loss: 9345.0838, validation loss: 0.1428
2024-05-22 17:10:41 [INFO]: Epoch 055 - training loss: 9337.5610, validation loss: 0.1387
2024-05-22 17:10:42 [INFO]: Epoch 056 - training loss: 9333.3105, validation loss: 0.1384
2024-05-22 17:10:42 [INFO]: Epoch 057 - training loss: 9332.0401, validation loss: 0.1353
2024-05-22 17:10:42 [INFO]: Epoch 058 - training loss: 9332.8388, validation loss: 0.1344
2024-05-22 17:10:42 [INFO]: Epoch 059 - training loss: 9329.6973, validation loss: 0.1310
2024-05-22 17:10:42 [INFO]: Epoch 060 - training loss: 9326.2892, validation loss: 0.1322
2024-05-22 17:10:42 [INFO]: Epoch 061 - training loss: 9324.3735, validation loss: 0.1328
2024-05-22 17:10:42 [INFO]: Epoch 062 - training loss: 9321.8055, validation loss: 0.1281
2024-05-22 17:10:42 [INFO]: Epoch 063 - training loss: 9322.8255, validation loss: 0.1271
2024-05-22 17:10:42 [INFO]: Epoch 064 - training loss: 9321.0194, validation loss: 0.1260
2024-05-22 17:10:42 [INFO]: Epoch 065 - training loss: 9319.6152, validation loss: 0.1246
2024-05-22 17:10:43 [INFO]: Epoch 066 - training loss: 9319.6749, validation loss: 0.1221
2024-05-22 17:10:43 [INFO]: Epoch 067 - training loss: 9318.3179, validation loss: 0.1240
2024-05-22 17:10:43 [INFO]: Epoch 068 - training loss: 9317.3580, validation loss: 0.1217
2024-05-22 17:10:43 [INFO]: Epoch 069 - training loss: 9313.7737, validation loss: 0.1210
2024-05-22 17:10:43 [INFO]: Epoch 070 - training loss: 9313.4769, validation loss: 0.1195
2024-05-22 17:10:43 [INFO]: Epoch 071 - training loss: 9313.8687, validation loss: 0.1193
2024-05-22 17:10:43 [INFO]: Epoch 072 - training loss: 9309.3304, validation loss: 0.1185
2024-05-22 17:10:43 [INFO]: Epoch 073 - training loss: 9307.4141, validation loss: 0.1184
2024-05-22 17:10:43 [INFO]: Epoch 074 - training loss: 9307.7990, validation loss: 0.1170
2024-05-22 17:10:44 [INFO]: Epoch 075 - training loss: 9308.0464, validation loss: 0.1162
2024-05-22 17:10:44 [INFO]: Epoch 076 - training loss: 9306.0132, validation loss: 0.1171
2024-05-22 17:10:44 [INFO]: Epoch 077 - training loss: 9316.6895, validation loss: 0.1152
2024-05-22 17:10:44 [INFO]: Epoch 078 - training loss: 9305.1731, validation loss: 0.1141
2024-05-22 17:10:44 [INFO]: Epoch 079 - training loss: 9305.7642, validation loss: 0.1131
2024-05-22 17:10:44 [INFO]: Epoch 080 - training loss: 9305.6100, validation loss: 0.1125
2024-05-22 17:10:44 [INFO]: Epoch 081 - training loss: 9301.3685, validation loss: 0.1126
2024-05-22 17:10:44 [INFO]: Epoch 082 - training loss: 9303.3500, validation loss: 0.1119
2024-05-22 17:10:45 [INFO]: Epoch 083 - training loss: 9300.8232, validation loss: 0.1093
2024-05-22 17:10:45 [INFO]: Epoch 084 - training loss: 9301.7443, validation loss: 0.1090
2024-05-22 17:10:45 [INFO]: Epoch 085 - training loss: 9298.8022, validation loss: 0.1103
2024-05-22 17:10:45 [INFO]: Epoch 086 - training loss: 9300.1077, validation loss: 0.1090
2024-05-22 17:10:45 [INFO]: Epoch 087 - training loss: 9299.7749, validation loss: 0.1092
2024-05-22 17:10:45 [INFO]: Epoch 088 - training loss: 9298.4744, validation loss: 0.1109
2024-05-22 17:10:45 [INFO]: Epoch 089 - training loss: 9298.4213, validation loss: 0.1082
2024-05-22 17:10:45 [INFO]: Epoch 090 - training loss: 9297.0325, validation loss: 0.1067
2024-05-22 17:10:46 [INFO]: Epoch 091 - training loss: 9295.3759, validation loss: 0.1077
2024-05-22 17:10:46 [INFO]: Epoch 092 - training loss: 9294.6562, validation loss: 0.1068
2024-05-22 17:10:46 [INFO]: Epoch 093 - training loss: 9294.3649, validation loss: 0.1047
2024-05-22 17:10:46 [INFO]: Epoch 094 - training loss: 9295.1588, validation loss: 0.1046
2024-05-22 17:10:46 [INFO]: Epoch 095 - training loss: 9293.8726, validation loss: 0.1042
2024-05-22 17:10:46 [INFO]: Epoch 096 - training loss: 9294.4114, validation loss: 0.1033
2024-05-22 17:10:46 [INFO]: Epoch 097 - training loss: 9293.0192, validation loss: 0.1035
2024-05-22 17:10:46 [INFO]: Epoch 098 - training loss: 9292.2308, validation loss: 0.1028
2024-05-22 17:10:46 [INFO]: Epoch 099 - training loss: 9293.1065, validation loss: 0.1034
2024-05-22 17:10:47 [INFO]: Epoch 100 - training loss: 9290.7621, validation loss: 0.1022
2024-05-22 17:10:47 [INFO]: Epoch 101 - training loss: 9290.2639, validation loss: 0.1024
2024-05-22 17:10:47 [INFO]: Epoch 102 - training loss: 9293.9653, validation loss: 0.1007
2024-05-22 17:10:47 [INFO]: Epoch 103 - training loss: 9292.6025, validation loss: 0.1012
2024-05-22 17:10:47 [INFO]: Epoch 104 - training loss: 9289.7659, validation loss: 0.1007
2024-05-22 17:10:47 [INFO]: Epoch 105 - training loss: 9290.0848, validation loss: 0.0998
2024-05-22 17:10:47 [INFO]: Epoch 106 - training loss: 9288.6986, validation loss: 0.1002
2024-05-22 17:10:47 [INFO]: Epoch 107 - training loss: 9288.8252, validation loss: 0.0983
2024-05-22 17:10:47 [INFO]: Epoch 108 - training loss: 9288.1363, validation loss: 0.0989
2024-05-22 17:10:48 [INFO]: Epoch 109 - training loss: 9289.4635, validation loss: 0.0962
2024-05-22 17:10:48 [INFO]: Epoch 110 - training loss: 9289.4076, validation loss: 0.0969
2024-05-22 17:10:48 [INFO]: Epoch 111 - training loss: 9287.5283, validation loss: 0.0975
2024-05-22 17:10:48 [INFO]: Epoch 112 - training loss: 9287.6934, validation loss: 0.0972
2024-05-22 17:10:48 [INFO]: Epoch 113 - training loss: 9285.7441, validation loss: 0.0962
2024-05-22 17:10:48 [INFO]: Epoch 114 - training loss: 9285.8475, validation loss: 0.0955
2024-05-22 17:10:48 [INFO]: Epoch 115 - training loss: 9288.4402, validation loss: 0.0946
2024-05-22 17:10:48 [INFO]: Epoch 116 - training loss: 9287.2339, validation loss: 0.0990
2024-05-22 17:10:48 [INFO]: Epoch 117 - training loss: 9290.7734, validation loss: 0.0958
2024-05-22 17:10:49 [INFO]: Epoch 118 - training loss: 9287.4711, validation loss: 0.0931
2024-05-22 17:10:49 [INFO]: Epoch 119 - training loss: 9286.4156, validation loss: 0.0948
2024-05-22 17:10:49 [INFO]: Epoch 120 - training loss: 9284.7756, validation loss: 0.0936
2024-05-22 17:10:49 [INFO]: Epoch 121 - training loss: 9284.8496, validation loss: 0.0926
2024-05-22 17:10:49 [INFO]: Epoch 122 - training loss: 9282.9087, validation loss: 0.0926
2024-05-22 17:10:49 [INFO]: Epoch 123 - training loss: 9283.2637, validation loss: 0.0944
2024-05-22 17:10:49 [INFO]: Epoch 124 - training loss: 9283.4014, validation loss: 0.0917
2024-05-22 17:10:49 [INFO]: Epoch 125 - training loss: 9285.2122, validation loss: 0.0911
2024-05-22 17:10:49 [INFO]: Epoch 126 - training loss: 9284.9865, validation loss: 0.0901
2024-05-22 17:10:50 [INFO]: Epoch 127 - training loss: 9283.0159, validation loss: 0.0924
2024-05-22 17:10:50 [INFO]: Epoch 128 - training loss: 9283.4170, validation loss: 0.0914
2024-05-22 17:10:50 [INFO]: Epoch 129 - training loss: 9282.9339, validation loss: 0.0894
2024-05-22 17:10:50 [INFO]: Epoch 130 - training loss: 9282.0381, validation loss: 0.0911
2024-05-22 17:10:50 [INFO]: Epoch 131 - training loss: 9281.6332, validation loss: 0.0901
2024-05-22 17:10:50 [INFO]: Epoch 132 - training loss: 9281.1908, validation loss: 0.0907
2024-05-22 17:10:50 [INFO]: Epoch 133 - training loss: 9283.6368, validation loss: 0.0892
2024-05-22 17:10:50 [INFO]: Epoch 134 - training loss: 9279.2149, validation loss: 0.0905
2024-05-22 17:10:50 [INFO]: Epoch 135 - training loss: 9280.8755, validation loss: 0.0879
2024-05-22 17:10:50 [INFO]: Epoch 136 - training loss: 9281.8842, validation loss: 0.0896
2024-05-22 17:10:51 [INFO]: Epoch 137 - training loss: 9280.9508, validation loss: 0.0878
2024-05-22 17:10:51 [INFO]: Epoch 138 - training loss: 9280.0096, validation loss: 0.0882
2024-05-22 17:10:51 [INFO]: Epoch 139 - training loss: 9280.5563, validation loss: 0.0862
2024-05-22 17:10:51 [INFO]: Epoch 140 - training loss: 9281.8275, validation loss: 0.0875
2024-05-22 17:10:51 [INFO]: Epoch 141 - training loss: 9279.3608, validation loss: 0.0871
2024-05-22 17:10:51 [INFO]: Epoch 142 - training loss: 9279.6907, validation loss: 0.0875
2024-05-22 17:10:51 [INFO]: Epoch 143 - training loss: 9279.3950, validation loss: 0.0865
2024-05-22 17:10:51 [INFO]: Epoch 144 - training loss: 9281.9431, validation loss: 0.0857
2024-05-22 17:10:51 [INFO]: Epoch 145 - training loss: 9278.1848, validation loss: 0.0870
2024-05-22 17:10:52 [INFO]: Epoch 146 - training loss: 9279.1754, validation loss: 0.0860
2024-05-22 17:10:52 [INFO]: Epoch 147 - training loss: 9280.1020, validation loss: 0.0861
2024-05-22 17:10:52 [INFO]: Epoch 148 - training loss: 9279.0868, validation loss: 0.0866
2024-05-22 17:10:52 [INFO]: Epoch 149 - training loss: 9277.6359, validation loss: 0.0869
2024-05-22 17:10:52 [INFO]: Epoch 150 - training loss: 9279.7739, validation loss: 0.0855
2024-05-22 17:10:52 [INFO]: Epoch 151 - training loss: 9278.3658, validation loss: 0.0838
2024-05-22 17:10:52 [INFO]: Epoch 152 - training loss: 9277.5439, validation loss: 0.0835
2024-05-22 17:10:53 [INFO]: Epoch 153 - training loss: 9278.3857, validation loss: 0.0852
2024-05-22 17:10:53 [INFO]: Epoch 154 - training loss: 9276.8826, validation loss: 0.0836
2024-05-22 17:10:53 [INFO]: Epoch 155 - training loss: 9278.0240, validation loss: 0.0831
2024-05-22 17:10:53 [INFO]: Epoch 156 - training loss: 9278.2113, validation loss: 0.0842
2024-05-22 17:10:53 [INFO]: Epoch 157 - training loss: 9276.7144, validation loss: 0.0836
2024-05-22 17:10:53 [INFO]: Epoch 158 - training loss: 9276.9305, validation loss: 0.0827
2024-05-22 17:10:53 [INFO]: Epoch 159 - training loss: 9276.3248, validation loss: 0.0823
2024-05-22 17:10:54 [INFO]: Epoch 160 - training loss: 9276.4218, validation loss: 0.0846
2024-05-22 17:10:54 [INFO]: Epoch 161 - training loss: 9277.2676, validation loss: 0.0837
2024-05-22 17:10:54 [INFO]: Epoch 162 - training loss: 9278.3696, validation loss: 0.0815
2024-05-22 17:10:54 [INFO]: Epoch 163 - training loss: 9277.2880, validation loss: 0.0815
2024-05-22 17:10:54 [INFO]: Epoch 164 - training loss: 9276.6393, validation loss: 0.0835
2024-05-22 17:10:54 [INFO]: Epoch 165 - training loss: 9275.5471, validation loss: 0.0810
2024-05-22 17:10:54 [INFO]: Epoch 166 - training loss: 9275.6924, validation loss: 0.0819
2024-05-22 17:10:54 [INFO]: Epoch 167 - training loss: 9274.6928, validation loss: 0.0814
2024-05-22 17:10:54 [INFO]: Epoch 168 - training loss: 9276.4138, validation loss: 0.0814
2024-05-22 17:10:55 [INFO]: Epoch 169 - training loss: 9276.0609, validation loss: 0.0796
2024-05-22 17:10:55 [INFO]: Epoch 170 - training loss: 9276.6013, validation loss: 0.0857
2024-05-22 17:10:55 [INFO]: Epoch 171 - training loss: 9276.0936, validation loss: 0.0835
2024-05-22 17:10:55 [INFO]: Epoch 172 - training loss: 9276.6135, validation loss: 0.0819
2024-05-22 17:10:55 [INFO]: Epoch 173 - training loss: 9275.4941, validation loss: 0.0796
2024-05-22 17:10:55 [INFO]: Epoch 174 - training loss: 9275.8944, validation loss: 0.0792
2024-05-22 17:10:55 [INFO]: Epoch 175 - training loss: 9274.8511, validation loss: 0.0807
2024-05-22 17:10:55 [INFO]: Epoch 176 - training loss: 9276.3393, validation loss: 0.0813
2024-05-22 17:10:55 [INFO]: Epoch 177 - training loss: 9274.7701, validation loss: 0.0790
2024-05-22 17:10:56 [INFO]: Epoch 178 - training loss: 9275.3948, validation loss: 0.0802
2024-05-22 17:10:56 [INFO]: Epoch 179 - training loss: 9276.1404, validation loss: 0.0790
2024-05-22 17:10:56 [INFO]: Epoch 180 - training loss: 9275.9449, validation loss: 0.0793
2024-05-22 17:10:56 [INFO]: Epoch 181 - training loss: 9274.4387, validation loss: 0.0803
2024-05-22 17:10:56 [INFO]: Epoch 182 - training loss: 9275.1357, validation loss: 0.0806
2024-05-22 17:10:56 [INFO]: Epoch 183 - training loss: 9274.3552, validation loss: 0.0785
2024-05-22 17:10:56 [INFO]: Epoch 184 - training loss: 9274.6133, validation loss: 0.0809
2024-05-22 17:10:56 [INFO]: Epoch 185 - training loss: 9274.6053, validation loss: 0.0805
2024-05-22 17:10:56 [INFO]: Epoch 186 - training loss: 9275.7964, validation loss: 0.0799
2024-05-22 17:10:57 [INFO]: Epoch 187 - training loss: 9274.6218, validation loss: 0.0791
2024-05-22 17:10:57 [INFO]: Epoch 188 - training loss: 9272.9578, validation loss: 0.0794
2024-05-22 17:10:57 [INFO]: Epoch 189 - training loss: 9274.1751, validation loss: 0.0777
2024-05-22 17:10:57 [INFO]: Epoch 190 - training loss: 9274.3302, validation loss: 0.0798
2024-05-22 17:10:57 [INFO]: Epoch 191 - training loss: 9273.7030, validation loss: 0.0782
2024-05-22 17:10:57 [INFO]: Epoch 192 - training loss: 9277.2313, validation loss: 0.0773
2024-05-22 17:10:57 [INFO]: Epoch 193 - training loss: 9273.0767, validation loss: 0.0804
2024-05-22 17:10:57 [INFO]: Epoch 194 - training loss: 9276.1860, validation loss: 0.0782
2024-05-22 17:10:57 [INFO]: Epoch 195 - training loss: 9273.5852, validation loss: 0.0782
2024-05-22 17:10:58 [INFO]: Epoch 196 - training loss: 9274.3022, validation loss: 0.0763
2024-05-22 17:10:58 [INFO]: Epoch 197 - training loss: 9273.1190, validation loss: 0.0791
2024-05-22 17:10:58 [INFO]: Epoch 198 - training loss: 9273.3090, validation loss: 0.0788
2024-05-22 17:10:58 [INFO]: Epoch 199 - training loss: 9273.1804, validation loss: 0.0798
2024-05-22 17:10:58 [INFO]: Epoch 200 - training loss: 9272.6769, validation loss: 0.0774
2024-05-22 17:10:58 [INFO]: Epoch 201 - training loss: 9273.4262, validation loss: 0.0761
2024-05-22 17:10:58 [INFO]: Epoch 202 - training loss: 9274.3090, validation loss: 0.0755
2024-05-22 17:10:58 [INFO]: Epoch 203 - training loss: 9272.5779, validation loss: 0.0775
2024-05-22 17:10:58 [INFO]: Epoch 204 - training loss: 9272.2710, validation loss: 0.0784
2024-05-22 17:10:59 [INFO]: Epoch 205 - training loss: 9273.1860, validation loss: 0.0763
2024-05-22 17:10:59 [INFO]: Epoch 206 - training loss: 9272.9561, validation loss: 0.0759
2024-05-22 17:10:59 [INFO]: Epoch 207 - training loss: 9272.1770, validation loss: 0.0770
2024-05-22 17:10:59 [INFO]: Epoch 208 - training loss: 9272.8397, validation loss: 0.0785
2024-05-22 17:10:59 [INFO]: Epoch 209 - training loss: 9272.5529, validation loss: 0.0783
2024-05-22 17:10:59 [INFO]: Epoch 210 - training loss: 9272.2639, validation loss: 0.0758
2024-05-22 17:10:59 [INFO]: Epoch 211 - training loss: 9272.7805, validation loss: 0.0749
2024-05-22 17:10:59 [INFO]: Epoch 212 - training loss: 9271.4240, validation loss: 0.0764
2024-05-22 17:10:59 [INFO]: Epoch 213 - training loss: 9272.5635, validation loss: 0.0766
2024-05-22 17:10:59 [INFO]: Epoch 214 - training loss: 9271.6046, validation loss: 0.0768
2024-05-22 17:11:00 [INFO]: Epoch 215 - training loss: 9271.8169, validation loss: 0.0773
2024-05-22 17:11:00 [INFO]: Epoch 216 - training loss: 9271.3936, validation loss: 0.0770
2024-05-22 17:11:00 [INFO]: Epoch 217 - training loss: 9272.1320, validation loss: 0.0748
2024-05-22 17:11:00 [INFO]: Epoch 218 - training loss: 9271.4452, validation loss: 0.0744
2024-05-22 17:11:00 [INFO]: Epoch 219 - training loss: 9272.4735, validation loss: 0.0751
2024-05-22 17:11:00 [INFO]: Epoch 220 - training loss: 9271.2188, validation loss: 0.0740
2024-05-22 17:11:00 [INFO]: Epoch 221 - training loss: 9272.3514, validation loss: 0.0770
2024-05-22 17:11:00 [INFO]: Epoch 222 - training loss: 9272.0964, validation loss: 0.0753
2024-05-22 17:11:00 [INFO]: Epoch 223 - training loss: 9271.3182, validation loss: 0.0747
2024-05-22 17:11:01 [INFO]: Epoch 224 - training loss: 9270.3976, validation loss: 0.0748
2024-05-22 17:11:01 [INFO]: Epoch 225 - training loss: 9271.6518, validation loss: 0.0733
2024-05-22 17:11:01 [INFO]: Epoch 226 - training loss: 9272.3143, validation loss: 0.0773
2024-05-22 17:11:01 [INFO]: Epoch 227 - training loss: 9275.0613, validation loss: 0.0727
2024-05-22 17:11:01 [INFO]: Epoch 228 - training loss: 9271.6218, validation loss: 0.0745
2024-05-22 17:11:01 [INFO]: Epoch 229 - training loss: 9277.9211, validation loss: 0.0754
2024-05-22 17:11:01 [INFO]: Epoch 230 - training loss: 9272.1823, validation loss: 0.0731
2024-05-22 17:11:01 [INFO]: Epoch 231 - training loss: 9271.8597, validation loss: 0.0741
2024-05-22 17:11:01 [INFO]: Epoch 232 - training loss: 9270.2225, validation loss: 0.0751
2024-05-22 17:11:02 [INFO]: Epoch 233 - training loss: 9271.0957, validation loss: 0.0744
2024-05-22 17:11:02 [INFO]: Epoch 234 - training loss: 9270.2801, validation loss: 0.0749
2024-05-22 17:11:02 [INFO]: Epoch 235 - training loss: 9270.6349, validation loss: 0.0743
2024-05-22 17:11:02 [INFO]: Epoch 236 - training loss: 9270.4363, validation loss: 0.0742
2024-05-22 17:11:02 [INFO]: Epoch 237 - training loss: 9270.4390, validation loss: 0.0754
2024-05-22 17:11:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:11:02 [INFO]: Finished training. The best model is from epoch#227.
2024-05-22 17:11:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/GPVAE_ettm1/20240522_T171035/GPVAE.pypots
2024-05-22 17:11:02 [INFO]: GP-VAE on ETTm1: MAE=0.2936, MSE=0.1823
2024-05-22 17:11:02 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-22 17:11:02 [INFO]: Using the given device: cuda:0
2024-05-22 17:11:02 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/USGAN_ettm1/20240522_T171102
2024-05-22 17:11:02 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/USGAN_ettm1/20240522_T171102/tensorboard
2024-05-22 17:11:02 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 17:11:11 [INFO]: Epoch 001 - generator training loss: 0.5374, discriminator training loss: 0.4105, validation loss: 0.3473
2024-05-22 17:11:18 [INFO]: Epoch 002 - generator training loss: 0.0148, discriminator training loss: 0.3200, validation loss: 0.1177
2024-05-22 17:11:26 [INFO]: Epoch 003 - generator training loss: -0.1181, discriminator training loss: 0.3103, validation loss: 0.0733
2024-05-22 17:11:33 [INFO]: Epoch 004 - generator training loss: -0.1291, discriminator training loss: 0.2929, validation loss: 0.0553
2024-05-22 17:11:41 [INFO]: Epoch 005 - generator training loss: -0.1149, discriminator training loss: 0.2688, validation loss: 0.0471
2024-05-22 17:11:48 [INFO]: Epoch 006 - generator training loss: -0.0923, discriminator training loss: 0.2353, validation loss: 0.0497
2024-05-22 17:11:56 [INFO]: Epoch 007 - generator training loss: -0.0665, discriminator training loss: 0.1991, validation loss: 0.0433
2024-05-22 17:12:03 [INFO]: Epoch 008 - generator training loss: -0.0460, discriminator training loss: 0.1658, validation loss: 0.0409
2024-05-22 17:12:10 [INFO]: Epoch 009 - generator training loss: -0.0354, discriminator training loss: 0.1460, validation loss: 0.0397
2024-05-22 17:12:18 [INFO]: Epoch 010 - generator training loss: -0.0323, discriminator training loss: 0.1346, validation loss: 0.0392
2024-05-22 17:12:25 [INFO]: Epoch 011 - generator training loss: -0.0284, discriminator training loss: 0.1280, validation loss: 0.0387
2024-05-22 17:12:32 [INFO]: Epoch 012 - generator training loss: -0.0275, discriminator training loss: 0.1236, validation loss: 0.0366
2024-05-22 17:12:40 [INFO]: Epoch 013 - generator training loss: -0.0285, discriminator training loss: 0.1228, validation loss: 0.0360
2024-05-22 17:12:47 [INFO]: Epoch 014 - generator training loss: -0.0280, discriminator training loss: 0.1204, validation loss: 0.0355
2024-05-22 17:12:54 [INFO]: Epoch 015 - generator training loss: -0.0292, discriminator training loss: 0.1189, validation loss: 0.0348
2024-05-22 17:13:02 [INFO]: Epoch 016 - generator training loss: -0.0304, discriminator training loss: 0.1192, validation loss: 0.0344
2024-05-22 17:13:09 [INFO]: Epoch 017 - generator training loss: -0.0258, discriminator training loss: 0.1160, validation loss: 0.0347
2024-05-22 17:13:16 [INFO]: Epoch 018 - generator training loss: -0.0283, discriminator training loss: 0.1150, validation loss: 0.0341
2024-05-22 17:13:24 [INFO]: Epoch 019 - generator training loss: -0.0299, discriminator training loss: 0.1165, validation loss: 0.0335
2024-05-22 17:13:31 [INFO]: Epoch 020 - generator training loss: -0.0318, discriminator training loss: 0.1168, validation loss: 0.0326
2024-05-22 17:13:39 [INFO]: Epoch 021 - generator training loss: -0.0293, discriminator training loss: 0.1161, validation loss: 0.0340
2024-05-22 17:13:46 [INFO]: Epoch 022 - generator training loss: -0.0286, discriminator training loss: 0.1144, validation loss: 0.0329
2024-05-22 17:13:54 [INFO]: Epoch 023 - generator training loss: -0.0308, discriminator training loss: 0.1143, validation loss: 0.0332
2024-05-22 17:14:01 [INFO]: Epoch 024 - generator training loss: -0.0291, discriminator training loss: 0.1148, validation loss: 0.0323
2024-05-22 17:14:09 [INFO]: Epoch 025 - generator training loss: -0.0272, discriminator training loss: 0.1143, validation loss: 0.0332
2024-05-22 17:14:16 [INFO]: Epoch 026 - generator training loss: -0.0323, discriminator training loss: 0.1140, validation loss: 0.0316
2024-05-22 17:14:23 [INFO]: Epoch 027 - generator training loss: -0.0323, discriminator training loss: 0.1131, validation loss: 0.0315
2024-05-22 17:14:31 [INFO]: Epoch 028 - generator training loss: -0.0351, discriminator training loss: 0.1120, validation loss: 0.0314
2024-05-22 17:14:38 [INFO]: Epoch 029 - generator training loss: -0.0317, discriminator training loss: 0.1111, validation loss: 0.0308
2024-05-22 17:14:46 [INFO]: Epoch 030 - generator training loss: -0.0337, discriminator training loss: 0.1132, validation loss: 0.0306
2024-05-22 17:14:53 [INFO]: Epoch 031 - generator training loss: -0.0362, discriminator training loss: 0.1133, validation loss: 0.0309
2024-05-22 17:15:00 [INFO]: Epoch 032 - generator training loss: -0.0351, discriminator training loss: 0.1115, validation loss: 0.0300
2024-05-22 17:15:08 [INFO]: Epoch 033 - generator training loss: -0.0316, discriminator training loss: 0.1111, validation loss: 0.0293
2024-05-22 17:15:15 [INFO]: Epoch 034 - generator training loss: -0.0356, discriminator training loss: 0.1115, validation loss: 0.0291
2024-05-22 17:15:23 [INFO]: Epoch 035 - generator training loss: -0.0366, discriminator training loss: 0.1118, validation loss: 0.0291
2024-05-22 17:15:30 [INFO]: Epoch 036 - generator training loss: -0.0339, discriminator training loss: 0.1112, validation loss: 0.0280
2024-05-22 17:15:37 [INFO]: Epoch 037 - generator training loss: -0.0337, discriminator training loss: 0.1108, validation loss: 0.0293
2024-05-22 17:15:45 [INFO]: Epoch 038 - generator training loss: -0.0326, discriminator training loss: 0.1129, validation loss: 0.0285
2024-05-22 17:15:53 [INFO]: Epoch 039 - generator training loss: -0.0365, discriminator training loss: 0.1100, validation loss: 0.0278
2024-05-22 17:16:00 [INFO]: Epoch 040 - generator training loss: -0.0376, discriminator training loss: 0.1105, validation loss: 0.0279
2024-05-22 17:16:08 [INFO]: Epoch 041 - generator training loss: -0.0374, discriminator training loss: 0.1092, validation loss: 0.0273
2024-05-22 17:16:16 [INFO]: Epoch 042 - generator training loss: -0.0402, discriminator training loss: 0.1099, validation loss: 0.0267
2024-05-22 17:16:24 [INFO]: Epoch 043 - generator training loss: -0.0376, discriminator training loss: 0.1105, validation loss: 0.0271
2024-05-22 17:16:31 [INFO]: Epoch 044 - generator training loss: -0.0376, discriminator training loss: 0.1083, validation loss: 0.0273
2024-05-22 17:16:38 [INFO]: Epoch 045 - generator training loss: -0.0419, discriminator training loss: 0.1109, validation loss: 0.0273
2024-05-22 17:16:46 [INFO]: Epoch 046 - generator training loss: -0.0386, discriminator training loss: 0.1091, validation loss: 0.0258
2024-05-22 17:16:54 [INFO]: Epoch 047 - generator training loss: -0.0427, discriminator training loss: 0.1105, validation loss: 0.0251
2024-05-22 17:17:01 [INFO]: Epoch 048 - generator training loss: -0.0415, discriminator training loss: 0.1108, validation loss: 0.0255
2024-05-22 17:17:09 [INFO]: Epoch 049 - generator training loss: -0.0414, discriminator training loss: 0.1094, validation loss: 0.0243
2024-05-22 17:17:16 [INFO]: Epoch 050 - generator training loss: -0.0421, discriminator training loss: 0.1086, validation loss: 0.0242
2024-05-22 17:17:24 [INFO]: Epoch 051 - generator training loss: -0.0409, discriminator training loss: 0.1110, validation loss: 0.0252
2024-05-22 17:17:31 [INFO]: Epoch 052 - generator training loss: -0.0423, discriminator training loss: 0.1089, validation loss: 0.0243
2024-05-22 17:17:39 [INFO]: Epoch 053 - generator training loss: -0.0407, discriminator training loss: 0.1087, validation loss: 0.0234
2024-05-22 17:17:46 [INFO]: Epoch 054 - generator training loss: -0.0404, discriminator training loss: 0.1074, validation loss: 0.0237
2024-05-22 17:17:54 [INFO]: Epoch 055 - generator training loss: -0.0416, discriminator training loss: 0.1092, validation loss: 0.0238
2024-05-22 17:18:01 [INFO]: Epoch 056 - generator training loss: -0.0412, discriminator training loss: 0.1092, validation loss: 0.0235
2024-05-22 17:18:08 [INFO]: Epoch 057 - generator training loss: -0.0437, discriminator training loss: 0.1080, validation loss: 0.0241
2024-05-22 17:18:16 [INFO]: Epoch 058 - generator training loss: -0.0447, discriminator training loss: 0.1099, validation loss: 0.0223
2024-05-22 17:18:24 [INFO]: Epoch 059 - generator training loss: -0.0442, discriminator training loss: 0.1091, validation loss: 0.0236
2024-05-22 17:18:31 [INFO]: Epoch 060 - generator training loss: -0.0438, discriminator training loss: 0.1093, validation loss: 0.0235
2024-05-22 17:18:39 [INFO]: Epoch 061 - generator training loss: -0.0440, discriminator training loss: 0.1090, validation loss: 0.0228
2024-05-22 17:18:46 [INFO]: Epoch 062 - generator training loss: -0.0444, discriminator training loss: 0.1079, validation loss: 0.0226
2024-05-22 17:18:53 [INFO]: Epoch 063 - generator training loss: -0.0439, discriminator training loss: 0.1098, validation loss: 0.0223
2024-05-22 17:19:01 [INFO]: Epoch 064 - generator training loss: -0.0421, discriminator training loss: 0.1086, validation loss: 0.0227
2024-05-22 17:19:08 [INFO]: Epoch 065 - generator training loss: -0.0457, discriminator training loss: 0.1092, validation loss: 0.0231
2024-05-22 17:19:16 [INFO]: Epoch 066 - generator training loss: -0.0450, discriminator training loss: 0.1085, validation loss: 0.0220
2024-05-22 17:19:23 [INFO]: Epoch 067 - generator training loss: -0.0457, discriminator training loss: 0.1112, validation loss: 0.0233
2024-05-22 17:19:30 [INFO]: Epoch 068 - generator training loss: -0.0439, discriminator training loss: 0.1114, validation loss: 0.0216
2024-05-22 17:19:38 [INFO]: Epoch 069 - generator training loss: -0.0427, discriminator training loss: 0.1073, validation loss: 0.0230
2024-05-22 17:19:45 [INFO]: Epoch 070 - generator training loss: -0.0418, discriminator training loss: 0.1079, validation loss: 0.0220
2024-05-22 17:19:52 [INFO]: Epoch 071 - generator training loss: -0.0413, discriminator training loss: 0.1087, validation loss: 0.0226
2024-05-22 17:20:00 [INFO]: Epoch 072 - generator training loss: -0.0436, discriminator training loss: 0.1079, validation loss: 0.0221
2024-05-22 17:20:07 [INFO]: Epoch 073 - generator training loss: -0.0457, discriminator training loss: 0.1070, validation loss: 0.0217
2024-05-22 17:20:14 [INFO]: Epoch 074 - generator training loss: -0.0468, discriminator training loss: 0.1079, validation loss: 0.0222
2024-05-22 17:20:21 [INFO]: Epoch 075 - generator training loss: -0.0429, discriminator training loss: 0.1086, validation loss: 0.0228
2024-05-22 17:20:28 [INFO]: Epoch 076 - generator training loss: -0.0439, discriminator training loss: 0.1083, validation loss: 0.0220
2024-05-22 17:20:36 [INFO]: Epoch 077 - generator training loss: -0.0443, discriminator training loss: 0.1083, validation loss: 0.0223
2024-05-22 17:20:43 [INFO]: Epoch 078 - generator training loss: -0.0447, discriminator training loss: 0.1081, validation loss: 0.0230
2024-05-22 17:20:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:20:43 [INFO]: Finished training. The best model is from epoch#68.
2024-05-22 17:20:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/USGAN_ettm1/20240522_T171102/USGAN.pypots
2024-05-22 17:20:44 [INFO]: US-GAN on ETTm1: MAE=0.1457, MSE=0.0502
2024-05-22 17:20:44 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-22 17:20:44 [INFO]: Using the given device: cuda:0
2024-05-22 17:20:44 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/BRITS_ettm1/20240522_T172044
2024-05-22 17:20:44 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/BRITS_ettm1/20240522_T172044/tensorboard
2024-05-22 17:20:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 17:20:50 [INFO]: Epoch 001 - training loss: 1.3261, validation loss: 0.2558
2024-05-22 17:20:55 [INFO]: Epoch 002 - training loss: 0.8992, validation loss: 0.0750
2024-05-22 17:20:59 [INFO]: Epoch 003 - training loss: 0.7238, validation loss: 0.0520
2024-05-22 17:21:04 [INFO]: Epoch 004 - training loss: 0.6549, validation loss: 0.0405
2024-05-22 17:21:09 [INFO]: Epoch 005 - training loss: 0.6047, validation loss: 0.0353
2024-05-22 17:21:14 [INFO]: Epoch 006 - training loss: 0.5849, validation loss: 0.0387
2024-05-22 17:21:19 [INFO]: Epoch 007 - training loss: 0.5601, validation loss: 0.0328
2024-05-22 17:21:24 [INFO]: Epoch 008 - training loss: 0.5216, validation loss: 0.0311
2024-05-22 17:21:28 [INFO]: Epoch 009 - training loss: 0.5197, validation loss: 0.0312
2024-05-22 17:21:33 [INFO]: Epoch 010 - training loss: 0.4970, validation loss: 0.0305
2024-05-22 17:21:38 [INFO]: Epoch 011 - training loss: 0.4761, validation loss: 0.0282
2024-05-22 17:21:43 [INFO]: Epoch 012 - training loss: 0.4480, validation loss: 0.0270
2024-05-22 17:21:48 [INFO]: Epoch 013 - training loss: 0.4384, validation loss: 0.0270
2024-05-22 17:21:53 [INFO]: Epoch 014 - training loss: 0.4500, validation loss: 0.0273
2024-05-22 17:21:58 [INFO]: Epoch 015 - training loss: 0.4189, validation loss: 0.0250
2024-05-22 17:22:02 [INFO]: Epoch 016 - training loss: 0.4070, validation loss: 0.0235
2024-05-22 17:22:07 [INFO]: Epoch 017 - training loss: 0.4049, validation loss: 0.0229
2024-05-22 17:22:12 [INFO]: Epoch 018 - training loss: 0.3945, validation loss: 0.0229
2024-05-22 17:22:17 [INFO]: Epoch 019 - training loss: 0.3956, validation loss: 0.0229
2024-05-22 17:22:22 [INFO]: Epoch 020 - training loss: 0.3932, validation loss: 0.0225
2024-05-22 17:22:27 [INFO]: Epoch 021 - training loss: 0.3889, validation loss: 0.0225
2024-05-22 17:22:31 [INFO]: Epoch 022 - training loss: 0.3873, validation loss: 0.0222
2024-05-22 17:22:36 [INFO]: Epoch 023 - training loss: 0.3863, validation loss: 0.0224
2024-05-22 17:22:41 [INFO]: Epoch 024 - training loss: 0.4008, validation loss: 0.0225
2024-05-22 17:22:46 [INFO]: Epoch 025 - training loss: 0.3925, validation loss: 0.0223
2024-05-22 17:22:51 [INFO]: Epoch 026 - training loss: 0.3912, validation loss: 0.0222
2024-05-22 17:22:55 [INFO]: Epoch 027 - training loss: 0.3912, validation loss: 0.0224
2024-05-22 17:23:00 [INFO]: Epoch 028 - training loss: 0.3921, validation loss: 0.0221
2024-05-22 17:23:05 [INFO]: Epoch 029 - training loss: 0.3915, validation loss: 0.0218
2024-05-22 17:23:10 [INFO]: Epoch 030 - training loss: 0.3854, validation loss: 0.0224
2024-05-22 17:23:15 [INFO]: Epoch 031 - training loss: 0.3826, validation loss: 0.0219
2024-05-22 17:23:20 [INFO]: Epoch 032 - training loss: 0.3827, validation loss: 0.0218
2024-05-22 17:23:25 [INFO]: Epoch 033 - training loss: 0.3956, validation loss: 0.0221
2024-05-22 17:23:29 [INFO]: Epoch 034 - training loss: 0.3801, validation loss: 0.0221
2024-05-22 17:23:34 [INFO]: Epoch 035 - training loss: 0.3823, validation loss: 0.0219
2024-05-22 17:23:39 [INFO]: Epoch 036 - training loss: 0.3832, validation loss: 0.0222
2024-05-22 17:23:44 [INFO]: Epoch 037 - training loss: 0.3866, validation loss: 0.0216
2024-05-22 17:23:49 [INFO]: Epoch 038 - training loss: 0.3841, validation loss: 0.0224
2024-05-22 17:23:54 [INFO]: Epoch 039 - training loss: 0.3875, validation loss: 0.0218
2024-05-22 17:23:58 [INFO]: Epoch 040 - training loss: 0.3846, validation loss: 0.0219
2024-05-22 17:24:03 [INFO]: Epoch 041 - training loss: 0.3806, validation loss: 0.0217
2024-05-22 17:24:08 [INFO]: Epoch 042 - training loss: 0.3817, validation loss: 0.0217
2024-05-22 17:24:13 [INFO]: Epoch 043 - training loss: 0.3744, validation loss: 0.0221
2024-05-22 17:24:18 [INFO]: Epoch 044 - training loss: 0.3839, validation loss: 0.0221
2024-05-22 17:24:23 [INFO]: Epoch 045 - training loss: 0.3807, validation loss: 0.0218
2024-05-22 17:24:28 [INFO]: Epoch 046 - training loss: 0.3767, validation loss: 0.0219
2024-05-22 17:24:32 [INFO]: Epoch 047 - training loss: 0.3758, validation loss: 0.0219
2024-05-22 17:24:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:24:32 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 17:24:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/BRITS_ettm1/20240522_T172044/BRITS.pypots
2024-05-22 17:24:33 [INFO]: BRITS on ETTm1: MAE=0.1225, MSE=0.0447
2024-05-22 17:24:33 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-22 17:24:33 [INFO]: Using the given device: cuda:0
2024-05-22 17:24:33 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433
2024-05-22 17:24:33 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/tensorboard
2024-05-22 17:24:33 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 17:24:34 [INFO]: Epoch 001 - training loss: 1.3970, validation loss: 1.2886
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch1_loss1.2885666638612747.pypots
2024-05-22 17:24:35 [INFO]: Epoch 002 - training loss: 1.0779, validation loss: 1.1600
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch2_loss1.1600363552570343.pypots
2024-05-22 17:24:35 [INFO]: Epoch 003 - training loss: 0.9824, validation loss: 1.0843
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch3_loss1.0842959135770798.pypots
2024-05-22 17:24:35 [INFO]: Epoch 004 - training loss: 0.9280, validation loss: 1.0555
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch4_loss1.0554843246936798.pypots
2024-05-22 17:24:35 [INFO]: Epoch 005 - training loss: 0.9514, validation loss: 1.0365
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch5_loss1.0365345776081085.pypots
2024-05-22 17:24:35 [INFO]: Epoch 006 - training loss: 0.9083, validation loss: 1.0249
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch6_loss1.0249003320932388.pypots
2024-05-22 17:24:35 [INFO]: Epoch 007 - training loss: 0.9140, validation loss: 1.0074
2024-05-22 17:24:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch7_loss1.0073918253183365.pypots
2024-05-22 17:24:36 [INFO]: Epoch 008 - training loss: 0.8916, validation loss: 0.9978
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch8_loss0.9977975338697433.pypots
2024-05-22 17:24:36 [INFO]: Epoch 009 - training loss: 0.8698, validation loss: 0.9891
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch9_loss0.9891113787889481.pypots
2024-05-22 17:24:36 [INFO]: Epoch 010 - training loss: 0.8681, validation loss: 0.9840
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch10_loss0.9839904606342316.pypots
2024-05-22 17:24:36 [INFO]: Epoch 011 - training loss: 0.8773, validation loss: 0.9790
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch11_loss0.9790432751178741.pypots
2024-05-22 17:24:36 [INFO]: Epoch 012 - training loss: 0.8661, validation loss: 0.9769
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch12_loss0.9768921434879303.pypots
2024-05-22 17:24:36 [INFO]: Epoch 013 - training loss: 0.8621, validation loss: 0.9717
2024-05-22 17:24:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch13_loss0.9717046320438385.pypots
2024-05-22 17:24:37 [INFO]: Epoch 014 - training loss: 0.8542, validation loss: 0.9701
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch14_loss0.9700507372617722.pypots
2024-05-22 17:24:37 [INFO]: Epoch 015 - training loss: 0.8875, validation loss: 0.9692
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch15_loss0.9692441374063492.pypots
2024-05-22 17:24:37 [INFO]: Epoch 016 - training loss: 0.8907, validation loss: 0.9644
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch16_loss0.9644315838813782.pypots
2024-05-22 17:24:37 [INFO]: Epoch 017 - training loss: 0.8696, validation loss: 0.9706
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch17_loss0.9705844074487686.pypots
2024-05-22 17:24:37 [INFO]: Epoch 018 - training loss: 0.8577, validation loss: 0.9719
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch18_loss0.9718508124351501.pypots
2024-05-22 17:24:37 [INFO]: Epoch 019 - training loss: 0.8579, validation loss: 0.9721
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch19_loss0.9721285104751587.pypots
2024-05-22 17:24:37 [INFO]: Epoch 020 - training loss: 0.8338, validation loss: 0.9672
2024-05-22 17:24:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch20_loss0.9672281742095947.pypots
2024-05-22 17:24:38 [INFO]: Epoch 021 - training loss: 0.8403, validation loss: 0.9648
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch21_loss0.964786559343338.pypots
2024-05-22 17:24:38 [INFO]: Epoch 022 - training loss: 0.8705, validation loss: 0.9636
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch22_loss0.9636180847883224.pypots
2024-05-22 17:24:38 [INFO]: Epoch 023 - training loss: 0.8635, validation loss: 0.9643
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch23_loss0.9642934054136276.pypots
2024-05-22 17:24:38 [INFO]: Epoch 024 - training loss: 0.8216, validation loss: 0.9627
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch24_loss0.9627397209405899.pypots
2024-05-22 17:24:38 [INFO]: Epoch 025 - training loss: 0.8390, validation loss: 0.9602
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch25_loss0.9602478593587875.pypots
2024-05-22 17:24:38 [INFO]: Epoch 026 - training loss: 0.8441, validation loss: 0.9596
2024-05-22 17:24:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch26_loss0.9596208930015564.pypots
2024-05-22 17:24:39 [INFO]: Epoch 027 - training loss: 0.8076, validation loss: 0.9580
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch27_loss0.9579646736383438.pypots
2024-05-22 17:24:39 [INFO]: Epoch 028 - training loss: 0.8136, validation loss: 0.9547
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch28_loss0.954682856798172.pypots
2024-05-22 17:24:39 [INFO]: Epoch 029 - training loss: 0.8096, validation loss: 0.9528
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch29_loss0.9528220295906067.pypots
2024-05-22 17:24:39 [INFO]: Epoch 030 - training loss: 0.8268, validation loss: 0.9510
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch30_loss0.9510337859392166.pypots
2024-05-22 17:24:39 [INFO]: Epoch 031 - training loss: 0.8262, validation loss: 0.9470
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch31_loss0.9469886720180511.pypots
2024-05-22 17:24:39 [INFO]: Epoch 032 - training loss: 0.8224, validation loss: 0.9477
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch32_loss0.9476726651191711.pypots
2024-05-22 17:24:39 [INFO]: Epoch 033 - training loss: 0.8016, validation loss: 0.9444
2024-05-22 17:24:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch33_loss0.9444066882133484.pypots
2024-05-22 17:24:40 [INFO]: Epoch 034 - training loss: 0.8218, validation loss: 0.9420
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch34_loss0.9420143961906433.pypots
2024-05-22 17:24:40 [INFO]: Epoch 035 - training loss: 0.8105, validation loss: 0.9376
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch35_loss0.9376352578401566.pypots
2024-05-22 17:24:40 [INFO]: Epoch 036 - training loss: 0.8187, validation loss: 0.9373
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch36_loss0.9372731596231461.pypots
2024-05-22 17:24:40 [INFO]: Epoch 037 - training loss: 0.8071, validation loss: 0.9340
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch37_loss0.9340360313653946.pypots
2024-05-22 17:24:40 [INFO]: Epoch 038 - training loss: 0.8405, validation loss: 0.9283
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch38_loss0.9283389151096344.pypots
2024-05-22 17:24:40 [INFO]: Epoch 039 - training loss: 0.8180, validation loss: 0.9247
2024-05-22 17:24:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch39_loss0.9247224628925323.pypots
2024-05-22 17:24:41 [INFO]: Epoch 040 - training loss: 0.8094, validation loss: 0.9220
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch40_loss0.9219720214605331.pypots
2024-05-22 17:24:41 [INFO]: Epoch 041 - training loss: 0.8239, validation loss: 0.9194
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch41_loss0.9193956553936005.pypots
2024-05-22 17:24:41 [INFO]: Epoch 042 - training loss: 0.7907, validation loss: 0.9170
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch42_loss0.9170068204402924.pypots
2024-05-22 17:24:41 [INFO]: Epoch 043 - training loss: 0.8026, validation loss: 0.9119
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch43_loss0.9118616282939911.pypots
2024-05-22 17:24:41 [INFO]: Epoch 044 - training loss: 0.8045, validation loss: 0.9082
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch44_loss0.9081752598285675.pypots
2024-05-22 17:24:41 [INFO]: Epoch 045 - training loss: 0.7789, validation loss: 0.9082
2024-05-22 17:24:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch45_loss0.9081786572933197.pypots
2024-05-22 17:24:42 [INFO]: Epoch 046 - training loss: 0.8164, validation loss: 0.9051
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch46_loss0.9050569087266922.pypots
2024-05-22 17:24:42 [INFO]: Epoch 047 - training loss: 0.7939, validation loss: 0.9003
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch47_loss0.9003497213125229.pypots
2024-05-22 17:24:42 [INFO]: Epoch 048 - training loss: 0.7956, validation loss: 0.8994
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch48_loss0.8993991166353226.pypots
2024-05-22 17:24:42 [INFO]: Epoch 049 - training loss: 0.7685, validation loss: 0.8964
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch49_loss0.8963937014341354.pypots
2024-05-22 17:24:42 [INFO]: Epoch 050 - training loss: 0.8015, validation loss: 0.8929
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch50_loss0.8928785622119904.pypots
2024-05-22 17:24:42 [INFO]: Epoch 051 - training loss: 0.7938, validation loss: 0.8945
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch51_loss0.8944903612136841.pypots
2024-05-22 17:24:42 [INFO]: Epoch 052 - training loss: 0.7876, validation loss: 0.8898
2024-05-22 17:24:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch52_loss0.8897534012794495.pypots
2024-05-22 17:24:43 [INFO]: Epoch 053 - training loss: 0.7987, validation loss: 0.8895
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch53_loss0.8894693851470947.pypots
2024-05-22 17:24:43 [INFO]: Epoch 054 - training loss: 0.8083, validation loss: 0.8873
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch54_loss0.8873388022184372.pypots
2024-05-22 17:24:43 [INFO]: Epoch 055 - training loss: 0.8060, validation loss: 0.8865
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch55_loss0.8865088373422623.pypots
2024-05-22 17:24:43 [INFO]: Epoch 056 - training loss: 0.7975, validation loss: 0.8813
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch56_loss0.8813320994377136.pypots
2024-05-22 17:24:43 [INFO]: Epoch 057 - training loss: 0.7923, validation loss: 0.8791
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch57_loss0.879122719168663.pypots
2024-05-22 17:24:43 [INFO]: Epoch 058 - training loss: 0.7627, validation loss: 0.8796
2024-05-22 17:24:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch58_loss0.8795876204967499.pypots
2024-05-22 17:24:44 [INFO]: Epoch 059 - training loss: 0.7809, validation loss: 0.8749
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch59_loss0.8748518526554108.pypots
2024-05-22 17:24:44 [INFO]: Epoch 060 - training loss: 0.7800, validation loss: 0.8798
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch60_loss0.8798473030328751.pypots
2024-05-22 17:24:44 [INFO]: Epoch 061 - training loss: 0.7895, validation loss: 0.8736
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch61_loss0.8736400157213211.pypots
2024-05-22 17:24:44 [INFO]: Epoch 062 - training loss: 0.7839, validation loss: 0.8709
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch62_loss0.8708957731723785.pypots
2024-05-22 17:24:44 [INFO]: Epoch 063 - training loss: 0.7810, validation loss: 0.8711
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch63_loss0.8711033463478088.pypots
2024-05-22 17:24:44 [INFO]: Epoch 064 - training loss: 0.7945, validation loss: 0.8711
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch64_loss0.8710981607437134.pypots
2024-05-22 17:24:44 [INFO]: Epoch 065 - training loss: 0.7740, validation loss: 0.8665
2024-05-22 17:24:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch65_loss0.8664581924676895.pypots
2024-05-22 17:24:45 [INFO]: Epoch 066 - training loss: 0.8144, validation loss: 0.8691
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch66_loss0.8691294938325882.pypots
2024-05-22 17:24:45 [INFO]: Epoch 067 - training loss: 0.7854, validation loss: 0.8659
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch67_loss0.8659196346998215.pypots
2024-05-22 17:24:45 [INFO]: Epoch 068 - training loss: 0.7823, validation loss: 0.8667
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch68_loss0.8666679412126541.pypots
2024-05-22 17:24:45 [INFO]: Epoch 069 - training loss: 0.7826, validation loss: 0.8642
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch69_loss0.8642232418060303.pypots
2024-05-22 17:24:45 [INFO]: Epoch 070 - training loss: 0.7878, validation loss: 0.8621
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch70_loss0.8620875179767609.pypots
2024-05-22 17:24:45 [INFO]: Epoch 071 - training loss: 0.7714, validation loss: 0.8626
2024-05-22 17:24:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch71_loss0.8625817447900772.pypots
2024-05-22 17:24:46 [INFO]: Epoch 072 - training loss: 0.7690, validation loss: 0.8609
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch72_loss0.86086805164814.pypots
2024-05-22 17:24:46 [INFO]: Epoch 073 - training loss: 0.7926, validation loss: 0.8564
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch73_loss0.8564134836196899.pypots
2024-05-22 17:24:46 [INFO]: Epoch 074 - training loss: 0.7725, validation loss: 0.8606
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch74_loss0.8606438189744949.pypots
2024-05-22 17:24:46 [INFO]: Epoch 075 - training loss: 0.7696, validation loss: 0.8579
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch75_loss0.8579188883304596.pypots
2024-05-22 17:24:46 [INFO]: Epoch 076 - training loss: 0.7710, validation loss: 0.8582
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch76_loss0.858209028840065.pypots
2024-05-22 17:24:46 [INFO]: Epoch 077 - training loss: 0.7900, validation loss: 0.8585
2024-05-22 17:24:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch77_loss0.8585238754749298.pypots
2024-05-22 17:24:47 [INFO]: Epoch 078 - training loss: 0.7754, validation loss: 0.8549
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch78_loss0.854858323931694.pypots
2024-05-22 17:24:47 [INFO]: Epoch 079 - training loss: 0.7730, validation loss: 0.8532
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch79_loss0.8532024919986725.pypots
2024-05-22 17:24:47 [INFO]: Epoch 080 - training loss: 0.7648, validation loss: 0.8551
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch80_loss0.8551114499568939.pypots
2024-05-22 17:24:47 [INFO]: Epoch 081 - training loss: 0.7772, validation loss: 0.8555
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch81_loss0.8555063754320145.pypots
2024-05-22 17:24:47 [INFO]: Epoch 082 - training loss: 0.7860, validation loss: 0.8507
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch82_loss0.850670576095581.pypots
2024-05-22 17:24:47 [INFO]: Epoch 083 - training loss: 0.7697, validation loss: 0.8525
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch83_loss0.8525285869836807.pypots
2024-05-22 17:24:47 [INFO]: Epoch 084 - training loss: 0.7527, validation loss: 0.8536
2024-05-22 17:24:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch84_loss0.8536006510257721.pypots
2024-05-22 17:24:48 [INFO]: Epoch 085 - training loss: 0.7473, validation loss: 0.8506
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch85_loss0.8506249338388443.pypots
2024-05-22 17:24:48 [INFO]: Epoch 086 - training loss: 0.7727, validation loss: 0.8531
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch86_loss0.8530930429697037.pypots
2024-05-22 17:24:48 [INFO]: Epoch 087 - training loss: 0.7632, validation loss: 0.8505
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch87_loss0.8505440950393677.pypots
2024-05-22 17:24:48 [INFO]: Epoch 088 - training loss: 0.7665, validation loss: 0.8488
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch88_loss0.8487840592861176.pypots
2024-05-22 17:24:48 [INFO]: Epoch 089 - training loss: 0.7808, validation loss: 0.8483
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch89_loss0.8482538908720016.pypots
2024-05-22 17:24:48 [INFO]: Epoch 090 - training loss: 0.7769, validation loss: 0.8500
2024-05-22 17:24:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch90_loss0.850018709897995.pypots
2024-05-22 17:24:49 [INFO]: Epoch 091 - training loss: 0.7730, validation loss: 0.8460
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch91_loss0.846019372344017.pypots
2024-05-22 17:24:49 [INFO]: Epoch 092 - training loss: 0.8059, validation loss: 0.8491
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch92_loss0.8490608036518097.pypots
2024-05-22 17:24:49 [INFO]: Epoch 093 - training loss: 0.7537, validation loss: 0.8489
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch93_loss0.8488709777593613.pypots
2024-05-22 17:24:49 [INFO]: Epoch 094 - training loss: 0.7892, validation loss: 0.8475
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch94_loss0.8475047498941422.pypots
2024-05-22 17:24:49 [INFO]: Epoch 095 - training loss: 0.7542, validation loss: 0.8463
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch95_loss0.8462939560413361.pypots
2024-05-22 17:24:49 [INFO]: Epoch 096 - training loss: 0.7684, validation loss: 0.8444
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch96_loss0.8444417864084244.pypots
2024-05-22 17:24:49 [INFO]: Epoch 097 - training loss: 0.7838, validation loss: 0.8461
2024-05-22 17:24:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch97_loss0.8460637480020523.pypots
2024-05-22 17:24:50 [INFO]: Epoch 098 - training loss: 0.7765, validation loss: 0.8466
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch98_loss0.8466437458992004.pypots
2024-05-22 17:24:50 [INFO]: Epoch 099 - training loss: 0.7534, validation loss: 0.8497
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch99_loss0.8497040867805481.pypots
2024-05-22 17:24:50 [INFO]: Epoch 100 - training loss: 0.7707, validation loss: 0.8470
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch100_loss0.8469779789447784.pypots
2024-05-22 17:24:50 [INFO]: Epoch 101 - training loss: 0.7778, validation loss: 0.8492
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch101_loss0.8491943925619125.pypots
2024-05-22 17:24:50 [INFO]: Epoch 102 - training loss: 0.7950, validation loss: 0.8478
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch102_loss0.8477520793676376.pypots
2024-05-22 17:24:50 [INFO]: Epoch 103 - training loss: 0.7681, validation loss: 0.8385
2024-05-22 17:24:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch103_loss0.8384764939546585.pypots
2024-05-22 17:24:51 [INFO]: Epoch 104 - training loss: 0.7676, validation loss: 0.8436
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch104_loss0.8436290621757507.pypots
2024-05-22 17:24:51 [INFO]: Epoch 105 - training loss: 0.7619, validation loss: 0.8446
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch105_loss0.8446264266967773.pypots
2024-05-22 17:24:51 [INFO]: Epoch 106 - training loss: 0.7581, validation loss: 0.8461
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch106_loss0.8460746109485626.pypots
2024-05-22 17:24:51 [INFO]: Epoch 107 - training loss: 0.7515, validation loss: 0.8411
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch107_loss0.8411357402801514.pypots
2024-05-22 17:24:51 [INFO]: Epoch 108 - training loss: 0.7710, validation loss: 0.8430
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch108_loss0.8429927825927734.pypots
2024-05-22 17:24:51 [INFO]: Epoch 109 - training loss: 0.7863, validation loss: 0.8460
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch109_loss0.8460327833890915.pypots
2024-05-22 17:24:51 [INFO]: Epoch 110 - training loss: 0.7498, validation loss: 0.8417
2024-05-22 17:24:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch110_loss0.8417491912841797.pypots
2024-05-22 17:24:52 [INFO]: Epoch 111 - training loss: 0.7668, validation loss: 0.8419
2024-05-22 17:24:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch111_loss0.841944009065628.pypots
2024-05-22 17:24:52 [INFO]: Epoch 112 - training loss: 0.7632, validation loss: 0.8409
2024-05-22 17:24:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch112_loss0.8409321308135986.pypots
2024-05-22 17:24:52 [INFO]: Epoch 113 - training loss: 0.7575, validation loss: 0.8402
2024-05-22 17:24:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN_epoch113_loss0.8401791602373123.pypots
2024-05-22 17:24:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:24:52 [INFO]: Finished training. The best model is from epoch#103.
2024-05-22 17:24:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/20240522_T172433/MRNN.pypots
2024-05-22 17:24:52 [INFO]: MRNN on ETTm1: MAE=0.6906, MSE=1.1622
2024-05-22 17:24:52 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-22 17:24:52 [INFO]: Using the given device: cpu
2024-05-22 17:24:52 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 17:24:52 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-22 17:24:52 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-22 17:24:52 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 17:24:52 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-22 17:24:52 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-22 17:24:52 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 17:24:52 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-22 17:24:52 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-22 17:24:52 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 17:24:52 [INFO]: Using the given device: cuda:0
2024-05-22 17:24:52 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/SAITS_ettm1/20240522_T172452
2024-05-22 17:24:52 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/SAITS_ettm1/20240522_T172452/tensorboard
2024-05-22 17:24:52 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 17:24:53 [INFO]: Epoch 001 - training loss: 1.2085, validation loss: 0.3209
2024-05-22 17:24:53 [INFO]: Epoch 002 - training loss: 0.9006, validation loss: 0.1580
2024-05-22 17:24:54 [INFO]: Epoch 003 - training loss: 0.7670, validation loss: 0.1135
2024-05-22 17:24:54 [INFO]: Epoch 004 - training loss: 0.7091, validation loss: 0.1112
2024-05-22 17:24:55 [INFO]: Epoch 005 - training loss: 0.6699, validation loss: 0.0833
2024-05-22 17:24:55 [INFO]: Epoch 006 - training loss: 0.6562, validation loss: 0.0973
2024-05-22 17:24:56 [INFO]: Epoch 007 - training loss: 0.6497, validation loss: 0.0769
2024-05-22 17:24:56 [INFO]: Epoch 008 - training loss: 0.6195, validation loss: 0.0775
2024-05-22 17:24:57 [INFO]: Epoch 009 - training loss: 0.6075, validation loss: 0.0768
2024-05-22 17:24:57 [INFO]: Epoch 010 - training loss: 0.6030, validation loss: 0.1074
2024-05-22 17:24:58 [INFO]: Epoch 011 - training loss: 0.5931, validation loss: 0.0819
2024-05-22 17:24:58 [INFO]: Epoch 012 - training loss: 0.5789, validation loss: 0.0795
2024-05-22 17:24:59 [INFO]: Epoch 013 - training loss: 0.5710, validation loss: 0.0525
2024-05-22 17:24:59 [INFO]: Epoch 014 - training loss: 0.5675, validation loss: 0.0877
2024-05-22 17:25:00 [INFO]: Epoch 015 - training loss: 0.5628, validation loss: 0.0568
2024-05-22 17:25:00 [INFO]: Epoch 016 - training loss: 0.5521, validation loss: 0.0645
2024-05-22 17:25:01 [INFO]: Epoch 017 - training loss: 0.5446, validation loss: 0.0652
2024-05-22 17:25:01 [INFO]: Epoch 018 - training loss: 0.5539, validation loss: 0.0567
2024-05-22 17:25:02 [INFO]: Epoch 019 - training loss: 0.5324, validation loss: 0.0534
2024-05-22 17:25:02 [INFO]: Epoch 020 - training loss: 0.5439, validation loss: 0.0698
2024-05-22 17:25:03 [INFO]: Epoch 021 - training loss: 0.5473, validation loss: 0.0652
2024-05-22 17:25:03 [INFO]: Epoch 022 - training loss: 0.5206, validation loss: 0.0575
2024-05-22 17:25:04 [INFO]: Epoch 023 - training loss: 0.5221, validation loss: 0.0526
2024-05-22 17:25:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:25:04 [INFO]: Finished training. The best model is from epoch#13.
2024-05-22 17:25:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/SAITS_ettm1/20240522_T172452/SAITS.pypots
2024-05-22 17:25:04 [INFO]: SAITS on ETTm1: MAE=0.1890, MSE=0.0634
2024-05-22 17:25:04 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-22 17:25:04 [INFO]: Using the given device: cuda:0
2024-05-22 17:25:04 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/Transformer_ettm1/20240522_T172504
2024-05-22 17:25:04 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/Transformer_ettm1/20240522_T172504/tensorboard
2024-05-22 17:25:04 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 17:25:04 [INFO]: Epoch 001 - training loss: 1.2391, validation loss: 0.3470
2024-05-22 17:25:04 [INFO]: Epoch 002 - training loss: 0.7792, validation loss: 0.1853
2024-05-22 17:25:05 [INFO]: Epoch 003 - training loss: 0.6449, validation loss: 0.1290
2024-05-22 17:25:05 [INFO]: Epoch 004 - training loss: 0.5646, validation loss: 0.0957
2024-05-22 17:25:05 [INFO]: Epoch 005 - training loss: 0.5149, validation loss: 0.0752
2024-05-22 17:25:05 [INFO]: Epoch 006 - training loss: 0.4854, validation loss: 0.0746
2024-05-22 17:25:05 [INFO]: Epoch 007 - training loss: 0.4589, validation loss: 0.0822
2024-05-22 17:25:06 [INFO]: Epoch 008 - training loss: 0.4623, validation loss: 0.0648
2024-05-22 17:25:06 [INFO]: Epoch 009 - training loss: 0.4264, validation loss: 0.0591
2024-05-22 17:25:06 [INFO]: Epoch 010 - training loss: 0.4066, validation loss: 0.0562
2024-05-22 17:25:06 [INFO]: Epoch 011 - training loss: 0.3941, validation loss: 0.0531
2024-05-22 17:25:06 [INFO]: Epoch 012 - training loss: 0.3886, validation loss: 0.0532
2024-05-22 17:25:07 [INFO]: Epoch 013 - training loss: 0.3811, validation loss: 0.0579
2024-05-22 17:25:07 [INFO]: Epoch 014 - training loss: 0.3764, validation loss: 0.0461
2024-05-22 17:25:07 [INFO]: Epoch 015 - training loss: 0.3617, validation loss: 0.0446
2024-05-22 17:25:07 [INFO]: Epoch 016 - training loss: 0.3615, validation loss: 0.0447
2024-05-22 17:25:07 [INFO]: Epoch 017 - training loss: 0.3511, validation loss: 0.0452
2024-05-22 17:25:08 [INFO]: Epoch 018 - training loss: 0.3519, validation loss: 0.0437
2024-05-22 17:25:08 [INFO]: Epoch 019 - training loss: 0.3430, validation loss: 0.0435
2024-05-22 17:25:08 [INFO]: Epoch 020 - training loss: 0.3310, validation loss: 0.0362
2024-05-22 17:25:08 [INFO]: Epoch 021 - training loss: 0.3314, validation loss: 0.0394
2024-05-22 17:25:08 [INFO]: Epoch 022 - training loss: 0.3178, validation loss: 0.0379
2024-05-22 17:25:09 [INFO]: Epoch 023 - training loss: 0.3122, validation loss: 0.0357
2024-05-22 17:25:09 [INFO]: Epoch 024 - training loss: 0.3130, validation loss: 0.0369
2024-05-22 17:25:09 [INFO]: Epoch 025 - training loss: 0.3077, validation loss: 0.0336
2024-05-22 17:25:09 [INFO]: Epoch 026 - training loss: 0.3025, validation loss: 0.0404
2024-05-22 17:25:10 [INFO]: Epoch 027 - training loss: 0.3139, validation loss: 0.0458
2024-05-22 17:25:10 [INFO]: Epoch 028 - training loss: 0.3188, validation loss: 0.0344
2024-05-22 17:25:10 [INFO]: Epoch 029 - training loss: 0.3023, validation loss: 0.0373
2024-05-22 17:25:10 [INFO]: Epoch 030 - training loss: 0.2952, validation loss: 0.0324
2024-05-22 17:25:10 [INFO]: Epoch 031 - training loss: 0.2901, validation loss: 0.0326
2024-05-22 17:25:11 [INFO]: Epoch 032 - training loss: 0.2889, validation loss: 0.0336
2024-05-22 17:25:11 [INFO]: Epoch 033 - training loss: 0.2850, validation loss: 0.0408
2024-05-22 17:25:11 [INFO]: Epoch 034 - training loss: 0.2849, validation loss: 0.0314
2024-05-22 17:25:11 [INFO]: Epoch 035 - training loss: 0.2768, validation loss: 0.0329
2024-05-22 17:25:11 [INFO]: Epoch 036 - training loss: 0.2762, validation loss: 0.0294
2024-05-22 17:25:12 [INFO]: Epoch 037 - training loss: 0.2734, validation loss: 0.0278
2024-05-22 17:25:12 [INFO]: Epoch 038 - training loss: 0.2690, validation loss: 0.0283
2024-05-22 17:25:12 [INFO]: Epoch 039 - training loss: 0.2635, validation loss: 0.0312
2024-05-22 17:25:12 [INFO]: Epoch 040 - training loss: 0.2650, validation loss: 0.0305
2024-05-22 17:25:12 [INFO]: Epoch 041 - training loss: 0.2633, validation loss: 0.0290
2024-05-22 17:25:13 [INFO]: Epoch 042 - training loss: 0.2544, validation loss: 0.0272
2024-05-22 17:25:13 [INFO]: Epoch 043 - training loss: 0.2589, validation loss: 0.0288
2024-05-22 17:25:13 [INFO]: Epoch 044 - training loss: 0.2596, validation loss: 0.0280
2024-05-22 17:25:13 [INFO]: Epoch 045 - training loss: 0.2533, validation loss: 0.0285
2024-05-22 17:25:13 [INFO]: Epoch 046 - training loss: 0.2500, validation loss: 0.0255
2024-05-22 17:25:14 [INFO]: Epoch 047 - training loss: 0.2491, validation loss: 0.0286
2024-05-22 17:25:14 [INFO]: Epoch 048 - training loss: 0.2466, validation loss: 0.0273
2024-05-22 17:25:14 [INFO]: Epoch 049 - training loss: 0.2499, validation loss: 0.0298
2024-05-22 17:25:14 [INFO]: Epoch 050 - training loss: 0.2559, validation loss: 0.0304
2024-05-22 17:25:14 [INFO]: Epoch 051 - training loss: 0.2471, validation loss: 0.0253
2024-05-22 17:25:15 [INFO]: Epoch 052 - training loss: 0.2482, validation loss: 0.0256
2024-05-22 17:25:15 [INFO]: Epoch 053 - training loss: 0.2464, validation loss: 0.0232
2024-05-22 17:25:15 [INFO]: Epoch 054 - training loss: 0.2382, validation loss: 0.0253
2024-05-22 17:25:15 [INFO]: Epoch 055 - training loss: 0.2389, validation loss: 0.0247
2024-05-22 17:25:15 [INFO]: Epoch 056 - training loss: 0.2359, validation loss: 0.0302
2024-05-22 17:25:16 [INFO]: Epoch 057 - training loss: 0.2328, validation loss: 0.0224
2024-05-22 17:25:16 [INFO]: Epoch 058 - training loss: 0.2302, validation loss: 0.0247
2024-05-22 17:25:16 [INFO]: Epoch 059 - training loss: 0.2328, validation loss: 0.0230
2024-05-22 17:25:16 [INFO]: Epoch 060 - training loss: 0.2288, validation loss: 0.0256
2024-05-22 17:25:16 [INFO]: Epoch 061 - training loss: 0.2360, validation loss: 0.0248
2024-05-22 17:25:17 [INFO]: Epoch 062 - training loss: 0.2266, validation loss: 0.0229
2024-05-22 17:25:17 [INFO]: Epoch 063 - training loss: 0.2308, validation loss: 0.0223
2024-05-22 17:25:17 [INFO]: Epoch 064 - training loss: 0.2383, validation loss: 0.0237
2024-05-22 17:25:17 [INFO]: Epoch 065 - training loss: 0.2342, validation loss: 0.0228
2024-05-22 17:25:17 [INFO]: Epoch 066 - training loss: 0.2247, validation loss: 0.0226
2024-05-22 17:25:18 [INFO]: Epoch 067 - training loss: 0.2202, validation loss: 0.0222
2024-05-22 17:25:18 [INFO]: Epoch 068 - training loss: 0.2155, validation loss: 0.0234
2024-05-22 17:25:18 [INFO]: Epoch 069 - training loss: 0.2225, validation loss: 0.0239
2024-05-22 17:25:18 [INFO]: Epoch 070 - training loss: 0.2310, validation loss: 0.0221
2024-05-22 17:25:18 [INFO]: Epoch 071 - training loss: 0.2250, validation loss: 0.0219
2024-05-22 17:25:19 [INFO]: Epoch 072 - training loss: 0.2167, validation loss: 0.0223
2024-05-22 17:25:19 [INFO]: Epoch 073 - training loss: 0.2163, validation loss: 0.0235
2024-05-22 17:25:19 [INFO]: Epoch 074 - training loss: 0.2136, validation loss: 0.0220
2024-05-22 17:25:19 [INFO]: Epoch 075 - training loss: 0.2146, validation loss: 0.0213
2024-05-22 17:25:20 [INFO]: Epoch 076 - training loss: 0.2147, validation loss: 0.0214
2024-05-22 17:25:20 [INFO]: Epoch 077 - training loss: 0.2116, validation loss: 0.0243
2024-05-22 17:25:20 [INFO]: Epoch 078 - training loss: 0.2139, validation loss: 0.0216
2024-05-22 17:25:20 [INFO]: Epoch 079 - training loss: 0.2103, validation loss: 0.0221
2024-05-22 17:25:20 [INFO]: Epoch 080 - training loss: 0.2115, validation loss: 0.0230
2024-05-22 17:25:21 [INFO]: Epoch 081 - training loss: 0.2119, validation loss: 0.0231
2024-05-22 17:25:21 [INFO]: Epoch 082 - training loss: 0.2112, validation loss: 0.0235
2024-05-22 17:25:21 [INFO]: Epoch 083 - training loss: 0.2087, validation loss: 0.0247
2024-05-22 17:25:21 [INFO]: Epoch 084 - training loss: 0.2256, validation loss: 0.0209
2024-05-22 17:25:21 [INFO]: Epoch 085 - training loss: 0.2092, validation loss: 0.0204
2024-05-22 17:25:22 [INFO]: Epoch 086 - training loss: 0.2024, validation loss: 0.0224
2024-05-22 17:25:22 [INFO]: Epoch 087 - training loss: 0.2072, validation loss: 0.0212
2024-05-22 17:25:22 [INFO]: Epoch 088 - training loss: 0.2061, validation loss: 0.0199
2024-05-22 17:25:22 [INFO]: Epoch 089 - training loss: 0.2007, validation loss: 0.0208
2024-05-22 17:25:22 [INFO]: Epoch 090 - training loss: 0.2059, validation loss: 0.0207
2024-05-22 17:25:23 [INFO]: Epoch 091 - training loss: 0.2055, validation loss: 0.0203
2024-05-22 17:25:23 [INFO]: Epoch 092 - training loss: 0.2078, validation loss: 0.0196
2024-05-22 17:25:23 [INFO]: Epoch 093 - training loss: 0.2052, validation loss: 0.0214
2024-05-22 17:25:23 [INFO]: Epoch 094 - training loss: 0.2039, validation loss: 0.0207
2024-05-22 17:25:23 [INFO]: Epoch 095 - training loss: 0.1986, validation loss: 0.0197
2024-05-22 17:25:24 [INFO]: Epoch 096 - training loss: 0.1984, validation loss: 0.0191
2024-05-22 17:25:24 [INFO]: Epoch 097 - training loss: 0.1996, validation loss: 0.0202
2024-05-22 17:25:24 [INFO]: Epoch 098 - training loss: 0.2015, validation loss: 0.0226
2024-05-22 17:25:24 [INFO]: Epoch 099 - training loss: 0.2029, validation loss: 0.0246
2024-05-22 17:25:24 [INFO]: Epoch 100 - training loss: 0.2022, validation loss: 0.0210
2024-05-22 17:25:25 [INFO]: Epoch 101 - training loss: 0.2015, validation loss: 0.0207
2024-05-22 17:25:25 [INFO]: Epoch 102 - training loss: 0.2000, validation loss: 0.0199
2024-05-22 17:25:25 [INFO]: Epoch 103 - training loss: 0.1950, validation loss: 0.0192
2024-05-22 17:25:25 [INFO]: Epoch 104 - training loss: 0.1995, validation loss: 0.0211
2024-05-22 17:25:25 [INFO]: Epoch 105 - training loss: 0.2159, validation loss: 0.0222
2024-05-22 17:25:26 [INFO]: Epoch 106 - training loss: 0.2015, validation loss: 0.0191
2024-05-22 17:25:26 [INFO]: Epoch 107 - training loss: 0.2005, validation loss: 0.0209
2024-05-22 17:25:26 [INFO]: Epoch 108 - training loss: 0.2005, validation loss: 0.0200
2024-05-22 17:25:26 [INFO]: Epoch 109 - training loss: 0.1944, validation loss: 0.0220
2024-05-22 17:25:26 [INFO]: Epoch 110 - training loss: 0.2026, validation loss: 0.0192
2024-05-22 17:25:27 [INFO]: Epoch 111 - training loss: 0.1934, validation loss: 0.0185
2024-05-22 17:25:27 [INFO]: Epoch 112 - training loss: 0.1918, validation loss: 0.0189
2024-05-22 17:25:27 [INFO]: Epoch 113 - training loss: 0.1972, validation loss: 0.0185
2024-05-22 17:25:27 [INFO]: Epoch 114 - training loss: 0.1917, validation loss: 0.0201
2024-05-22 17:25:27 [INFO]: Epoch 115 - training loss: 0.1905, validation loss: 0.0199
2024-05-22 17:25:28 [INFO]: Epoch 116 - training loss: 0.1909, validation loss: 0.0188
2024-05-22 17:25:28 [INFO]: Epoch 117 - training loss: 0.1885, validation loss: 0.0219
2024-05-22 17:25:28 [INFO]: Epoch 118 - training loss: 0.2019, validation loss: 0.0202
2024-05-22 17:25:28 [INFO]: Epoch 119 - training loss: 0.1988, validation loss: 0.0224
2024-05-22 17:25:29 [INFO]: Epoch 120 - training loss: 0.1971, validation loss: 0.0185
2024-05-22 17:25:29 [INFO]: Epoch 121 - training loss: 0.1887, validation loss: 0.0269
2024-05-22 17:25:29 [INFO]: Epoch 122 - training loss: 0.1963, validation loss: 0.0200
2024-05-22 17:25:29 [INFO]: Epoch 123 - training loss: 0.1917, validation loss: 0.0196
2024-05-22 17:25:29 [INFO]: Epoch 124 - training loss: 0.1887, validation loss: 0.0186
2024-05-22 17:25:30 [INFO]: Epoch 125 - training loss: 0.1872, validation loss: 0.0187
2024-05-22 17:25:30 [INFO]: Epoch 126 - training loss: 0.1878, validation loss: 0.0182
2024-05-22 17:25:30 [INFO]: Epoch 127 - training loss: 0.1862, validation loss: 0.0195
2024-05-22 17:25:30 [INFO]: Epoch 128 - training loss: 0.1885, validation loss: 0.0196
2024-05-22 17:25:30 [INFO]: Epoch 129 - training loss: 0.1885, validation loss: 0.0214
2024-05-22 17:25:31 [INFO]: Epoch 130 - training loss: 0.1936, validation loss: 0.0229
2024-05-22 17:25:31 [INFO]: Epoch 131 - training loss: 0.1915, validation loss: 0.0231
2024-05-22 17:25:31 [INFO]: Epoch 132 - training loss: 0.1956, validation loss: 0.0197
2024-05-22 17:25:31 [INFO]: Epoch 133 - training loss: 0.1891, validation loss: 0.0190
2024-05-22 17:25:31 [INFO]: Epoch 134 - training loss: 0.1880, validation loss: 0.0200
2024-05-22 17:25:32 [INFO]: Epoch 135 - training loss: 0.1839, validation loss: 0.0189
2024-05-22 17:25:32 [INFO]: Epoch 136 - training loss: 0.1880, validation loss: 0.0191
2024-05-22 17:25:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:25:32 [INFO]: Finished training. The best model is from epoch#126.
2024-05-22 17:25:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/Transformer_ettm1/20240522_T172504/Transformer.pypots
2024-05-22 17:25:32 [INFO]: Transformer on ETTm1: MAE=0.1178, MSE=0.0291
2024-05-22 17:25:32 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-22 17:25:32 [INFO]: Using the given device: cuda:0
2024-05-22 17:25:32 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_ettm1/20240522_T172532
2024-05-22 17:25:32 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_ettm1/20240522_T172532/tensorboard
2024-05-22 17:25:32 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 17:25:32 [INFO]: Epoch 001 - training loss: 0.1536, validation loss: 0.0636
2024-05-22 17:25:32 [INFO]: Epoch 002 - training loss: 0.0722, validation loss: 0.0403
2024-05-22 17:25:33 [INFO]: Epoch 003 - training loss: 0.0568, validation loss: 0.0334
2024-05-22 17:25:33 [INFO]: Epoch 004 - training loss: 0.0499, validation loss: 0.0314
2024-05-22 17:25:33 [INFO]: Epoch 005 - training loss: 0.0503, validation loss: 0.0299
2024-05-22 17:25:33 [INFO]: Epoch 006 - training loss: 0.0499, validation loss: 0.0318
2024-05-22 17:25:33 [INFO]: Epoch 007 - training loss: 0.0513, validation loss: 0.0314
2024-05-22 17:25:34 [INFO]: Epoch 008 - training loss: 0.0494, validation loss: 0.0317
2024-05-22 17:25:34 [INFO]: Epoch 009 - training loss: 0.0490, validation loss: 0.0309
2024-05-22 17:25:34 [INFO]: Epoch 010 - training loss: 0.0459, validation loss: 0.0300
2024-05-22 17:25:34 [INFO]: Epoch 011 - training loss: 0.0446, validation loss: 0.0311
2024-05-22 17:25:34 [INFO]: Epoch 012 - training loss: 0.0466, validation loss: 0.0297
2024-05-22 17:25:35 [INFO]: Epoch 013 - training loss: 0.0457, validation loss: 0.0294
2024-05-22 17:25:35 [INFO]: Epoch 014 - training loss: 0.0446, validation loss: 0.0321
2024-05-22 17:25:35 [INFO]: Epoch 015 - training loss: 0.0475, validation loss: 0.0376
2024-05-22 17:25:35 [INFO]: Epoch 016 - training loss: 0.0481, validation loss: 0.0319
2024-05-22 17:25:35 [INFO]: Epoch 017 - training loss: 0.0463, validation loss: 0.0311
2024-05-22 17:25:35 [INFO]: Epoch 018 - training loss: 0.0441, validation loss: 0.0286
2024-05-22 17:25:36 [INFO]: Epoch 019 - training loss: 0.0469, validation loss: 0.0319
2024-05-22 17:25:36 [INFO]: Epoch 020 - training loss: 0.0497, validation loss: 0.0326
2024-05-22 17:25:36 [INFO]: Epoch 021 - training loss: 0.0444, validation loss: 0.0309
2024-05-22 17:25:36 [INFO]: Epoch 022 - training loss: 0.0437, validation loss: 0.0265
2024-05-22 17:25:36 [INFO]: Epoch 023 - training loss: 0.0449, validation loss: 0.0294
2024-05-22 17:25:37 [INFO]: Epoch 024 - training loss: 0.0449, validation loss: 0.0272
2024-05-22 17:25:37 [INFO]: Epoch 025 - training loss: 0.0464, validation loss: 0.0302
2024-05-22 17:25:37 [INFO]: Epoch 026 - training loss: 0.0455, validation loss: 0.0300
2024-05-22 17:25:37 [INFO]: Epoch 027 - training loss: 0.0436, validation loss: 0.0282
2024-05-22 17:25:37 [INFO]: Epoch 028 - training loss: 0.0399, validation loss: 0.0268
2024-05-22 17:25:38 [INFO]: Epoch 029 - training loss: 0.0388, validation loss: 0.0263
2024-05-22 17:25:38 [INFO]: Epoch 030 - training loss: 0.0393, validation loss: 0.0267
2024-05-22 17:25:38 [INFO]: Epoch 031 - training loss: 0.0376, validation loss: 0.0290
2024-05-22 17:25:38 [INFO]: Epoch 032 - training loss: 0.0384, validation loss: 0.0269
2024-05-22 17:25:38 [INFO]: Epoch 033 - training loss: 0.0392, validation loss: 0.0282
2024-05-22 17:25:39 [INFO]: Epoch 034 - training loss: 0.0416, validation loss: 0.0268
2024-05-22 17:25:39 [INFO]: Epoch 035 - training loss: 0.0455, validation loss: 0.0260
2024-05-22 17:25:39 [INFO]: Epoch 036 - training loss: 0.0409, validation loss: 0.0277
2024-05-22 17:25:39 [INFO]: Epoch 037 - training loss: 0.0379, validation loss: 0.0256
2024-05-22 17:25:39 [INFO]: Epoch 038 - training loss: 0.0375, validation loss: 0.0270
2024-05-22 17:25:40 [INFO]: Epoch 039 - training loss: 0.0382, validation loss: 0.0274
2024-05-22 17:25:40 [INFO]: Epoch 040 - training loss: 0.0386, validation loss: 0.0265
2024-05-22 17:25:40 [INFO]: Epoch 041 - training loss: 0.0396, validation loss: 0.0251
2024-05-22 17:25:40 [INFO]: Epoch 042 - training loss: 0.0384, validation loss: 0.0253
2024-05-22 17:25:40 [INFO]: Epoch 043 - training loss: 0.0385, validation loss: 0.0258
2024-05-22 17:25:40 [INFO]: Epoch 044 - training loss: 0.0380, validation loss: 0.0244
2024-05-22 17:25:41 [INFO]: Epoch 045 - training loss: 0.0362, validation loss: 0.0232
2024-05-22 17:25:41 [INFO]: Epoch 046 - training loss: 0.0352, validation loss: 0.0250
2024-05-22 17:25:41 [INFO]: Epoch 047 - training loss: 0.0362, validation loss: 0.0240
2024-05-22 17:25:41 [INFO]: Epoch 048 - training loss: 0.0365, validation loss: 0.0250
2024-05-22 17:25:41 [INFO]: Epoch 049 - training loss: 0.0376, validation loss: 0.0242
2024-05-22 17:25:42 [INFO]: Epoch 050 - training loss: 0.0357, validation loss: 0.0260
2024-05-22 17:25:42 [INFO]: Epoch 051 - training loss: 0.0364, validation loss: 0.0247
2024-05-22 17:25:42 [INFO]: Epoch 052 - training loss: 0.0375, validation loss: 0.0259
2024-05-22 17:25:42 [INFO]: Epoch 053 - training loss: 0.0366, validation loss: 0.0243
2024-05-22 17:25:42 [INFO]: Epoch 054 - training loss: 0.0352, validation loss: 0.0231
2024-05-22 17:25:43 [INFO]: Epoch 055 - training loss: 0.0354, validation loss: 0.0236
2024-05-22 17:25:43 [INFO]: Epoch 056 - training loss: 0.0352, validation loss: 0.0227
2024-05-22 17:25:43 [INFO]: Epoch 057 - training loss: 0.0331, validation loss: 0.0228
2024-05-22 17:25:43 [INFO]: Epoch 058 - training loss: 0.0337, validation loss: 0.0232
2024-05-22 17:25:43 [INFO]: Epoch 059 - training loss: 0.0368, validation loss: 0.0225
2024-05-22 17:25:44 [INFO]: Epoch 060 - training loss: 0.0329, validation loss: 0.0225
2024-05-22 17:25:44 [INFO]: Epoch 061 - training loss: 0.0309, validation loss: 0.0217
2024-05-22 17:25:44 [INFO]: Epoch 062 - training loss: 0.0315, validation loss: 0.0215
2024-05-22 17:25:44 [INFO]: Epoch 063 - training loss: 0.0324, validation loss: 0.0218
2024-05-22 17:25:44 [INFO]: Epoch 064 - training loss: 0.0362, validation loss: 0.0232
2024-05-22 17:25:45 [INFO]: Epoch 065 - training loss: 0.0345, validation loss: 0.0215
2024-05-22 17:25:45 [INFO]: Epoch 066 - training loss: 0.0332, validation loss: 0.0225
2024-05-22 17:25:45 [INFO]: Epoch 067 - training loss: 0.0322, validation loss: 0.0210
2024-05-22 17:25:45 [INFO]: Epoch 068 - training loss: 0.0311, validation loss: 0.0217
2024-05-22 17:25:45 [INFO]: Epoch 069 - training loss: 0.0334, validation loss: 0.0240
2024-05-22 17:25:45 [INFO]: Epoch 070 - training loss: 0.0363, validation loss: 0.0226
2024-05-22 17:25:46 [INFO]: Epoch 071 - training loss: 0.0343, validation loss: 0.0211
2024-05-22 17:25:46 [INFO]: Epoch 072 - training loss: 0.0326, validation loss: 0.0211
2024-05-22 17:25:46 [INFO]: Epoch 073 - training loss: 0.0322, validation loss: 0.0212
2024-05-22 17:25:46 [INFO]: Epoch 074 - training loss: 0.0310, validation loss: 0.0207
2024-05-22 17:25:46 [INFO]: Epoch 075 - training loss: 0.0304, validation loss: 0.0210
2024-05-22 17:25:47 [INFO]: Epoch 076 - training loss: 0.0319, validation loss: 0.0208
2024-05-22 17:25:47 [INFO]: Epoch 077 - training loss: 0.0306, validation loss: 0.0225
2024-05-22 17:25:47 [INFO]: Epoch 078 - training loss: 0.0298, validation loss: 0.0204
2024-05-22 17:25:47 [INFO]: Epoch 079 - training loss: 0.0301, validation loss: 0.0207
2024-05-22 17:25:47 [INFO]: Epoch 080 - training loss: 0.0308, validation loss: 0.0198
2024-05-22 17:25:48 [INFO]: Epoch 081 - training loss: 0.0292, validation loss: 0.0201
2024-05-22 17:25:48 [INFO]: Epoch 082 - training loss: 0.0307, validation loss: 0.0201
2024-05-22 17:25:48 [INFO]: Epoch 083 - training loss: 0.0315, validation loss: 0.0206
2024-05-22 17:25:48 [INFO]: Epoch 084 - training loss: 0.0304, validation loss: 0.0201
2024-05-22 17:25:48 [INFO]: Epoch 085 - training loss: 0.0322, validation loss: 0.0220
2024-05-22 17:25:49 [INFO]: Epoch 086 - training loss: 0.0343, validation loss: 0.0229
2024-05-22 17:25:49 [INFO]: Epoch 087 - training loss: 0.0303, validation loss: 0.0209
2024-05-22 17:25:49 [INFO]: Epoch 088 - training loss: 0.0312, validation loss: 0.0210
2024-05-22 17:25:49 [INFO]: Epoch 089 - training loss: 0.0326, validation loss: 0.0212
2024-05-22 17:25:49 [INFO]: Epoch 090 - training loss: 0.0313, validation loss: 0.0208
2024-05-22 17:25:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:25:49 [INFO]: Finished training. The best model is from epoch#80.
2024-05-22 17:25:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/TimesNet_ettm1/20240522_T172532/TimesNet.pypots
2024-05-22 17:25:49 [INFO]: TimesNet on ETTm1: MAE=0.1051, MSE=0.0238
2024-05-22 17:25:49 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-22 17:25:49 [INFO]: Using the given device: cuda:0
2024-05-22 17:25:49 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549
2024-05-22 17:25:49 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/tensorboard
2024-05-22 17:25:49 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 17:25:51 [INFO]: Epoch 001 - training loss: 0.6862, validation loss: 0.4212
2024-05-22 17:25:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch1_loss0.4212494492530823.pypots
2024-05-22 17:25:54 [INFO]: Epoch 002 - training loss: 0.4117, validation loss: 0.3886
2024-05-22 17:25:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch2_loss0.38858138024806976.pypots
2024-05-22 17:25:56 [INFO]: Epoch 003 - training loss: 0.3224, validation loss: 0.3429
2024-05-22 17:25:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch3_loss0.3429024741053581.pypots
2024-05-22 17:25:58 [INFO]: Epoch 004 - training loss: 0.3415, validation loss: 0.3375
2024-05-22 17:25:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch4_loss0.33745306730270386.pypots
2024-05-22 17:26:00 [INFO]: Epoch 005 - training loss: 0.2800, validation loss: 0.3046
2024-05-22 17:26:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch5_loss0.30455464124679565.pypots
2024-05-22 17:26:02 [INFO]: Epoch 006 - training loss: 0.3010, validation loss: 0.3143
2024-05-22 17:26:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch6_loss0.31433603167533875.pypots
2024-05-22 17:26:04 [INFO]: Epoch 007 - training loss: 0.2966, validation loss: 0.2837
2024-05-22 17:26:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch7_loss0.28374289721250534.pypots
2024-05-22 17:26:06 [INFO]: Epoch 008 - training loss: 0.2685, validation loss: 0.2701
2024-05-22 17:26:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch8_loss0.27013955265283585.pypots
2024-05-22 17:26:08 [INFO]: Epoch 009 - training loss: 0.2440, validation loss: 0.2591
2024-05-22 17:26:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch9_loss0.2590992823243141.pypots
2024-05-22 17:26:10 [INFO]: Epoch 010 - training loss: 0.2977, validation loss: 0.2649
2024-05-22 17:26:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch10_loss0.26493220031261444.pypots
2024-05-22 17:26:12 [INFO]: Epoch 011 - training loss: 0.2475, validation loss: 0.2577
2024-05-22 17:26:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch11_loss0.2576558515429497.pypots
2024-05-22 17:26:14 [INFO]: Epoch 012 - training loss: 0.2500, validation loss: 0.2354
2024-05-22 17:26:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch12_loss0.23543503880500793.pypots
2024-05-22 17:26:16 [INFO]: Epoch 013 - training loss: 0.2569, validation loss: 0.2407
2024-05-22 17:26:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch13_loss0.24069910123944283.pypots
2024-05-22 17:26:18 [INFO]: Epoch 014 - training loss: 0.2403, validation loss: 0.2167
2024-05-22 17:26:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch14_loss0.21673225238919258.pypots
2024-05-22 17:26:20 [INFO]: Epoch 015 - training loss: 0.2196, validation loss: 0.2266
2024-05-22 17:26:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch15_loss0.22656488791108131.pypots
2024-05-22 17:26:22 [INFO]: Epoch 016 - training loss: 0.2279, validation loss: 0.2216
2024-05-22 17:26:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch16_loss0.22159084305167198.pypots
2024-05-22 17:26:24 [INFO]: Epoch 017 - training loss: 0.2536, validation loss: 0.2182
2024-05-22 17:26:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch17_loss0.21816285699605942.pypots
2024-05-22 17:26:26 [INFO]: Epoch 018 - training loss: 0.1946, validation loss: 0.2029
2024-05-22 17:26:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch18_loss0.2028937116265297.pypots
2024-05-22 17:26:28 [INFO]: Epoch 019 - training loss: 0.2086, validation loss: 0.2127
2024-05-22 17:26:29 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch19_loss0.21266233175992966.pypots
2024-05-22 17:26:31 [INFO]: Epoch 020 - training loss: 0.1783, validation loss: 0.1940
2024-05-22 17:26:31 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch20_loss0.19397875666618347.pypots
2024-05-22 17:26:33 [INFO]: Epoch 021 - training loss: 0.1862, validation loss: 0.1921
2024-05-22 17:26:33 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch21_loss0.19206521287560463.pypots
2024-05-22 17:26:35 [INFO]: Epoch 022 - training loss: 0.2109, validation loss: 0.1977
2024-05-22 17:26:35 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch22_loss0.19769072905182838.pypots
2024-05-22 17:26:37 [INFO]: Epoch 023 - training loss: 0.2258, validation loss: 0.2112
2024-05-22 17:26:37 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch23_loss0.21120046079158783.pypots
2024-05-22 17:26:39 [INFO]: Epoch 024 - training loss: 0.2057, validation loss: 0.1915
2024-05-22 17:26:39 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch24_loss0.1915138065814972.pypots
2024-05-22 17:26:41 [INFO]: Epoch 025 - training loss: 0.1984, validation loss: 0.1794
2024-05-22 17:26:41 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch25_loss0.17938373237848282.pypots
2024-05-22 17:26:43 [INFO]: Epoch 026 - training loss: 0.1755, validation loss: 0.1805
2024-05-22 17:26:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch26_loss0.1805240772664547.pypots
2024-05-22 17:26:45 [INFO]: Epoch 027 - training loss: 0.2471, validation loss: 0.1777
2024-05-22 17:26:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch27_loss0.17766913399100304.pypots
2024-05-22 17:26:47 [INFO]: Epoch 028 - training loss: 0.1807, validation loss: 0.1920
2024-05-22 17:26:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch28_loss0.19204672053456306.pypots
2024-05-22 17:26:49 [INFO]: Epoch 029 - training loss: 0.1887, validation loss: 0.1841
2024-05-22 17:26:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch29_loss0.1840648576617241.pypots
2024-05-22 17:26:51 [INFO]: Epoch 030 - training loss: 0.1839, validation loss: 0.1727
2024-05-22 17:26:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch30_loss0.1727476380765438.pypots
2024-05-22 17:26:53 [INFO]: Epoch 031 - training loss: 0.1974, validation loss: 0.1769
2024-05-22 17:26:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch31_loss0.17692993208765984.pypots
2024-05-22 17:26:55 [INFO]: Epoch 032 - training loss: 0.1992, validation loss: 0.1753
2024-05-22 17:26:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch32_loss0.17526830732822418.pypots
2024-05-22 17:26:57 [INFO]: Epoch 033 - training loss: 0.1961, validation loss: 0.1677
2024-05-22 17:26:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch33_loss0.1676855944097042.pypots
2024-05-22 17:26:59 [INFO]: Epoch 034 - training loss: 0.1700, validation loss: 0.1600
2024-05-22 17:26:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch34_loss0.1600460484623909.pypots
2024-05-22 17:27:01 [INFO]: Epoch 035 - training loss: 0.1642, validation loss: 0.1597
2024-05-22 17:27:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch35_loss0.15968246385455132.pypots
2024-05-22 17:27:03 [INFO]: Epoch 036 - training loss: 0.1679, validation loss: 0.1547
2024-05-22 17:27:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch36_loss0.1547372229397297.pypots
2024-05-22 17:27:05 [INFO]: Epoch 037 - training loss: 0.1863, validation loss: 0.1645
2024-05-22 17:27:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch37_loss0.16448404267430305.pypots
2024-05-22 17:27:08 [INFO]: Epoch 038 - training loss: 0.2084, validation loss: 0.1541
2024-05-22 17:27:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch38_loss0.15409453958272934.pypots
2024-05-22 17:27:10 [INFO]: Epoch 039 - training loss: 0.1842, validation loss: 0.1594
2024-05-22 17:27:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch39_loss0.15935881063342094.pypots
2024-05-22 17:27:12 [INFO]: Epoch 040 - training loss: 0.1767, validation loss: 0.1581
2024-05-22 17:27:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch40_loss0.1581098884344101.pypots
2024-05-22 17:27:14 [INFO]: Epoch 041 - training loss: 0.1739, validation loss: 0.1605
2024-05-22 17:27:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch41_loss0.16051015257835388.pypots
2024-05-22 17:27:16 [INFO]: Epoch 042 - training loss: 0.1749, validation loss: 0.1523
2024-05-22 17:27:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch42_loss0.15225112065672874.pypots
2024-05-22 17:27:18 [INFO]: Epoch 043 - training loss: 0.1769, validation loss: 0.1592
2024-05-22 17:27:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch43_loss0.15918916836380959.pypots
2024-05-22 17:27:20 [INFO]: Epoch 044 - training loss: 0.1855, validation loss: 0.1505
2024-05-22 17:27:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch44_loss0.1504838578402996.pypots
2024-05-22 17:27:22 [INFO]: Epoch 045 - training loss: 0.1649, validation loss: 0.1562
2024-05-22 17:27:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch45_loss0.1561596505343914.pypots
2024-05-22 17:27:24 [INFO]: Epoch 046 - training loss: 0.1421, validation loss: 0.1474
2024-05-22 17:27:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch46_loss0.14739607647061348.pypots
2024-05-22 17:27:26 [INFO]: Epoch 047 - training loss: 0.1619, validation loss: 0.1463
2024-05-22 17:27:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch47_loss0.14626246318221092.pypots
2024-05-22 17:27:28 [INFO]: Epoch 048 - training loss: 0.1583, validation loss: 0.1414
2024-05-22 17:27:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch48_loss0.14138862118124962.pypots
2024-05-22 17:27:30 [INFO]: Epoch 049 - training loss: 0.1526, validation loss: 0.1487
2024-05-22 17:27:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch49_loss0.14867907017469406.pypots
2024-05-22 17:27:32 [INFO]: Epoch 050 - training loss: 0.1835, validation loss: 0.1639
2024-05-22 17:27:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch50_loss0.16388610377907753.pypots
2024-05-22 17:27:34 [INFO]: Epoch 051 - training loss: 0.1793, validation loss: 0.1606
2024-05-22 17:27:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch51_loss0.16059105470776558.pypots
2024-05-22 17:27:36 [INFO]: Epoch 052 - training loss: 0.1894, validation loss: 0.1433
2024-05-22 17:27:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch52_loss0.1432553306221962.pypots
2024-05-22 17:27:38 [INFO]: Epoch 053 - training loss: 0.2021, validation loss: 0.1501
2024-05-22 17:27:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch53_loss0.15014779567718506.pypots
2024-05-22 17:27:40 [INFO]: Epoch 054 - training loss: 0.1376, validation loss: 0.1515
2024-05-22 17:27:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch54_loss0.15152228996157646.pypots
2024-05-22 17:27:43 [INFO]: Epoch 055 - training loss: 0.1698, validation loss: 0.1425
2024-05-22 17:27:43 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch55_loss0.14246418699622154.pypots
2024-05-22 17:27:45 [INFO]: Epoch 056 - training loss: 0.1518, validation loss: 0.1377
2024-05-22 17:27:45 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch56_loss0.13770272582769394.pypots
2024-05-22 17:27:47 [INFO]: Epoch 057 - training loss: 0.1637, validation loss: 0.1357
2024-05-22 17:27:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch57_loss0.13571060076355934.pypots
2024-05-22 17:27:49 [INFO]: Epoch 058 - training loss: 0.1861, validation loss: 0.1441
2024-05-22 17:27:49 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch58_loss0.14408645778894424.pypots
2024-05-22 17:27:51 [INFO]: Epoch 059 - training loss: 0.1724, validation loss: 0.1423
2024-05-22 17:27:51 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch59_loss0.1423150859773159.pypots
2024-05-22 17:27:53 [INFO]: Epoch 060 - training loss: 0.1728, validation loss: 0.1496
2024-05-22 17:27:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch60_loss0.14956825599074364.pypots
2024-05-22 17:27:55 [INFO]: Epoch 061 - training loss: 0.1552, validation loss: 0.1364
2024-05-22 17:27:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch61_loss0.1363786831498146.pypots
2024-05-22 17:27:57 [INFO]: Epoch 062 - training loss: 0.2064, validation loss: 0.1386
2024-05-22 17:27:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch62_loss0.1385561190545559.pypots
2024-05-22 17:27:59 [INFO]: Epoch 063 - training loss: 0.1621, validation loss: 0.1450
2024-05-22 17:27:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch63_loss0.14504233375191689.pypots
2024-05-22 17:28:01 [INFO]: Epoch 064 - training loss: 0.2152, validation loss: 0.1461
2024-05-22 17:28:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch64_loss0.14609985053539276.pypots
2024-05-22 17:28:03 [INFO]: Epoch 065 - training loss: 0.1830, validation loss: 0.1623
2024-05-22 17:28:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch65_loss0.1623353809118271.pypots
2024-05-22 17:28:05 [INFO]: Epoch 066 - training loss: 0.1771, validation loss: 0.1519
2024-05-22 17:28:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch66_loss0.15187440440058708.pypots
2024-05-22 17:28:07 [INFO]: Epoch 067 - training loss: 0.1760, validation loss: 0.1507
2024-05-22 17:28:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI_epoch67_loss0.1506592445075512.pypots
2024-05-22 17:28:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:28:07 [INFO]: Finished training. The best model is from epoch#57.
2024-05-22 17:28:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/20240522_T172549/CSDI.pypots
2024-05-22 17:28:23 [INFO]: CSDI on ETTm1: MAE=0.2160, MSE=0.4195
2024-05-22 17:28:23 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-22 17:28:23 [INFO]: Using the given device: cuda:0
2024-05-22 17:28:23 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_ettm1/20240522_T172823
2024-05-22 17:28:23 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_ettm1/20240522_T172823/tensorboard
2024-05-22 17:28:23 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 17:28:23 [INFO]: Epoch 001 - training loss: 23404.7061, validation loss: 0.9485
2024-05-22 17:28:23 [INFO]: Epoch 002 - training loss: 21172.1041, validation loss: 0.9436
2024-05-22 17:28:23 [INFO]: Epoch 003 - training loss: 19020.8899, validation loss: 0.9337
2024-05-22 17:28:23 [INFO]: Epoch 004 - training loss: 17105.1581, validation loss: 0.9252
2024-05-22 17:28:23 [INFO]: Epoch 005 - training loss: 15320.3307, validation loss: 0.8893
2024-05-22 17:28:24 [INFO]: Epoch 006 - training loss: 13702.3231, validation loss: 0.7930
2024-05-22 17:28:24 [INFO]: Epoch 007 - training loss: 12631.4372, validation loss: 0.6511
2024-05-22 17:28:24 [INFO]: Epoch 008 - training loss: 11957.7419, validation loss: 0.5494
2024-05-22 17:28:24 [INFO]: Epoch 009 - training loss: 11197.7245, validation loss: 0.4787
2024-05-22 17:28:24 [INFO]: Epoch 010 - training loss: 10912.0519, validation loss: 0.4439
2024-05-22 17:28:24 [INFO]: Epoch 011 - training loss: 10543.5620, validation loss: 0.4331
2024-05-22 17:28:24 [INFO]: Epoch 012 - training loss: 10302.7732, validation loss: 0.4134
2024-05-22 17:28:24 [INFO]: Epoch 013 - training loss: 10148.4278, validation loss: 0.3943
2024-05-22 17:28:24 [INFO]: Epoch 014 - training loss: 10056.8167, validation loss: 0.3790
2024-05-22 17:28:24 [INFO]: Epoch 015 - training loss: 9980.5216, validation loss: 0.3629
2024-05-22 17:28:25 [INFO]: Epoch 016 - training loss: 9876.1397, validation loss: 0.3418
2024-05-22 17:28:25 [INFO]: Epoch 017 - training loss: 9775.3026, validation loss: 0.3292
2024-05-22 17:28:25 [INFO]: Epoch 018 - training loss: 9725.1430, validation loss: 0.3159
2024-05-22 17:28:25 [INFO]: Epoch 019 - training loss: 9741.7230, validation loss: 0.3026
2024-05-22 17:28:25 [INFO]: Epoch 020 - training loss: 9655.6569, validation loss: 0.2943
2024-05-22 17:28:25 [INFO]: Epoch 021 - training loss: 9605.9528, validation loss: 0.2828
2024-05-22 17:28:25 [INFO]: Epoch 022 - training loss: 9622.7041, validation loss: 0.2763
2024-05-22 17:28:25 [INFO]: Epoch 023 - training loss: 9551.6387, validation loss: 0.2652
2024-05-22 17:28:25 [INFO]: Epoch 024 - training loss: 9531.7599, validation loss: 0.2557
2024-05-22 17:28:26 [INFO]: Epoch 025 - training loss: 9541.4326, validation loss: 0.2491
2024-05-22 17:28:26 [INFO]: Epoch 026 - training loss: 9512.3981, validation loss: 0.2514
2024-05-22 17:28:26 [INFO]: Epoch 027 - training loss: 9500.2488, validation loss: 0.2474
2024-05-22 17:28:26 [INFO]: Epoch 028 - training loss: 9469.2159, validation loss: 0.2348
2024-05-22 17:28:26 [INFO]: Epoch 029 - training loss: 9476.2958, validation loss: 0.2307
2024-05-22 17:28:26 [INFO]: Epoch 030 - training loss: 9446.5902, validation loss: 0.2266
2024-05-22 17:28:26 [INFO]: Epoch 031 - training loss: 9438.6541, validation loss: 0.2209
2024-05-22 17:28:26 [INFO]: Epoch 032 - training loss: 9426.2042, validation loss: 0.2182
2024-05-22 17:28:26 [INFO]: Epoch 033 - training loss: 9420.0050, validation loss: 0.2160
2024-05-22 17:28:27 [INFO]: Epoch 034 - training loss: 9424.5047, validation loss: 0.2095
2024-05-22 17:28:27 [INFO]: Epoch 035 - training loss: 9406.1066, validation loss: 0.2032
2024-05-22 17:28:27 [INFO]: Epoch 036 - training loss: 9399.2678, validation loss: 0.2024
2024-05-22 17:28:27 [INFO]: Epoch 037 - training loss: 9402.1816, validation loss: 0.1978
2024-05-22 17:28:27 [INFO]: Epoch 038 - training loss: 9398.3104, validation loss: 0.1954
2024-05-22 17:28:27 [INFO]: Epoch 039 - training loss: 9382.5819, validation loss: 0.1935
2024-05-22 17:28:27 [INFO]: Epoch 040 - training loss: 9382.3149, validation loss: 0.1868
2024-05-22 17:28:27 [INFO]: Epoch 041 - training loss: 9378.3466, validation loss: 0.1857
2024-05-22 17:28:27 [INFO]: Epoch 042 - training loss: 9392.9705, validation loss: 0.1822
2024-05-22 17:28:27 [INFO]: Epoch 043 - training loss: 9367.6705, validation loss: 0.1791
2024-05-22 17:28:28 [INFO]: Epoch 044 - training loss: 9363.3108, validation loss: 0.1748
2024-05-22 17:28:28 [INFO]: Epoch 045 - training loss: 9370.8831, validation loss: 0.1725
2024-05-22 17:28:28 [INFO]: Epoch 046 - training loss: 9375.8852, validation loss: 0.1690
2024-05-22 17:28:28 [INFO]: Epoch 047 - training loss: 9370.6575, validation loss: 0.1651
2024-05-22 17:28:28 [INFO]: Epoch 048 - training loss: 9348.6276, validation loss: 0.1629
2024-05-22 17:28:28 [INFO]: Epoch 049 - training loss: 9344.6660, validation loss: 0.1615
2024-05-22 17:28:28 [INFO]: Epoch 050 - training loss: 9342.9482, validation loss: 0.1599
2024-05-22 17:28:28 [INFO]: Epoch 051 - training loss: 9391.7292, validation loss: 0.1594
2024-05-22 17:28:28 [INFO]: Epoch 052 - training loss: 9339.8129, validation loss: 0.1567
2024-05-22 17:28:29 [INFO]: Epoch 053 - training loss: 9336.1326, validation loss: 0.1558
2024-05-22 17:28:29 [INFO]: Epoch 054 - training loss: 9333.3984, validation loss: 0.1525
2024-05-22 17:28:29 [INFO]: Epoch 055 - training loss: 9330.6269, validation loss: 0.1521
2024-05-22 17:28:29 [INFO]: Epoch 056 - training loss: 9333.8634, validation loss: 0.1505
2024-05-22 17:28:29 [INFO]: Epoch 057 - training loss: 9329.0090, validation loss: 0.1490
2024-05-22 17:28:29 [INFO]: Epoch 058 - training loss: 9332.2565, validation loss: 0.1471
2024-05-22 17:28:29 [INFO]: Epoch 059 - training loss: 9332.8766, validation loss: 0.1464
2024-05-22 17:28:29 [INFO]: Epoch 060 - training loss: 9322.5673, validation loss: 0.1454
2024-05-22 17:28:29 [INFO]: Epoch 061 - training loss: 9325.0369, validation loss: 0.1439
2024-05-22 17:28:30 [INFO]: Epoch 062 - training loss: 9320.1786, validation loss: 0.1448
2024-05-22 17:28:30 [INFO]: Epoch 063 - training loss: 9319.5054, validation loss: 0.1427
2024-05-22 17:28:30 [INFO]: Epoch 064 - training loss: 9319.1874, validation loss: 0.1412
2024-05-22 17:28:30 [INFO]: Epoch 065 - training loss: 9322.7824, validation loss: 0.1420
2024-05-22 17:28:30 [INFO]: Epoch 066 - training loss: 9316.1849, validation loss: 0.1424
2024-05-22 17:28:30 [INFO]: Epoch 067 - training loss: 9316.4229, validation loss: 0.1415
2024-05-22 17:28:30 [INFO]: Epoch 068 - training loss: 9313.2508, validation loss: 0.1397
2024-05-22 17:28:30 [INFO]: Epoch 069 - training loss: 9313.0056, validation loss: 0.1390
2024-05-22 17:28:30 [INFO]: Epoch 070 - training loss: 9310.9160, validation loss: 0.1389
2024-05-22 17:28:30 [INFO]: Epoch 071 - training loss: 9310.6219, validation loss: 0.1387
2024-05-22 17:28:31 [INFO]: Epoch 072 - training loss: 9313.1824, validation loss: 0.1395
2024-05-22 17:28:31 [INFO]: Epoch 073 - training loss: 9311.9230, validation loss: 0.1386
2024-05-22 17:28:31 [INFO]: Epoch 074 - training loss: 9308.4636, validation loss: 0.1355
2024-05-22 17:28:31 [INFO]: Epoch 075 - training loss: 9309.4622, validation loss: 0.1363
2024-05-22 17:28:31 [INFO]: Epoch 076 - training loss: 9306.3235, validation loss: 0.1358
2024-05-22 17:28:31 [INFO]: Epoch 077 - training loss: 9304.2276, validation loss: 0.1355
2024-05-22 17:28:31 [INFO]: Epoch 078 - training loss: 9306.3549, validation loss: 0.1347
2024-05-22 17:28:31 [INFO]: Epoch 079 - training loss: 9306.2710, validation loss: 0.1339
2024-05-22 17:28:31 [INFO]: Epoch 080 - training loss: 9307.1766, validation loss: 0.1324
2024-05-22 17:28:32 [INFO]: Epoch 081 - training loss: 9304.3033, validation loss: 0.1327
2024-05-22 17:28:32 [INFO]: Epoch 082 - training loss: 9303.5750, validation loss: 0.1304
2024-05-22 17:28:32 [INFO]: Epoch 083 - training loss: 9301.6122, validation loss: 0.1335
2024-05-22 17:28:32 [INFO]: Epoch 084 - training loss: 9299.9252, validation loss: 0.1296
2024-05-22 17:28:32 [INFO]: Epoch 085 - training loss: 9299.3074, validation loss: 0.1298
2024-05-22 17:28:32 [INFO]: Epoch 086 - training loss: 9297.9754, validation loss: 0.1297
2024-05-22 17:28:32 [INFO]: Epoch 087 - training loss: 9298.7276, validation loss: 0.1260
2024-05-22 17:28:32 [INFO]: Epoch 088 - training loss: 9296.8694, validation loss: 0.1298
2024-05-22 17:28:32 [INFO]: Epoch 089 - training loss: 9298.2366, validation loss: 0.1281
2024-05-22 17:28:33 [INFO]: Epoch 090 - training loss: 9297.5106, validation loss: 0.1239
2024-05-22 17:28:33 [INFO]: Epoch 091 - training loss: 9297.1052, validation loss: 0.1269
2024-05-22 17:28:33 [INFO]: Epoch 092 - training loss: 9295.8939, validation loss: 0.1242
2024-05-22 17:28:33 [INFO]: Epoch 093 - training loss: 9294.0474, validation loss: 0.1232
2024-05-22 17:28:33 [INFO]: Epoch 094 - training loss: 9297.8613, validation loss: 0.1208
2024-05-22 17:28:33 [INFO]: Epoch 095 - training loss: 9295.2758, validation loss: 0.1279
2024-05-22 17:28:33 [INFO]: Epoch 096 - training loss: 9295.4268, validation loss: 0.1222
2024-05-22 17:28:33 [INFO]: Epoch 097 - training loss: 9291.5998, validation loss: 0.1207
2024-05-22 17:28:33 [INFO]: Epoch 098 - training loss: 9294.7371, validation loss: 0.1217
2024-05-22 17:28:33 [INFO]: Epoch 099 - training loss: 9297.3011, validation loss: 0.1210
2024-05-22 17:28:34 [INFO]: Epoch 100 - training loss: 9294.0797, validation loss: 0.1205
2024-05-22 17:28:34 [INFO]: Epoch 101 - training loss: 9293.4053, validation loss: 0.1190
2024-05-22 17:28:34 [INFO]: Epoch 102 - training loss: 9290.3532, validation loss: 0.1191
2024-05-22 17:28:34 [INFO]: Epoch 103 - training loss: 9291.9564, validation loss: 0.1164
2024-05-22 17:28:34 [INFO]: Epoch 104 - training loss: 9295.0062, validation loss: 0.1185
2024-05-22 17:28:34 [INFO]: Epoch 105 - training loss: 9292.4099, validation loss: 0.1162
2024-05-22 17:28:34 [INFO]: Epoch 106 - training loss: 9292.1075, validation loss: 0.1149
2024-05-22 17:28:34 [INFO]: Epoch 107 - training loss: 9290.8706, validation loss: 0.1132
2024-05-22 17:28:34 [INFO]: Epoch 108 - training loss: 9289.4729, validation loss: 0.1166
2024-05-22 17:28:35 [INFO]: Epoch 109 - training loss: 9288.3774, validation loss: 0.1141
2024-05-22 17:28:35 [INFO]: Epoch 110 - training loss: 9289.4653, validation loss: 0.1127
2024-05-22 17:28:35 [INFO]: Epoch 111 - training loss: 9289.1556, validation loss: 0.1149
2024-05-22 17:28:35 [INFO]: Epoch 112 - training loss: 9288.7279, validation loss: 0.1132
2024-05-22 17:28:35 [INFO]: Epoch 113 - training loss: 9286.6155, validation loss: 0.1153
2024-05-22 17:28:35 [INFO]: Epoch 114 - training loss: 9287.3723, validation loss: 0.1112
2024-05-22 17:28:35 [INFO]: Epoch 115 - training loss: 9287.4567, validation loss: 0.1106
2024-05-22 17:28:35 [INFO]: Epoch 116 - training loss: 9286.7704, validation loss: 0.1120
2024-05-22 17:28:35 [INFO]: Epoch 117 - training loss: 9289.0242, validation loss: 0.1103
2024-05-22 17:28:36 [INFO]: Epoch 118 - training loss: 9287.7034, validation loss: 0.1085
2024-05-22 17:28:36 [INFO]: Epoch 119 - training loss: 9286.7681, validation loss: 0.1083
2024-05-22 17:28:36 [INFO]: Epoch 120 - training loss: 9286.7596, validation loss: 0.1080
2024-05-22 17:28:36 [INFO]: Epoch 121 - training loss: 9285.3295, validation loss: 0.1085
2024-05-22 17:28:36 [INFO]: Epoch 122 - training loss: 9283.2822, validation loss: 0.1073
2024-05-22 17:28:36 [INFO]: Epoch 123 - training loss: 9283.7260, validation loss: 0.1051
2024-05-22 17:28:36 [INFO]: Epoch 124 - training loss: 9286.6453, validation loss: 0.1041
2024-05-22 17:28:36 [INFO]: Epoch 125 - training loss: 9284.6404, validation loss: 0.1065
2024-05-22 17:28:36 [INFO]: Epoch 126 - training loss: 9283.8796, validation loss: 0.1032
2024-05-22 17:28:36 [INFO]: Epoch 127 - training loss: 9282.6606, validation loss: 0.1050
2024-05-22 17:28:37 [INFO]: Epoch 128 - training loss: 9283.4904, validation loss: 0.1038
2024-05-22 17:28:37 [INFO]: Epoch 129 - training loss: 9284.2443, validation loss: 0.1025
2024-05-22 17:28:37 [INFO]: Epoch 130 - training loss: 9284.2840, validation loss: 0.1026
2024-05-22 17:28:37 [INFO]: Epoch 131 - training loss: 9285.5659, validation loss: 0.1027
2024-05-22 17:28:37 [INFO]: Epoch 132 - training loss: 9281.0676, validation loss: 0.1018
2024-05-22 17:28:37 [INFO]: Epoch 133 - training loss: 9282.5408, validation loss: 0.1028
2024-05-22 17:28:37 [INFO]: Epoch 134 - training loss: 9282.9415, validation loss: 0.1006
2024-05-22 17:28:37 [INFO]: Epoch 135 - training loss: 9281.6912, validation loss: 0.1000
2024-05-22 17:28:37 [INFO]: Epoch 136 - training loss: 9281.3881, validation loss: 0.1007
2024-05-22 17:28:38 [INFO]: Epoch 137 - training loss: 9283.0549, validation loss: 0.0986
2024-05-22 17:28:38 [INFO]: Epoch 138 - training loss: 9282.4370, validation loss: 0.0987
2024-05-22 17:28:38 [INFO]: Epoch 139 - training loss: 9279.9007, validation loss: 0.0993
2024-05-22 17:28:38 [INFO]: Epoch 140 - training loss: 9281.5488, validation loss: 0.0970
2024-05-22 17:28:38 [INFO]: Epoch 141 - training loss: 9282.3301, validation loss: 0.0982
2024-05-22 17:28:38 [INFO]: Epoch 142 - training loss: 9280.0616, validation loss: 0.0956
2024-05-22 17:28:38 [INFO]: Epoch 143 - training loss: 9281.8097, validation loss: 0.0979
2024-05-22 17:28:38 [INFO]: Epoch 144 - training loss: 9279.8816, validation loss: 0.0970
2024-05-22 17:28:38 [INFO]: Epoch 145 - training loss: 9278.8821, validation loss: 0.0961
2024-05-22 17:28:39 [INFO]: Epoch 146 - training loss: 9281.1538, validation loss: 0.0946
2024-05-22 17:28:39 [INFO]: Epoch 147 - training loss: 9280.9460, validation loss: 0.0958
2024-05-22 17:28:39 [INFO]: Epoch 148 - training loss: 9279.9111, validation loss: 0.0959
2024-05-22 17:28:39 [INFO]: Epoch 149 - training loss: 9278.9918, validation loss: 0.0948
2024-05-22 17:28:39 [INFO]: Epoch 150 - training loss: 9280.0800, validation loss: 0.0945
2024-05-22 17:28:39 [INFO]: Epoch 151 - training loss: 9279.9817, validation loss: 0.0931
2024-05-22 17:28:39 [INFO]: Epoch 152 - training loss: 9278.6490, validation loss: 0.0943
2024-05-22 17:28:39 [INFO]: Epoch 153 - training loss: 9278.7224, validation loss: 0.0931
2024-05-22 17:28:39 [INFO]: Epoch 154 - training loss: 9279.7971, validation loss: 0.0921
2024-05-22 17:28:39 [INFO]: Epoch 155 - training loss: 9278.1361, validation loss: 0.0940
2024-05-22 17:28:40 [INFO]: Epoch 156 - training loss: 9278.1737, validation loss: 0.0921
2024-05-22 17:28:40 [INFO]: Epoch 157 - training loss: 9280.9374, validation loss: 0.0919
2024-05-22 17:28:40 [INFO]: Epoch 158 - training loss: 9277.7288, validation loss: 0.0937
2024-05-22 17:28:40 [INFO]: Epoch 159 - training loss: 9278.1148, validation loss: 0.0909
2024-05-22 17:28:40 [INFO]: Epoch 160 - training loss: 9277.1108, validation loss: 0.0909
2024-05-22 17:28:40 [INFO]: Epoch 161 - training loss: 9277.9565, validation loss: 0.0898
2024-05-22 17:28:40 [INFO]: Epoch 162 - training loss: 9275.8278, validation loss: 0.0904
2024-05-22 17:28:40 [INFO]: Epoch 163 - training loss: 9279.1212, validation loss: 0.0899
2024-05-22 17:28:40 [INFO]: Epoch 164 - training loss: 9276.8156, validation loss: 0.0894
2024-05-22 17:28:41 [INFO]: Epoch 165 - training loss: 9278.8988, validation loss: 0.0901
2024-05-22 17:28:41 [INFO]: Epoch 166 - training loss: 9276.4792, validation loss: 0.0884
2024-05-22 17:28:41 [INFO]: Epoch 167 - training loss: 9275.5252, validation loss: 0.0901
2024-05-22 17:28:41 [INFO]: Epoch 168 - training loss: 9276.8676, validation loss: 0.0879
2024-05-22 17:28:41 [INFO]: Epoch 169 - training loss: 9276.4207, validation loss: 0.0882
2024-05-22 17:28:41 [INFO]: Epoch 170 - training loss: 9276.1184, validation loss: 0.0878
2024-05-22 17:28:41 [INFO]: Epoch 171 - training loss: 9277.0469, validation loss: 0.0875
2024-05-22 17:28:41 [INFO]: Epoch 172 - training loss: 9277.3151, validation loss: 0.0866
2024-05-22 17:28:41 [INFO]: Epoch 173 - training loss: 9275.5007, validation loss: 0.0899
2024-05-22 17:28:42 [INFO]: Epoch 174 - training loss: 9276.3900, validation loss: 0.0878
2024-05-22 17:28:42 [INFO]: Epoch 175 - training loss: 9275.0848, validation loss: 0.0867
2024-05-22 17:28:42 [INFO]: Epoch 176 - training loss: 9274.9144, validation loss: 0.0888
2024-05-22 17:28:42 [INFO]: Epoch 177 - training loss: 9276.2265, validation loss: 0.0869
2024-05-22 17:28:42 [INFO]: Epoch 178 - training loss: 9276.7575, validation loss: 0.0863
2024-05-22 17:28:42 [INFO]: Epoch 179 - training loss: 9277.8696, validation loss: 0.0890
2024-05-22 17:28:42 [INFO]: Epoch 180 - training loss: 9276.0439, validation loss: 0.0868
2024-05-22 17:28:42 [INFO]: Epoch 181 - training loss: 9274.1496, validation loss: 0.0864
2024-05-22 17:28:42 [INFO]: Epoch 182 - training loss: 9275.0963, validation loss: 0.0847
2024-05-22 17:28:42 [INFO]: Epoch 183 - training loss: 9275.1993, validation loss: 0.0861
2024-05-22 17:28:43 [INFO]: Epoch 184 - training loss: 9275.3309, validation loss: 0.0844
2024-05-22 17:28:43 [INFO]: Epoch 185 - training loss: 9274.2797, validation loss: 0.0862
2024-05-22 17:28:43 [INFO]: Epoch 186 - training loss: 9274.9478, validation loss: 0.0838
2024-05-22 17:28:43 [INFO]: Epoch 187 - training loss: 9273.3281, validation loss: 0.0841
2024-05-22 17:28:43 [INFO]: Epoch 188 - training loss: 9277.0567, validation loss: 0.0847
2024-05-22 17:28:43 [INFO]: Epoch 189 - training loss: 9274.5641, validation loss: 0.0850
2024-05-22 17:28:43 [INFO]: Epoch 190 - training loss: 9274.2582, validation loss: 0.0841
2024-05-22 17:28:43 [INFO]: Epoch 191 - training loss: 9274.7570, validation loss: 0.0872
2024-05-22 17:28:43 [INFO]: Epoch 192 - training loss: 9274.1078, validation loss: 0.0828
2024-05-22 17:28:44 [INFO]: Epoch 193 - training loss: 9273.2057, validation loss: 0.0845
2024-05-22 17:28:44 [INFO]: Epoch 194 - training loss: 9273.9854, validation loss: 0.0840
2024-05-22 17:28:44 [INFO]: Epoch 195 - training loss: 9272.9876, validation loss: 0.0817
2024-05-22 17:28:44 [INFO]: Epoch 196 - training loss: 9274.7057, validation loss: 0.0827
2024-05-22 17:28:44 [INFO]: Epoch 197 - training loss: 9274.2603, validation loss: 0.0837
2024-05-22 17:28:44 [INFO]: Epoch 198 - training loss: 9277.2906, validation loss: 0.0817
2024-05-22 17:28:44 [INFO]: Epoch 199 - training loss: 9274.0408, validation loss: 0.0834
2024-05-22 17:28:44 [INFO]: Epoch 200 - training loss: 9274.1526, validation loss: 0.0833
2024-05-22 17:28:44 [INFO]: Epoch 201 - training loss: 9274.5861, validation loss: 0.0829
2024-05-22 17:28:45 [INFO]: Epoch 202 - training loss: 9272.3079, validation loss: 0.0851
2024-05-22 17:28:45 [INFO]: Epoch 203 - training loss: 9274.0306, validation loss: 0.0799
2024-05-22 17:28:45 [INFO]: Epoch 204 - training loss: 9273.4558, validation loss: 0.0811
2024-05-22 17:28:45 [INFO]: Epoch 205 - training loss: 9273.7532, validation loss: 0.0837
2024-05-22 17:28:45 [INFO]: Epoch 206 - training loss: 9273.6935, validation loss: 0.0824
2024-05-22 17:28:45 [INFO]: Epoch 207 - training loss: 9275.3300, validation loss: 0.0806
2024-05-22 17:28:45 [INFO]: Epoch 208 - training loss: 9274.1149, validation loss: 0.0834
2024-05-22 17:28:45 [INFO]: Epoch 209 - training loss: 9272.9576, validation loss: 0.0813
2024-05-22 17:28:45 [INFO]: Epoch 210 - training loss: 9272.0866, validation loss: 0.0810
2024-05-22 17:28:45 [INFO]: Epoch 211 - training loss: 9271.4500, validation loss: 0.0796
2024-05-22 17:28:46 [INFO]: Epoch 212 - training loss: 9271.7505, validation loss: 0.0815
2024-05-22 17:28:46 [INFO]: Epoch 213 - training loss: 9272.5300, validation loss: 0.0818
2024-05-22 17:28:46 [INFO]: Epoch 214 - training loss: 9272.0436, validation loss: 0.0797
2024-05-22 17:28:46 [INFO]: Epoch 215 - training loss: 9272.4803, validation loss: 0.0813
2024-05-22 17:28:46 [INFO]: Epoch 216 - training loss: 9272.9057, validation loss: 0.0812
2024-05-22 17:28:46 [INFO]: Epoch 217 - training loss: 9272.3699, validation loss: 0.0803
2024-05-22 17:28:46 [INFO]: Epoch 218 - training loss: 9271.6827, validation loss: 0.0804
2024-05-22 17:28:46 [INFO]: Epoch 219 - training loss: 9273.2872, validation loss: 0.0801
2024-05-22 17:28:46 [INFO]: Epoch 220 - training loss: 9272.4741, validation loss: 0.0801
2024-05-22 17:28:47 [INFO]: Epoch 221 - training loss: 9271.9305, validation loss: 0.0798
2024-05-22 17:28:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:28:47 [INFO]: Finished training. The best model is from epoch#211.
2024-05-22 17:28:47 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/GPVAE_ettm1/20240522_T172823/GPVAE.pypots
2024-05-22 17:28:47 [INFO]: GP-VAE on ETTm1: MAE=0.3090, MSE=0.1867
2024-05-22 17:28:47 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-22 17:28:47 [INFO]: Using the given device: cuda:0
2024-05-22 17:28:47 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/USGAN_ettm1/20240522_T172847
2024-05-22 17:28:47 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/USGAN_ettm1/20240522_T172847/tensorboard
2024-05-22 17:28:47 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 17:28:55 [INFO]: Epoch 001 - generator training loss: 0.4565, discriminator training loss: 0.4308, validation loss: 0.2763
2024-05-22 17:29:02 [INFO]: Epoch 002 - generator training loss: -0.0183, discriminator training loss: 0.3271, validation loss: 0.0998
2024-05-22 17:29:10 [INFO]: Epoch 003 - generator training loss: -0.1296, discriminator training loss: 0.3114, validation loss: 0.0660
2024-05-22 17:29:17 [INFO]: Epoch 004 - generator training loss: -0.1445, discriminator training loss: 0.3002, validation loss: 0.0484
2024-05-22 17:29:24 [INFO]: Epoch 005 - generator training loss: -0.1347, discriminator training loss: 0.2815, validation loss: 0.0423
2024-05-22 17:29:31 [INFO]: Epoch 006 - generator training loss: -0.1150, discriminator training loss: 0.2541, validation loss: 0.0390
2024-05-22 17:29:39 [INFO]: Epoch 007 - generator training loss: -0.0900, discriminator training loss: 0.2183, validation loss: 0.0372
2024-05-22 17:29:46 [INFO]: Epoch 008 - generator training loss: -0.0695, discriminator training loss: 0.1853, validation loss: 0.0350
2024-05-22 17:29:53 [INFO]: Epoch 009 - generator training loss: -0.0504, discriminator training loss: 0.1580, validation loss: 0.0333
2024-05-22 17:30:01 [INFO]: Epoch 010 - generator training loss: -0.0414, discriminator training loss: 0.1417, validation loss: 0.0332
2024-05-22 17:30:08 [INFO]: Epoch 011 - generator training loss: -0.0355, discriminator training loss: 0.1342, validation loss: 0.0317
2024-05-22 17:30:15 [INFO]: Epoch 012 - generator training loss: -0.0348, discriminator training loss: 0.1296, validation loss: 0.0327
2024-05-22 17:30:22 [INFO]: Epoch 013 - generator training loss: -0.0368, discriminator training loss: 0.1227, validation loss: 0.0310
2024-05-22 17:30:29 [INFO]: Epoch 014 - generator training loss: -0.0378, discriminator training loss: 0.1226, validation loss: 0.0298
2024-05-22 17:30:37 [INFO]: Epoch 015 - generator training loss: -0.0377, discriminator training loss: 0.1187, validation loss: 0.0291
2024-05-22 17:30:44 [INFO]: Epoch 016 - generator training loss: -0.0364, discriminator training loss: 0.1197, validation loss: 0.0291
2024-05-22 17:30:51 [INFO]: Epoch 017 - generator training loss: -0.0334, discriminator training loss: 0.1190, validation loss: 0.0299
2024-05-22 17:30:58 [INFO]: Epoch 018 - generator training loss: -0.0372, discriminator training loss: 0.1174, validation loss: 0.0290
2024-05-22 17:31:06 [INFO]: Epoch 019 - generator training loss: -0.0403, discriminator training loss: 0.1178, validation loss: 0.0279
2024-05-22 17:31:13 [INFO]: Epoch 020 - generator training loss: -0.0398, discriminator training loss: 0.1172, validation loss: 0.0282
2024-05-22 17:31:20 [INFO]: Epoch 021 - generator training loss: -0.0384, discriminator training loss: 0.1167, validation loss: 0.0274
2024-05-22 17:31:27 [INFO]: Epoch 022 - generator training loss: -0.0392, discriminator training loss: 0.1150, validation loss: 0.0272
2024-05-22 17:31:35 [INFO]: Epoch 023 - generator training loss: -0.0399, discriminator training loss: 0.1149, validation loss: 0.0271
2024-05-22 17:31:42 [INFO]: Epoch 024 - generator training loss: -0.0406, discriminator training loss: 0.1152, validation loss: 0.0274
2024-05-22 17:31:49 [INFO]: Epoch 025 - generator training loss: -0.0396, discriminator training loss: 0.1172, validation loss: 0.0262
2024-05-22 17:31:57 [INFO]: Epoch 026 - generator training loss: -0.0379, discriminator training loss: 0.1131, validation loss: 0.0265
2024-05-22 17:32:04 [INFO]: Epoch 027 - generator training loss: -0.0393, discriminator training loss: 0.1115, validation loss: 0.0264
2024-05-22 17:32:11 [INFO]: Epoch 028 - generator training loss: -0.0388, discriminator training loss: 0.1117, validation loss: 0.0259
2024-05-22 17:32:18 [INFO]: Epoch 029 - generator training loss: -0.0401, discriminator training loss: 0.1155, validation loss: 0.0264
2024-05-22 17:32:26 [INFO]: Epoch 030 - generator training loss: -0.0413, discriminator training loss: 0.1133, validation loss: 0.0259
2024-05-22 17:32:33 [INFO]: Epoch 031 - generator training loss: -0.0415, discriminator training loss: 0.1147, validation loss: 0.0260
2024-05-22 17:32:40 [INFO]: Epoch 032 - generator training loss: -0.0396, discriminator training loss: 0.1129, validation loss: 0.0264
2024-05-22 17:32:47 [INFO]: Epoch 033 - generator training loss: -0.0413, discriminator training loss: 0.1136, validation loss: 0.0261
2024-05-22 17:32:55 [INFO]: Epoch 034 - generator training loss: -0.0401, discriminator training loss: 0.1131, validation loss: 0.0253
2024-05-22 17:33:02 [INFO]: Epoch 035 - generator training loss: -0.0373, discriminator training loss: 0.1118, validation loss: 0.0255
2024-05-22 17:33:09 [INFO]: Epoch 036 - generator training loss: -0.0404, discriminator training loss: 0.1123, validation loss: 0.0249
2024-05-22 17:33:16 [INFO]: Epoch 037 - generator training loss: -0.0453, discriminator training loss: 0.1113, validation loss: 0.0260
2024-05-22 17:33:24 [INFO]: Epoch 038 - generator training loss: -0.0397, discriminator training loss: 0.1095, validation loss: 0.0248
2024-05-22 17:33:31 [INFO]: Epoch 039 - generator training loss: -0.0428, discriminator training loss: 0.1129, validation loss: 0.0250
2024-05-22 17:33:38 [INFO]: Epoch 040 - generator training loss: -0.0420, discriminator training loss: 0.1115, validation loss: 0.0246
2024-05-22 17:33:45 [INFO]: Epoch 041 - generator training loss: -0.0440, discriminator training loss: 0.1114, validation loss: 0.0248
2024-05-22 17:33:53 [INFO]: Epoch 042 - generator training loss: -0.0437, discriminator training loss: 0.1099, validation loss: 0.0245
2024-05-22 17:34:00 [INFO]: Epoch 043 - generator training loss: -0.0408, discriminator training loss: 0.1116, validation loss: 0.0247
2024-05-22 17:34:07 [INFO]: Epoch 044 - generator training loss: -0.0416, discriminator training loss: 0.1108, validation loss: 0.0248
2024-05-22 17:34:14 [INFO]: Epoch 045 - generator training loss: -0.0450, discriminator training loss: 0.1139, validation loss: 0.0238
2024-05-22 17:34:22 [INFO]: Epoch 046 - generator training loss: -0.0400, discriminator training loss: 0.1108, validation loss: 0.0249
2024-05-22 17:34:29 [INFO]: Epoch 047 - generator training loss: -0.0415, discriminator training loss: 0.1107, validation loss: 0.0238
2024-05-22 17:34:36 [INFO]: Epoch 048 - generator training loss: -0.0406, discriminator training loss: 0.1110, validation loss: 0.0236
2024-05-22 17:34:43 [INFO]: Epoch 049 - generator training loss: -0.0431, discriminator training loss: 0.1084, validation loss: 0.0242
2024-05-22 17:34:51 [INFO]: Epoch 050 - generator training loss: -0.0442, discriminator training loss: 0.1108, validation loss: 0.0234
2024-05-22 17:34:58 [INFO]: Epoch 051 - generator training loss: -0.0418, discriminator training loss: 0.1089, validation loss: 0.0236
2024-05-22 17:35:05 [INFO]: Epoch 052 - generator training loss: -0.0434, discriminator training loss: 0.1114, validation loss: 0.0246
2024-05-22 17:35:13 [INFO]: Epoch 053 - generator training loss: -0.0419, discriminator training loss: 0.1088, validation loss: 0.0253
2024-05-22 17:35:20 [INFO]: Epoch 054 - generator training loss: -0.0415, discriminator training loss: 0.1109, validation loss: 0.0241
2024-05-22 17:35:27 [INFO]: Epoch 055 - generator training loss: -0.0389, discriminator training loss: 0.1095, validation loss: 0.0246
2024-05-22 17:35:34 [INFO]: Epoch 056 - generator training loss: -0.0448, discriminator training loss: 0.1110, validation loss: 0.0231
2024-05-22 17:35:42 [INFO]: Epoch 057 - generator training loss: -0.0391, discriminator training loss: 0.1082, validation loss: 0.0258
2024-05-22 17:35:49 [INFO]: Epoch 058 - generator training loss: -0.0418, discriminator training loss: 0.1094, validation loss: 0.0238
2024-05-22 17:35:56 [INFO]: Epoch 059 - generator training loss: -0.0429, discriminator training loss: 0.1091, validation loss: 0.0234
2024-05-22 17:36:03 [INFO]: Epoch 060 - generator training loss: -0.0443, discriminator training loss: 0.1073, validation loss: 0.0233
2024-05-22 17:36:10 [INFO]: Epoch 061 - generator training loss: -0.0433, discriminator training loss: 0.1081, validation loss: 0.0225
2024-05-22 17:36:18 [INFO]: Epoch 062 - generator training loss: -0.0425, discriminator training loss: 0.1095, validation loss: 0.0232
2024-05-22 17:36:25 [INFO]: Epoch 063 - generator training loss: -0.0448, discriminator training loss: 0.1094, validation loss: 0.0224
2024-05-22 17:36:32 [INFO]: Epoch 064 - generator training loss: -0.0430, discriminator training loss: 0.1090, validation loss: 0.0230
2024-05-22 17:36:39 [INFO]: Epoch 065 - generator training loss: -0.0447, discriminator training loss: 0.1085, validation loss: 0.0233
2024-05-22 17:36:47 [INFO]: Epoch 066 - generator training loss: -0.0445, discriminator training loss: 0.1084, validation loss: 0.0230
2024-05-22 17:36:54 [INFO]: Epoch 067 - generator training loss: -0.0427, discriminator training loss: 0.1094, validation loss: 0.0219
2024-05-22 17:37:02 [INFO]: Epoch 068 - generator training loss: -0.0445, discriminator training loss: 0.1090, validation loss: 0.0227
2024-05-22 17:37:10 [INFO]: Epoch 069 - generator training loss: -0.0438, discriminator training loss: 0.1059, validation loss: 0.0220
2024-05-22 17:37:18 [INFO]: Epoch 070 - generator training loss: -0.0466, discriminator training loss: 0.1106, validation loss: 0.0221
2024-05-22 17:37:25 [INFO]: Epoch 071 - generator training loss: -0.0419, discriminator training loss: 0.1088, validation loss: 0.0224
2024-05-22 17:37:33 [INFO]: Epoch 072 - generator training loss: -0.0436, discriminator training loss: 0.1107, validation loss: 0.0231
2024-05-22 17:37:41 [INFO]: Epoch 073 - generator training loss: -0.0439, discriminator training loss: 0.1104, validation loss: 0.0221
2024-05-22 17:37:49 [INFO]: Epoch 074 - generator training loss: -0.0447, discriminator training loss: 0.1094, validation loss: 0.0219
2024-05-22 17:37:56 [INFO]: Epoch 075 - generator training loss: -0.0447, discriminator training loss: 0.1080, validation loss: 0.0219
2024-05-22 17:38:03 [INFO]: Epoch 076 - generator training loss: -0.0478, discriminator training loss: 0.1082, validation loss: 0.0219
2024-05-22 17:38:10 [INFO]: Epoch 077 - generator training loss: -0.0479, discriminator training loss: 0.1099, validation loss: 0.0218
2024-05-22 17:38:18 [INFO]: Epoch 078 - generator training loss: -0.0459, discriminator training loss: 0.1079, validation loss: 0.0220
2024-05-22 17:38:25 [INFO]: Epoch 079 - generator training loss: -0.0472, discriminator training loss: 0.1081, validation loss: 0.0227
2024-05-22 17:38:32 [INFO]: Epoch 080 - generator training loss: -0.0445, discriminator training loss: 0.1070, validation loss: 0.0217
2024-05-22 17:38:39 [INFO]: Epoch 081 - generator training loss: -0.0484, discriminator training loss: 0.1067, validation loss: 0.0210
2024-05-22 17:38:47 [INFO]: Epoch 082 - generator training loss: -0.0425, discriminator training loss: 0.1071, validation loss: 0.0215
2024-05-22 17:38:54 [INFO]: Epoch 083 - generator training loss: -0.0448, discriminator training loss: 0.1076, validation loss: 0.0257
2024-05-22 17:39:01 [INFO]: Epoch 084 - generator training loss: -0.0423, discriminator training loss: 0.1104, validation loss: 0.0228
2024-05-22 17:39:08 [INFO]: Epoch 085 - generator training loss: -0.0423, discriminator training loss: 0.1070, validation loss: 0.0218
2024-05-22 17:39:16 [INFO]: Epoch 086 - generator training loss: -0.0462, discriminator training loss: 0.1065, validation loss: 0.0215
2024-05-22 17:39:23 [INFO]: Epoch 087 - generator training loss: -0.0458, discriminator training loss: 0.1063, validation loss: 0.0212
2024-05-22 17:39:30 [INFO]: Epoch 088 - generator training loss: -0.0454, discriminator training loss: 0.1071, validation loss: 0.0208
2024-05-22 17:39:38 [INFO]: Epoch 089 - generator training loss: -0.0443, discriminator training loss: 0.1064, validation loss: 0.0210
2024-05-22 17:39:45 [INFO]: Epoch 090 - generator training loss: -0.0463, discriminator training loss: 0.1077, validation loss: 0.0201
2024-05-22 17:39:52 [INFO]: Epoch 091 - generator training loss: -0.0454, discriminator training loss: 0.1062, validation loss: 0.0215
2024-05-22 17:40:00 [INFO]: Epoch 092 - generator training loss: -0.0458, discriminator training loss: 0.1058, validation loss: 0.0205
2024-05-22 17:40:07 [INFO]: Epoch 093 - generator training loss: -0.0471, discriminator training loss: 0.1074, validation loss: 0.0205
2024-05-22 17:40:14 [INFO]: Epoch 094 - generator training loss: -0.0461, discriminator training loss: 0.1051, validation loss: 0.0202
2024-05-22 17:40:22 [INFO]: Epoch 095 - generator training loss: -0.0474, discriminator training loss: 0.1058, validation loss: 0.0200
2024-05-22 17:40:29 [INFO]: Epoch 096 - generator training loss: -0.0486, discriminator training loss: 0.1061, validation loss: 0.0202
2024-05-22 17:40:36 [INFO]: Epoch 097 - generator training loss: -0.0482, discriminator training loss: 0.1048, validation loss: 0.0203
2024-05-22 17:40:43 [INFO]: Epoch 098 - generator training loss: -0.0474, discriminator training loss: 0.1073, validation loss: 0.0195
2024-05-22 17:40:51 [INFO]: Epoch 099 - generator training loss: -0.0494, discriminator training loss: 0.1051, validation loss: 0.0195
2024-05-22 17:40:58 [INFO]: Epoch 100 - generator training loss: -0.0476, discriminator training loss: 0.1075, validation loss: 0.0196
2024-05-22 17:41:05 [INFO]: Epoch 101 - generator training loss: -0.0454, discriminator training loss: 0.1059, validation loss: 0.0201
2024-05-22 17:41:13 [INFO]: Epoch 102 - generator training loss: -0.0480, discriminator training loss: 0.1056, validation loss: 0.0194
2024-05-22 17:41:20 [INFO]: Epoch 103 - generator training loss: -0.0474, discriminator training loss: 0.1085, validation loss: 0.0192
2024-05-22 17:41:27 [INFO]: Epoch 104 - generator training loss: -0.0484, discriminator training loss: 0.1061, validation loss: 0.0197
2024-05-22 17:41:34 [INFO]: Epoch 105 - generator training loss: -0.0468, discriminator training loss: 0.1055, validation loss: 0.0193
2024-05-22 17:41:42 [INFO]: Epoch 106 - generator training loss: -0.0463, discriminator training loss: 0.1054, validation loss: 0.0191
2024-05-22 17:41:49 [INFO]: Epoch 107 - generator training loss: -0.0483, discriminator training loss: 0.1058, validation loss: 0.0193
2024-05-22 17:41:56 [INFO]: Epoch 108 - generator training loss: -0.0473, discriminator training loss: 0.1047, validation loss: 0.0194
2024-05-22 17:42:04 [INFO]: Epoch 109 - generator training loss: -0.0514, discriminator training loss: 0.1054, validation loss: 0.0192
2024-05-22 17:42:11 [INFO]: Epoch 110 - generator training loss: -0.0468, discriminator training loss: 0.1063, validation loss: 0.0190
2024-05-22 17:42:18 [INFO]: Epoch 111 - generator training loss: -0.0453, discriminator training loss: 0.1035, validation loss: 0.0188
2024-05-22 17:42:25 [INFO]: Epoch 112 - generator training loss: -0.0504, discriminator training loss: 0.1065, validation loss: 0.0187
2024-05-22 17:42:33 [INFO]: Epoch 113 - generator training loss: -0.0469, discriminator training loss: 0.1082, validation loss: 0.0190
2024-05-22 17:42:40 [INFO]: Epoch 114 - generator training loss: -0.0500, discriminator training loss: 0.1057, validation loss: 0.0187
2024-05-22 17:42:48 [INFO]: Epoch 115 - generator training loss: -0.0515, discriminator training loss: 0.1058, validation loss: 0.0186
2024-05-22 17:42:55 [INFO]: Epoch 116 - generator training loss: -0.0456, discriminator training loss: 0.1042, validation loss: 0.0189
2024-05-22 17:43:02 [INFO]: Epoch 117 - generator training loss: -0.0485, discriminator training loss: 0.1013, validation loss: 0.0195
2024-05-22 17:43:09 [INFO]: Epoch 118 - generator training loss: -0.0486, discriminator training loss: 0.1062, validation loss: 0.0189
2024-05-22 17:43:17 [INFO]: Epoch 119 - generator training loss: -0.0489, discriminator training loss: 0.1051, validation loss: 0.0187
2024-05-22 17:43:24 [INFO]: Epoch 120 - generator training loss: -0.0468, discriminator training loss: 0.1031, validation loss: 0.0189
2024-05-22 17:43:31 [INFO]: Epoch 121 - generator training loss: -0.0491, discriminator training loss: 0.1046, validation loss: 0.0191
2024-05-22 17:43:38 [INFO]: Epoch 122 - generator training loss: -0.0476, discriminator training loss: 0.1050, validation loss: 0.0187
2024-05-22 17:43:46 [INFO]: Epoch 123 - generator training loss: -0.0444, discriminator training loss: 0.1046, validation loss: 0.0194
2024-05-22 17:43:53 [INFO]: Epoch 124 - generator training loss: -0.0443, discriminator training loss: 0.1039, validation loss: 0.0205
2024-05-22 17:44:00 [INFO]: Epoch 125 - generator training loss: -0.0465, discriminator training loss: 0.1045, validation loss: 0.0190
2024-05-22 17:44:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:44:00 [INFO]: Finished training. The best model is from epoch#115.
2024-05-22 17:44:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/USGAN_ettm1/20240522_T172847/USGAN.pypots
2024-05-22 17:44:01 [INFO]: US-GAN on ETTm1: MAE=0.1371, MSE=0.0479
2024-05-22 17:44:01 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-22 17:44:01 [INFO]: Using the given device: cuda:0
2024-05-22 17:44:01 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/BRITS_ettm1/20240522_T174401
2024-05-22 17:44:01 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/BRITS_ettm1/20240522_T174401/tensorboard
2024-05-22 17:44:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 17:44:07 [INFO]: Epoch 001 - training loss: 1.2945, validation loss: 0.3163
2024-05-22 17:44:12 [INFO]: Epoch 002 - training loss: 0.8634, validation loss: 0.0932
2024-05-22 17:44:17 [INFO]: Epoch 003 - training loss: 0.7115, validation loss: 0.0539
2024-05-22 17:44:21 [INFO]: Epoch 004 - training loss: 0.6336, validation loss: 0.0457
2024-05-22 17:44:26 [INFO]: Epoch 005 - training loss: 0.5856, validation loss: 0.0383
2024-05-22 17:44:31 [INFO]: Epoch 006 - training loss: 0.5608, validation loss: 0.0362
2024-05-22 17:44:36 [INFO]: Epoch 007 - training loss: 0.5277, validation loss: 0.0322
2024-05-22 17:44:41 [INFO]: Epoch 008 - training loss: 0.5184, validation loss: 0.0319
2024-05-22 17:44:46 [INFO]: Epoch 009 - training loss: 0.4805, validation loss: 0.0290
2024-05-22 17:44:51 [INFO]: Epoch 010 - training loss: 0.4607, validation loss: 0.0279
2024-05-22 17:44:55 [INFO]: Epoch 011 - training loss: 0.4562, validation loss: 0.0270
2024-05-22 17:45:00 [INFO]: Epoch 012 - training loss: 0.4377, validation loss: 0.0262
2024-05-22 17:45:05 [INFO]: Epoch 013 - training loss: 0.4261, validation loss: 0.0258
2024-05-22 17:45:10 [INFO]: Epoch 014 - training loss: 0.4152, validation loss: 0.0251
2024-05-22 17:45:15 [INFO]: Epoch 015 - training loss: 0.4105, validation loss: 0.0252
2024-05-22 17:45:20 [INFO]: Epoch 016 - training loss: 0.4074, validation loss: 0.0236
2024-05-22 17:45:24 [INFO]: Epoch 017 - training loss: 0.4118, validation loss: 0.0234
2024-05-22 17:45:29 [INFO]: Epoch 018 - training loss: 0.3883, validation loss: 0.0231
2024-05-22 17:45:34 [INFO]: Epoch 019 - training loss: 0.4383, validation loss: 0.0236
2024-05-22 17:45:39 [INFO]: Epoch 020 - training loss: 0.4055, validation loss: 0.0235
2024-05-22 17:45:44 [INFO]: Epoch 021 - training loss: 0.3994, validation loss: 0.0230
2024-05-22 17:45:48 [INFO]: Epoch 022 - training loss: 0.3953, validation loss: 0.0227
2024-05-22 17:45:53 [INFO]: Epoch 023 - training loss: 0.3958, validation loss: 0.0232
2024-05-22 17:45:58 [INFO]: Epoch 024 - training loss: 0.3881, validation loss: 0.0227
2024-05-22 17:46:03 [INFO]: Epoch 025 - training loss: 0.3908, validation loss: 0.0222
2024-05-22 17:46:08 [INFO]: Epoch 026 - training loss: 0.3910, validation loss: 0.0220
2024-05-22 17:46:12 [INFO]: Epoch 027 - training loss: 0.3843, validation loss: 0.0231
2024-05-22 17:46:17 [INFO]: Epoch 028 - training loss: 0.3792, validation loss: 0.0227
2024-05-22 17:46:22 [INFO]: Epoch 029 - training loss: 0.3987, validation loss: 0.0230
2024-05-22 17:46:27 [INFO]: Epoch 030 - training loss: 0.3833, validation loss: 0.0230
2024-05-22 17:46:32 [INFO]: Epoch 031 - training loss: 0.3843, validation loss: 0.0223
2024-05-22 17:46:37 [INFO]: Epoch 032 - training loss: 0.3798, validation loss: 0.0220
2024-05-22 17:46:41 [INFO]: Epoch 033 - training loss: 0.3748, validation loss: 0.0224
2024-05-22 17:46:46 [INFO]: Epoch 034 - training loss: 0.3960, validation loss: 0.0229
2024-05-22 17:46:51 [INFO]: Epoch 035 - training loss: 0.3843, validation loss: 0.0226
2024-05-22 17:46:56 [INFO]: Epoch 036 - training loss: 0.3819, validation loss: 0.0220
2024-05-22 17:46:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:46:56 [INFO]: Finished training. The best model is from epoch#26.
2024-05-22 17:46:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/BRITS_ettm1/20240522_T174401/BRITS.pypots
2024-05-22 17:46:57 [INFO]: BRITS on ETTm1: MAE=0.1273, MSE=0.0466
2024-05-22 17:46:57 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-22 17:46:57 [INFO]: Using the given device: cuda:0
2024-05-22 17:46:57 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657
2024-05-22 17:46:57 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/tensorboard
2024-05-22 17:46:57 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 17:46:58 [INFO]: Epoch 001 - training loss: 1.4640, validation loss: 1.4178
2024-05-22 17:46:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch1_loss1.4177518486976624.pypots
2024-05-22 17:46:58 [INFO]: Epoch 002 - training loss: 1.1062, validation loss: 1.2457
2024-05-22 17:46:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch2_loss1.245704010128975.pypots
2024-05-22 17:46:58 [INFO]: Epoch 003 - training loss: 0.9851, validation loss: 1.1208
2024-05-22 17:46:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch3_loss1.1208492070436478.pypots
2024-05-22 17:46:58 [INFO]: Epoch 004 - training loss: 0.9507, validation loss: 1.0717
2024-05-22 17:46:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch4_loss1.0717250108718872.pypots
2024-05-22 17:46:59 [INFO]: Epoch 005 - training loss: 0.9187, validation loss: 1.0392
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch5_loss1.03916397690773.pypots
2024-05-22 17:46:59 [INFO]: Epoch 006 - training loss: 0.9307, validation loss: 1.0223
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch6_loss1.0222857743501663.pypots
2024-05-22 17:46:59 [INFO]: Epoch 007 - training loss: 0.9207, validation loss: 1.0176
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch7_loss1.0176036208868027.pypots
2024-05-22 17:46:59 [INFO]: Epoch 008 - training loss: 0.9137, validation loss: 1.0113
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch8_loss1.0112696588039398.pypots
2024-05-22 17:46:59 [INFO]: Epoch 009 - training loss: 0.8923, validation loss: 1.0087
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch9_loss1.0087176412343979.pypots
2024-05-22 17:46:59 [INFO]: Epoch 010 - training loss: 0.9143, validation loss: 1.0090
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch10_loss1.0089711397886276.pypots
2024-05-22 17:46:59 [INFO]: Epoch 011 - training loss: 0.8843, validation loss: 1.0084
2024-05-22 17:46:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch11_loss1.0084314495325089.pypots
2024-05-22 17:47:00 [INFO]: Epoch 012 - training loss: 0.8680, validation loss: 1.0030
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch12_loss1.0029602199792862.pypots
2024-05-22 17:47:00 [INFO]: Epoch 013 - training loss: 0.8647, validation loss: 1.0010
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch13_loss1.0009622424840927.pypots
2024-05-22 17:47:00 [INFO]: Epoch 014 - training loss: 0.9233, validation loss: 1.0013
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch14_loss1.001344233751297.pypots
2024-05-22 17:47:00 [INFO]: Epoch 015 - training loss: 0.9153, validation loss: 1.0003
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch15_loss1.0002713352441788.pypots
2024-05-22 17:47:00 [INFO]: Epoch 016 - training loss: 0.8716, validation loss: 0.9944
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch16_loss0.9944208264350891.pypots
2024-05-22 17:47:00 [INFO]: Epoch 017 - training loss: 0.8605, validation loss: 0.9918
2024-05-22 17:47:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch17_loss0.9917948693037033.pypots
2024-05-22 17:47:01 [INFO]: Epoch 018 - training loss: 0.8697, validation loss: 0.9883
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch18_loss0.988304927945137.pypots
2024-05-22 17:47:01 [INFO]: Epoch 019 - training loss: 0.8415, validation loss: 0.9804
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch19_loss0.9803697466850281.pypots
2024-05-22 17:47:01 [INFO]: Epoch 020 - training loss: 0.8365, validation loss: 0.9729
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch20_loss0.9728845804929733.pypots
2024-05-22 17:47:01 [INFO]: Epoch 021 - training loss: 0.8327, validation loss: 0.9645
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch21_loss0.9644601345062256.pypots
2024-05-22 17:47:01 [INFO]: Epoch 022 - training loss: 0.8228, validation loss: 0.9570
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch22_loss0.9569876790046692.pypots
2024-05-22 17:47:01 [INFO]: Epoch 023 - training loss: 0.8607, validation loss: 0.9501
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch23_loss0.9500540643930435.pypots
2024-05-22 17:47:01 [INFO]: Epoch 024 - training loss: 0.8557, validation loss: 0.9403
2024-05-22 17:47:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch24_loss0.9402767866849899.pypots
2024-05-22 17:47:02 [INFO]: Epoch 025 - training loss: 0.8131, validation loss: 0.9359
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch25_loss0.9359276294708252.pypots
2024-05-22 17:47:02 [INFO]: Epoch 026 - training loss: 0.8231, validation loss: 0.9276
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch26_loss0.9276423007249832.pypots
2024-05-22 17:47:02 [INFO]: Epoch 027 - training loss: 0.8282, validation loss: 0.9235
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch27_loss0.9235126376152039.pypots
2024-05-22 17:47:02 [INFO]: Epoch 028 - training loss: 0.8282, validation loss: 0.9193
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch28_loss0.9192725419998169.pypots
2024-05-22 17:47:02 [INFO]: Epoch 029 - training loss: 0.8187, validation loss: 0.9150
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch29_loss0.9150251597166061.pypots
2024-05-22 17:47:02 [INFO]: Epoch 030 - training loss: 0.8167, validation loss: 0.9108
2024-05-22 17:47:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch30_loss0.9107515066862106.pypots
2024-05-22 17:47:03 [INFO]: Epoch 031 - training loss: 0.8176, validation loss: 0.9039
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch31_loss0.9039288908243179.pypots
2024-05-22 17:47:03 [INFO]: Epoch 032 - training loss: 0.8124, validation loss: 0.9024
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch32_loss0.9023503065109253.pypots
2024-05-22 17:47:03 [INFO]: Epoch 033 - training loss: 0.8019, validation loss: 0.8972
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch33_loss0.8971992880105972.pypots
2024-05-22 17:47:03 [INFO]: Epoch 034 - training loss: 0.8105, validation loss: 0.8942
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch34_loss0.8941602557897568.pypots
2024-05-22 17:47:03 [INFO]: Epoch 035 - training loss: 0.8118, validation loss: 0.8910
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch35_loss0.890958696603775.pypots
2024-05-22 17:47:03 [INFO]: Epoch 036 - training loss: 0.7960, validation loss: 0.8882
2024-05-22 17:47:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch36_loss0.8882497698068619.pypots
2024-05-22 17:47:04 [INFO]: Epoch 037 - training loss: 0.8003, validation loss: 0.8856
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch37_loss0.8856312781572342.pypots
2024-05-22 17:47:04 [INFO]: Epoch 038 - training loss: 0.7902, validation loss: 0.8829
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch38_loss0.8829224109649658.pypots
2024-05-22 17:47:04 [INFO]: Epoch 039 - training loss: 0.7983, validation loss: 0.8797
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch39_loss0.8796932101249695.pypots
2024-05-22 17:47:04 [INFO]: Epoch 040 - training loss: 0.8141, validation loss: 0.8772
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch40_loss0.8771943897008896.pypots
2024-05-22 17:47:04 [INFO]: Epoch 041 - training loss: 0.7908, validation loss: 0.8737
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch41_loss0.8736515492200851.pypots
2024-05-22 17:47:04 [INFO]: Epoch 042 - training loss: 0.8032, validation loss: 0.8723
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch42_loss0.8722756206989288.pypots
2024-05-22 17:47:04 [INFO]: Epoch 043 - training loss: 0.7922, validation loss: 0.8710
2024-05-22 17:47:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch43_loss0.8710172772407532.pypots
2024-05-22 17:47:05 [INFO]: Epoch 044 - training loss: 0.7859, validation loss: 0.8687
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch44_loss0.8687127381563187.pypots
2024-05-22 17:47:05 [INFO]: Epoch 045 - training loss: 0.8049, validation loss: 0.8649
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch45_loss0.8649290055036545.pypots
2024-05-22 17:47:05 [INFO]: Epoch 046 - training loss: 0.7830, validation loss: 0.8634
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch46_loss0.8633836209774017.pypots
2024-05-22 17:47:05 [INFO]: Epoch 047 - training loss: 0.7929, validation loss: 0.8606
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch47_loss0.8606335520744324.pypots
2024-05-22 17:47:05 [INFO]: Epoch 048 - training loss: 0.7963, validation loss: 0.8582
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch48_loss0.858244463801384.pypots
2024-05-22 17:47:05 [INFO]: Epoch 049 - training loss: 0.8094, validation loss: 0.8552
2024-05-22 17:47:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch49_loss0.8551910519599915.pypots
2024-05-22 17:47:06 [INFO]: Epoch 050 - training loss: 0.7994, validation loss: 0.8568
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch50_loss0.856755256652832.pypots
2024-05-22 17:47:06 [INFO]: Epoch 051 - training loss: 0.8082, validation loss: 0.8525
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch51_loss0.8524720966815948.pypots
2024-05-22 17:47:06 [INFO]: Epoch 052 - training loss: 0.7718, validation loss: 0.8550
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch52_loss0.85496786236763.pypots
2024-05-22 17:47:06 [INFO]: Epoch 053 - training loss: 0.7875, validation loss: 0.8515
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch53_loss0.851458266377449.pypots
2024-05-22 17:47:06 [INFO]: Epoch 054 - training loss: 0.7794, validation loss: 0.8517
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch54_loss0.8517080098390579.pypots
2024-05-22 17:47:06 [INFO]: Epoch 055 - training loss: 0.7865, validation loss: 0.8478
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch55_loss0.8477679789066315.pypots
2024-05-22 17:47:06 [INFO]: Epoch 056 - training loss: 0.7784, validation loss: 0.8502
2024-05-22 17:47:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch56_loss0.8501976430416107.pypots
2024-05-22 17:47:07 [INFO]: Epoch 057 - training loss: 0.8068, validation loss: 0.8502
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch57_loss0.8502237796783447.pypots
2024-05-22 17:47:07 [INFO]: Epoch 058 - training loss: 0.7935, validation loss: 0.8462
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch58_loss0.8461522608995438.pypots
2024-05-22 17:47:07 [INFO]: Epoch 059 - training loss: 0.8079, validation loss: 0.8453
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch59_loss0.8452831208705902.pypots
2024-05-22 17:47:07 [INFO]: Epoch 060 - training loss: 0.7790, validation loss: 0.8438
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch60_loss0.8437819182872772.pypots
2024-05-22 17:47:07 [INFO]: Epoch 061 - training loss: 0.7904, validation loss: 0.8441
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch61_loss0.84414042532444.pypots
2024-05-22 17:47:07 [INFO]: Epoch 062 - training loss: 0.7622, validation loss: 0.8457
2024-05-22 17:47:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch62_loss0.8456733822822571.pypots
2024-05-22 17:47:08 [INFO]: Epoch 063 - training loss: 0.7797, validation loss: 0.8439
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch63_loss0.8438867330551147.pypots
2024-05-22 17:47:08 [INFO]: Epoch 064 - training loss: 0.7560, validation loss: 0.8427
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch64_loss0.842700868844986.pypots
2024-05-22 17:47:08 [INFO]: Epoch 065 - training loss: 0.7765, validation loss: 0.8449
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch65_loss0.8448550701141357.pypots
2024-05-22 17:47:08 [INFO]: Epoch 066 - training loss: 0.7841, validation loss: 0.8423
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch66_loss0.8422968536615372.pypots
2024-05-22 17:47:08 [INFO]: Epoch 067 - training loss: 0.7816, validation loss: 0.8428
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch67_loss0.8428201079368591.pypots
2024-05-22 17:47:08 [INFO]: Epoch 068 - training loss: 0.8091, validation loss: 0.8414
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch68_loss0.8413570523262024.pypots
2024-05-22 17:47:08 [INFO]: Epoch 069 - training loss: 0.8043, validation loss: 0.8419
2024-05-22 17:47:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch69_loss0.841855525970459.pypots
2024-05-22 17:47:09 [INFO]: Epoch 070 - training loss: 0.8025, validation loss: 0.8411
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch70_loss0.8411197066307068.pypots
2024-05-22 17:47:09 [INFO]: Epoch 071 - training loss: 0.7853, validation loss: 0.8401
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch71_loss0.8400963395833969.pypots
2024-05-22 17:47:09 [INFO]: Epoch 072 - training loss: 0.7856, validation loss: 0.8397
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch72_loss0.8396579474210739.pypots
2024-05-22 17:47:09 [INFO]: Epoch 073 - training loss: 0.7948, validation loss: 0.8391
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch73_loss0.8391109704971313.pypots
2024-05-22 17:47:09 [INFO]: Epoch 074 - training loss: 0.7525, validation loss: 0.8370
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch74_loss0.8370351940393448.pypots
2024-05-22 17:47:09 [INFO]: Epoch 075 - training loss: 0.7660, validation loss: 0.8381
2024-05-22 17:47:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch75_loss0.838128924369812.pypots
2024-05-22 17:47:10 [INFO]: Epoch 076 - training loss: 0.7580, validation loss: 0.8382
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch76_loss0.8382295966148376.pypots
2024-05-22 17:47:10 [INFO]: Epoch 077 - training loss: 0.7618, validation loss: 0.8369
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch77_loss0.8369258046150208.pypots
2024-05-22 17:47:10 [INFO]: Epoch 078 - training loss: 0.7771, validation loss: 0.8365
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch78_loss0.8365125060081482.pypots
2024-05-22 17:47:10 [INFO]: Epoch 079 - training loss: 0.7948, validation loss: 0.8367
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch79_loss0.8367320150136948.pypots
2024-05-22 17:47:10 [INFO]: Epoch 080 - training loss: 0.7850, validation loss: 0.8368
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch80_loss0.8368237912654877.pypots
2024-05-22 17:47:10 [INFO]: Epoch 081 - training loss: 0.7525, validation loss: 0.8344
2024-05-22 17:47:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch81_loss0.834446132183075.pypots
2024-05-22 17:47:11 [INFO]: Epoch 082 - training loss: 0.7544, validation loss: 0.8379
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch82_loss0.8379367887973785.pypots
2024-05-22 17:47:11 [INFO]: Epoch 083 - training loss: 0.7719, validation loss: 0.8374
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch83_loss0.8373672068119049.pypots
2024-05-22 17:47:11 [INFO]: Epoch 084 - training loss: 0.7711, validation loss: 0.8346
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch84_loss0.8346339911222458.pypots
2024-05-22 17:47:11 [INFO]: Epoch 085 - training loss: 0.7634, validation loss: 0.8349
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch85_loss0.8348506093025208.pypots
2024-05-22 17:47:11 [INFO]: Epoch 086 - training loss: 0.7661, validation loss: 0.8346
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch86_loss0.8345701396465302.pypots
2024-05-22 17:47:11 [INFO]: Epoch 087 - training loss: 0.7649, validation loss: 0.8377
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch87_loss0.8376608043909073.pypots
2024-05-22 17:47:11 [INFO]: Epoch 088 - training loss: 0.7742, validation loss: 0.8358
2024-05-22 17:47:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch88_loss0.8358240127563477.pypots
2024-05-22 17:47:12 [INFO]: Epoch 089 - training loss: 0.7863, validation loss: 0.8347
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch89_loss0.8346879184246063.pypots
2024-05-22 17:47:12 [INFO]: Epoch 090 - training loss: 0.7745, validation loss: 0.8353
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch90_loss0.8353208601474762.pypots
2024-05-22 17:47:12 [INFO]: Epoch 091 - training loss: 0.7738, validation loss: 0.8328
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch91_loss0.8328384906053543.pypots
2024-05-22 17:47:12 [INFO]: Epoch 092 - training loss: 0.7782, validation loss: 0.8334
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch92_loss0.8333757817745209.pypots
2024-05-22 17:47:12 [INFO]: Epoch 093 - training loss: 0.7621, validation loss: 0.8326
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch93_loss0.8325926065444946.pypots
2024-05-22 17:47:12 [INFO]: Epoch 094 - training loss: 0.7684, validation loss: 0.8338
2024-05-22 17:47:12 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch94_loss0.8337697386741638.pypots
2024-05-22 17:47:13 [INFO]: Epoch 095 - training loss: 0.7617, validation loss: 0.8333
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch95_loss0.8332806825637817.pypots
2024-05-22 17:47:13 [INFO]: Epoch 096 - training loss: 0.7565, validation loss: 0.8361
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch96_loss0.8360674381256104.pypots
2024-05-22 17:47:13 [INFO]: Epoch 097 - training loss: 0.7732, validation loss: 0.8353
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch97_loss0.8353486657142639.pypots
2024-05-22 17:47:13 [INFO]: Epoch 098 - training loss: 0.7733, validation loss: 0.8330
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch98_loss0.8329558968544006.pypots
2024-05-22 17:47:13 [INFO]: Epoch 099 - training loss: 0.7595, validation loss: 0.8312
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch99_loss0.8312415778636932.pypots
2024-05-22 17:47:13 [INFO]: Epoch 100 - training loss: 0.7761, validation loss: 0.8349
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch100_loss0.8349345773458481.pypots
2024-05-22 17:47:13 [INFO]: Epoch 101 - training loss: 0.7686, validation loss: 0.8326
2024-05-22 17:47:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch101_loss0.8326096087694168.pypots
2024-05-22 17:47:14 [INFO]: Epoch 102 - training loss: 0.7715, validation loss: 0.8344
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch102_loss0.834366649389267.pypots
2024-05-22 17:47:14 [INFO]: Epoch 103 - training loss: 0.7676, validation loss: 0.8366
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch103_loss0.8365796655416489.pypots
2024-05-22 17:47:14 [INFO]: Epoch 104 - training loss: 0.7628, validation loss: 0.8348
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch104_loss0.8348056375980377.pypots
2024-05-22 17:47:14 [INFO]: Epoch 105 - training loss: 0.7773, validation loss: 0.8361
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch105_loss0.8360504508018494.pypots
2024-05-22 17:47:14 [INFO]: Epoch 106 - training loss: 0.7833, validation loss: 0.8340
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch106_loss0.8340433537960052.pypots
2024-05-22 17:47:14 [INFO]: Epoch 107 - training loss: 0.7601, validation loss: 0.8357
2024-05-22 17:47:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch107_loss0.8356760740280151.pypots
2024-05-22 17:47:15 [INFO]: Epoch 108 - training loss: 0.7421, validation loss: 0.8303
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch108_loss0.8303042948246002.pypots
2024-05-22 17:47:15 [INFO]: Epoch 109 - training loss: 0.7668, validation loss: 0.8359
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch109_loss0.8359092772006989.pypots
2024-05-22 17:47:15 [INFO]: Epoch 110 - training loss: 0.7728, validation loss: 0.8308
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch110_loss0.8307911306619644.pypots
2024-05-22 17:47:15 [INFO]: Epoch 111 - training loss: 0.7864, validation loss: 0.8325
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch111_loss0.8325241506099701.pypots
2024-05-22 17:47:15 [INFO]: Epoch 112 - training loss: 0.8231, validation loss: 0.8255
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch112_loss0.8255169689655304.pypots
2024-05-22 17:47:15 [INFO]: Epoch 113 - training loss: 0.7690, validation loss: 0.8341
2024-05-22 17:47:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch113_loss0.8341400176286697.pypots
2024-05-22 17:47:16 [INFO]: Epoch 114 - training loss: 0.7724, validation loss: 0.8378
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch114_loss0.8377893716096878.pypots
2024-05-22 17:47:16 [INFO]: Epoch 115 - training loss: 0.7504, validation loss: 0.8325
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch115_loss0.8324731439352036.pypots
2024-05-22 17:47:16 [INFO]: Epoch 116 - training loss: 0.7533, validation loss: 0.8323
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch116_loss0.8322826474905014.pypots
2024-05-22 17:47:16 [INFO]: Epoch 117 - training loss: 0.7785, validation loss: 0.8317
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch117_loss0.831684410572052.pypots
2024-05-22 17:47:16 [INFO]: Epoch 118 - training loss: 0.7528, validation loss: 0.8295
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch118_loss0.8295057117938995.pypots
2024-05-22 17:47:16 [INFO]: Epoch 119 - training loss: 0.7455, validation loss: 0.8317
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch119_loss0.8317427188158035.pypots
2024-05-22 17:47:16 [INFO]: Epoch 120 - training loss: 0.7573, validation loss: 0.8311
2024-05-22 17:47:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch120_loss0.8311408013105392.pypots
2024-05-22 17:47:17 [INFO]: Epoch 121 - training loss: 0.8115, validation loss: 0.8351
2024-05-22 17:47:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch121_loss0.8351456671953201.pypots
2024-05-22 17:47:17 [INFO]: Epoch 122 - training loss: 0.7621, validation loss: 0.8340
2024-05-22 17:47:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN_epoch122_loss0.8339644819498062.pypots
2024-05-22 17:47:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:47:17 [INFO]: Finished training. The best model is from epoch#112.
2024-05-22 17:47:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/20240522_T174657/MRNN.pypots
2024-05-22 17:47:17 [INFO]: MRNN on ETTm1: MAE=0.6594, MSE=1.1137
2024-05-22 17:47:17 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-22 17:47:17 [INFO]: Using the given device: cpu
2024-05-22 17:47:17 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 17:47:17 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-22 17:47:17 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-22 17:47:17 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 17:47:17 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-22 17:47:17 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-22 17:47:17 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 17:47:17 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-22 17:47:17 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-22 17:47:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 17:47:17 [INFO]: Using the given device: cuda:0
2024-05-22 17:47:17 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/SAITS_ettm1/20240522_T174717
2024-05-22 17:47:17 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/SAITS_ettm1/20240522_T174717/tensorboard
2024-05-22 17:47:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 17:47:18 [INFO]: Epoch 001 - training loss: 1.1775, validation loss: 0.2404
2024-05-22 17:47:18 [INFO]: Epoch 002 - training loss: 0.9197, validation loss: 0.1279
2024-05-22 17:47:19 [INFO]: Epoch 003 - training loss: 0.8125, validation loss: 0.0953
2024-05-22 17:47:19 [INFO]: Epoch 004 - training loss: 0.7657, validation loss: 0.0881
2024-05-22 17:47:20 [INFO]: Epoch 005 - training loss: 0.7235, validation loss: 0.0813
2024-05-22 17:47:20 [INFO]: Epoch 006 - training loss: 0.7032, validation loss: 0.0670
2024-05-22 17:47:21 [INFO]: Epoch 007 - training loss: 0.6757, validation loss: 0.0683
2024-05-22 17:47:21 [INFO]: Epoch 008 - training loss: 0.6676, validation loss: 0.0832
2024-05-22 17:47:22 [INFO]: Epoch 009 - training loss: 0.6491, validation loss: 0.0779
2024-05-22 17:47:22 [INFO]: Epoch 010 - training loss: 0.6379, validation loss: 0.0621
2024-05-22 17:47:23 [INFO]: Epoch 011 - training loss: 0.6310, validation loss: 0.0684
2024-05-22 17:47:23 [INFO]: Epoch 012 - training loss: 0.6320, validation loss: 0.0693
2024-05-22 17:47:24 [INFO]: Epoch 013 - training loss: 0.6110, validation loss: 0.0530
2024-05-22 17:47:24 [INFO]: Epoch 014 - training loss: 0.6007, validation loss: 0.0635
2024-05-22 17:47:25 [INFO]: Epoch 015 - training loss: 0.6159, validation loss: 0.0684
2024-05-22 17:47:25 [INFO]: Epoch 016 - training loss: 0.5988, validation loss: 0.0689
2024-05-22 17:47:26 [INFO]: Epoch 017 - training loss: 0.5830, validation loss: 0.0620
2024-05-22 17:47:26 [INFO]: Epoch 018 - training loss: 0.5832, validation loss: 0.0501
2024-05-22 17:47:27 [INFO]: Epoch 019 - training loss: 0.5982, validation loss: 0.0755
2024-05-22 17:47:27 [INFO]: Epoch 020 - training loss: 0.5879, validation loss: 0.0537
2024-05-22 17:47:28 [INFO]: Epoch 021 - training loss: 0.5672, validation loss: 0.0615
2024-05-22 17:47:28 [INFO]: Epoch 022 - training loss: 0.5538, validation loss: 0.0576
2024-05-22 17:47:29 [INFO]: Epoch 023 - training loss: 0.5800, validation loss: 0.0433
2024-05-22 17:47:29 [INFO]: Epoch 024 - training loss: 0.5502, validation loss: 0.0507
2024-05-22 17:47:29 [INFO]: Epoch 025 - training loss: 0.5590, validation loss: 0.0538
2024-05-22 17:47:30 [INFO]: Epoch 026 - training loss: 0.5635, validation loss: 0.0604
2024-05-22 17:47:30 [INFO]: Epoch 027 - training loss: 0.5392, validation loss: 0.0511
2024-05-22 17:47:31 [INFO]: Epoch 028 - training loss: 0.5479, validation loss: 0.0403
2024-05-22 17:47:31 [INFO]: Epoch 029 - training loss: 0.5297, validation loss: 0.0552
2024-05-22 17:47:32 [INFO]: Epoch 030 - training loss: 0.5477, validation loss: 0.0412
2024-05-22 17:47:32 [INFO]: Epoch 031 - training loss: 0.5307, validation loss: 0.0445
2024-05-22 17:47:33 [INFO]: Epoch 032 - training loss: 0.5124, validation loss: 0.0518
2024-05-22 17:47:33 [INFO]: Epoch 033 - training loss: 0.5167, validation loss: 0.0356
2024-05-22 17:47:34 [INFO]: Epoch 034 - training loss: 0.5054, validation loss: 0.0283
2024-05-22 17:47:34 [INFO]: Epoch 035 - training loss: 0.5100, validation loss: 0.0454
2024-05-22 17:47:35 [INFO]: Epoch 036 - training loss: 0.5072, validation loss: 0.0424
2024-05-22 17:47:35 [INFO]: Epoch 037 - training loss: 0.4987, validation loss: 0.0279
2024-05-22 17:47:36 [INFO]: Epoch 038 - training loss: 0.4933, validation loss: 0.0319
2024-05-22 17:47:36 [INFO]: Epoch 039 - training loss: 0.5022, validation loss: 0.0481
2024-05-22 17:47:37 [INFO]: Epoch 040 - training loss: 0.5178, validation loss: 0.0465
2024-05-22 17:47:37 [INFO]: Epoch 041 - training loss: 0.5088, validation loss: 0.0527
2024-05-22 17:47:38 [INFO]: Epoch 042 - training loss: 0.4824, validation loss: 0.0317
2024-05-22 17:47:38 [INFO]: Epoch 043 - training loss: 0.4975, validation loss: 0.0412
2024-05-22 17:47:39 [INFO]: Epoch 044 - training loss: 0.4927, validation loss: 0.0373
2024-05-22 17:47:39 [INFO]: Epoch 045 - training loss: 0.4747, validation loss: 0.0446
2024-05-22 17:47:40 [INFO]: Epoch 046 - training loss: 0.4617, validation loss: 0.0418
2024-05-22 17:47:40 [INFO]: Epoch 047 - training loss: 0.4620, validation loss: 0.0374
2024-05-22 17:47:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:47:40 [INFO]: Finished training. The best model is from epoch#37.
2024-05-22 17:47:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/SAITS_ettm1/20240522_T174717/SAITS.pypots
2024-05-22 17:47:40 [INFO]: SAITS on ETTm1: MAE=0.1566, MSE=0.0471
2024-05-22 17:47:40 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-22 17:47:40 [INFO]: Using the given device: cuda:0
2024-05-22 17:47:40 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/Transformer_ettm1/20240522_T174740
2024-05-22 17:47:40 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/Transformer_ettm1/20240522_T174740/tensorboard
2024-05-22 17:47:41 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 17:47:41 [INFO]: Epoch 001 - training loss: 1.2100, validation loss: 0.3246
2024-05-22 17:47:41 [INFO]: Epoch 002 - training loss: 0.7363, validation loss: 0.1456
2024-05-22 17:47:41 [INFO]: Epoch 003 - training loss: 0.6018, validation loss: 0.1096
2024-05-22 17:47:41 [INFO]: Epoch 004 - training loss: 0.5283, validation loss: 0.0897
2024-05-22 17:47:42 [INFO]: Epoch 005 - training loss: 0.4949, validation loss: 0.0742
2024-05-22 17:47:42 [INFO]: Epoch 006 - training loss: 0.4647, validation loss: 0.0737
2024-05-22 17:47:42 [INFO]: Epoch 007 - training loss: 0.4442, validation loss: 0.0708
2024-05-22 17:47:42 [INFO]: Epoch 008 - training loss: 0.4305, validation loss: 0.0586
2024-05-22 17:47:42 [INFO]: Epoch 009 - training loss: 0.4096, validation loss: 0.0564
2024-05-22 17:47:43 [INFO]: Epoch 010 - training loss: 0.3933, validation loss: 0.0575
2024-05-22 17:47:43 [INFO]: Epoch 011 - training loss: 0.3874, validation loss: 0.0597
2024-05-22 17:47:43 [INFO]: Epoch 012 - training loss: 0.3838, validation loss: 0.0506
2024-05-22 17:47:43 [INFO]: Epoch 013 - training loss: 0.3754, validation loss: 0.0483
2024-05-22 17:47:43 [INFO]: Epoch 014 - training loss: 0.3621, validation loss: 0.0448
2024-05-22 17:47:44 [INFO]: Epoch 015 - training loss: 0.3582, validation loss: 0.0478
2024-05-22 17:47:44 [INFO]: Epoch 016 - training loss: 0.3502, validation loss: 0.0541
2024-05-22 17:47:44 [INFO]: Epoch 017 - training loss: 0.3455, validation loss: 0.0425
2024-05-22 17:47:44 [INFO]: Epoch 018 - training loss: 0.3383, validation loss: 0.0446
2024-05-22 17:47:44 [INFO]: Epoch 019 - training loss: 0.3295, validation loss: 0.0415
2024-05-22 17:47:45 [INFO]: Epoch 020 - training loss: 0.3360, validation loss: 0.0402
2024-05-22 17:47:45 [INFO]: Epoch 021 - training loss: 0.3144, validation loss: 0.0433
2024-05-22 17:47:45 [INFO]: Epoch 022 - training loss: 0.3204, validation loss: 0.0399
2024-05-22 17:47:45 [INFO]: Epoch 023 - training loss: 0.3201, validation loss: 0.0383
2024-05-22 17:47:45 [INFO]: Epoch 024 - training loss: 0.3172, validation loss: 0.0386
2024-05-22 17:47:46 [INFO]: Epoch 025 - training loss: 0.3053, validation loss: 0.0364
2024-05-22 17:47:46 [INFO]: Epoch 026 - training loss: 0.2984, validation loss: 0.0334
2024-05-22 17:47:46 [INFO]: Epoch 027 - training loss: 0.2957, validation loss: 0.0317
2024-05-22 17:47:46 [INFO]: Epoch 028 - training loss: 0.2909, validation loss: 0.0317
2024-05-22 17:47:46 [INFO]: Epoch 029 - training loss: 0.2887, validation loss: 0.0371
2024-05-22 17:47:47 [INFO]: Epoch 030 - training loss: 0.2871, validation loss: 0.0322
2024-05-22 17:47:47 [INFO]: Epoch 031 - training loss: 0.2754, validation loss: 0.0325
2024-05-22 17:47:47 [INFO]: Epoch 032 - training loss: 0.2790, validation loss: 0.0325
2024-05-22 17:47:47 [INFO]: Epoch 033 - training loss: 0.2731, validation loss: 0.0324
2024-05-22 17:47:47 [INFO]: Epoch 034 - training loss: 0.2726, validation loss: 0.0326
2024-05-22 17:47:48 [INFO]: Epoch 035 - training loss: 0.2675, validation loss: 0.0314
2024-05-22 17:47:48 [INFO]: Epoch 036 - training loss: 0.2676, validation loss: 0.0289
2024-05-22 17:47:48 [INFO]: Epoch 037 - training loss: 0.2667, validation loss: 0.0306
2024-05-22 17:47:48 [INFO]: Epoch 038 - training loss: 0.2628, validation loss: 0.0262
2024-05-22 17:47:49 [INFO]: Epoch 039 - training loss: 0.2612, validation loss: 0.0278
2024-05-22 17:47:49 [INFO]: Epoch 040 - training loss: 0.2524, validation loss: 0.0302
2024-05-22 17:47:49 [INFO]: Epoch 041 - training loss: 0.2579, validation loss: 0.0326
2024-05-22 17:47:49 [INFO]: Epoch 042 - training loss: 0.2558, validation loss: 0.0277
2024-05-22 17:47:49 [INFO]: Epoch 043 - training loss: 0.2518, validation loss: 0.0272
2024-05-22 17:47:50 [INFO]: Epoch 044 - training loss: 0.2455, validation loss: 0.0260
2024-05-22 17:47:50 [INFO]: Epoch 045 - training loss: 0.2454, validation loss: 0.0320
2024-05-22 17:47:50 [INFO]: Epoch 046 - training loss: 0.2454, validation loss: 0.0319
2024-05-22 17:47:50 [INFO]: Epoch 047 - training loss: 0.2472, validation loss: 0.0285
2024-05-22 17:47:50 [INFO]: Epoch 048 - training loss: 0.2443, validation loss: 0.0313
2024-05-22 17:47:51 [INFO]: Epoch 049 - training loss: 0.2536, validation loss: 0.0290
2024-05-22 17:47:51 [INFO]: Epoch 050 - training loss: 0.2474, validation loss: 0.0281
2024-05-22 17:47:51 [INFO]: Epoch 051 - training loss: 0.2434, validation loss: 0.0253
2024-05-22 17:47:51 [INFO]: Epoch 052 - training loss: 0.2390, validation loss: 0.0228
2024-05-22 17:47:51 [INFO]: Epoch 053 - training loss: 0.2297, validation loss: 0.0244
2024-05-22 17:47:52 [INFO]: Epoch 054 - training loss: 0.2308, validation loss: 0.0251
2024-05-22 17:47:52 [INFO]: Epoch 055 - training loss: 0.2397, validation loss: 0.0291
2024-05-22 17:47:52 [INFO]: Epoch 056 - training loss: 0.2349, validation loss: 0.0264
2024-05-22 17:47:52 [INFO]: Epoch 057 - training loss: 0.2317, validation loss: 0.0234
2024-05-22 17:47:52 [INFO]: Epoch 058 - training loss: 0.2259, validation loss: 0.0251
2024-05-22 17:47:53 [INFO]: Epoch 059 - training loss: 0.2268, validation loss: 0.0280
2024-05-22 17:47:53 [INFO]: Epoch 060 - training loss: 0.2396, validation loss: 0.0256
2024-05-22 17:47:53 [INFO]: Epoch 061 - training loss: 0.2267, validation loss: 0.0237
2024-05-22 17:47:53 [INFO]: Epoch 062 - training loss: 0.2193, validation loss: 0.0269
2024-05-22 17:47:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:47:53 [INFO]: Finished training. The best model is from epoch#52.
2024-05-22 17:47:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/Transformer_ettm1/20240522_T174740/Transformer.pypots
2024-05-22 17:47:53 [INFO]: Transformer on ETTm1: MAE=0.1358, MSE=0.0361
2024-05-22 17:47:53 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-22 17:47:53 [INFO]: Using the given device: cuda:0
2024-05-22 17:47:53 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_ettm1/20240522_T174753
2024-05-22 17:47:53 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_ettm1/20240522_T174753/tensorboard
2024-05-22 17:47:53 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 17:47:54 [INFO]: Epoch 001 - training loss: 0.1841, validation loss: 0.0603
2024-05-22 17:47:54 [INFO]: Epoch 002 - training loss: 0.0708, validation loss: 0.0442
2024-05-22 17:47:54 [INFO]: Epoch 003 - training loss: 0.0569, validation loss: 0.0392
2024-05-22 17:47:54 [INFO]: Epoch 004 - training loss: 0.0510, validation loss: 0.0339
2024-05-22 17:47:54 [INFO]: Epoch 005 - training loss: 0.0492, validation loss: 0.0318
2024-05-22 17:47:55 [INFO]: Epoch 006 - training loss: 0.0478, validation loss: 0.0333
2024-05-22 17:47:55 [INFO]: Epoch 007 - training loss: 0.0485, validation loss: 0.0329
2024-05-22 17:47:55 [INFO]: Epoch 008 - training loss: 0.0459, validation loss: 0.0345
2024-05-22 17:47:55 [INFO]: Epoch 009 - training loss: 0.0477, validation loss: 0.0336
2024-05-22 17:47:55 [INFO]: Epoch 010 - training loss: 0.0474, validation loss: 0.0317
2024-05-22 17:47:56 [INFO]: Epoch 011 - training loss: 0.0443, validation loss: 0.0289
2024-05-22 17:47:56 [INFO]: Epoch 012 - training loss: 0.0424, validation loss: 0.0297
2024-05-22 17:47:56 [INFO]: Epoch 013 - training loss: 0.0442, validation loss: 0.0284
2024-05-22 17:47:56 [INFO]: Epoch 014 - training loss: 0.0432, validation loss: 0.0291
2024-05-22 17:47:56 [INFO]: Epoch 015 - training loss: 0.0436, validation loss: 0.0281
2024-05-22 17:47:57 [INFO]: Epoch 016 - training loss: 0.0433, validation loss: 0.0284
2024-05-22 17:47:57 [INFO]: Epoch 017 - training loss: 0.0439, validation loss: 0.0315
2024-05-22 17:47:57 [INFO]: Epoch 018 - training loss: 0.0475, validation loss: 0.0313
2024-05-22 17:47:57 [INFO]: Epoch 019 - training loss: 0.0494, validation loss: 0.0296
2024-05-22 17:47:57 [INFO]: Epoch 020 - training loss: 0.0456, validation loss: 0.0270
2024-05-22 17:47:58 [INFO]: Epoch 021 - training loss: 0.0436, validation loss: 0.0301
2024-05-22 17:47:58 [INFO]: Epoch 022 - training loss: 0.0438, validation loss: 0.0286
2024-05-22 17:47:58 [INFO]: Epoch 023 - training loss: 0.0417, validation loss: 0.0279
2024-05-22 17:47:58 [INFO]: Epoch 024 - training loss: 0.0412, validation loss: 0.0338
2024-05-22 17:47:58 [INFO]: Epoch 025 - training loss: 0.0482, validation loss: 0.0269
2024-05-22 17:47:58 [INFO]: Epoch 026 - training loss: 0.0460, validation loss: 0.0275
2024-05-22 17:47:59 [INFO]: Epoch 027 - training loss: 0.0413, validation loss: 0.0265
2024-05-22 17:47:59 [INFO]: Epoch 028 - training loss: 0.0404, validation loss: 0.0264
2024-05-22 17:47:59 [INFO]: Epoch 029 - training loss: 0.0409, validation loss: 0.0281
2024-05-22 17:47:59 [INFO]: Epoch 030 - training loss: 0.0395, validation loss: 0.0262
2024-05-22 17:47:59 [INFO]: Epoch 031 - training loss: 0.0381, validation loss: 0.0263
2024-05-22 17:48:00 [INFO]: Epoch 032 - training loss: 0.0393, validation loss: 0.0268
2024-05-22 17:48:00 [INFO]: Epoch 033 - training loss: 0.0392, validation loss: 0.0253
2024-05-22 17:48:00 [INFO]: Epoch 034 - training loss: 0.0389, validation loss: 0.0270
2024-05-22 17:48:00 [INFO]: Epoch 035 - training loss: 0.0388, validation loss: 0.0263
2024-05-22 17:48:00 [INFO]: Epoch 036 - training loss: 0.0398, validation loss: 0.0240
2024-05-22 17:48:01 [INFO]: Epoch 037 - training loss: 0.0397, validation loss: 0.0253
2024-05-22 17:48:01 [INFO]: Epoch 038 - training loss: 0.0405, validation loss: 0.0262
2024-05-22 17:48:01 [INFO]: Epoch 039 - training loss: 0.0392, validation loss: 0.0252
2024-05-22 17:48:01 [INFO]: Epoch 040 - training loss: 0.0397, validation loss: 0.0252
2024-05-22 17:48:01 [INFO]: Epoch 041 - training loss: 0.0352, validation loss: 0.0236
2024-05-22 17:48:02 [INFO]: Epoch 042 - training loss: 0.0352, validation loss: 0.0242
2024-05-22 17:48:02 [INFO]: Epoch 043 - training loss: 0.0349, validation loss: 0.0253
2024-05-22 17:48:02 [INFO]: Epoch 044 - training loss: 0.0427, validation loss: 0.0245
2024-05-22 17:48:02 [INFO]: Epoch 045 - training loss: 0.0378, validation loss: 0.0246
2024-05-22 17:48:02 [INFO]: Epoch 046 - training loss: 0.0385, validation loss: 0.0247
2024-05-22 17:48:02 [INFO]: Epoch 047 - training loss: 0.0366, validation loss: 0.0253
2024-05-22 17:48:03 [INFO]: Epoch 048 - training loss: 0.0337, validation loss: 0.0251
2024-05-22 17:48:03 [INFO]: Epoch 049 - training loss: 0.0355, validation loss: 0.0241
2024-05-22 17:48:03 [INFO]: Epoch 050 - training loss: 0.0350, validation loss: 0.0233
2024-05-22 17:48:03 [INFO]: Epoch 051 - training loss: 0.0354, validation loss: 0.0224
2024-05-22 17:48:03 [INFO]: Epoch 052 - training loss: 0.0363, validation loss: 0.0234
2024-05-22 17:48:04 [INFO]: Epoch 053 - training loss: 0.0353, validation loss: 0.0227
2024-05-22 17:48:04 [INFO]: Epoch 054 - training loss: 0.0340, validation loss: 0.0239
2024-05-22 17:48:04 [INFO]: Epoch 055 - training loss: 0.0369, validation loss: 0.0261
2024-05-22 17:48:04 [INFO]: Epoch 056 - training loss: 0.0468, validation loss: 0.0247
2024-05-22 17:48:04 [INFO]: Epoch 057 - training loss: 0.0353, validation loss: 0.0234
2024-05-22 17:48:05 [INFO]: Epoch 058 - training loss: 0.0355, validation loss: 0.0223
2024-05-22 17:48:05 [INFO]: Epoch 059 - training loss: 0.0373, validation loss: 0.0236
2024-05-22 17:48:05 [INFO]: Epoch 060 - training loss: 0.0362, validation loss: 0.0237
2024-05-22 17:48:05 [INFO]: Epoch 061 - training loss: 0.0351, validation loss: 0.0229
2024-05-22 17:48:05 [INFO]: Epoch 062 - training loss: 0.0378, validation loss: 0.0222
2024-05-22 17:48:06 [INFO]: Epoch 063 - training loss: 0.0365, validation loss: 0.0234
2024-05-22 17:48:06 [INFO]: Epoch 064 - training loss: 0.0339, validation loss: 0.0234
2024-05-22 17:48:06 [INFO]: Epoch 065 - training loss: 0.0356, validation loss: 0.0224
2024-05-22 17:48:06 [INFO]: Epoch 066 - training loss: 0.0347, validation loss: 0.0218
2024-05-22 17:48:06 [INFO]: Epoch 067 - training loss: 0.0348, validation loss: 0.0221
2024-05-22 17:48:07 [INFO]: Epoch 068 - training loss: 0.0342, validation loss: 0.0217
2024-05-22 17:48:07 [INFO]: Epoch 069 - training loss: 0.0378, validation loss: 0.0225
2024-05-22 17:48:07 [INFO]: Epoch 070 - training loss: 0.0402, validation loss: 0.0234
2024-05-22 17:48:07 [INFO]: Epoch 071 - training loss: 0.0443, validation loss: 0.0256
2024-05-22 17:48:07 [INFO]: Epoch 072 - training loss: 0.0367, validation loss: 0.0234
2024-05-22 17:48:07 [INFO]: Epoch 073 - training loss: 0.0338, validation loss: 0.0230
2024-05-22 17:48:08 [INFO]: Epoch 074 - training loss: 0.0345, validation loss: 0.0215
2024-05-22 17:48:08 [INFO]: Epoch 075 - training loss: 0.0330, validation loss: 0.0208
2024-05-22 17:48:08 [INFO]: Epoch 076 - training loss: 0.0354, validation loss: 0.0222
2024-05-22 17:48:08 [INFO]: Epoch 077 - training loss: 0.0333, validation loss: 0.0235
2024-05-22 17:48:08 [INFO]: Epoch 078 - training loss: 0.0354, validation loss: 0.0215
2024-05-22 17:48:09 [INFO]: Epoch 079 - training loss: 0.0324, validation loss: 0.0218
2024-05-22 17:48:09 [INFO]: Epoch 080 - training loss: 0.0315, validation loss: 0.0218
2024-05-22 17:48:09 [INFO]: Epoch 081 - training loss: 0.0322, validation loss: 0.0211
2024-05-22 17:48:09 [INFO]: Epoch 082 - training loss: 0.0312, validation loss: 0.0208
2024-05-22 17:48:09 [INFO]: Epoch 083 - training loss: 0.0304, validation loss: 0.0201
2024-05-22 17:48:10 [INFO]: Epoch 084 - training loss: 0.0303, validation loss: 0.0203
2024-05-22 17:48:10 [INFO]: Epoch 085 - training loss: 0.0339, validation loss: 0.0226
2024-05-22 17:48:10 [INFO]: Epoch 086 - training loss: 0.0361, validation loss: 0.0239
2024-05-22 17:48:10 [INFO]: Epoch 087 - training loss: 0.0338, validation loss: 0.0217
2024-05-22 17:48:10 [INFO]: Epoch 088 - training loss: 0.0343, validation loss: 0.0227
2024-05-22 17:48:11 [INFO]: Epoch 089 - training loss: 0.0339, validation loss: 0.0211
2024-05-22 17:48:11 [INFO]: Epoch 090 - training loss: 0.0309, validation loss: 0.0235
2024-05-22 17:48:11 [INFO]: Epoch 091 - training loss: 0.0322, validation loss: 0.0215
2024-05-22 17:48:11 [INFO]: Epoch 092 - training loss: 0.0302, validation loss: 0.0209
2024-05-22 17:48:11 [INFO]: Epoch 093 - training loss: 0.0313, validation loss: 0.0202
2024-05-22 17:48:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:48:11 [INFO]: Finished training. The best model is from epoch#83.
2024-05-22 17:48:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/TimesNet_ettm1/20240522_T174753/TimesNet.pypots
2024-05-22 17:48:11 [INFO]: TimesNet on ETTm1: MAE=0.1041, MSE=0.0237
2024-05-22 17:48:11 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-22 17:48:11 [INFO]: Using the given device: cuda:0
2024-05-22 17:48:11 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811
2024-05-22 17:48:11 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/tensorboard
2024-05-22 17:48:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 17:48:14 [INFO]: Epoch 001 - training loss: 0.6581, validation loss: 0.4708
2024-05-22 17:48:14 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch1_loss0.4708099141716957.pypots
2024-05-22 17:48:16 [INFO]: Epoch 002 - training loss: 0.4367, validation loss: 0.3649
2024-05-22 17:48:16 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch2_loss0.3648889511823654.pypots
2024-05-22 17:48:18 [INFO]: Epoch 003 - training loss: 0.4025, validation loss: 0.3545
2024-05-22 17:48:18 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch3_loss0.35451899468898773.pypots
2024-05-22 17:48:20 [INFO]: Epoch 004 - training loss: 0.3318, validation loss: 0.3110
2024-05-22 17:48:20 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch4_loss0.31104907393455505.pypots
2024-05-22 17:48:22 [INFO]: Epoch 005 - training loss: 0.2602, validation loss: 0.2995
2024-05-22 17:48:22 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch5_loss0.29953674226999283.pypots
2024-05-22 17:48:24 [INFO]: Epoch 006 - training loss: 0.2915, validation loss: 0.2839
2024-05-22 17:48:24 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch6_loss0.28385622054338455.pypots
2024-05-22 17:48:26 [INFO]: Epoch 007 - training loss: 0.3525, validation loss: 0.2785
2024-05-22 17:48:26 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch7_loss0.2784629315137863.pypots
2024-05-22 17:48:28 [INFO]: Epoch 008 - training loss: 0.3301, validation loss: 0.3587
2024-05-22 17:48:28 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch8_loss0.3587171286344528.pypots
2024-05-22 17:48:30 [INFO]: Epoch 009 - training loss: 0.2676, validation loss: 0.3597
2024-05-22 17:48:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch9_loss0.35973650217056274.pypots
2024-05-22 17:48:32 [INFO]: Epoch 010 - training loss: 0.3165, validation loss: 0.2858
2024-05-22 17:48:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch10_loss0.2858072593808174.pypots
2024-05-22 17:48:34 [INFO]: Epoch 011 - training loss: 0.3001, validation loss: 0.2645
2024-05-22 17:48:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch11_loss0.264520026743412.pypots
2024-05-22 17:48:36 [INFO]: Epoch 012 - training loss: 0.2639, validation loss: 0.2705
2024-05-22 17:48:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch12_loss0.2704584524035454.pypots
2024-05-22 17:48:38 [INFO]: Epoch 013 - training loss: 0.2452, validation loss: 0.2474
2024-05-22 17:48:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch13_loss0.24736035987734795.pypots
2024-05-22 17:48:40 [INFO]: Epoch 014 - training loss: 0.2277, validation loss: 0.2369
2024-05-22 17:48:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch14_loss0.23694643378257751.pypots
2024-05-22 17:48:42 [INFO]: Epoch 015 - training loss: 0.2398, validation loss: 0.2306
2024-05-22 17:48:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch15_loss0.23062516748905182.pypots
2024-05-22 17:48:44 [INFO]: Epoch 016 - training loss: 0.2119, validation loss: 0.2282
2024-05-22 17:48:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch16_loss0.2282062992453575.pypots
2024-05-22 17:48:46 [INFO]: Epoch 017 - training loss: 0.2004, validation loss: 0.2200
2024-05-22 17:48:46 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch17_loss0.2200145497918129.pypots
2024-05-22 17:48:48 [INFO]: Epoch 018 - training loss: 0.2377, validation loss: 0.2112
2024-05-22 17:48:48 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch18_loss0.2112475223839283.pypots
2024-05-22 17:48:50 [INFO]: Epoch 019 - training loss: 0.2561, validation loss: 0.2289
2024-05-22 17:48:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch19_loss0.22888803854584694.pypots
2024-05-22 17:48:53 [INFO]: Epoch 020 - training loss: 0.2189, validation loss: 0.2468
2024-05-22 17:48:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch20_loss0.24679016694426537.pypots
2024-05-22 17:48:55 [INFO]: Epoch 021 - training loss: 0.2216, validation loss: 0.2124
2024-05-22 17:48:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch21_loss0.21240593865513802.pypots
2024-05-22 17:48:57 [INFO]: Epoch 022 - training loss: 0.1837, validation loss: 0.2081
2024-05-22 17:48:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch22_loss0.2080574370920658.pypots
2024-05-22 17:48:59 [INFO]: Epoch 023 - training loss: 0.1952, validation loss: 0.2033
2024-05-22 17:48:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch23_loss0.2032720446586609.pypots
2024-05-22 17:49:01 [INFO]: Epoch 024 - training loss: 0.2088, validation loss: 0.1996
2024-05-22 17:49:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch24_loss0.1996459700167179.pypots
2024-05-22 17:49:03 [INFO]: Epoch 025 - training loss: 0.2314, validation loss: 0.1909
2024-05-22 17:49:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch25_loss0.1909358985722065.pypots
2024-05-22 17:49:05 [INFO]: Epoch 026 - training loss: 0.1946, validation loss: 0.1906
2024-05-22 17:49:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch26_loss0.19064652547240257.pypots
2024-05-22 17:49:07 [INFO]: Epoch 027 - training loss: 0.1790, validation loss: 0.1833
2024-05-22 17:49:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch27_loss0.18334005400538445.pypots
2024-05-22 17:49:09 [INFO]: Epoch 028 - training loss: 0.1826, validation loss: 0.1804
2024-05-22 17:49:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch28_loss0.18037625774741173.pypots
2024-05-22 17:49:11 [INFO]: Epoch 029 - training loss: 0.1949, validation loss: 0.1799
2024-05-22 17:49:11 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch29_loss0.17992586642503738.pypots
2024-05-22 17:49:13 [INFO]: Epoch 030 - training loss: 0.1789, validation loss: 0.1864
2024-05-22 17:49:13 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch30_loss0.18635417148470879.pypots
2024-05-22 17:49:15 [INFO]: Epoch 031 - training loss: 0.1924, validation loss: 0.1734
2024-05-22 17:49:15 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch31_loss0.1733936183154583.pypots
2024-05-22 17:49:17 [INFO]: Epoch 032 - training loss: 0.2376, validation loss: 0.1706
2024-05-22 17:49:17 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch32_loss0.17059922963380814.pypots
2024-05-22 17:49:19 [INFO]: Epoch 033 - training loss: 0.1979, validation loss: 0.1750
2024-05-22 17:49:19 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch33_loss0.1749909482896328.pypots
2024-05-22 17:49:21 [INFO]: Epoch 034 - training loss: 0.1770, validation loss: 0.1738
2024-05-22 17:49:21 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch34_loss0.1737595871090889.pypots
2024-05-22 17:49:23 [INFO]: Epoch 035 - training loss: 0.1538, validation loss: 0.1646
2024-05-22 17:49:23 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch35_loss0.16460062563419342.pypots
2024-05-22 17:49:25 [INFO]: Epoch 036 - training loss: 0.1705, validation loss: 0.1695
2024-05-22 17:49:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch36_loss0.16945356130599976.pypots
2024-05-22 17:49:27 [INFO]: Epoch 037 - training loss: 0.1913, validation loss: 0.2590
2024-05-22 17:49:27 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch37_loss0.258955754339695.pypots
2024-05-22 17:49:30 [INFO]: Epoch 038 - training loss: 0.2024, validation loss: 0.2271
2024-05-22 17:49:30 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch38_loss0.22711637243628502.pypots
2024-05-22 17:49:32 [INFO]: Epoch 039 - training loss: 0.1869, validation loss: 0.1830
2024-05-22 17:49:32 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch39_loss0.18295137584209442.pypots
2024-05-22 17:49:34 [INFO]: Epoch 040 - training loss: 0.1822, validation loss: 0.1656
2024-05-22 17:49:34 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch40_loss0.16559064760804176.pypots
2024-05-22 17:49:36 [INFO]: Epoch 041 - training loss: 0.1711, validation loss: 0.1685
2024-05-22 17:49:36 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch41_loss0.1684560850262642.pypots
2024-05-22 17:49:38 [INFO]: Epoch 042 - training loss: 0.1860, validation loss: 0.2043
2024-05-22 17:49:38 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch42_loss0.20431185886263847.pypots
2024-05-22 17:49:40 [INFO]: Epoch 043 - training loss: 0.1978, validation loss: 0.1987
2024-05-22 17:49:40 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch43_loss0.1987118385732174.pypots
2024-05-22 17:49:42 [INFO]: Epoch 044 - training loss: 0.1993, validation loss: 0.1701
2024-05-22 17:49:42 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch44_loss0.17011383548378944.pypots
2024-05-22 17:49:44 [INFO]: Epoch 045 - training loss: 0.1554, validation loss: 0.1649
2024-05-22 17:49:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI_epoch45_loss0.16486137360334396.pypots
2024-05-22 17:49:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:49:44 [INFO]: Finished training. The best model is from epoch#35.
2024-05-22 17:49:44 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/20240522_T174811/CSDI.pypots
2024-05-22 17:50:00 [INFO]: CSDI on ETTm1: MAE=0.1879, MSE=0.1539
2024-05-22 17:50:00 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-22 17:50:00 [INFO]: Using the given device: cuda:0
2024-05-22 17:50:00 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_ettm1/20240522_T175000
2024-05-22 17:50:00 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_ettm1/20240522_T175000/tensorboard
2024-05-22 17:50:00 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 17:50:00 [INFO]: Epoch 001 - training loss: 23882.9249, validation loss: 0.9463
2024-05-22 17:50:00 [INFO]: Epoch 002 - training loss: 21765.1838, validation loss: 0.9546
2024-05-22 17:50:00 [INFO]: Epoch 003 - training loss: 19847.7880, validation loss: 0.9552
2024-05-22 17:50:00 [INFO]: Epoch 004 - training loss: 17775.6372, validation loss: 0.9499
2024-05-22 17:50:00 [INFO]: Epoch 005 - training loss: 15951.5519, validation loss: 0.9328
2024-05-22 17:50:00 [INFO]: Epoch 006 - training loss: 14229.4973, validation loss: 0.8892
2024-05-22 17:50:00 [INFO]: Epoch 007 - training loss: 13065.6790, validation loss: 0.8008
2024-05-22 17:50:00 [INFO]: Epoch 008 - training loss: 12124.3115, validation loss: 0.6706
2024-05-22 17:50:01 [INFO]: Epoch 009 - training loss: 11481.0773, validation loss: 0.5653
2024-05-22 17:50:01 [INFO]: Epoch 010 - training loss: 11192.5015, validation loss: 0.5204
2024-05-22 17:50:01 [INFO]: Epoch 011 - training loss: 10720.8967, validation loss: 0.5071
2024-05-22 17:50:01 [INFO]: Epoch 012 - training loss: 10436.6585, validation loss: 0.4956
2024-05-22 17:50:01 [INFO]: Epoch 013 - training loss: 10328.5896, validation loss: 0.4898
2024-05-22 17:50:01 [INFO]: Epoch 014 - training loss: 10152.6857, validation loss: 0.4889
2024-05-22 17:50:01 [INFO]: Epoch 015 - training loss: 10146.8362, validation loss: 0.4712
2024-05-22 17:50:01 [INFO]: Epoch 016 - training loss: 9985.5735, validation loss: 0.4464
2024-05-22 17:50:01 [INFO]: Epoch 017 - training loss: 9886.1417, validation loss: 0.4239
2024-05-22 17:50:02 [INFO]: Epoch 018 - training loss: 9841.7092, validation loss: 0.4038
2024-05-22 17:50:02 [INFO]: Epoch 019 - training loss: 9803.2196, validation loss: 0.3888
2024-05-22 17:50:02 [INFO]: Epoch 020 - training loss: 9733.4178, validation loss: 0.3674
2024-05-22 17:50:02 [INFO]: Epoch 021 - training loss: 9674.9464, validation loss: 0.3464
2024-05-22 17:50:02 [INFO]: Epoch 022 - training loss: 9649.7463, validation loss: 0.3232
2024-05-22 17:50:02 [INFO]: Epoch 023 - training loss: 9605.7952, validation loss: 0.3070
2024-05-22 17:50:02 [INFO]: Epoch 024 - training loss: 9601.7216, validation loss: 0.2908
2024-05-22 17:50:02 [INFO]: Epoch 025 - training loss: 9568.6212, validation loss: 0.2798
2024-05-22 17:50:02 [INFO]: Epoch 026 - training loss: 9538.0071, validation loss: 0.2727
2024-05-22 17:50:03 [INFO]: Epoch 027 - training loss: 9522.3409, validation loss: 0.2623
2024-05-22 17:50:03 [INFO]: Epoch 028 - training loss: 9498.5099, validation loss: 0.2537
2024-05-22 17:50:03 [INFO]: Epoch 029 - training loss: 9498.0303, validation loss: 0.2504
2024-05-22 17:50:03 [INFO]: Epoch 030 - training loss: 9488.2950, validation loss: 0.2472
2024-05-22 17:50:03 [INFO]: Epoch 031 - training loss: 9464.8248, validation loss: 0.2402
2024-05-22 17:50:03 [INFO]: Epoch 032 - training loss: 9456.0756, validation loss: 0.2378
2024-05-22 17:50:03 [INFO]: Epoch 033 - training loss: 9450.5086, validation loss: 0.2340
2024-05-22 17:50:03 [INFO]: Epoch 034 - training loss: 9440.7338, validation loss: 0.2312
2024-05-22 17:50:03 [INFO]: Epoch 035 - training loss: 9426.3579, validation loss: 0.2263
2024-05-22 17:50:04 [INFO]: Epoch 036 - training loss: 9418.9373, validation loss: 0.2195
2024-05-22 17:50:04 [INFO]: Epoch 037 - training loss: 9412.7292, validation loss: 0.2160
2024-05-22 17:50:04 [INFO]: Epoch 038 - training loss: 9403.3479, validation loss: 0.2135
2024-05-22 17:50:04 [INFO]: Epoch 039 - training loss: 9400.8336, validation loss: 0.2121
2024-05-22 17:50:04 [INFO]: Epoch 040 - training loss: 9398.2202, validation loss: 0.2087
2024-05-22 17:50:04 [INFO]: Epoch 041 - training loss: 9397.5164, validation loss: 0.2024
2024-05-22 17:50:04 [INFO]: Epoch 042 - training loss: 9402.3956, validation loss: 0.1954
2024-05-22 17:50:04 [INFO]: Epoch 043 - training loss: 9380.7756, validation loss: 0.1985
2024-05-22 17:50:04 [INFO]: Epoch 044 - training loss: 9376.8088, validation loss: 0.1940
2024-05-22 17:50:04 [INFO]: Epoch 045 - training loss: 9370.1071, validation loss: 0.1863
2024-05-22 17:50:05 [INFO]: Epoch 046 - training loss: 9369.1292, validation loss: 0.1819
2024-05-22 17:50:05 [INFO]: Epoch 047 - training loss: 9363.7374, validation loss: 0.1803
2024-05-22 17:50:05 [INFO]: Epoch 048 - training loss: 9368.6677, validation loss: 0.1755
2024-05-22 17:50:05 [INFO]: Epoch 049 - training loss: 9365.0137, validation loss: 0.1721
2024-05-22 17:50:05 [INFO]: Epoch 050 - training loss: 9353.1966, validation loss: 0.1679
2024-05-22 17:50:05 [INFO]: Epoch 051 - training loss: 9351.9633, validation loss: 0.1632
2024-05-22 17:50:05 [INFO]: Epoch 052 - training loss: 9345.4214, validation loss: 0.1598
2024-05-22 17:50:05 [INFO]: Epoch 053 - training loss: 9344.0128, validation loss: 0.1572
2024-05-22 17:50:05 [INFO]: Epoch 054 - training loss: 9341.2910, validation loss: 0.1533
2024-05-22 17:50:06 [INFO]: Epoch 055 - training loss: 9340.8418, validation loss: 0.1505
2024-05-22 17:50:06 [INFO]: Epoch 056 - training loss: 9335.8934, validation loss: 0.1474
2024-05-22 17:50:06 [INFO]: Epoch 057 - training loss: 9347.9754, validation loss: 0.1452
2024-05-22 17:50:06 [INFO]: Epoch 058 - training loss: 9336.5510, validation loss: 0.1403
2024-05-22 17:50:06 [INFO]: Epoch 059 - training loss: 9330.5082, validation loss: 0.1398
2024-05-22 17:50:06 [INFO]: Epoch 060 - training loss: 9331.7982, validation loss: 0.1359
2024-05-22 17:50:06 [INFO]: Epoch 061 - training loss: 9330.7147, validation loss: 0.1333
2024-05-22 17:50:06 [INFO]: Epoch 062 - training loss: 9326.3500, validation loss: 0.1321
2024-05-22 17:50:06 [INFO]: Epoch 063 - training loss: 9340.7289, validation loss: 0.1309
2024-05-22 17:50:07 [INFO]: Epoch 064 - training loss: 9325.0571, validation loss: 0.1285
2024-05-22 17:50:07 [INFO]: Epoch 065 - training loss: 9319.2813, validation loss: 0.1286
2024-05-22 17:50:07 [INFO]: Epoch 066 - training loss: 9321.7051, validation loss: 0.1274
2024-05-22 17:50:07 [INFO]: Epoch 067 - training loss: 9316.0331, validation loss: 0.1239
2024-05-22 17:50:07 [INFO]: Epoch 068 - training loss: 9320.3604, validation loss: 0.1237
2024-05-22 17:50:07 [INFO]: Epoch 069 - training loss: 9315.9134, validation loss: 0.1231
2024-05-22 17:50:07 [INFO]: Epoch 070 - training loss: 9316.0753, validation loss: 0.1209
2024-05-22 17:50:07 [INFO]: Epoch 071 - training loss: 9314.7704, validation loss: 0.1216
2024-05-22 17:50:07 [INFO]: Epoch 072 - training loss: 9313.7680, validation loss: 0.1206
2024-05-22 17:50:08 [INFO]: Epoch 073 - training loss: 9310.5090, validation loss: 0.1201
2024-05-22 17:50:08 [INFO]: Epoch 074 - training loss: 9311.5582, validation loss: 0.1172
2024-05-22 17:50:08 [INFO]: Epoch 075 - training loss: 9310.2749, validation loss: 0.1173
2024-05-22 17:50:08 [INFO]: Epoch 076 - training loss: 9308.3828, validation loss: 0.1161
2024-05-22 17:50:08 [INFO]: Epoch 077 - training loss: 9328.3973, validation loss: 0.1151
2024-05-22 17:50:08 [INFO]: Epoch 078 - training loss: 9307.4531, validation loss: 0.1144
2024-05-22 17:50:08 [INFO]: Epoch 079 - training loss: 9304.5099, validation loss: 0.1138
2024-05-22 17:50:08 [INFO]: Epoch 080 - training loss: 9306.1543, validation loss: 0.1137
2024-05-22 17:50:08 [INFO]: Epoch 081 - training loss: 9304.0420, validation loss: 0.1116
2024-05-22 17:50:08 [INFO]: Epoch 082 - training loss: 9303.2774, validation loss: 0.1122
2024-05-22 17:50:09 [INFO]: Epoch 083 - training loss: 9305.0238, validation loss: 0.1119
2024-05-22 17:50:09 [INFO]: Epoch 084 - training loss: 9301.6463, validation loss: 0.1093
2024-05-22 17:50:09 [INFO]: Epoch 085 - training loss: 9301.3918, validation loss: 0.1103
2024-05-22 17:50:09 [INFO]: Epoch 086 - training loss: 9299.3467, validation loss: 0.1097
2024-05-22 17:50:09 [INFO]: Epoch 087 - training loss: 9303.6680, validation loss: 0.1086
2024-05-22 17:50:09 [INFO]: Epoch 088 - training loss: 9298.3788, validation loss: 0.1117
2024-05-22 17:50:09 [INFO]: Epoch 089 - training loss: 9297.3672, validation loss: 0.1082
2024-05-22 17:50:09 [INFO]: Epoch 090 - training loss: 9296.9289, validation loss: 0.1089
2024-05-22 17:50:09 [INFO]: Epoch 091 - training loss: 9297.8557, validation loss: 0.1059
2024-05-22 17:50:10 [INFO]: Epoch 092 - training loss: 9295.9822, validation loss: 0.1086
2024-05-22 17:50:10 [INFO]: Epoch 093 - training loss: 9296.7940, validation loss: 0.1047
2024-05-22 17:50:10 [INFO]: Epoch 094 - training loss: 9296.1846, validation loss: 0.1052
2024-05-22 17:50:10 [INFO]: Epoch 095 - training loss: 9295.2452, validation loss: 0.1052
2024-05-22 17:50:10 [INFO]: Epoch 096 - training loss: 9295.5671, validation loss: 0.1037
2024-05-22 17:50:10 [INFO]: Epoch 097 - training loss: 9294.3426, validation loss: 0.1047
2024-05-22 17:50:10 [INFO]: Epoch 098 - training loss: 9295.5388, validation loss: 0.1032
2024-05-22 17:50:10 [INFO]: Epoch 099 - training loss: 9294.5039, validation loss: 0.1028
2024-05-22 17:50:10 [INFO]: Epoch 100 - training loss: 9292.7245, validation loss: 0.1027
2024-05-22 17:50:11 [INFO]: Epoch 101 - training loss: 9292.3509, validation loss: 0.1011
2024-05-22 17:50:11 [INFO]: Epoch 102 - training loss: 9293.5418, validation loss: 0.1007
2024-05-22 17:50:11 [INFO]: Epoch 103 - training loss: 9290.9741, validation loss: 0.1057
2024-05-22 17:50:11 [INFO]: Epoch 104 - training loss: 9291.6688, validation loss: 0.0995
2024-05-22 17:50:11 [INFO]: Epoch 105 - training loss: 9289.4077, validation loss: 0.1003
2024-05-22 17:50:11 [INFO]: Epoch 106 - training loss: 9289.2806, validation loss: 0.1007
2024-05-22 17:50:11 [INFO]: Epoch 107 - training loss: 9290.2320, validation loss: 0.0982
2024-05-22 17:50:11 [INFO]: Epoch 108 - training loss: 9291.8077, validation loss: 0.0988
2024-05-22 17:50:11 [INFO]: Epoch 109 - training loss: 9289.0587, validation loss: 0.0982
2024-05-22 17:50:12 [INFO]: Epoch 110 - training loss: 9289.0618, validation loss: 0.0984
2024-05-22 17:50:12 [INFO]: Epoch 111 - training loss: 9288.7558, validation loss: 0.0972
2024-05-22 17:50:12 [INFO]: Epoch 112 - training loss: 9290.6160, validation loss: 0.0979
2024-05-22 17:50:12 [INFO]: Epoch 113 - training loss: 9287.8229, validation loss: 0.0963
2024-05-22 17:50:12 [INFO]: Epoch 114 - training loss: 9286.7379, validation loss: 0.0988
2024-05-22 17:50:12 [INFO]: Epoch 115 - training loss: 9287.9421, validation loss: 0.0971
2024-05-22 17:50:12 [INFO]: Epoch 116 - training loss: 9286.9836, validation loss: 0.0971
2024-05-22 17:50:12 [INFO]: Epoch 117 - training loss: 9287.7394, validation loss: 0.0948
2024-05-22 17:50:12 [INFO]: Epoch 118 - training loss: 9287.7436, validation loss: 0.0961
2024-05-22 17:50:12 [INFO]: Epoch 119 - training loss: 9285.6980, validation loss: 0.0951
2024-05-22 17:50:13 [INFO]: Epoch 120 - training loss: 9287.2280, validation loss: 0.0958
2024-05-22 17:50:13 [INFO]: Epoch 121 - training loss: 9283.8997, validation loss: 0.0937
2024-05-22 17:50:13 [INFO]: Epoch 122 - training loss: 9285.0306, validation loss: 0.0924
2024-05-22 17:50:13 [INFO]: Epoch 123 - training loss: 9286.6362, validation loss: 0.0920
2024-05-22 17:50:13 [INFO]: Epoch 124 - training loss: 9283.5873, validation loss: 0.0936
2024-05-22 17:50:13 [INFO]: Epoch 125 - training loss: 9283.5226, validation loss: 0.0918
2024-05-22 17:50:13 [INFO]: Epoch 126 - training loss: 9285.2361, validation loss: 0.0928
2024-05-22 17:50:13 [INFO]: Epoch 127 - training loss: 9283.9497, validation loss: 0.0929
2024-05-22 17:50:13 [INFO]: Epoch 128 - training loss: 9282.8489, validation loss: 0.0942
2024-05-22 17:50:14 [INFO]: Epoch 129 - training loss: 9283.8036, validation loss: 0.0912
2024-05-22 17:50:14 [INFO]: Epoch 130 - training loss: 9283.9495, validation loss: 0.0909
2024-05-22 17:50:14 [INFO]: Epoch 131 - training loss: 9282.9032, validation loss: 0.0931
2024-05-22 17:50:14 [INFO]: Epoch 132 - training loss: 9282.8918, validation loss: 0.0920
2024-05-22 17:50:14 [INFO]: Epoch 133 - training loss: 9281.5406, validation loss: 0.0908
2024-05-22 17:50:14 [INFO]: Epoch 134 - training loss: 9283.9647, validation loss: 0.0894
2024-05-22 17:50:14 [INFO]: Epoch 135 - training loss: 9281.4904, validation loss: 0.0888
2024-05-22 17:50:14 [INFO]: Epoch 136 - training loss: 9281.8141, validation loss: 0.0893
2024-05-22 17:50:14 [INFO]: Epoch 137 - training loss: 9280.9441, validation loss: 0.0900
2024-05-22 17:50:15 [INFO]: Epoch 138 - training loss: 9280.7990, validation loss: 0.0904
2024-05-22 17:50:15 [INFO]: Epoch 139 - training loss: 9283.5774, validation loss: 0.0909
2024-05-22 17:50:15 [INFO]: Epoch 140 - training loss: 9280.7595, validation loss: 0.0901
2024-05-22 17:50:15 [INFO]: Epoch 141 - training loss: 9279.8340, validation loss: 0.0876
2024-05-22 17:50:15 [INFO]: Epoch 142 - training loss: 9282.2869, validation loss: 0.0884
2024-05-22 17:50:15 [INFO]: Epoch 143 - training loss: 9279.4136, validation loss: 0.0886
2024-05-22 17:50:15 [INFO]: Epoch 144 - training loss: 9281.4277, validation loss: 0.0879
2024-05-22 17:50:15 [INFO]: Epoch 145 - training loss: 9279.7949, validation loss: 0.0885
2024-05-22 17:50:15 [INFO]: Epoch 146 - training loss: 9280.7017, validation loss: 0.0889
2024-05-22 17:50:16 [INFO]: Epoch 147 - training loss: 9279.7124, validation loss: 0.0859
2024-05-22 17:50:16 [INFO]: Epoch 148 - training loss: 9283.2667, validation loss: 0.0877
2024-05-22 17:50:16 [INFO]: Epoch 149 - training loss: 9278.4089, validation loss: 0.0854
2024-05-22 17:50:16 [INFO]: Epoch 150 - training loss: 9279.6442, validation loss: 0.0849
2024-05-22 17:50:16 [INFO]: Epoch 151 - training loss: 9277.3765, validation loss: 0.0890
2024-05-22 17:50:16 [INFO]: Epoch 152 - training loss: 9278.4498, validation loss: 0.0871
2024-05-22 17:50:16 [INFO]: Epoch 153 - training loss: 9277.9095, validation loss: 0.0846
2024-05-22 17:50:16 [INFO]: Epoch 154 - training loss: 9279.6840, validation loss: 0.0863
2024-05-22 17:50:16 [INFO]: Epoch 155 - training loss: 9278.7712, validation loss: 0.0840
2024-05-22 17:50:17 [INFO]: Epoch 156 - training loss: 9277.9162, validation loss: 0.0860
2024-05-22 17:50:17 [INFO]: Epoch 157 - training loss: 9278.3786, validation loss: 0.0851
2024-05-22 17:50:17 [INFO]: Epoch 158 - training loss: 9277.4265, validation loss: 0.0849
2024-05-22 17:50:17 [INFO]: Epoch 159 - training loss: 9281.6879, validation loss: 0.0836
2024-05-22 17:50:17 [INFO]: Epoch 160 - training loss: 9277.1996, validation loss: 0.0848
2024-05-22 17:50:17 [INFO]: Epoch 161 - training loss: 9278.4529, validation loss: 0.0830
2024-05-22 17:50:17 [INFO]: Epoch 162 - training loss: 9277.0860, validation loss: 0.0843
2024-05-22 17:50:17 [INFO]: Epoch 163 - training loss: 9278.1599, validation loss: 0.0829
2024-05-22 17:50:17 [INFO]: Epoch 164 - training loss: 9276.5906, validation loss: 0.0847
2024-05-22 17:50:17 [INFO]: Epoch 165 - training loss: 9276.2767, validation loss: 0.0834
2024-05-22 17:50:18 [INFO]: Epoch 166 - training loss: 9275.9962, validation loss: 0.0828
2024-05-22 17:50:18 [INFO]: Epoch 167 - training loss: 9278.9034, validation loss: 0.0826
2024-05-22 17:50:18 [INFO]: Epoch 168 - training loss: 9277.9477, validation loss: 0.0823
2024-05-22 17:50:18 [INFO]: Epoch 169 - training loss: 9276.4938, validation loss: 0.0835
2024-05-22 17:50:18 [INFO]: Epoch 170 - training loss: 9276.7331, validation loss: 0.0822
2024-05-22 17:50:18 [INFO]: Epoch 171 - training loss: 9278.9875, validation loss: 0.0819
2024-05-22 17:50:18 [INFO]: Epoch 172 - training loss: 9276.5470, validation loss: 0.0818
2024-05-22 17:50:18 [INFO]: Epoch 173 - training loss: 9275.4489, validation loss: 0.0823
2024-05-22 17:50:18 [INFO]: Epoch 174 - training loss: 9276.1482, validation loss: 0.0826
2024-05-22 17:50:19 [INFO]: Epoch 175 - training loss: 9274.5066, validation loss: 0.0817
2024-05-22 17:50:19 [INFO]: Epoch 176 - training loss: 9274.8220, validation loss: 0.0822
2024-05-22 17:50:19 [INFO]: Epoch 177 - training loss: 9276.8844, validation loss: 0.0815
2024-05-22 17:50:19 [INFO]: Epoch 178 - training loss: 9276.2582, validation loss: 0.0805
2024-05-22 17:50:19 [INFO]: Epoch 179 - training loss: 9275.1761, validation loss: 0.0805
2024-05-22 17:50:19 [INFO]: Epoch 180 - training loss: 9276.0453, validation loss: 0.0817
2024-05-22 17:50:19 [INFO]: Epoch 181 - training loss: 9275.4974, validation loss: 0.0828
2024-05-22 17:50:19 [INFO]: Epoch 182 - training loss: 9277.1827, validation loss: 0.0828
2024-05-22 17:50:19 [INFO]: Epoch 183 - training loss: 9275.0204, validation loss: 0.0810
2024-05-22 17:50:20 [INFO]: Epoch 184 - training loss: 9274.6849, validation loss: 0.0811
2024-05-22 17:50:20 [INFO]: Epoch 185 - training loss: 9275.7443, validation loss: 0.0818
2024-05-22 17:50:20 [INFO]: Epoch 186 - training loss: 9273.7491, validation loss: 0.0799
2024-05-22 17:50:20 [INFO]: Epoch 187 - training loss: 9275.4027, validation loss: 0.0808
2024-05-22 17:50:20 [INFO]: Epoch 188 - training loss: 9275.6171, validation loss: 0.0793
2024-05-22 17:50:20 [INFO]: Epoch 189 - training loss: 9274.8395, validation loss: 0.0795
2024-05-22 17:50:20 [INFO]: Epoch 190 - training loss: 9274.0449, validation loss: 0.0811
2024-05-22 17:50:20 [INFO]: Epoch 191 - training loss: 9273.7496, validation loss: 0.0800
2024-05-22 17:50:20 [INFO]: Epoch 192 - training loss: 9274.7690, validation loss: 0.0779
2024-05-22 17:50:21 [INFO]: Epoch 193 - training loss: 9273.7736, validation loss: 0.0792
2024-05-22 17:50:21 [INFO]: Epoch 194 - training loss: 9274.1684, validation loss: 0.0797
2024-05-22 17:50:21 [INFO]: Epoch 195 - training loss: 9273.6539, validation loss: 0.0788
2024-05-22 17:50:21 [INFO]: Epoch 196 - training loss: 9274.4872, validation loss: 0.0796
2024-05-22 17:50:21 [INFO]: Epoch 197 - training loss: 9273.6708, validation loss: 0.0787
2024-05-22 17:50:21 [INFO]: Epoch 198 - training loss: 9273.7300, validation loss: 0.0785
2024-05-22 17:50:21 [INFO]: Epoch 199 - training loss: 9275.6811, validation loss: 0.0778
2024-05-22 17:50:21 [INFO]: Epoch 200 - training loss: 9274.1030, validation loss: 0.0784
2024-05-22 17:50:21 [INFO]: Epoch 201 - training loss: 9272.4899, validation loss: 0.0785
2024-05-22 17:50:22 [INFO]: Epoch 202 - training loss: 9272.6431, validation loss: 0.0782
2024-05-22 17:50:22 [INFO]: Epoch 203 - training loss: 9273.9129, validation loss: 0.0778
2024-05-22 17:50:22 [INFO]: Epoch 204 - training loss: 9273.1525, validation loss: 0.0808
2024-05-22 17:50:22 [INFO]: Epoch 205 - training loss: 9274.3036, validation loss: 0.0771
2024-05-22 17:50:22 [INFO]: Epoch 206 - training loss: 9273.2494, validation loss: 0.0789
2024-05-22 17:50:22 [INFO]: Epoch 207 - training loss: 9272.6354, validation loss: 0.0789
2024-05-22 17:50:22 [INFO]: Epoch 208 - training loss: 9272.2399, validation loss: 0.0780
2024-05-22 17:50:22 [INFO]: Epoch 209 - training loss: 9273.3022, validation loss: 0.0783
2024-05-22 17:50:22 [INFO]: Epoch 210 - training loss: 9272.7556, validation loss: 0.0765
2024-05-22 17:50:22 [INFO]: Epoch 211 - training loss: 9272.8531, validation loss: 0.0757
2024-05-22 17:50:23 [INFO]: Epoch 212 - training loss: 9273.0911, validation loss: 0.0773
2024-05-22 17:50:23 [INFO]: Epoch 213 - training loss: 9272.0884, validation loss: 0.0777
2024-05-22 17:50:23 [INFO]: Epoch 214 - training loss: 9271.4393, validation loss: 0.0766
2024-05-22 17:50:23 [INFO]: Epoch 215 - training loss: 9272.3743, validation loss: 0.0765
2024-05-22 17:50:23 [INFO]: Epoch 216 - training loss: 9270.7476, validation loss: 0.0772
2024-05-22 17:50:23 [INFO]: Epoch 217 - training loss: 9271.6741, validation loss: 0.0776
2024-05-22 17:50:23 [INFO]: Epoch 218 - training loss: 9270.6315, validation loss: 0.0776
2024-05-22 17:50:23 [INFO]: Epoch 219 - training loss: 9271.7040, validation loss: 0.0758
2024-05-22 17:50:23 [INFO]: Epoch 220 - training loss: 9272.3301, validation loss: 0.0764
2024-05-22 17:50:24 [INFO]: Epoch 221 - training loss: 9272.1386, validation loss: 0.0755
2024-05-22 17:50:24 [INFO]: Epoch 222 - training loss: 9270.5832, validation loss: 0.0768
2024-05-22 17:50:24 [INFO]: Epoch 223 - training loss: 9272.1970, validation loss: 0.0754
2024-05-22 17:50:24 [INFO]: Epoch 224 - training loss: 9271.9977, validation loss: 0.0742
2024-05-22 17:50:24 [INFO]: Epoch 225 - training loss: 9270.5530, validation loss: 0.0758
2024-05-22 17:50:24 [INFO]: Epoch 226 - training loss: 9271.3329, validation loss: 0.0753
2024-05-22 17:50:24 [INFO]: Epoch 227 - training loss: 9273.8687, validation loss: 0.0774
2024-05-22 17:50:24 [INFO]: Epoch 228 - training loss: 9271.3187, validation loss: 0.0765
2024-05-22 17:50:24 [INFO]: Epoch 229 - training loss: 9270.8759, validation loss: 0.0754
2024-05-22 17:50:25 [INFO]: Epoch 230 - training loss: 9272.6205, validation loss: 0.0754
2024-05-22 17:50:25 [INFO]: Epoch 231 - training loss: 9271.8893, validation loss: 0.0775
2024-05-22 17:50:25 [INFO]: Epoch 232 - training loss: 9271.6118, validation loss: 0.0762
2024-05-22 17:50:25 [INFO]: Epoch 233 - training loss: 9272.1049, validation loss: 0.0752
2024-05-22 17:50:25 [INFO]: Epoch 234 - training loss: 9271.4116, validation loss: 0.0759
2024-05-22 17:50:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:50:25 [INFO]: Finished training. The best model is from epoch#224.
2024-05-22 17:50:25 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/GPVAE_ettm1/20240522_T175000/GPVAE.pypots
2024-05-22 17:50:25 [INFO]: GP-VAE on ETTm1: MAE=0.2902, MSE=0.1698
2024-05-22 17:50:25 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-22 17:50:25 [INFO]: Using the given device: cuda:0
2024-05-22 17:50:25 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/USGAN_ettm1/20240522_T175025
2024-05-22 17:50:25 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/USGAN_ettm1/20240522_T175025/tensorboard
2024-05-22 17:50:25 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 17:50:33 [INFO]: Epoch 001 - generator training loss: 0.5493, discriminator training loss: 0.4295, validation loss: 0.2989
2024-05-22 17:50:41 [INFO]: Epoch 002 - generator training loss: -0.0002, discriminator training loss: 0.3222, validation loss: 0.0925
2024-05-22 17:50:48 [INFO]: Epoch 003 - generator training loss: -0.1262, discriminator training loss: 0.3093, validation loss: 0.0581
2024-05-22 17:50:55 [INFO]: Epoch 004 - generator training loss: -0.1349, discriminator training loss: 0.2949, validation loss: 0.0456
2024-05-22 17:51:03 [INFO]: Epoch 005 - generator training loss: -0.1270, discriminator training loss: 0.2761, validation loss: 0.0462
2024-05-22 17:51:10 [INFO]: Epoch 006 - generator training loss: -0.0985, discriminator training loss: 0.2455, validation loss: 0.0394
2024-05-22 17:51:17 [INFO]: Epoch 007 - generator training loss: -0.0781, discriminator training loss: 0.2125, validation loss: 0.0369
2024-05-22 17:51:25 [INFO]: Epoch 008 - generator training loss: -0.0493, discriminator training loss: 0.1776, validation loss: 0.0365
2024-05-22 17:51:32 [INFO]: Epoch 009 - generator training loss: -0.0402, discriminator training loss: 0.1548, validation loss: 0.0347
2024-05-22 17:51:39 [INFO]: Epoch 010 - generator training loss: -0.0346, discriminator training loss: 0.1388, validation loss: 0.0343
2024-05-22 17:51:47 [INFO]: Epoch 011 - generator training loss: -0.0309, discriminator training loss: 0.1310, validation loss: 0.0335
2024-05-22 17:51:54 [INFO]: Epoch 012 - generator training loss: -0.0303, discriminator training loss: 0.1261, validation loss: 0.0326
2024-05-22 17:52:01 [INFO]: Epoch 013 - generator training loss: -0.0311, discriminator training loss: 0.1226, validation loss: 0.0317
2024-05-22 17:52:09 [INFO]: Epoch 014 - generator training loss: -0.0316, discriminator training loss: 0.1213, validation loss: 0.0324
2024-05-22 17:52:16 [INFO]: Epoch 015 - generator training loss: -0.0319, discriminator training loss: 0.1196, validation loss: 0.0312
2024-05-22 17:52:23 [INFO]: Epoch 016 - generator training loss: -0.0327, discriminator training loss: 0.1172, validation loss: 0.0305
2024-05-22 17:52:30 [INFO]: Epoch 017 - generator training loss: -0.0320, discriminator training loss: 0.1164, validation loss: 0.0310
2024-05-22 17:52:38 [INFO]: Epoch 018 - generator training loss: -0.0328, discriminator training loss: 0.1181, validation loss: 0.0322
2024-05-22 17:52:45 [INFO]: Epoch 019 - generator training loss: -0.0348, discriminator training loss: 0.1160, validation loss: 0.0303
2024-05-22 17:52:52 [INFO]: Epoch 020 - generator training loss: -0.0340, discriminator training loss: 0.1145, validation loss: 0.0294
2024-05-22 17:52:59 [INFO]: Epoch 021 - generator training loss: -0.0302, discriminator training loss: 0.1158, validation loss: 0.0297
2024-05-22 17:53:07 [INFO]: Epoch 022 - generator training loss: -0.0320, discriminator training loss: 0.1139, validation loss: 0.0287
2024-05-22 17:53:14 [INFO]: Epoch 023 - generator training loss: -0.0305, discriminator training loss: 0.1156, validation loss: 0.0294
2024-05-22 17:53:21 [INFO]: Epoch 024 - generator training loss: -0.0335, discriminator training loss: 0.1132, validation loss: 0.0293
2024-05-22 17:53:29 [INFO]: Epoch 025 - generator training loss: -0.0356, discriminator training loss: 0.1133, validation loss: 0.0283
2024-05-22 17:53:36 [INFO]: Epoch 026 - generator training loss: -0.0337, discriminator training loss: 0.1137, validation loss: 0.0277
2024-05-22 17:53:43 [INFO]: Epoch 027 - generator training loss: -0.0355, discriminator training loss: 0.1121, validation loss: 0.0273
2024-05-22 17:53:50 [INFO]: Epoch 028 - generator training loss: -0.0351, discriminator training loss: 0.1120, validation loss: 0.0271
2024-05-22 17:53:58 [INFO]: Epoch 029 - generator training loss: -0.0360, discriminator training loss: 0.1108, validation loss: 0.0273
2024-05-22 17:54:05 [INFO]: Epoch 030 - generator training loss: -0.0350, discriminator training loss: 0.1134, validation loss: 0.0267
2024-05-22 17:54:12 [INFO]: Epoch 031 - generator training loss: -0.0358, discriminator training loss: 0.1105, validation loss: 0.0262
2024-05-22 17:54:20 [INFO]: Epoch 032 - generator training loss: -0.0374, discriminator training loss: 0.1111, validation loss: 0.0272
2024-05-22 17:54:28 [INFO]: Epoch 033 - generator training loss: -0.0367, discriminator training loss: 0.1131, validation loss: 0.0262
2024-05-22 17:54:35 [INFO]: Epoch 034 - generator training loss: -0.0362, discriminator training loss: 0.1123, validation loss: 0.0254
2024-05-22 17:54:43 [INFO]: Epoch 035 - generator training loss: -0.0374, discriminator training loss: 0.1115, validation loss: 0.0255
2024-05-22 17:54:50 [INFO]: Epoch 036 - generator training loss: -0.0372, discriminator training loss: 0.1112, validation loss: 0.0254
2024-05-22 17:54:57 [INFO]: Epoch 037 - generator training loss: -0.0377, discriminator training loss: 0.1104, validation loss: 0.0249
2024-05-22 17:55:05 [INFO]: Epoch 038 - generator training loss: -0.0377, discriminator training loss: 0.1105, validation loss: 0.0248
2024-05-22 17:55:12 [INFO]: Epoch 039 - generator training loss: -0.0377, discriminator training loss: 0.1099, validation loss: 0.0244
2024-05-22 17:55:19 [INFO]: Epoch 040 - generator training loss: -0.0390, discriminator training loss: 0.1116, validation loss: 0.0244
2024-05-22 17:55:27 [INFO]: Epoch 041 - generator training loss: -0.0369, discriminator training loss: 0.1124, validation loss: 0.0243
2024-05-22 17:55:34 [INFO]: Epoch 042 - generator training loss: -0.0375, discriminator training loss: 0.1090, validation loss: 0.0238
2024-05-22 17:55:41 [INFO]: Epoch 043 - generator training loss: -0.0390, discriminator training loss: 0.1101, validation loss: 0.0240
2024-05-22 17:55:48 [INFO]: Epoch 044 - generator training loss: -0.0383, discriminator training loss: 0.1129, validation loss: 0.0238
2024-05-22 17:55:56 [INFO]: Epoch 045 - generator training loss: -0.0385, discriminator training loss: 0.1106, validation loss: 0.0235
2024-05-22 17:56:03 [INFO]: Epoch 046 - generator training loss: -0.0410, discriminator training loss: 0.1107, validation loss: 0.0235
2024-05-22 17:56:10 [INFO]: Epoch 047 - generator training loss: -0.0377, discriminator training loss: 0.1105, validation loss: 0.0233
2024-05-22 17:56:18 [INFO]: Epoch 048 - generator training loss: -0.0406, discriminator training loss: 0.1101, validation loss: 0.0234
2024-05-22 17:56:25 [INFO]: Epoch 049 - generator training loss: -0.0381, discriminator training loss: 0.1098, validation loss: 0.0231
2024-05-22 17:56:32 [INFO]: Epoch 050 - generator training loss: -0.0394, discriminator training loss: 0.1089, validation loss: 0.0230
2024-05-22 17:56:40 [INFO]: Epoch 051 - generator training loss: -0.0421, discriminator training loss: 0.1090, validation loss: 0.0228
2024-05-22 17:56:47 [INFO]: Epoch 052 - generator training loss: -0.0400, discriminator training loss: 0.1103, validation loss: 0.0228
2024-05-22 17:56:55 [INFO]: Epoch 053 - generator training loss: -0.0388, discriminator training loss: 0.1089, validation loss: 0.0228
2024-05-22 17:57:02 [INFO]: Epoch 054 - generator training loss: -0.0441, discriminator training loss: 0.1093, validation loss: 0.0229
2024-05-22 17:57:09 [INFO]: Epoch 055 - generator training loss: -0.0422, discriminator training loss: 0.1094, validation loss: 0.0224
2024-05-22 17:57:17 [INFO]: Epoch 056 - generator training loss: -0.0426, discriminator training loss: 0.1096, validation loss: 0.0226
2024-05-22 17:57:24 [INFO]: Epoch 057 - generator training loss: -0.0432, discriminator training loss: 0.1081, validation loss: 0.0229
2024-05-22 17:57:31 [INFO]: Epoch 058 - generator training loss: -0.0427, discriminator training loss: 0.1070, validation loss: 0.0223
2024-05-22 17:57:39 [INFO]: Epoch 059 - generator training loss: -0.0413, discriminator training loss: 0.1070, validation loss: 0.0223
2024-05-22 17:57:46 [INFO]: Epoch 060 - generator training loss: -0.0429, discriminator training loss: 0.1082, validation loss: 0.0224
2024-05-22 17:57:53 [INFO]: Epoch 061 - generator training loss: -0.0446, discriminator training loss: 0.1087, validation loss: 0.0219
2024-05-22 17:58:00 [INFO]: Epoch 062 - generator training loss: -0.0417, discriminator training loss: 0.1081, validation loss: 0.0227
2024-05-22 17:58:08 [INFO]: Epoch 063 - generator training loss: -0.0432, discriminator training loss: 0.1069, validation loss: 0.0222
2024-05-22 17:58:15 [INFO]: Epoch 064 - generator training loss: -0.0455, discriminator training loss: 0.1075, validation loss: 0.0221
2024-05-22 17:58:22 [INFO]: Epoch 065 - generator training loss: -0.0404, discriminator training loss: 0.1067, validation loss: 0.0219
2024-05-22 17:58:30 [INFO]: Epoch 066 - generator training loss: -0.0472, discriminator training loss: 0.1090, validation loss: 0.0223
2024-05-22 17:58:37 [INFO]: Epoch 067 - generator training loss: -0.0436, discriminator training loss: 0.1089, validation loss: 0.0219
2024-05-22 17:58:44 [INFO]: Epoch 068 - generator training loss: -0.0416, discriminator training loss: 0.1080, validation loss: 0.0220
2024-05-22 17:58:52 [INFO]: Epoch 069 - generator training loss: -0.0413, discriminator training loss: 0.1081, validation loss: 0.0245
2024-05-22 17:58:59 [INFO]: Epoch 070 - generator training loss: -0.0418, discriminator training loss: 0.1059, validation loss: 0.0241
2024-05-22 17:59:06 [INFO]: Epoch 071 - generator training loss: -0.0419, discriminator training loss: 0.1073, validation loss: 0.0220
2024-05-22 17:59:06 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 17:59:06 [INFO]: Finished training. The best model is from epoch#61.
2024-05-22 17:59:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/USGAN_ettm1/20240522_T175025/USGAN.pypots
2024-05-22 17:59:07 [INFO]: US-GAN on ETTm1: MAE=0.1428, MSE=0.0478
2024-05-22 17:59:07 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-22 17:59:07 [INFO]: Using the given device: cuda:0
2024-05-22 17:59:07 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/BRITS_ettm1/20240522_T175907
2024-05-22 17:59:07 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/BRITS_ettm1/20240522_T175907/tensorboard
2024-05-22 17:59:07 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 17:59:13 [INFO]: Epoch 001 - training loss: 1.3785, validation loss: 0.2891
2024-05-22 17:59:18 [INFO]: Epoch 002 - training loss: 0.9139, validation loss: 0.0825
2024-05-22 17:59:23 [INFO]: Epoch 003 - training loss: 0.7553, validation loss: 0.0522
2024-05-22 17:59:27 [INFO]: Epoch 004 - training loss: 0.6833, validation loss: 0.0422
2024-05-22 17:59:32 [INFO]: Epoch 005 - training loss: 0.6368, validation loss: 0.0390
2024-05-22 17:59:37 [INFO]: Epoch 006 - training loss: 0.6041, validation loss: 0.0383
2024-05-22 17:59:42 [INFO]: Epoch 007 - training loss: 0.5762, validation loss: 0.0345
2024-05-22 17:59:47 [INFO]: Epoch 008 - training loss: 0.5479, validation loss: 0.0331
2024-05-22 17:59:52 [INFO]: Epoch 009 - training loss: 0.5467, validation loss: 0.0320
2024-05-22 17:59:56 [INFO]: Epoch 010 - training loss: 0.5239, validation loss: 0.0335
2024-05-22 18:00:01 [INFO]: Epoch 011 - training loss: 0.5030, validation loss: 0.0324
2024-05-22 18:00:06 [INFO]: Epoch 012 - training loss: 0.4798, validation loss: 0.0309
2024-05-22 18:00:11 [INFO]: Epoch 013 - training loss: 0.4572, validation loss: 0.0297
2024-05-22 18:00:16 [INFO]: Epoch 014 - training loss: 0.4423, validation loss: 0.0273
2024-05-22 18:00:21 [INFO]: Epoch 015 - training loss: 0.4277, validation loss: 0.0267
2024-05-22 18:00:25 [INFO]: Epoch 016 - training loss: 0.4180, validation loss: 0.0252
2024-05-22 18:00:30 [INFO]: Epoch 017 - training loss: 0.4130, validation loss: 0.0247
2024-05-22 18:00:35 [INFO]: Epoch 018 - training loss: 0.4075, validation loss: 0.0236
2024-05-22 18:00:40 [INFO]: Epoch 019 - training loss: 0.4001, validation loss: 0.0229
2024-05-22 18:00:45 [INFO]: Epoch 020 - training loss: 0.3963, validation loss: 0.0224
2024-05-22 18:00:49 [INFO]: Epoch 021 - training loss: 0.3956, validation loss: 0.0226
2024-05-22 18:00:54 [INFO]: Epoch 022 - training loss: 0.3950, validation loss: 0.0226
2024-05-22 18:00:59 [INFO]: Epoch 023 - training loss: 0.4282, validation loss: 0.0232
2024-05-22 18:01:04 [INFO]: Epoch 024 - training loss: 0.4024, validation loss: 0.0234
2024-05-22 18:01:09 [INFO]: Epoch 025 - training loss: 0.3923, validation loss: 0.0229
2024-05-22 18:01:14 [INFO]: Epoch 026 - training loss: 0.3885, validation loss: 0.0222
2024-05-22 18:01:18 [INFO]: Epoch 027 - training loss: 0.3825, validation loss: 0.0218
2024-05-22 18:01:23 [INFO]: Epoch 028 - training loss: 0.3828, validation loss: 0.0225
2024-05-22 18:01:28 [INFO]: Epoch 029 - training loss: 0.3847, validation loss: 0.0220
2024-05-22 18:01:33 [INFO]: Epoch 030 - training loss: 0.3818, validation loss: 0.0219
2024-05-22 18:01:38 [INFO]: Epoch 031 - training loss: 0.3908, validation loss: 0.0226
2024-05-22 18:01:43 [INFO]: Epoch 032 - training loss: 0.3834, validation loss: 0.0217
2024-05-22 18:01:48 [INFO]: Epoch 033 - training loss: 0.3974, validation loss: 0.0221
2024-05-22 18:01:52 [INFO]: Epoch 034 - training loss: 0.3861, validation loss: 0.0225
2024-05-22 18:01:57 [INFO]: Epoch 035 - training loss: 0.3906, validation loss: 0.0227
2024-05-22 18:02:02 [INFO]: Epoch 036 - training loss: 0.3778, validation loss: 0.0216
2024-05-22 18:02:07 [INFO]: Epoch 037 - training loss: 0.3939, validation loss: 0.0218
2024-05-22 18:02:12 [INFO]: Epoch 038 - training loss: 0.3771, validation loss: 0.0220
2024-05-22 18:02:17 [INFO]: Epoch 039 - training loss: 0.3814, validation loss: 0.0223
2024-05-22 18:02:21 [INFO]: Epoch 040 - training loss: 0.3805, validation loss: 0.0225
2024-05-22 18:02:26 [INFO]: Epoch 041 - training loss: 0.3809, validation loss: 0.0219
2024-05-22 18:02:31 [INFO]: Epoch 042 - training loss: 0.3728, validation loss: 0.0220
2024-05-22 18:02:36 [INFO]: Epoch 043 - training loss: 0.3793, validation loss: 0.0220
2024-05-22 18:02:41 [INFO]: Epoch 044 - training loss: 0.3781, validation loss: 0.0223
2024-05-22 18:02:45 [INFO]: Epoch 045 - training loss: 0.3743, validation loss: 0.0221
2024-05-22 18:02:50 [INFO]: Epoch 046 - training loss: 0.3842, validation loss: 0.0219
2024-05-22 18:02:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:02:50 [INFO]: Finished training. The best model is from epoch#36.
2024-05-22 18:02:50 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/BRITS_ettm1/20240522_T175907/BRITS.pypots
2024-05-22 18:02:51 [INFO]: BRITS on ETTm1: MAE=0.1266, MSE=0.0488
2024-05-22 18:02:51 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-22 18:02:51 [INFO]: Using the given device: cuda:0
2024-05-22 18:02:51 [INFO]: Model files will be saved to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251
2024-05-22 18:02:51 [INFO]: Tensorboard file will be saved to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/tensorboard
2024-05-22 18:02:51 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 18:02:52 [INFO]: Epoch 001 - training loss: 1.3964, validation loss: 1.2793
2024-05-22 18:02:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch1_loss1.2793384492397308.pypots
2024-05-22 18:02:52 [INFO]: Epoch 002 - training loss: 1.0472, validation loss: 1.1568
2024-05-22 18:02:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch2_loss1.1568193435668945.pypots
2024-05-22 18:02:52 [INFO]: Epoch 003 - training loss: 0.9792, validation loss: 1.0925
2024-05-22 18:02:52 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch3_loss1.092461720108986.pypots
2024-05-22 18:02:53 [INFO]: Epoch 004 - training loss: 0.9918, validation loss: 1.0634
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch4_loss1.0634127855300903.pypots
2024-05-22 18:02:53 [INFO]: Epoch 005 - training loss: 0.9337, validation loss: 1.0513
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch5_loss1.051250770688057.pypots
2024-05-22 18:02:53 [INFO]: Epoch 006 - training loss: 0.9196, validation loss: 1.0390
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch6_loss1.038961797952652.pypots
2024-05-22 18:02:53 [INFO]: Epoch 007 - training loss: 0.9021, validation loss: 1.0229
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch7_loss1.0229221284389496.pypots
2024-05-22 18:02:53 [INFO]: Epoch 008 - training loss: 0.8985, validation loss: 1.0171
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch8_loss1.0170598030090332.pypots
2024-05-22 18:02:53 [INFO]: Epoch 009 - training loss: 0.8942, validation loss: 1.0179
2024-05-22 18:02:53 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch9_loss1.0179326385259628.pypots
2024-05-22 18:02:54 [INFO]: Epoch 010 - training loss: 0.8810, validation loss: 1.0129
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch10_loss1.0128736943006516.pypots
2024-05-22 18:02:54 [INFO]: Epoch 011 - training loss: 0.8967, validation loss: 1.0088
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch11_loss1.008817508816719.pypots
2024-05-22 18:02:54 [INFO]: Epoch 012 - training loss: 0.8896, validation loss: 1.0066
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch12_loss1.0065736770629883.pypots
2024-05-22 18:02:54 [INFO]: Epoch 013 - training loss: 0.8737, validation loss: 1.0040
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch13_loss1.0040308982133865.pypots
2024-05-22 18:02:54 [INFO]: Epoch 014 - training loss: 0.8542, validation loss: 0.9944
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch14_loss0.994424894452095.pypots
2024-05-22 18:02:54 [INFO]: Epoch 015 - training loss: 0.8676, validation loss: 0.9877
2024-05-22 18:02:54 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch15_loss0.9876838326454163.pypots
2024-05-22 18:02:55 [INFO]: Epoch 016 - training loss: 0.8377, validation loss: 0.9827
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch16_loss0.9827498197555542.pypots
2024-05-22 18:02:55 [INFO]: Epoch 017 - training loss: 0.8466, validation loss: 0.9752
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch17_loss0.9751756340265274.pypots
2024-05-22 18:02:55 [INFO]: Epoch 018 - training loss: 0.8627, validation loss: 0.9720
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch18_loss0.9719718992710114.pypots
2024-05-22 18:02:55 [INFO]: Epoch 019 - training loss: 0.9003, validation loss: 0.9705
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch19_loss0.970493882894516.pypots
2024-05-22 18:02:55 [INFO]: Epoch 020 - training loss: 0.8507, validation loss: 0.9669
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch20_loss0.9669203162193298.pypots
2024-05-22 18:02:55 [INFO]: Epoch 021 - training loss: 0.8648, validation loss: 0.9625
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch21_loss0.9624585658311844.pypots
2024-05-22 18:02:55 [INFO]: Epoch 022 - training loss: 0.8506, validation loss: 0.9588
2024-05-22 18:02:55 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch22_loss0.9587675631046295.pypots
2024-05-22 18:02:56 [INFO]: Epoch 023 - training loss: 0.8477, validation loss: 0.9548
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch23_loss0.9548321068286896.pypots
2024-05-22 18:02:56 [INFO]: Epoch 024 - training loss: 0.8328, validation loss: 0.9503
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch24_loss0.9503387063741684.pypots
2024-05-22 18:02:56 [INFO]: Epoch 025 - training loss: 0.8406, validation loss: 0.9486
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch25_loss0.9485776424407959.pypots
2024-05-22 18:02:56 [INFO]: Epoch 026 - training loss: 0.8456, validation loss: 0.9469
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch26_loss0.9468770325183868.pypots
2024-05-22 18:02:56 [INFO]: Epoch 027 - training loss: 0.7962, validation loss: 0.9422
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch27_loss0.9421681314706802.pypots
2024-05-22 18:02:56 [INFO]: Epoch 028 - training loss: 0.8018, validation loss: 0.9405
2024-05-22 18:02:56 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch28_loss0.9405031800270081.pypots
2024-05-22 18:02:57 [INFO]: Epoch 029 - training loss: 0.7959, validation loss: 0.9373
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch29_loss0.9373379200696945.pypots
2024-05-22 18:02:57 [INFO]: Epoch 030 - training loss: 0.8224, validation loss: 0.9349
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch30_loss0.9348655492067337.pypots
2024-05-22 18:02:57 [INFO]: Epoch 031 - training loss: 0.8167, validation loss: 0.9311
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch31_loss0.9311223775148392.pypots
2024-05-22 18:02:57 [INFO]: Epoch 032 - training loss: 0.8131, validation loss: 0.9285
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch32_loss0.9284534454345703.pypots
2024-05-22 18:02:57 [INFO]: Epoch 033 - training loss: 0.8199, validation loss: 0.9281
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch33_loss0.9281466007232666.pypots
2024-05-22 18:02:57 [INFO]: Epoch 034 - training loss: 0.8252, validation loss: 0.9267
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch34_loss0.9267484098672867.pypots
2024-05-22 18:02:57 [INFO]: Epoch 035 - training loss: 0.8088, validation loss: 0.9246
2024-05-22 18:02:57 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch35_loss0.9246340841054916.pypots
2024-05-22 18:02:58 [INFO]: Epoch 036 - training loss: 0.8191, validation loss: 0.9209
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch36_loss0.9209396988153458.pypots
2024-05-22 18:02:58 [INFO]: Epoch 037 - training loss: 0.7959, validation loss: 0.9188
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch37_loss0.918819785118103.pypots
2024-05-22 18:02:58 [INFO]: Epoch 038 - training loss: 0.7895, validation loss: 0.9156
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch38_loss0.915579542517662.pypots
2024-05-22 18:02:58 [INFO]: Epoch 039 - training loss: 0.7936, validation loss: 0.9132
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch39_loss0.9132056832313538.pypots
2024-05-22 18:02:58 [INFO]: Epoch 040 - training loss: 0.7963, validation loss: 0.9112
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch40_loss0.9111616164445877.pypots
2024-05-22 18:02:58 [INFO]: Epoch 041 - training loss: 0.8076, validation loss: 0.9094
2024-05-22 18:02:58 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch41_loss0.9093644171953201.pypots
2024-05-22 18:02:59 [INFO]: Epoch 042 - training loss: 0.7902, validation loss: 0.9059
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch42_loss0.9059171229600906.pypots
2024-05-22 18:02:59 [INFO]: Epoch 043 - training loss: 0.7817, validation loss: 0.9026
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch43_loss0.90263232588768.pypots
2024-05-22 18:02:59 [INFO]: Epoch 044 - training loss: 0.7851, validation loss: 0.9005
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch44_loss0.9005007892847061.pypots
2024-05-22 18:02:59 [INFO]: Epoch 045 - training loss: 0.7980, validation loss: 0.8976
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch45_loss0.89757439494133.pypots
2024-05-22 18:02:59 [INFO]: Epoch 046 - training loss: 0.7833, validation loss: 0.8963
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch46_loss0.8963212370872498.pypots
2024-05-22 18:02:59 [INFO]: Epoch 047 - training loss: 0.8020, validation loss: 0.8942
2024-05-22 18:02:59 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch47_loss0.8941786885261536.pypots
2024-05-22 18:03:00 [INFO]: Epoch 048 - training loss: 0.8067, validation loss: 0.8925
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch48_loss0.8924909234046936.pypots
2024-05-22 18:03:00 [INFO]: Epoch 049 - training loss: 0.8072, validation loss: 0.8893
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch49_loss0.8892561197280884.pypots
2024-05-22 18:03:00 [INFO]: Epoch 050 - training loss: 0.7912, validation loss: 0.8872
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch50_loss0.8872236013412476.pypots
2024-05-22 18:03:00 [INFO]: Epoch 051 - training loss: 0.7880, validation loss: 0.8845
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch51_loss0.8844594806432724.pypots
2024-05-22 18:03:00 [INFO]: Epoch 052 - training loss: 0.7883, validation loss: 0.8826
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch52_loss0.8826005905866623.pypots
2024-05-22 18:03:00 [INFO]: Epoch 053 - training loss: 0.7883, validation loss: 0.8799
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch53_loss0.8799191862344742.pypots
2024-05-22 18:03:00 [INFO]: Epoch 054 - training loss: 0.7720, validation loss: 0.8783
2024-05-22 18:03:00 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch54_loss0.8782859444618225.pypots
2024-05-22 18:03:01 [INFO]: Epoch 055 - training loss: 0.7909, validation loss: 0.8759
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch55_loss0.8758831322193146.pypots
2024-05-22 18:03:01 [INFO]: Epoch 056 - training loss: 0.8016, validation loss: 0.8747
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch56_loss0.8746977299451828.pypots
2024-05-22 18:03:01 [INFO]: Epoch 057 - training loss: 0.7810, validation loss: 0.8713
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch57_loss0.8712724447250366.pypots
2024-05-22 18:03:01 [INFO]: Epoch 058 - training loss: 0.7869, validation loss: 0.8701
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch58_loss0.8700883388519287.pypots
2024-05-22 18:03:01 [INFO]: Epoch 059 - training loss: 0.8251, validation loss: 0.8679
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch59_loss0.8678760081529617.pypots
2024-05-22 18:03:01 [INFO]: Epoch 060 - training loss: 0.7952, validation loss: 0.8655
2024-05-22 18:03:01 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch60_loss0.8655350804328918.pypots
2024-05-22 18:03:02 [INFO]: Epoch 061 - training loss: 0.8231, validation loss: 0.8617
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch61_loss0.861659049987793.pypots
2024-05-22 18:03:02 [INFO]: Epoch 062 - training loss: 0.7893, validation loss: 0.8603
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch62_loss0.8602764308452606.pypots
2024-05-22 18:03:02 [INFO]: Epoch 063 - training loss: 0.7844, validation loss: 0.8587
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch63_loss0.8586636930704117.pypots
2024-05-22 18:03:02 [INFO]: Epoch 064 - training loss: 0.7817, validation loss: 0.8579
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch64_loss0.8578683435916901.pypots
2024-05-22 18:03:02 [INFO]: Epoch 065 - training loss: 0.7841, validation loss: 0.8553
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch65_loss0.8552913218736649.pypots
2024-05-22 18:03:02 [INFO]: Epoch 066 - training loss: 0.7864, validation loss: 0.8538
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch66_loss0.8537709712982178.pypots
2024-05-22 18:03:02 [INFO]: Epoch 067 - training loss: 0.7845, validation loss: 0.8520
2024-05-22 18:03:02 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch67_loss0.8520137071609497.pypots
2024-05-22 18:03:03 [INFO]: Epoch 068 - training loss: 0.7692, validation loss: 0.8508
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch68_loss0.8508255183696747.pypots
2024-05-22 18:03:03 [INFO]: Epoch 069 - training loss: 0.7687, validation loss: 0.8518
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch69_loss0.8518398702144623.pypots
2024-05-22 18:03:03 [INFO]: Epoch 070 - training loss: 0.7706, validation loss: 0.8479
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch70_loss0.8478889614343643.pypots
2024-05-22 18:03:03 [INFO]: Epoch 071 - training loss: 0.8071, validation loss: 0.8482
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch71_loss0.8482387214899063.pypots
2024-05-22 18:03:03 [INFO]: Epoch 072 - training loss: 0.7851, validation loss: 0.8451
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch72_loss0.8450991362333298.pypots
2024-05-22 18:03:03 [INFO]: Epoch 073 - training loss: 0.7900, validation loss: 0.8447
2024-05-22 18:03:03 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch73_loss0.8447036892175674.pypots
2024-05-22 18:03:04 [INFO]: Epoch 074 - training loss: 0.7927, validation loss: 0.8442
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch74_loss0.8441648632287979.pypots
2024-05-22 18:03:04 [INFO]: Epoch 075 - training loss: 0.7743, validation loss: 0.8411
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch75_loss0.8411391079425812.pypots
2024-05-22 18:03:04 [INFO]: Epoch 076 - training loss: 0.7911, validation loss: 0.8411
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch76_loss0.8410779535770416.pypots
2024-05-22 18:03:04 [INFO]: Epoch 077 - training loss: 0.7734, validation loss: 0.8412
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch77_loss0.8411991894245148.pypots
2024-05-22 18:03:04 [INFO]: Epoch 078 - training loss: 0.7650, validation loss: 0.8401
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch78_loss0.8401491194963455.pypots
2024-05-22 18:03:04 [INFO]: Epoch 079 - training loss: 0.8209, validation loss: 0.8390
2024-05-22 18:03:04 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch79_loss0.8389571309089661.pypots
2024-05-22 18:03:04 [INFO]: Epoch 080 - training loss: 0.7804, validation loss: 0.8374
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch80_loss0.837436243891716.pypots
2024-05-22 18:03:05 [INFO]: Epoch 081 - training loss: 0.7913, validation loss: 0.8391
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch81_loss0.8390636742115021.pypots
2024-05-22 18:03:05 [INFO]: Epoch 082 - training loss: 0.7833, validation loss: 0.8378
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch82_loss0.8377678841352463.pypots
2024-05-22 18:03:05 [INFO]: Epoch 083 - training loss: 0.7633, validation loss: 0.8381
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch83_loss0.8381290882825851.pypots
2024-05-22 18:03:05 [INFO]: Epoch 084 - training loss: 0.7653, validation loss: 0.8372
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch84_loss0.8371588587760925.pypots
2024-05-22 18:03:05 [INFO]: Epoch 085 - training loss: 0.7467, validation loss: 0.8331
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch85_loss0.8330999910831451.pypots
2024-05-22 18:03:05 [INFO]: Epoch 086 - training loss: 0.7870, validation loss: 0.8369
2024-05-22 18:03:05 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch86_loss0.8369018137454987.pypots
2024-05-22 18:03:06 [INFO]: Epoch 087 - training loss: 0.7842, validation loss: 0.8340
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch87_loss0.8340323269367218.pypots
2024-05-22 18:03:06 [INFO]: Epoch 088 - training loss: 0.7621, validation loss: 0.8334
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch88_loss0.8333510011434555.pypots
2024-05-22 18:03:06 [INFO]: Epoch 089 - training loss: 0.7801, validation loss: 0.8330
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch89_loss0.8329974263906479.pypots
2024-05-22 18:03:06 [INFO]: Epoch 090 - training loss: 0.7513, validation loss: 0.8349
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch90_loss0.834942638874054.pypots
2024-05-22 18:03:06 [INFO]: Epoch 091 - training loss: 0.7687, validation loss: 0.8317
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch91_loss0.8316801488399506.pypots
2024-05-22 18:03:06 [INFO]: Epoch 092 - training loss: 0.7623, validation loss: 0.8340
2024-05-22 18:03:06 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch92_loss0.8339963853359222.pypots
2024-05-22 18:03:07 [INFO]: Epoch 093 - training loss: 0.7628, validation loss: 0.8317
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch93_loss0.8316566497087479.pypots
2024-05-22 18:03:07 [INFO]: Epoch 094 - training loss: 0.7767, validation loss: 0.8350
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch94_loss0.8350439220666885.pypots
2024-05-22 18:03:07 [INFO]: Epoch 095 - training loss: 0.7839, validation loss: 0.8347
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch95_loss0.8346842676401138.pypots
2024-05-22 18:03:07 [INFO]: Epoch 096 - training loss: 0.7769, validation loss: 0.8324
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch96_loss0.8323672115802765.pypots
2024-05-22 18:03:07 [INFO]: Epoch 097 - training loss: 0.7717, validation loss: 0.8314
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch97_loss0.8313558846712112.pypots
2024-05-22 18:03:07 [INFO]: Epoch 098 - training loss: 0.7832, validation loss: 0.8331
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch98_loss0.8330804407596588.pypots
2024-05-22 18:03:07 [INFO]: Epoch 099 - training loss: 0.7635, validation loss: 0.8339
2024-05-22 18:03:07 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch99_loss0.8338752686977386.pypots
2024-05-22 18:03:08 [INFO]: Epoch 100 - training loss: 0.7645, validation loss: 0.8316
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch100_loss0.8315593898296356.pypots
2024-05-22 18:03:08 [INFO]: Epoch 101 - training loss: 0.8123, validation loss: 0.8330
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch101_loss0.8329792469739914.pypots
2024-05-22 18:03:08 [INFO]: Epoch 102 - training loss: 0.7625, validation loss: 0.8370
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch102_loss0.8369570672512054.pypots
2024-05-22 18:03:08 [INFO]: Epoch 103 - training loss: 0.7779, validation loss: 0.8311
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch103_loss0.8310694992542267.pypots
2024-05-22 18:03:08 [INFO]: Epoch 104 - training loss: 0.7945, validation loss: 0.8307
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch104_loss0.8307459950447083.pypots
2024-05-22 18:03:08 [INFO]: Epoch 105 - training loss: 0.7772, validation loss: 0.8321
2024-05-22 18:03:08 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch105_loss0.8320871591567993.pypots
2024-05-22 18:03:09 [INFO]: Epoch 106 - training loss: 0.7768, validation loss: 0.8294
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch106_loss0.8293869197368622.pypots
2024-05-22 18:03:09 [INFO]: Epoch 107 - training loss: 0.7719, validation loss: 0.8321
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch107_loss0.8321496248245239.pypots
2024-05-22 18:03:09 [INFO]: Epoch 108 - training loss: 0.7633, validation loss: 0.8324
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch108_loss0.8324188590049744.pypots
2024-05-22 18:03:09 [INFO]: Epoch 109 - training loss: 0.7547, validation loss: 0.8303
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch109_loss0.8302789330482483.pypots
2024-05-22 18:03:09 [INFO]: Epoch 110 - training loss: 0.7617, validation loss: 0.8310
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch110_loss0.83102947473526.pypots
2024-05-22 18:03:09 [INFO]: Epoch 111 - training loss: 0.7815, validation loss: 0.8309
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch111_loss0.8308986574411392.pypots
2024-05-22 18:03:09 [INFO]: Epoch 112 - training loss: 0.7476, validation loss: 0.8308
2024-05-22 18:03:09 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch112_loss0.8308318108320236.pypots
2024-05-22 18:03:10 [INFO]: Epoch 113 - training loss: 0.7656, validation loss: 0.8313
2024-05-22 18:03:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch113_loss0.8313219547271729.pypots
2024-05-22 18:03:10 [INFO]: Epoch 114 - training loss: 0.7674, validation loss: 0.8315
2024-05-22 18:03:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch114_loss0.8314653486013412.pypots
2024-05-22 18:03:10 [INFO]: Epoch 115 - training loss: 0.7827, validation loss: 0.8320
2024-05-22 18:03:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch115_loss0.8320171684026718.pypots
2024-05-22 18:03:10 [INFO]: Epoch 116 - training loss: 0.7820, validation loss: 0.8294
2024-05-22 18:03:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN_epoch116_loss0.8293968737125397.pypots
2024-05-22 18:03:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 18:03:10 [INFO]: Finished training. The best model is from epoch#106.
2024-05-22 18:03:10 [INFO]: Saved the model to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/20240522_T180251/MRNN.pypots
2024-05-22 18:03:10 [INFO]: MRNN on ETTm1: MAE=0.6856, MSE=1.1499
2024-05-22 18:03:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-22 18:03:10 [INFO]: Using the given device: cpu
2024-05-22 18:03:10 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 18:03:10 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-22 18:03:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-22 18:03:10 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 18:03:10 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-22 18:03:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-22 18:03:10 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 18:03:10 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-22 18:03:10 [INFO]: Successfully saved to overlay_minibatchmasking_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-22 18:03:10 [INFO]: 
SAITS on data/ettm1: MAE=0.165±0.013092507264993301, MSE=0.052±0.007791978209816723
Transformer on data/ettm1: MAE=0.132±0.00817686568753541, MSE=0.034±0.0037329675504087735
TimesNet on data/ettm1: MAE=0.110±0.005460165094818043, MSE=0.026±0.002511234677271123
CSDI on data/ettm1: MAE=0.203±0.04877181026658661, MSE=0.509±0.5688268544058841
GPVAE on data/ettm1: MAE=0.293±0.011846422461021237, MSE=0.177±0.00947786506015035
USGAN on data/ettm1: MAE=0.142±0.002962989687148635, MSE=0.049±0.0020946552732776335
BRITS on data/ettm1: MAE=0.127±0.0029531990141767306, MSE=0.048±0.0024240762396200476
MRNN on data/ettm1: MAE=0.640±0.049080872209877634, MSE=1.072±0.0881024005821012
LOCF on data/ettm1: MAE=0.135±0.0, MSE=0.072±0.0
Median on data/ettm1: MAE=0.657±0.0, MSE=0.825±0.0
Mean on data/ettm1: MAE=0.663±0.0, MSE=0.809±0.0

