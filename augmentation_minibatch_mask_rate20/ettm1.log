2024-05-25 01:15:54 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 01:15:54 [INFO]: Using the given device: cuda:0
2024-05-25 01:15:54 [INFO]: Model files will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T011554
2024-05-25 01:15:54 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T011554/tensorboard
2024-05-25 01:15:55 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 01:15:56 [INFO]: Epoch 001 - training loss: 1.2456, validation loss: 0.3202
2024-05-25 01:15:57 [INFO]: Epoch 002 - training loss: 0.9286, validation loss: 0.1472
2024-05-25 01:15:57 [INFO]: Epoch 003 - training loss: 0.8526, validation loss: 0.1149
2024-05-25 01:15:58 [INFO]: Epoch 004 - training loss: 0.7768, validation loss: 0.1115
2024-05-25 01:15:58 [INFO]: Epoch 005 - training loss: 0.7439, validation loss: 0.0864
2024-05-25 01:15:59 [INFO]: Epoch 006 - training loss: 0.6996, validation loss: 0.0798
2024-05-25 01:15:59 [INFO]: Epoch 007 - training loss: 0.6945, validation loss: 0.1046
2024-05-25 01:16:00 [INFO]: Epoch 008 - training loss: 0.6751, validation loss: 0.0817
2024-05-25 01:16:00 [INFO]: Epoch 009 - training loss: 0.6503, validation loss: 0.0608
2024-05-25 01:16:01 [INFO]: Epoch 010 - training loss: 0.6329, validation loss: 0.0708
2024-05-25 01:16:01 [INFO]: Epoch 011 - training loss: 0.6257, validation loss: 0.0829
2024-05-25 01:16:02 [INFO]: Epoch 012 - training loss: 0.6170, validation loss: 0.0816
2024-05-25 01:16:02 [INFO]: Epoch 013 - training loss: 0.6250, validation loss: 0.0732
2024-05-25 01:16:03 [INFO]: Epoch 014 - training loss: 0.5890, validation loss: 0.0624
2024-05-25 01:16:03 [INFO]: Epoch 015 - training loss: 0.5865, validation loss: 0.0652
2024-05-25 01:16:04 [INFO]: Epoch 016 - training loss: 0.5814, validation loss: 0.0694
2024-05-25 01:16:04 [INFO]: Epoch 017 - training loss: 0.5878, validation loss: 0.0633
2024-05-25 01:16:05 [INFO]: Epoch 018 - training loss: 0.5599, validation loss: 0.0556
2024-05-25 01:16:05 [INFO]: Epoch 019 - training loss: 0.5591, validation loss: 0.0782
2024-05-25 01:16:06 [INFO]: Epoch 020 - training loss: 0.5646, validation loss: 0.0616
2024-05-25 01:16:06 [INFO]: Epoch 021 - training loss: 0.5514, validation loss: 0.0477
2024-05-25 01:16:07 [INFO]: Epoch 022 - training loss: 0.5337, validation loss: 0.0469
2024-05-25 01:16:07 [INFO]: Epoch 023 - training loss: 0.5364, validation loss: 0.1586
2024-05-25 01:16:08 [INFO]: Epoch 024 - training loss: 0.5631, validation loss: 0.0473
2024-05-25 01:16:08 [INFO]: Epoch 025 - training loss: 0.5354, validation loss: 0.0660
2024-05-25 01:16:09 [INFO]: Epoch 026 - training loss: 0.5172, validation loss: 0.0419
2024-05-25 01:16:09 [INFO]: Epoch 027 - training loss: 0.5168, validation loss: 0.0521
2024-05-25 01:16:10 [INFO]: Epoch 028 - training loss: 0.5123, validation loss: 0.0501
2024-05-25 01:16:10 [INFO]: Epoch 029 - training loss: 0.5137, validation loss: 0.0463
2024-05-25 01:16:11 [INFO]: Epoch 030 - training loss: 0.5018, validation loss: 0.0490
2024-05-25 01:16:11 [INFO]: Epoch 031 - training loss: 0.4925, validation loss: 0.0422
2024-05-25 01:16:12 [INFO]: Epoch 032 - training loss: 0.4931, validation loss: 0.0534
2024-05-25 01:16:12 [INFO]: Epoch 033 - training loss: 0.4998, validation loss: 0.0454
2024-05-25 01:16:13 [INFO]: Epoch 034 - training loss: 0.4998, validation loss: 0.0433
2024-05-25 01:16:13 [INFO]: Epoch 035 - training loss: 0.4833, validation loss: 0.0547
2024-05-25 01:16:14 [INFO]: Epoch 036 - training loss: 0.5068, validation loss: 0.0698
2024-05-25 01:16:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:16:14 [INFO]: Finished training. The best model is from epoch#26.
2024-05-25 01:16:14 [INFO]: Saved the model to augmentation_saved_results/round_0/SAITS_ettm1/20240525_T011554/SAITS.pypots
2024-05-25 01:16:14 [INFO]: SAITS on ETTm1: MAE=0.1662, MSE=0.0543
2024-05-25 01:16:14 [INFO]: Successfully saved to augmentation_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-25 01:16:14 [INFO]: Using the given device: cuda:0
2024-05-25 01:16:14 [INFO]: Model files will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T011614
2024-05-25 01:16:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T011614/tensorboard
2024-05-25 01:16:14 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 01:16:14 [INFO]: Epoch 001 - training loss: 1.1858, validation loss: 0.3722
2024-05-25 01:16:14 [INFO]: Epoch 002 - training loss: 0.7397, validation loss: 0.1770
2024-05-25 01:16:15 [INFO]: Epoch 003 - training loss: 0.6063, validation loss: 0.1323
2024-05-25 01:16:15 [INFO]: Epoch 004 - training loss: 0.5431, validation loss: 0.0973
2024-05-25 01:16:15 [INFO]: Epoch 005 - training loss: 0.5007, validation loss: 0.0852
2024-05-25 01:16:15 [INFO]: Epoch 006 - training loss: 0.4782, validation loss: 0.0791
2024-05-25 01:16:15 [INFO]: Epoch 007 - training loss: 0.4556, validation loss: 0.0745
2024-05-25 01:16:16 [INFO]: Epoch 008 - training loss: 0.4294, validation loss: 0.0706
2024-05-25 01:16:16 [INFO]: Epoch 009 - training loss: 0.4222, validation loss: 0.0802
2024-05-25 01:16:16 [INFO]: Epoch 010 - training loss: 0.4184, validation loss: 0.0709
2024-05-25 01:16:16 [INFO]: Epoch 011 - training loss: 0.4091, validation loss: 0.0790
2024-05-25 01:16:16 [INFO]: Epoch 012 - training loss: 0.3988, validation loss: 0.0581
2024-05-25 01:16:17 [INFO]: Epoch 013 - training loss: 0.3764, validation loss: 0.0505
2024-05-25 01:16:17 [INFO]: Epoch 014 - training loss: 0.3760, validation loss: 0.0548
2024-05-25 01:16:17 [INFO]: Epoch 015 - training loss: 0.3670, validation loss: 0.0591
2024-05-25 01:16:17 [INFO]: Epoch 016 - training loss: 0.3624, validation loss: 0.0485
2024-05-25 01:16:17 [INFO]: Epoch 017 - training loss: 0.3591, validation loss: 0.0536
2024-05-25 01:16:18 [INFO]: Epoch 018 - training loss: 0.3520, validation loss: 0.0498
2024-05-25 01:16:18 [INFO]: Epoch 019 - training loss: 0.3408, validation loss: 0.0474
2024-05-25 01:16:18 [INFO]: Epoch 020 - training loss: 0.3359, validation loss: 0.0431
2024-05-25 01:16:18 [INFO]: Epoch 021 - training loss: 0.3324, validation loss: 0.0458
2024-05-25 01:16:19 [INFO]: Epoch 022 - training loss: 0.3371, validation loss: 0.0427
2024-05-25 01:16:19 [INFO]: Epoch 023 - training loss: 0.3311, validation loss: 0.0462
2024-05-25 01:16:19 [INFO]: Epoch 024 - training loss: 0.3247, validation loss: 0.0395
2024-05-25 01:16:19 [INFO]: Epoch 025 - training loss: 0.3159, validation loss: 0.0470
2024-05-25 01:16:19 [INFO]: Epoch 026 - training loss: 0.3181, validation loss: 0.0457
2024-05-25 01:16:20 [INFO]: Epoch 027 - training loss: 0.3078, validation loss: 0.0410
2024-05-25 01:16:20 [INFO]: Epoch 028 - training loss: 0.3045, validation loss: 0.0387
2024-05-25 01:16:20 [INFO]: Epoch 029 - training loss: 0.3078, validation loss: 0.0400
2024-05-25 01:16:20 [INFO]: Epoch 030 - training loss: 0.3013, validation loss: 0.0455
2024-05-25 01:16:20 [INFO]: Epoch 031 - training loss: 0.3028, validation loss: 0.0414
2024-05-25 01:16:21 [INFO]: Epoch 032 - training loss: 0.2945, validation loss: 0.0379
2024-05-25 01:16:21 [INFO]: Epoch 033 - training loss: 0.2893, validation loss: 0.0368
2024-05-25 01:16:21 [INFO]: Epoch 034 - training loss: 0.2876, validation loss: 0.0381
2024-05-25 01:16:21 [INFO]: Epoch 035 - training loss: 0.2877, validation loss: 0.0346
2024-05-25 01:16:22 [INFO]: Epoch 036 - training loss: 0.2788, validation loss: 0.0356
2024-05-25 01:16:22 [INFO]: Epoch 037 - training loss: 0.2791, validation loss: 0.0337
2024-05-25 01:16:22 [INFO]: Epoch 038 - training loss: 0.2784, validation loss: 0.0348
2024-05-25 01:16:22 [INFO]: Epoch 039 - training loss: 0.2759, validation loss: 0.0340
2024-05-25 01:16:22 [INFO]: Epoch 040 - training loss: 0.2718, validation loss: 0.0339
2024-05-25 01:16:23 [INFO]: Epoch 041 - training loss: 0.2718, validation loss: 0.0344
2024-05-25 01:16:23 [INFO]: Epoch 042 - training loss: 0.2649, validation loss: 0.0342
2024-05-25 01:16:23 [INFO]: Epoch 043 - training loss: 0.2628, validation loss: 0.0344
2024-05-25 01:16:23 [INFO]: Epoch 044 - training loss: 0.2659, validation loss: 0.0387
2024-05-25 01:16:23 [INFO]: Epoch 045 - training loss: 0.2659, validation loss: 0.0306
2024-05-25 01:16:24 [INFO]: Epoch 046 - training loss: 0.2585, validation loss: 0.0337
2024-05-25 01:16:24 [INFO]: Epoch 047 - training loss: 0.2700, validation loss: 0.0398
2024-05-25 01:16:24 [INFO]: Epoch 048 - training loss: 0.2725, validation loss: 0.0341
2024-05-25 01:16:24 [INFO]: Epoch 049 - training loss: 0.2520, validation loss: 0.0319
2024-05-25 01:16:25 [INFO]: Epoch 050 - training loss: 0.2501, validation loss: 0.0320
2024-05-25 01:16:25 [INFO]: Epoch 051 - training loss: 0.2477, validation loss: 0.0315
2024-05-25 01:16:25 [INFO]: Epoch 052 - training loss: 0.2442, validation loss: 0.0282
2024-05-25 01:16:25 [INFO]: Epoch 053 - training loss: 0.2474, validation loss: 0.0300
2024-05-25 01:16:25 [INFO]: Epoch 054 - training loss: 0.2531, validation loss: 0.0338
2024-05-25 01:16:26 [INFO]: Epoch 055 - training loss: 0.2436, validation loss: 0.0362
2024-05-25 01:16:26 [INFO]: Epoch 056 - training loss: 0.2603, validation loss: 0.0348
2024-05-25 01:16:26 [INFO]: Epoch 057 - training loss: 0.2377, validation loss: 0.0312
2024-05-25 01:16:26 [INFO]: Epoch 058 - training loss: 0.2399, validation loss: 0.0312
2024-05-25 01:16:26 [INFO]: Epoch 059 - training loss: 0.2441, validation loss: 0.0293
2024-05-25 01:16:27 [INFO]: Epoch 060 - training loss: 0.2477, validation loss: 0.0282
2024-05-25 01:16:27 [INFO]: Epoch 061 - training loss: 0.2406, validation loss: 0.0317
2024-05-25 01:16:27 [INFO]: Epoch 062 - training loss: 0.2411, validation loss: 0.0310
2024-05-25 01:16:27 [INFO]: Epoch 063 - training loss: 0.2367, validation loss: 0.0308
2024-05-25 01:16:28 [INFO]: Epoch 064 - training loss: 0.2331, validation loss: 0.0290
2024-05-25 01:16:28 [INFO]: Epoch 065 - training loss: 0.2313, validation loss: 0.0277
2024-05-25 01:16:28 [INFO]: Epoch 066 - training loss: 0.2287, validation loss: 0.0270
2024-05-25 01:16:28 [INFO]: Epoch 067 - training loss: 0.2283, validation loss: 0.0282
2024-05-25 01:16:28 [INFO]: Epoch 068 - training loss: 0.2292, validation loss: 0.0289
2024-05-25 01:16:29 [INFO]: Epoch 069 - training loss: 0.2266, validation loss: 0.0273
2024-05-25 01:16:29 [INFO]: Epoch 070 - training loss: 0.2268, validation loss: 0.0303
2024-05-25 01:16:29 [INFO]: Epoch 071 - training loss: 0.2289, validation loss: 0.0317
2024-05-25 01:16:29 [INFO]: Epoch 072 - training loss: 0.2247, validation loss: 0.0248
2024-05-25 01:16:29 [INFO]: Epoch 073 - training loss: 0.2246, validation loss: 0.0263
2024-05-25 01:16:30 [INFO]: Epoch 074 - training loss: 0.2260, validation loss: 0.0242
2024-05-25 01:16:30 [INFO]: Epoch 075 - training loss: 0.2221, validation loss: 0.0290
2024-05-25 01:16:30 [INFO]: Epoch 076 - training loss: 0.2279, validation loss: 0.0298
2024-05-25 01:16:30 [INFO]: Epoch 077 - training loss: 0.2181, validation loss: 0.0275
2024-05-25 01:16:31 [INFO]: Epoch 078 - training loss: 0.2165, validation loss: 0.0267
2024-05-25 01:16:31 [INFO]: Epoch 079 - training loss: 0.2224, validation loss: 0.0252
2024-05-25 01:16:31 [INFO]: Epoch 080 - training loss: 0.2228, validation loss: 0.0276
2024-05-25 01:16:31 [INFO]: Epoch 081 - training loss: 0.2387, validation loss: 0.0282
2024-05-25 01:16:31 [INFO]: Epoch 082 - training loss: 0.2220, validation loss: 0.0275
2024-05-25 01:16:32 [INFO]: Epoch 083 - training loss: 0.2218, validation loss: 0.0261
2024-05-25 01:16:32 [INFO]: Epoch 084 - training loss: 0.2113, validation loss: 0.0247
2024-05-25 01:16:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:16:32 [INFO]: Finished training. The best model is from epoch#74.
2024-05-25 01:16:32 [INFO]: Saved the model to augmentation_saved_results/round_0/Transformer_ettm1/20240525_T011614/Transformer.pypots
2024-05-25 01:16:32 [INFO]: Transformer on ETTm1: MAE=0.1248, MSE=0.0327
2024-05-25 01:16:32 [INFO]: Successfully saved to augmentation_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-25 01:16:32 [INFO]: Using the given device: cuda:0
2024-05-25 01:16:32 [INFO]: Model files will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T011632
2024-05-25 01:16:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T011632/tensorboard
2024-05-25 01:16:32 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 01:16:33 [INFO]: Epoch 001 - training loss: 0.1937, validation loss: 0.0604
2024-05-25 01:16:33 [INFO]: Epoch 002 - training loss: 0.0853, validation loss: 0.0441
2024-05-25 01:16:33 [INFO]: Epoch 003 - training loss: 0.0650, validation loss: 0.0391
2024-05-25 01:16:33 [INFO]: Epoch 004 - training loss: 0.0574, validation loss: 0.0349
2024-05-25 01:16:34 [INFO]: Epoch 005 - training loss: 0.0541, validation loss: 0.0368
2024-05-25 01:16:34 [INFO]: Epoch 006 - training loss: 0.0545, validation loss: 0.0355
2024-05-25 01:16:34 [INFO]: Epoch 007 - training loss: 0.0553, validation loss: 0.0352
2024-05-25 01:16:34 [INFO]: Epoch 008 - training loss: 0.0591, validation loss: 0.0354
2024-05-25 01:16:34 [INFO]: Epoch 009 - training loss: 0.0539, validation loss: 0.0344
2024-05-25 01:16:35 [INFO]: Epoch 010 - training loss: 0.0506, validation loss: 0.0338
2024-05-25 01:16:35 [INFO]: Epoch 011 - training loss: 0.0508, validation loss: 0.0335
2024-05-25 01:16:35 [INFO]: Epoch 012 - training loss: 0.0507, validation loss: 0.0355
2024-05-25 01:16:35 [INFO]: Epoch 013 - training loss: 0.0550, validation loss: 0.0357
2024-05-25 01:16:35 [INFO]: Epoch 014 - training loss: 0.0516, validation loss: 0.0349
2024-05-25 01:16:36 [INFO]: Epoch 015 - training loss: 0.0482, validation loss: 0.0352
2024-05-25 01:16:36 [INFO]: Epoch 016 - training loss: 0.0515, validation loss: 0.0345
2024-05-25 01:16:36 [INFO]: Epoch 017 - training loss: 0.0479, validation loss: 0.0319
2024-05-25 01:16:36 [INFO]: Epoch 018 - training loss: 0.0492, validation loss: 0.0325
2024-05-25 01:16:36 [INFO]: Epoch 019 - training loss: 0.0539, validation loss: 0.0353
2024-05-25 01:16:37 [INFO]: Epoch 020 - training loss: 0.0522, validation loss: 0.0348
2024-05-25 01:16:37 [INFO]: Epoch 021 - training loss: 0.0465, validation loss: 0.0313
2024-05-25 01:16:37 [INFO]: Epoch 022 - training loss: 0.0457, validation loss: 0.0310
2024-05-25 01:16:37 [INFO]: Epoch 023 - training loss: 0.0468, validation loss: 0.0321
2024-05-25 01:16:38 [INFO]: Epoch 024 - training loss: 0.0487, validation loss: 0.0291
2024-05-25 01:16:38 [INFO]: Epoch 025 - training loss: 0.0454, validation loss: 0.0302
2024-05-25 01:16:38 [INFO]: Epoch 026 - training loss: 0.0453, validation loss: 0.0299
2024-05-25 01:16:38 [INFO]: Epoch 027 - training loss: 0.0437, validation loss: 0.0306
2024-05-25 01:16:38 [INFO]: Epoch 028 - training loss: 0.0434, validation loss: 0.0290
2024-05-25 01:16:39 [INFO]: Epoch 029 - training loss: 0.0437, validation loss: 0.0303
2024-05-25 01:16:39 [INFO]: Epoch 030 - training loss: 0.0493, validation loss: 0.0367
2024-05-25 01:16:39 [INFO]: Epoch 031 - training loss: 0.0587, validation loss: 0.0314
2024-05-25 01:16:39 [INFO]: Epoch 032 - training loss: 0.0577, validation loss: 0.0325
2024-05-25 01:16:39 [INFO]: Epoch 033 - training loss: 0.0456, validation loss: 0.0300
2024-05-25 01:16:40 [INFO]: Epoch 034 - training loss: 0.0426, validation loss: 0.0289
2024-05-25 01:16:40 [INFO]: Epoch 035 - training loss: 0.0445, validation loss: 0.0284
2024-05-25 01:16:40 [INFO]: Epoch 036 - training loss: 0.0417, validation loss: 0.0278
2024-05-25 01:16:40 [INFO]: Epoch 037 - training loss: 0.0426, validation loss: 0.0282
2024-05-25 01:16:40 [INFO]: Epoch 038 - training loss: 0.0431, validation loss: 0.0283
2024-05-25 01:16:41 [INFO]: Epoch 039 - training loss: 0.0432, validation loss: 0.0285
2024-05-25 01:16:41 [INFO]: Epoch 040 - training loss: 0.0411, validation loss: 0.0288
2024-05-25 01:16:41 [INFO]: Epoch 041 - training loss: 0.0452, validation loss: 0.0297
2024-05-25 01:16:41 [INFO]: Epoch 042 - training loss: 0.0424, validation loss: 0.0281
2024-05-25 01:16:42 [INFO]: Epoch 043 - training loss: 0.0419, validation loss: 0.0292
2024-05-25 01:16:42 [INFO]: Epoch 044 - training loss: 0.0433, validation loss: 0.0286
2024-05-25 01:16:42 [INFO]: Epoch 045 - training loss: 0.0422, validation loss: 0.0291
2024-05-25 01:16:42 [INFO]: Epoch 046 - training loss: 0.0424, validation loss: 0.0287
2024-05-25 01:16:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:16:42 [INFO]: Finished training. The best model is from epoch#36.
2024-05-25 01:16:42 [INFO]: Saved the model to augmentation_saved_results/round_0/TimesNet_ettm1/20240525_T011632/TimesNet.pypots
2024-05-25 01:16:42 [INFO]: TimesNet on ETTm1: MAE=0.1238, MSE=0.0318
2024-05-25 01:16:42 [INFO]: Successfully saved to augmentation_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-25 01:16:42 [INFO]: Using the given device: cuda:0
2024-05-25 01:16:42 [INFO]: Model files will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642
2024-05-25 01:16:42 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/tensorboard
2024-05-25 01:16:42 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 01:16:44 [INFO]: Epoch 001 - training loss: 0.7312, validation loss: 0.4767
2024-05-25 01:16:44 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch1_loss0.4767472445964813.pypots
2024-05-25 01:16:47 [INFO]: Epoch 002 - training loss: 0.4379, validation loss: 0.3629
2024-05-25 01:16:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch2_loss0.36285174638032913.pypots
2024-05-25 01:16:49 [INFO]: Epoch 003 - training loss: 0.3353, validation loss: 0.3507
2024-05-25 01:16:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch3_loss0.3507039546966553.pypots
2024-05-25 01:16:51 [INFO]: Epoch 004 - training loss: 0.3826, validation loss: 0.3336
2024-05-25 01:16:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch4_loss0.3335828259587288.pypots
2024-05-25 01:16:53 [INFO]: Epoch 005 - training loss: 0.2974, validation loss: 0.3079
2024-05-25 01:16:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch5_loss0.30791570991277695.pypots
2024-05-25 01:16:55 [INFO]: Epoch 006 - training loss: 0.3081, validation loss: 0.2893
2024-05-25 01:16:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch6_loss0.28927090764045715.pypots
2024-05-25 01:16:57 [INFO]: Epoch 007 - training loss: 0.2776, validation loss: 0.2893
2024-05-25 01:16:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch7_loss0.28931237012147903.pypots
2024-05-25 01:16:59 [INFO]: Epoch 008 - training loss: 0.2858, validation loss: 0.2765
2024-05-25 01:16:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch8_loss0.27648673951625824.pypots
2024-05-25 01:17:01 [INFO]: Epoch 009 - training loss: 0.3009, validation loss: 0.2672
2024-05-25 01:17:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch9_loss0.2671916112303734.pypots
2024-05-25 01:17:03 [INFO]: Epoch 010 - training loss: 0.2403, validation loss: 0.2735
2024-05-25 01:17:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch10_loss0.2735079750418663.pypots
2024-05-25 01:17:05 [INFO]: Epoch 011 - training loss: 0.2473, validation loss: 0.2729
2024-05-25 01:17:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch11_loss0.27286791801452637.pypots
2024-05-25 01:17:07 [INFO]: Epoch 012 - training loss: 0.2299, validation loss: 0.2551
2024-05-25 01:17:07 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch12_loss0.255133930593729.pypots
2024-05-25 01:17:09 [INFO]: Epoch 013 - training loss: 0.2220, validation loss: 0.2632
2024-05-25 01:17:09 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch13_loss0.26321085542440414.pypots
2024-05-25 01:17:11 [INFO]: Epoch 014 - training loss: 0.2558, validation loss: 0.2581
2024-05-25 01:17:11 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch14_loss0.25812090933322906.pypots
2024-05-25 01:17:14 [INFO]: Epoch 015 - training loss: 0.2375, validation loss: 0.2510
2024-05-25 01:17:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch15_loss0.2510155513882637.pypots
2024-05-25 01:17:16 [INFO]: Epoch 016 - training loss: 0.2761, validation loss: 0.2532
2024-05-25 01:17:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch16_loss0.25317462533712387.pypots
2024-05-25 01:17:18 [INFO]: Epoch 017 - training loss: 0.2374, validation loss: 0.2320
2024-05-25 01:17:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch17_loss0.23203114420175552.pypots
2024-05-25 01:17:20 [INFO]: Epoch 018 - training loss: 0.2401, validation loss: 0.2153
2024-05-25 01:17:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch18_loss0.2153325341641903.pypots
2024-05-25 01:17:22 [INFO]: Epoch 019 - training loss: 0.2085, validation loss: 0.2099
2024-05-25 01:17:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch19_loss0.20994362980127335.pypots
2024-05-25 01:17:24 [INFO]: Epoch 020 - training loss: 0.2215, validation loss: 0.2091
2024-05-25 01:17:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch20_loss0.20914654433727264.pypots
2024-05-25 01:17:26 [INFO]: Epoch 021 - training loss: 0.2726, validation loss: 0.2228
2024-05-25 01:17:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch21_loss0.22275862842798233.pypots
2024-05-25 01:17:28 [INFO]: Epoch 022 - training loss: 0.2233, validation loss: 0.2103
2024-05-25 01:17:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch22_loss0.21026203408837318.pypots
2024-05-25 01:17:30 [INFO]: Epoch 023 - training loss: 0.2547, validation loss: 0.2159
2024-05-25 01:17:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch23_loss0.21591543033719063.pypots
2024-05-25 01:17:32 [INFO]: Epoch 024 - training loss: 0.2048, validation loss: 0.2068
2024-05-25 01:17:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch24_loss0.2068442516028881.pypots
2024-05-25 01:17:34 [INFO]: Epoch 025 - training loss: 0.2595, validation loss: 0.1896
2024-05-25 01:17:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch25_loss0.18964744731783867.pypots
2024-05-25 01:17:36 [INFO]: Epoch 026 - training loss: 0.1742, validation loss: 0.1896
2024-05-25 01:17:36 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch26_loss0.1895909570157528.pypots
2024-05-25 01:17:38 [INFO]: Epoch 027 - training loss: 0.2204, validation loss: 0.1917
2024-05-25 01:17:38 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch27_loss0.19170498102903366.pypots
2024-05-25 01:17:41 [INFO]: Epoch 028 - training loss: 0.3000, validation loss: 0.1969
2024-05-25 01:17:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch28_loss0.19691422209143639.pypots
2024-05-25 01:17:43 [INFO]: Epoch 029 - training loss: 0.2349, validation loss: 0.1953
2024-05-25 01:17:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch29_loss0.19527138024568558.pypots
2024-05-25 01:17:45 [INFO]: Epoch 030 - training loss: 0.2182, validation loss: 0.1839
2024-05-25 01:17:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch30_loss0.18385470286011696.pypots
2024-05-25 01:17:47 [INFO]: Epoch 031 - training loss: 0.1826, validation loss: 0.1989
2024-05-25 01:17:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch31_loss0.19893387332558632.pypots
2024-05-25 01:17:49 [INFO]: Epoch 032 - training loss: 0.2025, validation loss: 0.1882
2024-05-25 01:17:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch32_loss0.18818755447864532.pypots
2024-05-25 01:17:51 [INFO]: Epoch 033 - training loss: 0.1978, validation loss: 0.1831
2024-05-25 01:17:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch33_loss0.18306105956435204.pypots
2024-05-25 01:17:53 [INFO]: Epoch 034 - training loss: 0.2226, validation loss: 0.1799
2024-05-25 01:17:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch34_loss0.17991629987955093.pypots
2024-05-25 01:17:55 [INFO]: Epoch 035 - training loss: 0.1937, validation loss: 0.1763
2024-05-25 01:17:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch35_loss0.17634977027773857.pypots
2024-05-25 01:17:57 [INFO]: Epoch 036 - training loss: 0.1683, validation loss: 0.1714
2024-05-25 01:17:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch36_loss0.17140614613890648.pypots
2024-05-25 01:17:59 [INFO]: Epoch 037 - training loss: 0.2021, validation loss: 0.1751
2024-05-25 01:17:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch37_loss0.17507703602313995.pypots
2024-05-25 01:18:01 [INFO]: Epoch 038 - training loss: 0.2198, validation loss: 0.1724
2024-05-25 01:18:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch38_loss0.17240595072507858.pypots
2024-05-25 01:18:03 [INFO]: Epoch 039 - training loss: 0.2282, validation loss: 0.1753
2024-05-25 01:18:03 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch39_loss0.17530520632863045.pypots
2024-05-25 01:18:05 [INFO]: Epoch 040 - training loss: 0.2041, validation loss: 0.1745
2024-05-25 01:18:05 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch40_loss0.17448261007666588.pypots
2024-05-25 01:18:07 [INFO]: Epoch 041 - training loss: 0.2306, validation loss: 0.1722
2024-05-25 01:18:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch41_loss0.17218522354960442.pypots
2024-05-25 01:18:10 [INFO]: Epoch 042 - training loss: 0.2072, validation loss: 0.1697
2024-05-25 01:18:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch42_loss0.16972969844937325.pypots
2024-05-25 01:18:12 [INFO]: Epoch 043 - training loss: 0.1913, validation loss: 0.1707
2024-05-25 01:18:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch43_loss0.17066211998462677.pypots
2024-05-25 01:18:14 [INFO]: Epoch 044 - training loss: 0.1878, validation loss: 0.1690
2024-05-25 01:18:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch44_loss0.16901805996894836.pypots
2024-05-25 01:18:16 [INFO]: Epoch 045 - training loss: 0.1942, validation loss: 0.1633
2024-05-25 01:18:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch45_loss0.16326593607664108.pypots
2024-05-25 01:18:18 [INFO]: Epoch 046 - training loss: 0.1602, validation loss: 0.1642
2024-05-25 01:18:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch46_loss0.16415493562817574.pypots
2024-05-25 01:18:20 [INFO]: Epoch 047 - training loss: 0.1771, validation loss: 0.1570
2024-05-25 01:18:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch47_loss0.15703777223825455.pypots
2024-05-25 01:18:22 [INFO]: Epoch 048 - training loss: 0.1773, validation loss: 0.1617
2024-05-25 01:18:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch48_loss0.16167715191841125.pypots
2024-05-25 01:18:24 [INFO]: Epoch 049 - training loss: 0.2516, validation loss: 0.1611
2024-05-25 01:18:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch49_loss0.16113676875829697.pypots
2024-05-25 01:18:26 [INFO]: Epoch 050 - training loss: 0.1710, validation loss: 0.1550
2024-05-25 01:18:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch50_loss0.1550181731581688.pypots
2024-05-25 01:18:28 [INFO]: Epoch 051 - training loss: 0.1958, validation loss: 0.1520
2024-05-25 01:18:28 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch51_loss0.15202030166983604.pypots
2024-05-25 01:18:30 [INFO]: Epoch 052 - training loss: 0.1901, validation loss: 0.1505
2024-05-25 01:18:30 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch52_loss0.1505349688231945.pypots
2024-05-25 01:18:32 [INFO]: Epoch 053 - training loss: 0.1983, validation loss: 0.2476
2024-05-25 01:18:32 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch53_loss0.247617207467556.pypots
2024-05-25 01:18:34 [INFO]: Epoch 054 - training loss: 0.2231, validation loss: 0.2176
2024-05-25 01:18:34 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch54_loss0.21758589148521423.pypots
2024-05-25 01:18:37 [INFO]: Epoch 055 - training loss: 0.2249, validation loss: 0.1897
2024-05-25 01:18:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch55_loss0.18970106169581413.pypots
2024-05-25 01:18:39 [INFO]: Epoch 056 - training loss: 0.1982, validation loss: 0.1734
2024-05-25 01:18:39 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch56_loss0.17344873026013374.pypots
2024-05-25 01:18:41 [INFO]: Epoch 057 - training loss: 0.1773, validation loss: 0.1681
2024-05-25 01:18:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch57_loss0.16812309250235558.pypots
2024-05-25 01:18:43 [INFO]: Epoch 058 - training loss: 0.1926, validation loss: 0.1587
2024-05-25 01:18:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch58_loss0.15867261588573456.pypots
2024-05-25 01:18:45 [INFO]: Epoch 059 - training loss: 0.1651, validation loss: 0.1519
2024-05-25 01:18:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch59_loss0.15185125172138214.pypots
2024-05-25 01:18:47 [INFO]: Epoch 060 - training loss: 0.1532, validation loss: 0.1533
2024-05-25 01:18:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch60_loss0.15330279618501663.pypots
2024-05-25 01:18:49 [INFO]: Epoch 061 - training loss: 0.1767, validation loss: 0.1502
2024-05-25 01:18:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch61_loss0.15022187307476997.pypots
2024-05-25 01:18:51 [INFO]: Epoch 062 - training loss: 0.1611, validation loss: 0.1505
2024-05-25 01:18:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch62_loss0.1504666619002819.pypots
2024-05-25 01:18:53 [INFO]: Epoch 063 - training loss: 0.1642, validation loss: 0.1545
2024-05-25 01:18:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch63_loss0.15454288199543953.pypots
2024-05-25 01:18:55 [INFO]: Epoch 064 - training loss: 0.1831, validation loss: 0.1475
2024-05-25 01:18:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch64_loss0.1474788822233677.pypots
2024-05-25 01:18:57 [INFO]: Epoch 065 - training loss: 0.2184, validation loss: 0.1524
2024-05-25 01:18:57 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch65_loss0.15239423140883446.pypots
2024-05-25 01:18:59 [INFO]: Epoch 066 - training loss: 0.1775, validation loss: 0.1561
2024-05-25 01:18:59 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch66_loss0.1560804881155491.pypots
2024-05-25 01:19:01 [INFO]: Epoch 067 - training loss: 0.1687, validation loss: 0.1563
2024-05-25 01:19:01 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch67_loss0.15633945539593697.pypots
2024-05-25 01:19:04 [INFO]: Epoch 068 - training loss: 0.2047, validation loss: 0.1571
2024-05-25 01:19:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch68_loss0.15705043449997902.pypots
2024-05-25 01:19:06 [INFO]: Epoch 069 - training loss: 0.1859, validation loss: 0.1496
2024-05-25 01:19:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch69_loss0.14960305020213127.pypots
2024-05-25 01:19:08 [INFO]: Epoch 070 - training loss: 0.2139, validation loss: 0.1521
2024-05-25 01:19:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch70_loss0.15212836861610413.pypots
2024-05-25 01:19:10 [INFO]: Epoch 071 - training loss: 0.1927, validation loss: 0.1472
2024-05-25 01:19:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch71_loss0.14720994606614113.pypots
2024-05-25 01:19:12 [INFO]: Epoch 072 - training loss: 0.1716, validation loss: 0.1510
2024-05-25 01:19:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch72_loss0.1510075256228447.pypots
2024-05-25 01:19:14 [INFO]: Epoch 073 - training loss: 0.1677, validation loss: 0.1500
2024-05-25 01:19:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch73_loss0.14997651800513268.pypots
2024-05-25 01:19:16 [INFO]: Epoch 074 - training loss: 0.1580, validation loss: 0.1412
2024-05-25 01:19:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch74_loss0.14122290909290314.pypots
2024-05-25 01:19:18 [INFO]: Epoch 075 - training loss: 0.1410, validation loss: 0.1450
2024-05-25 01:19:18 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch75_loss0.14498097449541092.pypots
2024-05-25 01:19:20 [INFO]: Epoch 076 - training loss: 0.1611, validation loss: 0.1397
2024-05-25 01:19:20 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch76_loss0.1397455595433712.pypots
2024-05-25 01:19:22 [INFO]: Epoch 077 - training loss: 0.1970, validation loss: 0.1386
2024-05-25 01:19:22 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch77_loss0.13855436444282532.pypots
2024-05-25 01:19:24 [INFO]: Epoch 078 - training loss: 0.1605, validation loss: 0.1368
2024-05-25 01:19:24 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch78_loss0.13679902255535126.pypots
2024-05-25 01:19:26 [INFO]: Epoch 079 - training loss: 0.1612, validation loss: 0.1430
2024-05-25 01:19:26 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch79_loss0.1430051364004612.pypots
2024-05-25 01:19:28 [INFO]: Epoch 080 - training loss: 0.1541, validation loss: 0.1561
2024-05-25 01:19:29 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch80_loss0.1560550332069397.pypots
2024-05-25 01:19:31 [INFO]: Epoch 081 - training loss: 0.1775, validation loss: 0.1560
2024-05-25 01:19:31 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch81_loss0.1560494676232338.pypots
2024-05-25 01:19:33 [INFO]: Epoch 082 - training loss: 0.1755, validation loss: 0.1605
2024-05-25 01:19:33 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch82_loss0.16053824126720428.pypots
2024-05-25 01:19:35 [INFO]: Epoch 083 - training loss: 0.1844, validation loss: 0.1564
2024-05-25 01:19:35 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch83_loss0.1563926376402378.pypots
2024-05-25 01:19:37 [INFO]: Epoch 084 - training loss: 0.1664, validation loss: 0.1447
2024-05-25 01:19:37 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch84_loss0.14471594616770744.pypots
2024-05-25 01:19:39 [INFO]: Epoch 085 - training loss: 0.1740, validation loss: 0.1454
2024-05-25 01:19:39 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch85_loss0.1454361192882061.pypots
2024-05-25 01:19:41 [INFO]: Epoch 086 - training loss: 0.1734, validation loss: 0.1471
2024-05-25 01:19:41 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch86_loss0.14712649211287498.pypots
2024-05-25 01:19:43 [INFO]: Epoch 087 - training loss: 0.1580, validation loss: 0.1393
2024-05-25 01:19:43 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch87_loss0.13927412033081055.pypots
2024-05-25 01:19:45 [INFO]: Epoch 088 - training loss: 0.1722, validation loss: 0.1366
2024-05-25 01:19:45 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch88_loss0.1365872025489807.pypots
2024-05-25 01:19:47 [INFO]: Epoch 089 - training loss: 0.1847, validation loss: 0.1364
2024-05-25 01:19:47 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch89_loss0.13644707202911377.pypots
2024-05-25 01:19:49 [INFO]: Epoch 090 - training loss: 0.1557, validation loss: 0.1359
2024-05-25 01:19:49 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch90_loss0.13590911403298378.pypots
2024-05-25 01:19:51 [INFO]: Epoch 091 - training loss: 0.1707, validation loss: 0.1359
2024-05-25 01:19:51 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch91_loss0.13591808453202248.pypots
2024-05-25 01:19:53 [INFO]: Epoch 092 - training loss: 0.2210, validation loss: 0.1365
2024-05-25 01:19:53 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch92_loss0.1365322209894657.pypots
2024-05-25 01:19:55 [INFO]: Epoch 093 - training loss: 0.1587, validation loss: 0.1327
2024-05-25 01:19:55 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch93_loss0.13269924372434616.pypots
2024-05-25 01:19:58 [INFO]: Epoch 094 - training loss: 0.1491, validation loss: 0.1346
2024-05-25 01:19:58 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch94_loss0.1346498616039753.pypots
2024-05-25 01:20:00 [INFO]: Epoch 095 - training loss: 0.1542, validation loss: 0.1413
2024-05-25 01:20:00 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch95_loss0.1413477659225464.pypots
2024-05-25 01:20:02 [INFO]: Epoch 096 - training loss: 0.1525, validation loss: 0.1482
2024-05-25 01:20:02 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch96_loss0.14816896617412567.pypots
2024-05-25 01:20:04 [INFO]: Epoch 097 - training loss: 0.1612, validation loss: 0.1472
2024-05-25 01:20:04 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch97_loss0.14724324271082878.pypots
2024-05-25 01:20:06 [INFO]: Epoch 098 - training loss: 0.2058, validation loss: 0.1449
2024-05-25 01:20:06 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch98_loss0.14486254379153252.pypots
2024-05-25 01:20:08 [INFO]: Epoch 099 - training loss: 0.1786, validation loss: 0.1515
2024-05-25 01:20:08 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch99_loss0.1515047624707222.pypots
2024-05-25 01:20:10 [INFO]: Epoch 100 - training loss: 0.1730, validation loss: 0.1386
2024-05-25 01:20:10 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch100_loss0.13858049362897873.pypots
2024-05-25 01:20:12 [INFO]: Epoch 101 - training loss: 0.1498, validation loss: 0.1330
2024-05-25 01:20:12 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch101_loss0.1329779326915741.pypots
2024-05-25 01:20:14 [INFO]: Epoch 102 - training loss: 0.2024, validation loss: 0.1341
2024-05-25 01:20:14 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch102_loss0.13410009443759918.pypots
2024-05-25 01:20:16 [INFO]: Epoch 103 - training loss: 0.1953, validation loss: 0.1382
2024-05-25 01:20:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI_epoch103_loss0.1381673626601696.pypots
2024-05-25 01:20:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:20:16 [INFO]: Finished training. The best model is from epoch#93.
2024-05-25 01:20:16 [INFO]: Saved the model to augmentation_saved_results/round_0/CSDI_ettm1/20240525_T011642/CSDI.pypots
2024-05-25 01:20:32 [INFO]: CSDI on ETTm1: MAE=0.1503, MSE=0.0685
2024-05-25 01:20:32 [INFO]: Successfully saved to augmentation_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-25 01:20:32 [INFO]: Using the given device: cuda:0
2024-05-25 01:20:32 [INFO]: Model files will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T012032
2024-05-25 01:20:32 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T012032/tensorboard
2024-05-25 01:20:32 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 01:20:32 [INFO]: Epoch 001 - training loss: 23997.5551, validation loss: 0.9785
2024-05-25 01:20:32 [INFO]: Epoch 002 - training loss: 22094.3103, validation loss: 0.9771
2024-05-25 01:20:32 [INFO]: Epoch 003 - training loss: 20260.5093, validation loss: 0.9781
2024-05-25 01:20:33 [INFO]: Epoch 004 - training loss: 18223.7311, validation loss: 0.9708
2024-05-25 01:20:33 [INFO]: Epoch 005 - training loss: 16433.8138, validation loss: 0.9440
2024-05-25 01:20:33 [INFO]: Epoch 006 - training loss: 14511.0223, validation loss: 0.8903
2024-05-25 01:20:33 [INFO]: Epoch 007 - training loss: 13394.2959, validation loss: 0.7790
2024-05-25 01:20:33 [INFO]: Epoch 008 - training loss: 12209.3085, validation loss: 0.6748
2024-05-25 01:20:33 [INFO]: Epoch 009 - training loss: 11635.4500, validation loss: 0.5859
2024-05-25 01:20:33 [INFO]: Epoch 010 - training loss: 11129.6681, validation loss: 0.5346
2024-05-25 01:20:33 [INFO]: Epoch 011 - training loss: 10853.6448, validation loss: 0.4941
2024-05-25 01:20:34 [INFO]: Epoch 012 - training loss: 10553.9268, validation loss: 0.4693
2024-05-25 01:20:34 [INFO]: Epoch 013 - training loss: 10271.5009, validation loss: 0.4502
2024-05-25 01:20:34 [INFO]: Epoch 014 - training loss: 10187.9590, validation loss: 0.4321
2024-05-25 01:20:34 [INFO]: Epoch 015 - training loss: 10038.8334, validation loss: 0.4118
2024-05-25 01:20:34 [INFO]: Epoch 016 - training loss: 9935.6174, validation loss: 0.3937
2024-05-25 01:20:34 [INFO]: Epoch 017 - training loss: 9868.9770, validation loss: 0.3765
2024-05-25 01:20:34 [INFO]: Epoch 018 - training loss: 9761.6852, validation loss: 0.3478
2024-05-25 01:20:34 [INFO]: Epoch 019 - training loss: 9706.2131, validation loss: 0.3337
2024-05-25 01:20:34 [INFO]: Epoch 020 - training loss: 9750.7264, validation loss: 0.3271
2024-05-25 01:20:35 [INFO]: Epoch 021 - training loss: 9616.6575, validation loss: 0.3196
2024-05-25 01:20:35 [INFO]: Epoch 022 - training loss: 9601.4520, validation loss: 0.3133
2024-05-25 01:20:35 [INFO]: Epoch 023 - training loss: 9570.2580, validation loss: 0.3051
2024-05-25 01:20:35 [INFO]: Epoch 024 - training loss: 9522.3303, validation loss: 0.2967
2024-05-25 01:20:35 [INFO]: Epoch 025 - training loss: 9495.7512, validation loss: 0.2908
2024-05-25 01:20:35 [INFO]: Epoch 026 - training loss: 9475.7462, validation loss: 0.2871
2024-05-25 01:20:35 [INFO]: Epoch 027 - training loss: 9474.0709, validation loss: 0.2750
2024-05-25 01:20:35 [INFO]: Epoch 028 - training loss: 9448.5734, validation loss: 0.2677
2024-05-25 01:20:36 [INFO]: Epoch 029 - training loss: 9427.2917, validation loss: 0.2672
2024-05-25 01:20:36 [INFO]: Epoch 030 - training loss: 9426.0634, validation loss: 0.2594
2024-05-25 01:20:36 [INFO]: Epoch 031 - training loss: 9413.4147, validation loss: 0.2489
2024-05-25 01:20:36 [INFO]: Epoch 032 - training loss: 9394.6310, validation loss: 0.2432
2024-05-25 01:20:36 [INFO]: Epoch 033 - training loss: 9388.8310, validation loss: 0.2396
2024-05-25 01:20:36 [INFO]: Epoch 034 - training loss: 9377.4794, validation loss: 0.2380
2024-05-25 01:20:36 [INFO]: Epoch 035 - training loss: 9365.7524, validation loss: 0.2322
2024-05-25 01:20:36 [INFO]: Epoch 036 - training loss: 9360.0467, validation loss: 0.2258
2024-05-25 01:20:37 [INFO]: Epoch 037 - training loss: 9347.5959, validation loss: 0.2225
2024-05-25 01:20:37 [INFO]: Epoch 038 - training loss: 9356.9803, validation loss: 0.2195
2024-05-25 01:20:37 [INFO]: Epoch 039 - training loss: 9335.5981, validation loss: 0.2172
2024-05-25 01:20:37 [INFO]: Epoch 040 - training loss: 9332.3962, validation loss: 0.2108
2024-05-25 01:20:37 [INFO]: Epoch 041 - training loss: 9326.1761, validation loss: 0.2076
2024-05-25 01:20:37 [INFO]: Epoch 042 - training loss: 9329.9550, validation loss: 0.2043
2024-05-25 01:20:37 [INFO]: Epoch 043 - training loss: 9314.6461, validation loss: 0.2003
2024-05-25 01:20:37 [INFO]: Epoch 044 - training loss: 9313.2157, validation loss: 0.1951
2024-05-25 01:20:38 [INFO]: Epoch 045 - training loss: 9318.1703, validation loss: 0.1977
2024-05-25 01:20:38 [INFO]: Epoch 046 - training loss: 9301.9741, validation loss: 0.1960
2024-05-25 01:20:38 [INFO]: Epoch 047 - training loss: 9299.3159, validation loss: 0.1903
2024-05-25 01:20:38 [INFO]: Epoch 048 - training loss: 9311.2704, validation loss: 0.1861
2024-05-25 01:20:38 [INFO]: Epoch 049 - training loss: 9293.2816, validation loss: 0.1827
2024-05-25 01:20:38 [INFO]: Epoch 050 - training loss: 9292.5897, validation loss: 0.1770
2024-05-25 01:20:38 [INFO]: Epoch 051 - training loss: 9285.1712, validation loss: 0.1748
2024-05-25 01:20:38 [INFO]: Epoch 052 - training loss: 9288.0333, validation loss: 0.1714
2024-05-25 01:20:39 [INFO]: Epoch 053 - training loss: 9283.3458, validation loss: 0.1696
2024-05-25 01:20:39 [INFO]: Epoch 054 - training loss: 9280.7704, validation loss: 0.1679
2024-05-25 01:20:39 [INFO]: Epoch 055 - training loss: 9279.4326, validation loss: 0.1654
2024-05-25 01:20:39 [INFO]: Epoch 056 - training loss: 9273.3264, validation loss: 0.1614
2024-05-25 01:20:39 [INFO]: Epoch 057 - training loss: 9272.1058, validation loss: 0.1613
2024-05-25 01:20:39 [INFO]: Epoch 058 - training loss: 9271.9421, validation loss: 0.1587
2024-05-25 01:20:39 [INFO]: Epoch 059 - training loss: 9268.0931, validation loss: 0.1579
2024-05-25 01:20:39 [INFO]: Epoch 060 - training loss: 9265.7685, validation loss: 0.1584
2024-05-25 01:20:39 [INFO]: Epoch 061 - training loss: 9266.6474, validation loss: 0.1550
2024-05-25 01:20:40 [INFO]: Epoch 062 - training loss: 9265.0720, validation loss: 0.1477
2024-05-25 01:20:40 [INFO]: Epoch 063 - training loss: 9263.1634, validation loss: 0.1503
2024-05-25 01:20:40 [INFO]: Epoch 064 - training loss: 9260.8442, validation loss: 0.1480
2024-05-25 01:20:40 [INFO]: Epoch 065 - training loss: 9262.9749, validation loss: 0.1471
2024-05-25 01:20:40 [INFO]: Epoch 066 - training loss: 9256.8557, validation loss: 0.1493
2024-05-25 01:20:40 [INFO]: Epoch 067 - training loss: 9278.3210, validation loss: 0.1474
2024-05-25 01:20:40 [INFO]: Epoch 068 - training loss: 9258.2582, validation loss: 0.1451
2024-05-25 01:20:40 [INFO]: Epoch 069 - training loss: 9260.9229, validation loss: 0.1423
2024-05-25 01:20:41 [INFO]: Epoch 070 - training loss: 9254.3957, validation loss: 0.1419
2024-05-25 01:20:41 [INFO]: Epoch 071 - training loss: 9250.4939, validation loss: 0.1420
2024-05-25 01:20:41 [INFO]: Epoch 072 - training loss: 9248.2246, validation loss: 0.1394
2024-05-25 01:20:41 [INFO]: Epoch 073 - training loss: 9249.5815, validation loss: 0.1376
2024-05-25 01:20:41 [INFO]: Epoch 074 - training loss: 9248.4023, validation loss: 0.1376
2024-05-25 01:20:41 [INFO]: Epoch 075 - training loss: 9249.3621, validation loss: 0.1369
2024-05-25 01:20:41 [INFO]: Epoch 076 - training loss: 9247.1935, validation loss: 0.1368
2024-05-25 01:20:41 [INFO]: Epoch 077 - training loss: 9244.9464, validation loss: 0.1363
2024-05-25 01:20:42 [INFO]: Epoch 078 - training loss: 9244.0532, validation loss: 0.1357
2024-05-25 01:20:42 [INFO]: Epoch 079 - training loss: 9246.0172, validation loss: 0.1327
2024-05-25 01:20:42 [INFO]: Epoch 080 - training loss: 9242.1904, validation loss: 0.1332
2024-05-25 01:20:42 [INFO]: Epoch 081 - training loss: 9242.5030, validation loss: 0.1308
2024-05-25 01:20:42 [INFO]: Epoch 082 - training loss: 9241.8239, validation loss: 0.1312
2024-05-25 01:20:42 [INFO]: Epoch 083 - training loss: 9244.5496, validation loss: 0.1315
2024-05-25 01:20:42 [INFO]: Epoch 084 - training loss: 9239.4152, validation loss: 0.1311
2024-05-25 01:20:42 [INFO]: Epoch 085 - training loss: 9240.5593, validation loss: 0.1299
2024-05-25 01:20:43 [INFO]: Epoch 086 - training loss: 9242.2868, validation loss: 0.1286
2024-05-25 01:20:43 [INFO]: Epoch 087 - training loss: 9236.2907, validation loss: 0.1288
2024-05-25 01:20:43 [INFO]: Epoch 088 - training loss: 9243.0640, validation loss: 0.1289
2024-05-25 01:20:43 [INFO]: Epoch 089 - training loss: 9235.6105, validation loss: 0.1277
2024-05-25 01:20:43 [INFO]: Epoch 090 - training loss: 9235.8954, validation loss: 0.1272
2024-05-25 01:20:43 [INFO]: Epoch 091 - training loss: 9237.3085, validation loss: 0.1259
2024-05-25 01:20:43 [INFO]: Epoch 092 - training loss: 9235.1392, validation loss: 0.1269
2024-05-25 01:20:43 [INFO]: Epoch 093 - training loss: 9232.9669, validation loss: 0.1248
2024-05-25 01:20:44 [INFO]: Epoch 094 - training loss: 9231.9811, validation loss: 0.1242
2024-05-25 01:20:44 [INFO]: Epoch 095 - training loss: 9232.7203, validation loss: 0.1232
2024-05-25 01:20:44 [INFO]: Epoch 096 - training loss: 9233.5092, validation loss: 0.1245
2024-05-25 01:20:44 [INFO]: Epoch 097 - training loss: 9231.8192, validation loss: 0.1213
2024-05-25 01:20:44 [INFO]: Epoch 098 - training loss: 9231.8383, validation loss: 0.1236
2024-05-25 01:20:44 [INFO]: Epoch 099 - training loss: 9233.5330, validation loss: 0.1223
2024-05-25 01:20:44 [INFO]: Epoch 100 - training loss: 9228.3241, validation loss: 0.1213
2024-05-25 01:20:44 [INFO]: Epoch 101 - training loss: 9230.6357, validation loss: 0.1190
2024-05-25 01:20:44 [INFO]: Epoch 102 - training loss: 9228.0923, validation loss: 0.1209
2024-05-25 01:20:45 [INFO]: Epoch 103 - training loss: 9227.2869, validation loss: 0.1190
2024-05-25 01:20:45 [INFO]: Epoch 104 - training loss: 9227.2721, validation loss: 0.1195
2024-05-25 01:20:45 [INFO]: Epoch 105 - training loss: 9228.5059, validation loss: 0.1191
2024-05-25 01:20:45 [INFO]: Epoch 106 - training loss: 9227.6044, validation loss: 0.1179
2024-05-25 01:20:45 [INFO]: Epoch 107 - training loss: 9228.6512, validation loss: 0.1177
2024-05-25 01:20:45 [INFO]: Epoch 108 - training loss: 9226.1128, validation loss: 0.1160
2024-05-25 01:20:45 [INFO]: Epoch 109 - training loss: 9230.0541, validation loss: 0.1177
2024-05-25 01:20:45 [INFO]: Epoch 110 - training loss: 9228.4393, validation loss: 0.1150
2024-05-25 01:20:46 [INFO]: Epoch 111 - training loss: 9227.1147, validation loss: 0.1154
2024-05-25 01:20:46 [INFO]: Epoch 112 - training loss: 9225.4821, validation loss: 0.1147
2024-05-25 01:20:46 [INFO]: Epoch 113 - training loss: 9224.7807, validation loss: 0.1139
2024-05-25 01:20:46 [INFO]: Epoch 114 - training loss: 9225.2042, validation loss: 0.1152
2024-05-25 01:20:46 [INFO]: Epoch 115 - training loss: 9225.7957, validation loss: 0.1126
2024-05-25 01:20:46 [INFO]: Epoch 116 - training loss: 9225.2677, validation loss: 0.1117
2024-05-25 01:20:46 [INFO]: Epoch 117 - training loss: 9225.7542, validation loss: 0.1136
2024-05-25 01:20:46 [INFO]: Epoch 118 - training loss: 9225.2872, validation loss: 0.1121
2024-05-25 01:20:47 [INFO]: Epoch 119 - training loss: 9224.0533, validation loss: 0.1120
2024-05-25 01:20:47 [INFO]: Epoch 120 - training loss: 9224.0139, validation loss: 0.1113
2024-05-25 01:20:47 [INFO]: Epoch 121 - training loss: 9222.1550, validation loss: 0.1137
2024-05-25 01:20:47 [INFO]: Epoch 122 - training loss: 9222.3771, validation loss: 0.1099
2024-05-25 01:20:47 [INFO]: Epoch 123 - training loss: 9221.1906, validation loss: 0.1098
2024-05-25 01:20:47 [INFO]: Epoch 124 - training loss: 9223.2598, validation loss: 0.1097
2024-05-25 01:20:47 [INFO]: Epoch 125 - training loss: 9220.0275, validation loss: 0.1096
2024-05-25 01:20:47 [INFO]: Epoch 126 - training loss: 9222.5751, validation loss: 0.1088
2024-05-25 01:20:48 [INFO]: Epoch 127 - training loss: 9223.8193, validation loss: 0.1093
2024-05-25 01:20:48 [INFO]: Epoch 128 - training loss: 9220.2854, validation loss: 0.1080
2024-05-25 01:20:48 [INFO]: Epoch 129 - training loss: 9221.9160, validation loss: 0.1083
2024-05-25 01:20:48 [INFO]: Epoch 130 - training loss: 9219.5032, validation loss: 0.1064
2024-05-25 01:20:48 [INFO]: Epoch 131 - training loss: 9220.2315, validation loss: 0.1054
2024-05-25 01:20:48 [INFO]: Epoch 132 - training loss: 9218.9494, validation loss: 0.1052
2024-05-25 01:20:48 [INFO]: Epoch 133 - training loss: 9219.7868, validation loss: 0.1048
2024-05-25 01:20:48 [INFO]: Epoch 134 - training loss: 9221.5071, validation loss: 0.1058
2024-05-25 01:20:48 [INFO]: Epoch 135 - training loss: 9219.3835, validation loss: 0.1035
2024-05-25 01:20:49 [INFO]: Epoch 136 - training loss: 9218.0468, validation loss: 0.1050
2024-05-25 01:20:49 [INFO]: Epoch 137 - training loss: 9218.3910, validation loss: 0.1049
2024-05-25 01:20:49 [INFO]: Epoch 138 - training loss: 9218.9970, validation loss: 0.1031
2024-05-25 01:20:49 [INFO]: Epoch 139 - training loss: 9217.9179, validation loss: 0.1032
2024-05-25 01:20:49 [INFO]: Epoch 140 - training loss: 9218.4050, validation loss: 0.1021
2024-05-25 01:20:49 [INFO]: Epoch 141 - training loss: 9217.3932, validation loss: 0.1049
2024-05-25 01:20:49 [INFO]: Epoch 142 - training loss: 9215.9596, validation loss: 0.1021
2024-05-25 01:20:49 [INFO]: Epoch 143 - training loss: 9218.4893, validation loss: 0.1019
2024-05-25 01:20:50 [INFO]: Epoch 144 - training loss: 9217.9802, validation loss: 0.1013
2024-05-25 01:20:50 [INFO]: Epoch 145 - training loss: 9218.7734, validation loss: 0.1007
2024-05-25 01:20:50 [INFO]: Epoch 146 - training loss: 9216.8033, validation loss: 0.1000
2024-05-25 01:20:50 [INFO]: Epoch 147 - training loss: 9218.3586, validation loss: 0.1013
2024-05-25 01:20:50 [INFO]: Epoch 148 - training loss: 9216.6762, validation loss: 0.1004
2024-05-25 01:20:50 [INFO]: Epoch 149 - training loss: 9216.9625, validation loss: 0.1001
2024-05-25 01:20:50 [INFO]: Epoch 150 - training loss: 9216.7068, validation loss: 0.0987
2024-05-25 01:20:50 [INFO]: Epoch 151 - training loss: 9216.3354, validation loss: 0.0994
2024-05-25 01:20:51 [INFO]: Epoch 152 - training loss: 9216.2066, validation loss: 0.0977
2024-05-25 01:20:51 [INFO]: Epoch 153 - training loss: 9215.5804, validation loss: 0.0979
2024-05-25 01:20:51 [INFO]: Epoch 154 - training loss: 9215.8302, validation loss: 0.0967
2024-05-25 01:20:51 [INFO]: Epoch 155 - training loss: 9216.3350, validation loss: 0.0978
2024-05-25 01:20:51 [INFO]: Epoch 156 - training loss: 9214.3670, validation loss: 0.0974
2024-05-25 01:20:51 [INFO]: Epoch 157 - training loss: 9214.9077, validation loss: 0.0956
2024-05-25 01:20:51 [INFO]: Epoch 158 - training loss: 9215.4879, validation loss: 0.0958
2024-05-25 01:20:51 [INFO]: Epoch 159 - training loss: 9213.9188, validation loss: 0.0960
2024-05-25 01:20:52 [INFO]: Epoch 160 - training loss: 9215.0496, validation loss: 0.0952
2024-05-25 01:20:52 [INFO]: Epoch 161 - training loss: 9215.6021, validation loss: 0.0964
2024-05-25 01:20:52 [INFO]: Epoch 162 - training loss: 9215.5571, validation loss: 0.0966
2024-05-25 01:20:52 [INFO]: Epoch 163 - training loss: 9213.6626, validation loss: 0.0959
2024-05-25 01:20:52 [INFO]: Epoch 164 - training loss: 9213.8920, validation loss: 0.0970
2024-05-25 01:20:52 [INFO]: Epoch 165 - training loss: 9215.0189, validation loss: 0.0960
2024-05-25 01:20:52 [INFO]: Epoch 166 - training loss: 9214.1467, validation loss: 0.0939
2024-05-25 01:20:52 [INFO]: Epoch 167 - training loss: 9211.7668, validation loss: 0.0950
2024-05-25 01:20:52 [INFO]: Epoch 168 - training loss: 9214.6895, validation loss: 0.0942
2024-05-25 01:20:53 [INFO]: Epoch 169 - training loss: 9212.6066, validation loss: 0.0935
2024-05-25 01:20:53 [INFO]: Epoch 170 - training loss: 9212.7238, validation loss: 0.0945
2024-05-25 01:20:53 [INFO]: Epoch 171 - training loss: 9211.8309, validation loss: 0.0944
2024-05-25 01:20:53 [INFO]: Epoch 172 - training loss: 9212.7230, validation loss: 0.0926
2024-05-25 01:20:53 [INFO]: Epoch 173 - training loss: 9212.8616, validation loss: 0.0935
2024-05-25 01:20:53 [INFO]: Epoch 174 - training loss: 9213.1228, validation loss: 0.0921
2024-05-25 01:20:53 [INFO]: Epoch 175 - training loss: 9212.5563, validation loss: 0.0915
2024-05-25 01:20:53 [INFO]: Epoch 176 - training loss: 9213.2866, validation loss: 0.0928
2024-05-25 01:20:54 [INFO]: Epoch 177 - training loss: 9210.7598, validation loss: 0.0919
2024-05-25 01:20:54 [INFO]: Epoch 178 - training loss: 9211.4429, validation loss: 0.0930
2024-05-25 01:20:54 [INFO]: Epoch 179 - training loss: 9213.3662, validation loss: 0.0925
2024-05-25 01:20:54 [INFO]: Epoch 180 - training loss: 9213.0398, validation loss: 0.0905
2024-05-25 01:20:54 [INFO]: Epoch 181 - training loss: 9213.9733, validation loss: 0.0917
2024-05-25 01:20:54 [INFO]: Epoch 182 - training loss: 9212.5174, validation loss: 0.0903
2024-05-25 01:20:54 [INFO]: Epoch 183 - training loss: 9212.8573, validation loss: 0.0901
2024-05-25 01:20:54 [INFO]: Epoch 184 - training loss: 9212.4417, validation loss: 0.0899
2024-05-25 01:20:55 [INFO]: Epoch 185 - training loss: 9211.0891, validation loss: 0.0897
2024-05-25 01:20:55 [INFO]: Epoch 186 - training loss: 9211.4748, validation loss: 0.0912
2024-05-25 01:20:55 [INFO]: Epoch 187 - training loss: 9211.3911, validation loss: 0.0891
2024-05-25 01:20:55 [INFO]: Epoch 188 - training loss: 9211.1017, validation loss: 0.0889
2024-05-25 01:20:55 [INFO]: Epoch 189 - training loss: 9209.6433, validation loss: 0.0907
2024-05-25 01:20:55 [INFO]: Epoch 190 - training loss: 9209.6236, validation loss: 0.0893
2024-05-25 01:20:55 [INFO]: Epoch 191 - training loss: 9211.1660, validation loss: 0.0886
2024-05-25 01:20:55 [INFO]: Epoch 192 - training loss: 9211.8777, validation loss: 0.0903
2024-05-25 01:20:55 [INFO]: Epoch 193 - training loss: 9209.6949, validation loss: 0.0898
2024-05-25 01:20:56 [INFO]: Epoch 194 - training loss: 9210.2288, validation loss: 0.0888
2024-05-25 01:20:56 [INFO]: Epoch 195 - training loss: 9210.7598, validation loss: 0.0884
2024-05-25 01:20:56 [INFO]: Epoch 196 - training loss: 9209.8561, validation loss: 0.0886
2024-05-25 01:20:56 [INFO]: Epoch 197 - training loss: 9209.3884, validation loss: 0.0878
2024-05-25 01:20:56 [INFO]: Epoch 198 - training loss: 9210.9915, validation loss: 0.0893
2024-05-25 01:20:56 [INFO]: Epoch 199 - training loss: 9209.3073, validation loss: 0.0867
2024-05-25 01:20:56 [INFO]: Epoch 200 - training loss: 9210.5294, validation loss: 0.0885
2024-05-25 01:20:56 [INFO]: Epoch 201 - training loss: 9209.8713, validation loss: 0.0876
2024-05-25 01:20:57 [INFO]: Epoch 202 - training loss: 9209.3135, validation loss: 0.0877
2024-05-25 01:20:57 [INFO]: Epoch 203 - training loss: 9210.8081, validation loss: 0.0876
2024-05-25 01:20:57 [INFO]: Epoch 204 - training loss: 9209.8853, validation loss: 0.0863
2024-05-25 01:20:57 [INFO]: Epoch 205 - training loss: 9209.8406, validation loss: 0.0877
2024-05-25 01:20:57 [INFO]: Epoch 206 - training loss: 9208.5091, validation loss: 0.0856
2024-05-25 01:20:57 [INFO]: Epoch 207 - training loss: 9209.8591, validation loss: 0.0875
2024-05-25 01:20:57 [INFO]: Epoch 208 - training loss: 9211.1210, validation loss: 0.0863
2024-05-25 01:20:57 [INFO]: Epoch 209 - training loss: 9208.3433, validation loss: 0.0861
2024-05-25 01:20:58 [INFO]: Epoch 210 - training loss: 9209.7529, validation loss: 0.0852
2024-05-25 01:20:58 [INFO]: Epoch 211 - training loss: 9209.1063, validation loss: 0.0867
2024-05-25 01:20:58 [INFO]: Epoch 212 - training loss: 9209.7257, validation loss: 0.0892
2024-05-25 01:20:58 [INFO]: Epoch 213 - training loss: 9207.7531, validation loss: 0.0858
2024-05-25 01:20:58 [INFO]: Epoch 214 - training loss: 9208.2885, validation loss: 0.0869
2024-05-25 01:20:58 [INFO]: Epoch 215 - training loss: 9207.7750, validation loss: 0.0856
2024-05-25 01:20:58 [INFO]: Epoch 216 - training loss: 9208.6044, validation loss: 0.0857
2024-05-25 01:20:58 [INFO]: Epoch 217 - training loss: 9209.0798, validation loss: 0.0863
2024-05-25 01:20:59 [INFO]: Epoch 218 - training loss: 9209.6144, validation loss: 0.0851
2024-05-25 01:20:59 [INFO]: Epoch 219 - training loss: 9207.7735, validation loss: 0.0845
2024-05-25 01:20:59 [INFO]: Epoch 220 - training loss: 9209.1559, validation loss: 0.0871
2024-05-25 01:20:59 [INFO]: Epoch 221 - training loss: 9208.9571, validation loss: 0.0867
2024-05-25 01:20:59 [INFO]: Epoch 222 - training loss: 9208.9523, validation loss: 0.0854
2024-05-25 01:20:59 [INFO]: Epoch 223 - training loss: 9208.2788, validation loss: 0.0865
2024-05-25 01:20:59 [INFO]: Epoch 224 - training loss: 9209.5051, validation loss: 0.0858
2024-05-25 01:20:59 [INFO]: Epoch 225 - training loss: 9210.5513, validation loss: 0.0848
2024-05-25 01:20:59 [INFO]: Epoch 226 - training loss: 9208.6481, validation loss: 0.0829
2024-05-25 01:21:00 [INFO]: Epoch 227 - training loss: 9208.5238, validation loss: 0.0835
2024-05-25 01:21:00 [INFO]: Epoch 228 - training loss: 9208.0463, validation loss: 0.0866
2024-05-25 01:21:00 [INFO]: Epoch 229 - training loss: 9208.0439, validation loss: 0.0857
2024-05-25 01:21:00 [INFO]: Epoch 230 - training loss: 9209.8555, validation loss: 0.0853
2024-05-25 01:21:00 [INFO]: Epoch 231 - training loss: 9209.1956, validation loss: 0.0863
2024-05-25 01:21:00 [INFO]: Epoch 232 - training loss: 9207.1693, validation loss: 0.0863
2024-05-25 01:21:00 [INFO]: Epoch 233 - training loss: 9209.2593, validation loss: 0.0832
2024-05-25 01:21:00 [INFO]: Epoch 234 - training loss: 9209.8213, validation loss: 0.0832
2024-05-25 01:21:01 [INFO]: Epoch 235 - training loss: 9208.0597, validation loss: 0.0852
2024-05-25 01:21:01 [INFO]: Epoch 236 - training loss: 9205.8450, validation loss: 0.0836
2024-05-25 01:21:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:21:01 [INFO]: Finished training. The best model is from epoch#226.
2024-05-25 01:21:01 [INFO]: Saved the model to augmentation_saved_results/round_0/GPVAE_ettm1/20240525_T012032/GPVAE.pypots
2024-05-25 01:21:01 [INFO]: GP-VAE on ETTm1: MAE=0.2895, MSE=0.1751
2024-05-25 01:21:01 [INFO]: Successfully saved to augmentation_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-25 01:21:01 [INFO]: Using the given device: cuda:0
2024-05-25 01:21:01 [INFO]: Model files will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T012101
2024-05-25 01:21:01 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T012101/tensorboard
2024-05-25 01:21:01 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 01:21:12 [INFO]: Epoch 001 - generator training loss: 0.4534, discriminator training loss: 0.5385, validation loss: 0.3555
2024-05-25 01:21:21 [INFO]: Epoch 002 - generator training loss: -0.0710, discriminator training loss: 0.4731, validation loss: 0.1076
2024-05-25 01:21:30 [INFO]: Epoch 003 - generator training loss: -0.1671, discriminator training loss: 0.4293, validation loss: 0.0711
2024-05-25 01:21:38 [INFO]: Epoch 004 - generator training loss: -0.1479, discriminator training loss: 0.3644, validation loss: 0.0542
2024-05-25 01:21:47 [INFO]: Epoch 005 - generator training loss: -0.1050, discriminator training loss: 0.2903, validation loss: 0.0460
2024-05-25 01:21:56 [INFO]: Epoch 006 - generator training loss: -0.0740, discriminator training loss: 0.2332, validation loss: 0.0424
2024-05-25 01:22:05 [INFO]: Epoch 007 - generator training loss: -0.0612, discriminator training loss: 0.1995, validation loss: 0.0402
2024-05-25 01:22:14 [INFO]: Epoch 008 - generator training loss: -0.0574, discriminator training loss: 0.1862, validation loss: 0.0379
2024-05-25 01:22:23 [INFO]: Epoch 009 - generator training loss: -0.0570, discriminator training loss: 0.1814, validation loss: 0.0379
2024-05-25 01:22:32 [INFO]: Epoch 010 - generator training loss: -0.0547, discriminator training loss: 0.1783, validation loss: 0.0382
2024-05-25 01:22:41 [INFO]: Epoch 011 - generator training loss: -0.0544, discriminator training loss: 0.1775, validation loss: 0.0377
2024-05-25 01:22:50 [INFO]: Epoch 012 - generator training loss: -0.0548, discriminator training loss: 0.1759, validation loss: 0.0374
2024-05-25 01:22:59 [INFO]: Epoch 013 - generator training loss: -0.0547, discriminator training loss: 0.1733, validation loss: 0.0360
2024-05-25 01:23:08 [INFO]: Epoch 014 - generator training loss: -0.0588, discriminator training loss: 0.1745, validation loss: 0.0349
2024-05-25 01:23:17 [INFO]: Epoch 015 - generator training loss: -0.0552, discriminator training loss: 0.1726, validation loss: 0.0343
2024-05-25 01:23:26 [INFO]: Epoch 016 - generator training loss: -0.0574, discriminator training loss: 0.1731, validation loss: 0.0341
2024-05-25 01:23:35 [INFO]: Epoch 017 - generator training loss: -0.0572, discriminator training loss: 0.1705, validation loss: 0.0345
2024-05-25 01:23:44 [INFO]: Epoch 018 - generator training loss: -0.0591, discriminator training loss: 0.1721, validation loss: 0.0346
2024-05-25 01:23:53 [INFO]: Epoch 019 - generator training loss: -0.0532, discriminator training loss: 0.1707, validation loss: 0.0339
2024-05-25 01:24:02 [INFO]: Epoch 020 - generator training loss: -0.0578, discriminator training loss: 0.1713, validation loss: 0.0331
2024-05-25 01:24:11 [INFO]: Epoch 021 - generator training loss: -0.0600, discriminator training loss: 0.1723, validation loss: 0.0330
2024-05-25 01:24:20 [INFO]: Epoch 022 - generator training loss: -0.0609, discriminator training loss: 0.1691, validation loss: 0.0334
2024-05-25 01:24:29 [INFO]: Epoch 023 - generator training loss: -0.0598, discriminator training loss: 0.1686, validation loss: 0.0326
2024-05-25 01:24:38 [INFO]: Epoch 024 - generator training loss: -0.0607, discriminator training loss: 0.1697, validation loss: 0.0333
2024-05-25 01:24:46 [INFO]: Epoch 025 - generator training loss: -0.0621, discriminator training loss: 0.1692, validation loss: 0.0328
2024-05-25 01:24:55 [INFO]: Epoch 026 - generator training loss: -0.0591, discriminator training loss: 0.1699, validation loss: 0.0316
2024-05-25 01:25:04 [INFO]: Epoch 027 - generator training loss: -0.0603, discriminator training loss: 0.1692, validation loss: 0.0333
2024-05-25 01:25:13 [INFO]: Epoch 028 - generator training loss: -0.0598, discriminator training loss: 0.1670, validation loss: 0.0332
2024-05-25 01:25:22 [INFO]: Epoch 029 - generator training loss: -0.0612, discriminator training loss: 0.1671, validation loss: 0.0322
2024-05-25 01:25:31 [INFO]: Epoch 030 - generator training loss: -0.0584, discriminator training loss: 0.1666, validation loss: 0.0318
2024-05-25 01:25:40 [INFO]: Epoch 031 - generator training loss: -0.0612, discriminator training loss: 0.1686, validation loss: 0.0317
2024-05-25 01:25:49 [INFO]: Epoch 032 - generator training loss: -0.0622, discriminator training loss: 0.1685, validation loss: 0.0325
2024-05-25 01:25:58 [INFO]: Epoch 033 - generator training loss: -0.0627, discriminator training loss: 0.1690, validation loss: 0.0305
2024-05-25 01:26:07 [INFO]: Epoch 034 - generator training loss: -0.0644, discriminator training loss: 0.1672, validation loss: 0.0299
2024-05-25 01:26:16 [INFO]: Epoch 035 - generator training loss: -0.0632, discriminator training loss: 0.1674, validation loss: 0.0306
2024-05-25 01:26:25 [INFO]: Epoch 036 - generator training loss: -0.0623, discriminator training loss: 0.1653, validation loss: 0.0303
2024-05-25 01:26:33 [INFO]: Epoch 037 - generator training loss: -0.0631, discriminator training loss: 0.1647, validation loss: 0.0297
2024-05-25 01:26:42 [INFO]: Epoch 038 - generator training loss: -0.0687, discriminator training loss: 0.1670, validation loss: 0.0297
2024-05-25 01:26:51 [INFO]: Epoch 039 - generator training loss: -0.0633, discriminator training loss: 0.1650, validation loss: 0.0303
2024-05-25 01:27:00 [INFO]: Epoch 040 - generator training loss: -0.0671, discriminator training loss: 0.1690, validation loss: 0.0303
2024-05-25 01:27:09 [INFO]: Epoch 041 - generator training loss: -0.0637, discriminator training loss: 0.1691, validation loss: 0.0292
2024-05-25 01:27:18 [INFO]: Epoch 042 - generator training loss: -0.0658, discriminator training loss: 0.1673, validation loss: 0.0283
2024-05-25 01:27:27 [INFO]: Epoch 043 - generator training loss: -0.0684, discriminator training loss: 0.1683, validation loss: 0.0296
2024-05-25 01:27:36 [INFO]: Epoch 044 - generator training loss: -0.0637, discriminator training loss: 0.1664, validation loss: 0.0283
2024-05-25 01:27:45 [INFO]: Epoch 045 - generator training loss: -0.0671, discriminator training loss: 0.1684, validation loss: 0.0294
2024-05-25 01:27:54 [INFO]: Epoch 046 - generator training loss: -0.0666, discriminator training loss: 0.1662, validation loss: 0.0298
2024-05-25 01:28:03 [INFO]: Epoch 047 - generator training loss: -0.0669, discriminator training loss: 0.1647, validation loss: 0.0300
2024-05-25 01:28:12 [INFO]: Epoch 048 - generator training loss: -0.0651, discriminator training loss: 0.1655, validation loss: 0.0297
2024-05-25 01:28:21 [INFO]: Epoch 049 - generator training loss: -0.0671, discriminator training loss: 0.1686, validation loss: 0.0287
2024-05-25 01:28:29 [INFO]: Epoch 050 - generator training loss: -0.0692, discriminator training loss: 0.1663, validation loss: 0.0284
2024-05-25 01:28:38 [INFO]: Epoch 051 - generator training loss: -0.0691, discriminator training loss: 0.1660, validation loss: 0.0295
2024-05-25 01:28:47 [INFO]: Epoch 052 - generator training loss: -0.0653, discriminator training loss: 0.1672, validation loss: 0.0284
2024-05-25 01:28:56 [INFO]: Epoch 053 - generator training loss: -0.0668, discriminator training loss: 0.1668, validation loss: 0.0288
2024-05-25 01:29:05 [INFO]: Epoch 054 - generator training loss: -0.0657, discriminator training loss: 0.1696, validation loss: 0.0284
2024-05-25 01:29:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:29:05 [INFO]: Finished training. The best model is from epoch#44.
2024-05-25 01:29:05 [INFO]: Saved the model to augmentation_saved_results/round_0/USGAN_ettm1/20240525_T012101/USGAN.pypots
2024-05-25 01:29:06 [INFO]: US-GAN on ETTm1: MAE=0.1576, MSE=0.0676
2024-05-25 01:29:06 [INFO]: Successfully saved to augmentation_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-25 01:29:06 [INFO]: Using the given device: cuda:0
2024-05-25 01:29:06 [INFO]: Model files will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012906
2024-05-25 01:29:06 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012906/tensorboard
2024-05-25 01:29:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 01:29:13 [INFO]: Epoch 001 - training loss: 1.3310, validation loss: 0.3290
2024-05-25 01:29:19 [INFO]: Epoch 002 - training loss: 0.9257, validation loss: 0.1281
2024-05-25 01:29:25 [INFO]: Epoch 003 - training loss: 0.7413, validation loss: 0.0610
2024-05-25 01:29:31 [INFO]: Epoch 004 - training loss: 0.6554, validation loss: 0.0526
2024-05-25 01:29:37 [INFO]: Epoch 005 - training loss: 0.6022, validation loss: 0.0445
2024-05-25 01:29:43 [INFO]: Epoch 006 - training loss: 0.5622, validation loss: 0.0377
2024-05-25 01:29:49 [INFO]: Epoch 007 - training loss: 0.5358, validation loss: 0.0354
2024-05-25 01:29:55 [INFO]: Epoch 008 - training loss: 0.5075, validation loss: 0.0332
2024-05-25 01:30:01 [INFO]: Epoch 009 - training loss: 0.5089, validation loss: 0.0311
2024-05-25 01:30:07 [INFO]: Epoch 010 - training loss: 0.4849, validation loss: 0.0324
2024-05-25 01:30:13 [INFO]: Epoch 011 - training loss: 0.4668, validation loss: 0.0294
2024-05-25 01:30:18 [INFO]: Epoch 012 - training loss: 0.4661, validation loss: 0.0309
2024-05-25 01:30:24 [INFO]: Epoch 013 - training loss: 0.4477, validation loss: 0.0317
2024-05-25 01:30:30 [INFO]: Epoch 014 - training loss: 0.4474, validation loss: 0.0283
2024-05-25 01:30:36 [INFO]: Epoch 015 - training loss: 0.4336, validation loss: 0.0274
2024-05-25 01:30:42 [INFO]: Epoch 016 - training loss: 0.4288, validation loss: 0.0290
2024-05-25 01:30:48 [INFO]: Epoch 017 - training loss: 0.4189, validation loss: 0.0272
2024-05-25 01:30:54 [INFO]: Epoch 018 - training loss: 0.4117, validation loss: 0.0270
2024-05-25 01:31:00 [INFO]: Epoch 019 - training loss: 0.4113, validation loss: 0.0259
2024-05-25 01:31:06 [INFO]: Epoch 020 - training loss: 0.4106, validation loss: 0.0259
2024-05-25 01:31:12 [INFO]: Epoch 021 - training loss: 0.4078, validation loss: 0.0264
2024-05-25 01:31:18 [INFO]: Epoch 022 - training loss: 0.4085, validation loss: 0.0260
2024-05-25 01:31:24 [INFO]: Epoch 023 - training loss: 0.4214, validation loss: 0.0261
2024-05-25 01:31:30 [INFO]: Epoch 024 - training loss: 0.4238, validation loss: 0.0265
2024-05-25 01:31:36 [INFO]: Epoch 025 - training loss: 0.4111, validation loss: 0.0271
2024-05-25 01:31:42 [INFO]: Epoch 026 - training loss: 0.4018, validation loss: 0.0265
2024-05-25 01:31:48 [INFO]: Epoch 027 - training loss: 0.4052, validation loss: 0.0257
2024-05-25 01:31:54 [INFO]: Epoch 028 - training loss: 0.4037, validation loss: 0.0250
2024-05-25 01:32:00 [INFO]: Epoch 029 - training loss: 0.3968, validation loss: 0.0257
2024-05-25 01:32:06 [INFO]: Epoch 030 - training loss: 0.3983, validation loss: 0.0252
2024-05-25 01:32:12 [INFO]: Epoch 031 - training loss: 0.4000, validation loss: 0.0253
2024-05-25 01:32:18 [INFO]: Epoch 032 - training loss: 0.4014, validation loss: 0.0252
2024-05-25 01:32:24 [INFO]: Epoch 033 - training loss: 0.3954, validation loss: 0.0254
2024-05-25 01:32:30 [INFO]: Epoch 034 - training loss: 0.3929, validation loss: 0.0254
2024-05-25 01:32:36 [INFO]: Epoch 035 - training loss: 0.3940, validation loss: 0.0252
2024-05-25 01:32:42 [INFO]: Epoch 036 - training loss: 0.3928, validation loss: 0.0255
2024-05-25 01:32:48 [INFO]: Epoch 037 - training loss: 0.3926, validation loss: 0.0250
2024-05-25 01:32:54 [INFO]: Epoch 038 - training loss: 0.3959, validation loss: 0.0252
2024-05-25 01:32:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:32:54 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 01:32:54 [INFO]: Saved the model to augmentation_saved_results/round_0/BRITS_ettm1/20240525_T012906/BRITS.pypots
2024-05-25 01:32:55 [INFO]: BRITS on ETTm1: MAE=0.1372, MSE=0.0592
2024-05-25 01:32:55 [INFO]: Successfully saved to augmentation_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-25 01:32:55 [INFO]: Using the given device: cuda:0
2024-05-25 01:32:55 [INFO]: Model files will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255
2024-05-25 01:32:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/tensorboard
2024-05-25 01:32:55 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 01:32:57 [INFO]: Epoch 001 - training loss: 1.3472, validation loss: 1.3414
2024-05-25 01:32:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch1_loss1.341376632452011.pypots
2024-05-25 01:32:57 [INFO]: Epoch 002 - training loss: 0.9800, validation loss: 1.1890
2024-05-25 01:32:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch2_loss1.1890113204717636.pypots
2024-05-25 01:32:57 [INFO]: Epoch 003 - training loss: 0.9330, validation loss: 1.1004
2024-05-25 01:32:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch3_loss1.100405529141426.pypots
2024-05-25 01:32:57 [INFO]: Epoch 004 - training loss: 0.8919, validation loss: 1.0661
2024-05-25 01:32:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch4_loss1.0660536140203476.pypots
2024-05-25 01:32:57 [INFO]: Epoch 005 - training loss: 0.8640, validation loss: 1.0501
2024-05-25 01:32:57 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch5_loss1.050080269575119.pypots
2024-05-25 01:32:58 [INFO]: Epoch 006 - training loss: 0.8899, validation loss: 1.0348
2024-05-25 01:32:58 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch6_loss1.034837394952774.pypots
2024-05-25 01:32:58 [INFO]: Epoch 007 - training loss: 0.8649, validation loss: 1.0268
2024-05-25 01:32:58 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch7_loss1.02678681910038.pypots
2024-05-25 01:32:58 [INFO]: Epoch 008 - training loss: 0.8867, validation loss: 1.0224
2024-05-25 01:32:58 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch8_loss1.0223879963159561.pypots
2024-05-25 01:32:58 [INFO]: Epoch 009 - training loss: 0.8548, validation loss: 1.0168
2024-05-25 01:32:58 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch9_loss1.0167523324489594.pypots
2024-05-25 01:32:58 [INFO]: Epoch 010 - training loss: 0.8548, validation loss: 1.0125
2024-05-25 01:32:58 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch10_loss1.0124726444482803.pypots
2024-05-25 01:32:59 [INFO]: Epoch 011 - training loss: 0.8330, validation loss: 1.0114
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch11_loss1.011409878730774.pypots
2024-05-25 01:32:59 [INFO]: Epoch 012 - training loss: 0.8639, validation loss: 1.0125
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch12_loss1.0124990940093994.pypots
2024-05-25 01:32:59 [INFO]: Epoch 013 - training loss: 0.8512, validation loss: 1.0086
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch13_loss1.0086175948381424.pypots
2024-05-25 01:32:59 [INFO]: Epoch 014 - training loss: 0.8372, validation loss: 1.0066
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch14_loss1.006623923778534.pypots
2024-05-25 01:32:59 [INFO]: Epoch 015 - training loss: 0.8307, validation loss: 1.0041
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch15_loss1.0041236281394958.pypots
2024-05-25 01:32:59 [INFO]: Epoch 016 - training loss: 0.8384, validation loss: 1.0019
2024-05-25 01:32:59 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch16_loss1.0019040554761887.pypots
2024-05-25 01:33:00 [INFO]: Epoch 017 - training loss: 0.8055, validation loss: 1.0001
2024-05-25 01:33:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch17_loss1.0000925213098526.pypots
2024-05-25 01:33:00 [INFO]: Epoch 018 - training loss: 0.8491, validation loss: 0.9984
2024-05-25 01:33:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch18_loss0.9983830004930496.pypots
2024-05-25 01:33:00 [INFO]: Epoch 019 - training loss: 0.7955, validation loss: 0.9970
2024-05-25 01:33:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch19_loss0.9969544261693954.pypots
2024-05-25 01:33:00 [INFO]: Epoch 020 - training loss: 0.7978, validation loss: 0.9931
2024-05-25 01:33:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch20_loss0.993101954460144.pypots
2024-05-25 01:33:00 [INFO]: Epoch 021 - training loss: 0.7984, validation loss: 0.9923
2024-05-25 01:33:00 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch21_loss0.9922978430986404.pypots
2024-05-25 01:33:01 [INFO]: Epoch 022 - training loss: 0.8046, validation loss: 0.9912
2024-05-25 01:33:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch22_loss0.9911669939756393.pypots
2024-05-25 01:33:01 [INFO]: Epoch 023 - training loss: 0.7927, validation loss: 0.9885
2024-05-25 01:33:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch23_loss0.9884641170501709.pypots
2024-05-25 01:33:01 [INFO]: Epoch 024 - training loss: 0.7776, validation loss: 0.9862
2024-05-25 01:33:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch24_loss0.9861717820167542.pypots
2024-05-25 01:33:01 [INFO]: Epoch 025 - training loss: 0.7836, validation loss: 0.9843
2024-05-25 01:33:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch25_loss0.9842697978019714.pypots
2024-05-25 01:33:01 [INFO]: Epoch 026 - training loss: 0.8046, validation loss: 0.9809
2024-05-25 01:33:01 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch26_loss0.9809176325798035.pypots
2024-05-25 01:33:02 [INFO]: Epoch 027 - training loss: 0.7884, validation loss: 0.9778
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch27_loss0.9778469353914261.pypots
2024-05-25 01:33:02 [INFO]: Epoch 028 - training loss: 0.7855, validation loss: 0.9751
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch28_loss0.9750873446464539.pypots
2024-05-25 01:33:02 [INFO]: Epoch 029 - training loss: 0.7748, validation loss: 0.9712
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch29_loss0.9711543023586273.pypots
2024-05-25 01:33:02 [INFO]: Epoch 030 - training loss: 0.7825, validation loss: 0.9682
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch30_loss0.9682210981845856.pypots
2024-05-25 01:33:02 [INFO]: Epoch 031 - training loss: 0.7747, validation loss: 0.9668
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch31_loss0.9667944461107254.pypots
2024-05-25 01:33:02 [INFO]: Epoch 032 - training loss: 0.7672, validation loss: 0.9616
2024-05-25 01:33:02 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch32_loss0.9616355299949646.pypots
2024-05-25 01:33:03 [INFO]: Epoch 033 - training loss: 0.7738, validation loss: 0.9589
2024-05-25 01:33:03 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch33_loss0.9589141756296158.pypots
2024-05-25 01:33:03 [INFO]: Epoch 034 - training loss: 0.7612, validation loss: 0.9548
2024-05-25 01:33:03 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch34_loss0.9547988027334213.pypots
2024-05-25 01:33:03 [INFO]: Epoch 035 - training loss: 0.7593, validation loss: 0.9516
2024-05-25 01:33:03 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch35_loss0.9516335427761078.pypots
2024-05-25 01:33:03 [INFO]: Epoch 036 - training loss: 0.7575, validation loss: 0.9495
2024-05-25 01:33:03 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch36_loss0.9494536519050598.pypots
2024-05-25 01:33:03 [INFO]: Epoch 037 - training loss: 0.7803, validation loss: 0.9467
2024-05-25 01:33:03 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch37_loss0.9467325657606125.pypots
2024-05-25 01:33:04 [INFO]: Epoch 038 - training loss: 0.7655, validation loss: 0.9431
2024-05-25 01:33:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch38_loss0.9431397616863251.pypots
2024-05-25 01:33:04 [INFO]: Epoch 039 - training loss: 0.7525, validation loss: 0.9424
2024-05-25 01:33:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch39_loss0.9423986077308655.pypots
2024-05-25 01:33:04 [INFO]: Epoch 040 - training loss: 0.7636, validation loss: 0.9381
2024-05-25 01:33:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch40_loss0.9380663633346558.pypots
2024-05-25 01:33:04 [INFO]: Epoch 041 - training loss: 0.7614, validation loss: 0.9367
2024-05-25 01:33:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch41_loss0.9366768002510071.pypots
2024-05-25 01:33:04 [INFO]: Epoch 042 - training loss: 0.7483, validation loss: 0.9335
2024-05-25 01:33:04 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch42_loss0.9335037171840668.pypots
2024-05-25 01:33:05 [INFO]: Epoch 043 - training loss: 0.7566, validation loss: 0.9324
2024-05-25 01:33:05 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch43_loss0.9323555827140808.pypots
2024-05-25 01:33:05 [INFO]: Epoch 044 - training loss: 0.7586, validation loss: 0.9340
2024-05-25 01:33:05 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch44_loss0.9339622557163239.pypots
2024-05-25 01:33:05 [INFO]: Epoch 045 - training loss: 0.7746, validation loss: 0.9302
2024-05-25 01:33:05 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch45_loss0.930152952671051.pypots
2024-05-25 01:33:05 [INFO]: Epoch 046 - training loss: 0.7663, validation loss: 0.9283
2024-05-25 01:33:05 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch46_loss0.9283044189214706.pypots
2024-05-25 01:33:05 [INFO]: Epoch 047 - training loss: 0.7502, validation loss: 0.9239
2024-05-25 01:33:05 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch47_loss0.9238762259483337.pypots
2024-05-25 01:33:06 [INFO]: Epoch 048 - training loss: 0.7344, validation loss: 0.9224
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch48_loss0.9223977774381638.pypots
2024-05-25 01:33:06 [INFO]: Epoch 049 - training loss: 0.7520, validation loss: 0.9211
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch49_loss0.9210895150899887.pypots
2024-05-25 01:33:06 [INFO]: Epoch 050 - training loss: 0.7487, validation loss: 0.9218
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch50_loss0.9218015223741531.pypots
2024-05-25 01:33:06 [INFO]: Epoch 051 - training loss: 0.7351, validation loss: 0.9180
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch51_loss0.9180314242839813.pypots
2024-05-25 01:33:06 [INFO]: Epoch 052 - training loss: 0.7652, validation loss: 0.9138
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch52_loss0.9137775748968124.pypots
2024-05-25 01:33:06 [INFO]: Epoch 053 - training loss: 0.7586, validation loss: 0.9152
2024-05-25 01:33:06 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch53_loss0.915233314037323.pypots
2024-05-25 01:33:07 [INFO]: Epoch 054 - training loss: 0.7464, validation loss: 0.9154
2024-05-25 01:33:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch54_loss0.9154125899076462.pypots
2024-05-25 01:33:07 [INFO]: Epoch 055 - training loss: 0.7431, validation loss: 0.9118
2024-05-25 01:33:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch55_loss0.9117958098649979.pypots
2024-05-25 01:33:07 [INFO]: Epoch 056 - training loss: 0.7779, validation loss: 0.9116
2024-05-25 01:33:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch56_loss0.9116132110357285.pypots
2024-05-25 01:33:07 [INFO]: Epoch 057 - training loss: 0.7531, validation loss: 0.9093
2024-05-25 01:33:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch57_loss0.9092673063278198.pypots
2024-05-25 01:33:07 [INFO]: Epoch 058 - training loss: 0.7347, validation loss: 0.9119
2024-05-25 01:33:07 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch58_loss0.9118794798851013.pypots
2024-05-25 01:33:08 [INFO]: Epoch 059 - training loss: 0.7406, validation loss: 0.9090
2024-05-25 01:33:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch59_loss0.9089963138103485.pypots
2024-05-25 01:33:08 [INFO]: Epoch 060 - training loss: 0.7830, validation loss: 0.9113
2024-05-25 01:33:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch60_loss0.9112974554300308.pypots
2024-05-25 01:33:08 [INFO]: Epoch 061 - training loss: 0.7449, validation loss: 0.9089
2024-05-25 01:33:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch61_loss0.9088930785655975.pypots
2024-05-25 01:33:08 [INFO]: Epoch 062 - training loss: 0.7485, validation loss: 0.9088
2024-05-25 01:33:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch62_loss0.9087879508733749.pypots
2024-05-25 01:33:08 [INFO]: Epoch 063 - training loss: 0.7203, validation loss: 0.9063
2024-05-25 01:33:08 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch63_loss0.906261220574379.pypots
2024-05-25 01:33:09 [INFO]: Epoch 064 - training loss: 0.7604, validation loss: 0.9056
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch64_loss0.9056232124567032.pypots
2024-05-25 01:33:09 [INFO]: Epoch 065 - training loss: 0.7434, validation loss: 0.9034
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch65_loss0.9033952057361603.pypots
2024-05-25 01:33:09 [INFO]: Epoch 066 - training loss: 0.7896, validation loss: 0.9026
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch66_loss0.9026426374912262.pypots
2024-05-25 01:33:09 [INFO]: Epoch 067 - training loss: 0.7514, validation loss: 0.9022
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch67_loss0.9022158831357956.pypots
2024-05-25 01:33:09 [INFO]: Epoch 068 - training loss: 0.7429, validation loss: 0.9024
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch68_loss0.9024186134338379.pypots
2024-05-25 01:33:09 [INFO]: Epoch 069 - training loss: 0.7842, validation loss: 0.9048
2024-05-25 01:33:09 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch69_loss0.9048488140106201.pypots
2024-05-25 01:33:10 [INFO]: Epoch 070 - training loss: 0.7663, validation loss: 0.9032
2024-05-25 01:33:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch70_loss0.9032283425331116.pypots
2024-05-25 01:33:10 [INFO]: Epoch 071 - training loss: 0.7227, validation loss: 0.9047
2024-05-25 01:33:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch71_loss0.9047278612852097.pypots
2024-05-25 01:33:10 [INFO]: Epoch 072 - training loss: 0.7672, validation loss: 0.9041
2024-05-25 01:33:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch72_loss0.9040502309799194.pypots
2024-05-25 01:33:10 [INFO]: Epoch 073 - training loss: 0.7524, validation loss: 0.9075
2024-05-25 01:33:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch73_loss0.9075040370225906.pypots
2024-05-25 01:33:10 [INFO]: Epoch 074 - training loss: 0.7364, validation loss: 0.9025
2024-05-25 01:33:10 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch74_loss0.9024515748023987.pypots
2024-05-25 01:33:11 [INFO]: Epoch 075 - training loss: 0.7383, validation loss: 0.9040
2024-05-25 01:33:11 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch75_loss0.903976783156395.pypots
2024-05-25 01:33:11 [INFO]: Epoch 076 - training loss: 0.7493, validation loss: 0.9082
2024-05-25 01:33:11 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch76_loss0.9081737995147705.pypots
2024-05-25 01:33:11 [INFO]: Epoch 077 - training loss: 0.7370, validation loss: 0.9027
2024-05-25 01:33:11 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN_epoch77_loss0.9026678204536438.pypots
2024-05-25 01:33:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:33:11 [INFO]: Finished training. The best model is from epoch#67.
2024-05-25 01:33:11 [INFO]: Saved the model to augmentation_saved_results/round_0/MRNN_ettm1/20240525_T013255/MRNN.pypots
2024-05-25 01:33:11 [INFO]: MRNN on ETTm1: MAE=0.7965, MSE=1.4965
2024-05-25 01:33:11 [INFO]: Successfully saved to augmentation_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-25 01:33:11 [INFO]: Using the given device: cpu
2024-05-25 01:33:11 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-25 01:33:11 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-25 01:33:11 [INFO]: Successfully saved to augmentation_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-25 01:33:11 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-25 01:33:11 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-25 01:33:11 [INFO]: Successfully saved to augmentation_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-25 01:33:11 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-25 01:33:11 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-25 01:33:11 [INFO]: Successfully saved to augmentation_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-25 01:33:11 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 01:33:11 [INFO]: Using the given device: cuda:0
2024-05-25 01:33:11 [INFO]: Model files will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T013311
2024-05-25 01:33:11 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T013311/tensorboard
2024-05-25 01:33:11 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 01:33:12 [INFO]: Epoch 001 - training loss: 1.1534, validation loss: 0.3047
2024-05-25 01:33:13 [INFO]: Epoch 002 - training loss: 0.8681, validation loss: 0.1517
2024-05-25 01:33:13 [INFO]: Epoch 003 - training loss: 0.7772, validation loss: 0.1277
2024-05-25 01:33:14 [INFO]: Epoch 004 - training loss: 0.7165, validation loss: 0.0929
2024-05-25 01:33:14 [INFO]: Epoch 005 - training loss: 0.6868, validation loss: 0.0819
2024-05-25 01:33:15 [INFO]: Epoch 006 - training loss: 0.6706, validation loss: 0.0826
2024-05-25 01:33:15 [INFO]: Epoch 007 - training loss: 0.6553, validation loss: 0.0767
2024-05-25 01:33:16 [INFO]: Epoch 008 - training loss: 0.6241, validation loss: 0.0912
2024-05-25 01:33:16 [INFO]: Epoch 009 - training loss: 0.6133, validation loss: 0.0731
2024-05-25 01:33:17 [INFO]: Epoch 010 - training loss: 0.5827, validation loss: 0.0772
2024-05-25 01:33:17 [INFO]: Epoch 011 - training loss: 0.5802, validation loss: 0.0620
2024-05-25 01:33:18 [INFO]: Epoch 012 - training loss: 0.5776, validation loss: 0.0638
2024-05-25 01:33:18 [INFO]: Epoch 013 - training loss: 0.5571, validation loss: 0.0636
2024-05-25 01:33:19 [INFO]: Epoch 014 - training loss: 0.5477, validation loss: 0.0617
2024-05-25 01:33:19 [INFO]: Epoch 015 - training loss: 0.5412, validation loss: 0.0613
2024-05-25 01:33:20 [INFO]: Epoch 016 - training loss: 0.5348, validation loss: 0.0602
2024-05-25 01:33:20 [INFO]: Epoch 017 - training loss: 0.5207, validation loss: 0.0650
2024-05-25 01:33:21 [INFO]: Epoch 018 - training loss: 0.5200, validation loss: 0.0749
2024-05-25 01:33:21 [INFO]: Epoch 019 - training loss: 0.5312, validation loss: 0.0513
2024-05-25 01:33:22 [INFO]: Epoch 020 - training loss: 0.5014, validation loss: 0.0618
2024-05-25 01:33:22 [INFO]: Epoch 021 - training loss: 0.4870, validation loss: 0.0555
2024-05-25 01:33:23 [INFO]: Epoch 022 - training loss: 0.4769, validation loss: 0.0652
2024-05-25 01:33:23 [INFO]: Epoch 023 - training loss: 0.4858, validation loss: 0.0621
2024-05-25 01:33:24 [INFO]: Epoch 024 - training loss: 0.4652, validation loss: 0.0488
2024-05-25 01:33:24 [INFO]: Epoch 025 - training loss: 0.4474, validation loss: 0.0438
2024-05-25 01:33:25 [INFO]: Epoch 026 - training loss: 0.4708, validation loss: 0.0605
2024-05-25 01:33:25 [INFO]: Epoch 027 - training loss: 0.4538, validation loss: 0.0475
2024-05-25 01:33:26 [INFO]: Epoch 028 - training loss: 0.4487, validation loss: 0.0531
2024-05-25 01:33:26 [INFO]: Epoch 029 - training loss: 0.4240, validation loss: 0.0446
2024-05-25 01:33:27 [INFO]: Epoch 030 - training loss: 0.4394, validation loss: 0.0541
2024-05-25 01:33:27 [INFO]: Epoch 031 - training loss: 0.4116, validation loss: 0.0520
2024-05-25 01:33:28 [INFO]: Epoch 032 - training loss: 0.4064, validation loss: 0.0423
2024-05-25 01:33:28 [INFO]: Epoch 033 - training loss: 0.4104, validation loss: 0.0604
2024-05-25 01:33:29 [INFO]: Epoch 034 - training loss: 0.4140, validation loss: 0.0454
2024-05-25 01:33:29 [INFO]: Epoch 035 - training loss: 0.4053, validation loss: 0.0541
2024-05-25 01:33:30 [INFO]: Epoch 036 - training loss: 0.4105, validation loss: 0.0430
2024-05-25 01:33:30 [INFO]: Epoch 037 - training loss: 0.3965, validation loss: 0.0470
2024-05-25 01:33:31 [INFO]: Epoch 038 - training loss: 0.3850, validation loss: 0.0449
2024-05-25 01:33:31 [INFO]: Epoch 039 - training loss: 0.3827, validation loss: 0.0503
2024-05-25 01:33:32 [INFO]: Epoch 040 - training loss: 0.3769, validation loss: 0.0425
2024-05-25 01:33:32 [INFO]: Epoch 041 - training loss: 0.3863, validation loss: 0.0432
2024-05-25 01:33:33 [INFO]: Epoch 042 - training loss: 0.3890, validation loss: 0.0558
2024-05-25 01:33:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:33:33 [INFO]: Finished training. The best model is from epoch#32.
2024-05-25 01:33:33 [INFO]: Saved the model to augmentation_saved_results/round_1/SAITS_ettm1/20240525_T013311/SAITS.pypots
2024-05-25 01:33:33 [INFO]: SAITS on ETTm1: MAE=0.1603, MSE=0.0499
2024-05-25 01:33:33 [INFO]: Successfully saved to augmentation_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-25 01:33:33 [INFO]: Using the given device: cuda:0
2024-05-25 01:33:33 [INFO]: Model files will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T013333
2024-05-25 01:33:33 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T013333/tensorboard
2024-05-25 01:33:33 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 01:33:33 [INFO]: Epoch 001 - training loss: 1.2215, validation loss: 0.3714
2024-05-25 01:33:34 [INFO]: Epoch 002 - training loss: 0.7732, validation loss: 0.1930
2024-05-25 01:33:34 [INFO]: Epoch 003 - training loss: 0.6335, validation loss: 0.1350
2024-05-25 01:33:34 [INFO]: Epoch 004 - training loss: 0.5753, validation loss: 0.1159
2024-05-25 01:33:34 [INFO]: Epoch 005 - training loss: 0.5243, validation loss: 0.0969
2024-05-25 01:33:34 [INFO]: Epoch 006 - training loss: 0.4857, validation loss: 0.0835
2024-05-25 01:33:35 [INFO]: Epoch 007 - training loss: 0.4547, validation loss: 0.0743
2024-05-25 01:33:35 [INFO]: Epoch 008 - training loss: 0.4361, validation loss: 0.0766
2024-05-25 01:33:35 [INFO]: Epoch 009 - training loss: 0.4286, validation loss: 0.0718
2024-05-25 01:33:35 [INFO]: Epoch 010 - training loss: 0.4186, validation loss: 0.0732
2024-05-25 01:33:35 [INFO]: Epoch 011 - training loss: 0.4076, validation loss: 0.0598
2024-05-25 01:33:36 [INFO]: Epoch 012 - training loss: 0.3943, validation loss: 0.0653
2024-05-25 01:33:36 [INFO]: Epoch 013 - training loss: 0.3818, validation loss: 0.0533
2024-05-25 01:33:36 [INFO]: Epoch 014 - training loss: 0.3817, validation loss: 0.0497
2024-05-25 01:33:36 [INFO]: Epoch 015 - training loss: 0.3670, validation loss: 0.0542
2024-05-25 01:33:37 [INFO]: Epoch 016 - training loss: 0.3644, validation loss: 0.0476
2024-05-25 01:33:37 [INFO]: Epoch 017 - training loss: 0.3574, validation loss: 0.0501
2024-05-25 01:33:37 [INFO]: Epoch 018 - training loss: 0.3507, validation loss: 0.0513
2024-05-25 01:33:37 [INFO]: Epoch 019 - training loss: 0.3452, validation loss: 0.0450
2024-05-25 01:33:37 [INFO]: Epoch 020 - training loss: 0.3391, validation loss: 0.0458
2024-05-25 01:33:38 [INFO]: Epoch 021 - training loss: 0.3384, validation loss: 0.0477
2024-05-25 01:33:38 [INFO]: Epoch 022 - training loss: 0.3350, validation loss: 0.0455
2024-05-25 01:33:38 [INFO]: Epoch 023 - training loss: 0.3279, validation loss: 0.0410
2024-05-25 01:33:38 [INFO]: Epoch 024 - training loss: 0.3211, validation loss: 0.0493
2024-05-25 01:33:39 [INFO]: Epoch 025 - training loss: 0.3205, validation loss: 0.0497
2024-05-25 01:33:39 [INFO]: Epoch 026 - training loss: 0.3317, validation loss: 0.0488
2024-05-25 01:33:39 [INFO]: Epoch 027 - training loss: 0.3157, validation loss: 0.0416
2024-05-25 01:33:39 [INFO]: Epoch 028 - training loss: 0.3097, validation loss: 0.0368
2024-05-25 01:33:39 [INFO]: Epoch 029 - training loss: 0.3040, validation loss: 0.0377
2024-05-25 01:33:40 [INFO]: Epoch 030 - training loss: 0.3014, validation loss: 0.0417
2024-05-25 01:33:40 [INFO]: Epoch 031 - training loss: 0.3018, validation loss: 0.0383
2024-05-25 01:33:40 [INFO]: Epoch 032 - training loss: 0.2943, validation loss: 0.0384
2024-05-25 01:33:40 [INFO]: Epoch 033 - training loss: 0.2962, validation loss: 0.0363
2024-05-25 01:33:40 [INFO]: Epoch 034 - training loss: 0.2982, validation loss: 0.0400
2024-05-25 01:33:41 [INFO]: Epoch 035 - training loss: 0.2909, validation loss: 0.0349
2024-05-25 01:33:41 [INFO]: Epoch 036 - training loss: 0.2817, validation loss: 0.0382
2024-05-25 01:33:41 [INFO]: Epoch 037 - training loss: 0.2840, validation loss: 0.0378
2024-05-25 01:33:41 [INFO]: Epoch 038 - training loss: 0.2842, validation loss: 0.0398
2024-05-25 01:33:42 [INFO]: Epoch 039 - training loss: 0.2778, validation loss: 0.0355
2024-05-25 01:33:42 [INFO]: Epoch 040 - training loss: 0.2702, validation loss: 0.0343
2024-05-25 01:33:42 [INFO]: Epoch 041 - training loss: 0.2694, validation loss: 0.0325
2024-05-25 01:33:42 [INFO]: Epoch 042 - training loss: 0.2656, validation loss: 0.0372
2024-05-25 01:33:42 [INFO]: Epoch 043 - training loss: 0.2676, validation loss: 0.0321
2024-05-25 01:33:43 [INFO]: Epoch 044 - training loss: 0.2617, validation loss: 0.0318
2024-05-25 01:33:43 [INFO]: Epoch 045 - training loss: 0.2686, validation loss: 0.0300
2024-05-25 01:33:43 [INFO]: Epoch 046 - training loss: 0.2604, validation loss: 0.0295
2024-05-25 01:33:43 [INFO]: Epoch 047 - training loss: 0.2614, validation loss: 0.0285
2024-05-25 01:33:44 [INFO]: Epoch 048 - training loss: 0.2535, validation loss: 0.0359
2024-05-25 01:33:44 [INFO]: Epoch 049 - training loss: 0.2564, validation loss: 0.0303
2024-05-25 01:33:44 [INFO]: Epoch 050 - training loss: 0.2558, validation loss: 0.0359
2024-05-25 01:33:44 [INFO]: Epoch 051 - training loss: 0.2584, validation loss: 0.0318
2024-05-25 01:33:44 [INFO]: Epoch 052 - training loss: 0.2475, validation loss: 0.0276
2024-05-25 01:33:45 [INFO]: Epoch 053 - training loss: 0.2461, validation loss: 0.0328
2024-05-25 01:33:45 [INFO]: Epoch 054 - training loss: 0.2474, validation loss: 0.0328
2024-05-25 01:33:45 [INFO]: Epoch 055 - training loss: 0.2445, validation loss: 0.0278
2024-05-25 01:33:45 [INFO]: Epoch 056 - training loss: 0.2392, validation loss: 0.0276
2024-05-25 01:33:45 [INFO]: Epoch 057 - training loss: 0.2358, validation loss: 0.0286
2024-05-25 01:33:46 [INFO]: Epoch 058 - training loss: 0.2385, validation loss: 0.0271
2024-05-25 01:33:46 [INFO]: Epoch 059 - training loss: 0.2323, validation loss: 0.0312
2024-05-25 01:33:46 [INFO]: Epoch 060 - training loss: 0.2340, validation loss: 0.0296
2024-05-25 01:33:46 [INFO]: Epoch 061 - training loss: 0.2359, validation loss: 0.0258
2024-05-25 01:33:47 [INFO]: Epoch 062 - training loss: 0.2351, validation loss: 0.0276
2024-05-25 01:33:47 [INFO]: Epoch 063 - training loss: 0.2438, validation loss: 0.0342
2024-05-25 01:33:47 [INFO]: Epoch 064 - training loss: 0.2459, validation loss: 0.0285
2024-05-25 01:33:47 [INFO]: Epoch 065 - training loss: 0.2288, validation loss: 0.0258
2024-05-25 01:33:47 [INFO]: Epoch 066 - training loss: 0.2260, validation loss: 0.0279
2024-05-25 01:33:48 [INFO]: Epoch 067 - training loss: 0.2277, validation loss: 0.0267
2024-05-25 01:33:48 [INFO]: Epoch 068 - training loss: 0.2337, validation loss: 0.0277
2024-05-25 01:33:48 [INFO]: Epoch 069 - training loss: 0.2322, validation loss: 0.0320
2024-05-25 01:33:48 [INFO]: Epoch 070 - training loss: 0.2270, validation loss: 0.0289
2024-05-25 01:33:48 [INFO]: Epoch 071 - training loss: 0.2309, validation loss: 0.0285
2024-05-25 01:33:49 [INFO]: Epoch 072 - training loss: 0.2406, validation loss: 0.0262
2024-05-25 01:33:49 [INFO]: Epoch 073 - training loss: 0.2284, validation loss: 0.0313
2024-05-25 01:33:49 [INFO]: Epoch 074 - training loss: 0.2334, validation loss: 0.0273
2024-05-25 01:33:49 [INFO]: Epoch 075 - training loss: 0.2337, validation loss: 0.0267
2024-05-25 01:33:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:33:49 [INFO]: Finished training. The best model is from epoch#65.
2024-05-25 01:33:49 [INFO]: Saved the model to augmentation_saved_results/round_1/Transformer_ettm1/20240525_T013333/Transformer.pypots
2024-05-25 01:33:49 [INFO]: Transformer on ETTm1: MAE=0.1499, MSE=0.0413
2024-05-25 01:33:49 [INFO]: Successfully saved to augmentation_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-25 01:33:49 [INFO]: Using the given device: cuda:0
2024-05-25 01:33:49 [INFO]: Model files will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T013349
2024-05-25 01:33:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T013349/tensorboard
2024-05-25 01:33:50 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 01:33:50 [INFO]: Epoch 001 - training loss: 0.1698, validation loss: 0.0597
2024-05-25 01:33:50 [INFO]: Epoch 002 - training loss: 0.0744, validation loss: 0.0416
2024-05-25 01:33:50 [INFO]: Epoch 003 - training loss: 0.0599, validation loss: 0.0371
2024-05-25 01:33:50 [INFO]: Epoch 004 - training loss: 0.0572, validation loss: 0.0391
2024-05-25 01:33:51 [INFO]: Epoch 005 - training loss: 0.0549, validation loss: 0.0355
2024-05-25 01:33:51 [INFO]: Epoch 006 - training loss: 0.0532, validation loss: 0.0355
2024-05-25 01:33:51 [INFO]: Epoch 007 - training loss: 0.0560, validation loss: 0.0351
2024-05-25 01:33:51 [INFO]: Epoch 008 - training loss: 0.0571, validation loss: 0.0344
2024-05-25 01:33:52 [INFO]: Epoch 009 - training loss: 0.0540, validation loss: 0.0351
2024-05-25 01:33:52 [INFO]: Epoch 010 - training loss: 0.0529, validation loss: 0.0347
2024-05-25 01:33:52 [INFO]: Epoch 011 - training loss: 0.0506, validation loss: 0.0327
2024-05-25 01:33:52 [INFO]: Epoch 012 - training loss: 0.0511, validation loss: 0.0336
2024-05-25 01:33:52 [INFO]: Epoch 013 - training loss: 0.0497, validation loss: 0.0323
2024-05-25 01:33:53 [INFO]: Epoch 014 - training loss: 0.0473, validation loss: 0.0319
2024-05-25 01:33:53 [INFO]: Epoch 015 - training loss: 0.0506, validation loss: 0.0326
2024-05-25 01:33:53 [INFO]: Epoch 016 - training loss: 0.0538, validation loss: 0.0334
2024-05-25 01:33:53 [INFO]: Epoch 017 - training loss: 0.0490, validation loss: 0.0333
2024-05-25 01:33:53 [INFO]: Epoch 018 - training loss: 0.0477, validation loss: 0.0308
2024-05-25 01:33:54 [INFO]: Epoch 019 - training loss: 0.0453, validation loss: 0.0311
2024-05-25 01:33:54 [INFO]: Epoch 020 - training loss: 0.0467, validation loss: 0.0313
2024-05-25 01:33:54 [INFO]: Epoch 021 - training loss: 0.0468, validation loss: 0.0298
2024-05-25 01:33:54 [INFO]: Epoch 022 - training loss: 0.0428, validation loss: 0.0310
2024-05-25 01:33:54 [INFO]: Epoch 023 - training loss: 0.0453, validation loss: 0.0298
2024-05-25 01:33:55 [INFO]: Epoch 024 - training loss: 0.0447, validation loss: 0.0287
2024-05-25 01:33:55 [INFO]: Epoch 025 - training loss: 0.0439, validation loss: 0.0291
2024-05-25 01:33:55 [INFO]: Epoch 026 - training loss: 0.0431, validation loss: 0.0291
2024-05-25 01:33:55 [INFO]: Epoch 027 - training loss: 0.0441, validation loss: 0.0287
2024-05-25 01:33:56 [INFO]: Epoch 028 - training loss: 0.0450, validation loss: 0.0291
2024-05-25 01:33:56 [INFO]: Epoch 029 - training loss: 0.0445, validation loss: 0.0308
2024-05-25 01:33:56 [INFO]: Epoch 030 - training loss: 0.0472, validation loss: 0.0307
2024-05-25 01:33:56 [INFO]: Epoch 031 - training loss: 0.0428, validation loss: 0.0311
2024-05-25 01:33:56 [INFO]: Epoch 032 - training loss: 0.0429, validation loss: 0.0289
2024-05-25 01:33:57 [INFO]: Epoch 033 - training loss: 0.0403, validation loss: 0.0288
2024-05-25 01:33:57 [INFO]: Epoch 034 - training loss: 0.0406, validation loss: 0.0289
2024-05-25 01:33:57 [INFO]: Epoch 035 - training loss: 0.0420, validation loss: 0.0279
2024-05-25 01:33:57 [INFO]: Epoch 036 - training loss: 0.0422, validation loss: 0.0283
2024-05-25 01:33:57 [INFO]: Epoch 037 - training loss: 0.0455, validation loss: 0.0285
2024-05-25 01:33:58 [INFO]: Epoch 038 - training loss: 0.0452, validation loss: 0.0318
2024-05-25 01:33:58 [INFO]: Epoch 039 - training loss: 0.0431, validation loss: 0.0284
2024-05-25 01:33:58 [INFO]: Epoch 040 - training loss: 0.0446, validation loss: 0.0277
2024-05-25 01:33:58 [INFO]: Epoch 041 - training loss: 0.0403, validation loss: 0.0288
2024-05-25 01:33:58 [INFO]: Epoch 042 - training loss: 0.0415, validation loss: 0.0285
2024-05-25 01:33:59 [INFO]: Epoch 043 - training loss: 0.0433, validation loss: 0.0291
2024-05-25 01:33:59 [INFO]: Epoch 044 - training loss: 0.0435, validation loss: 0.0282
2024-05-25 01:33:59 [INFO]: Epoch 045 - training loss: 0.0414, validation loss: 0.0295
2024-05-25 01:33:59 [INFO]: Epoch 046 - training loss: 0.0418, validation loss: 0.0275
2024-05-25 01:34:00 [INFO]: Epoch 047 - training loss: 0.0459, validation loss: 0.0289
2024-05-25 01:34:00 [INFO]: Epoch 048 - training loss: 0.0517, validation loss: 0.0352
2024-05-25 01:34:00 [INFO]: Epoch 049 - training loss: 0.0596, validation loss: 0.0308
2024-05-25 01:34:00 [INFO]: Epoch 050 - training loss: 0.0441, validation loss: 0.0335
2024-05-25 01:34:00 [INFO]: Epoch 051 - training loss: 0.0478, validation loss: 0.0313
2024-05-25 01:34:01 [INFO]: Epoch 052 - training loss: 0.0476, validation loss: 0.0298
2024-05-25 01:34:01 [INFO]: Epoch 053 - training loss: 0.0417, validation loss: 0.0274
2024-05-25 01:34:01 [INFO]: Epoch 054 - training loss: 0.0386, validation loss: 0.0273
2024-05-25 01:34:01 [INFO]: Epoch 055 - training loss: 0.0396, validation loss: 0.0277
2024-05-25 01:34:01 [INFO]: Epoch 056 - training loss: 0.0413, validation loss: 0.0278
2024-05-25 01:34:02 [INFO]: Epoch 057 - training loss: 0.0399, validation loss: 0.0275
2024-05-25 01:34:02 [INFO]: Epoch 058 - training loss: 0.0409, validation loss: 0.0272
2024-05-25 01:34:02 [INFO]: Epoch 059 - training loss: 0.0421, validation loss: 0.0279
2024-05-25 01:34:02 [INFO]: Epoch 060 - training loss: 0.0402, validation loss: 0.0273
2024-05-25 01:34:03 [INFO]: Epoch 061 - training loss: 0.0369, validation loss: 0.0264
2024-05-25 01:34:03 [INFO]: Epoch 062 - training loss: 0.0375, validation loss: 0.0265
2024-05-25 01:34:03 [INFO]: Epoch 063 - training loss: 0.0369, validation loss: 0.0263
2024-05-25 01:34:03 [INFO]: Epoch 064 - training loss: 0.0409, validation loss: 0.0259
2024-05-25 01:34:03 [INFO]: Epoch 065 - training loss: 0.0401, validation loss: 0.0263
2024-05-25 01:34:04 [INFO]: Epoch 066 - training loss: 0.0401, validation loss: 0.0301
2024-05-25 01:34:04 [INFO]: Epoch 067 - training loss: 0.0369, validation loss: 0.0257
2024-05-25 01:34:04 [INFO]: Epoch 068 - training loss: 0.0364, validation loss: 0.0260
2024-05-25 01:34:04 [INFO]: Epoch 069 - training loss: 0.0356, validation loss: 0.0261
2024-05-25 01:34:04 [INFO]: Epoch 070 - training loss: 0.0388, validation loss: 0.0338
2024-05-25 01:34:05 [INFO]: Epoch 071 - training loss: 0.0484, validation loss: 0.0301
2024-05-25 01:34:05 [INFO]: Epoch 072 - training loss: 0.0385, validation loss: 0.0268
2024-05-25 01:34:05 [INFO]: Epoch 073 - training loss: 0.0364, validation loss: 0.0255
2024-05-25 01:34:05 [INFO]: Epoch 074 - training loss: 0.0362, validation loss: 0.0259
2024-05-25 01:34:05 [INFO]: Epoch 075 - training loss: 0.0368, validation loss: 0.0267
2024-05-25 01:34:06 [INFO]: Epoch 076 - training loss: 0.0375, validation loss: 0.0258
2024-05-25 01:34:06 [INFO]: Epoch 077 - training loss: 0.0371, validation loss: 0.0263
2024-05-25 01:34:06 [INFO]: Epoch 078 - training loss: 0.0361, validation loss: 0.0247
2024-05-25 01:34:06 [INFO]: Epoch 079 - training loss: 0.0344, validation loss: 0.0257
2024-05-25 01:34:07 [INFO]: Epoch 080 - training loss: 0.0346, validation loss: 0.0245
2024-05-25 01:34:07 [INFO]: Epoch 081 - training loss: 0.0357, validation loss: 0.0242
2024-05-25 01:34:07 [INFO]: Epoch 082 - training loss: 0.0352, validation loss: 0.0252
2024-05-25 01:34:07 [INFO]: Epoch 083 - training loss: 0.0443, validation loss: 0.0260
2024-05-25 01:34:07 [INFO]: Epoch 084 - training loss: 0.0430, validation loss: 0.0279
2024-05-25 01:34:08 [INFO]: Epoch 085 - training loss: 0.0411, validation loss: 0.0280
2024-05-25 01:34:08 [INFO]: Epoch 086 - training loss: 0.0372, validation loss: 0.0260
2024-05-25 01:34:08 [INFO]: Epoch 087 - training loss: 0.0365, validation loss: 0.0254
2024-05-25 01:34:08 [INFO]: Epoch 088 - training loss: 0.0357, validation loss: 0.0249
2024-05-25 01:34:08 [INFO]: Epoch 089 - training loss: 0.0336, validation loss: 0.0243
2024-05-25 01:34:09 [INFO]: Epoch 090 - training loss: 0.0339, validation loss: 0.0242
2024-05-25 01:34:09 [INFO]: Epoch 091 - training loss: 0.0329, validation loss: 0.0238
2024-05-25 01:34:09 [INFO]: Epoch 092 - training loss: 0.0334, validation loss: 0.0236
2024-05-25 01:34:09 [INFO]: Epoch 093 - training loss: 0.0327, validation loss: 0.0240
2024-05-25 01:34:09 [INFO]: Epoch 094 - training loss: 0.0335, validation loss: 0.0236
2024-05-25 01:34:10 [INFO]: Epoch 095 - training loss: 0.0336, validation loss: 0.0241
2024-05-25 01:34:10 [INFO]: Epoch 096 - training loss: 0.0344, validation loss: 0.0241
2024-05-25 01:34:10 [INFO]: Epoch 097 - training loss: 0.0335, validation loss: 0.0241
2024-05-25 01:34:10 [INFO]: Epoch 098 - training loss: 0.0338, validation loss: 0.0252
2024-05-25 01:34:10 [INFO]: Epoch 099 - training loss: 0.0351, validation loss: 0.0246
2024-05-25 01:34:11 [INFO]: Epoch 100 - training loss: 0.0340, validation loss: 0.0245
2024-05-25 01:34:11 [INFO]: Epoch 101 - training loss: 0.0343, validation loss: 0.0243
2024-05-25 01:34:11 [INFO]: Epoch 102 - training loss: 0.0338, validation loss: 0.0237
2024-05-25 01:34:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:34:11 [INFO]: Finished training. The best model is from epoch#92.
2024-05-25 01:34:11 [INFO]: Saved the model to augmentation_saved_results/round_1/TimesNet_ettm1/20240525_T013349/TimesNet.pypots
2024-05-25 01:34:11 [INFO]: TimesNet on ETTm1: MAE=0.1123, MSE=0.0268
2024-05-25 01:34:11 [INFO]: Successfully saved to augmentation_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-25 01:34:11 [INFO]: Using the given device: cuda:0
2024-05-25 01:34:11 [INFO]: Model files will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411
2024-05-25 01:34:11 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/tensorboard
2024-05-25 01:34:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 01:34:13 [INFO]: Epoch 001 - training loss: 0.6490, validation loss: 0.4623
2024-05-25 01:34:13 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch1_loss0.462269552052021.pypots
2024-05-25 01:34:15 [INFO]: Epoch 002 - training loss: 0.3903, validation loss: 0.3704
2024-05-25 01:34:15 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch2_loss0.37042804062366486.pypots
2024-05-25 01:34:17 [INFO]: Epoch 003 - training loss: 0.4213, validation loss: 0.3380
2024-05-25 01:34:17 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch3_loss0.33795667439699173.pypots
2024-05-25 01:34:20 [INFO]: Epoch 004 - training loss: 0.3126, validation loss: 0.3387
2024-05-25 01:34:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch4_loss0.3386506289243698.pypots
2024-05-25 01:34:22 [INFO]: Epoch 005 - training loss: 0.3576, validation loss: 0.3120
2024-05-25 01:34:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch5_loss0.31198565661907196.pypots
2024-05-25 01:34:24 [INFO]: Epoch 006 - training loss: 0.3262, validation loss: 0.2863
2024-05-25 01:34:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch6_loss0.28633491694927216.pypots
2024-05-25 01:34:26 [INFO]: Epoch 007 - training loss: 0.3525, validation loss: 0.2801
2024-05-25 01:34:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch7_loss0.2801434323191643.pypots
2024-05-25 01:34:28 [INFO]: Epoch 008 - training loss: 0.2531, validation loss: 0.2746
2024-05-25 01:34:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch8_loss0.27461478114128113.pypots
2024-05-25 01:34:30 [INFO]: Epoch 009 - training loss: 0.2624, validation loss: 0.2704
2024-05-25 01:34:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch9_loss0.27036289870738983.pypots
2024-05-25 01:34:32 [INFO]: Epoch 010 - training loss: 0.2795, validation loss: 0.2815
2024-05-25 01:34:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch10_loss0.28148654103279114.pypots
2024-05-25 01:34:34 [INFO]: Epoch 011 - training loss: 0.2930, validation loss: 0.2584
2024-05-25 01:34:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch11_loss0.2583608627319336.pypots
2024-05-25 01:34:36 [INFO]: Epoch 012 - training loss: 0.2774, validation loss: 0.2471
2024-05-25 01:34:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch12_loss0.24714336171746254.pypots
2024-05-25 01:34:38 [INFO]: Epoch 013 - training loss: 0.2941, validation loss: 0.2392
2024-05-25 01:34:38 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch13_loss0.23922809213399887.pypots
2024-05-25 01:34:40 [INFO]: Epoch 014 - training loss: 0.2366, validation loss: 0.2524
2024-05-25 01:34:40 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch14_loss0.25236697867512703.pypots
2024-05-25 01:34:42 [INFO]: Epoch 015 - training loss: 0.2401, validation loss: 0.2467
2024-05-25 01:34:42 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch15_loss0.24670865386724472.pypots
2024-05-25 01:34:44 [INFO]: Epoch 016 - training loss: 0.2114, validation loss: 0.2302
2024-05-25 01:34:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch16_loss0.2301798164844513.pypots
2024-05-25 01:34:47 [INFO]: Epoch 017 - training loss: 0.2910, validation loss: 0.2228
2024-05-25 01:34:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch17_loss0.22276996821165085.pypots
2024-05-25 01:34:49 [INFO]: Epoch 018 - training loss: 0.2183, validation loss: 0.2154
2024-05-25 01:34:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch18_loss0.21541287750005722.pypots
2024-05-25 01:34:51 [INFO]: Epoch 019 - training loss: 0.2017, validation loss: 0.2223
2024-05-25 01:34:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch19_loss0.22230982780456543.pypots
2024-05-25 01:34:53 [INFO]: Epoch 020 - training loss: 0.2303, validation loss: 0.2042
2024-05-25 01:34:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch20_loss0.2041919194161892.pypots
2024-05-25 01:34:55 [INFO]: Epoch 021 - training loss: 0.1880, validation loss: 0.2056
2024-05-25 01:34:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch21_loss0.20555999502539635.pypots
2024-05-25 01:34:57 [INFO]: Epoch 022 - training loss: 0.2618, validation loss: 0.2091
2024-05-25 01:34:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch22_loss0.20906824618577957.pypots
2024-05-25 01:34:59 [INFO]: Epoch 023 - training loss: 0.2244, validation loss: 0.2239
2024-05-25 01:34:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch23_loss0.22392301261425018.pypots
2024-05-25 01:35:01 [INFO]: Epoch 024 - training loss: 0.2182, validation loss: 0.2004
2024-05-25 01:35:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch24_loss0.20040366798639297.pypots
2024-05-25 01:35:03 [INFO]: Epoch 025 - training loss: 0.2238, validation loss: 0.2253
2024-05-25 01:35:03 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch25_loss0.225336242467165.pypots
2024-05-25 01:35:05 [INFO]: Epoch 026 - training loss: 0.2458, validation loss: 0.1975
2024-05-25 01:35:05 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch26_loss0.1975472830235958.pypots
2024-05-25 01:35:07 [INFO]: Epoch 027 - training loss: 0.2373, validation loss: 0.2081
2024-05-25 01:35:07 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch27_loss0.20814378559589386.pypots
2024-05-25 01:35:09 [INFO]: Epoch 028 - training loss: 0.2004, validation loss: 0.1923
2024-05-25 01:35:09 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch28_loss0.1923295110464096.pypots
2024-05-25 01:35:12 [INFO]: Epoch 029 - training loss: 0.1732, validation loss: 0.1881
2024-05-25 01:35:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch29_loss0.18805517628788948.pypots
2024-05-25 01:35:14 [INFO]: Epoch 030 - training loss: 0.1862, validation loss: 0.1802
2024-05-25 01:35:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch30_loss0.18022673577070236.pypots
2024-05-25 01:35:16 [INFO]: Epoch 031 - training loss: 0.1913, validation loss: 0.1828
2024-05-25 01:35:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch31_loss0.18279403075575829.pypots
2024-05-25 01:35:18 [INFO]: Epoch 032 - training loss: 0.2523, validation loss: 0.1850
2024-05-25 01:35:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch32_loss0.1850055642426014.pypots
2024-05-25 01:35:20 [INFO]: Epoch 033 - training loss: 0.1972, validation loss: 0.1876
2024-05-25 01:35:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch33_loss0.18758784979581833.pypots
2024-05-25 01:35:22 [INFO]: Epoch 034 - training loss: 0.2759, validation loss: 0.1912
2024-05-25 01:35:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch34_loss0.1911838874220848.pypots
2024-05-25 01:35:24 [INFO]: Epoch 035 - training loss: 0.2292, validation loss: 0.1976
2024-05-25 01:35:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch35_loss0.19757748395204544.pypots
2024-05-25 01:35:26 [INFO]: Epoch 036 - training loss: 0.1949, validation loss: 0.1822
2024-05-25 01:35:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch36_loss0.18218127265572548.pypots
2024-05-25 01:35:28 [INFO]: Epoch 037 - training loss: 0.2470, validation loss: 0.1694
2024-05-25 01:35:28 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch37_loss0.1694248802959919.pypots
2024-05-25 01:35:30 [INFO]: Epoch 038 - training loss: 0.2105, validation loss: 0.1658
2024-05-25 01:35:30 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch38_loss0.1657780557870865.pypots
2024-05-25 01:35:32 [INFO]: Epoch 039 - training loss: 0.1954, validation loss: 0.1679
2024-05-25 01:35:32 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch39_loss0.16788263246417046.pypots
2024-05-25 01:35:34 [INFO]: Epoch 040 - training loss: 0.2302, validation loss: 0.1625
2024-05-25 01:35:34 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch40_loss0.16253486275672913.pypots
2024-05-25 01:35:36 [INFO]: Epoch 041 - training loss: 0.1609, validation loss: 0.1661
2024-05-25 01:35:36 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch41_loss0.1661350205540657.pypots
2024-05-25 01:35:39 [INFO]: Epoch 042 - training loss: 0.1956, validation loss: 0.1725
2024-05-25 01:35:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch42_loss0.17248592153191566.pypots
2024-05-25 01:35:41 [INFO]: Epoch 043 - training loss: 0.2101, validation loss: 0.1826
2024-05-25 01:35:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch43_loss0.18258987367153168.pypots
2024-05-25 01:35:43 [INFO]: Epoch 044 - training loss: 0.1992, validation loss: 0.1719
2024-05-25 01:35:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch44_loss0.17189588770270348.pypots
2024-05-25 01:35:45 [INFO]: Epoch 045 - training loss: 0.2187, validation loss: 0.1647
2024-05-25 01:35:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch45_loss0.16467030718922615.pypots
2024-05-25 01:35:47 [INFO]: Epoch 046 - training loss: 0.2738, validation loss: 0.1678
2024-05-25 01:35:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch46_loss0.16779576241970062.pypots
2024-05-25 01:35:49 [INFO]: Epoch 047 - training loss: 0.1756, validation loss: 0.1600
2024-05-25 01:35:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch47_loss0.16000251099467278.pypots
2024-05-25 01:35:51 [INFO]: Epoch 048 - training loss: 0.1859, validation loss: 0.1552
2024-05-25 01:35:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch48_loss0.15521204844117165.pypots
2024-05-25 01:35:53 [INFO]: Epoch 049 - training loss: 0.2572, validation loss: 0.1534
2024-05-25 01:35:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch49_loss0.15335417911410332.pypots
2024-05-25 01:35:55 [INFO]: Epoch 050 - training loss: 0.1702, validation loss: 0.1513
2024-05-25 01:35:55 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch50_loss0.15129410102963448.pypots
2024-05-25 01:35:57 [INFO]: Epoch 051 - training loss: 0.1994, validation loss: 0.1575
2024-05-25 01:35:57 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch51_loss0.15746575593948364.pypots
2024-05-25 01:35:59 [INFO]: Epoch 052 - training loss: 0.1817, validation loss: 0.1724
2024-05-25 01:35:59 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch52_loss0.17237311229109764.pypots
2024-05-25 01:36:01 [INFO]: Epoch 053 - training loss: 0.1834, validation loss: 0.1564
2024-05-25 01:36:01 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch53_loss0.1564217284321785.pypots
2024-05-25 01:36:04 [INFO]: Epoch 054 - training loss: 0.1986, validation loss: 0.1528
2024-05-25 01:36:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch54_loss0.1528213433921337.pypots
2024-05-25 01:36:06 [INFO]: Epoch 055 - training loss: 0.1594, validation loss: 0.1514
2024-05-25 01:36:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch55_loss0.15138429403305054.pypots
2024-05-25 01:36:08 [INFO]: Epoch 056 - training loss: 0.1396, validation loss: 0.1523
2024-05-25 01:36:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch56_loss0.1522734947502613.pypots
2024-05-25 01:36:10 [INFO]: Epoch 057 - training loss: 0.1843, validation loss: 0.1524
2024-05-25 01:36:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch57_loss0.15236205607652664.pypots
2024-05-25 01:36:12 [INFO]: Epoch 058 - training loss: 0.1880, validation loss: 0.1511
2024-05-25 01:36:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch58_loss0.15107246488332748.pypots
2024-05-25 01:36:14 [INFO]: Epoch 059 - training loss: 0.1540, validation loss: 0.1463
2024-05-25 01:36:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch59_loss0.14633557945489883.pypots
2024-05-25 01:36:16 [INFO]: Epoch 060 - training loss: 0.1525, validation loss: 0.1458
2024-05-25 01:36:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch60_loss0.1457572504878044.pypots
2024-05-25 01:36:18 [INFO]: Epoch 061 - training loss: 0.1367, validation loss: 0.1473
2024-05-25 01:36:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch61_loss0.1473325751721859.pypots
2024-05-25 01:36:20 [INFO]: Epoch 062 - training loss: 0.1551, validation loss: 0.1432
2024-05-25 01:36:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch62_loss0.1431710347533226.pypots
2024-05-25 01:36:22 [INFO]: Epoch 063 - training loss: 0.1579, validation loss: 0.1424
2024-05-25 01:36:22 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch63_loss0.14238643646240234.pypots
2024-05-25 01:36:24 [INFO]: Epoch 064 - training loss: 0.1634, validation loss: 0.1440
2024-05-25 01:36:24 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch64_loss0.14398803934454918.pypots
2024-05-25 01:36:26 [INFO]: Epoch 065 - training loss: 0.1866, validation loss: 0.1530
2024-05-25 01:36:26 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch65_loss0.1530366726219654.pypots
2024-05-25 01:36:28 [INFO]: Epoch 066 - training loss: 0.2083, validation loss: 0.1725
2024-05-25 01:36:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch66_loss0.17247426137328148.pypots
2024-05-25 01:36:31 [INFO]: Epoch 067 - training loss: 0.2097, validation loss: 0.1617
2024-05-25 01:36:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch67_loss0.1617017537355423.pypots
2024-05-25 01:36:33 [INFO]: Epoch 068 - training loss: 0.1774, validation loss: 0.1528
2024-05-25 01:36:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch68_loss0.1527673415839672.pypots
2024-05-25 01:36:35 [INFO]: Epoch 069 - training loss: 0.1742, validation loss: 0.1506
2024-05-25 01:36:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch69_loss0.15064503997564316.pypots
2024-05-25 01:36:37 [INFO]: Epoch 070 - training loss: 0.1515, validation loss: 0.1440
2024-05-25 01:36:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch70_loss0.14395593479275703.pypots
2024-05-25 01:36:39 [INFO]: Epoch 071 - training loss: 0.1876, validation loss: 0.1468
2024-05-25 01:36:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch71_loss0.14679012447595596.pypots
2024-05-25 01:36:41 [INFO]: Epoch 072 - training loss: 0.2248, validation loss: 0.1400
2024-05-25 01:36:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch72_loss0.14004982635378838.pypots
2024-05-25 01:36:43 [INFO]: Epoch 073 - training loss: 0.1588, validation loss: 0.1431
2024-05-25 01:36:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch73_loss0.1431332863867283.pypots
2024-05-25 01:36:45 [INFO]: Epoch 074 - training loss: 0.1559, validation loss: 0.1609
2024-05-25 01:36:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch74_loss0.16093644872307777.pypots
2024-05-25 01:36:47 [INFO]: Epoch 075 - training loss: 0.2053, validation loss: 0.1528
2024-05-25 01:36:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch75_loss0.15278740227222443.pypots
2024-05-25 01:36:49 [INFO]: Epoch 076 - training loss: 0.1730, validation loss: 0.1406
2024-05-25 01:36:49 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch76_loss0.14062673971056938.pypots
2024-05-25 01:36:51 [INFO]: Epoch 077 - training loss: 0.1561, validation loss: 0.1416
2024-05-25 01:36:51 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch77_loss0.1415686011314392.pypots
2024-05-25 01:36:53 [INFO]: Epoch 078 - training loss: 0.1513, validation loss: 0.1407
2024-05-25 01:36:53 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch78_loss0.14065905287861824.pypots
2024-05-25 01:36:56 [INFO]: Epoch 079 - training loss: 0.1366, validation loss: 0.1358
2024-05-25 01:36:56 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch79_loss0.1357877515256405.pypots
2024-05-25 01:36:58 [INFO]: Epoch 080 - training loss: 0.1471, validation loss: 0.1349
2024-05-25 01:36:58 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch80_loss0.13487158715724945.pypots
2024-05-25 01:37:00 [INFO]: Epoch 081 - training loss: 0.1500, validation loss: 0.1370
2024-05-25 01:37:00 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch81_loss0.1370498202741146.pypots
2024-05-25 01:37:02 [INFO]: Epoch 082 - training loss: 0.1433, validation loss: 0.1425
2024-05-25 01:37:02 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch82_loss0.142534289509058.pypots
2024-05-25 01:37:04 [INFO]: Epoch 083 - training loss: 0.2010, validation loss: 0.1412
2024-05-25 01:37:04 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch83_loss0.14119776338338852.pypots
2024-05-25 01:37:06 [INFO]: Epoch 084 - training loss: 0.1651, validation loss: 0.1369
2024-05-25 01:37:06 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch84_loss0.13692929223179817.pypots
2024-05-25 01:37:08 [INFO]: Epoch 085 - training loss: 0.1262, validation loss: 0.1343
2024-05-25 01:37:08 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch85_loss0.13426243141293526.pypots
2024-05-25 01:37:10 [INFO]: Epoch 086 - training loss: 0.1714, validation loss: 0.1349
2024-05-25 01:37:10 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch86_loss0.13485274836421013.pypots
2024-05-25 01:37:12 [INFO]: Epoch 087 - training loss: 0.1538, validation loss: 0.1331
2024-05-25 01:37:12 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch87_loss0.1330820806324482.pypots
2024-05-25 01:37:14 [INFO]: Epoch 088 - training loss: 0.1688, validation loss: 0.1314
2024-05-25 01:37:14 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch88_loss0.13142088800668716.pypots
2024-05-25 01:37:16 [INFO]: Epoch 089 - training loss: 0.2001, validation loss: 0.1305
2024-05-25 01:37:16 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch89_loss0.1304585337638855.pypots
2024-05-25 01:37:18 [INFO]: Epoch 090 - training loss: 0.2101, validation loss: 0.1437
2024-05-25 01:37:18 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch90_loss0.14373385906219482.pypots
2024-05-25 01:37:20 [INFO]: Epoch 091 - training loss: 0.1711, validation loss: 0.1385
2024-05-25 01:37:20 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch91_loss0.13852845504879951.pypots
2024-05-25 01:37:23 [INFO]: Epoch 092 - training loss: 0.1901, validation loss: 0.1345
2024-05-25 01:37:23 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch92_loss0.1345006823539734.pypots
2024-05-25 01:37:25 [INFO]: Epoch 093 - training loss: 0.1577, validation loss: 0.1426
2024-05-25 01:37:25 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch93_loss0.14264977723360062.pypots
2024-05-25 01:37:27 [INFO]: Epoch 094 - training loss: 0.1387, validation loss: 0.1341
2024-05-25 01:37:27 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch94_loss0.13414950668811798.pypots
2024-05-25 01:37:29 [INFO]: Epoch 095 - training loss: 0.1554, validation loss: 0.1299
2024-05-25 01:37:29 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch95_loss0.12989244237542152.pypots
2024-05-25 01:37:31 [INFO]: Epoch 096 - training loss: 0.2142, validation loss: 0.1301
2024-05-25 01:37:31 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch96_loss0.13009792007505894.pypots
2024-05-25 01:37:33 [INFO]: Epoch 097 - training loss: 0.2133, validation loss: 0.1321
2024-05-25 01:37:33 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch97_loss0.13205842673778534.pypots
2024-05-25 01:37:35 [INFO]: Epoch 098 - training loss: 0.1597, validation loss: 0.1329
2024-05-25 01:37:35 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch98_loss0.1329236514866352.pypots
2024-05-25 01:37:37 [INFO]: Epoch 099 - training loss: 0.1455, validation loss: 0.1465
2024-05-25 01:37:37 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch99_loss0.14646807312965393.pypots
2024-05-25 01:37:39 [INFO]: Epoch 100 - training loss: 0.1811, validation loss: 0.1602
2024-05-25 01:37:39 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch100_loss0.16020849719643593.pypots
2024-05-25 01:37:41 [INFO]: Epoch 101 - training loss: 0.2403, validation loss: 0.1491
2024-05-25 01:37:41 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch101_loss0.1490892544388771.pypots
2024-05-25 01:37:43 [INFO]: Epoch 102 - training loss: 0.1746, validation loss: 0.1458
2024-05-25 01:37:43 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch102_loss0.14581924304366112.pypots
2024-05-25 01:37:45 [INFO]: Epoch 103 - training loss: 0.1645, validation loss: 0.1367
2024-05-25 01:37:45 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch103_loss0.13674086332321167.pypots
2024-05-25 01:37:47 [INFO]: Epoch 104 - training loss: 0.1707, validation loss: 0.1369
2024-05-25 01:37:47 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch104_loss0.1368987262248993.pypots
2024-05-25 01:37:50 [INFO]: Epoch 105 - training loss: 0.1611, validation loss: 0.1325
2024-05-25 01:37:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI_epoch105_loss0.13246221654117107.pypots
2024-05-25 01:37:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:37:50 [INFO]: Finished training. The best model is from epoch#95.
2024-05-25 01:37:50 [INFO]: Saved the model to augmentation_saved_results/round_1/CSDI_ettm1/20240525_T013411/CSDI.pypots
2024-05-25 01:38:05 [INFO]: CSDI on ETTm1: MAE=0.1273, MSE=0.0454
2024-05-25 01:38:05 [INFO]: Successfully saved to augmentation_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-25 01:38:05 [INFO]: Using the given device: cuda:0
2024-05-25 01:38:05 [INFO]: Model files will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013805
2024-05-25 01:38:05 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013805/tensorboard
2024-05-25 01:38:05 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 01:38:05 [INFO]: Epoch 001 - training loss: 23822.8242, validation loss: 0.9603
2024-05-25 01:38:06 [INFO]: Epoch 002 - training loss: 21765.9840, validation loss: 0.9567
2024-05-25 01:38:06 [INFO]: Epoch 003 - training loss: 19895.4674, validation loss: 0.9512
2024-05-25 01:38:06 [INFO]: Epoch 004 - training loss: 17881.2020, validation loss: 0.9353
2024-05-25 01:38:06 [INFO]: Epoch 005 - training loss: 16175.9678, validation loss: 0.8855
2024-05-25 01:38:06 [INFO]: Epoch 006 - training loss: 14515.2380, validation loss: 0.7932
2024-05-25 01:38:06 [INFO]: Epoch 007 - training loss: 13109.6573, validation loss: 0.6771
2024-05-25 01:38:06 [INFO]: Epoch 008 - training loss: 12167.2625, validation loss: 0.5800
2024-05-25 01:38:06 [INFO]: Epoch 009 - training loss: 11638.1161, validation loss: 0.5378
2024-05-25 01:38:07 [INFO]: Epoch 010 - training loss: 11035.5218, validation loss: 0.5165
2024-05-25 01:38:07 [INFO]: Epoch 011 - training loss: 10669.9245, validation loss: 0.5003
2024-05-25 01:38:07 [INFO]: Epoch 012 - training loss: 10477.1400, validation loss: 0.4861
2024-05-25 01:38:07 [INFO]: Epoch 013 - training loss: 10235.9947, validation loss: 0.4694
2024-05-25 01:38:07 [INFO]: Epoch 014 - training loss: 10112.9218, validation loss: 0.4521
2024-05-25 01:38:07 [INFO]: Epoch 015 - training loss: 9981.4022, validation loss: 0.4384
2024-05-25 01:38:07 [INFO]: Epoch 016 - training loss: 9904.5695, validation loss: 0.4252
2024-05-25 01:38:07 [INFO]: Epoch 017 - training loss: 9876.4179, validation loss: 0.4049
2024-05-25 01:38:08 [INFO]: Epoch 018 - training loss: 9755.6817, validation loss: 0.3884
2024-05-25 01:38:08 [INFO]: Epoch 019 - training loss: 9719.7572, validation loss: 0.3776
2024-05-25 01:38:08 [INFO]: Epoch 020 - training loss: 9702.6194, validation loss: 0.3671
2024-05-25 01:38:08 [INFO]: Epoch 021 - training loss: 9612.0640, validation loss: 0.3564
2024-05-25 01:38:08 [INFO]: Epoch 022 - training loss: 9591.2562, validation loss: 0.3469
2024-05-25 01:38:08 [INFO]: Epoch 023 - training loss: 9574.6498, validation loss: 0.3405
2024-05-25 01:38:08 [INFO]: Epoch 024 - training loss: 9523.4832, validation loss: 0.3298
2024-05-25 01:38:08 [INFO]: Epoch 025 - training loss: 9500.3173, validation loss: 0.3270
2024-05-25 01:38:09 [INFO]: Epoch 026 - training loss: 9505.9266, validation loss: 0.3186
2024-05-25 01:38:09 [INFO]: Epoch 027 - training loss: 9476.2509, validation loss: 0.3087
2024-05-25 01:38:09 [INFO]: Epoch 028 - training loss: 9440.4035, validation loss: 0.3026
2024-05-25 01:38:09 [INFO]: Epoch 029 - training loss: 9427.3198, validation loss: 0.2971
2024-05-25 01:38:09 [INFO]: Epoch 030 - training loss: 9415.6026, validation loss: 0.2876
2024-05-25 01:38:09 [INFO]: Epoch 031 - training loss: 9426.4186, validation loss: 0.2836
2024-05-25 01:38:09 [INFO]: Epoch 032 - training loss: 9389.4156, validation loss: 0.2774
2024-05-25 01:38:09 [INFO]: Epoch 033 - training loss: 9393.8001, validation loss: 0.2667
2024-05-25 01:38:10 [INFO]: Epoch 034 - training loss: 9373.6402, validation loss: 0.2623
2024-05-25 01:38:10 [INFO]: Epoch 035 - training loss: 9384.0616, validation loss: 0.2577
2024-05-25 01:38:10 [INFO]: Epoch 036 - training loss: 9356.3227, validation loss: 0.2460
2024-05-25 01:38:10 [INFO]: Epoch 037 - training loss: 9356.5368, validation loss: 0.2436
2024-05-25 01:38:10 [INFO]: Epoch 038 - training loss: 9349.6480, validation loss: 0.2368
2024-05-25 01:38:10 [INFO]: Epoch 039 - training loss: 9348.2885, validation loss: 0.2316
2024-05-25 01:38:10 [INFO]: Epoch 040 - training loss: 9334.8878, validation loss: 0.2261
2024-05-25 01:38:10 [INFO]: Epoch 041 - training loss: 9327.1543, validation loss: 0.2191
2024-05-25 01:38:11 [INFO]: Epoch 042 - training loss: 9322.8896, validation loss: 0.2147
2024-05-25 01:38:11 [INFO]: Epoch 043 - training loss: 9317.4039, validation loss: 0.2099
2024-05-25 01:38:11 [INFO]: Epoch 044 - training loss: 9315.1536, validation loss: 0.2111
2024-05-25 01:38:11 [INFO]: Epoch 045 - training loss: 9325.7346, validation loss: 0.2045
2024-05-25 01:38:11 [INFO]: Epoch 046 - training loss: 9306.5046, validation loss: 0.1997
2024-05-25 01:38:11 [INFO]: Epoch 047 - training loss: 9313.8713, validation loss: 0.1947
2024-05-25 01:38:11 [INFO]: Epoch 048 - training loss: 9302.0746, validation loss: 0.1975
2024-05-25 01:38:11 [INFO]: Epoch 049 - training loss: 9303.0815, validation loss: 0.1948
2024-05-25 01:38:12 [INFO]: Epoch 050 - training loss: 9293.6462, validation loss: 0.1865
2024-05-25 01:38:12 [INFO]: Epoch 051 - training loss: 9289.8231, validation loss: 0.1880
2024-05-25 01:38:12 [INFO]: Epoch 052 - training loss: 9287.4472, validation loss: 0.1827
2024-05-25 01:38:12 [INFO]: Epoch 053 - training loss: 9285.4710, validation loss: 0.1801
2024-05-25 01:38:12 [INFO]: Epoch 054 - training loss: 9284.5314, validation loss: 0.1765
2024-05-25 01:38:12 [INFO]: Epoch 055 - training loss: 9282.6569, validation loss: 0.1733
2024-05-25 01:38:12 [INFO]: Epoch 056 - training loss: 9279.8358, validation loss: 0.1693
2024-05-25 01:38:12 [INFO]: Epoch 057 - training loss: 9280.1564, validation loss: 0.1667
2024-05-25 01:38:13 [INFO]: Epoch 058 - training loss: 9271.6465, validation loss: 0.1644
2024-05-25 01:38:13 [INFO]: Epoch 059 - training loss: 9269.4500, validation loss: 0.1643
2024-05-25 01:38:13 [INFO]: Epoch 060 - training loss: 9271.8705, validation loss: 0.1609
2024-05-25 01:38:13 [INFO]: Epoch 061 - training loss: 9273.8043, validation loss: 0.1646
2024-05-25 01:38:13 [INFO]: Epoch 062 - training loss: 9276.2725, validation loss: 0.1606
2024-05-25 01:38:13 [INFO]: Epoch 063 - training loss: 9263.7711, validation loss: 0.1574
2024-05-25 01:38:13 [INFO]: Epoch 064 - training loss: 9261.5073, validation loss: 0.1559
2024-05-25 01:38:13 [INFO]: Epoch 065 - training loss: 9264.5275, validation loss: 0.1544
2024-05-25 01:38:13 [INFO]: Epoch 066 - training loss: 9262.2733, validation loss: 0.1511
2024-05-25 01:38:14 [INFO]: Epoch 067 - training loss: 9258.3774, validation loss: 0.1516
2024-05-25 01:38:14 [INFO]: Epoch 068 - training loss: 9257.2847, validation loss: 0.1509
2024-05-25 01:38:14 [INFO]: Epoch 069 - training loss: 9256.0364, validation loss: 0.1491
2024-05-25 01:38:14 [INFO]: Epoch 070 - training loss: 9253.9854, validation loss: 0.1472
2024-05-25 01:38:14 [INFO]: Epoch 071 - training loss: 9252.3622, validation loss: 0.1476
2024-05-25 01:38:14 [INFO]: Epoch 072 - training loss: 9253.7619, validation loss: 0.1453
2024-05-25 01:38:14 [INFO]: Epoch 073 - training loss: 9252.2095, validation loss: 0.1464
2024-05-25 01:38:14 [INFO]: Epoch 074 - training loss: 9257.1626, validation loss: 0.1452
2024-05-25 01:38:15 [INFO]: Epoch 075 - training loss: 9249.1340, validation loss: 0.1454
2024-05-25 01:38:15 [INFO]: Epoch 076 - training loss: 9252.2769, validation loss: 0.1431
2024-05-25 01:38:15 [INFO]: Epoch 077 - training loss: 9249.8183, validation loss: 0.1419
2024-05-25 01:38:15 [INFO]: Epoch 078 - training loss: 9250.8729, validation loss: 0.1406
2024-05-25 01:38:15 [INFO]: Epoch 079 - training loss: 9245.6648, validation loss: 0.1405
2024-05-25 01:38:15 [INFO]: Epoch 080 - training loss: 9246.0922, validation loss: 0.1387
2024-05-25 01:38:15 [INFO]: Epoch 081 - training loss: 9244.2048, validation loss: 0.1379
2024-05-25 01:38:15 [INFO]: Epoch 082 - training loss: 9247.9147, validation loss: 0.1367
2024-05-25 01:38:16 [INFO]: Epoch 083 - training loss: 9242.6846, validation loss: 0.1365
2024-05-25 01:38:16 [INFO]: Epoch 084 - training loss: 9243.0162, validation loss: 0.1354
2024-05-25 01:38:16 [INFO]: Epoch 085 - training loss: 9240.7275, validation loss: 0.1362
2024-05-25 01:38:16 [INFO]: Epoch 086 - training loss: 9242.1609, validation loss: 0.1352
2024-05-25 01:38:16 [INFO]: Epoch 087 - training loss: 9240.5944, validation loss: 0.1346
2024-05-25 01:38:16 [INFO]: Epoch 088 - training loss: 9239.8035, validation loss: 0.1335
2024-05-25 01:38:16 [INFO]: Epoch 089 - training loss: 9241.5121, validation loss: 0.1321
2024-05-25 01:38:16 [INFO]: Epoch 090 - training loss: 9239.0792, validation loss: 0.1305
2024-05-25 01:38:17 [INFO]: Epoch 091 - training loss: 9238.7961, validation loss: 0.1311
2024-05-25 01:38:17 [INFO]: Epoch 092 - training loss: 9237.6691, validation loss: 0.1294
2024-05-25 01:38:17 [INFO]: Epoch 093 - training loss: 9239.3613, validation loss: 0.1303
2024-05-25 01:38:17 [INFO]: Epoch 094 - training loss: 9237.0513, validation loss: 0.1286
2024-05-25 01:38:17 [INFO]: Epoch 095 - training loss: 9235.7817, validation loss: 0.1310
2024-05-25 01:38:17 [INFO]: Epoch 096 - training loss: 9234.7711, validation loss: 0.1282
2024-05-25 01:38:17 [INFO]: Epoch 097 - training loss: 9234.3048, validation loss: 0.1259
2024-05-25 01:38:17 [INFO]: Epoch 098 - training loss: 9233.9820, validation loss: 0.1245
2024-05-25 01:38:18 [INFO]: Epoch 099 - training loss: 9234.8369, validation loss: 0.1240
2024-05-25 01:38:18 [INFO]: Epoch 100 - training loss: 9232.8182, validation loss: 0.1255
2024-05-25 01:38:18 [INFO]: Epoch 101 - training loss: 9232.6281, validation loss: 0.1243
2024-05-25 01:38:18 [INFO]: Epoch 102 - training loss: 9231.2921, validation loss: 0.1229
2024-05-25 01:38:18 [INFO]: Epoch 103 - training loss: 9233.8640, validation loss: 0.1224
2024-05-25 01:38:18 [INFO]: Epoch 104 - training loss: 9230.9832, validation loss: 0.1214
2024-05-25 01:38:18 [INFO]: Epoch 105 - training loss: 9230.4288, validation loss: 0.1222
2024-05-25 01:38:18 [INFO]: Epoch 106 - training loss: 9229.4984, validation loss: 0.1211
2024-05-25 01:38:19 [INFO]: Epoch 107 - training loss: 9229.7634, validation loss: 0.1208
2024-05-25 01:38:19 [INFO]: Epoch 108 - training loss: 9230.0943, validation loss: 0.1194
2024-05-25 01:38:19 [INFO]: Epoch 109 - training loss: 9228.2477, validation loss: 0.1188
2024-05-25 01:38:19 [INFO]: Epoch 110 - training loss: 9227.3541, validation loss: 0.1190
2024-05-25 01:38:19 [INFO]: Epoch 111 - training loss: 9227.6071, validation loss: 0.1180
2024-05-25 01:38:19 [INFO]: Epoch 112 - training loss: 9226.8996, validation loss: 0.1187
2024-05-25 01:38:19 [INFO]: Epoch 113 - training loss: 9226.5017, validation loss: 0.1180
2024-05-25 01:38:19 [INFO]: Epoch 114 - training loss: 9227.8857, validation loss: 0.1170
2024-05-25 01:38:20 [INFO]: Epoch 115 - training loss: 9227.7448, validation loss: 0.1201
2024-05-25 01:38:20 [INFO]: Epoch 116 - training loss: 9227.9681, validation loss: 0.1144
2024-05-25 01:38:20 [INFO]: Epoch 117 - training loss: 9226.2970, validation loss: 0.1153
2024-05-25 01:38:20 [INFO]: Epoch 118 - training loss: 9227.6148, validation loss: 0.1149
2024-05-25 01:38:20 [INFO]: Epoch 119 - training loss: 9227.1342, validation loss: 0.1142
2024-05-25 01:38:20 [INFO]: Epoch 120 - training loss: 9225.1771, validation loss: 0.1132
2024-05-25 01:38:20 [INFO]: Epoch 121 - training loss: 9224.1913, validation loss: 0.1131
2024-05-25 01:38:20 [INFO]: Epoch 122 - training loss: 9223.3680, validation loss: 0.1136
2024-05-25 01:38:21 [INFO]: Epoch 123 - training loss: 9222.9672, validation loss: 0.1131
2024-05-25 01:38:21 [INFO]: Epoch 124 - training loss: 9225.7717, validation loss: 0.1113
2024-05-25 01:38:21 [INFO]: Epoch 125 - training loss: 9223.2784, validation loss: 0.1095
2024-05-25 01:38:21 [INFO]: Epoch 126 - training loss: 9221.9919, validation loss: 0.1102
2024-05-25 01:38:21 [INFO]: Epoch 127 - training loss: 9223.5123, validation loss: 0.1094
2024-05-25 01:38:21 [INFO]: Epoch 128 - training loss: 9223.7374, validation loss: 0.1124
2024-05-25 01:38:21 [INFO]: Epoch 129 - training loss: 9221.6688, validation loss: 0.1094
2024-05-25 01:38:21 [INFO]: Epoch 130 - training loss: 9227.6029, validation loss: 0.1095
2024-05-25 01:38:22 [INFO]: Epoch 131 - training loss: 9220.4957, validation loss: 0.1087
2024-05-25 01:38:22 [INFO]: Epoch 132 - training loss: 9222.1132, validation loss: 0.1084
2024-05-25 01:38:22 [INFO]: Epoch 133 - training loss: 9221.4932, validation loss: 0.1081
2024-05-25 01:38:22 [INFO]: Epoch 134 - training loss: 9219.3936, validation loss: 0.1063
2024-05-25 01:38:22 [INFO]: Epoch 135 - training loss: 9220.2137, validation loss: 0.1068
2024-05-25 01:38:22 [INFO]: Epoch 136 - training loss: 9219.5303, validation loss: 0.1054
2024-05-25 01:38:22 [INFO]: Epoch 137 - training loss: 9221.6804, validation loss: 0.1059
2024-05-25 01:38:22 [INFO]: Epoch 138 - training loss: 9220.2339, validation loss: 0.1045
2024-05-25 01:38:22 [INFO]: Epoch 139 - training loss: 9219.5931, validation loss: 0.1058
2024-05-25 01:38:23 [INFO]: Epoch 140 - training loss: 9220.1227, validation loss: 0.1044
2024-05-25 01:38:23 [INFO]: Epoch 141 - training loss: 9219.0077, validation loss: 0.1047
2024-05-25 01:38:23 [INFO]: Epoch 142 - training loss: 9218.9530, validation loss: 0.1042
2024-05-25 01:38:23 [INFO]: Epoch 143 - training loss: 9217.3274, validation loss: 0.1043
2024-05-25 01:38:23 [INFO]: Epoch 144 - training loss: 9219.7630, validation loss: 0.1030
2024-05-25 01:38:23 [INFO]: Epoch 145 - training loss: 9217.7784, validation loss: 0.1041
2024-05-25 01:38:23 [INFO]: Epoch 146 - training loss: 9219.9305, validation loss: 0.1018
2024-05-25 01:38:23 [INFO]: Epoch 147 - training loss: 9217.8140, validation loss: 0.1029
2024-05-25 01:38:24 [INFO]: Epoch 148 - training loss: 9218.1155, validation loss: 0.1020
2024-05-25 01:38:24 [INFO]: Epoch 149 - training loss: 9218.1569, validation loss: 0.1021
2024-05-25 01:38:24 [INFO]: Epoch 150 - training loss: 9215.9634, validation loss: 0.1010
2024-05-25 01:38:24 [INFO]: Epoch 151 - training loss: 9217.7459, validation loss: 0.1003
2024-05-25 01:38:24 [INFO]: Epoch 152 - training loss: 9218.4498, validation loss: 0.1014
2024-05-25 01:38:24 [INFO]: Epoch 153 - training loss: 9217.1294, validation loss: 0.1017
2024-05-25 01:38:24 [INFO]: Epoch 154 - training loss: 9216.6716, validation loss: 0.1006
2024-05-25 01:38:24 [INFO]: Epoch 155 - training loss: 9217.2726, validation loss: 0.0975
2024-05-25 01:38:25 [INFO]: Epoch 156 - training loss: 9217.9595, validation loss: 0.0992
2024-05-25 01:38:25 [INFO]: Epoch 157 - training loss: 9215.5748, validation loss: 0.1058
2024-05-25 01:38:25 [INFO]: Epoch 158 - training loss: 9216.3949, validation loss: 0.0988
2024-05-25 01:38:25 [INFO]: Epoch 159 - training loss: 9214.8001, validation loss: 0.0990
2024-05-25 01:38:25 [INFO]: Epoch 160 - training loss: 9216.7816, validation loss: 0.0982
2024-05-25 01:38:25 [INFO]: Epoch 161 - training loss: 9215.9960, validation loss: 0.0972
2024-05-25 01:38:25 [INFO]: Epoch 162 - training loss: 9216.6371, validation loss: 0.0967
2024-05-25 01:38:25 [INFO]: Epoch 163 - training loss: 9215.5361, validation loss: 0.0986
2024-05-25 01:38:26 [INFO]: Epoch 164 - training loss: 9215.7730, validation loss: 0.0965
2024-05-25 01:38:26 [INFO]: Epoch 165 - training loss: 9214.1443, validation loss: 0.0968
2024-05-25 01:38:26 [INFO]: Epoch 166 - training loss: 9214.5364, validation loss: 0.0962
2024-05-25 01:38:26 [INFO]: Epoch 167 - training loss: 9214.5707, validation loss: 0.0967
2024-05-25 01:38:26 [INFO]: Epoch 168 - training loss: 9215.1243, validation loss: 0.0957
2024-05-25 01:38:26 [INFO]: Epoch 169 - training loss: 9215.4175, validation loss: 0.0953
2024-05-25 01:38:26 [INFO]: Epoch 170 - training loss: 9217.1405, validation loss: 0.0960
2024-05-25 01:38:26 [INFO]: Epoch 171 - training loss: 9219.0608, validation loss: 0.0958
2024-05-25 01:38:27 [INFO]: Epoch 172 - training loss: 9214.7051, validation loss: 0.1006
2024-05-25 01:38:27 [INFO]: Epoch 173 - training loss: 9213.8530, validation loss: 0.0956
2024-05-25 01:38:27 [INFO]: Epoch 174 - training loss: 9213.1120, validation loss: 0.0929
2024-05-25 01:38:27 [INFO]: Epoch 175 - training loss: 9211.8928, validation loss: 0.0937
2024-05-25 01:38:27 [INFO]: Epoch 176 - training loss: 9213.4523, validation loss: 0.0944
2024-05-25 01:38:27 [INFO]: Epoch 177 - training loss: 9213.6878, validation loss: 0.0929
2024-05-25 01:38:27 [INFO]: Epoch 178 - training loss: 9214.0492, validation loss: 0.0951
2024-05-25 01:38:27 [INFO]: Epoch 179 - training loss: 9213.0434, validation loss: 0.0939
2024-05-25 01:38:28 [INFO]: Epoch 180 - training loss: 9215.3398, validation loss: 0.0941
2024-05-25 01:38:28 [INFO]: Epoch 181 - training loss: 9214.4081, validation loss: 0.0920
2024-05-25 01:38:28 [INFO]: Epoch 182 - training loss: 9212.5005, validation loss: 0.0939
2024-05-25 01:38:28 [INFO]: Epoch 183 - training loss: 9213.7429, validation loss: 0.0906
2024-05-25 01:38:28 [INFO]: Epoch 184 - training loss: 9213.1669, validation loss: 0.0952
2024-05-25 01:38:28 [INFO]: Epoch 185 - training loss: 9212.1385, validation loss: 0.0912
2024-05-25 01:38:28 [INFO]: Epoch 186 - training loss: 9211.8327, validation loss: 0.0929
2024-05-25 01:38:28 [INFO]: Epoch 187 - training loss: 9211.9313, validation loss: 0.0910
2024-05-25 01:38:29 [INFO]: Epoch 188 - training loss: 9211.2369, validation loss: 0.0924
2024-05-25 01:38:29 [INFO]: Epoch 189 - training loss: 9211.1317, validation loss: 0.0916
2024-05-25 01:38:29 [INFO]: Epoch 190 - training loss: 9212.4895, validation loss: 0.0899
2024-05-25 01:38:29 [INFO]: Epoch 191 - training loss: 9213.6351, validation loss: 0.0957
2024-05-25 01:38:29 [INFO]: Epoch 192 - training loss: 9212.1601, validation loss: 0.0913
2024-05-25 01:38:29 [INFO]: Epoch 193 - training loss: 9211.1691, validation loss: 0.0912
2024-05-25 01:38:29 [INFO]: Epoch 194 - training loss: 9211.7462, validation loss: 0.0918
2024-05-25 01:38:29 [INFO]: Epoch 195 - training loss: 9211.6642, validation loss: 0.0914
2024-05-25 01:38:30 [INFO]: Epoch 196 - training loss: 9212.7202, validation loss: 0.0901
2024-05-25 01:38:30 [INFO]: Epoch 197 - training loss: 9211.2704, validation loss: 0.0897
2024-05-25 01:38:30 [INFO]: Epoch 198 - training loss: 9212.5133, validation loss: 0.0891
2024-05-25 01:38:30 [INFO]: Epoch 199 - training loss: 9210.0580, validation loss: 0.0887
2024-05-25 01:38:30 [INFO]: Epoch 200 - training loss: 9210.1158, validation loss: 0.0910
2024-05-25 01:38:30 [INFO]: Epoch 201 - training loss: 9211.5165, validation loss: 0.0907
2024-05-25 01:38:30 [INFO]: Epoch 202 - training loss: 9211.9270, validation loss: 0.0895
2024-05-25 01:38:30 [INFO]: Epoch 203 - training loss: 9210.0886, validation loss: 0.0905
2024-05-25 01:38:31 [INFO]: Epoch 204 - training loss: 9209.8223, validation loss: 0.0906
2024-05-25 01:38:31 [INFO]: Epoch 205 - training loss: 9211.1263, validation loss: 0.0902
2024-05-25 01:38:31 [INFO]: Epoch 206 - training loss: 9208.9036, validation loss: 0.0881
2024-05-25 01:38:31 [INFO]: Epoch 207 - training loss: 9211.8454, validation loss: 0.0899
2024-05-25 01:38:31 [INFO]: Epoch 208 - training loss: 9211.3275, validation loss: 0.0888
2024-05-25 01:38:31 [INFO]: Epoch 209 - training loss: 9211.3621, validation loss: 0.0876
2024-05-25 01:38:31 [INFO]: Epoch 210 - training loss: 9209.2964, validation loss: 0.0922
2024-05-25 01:38:31 [INFO]: Epoch 211 - training loss: 9209.6882, validation loss: 0.0873
2024-05-25 01:38:31 [INFO]: Epoch 212 - training loss: 9210.0573, validation loss: 0.0872
2024-05-25 01:38:32 [INFO]: Epoch 213 - training loss: 9210.3184, validation loss: 0.0880
2024-05-25 01:38:32 [INFO]: Epoch 214 - training loss: 9210.2571, validation loss: 0.0881
2024-05-25 01:38:32 [INFO]: Epoch 215 - training loss: 9210.1178, validation loss: 0.0874
2024-05-25 01:38:32 [INFO]: Epoch 216 - training loss: 9210.8735, validation loss: 0.0884
2024-05-25 01:38:32 [INFO]: Epoch 217 - training loss: 9208.9312, validation loss: 0.0897
2024-05-25 01:38:32 [INFO]: Epoch 218 - training loss: 9209.8983, validation loss: 0.0874
2024-05-25 01:38:32 [INFO]: Epoch 219 - training loss: 9210.2429, validation loss: 0.0860
2024-05-25 01:38:32 [INFO]: Epoch 220 - training loss: 9211.6661, validation loss: 0.0865
2024-05-25 01:38:33 [INFO]: Epoch 221 - training loss: 9210.1251, validation loss: 0.0896
2024-05-25 01:38:33 [INFO]: Epoch 222 - training loss: 9209.7801, validation loss: 0.0864
2024-05-25 01:38:33 [INFO]: Epoch 223 - training loss: 9209.2398, validation loss: 0.0873
2024-05-25 01:38:33 [INFO]: Epoch 224 - training loss: 9208.8634, validation loss: 0.0885
2024-05-25 01:38:33 [INFO]: Epoch 225 - training loss: 9210.7225, validation loss: 0.0889
2024-05-25 01:38:33 [INFO]: Epoch 226 - training loss: 9207.9362, validation loss: 0.0866
2024-05-25 01:38:33 [INFO]: Epoch 227 - training loss: 9210.9167, validation loss: 0.0876
2024-05-25 01:38:33 [INFO]: Epoch 228 - training loss: 9211.1279, validation loss: 0.0853
2024-05-25 01:38:34 [INFO]: Epoch 229 - training loss: 9209.4595, validation loss: 0.0866
2024-05-25 01:38:34 [INFO]: Epoch 230 - training loss: 9207.7106, validation loss: 0.0853
2024-05-25 01:38:34 [INFO]: Epoch 231 - training loss: 9209.3840, validation loss: 0.0868
2024-05-25 01:38:34 [INFO]: Epoch 232 - training loss: 9208.0143, validation loss: 0.0874
2024-05-25 01:38:34 [INFO]: Epoch 233 - training loss: 9210.5117, validation loss: 0.0847
2024-05-25 01:38:34 [INFO]: Epoch 234 - training loss: 9209.0570, validation loss: 0.0844
2024-05-25 01:38:34 [INFO]: Epoch 235 - training loss: 9208.0927, validation loss: 0.0854
2024-05-25 01:38:34 [INFO]: Epoch 236 - training loss: 9209.5488, validation loss: 0.0848
2024-05-25 01:38:35 [INFO]: Epoch 237 - training loss: 9210.5280, validation loss: 0.0856
2024-05-25 01:38:35 [INFO]: Epoch 238 - training loss: 9208.6141, validation loss: 0.0866
2024-05-25 01:38:35 [INFO]: Epoch 239 - training loss: 9209.5156, validation loss: 0.0852
2024-05-25 01:38:35 [INFO]: Epoch 240 - training loss: 9207.8439, validation loss: 0.0860
2024-05-25 01:38:35 [INFO]: Epoch 241 - training loss: 9207.8771, validation loss: 0.0847
2024-05-25 01:38:35 [INFO]: Epoch 242 - training loss: 9206.4887, validation loss: 0.0851
2024-05-25 01:38:35 [INFO]: Epoch 243 - training loss: 9208.3666, validation loss: 0.0858
2024-05-25 01:38:35 [INFO]: Epoch 244 - training loss: 9208.3828, validation loss: 0.0864
2024-05-25 01:38:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:38:35 [INFO]: Finished training. The best model is from epoch#234.
2024-05-25 01:38:35 [INFO]: Saved the model to augmentation_saved_results/round_1/GPVAE_ettm1/20240525_T013805/GPVAE.pypots
2024-05-25 01:38:35 [INFO]: GP-VAE on ETTm1: MAE=0.2907, MSE=0.1866
2024-05-25 01:38:35 [INFO]: Successfully saved to augmentation_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-25 01:38:35 [INFO]: Using the given device: cuda:0
2024-05-25 01:38:35 [INFO]: Model files will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013835
2024-05-25 01:38:35 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013835/tensorboard
2024-05-25 01:38:35 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 01:38:46 [INFO]: Epoch 001 - generator training loss: 0.5023, discriminator training loss: 0.5302, validation loss: 0.4267
2024-05-25 01:38:55 [INFO]: Epoch 002 - generator training loss: -0.0136, discriminator training loss: 0.4684, validation loss: 0.1497
2024-05-25 01:39:04 [INFO]: Epoch 003 - generator training loss: -0.1412, discriminator training loss: 0.4176, validation loss: 0.0745
2024-05-25 01:39:13 [INFO]: Epoch 004 - generator training loss: -0.1345, discriminator training loss: 0.3470, validation loss: 0.0570
2024-05-25 01:39:22 [INFO]: Epoch 005 - generator training loss: -0.0927, discriminator training loss: 0.2726, validation loss: 0.0479
2024-05-25 01:39:31 [INFO]: Epoch 006 - generator training loss: -0.0680, discriminator training loss: 0.2210, validation loss: 0.0476
2024-05-25 01:39:40 [INFO]: Epoch 007 - generator training loss: -0.0573, discriminator training loss: 0.1955, validation loss: 0.0422
2024-05-25 01:39:49 [INFO]: Epoch 008 - generator training loss: -0.0528, discriminator training loss: 0.1832, validation loss: 0.0413
2024-05-25 01:39:58 [INFO]: Epoch 009 - generator training loss: -0.0506, discriminator training loss: 0.1800, validation loss: 0.0397
2024-05-25 01:40:07 [INFO]: Epoch 010 - generator training loss: -0.0535, discriminator training loss: 0.1779, validation loss: 0.0375
2024-05-25 01:40:16 [INFO]: Epoch 011 - generator training loss: -0.0556, discriminator training loss: 0.1769, validation loss: 0.0371
2024-05-25 01:40:25 [INFO]: Epoch 012 - generator training loss: -0.0558, discriminator training loss: 0.1760, validation loss: 0.0369
2024-05-25 01:40:34 [INFO]: Epoch 013 - generator training loss: -0.0546, discriminator training loss: 0.1739, validation loss: 0.0359
2024-05-25 01:40:43 [INFO]: Epoch 014 - generator training loss: -0.0576, discriminator training loss: 0.1715, validation loss: 0.0353
2024-05-25 01:40:52 [INFO]: Epoch 015 - generator training loss: -0.0576, discriminator training loss: 0.1728, validation loss: 0.0345
2024-05-25 01:41:01 [INFO]: Epoch 016 - generator training loss: -0.0543, discriminator training loss: 0.1707, validation loss: 0.0369
2024-05-25 01:41:10 [INFO]: Epoch 017 - generator training loss: -0.0577, discriminator training loss: 0.1695, validation loss: 0.0338
2024-05-25 01:41:19 [INFO]: Epoch 018 - generator training loss: -0.0591, discriminator training loss: 0.1707, validation loss: 0.0330
2024-05-25 01:41:28 [INFO]: Epoch 019 - generator training loss: -0.0569, discriminator training loss: 0.1712, validation loss: 0.0345
2024-05-25 01:41:37 [INFO]: Epoch 020 - generator training loss: -0.0599, discriminator training loss: 0.1703, validation loss: 0.0438
2024-05-25 01:41:46 [INFO]: Epoch 021 - generator training loss: -0.0545, discriminator training loss: 0.1691, validation loss: 0.0373
2024-05-25 01:41:55 [INFO]: Epoch 022 - generator training loss: -0.0594, discriminator training loss: 0.1704, validation loss: 0.0334
2024-05-25 01:42:04 [INFO]: Epoch 023 - generator training loss: -0.0584, discriminator training loss: 0.1679, validation loss: 0.0313
2024-05-25 01:42:13 [INFO]: Epoch 024 - generator training loss: -0.0634, discriminator training loss: 0.1677, validation loss: 0.0316
2024-05-25 01:42:22 [INFO]: Epoch 025 - generator training loss: -0.0602, discriminator training loss: 0.1680, validation loss: 0.0318
2024-05-25 01:42:31 [INFO]: Epoch 026 - generator training loss: -0.0631, discriminator training loss: 0.1707, validation loss: 0.0311
2024-05-25 01:42:40 [INFO]: Epoch 027 - generator training loss: -0.0585, discriminator training loss: 0.1670, validation loss: 0.0306
2024-05-25 01:42:49 [INFO]: Epoch 028 - generator training loss: -0.0598, discriminator training loss: 0.1684, validation loss: 0.0309
2024-05-25 01:42:58 [INFO]: Epoch 029 - generator training loss: -0.0621, discriminator training loss: 0.1678, validation loss: 0.0299
2024-05-25 01:43:07 [INFO]: Epoch 030 - generator training loss: -0.0636, discriminator training loss: 0.1664, validation loss: 0.0297
2024-05-25 01:43:16 [INFO]: Epoch 031 - generator training loss: -0.0636, discriminator training loss: 0.1661, validation loss: 0.0298
2024-05-25 01:43:25 [INFO]: Epoch 032 - generator training loss: -0.0656, discriminator training loss: 0.1684, validation loss: 0.0293
2024-05-25 01:43:34 [INFO]: Epoch 033 - generator training loss: -0.0604, discriminator training loss: 0.1673, validation loss: 0.0297
2024-05-25 01:43:42 [INFO]: Epoch 034 - generator training loss: -0.0639, discriminator training loss: 0.1671, validation loss: 0.0298
2024-05-25 01:43:51 [INFO]: Epoch 035 - generator training loss: -0.0629, discriminator training loss: 0.1672, validation loss: 0.0293
2024-05-25 01:44:00 [INFO]: Epoch 036 - generator training loss: -0.0614, discriminator training loss: 0.1683, validation loss: 0.0287
2024-05-25 01:44:09 [INFO]: Epoch 037 - generator training loss: -0.0665, discriminator training loss: 0.1653, validation loss: 0.0294
2024-05-25 01:44:18 [INFO]: Epoch 038 - generator training loss: -0.0630, discriminator training loss: 0.1680, validation loss: 0.0284
2024-05-25 01:44:27 [INFO]: Epoch 039 - generator training loss: -0.0643, discriminator training loss: 0.1675, validation loss: 0.0277
2024-05-25 01:44:36 [INFO]: Epoch 040 - generator training loss: -0.0654, discriminator training loss: 0.1663, validation loss: 0.0280
2024-05-25 01:44:45 [INFO]: Epoch 041 - generator training loss: -0.0655, discriminator training loss: 0.1659, validation loss: 0.0282
2024-05-25 01:44:54 [INFO]: Epoch 042 - generator training loss: -0.0650, discriminator training loss: 0.1665, validation loss: 0.0290
2024-05-25 01:45:03 [INFO]: Epoch 043 - generator training loss: -0.0684, discriminator training loss: 0.1657, validation loss: 0.0274
2024-05-25 01:45:12 [INFO]: Epoch 044 - generator training loss: -0.0660, discriminator training loss: 0.1674, validation loss: 0.0267
2024-05-25 01:45:21 [INFO]: Epoch 045 - generator training loss: -0.0661, discriminator training loss: 0.1660, validation loss: 0.0266
2024-05-25 01:45:30 [INFO]: Epoch 046 - generator training loss: -0.0667, discriminator training loss: 0.1688, validation loss: 0.0264
2024-05-25 01:45:39 [INFO]: Epoch 047 - generator training loss: -0.0660, discriminator training loss: 0.1668, validation loss: 0.0265
2024-05-25 01:45:47 [INFO]: Epoch 048 - generator training loss: -0.0656, discriminator training loss: 0.1678, validation loss: 0.0266
2024-05-25 01:45:56 [INFO]: Epoch 049 - generator training loss: -0.0658, discriminator training loss: 0.1654, validation loss: 0.0262
2024-05-25 01:46:05 [INFO]: Epoch 050 - generator training loss: -0.0681, discriminator training loss: 0.1660, validation loss: 0.0263
2024-05-25 01:46:14 [INFO]: Epoch 051 - generator training loss: -0.0685, discriminator training loss: 0.1653, validation loss: 0.0260
2024-05-25 01:46:23 [INFO]: Epoch 052 - generator training loss: -0.0686, discriminator training loss: 0.1664, validation loss: 0.0261
2024-05-25 01:46:32 [INFO]: Epoch 053 - generator training loss: -0.0678, discriminator training loss: 0.1642, validation loss: 0.0263
2024-05-25 01:46:41 [INFO]: Epoch 054 - generator training loss: -0.0683, discriminator training loss: 0.1662, validation loss: 0.0262
2024-05-25 01:46:50 [INFO]: Epoch 055 - generator training loss: -0.0674, discriminator training loss: 0.1653, validation loss: 0.0260
2024-05-25 01:46:59 [INFO]: Epoch 056 - generator training loss: -0.0660, discriminator training loss: 0.1670, validation loss: 0.0257
2024-05-25 01:47:08 [INFO]: Epoch 057 - generator training loss: -0.0685, discriminator training loss: 0.1661, validation loss: 0.0264
2024-05-25 01:47:17 [INFO]: Epoch 058 - generator training loss: -0.0665, discriminator training loss: 0.1639, validation loss: 0.0263
2024-05-25 01:47:25 [INFO]: Epoch 059 - generator training loss: -0.0664, discriminator training loss: 0.1643, validation loss: 0.0264
2024-05-25 01:47:34 [INFO]: Epoch 060 - generator training loss: -0.0678, discriminator training loss: 0.1641, validation loss: 0.0254
2024-05-25 01:47:44 [INFO]: Epoch 061 - generator training loss: -0.0681, discriminator training loss: 0.1644, validation loss: 0.0258
2024-05-25 01:47:53 [INFO]: Epoch 062 - generator training loss: -0.0705, discriminator training loss: 0.1658, validation loss: 0.0254
2024-05-25 01:48:02 [INFO]: Epoch 063 - generator training loss: -0.0686, discriminator training loss: 0.1652, validation loss: 0.0261
2024-05-25 01:48:11 [INFO]: Epoch 064 - generator training loss: -0.0649, discriminator training loss: 0.1661, validation loss: 0.0261
2024-05-25 01:48:20 [INFO]: Epoch 065 - generator training loss: -0.0683, discriminator training loss: 0.1639, validation loss: 0.0257
2024-05-25 01:48:29 [INFO]: Epoch 066 - generator training loss: -0.0682, discriminator training loss: 0.1631, validation loss: 0.0261
2024-05-25 01:48:38 [INFO]: Epoch 067 - generator training loss: -0.0705, discriminator training loss: 0.1629, validation loss: 0.0254
2024-05-25 01:48:47 [INFO]: Epoch 068 - generator training loss: -0.0664, discriminator training loss: 0.1642, validation loss: 0.0261
2024-05-25 01:48:56 [INFO]: Epoch 069 - generator training loss: -0.0672, discriminator training loss: 0.1644, validation loss: 0.0261
2024-05-25 01:49:05 [INFO]: Epoch 070 - generator training loss: -0.0650, discriminator training loss: 0.1621, validation loss: 0.0262
2024-05-25 01:49:14 [INFO]: Epoch 071 - generator training loss: -0.0691, discriminator training loss: 0.1621, validation loss: 0.0254
2024-05-25 01:49:23 [INFO]: Epoch 072 - generator training loss: -0.0718, discriminator training loss: 0.1633, validation loss: 0.0251
2024-05-25 01:49:31 [INFO]: Epoch 073 - generator training loss: -0.0672, discriminator training loss: 0.1633, validation loss: 0.0251
2024-05-25 01:49:40 [INFO]: Epoch 074 - generator training loss: -0.0696, discriminator training loss: 0.1647, validation loss: 0.0252
2024-05-25 01:49:49 [INFO]: Epoch 075 - generator training loss: -0.0699, discriminator training loss: 0.1639, validation loss: 0.0260
2024-05-25 01:49:58 [INFO]: Epoch 076 - generator training loss: -0.0685, discriminator training loss: 0.1637, validation loss: 0.0252
2024-05-25 01:50:07 [INFO]: Epoch 077 - generator training loss: -0.0674, discriminator training loss: 0.1641, validation loss: 0.0248
2024-05-25 01:50:16 [INFO]: Epoch 078 - generator training loss: -0.0699, discriminator training loss: 0.1634, validation loss: 0.0246
2024-05-25 01:50:25 [INFO]: Epoch 079 - generator training loss: -0.0698, discriminator training loss: 0.1634, validation loss: 0.0248
2024-05-25 01:50:34 [INFO]: Epoch 080 - generator training loss: -0.0672, discriminator training loss: 0.1619, validation loss: 0.0278
2024-05-25 01:50:43 [INFO]: Epoch 081 - generator training loss: -0.0698, discriminator training loss: 0.1585, validation loss: 0.0248
2024-05-25 01:50:52 [INFO]: Epoch 082 - generator training loss: -0.0687, discriminator training loss: 0.1630, validation loss: 0.0259
2024-05-25 01:51:01 [INFO]: Epoch 083 - generator training loss: -0.0688, discriminator training loss: 0.1641, validation loss: 0.0249
2024-05-25 01:51:10 [INFO]: Epoch 084 - generator training loss: -0.0688, discriminator training loss: 0.1619, validation loss: 0.0248
2024-05-25 01:51:19 [INFO]: Epoch 085 - generator training loss: -0.0712, discriminator training loss: 0.1646, validation loss: 0.0261
2024-05-25 01:51:28 [INFO]: Epoch 086 - generator training loss: -0.0683, discriminator training loss: 0.1633, validation loss: 0.0252
2024-05-25 01:51:37 [INFO]: Epoch 087 - generator training loss: -0.0681, discriminator training loss: 0.1617, validation loss: 0.0260
2024-05-25 01:51:46 [INFO]: Epoch 088 - generator training loss: -0.0680, discriminator training loss: 0.1612, validation loss: 0.0244
2024-05-25 01:51:55 [INFO]: Epoch 089 - generator training loss: -0.0724, discriminator training loss: 0.1614, validation loss: 0.0237
2024-05-25 01:52:04 [INFO]: Epoch 090 - generator training loss: -0.0704, discriminator training loss: 0.1603, validation loss: 0.0240
2024-05-25 01:52:13 [INFO]: Epoch 091 - generator training loss: -0.0697, discriminator training loss: 0.1607, validation loss: 0.0245
2024-05-25 01:52:22 [INFO]: Epoch 092 - generator training loss: -0.0680, discriminator training loss: 0.1607, validation loss: 0.0248
2024-05-25 01:52:31 [INFO]: Epoch 093 - generator training loss: -0.0704, discriminator training loss: 0.1623, validation loss: 0.0249
2024-05-25 01:52:40 [INFO]: Epoch 094 - generator training loss: -0.0701, discriminator training loss: 0.1603, validation loss: 0.0240
2024-05-25 01:52:49 [INFO]: Epoch 095 - generator training loss: -0.0699, discriminator training loss: 0.1610, validation loss: 0.0241
2024-05-25 01:52:58 [INFO]: Epoch 096 - generator training loss: -0.0676, discriminator training loss: 0.1608, validation loss: 0.0250
2024-05-25 01:53:07 [INFO]: Epoch 097 - generator training loss: -0.0703, discriminator training loss: 0.1608, validation loss: 0.0238
2024-05-25 01:53:16 [INFO]: Epoch 098 - generator training loss: -0.0687, discriminator training loss: 0.1616, validation loss: 0.0239
2024-05-25 01:53:25 [INFO]: Epoch 099 - generator training loss: -0.0696, discriminator training loss: 0.1600, validation loss: 0.0243
2024-05-25 01:53:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:53:25 [INFO]: Finished training. The best model is from epoch#89.
2024-05-25 01:53:25 [INFO]: Saved the model to augmentation_saved_results/round_1/USGAN_ettm1/20240525_T013835/USGAN.pypots
2024-05-25 01:53:26 [INFO]: US-GAN on ETTm1: MAE=0.1612, MSE=0.0669
2024-05-25 01:53:26 [INFO]: Successfully saved to augmentation_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-25 01:53:26 [INFO]: Using the given device: cuda:0
2024-05-25 01:53:26 [INFO]: Model files will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015326
2024-05-25 01:53:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015326/tensorboard
2024-05-25 01:53:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 01:53:33 [INFO]: Epoch 001 - training loss: 1.4160, validation loss: 0.3329
2024-05-25 01:53:39 [INFO]: Epoch 002 - training loss: 0.9508, validation loss: 0.1505
2024-05-25 01:53:45 [INFO]: Epoch 003 - training loss: 0.7535, validation loss: 0.0643
2024-05-25 01:53:51 [INFO]: Epoch 004 - training loss: 0.6681, validation loss: 0.0519
2024-05-25 01:53:57 [INFO]: Epoch 005 - training loss: 0.6145, validation loss: 0.0478
2024-05-25 01:54:03 [INFO]: Epoch 006 - training loss: 0.5842, validation loss: 0.0478
2024-05-25 01:54:09 [INFO]: Epoch 007 - training loss: 0.5788, validation loss: 0.0419
2024-05-25 01:54:15 [INFO]: Epoch 008 - training loss: 0.5441, validation loss: 0.0344
2024-05-25 01:54:21 [INFO]: Epoch 009 - training loss: 0.5120, validation loss: 0.0333
2024-05-25 01:54:27 [INFO]: Epoch 010 - training loss: 0.5027, validation loss: 0.0318
2024-05-25 01:54:33 [INFO]: Epoch 011 - training loss: 0.5004, validation loss: 0.0302
2024-05-25 01:54:39 [INFO]: Epoch 012 - training loss: 0.4761, validation loss: 0.0296
2024-05-25 01:54:45 [INFO]: Epoch 013 - training loss: 0.4494, validation loss: 0.0281
2024-05-25 01:54:51 [INFO]: Epoch 014 - training loss: 0.4359, validation loss: 0.0280
2024-05-25 01:54:57 [INFO]: Epoch 015 - training loss: 0.4293, validation loss: 0.0274
2024-05-25 01:55:03 [INFO]: Epoch 016 - training loss: 0.4220, validation loss: 0.0271
2024-05-25 01:55:09 [INFO]: Epoch 017 - training loss: 0.4341, validation loss: 0.0270
2024-05-25 01:55:15 [INFO]: Epoch 018 - training loss: 0.4157, validation loss: 0.0261
2024-05-25 01:55:21 [INFO]: Epoch 019 - training loss: 0.4176, validation loss: 0.0254
2024-05-25 01:55:27 [INFO]: Epoch 020 - training loss: 0.4074, validation loss: 0.0255
2024-05-25 01:55:32 [INFO]: Epoch 021 - training loss: 0.4029, validation loss: 0.0259
2024-05-25 01:55:38 [INFO]: Epoch 022 - training loss: 0.4684, validation loss: 0.0256
2024-05-25 01:55:44 [INFO]: Epoch 023 - training loss: 0.4209, validation loss: 0.0265
2024-05-25 01:55:50 [INFO]: Epoch 024 - training loss: 0.4097, validation loss: 0.0255
2024-05-25 01:55:56 [INFO]: Epoch 025 - training loss: 0.3992, validation loss: 0.0281
2024-05-25 01:56:02 [INFO]: Epoch 026 - training loss: 0.4167, validation loss: 0.0272
2024-05-25 01:56:08 [INFO]: Epoch 027 - training loss: 0.4083, validation loss: 0.0261
2024-05-25 01:56:14 [INFO]: Epoch 028 - training loss: 0.4013, validation loss: 0.0253
2024-05-25 01:56:20 [INFO]: Epoch 029 - training loss: 0.4021, validation loss: 0.0254
2024-05-25 01:56:26 [INFO]: Epoch 030 - training loss: 0.3959, validation loss: 0.0257
2024-05-25 01:56:32 [INFO]: Epoch 031 - training loss: 0.3980, validation loss: 0.0258
2024-05-25 01:56:38 [INFO]: Epoch 032 - training loss: 0.3992, validation loss: 0.0255
2024-05-25 01:56:44 [INFO]: Epoch 033 - training loss: 0.3949, validation loss: 0.0257
2024-05-25 01:56:50 [INFO]: Epoch 034 - training loss: 0.3942, validation loss: 0.0250
2024-05-25 01:56:56 [INFO]: Epoch 035 - training loss: 0.3949, validation loss: 0.0249
2024-05-25 01:57:02 [INFO]: Epoch 036 - training loss: 0.3999, validation loss: 0.0252
2024-05-25 01:57:07 [INFO]: Epoch 037 - training loss: 0.3954, validation loss: 0.0254
2024-05-25 01:57:14 [INFO]: Epoch 038 - training loss: 0.3950, validation loss: 0.0254
2024-05-25 01:57:19 [INFO]: Epoch 039 - training loss: 0.3935, validation loss: 0.0257
2024-05-25 01:57:25 [INFO]: Epoch 040 - training loss: 0.3946, validation loss: 0.0267
2024-05-25 01:57:31 [INFO]: Epoch 041 - training loss: 0.3968, validation loss: 0.0254
2024-05-25 01:57:37 [INFO]: Epoch 042 - training loss: 0.4009, validation loss: 0.0251
2024-05-25 01:57:43 [INFO]: Epoch 043 - training loss: 0.3917, validation loss: 0.0260
2024-05-25 01:57:49 [INFO]: Epoch 044 - training loss: 0.3919, validation loss: 0.0250
2024-05-25 01:57:55 [INFO]: Epoch 045 - training loss: 0.4036, validation loss: 0.0261
2024-05-25 01:57:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:57:55 [INFO]: Finished training. The best model is from epoch#35.
2024-05-25 01:57:55 [INFO]: Saved the model to augmentation_saved_results/round_1/BRITS_ettm1/20240525_T015326/BRITS.pypots
2024-05-25 01:57:56 [INFO]: BRITS on ETTm1: MAE=0.1390, MSE=0.0588
2024-05-25 01:57:56 [INFO]: Successfully saved to augmentation_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-25 01:57:56 [INFO]: Using the given device: cuda:0
2024-05-25 01:57:56 [INFO]: Model files will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756
2024-05-25 01:57:56 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/tensorboard
2024-05-25 01:57:56 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 01:57:58 [INFO]: Epoch 001 - training loss: 1.4150, validation loss: 1.3578
2024-05-25 01:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch1_loss1.3577624559402466.pypots
2024-05-25 01:57:58 [INFO]: Epoch 002 - training loss: 1.0218, validation loss: 1.1909
2024-05-25 01:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch2_loss1.1908505856990814.pypots
2024-05-25 01:57:58 [INFO]: Epoch 003 - training loss: 0.9272, validation loss: 1.0913
2024-05-25 01:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch3_loss1.091261014342308.pypots
2024-05-25 01:57:58 [INFO]: Epoch 004 - training loss: 0.9037, validation loss: 1.0516
2024-05-25 01:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch4_loss1.051645576953888.pypots
2024-05-25 01:57:58 [INFO]: Epoch 005 - training loss: 0.8756, validation loss: 1.0407
2024-05-25 01:57:58 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch5_loss1.040747031569481.pypots
2024-05-25 01:57:59 [INFO]: Epoch 006 - training loss: 0.8776, validation loss: 1.0337
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch6_loss1.0336576253175735.pypots
2024-05-25 01:57:59 [INFO]: Epoch 007 - training loss: 0.8640, validation loss: 1.0287
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch7_loss1.0286839008331299.pypots
2024-05-25 01:57:59 [INFO]: Epoch 008 - training loss: 0.8385, validation loss: 1.0259
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch8_loss1.0259095430374146.pypots
2024-05-25 01:57:59 [INFO]: Epoch 009 - training loss: 0.8627, validation loss: 1.0213
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch9_loss1.0213343650102615.pypots
2024-05-25 01:57:59 [INFO]: Epoch 010 - training loss: 0.8745, validation loss: 1.0183
2024-05-25 01:57:59 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch10_loss1.0182726234197617.pypots
2024-05-25 01:58:00 [INFO]: Epoch 011 - training loss: 0.8546, validation loss: 1.0183
2024-05-25 01:58:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch11_loss1.0183219462633133.pypots
2024-05-25 01:58:00 [INFO]: Epoch 012 - training loss: 0.8312, validation loss: 1.0135
2024-05-25 01:58:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch12_loss1.0134944170713425.pypots
2024-05-25 01:58:00 [INFO]: Epoch 013 - training loss: 0.8418, validation loss: 1.0117
2024-05-25 01:58:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch13_loss1.0117409974336624.pypots
2024-05-25 01:58:00 [INFO]: Epoch 014 - training loss: 0.8332, validation loss: 1.0047
2024-05-25 01:58:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch14_loss1.004735291004181.pypots
2024-05-25 01:58:00 [INFO]: Epoch 015 - training loss: 0.8338, validation loss: 1.0001
2024-05-25 01:58:00 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch15_loss1.0001024454832077.pypots
2024-05-25 01:58:01 [INFO]: Epoch 016 - training loss: 0.8216, validation loss: 0.9945
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch16_loss0.9944680035114288.pypots
2024-05-25 01:58:01 [INFO]: Epoch 017 - training loss: 0.8319, validation loss: 0.9881
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch17_loss0.9880729168653488.pypots
2024-05-25 01:58:01 [INFO]: Epoch 018 - training loss: 0.7893, validation loss: 0.9827
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch18_loss0.9827287495136261.pypots
2024-05-25 01:58:01 [INFO]: Epoch 019 - training loss: 0.7933, validation loss: 0.9759
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch19_loss0.9758706837892532.pypots
2024-05-25 01:58:01 [INFO]: Epoch 020 - training loss: 0.7937, validation loss: 0.9754
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch20_loss0.9753886014223099.pypots
2024-05-25 01:58:01 [INFO]: Epoch 021 - training loss: 0.7882, validation loss: 0.9697
2024-05-25 01:58:01 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch21_loss0.9696523100137711.pypots
2024-05-25 01:58:02 [INFO]: Epoch 022 - training loss: 0.7834, validation loss: 0.9636
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch22_loss0.9636049717664719.pypots
2024-05-25 01:58:02 [INFO]: Epoch 023 - training loss: 0.7731, validation loss: 0.9593
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch23_loss0.9593317210674286.pypots
2024-05-25 01:58:02 [INFO]: Epoch 024 - training loss: 0.7707, validation loss: 0.9566
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch24_loss0.956586480140686.pypots
2024-05-25 01:58:02 [INFO]: Epoch 025 - training loss: 0.7774, validation loss: 0.9542
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch25_loss0.9541721343994141.pypots
2024-05-25 01:58:02 [INFO]: Epoch 026 - training loss: 0.7758, validation loss: 0.9502
2024-05-25 01:58:02 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch26_loss0.9502125978469849.pypots
2024-05-25 01:58:03 [INFO]: Epoch 027 - training loss: 0.7761, validation loss: 0.9470
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch27_loss0.9470072686672211.pypots
2024-05-25 01:58:03 [INFO]: Epoch 028 - training loss: 0.7806, validation loss: 0.9444
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch28_loss0.9444300383329391.pypots
2024-05-25 01:58:03 [INFO]: Epoch 029 - training loss: 0.7605, validation loss: 0.9418
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch29_loss0.9417950809001923.pypots
2024-05-25 01:58:03 [INFO]: Epoch 030 - training loss: 0.7719, validation loss: 0.9408
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch30_loss0.9408412575721741.pypots
2024-05-25 01:58:03 [INFO]: Epoch 031 - training loss: 0.7439, validation loss: 0.9350
2024-05-25 01:58:03 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch31_loss0.9349672496318817.pypots
2024-05-25 01:58:04 [INFO]: Epoch 032 - training loss: 0.7607, validation loss: 0.9315
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch32_loss0.9315212666988373.pypots
2024-05-25 01:58:04 [INFO]: Epoch 033 - training loss: 0.7762, validation loss: 0.9320
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch33_loss0.9320183098316193.pypots
2024-05-25 01:58:04 [INFO]: Epoch 034 - training loss: 0.7637, validation loss: 0.9293
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch34_loss0.9293374717235565.pypots
2024-05-25 01:58:04 [INFO]: Epoch 035 - training loss: 0.7635, validation loss: 0.9293
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch35_loss0.929272010922432.pypots
2024-05-25 01:58:04 [INFO]: Epoch 036 - training loss: 0.7608, validation loss: 0.9268
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch36_loss0.9268095344305038.pypots
2024-05-25 01:58:04 [INFO]: Epoch 037 - training loss: 0.7640, validation loss: 0.9222
2024-05-25 01:58:04 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch37_loss0.9222486466169357.pypots
2024-05-25 01:58:05 [INFO]: Epoch 038 - training loss: 0.7734, validation loss: 0.9200
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch38_loss0.9199536591768265.pypots
2024-05-25 01:58:05 [INFO]: Epoch 039 - training loss: 0.7617, validation loss: 0.9189
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch39_loss0.9188559353351593.pypots
2024-05-25 01:58:05 [INFO]: Epoch 040 - training loss: 0.7579, validation loss: 0.9167
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch40_loss0.9167238771915436.pypots
2024-05-25 01:58:05 [INFO]: Epoch 041 - training loss: 0.7625, validation loss: 0.9168
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch41_loss0.9167921841144562.pypots
2024-05-25 01:58:05 [INFO]: Epoch 042 - training loss: 0.7703, validation loss: 0.9147
2024-05-25 01:58:05 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch42_loss0.914662629365921.pypots
2024-05-25 01:58:06 [INFO]: Epoch 043 - training loss: 0.7398, validation loss: 0.9136
2024-05-25 01:58:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch43_loss0.9135830402374268.pypots
2024-05-25 01:58:06 [INFO]: Epoch 044 - training loss: 0.7553, validation loss: 0.9114
2024-05-25 01:58:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch44_loss0.91142338514328.pypots
2024-05-25 01:58:06 [INFO]: Epoch 045 - training loss: 0.7761, validation loss: 0.9110
2024-05-25 01:58:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch45_loss0.9110353738069534.pypots
2024-05-25 01:58:06 [INFO]: Epoch 046 - training loss: 0.7440, validation loss: 0.9098
2024-05-25 01:58:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch46_loss0.9098270535469055.pypots
2024-05-25 01:58:06 [INFO]: Epoch 047 - training loss: 0.7469, validation loss: 0.9126
2024-05-25 01:58:06 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch47_loss0.9126060605049133.pypots
2024-05-25 01:58:07 [INFO]: Epoch 048 - training loss: 0.7278, validation loss: 0.9069
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch48_loss0.9069294780492783.pypots
2024-05-25 01:58:07 [INFO]: Epoch 049 - training loss: 0.7776, validation loss: 0.9066
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch49_loss0.9066459238529205.pypots
2024-05-25 01:58:07 [INFO]: Epoch 050 - training loss: 0.7616, validation loss: 0.9076
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch50_loss0.9075711518526077.pypots
2024-05-25 01:58:07 [INFO]: Epoch 051 - training loss: 0.7408, validation loss: 0.9053
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch51_loss0.9053432494401932.pypots
2024-05-25 01:58:07 [INFO]: Epoch 052 - training loss: 0.7428, validation loss: 0.9050
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch52_loss0.9050303250551224.pypots
2024-05-25 01:58:07 [INFO]: Epoch 053 - training loss: 0.7835, validation loss: 0.9060
2024-05-25 01:58:07 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch53_loss0.905996635556221.pypots
2024-05-25 01:58:08 [INFO]: Epoch 054 - training loss: 0.7660, validation loss: 0.9017
2024-05-25 01:58:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch54_loss0.9017104655504227.pypots
2024-05-25 01:58:08 [INFO]: Epoch 055 - training loss: 0.7377, validation loss: 0.9044
2024-05-25 01:58:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch55_loss0.9044246524572372.pypots
2024-05-25 01:58:08 [INFO]: Epoch 056 - training loss: 0.7467, validation loss: 0.9000
2024-05-25 01:58:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch56_loss0.9000204503536224.pypots
2024-05-25 01:58:08 [INFO]: Epoch 057 - training loss: 0.7182, validation loss: 0.9020
2024-05-25 01:58:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch57_loss0.9020432084798813.pypots
2024-05-25 01:58:08 [INFO]: Epoch 058 - training loss: 0.7413, validation loss: 0.9005
2024-05-25 01:58:08 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch58_loss0.9005172401666641.pypots
2024-05-25 01:58:09 [INFO]: Epoch 059 - training loss: 0.7437, validation loss: 0.8987
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch59_loss0.8987053483724594.pypots
2024-05-25 01:58:09 [INFO]: Epoch 060 - training loss: 0.7824, validation loss: 0.8989
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch60_loss0.8988502770662308.pypots
2024-05-25 01:58:09 [INFO]: Epoch 061 - training loss: 0.7649, validation loss: 0.8955
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch61_loss0.8954540342092514.pypots
2024-05-25 01:58:09 [INFO]: Epoch 062 - training loss: 0.7315, validation loss: 0.8981
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch62_loss0.8980619162321091.pypots
2024-05-25 01:58:09 [INFO]: Epoch 063 - training loss: 0.7333, validation loss: 0.8969
2024-05-25 01:58:09 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch63_loss0.8969288319349289.pypots
2024-05-25 01:58:10 [INFO]: Epoch 064 - training loss: 0.7379, validation loss: 0.8953
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch64_loss0.8953310251235962.pypots
2024-05-25 01:58:10 [INFO]: Epoch 065 - training loss: 0.7309, validation loss: 0.8966
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch65_loss0.8966195434331894.pypots
2024-05-25 01:58:10 [INFO]: Epoch 066 - training loss: 0.7401, validation loss: 0.8956
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch66_loss0.895614892244339.pypots
2024-05-25 01:58:10 [INFO]: Epoch 067 - training loss: 0.7451, validation loss: 0.8973
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch67_loss0.8972879350185394.pypots
2024-05-25 01:58:10 [INFO]: Epoch 068 - training loss: 0.7228, validation loss: 0.8976
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch68_loss0.8975595533847809.pypots
2024-05-25 01:58:10 [INFO]: Epoch 069 - training loss: 0.7276, validation loss: 0.8957
2024-05-25 01:58:10 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch69_loss0.8956644088029861.pypots
2024-05-25 01:58:11 [INFO]: Epoch 070 - training loss: 0.7424, validation loss: 0.8953
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch70_loss0.89527727663517.pypots
2024-05-25 01:58:11 [INFO]: Epoch 071 - training loss: 0.7420, validation loss: 0.8956
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch71_loss0.8956039249897003.pypots
2024-05-25 01:58:11 [INFO]: Epoch 072 - training loss: 0.7461, validation loss: 0.8954
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch72_loss0.8953953981399536.pypots
2024-05-25 01:58:11 [INFO]: Epoch 073 - training loss: 0.7450, validation loss: 0.8907
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch73_loss0.8907290399074554.pypots
2024-05-25 01:58:11 [INFO]: Epoch 074 - training loss: 0.7569, validation loss: 0.8942
2024-05-25 01:58:11 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch74_loss0.8942156285047531.pypots
2024-05-25 01:58:12 [INFO]: Epoch 075 - training loss: 0.7514, validation loss: 0.8912
2024-05-25 01:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch75_loss0.8911713063716888.pypots
2024-05-25 01:58:12 [INFO]: Epoch 076 - training loss: 0.7269, validation loss: 0.8945
2024-05-25 01:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch76_loss0.8945007175207138.pypots
2024-05-25 01:58:12 [INFO]: Epoch 077 - training loss: 0.7333, validation loss: 0.8915
2024-05-25 01:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch77_loss0.8915146142244339.pypots
2024-05-25 01:58:12 [INFO]: Epoch 078 - training loss: 0.7359, validation loss: 0.8931
2024-05-25 01:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch78_loss0.8930810242891312.pypots
2024-05-25 01:58:12 [INFO]: Epoch 079 - training loss: 0.7467, validation loss: 0.8928
2024-05-25 01:58:12 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch79_loss0.8928366303443909.pypots
2024-05-25 01:58:13 [INFO]: Epoch 080 - training loss: 0.7719, validation loss: 0.8931
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch80_loss0.8930563628673553.pypots
2024-05-25 01:58:13 [INFO]: Epoch 081 - training loss: 0.7610, validation loss: 0.8891
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch81_loss0.8890859186649323.pypots
2024-05-25 01:58:13 [INFO]: Epoch 082 - training loss: 0.7800, validation loss: 0.8925
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch82_loss0.8924643248319626.pypots
2024-05-25 01:58:13 [INFO]: Epoch 083 - training loss: 0.7247, validation loss: 0.8934
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch83_loss0.8934434950351715.pypots
2024-05-25 01:58:13 [INFO]: Epoch 084 - training loss: 0.7125, validation loss: 0.8909
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch84_loss0.8908581435680389.pypots
2024-05-25 01:58:13 [INFO]: Epoch 085 - training loss: 0.7430, validation loss: 0.8889
2024-05-25 01:58:13 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch85_loss0.8889093995094299.pypots
2024-05-25 01:58:14 [INFO]: Epoch 086 - training loss: 0.7462, validation loss: 0.8877
2024-05-25 01:58:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch86_loss0.8876802623271942.pypots
2024-05-25 01:58:14 [INFO]: Epoch 087 - training loss: 0.7212, validation loss: 0.8878
2024-05-25 01:58:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch87_loss0.8878066539764404.pypots
2024-05-25 01:58:14 [INFO]: Epoch 088 - training loss: 0.7352, validation loss: 0.8921
2024-05-25 01:58:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch88_loss0.8920781314373016.pypots
2024-05-25 01:58:14 [INFO]: Epoch 089 - training loss: 0.7832, validation loss: 0.8899
2024-05-25 01:58:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch89_loss0.8899008929729462.pypots
2024-05-25 01:58:14 [INFO]: Epoch 090 - training loss: 0.7621, validation loss: 0.8865
2024-05-25 01:58:14 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch90_loss0.8864618241786957.pypots
2024-05-25 01:58:15 [INFO]: Epoch 091 - training loss: 0.7450, validation loss: 0.8876
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch91_loss0.8876047432422638.pypots
2024-05-25 01:58:15 [INFO]: Epoch 092 - training loss: 0.7207, validation loss: 0.8887
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch92_loss0.8886618763208389.pypots
2024-05-25 01:58:15 [INFO]: Epoch 093 - training loss: 0.7251, validation loss: 0.8921
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch93_loss0.8920831680297852.pypots
2024-05-25 01:58:15 [INFO]: Epoch 094 - training loss: 0.7131, validation loss: 0.8891
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch94_loss0.8890561461448669.pypots
2024-05-25 01:58:15 [INFO]: Epoch 095 - training loss: 0.7271, validation loss: 0.8878
2024-05-25 01:58:15 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch95_loss0.8878135830163956.pypots
2024-05-25 01:58:16 [INFO]: Epoch 096 - training loss: 0.7421, validation loss: 0.8865
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch96_loss0.8864891082048416.pypots
2024-05-25 01:58:16 [INFO]: Epoch 097 - training loss: 0.7245, validation loss: 0.8855
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch97_loss0.8854623287916183.pypots
2024-05-25 01:58:16 [INFO]: Epoch 098 - training loss: 0.7437, validation loss: 0.8833
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch98_loss0.8833156079053879.pypots
2024-05-25 01:58:16 [INFO]: Epoch 099 - training loss: 0.7338, validation loss: 0.8857
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch99_loss0.8856826722621918.pypots
2024-05-25 01:58:16 [INFO]: Epoch 100 - training loss: 0.7077, validation loss: 0.8872
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch100_loss0.8872418999671936.pypots
2024-05-25 01:58:16 [INFO]: Epoch 101 - training loss: 0.7225, validation loss: 0.8858
2024-05-25 01:58:16 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch101_loss0.8857761472463608.pypots
2024-05-25 01:58:17 [INFO]: Epoch 102 - training loss: 0.7248, validation loss: 0.8833
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch102_loss0.8832893371582031.pypots
2024-05-25 01:58:17 [INFO]: Epoch 103 - training loss: 0.7408, validation loss: 0.8847
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch103_loss0.884678989648819.pypots
2024-05-25 01:58:17 [INFO]: Epoch 104 - training loss: 0.7235, validation loss: 0.8849
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch104_loss0.8849050998687744.pypots
2024-05-25 01:58:17 [INFO]: Epoch 105 - training loss: 0.7371, validation loss: 0.8851
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch105_loss0.8850823044776917.pypots
2024-05-25 01:58:17 [INFO]: Epoch 106 - training loss: 0.7164, validation loss: 0.8837
2024-05-25 01:58:17 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch106_loss0.8836642652750015.pypots
2024-05-25 01:58:18 [INFO]: Epoch 107 - training loss: 0.7371, validation loss: 0.8835
2024-05-25 01:58:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch107_loss0.8835130929946899.pypots
2024-05-25 01:58:18 [INFO]: Epoch 108 - training loss: 0.7317, validation loss: 0.8816
2024-05-25 01:58:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch108_loss0.8815754503011703.pypots
2024-05-25 01:58:18 [INFO]: Epoch 109 - training loss: 0.7289, validation loss: 0.8829
2024-05-25 01:58:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch109_loss0.8829206973314285.pypots
2024-05-25 01:58:18 [INFO]: Epoch 110 - training loss: 0.7297, validation loss: 0.8820
2024-05-25 01:58:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch110_loss0.881967157125473.pypots
2024-05-25 01:58:18 [INFO]: Epoch 111 - training loss: 0.7268, validation loss: 0.8794
2024-05-25 01:58:18 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch111_loss0.8793963938951492.pypots
2024-05-25 01:58:19 [INFO]: Epoch 112 - training loss: 0.7371, validation loss: 0.8796
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch112_loss0.879636287689209.pypots
2024-05-25 01:58:19 [INFO]: Epoch 113 - training loss: 0.7496, validation loss: 0.8794
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch113_loss0.8793755918741226.pypots
2024-05-25 01:58:19 [INFO]: Epoch 114 - training loss: 0.7122, validation loss: 0.8790
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch114_loss0.8789987713098526.pypots
2024-05-25 01:58:19 [INFO]: Epoch 115 - training loss: 0.7248, validation loss: 0.8788
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch115_loss0.8788011074066162.pypots
2024-05-25 01:58:19 [INFO]: Epoch 116 - training loss: 0.7149, validation loss: 0.8793
2024-05-25 01:58:19 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch116_loss0.8792704343795776.pypots
2024-05-25 01:58:20 [INFO]: Epoch 117 - training loss: 0.7228, validation loss: 0.8770
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch117_loss0.8769502937793732.pypots
2024-05-25 01:58:20 [INFO]: Epoch 118 - training loss: 0.7068, validation loss: 0.8796
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch118_loss0.8796098083257675.pypots
2024-05-25 01:58:20 [INFO]: Epoch 119 - training loss: 0.7211, validation loss: 0.8750
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch119_loss0.8750291615724564.pypots
2024-05-25 01:58:20 [INFO]: Epoch 120 - training loss: 0.7185, validation loss: 0.8764
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch120_loss0.876440092921257.pypots
2024-05-25 01:58:20 [INFO]: Epoch 121 - training loss: 0.7501, validation loss: 0.8715
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch121_loss0.8715499937534332.pypots
2024-05-25 01:58:20 [INFO]: Epoch 122 - training loss: 0.7352, validation loss: 0.8766
2024-05-25 01:58:20 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch122_loss0.8766296356916428.pypots
2024-05-25 01:58:21 [INFO]: Epoch 123 - training loss: 0.7196, validation loss: 0.8745
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch123_loss0.874466136097908.pypots
2024-05-25 01:58:21 [INFO]: Epoch 124 - training loss: 0.7268, validation loss: 0.8729
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch124_loss0.8729203790426254.pypots
2024-05-25 01:58:21 [INFO]: Epoch 125 - training loss: 0.7168, validation loss: 0.8720
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch125_loss0.87204210460186.pypots
2024-05-25 01:58:21 [INFO]: Epoch 126 - training loss: 0.7191, validation loss: 0.8742
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch126_loss0.8742337226867676.pypots
2024-05-25 01:58:21 [INFO]: Epoch 127 - training loss: 0.7621, validation loss: 0.8701
2024-05-25 01:58:21 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch127_loss0.8701363354921341.pypots
2024-05-25 01:58:22 [INFO]: Epoch 128 - training loss: 0.7493, validation loss: 0.8663
2024-05-25 01:58:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch128_loss0.8663473129272461.pypots
2024-05-25 01:58:22 [INFO]: Epoch 129 - training loss: 0.7445, validation loss: 0.8693
2024-05-25 01:58:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch129_loss0.8692588657140732.pypots
2024-05-25 01:58:22 [INFO]: Epoch 130 - training loss: 0.7274, validation loss: 0.8670
2024-05-25 01:58:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch130_loss0.8670382052659988.pypots
2024-05-25 01:58:22 [INFO]: Epoch 131 - training loss: 0.7178, validation loss: 0.8689
2024-05-25 01:58:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch131_loss0.8689060509204865.pypots
2024-05-25 01:58:22 [INFO]: Epoch 132 - training loss: 0.7285, validation loss: 0.8710
2024-05-25 01:58:22 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch132_loss0.8709593564271927.pypots
2024-05-25 01:58:23 [INFO]: Epoch 133 - training loss: 0.7144, validation loss: 0.8666
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch133_loss0.8666100949048996.pypots
2024-05-25 01:58:23 [INFO]: Epoch 134 - training loss: 0.7303, validation loss: 0.8639
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch134_loss0.8638575375080109.pypots
2024-05-25 01:58:23 [INFO]: Epoch 135 - training loss: 0.7323, validation loss: 0.8626
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch135_loss0.8625561147928238.pypots
2024-05-25 01:58:23 [INFO]: Epoch 136 - training loss: 0.7495, validation loss: 0.8717
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch136_loss0.8717102706432343.pypots
2024-05-25 01:58:23 [INFO]: Epoch 137 - training loss: 0.7337, validation loss: 0.8656
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch137_loss0.8656327575445175.pypots
2024-05-25 01:58:23 [INFO]: Epoch 138 - training loss: 0.7277, validation loss: 0.8643
2024-05-25 01:58:23 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch138_loss0.8642660975456238.pypots
2024-05-25 01:58:24 [INFO]: Epoch 139 - training loss: 0.7087, validation loss: 0.8623
2024-05-25 01:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch139_loss0.8623460680246353.pypots
2024-05-25 01:58:24 [INFO]: Epoch 140 - training loss: 0.7384, validation loss: 0.8632
2024-05-25 01:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch140_loss0.8632003366947174.pypots
2024-05-25 01:58:24 [INFO]: Epoch 141 - training loss: 0.7023, validation loss: 0.8585
2024-05-25 01:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch141_loss0.858493834733963.pypots
2024-05-25 01:58:24 [INFO]: Epoch 142 - training loss: 0.7222, validation loss: 0.8600
2024-05-25 01:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch142_loss0.8599564731121063.pypots
2024-05-25 01:58:24 [INFO]: Epoch 143 - training loss: 0.6987, validation loss: 0.8592
2024-05-25 01:58:24 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch143_loss0.8591906279325485.pypots
2024-05-25 01:58:25 [INFO]: Epoch 144 - training loss: 0.7111, validation loss: 0.8629
2024-05-25 01:58:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch144_loss0.8629194647073746.pypots
2024-05-25 01:58:25 [INFO]: Epoch 145 - training loss: 0.7060, validation loss: 0.8576
2024-05-25 01:58:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch145_loss0.857550635933876.pypots
2024-05-25 01:58:25 [INFO]: Epoch 146 - training loss: 0.7388, validation loss: 0.8569
2024-05-25 01:58:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch146_loss0.856875404715538.pypots
2024-05-25 01:58:25 [INFO]: Epoch 147 - training loss: 0.7274, validation loss: 0.8559
2024-05-25 01:58:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch147_loss0.855862557888031.pypots
2024-05-25 01:58:25 [INFO]: Epoch 148 - training loss: 0.7008, validation loss: 0.8561
2024-05-25 01:58:25 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch148_loss0.8561451137065887.pypots
2024-05-25 01:58:26 [INFO]: Epoch 149 - training loss: 0.7192, validation loss: 0.8580
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch149_loss0.8579948395490646.pypots
2024-05-25 01:58:26 [INFO]: Epoch 150 - training loss: 0.7378, validation loss: 0.8523
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch150_loss0.852291464805603.pypots
2024-05-25 01:58:26 [INFO]: Epoch 151 - training loss: 0.7335, validation loss: 0.8565
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch151_loss0.8565416783094406.pypots
2024-05-25 01:58:26 [INFO]: Epoch 152 - training loss: 0.7126, validation loss: 0.8529
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch152_loss0.8528864532709122.pypots
2024-05-25 01:58:26 [INFO]: Epoch 153 - training loss: 0.7180, validation loss: 0.8519
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch153_loss0.8519206494092941.pypots
2024-05-25 01:58:26 [INFO]: Epoch 154 - training loss: 0.7248, validation loss: 0.8536
2024-05-25 01:58:26 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch154_loss0.8536304831504822.pypots
2024-05-25 01:58:27 [INFO]: Epoch 155 - training loss: 0.7309, validation loss: 0.8489
2024-05-25 01:58:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch155_loss0.8488617092370987.pypots
2024-05-25 01:58:27 [INFO]: Epoch 156 - training loss: 0.7466, validation loss: 0.8566
2024-05-25 01:58:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch156_loss0.856587752699852.pypots
2024-05-25 01:58:27 [INFO]: Epoch 157 - training loss: 0.7167, validation loss: 0.8502
2024-05-25 01:58:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch157_loss0.8502084761857986.pypots
2024-05-25 01:58:27 [INFO]: Epoch 158 - training loss: 0.7041, validation loss: 0.8495
2024-05-25 01:58:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch158_loss0.8494982868432999.pypots
2024-05-25 01:58:27 [INFO]: Epoch 159 - training loss: 0.7232, validation loss: 0.8509
2024-05-25 01:58:27 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch159_loss0.8508855849504471.pypots
2024-05-25 01:58:28 [INFO]: Epoch 160 - training loss: 0.7375, validation loss: 0.8448
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch160_loss0.8448463827371597.pypots
2024-05-25 01:58:28 [INFO]: Epoch 161 - training loss: 0.7316, validation loss: 0.8473
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch161_loss0.8472966998815536.pypots
2024-05-25 01:58:28 [INFO]: Epoch 162 - training loss: 0.7218, validation loss: 0.8491
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch162_loss0.8490591496229172.pypots
2024-05-25 01:58:28 [INFO]: Epoch 163 - training loss: 0.7075, validation loss: 0.8466
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch163_loss0.8466411232948303.pypots
2024-05-25 01:58:28 [INFO]: Epoch 164 - training loss: 0.7517, validation loss: 0.8468
2024-05-25 01:58:28 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch164_loss0.8468095362186432.pypots
2024-05-25 01:58:29 [INFO]: Epoch 165 - training loss: 0.7152, validation loss: 0.8452
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch165_loss0.8451546430587769.pypots
2024-05-25 01:58:29 [INFO]: Epoch 166 - training loss: 0.7318, validation loss: 0.8518
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch166_loss0.8518018126487732.pypots
2024-05-25 01:58:29 [INFO]: Epoch 167 - training loss: 0.7057, validation loss: 0.8430
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch167_loss0.8429503440856934.pypots
2024-05-25 01:58:29 [INFO]: Epoch 168 - training loss: 0.7249, validation loss: 0.8435
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch168_loss0.8434841930866241.pypots
2024-05-25 01:58:29 [INFO]: Epoch 169 - training loss: 0.7352, validation loss: 0.8432
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch169_loss0.8432207256555557.pypots
2024-05-25 01:58:29 [INFO]: Epoch 170 - training loss: 0.7286, validation loss: 0.8412
2024-05-25 01:58:29 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch170_loss0.841178223490715.pypots
2024-05-25 01:58:30 [INFO]: Epoch 171 - training loss: 0.7657, validation loss: 0.8436
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch171_loss0.8436477035284042.pypots
2024-05-25 01:58:30 [INFO]: Epoch 172 - training loss: 0.7133, validation loss: 0.8385
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch172_loss0.8384933620691299.pypots
2024-05-25 01:58:30 [INFO]: Epoch 173 - training loss: 0.7112, validation loss: 0.8398
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch173_loss0.8398220837116241.pypots
2024-05-25 01:58:30 [INFO]: Epoch 174 - training loss: 0.7518, validation loss: 0.8416
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch174_loss0.8416052460670471.pypots
2024-05-25 01:58:30 [INFO]: Epoch 175 - training loss: 0.7092, validation loss: 0.8410
2024-05-25 01:58:30 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch175_loss0.8409579545259476.pypots
2024-05-25 01:58:31 [INFO]: Epoch 176 - training loss: 0.7119, validation loss: 0.8389
2024-05-25 01:58:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch176_loss0.8389189094305038.pypots
2024-05-25 01:58:31 [INFO]: Epoch 177 - training loss: 0.7083, validation loss: 0.8397
2024-05-25 01:58:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch177_loss0.8396618366241455.pypots
2024-05-25 01:58:31 [INFO]: Epoch 178 - training loss: 0.7230, validation loss: 0.8401
2024-05-25 01:58:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch178_loss0.8401303291320801.pypots
2024-05-25 01:58:31 [INFO]: Epoch 179 - training loss: 0.7200, validation loss: 0.8368
2024-05-25 01:58:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch179_loss0.8368013948202133.pypots
2024-05-25 01:58:31 [INFO]: Epoch 180 - training loss: 0.7139, validation loss: 0.8398
2024-05-25 01:58:31 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch180_loss0.8398169130086899.pypots
2024-05-25 01:58:32 [INFO]: Epoch 181 - training loss: 0.7174, validation loss: 0.8356
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch181_loss0.8356471657752991.pypots
2024-05-25 01:58:32 [INFO]: Epoch 182 - training loss: 0.7052, validation loss: 0.8372
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch182_loss0.8372025936841965.pypots
2024-05-25 01:58:32 [INFO]: Epoch 183 - training loss: 0.7278, validation loss: 0.8404
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch183_loss0.8404428958892822.pypots
2024-05-25 01:58:32 [INFO]: Epoch 184 - training loss: 0.7160, validation loss: 0.8359
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch184_loss0.8359239548444748.pypots
2024-05-25 01:58:32 [INFO]: Epoch 185 - training loss: 0.7087, validation loss: 0.8375
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch185_loss0.8374620079994202.pypots
2024-05-25 01:58:32 [INFO]: Epoch 186 - training loss: 0.6956, validation loss: 0.8380
2024-05-25 01:58:32 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch186_loss0.8380136489868164.pypots
2024-05-25 01:58:33 [INFO]: Epoch 187 - training loss: 0.7203, validation loss: 0.8361
2024-05-25 01:58:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch187_loss0.836136519908905.pypots
2024-05-25 01:58:33 [INFO]: Epoch 188 - training loss: 0.7258, validation loss: 0.8344
2024-05-25 01:58:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch188_loss0.8344229310750961.pypots
2024-05-25 01:58:33 [INFO]: Epoch 189 - training loss: 0.7042, validation loss: 0.8375
2024-05-25 01:58:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch189_loss0.837536484003067.pypots
2024-05-25 01:58:33 [INFO]: Epoch 190 - training loss: 0.7259, validation loss: 0.8317
2024-05-25 01:58:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch190_loss0.8316531032323837.pypots
2024-05-25 01:58:33 [INFO]: Epoch 191 - training loss: 0.7305, validation loss: 0.8326
2024-05-25 01:58:33 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch191_loss0.8325616419315338.pypots
2024-05-25 01:58:34 [INFO]: Epoch 192 - training loss: 0.7419, validation loss: 0.8344
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch192_loss0.8344211429357529.pypots
2024-05-25 01:58:34 [INFO]: Epoch 193 - training loss: 0.7009, validation loss: 0.8376
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch193_loss0.8375772833824158.pypots
2024-05-25 01:58:34 [INFO]: Epoch 194 - training loss: 0.7556, validation loss: 0.8329
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch194_loss0.8329253494739532.pypots
2024-05-25 01:58:34 [INFO]: Epoch 195 - training loss: 0.7111, validation loss: 0.8284
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch195_loss0.8284315019845963.pypots
2024-05-25 01:58:34 [INFO]: Epoch 196 - training loss: 0.7134, validation loss: 0.8299
2024-05-25 01:58:34 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch196_loss0.8298869580030441.pypots
2024-05-25 01:58:35 [INFO]: Epoch 197 - training loss: 0.7320, validation loss: 0.8325
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch197_loss0.8325264751911163.pypots
2024-05-25 01:58:35 [INFO]: Epoch 198 - training loss: 0.7057, validation loss: 0.8314
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch198_loss0.8313612192869186.pypots
2024-05-25 01:58:35 [INFO]: Epoch 199 - training loss: 0.7144, validation loss: 0.8305
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch199_loss0.830456405878067.pypots
2024-05-25 01:58:35 [INFO]: Epoch 200 - training loss: 0.7264, validation loss: 0.8290
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch200_loss0.82904452085495.pypots
2024-05-25 01:58:35 [INFO]: Epoch 201 - training loss: 0.7362, validation loss: 0.8309
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch201_loss0.8308933973312378.pypots
2024-05-25 01:58:35 [INFO]: Epoch 202 - training loss: 0.7154, validation loss: 0.8319
2024-05-25 01:58:35 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch202_loss0.8318541198968887.pypots
2024-05-25 01:58:36 [INFO]: Epoch 203 - training loss: 0.7308, validation loss: 0.8313
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch203_loss0.8313359320163727.pypots
2024-05-25 01:58:36 [INFO]: Epoch 204 - training loss: 0.7016, validation loss: 0.8298
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch204_loss0.8298415690660477.pypots
2024-05-25 01:58:36 [INFO]: Epoch 205 - training loss: 0.7090, validation loss: 0.8288
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN_epoch205_loss0.8287968188524246.pypots
2024-05-25 01:58:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:58:36 [INFO]: Finished training. The best model is from epoch#195.
2024-05-25 01:58:36 [INFO]: Saved the model to augmentation_saved_results/round_1/MRNN_ettm1/20240525_T015756/MRNN.pypots
2024-05-25 01:58:36 [INFO]: MRNN on ETTm1: MAE=0.6096, MSE=0.9911
2024-05-25 01:58:36 [INFO]: Successfully saved to augmentation_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-25 01:58:36 [INFO]: Using the given device: cpu
2024-05-25 01:58:36 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-25 01:58:36 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-25 01:58:36 [INFO]: Successfully saved to augmentation_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-25 01:58:36 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-25 01:58:36 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-25 01:58:36 [INFO]: Successfully saved to augmentation_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-25 01:58:36 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-25 01:58:36 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-25 01:58:36 [INFO]: Successfully saved to augmentation_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-25 01:58:36 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 01:58:36 [INFO]: Using the given device: cuda:0
2024-05-25 01:58:36 [INFO]: Model files will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015836
2024-05-25 01:58:36 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015836/tensorboard
2024-05-25 01:58:37 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 01:58:37 [INFO]: Epoch 001 - training loss: 1.2010, validation loss: 0.3267
2024-05-25 01:58:38 [INFO]: Epoch 002 - training loss: 0.8609, validation loss: 0.1727
2024-05-25 01:58:38 [INFO]: Epoch 003 - training loss: 0.7505, validation loss: 0.1574
2024-05-25 01:58:39 [INFO]: Epoch 004 - training loss: 0.6861, validation loss: 0.1085
2024-05-25 01:58:39 [INFO]: Epoch 005 - training loss: 0.6621, validation loss: 0.0959
2024-05-25 01:58:40 [INFO]: Epoch 006 - training loss: 0.6029, validation loss: 0.0864
2024-05-25 01:58:40 [INFO]: Epoch 007 - training loss: 0.5881, validation loss: 0.1153
2024-05-25 01:58:41 [INFO]: Epoch 008 - training loss: 0.5729, validation loss: 0.0691
2024-05-25 01:58:41 [INFO]: Epoch 009 - training loss: 0.5757, validation loss: 0.0896
2024-05-25 01:58:42 [INFO]: Epoch 010 - training loss: 0.5678, validation loss: 0.0766
2024-05-25 01:58:42 [INFO]: Epoch 011 - training loss: 0.5399, validation loss: 0.0830
2024-05-25 01:58:43 [INFO]: Epoch 012 - training loss: 0.5247, validation loss: 0.0917
2024-05-25 01:58:43 [INFO]: Epoch 013 - training loss: 0.5196, validation loss: 0.0825
2024-05-25 01:58:44 [INFO]: Epoch 014 - training loss: 0.5016, validation loss: 0.0810
2024-05-25 01:58:44 [INFO]: Epoch 015 - training loss: 0.5027, validation loss: 0.0694
2024-05-25 01:58:45 [INFO]: Epoch 016 - training loss: 0.4959, validation loss: 0.0656
2024-05-25 01:58:45 [INFO]: Epoch 017 - training loss: 0.5057, validation loss: 0.0686
2024-05-25 01:58:46 [INFO]: Epoch 018 - training loss: 0.4841, validation loss: 0.0629
2024-05-25 01:58:46 [INFO]: Epoch 019 - training loss: 0.4590, validation loss: 0.0570
2024-05-25 01:58:47 [INFO]: Epoch 020 - training loss: 0.4519, validation loss: 0.0606
2024-05-25 01:58:47 [INFO]: Epoch 021 - training loss: 0.4645, validation loss: 0.0547
2024-05-25 01:58:48 [INFO]: Epoch 022 - training loss: 0.4580, validation loss: 0.0517
2024-05-25 01:58:48 [INFO]: Epoch 023 - training loss: 0.4520, validation loss: 0.0661
2024-05-25 01:58:49 [INFO]: Epoch 024 - training loss: 0.4363, validation loss: 0.0667
2024-05-25 01:58:49 [INFO]: Epoch 025 - training loss: 0.4285, validation loss: 0.0520
2024-05-25 01:58:50 [INFO]: Epoch 026 - training loss: 0.4439, validation loss: 0.0521
2024-05-25 01:58:50 [INFO]: Epoch 027 - training loss: 0.4332, validation loss: 0.0565
2024-05-25 01:58:51 [INFO]: Epoch 028 - training loss: 0.4317, validation loss: 0.0556
2024-05-25 01:58:51 [INFO]: Epoch 029 - training loss: 0.4197, validation loss: 0.0546
2024-05-25 01:58:52 [INFO]: Epoch 030 - training loss: 0.4257, validation loss: 0.0494
2024-05-25 01:58:52 [INFO]: Epoch 031 - training loss: 0.4019, validation loss: 0.0422
2024-05-25 01:58:53 [INFO]: Epoch 032 - training loss: 0.4100, validation loss: 0.0445
2024-05-25 01:58:53 [INFO]: Epoch 033 - training loss: 0.4002, validation loss: 0.0445
2024-05-25 01:58:54 [INFO]: Epoch 034 - training loss: 0.3864, validation loss: 0.0417
2024-05-25 01:58:54 [INFO]: Epoch 035 - training loss: 0.3884, validation loss: 0.0509
2024-05-25 01:58:55 [INFO]: Epoch 036 - training loss: 0.3816, validation loss: 0.0383
2024-05-25 01:58:55 [INFO]: Epoch 037 - training loss: 0.3905, validation loss: 0.0385
2024-05-25 01:58:56 [INFO]: Epoch 038 - training loss: 0.4100, validation loss: 0.0526
2024-05-25 01:58:56 [INFO]: Epoch 039 - training loss: 0.4127, validation loss: 0.0603
2024-05-25 01:58:57 [INFO]: Epoch 040 - training loss: 0.3871, validation loss: 0.0501
2024-05-25 01:58:57 [INFO]: Epoch 041 - training loss: 0.3860, validation loss: 0.0492
2024-05-25 01:58:58 [INFO]: Epoch 042 - training loss: 0.3774, validation loss: 0.0377
2024-05-25 01:58:58 [INFO]: Epoch 043 - training loss: 0.3624, validation loss: 0.0457
2024-05-25 01:58:59 [INFO]: Epoch 044 - training loss: 0.3578, validation loss: 0.0518
2024-05-25 01:58:59 [INFO]: Epoch 045 - training loss: 0.3627, validation loss: 0.0493
2024-05-25 01:59:00 [INFO]: Epoch 046 - training loss: 0.3509, validation loss: 0.0448
2024-05-25 01:59:00 [INFO]: Epoch 047 - training loss: 0.3595, validation loss: 0.0441
2024-05-25 01:59:01 [INFO]: Epoch 048 - training loss: 0.3487, validation loss: 0.0403
2024-05-25 01:59:02 [INFO]: Epoch 049 - training loss: 0.3452, validation loss: 0.0389
2024-05-25 01:59:02 [INFO]: Epoch 050 - training loss: 0.3368, validation loss: 0.0461
2024-05-25 01:59:03 [INFO]: Epoch 051 - training loss: 0.3386, validation loss: 0.0428
2024-05-25 01:59:03 [INFO]: Epoch 052 - training loss: 0.3412, validation loss: 0.0382
2024-05-25 01:59:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:59:03 [INFO]: Finished training. The best model is from epoch#42.
2024-05-25 01:59:03 [INFO]: Saved the model to augmentation_saved_results/round_2/SAITS_ettm1/20240525_T015836/SAITS.pypots
2024-05-25 01:59:03 [INFO]: SAITS on ETTm1: MAE=0.1628, MSE=0.0555
2024-05-25 01:59:03 [INFO]: Successfully saved to augmentation_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-25 01:59:03 [INFO]: Using the given device: cuda:0
2024-05-25 01:59:03 [INFO]: Model files will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015903
2024-05-25 01:59:03 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015903/tensorboard
2024-05-25 01:59:03 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 01:59:03 [INFO]: Epoch 001 - training loss: 1.3559, validation loss: 0.4350
2024-05-25 01:59:04 [INFO]: Epoch 002 - training loss: 0.8436, validation loss: 0.2249
2024-05-25 01:59:04 [INFO]: Epoch 003 - training loss: 0.6673, validation loss: 0.1516
2024-05-25 01:59:04 [INFO]: Epoch 004 - training loss: 0.5898, validation loss: 0.1112
2024-05-25 01:59:04 [INFO]: Epoch 005 - training loss: 0.5320, validation loss: 0.0899
2024-05-25 01:59:05 [INFO]: Epoch 006 - training loss: 0.4887, validation loss: 0.0758
2024-05-25 01:59:05 [INFO]: Epoch 007 - training loss: 0.4686, validation loss: 0.0708
2024-05-25 01:59:05 [INFO]: Epoch 008 - training loss: 0.4410, validation loss: 0.0675
2024-05-25 01:59:05 [INFO]: Epoch 009 - training loss: 0.4287, validation loss: 0.0694
2024-05-25 01:59:05 [INFO]: Epoch 010 - training loss: 0.4275, validation loss: 0.0693
2024-05-25 01:59:06 [INFO]: Epoch 011 - training loss: 0.4148, validation loss: 0.0597
2024-05-25 01:59:06 [INFO]: Epoch 012 - training loss: 0.4031, validation loss: 0.0694
2024-05-25 01:59:06 [INFO]: Epoch 013 - training loss: 0.3913, validation loss: 0.0628
2024-05-25 01:59:06 [INFO]: Epoch 014 - training loss: 0.3913, validation loss: 0.0684
2024-05-25 01:59:06 [INFO]: Epoch 015 - training loss: 0.3915, validation loss: 0.0578
2024-05-25 01:59:07 [INFO]: Epoch 016 - training loss: 0.3769, validation loss: 0.0530
2024-05-25 01:59:07 [INFO]: Epoch 017 - training loss: 0.3655, validation loss: 0.0489
2024-05-25 01:59:07 [INFO]: Epoch 018 - training loss: 0.3665, validation loss: 0.0489
2024-05-25 01:59:07 [INFO]: Epoch 019 - training loss: 0.3557, validation loss: 0.0558
2024-05-25 01:59:08 [INFO]: Epoch 020 - training loss: 0.3521, validation loss: 0.0449
2024-05-25 01:59:08 [INFO]: Epoch 021 - training loss: 0.3458, validation loss: 0.0476
2024-05-25 01:59:08 [INFO]: Epoch 022 - training loss: 0.3368, validation loss: 0.0493
2024-05-25 01:59:08 [INFO]: Epoch 023 - training loss: 0.3297, validation loss: 0.0475
2024-05-25 01:59:08 [INFO]: Epoch 024 - training loss: 0.3301, validation loss: 0.0422
2024-05-25 01:59:09 [INFO]: Epoch 025 - training loss: 0.3273, validation loss: 0.0544
2024-05-25 01:59:09 [INFO]: Epoch 026 - training loss: 0.3234, validation loss: 0.0458
2024-05-25 01:59:09 [INFO]: Epoch 027 - training loss: 0.3212, validation loss: 0.0487
2024-05-25 01:59:09 [INFO]: Epoch 028 - training loss: 0.3155, validation loss: 0.0397
2024-05-25 01:59:10 [INFO]: Epoch 029 - training loss: 0.3142, validation loss: 0.0447
2024-05-25 01:59:10 [INFO]: Epoch 030 - training loss: 0.3068, validation loss: 0.0366
2024-05-25 01:59:10 [INFO]: Epoch 031 - training loss: 0.3090, validation loss: 0.0477
2024-05-25 01:59:10 [INFO]: Epoch 032 - training loss: 0.3083, validation loss: 0.0354
2024-05-25 01:59:10 [INFO]: Epoch 033 - training loss: 0.2978, validation loss: 0.0404
2024-05-25 01:59:11 [INFO]: Epoch 034 - training loss: 0.2991, validation loss: 0.0353
2024-05-25 01:59:11 [INFO]: Epoch 035 - training loss: 0.2998, validation loss: 0.0466
2024-05-25 01:59:11 [INFO]: Epoch 036 - training loss: 0.2906, validation loss: 0.0345
2024-05-25 01:59:11 [INFO]: Epoch 037 - training loss: 0.2936, validation loss: 0.0420
2024-05-25 01:59:11 [INFO]: Epoch 038 - training loss: 0.2898, validation loss: 0.0384
2024-05-25 01:59:12 [INFO]: Epoch 039 - training loss: 0.2845, validation loss: 0.0343
2024-05-25 01:59:12 [INFO]: Epoch 040 - training loss: 0.2754, validation loss: 0.0373
2024-05-25 01:59:12 [INFO]: Epoch 041 - training loss: 0.2756, validation loss: 0.0342
2024-05-25 01:59:12 [INFO]: Epoch 042 - training loss: 0.2801, validation loss: 0.0319
2024-05-25 01:59:13 [INFO]: Epoch 043 - training loss: 0.2771, validation loss: 0.0329
2024-05-25 01:59:13 [INFO]: Epoch 044 - training loss: 0.2701, validation loss: 0.0318
2024-05-25 01:59:13 [INFO]: Epoch 045 - training loss: 0.2615, validation loss: 0.0334
2024-05-25 01:59:13 [INFO]: Epoch 046 - training loss: 0.2633, validation loss: 0.0369
2024-05-25 01:59:13 [INFO]: Epoch 047 - training loss: 0.2653, validation loss: 0.0337
2024-05-25 01:59:14 [INFO]: Epoch 048 - training loss: 0.2710, validation loss: 0.0330
2024-05-25 01:59:14 [INFO]: Epoch 049 - training loss: 0.2675, validation loss: 0.0345
2024-05-25 01:59:14 [INFO]: Epoch 050 - training loss: 0.2606, validation loss: 0.0380
2024-05-25 01:59:14 [INFO]: Epoch 051 - training loss: 0.2595, validation loss: 0.0320
2024-05-25 01:59:14 [INFO]: Epoch 052 - training loss: 0.2556, validation loss: 0.0300
2024-05-25 01:59:15 [INFO]: Epoch 053 - training loss: 0.2543, validation loss: 0.0303
2024-05-25 01:59:15 [INFO]: Epoch 054 - training loss: 0.2458, validation loss: 0.0291
2024-05-25 01:59:15 [INFO]: Epoch 055 - training loss: 0.2453, validation loss: 0.0314
2024-05-25 01:59:15 [INFO]: Epoch 056 - training loss: 0.2510, validation loss: 0.0385
2024-05-25 01:59:16 [INFO]: Epoch 057 - training loss: 0.2450, validation loss: 0.0284
2024-05-25 01:59:16 [INFO]: Epoch 058 - training loss: 0.2433, validation loss: 0.0278
2024-05-25 01:59:16 [INFO]: Epoch 059 - training loss: 0.2389, validation loss: 0.0286
2024-05-25 01:59:16 [INFO]: Epoch 060 - training loss: 0.2359, validation loss: 0.0288
2024-05-25 01:59:16 [INFO]: Epoch 061 - training loss: 0.2350, validation loss: 0.0276
2024-05-25 01:59:17 [INFO]: Epoch 062 - training loss: 0.2333, validation loss: 0.0265
2024-05-25 01:59:17 [INFO]: Epoch 063 - training loss: 0.2358, validation loss: 0.0321
2024-05-25 01:59:17 [INFO]: Epoch 064 - training loss: 0.2369, validation loss: 0.0309
2024-05-25 01:59:17 [INFO]: Epoch 065 - training loss: 0.2383, validation loss: 0.0289
2024-05-25 01:59:18 [INFO]: Epoch 066 - training loss: 0.2304, validation loss: 0.0297
2024-05-25 01:59:18 [INFO]: Epoch 067 - training loss: 0.2383, validation loss: 0.0275
2024-05-25 01:59:18 [INFO]: Epoch 068 - training loss: 0.2334, validation loss: 0.0301
2024-05-25 01:59:18 [INFO]: Epoch 069 - training loss: 0.2335, validation loss: 0.0251
2024-05-25 01:59:18 [INFO]: Epoch 070 - training loss: 0.2281, validation loss: 0.0277
2024-05-25 01:59:19 [INFO]: Epoch 071 - training loss: 0.2261, validation loss: 0.0290
2024-05-25 01:59:19 [INFO]: Epoch 072 - training loss: 0.2268, validation loss: 0.0270
2024-05-25 01:59:19 [INFO]: Epoch 073 - training loss: 0.2183, validation loss: 0.0246
2024-05-25 01:59:19 [INFO]: Epoch 074 - training loss: 0.2291, validation loss: 0.0281
2024-05-25 01:59:19 [INFO]: Epoch 075 - training loss: 0.2456, validation loss: 0.0332
2024-05-25 01:59:20 [INFO]: Epoch 076 - training loss: 0.2331, validation loss: 0.0275
2024-05-25 01:59:20 [INFO]: Epoch 077 - training loss: 0.2254, validation loss: 0.0254
2024-05-25 01:59:20 [INFO]: Epoch 078 - training loss: 0.2203, validation loss: 0.0251
2024-05-25 01:59:20 [INFO]: Epoch 079 - training loss: 0.2187, validation loss: 0.0269
2024-05-25 01:59:21 [INFO]: Epoch 080 - training loss: 0.2204, validation loss: 0.0257
2024-05-25 01:59:21 [INFO]: Epoch 081 - training loss: 0.2200, validation loss: 0.0244
2024-05-25 01:59:21 [INFO]: Epoch 082 - training loss: 0.2193, validation loss: 0.0263
2024-05-25 01:59:21 [INFO]: Epoch 083 - training loss: 0.2160, validation loss: 0.0307
2024-05-25 01:59:21 [INFO]: Epoch 084 - training loss: 0.2226, validation loss: 0.0262
2024-05-25 01:59:22 [INFO]: Epoch 085 - training loss: 0.2175, validation loss: 0.0279
2024-05-25 01:59:22 [INFO]: Epoch 086 - training loss: 0.2125, validation loss: 0.0297
2024-05-25 01:59:22 [INFO]: Epoch 087 - training loss: 0.2184, validation loss: 0.0275
2024-05-25 01:59:22 [INFO]: Epoch 088 - training loss: 0.2133, validation loss: 0.0282
2024-05-25 01:59:23 [INFO]: Epoch 089 - training loss: 0.2144, validation loss: 0.0245
2024-05-25 01:59:23 [INFO]: Epoch 090 - training loss: 0.2179, validation loss: 0.0236
2024-05-25 01:59:23 [INFO]: Epoch 091 - training loss: 0.2098, validation loss: 0.0240
2024-05-25 01:59:23 [INFO]: Epoch 092 - training loss: 0.2092, validation loss: 0.0245
2024-05-25 01:59:23 [INFO]: Epoch 093 - training loss: 0.2165, validation loss: 0.0259
2024-05-25 01:59:24 [INFO]: Epoch 094 - training loss: 0.2194, validation loss: 0.0287
2024-05-25 01:59:24 [INFO]: Epoch 095 - training loss: 0.2211, validation loss: 0.0264
2024-05-25 01:59:24 [INFO]: Epoch 096 - training loss: 0.2141, validation loss: 0.0258
2024-05-25 01:59:24 [INFO]: Epoch 097 - training loss: 0.2058, validation loss: 0.0267
2024-05-25 01:59:24 [INFO]: Epoch 098 - training loss: 0.2109, validation loss: 0.0238
2024-05-25 01:59:25 [INFO]: Epoch 099 - training loss: 0.2239, validation loss: 0.0276
2024-05-25 01:59:25 [INFO]: Epoch 100 - training loss: 0.2295, validation loss: 0.0281
2024-05-25 01:59:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:59:25 [INFO]: Finished training. The best model is from epoch#90.
2024-05-25 01:59:25 [INFO]: Saved the model to augmentation_saved_results/round_2/Transformer_ettm1/20240525_T015903/Transformer.pypots
2024-05-25 01:59:25 [INFO]: Transformer on ETTm1: MAE=0.1390, MSE=0.0382
2024-05-25 01:59:25 [INFO]: Successfully saved to augmentation_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-25 01:59:25 [INFO]: Using the given device: cuda:0
2024-05-25 01:59:25 [INFO]: Model files will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015925
2024-05-25 01:59:25 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015925/tensorboard
2024-05-25 01:59:25 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 01:59:25 [INFO]: Epoch 001 - training loss: 0.1386, validation loss: 0.0512
2024-05-25 01:59:26 [INFO]: Epoch 002 - training loss: 0.0688, validation loss: 0.0407
2024-05-25 01:59:26 [INFO]: Epoch 003 - training loss: 0.0603, validation loss: 0.0384
2024-05-25 01:59:26 [INFO]: Epoch 004 - training loss: 0.0618, validation loss: 0.0398
2024-05-25 01:59:26 [INFO]: Epoch 005 - training loss: 0.0631, validation loss: 0.0380
2024-05-25 01:59:26 [INFO]: Epoch 006 - training loss: 0.0556, validation loss: 0.0351
2024-05-25 01:59:27 [INFO]: Epoch 007 - training loss: 0.0546, validation loss: 0.0372
2024-05-25 01:59:27 [INFO]: Epoch 008 - training loss: 0.0615, validation loss: 0.0374
2024-05-25 01:59:27 [INFO]: Epoch 009 - training loss: 0.0574, validation loss: 0.0351
2024-05-25 01:59:27 [INFO]: Epoch 010 - training loss: 0.0521, validation loss: 0.0328
2024-05-25 01:59:27 [INFO]: Epoch 011 - training loss: 0.0501, validation loss: 0.0347
2024-05-25 01:59:28 [INFO]: Epoch 012 - training loss: 0.0534, validation loss: 0.0333
2024-05-25 01:59:28 [INFO]: Epoch 013 - training loss: 0.0526, validation loss: 0.0376
2024-05-25 01:59:28 [INFO]: Epoch 014 - training loss: 0.0530, validation loss: 0.0340
2024-05-25 01:59:28 [INFO]: Epoch 015 - training loss: 0.0475, validation loss: 0.0333
2024-05-25 01:59:29 [INFO]: Epoch 016 - training loss: 0.0483, validation loss: 0.0318
2024-05-25 01:59:29 [INFO]: Epoch 017 - training loss: 0.0482, validation loss: 0.0335
2024-05-25 01:59:29 [INFO]: Epoch 018 - training loss: 0.0515, validation loss: 0.0347
2024-05-25 01:59:29 [INFO]: Epoch 019 - training loss: 0.0571, validation loss: 0.0331
2024-05-25 01:59:29 [INFO]: Epoch 020 - training loss: 0.0545, validation loss: 0.0314
2024-05-25 01:59:30 [INFO]: Epoch 021 - training loss: 0.0528, validation loss: 0.0329
2024-05-25 01:59:30 [INFO]: Epoch 022 - training loss: 0.0554, validation loss: 0.0353
2024-05-25 01:59:30 [INFO]: Epoch 023 - training loss: 0.0479, validation loss: 0.0331
2024-05-25 01:59:30 [INFO]: Epoch 024 - training loss: 0.0494, validation loss: 0.0315
2024-05-25 01:59:30 [INFO]: Epoch 025 - training loss: 0.0475, validation loss: 0.0311
2024-05-25 01:59:31 [INFO]: Epoch 026 - training loss: 0.0447, validation loss: 0.0312
2024-05-25 01:59:31 [INFO]: Epoch 027 - training loss: 0.0454, validation loss: 0.0296
2024-05-25 01:59:31 [INFO]: Epoch 028 - training loss: 0.0437, validation loss: 0.0289
2024-05-25 01:59:31 [INFO]: Epoch 029 - training loss: 0.0467, validation loss: 0.0291
2024-05-25 01:59:31 [INFO]: Epoch 030 - training loss: 0.0462, validation loss: 0.0312
2024-05-25 01:59:32 [INFO]: Epoch 031 - training loss: 0.0451, validation loss: 0.0326
2024-05-25 01:59:32 [INFO]: Epoch 032 - training loss: 0.2717, validation loss: 0.0322
2024-05-25 01:59:32 [INFO]: Epoch 033 - training loss: 0.0600, validation loss: 0.0398
2024-05-25 01:59:32 [INFO]: Epoch 034 - training loss: 0.0536, validation loss: 0.0344
2024-05-25 01:59:33 [INFO]: Epoch 035 - training loss: 0.0499, validation loss: 0.0321
2024-05-25 01:59:33 [INFO]: Epoch 036 - training loss: 0.0488, validation loss: 0.0310
2024-05-25 01:59:33 [INFO]: Epoch 037 - training loss: 0.0462, validation loss: 0.0311
2024-05-25 01:59:33 [INFO]: Epoch 038 - training loss: 0.0467, validation loss: 0.0315
2024-05-25 01:59:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 01:59:33 [INFO]: Finished training. The best model is from epoch#28.
2024-05-25 01:59:33 [INFO]: Saved the model to augmentation_saved_results/round_2/TimesNet_ettm1/20240525_T015925/TimesNet.pypots
2024-05-25 01:59:33 [INFO]: TimesNet on ETTm1: MAE=0.1285, MSE=0.0340
2024-05-25 01:59:33 [INFO]: Successfully saved to augmentation_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-25 01:59:33 [INFO]: Using the given device: cuda:0
2024-05-25 01:59:33 [INFO]: Model files will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933
2024-05-25 01:59:33 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/tensorboard
2024-05-25 01:59:33 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 01:59:35 [INFO]: Epoch 001 - training loss: 0.6739, validation loss: 0.4135
2024-05-25 01:59:35 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch1_loss0.4135344922542572.pypots
2024-05-25 01:59:37 [INFO]: Epoch 002 - training loss: 0.3894, validation loss: 0.3658
2024-05-25 01:59:37 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch2_loss0.3657521530985832.pypots
2024-05-25 01:59:39 [INFO]: Epoch 003 - training loss: 0.3432, validation loss: 0.3410
2024-05-25 01:59:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch3_loss0.340977743268013.pypots
2024-05-25 01:59:42 [INFO]: Epoch 004 - training loss: 0.3181, validation loss: 0.3247
2024-05-25 01:59:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch4_loss0.3246648535132408.pypots
2024-05-25 01:59:44 [INFO]: Epoch 005 - training loss: 0.2722, validation loss: 0.3030
2024-05-25 01:59:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch5_loss0.3030443415045738.pypots
2024-05-25 01:59:46 [INFO]: Epoch 006 - training loss: 0.3432, validation loss: 0.3142
2024-05-25 01:59:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch6_loss0.31422267109155655.pypots
2024-05-25 01:59:48 [INFO]: Epoch 007 - training loss: 0.3780, validation loss: 0.3223
2024-05-25 01:59:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch7_loss0.3223339915275574.pypots
2024-05-25 01:59:50 [INFO]: Epoch 008 - training loss: 0.3077, validation loss: 0.2876
2024-05-25 01:59:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch8_loss0.28762633353471756.pypots
2024-05-25 01:59:52 [INFO]: Epoch 009 - training loss: 0.3198, validation loss: 0.2776
2024-05-25 01:59:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch9_loss0.2776348888874054.pypots
2024-05-25 01:59:54 [INFO]: Epoch 010 - training loss: 0.2627, validation loss: 0.2651
2024-05-25 01:59:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch10_loss0.2651272341609001.pypots
2024-05-25 01:59:56 [INFO]: Epoch 011 - training loss: 0.2341, validation loss: 0.2700
2024-05-25 01:59:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch11_loss0.26999831199645996.pypots
2024-05-25 01:59:58 [INFO]: Epoch 012 - training loss: 0.2903, validation loss: 0.2589
2024-05-25 01:59:58 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch12_loss0.2588893622159958.pypots
2024-05-25 02:00:00 [INFO]: Epoch 013 - training loss: 0.2308, validation loss: 0.2646
2024-05-25 02:00:00 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch13_loss0.2646080255508423.pypots
2024-05-25 02:00:02 [INFO]: Epoch 014 - training loss: 0.2453, validation loss: 0.2438
2024-05-25 02:00:02 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch14_loss0.24377797171473503.pypots
2024-05-25 02:00:05 [INFO]: Epoch 015 - training loss: 0.2377, validation loss: 0.2361
2024-05-25 02:00:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch15_loss0.2361139841377735.pypots
2024-05-25 02:00:07 [INFO]: Epoch 016 - training loss: 0.2860, validation loss: 0.2501
2024-05-25 02:00:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch16_loss0.25005584210157394.pypots
2024-05-25 02:00:09 [INFO]: Epoch 017 - training loss: 0.2503, validation loss: 0.2576
2024-05-25 02:00:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch17_loss0.2575642429292202.pypots
2024-05-25 02:00:11 [INFO]: Epoch 018 - training loss: 0.2332, validation loss: 0.2404
2024-05-25 02:00:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch18_loss0.24044407531619072.pypots
2024-05-25 02:00:13 [INFO]: Epoch 019 - training loss: 0.3414, validation loss: 0.2597
2024-05-25 02:00:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch19_loss0.25974462926387787.pypots
2024-05-25 02:00:15 [INFO]: Epoch 020 - training loss: 0.3196, validation loss: 0.2560
2024-05-25 02:00:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch20_loss0.2559742033481598.pypots
2024-05-25 02:00:17 [INFO]: Epoch 021 - training loss: 0.2298, validation loss: 0.2325
2024-05-25 02:00:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch21_loss0.23245668038725853.pypots
2024-05-25 02:00:19 [INFO]: Epoch 022 - training loss: 0.1886, validation loss: 0.2117
2024-05-25 02:00:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch22_loss0.21166396513581276.pypots
2024-05-25 02:00:21 [INFO]: Epoch 023 - training loss: 0.2813, validation loss: 0.1995
2024-05-25 02:00:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch23_loss0.19945374876260757.pypots
2024-05-25 02:00:23 [INFO]: Epoch 024 - training loss: 0.2355, validation loss: 0.2124
2024-05-25 02:00:23 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch24_loss0.21235758811235428.pypots
2024-05-25 02:00:25 [INFO]: Epoch 025 - training loss: 0.2073, validation loss: 0.2064
2024-05-25 02:00:25 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch25_loss0.2063804641366005.pypots
2024-05-25 02:00:27 [INFO]: Epoch 026 - training loss: 0.2299, validation loss: 0.2037
2024-05-25 02:00:27 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch26_loss0.2037132903933525.pypots
2024-05-25 02:00:29 [INFO]: Epoch 027 - training loss: 0.2400, validation loss: 0.1919
2024-05-25 02:00:29 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch27_loss0.1918674111366272.pypots
2024-05-25 02:00:32 [INFO]: Epoch 028 - training loss: 0.2490, validation loss: 0.1924
2024-05-25 02:00:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch28_loss0.19240370020270348.pypots
2024-05-25 02:00:34 [INFO]: Epoch 029 - training loss: 0.2101, validation loss: 0.1948
2024-05-25 02:00:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch29_loss0.19477275758981705.pypots
2024-05-25 02:00:36 [INFO]: Epoch 030 - training loss: 0.2063, validation loss: 0.2140
2024-05-25 02:00:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch30_loss0.21401379629969597.pypots
2024-05-25 02:00:38 [INFO]: Epoch 031 - training loss: 0.2065, validation loss: 0.2185
2024-05-25 02:00:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch31_loss0.21847254037857056.pypots
2024-05-25 02:00:40 [INFO]: Epoch 032 - training loss: 0.2048, validation loss: 0.2202
2024-05-25 02:00:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch32_loss0.22024023905396461.pypots
2024-05-25 02:00:42 [INFO]: Epoch 033 - training loss: 0.2248, validation loss: 0.2111
2024-05-25 02:00:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch33_loss0.21108369529247284.pypots
2024-05-25 02:00:44 [INFO]: Epoch 034 - training loss: 0.2127, validation loss: 0.1984
2024-05-25 02:00:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch34_loss0.1983744539320469.pypots
2024-05-25 02:00:46 [INFO]: Epoch 035 - training loss: 0.1943, validation loss: 0.1906
2024-05-25 02:00:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch35_loss0.19063524156808853.pypots
2024-05-25 02:00:48 [INFO]: Epoch 036 - training loss: 0.2184, validation loss: 0.1840
2024-05-25 02:00:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch36_loss0.18395216763019562.pypots
2024-05-25 02:00:50 [INFO]: Epoch 037 - training loss: 0.1640, validation loss: 0.1749
2024-05-25 02:00:50 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch37_loss0.17490233480930328.pypots
2024-05-25 02:00:52 [INFO]: Epoch 038 - training loss: 0.2129, validation loss: 0.1897
2024-05-25 02:00:52 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch38_loss0.18965759873390198.pypots
2024-05-25 02:00:54 [INFO]: Epoch 039 - training loss: 0.1899, validation loss: 0.1821
2024-05-25 02:00:54 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch39_loss0.1820887103676796.pypots
2024-05-25 02:00:56 [INFO]: Epoch 040 - training loss: 0.2005, validation loss: 0.1744
2024-05-25 02:00:56 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch40_loss0.17441731318831444.pypots
2024-05-25 02:00:59 [INFO]: Epoch 041 - training loss: 0.1822, validation loss: 0.1706
2024-05-25 02:00:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch41_loss0.17056270316243172.pypots
2024-05-25 02:01:01 [INFO]: Epoch 042 - training loss: 0.1670, validation loss: 0.1694
2024-05-25 02:01:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch42_loss0.1693955771625042.pypots
2024-05-25 02:01:03 [INFO]: Epoch 043 - training loss: 0.1928, validation loss: 0.1651
2024-05-25 02:01:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch43_loss0.16509965434670448.pypots
2024-05-25 02:01:05 [INFO]: Epoch 044 - training loss: 0.2324, validation loss: 0.1889
2024-05-25 02:01:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch44_loss0.18893776461482048.pypots
2024-05-25 02:01:07 [INFO]: Epoch 045 - training loss: 0.2063, validation loss: 0.2013
2024-05-25 02:01:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch45_loss0.20131493732333183.pypots
2024-05-25 02:01:09 [INFO]: Epoch 046 - training loss: 0.2252, validation loss: 0.1741
2024-05-25 02:01:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch46_loss0.17409054189920425.pypots
2024-05-25 02:01:11 [INFO]: Epoch 047 - training loss: 0.1861, validation loss: 0.1679
2024-05-25 02:01:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch47_loss0.16792724281549454.pypots
2024-05-25 02:01:13 [INFO]: Epoch 048 - training loss: 0.1796, validation loss: 0.1675
2024-05-25 02:01:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch48_loss0.16751666739583015.pypots
2024-05-25 02:01:15 [INFO]: Epoch 049 - training loss: 0.1718, validation loss: 0.1634
2024-05-25 02:01:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch49_loss0.16342132911086082.pypots
2024-05-25 02:01:17 [INFO]: Epoch 050 - training loss: 0.2086, validation loss: 0.1674
2024-05-25 02:01:17 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch50_loss0.16739756986498833.pypots
2024-05-25 02:01:19 [INFO]: Epoch 051 - training loss: 0.2540, validation loss: 0.1695
2024-05-25 02:01:19 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch51_loss0.16951829940080643.pypots
2024-05-25 02:01:21 [INFO]: Epoch 052 - training loss: 0.1925, validation loss: 0.1595
2024-05-25 02:01:21 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch52_loss0.15952011570334435.pypots
2024-05-25 02:01:23 [INFO]: Epoch 053 - training loss: 0.2438, validation loss: 0.1565
2024-05-25 02:01:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch53_loss0.15652279928326607.pypots
2024-05-25 02:01:26 [INFO]: Epoch 054 - training loss: 0.1722, validation loss: 0.1575
2024-05-25 02:01:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch54_loss0.1575162708759308.pypots
2024-05-25 02:01:28 [INFO]: Epoch 055 - training loss: 0.1554, validation loss: 0.1534
2024-05-25 02:01:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch55_loss0.15341766923666.pypots
2024-05-25 02:01:30 [INFO]: Epoch 056 - training loss: 0.1984, validation loss: 0.1565
2024-05-25 02:01:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch56_loss0.156463623046875.pypots
2024-05-25 02:01:32 [INFO]: Epoch 057 - training loss: 0.2030, validation loss: 0.1624
2024-05-25 02:01:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch57_loss0.1623968780040741.pypots
2024-05-25 02:01:34 [INFO]: Epoch 058 - training loss: 0.2151, validation loss: 0.1653
2024-05-25 02:01:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch58_loss0.16533558815717697.pypots
2024-05-25 02:01:36 [INFO]: Epoch 059 - training loss: 0.1970, validation loss: 0.1708
2024-05-25 02:01:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch59_loss0.17076031118631363.pypots
2024-05-25 02:01:38 [INFO]: Epoch 060 - training loss: 0.2105, validation loss: 0.1639
2024-05-25 02:01:38 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch60_loss0.1638971008360386.pypots
2024-05-25 02:01:40 [INFO]: Epoch 061 - training loss: 0.1801, validation loss: 0.1560
2024-05-25 02:01:40 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch61_loss0.15601442381739616.pypots
2024-05-25 02:01:42 [INFO]: Epoch 062 - training loss: 0.1953, validation loss: 0.1512
2024-05-25 02:01:42 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch62_loss0.15120718255639076.pypots
2024-05-25 02:01:44 [INFO]: Epoch 063 - training loss: 0.1945, validation loss: 0.1489
2024-05-25 02:01:44 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch63_loss0.14888041839003563.pypots
2024-05-25 02:01:46 [INFO]: Epoch 064 - training loss: 0.1830, validation loss: 0.1528
2024-05-25 02:01:46 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch64_loss0.15284724161028862.pypots
2024-05-25 02:01:48 [INFO]: Epoch 065 - training loss: 0.1681, validation loss: 0.1480
2024-05-25 02:01:48 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch65_loss0.1479758359491825.pypots
2024-05-25 02:01:51 [INFO]: Epoch 066 - training loss: 0.1587, validation loss: 0.1468
2024-05-25 02:01:51 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch66_loss0.1468416452407837.pypots
2024-05-25 02:01:53 [INFO]: Epoch 067 - training loss: 0.1693, validation loss: 0.1445
2024-05-25 02:01:53 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch67_loss0.144477691501379.pypots
2024-05-25 02:01:55 [INFO]: Epoch 068 - training loss: 0.1718, validation loss: 0.1466
2024-05-25 02:01:55 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch68_loss0.14663830399513245.pypots
2024-05-25 02:01:57 [INFO]: Epoch 069 - training loss: 0.1699, validation loss: 0.1457
2024-05-25 02:01:57 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch69_loss0.14574617892503738.pypots
2024-05-25 02:01:59 [INFO]: Epoch 070 - training loss: 0.1382, validation loss: 0.1422
2024-05-25 02:01:59 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch70_loss0.14217015728354454.pypots
2024-05-25 02:02:01 [INFO]: Epoch 071 - training loss: 0.1743, validation loss: 0.1453
2024-05-25 02:02:01 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch71_loss0.1453147940337658.pypots
2024-05-25 02:02:03 [INFO]: Epoch 072 - training loss: 0.1685, validation loss: 0.1391
2024-05-25 02:02:03 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch72_loss0.1391281597316265.pypots
2024-05-25 02:02:05 [INFO]: Epoch 073 - training loss: 0.1362, validation loss: 0.1380
2024-05-25 02:02:05 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch73_loss0.13804791867733002.pypots
2024-05-25 02:02:07 [INFO]: Epoch 074 - training loss: 0.1582, validation loss: 0.1410
2024-05-25 02:02:07 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch74_loss0.14096323773264885.pypots
2024-05-25 02:02:09 [INFO]: Epoch 075 - training loss: 0.1659, validation loss: 0.1397
2024-05-25 02:02:09 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch75_loss0.13965659961104393.pypots
2024-05-25 02:02:11 [INFO]: Epoch 076 - training loss: 0.1643, validation loss: 0.1423
2024-05-25 02:02:11 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch76_loss0.14231440797448158.pypots
2024-05-25 02:02:13 [INFO]: Epoch 077 - training loss: 0.1285, validation loss: 0.1427
2024-05-25 02:02:13 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch77_loss0.1426798179745674.pypots
2024-05-25 02:02:15 [INFO]: Epoch 078 - training loss: 0.1666, validation loss: 0.1359
2024-05-25 02:02:15 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch78_loss0.13586843386292458.pypots
2024-05-25 02:02:18 [INFO]: Epoch 079 - training loss: 0.1722, validation loss: 0.1372
2024-05-25 02:02:18 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch79_loss0.1371578797698021.pypots
2024-05-25 02:02:20 [INFO]: Epoch 080 - training loss: 0.1404, validation loss: 0.1400
2024-05-25 02:02:20 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch80_loss0.13995933532714844.pypots
2024-05-25 02:02:22 [INFO]: Epoch 081 - training loss: 0.1481, validation loss: 0.1420
2024-05-25 02:02:22 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch81_loss0.14202186837792397.pypots
2024-05-25 02:02:24 [INFO]: Epoch 082 - training loss: 0.1732, validation loss: 0.1382
2024-05-25 02:02:24 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch82_loss0.13817520067095757.pypots
2024-05-25 02:02:26 [INFO]: Epoch 083 - training loss: 0.2112, validation loss: 0.1419
2024-05-25 02:02:26 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch83_loss0.14186660200357437.pypots
2024-05-25 02:02:28 [INFO]: Epoch 084 - training loss: 0.1686, validation loss: 0.1503
2024-05-25 02:02:28 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch84_loss0.15031519532203674.pypots
2024-05-25 02:02:30 [INFO]: Epoch 085 - training loss: 0.1555, validation loss: 0.1436
2024-05-25 02:02:30 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch85_loss0.14361071959137917.pypots
2024-05-25 02:02:32 [INFO]: Epoch 086 - training loss: 0.1672, validation loss: 0.1425
2024-05-25 02:02:32 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch86_loss0.14247504621744156.pypots
2024-05-25 02:02:34 [INFO]: Epoch 087 - training loss: 0.1623, validation loss: 0.1397
2024-05-25 02:02:34 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch87_loss0.13968074321746826.pypots
2024-05-25 02:02:36 [INFO]: Epoch 088 - training loss: 0.2350, validation loss: 0.1467
2024-05-25 02:02:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI_epoch88_loss0.14671985059976578.pypots
2024-05-25 02:02:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:02:36 [INFO]: Finished training. The best model is from epoch#78.
2024-05-25 02:02:36 [INFO]: Saved the model to augmentation_saved_results/round_2/CSDI_ettm1/20240525_T015933/CSDI.pypots
2024-05-25 02:02:52 [INFO]: CSDI on ETTm1: MAE=0.1794, MSE=0.1205
2024-05-25 02:02:52 [INFO]: Successfully saved to augmentation_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-25 02:02:52 [INFO]: Using the given device: cuda:0
2024-05-25 02:02:52 [INFO]: Model files will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T020252
2024-05-25 02:02:52 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T020252/tensorboard
2024-05-25 02:02:52 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 02:02:52 [INFO]: Epoch 001 - training loss: 24355.2550, validation loss: 0.9746
2024-05-25 02:02:52 [INFO]: Epoch 002 - training loss: 22306.1758, validation loss: 0.9682
2024-05-25 02:02:53 [INFO]: Epoch 003 - training loss: 20422.0441, validation loss: 0.9596
2024-05-25 02:02:53 [INFO]: Epoch 004 - training loss: 18361.2057, validation loss: 0.9419
2024-05-25 02:02:53 [INFO]: Epoch 005 - training loss: 16342.0102, validation loss: 0.9049
2024-05-25 02:02:53 [INFO]: Epoch 006 - training loss: 14776.4653, validation loss: 0.8360
2024-05-25 02:02:53 [INFO]: Epoch 007 - training loss: 13361.2975, validation loss: 0.7201
2024-05-25 02:02:53 [INFO]: Epoch 008 - training loss: 12213.7502, validation loss: 0.6140
2024-05-25 02:02:53 [INFO]: Epoch 009 - training loss: 11613.0979, validation loss: 0.5624
2024-05-25 02:02:53 [INFO]: Epoch 010 - training loss: 11137.4601, validation loss: 0.5200
2024-05-25 02:02:54 [INFO]: Epoch 011 - training loss: 10792.8671, validation loss: 0.4991
2024-05-25 02:02:54 [INFO]: Epoch 012 - training loss: 10553.5136, validation loss: 0.4844
2024-05-25 02:02:54 [INFO]: Epoch 013 - training loss: 10284.0655, validation loss: 0.4724
2024-05-25 02:02:54 [INFO]: Epoch 014 - training loss: 10231.7415, validation loss: 0.4648
2024-05-25 02:02:54 [INFO]: Epoch 015 - training loss: 10126.6855, validation loss: 0.4484
2024-05-25 02:02:54 [INFO]: Epoch 016 - training loss: 9958.6229, validation loss: 0.4246
2024-05-25 02:02:54 [INFO]: Epoch 017 - training loss: 9834.0911, validation loss: 0.3973
2024-05-25 02:02:54 [INFO]: Epoch 018 - training loss: 9814.0248, validation loss: 0.3742
2024-05-25 02:02:54 [INFO]: Epoch 019 - training loss: 9732.2283, validation loss: 0.3559
2024-05-25 02:02:55 [INFO]: Epoch 020 - training loss: 9677.5601, validation loss: 0.3464
2024-05-25 02:02:55 [INFO]: Epoch 021 - training loss: 9637.3532, validation loss: 0.3410
2024-05-25 02:02:55 [INFO]: Epoch 022 - training loss: 9607.1323, validation loss: 0.3333
2024-05-25 02:02:55 [INFO]: Epoch 023 - training loss: 9584.2966, validation loss: 0.3320
2024-05-25 02:02:55 [INFO]: Epoch 024 - training loss: 9534.9216, validation loss: 0.3292
2024-05-25 02:02:55 [INFO]: Epoch 025 - training loss: 9509.7600, validation loss: 0.3369
2024-05-25 02:02:55 [INFO]: Epoch 026 - training loss: 9553.6661, validation loss: 0.3334
2024-05-25 02:02:55 [INFO]: Epoch 027 - training loss: 9468.9467, validation loss: 0.3239
2024-05-25 02:02:56 [INFO]: Epoch 028 - training loss: 9457.3898, validation loss: 0.3203
2024-05-25 02:02:56 [INFO]: Epoch 029 - training loss: 9435.7770, validation loss: 0.3143
2024-05-25 02:02:56 [INFO]: Epoch 030 - training loss: 9420.3456, validation loss: 0.3178
2024-05-25 02:02:56 [INFO]: Epoch 031 - training loss: 9422.2399, validation loss: 0.3084
2024-05-25 02:02:56 [INFO]: Epoch 032 - training loss: 9409.0834, validation loss: 0.3048
2024-05-25 02:02:56 [INFO]: Epoch 033 - training loss: 9444.0412, validation loss: 0.3002
2024-05-25 02:02:56 [INFO]: Epoch 034 - training loss: 9397.1129, validation loss: 0.2925
2024-05-25 02:02:56 [INFO]: Epoch 035 - training loss: 9380.1100, validation loss: 0.2923
2024-05-25 02:02:57 [INFO]: Epoch 036 - training loss: 9361.3591, validation loss: 0.2857
2024-05-25 02:02:57 [INFO]: Epoch 037 - training loss: 9350.5520, validation loss: 0.2770
2024-05-25 02:02:57 [INFO]: Epoch 038 - training loss: 9344.9677, validation loss: 0.2759
2024-05-25 02:02:57 [INFO]: Epoch 039 - training loss: 9345.1431, validation loss: 0.2625
2024-05-25 02:02:57 [INFO]: Epoch 040 - training loss: 9341.1140, validation loss: 0.2550
2024-05-25 02:02:57 [INFO]: Epoch 041 - training loss: 9340.3636, validation loss: 0.2614
2024-05-25 02:02:57 [INFO]: Epoch 042 - training loss: 9330.5358, validation loss: 0.2481
2024-05-25 02:02:57 [INFO]: Epoch 043 - training loss: 9320.0206, validation loss: 0.2447
2024-05-25 02:02:58 [INFO]: Epoch 044 - training loss: 9315.7164, validation loss: 0.2390
2024-05-25 02:02:58 [INFO]: Epoch 045 - training loss: 9311.4843, validation loss: 0.2325
2024-05-25 02:02:58 [INFO]: Epoch 046 - training loss: 9310.4382, validation loss: 0.2227
2024-05-25 02:02:58 [INFO]: Epoch 047 - training loss: 9310.3680, validation loss: 0.2158
2024-05-25 02:02:58 [INFO]: Epoch 048 - training loss: 9302.0289, validation loss: 0.2138
2024-05-25 02:02:58 [INFO]: Epoch 049 - training loss: 9301.9385, validation loss: 0.2052
2024-05-25 02:02:58 [INFO]: Epoch 050 - training loss: 9298.9877, validation loss: 0.2007
2024-05-25 02:02:58 [INFO]: Epoch 051 - training loss: 9292.6146, validation loss: 0.1942
2024-05-25 02:02:59 [INFO]: Epoch 052 - training loss: 9287.3959, validation loss: 0.1919
2024-05-25 02:02:59 [INFO]: Epoch 053 - training loss: 9293.9734, validation loss: 0.1883
2024-05-25 02:02:59 [INFO]: Epoch 054 - training loss: 9288.4850, validation loss: 0.1863
2024-05-25 02:02:59 [INFO]: Epoch 055 - training loss: 9278.9493, validation loss: 0.1792
2024-05-25 02:02:59 [INFO]: Epoch 056 - training loss: 9276.9581, validation loss: 0.1765
2024-05-25 02:02:59 [INFO]: Epoch 057 - training loss: 9273.3187, validation loss: 0.1752
2024-05-25 02:02:59 [INFO]: Epoch 058 - training loss: 9271.7903, validation loss: 0.1711
2024-05-25 02:02:59 [INFO]: Epoch 059 - training loss: 9270.2166, validation loss: 0.1693
2024-05-25 02:03:00 [INFO]: Epoch 060 - training loss: 9268.6985, validation loss: 0.1646
2024-05-25 02:03:00 [INFO]: Epoch 061 - training loss: 9267.4800, validation loss: 0.1626
2024-05-25 02:03:00 [INFO]: Epoch 062 - training loss: 9266.1477, validation loss: 0.1590
2024-05-25 02:03:00 [INFO]: Epoch 063 - training loss: 9264.8899, validation loss: 0.1587
2024-05-25 02:03:00 [INFO]: Epoch 064 - training loss: 9263.7367, validation loss: 0.1561
2024-05-25 02:03:00 [INFO]: Epoch 065 - training loss: 9259.4762, validation loss: 0.1555
2024-05-25 02:03:00 [INFO]: Epoch 066 - training loss: 9257.3110, validation loss: 0.1541
2024-05-25 02:03:00 [INFO]: Epoch 067 - training loss: 9262.9612, validation loss: 0.1515
2024-05-25 02:03:00 [INFO]: Epoch 068 - training loss: 9256.2328, validation loss: 0.1512
2024-05-25 02:03:01 [INFO]: Epoch 069 - training loss: 9256.7465, validation loss: 0.1480
2024-05-25 02:03:01 [INFO]: Epoch 070 - training loss: 9253.5668, validation loss: 0.1481
2024-05-25 02:03:01 [INFO]: Epoch 071 - training loss: 9253.6794, validation loss: 0.1461
2024-05-25 02:03:01 [INFO]: Epoch 072 - training loss: 9251.3661, validation loss: 0.1454
2024-05-25 02:03:01 [INFO]: Epoch 073 - training loss: 9252.4616, validation loss: 0.1449
2024-05-25 02:03:01 [INFO]: Epoch 074 - training loss: 9249.8447, validation loss: 0.1432
2024-05-25 02:03:01 [INFO]: Epoch 075 - training loss: 9249.7150, validation loss: 0.1417
2024-05-25 02:03:01 [INFO]: Epoch 076 - training loss: 9248.8878, validation loss: 0.1396
2024-05-25 02:03:02 [INFO]: Epoch 077 - training loss: 9248.8193, validation loss: 0.1406
2024-05-25 02:03:02 [INFO]: Epoch 078 - training loss: 9246.6401, validation loss: 0.1388
2024-05-25 02:03:02 [INFO]: Epoch 079 - training loss: 9247.6719, validation loss: 0.1409
2024-05-25 02:03:02 [INFO]: Epoch 080 - training loss: 9245.2260, validation loss: 0.1385
2024-05-25 02:03:02 [INFO]: Epoch 081 - training loss: 9249.4255, validation loss: 0.1371
2024-05-25 02:03:02 [INFO]: Epoch 082 - training loss: 9242.3762, validation loss: 0.1360
2024-05-25 02:03:02 [INFO]: Epoch 083 - training loss: 9247.4493, validation loss: 0.1355
2024-05-25 02:03:02 [INFO]: Epoch 084 - training loss: 9242.6547, validation loss: 0.1366
2024-05-25 02:03:03 [INFO]: Epoch 085 - training loss: 9240.4706, validation loss: 0.1334
2024-05-25 02:03:03 [INFO]: Epoch 086 - training loss: 9239.5001, validation loss: 0.1342
2024-05-25 02:03:03 [INFO]: Epoch 087 - training loss: 9240.4904, validation loss: 0.1320
2024-05-25 02:03:03 [INFO]: Epoch 088 - training loss: 9239.6711, validation loss: 0.1307
2024-05-25 02:03:03 [INFO]: Epoch 089 - training loss: 9238.7546, validation loss: 0.1311
2024-05-25 02:03:03 [INFO]: Epoch 090 - training loss: 9236.6269, validation loss: 0.1307
2024-05-25 02:03:03 [INFO]: Epoch 091 - training loss: 9237.0936, validation loss: 0.1286
2024-05-25 02:03:03 [INFO]: Epoch 092 - training loss: 9236.8093, validation loss: 0.1294
2024-05-25 02:03:04 [INFO]: Epoch 093 - training loss: 9238.5613, validation loss: 0.1278
2024-05-25 02:03:04 [INFO]: Epoch 094 - training loss: 9234.0686, validation loss: 0.1263
2024-05-25 02:03:04 [INFO]: Epoch 095 - training loss: 9233.0720, validation loss: 0.1269
2024-05-25 02:03:04 [INFO]: Epoch 096 - training loss: 9237.3311, validation loss: 0.1255
2024-05-25 02:03:04 [INFO]: Epoch 097 - training loss: 9233.9454, validation loss: 0.1241
2024-05-25 02:03:04 [INFO]: Epoch 098 - training loss: 9233.6747, validation loss: 0.1259
2024-05-25 02:03:04 [INFO]: Epoch 099 - training loss: 9232.7386, validation loss: 0.1229
2024-05-25 02:03:04 [INFO]: Epoch 100 - training loss: 9229.7554, validation loss: 0.1243
2024-05-25 02:03:05 [INFO]: Epoch 101 - training loss: 9232.7069, validation loss: 0.1214
2024-05-25 02:03:05 [INFO]: Epoch 102 - training loss: 9229.2864, validation loss: 0.1213
2024-05-25 02:03:05 [INFO]: Epoch 103 - training loss: 9237.3278, validation loss: 0.1195
2024-05-25 02:03:05 [INFO]: Epoch 104 - training loss: 9231.1155, validation loss: 0.1197
2024-05-25 02:03:05 [INFO]: Epoch 105 - training loss: 9228.0579, validation loss: 0.1210
2024-05-25 02:03:05 [INFO]: Epoch 106 - training loss: 9227.3436, validation loss: 0.1201
2024-05-25 02:03:05 [INFO]: Epoch 107 - training loss: 9228.8781, validation loss: 0.1194
2024-05-25 02:03:05 [INFO]: Epoch 108 - training loss: 9228.3290, validation loss: 0.1192
2024-05-25 02:03:05 [INFO]: Epoch 109 - training loss: 9230.2799, validation loss: 0.1186
2024-05-25 02:03:06 [INFO]: Epoch 110 - training loss: 9229.0714, validation loss: 0.1164
2024-05-25 02:03:06 [INFO]: Epoch 111 - training loss: 9227.6031, validation loss: 0.1232
2024-05-25 02:03:06 [INFO]: Epoch 112 - training loss: 9227.6578, validation loss: 0.1188
2024-05-25 02:03:06 [INFO]: Epoch 113 - training loss: 9225.8708, validation loss: 0.1156
2024-05-25 02:03:06 [INFO]: Epoch 114 - training loss: 9226.8585, validation loss: 0.1142
2024-05-25 02:03:06 [INFO]: Epoch 115 - training loss: 9227.3447, validation loss: 0.1146
2024-05-25 02:03:06 [INFO]: Epoch 116 - training loss: 9227.9534, validation loss: 0.1143
2024-05-25 02:03:06 [INFO]: Epoch 117 - training loss: 9223.8462, validation loss: 0.1149
2024-05-25 02:03:07 [INFO]: Epoch 118 - training loss: 9226.9525, validation loss: 0.1122
2024-05-25 02:03:07 [INFO]: Epoch 119 - training loss: 9225.1881, validation loss: 0.1120
2024-05-25 02:03:07 [INFO]: Epoch 120 - training loss: 9225.7620, validation loss: 0.1135
2024-05-25 02:03:07 [INFO]: Epoch 121 - training loss: 9223.8102, validation loss: 0.1115
2024-05-25 02:03:07 [INFO]: Epoch 122 - training loss: 9225.0600, validation loss: 0.1130
2024-05-25 02:03:07 [INFO]: Epoch 123 - training loss: 9223.4958, validation loss: 0.1092
2024-05-25 02:03:07 [INFO]: Epoch 124 - training loss: 9221.3933, validation loss: 0.1118
2024-05-25 02:03:07 [INFO]: Epoch 125 - training loss: 9224.0648, validation loss: 0.1103
2024-05-25 02:03:08 [INFO]: Epoch 126 - training loss: 9224.2186, validation loss: 0.1097
2024-05-25 02:03:08 [INFO]: Epoch 127 - training loss: 9223.4703, validation loss: 0.1104
2024-05-25 02:03:08 [INFO]: Epoch 128 - training loss: 9221.1984, validation loss: 0.1074
2024-05-25 02:03:08 [INFO]: Epoch 129 - training loss: 9220.7737, validation loss: 0.1108
2024-05-25 02:03:08 [INFO]: Epoch 130 - training loss: 9221.9531, validation loss: 0.1087
2024-05-25 02:03:08 [INFO]: Epoch 131 - training loss: 9220.5646, validation loss: 0.1064
2024-05-25 02:03:08 [INFO]: Epoch 132 - training loss: 9225.7228, validation loss: 0.1096
2024-05-25 02:03:08 [INFO]: Epoch 133 - training loss: 9241.6412, validation loss: 0.1064
2024-05-25 02:03:09 [INFO]: Epoch 134 - training loss: 9219.1812, validation loss: 0.1064
2024-05-25 02:03:09 [INFO]: Epoch 135 - training loss: 9219.2391, validation loss: 0.1071
2024-05-25 02:03:09 [INFO]: Epoch 136 - training loss: 9223.1922, validation loss: 0.1052
2024-05-25 02:03:09 [INFO]: Epoch 137 - training loss: 9220.6124, validation loss: 0.1067
2024-05-25 02:03:09 [INFO]: Epoch 138 - training loss: 9218.0263, validation loss: 0.1047
2024-05-25 02:03:09 [INFO]: Epoch 139 - training loss: 9218.0789, validation loss: 0.1043
2024-05-25 02:03:09 [INFO]: Epoch 140 - training loss: 9219.2833, validation loss: 0.1042
2024-05-25 02:03:09 [INFO]: Epoch 141 - training loss: 9220.4169, validation loss: 0.1024
2024-05-25 02:03:10 [INFO]: Epoch 142 - training loss: 9218.3845, validation loss: 0.1054
2024-05-25 02:03:10 [INFO]: Epoch 143 - training loss: 9218.0651, validation loss: 0.1036
2024-05-25 02:03:10 [INFO]: Epoch 144 - training loss: 9217.2470, validation loss: 0.1024
2024-05-25 02:03:10 [INFO]: Epoch 145 - training loss: 9217.0754, validation loss: 0.1026
2024-05-25 02:03:10 [INFO]: Epoch 146 - training loss: 9218.8839, validation loss: 0.1041
2024-05-25 02:03:10 [INFO]: Epoch 147 - training loss: 9217.1040, validation loss: 0.1010
2024-05-25 02:03:10 [INFO]: Epoch 148 - training loss: 9217.7311, validation loss: 0.1011
2024-05-25 02:03:10 [INFO]: Epoch 149 - training loss: 9217.8979, validation loss: 0.0993
2024-05-25 02:03:10 [INFO]: Epoch 150 - training loss: 9216.8594, validation loss: 0.1007
2024-05-25 02:03:11 [INFO]: Epoch 151 - training loss: 9217.7448, validation loss: 0.1009
2024-05-25 02:03:11 [INFO]: Epoch 152 - training loss: 9217.7413, validation loss: 0.1011
2024-05-25 02:03:11 [INFO]: Epoch 153 - training loss: 9215.4864, validation loss: 0.1004
2024-05-25 02:03:11 [INFO]: Epoch 154 - training loss: 9217.0523, validation loss: 0.1021
2024-05-25 02:03:11 [INFO]: Epoch 155 - training loss: 9216.0312, validation loss: 0.1006
2024-05-25 02:03:11 [INFO]: Epoch 156 - training loss: 9215.4868, validation loss: 0.0986
2024-05-25 02:03:11 [INFO]: Epoch 157 - training loss: 9214.3079, validation loss: 0.0991
2024-05-25 02:03:11 [INFO]: Epoch 158 - training loss: 9214.4421, validation loss: 0.0992
2024-05-25 02:03:12 [INFO]: Epoch 159 - training loss: 9215.0669, validation loss: 0.0980
2024-05-25 02:03:12 [INFO]: Epoch 160 - training loss: 9215.7041, validation loss: 0.0971
2024-05-25 02:03:12 [INFO]: Epoch 161 - training loss: 9214.7719, validation loss: 0.1026
2024-05-25 02:03:12 [INFO]: Epoch 162 - training loss: 9216.0658, validation loss: 0.0969
2024-05-25 02:03:12 [INFO]: Epoch 163 - training loss: 9214.3915, validation loss: 0.0999
2024-05-25 02:03:12 [INFO]: Epoch 164 - training loss: 9214.4145, validation loss: 0.0979
2024-05-25 02:03:12 [INFO]: Epoch 165 - training loss: 9214.2896, validation loss: 0.0955
2024-05-25 02:03:12 [INFO]: Epoch 166 - training loss: 9213.5717, validation loss: 0.0986
2024-05-25 02:03:13 [INFO]: Epoch 167 - training loss: 9213.2422, validation loss: 0.0973
2024-05-25 02:03:13 [INFO]: Epoch 168 - training loss: 9213.4703, validation loss: 0.0967
2024-05-25 02:03:13 [INFO]: Epoch 169 - training loss: 9213.6704, validation loss: 0.0973
2024-05-25 02:03:13 [INFO]: Epoch 170 - training loss: 9213.5442, validation loss: 0.0963
2024-05-25 02:03:13 [INFO]: Epoch 171 - training loss: 9213.3939, validation loss: 0.0959
2024-05-25 02:03:13 [INFO]: Epoch 172 - training loss: 9214.7084, validation loss: 0.0956
2024-05-25 02:03:13 [INFO]: Epoch 173 - training loss: 9213.8712, validation loss: 0.0964
2024-05-25 02:03:13 [INFO]: Epoch 174 - training loss: 9214.6838, validation loss: 0.0958
2024-05-25 02:03:14 [INFO]: Epoch 175 - training loss: 9212.2446, validation loss: 0.0997
2024-05-25 02:03:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:03:14 [INFO]: Finished training. The best model is from epoch#165.
2024-05-25 02:03:14 [INFO]: Saved the model to augmentation_saved_results/round_2/GPVAE_ettm1/20240525_T020252/GPVAE.pypots
2024-05-25 02:03:14 [INFO]: GP-VAE on ETTm1: MAE=0.2964, MSE=0.1882
2024-05-25 02:03:14 [INFO]: Successfully saved to augmentation_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-25 02:03:14 [INFO]: Using the given device: cuda:0
2024-05-25 02:03:14 [INFO]: Model files will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020314
2024-05-25 02:03:14 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020314/tensorboard
2024-05-25 02:03:14 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:03:24 [INFO]: Epoch 001 - generator training loss: 0.4771, discriminator training loss: 0.5346, validation loss: 0.4669
2024-05-25 02:03:33 [INFO]: Epoch 002 - generator training loss: -0.0291, discriminator training loss: 0.4708, validation loss: 0.1249
2024-05-25 02:03:42 [INFO]: Epoch 003 - generator training loss: -0.1635, discriminator training loss: 0.4292, validation loss: 0.0704
2024-05-25 02:03:51 [INFO]: Epoch 004 - generator training loss: -0.1497, discriminator training loss: 0.3655, validation loss: 0.0562
2024-05-25 02:04:00 [INFO]: Epoch 005 - generator training loss: -0.1075, discriminator training loss: 0.2891, validation loss: 0.0473
2024-05-25 02:04:09 [INFO]: Epoch 006 - generator training loss: -0.0746, discriminator training loss: 0.2299, validation loss: 0.0441
2024-05-25 02:04:18 [INFO]: Epoch 007 - generator training loss: -0.0602, discriminator training loss: 0.1995, validation loss: 0.0407
2024-05-25 02:04:27 [INFO]: Epoch 008 - generator training loss: -0.0553, discriminator training loss: 0.1878, validation loss: 0.0396
2024-05-25 02:04:36 [INFO]: Epoch 009 - generator training loss: -0.0511, discriminator training loss: 0.1806, validation loss: 0.0395
2024-05-25 02:04:45 [INFO]: Epoch 010 - generator training loss: -0.0549, discriminator training loss: 0.1764, validation loss: 0.0380
2024-05-25 02:04:54 [INFO]: Epoch 011 - generator training loss: -0.0562, discriminator training loss: 0.1734, validation loss: 0.0362
2024-05-25 02:05:03 [INFO]: Epoch 012 - generator training loss: -0.0564, discriminator training loss: 0.1726, validation loss: 0.0361
2024-05-25 02:05:12 [INFO]: Epoch 013 - generator training loss: -0.0563, discriminator training loss: 0.1728, validation loss: 0.0349
2024-05-25 02:05:21 [INFO]: Epoch 014 - generator training loss: -0.0571, discriminator training loss: 0.1715, validation loss: 0.0366
2024-05-25 02:05:30 [INFO]: Epoch 015 - generator training loss: -0.0571, discriminator training loss: 0.1701, validation loss: 0.0358
2024-05-25 02:05:39 [INFO]: Epoch 016 - generator training loss: -0.0583, discriminator training loss: 0.1724, validation loss: 0.0347
2024-05-25 02:05:48 [INFO]: Epoch 017 - generator training loss: -0.0591, discriminator training loss: 0.1723, validation loss: 0.0343
2024-05-25 02:05:57 [INFO]: Epoch 018 - generator training loss: -0.0569, discriminator training loss: 0.1709, validation loss: 0.0341
2024-05-25 02:06:06 [INFO]: Epoch 019 - generator training loss: -0.0575, discriminator training loss: 0.1707, validation loss: 0.0343
2024-05-25 02:06:15 [INFO]: Epoch 020 - generator training loss: -0.0584, discriminator training loss: 0.1684, validation loss: 0.0334
2024-05-25 02:06:24 [INFO]: Epoch 021 - generator training loss: -0.0576, discriminator training loss: 0.1716, validation loss: 0.0335
2024-05-25 02:06:33 [INFO]: Epoch 022 - generator training loss: -0.0594, discriminator training loss: 0.1693, validation loss: 0.0336
2024-05-25 02:06:42 [INFO]: Epoch 023 - generator training loss: -0.0577, discriminator training loss: 0.1687, validation loss: 0.0336
2024-05-25 02:06:51 [INFO]: Epoch 024 - generator training loss: -0.0596, discriminator training loss: 0.1679, validation loss: 0.0331
2024-05-25 02:07:00 [INFO]: Epoch 025 - generator training loss: -0.0625, discriminator training loss: 0.1689, validation loss: 0.0320
2024-05-25 02:07:09 [INFO]: Epoch 026 - generator training loss: -0.0606, discriminator training loss: 0.1674, validation loss: 0.0329
2024-05-25 02:07:18 [INFO]: Epoch 027 - generator training loss: -0.0647, discriminator training loss: 0.1674, validation loss: 0.0316
2024-05-25 02:07:27 [INFO]: Epoch 028 - generator training loss: -0.0619, discriminator training loss: 0.1696, validation loss: 0.0315
2024-05-25 02:07:36 [INFO]: Epoch 029 - generator training loss: -0.0627, discriminator training loss: 0.1679, validation loss: 0.0314
2024-05-25 02:07:45 [INFO]: Epoch 030 - generator training loss: -0.0617, discriminator training loss: 0.1688, validation loss: 0.0312
2024-05-25 02:07:53 [INFO]: Epoch 031 - generator training loss: -0.0633, discriminator training loss: 0.1674, validation loss: 0.0314
2024-05-25 02:08:02 [INFO]: Epoch 032 - generator training loss: -0.0639, discriminator training loss: 0.1680, validation loss: 0.0306
2024-05-25 02:08:11 [INFO]: Epoch 033 - generator training loss: -0.0650, discriminator training loss: 0.1696, validation loss: 0.0315
2024-05-25 02:08:20 [INFO]: Epoch 034 - generator training loss: -0.0645, discriminator training loss: 0.1675, validation loss: 0.0303
2024-05-25 02:08:29 [INFO]: Epoch 035 - generator training loss: -0.0645, discriminator training loss: 0.1662, validation loss: 0.0299
2024-05-25 02:08:38 [INFO]: Epoch 036 - generator training loss: -0.0626, discriminator training loss: 0.1678, validation loss: 0.0302
2024-05-25 02:08:47 [INFO]: Epoch 037 - generator training loss: -0.0663, discriminator training loss: 0.1661, validation loss: 0.0298
2024-05-25 02:08:56 [INFO]: Epoch 038 - generator training loss: -0.0664, discriminator training loss: 0.1680, validation loss: 0.0289
2024-05-25 02:09:05 [INFO]: Epoch 039 - generator training loss: -0.0641, discriminator training loss: 0.1653, validation loss: 0.0300
2024-05-25 02:09:14 [INFO]: Epoch 040 - generator training loss: -0.0652, discriminator training loss: 0.1661, validation loss: 0.0291
2024-05-25 02:09:23 [INFO]: Epoch 041 - generator training loss: -0.0633, discriminator training loss: 0.1672, validation loss: 0.0290
2024-05-25 02:09:32 [INFO]: Epoch 042 - generator training loss: -0.0680, discriminator training loss: 0.1645, validation loss: 0.0280
2024-05-25 02:09:41 [INFO]: Epoch 043 - generator training loss: -0.0665, discriminator training loss: 0.1651, validation loss: 0.0283
2024-05-25 02:09:50 [INFO]: Epoch 044 - generator training loss: -0.0663, discriminator training loss: 0.1654, validation loss: 0.0278
2024-05-25 02:09:59 [INFO]: Epoch 045 - generator training loss: -0.0681, discriminator training loss: 0.1650, validation loss: 0.0281
2024-05-25 02:10:08 [INFO]: Epoch 046 - generator training loss: -0.0673, discriminator training loss: 0.1662, validation loss: 0.0299
2024-05-25 02:10:17 [INFO]: Epoch 047 - generator training loss: -0.0672, discriminator training loss: 0.1671, validation loss: 0.0273
2024-05-25 02:10:26 [INFO]: Epoch 048 - generator training loss: -0.0649, discriminator training loss: 0.1670, validation loss: 0.0274
2024-05-25 02:10:35 [INFO]: Epoch 049 - generator training loss: -0.0678, discriminator training loss: 0.1662, validation loss: 0.0263
2024-05-25 02:10:44 [INFO]: Epoch 050 - generator training loss: -0.0663, discriminator training loss: 0.1649, validation loss: 0.0274
2024-05-25 02:10:53 [INFO]: Epoch 051 - generator training loss: -0.0698, discriminator training loss: 0.1653, validation loss: 0.0265
2024-05-25 02:11:02 [INFO]: Epoch 052 - generator training loss: -0.0698, discriminator training loss: 0.1657, validation loss: 0.0271
2024-05-25 02:11:11 [INFO]: Epoch 053 - generator training loss: -0.0674, discriminator training loss: 0.1665, validation loss: 0.0263
2024-05-25 02:11:20 [INFO]: Epoch 054 - generator training loss: -0.0684, discriminator training loss: 0.1648, validation loss: 0.0263
2024-05-25 02:11:29 [INFO]: Epoch 055 - generator training loss: -0.0669, discriminator training loss: 0.1662, validation loss: 0.0265
2024-05-25 02:11:38 [INFO]: Epoch 056 - generator training loss: -0.0705, discriminator training loss: 0.1651, validation loss: 0.0258
2024-05-25 02:11:47 [INFO]: Epoch 057 - generator training loss: -0.0659, discriminator training loss: 0.1652, validation loss: 0.0255
2024-05-25 02:11:56 [INFO]: Epoch 058 - generator training loss: -0.0678, discriminator training loss: 0.1662, validation loss: 0.0261
2024-05-25 02:12:05 [INFO]: Epoch 059 - generator training loss: -0.0694, discriminator training loss: 0.1646, validation loss: 0.0254
2024-05-25 02:12:14 [INFO]: Epoch 060 - generator training loss: -0.0686, discriminator training loss: 0.1645, validation loss: 0.0258
2024-05-25 02:12:23 [INFO]: Epoch 061 - generator training loss: -0.0677, discriminator training loss: 0.1663, validation loss: 0.0260
2024-05-25 02:12:32 [INFO]: Epoch 062 - generator training loss: -0.0642, discriminator training loss: 0.1665, validation loss: 0.0256
2024-05-25 02:12:41 [INFO]: Epoch 063 - generator training loss: -0.0703, discriminator training loss: 0.1634, validation loss: 0.0253
2024-05-25 02:12:50 [INFO]: Epoch 064 - generator training loss: -0.0695, discriminator training loss: 0.1642, validation loss: 0.0253
2024-05-25 02:13:00 [INFO]: Epoch 065 - generator training loss: -0.0686, discriminator training loss: 0.1637, validation loss: 0.0255
2024-05-25 02:13:09 [INFO]: Epoch 066 - generator training loss: -0.0711, discriminator training loss: 0.1651, validation loss: 0.0250
2024-05-25 02:13:18 [INFO]: Epoch 067 - generator training loss: -0.0692, discriminator training loss: 0.1649, validation loss: 0.0251
2024-05-25 02:13:27 [INFO]: Epoch 068 - generator training loss: -0.0733, discriminator training loss: 0.1649, validation loss: 0.0249
2024-05-25 02:13:36 [INFO]: Epoch 069 - generator training loss: -0.0688, discriminator training loss: 0.1652, validation loss: 0.0253
2024-05-25 02:13:45 [INFO]: Epoch 070 - generator training loss: -0.0744, discriminator training loss: 0.1641, validation loss: 0.0252
2024-05-25 02:13:54 [INFO]: Epoch 071 - generator training loss: -0.0712, discriminator training loss: 0.1663, validation loss: 0.0247
2024-05-25 02:14:03 [INFO]: Epoch 072 - generator training loss: -0.0701, discriminator training loss: 0.1629, validation loss: 0.0252
2024-05-25 02:14:12 [INFO]: Epoch 073 - generator training loss: -0.0705, discriminator training loss: 0.1663, validation loss: 0.0245
2024-05-25 02:14:21 [INFO]: Epoch 074 - generator training loss: -0.0703, discriminator training loss: 0.1621, validation loss: 0.0255
2024-05-25 02:14:30 [INFO]: Epoch 075 - generator training loss: -0.0734, discriminator training loss: 0.1602, validation loss: 0.0255
2024-05-25 02:14:39 [INFO]: Epoch 076 - generator training loss: -0.0740, discriminator training loss: 0.1647, validation loss: 0.0247
2024-05-25 02:14:48 [INFO]: Epoch 077 - generator training loss: -0.0713, discriminator training loss: 0.1612, validation loss: 0.0243
2024-05-25 02:14:57 [INFO]: Epoch 078 - generator training loss: -0.0741, discriminator training loss: 0.1632, validation loss: 0.0253
2024-05-25 02:15:06 [INFO]: Epoch 079 - generator training loss: -0.0682, discriminator training loss: 0.1642, validation loss: 0.0245
2024-05-25 02:15:15 [INFO]: Epoch 080 - generator training loss: -0.0696, discriminator training loss: 0.1643, validation loss: 0.0264
2024-05-25 02:15:24 [INFO]: Epoch 081 - generator training loss: -0.0702, discriminator training loss: 0.1632, validation loss: 0.0250
2024-05-25 02:15:33 [INFO]: Epoch 082 - generator training loss: -0.0734, discriminator training loss: 0.1641, validation loss: 0.0246
2024-05-25 02:15:42 [INFO]: Epoch 083 - generator training loss: -0.0671, discriminator training loss: 0.1641, validation loss: 0.0258
2024-05-25 02:15:51 [INFO]: Epoch 084 - generator training loss: -0.0711, discriminator training loss: 0.1638, validation loss: 0.0260
2024-05-25 02:16:00 [INFO]: Epoch 085 - generator training loss: -0.0733, discriminator training loss: 0.1615, validation loss: 0.0249
2024-05-25 02:16:09 [INFO]: Epoch 086 - generator training loss: -0.0739, discriminator training loss: 0.1616, validation loss: 0.0246
2024-05-25 02:16:18 [INFO]: Epoch 087 - generator training loss: -0.0707, discriminator training loss: 0.1622, validation loss: 0.0248
2024-05-25 02:16:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:16:18 [INFO]: Finished training. The best model is from epoch#77.
2024-05-25 02:16:18 [INFO]: Saved the model to augmentation_saved_results/round_2/USGAN_ettm1/20240525_T020314/USGAN.pypots
2024-05-25 02:16:19 [INFO]: US-GAN on ETTm1: MAE=0.1705, MSE=0.0683
2024-05-25 02:16:19 [INFO]: Successfully saved to augmentation_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-25 02:16:19 [INFO]: Using the given device: cuda:0
2024-05-25 02:16:19 [INFO]: Model files will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021619
2024-05-25 02:16:19 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021619/tensorboard
2024-05-25 02:16:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 02:16:27 [INFO]: Epoch 001 - training loss: 1.3088, validation loss: 0.3640
2024-05-25 02:16:33 [INFO]: Epoch 002 - training loss: 0.9007, validation loss: 0.0982
2024-05-25 02:16:38 [INFO]: Epoch 003 - training loss: 0.7198, validation loss: 0.0649
2024-05-25 02:16:44 [INFO]: Epoch 004 - training loss: 0.6542, validation loss: 0.0463
2024-05-25 02:16:50 [INFO]: Epoch 005 - training loss: 0.6135, validation loss: 0.0435
2024-05-25 02:16:56 [INFO]: Epoch 006 - training loss: 0.5824, validation loss: 0.0393
2024-05-25 02:17:02 [INFO]: Epoch 007 - training loss: 0.5572, validation loss: 0.0365
2024-05-25 02:17:08 [INFO]: Epoch 008 - training loss: 0.5309, validation loss: 0.0354
2024-05-25 02:17:14 [INFO]: Epoch 009 - training loss: 0.5127, validation loss: 0.0346
2024-05-25 02:17:20 [INFO]: Epoch 010 - training loss: 0.5055, validation loss: 0.0324
2024-05-25 02:17:26 [INFO]: Epoch 011 - training loss: 0.4769, validation loss: 0.0328
2024-05-25 02:17:32 [INFO]: Epoch 012 - training loss: 0.4668, validation loss: 0.0299
2024-05-25 02:17:38 [INFO]: Epoch 013 - training loss: 0.4457, validation loss: 0.0300
2024-05-25 02:17:44 [INFO]: Epoch 014 - training loss: 0.4373, validation loss: 0.0289
2024-05-25 02:17:50 [INFO]: Epoch 015 - training loss: 0.4208, validation loss: 0.0279
2024-05-25 02:17:56 [INFO]: Epoch 016 - training loss: 0.4249, validation loss: 0.0277
2024-05-25 02:18:02 [INFO]: Epoch 017 - training loss: 0.4102, validation loss: 0.0269
2024-05-25 02:18:08 [INFO]: Epoch 018 - training loss: 0.4079, validation loss: 0.0270
2024-05-25 02:18:14 [INFO]: Epoch 019 - training loss: 0.4096, validation loss: 0.0262
2024-05-25 02:18:20 [INFO]: Epoch 020 - training loss: 0.4145, validation loss: 0.0259
2024-05-25 02:18:26 [INFO]: Epoch 021 - training loss: 0.4020, validation loss: 0.0265
2024-05-25 02:18:32 [INFO]: Epoch 022 - training loss: 0.4035, validation loss: 0.0258
2024-05-25 02:18:38 [INFO]: Epoch 023 - training loss: 0.4082, validation loss: 0.0257
2024-05-25 02:18:44 [INFO]: Epoch 024 - training loss: 0.4142, validation loss: 0.0306
2024-05-25 02:18:50 [INFO]: Epoch 025 - training loss: 0.4236, validation loss: 0.0260
2024-05-25 02:18:55 [INFO]: Epoch 026 - training loss: 0.4089, validation loss: 0.0264
2024-05-25 02:19:01 [INFO]: Epoch 027 - training loss: 0.3936, validation loss: 0.0264
2024-05-25 02:19:07 [INFO]: Epoch 028 - training loss: 0.4098, validation loss: 0.0260
2024-05-25 02:19:13 [INFO]: Epoch 029 - training loss: 0.4002, validation loss: 0.0260
2024-05-25 02:19:19 [INFO]: Epoch 030 - training loss: 0.3959, validation loss: 0.0260
2024-05-25 02:19:25 [INFO]: Epoch 031 - training loss: 0.3938, validation loss: 0.0256
2024-05-25 02:19:31 [INFO]: Epoch 032 - training loss: 0.3962, validation loss: 0.0265
2024-05-25 02:19:37 [INFO]: Epoch 033 - training loss: 0.3977, validation loss: 0.0256
2024-05-25 02:19:43 [INFO]: Epoch 034 - training loss: 0.4033, validation loss: 0.0260
2024-05-25 02:19:49 [INFO]: Epoch 035 - training loss: 0.3939, validation loss: 0.0256
2024-05-25 02:19:55 [INFO]: Epoch 036 - training loss: 0.3908, validation loss: 0.0253
2024-05-25 02:20:01 [INFO]: Epoch 037 - training loss: 0.3926, validation loss: 0.0254
2024-05-25 02:20:07 [INFO]: Epoch 038 - training loss: 0.3864, validation loss: 0.0249
2024-05-25 02:20:13 [INFO]: Epoch 039 - training loss: 0.3932, validation loss: 0.0251
2024-05-25 02:20:18 [INFO]: Epoch 040 - training loss: 0.4050, validation loss: 0.0257
2024-05-25 02:20:24 [INFO]: Epoch 041 - training loss: 0.3984, validation loss: 0.0259
2024-05-25 02:20:30 [INFO]: Epoch 042 - training loss: 0.3982, validation loss: 0.0255
2024-05-25 02:20:36 [INFO]: Epoch 043 - training loss: 0.3844, validation loss: 0.0254
2024-05-25 02:20:42 [INFO]: Epoch 044 - training loss: 0.3871, validation loss: 0.0245
2024-05-25 02:20:48 [INFO]: Epoch 045 - training loss: 0.3870, validation loss: 0.0255
2024-05-25 02:20:54 [INFO]: Epoch 046 - training loss: 0.3898, validation loss: 0.0255
2024-05-25 02:21:00 [INFO]: Epoch 047 - training loss: 0.3973, validation loss: 0.0258
2024-05-25 02:21:06 [INFO]: Epoch 048 - training loss: 0.3870, validation loss: 0.0262
2024-05-25 02:21:12 [INFO]: Epoch 049 - training loss: 0.3876, validation loss: 0.0256
2024-05-25 02:21:18 [INFO]: Epoch 050 - training loss: 0.3876, validation loss: 0.0255
2024-05-25 02:21:24 [INFO]: Epoch 051 - training loss: 0.3875, validation loss: 0.0251
2024-05-25 02:21:30 [INFO]: Epoch 052 - training loss: 0.3846, validation loss: 0.0255
2024-05-25 02:21:36 [INFO]: Epoch 053 - training loss: 0.3888, validation loss: 0.0258
2024-05-25 02:21:42 [INFO]: Epoch 054 - training loss: 0.4003, validation loss: 0.0266
2024-05-25 02:21:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:21:42 [INFO]: Finished training. The best model is from epoch#44.
2024-05-25 02:21:42 [INFO]: Saved the model to augmentation_saved_results/round_2/BRITS_ettm1/20240525_T021619/BRITS.pypots
2024-05-25 02:21:43 [INFO]: BRITS on ETTm1: MAE=0.1513, MSE=0.0657
2024-05-25 02:21:43 [INFO]: Successfully saved to augmentation_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-25 02:21:43 [INFO]: Using the given device: cuda:0
2024-05-25 02:21:43 [INFO]: Model files will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143
2024-05-25 02:21:43 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/tensorboard
2024-05-25 02:21:43 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 02:21:44 [INFO]: Epoch 001 - training loss: 1.3723, validation loss: 1.2775
2024-05-25 02:21:44 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch1_loss1.2775095105171204.pypots
2024-05-25 02:21:45 [INFO]: Epoch 002 - training loss: 0.9892, validation loss: 1.1455
2024-05-25 02:21:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch2_loss1.1455198377370834.pypots
2024-05-25 02:21:45 [INFO]: Epoch 003 - training loss: 0.9079, validation loss: 1.0885
2024-05-25 02:21:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch3_loss1.0885036885738373.pypots
2024-05-25 02:21:45 [INFO]: Epoch 004 - training loss: 0.8910, validation loss: 1.0694
2024-05-25 02:21:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch4_loss1.069401040673256.pypots
2024-05-25 02:21:45 [INFO]: Epoch 005 - training loss: 0.8848, validation loss: 1.0661
2024-05-25 02:21:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch5_loss1.066094920039177.pypots
2024-05-25 02:21:45 [INFO]: Epoch 006 - training loss: 0.8412, validation loss: 1.0624
2024-05-25 02:21:45 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch6_loss1.0624259114265442.pypots
2024-05-25 02:21:46 [INFO]: Epoch 007 - training loss: 0.8341, validation loss: 1.0526
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch7_loss1.0526375025510788.pypots
2024-05-25 02:21:46 [INFO]: Epoch 008 - training loss: 0.8515, validation loss: 1.0453
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch8_loss1.0452578216791153.pypots
2024-05-25 02:21:46 [INFO]: Epoch 009 - training loss: 0.8483, validation loss: 1.0457
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch9_loss1.0456591248512268.pypots
2024-05-25 02:21:46 [INFO]: Epoch 010 - training loss: 0.8166, validation loss: 1.0474
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch10_loss1.0473515689373016.pypots
2024-05-25 02:21:46 [INFO]: Epoch 011 - training loss: 0.8353, validation loss: 1.0445
2024-05-25 02:21:46 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch11_loss1.0444998294115067.pypots
2024-05-25 02:21:47 [INFO]: Epoch 012 - training loss: 0.8296, validation loss: 1.0431
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch12_loss1.04311902821064.pypots
2024-05-25 02:21:47 [INFO]: Epoch 013 - training loss: 0.8285, validation loss: 1.0349
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch13_loss1.0349397212266922.pypots
2024-05-25 02:21:47 [INFO]: Epoch 014 - training loss: 0.8348, validation loss: 1.0345
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch14_loss1.034547969698906.pypots
2024-05-25 02:21:47 [INFO]: Epoch 015 - training loss: 0.8189, validation loss: 1.0298
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch15_loss1.0297795236110687.pypots
2024-05-25 02:21:47 [INFO]: Epoch 016 - training loss: 0.8438, validation loss: 1.0202
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch16_loss1.0201531648635864.pypots
2024-05-25 02:21:47 [INFO]: Epoch 017 - training loss: 0.8014, validation loss: 1.0184
2024-05-25 02:21:47 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch17_loss1.0184122025966644.pypots
2024-05-25 02:21:48 [INFO]: Epoch 018 - training loss: 0.8095, validation loss: 1.0138
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch18_loss1.013782560825348.pypots
2024-05-25 02:21:48 [INFO]: Epoch 019 - training loss: 0.8393, validation loss: 1.0100
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch19_loss1.0099744200706482.pypots
2024-05-25 02:21:48 [INFO]: Epoch 020 - training loss: 0.7934, validation loss: 1.0065
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch20_loss1.006500005722046.pypots
2024-05-25 02:21:48 [INFO]: Epoch 021 - training loss: 0.8031, validation loss: 1.0020
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch21_loss1.0019865781068802.pypots
2024-05-25 02:21:48 [INFO]: Epoch 022 - training loss: 0.7793, validation loss: 0.9949
2024-05-25 02:21:48 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch22_loss0.9949149042367935.pypots
2024-05-25 02:21:49 [INFO]: Epoch 023 - training loss: 0.8309, validation loss: 0.9907
2024-05-25 02:21:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch23_loss0.9906788468360901.pypots
2024-05-25 02:21:49 [INFO]: Epoch 024 - training loss: 0.8146, validation loss: 0.9917
2024-05-25 02:21:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch24_loss0.9916732758283615.pypots
2024-05-25 02:21:49 [INFO]: Epoch 025 - training loss: 0.7701, validation loss: 0.9870
2024-05-25 02:21:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch25_loss0.9870122224092484.pypots
2024-05-25 02:21:49 [INFO]: Epoch 026 - training loss: 0.7805, validation loss: 0.9853
2024-05-25 02:21:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch26_loss0.9852836579084396.pypots
2024-05-25 02:21:49 [INFO]: Epoch 027 - training loss: 0.8209, validation loss: 0.9799
2024-05-25 02:21:49 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch27_loss0.9798548221588135.pypots
2024-05-25 02:21:50 [INFO]: Epoch 028 - training loss: 0.7717, validation loss: 0.9789
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch28_loss0.9788850694894791.pypots
2024-05-25 02:21:50 [INFO]: Epoch 029 - training loss: 0.7670, validation loss: 0.9767
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch29_loss0.9767194539308548.pypots
2024-05-25 02:21:50 [INFO]: Epoch 030 - training loss: 0.7835, validation loss: 0.9694
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch30_loss0.9694095999002457.pypots
2024-05-25 02:21:50 [INFO]: Epoch 031 - training loss: 0.7756, validation loss: 0.9715
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch31_loss0.9715125560760498.pypots
2024-05-25 02:21:50 [INFO]: Epoch 032 - training loss: 0.7606, validation loss: 0.9665
2024-05-25 02:21:50 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch32_loss0.9664869755506516.pypots
2024-05-25 02:21:51 [INFO]: Epoch 033 - training loss: 0.7494, validation loss: 0.9667
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch33_loss0.9666598588228226.pypots
2024-05-25 02:21:51 [INFO]: Epoch 034 - training loss: 0.7478, validation loss: 0.9637
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch34_loss0.9636985957622528.pypots
2024-05-25 02:21:51 [INFO]: Epoch 035 - training loss: 0.7661, validation loss: 0.9621
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch35_loss0.9620944559574127.pypots
2024-05-25 02:21:51 [INFO]: Epoch 036 - training loss: 0.7741, validation loss: 0.9580
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch36_loss0.9580287039279938.pypots
2024-05-25 02:21:51 [INFO]: Epoch 037 - training loss: 0.7560, validation loss: 0.9567
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch37_loss0.956689864397049.pypots
2024-05-25 02:21:51 [INFO]: Epoch 038 - training loss: 0.7503, validation loss: 0.9562
2024-05-25 02:21:51 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch38_loss0.9562294185161591.pypots
2024-05-25 02:21:52 [INFO]: Epoch 039 - training loss: 0.7574, validation loss: 0.9555
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch39_loss0.9555038958787918.pypots
2024-05-25 02:21:52 [INFO]: Epoch 040 - training loss: 0.7627, validation loss: 0.9517
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch40_loss0.9517374336719513.pypots
2024-05-25 02:21:52 [INFO]: Epoch 041 - training loss: 0.7597, validation loss: 0.9501
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch41_loss0.9501090943813324.pypots
2024-05-25 02:21:52 [INFO]: Epoch 042 - training loss: 0.7568, validation loss: 0.9468
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch42_loss0.9468429386615753.pypots
2024-05-25 02:21:52 [INFO]: Epoch 043 - training loss: 0.7407, validation loss: 0.9461
2024-05-25 02:21:52 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch43_loss0.9461492300033569.pypots
2024-05-25 02:21:53 [INFO]: Epoch 044 - training loss: 0.7495, validation loss: 0.9445
2024-05-25 02:21:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch44_loss0.9445434808731079.pypots
2024-05-25 02:21:53 [INFO]: Epoch 045 - training loss: 0.7447, validation loss: 0.9412
2024-05-25 02:21:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch45_loss0.9412244558334351.pypots
2024-05-25 02:21:53 [INFO]: Epoch 046 - training loss: 0.7499, validation loss: 0.9399
2024-05-25 02:21:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch46_loss0.9399100095033646.pypots
2024-05-25 02:21:53 [INFO]: Epoch 047 - training loss: 0.7355, validation loss: 0.9390
2024-05-25 02:21:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch47_loss0.9390078186988831.pypots
2024-05-25 02:21:53 [INFO]: Epoch 048 - training loss: 0.7551, validation loss: 0.9407
2024-05-25 02:21:53 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch48_loss0.9406922161579132.pypots
2024-05-25 02:21:54 [INFO]: Epoch 049 - training loss: 0.7649, validation loss: 0.9401
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch49_loss0.9401416927576065.pypots
2024-05-25 02:21:54 [INFO]: Epoch 050 - training loss: 0.7496, validation loss: 0.9353
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch50_loss0.9352926164865494.pypots
2024-05-25 02:21:54 [INFO]: Epoch 051 - training loss: 0.7399, validation loss: 0.9358
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch51_loss0.9357787370681763.pypots
2024-05-25 02:21:54 [INFO]: Epoch 052 - training loss: 0.7415, validation loss: 0.9337
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch52_loss0.9336621016263962.pypots
2024-05-25 02:21:54 [INFO]: Epoch 053 - training loss: 0.7603, validation loss: 0.9323
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch53_loss0.932291105389595.pypots
2024-05-25 02:21:54 [INFO]: Epoch 054 - training loss: 0.7386, validation loss: 0.9300
2024-05-25 02:21:54 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch54_loss0.9299581050872803.pypots
2024-05-25 02:21:55 [INFO]: Epoch 055 - training loss: 0.7501, validation loss: 0.9308
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch55_loss0.9307880848646164.pypots
2024-05-25 02:21:55 [INFO]: Epoch 056 - training loss: 0.7184, validation loss: 0.9306
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch56_loss0.9305507093667984.pypots
2024-05-25 02:21:55 [INFO]: Epoch 057 - training loss: 0.7298, validation loss: 0.9281
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch57_loss0.9280691146850586.pypots
2024-05-25 02:21:55 [INFO]: Epoch 058 - training loss: 0.7177, validation loss: 0.9294
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch58_loss0.9294082969427109.pypots
2024-05-25 02:21:55 [INFO]: Epoch 059 - training loss: 0.7449, validation loss: 0.9307
2024-05-25 02:21:55 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch59_loss0.9306857287883759.pypots
2024-05-25 02:21:56 [INFO]: Epoch 060 - training loss: 0.7840, validation loss: 0.9292
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch60_loss0.9291684627532959.pypots
2024-05-25 02:21:56 [INFO]: Epoch 061 - training loss: 0.7478, validation loss: 0.9269
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch61_loss0.9268940687179565.pypots
2024-05-25 02:21:56 [INFO]: Epoch 062 - training loss: 0.7371, validation loss: 0.9283
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch62_loss0.928344264626503.pypots
2024-05-25 02:21:56 [INFO]: Epoch 063 - training loss: 0.7245, validation loss: 0.9275
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch63_loss0.9274565875530243.pypots
2024-05-25 02:21:56 [INFO]: Epoch 064 - training loss: 0.7438, validation loss: 0.9252
2024-05-25 02:21:56 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch64_loss0.9252455234527588.pypots
2024-05-25 02:21:57 [INFO]: Epoch 065 - training loss: 0.7232, validation loss: 0.9274
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch65_loss0.9273973554372787.pypots
2024-05-25 02:21:57 [INFO]: Epoch 066 - training loss: 0.7548, validation loss: 0.9271
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch66_loss0.9270987659692764.pypots
2024-05-25 02:21:57 [INFO]: Epoch 067 - training loss: 0.7500, validation loss: 0.9243
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch67_loss0.9242568165063858.pypots
2024-05-25 02:21:57 [INFO]: Epoch 068 - training loss: 0.7360, validation loss: 0.9262
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch68_loss0.9261820465326309.pypots
2024-05-25 02:21:57 [INFO]: Epoch 069 - training loss: 0.7786, validation loss: 0.9255
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch69_loss0.9254563450813293.pypots
2024-05-25 02:21:57 [INFO]: Epoch 070 - training loss: 0.7633, validation loss: 0.9274
2024-05-25 02:21:57 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch70_loss0.927355945110321.pypots
2024-05-25 02:21:58 [INFO]: Epoch 071 - training loss: 0.7420, validation loss: 0.9257
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch71_loss0.9256648868322372.pypots
2024-05-25 02:21:58 [INFO]: Epoch 072 - training loss: 0.7296, validation loss: 0.9261
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch72_loss0.926068440079689.pypots
2024-05-25 02:21:58 [INFO]: Epoch 073 - training loss: 0.7479, validation loss: 0.9276
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch73_loss0.9275804758071899.pypots
2024-05-25 02:21:58 [INFO]: Epoch 074 - training loss: 0.7230, validation loss: 0.9267
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch74_loss0.9267251044511795.pypots
2024-05-25 02:21:58 [INFO]: Epoch 075 - training loss: 0.7293, validation loss: 0.9276
2024-05-25 02:21:58 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch75_loss0.927601233124733.pypots
2024-05-25 02:21:59 [INFO]: Epoch 076 - training loss: 0.7224, validation loss: 0.9248
2024-05-25 02:21:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch76_loss0.9248419404029846.pypots
2024-05-25 02:21:59 [INFO]: Epoch 077 - training loss: 0.7170, validation loss: 0.9248
2024-05-25 02:21:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN_epoch77_loss0.9247974008321762.pypots
2024-05-25 02:21:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:21:59 [INFO]: Finished training. The best model is from epoch#67.
2024-05-25 02:21:59 [INFO]: Saved the model to augmentation_saved_results/round_2/MRNN_ettm1/20240525_T022143/MRNN.pypots
2024-05-25 02:21:59 [INFO]: MRNN on ETTm1: MAE=0.8094, MSE=1.4658
2024-05-25 02:21:59 [INFO]: Successfully saved to augmentation_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-25 02:21:59 [INFO]: Using the given device: cpu
2024-05-25 02:21:59 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-25 02:21:59 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-25 02:21:59 [INFO]: Successfully saved to augmentation_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-25 02:21:59 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-25 02:21:59 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-25 02:21:59 [INFO]: Successfully saved to augmentation_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-25 02:21:59 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-25 02:21:59 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-25 02:21:59 [INFO]: Successfully saved to augmentation_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-25 02:21:59 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 02:21:59 [INFO]: Using the given device: cuda:0
2024-05-25 02:21:59 [INFO]: Model files will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T022159
2024-05-25 02:21:59 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T022159/tensorboard
2024-05-25 02:21:59 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 02:22:00 [INFO]: Epoch 001 - training loss: 1.2316, validation loss: 0.3797
2024-05-25 02:22:00 [INFO]: Epoch 002 - training loss: 0.9199, validation loss: 0.1867
2024-05-25 02:22:01 [INFO]: Epoch 003 - training loss: 0.7879, validation loss: 0.1254
2024-05-25 02:22:01 [INFO]: Epoch 004 - training loss: 0.7254, validation loss: 0.1457
2024-05-25 02:22:02 [INFO]: Epoch 005 - training loss: 0.6950, validation loss: 0.0862
2024-05-25 02:22:02 [INFO]: Epoch 006 - training loss: 0.6846, validation loss: 0.0974
2024-05-25 02:22:03 [INFO]: Epoch 007 - training loss: 0.6717, validation loss: 0.0886
2024-05-25 02:22:03 [INFO]: Epoch 008 - training loss: 0.6410, validation loss: 0.0927
2024-05-25 02:22:04 [INFO]: Epoch 009 - training loss: 0.6251, validation loss: 0.0907
2024-05-25 02:22:04 [INFO]: Epoch 010 - training loss: 0.6220, validation loss: 0.0947
2024-05-25 02:22:05 [INFO]: Epoch 011 - training loss: 0.6042, validation loss: 0.0985
2024-05-25 02:22:05 [INFO]: Epoch 012 - training loss: 0.5928, validation loss: 0.0789
2024-05-25 02:22:06 [INFO]: Epoch 013 - training loss: 0.5847, validation loss: 0.0609
2024-05-25 02:22:06 [INFO]: Epoch 014 - training loss: 0.5847, validation loss: 0.0957
2024-05-25 02:22:07 [INFO]: Epoch 015 - training loss: 0.5745, validation loss: 0.0686
2024-05-25 02:22:07 [INFO]: Epoch 016 - training loss: 0.5614, validation loss: 0.0660
2024-05-25 02:22:08 [INFO]: Epoch 017 - training loss: 0.5602, validation loss: 0.0749
2024-05-25 02:22:08 [INFO]: Epoch 018 - training loss: 0.5673, validation loss: 0.0658
2024-05-25 02:22:09 [INFO]: Epoch 019 - training loss: 0.5478, validation loss: 0.0552
2024-05-25 02:22:10 [INFO]: Epoch 020 - training loss: 0.5565, validation loss: 0.0649
2024-05-25 02:22:10 [INFO]: Epoch 021 - training loss: 0.5496, validation loss: 0.0703
2024-05-25 02:22:11 [INFO]: Epoch 022 - training loss: 0.5292, validation loss: 0.0726
2024-05-25 02:22:11 [INFO]: Epoch 023 - training loss: 0.5266, validation loss: 0.0651
2024-05-25 02:22:12 [INFO]: Epoch 024 - training loss: 0.5268, validation loss: 0.0625
2024-05-25 02:22:12 [INFO]: Epoch 025 - training loss: 0.5115, validation loss: 0.0579
2024-05-25 02:22:13 [INFO]: Epoch 026 - training loss: 0.5138, validation loss: 0.0678
2024-05-25 02:22:13 [INFO]: Epoch 027 - training loss: 0.5056, validation loss: 0.0516
2024-05-25 02:22:14 [INFO]: Epoch 028 - training loss: 0.5038, validation loss: 0.0583
2024-05-25 02:22:14 [INFO]: Epoch 029 - training loss: 0.4957, validation loss: 0.0448
2024-05-25 02:22:15 [INFO]: Epoch 030 - training loss: 0.5166, validation loss: 0.0642
2024-05-25 02:22:15 [INFO]: Epoch 031 - training loss: 0.5053, validation loss: 0.0438
2024-05-25 02:22:16 [INFO]: Epoch 032 - training loss: 0.5043, validation loss: 0.0680
2024-05-25 02:22:16 [INFO]: Epoch 033 - training loss: 0.5041, validation loss: 0.0567
2024-05-25 02:22:17 [INFO]: Epoch 034 - training loss: 0.4859, validation loss: 0.0464
2024-05-25 02:22:17 [INFO]: Epoch 035 - training loss: 0.4741, validation loss: 0.0476
2024-05-25 02:22:18 [INFO]: Epoch 036 - training loss: 0.4705, validation loss: 0.0487
2024-05-25 02:22:18 [INFO]: Epoch 037 - training loss: 0.4601, validation loss: 0.0478
2024-05-25 02:22:19 [INFO]: Epoch 038 - training loss: 0.4658, validation loss: 0.0452
2024-05-25 02:22:19 [INFO]: Epoch 039 - training loss: 0.4521, validation loss: 0.0473
2024-05-25 02:22:20 [INFO]: Epoch 040 - training loss: 0.4577, validation loss: 0.0551
2024-05-25 02:22:20 [INFO]: Epoch 041 - training loss: 0.4509, validation loss: 0.0507
2024-05-25 02:22:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:22:20 [INFO]: Finished training. The best model is from epoch#31.
2024-05-25 02:22:20 [INFO]: Saved the model to augmentation_saved_results/round_3/SAITS_ettm1/20240525_T022159/SAITS.pypots
2024-05-25 02:22:20 [INFO]: SAITS on ETTm1: MAE=0.1742, MSE=0.0570
2024-05-25 02:22:20 [INFO]: Successfully saved to augmentation_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-25 02:22:20 [INFO]: Using the given device: cuda:0
2024-05-25 02:22:20 [INFO]: Model files will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T022220
2024-05-25 02:22:20 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T022220/tensorboard
2024-05-25 02:22:20 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 02:22:21 [INFO]: Epoch 001 - training loss: 1.2191, validation loss: 0.4237
2024-05-25 02:22:21 [INFO]: Epoch 002 - training loss: 0.7784, validation loss: 0.1899
2024-05-25 02:22:21 [INFO]: Epoch 003 - training loss: 0.6378, validation loss: 0.1290
2024-05-25 02:22:21 [INFO]: Epoch 004 - training loss: 0.5533, validation loss: 0.0991
2024-05-25 02:22:21 [INFO]: Epoch 005 - training loss: 0.5033, validation loss: 0.0862
2024-05-25 02:22:22 [INFO]: Epoch 006 - training loss: 0.4751, validation loss: 0.0819
2024-05-25 02:22:22 [INFO]: Epoch 007 - training loss: 0.4542, validation loss: 0.0721
2024-05-25 02:22:22 [INFO]: Epoch 008 - training loss: 0.4321, validation loss: 0.0719
2024-05-25 02:22:22 [INFO]: Epoch 009 - training loss: 0.4362, validation loss: 0.0676
2024-05-25 02:22:23 [INFO]: Epoch 010 - training loss: 0.4135, validation loss: 0.0631
2024-05-25 02:22:23 [INFO]: Epoch 011 - training loss: 0.4027, validation loss: 0.0664
2024-05-25 02:22:23 [INFO]: Epoch 012 - training loss: 0.3921, validation loss: 0.0563
2024-05-25 02:22:23 [INFO]: Epoch 013 - training loss: 0.3851, validation loss: 0.0585
2024-05-25 02:22:23 [INFO]: Epoch 014 - training loss: 0.3737, validation loss: 0.0554
2024-05-25 02:22:24 [INFO]: Epoch 015 - training loss: 0.3692, validation loss: 0.0603
2024-05-25 02:22:24 [INFO]: Epoch 016 - training loss: 0.3597, validation loss: 0.0524
2024-05-25 02:22:24 [INFO]: Epoch 017 - training loss: 0.3497, validation loss: 0.0533
2024-05-25 02:22:24 [INFO]: Epoch 018 - training loss: 0.3464, validation loss: 0.0536
2024-05-25 02:22:25 [INFO]: Epoch 019 - training loss: 0.3439, validation loss: 0.0471
2024-05-25 02:22:25 [INFO]: Epoch 020 - training loss: 0.3364, validation loss: 0.0484
2024-05-25 02:22:25 [INFO]: Epoch 021 - training loss: 0.3300, validation loss: 0.0479
2024-05-25 02:22:25 [INFO]: Epoch 022 - training loss: 0.3338, validation loss: 0.0432
2024-05-25 02:22:25 [INFO]: Epoch 023 - training loss: 0.3244, validation loss: 0.0448
2024-05-25 02:22:26 [INFO]: Epoch 024 - training loss: 0.3171, validation loss: 0.0453
2024-05-25 02:22:26 [INFO]: Epoch 025 - training loss: 0.3185, validation loss: 0.0447
2024-05-25 02:22:26 [INFO]: Epoch 026 - training loss: 0.3132, validation loss: 0.0484
2024-05-25 02:22:26 [INFO]: Epoch 027 - training loss: 0.3118, validation loss: 0.0413
2024-05-25 02:22:26 [INFO]: Epoch 028 - training loss: 0.3058, validation loss: 0.0373
2024-05-25 02:22:27 [INFO]: Epoch 029 - training loss: 0.2976, validation loss: 0.0432
2024-05-25 02:22:27 [INFO]: Epoch 030 - training loss: 0.3002, validation loss: 0.0437
2024-05-25 02:22:27 [INFO]: Epoch 031 - training loss: 0.3055, validation loss: 0.0394
2024-05-25 02:22:27 [INFO]: Epoch 032 - training loss: 0.3076, validation loss: 0.0466
2024-05-25 02:22:28 [INFO]: Epoch 033 - training loss: 0.3000, validation loss: 0.0353
2024-05-25 02:22:28 [INFO]: Epoch 034 - training loss: 0.2887, validation loss: 0.0343
2024-05-25 02:22:28 [INFO]: Epoch 035 - training loss: 0.2876, validation loss: 0.0380
2024-05-25 02:22:28 [INFO]: Epoch 036 - training loss: 0.2947, validation loss: 0.0347
2024-05-25 02:22:28 [INFO]: Epoch 037 - training loss: 0.2808, validation loss: 0.0396
2024-05-25 02:22:29 [INFO]: Epoch 038 - training loss: 0.2823, validation loss: 0.0417
2024-05-25 02:22:29 [INFO]: Epoch 039 - training loss: 0.2793, validation loss: 0.0323
2024-05-25 02:22:29 [INFO]: Epoch 040 - training loss: 0.2715, validation loss: 0.0348
2024-05-25 02:22:29 [INFO]: Epoch 041 - training loss: 0.2709, validation loss: 0.0393
2024-05-25 02:22:30 [INFO]: Epoch 042 - training loss: 0.2693, validation loss: 0.0424
2024-05-25 02:22:30 [INFO]: Epoch 043 - training loss: 0.2822, validation loss: 0.0373
2024-05-25 02:22:30 [INFO]: Epoch 044 - training loss: 0.2706, validation loss: 0.0309
2024-05-25 02:22:30 [INFO]: Epoch 045 - training loss: 0.2721, validation loss: 0.0322
2024-05-25 02:22:30 [INFO]: Epoch 046 - training loss: 0.2715, validation loss: 0.0328
2024-05-25 02:22:31 [INFO]: Epoch 047 - training loss: 0.2613, validation loss: 0.0317
2024-05-25 02:22:31 [INFO]: Epoch 048 - training loss: 0.2635, validation loss: 0.0305
2024-05-25 02:22:31 [INFO]: Epoch 049 - training loss: 0.2503, validation loss: 0.0298
2024-05-25 02:22:31 [INFO]: Epoch 050 - training loss: 0.2458, validation loss: 0.0289
2024-05-25 02:22:31 [INFO]: Epoch 051 - training loss: 0.2471, validation loss: 0.0304
2024-05-25 02:22:32 [INFO]: Epoch 052 - training loss: 0.2582, validation loss: 0.0299
2024-05-25 02:22:32 [INFO]: Epoch 053 - training loss: 0.2482, validation loss: 0.0291
2024-05-25 02:22:32 [INFO]: Epoch 054 - training loss: 0.2423, validation loss: 0.0280
2024-05-25 02:22:32 [INFO]: Epoch 055 - training loss: 0.2433, validation loss: 0.0318
2024-05-25 02:22:33 [INFO]: Epoch 056 - training loss: 0.2388, validation loss: 0.0280
2024-05-25 02:22:33 [INFO]: Epoch 057 - training loss: 0.2396, validation loss: 0.0300
2024-05-25 02:22:33 [INFO]: Epoch 058 - training loss: 0.2448, validation loss: 0.0305
2024-05-25 02:22:33 [INFO]: Epoch 059 - training loss: 0.2372, validation loss: 0.0289
2024-05-25 02:22:33 [INFO]: Epoch 060 - training loss: 0.2351, validation loss: 0.0268
2024-05-25 02:22:34 [INFO]: Epoch 061 - training loss: 0.2386, validation loss: 0.0253
2024-05-25 02:22:34 [INFO]: Epoch 062 - training loss: 0.2296, validation loss: 0.0256
2024-05-25 02:22:34 [INFO]: Epoch 063 - training loss: 0.2326, validation loss: 0.0296
2024-05-25 02:22:34 [INFO]: Epoch 064 - training loss: 0.2301, validation loss: 0.0263
2024-05-25 02:22:35 [INFO]: Epoch 065 - training loss: 0.2271, validation loss: 0.0266
2024-05-25 02:22:35 [INFO]: Epoch 066 - training loss: 0.2316, validation loss: 0.0278
2024-05-25 02:22:35 [INFO]: Epoch 067 - training loss: 0.2287, validation loss: 0.0329
2024-05-25 02:22:35 [INFO]: Epoch 068 - training loss: 0.2319, validation loss: 0.0244
2024-05-25 02:22:35 [INFO]: Epoch 069 - training loss: 0.2271, validation loss: 0.0261
2024-05-25 02:22:36 [INFO]: Epoch 070 - training loss: 0.2258, validation loss: 0.0253
2024-05-25 02:22:36 [INFO]: Epoch 071 - training loss: 0.2201, validation loss: 0.0255
2024-05-25 02:22:36 [INFO]: Epoch 072 - training loss: 0.2329, validation loss: 0.0304
2024-05-25 02:22:36 [INFO]: Epoch 073 - training loss: 0.2279, validation loss: 0.0259
2024-05-25 02:22:36 [INFO]: Epoch 074 - training loss: 0.2270, validation loss: 0.0242
2024-05-25 02:22:37 [INFO]: Epoch 075 - training loss: 0.2197, validation loss: 0.0252
2024-05-25 02:22:37 [INFO]: Epoch 076 - training loss: 0.2218, validation loss: 0.0268
2024-05-25 02:22:37 [INFO]: Epoch 077 - training loss: 0.2235, validation loss: 0.0261
2024-05-25 02:22:37 [INFO]: Epoch 078 - training loss: 0.2187, validation loss: 0.0253
2024-05-25 02:22:38 [INFO]: Epoch 079 - training loss: 0.2162, validation loss: 0.0249
2024-05-25 02:22:38 [INFO]: Epoch 080 - training loss: 0.2150, validation loss: 0.0254
2024-05-25 02:22:38 [INFO]: Epoch 081 - training loss: 0.2149, validation loss: 0.0251
2024-05-25 02:22:38 [INFO]: Epoch 082 - training loss: 0.2143, validation loss: 0.0255
2024-05-25 02:22:38 [INFO]: Epoch 083 - training loss: 0.2141, validation loss: 0.0243
2024-05-25 02:22:39 [INFO]: Epoch 084 - training loss: 0.2139, validation loss: 0.0262
2024-05-25 02:22:39 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:22:39 [INFO]: Finished training. The best model is from epoch#74.
2024-05-25 02:22:39 [INFO]: Saved the model to augmentation_saved_results/round_3/Transformer_ettm1/20240525_T022220/Transformer.pypots
2024-05-25 02:22:39 [INFO]: Transformer on ETTm1: MAE=0.1415, MSE=0.0402
2024-05-25 02:22:39 [INFO]: Successfully saved to augmentation_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-25 02:22:39 [INFO]: Using the given device: cuda:0
2024-05-25 02:22:39 [INFO]: Model files will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T022239
2024-05-25 02:22:39 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T022239/tensorboard
2024-05-25 02:22:39 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 02:22:39 [INFO]: Epoch 001 - training loss: 0.1542, validation loss: 0.0558
2024-05-25 02:22:39 [INFO]: Epoch 002 - training loss: 0.0796, validation loss: 0.0453
2024-05-25 02:22:40 [INFO]: Epoch 003 - training loss: 0.0588, validation loss: 0.0416
2024-05-25 02:22:40 [INFO]: Epoch 004 - training loss: 0.0568, validation loss: 0.0371
2024-05-25 02:22:40 [INFO]: Epoch 005 - training loss: 0.0529, validation loss: 0.0347
2024-05-25 02:22:40 [INFO]: Epoch 006 - training loss: 0.0515, validation loss: 0.0351
2024-05-25 02:22:40 [INFO]: Epoch 007 - training loss: 0.0517, validation loss: 0.0360
2024-05-25 02:22:41 [INFO]: Epoch 008 - training loss: 0.0510, validation loss: 0.0340
2024-05-25 02:22:41 [INFO]: Epoch 009 - training loss: 0.0521, validation loss: 0.0349
2024-05-25 02:22:41 [INFO]: Epoch 010 - training loss: 0.0512, validation loss: 0.0363
2024-05-25 02:22:41 [INFO]: Epoch 011 - training loss: 0.0529, validation loss: 0.0358
2024-05-25 02:22:41 [INFO]: Epoch 012 - training loss: 0.0548, validation loss: 0.0328
2024-05-25 02:22:42 [INFO]: Epoch 013 - training loss: 0.0514, validation loss: 0.0345
2024-05-25 02:22:42 [INFO]: Epoch 014 - training loss: 0.0513, validation loss: 0.0343
2024-05-25 02:22:42 [INFO]: Epoch 015 - training loss: 0.0487, validation loss: 0.0344
2024-05-25 02:22:42 [INFO]: Epoch 016 - training loss: 0.0510, validation loss: 0.0324
2024-05-25 02:22:42 [INFO]: Epoch 017 - training loss: 0.0467, validation loss: 0.0321
2024-05-25 02:22:43 [INFO]: Epoch 018 - training loss: 0.0449, validation loss: 0.0323
2024-05-25 02:22:43 [INFO]: Epoch 019 - training loss: 0.0512, validation loss: 0.0337
2024-05-25 02:22:43 [INFO]: Epoch 020 - training loss: 0.0480, validation loss: 0.0358
2024-05-25 02:22:43 [INFO]: Epoch 021 - training loss: 0.0500, validation loss: 0.0336
2024-05-25 02:22:44 [INFO]: Epoch 022 - training loss: 0.0463, validation loss: 0.0296
2024-05-25 02:22:44 [INFO]: Epoch 023 - training loss: 0.0457, validation loss: 0.0305
2024-05-25 02:22:44 [INFO]: Epoch 024 - training loss: 0.0486, validation loss: 0.0321
2024-05-25 02:22:44 [INFO]: Epoch 025 - training loss: 0.0534, validation loss: 0.0324
2024-05-25 02:22:44 [INFO]: Epoch 026 - training loss: 0.0488, validation loss: 0.0335
2024-05-25 02:22:45 [INFO]: Epoch 027 - training loss: 0.0536, validation loss: 0.0308
2024-05-25 02:22:45 [INFO]: Epoch 028 - training loss: 0.0491, validation loss: 0.0302
2024-05-25 02:22:45 [INFO]: Epoch 029 - training loss: 0.0485, validation loss: 0.0311
2024-05-25 02:22:45 [INFO]: Epoch 030 - training loss: 0.0438, validation loss: 0.0293
2024-05-25 02:22:45 [INFO]: Epoch 031 - training loss: 0.0439, validation loss: 0.0298
2024-05-25 02:22:46 [INFO]: Epoch 032 - training loss: 0.0424, validation loss: 0.0281
2024-05-25 02:22:46 [INFO]: Epoch 033 - training loss: 0.0425, validation loss: 0.0298
2024-05-25 02:22:46 [INFO]: Epoch 034 - training loss: 0.0427, validation loss: 0.0285
2024-05-25 02:22:46 [INFO]: Epoch 035 - training loss: 0.0441, validation loss: 0.0306
2024-05-25 02:22:46 [INFO]: Epoch 036 - training loss: 0.0456, validation loss: 0.0295
2024-05-25 02:22:47 [INFO]: Epoch 037 - training loss: 0.0440, validation loss: 0.0284
2024-05-25 02:22:47 [INFO]: Epoch 038 - training loss: 0.0418, validation loss: 0.0282
2024-05-25 02:22:47 [INFO]: Epoch 039 - training loss: 0.0418, validation loss: 0.0290
2024-05-25 02:22:47 [INFO]: Epoch 040 - training loss: 0.0421, validation loss: 0.0279
2024-05-25 02:22:48 [INFO]: Epoch 041 - training loss: 0.0432, validation loss: 0.0285
2024-05-25 02:22:48 [INFO]: Epoch 042 - training loss: 0.0446, validation loss: 0.0294
2024-05-25 02:22:48 [INFO]: Epoch 043 - training loss: 0.0441, validation loss: 0.0283
2024-05-25 02:22:48 [INFO]: Epoch 044 - training loss: 0.0423, validation loss: 0.0281
2024-05-25 02:22:48 [INFO]: Epoch 045 - training loss: 0.0398, validation loss: 0.0288
2024-05-25 02:22:49 [INFO]: Epoch 046 - training loss: 0.0408, validation loss: 0.0277
2024-05-25 02:22:49 [INFO]: Epoch 047 - training loss: 0.0419, validation loss: 0.0280
2024-05-25 02:22:49 [INFO]: Epoch 048 - training loss: 0.0398, validation loss: 0.0292
2024-05-25 02:22:49 [INFO]: Epoch 049 - training loss: 0.0413, validation loss: 0.0301
2024-05-25 02:22:49 [INFO]: Epoch 050 - training loss: 0.0445, validation loss: 0.0293
2024-05-25 02:22:50 [INFO]: Epoch 051 - training loss: 0.0409, validation loss: 0.0285
2024-05-25 02:22:50 [INFO]: Epoch 052 - training loss: 0.0386, validation loss: 0.0272
2024-05-25 02:22:50 [INFO]: Epoch 053 - training loss: 0.0422, validation loss: 0.0283
2024-05-25 02:22:50 [INFO]: Epoch 054 - training loss: 0.0418, validation loss: 0.0301
2024-05-25 02:22:50 [INFO]: Epoch 055 - training loss: 0.0387, validation loss: 0.0271
2024-05-25 02:22:51 [INFO]: Epoch 056 - training loss: 0.0390, validation loss: 0.0258
2024-05-25 02:22:51 [INFO]: Epoch 057 - training loss: 0.0414, validation loss: 0.0321
2024-05-25 02:22:51 [INFO]: Epoch 058 - training loss: 0.0446, validation loss: 0.0275
2024-05-25 02:22:51 [INFO]: Epoch 059 - training loss: 0.0406, validation loss: 0.0279
2024-05-25 02:22:51 [INFO]: Epoch 060 - training loss: 0.0404, validation loss: 0.0290
2024-05-25 02:22:52 [INFO]: Epoch 061 - training loss: 0.0403, validation loss: 0.0270
2024-05-25 02:22:52 [INFO]: Epoch 062 - training loss: 0.0377, validation loss: 0.0269
2024-05-25 02:22:52 [INFO]: Epoch 063 - training loss: 0.0383, validation loss: 0.0268
2024-05-25 02:22:52 [INFO]: Epoch 064 - training loss: 0.0377, validation loss: 0.0267
2024-05-25 02:22:53 [INFO]: Epoch 065 - training loss: 0.0364, validation loss: 0.0275
2024-05-25 02:22:53 [INFO]: Epoch 066 - training loss: 0.0385, validation loss: 0.0271
2024-05-25 02:22:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:22:53 [INFO]: Finished training. The best model is from epoch#56.
2024-05-25 02:22:53 [INFO]: Saved the model to augmentation_saved_results/round_3/TimesNet_ettm1/20240525_T022239/TimesNet.pypots
2024-05-25 02:22:53 [INFO]: TimesNet on ETTm1: MAE=0.1212, MSE=0.0301
2024-05-25 02:22:53 [INFO]: Successfully saved to augmentation_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-25 02:22:53 [INFO]: Using the given device: cuda:0
2024-05-25 02:22:53 [INFO]: Model files will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253
2024-05-25 02:22:53 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/tensorboard
2024-05-25 02:22:53 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 02:22:55 [INFO]: Epoch 001 - training loss: 0.7083, validation loss: 0.5555
2024-05-25 02:22:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch1_loss0.5555073320865631.pypots
2024-05-25 02:22:57 [INFO]: Epoch 002 - training loss: 0.4410, validation loss: 0.4156
2024-05-25 02:22:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch2_loss0.41560371220111847.pypots
2024-05-25 02:22:59 [INFO]: Epoch 003 - training loss: 0.4223, validation loss: 0.3484
2024-05-25 02:22:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch3_loss0.3483881279826164.pypots
2024-05-25 02:23:01 [INFO]: Epoch 004 - training loss: 0.3904, validation loss: 0.3520
2024-05-25 02:23:01 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch4_loss0.35200075805187225.pypots
2024-05-25 02:23:03 [INFO]: Epoch 005 - training loss: 0.2956, validation loss: 0.3345
2024-05-25 02:23:03 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch5_loss0.33451254665851593.pypots
2024-05-25 02:23:05 [INFO]: Epoch 006 - training loss: 0.2590, validation loss: 0.3017
2024-05-25 02:23:05 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch6_loss0.3016635626554489.pypots
2024-05-25 02:23:07 [INFO]: Epoch 007 - training loss: 0.2970, validation loss: 0.3166
2024-05-25 02:23:07 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch7_loss0.3165725991129875.pypots
2024-05-25 02:23:10 [INFO]: Epoch 008 - training loss: 0.2846, validation loss: 0.2821
2024-05-25 02:23:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch8_loss0.2820942550897598.pypots
2024-05-25 02:23:12 [INFO]: Epoch 009 - training loss: 0.2640, validation loss: 0.2606
2024-05-25 02:23:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch9_loss0.26064491271972656.pypots
2024-05-25 02:23:14 [INFO]: Epoch 010 - training loss: 0.2833, validation loss: 0.2920
2024-05-25 02:23:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch10_loss0.29198262095451355.pypots
2024-05-25 02:23:16 [INFO]: Epoch 011 - training loss: 0.3302, validation loss: 0.2542
2024-05-25 02:23:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch11_loss0.2542209327220917.pypots
2024-05-25 02:23:18 [INFO]: Epoch 012 - training loss: 0.2547, validation loss: 0.2555
2024-05-25 02:23:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch12_loss0.2555013746023178.pypots
2024-05-25 02:23:20 [INFO]: Epoch 013 - training loss: 0.2380, validation loss: 0.2604
2024-05-25 02:23:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch13_loss0.26040760427713394.pypots
2024-05-25 02:23:22 [INFO]: Epoch 014 - training loss: 0.2249, validation loss: 0.2426
2024-05-25 02:23:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch14_loss0.2425970919430256.pypots
2024-05-25 02:23:24 [INFO]: Epoch 015 - training loss: 0.2120, validation loss: 0.2415
2024-05-25 02:23:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch15_loss0.24152397736907005.pypots
2024-05-25 02:23:26 [INFO]: Epoch 016 - training loss: 0.2284, validation loss: 0.2458
2024-05-25 02:23:26 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch16_loss0.24577148258686066.pypots
2024-05-25 02:23:28 [INFO]: Epoch 017 - training loss: 0.2201, validation loss: 0.2351
2024-05-25 02:23:28 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch17_loss0.23508478328585625.pypots
2024-05-25 02:23:30 [INFO]: Epoch 018 - training loss: 0.2056, validation loss: 0.2156
2024-05-25 02:23:30 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch18_loss0.21555134281516075.pypots
2024-05-25 02:23:32 [INFO]: Epoch 019 - training loss: 0.2148, validation loss: 0.2231
2024-05-25 02:23:32 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch19_loss0.22306741774082184.pypots
2024-05-25 02:23:34 [INFO]: Epoch 020 - training loss: 0.2217, validation loss: 0.2201
2024-05-25 02:23:34 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch20_loss0.22008681669831276.pypots
2024-05-25 02:23:37 [INFO]: Epoch 021 - training loss: 0.2046, validation loss: 0.2056
2024-05-25 02:23:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch21_loss0.20559586212038994.pypots
2024-05-25 02:23:39 [INFO]: Epoch 022 - training loss: 0.1913, validation loss: 0.2179
2024-05-25 02:23:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch22_loss0.21790750324726105.pypots
2024-05-25 02:23:41 [INFO]: Epoch 023 - training loss: 0.2098, validation loss: 0.2041
2024-05-25 02:23:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch23_loss0.20409220084547997.pypots
2024-05-25 02:23:43 [INFO]: Epoch 024 - training loss: 0.2569, validation loss: 0.2101
2024-05-25 02:23:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch24_loss0.21011628583073616.pypots
2024-05-25 02:23:45 [INFO]: Epoch 025 - training loss: 0.2149, validation loss: 0.2258
2024-05-25 02:23:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch25_loss0.22582296282052994.pypots
2024-05-25 02:23:47 [INFO]: Epoch 026 - training loss: 0.2152, validation loss: 0.1922
2024-05-25 02:23:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch26_loss0.1921502836048603.pypots
2024-05-25 02:23:49 [INFO]: Epoch 027 - training loss: 0.2103, validation loss: 0.1906
2024-05-25 02:23:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch27_loss0.1905982717871666.pypots
2024-05-25 02:23:51 [INFO]: Epoch 028 - training loss: 0.1800, validation loss: 0.1927
2024-05-25 02:23:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch28_loss0.1927185133099556.pypots
2024-05-25 02:23:53 [INFO]: Epoch 029 - training loss: 0.2078, validation loss: 0.1925
2024-05-25 02:23:53 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch29_loss0.192467350512743.pypots
2024-05-25 02:23:55 [INFO]: Epoch 030 - training loss: 0.1853, validation loss: 0.1850
2024-05-25 02:23:55 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch30_loss0.18501704186201096.pypots
2024-05-25 02:23:57 [INFO]: Epoch 031 - training loss: 0.1942, validation loss: 0.2100
2024-05-25 02:23:57 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch31_loss0.21003573015332222.pypots
2024-05-25 02:23:59 [INFO]: Epoch 032 - training loss: 0.1974, validation loss: 0.2084
2024-05-25 02:23:59 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch32_loss0.20842702686786652.pypots
2024-05-25 02:24:02 [INFO]: Epoch 033 - training loss: 0.2852, validation loss: 0.2001
2024-05-25 02:24:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch33_loss0.20013274624943733.pypots
2024-05-25 02:24:04 [INFO]: Epoch 034 - training loss: 0.2867, validation loss: 0.1902
2024-05-25 02:24:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch34_loss0.19018066674470901.pypots
2024-05-25 02:24:06 [INFO]: Epoch 035 - training loss: 0.2281, validation loss: 0.1853
2024-05-25 02:24:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch35_loss0.18527036905288696.pypots
2024-05-25 02:24:08 [INFO]: Epoch 036 - training loss: 0.2236, validation loss: 0.1766
2024-05-25 02:24:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch36_loss0.1765938512980938.pypots
2024-05-25 02:24:10 [INFO]: Epoch 037 - training loss: 0.2638, validation loss: 0.1691
2024-05-25 02:24:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch37_loss0.16906239464879036.pypots
2024-05-25 02:24:12 [INFO]: Epoch 038 - training loss: 0.1823, validation loss: 0.1727
2024-05-25 02:24:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch38_loss0.17269394919276237.pypots
2024-05-25 02:24:14 [INFO]: Epoch 039 - training loss: 0.1664, validation loss: 0.1668
2024-05-25 02:24:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch39_loss0.1667748987674713.pypots
2024-05-25 02:24:16 [INFO]: Epoch 040 - training loss: 0.1748, validation loss: 0.1605
2024-05-25 02:24:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch40_loss0.1604703962802887.pypots
2024-05-25 02:24:18 [INFO]: Epoch 041 - training loss: 0.1634, validation loss: 0.1614
2024-05-25 02:24:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch41_loss0.16141211986541748.pypots
2024-05-25 02:24:20 [INFO]: Epoch 042 - training loss: 0.1721, validation loss: 0.1589
2024-05-25 02:24:20 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch42_loss0.1589430868625641.pypots
2024-05-25 02:24:22 [INFO]: Epoch 043 - training loss: 0.1933, validation loss: 0.1598
2024-05-25 02:24:22 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch43_loss0.1597687564790249.pypots
2024-05-25 02:24:24 [INFO]: Epoch 044 - training loss: 0.2155, validation loss: 0.1597
2024-05-25 02:24:24 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch44_loss0.15969543531537056.pypots
2024-05-25 02:24:26 [INFO]: Epoch 045 - training loss: 0.1967, validation loss: 0.1563
2024-05-25 02:24:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch45_loss0.15626303479075432.pypots
2024-05-25 02:24:29 [INFO]: Epoch 046 - training loss: 0.1736, validation loss: 0.1554
2024-05-25 02:24:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch46_loss0.155444223433733.pypots
2024-05-25 02:24:31 [INFO]: Epoch 047 - training loss: 0.2139, validation loss: 0.1521
2024-05-25 02:24:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch47_loss0.1520990915596485.pypots
2024-05-25 02:24:33 [INFO]: Epoch 048 - training loss: 0.1875, validation loss: 0.1531
2024-05-25 02:24:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch48_loss0.15305647626519203.pypots
2024-05-25 02:24:35 [INFO]: Epoch 049 - training loss: 0.1856, validation loss: 0.1491
2024-05-25 02:24:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch49_loss0.14911719784140587.pypots
2024-05-25 02:24:37 [INFO]: Epoch 050 - training loss: 0.1673, validation loss: 0.1515
2024-05-25 02:24:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch50_loss0.15148339793086052.pypots
2024-05-25 02:24:39 [INFO]: Epoch 051 - training loss: 0.1461, validation loss: 0.1490
2024-05-25 02:24:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch51_loss0.148957971483469.pypots
2024-05-25 02:24:41 [INFO]: Epoch 052 - training loss: 0.1725, validation loss: 0.1445
2024-05-25 02:24:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch52_loss0.14452745765447617.pypots
2024-05-25 02:24:43 [INFO]: Epoch 053 - training loss: 0.1520, validation loss: 0.1506
2024-05-25 02:24:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch53_loss0.15064231678843498.pypots
2024-05-25 02:24:45 [INFO]: Epoch 054 - training loss: 0.1443, validation loss: 0.1454
2024-05-25 02:24:45 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch54_loss0.1454450748860836.pypots
2024-05-25 02:24:47 [INFO]: Epoch 055 - training loss: 0.2026, validation loss: 0.1520
2024-05-25 02:24:47 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch55_loss0.15203338488936424.pypots
2024-05-25 02:24:49 [INFO]: Epoch 056 - training loss: 0.2129, validation loss: 0.1539
2024-05-25 02:24:49 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch56_loss0.15389346703886986.pypots
2024-05-25 02:24:51 [INFO]: Epoch 057 - training loss: 0.1940, validation loss: 0.1566
2024-05-25 02:24:51 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch57_loss0.15660569444298744.pypots
2024-05-25 02:24:54 [INFO]: Epoch 058 - training loss: 0.1875, validation loss: 0.1445
2024-05-25 02:24:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch58_loss0.14453184604644775.pypots
2024-05-25 02:24:56 [INFO]: Epoch 059 - training loss: 0.1523, validation loss: 0.1413
2024-05-25 02:24:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch59_loss0.14131391420960426.pypots
2024-05-25 02:24:58 [INFO]: Epoch 060 - training loss: 0.2043, validation loss: 0.1726
2024-05-25 02:24:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch60_loss0.17259489372372627.pypots
2024-05-25 02:25:00 [INFO]: Epoch 061 - training loss: 0.2102, validation loss: 0.1720
2024-05-25 02:25:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch61_loss0.17197764664888382.pypots
2024-05-25 02:25:02 [INFO]: Epoch 062 - training loss: 0.1911, validation loss: 0.1713
2024-05-25 02:25:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch62_loss0.17134150862693787.pypots
2024-05-25 02:25:04 [INFO]: Epoch 063 - training loss: 0.2016, validation loss: 0.1529
2024-05-25 02:25:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch63_loss0.1529252715408802.pypots
2024-05-25 02:25:06 [INFO]: Epoch 064 - training loss: 0.1602, validation loss: 0.1532
2024-05-25 02:25:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch64_loss0.15324097126722336.pypots
2024-05-25 02:25:08 [INFO]: Epoch 065 - training loss: 0.2316, validation loss: 0.1487
2024-05-25 02:25:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch65_loss0.14872440695762634.pypots
2024-05-25 02:25:10 [INFO]: Epoch 066 - training loss: 0.1580, validation loss: 0.1482
2024-05-25 02:25:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch66_loss0.14822588860988617.pypots
2024-05-25 02:25:12 [INFO]: Epoch 067 - training loss: 0.1451, validation loss: 0.1422
2024-05-25 02:25:12 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch67_loss0.14222143217921257.pypots
2024-05-25 02:25:14 [INFO]: Epoch 068 - training loss: 0.1789, validation loss: 0.1413
2024-05-25 02:25:14 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch68_loss0.14129794389009476.pypots
2024-05-25 02:25:16 [INFO]: Epoch 069 - training loss: 0.1521, validation loss: 0.1417
2024-05-25 02:25:16 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch69_loss0.14169565215706825.pypots
2024-05-25 02:25:18 [INFO]: Epoch 070 - training loss: 0.1429, validation loss: 0.1466
2024-05-25 02:25:18 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch70_loss0.14657822251319885.pypots
2024-05-25 02:25:21 [INFO]: Epoch 071 - training loss: 0.1673, validation loss: 0.1400
2024-05-25 02:25:21 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch71_loss0.13997162505984306.pypots
2024-05-25 02:25:23 [INFO]: Epoch 072 - training loss: 0.1751, validation loss: 0.1428
2024-05-25 02:25:23 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch72_loss0.14276694133877754.pypots
2024-05-25 02:25:25 [INFO]: Epoch 073 - training loss: 0.1988, validation loss: 0.1566
2024-05-25 02:25:25 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch73_loss0.1565721593797207.pypots
2024-05-25 02:25:27 [INFO]: Epoch 074 - training loss: 0.1775, validation loss: 0.1652
2024-05-25 02:25:27 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch74_loss0.16522196307778358.pypots
2024-05-25 02:25:29 [INFO]: Epoch 075 - training loss: 0.1828, validation loss: 0.1480
2024-05-25 02:25:29 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch75_loss0.1479818895459175.pypots
2024-05-25 02:25:31 [INFO]: Epoch 076 - training loss: 0.2261, validation loss: 0.1564
2024-05-25 02:25:31 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch76_loss0.15638814494013786.pypots
2024-05-25 02:25:33 [INFO]: Epoch 077 - training loss: 0.1719, validation loss: 0.1505
2024-05-25 02:25:33 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch77_loss0.15048640593886375.pypots
2024-05-25 02:25:35 [INFO]: Epoch 078 - training loss: 0.1763, validation loss: 0.1446
2024-05-25 02:25:35 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch78_loss0.14455124735832214.pypots
2024-05-25 02:25:37 [INFO]: Epoch 079 - training loss: 0.1740, validation loss: 0.1458
2024-05-25 02:25:37 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch79_loss0.14582286402583122.pypots
2024-05-25 02:25:39 [INFO]: Epoch 080 - training loss: 0.1952, validation loss: 0.1548
2024-05-25 02:25:39 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch80_loss0.154827781021595.pypots
2024-05-25 02:25:41 [INFO]: Epoch 081 - training loss: 0.1605, validation loss: 0.1377
2024-05-25 02:25:41 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch81_loss0.13766221329569817.pypots
2024-05-25 02:25:43 [INFO]: Epoch 082 - training loss: 0.1694, validation loss: 0.1419
2024-05-25 02:25:43 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch82_loss0.14193324744701385.pypots
2024-05-25 02:25:46 [INFO]: Epoch 083 - training loss: 0.1796, validation loss: 0.1362
2024-05-25 02:25:46 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch83_loss0.1362486518919468.pypots
2024-05-25 02:25:48 [INFO]: Epoch 084 - training loss: 0.1451, validation loss: 0.1334
2024-05-25 02:25:48 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch84_loss0.1333956252783537.pypots
2024-05-25 02:25:50 [INFO]: Epoch 085 - training loss: 0.1894, validation loss: 0.1357
2024-05-25 02:25:50 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch85_loss0.1356547363102436.pypots
2024-05-25 02:25:52 [INFO]: Epoch 086 - training loss: 0.1727, validation loss: 0.1332
2024-05-25 02:25:52 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch86_loss0.13321064785122871.pypots
2024-05-25 02:25:54 [INFO]: Epoch 087 - training loss: 0.1710, validation loss: 0.1376
2024-05-25 02:25:54 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch87_loss0.13758084550499916.pypots
2024-05-25 02:25:56 [INFO]: Epoch 088 - training loss: 0.1608, validation loss: 0.1334
2024-05-25 02:25:56 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch88_loss0.1334094349294901.pypots
2024-05-25 02:25:58 [INFO]: Epoch 089 - training loss: 0.1668, validation loss: 0.1313
2024-05-25 02:25:58 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch89_loss0.13134543225169182.pypots
2024-05-25 02:26:00 [INFO]: Epoch 090 - training loss: 0.1591, validation loss: 0.1498
2024-05-25 02:26:00 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch90_loss0.14979152008891106.pypots
2024-05-25 02:26:02 [INFO]: Epoch 091 - training loss: 0.1854, validation loss: 0.1484
2024-05-25 02:26:02 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch91_loss0.14835461601614952.pypots
2024-05-25 02:26:04 [INFO]: Epoch 092 - training loss: 0.1619, validation loss: 0.1381
2024-05-25 02:26:04 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch92_loss0.1381414495408535.pypots
2024-05-25 02:26:06 [INFO]: Epoch 093 - training loss: 0.1835, validation loss: 0.1346
2024-05-25 02:26:06 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch93_loss0.1346435211598873.pypots
2024-05-25 02:26:08 [INFO]: Epoch 094 - training loss: 0.2178, validation loss: 0.1478
2024-05-25 02:26:08 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch94_loss0.1478101909160614.pypots
2024-05-25 02:26:10 [INFO]: Epoch 095 - training loss: 0.1637, validation loss: 0.1442
2024-05-25 02:26:10 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch95_loss0.1441805101931095.pypots
2024-05-25 02:26:13 [INFO]: Epoch 096 - training loss: 0.1614, validation loss: 0.1385
2024-05-25 02:26:13 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch96_loss0.13849717378616333.pypots
2024-05-25 02:26:15 [INFO]: Epoch 097 - training loss: 0.1531, validation loss: 0.1373
2024-05-25 02:26:15 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch97_loss0.13725627586245537.pypots
2024-05-25 02:26:17 [INFO]: Epoch 098 - training loss: 0.1758, validation loss: 0.1353
2024-05-25 02:26:17 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch98_loss0.135316064581275.pypots
2024-05-25 02:26:19 [INFO]: Epoch 099 - training loss: 0.1620, validation loss: 0.1362
2024-05-25 02:26:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI_epoch99_loss0.13615616410970688.pypots
2024-05-25 02:26:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:26:19 [INFO]: Finished training. The best model is from epoch#89.
2024-05-25 02:26:19 [INFO]: Saved the model to augmentation_saved_results/round_3/CSDI_ettm1/20240525_T022253/CSDI.pypots
2024-05-25 02:26:35 [INFO]: CSDI on ETTm1: MAE=0.1514, MSE=0.0885
2024-05-25 02:26:35 [INFO]: Successfully saved to augmentation_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-25 02:26:35 [INFO]: Using the given device: cuda:0
2024-05-25 02:26:35 [INFO]: Model files will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022635
2024-05-25 02:26:35 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022635/tensorboard
2024-05-25 02:26:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 02:26:35 [INFO]: Epoch 001 - training loss: 23924.4167, validation loss: 0.9793
2024-05-25 02:26:35 [INFO]: Epoch 002 - training loss: 21902.5179, validation loss: 0.9735
2024-05-25 02:26:35 [INFO]: Epoch 003 - training loss: 19858.7352, validation loss: 0.9694
2024-05-25 02:26:35 [INFO]: Epoch 004 - training loss: 17866.4421, validation loss: 0.9513
2024-05-25 02:26:35 [INFO]: Epoch 005 - training loss: 15945.9989, validation loss: 0.9104
2024-05-25 02:26:35 [INFO]: Epoch 006 - training loss: 14483.2189, validation loss: 0.8365
2024-05-25 02:26:36 [INFO]: Epoch 007 - training loss: 13068.1494, validation loss: 0.7458
2024-05-25 02:26:36 [INFO]: Epoch 008 - training loss: 12168.8865, validation loss: 0.6649
2024-05-25 02:26:36 [INFO]: Epoch 009 - training loss: 11592.6861, validation loss: 0.5930
2024-05-25 02:26:36 [INFO]: Epoch 010 - training loss: 11069.3253, validation loss: 0.5542
2024-05-25 02:26:36 [INFO]: Epoch 011 - training loss: 10799.4210, validation loss: 0.5189
2024-05-25 02:26:36 [INFO]: Epoch 012 - training loss: 10470.7849, validation loss: 0.4973
2024-05-25 02:26:36 [INFO]: Epoch 013 - training loss: 10318.8548, validation loss: 0.4864
2024-05-25 02:26:37 [INFO]: Epoch 014 - training loss: 10129.2779, validation loss: 0.4747
2024-05-25 02:26:37 [INFO]: Epoch 015 - training loss: 10046.2188, validation loss: 0.4637
2024-05-25 02:26:37 [INFO]: Epoch 016 - training loss: 9924.4990, validation loss: 0.4359
2024-05-25 02:26:37 [INFO]: Epoch 017 - training loss: 9882.0101, validation loss: 0.4248
2024-05-25 02:26:37 [INFO]: Epoch 018 - training loss: 9886.9410, validation loss: 0.4039
2024-05-25 02:26:37 [INFO]: Epoch 019 - training loss: 9718.8027, validation loss: 0.3817
2024-05-25 02:26:37 [INFO]: Epoch 020 - training loss: 9684.6895, validation loss: 0.3648
2024-05-25 02:26:37 [INFO]: Epoch 021 - training loss: 9632.1706, validation loss: 0.3444
2024-05-25 02:26:38 [INFO]: Epoch 022 - training loss: 9589.0865, validation loss: 0.3261
2024-05-25 02:26:38 [INFO]: Epoch 023 - training loss: 9548.3759, validation loss: 0.3114
2024-05-25 02:26:38 [INFO]: Epoch 024 - training loss: 9528.1158, validation loss: 0.2946
2024-05-25 02:26:38 [INFO]: Epoch 025 - training loss: 9522.9686, validation loss: 0.2826
2024-05-25 02:26:38 [INFO]: Epoch 026 - training loss: 9511.2081, validation loss: 0.2729
2024-05-25 02:26:38 [INFO]: Epoch 027 - training loss: 9460.8037, validation loss: 0.2648
2024-05-25 02:26:38 [INFO]: Epoch 028 - training loss: 9458.6218, validation loss: 0.2567
2024-05-25 02:26:38 [INFO]: Epoch 029 - training loss: 9431.7625, validation loss: 0.2500
2024-05-25 02:26:39 [INFO]: Epoch 030 - training loss: 9413.1259, validation loss: 0.2409
2024-05-25 02:26:39 [INFO]: Epoch 031 - training loss: 9396.2827, validation loss: 0.2388
2024-05-25 02:26:39 [INFO]: Epoch 032 - training loss: 9393.8888, validation loss: 0.2357
2024-05-25 02:26:39 [INFO]: Epoch 033 - training loss: 9398.5206, validation loss: 0.2321
2024-05-25 02:26:39 [INFO]: Epoch 034 - training loss: 9370.3519, validation loss: 0.2263
2024-05-25 02:26:39 [INFO]: Epoch 035 - training loss: 9376.0704, validation loss: 0.2258
2024-05-25 02:26:39 [INFO]: Epoch 036 - training loss: 9352.6097, validation loss: 0.2203
2024-05-25 02:26:40 [INFO]: Epoch 037 - training loss: 9348.1838, validation loss: 0.2188
2024-05-25 02:26:40 [INFO]: Epoch 038 - training loss: 9347.1982, validation loss: 0.2171
2024-05-25 02:26:40 [INFO]: Epoch 039 - training loss: 9338.4121, validation loss: 0.2154
2024-05-25 02:26:40 [INFO]: Epoch 040 - training loss: 9328.1163, validation loss: 0.2124
2024-05-25 02:26:40 [INFO]: Epoch 041 - training loss: 9320.6339, validation loss: 0.2090
2024-05-25 02:26:40 [INFO]: Epoch 042 - training loss: 9333.5500, validation loss: 0.2069
2024-05-25 02:26:40 [INFO]: Epoch 043 - training loss: 9314.4127, validation loss: 0.2047
2024-05-25 02:26:40 [INFO]: Epoch 044 - training loss: 9309.5756, validation loss: 0.2010
2024-05-25 02:26:41 [INFO]: Epoch 045 - training loss: 9328.3102, validation loss: 0.2009
2024-05-25 02:26:41 [INFO]: Epoch 046 - training loss: 9306.3600, validation loss: 0.1968
2024-05-25 02:26:41 [INFO]: Epoch 047 - training loss: 9299.9113, validation loss: 0.1936
2024-05-25 02:26:41 [INFO]: Epoch 048 - training loss: 9303.8359, validation loss: 0.1911
2024-05-25 02:26:41 [INFO]: Epoch 049 - training loss: 9296.3648, validation loss: 0.1889
2024-05-25 02:26:41 [INFO]: Epoch 050 - training loss: 9294.8056, validation loss: 0.1856
2024-05-25 02:26:41 [INFO]: Epoch 051 - training loss: 9302.7982, validation loss: 0.1834
2024-05-25 02:26:41 [INFO]: Epoch 052 - training loss: 9288.2562, validation loss: 0.1826
2024-05-25 02:26:42 [INFO]: Epoch 053 - training loss: 9281.1485, validation loss: 0.1793
2024-05-25 02:26:42 [INFO]: Epoch 054 - training loss: 9277.6898, validation loss: 0.1734
2024-05-25 02:26:42 [INFO]: Epoch 055 - training loss: 9275.5267, validation loss: 0.1743
2024-05-25 02:26:42 [INFO]: Epoch 056 - training loss: 9312.1059, validation loss: 0.1724
2024-05-25 02:26:42 [INFO]: Epoch 057 - training loss: 9269.9228, validation loss: 0.1685
2024-05-25 02:26:42 [INFO]: Epoch 058 - training loss: 9268.0565, validation loss: 0.1674
2024-05-25 02:26:42 [INFO]: Epoch 059 - training loss: 9268.1291, validation loss: 0.1668
2024-05-25 02:26:43 [INFO]: Epoch 060 - training loss: 9265.0303, validation loss: 0.1644
2024-05-25 02:26:43 [INFO]: Epoch 061 - training loss: 9265.4401, validation loss: 0.1623
2024-05-25 02:26:43 [INFO]: Epoch 062 - training loss: 9265.5916, validation loss: 0.1547
2024-05-25 02:26:43 [INFO]: Epoch 063 - training loss: 9263.9143, validation loss: 0.1578
2024-05-25 02:26:43 [INFO]: Epoch 064 - training loss: 9259.5290, validation loss: 0.1551
2024-05-25 02:26:43 [INFO]: Epoch 065 - training loss: 9257.4016, validation loss: 0.1533
2024-05-25 02:26:43 [INFO]: Epoch 066 - training loss: 9257.7687, validation loss: 0.1542
2024-05-25 02:26:43 [INFO]: Epoch 067 - training loss: 9261.3575, validation loss: 0.1492
2024-05-25 02:26:44 [INFO]: Epoch 068 - training loss: 9257.0982, validation loss: 0.1475
2024-05-25 02:26:44 [INFO]: Epoch 069 - training loss: 9254.1118, validation loss: 0.1466
2024-05-25 02:26:44 [INFO]: Epoch 070 - training loss: 9256.5471, validation loss: 0.1467
2024-05-25 02:26:44 [INFO]: Epoch 071 - training loss: 9250.1050, validation loss: 0.1462
2024-05-25 02:26:44 [INFO]: Epoch 072 - training loss: 9247.7766, validation loss: 0.1447
2024-05-25 02:26:44 [INFO]: Epoch 073 - training loss: 9247.0865, validation loss: 0.1428
2024-05-25 02:26:44 [INFO]: Epoch 074 - training loss: 9257.8088, validation loss: 0.1410
2024-05-25 02:26:44 [INFO]: Epoch 075 - training loss: 9245.3914, validation loss: 0.1414
2024-05-25 02:26:45 [INFO]: Epoch 076 - training loss: 9245.5526, validation loss: 0.1418
2024-05-25 02:26:45 [INFO]: Epoch 077 - training loss: 9246.7970, validation loss: 0.1411
2024-05-25 02:26:45 [INFO]: Epoch 078 - training loss: 9245.6234, validation loss: 0.1411
2024-05-25 02:26:45 [INFO]: Epoch 079 - training loss: 9243.4794, validation loss: 0.1387
2024-05-25 02:26:45 [INFO]: Epoch 080 - training loss: 9243.8580, validation loss: 0.1370
2024-05-25 02:26:45 [INFO]: Epoch 081 - training loss: 9242.8463, validation loss: 0.1366
2024-05-25 02:26:45 [INFO]: Epoch 082 - training loss: 9241.6929, validation loss: 0.1356
2024-05-25 02:26:46 [INFO]: Epoch 083 - training loss: 9239.3535, validation loss: 0.1349
2024-05-25 02:26:46 [INFO]: Epoch 084 - training loss: 9239.9849, validation loss: 0.1321
2024-05-25 02:26:46 [INFO]: Epoch 085 - training loss: 9241.8185, validation loss: 0.1327
2024-05-25 02:26:46 [INFO]: Epoch 086 - training loss: 9241.2281, validation loss: 0.1325
2024-05-25 02:26:46 [INFO]: Epoch 087 - training loss: 9240.7945, validation loss: 0.1305
2024-05-25 02:26:46 [INFO]: Epoch 088 - training loss: 9236.6871, validation loss: 0.1295
2024-05-25 02:26:46 [INFO]: Epoch 089 - training loss: 9237.0788, validation loss: 0.1303
2024-05-25 02:26:46 [INFO]: Epoch 090 - training loss: 9234.3803, validation loss: 0.1311
2024-05-25 02:26:47 [INFO]: Epoch 091 - training loss: 9237.9334, validation loss: 0.1283
2024-05-25 02:26:47 [INFO]: Epoch 092 - training loss: 9237.3687, validation loss: 0.1277
2024-05-25 02:26:47 [INFO]: Epoch 093 - training loss: 9235.2966, validation loss: 0.1269
2024-05-25 02:26:47 [INFO]: Epoch 094 - training loss: 9233.0406, validation loss: 0.1285
2024-05-25 02:26:47 [INFO]: Epoch 095 - training loss: 9232.7108, validation loss: 0.1257
2024-05-25 02:26:47 [INFO]: Epoch 096 - training loss: 9231.4240, validation loss: 0.1272
2024-05-25 02:26:47 [INFO]: Epoch 097 - training loss: 9232.5233, validation loss: 0.1262
2024-05-25 02:26:47 [INFO]: Epoch 098 - training loss: 9232.2169, validation loss: 0.1249
2024-05-25 02:26:48 [INFO]: Epoch 099 - training loss: 9231.9357, validation loss: 0.1241
2024-05-25 02:26:48 [INFO]: Epoch 100 - training loss: 9232.7687, validation loss: 0.1230
2024-05-25 02:26:48 [INFO]: Epoch 101 - training loss: 9230.9818, validation loss: 0.1239
2024-05-25 02:26:48 [INFO]: Epoch 102 - training loss: 9230.7059, validation loss: 0.1223
2024-05-25 02:26:48 [INFO]: Epoch 103 - training loss: 9231.2269, validation loss: 0.1227
2024-05-25 02:26:48 [INFO]: Epoch 104 - training loss: 9230.2358, validation loss: 0.1217
2024-05-25 02:26:48 [INFO]: Epoch 105 - training loss: 9229.5698, validation loss: 0.1208
2024-05-25 02:26:49 [INFO]: Epoch 106 - training loss: 9229.5030, validation loss: 0.1192
2024-05-25 02:26:49 [INFO]: Epoch 107 - training loss: 9226.9803, validation loss: 0.1199
2024-05-25 02:26:49 [INFO]: Epoch 108 - training loss: 9227.3026, validation loss: 0.1192
2024-05-25 02:26:49 [INFO]: Epoch 109 - training loss: 9227.7401, validation loss: 0.1183
2024-05-25 02:26:49 [INFO]: Epoch 110 - training loss: 9228.3160, validation loss: 0.1210
2024-05-25 02:26:49 [INFO]: Epoch 111 - training loss: 9225.2618, validation loss: 0.1185
2024-05-25 02:26:49 [INFO]: Epoch 112 - training loss: 9225.9750, validation loss: 0.1159
2024-05-25 02:26:49 [INFO]: Epoch 113 - training loss: 9225.7732, validation loss: 0.1162
2024-05-25 02:26:50 [INFO]: Epoch 114 - training loss: 9224.8217, validation loss: 0.1153
2024-05-25 02:26:50 [INFO]: Epoch 115 - training loss: 9225.7382, validation loss: 0.1148
2024-05-25 02:26:50 [INFO]: Epoch 116 - training loss: 9226.1414, validation loss: 0.1134
2024-05-25 02:26:50 [INFO]: Epoch 117 - training loss: 9225.3289, validation loss: 0.1179
2024-05-25 02:26:50 [INFO]: Epoch 118 - training loss: 9224.9332, validation loss: 0.1139
2024-05-25 02:26:50 [INFO]: Epoch 119 - training loss: 9227.3879, validation loss: 0.1144
2024-05-25 02:26:50 [INFO]: Epoch 120 - training loss: 9223.4081, validation loss: 0.1131
2024-05-25 02:26:51 [INFO]: Epoch 121 - training loss: 9224.3075, validation loss: 0.1116
2024-05-25 02:26:51 [INFO]: Epoch 122 - training loss: 9223.0541, validation loss: 0.1109
2024-05-25 02:26:51 [INFO]: Epoch 123 - training loss: 9222.8813, validation loss: 0.1099
2024-05-25 02:26:51 [INFO]: Epoch 124 - training loss: 9222.0244, validation loss: 0.1097
2024-05-25 02:26:51 [INFO]: Epoch 125 - training loss: 9221.7809, validation loss: 0.1102
2024-05-25 02:26:51 [INFO]: Epoch 126 - training loss: 9222.9688, validation loss: 0.1090
2024-05-25 02:26:51 [INFO]: Epoch 127 - training loss: 9224.4768, validation loss: 0.1076
2024-05-25 02:26:51 [INFO]: Epoch 128 - training loss: 9220.6884, validation loss: 0.1090
2024-05-25 02:26:52 [INFO]: Epoch 129 - training loss: 9220.8919, validation loss: 0.1071
2024-05-25 02:26:52 [INFO]: Epoch 130 - training loss: 9222.5900, validation loss: 0.1067
2024-05-25 02:26:52 [INFO]: Epoch 131 - training loss: 9219.8292, validation loss: 0.1085
2024-05-25 02:26:52 [INFO]: Epoch 132 - training loss: 9220.6719, validation loss: 0.1064
2024-05-25 02:26:52 [INFO]: Epoch 133 - training loss: 9220.4257, validation loss: 0.1050
2024-05-25 02:26:52 [INFO]: Epoch 134 - training loss: 9219.6119, validation loss: 0.1063
2024-05-25 02:26:52 [INFO]: Epoch 135 - training loss: 9218.9317, validation loss: 0.1039
2024-05-25 02:26:52 [INFO]: Epoch 136 - training loss: 9219.8396, validation loss: 0.1043
2024-05-25 02:26:53 [INFO]: Epoch 137 - training loss: 9218.8537, validation loss: 0.1049
2024-05-25 02:26:53 [INFO]: Epoch 138 - training loss: 9218.1083, validation loss: 0.1045
2024-05-25 02:26:53 [INFO]: Epoch 139 - training loss: 9218.5306, validation loss: 0.1034
2024-05-25 02:26:53 [INFO]: Epoch 140 - training loss: 9217.8433, validation loss: 0.1046
2024-05-25 02:26:53 [INFO]: Epoch 141 - training loss: 9218.3789, validation loss: 0.1020
2024-05-25 02:26:53 [INFO]: Epoch 142 - training loss: 9217.0303, validation loss: 0.1022
2024-05-25 02:26:53 [INFO]: Epoch 143 - training loss: 9217.6160, validation loss: 0.1015
2024-05-25 02:26:54 [INFO]: Epoch 144 - training loss: 9216.6981, validation loss: 0.1005
2024-05-25 02:26:54 [INFO]: Epoch 145 - training loss: 9216.7515, validation loss: 0.1008
2024-05-25 02:26:54 [INFO]: Epoch 146 - training loss: 9216.4648, validation loss: 0.1002
2024-05-25 02:26:54 [INFO]: Epoch 147 - training loss: 9217.1418, validation loss: 0.0998
2024-05-25 02:26:54 [INFO]: Epoch 148 - training loss: 9216.3721, validation loss: 0.1013
2024-05-25 02:26:54 [INFO]: Epoch 149 - training loss: 9217.5154, validation loss: 0.1007
2024-05-25 02:26:54 [INFO]: Epoch 150 - training loss: 9219.8307, validation loss: 0.0989
2024-05-25 02:26:54 [INFO]: Epoch 151 - training loss: 9218.9775, validation loss: 0.1009
2024-05-25 02:26:55 [INFO]: Epoch 152 - training loss: 9215.7778, validation loss: 0.0997
2024-05-25 02:26:55 [INFO]: Epoch 153 - training loss: 9215.3781, validation loss: 0.0975
2024-05-25 02:26:55 [INFO]: Epoch 154 - training loss: 9214.1760, validation loss: 0.0965
2024-05-25 02:26:55 [INFO]: Epoch 155 - training loss: 9214.7398, validation loss: 0.0968
2024-05-25 02:26:55 [INFO]: Epoch 156 - training loss: 9216.4224, validation loss: 0.0966
2024-05-25 02:26:55 [INFO]: Epoch 157 - training loss: 9214.1016, validation loss: 0.0972
2024-05-25 02:26:55 [INFO]: Epoch 158 - training loss: 9216.5415, validation loss: 0.0961
2024-05-25 02:26:55 [INFO]: Epoch 159 - training loss: 9215.5523, validation loss: 0.0978
2024-05-25 02:26:56 [INFO]: Epoch 160 - training loss: 9217.0130, validation loss: 0.0967
2024-05-25 02:26:56 [INFO]: Epoch 161 - training loss: 9212.9242, validation loss: 0.0956
2024-05-25 02:26:56 [INFO]: Epoch 162 - training loss: 9217.1093, validation loss: 0.0949
2024-05-25 02:26:56 [INFO]: Epoch 163 - training loss: 9214.3688, validation loss: 0.0941
2024-05-25 02:26:56 [INFO]: Epoch 164 - training loss: 9215.1899, validation loss: 0.0948
2024-05-25 02:26:56 [INFO]: Epoch 165 - training loss: 9215.2622, validation loss: 0.0958
2024-05-25 02:26:56 [INFO]: Epoch 166 - training loss: 9215.4234, validation loss: 0.0942
2024-05-25 02:26:57 [INFO]: Epoch 167 - training loss: 9212.6570, validation loss: 0.0968
2024-05-25 02:26:57 [INFO]: Epoch 168 - training loss: 9213.2538, validation loss: 0.0935
2024-05-25 02:26:57 [INFO]: Epoch 169 - training loss: 9214.6207, validation loss: 0.0951
2024-05-25 02:26:57 [INFO]: Epoch 170 - training loss: 9215.2971, validation loss: 0.0935
2024-05-25 02:26:57 [INFO]: Epoch 171 - training loss: 9215.0339, validation loss: 0.0965
2024-05-25 02:26:57 [INFO]: Epoch 172 - training loss: 9214.0432, validation loss: 0.0932
2024-05-25 02:26:57 [INFO]: Epoch 173 - training loss: 9212.3416, validation loss: 0.0926
2024-05-25 02:26:57 [INFO]: Epoch 174 - training loss: 9214.3553, validation loss: 0.0946
2024-05-25 02:26:58 [INFO]: Epoch 175 - training loss: 9213.2172, validation loss: 0.0945
2024-05-25 02:26:58 [INFO]: Epoch 176 - training loss: 9214.9166, validation loss: 0.0932
2024-05-25 02:26:58 [INFO]: Epoch 177 - training loss: 9212.8323, validation loss: 0.0900
2024-05-25 02:26:58 [INFO]: Epoch 178 - training loss: 9212.1601, validation loss: 0.0939
2024-05-25 02:26:58 [INFO]: Epoch 179 - training loss: 9212.6684, validation loss: 0.0930
2024-05-25 02:26:58 [INFO]: Epoch 180 - training loss: 9212.7936, validation loss: 0.0913
2024-05-25 02:26:58 [INFO]: Epoch 181 - training loss: 9213.2761, validation loss: 0.0928
2024-05-25 02:26:58 [INFO]: Epoch 182 - training loss: 9212.1768, validation loss: 0.0918
2024-05-25 02:26:59 [INFO]: Epoch 183 - training loss: 9212.3001, validation loss: 0.0908
2024-05-25 02:26:59 [INFO]: Epoch 184 - training loss: 9213.6080, validation loss: 0.0905
2024-05-25 02:26:59 [INFO]: Epoch 185 - training loss: 9212.5164, validation loss: 0.0922
2024-05-25 02:26:59 [INFO]: Epoch 186 - training loss: 9211.6000, validation loss: 0.0892
2024-05-25 02:26:59 [INFO]: Epoch 187 - training loss: 9212.8438, validation loss: 0.0919
2024-05-25 02:26:59 [INFO]: Epoch 188 - training loss: 9212.5909, validation loss: 0.0918
2024-05-25 02:26:59 [INFO]: Epoch 189 - training loss: 9212.1395, validation loss: 0.0929
2024-05-25 02:27:00 [INFO]: Epoch 190 - training loss: 9211.4425, validation loss: 0.0904
2024-05-25 02:27:00 [INFO]: Epoch 191 - training loss: 9213.3583, validation loss: 0.0898
2024-05-25 02:27:00 [INFO]: Epoch 192 - training loss: 9210.3580, validation loss: 0.0907
2024-05-25 02:27:00 [INFO]: Epoch 193 - training loss: 9209.8236, validation loss: 0.0883
2024-05-25 02:27:00 [INFO]: Epoch 194 - training loss: 9214.0676, validation loss: 0.0903
2024-05-25 02:27:00 [INFO]: Epoch 195 - training loss: 9212.1857, validation loss: 0.0891
2024-05-25 02:27:00 [INFO]: Epoch 196 - training loss: 9212.9998, validation loss: 0.0924
2024-05-25 02:27:00 [INFO]: Epoch 197 - training loss: 9211.9486, validation loss: 0.0913
2024-05-25 02:27:01 [INFO]: Epoch 198 - training loss: 9210.6011, validation loss: 0.0889
2024-05-25 02:27:01 [INFO]: Epoch 199 - training loss: 9210.2341, validation loss: 0.0887
2024-05-25 02:27:01 [INFO]: Epoch 200 - training loss: 9211.1155, validation loss: 0.0899
2024-05-25 02:27:01 [INFO]: Epoch 201 - training loss: 9210.8550, validation loss: 0.0912
2024-05-25 02:27:01 [INFO]: Epoch 202 - training loss: 9210.4540, validation loss: 0.0875
2024-05-25 02:27:01 [INFO]: Epoch 203 - training loss: 9210.1085, validation loss: 0.0891
2024-05-25 02:27:01 [INFO]: Epoch 204 - training loss: 9210.9617, validation loss: 0.0881
2024-05-25 02:27:02 [INFO]: Epoch 205 - training loss: 9210.6905, validation loss: 0.0895
2024-05-25 02:27:02 [INFO]: Epoch 206 - training loss: 9209.5443, validation loss: 0.0888
2024-05-25 02:27:02 [INFO]: Epoch 207 - training loss: 9209.7555, validation loss: 0.0874
2024-05-25 02:27:02 [INFO]: Epoch 208 - training loss: 9209.8907, validation loss: 0.0876
2024-05-25 02:27:02 [INFO]: Epoch 209 - training loss: 9210.6214, validation loss: 0.0888
2024-05-25 02:27:02 [INFO]: Epoch 210 - training loss: 9208.4898, validation loss: 0.0871
2024-05-25 02:27:02 [INFO]: Epoch 211 - training loss: 9210.1817, validation loss: 0.0852
2024-05-25 02:27:02 [INFO]: Epoch 212 - training loss: 9208.3046, validation loss: 0.0879
2024-05-25 02:27:03 [INFO]: Epoch 213 - training loss: 9208.2130, validation loss: 0.0866
2024-05-25 02:27:03 [INFO]: Epoch 214 - training loss: 9209.5027, validation loss: 0.0873
2024-05-25 02:27:03 [INFO]: Epoch 215 - training loss: 9211.6230, validation loss: 0.0872
2024-05-25 02:27:03 [INFO]: Epoch 216 - training loss: 9207.5905, validation loss: 0.0876
2024-05-25 02:27:03 [INFO]: Epoch 217 - training loss: 9209.0178, validation loss: 0.0867
2024-05-25 02:27:03 [INFO]: Epoch 218 - training loss: 9208.9224, validation loss: 0.0877
2024-05-25 02:27:03 [INFO]: Epoch 219 - training loss: 9210.1405, validation loss: 0.0882
2024-05-25 02:27:03 [INFO]: Epoch 220 - training loss: 9207.6340, validation loss: 0.0861
2024-05-25 02:27:04 [INFO]: Epoch 221 - training loss: 9208.2673, validation loss: 0.0862
2024-05-25 02:27:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:27:04 [INFO]: Finished training. The best model is from epoch#211.
2024-05-25 02:27:04 [INFO]: Saved the model to augmentation_saved_results/round_3/GPVAE_ettm1/20240525_T022635/GPVAE.pypots
2024-05-25 02:27:04 [INFO]: GP-VAE on ETTm1: MAE=0.3138, MSE=0.2097
2024-05-25 02:27:04 [INFO]: Successfully saved to augmentation_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-25 02:27:04 [INFO]: Using the given device: cuda:0
2024-05-25 02:27:04 [INFO]: Model files will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022704
2024-05-25 02:27:04 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022704/tensorboard
2024-05-25 02:27:04 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:27:14 [INFO]: Epoch 001 - generator training loss: 0.4500, discriminator training loss: 0.5293, validation loss: 0.4106
2024-05-25 02:27:23 [INFO]: Epoch 002 - generator training loss: -0.0388, discriminator training loss: 0.4698, validation loss: 0.1221
2024-05-25 02:27:32 [INFO]: Epoch 003 - generator training loss: -0.1558, discriminator training loss: 0.4217, validation loss: 0.0758
2024-05-25 02:27:41 [INFO]: Epoch 004 - generator training loss: -0.1332, discriminator training loss: 0.3495, validation loss: 0.0586
2024-05-25 02:27:50 [INFO]: Epoch 005 - generator training loss: -0.0942, discriminator training loss: 0.2719, validation loss: 0.0459
2024-05-25 02:27:59 [INFO]: Epoch 006 - generator training loss: -0.0667, discriminator training loss: 0.2173, validation loss: 0.0450
2024-05-25 02:28:08 [INFO]: Epoch 007 - generator training loss: -0.0550, discriminator training loss: 0.1947, validation loss: 0.0449
2024-05-25 02:28:17 [INFO]: Epoch 008 - generator training loss: -0.0518, discriminator training loss: 0.1804, validation loss: 0.0409
2024-05-25 02:28:26 [INFO]: Epoch 009 - generator training loss: -0.0520, discriminator training loss: 0.1753, validation loss: 0.0394
2024-05-25 02:28:35 [INFO]: Epoch 010 - generator training loss: -0.0561, discriminator training loss: 0.1769, validation loss: 0.0380
2024-05-25 02:28:44 [INFO]: Epoch 011 - generator training loss: -0.0522, discriminator training loss: 0.1732, validation loss: 0.0365
2024-05-25 02:28:53 [INFO]: Epoch 012 - generator training loss: -0.0545, discriminator training loss: 0.1729, validation loss: 0.0360
2024-05-25 02:29:02 [INFO]: Epoch 013 - generator training loss: -0.0545, discriminator training loss: 0.1728, validation loss: 0.0362
2024-05-25 02:29:11 [INFO]: Epoch 014 - generator training loss: -0.0583, discriminator training loss: 0.1704, validation loss: 0.0358
2024-05-25 02:29:20 [INFO]: Epoch 015 - generator training loss: -0.0546, discriminator training loss: 0.1707, validation loss: 0.0348
2024-05-25 02:29:29 [INFO]: Epoch 016 - generator training loss: -0.0568, discriminator training loss: 0.1701, validation loss: 0.0345
2024-05-25 02:29:38 [INFO]: Epoch 017 - generator training loss: -0.0582, discriminator training loss: 0.1698, validation loss: 0.0353
2024-05-25 02:29:47 [INFO]: Epoch 018 - generator training loss: -0.0560, discriminator training loss: 0.1698, validation loss: 0.0346
2024-05-25 02:29:56 [INFO]: Epoch 019 - generator training loss: -0.0572, discriminator training loss: 0.1690, validation loss: 0.0345
2024-05-25 02:30:05 [INFO]: Epoch 020 - generator training loss: -0.0588, discriminator training loss: 0.1691, validation loss: 0.0340
2024-05-25 02:30:14 [INFO]: Epoch 021 - generator training loss: -0.0578, discriminator training loss: 0.1694, validation loss: 0.0332
2024-05-25 02:30:23 [INFO]: Epoch 022 - generator training loss: -0.0579, discriminator training loss: 0.1704, validation loss: 0.0330
2024-05-25 02:30:32 [INFO]: Epoch 023 - generator training loss: -0.0556, discriminator training loss: 0.1678, validation loss: 0.0345
2024-05-25 02:30:41 [INFO]: Epoch 024 - generator training loss: -0.0595, discriminator training loss: 0.1711, validation loss: 0.0377
2024-05-25 02:30:49 [INFO]: Epoch 025 - generator training loss: -0.0542, discriminator training loss: 0.1702, validation loss: 0.0370
2024-05-25 02:30:58 [INFO]: Epoch 026 - generator training loss: -0.0606, discriminator training loss: 0.1683, validation loss: 0.0329
2024-05-25 02:31:07 [INFO]: Epoch 027 - generator training loss: -0.0610, discriminator training loss: 0.1682, validation loss: 0.0320
2024-05-25 02:31:16 [INFO]: Epoch 028 - generator training loss: -0.0627, discriminator training loss: 0.1675, validation loss: 0.0325
2024-05-25 02:31:25 [INFO]: Epoch 029 - generator training loss: -0.0606, discriminator training loss: 0.1665, validation loss: 0.0328
2024-05-25 02:31:34 [INFO]: Epoch 030 - generator training loss: -0.0580, discriminator training loss: 0.1660, validation loss: 0.0317
2024-05-25 02:31:43 [INFO]: Epoch 031 - generator training loss: -0.0647, discriminator training loss: 0.1686, validation loss: 0.0316
2024-05-25 02:31:52 [INFO]: Epoch 032 - generator training loss: -0.0568, discriminator training loss: 0.1662, validation loss: 0.0307
2024-05-25 02:32:01 [INFO]: Epoch 033 - generator training loss: -0.0636, discriminator training loss: 0.1670, validation loss: 0.0310
2024-05-25 02:32:10 [INFO]: Epoch 034 - generator training loss: -0.0593, discriminator training loss: 0.1656, validation loss: 0.0314
2024-05-25 02:32:19 [INFO]: Epoch 035 - generator training loss: -0.0614, discriminator training loss: 0.1670, validation loss: 0.0314
2024-05-25 02:32:28 [INFO]: Epoch 036 - generator training loss: -0.0603, discriminator training loss: 0.1665, validation loss: 0.0310
2024-05-25 02:32:37 [INFO]: Epoch 037 - generator training loss: -0.0622, discriminator training loss: 0.1658, validation loss: 0.0299
2024-05-25 02:32:46 [INFO]: Epoch 038 - generator training loss: -0.0641, discriminator training loss: 0.1656, validation loss: 0.0304
2024-05-25 02:32:55 [INFO]: Epoch 039 - generator training loss: -0.0662, discriminator training loss: 0.1654, validation loss: 0.0300
2024-05-25 02:33:04 [INFO]: Epoch 040 - generator training loss: -0.0618, discriminator training loss: 0.1670, validation loss: 0.0320
2024-05-25 02:33:13 [INFO]: Epoch 041 - generator training loss: -0.0628, discriminator training loss: 0.1683, validation loss: 0.0301
2024-05-25 02:33:22 [INFO]: Epoch 042 - generator training loss: -0.0639, discriminator training loss: 0.1662, validation loss: 0.0298
2024-05-25 02:33:31 [INFO]: Epoch 043 - generator training loss: -0.0662, discriminator training loss: 0.1665, validation loss: 0.0299
2024-05-25 02:33:40 [INFO]: Epoch 044 - generator training loss: -0.0648, discriminator training loss: 0.1673, validation loss: 0.0303
2024-05-25 02:33:49 [INFO]: Epoch 045 - generator training loss: -0.0663, discriminator training loss: 0.1671, validation loss: 0.0286
2024-05-25 02:33:58 [INFO]: Epoch 046 - generator training loss: -0.0620, discriminator training loss: 0.1635, validation loss: 0.0283
2024-05-25 02:34:07 [INFO]: Epoch 047 - generator training loss: -0.0672, discriminator training loss: 0.1628, validation loss: 0.0287
2024-05-25 02:34:16 [INFO]: Epoch 048 - generator training loss: -0.0652, discriminator training loss: 0.1645, validation loss: 0.0280
2024-05-25 02:34:25 [INFO]: Epoch 049 - generator training loss: -0.0649, discriminator training loss: 0.1638, validation loss: 0.0288
2024-05-25 02:34:34 [INFO]: Epoch 050 - generator training loss: -0.0665, discriminator training loss: 0.1656, validation loss: 0.0283
2024-05-25 02:34:43 [INFO]: Epoch 051 - generator training loss: -0.0668, discriminator training loss: 0.1657, validation loss: 0.0269
2024-05-25 02:34:52 [INFO]: Epoch 052 - generator training loss: -0.0655, discriminator training loss: 0.1653, validation loss: 0.0283
2024-05-25 02:35:01 [INFO]: Epoch 053 - generator training loss: -0.0667, discriminator training loss: 0.1659, validation loss: 0.0276
2024-05-25 02:35:10 [INFO]: Epoch 054 - generator training loss: -0.0645, discriminator training loss: 0.1640, validation loss: 0.0289
2024-05-25 02:35:19 [INFO]: Epoch 055 - generator training loss: -0.0663, discriminator training loss: 0.1630, validation loss: 0.0264
2024-05-25 02:35:28 [INFO]: Epoch 056 - generator training loss: -0.0678, discriminator training loss: 0.1629, validation loss: 0.0273
2024-05-25 02:35:37 [INFO]: Epoch 057 - generator training loss: -0.0663, discriminator training loss: 0.1628, validation loss: 0.0260
2024-05-25 02:35:46 [INFO]: Epoch 058 - generator training loss: -0.0679, discriminator training loss: 0.1659, validation loss: 0.0265
2024-05-25 02:35:54 [INFO]: Epoch 059 - generator training loss: -0.0645, discriminator training loss: 0.1631, validation loss: 0.0262
2024-05-25 02:36:03 [INFO]: Epoch 060 - generator training loss: -0.0710, discriminator training loss: 0.1661, validation loss: 0.0264
2024-05-25 02:36:12 [INFO]: Epoch 061 - generator training loss: -0.0610, discriminator training loss: 0.1676, validation loss: 0.0265
2024-05-25 02:36:21 [INFO]: Epoch 062 - generator training loss: -0.0701, discriminator training loss: 0.1655, validation loss: 0.0248
2024-05-25 02:36:30 [INFO]: Epoch 063 - generator training loss: -0.0662, discriminator training loss: 0.1628, validation loss: 0.0262
2024-05-25 02:36:39 [INFO]: Epoch 064 - generator training loss: -0.0689, discriminator training loss: 0.1640, validation loss: 0.0248
2024-05-25 02:36:48 [INFO]: Epoch 065 - generator training loss: -0.0689, discriminator training loss: 0.1642, validation loss: 0.0244
2024-05-25 02:36:57 [INFO]: Epoch 066 - generator training loss: -0.0692, discriminator training loss: 0.1643, validation loss: 0.0249
2024-05-25 02:37:06 [INFO]: Epoch 067 - generator training loss: -0.0694, discriminator training loss: 0.1652, validation loss: 0.0254
2024-05-25 02:37:15 [INFO]: Epoch 068 - generator training loss: -0.0673, discriminator training loss: 0.1616, validation loss: 0.0257
2024-05-25 02:37:24 [INFO]: Epoch 069 - generator training loss: -0.0710, discriminator training loss: 0.1602, validation loss: 0.0245
2024-05-25 02:37:33 [INFO]: Epoch 070 - generator training loss: -0.0719, discriminator training loss: 0.1636, validation loss: 0.0244
2024-05-25 02:37:42 [INFO]: Epoch 071 - generator training loss: -0.0702, discriminator training loss: 0.1617, validation loss: 0.0242
2024-05-25 02:37:50 [INFO]: Epoch 072 - generator training loss: -0.0707, discriminator training loss: 0.1622, validation loss: 0.0244
2024-05-25 02:37:59 [INFO]: Epoch 073 - generator training loss: -0.0699, discriminator training loss: 0.1631, validation loss: 0.0239
2024-05-25 02:38:08 [INFO]: Epoch 074 - generator training loss: -0.0729, discriminator training loss: 0.1638, validation loss: 0.0240
2024-05-25 02:38:17 [INFO]: Epoch 075 - generator training loss: -0.0686, discriminator training loss: 0.1615, validation loss: 0.0244
2024-05-25 02:38:26 [INFO]: Epoch 076 - generator training loss: -0.0729, discriminator training loss: 0.1612, validation loss: 0.0237
2024-05-25 02:38:35 [INFO]: Epoch 077 - generator training loss: -0.0708, discriminator training loss: 0.1603, validation loss: 0.0237
2024-05-25 02:38:44 [INFO]: Epoch 078 - generator training loss: -0.0731, discriminator training loss: 0.1633, validation loss: 0.0237
2024-05-25 02:38:53 [INFO]: Epoch 079 - generator training loss: -0.0687, discriminator training loss: 0.1623, validation loss: 0.0234
2024-05-25 02:39:02 [INFO]: Epoch 080 - generator training loss: -0.0711, discriminator training loss: 0.1613, validation loss: 0.0241
2024-05-25 02:39:10 [INFO]: Epoch 081 - generator training loss: -0.0705, discriminator training loss: 0.1612, validation loss: 0.0238
2024-05-25 02:39:19 [INFO]: Epoch 082 - generator training loss: -0.0718, discriminator training loss: 0.1605, validation loss: 0.0232
2024-05-25 02:39:28 [INFO]: Epoch 083 - generator training loss: -0.0699, discriminator training loss: 0.1595, validation loss: 0.0234
2024-05-25 02:39:37 [INFO]: Epoch 084 - generator training loss: -0.0728, discriminator training loss: 0.1607, validation loss: 0.0233
2024-05-25 02:39:46 [INFO]: Epoch 085 - generator training loss: -0.0719, discriminator training loss: 0.1601, validation loss: 0.0231
2024-05-25 02:39:55 [INFO]: Epoch 086 - generator training loss: -0.0709, discriminator training loss: 0.1618, validation loss: 0.0238
2024-05-25 02:40:04 [INFO]: Epoch 087 - generator training loss: -0.0702, discriminator training loss: 0.1622, validation loss: 0.0234
2024-05-25 02:40:13 [INFO]: Epoch 088 - generator training loss: -0.0720, discriminator training loss: 0.1627, validation loss: 0.0234
2024-05-25 02:40:22 [INFO]: Epoch 089 - generator training loss: -0.0704, discriminator training loss: 0.1608, validation loss: 0.0234
2024-05-25 02:40:31 [INFO]: Epoch 090 - generator training loss: -0.0744, discriminator training loss: 0.1611, validation loss: 0.0237
2024-05-25 02:40:39 [INFO]: Epoch 091 - generator training loss: -0.0715, discriminator training loss: 0.1616, validation loss: 0.0234
2024-05-25 02:40:48 [INFO]: Epoch 092 - generator training loss: -0.0747, discriminator training loss: 0.1599, validation loss: 0.0231
2024-05-25 02:40:57 [INFO]: Epoch 093 - generator training loss: -0.0735, discriminator training loss: 0.1641, validation loss: 0.0230
2024-05-25 02:41:06 [INFO]: Epoch 094 - generator training loss: -0.0712, discriminator training loss: 0.1587, validation loss: 0.0231
2024-05-25 02:41:15 [INFO]: Epoch 095 - generator training loss: -0.0759, discriminator training loss: 0.1610, validation loss: 0.0238
2024-05-25 02:41:24 [INFO]: Epoch 096 - generator training loss: -0.0726, discriminator training loss: 0.1599, validation loss: 0.0233
2024-05-25 02:41:33 [INFO]: Epoch 097 - generator training loss: -0.0724, discriminator training loss: 0.1611, validation loss: 0.0232
2024-05-25 02:41:42 [INFO]: Epoch 098 - generator training loss: -0.0730, discriminator training loss: 0.1585, validation loss: 0.0233
2024-05-25 02:41:50 [INFO]: Epoch 099 - generator training loss: -0.0731, discriminator training loss: 0.1596, validation loss: 0.0241
2024-05-25 02:41:59 [INFO]: Epoch 100 - generator training loss: -0.0722, discriminator training loss: 0.1590, validation loss: 0.0230
2024-05-25 02:42:08 [INFO]: Epoch 101 - generator training loss: -0.0714, discriminator training loss: 0.1596, validation loss: 0.0236
2024-05-25 02:42:17 [INFO]: Epoch 102 - generator training loss: -0.0711, discriminator training loss: 0.1610, validation loss: 0.0232
2024-05-25 02:42:26 [INFO]: Epoch 103 - generator training loss: -0.0703, discriminator training loss: 0.1593, validation loss: 0.0227
2024-05-25 02:42:35 [INFO]: Epoch 104 - generator training loss: -0.0732, discriminator training loss: 0.1600, validation loss: 0.0236
2024-05-25 02:42:44 [INFO]: Epoch 105 - generator training loss: -0.0742, discriminator training loss: 0.1604, validation loss: 0.0235
2024-05-25 02:42:53 [INFO]: Epoch 106 - generator training loss: -0.0708, discriminator training loss: 0.1616, validation loss: 0.0234
2024-05-25 02:43:01 [INFO]: Epoch 107 - generator training loss: -0.0725, discriminator training loss: 0.1597, validation loss: 0.0230
2024-05-25 02:43:10 [INFO]: Epoch 108 - generator training loss: -0.0709, discriminator training loss: 0.1619, validation loss: 0.0239
2024-05-25 02:43:19 [INFO]: Epoch 109 - generator training loss: -0.0723, discriminator training loss: 0.1587, validation loss: 0.0233
2024-05-25 02:43:28 [INFO]: Epoch 110 - generator training loss: -0.0735, discriminator training loss: 0.1587, validation loss: 0.0230
2024-05-25 02:43:37 [INFO]: Epoch 111 - generator training loss: -0.0719, discriminator training loss: 0.1606, validation loss: 0.0240
2024-05-25 02:43:45 [INFO]: Epoch 112 - generator training loss: -0.0731, discriminator training loss: 0.1621, validation loss: 0.0236
2024-05-25 02:43:54 [INFO]: Epoch 113 - generator training loss: -0.0737, discriminator training loss: 0.1596, validation loss: 0.0229
2024-05-25 02:43:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:43:54 [INFO]: Finished training. The best model is from epoch#103.
2024-05-25 02:43:54 [INFO]: Saved the model to augmentation_saved_results/round_3/USGAN_ettm1/20240525_T022704/USGAN.pypots
2024-05-25 02:43:55 [INFO]: US-GAN on ETTm1: MAE=0.1670, MSE=0.0715
2024-05-25 02:43:55 [INFO]: Successfully saved to augmentation_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-25 02:43:55 [INFO]: Using the given device: cuda:0
2024-05-25 02:43:55 [INFO]: Model files will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T024355
2024-05-25 02:43:55 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T024355/tensorboard
2024-05-25 02:43:55 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 02:44:03 [INFO]: Epoch 001 - training loss: 1.3462, validation loss: 0.3363
2024-05-25 02:44:09 [INFO]: Epoch 002 - training loss: 0.9319, validation loss: 0.1132
2024-05-25 02:44:15 [INFO]: Epoch 003 - training loss: 0.7436, validation loss: 0.0608
2024-05-25 02:44:20 [INFO]: Epoch 004 - training loss: 0.6599, validation loss: 0.0454
2024-05-25 02:44:26 [INFO]: Epoch 005 - training loss: 0.6125, validation loss: 0.0451
2024-05-25 02:44:32 [INFO]: Epoch 006 - training loss: 0.5890, validation loss: 0.0416
2024-05-25 02:44:38 [INFO]: Epoch 007 - training loss: 0.5642, validation loss: 0.0365
2024-05-25 02:44:44 [INFO]: Epoch 008 - training loss: 0.5349, validation loss: 0.0353
2024-05-25 02:44:50 [INFO]: Epoch 009 - training loss: 0.5067, validation loss: 0.0362
2024-05-25 02:44:56 [INFO]: Epoch 010 - training loss: 0.4975, validation loss: 0.0333
2024-05-25 02:45:01 [INFO]: Epoch 011 - training loss: 0.4912, validation loss: 0.0348
2024-05-25 02:45:07 [INFO]: Epoch 012 - training loss: 0.4804, validation loss: 0.0327
2024-05-25 02:45:13 [INFO]: Epoch 013 - training loss: 0.5157, validation loss: 0.0312
2024-05-25 02:45:19 [INFO]: Epoch 014 - training loss: 0.4570, validation loss: 0.0287
2024-05-25 02:45:25 [INFO]: Epoch 015 - training loss: 0.4429, validation loss: 0.0282
2024-05-25 02:45:31 [INFO]: Epoch 016 - training loss: 0.4302, validation loss: 0.0279
2024-05-25 02:45:37 [INFO]: Epoch 017 - training loss: 0.4215, validation loss: 0.0271
2024-05-25 02:45:43 [INFO]: Epoch 018 - training loss: 0.4209, validation loss: 0.0264
2024-05-25 02:45:49 [INFO]: Epoch 019 - training loss: 0.4080, validation loss: 0.0265
2024-05-25 02:45:55 [INFO]: Epoch 020 - training loss: 0.4082, validation loss: 0.0258
2024-05-25 02:46:01 [INFO]: Epoch 021 - training loss: 0.4097, validation loss: 0.0252
2024-05-25 02:46:07 [INFO]: Epoch 022 - training loss: 0.4102, validation loss: 0.0258
2024-05-25 02:46:13 [INFO]: Epoch 023 - training loss: 0.4044, validation loss: 0.0265
2024-05-25 02:46:19 [INFO]: Epoch 024 - training loss: 0.4040, validation loss: 0.0263
2024-05-25 02:46:25 [INFO]: Epoch 025 - training loss: 0.3954, validation loss: 0.0263
2024-05-25 02:46:31 [INFO]: Epoch 026 - training loss: 0.4140, validation loss: 0.0267
2024-05-25 02:46:37 [INFO]: Epoch 027 - training loss: 0.4045, validation loss: 0.0263
2024-05-25 02:46:43 [INFO]: Epoch 028 - training loss: 0.4083, validation loss: 0.0270
2024-05-25 02:46:49 [INFO]: Epoch 029 - training loss: 0.4000, validation loss: 0.0266
2024-05-25 02:46:55 [INFO]: Epoch 030 - training loss: 0.4073, validation loss: 0.0266
2024-05-25 02:47:00 [INFO]: Epoch 031 - training loss: 0.3993, validation loss: 0.0253
2024-05-25 02:47:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:47:00 [INFO]: Finished training. The best model is from epoch#21.
2024-05-25 02:47:00 [INFO]: Saved the model to augmentation_saved_results/round_3/BRITS_ettm1/20240525_T024355/BRITS.pypots
2024-05-25 02:47:02 [INFO]: BRITS on ETTm1: MAE=0.1436, MSE=0.0636
2024-05-25 02:47:02 [INFO]: Successfully saved to augmentation_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-25 02:47:02 [INFO]: Using the given device: cuda:0
2024-05-25 02:47:02 [INFO]: Model files will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702
2024-05-25 02:47:02 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/tensorboard
2024-05-25 02:47:02 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 02:47:03 [INFO]: Epoch 001 - training loss: 1.3221, validation loss: 1.3465
2024-05-25 02:47:03 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch1_loss1.3464621305465698.pypots
2024-05-25 02:47:04 [INFO]: Epoch 002 - training loss: 0.9811, validation loss: 1.2214
2024-05-25 02:47:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch2_loss1.2214493602514267.pypots
2024-05-25 02:47:04 [INFO]: Epoch 003 - training loss: 0.9326, validation loss: 1.1419
2024-05-25 02:47:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch3_loss1.141855463385582.pypots
2024-05-25 02:47:04 [INFO]: Epoch 004 - training loss: 0.9106, validation loss: 1.1052
2024-05-25 02:47:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch4_loss1.1051797270774841.pypots
2024-05-25 02:47:04 [INFO]: Epoch 005 - training loss: 0.8974, validation loss: 1.0807
2024-05-25 02:47:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch5_loss1.0806892663240433.pypots
2024-05-25 02:47:04 [INFO]: Epoch 006 - training loss: 0.9051, validation loss: 1.0588
2024-05-25 02:47:04 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch6_loss1.05880106985569.pypots
2024-05-25 02:47:05 [INFO]: Epoch 007 - training loss: 0.8640, validation loss: 1.0482
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch7_loss1.048243060708046.pypots
2024-05-25 02:47:05 [INFO]: Epoch 008 - training loss: 0.8867, validation loss: 1.0389
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch8_loss1.0388584434986115.pypots
2024-05-25 02:47:05 [INFO]: Epoch 009 - training loss: 0.8726, validation loss: 1.0345
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch9_loss1.0344735831022263.pypots
2024-05-25 02:47:05 [INFO]: Epoch 010 - training loss: 0.8457, validation loss: 1.0275
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch10_loss1.0275226682424545.pypots
2024-05-25 02:47:05 [INFO]: Epoch 011 - training loss: 0.8574, validation loss: 1.0219
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch11_loss1.0218951851129532.pypots
2024-05-25 02:47:05 [INFO]: Epoch 012 - training loss: 0.8427, validation loss: 1.0188
2024-05-25 02:47:05 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch12_loss1.018832117319107.pypots
2024-05-25 02:47:06 [INFO]: Epoch 013 - training loss: 0.8338, validation loss: 1.0178
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch13_loss1.0177733898162842.pypots
2024-05-25 02:47:06 [INFO]: Epoch 014 - training loss: 0.8312, validation loss: 1.0144
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch14_loss1.014363706111908.pypots
2024-05-25 02:47:06 [INFO]: Epoch 015 - training loss: 0.7959, validation loss: 1.0143
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch15_loss1.0143482983112335.pypots
2024-05-25 02:47:06 [INFO]: Epoch 016 - training loss: 0.8388, validation loss: 1.0128
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch16_loss1.0128391683101654.pypots
2024-05-25 02:47:06 [INFO]: Epoch 017 - training loss: 0.8199, validation loss: 1.0079
2024-05-25 02:47:06 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch17_loss1.007888838648796.pypots
2024-05-25 02:47:07 [INFO]: Epoch 018 - training loss: 0.8118, validation loss: 1.0063
2024-05-25 02:47:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch18_loss1.0063104331493378.pypots
2024-05-25 02:47:07 [INFO]: Epoch 019 - training loss: 0.8229, validation loss: 1.0023
2024-05-25 02:47:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch19_loss1.002281203866005.pypots
2024-05-25 02:47:07 [INFO]: Epoch 020 - training loss: 0.8042, validation loss: 1.0000
2024-05-25 02:47:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch20_loss1.0000101178884506.pypots
2024-05-25 02:47:07 [INFO]: Epoch 021 - training loss: 0.7981, validation loss: 0.9987
2024-05-25 02:47:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch21_loss0.9986667186021805.pypots
2024-05-25 02:47:07 [INFO]: Epoch 022 - training loss: 0.7899, validation loss: 0.9969
2024-05-25 02:47:07 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch22_loss0.9969390630722046.pypots
2024-05-25 02:47:08 [INFO]: Epoch 023 - training loss: 0.7898, validation loss: 0.9946
2024-05-25 02:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch23_loss0.9946134686470032.pypots
2024-05-25 02:47:08 [INFO]: Epoch 024 - training loss: 0.7979, validation loss: 0.9939
2024-05-25 02:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch24_loss0.9938678294420242.pypots
2024-05-25 02:47:08 [INFO]: Epoch 025 - training loss: 0.7706, validation loss: 0.9921
2024-05-25 02:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch25_loss0.9920913875102997.pypots
2024-05-25 02:47:08 [INFO]: Epoch 026 - training loss: 0.7889, validation loss: 0.9907
2024-05-25 02:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch26_loss0.9906608760356903.pypots
2024-05-25 02:47:08 [INFO]: Epoch 027 - training loss: 0.8280, validation loss: 0.9889
2024-05-25 02:47:08 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch27_loss0.9888693243265152.pypots
2024-05-25 02:47:08 [INFO]: Epoch 028 - training loss: 0.7783, validation loss: 0.9853
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch28_loss0.9853339493274689.pypots
2024-05-25 02:47:09 [INFO]: Epoch 029 - training loss: 0.7697, validation loss: 0.9858
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch29_loss0.9857776612043381.pypots
2024-05-25 02:47:09 [INFO]: Epoch 030 - training loss: 0.7773, validation loss: 0.9820
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch30_loss0.9820448011159897.pypots
2024-05-25 02:47:09 [INFO]: Epoch 031 - training loss: 0.7785, validation loss: 0.9811
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch31_loss0.9811401069164276.pypots
2024-05-25 02:47:09 [INFO]: Epoch 032 - training loss: 0.7884, validation loss: 0.9759
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch32_loss0.9759219884872437.pypots
2024-05-25 02:47:09 [INFO]: Epoch 033 - training loss: 0.7605, validation loss: 0.9753
2024-05-25 02:47:09 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch33_loss0.9753125905990601.pypots
2024-05-25 02:47:10 [INFO]: Epoch 034 - training loss: 0.7841, validation loss: 0.9734
2024-05-25 02:47:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch34_loss0.973418191075325.pypots
2024-05-25 02:47:10 [INFO]: Epoch 035 - training loss: 0.7686, validation loss: 0.9723
2024-05-25 02:47:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch35_loss0.972273662686348.pypots
2024-05-25 02:47:10 [INFO]: Epoch 036 - training loss: 0.7573, validation loss: 0.9689
2024-05-25 02:47:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch36_loss0.9688525497913361.pypots
2024-05-25 02:47:10 [INFO]: Epoch 037 - training loss: 0.7658, validation loss: 0.9648
2024-05-25 02:47:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch37_loss0.9648285657167435.pypots
2024-05-25 02:47:10 [INFO]: Epoch 038 - training loss: 0.7561, validation loss: 0.9636
2024-05-25 02:47:10 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch38_loss0.963598906993866.pypots
2024-05-25 02:47:11 [INFO]: Epoch 039 - training loss: 0.7646, validation loss: 0.9610
2024-05-25 02:47:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch39_loss0.9609858840703964.pypots
2024-05-25 02:47:11 [INFO]: Epoch 040 - training loss: 0.7718, validation loss: 0.9599
2024-05-25 02:47:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch40_loss0.9598639458417892.pypots
2024-05-25 02:47:11 [INFO]: Epoch 041 - training loss: 0.7613, validation loss: 0.9605
2024-05-25 02:47:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch41_loss0.9605079889297485.pypots
2024-05-25 02:47:11 [INFO]: Epoch 042 - training loss: 0.7520, validation loss: 0.9549
2024-05-25 02:47:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch42_loss0.954853817820549.pypots
2024-05-25 02:47:11 [INFO]: Epoch 043 - training loss: 0.7407, validation loss: 0.9548
2024-05-25 02:47:11 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch43_loss0.9547701179981232.pypots
2024-05-25 02:47:12 [INFO]: Epoch 044 - training loss: 0.7513, validation loss: 0.9535
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch44_loss0.9535496979951859.pypots
2024-05-25 02:47:12 [INFO]: Epoch 045 - training loss: 0.7675, validation loss: 0.9525
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch45_loss0.9525394886732101.pypots
2024-05-25 02:47:12 [INFO]: Epoch 046 - training loss: 0.7315, validation loss: 0.9479
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch46_loss0.9478516727685928.pypots
2024-05-25 02:47:12 [INFO]: Epoch 047 - training loss: 0.7641, validation loss: 0.9488
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch47_loss0.9487916082143784.pypots
2024-05-25 02:47:12 [INFO]: Epoch 048 - training loss: 0.7520, validation loss: 0.9421
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch48_loss0.9420748651027679.pypots
2024-05-25 02:47:12 [INFO]: Epoch 049 - training loss: 0.7597, validation loss: 0.9455
2024-05-25 02:47:12 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch49_loss0.9454923719167709.pypots
2024-05-25 02:47:13 [INFO]: Epoch 050 - training loss: 0.7511, validation loss: 0.9446
2024-05-25 02:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch50_loss0.9445696622133255.pypots
2024-05-25 02:47:13 [INFO]: Epoch 051 - training loss: 0.7799, validation loss: 0.9427
2024-05-25 02:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch51_loss0.9427493363618851.pypots
2024-05-25 02:47:13 [INFO]: Epoch 052 - training loss: 0.7352, validation loss: 0.9382
2024-05-25 02:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch52_loss0.9382297098636627.pypots
2024-05-25 02:47:13 [INFO]: Epoch 053 - training loss: 0.7432, validation loss: 0.9388
2024-05-25 02:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch53_loss0.9388386458158493.pypots
2024-05-25 02:47:13 [INFO]: Epoch 054 - training loss: 0.7578, validation loss: 0.9381
2024-05-25 02:47:13 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch54_loss0.9381471127271652.pypots
2024-05-25 02:47:14 [INFO]: Epoch 055 - training loss: 0.7530, validation loss: 0.9370
2024-05-25 02:47:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch55_loss0.9370134919881821.pypots
2024-05-25 02:47:14 [INFO]: Epoch 056 - training loss: 0.7333, validation loss: 0.9336
2024-05-25 02:47:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch56_loss0.9336051642894745.pypots
2024-05-25 02:47:14 [INFO]: Epoch 057 - training loss: 0.7520, validation loss: 0.9326
2024-05-25 02:47:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch57_loss0.9326218962669373.pypots
2024-05-25 02:47:14 [INFO]: Epoch 058 - training loss: 0.7467, validation loss: 0.9319
2024-05-25 02:47:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch58_loss0.9319051951169968.pypots
2024-05-25 02:47:14 [INFO]: Epoch 059 - training loss: 0.7252, validation loss: 0.9307
2024-05-25 02:47:14 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch59_loss0.930720642209053.pypots
2024-05-25 02:47:15 [INFO]: Epoch 060 - training loss: 0.7409, validation loss: 0.9314
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch60_loss0.9313863813877106.pypots
2024-05-25 02:47:15 [INFO]: Epoch 061 - training loss: 0.7471, validation loss: 0.9287
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch61_loss0.9286724627017975.pypots
2024-05-25 02:47:15 [INFO]: Epoch 062 - training loss: 0.7573, validation loss: 0.9250
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch62_loss0.9249989539384842.pypots
2024-05-25 02:47:15 [INFO]: Epoch 063 - training loss: 0.7592, validation loss: 0.9244
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch63_loss0.924420490860939.pypots
2024-05-25 02:47:15 [INFO]: Epoch 064 - training loss: 0.7296, validation loss: 0.9266
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch64_loss0.9265928417444229.pypots
2024-05-25 02:47:15 [INFO]: Epoch 065 - training loss: 0.7447, validation loss: 0.9224
2024-05-25 02:47:15 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch65_loss0.9224136173725128.pypots
2024-05-25 02:47:16 [INFO]: Epoch 066 - training loss: 0.7357, validation loss: 0.9218
2024-05-25 02:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch66_loss0.9217993319034576.pypots
2024-05-25 02:47:16 [INFO]: Epoch 067 - training loss: 0.7434, validation loss: 0.9226
2024-05-25 02:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch67_loss0.9225906282663345.pypots
2024-05-25 02:47:16 [INFO]: Epoch 068 - training loss: 0.7496, validation loss: 0.9219
2024-05-25 02:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch68_loss0.9218587279319763.pypots
2024-05-25 02:47:16 [INFO]: Epoch 069 - training loss: 0.7387, validation loss: 0.9191
2024-05-25 02:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch69_loss0.9191492199897766.pypots
2024-05-25 02:47:16 [INFO]: Epoch 070 - training loss: 0.7445, validation loss: 0.9199
2024-05-25 02:47:16 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch70_loss0.9199234545230865.pypots
2024-05-25 02:47:17 [INFO]: Epoch 071 - training loss: 0.7465, validation loss: 0.9206
2024-05-25 02:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch71_loss0.9205841422080994.pypots
2024-05-25 02:47:17 [INFO]: Epoch 072 - training loss: 0.7354, validation loss: 0.9185
2024-05-25 02:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch72_loss0.9185370951890945.pypots
2024-05-25 02:47:17 [INFO]: Epoch 073 - training loss: 0.7285, validation loss: 0.9172
2024-05-25 02:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch73_loss0.9172054976224899.pypots
2024-05-25 02:47:17 [INFO]: Epoch 074 - training loss: 0.7266, validation loss: 0.9156
2024-05-25 02:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch74_loss0.9155602753162384.pypots
2024-05-25 02:47:17 [INFO]: Epoch 075 - training loss: 0.7132, validation loss: 0.9159
2024-05-25 02:47:17 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch75_loss0.9158546924591064.pypots
2024-05-25 02:47:18 [INFO]: Epoch 076 - training loss: 0.7936, validation loss: 0.9154
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch76_loss0.9153947234153748.pypots
2024-05-25 02:47:18 [INFO]: Epoch 077 - training loss: 0.7576, validation loss: 0.9165
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch77_loss0.9164823591709137.pypots
2024-05-25 02:47:18 [INFO]: Epoch 078 - training loss: 0.7361, validation loss: 0.9169
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch78_loss0.9169281125068665.pypots
2024-05-25 02:47:18 [INFO]: Epoch 079 - training loss: 0.7331, validation loss: 0.9157
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch79_loss0.9156681001186371.pypots
2024-05-25 02:47:18 [INFO]: Epoch 080 - training loss: 0.7343, validation loss: 0.9154
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch80_loss0.9153616428375244.pypots
2024-05-25 02:47:18 [INFO]: Epoch 081 - training loss: 0.7117, validation loss: 0.9115
2024-05-25 02:47:18 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch81_loss0.9115248322486877.pypots
2024-05-25 02:47:19 [INFO]: Epoch 082 - training loss: 0.7287, validation loss: 0.9118
2024-05-25 02:47:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch82_loss0.9118078947067261.pypots
2024-05-25 02:47:19 [INFO]: Epoch 083 - training loss: 0.7358, validation loss: 0.9109
2024-05-25 02:47:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch83_loss0.9108802527189255.pypots
2024-05-25 02:47:19 [INFO]: Epoch 084 - training loss: 0.7439, validation loss: 0.9103
2024-05-25 02:47:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch84_loss0.910277709364891.pypots
2024-05-25 02:47:19 [INFO]: Epoch 085 - training loss: 0.7752, validation loss: 0.9097
2024-05-25 02:47:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch85_loss0.909662589430809.pypots
2024-05-25 02:47:19 [INFO]: Epoch 086 - training loss: 0.7219, validation loss: 0.9122
2024-05-25 02:47:19 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch86_loss0.9122306406497955.pypots
2024-05-25 02:47:20 [INFO]: Epoch 087 - training loss: 0.7502, validation loss: 0.9093
2024-05-25 02:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch87_loss0.9092794805765152.pypots
2024-05-25 02:47:20 [INFO]: Epoch 088 - training loss: 0.7464, validation loss: 0.9109
2024-05-25 02:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch88_loss0.9108889102935791.pypots
2024-05-25 02:47:20 [INFO]: Epoch 089 - training loss: 0.7451, validation loss: 0.9082
2024-05-25 02:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch89_loss0.9082014262676239.pypots
2024-05-25 02:47:20 [INFO]: Epoch 090 - training loss: 0.7323, validation loss: 0.9086
2024-05-25 02:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch90_loss0.9085612148046494.pypots
2024-05-25 02:47:20 [INFO]: Epoch 091 - training loss: 0.7405, validation loss: 0.9080
2024-05-25 02:47:20 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch91_loss0.9080102741718292.pypots
2024-05-25 02:47:21 [INFO]: Epoch 092 - training loss: 0.7584, validation loss: 0.9089
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch92_loss0.9088565856218338.pypots
2024-05-25 02:47:21 [INFO]: Epoch 093 - training loss: 0.7288, validation loss: 0.9009
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch93_loss0.9008899033069611.pypots
2024-05-25 02:47:21 [INFO]: Epoch 094 - training loss: 0.7221, validation loss: 0.9052
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch94_loss0.9051719456911087.pypots
2024-05-25 02:47:21 [INFO]: Epoch 095 - training loss: 0.7253, validation loss: 0.9010
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch95_loss0.9010193794965744.pypots
2024-05-25 02:47:21 [INFO]: Epoch 096 - training loss: 0.7138, validation loss: 0.8997
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch96_loss0.8996947407722473.pypots
2024-05-25 02:47:21 [INFO]: Epoch 097 - training loss: 0.7263, validation loss: 0.9021
2024-05-25 02:47:21 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch97_loss0.9021154642105103.pypots
2024-05-25 02:47:22 [INFO]: Epoch 098 - training loss: 0.7461, validation loss: 0.8978
2024-05-25 02:47:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch98_loss0.8978315889835358.pypots
2024-05-25 02:47:22 [INFO]: Epoch 099 - training loss: 0.7417, validation loss: 0.9001
2024-05-25 02:47:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch99_loss0.9000827670097351.pypots
2024-05-25 02:47:22 [INFO]: Epoch 100 - training loss: 0.7136, validation loss: 0.8975
2024-05-25 02:47:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch100_loss0.8974745869636536.pypots
2024-05-25 02:47:22 [INFO]: Epoch 101 - training loss: 0.7380, validation loss: 0.8978
2024-05-25 02:47:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch101_loss0.897786557674408.pypots
2024-05-25 02:47:22 [INFO]: Epoch 102 - training loss: 0.7285, validation loss: 0.8986
2024-05-25 02:47:22 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch102_loss0.8985510915517807.pypots
2024-05-25 02:47:23 [INFO]: Epoch 103 - training loss: 0.7077, validation loss: 0.8941
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch103_loss0.894119992852211.pypots
2024-05-25 02:47:23 [INFO]: Epoch 104 - training loss: 0.7332, validation loss: 0.9010
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch104_loss0.9009633958339691.pypots
2024-05-25 02:47:23 [INFO]: Epoch 105 - training loss: 0.7723, validation loss: 0.8925
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch105_loss0.8925362676382065.pypots
2024-05-25 02:47:23 [INFO]: Epoch 106 - training loss: 0.7724, validation loss: 0.8954
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch106_loss0.8953699916601181.pypots
2024-05-25 02:47:23 [INFO]: Epoch 107 - training loss: 0.7433, validation loss: 0.8942
2024-05-25 02:47:23 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch107_loss0.8942246437072754.pypots
2024-05-25 02:47:24 [INFO]: Epoch 108 - training loss: 0.7406, validation loss: 0.8929
2024-05-25 02:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch108_loss0.892885759472847.pypots
2024-05-25 02:47:24 [INFO]: Epoch 109 - training loss: 0.7239, validation loss: 0.8910
2024-05-25 02:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch109_loss0.891016349196434.pypots
2024-05-25 02:47:24 [INFO]: Epoch 110 - training loss: 0.7237, validation loss: 0.8909
2024-05-25 02:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch110_loss0.8908535689115524.pypots
2024-05-25 02:47:24 [INFO]: Epoch 111 - training loss: 0.7316, validation loss: 0.8879
2024-05-25 02:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch111_loss0.8878788650035858.pypots
2024-05-25 02:47:24 [INFO]: Epoch 112 - training loss: 0.7319, validation loss: 0.8876
2024-05-25 02:47:24 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch112_loss0.887628823518753.pypots
2024-05-25 02:47:24 [INFO]: Epoch 113 - training loss: 0.7188, validation loss: 0.8875
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch113_loss0.8874678462743759.pypots
2024-05-25 02:47:25 [INFO]: Epoch 114 - training loss: 0.7270, validation loss: 0.8847
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch114_loss0.8847236186265945.pypots
2024-05-25 02:47:25 [INFO]: Epoch 115 - training loss: 0.7388, validation loss: 0.8851
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch115_loss0.8850916773080826.pypots
2024-05-25 02:47:25 [INFO]: Epoch 116 - training loss: 0.7196, validation loss: 0.8812
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch116_loss0.8811933100223541.pypots
2024-05-25 02:47:25 [INFO]: Epoch 117 - training loss: 0.7337, validation loss: 0.8842
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch117_loss0.8841789215803146.pypots
2024-05-25 02:47:25 [INFO]: Epoch 118 - training loss: 0.7266, validation loss: 0.8822
2024-05-25 02:47:25 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch118_loss0.8822333067655563.pypots
2024-05-25 02:47:26 [INFO]: Epoch 119 - training loss: 0.7646, validation loss: 0.8807
2024-05-25 02:47:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch119_loss0.8806597590446472.pypots
2024-05-25 02:47:26 [INFO]: Epoch 120 - training loss: 0.7385, validation loss: 0.8776
2024-05-25 02:47:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch120_loss0.8776369094848633.pypots
2024-05-25 02:47:26 [INFO]: Epoch 121 - training loss: 0.7053, validation loss: 0.8796
2024-05-25 02:47:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch121_loss0.8796216696500778.pypots
2024-05-25 02:47:26 [INFO]: Epoch 122 - training loss: 0.7273, validation loss: 0.8784
2024-05-25 02:47:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch122_loss0.8783565610647202.pypots
2024-05-25 02:47:26 [INFO]: Epoch 123 - training loss: 0.7267, validation loss: 0.8758
2024-05-25 02:47:26 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch123_loss0.8758345395326614.pypots
2024-05-25 02:47:27 [INFO]: Epoch 124 - training loss: 0.7206, validation loss: 0.8775
2024-05-25 02:47:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch124_loss0.8774679005146027.pypots
2024-05-25 02:47:27 [INFO]: Epoch 125 - training loss: 0.7190, validation loss: 0.8771
2024-05-25 02:47:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch125_loss0.8770669996738434.pypots
2024-05-25 02:47:27 [INFO]: Epoch 126 - training loss: 0.7158, validation loss: 0.8754
2024-05-25 02:47:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch126_loss0.8754183351993561.pypots
2024-05-25 02:47:27 [INFO]: Epoch 127 - training loss: 0.7357, validation loss: 0.8758
2024-05-25 02:47:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch127_loss0.8758150637149811.pypots
2024-05-25 02:47:27 [INFO]: Epoch 128 - training loss: 0.7198, validation loss: 0.8757
2024-05-25 02:47:27 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch128_loss0.8757115602493286.pypots
2024-05-25 02:47:28 [INFO]: Epoch 129 - training loss: 0.7026, validation loss: 0.8752
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch129_loss0.8751630038022995.pypots
2024-05-25 02:47:28 [INFO]: Epoch 130 - training loss: 0.7614, validation loss: 0.8743
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch130_loss0.8742711842060089.pypots
2024-05-25 02:47:28 [INFO]: Epoch 131 - training loss: 0.7264, validation loss: 0.8712
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch131_loss0.8712210655212402.pypots
2024-05-25 02:47:28 [INFO]: Epoch 132 - training loss: 0.7150, validation loss: 0.8740
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch132_loss0.8739638924598694.pypots
2024-05-25 02:47:28 [INFO]: Epoch 133 - training loss: 0.7267, validation loss: 0.8711
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch133_loss0.8711036443710327.pypots
2024-05-25 02:47:28 [INFO]: Epoch 134 - training loss: 0.7019, validation loss: 0.8740
2024-05-25 02:47:28 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch134_loss0.8739797174930573.pypots
2024-05-25 02:47:29 [INFO]: Epoch 135 - training loss: 0.7382, validation loss: 0.8693
2024-05-25 02:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch135_loss0.8693204969167709.pypots
2024-05-25 02:47:29 [INFO]: Epoch 136 - training loss: 0.7331, validation loss: 0.8695
2024-05-25 02:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch136_loss0.8695456832647324.pypots
2024-05-25 02:47:29 [INFO]: Epoch 137 - training loss: 0.7045, validation loss: 0.8696
2024-05-25 02:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch137_loss0.8696118146181107.pypots
2024-05-25 02:47:29 [INFO]: Epoch 138 - training loss: 0.7265, validation loss: 0.8731
2024-05-25 02:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch138_loss0.8730724602937698.pypots
2024-05-25 02:47:29 [INFO]: Epoch 139 - training loss: 0.6988, validation loss: 0.8721
2024-05-25 02:47:29 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch139_loss0.872092142701149.pypots
2024-05-25 02:47:30 [INFO]: Epoch 140 - training loss: 0.7253, validation loss: 0.8640
2024-05-25 02:47:30 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch140_loss0.8640293180942535.pypots
2024-05-25 02:47:30 [INFO]: Epoch 141 - training loss: 0.7346, validation loss: 0.8655
2024-05-25 02:47:30 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch141_loss0.8654511570930481.pypots
2024-05-25 02:47:30 [INFO]: Epoch 142 - training loss: 0.7255, validation loss: 0.8630
2024-05-25 02:47:30 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch142_loss0.8629935383796692.pypots
2024-05-25 02:47:30 [INFO]: Epoch 143 - training loss: 0.7344, validation loss: 0.8665
2024-05-25 02:47:30 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch143_loss0.8664890825748444.pypots
2024-05-25 02:47:30 [INFO]: Epoch 144 - training loss: 0.7485, validation loss: 0.8647
2024-05-25 02:47:30 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch144_loss0.8646675795316696.pypots
2024-05-25 02:47:31 [INFO]: Epoch 145 - training loss: 0.7345, validation loss: 0.8620
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch145_loss0.8619670569896698.pypots
2024-05-25 02:47:31 [INFO]: Epoch 146 - training loss: 0.7092, validation loss: 0.8624
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch146_loss0.8624291718006134.pypots
2024-05-25 02:47:31 [INFO]: Epoch 147 - training loss: 0.7244, validation loss: 0.8613
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch147_loss0.8613162487745285.pypots
2024-05-25 02:47:31 [INFO]: Epoch 148 - training loss: 0.7456, validation loss: 0.8588
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch148_loss0.8587677031755447.pypots
2024-05-25 02:47:31 [INFO]: Epoch 149 - training loss: 0.7207, validation loss: 0.8589
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch149_loss0.8588741719722748.pypots
2024-05-25 02:47:31 [INFO]: Epoch 150 - training loss: 0.7218, validation loss: 0.8580
2024-05-25 02:47:31 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch150_loss0.8579925298690796.pypots
2024-05-25 02:47:32 [INFO]: Epoch 151 - training loss: 0.7216, validation loss: 0.8587
2024-05-25 02:47:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch151_loss0.8587398380041122.pypots
2024-05-25 02:47:32 [INFO]: Epoch 152 - training loss: 0.7105, validation loss: 0.8579
2024-05-25 02:47:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch152_loss0.8579038381576538.pypots
2024-05-25 02:47:32 [INFO]: Epoch 153 - training loss: 0.7145, validation loss: 0.8598
2024-05-25 02:47:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch153_loss0.8598424047231674.pypots
2024-05-25 02:47:32 [INFO]: Epoch 154 - training loss: 0.6940, validation loss: 0.8560
2024-05-25 02:47:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch154_loss0.8560163378715515.pypots
2024-05-25 02:47:32 [INFO]: Epoch 155 - training loss: 0.7253, validation loss: 0.8565
2024-05-25 02:47:32 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch155_loss0.8565325886011124.pypots
2024-05-25 02:47:33 [INFO]: Epoch 156 - training loss: 0.7189, validation loss: 0.8578
2024-05-25 02:47:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch156_loss0.8578193485736847.pypots
2024-05-25 02:47:33 [INFO]: Epoch 157 - training loss: 0.7337, validation loss: 0.8530
2024-05-25 02:47:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch157_loss0.8529666066169739.pypots
2024-05-25 02:47:33 [INFO]: Epoch 158 - training loss: 0.7260, validation loss: 0.8521
2024-05-25 02:47:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch158_loss0.852120041847229.pypots
2024-05-25 02:47:33 [INFO]: Epoch 159 - training loss: 0.7079, validation loss: 0.8556
2024-05-25 02:47:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch159_loss0.8556191474199295.pypots
2024-05-25 02:47:33 [INFO]: Epoch 160 - training loss: 0.7053, validation loss: 0.8569
2024-05-25 02:47:33 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch160_loss0.8568771779537201.pypots
2024-05-25 02:47:34 [INFO]: Epoch 161 - training loss: 0.7136, validation loss: 0.8564
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch161_loss0.8563729673624039.pypots
2024-05-25 02:47:34 [INFO]: Epoch 162 - training loss: 0.7266, validation loss: 0.8510
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch162_loss0.8509636372327805.pypots
2024-05-25 02:47:34 [INFO]: Epoch 163 - training loss: 0.7245, validation loss: 0.8534
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch163_loss0.8533565551042557.pypots
2024-05-25 02:47:34 [INFO]: Epoch 164 - training loss: 0.7011, validation loss: 0.8539
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch164_loss0.8539281934499741.pypots
2024-05-25 02:47:34 [INFO]: Epoch 165 - training loss: 0.7210, validation loss: 0.8535
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch165_loss0.853543758392334.pypots
2024-05-25 02:47:34 [INFO]: Epoch 166 - training loss: 0.7193, validation loss: 0.8547
2024-05-25 02:47:34 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch166_loss0.8546538352966309.pypots
2024-05-25 02:47:35 [INFO]: Epoch 167 - training loss: 0.7069, validation loss: 0.8512
2024-05-25 02:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch167_loss0.8512125909328461.pypots
2024-05-25 02:47:35 [INFO]: Epoch 168 - training loss: 0.7220, validation loss: 0.8497
2024-05-25 02:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch168_loss0.8497004806995392.pypots
2024-05-25 02:47:35 [INFO]: Epoch 169 - training loss: 0.7240, validation loss: 0.8494
2024-05-25 02:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch169_loss0.8494216799736023.pypots
2024-05-25 02:47:35 [INFO]: Epoch 170 - training loss: 0.7197, validation loss: 0.8461
2024-05-25 02:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch170_loss0.8460809141397476.pypots
2024-05-25 02:47:35 [INFO]: Epoch 171 - training loss: 0.7254, validation loss: 0.8454
2024-05-25 02:47:35 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch171_loss0.8454454094171524.pypots
2024-05-25 02:47:36 [INFO]: Epoch 172 - training loss: 0.7105, validation loss: 0.8463
2024-05-25 02:47:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch172_loss0.8462654054164886.pypots
2024-05-25 02:47:36 [INFO]: Epoch 173 - training loss: 0.7238, validation loss: 0.8490
2024-05-25 02:47:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch173_loss0.8489882797002792.pypots
2024-05-25 02:47:36 [INFO]: Epoch 174 - training loss: 0.7187, validation loss: 0.8498
2024-05-25 02:47:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch174_loss0.8498227596282959.pypots
2024-05-25 02:47:36 [INFO]: Epoch 175 - training loss: 0.7329, validation loss: 0.8514
2024-05-25 02:47:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch175_loss0.8513992577791214.pypots
2024-05-25 02:47:36 [INFO]: Epoch 176 - training loss: 0.7303, validation loss: 0.8452
2024-05-25 02:47:36 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch176_loss0.8451951444149017.pypots
2024-05-25 02:47:37 [INFO]: Epoch 177 - training loss: 0.7272, validation loss: 0.8480
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch177_loss0.8479916751384735.pypots
2024-05-25 02:47:37 [INFO]: Epoch 178 - training loss: 0.6931, validation loss: 0.8475
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch178_loss0.8474545627832413.pypots
2024-05-25 02:47:37 [INFO]: Epoch 179 - training loss: 0.7343, validation loss: 0.8473
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch179_loss0.8472725749015808.pypots
2024-05-25 02:47:37 [INFO]: Epoch 180 - training loss: 0.7121, validation loss: 0.8482
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch180_loss0.8482116907835007.pypots
2024-05-25 02:47:37 [INFO]: Epoch 181 - training loss: 0.7114, validation loss: 0.8432
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch181_loss0.8432372808456421.pypots
2024-05-25 02:47:37 [INFO]: Epoch 182 - training loss: 0.7255, validation loss: 0.8452
2024-05-25 02:47:37 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch182_loss0.8452115952968597.pypots
2024-05-25 02:47:38 [INFO]: Epoch 183 - training loss: 0.7235, validation loss: 0.8435
2024-05-25 02:47:38 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch183_loss0.8435294777154922.pypots
2024-05-25 02:47:38 [INFO]: Epoch 184 - training loss: 0.7413, validation loss: 0.8435
2024-05-25 02:47:38 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch184_loss0.8434839397668839.pypots
2024-05-25 02:47:38 [INFO]: Epoch 185 - training loss: 0.7160, validation loss: 0.8456
2024-05-25 02:47:38 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch185_loss0.8455904573202133.pypots
2024-05-25 02:47:38 [INFO]: Epoch 186 - training loss: 0.7237, validation loss: 0.8406
2024-05-25 02:47:38 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch186_loss0.8405820727348328.pypots
2024-05-25 02:47:38 [INFO]: Epoch 187 - training loss: 0.7308, validation loss: 0.8417
2024-05-25 02:47:38 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch187_loss0.8417342752218246.pypots
2024-05-25 02:47:39 [INFO]: Epoch 188 - training loss: 0.7065, validation loss: 0.8419
2024-05-25 02:47:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch188_loss0.8419470936059952.pypots
2024-05-25 02:47:39 [INFO]: Epoch 189 - training loss: 0.7099, validation loss: 0.8404
2024-05-25 02:47:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch189_loss0.8403551280498505.pypots
2024-05-25 02:47:39 [INFO]: Epoch 190 - training loss: 0.7307, validation loss: 0.8432
2024-05-25 02:47:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch190_loss0.843196764588356.pypots
2024-05-25 02:47:39 [INFO]: Epoch 191 - training loss: 0.7151, validation loss: 0.8384
2024-05-25 02:47:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch191_loss0.8384277671575546.pypots
2024-05-25 02:47:39 [INFO]: Epoch 192 - training loss: 0.7358, validation loss: 0.8397
2024-05-25 02:47:39 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch192_loss0.8397213220596313.pypots
2024-05-25 02:47:40 [INFO]: Epoch 193 - training loss: 0.7025, validation loss: 0.8411
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch193_loss0.841068223118782.pypots
2024-05-25 02:47:40 [INFO]: Epoch 194 - training loss: 0.7010, validation loss: 0.8414
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch194_loss0.8413636088371277.pypots
2024-05-25 02:47:40 [INFO]: Epoch 195 - training loss: 0.6980, validation loss: 0.8408
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch195_loss0.8408405035734177.pypots
2024-05-25 02:47:40 [INFO]: Epoch 196 - training loss: 0.7256, validation loss: 0.8404
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch196_loss0.8404303640127182.pypots
2024-05-25 02:47:40 [INFO]: Epoch 197 - training loss: 0.6979, validation loss: 0.8382
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch197_loss0.8382189720869064.pypots
2024-05-25 02:47:40 [INFO]: Epoch 198 - training loss: 0.7316, validation loss: 0.8389
2024-05-25 02:47:40 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch198_loss0.8389321267604828.pypots
2024-05-25 02:47:41 [INFO]: Epoch 199 - training loss: 0.7276, validation loss: 0.8419
2024-05-25 02:47:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch199_loss0.8418564349412918.pypots
2024-05-25 02:47:41 [INFO]: Epoch 200 - training loss: 0.7215, validation loss: 0.8406
2024-05-25 02:47:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch200_loss0.8405982851982117.pypots
2024-05-25 02:47:41 [INFO]: Epoch 201 - training loss: 0.7274, validation loss: 0.8417
2024-05-25 02:47:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch201_loss0.8416652083396912.pypots
2024-05-25 02:47:41 [INFO]: Epoch 202 - training loss: 0.7361, validation loss: 0.8365
2024-05-25 02:47:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch202_loss0.8364837169647217.pypots
2024-05-25 02:47:41 [INFO]: Epoch 203 - training loss: 0.7255, validation loss: 0.8357
2024-05-25 02:47:41 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch203_loss0.8357004970312119.pypots
2024-05-25 02:47:42 [INFO]: Epoch 204 - training loss: 0.7197, validation loss: 0.8377
2024-05-25 02:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch204_loss0.8376638740301132.pypots
2024-05-25 02:47:42 [INFO]: Epoch 205 - training loss: 0.7223, validation loss: 0.8383
2024-05-25 02:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch205_loss0.838263139128685.pypots
2024-05-25 02:47:42 [INFO]: Epoch 206 - training loss: 0.7105, validation loss: 0.8375
2024-05-25 02:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch206_loss0.8375242799520493.pypots
2024-05-25 02:47:42 [INFO]: Epoch 207 - training loss: 0.7164, validation loss: 0.8375
2024-05-25 02:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch207_loss0.8374790102243423.pypots
2024-05-25 02:47:42 [INFO]: Epoch 208 - training loss: 0.7240, validation loss: 0.8373
2024-05-25 02:47:42 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch208_loss0.8372973799705505.pypots
2024-05-25 02:47:43 [INFO]: Epoch 209 - training loss: 0.7210, validation loss: 0.8353
2024-05-25 02:47:43 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch209_loss0.8353185057640076.pypots
2024-05-25 02:47:43 [INFO]: Epoch 210 - training loss: 0.7156, validation loss: 0.8340
2024-05-25 02:47:43 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch210_loss0.8340370059013367.pypots
2024-05-25 02:47:43 [INFO]: Epoch 211 - training loss: 0.7286, validation loss: 0.8353
2024-05-25 02:47:43 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch211_loss0.8352610617876053.pypots
2024-05-25 02:47:43 [INFO]: Epoch 212 - training loss: 0.6938, validation loss: 0.8374
2024-05-25 02:47:43 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch212_loss0.8374427706003189.pypots
2024-05-25 02:47:43 [INFO]: Epoch 213 - training loss: 0.7028, validation loss: 0.8358
2024-05-25 02:47:43 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch213_loss0.8357892781496048.pypots
2024-05-25 02:47:44 [INFO]: Epoch 214 - training loss: 0.7041, validation loss: 0.8382
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch214_loss0.8381579667329788.pypots
2024-05-25 02:47:44 [INFO]: Epoch 215 - training loss: 0.7216, validation loss: 0.8331
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch215_loss0.8330643177032471.pypots
2024-05-25 02:47:44 [INFO]: Epoch 216 - training loss: 0.7278, validation loss: 0.8339
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch216_loss0.8339203596115112.pypots
2024-05-25 02:47:44 [INFO]: Epoch 217 - training loss: 0.7378, validation loss: 0.8358
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch217_loss0.8358086794614792.pypots
2024-05-25 02:47:44 [INFO]: Epoch 218 - training loss: 0.7247, validation loss: 0.8374
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch218_loss0.837437242269516.pypots
2024-05-25 02:47:44 [INFO]: Epoch 219 - training loss: 0.7144, validation loss: 0.8346
2024-05-25 02:47:44 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch219_loss0.8346329629421234.pypots
2024-05-25 02:47:45 [INFO]: Epoch 220 - training loss: 0.7231, validation loss: 0.8352
2024-05-25 02:47:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch220_loss0.8351562917232513.pypots
2024-05-25 02:47:45 [INFO]: Epoch 221 - training loss: 0.7064, validation loss: 0.8342
2024-05-25 02:47:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch221_loss0.8342221826314926.pypots
2024-05-25 02:47:45 [INFO]: Epoch 222 - training loss: 0.7346, validation loss: 0.8349
2024-05-25 02:47:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch222_loss0.8348975628614426.pypots
2024-05-25 02:47:45 [INFO]: Epoch 223 - training loss: 0.7076, validation loss: 0.8345
2024-05-25 02:47:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch223_loss0.8345246016979218.pypots
2024-05-25 02:47:45 [INFO]: Epoch 224 - training loss: 0.7177, validation loss: 0.8341
2024-05-25 02:47:45 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch224_loss0.8340994417667389.pypots
2024-05-25 02:47:46 [INFO]: Epoch 225 - training loss: 0.6906, validation loss: 0.8321
2024-05-25 02:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch225_loss0.8320800960063934.pypots
2024-05-25 02:47:46 [INFO]: Epoch 226 - training loss: 0.7148, validation loss: 0.8396
2024-05-25 02:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch226_loss0.839573323726654.pypots
2024-05-25 02:47:46 [INFO]: Epoch 227 - training loss: 0.7187, validation loss: 0.8327
2024-05-25 02:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch227_loss0.8326599597930908.pypots
2024-05-25 02:47:46 [INFO]: Epoch 228 - training loss: 0.6973, validation loss: 0.8339
2024-05-25 02:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch228_loss0.8338960707187653.pypots
2024-05-25 02:47:46 [INFO]: Epoch 229 - training loss: 0.7166, validation loss: 0.8346
2024-05-25 02:47:46 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch229_loss0.8345502763986588.pypots
2024-05-25 02:47:47 [INFO]: Epoch 230 - training loss: 0.7159, validation loss: 0.8319
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch230_loss0.8318842798471451.pypots
2024-05-25 02:47:47 [INFO]: Epoch 231 - training loss: 0.6864, validation loss: 0.8311
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch231_loss0.8310576528310776.pypots
2024-05-25 02:47:47 [INFO]: Epoch 232 - training loss: 0.7217, validation loss: 0.8390
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch232_loss0.838969424366951.pypots
2024-05-25 02:47:47 [INFO]: Epoch 233 - training loss: 0.7207, validation loss: 0.8305
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch233_loss0.8305315971374512.pypots
2024-05-25 02:47:47 [INFO]: Epoch 234 - training loss: 0.7060, validation loss: 0.8307
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch234_loss0.8307497650384903.pypots
2024-05-25 02:47:47 [INFO]: Epoch 235 - training loss: 0.7133, validation loss: 0.8316
2024-05-25 02:47:47 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch235_loss0.8316086679697037.pypots
2024-05-25 02:47:48 [INFO]: Epoch 236 - training loss: 0.7261, validation loss: 0.8344
2024-05-25 02:47:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch236_loss0.8344140350818634.pypots
2024-05-25 02:47:48 [INFO]: Epoch 237 - training loss: 0.7031, validation loss: 0.8324
2024-05-25 02:47:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch237_loss0.8323795050382614.pypots
2024-05-25 02:47:48 [INFO]: Epoch 238 - training loss: 0.7224, validation loss: 0.8324
2024-05-25 02:47:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch238_loss0.832371324300766.pypots
2024-05-25 02:47:48 [INFO]: Epoch 239 - training loss: 0.7167, validation loss: 0.8333
2024-05-25 02:47:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch239_loss0.8333333730697632.pypots
2024-05-25 02:47:48 [INFO]: Epoch 240 - training loss: 0.7050, validation loss: 0.8311
2024-05-25 02:47:48 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch240_loss0.8311327993869781.pypots
2024-05-25 02:47:49 [INFO]: Epoch 241 - training loss: 0.7199, validation loss: 0.8333
2024-05-25 02:47:49 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch241_loss0.8332519680261612.pypots
2024-05-25 02:47:49 [INFO]: Epoch 242 - training loss: 0.7117, validation loss: 0.8309
2024-05-25 02:47:49 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch242_loss0.8308905065059662.pypots
2024-05-25 02:47:49 [INFO]: Epoch 243 - training loss: 0.7000, validation loss: 0.8327
2024-05-25 02:47:49 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN_epoch243_loss0.8327102065086365.pypots
2024-05-25 02:47:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:47:49 [INFO]: Finished training. The best model is from epoch#233.
2024-05-25 02:47:49 [INFO]: Saved the model to augmentation_saved_results/round_3/MRNN_ettm1/20240525_T024702/MRNN.pypots
2024-05-25 02:47:49 [INFO]: MRNN on ETTm1: MAE=0.5868, MSE=1.0066
2024-05-25 02:47:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-25 02:47:49 [INFO]: Using the given device: cpu
2024-05-25 02:47:49 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-25 02:47:49 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-25 02:47:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-25 02:47:49 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-25 02:47:49 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-25 02:47:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-25 02:47:49 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-25 02:47:49 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-25 02:47:49 [INFO]: Successfully saved to augmentation_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-25 02:47:49 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 02:47:49 [INFO]: Using the given device: cuda:0
2024-05-25 02:47:49 [INFO]: Model files will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024749
2024-05-25 02:47:49 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024749/tensorboard
2024-05-25 02:47:49 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-25 02:47:50 [INFO]: Epoch 001 - training loss: 1.1998, validation loss: 0.2762
2024-05-25 02:47:50 [INFO]: Epoch 002 - training loss: 0.9503, validation loss: 0.1591
2024-05-25 02:47:51 [INFO]: Epoch 003 - training loss: 0.8360, validation loss: 0.1123
2024-05-25 02:47:52 [INFO]: Epoch 004 - training loss: 0.7859, validation loss: 0.1068
2024-05-25 02:47:52 [INFO]: Epoch 005 - training loss: 0.7390, validation loss: 0.0880
2024-05-25 02:47:53 [INFO]: Epoch 006 - training loss: 0.7151, validation loss: 0.0908
2024-05-25 02:47:53 [INFO]: Epoch 007 - training loss: 0.6901, validation loss: 0.0823
2024-05-25 02:47:54 [INFO]: Epoch 008 - training loss: 0.6768, validation loss: 0.0946
2024-05-25 02:47:54 [INFO]: Epoch 009 - training loss: 0.6605, validation loss: 0.0996
2024-05-25 02:47:55 [INFO]: Epoch 010 - training loss: 0.6596, validation loss: 0.0875
2024-05-25 02:47:55 [INFO]: Epoch 011 - training loss: 0.6469, validation loss: 0.0775
2024-05-25 02:47:56 [INFO]: Epoch 012 - training loss: 0.6463, validation loss: 0.0826
2024-05-25 02:47:56 [INFO]: Epoch 013 - training loss: 0.6278, validation loss: 0.0719
2024-05-25 02:47:57 [INFO]: Epoch 014 - training loss: 0.6124, validation loss: 0.0716
2024-05-25 02:47:57 [INFO]: Epoch 015 - training loss: 0.6274, validation loss: 0.0774
2024-05-25 02:47:58 [INFO]: Epoch 016 - training loss: 0.6118, validation loss: 0.0695
2024-05-25 02:47:58 [INFO]: Epoch 017 - training loss: 0.5909, validation loss: 0.0716
2024-05-25 02:47:59 [INFO]: Epoch 018 - training loss: 0.5926, validation loss: 0.0671
2024-05-25 02:47:59 [INFO]: Epoch 019 - training loss: 0.6049, validation loss: 0.0822
2024-05-25 02:48:00 [INFO]: Epoch 020 - training loss: 0.5988, validation loss: 0.0582
2024-05-25 02:48:00 [INFO]: Epoch 021 - training loss: 0.5767, validation loss: 0.0525
2024-05-25 02:48:01 [INFO]: Epoch 022 - training loss: 0.5677, validation loss: 0.0724
2024-05-25 02:48:01 [INFO]: Epoch 023 - training loss: 0.5967, validation loss: 0.0618
2024-05-25 02:48:02 [INFO]: Epoch 024 - training loss: 0.5601, validation loss: 0.0676
2024-05-25 02:48:02 [INFO]: Epoch 025 - training loss: 0.5704, validation loss: 0.0792
2024-05-25 02:48:03 [INFO]: Epoch 026 - training loss: 0.5777, validation loss: 0.0783
2024-05-25 02:48:03 [INFO]: Epoch 027 - training loss: 0.5560, validation loss: 0.0672
2024-05-25 02:48:04 [INFO]: Epoch 028 - training loss: 0.5611, validation loss: 0.0442
2024-05-25 02:48:04 [INFO]: Epoch 029 - training loss: 0.5460, validation loss: 0.0655
2024-05-25 02:48:05 [INFO]: Epoch 030 - training loss: 0.5634, validation loss: 0.0602
2024-05-25 02:48:05 [INFO]: Epoch 031 - training loss: 0.5438, validation loss: 0.0624
2024-05-25 02:48:06 [INFO]: Epoch 032 - training loss: 0.5242, validation loss: 0.0421
2024-05-25 02:48:06 [INFO]: Epoch 033 - training loss: 0.5267, validation loss: 0.0440
2024-05-25 02:48:07 [INFO]: Epoch 034 - training loss: 0.5160, validation loss: 0.0383
2024-05-25 02:48:07 [INFO]: Epoch 035 - training loss: 0.5265, validation loss: 0.0584
2024-05-25 02:48:08 [INFO]: Epoch 036 - training loss: 0.5142, validation loss: 0.0464
2024-05-25 02:48:08 [INFO]: Epoch 037 - training loss: 0.5070, validation loss: 0.0476
2024-05-25 02:48:09 [INFO]: Epoch 038 - training loss: 0.5049, validation loss: 0.0374
2024-05-25 02:48:09 [INFO]: Epoch 039 - training loss: 0.5083, validation loss: 0.0476
2024-05-25 02:48:10 [INFO]: Epoch 040 - training loss: 0.5290, validation loss: 0.0479
2024-05-25 02:48:10 [INFO]: Epoch 041 - training loss: 0.5276, validation loss: 0.0504
2024-05-25 02:48:11 [INFO]: Epoch 042 - training loss: 0.4955, validation loss: 0.0390
2024-05-25 02:48:11 [INFO]: Epoch 043 - training loss: 0.5210, validation loss: 0.0381
2024-05-25 02:48:12 [INFO]: Epoch 044 - training loss: 0.5100, validation loss: 0.0441
2024-05-25 02:48:12 [INFO]: Epoch 045 - training loss: 0.4942, validation loss: 0.0452
2024-05-25 02:48:13 [INFO]: Epoch 046 - training loss: 0.4827, validation loss: 0.0448
2024-05-25 02:48:13 [INFO]: Epoch 047 - training loss: 0.4800, validation loss: 0.0424
2024-05-25 02:48:14 [INFO]: Epoch 048 - training loss: 0.4850, validation loss: 0.0337
2024-05-25 02:48:14 [INFO]: Epoch 049 - training loss: 0.4719, validation loss: 0.0349
2024-05-25 02:48:15 [INFO]: Epoch 050 - training loss: 0.4770, validation loss: 0.0397
2024-05-25 02:48:15 [INFO]: Epoch 051 - training loss: 0.4896, validation loss: 0.0440
2024-05-25 02:48:16 [INFO]: Epoch 052 - training loss: 0.4754, validation loss: 0.0445
2024-05-25 02:48:17 [INFO]: Epoch 053 - training loss: 0.4680, validation loss: 0.0324
2024-05-25 02:48:17 [INFO]: Epoch 054 - training loss: 0.4783, validation loss: 0.0359
2024-05-25 02:48:18 [INFO]: Epoch 055 - training loss: 0.4715, validation loss: 0.0409
2024-05-25 02:48:18 [INFO]: Epoch 056 - training loss: 0.4703, validation loss: 0.0339
2024-05-25 02:48:19 [INFO]: Epoch 057 - training loss: 0.4587, validation loss: 0.0347
2024-05-25 02:48:19 [INFO]: Epoch 058 - training loss: 0.4577, validation loss: 0.0445
2024-05-25 02:48:20 [INFO]: Epoch 059 - training loss: 0.4662, validation loss: 0.0402
2024-05-25 02:48:20 [INFO]: Epoch 060 - training loss: 0.4574, validation loss: 0.0379
2024-05-25 02:48:21 [INFO]: Epoch 061 - training loss: 0.4552, validation loss: 0.0310
2024-05-25 02:48:21 [INFO]: Epoch 062 - training loss: 0.4425, validation loss: 0.0393
2024-05-25 02:48:22 [INFO]: Epoch 063 - training loss: 0.4430, validation loss: 0.0341
2024-05-25 02:48:22 [INFO]: Epoch 064 - training loss: 0.4448, validation loss: 0.0388
2024-05-25 02:48:23 [INFO]: Epoch 065 - training loss: 0.4320, validation loss: 0.0316
2024-05-25 02:48:23 [INFO]: Epoch 066 - training loss: 0.4401, validation loss: 0.0321
2024-05-25 02:48:24 [INFO]: Epoch 067 - training loss: 0.4325, validation loss: 0.0448
2024-05-25 02:48:24 [INFO]: Epoch 068 - training loss: 0.4330, validation loss: 0.0413
2024-05-25 02:48:25 [INFO]: Epoch 069 - training loss: 0.4277, validation loss: 0.0359
2024-05-25 02:48:25 [INFO]: Epoch 070 - training loss: 0.4261, validation loss: 0.0324
2024-05-25 02:48:26 [INFO]: Epoch 071 - training loss: 0.4206, validation loss: 0.0358
2024-05-25 02:48:26 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:48:26 [INFO]: Finished training. The best model is from epoch#61.
2024-05-25 02:48:26 [INFO]: Saved the model to augmentation_saved_results/round_4/SAITS_ettm1/20240525_T024749/SAITS.pypots
2024-05-25 02:48:26 [INFO]: SAITS on ETTm1: MAE=0.1504, MSE=0.0429
2024-05-25 02:48:26 [INFO]: Successfully saved to augmentation_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-25 02:48:26 [INFO]: Using the given device: cuda:0
2024-05-25 02:48:26 [INFO]: Model files will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024826
2024-05-25 02:48:26 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024826/tensorboard
2024-05-25 02:48:26 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-25 02:48:26 [INFO]: Epoch 001 - training loss: 1.2256, validation loss: 0.4006
2024-05-25 02:48:26 [INFO]: Epoch 002 - training loss: 0.7546, validation loss: 0.1767
2024-05-25 02:48:26 [INFO]: Epoch 003 - training loss: 0.6159, validation loss: 0.1264
2024-05-25 02:48:27 [INFO]: Epoch 004 - training loss: 0.5460, validation loss: 0.0988
2024-05-25 02:48:27 [INFO]: Epoch 005 - training loss: 0.5078, validation loss: 0.0883
2024-05-25 02:48:27 [INFO]: Epoch 006 - training loss: 0.4711, validation loss: 0.0756
2024-05-25 02:48:27 [INFO]: Epoch 007 - training loss: 0.4475, validation loss: 0.0730
2024-05-25 02:48:28 [INFO]: Epoch 008 - training loss: 0.4356, validation loss: 0.0755
2024-05-25 02:48:28 [INFO]: Epoch 009 - training loss: 0.4152, validation loss: 0.0694
2024-05-25 02:48:28 [INFO]: Epoch 010 - training loss: 0.4073, validation loss: 0.0594
2024-05-25 02:48:28 [INFO]: Epoch 011 - training loss: 0.3925, validation loss: 0.0626
2024-05-25 02:48:28 [INFO]: Epoch 012 - training loss: 0.3861, validation loss: 0.0522
2024-05-25 02:48:29 [INFO]: Epoch 013 - training loss: 0.3820, validation loss: 0.0596
2024-05-25 02:48:29 [INFO]: Epoch 014 - training loss: 0.3688, validation loss: 0.0546
2024-05-25 02:48:29 [INFO]: Epoch 015 - training loss: 0.3638, validation loss: 0.0585
2024-05-25 02:48:29 [INFO]: Epoch 016 - training loss: 0.3593, validation loss: 0.0479
2024-05-25 02:48:30 [INFO]: Epoch 017 - training loss: 0.3588, validation loss: 0.0479
2024-05-25 02:48:30 [INFO]: Epoch 018 - training loss: 0.3640, validation loss: 0.0546
2024-05-25 02:48:30 [INFO]: Epoch 019 - training loss: 0.3459, validation loss: 0.0502
2024-05-25 02:48:30 [INFO]: Epoch 020 - training loss: 0.3378, validation loss: 0.0529
2024-05-25 02:48:30 [INFO]: Epoch 021 - training loss: 0.3366, validation loss: 0.0457
2024-05-25 02:48:31 [INFO]: Epoch 022 - training loss: 0.3305, validation loss: 0.0525
2024-05-25 02:48:31 [INFO]: Epoch 023 - training loss: 0.3252, validation loss: 0.0447
2024-05-25 02:48:31 [INFO]: Epoch 024 - training loss: 0.3205, validation loss: 0.0455
2024-05-25 02:48:31 [INFO]: Epoch 025 - training loss: 0.3186, validation loss: 0.0481
2024-05-25 02:48:31 [INFO]: Epoch 026 - training loss: 0.3147, validation loss: 0.0426
2024-05-25 02:48:32 [INFO]: Epoch 027 - training loss: 0.3087, validation loss: 0.0402
2024-05-25 02:48:32 [INFO]: Epoch 028 - training loss: 0.3055, validation loss: 0.0375
2024-05-25 02:48:32 [INFO]: Epoch 029 - training loss: 0.3011, validation loss: 0.0388
2024-05-25 02:48:32 [INFO]: Epoch 030 - training loss: 0.2989, validation loss: 0.0390
2024-05-25 02:48:33 [INFO]: Epoch 031 - training loss: 0.3075, validation loss: 0.0409
2024-05-25 02:48:33 [INFO]: Epoch 032 - training loss: 0.2942, validation loss: 0.0410
2024-05-25 02:48:33 [INFO]: Epoch 033 - training loss: 0.2917, validation loss: 0.0385
2024-05-25 02:48:33 [INFO]: Epoch 034 - training loss: 0.2886, validation loss: 0.0364
2024-05-25 02:48:33 [INFO]: Epoch 035 - training loss: 0.2858, validation loss: 0.0435
2024-05-25 02:48:34 [INFO]: Epoch 036 - training loss: 0.2855, validation loss: 0.0362
2024-05-25 02:48:34 [INFO]: Epoch 037 - training loss: 0.2795, validation loss: 0.0371
2024-05-25 02:48:34 [INFO]: Epoch 038 - training loss: 0.2764, validation loss: 0.0354
2024-05-25 02:48:34 [INFO]: Epoch 039 - training loss: 0.2829, validation loss: 0.0348
2024-05-25 02:48:35 [INFO]: Epoch 040 - training loss: 0.2740, validation loss: 0.0320
2024-05-25 02:48:35 [INFO]: Epoch 041 - training loss: 0.2706, validation loss: 0.0377
2024-05-25 02:48:35 [INFO]: Epoch 042 - training loss: 0.2704, validation loss: 0.0317
2024-05-25 02:48:35 [INFO]: Epoch 043 - training loss: 0.2683, validation loss: 0.0354
2024-05-25 02:48:35 [INFO]: Epoch 044 - training loss: 0.2622, validation loss: 0.0312
2024-05-25 02:48:36 [INFO]: Epoch 045 - training loss: 0.2675, validation loss: 0.0307
2024-05-25 02:48:36 [INFO]: Epoch 046 - training loss: 0.2533, validation loss: 0.0301
2024-05-25 02:48:36 [INFO]: Epoch 047 - training loss: 0.2544, validation loss: 0.0325
2024-05-25 02:48:36 [INFO]: Epoch 048 - training loss: 0.2520, validation loss: 0.0300
2024-05-25 02:48:36 [INFO]: Epoch 049 - training loss: 0.2508, validation loss: 0.0306
2024-05-25 02:48:37 [INFO]: Epoch 050 - training loss: 0.2498, validation loss: 0.0296
2024-05-25 02:48:37 [INFO]: Epoch 051 - training loss: 0.2483, validation loss: 0.0292
2024-05-25 02:48:37 [INFO]: Epoch 052 - training loss: 0.2507, validation loss: 0.0317
2024-05-25 02:48:37 [INFO]: Epoch 053 - training loss: 0.2543, validation loss: 0.0329
2024-05-25 02:48:38 [INFO]: Epoch 054 - training loss: 0.2485, validation loss: 0.0291
2024-05-25 02:48:38 [INFO]: Epoch 055 - training loss: 0.2413, validation loss: 0.0297
2024-05-25 02:48:38 [INFO]: Epoch 056 - training loss: 0.2447, validation loss: 0.0298
2024-05-25 02:48:38 [INFO]: Epoch 057 - training loss: 0.2450, validation loss: 0.0374
2024-05-25 02:48:38 [INFO]: Epoch 058 - training loss: 0.2438, validation loss: 0.0322
2024-05-25 02:48:39 [INFO]: Epoch 059 - training loss: 0.2411, validation loss: 0.0315
2024-05-25 02:48:39 [INFO]: Epoch 060 - training loss: 0.2365, validation loss: 0.0273
2024-05-25 02:48:39 [INFO]: Epoch 061 - training loss: 0.2385, validation loss: 0.0289
2024-05-25 02:48:39 [INFO]: Epoch 062 - training loss: 0.2374, validation loss: 0.0294
2024-05-25 02:48:40 [INFO]: Epoch 063 - training loss: 0.2353, validation loss: 0.0285
2024-05-25 02:48:40 [INFO]: Epoch 064 - training loss: 0.2357, validation loss: 0.0285
2024-05-25 02:48:40 [INFO]: Epoch 065 - training loss: 0.2282, validation loss: 0.0280
2024-05-25 02:48:40 [INFO]: Epoch 066 - training loss: 0.2339, validation loss: 0.0272
2024-05-25 02:48:40 [INFO]: Epoch 067 - training loss: 0.2302, validation loss: 0.0300
2024-05-25 02:48:41 [INFO]: Epoch 068 - training loss: 0.2323, validation loss: 0.0269
2024-05-25 02:48:41 [INFO]: Epoch 069 - training loss: 0.2266, validation loss: 0.0289
2024-05-25 02:48:41 [INFO]: Epoch 070 - training loss: 0.2356, validation loss: 0.0283
2024-05-25 02:48:41 [INFO]: Epoch 071 - training loss: 0.2246, validation loss: 0.0288
2024-05-25 02:48:41 [INFO]: Epoch 072 - training loss: 0.2257, validation loss: 0.0258
2024-05-25 02:48:42 [INFO]: Epoch 073 - training loss: 0.2227, validation loss: 0.0246
2024-05-25 02:48:42 [INFO]: Epoch 074 - training loss: 0.2221, validation loss: 0.0273
2024-05-25 02:48:42 [INFO]: Epoch 075 - training loss: 0.2211, validation loss: 0.0247
2024-05-25 02:48:42 [INFO]: Epoch 076 - training loss: 0.2194, validation loss: 0.0323
2024-05-25 02:48:43 [INFO]: Epoch 077 - training loss: 0.2247, validation loss: 0.0258
2024-05-25 02:48:43 [INFO]: Epoch 078 - training loss: 0.2188, validation loss: 0.0275
2024-05-25 02:48:43 [INFO]: Epoch 079 - training loss: 0.2213, validation loss: 0.0261
2024-05-25 02:48:43 [INFO]: Epoch 080 - training loss: 0.2187, validation loss: 0.0286
2024-05-25 02:48:43 [INFO]: Epoch 081 - training loss: 0.2309, validation loss: 0.0279
2024-05-25 02:48:44 [INFO]: Epoch 082 - training loss: 0.2216, validation loss: 0.0273
2024-05-25 02:48:44 [INFO]: Epoch 083 - training loss: 0.2146, validation loss: 0.0259
2024-05-25 02:48:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:48:44 [INFO]: Finished training. The best model is from epoch#73.
2024-05-25 02:48:44 [INFO]: Saved the model to augmentation_saved_results/round_4/Transformer_ettm1/20240525_T024826/Transformer.pypots
2024-05-25 02:48:44 [INFO]: Transformer on ETTm1: MAE=0.1477, MSE=0.0413
2024-05-25 02:48:44 [INFO]: Successfully saved to augmentation_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-25 02:48:44 [INFO]: Using the given device: cuda:0
2024-05-25 02:48:44 [INFO]: Model files will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024844
2024-05-25 02:48:44 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024844/tensorboard
2024-05-25 02:48:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-25 02:48:44 [INFO]: Epoch 001 - training loss: 0.1626, validation loss: 0.0570
2024-05-25 02:48:45 [INFO]: Epoch 002 - training loss: 0.0779, validation loss: 0.0458
2024-05-25 02:48:45 [INFO]: Epoch 003 - training loss: 0.0587, validation loss: 0.0410
2024-05-25 02:48:45 [INFO]: Epoch 004 - training loss: 0.0574, validation loss: 0.0379
2024-05-25 02:48:45 [INFO]: Epoch 005 - training loss: 0.0622, validation loss: 0.0385
2024-05-25 02:48:45 [INFO]: Epoch 006 - training loss: 0.0569, validation loss: 0.0373
2024-05-25 02:48:46 [INFO]: Epoch 007 - training loss: 0.0560, validation loss: 0.0365
2024-05-25 02:48:46 [INFO]: Epoch 008 - training loss: 0.0530, validation loss: 0.0327
2024-05-25 02:48:46 [INFO]: Epoch 009 - training loss: 0.0525, validation loss: 0.0354
2024-05-25 02:48:46 [INFO]: Epoch 010 - training loss: 0.0532, validation loss: 0.0376
2024-05-25 02:48:46 [INFO]: Epoch 011 - training loss: 0.0542, validation loss: 0.0365
2024-05-25 02:48:47 [INFO]: Epoch 012 - training loss: 0.0502, validation loss: 0.0330
2024-05-25 02:48:47 [INFO]: Epoch 013 - training loss: 0.0511, validation loss: 0.0337
2024-05-25 02:48:47 [INFO]: Epoch 014 - training loss: 0.0548, validation loss: 0.0324
2024-05-25 02:48:47 [INFO]: Epoch 015 - training loss: 0.0524, validation loss: 0.0323
2024-05-25 02:48:47 [INFO]: Epoch 016 - training loss: 0.0510, validation loss: 0.0324
2024-05-25 02:48:48 [INFO]: Epoch 017 - training loss: 0.0536, validation loss: 0.0351
2024-05-25 02:48:48 [INFO]: Epoch 018 - training loss: 0.0563, validation loss: 0.0354
2024-05-25 02:48:48 [INFO]: Epoch 019 - training loss: 0.0480, validation loss: 0.0336
2024-05-25 02:48:48 [INFO]: Epoch 020 - training loss: 0.0504, validation loss: 0.0362
2024-05-25 02:48:49 [INFO]: Epoch 021 - training loss: 0.0577, validation loss: 0.0339
2024-05-25 02:48:49 [INFO]: Epoch 022 - training loss: 0.0495, validation loss: 0.0316
2024-05-25 02:48:49 [INFO]: Epoch 023 - training loss: 0.0484, validation loss: 0.0322
2024-05-25 02:48:49 [INFO]: Epoch 024 - training loss: 0.0515, validation loss: 0.0334
2024-05-25 02:48:49 [INFO]: Epoch 025 - training loss: 0.0522, validation loss: 0.0320
2024-05-25 02:48:50 [INFO]: Epoch 026 - training loss: 0.0561, validation loss: 0.0350
2024-05-25 02:48:50 [INFO]: Epoch 027 - training loss: 0.0511, validation loss: 0.0316
2024-05-25 02:48:50 [INFO]: Epoch 028 - training loss: 0.0476, validation loss: 0.0323
2024-05-25 02:48:50 [INFO]: Epoch 029 - training loss: 0.0486, validation loss: 0.0318
2024-05-25 02:48:50 [INFO]: Epoch 030 - training loss: 0.0459, validation loss: 0.0292
2024-05-25 02:48:51 [INFO]: Epoch 031 - training loss: 0.0465, validation loss: 0.0313
2024-05-25 02:48:51 [INFO]: Epoch 032 - training loss: 0.0439, validation loss: 0.0309
2024-05-25 02:48:51 [INFO]: Epoch 033 - training loss: 0.0461, validation loss: 0.0300
2024-05-25 02:48:51 [INFO]: Epoch 034 - training loss: 0.0447, validation loss: 0.0289
2024-05-25 02:48:51 [INFO]: Epoch 035 - training loss: 0.0423, validation loss: 0.0289
2024-05-25 02:48:52 [INFO]: Epoch 036 - training loss: 0.0429, validation loss: 0.0298
2024-05-25 02:48:52 [INFO]: Epoch 037 - training loss: 0.0442, validation loss: 0.0282
2024-05-25 02:48:52 [INFO]: Epoch 038 - training loss: 0.0411, validation loss: 0.0289
2024-05-25 02:48:52 [INFO]: Epoch 039 - training loss: 0.0432, validation loss: 0.0289
2024-05-25 02:48:53 [INFO]: Epoch 040 - training loss: 0.0504, validation loss: 0.0339
2024-05-25 02:48:53 [INFO]: Epoch 041 - training loss: 0.0559, validation loss: 0.0353
2024-05-25 02:48:53 [INFO]: Epoch 042 - training loss: 0.0479, validation loss: 0.0311
2024-05-25 02:48:53 [INFO]: Epoch 043 - training loss: 0.0462, validation loss: 0.0315
2024-05-25 02:48:53 [INFO]: Epoch 044 - training loss: 0.0455, validation loss: 0.0293
2024-05-25 02:48:54 [INFO]: Epoch 045 - training loss: 0.0438, validation loss: 0.0369
2024-05-25 02:48:54 [INFO]: Epoch 046 - training loss: 0.0470, validation loss: 0.0323
2024-05-25 02:48:54 [INFO]: Epoch 047 - training loss: 0.0407, validation loss: 0.0291
2024-05-25 02:48:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:48:54 [INFO]: Finished training. The best model is from epoch#37.
2024-05-25 02:48:54 [INFO]: Saved the model to augmentation_saved_results/round_4/TimesNet_ettm1/20240525_T024844/TimesNet.pypots
2024-05-25 02:48:54 [INFO]: TimesNet on ETTm1: MAE=0.1235, MSE=0.0317
2024-05-25 02:48:54 [INFO]: Successfully saved to augmentation_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-25 02:48:54 [INFO]: Using the given device: cuda:0
2024-05-25 02:48:54 [INFO]: Model files will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854
2024-05-25 02:48:54 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/tensorboard
2024-05-25 02:48:54 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-25 02:48:56 [INFO]: Epoch 001 - training loss: 0.6854, validation loss: 0.4296
2024-05-25 02:48:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch1_loss0.429623082280159.pypots
2024-05-25 02:48:58 [INFO]: Epoch 002 - training loss: 0.3629, validation loss: 0.3687
2024-05-25 02:48:58 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch2_loss0.3687126263976097.pypots
2024-05-25 02:49:00 [INFO]: Epoch 003 - training loss: 0.3727, validation loss: 0.3386
2024-05-25 02:49:00 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch3_loss0.3385736271739006.pypots
2024-05-25 02:49:02 [INFO]: Epoch 004 - training loss: 0.3787, validation loss: 0.3738
2024-05-25 02:49:02 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch4_loss0.37380121648311615.pypots
2024-05-25 02:49:04 [INFO]: Epoch 005 - training loss: 0.3635, validation loss: 0.3383
2024-05-25 02:49:04 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch5_loss0.33829543739557266.pypots
2024-05-25 02:49:07 [INFO]: Epoch 006 - training loss: 0.2968, validation loss: 0.3031
2024-05-25 02:49:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch6_loss0.30307626724243164.pypots
2024-05-25 02:49:09 [INFO]: Epoch 007 - training loss: 0.2768, validation loss: 0.2916
2024-05-25 02:49:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch7_loss0.29157064110040665.pypots
2024-05-25 02:49:11 [INFO]: Epoch 008 - training loss: 0.2592, validation loss: 0.2984
2024-05-25 02:49:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch8_loss0.2983599379658699.pypots
2024-05-25 02:49:13 [INFO]: Epoch 009 - training loss: 0.2858, validation loss: 0.2836
2024-05-25 02:49:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch9_loss0.2835826203227043.pypots
2024-05-25 02:49:15 [INFO]: Epoch 010 - training loss: 0.3058, validation loss: 0.2663
2024-05-25 02:49:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch10_loss0.2662668451666832.pypots
2024-05-25 02:49:17 [INFO]: Epoch 011 - training loss: 0.2697, validation loss: 0.2716
2024-05-25 02:49:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch11_loss0.2715774178504944.pypots
2024-05-25 02:49:19 [INFO]: Epoch 012 - training loss: 0.2172, validation loss: 0.2642
2024-05-25 02:49:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch12_loss0.2642189636826515.pypots
2024-05-25 02:49:21 [INFO]: Epoch 013 - training loss: 0.2467, validation loss: 0.2641
2024-05-25 02:49:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch13_loss0.26410920172929764.pypots
2024-05-25 02:49:23 [INFO]: Epoch 014 - training loss: 0.2371, validation loss: 0.2443
2024-05-25 02:49:23 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch14_loss0.24429645761847496.pypots
2024-05-25 02:49:25 [INFO]: Epoch 015 - training loss: 0.2369, validation loss: 0.2404
2024-05-25 02:49:25 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch15_loss0.24037661403417587.pypots
2024-05-25 02:49:27 [INFO]: Epoch 016 - training loss: 0.2135, validation loss: 0.2094
2024-05-25 02:49:27 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch16_loss0.20936661586165428.pypots
2024-05-25 02:49:29 [INFO]: Epoch 017 - training loss: 0.2284, validation loss: 0.2223
2024-05-25 02:49:29 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch17_loss0.2222970686852932.pypots
2024-05-25 02:49:31 [INFO]: Epoch 018 - training loss: 0.2202, validation loss: 0.2201
2024-05-25 02:49:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch18_loss0.2200935333967209.pypots
2024-05-25 02:49:34 [INFO]: Epoch 019 - training loss: 0.2683, validation loss: 0.2348
2024-05-25 02:49:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch19_loss0.23475965484976768.pypots
2024-05-25 02:49:36 [INFO]: Epoch 020 - training loss: 0.2296, validation loss: 0.2321
2024-05-25 02:49:36 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch20_loss0.23205891996622086.pypots
2024-05-25 02:49:38 [INFO]: Epoch 021 - training loss: 0.2568, validation loss: 0.2072
2024-05-25 02:49:38 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch21_loss0.20724238455295563.pypots
2024-05-25 02:49:40 [INFO]: Epoch 022 - training loss: 0.2207, validation loss: 0.2094
2024-05-25 02:49:40 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch22_loss0.20944855362176895.pypots
2024-05-25 02:49:42 [INFO]: Epoch 023 - training loss: 0.2380, validation loss: 0.2150
2024-05-25 02:49:42 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch23_loss0.21503307670354843.pypots
2024-05-25 02:49:44 [INFO]: Epoch 024 - training loss: 0.2322, validation loss: 0.2060
2024-05-25 02:49:44 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch24_loss0.20602503046393394.pypots
2024-05-25 02:49:46 [INFO]: Epoch 025 - training loss: 0.2273, validation loss: 0.2011
2024-05-25 02:49:46 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch25_loss0.20109053328633308.pypots
2024-05-25 02:49:48 [INFO]: Epoch 026 - training loss: 0.2016, validation loss: 0.2036
2024-05-25 02:49:48 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch26_loss0.2036251462996006.pypots
2024-05-25 02:49:50 [INFO]: Epoch 027 - training loss: 0.2453, validation loss: 0.2066
2024-05-25 02:49:50 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch27_loss0.2066415548324585.pypots
2024-05-25 02:49:52 [INFO]: Epoch 028 - training loss: 0.2399, validation loss: 0.2058
2024-05-25 02:49:52 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch28_loss0.20579897239804268.pypots
2024-05-25 02:49:54 [INFO]: Epoch 029 - training loss: 0.2450, validation loss: 0.1914
2024-05-25 02:49:54 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch29_loss0.19142238050699234.pypots
2024-05-25 02:49:56 [INFO]: Epoch 030 - training loss: 0.2381, validation loss: 0.2003
2024-05-25 02:49:56 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch30_loss0.20031870901584625.pypots
2024-05-25 02:49:59 [INFO]: Epoch 031 - training loss: 0.2628, validation loss: 0.2050
2024-05-25 02:49:59 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch31_loss0.20496908202767372.pypots
2024-05-25 02:50:01 [INFO]: Epoch 032 - training loss: 0.2444, validation loss: 0.1954
2024-05-25 02:50:01 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch32_loss0.1953674629330635.pypots
2024-05-25 02:50:03 [INFO]: Epoch 033 - training loss: 0.2154, validation loss: 0.1874
2024-05-25 02:50:03 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch33_loss0.18742816150188446.pypots
2024-05-25 02:50:05 [INFO]: Epoch 034 - training loss: 0.1826, validation loss: 0.1799
2024-05-25 02:50:05 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch34_loss0.17985526472330093.pypots
2024-05-25 02:50:07 [INFO]: Epoch 035 - training loss: 0.2130, validation loss: 0.1722
2024-05-25 02:50:07 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch35_loss0.17219903320074081.pypots
2024-05-25 02:50:09 [INFO]: Epoch 036 - training loss: 0.1679, validation loss: 0.1712
2024-05-25 02:50:09 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch36_loss0.17123345285654068.pypots
2024-05-25 02:50:11 [INFO]: Epoch 037 - training loss: 0.2003, validation loss: 0.1698
2024-05-25 02:50:11 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch37_loss0.1698087900876999.pypots
2024-05-25 02:50:13 [INFO]: Epoch 038 - training loss: 0.2233, validation loss: 0.1637
2024-05-25 02:50:13 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch38_loss0.16365064680576324.pypots
2024-05-25 02:50:15 [INFO]: Epoch 039 - training loss: 0.2272, validation loss: 0.1933
2024-05-25 02:50:15 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch39_loss0.19332792237401009.pypots
2024-05-25 02:50:17 [INFO]: Epoch 040 - training loss: 0.2243, validation loss: 0.1878
2024-05-25 02:50:17 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch40_loss0.18778109550476074.pypots
2024-05-25 02:50:19 [INFO]: Epoch 041 - training loss: 0.1720, validation loss: 0.1713
2024-05-25 02:50:19 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch41_loss0.17129447683691978.pypots
2024-05-25 02:50:21 [INFO]: Epoch 042 - training loss: 0.2030, validation loss: 0.1719
2024-05-25 02:50:21 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch42_loss0.1718793325126171.pypots
2024-05-25 02:50:24 [INFO]: Epoch 043 - training loss: 0.1771, validation loss: 0.1691
2024-05-25 02:50:24 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch43_loss0.1691219098865986.pypots
2024-05-25 02:50:26 [INFO]: Epoch 044 - training loss: 0.1914, validation loss: 0.2072
2024-05-25 02:50:26 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch44_loss0.20721253380179405.pypots
2024-05-25 02:50:28 [INFO]: Epoch 045 - training loss: 0.2305, validation loss: 0.1908
2024-05-25 02:50:28 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch45_loss0.1907738782465458.pypots
2024-05-25 02:50:30 [INFO]: Epoch 046 - training loss: 0.1669, validation loss: 0.1729
2024-05-25 02:50:30 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch46_loss0.172939270734787.pypots
2024-05-25 02:50:32 [INFO]: Epoch 047 - training loss: 0.2026, validation loss: 0.1739
2024-05-25 02:50:32 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch47_loss0.17385956645011902.pypots
2024-05-25 02:50:34 [INFO]: Epoch 048 - training loss: 0.2099, validation loss: 0.1696
2024-05-25 02:50:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI_epoch48_loss0.16959787160158157.pypots
2024-05-25 02:50:34 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:50:34 [INFO]: Finished training. The best model is from epoch#38.
2024-05-25 02:50:34 [INFO]: Saved the model to augmentation_saved_results/round_4/CSDI_ettm1/20240525_T024854/CSDI.pypots
2024-05-25 02:50:50 [INFO]: CSDI on ETTm1: MAE=0.2218, MSE=0.3168
2024-05-25 02:50:50 [INFO]: Successfully saved to augmentation_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-25 02:50:50 [INFO]: Using the given device: cuda:0
2024-05-25 02:50:50 [INFO]: Model files will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T025050
2024-05-25 02:50:50 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T025050/tensorboard
2024-05-25 02:50:50 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-25 02:50:50 [INFO]: Epoch 001 - training loss: 23979.7506, validation loss: 0.9670
2024-05-25 02:50:50 [INFO]: Epoch 002 - training loss: 22195.1478, validation loss: 0.9582
2024-05-25 02:50:50 [INFO]: Epoch 003 - training loss: 20379.8356, validation loss: 0.9512
2024-05-25 02:50:50 [INFO]: Epoch 004 - training loss: 18556.7371, validation loss: 0.9395
2024-05-25 02:50:51 [INFO]: Epoch 005 - training loss: 16492.0880, validation loss: 0.9186
2024-05-25 02:50:51 [INFO]: Epoch 006 - training loss: 14779.3784, validation loss: 0.8693
2024-05-25 02:50:51 [INFO]: Epoch 007 - training loss: 13487.5577, validation loss: 0.7953
2024-05-25 02:50:51 [INFO]: Epoch 008 - training loss: 12521.7216, validation loss: 0.7076
2024-05-25 02:50:51 [INFO]: Epoch 009 - training loss: 11747.3535, validation loss: 0.6449
2024-05-25 02:50:51 [INFO]: Epoch 010 - training loss: 11171.7181, validation loss: 0.5907
2024-05-25 02:50:51 [INFO]: Epoch 011 - training loss: 10864.8379, validation loss: 0.5557
2024-05-25 02:50:51 [INFO]: Epoch 012 - training loss: 10569.6622, validation loss: 0.5438
2024-05-25 02:50:52 [INFO]: Epoch 013 - training loss: 10430.8804, validation loss: 0.5211
2024-05-25 02:50:52 [INFO]: Epoch 014 - training loss: 10289.4457, validation loss: 0.4994
2024-05-25 02:50:52 [INFO]: Epoch 015 - training loss: 10087.8579, validation loss: 0.4852
2024-05-25 02:50:52 [INFO]: Epoch 016 - training loss: 10143.1605, validation loss: 0.4617
2024-05-25 02:50:52 [INFO]: Epoch 017 - training loss: 9916.5536, validation loss: 0.4462
2024-05-25 02:50:52 [INFO]: Epoch 018 - training loss: 9856.3810, validation loss: 0.4198
2024-05-25 02:50:52 [INFO]: Epoch 019 - training loss: 9754.9562, validation loss: 0.4040
2024-05-25 02:50:52 [INFO]: Epoch 020 - training loss: 9706.9466, validation loss: 0.3894
2024-05-25 02:50:53 [INFO]: Epoch 021 - training loss: 9664.1635, validation loss: 0.3682
2024-05-25 02:50:53 [INFO]: Epoch 022 - training loss: 9625.3407, validation loss: 0.3478
2024-05-25 02:50:53 [INFO]: Epoch 023 - training loss: 9596.2594, validation loss: 0.3387
2024-05-25 02:50:53 [INFO]: Epoch 024 - training loss: 9569.8973, validation loss: 0.3256
2024-05-25 02:50:53 [INFO]: Epoch 025 - training loss: 9614.0439, validation loss: 0.3083
2024-05-25 02:50:53 [INFO]: Epoch 026 - training loss: 9518.9483, validation loss: 0.3154
2024-05-25 02:50:53 [INFO]: Epoch 027 - training loss: 9497.5262, validation loss: 0.3069
2024-05-25 02:50:53 [INFO]: Epoch 028 - training loss: 9476.8301, validation loss: 0.2970
2024-05-25 02:50:54 [INFO]: Epoch 029 - training loss: 9499.0721, validation loss: 0.2938
2024-05-25 02:50:54 [INFO]: Epoch 030 - training loss: 9438.9139, validation loss: 0.2915
2024-05-25 02:50:54 [INFO]: Epoch 031 - training loss: 9426.6157, validation loss: 0.2867
2024-05-25 02:50:54 [INFO]: Epoch 032 - training loss: 9422.2347, validation loss: 0.2801
2024-05-25 02:50:54 [INFO]: Epoch 033 - training loss: 9407.2245, validation loss: 0.2755
2024-05-25 02:50:54 [INFO]: Epoch 034 - training loss: 9396.1064, validation loss: 0.2659
2024-05-25 02:50:54 [INFO]: Epoch 035 - training loss: 9432.4080, validation loss: 0.2610
2024-05-25 02:50:54 [INFO]: Epoch 036 - training loss: 9369.1836, validation loss: 0.2582
2024-05-25 02:50:55 [INFO]: Epoch 037 - training loss: 9400.6611, validation loss: 0.2542
2024-05-25 02:50:55 [INFO]: Epoch 038 - training loss: 9360.0298, validation loss: 0.2492
2024-05-25 02:50:55 [INFO]: Epoch 039 - training loss: 9354.4779, validation loss: 0.2446
2024-05-25 02:50:55 [INFO]: Epoch 040 - training loss: 9345.3383, validation loss: 0.2423
2024-05-25 02:50:55 [INFO]: Epoch 041 - training loss: 9335.9808, validation loss: 0.2395
2024-05-25 02:50:55 [INFO]: Epoch 042 - training loss: 9329.4670, validation loss: 0.2358
2024-05-25 02:50:55 [INFO]: Epoch 043 - training loss: 9325.9426, validation loss: 0.2334
2024-05-25 02:50:55 [INFO]: Epoch 044 - training loss: 9328.1218, validation loss: 0.2281
2024-05-25 02:50:56 [INFO]: Epoch 045 - training loss: 9314.9692, validation loss: 0.2255
2024-05-25 02:50:56 [INFO]: Epoch 046 - training loss: 9334.4465, validation loss: 0.2221
2024-05-25 02:50:56 [INFO]: Epoch 047 - training loss: 9309.3924, validation loss: 0.2193
2024-05-25 02:50:56 [INFO]: Epoch 048 - training loss: 9307.3964, validation loss: 0.2169
2024-05-25 02:50:56 [INFO]: Epoch 049 - training loss: 9309.3758, validation loss: 0.2152
2024-05-25 02:50:56 [INFO]: Epoch 050 - training loss: 9306.9196, validation loss: 0.2096
2024-05-25 02:50:56 [INFO]: Epoch 051 - training loss: 9297.6227, validation loss: 0.2061
2024-05-25 02:50:57 [INFO]: Epoch 052 - training loss: 9294.5222, validation loss: 0.2027
2024-05-25 02:50:57 [INFO]: Epoch 053 - training loss: 9294.3565, validation loss: 0.1992
2024-05-25 02:50:57 [INFO]: Epoch 054 - training loss: 9294.3967, validation loss: 0.1961
2024-05-25 02:50:57 [INFO]: Epoch 055 - training loss: 9288.8549, validation loss: 0.1921
2024-05-25 02:50:57 [INFO]: Epoch 056 - training loss: 9284.9297, validation loss: 0.1917
2024-05-25 02:50:57 [INFO]: Epoch 057 - training loss: 9278.6727, validation loss: 0.1876
2024-05-25 02:50:57 [INFO]: Epoch 058 - training loss: 9276.8104, validation loss: 0.1832
2024-05-25 02:50:57 [INFO]: Epoch 059 - training loss: 9274.6653, validation loss: 0.1823
2024-05-25 02:50:58 [INFO]: Epoch 060 - training loss: 9277.4925, validation loss: 0.1789
2024-05-25 02:50:58 [INFO]: Epoch 061 - training loss: 9272.5400, validation loss: 0.1742
2024-05-25 02:50:58 [INFO]: Epoch 062 - training loss: 9272.8904, validation loss: 0.1705
2024-05-25 02:50:58 [INFO]: Epoch 063 - training loss: 9270.8214, validation loss: 0.1699
2024-05-25 02:50:58 [INFO]: Epoch 064 - training loss: 9265.4910, validation loss: 0.1668
2024-05-25 02:50:58 [INFO]: Epoch 065 - training loss: 9266.5859, validation loss: 0.1638
2024-05-25 02:50:58 [INFO]: Epoch 066 - training loss: 9263.9584, validation loss: 0.1623
2024-05-25 02:50:58 [INFO]: Epoch 067 - training loss: 9261.9078, validation loss: 0.1581
2024-05-25 02:50:59 [INFO]: Epoch 068 - training loss: 9262.7656, validation loss: 0.1567
2024-05-25 02:50:59 [INFO]: Epoch 069 - training loss: 9258.8800, validation loss: 0.1553
2024-05-25 02:50:59 [INFO]: Epoch 070 - training loss: 9256.6009, validation loss: 0.1540
2024-05-25 02:50:59 [INFO]: Epoch 071 - training loss: 9259.9295, validation loss: 0.1531
2024-05-25 02:50:59 [INFO]: Epoch 072 - training loss: 9255.1759, validation loss: 0.1516
2024-05-25 02:50:59 [INFO]: Epoch 073 - training loss: 9252.7358, validation loss: 0.1498
2024-05-25 02:50:59 [INFO]: Epoch 074 - training loss: 9250.3759, validation loss: 0.1488
2024-05-25 02:50:59 [INFO]: Epoch 075 - training loss: 9252.7662, validation loss: 0.1479
2024-05-25 02:51:00 [INFO]: Epoch 076 - training loss: 9250.0654, validation loss: 0.1473
2024-05-25 02:51:00 [INFO]: Epoch 077 - training loss: 9254.9328, validation loss: 0.1435
2024-05-25 02:51:00 [INFO]: Epoch 078 - training loss: 9249.2542, validation loss: 0.1440
2024-05-25 02:51:00 [INFO]: Epoch 079 - training loss: 9246.4310, validation loss: 0.1411
2024-05-25 02:51:00 [INFO]: Epoch 080 - training loss: 9248.1602, validation loss: 0.1426
2024-05-25 02:51:00 [INFO]: Epoch 081 - training loss: 9247.4097, validation loss: 0.1416
2024-05-25 02:51:00 [INFO]: Epoch 082 - training loss: 9243.1204, validation loss: 0.1404
2024-05-25 02:51:00 [INFO]: Epoch 083 - training loss: 9243.6186, validation loss: 0.1390
2024-05-25 02:51:01 [INFO]: Epoch 084 - training loss: 9244.5887, validation loss: 0.1378
2024-05-25 02:51:01 [INFO]: Epoch 085 - training loss: 9242.0098, validation loss: 0.1376
2024-05-25 02:51:01 [INFO]: Epoch 086 - training loss: 9241.2999, validation loss: 0.1363
2024-05-25 02:51:01 [INFO]: Epoch 087 - training loss: 9243.2861, validation loss: 0.1352
2024-05-25 02:51:01 [INFO]: Epoch 088 - training loss: 9240.7601, validation loss: 0.1350
2024-05-25 02:51:01 [INFO]: Epoch 089 - training loss: 9238.6441, validation loss: 0.1313
2024-05-25 02:51:01 [INFO]: Epoch 090 - training loss: 9238.6850, validation loss: 0.1321
2024-05-25 02:51:01 [INFO]: Epoch 091 - training loss: 9236.5551, validation loss: 0.1318
2024-05-25 02:51:02 [INFO]: Epoch 092 - training loss: 9240.5145, validation loss: 0.1326
2024-05-25 02:51:02 [INFO]: Epoch 093 - training loss: 9238.3640, validation loss: 0.1302
2024-05-25 02:51:02 [INFO]: Epoch 094 - training loss: 9236.0012, validation loss: 0.1293
2024-05-25 02:51:02 [INFO]: Epoch 095 - training loss: 9235.4642, validation loss: 0.1285
2024-05-25 02:51:02 [INFO]: Epoch 096 - training loss: 9234.5220, validation loss: 0.1285
2024-05-25 02:51:02 [INFO]: Epoch 097 - training loss: 9237.5265, validation loss: 0.1257
2024-05-25 02:51:02 [INFO]: Epoch 098 - training loss: 9236.3010, validation loss: 0.1264
2024-05-25 02:51:03 [INFO]: Epoch 099 - training loss: 9235.8344, validation loss: 0.1264
2024-05-25 02:51:03 [INFO]: Epoch 100 - training loss: 9232.9033, validation loss: 0.1244
2024-05-25 02:51:03 [INFO]: Epoch 101 - training loss: 9233.8682, validation loss: 0.1248
2024-05-25 02:51:03 [INFO]: Epoch 102 - training loss: 9232.6442, validation loss: 0.1234
2024-05-25 02:51:03 [INFO]: Epoch 103 - training loss: 9231.3205, validation loss: 0.1214
2024-05-25 02:51:03 [INFO]: Epoch 104 - training loss: 9231.8547, validation loss: 0.1218
2024-05-25 02:51:03 [INFO]: Epoch 105 - training loss: 9232.2043, validation loss: 0.1211
2024-05-25 02:51:03 [INFO]: Epoch 106 - training loss: 9230.4061, validation loss: 0.1208
2024-05-25 02:51:04 [INFO]: Epoch 107 - training loss: 9230.1102, validation loss: 0.1202
2024-05-25 02:51:04 [INFO]: Epoch 108 - training loss: 9230.9614, validation loss: 0.1194
2024-05-25 02:51:04 [INFO]: Epoch 109 - training loss: 9227.8884, validation loss: 0.1188
2024-05-25 02:51:04 [INFO]: Epoch 110 - training loss: 9228.0427, validation loss: 0.1202
2024-05-25 02:51:04 [INFO]: Epoch 111 - training loss: 9228.5354, validation loss: 0.1182
2024-05-25 02:51:04 [INFO]: Epoch 112 - training loss: 9229.0951, validation loss: 0.1187
2024-05-25 02:51:04 [INFO]: Epoch 113 - training loss: 9228.9264, validation loss: 0.1152
2024-05-25 02:51:04 [INFO]: Epoch 114 - training loss: 9228.1203, validation loss: 0.1221
2024-05-25 02:51:05 [INFO]: Epoch 115 - training loss: 9227.3274, validation loss: 0.1169
2024-05-25 02:51:05 [INFO]: Epoch 116 - training loss: 9229.3245, validation loss: 0.1153
2024-05-25 02:51:05 [INFO]: Epoch 117 - training loss: 9226.6802, validation loss: 0.1157
2024-05-25 02:51:05 [INFO]: Epoch 118 - training loss: 9225.9113, validation loss: 0.1150
2024-05-25 02:51:05 [INFO]: Epoch 119 - training loss: 9226.6923, validation loss: 0.1144
2024-05-25 02:51:05 [INFO]: Epoch 120 - training loss: 9226.1838, validation loss: 0.1122
2024-05-25 02:51:05 [INFO]: Epoch 121 - training loss: 9225.7341, validation loss: 0.1125
2024-05-25 02:51:05 [INFO]: Epoch 122 - training loss: 9224.8636, validation loss: 0.1126
2024-05-25 02:51:06 [INFO]: Epoch 123 - training loss: 9225.4510, validation loss: 0.1122
2024-05-25 02:51:06 [INFO]: Epoch 124 - training loss: 9224.2551, validation loss: 0.1111
2024-05-25 02:51:06 [INFO]: Epoch 125 - training loss: 9222.8453, validation loss: 0.1114
2024-05-25 02:51:06 [INFO]: Epoch 126 - training loss: 9223.6866, validation loss: 0.1093
2024-05-25 02:51:06 [INFO]: Epoch 127 - training loss: 9224.4697, validation loss: 0.1101
2024-05-25 02:51:06 [INFO]: Epoch 128 - training loss: 9223.3313, validation loss: 0.1093
2024-05-25 02:51:06 [INFO]: Epoch 129 - training loss: 9223.6105, validation loss: 0.1084
2024-05-25 02:51:06 [INFO]: Epoch 130 - training loss: 9226.3116, validation loss: 0.1089
2024-05-25 02:51:07 [INFO]: Epoch 131 - training loss: 9222.5826, validation loss: 0.1101
2024-05-25 02:51:07 [INFO]: Epoch 132 - training loss: 9222.1299, validation loss: 0.1068
2024-05-25 02:51:07 [INFO]: Epoch 133 - training loss: 9222.6189, validation loss: 0.1063
2024-05-25 02:51:07 [INFO]: Epoch 134 - training loss: 9222.1794, validation loss: 0.1074
2024-05-25 02:51:07 [INFO]: Epoch 135 - training loss: 9221.4749, validation loss: 0.1059
2024-05-25 02:51:07 [INFO]: Epoch 136 - training loss: 9225.3871, validation loss: 0.1056
2024-05-25 02:51:07 [INFO]: Epoch 137 - training loss: 9221.2308, validation loss: 0.1061
2024-05-25 02:51:07 [INFO]: Epoch 138 - training loss: 9219.5892, validation loss: 0.1051
2024-05-25 02:51:08 [INFO]: Epoch 139 - training loss: 9219.1343, validation loss: 0.1042
2024-05-25 02:51:08 [INFO]: Epoch 140 - training loss: 9218.4653, validation loss: 0.1050
2024-05-25 02:51:08 [INFO]: Epoch 141 - training loss: 9218.2837, validation loss: 0.1041
2024-05-25 02:51:08 [INFO]: Epoch 142 - training loss: 9218.6738, validation loss: 0.1048
2024-05-25 02:51:08 [INFO]: Epoch 143 - training loss: 9218.5317, validation loss: 0.1041
2024-05-25 02:51:08 [INFO]: Epoch 144 - training loss: 9218.9681, validation loss: 0.1042
2024-05-25 02:51:08 [INFO]: Epoch 145 - training loss: 9220.2250, validation loss: 0.1021
2024-05-25 02:51:08 [INFO]: Epoch 146 - training loss: 9219.2252, validation loss: 0.1014
2024-05-25 02:51:09 [INFO]: Epoch 147 - training loss: 9219.6699, validation loss: 0.1027
2024-05-25 02:51:09 [INFO]: Epoch 148 - training loss: 9218.5847, validation loss: 0.1011
2024-05-25 02:51:09 [INFO]: Epoch 149 - training loss: 9217.5726, validation loss: 0.1021
2024-05-25 02:51:09 [INFO]: Epoch 150 - training loss: 9217.8947, validation loss: 0.1014
2024-05-25 02:51:09 [INFO]: Epoch 151 - training loss: 9217.4917, validation loss: 0.1013
2024-05-25 02:51:09 [INFO]: Epoch 152 - training loss: 9217.2308, validation loss: 0.1005
2024-05-25 02:51:09 [INFO]: Epoch 153 - training loss: 9218.3679, validation loss: 0.0982
2024-05-25 02:51:10 [INFO]: Epoch 154 - training loss: 9215.2375, validation loss: 0.1020
2024-05-25 02:51:10 [INFO]: Epoch 155 - training loss: 9218.1572, validation loss: 0.0986
2024-05-25 02:51:10 [INFO]: Epoch 156 - training loss: 9216.3817, validation loss: 0.0975
2024-05-25 02:51:10 [INFO]: Epoch 157 - training loss: 9216.2638, validation loss: 0.0981
2024-05-25 02:51:10 [INFO]: Epoch 158 - training loss: 9217.6821, validation loss: 0.0999
2024-05-25 02:51:10 [INFO]: Epoch 159 - training loss: 9215.8724, validation loss: 0.0966
2024-05-25 02:51:10 [INFO]: Epoch 160 - training loss: 9214.9451, validation loss: 0.0982
2024-05-25 02:51:10 [INFO]: Epoch 161 - training loss: 9215.3297, validation loss: 0.0988
2024-05-25 02:51:11 [INFO]: Epoch 162 - training loss: 9216.2731, validation loss: 0.0974
2024-05-25 02:51:11 [INFO]: Epoch 163 - training loss: 9213.9906, validation loss: 0.0969
2024-05-25 02:51:11 [INFO]: Epoch 164 - training loss: 9214.2263, validation loss: 0.0972
2024-05-25 02:51:11 [INFO]: Epoch 165 - training loss: 9216.3536, validation loss: 0.0980
2024-05-25 02:51:11 [INFO]: Epoch 166 - training loss: 9215.1566, validation loss: 0.0983
2024-05-25 02:51:11 [INFO]: Epoch 167 - training loss: 9213.4225, validation loss: 0.0985
2024-05-25 02:51:11 [INFO]: Epoch 168 - training loss: 9215.1389, validation loss: 0.0969
2024-05-25 02:51:11 [INFO]: Epoch 169 - training loss: 9213.5223, validation loss: 0.0946
2024-05-25 02:51:12 [INFO]: Epoch 170 - training loss: 9216.4072, validation loss: 0.0945
2024-05-25 02:51:12 [INFO]: Epoch 171 - training loss: 9214.3109, validation loss: 0.0936
2024-05-25 02:51:12 [INFO]: Epoch 172 - training loss: 9215.8969, validation loss: 0.0955
2024-05-25 02:51:12 [INFO]: Epoch 173 - training loss: 9213.6915, validation loss: 0.0933
2024-05-25 02:51:12 [INFO]: Epoch 174 - training loss: 9214.3121, validation loss: 0.0952
2024-05-25 02:51:12 [INFO]: Epoch 175 - training loss: 9213.8380, validation loss: 0.0941
2024-05-25 02:51:12 [INFO]: Epoch 176 - training loss: 9213.3388, validation loss: 0.0952
2024-05-25 02:51:12 [INFO]: Epoch 177 - training loss: 9214.3717, validation loss: 0.0947
2024-05-25 02:51:13 [INFO]: Epoch 178 - training loss: 9211.9175, validation loss: 0.0950
2024-05-25 02:51:13 [INFO]: Epoch 179 - training loss: 9212.3198, validation loss: 0.0944
2024-05-25 02:51:13 [INFO]: Epoch 180 - training loss: 9213.2304, validation loss: 0.0934
2024-05-25 02:51:13 [INFO]: Epoch 181 - training loss: 9212.0728, validation loss: 0.0912
2024-05-25 02:51:13 [INFO]: Epoch 182 - training loss: 9212.2710, validation loss: 0.0928
2024-05-25 02:51:13 [INFO]: Epoch 183 - training loss: 9212.1553, validation loss: 0.0947
2024-05-25 02:51:13 [INFO]: Epoch 184 - training loss: 9213.0290, validation loss: 0.0930
2024-05-25 02:51:13 [INFO]: Epoch 185 - training loss: 9210.8760, validation loss: 0.0925
2024-05-25 02:51:14 [INFO]: Epoch 186 - training loss: 9211.2629, validation loss: 0.0923
2024-05-25 02:51:14 [INFO]: Epoch 187 - training loss: 9215.6148, validation loss: 0.0905
2024-05-25 02:51:14 [INFO]: Epoch 188 - training loss: 9212.1828, validation loss: 0.0933
2024-05-25 02:51:14 [INFO]: Epoch 189 - training loss: 9212.3655, validation loss: 0.0914
2024-05-25 02:51:14 [INFO]: Epoch 190 - training loss: 9214.2534, validation loss: 0.0926
2024-05-25 02:51:14 [INFO]: Epoch 191 - training loss: 9211.9134, validation loss: 0.0904
2024-05-25 02:51:14 [INFO]: Epoch 192 - training loss: 9211.6376, validation loss: 0.0929
2024-05-25 02:51:14 [INFO]: Epoch 193 - training loss: 9212.4164, validation loss: 0.0921
2024-05-25 02:51:15 [INFO]: Epoch 194 - training loss: 9210.8179, validation loss: 0.0941
2024-05-25 02:51:15 [INFO]: Epoch 195 - training loss: 9211.3395, validation loss: 0.0929
2024-05-25 02:51:15 [INFO]: Epoch 196 - training loss: 9211.2998, validation loss: 0.0917
2024-05-25 02:51:15 [INFO]: Epoch 197 - training loss: 9213.6210, validation loss: 0.0900
2024-05-25 02:51:15 [INFO]: Epoch 198 - training loss: 9210.6086, validation loss: 0.0891
2024-05-25 02:51:15 [INFO]: Epoch 199 - training loss: 9210.0017, validation loss: 0.0920
2024-05-25 02:51:15 [INFO]: Epoch 200 - training loss: 9212.8270, validation loss: 0.0908
2024-05-25 02:51:15 [INFO]: Epoch 201 - training loss: 9210.6236, validation loss: 0.0905
2024-05-25 02:51:16 [INFO]: Epoch 202 - training loss: 9210.9510, validation loss: 0.0902
2024-05-25 02:51:16 [INFO]: Epoch 203 - training loss: 9210.6588, validation loss: 0.0903
2024-05-25 02:51:16 [INFO]: Epoch 204 - training loss: 9210.8252, validation loss: 0.0893
2024-05-25 02:51:16 [INFO]: Epoch 205 - training loss: 9211.5544, validation loss: 0.0918
2024-05-25 02:51:16 [INFO]: Epoch 206 - training loss: 9211.2858, validation loss: 0.0914
2024-05-25 02:51:16 [INFO]: Epoch 207 - training loss: 9212.3183, validation loss: 0.0887
2024-05-25 02:51:16 [INFO]: Epoch 208 - training loss: 9211.4159, validation loss: 0.0922
2024-05-25 02:51:17 [INFO]: Epoch 209 - training loss: 9211.5883, validation loss: 0.0891
2024-05-25 02:51:17 [INFO]: Epoch 210 - training loss: 9210.3002, validation loss: 0.0904
2024-05-25 02:51:17 [INFO]: Epoch 211 - training loss: 9210.0635, validation loss: 0.0909
2024-05-25 02:51:17 [INFO]: Epoch 212 - training loss: 9210.5977, validation loss: 0.0875
2024-05-25 02:51:17 [INFO]: Epoch 213 - training loss: 9210.4013, validation loss: 0.0882
2024-05-25 02:51:17 [INFO]: Epoch 214 - training loss: 9209.5303, validation loss: 0.0875
2024-05-25 02:51:17 [INFO]: Epoch 215 - training loss: 9210.4523, validation loss: 0.0877
2024-05-25 02:51:17 [INFO]: Epoch 216 - training loss: 9208.6860, validation loss: 0.0866
2024-05-25 02:51:18 [INFO]: Epoch 217 - training loss: 9210.3983, validation loss: 0.0876
2024-05-25 02:51:18 [INFO]: Epoch 218 - training loss: 9209.1855, validation loss: 0.0874
2024-05-25 02:51:18 [INFO]: Epoch 219 - training loss: 9209.3518, validation loss: 0.0876
2024-05-25 02:51:18 [INFO]: Epoch 220 - training loss: 9209.8254, validation loss: 0.0905
2024-05-25 02:51:18 [INFO]: Epoch 221 - training loss: 9208.9162, validation loss: 0.0870
2024-05-25 02:51:18 [INFO]: Epoch 222 - training loss: 9210.8025, validation loss: 0.0880
2024-05-25 02:51:18 [INFO]: Epoch 223 - training loss: 9209.8450, validation loss: 0.0854
2024-05-25 02:51:18 [INFO]: Epoch 224 - training loss: 9209.4649, validation loss: 0.0877
2024-05-25 02:51:19 [INFO]: Epoch 225 - training loss: 9210.4163, validation loss: 0.0882
2024-05-25 02:51:19 [INFO]: Epoch 226 - training loss: 9207.9573, validation loss: 0.0865
2024-05-25 02:51:19 [INFO]: Epoch 227 - training loss: 9208.5789, validation loss: 0.0890
2024-05-25 02:51:19 [INFO]: Epoch 228 - training loss: 9209.6699, validation loss: 0.0864
2024-05-25 02:51:19 [INFO]: Epoch 229 - training loss: 9208.9147, validation loss: 0.0857
2024-05-25 02:51:19 [INFO]: Epoch 230 - training loss: 9208.2592, validation loss: 0.0874
2024-05-25 02:51:19 [INFO]: Epoch 231 - training loss: 9209.6849, validation loss: 0.0870
2024-05-25 02:51:19 [INFO]: Epoch 232 - training loss: 9209.8927, validation loss: 0.0848
2024-05-25 02:51:20 [INFO]: Epoch 233 - training loss: 9209.9026, validation loss: 0.0835
2024-05-25 02:51:20 [INFO]: Epoch 234 - training loss: 9208.7740, validation loss: 0.0866
2024-05-25 02:51:20 [INFO]: Epoch 235 - training loss: 9208.2131, validation loss: 0.0881
2024-05-25 02:51:20 [INFO]: Epoch 236 - training loss: 9207.5934, validation loss: 0.0866
2024-05-25 02:51:20 [INFO]: Epoch 237 - training loss: 9209.3641, validation loss: 0.0880
2024-05-25 02:51:20 [INFO]: Epoch 238 - training loss: 9208.1821, validation loss: 0.0848
2024-05-25 02:51:20 [INFO]: Epoch 239 - training loss: 9207.9156, validation loss: 0.0853
2024-05-25 02:51:20 [INFO]: Epoch 240 - training loss: 9209.9846, validation loss: 0.0883
2024-05-25 02:51:21 [INFO]: Epoch 241 - training loss: 9212.8435, validation loss: 0.0882
2024-05-25 02:51:21 [INFO]: Epoch 242 - training loss: 9207.4414, validation loss: 0.0879
2024-05-25 02:51:21 [INFO]: Epoch 243 - training loss: 9208.9189, validation loss: 0.0872
2024-05-25 02:51:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:51:21 [INFO]: Finished training. The best model is from epoch#233.
2024-05-25 02:51:21 [INFO]: Saved the model to augmentation_saved_results/round_4/GPVAE_ettm1/20240525_T025050/GPVAE.pypots
2024-05-25 02:51:21 [INFO]: GP-VAE on ETTm1: MAE=0.3004, MSE=0.1899
2024-05-25 02:51:21 [INFO]: Successfully saved to augmentation_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-25 02:51:21 [INFO]: Using the given device: cuda:0
2024-05-25 02:51:21 [INFO]: Model files will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T025121
2024-05-25 02:51:21 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T025121/tensorboard
2024-05-25 02:51:21 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-25 02:51:32 [INFO]: Epoch 001 - generator training loss: 0.4799, discriminator training loss: 0.5425, validation loss: 0.3541
2024-05-25 02:51:41 [INFO]: Epoch 002 - generator training loss: -0.0425, discriminator training loss: 0.4754, validation loss: 0.1257
2024-05-25 02:51:49 [INFO]: Epoch 003 - generator training loss: -0.1538, discriminator training loss: 0.4324, validation loss: 0.0779
2024-05-25 02:51:58 [INFO]: Epoch 004 - generator training loss: -0.1479, discriminator training loss: 0.3709, validation loss: 0.0589
2024-05-25 02:52:07 [INFO]: Epoch 005 - generator training loss: -0.1064, discriminator training loss: 0.2943, validation loss: 0.0532
2024-05-25 02:52:16 [INFO]: Epoch 006 - generator training loss: -0.0744, discriminator training loss: 0.2346, validation loss: 0.0457
2024-05-25 02:52:25 [INFO]: Epoch 007 - generator training loss: -0.0598, discriminator training loss: 0.2012, validation loss: 0.0423
2024-05-25 02:52:34 [INFO]: Epoch 008 - generator training loss: -0.0553, discriminator training loss: 0.1845, validation loss: 0.0402
2024-05-25 02:52:43 [INFO]: Epoch 009 - generator training loss: -0.0562, discriminator training loss: 0.1810, validation loss: 0.0389
2024-05-25 02:52:52 [INFO]: Epoch 010 - generator training loss: -0.0550, discriminator training loss: 0.1788, validation loss: 0.0384
2024-05-25 02:53:01 [INFO]: Epoch 011 - generator training loss: -0.0551, discriminator training loss: 0.1761, validation loss: 0.0378
2024-05-25 02:53:10 [INFO]: Epoch 012 - generator training loss: -0.0513, discriminator training loss: 0.1754, validation loss: 0.0378
2024-05-25 02:53:19 [INFO]: Epoch 013 - generator training loss: -0.0542, discriminator training loss: 0.1726, validation loss: 0.0367
2024-05-25 02:53:28 [INFO]: Epoch 014 - generator training loss: -0.0536, discriminator training loss: 0.1724, validation loss: 0.0359
2024-05-25 02:53:37 [INFO]: Epoch 015 - generator training loss: -0.0564, discriminator training loss: 0.1727, validation loss: 0.0359
2024-05-25 02:53:46 [INFO]: Epoch 016 - generator training loss: -0.0529, discriminator training loss: 0.1730, validation loss: 0.0362
2024-05-25 02:53:55 [INFO]: Epoch 017 - generator training loss: -0.0555, discriminator training loss: 0.1726, validation loss: 0.0356
2024-05-25 02:54:04 [INFO]: Epoch 018 - generator training loss: -0.0530, discriminator training loss: 0.1737, validation loss: 0.0358
2024-05-25 02:54:13 [INFO]: Epoch 019 - generator training loss: -0.0572, discriminator training loss: 0.1701, validation loss: 0.0353
2024-05-25 02:54:22 [INFO]: Epoch 020 - generator training loss: -0.0578, discriminator training loss: 0.1711, validation loss: 0.0345
2024-05-25 02:54:31 [INFO]: Epoch 021 - generator training loss: -0.0537, discriminator training loss: 0.1697, validation loss: 0.0360
2024-05-25 02:54:40 [INFO]: Epoch 022 - generator training loss: -0.0551, discriminator training loss: 0.1717, validation loss: 0.0339
2024-05-25 02:54:49 [INFO]: Epoch 023 - generator training loss: -0.0587, discriminator training loss: 0.1681, validation loss: 0.0350
2024-05-25 02:54:58 [INFO]: Epoch 024 - generator training loss: -0.0575, discriminator training loss: 0.1695, validation loss: 0.0344
2024-05-25 02:55:07 [INFO]: Epoch 025 - generator training loss: -0.0573, discriminator training loss: 0.1687, validation loss: 0.0338
2024-05-25 02:55:16 [INFO]: Epoch 026 - generator training loss: -0.0596, discriminator training loss: 0.1679, validation loss: 0.0340
2024-05-25 02:55:25 [INFO]: Epoch 027 - generator training loss: -0.0597, discriminator training loss: 0.1705, validation loss: 0.0335
2024-05-25 02:55:34 [INFO]: Epoch 028 - generator training loss: -0.0584, discriminator training loss: 0.1688, validation loss: 0.0351
2024-05-25 02:55:43 [INFO]: Epoch 029 - generator training loss: -0.0565, discriminator training loss: 0.1682, validation loss: 0.0353
2024-05-25 02:55:52 [INFO]: Epoch 030 - generator training loss: -0.0540, discriminator training loss: 0.1708, validation loss: 0.0330
2024-05-25 02:56:01 [INFO]: Epoch 031 - generator training loss: -0.0579, discriminator training loss: 0.1713, validation loss: 0.0340
2024-05-25 02:56:10 [INFO]: Epoch 032 - generator training loss: -0.0596, discriminator training loss: 0.1659, validation loss: 0.0327
2024-05-25 02:56:19 [INFO]: Epoch 033 - generator training loss: -0.0620, discriminator training loss: 0.1666, validation loss: 0.0331
2024-05-25 02:56:28 [INFO]: Epoch 034 - generator training loss: -0.0588, discriminator training loss: 0.1666, validation loss: 0.0338
2024-05-25 02:56:37 [INFO]: Epoch 035 - generator training loss: -0.0610, discriminator training loss: 0.1672, validation loss: 0.0329
2024-05-25 02:56:46 [INFO]: Epoch 036 - generator training loss: -0.0532, discriminator training loss: 0.1681, validation loss: 0.0329
2024-05-25 02:56:55 [INFO]: Epoch 037 - generator training loss: -0.0625, discriminator training loss: 0.1679, validation loss: 0.0330
2024-05-25 02:57:04 [INFO]: Epoch 038 - generator training loss: -0.0610, discriminator training loss: 0.1690, validation loss: 0.0316
2024-05-25 02:57:13 [INFO]: Epoch 039 - generator training loss: -0.0603, discriminator training loss: 0.1689, validation loss: 0.0317
2024-05-25 02:57:22 [INFO]: Epoch 040 - generator training loss: -0.0603, discriminator training loss: 0.1685, validation loss: 0.0324
2024-05-25 02:57:31 [INFO]: Epoch 041 - generator training loss: -0.0611, discriminator training loss: 0.1666, validation loss: 0.0340
2024-05-25 02:57:40 [INFO]: Epoch 042 - generator training loss: -0.0650, discriminator training loss: 0.1669, validation loss: 0.0309
2024-05-25 02:57:49 [INFO]: Epoch 043 - generator training loss: -0.0611, discriminator training loss: 0.1659, validation loss: 0.0312
2024-05-25 02:57:58 [INFO]: Epoch 044 - generator training loss: -0.0647, discriminator training loss: 0.1661, validation loss: 0.0311
2024-05-25 02:58:07 [INFO]: Epoch 045 - generator training loss: -0.0637, discriminator training loss: 0.1666, validation loss: 0.0305
2024-05-25 02:58:16 [INFO]: Epoch 046 - generator training loss: -0.0623, discriminator training loss: 0.1664, validation loss: 0.0300
2024-05-25 02:58:25 [INFO]: Epoch 047 - generator training loss: -0.0617, discriminator training loss: 0.1669, validation loss: 0.0297
2024-05-25 02:58:33 [INFO]: Epoch 048 - generator training loss: -0.0650, discriminator training loss: 0.1666, validation loss: 0.0295
2024-05-25 02:58:42 [INFO]: Epoch 049 - generator training loss: -0.0651, discriminator training loss: 0.1677, validation loss: 0.0288
2024-05-25 02:58:51 [INFO]: Epoch 050 - generator training loss: -0.0665, discriminator training loss: 0.1671, validation loss: 0.0292
2024-05-25 02:59:00 [INFO]: Epoch 051 - generator training loss: -0.0649, discriminator training loss: 0.1655, validation loss: 0.0296
2024-05-25 02:59:09 [INFO]: Epoch 052 - generator training loss: -0.0676, discriminator training loss: 0.1676, validation loss: 0.0292
2024-05-25 02:59:18 [INFO]: Epoch 053 - generator training loss: -0.0643, discriminator training loss: 0.1654, validation loss: 0.0286
2024-05-25 02:59:27 [INFO]: Epoch 054 - generator training loss: -0.0655, discriminator training loss: 0.1651, validation loss: 0.0287
2024-05-25 02:59:36 [INFO]: Epoch 055 - generator training loss: -0.0674, discriminator training loss: 0.1661, validation loss: 0.0285
2024-05-25 02:59:45 [INFO]: Epoch 056 - generator training loss: -0.0664, discriminator training loss: 0.1660, validation loss: 0.0285
2024-05-25 02:59:54 [INFO]: Epoch 057 - generator training loss: -0.0676, discriminator training loss: 0.1636, validation loss: 0.0282
2024-05-25 03:00:03 [INFO]: Epoch 058 - generator training loss: -0.0689, discriminator training loss: 0.1656, validation loss: 0.0283
2024-05-25 03:00:12 [INFO]: Epoch 059 - generator training loss: -0.0636, discriminator training loss: 0.1650, validation loss: 0.0279
2024-05-25 03:00:21 [INFO]: Epoch 060 - generator training loss: -0.0657, discriminator training loss: 0.1634, validation loss: 0.0276
2024-05-25 03:00:30 [INFO]: Epoch 061 - generator training loss: -0.0690, discriminator training loss: 0.1642, validation loss: 0.0276
2024-05-25 03:00:39 [INFO]: Epoch 062 - generator training loss: -0.0675, discriminator training loss: 0.1640, validation loss: 0.0275
2024-05-25 03:00:48 [INFO]: Epoch 063 - generator training loss: -0.0688, discriminator training loss: 0.1664, validation loss: 0.0272
2024-05-25 03:00:57 [INFO]: Epoch 064 - generator training loss: -0.0684, discriminator training loss: 0.1660, validation loss: 0.0279
2024-05-25 03:01:06 [INFO]: Epoch 065 - generator training loss: -0.0682, discriminator training loss: 0.1638, validation loss: 0.0271
2024-05-25 03:01:15 [INFO]: Epoch 066 - generator training loss: -0.0703, discriminator training loss: 0.1657, validation loss: 0.0263
2024-05-25 03:01:24 [INFO]: Epoch 067 - generator training loss: -0.0704, discriminator training loss: 0.1644, validation loss: 0.0263
2024-05-25 03:01:33 [INFO]: Epoch 068 - generator training loss: -0.0690, discriminator training loss: 0.1644, validation loss: 0.0269
2024-05-25 03:01:42 [INFO]: Epoch 069 - generator training loss: -0.0714, discriminator training loss: 0.1626, validation loss: 0.0264
2024-05-25 03:01:51 [INFO]: Epoch 070 - generator training loss: -0.0683, discriminator training loss: 0.1631, validation loss: 0.0259
2024-05-25 03:02:00 [INFO]: Epoch 071 - generator training loss: -0.0703, discriminator training loss: 0.1631, validation loss: 0.0257
2024-05-25 03:02:09 [INFO]: Epoch 072 - generator training loss: -0.0692, discriminator training loss: 0.1657, validation loss: 0.0268
2024-05-25 03:02:18 [INFO]: Epoch 073 - generator training loss: -0.0695, discriminator training loss: 0.1643, validation loss: 0.0268
2024-05-25 03:02:27 [INFO]: Epoch 074 - generator training loss: -0.0687, discriminator training loss: 0.1639, validation loss: 0.0254
2024-05-25 03:02:35 [INFO]: Epoch 075 - generator training loss: -0.0738, discriminator training loss: 0.1622, validation loss: 0.0253
2024-05-25 03:02:44 [INFO]: Epoch 076 - generator training loss: -0.0699, discriminator training loss: 0.1631, validation loss: 0.0253
2024-05-25 03:02:53 [INFO]: Epoch 077 - generator training loss: -0.0736, discriminator training loss: 0.1627, validation loss: 0.0251
2024-05-25 03:03:02 [INFO]: Epoch 078 - generator training loss: -0.0729, discriminator training loss: 0.1617, validation loss: 0.0262
2024-05-25 03:03:11 [INFO]: Epoch 079 - generator training loss: -0.0714, discriminator training loss: 0.1623, validation loss: 0.0246
2024-05-25 03:03:20 [INFO]: Epoch 080 - generator training loss: -0.0687, discriminator training loss: 0.1599, validation loss: 0.0247
2024-05-25 03:03:29 [INFO]: Epoch 081 - generator training loss: -0.0721, discriminator training loss: 0.1631, validation loss: 0.0246
2024-05-25 03:03:38 [INFO]: Epoch 082 - generator training loss: -0.0698, discriminator training loss: 0.1624, validation loss: 0.0244
2024-05-25 03:03:47 [INFO]: Epoch 083 - generator training loss: -0.0716, discriminator training loss: 0.1622, validation loss: 0.0239
2024-05-25 03:03:56 [INFO]: Epoch 084 - generator training loss: -0.0739, discriminator training loss: 0.1616, validation loss: 0.0242
2024-05-25 03:04:05 [INFO]: Epoch 085 - generator training loss: -0.0736, discriminator training loss: 0.1619, validation loss: 0.0241
2024-05-25 03:04:14 [INFO]: Epoch 086 - generator training loss: -0.0719, discriminator training loss: 0.1618, validation loss: 0.0237
2024-05-25 03:04:23 [INFO]: Epoch 087 - generator training loss: -0.0716, discriminator training loss: 0.1614, validation loss: 0.0235
2024-05-25 03:04:32 [INFO]: Epoch 088 - generator training loss: -0.0717, discriminator training loss: 0.1610, validation loss: 0.0238
2024-05-25 03:04:41 [INFO]: Epoch 089 - generator training loss: -0.0705, discriminator training loss: 0.1599, validation loss: 0.0242
2024-05-25 03:04:50 [INFO]: Epoch 090 - generator training loss: -0.0711, discriminator training loss: 0.1623, validation loss: 0.0236
2024-05-25 03:04:59 [INFO]: Epoch 091 - generator training loss: -0.0714, discriminator training loss: 0.1610, validation loss: 0.0235
2024-05-25 03:05:07 [INFO]: Epoch 092 - generator training loss: -0.0710, discriminator training loss: 0.1619, validation loss: 0.0234
2024-05-25 03:05:16 [INFO]: Epoch 093 - generator training loss: -0.0718, discriminator training loss: 0.1621, validation loss: 0.0246
2024-05-25 03:05:25 [INFO]: Epoch 094 - generator training loss: -0.0725, discriminator training loss: 0.1600, validation loss: 0.0236
2024-05-25 03:05:34 [INFO]: Epoch 095 - generator training loss: -0.0724, discriminator training loss: 0.1620, validation loss: 0.0231
2024-05-25 03:05:43 [INFO]: Epoch 096 - generator training loss: -0.0721, discriminator training loss: 0.1593, validation loss: 0.0240
2024-05-25 03:05:52 [INFO]: Epoch 097 - generator training loss: -0.0711, discriminator training loss: 0.1620, validation loss: 0.0228
2024-05-25 03:06:01 [INFO]: Epoch 098 - generator training loss: -0.0742, discriminator training loss: 0.1611, validation loss: 0.0229
2024-05-25 03:06:10 [INFO]: Epoch 099 - generator training loss: -0.0707, discriminator training loss: 0.1588, validation loss: 0.0230
2024-05-25 03:06:19 [INFO]: Epoch 100 - generator training loss: -0.0712, discriminator training loss: 0.1589, validation loss: 0.0244
2024-05-25 03:06:28 [INFO]: Epoch 101 - generator training loss: -0.0714, discriminator training loss: 0.1588, validation loss: 0.0234
2024-05-25 03:06:37 [INFO]: Epoch 102 - generator training loss: -0.0717, discriminator training loss: 0.1584, validation loss: 0.0228
2024-05-25 03:06:46 [INFO]: Epoch 103 - generator training loss: -0.0681, discriminator training loss: 0.1587, validation loss: 0.0235
2024-05-25 03:06:55 [INFO]: Epoch 104 - generator training loss: -0.0731, discriminator training loss: 0.1583, validation loss: 0.0232
2024-05-25 03:07:04 [INFO]: Epoch 105 - generator training loss: -0.0723, discriminator training loss: 0.1591, validation loss: 0.0228
2024-05-25 03:07:13 [INFO]: Epoch 106 - generator training loss: -0.0729, discriminator training loss: 0.1598, validation loss: 0.0230
2024-05-25 03:07:22 [INFO]: Epoch 107 - generator training loss: -0.0701, discriminator training loss: 0.1621, validation loss: 0.0232
2024-05-25 03:07:31 [INFO]: Epoch 108 - generator training loss: -0.0713, discriminator training loss: 0.1587, validation loss: 0.0230
2024-05-25 03:07:40 [INFO]: Epoch 109 - generator training loss: -0.0727, discriminator training loss: 0.1588, validation loss: 0.0247
2024-05-25 03:07:49 [INFO]: Epoch 110 - generator training loss: -0.0721, discriminator training loss: 0.1604, validation loss: 0.0231
2024-05-25 03:07:58 [INFO]: Epoch 111 - generator training loss: -0.0718, discriminator training loss: 0.1572, validation loss: 0.0224
2024-05-25 03:08:07 [INFO]: Epoch 112 - generator training loss: -0.0714, discriminator training loss: 0.1575, validation loss: 0.0236
2024-05-25 03:08:16 [INFO]: Epoch 113 - generator training loss: -0.0728, discriminator training loss: 0.1573, validation loss: 0.0232
2024-05-25 03:08:25 [INFO]: Epoch 114 - generator training loss: -0.0735, discriminator training loss: 0.1586, validation loss: 0.0226
2024-05-25 03:08:34 [INFO]: Epoch 115 - generator training loss: -0.0725, discriminator training loss: 0.1577, validation loss: 0.0227
2024-05-25 03:08:43 [INFO]: Epoch 116 - generator training loss: -0.0694, discriminator training loss: 0.1586, validation loss: 0.0247
2024-05-25 03:08:52 [INFO]: Epoch 117 - generator training loss: -0.0724, discriminator training loss: 0.1600, validation loss: 0.0230
2024-05-25 03:09:01 [INFO]: Epoch 118 - generator training loss: -0.0715, discriminator training loss: 0.1590, validation loss: 0.0229
2024-05-25 03:09:10 [INFO]: Epoch 119 - generator training loss: -0.0731, discriminator training loss: 0.1586, validation loss: 0.0229
2024-05-25 03:09:19 [INFO]: Epoch 120 - generator training loss: -0.0709, discriminator training loss: 0.1577, validation loss: 0.0225
2024-05-25 03:09:28 [INFO]: Epoch 121 - generator training loss: -0.0709, discriminator training loss: 0.1607, validation loss: 0.0239
2024-05-25 03:09:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:09:28 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 03:09:28 [INFO]: Saved the model to augmentation_saved_results/round_4/USGAN_ettm1/20240525_T025121/USGAN.pypots
2024-05-25 03:09:29 [INFO]: US-GAN on ETTm1: MAE=0.1612, MSE=0.0683
2024-05-25 03:09:29 [INFO]: Successfully saved to augmentation_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-25 03:09:29 [INFO]: Using the given device: cuda:0
2024-05-25 03:09:29 [INFO]: Model files will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030929
2024-05-25 03:09:29 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030929/tensorboard
2024-05-25 03:09:29 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-25 03:09:37 [INFO]: Epoch 001 - training loss: 1.3532, validation loss: 0.3392
2024-05-25 03:09:43 [INFO]: Epoch 002 - training loss: 0.9301, validation loss: 0.0998
2024-05-25 03:09:49 [INFO]: Epoch 003 - training loss: 0.7704, validation loss: 0.0617
2024-05-25 03:09:55 [INFO]: Epoch 004 - training loss: 0.6697, validation loss: 0.0464
2024-05-25 03:10:01 [INFO]: Epoch 005 - training loss: 0.6346, validation loss: 0.0418
2024-05-25 03:10:07 [INFO]: Epoch 006 - training loss: 0.6415, validation loss: 0.0433
2024-05-25 03:10:13 [INFO]: Epoch 007 - training loss: 0.5948, validation loss: 0.0397
2024-05-25 03:10:19 [INFO]: Epoch 008 - training loss: 0.5630, validation loss: 0.0377
2024-05-25 03:10:25 [INFO]: Epoch 009 - training loss: 0.5373, validation loss: 0.0354
2024-05-25 03:10:31 [INFO]: Epoch 010 - training loss: 0.5292, validation loss: 0.0333
2024-05-25 03:10:37 [INFO]: Epoch 011 - training loss: 0.5498, validation loss: 0.0339
2024-05-25 03:10:43 [INFO]: Epoch 012 - training loss: 0.5006, validation loss: 0.0367
2024-05-25 03:10:49 [INFO]: Epoch 013 - training loss: 0.4758, validation loss: 0.0324
2024-05-25 03:10:55 [INFO]: Epoch 014 - training loss: 0.4500, validation loss: 0.0299
2024-05-25 03:11:01 [INFO]: Epoch 015 - training loss: 0.4411, validation loss: 0.0294
2024-05-25 03:11:07 [INFO]: Epoch 016 - training loss: 0.4284, validation loss: 0.0284
2024-05-25 03:11:13 [INFO]: Epoch 017 - training loss: 0.4286, validation loss: 0.0272
2024-05-25 03:11:19 [INFO]: Epoch 018 - training loss: 0.4125, validation loss: 0.0266
2024-05-25 03:11:24 [INFO]: Epoch 019 - training loss: 0.4134, validation loss: 0.0262
2024-05-25 03:11:30 [INFO]: Epoch 020 - training loss: 0.4067, validation loss: 0.0264
2024-05-25 03:11:36 [INFO]: Epoch 021 - training loss: 0.4045, validation loss: 0.0259
2024-05-25 03:11:42 [INFO]: Epoch 022 - training loss: 0.4047, validation loss: 0.0266
2024-05-25 03:11:48 [INFO]: Epoch 023 - training loss: 0.4034, validation loss: 0.0263
2024-05-25 03:11:54 [INFO]: Epoch 024 - training loss: 0.4042, validation loss: 0.0269
2024-05-25 03:12:00 [INFO]: Epoch 025 - training loss: 0.3987, validation loss: 0.0256
2024-05-25 03:12:06 [INFO]: Epoch 026 - training loss: 0.4013, validation loss: 0.0256
2024-05-25 03:12:12 [INFO]: Epoch 027 - training loss: 0.4062, validation loss: 0.0258
2024-05-25 03:12:18 [INFO]: Epoch 028 - training loss: 0.4081, validation loss: 0.0263
2024-05-25 03:12:24 [INFO]: Epoch 029 - training loss: 0.3989, validation loss: 0.0264
2024-05-25 03:12:30 [INFO]: Epoch 030 - training loss: 0.3986, validation loss: 0.0259
2024-05-25 03:12:36 [INFO]: Epoch 031 - training loss: 0.3967, validation loss: 0.0258
2024-05-25 03:12:42 [INFO]: Epoch 032 - training loss: 0.3985, validation loss: 0.0254
2024-05-25 03:12:48 [INFO]: Epoch 033 - training loss: 0.4036, validation loss: 0.0248
2024-05-25 03:12:54 [INFO]: Epoch 034 - training loss: 0.3979, validation loss: 0.0255
2024-05-25 03:13:00 [INFO]: Epoch 035 - training loss: 0.3965, validation loss: 0.0253
2024-05-25 03:13:06 [INFO]: Epoch 036 - training loss: 0.3977, validation loss: 0.0255
2024-05-25 03:13:12 [INFO]: Epoch 037 - training loss: 0.4044, validation loss: 0.0267
2024-05-25 03:13:18 [INFO]: Epoch 038 - training loss: 0.4015, validation loss: 0.0272
2024-05-25 03:13:24 [INFO]: Epoch 039 - training loss: 0.4002, validation loss: 0.0253
2024-05-25 03:13:29 [INFO]: Epoch 040 - training loss: 0.3985, validation loss: 0.0250
2024-05-25 03:13:35 [INFO]: Epoch 041 - training loss: 0.3954, validation loss: 0.0255
2024-05-25 03:13:41 [INFO]: Epoch 042 - training loss: 0.3911, validation loss: 0.0252
2024-05-25 03:13:47 [INFO]: Epoch 043 - training loss: 0.4055, validation loss: 0.0260
2024-05-25 03:13:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:13:47 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 03:13:47 [INFO]: Saved the model to augmentation_saved_results/round_4/BRITS_ettm1/20240525_T030929/BRITS.pypots
2024-05-25 03:13:48 [INFO]: BRITS on ETTm1: MAE=0.1423, MSE=0.0612
2024-05-25 03:13:48 [INFO]: Successfully saved to augmentation_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-25 03:13:48 [INFO]: Using the given device: cuda:0
2024-05-25 03:13:48 [INFO]: Model files will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348
2024-05-25 03:13:48 [INFO]: Tensorboard file will be saved to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/tensorboard
2024-05-25 03:13:48 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-25 03:13:50 [INFO]: Epoch 001 - training loss: 1.3585, validation loss: 1.2204
2024-05-25 03:13:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch1_loss1.2204290181398392.pypots
2024-05-25 03:13:50 [INFO]: Epoch 002 - training loss: 0.9753, validation loss: 1.0938
2024-05-25 03:13:50 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch2_loss1.0938014388084412.pypots
2024-05-25 03:13:51 [INFO]: Epoch 003 - training loss: 0.9167, validation loss: 1.0484
2024-05-25 03:13:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch3_loss1.0484028905630112.pypots
2024-05-25 03:13:51 [INFO]: Epoch 004 - training loss: 0.9016, validation loss: 1.0321
2024-05-25 03:13:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch4_loss1.032098188996315.pypots
2024-05-25 03:13:51 [INFO]: Epoch 005 - training loss: 0.8818, validation loss: 1.0275
2024-05-25 03:13:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch5_loss1.027535229921341.pypots
2024-05-25 03:13:51 [INFO]: Epoch 006 - training loss: 0.8754, validation loss: 1.0189
2024-05-25 03:13:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch6_loss1.0189121812582016.pypots
2024-05-25 03:13:51 [INFO]: Epoch 007 - training loss: 0.8723, validation loss: 1.0150
2024-05-25 03:13:51 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch7_loss1.014999970793724.pypots
2024-05-25 03:13:52 [INFO]: Epoch 008 - training loss: 0.8622, validation loss: 1.0097
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch8_loss1.0096885412931442.pypots
2024-05-25 03:13:52 [INFO]: Epoch 009 - training loss: 0.8768, validation loss: 1.0053
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch9_loss1.0052874237298965.pypots
2024-05-25 03:13:52 [INFO]: Epoch 010 - training loss: 0.8718, validation loss: 1.0026
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch10_loss1.0026413798332214.pypots
2024-05-25 03:13:52 [INFO]: Epoch 011 - training loss: 0.8746, validation loss: 0.9991
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch11_loss0.999149277806282.pypots
2024-05-25 03:13:52 [INFO]: Epoch 012 - training loss: 0.8512, validation loss: 1.0009
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch12_loss1.000859573483467.pypots
2024-05-25 03:13:52 [INFO]: Epoch 013 - training loss: 0.8173, validation loss: 0.9999
2024-05-25 03:13:52 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch13_loss0.9999106973409653.pypots
2024-05-25 03:13:53 [INFO]: Epoch 014 - training loss: 0.8307, validation loss: 0.9963
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch14_loss0.9963450580835342.pypots
2024-05-25 03:13:53 [INFO]: Epoch 015 - training loss: 0.8183, validation loss: 0.9939
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch15_loss0.9938817620277405.pypots
2024-05-25 03:13:53 [INFO]: Epoch 016 - training loss: 0.8043, validation loss: 0.9884
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch16_loss0.9883748292922974.pypots
2024-05-25 03:13:53 [INFO]: Epoch 017 - training loss: 0.8040, validation loss: 0.9875
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch17_loss0.987491101026535.pypots
2024-05-25 03:13:53 [INFO]: Epoch 018 - training loss: 0.7944, validation loss: 0.9841
2024-05-25 03:13:53 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch18_loss0.9841145724058151.pypots
2024-05-25 03:13:54 [INFO]: Epoch 019 - training loss: 0.8124, validation loss: 0.9843
2024-05-25 03:13:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch19_loss0.984338104724884.pypots
2024-05-25 03:13:54 [INFO]: Epoch 020 - training loss: 0.7974, validation loss: 0.9836
2024-05-25 03:13:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch20_loss0.9835846275091171.pypots
2024-05-25 03:13:54 [INFO]: Epoch 021 - training loss: 0.7921, validation loss: 0.9796
2024-05-25 03:13:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch21_loss0.9795973747968674.pypots
2024-05-25 03:13:54 [INFO]: Epoch 022 - training loss: 0.7858, validation loss: 0.9749
2024-05-25 03:13:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch22_loss0.9748734682798386.pypots
2024-05-25 03:13:54 [INFO]: Epoch 023 - training loss: 0.7768, validation loss: 0.9726
2024-05-25 03:13:54 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch23_loss0.9726083427667618.pypots
2024-05-25 03:13:55 [INFO]: Epoch 024 - training loss: 0.7770, validation loss: 0.9670
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch24_loss0.9669602364301682.pypots
2024-05-25 03:13:55 [INFO]: Epoch 025 - training loss: 0.7984, validation loss: 0.9658
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch25_loss0.9657715409994125.pypots
2024-05-25 03:13:55 [INFO]: Epoch 026 - training loss: 0.7656, validation loss: 0.9598
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch26_loss0.9598260521888733.pypots
2024-05-25 03:13:55 [INFO]: Epoch 027 - training loss: 0.7736, validation loss: 0.9580
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch27_loss0.9580028355121613.pypots
2024-05-25 03:13:55 [INFO]: Epoch 028 - training loss: 0.7728, validation loss: 0.9555
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch28_loss0.9555316120386124.pypots
2024-05-25 03:13:55 [INFO]: Epoch 029 - training loss: 0.7611, validation loss: 0.9532
2024-05-25 03:13:55 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch29_loss0.9532423168420792.pypots
2024-05-25 03:13:56 [INFO]: Epoch 030 - training loss: 0.7745, validation loss: 0.9493
2024-05-25 03:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch30_loss0.9492865055799484.pypots
2024-05-25 03:13:56 [INFO]: Epoch 031 - training loss: 0.7589, validation loss: 0.9469
2024-05-25 03:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch31_loss0.9468757063150406.pypots
2024-05-25 03:13:56 [INFO]: Epoch 032 - training loss: 0.7627, validation loss: 0.9450
2024-05-25 03:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch32_loss0.9450078904628754.pypots
2024-05-25 03:13:56 [INFO]: Epoch 033 - training loss: 0.7521, validation loss: 0.9444
2024-05-25 03:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch33_loss0.9444124400615692.pypots
2024-05-25 03:13:56 [INFO]: Epoch 034 - training loss: 0.7520, validation loss: 0.9427
2024-05-25 03:13:56 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch34_loss0.9426744431257248.pypots
2024-05-25 03:13:57 [INFO]: Epoch 035 - training loss: 0.7610, validation loss: 0.9416
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch35_loss0.9415753036737442.pypots
2024-05-25 03:13:57 [INFO]: Epoch 036 - training loss: 0.7476, validation loss: 0.9401
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch36_loss0.9401025921106339.pypots
2024-05-25 03:13:57 [INFO]: Epoch 037 - training loss: 0.7607, validation loss: 0.9365
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch37_loss0.9365266710519791.pypots
2024-05-25 03:13:57 [INFO]: Epoch 038 - training loss: 0.7670, validation loss: 0.9321
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch38_loss0.9321366101503372.pypots
2024-05-25 03:13:57 [INFO]: Epoch 039 - training loss: 0.8041, validation loss: 0.9314
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch39_loss0.9314338266849518.pypots
2024-05-25 03:13:58 [INFO]: Epoch 040 - training loss: 0.7532, validation loss: 0.9340
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch40_loss0.9340385645627975.pypots
2024-05-25 03:13:58 [INFO]: Epoch 041 - training loss: 0.7730, validation loss: 0.9321
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch41_loss0.9321499317884445.pypots
2024-05-25 03:13:58 [INFO]: Epoch 042 - training loss: 0.7607, validation loss: 0.9289
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch42_loss0.9289417415857315.pypots
2024-05-25 03:13:58 [INFO]: Epoch 043 - training loss: 0.7457, validation loss: 0.9272
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch43_loss0.9271873235702515.pypots
2024-05-25 03:13:58 [INFO]: Epoch 044 - training loss: 0.7526, validation loss: 0.9266
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch44_loss0.9266343712806702.pypots
2024-05-25 03:13:58 [INFO]: Epoch 045 - training loss: 0.7401, validation loss: 0.9251
2024-05-25 03:13:58 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch45_loss0.9251466244459152.pypots
2024-05-25 03:13:59 [INFO]: Epoch 046 - training loss: 0.7550, validation loss: 0.9250
2024-05-25 03:13:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch46_loss0.9249923080205917.pypots
2024-05-25 03:13:59 [INFO]: Epoch 047 - training loss: 0.7813, validation loss: 0.9243
2024-05-25 03:13:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch47_loss0.92429319024086.pypots
2024-05-25 03:13:59 [INFO]: Epoch 048 - training loss: 0.7356, validation loss: 0.9251
2024-05-25 03:13:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch48_loss0.9251430928707123.pypots
2024-05-25 03:13:59 [INFO]: Epoch 049 - training loss: 0.7542, validation loss: 0.9206
2024-05-25 03:13:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch49_loss0.9206039160490036.pypots
2024-05-25 03:13:59 [INFO]: Epoch 050 - training loss: 0.7441, validation loss: 0.9210
2024-05-25 03:13:59 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch50_loss0.9210443049669266.pypots
2024-05-25 03:14:00 [INFO]: Epoch 051 - training loss: 0.7323, validation loss: 0.9179
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch51_loss0.9178802520036697.pypots
2024-05-25 03:14:00 [INFO]: Epoch 052 - training loss: 0.7403, validation loss: 0.9193
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch52_loss0.919337660074234.pypots
2024-05-25 03:14:00 [INFO]: Epoch 053 - training loss: 0.7555, validation loss: 0.9202
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch53_loss0.9201968610286713.pypots
2024-05-25 03:14:00 [INFO]: Epoch 054 - training loss: 0.7574, validation loss: 0.9174
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch54_loss0.917434498667717.pypots
2024-05-25 03:14:00 [INFO]: Epoch 055 - training loss: 0.7190, validation loss: 0.9146
2024-05-25 03:14:00 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch55_loss0.9146303683519363.pypots
2024-05-25 03:14:01 [INFO]: Epoch 056 - training loss: 0.7398, validation loss: 0.9158
2024-05-25 03:14:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch56_loss0.9158194214105606.pypots
2024-05-25 03:14:01 [INFO]: Epoch 057 - training loss: 0.7460, validation loss: 0.9124
2024-05-25 03:14:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch57_loss0.9124416559934616.pypots
2024-05-25 03:14:01 [INFO]: Epoch 058 - training loss: 0.7563, validation loss: 0.9129
2024-05-25 03:14:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch58_loss0.9128617942333221.pypots
2024-05-25 03:14:01 [INFO]: Epoch 059 - training loss: 0.7468, validation loss: 0.9120
2024-05-25 03:14:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch59_loss0.9120485335588455.pypots
2024-05-25 03:14:01 [INFO]: Epoch 060 - training loss: 0.7396, validation loss: 0.9092
2024-05-25 03:14:01 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch60_loss0.909179762005806.pypots
2024-05-25 03:14:02 [INFO]: Epoch 061 - training loss: 0.7121, validation loss: 0.9127
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch61_loss0.912656307220459.pypots
2024-05-25 03:14:02 [INFO]: Epoch 062 - training loss: 0.7547, validation loss: 0.9126
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch62_loss0.9125653505325317.pypots
2024-05-25 03:14:02 [INFO]: Epoch 063 - training loss: 0.7414, validation loss: 0.9124
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch63_loss0.9123535007238388.pypots
2024-05-25 03:14:02 [INFO]: Epoch 064 - training loss: 0.7429, validation loss: 0.9126
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch64_loss0.912625789642334.pypots
2024-05-25 03:14:02 [INFO]: Epoch 065 - training loss: 0.7342, validation loss: 0.9118
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch65_loss0.9118097573518753.pypots
2024-05-25 03:14:02 [INFO]: Epoch 066 - training loss: 0.7442, validation loss: 0.9100
2024-05-25 03:14:02 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch66_loss0.9099924266338348.pypots
2024-05-25 03:14:03 [INFO]: Epoch 067 - training loss: 0.7273, validation loss: 0.9097
2024-05-25 03:14:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch67_loss0.9096550196409225.pypots
2024-05-25 03:14:03 [INFO]: Epoch 068 - training loss: 0.7397, validation loss: 0.9115
2024-05-25 03:14:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch68_loss0.9115023910999298.pypots
2024-05-25 03:14:03 [INFO]: Epoch 069 - training loss: 0.7159, validation loss: 0.9083
2024-05-25 03:14:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch69_loss0.908344179391861.pypots
2024-05-25 03:14:03 [INFO]: Epoch 070 - training loss: 0.7328, validation loss: 0.9103
2024-05-25 03:14:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch70_loss0.9102618098258972.pypots
2024-05-25 03:14:03 [INFO]: Epoch 071 - training loss: 0.7382, validation loss: 0.9106
2024-05-25 03:14:03 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch71_loss0.9106456786394119.pypots
2024-05-25 03:14:04 [INFO]: Epoch 072 - training loss: 0.7524, validation loss: 0.9135
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch72_loss0.9134545177221298.pypots
2024-05-25 03:14:04 [INFO]: Epoch 073 - training loss: 0.7451, validation loss: 0.9112
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch73_loss0.9112229943275452.pypots
2024-05-25 03:14:04 [INFO]: Epoch 074 - training loss: 0.7374, validation loss: 0.9094
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch74_loss0.9093611985445023.pypots
2024-05-25 03:14:04 [INFO]: Epoch 075 - training loss: 0.7456, validation loss: 0.9111
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch75_loss0.9110560417175293.pypots
2024-05-25 03:14:04 [INFO]: Epoch 076 - training loss: 0.7506, validation loss: 0.9091
2024-05-25 03:14:04 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch76_loss0.9091298431158066.pypots
2024-05-25 03:14:05 [INFO]: Epoch 077 - training loss: 0.7362, validation loss: 0.9122
2024-05-25 03:14:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch77_loss0.9122421741485596.pypots
2024-05-25 03:14:05 [INFO]: Epoch 078 - training loss: 0.7445, validation loss: 0.9095
2024-05-25 03:14:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch78_loss0.9094971567392349.pypots
2024-05-25 03:14:05 [INFO]: Epoch 079 - training loss: 0.7510, validation loss: 0.9098
2024-05-25 03:14:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN_epoch79_loss0.9098404049873352.pypots
2024-05-25 03:14:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:14:05 [INFO]: Finished training. The best model is from epoch#69.
2024-05-25 03:14:05 [INFO]: Saved the model to augmentation_saved_results/round_4/MRNN_ettm1/20240525_T031348/MRNN.pypots
2024-05-25 03:14:05 [INFO]: MRNN on ETTm1: MAE=0.7254, MSE=1.2870
2024-05-25 03:14:05 [INFO]: Successfully saved to augmentation_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-25 03:14:05 [INFO]: Using the given device: cpu
2024-05-25 03:14:05 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-25 03:14:05 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-25 03:14:05 [INFO]: Successfully saved to augmentation_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-25 03:14:05 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-25 03:14:05 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-25 03:14:05 [INFO]: Successfully saved to augmentation_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-25 03:14:05 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-25 03:14:05 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-25 03:14:05 [INFO]: Successfully saved to augmentation_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-25 03:14:05 [INFO]: 
SAITS on data/ettm1: MAE=0.163±0.0077629106322009665, MSE=0.052±0.005113474981874588
Transformer on data/ettm1: MAE=0.141±0.008805479623882454, MSE=0.039±0.003225168759895303
TimesNet on data/ettm1: MAE=0.122±0.005348517736483459, MSE=0.031±0.0024094436501456277
CSDI on data/ettm1: MAE=0.166±0.03239985474048914, MSE=0.128±0.0975899321041513
GPVAE on data/ettm1: MAE=0.298±0.00875591673044102, MSE=0.190±0.011179368330649921
USGAN on data/ettm1: MAE=0.164±0.004611517063523742, MSE=0.069±0.001559789216354327
BRITS on data/ettm1: MAE=0.143±0.004880024624059591, MSE=0.062±0.0026315033066142946
MRNN on data/ettm1: MAE=0.706±0.09247598247351331, MSE=1.249±0.21676784709917674
LOCF on data/ettm1: MAE=0.143±0.0, MSE=0.083±0.0
Median on data/ettm1: MAE=0.653±0.0, MSE=0.821±1.1102230246251565e-16
Mean on data/ettm1: MAE=0.658±0.0, MSE=0.801±0.0

