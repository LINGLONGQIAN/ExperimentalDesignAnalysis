2024-05-23 17:26:42 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-23 17:26:43 [INFO]: Using the given device: cuda:0
2024-05-23 17:26:43 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172643
2024-05-23 17:26:43 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172643/tensorboard
2024-05-23 17:26:43 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 17:26:45 [INFO]: Epoch 001 - training loss: 1.0482, validation loss: 0.4808
2024-05-23 17:26:46 [INFO]: Epoch 002 - training loss: 0.6814, validation loss: 0.4112
2024-05-23 17:26:47 [INFO]: Epoch 003 - training loss: 0.5615, validation loss: 0.3833
2024-05-23 17:26:48 [INFO]: Epoch 004 - training loss: 0.5024, validation loss: 0.3697
2024-05-23 17:26:49 [INFO]: Epoch 005 - training loss: 0.4635, validation loss: 0.3578
2024-05-23 17:26:50 [INFO]: Epoch 006 - training loss: 0.4392, validation loss: 0.3457
2024-05-23 17:26:52 [INFO]: Epoch 007 - training loss: 0.4089, validation loss: 0.3423
2024-05-23 17:26:53 [INFO]: Epoch 008 - training loss: 0.3904, validation loss: 0.3336
2024-05-23 17:26:54 [INFO]: Epoch 009 - training loss: 0.3669, validation loss: 0.3296
2024-05-23 17:26:55 [INFO]: Epoch 010 - training loss: 0.3496, validation loss: 0.3143
2024-05-23 17:26:56 [INFO]: Epoch 011 - training loss: 0.3336, validation loss: 0.3110
2024-05-23 17:26:57 [INFO]: Epoch 012 - training loss: 0.3212, validation loss: 0.3108
2024-05-23 17:26:58 [INFO]: Epoch 013 - training loss: 0.3074, validation loss: 0.3073
2024-05-23 17:27:00 [INFO]: Epoch 014 - training loss: 0.2954, validation loss: 0.3017
2024-05-23 17:27:01 [INFO]: Epoch 015 - training loss: 0.2917, validation loss: 0.3027
2024-05-23 17:27:02 [INFO]: Epoch 016 - training loss: 0.2734, validation loss: 0.3040
2024-05-23 17:27:03 [INFO]: Epoch 017 - training loss: 0.2663, validation loss: 0.2970
2024-05-23 17:27:04 [INFO]: Epoch 018 - training loss: 0.2595, validation loss: 0.2994
2024-05-23 17:27:05 [INFO]: Epoch 019 - training loss: 0.2495, validation loss: 0.2973
2024-05-23 17:27:06 [INFO]: Epoch 020 - training loss: 0.2436, validation loss: 0.3022
2024-05-23 17:27:08 [INFO]: Epoch 021 - training loss: 0.2388, validation loss: 0.2958
2024-05-23 17:27:09 [INFO]: Epoch 022 - training loss: 0.2310, validation loss: 0.2970
2024-05-23 17:27:10 [INFO]: Epoch 023 - training loss: 0.2260, validation loss: 0.2981
2024-05-23 17:27:11 [INFO]: Epoch 024 - training loss: 0.2181, validation loss: 0.2985
2024-05-23 17:27:12 [INFO]: Epoch 025 - training loss: 0.2134, validation loss: 0.2969
2024-05-23 17:27:13 [INFO]: Epoch 026 - training loss: 0.2088, validation loss: 0.3016
2024-05-23 17:27:14 [INFO]: Epoch 027 - training loss: 0.2071, validation loss: 0.2966
2024-05-23 17:27:15 [INFO]: Epoch 028 - training loss: 0.1998, validation loss: 0.2941
2024-05-23 17:27:17 [INFO]: Epoch 029 - training loss: 0.1966, validation loss: 0.2932
2024-05-23 17:27:18 [INFO]: Epoch 030 - training loss: 0.1903, validation loss: 0.2959
2024-05-23 17:27:19 [INFO]: Epoch 031 - training loss: 0.1872, validation loss: 0.2929
2024-05-23 17:27:20 [INFO]: Epoch 032 - training loss: 0.1852, validation loss: 0.3006
2024-05-23 17:27:21 [INFO]: Epoch 033 - training loss: 0.1809, validation loss: 0.2941
2024-05-23 17:27:22 [INFO]: Epoch 034 - training loss: 0.1826, validation loss: 0.2970
2024-05-23 17:27:23 [INFO]: Epoch 035 - training loss: 0.1771, validation loss: 0.2945
2024-05-23 17:27:25 [INFO]: Epoch 036 - training loss: 0.1725, validation loss: 0.2959
2024-05-23 17:27:26 [INFO]: Epoch 037 - training loss: 0.1704, validation loss: 0.2921
2024-05-23 17:27:27 [INFO]: Epoch 038 - training loss: 0.1665, validation loss: 0.2931
2024-05-23 17:27:28 [INFO]: Epoch 039 - training loss: 0.1669, validation loss: 0.2925
2024-05-23 17:27:29 [INFO]: Epoch 040 - training loss: 0.1620, validation loss: 0.2921
2024-05-23 17:27:30 [INFO]: Epoch 041 - training loss: 0.1611, validation loss: 0.2938
2024-05-23 17:27:31 [INFO]: Epoch 042 - training loss: 0.1582, validation loss: 0.2920
2024-05-23 17:27:33 [INFO]: Epoch 043 - training loss: 0.1548, validation loss: 0.2921
2024-05-23 17:27:34 [INFO]: Epoch 044 - training loss: 0.1544, validation loss: 0.2888
2024-05-23 17:27:35 [INFO]: Epoch 045 - training loss: 0.1523, validation loss: 0.2910
2024-05-23 17:27:36 [INFO]: Epoch 046 - training loss: 0.1516, validation loss: 0.2935
2024-05-23 17:27:37 [INFO]: Epoch 047 - training loss: 0.1490, validation loss: 0.2918
2024-05-23 17:27:38 [INFO]: Epoch 048 - training loss: 0.1512, validation loss: 0.2914
2024-05-23 17:27:39 [INFO]: Epoch 049 - training loss: 0.1518, validation loss: 0.2936
2024-05-23 17:27:41 [INFO]: Epoch 050 - training loss: 0.1467, validation loss: 0.2944
2024-05-23 17:27:42 [INFO]: Epoch 051 - training loss: 0.1448, validation loss: 0.2904
2024-05-23 17:27:43 [INFO]: Epoch 052 - training loss: 0.1408, validation loss: 0.2917
2024-05-23 17:27:44 [INFO]: Epoch 053 - training loss: 0.1384, validation loss: 0.2935
2024-05-23 17:27:45 [INFO]: Epoch 054 - training loss: 0.1401, validation loss: 0.2914
2024-05-23 17:27:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:27:45 [INFO]: Finished training. The best model is from epoch#44.
2024-05-23 17:27:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_physionet_2012_seta/20240523_T172643/SAITS.pypots
2024-05-23 17:27:45 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2693, MSE=0.3213
2024-05-23 17:27:46 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 17:27:46 [INFO]: Using the given device: cuda:0
2024-05-23 17:27:46 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172746
2024-05-23 17:27:46 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172746/tensorboard
2024-05-23 17:27:46 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 17:27:46 [INFO]: Epoch 001 - training loss: 1.2217, validation loss: 0.5508
2024-05-23 17:27:47 [INFO]: Epoch 002 - training loss: 0.7476, validation loss: 0.4777
2024-05-23 17:27:48 [INFO]: Epoch 003 - training loss: 0.6397, validation loss: 0.4399
2024-05-23 17:27:48 [INFO]: Epoch 004 - training loss: 0.5776, validation loss: 0.4320
2024-05-23 17:27:49 [INFO]: Epoch 005 - training loss: 0.5413, validation loss: 0.4097
2024-05-23 17:27:49 [INFO]: Epoch 006 - training loss: 0.5090, validation loss: 0.3901
2024-05-23 17:27:50 [INFO]: Epoch 007 - training loss: 0.4807, validation loss: 0.3742
2024-05-23 17:27:50 [INFO]: Epoch 008 - training loss: 0.4527, validation loss: 0.3667
2024-05-23 17:27:51 [INFO]: Epoch 009 - training loss: 0.4400, validation loss: 0.3689
2024-05-23 17:27:52 [INFO]: Epoch 010 - training loss: 0.4237, validation loss: 0.3677
2024-05-23 17:27:52 [INFO]: Epoch 011 - training loss: 0.4099, validation loss: 0.3504
2024-05-23 17:27:53 [INFO]: Epoch 012 - training loss: 0.3908, validation loss: 0.3451
2024-05-23 17:27:53 [INFO]: Epoch 013 - training loss: 0.3819, validation loss: 0.3434
2024-05-23 17:27:54 [INFO]: Epoch 014 - training loss: 0.3729, validation loss: 0.3373
2024-05-23 17:27:54 [INFO]: Epoch 015 - training loss: 0.3611, validation loss: 0.3342
2024-05-23 17:27:55 [INFO]: Epoch 016 - training loss: 0.3541, validation loss: 0.3256
2024-05-23 17:27:56 [INFO]: Epoch 017 - training loss: 0.3416, validation loss: 0.3282
2024-05-23 17:27:56 [INFO]: Epoch 018 - training loss: 0.3357, validation loss: 0.3242
2024-05-23 17:27:57 [INFO]: Epoch 019 - training loss: 0.3277, validation loss: 0.3222
2024-05-23 17:27:57 [INFO]: Epoch 020 - training loss: 0.3199, validation loss: 0.3217
2024-05-23 17:27:58 [INFO]: Epoch 021 - training loss: 0.3149, validation loss: 0.3222
2024-05-23 17:27:59 [INFO]: Epoch 022 - training loss: 0.3105, validation loss: 0.3150
2024-05-23 17:27:59 [INFO]: Epoch 023 - training loss: 0.3025, validation loss: 0.3183
2024-05-23 17:28:00 [INFO]: Epoch 024 - training loss: 0.2968, validation loss: 0.3131
2024-05-23 17:28:00 [INFO]: Epoch 025 - training loss: 0.2890, validation loss: 0.3141
2024-05-23 17:28:01 [INFO]: Epoch 026 - training loss: 0.2887, validation loss: 0.3121
2024-05-23 17:28:01 [INFO]: Epoch 027 - training loss: 0.2827, validation loss: 0.3108
2024-05-23 17:28:02 [INFO]: Epoch 028 - training loss: 0.2756, validation loss: 0.3117
2024-05-23 17:28:03 [INFO]: Epoch 029 - training loss: 0.2708, validation loss: 0.3165
2024-05-23 17:28:03 [INFO]: Epoch 030 - training loss: 0.2663, validation loss: 0.3065
2024-05-23 17:28:04 [INFO]: Epoch 031 - training loss: 0.2604, validation loss: 0.3104
2024-05-23 17:28:04 [INFO]: Epoch 032 - training loss: 0.2573, validation loss: 0.3102
2024-05-23 17:28:05 [INFO]: Epoch 033 - training loss: 0.2557, validation loss: 0.3124
2024-05-23 17:28:05 [INFO]: Epoch 034 - training loss: 0.2497, validation loss: 0.3122
2024-05-23 17:28:06 [INFO]: Epoch 035 - training loss: 0.2486, validation loss: 0.3142
2024-05-23 17:28:07 [INFO]: Epoch 036 - training loss: 0.2461, validation loss: 0.3158
2024-05-23 17:28:07 [INFO]: Epoch 037 - training loss: 0.2384, validation loss: 0.3111
2024-05-23 17:28:08 [INFO]: Epoch 038 - training loss: 0.2369, validation loss: 0.3157
2024-05-23 17:28:09 [INFO]: Epoch 039 - training loss: 0.2351, validation loss: 0.3135
2024-05-23 17:28:09 [INFO]: Epoch 040 - training loss: 0.2322, validation loss: 0.3146
2024-05-23 17:28:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:28:09 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 17:28:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_physionet_2012_seta/20240523_T172746/Transformer.pypots
2024-05-23 17:28:09 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2915, MSE=0.3355
2024-05-23 17:28:09 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 17:28:09 [INFO]: Using the given device: cuda:0
2024-05-23 17:28:09 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172809
2024-05-23 17:28:09 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172809/tensorboard
2024-05-23 17:28:10 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 17:28:11 [INFO]: Epoch 001 - training loss: 0.4695, validation loss: 0.3586
2024-05-23 17:28:11 [INFO]: Epoch 002 - training loss: 0.4995, validation loss: 0.3855
2024-05-23 17:28:12 [INFO]: Epoch 003 - training loss: 0.5262, validation loss: 0.3323
2024-05-23 17:28:13 [INFO]: Epoch 004 - training loss: 0.4728, validation loss: 0.3205
2024-05-23 17:28:13 [INFO]: Epoch 005 - training loss: 0.3702, validation loss: 0.3083
2024-05-23 17:28:14 [INFO]: Epoch 006 - training loss: 0.3071, validation loss: 0.3072
2024-05-23 17:28:15 [INFO]: Epoch 007 - training loss: 0.2862, validation loss: 0.3085
2024-05-23 17:28:16 [INFO]: Epoch 008 - training loss: 0.2867, validation loss: 0.3180
2024-05-23 17:28:16 [INFO]: Epoch 009 - training loss: 0.2731, validation loss: 0.3067
2024-05-23 17:28:17 [INFO]: Epoch 010 - training loss: 0.2651, validation loss: 0.2971
2024-05-23 17:28:18 [INFO]: Epoch 011 - training loss: 0.2599, validation loss: 0.3006
2024-05-23 17:28:18 [INFO]: Epoch 012 - training loss: 0.2591, validation loss: 0.2931
2024-05-23 17:28:19 [INFO]: Epoch 013 - training loss: 0.2589, validation loss: 0.2979
2024-05-23 17:28:20 [INFO]: Epoch 014 - training loss: 0.2437, validation loss: 0.2996
2024-05-23 17:28:20 [INFO]: Epoch 015 - training loss: 0.2406, validation loss: 0.3051
2024-05-23 17:28:21 [INFO]: Epoch 016 - training loss: 0.2402, validation loss: 0.2956
2024-05-23 17:28:22 [INFO]: Epoch 017 - training loss: 0.2294, validation loss: 0.3033
2024-05-23 17:28:23 [INFO]: Epoch 018 - training loss: 0.2301, validation loss: 0.2966
2024-05-23 17:28:23 [INFO]: Epoch 019 - training loss: 0.2190, validation loss: 0.3027
2024-05-23 17:28:24 [INFO]: Epoch 020 - training loss: 0.2189, validation loss: 0.3121
2024-05-23 17:28:25 [INFO]: Epoch 021 - training loss: 0.2215, validation loss: 0.3071
2024-05-23 17:28:25 [INFO]: Epoch 022 - training loss: 0.2134, validation loss: 0.3022
2024-05-23 17:28:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:28:25 [INFO]: Finished training. The best model is from epoch#12.
2024-05-23 17:28:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_physionet_2012_seta/20240523_T172809/TimesNet.pypots
2024-05-23 17:28:26 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2917, MSE=0.2844
2024-05-23 17:28:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 17:28:26 [INFO]: Using the given device: cuda:0
2024-05-23 17:28:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826
2024-05-23 17:28:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/tensorboard
2024-05-23 17:28:26 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 17:29:09 [INFO]: Epoch 001 - training loss: 0.4264, validation loss: 0.3471
2024-05-23 17:29:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch1_loss0.34708307683467865.pypots
2024-05-23 17:29:53 [INFO]: Epoch 002 - training loss: 0.3203, validation loss: 0.2936
2024-05-23 17:29:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch2_loss0.2936087265610695.pypots
2024-05-23 17:30:37 [INFO]: Epoch 003 - training loss: 0.2981, validation loss: 0.2689
2024-05-23 17:30:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch3_loss0.26887491047382356.pypots
2024-05-23 17:31:21 [INFO]: Epoch 004 - training loss: 0.2643, validation loss: 0.2557
2024-05-23 17:31:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch4_loss0.2557299919426441.pypots
2024-05-23 17:32:05 [INFO]: Epoch 005 - training loss: 0.2706, validation loss: 0.2550
2024-05-23 17:32:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch5_loss0.2550158426165581.pypots
2024-05-23 17:32:48 [INFO]: Epoch 006 - training loss: 0.2498, validation loss: 0.2317
2024-05-23 17:32:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch6_loss0.23174016252160073.pypots
2024-05-23 17:33:32 [INFO]: Epoch 007 - training loss: 0.2422, validation loss: 0.2220
2024-05-23 17:33:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch7_loss0.22198712304234505.pypots
2024-05-23 17:34:16 [INFO]: Epoch 008 - training loss: 0.2394, validation loss: 0.2196
2024-05-23 17:34:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch8_loss0.2196185663342476.pypots
2024-05-23 17:35:00 [INFO]: Epoch 009 - training loss: 0.2383, validation loss: 0.2256
2024-05-23 17:35:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch9_loss0.22556447982788086.pypots
2024-05-23 17:35:45 [INFO]: Epoch 010 - training loss: 0.2215, validation loss: 0.2141
2024-05-23 17:35:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch10_loss0.21405317410826682.pypots
2024-05-23 17:36:29 [INFO]: Epoch 011 - training loss: 0.2236, validation loss: 0.2140
2024-05-23 17:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch11_loss0.21395039036870003.pypots
2024-05-23 17:37:13 [INFO]: Epoch 012 - training loss: 0.2258, validation loss: 0.2095
2024-05-23 17:37:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch12_loss0.20951213017106057.pypots
2024-05-23 17:37:57 [INFO]: Epoch 013 - training loss: 0.2259, validation loss: 0.2105
2024-05-23 17:37:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch13_loss0.2104659289121628.pypots
2024-05-23 17:38:41 [INFO]: Epoch 014 - training loss: 0.2269, validation loss: 0.2108
2024-05-23 17:38:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch14_loss0.21080473959445953.pypots
2024-05-23 17:39:25 [INFO]: Epoch 015 - training loss: 0.2178, validation loss: 0.2039
2024-05-23 17:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch15_loss0.20387496426701546.pypots
2024-05-23 17:40:08 [INFO]: Epoch 016 - training loss: 0.2097, validation loss: 0.2128
2024-05-23 17:40:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch16_loss0.21280731931328772.pypots
2024-05-23 17:40:52 [INFO]: Epoch 017 - training loss: 0.2085, validation loss: 0.2048
2024-05-23 17:40:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch17_loss0.20475891903042792.pypots
2024-05-23 17:41:36 [INFO]: Epoch 018 - training loss: 0.2027, validation loss: 0.2040
2024-05-23 17:41:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch18_loss0.20402940586209298.pypots
2024-05-23 17:42:20 [INFO]: Epoch 019 - training loss: 0.2081, validation loss: 0.2004
2024-05-23 17:42:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch19_loss0.20035164728760718.pypots
2024-05-23 17:43:04 [INFO]: Epoch 020 - training loss: 0.2268, validation loss: 0.2020
2024-05-23 17:43:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch20_loss0.2019733667373657.pypots
2024-05-23 17:43:48 [INFO]: Epoch 021 - training loss: 0.2095, validation loss: 0.1986
2024-05-23 17:43:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch21_loss0.19860571697354318.pypots
2024-05-23 17:44:32 [INFO]: Epoch 022 - training loss: 0.1999, validation loss: 0.1983
2024-05-23 17:44:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch22_loss0.1982981763780117.pypots
2024-05-23 17:45:16 [INFO]: Epoch 023 - training loss: 0.2065, validation loss: 0.2064
2024-05-23 17:45:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch23_loss0.20642647445201873.pypots
2024-05-23 17:46:00 [INFO]: Epoch 024 - training loss: 0.2068, validation loss: 0.1974
2024-05-23 17:46:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch24_loss0.19737022295594214.pypots
2024-05-23 17:46:44 [INFO]: Epoch 025 - training loss: 0.2146, validation loss: 0.1968
2024-05-23 17:46:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch25_loss0.19677494540810586.pypots
2024-05-23 17:47:28 [INFO]: Epoch 026 - training loss: 0.2119, validation loss: 0.1949
2024-05-23 17:47:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch26_loss0.19491908252239226.pypots
2024-05-23 17:48:12 [INFO]: Epoch 027 - training loss: 0.2034, validation loss: 0.1931
2024-05-23 17:48:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch27_loss0.19314876049757004.pypots
2024-05-23 17:48:56 [INFO]: Epoch 028 - training loss: 0.2045, validation loss: 0.1944
2024-05-23 17:48:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch28_loss0.19444742277264596.pypots
2024-05-23 17:49:40 [INFO]: Epoch 029 - training loss: 0.2145, validation loss: 0.1966
2024-05-23 17:49:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch29_loss0.19657368138432502.pypots
2024-05-23 17:50:23 [INFO]: Epoch 030 - training loss: 0.2128, validation loss: 0.1948
2024-05-23 17:50:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch30_loss0.19484232738614082.pypots
2024-05-23 17:51:07 [INFO]: Epoch 031 - training loss: 0.1969, validation loss: 0.1927
2024-05-23 17:51:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch31_loss0.19274479150772095.pypots
2024-05-23 17:51:51 [INFO]: Epoch 032 - training loss: 0.2075, validation loss: 0.1920
2024-05-23 17:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch32_loss0.19204761162400247.pypots
2024-05-23 17:52:35 [INFO]: Epoch 033 - training loss: 0.2009, validation loss: 0.1943
2024-05-23 17:52:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch33_loss0.1943003460764885.pypots
2024-05-23 17:53:19 [INFO]: Epoch 034 - training loss: 0.2020, validation loss: 0.1937
2024-05-23 17:53:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch34_loss0.19372434318065643.pypots
2024-05-23 17:54:03 [INFO]: Epoch 035 - training loss: 0.2028, validation loss: 0.1931
2024-05-23 17:54:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch35_loss0.19312911704182625.pypots
2024-05-23 17:54:47 [INFO]: Epoch 036 - training loss: 0.1933, validation loss: 0.1939
2024-05-23 17:54:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch36_loss0.1939484268426895.pypots
2024-05-23 17:55:31 [INFO]: Epoch 037 - training loss: 0.2012, validation loss: 0.1937
2024-05-23 17:55:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch37_loss0.19373909905552864.pypots
2024-05-23 17:56:15 [INFO]: Epoch 038 - training loss: 0.2092, validation loss: 0.1936
2024-05-23 17:56:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch38_loss0.19361136257648467.pypots
2024-05-23 17:56:59 [INFO]: Epoch 039 - training loss: 0.1938, validation loss: 0.1929
2024-05-23 17:56:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch39_loss0.1929058738052845.pypots
2024-05-23 17:57:43 [INFO]: Epoch 040 - training loss: 0.1931, validation loss: 0.1928
2024-05-23 17:57:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch40_loss0.19275874122977257.pypots
2024-05-23 17:58:27 [INFO]: Epoch 041 - training loss: 0.2019, validation loss: 0.1874
2024-05-23 17:58:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch41_loss0.18738072514533996.pypots
2024-05-23 17:59:11 [INFO]: Epoch 042 - training loss: 0.1922, validation loss: 0.1933
2024-05-23 17:59:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch42_loss0.19331028684973717.pypots
2024-05-23 17:59:55 [INFO]: Epoch 043 - training loss: 0.2049, validation loss: 0.1864
2024-05-23 17:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch43_loss0.18635601326823234.pypots
2024-05-23 18:00:39 [INFO]: Epoch 044 - training loss: 0.1984, validation loss: 0.1904
2024-05-23 18:00:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch44_loss0.19040774554014206.pypots
2024-05-23 18:01:23 [INFO]: Epoch 045 - training loss: 0.1937, validation loss: 0.1873
2024-05-23 18:01:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch45_loss0.18733844235539437.pypots
2024-05-23 18:02:07 [INFO]: Epoch 046 - training loss: 0.1990, validation loss: 0.1908
2024-05-23 18:02:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch46_loss0.1907867044210434.pypots
2024-05-23 18:02:51 [INFO]: Epoch 047 - training loss: 0.1939, validation loss: 0.1886
2024-05-23 18:02:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch47_loss0.18859782069921494.pypots
2024-05-23 18:03:35 [INFO]: Epoch 048 - training loss: 0.1961, validation loss: 0.1886
2024-05-23 18:03:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch48_loss0.18862437903881074.pypots
2024-05-23 18:04:19 [INFO]: Epoch 049 - training loss: 0.1945, validation loss: 0.1918
2024-05-23 18:04:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch49_loss0.19179116412997246.pypots
2024-05-23 18:05:03 [INFO]: Epoch 050 - training loss: 0.2058, validation loss: 0.1875
2024-05-23 18:05:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch50_loss0.18747307881712913.pypots
2024-05-23 18:05:47 [INFO]: Epoch 051 - training loss: 0.1933, validation loss: 0.1870
2024-05-23 18:05:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch51_loss0.18700318187475204.pypots
2024-05-23 18:06:31 [INFO]: Epoch 052 - training loss: 0.1937, validation loss: 0.1874
2024-05-23 18:06:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch52_loss0.18742411434650422.pypots
2024-05-23 18:07:15 [INFO]: Epoch 053 - training loss: 0.1924, validation loss: 0.1869
2024-05-23 18:07:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI_epoch53_loss0.18688899949193.pypots
2024-05-23 18:07:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:07:15 [INFO]: Finished training. The best model is from epoch#43.
2024-05-23 18:07:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/20240523_T172826/CSDI.pypots
2024-05-23 18:14:38 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2624, MSE=0.4958
2024-05-23 18:44:10 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 18:44:10 [INFO]: Using the given device: cuda:0
2024-05-23 18:44:10 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T184410
2024-05-23 18:44:10 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T184410/tensorboard
2024-05-23 18:44:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 18:44:11 [INFO]: Epoch 001 - training loss: 43170.9254, validation loss: 0.9366
2024-05-23 18:44:12 [INFO]: Epoch 002 - training loss: 24422.5607, validation loss: 0.7328
2024-05-23 18:44:12 [INFO]: Epoch 003 - training loss: 23489.8958, validation loss: 0.6753
2024-05-23 18:44:13 [INFO]: Epoch 004 - training loss: 23190.2129, validation loss: 0.6487
2024-05-23 18:44:13 [INFO]: Epoch 005 - training loss: 23042.9140, validation loss: 0.6474
2024-05-23 18:44:14 [INFO]: Epoch 006 - training loss: 22960.1908, validation loss: 0.6497
2024-05-23 18:44:15 [INFO]: Epoch 007 - training loss: 22909.2834, validation loss: 0.6441
2024-05-23 18:44:15 [INFO]: Epoch 008 - training loss: 22876.8058, validation loss: 0.6421
2024-05-23 18:44:16 [INFO]: Epoch 009 - training loss: 22855.5042, validation loss: 0.6461
2024-05-23 18:44:16 [INFO]: Epoch 010 - training loss: 22840.1833, validation loss: 0.6433
2024-05-23 18:44:17 [INFO]: Epoch 011 - training loss: 22828.8257, validation loss: 0.6358
2024-05-23 18:44:18 [INFO]: Epoch 012 - training loss: 22820.6069, validation loss: 0.6414
2024-05-23 18:44:18 [INFO]: Epoch 013 - training loss: 22814.0388, validation loss: 0.6391
2024-05-23 18:44:19 [INFO]: Epoch 014 - training loss: 22809.1579, validation loss: 0.6335
2024-05-23 18:44:19 [INFO]: Epoch 015 - training loss: 22806.0005, validation loss: 0.6431
2024-05-23 18:44:20 [INFO]: Epoch 016 - training loss: 22802.4520, validation loss: 0.6276
2024-05-23 18:44:21 [INFO]: Epoch 017 - training loss: 22799.6490, validation loss: 0.6287
2024-05-23 18:44:21 [INFO]: Epoch 018 - training loss: 22796.9411, validation loss: 0.6233
2024-05-23 18:44:22 [INFO]: Epoch 019 - training loss: 22795.4016, validation loss: 0.6192
2024-05-23 18:44:22 [INFO]: Epoch 020 - training loss: 22793.5958, validation loss: 0.6182
2024-05-23 18:44:23 [INFO]: Epoch 021 - training loss: 22791.8956, validation loss: 0.6134
2024-05-23 18:44:24 [INFO]: Epoch 022 - training loss: 22790.3534, validation loss: 0.6271
2024-05-23 18:44:24 [INFO]: Epoch 023 - training loss: 22789.5388, validation loss: 0.6104
2024-05-23 18:44:25 [INFO]: Epoch 024 - training loss: 22788.2283, validation loss: 0.6127
2024-05-23 18:44:26 [INFO]: Epoch 025 - training loss: 22786.5069, validation loss: 0.6205
2024-05-23 18:44:26 [INFO]: Epoch 026 - training loss: 22786.3426, validation loss: 0.6021
2024-05-23 18:44:27 [INFO]: Epoch 027 - training loss: 22785.6184, validation loss: 0.6018
2024-05-23 18:44:27 [INFO]: Epoch 028 - training loss: 22785.1648, validation loss: 0.6036
2024-05-23 18:44:28 [INFO]: Epoch 029 - training loss: 22784.4203, validation loss: 0.6009
2024-05-23 18:44:29 [INFO]: Epoch 030 - training loss: 22783.3619, validation loss: 0.6006
2024-05-23 18:44:29 [INFO]: Epoch 031 - training loss: 22783.2030, validation loss: 0.5981
2024-05-23 18:44:30 [INFO]: Epoch 032 - training loss: 22783.1079, validation loss: 0.5965
2024-05-23 18:44:30 [INFO]: Epoch 033 - training loss: 22782.9175, validation loss: 0.5955
2024-05-23 18:44:31 [INFO]: Epoch 034 - training loss: 22782.1468, validation loss: 0.6228
2024-05-23 18:44:32 [INFO]: Epoch 035 - training loss: 22782.3124, validation loss: 0.6024
2024-05-23 18:44:32 [INFO]: Epoch 036 - training loss: 22781.0246, validation loss: 0.5948
2024-05-23 18:44:33 [INFO]: Epoch 037 - training loss: 22780.2286, validation loss: 0.5887
2024-05-23 18:44:33 [INFO]: Epoch 038 - training loss: 22779.3070, validation loss: 0.5855
2024-05-23 18:44:34 [INFO]: Epoch 039 - training loss: 22778.7008, validation loss: 0.5858
2024-05-23 18:44:35 [INFO]: Epoch 040 - training loss: 22776.5760, validation loss: 0.5759
2024-05-23 18:44:35 [INFO]: Epoch 041 - training loss: 22775.2737, validation loss: 0.5709
2024-05-23 18:44:36 [INFO]: Epoch 042 - training loss: 22773.8596, validation loss: 0.5761
2024-05-23 18:44:36 [INFO]: Epoch 043 - training loss: 22772.7651, validation loss: 0.5636
2024-05-23 18:44:37 [INFO]: Epoch 044 - training loss: 22772.2657, validation loss: 0.5757
2024-05-23 18:44:38 [INFO]: Epoch 045 - training loss: 22772.6663, validation loss: 0.5589
2024-05-23 18:44:38 [INFO]: Epoch 046 - training loss: 22771.8507, validation loss: 0.5590
2024-05-23 18:44:39 [INFO]: Epoch 047 - training loss: 22770.8257, validation loss: 0.5596
2024-05-23 18:44:39 [INFO]: Epoch 048 - training loss: 22769.4521, validation loss: 0.5593
2024-05-23 18:44:40 [INFO]: Epoch 049 - training loss: 22768.8358, validation loss: 0.5547
2024-05-23 18:44:41 [INFO]: Epoch 050 - training loss: 22768.3526, validation loss: 0.5546
2024-05-23 18:44:41 [INFO]: Epoch 051 - training loss: 22767.7792, validation loss: 0.5492
2024-05-23 18:44:42 [INFO]: Epoch 052 - training loss: 22766.7708, validation loss: 0.5496
2024-05-23 18:44:42 [INFO]: Epoch 053 - training loss: 22766.9906, validation loss: 0.5458
2024-05-23 18:44:43 [INFO]: Epoch 054 - training loss: 22766.0532, validation loss: 0.5431
2024-05-23 18:44:44 [INFO]: Epoch 055 - training loss: 22765.3863, validation loss: 0.5363
2024-05-23 18:44:44 [INFO]: Epoch 056 - training loss: 22764.0260, validation loss: 0.5381
2024-05-23 18:44:45 [INFO]: Epoch 057 - training loss: 22763.6297, validation loss: 0.5301
2024-05-23 18:44:45 [INFO]: Epoch 058 - training loss: 22762.3718, validation loss: 0.5278
2024-05-23 18:44:46 [INFO]: Epoch 059 - training loss: 22761.8602, validation loss: 0.5269
2024-05-23 18:44:46 [INFO]: Epoch 060 - training loss: 22761.7490, validation loss: 0.5260
2024-05-23 18:44:47 [INFO]: Epoch 061 - training loss: 22761.1725, validation loss: 0.5303
2024-05-23 18:44:48 [INFO]: Epoch 062 - training loss: 22761.7044, validation loss: 0.5244
2024-05-23 18:44:48 [INFO]: Epoch 063 - training loss: 22760.5700, validation loss: 0.5244
2024-05-23 18:44:49 [INFO]: Epoch 064 - training loss: 22760.0271, validation loss: 0.5166
2024-05-23 18:44:49 [INFO]: Epoch 065 - training loss: 22759.7985, validation loss: 0.5219
2024-05-23 18:44:50 [INFO]: Epoch 066 - training loss: 22759.3946, validation loss: 0.5172
2024-05-23 18:44:51 [INFO]: Epoch 067 - training loss: 22758.5968, validation loss: 0.5195
2024-05-23 18:44:51 [INFO]: Epoch 068 - training loss: 22758.2132, validation loss: 0.5149
2024-05-23 18:44:52 [INFO]: Epoch 069 - training loss: 22758.2469, validation loss: 0.5128
2024-05-23 18:44:52 [INFO]: Epoch 070 - training loss: 22757.4723, validation loss: 0.5091
2024-05-23 18:44:53 [INFO]: Epoch 071 - training loss: 22758.3160, validation loss: 0.5117
2024-05-23 18:44:54 [INFO]: Epoch 072 - training loss: 22758.1154, validation loss: 0.5091
2024-05-23 18:44:54 [INFO]: Epoch 073 - training loss: 22756.8855, validation loss: 0.5046
2024-05-23 18:44:55 [INFO]: Epoch 074 - training loss: 22756.2509, validation loss: 0.5014
2024-05-23 18:44:55 [INFO]: Epoch 075 - training loss: 22755.8571, validation loss: 0.5035
2024-05-23 18:44:56 [INFO]: Epoch 076 - training loss: 22757.2512, validation loss: 0.4985
2024-05-23 18:44:57 [INFO]: Epoch 077 - training loss: 22755.8330, validation loss: 0.4968
2024-05-23 18:44:57 [INFO]: Epoch 078 - training loss: 22755.8636, validation loss: 0.5080
2024-05-23 18:44:58 [INFO]: Epoch 079 - training loss: 22755.9683, validation loss: 0.4967
2024-05-23 18:44:58 [INFO]: Epoch 080 - training loss: 22755.3624, validation loss: 0.4984
2024-05-23 18:44:59 [INFO]: Epoch 081 - training loss: 22754.9446, validation loss: 0.4974
2024-05-23 18:45:00 [INFO]: Epoch 082 - training loss: 22755.1378, validation loss: 0.4921
2024-05-23 18:45:00 [INFO]: Epoch 083 - training loss: 22753.2949, validation loss: 0.4926
2024-05-23 18:45:01 [INFO]: Epoch 084 - training loss: 22753.3602, validation loss: 0.4905
2024-05-23 18:45:02 [INFO]: Epoch 085 - training loss: 22752.8275, validation loss: 0.4962
2024-05-23 18:45:02 [INFO]: Epoch 086 - training loss: 22752.6971, validation loss: 0.4910
2024-05-23 18:45:03 [INFO]: Epoch 087 - training loss: 22752.5866, validation loss: 0.4956
2024-05-23 18:45:03 [INFO]: Epoch 088 - training loss: 22751.9531, validation loss: 0.4923
2024-05-23 18:45:04 [INFO]: Epoch 089 - training loss: 22751.7466, validation loss: 0.4888
2024-05-23 18:45:05 [INFO]: Epoch 090 - training loss: 22751.8277, validation loss: 0.4973
2024-05-23 18:45:05 [INFO]: Epoch 091 - training loss: 22751.7993, validation loss: 0.4908
2024-05-23 18:45:06 [INFO]: Epoch 092 - training loss: 22751.9140, validation loss: 0.4910
2024-05-23 18:45:06 [INFO]: Epoch 093 - training loss: 22751.6812, validation loss: 0.4982
2024-05-23 18:45:07 [INFO]: Epoch 094 - training loss: 22752.0878, validation loss: 0.4884
2024-05-23 18:45:08 [INFO]: Epoch 095 - training loss: 22751.2007, validation loss: 0.4873
2024-05-23 18:45:08 [INFO]: Epoch 096 - training loss: 22751.1372, validation loss: 0.4845
2024-05-23 18:45:09 [INFO]: Epoch 097 - training loss: 22751.1311, validation loss: 0.4843
2024-05-23 18:45:09 [INFO]: Epoch 098 - training loss: 22751.5812, validation loss: 0.4883
2024-05-23 18:45:10 [INFO]: Epoch 099 - training loss: 22752.6919, validation loss: 0.4903
2024-05-23 18:45:11 [INFO]: Epoch 100 - training loss: 22751.7607, validation loss: 0.4872
2024-05-23 18:45:11 [INFO]: Epoch 101 - training loss: 22753.2566, validation loss: 0.4831
2024-05-23 18:45:12 [INFO]: Epoch 102 - training loss: 22751.4673, validation loss: 0.4837
2024-05-23 18:45:12 [INFO]: Epoch 103 - training loss: 22749.8078, validation loss: 0.4836
2024-05-23 18:45:13 [INFO]: Epoch 104 - training loss: 22749.8970, validation loss: 0.4828
2024-05-23 18:45:14 [INFO]: Epoch 105 - training loss: 22749.5441, validation loss: 0.4804
2024-05-23 18:45:14 [INFO]: Epoch 106 - training loss: 22749.4384, validation loss: 0.4808
2024-05-23 18:45:15 [INFO]: Epoch 107 - training loss: 22749.1377, validation loss: 0.4843
2024-05-23 18:45:15 [INFO]: Epoch 108 - training loss: 22749.2087, validation loss: 0.4805
2024-05-23 18:45:16 [INFO]: Epoch 109 - training loss: 22749.3584, validation loss: 0.4839
2024-05-23 18:45:17 [INFO]: Epoch 110 - training loss: 22750.7101, validation loss: 0.4787
2024-05-23 18:45:17 [INFO]: Epoch 111 - training loss: 22750.8797, validation loss: 0.4810
2024-05-23 18:45:18 [INFO]: Epoch 112 - training loss: 22749.0300, validation loss: 0.4809
2024-05-23 18:45:18 [INFO]: Epoch 113 - training loss: 22749.3179, validation loss: 0.4808
2024-05-23 18:45:19 [INFO]: Epoch 114 - training loss: 22748.4344, validation loss: 0.4784
2024-05-23 18:45:20 [INFO]: Epoch 115 - training loss: 22747.8840, validation loss: 0.4765
2024-05-23 18:45:20 [INFO]: Epoch 116 - training loss: 22748.9491, validation loss: 0.4748
2024-05-23 18:45:21 [INFO]: Epoch 117 - training loss: 22749.9819, validation loss: 0.4782
2024-05-23 18:45:21 [INFO]: Epoch 118 - training loss: 22749.1535, validation loss: 0.4736
2024-05-23 18:45:22 [INFO]: Epoch 119 - training loss: 22748.5260, validation loss: 0.4734
2024-05-23 18:45:22 [INFO]: Epoch 120 - training loss: 22747.6431, validation loss: 0.4759
2024-05-23 18:45:23 [INFO]: Epoch 121 - training loss: 22747.6406, validation loss: 0.4753
2024-05-23 18:45:24 [INFO]: Epoch 122 - training loss: 22747.2891, validation loss: 0.4741
2024-05-23 18:45:24 [INFO]: Epoch 123 - training loss: 22746.9584, validation loss: 0.4720
2024-05-23 18:45:25 [INFO]: Epoch 124 - training loss: 22747.0636, validation loss: 0.4729
2024-05-23 18:45:25 [INFO]: Epoch 125 - training loss: 22746.7329, validation loss: 0.4730
2024-05-23 18:45:26 [INFO]: Epoch 126 - training loss: 22746.9935, validation loss: 0.4716
2024-05-23 18:45:27 [INFO]: Epoch 127 - training loss: 22747.5130, validation loss: 0.4727
2024-05-23 18:45:27 [INFO]: Epoch 128 - training loss: 22747.1802, validation loss: 0.4737
2024-05-23 18:45:28 [INFO]: Epoch 129 - training loss: 22748.5314, validation loss: 0.4783
2024-05-23 18:45:28 [INFO]: Epoch 130 - training loss: 22750.3080, validation loss: 0.4726
2024-05-23 18:45:29 [INFO]: Epoch 131 - training loss: 22747.5117, validation loss: 0.4713
2024-05-23 18:45:30 [INFO]: Epoch 132 - training loss: 22746.5627, validation loss: 0.4727
2024-05-23 18:45:30 [INFO]: Epoch 133 - training loss: 22746.4084, validation loss: 0.4698
2024-05-23 18:45:31 [INFO]: Epoch 134 - training loss: 22746.2170, validation loss: 0.4702
2024-05-23 18:45:31 [INFO]: Epoch 135 - training loss: 22745.8015, validation loss: 0.4702
2024-05-23 18:45:32 [INFO]: Epoch 136 - training loss: 22745.5841, validation loss: 0.4694
2024-05-23 18:45:33 [INFO]: Epoch 137 - training loss: 22745.3651, validation loss: 0.4720
2024-05-23 18:45:33 [INFO]: Epoch 138 - training loss: 22745.3589, validation loss: 0.4722
2024-05-23 18:45:34 [INFO]: Epoch 139 - training loss: 22745.3074, validation loss: 0.4637
2024-05-23 18:45:34 [INFO]: Epoch 140 - training loss: 22745.5780, validation loss: 0.4666
2024-05-23 18:45:35 [INFO]: Epoch 141 - training loss: 22745.5973, validation loss: 0.4632
2024-05-23 18:45:36 [INFO]: Epoch 142 - training loss: 22745.4202, validation loss: 0.4672
2024-05-23 18:45:36 [INFO]: Epoch 143 - training loss: 22745.3727, validation loss: 0.4682
2024-05-23 18:45:37 [INFO]: Epoch 144 - training loss: 22746.2374, validation loss: 0.4681
2024-05-23 18:45:38 [INFO]: Epoch 145 - training loss: 22745.8387, validation loss: 0.4655
2024-05-23 18:45:38 [INFO]: Epoch 146 - training loss: 22745.3730, validation loss: 0.4702
2024-05-23 18:45:39 [INFO]: Epoch 147 - training loss: 22746.3149, validation loss: 0.4652
2024-05-23 18:45:39 [INFO]: Epoch 148 - training loss: 22745.9850, validation loss: 0.4687
2024-05-23 18:45:40 [INFO]: Epoch 149 - training loss: 22745.1004, validation loss: 0.4649
2024-05-23 18:45:41 [INFO]: Epoch 150 - training loss: 22744.4743, validation loss: 0.4667
2024-05-23 18:45:41 [INFO]: Epoch 151 - training loss: 22744.3751, validation loss: 0.4671
2024-05-23 18:45:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:45:41 [INFO]: Finished training. The best model is from epoch#141.
2024-05-23 18:45:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_physionet_2012_seta/20240523_T184410/GPVAE.pypots
2024-05-23 18:45:41 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4119, MSE=0.4886
2024-05-23 18:45:42 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 18:45:42 [INFO]: Using the given device: cuda:0
2024-05-23 18:45:42 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T184542
2024-05-23 18:45:42 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T184542/tensorboard
2024-05-23 18:45:42 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 18:46:04 [INFO]: Epoch 001 - generator training loss: 0.5975, discriminator training loss: 0.3829, validation loss: 0.6150
2024-05-23 18:46:23 [INFO]: Epoch 002 - generator training loss: 0.4802, discriminator training loss: 0.2732, validation loss: 0.5251
2024-05-23 18:46:41 [INFO]: Epoch 003 - generator training loss: 0.4324, discriminator training loss: 0.2375, validation loss: 0.5100
2024-05-23 18:47:00 [INFO]: Epoch 004 - generator training loss: 0.4507, discriminator training loss: 0.1920, validation loss: 0.5078
2024-05-23 18:47:19 [INFO]: Epoch 005 - generator training loss: 0.4481, discriminator training loss: 0.1623, validation loss: 0.4853
2024-05-23 18:47:38 [INFO]: Epoch 006 - generator training loss: 0.4364, discriminator training loss: 0.1425, validation loss: 0.4692
2024-05-23 18:47:57 [INFO]: Epoch 007 - generator training loss: 0.4248, discriminator training loss: 0.1278, validation loss: 0.4555
2024-05-23 18:48:15 [INFO]: Epoch 008 - generator training loss: 0.4172, discriminator training loss: 0.1170, validation loss: 0.4445
2024-05-23 18:48:34 [INFO]: Epoch 009 - generator training loss: 0.4068, discriminator training loss: 0.1082, validation loss: 0.4346
2024-05-23 18:48:53 [INFO]: Epoch 010 - generator training loss: 0.4011, discriminator training loss: 0.1010, validation loss: 0.4317
2024-05-23 18:49:12 [INFO]: Epoch 011 - generator training loss: 0.3936, discriminator training loss: 0.0951, validation loss: 0.4228
2024-05-23 18:49:31 [INFO]: Epoch 012 - generator training loss: 0.3904, discriminator training loss: 0.0899, validation loss: 0.4185
2024-05-23 18:49:50 [INFO]: Epoch 013 - generator training loss: 0.3825, discriminator training loss: 0.0852, validation loss: 0.4120
2024-05-23 18:50:09 [INFO]: Epoch 014 - generator training loss: 0.3773, discriminator training loss: 0.0812, validation loss: 0.4082
2024-05-23 18:50:28 [INFO]: Epoch 015 - generator training loss: 0.3734, discriminator training loss: 0.0778, validation loss: 0.4025
2024-05-23 18:50:47 [INFO]: Epoch 016 - generator training loss: 0.3689, discriminator training loss: 0.0745, validation loss: 0.4013
2024-05-23 18:51:06 [INFO]: Epoch 017 - generator training loss: 0.3647, discriminator training loss: 0.0718, validation loss: 0.3933
2024-05-23 18:51:25 [INFO]: Epoch 018 - generator training loss: 0.3590, discriminator training loss: 0.0691, validation loss: 0.3906
2024-05-23 18:51:44 [INFO]: Epoch 019 - generator training loss: 0.3550, discriminator training loss: 0.0667, validation loss: 0.3860
2024-05-23 18:52:03 [INFO]: Epoch 020 - generator training loss: 0.3508, discriminator training loss: 0.0646, validation loss: 0.3848
2024-05-23 18:52:22 [INFO]: Epoch 021 - generator training loss: 0.3465, discriminator training loss: 0.0627, validation loss: 0.3775
2024-05-23 18:52:41 [INFO]: Epoch 022 - generator training loss: 0.3408, discriminator training loss: 0.0609, validation loss: 0.3737
2024-05-23 18:53:00 [INFO]: Epoch 023 - generator training loss: 0.3361, discriminator training loss: 0.0592, validation loss: 0.3720
2024-05-23 18:53:18 [INFO]: Epoch 024 - generator training loss: 0.3335, discriminator training loss: 0.0578, validation loss: 0.3694
2024-05-23 18:53:37 [INFO]: Epoch 025 - generator training loss: 0.3276, discriminator training loss: 0.0562, validation loss: 0.3784
2024-05-23 18:53:56 [INFO]: Epoch 026 - generator training loss: 0.3257, discriminator training loss: 0.0553, validation loss: 0.3612
2024-05-23 18:54:15 [INFO]: Epoch 027 - generator training loss: 0.3208, discriminator training loss: 0.0540, validation loss: 0.3578
2024-05-23 18:54:34 [INFO]: Epoch 028 - generator training loss: 0.3149, discriminator training loss: 0.0531, validation loss: 0.3552
2024-05-23 18:54:54 [INFO]: Epoch 029 - generator training loss: 0.3092, discriminator training loss: 0.0524, validation loss: 0.3504
2024-05-23 18:55:13 [INFO]: Epoch 030 - generator training loss: 0.3108, discriminator training loss: 0.0515, validation loss: 0.3565
2024-05-23 18:55:31 [INFO]: Epoch 031 - generator training loss: 0.3154, discriminator training loss: 0.0509, validation loss: 0.3540
2024-05-23 18:55:50 [INFO]: Epoch 032 - generator training loss: 0.3033, discriminator training loss: 0.0500, validation loss: 0.3476
2024-05-23 18:56:09 [INFO]: Epoch 033 - generator training loss: 0.2945, discriminator training loss: 0.0494, validation loss: 0.3420
2024-05-23 18:56:28 [INFO]: Epoch 034 - generator training loss: 0.2902, discriminator training loss: 0.0488, validation loss: 0.3387
2024-05-23 18:56:47 [INFO]: Epoch 035 - generator training loss: 0.2907, discriminator training loss: 0.0484, validation loss: 0.3354
2024-05-23 18:57:06 [INFO]: Epoch 036 - generator training loss: 0.2886, discriminator training loss: 0.0480, validation loss: 0.3356
2024-05-23 18:57:25 [INFO]: Epoch 037 - generator training loss: 0.2905, discriminator training loss: 0.0475, validation loss: 0.3334
2024-05-23 18:57:44 [INFO]: Epoch 038 - generator training loss: 0.2861, discriminator training loss: 0.0472, validation loss: 0.3325
2024-05-23 18:58:03 [INFO]: Epoch 039 - generator training loss: 0.2803, discriminator training loss: 0.0466, validation loss: 0.3327
2024-05-23 18:58:22 [INFO]: Epoch 040 - generator training loss: 0.2767, discriminator training loss: 0.0462, validation loss: 0.3274
2024-05-23 18:58:41 [INFO]: Epoch 041 - generator training loss: 0.2707, discriminator training loss: 0.0458, validation loss: 0.3265
2024-05-23 18:59:00 [INFO]: Epoch 042 - generator training loss: 0.2711, discriminator training loss: 0.0455, validation loss: 0.3233
2024-05-23 18:59:19 [INFO]: Epoch 043 - generator training loss: 0.2643, discriminator training loss: 0.0453, validation loss: 0.3246
2024-05-23 18:59:37 [INFO]: Epoch 044 - generator training loss: 0.2631, discriminator training loss: 0.0448, validation loss: 0.3244
2024-05-23 18:59:56 [INFO]: Epoch 045 - generator training loss: 0.2705, discriminator training loss: 0.0447, validation loss: 0.3241
2024-05-23 19:00:15 [INFO]: Epoch 046 - generator training loss: 0.2636, discriminator training loss: 0.0444, validation loss: 0.3229
2024-05-23 19:00:35 [INFO]: Epoch 047 - generator training loss: 0.2634, discriminator training loss: 0.0442, validation loss: 0.3241
2024-05-23 19:00:54 [INFO]: Epoch 048 - generator training loss: 0.2573, discriminator training loss: 0.0440, validation loss: 0.3127
2024-05-23 19:01:13 [INFO]: Epoch 049 - generator training loss: 0.2507, discriminator training loss: 0.0435, validation loss: 0.3160
2024-05-23 19:01:32 [INFO]: Epoch 050 - generator training loss: 0.2540, discriminator training loss: 0.0437, validation loss: 0.3114
2024-05-23 19:01:50 [INFO]: Epoch 051 - generator training loss: 0.2482, discriminator training loss: 0.0434, validation loss: 0.3117
2024-05-23 19:02:09 [INFO]: Epoch 052 - generator training loss: 0.2431, discriminator training loss: 0.0431, validation loss: 0.3153
2024-05-23 19:02:28 [INFO]: Epoch 053 - generator training loss: 0.2438, discriminator training loss: 0.0432, validation loss: 0.3154
2024-05-23 19:02:47 [INFO]: Epoch 054 - generator training loss: 0.2498, discriminator training loss: 0.0433, validation loss: 0.3131
2024-05-23 19:03:06 [INFO]: Epoch 055 - generator training loss: 0.2438, discriminator training loss: 0.0430, validation loss: 0.3128
2024-05-23 19:03:25 [INFO]: Epoch 056 - generator training loss: 0.2378, discriminator training loss: 0.0430, validation loss: 0.3162
2024-05-23 19:03:44 [INFO]: Epoch 057 - generator training loss: 0.2372, discriminator training loss: 0.0428, validation loss: 0.3116
2024-05-23 19:04:02 [INFO]: Epoch 058 - generator training loss: 0.2338, discriminator training loss: 0.0426, validation loss: 0.3110
2024-05-23 19:04:21 [INFO]: Epoch 059 - generator training loss: 0.2318, discriminator training loss: 0.0426, validation loss: 0.3086
2024-05-23 19:04:40 [INFO]: Epoch 060 - generator training loss: 0.2311, discriminator training loss: 0.0426, validation loss: 0.3133
2024-05-23 19:04:59 [INFO]: Epoch 061 - generator training loss: 0.2301, discriminator training loss: 0.0425, validation loss: 0.3161
2024-05-23 19:05:18 [INFO]: Epoch 062 - generator training loss: 0.2334, discriminator training loss: 0.0425, validation loss: 0.3081
2024-05-23 19:05:37 [INFO]: Epoch 063 - generator training loss: 0.2310, discriminator training loss: 0.0423, validation loss: 0.3171
2024-05-23 19:05:55 [INFO]: Epoch 064 - generator training loss: 0.2312, discriminator training loss: 0.0422, validation loss: 0.3157
2024-05-23 19:06:14 [INFO]: Epoch 065 - generator training loss: 0.2289, discriminator training loss: 0.0421, validation loss: 0.3023
2024-05-23 19:06:33 [INFO]: Epoch 066 - generator training loss: 0.2225, discriminator training loss: 0.0420, validation loss: 0.3053
2024-05-23 19:06:52 [INFO]: Epoch 067 - generator training loss: 0.2209, discriminator training loss: 0.0419, validation loss: 0.3073
2024-05-23 19:07:11 [INFO]: Epoch 068 - generator training loss: 0.2220, discriminator training loss: 0.0420, validation loss: 0.3010
2024-05-23 19:07:30 [INFO]: Epoch 069 - generator training loss: 0.2109, discriminator training loss: 0.0416, validation loss: 0.3044
2024-05-23 19:07:49 [INFO]: Epoch 070 - generator training loss: 0.2066, discriminator training loss: 0.0417, validation loss: 0.3049
2024-05-23 19:08:07 [INFO]: Epoch 071 - generator training loss: 0.2065, discriminator training loss: 0.0416, validation loss: 0.3027
2024-05-23 19:08:26 [INFO]: Epoch 072 - generator training loss: 0.2092, discriminator training loss: 0.0413, validation loss: 0.3064
2024-05-23 19:08:45 [INFO]: Epoch 073 - generator training loss: 0.2044, discriminator training loss: 0.0414, validation loss: 0.3061
2024-05-23 19:09:04 [INFO]: Epoch 074 - generator training loss: 0.2005, discriminator training loss: 0.0411, validation loss: 0.3068
2024-05-23 19:09:23 [INFO]: Epoch 075 - generator training loss: 0.2002, discriminator training loss: 0.0410, validation loss: 0.3043
2024-05-23 19:09:42 [INFO]: Epoch 076 - generator training loss: 0.1973, discriminator training loss: 0.0410, validation loss: 0.3060
2024-05-23 19:10:00 [INFO]: Epoch 077 - generator training loss: 0.1954, discriminator training loss: 0.0407, validation loss: 0.3046
2024-05-23 19:10:19 [INFO]: Epoch 078 - generator training loss: 0.1944, discriminator training loss: 0.0406, validation loss: 0.3056
2024-05-23 19:10:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:10:19 [INFO]: Finished training. The best model is from epoch#68.
2024-05-23 19:10:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_physionet_2012_seta/20240523_T184542/USGAN.pypots
2024-05-23 19:10:22 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2987, MSE=0.2836
2024-05-23 19:10:32 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 19:10:32 [INFO]: Using the given device: cuda:0
2024-05-23 19:10:32 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T191032
2024-05-23 19:10:32 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T191032/tensorboard
2024-05-23 19:10:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 19:10:47 [INFO]: Epoch 001 - training loss: 1.1309, validation loss: 0.5308
2024-05-23 19:10:59 [INFO]: Epoch 002 - training loss: 0.9242, validation loss: 0.4709
2024-05-23 19:11:11 [INFO]: Epoch 003 - training loss: 0.8612, validation loss: 0.4396
2024-05-23 19:11:24 [INFO]: Epoch 004 - training loss: 0.8254, validation loss: 0.4180
2024-05-23 19:11:36 [INFO]: Epoch 005 - training loss: 0.7952, validation loss: 0.3975
2024-05-23 19:11:48 [INFO]: Epoch 006 - training loss: 0.7738, validation loss: 0.3826
2024-05-23 19:12:01 [INFO]: Epoch 007 - training loss: 0.7548, validation loss: 0.3726
2024-05-23 19:12:13 [INFO]: Epoch 008 - training loss: 0.7396, validation loss: 0.3625
2024-05-23 19:12:25 [INFO]: Epoch 009 - training loss: 0.7267, validation loss: 0.3596
2024-05-23 19:12:38 [INFO]: Epoch 010 - training loss: 0.7156, validation loss: 0.3508
2024-05-23 19:12:50 [INFO]: Epoch 011 - training loss: 0.7062, validation loss: 0.3476
2024-05-23 19:13:02 [INFO]: Epoch 012 - training loss: 0.6981, validation loss: 0.3451
2024-05-23 19:13:14 [INFO]: Epoch 013 - training loss: 0.6909, validation loss: 0.3415
2024-05-23 19:13:27 [INFO]: Epoch 014 - training loss: 0.6849, validation loss: 0.3401
2024-05-23 19:13:39 [INFO]: Epoch 015 - training loss: 0.6789, validation loss: 0.3385
2024-05-23 19:13:51 [INFO]: Epoch 016 - training loss: 0.6745, validation loss: 0.3369
2024-05-23 19:14:04 [INFO]: Epoch 017 - training loss: 0.6700, validation loss: 0.3350
2024-05-23 19:14:16 [INFO]: Epoch 018 - training loss: 0.6653, validation loss: 0.3340
2024-05-23 19:14:28 [INFO]: Epoch 019 - training loss: 0.6628, validation loss: 0.3337
2024-05-23 19:14:41 [INFO]: Epoch 020 - training loss: 0.6587, validation loss: 0.3325
2024-05-23 19:14:53 [INFO]: Epoch 021 - training loss: 0.6549, validation loss: 0.3315
2024-05-23 19:15:05 [INFO]: Epoch 022 - training loss: 0.6516, validation loss: 0.3322
2024-05-23 19:15:18 [INFO]: Epoch 023 - training loss: 0.6479, validation loss: 0.3310
2024-05-23 19:15:30 [INFO]: Epoch 024 - training loss: 0.6445, validation loss: 0.3282
2024-05-23 19:15:42 [INFO]: Epoch 025 - training loss: 0.6423, validation loss: 0.3302
2024-05-23 19:15:54 [INFO]: Epoch 026 - training loss: 0.6394, validation loss: 0.3284
2024-05-23 19:16:07 [INFO]: Epoch 027 - training loss: 0.6367, validation loss: 0.3275
2024-05-23 19:16:19 [INFO]: Epoch 028 - training loss: 0.6336, validation loss: 0.3284
2024-05-23 19:16:31 [INFO]: Epoch 029 - training loss: 0.6316, validation loss: 0.3268
2024-05-23 19:16:44 [INFO]: Epoch 030 - training loss: 0.6285, validation loss: 0.3281
2024-05-23 19:16:56 [INFO]: Epoch 031 - training loss: 0.6277, validation loss: 0.3285
2024-05-23 19:17:08 [INFO]: Epoch 032 - training loss: 0.6233, validation loss: 0.3280
2024-05-23 19:17:21 [INFO]: Epoch 033 - training loss: 0.6205, validation loss: 0.3306
2024-05-23 19:17:33 [INFO]: Epoch 034 - training loss: 0.6183, validation loss: 0.3274
2024-05-23 19:17:45 [INFO]: Epoch 035 - training loss: 0.6154, validation loss: 0.3274
2024-05-23 19:17:58 [INFO]: Epoch 036 - training loss: 0.6121, validation loss: 0.3291
2024-05-23 19:18:10 [INFO]: Epoch 037 - training loss: 0.6099, validation loss: 0.3290
2024-05-23 19:18:22 [INFO]: Epoch 038 - training loss: 0.6078, validation loss: 0.3282
2024-05-23 19:18:35 [INFO]: Epoch 039 - training loss: 0.6058, validation loss: 0.3290
2024-05-23 19:18:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:18:35 [INFO]: Finished training. The best model is from epoch#29.
2024-05-23 19:18:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_physionet_2012_seta/20240523_T191032/BRITS.pypots
2024-05-23 19:18:37 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2611, MSE=0.2811
2024-05-23 19:18:47 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:18:47 [INFO]: Using the given device: cuda:0
2024-05-23 19:18:47 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847
2024-05-23 19:18:47 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/tensorboard
2024-05-23 19:18:47 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 19:18:53 [INFO]: Epoch 001 - training loss: 1.2736, validation loss: 0.9977
2024-05-23 19:18:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch1_loss0.9976795434951782.pypots
2024-05-23 19:18:56 [INFO]: Epoch 002 - training loss: 0.8624, validation loss: 0.9673
2024-05-23 19:18:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch2_loss0.9672724604606628.pypots
2024-05-23 19:18:59 [INFO]: Epoch 003 - training loss: 0.6427, validation loss: 0.9458
2024-05-23 19:18:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch3_loss0.9458258032798768.pypots
2024-05-23 19:19:01 [INFO]: Epoch 004 - training loss: 0.5891, validation loss: 0.9296
2024-05-23 19:19:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch4_loss0.9295633852481842.pypots
2024-05-23 19:19:04 [INFO]: Epoch 005 - training loss: 0.5524, validation loss: 0.9204
2024-05-23 19:19:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch5_loss0.9203751772642136.pypots
2024-05-23 19:19:07 [INFO]: Epoch 006 - training loss: 0.5267, validation loss: 0.9164
2024-05-23 19:19:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch6_loss0.9163816332817077.pypots
2024-05-23 19:19:10 [INFO]: Epoch 007 - training loss: 0.5158, validation loss: 0.9128
2024-05-23 19:19:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch7_loss0.9128306120634079.pypots
2024-05-23 19:19:13 [INFO]: Epoch 008 - training loss: 0.4987, validation loss: 0.9110
2024-05-23 19:19:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch8_loss0.9110237658023834.pypots
2024-05-23 19:19:16 [INFO]: Epoch 009 - training loss: 0.4957, validation loss: 0.9117
2024-05-23 19:19:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch9_loss0.9116707473993302.pypots
2024-05-23 19:19:18 [INFO]: Epoch 010 - training loss: 0.4845, validation loss: 0.9103
2024-05-23 19:19:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch10_loss0.9102790117263794.pypots
2024-05-23 19:19:21 [INFO]: Epoch 011 - training loss: 0.4753, validation loss: 0.9119
2024-05-23 19:19:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch11_loss0.911919629573822.pypots
2024-05-23 19:19:24 [INFO]: Epoch 012 - training loss: 0.4749, validation loss: 0.9141
2024-05-23 19:19:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch12_loss0.9141256749629975.pypots
2024-05-23 19:19:27 [INFO]: Epoch 013 - training loss: 0.4651, validation loss: 0.9165
2024-05-23 19:19:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch13_loss0.9164568096399307.pypots
2024-05-23 19:19:30 [INFO]: Epoch 014 - training loss: 0.4587, validation loss: 0.9175
2024-05-23 19:19:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch14_loss0.9175187319517135.pypots
2024-05-23 19:19:33 [INFO]: Epoch 015 - training loss: 0.4536, validation loss: 0.9189
2024-05-23 19:19:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch15_loss0.9189460724592209.pypots
2024-05-23 19:19:36 [INFO]: Epoch 016 - training loss: 0.4542, validation loss: 0.9220
2024-05-23 19:19:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch16_loss0.9220262348651886.pypots
2024-05-23 19:19:38 [INFO]: Epoch 017 - training loss: 0.4446, validation loss: 0.9237
2024-05-23 19:19:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch17_loss0.923741015791893.pypots
2024-05-23 19:19:41 [INFO]: Epoch 018 - training loss: 0.4504, validation loss: 0.9286
2024-05-23 19:19:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch18_loss0.9285956472158432.pypots
2024-05-23 19:19:44 [INFO]: Epoch 019 - training loss: 0.4513, validation loss: 0.9309
2024-05-23 19:19:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch19_loss0.9308937102556228.pypots
2024-05-23 19:19:47 [INFO]: Epoch 020 - training loss: 0.4452, validation loss: 0.9304
2024-05-23 19:19:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN_epoch20_loss0.9303822547197342.pypots
2024-05-23 19:19:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:19:47 [INFO]: Finished training. The best model is from epoch#10.
2024-05-23 19:19:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/20240523_T191847/MRNN.pypots
2024-05-23 19:19:48 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6857, MSE=0.9259
2024-05-23 19:19:52 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 19:19:52 [INFO]: Using the given device: cpu
2024-05-23 19:19:52 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4083, MSE=0.5397
2024-05-23 19:19:52 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_physionet_2012_seta".
2024-05-23 19:19:52 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 19:19:52 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6856, MSE=1.0305
2024-05-23 19:19:52 [INFO]: Successfully created the given path "saved_results/round_0/Median_physionet_2012_seta".
2024-05-23 19:19:52 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_physionet_2012_seta/imputation.pkl
2024-05-23 19:19:52 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7023, MSE=1.0007
2024-05-23 19:19:53 [INFO]: Successfully created the given path "saved_results/round_0/Mean_physionet_2012_seta".
2024-05-23 19:19:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 19:19:53 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-23 19:19:53 [INFO]: Using the given device: cuda:0
2024-05-23 19:19:53 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T191953
2024-05-23 19:19:53 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T191953/tensorboard
2024-05-23 19:19:53 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 19:19:54 [INFO]: Epoch 001 - training loss: 1.1219, validation loss: 0.4818
2024-05-23 19:19:55 [INFO]: Epoch 002 - training loss: 0.8306, validation loss: 0.4187
2024-05-23 19:19:56 [INFO]: Epoch 003 - training loss: 0.7476, validation loss: 0.3820
2024-05-23 19:19:57 [INFO]: Epoch 004 - training loss: 0.6995, validation loss: 0.3723
2024-05-23 19:19:59 [INFO]: Epoch 005 - training loss: 0.6610, validation loss: 0.3647
2024-05-23 19:20:00 [INFO]: Epoch 006 - training loss: 0.6290, validation loss: 0.3451
2024-05-23 19:20:01 [INFO]: Epoch 007 - training loss: 0.6064, validation loss: 0.3366
2024-05-23 19:20:02 [INFO]: Epoch 008 - training loss: 0.5844, validation loss: 0.3310
2024-05-23 19:20:03 [INFO]: Epoch 009 - training loss: 0.5669, validation loss: 0.3150
2024-05-23 19:20:04 [INFO]: Epoch 010 - training loss: 0.5486, validation loss: 0.3076
2024-05-23 19:20:06 [INFO]: Epoch 011 - training loss: 0.5318, validation loss: 0.3021
2024-05-23 19:20:07 [INFO]: Epoch 012 - training loss: 0.5159, validation loss: 0.3053
2024-05-23 19:20:08 [INFO]: Epoch 013 - training loss: 0.5054, validation loss: 0.2963
2024-05-23 19:20:09 [INFO]: Epoch 014 - training loss: 0.4932, validation loss: 0.3000
2024-05-23 19:20:11 [INFO]: Epoch 015 - training loss: 0.4850, validation loss: 0.2974
2024-05-23 19:20:12 [INFO]: Epoch 016 - training loss: 0.4796, validation loss: 0.2969
2024-05-23 19:20:13 [INFO]: Epoch 017 - training loss: 0.4690, validation loss: 0.2974
2024-05-23 19:20:14 [INFO]: Epoch 018 - training loss: 0.4627, validation loss: 0.2934
2024-05-23 19:20:15 [INFO]: Epoch 019 - training loss: 0.4540, validation loss: 0.2898
2024-05-23 19:20:17 [INFO]: Epoch 020 - training loss: 0.4453, validation loss: 0.2909
2024-05-23 19:20:18 [INFO]: Epoch 021 - training loss: 0.4434, validation loss: 0.2944
2024-05-23 19:20:19 [INFO]: Epoch 022 - training loss: 0.4362, validation loss: 0.2953
2024-05-23 19:20:20 [INFO]: Epoch 023 - training loss: 0.4334, validation loss: 0.2912
2024-05-23 19:20:21 [INFO]: Epoch 024 - training loss: 0.4309, validation loss: 0.2913
2024-05-23 19:20:22 [INFO]: Epoch 025 - training loss: 0.4233, validation loss: 0.2914
2024-05-23 19:20:24 [INFO]: Epoch 026 - training loss: 0.4193, validation loss: 0.2937
2024-05-23 19:20:25 [INFO]: Epoch 027 - training loss: 0.4161, validation loss: 0.2914
2024-05-23 19:20:26 [INFO]: Epoch 028 - training loss: 0.4097, validation loss: 0.2882
2024-05-23 19:20:28 [INFO]: Epoch 029 - training loss: 0.4060, validation loss: 0.2931
2024-05-23 19:20:29 [INFO]: Epoch 030 - training loss: 0.4067, validation loss: 0.2902
2024-05-23 19:20:30 [INFO]: Epoch 031 - training loss: 0.4020, validation loss: 0.2952
2024-05-23 19:20:31 [INFO]: Epoch 032 - training loss: 0.3986, validation loss: 0.2939
2024-05-23 19:20:32 [INFO]: Epoch 033 - training loss: 0.3971, validation loss: 0.2899
2024-05-23 19:20:33 [INFO]: Epoch 034 - training loss: 0.3970, validation loss: 0.3011
2024-05-23 19:20:35 [INFO]: Epoch 035 - training loss: 0.3910, validation loss: 0.2953
2024-05-23 19:20:36 [INFO]: Epoch 036 - training loss: 0.3888, validation loss: 0.2926
2024-05-23 19:20:37 [INFO]: Epoch 037 - training loss: 0.3861, validation loss: 0.2942
2024-05-23 19:20:38 [INFO]: Epoch 038 - training loss: 0.3849, validation loss: 0.2919
2024-05-23 19:20:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:20:38 [INFO]: Finished training. The best model is from epoch#28.
2024-05-23 19:20:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_physionet_2012_seta/20240523_T191953/SAITS.pypots
2024-05-23 19:20:38 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2771, MSE=0.3228
2024-05-23 19:20:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 19:20:39 [INFO]: Using the given device: cuda:0
2024-05-23 19:20:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T192039
2024-05-23 19:20:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T192039/tensorboard
2024-05-23 19:20:39 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 19:20:39 [INFO]: Epoch 001 - training loss: 1.1393, validation loss: 0.5554
2024-05-23 19:20:40 [INFO]: Epoch 002 - training loss: 0.7435, validation loss: 0.4793
2024-05-23 19:20:41 [INFO]: Epoch 003 - training loss: 0.6376, validation loss: 0.4493
2024-05-23 19:20:41 [INFO]: Epoch 004 - training loss: 0.5855, validation loss: 0.4257
2024-05-23 19:20:42 [INFO]: Epoch 005 - training loss: 0.5455, validation loss: 0.4121
2024-05-23 19:20:42 [INFO]: Epoch 006 - training loss: 0.5013, validation loss: 0.3939
2024-05-23 19:20:43 [INFO]: Epoch 007 - training loss: 0.4785, validation loss: 0.3847
2024-05-23 19:20:44 [INFO]: Epoch 008 - training loss: 0.4619, validation loss: 0.3745
2024-05-23 19:20:44 [INFO]: Epoch 009 - training loss: 0.4369, validation loss: 0.3621
2024-05-23 19:20:45 [INFO]: Epoch 010 - training loss: 0.4261, validation loss: 0.3593
2024-05-23 19:20:45 [INFO]: Epoch 011 - training loss: 0.4074, validation loss: 0.3540
2024-05-23 19:20:46 [INFO]: Epoch 012 - training loss: 0.3902, validation loss: 0.3426
2024-05-23 19:20:47 [INFO]: Epoch 013 - training loss: 0.3805, validation loss: 0.3413
2024-05-23 19:20:47 [INFO]: Epoch 014 - training loss: 0.3711, validation loss: 0.3394
2024-05-23 19:20:48 [INFO]: Epoch 015 - training loss: 0.3584, validation loss: 0.3396
2024-05-23 19:20:48 [INFO]: Epoch 016 - training loss: 0.3564, validation loss: 0.3361
2024-05-23 19:20:49 [INFO]: Epoch 017 - training loss: 0.3437, validation loss: 0.3337
2024-05-23 19:20:50 [INFO]: Epoch 018 - training loss: 0.3350, validation loss: 0.3281
2024-05-23 19:20:50 [INFO]: Epoch 019 - training loss: 0.3281, validation loss: 0.3261
2024-05-23 19:20:51 [INFO]: Epoch 020 - training loss: 0.3160, validation loss: 0.3244
2024-05-23 19:20:51 [INFO]: Epoch 021 - training loss: 0.3174, validation loss: 0.3246
2024-05-23 19:20:52 [INFO]: Epoch 022 - training loss: 0.3072, validation loss: 0.3221
2024-05-23 19:20:53 [INFO]: Epoch 023 - training loss: 0.3002, validation loss: 0.3236
2024-05-23 19:20:53 [INFO]: Epoch 024 - training loss: 0.2949, validation loss: 0.3175
2024-05-23 19:20:54 [INFO]: Epoch 025 - training loss: 0.2942, validation loss: 0.3234
2024-05-23 19:20:54 [INFO]: Epoch 026 - training loss: 0.2842, validation loss: 0.3215
2024-05-23 19:20:55 [INFO]: Epoch 027 - training loss: 0.2876, validation loss: 0.3190
2024-05-23 19:20:56 [INFO]: Epoch 028 - training loss: 0.2742, validation loss: 0.3146
2024-05-23 19:20:56 [INFO]: Epoch 029 - training loss: 0.2711, validation loss: 0.3166
2024-05-23 19:20:57 [INFO]: Epoch 030 - training loss: 0.2661, validation loss: 0.3190
2024-05-23 19:20:58 [INFO]: Epoch 031 - training loss: 0.2601, validation loss: 0.3140
2024-05-23 19:20:58 [INFO]: Epoch 032 - training loss: 0.2592, validation loss: 0.3157
2024-05-23 19:20:59 [INFO]: Epoch 033 - training loss: 0.2555, validation loss: 0.3171
2024-05-23 19:20:59 [INFO]: Epoch 034 - training loss: 0.2488, validation loss: 0.3119
2024-05-23 19:21:00 [INFO]: Epoch 035 - training loss: 0.2472, validation loss: 0.3146
2024-05-23 19:21:01 [INFO]: Epoch 036 - training loss: 0.2448, validation loss: 0.3100
2024-05-23 19:21:02 [INFO]: Epoch 037 - training loss: 0.2478, validation loss: 0.3170
2024-05-23 19:21:02 [INFO]: Epoch 038 - training loss: 0.2387, validation loss: 0.3122
2024-05-23 19:21:03 [INFO]: Epoch 039 - training loss: 0.2340, validation loss: 0.3119
2024-05-23 19:21:03 [INFO]: Epoch 040 - training loss: 0.2328, validation loss: 0.3161
2024-05-23 19:21:04 [INFO]: Epoch 041 - training loss: 0.2305, validation loss: 0.3141
2024-05-23 19:21:05 [INFO]: Epoch 042 - training loss: 0.2275, validation loss: 0.3168
2024-05-23 19:21:05 [INFO]: Epoch 043 - training loss: 0.2231, validation loss: 0.3180
2024-05-23 19:21:06 [INFO]: Epoch 044 - training loss: 0.2230, validation loss: 0.3164
2024-05-23 19:21:06 [INFO]: Epoch 045 - training loss: 0.2164, validation loss: 0.3113
2024-05-23 19:21:07 [INFO]: Epoch 046 - training loss: 0.2145, validation loss: 0.3170
2024-05-23 19:21:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:21:07 [INFO]: Finished training. The best model is from epoch#36.
2024-05-23 19:21:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_physionet_2012_seta/20240523_T192039/Transformer.pypots
2024-05-23 19:21:07 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2899, MSE=0.3344
2024-05-23 19:21:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 19:21:07 [INFO]: Using the given device: cuda:0
2024-05-23 19:21:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T192107
2024-05-23 19:21:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T192107/tensorboard
2024-05-23 19:21:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 19:21:08 [INFO]: Epoch 001 - training loss: 0.4840, validation loss: 0.3805
2024-05-23 19:21:09 [INFO]: Epoch 002 - training loss: 0.5964, validation loss: 0.3685
2024-05-23 19:21:10 [INFO]: Epoch 003 - training loss: 0.4168, validation loss: 0.3523
2024-05-23 19:21:10 [INFO]: Epoch 004 - training loss: 0.3820, validation loss: 0.3363
2024-05-23 19:21:11 [INFO]: Epoch 005 - training loss: 0.3351, validation loss: 0.3208
2024-05-23 19:21:12 [INFO]: Epoch 006 - training loss: 0.3156, validation loss: 0.3238
2024-05-23 19:21:13 [INFO]: Epoch 007 - training loss: 0.3127, validation loss: 0.3190
2024-05-23 19:21:13 [INFO]: Epoch 008 - training loss: 0.3017, validation loss: 0.3100
2024-05-23 19:21:14 [INFO]: Epoch 009 - training loss: 0.2869, validation loss: 0.2978
2024-05-23 19:21:15 [INFO]: Epoch 010 - training loss: 0.2811, validation loss: 0.2948
2024-05-23 19:21:15 [INFO]: Epoch 011 - training loss: 0.2747, validation loss: 0.3080
2024-05-23 19:21:16 [INFO]: Epoch 012 - training loss: 0.2726, validation loss: 0.3054
2024-05-23 19:21:17 [INFO]: Epoch 013 - training loss: 0.2621, validation loss: 0.2956
2024-05-23 19:21:17 [INFO]: Epoch 014 - training loss: 0.2618, validation loss: 0.2924
2024-05-23 19:21:18 [INFO]: Epoch 015 - training loss: 0.2542, validation loss: 0.3062
2024-05-23 19:21:19 [INFO]: Epoch 016 - training loss: 0.2559, validation loss: 0.2919
2024-05-23 19:21:20 [INFO]: Epoch 017 - training loss: 0.2364, validation loss: 0.2900
2024-05-23 19:21:20 [INFO]: Epoch 018 - training loss: 0.2358, validation loss: 0.2942
2024-05-23 19:21:21 [INFO]: Epoch 019 - training loss: 0.2392, validation loss: 0.3039
2024-05-23 19:21:22 [INFO]: Epoch 020 - training loss: 0.2396, validation loss: 0.2937
2024-05-23 19:21:22 [INFO]: Epoch 021 - training loss: 0.2341, validation loss: 0.2939
2024-05-23 19:21:23 [INFO]: Epoch 022 - training loss: 0.2254, validation loss: 0.2890
2024-05-23 19:21:24 [INFO]: Epoch 023 - training loss: 0.2278, validation loss: 0.2887
2024-05-23 19:21:25 [INFO]: Epoch 024 - training loss: 0.2178, validation loss: 0.2902
2024-05-23 19:21:25 [INFO]: Epoch 025 - training loss: 0.2128, validation loss: 0.2954
2024-05-23 19:21:26 [INFO]: Epoch 026 - training loss: 0.2104, validation loss: 0.2944
2024-05-23 19:21:27 [INFO]: Epoch 027 - training loss: 0.2118, validation loss: 0.3040
2024-05-23 19:21:27 [INFO]: Epoch 028 - training loss: 0.1991, validation loss: 0.3060
2024-05-23 19:21:28 [INFO]: Epoch 029 - training loss: 0.2018, validation loss: 0.3009
2024-05-23 19:21:29 [INFO]: Epoch 030 - training loss: 0.2011, validation loss: 0.2999
2024-05-23 19:21:30 [INFO]: Epoch 031 - training loss: 0.1955, validation loss: 0.3025
2024-05-23 19:21:30 [INFO]: Epoch 032 - training loss: 0.1955, validation loss: 0.2999
2024-05-23 19:21:31 [INFO]: Epoch 033 - training loss: 0.1925, validation loss: 0.3074
2024-05-23 19:21:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:21:31 [INFO]: Finished training. The best model is from epoch#23.
2024-05-23 19:21:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_physionet_2012_seta/20240523_T192107/TimesNet.pypots
2024-05-23 19:21:31 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2969, MSE=0.3105
2024-05-23 19:21:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 19:21:31 [INFO]: Using the given device: cuda:0
2024-05-23 19:21:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131
2024-05-23 19:21:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/tensorboard
2024-05-23 19:21:31 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 19:22:15 [INFO]: Epoch 001 - training loss: 0.4204, validation loss: 0.3379
2024-05-23 19:22:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch1_loss0.33785253316164016.pypots
2024-05-23 19:22:58 [INFO]: Epoch 002 - training loss: 0.3168, validation loss: 0.2975
2024-05-23 19:22:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch2_loss0.29748289436101916.pypots
2024-05-23 19:23:42 [INFO]: Epoch 003 - training loss: 0.2913, validation loss: 0.2708
2024-05-23 19:23:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch3_loss0.2707592576742172.pypots
2024-05-23 19:24:26 [INFO]: Epoch 004 - training loss: 0.2734, validation loss: 0.2573
2024-05-23 19:24:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch4_loss0.2573249973356724.pypots
2024-05-23 19:25:10 [INFO]: Epoch 005 - training loss: 0.2532, validation loss: 0.2390
2024-05-23 19:25:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch5_loss0.23898497447371483.pypots
2024-05-23 19:25:54 [INFO]: Epoch 006 - training loss: 0.2458, validation loss: 0.2323
2024-05-23 19:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch6_loss0.23234123587608338.pypots
2024-05-23 19:26:38 [INFO]: Epoch 007 - training loss: 0.2380, validation loss: 0.2261
2024-05-23 19:26:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch7_loss0.22608667314052583.pypots
2024-05-23 19:27:22 [INFO]: Epoch 008 - training loss: 0.2377, validation loss: 0.2238
2024-05-23 19:27:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch8_loss0.2237823151051998.pypots
2024-05-23 19:28:07 [INFO]: Epoch 009 - training loss: 0.2348, validation loss: 0.2223
2024-05-23 19:28:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch9_loss0.22228963375091554.pypots
2024-05-23 19:28:51 [INFO]: Epoch 010 - training loss: 0.2292, validation loss: 0.2166
2024-05-23 19:28:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch10_loss0.21661591529846191.pypots
2024-05-23 19:29:35 [INFO]: Epoch 011 - training loss: 0.2239, validation loss: 0.2148
2024-05-23 19:29:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch11_loss0.21481078043580054.pypots
2024-05-23 19:30:19 [INFO]: Epoch 012 - training loss: 0.2225, validation loss: 0.2095
2024-05-23 19:30:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch12_loss0.2094849944114685.pypots
2024-05-23 19:31:03 [INFO]: Epoch 013 - training loss: 0.2151, validation loss: 0.2044
2024-05-23 19:31:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch13_loss0.2044132187962532.pypots
2024-05-23 19:31:47 [INFO]: Epoch 014 - training loss: 0.2192, validation loss: 0.2103
2024-05-23 19:31:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch14_loss0.2102558620274067.pypots
2024-05-23 19:32:31 [INFO]: Epoch 015 - training loss: 0.2222, validation loss: 0.2086
2024-05-23 19:32:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch15_loss0.20862528830766677.pypots
2024-05-23 19:33:15 [INFO]: Epoch 016 - training loss: 0.2086, validation loss: 0.2071
2024-05-23 19:33:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch16_loss0.2070699580013752.pypots
2024-05-23 19:33:59 [INFO]: Epoch 017 - training loss: 0.2145, validation loss: 0.2008
2024-05-23 19:33:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch17_loss0.20082204788923264.pypots
2024-05-23 19:34:43 [INFO]: Epoch 018 - training loss: 0.2195, validation loss: 0.2011
2024-05-23 19:34:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch18_loss0.20109550505876542.pypots
2024-05-23 19:35:27 [INFO]: Epoch 019 - training loss: 0.2060, validation loss: 0.2004
2024-05-23 19:35:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch19_loss0.20035148784518242.pypots
2024-05-23 19:36:11 [INFO]: Epoch 020 - training loss: 0.2025, validation loss: 0.2019
2024-05-23 19:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch20_loss0.20188339799642563.pypots
2024-05-23 19:36:55 [INFO]: Epoch 021 - training loss: 0.2162, validation loss: 0.2003
2024-05-23 19:36:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch21_loss0.20025688037276268.pypots
2024-05-23 19:37:39 [INFO]: Epoch 022 - training loss: 0.2163, validation loss: 0.2014
2024-05-23 19:37:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch22_loss0.20143291354179382.pypots
2024-05-23 19:38:23 [INFO]: Epoch 023 - training loss: 0.2081, validation loss: 0.2002
2024-05-23 19:38:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch23_loss0.20020379424095153.pypots
2024-05-23 19:39:07 [INFO]: Epoch 024 - training loss: 0.2112, validation loss: 0.2000
2024-05-23 19:39:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch24_loss0.19997793361544608.pypots
2024-05-23 19:39:51 [INFO]: Epoch 025 - training loss: 0.2093, validation loss: 0.1953
2024-05-23 19:39:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch25_loss0.1953133910894394.pypots
2024-05-23 19:40:35 [INFO]: Epoch 026 - training loss: 0.2172, validation loss: 0.1978
2024-05-23 19:40:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch26_loss0.1978243999183178.pypots
2024-05-23 19:41:20 [INFO]: Epoch 027 - training loss: 0.2076, validation loss: 0.1970
2024-05-23 19:41:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch27_loss0.19700952544808387.pypots
2024-05-23 19:42:04 [INFO]: Epoch 028 - training loss: 0.1998, validation loss: 0.1971
2024-05-23 19:42:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch28_loss0.19705561697483062.pypots
2024-05-23 19:42:48 [INFO]: Epoch 029 - training loss: 0.2106, validation loss: 0.1954
2024-05-23 19:42:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch29_loss0.19542418643832207.pypots
2024-05-23 19:43:32 [INFO]: Epoch 030 - training loss: 0.2004, validation loss: 0.1953
2024-05-23 19:43:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch30_loss0.19531513452529908.pypots
2024-05-23 19:44:16 [INFO]: Epoch 031 - training loss: 0.2119, validation loss: 0.1980
2024-05-23 19:44:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch31_loss0.19798010662198068.pypots
2024-05-23 19:45:00 [INFO]: Epoch 032 - training loss: 0.2124, validation loss: 0.1921
2024-05-23 19:45:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch32_loss0.19213431626558303.pypots
2024-05-23 19:45:44 [INFO]: Epoch 033 - training loss: 0.2021, validation loss: 0.1933
2024-05-23 19:45:44 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch33_loss0.19329252243041992.pypots
2024-05-23 19:46:28 [INFO]: Epoch 034 - training loss: 0.1948, validation loss: 0.1914
2024-05-23 19:46:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch34_loss0.19143714457750322.pypots
2024-05-23 19:47:12 [INFO]: Epoch 035 - training loss: 0.1978, validation loss: 0.1970
2024-05-23 19:47:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch35_loss0.1970222271978855.pypots
2024-05-23 19:47:56 [INFO]: Epoch 036 - training loss: 0.1921, validation loss: 0.1927
2024-05-23 19:47:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch36_loss0.1927330270409584.pypots
2024-05-23 19:48:40 [INFO]: Epoch 037 - training loss: 0.2091, validation loss: 0.1933
2024-05-23 19:48:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch37_loss0.193270680308342.pypots
2024-05-23 19:49:25 [INFO]: Epoch 038 - training loss: 0.1947, validation loss: 0.1944
2024-05-23 19:49:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch38_loss0.19441806375980378.pypots
2024-05-23 19:50:09 [INFO]: Epoch 039 - training loss: 0.1941, validation loss: 0.1901
2024-05-23 19:50:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch39_loss0.19005480781197548.pypots
2024-05-23 19:50:53 [INFO]: Epoch 040 - training loss: 0.2070, validation loss: 0.1908
2024-05-23 19:50:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch40_loss0.19082003608345985.pypots
2024-05-23 19:51:37 [INFO]: Epoch 041 - training loss: 0.2022, validation loss: 0.1929
2024-05-23 19:51:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch41_loss0.192928284406662.pypots
2024-05-23 19:52:21 [INFO]: Epoch 042 - training loss: 0.2043, validation loss: 0.1959
2024-05-23 19:52:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch42_loss0.1959248326718807.pypots
2024-05-23 19:53:05 [INFO]: Epoch 043 - training loss: 0.1969, validation loss: 0.1906
2024-05-23 19:53:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch43_loss0.19063883274793625.pypots
2024-05-23 19:53:50 [INFO]: Epoch 044 - training loss: 0.1956, validation loss: 0.1879
2024-05-23 19:53:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch44_loss0.18786370977759362.pypots
2024-05-23 19:54:34 [INFO]: Epoch 045 - training loss: 0.1995, validation loss: 0.1919
2024-05-23 19:54:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch45_loss0.191916374117136.pypots
2024-05-23 19:55:18 [INFO]: Epoch 046 - training loss: 0.1932, validation loss: 0.1898
2024-05-23 19:55:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch46_loss0.18976975604891777.pypots
2024-05-23 19:56:02 [INFO]: Epoch 047 - training loss: 0.1959, validation loss: 0.1881
2024-05-23 19:56:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch47_loss0.1881097972393036.pypots
2024-05-23 19:56:46 [INFO]: Epoch 048 - training loss: 0.2002, validation loss: 0.1892
2024-05-23 19:56:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch48_loss0.18917894288897513.pypots
2024-05-23 19:57:30 [INFO]: Epoch 049 - training loss: 0.2005, validation loss: 0.1911
2024-05-23 19:57:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch49_loss0.1911494143307209.pypots
2024-05-23 19:58:14 [INFO]: Epoch 050 - training loss: 0.2004, validation loss: 0.1913
2024-05-23 19:58:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch50_loss0.19129845574498178.pypots
2024-05-23 19:58:59 [INFO]: Epoch 051 - training loss: 0.1980, validation loss: 0.1879
2024-05-23 19:58:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch51_loss0.18790731504559516.pypots
2024-05-23 19:59:43 [INFO]: Epoch 052 - training loss: 0.1900, validation loss: 0.1874
2024-05-23 19:59:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch52_loss0.1874086745083332.pypots
2024-05-23 20:00:27 [INFO]: Epoch 053 - training loss: 0.1899, validation loss: 0.1888
2024-05-23 20:00:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch53_loss0.18875891268253325.pypots
2024-05-23 20:01:11 [INFO]: Epoch 054 - training loss: 0.1928, validation loss: 0.1899
2024-05-23 20:01:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch54_loss0.18986351490020753.pypots
2024-05-23 20:01:55 [INFO]: Epoch 055 - training loss: 0.1897, validation loss: 0.1853
2024-05-23 20:01:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch55_loss0.18525405004620552.pypots
2024-05-23 20:02:39 [INFO]: Epoch 056 - training loss: 0.1966, validation loss: 0.1845
2024-05-23 20:02:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch56_loss0.1845196284353733.pypots
2024-05-23 20:03:23 [INFO]: Epoch 057 - training loss: 0.2018, validation loss: 0.1908
2024-05-23 20:03:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch57_loss0.19079963639378547.pypots
2024-05-23 20:04:07 [INFO]: Epoch 058 - training loss: 0.1883, validation loss: 0.1864
2024-05-23 20:04:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch58_loss0.18635290637612342.pypots
2024-05-23 20:04:51 [INFO]: Epoch 059 - training loss: 0.1950, validation loss: 0.1870
2024-05-23 20:04:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch59_loss0.18698329403996466.pypots
2024-05-23 20:05:35 [INFO]: Epoch 060 - training loss: 0.1997, validation loss: 0.1929
2024-05-23 20:05:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch60_loss0.19288599789142608.pypots
2024-05-23 20:06:19 [INFO]: Epoch 061 - training loss: 0.1857, validation loss: 0.1862
2024-05-23 20:06:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch61_loss0.18616420924663543.pypots
2024-05-23 20:07:03 [INFO]: Epoch 062 - training loss: 0.2005, validation loss: 0.1888
2024-05-23 20:07:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch62_loss0.1887522205710411.pypots
2024-05-23 20:07:47 [INFO]: Epoch 063 - training loss: 0.1829, validation loss: 0.1873
2024-05-23 20:07:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch63_loss0.18732037022709846.pypots
2024-05-23 20:08:31 [INFO]: Epoch 064 - training loss: 0.2001, validation loss: 0.1893
2024-05-23 20:08:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch64_loss0.18932013362646102.pypots
2024-05-23 20:09:15 [INFO]: Epoch 065 - training loss: 0.1882, validation loss: 0.1840
2024-05-23 20:09:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch65_loss0.1839996337890625.pypots
2024-05-23 20:09:59 [INFO]: Epoch 066 - training loss: 0.1966, validation loss: 0.1848
2024-05-23 20:09:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch66_loss0.1847989432513714.pypots
2024-05-23 20:10:43 [INFO]: Epoch 067 - training loss: 0.1900, validation loss: 0.1864
2024-05-23 20:10:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch67_loss0.18640004098415375.pypots
2024-05-23 20:11:28 [INFO]: Epoch 068 - training loss: 0.1907, validation loss: 0.1865
2024-05-23 20:11:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch68_loss0.18646188899874688.pypots
2024-05-23 20:12:12 [INFO]: Epoch 069 - training loss: 0.1975, validation loss: 0.1863
2024-05-23 20:12:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch69_loss0.18625516071915627.pypots
2024-05-23 20:12:56 [INFO]: Epoch 070 - training loss: 0.1910, validation loss: 0.1893
2024-05-23 20:12:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch70_loss0.18932553976774216.pypots
2024-05-23 20:13:40 [INFO]: Epoch 071 - training loss: 0.1927, validation loss: 0.1825
2024-05-23 20:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch71_loss0.18245562836527823.pypots
2024-05-23 20:14:24 [INFO]: Epoch 072 - training loss: 0.2005, validation loss: 0.1840
2024-05-23 20:14:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch72_loss0.18404894322156906.pypots
2024-05-23 20:15:08 [INFO]: Epoch 073 - training loss: 0.2023, validation loss: 0.1835
2024-05-23 20:15:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch73_loss0.18345634862780572.pypots
2024-05-23 20:15:52 [INFO]: Epoch 074 - training loss: 0.1888, validation loss: 0.1838
2024-05-23 20:15:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch74_loss0.18381259068846703.pypots
2024-05-23 20:16:36 [INFO]: Epoch 075 - training loss: 0.1811, validation loss: 0.1835
2024-05-23 20:16:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch75_loss0.18345529288053514.pypots
2024-05-23 20:17:20 [INFO]: Epoch 076 - training loss: 0.1871, validation loss: 0.1832
2024-05-23 20:17:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch76_loss0.18320294842123985.pypots
2024-05-23 20:18:04 [INFO]: Epoch 077 - training loss: 0.1875, validation loss: 0.1835
2024-05-23 20:18:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch77_loss0.18347875475883485.pypots
2024-05-23 20:18:48 [INFO]: Epoch 078 - training loss: 0.1825, validation loss: 0.1832
2024-05-23 20:18:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch78_loss0.1831715352833271.pypots
2024-05-23 20:19:32 [INFO]: Epoch 079 - training loss: 0.1910, validation loss: 0.1868
2024-05-23 20:19:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch79_loss0.18683001399040222.pypots
2024-05-23 20:20:17 [INFO]: Epoch 080 - training loss: 0.1860, validation loss: 0.1860
2024-05-23 20:20:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch80_loss0.185960041731596.pypots
2024-05-23 20:21:01 [INFO]: Epoch 081 - training loss: 0.1944, validation loss: 0.1844
2024-05-23 20:21:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI_epoch81_loss0.18441387116909028.pypots
2024-05-23 20:21:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:21:01 [INFO]: Finished training. The best model is from epoch#71.
2024-05-23 20:21:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/20240523_T192131/CSDI.pypots
2024-05-23 20:28:24 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2557, MSE=0.5804
2024-05-23 20:57:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 20:57:56 [INFO]: Using the given device: cuda:0
2024-05-23 20:57:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T205756
2024-05-23 20:57:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T205756/tensorboard
2024-05-23 20:57:56 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 20:57:57 [INFO]: Epoch 001 - training loss: 42819.7011, validation loss: 0.9349
2024-05-23 20:57:58 [INFO]: Epoch 002 - training loss: 24449.1059, validation loss: 0.7435
2024-05-23 20:57:58 [INFO]: Epoch 003 - training loss: 23488.8206, validation loss: 0.6998
2024-05-23 20:57:59 [INFO]: Epoch 004 - training loss: 23185.8602, validation loss: 0.6605
2024-05-23 20:58:00 [INFO]: Epoch 005 - training loss: 23036.7000, validation loss: 0.6505
2024-05-23 20:58:00 [INFO]: Epoch 006 - training loss: 22954.7485, validation loss: 0.6455
2024-05-23 20:58:01 [INFO]: Epoch 007 - training loss: 22904.8325, validation loss: 0.6404
2024-05-23 20:58:02 [INFO]: Epoch 008 - training loss: 22873.0045, validation loss: 0.6409
2024-05-23 20:58:03 [INFO]: Epoch 009 - training loss: 22851.6658, validation loss: 0.6379
2024-05-23 20:58:03 [INFO]: Epoch 010 - training loss: 22837.1667, validation loss: 0.6536
2024-05-23 20:58:04 [INFO]: Epoch 011 - training loss: 22826.8202, validation loss: 0.6379
2024-05-23 20:58:05 [INFO]: Epoch 012 - training loss: 22818.6798, validation loss: 0.6364
2024-05-23 20:58:05 [INFO]: Epoch 013 - training loss: 22812.7277, validation loss: 0.6383
2024-05-23 20:58:06 [INFO]: Epoch 014 - training loss: 22808.3623, validation loss: 0.6332
2024-05-23 20:58:07 [INFO]: Epoch 015 - training loss: 22804.1052, validation loss: 0.6326
2024-05-23 20:58:08 [INFO]: Epoch 016 - training loss: 22800.5724, validation loss: 0.6294
2024-05-23 20:58:08 [INFO]: Epoch 017 - training loss: 22798.3890, validation loss: 0.6236
2024-05-23 20:58:09 [INFO]: Epoch 018 - training loss: 22796.5801, validation loss: 0.6232
2024-05-23 20:58:10 [INFO]: Epoch 019 - training loss: 22794.0888, validation loss: 0.6160
2024-05-23 20:58:10 [INFO]: Epoch 020 - training loss: 22792.4609, validation loss: 0.6132
2024-05-23 20:58:11 [INFO]: Epoch 021 - training loss: 22790.7703, validation loss: 0.6111
2024-05-23 20:58:12 [INFO]: Epoch 022 - training loss: 22789.5013, validation loss: 0.6088
2024-05-23 20:58:13 [INFO]: Epoch 023 - training loss: 22788.4108, validation loss: 0.6086
2024-05-23 20:58:13 [INFO]: Epoch 024 - training loss: 22786.8953, validation loss: 0.6133
2024-05-23 20:58:14 [INFO]: Epoch 025 - training loss: 22786.0147, validation loss: 0.6008
2024-05-23 20:58:15 [INFO]: Epoch 026 - training loss: 22785.4605, validation loss: 0.6013
2024-05-23 20:58:15 [INFO]: Epoch 027 - training loss: 22784.5789, validation loss: 0.5994
2024-05-23 20:58:16 [INFO]: Epoch 028 - training loss: 22785.0017, validation loss: 0.5995
2024-05-23 20:58:17 [INFO]: Epoch 029 - training loss: 22785.1415, validation loss: 0.6015
2024-05-23 20:58:18 [INFO]: Epoch 030 - training loss: 22784.0568, validation loss: 0.6092
2024-05-23 20:58:18 [INFO]: Epoch 031 - training loss: 22783.6311, validation loss: 0.6078
2024-05-23 20:58:19 [INFO]: Epoch 032 - training loss: 22784.2067, validation loss: 0.5974
2024-05-23 20:58:20 [INFO]: Epoch 033 - training loss: 22781.6219, validation loss: 0.5974
2024-05-23 20:58:20 [INFO]: Epoch 034 - training loss: 22780.8774, validation loss: 0.6021
2024-05-23 20:58:21 [INFO]: Epoch 035 - training loss: 22781.4348, validation loss: 0.5941
2024-05-23 20:58:22 [INFO]: Epoch 036 - training loss: 22780.5522, validation loss: 0.5966
2024-05-23 20:58:22 [INFO]: Epoch 037 - training loss: 22779.8220, validation loss: 0.5892
2024-05-23 20:58:23 [INFO]: Epoch 038 - training loss: 22779.1691, validation loss: 0.5868
2024-05-23 20:58:24 [INFO]: Epoch 039 - training loss: 22778.4965, validation loss: 0.5837
2024-05-23 20:58:25 [INFO]: Epoch 040 - training loss: 22777.2796, validation loss: 0.5961
2024-05-23 20:58:25 [INFO]: Epoch 041 - training loss: 22776.3928, validation loss: 0.5836
2024-05-23 20:58:26 [INFO]: Epoch 042 - training loss: 22776.2096, validation loss: 0.5728
2024-05-23 20:58:27 [INFO]: Epoch 043 - training loss: 22774.7675, validation loss: 0.5694
2024-05-23 20:58:27 [INFO]: Epoch 044 - training loss: 22772.9310, validation loss: 0.5642
2024-05-23 20:58:28 [INFO]: Epoch 045 - training loss: 22771.6155, validation loss: 0.5578
2024-05-23 20:58:29 [INFO]: Epoch 046 - training loss: 22770.3072, validation loss: 0.5779
2024-05-23 20:58:30 [INFO]: Epoch 047 - training loss: 22769.4852, validation loss: 0.5575
2024-05-23 20:58:30 [INFO]: Epoch 048 - training loss: 22768.2985, validation loss: 0.5489
2024-05-23 20:58:31 [INFO]: Epoch 049 - training loss: 22767.4385, validation loss: 0.5504
2024-05-23 20:58:32 [INFO]: Epoch 050 - training loss: 22767.0997, validation loss: 0.5453
2024-05-23 20:58:32 [INFO]: Epoch 051 - training loss: 22767.0268, validation loss: 0.5396
2024-05-23 20:58:33 [INFO]: Epoch 052 - training loss: 22765.9260, validation loss: 0.5401
2024-05-23 20:58:34 [INFO]: Epoch 053 - training loss: 22764.9341, validation loss: 0.5370
2024-05-23 20:58:35 [INFO]: Epoch 054 - training loss: 22764.7981, validation loss: 0.5361
2024-05-23 20:58:35 [INFO]: Epoch 055 - training loss: 22763.5275, validation loss: 0.5327
2024-05-23 20:58:36 [INFO]: Epoch 056 - training loss: 22762.9494, validation loss: 0.5297
2024-05-23 20:58:37 [INFO]: Epoch 057 - training loss: 22762.5656, validation loss: 0.5554
2024-05-23 20:58:37 [INFO]: Epoch 058 - training loss: 22762.4674, validation loss: 0.5267
2024-05-23 20:58:38 [INFO]: Epoch 059 - training loss: 22761.6261, validation loss: 0.5276
2024-05-23 20:58:39 [INFO]: Epoch 060 - training loss: 22760.9063, validation loss: 0.5211
2024-05-23 20:58:39 [INFO]: Epoch 061 - training loss: 22760.4751, validation loss: 0.5193
2024-05-23 20:58:40 [INFO]: Epoch 062 - training loss: 22760.3937, validation loss: 0.5238
2024-05-23 20:58:41 [INFO]: Epoch 063 - training loss: 22760.5852, validation loss: 0.5151
2024-05-23 20:58:42 [INFO]: Epoch 064 - training loss: 22760.5413, validation loss: 0.5312
2024-05-23 20:58:42 [INFO]: Epoch 065 - training loss: 22760.2202, validation loss: 0.5148
2024-05-23 20:58:43 [INFO]: Epoch 066 - training loss: 22759.3737, validation loss: 0.5252
2024-05-23 20:58:44 [INFO]: Epoch 067 - training loss: 22759.3135, validation loss: 0.5170
2024-05-23 20:58:44 [INFO]: Epoch 068 - training loss: 22757.9067, validation loss: 0.5291
2024-05-23 20:58:45 [INFO]: Epoch 069 - training loss: 22758.8424, validation loss: 0.5090
2024-05-23 20:58:46 [INFO]: Epoch 070 - training loss: 22757.7714, validation loss: 0.5138
2024-05-23 20:58:47 [INFO]: Epoch 071 - training loss: 22756.5403, validation loss: 0.5022
2024-05-23 20:58:47 [INFO]: Epoch 072 - training loss: 22756.4396, validation loss: 0.4967
2024-05-23 20:58:48 [INFO]: Epoch 073 - training loss: 22755.4726, validation loss: 0.4935
2024-05-23 20:58:49 [INFO]: Epoch 074 - training loss: 22754.8130, validation loss: 0.5059
2024-05-23 20:58:49 [INFO]: Epoch 075 - training loss: 22754.4961, validation loss: 0.4951
2024-05-23 20:58:50 [INFO]: Epoch 076 - training loss: 22754.3774, validation loss: 0.4909
2024-05-23 20:58:51 [INFO]: Epoch 077 - training loss: 22753.9240, validation loss: 0.4971
2024-05-23 20:58:51 [INFO]: Epoch 078 - training loss: 22753.8939, validation loss: 0.4898
2024-05-23 20:58:52 [INFO]: Epoch 079 - training loss: 22754.3556, validation loss: 0.5036
2024-05-23 20:58:53 [INFO]: Epoch 080 - training loss: 22756.5976, validation loss: 0.5020
2024-05-23 20:58:54 [INFO]: Epoch 081 - training loss: 22754.2504, validation loss: 0.4880
2024-05-23 20:58:54 [INFO]: Epoch 082 - training loss: 22753.0106, validation loss: 0.4871
2024-05-23 20:58:55 [INFO]: Epoch 083 - training loss: 22752.9139, validation loss: 0.4847
2024-05-23 20:58:56 [INFO]: Epoch 084 - training loss: 22751.8841, validation loss: 0.4858
2024-05-23 20:58:56 [INFO]: Epoch 085 - training loss: 22751.8799, validation loss: 0.4867
2024-05-23 20:58:57 [INFO]: Epoch 086 - training loss: 22751.4267, validation loss: 0.4848
2024-05-23 20:58:58 [INFO]: Epoch 087 - training loss: 22751.5205, validation loss: 0.4889
2024-05-23 20:58:59 [INFO]: Epoch 088 - training loss: 22751.6788, validation loss: 0.4804
2024-05-23 20:58:59 [INFO]: Epoch 089 - training loss: 22751.4260, validation loss: 0.4854
2024-05-23 20:59:00 [INFO]: Epoch 090 - training loss: 22750.9264, validation loss: 0.4834
2024-05-23 20:59:01 [INFO]: Epoch 091 - training loss: 22752.4362, validation loss: 0.4812
2024-05-23 20:59:01 [INFO]: Epoch 092 - training loss: 22750.5162, validation loss: 0.4802
2024-05-23 20:59:02 [INFO]: Epoch 093 - training loss: 22750.5194, validation loss: 0.4818
2024-05-23 20:59:03 [INFO]: Epoch 094 - training loss: 22750.3165, validation loss: 0.4860
2024-05-23 20:59:04 [INFO]: Epoch 095 - training loss: 22750.1458, validation loss: 0.4788
2024-05-23 20:59:04 [INFO]: Epoch 096 - training loss: 22749.9397, validation loss: 0.4790
2024-05-23 20:59:05 [INFO]: Epoch 097 - training loss: 22749.7188, validation loss: 0.4818
2024-05-23 20:59:06 [INFO]: Epoch 098 - training loss: 22749.5417, validation loss: 0.4747
2024-05-23 20:59:06 [INFO]: Epoch 099 - training loss: 22749.2785, validation loss: 0.4802
2024-05-23 20:59:07 [INFO]: Epoch 100 - training loss: 22749.2651, validation loss: 0.4798
2024-05-23 20:59:08 [INFO]: Epoch 101 - training loss: 22749.1216, validation loss: 0.4859
2024-05-23 20:59:08 [INFO]: Epoch 102 - training loss: 22749.5839, validation loss: 0.4826
2024-05-23 20:59:09 [INFO]: Epoch 103 - training loss: 22751.3553, validation loss: 0.4766
2024-05-23 20:59:10 [INFO]: Epoch 104 - training loss: 22750.2932, validation loss: 0.4764
2024-05-23 20:59:11 [INFO]: Epoch 105 - training loss: 22748.1246, validation loss: 0.4715
2024-05-23 20:59:11 [INFO]: Epoch 106 - training loss: 22748.6040, validation loss: 0.4725
2024-05-23 20:59:12 [INFO]: Epoch 107 - training loss: 22748.3878, validation loss: 0.4700
2024-05-23 20:59:13 [INFO]: Epoch 108 - training loss: 22747.7394, validation loss: 0.4747
2024-05-23 20:59:13 [INFO]: Epoch 109 - training loss: 22747.6305, validation loss: 0.4740
2024-05-23 20:59:14 [INFO]: Epoch 110 - training loss: 22749.8833, validation loss: 0.4731
2024-05-23 20:59:15 [INFO]: Epoch 111 - training loss: 22748.1002, validation loss: 0.4728
2024-05-23 20:59:16 [INFO]: Epoch 112 - training loss: 22747.3860, validation loss: 0.4730
2024-05-23 20:59:16 [INFO]: Epoch 113 - training loss: 22747.1404, validation loss: 0.4697
2024-05-23 20:59:17 [INFO]: Epoch 114 - training loss: 22746.6532, validation loss: 0.4727
2024-05-23 20:59:18 [INFO]: Epoch 115 - training loss: 22746.6652, validation loss: 0.4715
2024-05-23 20:59:18 [INFO]: Epoch 116 - training loss: 22746.6337, validation loss: 0.4718
2024-05-23 20:59:19 [INFO]: Epoch 117 - training loss: 22746.7652, validation loss: 0.4715
2024-05-23 20:59:20 [INFO]: Epoch 118 - training loss: 22746.8112, validation loss: 0.4703
2024-05-23 20:59:21 [INFO]: Epoch 119 - training loss: 22747.3092, validation loss: 0.4767
2024-05-23 20:59:21 [INFO]: Epoch 120 - training loss: 22747.4097, validation loss: 0.4690
2024-05-23 20:59:22 [INFO]: Epoch 121 - training loss: 22746.7909, validation loss: 0.4718
2024-05-23 20:59:23 [INFO]: Epoch 122 - training loss: 22746.3355, validation loss: 0.4690
2024-05-23 20:59:23 [INFO]: Epoch 123 - training loss: 22747.0467, validation loss: 0.4690
2024-05-23 20:59:24 [INFO]: Epoch 124 - training loss: 22747.1066, validation loss: 0.4676
2024-05-23 20:59:25 [INFO]: Epoch 125 - training loss: 22746.1552, validation loss: 0.4729
2024-05-23 20:59:25 [INFO]: Epoch 126 - training loss: 22746.4670, validation loss: 0.4708
2024-05-23 20:59:26 [INFO]: Epoch 127 - training loss: 22746.7602, validation loss: 0.4727
2024-05-23 20:59:27 [INFO]: Epoch 128 - training loss: 22746.3181, validation loss: 0.4702
2024-05-23 20:59:28 [INFO]: Epoch 129 - training loss: 22745.5372, validation loss: 0.4663
2024-05-23 20:59:28 [INFO]: Epoch 130 - training loss: 22745.7754, validation loss: 0.4712
2024-05-23 20:59:29 [INFO]: Epoch 131 - training loss: 22745.3502, validation loss: 0.4712
2024-05-23 20:59:30 [INFO]: Epoch 132 - training loss: 22745.9596, validation loss: 0.4683
2024-05-23 20:59:30 [INFO]: Epoch 133 - training loss: 22745.8390, validation loss: 0.4677
2024-05-23 20:59:31 [INFO]: Epoch 134 - training loss: 22746.5019, validation loss: 0.4672
2024-05-23 20:59:32 [INFO]: Epoch 135 - training loss: 22745.5990, validation loss: 0.4730
2024-05-23 20:59:33 [INFO]: Epoch 136 - training loss: 22746.4806, validation loss: 0.4672
2024-05-23 20:59:33 [INFO]: Epoch 137 - training loss: 22745.3143, validation loss: 0.4701
2024-05-23 20:59:34 [INFO]: Epoch 138 - training loss: 22745.9200, validation loss: 0.4658
2024-05-23 20:59:35 [INFO]: Epoch 139 - training loss: 22744.9730, validation loss: 0.4736
2024-05-23 20:59:35 [INFO]: Epoch 140 - training loss: 22744.7469, validation loss: 0.4635
2024-05-23 20:59:36 [INFO]: Epoch 141 - training loss: 22744.9361, validation loss: 0.4665
2024-05-23 20:59:37 [INFO]: Epoch 142 - training loss: 22744.3590, validation loss: 0.4634
2024-05-23 20:59:38 [INFO]: Epoch 143 - training loss: 22744.9547, validation loss: 0.4637
2024-05-23 20:59:38 [INFO]: Epoch 144 - training loss: 22744.3666, validation loss: 0.4649
2024-05-23 20:59:39 [INFO]: Epoch 145 - training loss: 22745.6236, validation loss: 0.4625
2024-05-23 20:59:40 [INFO]: Epoch 146 - training loss: 22745.4657, validation loss: 0.4640
2024-05-23 20:59:40 [INFO]: Epoch 147 - training loss: 22743.9056, validation loss: 0.4669
2024-05-23 20:59:41 [INFO]: Epoch 148 - training loss: 22746.9359, validation loss: 0.4644
2024-05-23 20:59:42 [INFO]: Epoch 149 - training loss: 22744.1265, validation loss: 0.4637
2024-05-23 20:59:43 [INFO]: Epoch 150 - training loss: 22743.9964, validation loss: 0.4609
2024-05-23 20:59:43 [INFO]: Epoch 151 - training loss: 22743.6731, validation loss: 0.4633
2024-05-23 20:59:44 [INFO]: Epoch 152 - training loss: 22743.8179, validation loss: 0.4590
2024-05-23 20:59:45 [INFO]: Epoch 153 - training loss: 22743.4672, validation loss: 0.4633
2024-05-23 20:59:45 [INFO]: Epoch 154 - training loss: 22743.6341, validation loss: 0.4582
2024-05-23 20:59:46 [INFO]: Epoch 155 - training loss: 22744.5344, validation loss: 0.4600
2024-05-23 20:59:47 [INFO]: Epoch 156 - training loss: 22743.6521, validation loss: 0.4602
2024-05-23 20:59:47 [INFO]: Epoch 157 - training loss: 22744.9690, validation loss: 0.4634
2024-05-23 20:59:48 [INFO]: Epoch 158 - training loss: 22743.5130, validation loss: 0.4604
2024-05-23 20:59:49 [INFO]: Epoch 159 - training loss: 22743.3507, validation loss: 0.4599
2024-05-23 20:59:50 [INFO]: Epoch 160 - training loss: 22743.2990, validation loss: 0.4581
2024-05-23 20:59:50 [INFO]: Epoch 161 - training loss: 22743.1146, validation loss: 0.4608
2024-05-23 20:59:51 [INFO]: Epoch 162 - training loss: 22742.9866, validation loss: 0.4609
2024-05-23 20:59:52 [INFO]: Epoch 163 - training loss: 22743.3605, validation loss: 0.4596
2024-05-23 20:59:52 [INFO]: Epoch 164 - training loss: 22743.4538, validation loss: 0.4568
2024-05-23 20:59:53 [INFO]: Epoch 165 - training loss: 22742.5004, validation loss: 0.4574
2024-05-23 20:59:54 [INFO]: Epoch 166 - training loss: 22742.6692, validation loss: 0.4604
2024-05-23 20:59:55 [INFO]: Epoch 167 - training loss: 22742.4343, validation loss: 0.4563
2024-05-23 20:59:55 [INFO]: Epoch 168 - training loss: 22742.5236, validation loss: 0.4592
2024-05-23 20:59:56 [INFO]: Epoch 169 - training loss: 22742.3558, validation loss: 0.4581
2024-05-23 20:59:57 [INFO]: Epoch 170 - training loss: 22742.5981, validation loss: 0.4595
2024-05-23 20:59:57 [INFO]: Epoch 171 - training loss: 22742.7321, validation loss: 0.4562
2024-05-23 20:59:58 [INFO]: Epoch 172 - training loss: 22742.2850, validation loss: 0.4637
2024-05-23 20:59:59 [INFO]: Epoch 173 - training loss: 22742.4981, validation loss: 0.4577
2024-05-23 21:00:00 [INFO]: Epoch 174 - training loss: 22742.5993, validation loss: 0.4614
2024-05-23 21:00:00 [INFO]: Epoch 175 - training loss: 22744.2445, validation loss: 0.4589
2024-05-23 21:00:01 [INFO]: Epoch 176 - training loss: 22742.3406, validation loss: 0.4586
2024-05-23 21:00:02 [INFO]: Epoch 177 - training loss: 22742.6365, validation loss: 0.4563
2024-05-23 21:00:02 [INFO]: Epoch 178 - training loss: 22741.8925, validation loss: 0.4575
2024-05-23 21:00:03 [INFO]: Epoch 179 - training loss: 22741.9990, validation loss: 0.4552
2024-05-23 21:00:04 [INFO]: Epoch 180 - training loss: 22742.0186, validation loss: 0.4546
2024-05-23 21:00:05 [INFO]: Epoch 181 - training loss: 22741.6878, validation loss: 0.4565
2024-05-23 21:00:05 [INFO]: Epoch 182 - training loss: 22741.6159, validation loss: 0.4565
2024-05-23 21:00:06 [INFO]: Epoch 183 - training loss: 22742.0703, validation loss: 0.4550
2024-05-23 21:00:07 [INFO]: Epoch 184 - training loss: 22742.7525, validation loss: 0.4574
2024-05-23 21:00:07 [INFO]: Epoch 185 - training loss: 22743.5403, validation loss: 0.4552
2024-05-23 21:00:08 [INFO]: Epoch 186 - training loss: 22742.1267, validation loss: 0.4562
2024-05-23 21:00:09 [INFO]: Epoch 187 - training loss: 22741.5547, validation loss: 0.4537
2024-05-23 21:00:10 [INFO]: Epoch 188 - training loss: 22742.2731, validation loss: 0.4556
2024-05-23 21:00:10 [INFO]: Epoch 189 - training loss: 22741.5511, validation loss: 0.4567
2024-05-23 21:00:11 [INFO]: Epoch 190 - training loss: 22741.5070, validation loss: 0.4595
2024-05-23 21:00:12 [INFO]: Epoch 191 - training loss: 22741.3142, validation loss: 0.4555
2024-05-23 21:00:12 [INFO]: Epoch 192 - training loss: 22741.1034, validation loss: 0.4576
2024-05-23 21:00:13 [INFO]: Epoch 193 - training loss: 22741.6843, validation loss: 0.4531
2024-05-23 21:00:14 [INFO]: Epoch 194 - training loss: 22741.6649, validation loss: 0.4538
2024-05-23 21:00:15 [INFO]: Epoch 195 - training loss: 22741.4887, validation loss: 0.4528
2024-05-23 21:00:15 [INFO]: Epoch 196 - training loss: 22741.1934, validation loss: 0.4612
2024-05-23 21:00:16 [INFO]: Epoch 197 - training loss: 22741.0946, validation loss: 0.4579
2024-05-23 21:00:17 [INFO]: Epoch 198 - training loss: 22740.8117, validation loss: 0.4537
2024-05-23 21:00:17 [INFO]: Epoch 199 - training loss: 22741.1427, validation loss: 0.4522
2024-05-23 21:00:18 [INFO]: Epoch 200 - training loss: 22740.6505, validation loss: 0.4534
2024-05-23 21:00:19 [INFO]: Epoch 201 - training loss: 22741.5071, validation loss: 0.4500
2024-05-23 21:00:20 [INFO]: Epoch 202 - training loss: 22741.3798, validation loss: 0.4523
2024-05-23 21:00:20 [INFO]: Epoch 203 - training loss: 22740.5363, validation loss: 0.4536
2024-05-23 21:00:21 [INFO]: Epoch 204 - training loss: 22740.4864, validation loss: 0.4529
2024-05-23 21:00:22 [INFO]: Epoch 205 - training loss: 22740.5034, validation loss: 0.4506
2024-05-23 21:00:23 [INFO]: Epoch 206 - training loss: 22740.2720, validation loss: 0.4526
2024-05-23 21:00:23 [INFO]: Epoch 207 - training loss: 22740.3125, validation loss: 0.4510
2024-05-23 21:00:24 [INFO]: Epoch 208 - training loss: 22740.0452, validation loss: 0.4550
2024-05-23 21:00:25 [INFO]: Epoch 209 - training loss: 22740.1401, validation loss: 0.4496
2024-05-23 21:00:25 [INFO]: Epoch 210 - training loss: 22740.3679, validation loss: 0.4511
2024-05-23 21:00:26 [INFO]: Epoch 211 - training loss: 22740.7141, validation loss: 0.4500
2024-05-23 21:00:27 [INFO]: Epoch 212 - training loss: 22740.2348, validation loss: 0.4537
2024-05-23 21:00:28 [INFO]: Epoch 213 - training loss: 22740.0988, validation loss: 0.4506
2024-05-23 21:00:28 [INFO]: Epoch 214 - training loss: 22739.7939, validation loss: 0.4515
2024-05-23 21:00:29 [INFO]: Epoch 215 - training loss: 22741.1283, validation loss: 0.4516
2024-05-23 21:00:30 [INFO]: Epoch 216 - training loss: 22739.9435, validation loss: 0.4495
2024-05-23 21:00:30 [INFO]: Epoch 217 - training loss: 22739.5622, validation loss: 0.4502
2024-05-23 21:00:31 [INFO]: Epoch 218 - training loss: 22738.8069, validation loss: 0.4543
2024-05-23 21:00:32 [INFO]: Epoch 219 - training loss: 22739.2967, validation loss: 0.4529
2024-05-23 21:00:33 [INFO]: Epoch 220 - training loss: 22739.5639, validation loss: 0.4517
2024-05-23 21:00:33 [INFO]: Epoch 221 - training loss: 22739.6111, validation loss: 0.4516
2024-05-23 21:00:34 [INFO]: Epoch 222 - training loss: 22738.9116, validation loss: 0.4478
2024-05-23 21:00:35 [INFO]: Epoch 223 - training loss: 22738.5778, validation loss: 0.4468
2024-05-23 21:00:35 [INFO]: Epoch 224 - training loss: 22738.3876, validation loss: 0.4505
2024-05-23 21:00:36 [INFO]: Epoch 225 - training loss: 22738.0873, validation loss: 0.4500
2024-05-23 21:00:37 [INFO]: Epoch 226 - training loss: 22738.8104, validation loss: 0.4495
2024-05-23 21:00:38 [INFO]: Epoch 227 - training loss: 22739.4958, validation loss: 0.4475
2024-05-23 21:00:38 [INFO]: Epoch 228 - training loss: 22739.4808, validation loss: 0.4523
2024-05-23 21:00:39 [INFO]: Epoch 229 - training loss: 22738.2408, validation loss: 0.4497
2024-05-23 21:00:40 [INFO]: Epoch 230 - training loss: 22737.2462, validation loss: 0.4474
2024-05-23 21:00:40 [INFO]: Epoch 231 - training loss: 22737.6282, validation loss: 0.4464
2024-05-23 21:00:41 [INFO]: Epoch 232 - training loss: 22738.3395, validation loss: 0.4482
2024-05-23 21:00:42 [INFO]: Epoch 233 - training loss: 22739.4384, validation loss: 0.4503
2024-05-23 21:00:43 [INFO]: Epoch 234 - training loss: 22739.9045, validation loss: 0.4488
2024-05-23 21:00:43 [INFO]: Epoch 235 - training loss: 22737.7894, validation loss: 0.4459
2024-05-23 21:00:44 [INFO]: Epoch 236 - training loss: 22736.9080, validation loss: 0.4478
2024-05-23 21:00:45 [INFO]: Epoch 237 - training loss: 22736.4601, validation loss: 0.4441
2024-05-23 21:00:45 [INFO]: Epoch 238 - training loss: 22736.5705, validation loss: 0.4502
2024-05-23 21:00:46 [INFO]: Epoch 239 - training loss: 22736.4835, validation loss: 0.4462
2024-05-23 21:00:47 [INFO]: Epoch 240 - training loss: 22736.9771, validation loss: 0.4441
2024-05-23 21:00:47 [INFO]: Epoch 241 - training loss: 22737.0089, validation loss: 0.4471
2024-05-23 21:00:48 [INFO]: Epoch 242 - training loss: 22738.0188, validation loss: 0.4452
2024-05-23 21:00:48 [INFO]: Epoch 243 - training loss: 22737.0069, validation loss: 0.4456
2024-05-23 21:00:49 [INFO]: Epoch 244 - training loss: 22736.1083, validation loss: 0.4454
2024-05-23 21:00:50 [INFO]: Epoch 245 - training loss: 22736.1900, validation loss: 0.4477
2024-05-23 21:00:50 [INFO]: Epoch 246 - training loss: 22735.8183, validation loss: 0.4453
2024-05-23 21:00:51 [INFO]: Epoch 247 - training loss: 22736.3275, validation loss: 0.4417
2024-05-23 21:00:51 [INFO]: Epoch 248 - training loss: 22737.3150, validation loss: 0.4411
2024-05-23 21:00:52 [INFO]: Epoch 249 - training loss: 22737.0769, validation loss: 0.4459
2024-05-23 21:00:53 [INFO]: Epoch 250 - training loss: 22736.6679, validation loss: 0.4423
2024-05-23 21:00:53 [INFO]: Epoch 251 - training loss: 22736.4932, validation loss: 0.4420
2024-05-23 21:00:54 [INFO]: Epoch 252 - training loss: 22735.9341, validation loss: 0.4449
2024-05-23 21:00:55 [INFO]: Epoch 253 - training loss: 22736.3486, validation loss: 0.4369
2024-05-23 21:00:55 [INFO]: Epoch 254 - training loss: 22735.9085, validation loss: 0.4417
2024-05-23 21:00:56 [INFO]: Epoch 255 - training loss: 22735.7919, validation loss: 0.4404
2024-05-23 21:00:56 [INFO]: Epoch 256 - training loss: 22735.5334, validation loss: 0.4423
2024-05-23 21:00:57 [INFO]: Epoch 257 - training loss: 22735.4309, validation loss: 0.4423
2024-05-23 21:00:58 [INFO]: Epoch 258 - training loss: 22736.2004, validation loss: 0.4436
2024-05-23 21:00:58 [INFO]: Epoch 259 - training loss: 22735.5525, validation loss: 0.4412
2024-05-23 21:00:59 [INFO]: Epoch 260 - training loss: 22735.5070, validation loss: 0.4389
2024-05-23 21:01:00 [INFO]: Epoch 261 - training loss: 22735.2088, validation loss: 0.4404
2024-05-23 21:01:00 [INFO]: Epoch 262 - training loss: 22735.1806, validation loss: 0.4431
2024-05-23 21:01:01 [INFO]: Epoch 263 - training loss: 22735.2329, validation loss: 0.4361
2024-05-23 21:01:01 [INFO]: Epoch 264 - training loss: 22734.9630, validation loss: 0.4388
2024-05-23 21:01:02 [INFO]: Epoch 265 - training loss: 22735.8269, validation loss: 0.4405
2024-05-23 21:01:03 [INFO]: Epoch 266 - training loss: 22735.7765, validation loss: 0.4419
2024-05-23 21:01:03 [INFO]: Epoch 267 - training loss: 22735.5047, validation loss: 0.4374
2024-05-23 21:01:04 [INFO]: Epoch 268 - training loss: 22735.6942, validation loss: 0.4355
2024-05-23 21:01:05 [INFO]: Epoch 269 - training loss: 22735.2191, validation loss: 0.4429
2024-05-23 21:01:05 [INFO]: Epoch 270 - training loss: 22734.7234, validation loss: 0.4394
2024-05-23 21:01:06 [INFO]: Epoch 271 - training loss: 22734.3624, validation loss: 0.4400
2024-05-23 21:01:06 [INFO]: Epoch 272 - training loss: 22734.5132, validation loss: 0.4388
2024-05-23 21:01:07 [INFO]: Epoch 273 - training loss: 22734.7777, validation loss: 0.4398
2024-05-23 21:01:08 [INFO]: Epoch 274 - training loss: 22734.8024, validation loss: 0.4334
2024-05-23 21:01:08 [INFO]: Epoch 275 - training loss: 22734.3367, validation loss: 0.4421
2024-05-23 21:01:09 [INFO]: Epoch 276 - training loss: 22734.8850, validation loss: 0.4341
2024-05-23 21:01:10 [INFO]: Epoch 277 - training loss: 22735.2027, validation loss: 0.4365
2024-05-23 21:01:10 [INFO]: Epoch 278 - training loss: 22734.7591, validation loss: 0.4344
2024-05-23 21:01:11 [INFO]: Epoch 279 - training loss: 22734.4639, validation loss: 0.4389
2024-05-23 21:01:11 [INFO]: Epoch 280 - training loss: 22734.5062, validation loss: 0.4382
2024-05-23 21:01:12 [INFO]: Epoch 281 - training loss: 22734.3296, validation loss: 0.4348
2024-05-23 21:01:13 [INFO]: Epoch 282 - training loss: 22734.1733, validation loss: 0.4364
2024-05-23 21:01:13 [INFO]: Epoch 283 - training loss: 22734.1727, validation loss: 0.4390
2024-05-23 21:01:14 [INFO]: Epoch 284 - training loss: 22734.8880, validation loss: 0.4314
2024-05-23 21:01:15 [INFO]: Epoch 285 - training loss: 22734.6925, validation loss: 0.4319
2024-05-23 21:01:15 [INFO]: Epoch 286 - training loss: 22734.3374, validation loss: 0.4365
2024-05-23 21:01:16 [INFO]: Epoch 287 - training loss: 22734.5549, validation loss: 0.4362
2024-05-23 21:01:16 [INFO]: Epoch 288 - training loss: 22734.0298, validation loss: 0.4350
2024-05-23 21:01:17 [INFO]: Epoch 289 - training loss: 22734.2973, validation loss: 0.4344
2024-05-23 21:01:18 [INFO]: Epoch 290 - training loss: 22733.8449, validation loss: 0.4352
2024-05-23 21:01:18 [INFO]: Epoch 291 - training loss: 22733.9148, validation loss: 0.4393
2024-05-23 21:01:19 [INFO]: Epoch 292 - training loss: 22733.9905, validation loss: 0.4312
2024-05-23 21:01:20 [INFO]: Epoch 293 - training loss: 22734.1640, validation loss: 0.4348
2024-05-23 21:01:20 [INFO]: Epoch 294 - training loss: 22733.6075, validation loss: 0.4381
2024-05-23 21:01:21 [INFO]: Epoch 295 - training loss: 22733.9273, validation loss: 0.4395
2024-05-23 21:01:21 [INFO]: Epoch 296 - training loss: 22734.3104, validation loss: 0.4307
2024-05-23 21:01:22 [INFO]: Epoch 297 - training loss: 22734.2984, validation loss: 0.4368
2024-05-23 21:01:23 [INFO]: Epoch 298 - training loss: 22733.6442, validation loss: 0.4302
2024-05-23 21:01:23 [INFO]: Epoch 299 - training loss: 22733.7356, validation loss: 0.4365
2024-05-23 21:01:24 [INFO]: Epoch 300 - training loss: 22733.6063, validation loss: 0.4310
2024-05-23 21:01:24 [INFO]: Finished training. The best model is from epoch#298.
2024-05-23 21:01:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_physionet_2012_seta/20240523_T205756/GPVAE.pypots
2024-05-23 21:01:24 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.3994, MSE=0.4605
2024-05-23 21:01:24 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 21:01:24 [INFO]: Using the given device: cuda:0
2024-05-23 21:01:24 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T210124
2024-05-23 21:01:24 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T210124/tensorboard
2024-05-23 21:01:24 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 21:01:46 [INFO]: Epoch 001 - generator training loss: 0.6047, discriminator training loss: 0.3869, validation loss: 0.6117
2024-05-23 21:02:05 [INFO]: Epoch 002 - generator training loss: 0.4814, discriminator training loss: 0.2726, validation loss: 0.5201
2024-05-23 21:02:24 [INFO]: Epoch 003 - generator training loss: 0.4340, discriminator training loss: 0.2363, validation loss: 0.5096
2024-05-23 21:02:43 [INFO]: Epoch 004 - generator training loss: 0.4527, discriminator training loss: 0.1873, validation loss: 0.4997
2024-05-23 21:03:01 [INFO]: Epoch 005 - generator training loss: 0.4444, discriminator training loss: 0.1579, validation loss: 0.4857
2024-05-23 21:03:20 [INFO]: Epoch 006 - generator training loss: 0.4314, discriminator training loss: 0.1390, validation loss: 0.4666
2024-05-23 21:03:39 [INFO]: Epoch 007 - generator training loss: 0.4186, discriminator training loss: 0.1261, validation loss: 0.4563
2024-05-23 21:03:58 [INFO]: Epoch 008 - generator training loss: 0.4077, discriminator training loss: 0.1153, validation loss: 0.4463
2024-05-23 21:04:17 [INFO]: Epoch 009 - generator training loss: 0.3974, discriminator training loss: 0.1070, validation loss: 0.4320
2024-05-23 21:04:35 [INFO]: Epoch 010 - generator training loss: 0.3893, discriminator training loss: 0.1002, validation loss: 0.4285
2024-05-23 21:04:54 [INFO]: Epoch 011 - generator training loss: 0.3818, discriminator training loss: 0.0942, validation loss: 0.4174
2024-05-23 21:05:13 [INFO]: Epoch 012 - generator training loss: 0.3767, discriminator training loss: 0.0892, validation loss: 0.4120
2024-05-23 21:05:32 [INFO]: Epoch 013 - generator training loss: 0.3714, discriminator training loss: 0.0846, validation loss: 0.4022
2024-05-23 21:05:50 [INFO]: Epoch 014 - generator training loss: 0.3664, discriminator training loss: 0.0805, validation loss: 0.3992
2024-05-23 21:06:09 [INFO]: Epoch 015 - generator training loss: 0.3623, discriminator training loss: 0.0771, validation loss: 0.3954
2024-05-23 21:06:28 [INFO]: Epoch 016 - generator training loss: 0.3559, discriminator training loss: 0.0740, validation loss: 0.3912
2024-05-23 21:06:47 [INFO]: Epoch 017 - generator training loss: 0.3525, discriminator training loss: 0.0711, validation loss: 0.3878
2024-05-23 21:07:05 [INFO]: Epoch 018 - generator training loss: 0.3494, discriminator training loss: 0.0686, validation loss: 0.3816
2024-05-23 21:07:24 [INFO]: Epoch 019 - generator training loss: 0.3444, discriminator training loss: 0.0664, validation loss: 0.3797
2024-05-23 21:07:43 [INFO]: Epoch 020 - generator training loss: 0.3408, discriminator training loss: 0.0640, validation loss: 0.3734
2024-05-23 21:08:02 [INFO]: Epoch 021 - generator training loss: 0.3378, discriminator training loss: 0.0622, validation loss: 0.3716
2024-05-23 21:08:21 [INFO]: Epoch 022 - generator training loss: 0.3334, discriminator training loss: 0.0606, validation loss: 0.3686
2024-05-23 21:08:40 [INFO]: Epoch 023 - generator training loss: 0.3298, discriminator training loss: 0.0587, validation loss: 0.3661
2024-05-23 21:08:59 [INFO]: Epoch 024 - generator training loss: 0.3275, discriminator training loss: 0.0573, validation loss: 0.3625
2024-05-23 21:09:17 [INFO]: Epoch 025 - generator training loss: 0.3230, discriminator training loss: 0.0561, validation loss: 0.3601
2024-05-23 21:09:36 [INFO]: Epoch 026 - generator training loss: 0.3189, discriminator training loss: 0.0550, validation loss: 0.3582
2024-05-23 21:09:55 [INFO]: Epoch 027 - generator training loss: 0.3163, discriminator training loss: 0.0542, validation loss: 0.3521
2024-05-23 21:10:13 [INFO]: Epoch 028 - generator training loss: 0.3164, discriminator training loss: 0.0529, validation loss: 0.3524
2024-05-23 21:10:32 [INFO]: Epoch 029 - generator training loss: 0.3078, discriminator training loss: 0.0519, validation loss: 0.3507
2024-05-23 21:10:51 [INFO]: Epoch 030 - generator training loss: 0.3003, discriminator training loss: 0.0514, validation loss: 0.3445
2024-05-23 21:11:10 [INFO]: Epoch 031 - generator training loss: 0.2973, discriminator training loss: 0.0505, validation loss: 0.3381
2024-05-23 21:11:28 [INFO]: Epoch 032 - generator training loss: 0.2954, discriminator training loss: 0.0500, validation loss: 0.3399
2024-05-23 21:11:47 [INFO]: Epoch 033 - generator training loss: 0.2936, discriminator training loss: 0.0492, validation loss: 0.3296
2024-05-23 21:12:06 [INFO]: Epoch 034 - generator training loss: 0.2903, discriminator training loss: 0.0487, validation loss: 0.3366
2024-05-23 21:12:25 [INFO]: Epoch 035 - generator training loss: 0.2843, discriminator training loss: 0.0481, validation loss: 0.3273
2024-05-23 21:12:43 [INFO]: Epoch 036 - generator training loss: 0.2831, discriminator training loss: 0.0478, validation loss: 0.3265
2024-05-23 21:13:02 [INFO]: Epoch 037 - generator training loss: 0.2844, discriminator training loss: 0.0471, validation loss: 0.3241
2024-05-23 21:13:21 [INFO]: Epoch 038 - generator training loss: 0.2804, discriminator training loss: 0.0469, validation loss: 0.3248
2024-05-23 21:13:39 [INFO]: Epoch 039 - generator training loss: 0.2707, discriminator training loss: 0.0464, validation loss: 0.3157
2024-05-23 21:13:58 [INFO]: Epoch 040 - generator training loss: 0.2686, discriminator training loss: 0.0462, validation loss: 0.3188
2024-05-23 21:14:17 [INFO]: Epoch 041 - generator training loss: 0.2660, discriminator training loss: 0.0457, validation loss: 0.3175
2024-05-23 21:14:36 [INFO]: Epoch 042 - generator training loss: 0.2628, discriminator training loss: 0.0456, validation loss: 0.3156
2024-05-23 21:14:55 [INFO]: Epoch 043 - generator training loss: 0.2593, discriminator training loss: 0.0452, validation loss: 0.3152
2024-05-23 21:15:13 [INFO]: Epoch 044 - generator training loss: 0.2600, discriminator training loss: 0.0448, validation loss: 0.3118
2024-05-23 21:15:32 [INFO]: Epoch 045 - generator training loss: 0.2602, discriminator training loss: 0.0445, validation loss: 0.3148
2024-05-23 21:15:51 [INFO]: Epoch 046 - generator training loss: 0.2566, discriminator training loss: 0.0444, validation loss: 0.3104
2024-05-23 21:16:09 [INFO]: Epoch 047 - generator training loss: 0.2499, discriminator training loss: 0.0439, validation loss: 0.3101
2024-05-23 21:16:28 [INFO]: Epoch 048 - generator training loss: 0.2489, discriminator training loss: 0.0439, validation loss: 0.3060
2024-05-23 21:16:47 [INFO]: Epoch 049 - generator training loss: 0.2447, discriminator training loss: 0.0438, validation loss: 0.3081
2024-05-23 21:17:06 [INFO]: Epoch 050 - generator training loss: 0.2432, discriminator training loss: 0.0432, validation loss: 0.3062
2024-05-23 21:17:24 [INFO]: Epoch 051 - generator training loss: 0.2400, discriminator training loss: 0.0434, validation loss: 0.3060
2024-05-23 21:17:43 [INFO]: Epoch 052 - generator training loss: 0.2402, discriminator training loss: 0.0428, validation loss: 0.3056
2024-05-23 21:18:02 [INFO]: Epoch 053 - generator training loss: 0.2405, discriminator training loss: 0.0429, validation loss: 0.3077
2024-05-23 21:18:20 [INFO]: Epoch 054 - generator training loss: 0.2394, discriminator training loss: 0.0427, validation loss: 0.3129
2024-05-23 21:18:39 [INFO]: Epoch 055 - generator training loss: 0.2355, discriminator training loss: 0.0425, validation loss: 0.3063
2024-05-23 21:18:58 [INFO]: Epoch 056 - generator training loss: 0.2317, discriminator training loss: 0.0425, validation loss: 0.3027
2024-05-23 21:19:17 [INFO]: Epoch 057 - generator training loss: 0.2279, discriminator training loss: 0.0423, validation loss: 0.3062
2024-05-23 21:19:35 [INFO]: Epoch 058 - generator training loss: 0.2303, discriminator training loss: 0.0420, validation loss: 0.3072
2024-05-23 21:19:54 [INFO]: Epoch 059 - generator training loss: 0.2327, discriminator training loss: 0.0420, validation loss: 0.3047
2024-05-23 21:20:13 [INFO]: Epoch 060 - generator training loss: 0.2234, discriminator training loss: 0.0417, validation loss: 0.3071
2024-05-23 21:20:32 [INFO]: Epoch 061 - generator training loss: 0.2263, discriminator training loss: 0.0416, validation loss: 0.3025
2024-05-23 21:20:50 [INFO]: Epoch 062 - generator training loss: 0.2201, discriminator training loss: 0.0416, validation loss: 0.3009
2024-05-23 21:21:09 [INFO]: Epoch 063 - generator training loss: 0.2142, discriminator training loss: 0.0415, validation loss: 0.3045
2024-05-23 21:21:28 [INFO]: Epoch 064 - generator training loss: 0.2147, discriminator training loss: 0.0413, validation loss: 0.3038
2024-05-23 21:21:47 [INFO]: Epoch 065 - generator training loss: 0.2109, discriminator training loss: 0.0413, validation loss: 0.3004
2024-05-23 21:22:05 [INFO]: Epoch 066 - generator training loss: 0.2090, discriminator training loss: 0.0412, validation loss: 0.3020
2024-05-23 21:22:24 [INFO]: Epoch 067 - generator training loss: 0.2104, discriminator training loss: 0.0410, validation loss: 0.3013
2024-05-23 21:22:43 [INFO]: Epoch 068 - generator training loss: 0.2132, discriminator training loss: 0.0410, validation loss: 0.3015
2024-05-23 21:23:02 [INFO]: Epoch 069 - generator training loss: 0.2070, discriminator training loss: 0.0409, validation loss: 0.3031
2024-05-23 21:23:21 [INFO]: Epoch 070 - generator training loss: 0.2052, discriminator training loss: 0.0409, validation loss: 0.3001
2024-05-23 21:23:39 [INFO]: Epoch 071 - generator training loss: 0.2051, discriminator training loss: 0.0409, validation loss: 0.3017
2024-05-23 21:23:58 [INFO]: Epoch 072 - generator training loss: 0.2047, discriminator training loss: 0.0405, validation loss: 0.3055
2024-05-23 21:24:17 [INFO]: Epoch 073 - generator training loss: 0.2005, discriminator training loss: 0.0406, validation loss: 0.3012
2024-05-23 21:24:35 [INFO]: Epoch 074 - generator training loss: 0.1991, discriminator training loss: 0.0407, validation loss: 0.3013
2024-05-23 21:24:54 [INFO]: Epoch 075 - generator training loss: 0.1930, discriminator training loss: 0.0404, validation loss: 0.3003
2024-05-23 21:25:13 [INFO]: Epoch 076 - generator training loss: 0.1930, discriminator training loss: 0.0405, validation loss: 0.3015
2024-05-23 21:25:32 [INFO]: Epoch 077 - generator training loss: 0.1929, discriminator training loss: 0.0404, validation loss: 0.3035
2024-05-23 21:25:50 [INFO]: Epoch 078 - generator training loss: 0.1914, discriminator training loss: 0.0404, validation loss: 0.3014
2024-05-23 21:26:09 [INFO]: Epoch 079 - generator training loss: 0.1936, discriminator training loss: 0.0402, validation loss: 0.3004
2024-05-23 21:26:28 [INFO]: Epoch 080 - generator training loss: 0.1924, discriminator training loss: 0.0402, validation loss: 0.3015
2024-05-23 21:26:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:26:28 [INFO]: Finished training. The best model is from epoch#70.
2024-05-23 21:26:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_physionet_2012_seta/20240523_T210124/USGAN.pypots
2024-05-23 21:26:30 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2962, MSE=0.2835
2024-05-23 21:26:40 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 21:26:40 [INFO]: Using the given device: cuda:0
2024-05-23 21:26:40 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T212640
2024-05-23 21:26:40 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T212640/tensorboard
2024-05-23 21:26:40 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 21:26:55 [INFO]: Epoch 001 - training loss: 1.1114, validation loss: 0.5159
2024-05-23 21:27:07 [INFO]: Epoch 002 - training loss: 0.9101, validation loss: 0.4573
2024-05-23 21:27:20 [INFO]: Epoch 003 - training loss: 0.8508, validation loss: 0.4265
2024-05-23 21:27:32 [INFO]: Epoch 004 - training loss: 0.8155, validation loss: 0.4057
2024-05-23 21:27:44 [INFO]: Epoch 005 - training loss: 0.7884, validation loss: 0.3916
2024-05-23 21:27:57 [INFO]: Epoch 006 - training loss: 0.7671, validation loss: 0.3776
2024-05-23 21:28:09 [INFO]: Epoch 007 - training loss: 0.7500, validation loss: 0.3679
2024-05-23 21:28:21 [INFO]: Epoch 008 - training loss: 0.7362, validation loss: 0.3596
2024-05-23 21:28:33 [INFO]: Epoch 009 - training loss: 0.7238, validation loss: 0.3547
2024-05-23 21:28:46 [INFO]: Epoch 010 - training loss: 0.7141, validation loss: 0.3518
2024-05-23 21:28:58 [INFO]: Epoch 011 - training loss: 0.7039, validation loss: 0.3483
2024-05-23 21:29:10 [INFO]: Epoch 012 - training loss: 0.6964, validation loss: 0.3449
2024-05-23 21:29:22 [INFO]: Epoch 013 - training loss: 0.6901, validation loss: 0.3431
2024-05-23 21:29:35 [INFO]: Epoch 014 - training loss: 0.6841, validation loss: 0.3421
2024-05-23 21:29:47 [INFO]: Epoch 015 - training loss: 0.6781, validation loss: 0.3397
2024-05-23 21:30:00 [INFO]: Epoch 016 - training loss: 0.6730, validation loss: 0.3404
2024-05-23 21:30:13 [INFO]: Epoch 017 - training loss: 0.6691, validation loss: 0.3373
2024-05-23 21:30:25 [INFO]: Epoch 018 - training loss: 0.6651, validation loss: 0.3367
2024-05-23 21:30:37 [INFO]: Epoch 019 - training loss: 0.6619, validation loss: 0.3394
2024-05-23 21:30:51 [INFO]: Epoch 020 - training loss: 0.6620, validation loss: 0.3369
2024-05-23 21:31:03 [INFO]: Epoch 021 - training loss: 0.6563, validation loss: 0.3363
2024-05-23 21:31:15 [INFO]: Epoch 022 - training loss: 0.6525, validation loss: 0.3354
2024-05-23 21:31:28 [INFO]: Epoch 023 - training loss: 0.6490, validation loss: 0.3352
2024-05-23 21:31:40 [INFO]: Epoch 024 - training loss: 0.6459, validation loss: 0.3345
2024-05-23 21:31:52 [INFO]: Epoch 025 - training loss: 0.6424, validation loss: 0.3327
2024-05-23 21:32:05 [INFO]: Epoch 026 - training loss: 0.6391, validation loss: 0.3340
2024-05-23 21:32:17 [INFO]: Epoch 027 - training loss: 0.6361, validation loss: 0.3332
2024-05-23 21:32:30 [INFO]: Epoch 028 - training loss: 0.6351, validation loss: 0.3324
2024-05-23 21:32:43 [INFO]: Epoch 029 - training loss: 0.6318, validation loss: 0.3335
2024-05-23 21:32:56 [INFO]: Epoch 030 - training loss: 0.6286, validation loss: 0.3307
2024-05-23 21:33:09 [INFO]: Epoch 031 - training loss: 0.6269, validation loss: 0.3319
2024-05-23 21:33:22 [INFO]: Epoch 032 - training loss: 0.6243, validation loss: 0.3337
2024-05-23 21:33:34 [INFO]: Epoch 033 - training loss: 0.6222, validation loss: 0.3316
2024-05-23 21:33:47 [INFO]: Epoch 034 - training loss: 0.6184, validation loss: 0.3309
2024-05-23 21:33:59 [INFO]: Epoch 035 - training loss: 0.6160, validation loss: 0.3317
2024-05-23 21:34:12 [INFO]: Epoch 036 - training loss: 0.6137, validation loss: 0.3312
2024-05-23 21:34:24 [INFO]: Epoch 037 - training loss: 0.6101, validation loss: 0.3309
2024-05-23 21:34:36 [INFO]: Epoch 038 - training loss: 0.6097, validation loss: 0.3331
2024-05-23 21:34:49 [INFO]: Epoch 039 - training loss: 0.6083, validation loss: 0.3328
2024-05-23 21:35:01 [INFO]: Epoch 040 - training loss: 0.6031, validation loss: 0.3328
2024-05-23 21:35:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:35:01 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 21:35:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_physionet_2012_seta/20240523_T212640/BRITS.pypots
2024-05-23 21:35:04 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2624, MSE=0.2883
2024-05-23 21:35:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_physionet_2012_seta/imputation.pkl
2024-05-23 21:35:13 [INFO]: Using the given device: cuda:0
2024-05-23 21:35:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513
2024-05-23 21:35:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/tensorboard
2024-05-23 21:35:13 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-23 21:35:19 [INFO]: Epoch 001 - training loss: 1.1838, validation loss: 0.9997
2024-05-23 21:35:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch1_loss0.9996924251317978.pypots
2024-05-23 21:35:22 [INFO]: Epoch 002 - training loss: 0.7649, validation loss: 0.9773
2024-05-23 21:35:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch2_loss0.9772839814424514.pypots
2024-05-23 21:35:25 [INFO]: Epoch 003 - training loss: 0.6335, validation loss: 0.9553
2024-05-23 21:35:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch3_loss0.955288541316986.pypots
2024-05-23 21:35:28 [INFO]: Epoch 004 - training loss: 0.5825, validation loss: 0.9383
2024-05-23 21:35:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch4_loss0.9382703989744187.pypots
2024-05-23 21:35:31 [INFO]: Epoch 005 - training loss: 0.5503, validation loss: 0.9272
2024-05-23 21:35:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch5_loss0.9272428691387177.pypots
2024-05-23 21:35:34 [INFO]: Epoch 006 - training loss: 0.5326, validation loss: 0.9215
2024-05-23 21:35:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch6_loss0.9214543104171753.pypots
2024-05-23 21:35:36 [INFO]: Epoch 007 - training loss: 0.5115, validation loss: 0.9176
2024-05-23 21:35:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch7_loss0.9175827115774154.pypots
2024-05-23 21:35:39 [INFO]: Epoch 008 - training loss: 0.5035, validation loss: 0.9161
2024-05-23 21:35:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch8_loss0.9161127924919128.pypots
2024-05-23 21:35:42 [INFO]: Epoch 009 - training loss: 0.5001, validation loss: 0.9147
2024-05-23 21:35:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch9_loss0.9147165536880493.pypots
2024-05-23 21:35:45 [INFO]: Epoch 010 - training loss: 0.4855, validation loss: 0.9139
2024-05-23 21:35:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch10_loss0.9138839304447174.pypots
2024-05-23 21:35:48 [INFO]: Epoch 011 - training loss: 0.4737, validation loss: 0.9144
2024-05-23 21:35:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch11_loss0.9143635302782058.pypots
2024-05-23 21:35:51 [INFO]: Epoch 012 - training loss: 0.4678, validation loss: 0.9157
2024-05-23 21:35:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch12_loss0.9156978905200959.pypots
2024-05-23 21:35:54 [INFO]: Epoch 013 - training loss: 0.4661, validation loss: 0.9170
2024-05-23 21:35:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch13_loss0.9170167833566666.pypots
2024-05-23 21:35:56 [INFO]: Epoch 014 - training loss: 0.4532, validation loss: 0.9198
2024-05-23 21:35:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch14_loss0.9197959989309311.pypots
2024-05-23 21:35:59 [INFO]: Epoch 015 - training loss: 0.4606, validation loss: 0.9215
2024-05-23 21:35:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch15_loss0.9214820235967636.pypots
2024-05-23 21:36:02 [INFO]: Epoch 016 - training loss: 0.4553, validation loss: 0.9220
2024-05-23 21:36:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch16_loss0.92199687063694.pypots
2024-05-23 21:36:05 [INFO]: Epoch 017 - training loss: 0.4468, validation loss: 0.9236
2024-05-23 21:36:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch17_loss0.9235598653554916.pypots
2024-05-23 21:36:08 [INFO]: Epoch 018 - training loss: 0.4479, validation loss: 0.9260
2024-05-23 21:36:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch18_loss0.9259646505117416.pypots
2024-05-23 21:36:11 [INFO]: Epoch 019 - training loss: 0.4515, validation loss: 0.9274
2024-05-23 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch19_loss0.9273739993572235.pypots
2024-05-23 21:36:14 [INFO]: Epoch 020 - training loss: 0.4417, validation loss: 0.9281
2024-05-23 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN_epoch20_loss0.9281128406524658.pypots
2024-05-23 21:36:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:36:14 [INFO]: Finished training. The best model is from epoch#10.
2024-05-23 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/20240523_T213513/MRNN.pypots
2024-05-23 21:36:15 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6859, MSE=0.9245
2024-05-23 21:36:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_physionet_2012_seta/imputation.pkl
2024-05-23 21:36:19 [INFO]: Using the given device: cpu
2024-05-23 21:36:19 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4083, MSE=0.5397
2024-05-23 21:36:19 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_physionet_2012_seta".
2024-05-23 21:36:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_physionet_2012_seta/imputation.pkl
2024-05-23 21:36:19 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6856, MSE=1.0305
2024-05-23 21:36:19 [INFO]: Successfully created the given path "saved_results/round_1/Median_physionet_2012_seta".
2024-05-23 21:36:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_physionet_2012_seta/imputation.pkl
2024-05-23 21:36:19 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7023, MSE=1.0007
2024-05-23 21:36:19 [INFO]: Successfully created the given path "saved_results/round_1/Mean_physionet_2012_seta".
2024-05-23 21:36:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_physionet_2012_seta/imputation.pkl
2024-05-23 21:36:19 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-23 21:36:19 [INFO]: Using the given device: cuda:0
2024-05-23 21:36:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T213619
2024-05-23 21:36:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T213619/tensorboard
2024-05-23 21:36:19 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-23 21:36:21 [INFO]: Epoch 001 - training loss: 1.0680, validation loss: 0.4868
2024-05-23 21:36:22 [INFO]: Epoch 002 - training loss: 0.6746, validation loss: 0.4186
2024-05-23 21:36:23 [INFO]: Epoch 003 - training loss: 0.5714, validation loss: 0.3881
2024-05-23 21:36:24 [INFO]: Epoch 004 - training loss: 0.5102, validation loss: 0.3706
2024-05-23 21:36:25 [INFO]: Epoch 005 - training loss: 0.4720, validation loss: 0.3638
2024-05-23 21:36:26 [INFO]: Epoch 006 - training loss: 0.4387, validation loss: 0.3405
2024-05-23 21:36:28 [INFO]: Epoch 007 - training loss: 0.4118, validation loss: 0.3346
2024-05-23 21:36:29 [INFO]: Epoch 008 - training loss: 0.3936, validation loss: 0.3288
2024-05-23 21:36:30 [INFO]: Epoch 009 - training loss: 0.3676, validation loss: 0.3194
2024-05-23 21:36:31 [INFO]: Epoch 010 - training loss: 0.3503, validation loss: 0.3146
2024-05-23 21:36:32 [INFO]: Epoch 011 - training loss: 0.3325, validation loss: 0.3104
2024-05-23 21:36:33 [INFO]: Epoch 012 - training loss: 0.3183, validation loss: 0.3057
2024-05-23 21:36:35 [INFO]: Epoch 013 - training loss: 0.3050, validation loss: 0.3022
2024-05-23 21:36:36 [INFO]: Epoch 014 - training loss: 0.2989, validation loss: 0.3017
2024-05-23 21:36:37 [INFO]: Epoch 015 - training loss: 0.2906, validation loss: 0.2990
2024-05-23 21:36:38 [INFO]: Epoch 016 - training loss: 0.2787, validation loss: 0.2942
2024-05-23 21:36:39 [INFO]: Epoch 017 - training loss: 0.2629, validation loss: 0.2920
2024-05-23 21:36:40 [INFO]: Epoch 018 - training loss: 0.2579, validation loss: 0.2965
2024-05-23 21:36:42 [INFO]: Epoch 019 - training loss: 0.2548, validation loss: 0.2930
2024-05-23 21:36:43 [INFO]: Epoch 020 - training loss: 0.2423, validation loss: 0.2889
2024-05-23 21:36:44 [INFO]: Epoch 021 - training loss: 0.2358, validation loss: 0.2933
2024-05-23 21:36:45 [INFO]: Epoch 022 - training loss: 0.2305, validation loss: 0.2932
2024-05-23 21:36:47 [INFO]: Epoch 023 - training loss: 0.2254, validation loss: 0.2890
2024-05-23 21:36:48 [INFO]: Epoch 024 - training loss: 0.2206, validation loss: 0.2914
2024-05-23 21:36:49 [INFO]: Epoch 025 - training loss: 0.2188, validation loss: 0.2900
2024-05-23 21:36:50 [INFO]: Epoch 026 - training loss: 0.2113, validation loss: 0.2911
2024-05-23 21:36:51 [INFO]: Epoch 027 - training loss: 0.2054, validation loss: 0.2889
2024-05-23 21:36:52 [INFO]: Epoch 028 - training loss: 0.2016, validation loss: 0.2933
2024-05-23 21:36:54 [INFO]: Epoch 029 - training loss: 0.1983, validation loss: 0.2877
2024-05-23 21:36:55 [INFO]: Epoch 030 - training loss: 0.1909, validation loss: 0.2871
2024-05-23 21:36:56 [INFO]: Epoch 031 - training loss: 0.1916, validation loss: 0.2846
2024-05-23 21:36:57 [INFO]: Epoch 032 - training loss: 0.1865, validation loss: 0.2849
2024-05-23 21:36:58 [INFO]: Epoch 033 - training loss: 0.1831, validation loss: 0.2837
2024-05-23 21:36:59 [INFO]: Epoch 034 - training loss: 0.1815, validation loss: 0.2905
2024-05-23 21:37:01 [INFO]: Epoch 035 - training loss: 0.1759, validation loss: 0.2879
2024-05-23 21:37:02 [INFO]: Epoch 036 - training loss: 0.1758, validation loss: 0.2821
2024-05-23 21:37:03 [INFO]: Epoch 037 - training loss: 0.1724, validation loss: 0.2851
2024-05-23 21:37:04 [INFO]: Epoch 038 - training loss: 0.1708, validation loss: 0.2883
2024-05-23 21:37:05 [INFO]: Epoch 039 - training loss: 0.1677, validation loss: 0.2895
2024-05-23 21:37:07 [INFO]: Epoch 040 - training loss: 0.1620, validation loss: 0.2825
2024-05-23 21:37:08 [INFO]: Epoch 041 - training loss: 0.1621, validation loss: 0.2845
2024-05-23 21:37:10 [INFO]: Epoch 042 - training loss: 0.1610, validation loss: 0.2818
2024-05-23 21:37:11 [INFO]: Epoch 043 - training loss: 0.1585, validation loss: 0.2858
2024-05-23 21:37:12 [INFO]: Epoch 044 - training loss: 0.1565, validation loss: 0.2820
2024-05-23 21:37:13 [INFO]: Epoch 045 - training loss: 0.1546, validation loss: 0.2822
2024-05-23 21:37:14 [INFO]: Epoch 046 - training loss: 0.1535, validation loss: 0.2833
2024-05-23 21:37:15 [INFO]: Epoch 047 - training loss: 0.1493, validation loss: 0.2936
2024-05-23 21:37:17 [INFO]: Epoch 048 - training loss: 0.1481, validation loss: 0.2849
2024-05-23 21:37:18 [INFO]: Epoch 049 - training loss: 0.1480, validation loss: 0.2855
2024-05-23 21:37:19 [INFO]: Epoch 050 - training loss: 0.1450, validation loss: 0.2864
2024-05-23 21:37:20 [INFO]: Epoch 051 - training loss: 0.1468, validation loss: 0.2835
2024-05-23 21:37:21 [INFO]: Epoch 052 - training loss: 0.1419, validation loss: 0.2887
2024-05-23 21:37:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:37:21 [INFO]: Finished training. The best model is from epoch#42.
2024-05-23 21:37:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_physionet_2012_seta/20240523_T213619/SAITS.pypots
2024-05-23 21:37:21 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2662, MSE=0.3246
2024-05-23 21:37:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_physionet_2012_seta/imputation.pkl
2024-05-23 21:37:22 [INFO]: Using the given device: cuda:0
2024-05-23 21:37:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T213722
2024-05-23 21:37:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T213722/tensorboard
2024-05-23 21:37:22 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-23 21:37:23 [INFO]: Epoch 001 - training loss: 1.2049, validation loss: 0.5693
2024-05-23 21:37:23 [INFO]: Epoch 002 - training loss: 0.7587, validation loss: 0.4736
2024-05-23 21:37:24 [INFO]: Epoch 003 - training loss: 0.6414, validation loss: 0.4513
2024-05-23 21:37:24 [INFO]: Epoch 004 - training loss: 0.5810, validation loss: 0.4210
2024-05-23 21:37:25 [INFO]: Epoch 005 - training loss: 0.5355, validation loss: 0.3927
2024-05-23 21:37:26 [INFO]: Epoch 006 - training loss: 0.5021, validation loss: 0.3834
2024-05-23 21:37:26 [INFO]: Epoch 007 - training loss: 0.4760, validation loss: 0.3774
2024-05-23 21:37:27 [INFO]: Epoch 008 - training loss: 0.4560, validation loss: 0.3605
2024-05-23 21:37:28 [INFO]: Epoch 009 - training loss: 0.4343, validation loss: 0.3600
2024-05-23 21:37:28 [INFO]: Epoch 010 - training loss: 0.4232, validation loss: 0.3529
2024-05-23 21:37:29 [INFO]: Epoch 011 - training loss: 0.4046, validation loss: 0.3563
2024-05-23 21:37:29 [INFO]: Epoch 012 - training loss: 0.3905, validation loss: 0.3577
2024-05-23 21:37:30 [INFO]: Epoch 013 - training loss: 0.3887, validation loss: 0.3452
2024-05-23 21:37:31 [INFO]: Epoch 014 - training loss: 0.3667, validation loss: 0.3431
2024-05-23 21:37:31 [INFO]: Epoch 015 - training loss: 0.3634, validation loss: 0.3333
2024-05-23 21:37:32 [INFO]: Epoch 016 - training loss: 0.3505, validation loss: 0.3363
2024-05-23 21:37:33 [INFO]: Epoch 017 - training loss: 0.3397, validation loss: 0.3273
2024-05-23 21:37:33 [INFO]: Epoch 018 - training loss: 0.3309, validation loss: 0.3246
2024-05-23 21:37:34 [INFO]: Epoch 019 - training loss: 0.3331, validation loss: 0.3255
2024-05-23 21:37:34 [INFO]: Epoch 020 - training loss: 0.3224, validation loss: 0.3219
2024-05-23 21:37:35 [INFO]: Epoch 021 - training loss: 0.3129, validation loss: 0.3183
2024-05-23 21:37:36 [INFO]: Epoch 022 - training loss: 0.3102, validation loss: 0.3201
2024-05-23 21:37:36 [INFO]: Epoch 023 - training loss: 0.3027, validation loss: 0.3199
2024-05-23 21:37:37 [INFO]: Epoch 024 - training loss: 0.3013, validation loss: 0.3269
2024-05-23 21:37:37 [INFO]: Epoch 025 - training loss: 0.2913, validation loss: 0.3160
2024-05-23 21:37:38 [INFO]: Epoch 026 - training loss: 0.2884, validation loss: 0.3173
2024-05-23 21:37:39 [INFO]: Epoch 027 - training loss: 0.2818, validation loss: 0.3176
2024-05-23 21:37:39 [INFO]: Epoch 028 - training loss: 0.2762, validation loss: 0.3187
2024-05-23 21:37:40 [INFO]: Epoch 029 - training loss: 0.2700, validation loss: 0.3183
2024-05-23 21:37:41 [INFO]: Epoch 030 - training loss: 0.2716, validation loss: 0.3152
2024-05-23 21:37:41 [INFO]: Epoch 031 - training loss: 0.2635, validation loss: 0.3150
2024-05-23 21:37:42 [INFO]: Epoch 032 - training loss: 0.2595, validation loss: 0.3146
2024-05-23 21:37:43 [INFO]: Epoch 033 - training loss: 0.2520, validation loss: 0.3151
2024-05-23 21:37:43 [INFO]: Epoch 034 - training loss: 0.2510, validation loss: 0.3141
2024-05-23 21:37:44 [INFO]: Epoch 035 - training loss: 0.2466, validation loss: 0.3162
2024-05-23 21:37:44 [INFO]: Epoch 036 - training loss: 0.2443, validation loss: 0.3131
2024-05-23 21:37:45 [INFO]: Epoch 037 - training loss: 0.2418, validation loss: 0.3145
2024-05-23 21:37:46 [INFO]: Epoch 038 - training loss: 0.2373, validation loss: 0.3165
2024-05-23 21:37:46 [INFO]: Epoch 039 - training loss: 0.2314, validation loss: 0.3124
2024-05-23 21:37:48 [INFO]: Epoch 040 - training loss: 0.2321, validation loss: 0.3155
2024-05-23 21:37:48 [INFO]: Epoch 041 - training loss: 0.2266, validation loss: 0.3149
2024-05-23 21:37:49 [INFO]: Epoch 042 - training loss: 0.2250, validation loss: 0.3150
2024-05-23 21:37:49 [INFO]: Epoch 043 - training loss: 0.2253, validation loss: 0.3103
2024-05-23 21:37:50 [INFO]: Epoch 044 - training loss: 0.2202, validation loss: 0.3176
2024-05-23 21:37:51 [INFO]: Epoch 045 - training loss: 0.2165, validation loss: 0.3134
2024-05-23 21:37:51 [INFO]: Epoch 046 - training loss: 0.2150, validation loss: 0.3165
2024-05-23 21:37:52 [INFO]: Epoch 047 - training loss: 0.2122, validation loss: 0.3155
2024-05-23 21:37:52 [INFO]: Epoch 048 - training loss: 0.2100, validation loss: 0.3140
2024-05-23 21:37:53 [INFO]: Epoch 049 - training loss: 0.2108, validation loss: 0.3152
2024-05-23 21:37:54 [INFO]: Epoch 050 - training loss: 0.2088, validation loss: 0.3119
2024-05-23 21:37:54 [INFO]: Epoch 051 - training loss: 0.2041, validation loss: 0.3154
2024-05-23 21:37:55 [INFO]: Epoch 052 - training loss: 0.2019, validation loss: 0.3144
2024-05-23 21:37:55 [INFO]: Epoch 053 - training loss: 0.1995, validation loss: 0.3133
2024-05-23 21:37:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:37:55 [INFO]: Finished training. The best model is from epoch#43.
2024-05-23 21:37:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_physionet_2012_seta/20240523_T213722/Transformer.pypots
2024-05-23 21:37:55 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2901, MSE=0.3359
2024-05-23 21:37:56 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_physionet_2012_seta/imputation.pkl
2024-05-23 21:37:56 [INFO]: Using the given device: cuda:0
2024-05-23 21:37:56 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T213756
2024-05-23 21:37:56 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T213756/tensorboard
2024-05-23 21:37:56 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-23 21:37:57 [INFO]: Epoch 001 - training loss: 0.4263, validation loss: 0.3570
2024-05-23 21:37:57 [INFO]: Epoch 002 - training loss: 0.5753, validation loss: 0.4315
2024-05-23 21:37:58 [INFO]: Epoch 003 - training loss: 0.4744, validation loss: 0.3711
2024-05-23 21:37:59 [INFO]: Epoch 004 - training loss: 0.5512, validation loss: 0.3093
2024-05-23 21:38:00 [INFO]: Epoch 005 - training loss: 0.3280, validation loss: 0.3090
2024-05-23 21:38:00 [INFO]: Epoch 006 - training loss: 0.3022, validation loss: 0.3011
2024-05-23 21:38:01 [INFO]: Epoch 007 - training loss: 0.2883, validation loss: 0.2959
2024-05-23 21:38:02 [INFO]: Epoch 008 - training loss: 0.2757, validation loss: 0.3008
2024-05-23 21:38:02 [INFO]: Epoch 009 - training loss: 0.2750, validation loss: 0.2957
2024-05-23 21:38:03 [INFO]: Epoch 010 - training loss: 0.2659, validation loss: 0.3040
2024-05-23 21:38:04 [INFO]: Epoch 011 - training loss: 0.2652, validation loss: 0.2969
2024-05-23 21:38:04 [INFO]: Epoch 012 - training loss: 0.2710, validation loss: 0.2911
2024-05-23 21:38:05 [INFO]: Epoch 013 - training loss: 0.2438, validation loss: 0.2964
2024-05-23 21:38:06 [INFO]: Epoch 014 - training loss: 0.2435, validation loss: 0.2980
2024-05-23 21:38:07 [INFO]: Epoch 015 - training loss: 0.2416, validation loss: 0.2959
2024-05-23 21:38:07 [INFO]: Epoch 016 - training loss: 0.2363, validation loss: 0.2982
2024-05-23 21:38:08 [INFO]: Epoch 017 - training loss: 0.2279, validation loss: 0.2889
2024-05-23 21:38:09 [INFO]: Epoch 018 - training loss: 0.2253, validation loss: 0.3016
2024-05-23 21:38:09 [INFO]: Epoch 019 - training loss: 0.2247, validation loss: 0.2926
2024-05-23 21:38:10 [INFO]: Epoch 020 - training loss: 0.2238, validation loss: 0.2981
2024-05-23 21:38:11 [INFO]: Epoch 021 - training loss: 0.2197, validation loss: 0.3043
2024-05-23 21:38:12 [INFO]: Epoch 022 - training loss: 0.2137, validation loss: 0.3006
2024-05-23 21:38:12 [INFO]: Epoch 023 - training loss: 0.2086, validation loss: 0.2878
2024-05-23 21:38:13 [INFO]: Epoch 024 - training loss: 0.2196, validation loss: 0.3055
2024-05-23 21:38:14 [INFO]: Epoch 025 - training loss: 0.2466, validation loss: 0.2938
2024-05-23 21:38:14 [INFO]: Epoch 026 - training loss: 0.2226, validation loss: 0.3001
2024-05-23 21:38:15 [INFO]: Epoch 027 - training loss: 0.2152, validation loss: 0.3094
2024-05-23 21:38:16 [INFO]: Epoch 028 - training loss: 0.2297, validation loss: 0.3002
2024-05-23 21:38:17 [INFO]: Epoch 029 - training loss: 0.2077, validation loss: 0.2984
2024-05-23 21:38:17 [INFO]: Epoch 030 - training loss: 0.1965, validation loss: 0.3078
2024-05-23 21:38:18 [INFO]: Epoch 031 - training loss: 0.1886, validation loss: 0.2918
2024-05-23 21:38:19 [INFO]: Epoch 032 - training loss: 0.1878, validation loss: 0.3063
2024-05-23 21:38:19 [INFO]: Epoch 033 - training loss: 0.1853, validation loss: 0.2944
2024-05-23 21:38:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:38:19 [INFO]: Finished training. The best model is from epoch#23.
2024-05-23 21:38:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_physionet_2012_seta/20240523_T213756/TimesNet.pypots
2024-05-23 21:38:20 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2947, MSE=0.2882
2024-05-23 21:38:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-23 21:38:20 [INFO]: Using the given device: cuda:0
2024-05-23 21:38:20 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820
2024-05-23 21:38:20 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/tensorboard
2024-05-23 21:38:20 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-23 21:39:03 [INFO]: Epoch 001 - training loss: 0.4149, validation loss: 0.3350
2024-05-23 21:39:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch1_loss0.33499919027090075.pypots
2024-05-23 21:39:47 [INFO]: Epoch 002 - training loss: 0.3259, validation loss: 0.3089
2024-05-23 21:39:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch2_loss0.3089113235473633.pypots
2024-05-23 21:40:32 [INFO]: Epoch 003 - training loss: 0.3014, validation loss: 0.2696
2024-05-23 21:40:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch3_loss0.2695989489555359.pypots
2024-05-23 21:41:16 [INFO]: Epoch 004 - training loss: 0.2712, validation loss: 0.2545
2024-05-23 21:41:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch4_loss0.254541901499033.pypots
2024-05-23 21:42:00 [INFO]: Epoch 005 - training loss: 0.2593, validation loss: 0.2606
2024-05-23 21:42:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch5_loss0.26063180193305013.pypots
2024-05-23 21:42:44 [INFO]: Epoch 006 - training loss: 0.2517, validation loss: 0.2430
2024-05-23 21:42:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch6_loss0.24298438876867295.pypots
2024-05-23 21:43:28 [INFO]: Epoch 007 - training loss: 0.2446, validation loss: 0.2274
2024-05-23 21:43:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch7_loss0.22736189961433412.pypots
2024-05-23 21:44:13 [INFO]: Epoch 008 - training loss: 0.2370, validation loss: 0.2355
2024-05-23 21:44:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch8_loss0.23546508327126503.pypots
2024-05-23 21:44:57 [INFO]: Epoch 009 - training loss: 0.2245, validation loss: 0.2211
2024-05-23 21:44:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch9_loss0.22111889123916625.pypots
2024-05-23 21:45:41 [INFO]: Epoch 010 - training loss: 0.2232, validation loss: 0.2169
2024-05-23 21:45:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch10_loss0.21694625094532966.pypots
2024-05-23 21:46:25 [INFO]: Epoch 011 - training loss: 0.2246, validation loss: 0.2187
2024-05-23 21:46:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch11_loss0.21871772408485413.pypots
2024-05-23 21:47:09 [INFO]: Epoch 012 - training loss: 0.2160, validation loss: 0.2201
2024-05-23 21:47:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch12_loss0.2201412685215473.pypots
2024-05-23 21:47:53 [INFO]: Epoch 013 - training loss: 0.2247, validation loss: 0.2080
2024-05-23 21:47:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch13_loss0.20796560272574424.pypots
2024-05-23 21:48:38 [INFO]: Epoch 014 - training loss: 0.2216, validation loss: 0.2105
2024-05-23 21:48:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch14_loss0.21052191630005837.pypots
2024-05-23 21:49:22 [INFO]: Epoch 015 - training loss: 0.2183, validation loss: 0.2067
2024-05-23 21:49:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch15_loss0.20673324167728424.pypots
2024-05-23 21:50:06 [INFO]: Epoch 016 - training loss: 0.2146, validation loss: 0.2044
2024-05-23 21:50:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch16_loss0.20439307540655136.pypots
2024-05-23 21:50:50 [INFO]: Epoch 017 - training loss: 0.2236, validation loss: 0.2051
2024-05-23 21:50:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch17_loss0.2050804764032364.pypots
2024-05-23 21:51:34 [INFO]: Epoch 018 - training loss: 0.2147, validation loss: 0.2069
2024-05-23 21:51:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch18_loss0.20686230733990668.pypots
2024-05-23 21:52:19 [INFO]: Epoch 019 - training loss: 0.2245, validation loss: 0.2030
2024-05-23 21:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch19_loss0.2030049167573452.pypots
2024-05-23 21:53:03 [INFO]: Epoch 020 - training loss: 0.2142, validation loss: 0.2028
2024-05-23 21:53:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch20_loss0.20284036323428153.pypots
2024-05-23 21:53:47 [INFO]: Epoch 021 - training loss: 0.2149, validation loss: 0.2019
2024-05-23 21:53:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch21_loss0.20193648859858512.pypots
2024-05-23 21:54:31 [INFO]: Epoch 022 - training loss: 0.2091, validation loss: 0.2021
2024-05-23 21:54:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch22_loss0.20207331627607344.pypots
2024-05-23 21:55:15 [INFO]: Epoch 023 - training loss: 0.2118, validation loss: 0.2008
2024-05-23 21:55:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch23_loss0.20078466087579727.pypots
2024-05-23 21:56:00 [INFO]: Epoch 024 - training loss: 0.2047, validation loss: 0.2006
2024-05-23 21:56:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch24_loss0.20057117119431495.pypots
2024-05-23 21:56:44 [INFO]: Epoch 025 - training loss: 0.2040, validation loss: 0.1966
2024-05-23 21:56:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch25_loss0.19658199474215507.pypots
2024-05-23 21:57:28 [INFO]: Epoch 026 - training loss: 0.2068, validation loss: 0.1937
2024-05-23 21:57:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch26_loss0.19370713979005813.pypots
2024-05-23 21:58:12 [INFO]: Epoch 027 - training loss: 0.2067, validation loss: 0.1950
2024-05-23 21:58:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch27_loss0.1950458414852619.pypots
2024-05-23 21:58:56 [INFO]: Epoch 028 - training loss: 0.1993, validation loss: 0.1959
2024-05-23 21:58:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch28_loss0.19588825479149818.pypots
2024-05-23 21:59:40 [INFO]: Epoch 029 - training loss: 0.2048, validation loss: 0.1957
2024-05-23 21:59:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch29_loss0.19565572291612626.pypots
2024-05-23 22:00:24 [INFO]: Epoch 030 - training loss: 0.2092, validation loss: 0.1950
2024-05-23 22:00:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch30_loss0.19495480731129647.pypots
2024-05-23 22:01:08 [INFO]: Epoch 031 - training loss: 0.2065, validation loss: 0.1966
2024-05-23 22:01:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch31_loss0.19659405574202538.pypots
2024-05-23 22:01:52 [INFO]: Epoch 032 - training loss: 0.1966, validation loss: 0.1978
2024-05-23 22:01:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch32_loss0.1977608986198902.pypots
2024-05-23 22:02:36 [INFO]: Epoch 033 - training loss: 0.2033, validation loss: 0.1960
2024-05-23 22:02:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch33_loss0.1959645316004753.pypots
2024-05-23 22:03:20 [INFO]: Epoch 034 - training loss: 0.2004, validation loss: 0.1905
2024-05-23 22:03:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch34_loss0.19046589583158494.pypots
2024-05-23 22:04:04 [INFO]: Epoch 035 - training loss: 0.1966, validation loss: 0.1938
2024-05-23 22:04:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch35_loss0.1937869183719158.pypots
2024-05-23 22:04:48 [INFO]: Epoch 036 - training loss: 0.2058, validation loss: 0.1988
2024-05-23 22:04:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch36_loss0.1987656645476818.pypots
2024-05-23 22:05:33 [INFO]: Epoch 037 - training loss: 0.1999, validation loss: 0.1929
2024-05-23 22:05:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch37_loss0.19287439435720444.pypots
2024-05-23 22:06:17 [INFO]: Epoch 038 - training loss: 0.1998, validation loss: 0.1960
2024-05-23 22:06:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch38_loss0.19602250680327415.pypots
2024-05-23 22:07:01 [INFO]: Epoch 039 - training loss: 0.1971, validation loss: 0.1936
2024-05-23 22:07:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch39_loss0.19357239007949828.pypots
2024-05-23 22:07:45 [INFO]: Epoch 040 - training loss: 0.2020, validation loss: 0.1922
2024-05-23 22:07:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch40_loss0.19216901287436486.pypots
2024-05-23 22:08:29 [INFO]: Epoch 041 - training loss: 0.2079, validation loss: 0.1921
2024-05-23 22:08:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch41_loss0.19213901311159134.pypots
2024-05-23 22:09:13 [INFO]: Epoch 042 - training loss: 0.2055, validation loss: 0.1871
2024-05-23 22:09:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch42_loss0.18712807223200797.pypots
2024-05-23 22:09:57 [INFO]: Epoch 043 - training loss: 0.2011, validation loss: 0.1887
2024-05-23 22:09:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch43_loss0.1887151412665844.pypots
2024-05-23 22:10:41 [INFO]: Epoch 044 - training loss: 0.1948, validation loss: 0.1919
2024-05-23 22:10:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch44_loss0.19188100025057792.pypots
2024-05-23 22:11:25 [INFO]: Epoch 045 - training loss: 0.2040, validation loss: 0.1882
2024-05-23 22:11:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch45_loss0.18817802965641023.pypots
2024-05-23 22:12:09 [INFO]: Epoch 046 - training loss: 0.2030, validation loss: 0.1893
2024-05-23 22:12:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch46_loss0.18932788148522378.pypots
2024-05-23 22:12:53 [INFO]: Epoch 047 - training loss: 0.1848, validation loss: 0.1870
2024-05-23 22:12:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch47_loss0.18704143837094306.pypots
2024-05-23 22:13:37 [INFO]: Epoch 048 - training loss: 0.1955, validation loss: 0.1869
2024-05-23 22:13:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch48_loss0.1868910051882267.pypots
2024-05-23 22:14:21 [INFO]: Epoch 049 - training loss: 0.1987, validation loss: 0.1883
2024-05-23 22:14:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch49_loss0.1882965810596943.pypots
2024-05-23 22:15:05 [INFO]: Epoch 050 - training loss: 0.1925, validation loss: 0.1888
2024-05-23 22:15:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch50_loss0.18876201063394546.pypots
2024-05-23 22:15:50 [INFO]: Epoch 051 - training loss: 0.2050, validation loss: 0.1886
2024-05-23 22:15:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch51_loss0.1885984607040882.pypots
2024-05-23 22:16:34 [INFO]: Epoch 052 - training loss: 0.2007, validation loss: 0.1883
2024-05-23 22:16:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch52_loss0.18829700574278832.pypots
2024-05-23 22:17:18 [INFO]: Epoch 053 - training loss: 0.1984, validation loss: 0.1870
2024-05-23 22:17:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch53_loss0.1869990386068821.pypots
2024-05-23 22:18:02 [INFO]: Epoch 054 - training loss: 0.1928, validation loss: 0.1894
2024-05-23 22:18:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch54_loss0.18941278532147407.pypots
2024-05-23 22:18:45 [INFO]: Epoch 055 - training loss: 0.1914, validation loss: 0.1863
2024-05-23 22:18:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch55_loss0.18632055521011354.pypots
2024-05-23 22:19:29 [INFO]: Epoch 056 - training loss: 0.1922, validation loss: 0.1887
2024-05-23 22:19:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch56_loss0.1886950246989727.pypots
2024-05-23 22:20:13 [INFO]: Epoch 057 - training loss: 0.2055, validation loss: 0.1853
2024-05-23 22:20:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch57_loss0.18527626916766166.pypots
2024-05-23 22:20:57 [INFO]: Epoch 058 - training loss: 0.1903, validation loss: 0.1876
2024-05-23 22:20:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch58_loss0.18756128698587418.pypots
2024-05-23 22:21:41 [INFO]: Epoch 059 - training loss: 0.1834, validation loss: 0.1859
2024-05-23 22:21:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch59_loss0.18593026101589202.pypots
2024-05-23 22:22:25 [INFO]: Epoch 060 - training loss: 0.2040, validation loss: 0.1891
2024-05-23 22:22:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch60_loss0.18913752883672713.pypots
2024-05-23 22:23:09 [INFO]: Epoch 061 - training loss: 0.1927, validation loss: 0.1840
2024-05-23 22:23:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch61_loss0.18396044746041298.pypots
2024-05-23 22:23:53 [INFO]: Epoch 062 - training loss: 0.1928, validation loss: 0.1877
2024-05-23 22:23:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch62_loss0.1877066858112812.pypots
2024-05-23 22:24:37 [INFO]: Epoch 063 - training loss: 0.1887, validation loss: 0.1841
2024-05-23 22:24:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch63_loss0.18409552276134492.pypots
2024-05-23 22:25:21 [INFO]: Epoch 064 - training loss: 0.1948, validation loss: 0.1869
2024-05-23 22:25:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch64_loss0.18691097646951677.pypots
2024-05-23 22:26:05 [INFO]: Epoch 065 - training loss: 0.1990, validation loss: 0.1837
2024-05-23 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch65_loss0.1836640566587448.pypots
2024-05-23 22:26:49 [INFO]: Epoch 066 - training loss: 0.1805, validation loss: 0.1853
2024-05-23 22:26:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch66_loss0.1852685533463955.pypots
2024-05-23 22:27:33 [INFO]: Epoch 067 - training loss: 0.1841, validation loss: 0.1843
2024-05-23 22:27:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch67_loss0.1842608258128166.pypots
2024-05-23 22:28:17 [INFO]: Epoch 068 - training loss: 0.1840, validation loss: 0.1849
2024-05-23 22:28:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch68_loss0.18491386771202087.pypots
2024-05-23 22:29:01 [INFO]: Epoch 069 - training loss: 0.1917, validation loss: 0.1830
2024-05-23 22:29:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch69_loss0.18299807086586953.pypots
2024-05-23 22:29:45 [INFO]: Epoch 070 - training loss: 0.1881, validation loss: 0.1837
2024-05-23 22:29:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch70_loss0.18365051299333573.pypots
2024-05-23 22:30:29 [INFO]: Epoch 071 - training loss: 0.1807, validation loss: 0.1835
2024-05-23 22:30:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch71_loss0.18351281061768532.pypots
2024-05-23 22:31:13 [INFO]: Epoch 072 - training loss: 0.1928, validation loss: 0.1824
2024-05-23 22:31:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch72_loss0.1823907859623432.pypots
2024-05-23 22:31:57 [INFO]: Epoch 073 - training loss: 0.1876, validation loss: 0.1846
2024-05-23 22:31:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch73_loss0.1845664784312248.pypots
2024-05-23 22:32:41 [INFO]: Epoch 074 - training loss: 0.1883, validation loss: 0.1807
2024-05-23 22:32:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch74_loss0.18066342324018478.pypots
2024-05-23 22:33:25 [INFO]: Epoch 075 - training loss: 0.1937, validation loss: 0.1822
2024-05-23 22:33:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch75_loss0.18224635422229768.pypots
2024-05-23 22:34:09 [INFO]: Epoch 076 - training loss: 0.1946, validation loss: 0.1852
2024-05-23 22:34:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch76_loss0.18517782762646676.pypots
2024-05-23 22:34:53 [INFO]: Epoch 077 - training loss: 0.1815, validation loss: 0.1825
2024-05-23 22:34:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch77_loss0.18253326267004014.pypots
2024-05-23 22:35:37 [INFO]: Epoch 078 - training loss: 0.1881, validation loss: 0.1840
2024-05-23 22:35:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch78_loss0.18395740762352944.pypots
2024-05-23 22:36:21 [INFO]: Epoch 079 - training loss: 0.1919, validation loss: 0.1836
2024-05-23 22:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch79_loss0.18356071561574935.pypots
2024-05-23 22:37:05 [INFO]: Epoch 080 - training loss: 0.1938, validation loss: 0.1837
2024-05-23 22:37:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch80_loss0.1837048277258873.pypots
2024-05-23 22:37:49 [INFO]: Epoch 081 - training loss: 0.1922, validation loss: 0.1804
2024-05-23 22:37:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch81_loss0.18037448450922966.pypots
2024-05-23 22:38:33 [INFO]: Epoch 082 - training loss: 0.1868, validation loss: 0.1833
2024-05-23 22:38:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch82_loss0.18330308571457862.pypots
2024-05-23 22:39:17 [INFO]: Epoch 083 - training loss: 0.1919, validation loss: 0.1831
2024-05-23 22:39:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch83_loss0.18311409428715705.pypots
2024-05-23 22:40:00 [INFO]: Epoch 084 - training loss: 0.1813, validation loss: 0.1809
2024-05-23 22:40:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch84_loss0.18088559359312056.pypots
2024-05-23 22:40:44 [INFO]: Epoch 085 - training loss: 0.1989, validation loss: 0.1825
2024-05-23 22:40:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch85_loss0.18248720169067384.pypots
2024-05-23 22:41:28 [INFO]: Epoch 086 - training loss: 0.1746, validation loss: 0.1830
2024-05-23 22:41:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch86_loss0.18298783227801324.pypots
2024-05-23 22:42:12 [INFO]: Epoch 087 - training loss: 0.1892, validation loss: 0.1816
2024-05-23 22:42:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch87_loss0.18164083138108253.pypots
2024-05-23 22:42:56 [INFO]: Epoch 088 - training loss: 0.1809, validation loss: 0.1791
2024-05-23 22:42:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch88_loss0.17908832505345346.pypots
2024-05-23 22:43:40 [INFO]: Epoch 089 - training loss: 0.1970, validation loss: 0.1806
2024-05-23 22:43:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch89_loss0.1805847816169262.pypots
2024-05-23 22:44:24 [INFO]: Epoch 090 - training loss: 0.1903, validation loss: 0.1816
2024-05-23 22:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch90_loss0.18156281784176825.pypots
2024-05-23 22:45:08 [INFO]: Epoch 091 - training loss: 0.1968, validation loss: 0.1828
2024-05-23 22:45:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch91_loss0.18280667811632156.pypots
2024-05-23 22:45:52 [INFO]: Epoch 092 - training loss: 0.1842, validation loss: 0.1796
2024-05-23 22:45:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch92_loss0.17963463440537453.pypots
2024-05-23 22:46:36 [INFO]: Epoch 093 - training loss: 0.1723, validation loss: 0.1822
2024-05-23 22:46:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch93_loss0.18223934769630432.pypots
2024-05-23 22:47:20 [INFO]: Epoch 094 - training loss: 0.1905, validation loss: 0.1809
2024-05-23 22:47:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch94_loss0.18092542588710786.pypots
2024-05-23 22:48:04 [INFO]: Epoch 095 - training loss: 0.1829, validation loss: 0.1829
2024-05-23 22:48:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch95_loss0.1829147107899189.pypots
2024-05-23 22:48:48 [INFO]: Epoch 096 - training loss: 0.1903, validation loss: 0.1833
2024-05-23 22:48:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch96_loss0.18329844921827315.pypots
2024-05-23 22:49:32 [INFO]: Epoch 097 - training loss: 0.1789, validation loss: 0.1830
2024-05-23 22:49:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch97_loss0.18295929282903672.pypots
2024-05-23 22:50:16 [INFO]: Epoch 098 - training loss: 0.1792, validation loss: 0.1790
2024-05-23 22:50:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch98_loss0.17903054729104043.pypots
2024-05-23 22:51:00 [INFO]: Epoch 099 - training loss: 0.1924, validation loss: 0.1794
2024-05-23 22:51:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch99_loss0.17940522134304046.pypots
2024-05-23 22:51:44 [INFO]: Epoch 100 - training loss: 0.1908, validation loss: 0.1806
2024-05-23 22:51:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch100_loss0.18063700944185257.pypots
2024-05-23 22:52:28 [INFO]: Epoch 101 - training loss: 0.1854, validation loss: 0.1800
2024-05-23 22:52:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch101_loss0.18004945963621138.pypots
2024-05-23 22:53:12 [INFO]: Epoch 102 - training loss: 0.1895, validation loss: 0.1807
2024-05-23 22:53:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch102_loss0.1806516781449318.pypots
2024-05-23 22:53:56 [INFO]: Epoch 103 - training loss: 0.1809, validation loss: 0.1819
2024-05-23 22:53:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch103_loss0.18193566650152207.pypots
2024-05-23 22:54:40 [INFO]: Epoch 104 - training loss: 0.1814, validation loss: 0.1815
2024-05-23 22:54:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch104_loss0.1815321274101734.pypots
2024-05-23 22:55:23 [INFO]: Epoch 105 - training loss: 0.1828, validation loss: 0.1801
2024-05-23 22:55:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch105_loss0.18006141856312752.pypots
2024-05-23 22:56:07 [INFO]: Epoch 106 - training loss: 0.1814, validation loss: 0.1817
2024-05-23 22:56:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch106_loss0.18165491968393327.pypots
2024-05-23 22:56:51 [INFO]: Epoch 107 - training loss: 0.1823, validation loss: 0.1852
2024-05-23 22:56:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch107_loss0.18519335761666297.pypots
2024-05-23 22:57:35 [INFO]: Epoch 108 - training loss: 0.1856, validation loss: 0.1824
2024-05-23 22:57:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI_epoch108_loss0.1823692500591278.pypots
2024-05-23 22:57:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 22:57:35 [INFO]: Finished training. The best model is from epoch#98.
2024-05-23 22:57:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/20240523_T213820/CSDI.pypots
2024-05-23 23:04:58 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2494, MSE=0.4456
2024-05-23 23:34:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_physionet_2012_seta/imputation.pkl
2024-05-23 23:34:28 [INFO]: Using the given device: cuda:0
2024-05-23 23:34:28 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T233428
2024-05-23 23:34:28 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T233428/tensorboard
2024-05-23 23:34:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-23 23:34:28 [INFO]: Epoch 001 - training loss: 42904.1016, validation loss: 0.9245
2024-05-23 23:34:29 [INFO]: Epoch 002 - training loss: 24447.9579, validation loss: 0.7502
2024-05-23 23:34:30 [INFO]: Epoch 003 - training loss: 23496.4632, validation loss: 0.7175
2024-05-23 23:34:31 [INFO]: Epoch 004 - training loss: 23191.7580, validation loss: 0.6673
2024-05-23 23:34:31 [INFO]: Epoch 005 - training loss: 23040.3012, validation loss: 0.6517
2024-05-23 23:34:32 [INFO]: Epoch 006 - training loss: 22956.3803, validation loss: 0.6483
2024-05-23 23:34:33 [INFO]: Epoch 007 - training loss: 22906.6916, validation loss: 0.6434
2024-05-23 23:34:33 [INFO]: Epoch 008 - training loss: 22874.4005, validation loss: 0.6414
2024-05-23 23:34:34 [INFO]: Epoch 009 - training loss: 22852.8788, validation loss: 0.6408
2024-05-23 23:34:35 [INFO]: Epoch 010 - training loss: 22838.0122, validation loss: 0.6446
2024-05-23 23:34:35 [INFO]: Epoch 011 - training loss: 22827.2133, validation loss: 0.6420
2024-05-23 23:34:36 [INFO]: Epoch 012 - training loss: 22819.2672, validation loss: 0.6342
2024-05-23 23:34:37 [INFO]: Epoch 013 - training loss: 22813.4193, validation loss: 0.6330
2024-05-23 23:34:37 [INFO]: Epoch 014 - training loss: 22808.3449, validation loss: 0.6301
2024-05-23 23:34:38 [INFO]: Epoch 015 - training loss: 22804.2014, validation loss: 0.6329
2024-05-23 23:34:39 [INFO]: Epoch 016 - training loss: 22801.4091, validation loss: 0.6278
2024-05-23 23:34:39 [INFO]: Epoch 017 - training loss: 22798.8376, validation loss: 0.6262
2024-05-23 23:34:40 [INFO]: Epoch 018 - training loss: 22796.8320, validation loss: 0.6198
2024-05-23 23:34:41 [INFO]: Epoch 019 - training loss: 22794.7546, validation loss: 0.6167
2024-05-23 23:34:42 [INFO]: Epoch 020 - training loss: 22792.5090, validation loss: 0.6146
2024-05-23 23:34:42 [INFO]: Epoch 021 - training loss: 22790.7147, validation loss: 0.6151
2024-05-23 23:34:43 [INFO]: Epoch 022 - training loss: 22789.4490, validation loss: 0.6097
2024-05-23 23:34:44 [INFO]: Epoch 023 - training loss: 22788.4575, validation loss: 0.6167
2024-05-23 23:34:44 [INFO]: Epoch 024 - training loss: 22786.9550, validation loss: 0.6107
2024-05-23 23:34:45 [INFO]: Epoch 025 - training loss: 22786.5479, validation loss: 0.6125
2024-05-23 23:34:46 [INFO]: Epoch 026 - training loss: 22785.6980, validation loss: 0.6006
2024-05-23 23:34:46 [INFO]: Epoch 027 - training loss: 22785.2133, validation loss: 0.5984
2024-05-23 23:34:47 [INFO]: Epoch 028 - training loss: 22784.0312, validation loss: 0.6002
2024-05-23 23:34:48 [INFO]: Epoch 029 - training loss: 22783.6721, validation loss: 0.6004
2024-05-23 23:34:48 [INFO]: Epoch 030 - training loss: 22783.4220, validation loss: 0.5946
2024-05-23 23:34:49 [INFO]: Epoch 031 - training loss: 22783.3325, validation loss: 0.5929
2024-05-23 23:34:50 [INFO]: Epoch 032 - training loss: 22782.9157, validation loss: 0.5932
2024-05-23 23:34:50 [INFO]: Epoch 033 - training loss: 22782.0736, validation loss: 0.5904
2024-05-23 23:34:51 [INFO]: Epoch 034 - training loss: 22781.2381, validation loss: 0.5949
2024-05-23 23:34:52 [INFO]: Epoch 035 - training loss: 22781.3291, validation loss: 0.5872
2024-05-23 23:34:53 [INFO]: Epoch 036 - training loss: 22780.1881, validation loss: 0.5888
2024-05-23 23:34:53 [INFO]: Epoch 037 - training loss: 22779.0559, validation loss: 0.5805
2024-05-23 23:34:54 [INFO]: Epoch 038 - training loss: 22778.0779, validation loss: 0.5820
2024-05-23 23:34:55 [INFO]: Epoch 039 - training loss: 22776.9798, validation loss: 0.5723
2024-05-23 23:34:55 [INFO]: Epoch 040 - training loss: 22775.9564, validation loss: 0.5680
2024-05-23 23:34:56 [INFO]: Epoch 041 - training loss: 22776.1362, validation loss: 0.5677
2024-05-23 23:34:57 [INFO]: Epoch 042 - training loss: 22774.8840, validation loss: 0.5639
2024-05-23 23:34:57 [INFO]: Epoch 043 - training loss: 22773.8003, validation loss: 0.5591
2024-05-23 23:34:58 [INFO]: Epoch 044 - training loss: 22772.7996, validation loss: 0.5584
2024-05-23 23:34:59 [INFO]: Epoch 045 - training loss: 22771.4243, validation loss: 0.5633
2024-05-23 23:34:59 [INFO]: Epoch 046 - training loss: 22770.8230, validation loss: 0.5565
2024-05-23 23:35:00 [INFO]: Epoch 047 - training loss: 22770.3603, validation loss: 0.5590
2024-05-23 23:35:01 [INFO]: Epoch 048 - training loss: 22769.5344, validation loss: 0.5587
2024-05-23 23:35:01 [INFO]: Epoch 049 - training loss: 22769.3804, validation loss: 0.5494
2024-05-23 23:35:02 [INFO]: Epoch 050 - training loss: 22768.2672, validation loss: 0.5440
2024-05-23 23:35:03 [INFO]: Epoch 051 - training loss: 22767.1760, validation loss: 0.5384
2024-05-23 23:35:04 [INFO]: Epoch 052 - training loss: 22766.5985, validation loss: 0.5376
2024-05-23 23:35:04 [INFO]: Epoch 053 - training loss: 22765.7342, validation loss: 0.5419
2024-05-23 23:35:05 [INFO]: Epoch 054 - training loss: 22764.9615, validation loss: 0.5333
2024-05-23 23:35:06 [INFO]: Epoch 055 - training loss: 22764.4661, validation loss: 0.5333
2024-05-23 23:35:06 [INFO]: Epoch 056 - training loss: 22763.7355, validation loss: 0.5355
2024-05-23 23:35:07 [INFO]: Epoch 057 - training loss: 22763.3075, validation loss: 0.5302
2024-05-23 23:35:08 [INFO]: Epoch 058 - training loss: 22763.0543, validation loss: 0.5328
2024-05-23 23:35:08 [INFO]: Epoch 059 - training loss: 22762.6718, validation loss: 0.5291
2024-05-23 23:35:09 [INFO]: Epoch 060 - training loss: 22761.6957, validation loss: 0.5260
2024-05-23 23:35:10 [INFO]: Epoch 061 - training loss: 22761.1410, validation loss: 0.5437
2024-05-23 23:35:10 [INFO]: Epoch 062 - training loss: 22761.7459, validation loss: 0.5223
2024-05-23 23:35:11 [INFO]: Epoch 063 - training loss: 22761.0772, validation loss: 0.5206
2024-05-23 23:35:12 [INFO]: Epoch 064 - training loss: 22760.4156, validation loss: 0.5165
2024-05-23 23:35:12 [INFO]: Epoch 065 - training loss: 22759.9278, validation loss: 0.5399
2024-05-23 23:35:13 [INFO]: Epoch 066 - training loss: 22759.8798, validation loss: 0.5144
2024-05-23 23:35:14 [INFO]: Epoch 067 - training loss: 22759.7968, validation loss: 0.5159
2024-05-23 23:35:14 [INFO]: Epoch 068 - training loss: 22758.4932, validation loss: 0.5095
2024-05-23 23:35:15 [INFO]: Epoch 069 - training loss: 22757.7592, validation loss: 0.5062
2024-05-23 23:35:16 [INFO]: Epoch 070 - training loss: 22757.6482, validation loss: 0.5086
2024-05-23 23:35:17 [INFO]: Epoch 071 - training loss: 22757.6604, validation loss: 0.5106
2024-05-23 23:35:17 [INFO]: Epoch 072 - training loss: 22757.5819, validation loss: 0.5113
2024-05-23 23:35:18 [INFO]: Epoch 073 - training loss: 22756.6125, validation loss: 0.5067
2024-05-23 23:35:19 [INFO]: Epoch 074 - training loss: 22756.9226, validation loss: 0.5067
2024-05-23 23:35:19 [INFO]: Epoch 075 - training loss: 22756.2384, validation loss: 0.5044
2024-05-23 23:35:20 [INFO]: Epoch 076 - training loss: 22758.0119, validation loss: 0.5043
2024-05-23 23:35:21 [INFO]: Epoch 077 - training loss: 22755.8787, validation loss: 0.5029
2024-05-23 23:35:21 [INFO]: Epoch 078 - training loss: 22756.2542, validation loss: 0.5036
2024-05-23 23:35:22 [INFO]: Epoch 079 - training loss: 22755.0949, validation loss: 0.5010
2024-05-23 23:35:23 [INFO]: Epoch 080 - training loss: 22754.8021, validation loss: 0.5063
2024-05-23 23:35:23 [INFO]: Epoch 081 - training loss: 22754.5145, validation loss: 0.5011
2024-05-23 23:35:24 [INFO]: Epoch 082 - training loss: 22754.2545, validation loss: 0.4985
2024-05-23 23:35:25 [INFO]: Epoch 083 - training loss: 22753.9236, validation loss: 0.5009
2024-05-23 23:35:25 [INFO]: Epoch 084 - training loss: 22754.1175, validation loss: 0.4979
2024-05-23 23:35:26 [INFO]: Epoch 085 - training loss: 22753.9039, validation loss: 0.4953
2024-05-23 23:35:27 [INFO]: Epoch 086 - training loss: 22753.3910, validation loss: 0.4943
2024-05-23 23:35:27 [INFO]: Epoch 087 - training loss: 22753.5389, validation loss: 0.4948
2024-05-23 23:35:28 [INFO]: Epoch 088 - training loss: 22752.7002, validation loss: 0.4898
2024-05-23 23:35:29 [INFO]: Epoch 089 - training loss: 22752.4998, validation loss: 0.4941
2024-05-23 23:35:29 [INFO]: Epoch 090 - training loss: 22752.3235, validation loss: 0.4971
2024-05-23 23:35:30 [INFO]: Epoch 091 - training loss: 22752.1949, validation loss: 0.4885
2024-05-23 23:35:31 [INFO]: Epoch 092 - training loss: 22751.8032, validation loss: 0.4891
2024-05-23 23:35:31 [INFO]: Epoch 093 - training loss: 22752.3091, validation loss: 0.4929
2024-05-23 23:35:32 [INFO]: Epoch 094 - training loss: 22752.0330, validation loss: 0.4921
2024-05-23 23:35:33 [INFO]: Epoch 095 - training loss: 22751.7680, validation loss: 0.4899
2024-05-23 23:35:33 [INFO]: Epoch 096 - training loss: 22752.5710, validation loss: 0.4919
2024-05-23 23:35:34 [INFO]: Epoch 097 - training loss: 22752.0748, validation loss: 0.4905
2024-05-23 23:35:35 [INFO]: Epoch 098 - training loss: 22751.8192, validation loss: 0.4859
2024-05-23 23:35:35 [INFO]: Epoch 099 - training loss: 22751.4631, validation loss: 0.4959
2024-05-23 23:35:36 [INFO]: Epoch 100 - training loss: 22754.0155, validation loss: 0.4858
2024-05-23 23:35:37 [INFO]: Epoch 101 - training loss: 22751.6861, validation loss: 0.4920
2024-05-23 23:35:37 [INFO]: Epoch 102 - training loss: 22751.0295, validation loss: 0.5092
2024-05-23 23:35:38 [INFO]: Epoch 103 - training loss: 22751.9583, validation loss: 0.4855
2024-05-23 23:35:39 [INFO]: Epoch 104 - training loss: 22751.9477, validation loss: 0.4894
2024-05-23 23:35:40 [INFO]: Epoch 105 - training loss: 22750.2992, validation loss: 0.5019
2024-05-23 23:35:40 [INFO]: Epoch 106 - training loss: 22751.6797, validation loss: 0.4890
2024-05-23 23:35:41 [INFO]: Epoch 107 - training loss: 22751.5177, validation loss: 0.4822
2024-05-23 23:35:42 [INFO]: Epoch 108 - training loss: 22750.4518, validation loss: 0.4828
2024-05-23 23:35:42 [INFO]: Epoch 109 - training loss: 22749.8754, validation loss: 0.4783
2024-05-23 23:35:43 [INFO]: Epoch 110 - training loss: 22749.1294, validation loss: 0.4784
2024-05-23 23:35:44 [INFO]: Epoch 111 - training loss: 22749.2491, validation loss: 0.4749
2024-05-23 23:35:44 [INFO]: Epoch 112 - training loss: 22749.5342, validation loss: 0.4833
2024-05-23 23:35:45 [INFO]: Epoch 113 - training loss: 22749.3100, validation loss: 0.4795
2024-05-23 23:35:46 [INFO]: Epoch 114 - training loss: 22748.9859, validation loss: 0.4793
2024-05-23 23:35:46 [INFO]: Epoch 115 - training loss: 22748.6712, validation loss: 0.4764
2024-05-23 23:35:47 [INFO]: Epoch 116 - training loss: 22748.7201, validation loss: 0.4780
2024-05-23 23:35:48 [INFO]: Epoch 117 - training loss: 22748.4158, validation loss: 0.4760
2024-05-23 23:35:48 [INFO]: Epoch 118 - training loss: 22748.3891, validation loss: 0.4785
2024-05-23 23:35:49 [INFO]: Epoch 119 - training loss: 22748.2879, validation loss: 0.4752
2024-05-23 23:35:50 [INFO]: Epoch 120 - training loss: 22747.7172, validation loss: 0.4766
2024-05-23 23:35:50 [INFO]: Epoch 121 - training loss: 22748.1299, validation loss: 0.4760
2024-05-23 23:35:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:35:50 [INFO]: Finished training. The best model is from epoch#111.
2024-05-23 23:35:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_physionet_2012_seta/20240523_T233428/GPVAE.pypots
2024-05-23 23:35:50 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4225, MSE=0.4921
2024-05-23 23:35:51 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-23 23:35:51 [INFO]: Using the given device: cuda:0
2024-05-23 23:35:51 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T233551
2024-05-23 23:35:51 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T233551/tensorboard
2024-05-23 23:35:51 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-23 23:36:14 [INFO]: Epoch 001 - generator training loss: 0.5861, discriminator training loss: 0.3834, validation loss: 0.6128
2024-05-23 23:36:33 [INFO]: Epoch 002 - generator training loss: 0.4837, discriminator training loss: 0.2712, validation loss: 0.5264
2024-05-23 23:36:52 [INFO]: Epoch 003 - generator training loss: 0.4407, discriminator training loss: 0.2364, validation loss: 0.4993
2024-05-23 23:37:11 [INFO]: Epoch 004 - generator training loss: 0.4503, discriminator training loss: 0.1896, validation loss: 0.4938
2024-05-23 23:37:30 [INFO]: Epoch 005 - generator training loss: 0.4451, discriminator training loss: 0.1588, validation loss: 0.4834
2024-05-23 23:37:48 [INFO]: Epoch 006 - generator training loss: 0.4362, discriminator training loss: 0.1402, validation loss: 0.4642
2024-05-23 23:38:07 [INFO]: Epoch 007 - generator training loss: 0.4224, discriminator training loss: 0.1262, validation loss: 0.4530
2024-05-23 23:38:26 [INFO]: Epoch 008 - generator training loss: 0.4097, discriminator training loss: 0.1162, validation loss: 0.4423
2024-05-23 23:38:45 [INFO]: Epoch 009 - generator training loss: 0.4010, discriminator training loss: 0.1075, validation loss: 0.4306
2024-05-23 23:39:03 [INFO]: Epoch 010 - generator training loss: 0.3900, discriminator training loss: 0.1006, validation loss: 0.4212
2024-05-23 23:39:22 [INFO]: Epoch 011 - generator training loss: 0.3891, discriminator training loss: 0.0944, validation loss: 0.4175
2024-05-23 23:39:41 [INFO]: Epoch 012 - generator training loss: 0.3782, discriminator training loss: 0.0892, validation loss: 0.4106
2024-05-23 23:39:59 [INFO]: Epoch 013 - generator training loss: 0.3739, discriminator training loss: 0.0846, validation loss: 0.4016
2024-05-23 23:40:18 [INFO]: Epoch 014 - generator training loss: 0.3640, discriminator training loss: 0.0806, validation loss: 0.3955
2024-05-23 23:40:37 [INFO]: Epoch 015 - generator training loss: 0.3598, discriminator training loss: 0.0771, validation loss: 0.3905
2024-05-23 23:40:56 [INFO]: Epoch 016 - generator training loss: 0.3558, discriminator training loss: 0.0738, validation loss: 0.3835
2024-05-23 23:41:15 [INFO]: Epoch 017 - generator training loss: 0.3490, discriminator training loss: 0.0711, validation loss: 0.3783
2024-05-23 23:41:33 [INFO]: Epoch 018 - generator training loss: 0.3448, discriminator training loss: 0.0684, validation loss: 0.3749
2024-05-23 23:41:52 [INFO]: Epoch 019 - generator training loss: 0.3397, discriminator training loss: 0.0662, validation loss: 0.3672
2024-05-23 23:42:11 [INFO]: Epoch 020 - generator training loss: 0.3346, discriminator training loss: 0.0639, validation loss: 0.3668
2024-05-23 23:42:29 [INFO]: Epoch 021 - generator training loss: 0.3328, discriminator training loss: 0.0622, validation loss: 0.3615
2024-05-23 23:42:48 [INFO]: Epoch 022 - generator training loss: 0.3271, discriminator training loss: 0.0604, validation loss: 0.3590
2024-05-23 23:43:07 [INFO]: Epoch 023 - generator training loss: 0.3222, discriminator training loss: 0.0589, validation loss: 0.3523
2024-05-23 23:43:26 [INFO]: Epoch 024 - generator training loss: 0.3193, discriminator training loss: 0.0573, validation loss: 0.3499
2024-05-23 23:43:45 [INFO]: Epoch 025 - generator training loss: 0.3126, discriminator training loss: 0.0559, validation loss: 0.3489
2024-05-23 23:44:03 [INFO]: Epoch 026 - generator training loss: 0.3113, discriminator training loss: 0.0548, validation loss: 0.3476
2024-05-23 23:44:22 [INFO]: Epoch 027 - generator training loss: 0.3083, discriminator training loss: 0.0538, validation loss: 0.3430
2024-05-23 23:44:41 [INFO]: Epoch 028 - generator training loss: 0.3031, discriminator training loss: 0.0527, validation loss: 0.3373
2024-05-23 23:45:00 [INFO]: Epoch 029 - generator training loss: 0.3052, discriminator training loss: 0.0522, validation loss: 0.3498
2024-05-23 23:45:19 [INFO]: Epoch 030 - generator training loss: 0.3002, discriminator training loss: 0.0514, validation loss: 0.3370
2024-05-23 23:45:39 [INFO]: Epoch 031 - generator training loss: 0.2925, discriminator training loss: 0.0506, validation loss: 0.3264
2024-05-23 23:45:58 [INFO]: Epoch 032 - generator training loss: 0.2892, discriminator training loss: 0.0499, validation loss: 0.3264
2024-05-23 23:46:18 [INFO]: Epoch 033 - generator training loss: 0.2860, discriminator training loss: 0.0494, validation loss: 0.3230
2024-05-23 23:46:37 [INFO]: Epoch 034 - generator training loss: 0.2825, discriminator training loss: 0.0487, validation loss: 0.3212
2024-05-23 23:46:56 [INFO]: Epoch 035 - generator training loss: 0.2867, discriminator training loss: 0.0483, validation loss: 0.3211
2024-05-23 23:47:15 [INFO]: Epoch 036 - generator training loss: 0.2776, discriminator training loss: 0.0479, validation loss: 0.3221
2024-05-23 23:47:34 [INFO]: Epoch 037 - generator training loss: 0.2713, discriminator training loss: 0.0474, validation loss: 0.3137
2024-05-23 23:47:53 [INFO]: Epoch 038 - generator training loss: 0.2674, discriminator training loss: 0.0472, validation loss: 0.3105
2024-05-23 23:48:12 [INFO]: Epoch 039 - generator training loss: 0.2675, discriminator training loss: 0.0467, validation loss: 0.3112
2024-05-23 23:48:30 [INFO]: Epoch 040 - generator training loss: 0.2637, discriminator training loss: 0.0465, validation loss: 0.3137
2024-05-23 23:48:49 [INFO]: Epoch 041 - generator training loss: 0.2615, discriminator training loss: 0.0462, validation loss: 0.3109
2024-05-23 23:49:08 [INFO]: Epoch 042 - generator training loss: 0.2573, discriminator training loss: 0.0460, validation loss: 0.3146
2024-05-23 23:49:27 [INFO]: Epoch 043 - generator training loss: 0.2603, discriminator training loss: 0.0457, validation loss: 0.3193
2024-05-23 23:49:46 [INFO]: Epoch 044 - generator training loss: 0.2652, discriminator training loss: 0.0456, validation loss: 0.3139
2024-05-23 23:50:05 [INFO]: Epoch 045 - generator training loss: 0.2594, discriminator training loss: 0.0454, validation loss: 0.3060
2024-05-23 23:50:23 [INFO]: Epoch 046 - generator training loss: 0.2528, discriminator training loss: 0.0451, validation loss: 0.3069
2024-05-23 23:50:42 [INFO]: Epoch 047 - generator training loss: 0.2563, discriminator training loss: 0.0449, validation loss: 0.3130
2024-05-23 23:51:01 [INFO]: Epoch 048 - generator training loss: 0.2495, discriminator training loss: 0.0446, validation loss: 0.3055
2024-05-23 23:51:20 [INFO]: Epoch 049 - generator training loss: 0.2433, discriminator training loss: 0.0446, validation loss: 0.3082
2024-05-23 23:51:39 [INFO]: Epoch 050 - generator training loss: 0.2415, discriminator training loss: 0.0445, validation loss: 0.3012
2024-05-23 23:51:58 [INFO]: Epoch 051 - generator training loss: 0.2380, discriminator training loss: 0.0443, validation loss: 0.3054
2024-05-23 23:52:16 [INFO]: Epoch 052 - generator training loss: 0.2368, discriminator training loss: 0.0442, validation loss: 0.3028
2024-05-23 23:52:35 [INFO]: Epoch 053 - generator training loss: 0.2361, discriminator training loss: 0.0439, validation loss: 0.3036
2024-05-23 23:52:54 [INFO]: Epoch 054 - generator training loss: 0.2365, discriminator training loss: 0.0439, validation loss: 0.3075
2024-05-23 23:53:13 [INFO]: Epoch 055 - generator training loss: 0.2332, discriminator training loss: 0.0438, validation loss: 0.3077
2024-05-23 23:53:31 [INFO]: Epoch 056 - generator training loss: 0.2299, discriminator training loss: 0.0437, validation loss: 0.3003
2024-05-23 23:53:50 [INFO]: Epoch 057 - generator training loss: 0.2409, discriminator training loss: 0.0435, validation loss: 0.3150
2024-05-23 23:54:09 [INFO]: Epoch 058 - generator training loss: 0.2398, discriminator training loss: 0.0435, validation loss: 0.3055
2024-05-23 23:54:28 [INFO]: Epoch 059 - generator training loss: 0.2305, discriminator training loss: 0.0433, validation loss: 0.3033
2024-05-23 23:54:47 [INFO]: Epoch 060 - generator training loss: 0.2248, discriminator training loss: 0.0431, validation loss: 0.3032
2024-05-23 23:55:05 [INFO]: Epoch 061 - generator training loss: 0.2231, discriminator training loss: 0.0430, validation loss: 0.3045
2024-05-23 23:55:24 [INFO]: Epoch 062 - generator training loss: 0.2222, discriminator training loss: 0.0426, validation loss: 0.3028
2024-05-23 23:55:43 [INFO]: Epoch 063 - generator training loss: 0.2270, discriminator training loss: 0.0426, validation loss: 0.3055
2024-05-23 23:56:02 [INFO]: Epoch 064 - generator training loss: 0.2208, discriminator training loss: 0.0425, validation loss: 0.3034
2024-05-23 23:56:21 [INFO]: Epoch 065 - generator training loss: 0.2150, discriminator training loss: 0.0424, validation loss: 0.3044
2024-05-23 23:56:40 [INFO]: Epoch 066 - generator training loss: 0.2117, discriminator training loss: 0.0424, validation loss: 0.3030
2024-05-23 23:56:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 23:56:40 [INFO]: Finished training. The best model is from epoch#56.
2024-05-23 23:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_physionet_2012_seta/20240523_T233551/USGAN.pypots
2024-05-23 23:56:42 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2967, MSE=0.2881
2024-05-23 23:56:52 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_physionet_2012_seta/imputation.pkl
2024-05-23 23:56:52 [INFO]: Using the given device: cuda:0
2024-05-23 23:56:52 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T235652
2024-05-23 23:56:52 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T235652/tensorboard
2024-05-23 23:56:52 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-23 23:57:07 [INFO]: Epoch 001 - training loss: 1.1413, validation loss: 0.5245
2024-05-23 23:57:20 [INFO]: Epoch 002 - training loss: 0.9295, validation loss: 0.4681
2024-05-23 23:57:32 [INFO]: Epoch 003 - training loss: 0.8671, validation loss: 0.4417
2024-05-23 23:57:44 [INFO]: Epoch 004 - training loss: 0.8314, validation loss: 0.4212
2024-05-23 23:57:57 [INFO]: Epoch 005 - training loss: 0.8049, validation loss: 0.4048
2024-05-23 23:58:09 [INFO]: Epoch 006 - training loss: 0.7802, validation loss: 0.3885
2024-05-23 23:58:21 [INFO]: Epoch 007 - training loss: 0.7619, validation loss: 0.3779
2024-05-23 23:58:34 [INFO]: Epoch 008 - training loss: 0.7453, validation loss: 0.3678
2024-05-23 23:58:46 [INFO]: Epoch 009 - training loss: 0.7307, validation loss: 0.3614
2024-05-23 23:58:58 [INFO]: Epoch 010 - training loss: 0.7191, validation loss: 0.3535
2024-05-23 23:59:10 [INFO]: Epoch 011 - training loss: 0.7094, validation loss: 0.3481
2024-05-23 23:59:23 [INFO]: Epoch 012 - training loss: 0.7004, validation loss: 0.3470
2024-05-23 23:59:35 [INFO]: Epoch 013 - training loss: 0.6928, validation loss: 0.3457
2024-05-23 23:59:48 [INFO]: Epoch 014 - training loss: 0.6870, validation loss: 0.3427
2024-05-24 00:00:00 [INFO]: Epoch 015 - training loss: 0.6803, validation loss: 0.3404
2024-05-24 00:00:12 [INFO]: Epoch 016 - training loss: 0.6755, validation loss: 0.3380
2024-05-24 00:00:25 [INFO]: Epoch 017 - training loss: 0.6701, validation loss: 0.3386
2024-05-24 00:00:37 [INFO]: Epoch 018 - training loss: 0.6667, validation loss: 0.3352
2024-05-24 00:00:49 [INFO]: Epoch 019 - training loss: 0.6627, validation loss: 0.3360
2024-05-24 00:01:02 [INFO]: Epoch 020 - training loss: 0.6596, validation loss: 0.3357
2024-05-24 00:01:14 [INFO]: Epoch 021 - training loss: 0.6553, validation loss: 0.3331
2024-05-24 00:01:26 [INFO]: Epoch 022 - training loss: 0.6515, validation loss: 0.3336
2024-05-24 00:01:38 [INFO]: Epoch 023 - training loss: 0.6491, validation loss: 0.3343
2024-05-24 00:01:51 [INFO]: Epoch 024 - training loss: 0.6469, validation loss: 0.3330
2024-05-24 00:02:03 [INFO]: Epoch 025 - training loss: 0.6427, validation loss: 0.3323
2024-05-24 00:02:16 [INFO]: Epoch 026 - training loss: 0.6397, validation loss: 0.3311
2024-05-24 00:02:28 [INFO]: Epoch 027 - training loss: 0.6362, validation loss: 0.3320
2024-05-24 00:02:40 [INFO]: Epoch 028 - training loss: 0.6338, validation loss: 0.3312
2024-05-24 00:02:52 [INFO]: Epoch 029 - training loss: 0.6303, validation loss: 0.3309
2024-05-24 00:03:05 [INFO]: Epoch 030 - training loss: 0.6275, validation loss: 0.3313
2024-05-24 00:03:17 [INFO]: Epoch 031 - training loss: 0.6256, validation loss: 0.3280
2024-05-24 00:03:29 [INFO]: Epoch 032 - training loss: 0.6230, validation loss: 0.3298
2024-05-24 00:03:42 [INFO]: Epoch 033 - training loss: 0.6202, validation loss: 0.3289
2024-05-24 00:03:54 [INFO]: Epoch 034 - training loss: 0.6189, validation loss: 0.3328
2024-05-24 00:04:07 [INFO]: Epoch 035 - training loss: 0.6157, validation loss: 0.3301
2024-05-24 00:04:19 [INFO]: Epoch 036 - training loss: 0.6145, validation loss: 0.3328
2024-05-24 00:04:31 [INFO]: Epoch 037 - training loss: 0.6200, validation loss: 0.3323
2024-05-24 00:04:44 [INFO]: Epoch 038 - training loss: 0.6151, validation loss: 0.3320
2024-05-24 00:04:56 [INFO]: Epoch 039 - training loss: 0.6138, validation loss: 0.3367
2024-05-24 00:05:08 [INFO]: Epoch 040 - training loss: 0.6128, validation loss: 0.3358
2024-05-24 00:05:21 [INFO]: Epoch 041 - training loss: 0.6058, validation loss: 0.3345
2024-05-24 00:05:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:05:21 [INFO]: Finished training. The best model is from epoch#31.
2024-05-24 00:05:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_physionet_2012_seta/20240523_T235652/BRITS.pypots
2024-05-24 00:05:23 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2618, MSE=0.2881
2024-05-24 00:05:33 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 00:05:33 [INFO]: Using the given device: cuda:0
2024-05-24 00:05:33 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533
2024-05-24 00:05:33 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/tensorboard
2024-05-24 00:05:33 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 00:05:38 [INFO]: Epoch 001 - training loss: 1.1617, validation loss: 1.0041
2024-05-24 00:05:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch1_loss1.00409115254879.pypots
2024-05-24 00:05:41 [INFO]: Epoch 002 - training loss: 0.7124, validation loss: 0.9784
2024-05-24 00:05:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch2_loss0.978370863199234.pypots
2024-05-24 00:05:44 [INFO]: Epoch 003 - training loss: 0.5929, validation loss: 0.9508
2024-05-24 00:05:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch3_loss0.9507534950971603.pypots
2024-05-24 00:05:47 [INFO]: Epoch 004 - training loss: 0.5605, validation loss: 0.9348
2024-05-24 00:05:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch4_loss0.9347739785909652.pypots
2024-05-24 00:05:50 [INFO]: Epoch 005 - training loss: 0.5244, validation loss: 0.9257
2024-05-24 00:05:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch5_loss0.9256513059139252.pypots
2024-05-24 00:05:53 [INFO]: Epoch 006 - training loss: 0.5199, validation loss: 0.9212
2024-05-24 00:05:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch6_loss0.9212072402238846.pypots
2024-05-24 00:05:56 [INFO]: Epoch 007 - training loss: 0.5045, validation loss: 0.9174
2024-05-24 00:05:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch7_loss0.9174135118722916.pypots
2024-05-24 00:05:58 [INFO]: Epoch 008 - training loss: 0.4964, validation loss: 0.9156
2024-05-24 00:05:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch8_loss0.915564888715744.pypots
2024-05-24 00:06:01 [INFO]: Epoch 009 - training loss: 0.4956, validation loss: 0.9150
2024-05-24 00:06:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch9_loss0.9150026619434357.pypots
2024-05-24 00:06:04 [INFO]: Epoch 010 - training loss: 0.4774, validation loss: 0.9153
2024-05-24 00:06:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch10_loss0.9152736663818359.pypots
2024-05-24 00:06:07 [INFO]: Epoch 011 - training loss: 0.4785, validation loss: 0.9159
2024-05-24 00:06:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch11_loss0.9159434586763382.pypots
2024-05-24 00:06:10 [INFO]: Epoch 012 - training loss: 0.4715, validation loss: 0.9182
2024-05-24 00:06:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch12_loss0.9181540668010711.pypots
2024-05-24 00:06:13 [INFO]: Epoch 013 - training loss: 0.4664, validation loss: 0.9211
2024-05-24 00:06:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch13_loss0.9211259961128235.pypots
2024-05-24 00:06:15 [INFO]: Epoch 014 - training loss: 0.4622, validation loss: 0.9226
2024-05-24 00:06:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch14_loss0.9226144343614578.pypots
2024-05-24 00:06:18 [INFO]: Epoch 015 - training loss: 0.4553, validation loss: 0.9250
2024-05-24 00:06:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch15_loss0.9250330775976181.pypots
2024-05-24 00:06:21 [INFO]: Epoch 016 - training loss: 0.4494, validation loss: 0.9272
2024-05-24 00:06:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch16_loss0.927226448059082.pypots
2024-05-24 00:06:24 [INFO]: Epoch 017 - training loss: 0.4532, validation loss: 0.9294
2024-05-24 00:06:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch17_loss0.9293798953294754.pypots
2024-05-24 00:06:27 [INFO]: Epoch 018 - training loss: 0.4438, validation loss: 0.9305
2024-05-24 00:06:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch18_loss0.9304551392793655.pypots
2024-05-24 00:06:30 [INFO]: Epoch 019 - training loss: 0.4444, validation loss: 0.9320
2024-05-24 00:06:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN_epoch19_loss0.9319905340671539.pypots
2024-05-24 00:06:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:06:30 [INFO]: Finished training. The best model is from epoch#9.
2024-05-24 00:06:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/20240524_T000533/MRNN.pypots
2024-05-24 00:06:31 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6858, MSE=0.9282
2024-05-24 00:06:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 00:06:35 [INFO]: Using the given device: cpu
2024-05-24 00:06:35 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4083, MSE=0.5397
2024-05-24 00:06:35 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_physionet_2012_seta".
2024-05-24 00:06:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 00:06:35 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6856, MSE=1.0305
2024-05-24 00:06:35 [INFO]: Successfully created the given path "saved_results/round_2/Median_physionet_2012_seta".
2024-05-24 00:06:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_physionet_2012_seta/imputation.pkl
2024-05-24 00:06:35 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7023, MSE=1.0007
2024-05-24 00:06:35 [INFO]: Successfully created the given path "saved_results/round_2/Mean_physionet_2012_seta".
2024-05-24 00:06:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 00:06:35 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-24 00:06:35 [INFO]: Using the given device: cuda:0
2024-05-24 00:06:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T000635
2024-05-24 00:06:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T000635/tensorboard
2024-05-24 00:06:35 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-24 00:06:36 [INFO]: Epoch 001 - training loss: 1.1000, validation loss: 0.4863
2024-05-24 00:06:38 [INFO]: Epoch 002 - training loss: 0.7383, validation loss: 0.4145
2024-05-24 00:06:39 [INFO]: Epoch 003 - training loss: 0.5882, validation loss: 0.4032
2024-05-24 00:06:40 [INFO]: Epoch 004 - training loss: 0.5209, validation loss: 0.3655
2024-05-24 00:06:41 [INFO]: Epoch 005 - training loss: 0.4838, validation loss: 0.3638
2024-05-24 00:06:42 [INFO]: Epoch 006 - training loss: 0.4433, validation loss: 0.3463
2024-05-24 00:06:43 [INFO]: Epoch 007 - training loss: 0.4131, validation loss: 0.3392
2024-05-24 00:06:45 [INFO]: Epoch 008 - training loss: 0.3898, validation loss: 0.3318
2024-05-24 00:06:46 [INFO]: Epoch 009 - training loss: 0.3706, validation loss: 0.3242
2024-05-24 00:06:47 [INFO]: Epoch 010 - training loss: 0.3493, validation loss: 0.3226
2024-05-24 00:06:48 [INFO]: Epoch 011 - training loss: 0.3386, validation loss: 0.3143
2024-05-24 00:06:49 [INFO]: Epoch 012 - training loss: 0.3181, validation loss: 0.3133
2024-05-24 00:06:50 [INFO]: Epoch 013 - training loss: 0.3101, validation loss: 0.3120
2024-05-24 00:06:52 [INFO]: Epoch 014 - training loss: 0.2956, validation loss: 0.3069
2024-05-24 00:06:53 [INFO]: Epoch 015 - training loss: 0.2796, validation loss: 0.3026
2024-05-24 00:06:54 [INFO]: Epoch 016 - training loss: 0.2745, validation loss: 0.3000
2024-05-24 00:06:55 [INFO]: Epoch 017 - training loss: 0.2616, validation loss: 0.3005
2024-05-24 00:06:56 [INFO]: Epoch 018 - training loss: 0.2626, validation loss: 0.3034
2024-05-24 00:06:57 [INFO]: Epoch 019 - training loss: 0.2488, validation loss: 0.2987
2024-05-24 00:06:59 [INFO]: Epoch 020 - training loss: 0.2397, validation loss: 0.2962
2024-05-24 00:07:00 [INFO]: Epoch 021 - training loss: 0.2335, validation loss: 0.2917
2024-05-24 00:07:01 [INFO]: Epoch 022 - training loss: 0.2286, validation loss: 0.2952
2024-05-24 00:07:02 [INFO]: Epoch 023 - training loss: 0.2259, validation loss: 0.2990
2024-05-24 00:07:03 [INFO]: Epoch 024 - training loss: 0.2201, validation loss: 0.2967
2024-05-24 00:07:04 [INFO]: Epoch 025 - training loss: 0.2128, validation loss: 0.2953
2024-05-24 00:07:06 [INFO]: Epoch 026 - training loss: 0.2085, validation loss: 0.2960
2024-05-24 00:07:07 [INFO]: Epoch 027 - training loss: 0.2041, validation loss: 0.2962
2024-05-24 00:07:08 [INFO]: Epoch 028 - training loss: 0.1988, validation loss: 0.2935
2024-05-24 00:07:09 [INFO]: Epoch 029 - training loss: 0.1968, validation loss: 0.2950
2024-05-24 00:07:10 [INFO]: Epoch 030 - training loss: 0.1911, validation loss: 0.3003
2024-05-24 00:07:11 [INFO]: Epoch 031 - training loss: 0.1891, validation loss: 0.2936
2024-05-24 00:07:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:07:11 [INFO]: Finished training. The best model is from epoch#21.
2024-05-24 00:07:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_physionet_2012_seta/20240524_T000635/SAITS.pypots
2024-05-24 00:07:12 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2818, MSE=0.3366
2024-05-24 00:07:12 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_physionet_2012_seta/imputation.pkl
2024-05-24 00:07:12 [INFO]: Using the given device: cuda:0
2024-05-24 00:07:12 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T000712
2024-05-24 00:07:12 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T000712/tensorboard
2024-05-24 00:07:12 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-24 00:07:13 [INFO]: Epoch 001 - training loss: 1.1904, validation loss: 0.5738
2024-05-24 00:07:13 [INFO]: Epoch 002 - training loss: 0.7429, validation loss: 0.4654
2024-05-24 00:07:14 [INFO]: Epoch 003 - training loss: 0.6272, validation loss: 0.4423
2024-05-24 00:07:14 [INFO]: Epoch 004 - training loss: 0.5825, validation loss: 0.4235
2024-05-24 00:07:15 [INFO]: Epoch 005 - training loss: 0.5461, validation loss: 0.4037
2024-05-24 00:07:16 [INFO]: Epoch 006 - training loss: 0.5011, validation loss: 0.3925
2024-05-24 00:07:16 [INFO]: Epoch 007 - training loss: 0.4739, validation loss: 0.3844
2024-05-24 00:07:17 [INFO]: Epoch 008 - training loss: 0.4525, validation loss: 0.3682
2024-05-24 00:07:17 [INFO]: Epoch 009 - training loss: 0.4376, validation loss: 0.3659
2024-05-24 00:07:18 [INFO]: Epoch 010 - training loss: 0.4214, validation loss: 0.3573
2024-05-24 00:07:19 [INFO]: Epoch 011 - training loss: 0.4030, validation loss: 0.3489
2024-05-24 00:07:19 [INFO]: Epoch 012 - training loss: 0.3942, validation loss: 0.3434
2024-05-24 00:07:20 [INFO]: Epoch 013 - training loss: 0.3832, validation loss: 0.3415
2024-05-24 00:07:20 [INFO]: Epoch 014 - training loss: 0.3661, validation loss: 0.3398
2024-05-24 00:07:21 [INFO]: Epoch 015 - training loss: 0.3578, validation loss: 0.3326
2024-05-24 00:07:22 [INFO]: Epoch 016 - training loss: 0.3520, validation loss: 0.3382
2024-05-24 00:07:22 [INFO]: Epoch 017 - training loss: 0.3460, validation loss: 0.3303
2024-05-24 00:07:23 [INFO]: Epoch 018 - training loss: 0.3309, validation loss: 0.3288
2024-05-24 00:07:23 [INFO]: Epoch 019 - training loss: 0.3222, validation loss: 0.3228
2024-05-24 00:07:24 [INFO]: Epoch 020 - training loss: 0.3208, validation loss: 0.3257
2024-05-24 00:07:25 [INFO]: Epoch 021 - training loss: 0.3086, validation loss: 0.3239
2024-05-24 00:07:25 [INFO]: Epoch 022 - training loss: 0.3070, validation loss: 0.3271
2024-05-24 00:07:26 [INFO]: Epoch 023 - training loss: 0.2999, validation loss: 0.3181
2024-05-24 00:07:26 [INFO]: Epoch 024 - training loss: 0.2985, validation loss: 0.3210
2024-05-24 00:07:27 [INFO]: Epoch 025 - training loss: 0.2904, validation loss: 0.3225
2024-05-24 00:07:28 [INFO]: Epoch 026 - training loss: 0.2889, validation loss: 0.3201
2024-05-24 00:07:28 [INFO]: Epoch 027 - training loss: 0.2797, validation loss: 0.3238
2024-05-24 00:07:29 [INFO]: Epoch 028 - training loss: 0.2732, validation loss: 0.3166
2024-05-24 00:07:29 [INFO]: Epoch 029 - training loss: 0.2760, validation loss: 0.3209
2024-05-24 00:07:30 [INFO]: Epoch 030 - training loss: 0.2667, validation loss: 0.3118
2024-05-24 00:07:31 [INFO]: Epoch 031 - training loss: 0.2609, validation loss: 0.3156
2024-05-24 00:07:31 [INFO]: Epoch 032 - training loss: 0.2589, validation loss: 0.3154
2024-05-24 00:07:32 [INFO]: Epoch 033 - training loss: 0.2550, validation loss: 0.3198
2024-05-24 00:07:32 [INFO]: Epoch 034 - training loss: 0.2525, validation loss: 0.3177
2024-05-24 00:07:33 [INFO]: Epoch 035 - training loss: 0.2445, validation loss: 0.3171
2024-05-24 00:07:34 [INFO]: Epoch 036 - training loss: 0.2438, validation loss: 0.3155
2024-05-24 00:07:34 [INFO]: Epoch 037 - training loss: 0.2397, validation loss: 0.3152
2024-05-24 00:07:35 [INFO]: Epoch 038 - training loss: 0.2344, validation loss: 0.3157
2024-05-24 00:07:35 [INFO]: Epoch 039 - training loss: 0.2359, validation loss: 0.3150
2024-05-24 00:07:36 [INFO]: Epoch 040 - training loss: 0.2290, validation loss: 0.3175
2024-05-24 00:07:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:07:36 [INFO]: Finished training. The best model is from epoch#30.
2024-05-24 00:07:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_physionet_2012_seta/20240524_T000712/Transformer.pypots
2024-05-24 00:07:36 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2884, MSE=0.3396
2024-05-24 00:07:36 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_physionet_2012_seta/imputation.pkl
2024-05-24 00:07:36 [INFO]: Using the given device: cuda:0
2024-05-24 00:07:36 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T000736
2024-05-24 00:07:36 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T000736/tensorboard
2024-05-24 00:07:36 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-24 00:07:37 [INFO]: Epoch 001 - training loss: 0.4470, validation loss: 0.3704
2024-05-24 00:07:38 [INFO]: Epoch 002 - training loss: 0.5383, validation loss: 0.3388
2024-05-24 00:07:39 [INFO]: Epoch 003 - training loss: 0.4925, validation loss: 0.3394
2024-05-24 00:07:39 [INFO]: Epoch 004 - training loss: 0.3709, validation loss: 0.3307
2024-05-24 00:07:40 [INFO]: Epoch 005 - training loss: 0.3111, validation loss: 0.3068
2024-05-24 00:07:41 [INFO]: Epoch 006 - training loss: 0.2989, validation loss: 0.2976
2024-05-24 00:07:41 [INFO]: Epoch 007 - training loss: 0.2858, validation loss: 0.3163
2024-05-24 00:07:42 [INFO]: Epoch 008 - training loss: 0.2713, validation loss: 0.2944
2024-05-24 00:07:43 [INFO]: Epoch 009 - training loss: 0.2638, validation loss: 0.2947
2024-05-24 00:07:44 [INFO]: Epoch 010 - training loss: 0.2720, validation loss: 0.2946
2024-05-24 00:07:44 [INFO]: Epoch 011 - training loss: 0.2574, validation loss: 0.2924
2024-05-24 00:07:45 [INFO]: Epoch 012 - training loss: 0.2553, validation loss: 0.3163
2024-05-24 00:07:46 [INFO]: Epoch 013 - training loss: 0.2625, validation loss: 0.2944
2024-05-24 00:07:46 [INFO]: Epoch 014 - training loss: 0.2468, validation loss: 0.2910
2024-05-24 00:07:47 [INFO]: Epoch 015 - training loss: 0.2362, validation loss: 0.3043
2024-05-24 00:07:48 [INFO]: Epoch 016 - training loss: 0.2353, validation loss: 0.2907
2024-05-24 00:07:49 [INFO]: Epoch 017 - training loss: 0.2305, validation loss: 0.2936
2024-05-24 00:07:49 [INFO]: Epoch 018 - training loss: 0.2229, validation loss: 0.3111
2024-05-24 00:07:50 [INFO]: Epoch 019 - training loss: 0.2234, validation loss: 0.2905
2024-05-24 00:07:51 [INFO]: Epoch 020 - training loss: 0.2194, validation loss: 0.3022
2024-05-24 00:07:51 [INFO]: Epoch 021 - training loss: 0.2331, validation loss: 0.2999
2024-05-24 00:07:52 [INFO]: Epoch 022 - training loss: 0.2204, validation loss: 0.2986
2024-05-24 00:07:53 [INFO]: Epoch 023 - training loss: 0.2363, validation loss: 0.2989
2024-05-24 00:07:53 [INFO]: Epoch 024 - training loss: 0.2105, validation loss: 0.3024
2024-05-24 00:07:54 [INFO]: Epoch 025 - training loss: 0.2055, validation loss: 0.3073
2024-05-24 00:07:55 [INFO]: Epoch 026 - training loss: 0.2107, validation loss: 0.3026
2024-05-24 00:07:56 [INFO]: Epoch 027 - training loss: 0.1909, validation loss: 0.3014
2024-05-24 00:07:56 [INFO]: Epoch 028 - training loss: 0.1891, validation loss: 0.2977
2024-05-24 00:07:57 [INFO]: Epoch 029 - training loss: 0.1880, validation loss: 0.3078
2024-05-24 00:07:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:07:57 [INFO]: Finished training. The best model is from epoch#19.
2024-05-24 00:07:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_physionet_2012_seta/20240524_T000736/TimesNet.pypots
2024-05-24 00:07:57 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2935, MSE=0.2891
2024-05-24 00:07:57 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-24 00:07:57 [INFO]: Using the given device: cuda:0
2024-05-24 00:07:57 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757
2024-05-24 00:07:57 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/tensorboard
2024-05-24 00:07:57 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-24 00:08:41 [INFO]: Epoch 001 - training loss: 0.4301, validation loss: 0.3357
2024-05-24 00:08:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch1_loss0.33568947166204455.pypots
2024-05-24 00:09:25 [INFO]: Epoch 002 - training loss: 0.3176, validation loss: 0.3026
2024-05-24 00:09:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch2_loss0.3026045635342598.pypots
2024-05-24 00:10:09 [INFO]: Epoch 003 - training loss: 0.2882, validation loss: 0.2675
2024-05-24 00:10:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch3_loss0.26749666929245.pypots
2024-05-24 00:10:53 [INFO]: Epoch 004 - training loss: 0.2810, validation loss: 0.2485
2024-05-24 00:10:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch4_loss0.2485348403453827.pypots
2024-05-24 00:11:36 [INFO]: Epoch 005 - training loss: 0.2557, validation loss: 0.2400
2024-05-24 00:11:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch5_loss0.24001890644431115.pypots
2024-05-24 00:12:20 [INFO]: Epoch 006 - training loss: 0.2485, validation loss: 0.2306
2024-05-24 00:12:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch6_loss0.23062652200460435.pypots
2024-05-24 00:13:04 [INFO]: Epoch 007 - training loss: 0.2427, validation loss: 0.2261
2024-05-24 00:13:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch7_loss0.22608169466257094.pypots
2024-05-24 00:13:48 [INFO]: Epoch 008 - training loss: 0.2517, validation loss: 0.2221
2024-05-24 00:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch8_loss0.22208481207489966.pypots
2024-05-24 00:14:32 [INFO]: Epoch 009 - training loss: 0.2301, validation loss: 0.2196
2024-05-24 00:14:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch9_loss0.219620930403471.pypots
2024-05-24 00:15:16 [INFO]: Epoch 010 - training loss: 0.2226, validation loss: 0.2152
2024-05-24 00:15:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch10_loss0.2152318112552166.pypots
2024-05-24 00:16:00 [INFO]: Epoch 011 - training loss: 0.2280, validation loss: 0.2159
2024-05-24 00:16:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch11_loss0.21590107232332229.pypots
2024-05-24 00:16:44 [INFO]: Epoch 012 - training loss: 0.2210, validation loss: 0.2172
2024-05-24 00:16:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch12_loss0.21721169129014015.pypots
2024-05-24 00:17:28 [INFO]: Epoch 013 - training loss: 0.2286, validation loss: 0.2075
2024-05-24 00:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch13_loss0.2074793718755245.pypots
2024-05-24 00:18:12 [INFO]: Epoch 014 - training loss: 0.2111, validation loss: 0.2019
2024-05-24 00:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch14_loss0.20190216600894928.pypots
2024-05-24 00:18:56 [INFO]: Epoch 015 - training loss: 0.2102, validation loss: 0.2027
2024-05-24 00:18:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch15_loss0.2027418926358223.pypots
2024-05-24 00:19:40 [INFO]: Epoch 016 - training loss: 0.2162, validation loss: 0.2029
2024-05-24 00:19:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch16_loss0.20289067402482033.pypots
2024-05-24 00:20:24 [INFO]: Epoch 017 - training loss: 0.2187, validation loss: 0.2047
2024-05-24 00:20:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch17_loss0.2047298550605774.pypots
2024-05-24 00:21:08 [INFO]: Epoch 018 - training loss: 0.2126, validation loss: 0.2027
2024-05-24 00:21:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch18_loss0.20271771401166916.pypots
2024-05-24 00:21:52 [INFO]: Epoch 019 - training loss: 0.2135, validation loss: 0.2002
2024-05-24 00:21:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch19_loss0.20019970014691352.pypots
2024-05-24 00:22:35 [INFO]: Epoch 020 - training loss: 0.2097, validation loss: 0.2019
2024-05-24 00:22:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch20_loss0.20185921117663383.pypots
2024-05-24 00:23:19 [INFO]: Epoch 021 - training loss: 0.2041, validation loss: 0.2002
2024-05-24 00:23:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch21_loss0.2002151280641556.pypots
2024-05-24 00:24:03 [INFO]: Epoch 022 - training loss: 0.2097, validation loss: 0.2041
2024-05-24 00:24:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch22_loss0.20412685349583626.pypots
2024-05-24 00:24:47 [INFO]: Epoch 023 - training loss: 0.2028, validation loss: 0.1971
2024-05-24 00:24:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch23_loss0.19706171452999116.pypots
2024-05-24 00:25:31 [INFO]: Epoch 024 - training loss: 0.2065, validation loss: 0.1995
2024-05-24 00:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch24_loss0.19946638867259026.pypots
2024-05-24 00:26:15 [INFO]: Epoch 025 - training loss: 0.2026, validation loss: 0.2003
2024-05-24 00:26:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch25_loss0.20029879212379456.pypots
2024-05-24 00:26:59 [INFO]: Epoch 026 - training loss: 0.2048, validation loss: 0.1980
2024-05-24 00:26:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch26_loss0.19801485389471055.pypots
2024-05-24 00:27:43 [INFO]: Epoch 027 - training loss: 0.2140, validation loss: 0.1934
2024-05-24 00:27:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch27_loss0.19341935589909554.pypots
2024-05-24 00:28:27 [INFO]: Epoch 028 - training loss: 0.2018, validation loss: 0.1967
2024-05-24 00:28:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch28_loss0.19667321294546128.pypots
2024-05-24 00:29:11 [INFO]: Epoch 029 - training loss: 0.2056, validation loss: 0.1964
2024-05-24 00:29:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch29_loss0.1964182548224926.pypots
2024-05-24 00:29:55 [INFO]: Epoch 030 - training loss: 0.2127, validation loss: 0.1938
2024-05-24 00:29:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch30_loss0.1937737539410591.pypots
2024-05-24 00:30:39 [INFO]: Epoch 031 - training loss: 0.2098, validation loss: 0.1949
2024-05-24 00:30:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch31_loss0.19485630765557288.pypots
2024-05-24 00:31:23 [INFO]: Epoch 032 - training loss: 0.1979, validation loss: 0.1936
2024-05-24 00:31:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch32_loss0.19364055544137954.pypots
2024-05-24 00:32:07 [INFO]: Epoch 033 - training loss: 0.2116, validation loss: 0.2024
2024-05-24 00:32:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch33_loss0.2023962676525116.pypots
2024-05-24 00:32:50 [INFO]: Epoch 034 - training loss: 0.2106, validation loss: 0.1933
2024-05-24 00:32:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch34_loss0.19328262358903886.pypots
2024-05-24 00:33:34 [INFO]: Epoch 035 - training loss: 0.1958, validation loss: 0.1930
2024-05-24 00:33:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch35_loss0.19301887676119805.pypots
2024-05-24 00:34:18 [INFO]: Epoch 036 - training loss: 0.2080, validation loss: 0.1918
2024-05-24 00:34:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch36_loss0.1918201006948948.pypots
2024-05-24 00:35:02 [INFO]: Epoch 037 - training loss: 0.2003, validation loss: 0.1903
2024-05-24 00:35:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch37_loss0.1902846574783325.pypots
2024-05-24 00:35:46 [INFO]: Epoch 038 - training loss: 0.2033, validation loss: 0.1955
2024-05-24 00:35:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch38_loss0.19549607783555983.pypots
2024-05-24 00:36:30 [INFO]: Epoch 039 - training loss: 0.1835, validation loss: 0.1895
2024-05-24 00:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch39_loss0.18946863189339638.pypots
2024-05-24 00:37:14 [INFO]: Epoch 040 - training loss: 0.1965, validation loss: 0.1895
2024-05-24 00:37:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch40_loss0.1895488604903221.pypots
2024-05-24 00:37:58 [INFO]: Epoch 041 - training loss: 0.2051, validation loss: 0.1895
2024-05-24 00:37:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch41_loss0.18946404680609702.pypots
2024-05-24 00:38:42 [INFO]: Epoch 042 - training loss: 0.2052, validation loss: 0.1931
2024-05-24 00:38:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch42_loss0.19308073148131372.pypots
2024-05-24 00:39:25 [INFO]: Epoch 043 - training loss: 0.1968, validation loss: 0.1898
2024-05-24 00:39:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch43_loss0.18975163027644157.pypots
2024-05-24 00:40:09 [INFO]: Epoch 044 - training loss: 0.1989, validation loss: 0.1902
2024-05-24 00:40:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch44_loss0.1901986375451088.pypots
2024-05-24 00:40:53 [INFO]: Epoch 045 - training loss: 0.2118, validation loss: 0.1925
2024-05-24 00:40:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch45_loss0.19251479879021643.pypots
2024-05-24 00:41:37 [INFO]: Epoch 046 - training loss: 0.1958, validation loss: 0.1897
2024-05-24 00:41:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch46_loss0.18970764726400374.pypots
2024-05-24 00:42:21 [INFO]: Epoch 047 - training loss: 0.1947, validation loss: 0.1910
2024-05-24 00:42:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch47_loss0.19097575098276137.pypots
2024-05-24 00:43:05 [INFO]: Epoch 048 - training loss: 0.2009, validation loss: 0.1901
2024-05-24 00:43:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch48_loss0.19006845429539682.pypots
2024-05-24 00:43:49 [INFO]: Epoch 049 - training loss: 0.2033, validation loss: 0.1882
2024-05-24 00:43:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch49_loss0.18818864971399307.pypots
2024-05-24 00:44:33 [INFO]: Epoch 050 - training loss: 0.2038, validation loss: 0.1866
2024-05-24 00:44:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch50_loss0.18663364872336388.pypots
2024-05-24 00:45:17 [INFO]: Epoch 051 - training loss: 0.1972, validation loss: 0.1898
2024-05-24 00:45:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch51_loss0.1897531270980835.pypots
2024-05-24 00:46:01 [INFO]: Epoch 052 - training loss: 0.1961, validation loss: 0.1881
2024-05-24 00:46:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch52_loss0.18807908669114112.pypots
2024-05-24 00:46:45 [INFO]: Epoch 053 - training loss: 0.1979, validation loss: 0.1906
2024-05-24 00:46:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch53_loss0.1906018652021885.pypots
2024-05-24 00:47:29 [INFO]: Epoch 054 - training loss: 0.2031, validation loss: 0.1919
2024-05-24 00:47:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch54_loss0.19187261387705803.pypots
2024-05-24 00:48:13 [INFO]: Epoch 055 - training loss: 0.1930, validation loss: 0.1907
2024-05-24 00:48:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch55_loss0.19068852066993713.pypots
2024-05-24 00:48:57 [INFO]: Epoch 056 - training loss: 0.1962, validation loss: 0.1874
2024-05-24 00:48:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch56_loss0.18741820752620697.pypots
2024-05-24 00:49:41 [INFO]: Epoch 057 - training loss: 0.1835, validation loss: 0.1886
2024-05-24 00:49:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch57_loss0.1886010766029358.pypots
2024-05-24 00:50:25 [INFO]: Epoch 058 - training loss: 0.1996, validation loss: 0.1876
2024-05-24 00:50:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch58_loss0.1876374326646328.pypots
2024-05-24 00:51:09 [INFO]: Epoch 059 - training loss: 0.1904, validation loss: 0.1936
2024-05-24 00:51:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch59_loss0.19357497468590737.pypots
2024-05-24 00:51:53 [INFO]: Epoch 060 - training loss: 0.1987, validation loss: 0.1898
2024-05-24 00:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI_epoch60_loss0.18980126455426216.pypots
2024-05-24 00:51:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 00:51:53 [INFO]: Finished training. The best model is from epoch#50.
2024-05-24 00:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/20240524_T000757/CSDI.pypots
2024-05-24 00:59:15 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2504, MSE=0.4218
2024-05-24 07:30:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 07:34:00 [INFO]: Using the given device: cuda:0
2024-05-24 07:34:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400
2024-05-24 07:34:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400/tensorboard
2024-05-24 07:34:01 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 07:34:03 [INFO]: Epoch 001 - training loss: 43104.0307, validation loss: 0.9198
2024-05-24 07:34:03 [INFO]: Epoch 002 - training loss: 24398.9041, validation loss: 0.7416
2024-05-24 07:34:04 [INFO]: Epoch 003 - training loss: 23469.4941, validation loss: 0.7098
2024-05-24 07:34:05 [INFO]: Epoch 004 - training loss: 23176.7034, validation loss: 0.6642
2024-05-24 07:34:05 [INFO]: Epoch 005 - training loss: 23033.4613, validation loss: 0.6487
2024-05-24 07:34:06 [INFO]: Epoch 006 - training loss: 22954.3864, validation loss: 0.6463
2024-05-24 07:34:07 [INFO]: Epoch 007 - training loss: 22906.1446, validation loss: 0.6494
2024-05-24 07:34:07 [INFO]: Epoch 008 - training loss: 22874.7334, validation loss: 0.6430
2024-05-24 07:34:08 [INFO]: Epoch 009 - training loss: 22853.0618, validation loss: 0.6443
2024-05-24 07:34:09 [INFO]: Epoch 010 - training loss: 22838.5219, validation loss: 0.6469
2024-05-24 07:34:09 [INFO]: Epoch 011 - training loss: 22827.9021, validation loss: 0.6411
2024-05-24 07:34:10 [INFO]: Epoch 012 - training loss: 22819.4092, validation loss: 0.6366
2024-05-24 07:34:11 [INFO]: Epoch 013 - training loss: 22813.7458, validation loss: 0.6422
2024-05-24 07:34:11 [INFO]: Epoch 014 - training loss: 22808.2265, validation loss: 0.6341
2024-05-24 07:34:12 [INFO]: Epoch 015 - training loss: 22805.8050, validation loss: 0.6345
2024-05-24 07:34:13 [INFO]: Epoch 016 - training loss: 22801.2380, validation loss: 0.6304
2024-05-24 07:34:14 [INFO]: Epoch 017 - training loss: 22798.8320, validation loss: 0.6243
2024-05-24 07:34:14 [INFO]: Epoch 018 - training loss: 22796.0759, validation loss: 0.6213
2024-05-24 07:34:15 [INFO]: Epoch 019 - training loss: 22794.1795, validation loss: 0.6257
2024-05-24 07:34:16 [INFO]: Epoch 020 - training loss: 22792.7482, validation loss: 0.6176
2024-05-24 07:34:16 [INFO]: Epoch 021 - training loss: 22791.8339, validation loss: 0.6146
2024-05-24 07:34:17 [INFO]: Epoch 022 - training loss: 22790.3317, validation loss: 0.6098
2024-05-24 07:34:18 [INFO]: Epoch 023 - training loss: 22788.8212, validation loss: 0.6078
2024-05-24 07:34:18 [INFO]: Epoch 024 - training loss: 22787.6914, validation loss: 0.6036
2024-05-24 07:34:19 [INFO]: Epoch 025 - training loss: 22786.3496, validation loss: 0.6013
2024-05-24 07:34:20 [INFO]: Epoch 026 - training loss: 22785.3334, validation loss: 0.6042
2024-05-24 07:34:20 [INFO]: Epoch 027 - training loss: 22785.3362, validation loss: 0.5994
2024-05-24 07:34:21 [INFO]: Epoch 028 - training loss: 22784.7332, validation loss: 0.6001
2024-05-24 07:34:22 [INFO]: Epoch 029 - training loss: 22785.0329, validation loss: 0.6022
2024-05-24 07:34:22 [INFO]: Epoch 030 - training loss: 22783.4158, validation loss: 0.5966
2024-05-24 07:34:23 [INFO]: Epoch 031 - training loss: 22782.3133, validation loss: 0.5968
2024-05-24 07:34:24 [INFO]: Epoch 032 - training loss: 22782.2471, validation loss: 0.5954
2024-05-24 07:34:25 [INFO]: Epoch 033 - training loss: 22781.4029, validation loss: 0.5920
2024-05-24 07:34:25 [INFO]: Epoch 034 - training loss: 22780.2504, validation loss: 0.5905
2024-05-24 07:34:26 [INFO]: Epoch 035 - training loss: 22779.6723, validation loss: 0.5852
2024-05-24 07:34:27 [INFO]: Epoch 036 - training loss: 22778.7437, validation loss: 0.5821
2024-05-24 07:34:27 [INFO]: Epoch 037 - training loss: 22776.7198, validation loss: 0.5763
2024-05-24 07:34:28 [INFO]: Epoch 038 - training loss: 22775.5547, validation loss: 0.5746
2024-05-24 07:34:29 [INFO]: Epoch 039 - training loss: 22774.9025, validation loss: 0.5715
2024-05-24 07:34:29 [INFO]: Epoch 040 - training loss: 22774.0669, validation loss: 0.5781
2024-05-24 07:34:30 [INFO]: Epoch 041 - training loss: 22773.5906, validation loss: 0.5781
2024-05-24 07:34:31 [INFO]: Epoch 042 - training loss: 22772.9043, validation loss: 0.5620
2024-05-24 07:34:31 [INFO]: Epoch 043 - training loss: 22771.8687, validation loss: 0.5641
2024-05-24 07:34:32 [INFO]: Epoch 044 - training loss: 22771.4012, validation loss: 0.5638
2024-05-24 07:34:33 [INFO]: Epoch 045 - training loss: 22770.4753, validation loss: 0.5685
2024-05-24 07:34:33 [INFO]: Epoch 046 - training loss: 22770.3396, validation loss: 0.5646
2024-05-24 07:34:34 [INFO]: Epoch 047 - training loss: 22769.6610, validation loss: 0.5660
2024-05-24 07:34:35 [INFO]: Epoch 048 - training loss: 22769.1643, validation loss: 0.5594
2024-05-24 07:34:35 [INFO]: Epoch 049 - training loss: 22768.9157, validation loss: 0.5555
2024-05-24 07:34:36 [INFO]: Epoch 050 - training loss: 22768.4300, validation loss: 0.5544
2024-05-24 07:34:37 [INFO]: Epoch 051 - training loss: 22767.2197, validation loss: 0.5567
2024-05-24 07:34:37 [INFO]: Epoch 052 - training loss: 22767.0226, validation loss: 0.5712
2024-05-24 07:34:38 [INFO]: Epoch 053 - training loss: 22766.4716, validation loss: 0.5507
2024-05-24 07:34:39 [INFO]: Epoch 054 - training loss: 22764.9931, validation loss: 0.5452
2024-05-24 07:34:39 [INFO]: Epoch 055 - training loss: 22763.9693, validation loss: 0.5408
2024-05-24 07:34:40 [INFO]: Epoch 056 - training loss: 22763.6889, validation loss: 0.5399
2024-05-24 07:34:41 [INFO]: Epoch 057 - training loss: 22763.4344, validation loss: 0.5379
2024-05-24 07:34:41 [INFO]: Epoch 058 - training loss: 22762.9517, validation loss: 0.5356
2024-05-24 07:34:42 [INFO]: Epoch 059 - training loss: 22762.3306, validation loss: 0.5357
2024-05-24 07:34:43 [INFO]: Epoch 060 - training loss: 22761.6917, validation loss: 0.5324
2024-05-24 07:34:43 [INFO]: Epoch 061 - training loss: 22761.8455, validation loss: 0.5293
2024-05-24 07:34:44 [INFO]: Epoch 062 - training loss: 22761.2499, validation loss: 0.5291
2024-05-24 07:34:45 [INFO]: Epoch 063 - training loss: 22760.3724, validation loss: 0.5297
2024-05-24 07:34:46 [INFO]: Epoch 064 - training loss: 22760.7187, validation loss: 0.5208
2024-05-24 07:34:46 [INFO]: Epoch 065 - training loss: 22760.4188, validation loss: 0.5235
2024-05-24 07:34:47 [INFO]: Epoch 066 - training loss: 22759.8824, validation loss: 0.5189
2024-05-24 07:34:48 [INFO]: Epoch 067 - training loss: 22759.7020, validation loss: 0.5185
2024-05-24 07:34:48 [INFO]: Epoch 068 - training loss: 22758.7670, validation loss: 0.5125
2024-05-24 07:34:49 [INFO]: Epoch 069 - training loss: 22758.7327, validation loss: 0.5192
2024-05-24 07:34:50 [INFO]: Epoch 070 - training loss: 22757.9014, validation loss: 0.5084
2024-05-24 07:34:50 [INFO]: Epoch 071 - training loss: 22757.7380, validation loss: 0.5140
2024-05-24 07:34:51 [INFO]: Epoch 072 - training loss: 22757.0487, validation loss: 0.5078
2024-05-24 07:34:52 [INFO]: Epoch 073 - training loss: 22756.8990, validation loss: 0.5069
2024-05-24 07:34:52 [INFO]: Epoch 074 - training loss: 22757.0364, validation loss: 0.5065
2024-05-24 07:34:53 [INFO]: Epoch 075 - training loss: 22755.6847, validation loss: 0.5042
2024-05-24 07:34:54 [INFO]: Epoch 076 - training loss: 22755.5457, validation loss: 0.4966
2024-05-24 07:34:54 [INFO]: Epoch 077 - training loss: 22755.2871, validation loss: 0.4928
2024-05-24 07:34:55 [INFO]: Epoch 078 - training loss: 22755.5215, validation loss: 0.5580
2024-05-24 07:34:56 [INFO]: Epoch 079 - training loss: 22763.0382, validation loss: 0.5112
2024-05-24 07:34:56 [INFO]: Epoch 080 - training loss: 22756.5350, validation loss: 0.4967
2024-05-24 07:34:57 [INFO]: Epoch 081 - training loss: 22754.2415, validation loss: 0.4956
2024-05-24 07:34:58 [INFO]: Epoch 082 - training loss: 22753.6349, validation loss: 0.4968
2024-05-24 07:34:58 [INFO]: Epoch 083 - training loss: 22753.4487, validation loss: 0.4878
2024-05-24 07:34:59 [INFO]: Epoch 084 - training loss: 22752.9495, validation loss: 0.4901
2024-05-24 07:35:00 [INFO]: Epoch 085 - training loss: 22752.7515, validation loss: 0.4965
2024-05-24 07:35:00 [INFO]: Epoch 086 - training loss: 22752.4602, validation loss: 0.4937
2024-05-24 07:35:01 [INFO]: Epoch 087 - training loss: 22752.5327, validation loss: 0.4908
2024-05-24 07:35:02 [INFO]: Epoch 088 - training loss: 22752.7628, validation loss: 0.4893
2024-05-24 07:35:02 [INFO]: Epoch 089 - training loss: 22752.3387, validation loss: 0.4897
2024-05-24 07:35:03 [INFO]: Epoch 090 - training loss: 22752.4315, validation loss: 0.4942
2024-05-24 07:35:04 [INFO]: Epoch 091 - training loss: 22752.6724, validation loss: 0.4965
2024-05-24 07:35:05 [INFO]: Epoch 092 - training loss: 22752.2266, validation loss: 0.4864
2024-05-24 07:35:05 [INFO]: Epoch 093 - training loss: 22752.3288, validation loss: 0.4944
2024-05-24 07:35:06 [INFO]: Epoch 094 - training loss: 22751.1283, validation loss: 0.4861
2024-05-24 07:35:07 [INFO]: Epoch 095 - training loss: 22751.3132, validation loss: 0.4897
2024-05-24 07:35:07 [INFO]: Epoch 096 - training loss: 22750.9207, validation loss: 0.4921
2024-05-24 07:35:08 [INFO]: Epoch 097 - training loss: 22751.6813, validation loss: 0.4884
2024-05-24 07:35:09 [INFO]: Epoch 098 - training loss: 22751.0386, validation loss: 0.4835
2024-05-24 07:35:09 [INFO]: Epoch 099 - training loss: 22750.6461, validation loss: 0.4925
2024-05-24 07:35:10 [INFO]: Epoch 100 - training loss: 22750.2200, validation loss: 0.4863
2024-05-24 07:35:11 [INFO]: Epoch 101 - training loss: 22750.0358, validation loss: 0.4875
2024-05-24 07:35:11 [INFO]: Epoch 102 - training loss: 22750.0868, validation loss: 0.4910
2024-05-24 07:35:12 [INFO]: Epoch 103 - training loss: 22750.4281, validation loss: 0.4877
2024-05-24 07:35:13 [INFO]: Epoch 104 - training loss: 22750.6640, validation loss: 0.4830
2024-05-24 07:35:13 [INFO]: Epoch 105 - training loss: 22749.5813, validation loss: 0.4799
2024-05-24 07:35:14 [INFO]: Epoch 106 - training loss: 22750.5339, validation loss: 0.4830
2024-05-24 07:35:15 [INFO]: Epoch 107 - training loss: 22749.4135, validation loss: 0.4844
2024-05-24 07:35:15 [INFO]: Epoch 108 - training loss: 22750.5744, validation loss: 0.4797
2024-05-24 07:35:16 [INFO]: Epoch 109 - training loss: 22750.2787, validation loss: 0.4823
2024-05-24 07:35:17 [INFO]: Epoch 110 - training loss: 22750.4019, validation loss: 0.4800
2024-05-24 07:35:17 [INFO]: Epoch 111 - training loss: 22749.6663, validation loss: 0.4814
2024-05-24 07:35:18 [INFO]: Epoch 112 - training loss: 22750.1185, validation loss: 0.4777
2024-05-24 07:35:19 [INFO]: Epoch 113 - training loss: 22749.7279, validation loss: 0.4825
2024-05-24 07:35:19 [INFO]: Epoch 114 - training loss: 22749.5803, validation loss: 0.4765
2024-05-24 07:35:20 [INFO]: Epoch 115 - training loss: 22748.4441, validation loss: 0.4775
2024-05-24 07:35:21 [INFO]: Epoch 116 - training loss: 22748.5211, validation loss: 0.4833
2024-05-24 07:35:21 [INFO]: Epoch 117 - training loss: 22748.6913, validation loss: 0.4756
2024-05-24 07:35:22 [INFO]: Epoch 118 - training loss: 22748.2416, validation loss: 0.4757
2024-05-24 07:35:23 [INFO]: Epoch 119 - training loss: 22747.5092, validation loss: 0.4753
2024-05-24 07:35:23 [INFO]: Epoch 120 - training loss: 22747.5979, validation loss: 0.4776
2024-05-24 07:35:24 [INFO]: Epoch 121 - training loss: 22747.3655, validation loss: 0.4754
2024-05-24 07:35:25 [INFO]: Epoch 122 - training loss: 22747.6076, validation loss: 0.4776
2024-05-24 07:35:25 [INFO]: Epoch 123 - training loss: 22747.3812, validation loss: 0.4792
2024-05-24 07:35:26 [INFO]: Epoch 124 - training loss: 22747.7069, validation loss: 0.4825
2024-05-24 07:35:27 [INFO]: Epoch 125 - training loss: 22749.1112, validation loss: 0.4738
2024-05-24 07:35:28 [INFO]: Epoch 126 - training loss: 22747.8663, validation loss: 0.4788
2024-05-24 07:35:28 [INFO]: Epoch 127 - training loss: 22746.9934, validation loss: 0.4776
2024-05-24 07:35:29 [INFO]: Epoch 128 - training loss: 22747.9337, validation loss: 0.4732
2024-05-24 07:35:30 [INFO]: Epoch 129 - training loss: 22747.3760, validation loss: 0.4830
2024-05-24 07:35:30 [INFO]: Epoch 130 - training loss: 22747.6296, validation loss: 0.4728
2024-05-24 07:35:31 [INFO]: Epoch 131 - training loss: 22746.6876, validation loss: 0.4747
2024-05-24 07:35:32 [INFO]: Epoch 132 - training loss: 22746.6176, validation loss: 0.4746
2024-05-24 07:35:32 [INFO]: Epoch 133 - training loss: 22746.4643, validation loss: 0.4723
2024-05-24 07:35:33 [INFO]: Epoch 134 - training loss: 22746.2954, validation loss: 0.4691
2024-05-24 07:35:34 [INFO]: Epoch 135 - training loss: 22746.1895, validation loss: 0.4698
2024-05-24 07:35:34 [INFO]: Epoch 136 - training loss: 22745.9290, validation loss: 0.4737
2024-05-24 07:35:35 [INFO]: Epoch 137 - training loss: 22746.1589, validation loss: 0.4740
2024-05-24 07:35:36 [INFO]: Epoch 138 - training loss: 22746.2137, validation loss: 0.4700
2024-05-24 07:35:36 [INFO]: Epoch 139 - training loss: 22746.6838, validation loss: 0.4687
2024-05-24 07:35:37 [INFO]: Epoch 140 - training loss: 22745.5902, validation loss: 0.4704
2024-05-24 07:35:38 [INFO]: Epoch 141 - training loss: 22745.4172, validation loss: 0.4740
2024-05-24 07:35:38 [INFO]: Epoch 142 - training loss: 22745.3264, validation loss: 0.4728
2024-05-24 07:35:39 [INFO]: Epoch 143 - training loss: 22746.4103, validation loss: 0.4701
2024-05-24 07:35:40 [INFO]: Epoch 144 - training loss: 22746.2490, validation loss: 0.4719
2024-05-24 07:35:40 [INFO]: Epoch 145 - training loss: 22746.0645, validation loss: 0.4717
2024-05-24 07:35:41 [INFO]: Epoch 146 - training loss: 22746.4239, validation loss: 0.4701
2024-05-24 07:35:42 [INFO]: Epoch 147 - training loss: 22745.6068, validation loss: 0.4763
2024-05-24 07:35:42 [INFO]: Epoch 148 - training loss: 22745.7025, validation loss: 0.4690
2024-05-24 07:35:43 [INFO]: Epoch 149 - training loss: 22745.3825, validation loss: 0.4693
2024-05-24 07:35:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 07:35:43 [INFO]: Finished training. The best model is from epoch#139.
2024-05-24 07:35:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_physionet_2012_seta/20240524_T073400/GPVAE.pypots
2024-05-24 07:35:43 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4139, MSE=0.4961
2024-05-24 07:35:44 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 07:35:44 [INFO]: Using the given device: cuda:0
2024-05-24 07:35:44 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073544
2024-05-24 07:35:44 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073544/tensorboard
2024-05-24 07:35:44 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 07:36:07 [INFO]: Epoch 001 - generator training loss: 0.5856, discriminator training loss: 0.3844, validation loss: 0.6098
2024-05-24 07:36:26 [INFO]: Epoch 002 - generator training loss: 0.4712, discriminator training loss: 0.2721, validation loss: 0.5201
2024-05-24 07:36:46 [INFO]: Epoch 003 - generator training loss: 0.4249, discriminator training loss: 0.2354, validation loss: 0.4955
2024-05-24 07:37:05 [INFO]: Epoch 004 - generator training loss: 0.4431, discriminator training loss: 0.1874, validation loss: 0.4886
2024-05-24 07:37:23 [INFO]: Epoch 005 - generator training loss: 0.4421, discriminator training loss: 0.1574, validation loss: 0.4799
2024-05-24 07:37:42 [INFO]: Epoch 006 - generator training loss: 0.4315, discriminator training loss: 0.1387, validation loss: 0.4652
2024-05-24 07:38:01 [INFO]: Epoch 007 - generator training loss: 0.4167, discriminator training loss: 0.1251, validation loss: 0.4559
2024-05-24 07:38:19 [INFO]: Epoch 008 - generator training loss: 0.4086, discriminator training loss: 0.1149, validation loss: 0.4358
2024-05-24 07:38:38 [INFO]: Epoch 009 - generator training loss: 0.3976, discriminator training loss: 0.1065, validation loss: 0.4338
2024-05-24 07:38:57 [INFO]: Epoch 010 - generator training loss: 0.3908, discriminator training loss: 0.0996, validation loss: 0.4216
2024-05-24 07:39:16 [INFO]: Epoch 011 - generator training loss: 0.3831, discriminator training loss: 0.0936, validation loss: 0.4124
2024-05-24 07:39:34 [INFO]: Epoch 012 - generator training loss: 0.3771, discriminator training loss: 0.0885, validation loss: 0.4103
2024-05-24 07:39:53 [INFO]: Epoch 013 - generator training loss: 0.3739, discriminator training loss: 0.0838, validation loss: 0.4022
2024-05-24 07:40:12 [INFO]: Epoch 014 - generator training loss: 0.3690, discriminator training loss: 0.0797, validation loss: 0.3944
2024-05-24 07:40:31 [INFO]: Epoch 015 - generator training loss: 0.3635, discriminator training loss: 0.0764, validation loss: 0.3948
2024-05-24 07:40:49 [INFO]: Epoch 016 - generator training loss: 0.3587, discriminator training loss: 0.0731, validation loss: 0.3878
2024-05-24 07:41:08 [INFO]: Epoch 017 - generator training loss: 0.3548, discriminator training loss: 0.0702, validation loss: 0.3824
2024-05-24 07:41:27 [INFO]: Epoch 018 - generator training loss: 0.3508, discriminator training loss: 0.0676, validation loss: 0.3785
2024-05-24 07:41:46 [INFO]: Epoch 019 - generator training loss: 0.3475, discriminator training loss: 0.0653, validation loss: 0.3750
2024-05-24 07:42:04 [INFO]: Epoch 020 - generator training loss: 0.3423, discriminator training loss: 0.0633, validation loss: 0.3700
2024-05-24 07:42:23 [INFO]: Epoch 021 - generator training loss: 0.3384, discriminator training loss: 0.0611, validation loss: 0.3688
2024-05-24 07:42:42 [INFO]: Epoch 022 - generator training loss: 0.3351, discriminator training loss: 0.0595, validation loss: 0.3645
2024-05-24 07:43:01 [INFO]: Epoch 023 - generator training loss: 0.3300, discriminator training loss: 0.0580, validation loss: 0.3573
2024-05-24 07:43:19 [INFO]: Epoch 024 - generator training loss: 0.3254, discriminator training loss: 0.0567, validation loss: 0.3548
2024-05-24 07:43:38 [INFO]: Epoch 025 - generator training loss: 0.3217, discriminator training loss: 0.0553, validation loss: 0.3537
2024-05-24 07:43:57 [INFO]: Epoch 026 - generator training loss: 0.3195, discriminator training loss: 0.0543, validation loss: 0.3460
2024-05-24 07:44:16 [INFO]: Epoch 027 - generator training loss: 0.3146, discriminator training loss: 0.0533, validation loss: 0.3489
2024-05-24 07:44:34 [INFO]: Epoch 028 - generator training loss: 0.3093, discriminator training loss: 0.0524, validation loss: 0.3461
2024-05-24 07:44:53 [INFO]: Epoch 029 - generator training loss: 0.3043, discriminator training loss: 0.0515, validation loss: 0.3378
2024-05-24 07:45:12 [INFO]: Epoch 030 - generator training loss: 0.3013, discriminator training loss: 0.0507, validation loss: 0.3353
2024-05-24 07:45:31 [INFO]: Epoch 031 - generator training loss: 0.2975, discriminator training loss: 0.0500, validation loss: 0.3304
2024-05-24 07:45:49 [INFO]: Epoch 032 - generator training loss: 0.2939, discriminator training loss: 0.0494, validation loss: 0.3352
2024-05-24 07:46:08 [INFO]: Epoch 033 - generator training loss: 0.2904, discriminator training loss: 0.0489, validation loss: 0.3317
2024-05-24 07:46:27 [INFO]: Epoch 034 - generator training loss: 0.2845, discriminator training loss: 0.0483, validation loss: 0.3273
2024-05-24 07:46:46 [INFO]: Epoch 035 - generator training loss: 0.2807, discriminator training loss: 0.0479, validation loss: 0.3289
2024-05-24 07:47:04 [INFO]: Epoch 036 - generator training loss: 0.2845, discriminator training loss: 0.0476, validation loss: 0.3259
2024-05-24 07:47:23 [INFO]: Epoch 037 - generator training loss: 0.2804, discriminator training loss: 0.0471, validation loss: 0.3203
2024-05-24 07:47:42 [INFO]: Epoch 038 - generator training loss: 0.2717, discriminator training loss: 0.0464, validation loss: 0.3190
2024-05-24 07:48:01 [INFO]: Epoch 039 - generator training loss: 0.2702, discriminator training loss: 0.0464, validation loss: 0.3191
2024-05-24 07:48:19 [INFO]: Epoch 040 - generator training loss: 0.2731, discriminator training loss: 0.0462, validation loss: 0.3161
2024-05-24 07:48:38 [INFO]: Epoch 041 - generator training loss: 0.2701, discriminator training loss: 0.0459, validation loss: 0.3233
2024-05-24 07:48:57 [INFO]: Epoch 042 - generator training loss: 0.2678, discriminator training loss: 0.0454, validation loss: 0.3142
2024-05-24 07:49:15 [INFO]: Epoch 043 - generator training loss: 0.2639, discriminator training loss: 0.0451, validation loss: 0.3157
2024-05-24 07:49:34 [INFO]: Epoch 044 - generator training loss: 0.2636, discriminator training loss: 0.0448, validation loss: 0.3092
2024-05-24 07:49:53 [INFO]: Epoch 045 - generator training loss: 0.2599, discriminator training loss: 0.0445, validation loss: 0.3131
2024-05-24 07:50:12 [INFO]: Epoch 046 - generator training loss: 0.2524, discriminator training loss: 0.0441, validation loss: 0.3051
2024-05-24 07:50:30 [INFO]: Epoch 047 - generator training loss: 0.2478, discriminator training loss: 0.0442, validation loss: 0.3056
2024-05-24 07:50:49 [INFO]: Epoch 048 - generator training loss: 0.2433, discriminator training loss: 0.0439, validation loss: 0.3061
2024-05-24 07:51:08 [INFO]: Epoch 049 - generator training loss: 0.2442, discriminator training loss: 0.0437, validation loss: 0.3036
2024-05-24 07:51:27 [INFO]: Epoch 050 - generator training loss: 0.2429, discriminator training loss: 0.0435, validation loss: 0.3030
2024-05-24 07:51:46 [INFO]: Epoch 051 - generator training loss: 0.2395, discriminator training loss: 0.0436, validation loss: 0.3046
2024-05-24 07:52:04 [INFO]: Epoch 052 - generator training loss: 0.2360, discriminator training loss: 0.0433, validation loss: 0.3067
2024-05-24 07:52:23 [INFO]: Epoch 053 - generator training loss: 0.2379, discriminator training loss: 0.0433, validation loss: 0.3048
2024-05-24 07:52:42 [INFO]: Epoch 054 - generator training loss: 0.2313, discriminator training loss: 0.0430, validation loss: 0.3073
2024-05-24 07:53:00 [INFO]: Epoch 055 - generator training loss: 0.2299, discriminator training loss: 0.0429, validation loss: 0.3041
2024-05-24 07:53:19 [INFO]: Epoch 056 - generator training loss: 0.2320, discriminator training loss: 0.0429, validation loss: 0.3084
2024-05-24 07:53:38 [INFO]: Epoch 057 - generator training loss: 0.2303, discriminator training loss: 0.0429, validation loss: 0.3055
2024-05-24 07:53:57 [INFO]: Epoch 058 - generator training loss: 0.2294, discriminator training loss: 0.0426, validation loss: 0.3021
2024-05-24 07:54:15 [INFO]: Epoch 059 - generator training loss: 0.2248, discriminator training loss: 0.0426, validation loss: 0.3018
2024-05-24 07:54:34 [INFO]: Epoch 060 - generator training loss: 0.2289, discriminator training loss: 0.0426, validation loss: 0.3050
2024-05-24 07:54:53 [INFO]: Epoch 061 - generator training loss: 0.2281, discriminator training loss: 0.0425, validation loss: 0.3012
2024-05-24 07:55:12 [INFO]: Epoch 062 - generator training loss: 0.2259, discriminator training loss: 0.0423, validation loss: 0.3110
2024-05-24 07:55:30 [INFO]: Epoch 063 - generator training loss: 0.2280, discriminator training loss: 0.0422, validation loss: 0.3040
2024-05-24 07:55:49 [INFO]: Epoch 064 - generator training loss: 0.2201, discriminator training loss: 0.0423, validation loss: 0.3004
2024-05-24 07:56:08 [INFO]: Epoch 065 - generator training loss: 0.2122, discriminator training loss: 0.0422, validation loss: 0.3017
2024-05-24 07:56:26 [INFO]: Epoch 066 - generator training loss: 0.2145, discriminator training loss: 0.0421, validation loss: 0.3024
2024-05-24 07:56:45 [INFO]: Epoch 067 - generator training loss: 0.2177, discriminator training loss: 0.0421, validation loss: 0.3038
2024-05-24 07:57:04 [INFO]: Epoch 068 - generator training loss: 0.2201, discriminator training loss: 0.0419, validation loss: 0.3094
2024-05-24 07:57:23 [INFO]: Epoch 069 - generator training loss: 0.2142, discriminator training loss: 0.0418, validation loss: 0.3032
2024-05-24 07:57:41 [INFO]: Epoch 070 - generator training loss: 0.2262, discriminator training loss: 0.0421, validation loss: 0.3043
2024-05-24 07:58:00 [INFO]: Epoch 071 - generator training loss: 0.2118, discriminator training loss: 0.0418, validation loss: 0.2999
2024-05-24 07:58:19 [INFO]: Epoch 072 - generator training loss: 0.2087, discriminator training loss: 0.0417, validation loss: 0.3031
2024-05-24 07:58:38 [INFO]: Epoch 073 - generator training loss: 0.2034, discriminator training loss: 0.0416, validation loss: 0.3014
2024-05-24 07:58:56 [INFO]: Epoch 074 - generator training loss: 0.2008, discriminator training loss: 0.0415, validation loss: 0.3018
2024-05-24 07:59:15 [INFO]: Epoch 075 - generator training loss: 0.1968, discriminator training loss: 0.0416, validation loss: 0.3022
2024-05-24 07:59:34 [INFO]: Epoch 076 - generator training loss: 0.2003, discriminator training loss: 0.0415, validation loss: 0.3031
2024-05-24 07:59:53 [INFO]: Epoch 077 - generator training loss: 0.2011, discriminator training loss: 0.0413, validation loss: 0.3014
2024-05-24 08:00:11 [INFO]: Epoch 078 - generator training loss: 0.1968, discriminator training loss: 0.0413, validation loss: 0.3052
2024-05-24 08:00:30 [INFO]: Epoch 079 - generator training loss: 0.2000, discriminator training loss: 0.0413, validation loss: 0.3029
2024-05-24 08:00:49 [INFO]: Epoch 080 - generator training loss: 0.1981, discriminator training loss: 0.0412, validation loss: 0.2992
2024-05-24 08:01:08 [INFO]: Epoch 081 - generator training loss: 0.1904, discriminator training loss: 0.0408, validation loss: 0.2980
2024-05-24 08:01:26 [INFO]: Epoch 082 - generator training loss: 0.1901, discriminator training loss: 0.0410, validation loss: 0.3024
2024-05-24 08:01:45 [INFO]: Epoch 083 - generator training loss: 0.1859, discriminator training loss: 0.0409, validation loss: 0.3053
2024-05-24 08:02:04 [INFO]: Epoch 084 - generator training loss: 0.1823, discriminator training loss: 0.0409, validation loss: 0.3008
2024-05-24 08:02:23 [INFO]: Epoch 085 - generator training loss: 0.1830, discriminator training loss: 0.0407, validation loss: 0.3040
2024-05-24 08:02:41 [INFO]: Epoch 086 - generator training loss: 0.1838, discriminator training loss: 0.0405, validation loss: 0.3024
2024-05-24 08:03:00 [INFO]: Epoch 087 - generator training loss: 0.1798, discriminator training loss: 0.0404, validation loss: 0.3025
2024-05-24 08:03:19 [INFO]: Epoch 088 - generator training loss: 0.1771, discriminator training loss: 0.0402, validation loss: 0.3016
2024-05-24 08:03:37 [INFO]: Epoch 089 - generator training loss: 0.1731, discriminator training loss: 0.0401, validation loss: 0.3030
2024-05-24 08:03:56 [INFO]: Epoch 090 - generator training loss: 0.1704, discriminator training loss: 0.0399, validation loss: 0.3028
2024-05-24 08:04:15 [INFO]: Epoch 091 - generator training loss: 0.1678, discriminator training loss: 0.0401, validation loss: 0.3022
2024-05-24 08:04:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:04:15 [INFO]: Finished training. The best model is from epoch#81.
2024-05-24 08:04:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_physionet_2012_seta/20240524_T073544/USGAN.pypots
2024-05-24 08:04:17 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2925, MSE=0.2745
2024-05-24 08:04:27 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 08:04:27 [INFO]: Using the given device: cuda:0
2024-05-24 08:04:27 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T080427
2024-05-24 08:04:27 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T080427/tensorboard
2024-05-24 08:04:27 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 08:04:42 [INFO]: Epoch 001 - training loss: 1.1478, validation loss: 0.5340
2024-05-24 08:04:55 [INFO]: Epoch 002 - training loss: 0.9323, validation loss: 0.4710
2024-05-24 08:05:07 [INFO]: Epoch 003 - training loss: 0.8689, validation loss: 0.4422
2024-05-24 08:05:19 [INFO]: Epoch 004 - training loss: 0.8313, validation loss: 0.4187
2024-05-24 08:05:32 [INFO]: Epoch 005 - training loss: 0.8028, validation loss: 0.3994
2024-05-24 08:05:44 [INFO]: Epoch 006 - training loss: 0.7790, validation loss: 0.3836
2024-05-24 08:05:56 [INFO]: Epoch 007 - training loss: 0.7599, validation loss: 0.3718
2024-05-24 08:06:09 [INFO]: Epoch 008 - training loss: 0.7438, validation loss: 0.3642
2024-05-24 08:06:21 [INFO]: Epoch 009 - training loss: 0.7304, validation loss: 0.3574
2024-05-24 08:06:33 [INFO]: Epoch 010 - training loss: 0.7180, validation loss: 0.3519
2024-05-24 08:06:45 [INFO]: Epoch 011 - training loss: 0.7087, validation loss: 0.3468
2024-05-24 08:06:58 [INFO]: Epoch 012 - training loss: 0.7004, validation loss: 0.3444
2024-05-24 08:07:10 [INFO]: Epoch 013 - training loss: 0.6926, validation loss: 0.3433
2024-05-24 08:07:22 [INFO]: Epoch 014 - training loss: 0.6854, validation loss: 0.3393
2024-05-24 08:07:35 [INFO]: Epoch 015 - training loss: 0.6803, validation loss: 0.3380
2024-05-24 08:07:47 [INFO]: Epoch 016 - training loss: 0.6744, validation loss: 0.3366
2024-05-24 08:07:59 [INFO]: Epoch 017 - training loss: 0.6703, validation loss: 0.3368
2024-05-24 08:08:12 [INFO]: Epoch 018 - training loss: 0.6653, validation loss: 0.3352
2024-05-24 08:08:24 [INFO]: Epoch 019 - training loss: 0.6618, validation loss: 0.3337
2024-05-24 08:08:36 [INFO]: Epoch 020 - training loss: 0.6578, validation loss: 0.3330
2024-05-24 08:08:48 [INFO]: Epoch 021 - training loss: 0.6550, validation loss: 0.3324
2024-05-24 08:09:01 [INFO]: Epoch 022 - training loss: 0.6502, validation loss: 0.3315
2024-05-24 08:09:13 [INFO]: Epoch 023 - training loss: 0.6476, validation loss: 0.3303
2024-05-24 08:09:25 [INFO]: Epoch 024 - training loss: 0.6441, validation loss: 0.3290
2024-05-24 08:09:38 [INFO]: Epoch 025 - training loss: 0.6413, validation loss: 0.3303
2024-05-24 08:09:50 [INFO]: Epoch 026 - training loss: 0.6400, validation loss: 0.3298
2024-05-24 08:10:02 [INFO]: Epoch 027 - training loss: 0.6369, validation loss: 0.3297
2024-05-24 08:10:14 [INFO]: Epoch 028 - training loss: 0.6340, validation loss: 0.3298
2024-05-24 08:10:27 [INFO]: Epoch 029 - training loss: 0.6309, validation loss: 0.3313
2024-05-24 08:10:39 [INFO]: Epoch 030 - training loss: 0.6296, validation loss: 0.3283
2024-05-24 08:10:51 [INFO]: Epoch 031 - training loss: 0.6265, validation loss: 0.3301
2024-05-24 08:11:04 [INFO]: Epoch 032 - training loss: 0.6264, validation loss: 0.3307
2024-05-24 08:11:16 [INFO]: Epoch 033 - training loss: 0.6224, validation loss: 0.3290
2024-05-24 08:11:28 [INFO]: Epoch 034 - training loss: 0.6211, validation loss: 0.3305
2024-05-24 08:11:40 [INFO]: Epoch 035 - training loss: 0.6182, validation loss: 0.3296
2024-05-24 08:11:53 [INFO]: Epoch 036 - training loss: 0.6132, validation loss: 0.3302
2024-05-24 08:12:05 [INFO]: Epoch 037 - training loss: 0.6113, validation loss: 0.3299
2024-05-24 08:12:17 [INFO]: Epoch 038 - training loss: 0.6083, validation loss: 0.3290
2024-05-24 08:12:29 [INFO]: Epoch 039 - training loss: 0.6052, validation loss: 0.3297
2024-05-24 08:12:42 [INFO]: Epoch 040 - training loss: 0.6018, validation loss: 0.3292
2024-05-24 08:12:42 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:12:42 [INFO]: Finished training. The best model is from epoch#30.
2024-05-24 08:12:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_physionet_2012_seta/20240524_T080427/BRITS.pypots
2024-05-24 08:12:44 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2617, MSE=0.2909
2024-05-24 08:12:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:12:54 [INFO]: Using the given device: cuda:0
2024-05-24 08:12:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254
2024-05-24 08:12:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/tensorboard
2024-05-24 08:12:54 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 08:12:59 [INFO]: Epoch 001 - training loss: 1.1304, validation loss: 0.9942
2024-05-24 08:12:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch1_loss0.994200375676155.pypots
2024-05-24 08:13:02 [INFO]: Epoch 002 - training loss: 0.6915, validation loss: 0.9703
2024-05-24 08:13:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch2_loss0.9702976256608963.pypots
2024-05-24 08:13:05 [INFO]: Epoch 003 - training loss: 0.5923, validation loss: 0.9425
2024-05-24 08:13:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch3_loss0.942519748210907.pypots
2024-05-24 08:13:08 [INFO]: Epoch 004 - training loss: 0.5537, validation loss: 0.9269
2024-05-24 08:13:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch4_loss0.9268893539905548.pypots
2024-05-24 08:13:11 [INFO]: Epoch 005 - training loss: 0.5313, validation loss: 0.9188
2024-05-24 08:13:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch5_loss0.9187601566314697.pypots
2024-05-24 08:13:14 [INFO]: Epoch 006 - training loss: 0.5169, validation loss: 0.9147
2024-05-24 08:13:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch6_loss0.9146988391876221.pypots
2024-05-24 08:13:16 [INFO]: Epoch 007 - training loss: 0.5005, validation loss: 0.9128
2024-05-24 08:13:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch7_loss0.9127717852592468.pypots
2024-05-24 08:13:19 [INFO]: Epoch 008 - training loss: 0.4845, validation loss: 0.9102
2024-05-24 08:13:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch8_loss0.9101851969957352.pypots
2024-05-24 08:13:22 [INFO]: Epoch 009 - training loss: 0.4776, validation loss: 0.9107
2024-05-24 08:13:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch9_loss0.9107121378183365.pypots
2024-05-24 08:13:25 [INFO]: Epoch 010 - training loss: 0.4722, validation loss: 0.9116
2024-05-24 08:13:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch10_loss0.9116133987903595.pypots
2024-05-24 08:13:28 [INFO]: Epoch 011 - training loss: 0.4697, validation loss: 0.9131
2024-05-24 08:13:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch11_loss0.9130849123001099.pypots
2024-05-24 08:13:30 [INFO]: Epoch 012 - training loss: 0.4675, validation loss: 0.9164
2024-05-24 08:13:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch12_loss0.9163952380418777.pypots
2024-05-24 08:13:33 [INFO]: Epoch 013 - training loss: 0.4611, validation loss: 0.9184
2024-05-24 08:13:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch13_loss0.918433228135109.pypots
2024-05-24 08:13:36 [INFO]: Epoch 014 - training loss: 0.4519, validation loss: 0.9214
2024-05-24 08:13:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch14_loss0.9214093953371048.pypots
2024-05-24 08:13:39 [INFO]: Epoch 015 - training loss: 0.4519, validation loss: 0.9232
2024-05-24 08:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch15_loss0.9232100963592529.pypots
2024-05-24 08:13:42 [INFO]: Epoch 016 - training loss: 0.4400, validation loss: 0.9240
2024-05-24 08:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch16_loss0.9239855229854583.pypots
2024-05-24 08:13:45 [INFO]: Epoch 017 - training loss: 0.4492, validation loss: 0.9269
2024-05-24 08:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch17_loss0.9268626034259796.pypots
2024-05-24 08:13:47 [INFO]: Epoch 018 - training loss: 0.4518, validation loss: 0.9269
2024-05-24 08:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN_epoch18_loss0.926860237121582.pypots
2024-05-24 08:13:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:13:47 [INFO]: Finished training. The best model is from epoch#8.
2024-05-24 08:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/20240524_T081254/MRNN.pypots
2024-05-24 08:13:48 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6838, MSE=0.9237
2024-05-24 08:13:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 08:13:53 [INFO]: Using the given device: cpu
2024-05-24 08:13:53 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4083, MSE=0.5397
2024-05-24 08:13:53 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_physionet_2012_seta".
2024-05-24 08:13:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 08:13:53 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6856, MSE=1.0305
2024-05-24 08:13:53 [INFO]: Successfully created the given path "saved_results/round_3/Median_physionet_2012_seta".
2024-05-24 08:13:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_physionet_2012_seta/imputation.pkl
2024-05-24 08:13:53 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7023, MSE=1.0007
2024-05-24 08:13:53 [INFO]: Successfully created the given path "saved_results/round_3/Mean_physionet_2012_seta".
2024-05-24 08:13:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 08:13:53 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-24 08:13:54 [INFO]: Using the given device: cuda:0
2024-05-24 08:13:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T081354
2024-05-24 08:13:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T081354/tensorboard
2024-05-24 08:13:54 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 5,322,806
2024-05-24 08:13:55 [INFO]: Epoch 001 - training loss: 1.1486, validation loss: 0.5107
2024-05-24 08:13:56 [INFO]: Epoch 002 - training loss: 0.8446, validation loss: 0.4159
2024-05-24 08:13:58 [INFO]: Epoch 003 - training loss: 0.7489, validation loss: 0.3826
2024-05-24 08:13:59 [INFO]: Epoch 004 - training loss: 0.6952, validation loss: 0.3627
2024-05-24 08:14:00 [INFO]: Epoch 005 - training loss: 0.6624, validation loss: 0.3478
2024-05-24 08:14:01 [INFO]: Epoch 006 - training loss: 0.6280, validation loss: 0.3432
2024-05-24 08:14:02 [INFO]: Epoch 007 - training loss: 0.6023, validation loss: 0.3360
2024-05-24 08:14:03 [INFO]: Epoch 008 - training loss: 0.5851, validation loss: 0.3235
2024-05-24 08:14:05 [INFO]: Epoch 009 - training loss: 0.5600, validation loss: 0.3142
2024-05-24 08:14:06 [INFO]: Epoch 010 - training loss: 0.5452, validation loss: 0.3115
2024-05-24 08:14:07 [INFO]: Epoch 011 - training loss: 0.5329, validation loss: 0.3030
2024-05-24 08:14:08 [INFO]: Epoch 012 - training loss: 0.5163, validation loss: 0.2950
2024-05-24 08:14:09 [INFO]: Epoch 013 - training loss: 0.5039, validation loss: 0.2945
2024-05-24 08:14:10 [INFO]: Epoch 014 - training loss: 0.4939, validation loss: 0.2904
2024-05-24 08:14:12 [INFO]: Epoch 015 - training loss: 0.4792, validation loss: 0.2928
2024-05-24 08:14:13 [INFO]: Epoch 016 - training loss: 0.4722, validation loss: 0.2909
2024-05-24 08:14:14 [INFO]: Epoch 017 - training loss: 0.4677, validation loss: 0.2911
2024-05-24 08:14:15 [INFO]: Epoch 018 - training loss: 0.4577, validation loss: 0.2901
2024-05-24 08:14:16 [INFO]: Epoch 019 - training loss: 0.4507, validation loss: 0.2893
2024-05-24 08:14:18 [INFO]: Epoch 020 - training loss: 0.4432, validation loss: 0.2858
2024-05-24 08:14:19 [INFO]: Epoch 021 - training loss: 0.4383, validation loss: 0.2853
2024-05-24 08:14:20 [INFO]: Epoch 022 - training loss: 0.4335, validation loss: 0.2893
2024-05-24 08:14:21 [INFO]: Epoch 023 - training loss: 0.4277, validation loss: 0.2863
2024-05-24 08:14:22 [INFO]: Epoch 024 - training loss: 0.4217, validation loss: 0.2886
2024-05-24 08:14:23 [INFO]: Epoch 025 - training loss: 0.4197, validation loss: 0.2914
2024-05-24 08:14:25 [INFO]: Epoch 026 - training loss: 0.4156, validation loss: 0.2939
2024-05-24 08:14:26 [INFO]: Epoch 027 - training loss: 0.4127, validation loss: 0.2881
2024-05-24 08:14:27 [INFO]: Epoch 028 - training loss: 0.4117, validation loss: 0.2891
2024-05-24 08:14:28 [INFO]: Epoch 029 - training loss: 0.4051, validation loss: 0.2926
2024-05-24 08:14:29 [INFO]: Epoch 030 - training loss: 0.4039, validation loss: 0.2927
2024-05-24 08:14:30 [INFO]: Epoch 031 - training loss: 0.4005, validation loss: 0.2858
2024-05-24 08:14:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:14:30 [INFO]: Finished training. The best model is from epoch#21.
2024-05-24 08:14:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_physionet_2012_seta/20240524_T081354/SAITS.pypots
2024-05-24 08:14:31 [INFO]: SAITS on PhysioNet-2012-seta: MAE=0.2763, MSE=0.3257
2024-05-24 08:14:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_physionet_2012_seta/imputation.pkl
2024-05-24 08:14:31 [INFO]: Using the given device: cuda:0
2024-05-24 08:14:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T081431
2024-05-24 08:14:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T081431/tensorboard
2024-05-24 08:14:31 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 2,152,613
2024-05-24 08:14:32 [INFO]: Epoch 001 - training loss: 1.2096, validation loss: 0.5939
2024-05-24 08:14:32 [INFO]: Epoch 002 - training loss: 0.7619, validation loss: 0.4743
2024-05-24 08:14:33 [INFO]: Epoch 003 - training loss: 0.6519, validation loss: 0.4402
2024-05-24 08:14:33 [INFO]: Epoch 004 - training loss: 0.5856, validation loss: 0.4329
2024-05-24 08:14:34 [INFO]: Epoch 005 - training loss: 0.5500, validation loss: 0.4149
2024-05-24 08:14:35 [INFO]: Epoch 006 - training loss: 0.5124, validation loss: 0.3923
2024-05-24 08:14:35 [INFO]: Epoch 007 - training loss: 0.4854, validation loss: 0.3831
2024-05-24 08:14:36 [INFO]: Epoch 008 - training loss: 0.4607, validation loss: 0.3826
2024-05-24 08:14:36 [INFO]: Epoch 009 - training loss: 0.4395, validation loss: 0.3754
2024-05-24 08:14:37 [INFO]: Epoch 010 - training loss: 0.4294, validation loss: 0.3657
2024-05-24 08:14:38 [INFO]: Epoch 011 - training loss: 0.4099, validation loss: 0.3608
2024-05-24 08:14:38 [INFO]: Epoch 012 - training loss: 0.3931, validation loss: 0.3550
2024-05-24 08:14:39 [INFO]: Epoch 013 - training loss: 0.3785, validation loss: 0.3449
2024-05-24 08:14:39 [INFO]: Epoch 014 - training loss: 0.3729, validation loss: 0.3405
2024-05-24 08:14:40 [INFO]: Epoch 015 - training loss: 0.3621, validation loss: 0.3349
2024-05-24 08:14:41 [INFO]: Epoch 016 - training loss: 0.3500, validation loss: 0.3361
2024-05-24 08:14:41 [INFO]: Epoch 017 - training loss: 0.3467, validation loss: 0.3348
2024-05-24 08:14:42 [INFO]: Epoch 018 - training loss: 0.3387, validation loss: 0.3342
2024-05-24 08:14:42 [INFO]: Epoch 019 - training loss: 0.3269, validation loss: 0.3259
2024-05-24 08:14:43 [INFO]: Epoch 020 - training loss: 0.3211, validation loss: 0.3254
2024-05-24 08:14:44 [INFO]: Epoch 021 - training loss: 0.3168, validation loss: 0.3257
2024-05-24 08:14:44 [INFO]: Epoch 022 - training loss: 0.3080, validation loss: 0.3259
2024-05-24 08:14:45 [INFO]: Epoch 023 - training loss: 0.3027, validation loss: 0.3187
2024-05-24 08:14:46 [INFO]: Epoch 024 - training loss: 0.2930, validation loss: 0.3166
2024-05-24 08:14:46 [INFO]: Epoch 025 - training loss: 0.2891, validation loss: 0.3187
2024-05-24 08:14:47 [INFO]: Epoch 026 - training loss: 0.2825, validation loss: 0.3152
2024-05-24 08:14:47 [INFO]: Epoch 027 - training loss: 0.2760, validation loss: 0.3200
2024-05-24 08:14:48 [INFO]: Epoch 028 - training loss: 0.2811, validation loss: 0.3139
2024-05-24 08:14:49 [INFO]: Epoch 029 - training loss: 0.2761, validation loss: 0.3150
2024-05-24 08:14:49 [INFO]: Epoch 030 - training loss: 0.2657, validation loss: 0.3105
2024-05-24 08:14:50 [INFO]: Epoch 031 - training loss: 0.2636, validation loss: 0.3135
2024-05-24 08:14:50 [INFO]: Epoch 032 - training loss: 0.2584, validation loss: 0.3117
2024-05-24 08:14:51 [INFO]: Epoch 033 - training loss: 0.2580, validation loss: 0.3142
2024-05-24 08:14:52 [INFO]: Epoch 034 - training loss: 0.2531, validation loss: 0.3138
2024-05-24 08:14:52 [INFO]: Epoch 035 - training loss: 0.2487, validation loss: 0.3121
2024-05-24 08:14:53 [INFO]: Epoch 036 - training loss: 0.2364, validation loss: 0.3128
2024-05-24 08:14:53 [INFO]: Epoch 037 - training loss: 0.2398, validation loss: 0.3100
2024-05-24 08:14:54 [INFO]: Epoch 038 - training loss: 0.2376, validation loss: 0.3119
2024-05-24 08:14:55 [INFO]: Epoch 039 - training loss: 0.2322, validation loss: 0.3138
2024-05-24 08:14:55 [INFO]: Epoch 040 - training loss: 0.2272, validation loss: 0.3122
2024-05-24 08:14:56 [INFO]: Epoch 041 - training loss: 0.2257, validation loss: 0.3098
2024-05-24 08:14:56 [INFO]: Epoch 042 - training loss: 0.2253, validation loss: 0.3146
2024-05-24 08:14:57 [INFO]: Epoch 043 - training loss: 0.2249, validation loss: 0.3113
2024-05-24 08:14:57 [INFO]: Epoch 044 - training loss: 0.2213, validation loss: 0.3137
2024-05-24 08:14:58 [INFO]: Epoch 045 - training loss: 0.2180, validation loss: 0.3123
2024-05-24 08:14:59 [INFO]: Epoch 046 - training loss: 0.2159, validation loss: 0.3124
2024-05-24 08:14:59 [INFO]: Epoch 047 - training loss: 0.2144, validation loss: 0.3140
2024-05-24 08:15:00 [INFO]: Epoch 048 - training loss: 0.2112, validation loss: 0.3157
2024-05-24 08:15:01 [INFO]: Epoch 049 - training loss: 0.2068, validation loss: 0.3137
2024-05-24 08:15:01 [INFO]: Epoch 050 - training loss: 0.2074, validation loss: 0.3174
2024-05-24 08:15:02 [INFO]: Epoch 051 - training loss: 0.2060, validation loss: 0.3104
2024-05-24 08:15:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:15:02 [INFO]: Finished training. The best model is from epoch#41.
2024-05-24 08:15:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_physionet_2012_seta/20240524_T081431/Transformer.pypots
2024-05-24 08:15:02 [INFO]: Transformer on PhysioNet-2012-seta: MAE=0.2869, MSE=0.3365
2024-05-24 08:15:02 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_physionet_2012_seta/imputation.pkl
2024-05-24 08:15:02 [INFO]: Using the given device: cuda:0
2024-05-24 08:15:02 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T081502
2024-05-24 08:15:02 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T081502/tensorboard
2024-05-24 08:15:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,649,573
2024-05-24 08:15:03 [INFO]: Epoch 001 - training loss: 0.4314, validation loss: 0.5101
2024-05-24 08:15:04 [INFO]: Epoch 002 - training loss: 0.6069, validation loss: 0.3498
2024-05-24 08:15:04 [INFO]: Epoch 003 - training loss: 0.5173, validation loss: 0.3529
2024-05-24 08:15:05 [INFO]: Epoch 004 - training loss: 0.4183, validation loss: 0.3159
2024-05-24 08:15:06 [INFO]: Epoch 005 - training loss: 0.3167, validation loss: 0.3084
2024-05-24 08:15:06 [INFO]: Epoch 006 - training loss: 0.3040, validation loss: 0.2986
2024-05-24 08:15:07 [INFO]: Epoch 007 - training loss: 0.2835, validation loss: 0.3058
2024-05-24 08:15:08 [INFO]: Epoch 008 - training loss: 0.2698, validation loss: 0.3022
2024-05-24 08:15:09 [INFO]: Epoch 009 - training loss: 0.2668, validation loss: 0.3002
2024-05-24 08:15:09 [INFO]: Epoch 010 - training loss: 0.2592, validation loss: 0.2972
2024-05-24 08:15:10 [INFO]: Epoch 011 - training loss: 0.2517, validation loss: 0.2908
2024-05-24 08:15:11 [INFO]: Epoch 012 - training loss: 0.2497, validation loss: 0.2877
2024-05-24 08:15:11 [INFO]: Epoch 013 - training loss: 0.2508, validation loss: 0.2948
2024-05-24 08:15:12 [INFO]: Epoch 014 - training loss: 0.2381, validation loss: 0.3155
2024-05-24 08:15:13 [INFO]: Epoch 015 - training loss: 0.2392, validation loss: 0.2931
2024-05-24 08:15:14 [INFO]: Epoch 016 - training loss: 0.2386, validation loss: 0.2993
2024-05-24 08:15:14 [INFO]: Epoch 017 - training loss: 0.2400, validation loss: 0.2942
2024-05-24 08:15:15 [INFO]: Epoch 018 - training loss: 0.2457, validation loss: 0.2993
2024-05-24 08:15:16 [INFO]: Epoch 019 - training loss: 0.2428, validation loss: 0.2942
2024-05-24 08:15:16 [INFO]: Epoch 020 - training loss: 0.2206, validation loss: 0.3041
2024-05-24 08:15:17 [INFO]: Epoch 021 - training loss: 0.2164, validation loss: 0.2948
2024-05-24 08:15:18 [INFO]: Epoch 022 - training loss: 0.2031, validation loss: 0.2998
2024-05-24 08:15:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:15:18 [INFO]: Finished training. The best model is from epoch#12.
2024-05-24 08:15:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_physionet_2012_seta/20240524_T081502/TimesNet.pypots
2024-05-24 08:15:18 [INFO]: TimesNet on PhysioNet-2012-seta: MAE=0.2886, MSE=0.2801
2024-05-24 08:15:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_physionet_2012_seta/imputation.pkl
2024-05-24 08:15:18 [INFO]: Using the given device: cuda:0
2024-05-24 08:15:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518
2024-05-24 08:15:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/tensorboard
2024-05-24 08:15:18 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 1,694,753
2024-05-24 08:16:01 [INFO]: Epoch 001 - training loss: 0.4199, validation loss: 0.3380
2024-05-24 08:16:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch1_loss0.33799902349710464.pypots
2024-05-24 08:16:45 [INFO]: Epoch 002 - training loss: 0.3185, validation loss: 0.2936
2024-05-24 08:16:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch2_loss0.29359567910432816.pypots
2024-05-24 08:17:28 [INFO]: Epoch 003 - training loss: 0.2705, validation loss: 0.2613
2024-05-24 08:17:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch3_loss0.2613452970981598.pypots
2024-05-24 08:18:12 [INFO]: Epoch 004 - training loss: 0.2604, validation loss: 0.2457
2024-05-24 08:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch4_loss0.24565937519073486.pypots
2024-05-24 08:18:56 [INFO]: Epoch 005 - training loss: 0.2528, validation loss: 0.2334
2024-05-24 08:18:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch5_loss0.23339659199118615.pypots
2024-05-24 08:19:41 [INFO]: Epoch 006 - training loss: 0.2378, validation loss: 0.2245
2024-05-24 08:19:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch6_loss0.22452197521924971.pypots
2024-05-24 08:20:25 [INFO]: Epoch 007 - training loss: 0.2353, validation loss: 0.2201
2024-05-24 08:20:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch7_loss0.22011018991470338.pypots
2024-05-24 08:21:09 [INFO]: Epoch 008 - training loss: 0.2303, validation loss: 0.2209
2024-05-24 08:21:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch8_loss0.22086438536643982.pypots
2024-05-24 08:21:53 [INFO]: Epoch 009 - training loss: 0.2283, validation loss: 0.2168
2024-05-24 08:21:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch9_loss0.21683135107159615.pypots
2024-05-24 08:22:37 [INFO]: Epoch 010 - training loss: 0.2239, validation loss: 0.2132
2024-05-24 08:22:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch10_loss0.21318428367376327.pypots
2024-05-24 08:23:21 [INFO]: Epoch 011 - training loss: 0.2277, validation loss: 0.2104
2024-05-24 08:23:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch11_loss0.2103523686528206.pypots
2024-05-24 08:24:05 [INFO]: Epoch 012 - training loss: 0.2207, validation loss: 0.2087
2024-05-24 08:24:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch12_loss0.20869178250432013.pypots
2024-05-24 08:24:49 [INFO]: Epoch 013 - training loss: 0.2218, validation loss: 0.2078
2024-05-24 08:24:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch13_loss0.2077981412410736.pypots
2024-05-24 08:25:33 [INFO]: Epoch 014 - training loss: 0.2094, validation loss: 0.2070
2024-05-24 08:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch14_loss0.20700979605317116.pypots
2024-05-24 08:26:17 [INFO]: Epoch 015 - training loss: 0.2226, validation loss: 0.2046
2024-05-24 08:26:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch15_loss0.2045504629611969.pypots
2024-05-24 08:27:01 [INFO]: Epoch 016 - training loss: 0.2170, validation loss: 0.2082
2024-05-24 08:27:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch16_loss0.20822618901729584.pypots
2024-05-24 08:27:45 [INFO]: Epoch 017 - training loss: 0.2153, validation loss: 0.2038
2024-05-24 08:27:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch17_loss0.2038460075855255.pypots
2024-05-24 08:28:29 [INFO]: Epoch 018 - training loss: 0.2062, validation loss: 0.2024
2024-05-24 08:28:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch18_loss0.20244741514325143.pypots
2024-05-24 08:29:13 [INFO]: Epoch 019 - training loss: 0.2152, validation loss: 0.2020
2024-05-24 08:29:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch19_loss0.20198996886610984.pypots
2024-05-24 08:29:57 [INFO]: Epoch 020 - training loss: 0.2006, validation loss: 0.1977
2024-05-24 08:29:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch20_loss0.1976761631667614.pypots
2024-05-24 08:30:41 [INFO]: Epoch 021 - training loss: 0.2031, validation loss: 0.2003
2024-05-24 08:30:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch21_loss0.20027633979916573.pypots
2024-05-24 08:31:25 [INFO]: Epoch 022 - training loss: 0.2081, validation loss: 0.1969
2024-05-24 08:31:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch22_loss0.19694650545716286.pypots
2024-05-24 08:32:09 [INFO]: Epoch 023 - training loss: 0.2179, validation loss: 0.1952
2024-05-24 08:32:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch23_loss0.195163806527853.pypots
2024-05-24 08:32:53 [INFO]: Epoch 024 - training loss: 0.2007, validation loss: 0.1967
2024-05-24 08:32:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch24_loss0.19669968709349633.pypots
2024-05-24 08:33:37 [INFO]: Epoch 025 - training loss: 0.1991, validation loss: 0.1980
2024-05-24 08:33:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch25_loss0.19799405634403228.pypots
2024-05-24 08:34:21 [INFO]: Epoch 026 - training loss: 0.1917, validation loss: 0.1940
2024-05-24 08:34:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch26_loss0.19396973997354508.pypots
2024-05-24 08:35:05 [INFO]: Epoch 027 - training loss: 0.2075, validation loss: 0.1989
2024-05-24 08:35:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch27_loss0.19893226251006127.pypots
2024-05-24 08:35:49 [INFO]: Epoch 028 - training loss: 0.2020, validation loss: 0.1950
2024-05-24 08:35:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch28_loss0.19504628330469131.pypots
2024-05-24 08:36:33 [INFO]: Epoch 029 - training loss: 0.2047, validation loss: 0.1953
2024-05-24 08:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch29_loss0.19534365683794022.pypots
2024-05-24 08:37:17 [INFO]: Epoch 030 - training loss: 0.1984, validation loss: 0.1982
2024-05-24 08:37:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch30_loss0.19820965081453323.pypots
2024-05-24 08:38:01 [INFO]: Epoch 031 - training loss: 0.2104, validation loss: 0.1945
2024-05-24 08:38:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch31_loss0.19452450573444366.pypots
2024-05-24 08:38:45 [INFO]: Epoch 032 - training loss: 0.2056, validation loss: 0.1911
2024-05-24 08:38:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch32_loss0.19112889021635054.pypots
2024-05-24 08:39:29 [INFO]: Epoch 033 - training loss: 0.2000, validation loss: 0.1928
2024-05-24 08:39:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch33_loss0.19275835976004602.pypots
2024-05-24 08:40:13 [INFO]: Epoch 034 - training loss: 0.2016, validation loss: 0.1923
2024-05-24 08:40:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch34_loss0.19228206649422647.pypots
2024-05-24 08:40:57 [INFO]: Epoch 035 - training loss: 0.1959, validation loss: 0.1900
2024-05-24 08:40:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch35_loss0.18995294272899627.pypots
2024-05-24 08:41:41 [INFO]: Epoch 036 - training loss: 0.2099, validation loss: 0.1966
2024-05-24 08:41:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch36_loss0.19662051051855087.pypots
2024-05-24 08:42:25 [INFO]: Epoch 037 - training loss: 0.2030, validation loss: 0.1888
2024-05-24 08:42:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch37_loss0.18876130655407905.pypots
2024-05-24 08:43:09 [INFO]: Epoch 038 - training loss: 0.2010, validation loss: 0.1948
2024-05-24 08:43:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch38_loss0.19476081654429436.pypots
2024-05-24 08:43:53 [INFO]: Epoch 039 - training loss: 0.1924, validation loss: 0.1911
2024-05-24 08:43:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch39_loss0.19110637456178664.pypots
2024-05-24 08:44:37 [INFO]: Epoch 040 - training loss: 0.2003, validation loss: 0.1864
2024-05-24 08:44:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch40_loss0.18635681122541428.pypots
2024-05-24 08:45:22 [INFO]: Epoch 041 - training loss: 0.2029, validation loss: 0.1909
2024-05-24 08:45:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch41_loss0.19087131321430206.pypots
2024-05-24 08:46:06 [INFO]: Epoch 042 - training loss: 0.2077, validation loss: 0.1945
2024-05-24 08:46:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch42_loss0.1945176303386688.pypots
2024-05-24 08:46:50 [INFO]: Epoch 043 - training loss: 0.1948, validation loss: 0.1922
2024-05-24 08:46:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch43_loss0.19215587973594667.pypots
2024-05-24 08:47:34 [INFO]: Epoch 044 - training loss: 0.1974, validation loss: 0.1916
2024-05-24 08:47:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch44_loss0.19161225408315657.pypots
2024-05-24 08:48:18 [INFO]: Epoch 045 - training loss: 0.1979, validation loss: 0.1890
2024-05-24 08:48:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch45_loss0.18902691304683686.pypots
2024-05-24 08:49:02 [INFO]: Epoch 046 - training loss: 0.2020, validation loss: 0.1871
2024-05-24 08:49:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch46_loss0.1871008902788162.pypots
2024-05-24 08:49:46 [INFO]: Epoch 047 - training loss: 0.1928, validation loss: 0.1901
2024-05-24 08:49:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch47_loss0.19005599692463876.pypots
2024-05-24 08:50:30 [INFO]: Epoch 048 - training loss: 0.1945, validation loss: 0.1912
2024-05-24 08:50:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch48_loss0.19123419895768165.pypots
2024-05-24 08:51:14 [INFO]: Epoch 049 - training loss: 0.1883, validation loss: 0.1870
2024-05-24 08:51:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch49_loss0.18701010420918465.pypots
2024-05-24 08:51:58 [INFO]: Epoch 050 - training loss: 0.1888, validation loss: 0.1925
2024-05-24 08:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI_epoch50_loss0.19254125729203225.pypots
2024-05-24 08:51:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 08:51:58 [INFO]: Finished training. The best model is from epoch#40.
2024-05-24 08:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/20240524_T081518/CSDI.pypots
2024-05-24 08:59:21 [INFO]: CSDI on PhysioNet-2012-seta: MAE=0.2483, MSE=0.3607
2024-05-24 09:28:51 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_physionet_2012_seta/imputation.pkl
2024-05-24 09:28:51 [INFO]: Using the given device: cuda:0
2024-05-24 09:28:51 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T092851
2024-05-24 09:28:51 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T092851/tensorboard
2024-05-24 09:28:51 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 1,028,244
2024-05-24 09:28:52 [INFO]: Epoch 001 - training loss: 42847.2396, validation loss: 0.9197
2024-05-24 09:28:52 [INFO]: Epoch 002 - training loss: 24407.3610, validation loss: 0.7327
2024-05-24 09:28:53 [INFO]: Epoch 003 - training loss: 23466.8155, validation loss: 0.7111
2024-05-24 09:28:54 [INFO]: Epoch 004 - training loss: 23174.5591, validation loss: 0.6766
2024-05-24 09:28:54 [INFO]: Epoch 005 - training loss: 23032.0805, validation loss: 0.6509
2024-05-24 09:28:55 [INFO]: Epoch 006 - training loss: 22953.4945, validation loss: 0.6531
2024-05-24 09:28:55 [INFO]: Epoch 007 - training loss: 22905.5588, validation loss: 0.6457
2024-05-24 09:28:56 [INFO]: Epoch 008 - training loss: 22874.8724, validation loss: 0.6484
2024-05-24 09:28:57 [INFO]: Epoch 009 - training loss: 22853.7833, validation loss: 0.6429
2024-05-24 09:28:57 [INFO]: Epoch 010 - training loss: 22838.5594, validation loss: 0.6409
2024-05-24 09:28:58 [INFO]: Epoch 011 - training loss: 22827.9229, validation loss: 0.6407
2024-05-24 09:28:58 [INFO]: Epoch 012 - training loss: 22819.6309, validation loss: 0.6357
2024-05-24 09:28:59 [INFO]: Epoch 013 - training loss: 22814.0416, validation loss: 0.6361
2024-05-24 09:29:00 [INFO]: Epoch 014 - training loss: 22809.0796, validation loss: 0.6316
2024-05-24 09:29:00 [INFO]: Epoch 015 - training loss: 22805.6558, validation loss: 0.6347
2024-05-24 09:29:01 [INFO]: Epoch 016 - training loss: 22802.9031, validation loss: 0.6305
2024-05-24 09:29:01 [INFO]: Epoch 017 - training loss: 22799.3142, validation loss: 0.6305
2024-05-24 09:29:02 [INFO]: Epoch 018 - training loss: 22796.8225, validation loss: 0.6228
2024-05-24 09:29:03 [INFO]: Epoch 019 - training loss: 22794.5489, validation loss: 0.6243
2024-05-24 09:29:03 [INFO]: Epoch 020 - training loss: 22792.7905, validation loss: 0.6164
2024-05-24 09:29:04 [INFO]: Epoch 021 - training loss: 22791.5711, validation loss: 0.6161
2024-05-24 09:29:05 [INFO]: Epoch 022 - training loss: 22790.2827, validation loss: 0.6107
2024-05-24 09:29:05 [INFO]: Epoch 023 - training loss: 22790.3047, validation loss: 0.6144
2024-05-24 09:29:06 [INFO]: Epoch 024 - training loss: 22788.2102, validation loss: 0.6162
2024-05-24 09:29:06 [INFO]: Epoch 025 - training loss: 22786.9516, validation loss: 0.6102
2024-05-24 09:29:07 [INFO]: Epoch 026 - training loss: 22785.5885, validation loss: 0.6037
2024-05-24 09:29:08 [INFO]: Epoch 027 - training loss: 22785.0700, validation loss: 0.6032
2024-05-24 09:29:08 [INFO]: Epoch 028 - training loss: 22784.3411, validation loss: 0.6063
2024-05-24 09:29:09 [INFO]: Epoch 029 - training loss: 22783.9338, validation loss: 0.6030
2024-05-24 09:29:09 [INFO]: Epoch 030 - training loss: 22784.4710, validation loss: 0.6140
2024-05-24 09:29:10 [INFO]: Epoch 031 - training loss: 22785.0234, validation loss: 0.5998
2024-05-24 09:29:11 [INFO]: Epoch 032 - training loss: 22784.1106, validation loss: 0.6120
2024-05-24 09:29:11 [INFO]: Epoch 033 - training loss: 22782.5675, validation loss: 0.6042
2024-05-24 09:29:12 [INFO]: Epoch 034 - training loss: 22782.5930, validation loss: 0.6010
2024-05-24 09:29:12 [INFO]: Epoch 035 - training loss: 22781.4272, validation loss: 0.5960
2024-05-24 09:29:13 [INFO]: Epoch 036 - training loss: 22780.5801, validation loss: 0.5973
2024-05-24 09:29:14 [INFO]: Epoch 037 - training loss: 22779.6899, validation loss: 0.5919
2024-05-24 09:29:14 [INFO]: Epoch 038 - training loss: 22779.4458, validation loss: 0.5917
2024-05-24 09:29:15 [INFO]: Epoch 039 - training loss: 22778.8550, validation loss: 0.5982
2024-05-24 09:29:16 [INFO]: Epoch 040 - training loss: 22777.4996, validation loss: 0.5852
2024-05-24 09:29:16 [INFO]: Epoch 041 - training loss: 22776.1294, validation loss: 0.5817
2024-05-24 09:29:17 [INFO]: Epoch 042 - training loss: 22774.9110, validation loss: 0.5730
2024-05-24 09:29:17 [INFO]: Epoch 043 - training loss: 22774.2310, validation loss: 0.5714
2024-05-24 09:29:18 [INFO]: Epoch 044 - training loss: 22772.7458, validation loss: 0.5671
2024-05-24 09:29:19 [INFO]: Epoch 045 - training loss: 22772.1524, validation loss: 0.5705
2024-05-24 09:29:19 [INFO]: Epoch 046 - training loss: 22771.0554, validation loss: 0.5658
2024-05-24 09:29:20 [INFO]: Epoch 047 - training loss: 22770.3116, validation loss: 0.5626
2024-05-24 09:29:20 [INFO]: Epoch 048 - training loss: 22769.5511, validation loss: 0.5628
2024-05-24 09:29:21 [INFO]: Epoch 049 - training loss: 22768.7854, validation loss: 0.5610
2024-05-24 09:29:22 [INFO]: Epoch 050 - training loss: 22768.4124, validation loss: 0.5593
2024-05-24 09:29:22 [INFO]: Epoch 051 - training loss: 22767.8856, validation loss: 0.5535
2024-05-24 09:29:23 [INFO]: Epoch 052 - training loss: 22767.5275, validation loss: 0.5513
2024-05-24 09:29:23 [INFO]: Epoch 053 - training loss: 22766.3657, validation loss: 0.5467
2024-05-24 09:29:24 [INFO]: Epoch 054 - training loss: 22765.6747, validation loss: 0.5447
2024-05-24 09:29:25 [INFO]: Epoch 055 - training loss: 22764.9510, validation loss: 0.5432
2024-05-24 09:29:25 [INFO]: Epoch 056 - training loss: 22764.2458, validation loss: 0.5410
2024-05-24 09:29:26 [INFO]: Epoch 057 - training loss: 22763.5331, validation loss: 0.5433
2024-05-24 09:29:27 [INFO]: Epoch 058 - training loss: 22762.9973, validation loss: 0.5320
2024-05-24 09:29:27 [INFO]: Epoch 059 - training loss: 22761.4848, validation loss: 0.5242
2024-05-24 09:29:28 [INFO]: Epoch 060 - training loss: 22761.1268, validation loss: 0.5194
2024-05-24 09:29:28 [INFO]: Epoch 061 - training loss: 22760.4661, validation loss: 0.5166
2024-05-24 09:29:29 [INFO]: Epoch 062 - training loss: 22759.4132, validation loss: 0.5144
2024-05-24 09:29:30 [INFO]: Epoch 063 - training loss: 22758.7060, validation loss: 0.5122
2024-05-24 09:29:30 [INFO]: Epoch 064 - training loss: 22758.3235, validation loss: 0.5106
2024-05-24 09:29:31 [INFO]: Epoch 065 - training loss: 22757.5971, validation loss: 0.5083
2024-05-24 09:29:31 [INFO]: Epoch 066 - training loss: 22756.9135, validation loss: 0.5009
2024-05-24 09:29:32 [INFO]: Epoch 067 - training loss: 22757.0088, validation loss: 0.5006
2024-05-24 09:29:33 [INFO]: Epoch 068 - training loss: 22756.7680, validation loss: 0.5156
2024-05-24 09:29:33 [INFO]: Epoch 069 - training loss: 22756.8230, validation loss: 0.4980
2024-05-24 09:29:34 [INFO]: Epoch 070 - training loss: 22758.3628, validation loss: 0.4955
2024-05-24 09:29:34 [INFO]: Epoch 071 - training loss: 22755.2914, validation loss: 0.4954
2024-05-24 09:29:35 [INFO]: Epoch 072 - training loss: 22755.5636, validation loss: 0.4962
2024-05-24 09:29:36 [INFO]: Epoch 073 - training loss: 22755.1727, validation loss: 0.4939
2024-05-24 09:29:36 [INFO]: Epoch 074 - training loss: 22754.3453, validation loss: 0.5080
2024-05-24 09:29:37 [INFO]: Epoch 075 - training loss: 22754.8035, validation loss: 0.4935
2024-05-24 09:29:37 [INFO]: Epoch 076 - training loss: 22756.1681, validation loss: 0.4942
2024-05-24 09:29:38 [INFO]: Epoch 077 - training loss: 22753.7425, validation loss: 0.4914
2024-05-24 09:29:39 [INFO]: Epoch 078 - training loss: 22753.5864, validation loss: 0.4907
2024-05-24 09:29:39 [INFO]: Epoch 079 - training loss: 22753.0987, validation loss: 0.4931
2024-05-24 09:29:40 [INFO]: Epoch 080 - training loss: 22753.4323, validation loss: 0.4908
2024-05-24 09:29:41 [INFO]: Epoch 081 - training loss: 22753.2964, validation loss: 0.4885
2024-05-24 09:29:41 [INFO]: Epoch 082 - training loss: 22752.9831, validation loss: 0.4947
2024-05-24 09:29:42 [INFO]: Epoch 083 - training loss: 22752.4800, validation loss: 0.4903
2024-05-24 09:29:42 [INFO]: Epoch 084 - training loss: 22752.9231, validation loss: 0.4882
2024-05-24 09:29:43 [INFO]: Epoch 085 - training loss: 22753.0178, validation loss: 0.4926
2024-05-24 09:29:44 [INFO]: Epoch 086 - training loss: 22752.0748, validation loss: 0.4919
2024-05-24 09:29:44 [INFO]: Epoch 087 - training loss: 22755.2443, validation loss: 0.4900
2024-05-24 09:29:45 [INFO]: Epoch 088 - training loss: 22752.2728, validation loss: 0.5026
2024-05-24 09:29:45 [INFO]: Epoch 089 - training loss: 22752.6822, validation loss: 0.4887
2024-05-24 09:29:46 [INFO]: Epoch 090 - training loss: 22752.5554, validation loss: 0.4897
2024-05-24 09:29:47 [INFO]: Epoch 091 - training loss: 22752.1631, validation loss: 0.4936
2024-05-24 09:29:47 [INFO]: Epoch 092 - training loss: 22752.5229, validation loss: 0.4871
2024-05-24 09:29:48 [INFO]: Epoch 093 - training loss: 22751.6112, validation loss: 0.4910
2024-05-24 09:29:48 [INFO]: Epoch 094 - training loss: 22751.4313, validation loss: 0.4996
2024-05-24 09:29:49 [INFO]: Epoch 095 - training loss: 22754.0600, validation loss: 0.4894
2024-05-24 09:29:50 [INFO]: Epoch 096 - training loss: 22752.8129, validation loss: 0.4879
2024-05-24 09:29:50 [INFO]: Epoch 097 - training loss: 22751.5012, validation loss: 0.4880
2024-05-24 09:29:51 [INFO]: Epoch 098 - training loss: 22751.3075, validation loss: 0.4877
2024-05-24 09:29:52 [INFO]: Epoch 099 - training loss: 22751.0661, validation loss: 0.4875
2024-05-24 09:29:52 [INFO]: Epoch 100 - training loss: 22750.6740, validation loss: 0.4850
2024-05-24 09:29:53 [INFO]: Epoch 101 - training loss: 22750.9475, validation loss: 0.4820
2024-05-24 09:29:53 [INFO]: Epoch 102 - training loss: 22750.6999, validation loss: 0.4836
2024-05-24 09:29:54 [INFO]: Epoch 103 - training loss: 22750.2104, validation loss: 0.4838
2024-05-24 09:29:55 [INFO]: Epoch 104 - training loss: 22750.0194, validation loss: 0.4805
2024-05-24 09:29:55 [INFO]: Epoch 105 - training loss: 22749.9065, validation loss: 0.4850
2024-05-24 09:29:56 [INFO]: Epoch 106 - training loss: 22749.6314, validation loss: 0.4823
2024-05-24 09:29:56 [INFO]: Epoch 107 - training loss: 22749.3147, validation loss: 0.4894
2024-05-24 09:29:57 [INFO]: Epoch 108 - training loss: 22750.5295, validation loss: 0.4909
2024-05-24 09:29:58 [INFO]: Epoch 109 - training loss: 22750.2845, validation loss: 0.4810
2024-05-24 09:29:58 [INFO]: Epoch 110 - training loss: 22750.9591, validation loss: 0.4841
2024-05-24 09:29:59 [INFO]: Epoch 111 - training loss: 22749.7172, validation loss: 0.4853
2024-05-24 09:29:59 [INFO]: Epoch 112 - training loss: 22750.6977, validation loss: 0.4787
2024-05-24 09:30:00 [INFO]: Epoch 113 - training loss: 22749.8482, validation loss: 0.4839
2024-05-24 09:30:01 [INFO]: Epoch 114 - training loss: 22748.8972, validation loss: 0.4792
2024-05-24 09:30:01 [INFO]: Epoch 115 - training loss: 22748.5680, validation loss: 0.4783
2024-05-24 09:30:02 [INFO]: Epoch 116 - training loss: 22749.3278, validation loss: 0.4775
2024-05-24 09:30:03 [INFO]: Epoch 117 - training loss: 22748.8407, validation loss: 0.4760
2024-05-24 09:30:03 [INFO]: Epoch 118 - training loss: 22748.1016, validation loss: 0.4760
2024-05-24 09:30:04 [INFO]: Epoch 119 - training loss: 22748.0541, validation loss: 0.4754
2024-05-24 09:30:04 [INFO]: Epoch 120 - training loss: 22747.9750, validation loss: 0.4885
2024-05-24 09:30:05 [INFO]: Epoch 121 - training loss: 22749.6647, validation loss: 0.4755
2024-05-24 09:30:06 [INFO]: Epoch 122 - training loss: 22748.5488, validation loss: 0.4745
2024-05-24 09:30:06 [INFO]: Epoch 123 - training loss: 22748.3155, validation loss: 0.4737
2024-05-24 09:30:07 [INFO]: Epoch 124 - training loss: 22747.9426, validation loss: 0.4782
2024-05-24 09:30:07 [INFO]: Epoch 125 - training loss: 22747.3395, validation loss: 0.4699
2024-05-24 09:30:08 [INFO]: Epoch 126 - training loss: 22746.7743, validation loss: 0.4803
2024-05-24 09:30:09 [INFO]: Epoch 127 - training loss: 22746.8527, validation loss: 0.4709
2024-05-24 09:30:09 [INFO]: Epoch 128 - training loss: 22748.7109, validation loss: 0.4741
2024-05-24 09:30:10 [INFO]: Epoch 129 - training loss: 22747.1279, validation loss: 0.4724
2024-05-24 09:30:10 [INFO]: Epoch 130 - training loss: 22746.2033, validation loss: 0.4770
2024-05-24 09:30:11 [INFO]: Epoch 131 - training loss: 22746.7711, validation loss: 0.4682
2024-05-24 09:30:12 [INFO]: Epoch 132 - training loss: 22746.5230, validation loss: 0.4695
2024-05-24 09:30:12 [INFO]: Epoch 133 - training loss: 22746.1617, validation loss: 0.4712
2024-05-24 09:30:13 [INFO]: Epoch 134 - training loss: 22746.5619, validation loss: 0.4683
2024-05-24 09:30:14 [INFO]: Epoch 135 - training loss: 22745.7738, validation loss: 0.4714
2024-05-24 09:30:14 [INFO]: Epoch 136 - training loss: 22745.8551, validation loss: 0.4667
2024-05-24 09:30:15 [INFO]: Epoch 137 - training loss: 22745.2921, validation loss: 0.4705
2024-05-24 09:30:15 [INFO]: Epoch 138 - training loss: 22745.5188, validation loss: 0.4663
2024-05-24 09:30:16 [INFO]: Epoch 139 - training loss: 22745.1513, validation loss: 0.4691
2024-05-24 09:30:17 [INFO]: Epoch 140 - training loss: 22745.9748, validation loss: 0.4658
2024-05-24 09:30:17 [INFO]: Epoch 141 - training loss: 22745.3879, validation loss: 0.4732
2024-05-24 09:30:18 [INFO]: Epoch 142 - training loss: 22746.7073, validation loss: 0.4639
2024-05-24 09:30:18 [INFO]: Epoch 143 - training loss: 22745.8503, validation loss: 0.4692
2024-05-24 09:30:19 [INFO]: Epoch 144 - training loss: 22744.7610, validation loss: 0.4631
2024-05-24 09:30:20 [INFO]: Epoch 145 - training loss: 22744.9769, validation loss: 0.4649
2024-05-24 09:30:20 [INFO]: Epoch 146 - training loss: 22745.1303, validation loss: 0.4658
2024-05-24 09:30:21 [INFO]: Epoch 147 - training loss: 22744.4083, validation loss: 0.4722
2024-05-24 09:30:21 [INFO]: Epoch 148 - training loss: 22745.1100, validation loss: 0.4663
2024-05-24 09:30:22 [INFO]: Epoch 149 - training loss: 22744.7506, validation loss: 0.4669
2024-05-24 09:30:23 [INFO]: Epoch 150 - training loss: 22744.1004, validation loss: 0.4681
2024-05-24 09:30:23 [INFO]: Epoch 151 - training loss: 22744.0446, validation loss: 0.4644
2024-05-24 09:30:24 [INFO]: Epoch 152 - training loss: 22744.0950, validation loss: 0.4647
2024-05-24 09:30:24 [INFO]: Epoch 153 - training loss: 22744.4678, validation loss: 0.4596
2024-05-24 09:30:25 [INFO]: Epoch 154 - training loss: 22744.3021, validation loss: 0.4626
2024-05-24 09:30:26 [INFO]: Epoch 155 - training loss: 22743.6942, validation loss: 0.4654
2024-05-24 09:30:26 [INFO]: Epoch 156 - training loss: 22743.6833, validation loss: 0.4607
2024-05-24 09:30:27 [INFO]: Epoch 157 - training loss: 22744.1669, validation loss: 0.4671
2024-05-24 09:30:27 [INFO]: Epoch 158 - training loss: 22744.6357, validation loss: 0.4624
2024-05-24 09:30:28 [INFO]: Epoch 159 - training loss: 22744.5668, validation loss: 0.4673
2024-05-24 09:30:29 [INFO]: Epoch 160 - training loss: 22743.6351, validation loss: 0.4762
2024-05-24 09:30:29 [INFO]: Epoch 161 - training loss: 22744.8730, validation loss: 0.4744
2024-05-24 09:30:30 [INFO]: Epoch 162 - training loss: 22744.2317, validation loss: 0.4646
2024-05-24 09:30:30 [INFO]: Epoch 163 - training loss: 22746.6953, validation loss: 0.4638
2024-05-24 09:30:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:30:30 [INFO]: Finished training. The best model is from epoch#153.
2024-05-24 09:30:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_physionet_2012_seta/20240524_T092851/GPVAE.pypots
2024-05-24 09:30:30 [INFO]: GP-VAE on PhysioNet-2012-seta: MAE=0.4120, MSE=0.4834
2024-05-24 09:30:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_physionet_2012_seta/imputation.pkl
2024-05-24 09:30:31 [INFO]: Using the given device: cuda:0
2024-05-24 09:30:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T093031
2024-05-24 09:30:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T093031/tensorboard
2024-05-24 09:30:31 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 16,010,261
2024-05-24 09:30:52 [INFO]: Epoch 001 - generator training loss: 0.5989, discriminator training loss: 0.3831, validation loss: 0.6182
2024-05-24 09:31:11 [INFO]: Epoch 002 - generator training loss: 0.4818, discriminator training loss: 0.2726, validation loss: 0.5250
2024-05-24 09:31:30 [INFO]: Epoch 003 - generator training loss: 0.4398, discriminator training loss: 0.2369, validation loss: 0.5085
2024-05-24 09:31:49 [INFO]: Epoch 004 - generator training loss: 0.4579, discriminator training loss: 0.1892, validation loss: 0.4978
2024-05-24 09:32:07 [INFO]: Epoch 005 - generator training loss: 0.4499, discriminator training loss: 0.1595, validation loss: 0.4855
2024-05-24 09:32:26 [INFO]: Epoch 006 - generator training loss: 0.4370, discriminator training loss: 0.1398, validation loss: 0.4691
2024-05-24 09:32:45 [INFO]: Epoch 007 - generator training loss: 0.4214, discriminator training loss: 0.1261, validation loss: 0.4590
2024-05-24 09:33:04 [INFO]: Epoch 008 - generator training loss: 0.4103, discriminator training loss: 0.1155, validation loss: 0.4451
2024-05-24 09:33:22 [INFO]: Epoch 009 - generator training loss: 0.4006, discriminator training loss: 0.1070, validation loss: 0.4369
2024-05-24 09:33:41 [INFO]: Epoch 010 - generator training loss: 0.3937, discriminator training loss: 0.0999, validation loss: 0.4324
2024-05-24 09:34:00 [INFO]: Epoch 011 - generator training loss: 0.3899, discriminator training loss: 0.0937, validation loss: 0.4212
2024-05-24 09:34:19 [INFO]: Epoch 012 - generator training loss: 0.3855, discriminator training loss: 0.0884, validation loss: 0.4171
2024-05-24 09:34:37 [INFO]: Epoch 013 - generator training loss: 0.3787, discriminator training loss: 0.0842, validation loss: 0.4129
2024-05-24 09:34:56 [INFO]: Epoch 014 - generator training loss: 0.3738, discriminator training loss: 0.0799, validation loss: 0.4053
2024-05-24 09:35:15 [INFO]: Epoch 015 - generator training loss: 0.3671, discriminator training loss: 0.0763, validation loss: 0.4014
2024-05-24 09:35:34 [INFO]: Epoch 016 - generator training loss: 0.3652, discriminator training loss: 0.0729, validation loss: 0.3965
2024-05-24 09:35:52 [INFO]: Epoch 017 - generator training loss: 0.3589, discriminator training loss: 0.0703, validation loss: 0.3930
2024-05-24 09:36:11 [INFO]: Epoch 018 - generator training loss: 0.3567, discriminator training loss: 0.0677, validation loss: 0.3880
2024-05-24 09:36:30 [INFO]: Epoch 019 - generator training loss: 0.3527, discriminator training loss: 0.0654, validation loss: 0.3854
2024-05-24 09:36:49 [INFO]: Epoch 020 - generator training loss: 0.3466, discriminator training loss: 0.0633, validation loss: 0.3835
2024-05-24 09:37:08 [INFO]: Epoch 021 - generator training loss: 0.3416, discriminator training loss: 0.0615, validation loss: 0.3770
2024-05-24 09:37:27 [INFO]: Epoch 022 - generator training loss: 0.3384, discriminator training loss: 0.0596, validation loss: 0.3751
2024-05-24 09:37:45 [INFO]: Epoch 023 - generator training loss: 0.3357, discriminator training loss: 0.0581, validation loss: 0.3692
2024-05-24 09:38:04 [INFO]: Epoch 024 - generator training loss: 0.3286, discriminator training loss: 0.0567, validation loss: 0.3666
2024-05-24 09:38:23 [INFO]: Epoch 025 - generator training loss: 0.3272, discriminator training loss: 0.0557, validation loss: 0.3601
2024-05-24 09:38:42 [INFO]: Epoch 026 - generator training loss: 0.3233, discriminator training loss: 0.0544, validation loss: 0.3592
2024-05-24 09:39:00 [INFO]: Epoch 027 - generator training loss: 0.3163, discriminator training loss: 0.0537, validation loss: 0.3581
2024-05-24 09:39:19 [INFO]: Epoch 028 - generator training loss: 0.3161, discriminator training loss: 0.0527, validation loss: 0.3524
2024-05-24 09:39:38 [INFO]: Epoch 029 - generator training loss: 0.3092, discriminator training loss: 0.0517, validation loss: 0.3469
2024-05-24 09:39:57 [INFO]: Epoch 030 - generator training loss: 0.3093, discriminator training loss: 0.0512, validation loss: 0.3491
2024-05-24 09:40:16 [INFO]: Epoch 031 - generator training loss: 0.3058, discriminator training loss: 0.0503, validation loss: 0.3409
2024-05-24 09:40:34 [INFO]: Epoch 032 - generator training loss: 0.2992, discriminator training loss: 0.0497, validation loss: 0.3428
2024-05-24 09:40:53 [INFO]: Epoch 033 - generator training loss: 0.3010, discriminator training loss: 0.0492, validation loss: 0.3423
2024-05-24 09:41:12 [INFO]: Epoch 034 - generator training loss: 0.2938, discriminator training loss: 0.0485, validation loss: 0.3308
2024-05-24 09:41:31 [INFO]: Epoch 035 - generator training loss: 0.2886, discriminator training loss: 0.0480, validation loss: 0.3327
2024-05-24 09:41:50 [INFO]: Epoch 036 - generator training loss: 0.2849, discriminator training loss: 0.0477, validation loss: 0.3378
2024-05-24 09:42:08 [INFO]: Epoch 037 - generator training loss: 0.2881, discriminator training loss: 0.0473, validation loss: 0.3297
2024-05-24 09:42:27 [INFO]: Epoch 038 - generator training loss: 0.2803, discriminator training loss: 0.0469, validation loss: 0.3267
2024-05-24 09:42:46 [INFO]: Epoch 039 - generator training loss: 0.2735, discriminator training loss: 0.0466, validation loss: 0.3253
2024-05-24 09:43:05 [INFO]: Epoch 040 - generator training loss: 0.2703, discriminator training loss: 0.0462, validation loss: 0.3272
2024-05-24 09:43:24 [INFO]: Epoch 041 - generator training loss: 0.2696, discriminator training loss: 0.0459, validation loss: 0.3253
2024-05-24 09:43:42 [INFO]: Epoch 042 - generator training loss: 0.2740, discriminator training loss: 0.0457, validation loss: 0.3226
2024-05-24 09:44:01 [INFO]: Epoch 043 - generator training loss: 0.2701, discriminator training loss: 0.0453, validation loss: 0.3197
2024-05-24 09:44:20 [INFO]: Epoch 044 - generator training loss: 0.2625, discriminator training loss: 0.0451, validation loss: 0.3231
2024-05-24 09:44:39 [INFO]: Epoch 045 - generator training loss: 0.2610, discriminator training loss: 0.0448, validation loss: 0.3194
2024-05-24 09:44:57 [INFO]: Epoch 046 - generator training loss: 0.2570, discriminator training loss: 0.0446, validation loss: 0.3185
2024-05-24 09:45:16 [INFO]: Epoch 047 - generator training loss: 0.2551, discriminator training loss: 0.0443, validation loss: 0.3164
2024-05-24 09:45:35 [INFO]: Epoch 048 - generator training loss: 0.2526, discriminator training loss: 0.0441, validation loss: 0.3184
2024-05-24 09:45:54 [INFO]: Epoch 049 - generator training loss: 0.2535, discriminator training loss: 0.0441, validation loss: 0.3157
2024-05-24 09:46:13 [INFO]: Epoch 050 - generator training loss: 0.2513, discriminator training loss: 0.0439, validation loss: 0.3141
2024-05-24 09:46:31 [INFO]: Epoch 051 - generator training loss: 0.2478, discriminator training loss: 0.0438, validation loss: 0.3242
2024-05-24 09:46:50 [INFO]: Epoch 052 - generator training loss: 0.2477, discriminator training loss: 0.0436, validation loss: 0.3161
2024-05-24 09:47:09 [INFO]: Epoch 053 - generator training loss: 0.2422, discriminator training loss: 0.0436, validation loss: 0.3176
2024-05-24 09:47:28 [INFO]: Epoch 054 - generator training loss: 0.2480, discriminator training loss: 0.0438, validation loss: 0.3185
2024-05-24 09:47:47 [INFO]: Epoch 055 - generator training loss: 0.2531, discriminator training loss: 0.0436, validation loss: 0.3188
2024-05-24 09:48:05 [INFO]: Epoch 056 - generator training loss: 0.2473, discriminator training loss: 0.0434, validation loss: 0.3143
2024-05-24 09:48:24 [INFO]: Epoch 057 - generator training loss: 0.2416, discriminator training loss: 0.0434, validation loss: 0.3107
2024-05-24 09:48:43 [INFO]: Epoch 058 - generator training loss: 0.2360, discriminator training loss: 0.0432, validation loss: 0.3173
2024-05-24 09:49:01 [INFO]: Epoch 059 - generator training loss: 0.2351, discriminator training loss: 0.0430, validation loss: 0.3116
2024-05-24 09:49:20 [INFO]: Epoch 060 - generator training loss: 0.2285, discriminator training loss: 0.0428, validation loss: 0.3129
2024-05-24 09:49:39 [INFO]: Epoch 061 - generator training loss: 0.2287, discriminator training loss: 0.0429, validation loss: 0.3108
2024-05-24 09:49:58 [INFO]: Epoch 062 - generator training loss: 0.2286, discriminator training loss: 0.0427, validation loss: 0.3146
2024-05-24 09:50:17 [INFO]: Epoch 063 - generator training loss: 0.2241, discriminator training loss: 0.0427, validation loss: 0.3126
2024-05-24 09:50:35 [INFO]: Epoch 064 - generator training loss: 0.2210, discriminator training loss: 0.0425, validation loss: 0.3090
2024-05-24 09:50:54 [INFO]: Epoch 065 - generator training loss: 0.2161, discriminator training loss: 0.0422, validation loss: 0.3082
2024-05-24 09:51:13 [INFO]: Epoch 066 - generator training loss: 0.2229, discriminator training loss: 0.0425, validation loss: 0.3092
2024-05-24 09:51:32 [INFO]: Epoch 067 - generator training loss: 0.2388, discriminator training loss: 0.0423, validation loss: 0.3105
2024-05-24 09:51:51 [INFO]: Epoch 068 - generator training loss: 0.2261, discriminator training loss: 0.0424, validation loss: 0.3094
2024-05-24 09:52:10 [INFO]: Epoch 069 - generator training loss: 0.2168, discriminator training loss: 0.0421, validation loss: 0.3116
2024-05-24 09:52:28 [INFO]: Epoch 070 - generator training loss: 0.2106, discriminator training loss: 0.0420, validation loss: 0.3082
2024-05-24 09:52:47 [INFO]: Epoch 071 - generator training loss: 0.2084, discriminator training loss: 0.0419, validation loss: 0.3094
2024-05-24 09:53:06 [INFO]: Epoch 072 - generator training loss: 0.2078, discriminator training loss: 0.0417, validation loss: 0.3044
2024-05-24 09:53:25 [INFO]: Epoch 073 - generator training loss: 0.2080, discriminator training loss: 0.0415, validation loss: 0.3146
2024-05-24 09:53:43 [INFO]: Epoch 074 - generator training loss: 0.2168, discriminator training loss: 0.0417, validation loss: 0.3104
2024-05-24 09:54:02 [INFO]: Epoch 075 - generator training loss: 0.2163, discriminator training loss: 0.0416, validation loss: 0.3100
2024-05-24 09:54:21 [INFO]: Epoch 076 - generator training loss: 0.2092, discriminator training loss: 0.0414, validation loss: 0.3048
2024-05-24 09:54:40 [INFO]: Epoch 077 - generator training loss: 0.2013, discriminator training loss: 0.0413, validation loss: 0.3098
2024-05-24 09:54:58 [INFO]: Epoch 078 - generator training loss: 0.1998, discriminator training loss: 0.0413, validation loss: 0.3071
2024-05-24 09:55:17 [INFO]: Epoch 079 - generator training loss: 0.1961, discriminator training loss: 0.0412, validation loss: 0.3057
2024-05-24 09:55:36 [INFO]: Epoch 080 - generator training loss: 0.1926, discriminator training loss: 0.0411, validation loss: 0.3078
2024-05-24 09:55:55 [INFO]: Epoch 081 - generator training loss: 0.1919, discriminator training loss: 0.0409, validation loss: 0.3103
2024-05-24 09:56:14 [INFO]: Epoch 082 - generator training loss: 0.1938, discriminator training loss: 0.0408, validation loss: 0.3079
2024-05-24 09:56:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 09:56:14 [INFO]: Finished training. The best model is from epoch#72.
2024-05-24 09:56:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_physionet_2012_seta/20240524_T093031/USGAN.pypots
2024-05-24 09:56:16 [INFO]: US-GAN on PhysioNet-2012-seta: MAE=0.2991, MSE=0.2890
2024-05-24 09:56:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_physionet_2012_seta/imputation.pkl
2024-05-24 09:56:26 [INFO]: Using the given device: cuda:0
2024-05-24 09:56:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T095626
2024-05-24 09:56:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T095626/tensorboard
2024-05-24 09:56:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 9,176,048
2024-05-24 09:56:41 [INFO]: Epoch 001 - training loss: 1.1405, validation loss: 0.5325
2024-05-24 09:56:54 [INFO]: Epoch 002 - training loss: 0.9267, validation loss: 0.4691
2024-05-24 09:57:06 [INFO]: Epoch 003 - training loss: 0.8648, validation loss: 0.4412
2024-05-24 09:57:18 [INFO]: Epoch 004 - training loss: 0.8295, validation loss: 0.4211
2024-05-24 09:57:30 [INFO]: Epoch 005 - training loss: 0.8023, validation loss: 0.4017
2024-05-24 09:57:43 [INFO]: Epoch 006 - training loss: 0.7790, validation loss: 0.3871
2024-05-24 09:57:55 [INFO]: Epoch 007 - training loss: 0.7592, validation loss: 0.3752
2024-05-24 09:58:07 [INFO]: Epoch 008 - training loss: 0.7438, validation loss: 0.3685
2024-05-24 09:58:20 [INFO]: Epoch 009 - training loss: 0.7308, validation loss: 0.3595
2024-05-24 09:58:32 [INFO]: Epoch 010 - training loss: 0.7192, validation loss: 0.3517
2024-05-24 09:58:44 [INFO]: Epoch 011 - training loss: 0.7088, validation loss: 0.3488
2024-05-24 09:58:56 [INFO]: Epoch 012 - training loss: 0.7008, validation loss: 0.3467
2024-05-24 09:59:09 [INFO]: Epoch 013 - training loss: 0.6921, validation loss: 0.3451
2024-05-24 09:59:21 [INFO]: Epoch 014 - training loss: 0.6868, validation loss: 0.3419
2024-05-24 09:59:33 [INFO]: Epoch 015 - training loss: 0.6798, validation loss: 0.3399
2024-05-24 09:59:45 [INFO]: Epoch 016 - training loss: 0.6748, validation loss: 0.3390
2024-05-24 09:59:58 [INFO]: Epoch 017 - training loss: 0.6702, validation loss: 0.3389
2024-05-24 10:00:10 [INFO]: Epoch 018 - training loss: 0.6665, validation loss: 0.3377
2024-05-24 10:00:22 [INFO]: Epoch 019 - training loss: 0.6621, validation loss: 0.3364
2024-05-24 10:00:35 [INFO]: Epoch 020 - training loss: 0.6595, validation loss: 0.3365
2024-05-24 10:00:47 [INFO]: Epoch 021 - training loss: 0.6543, validation loss: 0.3341
2024-05-24 10:00:59 [INFO]: Epoch 022 - training loss: 0.6529, validation loss: 0.3351
2024-05-24 10:01:11 [INFO]: Epoch 023 - training loss: 0.6504, validation loss: 0.3342
2024-05-24 10:01:24 [INFO]: Epoch 024 - training loss: 0.6475, validation loss: 0.3337
2024-05-24 10:01:36 [INFO]: Epoch 025 - training loss: 0.6442, validation loss: 0.3308
2024-05-24 10:01:48 [INFO]: Epoch 026 - training loss: 0.6399, validation loss: 0.3309
2024-05-24 10:02:00 [INFO]: Epoch 027 - training loss: 0.6363, validation loss: 0.3294
2024-05-24 10:02:13 [INFO]: Epoch 028 - training loss: 0.6359, validation loss: 0.3319
2024-05-24 10:02:25 [INFO]: Epoch 029 - training loss: 0.6334, validation loss: 0.3319
2024-05-24 10:02:37 [INFO]: Epoch 030 - training loss: 0.6299, validation loss: 0.3310
2024-05-24 10:02:49 [INFO]: Epoch 031 - training loss: 0.6288, validation loss: 0.3330
2024-05-24 10:03:02 [INFO]: Epoch 032 - training loss: 0.6246, validation loss: 0.3304
2024-05-24 10:03:14 [INFO]: Epoch 033 - training loss: 0.6236, validation loss: 0.3304
2024-05-24 10:03:26 [INFO]: Epoch 034 - training loss: 0.6197, validation loss: 0.3307
2024-05-24 10:03:38 [INFO]: Epoch 035 - training loss: 0.6170, validation loss: 0.3301
2024-05-24 10:03:51 [INFO]: Epoch 036 - training loss: 0.6129, validation loss: 0.3302
2024-05-24 10:04:04 [INFO]: Epoch 037 - training loss: 0.6103, validation loss: 0.3284
2024-05-24 10:04:17 [INFO]: Epoch 038 - training loss: 0.6085, validation loss: 0.3292
2024-05-24 10:04:30 [INFO]: Epoch 039 - training loss: 0.6062, validation loss: 0.3303
2024-05-24 10:04:43 [INFO]: Epoch 040 - training loss: 0.6039, validation loss: 0.3302
2024-05-24 10:04:56 [INFO]: Epoch 041 - training loss: 0.6005, validation loss: 0.3304
2024-05-24 10:05:08 [INFO]: Epoch 042 - training loss: 0.5971, validation loss: 0.3305
2024-05-24 10:05:20 [INFO]: Epoch 043 - training loss: 0.5944, validation loss: 0.3313
2024-05-24 10:05:32 [INFO]: Epoch 044 - training loss: 0.5921, validation loss: 0.3309
2024-05-24 10:05:45 [INFO]: Epoch 045 - training loss: 0.5895, validation loss: 0.3324
2024-05-24 10:05:57 [INFO]: Epoch 046 - training loss: 0.5867, validation loss: 0.3312
2024-05-24 10:06:09 [INFO]: Epoch 047 - training loss: 0.5830, validation loss: 0.3322
2024-05-24 10:06:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:06:09 [INFO]: Finished training. The best model is from epoch#37.
2024-05-24 10:06:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_physionet_2012_seta/20240524_T095626/BRITS.pypots
2024-05-24 10:06:12 [INFO]: BRITS on PhysioNet-2012-seta: MAE=0.2623, MSE=0.2900
2024-05-24 10:06:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_physionet_2012_seta/imputation.pkl
2024-05-24 10:06:21 [INFO]: Using the given device: cuda:0
2024-05-24 10:06:21 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621
2024-05-24 10:06:21 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/tensorboard
2024-05-24 10:06:21 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 7,599
2024-05-24 10:06:27 [INFO]: Epoch 001 - training loss: 1.1914, validation loss: 0.9934
2024-05-24 10:06:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch1_loss0.9934355318546295.pypots
2024-05-24 10:06:30 [INFO]: Epoch 002 - training loss: 0.7283, validation loss: 0.9630
2024-05-24 10:06:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch2_loss0.9629525125026703.pypots
2024-05-24 10:06:33 [INFO]: Epoch 003 - training loss: 0.5890, validation loss: 0.9368
2024-05-24 10:06:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch3_loss0.9368353575468064.pypots
2024-05-24 10:06:36 [INFO]: Epoch 004 - training loss: 0.5570, validation loss: 0.9260
2024-05-24 10:06:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch4_loss0.9259943634271621.pypots
2024-05-24 10:06:38 [INFO]: Epoch 005 - training loss: 0.5368, validation loss: 0.9212
2024-05-24 10:06:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch5_loss0.9212025374174118.pypots
2024-05-24 10:06:41 [INFO]: Epoch 006 - training loss: 0.5165, validation loss: 0.9180
2024-05-24 10:06:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch6_loss0.9179596722126007.pypots
2024-05-24 10:06:44 [INFO]: Epoch 007 - training loss: 0.5039, validation loss: 0.9156
2024-05-24 10:06:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch7_loss0.9156298577785492.pypots
2024-05-24 10:06:47 [INFO]: Epoch 008 - training loss: 0.4943, validation loss: 0.9147
2024-05-24 10:06:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch8_loss0.9147095263004303.pypots
2024-05-24 10:06:50 [INFO]: Epoch 009 - training loss: 0.4806, validation loss: 0.9136
2024-05-24 10:06:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch9_loss0.9136045902967453.pypots
2024-05-24 10:06:53 [INFO]: Epoch 010 - training loss: 0.4824, validation loss: 0.9135
2024-05-24 10:06:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch10_loss0.9134514480829239.pypots
2024-05-24 10:06:55 [INFO]: Epoch 011 - training loss: 0.4687, validation loss: 0.9154
2024-05-24 10:06:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch11_loss0.9154101043939591.pypots
2024-05-24 10:06:58 [INFO]: Epoch 012 - training loss: 0.4679, validation loss: 0.9167
2024-05-24 10:06:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch12_loss0.916736900806427.pypots
2024-05-24 10:07:01 [INFO]: Epoch 013 - training loss: 0.4653, validation loss: 0.9182
2024-05-24 10:07:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch13_loss0.9181838899850845.pypots
2024-05-24 10:07:04 [INFO]: Epoch 014 - training loss: 0.4643, validation loss: 0.9208
2024-05-24 10:07:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch14_loss0.9207612067461014.pypots
2024-05-24 10:07:07 [INFO]: Epoch 015 - training loss: 0.4538, validation loss: 0.9223
2024-05-24 10:07:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch15_loss0.9223208099603653.pypots
2024-05-24 10:07:10 [INFO]: Epoch 016 - training loss: 0.4574, validation loss: 0.9254
2024-05-24 10:07:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch16_loss0.9254004687070847.pypots
2024-05-24 10:07:12 [INFO]: Epoch 017 - training loss: 0.4492, validation loss: 0.9262
2024-05-24 10:07:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch17_loss0.9262158304452897.pypots
2024-05-24 10:07:15 [INFO]: Epoch 018 - training loss: 0.4456, validation loss: 0.9279
2024-05-24 10:07:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch18_loss0.9278965085744858.pypots
2024-05-24 10:07:18 [INFO]: Epoch 019 - training loss: 0.4411, validation loss: 0.9293
2024-05-24 10:07:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch19_loss0.9292585641145706.pypots
2024-05-24 10:07:21 [INFO]: Epoch 020 - training loss: 0.4379, validation loss: 0.9309
2024-05-24 10:07:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN_epoch20_loss0.9309469729661941.pypots
2024-05-24 10:07:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 10:07:21 [INFO]: Finished training. The best model is from epoch#10.
2024-05-24 10:07:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/20240524_T100621/MRNN.pypots
2024-05-24 10:07:22 [INFO]: MRNN on PhysioNet-2012-seta: MAE=0.6854, MSE=0.9281
2024-05-24 10:07:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_physionet_2012_seta/imputation.pkl
2024-05-24 10:07:26 [INFO]: Using the given device: cpu
2024-05-24 10:07:26 [INFO]: LOCF on PhysioNet-2012-seta: MAE=0.4083, MSE=0.5397
2024-05-24 10:07:26 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_physionet_2012_seta".
2024-05-24 10:07:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_physionet_2012_seta/imputation.pkl
2024-05-24 10:07:26 [INFO]: Median on PhysioNet-2012-seta: MAE=0.6856, MSE=1.0305
2024-05-24 10:07:26 [INFO]: Successfully created the given path "saved_results/round_4/Median_physionet_2012_seta".
2024-05-24 10:07:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_physionet_2012_seta/imputation.pkl
2024-05-24 10:07:26 [INFO]: Mean on PhysioNet-2012-seta: MAE=0.7023, MSE=1.0007
2024-05-24 10:07:26 [INFO]: Successfully created the given path "saved_results/round_4/Mean_physionet_2012_seta".
2024-05-24 10:07:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_physionet_2012_seta/imputation.pkl
2024-05-24 10:07:26 [INFO]: 
SAITS on data_overlay_premask/physionet_2012_seta: MAE=0.274±0.005642175638459283, MSE=0.326±0.005407194579611156
Transformer on data_overlay_premask/physionet_2012_seta: MAE=0.289±0.0015692275593638097, MSE=0.336±0.0017738320980390451
TimesNet on data_overlay_premask/physionet_2012_seta: MAE=0.293±0.0027941133699338483, MSE=0.290±0.010523104230059947
CSDI on data_overlay_premask/physionet_2012_seta: MAE=0.253±0.0052361046497356985, MSE=0.461±0.07388121574246813
GPVAE on data_overlay_premask/physionet_2012_seta: MAE=0.412±0.00737562104327078, MSE=0.484±0.01253173354584285
USGAN on data_overlay_premask/physionet_2012_seta: MAE=0.297±0.0023545020530744993, MSE=0.284±0.005116354698033769
BRITS on data_overlay_premask/physionet_2012_seta: MAE=0.262±0.0004568735770612779, MSE=0.288±0.0034284622736842018
MRNN on data_overlay_premask/physionet_2012_seta: MAE=0.685±0.0007863473759005652, MSE=0.926±0.0018322921772531255
LOCF on data_overlay_premask/physionet_2012_seta: MAE=0.408±0.0, MSE=0.540±0.0
Median on data_overlay_premask/physionet_2012_seta: MAE=0.686±0.0, MSE=1.030±0.0
Mean on data_overlay_premask/physionet_2012_seta: MAE=0.702±0.0, MSE=1.001±0.0