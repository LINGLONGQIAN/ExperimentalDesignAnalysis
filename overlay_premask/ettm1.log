2024-05-22 21:15:13 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-22 21:15:13 [INFO]: Using the given device: cuda:0
2024-05-22 21:15:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240522_T211513
2024-05-22 21:15:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_ettm1/20240522_T211513/tensorboard
2024-05-22 21:15:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 21:15:14 [INFO]: Epoch 001 - training loss: 1.1865, validation loss: 0.2459
2024-05-22 21:15:15 [INFO]: Epoch 002 - training loss: 0.9058, validation loss: 0.1183
2024-05-22 21:15:15 [INFO]: Epoch 003 - training loss: 0.7747, validation loss: 0.0924
2024-05-22 21:15:16 [INFO]: Epoch 004 - training loss: 0.7260, validation loss: 0.0811
2024-05-22 21:15:16 [INFO]: Epoch 005 - training loss: 0.6878, validation loss: 0.0826
2024-05-22 21:15:17 [INFO]: Epoch 006 - training loss: 0.6813, validation loss: 0.0710
2024-05-22 21:15:17 [INFO]: Epoch 007 - training loss: 0.6473, validation loss: 0.0658
2024-05-22 21:15:18 [INFO]: Epoch 008 - training loss: 0.6270, validation loss: 0.0760
2024-05-22 21:15:18 [INFO]: Epoch 009 - training loss: 0.6206, validation loss: 0.0684
2024-05-22 21:15:19 [INFO]: Epoch 010 - training loss: 0.6233, validation loss: 0.0565
2024-05-22 21:15:19 [INFO]: Epoch 011 - training loss: 0.5897, validation loss: 0.0774
2024-05-22 21:15:19 [INFO]: Epoch 012 - training loss: 0.5748, validation loss: 0.0586
2024-05-22 21:15:20 [INFO]: Epoch 013 - training loss: 0.5682, validation loss: 0.0492
2024-05-22 21:15:20 [INFO]: Epoch 014 - training loss: 0.5577, validation loss: 0.0451
2024-05-22 21:15:21 [INFO]: Epoch 015 - training loss: 0.5464, validation loss: 0.0514
2024-05-22 21:15:21 [INFO]: Epoch 016 - training loss: 0.5524, validation loss: 0.0496
2024-05-22 21:15:22 [INFO]: Epoch 017 - training loss: 0.5690, validation loss: 0.0516
2024-05-22 21:15:22 [INFO]: Epoch 018 - training loss: 0.5491, validation loss: 0.0466
2024-05-22 21:15:23 [INFO]: Epoch 019 - training loss: 0.5588, validation loss: 0.0413
2024-05-22 21:15:23 [INFO]: Epoch 020 - training loss: 0.5300, validation loss: 0.0413
2024-05-22 21:15:24 [INFO]: Epoch 021 - training loss: 0.5338, validation loss: 0.0407
2024-05-22 21:15:24 [INFO]: Epoch 022 - training loss: 0.5265, validation loss: 0.0448
2024-05-22 21:15:25 [INFO]: Epoch 023 - training loss: 0.5096, validation loss: 0.0425
2024-05-22 21:15:25 [INFO]: Epoch 024 - training loss: 0.5010, validation loss: 0.0459
2024-05-22 21:15:26 [INFO]: Epoch 025 - training loss: 0.5006, validation loss: 0.0401
2024-05-22 21:15:26 [INFO]: Epoch 026 - training loss: 0.5073, validation loss: 0.0403
2024-05-22 21:15:27 [INFO]: Epoch 027 - training loss: 0.4895, validation loss: 0.0425
2024-05-22 21:15:27 [INFO]: Epoch 028 - training loss: 0.4865, validation loss: 0.0456
2024-05-22 21:15:28 [INFO]: Epoch 029 - training loss: 0.4820, validation loss: 0.0477
2024-05-22 21:15:28 [INFO]: Epoch 030 - training loss: 0.4898, validation loss: 0.0351
2024-05-22 21:15:29 [INFO]: Epoch 031 - training loss: 0.5054, validation loss: 0.0348
2024-05-22 21:15:29 [INFO]: Epoch 032 - training loss: 0.4865, validation loss: 0.0398
2024-05-22 21:15:30 [INFO]: Epoch 033 - training loss: 0.4681, validation loss: 0.0379
2024-05-22 21:15:30 [INFO]: Epoch 034 - training loss: 0.4671, validation loss: 0.0444
2024-05-22 21:15:31 [INFO]: Epoch 035 - training loss: 0.4575, validation loss: 0.0391
2024-05-22 21:15:31 [INFO]: Epoch 036 - training loss: 0.4450, validation loss: 0.0362
2024-05-22 21:15:31 [INFO]: Epoch 037 - training loss: 0.4412, validation loss: 0.0332
2024-05-22 21:15:32 [INFO]: Epoch 038 - training loss: 0.4304, validation loss: 0.0340
2024-05-22 21:15:32 [INFO]: Epoch 039 - training loss: 0.4209, validation loss: 0.0342
2024-05-22 21:15:33 [INFO]: Epoch 040 - training loss: 0.4087, validation loss: 0.0372
2024-05-22 21:15:33 [INFO]: Epoch 041 - training loss: 0.4186, validation loss: 0.0750
2024-05-22 21:15:34 [INFO]: Epoch 042 - training loss: 0.4172, validation loss: 0.0357
2024-05-22 21:15:34 [INFO]: Epoch 043 - training loss: 0.4073, validation loss: 0.0332
2024-05-22 21:15:35 [INFO]: Epoch 044 - training loss: 0.4060, validation loss: 0.0329
2024-05-22 21:15:35 [INFO]: Epoch 045 - training loss: 0.3959, validation loss: 0.0412
2024-05-22 21:15:36 [INFO]: Epoch 046 - training loss: 0.3975, validation loss: 0.0418
2024-05-22 21:15:36 [INFO]: Epoch 047 - training loss: 0.4138, validation loss: 0.0359
2024-05-22 21:15:37 [INFO]: Epoch 048 - training loss: 0.3883, validation loss: 0.0402
2024-05-22 21:15:37 [INFO]: Epoch 049 - training loss: 0.3738, validation loss: 0.0314
2024-05-22 21:15:38 [INFO]: Epoch 050 - training loss: 0.3716, validation loss: 0.0339
2024-05-22 21:15:38 [INFO]: Epoch 051 - training loss: 0.3651, validation loss: 0.0316
2024-05-22 21:15:39 [INFO]: Epoch 052 - training loss: 0.3544, validation loss: 0.0339
2024-05-22 21:15:39 [INFO]: Epoch 053 - training loss: 0.3600, validation loss: 0.0333
2024-05-22 21:15:40 [INFO]: Epoch 054 - training loss: 0.3522, validation loss: 0.0271
2024-05-22 21:15:40 [INFO]: Epoch 055 - training loss: 0.3494, validation loss: 0.0314
2024-05-22 21:15:41 [INFO]: Epoch 056 - training loss: 0.3464, validation loss: 0.0448
2024-05-22 21:15:41 [INFO]: Epoch 057 - training loss: 0.3470, validation loss: 0.0337
2024-05-22 21:15:41 [INFO]: Epoch 058 - training loss: 0.3426, validation loss: 0.0455
2024-05-22 21:15:42 [INFO]: Epoch 059 - training loss: 0.3462, validation loss: 0.0396
2024-05-22 21:15:42 [INFO]: Epoch 060 - training loss: 0.3397, validation loss: 0.0363
2024-05-22 21:15:43 [INFO]: Epoch 061 - training loss: 0.3357, validation loss: 0.0296
2024-05-22 21:15:43 [INFO]: Epoch 062 - training loss: 0.3424, validation loss: 0.0432
2024-05-22 21:15:44 [INFO]: Epoch 063 - training loss: 0.3259, validation loss: 0.0252
2024-05-22 21:15:44 [INFO]: Epoch 064 - training loss: 0.3237, validation loss: 0.0318
2024-05-22 21:15:45 [INFO]: Epoch 065 - training loss: 0.3123, validation loss: 0.0371
2024-05-22 21:15:45 [INFO]: Epoch 066 - training loss: 0.3104, validation loss: 0.0394
2024-05-22 21:15:46 [INFO]: Epoch 067 - training loss: 0.3182, validation loss: 0.0366
2024-05-22 21:15:46 [INFO]: Epoch 068 - training loss: 0.3130, validation loss: 0.0279
2024-05-22 21:15:47 [INFO]: Epoch 069 - training loss: 0.3060, validation loss: 0.0327
2024-05-22 21:15:47 [INFO]: Epoch 070 - training loss: 0.3154, validation loss: 0.0321
2024-05-22 21:15:48 [INFO]: Epoch 071 - training loss: 0.3107, validation loss: 0.0244
2024-05-22 21:15:48 [INFO]: Epoch 072 - training loss: 0.3023, validation loss: 0.0344
2024-05-22 21:15:49 [INFO]: Epoch 073 - training loss: 0.3053, validation loss: 0.0412
2024-05-22 21:15:49 [INFO]: Epoch 074 - training loss: 0.3113, validation loss: 0.0348
2024-05-22 21:15:50 [INFO]: Epoch 075 - training loss: 0.3262, validation loss: 0.0350
2024-05-22 21:15:50 [INFO]: Epoch 076 - training loss: 0.3194, validation loss: 0.0336
2024-05-22 21:15:51 [INFO]: Epoch 077 - training loss: 0.3029, validation loss: 0.0265
2024-05-22 21:15:51 [INFO]: Epoch 078 - training loss: 0.3072, validation loss: 0.0340
2024-05-22 21:15:52 [INFO]: Epoch 079 - training loss: 0.3119, validation loss: 0.0442
2024-05-22 21:15:52 [INFO]: Epoch 080 - training loss: 0.3029, validation loss: 0.0318
2024-05-22 21:15:52 [INFO]: Epoch 081 - training loss: 0.2925, validation loss: 0.0267
2024-05-22 21:15:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:15:52 [INFO]: Finished training. The best model is from epoch#71.
2024-05-22 21:15:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_ettm1/20240522_T211513/SAITS.pypots
2024-05-22 21:15:53 [INFO]: SAITS on ETTm1: MAE=0.1446, MSE=0.0434
2024-05-22 21:15:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-22 21:15:53 [INFO]: Using the given device: cuda:0
2024-05-22 21:15:53 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240522_T211553
2024-05-22 21:15:53 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_ettm1/20240522_T211553/tensorboard
2024-05-22 21:15:53 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 21:15:53 [INFO]: Epoch 001 - training loss: 1.1551, validation loss: 0.3007
2024-05-22 21:15:53 [INFO]: Epoch 002 - training loss: 0.6540, validation loss: 0.1478
2024-05-22 21:15:53 [INFO]: Epoch 003 - training loss: 0.5283, validation loss: 0.1044
2024-05-22 21:15:53 [INFO]: Epoch 004 - training loss: 0.4815, validation loss: 0.0932
2024-05-22 21:15:54 [INFO]: Epoch 005 - training loss: 0.4458, validation loss: 0.0763
2024-05-22 21:15:54 [INFO]: Epoch 006 - training loss: 0.4270, validation loss: 0.0745
2024-05-22 21:15:54 [INFO]: Epoch 007 - training loss: 0.4104, validation loss: 0.0631
2024-05-22 21:15:54 [INFO]: Epoch 008 - training loss: 0.3948, validation loss: 0.0611
2024-05-22 21:15:54 [INFO]: Epoch 009 - training loss: 0.3846, validation loss: 0.0589
2024-05-22 21:15:55 [INFO]: Epoch 010 - training loss: 0.3697, validation loss: 0.0534
2024-05-22 21:15:55 [INFO]: Epoch 011 - training loss: 0.3608, validation loss: 0.0504
2024-05-22 21:15:55 [INFO]: Epoch 012 - training loss: 0.3520, validation loss: 0.0542
2024-05-22 21:15:55 [INFO]: Epoch 013 - training loss: 0.3495, validation loss: 0.0506
2024-05-22 21:15:55 [INFO]: Epoch 014 - training loss: 0.3409, validation loss: 0.0441
2024-05-22 21:15:55 [INFO]: Epoch 015 - training loss: 0.3260, validation loss: 0.0422
2024-05-22 21:15:56 [INFO]: Epoch 016 - training loss: 0.3190, validation loss: 0.0427
2024-05-22 21:15:56 [INFO]: Epoch 017 - training loss: 0.3137, validation loss: 0.0437
2024-05-22 21:15:56 [INFO]: Epoch 018 - training loss: 0.3161, validation loss: 0.0389
2024-05-22 21:15:56 [INFO]: Epoch 019 - training loss: 0.3148, validation loss: 0.0435
2024-05-22 21:15:56 [INFO]: Epoch 020 - training loss: 0.3039, validation loss: 0.0379
2024-05-22 21:15:57 [INFO]: Epoch 021 - training loss: 0.3021, validation loss: 0.0376
2024-05-22 21:15:57 [INFO]: Epoch 022 - training loss: 0.2978, validation loss: 0.0411
2024-05-22 21:15:57 [INFO]: Epoch 023 - training loss: 0.2961, validation loss: 0.0363
2024-05-22 21:15:57 [INFO]: Epoch 024 - training loss: 0.2882, validation loss: 0.0391
2024-05-22 21:15:57 [INFO]: Epoch 025 - training loss: 0.2883, validation loss: 0.0335
2024-05-22 21:15:58 [INFO]: Epoch 026 - training loss: 0.2754, validation loss: 0.0335
2024-05-22 21:15:58 [INFO]: Epoch 027 - training loss: 0.2798, validation loss: 0.0362
2024-05-22 21:15:58 [INFO]: Epoch 028 - training loss: 0.2755, validation loss: 0.0347
2024-05-22 21:15:58 [INFO]: Epoch 029 - training loss: 0.2742, validation loss: 0.0330
2024-05-22 21:15:58 [INFO]: Epoch 030 - training loss: 0.2705, validation loss: 0.0359
2024-05-22 21:15:58 [INFO]: Epoch 031 - training loss: 0.2710, validation loss: 0.0316
2024-05-22 21:15:59 [INFO]: Epoch 032 - training loss: 0.2580, validation loss: 0.0312
2024-05-22 21:15:59 [INFO]: Epoch 033 - training loss: 0.2585, validation loss: 0.0311
2024-05-22 21:15:59 [INFO]: Epoch 034 - training loss: 0.2521, validation loss: 0.0284
2024-05-22 21:15:59 [INFO]: Epoch 035 - training loss: 0.2536, validation loss: 0.0344
2024-05-22 21:15:59 [INFO]: Epoch 036 - training loss: 0.2581, validation loss: 0.0287
2024-05-22 21:16:00 [INFO]: Epoch 037 - training loss: 0.2480, validation loss: 0.0279
2024-05-22 21:16:00 [INFO]: Epoch 038 - training loss: 0.2439, validation loss: 0.0317
2024-05-22 21:16:00 [INFO]: Epoch 039 - training loss: 0.2490, validation loss: 0.0295
2024-05-22 21:16:00 [INFO]: Epoch 040 - training loss: 0.2471, validation loss: 0.0276
2024-05-22 21:16:00 [INFO]: Epoch 041 - training loss: 0.2414, validation loss: 0.0275
2024-05-22 21:16:01 [INFO]: Epoch 042 - training loss: 0.2411, validation loss: 0.0272
2024-05-22 21:16:01 [INFO]: Epoch 043 - training loss: 0.2314, validation loss: 0.0262
2024-05-22 21:16:01 [INFO]: Epoch 044 - training loss: 0.2287, validation loss: 0.0288
2024-05-22 21:16:01 [INFO]: Epoch 045 - training loss: 0.2306, validation loss: 0.0312
2024-05-22 21:16:01 [INFO]: Epoch 046 - training loss: 0.2347, validation loss: 0.0281
2024-05-22 21:16:02 [INFO]: Epoch 047 - training loss: 0.2282, validation loss: 0.0274
2024-05-22 21:16:02 [INFO]: Epoch 048 - training loss: 0.2276, validation loss: 0.0271
2024-05-22 21:16:02 [INFO]: Epoch 049 - training loss: 0.2278, validation loss: 0.0241
2024-05-22 21:16:02 [INFO]: Epoch 050 - training loss: 0.2263, validation loss: 0.0243
2024-05-22 21:16:02 [INFO]: Epoch 051 - training loss: 0.2252, validation loss: 0.0267
2024-05-22 21:16:03 [INFO]: Epoch 052 - training loss: 0.2206, validation loss: 0.0281
2024-05-22 21:16:03 [INFO]: Epoch 053 - training loss: 0.2246, validation loss: 0.0261
2024-05-22 21:16:03 [INFO]: Epoch 054 - training loss: 0.2150, validation loss: 0.0252
2024-05-22 21:16:03 [INFO]: Epoch 055 - training loss: 0.2134, validation loss: 0.0244
2024-05-22 21:16:03 [INFO]: Epoch 056 - training loss: 0.2129, validation loss: 0.0248
2024-05-22 21:16:03 [INFO]: Epoch 057 - training loss: 0.2140, validation loss: 0.0252
2024-05-22 21:16:04 [INFO]: Epoch 058 - training loss: 0.2178, validation loss: 0.0256
2024-05-22 21:16:04 [INFO]: Epoch 059 - training loss: 0.2087, validation loss: 0.0252
2024-05-22 21:16:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:16:04 [INFO]: Finished training. The best model is from epoch#49.
2024-05-22 21:16:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_ettm1/20240522_T211553/Transformer.pypots
2024-05-22 21:16:04 [INFO]: Transformer on ETTm1: MAE=0.1351, MSE=0.0377
2024-05-22 21:16:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-22 21:16:04 [INFO]: Using the given device: cuda:0
2024-05-22 21:16:04 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211604
2024-05-22 21:16:04 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211604/tensorboard
2024-05-22 21:16:04 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 21:16:05 [INFO]: Epoch 001 - training loss: 0.1412, validation loss: 0.0501
2024-05-22 21:16:05 [INFO]: Epoch 002 - training loss: 0.0630, validation loss: 0.0371
2024-05-22 21:16:05 [INFO]: Epoch 003 - training loss: 0.0494, validation loss: 0.0314
2024-05-22 21:16:05 [INFO]: Epoch 004 - training loss: 0.0395, validation loss: 0.0283
2024-05-22 21:16:05 [INFO]: Epoch 005 - training loss: 0.0393, validation loss: 0.0279
2024-05-22 21:16:06 [INFO]: Epoch 006 - training loss: 0.0409, validation loss: 0.0283
2024-05-22 21:16:06 [INFO]: Epoch 007 - training loss: 0.0376, validation loss: 0.0261
2024-05-22 21:16:06 [INFO]: Epoch 008 - training loss: 0.0364, validation loss: 0.0251
2024-05-22 21:16:06 [INFO]: Epoch 009 - training loss: 0.0326, validation loss: 0.0252
2024-05-22 21:16:06 [INFO]: Epoch 010 - training loss: 0.0311, validation loss: 0.0238
2024-05-22 21:16:06 [INFO]: Epoch 011 - training loss: 0.0299, validation loss: 0.0232
2024-05-22 21:16:07 [INFO]: Epoch 012 - training loss: 0.0303, validation loss: 0.0237
2024-05-22 21:16:07 [INFO]: Epoch 013 - training loss: 0.0309, validation loss: 0.0249
2024-05-22 21:16:07 [INFO]: Epoch 014 - training loss: 0.0312, validation loss: 0.0261
2024-05-22 21:16:07 [INFO]: Epoch 015 - training loss: 0.0303, validation loss: 0.0251
2024-05-22 21:16:07 [INFO]: Epoch 016 - training loss: 0.0286, validation loss: 0.0240
2024-05-22 21:16:08 [INFO]: Epoch 017 - training loss: 0.0296, validation loss: 0.0247
2024-05-22 21:16:08 [INFO]: Epoch 018 - training loss: 0.0302, validation loss: 0.0271
2024-05-22 21:16:08 [INFO]: Epoch 019 - training loss: 0.0308, validation loss: 0.0268
2024-05-22 21:16:08 [INFO]: Epoch 020 - training loss: 0.0308, validation loss: 0.0237
2024-05-22 21:16:08 [INFO]: Epoch 021 - training loss: 0.0295, validation loss: 0.0246
2024-05-22 21:16:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:16:08 [INFO]: Finished training. The best model is from epoch#11.
2024-05-22 21:16:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_ettm1/20240522_T211604/TimesNet.pypots
2024-05-22 21:16:08 [INFO]: TimesNet on ETTm1: MAE=0.1097, MSE=0.0264
2024-05-22 21:16:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-22 21:16:08 [INFO]: Using the given device: cuda:0
2024-05-22 21:16:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608
2024-05-22 21:16:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/tensorboard
/scratch/users/k1814348/.conda/envs/pypots/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2024-05-22 21:16:08 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 21:16:10 [INFO]: Epoch 001 - training loss: 0.6685, validation loss: 0.4178
2024-05-22 21:16:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch1_loss0.4178362712264061.pypots
2024-05-22 21:16:13 [INFO]: Epoch 002 - training loss: 0.3567, validation loss: 0.3614
2024-05-22 21:16:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch2_loss0.3614343926310539.pypots
2024-05-22 21:16:15 [INFO]: Epoch 003 - training loss: 0.3369, validation loss: 0.3270
2024-05-22 21:16:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch3_loss0.3269610032439232.pypots
2024-05-22 21:16:17 [INFO]: Epoch 004 - training loss: 0.3092, validation loss: 0.3108
2024-05-22 21:16:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch4_loss0.3108086735010147.pypots
2024-05-22 21:16:19 [INFO]: Epoch 005 - training loss: 0.2648, validation loss: 0.2740
2024-05-22 21:16:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch5_loss0.27401676774024963.pypots
2024-05-22 21:16:21 [INFO]: Epoch 006 - training loss: 0.3185, validation loss: 0.2676
2024-05-22 21:16:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch6_loss0.26759447157382965.pypots
2024-05-22 21:16:23 [INFO]: Epoch 007 - training loss: 0.2314, validation loss: 0.2616
2024-05-22 21:16:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch7_loss0.26158154755830765.pypots
2024-05-22 21:16:25 [INFO]: Epoch 008 - training loss: 0.2838, validation loss: 0.2484
2024-05-22 21:16:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch8_loss0.24841728433966637.pypots
2024-05-22 21:16:27 [INFO]: Epoch 009 - training loss: 0.3058, validation loss: 0.2618
2024-05-22 21:16:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch9_loss0.26179173588752747.pypots
2024-05-22 21:16:29 [INFO]: Epoch 010 - training loss: 0.2646, validation loss: 0.2551
2024-05-22 21:16:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch10_loss0.25510673969984055.pypots
2024-05-22 21:16:31 [INFO]: Epoch 011 - training loss: 0.2917, validation loss: 0.2499
2024-05-22 21:16:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch11_loss0.24993722885847092.pypots
2024-05-22 21:16:33 [INFO]: Epoch 012 - training loss: 0.2415, validation loss: 0.2593
2024-05-22 21:16:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch12_loss0.25932617485523224.pypots
2024-05-22 21:16:35 [INFO]: Epoch 013 - training loss: 0.2412, validation loss: 0.2221
2024-05-22 21:16:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch13_loss0.22205238044261932.pypots
2024-05-22 21:16:37 [INFO]: Epoch 014 - training loss: 0.2123, validation loss: 0.2130
2024-05-22 21:16:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch14_loss0.21304337680339813.pypots
2024-05-22 21:16:39 [INFO]: Epoch 015 - training loss: 0.2208, validation loss: 0.2191
2024-05-22 21:16:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch15_loss0.2191421277821064.pypots
2024-05-22 21:16:41 [INFO]: Epoch 016 - training loss: 0.2144, validation loss: 0.2004
2024-05-22 21:16:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch16_loss0.20043988525867462.pypots
2024-05-22 21:16:43 [INFO]: Epoch 017 - training loss: 0.2129, validation loss: 0.2151
2024-05-22 21:16:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch17_loss0.21506255492568016.pypots
2024-05-22 21:16:45 [INFO]: Epoch 018 - training loss: 0.2432, validation loss: 0.2023
2024-05-22 21:16:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch18_loss0.2023109346628189.pypots
2024-05-22 21:16:47 [INFO]: Epoch 019 - training loss: 0.2467, validation loss: 0.2202
2024-05-22 21:16:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch19_loss0.22016798704862595.pypots
2024-05-22 21:16:49 [INFO]: Epoch 020 - training loss: 0.2402, validation loss: 0.2171
2024-05-22 21:16:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch20_loss0.2170679122209549.pypots
2024-05-22 21:16:51 [INFO]: Epoch 021 - training loss: 0.2276, validation loss: 0.2037
2024-05-22 21:16:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch21_loss0.20371609553694725.pypots
2024-05-22 21:16:53 [INFO]: Epoch 022 - training loss: 0.1929, validation loss: 0.1898
2024-05-22 21:16:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch22_loss0.1898101530969143.pypots
2024-05-22 21:16:55 [INFO]: Epoch 023 - training loss: 0.1942, validation loss: 0.1853
2024-05-22 21:16:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch23_loss0.18532434478402138.pypots
2024-05-22 21:16:57 [INFO]: Epoch 024 - training loss: 0.1907, validation loss: 0.1759
2024-05-22 21:16:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch24_loss0.17589250579476357.pypots
2024-05-22 21:16:59 [INFO]: Epoch 025 - training loss: 0.1924, validation loss: 0.1697
2024-05-22 21:16:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch25_loss0.16972488909959793.pypots
2024-05-22 21:17:01 [INFO]: Epoch 026 - training loss: 0.2134, validation loss: 0.1749
2024-05-22 21:17:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch26_loss0.17488453537225723.pypots
2024-05-22 21:17:03 [INFO]: Epoch 027 - training loss: 0.2057, validation loss: 0.1918
2024-05-22 21:17:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch27_loss0.1917700432240963.pypots
2024-05-22 21:17:05 [INFO]: Epoch 028 - training loss: 0.1989, validation loss: 0.1860
2024-05-22 21:17:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch28_loss0.18601812794804573.pypots
2024-05-22 21:17:07 [INFO]: Epoch 029 - training loss: 0.1840, validation loss: 0.1770
2024-05-22 21:17:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch29_loss0.17701569572091103.pypots
2024-05-22 21:17:09 [INFO]: Epoch 030 - training loss: 0.1718, validation loss: 0.1752
2024-05-22 21:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch30_loss0.17523367330431938.pypots
2024-05-22 21:17:11 [INFO]: Epoch 031 - training loss: 0.1923, validation loss: 0.1754
2024-05-22 21:17:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch31_loss0.1754031926393509.pypots
2024-05-22 21:17:13 [INFO]: Epoch 032 - training loss: 0.1931, validation loss: 0.1662
2024-05-22 21:17:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch32_loss0.16620856896042824.pypots
2024-05-22 21:17:15 [INFO]: Epoch 033 - training loss: 0.1781, validation loss: 0.1710
2024-05-22 21:17:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch33_loss0.17096953094005585.pypots
2024-05-22 21:17:17 [INFO]: Epoch 034 - training loss: 0.1430, validation loss: 0.1612
2024-05-22 21:17:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch34_loss0.16124633327126503.pypots
2024-05-22 21:17:19 [INFO]: Epoch 035 - training loss: 0.1719, validation loss: 0.1550
2024-05-22 21:17:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch35_loss0.15502651408314705.pypots
2024-05-22 21:17:21 [INFO]: Epoch 036 - training loss: 0.1670, validation loss: 0.1525
2024-05-22 21:17:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch36_loss0.15245617181062698.pypots
2024-05-22 21:17:23 [INFO]: Epoch 037 - training loss: 0.1915, validation loss: 0.1512
2024-05-22 21:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch37_loss0.15121585130691528.pypots
2024-05-22 21:17:25 [INFO]: Epoch 038 - training loss: 0.1501, validation loss: 0.1563
2024-05-22 21:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch38_loss0.1562933661043644.pypots
2024-05-22 21:17:27 [INFO]: Epoch 039 - training loss: 0.1705, validation loss: 0.1478
2024-05-22 21:17:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch39_loss0.1477961614727974.pypots
2024-05-22 21:17:29 [INFO]: Epoch 040 - training loss: 0.1452, validation loss: 0.1449
2024-05-22 21:17:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch40_loss0.14485954493284225.pypots
2024-05-22 21:17:31 [INFO]: Epoch 041 - training loss: 0.2124, validation loss: 0.1961
2024-05-22 21:17:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch41_loss0.19605766236782074.pypots
2024-05-22 21:17:33 [INFO]: Epoch 042 - training loss: 0.2579, validation loss: 0.1851
2024-05-22 21:17:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch42_loss0.18509434908628464.pypots
2024-05-22 21:17:35 [INFO]: Epoch 043 - training loss: 0.2006, validation loss: 0.1755
2024-05-22 21:17:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch43_loss0.17549502104520798.pypots
2024-05-22 21:17:37 [INFO]: Epoch 044 - training loss: 0.1855, validation loss: 0.1711
2024-05-22 21:17:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch44_loss0.17109804973006248.pypots
2024-05-22 21:17:39 [INFO]: Epoch 045 - training loss: 0.2213, validation loss: 0.1619
2024-05-22 21:17:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch45_loss0.16188447177410126.pypots
2024-05-22 21:17:42 [INFO]: Epoch 046 - training loss: 0.1559, validation loss: 0.1505
2024-05-22 21:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch46_loss0.15052581951022148.pypots
2024-05-22 21:17:44 [INFO]: Epoch 047 - training loss: 0.1592, validation loss: 0.1502
2024-05-22 21:17:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch47_loss0.15021492913365364.pypots
2024-05-22 21:17:46 [INFO]: Epoch 048 - training loss: 0.1497, validation loss: 0.1468
2024-05-22 21:17:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch48_loss0.14682668074965477.pypots
2024-05-22 21:17:48 [INFO]: Epoch 049 - training loss: 0.1425, validation loss: 0.1431
2024-05-22 21:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch49_loss0.14314984157681465.pypots
2024-05-22 21:17:50 [INFO]: Epoch 050 - training loss: 0.1371, validation loss: 0.1411
2024-05-22 21:17:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch50_loss0.1411258615553379.pypots
2024-05-22 21:17:52 [INFO]: Epoch 051 - training loss: 0.1475, validation loss: 0.1400
2024-05-22 21:17:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch51_loss0.1400301307439804.pypots
2024-05-22 21:17:54 [INFO]: Epoch 052 - training loss: 0.1611, validation loss: 0.1412
2024-05-22 21:17:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch52_loss0.14120874926447868.pypots
2024-05-22 21:17:56 [INFO]: Epoch 053 - training loss: 0.1558, validation loss: 0.1400
2024-05-22 21:17:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch53_loss0.1400141380727291.pypots
2024-05-22 21:17:58 [INFO]: Epoch 054 - training loss: 0.1379, validation loss: 0.1480
2024-05-22 21:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch54_loss0.14804106950759888.pypots
2024-05-22 21:18:00 [INFO]: Epoch 055 - training loss: 0.1397, validation loss: 0.1405
2024-05-22 21:18:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch55_loss0.1404605507850647.pypots
2024-05-22 21:18:02 [INFO]: Epoch 056 - training loss: 0.1474, validation loss: 0.1462
2024-05-22 21:18:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch56_loss0.14620869234204292.pypots
2024-05-22 21:18:04 [INFO]: Epoch 057 - training loss: 0.1422, validation loss: 0.1391
2024-05-22 21:18:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch57_loss0.13906968757510185.pypots
2024-05-22 21:18:06 [INFO]: Epoch 058 - training loss: 0.1576, validation loss: 0.1346
2024-05-22 21:18:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch58_loss0.13456706702709198.pypots
2024-05-22 21:18:08 [INFO]: Epoch 059 - training loss: 0.1382, validation loss: 0.1311
2024-05-22 21:18:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch59_loss0.1310989335179329.pypots
2024-05-22 21:18:10 [INFO]: Epoch 060 - training loss: 0.1321, validation loss: 0.1297
2024-05-22 21:18:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch60_loss0.1297351885586977.pypots
2024-05-22 21:18:12 [INFO]: Epoch 061 - training loss: 0.1211, validation loss: 0.1338
2024-05-22 21:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch61_loss0.1338295079767704.pypots
2024-05-22 21:18:14 [INFO]: Epoch 062 - training loss: 0.1838, validation loss: 0.1327
2024-05-22 21:18:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch62_loss0.13272136077284813.pypots
2024-05-22 21:18:16 [INFO]: Epoch 063 - training loss: 0.1717, validation loss: 0.1456
2024-05-22 21:18:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch63_loss0.14555251225829124.pypots
2024-05-22 21:18:18 [INFO]: Epoch 064 - training loss: 0.1736, validation loss: 0.1414
2024-05-22 21:18:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch64_loss0.1413799487054348.pypots
2024-05-22 21:18:20 [INFO]: Epoch 065 - training loss: 0.1499, validation loss: 0.1428
2024-05-22 21:18:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch65_loss0.14280356094241142.pypots
2024-05-22 21:18:22 [INFO]: Epoch 066 - training loss: 0.1600, validation loss: 0.1358
2024-05-22 21:18:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch66_loss0.1358230710029602.pypots
2024-05-22 21:18:24 [INFO]: Epoch 067 - training loss: 0.1245, validation loss: 0.1309
2024-05-22 21:18:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch67_loss0.13092735037207603.pypots
2024-05-22 21:18:26 [INFO]: Epoch 068 - training loss: 0.1933, validation loss: 0.1294
2024-05-22 21:18:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch68_loss0.12935460731387138.pypots
2024-05-22 21:18:28 [INFO]: Epoch 069 - training loss: 0.1204, validation loss: 0.1331
2024-05-22 21:18:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch69_loss0.13314424268901348.pypots
2024-05-22 21:18:30 [INFO]: Epoch 070 - training loss: 0.1549, validation loss: 0.1466
2024-05-22 21:18:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch70_loss0.14660128206014633.pypots
2024-05-22 21:18:32 [INFO]: Epoch 071 - training loss: 0.1491, validation loss: 0.1395
2024-05-22 21:18:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch71_loss0.13948151096701622.pypots
2024-05-22 21:18:34 [INFO]: Epoch 072 - training loss: 0.1485, validation loss: 0.1342
2024-05-22 21:18:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch72_loss0.13417018204927444.pypots
2024-05-22 21:18:36 [INFO]: Epoch 073 - training loss: 0.1311, validation loss: 0.1355
2024-05-22 21:18:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch73_loss0.1355246566236019.pypots
2024-05-22 21:18:38 [INFO]: Epoch 074 - training loss: 0.1434, validation loss: 0.1317
2024-05-22 21:18:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch74_loss0.1316884197294712.pypots
2024-05-22 21:18:40 [INFO]: Epoch 075 - training loss: 0.1213, validation loss: 0.1270
2024-05-22 21:18:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch75_loss0.12699149549007416.pypots
2024-05-22 21:18:42 [INFO]: Epoch 076 - training loss: 0.1356, validation loss: 0.1337
2024-05-22 21:18:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch76_loss0.13371550664305687.pypots
2024-05-22 21:18:44 [INFO]: Epoch 077 - training loss: 0.1768, validation loss: 0.1283
2024-05-22 21:18:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch77_loss0.12829756550490856.pypots
2024-05-22 21:18:46 [INFO]: Epoch 078 - training loss: 0.1416, validation loss: 0.1261
2024-05-22 21:18:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch78_loss0.12607569806277752.pypots
2024-05-22 21:18:48 [INFO]: Epoch 079 - training loss: 0.1378, validation loss: 0.1240
2024-05-22 21:18:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch79_loss0.12404477223753929.pypots
2024-05-22 21:18:50 [INFO]: Epoch 080 - training loss: 0.1353, validation loss: 0.1225
2024-05-22 21:18:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch80_loss0.12248909845948219.pypots
2024-05-22 21:18:52 [INFO]: Epoch 081 - training loss: 0.1155, validation loss: 0.1218
2024-05-22 21:18:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch81_loss0.12175655364990234.pypots
2024-05-22 21:18:54 [INFO]: Epoch 082 - training loss: 0.1704, validation loss: 0.1447
2024-05-22 21:18:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch82_loss0.14470108970999718.pypots
2024-05-22 21:18:56 [INFO]: Epoch 083 - training loss: 0.1463, validation loss: 0.1449
2024-05-22 21:18:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch83_loss0.14487529546022415.pypots
2024-05-22 21:18:58 [INFO]: Epoch 084 - training loss: 0.1413, validation loss: 0.1305
2024-05-22 21:18:58 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch84_loss0.1305057257413864.pypots
2024-05-22 21:19:00 [INFO]: Epoch 085 - training loss: 0.1292, validation loss: 0.1274
2024-05-22 21:19:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch85_loss0.1273868214339018.pypots
2024-05-22 21:19:02 [INFO]: Epoch 086 - training loss: 0.1517, validation loss: 0.1294
2024-05-22 21:19:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch86_loss0.12935899198055267.pypots
2024-05-22 21:19:04 [INFO]: Epoch 087 - training loss: 0.1231, validation loss: 0.1272
2024-05-22 21:19:04 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch87_loss0.12717537954449654.pypots
2024-05-22 21:19:06 [INFO]: Epoch 088 - training loss: 0.2001, validation loss: 0.1279
2024-05-22 21:19:06 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch88_loss0.12793308682739735.pypots
2024-05-22 21:19:08 [INFO]: Epoch 089 - training loss: 0.1211, validation loss: 0.1239
2024-05-22 21:19:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch89_loss0.12386937439441681.pypots
2024-05-22 21:19:10 [INFO]: Epoch 090 - training loss: 0.1425, validation loss: 0.1221
2024-05-22 21:19:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch90_loss0.12206096015870571.pypots
2024-05-22 21:19:12 [INFO]: Epoch 091 - training loss: 0.1487, validation loss: 0.1271
2024-05-22 21:19:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI_epoch91_loss0.12712624110281467.pypots
2024-05-22 21:19:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:19:12 [INFO]: Finished training. The best model is from epoch#81.
2024-05-22 21:19:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_ettm1/20240522_T211608/CSDI.pypots
2024-05-22 21:19:28 [INFO]: CSDI on ETTm1: MAE=0.1221, MSE=0.0337
2024-05-22 21:19:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-22 21:19:28 [INFO]: Using the given device: cuda:0
2024-05-22 21:19:28 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211928
2024-05-22 21:19:28 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211928/tensorboard
2024-05-22 21:19:28 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 21:19:28 [INFO]: Epoch 001 - training loss: 23468.4575, validation loss: 0.9549
2024-05-22 21:19:28 [INFO]: Epoch 002 - training loss: 21314.3348, validation loss: 0.9518
2024-05-22 21:19:28 [INFO]: Epoch 003 - training loss: 19329.1940, validation loss: 0.9419
2024-05-22 21:19:29 [INFO]: Epoch 004 - training loss: 17298.1929, validation loss: 0.9241
2024-05-22 21:19:29 [INFO]: Epoch 005 - training loss: 15382.4250, validation loss: 0.8773
2024-05-22 21:19:29 [INFO]: Epoch 006 - training loss: 13958.4847, validation loss: 0.7738
2024-05-22 21:19:29 [INFO]: Epoch 007 - training loss: 12829.4020, validation loss: 0.6517
2024-05-22 21:19:29 [INFO]: Epoch 008 - training loss: 11927.9026, validation loss: 0.5826
2024-05-22 21:19:29 [INFO]: Epoch 009 - training loss: 11407.2029, validation loss: 0.5531
2024-05-22 21:19:29 [INFO]: Epoch 010 - training loss: 10909.1321, validation loss: 0.5019
2024-05-22 21:19:29 [INFO]: Epoch 011 - training loss: 10594.4200, validation loss: 0.4689
2024-05-22 21:19:29 [INFO]: Epoch 012 - training loss: 10531.4860, validation loss: 0.4488
2024-05-22 21:19:30 [INFO]: Epoch 013 - training loss: 10236.6339, validation loss: 0.4279
2024-05-22 21:19:30 [INFO]: Epoch 014 - training loss: 10076.9696, validation loss: 0.4095
2024-05-22 21:19:30 [INFO]: Epoch 015 - training loss: 9995.5524, validation loss: 0.3935
2024-05-22 21:19:30 [INFO]: Epoch 016 - training loss: 9898.7375, validation loss: 0.3723
2024-05-22 21:19:30 [INFO]: Epoch 017 - training loss: 9884.3622, validation loss: 0.3658
2024-05-22 21:19:30 [INFO]: Epoch 018 - training loss: 9783.0667, validation loss: 0.3586
2024-05-22 21:19:30 [INFO]: Epoch 019 - training loss: 9717.2375, validation loss: 0.3502
2024-05-22 21:19:30 [INFO]: Epoch 020 - training loss: 9672.0666, validation loss: 0.3447
2024-05-22 21:19:30 [INFO]: Epoch 021 - training loss: 9644.9101, validation loss: 0.3422
2024-05-22 21:19:30 [INFO]: Epoch 022 - training loss: 9613.3323, validation loss: 0.3359
2024-05-22 21:19:31 [INFO]: Epoch 023 - training loss: 9585.0889, validation loss: 0.3226
2024-05-22 21:19:31 [INFO]: Epoch 024 - training loss: 9562.1155, validation loss: 0.3249
2024-05-22 21:19:31 [INFO]: Epoch 025 - training loss: 9539.8237, validation loss: 0.3176
2024-05-22 21:19:31 [INFO]: Epoch 026 - training loss: 9544.7975, validation loss: 0.3125
2024-05-22 21:19:31 [INFO]: Epoch 027 - training loss: 9508.0769, validation loss: 0.3063
2024-05-22 21:19:31 [INFO]: Epoch 028 - training loss: 9486.2292, validation loss: 0.2947
2024-05-22 21:19:31 [INFO]: Epoch 029 - training loss: 9500.6332, validation loss: 0.2897
2024-05-22 21:19:31 [INFO]: Epoch 030 - training loss: 9460.2281, validation loss: 0.2796
2024-05-22 21:19:31 [INFO]: Epoch 031 - training loss: 9449.6635, validation loss: 0.2731
2024-05-22 21:19:31 [INFO]: Epoch 032 - training loss: 9453.7742, validation loss: 0.2665
2024-05-22 21:19:32 [INFO]: Epoch 033 - training loss: 9441.9166, validation loss: 0.2584
2024-05-22 21:19:32 [INFO]: Epoch 034 - training loss: 9422.7246, validation loss: 0.2533
2024-05-22 21:19:32 [INFO]: Epoch 035 - training loss: 9417.2656, validation loss: 0.2451
2024-05-22 21:19:32 [INFO]: Epoch 036 - training loss: 9414.2355, validation loss: 0.2374
2024-05-22 21:19:32 [INFO]: Epoch 037 - training loss: 9404.1285, validation loss: 0.2310
2024-05-22 21:19:32 [INFO]: Epoch 038 - training loss: 9402.2933, validation loss: 0.2245
2024-05-22 21:19:32 [INFO]: Epoch 039 - training loss: 9410.2275, validation loss: 0.2207
2024-05-22 21:19:32 [INFO]: Epoch 040 - training loss: 9387.9888, validation loss: 0.2158
2024-05-22 21:19:32 [INFO]: Epoch 041 - training loss: 9385.8016, validation loss: 0.2127
2024-05-22 21:19:33 [INFO]: Epoch 042 - training loss: 9382.6136, validation loss: 0.2057
2024-05-22 21:19:33 [INFO]: Epoch 043 - training loss: 9370.4806, validation loss: 0.2029
2024-05-22 21:19:33 [INFO]: Epoch 044 - training loss: 9388.6271, validation loss: 0.1972
2024-05-22 21:19:33 [INFO]: Epoch 045 - training loss: 9371.7422, validation loss: 0.1913
2024-05-22 21:19:33 [INFO]: Epoch 046 - training loss: 9373.8615, validation loss: 0.1895
2024-05-22 21:19:33 [INFO]: Epoch 047 - training loss: 9352.4265, validation loss: 0.1832
2024-05-22 21:19:33 [INFO]: Epoch 048 - training loss: 9350.5882, validation loss: 0.1814
2024-05-22 21:19:33 [INFO]: Epoch 049 - training loss: 9356.2607, validation loss: 0.1766
2024-05-22 21:19:33 [INFO]: Epoch 050 - training loss: 9345.9808, validation loss: 0.1689
2024-05-22 21:19:33 [INFO]: Epoch 051 - training loss: 9353.2116, validation loss: 0.1670
2024-05-22 21:19:34 [INFO]: Epoch 052 - training loss: 9341.1778, validation loss: 0.1612
2024-05-22 21:19:34 [INFO]: Epoch 053 - training loss: 9400.7554, validation loss: 0.1611
2024-05-22 21:19:34 [INFO]: Epoch 054 - training loss: 9337.4673, validation loss: 0.1586
2024-05-22 21:19:34 [INFO]: Epoch 055 - training loss: 9331.3397, validation loss: 0.1523
2024-05-22 21:19:34 [INFO]: Epoch 056 - training loss: 9330.1769, validation loss: 0.1475
2024-05-22 21:19:34 [INFO]: Epoch 057 - training loss: 9327.4983, validation loss: 0.1465
2024-05-22 21:19:34 [INFO]: Epoch 058 - training loss: 9327.3030, validation loss: 0.1436
2024-05-22 21:19:34 [INFO]: Epoch 059 - training loss: 9329.1184, validation loss: 0.1435
2024-05-22 21:19:34 [INFO]: Epoch 060 - training loss: 9326.0007, validation loss: 0.1398
2024-05-22 21:19:35 [INFO]: Epoch 061 - training loss: 9322.4320, validation loss: 0.1404
2024-05-22 21:19:35 [INFO]: Epoch 062 - training loss: 9330.7190, validation loss: 0.1396
2024-05-22 21:19:35 [INFO]: Epoch 063 - training loss: 9317.2816, validation loss: 0.1333
2024-05-22 21:19:35 [INFO]: Epoch 064 - training loss: 9315.8649, validation loss: 0.1323
2024-05-22 21:19:35 [INFO]: Epoch 065 - training loss: 9314.6447, validation loss: 0.1317
2024-05-22 21:19:35 [INFO]: Epoch 066 - training loss: 9317.6397, validation loss: 0.1302
2024-05-22 21:19:35 [INFO]: Epoch 067 - training loss: 9314.8390, validation loss: 0.1305
2024-05-22 21:19:35 [INFO]: Epoch 068 - training loss: 9311.9063, validation loss: 0.1294
2024-05-22 21:19:35 [INFO]: Epoch 069 - training loss: 9316.1766, validation loss: 0.1275
2024-05-22 21:19:35 [INFO]: Epoch 070 - training loss: 9310.7242, validation loss: 0.1259
2024-05-22 21:19:36 [INFO]: Epoch 071 - training loss: 9311.5926, validation loss: 0.1253
2024-05-22 21:19:36 [INFO]: Epoch 072 - training loss: 9307.6513, validation loss: 0.1246
2024-05-22 21:19:36 [INFO]: Epoch 073 - training loss: 9306.9289, validation loss: 0.1236
2024-05-22 21:19:36 [INFO]: Epoch 074 - training loss: 9310.8033, validation loss: 0.1214
2024-05-22 21:19:36 [INFO]: Epoch 075 - training loss: 9311.1214, validation loss: 0.1189
2024-05-22 21:19:36 [INFO]: Epoch 076 - training loss: 9304.2565, validation loss: 0.1195
2024-05-22 21:19:36 [INFO]: Epoch 077 - training loss: 9303.0563, validation loss: 0.1192
2024-05-22 21:19:36 [INFO]: Epoch 078 - training loss: 9308.3398, validation loss: 0.1193
2024-05-22 21:19:36 [INFO]: Epoch 079 - training loss: 9305.8833, validation loss: 0.1179
2024-05-22 21:19:37 [INFO]: Epoch 080 - training loss: 9303.4457, validation loss: 0.1171
2024-05-22 21:19:37 [INFO]: Epoch 081 - training loss: 9300.0537, validation loss: 0.1176
2024-05-22 21:19:37 [INFO]: Epoch 082 - training loss: 9299.5317, validation loss: 0.1164
2024-05-22 21:19:37 [INFO]: Epoch 083 - training loss: 9299.2147, validation loss: 0.1140
2024-05-22 21:19:37 [INFO]: Epoch 084 - training loss: 9299.4520, validation loss: 0.1146
2024-05-22 21:19:37 [INFO]: Epoch 085 - training loss: 9297.9645, validation loss: 0.1128
2024-05-22 21:19:37 [INFO]: Epoch 086 - training loss: 9296.3555, validation loss: 0.1139
2024-05-22 21:19:37 [INFO]: Epoch 087 - training loss: 9298.0042, validation loss: 0.1119
2024-05-22 21:19:37 [INFO]: Epoch 088 - training loss: 9296.3008, validation loss: 0.1108
2024-05-22 21:19:37 [INFO]: Epoch 089 - training loss: 9294.4349, validation loss: 0.1109
2024-05-22 21:19:38 [INFO]: Epoch 090 - training loss: 9295.4706, validation loss: 0.1114
2024-05-22 21:19:38 [INFO]: Epoch 091 - training loss: 9296.5310, validation loss: 0.1081
2024-05-22 21:19:38 [INFO]: Epoch 092 - training loss: 9296.3817, validation loss: 0.1108
2024-05-22 21:19:38 [INFO]: Epoch 093 - training loss: 9294.0162, validation loss: 0.1074
2024-05-22 21:19:38 [INFO]: Epoch 094 - training loss: 9293.5512, validation loss: 0.1069
2024-05-22 21:19:38 [INFO]: Epoch 095 - training loss: 9292.1564, validation loss: 0.1087
2024-05-22 21:19:38 [INFO]: Epoch 096 - training loss: 9290.8287, validation loss: 0.1059
2024-05-22 21:19:38 [INFO]: Epoch 097 - training loss: 9293.5895, validation loss: 0.1052
2024-05-22 21:19:38 [INFO]: Epoch 098 - training loss: 9291.6272, validation loss: 0.1052
2024-05-22 21:19:39 [INFO]: Epoch 099 - training loss: 9293.4467, validation loss: 0.1075
2024-05-22 21:19:39 [INFO]: Epoch 100 - training loss: 9293.4218, validation loss: 0.1026
2024-05-22 21:19:39 [INFO]: Epoch 101 - training loss: 9290.9403, validation loss: 0.1030
2024-05-22 21:19:39 [INFO]: Epoch 102 - training loss: 9291.9217, validation loss: 0.1039
2024-05-22 21:19:39 [INFO]: Epoch 103 - training loss: 9290.0670, validation loss: 0.1030
2024-05-22 21:19:39 [INFO]: Epoch 104 - training loss: 9290.6946, validation loss: 0.1013
2024-05-22 21:19:39 [INFO]: Epoch 105 - training loss: 9288.5413, validation loss: 0.1015
2024-05-22 21:19:39 [INFO]: Epoch 106 - training loss: 9286.4534, validation loss: 0.1017
2024-05-22 21:19:39 [INFO]: Epoch 107 - training loss: 9290.1673, validation loss: 0.1017
2024-05-22 21:19:39 [INFO]: Epoch 108 - training loss: 9287.0750, validation loss: 0.1004
2024-05-22 21:19:40 [INFO]: Epoch 109 - training loss: 9289.0148, validation loss: 0.0997
2024-05-22 21:19:40 [INFO]: Epoch 110 - training loss: 9286.9539, validation loss: 0.0994
2024-05-22 21:19:40 [INFO]: Epoch 111 - training loss: 9286.0131, validation loss: 0.0996
2024-05-22 21:19:40 [INFO]: Epoch 112 - training loss: 9288.4081, validation loss: 0.0977
2024-05-22 21:19:40 [INFO]: Epoch 113 - training loss: 9286.5950, validation loss: 0.0999
2024-05-22 21:19:40 [INFO]: Epoch 114 - training loss: 9286.4727, validation loss: 0.0976
2024-05-22 21:19:40 [INFO]: Epoch 115 - training loss: 9285.9250, validation loss: 0.0967
2024-05-22 21:19:40 [INFO]: Epoch 116 - training loss: 9284.8867, validation loss: 0.0961
2024-05-22 21:19:40 [INFO]: Epoch 117 - training loss: 9288.1854, validation loss: 0.0971
2024-05-22 21:19:41 [INFO]: Epoch 118 - training loss: 9287.0602, validation loss: 0.0947
2024-05-22 21:19:41 [INFO]: Epoch 119 - training loss: 9283.3729, validation loss: 0.0950
2024-05-22 21:19:41 [INFO]: Epoch 120 - training loss: 9283.1917, validation loss: 0.0945
2024-05-22 21:19:41 [INFO]: Epoch 121 - training loss: 9282.8472, validation loss: 0.0936
2024-05-22 21:19:41 [INFO]: Epoch 122 - training loss: 9283.0845, validation loss: 0.0954
2024-05-22 21:19:41 [INFO]: Epoch 123 - training loss: 9282.4044, validation loss: 0.0936
2024-05-22 21:19:41 [INFO]: Epoch 124 - training loss: 9282.3769, validation loss: 0.0919
2024-05-22 21:19:41 [INFO]: Epoch 125 - training loss: 9281.7437, validation loss: 0.0939
2024-05-22 21:19:41 [INFO]: Epoch 126 - training loss: 9282.8527, validation loss: 0.0931
2024-05-22 21:19:41 [INFO]: Epoch 127 - training loss: 9283.4709, validation loss: 0.0907
2024-05-22 21:19:42 [INFO]: Epoch 128 - training loss: 9281.8699, validation loss: 0.0916
2024-05-22 21:19:42 [INFO]: Epoch 129 - training loss: 9283.0568, validation loss: 0.0919
2024-05-22 21:19:42 [INFO]: Epoch 130 - training loss: 9282.4064, validation loss: 0.0916
2024-05-22 21:19:42 [INFO]: Epoch 131 - training loss: 9281.9779, validation loss: 0.0904
2024-05-22 21:19:42 [INFO]: Epoch 132 - training loss: 9279.7581, validation loss: 0.0892
2024-05-22 21:19:42 [INFO]: Epoch 133 - training loss: 9282.3312, validation loss: 0.0921
2024-05-22 21:19:42 [INFO]: Epoch 134 - training loss: 9280.0722, validation loss: 0.0903
2024-05-22 21:19:42 [INFO]: Epoch 135 - training loss: 9279.7096, validation loss: 0.0918
2024-05-22 21:19:42 [INFO]: Epoch 136 - training loss: 9279.3207, validation loss: 0.0901
2024-05-22 21:19:43 [INFO]: Epoch 137 - training loss: 9280.3773, validation loss: 0.0908
2024-05-22 21:19:43 [INFO]: Epoch 138 - training loss: 9278.4255, validation loss: 0.0891
2024-05-22 21:19:43 [INFO]: Epoch 139 - training loss: 9278.6395, validation loss: 0.0896
2024-05-22 21:19:43 [INFO]: Epoch 140 - training loss: 9278.8083, validation loss: 0.0902
2024-05-22 21:19:43 [INFO]: Epoch 141 - training loss: 9282.3082, validation loss: 0.0881
2024-05-22 21:19:43 [INFO]: Epoch 142 - training loss: 9281.3577, validation loss: 0.0884
2024-05-22 21:19:43 [INFO]: Epoch 143 - training loss: 9278.7621, validation loss: 0.0891
2024-05-22 21:19:43 [INFO]: Epoch 144 - training loss: 9277.7901, validation loss: 0.0867
2024-05-22 21:19:43 [INFO]: Epoch 145 - training loss: 9280.3463, validation loss: 0.0883
2024-05-22 21:19:43 [INFO]: Epoch 146 - training loss: 9278.2039, validation loss: 0.0856
2024-05-22 21:19:44 [INFO]: Epoch 147 - training loss: 9278.1198, validation loss: 0.0878
2024-05-22 21:19:44 [INFO]: Epoch 148 - training loss: 9279.5928, validation loss: 0.0866
2024-05-22 21:19:44 [INFO]: Epoch 149 - training loss: 9279.0900, validation loss: 0.0866
2024-05-22 21:19:44 [INFO]: Epoch 150 - training loss: 9278.5002, validation loss: 0.0856
2024-05-22 21:19:44 [INFO]: Epoch 151 - training loss: 9277.1823, validation loss: 0.0856
2024-05-22 21:19:44 [INFO]: Epoch 152 - training loss: 9279.7489, validation loss: 0.0858
2024-05-22 21:19:44 [INFO]: Epoch 153 - training loss: 9276.3909, validation loss: 0.0849
2024-05-22 21:19:44 [INFO]: Epoch 154 - training loss: 9277.8165, validation loss: 0.0857
2024-05-22 21:19:44 [INFO]: Epoch 155 - training loss: 9276.8328, validation loss: 0.0842
2024-05-22 21:19:44 [INFO]: Epoch 156 - training loss: 9277.2703, validation loss: 0.0856
2024-05-22 21:19:45 [INFO]: Epoch 157 - training loss: 9278.2779, validation loss: 0.0843
2024-05-22 21:19:45 [INFO]: Epoch 158 - training loss: 9277.1857, validation loss: 0.0853
2024-05-22 21:19:45 [INFO]: Epoch 159 - training loss: 9276.5897, validation loss: 0.0856
2024-05-22 21:19:45 [INFO]: Epoch 160 - training loss: 9278.4609, validation loss: 0.0855
2024-05-22 21:19:45 [INFO]: Epoch 161 - training loss: 9276.9128, validation loss: 0.0843
2024-05-22 21:19:45 [INFO]: Epoch 162 - training loss: 9278.9212, validation loss: 0.0843
2024-05-22 21:19:45 [INFO]: Epoch 163 - training loss: 9277.4711, validation loss: 0.0839
2024-05-22 21:19:45 [INFO]: Epoch 164 - training loss: 9277.1587, validation loss: 0.0838
2024-05-22 21:19:45 [INFO]: Epoch 165 - training loss: 9277.7141, validation loss: 0.0856
2024-05-22 21:19:46 [INFO]: Epoch 166 - training loss: 9276.9727, validation loss: 0.0826
2024-05-22 21:19:46 [INFO]: Epoch 167 - training loss: 9277.3511, validation loss: 0.0822
2024-05-22 21:19:46 [INFO]: Epoch 168 - training loss: 9276.7551, validation loss: 0.0883
2024-05-22 21:19:46 [INFO]: Epoch 169 - training loss: 9277.6190, validation loss: 0.0811
2024-05-22 21:19:46 [INFO]: Epoch 170 - training loss: 9275.3543, validation loss: 0.0827
2024-05-22 21:19:46 [INFO]: Epoch 171 - training loss: 9275.1642, validation loss: 0.0838
2024-05-22 21:19:46 [INFO]: Epoch 172 - training loss: 9275.0657, validation loss: 0.0813
2024-05-22 21:19:46 [INFO]: Epoch 173 - training loss: 9276.6819, validation loss: 0.0825
2024-05-22 21:19:46 [INFO]: Epoch 174 - training loss: 9274.6893, validation loss: 0.0831
2024-05-22 21:19:46 [INFO]: Epoch 175 - training loss: 9276.2363, validation loss: 0.0824
2024-05-22 21:19:47 [INFO]: Epoch 176 - training loss: 9276.1862, validation loss: 0.0805
2024-05-22 21:19:47 [INFO]: Epoch 177 - training loss: 9275.8584, validation loss: 0.0828
2024-05-22 21:19:47 [INFO]: Epoch 178 - training loss: 9275.0601, validation loss: 0.0810
2024-05-22 21:19:47 [INFO]: Epoch 179 - training loss: 9274.7281, validation loss: 0.0816
2024-05-22 21:19:47 [INFO]: Epoch 180 - training loss: 9276.4823, validation loss: 0.0806
2024-05-22 21:19:47 [INFO]: Epoch 181 - training loss: 9276.3798, validation loss: 0.0789
2024-05-22 21:19:47 [INFO]: Epoch 182 - training loss: 9274.6596, validation loss: 0.0834
2024-05-22 21:19:47 [INFO]: Epoch 183 - training loss: 9274.7729, validation loss: 0.0787
2024-05-22 21:19:47 [INFO]: Epoch 184 - training loss: 9275.5126, validation loss: 0.0827
2024-05-22 21:19:48 [INFO]: Epoch 185 - training loss: 9275.1082, validation loss: 0.0838
2024-05-22 21:19:48 [INFO]: Epoch 186 - training loss: 9274.3170, validation loss: 0.0802
2024-05-22 21:19:48 [INFO]: Epoch 187 - training loss: 9274.2700, validation loss: 0.0810
2024-05-22 21:19:48 [INFO]: Epoch 188 - training loss: 9273.8961, validation loss: 0.0803
2024-05-22 21:19:48 [INFO]: Epoch 189 - training loss: 9274.7866, validation loss: 0.0802
2024-05-22 21:19:48 [INFO]: Epoch 190 - training loss: 9274.3283, validation loss: 0.0818
2024-05-22 21:19:48 [INFO]: Epoch 191 - training loss: 9273.7742, validation loss: 0.0803
2024-05-22 21:19:48 [INFO]: Epoch 192 - training loss: 9273.4827, validation loss: 0.0802
2024-05-22 21:19:48 [INFO]: Epoch 193 - training loss: 9272.8862, validation loss: 0.0795
2024-05-22 21:19:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:19:48 [INFO]: Finished training. The best model is from epoch#183.
2024-05-22 21:19:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_ettm1/20240522_T211928/GPVAE.pypots
2024-05-22 21:19:48 [INFO]: GP-VAE on ETTm1: MAE=0.2754, MSE=0.1623
2024-05-22 21:19:48 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-22 21:19:48 [INFO]: Using the given device: cuda:0
2024-05-22 21:19:48 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240522_T211948
2024-05-22 21:19:48 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_ettm1/20240522_T211948/tensorboard
2024-05-22 21:19:48 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 21:19:57 [INFO]: Epoch 001 - generator training loss: 0.5226, discriminator training loss: 0.4507, validation loss: 0.3076
2024-05-22 21:20:04 [INFO]: Epoch 002 - generator training loss: 0.0022, discriminator training loss: 0.3233, validation loss: 0.1031
2024-05-22 21:20:11 [INFO]: Epoch 003 - generator training loss: -0.1270, discriminator training loss: 0.3126, validation loss: 0.0675
2024-05-22 21:20:19 [INFO]: Epoch 004 - generator training loss: -0.1399, discriminator training loss: 0.3011, validation loss: 0.0516
2024-05-22 21:20:26 [INFO]: Epoch 005 - generator training loss: -0.1332, discriminator training loss: 0.2845, validation loss: 0.0457
2024-05-22 21:20:33 [INFO]: Epoch 006 - generator training loss: -0.1150, discriminator training loss: 0.2565, validation loss: 0.0423
2024-05-22 21:20:40 [INFO]: Epoch 007 - generator training loss: -0.0914, discriminator training loss: 0.2263, validation loss: 0.0399
2024-05-22 21:20:47 [INFO]: Epoch 008 - generator training loss: -0.0644, discriminator training loss: 0.1890, validation loss: 0.0433
2024-05-22 21:20:54 [INFO]: Epoch 009 - generator training loss: -0.0435, discriminator training loss: 0.1609, validation loss: 0.0418
2024-05-22 21:21:01 [INFO]: Epoch 010 - generator training loss: -0.0381, discriminator training loss: 0.1454, validation loss: 0.0378
2024-05-22 21:21:08 [INFO]: Epoch 011 - generator training loss: -0.0316, discriminator training loss: 0.1335, validation loss: 0.0377
2024-05-22 21:21:16 [INFO]: Epoch 012 - generator training loss: -0.0278, discriminator training loss: 0.1272, validation loss: 0.0367
2024-05-22 21:21:23 [INFO]: Epoch 013 - generator training loss: -0.0304, discriminator training loss: 0.1216, validation loss: 0.0358
2024-05-22 21:21:30 [INFO]: Epoch 014 - generator training loss: -0.0290, discriminator training loss: 0.1197, validation loss: 0.0338
2024-05-22 21:21:37 [INFO]: Epoch 015 - generator training loss: -0.0284, discriminator training loss: 0.1194, validation loss: 0.0350
2024-05-22 21:21:44 [INFO]: Epoch 016 - generator training loss: -0.0333, discriminator training loss: 0.1170, validation loss: 0.0346
2024-05-22 21:21:51 [INFO]: Epoch 017 - generator training loss: -0.0314, discriminator training loss: 0.1167, validation loss: 0.0336
2024-05-22 21:21:58 [INFO]: Epoch 018 - generator training loss: -0.0334, discriminator training loss: 0.1169, validation loss: 0.0345
2024-05-22 21:22:06 [INFO]: Epoch 019 - generator training loss: -0.0319, discriminator training loss: 0.1145, validation loss: 0.0344
2024-05-22 21:22:13 [INFO]: Epoch 020 - generator training loss: -0.0304, discriminator training loss: 0.1136, validation loss: 0.0323
2024-05-22 21:22:20 [INFO]: Epoch 021 - generator training loss: -0.0337, discriminator training loss: 0.1145, validation loss: 0.0333
2024-05-22 21:22:27 [INFO]: Epoch 022 - generator training loss: -0.0327, discriminator training loss: 0.1146, validation loss: 0.0326
2024-05-22 21:22:35 [INFO]: Epoch 023 - generator training loss: -0.0318, discriminator training loss: 0.1145, validation loss: 0.0320
2024-05-22 21:22:42 [INFO]: Epoch 024 - generator training loss: -0.0335, discriminator training loss: 0.1155, validation loss: 0.0353
2024-05-22 21:22:49 [INFO]: Epoch 025 - generator training loss: -0.0323, discriminator training loss: 0.1124, validation loss: 0.0314
2024-05-22 21:22:56 [INFO]: Epoch 026 - generator training loss: -0.0331, discriminator training loss: 0.1159, validation loss: 0.0329
2024-05-22 21:23:03 [INFO]: Epoch 027 - generator training loss: -0.0320, discriminator training loss: 0.1136, validation loss: 0.0321
2024-05-22 21:23:10 [INFO]: Epoch 028 - generator training loss: -0.0349, discriminator training loss: 0.1129, validation loss: 0.0321
2024-05-22 21:23:18 [INFO]: Epoch 029 - generator training loss: -0.0347, discriminator training loss: 0.1097, validation loss: 0.0309
2024-05-22 21:23:25 [INFO]: Epoch 030 - generator training loss: -0.0377, discriminator training loss: 0.1120, validation loss: 0.0304
2024-05-22 21:23:32 [INFO]: Epoch 031 - generator training loss: -0.0363, discriminator training loss: 0.1135, validation loss: 0.0296
2024-05-22 21:23:39 [INFO]: Epoch 032 - generator training loss: -0.0337, discriminator training loss: 0.1120, validation loss: 0.0307
2024-05-22 21:23:46 [INFO]: Epoch 033 - generator training loss: -0.0403, discriminator training loss: 0.1120, validation loss: 0.0287
2024-05-22 21:23:53 [INFO]: Epoch 034 - generator training loss: -0.0357, discriminator training loss: 0.1114, validation loss: 0.0294
2024-05-22 21:24:00 [INFO]: Epoch 035 - generator training loss: -0.0386, discriminator training loss: 0.1106, validation loss: 0.0286
2024-05-22 21:24:08 [INFO]: Epoch 036 - generator training loss: -0.0371, discriminator training loss: 0.1093, validation loss: 0.0281
2024-05-22 21:24:15 [INFO]: Epoch 037 - generator training loss: -0.0389, discriminator training loss: 0.1115, validation loss: 0.0284
2024-05-22 21:24:22 [INFO]: Epoch 038 - generator training loss: -0.0404, discriminator training loss: 0.1076, validation loss: 0.0279
2024-05-22 21:24:29 [INFO]: Epoch 039 - generator training loss: -0.0402, discriminator training loss: 0.1150, validation loss: 0.0267
2024-05-22 21:24:36 [INFO]: Epoch 040 - generator training loss: -0.0379, discriminator training loss: 0.1102, validation loss: 0.0265
2024-05-22 21:24:44 [INFO]: Epoch 041 - generator training loss: -0.0422, discriminator training loss: 0.1117, validation loss: 0.0269
2024-05-22 21:24:51 [INFO]: Epoch 042 - generator training loss: -0.0411, discriminator training loss: 0.1132, validation loss: 0.0270
2024-05-22 21:24:58 [INFO]: Epoch 043 - generator training loss: -0.0375, discriminator training loss: 0.1118, validation loss: 0.0266
2024-05-22 21:25:05 [INFO]: Epoch 044 - generator training loss: -0.0416, discriminator training loss: 0.1086, validation loss: 0.0259
2024-05-22 21:25:12 [INFO]: Epoch 045 - generator training loss: -0.0396, discriminator training loss: 0.1084, validation loss: 0.0255
2024-05-22 21:25:20 [INFO]: Epoch 046 - generator training loss: -0.0426, discriminator training loss: 0.1105, validation loss: 0.0254
2024-05-22 21:25:27 [INFO]: Epoch 047 - generator training loss: -0.0425, discriminator training loss: 0.1095, validation loss: 0.0256
2024-05-22 21:25:34 [INFO]: Epoch 048 - generator training loss: -0.0403, discriminator training loss: 0.1089, validation loss: 0.0256
2024-05-22 21:25:41 [INFO]: Epoch 049 - generator training loss: -0.0438, discriminator training loss: 0.1097, validation loss: 0.0244
2024-05-22 21:25:48 [INFO]: Epoch 050 - generator training loss: -0.0422, discriminator training loss: 0.1090, validation loss: 0.0254
2024-05-22 21:25:55 [INFO]: Epoch 051 - generator training loss: -0.0449, discriminator training loss: 0.1101, validation loss: 0.0242
2024-05-22 21:26:03 [INFO]: Epoch 052 - generator training loss: -0.0444, discriminator training loss: 0.1086, validation loss: 0.0250
2024-05-22 21:26:10 [INFO]: Epoch 053 - generator training loss: -0.0455, discriminator training loss: 0.1081, validation loss: 0.0244
2024-05-22 21:26:17 [INFO]: Epoch 054 - generator training loss: -0.0440, discriminator training loss: 0.1083, validation loss: 0.0257
2024-05-22 21:26:24 [INFO]: Epoch 055 - generator training loss: -0.0426, discriminator training loss: 0.1078, validation loss: 0.0241
2024-05-22 21:26:31 [INFO]: Epoch 056 - generator training loss: -0.0458, discriminator training loss: 0.1085, validation loss: 0.0255
2024-05-22 21:26:39 [INFO]: Epoch 057 - generator training loss: -0.0451, discriminator training loss: 0.1082, validation loss: 0.0239
2024-05-22 21:26:46 [INFO]: Epoch 058 - generator training loss: -0.0454, discriminator training loss: 0.1096, validation loss: 0.0241
2024-05-22 21:26:53 [INFO]: Epoch 059 - generator training loss: -0.0461, discriminator training loss: 0.1078, validation loss: 0.0241
2024-05-22 21:27:00 [INFO]: Epoch 060 - generator training loss: -0.0451, discriminator training loss: 0.1073, validation loss: 0.0245
2024-05-22 21:27:07 [INFO]: Epoch 061 - generator training loss: -0.0447, discriminator training loss: 0.1098, validation loss: 0.0239
2024-05-22 21:27:14 [INFO]: Epoch 062 - generator training loss: -0.0431, discriminator training loss: 0.1087, validation loss: 0.0231
2024-05-22 21:27:22 [INFO]: Epoch 063 - generator training loss: -0.0486, discriminator training loss: 0.1078, validation loss: 0.0240
2024-05-22 21:27:29 [INFO]: Epoch 064 - generator training loss: -0.0461, discriminator training loss: 0.1091, validation loss: 0.0234
2024-05-22 21:27:36 [INFO]: Epoch 065 - generator training loss: -0.0462, discriminator training loss: 0.1084, validation loss: 0.0240
2024-05-22 21:27:43 [INFO]: Epoch 066 - generator training loss: -0.0463, discriminator training loss: 0.1103, validation loss: 0.0229
2024-05-22 21:27:51 [INFO]: Epoch 067 - generator training loss: -0.0457, discriminator training loss: 0.1098, validation loss: 0.0227
2024-05-22 21:27:58 [INFO]: Epoch 068 - generator training loss: -0.0482, discriminator training loss: 0.1088, validation loss: 0.0228
2024-05-22 21:28:05 [INFO]: Epoch 069 - generator training loss: -0.0458, discriminator training loss: 0.1086, validation loss: 0.0224
2024-05-22 21:28:12 [INFO]: Epoch 070 - generator training loss: -0.0477, discriminator training loss: 0.1086, validation loss: 0.0219
2024-05-22 21:28:19 [INFO]: Epoch 071 - generator training loss: -0.0484, discriminator training loss: 0.1081, validation loss: 0.0227
2024-05-22 21:28:27 [INFO]: Epoch 072 - generator training loss: -0.0473, discriminator training loss: 0.1079, validation loss: 0.0220
2024-05-22 21:28:34 [INFO]: Epoch 073 - generator training loss: -0.0458, discriminator training loss: 0.1080, validation loss: 0.0218
2024-05-22 21:28:41 [INFO]: Epoch 074 - generator training loss: -0.0472, discriminator training loss: 0.1076, validation loss: 0.0216
2024-05-22 21:28:48 [INFO]: Epoch 075 - generator training loss: -0.0475, discriminator training loss: 0.1097, validation loss: 0.0209
2024-05-22 21:28:55 [INFO]: Epoch 076 - generator training loss: -0.0499, discriminator training loss: 0.1082, validation loss: 0.0207
2024-05-22 21:29:02 [INFO]: Epoch 077 - generator training loss: -0.0495, discriminator training loss: 0.1062, validation loss: 0.0208
2024-05-22 21:29:10 [INFO]: Epoch 078 - generator training loss: -0.0493, discriminator training loss: 0.1058, validation loss: 0.0203
2024-05-22 21:29:17 [INFO]: Epoch 079 - generator training loss: -0.0464, discriminator training loss: 0.1070, validation loss: 0.0222
2024-05-22 21:29:24 [INFO]: Epoch 080 - generator training loss: -0.0499, discriminator training loss: 0.1087, validation loss: 0.0212
2024-05-22 21:29:31 [INFO]: Epoch 081 - generator training loss: -0.0456, discriminator training loss: 0.1082, validation loss: 0.0213
2024-05-22 21:29:38 [INFO]: Epoch 082 - generator training loss: -0.0522, discriminator training loss: 0.1064, validation loss: 0.0212
2024-05-22 21:29:45 [INFO]: Epoch 083 - generator training loss: -0.0476, discriminator training loss: 0.1078, validation loss: 0.0208
2024-05-22 21:29:53 [INFO]: Epoch 084 - generator training loss: -0.0485, discriminator training loss: 0.1070, validation loss: 0.0207
2024-05-22 21:30:00 [INFO]: Epoch 085 - generator training loss: -0.0471, discriminator training loss: 0.1059, validation loss: 0.0205
2024-05-22 21:30:07 [INFO]: Epoch 086 - generator training loss: -0.0486, discriminator training loss: 0.1072, validation loss: 0.0203
2024-05-22 21:30:14 [INFO]: Epoch 087 - generator training loss: -0.0487, discriminator training loss: 0.1066, validation loss: 0.0199
2024-05-22 21:30:21 [INFO]: Epoch 088 - generator training loss: -0.0487, discriminator training loss: 0.1096, validation loss: 0.0204
2024-05-22 21:30:28 [INFO]: Epoch 089 - generator training loss: -0.0498, discriminator training loss: 0.1072, validation loss: 0.0210
2024-05-22 21:30:36 [INFO]: Epoch 090 - generator training loss: -0.0520, discriminator training loss: 0.1079, validation loss: 0.0209
2024-05-22 21:30:43 [INFO]: Epoch 091 - generator training loss: -0.0465, discriminator training loss: 0.1055, validation loss: 0.0200
2024-05-22 21:30:50 [INFO]: Epoch 092 - generator training loss: -0.0481, discriminator training loss: 0.1058, validation loss: 0.0195
2024-05-22 21:30:57 [INFO]: Epoch 093 - generator training loss: -0.0442, discriminator training loss: 0.1065, validation loss: 0.0229
2024-05-22 21:31:04 [INFO]: Epoch 094 - generator training loss: -0.0482, discriminator training loss: 0.1086, validation loss: 0.0208
2024-05-22 21:31:11 [INFO]: Epoch 095 - generator training loss: -0.0460, discriminator training loss: 0.1050, validation loss: 0.0203
2024-05-22 21:31:18 [INFO]: Epoch 096 - generator training loss: -0.0496, discriminator training loss: 0.1040, validation loss: 0.0203
2024-05-22 21:31:25 [INFO]: Epoch 097 - generator training loss: -0.0471, discriminator training loss: 0.1059, validation loss: 0.0202
2024-05-22 21:31:32 [INFO]: Epoch 098 - generator training loss: -0.0457, discriminator training loss: 0.1064, validation loss: 0.0203
2024-05-22 21:31:39 [INFO]: Epoch 099 - generator training loss: -0.0480, discriminator training loss: 0.1037, validation loss: 0.0196
2024-05-22 21:31:46 [INFO]: Epoch 100 - generator training loss: -0.0487, discriminator training loss: 0.1053, validation loss: 0.0203
2024-05-22 21:31:54 [INFO]: Epoch 101 - generator training loss: -0.0500, discriminator training loss: 0.1053, validation loss: 0.0205
2024-05-22 21:32:01 [INFO]: Epoch 102 - generator training loss: -0.0468, discriminator training loss: 0.1072, validation loss: 0.0212
2024-05-22 21:32:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:32:01 [INFO]: Finished training. The best model is from epoch#92.
2024-05-22 21:32:01 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_ettm1/20240522_T211948/USGAN.pypots
2024-05-22 21:32:01 [INFO]: US-GAN on ETTm1: MAE=0.1494, MSE=0.0539
2024-05-22 21:32:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-22 21:32:01 [INFO]: Using the given device: cuda:0
2024-05-22 21:32:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240522_T213201
2024-05-22 21:32:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_ettm1/20240522_T213201/tensorboard
2024-05-22 21:32:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 21:32:07 [INFO]: Epoch 001 - training loss: 1.3577, validation loss: 0.2966
2024-05-22 21:32:12 [INFO]: Epoch 002 - training loss: 0.9067, validation loss: 0.0956
2024-05-22 21:32:17 [INFO]: Epoch 003 - training loss: 0.7112, validation loss: 0.0532
2024-05-22 21:32:21 [INFO]: Epoch 004 - training loss: 0.6430, validation loss: 0.0409
2024-05-22 21:32:26 [INFO]: Epoch 005 - training loss: 0.5997, validation loss: 0.0375
2024-05-22 21:32:31 [INFO]: Epoch 006 - training loss: 0.5600, validation loss: 0.0372
2024-05-22 21:32:35 [INFO]: Epoch 007 - training loss: 0.5537, validation loss: 0.0339
2024-05-22 21:32:40 [INFO]: Epoch 008 - training loss: 0.5155, validation loss: 0.0310
2024-05-22 21:32:45 [INFO]: Epoch 009 - training loss: 0.5027, validation loss: 0.0319
2024-05-22 21:32:50 [INFO]: Epoch 010 - training loss: 0.5304, validation loss: 0.0335
2024-05-22 21:32:54 [INFO]: Epoch 011 - training loss: 0.4879, validation loss: 0.0306
2024-05-22 21:32:59 [INFO]: Epoch 012 - training loss: 0.4598, validation loss: 0.0290
2024-05-22 21:33:04 [INFO]: Epoch 013 - training loss: 0.4484, validation loss: 0.0288
2024-05-22 21:33:09 [INFO]: Epoch 014 - training loss: 0.4367, validation loss: 0.0277
2024-05-22 21:33:13 [INFO]: Epoch 015 - training loss: 0.4220, validation loss: 0.0273
2024-05-22 21:33:18 [INFO]: Epoch 016 - training loss: 0.4130, validation loss: 0.0258
2024-05-22 21:33:23 [INFO]: Epoch 017 - training loss: 0.4156, validation loss: 0.0255
2024-05-22 21:33:27 [INFO]: Epoch 018 - training loss: 0.4104, validation loss: 0.0246
2024-05-22 21:33:32 [INFO]: Epoch 019 - training loss: 0.3963, validation loss: 0.0234
2024-05-22 21:33:37 [INFO]: Epoch 020 - training loss: 0.4009, validation loss: 0.0234
2024-05-22 21:33:41 [INFO]: Epoch 021 - training loss: 0.4453, validation loss: 0.0230
2024-05-22 21:33:46 [INFO]: Epoch 022 - training loss: 0.4267, validation loss: 0.0248
2024-05-22 21:33:51 [INFO]: Epoch 023 - training loss: 0.4173, validation loss: 0.0245
2024-05-22 21:33:55 [INFO]: Epoch 024 - training loss: 0.3950, validation loss: 0.0226
2024-05-22 21:34:00 [INFO]: Epoch 025 - training loss: 0.3989, validation loss: 0.0221
2024-05-22 21:34:05 [INFO]: Epoch 026 - training loss: 0.3873, validation loss: 0.0227
2024-05-22 21:34:10 [INFO]: Epoch 027 - training loss: 0.3731, validation loss: 0.0226
2024-05-22 21:34:14 [INFO]: Epoch 028 - training loss: 0.4164, validation loss: 0.0244
2024-05-22 21:34:19 [INFO]: Epoch 029 - training loss: 0.3945, validation loss: 0.0232
2024-05-22 21:34:24 [INFO]: Epoch 030 - training loss: 0.3851, validation loss: 0.0225
2024-05-22 21:34:28 [INFO]: Epoch 031 - training loss: 0.3825, validation loss: 0.0224
2024-05-22 21:34:33 [INFO]: Epoch 032 - training loss: 0.3815, validation loss: 0.0221
2024-05-22 21:34:38 [INFO]: Epoch 033 - training loss: 0.3918, validation loss: 0.0218
2024-05-22 21:34:42 [INFO]: Epoch 034 - training loss: 0.3817, validation loss: 0.0218
2024-05-22 21:34:47 [INFO]: Epoch 035 - training loss: 0.3804, validation loss: 0.0218
2024-05-22 21:34:52 [INFO]: Epoch 036 - training loss: 0.3782, validation loss: 0.0219
2024-05-22 21:34:56 [INFO]: Epoch 037 - training loss: 0.3866, validation loss: 0.0218
2024-05-22 21:35:01 [INFO]: Epoch 038 - training loss: 0.3807, validation loss: 0.0222
2024-05-22 21:35:06 [INFO]: Epoch 039 - training loss: 0.3839, validation loss: 0.0221
2024-05-22 21:35:10 [INFO]: Epoch 040 - training loss: 0.3863, validation loss: 0.0224
2024-05-22 21:35:15 [INFO]: Epoch 041 - training loss: 0.3787, validation loss: 0.0220
2024-05-22 21:35:20 [INFO]: Epoch 042 - training loss: 0.3727, validation loss: 0.0215
2024-05-22 21:35:25 [INFO]: Epoch 043 - training loss: 0.3782, validation loss: 0.0220
2024-05-22 21:35:29 [INFO]: Epoch 044 - training loss: 0.3936, validation loss: 0.0223
2024-05-22 21:35:34 [INFO]: Epoch 045 - training loss: 0.3774, validation loss: 0.0218
2024-05-22 21:35:39 [INFO]: Epoch 046 - training loss: 0.3821, validation loss: 0.0220
2024-05-22 21:35:43 [INFO]: Epoch 047 - training loss: 0.3758, validation loss: 0.0222
2024-05-22 21:35:48 [INFO]: Epoch 048 - training loss: 0.3796, validation loss: 0.0220
2024-05-22 21:35:53 [INFO]: Epoch 049 - training loss: 0.3793, validation loss: 0.0221
2024-05-22 21:35:57 [INFO]: Epoch 050 - training loss: 0.3799, validation loss: 0.0222
2024-05-22 21:36:02 [INFO]: Epoch 051 - training loss: 0.3842, validation loss: 0.0228
2024-05-22 21:36:07 [INFO]: Epoch 052 - training loss: 0.3794, validation loss: 0.0224
2024-05-22 21:36:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:36:07 [INFO]: Finished training. The best model is from epoch#42.
2024-05-22 21:36:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_ettm1/20240522_T213201/BRITS.pypots
2024-05-22 21:36:08 [INFO]: BRITS on ETTm1: MAE=0.1377, MSE=0.0552
2024-05-22 21:36:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-22 21:36:08 [INFO]: Using the given device: cuda:0
2024-05-22 21:36:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608
2024-05-22 21:36:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/tensorboard
2024-05-22 21:36:08 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 21:36:09 [INFO]: Epoch 001 - training loss: 1.3956, validation loss: 1.2582
2024-05-22 21:36:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch1_loss1.2581771463155746.pypots
2024-05-22 21:36:09 [INFO]: Epoch 002 - training loss: 1.1088, validation loss: 1.1193
2024-05-22 21:36:09 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch2_loss1.1193277537822723.pypots
2024-05-22 21:36:10 [INFO]: Epoch 003 - training loss: 1.0109, validation loss: 1.0497
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch3_loss1.0497166067361832.pypots
2024-05-22 21:36:10 [INFO]: Epoch 004 - training loss: 0.9630, validation loss: 1.0241
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch4_loss1.024132177233696.pypots
2024-05-22 21:36:10 [INFO]: Epoch 005 - training loss: 0.9325, validation loss: 1.0073
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch5_loss1.0072927474975586.pypots
2024-05-22 21:36:10 [INFO]: Epoch 006 - training loss: 0.9480, validation loss: 0.9980
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch6_loss0.997993066906929.pypots
2024-05-22 21:36:10 [INFO]: Epoch 007 - training loss: 0.9170, validation loss: 0.9888
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch7_loss0.9887593239545822.pypots
2024-05-22 21:36:10 [INFO]: Epoch 008 - training loss: 0.9033, validation loss: 0.9783
2024-05-22 21:36:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch8_loss0.9782862663269043.pypots
2024-05-22 21:36:11 [INFO]: Epoch 009 - training loss: 0.9162, validation loss: 0.9728
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch9_loss0.9728015512228012.pypots
2024-05-22 21:36:11 [INFO]: Epoch 010 - training loss: 0.9016, validation loss: 0.9670
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch10_loss0.9669864475727081.pypots
2024-05-22 21:36:11 [INFO]: Epoch 011 - training loss: 0.8803, validation loss: 0.9662
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch11_loss0.9662008136510849.pypots
2024-05-22 21:36:11 [INFO]: Epoch 012 - training loss: 0.8980, validation loss: 0.9629
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch12_loss0.9628790616989136.pypots
2024-05-22 21:36:11 [INFO]: Epoch 013 - training loss: 0.9043, validation loss: 0.9573
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch13_loss0.9573136419057846.pypots
2024-05-22 21:36:11 [INFO]: Epoch 014 - training loss: 0.8571, validation loss: 0.9546
2024-05-22 21:36:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch14_loss0.9545608013868332.pypots
2024-05-22 21:36:12 [INFO]: Epoch 015 - training loss: 0.8599, validation loss: 0.9513
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch15_loss0.9513339996337891.pypots
2024-05-22 21:36:12 [INFO]: Epoch 016 - training loss: 0.8655, validation loss: 0.9484
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch16_loss0.9484253078699112.pypots
2024-05-22 21:36:12 [INFO]: Epoch 017 - training loss: 0.8320, validation loss: 0.9482
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch17_loss0.9481958299875259.pypots
2024-05-22 21:36:12 [INFO]: Epoch 018 - training loss: 0.8422, validation loss: 0.9453
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch18_loss0.9452775567770004.pypots
2024-05-22 21:36:12 [INFO]: Epoch 019 - training loss: 0.8548, validation loss: 0.9434
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch19_loss0.9434216767549515.pypots
2024-05-22 21:36:12 [INFO]: Epoch 020 - training loss: 0.8472, validation loss: 0.9385
2024-05-22 21:36:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch20_loss0.9385109394788742.pypots
2024-05-22 21:36:13 [INFO]: Epoch 021 - training loss: 0.8155, validation loss: 0.9373
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch21_loss0.9372683465480804.pypots
2024-05-22 21:36:13 [INFO]: Epoch 022 - training loss: 0.8437, validation loss: 0.9328
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch22_loss0.932757243514061.pypots
2024-05-22 21:36:13 [INFO]: Epoch 023 - training loss: 0.8395, validation loss: 0.9326
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch23_loss0.9326085597276688.pypots
2024-05-22 21:36:13 [INFO]: Epoch 024 - training loss: 0.8105, validation loss: 0.9264
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch24_loss0.9263580441474915.pypots
2024-05-22 21:36:13 [INFO]: Epoch 025 - training loss: 0.8224, validation loss: 0.9241
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch25_loss0.9241115003824234.pypots
2024-05-22 21:36:13 [INFO]: Epoch 026 - training loss: 0.8216, validation loss: 0.9220
2024-05-22 21:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch26_loss0.9219797700643539.pypots
2024-05-22 21:36:14 [INFO]: Epoch 027 - training loss: 0.8006, validation loss: 0.9174
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch27_loss0.9174302518367767.pypots
2024-05-22 21:36:14 [INFO]: Epoch 028 - training loss: 0.8120, validation loss: 0.9176
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch28_loss0.9176152646541595.pypots
2024-05-22 21:36:14 [INFO]: Epoch 029 - training loss: 0.7877, validation loss: 0.9129
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch29_loss0.9128688126802444.pypots
2024-05-22 21:36:14 [INFO]: Epoch 030 - training loss: 0.8103, validation loss: 0.9098
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch30_loss0.909787729382515.pypots
2024-05-22 21:36:14 [INFO]: Epoch 031 - training loss: 0.8124, validation loss: 0.9072
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch31_loss0.907155379652977.pypots
2024-05-22 21:36:14 [INFO]: Epoch 032 - training loss: 0.7947, validation loss: 0.9050
2024-05-22 21:36:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch32_loss0.9049771130084991.pypots
2024-05-22 21:36:15 [INFO]: Epoch 033 - training loss: 0.8135, validation loss: 0.9016
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch33_loss0.9016305357217789.pypots
2024-05-22 21:36:15 [INFO]: Epoch 034 - training loss: 0.8130, validation loss: 0.8982
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch34_loss0.8982353657484055.pypots
2024-05-22 21:36:15 [INFO]: Epoch 035 - training loss: 0.8207, validation loss: 0.8984
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch35_loss0.8984224796295166.pypots
2024-05-22 21:36:15 [INFO]: Epoch 036 - training loss: 0.8127, validation loss: 0.8940
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch36_loss0.8939803391695023.pypots
2024-05-22 21:36:15 [INFO]: Epoch 037 - training loss: 0.8186, validation loss: 0.8929
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch37_loss0.8928874284029007.pypots
2024-05-22 21:36:15 [INFO]: Epoch 038 - training loss: 0.8037, validation loss: 0.8940
2024-05-22 21:36:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch38_loss0.8940343260765076.pypots
2024-05-22 21:36:16 [INFO]: Epoch 039 - training loss: 0.7813, validation loss: 0.8881
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch39_loss0.8880577981472015.pypots
2024-05-22 21:36:16 [INFO]: Epoch 040 - training loss: 0.8001, validation loss: 0.8865
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch40_loss0.8864827454090118.pypots
2024-05-22 21:36:16 [INFO]: Epoch 041 - training loss: 0.7913, validation loss: 0.8868
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch41_loss0.8867844641208649.pypots
2024-05-22 21:36:16 [INFO]: Epoch 042 - training loss: 0.8044, validation loss: 0.8843
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch42_loss0.8842986673116684.pypots
2024-05-22 21:36:16 [INFO]: Epoch 043 - training loss: 0.8000, validation loss: 0.8822
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch43_loss0.882220670580864.pypots
2024-05-22 21:36:16 [INFO]: Epoch 044 - training loss: 0.7830, validation loss: 0.8791
2024-05-22 21:36:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch44_loss0.8790787905454636.pypots
2024-05-22 21:36:17 [INFO]: Epoch 045 - training loss: 0.8131, validation loss: 0.8810
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch45_loss0.8810435980558395.pypots
2024-05-22 21:36:17 [INFO]: Epoch 046 - training loss: 0.8080, validation loss: 0.8782
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch46_loss0.878215566277504.pypots
2024-05-22 21:36:17 [INFO]: Epoch 047 - training loss: 0.8040, validation loss: 0.8767
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch47_loss0.8767086863517761.pypots
2024-05-22 21:36:17 [INFO]: Epoch 048 - training loss: 0.7856, validation loss: 0.8740
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch48_loss0.8739679455757141.pypots
2024-05-22 21:36:17 [INFO]: Epoch 049 - training loss: 0.7823, validation loss: 0.8730
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch49_loss0.8730028122663498.pypots
2024-05-22 21:36:17 [INFO]: Epoch 050 - training loss: 0.7674, validation loss: 0.8715
2024-05-22 21:36:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch50_loss0.8715040683746338.pypots
2024-05-22 21:36:18 [INFO]: Epoch 051 - training loss: 0.7995, validation loss: 0.8705
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch51_loss0.8704907298088074.pypots
2024-05-22 21:36:18 [INFO]: Epoch 052 - training loss: 0.7997, validation loss: 0.8675
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch52_loss0.8674926906824112.pypots
2024-05-22 21:36:18 [INFO]: Epoch 053 - training loss: 0.7608, validation loss: 0.8687
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch53_loss0.8687336146831512.pypots
2024-05-22 21:36:18 [INFO]: Epoch 054 - training loss: 0.7757, validation loss: 0.8692
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch54_loss0.8691922277212143.pypots
2024-05-22 21:36:18 [INFO]: Epoch 055 - training loss: 0.7952, validation loss: 0.8668
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch55_loss0.8668307214975357.pypots
2024-05-22 21:36:18 [INFO]: Epoch 056 - training loss: 0.7637, validation loss: 0.8690
2024-05-22 21:36:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch56_loss0.8689973056316376.pypots
2024-05-22 21:36:19 [INFO]: Epoch 057 - training loss: 0.7790, validation loss: 0.8660
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch57_loss0.8659830242395401.pypots
2024-05-22 21:36:19 [INFO]: Epoch 058 - training loss: 0.7644, validation loss: 0.8642
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch58_loss0.8641927242279053.pypots
2024-05-22 21:36:19 [INFO]: Epoch 059 - training loss: 0.7827, validation loss: 0.8636
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch59_loss0.8635604083538055.pypots
2024-05-22 21:36:19 [INFO]: Epoch 060 - training loss: 0.7549, validation loss: 0.8649
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch60_loss0.8649300187826157.pypots
2024-05-22 21:36:19 [INFO]: Epoch 061 - training loss: 0.7962, validation loss: 0.8631
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch61_loss0.8631220906972885.pypots
2024-05-22 21:36:19 [INFO]: Epoch 062 - training loss: 0.7663, validation loss: 0.8616
2024-05-22 21:36:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch62_loss0.861564889550209.pypots
2024-05-22 21:36:20 [INFO]: Epoch 063 - training loss: 0.7854, validation loss: 0.8631
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch63_loss0.8630761653184891.pypots
2024-05-22 21:36:20 [INFO]: Epoch 064 - training loss: 0.7970, validation loss: 0.8606
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch64_loss0.8606477379798889.pypots
2024-05-22 21:36:20 [INFO]: Epoch 065 - training loss: 0.7550, validation loss: 0.8611
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch65_loss0.8611275553703308.pypots
2024-05-22 21:36:20 [INFO]: Epoch 066 - training loss: 0.7746, validation loss: 0.8574
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch66_loss0.8574323505163193.pypots
2024-05-22 21:36:20 [INFO]: Epoch 067 - training loss: 0.7803, validation loss: 0.8604
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch67_loss0.8604256212711334.pypots
2024-05-22 21:36:20 [INFO]: Epoch 068 - training loss: 0.7602, validation loss: 0.8588
2024-05-22 21:36:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch68_loss0.8587699234485626.pypots
2024-05-22 21:36:21 [INFO]: Epoch 069 - training loss: 0.7782, validation loss: 0.8556
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch69_loss0.8556182533502579.pypots
2024-05-22 21:36:21 [INFO]: Epoch 070 - training loss: 0.8331, validation loss: 0.8588
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch70_loss0.858830913901329.pypots
2024-05-22 21:36:21 [INFO]: Epoch 071 - training loss: 0.7897, validation loss: 0.8550
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch71_loss0.8549733459949493.pypots
2024-05-22 21:36:21 [INFO]: Epoch 072 - training loss: 0.7544, validation loss: 0.8528
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch72_loss0.8528492748737335.pypots
2024-05-22 21:36:21 [INFO]: Epoch 073 - training loss: 0.7780, validation loss: 0.8565
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch73_loss0.856473296880722.pypots
2024-05-22 21:36:21 [INFO]: Epoch 074 - training loss: 0.7723, validation loss: 0.8558
2024-05-22 21:36:21 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch74_loss0.8558106273412704.pypots
2024-05-22 21:36:22 [INFO]: Epoch 075 - training loss: 0.7732, validation loss: 0.8563
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch75_loss0.8563065826892853.pypots
2024-05-22 21:36:22 [INFO]: Epoch 076 - training loss: 0.7644, validation loss: 0.8556
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch76_loss0.8555671721696854.pypots
2024-05-22 21:36:22 [INFO]: Epoch 077 - training loss: 0.7857, validation loss: 0.8547
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch77_loss0.8547162860631943.pypots
2024-05-22 21:36:22 [INFO]: Epoch 078 - training loss: 0.7788, validation loss: 0.8523
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch78_loss0.8522738516330719.pypots
2024-05-22 21:36:22 [INFO]: Epoch 079 - training loss: 0.7668, validation loss: 0.8556
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch79_loss0.8556018173694611.pypots
2024-05-22 21:36:22 [INFO]: Epoch 080 - training loss: 0.7710, validation loss: 0.8521
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch80_loss0.8521483987569809.pypots
2024-05-22 21:36:22 [INFO]: Epoch 081 - training loss: 0.7604, validation loss: 0.8538
2024-05-22 21:36:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch81_loss0.8538499474525452.pypots
2024-05-22 21:36:23 [INFO]: Epoch 082 - training loss: 0.7561, validation loss: 0.8548
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch82_loss0.8548464328050613.pypots
2024-05-22 21:36:23 [INFO]: Epoch 083 - training loss: 0.7680, validation loss: 0.8523
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch83_loss0.8522684127092361.pypots
2024-05-22 21:36:23 [INFO]: Epoch 084 - training loss: 0.7730, validation loss: 0.8497
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch84_loss0.849668875336647.pypots
2024-05-22 21:36:23 [INFO]: Epoch 085 - training loss: 0.7670, validation loss: 0.8533
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch85_loss0.8532660752534866.pypots
2024-05-22 21:36:23 [INFO]: Epoch 086 - training loss: 0.7724, validation loss: 0.8512
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch86_loss0.8511945754289627.pypots
2024-05-22 21:36:23 [INFO]: Epoch 087 - training loss: 0.7453, validation loss: 0.8521
2024-05-22 21:36:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch87_loss0.85211481153965.pypots
2024-05-22 21:36:24 [INFO]: Epoch 088 - training loss: 0.7603, validation loss: 0.8509
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch88_loss0.8508623242378235.pypots
2024-05-22 21:36:24 [INFO]: Epoch 089 - training loss: 0.7836, validation loss: 0.8489
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch89_loss0.8488819003105164.pypots
2024-05-22 21:36:24 [INFO]: Epoch 090 - training loss: 0.7520, validation loss: 0.8499
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch90_loss0.849896177649498.pypots
2024-05-22 21:36:24 [INFO]: Epoch 091 - training loss: 0.7758, validation loss: 0.8473
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch91_loss0.8472647070884705.pypots
2024-05-22 21:36:24 [INFO]: Epoch 092 - training loss: 0.8117, validation loss: 0.8462
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch92_loss0.8461778312921524.pypots
2024-05-22 21:36:24 [INFO]: Epoch 093 - training loss: 0.7813, validation loss: 0.8475
2024-05-22 21:36:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch93_loss0.847545251250267.pypots
2024-05-22 21:36:25 [INFO]: Epoch 094 - training loss: 0.7934, validation loss: 0.8462
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch94_loss0.8461802452802658.pypots
2024-05-22 21:36:25 [INFO]: Epoch 095 - training loss: 0.7881, validation loss: 0.8451
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch95_loss0.845106452703476.pypots
2024-05-22 21:36:25 [INFO]: Epoch 096 - training loss: 0.7630, validation loss: 0.8451
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch96_loss0.8451157808303833.pypots
2024-05-22 21:36:25 [INFO]: Epoch 097 - training loss: 0.7681, validation loss: 0.8480
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch97_loss0.8479820638895035.pypots
2024-05-22 21:36:25 [INFO]: Epoch 098 - training loss: 0.7679, validation loss: 0.8479
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch98_loss0.8478948175907135.pypots
2024-05-22 21:36:25 [INFO]: Epoch 099 - training loss: 0.7513, validation loss: 0.8423
2024-05-22 21:36:25 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch99_loss0.842250794172287.pypots
2024-05-22 21:36:26 [INFO]: Epoch 100 - training loss: 0.7500, validation loss: 0.8495
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch100_loss0.8495223969221115.pypots
2024-05-22 21:36:26 [INFO]: Epoch 101 - training loss: 0.7621, validation loss: 0.8425
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch101_loss0.8424974977970123.pypots
2024-05-22 21:36:26 [INFO]: Epoch 102 - training loss: 0.7618, validation loss: 0.8441
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch102_loss0.8441353589296341.pypots
2024-05-22 21:36:26 [INFO]: Epoch 103 - training loss: 0.7632, validation loss: 0.8431
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch103_loss0.8431113809347153.pypots
2024-05-22 21:36:26 [INFO]: Epoch 104 - training loss: 0.7583, validation loss: 0.8421
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch104_loss0.8421125113964081.pypots
2024-05-22 21:36:26 [INFO]: Epoch 105 - training loss: 0.7661, validation loss: 0.8439
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch105_loss0.8438533246517181.pypots
2024-05-22 21:36:26 [INFO]: Epoch 106 - training loss: 0.7516, validation loss: 0.8396
2024-05-22 21:36:26 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch106_loss0.8395723104476929.pypots
2024-05-22 21:36:27 [INFO]: Epoch 107 - training loss: 0.7711, validation loss: 0.8399
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch107_loss0.8398955166339874.pypots
2024-05-22 21:36:27 [INFO]: Epoch 108 - training loss: 0.7535, validation loss: 0.8394
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch108_loss0.8394307345151901.pypots
2024-05-22 21:36:27 [INFO]: Epoch 109 - training loss: 0.7634, validation loss: 0.8419
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch109_loss0.8418944478034973.pypots
2024-05-22 21:36:27 [INFO]: Epoch 110 - training loss: 0.7736, validation loss: 0.8381
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch110_loss0.838099792599678.pypots
2024-05-22 21:36:27 [INFO]: Epoch 111 - training loss: 0.7720, validation loss: 0.8396
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch111_loss0.8396051824092865.pypots
2024-05-22 21:36:27 [INFO]: Epoch 112 - training loss: 0.7490, validation loss: 0.8409
2024-05-22 21:36:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch112_loss0.8409053981304169.pypots
2024-05-22 21:36:28 [INFO]: Epoch 113 - training loss: 0.7730, validation loss: 0.8350
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch113_loss0.8349713832139969.pypots
2024-05-22 21:36:28 [INFO]: Epoch 114 - training loss: 0.7497, validation loss: 0.8353
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch114_loss0.8352519273757935.pypots
2024-05-22 21:36:28 [INFO]: Epoch 115 - training loss: 0.7682, validation loss: 0.8342
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch115_loss0.8342084437608719.pypots
2024-05-22 21:36:28 [INFO]: Epoch 116 - training loss: 0.7803, validation loss: 0.8373
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch116_loss0.8372963070869446.pypots
2024-05-22 21:36:28 [INFO]: Epoch 117 - training loss: 0.7511, validation loss: 0.8355
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch117_loss0.8354625552892685.pypots
2024-05-22 21:36:28 [INFO]: Epoch 118 - training loss: 0.7628, validation loss: 0.8350
2024-05-22 21:36:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch118_loss0.8350231498479843.pypots
2024-05-22 21:36:29 [INFO]: Epoch 119 - training loss: 0.7456, validation loss: 0.8316
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch119_loss0.8315814435482025.pypots
2024-05-22 21:36:29 [INFO]: Epoch 120 - training loss: 0.7458, validation loss: 0.8342
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch120_loss0.8342060893774033.pypots
2024-05-22 21:36:29 [INFO]: Epoch 121 - training loss: 0.7474, validation loss: 0.8325
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch121_loss0.8324974030256271.pypots
2024-05-22 21:36:29 [INFO]: Epoch 122 - training loss: 0.7505, validation loss: 0.8328
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch122_loss0.8327732384204865.pypots
2024-05-22 21:36:29 [INFO]: Epoch 123 - training loss: 0.7622, validation loss: 0.8294
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch123_loss0.8293986767530441.pypots
2024-05-22 21:36:29 [INFO]: Epoch 124 - training loss: 0.7925, validation loss: 0.8341
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch124_loss0.8341127932071686.pypots
2024-05-22 21:36:29 [INFO]: Epoch 125 - training loss: 0.7993, validation loss: 0.8366
2024-05-22 21:36:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch125_loss0.8365688025951385.pypots
2024-05-22 21:36:30 [INFO]: Epoch 126 - training loss: 0.8020, validation loss: 0.8307
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch126_loss0.8307373374700546.pypots
2024-05-22 21:36:30 [INFO]: Epoch 127 - training loss: 0.7669, validation loss: 0.8330
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch127_loss0.8329602032899857.pypots
2024-05-22 21:36:30 [INFO]: Epoch 128 - training loss: 0.7663, validation loss: 0.8297
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch128_loss0.8297188580036163.pypots
2024-05-22 21:36:30 [INFO]: Epoch 129 - training loss: 0.7580, validation loss: 0.8305
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch129_loss0.8305399864912033.pypots
2024-05-22 21:36:30 [INFO]: Epoch 130 - training loss: 0.7377, validation loss: 0.8262
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch130_loss0.8262056410312653.pypots
2024-05-22 21:36:30 [INFO]: Epoch 131 - training loss: 0.7773, validation loss: 0.8300
2024-05-22 21:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch131_loss0.8300419896841049.pypots
2024-05-22 21:36:31 [INFO]: Epoch 132 - training loss: 0.8078, validation loss: 0.8251
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch132_loss0.8250507265329361.pypots
2024-05-22 21:36:31 [INFO]: Epoch 133 - training loss: 0.7869, validation loss: 0.8219
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch133_loss0.821911409497261.pypots
2024-05-22 21:36:31 [INFO]: Epoch 134 - training loss: 0.7982, validation loss: 0.8299
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch134_loss0.829944908618927.pypots
2024-05-22 21:36:31 [INFO]: Epoch 135 - training loss: 0.7718, validation loss: 0.8233
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch135_loss0.8233247250318527.pypots
2024-05-22 21:36:31 [INFO]: Epoch 136 - training loss: 0.7700, validation loss: 0.8225
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch136_loss0.8224897682666779.pypots
2024-05-22 21:36:31 [INFO]: Epoch 137 - training loss: 0.7690, validation loss: 0.8290
2024-05-22 21:36:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch137_loss0.8290403783321381.pypots
2024-05-22 21:36:32 [INFO]: Epoch 138 - training loss: 0.7766, validation loss: 0.8260
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch138_loss0.825971707701683.pypots
2024-05-22 21:36:32 [INFO]: Epoch 139 - training loss: 0.7671, validation loss: 0.8272
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch139_loss0.8272491097450256.pypots
2024-05-22 21:36:32 [INFO]: Epoch 140 - training loss: 0.7533, validation loss: 0.8236
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch140_loss0.8235811293125153.pypots
2024-05-22 21:36:32 [INFO]: Epoch 141 - training loss: 0.7557, validation loss: 0.8221
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch141_loss0.8220891952514648.pypots
2024-05-22 21:36:32 [INFO]: Epoch 142 - training loss: 0.7597, validation loss: 0.8224
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch142_loss0.8223932683467865.pypots
2024-05-22 21:36:32 [INFO]: Epoch 143 - training loss: 0.7449, validation loss: 0.8190
2024-05-22 21:36:32 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch143_loss0.818952739238739.pypots
2024-05-22 21:36:33 [INFO]: Epoch 144 - training loss: 0.7496, validation loss: 0.8205
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch144_loss0.820518434047699.pypots
2024-05-22 21:36:33 [INFO]: Epoch 145 - training loss: 0.7830, validation loss: 0.8205
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch145_loss0.8205203413963318.pypots
2024-05-22 21:36:33 [INFO]: Epoch 146 - training loss: 0.7683, validation loss: 0.8189
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch146_loss0.818889781832695.pypots
2024-05-22 21:36:33 [INFO]: Epoch 147 - training loss: 0.7735, validation loss: 0.8201
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch147_loss0.8201350569725037.pypots
2024-05-22 21:36:33 [INFO]: Epoch 148 - training loss: 0.7833, validation loss: 0.8181
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch148_loss0.8180655390024185.pypots
2024-05-22 21:36:33 [INFO]: Epoch 149 - training loss: 0.7519, validation loss: 0.8169
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch149_loss0.8169240057468414.pypots
2024-05-22 21:36:33 [INFO]: Epoch 150 - training loss: 0.7413, validation loss: 0.8168
2024-05-22 21:36:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch150_loss0.8168079406023026.pypots
2024-05-22 21:36:34 [INFO]: Epoch 151 - training loss: 0.7619, validation loss: 0.8178
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch151_loss0.8178210854530334.pypots
2024-05-22 21:36:34 [INFO]: Epoch 152 - training loss: 0.7631, validation loss: 0.8181
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch152_loss0.8180613815784454.pypots
2024-05-22 21:36:34 [INFO]: Epoch 153 - training loss: 0.7624, validation loss: 0.8156
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch153_loss0.8156318515539169.pypots
2024-05-22 21:36:34 [INFO]: Epoch 154 - training loss: 0.7555, validation loss: 0.8152
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch154_loss0.8152341991662979.pypots
2024-05-22 21:36:34 [INFO]: Epoch 155 - training loss: 0.7412, validation loss: 0.8184
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch155_loss0.8183933198451996.pypots
2024-05-22 21:36:34 [INFO]: Epoch 156 - training loss: 0.7819, validation loss: 0.8150
2024-05-22 21:36:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch156_loss0.8150243163108826.pypots
2024-05-22 21:36:35 [INFO]: Epoch 157 - training loss: 0.7596, validation loss: 0.8199
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch157_loss0.8199246972799301.pypots
2024-05-22 21:36:35 [INFO]: Epoch 158 - training loss: 0.7616, validation loss: 0.8146
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch158_loss0.8146214038133621.pypots
2024-05-22 21:36:35 [INFO]: Epoch 159 - training loss: 0.7685, validation loss: 0.8140
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch159_loss0.8139890730381012.pypots
2024-05-22 21:36:35 [INFO]: Epoch 160 - training loss: 0.7580, validation loss: 0.8099
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch160_loss0.8099367320537567.pypots
2024-05-22 21:36:35 [INFO]: Epoch 161 - training loss: 0.7518, validation loss: 0.8165
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch161_loss0.816544383764267.pypots
2024-05-22 21:36:35 [INFO]: Epoch 162 - training loss: 0.7453, validation loss: 0.8127
2024-05-22 21:36:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch162_loss0.8127467781305313.pypots
2024-05-22 21:36:36 [INFO]: Epoch 163 - training loss: 0.7711, validation loss: 0.8134
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch163_loss0.8133613765239716.pypots
2024-05-22 21:36:36 [INFO]: Epoch 164 - training loss: 0.7478, validation loss: 0.8099
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch164_loss0.8099205940961838.pypots
2024-05-22 21:36:36 [INFO]: Epoch 165 - training loss: 0.7799, validation loss: 0.8134
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch165_loss0.8133883625268936.pypots
2024-05-22 21:36:36 [INFO]: Epoch 166 - training loss: 0.7657, validation loss: 0.8117
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch166_loss0.8117124736309052.pypots
2024-05-22 21:36:36 [INFO]: Epoch 167 - training loss: 0.7691, validation loss: 0.8081
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch167_loss0.8080709278583527.pypots
2024-05-22 21:36:36 [INFO]: Epoch 168 - training loss: 0.7680, validation loss: 0.8095
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch168_loss0.809538871049881.pypots
2024-05-22 21:36:36 [INFO]: Epoch 169 - training loss: 0.7593, validation loss: 0.8099
2024-05-22 21:36:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch169_loss0.8098888248205185.pypots
2024-05-22 21:36:37 [INFO]: Epoch 170 - training loss: 0.7614, validation loss: 0.8089
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch170_loss0.8089197129011154.pypots
2024-05-22 21:36:37 [INFO]: Epoch 171 - training loss: 0.7574, validation loss: 0.8090
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch171_loss0.8089930266141891.pypots
2024-05-22 21:36:37 [INFO]: Epoch 172 - training loss: 0.7709, validation loss: 0.8083
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch172_loss0.808324322104454.pypots
2024-05-22 21:36:37 [INFO]: Epoch 173 - training loss: 0.7500, validation loss: 0.8104
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch173_loss0.8104439973831177.pypots
2024-05-22 21:36:37 [INFO]: Epoch 174 - training loss: 0.7598, validation loss: 0.8086
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch174_loss0.8086008727550507.pypots
2024-05-22 21:36:37 [INFO]: Epoch 175 - training loss: 0.7558, validation loss: 0.8066
2024-05-22 21:36:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch175_loss0.8065519332885742.pypots
2024-05-22 21:36:38 [INFO]: Epoch 176 - training loss: 0.7579, validation loss: 0.8072
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch176_loss0.8072336316108704.pypots
2024-05-22 21:36:38 [INFO]: Epoch 177 - training loss: 0.7782, validation loss: 0.8078
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch177_loss0.807761624455452.pypots
2024-05-22 21:36:38 [INFO]: Epoch 178 - training loss: 0.7780, validation loss: 0.8072
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch178_loss0.807231530547142.pypots
2024-05-22 21:36:38 [INFO]: Epoch 179 - training loss: 0.7517, validation loss: 0.8055
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch179_loss0.8055103421211243.pypots
2024-05-22 21:36:38 [INFO]: Epoch 180 - training loss: 0.7703, validation loss: 0.8038
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch180_loss0.8037844747304916.pypots
2024-05-22 21:36:38 [INFO]: Epoch 181 - training loss: 0.7801, validation loss: 0.8043
2024-05-22 21:36:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch181_loss0.80428047478199.pypots
2024-05-22 21:36:39 [INFO]: Epoch 182 - training loss: 0.7635, validation loss: 0.8041
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch182_loss0.8041479140520096.pypots
2024-05-22 21:36:39 [INFO]: Epoch 183 - training loss: 0.7519, validation loss: 0.8063
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch183_loss0.8062627017498016.pypots
2024-05-22 21:36:39 [INFO]: Epoch 184 - training loss: 0.7456, validation loss: 0.8055
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch184_loss0.805527463555336.pypots
2024-05-22 21:36:39 [INFO]: Epoch 185 - training loss: 0.7512, validation loss: 0.8040
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch185_loss0.8040148317813873.pypots
2024-05-22 21:36:39 [INFO]: Epoch 186 - training loss: 0.7749, validation loss: 0.8081
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch186_loss0.8081361949443817.pypots
2024-05-22 21:36:39 [INFO]: Epoch 187 - training loss: 0.7478, validation loss: 0.7996
2024-05-22 21:36:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch187_loss0.7996042668819427.pypots
2024-05-22 21:36:40 [INFO]: Epoch 188 - training loss: 0.7423, validation loss: 0.8016
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch188_loss0.8015893250703812.pypots
2024-05-22 21:36:40 [INFO]: Epoch 189 - training loss: 0.7427, validation loss: 0.8022
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch189_loss0.80223149061203.pypots
2024-05-22 21:36:40 [INFO]: Epoch 190 - training loss: 0.7556, validation loss: 0.8008
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch190_loss0.800775870680809.pypots
2024-05-22 21:36:40 [INFO]: Epoch 191 - training loss: 0.7589, validation loss: 0.8027
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch191_loss0.8026560544967651.pypots
2024-05-22 21:36:40 [INFO]: Epoch 192 - training loss: 0.7314, validation loss: 0.8031
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch192_loss0.8030809015035629.pypots
2024-05-22 21:36:40 [INFO]: Epoch 193 - training loss: 0.7604, validation loss: 0.7997
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch193_loss0.7997490912675858.pypots
2024-05-22 21:36:40 [INFO]: Epoch 194 - training loss: 0.7432, validation loss: 0.8022
2024-05-22 21:36:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch194_loss0.8021888881921768.pypots
2024-05-22 21:36:41 [INFO]: Epoch 195 - training loss: 0.7446, validation loss: 0.8021
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch195_loss0.8021197319030762.pypots
2024-05-22 21:36:41 [INFO]: Epoch 196 - training loss: 0.7646, validation loss: 0.7997
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch196_loss0.7997258305549622.pypots
2024-05-22 21:36:41 [INFO]: Epoch 197 - training loss: 0.7400, validation loss: 0.7978
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch197_loss0.7977652996778488.pypots
2024-05-22 21:36:41 [INFO]: Epoch 198 - training loss: 0.7399, validation loss: 0.8002
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch198_loss0.8001716136932373.pypots
2024-05-22 21:36:41 [INFO]: Epoch 199 - training loss: 0.7431, validation loss: 0.8000
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch199_loss0.8000161200761795.pypots
2024-05-22 21:36:41 [INFO]: Epoch 200 - training loss: 0.7478, validation loss: 0.7999
2024-05-22 21:36:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch200_loss0.7998693734407425.pypots
2024-05-22 21:36:42 [INFO]: Epoch 201 - training loss: 0.7638, validation loss: 0.8002
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch201_loss0.8002185821533203.pypots
2024-05-22 21:36:42 [INFO]: Epoch 202 - training loss: 0.7765, validation loss: 0.7990
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch202_loss0.7990279793739319.pypots
2024-05-22 21:36:42 [INFO]: Epoch 203 - training loss: 0.7565, validation loss: 0.8005
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch203_loss0.8004995584487915.pypots
2024-05-22 21:36:42 [INFO]: Epoch 204 - training loss: 0.7604, validation loss: 0.7993
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch204_loss0.7993368208408356.pypots
2024-05-22 21:36:42 [INFO]: Epoch 205 - training loss: 0.7651, validation loss: 0.7982
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch205_loss0.7982149422168732.pypots
2024-05-22 21:36:42 [INFO]: Epoch 206 - training loss: 0.7631, validation loss: 0.8000
2024-05-22 21:36:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch206_loss0.800038754940033.pypots
2024-05-22 21:36:43 [INFO]: Epoch 207 - training loss: 0.7621, validation loss: 0.7965
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch207_loss0.7965241074562073.pypots
2024-05-22 21:36:43 [INFO]: Epoch 208 - training loss: 0.7682, validation loss: 0.8008
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch208_loss0.8008303791284561.pypots
2024-05-22 21:36:43 [INFO]: Epoch 209 - training loss: 0.7491, validation loss: 0.7954
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch209_loss0.7954358905553818.pypots
2024-05-22 21:36:43 [INFO]: Epoch 210 - training loss: 0.7449, validation loss: 0.7998
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch210_loss0.7997613847255707.pypots
2024-05-22 21:36:43 [INFO]: Epoch 211 - training loss: 0.7777, validation loss: 0.7970
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch211_loss0.7969550788402557.pypots
2024-05-22 21:36:43 [INFO]: Epoch 212 - training loss: 0.7646, validation loss: 0.7961
2024-05-22 21:36:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch212_loss0.7961229979991913.pypots
2024-05-22 21:36:44 [INFO]: Epoch 213 - training loss: 0.7696, validation loss: 0.7943
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch213_loss0.7943121194839478.pypots
2024-05-22 21:36:44 [INFO]: Epoch 214 - training loss: 0.7446, validation loss: 0.7972
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch214_loss0.7971656322479248.pypots
2024-05-22 21:36:44 [INFO]: Epoch 215 - training loss: 0.7544, validation loss: 0.7945
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch215_loss0.7944665998220444.pypots
2024-05-22 21:36:44 [INFO]: Epoch 216 - training loss: 0.7600, validation loss: 0.7954
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch216_loss0.7954333573579788.pypots
2024-05-22 21:36:44 [INFO]: Epoch 217 - training loss: 0.7478, validation loss: 0.7948
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch217_loss0.7947890013456345.pypots
2024-05-22 21:36:44 [INFO]: Epoch 218 - training loss: 0.7641, validation loss: 0.7941
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch218_loss0.7941420525312424.pypots
2024-05-22 21:36:44 [INFO]: Epoch 219 - training loss: 0.7411, validation loss: 0.7926
2024-05-22 21:36:44 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch219_loss0.7925708442926407.pypots
2024-05-22 21:36:45 [INFO]: Epoch 220 - training loss: 0.7650, validation loss: 0.7946
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch220_loss0.7945898771286011.pypots
2024-05-22 21:36:45 [INFO]: Epoch 221 - training loss: 0.7402, validation loss: 0.7940
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch221_loss0.7939970046281815.pypots
2024-05-22 21:36:45 [INFO]: Epoch 222 - training loss: 0.7736, validation loss: 0.7963
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch222_loss0.7963134795427322.pypots
2024-05-22 21:36:45 [INFO]: Epoch 223 - training loss: 0.7424, validation loss: 0.7914
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch223_loss0.7914324998855591.pypots
2024-05-22 21:36:45 [INFO]: Epoch 224 - training loss: 0.7538, validation loss: 0.7950
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch224_loss0.7949524521827698.pypots
2024-05-22 21:36:45 [INFO]: Epoch 225 - training loss: 0.7640, validation loss: 0.7966
2024-05-22 21:36:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch225_loss0.7966330498456955.pypots
2024-05-22 21:36:46 [INFO]: Epoch 226 - training loss: 0.7692, validation loss: 0.7932
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch226_loss0.7932466268539429.pypots
2024-05-22 21:36:46 [INFO]: Epoch 227 - training loss: 0.7829, validation loss: 0.7927
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch227_loss0.7927387356758118.pypots
2024-05-22 21:36:46 [INFO]: Epoch 228 - training loss: 0.8009, validation loss: 0.7912
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch228_loss0.7912132441997528.pypots
2024-05-22 21:36:46 [INFO]: Epoch 229 - training loss: 0.7667, validation loss: 0.7918
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch229_loss0.7917913049459457.pypots
2024-05-22 21:36:46 [INFO]: Epoch 230 - training loss: 0.7603, validation loss: 0.7926
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch230_loss0.7925902605056763.pypots
2024-05-22 21:36:46 [INFO]: Epoch 231 - training loss: 0.7408, validation loss: 0.7915
2024-05-22 21:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch231_loss0.7915257811546326.pypots
2024-05-22 21:36:47 [INFO]: Epoch 232 - training loss: 0.7449, validation loss: 0.7926
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch232_loss0.7926367223262787.pypots
2024-05-22 21:36:47 [INFO]: Epoch 233 - training loss: 0.7461, validation loss: 0.7928
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch233_loss0.7927613854408264.pypots
2024-05-22 21:36:47 [INFO]: Epoch 234 - training loss: 0.7711, validation loss: 0.7915
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch234_loss0.7915314882993698.pypots
2024-05-22 21:36:47 [INFO]: Epoch 235 - training loss: 0.7451, validation loss: 0.7922
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch235_loss0.7922125905752182.pypots
2024-05-22 21:36:47 [INFO]: Epoch 236 - training loss: 0.7668, validation loss: 0.7909
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch236_loss0.7908744961023331.pypots
2024-05-22 21:36:47 [INFO]: Epoch 237 - training loss: 0.7639, validation loss: 0.7906
2024-05-22 21:36:47 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch237_loss0.7906222492456436.pypots
2024-05-22 21:36:48 [INFO]: Epoch 238 - training loss: 0.7624, validation loss: 0.7909
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch238_loss0.7908592075109482.pypots
2024-05-22 21:36:48 [INFO]: Epoch 239 - training loss: 0.7364, validation loss: 0.7915
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch239_loss0.7914783209562302.pypots
2024-05-22 21:36:48 [INFO]: Epoch 240 - training loss: 0.7626, validation loss: 0.7887
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch240_loss0.7886767983436584.pypots
2024-05-22 21:36:48 [INFO]: Epoch 241 - training loss: 0.7400, validation loss: 0.7914
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch241_loss0.7914410829544067.pypots
2024-05-22 21:36:48 [INFO]: Epoch 242 - training loss: 0.7829, validation loss: 0.7906
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch242_loss0.790613979101181.pypots
2024-05-22 21:36:48 [INFO]: Epoch 243 - training loss: 0.7999, validation loss: 0.7921
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch243_loss0.792110413312912.pypots
2024-05-22 21:36:48 [INFO]: Epoch 244 - training loss: 0.7848, validation loss: 0.7910
2024-05-22 21:36:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch244_loss0.7909747213125229.pypots
2024-05-22 21:36:49 [INFO]: Epoch 245 - training loss: 0.7552, validation loss: 0.7894
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch245_loss0.7894006073474884.pypots
2024-05-22 21:36:49 [INFO]: Epoch 246 - training loss: 0.7388, validation loss: 0.7904
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch246_loss0.7904228419065475.pypots
2024-05-22 21:36:49 [INFO]: Epoch 247 - training loss: 0.7539, validation loss: 0.7879
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch247_loss0.7878613471984863.pypots
2024-05-22 21:36:49 [INFO]: Epoch 248 - training loss: 0.7559, validation loss: 0.7875
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch248_loss0.7874926626682281.pypots
2024-05-22 21:36:49 [INFO]: Epoch 249 - training loss: 0.7769, validation loss: 0.7879
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch249_loss0.78787861764431.pypots
2024-05-22 21:36:49 [INFO]: Epoch 250 - training loss: 0.7576, validation loss: 0.7895
2024-05-22 21:36:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch250_loss0.7895343899726868.pypots
2024-05-22 21:36:50 [INFO]: Epoch 251 - training loss: 0.7823, validation loss: 0.7877
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch251_loss0.7877073287963867.pypots
2024-05-22 21:36:50 [INFO]: Epoch 252 - training loss: 0.7594, validation loss: 0.7905
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch252_loss0.7905462235212326.pypots
2024-05-22 21:36:50 [INFO]: Epoch 253 - training loss: 0.7733, validation loss: 0.7899
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch253_loss0.7898798435926437.pypots
2024-05-22 21:36:50 [INFO]: Epoch 254 - training loss: 0.7537, validation loss: 0.7886
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch254_loss0.7885721623897552.pypots
2024-05-22 21:36:50 [INFO]: Epoch 255 - training loss: 0.7545, validation loss: 0.7874
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch255_loss0.7874451279640198.pypots
2024-05-22 21:36:50 [INFO]: Epoch 256 - training loss: 0.7532, validation loss: 0.7875
2024-05-22 21:36:50 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch256_loss0.7875300794839859.pypots
2024-05-22 21:36:51 [INFO]: Epoch 257 - training loss: 0.7342, validation loss: 0.7872
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch257_loss0.7872078716754913.pypots
2024-05-22 21:36:51 [INFO]: Epoch 258 - training loss: 0.7500, validation loss: 0.7868
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch258_loss0.7868422269821167.pypots
2024-05-22 21:36:51 [INFO]: Epoch 259 - training loss: 0.7514, validation loss: 0.7875
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch259_loss0.7874780893325806.pypots
2024-05-22 21:36:51 [INFO]: Epoch 260 - training loss: 0.7627, validation loss: 0.7873
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch260_loss0.787276953458786.pypots
2024-05-22 21:36:51 [INFO]: Epoch 261 - training loss: 0.7537, validation loss: 0.7875
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch261_loss0.7875368148088455.pypots
2024-05-22 21:36:51 [INFO]: Epoch 262 - training loss: 0.7380, validation loss: 0.7854
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch262_loss0.7854252308607101.pypots
2024-05-22 21:36:51 [INFO]: Epoch 263 - training loss: 0.7466, validation loss: 0.7860
2024-05-22 21:36:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch263_loss0.7860087901353836.pypots
2024-05-22 21:36:52 [INFO]: Epoch 264 - training loss: 0.7722, validation loss: 0.7899
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch264_loss0.7898983955383301.pypots
2024-05-22 21:36:52 [INFO]: Epoch 265 - training loss: 0.7496, validation loss: 0.7868
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch265_loss0.7867766469717026.pypots
2024-05-22 21:36:52 [INFO]: Epoch 266 - training loss: 0.7654, validation loss: 0.7858
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch266_loss0.7857999801635742.pypots
2024-05-22 21:36:52 [INFO]: Epoch 267 - training loss: 0.7692, validation loss: 0.7873
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch267_loss0.7873200476169586.pypots
2024-05-22 21:36:52 [INFO]: Epoch 268 - training loss: 0.7686, validation loss: 0.7854
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch268_loss0.7853682786226273.pypots
2024-05-22 21:36:52 [INFO]: Epoch 269 - training loss: 0.7867, validation loss: 0.7862
2024-05-22 21:36:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch269_loss0.7861696183681488.pypots
2024-05-22 21:36:53 [INFO]: Epoch 270 - training loss: 0.7500, validation loss: 0.7870
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch270_loss0.7870341837406158.pypots
2024-05-22 21:36:53 [INFO]: Epoch 271 - training loss: 0.7518, validation loss: 0.7849
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch271_loss0.7848943620920181.pypots
2024-05-22 21:36:53 [INFO]: Epoch 272 - training loss: 0.7551, validation loss: 0.7824
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch272_loss0.7824043929576874.pypots
2024-05-22 21:36:53 [INFO]: Epoch 273 - training loss: 0.7637, validation loss: 0.7857
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch273_loss0.785690501332283.pypots
2024-05-22 21:36:53 [INFO]: Epoch 274 - training loss: 0.7583, validation loss: 0.7860
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch274_loss0.7859808951616287.pypots
2024-05-22 21:36:53 [INFO]: Epoch 275 - training loss: 0.7556, validation loss: 0.7841
2024-05-22 21:36:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch275_loss0.7841074019670486.pypots
2024-05-22 21:36:54 [INFO]: Epoch 276 - training loss: 0.7633, validation loss: 0.7865
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch276_loss0.7865176200866699.pypots
2024-05-22 21:36:54 [INFO]: Epoch 277 - training loss: 0.7408, validation loss: 0.7865
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch277_loss0.7865213602781296.pypots
2024-05-22 21:36:54 [INFO]: Epoch 278 - training loss: 0.7573, validation loss: 0.7881
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch278_loss0.7880916744470596.pypots
2024-05-22 21:36:54 [INFO]: Epoch 279 - training loss: 0.7606, validation loss: 0.7830
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch279_loss0.7830079644918442.pypots
2024-05-22 21:36:54 [INFO]: Epoch 280 - training loss: 0.7640, validation loss: 0.7871
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch280_loss0.7870934456586838.pypots
2024-05-22 21:36:54 [INFO]: Epoch 281 - training loss: 0.7586, validation loss: 0.7852
2024-05-22 21:36:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch281_loss0.7852388024330139.pypots
2024-05-22 21:36:55 [INFO]: Epoch 282 - training loss: 0.7374, validation loss: 0.7837
2024-05-22 21:36:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN_epoch282_loss0.7836930155754089.pypots
2024-05-22 21:36:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:36:55 [INFO]: Finished training. The best model is from epoch#272.
2024-05-22 21:36:55 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_ettm1/20240522_T213608/MRNN.pypots
2024-05-22 21:36:55 [INFO]: MRNN on ETTm1: MAE=0.5702, MSE=0.9693
2024-05-22 21:36:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-22 21:36:55 [INFO]: Using the given device: cpu
2024-05-22 21:36:55 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 21:36:55 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-22 21:36:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-22 21:36:55 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 21:36:55 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-22 21:36:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-22 21:36:55 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 21:36:55 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-22 21:36:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-22 21:36:55 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-22 21:36:55 [INFO]: Using the given device: cuda:0
2024-05-22 21:36:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240522_T213655
2024-05-22 21:36:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_ettm1/20240522_T213655/tensorboard
2024-05-22 21:36:55 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 21:36:55 [INFO]: Epoch 001 - training loss: 1.0963, validation loss: 0.2530
2024-05-22 21:36:56 [INFO]: Epoch 002 - training loss: 0.7933, validation loss: 0.1231
2024-05-22 21:36:56 [INFO]: Epoch 003 - training loss: 0.7052, validation loss: 0.0973
2024-05-22 21:36:57 [INFO]: Epoch 004 - training loss: 0.6600, validation loss: 0.0790
2024-05-22 21:36:57 [INFO]: Epoch 005 - training loss: 0.6198, validation loss: 0.0745
2024-05-22 21:36:58 [INFO]: Epoch 006 - training loss: 0.5963, validation loss: 0.0699
2024-05-22 21:36:58 [INFO]: Epoch 007 - training loss: 0.5735, validation loss: 0.0646
2024-05-22 21:36:59 [INFO]: Epoch 008 - training loss: 0.5568, validation loss: 0.0625
2024-05-22 21:36:59 [INFO]: Epoch 009 - training loss: 0.5650, validation loss: 0.0525
2024-05-22 21:37:00 [INFO]: Epoch 010 - training loss: 0.5347, validation loss: 0.0569
2024-05-22 21:37:00 [INFO]: Epoch 011 - training loss: 0.5146, validation loss: 0.0548
2024-05-22 21:37:01 [INFO]: Epoch 012 - training loss: 0.5227, validation loss: 0.0662
2024-05-22 21:37:01 [INFO]: Epoch 013 - training loss: 0.5090, validation loss: 0.0549
2024-05-22 21:37:02 [INFO]: Epoch 014 - training loss: 0.5240, validation loss: 0.0557
2024-05-22 21:37:02 [INFO]: Epoch 015 - training loss: 0.4986, validation loss: 0.0524
2024-05-22 21:37:03 [INFO]: Epoch 016 - training loss: 0.4826, validation loss: 0.0457
2024-05-22 21:37:03 [INFO]: Epoch 017 - training loss: 0.4801, validation loss: 0.0403
2024-05-22 21:37:03 [INFO]: Epoch 018 - training loss: 0.4752, validation loss: 0.0419
2024-05-22 21:37:04 [INFO]: Epoch 019 - training loss: 0.4681, validation loss: 0.0365
2024-05-22 21:37:04 [INFO]: Epoch 020 - training loss: 0.4574, validation loss: 0.0367
2024-05-22 21:37:05 [INFO]: Epoch 021 - training loss: 0.4458, validation loss: 0.0365
2024-05-22 21:37:05 [INFO]: Epoch 022 - training loss: 0.4328, validation loss: 0.0351
2024-05-22 21:37:06 [INFO]: Epoch 023 - training loss: 0.4254, validation loss: 0.0386
2024-05-22 21:37:06 [INFO]: Epoch 024 - training loss: 0.4263, validation loss: 0.0387
2024-05-22 21:37:07 [INFO]: Epoch 025 - training loss: 0.4282, validation loss: 0.0412
2024-05-22 21:37:07 [INFO]: Epoch 026 - training loss: 0.4324, validation loss: 0.1177
2024-05-22 21:37:08 [INFO]: Epoch 027 - training loss: 0.4725, validation loss: 0.0399
2024-05-22 21:37:08 [INFO]: Epoch 028 - training loss: 0.4199, validation loss: 0.0480
2024-05-22 21:37:09 [INFO]: Epoch 029 - training loss: 0.4075, validation loss: 0.0373
2024-05-22 21:37:09 [INFO]: Epoch 030 - training loss: 0.4031, validation loss: 0.0412
2024-05-22 21:37:10 [INFO]: Epoch 031 - training loss: 0.3989, validation loss: 0.0361
2024-05-22 21:37:10 [INFO]: Epoch 032 - training loss: 0.4059, validation loss: 0.0412
2024-05-22 21:37:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:37:10 [INFO]: Finished training. The best model is from epoch#22.
2024-05-22 21:37:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_ettm1/20240522_T213655/SAITS.pypots
2024-05-22 21:37:10 [INFO]: SAITS on ETTm1: MAE=0.1652, MSE=0.0497
2024-05-22 21:37:10 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-22 21:37:10 [INFO]: Using the given device: cuda:0
2024-05-22 21:37:10 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240522_T213710
2024-05-22 21:37:10 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_ettm1/20240522_T213710/tensorboard
2024-05-22 21:37:10 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 21:37:10 [INFO]: Epoch 001 - training loss: 1.1471, validation loss: 0.2648
2024-05-22 21:37:11 [INFO]: Epoch 002 - training loss: 0.6692, validation loss: 0.1375
2024-05-22 21:37:11 [INFO]: Epoch 003 - training loss: 0.5573, validation loss: 0.1068
2024-05-22 21:37:11 [INFO]: Epoch 004 - training loss: 0.5081, validation loss: 0.0933
2024-05-22 21:37:11 [INFO]: Epoch 005 - training loss: 0.4680, validation loss: 0.0780
2024-05-22 21:37:11 [INFO]: Epoch 006 - training loss: 0.4453, validation loss: 0.0712
2024-05-22 21:37:12 [INFO]: Epoch 007 - training loss: 0.4155, validation loss: 0.0715
2024-05-22 21:37:12 [INFO]: Epoch 008 - training loss: 0.4055, validation loss: 0.0645
2024-05-22 21:37:12 [INFO]: Epoch 009 - training loss: 0.3961, validation loss: 0.0625
2024-05-22 21:37:12 [INFO]: Epoch 010 - training loss: 0.3833, validation loss: 0.0583
2024-05-22 21:37:12 [INFO]: Epoch 011 - training loss: 0.3684, validation loss: 0.0543
2024-05-22 21:37:13 [INFO]: Epoch 012 - training loss: 0.3557, validation loss: 0.0520
2024-05-22 21:37:13 [INFO]: Epoch 013 - training loss: 0.3521, validation loss: 0.0513
2024-05-22 21:37:13 [INFO]: Epoch 014 - training loss: 0.3494, validation loss: 0.0511
2024-05-22 21:37:13 [INFO]: Epoch 015 - training loss: 0.3373, validation loss: 0.0491
2024-05-22 21:37:13 [INFO]: Epoch 016 - training loss: 0.3317, validation loss: 0.0474
2024-05-22 21:37:14 [INFO]: Epoch 017 - training loss: 0.3326, validation loss: 0.0461
2024-05-22 21:37:14 [INFO]: Epoch 018 - training loss: 0.3185, validation loss: 0.0439
2024-05-22 21:37:14 [INFO]: Epoch 019 - training loss: 0.3139, validation loss: 0.0439
2024-05-22 21:37:14 [INFO]: Epoch 020 - training loss: 0.3141, validation loss: 0.0489
2024-05-22 21:37:14 [INFO]: Epoch 021 - training loss: 0.3140, validation loss: 0.0417
2024-05-22 21:37:14 [INFO]: Epoch 022 - training loss: 0.3056, validation loss: 0.0443
2024-05-22 21:37:15 [INFO]: Epoch 023 - training loss: 0.3013, validation loss: 0.0394
2024-05-22 21:37:15 [INFO]: Epoch 024 - training loss: 0.2988, validation loss: 0.0377
2024-05-22 21:37:15 [INFO]: Epoch 025 - training loss: 0.2882, validation loss: 0.0385
2024-05-22 21:37:15 [INFO]: Epoch 026 - training loss: 0.2868, validation loss: 0.0392
2024-05-22 21:37:15 [INFO]: Epoch 027 - training loss: 0.2827, validation loss: 0.0367
2024-05-22 21:37:16 [INFO]: Epoch 028 - training loss: 0.2794, validation loss: 0.0354
2024-05-22 21:37:16 [INFO]: Epoch 029 - training loss: 0.2734, validation loss: 0.0363
2024-05-22 21:37:16 [INFO]: Epoch 030 - training loss: 0.2764, validation loss: 0.0347
2024-05-22 21:37:16 [INFO]: Epoch 031 - training loss: 0.2712, validation loss: 0.0355
2024-05-22 21:37:16 [INFO]: Epoch 032 - training loss: 0.2656, validation loss: 0.0372
2024-05-22 21:37:17 [INFO]: Epoch 033 - training loss: 0.2704, validation loss: 0.0342
2024-05-22 21:37:17 [INFO]: Epoch 034 - training loss: 0.2630, validation loss: 0.0343
2024-05-22 21:37:17 [INFO]: Epoch 035 - training loss: 0.2594, validation loss: 0.0325
2024-05-22 21:37:17 [INFO]: Epoch 036 - training loss: 0.2594, validation loss: 0.0309
2024-05-22 21:37:17 [INFO]: Epoch 037 - training loss: 0.2543, validation loss: 0.0363
2024-05-22 21:37:17 [INFO]: Epoch 038 - training loss: 0.2578, validation loss: 0.0315
2024-05-22 21:37:18 [INFO]: Epoch 039 - training loss: 0.2494, validation loss: 0.0305
2024-05-22 21:37:18 [INFO]: Epoch 040 - training loss: 0.2466, validation loss: 0.0308
2024-05-22 21:37:18 [INFO]: Epoch 041 - training loss: 0.2438, validation loss: 0.0299
2024-05-22 21:37:18 [INFO]: Epoch 042 - training loss: 0.2436, validation loss: 0.0280
2024-05-22 21:37:18 [INFO]: Epoch 043 - training loss: 0.2398, validation loss: 0.0353
2024-05-22 21:37:19 [INFO]: Epoch 044 - training loss: 0.2598, validation loss: 0.0324
2024-05-22 21:37:19 [INFO]: Epoch 045 - training loss: 0.2466, validation loss: 0.0288
2024-05-22 21:37:19 [INFO]: Epoch 046 - training loss: 0.2374, validation loss: 0.0285
2024-05-22 21:37:19 [INFO]: Epoch 047 - training loss: 0.2368, validation loss: 0.0368
2024-05-22 21:37:19 [INFO]: Epoch 048 - training loss: 0.2457, validation loss: 0.0287
2024-05-22 21:37:20 [INFO]: Epoch 049 - training loss: 0.2366, validation loss: 0.0265
2024-05-22 21:37:20 [INFO]: Epoch 050 - training loss: 0.2323, validation loss: 0.0248
2024-05-22 21:37:20 [INFO]: Epoch 051 - training loss: 0.2272, validation loss: 0.0272
2024-05-22 21:37:20 [INFO]: Epoch 052 - training loss: 0.2286, validation loss: 0.0246
2024-05-22 21:37:20 [INFO]: Epoch 053 - training loss: 0.2213, validation loss: 0.0291
2024-05-22 21:37:20 [INFO]: Epoch 054 - training loss: 0.2297, validation loss: 0.0270
2024-05-22 21:37:21 [INFO]: Epoch 055 - training loss: 0.2220, validation loss: 0.0299
2024-05-22 21:37:21 [INFO]: Epoch 056 - training loss: 0.2201, validation loss: 0.0262
2024-05-22 21:37:21 [INFO]: Epoch 057 - training loss: 0.2154, validation loss: 0.0252
2024-05-22 21:37:21 [INFO]: Epoch 058 - training loss: 0.2130, validation loss: 0.0253
2024-05-22 21:37:21 [INFO]: Epoch 059 - training loss: 0.2220, validation loss: 0.0262
2024-05-22 21:37:22 [INFO]: Epoch 060 - training loss: 0.2273, validation loss: 0.0266
2024-05-22 21:37:22 [INFO]: Epoch 061 - training loss: 0.2339, validation loss: 0.0320
2024-05-22 21:37:22 [INFO]: Epoch 062 - training loss: 0.2264, validation loss: 0.0257
2024-05-22 21:37:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:37:22 [INFO]: Finished training. The best model is from epoch#52.
2024-05-22 21:37:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_ettm1/20240522_T213710/Transformer.pypots
2024-05-22 21:37:22 [INFO]: Transformer on ETTm1: MAE=0.1375, MSE=0.0407
2024-05-22 21:37:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-22 21:37:22 [INFO]: Using the given device: cuda:0
2024-05-22 21:37:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213722
2024-05-22 21:37:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213722/tensorboard
2024-05-22 21:37:22 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 21:37:22 [INFO]: Epoch 001 - training loss: 0.1793, validation loss: 0.0574
2024-05-22 21:37:23 [INFO]: Epoch 002 - training loss: 0.0706, validation loss: 0.0445
2024-05-22 21:37:23 [INFO]: Epoch 003 - training loss: 0.0575, validation loss: 0.0374
2024-05-22 21:37:23 [INFO]: Epoch 004 - training loss: 0.0467, validation loss: 0.0343
2024-05-22 21:37:23 [INFO]: Epoch 005 - training loss: 0.0460, validation loss: 0.0313
2024-05-22 21:37:23 [INFO]: Epoch 006 - training loss: 0.0423, validation loss: 0.0316
2024-05-22 21:37:23 [INFO]: Epoch 007 - training loss: 0.0467, validation loss: 0.0307
2024-05-22 21:37:24 [INFO]: Epoch 008 - training loss: 0.0420, validation loss: 0.0286
2024-05-22 21:37:24 [INFO]: Epoch 009 - training loss: 0.0339, validation loss: 0.0262
2024-05-22 21:37:24 [INFO]: Epoch 010 - training loss: 0.0311, validation loss: 0.0256
2024-05-22 21:37:24 [INFO]: Epoch 011 - training loss: 0.0342, validation loss: 0.0259
2024-05-22 21:37:24 [INFO]: Epoch 012 - training loss: 0.0356, validation loss: 0.0265
2024-05-22 21:37:25 [INFO]: Epoch 013 - training loss: 0.0339, validation loss: 0.0263
2024-05-22 21:37:25 [INFO]: Epoch 014 - training loss: 0.0343, validation loss: 0.0252
2024-05-22 21:37:25 [INFO]: Epoch 015 - training loss: 0.0315, validation loss: 0.0250
2024-05-22 21:37:25 [INFO]: Epoch 016 - training loss: 0.0293, validation loss: 0.0249
2024-05-22 21:37:25 [INFO]: Epoch 017 - training loss: 0.0301, validation loss: 0.0246
2024-05-22 21:37:25 [INFO]: Epoch 018 - training loss: 0.0303, validation loss: 0.0243
2024-05-22 21:37:26 [INFO]: Epoch 019 - training loss: 0.0292, validation loss: 0.0251
2024-05-22 21:37:26 [INFO]: Epoch 020 - training loss: 0.0311, validation loss: 0.0242
2024-05-22 21:37:26 [INFO]: Epoch 021 - training loss: 0.0288, validation loss: 0.0274
2024-05-22 21:37:26 [INFO]: Epoch 022 - training loss: 0.0325, validation loss: 0.0254
2024-05-22 21:37:26 [INFO]: Epoch 023 - training loss: 0.0297, validation loss: 0.0246
2024-05-22 21:37:26 [INFO]: Epoch 024 - training loss: 0.0277, validation loss: 0.0238
2024-05-22 21:37:27 [INFO]: Epoch 025 - training loss: 0.0265, validation loss: 0.0239
2024-05-22 21:37:27 [INFO]: Epoch 026 - training loss: 0.0265, validation loss: 0.0240
2024-05-22 21:37:27 [INFO]: Epoch 027 - training loss: 0.0260, validation loss: 0.0240
2024-05-22 21:37:27 [INFO]: Epoch 028 - training loss: 0.0255, validation loss: 0.0245
2024-05-22 21:37:27 [INFO]: Epoch 029 - training loss: 0.0255, validation loss: 0.0235
2024-05-22 21:37:28 [INFO]: Epoch 030 - training loss: 0.0250, validation loss: 0.0236
2024-05-22 21:37:28 [INFO]: Epoch 031 - training loss: 0.0238, validation loss: 0.0232
2024-05-22 21:37:28 [INFO]: Epoch 032 - training loss: 0.0233, validation loss: 0.0235
2024-05-22 21:37:28 [INFO]: Epoch 033 - training loss: 0.0231, validation loss: 0.0239
2024-05-22 21:37:28 [INFO]: Epoch 034 - training loss: 0.0233, validation loss: 0.0235
2024-05-22 21:37:28 [INFO]: Epoch 035 - training loss: 0.0236, validation loss: 0.0234
2024-05-22 21:37:29 [INFO]: Epoch 036 - training loss: 0.0242, validation loss: 0.0245
2024-05-22 21:37:29 [INFO]: Epoch 037 - training loss: 0.0245, validation loss: 0.0241
2024-05-22 21:37:29 [INFO]: Epoch 038 - training loss: 0.0231, validation loss: 0.0233
2024-05-22 21:37:29 [INFO]: Epoch 039 - training loss: 0.0220, validation loss: 0.0236
2024-05-22 21:37:29 [INFO]: Epoch 040 - training loss: 0.0221, validation loss: 0.0235
2024-05-22 21:37:30 [INFO]: Epoch 041 - training loss: 0.0211, validation loss: 0.0230
2024-05-22 21:37:30 [INFO]: Epoch 042 - training loss: 0.0213, validation loss: 0.0235
2024-05-22 21:37:30 [INFO]: Epoch 043 - training loss: 0.0213, validation loss: 0.0248
2024-05-22 21:37:30 [INFO]: Epoch 044 - training loss: 0.0221, validation loss: 0.0240
2024-05-22 21:37:30 [INFO]: Epoch 045 - training loss: 0.0210, validation loss: 0.0236
2024-05-22 21:37:30 [INFO]: Epoch 046 - training loss: 0.0195, validation loss: 0.0236
2024-05-22 21:37:31 [INFO]: Epoch 047 - training loss: 0.0199, validation loss: 0.0228
2024-05-22 21:37:31 [INFO]: Epoch 048 - training loss: 0.0199, validation loss: 0.0243
2024-05-22 21:37:31 [INFO]: Epoch 049 - training loss: 0.0210, validation loss: 0.0259
2024-05-22 21:37:31 [INFO]: Epoch 050 - training loss: 0.0185, validation loss: 0.0228
2024-05-22 21:37:31 [INFO]: Epoch 051 - training loss: 0.0177, validation loss: 0.0232
2024-05-22 21:37:31 [INFO]: Epoch 052 - training loss: 0.0180, validation loss: 0.0238
2024-05-22 21:37:32 [INFO]: Epoch 053 - training loss: 0.0213, validation loss: 0.0247
2024-05-22 21:37:32 [INFO]: Epoch 054 - training loss: 0.0195, validation loss: 0.0246
2024-05-22 21:37:32 [INFO]: Epoch 055 - training loss: 0.0187, validation loss: 0.0242
2024-05-22 21:37:32 [INFO]: Epoch 056 - training loss: 0.0183, validation loss: 0.0237
2024-05-22 21:37:32 [INFO]: Epoch 057 - training loss: 0.0168, validation loss: 0.0241
2024-05-22 21:37:32 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:37:32 [INFO]: Finished training. The best model is from epoch#47.
2024-05-22 21:37:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_ettm1/20240522_T213722/TimesNet.pypots
2024-05-22 21:37:32 [INFO]: TimesNet on ETTm1: MAE=0.1071, MSE=0.0251
2024-05-22 21:37:32 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-22 21:37:32 [INFO]: Using the given device: cuda:0
2024-05-22 21:37:32 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732
2024-05-22 21:37:32 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/tensorboard
2024-05-22 21:37:32 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 21:37:34 [INFO]: Epoch 001 - training loss: 0.7063, validation loss: 0.4450
2024-05-22 21:37:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch1_loss0.44498373568058014.pypots
2024-05-22 21:37:36 [INFO]: Epoch 002 - training loss: 0.4476, validation loss: 0.3691
2024-05-22 21:37:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch2_loss0.3690836727619171.pypots
2024-05-22 21:37:39 [INFO]: Epoch 003 - training loss: 0.3662, validation loss: 0.3388
2024-05-22 21:37:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch3_loss0.3388490378856659.pypots
2024-05-22 21:37:41 [INFO]: Epoch 004 - training loss: 0.3158, validation loss: 0.2923
2024-05-22 21:37:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch4_loss0.2923268526792526.pypots
2024-05-22 21:37:43 [INFO]: Epoch 005 - training loss: 0.3658, validation loss: 0.2966
2024-05-22 21:37:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch5_loss0.29663780331611633.pypots
2024-05-22 21:37:45 [INFO]: Epoch 006 - training loss: 0.3753, validation loss: 0.2695
2024-05-22 21:37:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch6_loss0.26948176324367523.pypots
2024-05-22 21:37:47 [INFO]: Epoch 007 - training loss: 0.2910, validation loss: 0.2618
2024-05-22 21:37:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch7_loss0.2618045508861542.pypots
2024-05-22 21:37:49 [INFO]: Epoch 008 - training loss: 0.2215, validation loss: 0.2422
2024-05-22 21:37:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch8_loss0.2422371730208397.pypots
2024-05-22 21:37:51 [INFO]: Epoch 009 - training loss: 0.2555, validation loss: 0.2344
2024-05-22 21:37:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch9_loss0.2343590185046196.pypots
2024-05-22 21:37:53 [INFO]: Epoch 010 - training loss: 0.2799, validation loss: 0.2683
2024-05-22 21:37:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch10_loss0.2683415040373802.pypots
2024-05-22 21:37:55 [INFO]: Epoch 011 - training loss: 0.2987, validation loss: 0.2286
2024-05-22 21:37:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch11_loss0.22860177233815193.pypots
2024-05-22 21:37:57 [INFO]: Epoch 012 - training loss: 0.2479, validation loss: 0.2178
2024-05-22 21:37:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch12_loss0.2177986465394497.pypots
2024-05-22 21:37:59 [INFO]: Epoch 013 - training loss: 0.2101, validation loss: 0.2181
2024-05-22 21:37:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch13_loss0.21813293173909187.pypots
2024-05-22 21:38:01 [INFO]: Epoch 014 - training loss: 0.2538, validation loss: 0.2155
2024-05-22 21:38:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch14_loss0.2155037373304367.pypots
2024-05-22 21:38:03 [INFO]: Epoch 015 - training loss: 0.1968, validation loss: 0.2001
2024-05-22 21:38:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch15_loss0.20009132102131844.pypots
2024-05-22 21:38:05 [INFO]: Epoch 016 - training loss: 0.1910, validation loss: 0.1983
2024-05-22 21:38:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch16_loss0.1982622891664505.pypots
2024-05-22 21:38:07 [INFO]: Epoch 017 - training loss: 0.2092, validation loss: 0.1909
2024-05-22 21:38:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch17_loss0.19090662896633148.pypots
2024-05-22 21:38:09 [INFO]: Epoch 018 - training loss: 0.2072, validation loss: 0.1911
2024-05-22 21:38:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch18_loss0.1910565420985222.pypots
2024-05-22 21:38:11 [INFO]: Epoch 019 - training loss: 0.1702, validation loss: 0.1816
2024-05-22 21:38:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch19_loss0.18160328269004822.pypots
2024-05-22 21:38:13 [INFO]: Epoch 020 - training loss: 0.1798, validation loss: 0.1875
2024-05-22 21:38:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch20_loss0.18750248849391937.pypots
2024-05-22 21:38:15 [INFO]: Epoch 021 - training loss: 0.1768, validation loss: 0.1797
2024-05-22 21:38:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch21_loss0.17965922504663467.pypots
2024-05-22 21:38:17 [INFO]: Epoch 022 - training loss: 0.1876, validation loss: 0.1703
2024-05-22 21:38:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch22_loss0.17029687762260437.pypots
2024-05-22 21:38:19 [INFO]: Epoch 023 - training loss: 0.1659, validation loss: 0.1772
2024-05-22 21:38:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch23_loss0.1771608367562294.pypots
2024-05-22 21:38:21 [INFO]: Epoch 024 - training loss: 0.1845, validation loss: 0.1770
2024-05-22 21:38:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch24_loss0.1769823245704174.pypots
2024-05-22 21:38:23 [INFO]: Epoch 025 - training loss: 0.1695, validation loss: 0.1679
2024-05-22 21:38:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch25_loss0.16786033287644386.pypots
2024-05-22 21:38:25 [INFO]: Epoch 026 - training loss: 0.2398, validation loss: 0.1689
2024-05-22 21:38:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch26_loss0.16888628900051117.pypots
2024-05-22 21:38:27 [INFO]: Epoch 027 - training loss: 0.2473, validation loss: 0.1657
2024-05-22 21:38:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch27_loss0.1657050959765911.pypots
2024-05-22 21:38:29 [INFO]: Epoch 028 - training loss: 0.1826, validation loss: 0.1621
2024-05-22 21:38:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch28_loss0.16210993379354477.pypots
2024-05-22 21:38:31 [INFO]: Epoch 029 - training loss: 0.1537, validation loss: 0.1661
2024-05-22 21:38:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch29_loss0.1660686582326889.pypots
2024-05-22 21:38:33 [INFO]: Epoch 030 - training loss: 0.2279, validation loss: 0.1668
2024-05-22 21:38:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch30_loss0.16677571833133698.pypots
2024-05-22 21:38:35 [INFO]: Epoch 031 - training loss: 0.1714, validation loss: 0.1545
2024-05-22 21:38:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch31_loss0.15452799573540688.pypots
2024-05-22 21:38:37 [INFO]: Epoch 032 - training loss: 0.1578, validation loss: 0.1628
2024-05-22 21:38:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch32_loss0.16279952600598335.pypots
2024-05-22 21:38:39 [INFO]: Epoch 033 - training loss: 0.1540, validation loss: 0.1571
2024-05-22 21:38:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch33_loss0.15710454061627388.pypots
2024-05-22 21:38:41 [INFO]: Epoch 034 - training loss: 0.1538, validation loss: 0.1552
2024-05-22 21:38:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch34_loss0.1551661714911461.pypots
2024-05-22 21:38:43 [INFO]: Epoch 035 - training loss: 0.1684, validation loss: 0.1494
2024-05-22 21:38:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch35_loss0.14939165487885475.pypots
2024-05-22 21:38:45 [INFO]: Epoch 036 - training loss: 0.1594, validation loss: 0.1593
2024-05-22 21:38:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch36_loss0.1593104712665081.pypots
2024-05-22 21:38:47 [INFO]: Epoch 037 - training loss: 0.2167, validation loss: 0.1703
2024-05-22 21:38:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch37_loss0.1702902391552925.pypots
2024-05-22 21:38:49 [INFO]: Epoch 038 - training loss: 0.2122, validation loss: 0.1742
2024-05-22 21:38:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch38_loss0.17417310178279877.pypots
2024-05-22 21:38:51 [INFO]: Epoch 039 - training loss: 0.1595, validation loss: 0.1567
2024-05-22 21:38:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch39_loss0.15670724213123322.pypots
2024-05-22 21:38:53 [INFO]: Epoch 040 - training loss: 0.1731, validation loss: 0.1747
2024-05-22 21:38:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch40_loss0.17473150044679642.pypots
2024-05-22 21:38:55 [INFO]: Epoch 041 - training loss: 0.1836, validation loss: 0.1704
2024-05-22 21:38:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch41_loss0.17040908336639404.pypots
2024-05-22 21:38:57 [INFO]: Epoch 042 - training loss: 0.1830, validation loss: 0.1664
2024-05-22 21:38:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch42_loss0.16639849916100502.pypots
2024-05-22 21:38:59 [INFO]: Epoch 043 - training loss: 0.2118, validation loss: 0.1608
2024-05-22 21:38:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch43_loss0.16083794087171555.pypots
2024-05-22 21:39:01 [INFO]: Epoch 044 - training loss: 0.1816, validation loss: 0.1621
2024-05-22 21:39:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch44_loss0.16211630031466484.pypots
2024-05-22 21:39:03 [INFO]: Epoch 045 - training loss: 0.1785, validation loss: 0.1523
2024-05-22 21:39:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI_epoch45_loss0.15230045840144157.pypots
2024-05-22 21:39:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:39:03 [INFO]: Finished training. The best model is from epoch#35.
2024-05-22 21:39:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_ettm1/20240522_T213732/CSDI.pypots
2024-05-22 21:39:19 [INFO]: CSDI on ETTm1: MAE=0.1536, MSE=0.0527
2024-05-22 21:39:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-22 21:39:19 [INFO]: Using the given device: cuda:0
2024-05-22 21:39:19 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213919
2024-05-22 21:39:19 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213919/tensorboard
2024-05-22 21:39:19 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 21:39:19 [INFO]: Epoch 001 - training loss: 24238.4824, validation loss: 0.9700
2024-05-22 21:39:19 [INFO]: Epoch 002 - training loss: 22143.9122, validation loss: 0.9529
2024-05-22 21:39:19 [INFO]: Epoch 003 - training loss: 20089.0706, validation loss: 0.9372
2024-05-22 21:39:19 [INFO]: Epoch 004 - training loss: 18119.4783, validation loss: 0.9083
2024-05-22 21:39:19 [INFO]: Epoch 005 - training loss: 16048.1271, validation loss: 0.8383
2024-05-22 21:39:19 [INFO]: Epoch 006 - training loss: 14521.9257, validation loss: 0.7241
2024-05-22 21:39:20 [INFO]: Epoch 007 - training loss: 13009.9882, validation loss: 0.6454
2024-05-22 21:39:20 [INFO]: Epoch 008 - training loss: 12162.0880, validation loss: 0.5794
2024-05-22 21:39:20 [INFO]: Epoch 009 - training loss: 11532.5709, validation loss: 0.5183
2024-05-22 21:39:20 [INFO]: Epoch 010 - training loss: 11030.6712, validation loss: 0.4682
2024-05-22 21:39:20 [INFO]: Epoch 011 - training loss: 10762.0013, validation loss: 0.4440
2024-05-22 21:39:20 [INFO]: Epoch 012 - training loss: 10512.8069, validation loss: 0.4275
2024-05-22 21:39:20 [INFO]: Epoch 013 - training loss: 10405.2191, validation loss: 0.4153
2024-05-22 21:39:20 [INFO]: Epoch 014 - training loss: 10196.5189, validation loss: 0.3888
2024-05-22 21:39:20 [INFO]: Epoch 015 - training loss: 10039.5886, validation loss: 0.3615
2024-05-22 21:39:21 [INFO]: Epoch 016 - training loss: 10010.5249, validation loss: 0.3397
2024-05-22 21:39:21 [INFO]: Epoch 017 - training loss: 9902.7125, validation loss: 0.3163
2024-05-22 21:39:21 [INFO]: Epoch 018 - training loss: 9827.9327, validation loss: 0.2909
2024-05-22 21:39:21 [INFO]: Epoch 019 - training loss: 9733.0386, validation loss: 0.2732
2024-05-22 21:39:21 [INFO]: Epoch 020 - training loss: 9683.0500, validation loss: 0.2520
2024-05-22 21:39:21 [INFO]: Epoch 021 - training loss: 9644.5164, validation loss: 0.2436
2024-05-22 21:39:21 [INFO]: Epoch 022 - training loss: 9616.5623, validation loss: 0.2374
2024-05-22 21:39:21 [INFO]: Epoch 023 - training loss: 9602.1905, validation loss: 0.2325
2024-05-22 21:39:21 [INFO]: Epoch 024 - training loss: 9589.9252, validation loss: 0.2321
2024-05-22 21:39:21 [INFO]: Epoch 025 - training loss: 9541.7389, validation loss: 0.2266
2024-05-22 21:39:22 [INFO]: Epoch 026 - training loss: 9528.2902, validation loss: 0.2211
2024-05-22 21:39:22 [INFO]: Epoch 027 - training loss: 9502.7922, validation loss: 0.2150
2024-05-22 21:39:22 [INFO]: Epoch 028 - training loss: 9499.2725, validation loss: 0.2146
2024-05-22 21:39:22 [INFO]: Epoch 029 - training loss: 9513.3181, validation loss: 0.2077
2024-05-22 21:39:22 [INFO]: Epoch 030 - training loss: 9462.5349, validation loss: 0.2021
2024-05-22 21:39:22 [INFO]: Epoch 031 - training loss: 9458.9747, validation loss: 0.2018
2024-05-22 21:39:22 [INFO]: Epoch 032 - training loss: 9443.8604, validation loss: 0.1968
2024-05-22 21:39:22 [INFO]: Epoch 033 - training loss: 9433.0042, validation loss: 0.1938
2024-05-22 21:39:22 [INFO]: Epoch 034 - training loss: 9423.5627, validation loss: 0.1867
2024-05-22 21:39:23 [INFO]: Epoch 035 - training loss: 9430.0530, validation loss: 0.1842
2024-05-22 21:39:23 [INFO]: Epoch 036 - training loss: 9406.6586, validation loss: 0.1777
2024-05-22 21:39:23 [INFO]: Epoch 037 - training loss: 9408.7943, validation loss: 0.1691
2024-05-22 21:39:23 [INFO]: Epoch 038 - training loss: 9391.6043, validation loss: 0.1693
2024-05-22 21:39:23 [INFO]: Epoch 039 - training loss: 9389.3187, validation loss: 0.1677
2024-05-22 21:39:23 [INFO]: Epoch 040 - training loss: 9382.6575, validation loss: 0.1631
2024-05-22 21:39:23 [INFO]: Epoch 041 - training loss: 9376.8049, validation loss: 0.1615
2024-05-22 21:39:23 [INFO]: Epoch 042 - training loss: 9372.1425, validation loss: 0.1581
2024-05-22 21:39:23 [INFO]: Epoch 043 - training loss: 9368.0565, validation loss: 0.1578
2024-05-22 21:39:23 [INFO]: Epoch 044 - training loss: 9372.6288, validation loss: 0.1534
2024-05-22 21:39:24 [INFO]: Epoch 045 - training loss: 9367.9919, validation loss: 0.1506
2024-05-22 21:39:24 [INFO]: Epoch 046 - training loss: 9357.1400, validation loss: 0.1466
2024-05-22 21:39:24 [INFO]: Epoch 047 - training loss: 9351.7087, validation loss: 0.1464
2024-05-22 21:39:24 [INFO]: Epoch 048 - training loss: 9351.5786, validation loss: 0.1452
2024-05-22 21:39:24 [INFO]: Epoch 049 - training loss: 9347.7489, validation loss: 0.1444
2024-05-22 21:39:24 [INFO]: Epoch 050 - training loss: 9350.1212, validation loss: 0.1430
2024-05-22 21:39:24 [INFO]: Epoch 051 - training loss: 9347.7844, validation loss: 0.1400
2024-05-22 21:39:24 [INFO]: Epoch 052 - training loss: 9339.8528, validation loss: 0.1382
2024-05-22 21:39:24 [INFO]: Epoch 053 - training loss: 9337.3228, validation loss: 0.1381
2024-05-22 21:39:25 [INFO]: Epoch 054 - training loss: 9334.9814, validation loss: 0.1361
2024-05-22 21:39:25 [INFO]: Epoch 055 - training loss: 9333.3252, validation loss: 0.1337
2024-05-22 21:39:25 [INFO]: Epoch 056 - training loss: 9334.4931, validation loss: 0.1340
2024-05-22 21:39:25 [INFO]: Epoch 057 - training loss: 9328.2316, validation loss: 0.1333
2024-05-22 21:39:25 [INFO]: Epoch 058 - training loss: 9337.3239, validation loss: 0.1323
2024-05-22 21:39:25 [INFO]: Epoch 059 - training loss: 9328.2820, validation loss: 0.1302
2024-05-22 21:39:25 [INFO]: Epoch 060 - training loss: 9325.5468, validation loss: 0.1284
2024-05-22 21:39:25 [INFO]: Epoch 061 - training loss: 9324.6408, validation loss: 0.1275
2024-05-22 21:39:25 [INFO]: Epoch 062 - training loss: 9322.4808, validation loss: 0.1270
2024-05-22 21:39:26 [INFO]: Epoch 063 - training loss: 9320.1368, validation loss: 0.1291
2024-05-22 21:39:26 [INFO]: Epoch 064 - training loss: 9320.5144, validation loss: 0.1267
2024-05-22 21:39:26 [INFO]: Epoch 065 - training loss: 9318.6767, validation loss: 0.1247
2024-05-22 21:39:26 [INFO]: Epoch 066 - training loss: 9315.6627, validation loss: 0.1253
2024-05-22 21:39:26 [INFO]: Epoch 067 - training loss: 9315.4727, validation loss: 0.1241
2024-05-22 21:39:26 [INFO]: Epoch 068 - training loss: 9314.4669, validation loss: 0.1237
2024-05-22 21:39:26 [INFO]: Epoch 069 - training loss: 9311.9796, validation loss: 0.1219
2024-05-22 21:39:26 [INFO]: Epoch 070 - training loss: 9312.7186, validation loss: 0.1222
2024-05-22 21:39:26 [INFO]: Epoch 071 - training loss: 9309.0754, validation loss: 0.1216
2024-05-22 21:39:26 [INFO]: Epoch 072 - training loss: 9308.3756, validation loss: 0.1207
2024-05-22 21:39:27 [INFO]: Epoch 073 - training loss: 9307.0291, validation loss: 0.1196
2024-05-22 21:39:27 [INFO]: Epoch 074 - training loss: 9307.0707, validation loss: 0.1191
2024-05-22 21:39:27 [INFO]: Epoch 075 - training loss: 9311.0911, validation loss: 0.1183
2024-05-22 21:39:27 [INFO]: Epoch 076 - training loss: 9304.7343, validation loss: 0.1172
2024-05-22 21:39:27 [INFO]: Epoch 077 - training loss: 9306.7903, validation loss: 0.1170
2024-05-22 21:39:27 [INFO]: Epoch 078 - training loss: 9304.9077, validation loss: 0.1161
2024-05-22 21:39:27 [INFO]: Epoch 079 - training loss: 9305.2479, validation loss: 0.1158
2024-05-22 21:39:27 [INFO]: Epoch 080 - training loss: 9301.7620, validation loss: 0.1149
2024-05-22 21:39:27 [INFO]: Epoch 081 - training loss: 9303.6965, validation loss: 0.1145
2024-05-22 21:39:28 [INFO]: Epoch 082 - training loss: 9299.7600, validation loss: 0.1137
2024-05-22 21:39:28 [INFO]: Epoch 083 - training loss: 9298.7872, validation loss: 0.1122
2024-05-22 21:39:28 [INFO]: Epoch 084 - training loss: 9300.5609, validation loss: 0.1120
2024-05-22 21:39:28 [INFO]: Epoch 085 - training loss: 9297.5215, validation loss: 0.1109
2024-05-22 21:39:28 [INFO]: Epoch 086 - training loss: 9299.5983, validation loss: 0.1111
2024-05-22 21:39:28 [INFO]: Epoch 087 - training loss: 9298.2337, validation loss: 0.1096
2024-05-22 21:39:28 [INFO]: Epoch 088 - training loss: 9299.4111, validation loss: 0.1101
2024-05-22 21:39:28 [INFO]: Epoch 089 - training loss: 9296.7457, validation loss: 0.1122
2024-05-22 21:39:28 [INFO]: Epoch 090 - training loss: 9296.0787, validation loss: 0.1079
2024-05-22 21:39:28 [INFO]: Epoch 091 - training loss: 9299.1489, validation loss: 0.1071
2024-05-22 21:39:29 [INFO]: Epoch 092 - training loss: 9296.1054, validation loss: 0.1081
2024-05-22 21:39:29 [INFO]: Epoch 093 - training loss: 9296.0729, validation loss: 0.1075
2024-05-22 21:39:29 [INFO]: Epoch 094 - training loss: 9295.0909, validation loss: 0.1070
2024-05-22 21:39:29 [INFO]: Epoch 095 - training loss: 9294.3325, validation loss: 0.1071
2024-05-22 21:39:29 [INFO]: Epoch 096 - training loss: 9293.0248, validation loss: 0.1047
2024-05-22 21:39:29 [INFO]: Epoch 097 - training loss: 9295.3716, validation loss: 0.1046
2024-05-22 21:39:29 [INFO]: Epoch 098 - training loss: 9292.4633, validation loss: 0.1035
2024-05-22 21:39:29 [INFO]: Epoch 099 - training loss: 9290.7678, validation loss: 0.1042
2024-05-22 21:39:29 [INFO]: Epoch 100 - training loss: 9293.4958, validation loss: 0.1050
2024-05-22 21:39:30 [INFO]: Epoch 101 - training loss: 9291.3206, validation loss: 0.1029
2024-05-22 21:39:30 [INFO]: Epoch 102 - training loss: 9290.9286, validation loss: 0.1027
2024-05-22 21:39:30 [INFO]: Epoch 103 - training loss: 9290.5619, validation loss: 0.1014
2024-05-22 21:39:30 [INFO]: Epoch 104 - training loss: 9290.0677, validation loss: 0.1013
2024-05-22 21:39:30 [INFO]: Epoch 105 - training loss: 9288.0331, validation loss: 0.1008
2024-05-22 21:39:30 [INFO]: Epoch 106 - training loss: 9288.5253, validation loss: 0.1017
2024-05-22 21:39:30 [INFO]: Epoch 107 - training loss: 9288.2584, validation loss: 0.1013
2024-05-22 21:39:30 [INFO]: Epoch 108 - training loss: 9287.7121, validation loss: 0.0998
2024-05-22 21:39:30 [INFO]: Epoch 109 - training loss: 9287.8538, validation loss: 0.1007
2024-05-22 21:39:31 [INFO]: Epoch 110 - training loss: 9288.0278, validation loss: 0.0992
2024-05-22 21:39:31 [INFO]: Epoch 111 - training loss: 9287.7693, validation loss: 0.0996
2024-05-22 21:39:31 [INFO]: Epoch 112 - training loss: 9287.0734, validation loss: 0.0978
2024-05-22 21:39:31 [INFO]: Epoch 113 - training loss: 9287.4600, validation loss: 0.0967
2024-05-22 21:39:31 [INFO]: Epoch 114 - training loss: 9285.8534, validation loss: 0.0968
2024-05-22 21:39:31 [INFO]: Epoch 115 - training loss: 9287.6049, validation loss: 0.0987
2024-05-22 21:39:31 [INFO]: Epoch 116 - training loss: 9285.6458, validation loss: 0.0969
2024-05-22 21:39:31 [INFO]: Epoch 117 - training loss: 9284.1000, validation loss: 0.0958
2024-05-22 21:39:31 [INFO]: Epoch 118 - training loss: 9287.8610, validation loss: 0.0953
2024-05-22 21:39:31 [INFO]: Epoch 119 - training loss: 9283.1701, validation loss: 0.0966
2024-05-22 21:39:32 [INFO]: Epoch 120 - training loss: 9286.3958, validation loss: 0.0947
2024-05-22 21:39:32 [INFO]: Epoch 121 - training loss: 9285.0930, validation loss: 0.0965
2024-05-22 21:39:32 [INFO]: Epoch 122 - training loss: 9283.9459, validation loss: 0.0943
2024-05-22 21:39:32 [INFO]: Epoch 123 - training loss: 9286.5500, validation loss: 0.0952
2024-05-22 21:39:32 [INFO]: Epoch 124 - training loss: 9283.5989, validation loss: 0.0952
2024-05-22 21:39:32 [INFO]: Epoch 125 - training loss: 9284.2596, validation loss: 0.0933
2024-05-22 21:39:32 [INFO]: Epoch 126 - training loss: 9283.3595, validation loss: 0.0932
2024-05-22 21:39:32 [INFO]: Epoch 127 - training loss: 9283.9955, validation loss: 0.0931
2024-05-22 21:39:32 [INFO]: Epoch 128 - training loss: 9282.7761, validation loss: 0.0919
2024-05-22 21:39:33 [INFO]: Epoch 129 - training loss: 9282.2481, validation loss: 0.0918
2024-05-22 21:39:33 [INFO]: Epoch 130 - training loss: 9282.7106, validation loss: 0.0923
2024-05-22 21:39:33 [INFO]: Epoch 131 - training loss: 9281.4621, validation loss: 0.0922
2024-05-22 21:39:33 [INFO]: Epoch 132 - training loss: 9282.9772, validation loss: 0.0911
2024-05-22 21:39:33 [INFO]: Epoch 133 - training loss: 9280.4602, validation loss: 0.0919
2024-05-22 21:39:33 [INFO]: Epoch 134 - training loss: 9280.6241, validation loss: 0.0909
2024-05-22 21:39:33 [INFO]: Epoch 135 - training loss: 9280.3803, validation loss: 0.0903
2024-05-22 21:39:33 [INFO]: Epoch 136 - training loss: 9280.3387, validation loss: 0.0926
2024-05-22 21:39:33 [INFO]: Epoch 137 - training loss: 9281.8971, validation loss: 0.0884
2024-05-22 21:39:34 [INFO]: Epoch 138 - training loss: 9286.2437, validation loss: 0.0908
2024-05-22 21:39:34 [INFO]: Epoch 139 - training loss: 9280.7682, validation loss: 0.0900
2024-05-22 21:39:34 [INFO]: Epoch 140 - training loss: 9280.5104, validation loss: 0.0901
2024-05-22 21:39:34 [INFO]: Epoch 141 - training loss: 9279.7086, validation loss: 0.0871
2024-05-22 21:39:34 [INFO]: Epoch 142 - training loss: 9281.6169, validation loss: 0.0883
2024-05-22 21:39:34 [INFO]: Epoch 143 - training loss: 9277.6107, validation loss: 0.0882
2024-05-22 21:39:34 [INFO]: Epoch 144 - training loss: 9280.9428, validation loss: 0.0876
2024-05-22 21:39:34 [INFO]: Epoch 145 - training loss: 9280.3086, validation loss: 0.0878
2024-05-22 21:39:34 [INFO]: Epoch 146 - training loss: 9278.0839, validation loss: 0.0867
2024-05-22 21:39:34 [INFO]: Epoch 147 - training loss: 9277.9213, validation loss: 0.0861
2024-05-22 21:39:35 [INFO]: Epoch 148 - training loss: 9279.2699, validation loss: 0.0867
2024-05-22 21:39:35 [INFO]: Epoch 149 - training loss: 9278.2583, validation loss: 0.0873
2024-05-22 21:39:35 [INFO]: Epoch 150 - training loss: 9278.2461, validation loss: 0.0846
2024-05-22 21:39:35 [INFO]: Epoch 151 - training loss: 9278.9179, validation loss: 0.0865
2024-05-22 21:39:35 [INFO]: Epoch 152 - training loss: 9278.7112, validation loss: 0.0851
2024-05-22 21:39:35 [INFO]: Epoch 153 - training loss: 9279.6060, validation loss: 0.0854
2024-05-22 21:39:35 [INFO]: Epoch 154 - training loss: 9277.9115, validation loss: 0.0854
2024-05-22 21:39:35 [INFO]: Epoch 155 - training loss: 9278.2314, validation loss: 0.0842
2024-05-22 21:39:35 [INFO]: Epoch 156 - training loss: 9279.3166, validation loss: 0.0846
2024-05-22 21:39:36 [INFO]: Epoch 157 - training loss: 9278.0718, validation loss: 0.0844
2024-05-22 21:39:36 [INFO]: Epoch 158 - training loss: 9278.0299, validation loss: 0.0837
2024-05-22 21:39:36 [INFO]: Epoch 159 - training loss: 9278.0410, validation loss: 0.0837
2024-05-22 21:39:36 [INFO]: Epoch 160 - training loss: 9277.7806, validation loss: 0.0843
2024-05-22 21:39:36 [INFO]: Epoch 161 - training loss: 9276.8566, validation loss: 0.0830
2024-05-22 21:39:36 [INFO]: Epoch 162 - training loss: 9276.2350, validation loss: 0.0843
2024-05-22 21:39:36 [INFO]: Epoch 163 - training loss: 9277.0107, validation loss: 0.0826
2024-05-22 21:39:36 [INFO]: Epoch 164 - training loss: 9277.8073, validation loss: 0.0826
2024-05-22 21:39:36 [INFO]: Epoch 165 - training loss: 9275.5087, validation loss: 0.0821
2024-05-22 21:39:36 [INFO]: Epoch 166 - training loss: 9275.7462, validation loss: 0.0829
2024-05-22 21:39:37 [INFO]: Epoch 167 - training loss: 9276.3962, validation loss: 0.0830
2024-05-22 21:39:37 [INFO]: Epoch 168 - training loss: 9275.0471, validation loss: 0.0826
2024-05-22 21:39:37 [INFO]: Epoch 169 - training loss: 9275.1734, validation loss: 0.0820
2024-05-22 21:39:37 [INFO]: Epoch 170 - training loss: 9276.7468, validation loss: 0.0827
2024-05-22 21:39:37 [INFO]: Epoch 171 - training loss: 9275.7543, validation loss: 0.0824
2024-05-22 21:39:37 [INFO]: Epoch 172 - training loss: 9276.7190, validation loss: 0.0827
2024-05-22 21:39:37 [INFO]: Epoch 173 - training loss: 9274.7235, validation loss: 0.0802
2024-05-22 21:39:37 [INFO]: Epoch 174 - training loss: 9276.1620, validation loss: 0.0795
2024-05-22 21:39:37 [INFO]: Epoch 175 - training loss: 9276.1826, validation loss: 0.0815
2024-05-22 21:39:38 [INFO]: Epoch 176 - training loss: 9275.2321, validation loss: 0.0819
2024-05-22 21:39:38 [INFO]: Epoch 177 - training loss: 9274.8946, validation loss: 0.0796
2024-05-22 21:39:38 [INFO]: Epoch 178 - training loss: 9274.8846, validation loss: 0.0810
2024-05-22 21:39:38 [INFO]: Epoch 179 - training loss: 9275.0402, validation loss: 0.0793
2024-05-22 21:39:38 [INFO]: Epoch 180 - training loss: 9274.0503, validation loss: 0.0811
2024-05-22 21:39:38 [INFO]: Epoch 181 - training loss: 9273.6294, validation loss: 0.0797
2024-05-22 21:39:38 [INFO]: Epoch 182 - training loss: 9273.7444, validation loss: 0.0800
2024-05-22 21:39:38 [INFO]: Epoch 183 - training loss: 9274.9824, validation loss: 0.0791
2024-05-22 21:39:38 [INFO]: Epoch 184 - training loss: 9273.0956, validation loss: 0.0798
2024-05-22 21:39:39 [INFO]: Epoch 185 - training loss: 9273.9108, validation loss: 0.0796
2024-05-22 21:39:39 [INFO]: Epoch 186 - training loss: 9274.2974, validation loss: 0.0779
2024-05-22 21:39:39 [INFO]: Epoch 187 - training loss: 9273.9761, validation loss: 0.0808
2024-05-22 21:39:39 [INFO]: Epoch 188 - training loss: 9274.8298, validation loss: 0.0786
2024-05-22 21:39:39 [INFO]: Epoch 189 - training loss: 9274.9702, validation loss: 0.0793
2024-05-22 21:39:39 [INFO]: Epoch 190 - training loss: 9272.5577, validation loss: 0.0796
2024-05-22 21:39:39 [INFO]: Epoch 191 - training loss: 9274.1636, validation loss: 0.0778
2024-05-22 21:39:39 [INFO]: Epoch 192 - training loss: 9274.4588, validation loss: 0.0799
2024-05-22 21:39:39 [INFO]: Epoch 193 - training loss: 9273.3624, validation loss: 0.0771
2024-05-22 21:39:40 [INFO]: Epoch 194 - training loss: 9272.8065, validation loss: 0.0776
2024-05-22 21:39:40 [INFO]: Epoch 195 - training loss: 9272.6983, validation loss: 0.0785
2024-05-22 21:39:40 [INFO]: Epoch 196 - training loss: 9273.5289, validation loss: 0.0793
2024-05-22 21:39:40 [INFO]: Epoch 197 - training loss: 9273.6891, validation loss: 0.0782
2024-05-22 21:39:40 [INFO]: Epoch 198 - training loss: 9273.0356, validation loss: 0.0781
2024-05-22 21:39:40 [INFO]: Epoch 199 - training loss: 9272.3974, validation loss: 0.0774
2024-05-22 21:39:40 [INFO]: Epoch 200 - training loss: 9273.4813, validation loss: 0.0773
2024-05-22 21:39:40 [INFO]: Epoch 201 - training loss: 9273.5710, validation loss: 0.0793
2024-05-22 21:39:40 [INFO]: Epoch 202 - training loss: 9273.1511, validation loss: 0.0777
2024-05-22 21:39:40 [INFO]: Epoch 203 - training loss: 9273.2287, validation loss: 0.0773
2024-05-22 21:39:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:39:40 [INFO]: Finished training. The best model is from epoch#193.
2024-05-22 21:39:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_ettm1/20240522_T213919/GPVAE.pypots
2024-05-22 21:39:41 [INFO]: GP-VAE on ETTm1: MAE=0.2916, MSE=0.1728
2024-05-22 21:39:41 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-22 21:39:41 [INFO]: Using the given device: cuda:0
2024-05-22 21:39:41 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240522_T213941
2024-05-22 21:39:41 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_ettm1/20240522_T213941/tensorboard
2024-05-22 21:39:41 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 21:39:49 [INFO]: Epoch 001 - generator training loss: 0.6182, discriminator training loss: 0.4286, validation loss: 0.3509
2024-05-22 21:39:56 [INFO]: Epoch 002 - generator training loss: 0.0125, discriminator training loss: 0.3215, validation loss: 0.1317
2024-05-22 21:40:03 [INFO]: Epoch 003 - generator training loss: -0.1116, discriminator training loss: 0.3112, validation loss: 0.0746
2024-05-22 21:40:10 [INFO]: Epoch 004 - generator training loss: -0.1277, discriminator training loss: 0.2985, validation loss: 0.0525
2024-05-22 21:40:18 [INFO]: Epoch 005 - generator training loss: -0.1263, discriminator training loss: 0.2810, validation loss: 0.0466
2024-05-22 21:40:25 [INFO]: Epoch 006 - generator training loss: -0.1053, discriminator training loss: 0.2538, validation loss: 0.0407
2024-05-22 21:40:32 [INFO]: Epoch 007 - generator training loss: -0.0821, discriminator training loss: 0.2175, validation loss: 0.0375
2024-05-22 21:40:39 [INFO]: Epoch 008 - generator training loss: -0.0574, discriminator training loss: 0.1809, validation loss: 0.0367
2024-05-22 21:40:46 [INFO]: Epoch 009 - generator training loss: -0.0466, discriminator training loss: 0.1584, validation loss: 0.0352
2024-05-22 21:40:53 [INFO]: Epoch 010 - generator training loss: -0.0336, discriminator training loss: 0.1420, validation loss: 0.0352
2024-05-22 21:41:00 [INFO]: Epoch 011 - generator training loss: -0.0294, discriminator training loss: 0.1326, validation loss: 0.0340
2024-05-22 21:41:07 [INFO]: Epoch 012 - generator training loss: -0.0311, discriminator training loss: 0.1284, validation loss: 0.0333
2024-05-22 21:41:15 [INFO]: Epoch 013 - generator training loss: -0.0325, discriminator training loss: 0.1252, validation loss: 0.0324
2024-05-22 21:41:22 [INFO]: Epoch 014 - generator training loss: -0.0284, discriminator training loss: 0.1230, validation loss: 0.0320
2024-05-22 21:41:29 [INFO]: Epoch 015 - generator training loss: -0.0304, discriminator training loss: 0.1188, validation loss: 0.0317
2024-05-22 21:41:36 [INFO]: Epoch 016 - generator training loss: -0.0308, discriminator training loss: 0.1193, validation loss: 0.0307
2024-05-22 21:41:43 [INFO]: Epoch 017 - generator training loss: -0.0303, discriminator training loss: 0.1188, validation loss: 0.0306
2024-05-22 21:41:50 [INFO]: Epoch 018 - generator training loss: -0.0306, discriminator training loss: 0.1187, validation loss: 0.0303
2024-05-22 21:41:57 [INFO]: Epoch 019 - generator training loss: -0.0301, discriminator training loss: 0.1185, validation loss: 0.0299
2024-05-22 21:42:05 [INFO]: Epoch 020 - generator training loss: -0.0276, discriminator training loss: 0.1164, validation loss: 0.0298
2024-05-22 21:42:12 [INFO]: Epoch 021 - generator training loss: -0.0295, discriminator training loss: 0.1144, validation loss: 0.0305
2024-05-22 21:42:19 [INFO]: Epoch 022 - generator training loss: -0.0320, discriminator training loss: 0.1120, validation loss: 0.0295
2024-05-22 21:42:26 [INFO]: Epoch 023 - generator training loss: -0.0343, discriminator training loss: 0.1177, validation loss: 0.0285
2024-05-22 21:42:33 [INFO]: Epoch 024 - generator training loss: -0.0306, discriminator training loss: 0.1138, validation loss: 0.0285
2024-05-22 21:42:40 [INFO]: Epoch 025 - generator training loss: -0.0363, discriminator training loss: 0.1147, validation loss: 0.0287
2024-05-22 21:42:48 [INFO]: Epoch 026 - generator training loss: -0.0316, discriminator training loss: 0.1135, validation loss: 0.0286
2024-05-22 21:42:55 [INFO]: Epoch 027 - generator training loss: -0.0344, discriminator training loss: 0.1126, validation loss: 0.0283
2024-05-22 21:43:02 [INFO]: Epoch 028 - generator training loss: -0.0327, discriminator training loss: 0.1123, validation loss: 0.0278
2024-05-22 21:43:09 [INFO]: Epoch 029 - generator training loss: -0.0339, discriminator training loss: 0.1131, validation loss: 0.0283
2024-05-22 21:43:16 [INFO]: Epoch 030 - generator training loss: -0.0354, discriminator training loss: 0.1133, validation loss: 0.0280
2024-05-22 21:43:23 [INFO]: Epoch 031 - generator training loss: -0.0378, discriminator training loss: 0.1110, validation loss: 0.0276
2024-05-22 21:43:31 [INFO]: Epoch 032 - generator training loss: -0.0374, discriminator training loss: 0.1102, validation loss: 0.0270
2024-05-22 21:43:38 [INFO]: Epoch 033 - generator training loss: -0.0339, discriminator training loss: 0.1112, validation loss: 0.0270
2024-05-22 21:43:45 [INFO]: Epoch 034 - generator training loss: -0.0337, discriminator training loss: 0.1115, validation loss: 0.0264
2024-05-22 21:43:52 [INFO]: Epoch 035 - generator training loss: -0.0386, discriminator training loss: 0.1143, validation loss: 0.0264
2024-05-22 21:43:59 [INFO]: Epoch 036 - generator training loss: -0.0375, discriminator training loss: 0.1109, validation loss: 0.0261
2024-05-22 21:44:06 [INFO]: Epoch 037 - generator training loss: -0.0402, discriminator training loss: 0.1115, validation loss: 0.0259
2024-05-22 21:44:13 [INFO]: Epoch 038 - generator training loss: -0.0355, discriminator training loss: 0.1118, validation loss: 0.0259
2024-05-22 21:44:20 [INFO]: Epoch 039 - generator training loss: -0.0385, discriminator training loss: 0.1104, validation loss: 0.0257
2024-05-22 21:44:27 [INFO]: Epoch 040 - generator training loss: -0.0400, discriminator training loss: 0.1124, validation loss: 0.0270
2024-05-22 21:44:35 [INFO]: Epoch 041 - generator training loss: -0.0363, discriminator training loss: 0.1121, validation loss: 0.0255
2024-05-22 21:44:42 [INFO]: Epoch 042 - generator training loss: -0.0383, discriminator training loss: 0.1114, validation loss: 0.0251
2024-05-22 21:44:49 [INFO]: Epoch 043 - generator training loss: -0.0394, discriminator training loss: 0.1123, validation loss: 0.0249
2024-05-22 21:44:56 [INFO]: Epoch 044 - generator training loss: -0.0364, discriminator training loss: 0.1104, validation loss: 0.0255
2024-05-22 21:45:03 [INFO]: Epoch 045 - generator training loss: -0.0421, discriminator training loss: 0.1129, validation loss: 0.0242
2024-05-22 21:45:11 [INFO]: Epoch 046 - generator training loss: -0.0346, discriminator training loss: 0.1099, validation loss: 0.0246
2024-05-22 21:45:18 [INFO]: Epoch 047 - generator training loss: -0.0411, discriminator training loss: 0.1099, validation loss: 0.0244
2024-05-22 21:45:25 [INFO]: Epoch 048 - generator training loss: -0.0408, discriminator training loss: 0.1092, validation loss: 0.0241
2024-05-22 21:45:32 [INFO]: Epoch 049 - generator training loss: -0.0417, discriminator training loss: 0.1103, validation loss: 0.0238
2024-05-22 21:45:39 [INFO]: Epoch 050 - generator training loss: -0.0403, discriminator training loss: 0.1102, validation loss: 0.0236
2024-05-22 21:45:46 [INFO]: Epoch 051 - generator training loss: -0.0375, discriminator training loss: 0.1114, validation loss: 0.0244
2024-05-22 21:45:54 [INFO]: Epoch 052 - generator training loss: -0.0415, discriminator training loss: 0.1090, validation loss: 0.0233
2024-05-22 21:46:01 [INFO]: Epoch 053 - generator training loss: -0.0403, discriminator training loss: 0.1114, validation loss: 0.0237
2024-05-22 21:46:08 [INFO]: Epoch 054 - generator training loss: -0.0400, discriminator training loss: 0.1110, validation loss: 0.0232
2024-05-22 21:46:15 [INFO]: Epoch 055 - generator training loss: -0.0407, discriminator training loss: 0.1104, validation loss: 0.0225
2024-05-22 21:46:22 [INFO]: Epoch 056 - generator training loss: -0.0403, discriminator training loss: 0.1084, validation loss: 0.0228
2024-05-22 21:46:29 [INFO]: Epoch 057 - generator training loss: -0.0427, discriminator training loss: 0.1082, validation loss: 0.0226
2024-05-22 21:46:36 [INFO]: Epoch 058 - generator training loss: -0.0404, discriminator training loss: 0.1098, validation loss: 0.0221
2024-05-22 21:46:43 [INFO]: Epoch 059 - generator training loss: -0.0430, discriminator training loss: 0.1101, validation loss: 0.0224
2024-05-22 21:46:50 [INFO]: Epoch 060 - generator training loss: -0.0414, discriminator training loss: 0.1088, validation loss: 0.0224
2024-05-22 21:46:58 [INFO]: Epoch 061 - generator training loss: -0.0426, discriminator training loss: 0.1085, validation loss: 0.0221
2024-05-22 21:47:05 [INFO]: Epoch 062 - generator training loss: -0.0426, discriminator training loss: 0.1102, validation loss: 0.0223
2024-05-22 21:47:12 [INFO]: Epoch 063 - generator training loss: -0.0434, discriminator training loss: 0.1062, validation loss: 0.0220
2024-05-22 21:47:19 [INFO]: Epoch 064 - generator training loss: -0.0410, discriminator training loss: 0.1081, validation loss: 0.0220
2024-05-22 21:47:26 [INFO]: Epoch 065 - generator training loss: -0.0427, discriminator training loss: 0.1064, validation loss: 0.0218
2024-05-22 21:47:33 [INFO]: Epoch 066 - generator training loss: -0.0421, discriminator training loss: 0.1094, validation loss: 0.0218
2024-05-22 21:47:40 [INFO]: Epoch 067 - generator training loss: -0.0385, discriminator training loss: 0.1071, validation loss: 0.0225
2024-05-22 21:47:48 [INFO]: Epoch 068 - generator training loss: -0.0433, discriminator training loss: 0.1091, validation loss: 0.0216
2024-05-22 21:47:55 [INFO]: Epoch 069 - generator training loss: -0.0409, discriminator training loss: 0.1065, validation loss: 0.0213
2024-05-22 21:48:02 [INFO]: Epoch 070 - generator training loss: -0.0428, discriminator training loss: 0.1086, validation loss: 0.0220
2024-05-22 21:48:09 [INFO]: Epoch 071 - generator training loss: -0.0409, discriminator training loss: 0.1077, validation loss: 0.0218
2024-05-22 21:48:17 [INFO]: Epoch 072 - generator training loss: -0.0427, discriminator training loss: 0.1083, validation loss: 0.0225
2024-05-22 21:48:24 [INFO]: Epoch 073 - generator training loss: -0.0430, discriminator training loss: 0.1058, validation loss: 0.0217
2024-05-22 21:48:31 [INFO]: Epoch 074 - generator training loss: -0.0439, discriminator training loss: 0.1068, validation loss: 0.0212
2024-05-22 21:48:38 [INFO]: Epoch 075 - generator training loss: -0.0436, discriminator training loss: 0.1085, validation loss: 0.0211
2024-05-22 21:48:45 [INFO]: Epoch 076 - generator training loss: -0.0455, discriminator training loss: 0.1092, validation loss: 0.0213
2024-05-22 21:48:52 [INFO]: Epoch 077 - generator training loss: -0.0421, discriminator training loss: 0.1072, validation loss: 0.0216
2024-05-22 21:48:59 [INFO]: Epoch 078 - generator training loss: -0.0443, discriminator training loss: 0.1083, validation loss: 0.0213
2024-05-22 21:49:06 [INFO]: Epoch 079 - generator training loss: -0.0433, discriminator training loss: 0.1070, validation loss: 0.0207
2024-05-22 21:49:13 [INFO]: Epoch 080 - generator training loss: -0.0475, discriminator training loss: 0.1076, validation loss: 0.0209
2024-05-22 21:49:21 [INFO]: Epoch 081 - generator training loss: -0.0427, discriminator training loss: 0.1063, validation loss: 0.0204
2024-05-22 21:49:28 [INFO]: Epoch 082 - generator training loss: -0.0458, discriminator training loss: 0.1085, validation loss: 0.0209
2024-05-22 21:49:35 [INFO]: Epoch 083 - generator training loss: -0.0446, discriminator training loss: 0.1075, validation loss: 0.0203
2024-05-22 21:49:42 [INFO]: Epoch 084 - generator training loss: -0.0447, discriminator training loss: 0.1052, validation loss: 0.0204
2024-05-22 21:49:49 [INFO]: Epoch 085 - generator training loss: -0.0447, discriminator training loss: 0.1066, validation loss: 0.0204
2024-05-22 21:49:56 [INFO]: Epoch 086 - generator training loss: -0.0458, discriminator training loss: 0.1059, validation loss: 0.0200
2024-05-22 21:50:03 [INFO]: Epoch 087 - generator training loss: -0.0465, discriminator training loss: 0.1048, validation loss: 0.0200
2024-05-22 21:50:11 [INFO]: Epoch 088 - generator training loss: -0.0422, discriminator training loss: 0.1058, validation loss: 0.0201
2024-05-22 21:50:18 [INFO]: Epoch 089 - generator training loss: -0.0481, discriminator training loss: 0.1066, validation loss: 0.0198
2024-05-22 21:50:25 [INFO]: Epoch 090 - generator training loss: -0.0439, discriminator training loss: 0.1047, validation loss: 0.0203
2024-05-22 21:50:32 [INFO]: Epoch 091 - generator training loss: -0.0449, discriminator training loss: 0.1046, validation loss: 0.0199
2024-05-22 21:50:39 [INFO]: Epoch 092 - generator training loss: -0.0482, discriminator training loss: 0.1047, validation loss: 0.0202
2024-05-22 21:50:47 [INFO]: Epoch 093 - generator training loss: -0.0450, discriminator training loss: 0.1062, validation loss: 0.0195
2024-05-22 21:50:54 [INFO]: Epoch 094 - generator training loss: -0.0445, discriminator training loss: 0.1049, validation loss: 0.0197
2024-05-22 21:51:02 [INFO]: Epoch 095 - generator training loss: -0.0477, discriminator training loss: 0.1058, validation loss: 0.0198
2024-05-22 21:51:09 [INFO]: Epoch 096 - generator training loss: -0.0436, discriminator training loss: 0.1064, validation loss: 0.0198
2024-05-22 21:51:16 [INFO]: Epoch 097 - generator training loss: -0.0433, discriminator training loss: 0.1046, validation loss: 0.0209
2024-05-22 21:51:23 [INFO]: Epoch 098 - generator training loss: -0.0457, discriminator training loss: 0.1047, validation loss: 0.0197
2024-05-22 21:51:31 [INFO]: Epoch 099 - generator training loss: -0.0451, discriminator training loss: 0.1045, validation loss: 0.0197
2024-05-22 21:51:38 [INFO]: Epoch 100 - generator training loss: -0.0472, discriminator training loss: 0.1049, validation loss: 0.0194
2024-05-22 21:51:45 [INFO]: Epoch 101 - generator training loss: -0.0446, discriminator training loss: 0.1056, validation loss: 0.0188
2024-05-22 21:51:52 [INFO]: Epoch 102 - generator training loss: -0.0461, discriminator training loss: 0.1050, validation loss: 0.0192
2024-05-22 21:51:59 [INFO]: Epoch 103 - generator training loss: -0.0438, discriminator training loss: 0.1057, validation loss: 0.0189
2024-05-22 21:52:06 [INFO]: Epoch 104 - generator training loss: -0.0488, discriminator training loss: 0.1092, validation loss: 0.0206
2024-05-22 21:52:14 [INFO]: Epoch 105 - generator training loss: -0.0448, discriminator training loss: 0.1060, validation loss: 0.0191
2024-05-22 21:52:21 [INFO]: Epoch 106 - generator training loss: -0.0456, discriminator training loss: 0.1066, validation loss: 0.0188
2024-05-22 21:52:28 [INFO]: Epoch 107 - generator training loss: -0.0441, discriminator training loss: 0.1041, validation loss: 0.0187
2024-05-22 21:52:35 [INFO]: Epoch 108 - generator training loss: -0.0456, discriminator training loss: 0.1064, validation loss: 0.0197
2024-05-22 21:52:42 [INFO]: Epoch 109 - generator training loss: -0.0443, discriminator training loss: 0.1072, validation loss: 0.0188
2024-05-22 21:52:50 [INFO]: Epoch 110 - generator training loss: -0.0457, discriminator training loss: 0.1059, validation loss: 0.0189
2024-05-22 21:52:57 [INFO]: Epoch 111 - generator training loss: -0.0472, discriminator training loss: 0.1056, validation loss: 0.0192
2024-05-22 21:53:04 [INFO]: Epoch 112 - generator training loss: -0.0444, discriminator training loss: 0.1058, validation loss: 0.0188
2024-05-22 21:53:11 [INFO]: Epoch 113 - generator training loss: -0.0453, discriminator training loss: 0.1046, validation loss: 0.0189
2024-05-22 21:53:18 [INFO]: Epoch 114 - generator training loss: -0.0475, discriminator training loss: 0.1050, validation loss: 0.0186
2024-05-22 21:53:26 [INFO]: Epoch 115 - generator training loss: -0.0447, discriminator training loss: 0.1027, validation loss: 0.0190
2024-05-22 21:53:33 [INFO]: Epoch 116 - generator training loss: -0.0463, discriminator training loss: 0.1035, validation loss: 0.0193
2024-05-22 21:53:40 [INFO]: Epoch 117 - generator training loss: -0.0466, discriminator training loss: 0.1053, validation loss: 0.0189
2024-05-22 21:53:47 [INFO]: Epoch 118 - generator training loss: -0.0455, discriminator training loss: 0.1033, validation loss: 0.0192
2024-05-22 21:53:54 [INFO]: Epoch 119 - generator training loss: -0.0456, discriminator training loss: 0.1065, validation loss: 0.0190
2024-05-22 21:54:01 [INFO]: Epoch 120 - generator training loss: -0.0449, discriminator training loss: 0.1055, validation loss: 0.0186
2024-05-22 21:54:08 [INFO]: Epoch 121 - generator training loss: -0.0442, discriminator training loss: 0.1059, validation loss: 0.0193
2024-05-22 21:54:16 [INFO]: Epoch 122 - generator training loss: -0.0464, discriminator training loss: 0.1031, validation loss: 0.0196
2024-05-22 21:54:24 [INFO]: Epoch 123 - generator training loss: -0.0477, discriminator training loss: 0.1053, validation loss: 0.0188
2024-05-22 21:54:31 [INFO]: Epoch 124 - generator training loss: -0.0469, discriminator training loss: 0.1044, validation loss: 0.0190
2024-05-22 21:54:38 [INFO]: Epoch 125 - generator training loss: -0.0436, discriminator training loss: 0.1036, validation loss: 0.0193
2024-05-22 21:54:46 [INFO]: Epoch 126 - generator training loss: -0.0465, discriminator training loss: 0.1056, validation loss: 0.0187
2024-05-22 21:54:53 [INFO]: Epoch 127 - generator training loss: -0.0462, discriminator training loss: 0.1053, validation loss: 0.0186
2024-05-22 21:55:00 [INFO]: Epoch 128 - generator training loss: -0.0461, discriminator training loss: 0.1033, validation loss: 0.0187
2024-05-22 21:55:07 [INFO]: Epoch 129 - generator training loss: -0.0436, discriminator training loss: 0.1060, validation loss: 0.0186
2024-05-22 21:55:14 [INFO]: Epoch 130 - generator training loss: -0.0393, discriminator training loss: 0.1037, validation loss: 0.0231
2024-05-22 21:55:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:55:14 [INFO]: Finished training. The best model is from epoch#120.
2024-05-22 21:55:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_ettm1/20240522_T213941/USGAN.pypots
2024-05-22 21:55:15 [INFO]: US-GAN on ETTm1: MAE=0.1469, MSE=0.0548
2024-05-22 21:55:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-22 21:55:15 [INFO]: Using the given device: cuda:0
2024-05-22 21:55:15 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240522_T215515
2024-05-22 21:55:15 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_ettm1/20240522_T215515/tensorboard
2024-05-22 21:55:15 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 21:55:21 [INFO]: Epoch 001 - training loss: 1.3618, validation loss: 0.2642
2024-05-22 21:55:26 [INFO]: Epoch 002 - training loss: 0.9386, validation loss: 0.0831
2024-05-22 21:55:31 [INFO]: Epoch 003 - training loss: 0.7528, validation loss: 0.0636
2024-05-22 21:55:35 [INFO]: Epoch 004 - training loss: 0.6803, validation loss: 0.0511
2024-05-22 21:55:40 [INFO]: Epoch 005 - training loss: 0.6226, validation loss: 0.0400
2024-05-22 21:55:45 [INFO]: Epoch 006 - training loss: 0.5898, validation loss: 0.0374
2024-05-22 21:55:49 [INFO]: Epoch 007 - training loss: 0.5480, validation loss: 0.0345
2024-05-22 21:55:54 [INFO]: Epoch 008 - training loss: 0.5287, validation loss: 0.0337
2024-05-22 21:55:59 [INFO]: Epoch 009 - training loss: 0.5085, validation loss: 0.0307
2024-05-22 21:56:04 [INFO]: Epoch 010 - training loss: 0.4997, validation loss: 0.0308
2024-05-22 21:56:08 [INFO]: Epoch 011 - training loss: 0.4803, validation loss: 0.0312
2024-05-22 21:56:13 [INFO]: Epoch 012 - training loss: 0.4575, validation loss: 0.0305
2024-05-22 21:56:18 [INFO]: Epoch 013 - training loss: 0.4523, validation loss: 0.0284
2024-05-22 21:56:23 [INFO]: Epoch 014 - training loss: 0.4394, validation loss: 0.0283
2024-05-22 21:56:28 [INFO]: Epoch 015 - training loss: 0.4217, validation loss: 0.0266
2024-05-22 21:56:32 [INFO]: Epoch 016 - training loss: 0.4104, validation loss: 0.0259
2024-05-22 21:56:37 [INFO]: Epoch 017 - training loss: 0.4033, validation loss: 0.0245
2024-05-22 21:56:42 [INFO]: Epoch 018 - training loss: 0.4103, validation loss: 0.0242
2024-05-22 21:56:47 [INFO]: Epoch 019 - training loss: 0.3943, validation loss: 0.0238
2024-05-22 21:56:51 [INFO]: Epoch 020 - training loss: 0.3909, validation loss: 0.0232
2024-05-22 21:56:56 [INFO]: Epoch 021 - training loss: 0.3889, validation loss: 0.0230
2024-05-22 21:57:01 [INFO]: Epoch 022 - training loss: 0.3929, validation loss: 0.0230
2024-05-22 21:57:06 [INFO]: Epoch 023 - training loss: 0.3922, validation loss: 0.0227
2024-05-22 21:57:10 [INFO]: Epoch 024 - training loss: 0.3905, validation loss: 0.0222
2024-05-22 21:57:15 [INFO]: Epoch 025 - training loss: 0.3912, validation loss: 0.0223
2024-05-22 21:57:20 [INFO]: Epoch 026 - training loss: 0.3904, validation loss: 0.0222
2024-05-22 21:57:25 [INFO]: Epoch 027 - training loss: 0.3939, validation loss: 0.0220
2024-05-22 21:57:30 [INFO]: Epoch 028 - training loss: 0.4022, validation loss: 0.0228
2024-05-22 21:57:34 [INFO]: Epoch 029 - training loss: 0.3971, validation loss: 0.0230
2024-05-22 21:57:39 [INFO]: Epoch 030 - training loss: 0.3869, validation loss: 0.0224
2024-05-22 21:57:44 [INFO]: Epoch 031 - training loss: 0.3908, validation loss: 0.0219
2024-05-22 21:57:49 [INFO]: Epoch 032 - training loss: 0.3880, validation loss: 0.0226
2024-05-22 21:57:53 [INFO]: Epoch 033 - training loss: 0.3835, validation loss: 0.0221
2024-05-22 21:57:58 [INFO]: Epoch 034 - training loss: 0.3818, validation loss: 0.0222
2024-05-22 21:58:03 [INFO]: Epoch 035 - training loss: 0.3820, validation loss: 0.0220
2024-05-22 21:58:08 [INFO]: Epoch 036 - training loss: 0.3827, validation loss: 0.0224
2024-05-22 21:58:12 [INFO]: Epoch 037 - training loss: 0.3823, validation loss: 0.0218
2024-05-22 21:58:17 [INFO]: Epoch 038 - training loss: 0.3887, validation loss: 0.0221
2024-05-22 21:58:22 [INFO]: Epoch 039 - training loss: 0.3815, validation loss: 0.0235
2024-05-22 21:58:27 [INFO]: Epoch 040 - training loss: 0.3810, validation loss: 0.0223
2024-05-22 21:58:31 [INFO]: Epoch 041 - training loss: 0.3810, validation loss: 0.0221
2024-05-22 21:58:36 [INFO]: Epoch 042 - training loss: 0.3800, validation loss: 0.0219
2024-05-22 21:58:41 [INFO]: Epoch 043 - training loss: 0.3781, validation loss: 0.0225
2024-05-22 21:58:45 [INFO]: Epoch 044 - training loss: 0.3930, validation loss: 0.0225
2024-05-22 21:58:50 [INFO]: Epoch 045 - training loss: 0.3824, validation loss: 0.0220
2024-05-22 21:58:55 [INFO]: Epoch 046 - training loss: 0.3849, validation loss: 0.0217
2024-05-22 21:59:00 [INFO]: Epoch 047 - training loss: 0.3775, validation loss: 0.0221
2024-05-22 21:59:04 [INFO]: Epoch 048 - training loss: 0.3757, validation loss: 0.0218
2024-05-22 21:59:09 [INFO]: Epoch 049 - training loss: 0.3779, validation loss: 0.0219
2024-05-22 21:59:14 [INFO]: Epoch 050 - training loss: 0.3830, validation loss: 0.0225
2024-05-22 21:59:19 [INFO]: Epoch 051 - training loss: 0.3833, validation loss: 0.0223
2024-05-22 21:59:24 [INFO]: Epoch 052 - training loss: 0.3856, validation loss: 0.0236
2024-05-22 21:59:28 [INFO]: Epoch 053 - training loss: 0.3903, validation loss: 0.0227
2024-05-22 21:59:33 [INFO]: Epoch 054 - training loss: 0.4015, validation loss: 0.0233
2024-05-22 21:59:38 [INFO]: Epoch 055 - training loss: 0.3880, validation loss: 0.0224
2024-05-22 21:59:43 [INFO]: Epoch 056 - training loss: 0.3757, validation loss: 0.0222
2024-05-22 21:59:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 21:59:43 [INFO]: Finished training. The best model is from epoch#46.
2024-05-22 21:59:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_ettm1/20240522_T215515/BRITS.pypots
2024-05-22 21:59:43 [INFO]: BRITS on ETTm1: MAE=0.1340, MSE=0.0566
2024-05-22 21:59:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-22 21:59:43 [INFO]: Using the given device: cuda:0
2024-05-22 21:59:43 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943
2024-05-22 21:59:43 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/tensorboard
2024-05-22 21:59:43 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 21:59:45 [INFO]: Epoch 001 - training loss: 1.3603, validation loss: 1.2820
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch1_loss1.2820418030023575.pypots
2024-05-22 21:59:45 [INFO]: Epoch 002 - training loss: 1.0445, validation loss: 1.1399
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch2_loss1.1398688554763794.pypots
2024-05-22 21:59:45 [INFO]: Epoch 003 - training loss: 0.9760, validation loss: 1.0577
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch3_loss1.0577455163002014.pypots
2024-05-22 21:59:45 [INFO]: Epoch 004 - training loss: 0.9462, validation loss: 1.0134
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch4_loss1.0134307742118835.pypots
2024-05-22 21:59:45 [INFO]: Epoch 005 - training loss: 0.9375, validation loss: 1.0003
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch5_loss1.0003448724746704.pypots
2024-05-22 21:59:45 [INFO]: Epoch 006 - training loss: 0.9041, validation loss: 0.9917
2024-05-22 21:59:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch6_loss0.9917298704385757.pypots
2024-05-22 21:59:46 [INFO]: Epoch 007 - training loss: 0.9115, validation loss: 0.9832
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch7_loss0.9832213670015335.pypots
2024-05-22 21:59:46 [INFO]: Epoch 008 - training loss: 0.9021, validation loss: 0.9760
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch8_loss0.9759979844093323.pypots
2024-05-22 21:59:46 [INFO]: Epoch 009 - training loss: 0.9062, validation loss: 0.9711
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch9_loss0.971143364906311.pypots
2024-05-22 21:59:46 [INFO]: Epoch 010 - training loss: 0.9016, validation loss: 0.9693
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch10_loss0.9693343490362167.pypots
2024-05-22 21:59:46 [INFO]: Epoch 011 - training loss: 0.8755, validation loss: 0.9670
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch11_loss0.9670491516590118.pypots
2024-05-22 21:59:46 [INFO]: Epoch 012 - training loss: 0.8824, validation loss: 0.9651
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch12_loss0.9651156365871429.pypots
2024-05-22 21:59:46 [INFO]: Epoch 013 - training loss: 0.8762, validation loss: 0.9661
2024-05-22 21:59:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch13_loss0.9661325365304947.pypots
2024-05-22 21:59:47 [INFO]: Epoch 014 - training loss: 0.8640, validation loss: 0.9637
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch14_loss0.9636737108230591.pypots
2024-05-22 21:59:47 [INFO]: Epoch 015 - training loss: 0.8728, validation loss: 0.9627
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch15_loss0.9627363234758377.pypots
2024-05-22 21:59:47 [INFO]: Epoch 016 - training loss: 0.8825, validation loss: 0.9622
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch16_loss0.9622179716825485.pypots
2024-05-22 21:59:47 [INFO]: Epoch 017 - training loss: 0.8593, validation loss: 0.9628
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch17_loss0.9627685546875.pypots
2024-05-22 21:59:47 [INFO]: Epoch 018 - training loss: 0.8695, validation loss: 0.9575
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch18_loss0.9575179517269135.pypots
2024-05-22 21:59:47 [INFO]: Epoch 019 - training loss: 0.8524, validation loss: 0.9632
2024-05-22 21:59:47 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch19_loss0.9631749391555786.pypots
2024-05-22 21:59:48 [INFO]: Epoch 020 - training loss: 0.8432, validation loss: 0.9627
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch20_loss0.9626941978931427.pypots
2024-05-22 21:59:48 [INFO]: Epoch 021 - training loss: 0.8497, validation loss: 0.9605
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch21_loss0.9604645073413849.pypots
2024-05-22 21:59:48 [INFO]: Epoch 022 - training loss: 0.8325, validation loss: 0.9637
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch22_loss0.9637356251478195.pypots
2024-05-22 21:59:48 [INFO]: Epoch 023 - training loss: 0.8435, validation loss: 0.9630
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch23_loss0.9629715532064438.pypots
2024-05-22 21:59:48 [INFO]: Epoch 024 - training loss: 0.8216, validation loss: 0.9599
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch24_loss0.9598512202501297.pypots
2024-05-22 21:59:48 [INFO]: Epoch 025 - training loss: 0.8375, validation loss: 0.9561
2024-05-22 21:59:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch25_loss0.9561257064342499.pypots
2024-05-22 21:59:49 [INFO]: Epoch 026 - training loss: 0.8341, validation loss: 0.9555
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch26_loss0.9554987400770187.pypots
2024-05-22 21:59:49 [INFO]: Epoch 027 - training loss: 0.8229, validation loss: 0.9540
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch27_loss0.9539560079574585.pypots
2024-05-22 21:59:49 [INFO]: Epoch 028 - training loss: 0.8168, validation loss: 0.9517
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch28_loss0.9517264813184738.pypots
2024-05-22 21:59:49 [INFO]: Epoch 029 - training loss: 0.8151, validation loss: 0.9505
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch29_loss0.9504687339067459.pypots
2024-05-22 21:59:49 [INFO]: Epoch 030 - training loss: 0.8179, validation loss: 0.9470
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch30_loss0.9470176100730896.pypots
2024-05-22 21:59:49 [INFO]: Epoch 031 - training loss: 0.8127, validation loss: 0.9393
2024-05-22 21:59:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch31_loss0.9393215179443359.pypots
2024-05-22 21:59:50 [INFO]: Epoch 032 - training loss: 0.8151, validation loss: 0.9351
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch32_loss0.9351342767477036.pypots
2024-05-22 21:59:50 [INFO]: Epoch 033 - training loss: 0.8185, validation loss: 0.9330
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch33_loss0.932964101433754.pypots
2024-05-22 21:59:50 [INFO]: Epoch 034 - training loss: 0.8214, validation loss: 0.9268
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch34_loss0.9268307685852051.pypots
2024-05-22 21:59:50 [INFO]: Epoch 035 - training loss: 0.8016, validation loss: 0.9213
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch35_loss0.9213010966777802.pypots
2024-05-22 21:59:50 [INFO]: Epoch 036 - training loss: 0.8039, validation loss: 0.9168
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch36_loss0.9168130457401276.pypots
2024-05-22 21:59:50 [INFO]: Epoch 037 - training loss: 0.8072, validation loss: 0.9143
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch37_loss0.9143196940422058.pypots
2024-05-22 21:59:50 [INFO]: Epoch 038 - training loss: 0.8099, validation loss: 0.9110
2024-05-22 21:59:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch38_loss0.9109717309474945.pypots
2024-05-22 21:59:51 [INFO]: Epoch 039 - training loss: 0.7842, validation loss: 0.9075
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch39_loss0.9075052589178085.pypots
2024-05-22 21:59:51 [INFO]: Epoch 040 - training loss: 0.8376, validation loss: 0.9034
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch40_loss0.9033746719360352.pypots
2024-05-22 21:59:51 [INFO]: Epoch 041 - training loss: 0.8068, validation loss: 0.8999
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch41_loss0.8998580574989319.pypots
2024-05-22 21:59:51 [INFO]: Epoch 042 - training loss: 0.7962, validation loss: 0.8945
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch42_loss0.8944688141345978.pypots
2024-05-22 21:59:51 [INFO]: Epoch 043 - training loss: 0.7845, validation loss: 0.8919
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch43_loss0.8919432163238525.pypots
2024-05-22 21:59:51 [INFO]: Epoch 044 - training loss: 0.7881, validation loss: 0.8880
2024-05-22 21:59:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch44_loss0.8880251795053482.pypots
2024-05-22 21:59:52 [INFO]: Epoch 045 - training loss: 0.7738, validation loss: 0.8882
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch45_loss0.8882067948579788.pypots
2024-05-22 21:59:52 [INFO]: Epoch 046 - training loss: 0.7764, validation loss: 0.8843
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch46_loss0.8843268603086472.pypots
2024-05-22 21:59:52 [INFO]: Epoch 047 - training loss: 0.7846, validation loss: 0.8809
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch47_loss0.8809313327074051.pypots
2024-05-22 21:59:52 [INFO]: Epoch 048 - training loss: 0.7907, validation loss: 0.8781
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch48_loss0.8780836910009384.pypots
2024-05-22 21:59:52 [INFO]: Epoch 049 - training loss: 0.7931, validation loss: 0.8771
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch49_loss0.8770929872989655.pypots
2024-05-22 21:59:52 [INFO]: Epoch 050 - training loss: 0.8148, validation loss: 0.8736
2024-05-22 21:59:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch50_loss0.873634085059166.pypots
2024-05-22 21:59:53 [INFO]: Epoch 051 - training loss: 0.8189, validation loss: 0.8719
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch51_loss0.8719054311513901.pypots
2024-05-22 21:59:53 [INFO]: Epoch 052 - training loss: 0.7826, validation loss: 0.8716
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch52_loss0.871567890048027.pypots
2024-05-22 21:59:53 [INFO]: Epoch 053 - training loss: 0.7859, validation loss: 0.8697
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch53_loss0.869708389043808.pypots
2024-05-22 21:59:53 [INFO]: Epoch 054 - training loss: 0.7901, validation loss: 0.8675
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch54_loss0.8675202429294586.pypots
2024-05-22 21:59:53 [INFO]: Epoch 055 - training loss: 0.7892, validation loss: 0.8672
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch55_loss0.8672342002391815.pypots
2024-05-22 21:59:53 [INFO]: Epoch 056 - training loss: 0.8013, validation loss: 0.8643
2024-05-22 21:59:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch56_loss0.8643306493759155.pypots
2024-05-22 21:59:54 [INFO]: Epoch 057 - training loss: 0.7795, validation loss: 0.8654
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch57_loss0.8653840720653534.pypots
2024-05-22 21:59:54 [INFO]: Epoch 058 - training loss: 0.7627, validation loss: 0.8644
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch58_loss0.8644267022609711.pypots
2024-05-22 21:59:54 [INFO]: Epoch 059 - training loss: 0.7859, validation loss: 0.8636
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch59_loss0.8635743111371994.pypots
2024-05-22 21:59:54 [INFO]: Epoch 060 - training loss: 0.7804, validation loss: 0.8602
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch60_loss0.8601602166891098.pypots
2024-05-22 21:59:54 [INFO]: Epoch 061 - training loss: 0.7953, validation loss: 0.8592
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch61_loss0.8591512739658356.pypots
2024-05-22 21:59:54 [INFO]: Epoch 062 - training loss: 0.7838, validation loss: 0.8585
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch62_loss0.8584767132997513.pypots
2024-05-22 21:59:54 [INFO]: Epoch 063 - training loss: 0.7511, validation loss: 0.8572
2024-05-22 21:59:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch63_loss0.8571727722883224.pypots
2024-05-22 21:59:55 [INFO]: Epoch 064 - training loss: 0.7882, validation loss: 0.8582
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch64_loss0.8581827282905579.pypots
2024-05-22 21:59:55 [INFO]: Epoch 065 - training loss: 0.7707, validation loss: 0.8536
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch65_loss0.8536232858896255.pypots
2024-05-22 21:59:55 [INFO]: Epoch 066 - training loss: 0.7645, validation loss: 0.8553
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch66_loss0.8552649170160294.pypots
2024-05-22 21:59:55 [INFO]: Epoch 067 - training loss: 0.7765, validation loss: 0.8519
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch67_loss0.8518895506858826.pypots
2024-05-22 21:59:55 [INFO]: Epoch 068 - training loss: 0.7803, validation loss: 0.8527
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch68_loss0.8527275919914246.pypots
2024-05-22 21:59:55 [INFO]: Epoch 069 - training loss: 0.7685, validation loss: 0.8516
2024-05-22 21:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch69_loss0.8515846729278564.pypots
2024-05-22 21:59:56 [INFO]: Epoch 070 - training loss: 0.8189, validation loss: 0.8511
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch70_loss0.8510998487472534.pypots
2024-05-22 21:59:56 [INFO]: Epoch 071 - training loss: 0.7876, validation loss: 0.8508
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch71_loss0.8508210182189941.pypots
2024-05-22 21:59:56 [INFO]: Epoch 072 - training loss: 0.7724, validation loss: 0.8487
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch72_loss0.8486876785755157.pypots
2024-05-22 21:59:56 [INFO]: Epoch 073 - training loss: 0.7580, validation loss: 0.8492
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch73_loss0.8492177277803421.pypots
2024-05-22 21:59:56 [INFO]: Epoch 074 - training loss: 0.7593, validation loss: 0.8514
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch74_loss0.8514479398727417.pypots
2024-05-22 21:59:56 [INFO]: Epoch 075 - training loss: 0.7645, validation loss: 0.8495
2024-05-22 21:59:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch75_loss0.8494717180728912.pypots
2024-05-22 21:59:57 [INFO]: Epoch 076 - training loss: 0.7456, validation loss: 0.8519
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch76_loss0.8518866449594498.pypots
2024-05-22 21:59:57 [INFO]: Epoch 077 - training loss: 0.7809, validation loss: 0.8499
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch77_loss0.8499467968940735.pypots
2024-05-22 21:59:57 [INFO]: Epoch 078 - training loss: 0.8194, validation loss: 0.8486
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch78_loss0.8486240655183792.pypots
2024-05-22 21:59:57 [INFO]: Epoch 079 - training loss: 0.7498, validation loss: 0.8462
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch79_loss0.8461548537015915.pypots
2024-05-22 21:59:57 [INFO]: Epoch 080 - training loss: 0.7764, validation loss: 0.8521
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch80_loss0.8520986884832382.pypots
2024-05-22 21:59:57 [INFO]: Epoch 081 - training loss: 0.7708, validation loss: 0.8462
2024-05-22 21:59:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch81_loss0.8462283909320831.pypots
2024-05-22 21:59:58 [INFO]: Epoch 082 - training loss: 0.7854, validation loss: 0.8461
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch82_loss0.8461486846208572.pypots
2024-05-22 21:59:58 [INFO]: Epoch 083 - training loss: 0.7936, validation loss: 0.8457
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch83_loss0.8456661403179169.pypots
2024-05-22 21:59:58 [INFO]: Epoch 084 - training loss: 0.7600, validation loss: 0.8476
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch84_loss0.8476162254810333.pypots
2024-05-22 21:59:58 [INFO]: Epoch 085 - training loss: 0.7544, validation loss: 0.8491
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch85_loss0.8490905463695526.pypots
2024-05-22 21:59:58 [INFO]: Epoch 086 - training loss: 0.7798, validation loss: 0.8438
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch86_loss0.8438326418399811.pypots
2024-05-22 21:59:58 [INFO]: Epoch 087 - training loss: 0.7576, validation loss: 0.8441
2024-05-22 21:59:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch87_loss0.8440504223108292.pypots
2024-05-22 21:59:59 [INFO]: Epoch 088 - training loss: 0.7478, validation loss: 0.8419
2024-05-22 21:59:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch88_loss0.841892883181572.pypots
2024-05-22 21:59:59 [INFO]: Epoch 089 - training loss: 0.7651, validation loss: 0.8427
2024-05-22 21:59:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch89_loss0.842683956027031.pypots
2024-05-22 21:59:59 [INFO]: Epoch 090 - training loss: 0.7963, validation loss: 0.8442
2024-05-22 21:59:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch90_loss0.8441778272390366.pypots
2024-05-22 21:59:59 [INFO]: Epoch 091 - training loss: 0.7490, validation loss: 0.8407
2024-05-22 21:59:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch91_loss0.8406516015529633.pypots
2024-05-22 21:59:59 [INFO]: Epoch 092 - training loss: 0.7857, validation loss: 0.8405
2024-05-22 21:59:59 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch92_loss0.840503141283989.pypots
2024-05-22 22:00:00 [INFO]: Epoch 093 - training loss: 0.7383, validation loss: 0.8395
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch93_loss0.8395036160945892.pypots
2024-05-22 22:00:00 [INFO]: Epoch 094 - training loss: 0.7645, validation loss: 0.8398
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch94_loss0.8397585302591324.pypots
2024-05-22 22:00:00 [INFO]: Epoch 095 - training loss: 0.7924, validation loss: 0.8407
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch95_loss0.8407138884067535.pypots
2024-05-22 22:00:00 [INFO]: Epoch 096 - training loss: 0.7526, validation loss: 0.8429
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch96_loss0.8428721278905869.pypots
2024-05-22 22:00:00 [INFO]: Epoch 097 - training loss: 0.7629, validation loss: 0.8375
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch97_loss0.8375192880630493.pypots
2024-05-22 22:00:00 [INFO]: Epoch 098 - training loss: 0.7726, validation loss: 0.8376
2024-05-22 22:00:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch98_loss0.837635263800621.pypots
2024-05-22 22:00:01 [INFO]: Epoch 099 - training loss: 0.7777, validation loss: 0.8357
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch99_loss0.8357145339250565.pypots
2024-05-22 22:00:01 [INFO]: Epoch 100 - training loss: 0.7531, validation loss: 0.8393
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch100_loss0.8392567932605743.pypots
2024-05-22 22:00:01 [INFO]: Epoch 101 - training loss: 0.7520, validation loss: 0.8374
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch101_loss0.8373981565237045.pypots
2024-05-22 22:00:01 [INFO]: Epoch 102 - training loss: 0.7730, validation loss: 0.8387
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch102_loss0.8387339264154434.pypots
2024-05-22 22:00:01 [INFO]: Epoch 103 - training loss: 0.7672, validation loss: 0.8416
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch103_loss0.8416120558977127.pypots
2024-05-22 22:00:01 [INFO]: Epoch 104 - training loss: 0.7646, validation loss: 0.8340
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch104_loss0.8340074270963669.pypots
2024-05-22 22:00:01 [INFO]: Epoch 105 - training loss: 0.7610, validation loss: 0.8332
2024-05-22 22:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch105_loss0.8331664353609085.pypots
2024-05-22 22:00:02 [INFO]: Epoch 106 - training loss: 0.7451, validation loss: 0.8351
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch106_loss0.8351303786039352.pypots
2024-05-22 22:00:02 [INFO]: Epoch 107 - training loss: 0.7736, validation loss: 0.8311
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch107_loss0.8311063647270203.pypots
2024-05-22 22:00:02 [INFO]: Epoch 108 - training loss: 0.7752, validation loss: 0.8346
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch108_loss0.8346433788537979.pypots
2024-05-22 22:00:02 [INFO]: Epoch 109 - training loss: 0.7650, validation loss: 0.8367
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch109_loss0.8366974741220474.pypots
2024-05-22 22:00:02 [INFO]: Epoch 110 - training loss: 0.7676, validation loss: 0.8309
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch110_loss0.8308541774749756.pypots
2024-05-22 22:00:02 [INFO]: Epoch 111 - training loss: 0.7774, validation loss: 0.8314
2024-05-22 22:00:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch111_loss0.8313773572444916.pypots
2024-05-22 22:00:03 [INFO]: Epoch 112 - training loss: 0.7706, validation loss: 0.8330
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch112_loss0.8330157548189163.pypots
2024-05-22 22:00:03 [INFO]: Epoch 113 - training loss: 0.7609, validation loss: 0.8301
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch113_loss0.8301214724779129.pypots
2024-05-22 22:00:03 [INFO]: Epoch 114 - training loss: 0.7618, validation loss: 0.8286
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch114_loss0.8286391496658325.pypots
2024-05-22 22:00:03 [INFO]: Epoch 115 - training loss: 0.7663, validation loss: 0.8299
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch115_loss0.8299148082733154.pypots
2024-05-22 22:00:03 [INFO]: Epoch 116 - training loss: 0.7625, validation loss: 0.8340
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch116_loss0.8339914530515671.pypots
2024-05-22 22:00:03 [INFO]: Epoch 117 - training loss: 0.7527, validation loss: 0.8309
2024-05-22 22:00:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch117_loss0.830883577466011.pypots
2024-05-22 22:00:04 [INFO]: Epoch 118 - training loss: 0.7835, validation loss: 0.8295
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch118_loss0.8294991105794907.pypots
2024-05-22 22:00:04 [INFO]: Epoch 119 - training loss: 0.7800, validation loss: 0.8295
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch119_loss0.8294670581817627.pypots
2024-05-22 22:00:04 [INFO]: Epoch 120 - training loss: 0.7700, validation loss: 0.8293
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch120_loss0.8293091803789139.pypots
2024-05-22 22:00:04 [INFO]: Epoch 121 - training loss: 0.8110, validation loss: 0.8285
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch121_loss0.8285311460494995.pypots
2024-05-22 22:00:04 [INFO]: Epoch 122 - training loss: 0.7719, validation loss: 0.8282
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch122_loss0.8281911313533783.pypots
2024-05-22 22:00:04 [INFO]: Epoch 123 - training loss: 0.7636, validation loss: 0.8306
2024-05-22 22:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch123_loss0.8305823057889938.pypots
2024-05-22 22:00:05 [INFO]: Epoch 124 - training loss: 0.7627, validation loss: 0.8261
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch124_loss0.8260770589113235.pypots
2024-05-22 22:00:05 [INFO]: Epoch 125 - training loss: 0.7452, validation loss: 0.8299
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch125_loss0.829878032207489.pypots
2024-05-22 22:00:05 [INFO]: Epoch 126 - training loss: 0.7667, validation loss: 0.8296
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch126_loss0.8295935094356537.pypots
2024-05-22 22:00:05 [INFO]: Epoch 127 - training loss: 0.7687, validation loss: 0.8230
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch127_loss0.8229852467775345.pypots
2024-05-22 22:00:05 [INFO]: Epoch 128 - training loss: 0.7650, validation loss: 0.8226
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch128_loss0.8225766122341156.pypots
2024-05-22 22:00:05 [INFO]: Epoch 129 - training loss: 0.7843, validation loss: 0.8258
2024-05-22 22:00:05 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch129_loss0.8257942795753479.pypots
2024-05-22 22:00:06 [INFO]: Epoch 130 - training loss: 0.7887, validation loss: 0.8237
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch130_loss0.8236622512340546.pypots
2024-05-22 22:00:06 [INFO]: Epoch 131 - training loss: 0.7508, validation loss: 0.8278
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch131_loss0.8277510702610016.pypots
2024-05-22 22:00:06 [INFO]: Epoch 132 - training loss: 0.7649, validation loss: 0.8243
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch132_loss0.8242588043212891.pypots
2024-05-22 22:00:06 [INFO]: Epoch 133 - training loss: 0.7569, validation loss: 0.8231
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch133_loss0.8231495320796967.pypots
2024-05-22 22:00:06 [INFO]: Epoch 134 - training loss: 0.7545, validation loss: 0.8219
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch134_loss0.8219022452831268.pypots
2024-05-22 22:00:06 [INFO]: Epoch 135 - training loss: 0.7846, validation loss: 0.8232
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch135_loss0.8232457339763641.pypots
2024-05-22 22:00:06 [INFO]: Epoch 136 - training loss: 0.7556, validation loss: 0.8229
2024-05-22 22:00:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch136_loss0.8228927552700043.pypots
2024-05-22 22:00:07 [INFO]: Epoch 137 - training loss: 0.7790, validation loss: 0.8209
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch137_loss0.8208618015050888.pypots
2024-05-22 22:00:07 [INFO]: Epoch 138 - training loss: 0.7654, validation loss: 0.8199
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch138_loss0.819877564907074.pypots
2024-05-22 22:00:07 [INFO]: Epoch 139 - training loss: 0.7621, validation loss: 0.8205
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch139_loss0.8204999566078186.pypots
2024-05-22 22:00:07 [INFO]: Epoch 140 - training loss: 0.7471, validation loss: 0.8211
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch140_loss0.8211361169815063.pypots
2024-05-22 22:00:07 [INFO]: Epoch 141 - training loss: 0.7893, validation loss: 0.8187
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch141_loss0.8186649680137634.pypots
2024-05-22 22:00:07 [INFO]: Epoch 142 - training loss: 0.7577, validation loss: 0.8170
2024-05-22 22:00:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch142_loss0.8170104771852493.pypots
2024-05-22 22:00:08 [INFO]: Epoch 143 - training loss: 0.7641, validation loss: 0.8215
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch143_loss0.8215271234512329.pypots
2024-05-22 22:00:08 [INFO]: Epoch 144 - training loss: 0.7730, validation loss: 0.8169
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch144_loss0.8169229179620743.pypots
2024-05-22 22:00:08 [INFO]: Epoch 145 - training loss: 0.7441, validation loss: 0.8158
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch145_loss0.8157901465892792.pypots
2024-05-22 22:00:08 [INFO]: Epoch 146 - training loss: 0.7460, validation loss: 0.8142
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch146_loss0.8141840249300003.pypots
2024-05-22 22:00:08 [INFO]: Epoch 147 - training loss: 0.7664, validation loss: 0.8166
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch147_loss0.816585972905159.pypots
2024-05-22 22:00:08 [INFO]: Epoch 148 - training loss: 0.7849, validation loss: 0.8161
2024-05-22 22:00:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch148_loss0.8160775899887085.pypots
2024-05-22 22:00:09 [INFO]: Epoch 149 - training loss: 0.7958, validation loss: 0.8138
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch149_loss0.8137606978416443.pypots
2024-05-22 22:00:09 [INFO]: Epoch 150 - training loss: 0.7750, validation loss: 0.8137
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch150_loss0.8137278854846954.pypots
2024-05-22 22:00:09 [INFO]: Epoch 151 - training loss: 0.7496, validation loss: 0.8150
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch151_loss0.814983531832695.pypots
2024-05-22 22:00:09 [INFO]: Epoch 152 - training loss: 0.7802, validation loss: 0.8108
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch152_loss0.8107861876487732.pypots
2024-05-22 22:00:09 [INFO]: Epoch 153 - training loss: 0.7604, validation loss: 0.8116
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch153_loss0.8115671575069427.pypots
2024-05-22 22:00:09 [INFO]: Epoch 154 - training loss: 0.7589, validation loss: 0.8114
2024-05-22 22:00:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch154_loss0.8113945573568344.pypots
2024-05-22 22:00:10 [INFO]: Epoch 155 - training loss: 0.7485, validation loss: 0.8100
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch155_loss0.8099811226129532.pypots
2024-05-22 22:00:10 [INFO]: Epoch 156 - training loss: 0.7605, validation loss: 0.8137
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch156_loss0.8137166202068329.pypots
2024-05-22 22:00:10 [INFO]: Epoch 157 - training loss: 0.7668, validation loss: 0.8107
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch157_loss0.810674637556076.pypots
2024-05-22 22:00:10 [INFO]: Epoch 158 - training loss: 0.7599, validation loss: 0.8096
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch158_loss0.8096210658550262.pypots
2024-05-22 22:00:10 [INFO]: Epoch 159 - training loss: 0.7405, validation loss: 0.8118
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch159_loss0.8118070811033249.pypots
2024-05-22 22:00:10 [INFO]: Epoch 160 - training loss: 0.7416, validation loss: 0.8087
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch160_loss0.8086915463209152.pypots
2024-05-22 22:00:10 [INFO]: Epoch 161 - training loss: 0.7412, validation loss: 0.8100
2024-05-22 22:00:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch161_loss0.8100376278162003.pypots
2024-05-22 22:00:11 [INFO]: Epoch 162 - training loss: 0.7675, validation loss: 0.8105
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch162_loss0.8104869425296783.pypots
2024-05-22 22:00:11 [INFO]: Epoch 163 - training loss: 0.7625, validation loss: 0.8088
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch163_loss0.8087502419948578.pypots
2024-05-22 22:00:11 [INFO]: Epoch 164 - training loss: 0.7759, validation loss: 0.8091
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch164_loss0.8090878278017044.pypots
2024-05-22 22:00:11 [INFO]: Epoch 165 - training loss: 0.7588, validation loss: 0.8060
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch165_loss0.8059650808572769.pypots
2024-05-22 22:00:11 [INFO]: Epoch 166 - training loss: 0.7765, validation loss: 0.8103
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch166_loss0.8102690428495407.pypots
2024-05-22 22:00:11 [INFO]: Epoch 167 - training loss: 0.7763, validation loss: 0.8050
2024-05-22 22:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch167_loss0.805013582110405.pypots
2024-05-22 22:00:12 [INFO]: Epoch 168 - training loss: 0.7579, validation loss: 0.8069
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch168_loss0.8069266527891159.pypots
2024-05-22 22:00:12 [INFO]: Epoch 169 - training loss: 0.7711, validation loss: 0.8055
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch169_loss0.8054977804422379.pypots
2024-05-22 22:00:12 [INFO]: Epoch 170 - training loss: 0.7656, validation loss: 0.8048
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch170_loss0.8048467040061951.pypots
2024-05-22 22:00:12 [INFO]: Epoch 171 - training loss: 0.7567, validation loss: 0.8038
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch171_loss0.8038246333599091.pypots
2024-05-22 22:00:12 [INFO]: Epoch 172 - training loss: 0.7705, validation loss: 0.8036
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch172_loss0.8035580962896347.pypots
2024-05-22 22:00:12 [INFO]: Epoch 173 - training loss: 0.7634, validation loss: 0.8090
2024-05-22 22:00:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch173_loss0.8089586943387985.pypots
2024-05-22 22:00:13 [INFO]: Epoch 174 - training loss: 0.7718, validation loss: 0.8105
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch174_loss0.8105494976043701.pypots
2024-05-22 22:00:13 [INFO]: Epoch 175 - training loss: 0.7634, validation loss: 0.8087
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch175_loss0.8087451159954071.pypots
2024-05-22 22:00:13 [INFO]: Epoch 176 - training loss: 0.7380, validation loss: 0.8043
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch176_loss0.8042796403169632.pypots
2024-05-22 22:00:13 [INFO]: Epoch 177 - training loss: 0.7368, validation loss: 0.8027
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch177_loss0.8026705384254456.pypots
2024-05-22 22:00:13 [INFO]: Epoch 178 - training loss: 0.7533, validation loss: 0.8037
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch178_loss0.8037301003932953.pypots
2024-05-22 22:00:13 [INFO]: Epoch 179 - training loss: 0.7645, validation loss: 0.8024
2024-05-22 22:00:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch179_loss0.8023726642131805.pypots
2024-05-22 22:00:14 [INFO]: Epoch 180 - training loss: 0.7417, validation loss: 0.8027
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch180_loss0.8027386218309402.pypots
2024-05-22 22:00:14 [INFO]: Epoch 181 - training loss: 0.7372, validation loss: 0.8026
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch181_loss0.8026254028081894.pypots
2024-05-22 22:00:14 [INFO]: Epoch 182 - training loss: 0.7532, validation loss: 0.7995
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch182_loss0.799499973654747.pypots
2024-05-22 22:00:14 [INFO]: Epoch 183 - training loss: 0.7584, validation loss: 0.7976
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch183_loss0.7975581884384155.pypots
2024-05-22 22:00:14 [INFO]: Epoch 184 - training loss: 0.7702, validation loss: 0.8010
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch184_loss0.8010281771421432.pypots
2024-05-22 22:00:14 [INFO]: Epoch 185 - training loss: 0.7568, validation loss: 0.8028
2024-05-22 22:00:14 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch185_loss0.8027894049882889.pypots
2024-05-22 22:00:15 [INFO]: Epoch 186 - training loss: 0.7761, validation loss: 0.8027
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch186_loss0.8026626408100128.pypots
2024-05-22 22:00:15 [INFO]: Epoch 187 - training loss: 0.7643, validation loss: 0.8001
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch187_loss0.8000975400209427.pypots
2024-05-22 22:00:15 [INFO]: Epoch 188 - training loss: 0.7637, validation loss: 0.8014
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch188_loss0.8013712763786316.pypots
2024-05-22 22:00:15 [INFO]: Epoch 189 - training loss: 0.7828, validation loss: 0.7980
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch189_loss0.7980367988348007.pypots
2024-05-22 22:00:15 [INFO]: Epoch 190 - training loss: 0.7797, validation loss: 0.7979
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch190_loss0.7979199439287186.pypots
2024-05-22 22:00:15 [INFO]: Epoch 191 - training loss: 0.7562, validation loss: 0.7984
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch191_loss0.7983777225017548.pypots
2024-05-22 22:00:15 [INFO]: Epoch 192 - training loss: 0.7987, validation loss: 0.8005
2024-05-22 22:00:15 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch192_loss0.8004501014947891.pypots
2024-05-22 22:00:16 [INFO]: Epoch 193 - training loss: 0.7619, validation loss: 0.7970
2024-05-22 22:00:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch193_loss0.7969819903373718.pypots
2024-05-22 22:00:16 [INFO]: Epoch 194 - training loss: 0.7419, validation loss: 0.7980
2024-05-22 22:00:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch194_loss0.798026904463768.pypots
2024-05-22 22:00:16 [INFO]: Epoch 195 - training loss: 0.7605, validation loss: 0.7999
2024-05-22 22:00:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch195_loss0.7999303787946701.pypots
2024-05-22 22:00:16 [INFO]: Epoch 196 - training loss: 0.7497, validation loss: 0.7980
2024-05-22 22:00:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch196_loss0.7980118542909622.pypots
2024-05-22 22:00:16 [INFO]: Epoch 197 - training loss: 0.7594, validation loss: 0.7970
2024-05-22 22:00:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch197_loss0.7969648540019989.pypots
2024-05-22 22:00:17 [INFO]: Epoch 198 - training loss: 0.7590, validation loss: 0.8003
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch198_loss0.8003233224153519.pypots
2024-05-22 22:00:17 [INFO]: Epoch 199 - training loss: 0.7589, validation loss: 0.7965
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch199_loss0.796467661857605.pypots
2024-05-22 22:00:17 [INFO]: Epoch 200 - training loss: 0.7775, validation loss: 0.7969
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch200_loss0.7968544363975525.pypots
2024-05-22 22:00:17 [INFO]: Epoch 201 - training loss: 0.7635, validation loss: 0.7982
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch201_loss0.7981568723917007.pypots
2024-05-22 22:00:17 [INFO]: Epoch 202 - training loss: 0.7601, validation loss: 0.7969
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch202_loss0.7969182878732681.pypots
2024-05-22 22:00:17 [INFO]: Epoch 203 - training loss: 0.7508, validation loss: 0.7954
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch203_loss0.7954345643520355.pypots
2024-05-22 22:00:17 [INFO]: Epoch 204 - training loss: 0.7652, validation loss: 0.7942
2024-05-22 22:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch204_loss0.7941934317350388.pypots
2024-05-22 22:00:18 [INFO]: Epoch 205 - training loss: 0.7372, validation loss: 0.7932
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch205_loss0.7932059168815613.pypots
2024-05-22 22:00:18 [INFO]: Epoch 206 - training loss: 0.7561, validation loss: 0.7988
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch206_loss0.7988060414791107.pypots
2024-05-22 22:00:18 [INFO]: Epoch 207 - training loss: 0.7563, validation loss: 0.7945
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch207_loss0.7944642305374146.pypots
2024-05-22 22:00:18 [INFO]: Epoch 208 - training loss: 0.7675, validation loss: 0.7954
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch208_loss0.7953523844480515.pypots
2024-05-22 22:00:18 [INFO]: Epoch 209 - training loss: 0.7610, validation loss: 0.7949
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch209_loss0.7948563992977142.pypots
2024-05-22 22:00:18 [INFO]: Epoch 210 - training loss: 0.7612, validation loss: 0.7949
2024-05-22 22:00:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch210_loss0.7949400693178177.pypots
2024-05-22 22:00:19 [INFO]: Epoch 211 - training loss: 0.7561, validation loss: 0.7917
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch211_loss0.7917009145021439.pypots
2024-05-22 22:00:19 [INFO]: Epoch 212 - training loss: 0.7408, validation loss: 0.7940
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch212_loss0.7940386086702347.pypots
2024-05-22 22:00:19 [INFO]: Epoch 213 - training loss: 0.7489, validation loss: 0.7950
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch213_loss0.7950023114681244.pypots
2024-05-22 22:00:19 [INFO]: Epoch 214 - training loss: 0.7690, validation loss: 0.7904
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch214_loss0.7903786599636078.pypots
2024-05-22 22:00:19 [INFO]: Epoch 215 - training loss: 0.7470, validation loss: 0.7947
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch215_loss0.7947413921356201.pypots
2024-05-22 22:00:19 [INFO]: Epoch 216 - training loss: 0.7588, validation loss: 0.7931
2024-05-22 22:00:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch216_loss0.793059304356575.pypots
2024-05-22 22:00:20 [INFO]: Epoch 217 - training loss: 0.7633, validation loss: 0.7928
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch217_loss0.7928013950586319.pypots
2024-05-22 22:00:20 [INFO]: Epoch 218 - training loss: 0.7499, validation loss: 0.7944
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch218_loss0.794431522488594.pypots
2024-05-22 22:00:20 [INFO]: Epoch 219 - training loss: 0.7487, validation loss: 0.7910
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch219_loss0.7909968495368958.pypots
2024-05-22 22:00:20 [INFO]: Epoch 220 - training loss: 0.7653, validation loss: 0.7932
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch220_loss0.7931747734546661.pypots
2024-05-22 22:00:20 [INFO]: Epoch 221 - training loss: 0.7607, validation loss: 0.7909
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch221_loss0.7908553928136826.pypots
2024-05-22 22:00:20 [INFO]: Epoch 222 - training loss: 0.7584, validation loss: 0.7931
2024-05-22 22:00:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch222_loss0.793130099773407.pypots
2024-05-22 22:00:21 [INFO]: Epoch 223 - training loss: 0.7631, validation loss: 0.7921
2024-05-22 22:00:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch223_loss0.7921466380357742.pypots
2024-05-22 22:00:21 [INFO]: Epoch 224 - training loss: 0.7424, validation loss: 0.7926
2024-05-22 22:00:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN_epoch224_loss0.7926177829504013.pypots
2024-05-22 22:00:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:00:21 [INFO]: Finished training. The best model is from epoch#214.
2024-05-22 22:00:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_ettm1/20240522_T215943/MRNN.pypots
2024-05-22 22:00:21 [INFO]: MRNN on ETTm1: MAE=0.5865, MSE=1.0032
2024-05-22 22:00:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-22 22:00:21 [INFO]: Using the given device: cpu
2024-05-22 22:00:21 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 22:00:21 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-22 22:00:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-22 22:00:21 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 22:00:21 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-22 22:00:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-22 22:00:21 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 22:00:21 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-22 22:00:21 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-22 22:00:21 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-22 22:00:21 [INFO]: Using the given device: cuda:0
2024-05-22 22:00:21 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240522_T220021
2024-05-22 22:00:21 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_ettm1/20240522_T220021/tensorboard
2024-05-22 22:00:21 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 22:00:22 [INFO]: Epoch 001 - training loss: 1.1427, validation loss: 0.2414
2024-05-22 22:00:22 [INFO]: Epoch 002 - training loss: 0.8133, validation loss: 0.1295
2024-05-22 22:00:23 [INFO]: Epoch 003 - training loss: 0.7043, validation loss: 0.1083
2024-05-22 22:00:23 [INFO]: Epoch 004 - training loss: 0.6392, validation loss: 0.0932
2024-05-22 22:00:23 [INFO]: Epoch 005 - training loss: 0.6081, validation loss: 0.0881
2024-05-22 22:00:24 [INFO]: Epoch 006 - training loss: 0.5733, validation loss: 0.0724
2024-05-22 22:00:24 [INFO]: Epoch 007 - training loss: 0.5567, validation loss: 0.0677
2024-05-22 22:00:25 [INFO]: Epoch 008 - training loss: 0.5311, validation loss: 0.0723
2024-05-22 22:00:25 [INFO]: Epoch 009 - training loss: 0.5314, validation loss: 0.0653
2024-05-22 22:00:26 [INFO]: Epoch 010 - training loss: 0.5219, validation loss: 0.0538
2024-05-22 22:00:26 [INFO]: Epoch 011 - training loss: 0.4906, validation loss: 0.0629
2024-05-22 22:00:27 [INFO]: Epoch 012 - training loss: 0.4908, validation loss: 0.0619
2024-05-22 22:00:27 [INFO]: Epoch 013 - training loss: 0.4821, validation loss: 0.0505
2024-05-22 22:00:28 [INFO]: Epoch 014 - training loss: 0.4638, validation loss: 0.0477
2024-05-22 22:00:28 [INFO]: Epoch 015 - training loss: 0.4672, validation loss: 0.0460
2024-05-22 22:00:29 [INFO]: Epoch 016 - training loss: 0.4449, validation loss: 0.0501
2024-05-22 22:00:29 [INFO]: Epoch 017 - training loss: 0.4784, validation loss: 0.0405
2024-05-22 22:00:30 [INFO]: Epoch 018 - training loss: 0.4374, validation loss: 0.0545
2024-05-22 22:00:30 [INFO]: Epoch 019 - training loss: 0.4279, validation loss: 0.0374
2024-05-22 22:00:31 [INFO]: Epoch 020 - training loss: 0.4109, validation loss: 0.0404
2024-05-22 22:00:31 [INFO]: Epoch 021 - training loss: 0.4363, validation loss: 0.0411
2024-05-22 22:00:32 [INFO]: Epoch 022 - training loss: 0.4146, validation loss: 0.0547
2024-05-22 22:00:32 [INFO]: Epoch 023 - training loss: 0.4099, validation loss: 0.0367
2024-05-22 22:00:33 [INFO]: Epoch 024 - training loss: 0.3995, validation loss: 0.0368
2024-05-22 22:00:33 [INFO]: Epoch 025 - training loss: 0.3879, validation loss: 0.0356
2024-05-22 22:00:33 [INFO]: Epoch 026 - training loss: 0.3875, validation loss: 0.0345
2024-05-22 22:00:34 [INFO]: Epoch 027 - training loss: 0.3824, validation loss: 0.0443
2024-05-22 22:00:34 [INFO]: Epoch 028 - training loss: 0.3887, validation loss: 0.0421
2024-05-22 22:00:35 [INFO]: Epoch 029 - training loss: 0.4037, validation loss: 0.0461
2024-05-22 22:00:35 [INFO]: Epoch 030 - training loss: 0.3811, validation loss: 0.0368
2024-05-22 22:00:36 [INFO]: Epoch 031 - training loss: 0.3816, validation loss: 0.0433
2024-05-22 22:00:36 [INFO]: Epoch 032 - training loss: 0.3768, validation loss: 0.0500
2024-05-22 22:00:37 [INFO]: Epoch 033 - training loss: 0.3726, validation loss: 0.0358
2024-05-22 22:00:37 [INFO]: Epoch 034 - training loss: 0.3658, validation loss: 0.0331
2024-05-22 22:00:38 [INFO]: Epoch 035 - training loss: 0.3522, validation loss: 0.0327
2024-05-22 22:00:38 [INFO]: Epoch 036 - training loss: 0.3602, validation loss: 0.0400
2024-05-22 22:00:39 [INFO]: Epoch 037 - training loss: 0.3601, validation loss: 0.0521
2024-05-22 22:00:39 [INFO]: Epoch 038 - training loss: 0.3600, validation loss: 0.0289
2024-05-22 22:00:40 [INFO]: Epoch 039 - training loss: 0.3732, validation loss: 0.0401
2024-05-22 22:00:40 [INFO]: Epoch 040 - training loss: 0.3761, validation loss: 0.0401
2024-05-22 22:00:41 [INFO]: Epoch 041 - training loss: 0.3437, validation loss: 0.0304
2024-05-22 22:00:41 [INFO]: Epoch 042 - training loss: 0.3298, validation loss: 0.0332
2024-05-22 22:00:42 [INFO]: Epoch 043 - training loss: 0.3330, validation loss: 0.0281
2024-05-22 22:00:42 [INFO]: Epoch 044 - training loss: 0.3287, validation loss: 0.0356
2024-05-22 22:00:43 [INFO]: Epoch 045 - training loss: 0.3298, validation loss: 0.0707
2024-05-22 22:00:43 [INFO]: Epoch 046 - training loss: 0.3578, validation loss: 0.0326
2024-05-22 22:00:44 [INFO]: Epoch 047 - training loss: 0.3282, validation loss: 0.0425
2024-05-22 22:00:44 [INFO]: Epoch 048 - training loss: 0.3201, validation loss: 0.0340
2024-05-22 22:00:44 [INFO]: Epoch 049 - training loss: 0.3246, validation loss: 0.0348
2024-05-22 22:00:45 [INFO]: Epoch 050 - training loss: 0.3147, validation loss: 0.0275
2024-05-22 22:00:45 [INFO]: Epoch 051 - training loss: 0.3099, validation loss: 0.0340
2024-05-22 22:00:46 [INFO]: Epoch 052 - training loss: 0.3105, validation loss: 0.0327
2024-05-22 22:00:46 [INFO]: Epoch 053 - training loss: 0.3036, validation loss: 0.0381
2024-05-22 22:00:47 [INFO]: Epoch 054 - training loss: 0.3182, validation loss: 0.0387
2024-05-22 22:00:47 [INFO]: Epoch 055 - training loss: 0.3355, validation loss: 0.0306
2024-05-22 22:00:48 [INFO]: Epoch 056 - training loss: 0.3275, validation loss: 0.0332
2024-05-22 22:00:48 [INFO]: Epoch 057 - training loss: 0.3085, validation loss: 0.0257
2024-05-22 22:00:49 [INFO]: Epoch 058 - training loss: 0.2941, validation loss: 0.0371
2024-05-22 22:00:49 [INFO]: Epoch 059 - training loss: 0.3000, validation loss: 0.0282
2024-05-22 22:00:50 [INFO]: Epoch 060 - training loss: 0.2955, validation loss: 0.0286
2024-05-22 22:00:50 [INFO]: Epoch 061 - training loss: 0.2918, validation loss: 0.0357
2024-05-22 22:00:51 [INFO]: Epoch 062 - training loss: 0.2878, validation loss: 0.0285
2024-05-22 22:00:51 [INFO]: Epoch 063 - training loss: 0.2932, validation loss: 0.0392
2024-05-22 22:00:52 [INFO]: Epoch 064 - training loss: 0.3074, validation loss: 0.0281
2024-05-22 22:00:52 [INFO]: Epoch 065 - training loss: 0.2939, validation loss: 0.0323
2024-05-22 22:00:53 [INFO]: Epoch 066 - training loss: 0.2860, validation loss: 0.0274
2024-05-22 22:00:53 [INFO]: Epoch 067 - training loss: 0.2825, validation loss: 0.0246
2024-05-22 22:00:54 [INFO]: Epoch 068 - training loss: 0.2814, validation loss: 0.0305
2024-05-22 22:00:54 [INFO]: Epoch 069 - training loss: 0.2805, validation loss: 0.0308
2024-05-22 22:00:55 [INFO]: Epoch 070 - training loss: 0.2843, validation loss: 0.0297
2024-05-22 22:00:55 [INFO]: Epoch 071 - training loss: 0.2794, validation loss: 0.0312
2024-05-22 22:00:55 [INFO]: Epoch 072 - training loss: 0.2759, validation loss: 0.0346
2024-05-22 22:00:56 [INFO]: Epoch 073 - training loss: 0.2833, validation loss: 0.0290
2024-05-22 22:00:56 [INFO]: Epoch 074 - training loss: 0.2718, validation loss: 0.0312
2024-05-22 22:00:57 [INFO]: Epoch 075 - training loss: 0.2655, validation loss: 0.0414
2024-05-22 22:00:57 [INFO]: Epoch 076 - training loss: 0.2827, validation loss: 0.0374
2024-05-22 22:00:58 [INFO]: Epoch 077 - training loss: 0.2822, validation loss: 0.0326
2024-05-22 22:00:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:00:58 [INFO]: Finished training. The best model is from epoch#67.
2024-05-22 22:00:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_ettm1/20240522_T220021/SAITS.pypots
2024-05-22 22:00:58 [INFO]: SAITS on ETTm1: MAE=0.1895, MSE=0.0763
2024-05-22 22:00:58 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-22 22:00:58 [INFO]: Using the given device: cuda:0
2024-05-22 22:00:58 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240522_T220058
2024-05-22 22:00:58 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_ettm1/20240522_T220058/tensorboard
2024-05-22 22:00:58 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 22:00:58 [INFO]: Epoch 001 - training loss: 1.2172, validation loss: 0.3127
2024-05-22 22:00:58 [INFO]: Epoch 002 - training loss: 0.7104, validation loss: 0.1653
2024-05-22 22:00:59 [INFO]: Epoch 003 - training loss: 0.5643, validation loss: 0.1125
2024-05-22 22:00:59 [INFO]: Epoch 004 - training loss: 0.4923, validation loss: 0.0965
2024-05-22 22:00:59 [INFO]: Epoch 005 - training loss: 0.4591, validation loss: 0.0810
2024-05-22 22:00:59 [INFO]: Epoch 006 - training loss: 0.4323, validation loss: 0.0786
2024-05-22 22:00:59 [INFO]: Epoch 007 - training loss: 0.4149, validation loss: 0.0640
2024-05-22 22:01:00 [INFO]: Epoch 008 - training loss: 0.3973, validation loss: 0.0641
2024-05-22 22:01:00 [INFO]: Epoch 009 - training loss: 0.3919, validation loss: 0.0601
2024-05-22 22:01:00 [INFO]: Epoch 010 - training loss: 0.3830, validation loss: 0.0608
2024-05-22 22:01:00 [INFO]: Epoch 011 - training loss: 0.3687, validation loss: 0.0532
2024-05-22 22:01:00 [INFO]: Epoch 012 - training loss: 0.3588, validation loss: 0.0508
2024-05-22 22:01:00 [INFO]: Epoch 013 - training loss: 0.3488, validation loss: 0.0494
2024-05-22 22:01:01 [INFO]: Epoch 014 - training loss: 0.3462, validation loss: 0.0464
2024-05-22 22:01:01 [INFO]: Epoch 015 - training loss: 0.3341, validation loss: 0.0477
2024-05-22 22:01:01 [INFO]: Epoch 016 - training loss: 0.3314, validation loss: 0.0447
2024-05-22 22:01:01 [INFO]: Epoch 017 - training loss: 0.3284, validation loss: 0.0441
2024-05-22 22:01:01 [INFO]: Epoch 018 - training loss: 0.3187, validation loss: 0.0405
2024-05-22 22:01:02 [INFO]: Epoch 019 - training loss: 0.3153, validation loss: 0.0402
2024-05-22 22:01:02 [INFO]: Epoch 020 - training loss: 0.3091, validation loss: 0.0393
2024-05-22 22:01:02 [INFO]: Epoch 021 - training loss: 0.3042, validation loss: 0.0393
2024-05-22 22:01:02 [INFO]: Epoch 022 - training loss: 0.3034, validation loss: 0.0363
2024-05-22 22:01:02 [INFO]: Epoch 023 - training loss: 0.2940, validation loss: 0.0417
2024-05-22 22:01:03 [INFO]: Epoch 024 - training loss: 0.2959, validation loss: 0.0375
2024-05-22 22:01:03 [INFO]: Epoch 025 - training loss: 0.2956, validation loss: 0.0342
2024-05-22 22:01:03 [INFO]: Epoch 026 - training loss: 0.2879, validation loss: 0.0368
2024-05-22 22:01:03 [INFO]: Epoch 027 - training loss: 0.2842, validation loss: 0.0375
2024-05-22 22:01:03 [INFO]: Epoch 028 - training loss: 0.2863, validation loss: 0.0340
2024-05-22 22:01:04 [INFO]: Epoch 029 - training loss: 0.2797, validation loss: 0.0333
2024-05-22 22:01:04 [INFO]: Epoch 030 - training loss: 0.2751, validation loss: 0.0340
2024-05-22 22:01:04 [INFO]: Epoch 031 - training loss: 0.2698, validation loss: 0.0319
2024-05-22 22:01:04 [INFO]: Epoch 032 - training loss: 0.2643, validation loss: 0.0349
2024-05-22 22:01:04 [INFO]: Epoch 033 - training loss: 0.2768, validation loss: 0.0314
2024-05-22 22:01:04 [INFO]: Epoch 034 - training loss: 0.2580, validation loss: 0.0319
2024-05-22 22:01:05 [INFO]: Epoch 035 - training loss: 0.2557, validation loss: 0.0322
2024-05-22 22:01:05 [INFO]: Epoch 036 - training loss: 0.2589, validation loss: 0.0310
2024-05-22 22:01:05 [INFO]: Epoch 037 - training loss: 0.2494, validation loss: 0.0314
2024-05-22 22:01:05 [INFO]: Epoch 038 - training loss: 0.2482, validation loss: 0.0289
2024-05-22 22:01:05 [INFO]: Epoch 039 - training loss: 0.2460, validation loss: 0.0273
2024-05-22 22:01:06 [INFO]: Epoch 040 - training loss: 0.2437, validation loss: 0.0290
2024-05-22 22:01:06 [INFO]: Epoch 041 - training loss: 0.2470, validation loss: 0.0281
2024-05-22 22:01:06 [INFO]: Epoch 042 - training loss: 0.2418, validation loss: 0.0280
2024-05-22 22:01:06 [INFO]: Epoch 043 - training loss: 0.2417, validation loss: 0.0264
2024-05-22 22:01:06 [INFO]: Epoch 044 - training loss: 0.2388, validation loss: 0.0340
2024-05-22 22:01:07 [INFO]: Epoch 045 - training loss: 0.2454, validation loss: 0.0266
2024-05-22 22:01:07 [INFO]: Epoch 046 - training loss: 0.2356, validation loss: 0.0280
2024-05-22 22:01:07 [INFO]: Epoch 047 - training loss: 0.2385, validation loss: 0.0269
2024-05-22 22:01:07 [INFO]: Epoch 048 - training loss: 0.2310, validation loss: 0.0287
2024-05-22 22:01:07 [INFO]: Epoch 049 - training loss: 0.2296, validation loss: 0.0280
2024-05-22 22:01:07 [INFO]: Epoch 050 - training loss: 0.2288, validation loss: 0.0256
2024-05-22 22:01:08 [INFO]: Epoch 051 - training loss: 0.2249, validation loss: 0.0247
2024-05-22 22:01:08 [INFO]: Epoch 052 - training loss: 0.2208, validation loss: 0.0286
2024-05-22 22:01:08 [INFO]: Epoch 053 - training loss: 0.2237, validation loss: 0.0284
2024-05-22 22:01:08 [INFO]: Epoch 054 - training loss: 0.2226, validation loss: 0.0256
2024-05-22 22:01:08 [INFO]: Epoch 055 - training loss: 0.2221, validation loss: 0.0249
2024-05-22 22:01:09 [INFO]: Epoch 056 - training loss: 0.2196, validation loss: 0.0279
2024-05-22 22:01:09 [INFO]: Epoch 057 - training loss: 0.2235, validation loss: 0.0275
2024-05-22 22:01:09 [INFO]: Epoch 058 - training loss: 0.2212, validation loss: 0.0301
2024-05-22 22:01:09 [INFO]: Epoch 059 - training loss: 0.2214, validation loss: 0.0246
2024-05-22 22:01:09 [INFO]: Epoch 060 - training loss: 0.2151, validation loss: 0.0292
2024-05-22 22:01:10 [INFO]: Epoch 061 - training loss: 0.2178, validation loss: 0.0287
2024-05-22 22:01:10 [INFO]: Epoch 062 - training loss: 0.2130, validation loss: 0.0266
2024-05-22 22:01:10 [INFO]: Epoch 063 - training loss: 0.2091, validation loss: 0.0246
2024-05-22 22:01:10 [INFO]: Epoch 064 - training loss: 0.2119, validation loss: 0.0231
2024-05-22 22:01:10 [INFO]: Epoch 065 - training loss: 0.2117, validation loss: 0.0250
2024-05-22 22:01:10 [INFO]: Epoch 066 - training loss: 0.2066, validation loss: 0.0251
2024-05-22 22:01:11 [INFO]: Epoch 067 - training loss: 0.2056, validation loss: 0.0226
2024-05-22 22:01:11 [INFO]: Epoch 068 - training loss: 0.1979, validation loss: 0.0330
2024-05-22 22:01:11 [INFO]: Epoch 069 - training loss: 0.2205, validation loss: 0.0278
2024-05-22 22:01:11 [INFO]: Epoch 070 - training loss: 0.2086, validation loss: 0.0234
2024-05-22 22:01:11 [INFO]: Epoch 071 - training loss: 0.2006, validation loss: 0.0225
2024-05-22 22:01:12 [INFO]: Epoch 072 - training loss: 0.2027, validation loss: 0.0236
2024-05-22 22:01:12 [INFO]: Epoch 073 - training loss: 0.2010, validation loss: 0.0236
2024-05-22 22:01:12 [INFO]: Epoch 074 - training loss: 0.1968, validation loss: 0.0275
2024-05-22 22:01:12 [INFO]: Epoch 075 - training loss: 0.2036, validation loss: 0.0221
2024-05-22 22:01:12 [INFO]: Epoch 076 - training loss: 0.1961, validation loss: 0.0254
2024-05-22 22:01:13 [INFO]: Epoch 077 - training loss: 0.1962, validation loss: 0.0234
2024-05-22 22:01:13 [INFO]: Epoch 078 - training loss: 0.1992, validation loss: 0.0216
2024-05-22 22:01:13 [INFO]: Epoch 079 - training loss: 0.1924, validation loss: 0.0209
2024-05-22 22:01:13 [INFO]: Epoch 080 - training loss: 0.1904, validation loss: 0.0218
2024-05-22 22:01:13 [INFO]: Epoch 081 - training loss: 0.1959, validation loss: 0.0219
2024-05-22 22:01:13 [INFO]: Epoch 082 - training loss: 0.1952, validation loss: 0.0256
2024-05-22 22:01:14 [INFO]: Epoch 083 - training loss: 0.1947, validation loss: 0.0215
2024-05-22 22:01:14 [INFO]: Epoch 084 - training loss: 0.1984, validation loss: 0.0223
2024-05-22 22:01:14 [INFO]: Epoch 085 - training loss: 0.1898, validation loss: 0.0208
2024-05-22 22:01:14 [INFO]: Epoch 086 - training loss: 0.1886, validation loss: 0.0199
2024-05-22 22:01:14 [INFO]: Epoch 087 - training loss: 0.1853, validation loss: 0.0208
2024-05-22 22:01:15 [INFO]: Epoch 088 - training loss: 0.1873, validation loss: 0.0205
2024-05-22 22:01:15 [INFO]: Epoch 089 - training loss: 0.1877, validation loss: 0.0222
2024-05-22 22:01:15 [INFO]: Epoch 090 - training loss: 0.1901, validation loss: 0.0242
2024-05-22 22:01:15 [INFO]: Epoch 091 - training loss: 0.1915, validation loss: 0.0244
2024-05-22 22:01:15 [INFO]: Epoch 092 - training loss: 0.1908, validation loss: 0.0229
2024-05-22 22:01:16 [INFO]: Epoch 093 - training loss: 0.1944, validation loss: 0.0211
2024-05-22 22:01:16 [INFO]: Epoch 094 - training loss: 0.1888, validation loss: 0.0208
2024-05-22 22:01:16 [INFO]: Epoch 095 - training loss: 0.1866, validation loss: 0.0293
2024-05-22 22:01:16 [INFO]: Epoch 096 - training loss: 0.2042, validation loss: 0.0263
2024-05-22 22:01:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:01:16 [INFO]: Finished training. The best model is from epoch#86.
2024-05-22 22:01:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_ettm1/20240522_T220058/Transformer.pypots
2024-05-22 22:01:16 [INFO]: Transformer on ETTm1: MAE=0.1413, MSE=0.0395
2024-05-22 22:01:16 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-22 22:01:16 [INFO]: Using the given device: cuda:0
2024-05-22 22:01:16 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240522_T220116
2024-05-22 22:01:16 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240522_T220116/tensorboard
2024-05-22 22:01:16 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 22:01:17 [INFO]: Epoch 001 - training loss: 0.1360, validation loss: 0.0510
2024-05-22 22:01:17 [INFO]: Epoch 002 - training loss: 0.0629, validation loss: 0.0369
2024-05-22 22:01:17 [INFO]: Epoch 003 - training loss: 0.0456, validation loss: 0.0308
2024-05-22 22:01:17 [INFO]: Epoch 004 - training loss: 0.0403, validation loss: 0.0278
2024-05-22 22:01:17 [INFO]: Epoch 005 - training loss: 0.0367, validation loss: 0.0266
2024-05-22 22:01:17 [INFO]: Epoch 006 - training loss: 0.0340, validation loss: 0.0267
2024-05-22 22:01:18 [INFO]: Epoch 007 - training loss: 0.0344, validation loss: 0.0273
2024-05-22 22:01:18 [INFO]: Epoch 008 - training loss: 0.0338, validation loss: 0.0253
2024-05-22 22:01:18 [INFO]: Epoch 009 - training loss: 0.0328, validation loss: 0.0273
2024-05-22 22:01:18 [INFO]: Epoch 010 - training loss: 0.0339, validation loss: 0.0266
2024-05-22 22:01:18 [INFO]: Epoch 011 - training loss: 0.0335, validation loss: 0.0249
2024-05-22 22:01:18 [INFO]: Epoch 012 - training loss: 0.0324, validation loss: 0.0255
2024-05-22 22:01:19 [INFO]: Epoch 013 - training loss: 0.0326, validation loss: 0.0267
2024-05-22 22:01:19 [INFO]: Epoch 014 - training loss: 0.0327, validation loss: 0.0241
2024-05-22 22:01:19 [INFO]: Epoch 015 - training loss: 0.0313, validation loss: 0.0236
2024-05-22 22:01:19 [INFO]: Epoch 016 - training loss: 0.0299, validation loss: 0.0239
2024-05-22 22:01:19 [INFO]: Epoch 017 - training loss: 0.0290, validation loss: 0.0243
2024-05-22 22:01:20 [INFO]: Epoch 018 - training loss: 0.0306, validation loss: 0.0246
2024-05-22 22:01:20 [INFO]: Epoch 019 - training loss: 0.0305, validation loss: 0.0243
2024-05-22 22:01:20 [INFO]: Epoch 020 - training loss: 0.0272, validation loss: 0.0240
2024-05-22 22:01:20 [INFO]: Epoch 021 - training loss: 0.0248, validation loss: 0.0231
2024-05-22 22:01:20 [INFO]: Epoch 022 - training loss: 0.0258, validation loss: 0.0232
2024-05-22 22:01:20 [INFO]: Epoch 023 - training loss: 0.0290, validation loss: 0.0248
2024-05-22 22:01:21 [INFO]: Epoch 024 - training loss: 0.0264, validation loss: 0.0227
2024-05-22 22:01:21 [INFO]: Epoch 025 - training loss: 0.0266, validation loss: 0.0256
2024-05-22 22:01:21 [INFO]: Epoch 026 - training loss: 0.0302, validation loss: 0.0250
2024-05-22 22:01:21 [INFO]: Epoch 027 - training loss: 0.0287, validation loss: 0.0236
2024-05-22 22:01:21 [INFO]: Epoch 028 - training loss: 0.0246, validation loss: 0.0233
2024-05-22 22:01:22 [INFO]: Epoch 029 - training loss: 0.0229, validation loss: 0.0226
2024-05-22 22:01:22 [INFO]: Epoch 030 - training loss: 0.0227, validation loss: 0.0234
2024-05-22 22:01:22 [INFO]: Epoch 031 - training loss: 0.0241, validation loss: 0.0224
2024-05-22 22:01:22 [INFO]: Epoch 032 - training loss: 0.0244, validation loss: 0.0238
2024-05-22 22:01:22 [INFO]: Epoch 033 - training loss: 0.0236, validation loss: 0.0246
2024-05-22 22:01:22 [INFO]: Epoch 034 - training loss: 0.0229, validation loss: 0.0229
2024-05-22 22:01:23 [INFO]: Epoch 035 - training loss: 0.0230, validation loss: 0.0235
2024-05-22 22:01:23 [INFO]: Epoch 036 - training loss: 0.0223, validation loss: 0.0238
2024-05-22 22:01:23 [INFO]: Epoch 037 - training loss: 0.0244, validation loss: 0.0272
2024-05-22 22:01:23 [INFO]: Epoch 038 - training loss: 0.0280, validation loss: 0.0241
2024-05-22 22:01:23 [INFO]: Epoch 039 - training loss: 0.0223, validation loss: 0.0237
2024-05-22 22:01:23 [INFO]: Epoch 040 - training loss: 0.0210, validation loss: 0.0239
2024-05-22 22:01:24 [INFO]: Epoch 041 - training loss: 0.0219, validation loss: 0.0232
2024-05-22 22:01:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:01:24 [INFO]: Finished training. The best model is from epoch#31.
2024-05-22 22:01:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_ettm1/20240522_T220116/TimesNet.pypots
2024-05-22 22:01:24 [INFO]: TimesNet on ETTm1: MAE=0.1084, MSE=0.0250
2024-05-22 22:01:24 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-22 22:01:24 [INFO]: Using the given device: cuda:0
2024-05-22 22:01:24 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124
2024-05-22 22:01:24 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/tensorboard
2024-05-22 22:01:24 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 22:01:26 [INFO]: Epoch 001 - training loss: 0.6747, validation loss: 0.4720
2024-05-22 22:01:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch1_loss0.4720410108566284.pypots
2024-05-22 22:01:28 [INFO]: Epoch 002 - training loss: 0.4254, validation loss: 0.3682
2024-05-22 22:01:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch2_loss0.36815426498651505.pypots
2024-05-22 22:01:30 [INFO]: Epoch 003 - training loss: 0.4298, validation loss: 0.3388
2024-05-22 22:01:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch3_loss0.3387506902217865.pypots
2024-05-22 22:01:32 [INFO]: Epoch 004 - training loss: 0.2977, validation loss: 0.2950
2024-05-22 22:01:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch4_loss0.29498231410980225.pypots
2024-05-22 22:01:34 [INFO]: Epoch 005 - training loss: 0.3072, validation loss: 0.2877
2024-05-22 22:01:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch5_loss0.2876783013343811.pypots
2024-05-22 22:01:36 [INFO]: Epoch 006 - training loss: 0.2656, validation loss: 0.2881
2024-05-22 22:01:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch6_loss0.28813453763723373.pypots
2024-05-22 22:01:38 [INFO]: Epoch 007 - training loss: 0.3087, validation loss: 0.2915
2024-05-22 22:01:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch7_loss0.2915196418762207.pypots
2024-05-22 22:01:40 [INFO]: Epoch 008 - training loss: 0.2650, validation loss: 0.2750
2024-05-22 22:01:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch8_loss0.2749530002474785.pypots
2024-05-22 22:01:42 [INFO]: Epoch 009 - training loss: 0.2684, validation loss: 0.2505
2024-05-22 22:01:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch9_loss0.2504683695733547.pypots
2024-05-22 22:01:44 [INFO]: Epoch 010 - training loss: 0.2740, validation loss: 0.2441
2024-05-22 22:01:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch10_loss0.24410811066627502.pypots
2024-05-22 22:01:46 [INFO]: Epoch 011 - training loss: 0.2289, validation loss: 0.2405
2024-05-22 22:01:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch11_loss0.24052805826067924.pypots
2024-05-22 22:01:48 [INFO]: Epoch 012 - training loss: 0.2340, validation loss: 0.2385
2024-05-22 22:01:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch12_loss0.23846342042088509.pypots
2024-05-22 22:01:50 [INFO]: Epoch 013 - training loss: 0.2157, validation loss: 0.2276
2024-05-22 22:01:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch13_loss0.22755808755755424.pypots
2024-05-22 22:01:52 [INFO]: Epoch 014 - training loss: 0.2158, validation loss: 0.2202
2024-05-22 22:01:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch14_loss0.22023959830403328.pypots
2024-05-22 22:01:54 [INFO]: Epoch 015 - training loss: 0.2117, validation loss: 0.2179
2024-05-22 22:01:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch15_loss0.2179441675543785.pypots
2024-05-22 22:01:56 [INFO]: Epoch 016 - training loss: 0.2026, validation loss: 0.2133
2024-05-22 22:01:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch16_loss0.21327253803610802.pypots
2024-05-22 22:01:58 [INFO]: Epoch 017 - training loss: 0.2105, validation loss: 0.2089
2024-05-22 22:01:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch17_loss0.2089017927646637.pypots
2024-05-22 22:02:00 [INFO]: Epoch 018 - training loss: 0.1957, validation loss: 0.1986
2024-05-22 22:02:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch18_loss0.19860680028796196.pypots
2024-05-22 22:02:02 [INFO]: Epoch 019 - training loss: 0.2127, validation loss: 0.1997
2024-05-22 22:02:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch19_loss0.19971422106027603.pypots
2024-05-22 22:02:04 [INFO]: Epoch 020 - training loss: 0.2512, validation loss: 0.1943
2024-05-22 22:02:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch20_loss0.19431717321276665.pypots
2024-05-22 22:02:06 [INFO]: Epoch 021 - training loss: 0.1968, validation loss: 0.1913
2024-05-22 22:02:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch21_loss0.19129138067364693.pypots
2024-05-22 22:02:08 [INFO]: Epoch 022 - training loss: 0.1941, validation loss: 0.1820
2024-05-22 22:02:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch22_loss0.1819572076201439.pypots
2024-05-22 22:02:10 [INFO]: Epoch 023 - training loss: 0.1918, validation loss: 0.1850
2024-05-22 22:02:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch23_loss0.18500348925590515.pypots
2024-05-22 22:02:12 [INFO]: Epoch 024 - training loss: 0.1936, validation loss: 0.1764
2024-05-22 22:02:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch24_loss0.17642341181635857.pypots
2024-05-22 22:02:14 [INFO]: Epoch 025 - training loss: 0.1721, validation loss: 0.1706
2024-05-22 22:02:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch25_loss0.17064271122217178.pypots
2024-05-22 22:02:17 [INFO]: Epoch 026 - training loss: 0.1712, validation loss: 0.1673
2024-05-22 22:02:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch26_loss0.16728539019823074.pypots
2024-05-22 22:02:19 [INFO]: Epoch 027 - training loss: 0.1598, validation loss: 0.1643
2024-05-22 22:02:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch27_loss0.16425690799951553.pypots
2024-05-22 22:02:21 [INFO]: Epoch 028 - training loss: 0.1489, validation loss: 0.1584
2024-05-22 22:02:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch28_loss0.15838054940104485.pypots
2024-05-22 22:02:23 [INFO]: Epoch 029 - training loss: 0.1553, validation loss: 0.1597
2024-05-22 22:02:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch29_loss0.15967874228954315.pypots
2024-05-22 22:02:25 [INFO]: Epoch 030 - training loss: 0.1893, validation loss: 0.1578
2024-05-22 22:02:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch30_loss0.15776080638170242.pypots
2024-05-22 22:02:27 [INFO]: Epoch 031 - training loss: 0.1631, validation loss: 0.1647
2024-05-22 22:02:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch31_loss0.1647023893892765.pypots
2024-05-22 22:02:29 [INFO]: Epoch 032 - training loss: 0.1731, validation loss: 0.1571
2024-05-22 22:02:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch32_loss0.1570540890097618.pypots
2024-05-22 22:02:31 [INFO]: Epoch 033 - training loss: 0.1763, validation loss: 0.1595
2024-05-22 22:02:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch33_loss0.15954263508319855.pypots
2024-05-22 22:02:33 [INFO]: Epoch 034 - training loss: 0.1723, validation loss: 0.1658
2024-05-22 22:02:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch34_loss0.16581087186932564.pypots
2024-05-22 22:02:35 [INFO]: Epoch 035 - training loss: 0.1902, validation loss: 0.1735
2024-05-22 22:02:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch35_loss0.17353536188602448.pypots
2024-05-22 22:02:37 [INFO]: Epoch 036 - training loss: 0.1830, validation loss: 0.1582
2024-05-22 22:02:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch36_loss0.15815450251102448.pypots
2024-05-22 22:02:39 [INFO]: Epoch 037 - training loss: 0.1597, validation loss: 0.1605
2024-05-22 22:02:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch37_loss0.16051728650927544.pypots
2024-05-22 22:02:41 [INFO]: Epoch 038 - training loss: 0.1385, validation loss: 0.1572
2024-05-22 22:02:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch38_loss0.15717852488160133.pypots
2024-05-22 22:02:43 [INFO]: Epoch 039 - training loss: 0.1387, validation loss: 0.1487
2024-05-22 22:02:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch39_loss0.14866813644766808.pypots
2024-05-22 22:02:45 [INFO]: Epoch 040 - training loss: 0.1528, validation loss: 0.1460
2024-05-22 22:02:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch40_loss0.1459938809275627.pypots
2024-05-22 22:02:47 [INFO]: Epoch 041 - training loss: 0.1425, validation loss: 0.1442
2024-05-22 22:02:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch41_loss0.14416691660881042.pypots
2024-05-22 22:02:49 [INFO]: Epoch 042 - training loss: 0.1660, validation loss: 0.1445
2024-05-22 22:02:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch42_loss0.1445324309170246.pypots
2024-05-22 22:02:51 [INFO]: Epoch 043 - training loss: 0.1318, validation loss: 0.1456
2024-05-22 22:02:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch43_loss0.1455688551068306.pypots
2024-05-22 22:02:53 [INFO]: Epoch 044 - training loss: 0.1583, validation loss: 0.1494
2024-05-22 22:02:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch44_loss0.1493692547082901.pypots
2024-05-22 22:02:55 [INFO]: Epoch 045 - training loss: 0.1545, validation loss: 0.1461
2024-05-22 22:02:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch45_loss0.14610963687300682.pypots
2024-05-22 22:02:57 [INFO]: Epoch 046 - training loss: 0.1465, validation loss: 0.1484
2024-05-22 22:02:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch46_loss0.1483805701136589.pypots
2024-05-22 22:02:59 [INFO]: Epoch 047 - training loss: 0.1424, validation loss: 0.1387
2024-05-22 22:02:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch47_loss0.1387042999267578.pypots
2024-05-22 22:03:01 [INFO]: Epoch 048 - training loss: 0.1328, validation loss: 0.1372
2024-05-22 22:03:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch48_loss0.13715920597314835.pypots
2024-05-22 22:03:03 [INFO]: Epoch 049 - training loss: 0.1515, validation loss: 0.1506
2024-05-22 22:03:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch49_loss0.15055209770798683.pypots
2024-05-22 22:03:05 [INFO]: Epoch 050 - training loss: 0.1476, validation loss: 0.1392
2024-05-22 22:03:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch50_loss0.1391897276043892.pypots
2024-05-22 22:03:07 [INFO]: Epoch 051 - training loss: 0.1490, validation loss: 0.1420
2024-05-22 22:03:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch51_loss0.14200866967439651.pypots
2024-05-22 22:03:09 [INFO]: Epoch 052 - training loss: 0.1325, validation loss: 0.1339
2024-05-22 22:03:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch52_loss0.13390258699655533.pypots
2024-05-22 22:03:11 [INFO]: Epoch 053 - training loss: 0.1346, validation loss: 0.1321
2024-05-22 22:03:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch53_loss0.1321289800107479.pypots
2024-05-22 22:03:13 [INFO]: Epoch 054 - training loss: 0.1333, validation loss: 0.1350
2024-05-22 22:03:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch54_loss0.13502370938658714.pypots
2024-05-22 22:03:15 [INFO]: Epoch 055 - training loss: 0.1332, validation loss: 0.1338
2024-05-22 22:03:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch55_loss0.1337861306965351.pypots
2024-05-22 22:03:17 [INFO]: Epoch 056 - training loss: 0.1426, validation loss: 0.1308
2024-05-22 22:03:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch56_loss0.13077371194958687.pypots
2024-05-22 22:03:19 [INFO]: Epoch 057 - training loss: 0.1516, validation loss: 0.1814
2024-05-22 22:03:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch57_loss0.18140416592359543.pypots
2024-05-22 22:03:21 [INFO]: Epoch 058 - training loss: 0.1888, validation loss: 0.1589
2024-05-22 22:03:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch58_loss0.15894727036356926.pypots
2024-05-22 22:03:23 [INFO]: Epoch 059 - training loss: 0.1515, validation loss: 0.1400
2024-05-22 22:03:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch59_loss0.1400085687637329.pypots
2024-05-22 22:03:25 [INFO]: Epoch 060 - training loss: 0.1612, validation loss: 0.1344
2024-05-22 22:03:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch60_loss0.13437757641077042.pypots
2024-05-22 22:03:27 [INFO]: Epoch 061 - training loss: 0.1305, validation loss: 0.1332
2024-05-22 22:03:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch61_loss0.13316003419458866.pypots
2024-05-22 22:03:29 [INFO]: Epoch 062 - training loss: 0.1530, validation loss: 0.1354
2024-05-22 22:03:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch62_loss0.13537017069756985.pypots
2024-05-22 22:03:31 [INFO]: Epoch 063 - training loss: 0.1642, validation loss: 0.1443
2024-05-22 22:03:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch63_loss0.14425333216786385.pypots
2024-05-22 22:03:33 [INFO]: Epoch 064 - training loss: 0.1422, validation loss: 0.1377
2024-05-22 22:03:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch64_loss0.13770240172743797.pypots
2024-05-22 22:03:35 [INFO]: Epoch 065 - training loss: 0.1420, validation loss: 0.1381
2024-05-22 22:03:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch65_loss0.13813746348023415.pypots
2024-05-22 22:03:37 [INFO]: Epoch 066 - training loss: 0.1431, validation loss: 0.1346
2024-05-22 22:03:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI_epoch66_loss0.13459708541631699.pypots
2024-05-22 22:03:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:03:37 [INFO]: Finished training. The best model is from epoch#56.
2024-05-22 22:03:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_ettm1/20240522_T220124/CSDI.pypots
2024-05-22 22:03:53 [INFO]: CSDI on ETTm1: MAE=0.1225, MSE=0.0343
2024-05-22 22:03:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-22 22:03:53 [INFO]: Using the given device: cuda:0
2024-05-22 22:03:53 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220353
2024-05-22 22:03:53 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220353/tensorboard
2024-05-22 22:03:53 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:03:53 [INFO]: Epoch 001 - training loss: 24262.1654, validation loss: 0.9504
2024-05-22 22:03:53 [INFO]: Epoch 002 - training loss: 21999.1769, validation loss: 0.9391
2024-05-22 22:03:53 [INFO]: Epoch 003 - training loss: 20068.9053, validation loss: 0.9199
2024-05-22 22:03:53 [INFO]: Epoch 004 - training loss: 18000.9648, validation loss: 0.8802
2024-05-22 22:03:53 [INFO]: Epoch 005 - training loss: 16249.8480, validation loss: 0.8039
2024-05-22 22:03:54 [INFO]: Epoch 006 - training loss: 14594.6457, validation loss: 0.6866
2024-05-22 22:03:54 [INFO]: Epoch 007 - training loss: 13413.3273, validation loss: 0.5693
2024-05-22 22:03:54 [INFO]: Epoch 008 - training loss: 12524.0765, validation loss: 0.5399
2024-05-22 22:03:54 [INFO]: Epoch 009 - training loss: 11584.1004, validation loss: 0.5076
2024-05-22 22:03:54 [INFO]: Epoch 010 - training loss: 11166.2944, validation loss: 0.4727
2024-05-22 22:03:54 [INFO]: Epoch 011 - training loss: 10803.1069, validation loss: 0.4553
2024-05-22 22:03:54 [INFO]: Epoch 012 - training loss: 10619.6667, validation loss: 0.4521
2024-05-22 22:03:54 [INFO]: Epoch 013 - training loss: 10480.4806, validation loss: 0.4365
2024-05-22 22:03:54 [INFO]: Epoch 014 - training loss: 10167.2476, validation loss: 0.4193
2024-05-22 22:03:55 [INFO]: Epoch 015 - training loss: 10122.4548, validation loss: 0.3977
2024-05-22 22:03:55 [INFO]: Epoch 016 - training loss: 9971.3127, validation loss: 0.3695
2024-05-22 22:03:55 [INFO]: Epoch 017 - training loss: 9882.3815, validation loss: 0.3461
2024-05-22 22:03:55 [INFO]: Epoch 018 - training loss: 9873.4081, validation loss: 0.3265
2024-05-22 22:03:55 [INFO]: Epoch 019 - training loss: 9837.9043, validation loss: 0.3005
2024-05-22 22:03:55 [INFO]: Epoch 020 - training loss: 9723.7856, validation loss: 0.2791
2024-05-22 22:03:55 [INFO]: Epoch 021 - training loss: 9768.1536, validation loss: 0.2611
2024-05-22 22:03:55 [INFO]: Epoch 022 - training loss: 9654.9166, validation loss: 0.2522
2024-05-22 22:03:55 [INFO]: Epoch 023 - training loss: 9647.4661, validation loss: 0.2409
2024-05-22 22:03:56 [INFO]: Epoch 024 - training loss: 9612.3699, validation loss: 0.2363
2024-05-22 22:03:56 [INFO]: Epoch 025 - training loss: 9572.3597, validation loss: 0.2355
2024-05-22 22:03:56 [INFO]: Epoch 026 - training loss: 9549.2753, validation loss: 0.2281
2024-05-22 22:03:56 [INFO]: Epoch 027 - training loss: 9515.1388, validation loss: 0.2218
2024-05-22 22:03:56 [INFO]: Epoch 028 - training loss: 9527.4141, validation loss: 0.2179
2024-05-22 22:03:56 [INFO]: Epoch 029 - training loss: 9496.6176, validation loss: 0.2139
2024-05-22 22:03:56 [INFO]: Epoch 030 - training loss: 9475.2374, validation loss: 0.2148
2024-05-22 22:03:56 [INFO]: Epoch 031 - training loss: 9468.5468, validation loss: 0.2155
2024-05-22 22:03:57 [INFO]: Epoch 032 - training loss: 9468.2688, validation loss: 0.2059
2024-05-22 22:03:57 [INFO]: Epoch 033 - training loss: 9474.9736, validation loss: 0.2057
2024-05-22 22:03:57 [INFO]: Epoch 034 - training loss: 9436.8498, validation loss: 0.2001
2024-05-22 22:03:57 [INFO]: Epoch 035 - training loss: 9427.1365, validation loss: 0.1999
2024-05-22 22:03:57 [INFO]: Epoch 036 - training loss: 9423.6967, validation loss: 0.1946
2024-05-22 22:03:57 [INFO]: Epoch 037 - training loss: 9420.2909, validation loss: 0.1941
2024-05-22 22:03:57 [INFO]: Epoch 038 - training loss: 9405.8842, validation loss: 0.1931
2024-05-22 22:03:57 [INFO]: Epoch 039 - training loss: 9409.6577, validation loss: 0.1878
2024-05-22 22:03:57 [INFO]: Epoch 040 - training loss: 9405.5540, validation loss: 0.1867
2024-05-22 22:03:58 [INFO]: Epoch 041 - training loss: 9393.2753, validation loss: 0.1848
2024-05-22 22:03:58 [INFO]: Epoch 042 - training loss: 9386.2744, validation loss: 0.1839
2024-05-22 22:03:58 [INFO]: Epoch 043 - training loss: 9383.0961, validation loss: 0.1812
2024-05-22 22:03:58 [INFO]: Epoch 044 - training loss: 9378.3931, validation loss: 0.1807
2024-05-22 22:03:58 [INFO]: Epoch 045 - training loss: 9374.9703, validation loss: 0.1742
2024-05-22 22:03:58 [INFO]: Epoch 046 - training loss: 9372.6314, validation loss: 0.1706
2024-05-22 22:03:58 [INFO]: Epoch 047 - training loss: 9365.0403, validation loss: 0.1687
2024-05-22 22:03:58 [INFO]: Epoch 048 - training loss: 9365.6475, validation loss: 0.1644
2024-05-22 22:03:58 [INFO]: Epoch 049 - training loss: 9361.7306, validation loss: 0.1623
2024-05-22 22:03:59 [INFO]: Epoch 050 - training loss: 9366.7159, validation loss: 0.1619
2024-05-22 22:03:59 [INFO]: Epoch 051 - training loss: 9370.4331, validation loss: 0.1570
2024-05-22 22:03:59 [INFO]: Epoch 052 - training loss: 9352.9012, validation loss: 0.1520
2024-05-22 22:03:59 [INFO]: Epoch 053 - training loss: 9344.9529, validation loss: 0.1507
2024-05-22 22:03:59 [INFO]: Epoch 054 - training loss: 9345.2040, validation loss: 0.1476
2024-05-22 22:03:59 [INFO]: Epoch 055 - training loss: 9342.1503, validation loss: 0.1470
2024-05-22 22:03:59 [INFO]: Epoch 056 - training loss: 9341.6689, validation loss: 0.1432
2024-05-22 22:03:59 [INFO]: Epoch 057 - training loss: 9337.4058, validation loss: 0.1409
2024-05-22 22:03:59 [INFO]: Epoch 058 - training loss: 9337.5576, validation loss: 0.1364
2024-05-22 22:04:00 [INFO]: Epoch 059 - training loss: 9332.0433, validation loss: 0.1385
2024-05-22 22:04:00 [INFO]: Epoch 060 - training loss: 9331.3568, validation loss: 0.1319
2024-05-22 22:04:00 [INFO]: Epoch 061 - training loss: 9327.2894, validation loss: 0.1337
2024-05-22 22:04:00 [INFO]: Epoch 062 - training loss: 9330.0773, validation loss: 0.1283
2024-05-22 22:04:00 [INFO]: Epoch 063 - training loss: 9340.1436, validation loss: 0.1282
2024-05-22 22:04:00 [INFO]: Epoch 064 - training loss: 9323.2919, validation loss: 0.1248
2024-05-22 22:04:00 [INFO]: Epoch 065 - training loss: 9327.7415, validation loss: 0.1229
2024-05-22 22:04:00 [INFO]: Epoch 066 - training loss: 9321.2026, validation loss: 0.1235
2024-05-22 22:04:00 [INFO]: Epoch 067 - training loss: 9320.3228, validation loss: 0.1221
2024-05-22 22:04:01 [INFO]: Epoch 068 - training loss: 9320.3719, validation loss: 0.1191
2024-05-22 22:04:01 [INFO]: Epoch 069 - training loss: 9317.9522, validation loss: 0.1210
2024-05-22 22:04:01 [INFO]: Epoch 070 - training loss: 9318.5991, validation loss: 0.1203
2024-05-22 22:04:01 [INFO]: Epoch 071 - training loss: 9315.9990, validation loss: 0.1173
2024-05-22 22:04:01 [INFO]: Epoch 072 - training loss: 9315.7032, validation loss: 0.1157
2024-05-22 22:04:01 [INFO]: Epoch 073 - training loss: 9312.3237, validation loss: 0.1168
2024-05-22 22:04:01 [INFO]: Epoch 074 - training loss: 9313.2321, validation loss: 0.1145
2024-05-22 22:04:01 [INFO]: Epoch 075 - training loss: 9310.7413, validation loss: 0.1134
2024-05-22 22:04:01 [INFO]: Epoch 076 - training loss: 9310.8124, validation loss: 0.1120
2024-05-22 22:04:02 [INFO]: Epoch 077 - training loss: 9310.5284, validation loss: 0.1140
2024-05-22 22:04:02 [INFO]: Epoch 078 - training loss: 9311.4622, validation loss: 0.1126
2024-05-22 22:04:02 [INFO]: Epoch 079 - training loss: 9306.7307, validation loss: 0.1110
2024-05-22 22:04:02 [INFO]: Epoch 080 - training loss: 9307.0551, validation loss: 0.1094
2024-05-22 22:04:02 [INFO]: Epoch 081 - training loss: 9306.5118, validation loss: 0.1125
2024-05-22 22:04:02 [INFO]: Epoch 082 - training loss: 9304.5302, validation loss: 0.1079
2024-05-22 22:04:02 [INFO]: Epoch 083 - training loss: 9305.3175, validation loss: 0.1082
2024-05-22 22:04:02 [INFO]: Epoch 084 - training loss: 9302.7878, validation loss: 0.1080
2024-05-22 22:04:02 [INFO]: Epoch 085 - training loss: 9304.0501, validation loss: 0.1064
2024-05-22 22:04:03 [INFO]: Epoch 086 - training loss: 9301.4493, validation loss: 0.1071
2024-05-22 22:04:03 [INFO]: Epoch 087 - training loss: 9301.5640, validation loss: 0.1054
2024-05-22 22:04:03 [INFO]: Epoch 088 - training loss: 9301.2442, validation loss: 0.1041
2024-05-22 22:04:03 [INFO]: Epoch 089 - training loss: 9301.4104, validation loss: 0.1055
2024-05-22 22:04:03 [INFO]: Epoch 090 - training loss: 9298.4479, validation loss: 0.1040
2024-05-22 22:04:03 [INFO]: Epoch 091 - training loss: 9297.8499, validation loss: 0.1040
2024-05-22 22:04:03 [INFO]: Epoch 092 - training loss: 9299.3544, validation loss: 0.1028
2024-05-22 22:04:03 [INFO]: Epoch 093 - training loss: 9298.5403, validation loss: 0.1010
2024-05-22 22:04:03 [INFO]: Epoch 094 - training loss: 9297.5518, validation loss: 0.1032
2024-05-22 22:04:04 [INFO]: Epoch 095 - training loss: 9295.4915, validation loss: 0.1016
2024-05-22 22:04:04 [INFO]: Epoch 096 - training loss: 9295.9155, validation loss: 0.1022
2024-05-22 22:04:04 [INFO]: Epoch 097 - training loss: 9299.1029, validation loss: 0.1000
2024-05-22 22:04:04 [INFO]: Epoch 098 - training loss: 9296.1985, validation loss: 0.1010
2024-05-22 22:04:04 [INFO]: Epoch 099 - training loss: 9294.2336, validation loss: 0.0995
2024-05-22 22:04:04 [INFO]: Epoch 100 - training loss: 9293.0864, validation loss: 0.1006
2024-05-22 22:04:04 [INFO]: Epoch 101 - training loss: 9293.7724, validation loss: 0.0990
2024-05-22 22:04:04 [INFO]: Epoch 102 - training loss: 9293.9502, validation loss: 0.0973
2024-05-22 22:04:04 [INFO]: Epoch 103 - training loss: 9293.0277, validation loss: 0.0983
2024-05-22 22:04:05 [INFO]: Epoch 104 - training loss: 9293.6902, validation loss: 0.0976
2024-05-22 22:04:05 [INFO]: Epoch 105 - training loss: 9293.2300, validation loss: 0.0981
2024-05-22 22:04:05 [INFO]: Epoch 106 - training loss: 9293.7803, validation loss: 0.0961
2024-05-22 22:04:05 [INFO]: Epoch 107 - training loss: 9291.5681, validation loss: 0.0951
2024-05-22 22:04:05 [INFO]: Epoch 108 - training loss: 9291.6683, validation loss: 0.0954
2024-05-22 22:04:05 [INFO]: Epoch 109 - training loss: 9291.3711, validation loss: 0.0942
2024-05-22 22:04:05 [INFO]: Epoch 110 - training loss: 9291.6981, validation loss: 0.0936
2024-05-22 22:04:05 [INFO]: Epoch 111 - training loss: 9290.3433, validation loss: 0.0969
2024-05-22 22:04:05 [INFO]: Epoch 112 - training loss: 9288.1445, validation loss: 0.0927
2024-05-22 22:04:06 [INFO]: Epoch 113 - training loss: 9289.6520, validation loss: 0.0933
2024-05-22 22:04:06 [INFO]: Epoch 114 - training loss: 9291.9162, validation loss: 0.0954
2024-05-22 22:04:06 [INFO]: Epoch 115 - training loss: 9290.4795, validation loss: 0.0923
2024-05-22 22:04:06 [INFO]: Epoch 116 - training loss: 9287.4343, validation loss: 0.0942
2024-05-22 22:04:06 [INFO]: Epoch 117 - training loss: 9287.8986, validation loss: 0.0927
2024-05-22 22:04:06 [INFO]: Epoch 118 - training loss: 9287.8613, validation loss: 0.0923
2024-05-22 22:04:06 [INFO]: Epoch 119 - training loss: 9286.4975, validation loss: 0.0912
2024-05-22 22:04:06 [INFO]: Epoch 120 - training loss: 9284.7107, validation loss: 0.0919
2024-05-22 22:04:06 [INFO]: Epoch 121 - training loss: 9286.7217, validation loss: 0.0921
2024-05-22 22:04:07 [INFO]: Epoch 122 - training loss: 9288.9651, validation loss: 0.0909
2024-05-22 22:04:07 [INFO]: Epoch 123 - training loss: 9284.4135, validation loss: 0.0905
2024-05-22 22:04:07 [INFO]: Epoch 124 - training loss: 9284.6241, validation loss: 0.0909
2024-05-22 22:04:07 [INFO]: Epoch 125 - training loss: 9285.2000, validation loss: 0.0903
2024-05-22 22:04:07 [INFO]: Epoch 126 - training loss: 9285.0575, validation loss: 0.0899
2024-05-22 22:04:07 [INFO]: Epoch 127 - training loss: 9284.8318, validation loss: 0.0890
2024-05-22 22:04:07 [INFO]: Epoch 128 - training loss: 9284.4034, validation loss: 0.0903
2024-05-22 22:04:07 [INFO]: Epoch 129 - training loss: 9283.6389, validation loss: 0.0883
2024-05-22 22:04:07 [INFO]: Epoch 130 - training loss: 9284.3674, validation loss: 0.0889
2024-05-22 22:04:08 [INFO]: Epoch 131 - training loss: 9285.4767, validation loss: 0.0882
2024-05-22 22:04:08 [INFO]: Epoch 132 - training loss: 9283.0194, validation loss: 0.0887
2024-05-22 22:04:08 [INFO]: Epoch 133 - training loss: 9283.5775, validation loss: 0.0864
2024-05-22 22:04:08 [INFO]: Epoch 134 - training loss: 9281.3847, validation loss: 0.0873
2024-05-22 22:04:08 [INFO]: Epoch 135 - training loss: 9281.6569, validation loss: 0.0860
2024-05-22 22:04:08 [INFO]: Epoch 136 - training loss: 9281.5642, validation loss: 0.0870
2024-05-22 22:04:08 [INFO]: Epoch 137 - training loss: 9282.4981, validation loss: 0.0863
2024-05-22 22:04:08 [INFO]: Epoch 138 - training loss: 9281.6940, validation loss: 0.0862
2024-05-22 22:04:08 [INFO]: Epoch 139 - training loss: 9281.3421, validation loss: 0.0847
2024-05-22 22:04:09 [INFO]: Epoch 140 - training loss: 9282.6078, validation loss: 0.0840
2024-05-22 22:04:09 [INFO]: Epoch 141 - training loss: 9283.4260, validation loss: 0.0871
2024-05-22 22:04:09 [INFO]: Epoch 142 - training loss: 9281.5592, validation loss: 0.0841
2024-05-22 22:04:09 [INFO]: Epoch 143 - training loss: 9282.5911, validation loss: 0.0842
2024-05-22 22:04:09 [INFO]: Epoch 144 - training loss: 9281.3244, validation loss: 0.0843
2024-05-22 22:04:09 [INFO]: Epoch 145 - training loss: 9281.6443, validation loss: 0.0815
2024-05-22 22:04:09 [INFO]: Epoch 146 - training loss: 9280.6461, validation loss: 0.0854
2024-05-22 22:04:09 [INFO]: Epoch 147 - training loss: 9278.8314, validation loss: 0.0826
2024-05-22 22:04:09 [INFO]: Epoch 148 - training loss: 9279.8603, validation loss: 0.0837
2024-05-22 22:04:10 [INFO]: Epoch 149 - training loss: 9280.4470, validation loss: 0.0839
2024-05-22 22:04:10 [INFO]: Epoch 150 - training loss: 9279.1336, validation loss: 0.0843
2024-05-22 22:04:10 [INFO]: Epoch 151 - training loss: 9281.9462, validation loss: 0.0828
2024-05-22 22:04:10 [INFO]: Epoch 152 - training loss: 9279.7763, validation loss: 0.0853
2024-05-22 22:04:10 [INFO]: Epoch 153 - training loss: 9280.1783, validation loss: 0.0808
2024-05-22 22:04:10 [INFO]: Epoch 154 - training loss: 9279.0599, validation loss: 0.0826
2024-05-22 22:04:10 [INFO]: Epoch 155 - training loss: 9279.5531, validation loss: 0.0831
2024-05-22 22:04:10 [INFO]: Epoch 156 - training loss: 9279.8567, validation loss: 0.0807
2024-05-22 22:04:10 [INFO]: Epoch 157 - training loss: 9279.1871, validation loss: 0.0812
2024-05-22 22:04:11 [INFO]: Epoch 158 - training loss: 9278.7335, validation loss: 0.0804
2024-05-22 22:04:11 [INFO]: Epoch 159 - training loss: 9278.0190, validation loss: 0.0805
2024-05-22 22:04:11 [INFO]: Epoch 160 - training loss: 9277.1841, validation loss: 0.0818
2024-05-22 22:04:11 [INFO]: Epoch 161 - training loss: 9276.0182, validation loss: 0.0801
2024-05-22 22:04:11 [INFO]: Epoch 162 - training loss: 9277.2394, validation loss: 0.0810
2024-05-22 22:04:11 [INFO]: Epoch 163 - training loss: 9289.3178, validation loss: 0.0804
2024-05-22 22:04:11 [INFO]: Epoch 164 - training loss: 9277.9036, validation loss: 0.0795
2024-05-22 22:04:11 [INFO]: Epoch 165 - training loss: 9276.0215, validation loss: 0.0793
2024-05-22 22:04:11 [INFO]: Epoch 166 - training loss: 9277.3136, validation loss: 0.0787
2024-05-22 22:04:12 [INFO]: Epoch 167 - training loss: 9276.3883, validation loss: 0.0795
2024-05-22 22:04:12 [INFO]: Epoch 168 - training loss: 9275.6353, validation loss: 0.0788
2024-05-22 22:04:12 [INFO]: Epoch 169 - training loss: 9277.6315, validation loss: 0.0789
2024-05-22 22:04:12 [INFO]: Epoch 170 - training loss: 9276.5638, validation loss: 0.0793
2024-05-22 22:04:12 [INFO]: Epoch 171 - training loss: 9276.5485, validation loss: 0.0773
2024-05-22 22:04:12 [INFO]: Epoch 172 - training loss: 9275.9076, validation loss: 0.0785
2024-05-22 22:04:12 [INFO]: Epoch 173 - training loss: 9275.4274, validation loss: 0.0782
2024-05-22 22:04:12 [INFO]: Epoch 174 - training loss: 9276.3699, validation loss: 0.0782
2024-05-22 22:04:12 [INFO]: Epoch 175 - training loss: 9276.7838, validation loss: 0.0790
2024-05-22 22:04:13 [INFO]: Epoch 176 - training loss: 9276.8829, validation loss: 0.0750
2024-05-22 22:04:13 [INFO]: Epoch 177 - training loss: 9276.5771, validation loss: 0.0780
2024-05-22 22:04:13 [INFO]: Epoch 178 - training loss: 9277.5690, validation loss: 0.0770
2024-05-22 22:04:13 [INFO]: Epoch 179 - training loss: 9275.4313, validation loss: 0.0771
2024-05-22 22:04:13 [INFO]: Epoch 180 - training loss: 9275.9178, validation loss: 0.0783
2024-05-22 22:04:13 [INFO]: Epoch 181 - training loss: 9276.7993, validation loss: 0.0759
2024-05-22 22:04:13 [INFO]: Epoch 182 - training loss: 9276.0662, validation loss: 0.0789
2024-05-22 22:04:13 [INFO]: Epoch 183 - training loss: 9274.6564, validation loss: 0.0775
2024-05-22 22:04:13 [INFO]: Epoch 184 - training loss: 9277.3159, validation loss: 0.0763
2024-05-22 22:04:14 [INFO]: Epoch 185 - training loss: 9275.8127, validation loss: 0.0793
2024-05-22 22:04:14 [INFO]: Epoch 186 - training loss: 9274.8347, validation loss: 0.0767
2024-05-22 22:04:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:04:14 [INFO]: Finished training. The best model is from epoch#176.
2024-05-22 22:04:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_ettm1/20240522_T220353/GPVAE.pypots
2024-05-22 22:04:14 [INFO]: GP-VAE on ETTm1: MAE=0.2741, MSE=0.1576
2024-05-22 22:04:14 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-22 22:04:14 [INFO]: Using the given device: cuda:0
2024-05-22 22:04:14 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240522_T220414
2024-05-22 22:04:14 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_ettm1/20240522_T220414/tensorboard
2024-05-22 22:04:14 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:04:22 [INFO]: Epoch 001 - generator training loss: 0.4744, discriminator training loss: 0.4208, validation loss: 0.2692
2024-05-22 22:04:29 [INFO]: Epoch 002 - generator training loss: 0.0001, discriminator training loss: 0.3229, validation loss: 0.1061
2024-05-22 22:04:37 [INFO]: Epoch 003 - generator training loss: -0.1242, discriminator training loss: 0.3103, validation loss: 0.0584
2024-05-22 22:04:44 [INFO]: Epoch 004 - generator training loss: -0.1337, discriminator training loss: 0.2946, validation loss: 0.0484
2024-05-22 22:04:51 [INFO]: Epoch 005 - generator training loss: -0.1223, discriminator training loss: 0.2704, validation loss: 0.0434
2024-05-22 22:04:58 [INFO]: Epoch 006 - generator training loss: -0.0969, discriminator training loss: 0.2382, validation loss: 0.0395
2024-05-22 22:05:05 [INFO]: Epoch 007 - generator training loss: -0.0724, discriminator training loss: 0.2040, validation loss: 0.0373
2024-05-22 22:05:12 [INFO]: Epoch 008 - generator training loss: -0.0540, discriminator training loss: 0.1719, validation loss: 0.0350
2024-05-22 22:05:20 [INFO]: Epoch 009 - generator training loss: -0.0414, discriminator training loss: 0.1505, validation loss: 0.0353
2024-05-22 22:05:27 [INFO]: Epoch 010 - generator training loss: -0.0370, discriminator training loss: 0.1362, validation loss: 0.0337
2024-05-22 22:05:34 [INFO]: Epoch 011 - generator training loss: -0.0321, discriminator training loss: 0.1283, validation loss: 0.0329
2024-05-22 22:05:41 [INFO]: Epoch 012 - generator training loss: -0.0342, discriminator training loss: 0.1268, validation loss: 0.0334
2024-05-22 22:05:49 [INFO]: Epoch 013 - generator training loss: -0.0325, discriminator training loss: 0.1238, validation loss: 0.0319
2024-05-22 22:05:56 [INFO]: Epoch 014 - generator training loss: -0.0327, discriminator training loss: 0.1229, validation loss: 0.0312
2024-05-22 22:06:03 [INFO]: Epoch 015 - generator training loss: -0.0320, discriminator training loss: 0.1201, validation loss: 0.0312
2024-05-22 22:06:10 [INFO]: Epoch 016 - generator training loss: -0.0315, discriminator training loss: 0.1192, validation loss: 0.0307
2024-05-22 22:06:17 [INFO]: Epoch 017 - generator training loss: -0.0284, discriminator training loss: 0.1192, validation loss: 0.0315
2024-05-22 22:06:25 [INFO]: Epoch 018 - generator training loss: -0.0300, discriminator training loss: 0.1175, validation loss: 0.0327
2024-05-22 22:06:32 [INFO]: Epoch 019 - generator training loss: -0.0328, discriminator training loss: 0.1197, validation loss: 0.0301
2024-05-22 22:06:39 [INFO]: Epoch 020 - generator training loss: -0.0351, discriminator training loss: 0.1177, validation loss: 0.0295
2024-05-22 22:06:46 [INFO]: Epoch 021 - generator training loss: -0.0369, discriminator training loss: 0.1163, validation loss: 0.0295
2024-05-22 22:06:54 [INFO]: Epoch 022 - generator training loss: -0.0319, discriminator training loss: 0.1150, validation loss: 0.0288
2024-05-22 22:07:01 [INFO]: Epoch 023 - generator training loss: -0.0367, discriminator training loss: 0.1150, validation loss: 0.0292
2024-05-22 22:07:08 [INFO]: Epoch 024 - generator training loss: -0.0353, discriminator training loss: 0.1149, validation loss: 0.0285
2024-05-22 22:07:16 [INFO]: Epoch 025 - generator training loss: -0.0348, discriminator training loss: 0.1143, validation loss: 0.0293
2024-05-22 22:07:23 [INFO]: Epoch 026 - generator training loss: -0.0364, discriminator training loss: 0.1151, validation loss: 0.0275
2024-05-22 22:07:30 [INFO]: Epoch 027 - generator training loss: -0.0374, discriminator training loss: 0.1143, validation loss: 0.0275
2024-05-22 22:07:37 [INFO]: Epoch 028 - generator training loss: -0.0368, discriminator training loss: 0.1154, validation loss: 0.0269
2024-05-22 22:07:44 [INFO]: Epoch 029 - generator training loss: -0.0358, discriminator training loss: 0.1123, validation loss: 0.0274
2024-05-22 22:07:51 [INFO]: Epoch 030 - generator training loss: -0.0377, discriminator training loss: 0.1118, validation loss: 0.0272
2024-05-22 22:07:59 [INFO]: Epoch 031 - generator training loss: -0.0381, discriminator training loss: 0.1129, validation loss: 0.0260
2024-05-22 22:08:06 [INFO]: Epoch 032 - generator training loss: -0.0380, discriminator training loss: 0.1122, validation loss: 0.0258
2024-05-22 22:08:13 [INFO]: Epoch 033 - generator training loss: -0.0387, discriminator training loss: 0.1123, validation loss: 0.0253
2024-05-22 22:08:20 [INFO]: Epoch 034 - generator training loss: -0.0387, discriminator training loss: 0.1132, validation loss: 0.0254
2024-05-22 22:08:27 [INFO]: Epoch 035 - generator training loss: -0.0401, discriminator training loss: 0.1101, validation loss: 0.0252
2024-05-22 22:08:35 [INFO]: Epoch 036 - generator training loss: -0.0416, discriminator training loss: 0.1108, validation loss: 0.0245
2024-05-22 22:08:42 [INFO]: Epoch 037 - generator training loss: -0.0414, discriminator training loss: 0.1135, validation loss: 0.0247
2024-05-22 22:08:49 [INFO]: Epoch 038 - generator training loss: -0.0404, discriminator training loss: 0.1122, validation loss: 0.0247
2024-05-22 22:08:56 [INFO]: Epoch 039 - generator training loss: -0.0423, discriminator training loss: 0.1108, validation loss: 0.0243
2024-05-22 22:09:03 [INFO]: Epoch 040 - generator training loss: -0.0402, discriminator training loss: 0.1100, validation loss: 0.0240
2024-05-22 22:09:11 [INFO]: Epoch 041 - generator training loss: -0.0411, discriminator training loss: 0.1084, validation loss: 0.0242
2024-05-22 22:09:18 [INFO]: Epoch 042 - generator training loss: -0.0434, discriminator training loss: 0.1094, validation loss: 0.0236
2024-05-22 22:09:25 [INFO]: Epoch 043 - generator training loss: -0.0399, discriminator training loss: 0.1112, validation loss: 0.0238
2024-05-22 22:09:33 [INFO]: Epoch 044 - generator training loss: -0.0396, discriminator training loss: 0.1102, validation loss: 0.0240
2024-05-22 22:09:40 [INFO]: Epoch 045 - generator training loss: -0.0414, discriminator training loss: 0.1126, validation loss: 0.0233
2024-05-22 22:09:47 [INFO]: Epoch 046 - generator training loss: -0.0438, discriminator training loss: 0.1113, validation loss: 0.0237
2024-05-22 22:09:54 [INFO]: Epoch 047 - generator training loss: -0.0429, discriminator training loss: 0.1082, validation loss: 0.0236
2024-05-22 22:10:01 [INFO]: Epoch 048 - generator training loss: -0.0418, discriminator training loss: 0.1107, validation loss: 0.0237
2024-05-22 22:10:09 [INFO]: Epoch 049 - generator training loss: -0.0413, discriminator training loss: 0.1076, validation loss: 0.0236
2024-05-22 22:10:16 [INFO]: Epoch 050 - generator training loss: -0.0419, discriminator training loss: 0.1104, validation loss: 0.0233
2024-05-22 22:10:23 [INFO]: Epoch 051 - generator training loss: -0.0405, discriminator training loss: 0.1112, validation loss: 0.0234
2024-05-22 22:10:30 [INFO]: Epoch 052 - generator training loss: -0.0427, discriminator training loss: 0.1084, validation loss: 0.0231
2024-05-22 22:10:37 [INFO]: Epoch 053 - generator training loss: -0.0422, discriminator training loss: 0.1087, validation loss: 0.0233
2024-05-22 22:10:45 [INFO]: Epoch 054 - generator training loss: -0.0413, discriminator training loss: 0.1081, validation loss: 0.0230
2024-05-22 22:10:52 [INFO]: Epoch 055 - generator training loss: -0.0434, discriminator training loss: 0.1123, validation loss: 0.0238
2024-05-22 22:10:59 [INFO]: Epoch 056 - generator training loss: -0.0416, discriminator training loss: 0.1104, validation loss: 0.0234
2024-05-22 22:11:06 [INFO]: Epoch 057 - generator training loss: -0.0443, discriminator training loss: 0.1092, validation loss: 0.0232
2024-05-22 22:11:13 [INFO]: Epoch 058 - generator training loss: -0.0455, discriminator training loss: 0.1088, validation loss: 0.0232
2024-05-22 22:11:21 [INFO]: Epoch 059 - generator training loss: -0.0431, discriminator training loss: 0.1089, validation loss: 0.0228
2024-05-22 22:11:28 [INFO]: Epoch 060 - generator training loss: -0.0398, discriminator training loss: 0.1086, validation loss: 0.0228
2024-05-22 22:11:35 [INFO]: Epoch 061 - generator training loss: -0.0420, discriminator training loss: 0.1097, validation loss: 0.0229
2024-05-22 22:11:42 [INFO]: Epoch 062 - generator training loss: -0.0415, discriminator training loss: 0.1081, validation loss: 0.0228
2024-05-22 22:11:49 [INFO]: Epoch 063 - generator training loss: -0.0427, discriminator training loss: 0.1097, validation loss: 0.0228
2024-05-22 22:11:57 [INFO]: Epoch 064 - generator training loss: -0.0419, discriminator training loss: 0.1090, validation loss: 0.0237
2024-05-22 22:12:04 [INFO]: Epoch 065 - generator training loss: -0.0417, discriminator training loss: 0.1089, validation loss: 0.0227
2024-05-22 22:12:11 [INFO]: Epoch 066 - generator training loss: -0.0428, discriminator training loss: 0.1093, validation loss: 0.0228
2024-05-22 22:12:19 [INFO]: Epoch 067 - generator training loss: -0.0400, discriminator training loss: 0.1086, validation loss: 0.0223
2024-05-22 22:12:26 [INFO]: Epoch 068 - generator training loss: -0.0440, discriminator training loss: 0.1065, validation loss: 0.0223
2024-05-22 22:12:33 [INFO]: Epoch 069 - generator training loss: -0.0464, discriminator training loss: 0.1077, validation loss: 0.0230
2024-05-22 22:12:40 [INFO]: Epoch 070 - generator training loss: -0.0418, discriminator training loss: 0.1095, validation loss: 0.0224
2024-05-22 22:12:47 [INFO]: Epoch 071 - generator training loss: -0.0438, discriminator training loss: 0.1088, validation loss: 0.0220
2024-05-22 22:12:54 [INFO]: Epoch 072 - generator training loss: -0.0425, discriminator training loss: 0.1094, validation loss: 0.0224
2024-05-22 22:13:02 [INFO]: Epoch 073 - generator training loss: -0.0411, discriminator training loss: 0.1088, validation loss: 0.0229
2024-05-22 22:13:09 [INFO]: Epoch 074 - generator training loss: -0.0417, discriminator training loss: 0.1084, validation loss: 0.0221
2024-05-22 22:13:16 [INFO]: Epoch 075 - generator training loss: -0.0449, discriminator training loss: 0.1081, validation loss: 0.0219
2024-05-22 22:13:23 [INFO]: Epoch 076 - generator training loss: -0.0459, discriminator training loss: 0.1074, validation loss: 0.0219
2024-05-22 22:13:31 [INFO]: Epoch 077 - generator training loss: -0.0425, discriminator training loss: 0.1076, validation loss: 0.0217
2024-05-22 22:13:38 [INFO]: Epoch 078 - generator training loss: -0.0432, discriminator training loss: 0.1090, validation loss: 0.0221
2024-05-22 22:13:45 [INFO]: Epoch 079 - generator training loss: -0.0445, discriminator training loss: 0.1091, validation loss: 0.0217
2024-05-22 22:13:52 [INFO]: Epoch 080 - generator training loss: -0.0444, discriminator training loss: 0.1090, validation loss: 0.0216
2024-05-22 22:14:00 [INFO]: Epoch 081 - generator training loss: -0.0435, discriminator training loss: 0.1062, validation loss: 0.0210
2024-05-22 22:14:07 [INFO]: Epoch 082 - generator training loss: -0.0454, discriminator training loss: 0.1074, validation loss: 0.0209
2024-05-22 22:14:14 [INFO]: Epoch 083 - generator training loss: -0.0443, discriminator training loss: 0.1083, validation loss: 0.0211
2024-05-22 22:14:21 [INFO]: Epoch 084 - generator training loss: -0.0425, discriminator training loss: 0.1050, validation loss: 0.0210
2024-05-22 22:14:29 [INFO]: Epoch 085 - generator training loss: -0.0482, discriminator training loss: 0.1066, validation loss: 0.0212
2024-05-22 22:14:36 [INFO]: Epoch 086 - generator training loss: -0.0433, discriminator training loss: 0.1061, validation loss: 0.0209
2024-05-22 22:14:43 [INFO]: Epoch 087 - generator training loss: -0.0436, discriminator training loss: 0.1077, validation loss: 0.0209
2024-05-22 22:14:50 [INFO]: Epoch 088 - generator training loss: -0.0437, discriminator training loss: 0.1064, validation loss: 0.0208
2024-05-22 22:14:58 [INFO]: Epoch 089 - generator training loss: -0.0472, discriminator training loss: 0.1076, validation loss: 0.0204
2024-05-22 22:15:05 [INFO]: Epoch 090 - generator training loss: -0.0471, discriminator training loss: 0.1085, validation loss: 0.0207
2024-05-22 22:15:12 [INFO]: Epoch 091 - generator training loss: -0.0445, discriminator training loss: 0.1064, validation loss: 0.0202
2024-05-22 22:15:19 [INFO]: Epoch 092 - generator training loss: -0.0451, discriminator training loss: 0.1033, validation loss: 0.0205
2024-05-22 22:15:26 [INFO]: Epoch 093 - generator training loss: -0.0451, discriminator training loss: 0.1053, validation loss: 0.0226
2024-05-22 22:15:33 [INFO]: Epoch 094 - generator training loss: -0.0400, discriminator training loss: 0.1062, validation loss: 0.0222
2024-05-22 22:15:40 [INFO]: Epoch 095 - generator training loss: -0.0430, discriminator training loss: 0.1060, validation loss: 0.0209
2024-05-22 22:15:48 [INFO]: Epoch 096 - generator training loss: -0.0443, discriminator training loss: 0.1065, validation loss: 0.0220
2024-05-22 22:15:55 [INFO]: Epoch 097 - generator training loss: -0.0444, discriminator training loss: 0.1058, validation loss: 0.0201
2024-05-22 22:16:02 [INFO]: Epoch 098 - generator training loss: -0.0477, discriminator training loss: 0.1060, validation loss: 0.0206
2024-05-22 22:16:09 [INFO]: Epoch 099 - generator training loss: -0.0457, discriminator training loss: 0.1049, validation loss: 0.0202
2024-05-22 22:16:16 [INFO]: Epoch 100 - generator training loss: -0.0451, discriminator training loss: 0.1078, validation loss: 0.0199
2024-05-22 22:16:23 [INFO]: Epoch 101 - generator training loss: -0.0483, discriminator training loss: 0.1053, validation loss: 0.0195
2024-05-22 22:16:31 [INFO]: Epoch 102 - generator training loss: -0.0490, discriminator training loss: 0.1072, validation loss: 0.0195
2024-05-22 22:16:38 [INFO]: Epoch 103 - generator training loss: -0.0452, discriminator training loss: 0.1034, validation loss: 0.0198
2024-05-22 22:16:45 [INFO]: Epoch 104 - generator training loss: -0.0480, discriminator training loss: 0.1068, validation loss: 0.0190
2024-05-22 22:16:53 [INFO]: Epoch 105 - generator training loss: -0.0461, discriminator training loss: 0.1097, validation loss: 0.0192
2024-05-22 22:17:00 [INFO]: Epoch 106 - generator training loss: -0.0504, discriminator training loss: 0.1067, validation loss: 0.0187
2024-05-22 22:17:08 [INFO]: Epoch 107 - generator training loss: -0.0484, discriminator training loss: 0.1075, validation loss: 0.0198
2024-05-22 22:17:15 [INFO]: Epoch 108 - generator training loss: -0.0457, discriminator training loss: 0.1042, validation loss: 0.0186
2024-05-22 22:17:22 [INFO]: Epoch 109 - generator training loss: -0.0483, discriminator training loss: 0.1045, validation loss: 0.0189
2024-05-22 22:17:30 [INFO]: Epoch 110 - generator training loss: -0.0456, discriminator training loss: 0.1050, validation loss: 0.0188
2024-05-22 22:17:37 [INFO]: Epoch 111 - generator training loss: -0.0523, discriminator training loss: 0.1068, validation loss: 0.0185
2024-05-22 22:17:44 [INFO]: Epoch 112 - generator training loss: -0.0477, discriminator training loss: 0.1036, validation loss: 0.0188
2024-05-22 22:17:51 [INFO]: Epoch 113 - generator training loss: -0.0474, discriminator training loss: 0.1054, validation loss: 0.0184
2024-05-22 22:17:58 [INFO]: Epoch 114 - generator training loss: -0.0511, discriminator training loss: 0.1046, validation loss: 0.0187
2024-05-22 22:18:05 [INFO]: Epoch 115 - generator training loss: -0.0441, discriminator training loss: 0.1038, validation loss: 0.0189
2024-05-22 22:18:12 [INFO]: Epoch 116 - generator training loss: -0.0506, discriminator training loss: 0.1060, validation loss: 0.0205
2024-05-22 22:18:20 [INFO]: Epoch 117 - generator training loss: -0.0466, discriminator training loss: 0.1031, validation loss: 0.0191
2024-05-22 22:18:27 [INFO]: Epoch 118 - generator training loss: -0.0473, discriminator training loss: 0.1038, validation loss: 0.0188
2024-05-22 22:18:34 [INFO]: Epoch 119 - generator training loss: -0.0473, discriminator training loss: 0.1047, validation loss: 0.0187
2024-05-22 22:18:41 [INFO]: Epoch 120 - generator training loss: -0.0470, discriminator training loss: 0.1060, validation loss: 0.0184
2024-05-22 22:18:48 [INFO]: Epoch 121 - generator training loss: -0.0460, discriminator training loss: 0.1019, validation loss: 0.0183
2024-05-22 22:18:55 [INFO]: Epoch 122 - generator training loss: -0.0487, discriminator training loss: 0.1056, validation loss: 0.0183
2024-05-22 22:19:02 [INFO]: Epoch 123 - generator training loss: -0.0483, discriminator training loss: 0.1073, validation loss: 0.0183
2024-05-22 22:19:10 [INFO]: Epoch 124 - generator training loss: -0.0472, discriminator training loss: 0.1040, validation loss: 0.0179
2024-05-22 22:19:17 [INFO]: Epoch 125 - generator training loss: -0.0492, discriminator training loss: 0.1061, validation loss: 0.0191
2024-05-22 22:19:24 [INFO]: Epoch 126 - generator training loss: -0.0490, discriminator training loss: 0.1053, validation loss: 0.0180
2024-05-22 22:19:31 [INFO]: Epoch 127 - generator training loss: -0.0516, discriminator training loss: 0.1044, validation loss: 0.0184
2024-05-22 22:19:38 [INFO]: Epoch 128 - generator training loss: -0.0472, discriminator training loss: 0.1051, validation loss: 0.0186
2024-05-22 22:19:46 [INFO]: Epoch 129 - generator training loss: -0.0482, discriminator training loss: 0.1044, validation loss: 0.0180
2024-05-22 22:19:53 [INFO]: Epoch 130 - generator training loss: -0.0483, discriminator training loss: 0.1045, validation loss: 0.0181
2024-05-22 22:20:00 [INFO]: Epoch 131 - generator training loss: -0.0474, discriminator training loss: 0.1044, validation loss: 0.0178
2024-05-22 22:20:07 [INFO]: Epoch 132 - generator training loss: -0.0509, discriminator training loss: 0.1042, validation loss: 0.0180
2024-05-22 22:20:14 [INFO]: Epoch 133 - generator training loss: -0.0491, discriminator training loss: 0.1029, validation loss: 0.0178
2024-05-22 22:20:22 [INFO]: Epoch 134 - generator training loss: -0.0501, discriminator training loss: 0.1035, validation loss: 0.0189
2024-05-22 22:20:29 [INFO]: Epoch 135 - generator training loss: -0.0465, discriminator training loss: 0.1032, validation loss: 0.0179
2024-05-22 22:20:36 [INFO]: Epoch 136 - generator training loss: -0.0507, discriminator training loss: 0.1044, validation loss: 0.0179
2024-05-22 22:20:43 [INFO]: Epoch 137 - generator training loss: -0.0480, discriminator training loss: 0.1043, validation loss: 0.0203
2024-05-22 22:20:50 [INFO]: Epoch 138 - generator training loss: -0.0507, discriminator training loss: 0.1033, validation loss: 0.0175
2024-05-22 22:20:57 [INFO]: Epoch 139 - generator training loss: -0.0486, discriminator training loss: 0.1035, validation loss: 0.0184
2024-05-22 22:21:04 [INFO]: Epoch 140 - generator training loss: -0.0489, discriminator training loss: 0.1041, validation loss: 0.0184
2024-05-22 22:21:12 [INFO]: Epoch 141 - generator training loss: -0.0495, discriminator training loss: 0.1059, validation loss: 0.0179
2024-05-22 22:21:19 [INFO]: Epoch 142 - generator training loss: -0.0480, discriminator training loss: 0.1026, validation loss: 0.0186
2024-05-22 22:21:26 [INFO]: Epoch 143 - generator training loss: -0.0506, discriminator training loss: 0.1046, validation loss: 0.0180
2024-05-22 22:21:33 [INFO]: Epoch 144 - generator training loss: -0.0495, discriminator training loss: 0.1046, validation loss: 0.0182
2024-05-22 22:21:40 [INFO]: Epoch 145 - generator training loss: -0.0503, discriminator training loss: 0.1037, validation loss: 0.0179
2024-05-22 22:21:47 [INFO]: Epoch 146 - generator training loss: -0.0499, discriminator training loss: 0.1038, validation loss: 0.0177
2024-05-22 22:21:55 [INFO]: Epoch 147 - generator training loss: -0.0509, discriminator training loss: 0.1028, validation loss: 0.0177
2024-05-22 22:22:02 [INFO]: Epoch 148 - generator training loss: -0.0491, discriminator training loss: 0.1033, validation loss: 0.0179
2024-05-22 22:22:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:22:02 [INFO]: Finished training. The best model is from epoch#138.
2024-05-22 22:22:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_ettm1/20240522_T220414/USGAN.pypots
2024-05-22 22:22:03 [INFO]: US-GAN on ETTm1: MAE=0.1356, MSE=0.0486
2024-05-22 22:22:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-22 22:22:03 [INFO]: Using the given device: cuda:0
2024-05-22 22:22:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240522_T222203
2024-05-22 22:22:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_ettm1/20240522_T222203/tensorboard
2024-05-22 22:22:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 22:22:08 [INFO]: Epoch 001 - training loss: 1.3310, validation loss: 0.3413
2024-05-22 22:22:13 [INFO]: Epoch 002 - training loss: 0.8946, validation loss: 0.0949
2024-05-22 22:22:18 [INFO]: Epoch 003 - training loss: 0.7256, validation loss: 0.0507
2024-05-22 22:22:23 [INFO]: Epoch 004 - training loss: 0.6522, validation loss: 0.0418
2024-05-22 22:22:27 [INFO]: Epoch 005 - training loss: 0.6106, validation loss: 0.0384
2024-05-22 22:22:32 [INFO]: Epoch 006 - training loss: 0.5744, validation loss: 0.0339
2024-05-22 22:22:37 [INFO]: Epoch 007 - training loss: 0.5453, validation loss: 0.0333
2024-05-22 22:22:41 [INFO]: Epoch 008 - training loss: 0.5370, validation loss: 0.0325
2024-05-22 22:22:46 [INFO]: Epoch 009 - training loss: 0.5124, validation loss: 0.0334
2024-05-22 22:22:51 [INFO]: Epoch 010 - training loss: 0.4850, validation loss: 0.0321
2024-05-22 22:22:56 [INFO]: Epoch 011 - training loss: 0.4696, validation loss: 0.0302
2024-05-22 22:23:00 [INFO]: Epoch 012 - training loss: 0.4494, validation loss: 0.0301
2024-05-22 22:23:05 [INFO]: Epoch 013 - training loss: 0.4374, validation loss: 0.0292
2024-05-22 22:23:10 [INFO]: Epoch 014 - training loss: 0.4241, validation loss: 0.0291
2024-05-22 22:23:15 [INFO]: Epoch 015 - training loss: 0.4112, validation loss: 0.0274
2024-05-22 22:23:19 [INFO]: Epoch 016 - training loss: 0.4106, validation loss: 0.0250
2024-05-22 22:23:24 [INFO]: Epoch 017 - training loss: 0.3981, validation loss: 0.0247
2024-05-22 22:23:29 [INFO]: Epoch 018 - training loss: 0.3948, validation loss: 0.0234
2024-05-22 22:23:34 [INFO]: Epoch 019 - training loss: 0.3885, validation loss: 0.0228
2024-05-22 22:23:38 [INFO]: Epoch 020 - training loss: 0.3872, validation loss: 0.0220
2024-05-22 22:23:43 [INFO]: Epoch 021 - training loss: 0.3806, validation loss: 0.0226
2024-05-22 22:23:48 [INFO]: Epoch 022 - training loss: 0.3842, validation loss: 0.0225
2024-05-22 22:23:53 [INFO]: Epoch 023 - training loss: 0.3986, validation loss: 0.0222
2024-05-22 22:23:57 [INFO]: Epoch 024 - training loss: 0.3863, validation loss: 0.0225
2024-05-22 22:24:02 [INFO]: Epoch 025 - training loss: 0.3852, validation loss: 0.0225
2024-05-22 22:24:07 [INFO]: Epoch 026 - training loss: 0.3867, validation loss: 0.0225
2024-05-22 22:24:11 [INFO]: Epoch 027 - training loss: 0.3918, validation loss: 0.0223
2024-05-22 22:24:16 [INFO]: Epoch 028 - training loss: 0.3995, validation loss: 0.0227
2024-05-22 22:24:21 [INFO]: Epoch 029 - training loss: 0.3930, validation loss: 0.0226
2024-05-22 22:24:26 [INFO]: Epoch 030 - training loss: 0.3902, validation loss: 0.0220
2024-05-22 22:24:30 [INFO]: Epoch 031 - training loss: 0.3855, validation loss: 0.0221
2024-05-22 22:24:35 [INFO]: Epoch 032 - training loss: 0.3833, validation loss: 0.0218
2024-05-22 22:24:40 [INFO]: Epoch 033 - training loss: 0.3935, validation loss: 0.0229
2024-05-22 22:24:44 [INFO]: Epoch 034 - training loss: 0.3979, validation loss: 0.0226
2024-05-22 22:24:49 [INFO]: Epoch 035 - training loss: 0.3916, validation loss: 0.0229
2024-05-22 22:24:54 [INFO]: Epoch 036 - training loss: 0.3829, validation loss: 0.0225
2024-05-22 22:24:59 [INFO]: Epoch 037 - training loss: 0.3800, validation loss: 0.0221
2024-05-22 22:25:03 [INFO]: Epoch 038 - training loss: 0.3829, validation loss: 0.0220
2024-05-22 22:25:08 [INFO]: Epoch 039 - training loss: 0.3749, validation loss: 0.0219
2024-05-22 22:25:13 [INFO]: Epoch 040 - training loss: 0.3755, validation loss: 0.0224
2024-05-22 22:25:18 [INFO]: Epoch 041 - training loss: 0.3848, validation loss: 0.0223
2024-05-22 22:25:22 [INFO]: Epoch 042 - training loss: 0.3799, validation loss: 0.0220
2024-05-22 22:25:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:25:22 [INFO]: Finished training. The best model is from epoch#32.
2024-05-22 22:25:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_ettm1/20240522_T222203/BRITS.pypots
2024-05-22 22:25:23 [INFO]: BRITS on ETTm1: MAE=0.1222, MSE=0.0430
2024-05-22 22:25:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-22 22:25:23 [INFO]: Using the given device: cuda:0
2024-05-22 22:25:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523
2024-05-22 22:25:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/tensorboard
2024-05-22 22:25:23 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 22:25:24 [INFO]: Epoch 001 - training loss: 1.4150, validation loss: 1.2447
2024-05-22 22:25:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch1_loss1.2447255998849869.pypots
2024-05-22 22:25:24 [INFO]: Epoch 002 - training loss: 1.0661, validation loss: 1.1181
2024-05-22 22:25:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch2_loss1.11811763048172.pypots
2024-05-22 22:25:25 [INFO]: Epoch 003 - training loss: 0.9702, validation loss: 1.0591
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch3_loss1.059119462966919.pypots
2024-05-22 22:25:25 [INFO]: Epoch 004 - training loss: 0.9302, validation loss: 1.0391
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch4_loss1.0391155928373337.pypots
2024-05-22 22:25:25 [INFO]: Epoch 005 - training loss: 0.9308, validation loss: 1.0323
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch5_loss1.0323436558246613.pypots
2024-05-22 22:25:25 [INFO]: Epoch 006 - training loss: 0.9422, validation loss: 1.0247
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch6_loss1.0247096568346024.pypots
2024-05-22 22:25:25 [INFO]: Epoch 007 - training loss: 0.9150, validation loss: 1.0248
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch7_loss1.0248083770275116.pypots
2024-05-22 22:25:25 [INFO]: Epoch 008 - training loss: 0.9052, validation loss: 1.0201
2024-05-22 22:25:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch8_loss1.0200521647930145.pypots
2024-05-22 22:25:26 [INFO]: Epoch 009 - training loss: 0.9550, validation loss: 1.0183
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch9_loss1.0182860642671585.pypots
2024-05-22 22:25:26 [INFO]: Epoch 010 - training loss: 0.8965, validation loss: 1.0125
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch10_loss1.012479841709137.pypots
2024-05-22 22:25:26 [INFO]: Epoch 011 - training loss: 0.8729, validation loss: 1.0086
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch11_loss1.0085748583078384.pypots
2024-05-22 22:25:26 [INFO]: Epoch 012 - training loss: 0.8816, validation loss: 1.0095
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch12_loss1.0095000863075256.pypots
2024-05-22 22:25:26 [INFO]: Epoch 013 - training loss: 0.8865, validation loss: 1.0048
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch13_loss1.0048100352287292.pypots
2024-05-22 22:25:26 [INFO]: Epoch 014 - training loss: 0.8818, validation loss: 1.0029
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch14_loss1.0029265880584717.pypots
2024-05-22 22:25:26 [INFO]: Epoch 015 - training loss: 0.8726, validation loss: 0.9975
2024-05-22 22:25:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch15_loss0.9975181072950363.pypots
2024-05-22 22:25:27 [INFO]: Epoch 016 - training loss: 0.8603, validation loss: 0.9903
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch16_loss0.9903082251548767.pypots
2024-05-22 22:25:27 [INFO]: Epoch 017 - training loss: 0.8638, validation loss: 0.9925
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch17_loss0.9924991875886917.pypots
2024-05-22 22:25:27 [INFO]: Epoch 018 - training loss: 0.8717, validation loss: 0.9922
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch18_loss0.992231696844101.pypots
2024-05-22 22:25:27 [INFO]: Epoch 019 - training loss: 0.8564, validation loss: 0.9897
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch19_loss0.9896947741508484.pypots
2024-05-22 22:25:27 [INFO]: Epoch 020 - training loss: 0.8934, validation loss: 0.9840
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch20_loss0.9839777052402496.pypots
2024-05-22 22:25:27 [INFO]: Epoch 021 - training loss: 0.9149, validation loss: 0.9829
2024-05-22 22:25:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch21_loss0.9829301834106445.pypots
2024-05-22 22:25:28 [INFO]: Epoch 022 - training loss: 0.8482, validation loss: 0.9863
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch22_loss0.9862794876098633.pypots
2024-05-22 22:25:28 [INFO]: Epoch 023 - training loss: 0.8439, validation loss: 0.9824
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch23_loss0.9823997616767883.pypots
2024-05-22 22:25:28 [INFO]: Epoch 024 - training loss: 0.8561, validation loss: 0.9794
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch24_loss0.9794103801250458.pypots
2024-05-22 22:25:28 [INFO]: Epoch 025 - training loss: 0.8412, validation loss: 0.9758
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch25_loss0.9757779538631439.pypots
2024-05-22 22:25:28 [INFO]: Epoch 026 - training loss: 0.8191, validation loss: 0.9730
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch26_loss0.973003551363945.pypots
2024-05-22 22:25:28 [INFO]: Epoch 027 - training loss: 0.8316, validation loss: 0.9706
2024-05-22 22:25:28 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch27_loss0.9706163555383682.pypots
2024-05-22 22:25:29 [INFO]: Epoch 028 - training loss: 0.8233, validation loss: 0.9686
2024-05-22 22:25:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch28_loss0.9685512334108353.pypots
2024-05-22 22:25:29 [INFO]: Epoch 029 - training loss: 0.8329, validation loss: 0.9633
2024-05-22 22:25:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch29_loss0.9633333534002304.pypots
2024-05-22 22:25:29 [INFO]: Epoch 030 - training loss: 0.8165, validation loss: 0.9611
2024-05-22 22:25:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch30_loss0.9611015021800995.pypots
2024-05-22 22:25:29 [INFO]: Epoch 031 - training loss: 0.8046, validation loss: 0.9602
2024-05-22 22:25:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch31_loss0.960170328617096.pypots
2024-05-22 22:25:29 [INFO]: Epoch 032 - training loss: 0.8155, validation loss: 0.9553
2024-05-22 22:25:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch32_loss0.9552527517080307.pypots
2024-05-22 22:25:30 [INFO]: Epoch 033 - training loss: 0.7972, validation loss: 0.9503
2024-05-22 22:25:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch33_loss0.9503340274095535.pypots
2024-05-22 22:25:30 [INFO]: Epoch 034 - training loss: 0.7993, validation loss: 0.9480
2024-05-22 22:25:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch34_loss0.9480275064706802.pypots
2024-05-22 22:25:31 [INFO]: Epoch 035 - training loss: 0.8060, validation loss: 0.9437
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch35_loss0.9437394738197327.pypots
2024-05-22 22:25:31 [INFO]: Epoch 036 - training loss: 0.8116, validation loss: 0.9403
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch36_loss0.9402820765972137.pypots
2024-05-22 22:25:31 [INFO]: Epoch 037 - training loss: 0.8192, validation loss: 0.9357
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch37_loss0.9357351511716843.pypots
2024-05-22 22:25:31 [INFO]: Epoch 038 - training loss: 0.8116, validation loss: 0.9313
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch38_loss0.931267186999321.pypots
2024-05-22 22:25:31 [INFO]: Epoch 039 - training loss: 0.8043, validation loss: 0.9291
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch39_loss0.9290786385536194.pypots
2024-05-22 22:25:31 [INFO]: Epoch 040 - training loss: 0.8225, validation loss: 0.9244
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch40_loss0.9244480282068253.pypots
2024-05-22 22:25:31 [INFO]: Epoch 041 - training loss: 0.8186, validation loss: 0.9220
2024-05-22 22:25:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch41_loss0.9219647794961929.pypots
2024-05-22 22:25:32 [INFO]: Epoch 042 - training loss: 0.8053, validation loss: 0.9171
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch42_loss0.9170542061328888.pypots
2024-05-22 22:25:32 [INFO]: Epoch 043 - training loss: 0.8148, validation loss: 0.9133
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch43_loss0.9133230447769165.pypots
2024-05-22 22:25:32 [INFO]: Epoch 044 - training loss: 0.7956, validation loss: 0.9097
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch44_loss0.9097249358892441.pypots
2024-05-22 22:25:32 [INFO]: Epoch 045 - training loss: 0.7848, validation loss: 0.9081
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch45_loss0.9081435203552246.pypots
2024-05-22 22:25:32 [INFO]: Epoch 046 - training loss: 0.7917, validation loss: 0.9039
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch46_loss0.9039242565631866.pypots
2024-05-22 22:25:32 [INFO]: Epoch 047 - training loss: 0.8071, validation loss: 0.9002
2024-05-22 22:25:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch47_loss0.900163397192955.pypots
2024-05-22 22:25:33 [INFO]: Epoch 048 - training loss: 0.7786, validation loss: 0.9004
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch48_loss0.9003962576389313.pypots
2024-05-22 22:25:33 [INFO]: Epoch 049 - training loss: 0.8145, validation loss: 0.8953
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch49_loss0.8953151106834412.pypots
2024-05-22 22:25:33 [INFO]: Epoch 050 - training loss: 0.7854, validation loss: 0.8931
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch50_loss0.893088087439537.pypots
2024-05-22 22:25:33 [INFO]: Epoch 051 - training loss: 0.7985, validation loss: 0.8921
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch51_loss0.8921215683221817.pypots
2024-05-22 22:25:33 [INFO]: Epoch 052 - training loss: 0.8009, validation loss: 0.8893
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch52_loss0.8893239498138428.pypots
2024-05-22 22:25:33 [INFO]: Epoch 053 - training loss: 0.7731, validation loss: 0.8880
2024-05-22 22:25:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch53_loss0.8880065530538559.pypots
2024-05-22 22:25:34 [INFO]: Epoch 054 - training loss: 0.7885, validation loss: 0.8864
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch54_loss0.8863728642463684.pypots
2024-05-22 22:25:34 [INFO]: Epoch 055 - training loss: 0.7862, validation loss: 0.8847
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch55_loss0.8846939504146576.pypots
2024-05-22 22:25:34 [INFO]: Epoch 056 - training loss: 0.8431, validation loss: 0.8828
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch56_loss0.8827605098485947.pypots
2024-05-22 22:25:34 [INFO]: Epoch 057 - training loss: 0.7875, validation loss: 0.8816
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch57_loss0.8815510272979736.pypots
2024-05-22 22:25:34 [INFO]: Epoch 058 - training loss: 0.7795, validation loss: 0.8801
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch58_loss0.8800714462995529.pypots
2024-05-22 22:25:34 [INFO]: Epoch 059 - training loss: 0.7776, validation loss: 0.8783
2024-05-22 22:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch59_loss0.8783425539731979.pypots
2024-05-22 22:25:35 [INFO]: Epoch 060 - training loss: 0.7895, validation loss: 0.8777
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch60_loss0.8776731789112091.pypots
2024-05-22 22:25:35 [INFO]: Epoch 061 - training loss: 0.7729, validation loss: 0.8761
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch61_loss0.8761093616485596.pypots
2024-05-22 22:25:35 [INFO]: Epoch 062 - training loss: 0.7885, validation loss: 0.8768
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch62_loss0.8767541199922562.pypots
2024-05-22 22:25:35 [INFO]: Epoch 063 - training loss: 0.7527, validation loss: 0.8735
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch63_loss0.8734948337078094.pypots
2024-05-22 22:25:35 [INFO]: Epoch 064 - training loss: 0.7730, validation loss: 0.8733
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch64_loss0.8733350187540054.pypots
2024-05-22 22:25:35 [INFO]: Epoch 065 - training loss: 0.7910, validation loss: 0.8717
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch65_loss0.8717231750488281.pypots
2024-05-22 22:25:35 [INFO]: Epoch 066 - training loss: 0.7879, validation loss: 0.8718
2024-05-22 22:25:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch66_loss0.8718238919973373.pypots
2024-05-22 22:25:36 [INFO]: Epoch 067 - training loss: 0.7864, validation loss: 0.8690
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch67_loss0.868965670466423.pypots
2024-05-22 22:25:36 [INFO]: Epoch 068 - training loss: 0.7905, validation loss: 0.8683
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch68_loss0.8683046102523804.pypots
2024-05-22 22:25:36 [INFO]: Epoch 069 - training loss: 0.8250, validation loss: 0.8691
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch69_loss0.8691077679395676.pypots
2024-05-22 22:25:36 [INFO]: Epoch 070 - training loss: 0.7793, validation loss: 0.8711
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch70_loss0.8710936307907104.pypots
2024-05-22 22:25:36 [INFO]: Epoch 071 - training loss: 0.7876, validation loss: 0.8654
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch71_loss0.8654021918773651.pypots
2024-05-22 22:25:36 [INFO]: Epoch 072 - training loss: 0.7931, validation loss: 0.8673
2024-05-22 22:25:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch72_loss0.8672823756933212.pypots
2024-05-22 22:25:37 [INFO]: Epoch 073 - training loss: 0.7866, validation loss: 0.8650
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch73_loss0.8650420904159546.pypots
2024-05-22 22:25:37 [INFO]: Epoch 074 - training loss: 0.7763, validation loss: 0.8647
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch74_loss0.8646791875362396.pypots
2024-05-22 22:25:37 [INFO]: Epoch 075 - training loss: 0.7656, validation loss: 0.8630
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch75_loss0.8630287647247314.pypots
2024-05-22 22:25:37 [INFO]: Epoch 076 - training loss: 0.7741, validation loss: 0.8639
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch76_loss0.8638883531093597.pypots
2024-05-22 22:25:37 [INFO]: Epoch 077 - training loss: 0.7782, validation loss: 0.8644
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch77_loss0.8643718063831329.pypots
2024-05-22 22:25:37 [INFO]: Epoch 078 - training loss: 0.7748, validation loss: 0.8633
2024-05-22 22:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch78_loss0.8632675260305405.pypots
2024-05-22 22:25:38 [INFO]: Epoch 079 - training loss: 0.7766, validation loss: 0.8622
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch79_loss0.8621986508369446.pypots
2024-05-22 22:25:38 [INFO]: Epoch 080 - training loss: 0.7710, validation loss: 0.8591
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch80_loss0.8590724319219589.pypots
2024-05-22 22:25:38 [INFO]: Epoch 081 - training loss: 0.7527, validation loss: 0.8607
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch81_loss0.8607182204723358.pypots
2024-05-22 22:25:38 [INFO]: Epoch 082 - training loss: 0.7654, validation loss: 0.8608
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch82_loss0.8607939034700394.pypots
2024-05-22 22:25:38 [INFO]: Epoch 083 - training loss: 0.7751, validation loss: 0.8581
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch83_loss0.858086109161377.pypots
2024-05-22 22:25:38 [INFO]: Epoch 084 - training loss: 0.7733, validation loss: 0.8588
2024-05-22 22:25:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch84_loss0.8587590456008911.pypots
2024-05-22 22:25:39 [INFO]: Epoch 085 - training loss: 0.7536, validation loss: 0.8573
2024-05-22 22:25:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch85_loss0.8572739064693451.pypots
2024-05-22 22:25:39 [INFO]: Epoch 086 - training loss: 0.7633, validation loss: 0.8578
2024-05-22 22:25:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch86_loss0.8578011244535446.pypots
2024-05-22 22:25:39 [INFO]: Epoch 087 - training loss: 0.7834, validation loss: 0.8579
2024-05-22 22:25:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch87_loss0.8578840047121048.pypots
2024-05-22 22:25:39 [INFO]: Epoch 088 - training loss: 0.7587, validation loss: 0.8575
2024-05-22 22:25:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch88_loss0.8575395345687866.pypots
2024-05-22 22:25:39 [INFO]: Epoch 089 - training loss: 0.7653, validation loss: 0.8560
2024-05-22 22:25:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch89_loss0.856047660112381.pypots
2024-05-22 22:25:40 [INFO]: Epoch 090 - training loss: 0.7727, validation loss: 0.8541
2024-05-22 22:25:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch90_loss0.8540632575750351.pypots
2024-05-22 22:25:40 [INFO]: Epoch 091 - training loss: 0.7652, validation loss: 0.8530
2024-05-22 22:25:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch91_loss0.8530180901288986.pypots
2024-05-22 22:25:41 [INFO]: Epoch 092 - training loss: 0.8060, validation loss: 0.8513
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch92_loss0.85127854347229.pypots
2024-05-22 22:25:41 [INFO]: Epoch 093 - training loss: 0.7834, validation loss: 0.8533
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch93_loss0.853336438536644.pypots
2024-05-22 22:25:41 [INFO]: Epoch 094 - training loss: 0.7797, validation loss: 0.8520
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch94_loss0.8519929796457291.pypots
2024-05-22 22:25:41 [INFO]: Epoch 095 - training loss: 0.7618, validation loss: 0.8530
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch95_loss0.8530003726482391.pypots
2024-05-22 22:25:41 [INFO]: Epoch 096 - training loss: 0.8164, validation loss: 0.8506
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch96_loss0.8505519330501556.pypots
2024-05-22 22:25:41 [INFO]: Epoch 097 - training loss: 0.7911, validation loss: 0.8503
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch97_loss0.8503491431474686.pypots
2024-05-22 22:25:41 [INFO]: Epoch 098 - training loss: 0.7818, validation loss: 0.8500
2024-05-22 22:25:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch98_loss0.8500313758850098.pypots
2024-05-22 22:25:42 [INFO]: Epoch 099 - training loss: 0.7796, validation loss: 0.8473
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch99_loss0.8472753614187241.pypots
2024-05-22 22:25:42 [INFO]: Epoch 100 - training loss: 0.7687, validation loss: 0.8485
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch100_loss0.8484897464513779.pypots
2024-05-22 22:25:42 [INFO]: Epoch 101 - training loss: 0.7555, validation loss: 0.8498
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch101_loss0.8498408496379852.pypots
2024-05-22 22:25:42 [INFO]: Epoch 102 - training loss: 0.8212, validation loss: 0.8466
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch102_loss0.8466369360685349.pypots
2024-05-22 22:25:42 [INFO]: Epoch 103 - training loss: 0.8180, validation loss: 0.8493
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch103_loss0.8492769002914429.pypots
2024-05-22 22:25:42 [INFO]: Epoch 104 - training loss: 0.7890, validation loss: 0.8449
2024-05-22 22:25:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch104_loss0.8448841571807861.pypots
2024-05-22 22:25:43 [INFO]: Epoch 105 - training loss: 0.7775, validation loss: 0.8435
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch105_loss0.843533918261528.pypots
2024-05-22 22:25:43 [INFO]: Epoch 106 - training loss: 0.7630, validation loss: 0.8456
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch106_loss0.8456191271543503.pypots
2024-05-22 22:25:43 [INFO]: Epoch 107 - training loss: 0.7729, validation loss: 0.8442
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch107_loss0.844219982624054.pypots
2024-05-22 22:25:43 [INFO]: Epoch 108 - training loss: 0.7965, validation loss: 0.8409
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch108_loss0.8408974707126617.pypots
2024-05-22 22:25:43 [INFO]: Epoch 109 - training loss: 0.7755, validation loss: 0.8453
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch109_loss0.8452855050563812.pypots
2024-05-22 22:25:43 [INFO]: Epoch 110 - training loss: 0.7837, validation loss: 0.8438
2024-05-22 22:25:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch110_loss0.8438351154327393.pypots
2024-05-22 22:25:44 [INFO]: Epoch 111 - training loss: 0.7491, validation loss: 0.8422
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch111_loss0.8421768099069595.pypots
2024-05-22 22:25:44 [INFO]: Epoch 112 - training loss: 0.7657, validation loss: 0.8441
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch112_loss0.8441156893968582.pypots
2024-05-22 22:25:44 [INFO]: Epoch 113 - training loss: 0.7713, validation loss: 0.8416
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch113_loss0.8415807783603668.pypots
2024-05-22 22:25:44 [INFO]: Epoch 114 - training loss: 0.7761, validation loss: 0.8432
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch114_loss0.8432040065526962.pypots
2024-05-22 22:25:44 [INFO]: Epoch 115 - training loss: 0.8000, validation loss: 0.8399
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch115_loss0.8398753553628922.pypots
2024-05-22 22:25:44 [INFO]: Epoch 116 - training loss: 0.7526, validation loss: 0.8399
2024-05-22 22:25:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch116_loss0.839859738945961.pypots
2024-05-22 22:25:45 [INFO]: Epoch 117 - training loss: 0.7702, validation loss: 0.8365
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch117_loss0.8364642709493637.pypots
2024-05-22 22:25:45 [INFO]: Epoch 118 - training loss: 0.7692, validation loss: 0.8357
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch118_loss0.8356545567512512.pypots
2024-05-22 22:25:45 [INFO]: Epoch 119 - training loss: 0.7717, validation loss: 0.8376
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch119_loss0.8375657349824905.pypots
2024-05-22 22:25:45 [INFO]: Epoch 120 - training loss: 0.7746, validation loss: 0.8361
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch120_loss0.8361219763755798.pypots
2024-05-22 22:25:45 [INFO]: Epoch 121 - training loss: 0.7954, validation loss: 0.8369
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch121_loss0.8369397073984146.pypots
2024-05-22 22:25:45 [INFO]: Epoch 122 - training loss: 0.7714, validation loss: 0.8364
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch122_loss0.8364357650279999.pypots
2024-05-22 22:25:45 [INFO]: Epoch 123 - training loss: 0.7782, validation loss: 0.8384
2024-05-22 22:25:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch123_loss0.8383773118257523.pypots
2024-05-22 22:25:46 [INFO]: Epoch 124 - training loss: 0.7668, validation loss: 0.8377
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch124_loss0.8377250134944916.pypots
2024-05-22 22:25:46 [INFO]: Epoch 125 - training loss: 0.7578, validation loss: 0.8346
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch125_loss0.8345889896154404.pypots
2024-05-22 22:25:46 [INFO]: Epoch 126 - training loss: 0.7633, validation loss: 0.8374
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch126_loss0.8374000191688538.pypots
2024-05-22 22:25:46 [INFO]: Epoch 127 - training loss: 0.7921, validation loss: 0.8360
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch127_loss0.8360386043787003.pypots
2024-05-22 22:25:46 [INFO]: Epoch 128 - training loss: 0.8181, validation loss: 0.8313
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch128_loss0.831333577632904.pypots
2024-05-22 22:25:46 [INFO]: Epoch 129 - training loss: 0.7522, validation loss: 0.8276
2024-05-22 22:25:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch129_loss0.8275894075632095.pypots
2024-05-22 22:25:47 [INFO]: Epoch 130 - training loss: 0.7632, validation loss: 0.8317
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch130_loss0.8317179977893829.pypots
2024-05-22 22:25:47 [INFO]: Epoch 131 - training loss: 0.7629, validation loss: 0.8351
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch131_loss0.8351391404867172.pypots
2024-05-22 22:25:47 [INFO]: Epoch 132 - training loss: 0.7799, validation loss: 0.8318
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch132_loss0.8317866623401642.pypots
2024-05-22 22:25:47 [INFO]: Epoch 133 - training loss: 0.7612, validation loss: 0.8298
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch133_loss0.8297800570726395.pypots
2024-05-22 22:25:47 [INFO]: Epoch 134 - training loss: 0.7675, validation loss: 0.8299
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch134_loss0.8299493938684464.pypots
2024-05-22 22:25:47 [INFO]: Epoch 135 - training loss: 0.7778, validation loss: 0.8299
2024-05-22 22:25:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch135_loss0.8299272507429123.pypots
2024-05-22 22:25:48 [INFO]: Epoch 136 - training loss: 0.7622, validation loss: 0.8253
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch136_loss0.8252803981304169.pypots
2024-05-22 22:25:48 [INFO]: Epoch 137 - training loss: 0.7542, validation loss: 0.8278
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch137_loss0.827792689204216.pypots
2024-05-22 22:25:48 [INFO]: Epoch 138 - training loss: 0.7553, validation loss: 0.8253
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch138_loss0.8252549022436142.pypots
2024-05-22 22:25:48 [INFO]: Epoch 139 - training loss: 0.7689, validation loss: 0.8280
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch139_loss0.827951967716217.pypots
2024-05-22 22:25:48 [INFO]: Epoch 140 - training loss: 0.7504, validation loss: 0.8253
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch140_loss0.8252611756324768.pypots
2024-05-22 22:25:48 [INFO]: Epoch 141 - training loss: 0.8065, validation loss: 0.8223
2024-05-22 22:25:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch141_loss0.8223012387752533.pypots
2024-05-22 22:25:49 [INFO]: Epoch 142 - training loss: 0.7710, validation loss: 0.8265
2024-05-22 22:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch142_loss0.8264655619859695.pypots
2024-05-22 22:25:49 [INFO]: Epoch 143 - training loss: 0.7648, validation loss: 0.8263
2024-05-22 22:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch143_loss0.8262688219547272.pypots
2024-05-22 22:25:49 [INFO]: Epoch 144 - training loss: 0.7726, validation loss: 0.8235
2024-05-22 22:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch144_loss0.8235385417938232.pypots
2024-05-22 22:25:49 [INFO]: Epoch 145 - training loss: 0.7578, validation loss: 0.8214
2024-05-22 22:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch145_loss0.8213924914598465.pypots
2024-05-22 22:25:49 [INFO]: Epoch 146 - training loss: 0.7785, validation loss: 0.8253
2024-05-22 22:25:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch146_loss0.8253368884325027.pypots
2024-05-22 22:25:49 [INFO]: Epoch 147 - training loss: 0.7372, validation loss: 0.8203
2024-05-22 22:25:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch147_loss0.820348471403122.pypots
2024-05-22 22:25:50 [INFO]: Epoch 148 - training loss: 0.7462, validation loss: 0.8199
2024-05-22 22:25:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch148_loss0.8198947608470917.pypots
2024-05-22 22:25:51 [INFO]: Epoch 149 - training loss: 0.7767, validation loss: 0.8212
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch149_loss0.8212265223264694.pypots
2024-05-22 22:25:51 [INFO]: Epoch 150 - training loss: 0.7609, validation loss: 0.8175
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch150_loss0.8175197392702103.pypots
2024-05-22 22:25:51 [INFO]: Epoch 151 - training loss: 0.7596, validation loss: 0.8207
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch151_loss0.8207468092441559.pypots
2024-05-22 22:25:51 [INFO]: Epoch 152 - training loss: 0.7428, validation loss: 0.8204
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch152_loss0.820352166891098.pypots
2024-05-22 22:25:51 [INFO]: Epoch 153 - training loss: 0.7728, validation loss: 0.8158
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch153_loss0.8157865107059479.pypots
2024-05-22 22:25:51 [INFO]: Epoch 154 - training loss: 0.7787, validation loss: 0.8170
2024-05-22 22:25:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch154_loss0.8169627785682678.pypots
2024-05-22 22:25:52 [INFO]: Epoch 155 - training loss: 0.7569, validation loss: 0.8180
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch155_loss0.8180240243673325.pypots
2024-05-22 22:25:52 [INFO]: Epoch 156 - training loss: 0.7837, validation loss: 0.8188
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch156_loss0.8188333660364151.pypots
2024-05-22 22:25:52 [INFO]: Epoch 157 - training loss: 0.7836, validation loss: 0.8154
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch157_loss0.8153580874204636.pypots
2024-05-22 22:25:52 [INFO]: Epoch 158 - training loss: 0.7731, validation loss: 0.8166
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch158_loss0.8165610134601593.pypots
2024-05-22 22:25:52 [INFO]: Epoch 159 - training loss: 0.7597, validation loss: 0.8182
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch159_loss0.8182188272476196.pypots
2024-05-22 22:25:52 [INFO]: Epoch 160 - training loss: 0.7617, validation loss: 0.8156
2024-05-22 22:25:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch160_loss0.8155576139688492.pypots
2024-05-22 22:25:53 [INFO]: Epoch 161 - training loss: 0.7629, validation loss: 0.8147
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch161_loss0.8147384524345398.pypots
2024-05-22 22:25:53 [INFO]: Epoch 162 - training loss: 0.7620, validation loss: 0.8169
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch162_loss0.8168822228908539.pypots
2024-05-22 22:25:53 [INFO]: Epoch 163 - training loss: 0.7575, validation loss: 0.8181
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch163_loss0.8181060701608658.pypots
2024-05-22 22:25:53 [INFO]: Epoch 164 - training loss: 0.7566, validation loss: 0.8140
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch164_loss0.8140237480401993.pypots
2024-05-22 22:25:53 [INFO]: Epoch 165 - training loss: 0.7405, validation loss: 0.8108
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch165_loss0.8108181357383728.pypots
2024-05-22 22:25:53 [INFO]: Epoch 166 - training loss: 0.7658, validation loss: 0.8121
2024-05-22 22:25:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch166_loss0.8120853751897812.pypots
2024-05-22 22:25:54 [INFO]: Epoch 167 - training loss: 0.7625, validation loss: 0.8127
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch167_loss0.8126925528049469.pypots
2024-05-22 22:25:54 [INFO]: Epoch 168 - training loss: 0.7648, validation loss: 0.8093
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch168_loss0.8093219101428986.pypots
2024-05-22 22:25:54 [INFO]: Epoch 169 - training loss: 0.7429, validation loss: 0.8142
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch169_loss0.8142103403806686.pypots
2024-05-22 22:25:54 [INFO]: Epoch 170 - training loss: 0.7551, validation loss: 0.8128
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch170_loss0.8128015697002411.pypots
2024-05-22 22:25:54 [INFO]: Epoch 171 - training loss: 0.7519, validation loss: 0.8073
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch171_loss0.8073371052742004.pypots
2024-05-22 22:25:54 [INFO]: Epoch 172 - training loss: 0.7583, validation loss: 0.8087
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch172_loss0.8087445199489594.pypots
2024-05-22 22:25:54 [INFO]: Epoch 173 - training loss: 0.7510, validation loss: 0.8102
2024-05-22 22:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch173_loss0.8101842105388641.pypots
2024-05-22 22:25:55 [INFO]: Epoch 174 - training loss: 0.7577, validation loss: 0.8084
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch174_loss0.8084169626235962.pypots
2024-05-22 22:25:55 [INFO]: Epoch 175 - training loss: 0.7589, validation loss: 0.8110
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch175_loss0.8110324293375015.pypots
2024-05-22 22:25:55 [INFO]: Epoch 176 - training loss: 0.7632, validation loss: 0.8089
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch176_loss0.8089059293270111.pypots
2024-05-22 22:25:55 [INFO]: Epoch 177 - training loss: 0.7533, validation loss: 0.8085
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch177_loss0.80848029255867.pypots
2024-05-22 22:25:55 [INFO]: Epoch 178 - training loss: 0.7429, validation loss: 0.8088
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch178_loss0.8088317960500717.pypots
2024-05-22 22:25:55 [INFO]: Epoch 179 - training loss: 0.7545, validation loss: 0.8061
2024-05-22 22:25:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch179_loss0.8060896545648575.pypots
2024-05-22 22:25:56 [INFO]: Epoch 180 - training loss: 0.7389, validation loss: 0.8052
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch180_loss0.8051620572805405.pypots
2024-05-22 22:25:56 [INFO]: Epoch 181 - training loss: 0.7467, validation loss: 0.8073
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch181_loss0.8072621524333954.pypots
2024-05-22 22:25:56 [INFO]: Epoch 182 - training loss: 0.7845, validation loss: 0.8084
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch182_loss0.8083707988262177.pypots
2024-05-22 22:25:56 [INFO]: Epoch 183 - training loss: 0.7693, validation loss: 0.8083
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch183_loss0.808286190032959.pypots
2024-05-22 22:25:56 [INFO]: Epoch 184 - training loss: 0.7387, validation loss: 0.8066
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch184_loss0.8066476136445999.pypots
2024-05-22 22:25:56 [INFO]: Epoch 185 - training loss: 0.7590, validation loss: 0.8040
2024-05-22 22:25:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch185_loss0.8039713799953461.pypots
2024-05-22 22:25:57 [INFO]: Epoch 186 - training loss: 0.7671, validation loss: 0.8042
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch186_loss0.8042313605546951.pypots
2024-05-22 22:25:57 [INFO]: Epoch 187 - training loss: 0.7637, validation loss: 0.8028
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch187_loss0.8028142601251602.pypots
2024-05-22 22:25:57 [INFO]: Epoch 188 - training loss: 0.7651, validation loss: 0.8053
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch188_loss0.805336594581604.pypots
2024-05-22 22:25:57 [INFO]: Epoch 189 - training loss: 0.7555, validation loss: 0.8061
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch189_loss0.8060733824968338.pypots
2024-05-22 22:25:57 [INFO]: Epoch 190 - training loss: 0.7562, validation loss: 0.8036
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch190_loss0.8035758286714554.pypots
2024-05-22 22:25:57 [INFO]: Epoch 191 - training loss: 0.7708, validation loss: 0.8024
2024-05-22 22:25:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch191_loss0.8023889809846878.pypots
2024-05-22 22:25:58 [INFO]: Epoch 192 - training loss: 0.7623, validation loss: 0.8039
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch192_loss0.8038555830717087.pypots
2024-05-22 22:25:58 [INFO]: Epoch 193 - training loss: 0.7594, validation loss: 0.8030
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch193_loss0.8030136525630951.pypots
2024-05-22 22:25:58 [INFO]: Epoch 194 - training loss: 0.7646, validation loss: 0.8033
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch194_loss0.8033476769924164.pypots
2024-05-22 22:25:58 [INFO]: Epoch 195 - training loss: 0.7586, validation loss: 0.8025
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch195_loss0.802484542131424.pypots
2024-05-22 22:25:58 [INFO]: Epoch 196 - training loss: 0.7342, validation loss: 0.8027
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch196_loss0.8027356863021851.pypots
2024-05-22 22:25:58 [INFO]: Epoch 197 - training loss: 0.7482, validation loss: 0.8026
2024-05-22 22:25:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch197_loss0.8026293218135834.pypots
2024-05-22 22:25:59 [INFO]: Epoch 198 - training loss: 0.7724, validation loss: 0.8017
2024-05-22 22:25:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch198_loss0.8017401248216629.pypots
2024-05-22 22:25:59 [INFO]: Epoch 199 - training loss: 0.7862, validation loss: 0.8018
2024-05-22 22:25:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch199_loss0.8018418252468109.pypots
2024-05-22 22:25:59 [INFO]: Epoch 200 - training loss: 0.7707, validation loss: 0.8007
2024-05-22 22:25:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch200_loss0.80068139731884.pypots
2024-05-22 22:25:59 [INFO]: Epoch 201 - training loss: 0.7778, validation loss: 0.7998
2024-05-22 22:25:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch201_loss0.7998479306697845.pypots
2024-05-22 22:25:59 [INFO]: Epoch 202 - training loss: 0.7554, validation loss: 0.8023
2024-05-22 22:26:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch202_loss0.8023352771997452.pypots
2024-05-22 22:26:00 [INFO]: Epoch 203 - training loss: 0.7483, validation loss: 0.8007
2024-05-22 22:26:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch203_loss0.8006965517997742.pypots
2024-05-22 22:26:00 [INFO]: Epoch 204 - training loss: 0.7424, validation loss: 0.8011
2024-05-22 22:26:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch204_loss0.8011086285114288.pypots
2024-05-22 22:26:00 [INFO]: Epoch 205 - training loss: 0.7721, validation loss: 0.7996
2024-05-22 22:26:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch205_loss0.7995743900537491.pypots
2024-05-22 22:26:00 [INFO]: Epoch 206 - training loss: 0.7567, validation loss: 0.8013
2024-05-22 22:26:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch206_loss0.8012789785861969.pypots
2024-05-22 22:26:01 [INFO]: Epoch 207 - training loss: 0.7984, validation loss: 0.7992
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch207_loss0.7991526126861572.pypots
2024-05-22 22:26:01 [INFO]: Epoch 208 - training loss: 0.7772, validation loss: 0.7981
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch208_loss0.7981339395046234.pypots
2024-05-22 22:26:01 [INFO]: Epoch 209 - training loss: 0.7524, validation loss: 0.7985
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch209_loss0.7984770983457565.pypots
2024-05-22 22:26:01 [INFO]: Epoch 210 - training loss: 0.7387, validation loss: 0.7988
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch210_loss0.7988402545452118.pypots
2024-05-22 22:26:01 [INFO]: Epoch 211 - training loss: 0.7369, validation loss: 0.7971
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch211_loss0.7970670908689499.pypots
2024-05-22 22:26:01 [INFO]: Epoch 212 - training loss: 0.7827, validation loss: 0.7984
2024-05-22 22:26:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch212_loss0.7984074652194977.pypots
2024-05-22 22:26:02 [INFO]: Epoch 213 - training loss: 0.7483, validation loss: 0.7947
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch213_loss0.7947462946176529.pypots
2024-05-22 22:26:02 [INFO]: Epoch 214 - training loss: 0.7586, validation loss: 0.7978
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch214_loss0.7977631390094757.pypots
2024-05-22 22:26:02 [INFO]: Epoch 215 - training loss: 0.7380, validation loss: 0.7958
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch215_loss0.7958251982927322.pypots
2024-05-22 22:26:02 [INFO]: Epoch 216 - training loss: 0.7429, validation loss: 0.7954
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch216_loss0.7954152226448059.pypots
2024-05-22 22:26:02 [INFO]: Epoch 217 - training loss: 0.7614, validation loss: 0.7991
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch217_loss0.799100250005722.pypots
2024-05-22 22:26:02 [INFO]: Epoch 218 - training loss: 0.8040, validation loss: 0.7992
2024-05-22 22:26:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch218_loss0.7991767078638077.pypots
2024-05-22 22:26:03 [INFO]: Epoch 219 - training loss: 0.7679, validation loss: 0.7985
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch219_loss0.7985461503267288.pypots
2024-05-22 22:26:03 [INFO]: Epoch 220 - training loss: 0.7630, validation loss: 0.7975
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch220_loss0.7974536567926407.pypots
2024-05-22 22:26:03 [INFO]: Epoch 221 - training loss: 0.7438, validation loss: 0.7955
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch221_loss0.7955150902271271.pypots
2024-05-22 22:26:03 [INFO]: Epoch 222 - training loss: 0.7480, validation loss: 0.7979
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch222_loss0.7979302555322647.pypots
2024-05-22 22:26:03 [INFO]: Epoch 223 - training loss: 0.7698, validation loss: 0.7945
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch223_loss0.7944788038730621.pypots
2024-05-22 22:26:03 [INFO]: Epoch 224 - training loss: 0.7471, validation loss: 0.7968
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch224_loss0.7967742830514908.pypots
2024-05-22 22:26:03 [INFO]: Epoch 225 - training loss: 0.7662, validation loss: 0.7973
2024-05-22 22:26:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch225_loss0.7973113656044006.pypots
2024-05-22 22:26:04 [INFO]: Epoch 226 - training loss: 0.7340, validation loss: 0.7953
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch226_loss0.7953042238950729.pypots
2024-05-22 22:26:04 [INFO]: Epoch 227 - training loss: 0.7532, validation loss: 0.7931
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch227_loss0.7931134253740311.pypots
2024-05-22 22:26:04 [INFO]: Epoch 228 - training loss: 0.7785, validation loss: 0.7943
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch228_loss0.7942605316638947.pypots
2024-05-22 22:26:04 [INFO]: Epoch 229 - training loss: 0.7642, validation loss: 0.7948
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch229_loss0.7948375046253204.pypots
2024-05-22 22:26:04 [INFO]: Epoch 230 - training loss: 0.8017, validation loss: 0.7938
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch230_loss0.7938466519117355.pypots
2024-05-22 22:26:04 [INFO]: Epoch 231 - training loss: 0.7514, validation loss: 0.7935
2024-05-22 22:26:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch231_loss0.7934641093015671.pypots
2024-05-22 22:26:05 [INFO]: Epoch 232 - training loss: 0.7712, validation loss: 0.7945
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch232_loss0.7945268154144287.pypots
2024-05-22 22:26:05 [INFO]: Epoch 233 - training loss: 0.7462, validation loss: 0.7953
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch233_loss0.7953215837478638.pypots
2024-05-22 22:26:05 [INFO]: Epoch 234 - training loss: 0.7441, validation loss: 0.7923
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch234_loss0.7923435866832733.pypots
2024-05-22 22:26:05 [INFO]: Epoch 235 - training loss: 0.7544, validation loss: 0.7951
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch235_loss0.7950742244720459.pypots
2024-05-22 22:26:05 [INFO]: Epoch 236 - training loss: 0.7404, validation loss: 0.7942
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch236_loss0.7941595166921616.pypots
2024-05-22 22:26:05 [INFO]: Epoch 237 - training loss: 0.7607, validation loss: 0.7957
2024-05-22 22:26:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch237_loss0.7956850826740265.pypots
2024-05-22 22:26:06 [INFO]: Epoch 238 - training loss: 0.7502, validation loss: 0.7894
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch238_loss0.7893704473972321.pypots
2024-05-22 22:26:06 [INFO]: Epoch 239 - training loss: 0.7386, validation loss: 0.7941
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch239_loss0.7940811216831207.pypots
2024-05-22 22:26:06 [INFO]: Epoch 240 - training loss: 0.7454, validation loss: 0.7911
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch240_loss0.7910746484994888.pypots
2024-05-22 22:26:06 [INFO]: Epoch 241 - training loss: 0.7437, validation loss: 0.7940
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch241_loss0.7940268367528915.pypots
2024-05-22 22:26:06 [INFO]: Epoch 242 - training loss: 0.7480, validation loss: 0.7931
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch242_loss0.7931082546710968.pypots
2024-05-22 22:26:06 [INFO]: Epoch 243 - training loss: 0.7533, validation loss: 0.7944
2024-05-22 22:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch243_loss0.7944449335336685.pypots
2024-05-22 22:26:07 [INFO]: Epoch 244 - training loss: 0.7602, validation loss: 0.7933
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch244_loss0.7932520061731339.pypots
2024-05-22 22:26:07 [INFO]: Epoch 245 - training loss: 0.7984, validation loss: 0.7918
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch245_loss0.7918037921190262.pypots
2024-05-22 22:26:07 [INFO]: Epoch 246 - training loss: 0.7517, validation loss: 0.7924
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch246_loss0.792434424161911.pypots
2024-05-22 22:26:07 [INFO]: Epoch 247 - training loss: 0.7514, validation loss: 0.7925
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch247_loss0.79249007999897.pypots
2024-05-22 22:26:07 [INFO]: Epoch 248 - training loss: 0.7789, validation loss: 0.7929
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN_epoch248_loss0.7929049134254456.pypots
2024-05-22 22:26:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:26:07 [INFO]: Finished training. The best model is from epoch#238.
2024-05-22 22:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_ettm1/20240522_T222523/MRNN.pypots
2024-05-22 22:26:07 [INFO]: MRNN on ETTm1: MAE=0.5786, MSE=0.9657
2024-05-22 22:26:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-22 22:26:07 [INFO]: Using the given device: cpu
2024-05-22 22:26:07 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 22:26:07 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-22 22:26:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-22 22:26:07 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 22:26:07 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-22 22:26:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-22 22:26:07 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 22:26:07 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-22 22:26:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-22 22:26:07 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-22 22:26:07 [INFO]: Using the given device: cuda:0
2024-05-22 22:26:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240522_T222607
2024-05-22 22:26:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_ettm1/20240522_T222607/tensorboard
2024-05-22 22:26:07 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 22:26:08 [INFO]: Epoch 001 - training loss: 1.1626, validation loss: 0.2475
2024-05-22 22:26:08 [INFO]: Epoch 002 - training loss: 0.8161, validation loss: 0.1691
2024-05-22 22:26:09 [INFO]: Epoch 003 - training loss: 0.7338, validation loss: 0.0972
2024-05-22 22:26:09 [INFO]: Epoch 004 - training loss: 0.6772, validation loss: 0.1005
2024-05-22 22:26:10 [INFO]: Epoch 005 - training loss: 0.6518, validation loss: 0.0950
2024-05-22 22:26:10 [INFO]: Epoch 006 - training loss: 0.6320, validation loss: 0.0760
2024-05-22 22:26:11 [INFO]: Epoch 007 - training loss: 0.6075, validation loss: 0.0717
2024-05-22 22:26:11 [INFO]: Epoch 008 - training loss: 0.5940, validation loss: 0.0756
2024-05-22 22:26:12 [INFO]: Epoch 009 - training loss: 0.5905, validation loss: 0.0631
2024-05-22 22:26:12 [INFO]: Epoch 010 - training loss: 0.5825, validation loss: 0.0585
2024-05-22 22:26:13 [INFO]: Epoch 011 - training loss: 0.5653, validation loss: 0.0552
2024-05-22 22:26:13 [INFO]: Epoch 012 - training loss: 0.5498, validation loss: 0.0521
2024-05-22 22:26:14 [INFO]: Epoch 013 - training loss: 0.5418, validation loss: 0.0464
2024-05-22 22:26:14 [INFO]: Epoch 014 - training loss: 0.5364, validation loss: 0.0608
2024-05-22 22:26:15 [INFO]: Epoch 015 - training loss: 0.5369, validation loss: 0.0484
2024-05-22 22:26:15 [INFO]: Epoch 016 - training loss: 0.5398, validation loss: 0.0585
2024-05-22 22:26:16 [INFO]: Epoch 017 - training loss: 0.5253, validation loss: 0.0399
2024-05-22 22:26:16 [INFO]: Epoch 018 - training loss: 0.5323, validation loss: 0.0495
2024-05-22 22:26:17 [INFO]: Epoch 019 - training loss: 0.5303, validation loss: 0.0432
2024-05-22 22:26:17 [INFO]: Epoch 020 - training loss: 0.5130, validation loss: 0.0498
2024-05-22 22:26:18 [INFO]: Epoch 021 - training loss: 0.5020, validation loss: 0.0383
2024-05-22 22:26:18 [INFO]: Epoch 022 - training loss: 0.4923, validation loss: 0.0456
2024-05-22 22:26:18 [INFO]: Epoch 023 - training loss: 0.4923, validation loss: 0.0434
2024-05-22 22:26:19 [INFO]: Epoch 024 - training loss: 0.4922, validation loss: 0.0487
2024-05-22 22:26:19 [INFO]: Epoch 025 - training loss: 0.5012, validation loss: 0.0543
2024-05-22 22:26:20 [INFO]: Epoch 026 - training loss: 0.4849, validation loss: 0.0352
2024-05-22 22:26:20 [INFO]: Epoch 027 - training loss: 0.4899, validation loss: 0.0422
2024-05-22 22:26:21 [INFO]: Epoch 028 - training loss: 0.4839, validation loss: 0.0456
2024-05-22 22:26:21 [INFO]: Epoch 029 - training loss: 0.4735, validation loss: 0.0351
2024-05-22 22:26:22 [INFO]: Epoch 030 - training loss: 0.4700, validation loss: 0.0603
2024-05-22 22:26:22 [INFO]: Epoch 031 - training loss: 0.4638, validation loss: 0.0358
2024-05-22 22:26:23 [INFO]: Epoch 032 - training loss: 0.4570, validation loss: 0.0362
2024-05-22 22:26:23 [INFO]: Epoch 033 - training loss: 0.4556, validation loss: 0.0509
2024-05-22 22:26:24 [INFO]: Epoch 034 - training loss: 0.4740, validation loss: 0.0292
2024-05-22 22:26:24 [INFO]: Epoch 035 - training loss: 0.4677, validation loss: 0.0349
2024-05-22 22:26:25 [INFO]: Epoch 036 - training loss: 0.4683, validation loss: 0.0363
2024-05-22 22:26:25 [INFO]: Epoch 037 - training loss: 0.4610, validation loss: 0.0454
2024-05-22 22:26:26 [INFO]: Epoch 038 - training loss: 0.4621, validation loss: 0.0389
2024-05-22 22:26:26 [INFO]: Epoch 039 - training loss: 0.4416, validation loss: 0.0492
2024-05-22 22:26:27 [INFO]: Epoch 040 - training loss: 0.4471, validation loss: 0.0318
2024-05-22 22:26:27 [INFO]: Epoch 041 - training loss: 0.4471, validation loss: 0.0323
2024-05-22 22:26:28 [INFO]: Epoch 042 - training loss: 0.4419, validation loss: 0.0350
2024-05-22 22:26:28 [INFO]: Epoch 043 - training loss: 0.4537, validation loss: 0.0466
2024-05-22 22:26:28 [INFO]: Epoch 044 - training loss: 0.4497, validation loss: 0.0398
2024-05-22 22:26:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:26:28 [INFO]: Finished training. The best model is from epoch#34.
2024-05-22 22:26:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_ettm1/20240522_T222607/SAITS.pypots
2024-05-22 22:26:29 [INFO]: SAITS on ETTm1: MAE=0.1673, MSE=0.0524
2024-05-22 22:26:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-22 22:26:29 [INFO]: Using the given device: cuda:0
2024-05-22 22:26:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240522_T222629
2024-05-22 22:26:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_ettm1/20240522_T222629/tensorboard
2024-05-22 22:26:29 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 22:26:29 [INFO]: Epoch 001 - training loss: 1.0712, validation loss: 0.2825
2024-05-22 22:26:29 [INFO]: Epoch 002 - training loss: 0.6537, validation loss: 0.1472
2024-05-22 22:26:29 [INFO]: Epoch 003 - training loss: 0.5284, validation loss: 0.1130
2024-05-22 22:26:30 [INFO]: Epoch 004 - training loss: 0.4761, validation loss: 0.0894
2024-05-22 22:26:30 [INFO]: Epoch 005 - training loss: 0.4559, validation loss: 0.0868
2024-05-22 22:26:30 [INFO]: Epoch 006 - training loss: 0.4262, validation loss: 0.0715
2024-05-22 22:26:30 [INFO]: Epoch 007 - training loss: 0.4048, validation loss: 0.0647
2024-05-22 22:26:30 [INFO]: Epoch 008 - training loss: 0.3994, validation loss: 0.0657
2024-05-22 22:26:30 [INFO]: Epoch 009 - training loss: 0.3899, validation loss: 0.0589
2024-05-22 22:26:31 [INFO]: Epoch 010 - training loss: 0.3797, validation loss: 0.0530
2024-05-22 22:26:31 [INFO]: Epoch 011 - training loss: 0.3575, validation loss: 0.0527
2024-05-22 22:26:31 [INFO]: Epoch 012 - training loss: 0.3482, validation loss: 0.0491
2024-05-22 22:26:31 [INFO]: Epoch 013 - training loss: 0.3469, validation loss: 0.0490
2024-05-22 22:26:31 [INFO]: Epoch 014 - training loss: 0.3424, validation loss: 0.0500
2024-05-22 22:26:32 [INFO]: Epoch 015 - training loss: 0.3352, validation loss: 0.0443
2024-05-22 22:26:32 [INFO]: Epoch 016 - training loss: 0.3211, validation loss: 0.0520
2024-05-22 22:26:32 [INFO]: Epoch 017 - training loss: 0.3271, validation loss: 0.0422
2024-05-22 22:26:32 [INFO]: Epoch 018 - training loss: 0.3112, validation loss: 0.0430
2024-05-22 22:26:32 [INFO]: Epoch 019 - training loss: 0.3080, validation loss: 0.0395
2024-05-22 22:26:33 [INFO]: Epoch 020 - training loss: 0.3024, validation loss: 0.0442
2024-05-22 22:26:33 [INFO]: Epoch 021 - training loss: 0.3036, validation loss: 0.0395
2024-05-22 22:26:33 [INFO]: Epoch 022 - training loss: 0.2904, validation loss: 0.0373
2024-05-22 22:26:33 [INFO]: Epoch 023 - training loss: 0.2958, validation loss: 0.0413
2024-05-22 22:26:33 [INFO]: Epoch 024 - training loss: 0.2975, validation loss: 0.0348
2024-05-22 22:26:33 [INFO]: Epoch 025 - training loss: 0.2870, validation loss: 0.0347
2024-05-22 22:26:34 [INFO]: Epoch 026 - training loss: 0.2783, validation loss: 0.0348
2024-05-22 22:26:34 [INFO]: Epoch 027 - training loss: 0.2786, validation loss: 0.0368
2024-05-22 22:26:34 [INFO]: Epoch 028 - training loss: 0.2772, validation loss: 0.0351
2024-05-22 22:26:34 [INFO]: Epoch 029 - training loss: 0.2803, validation loss: 0.0327
2024-05-22 22:26:34 [INFO]: Epoch 030 - training loss: 0.2739, validation loss: 0.0336
2024-05-22 22:26:35 [INFO]: Epoch 031 - training loss: 0.2712, validation loss: 0.0329
2024-05-22 22:26:35 [INFO]: Epoch 032 - training loss: 0.2677, validation loss: 0.0343
2024-05-22 22:26:35 [INFO]: Epoch 033 - training loss: 0.2699, validation loss: 0.0315
2024-05-22 22:26:35 [INFO]: Epoch 034 - training loss: 0.2594, validation loss: 0.0317
2024-05-22 22:26:35 [INFO]: Epoch 035 - training loss: 0.2555, validation loss: 0.0315
2024-05-22 22:26:36 [INFO]: Epoch 036 - training loss: 0.2511, validation loss: 0.0312
2024-05-22 22:26:36 [INFO]: Epoch 037 - training loss: 0.2560, validation loss: 0.0286
2024-05-22 22:26:36 [INFO]: Epoch 038 - training loss: 0.2466, validation loss: 0.0290
2024-05-22 22:26:36 [INFO]: Epoch 039 - training loss: 0.2422, validation loss: 0.0270
2024-05-22 22:26:36 [INFO]: Epoch 040 - training loss: 0.2391, validation loss: 0.0293
2024-05-22 22:26:36 [INFO]: Epoch 041 - training loss: 0.2450, validation loss: 0.0289
2024-05-22 22:26:37 [INFO]: Epoch 042 - training loss: 0.2362, validation loss: 0.0326
2024-05-22 22:26:37 [INFO]: Epoch 043 - training loss: 0.2376, validation loss: 0.0274
2024-05-22 22:26:37 [INFO]: Epoch 044 - training loss: 0.2364, validation loss: 0.0284
2024-05-22 22:26:37 [INFO]: Epoch 045 - training loss: 0.2311, validation loss: 0.0261
2024-05-22 22:26:37 [INFO]: Epoch 046 - training loss: 0.2266, validation loss: 0.0265
2024-05-22 22:26:38 [INFO]: Epoch 047 - training loss: 0.2235, validation loss: 0.0291
2024-05-22 22:26:38 [INFO]: Epoch 048 - training loss: 0.2232, validation loss: 0.0256
2024-05-22 22:26:38 [INFO]: Epoch 049 - training loss: 0.2225, validation loss: 0.0259
2024-05-22 22:26:38 [INFO]: Epoch 050 - training loss: 0.2226, validation loss: 0.0322
2024-05-22 22:26:38 [INFO]: Epoch 051 - training loss: 0.2559, validation loss: 0.0406
2024-05-22 22:26:39 [INFO]: Epoch 052 - training loss: 0.2641, validation loss: 0.0348
2024-05-22 22:26:39 [INFO]: Epoch 053 - training loss: 0.2379, validation loss: 0.0273
2024-05-22 22:26:39 [INFO]: Epoch 054 - training loss: 0.2261, validation loss: 0.0264
2024-05-22 22:26:39 [INFO]: Epoch 055 - training loss: 0.2215, validation loss: 0.0261
2024-05-22 22:26:39 [INFO]: Epoch 056 - training loss: 0.2154, validation loss: 0.0251
2024-05-22 22:26:39 [INFO]: Epoch 057 - training loss: 0.2151, validation loss: 0.0249
2024-05-22 22:26:40 [INFO]: Epoch 058 - training loss: 0.2104, validation loss: 0.0233
2024-05-22 22:26:40 [INFO]: Epoch 059 - training loss: 0.2099, validation loss: 0.0245
2024-05-22 22:26:40 [INFO]: Epoch 060 - training loss: 0.2150, validation loss: 0.0263
2024-05-22 22:26:40 [INFO]: Epoch 061 - training loss: 0.2089, validation loss: 0.0241
2024-05-22 22:26:40 [INFO]: Epoch 062 - training loss: 0.2087, validation loss: 0.0264
2024-05-22 22:26:41 [INFO]: Epoch 063 - training loss: 0.2163, validation loss: 0.0237
2024-05-22 22:26:41 [INFO]: Epoch 064 - training loss: 0.2078, validation loss: 0.0238
2024-05-22 22:26:41 [INFO]: Epoch 065 - training loss: 0.2021, validation loss: 0.0238
2024-05-22 22:26:41 [INFO]: Epoch 066 - training loss: 0.2004, validation loss: 0.0264
2024-05-22 22:26:41 [INFO]: Epoch 067 - training loss: 0.2021, validation loss: 0.0219
2024-05-22 22:26:42 [INFO]: Epoch 068 - training loss: 0.1995, validation loss: 0.0235
2024-05-22 22:26:42 [INFO]: Epoch 069 - training loss: 0.2005, validation loss: 0.0247
2024-05-22 22:26:42 [INFO]: Epoch 070 - training loss: 0.2016, validation loss: 0.0238
2024-05-22 22:26:42 [INFO]: Epoch 071 - training loss: 0.2008, validation loss: 0.0245
2024-05-22 22:26:42 [INFO]: Epoch 072 - training loss: 0.2007, validation loss: 0.0219
2024-05-22 22:26:42 [INFO]: Epoch 073 - training loss: 0.1914, validation loss: 0.0261
2024-05-22 22:26:43 [INFO]: Epoch 074 - training loss: 0.1996, validation loss: 0.0243
2024-05-22 22:26:43 [INFO]: Epoch 075 - training loss: 0.1999, validation loss: 0.0263
2024-05-22 22:26:43 [INFO]: Epoch 076 - training loss: 0.2078, validation loss: 0.0228
2024-05-22 22:26:43 [INFO]: Epoch 077 - training loss: 0.2114, validation loss: 0.0319
2024-05-22 22:26:43 [INFO]: Epoch 078 - training loss: 0.2071, validation loss: 0.0226
2024-05-22 22:26:44 [INFO]: Epoch 079 - training loss: 0.1957, validation loss: 0.0246
2024-05-22 22:26:44 [INFO]: Epoch 080 - training loss: 0.1976, validation loss: 0.0215
2024-05-22 22:26:44 [INFO]: Epoch 081 - training loss: 0.1989, validation loss: 0.0212
2024-05-22 22:26:44 [INFO]: Epoch 082 - training loss: 0.1901, validation loss: 0.0229
2024-05-22 22:26:44 [INFO]: Epoch 083 - training loss: 0.1927, validation loss: 0.0217
2024-05-22 22:26:45 [INFO]: Epoch 084 - training loss: 0.1919, validation loss: 0.0230
2024-05-22 22:26:45 [INFO]: Epoch 085 - training loss: 0.1966, validation loss: 0.0262
2024-05-22 22:26:45 [INFO]: Epoch 086 - training loss: 0.1931, validation loss: 0.0226
2024-05-22 22:26:45 [INFO]: Epoch 087 - training loss: 0.1878, validation loss: 0.0216
2024-05-22 22:26:45 [INFO]: Epoch 088 - training loss: 0.1841, validation loss: 0.0213
2024-05-22 22:26:45 [INFO]: Epoch 089 - training loss: 0.1852, validation loss: 0.0221
2024-05-22 22:26:46 [INFO]: Epoch 090 - training loss: 0.1934, validation loss: 0.0219
2024-05-22 22:26:46 [INFO]: Epoch 091 - training loss: 0.1871, validation loss: 0.0207
2024-05-22 22:26:46 [INFO]: Epoch 092 - training loss: 0.1843, validation loss: 0.0216
2024-05-22 22:26:46 [INFO]: Epoch 093 - training loss: 0.1814, validation loss: 0.0210
2024-05-22 22:26:46 [INFO]: Epoch 094 - training loss: 0.1822, validation loss: 0.0208
2024-05-22 22:26:47 [INFO]: Epoch 095 - training loss: 0.1775, validation loss: 0.0210
2024-05-22 22:26:47 [INFO]: Epoch 096 - training loss: 0.1805, validation loss: 0.0222
2024-05-22 22:26:47 [INFO]: Epoch 097 - training loss: 0.1790, validation loss: 0.0239
2024-05-22 22:26:47 [INFO]: Epoch 098 - training loss: 0.1833, validation loss: 0.0214
2024-05-22 22:26:47 [INFO]: Epoch 099 - training loss: 0.1840, validation loss: 0.0209
2024-05-22 22:26:48 [INFO]: Epoch 100 - training loss: 0.1800, validation loss: 0.0217
2024-05-22 22:26:48 [INFO]: Epoch 101 - training loss: 0.1853, validation loss: 0.0234
2024-05-22 22:26:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:26:48 [INFO]: Finished training. The best model is from epoch#91.
2024-05-22 22:26:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_ettm1/20240522_T222629/Transformer.pypots
2024-05-22 22:26:48 [INFO]: Transformer on ETTm1: MAE=0.1307, MSE=0.0358
2024-05-22 22:26:48 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-22 22:26:48 [INFO]: Using the given device: cuda:0
2024-05-22 22:26:48 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240522_T222648
2024-05-22 22:26:48 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240522_T222648/tensorboard
2024-05-22 22:26:48 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 22:26:48 [INFO]: Epoch 001 - training loss: 0.1210, validation loss: 0.0459
2024-05-22 22:26:48 [INFO]: Epoch 002 - training loss: 0.0542, validation loss: 0.0347
2024-05-22 22:26:49 [INFO]: Epoch 003 - training loss: 0.0478, validation loss: 0.0290
2024-05-22 22:26:49 [INFO]: Epoch 004 - training loss: 0.0408, validation loss: 0.0282
2024-05-22 22:26:49 [INFO]: Epoch 005 - training loss: 0.0390, validation loss: 0.0262
2024-05-22 22:26:49 [INFO]: Epoch 006 - training loss: 0.0358, validation loss: 0.0259
2024-05-22 22:26:49 [INFO]: Epoch 007 - training loss: 0.0354, validation loss: 0.0254
2024-05-22 22:26:50 [INFO]: Epoch 008 - training loss: 0.0357, validation loss: 0.0251
2024-05-22 22:26:50 [INFO]: Epoch 009 - training loss: 0.0328, validation loss: 0.0246
2024-05-22 22:26:50 [INFO]: Epoch 010 - training loss: 0.0339, validation loss: 0.0270
2024-05-22 22:26:50 [INFO]: Epoch 011 - training loss: 0.0318, validation loss: 0.0263
2024-05-22 22:26:50 [INFO]: Epoch 012 - training loss: 0.0309, validation loss: 0.0241
2024-05-22 22:26:50 [INFO]: Epoch 013 - training loss: 0.0300, validation loss: 0.0235
2024-05-22 22:26:51 [INFO]: Epoch 014 - training loss: 0.0281, validation loss: 0.0239
2024-05-22 22:26:51 [INFO]: Epoch 015 - training loss: 0.0276, validation loss: 0.0233
2024-05-22 22:26:51 [INFO]: Epoch 016 - training loss: 0.0288, validation loss: 0.0237
2024-05-22 22:26:51 [INFO]: Epoch 017 - training loss: 0.0279, validation loss: 0.0243
2024-05-22 22:26:51 [INFO]: Epoch 018 - training loss: 0.0274, validation loss: 0.0235
2024-05-22 22:26:51 [INFO]: Epoch 019 - training loss: 0.0284, validation loss: 0.0249
2024-05-22 22:26:52 [INFO]: Epoch 020 - training loss: 0.0259, validation loss: 0.0230
2024-05-22 22:26:52 [INFO]: Epoch 021 - training loss: 0.0255, validation loss: 0.0250
2024-05-22 22:26:52 [INFO]: Epoch 022 - training loss: 0.0309, validation loss: 0.0257
2024-05-22 22:26:52 [INFO]: Epoch 023 - training loss: 0.0363, validation loss: 0.0253
2024-05-22 22:26:52 [INFO]: Epoch 024 - training loss: 0.0282, validation loss: 0.0242
2024-05-22 22:26:53 [INFO]: Epoch 025 - training loss: 0.0253, validation loss: 0.0221
2024-05-22 22:26:53 [INFO]: Epoch 026 - training loss: 0.0228, validation loss: 0.0230
2024-05-22 22:26:53 [INFO]: Epoch 027 - training loss: 0.0218, validation loss: 0.0224
2024-05-22 22:26:53 [INFO]: Epoch 028 - training loss: 0.0215, validation loss: 0.0226
2024-05-22 22:26:53 [INFO]: Epoch 029 - training loss: 0.0216, validation loss: 0.0225
2024-05-22 22:26:53 [INFO]: Epoch 030 - training loss: 0.0212, validation loss: 0.0226
2024-05-22 22:26:54 [INFO]: Epoch 031 - training loss: 0.0206, validation loss: 0.0221
2024-05-22 22:26:54 [INFO]: Epoch 032 - training loss: 0.0196, validation loss: 0.0225
2024-05-22 22:26:54 [INFO]: Epoch 033 - training loss: 0.0203, validation loss: 0.0227
2024-05-22 22:26:54 [INFO]: Epoch 034 - training loss: 0.0194, validation loss: 0.0234
2024-05-22 22:26:54 [INFO]: Epoch 035 - training loss: 0.0206, validation loss: 0.0239
2024-05-22 22:26:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:26:54 [INFO]: Finished training. The best model is from epoch#25.
2024-05-22 22:26:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_ettm1/20240522_T222648/TimesNet.pypots
2024-05-22 22:26:54 [INFO]: TimesNet on ETTm1: MAE=0.1080, MSE=0.0259
2024-05-22 22:26:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-22 22:26:54 [INFO]: Using the given device: cuda:0
2024-05-22 22:26:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654
2024-05-22 22:26:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/tensorboard
2024-05-22 22:26:54 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 22:26:56 [INFO]: Epoch 001 - training loss: 0.7316, validation loss: 0.4984
2024-05-22 22:26:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch1_loss0.49837470054626465.pypots
2024-05-22 22:26:58 [INFO]: Epoch 002 - training loss: 0.4264, validation loss: 0.3647
2024-05-22 22:26:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch2_loss0.36473070830106735.pypots
2024-05-22 22:27:01 [INFO]: Epoch 003 - training loss: 0.3598, validation loss: 0.3665
2024-05-22 22:27:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch3_loss0.3664832264184952.pypots
2024-05-22 22:27:03 [INFO]: Epoch 004 - training loss: 0.3747, validation loss: 0.3016
2024-05-22 22:27:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch4_loss0.3015846982598305.pypots
2024-05-22 22:27:05 [INFO]: Epoch 005 - training loss: 0.3014, validation loss: 0.2830
2024-05-22 22:27:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch5_loss0.28303370624780655.pypots
2024-05-22 22:27:07 [INFO]: Epoch 006 - training loss: 0.2981, validation loss: 0.2678
2024-05-22 22:27:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch6_loss0.2678172290325165.pypots
2024-05-22 22:27:09 [INFO]: Epoch 007 - training loss: 0.2649, validation loss: 0.2569
2024-05-22 22:27:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch7_loss0.25686706975102425.pypots
2024-05-22 22:27:11 [INFO]: Epoch 008 - training loss: 0.2900, validation loss: 0.2530
2024-05-22 22:27:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch8_loss0.2530384622514248.pypots
2024-05-22 22:27:13 [INFO]: Epoch 009 - training loss: 0.2487, validation loss: 0.2484
2024-05-22 22:27:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch9_loss0.24837275594472885.pypots
2024-05-22 22:27:15 [INFO]: Epoch 010 - training loss: 0.2923, validation loss: 0.2382
2024-05-22 22:27:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch10_loss0.23817405849695206.pypots
2024-05-22 22:27:17 [INFO]: Epoch 011 - training loss: 0.2506, validation loss: 0.2368
2024-05-22 22:27:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch11_loss0.23681802302598953.pypots
2024-05-22 22:27:19 [INFO]: Epoch 012 - training loss: 0.2804, validation loss: 0.2294
2024-05-22 22:27:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch12_loss0.2293846756219864.pypots
2024-05-22 22:27:21 [INFO]: Epoch 013 - training loss: 0.2305, validation loss: 0.2471
2024-05-22 22:27:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch13_loss0.24707049876451492.pypots
2024-05-22 22:27:23 [INFO]: Epoch 014 - training loss: 0.2327, validation loss: 0.2291
2024-05-22 22:27:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch14_loss0.22912048175930977.pypots
2024-05-22 22:27:25 [INFO]: Epoch 015 - training loss: 0.2794, validation loss: 0.2125
2024-05-22 22:27:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch15_loss0.21251611039042473.pypots
2024-05-22 22:27:27 [INFO]: Epoch 016 - training loss: 0.2133, validation loss: 0.1999
2024-05-22 22:27:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch16_loss0.19990955293178558.pypots
2024-05-22 22:27:29 [INFO]: Epoch 017 - training loss: 0.1962, validation loss: 0.1952
2024-05-22 22:27:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch17_loss0.19520672410726547.pypots
2024-05-22 22:27:31 [INFO]: Epoch 018 - training loss: 0.1971, validation loss: 0.1906
2024-05-22 22:27:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch18_loss0.19059665501117706.pypots
2024-05-22 22:27:33 [INFO]: Epoch 019 - training loss: 0.2019, validation loss: 0.1891
2024-05-22 22:27:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch19_loss0.1891210526227951.pypots
2024-05-22 22:27:35 [INFO]: Epoch 020 - training loss: 0.2361, validation loss: 0.1894
2024-05-22 22:27:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch20_loss0.18942387402057648.pypots
2024-05-22 22:27:37 [INFO]: Epoch 021 - training loss: 0.2128, validation loss: 0.2057
2024-05-22 22:27:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch21_loss0.20573130622506142.pypots
2024-05-22 22:27:39 [INFO]: Epoch 022 - training loss: 0.2192, validation loss: 0.2039
2024-05-22 22:27:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch22_loss0.20385649427771568.pypots
2024-05-22 22:27:41 [INFO]: Epoch 023 - training loss: 0.1984, validation loss: 0.1986
2024-05-22 22:27:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch23_loss0.1985950991511345.pypots
2024-05-22 22:27:43 [INFO]: Epoch 024 - training loss: 0.1839, validation loss: 0.1885
2024-05-22 22:27:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch24_loss0.18846651911735535.pypots
2024-05-22 22:27:45 [INFO]: Epoch 025 - training loss: 0.2136, validation loss: 0.1806
2024-05-22 22:27:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch25_loss0.1806180663406849.pypots
2024-05-22 22:27:47 [INFO]: Epoch 026 - training loss: 0.2208, validation loss: 0.1816
2024-05-22 22:27:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch26_loss0.18159297481179237.pypots
2024-05-22 22:27:49 [INFO]: Epoch 027 - training loss: 0.2671, validation loss: 0.1848
2024-05-22 22:27:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch27_loss0.1848224252462387.pypots
2024-05-22 22:27:51 [INFO]: Epoch 028 - training loss: 0.2067, validation loss: 0.1767
2024-05-22 22:27:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch28_loss0.17671001702547073.pypots
2024-05-22 22:27:53 [INFO]: Epoch 029 - training loss: 0.1801, validation loss: 0.1686
2024-05-22 22:27:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch29_loss0.16855056956410408.pypots
2024-05-22 22:27:55 [INFO]: Epoch 030 - training loss: 0.1569, validation loss: 0.1658
2024-05-22 22:27:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch30_loss0.16576721519231796.pypots
2024-05-22 22:27:57 [INFO]: Epoch 031 - training loss: 0.1536, validation loss: 0.1640
2024-05-22 22:27:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch31_loss0.16400348022580147.pypots
2024-05-22 22:27:59 [INFO]: Epoch 032 - training loss: 0.1735, validation loss: 0.1639
2024-05-22 22:27:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch32_loss0.1638597622513771.pypots
2024-05-22 22:28:01 [INFO]: Epoch 033 - training loss: 0.1781, validation loss: 0.1663
2024-05-22 22:28:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch33_loss0.16634967923164368.pypots
2024-05-22 22:28:03 [INFO]: Epoch 034 - training loss: 0.1492, validation loss: 0.1669
2024-05-22 22:28:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch34_loss0.1668672002851963.pypots
2024-05-22 22:28:05 [INFO]: Epoch 035 - training loss: 0.1492, validation loss: 0.1550
2024-05-22 22:28:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch35_loss0.15501686558127403.pypots
2024-05-22 22:28:07 [INFO]: Epoch 036 - training loss: 0.1831, validation loss: 0.1626
2024-05-22 22:28:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch36_loss0.16259842738509178.pypots
2024-05-22 22:28:09 [INFO]: Epoch 037 - training loss: 0.2400, validation loss: 0.1632
2024-05-22 22:28:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch37_loss0.16316817700862885.pypots
2024-05-22 22:28:12 [INFO]: Epoch 038 - training loss: 0.1589, validation loss: 0.1584
2024-05-22 22:28:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch38_loss0.1584293581545353.pypots
2024-05-22 22:28:14 [INFO]: Epoch 039 - training loss: 0.1533, validation loss: 0.1628
2024-05-22 22:28:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch39_loss0.16283584386110306.pypots
2024-05-22 22:28:16 [INFO]: Epoch 040 - training loss: 0.2394, validation loss: 0.1545
2024-05-22 22:28:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch40_loss0.15446113049983978.pypots
2024-05-22 22:28:18 [INFO]: Epoch 041 - training loss: 0.1683, validation loss: 0.1544
2024-05-22 22:28:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch41_loss0.1543595977127552.pypots
2024-05-22 22:28:20 [INFO]: Epoch 042 - training loss: 0.1528, validation loss: 0.1482
2024-05-22 22:28:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch42_loss0.14816326647996902.pypots
2024-05-22 22:28:22 [INFO]: Epoch 043 - training loss: 0.1656, validation loss: 0.1471
2024-05-22 22:28:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch43_loss0.14713580906391144.pypots
2024-05-22 22:28:24 [INFO]: Epoch 044 - training loss: 0.1646, validation loss: 0.1493
2024-05-22 22:28:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch44_loss0.1493024341762066.pypots
2024-05-22 22:28:26 [INFO]: Epoch 045 - training loss: 0.1533, validation loss: 0.1434
2024-05-22 22:28:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch45_loss0.14340567961335182.pypots
2024-05-22 22:28:28 [INFO]: Epoch 046 - training loss: 0.1428, validation loss: 0.1472
2024-05-22 22:28:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch46_loss0.14723119139671326.pypots
2024-05-22 22:28:30 [INFO]: Epoch 047 - training loss: 0.1425, validation loss: 0.1460
2024-05-22 22:28:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch47_loss0.14598244801163673.pypots
2024-05-22 22:28:32 [INFO]: Epoch 048 - training loss: 0.1507, validation loss: 0.1444
2024-05-22 22:28:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch48_loss0.14444391429424286.pypots
2024-05-22 22:28:34 [INFO]: Epoch 049 - training loss: 0.1366, validation loss: 0.1394
2024-05-22 22:28:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch49_loss0.13935329765081406.pypots
2024-05-22 22:28:36 [INFO]: Epoch 050 - training loss: 0.2399, validation loss: 0.1851
2024-05-22 22:28:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch50_loss0.1850813888013363.pypots
2024-05-22 22:28:38 [INFO]: Epoch 051 - training loss: 0.1977, validation loss: 0.1911
2024-05-22 22:28:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch51_loss0.1910978928208351.pypots
2024-05-22 22:28:40 [INFO]: Epoch 052 - training loss: 0.1792, validation loss: 0.1591
2024-05-22 22:28:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch52_loss0.15914013236761093.pypots
2024-05-22 22:28:42 [INFO]: Epoch 053 - training loss: 0.1624, validation loss: 0.1505
2024-05-22 22:28:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch53_loss0.15050984919071198.pypots
2024-05-22 22:28:44 [INFO]: Epoch 054 - training loss: 0.1884, validation loss: 0.1566
2024-05-22 22:28:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch54_loss0.1565915197134018.pypots
2024-05-22 22:28:46 [INFO]: Epoch 055 - training loss: 0.1879, validation loss: 0.1674
2024-05-22 22:28:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch55_loss0.16740067303180695.pypots
2024-05-22 22:28:48 [INFO]: Epoch 056 - training loss: 0.1527, validation loss: 0.1486
2024-05-22 22:28:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch56_loss0.14855200424790382.pypots
2024-05-22 22:28:50 [INFO]: Epoch 057 - training loss: 0.1588, validation loss: 0.1412
2024-05-22 22:28:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch57_loss0.1411554478108883.pypots
2024-05-22 22:28:52 [INFO]: Epoch 058 - training loss: 0.2149, validation loss: 0.1598
2024-05-22 22:28:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch58_loss0.1597617082297802.pypots
2024-05-22 22:28:54 [INFO]: Epoch 059 - training loss: 0.1817, validation loss: 0.1632
2024-05-22 22:28:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI_epoch59_loss0.1632148213684559.pypots
2024-05-22 22:28:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:28:54 [INFO]: Finished training. The best model is from epoch#49.
2024-05-22 22:28:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_ettm1/20240522_T222654/CSDI.pypots
2024-05-22 22:29:10 [INFO]: CSDI on ETTm1: MAE=0.1826, MSE=0.1375
2024-05-22 22:29:10 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-22 22:29:10 [INFO]: Using the given device: cuda:0
2024-05-22 22:29:10 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240522_T222910
2024-05-22 22:29:10 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240522_T222910/tensorboard
2024-05-22 22:29:10 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:29:10 [INFO]: Epoch 001 - training loss: 23736.4857, validation loss: 0.9800
2024-05-22 22:29:10 [INFO]: Epoch 002 - training loss: 21753.0420, validation loss: 0.9719
2024-05-22 22:29:10 [INFO]: Epoch 003 - training loss: 19762.8452, validation loss: 0.9568
2024-05-22 22:29:10 [INFO]: Epoch 004 - training loss: 17632.7515, validation loss: 0.9365
2024-05-22 22:29:10 [INFO]: Epoch 005 - training loss: 15641.1821, validation loss: 0.8937
2024-05-22 22:29:10 [INFO]: Epoch 006 - training loss: 14109.7200, validation loss: 0.8097
2024-05-22 22:29:10 [INFO]: Epoch 007 - training loss: 12922.8417, validation loss: 0.6902
2024-05-22 22:29:10 [INFO]: Epoch 008 - training loss: 12000.5837, validation loss: 0.5788
2024-05-22 22:29:11 [INFO]: Epoch 009 - training loss: 11376.7451, validation loss: 0.4947
2024-05-22 22:29:11 [INFO]: Epoch 010 - training loss: 11043.7812, validation loss: 0.4705
2024-05-22 22:29:11 [INFO]: Epoch 011 - training loss: 10655.1715, validation loss: 0.4648
2024-05-22 22:29:11 [INFO]: Epoch 012 - training loss: 10384.0099, validation loss: 0.4601
2024-05-22 22:29:11 [INFO]: Epoch 013 - training loss: 10216.3975, validation loss: 0.4446
2024-05-22 22:29:11 [INFO]: Epoch 014 - training loss: 10099.6476, validation loss: 0.4265
2024-05-22 22:29:11 [INFO]: Epoch 015 - training loss: 10027.6266, validation loss: 0.4060
2024-05-22 22:29:11 [INFO]: Epoch 016 - training loss: 9989.7526, validation loss: 0.3952
2024-05-22 22:29:11 [INFO]: Epoch 017 - training loss: 9859.0201, validation loss: 0.3734
2024-05-22 22:29:11 [INFO]: Epoch 018 - training loss: 9781.1633, validation loss: 0.3447
2024-05-22 22:29:12 [INFO]: Epoch 019 - training loss: 9769.9805, validation loss: 0.3228
2024-05-22 22:29:12 [INFO]: Epoch 020 - training loss: 9696.8242, validation loss: 0.3020
2024-05-22 22:29:12 [INFO]: Epoch 021 - training loss: 9665.6455, validation loss: 0.2806
2024-05-22 22:29:12 [INFO]: Epoch 022 - training loss: 9614.1481, validation loss: 0.2692
2024-05-22 22:29:12 [INFO]: Epoch 023 - training loss: 9605.0185, validation loss: 0.2604
2024-05-22 22:29:12 [INFO]: Epoch 024 - training loss: 9586.7478, validation loss: 0.2483
2024-05-22 22:29:12 [INFO]: Epoch 025 - training loss: 9551.8001, validation loss: 0.2406
2024-05-22 22:29:12 [INFO]: Epoch 026 - training loss: 9527.2831, validation loss: 0.2315
2024-05-22 22:29:12 [INFO]: Epoch 027 - training loss: 9519.8760, validation loss: 0.2268
2024-05-22 22:29:13 [INFO]: Epoch 028 - training loss: 9504.0496, validation loss: 0.2226
2024-05-22 22:29:13 [INFO]: Epoch 029 - training loss: 9511.3889, validation loss: 0.2177
2024-05-22 22:29:13 [INFO]: Epoch 030 - training loss: 9461.0746, validation loss: 0.2166
2024-05-22 22:29:13 [INFO]: Epoch 031 - training loss: 9480.0371, validation loss: 0.2131
2024-05-22 22:29:13 [INFO]: Epoch 032 - training loss: 9451.1768, validation loss: 0.2089
2024-05-22 22:29:13 [INFO]: Epoch 033 - training loss: 9433.3318, validation loss: 0.2047
2024-05-22 22:29:13 [INFO]: Epoch 034 - training loss: 9438.3601, validation loss: 0.2007
2024-05-22 22:29:13 [INFO]: Epoch 035 - training loss: 9423.9240, validation loss: 0.1958
2024-05-22 22:29:13 [INFO]: Epoch 036 - training loss: 9410.8105, validation loss: 0.1935
2024-05-22 22:29:14 [INFO]: Epoch 037 - training loss: 9400.1239, validation loss: 0.1903
2024-05-22 22:29:14 [INFO]: Epoch 038 - training loss: 9402.5857, validation loss: 0.1879
2024-05-22 22:29:14 [INFO]: Epoch 039 - training loss: 9410.8224, validation loss: 0.1822
2024-05-22 22:29:14 [INFO]: Epoch 040 - training loss: 9384.3992, validation loss: 0.1858
2024-05-22 22:29:14 [INFO]: Epoch 041 - training loss: 9382.8337, validation loss: 0.1781
2024-05-22 22:29:14 [INFO]: Epoch 042 - training loss: 9377.2786, validation loss: 0.1694
2024-05-22 22:29:14 [INFO]: Epoch 043 - training loss: 9369.5323, validation loss: 0.1648
2024-05-22 22:29:14 [INFO]: Epoch 044 - training loss: 9371.5193, validation loss: 0.1650
2024-05-22 22:29:14 [INFO]: Epoch 045 - training loss: 9364.1420, validation loss: 0.1599
2024-05-22 22:29:14 [INFO]: Epoch 046 - training loss: 9360.3506, validation loss: 0.1586
2024-05-22 22:29:15 [INFO]: Epoch 047 - training loss: 9358.1891, validation loss: 0.1536
2024-05-22 22:29:15 [INFO]: Epoch 048 - training loss: 9363.2546, validation loss: 0.1519
2024-05-22 22:29:15 [INFO]: Epoch 049 - training loss: 9350.9924, validation loss: 0.1471
2024-05-22 22:29:15 [INFO]: Epoch 050 - training loss: 9349.0403, validation loss: 0.1468
2024-05-22 22:29:15 [INFO]: Epoch 051 - training loss: 9350.3506, validation loss: 0.1458
2024-05-22 22:29:15 [INFO]: Epoch 052 - training loss: 9347.2416, validation loss: 0.1408
2024-05-22 22:29:15 [INFO]: Epoch 053 - training loss: 9349.2142, validation loss: 0.1391
2024-05-22 22:29:15 [INFO]: Epoch 054 - training loss: 9336.6557, validation loss: 0.1366
2024-05-22 22:29:15 [INFO]: Epoch 055 - training loss: 9337.9678, validation loss: 0.1341
2024-05-22 22:29:16 [INFO]: Epoch 056 - training loss: 9340.6770, validation loss: 0.1339
2024-05-22 22:29:16 [INFO]: Epoch 057 - training loss: 9332.1552, validation loss: 0.1291
2024-05-22 22:29:16 [INFO]: Epoch 058 - training loss: 9328.1466, validation loss: 0.1301
2024-05-22 22:29:16 [INFO]: Epoch 059 - training loss: 9326.6641, validation loss: 0.1277
2024-05-22 22:29:16 [INFO]: Epoch 060 - training loss: 9329.1098, validation loss: 0.1265
2024-05-22 22:29:16 [INFO]: Epoch 061 - training loss: 9323.5482, validation loss: 0.1248
2024-05-22 22:29:16 [INFO]: Epoch 062 - training loss: 9322.7043, validation loss: 0.1246
2024-05-22 22:29:16 [INFO]: Epoch 063 - training loss: 9322.6775, validation loss: 0.1226
2024-05-22 22:29:16 [INFO]: Epoch 064 - training loss: 9319.7999, validation loss: 0.1231
2024-05-22 22:29:17 [INFO]: Epoch 065 - training loss: 9327.2342, validation loss: 0.1199
2024-05-22 22:29:17 [INFO]: Epoch 066 - training loss: 9317.1356, validation loss: 0.1199
2024-05-22 22:29:17 [INFO]: Epoch 067 - training loss: 9322.2928, validation loss: 0.1209
2024-05-22 22:29:17 [INFO]: Epoch 068 - training loss: 9315.3409, validation loss: 0.1184
2024-05-22 22:29:17 [INFO]: Epoch 069 - training loss: 9312.4181, validation loss: 0.1205
2024-05-22 22:29:17 [INFO]: Epoch 070 - training loss: 9312.2756, validation loss: 0.1160
2024-05-22 22:29:17 [INFO]: Epoch 071 - training loss: 9311.8204, validation loss: 0.1171
2024-05-22 22:29:17 [INFO]: Epoch 072 - training loss: 9312.8380, validation loss: 0.1151
2024-05-22 22:29:17 [INFO]: Epoch 073 - training loss: 9308.5560, validation loss: 0.1174
2024-05-22 22:29:17 [INFO]: Epoch 074 - training loss: 9307.1685, validation loss: 0.1141
2024-05-22 22:29:18 [INFO]: Epoch 075 - training loss: 9306.7440, validation loss: 0.1165
2024-05-22 22:29:18 [INFO]: Epoch 076 - training loss: 9308.7890, validation loss: 0.1097
2024-05-22 22:29:18 [INFO]: Epoch 077 - training loss: 9308.9708, validation loss: 0.1141
2024-05-22 22:29:18 [INFO]: Epoch 078 - training loss: 9308.5311, validation loss: 0.1118
2024-05-22 22:29:18 [INFO]: Epoch 079 - training loss: 9304.1859, validation loss: 0.1119
2024-05-22 22:29:18 [INFO]: Epoch 080 - training loss: 9301.4498, validation loss: 0.1120
2024-05-22 22:29:18 [INFO]: Epoch 081 - training loss: 9301.8567, validation loss: 0.1107
2024-05-22 22:29:18 [INFO]: Epoch 082 - training loss: 9302.8051, validation loss: 0.1102
2024-05-22 22:29:18 [INFO]: Epoch 083 - training loss: 9305.0721, validation loss: 0.1124
2024-05-22 22:29:19 [INFO]: Epoch 084 - training loss: 9303.6648, validation loss: 0.1079
2024-05-22 22:29:19 [INFO]: Epoch 085 - training loss: 9307.3275, validation loss: 0.1083
2024-05-22 22:29:19 [INFO]: Epoch 086 - training loss: 9298.7427, validation loss: 0.1072
2024-05-22 22:29:19 [INFO]: Epoch 087 - training loss: 9297.5918, validation loss: 0.1096
2024-05-22 22:29:19 [INFO]: Epoch 088 - training loss: 9299.2197, validation loss: 0.1087
2024-05-22 22:29:19 [INFO]: Epoch 089 - training loss: 9296.7753, validation loss: 0.1077
2024-05-22 22:29:19 [INFO]: Epoch 090 - training loss: 9297.3974, validation loss: 0.1073
2024-05-22 22:29:19 [INFO]: Epoch 091 - training loss: 9297.4117, validation loss: 0.1050
2024-05-22 22:29:19 [INFO]: Epoch 092 - training loss: 9295.5696, validation loss: 0.1086
2024-05-22 22:29:20 [INFO]: Epoch 093 - training loss: 9296.5482, validation loss: 0.1035
2024-05-22 22:29:20 [INFO]: Epoch 094 - training loss: 9296.5540, validation loss: 0.1053
2024-05-22 22:29:20 [INFO]: Epoch 095 - training loss: 9295.5745, validation loss: 0.1025
2024-05-22 22:29:20 [INFO]: Epoch 096 - training loss: 9293.3813, validation loss: 0.1039
2024-05-22 22:29:20 [INFO]: Epoch 097 - training loss: 9292.2650, validation loss: 0.1054
2024-05-22 22:29:20 [INFO]: Epoch 098 - training loss: 9292.9202, validation loss: 0.1034
2024-05-22 22:29:20 [INFO]: Epoch 099 - training loss: 9290.3812, validation loss: 0.1030
2024-05-22 22:29:20 [INFO]: Epoch 100 - training loss: 9293.3018, validation loss: 0.1032
2024-05-22 22:29:20 [INFO]: Epoch 101 - training loss: 9291.0008, validation loss: 0.1026
2024-05-22 22:29:20 [INFO]: Epoch 102 - training loss: 9291.3738, validation loss: 0.1003
2024-05-22 22:29:21 [INFO]: Epoch 103 - training loss: 9289.8194, validation loss: 0.1022
2024-05-22 22:29:21 [INFO]: Epoch 104 - training loss: 9290.6268, validation loss: 0.1000
2024-05-22 22:29:21 [INFO]: Epoch 105 - training loss: 9291.5828, validation loss: 0.1000
2024-05-22 22:29:21 [INFO]: Epoch 106 - training loss: 9292.3459, validation loss: 0.0986
2024-05-22 22:29:21 [INFO]: Epoch 107 - training loss: 9289.3058, validation loss: 0.1002
2024-05-22 22:29:21 [INFO]: Epoch 108 - training loss: 9293.1371, validation loss: 0.0992
2024-05-22 22:29:21 [INFO]: Epoch 109 - training loss: 9288.6654, validation loss: 0.0990
2024-05-22 22:29:21 [INFO]: Epoch 110 - training loss: 9291.7980, validation loss: 0.0990
2024-05-22 22:29:21 [INFO]: Epoch 111 - training loss: 9289.5611, validation loss: 0.0976
2024-05-22 22:29:22 [INFO]: Epoch 112 - training loss: 9286.7546, validation loss: 0.0964
2024-05-22 22:29:22 [INFO]: Epoch 113 - training loss: 9288.1323, validation loss: 0.0961
2024-05-22 22:29:22 [INFO]: Epoch 114 - training loss: 9289.0668, validation loss: 0.0961
2024-05-22 22:29:22 [INFO]: Epoch 115 - training loss: 9287.1049, validation loss: 0.0961
2024-05-22 22:29:22 [INFO]: Epoch 116 - training loss: 9286.6042, validation loss: 0.0956
2024-05-22 22:29:22 [INFO]: Epoch 117 - training loss: 9284.9219, validation loss: 0.0955
2024-05-22 22:29:22 [INFO]: Epoch 118 - training loss: 9285.2648, validation loss: 0.0952
2024-05-22 22:29:22 [INFO]: Epoch 119 - training loss: 9283.3630, validation loss: 0.0958
2024-05-22 22:29:22 [INFO]: Epoch 120 - training loss: 9282.9840, validation loss: 0.0939
2024-05-22 22:29:22 [INFO]: Epoch 121 - training loss: 9284.4528, validation loss: 0.0951
2024-05-22 22:29:23 [INFO]: Epoch 122 - training loss: 9285.4924, validation loss: 0.0926
2024-05-22 22:29:23 [INFO]: Epoch 123 - training loss: 9285.4959, validation loss: 0.0917
2024-05-22 22:29:23 [INFO]: Epoch 124 - training loss: 9284.4240, validation loss: 0.0941
2024-05-22 22:29:23 [INFO]: Epoch 125 - training loss: 9283.5359, validation loss: 0.0936
2024-05-22 22:29:23 [INFO]: Epoch 126 - training loss: 9282.0931, validation loss: 0.0922
2024-05-22 22:29:23 [INFO]: Epoch 127 - training loss: 9283.0620, validation loss: 0.0922
2024-05-22 22:29:23 [INFO]: Epoch 128 - training loss: 9281.5529, validation loss: 0.0913
2024-05-22 22:29:23 [INFO]: Epoch 129 - training loss: 9282.7816, validation loss: 0.0909
2024-05-22 22:29:23 [INFO]: Epoch 130 - training loss: 9280.4682, validation loss: 0.0924
2024-05-22 22:29:24 [INFO]: Epoch 131 - training loss: 9281.2919, validation loss: 0.0920
2024-05-22 22:29:24 [INFO]: Epoch 132 - training loss: 9281.4538, validation loss: 0.0900
2024-05-22 22:29:24 [INFO]: Epoch 133 - training loss: 9283.3949, validation loss: 0.0915
2024-05-22 22:29:24 [INFO]: Epoch 134 - training loss: 9281.4390, validation loss: 0.0879
2024-05-22 22:29:24 [INFO]: Epoch 135 - training loss: 9281.5580, validation loss: 0.0916
2024-05-22 22:29:24 [INFO]: Epoch 136 - training loss: 9280.5422, validation loss: 0.0887
2024-05-22 22:29:24 [INFO]: Epoch 137 - training loss: 9280.6254, validation loss: 0.0891
2024-05-22 22:29:24 [INFO]: Epoch 138 - training loss: 9281.2217, validation loss: 0.0897
2024-05-22 22:29:24 [INFO]: Epoch 139 - training loss: 9281.3304, validation loss: 0.0906
2024-05-22 22:29:25 [INFO]: Epoch 140 - training loss: 9278.7513, validation loss: 0.0892
2024-05-22 22:29:25 [INFO]: Epoch 141 - training loss: 9280.0733, validation loss: 0.0899
2024-05-22 22:29:25 [INFO]: Epoch 142 - training loss: 9279.9882, validation loss: 0.0892
2024-05-22 22:29:25 [INFO]: Epoch 143 - training loss: 9278.4708, validation loss: 0.0889
2024-05-22 22:29:25 [INFO]: Epoch 144 - training loss: 9279.5015, validation loss: 0.0875
2024-05-22 22:29:25 [INFO]: Epoch 145 - training loss: 9279.7413, validation loss: 0.0881
2024-05-22 22:29:25 [INFO]: Epoch 146 - training loss: 9279.3096, validation loss: 0.0863
2024-05-22 22:29:25 [INFO]: Epoch 147 - training loss: 9277.5373, validation loss: 0.0885
2024-05-22 22:29:25 [INFO]: Epoch 148 - training loss: 9279.6493, validation loss: 0.0864
2024-05-22 22:29:25 [INFO]: Epoch 149 - training loss: 9279.0980, validation loss: 0.0880
2024-05-22 22:29:26 [INFO]: Epoch 150 - training loss: 9279.6128, validation loss: 0.0868
2024-05-22 22:29:26 [INFO]: Epoch 151 - training loss: 9276.6357, validation loss: 0.0853
2024-05-22 22:29:26 [INFO]: Epoch 152 - training loss: 9278.3315, validation loss: 0.0854
2024-05-22 22:29:26 [INFO]: Epoch 153 - training loss: 9278.5663, validation loss: 0.0848
2024-05-22 22:29:26 [INFO]: Epoch 154 - training loss: 9277.6010, validation loss: 0.0862
2024-05-22 22:29:26 [INFO]: Epoch 155 - training loss: 9277.0163, validation loss: 0.0841
2024-05-22 22:29:26 [INFO]: Epoch 156 - training loss: 9277.5446, validation loss: 0.0852
2024-05-22 22:29:26 [INFO]: Epoch 157 - training loss: 9276.3501, validation loss: 0.0857
2024-05-22 22:29:26 [INFO]: Epoch 158 - training loss: 9279.2103, validation loss: 0.0863
2024-05-22 22:29:27 [INFO]: Epoch 159 - training loss: 9277.0522, validation loss: 0.0854
2024-05-22 22:29:27 [INFO]: Epoch 160 - training loss: 9276.4183, validation loss: 0.0840
2024-05-22 22:29:27 [INFO]: Epoch 161 - training loss: 9275.8218, validation loss: 0.0855
2024-05-22 22:29:27 [INFO]: Epoch 162 - training loss: 9275.6335, validation loss: 0.0848
2024-05-22 22:29:27 [INFO]: Epoch 163 - training loss: 9275.5148, validation loss: 0.0844
2024-05-22 22:29:27 [INFO]: Epoch 164 - training loss: 9278.3380, validation loss: 0.0850
2024-05-22 22:29:27 [INFO]: Epoch 165 - training loss: 9275.6674, validation loss: 0.0837
2024-05-22 22:29:27 [INFO]: Epoch 166 - training loss: 9276.1447, validation loss: 0.0828
2024-05-22 22:29:27 [INFO]: Epoch 167 - training loss: 9275.1121, validation loss: 0.0825
2024-05-22 22:29:28 [INFO]: Epoch 168 - training loss: 9275.5262, validation loss: 0.0831
2024-05-22 22:29:28 [INFO]: Epoch 169 - training loss: 9276.1782, validation loss: 0.0812
2024-05-22 22:29:28 [INFO]: Epoch 170 - training loss: 9275.1557, validation loss: 0.0826
2024-05-22 22:29:28 [INFO]: Epoch 171 - training loss: 9276.5468, validation loss: 0.0849
2024-05-22 22:29:28 [INFO]: Epoch 172 - training loss: 9276.1483, validation loss: 0.0816
2024-05-22 22:29:28 [INFO]: Epoch 173 - training loss: 9276.5955, validation loss: 0.0826
2024-05-22 22:29:28 [INFO]: Epoch 174 - training loss: 9276.2505, validation loss: 0.0818
2024-05-22 22:29:28 [INFO]: Epoch 175 - training loss: 9274.8795, validation loss: 0.0829
2024-05-22 22:29:28 [INFO]: Epoch 176 - training loss: 9275.0317, validation loss: 0.0829
2024-05-22 22:29:29 [INFO]: Epoch 177 - training loss: 9275.6458, validation loss: 0.0815
2024-05-22 22:29:29 [INFO]: Epoch 178 - training loss: 9276.0762, validation loss: 0.0821
2024-05-22 22:29:29 [INFO]: Epoch 179 - training loss: 9274.1608, validation loss: 0.0815
2024-05-22 22:29:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:29:29 [INFO]: Finished training. The best model is from epoch#169.
2024-05-22 22:29:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_ettm1/20240522_T222910/GPVAE.pypots
2024-05-22 22:29:29 [INFO]: GP-VAE on ETTm1: MAE=0.2879, MSE=0.1727
2024-05-22 22:29:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-22 22:29:29 [INFO]: Using the given device: cuda:0
2024-05-22 22:29:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240522_T222929
2024-05-22 22:29:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_ettm1/20240522_T222929/tensorboard
2024-05-22 22:29:29 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:29:37 [INFO]: Epoch 001 - generator training loss: 0.5171, discriminator training loss: 0.4382, validation loss: 0.3589
2024-05-22 22:29:44 [INFO]: Epoch 002 - generator training loss: 0.0080, discriminator training loss: 0.3254, validation loss: 0.1137
2024-05-22 22:29:51 [INFO]: Epoch 003 - generator training loss: -0.1228, discriminator training loss: 0.3112, validation loss: 0.0651
2024-05-22 22:29:59 [INFO]: Epoch 004 - generator training loss: -0.1334, discriminator training loss: 0.2981, validation loss: 0.0534
2024-05-22 22:30:06 [INFO]: Epoch 005 - generator training loss: -0.1289, discriminator training loss: 0.2795, validation loss: 0.0454
2024-05-22 22:30:13 [INFO]: Epoch 006 - generator training loss: -0.1086, discriminator training loss: 0.2492, validation loss: 0.0404
2024-05-22 22:30:20 [INFO]: Epoch 007 - generator training loss: -0.0815, discriminator training loss: 0.2168, validation loss: 0.0388
2024-05-22 22:30:27 [INFO]: Epoch 008 - generator training loss: -0.0570, discriminator training loss: 0.1798, validation loss: 0.0379
2024-05-22 22:30:34 [INFO]: Epoch 009 - generator training loss: -0.0436, discriminator training loss: 0.1549, validation loss: 0.0361
2024-05-22 22:30:41 [INFO]: Epoch 010 - generator training loss: -0.0366, discriminator training loss: 0.1399, validation loss: 0.0359
2024-05-22 22:30:49 [INFO]: Epoch 011 - generator training loss: -0.0335, discriminator training loss: 0.1316, validation loss: 0.0348
2024-05-22 22:30:56 [INFO]: Epoch 012 - generator training loss: -0.0347, discriminator training loss: 0.1280, validation loss: 0.0339
2024-05-22 22:31:03 [INFO]: Epoch 013 - generator training loss: -0.0335, discriminator training loss: 0.1233, validation loss: 0.0324
2024-05-22 22:31:10 [INFO]: Epoch 014 - generator training loss: -0.0328, discriminator training loss: 0.1219, validation loss: 0.0333
2024-05-22 22:31:17 [INFO]: Epoch 015 - generator training loss: -0.0329, discriminator training loss: 0.1191, validation loss: 0.0323
2024-05-22 22:31:24 [INFO]: Epoch 016 - generator training loss: -0.0321, discriminator training loss: 0.1188, validation loss: 0.0315
2024-05-22 22:31:31 [INFO]: Epoch 017 - generator training loss: -0.0311, discriminator training loss: 0.1200, validation loss: 0.0317
2024-05-22 22:31:38 [INFO]: Epoch 018 - generator training loss: -0.0323, discriminator training loss: 0.1176, validation loss: 0.0303
2024-05-22 22:31:46 [INFO]: Epoch 019 - generator training loss: -0.0311, discriminator training loss: 0.1166, validation loss: 0.0311
2024-05-22 22:31:53 [INFO]: Epoch 020 - generator training loss: -0.0329, discriminator training loss: 0.1159, validation loss: 0.0299
2024-05-22 22:32:00 [INFO]: Epoch 021 - generator training loss: -0.0350, discriminator training loss: 0.1158, validation loss: 0.0295
2024-05-22 22:32:07 [INFO]: Epoch 022 - generator training loss: -0.0347, discriminator training loss: 0.1159, validation loss: 0.0301
2024-05-22 22:32:14 [INFO]: Epoch 023 - generator training loss: -0.0349, discriminator training loss: 0.1156, validation loss: 0.0288
2024-05-22 22:32:22 [INFO]: Epoch 024 - generator training loss: -0.0338, discriminator training loss: 0.1132, validation loss: 0.0288
2024-05-22 22:32:29 [INFO]: Epoch 025 - generator training loss: -0.0353, discriminator training loss: 0.1151, validation loss: 0.0314
2024-05-22 22:32:36 [INFO]: Epoch 026 - generator training loss: -0.0347, discriminator training loss: 0.1129, validation loss: 0.0293
2024-05-22 22:32:43 [INFO]: Epoch 027 - generator training loss: -0.0355, discriminator training loss: 0.1137, validation loss: 0.0288
2024-05-22 22:32:50 [INFO]: Epoch 028 - generator training loss: -0.0341, discriminator training loss: 0.1120, validation loss: 0.0277
2024-05-22 22:32:57 [INFO]: Epoch 029 - generator training loss: -0.0384, discriminator training loss: 0.1127, validation loss: 0.0277
2024-05-22 22:33:04 [INFO]: Epoch 030 - generator training loss: -0.0373, discriminator training loss: 0.1143, validation loss: 0.0272
2024-05-22 22:33:11 [INFO]: Epoch 031 - generator training loss: -0.0337, discriminator training loss: 0.1149, validation loss: 0.0271
2024-05-22 22:33:19 [INFO]: Epoch 032 - generator training loss: -0.0357, discriminator training loss: 0.1137, validation loss: 0.0266
2024-05-22 22:33:26 [INFO]: Epoch 033 - generator training loss: -0.0358, discriminator training loss: 0.1117, validation loss: 0.0275
2024-05-22 22:33:33 [INFO]: Epoch 034 - generator training loss: -0.0361, discriminator training loss: 0.1108, validation loss: 0.0265
2024-05-22 22:33:40 [INFO]: Epoch 035 - generator training loss: -0.0383, discriminator training loss: 0.1106, validation loss: 0.0263
2024-05-22 22:33:47 [INFO]: Epoch 036 - generator training loss: -0.0394, discriminator training loss: 0.1118, validation loss: 0.0262
2024-05-22 22:33:54 [INFO]: Epoch 037 - generator training loss: -0.0381, discriminator training loss: 0.1098, validation loss: 0.0257
2024-05-22 22:34:01 [INFO]: Epoch 038 - generator training loss: -0.0367, discriminator training loss: 0.1087, validation loss: 0.0257
2024-05-22 22:34:09 [INFO]: Epoch 039 - generator training loss: -0.0396, discriminator training loss: 0.1110, validation loss: 0.0259
2024-05-22 22:34:16 [INFO]: Epoch 040 - generator training loss: -0.0383, discriminator training loss: 0.1113, validation loss: 0.0256
2024-05-22 22:34:23 [INFO]: Epoch 041 - generator training loss: -0.0382, discriminator training loss: 0.1103, validation loss: 0.0252
2024-05-22 22:34:30 [INFO]: Epoch 042 - generator training loss: -0.0378, discriminator training loss: 0.1100, validation loss: 0.0251
2024-05-22 22:34:37 [INFO]: Epoch 043 - generator training loss: -0.0407, discriminator training loss: 0.1136, validation loss: 0.0250
2024-05-22 22:34:44 [INFO]: Epoch 044 - generator training loss: -0.0376, discriminator training loss: 0.1125, validation loss: 0.0249
2024-05-22 22:34:52 [INFO]: Epoch 045 - generator training loss: -0.0391, discriminator training loss: 0.1117, validation loss: 0.0248
2024-05-22 22:34:59 [INFO]: Epoch 046 - generator training loss: -0.0398, discriminator training loss: 0.1106, validation loss: 0.0241
2024-05-22 22:35:06 [INFO]: Epoch 047 - generator training loss: -0.0413, discriminator training loss: 0.1107, validation loss: 0.0244
2024-05-22 22:35:13 [INFO]: Epoch 048 - generator training loss: -0.0389, discriminator training loss: 0.1096, validation loss: 0.0248
2024-05-22 22:35:20 [INFO]: Epoch 049 - generator training loss: -0.0394, discriminator training loss: 0.1084, validation loss: 0.0238
2024-05-22 22:35:27 [INFO]: Epoch 050 - generator training loss: -0.0418, discriminator training loss: 0.1109, validation loss: 0.0239
2024-05-22 22:35:34 [INFO]: Epoch 051 - generator training loss: -0.0427, discriminator training loss: 0.1085, validation loss: 0.0235
2024-05-22 22:35:41 [INFO]: Epoch 052 - generator training loss: -0.0424, discriminator training loss: 0.1077, validation loss: 0.0236
2024-05-22 22:35:49 [INFO]: Epoch 053 - generator training loss: -0.0443, discriminator training loss: 0.1094, validation loss: 0.0235
2024-05-22 22:35:56 [INFO]: Epoch 054 - generator training loss: -0.0416, discriminator training loss: 0.1070, validation loss: 0.0243
2024-05-22 22:36:03 [INFO]: Epoch 055 - generator training loss: -0.0403, discriminator training loss: 0.1094, validation loss: 0.0229
2024-05-22 22:36:10 [INFO]: Epoch 056 - generator training loss: -0.0406, discriminator training loss: 0.1091, validation loss: 0.0243
2024-05-22 22:36:17 [INFO]: Epoch 057 - generator training loss: -0.0411, discriminator training loss: 0.1092, validation loss: 0.0241
2024-05-22 22:36:24 [INFO]: Epoch 058 - generator training loss: -0.0423, discriminator training loss: 0.1095, validation loss: 0.0236
2024-05-22 22:36:31 [INFO]: Epoch 059 - generator training loss: -0.0426, discriminator training loss: 0.1086, validation loss: 0.0232
2024-05-22 22:36:38 [INFO]: Epoch 060 - generator training loss: -0.0427, discriminator training loss: 0.1103, validation loss: 0.0230
2024-05-22 22:36:45 [INFO]: Epoch 061 - generator training loss: -0.0439, discriminator training loss: 0.1114, validation loss: 0.0228
2024-05-22 22:36:53 [INFO]: Epoch 062 - generator training loss: -0.0466, discriminator training loss: 0.1120, validation loss: 0.0224
2024-05-22 22:37:00 [INFO]: Epoch 063 - generator training loss: -0.0453, discriminator training loss: 0.1108, validation loss: 0.0226
2024-05-22 22:37:07 [INFO]: Epoch 064 - generator training loss: -0.0445, discriminator training loss: 0.1094, validation loss: 0.0222
2024-05-22 22:37:14 [INFO]: Epoch 065 - generator training loss: -0.0437, discriminator training loss: 0.1058, validation loss: 0.0224
2024-05-22 22:37:21 [INFO]: Epoch 066 - generator training loss: -0.0440, discriminator training loss: 0.1081, validation loss: 0.0223
2024-05-22 22:37:29 [INFO]: Epoch 067 - generator training loss: -0.0460, discriminator training loss: 0.1082, validation loss: 0.0223
2024-05-22 22:37:36 [INFO]: Epoch 068 - generator training loss: -0.0445, discriminator training loss: 0.1072, validation loss: 0.0220
2024-05-22 22:37:43 [INFO]: Epoch 069 - generator training loss: -0.0429, discriminator training loss: 0.1076, validation loss: 0.0228
2024-05-22 22:37:50 [INFO]: Epoch 070 - generator training loss: -0.0428, discriminator training loss: 0.1092, validation loss: 0.0217
2024-05-22 22:37:57 [INFO]: Epoch 071 - generator training loss: -0.0408, discriminator training loss: 0.1091, validation loss: 0.0221
2024-05-22 22:38:04 [INFO]: Epoch 072 - generator training loss: -0.0411, discriminator training loss: 0.1080, validation loss: 0.0237
2024-05-22 22:38:11 [INFO]: Epoch 073 - generator training loss: -0.0449, discriminator training loss: 0.1083, validation loss: 0.0223
2024-05-22 22:38:18 [INFO]: Epoch 074 - generator training loss: -0.0451, discriminator training loss: 0.1092, validation loss: 0.0218
2024-05-22 22:38:25 [INFO]: Epoch 075 - generator training loss: -0.0431, discriminator training loss: 0.1079, validation loss: 0.0220
2024-05-22 22:38:32 [INFO]: Epoch 076 - generator training loss: -0.0443, discriminator training loss: 0.1068, validation loss: 0.0220
2024-05-22 22:38:39 [INFO]: Epoch 077 - generator training loss: -0.0458, discriminator training loss: 0.1051, validation loss: 0.0216
2024-05-22 22:38:47 [INFO]: Epoch 078 - generator training loss: -0.0456, discriminator training loss: 0.1075, validation loss: 0.0213
2024-05-22 22:38:54 [INFO]: Epoch 079 - generator training loss: -0.0460, discriminator training loss: 0.1058, validation loss: 0.0215
2024-05-22 22:39:01 [INFO]: Epoch 080 - generator training loss: -0.0468, discriminator training loss: 0.1068, validation loss: 0.0216
2024-05-22 22:39:08 [INFO]: Epoch 081 - generator training loss: -0.0438, discriminator training loss: 0.1061, validation loss: 0.0211
2024-05-22 22:39:15 [INFO]: Epoch 082 - generator training loss: -0.0447, discriminator training loss: 0.1058, validation loss: 0.0215
2024-05-22 22:39:22 [INFO]: Epoch 083 - generator training loss: -0.0444, discriminator training loss: 0.1075, validation loss: 0.0214
2024-05-22 22:39:29 [INFO]: Epoch 084 - generator training loss: -0.0473, discriminator training loss: 0.1074, validation loss: 0.0219
2024-05-22 22:39:36 [INFO]: Epoch 085 - generator training loss: -0.0463, discriminator training loss: 0.1100, validation loss: 0.0210
2024-05-22 22:39:43 [INFO]: Epoch 086 - generator training loss: -0.0464, discriminator training loss: 0.1071, validation loss: 0.0209
2024-05-22 22:39:51 [INFO]: Epoch 087 - generator training loss: -0.0470, discriminator training loss: 0.1076, validation loss: 0.0214
2024-05-22 22:39:59 [INFO]: Epoch 088 - generator training loss: -0.0458, discriminator training loss: 0.1088, validation loss: 0.0211
2024-05-22 22:40:06 [INFO]: Epoch 089 - generator training loss: -0.0467, discriminator training loss: 0.1048, validation loss: 0.0210
2024-05-22 22:40:13 [INFO]: Epoch 090 - generator training loss: -0.0476, discriminator training loss: 0.1048, validation loss: 0.0211
2024-05-22 22:40:21 [INFO]: Epoch 091 - generator training loss: -0.0462, discriminator training loss: 0.1092, validation loss: 0.0210
2024-05-22 22:40:28 [INFO]: Epoch 092 - generator training loss: -0.0452, discriminator training loss: 0.1065, validation loss: 0.0204
2024-05-22 22:40:35 [INFO]: Epoch 093 - generator training loss: -0.0452, discriminator training loss: 0.1065, validation loss: 0.0207
2024-05-22 22:40:42 [INFO]: Epoch 094 - generator training loss: -0.0457, discriminator training loss: 0.1062, validation loss: 0.0206
2024-05-22 22:40:49 [INFO]: Epoch 095 - generator training loss: -0.0466, discriminator training loss: 0.1079, validation loss: 0.0206
2024-05-22 22:40:56 [INFO]: Epoch 096 - generator training loss: -0.0464, discriminator training loss: 0.1067, validation loss: 0.0207
2024-05-22 22:41:03 [INFO]: Epoch 097 - generator training loss: -0.0469, discriminator training loss: 0.1056, validation loss: 0.0205
2024-05-22 22:41:10 [INFO]: Epoch 098 - generator training loss: -0.0471, discriminator training loss: 0.1072, validation loss: 0.0204
2024-05-22 22:41:17 [INFO]: Epoch 099 - generator training loss: -0.0454, discriminator training loss: 0.1070, validation loss: 0.0201
2024-05-22 22:41:24 [INFO]: Epoch 100 - generator training loss: -0.0485, discriminator training loss: 0.1057, validation loss: 0.0201
2024-05-22 22:41:32 [INFO]: Epoch 101 - generator training loss: -0.0477, discriminator training loss: 0.1041, validation loss: 0.0198
2024-05-22 22:41:39 [INFO]: Epoch 102 - generator training loss: -0.0463, discriminator training loss: 0.1069, validation loss: 0.0196
2024-05-22 22:41:46 [INFO]: Epoch 103 - generator training loss: -0.0437, discriminator training loss: 0.1068, validation loss: 0.0200
2024-05-22 22:41:53 [INFO]: Epoch 104 - generator training loss: -0.0469, discriminator training loss: 0.1059, validation loss: 0.0198
2024-05-22 22:42:00 [INFO]: Epoch 105 - generator training loss: -0.0450, discriminator training loss: 0.1055, validation loss: 0.0213
2024-05-22 22:42:07 [INFO]: Epoch 106 - generator training loss: -0.0478, discriminator training loss: 0.1068, validation loss: 0.0209
2024-05-22 22:42:15 [INFO]: Epoch 107 - generator training loss: -0.0459, discriminator training loss: 0.1039, validation loss: 0.0204
2024-05-22 22:42:22 [INFO]: Epoch 108 - generator training loss: -0.0499, discriminator training loss: 0.1067, validation loss: 0.0200
2024-05-22 22:42:29 [INFO]: Epoch 109 - generator training loss: -0.0451, discriminator training loss: 0.1059, validation loss: 0.0195
2024-05-22 22:42:36 [INFO]: Epoch 110 - generator training loss: -0.0458, discriminator training loss: 0.1044, validation loss: 0.0194
2024-05-22 22:42:43 [INFO]: Epoch 111 - generator training loss: -0.0459, discriminator training loss: 0.1043, validation loss: 0.0198
2024-05-22 22:42:51 [INFO]: Epoch 112 - generator training loss: -0.0498, discriminator training loss: 0.1060, validation loss: 0.0196
2024-05-22 22:42:58 [INFO]: Epoch 113 - generator training loss: -0.0484, discriminator training loss: 0.1066, validation loss: 0.0193
2024-05-22 22:43:05 [INFO]: Epoch 114 - generator training loss: -0.0456, discriminator training loss: 0.1056, validation loss: 0.0193
2024-05-22 22:43:12 [INFO]: Epoch 115 - generator training loss: -0.0500, discriminator training loss: 0.1078, validation loss: 0.0233
2024-05-22 22:43:19 [INFO]: Epoch 116 - generator training loss: -0.0474, discriminator training loss: 0.1050, validation loss: 0.0194
2024-05-22 22:43:26 [INFO]: Epoch 117 - generator training loss: -0.0501, discriminator training loss: 0.1084, validation loss: 0.0203
2024-05-22 22:43:33 [INFO]: Epoch 118 - generator training loss: -0.0483, discriminator training loss: 0.1083, validation loss: 0.0187
2024-05-22 22:43:40 [INFO]: Epoch 119 - generator training loss: -0.0500, discriminator training loss: 0.1067, validation loss: 0.0191
2024-05-22 22:43:47 [INFO]: Epoch 120 - generator training loss: -0.0493, discriminator training loss: 0.1037, validation loss: 0.0185
2024-05-22 22:43:54 [INFO]: Epoch 121 - generator training loss: -0.0476, discriminator training loss: 0.1077, validation loss: 0.0188
2024-05-22 22:44:02 [INFO]: Epoch 122 - generator training loss: -0.0484, discriminator training loss: 0.1040, validation loss: 0.0183
2024-05-22 22:44:09 [INFO]: Epoch 123 - generator training loss: -0.0528, discriminator training loss: 0.1062, validation loss: 0.0187
2024-05-22 22:44:16 [INFO]: Epoch 124 - generator training loss: -0.0468, discriminator training loss: 0.1061, validation loss: 0.0185
2024-05-22 22:44:23 [INFO]: Epoch 125 - generator training loss: -0.0517, discriminator training loss: 0.1053, validation loss: 0.0183
2024-05-22 22:44:30 [INFO]: Epoch 126 - generator training loss: -0.0507, discriminator training loss: 0.1065, validation loss: 0.0184
2024-05-22 22:44:37 [INFO]: Epoch 127 - generator training loss: -0.0486, discriminator training loss: 0.1031, validation loss: 0.0180
2024-05-22 22:44:45 [INFO]: Epoch 128 - generator training loss: -0.0499, discriminator training loss: 0.1066, validation loss: 0.0182
2024-05-22 22:44:52 [INFO]: Epoch 129 - generator training loss: -0.0512, discriminator training loss: 0.1044, validation loss: 0.0182
2024-05-22 22:45:00 [INFO]: Epoch 130 - generator training loss: -0.0491, discriminator training loss: 0.1025, validation loss: 0.0180
2024-05-22 22:45:07 [INFO]: Epoch 131 - generator training loss: -0.0504, discriminator training loss: 0.1057, validation loss: 0.0187
2024-05-22 22:45:15 [INFO]: Epoch 132 - generator training loss: -0.0482, discriminator training loss: 0.1049, validation loss: 0.0183
2024-05-22 22:45:22 [INFO]: Epoch 133 - generator training loss: -0.0502, discriminator training loss: 0.1043, validation loss: 0.0183
2024-05-22 22:45:29 [INFO]: Epoch 134 - generator training loss: -0.0487, discriminator training loss: 0.1055, validation loss: 0.0183
2024-05-22 22:45:36 [INFO]: Epoch 135 - generator training loss: -0.0473, discriminator training loss: 0.1037, validation loss: 0.0191
2024-05-22 22:45:43 [INFO]: Epoch 136 - generator training loss: -0.0498, discriminator training loss: 0.1049, validation loss: 0.0183
2024-05-22 22:45:51 [INFO]: Epoch 137 - generator training loss: -0.0497, discriminator training loss: 0.1035, validation loss: 0.0182
2024-05-22 22:45:58 [INFO]: Epoch 138 - generator training loss: -0.0502, discriminator training loss: 0.1039, validation loss: 0.0192
2024-05-22 22:46:05 [INFO]: Epoch 139 - generator training loss: -0.0526, discriminator training loss: 0.1063, validation loss: 0.0184
2024-05-22 22:46:12 [INFO]: Epoch 140 - generator training loss: -0.0490, discriminator training loss: 0.1023, validation loss: 0.0178
2024-05-22 22:46:19 [INFO]: Epoch 141 - generator training loss: -0.0502, discriminator training loss: 0.1067, validation loss: 0.0183
2024-05-22 22:46:26 [INFO]: Epoch 142 - generator training loss: -0.0490, discriminator training loss: 0.1039, validation loss: 0.0179
2024-05-22 22:46:34 [INFO]: Epoch 143 - generator training loss: -0.0485, discriminator training loss: 0.1046, validation loss: 0.0181
2024-05-22 22:46:41 [INFO]: Epoch 144 - generator training loss: -0.0507, discriminator training loss: 0.1060, validation loss: 0.0181
2024-05-22 22:46:48 [INFO]: Epoch 145 - generator training loss: -0.0500, discriminator training loss: 0.1029, validation loss: 0.0188
2024-05-22 22:46:55 [INFO]: Epoch 146 - generator training loss: -0.0499, discriminator training loss: 0.1040, validation loss: 0.0176
2024-05-22 22:47:02 [INFO]: Epoch 147 - generator training loss: -0.0500, discriminator training loss: 0.1057, validation loss: 0.0178
2024-05-22 22:47:10 [INFO]: Epoch 148 - generator training loss: -0.0484, discriminator training loss: 0.1041, validation loss: 0.0179
2024-05-22 22:47:17 [INFO]: Epoch 149 - generator training loss: -0.0501, discriminator training loss: 0.1038, validation loss: 0.0179
2024-05-22 22:47:24 [INFO]: Epoch 150 - generator training loss: -0.0508, discriminator training loss: 0.1031, validation loss: 0.0178
2024-05-22 22:47:31 [INFO]: Epoch 151 - generator training loss: -0.0487, discriminator training loss: 0.1020, validation loss: 0.0174
2024-05-22 22:47:38 [INFO]: Epoch 152 - generator training loss: -0.0523, discriminator training loss: 0.1036, validation loss: 0.0181
2024-05-22 22:47:46 [INFO]: Epoch 153 - generator training loss: -0.0498, discriminator training loss: 0.1046, validation loss: 0.0181
2024-05-22 22:47:53 [INFO]: Epoch 154 - generator training loss: -0.0500, discriminator training loss: 0.1042, validation loss: 0.0184
2024-05-22 22:48:00 [INFO]: Epoch 155 - generator training loss: -0.0476, discriminator training loss: 0.1060, validation loss: 0.0188
2024-05-22 22:48:07 [INFO]: Epoch 156 - generator training loss: -0.0499, discriminator training loss: 0.1052, validation loss: 0.0187
2024-05-22 22:48:14 [INFO]: Epoch 157 - generator training loss: -0.0488, discriminator training loss: 0.1045, validation loss: 0.0199
2024-05-22 22:48:22 [INFO]: Epoch 158 - generator training loss: -0.0500, discriminator training loss: 0.1040, validation loss: 0.0176
2024-05-22 22:48:29 [INFO]: Epoch 159 - generator training loss: -0.0469, discriminator training loss: 0.1031, validation loss: 0.0179
2024-05-22 22:48:36 [INFO]: Epoch 160 - generator training loss: -0.0511, discriminator training loss: 0.1037, validation loss: 0.0184
2024-05-22 22:48:43 [INFO]: Epoch 161 - generator training loss: -0.0480, discriminator training loss: 0.1037, validation loss: 0.0178
2024-05-22 22:48:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:48:43 [INFO]: Finished training. The best model is from epoch#151.
2024-05-22 22:48:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_ettm1/20240522_T222929/USGAN.pypots
2024-05-22 22:48:44 [INFO]: US-GAN on ETTm1: MAE=0.1587, MSE=0.0669
2024-05-22 22:48:44 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-22 22:48:44 [INFO]: Using the given device: cuda:0
2024-05-22 22:48:44 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240522_T224844
2024-05-22 22:48:44 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_ettm1/20240522_T224844/tensorboard
2024-05-22 22:48:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 22:48:50 [INFO]: Epoch 001 - training loss: 1.2980, validation loss: 0.2441
2024-05-22 22:48:54 [INFO]: Epoch 002 - training loss: 0.8721, validation loss: 0.0961
2024-05-22 22:48:59 [INFO]: Epoch 003 - training loss: 0.7070, validation loss: 0.0576
2024-05-22 22:49:04 [INFO]: Epoch 004 - training loss: 0.6326, validation loss: 0.0462
2024-05-22 22:49:09 [INFO]: Epoch 005 - training loss: 0.5782, validation loss: 0.0384
2024-05-22 22:49:14 [INFO]: Epoch 006 - training loss: 0.5456, validation loss: 0.0340
2024-05-22 22:49:19 [INFO]: Epoch 007 - training loss: 0.5148, validation loss: 0.0326
2024-05-22 22:49:24 [INFO]: Epoch 008 - training loss: 0.4912, validation loss: 0.0301
2024-05-22 22:49:28 [INFO]: Epoch 009 - training loss: 0.4672, validation loss: 0.0294
2024-05-22 22:49:33 [INFO]: Epoch 010 - training loss: 0.4562, validation loss: 0.0272
2024-05-22 22:49:38 [INFO]: Epoch 011 - training loss: 0.4371, validation loss: 0.0272
2024-05-22 22:49:43 [INFO]: Epoch 012 - training loss: 0.4359, validation loss: 0.0268
2024-05-22 22:49:48 [INFO]: Epoch 013 - training loss: 0.4148, validation loss: 0.0268
2024-05-22 22:49:52 [INFO]: Epoch 014 - training loss: 0.4160, validation loss: 0.0253
2024-05-22 22:49:57 [INFO]: Epoch 015 - training loss: 0.4101, validation loss: 0.0248
2024-05-22 22:50:02 [INFO]: Epoch 016 - training loss: 0.3993, validation loss: 0.0248
2024-05-22 22:50:07 [INFO]: Epoch 017 - training loss: 0.3949, validation loss: 0.0234
2024-05-22 22:50:11 [INFO]: Epoch 018 - training loss: 0.3882, validation loss: 0.0235
2024-05-22 22:50:16 [INFO]: Epoch 019 - training loss: 0.3871, validation loss: 0.0232
2024-05-22 22:50:21 [INFO]: Epoch 020 - training loss: 0.3916, validation loss: 0.0235
2024-05-22 22:50:26 [INFO]: Epoch 021 - training loss: 0.3855, validation loss: 0.0226
2024-05-22 22:50:30 [INFO]: Epoch 022 - training loss: 0.3908, validation loss: 0.0223
2024-05-22 22:50:35 [INFO]: Epoch 023 - training loss: 0.3858, validation loss: 0.0219
2024-05-22 22:50:40 [INFO]: Epoch 024 - training loss: 0.3936, validation loss: 0.0220
2024-05-22 22:50:45 [INFO]: Epoch 025 - training loss: 0.3832, validation loss: 0.0222
2024-05-22 22:50:49 [INFO]: Epoch 026 - training loss: 0.3828, validation loss: 0.0219
2024-05-22 22:50:54 [INFO]: Epoch 027 - training loss: 0.3824, validation loss: 0.0221
2024-05-22 22:50:59 [INFO]: Epoch 028 - training loss: 0.3815, validation loss: 0.0214
2024-05-22 22:51:04 [INFO]: Epoch 029 - training loss: 0.4410, validation loss: 0.0230
2024-05-22 22:51:09 [INFO]: Epoch 030 - training loss: 0.4131, validation loss: 0.0251
2024-05-22 22:51:13 [INFO]: Epoch 031 - training loss: 0.4072, validation loss: 0.0230
2024-05-22 22:51:18 [INFO]: Epoch 032 - training loss: 0.3908, validation loss: 0.0225
2024-05-22 22:51:23 [INFO]: Epoch 033 - training loss: 0.3958, validation loss: 0.0228
2024-05-22 22:51:28 [INFO]: Epoch 034 - training loss: 0.3835, validation loss: 0.0301
2024-05-22 22:51:32 [INFO]: Epoch 035 - training loss: 0.4001, validation loss: 0.0248
2024-05-22 22:51:37 [INFO]: Epoch 036 - training loss: 0.3862, validation loss: 0.0224
2024-05-22 22:51:42 [INFO]: Epoch 037 - training loss: 0.3867, validation loss: 0.0219
2024-05-22 22:51:47 [INFO]: Epoch 038 - training loss: 0.4377, validation loss: 0.0226
2024-05-22 22:51:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:51:47 [INFO]: Finished training. The best model is from epoch#28.
2024-05-22 22:51:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_ettm1/20240522_T224844/BRITS.pypots
2024-05-22 22:51:47 [INFO]: BRITS on ETTm1: MAE=0.1292, MSE=0.0471
2024-05-22 22:51:47 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-22 22:51:47 [INFO]: Using the given device: cuda:0
2024-05-22 22:51:47 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147
2024-05-22 22:51:47 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/tensorboard
2024-05-22 22:51:47 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 22:51:49 [INFO]: Epoch 001 - training loss: 1.4138, validation loss: 1.3360
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch1_loss1.3359984457492828.pypots
2024-05-22 22:51:49 [INFO]: Epoch 002 - training loss: 1.0533, validation loss: 1.1824
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch2_loss1.1823711395263672.pypots
2024-05-22 22:51:49 [INFO]: Epoch 003 - training loss: 0.9865, validation loss: 1.0971
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch3_loss1.0970682203769684.pypots
2024-05-22 22:51:49 [INFO]: Epoch 004 - training loss: 0.9798, validation loss: 1.0621
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch4_loss1.062079757452011.pypots
2024-05-22 22:51:49 [INFO]: Epoch 005 - training loss: 0.9442, validation loss: 1.0482
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch5_loss1.0482001602649689.pypots
2024-05-22 22:51:49 [INFO]: Epoch 006 - training loss: 0.9184, validation loss: 1.0430
2024-05-22 22:51:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch6_loss1.0429862439632416.pypots
2024-05-22 22:51:50 [INFO]: Epoch 007 - training loss: 0.8981, validation loss: 1.0276
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch7_loss1.0275527834892273.pypots
2024-05-22 22:51:50 [INFO]: Epoch 008 - training loss: 0.9377, validation loss: 1.0154
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch8_loss1.0153958350419998.pypots
2024-05-22 22:51:50 [INFO]: Epoch 009 - training loss: 0.8880, validation loss: 1.0091
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch9_loss1.0091332644224167.pypots
2024-05-22 22:51:50 [INFO]: Epoch 010 - training loss: 0.9039, validation loss: 1.0032
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch10_loss1.0031781941652298.pypots
2024-05-22 22:51:50 [INFO]: Epoch 011 - training loss: 0.9232, validation loss: 0.9999
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch11_loss0.9999241828918457.pypots
2024-05-22 22:51:50 [INFO]: Epoch 012 - training loss: 0.8839, validation loss: 0.9976
2024-05-22 22:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch12_loss0.9975875169038773.pypots
2024-05-22 22:51:51 [INFO]: Epoch 013 - training loss: 0.8904, validation loss: 0.9950
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch13_loss0.9950264543294907.pypots
2024-05-22 22:51:51 [INFO]: Epoch 014 - training loss: 0.8736, validation loss: 0.9931
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch14_loss0.9931356757879257.pypots
2024-05-22 22:51:51 [INFO]: Epoch 015 - training loss: 0.8749, validation loss: 0.9901
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch15_loss0.9900914132595062.pypots
2024-05-22 22:51:51 [INFO]: Epoch 016 - training loss: 0.8519, validation loss: 0.9927
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch16_loss0.9926746338605881.pypots
2024-05-22 22:51:51 [INFO]: Epoch 017 - training loss: 0.8406, validation loss: 0.9899
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch17_loss0.9898706823587418.pypots
2024-05-22 22:51:51 [INFO]: Epoch 018 - training loss: 0.8601, validation loss: 0.9846
2024-05-22 22:51:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch18_loss0.9845579564571381.pypots
2024-05-22 22:51:52 [INFO]: Epoch 019 - training loss: 0.8469, validation loss: 0.9838
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch19_loss0.9838490784168243.pypots
2024-05-22 22:51:52 [INFO]: Epoch 020 - training loss: 0.8286, validation loss: 0.9770
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch20_loss0.9769741743803024.pypots
2024-05-22 22:51:52 [INFO]: Epoch 021 - training loss: 0.8323, validation loss: 0.9730
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch21_loss0.9730442613363266.pypots
2024-05-22 22:51:52 [INFO]: Epoch 022 - training loss: 0.8629, validation loss: 0.9690
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch22_loss0.9690040349960327.pypots
2024-05-22 22:51:52 [INFO]: Epoch 023 - training loss: 0.8330, validation loss: 0.9647
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch23_loss0.9646658897399902.pypots
2024-05-22 22:51:52 [INFO]: Epoch 024 - training loss: 0.8405, validation loss: 0.9603
2024-05-22 22:51:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch24_loss0.9603233486413956.pypots
2024-05-22 22:51:53 [INFO]: Epoch 025 - training loss: 0.8061, validation loss: 0.9573
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch25_loss0.9573336690664291.pypots
2024-05-22 22:51:53 [INFO]: Epoch 026 - training loss: 0.8248, validation loss: 0.9541
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch26_loss0.9540817886590958.pypots
2024-05-22 22:51:53 [INFO]: Epoch 027 - training loss: 0.8176, validation loss: 0.9530
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch27_loss0.9529656320810318.pypots
2024-05-22 22:51:53 [INFO]: Epoch 028 - training loss: 0.8136, validation loss: 0.9472
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch28_loss0.9471743851900101.pypots
2024-05-22 22:51:53 [INFO]: Epoch 029 - training loss: 0.8091, validation loss: 0.9439
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch29_loss0.9439079910516739.pypots
2024-05-22 22:51:53 [INFO]: Epoch 030 - training loss: 0.7932, validation loss: 0.9407
2024-05-22 22:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch30_loss0.9406968057155609.pypots
2024-05-22 22:51:54 [INFO]: Epoch 031 - training loss: 0.8273, validation loss: 0.9395
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch31_loss0.9395066052675247.pypots
2024-05-22 22:51:54 [INFO]: Epoch 032 - training loss: 0.8174, validation loss: 0.9350
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch32_loss0.9349946081638336.pypots
2024-05-22 22:51:54 [INFO]: Epoch 033 - training loss: 0.7887, validation loss: 0.9316
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch33_loss0.9316005706787109.pypots
2024-05-22 22:51:54 [INFO]: Epoch 034 - training loss: 0.8134, validation loss: 0.9336
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch34_loss0.9335865825414658.pypots
2024-05-22 22:51:54 [INFO]: Epoch 035 - training loss: 0.8222, validation loss: 0.9250
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch35_loss0.925031840801239.pypots
2024-05-22 22:51:54 [INFO]: Epoch 036 - training loss: 0.7963, validation loss: 0.9225
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch36_loss0.9225387573242188.pypots
2024-05-22 22:51:54 [INFO]: Epoch 037 - training loss: 0.8142, validation loss: 0.9191
2024-05-22 22:51:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch37_loss0.9191354811191559.pypots
2024-05-22 22:51:55 [INFO]: Epoch 038 - training loss: 0.8131, validation loss: 0.9139
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch38_loss0.9139007925987244.pypots
2024-05-22 22:51:55 [INFO]: Epoch 039 - training loss: 0.7836, validation loss: 0.9118
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch39_loss0.9118217080831528.pypots
2024-05-22 22:51:55 [INFO]: Epoch 040 - training loss: 0.7968, validation loss: 0.9098
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch40_loss0.9098368883132935.pypots
2024-05-22 22:51:55 [INFO]: Epoch 041 - training loss: 0.8036, validation loss: 0.9103
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch41_loss0.910308226943016.pypots
2024-05-22 22:51:55 [INFO]: Epoch 042 - training loss: 0.7993, validation loss: 0.9042
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch42_loss0.9041991978883743.pypots
2024-05-22 22:51:55 [INFO]: Epoch 043 - training loss: 0.7825, validation loss: 0.9009
2024-05-22 22:51:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch43_loss0.9009046107530594.pypots
2024-05-22 22:51:56 [INFO]: Epoch 044 - training loss: 0.7788, validation loss: 0.8997
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch44_loss0.8996943086385727.pypots
2024-05-22 22:51:56 [INFO]: Epoch 045 - training loss: 0.7879, validation loss: 0.8950
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch45_loss0.8950449824333191.pypots
2024-05-22 22:51:56 [INFO]: Epoch 046 - training loss: 0.8001, validation loss: 0.8937
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch46_loss0.8937429487705231.pypots
2024-05-22 22:51:56 [INFO]: Epoch 047 - training loss: 0.7949, validation loss: 0.8934
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch47_loss0.893410861492157.pypots
2024-05-22 22:51:56 [INFO]: Epoch 048 - training loss: 0.7858, validation loss: 0.8920
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch48_loss0.8919569104909897.pypots
2024-05-22 22:51:56 [INFO]: Epoch 049 - training loss: 0.7769, validation loss: 0.8893
2024-05-22 22:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch49_loss0.8893389701843262.pypots
2024-05-22 22:51:57 [INFO]: Epoch 050 - training loss: 0.7901, validation loss: 0.8872
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch50_loss0.8871999233961105.pypots
2024-05-22 22:51:57 [INFO]: Epoch 051 - training loss: 0.7753, validation loss: 0.8859
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch51_loss0.88587886095047.pypots
2024-05-22 22:51:57 [INFO]: Epoch 052 - training loss: 0.7824, validation loss: 0.8845
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch52_loss0.8844768553972244.pypots
2024-05-22 22:51:57 [INFO]: Epoch 053 - training loss: 0.7789, validation loss: 0.8833
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch53_loss0.8832665234804153.pypots
2024-05-22 22:51:57 [INFO]: Epoch 054 - training loss: 0.7758, validation loss: 0.8826
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch54_loss0.882645770907402.pypots
2024-05-22 22:51:57 [INFO]: Epoch 055 - training loss: 0.8269, validation loss: 0.8815
2024-05-22 22:51:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch55_loss0.8814762085676193.pypots
2024-05-22 22:51:58 [INFO]: Epoch 056 - training loss: 0.7940, validation loss: 0.8801
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch56_loss0.8800706714391708.pypots
2024-05-22 22:51:58 [INFO]: Epoch 057 - training loss: 0.8061, validation loss: 0.8786
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch57_loss0.8786372542381287.pypots
2024-05-22 22:51:58 [INFO]: Epoch 058 - training loss: 0.7837, validation loss: 0.8742
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch58_loss0.8741672933101654.pypots
2024-05-22 22:51:58 [INFO]: Epoch 059 - training loss: 0.8004, validation loss: 0.8749
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch59_loss0.874948114156723.pypots
2024-05-22 22:51:58 [INFO]: Epoch 060 - training loss: 0.7945, validation loss: 0.8739
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch60_loss0.873938575387001.pypots
2024-05-22 22:51:58 [INFO]: Epoch 061 - training loss: 0.7690, validation loss: 0.8737
2024-05-22 22:51:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch61_loss0.8737012445926666.pypots
2024-05-22 22:51:59 [INFO]: Epoch 062 - training loss: 0.7635, validation loss: 0.8728
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch62_loss0.8728471100330353.pypots
2024-05-22 22:51:59 [INFO]: Epoch 063 - training loss: 0.7838, validation loss: 0.8727
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch63_loss0.8726672977209091.pypots
2024-05-22 22:51:59 [INFO]: Epoch 064 - training loss: 0.7794, validation loss: 0.8702
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch64_loss0.8702329099178314.pypots
2024-05-22 22:51:59 [INFO]: Epoch 065 - training loss: 0.7744, validation loss: 0.8696
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch65_loss0.8696256577968597.pypots
2024-05-22 22:51:59 [INFO]: Epoch 066 - training loss: 0.7865, validation loss: 0.8681
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch66_loss0.8680891394615173.pypots
2024-05-22 22:51:59 [INFO]: Epoch 067 - training loss: 0.7793, validation loss: 0.8680
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch67_loss0.867967426776886.pypots
2024-05-22 22:51:59 [INFO]: Epoch 068 - training loss: 0.7597, validation loss: 0.8695
2024-05-22 22:51:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch68_loss0.8694674074649811.pypots
2024-05-22 22:52:00 [INFO]: Epoch 069 - training loss: 0.7717, validation loss: 0.8678
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch69_loss0.867762878537178.pypots
2024-05-22 22:52:00 [INFO]: Epoch 070 - training loss: 0.7667, validation loss: 0.8633
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch70_loss0.863260954618454.pypots
2024-05-22 22:52:00 [INFO]: Epoch 071 - training loss: 0.8000, validation loss: 0.8639
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch71_loss0.8638961315155029.pypots
2024-05-22 22:52:00 [INFO]: Epoch 072 - training loss: 0.7887, validation loss: 0.8638
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch72_loss0.8637965172529221.pypots
2024-05-22 22:52:00 [INFO]: Epoch 073 - training loss: 0.7749, validation loss: 0.8619
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch73_loss0.861866295337677.pypots
2024-05-22 22:52:00 [INFO]: Epoch 074 - training loss: 0.7727, validation loss: 0.8626
2024-05-22 22:52:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch74_loss0.8626267462968826.pypots
2024-05-22 22:52:01 [INFO]: Epoch 075 - training loss: 0.8066, validation loss: 0.8626
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch75_loss0.8626199513673782.pypots
2024-05-22 22:52:01 [INFO]: Epoch 076 - training loss: 0.7738, validation loss: 0.8617
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch76_loss0.8616624623537064.pypots
2024-05-22 22:52:01 [INFO]: Epoch 077 - training loss: 0.7824, validation loss: 0.8606
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch77_loss0.8605940788984299.pypots
2024-05-22 22:52:01 [INFO]: Epoch 078 - training loss: 0.7691, validation loss: 0.8574
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch78_loss0.8573978990316391.pypots
2024-05-22 22:52:01 [INFO]: Epoch 079 - training loss: 0.7651, validation loss: 0.8593
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch79_loss0.859296053647995.pypots
2024-05-22 22:52:01 [INFO]: Epoch 080 - training loss: 0.7733, validation loss: 0.8572
2024-05-22 22:52:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch80_loss0.8571524620056152.pypots
2024-05-22 22:52:02 [INFO]: Epoch 081 - training loss: 0.7562, validation loss: 0.8580
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch81_loss0.8580340296030045.pypots
2024-05-22 22:52:02 [INFO]: Epoch 082 - training loss: 0.7968, validation loss: 0.8556
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch82_loss0.8555601239204407.pypots
2024-05-22 22:52:02 [INFO]: Epoch 083 - training loss: 0.7618, validation loss: 0.8556
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch83_loss0.8556088805198669.pypots
2024-05-22 22:52:02 [INFO]: Epoch 084 - training loss: 0.7668, validation loss: 0.8543
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch84_loss0.8543294072151184.pypots
2024-05-22 22:52:02 [INFO]: Epoch 085 - training loss: 0.7694, validation loss: 0.8537
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch85_loss0.8537227362394333.pypots
2024-05-22 22:52:02 [INFO]: Epoch 086 - training loss: 0.7822, validation loss: 0.8529
2024-05-22 22:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch86_loss0.8529131263494492.pypots
2024-05-22 22:52:03 [INFO]: Epoch 087 - training loss: 0.7676, validation loss: 0.8523
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch87_loss0.8522561490535736.pypots
2024-05-22 22:52:03 [INFO]: Epoch 088 - training loss: 0.7582, validation loss: 0.8517
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch88_loss0.8517104983329773.pypots
2024-05-22 22:52:03 [INFO]: Epoch 089 - training loss: 0.7607, validation loss: 0.8491
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch89_loss0.8491480797529221.pypots
2024-05-22 22:52:03 [INFO]: Epoch 090 - training loss: 0.7749, validation loss: 0.8500
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch90_loss0.8499691933393478.pypots
2024-05-22 22:52:03 [INFO]: Epoch 091 - training loss: 0.7834, validation loss: 0.8468
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch91_loss0.8468087315559387.pypots
2024-05-22 22:52:03 [INFO]: Epoch 092 - training loss: 0.7834, validation loss: 0.8497
2024-05-22 22:52:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch92_loss0.849700465798378.pypots
2024-05-22 22:52:04 [INFO]: Epoch 093 - training loss: 0.7595, validation loss: 0.8474
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch93_loss0.8474221378564835.pypots
2024-05-22 22:52:04 [INFO]: Epoch 094 - training loss: 0.7891, validation loss: 0.8456
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch94_loss0.8455746173858643.pypots
2024-05-22 22:52:04 [INFO]: Epoch 095 - training loss: 0.7603, validation loss: 0.8488
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch95_loss0.8487720340490341.pypots
2024-05-22 22:52:04 [INFO]: Epoch 096 - training loss: 0.7530, validation loss: 0.8464
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch96_loss0.8464418053627014.pypots
2024-05-22 22:52:04 [INFO]: Epoch 097 - training loss: 0.7831, validation loss: 0.8468
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch97_loss0.8467519134283066.pypots
2024-05-22 22:52:04 [INFO]: Epoch 098 - training loss: 0.7814, validation loss: 0.8458
2024-05-22 22:52:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch98_loss0.8457871228456497.pypots
2024-05-22 22:52:05 [INFO]: Epoch 099 - training loss: 0.7619, validation loss: 0.8453
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch99_loss0.8452838659286499.pypots
2024-05-22 22:52:05 [INFO]: Epoch 100 - training loss: 0.7469, validation loss: 0.8441
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch100_loss0.8440997451543808.pypots
2024-05-22 22:52:05 [INFO]: Epoch 101 - training loss: 0.7707, validation loss: 0.8473
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch101_loss0.8473089337348938.pypots
2024-05-22 22:52:05 [INFO]: Epoch 102 - training loss: 0.8156, validation loss: 0.8419
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch102_loss0.8418746590614319.pypots
2024-05-22 22:52:05 [INFO]: Epoch 103 - training loss: 0.7838, validation loss: 0.8440
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch103_loss0.8440241366624832.pypots
2024-05-22 22:52:05 [INFO]: Epoch 104 - training loss: 0.7630, validation loss: 0.8425
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch104_loss0.8424653559923172.pypots
2024-05-22 22:52:05 [INFO]: Epoch 105 - training loss: 0.7644, validation loss: 0.8447
2024-05-22 22:52:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch105_loss0.8446809202432632.pypots
2024-05-22 22:52:06 [INFO]: Epoch 106 - training loss: 0.8084, validation loss: 0.8457
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch106_loss0.8456756472587585.pypots
2024-05-22 22:52:06 [INFO]: Epoch 107 - training loss: 0.7732, validation loss: 0.8417
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch107_loss0.8417186588048935.pypots
2024-05-22 22:52:06 [INFO]: Epoch 108 - training loss: 0.7818, validation loss: 0.8441
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch108_loss0.8440979272127151.pypots
2024-05-22 22:52:06 [INFO]: Epoch 109 - training loss: 0.8140, validation loss: 0.8417
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch109_loss0.8417373150587082.pypots
2024-05-22 22:52:06 [INFO]: Epoch 110 - training loss: 0.7956, validation loss: 0.8453
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch110_loss0.8453378528356552.pypots
2024-05-22 22:52:06 [INFO]: Epoch 111 - training loss: 0.7863, validation loss: 0.8442
2024-05-22 22:52:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch111_loss0.8441885113716125.pypots
2024-05-22 22:52:07 [INFO]: Epoch 112 - training loss: 0.7792, validation loss: 0.8438
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch112_loss0.8437781780958176.pypots
2024-05-22 22:52:07 [INFO]: Epoch 113 - training loss: 0.7764, validation loss: 0.8420
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch113_loss0.8420181572437286.pypots
2024-05-22 22:52:07 [INFO]: Epoch 114 - training loss: 0.7599, validation loss: 0.8426
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch114_loss0.8425861150026321.pypots
2024-05-22 22:52:07 [INFO]: Epoch 115 - training loss: 0.7821, validation loss: 0.8391
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch115_loss0.839053213596344.pypots
2024-05-22 22:52:07 [INFO]: Epoch 116 - training loss: 0.7582, validation loss: 0.8402
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch116_loss0.8401597440242767.pypots
2024-05-22 22:52:07 [INFO]: Epoch 117 - training loss: 0.7718, validation loss: 0.8398
2024-05-22 22:52:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch117_loss0.839761421084404.pypots
2024-05-22 22:52:08 [INFO]: Epoch 118 - training loss: 0.7645, validation loss: 0.8375
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch118_loss0.8375252783298492.pypots
2024-05-22 22:52:08 [INFO]: Epoch 119 - training loss: 0.7779, validation loss: 0.8383
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch119_loss0.8383249342441559.pypots
2024-05-22 22:52:08 [INFO]: Epoch 120 - training loss: 0.7671, validation loss: 0.8382
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch120_loss0.8382321447134018.pypots
2024-05-22 22:52:08 [INFO]: Epoch 121 - training loss: 0.7686, validation loss: 0.8395
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch121_loss0.839547798037529.pypots
2024-05-22 22:52:08 [INFO]: Epoch 122 - training loss: 0.8120, validation loss: 0.8370
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch122_loss0.8369540870189667.pypots
2024-05-22 22:52:08 [INFO]: Epoch 123 - training loss: 0.7583, validation loss: 0.8429
2024-05-22 22:52:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch123_loss0.8428754061460495.pypots
2024-05-22 22:52:09 [INFO]: Epoch 124 - training loss: 0.7513, validation loss: 0.8351
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch124_loss0.8350810110569.pypots
2024-05-22 22:52:09 [INFO]: Epoch 125 - training loss: 0.7608, validation loss: 0.8410
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch125_loss0.8409643173217773.pypots
2024-05-22 22:52:09 [INFO]: Epoch 126 - training loss: 0.7720, validation loss: 0.8335
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch126_loss0.8334773033857346.pypots
2024-05-22 22:52:09 [INFO]: Epoch 127 - training loss: 0.7753, validation loss: 0.8359
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch127_loss0.8359358459711075.pypots
2024-05-22 22:52:09 [INFO]: Epoch 128 - training loss: 0.7711, validation loss: 0.8356
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch128_loss0.835576593875885.pypots
2024-05-22 22:52:09 [INFO]: Epoch 129 - training loss: 0.7682, validation loss: 0.8368
2024-05-22 22:52:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch129_loss0.8367977738380432.pypots
2024-05-22 22:52:10 [INFO]: Epoch 130 - training loss: 0.7857, validation loss: 0.8342
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch130_loss0.8341980129480362.pypots
2024-05-22 22:52:10 [INFO]: Epoch 131 - training loss: 0.7409, validation loss: 0.8374
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch131_loss0.8374008536338806.pypots
2024-05-22 22:52:10 [INFO]: Epoch 132 - training loss: 0.7542, validation loss: 0.8334
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch132_loss0.8333608955144882.pypots
2024-05-22 22:52:10 [INFO]: Epoch 133 - training loss: 0.7631, validation loss: 0.8342
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch133_loss0.8341533839702606.pypots
2024-05-22 22:52:10 [INFO]: Epoch 134 - training loss: 0.7663, validation loss: 0.8315
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch134_loss0.8314659148454666.pypots
2024-05-22 22:52:10 [INFO]: Epoch 135 - training loss: 0.7568, validation loss: 0.8344
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch135_loss0.8344120383262634.pypots
2024-05-22 22:52:10 [INFO]: Epoch 136 - training loss: 0.7550, validation loss: 0.8325
2024-05-22 22:52:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch136_loss0.8325332850217819.pypots
2024-05-22 22:52:11 [INFO]: Epoch 137 - training loss: 0.7621, validation loss: 0.8311
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch137_loss0.8311142325401306.pypots
2024-05-22 22:52:11 [INFO]: Epoch 138 - training loss: 0.7756, validation loss: 0.8324
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch138_loss0.8324337899684906.pypots
2024-05-22 22:52:11 [INFO]: Epoch 139 - training loss: 0.7457, validation loss: 0.8306
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch139_loss0.8306097239255905.pypots
2024-05-22 22:52:11 [INFO]: Epoch 140 - training loss: 0.7661, validation loss: 0.8352
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch140_loss0.8351653665304184.pypots
2024-05-22 22:52:11 [INFO]: Epoch 141 - training loss: 0.7410, validation loss: 0.8311
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch141_loss0.8311328440904617.pypots
2024-05-22 22:52:11 [INFO]: Epoch 142 - training loss: 0.7529, validation loss: 0.8324
2024-05-22 22:52:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch142_loss0.8323688954114914.pypots
2024-05-22 22:52:12 [INFO]: Epoch 143 - training loss: 0.7670, validation loss: 0.8293
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch143_loss0.8292777240276337.pypots
2024-05-22 22:52:12 [INFO]: Epoch 144 - training loss: 0.7703, validation loss: 0.8295
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch144_loss0.829511895775795.pypots
2024-05-22 22:52:12 [INFO]: Epoch 145 - training loss: 0.7506, validation loss: 0.8306
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch145_loss0.8305532783269882.pypots
2024-05-22 22:52:12 [INFO]: Epoch 146 - training loss: 0.7533, validation loss: 0.8312
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch146_loss0.8311943858861923.pypots
2024-05-22 22:52:12 [INFO]: Epoch 147 - training loss: 0.7605, validation loss: 0.8276
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch147_loss0.8275574892759323.pypots
2024-05-22 22:52:12 [INFO]: Epoch 148 - training loss: 0.7832, validation loss: 0.8299
2024-05-22 22:52:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch148_loss0.8299318104982376.pypots
2024-05-22 22:52:13 [INFO]: Epoch 149 - training loss: 0.7516, validation loss: 0.8302
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch149_loss0.8301514536142349.pypots
2024-05-22 22:52:13 [INFO]: Epoch 150 - training loss: 0.7476, validation loss: 0.8310
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch150_loss0.8309770226478577.pypots
2024-05-22 22:52:13 [INFO]: Epoch 151 - training loss: 0.7762, validation loss: 0.8288
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch151_loss0.8288109004497528.pypots
2024-05-22 22:52:13 [INFO]: Epoch 152 - training loss: 0.7484, validation loss: 0.8271
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch152_loss0.8270841240882874.pypots
2024-05-22 22:52:13 [INFO]: Epoch 153 - training loss: 0.7647, validation loss: 0.8347
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch153_loss0.834697350859642.pypots
2024-05-22 22:52:13 [INFO]: Epoch 154 - training loss: 0.7660, validation loss: 0.8247
2024-05-22 22:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch154_loss0.8247138857841492.pypots
2024-05-22 22:52:14 [INFO]: Epoch 155 - training loss: 0.7525, validation loss: 0.8320
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch155_loss0.8320181220769882.pypots
2024-05-22 22:52:14 [INFO]: Epoch 156 - training loss: 0.7664, validation loss: 0.8286
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch156_loss0.828609436750412.pypots
2024-05-22 22:52:14 [INFO]: Epoch 157 - training loss: 0.7863, validation loss: 0.8274
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch157_loss0.8273600786924362.pypots
2024-05-22 22:52:14 [INFO]: Epoch 158 - training loss: 0.7529, validation loss: 0.8279
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch158_loss0.827882930636406.pypots
2024-05-22 22:52:14 [INFO]: Epoch 159 - training loss: 0.7668, validation loss: 0.8272
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch159_loss0.8271578252315521.pypots
2024-05-22 22:52:14 [INFO]: Epoch 160 - training loss: 0.7531, validation loss: 0.8245
2024-05-22 22:52:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch160_loss0.8244753032922745.pypots
2024-05-22 22:52:15 [INFO]: Epoch 161 - training loss: 0.7378, validation loss: 0.8244
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch161_loss0.8244247138500214.pypots
2024-05-22 22:52:15 [INFO]: Epoch 162 - training loss: 0.7610, validation loss: 0.8255
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch162_loss0.825547382235527.pypots
2024-05-22 22:52:15 [INFO]: Epoch 163 - training loss: 0.7896, validation loss: 0.8215
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch163_loss0.8214815557003021.pypots
2024-05-22 22:52:15 [INFO]: Epoch 164 - training loss: 0.7811, validation loss: 0.8235
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch164_loss0.823461040854454.pypots
2024-05-22 22:52:15 [INFO]: Epoch 165 - training loss: 0.7811, validation loss: 0.8241
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch165_loss0.8241205960512161.pypots
2024-05-22 22:52:15 [INFO]: Epoch 166 - training loss: 0.7611, validation loss: 0.8222
2024-05-22 22:52:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch166_loss0.8221534639596939.pypots
2024-05-22 22:52:16 [INFO]: Epoch 167 - training loss: 0.7628, validation loss: 0.8176
2024-05-22 22:52:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch167_loss0.8176190108060837.pypots
2024-05-22 22:52:16 [INFO]: Epoch 168 - training loss: 0.7657, validation loss: 0.8202
2024-05-22 22:52:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch168_loss0.8201786428689957.pypots
2024-05-22 22:52:16 [INFO]: Epoch 169 - training loss: 0.7493, validation loss: 0.8224
2024-05-22 22:52:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch169_loss0.8224488198757172.pypots
2024-05-22 22:52:16 [INFO]: Epoch 170 - training loss: 0.7514, validation loss: 0.8229
2024-05-22 22:52:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch170_loss0.8229436427354813.pypots
2024-05-22 22:52:16 [INFO]: Epoch 171 - training loss: 0.7571, validation loss: 0.8228
2024-05-22 22:52:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch171_loss0.8227516859769821.pypots
2024-05-22 22:52:17 [INFO]: Epoch 172 - training loss: 0.7470, validation loss: 0.8216
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch172_loss0.8215619623661041.pypots
2024-05-22 22:52:17 [INFO]: Epoch 173 - training loss: 0.7705, validation loss: 0.8203
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch173_loss0.8202913105487823.pypots
2024-05-22 22:52:17 [INFO]: Epoch 174 - training loss: 0.7488, validation loss: 0.8196
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch174_loss0.8196144849061966.pypots
2024-05-22 22:52:17 [INFO]: Epoch 175 - training loss: 0.7740, validation loss: 0.8202
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch175_loss0.8202043920755386.pypots
2024-05-22 22:52:17 [INFO]: Epoch 176 - training loss: 0.7602, validation loss: 0.8171
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch176_loss0.8170720338821411.pypots
2024-05-22 22:52:17 [INFO]: Epoch 177 - training loss: 0.7706, validation loss: 0.8215
2024-05-22 22:52:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch177_loss0.821461483836174.pypots
2024-05-22 22:52:18 [INFO]: Epoch 178 - training loss: 0.7813, validation loss: 0.8129
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch178_loss0.8129489421844482.pypots
2024-05-22 22:52:18 [INFO]: Epoch 179 - training loss: 0.7707, validation loss: 0.8171
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch179_loss0.8170546144247055.pypots
2024-05-22 22:52:18 [INFO]: Epoch 180 - training loss: 0.7625, validation loss: 0.8165
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch180_loss0.816451907157898.pypots
2024-05-22 22:52:18 [INFO]: Epoch 181 - training loss: 0.7662, validation loss: 0.8123
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch181_loss0.8122946321964264.pypots
2024-05-22 22:52:18 [INFO]: Epoch 182 - training loss: 0.7459, validation loss: 0.8149
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch182_loss0.8148958534002304.pypots
2024-05-22 22:52:18 [INFO]: Epoch 183 - training loss: 0.7415, validation loss: 0.8168
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch183_loss0.816834956407547.pypots
2024-05-22 22:52:18 [INFO]: Epoch 184 - training loss: 0.7805, validation loss: 0.8180
2024-05-22 22:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch184_loss0.8180420100688934.pypots
2024-05-22 22:52:19 [INFO]: Epoch 185 - training loss: 0.7726, validation loss: 0.8142
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch185_loss0.814245879650116.pypots
2024-05-22 22:52:19 [INFO]: Epoch 186 - training loss: 0.7491, validation loss: 0.8138
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch186_loss0.8138378858566284.pypots
2024-05-22 22:52:19 [INFO]: Epoch 187 - training loss: 0.7420, validation loss: 0.8152
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch187_loss0.815169021487236.pypots
2024-05-22 22:52:19 [INFO]: Epoch 188 - training loss: 0.7555, validation loss: 0.8165
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch188_loss0.8165185004472733.pypots
2024-05-22 22:52:19 [INFO]: Epoch 189 - training loss: 0.7652, validation loss: 0.8156
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch189_loss0.8156420290470123.pypots
2024-05-22 22:52:19 [INFO]: Epoch 190 - training loss: 0.7621, validation loss: 0.8131
2024-05-22 22:52:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch190_loss0.8130584061145782.pypots
2024-05-22 22:52:20 [INFO]: Epoch 191 - training loss: 0.7507, validation loss: 0.8133
2024-05-22 22:52:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN_epoch191_loss0.8133355379104614.pypots
2024-05-22 22:52:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:52:20 [INFO]: Finished training. The best model is from epoch#181.
2024-05-22 22:52:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_ettm1/20240522_T225147/MRNN.pypots
2024-05-22 22:52:20 [INFO]: MRNN on ETTm1: MAE=0.6313, MSE=1.0473
2024-05-22 22:52:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-22 22:52:20 [INFO]: Using the given device: cpu
2024-05-22 22:52:20 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 22:52:20 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-22 22:52:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-22 22:52:20 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 22:52:20 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-22 22:52:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-22 22:52:20 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 22:52:20 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-22 22:52:20 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-22 22:52:20 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-22 22:52:20 [INFO]: Using the given device: cuda:0
2024-05-22 22:52:20 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240522_T225220
2024-05-22 22:52:20 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_ettm1/20240522_T225220/tensorboard
2024-05-22 22:52:20 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-22 22:52:20 [INFO]: Epoch 001 - training loss: 1.1532, validation loss: 0.2587
2024-05-22 22:52:21 [INFO]: Epoch 002 - training loss: 0.8655, validation loss: 0.1285
2024-05-22 22:52:21 [INFO]: Epoch 003 - training loss: 0.7819, validation loss: 0.0908
2024-05-22 22:52:22 [INFO]: Epoch 004 - training loss: 0.7383, validation loss: 0.0763
2024-05-22 22:52:22 [INFO]: Epoch 005 - training loss: 0.7119, validation loss: 0.0799
2024-05-22 22:52:23 [INFO]: Epoch 006 - training loss: 0.6947, validation loss: 0.0777
2024-05-22 22:52:23 [INFO]: Epoch 007 - training loss: 0.6593, validation loss: 0.0632
2024-05-22 22:52:24 [INFO]: Epoch 008 - training loss: 0.6453, validation loss: 0.0670
2024-05-22 22:52:24 [INFO]: Epoch 009 - training loss: 0.6253, validation loss: 0.0652
2024-05-22 22:52:25 [INFO]: Epoch 010 - training loss: 0.6068, validation loss: 0.0499
2024-05-22 22:52:25 [INFO]: Epoch 011 - training loss: 0.6067, validation loss: 0.0491
2024-05-22 22:52:26 [INFO]: Epoch 012 - training loss: 0.5933, validation loss: 0.0616
2024-05-22 22:52:26 [INFO]: Epoch 013 - training loss: 0.5907, validation loss: 0.0755
2024-05-22 22:52:27 [INFO]: Epoch 014 - training loss: 0.5901, validation loss: 0.0674
2024-05-22 22:52:27 [INFO]: Epoch 015 - training loss: 0.6054, validation loss: 0.0569
2024-05-22 22:52:28 [INFO]: Epoch 016 - training loss: 0.6025, validation loss: 0.0574
2024-05-22 22:52:28 [INFO]: Epoch 017 - training loss: 0.5886, validation loss: 0.0515
2024-05-22 22:52:29 [INFO]: Epoch 018 - training loss: 0.5836, validation loss: 0.0802
2024-05-22 22:52:29 [INFO]: Epoch 019 - training loss: 0.5632, validation loss: 0.0435
2024-05-22 22:52:30 [INFO]: Epoch 020 - training loss: 0.5446, validation loss: 0.0474
2024-05-22 22:52:30 [INFO]: Epoch 021 - training loss: 0.5451, validation loss: 0.0378
2024-05-22 22:52:31 [INFO]: Epoch 022 - training loss: 0.5359, validation loss: 0.0432
2024-05-22 22:52:31 [INFO]: Epoch 023 - training loss: 0.5401, validation loss: 0.0445
2024-05-22 22:52:31 [INFO]: Epoch 024 - training loss: 0.5360, validation loss: 0.0376
2024-05-22 22:52:32 [INFO]: Epoch 025 - training loss: 0.5233, validation loss: 0.0452
2024-05-22 22:52:32 [INFO]: Epoch 026 - training loss: 0.5180, validation loss: 0.0355
2024-05-22 22:52:33 [INFO]: Epoch 027 - training loss: 0.5137, validation loss: 0.0350
2024-05-22 22:52:33 [INFO]: Epoch 028 - training loss: 0.5304, validation loss: 0.0360
2024-05-22 22:52:34 [INFO]: Epoch 029 - training loss: 0.5243, validation loss: 0.0378
2024-05-22 22:52:34 [INFO]: Epoch 030 - training loss: 0.5036, validation loss: 0.0423
2024-05-22 22:52:35 [INFO]: Epoch 031 - training loss: 0.4992, validation loss: 0.0429
2024-05-22 22:52:35 [INFO]: Epoch 032 - training loss: 0.4980, validation loss: 0.0385
2024-05-22 22:52:36 [INFO]: Epoch 033 - training loss: 0.5066, validation loss: 0.0330
2024-05-22 22:52:36 [INFO]: Epoch 034 - training loss: 0.5113, validation loss: 0.0326
2024-05-22 22:52:37 [INFO]: Epoch 035 - training loss: 0.4957, validation loss: 0.0507
2024-05-22 22:52:37 [INFO]: Epoch 036 - training loss: 0.5005, validation loss: 0.0376
2024-05-22 22:52:38 [INFO]: Epoch 037 - training loss: 0.4898, validation loss: 0.0442
2024-05-22 22:52:38 [INFO]: Epoch 038 - training loss: 0.4902, validation loss: 0.0302
2024-05-22 22:52:39 [INFO]: Epoch 039 - training loss: 0.4952, validation loss: 0.0440
2024-05-22 22:52:39 [INFO]: Epoch 040 - training loss: 0.4850, validation loss: 0.0315
2024-05-22 22:52:40 [INFO]: Epoch 041 - training loss: 0.4915, validation loss: 0.0355
2024-05-22 22:52:40 [INFO]: Epoch 042 - training loss: 0.4763, validation loss: 0.0508
2024-05-22 22:52:41 [INFO]: Epoch 043 - training loss: 0.4717, validation loss: 0.0306
2024-05-22 22:52:41 [INFO]: Epoch 044 - training loss: 0.4696, validation loss: 0.0351
2024-05-22 22:52:42 [INFO]: Epoch 045 - training loss: 0.4680, validation loss: 0.0321
2024-05-22 22:52:42 [INFO]: Epoch 046 - training loss: 0.4716, validation loss: 0.0465
2024-05-22 22:52:43 [INFO]: Epoch 047 - training loss: 0.4615, validation loss: 0.0349
2024-05-22 22:52:43 [INFO]: Epoch 048 - training loss: 0.4653, validation loss: 0.0404
2024-05-22 22:52:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:52:43 [INFO]: Finished training. The best model is from epoch#38.
2024-05-22 22:52:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_ettm1/20240522_T225220/SAITS.pypots
2024-05-22 22:52:43 [INFO]: SAITS on ETTm1: MAE=0.1553, MSE=0.0473
2024-05-22 22:52:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-22 22:52:43 [INFO]: Using the given device: cuda:0
2024-05-22 22:52:43 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240522_T225243
2024-05-22 22:52:43 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_ettm1/20240522_T225243/tensorboard
2024-05-22 22:52:43 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-22 22:52:43 [INFO]: Epoch 001 - training loss: 1.1781, validation loss: 0.3026
2024-05-22 22:52:44 [INFO]: Epoch 002 - training loss: 0.6835, validation loss: 0.1611
2024-05-22 22:52:44 [INFO]: Epoch 003 - training loss: 0.5497, validation loss: 0.1084
2024-05-22 22:52:44 [INFO]: Epoch 004 - training loss: 0.4795, validation loss: 0.0895
2024-05-22 22:52:44 [INFO]: Epoch 005 - training loss: 0.4582, validation loss: 0.0789
2024-05-22 22:52:44 [INFO]: Epoch 006 - training loss: 0.4334, validation loss: 0.0749
2024-05-22 22:52:45 [INFO]: Epoch 007 - training loss: 0.4214, validation loss: 0.0755
2024-05-22 22:52:45 [INFO]: Epoch 008 - training loss: 0.4078, validation loss: 0.0659
2024-05-22 22:52:45 [INFO]: Epoch 009 - training loss: 0.4082, validation loss: 0.0636
2024-05-22 22:52:45 [INFO]: Epoch 010 - training loss: 0.3866, validation loss: 0.0610
2024-05-22 22:52:45 [INFO]: Epoch 011 - training loss: 0.3658, validation loss: 0.0622
2024-05-22 22:52:46 [INFO]: Epoch 012 - training loss: 0.3630, validation loss: 0.0509
2024-05-22 22:52:46 [INFO]: Epoch 013 - training loss: 0.3464, validation loss: 0.0509
2024-05-22 22:52:46 [INFO]: Epoch 014 - training loss: 0.3414, validation loss: 0.0475
2024-05-22 22:52:46 [INFO]: Epoch 015 - training loss: 0.3320, validation loss: 0.0460
2024-05-22 22:52:46 [INFO]: Epoch 016 - training loss: 0.3256, validation loss: 0.0448
2024-05-22 22:52:47 [INFO]: Epoch 017 - training loss: 0.3288, validation loss: 0.0450
2024-05-22 22:52:47 [INFO]: Epoch 018 - training loss: 0.3174, validation loss: 0.0445
2024-05-22 22:52:47 [INFO]: Epoch 019 - training loss: 0.3147, validation loss: 0.0422
2024-05-22 22:52:47 [INFO]: Epoch 020 - training loss: 0.3066, validation loss: 0.0404
2024-05-22 22:52:47 [INFO]: Epoch 021 - training loss: 0.3040, validation loss: 0.0441
2024-05-22 22:52:47 [INFO]: Epoch 022 - training loss: 0.3039, validation loss: 0.0398
2024-05-22 22:52:48 [INFO]: Epoch 023 - training loss: 0.3007, validation loss: 0.0404
2024-05-22 22:52:48 [INFO]: Epoch 024 - training loss: 0.2939, validation loss: 0.0393
2024-05-22 22:52:48 [INFO]: Epoch 025 - training loss: 0.2880, validation loss: 0.0377
2024-05-22 22:52:48 [INFO]: Epoch 026 - training loss: 0.2968, validation loss: 0.0413
2024-05-22 22:52:48 [INFO]: Epoch 027 - training loss: 0.2903, validation loss: 0.0376
2024-05-22 22:52:49 [INFO]: Epoch 028 - training loss: 0.2781, validation loss: 0.0360
2024-05-22 22:52:49 [INFO]: Epoch 029 - training loss: 0.2751, validation loss: 0.0324
2024-05-22 22:52:49 [INFO]: Epoch 030 - training loss: 0.2689, validation loss: 0.0340
2024-05-22 22:52:49 [INFO]: Epoch 031 - training loss: 0.2706, validation loss: 0.0340
2024-05-22 22:52:49 [INFO]: Epoch 032 - training loss: 0.2668, validation loss: 0.0323
2024-05-22 22:52:50 [INFO]: Epoch 033 - training loss: 0.2596, validation loss: 0.0327
2024-05-22 22:52:50 [INFO]: Epoch 034 - training loss: 0.2614, validation loss: 0.0378
2024-05-22 22:52:50 [INFO]: Epoch 035 - training loss: 0.2598, validation loss: 0.0318
2024-05-22 22:52:50 [INFO]: Epoch 036 - training loss: 0.2544, validation loss: 0.0342
2024-05-22 22:52:50 [INFO]: Epoch 037 - training loss: 0.2562, validation loss: 0.0295
2024-05-22 22:52:50 [INFO]: Epoch 038 - training loss: 0.2507, validation loss: 0.0292
2024-05-22 22:52:51 [INFO]: Epoch 039 - training loss: 0.2461, validation loss: 0.0342
2024-05-22 22:52:51 [INFO]: Epoch 040 - training loss: 0.2517, validation loss: 0.0320
2024-05-22 22:52:51 [INFO]: Epoch 041 - training loss: 0.2510, validation loss: 0.0282
2024-05-22 22:52:51 [INFO]: Epoch 042 - training loss: 0.2404, validation loss: 0.0303
2024-05-22 22:52:51 [INFO]: Epoch 043 - training loss: 0.2394, validation loss: 0.0274
2024-05-22 22:52:52 [INFO]: Epoch 044 - training loss: 0.2397, validation loss: 0.0313
2024-05-22 22:52:52 [INFO]: Epoch 045 - training loss: 0.2430, validation loss: 0.0328
2024-05-22 22:52:52 [INFO]: Epoch 046 - training loss: 0.2419, validation loss: 0.0275
2024-05-22 22:52:52 [INFO]: Epoch 047 - training loss: 0.2333, validation loss: 0.0279
2024-05-22 22:52:52 [INFO]: Epoch 048 - training loss: 0.2290, validation loss: 0.0293
2024-05-22 22:52:53 [INFO]: Epoch 049 - training loss: 0.2308, validation loss: 0.0283
2024-05-22 22:52:53 [INFO]: Epoch 050 - training loss: 0.2266, validation loss: 0.0268
2024-05-22 22:52:53 [INFO]: Epoch 051 - training loss: 0.2262, validation loss: 0.0282
2024-05-22 22:52:53 [INFO]: Epoch 052 - training loss: 0.2235, validation loss: 0.0265
2024-05-22 22:52:53 [INFO]: Epoch 053 - training loss: 0.2251, validation loss: 0.0275
2024-05-22 22:52:54 [INFO]: Epoch 054 - training loss: 0.2210, validation loss: 0.0301
2024-05-22 22:52:54 [INFO]: Epoch 055 - training loss: 0.2177, validation loss: 0.0284
2024-05-22 22:52:54 [INFO]: Epoch 056 - training loss: 0.2194, validation loss: 0.0299
2024-05-22 22:52:54 [INFO]: Epoch 057 - training loss: 0.2251, validation loss: 0.0295
2024-05-22 22:52:54 [INFO]: Epoch 058 - training loss: 0.2227, validation loss: 0.0258
2024-05-22 22:52:54 [INFO]: Epoch 059 - training loss: 0.2124, validation loss: 0.0244
2024-05-22 22:52:55 [INFO]: Epoch 060 - training loss: 0.2135, validation loss: 0.0264
2024-05-22 22:52:55 [INFO]: Epoch 061 - training loss: 0.2167, validation loss: 0.0265
2024-05-22 22:52:55 [INFO]: Epoch 062 - training loss: 0.2164, validation loss: 0.0239
2024-05-22 22:52:55 [INFO]: Epoch 063 - training loss: 0.2075, validation loss: 0.0246
2024-05-22 22:52:55 [INFO]: Epoch 064 - training loss: 0.2081, validation loss: 0.0233
2024-05-22 22:52:56 [INFO]: Epoch 065 - training loss: 0.2041, validation loss: 0.0237
2024-05-22 22:52:56 [INFO]: Epoch 066 - training loss: 0.2047, validation loss: 0.0272
2024-05-22 22:52:56 [INFO]: Epoch 067 - training loss: 0.2087, validation loss: 0.0236
2024-05-22 22:52:56 [INFO]: Epoch 068 - training loss: 0.2050, validation loss: 0.0218
2024-05-22 22:52:56 [INFO]: Epoch 069 - training loss: 0.2030, validation loss: 0.0259
2024-05-22 22:52:57 [INFO]: Epoch 070 - training loss: 0.2078, validation loss: 0.0245
2024-05-22 22:52:57 [INFO]: Epoch 071 - training loss: 0.2077, validation loss: 0.0232
2024-05-22 22:52:57 [INFO]: Epoch 072 - training loss: 0.2006, validation loss: 0.0229
2024-05-22 22:52:57 [INFO]: Epoch 073 - training loss: 0.1995, validation loss: 0.0217
2024-05-22 22:52:57 [INFO]: Epoch 074 - training loss: 0.2073, validation loss: 0.0242
2024-05-22 22:52:57 [INFO]: Epoch 075 - training loss: 0.2018, validation loss: 0.0262
2024-05-22 22:52:58 [INFO]: Epoch 076 - training loss: 0.2023, validation loss: 0.0256
2024-05-22 22:52:58 [INFO]: Epoch 077 - training loss: 0.2003, validation loss: 0.0229
2024-05-22 22:52:58 [INFO]: Epoch 078 - training loss: 0.1923, validation loss: 0.0222
2024-05-22 22:52:58 [INFO]: Epoch 079 - training loss: 0.1962, validation loss: 0.0226
2024-05-22 22:52:58 [INFO]: Epoch 080 - training loss: 0.1961, validation loss: 0.0228
2024-05-22 22:52:59 [INFO]: Epoch 081 - training loss: 0.1955, validation loss: 0.0222
2024-05-22 22:52:59 [INFO]: Epoch 082 - training loss: 0.1923, validation loss: 0.0222
2024-05-22 22:52:59 [INFO]: Epoch 083 - training loss: 0.1900, validation loss: 0.0225
2024-05-22 22:52:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:52:59 [INFO]: Finished training. The best model is from epoch#73.
2024-05-22 22:52:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_ettm1/20240522_T225243/Transformer.pypots
2024-05-22 22:52:59 [INFO]: Transformer on ETTm1: MAE=0.1370, MSE=0.0401
2024-05-22 22:52:59 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-22 22:52:59 [INFO]: Using the given device: cuda:0
2024-05-22 22:52:59 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240522_T225259
2024-05-22 22:52:59 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240522_T225259/tensorboard
2024-05-22 22:52:59 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-22 22:52:59 [INFO]: Epoch 001 - training loss: 0.1543, validation loss: 0.0507
2024-05-22 22:53:00 [INFO]: Epoch 002 - training loss: 0.0630, validation loss: 0.0386
2024-05-22 22:53:00 [INFO]: Epoch 003 - training loss: 0.0535, validation loss: 0.0351
2024-05-22 22:53:00 [INFO]: Epoch 004 - training loss: 0.0451, validation loss: 0.0303
2024-05-22 22:53:00 [INFO]: Epoch 005 - training loss: 0.0384, validation loss: 0.0277
2024-05-22 22:53:00 [INFO]: Epoch 006 - training loss: 0.0378, validation loss: 0.0264
2024-05-22 22:53:00 [INFO]: Epoch 007 - training loss: 0.0347, validation loss: 0.0259
2024-05-22 22:53:01 [INFO]: Epoch 008 - training loss: 0.0354, validation loss: 0.0260
2024-05-22 22:53:01 [INFO]: Epoch 009 - training loss: 0.0354, validation loss: 0.0245
2024-05-22 22:53:01 [INFO]: Epoch 010 - training loss: 0.0344, validation loss: 0.0248
2024-05-22 22:53:01 [INFO]: Epoch 011 - training loss: 0.0349, validation loss: 0.0276
2024-05-22 22:53:01 [INFO]: Epoch 012 - training loss: 0.0334, validation loss: 0.0263
2024-05-22 22:53:02 [INFO]: Epoch 013 - training loss: 0.0328, validation loss: 0.0244
2024-05-22 22:53:02 [INFO]: Epoch 014 - training loss: 0.0309, validation loss: 0.0245
2024-05-22 22:53:02 [INFO]: Epoch 015 - training loss: 0.0311, validation loss: 0.0250
2024-05-22 22:53:02 [INFO]: Epoch 016 - training loss: 0.0297, validation loss: 0.0242
2024-05-22 22:53:02 [INFO]: Epoch 017 - training loss: 0.0319, validation loss: 0.0255
2024-05-22 22:53:02 [INFO]: Epoch 018 - training loss: 0.0303, validation loss: 0.0238
2024-05-22 22:53:03 [INFO]: Epoch 019 - training loss: 0.0292, validation loss: 0.0239
2024-05-22 22:53:03 [INFO]: Epoch 020 - training loss: 0.0287, validation loss: 0.0234
2024-05-22 22:53:03 [INFO]: Epoch 021 - training loss: 0.0273, validation loss: 0.0245
2024-05-22 22:53:03 [INFO]: Epoch 022 - training loss: 0.0280, validation loss: 0.0234
2024-05-22 22:53:03 [INFO]: Epoch 023 - training loss: 0.0262, validation loss: 0.0230
2024-05-22 22:53:04 [INFO]: Epoch 024 - training loss: 0.0262, validation loss: 0.0226
2024-05-22 22:53:04 [INFO]: Epoch 025 - training loss: 0.0253, validation loss: 0.0239
2024-05-22 22:53:04 [INFO]: Epoch 026 - training loss: 0.0247, validation loss: 0.0231
2024-05-22 22:53:04 [INFO]: Epoch 027 - training loss: 0.0276, validation loss: 0.0249
2024-05-22 22:53:04 [INFO]: Epoch 028 - training loss: 0.0302, validation loss: 0.0244
2024-05-22 22:53:04 [INFO]: Epoch 029 - training loss: 0.0275, validation loss: 0.0240
2024-05-22 22:53:05 [INFO]: Epoch 030 - training loss: 0.0266, validation loss: 0.0238
2024-05-22 22:53:05 [INFO]: Epoch 031 - training loss: 0.0252, validation loss: 0.0228
2024-05-22 22:53:05 [INFO]: Epoch 032 - training loss: 0.0229, validation loss: 0.0229
2024-05-22 22:53:05 [INFO]: Epoch 033 - training loss: 0.0238, validation loss: 0.0234
2024-05-22 22:53:05 [INFO]: Epoch 034 - training loss: 0.0238, validation loss: 0.0234
2024-05-22 22:53:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:53:05 [INFO]: Finished training. The best model is from epoch#24.
2024-05-22 22:53:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_ettm1/20240522_T225259/TimesNet.pypots
2024-05-22 22:53:05 [INFO]: TimesNet on ETTm1: MAE=0.1102, MSE=0.0264
2024-05-22 22:53:05 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-22 22:53:05 [INFO]: Using the given device: cuda:0
2024-05-22 22:53:05 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305
2024-05-22 22:53:05 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/tensorboard
2024-05-22 22:53:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-22 22:53:07 [INFO]: Epoch 001 - training loss: 0.6918, validation loss: 0.4504
2024-05-22 22:53:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch1_loss0.45040932297706604.pypots
2024-05-22 22:53:09 [INFO]: Epoch 002 - training loss: 0.3845, validation loss: 0.3619
2024-05-22 22:53:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch2_loss0.36187803000211716.pypots
2024-05-22 22:53:11 [INFO]: Epoch 003 - training loss: 0.3413, validation loss: 0.3145
2024-05-22 22:53:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch3_loss0.3144662231206894.pypots
2024-05-22 22:53:13 [INFO]: Epoch 004 - training loss: 0.3446, validation loss: 0.2855
2024-05-22 22:53:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch4_loss0.28552331775426865.pypots
2024-05-22 22:53:16 [INFO]: Epoch 005 - training loss: 0.2933, validation loss: 0.2780
2024-05-22 22:53:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch5_loss0.2779941260814667.pypots
2024-05-22 22:53:18 [INFO]: Epoch 006 - training loss: 0.2547, validation loss: 0.2652
2024-05-22 22:53:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch6_loss0.26524005830287933.pypots
2024-05-22 22:53:20 [INFO]: Epoch 007 - training loss: 0.2891, validation loss: 0.3353
2024-05-22 22:53:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch7_loss0.33528145402669907.pypots
2024-05-22 22:53:22 [INFO]: Epoch 008 - training loss: 0.2849, validation loss: 0.2602
2024-05-22 22:53:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch8_loss0.26019009202718735.pypots
2024-05-22 22:53:24 [INFO]: Epoch 009 - training loss: 0.2629, validation loss: 0.2555
2024-05-22 22:53:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch9_loss0.2554673030972481.pypots
2024-05-22 22:53:26 [INFO]: Epoch 010 - training loss: 0.2585, validation loss: 0.2399
2024-05-22 22:53:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch10_loss0.2399454526603222.pypots
2024-05-22 22:53:28 [INFO]: Epoch 011 - training loss: 0.2677, validation loss: 0.3073
2024-05-22 22:53:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch11_loss0.3073067143559456.pypots
2024-05-22 22:53:30 [INFO]: Epoch 012 - training loss: 0.2890, validation loss: 0.2554
2024-05-22 22:53:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch12_loss0.25537417456507683.pypots
2024-05-22 22:53:32 [INFO]: Epoch 013 - training loss: 0.2342, validation loss: 0.2446
2024-05-22 22:53:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch13_loss0.24457517638802528.pypots
2024-05-22 22:53:34 [INFO]: Epoch 014 - training loss: 0.2360, validation loss: 0.2267
2024-05-22 22:53:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch14_loss0.22670766711235046.pypots
2024-05-22 22:53:36 [INFO]: Epoch 015 - training loss: 0.2182, validation loss: 0.2190
2024-05-22 22:53:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch15_loss0.21903762966394424.pypots
2024-05-22 22:53:38 [INFO]: Epoch 016 - training loss: 0.2399, validation loss: 0.2113
2024-05-22 22:53:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch16_loss0.21127644926309586.pypots
2024-05-22 22:53:40 [INFO]: Epoch 017 - training loss: 0.2305, validation loss: 0.2244
2024-05-22 22:53:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch17_loss0.22442543506622314.pypots
2024-05-22 22:53:42 [INFO]: Epoch 018 - training loss: 0.2206, validation loss: 0.2036
2024-05-22 22:53:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch18_loss0.20361928641796112.pypots
2024-05-22 22:53:44 [INFO]: Epoch 019 - training loss: 0.2408, validation loss: 0.2082
2024-05-22 22:53:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch19_loss0.2081521824002266.pypots
2024-05-22 22:53:46 [INFO]: Epoch 020 - training loss: 0.2046, validation loss: 0.2009
2024-05-22 22:53:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch20_loss0.20086291804909706.pypots
2024-05-22 22:53:48 [INFO]: Epoch 021 - training loss: 0.2081, validation loss: 0.2054
2024-05-22 22:53:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch21_loss0.20539407804608345.pypots
2024-05-22 22:53:50 [INFO]: Epoch 022 - training loss: 0.1959, validation loss: 0.1984
2024-05-22 22:53:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch22_loss0.19843032583594322.pypots
2024-05-22 22:53:52 [INFO]: Epoch 023 - training loss: 0.1833, validation loss: 0.1924
2024-05-22 22:53:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch23_loss0.1924033872783184.pypots
2024-05-22 22:53:54 [INFO]: Epoch 024 - training loss: 0.1829, validation loss: 0.1822
2024-05-22 22:53:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch24_loss0.18215646967291832.pypots
2024-05-22 22:53:56 [INFO]: Epoch 025 - training loss: 0.2079, validation loss: 0.1763
2024-05-22 22:53:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch25_loss0.17634283751249313.pypots
2024-05-22 22:53:58 [INFO]: Epoch 026 - training loss: 0.1973, validation loss: 0.1799
2024-05-22 22:53:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch26_loss0.17988427728414536.pypots
2024-05-22 22:54:00 [INFO]: Epoch 027 - training loss: 0.1767, validation loss: 0.1766
2024-05-22 22:54:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch27_loss0.1766422800719738.pypots
2024-05-22 22:54:02 [INFO]: Epoch 028 - training loss: 0.1805, validation loss: 0.1732
2024-05-22 22:54:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch28_loss0.17324939370155334.pypots
2024-05-22 22:54:04 [INFO]: Epoch 029 - training loss: 0.1571, validation loss: 0.1650
2024-05-22 22:54:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch29_loss0.16495084017515182.pypots
2024-05-22 22:54:06 [INFO]: Epoch 030 - training loss: 0.1484, validation loss: 0.1635
2024-05-22 22:54:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch30_loss0.16345474123954773.pypots
2024-05-22 22:54:08 [INFO]: Epoch 031 - training loss: 0.1840, validation loss: 0.1572
2024-05-22 22:54:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch31_loss0.15718603134155273.pypots
2024-05-22 22:54:10 [INFO]: Epoch 032 - training loss: 0.1598, validation loss: 0.1596
2024-05-22 22:54:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch32_loss0.1595853939652443.pypots
2024-05-22 22:54:12 [INFO]: Epoch 033 - training loss: 0.1638, validation loss: 0.1704
2024-05-22 22:54:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch33_loss0.17035219445824623.pypots
2024-05-22 22:54:14 [INFO]: Epoch 034 - training loss: 0.2042, validation loss: 0.1630
2024-05-22 22:54:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch34_loss0.16297421976923943.pypots
2024-05-22 22:54:16 [INFO]: Epoch 035 - training loss: 0.1732, validation loss: 0.1634
2024-05-22 22:54:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch35_loss0.16343273222446442.pypots
2024-05-22 22:54:18 [INFO]: Epoch 036 - training loss: 0.1698, validation loss: 0.1544
2024-05-22 22:54:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch36_loss0.1543988138437271.pypots
2024-05-22 22:54:20 [INFO]: Epoch 037 - training loss: 0.2076, validation loss: 0.1585
2024-05-22 22:54:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch37_loss0.158509761095047.pypots
2024-05-22 22:54:22 [INFO]: Epoch 038 - training loss: 0.2054, validation loss: 0.1802
2024-05-22 22:54:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch38_loss0.180187176913023.pypots
2024-05-22 22:54:24 [INFO]: Epoch 039 - training loss: 0.1867, validation loss: 0.1834
2024-05-22 22:54:24 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch39_loss0.18335086479783058.pypots
2024-05-22 22:54:26 [INFO]: Epoch 040 - training loss: 0.1852, validation loss: 0.1564
2024-05-22 22:54:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch40_loss0.15642399340867996.pypots
2024-05-22 22:54:28 [INFO]: Epoch 041 - training loss: 0.1645, validation loss: 0.1497
2024-05-22 22:54:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch41_loss0.14974654465913773.pypots
2024-05-22 22:54:30 [INFO]: Epoch 042 - training loss: 0.1484, validation loss: 0.1495
2024-05-22 22:54:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch42_loss0.14952335506677628.pypots
2024-05-22 22:54:32 [INFO]: Epoch 043 - training loss: 0.1546, validation loss: 0.1516
2024-05-22 22:54:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch43_loss0.15162187069654465.pypots
2024-05-22 22:54:34 [INFO]: Epoch 044 - training loss: 0.1413, validation loss: 0.1542
2024-05-22 22:54:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch44_loss0.15417831018567085.pypots
2024-05-22 22:54:36 [INFO]: Epoch 045 - training loss: 0.1825, validation loss: 0.1480
2024-05-22 22:54:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch45_loss0.14801176637411118.pypots
2024-05-22 22:54:38 [INFO]: Epoch 046 - training loss: 0.1677, validation loss: 0.1710
2024-05-22 22:54:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch46_loss0.1709831804037094.pypots
2024-05-22 22:54:40 [INFO]: Epoch 047 - training loss: 0.1922, validation loss: 0.1880
2024-05-22 22:54:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch47_loss0.1880245991051197.pypots
2024-05-22 22:54:42 [INFO]: Epoch 048 - training loss: 0.1803, validation loss: 0.1603
2024-05-22 22:54:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch48_loss0.1603047251701355.pypots
2024-05-22 22:54:44 [INFO]: Epoch 049 - training loss: 0.1654, validation loss: 0.1482
2024-05-22 22:54:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch49_loss0.1481919325888157.pypots
2024-05-22 22:54:46 [INFO]: Epoch 050 - training loss: 0.1516, validation loss: 0.1417
2024-05-22 22:54:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch50_loss0.14169714227318764.pypots
2024-05-22 22:54:48 [INFO]: Epoch 051 - training loss: 0.1967, validation loss: 0.1795
2024-05-22 22:54:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch51_loss0.17949872091412544.pypots
2024-05-22 22:54:50 [INFO]: Epoch 052 - training loss: 0.2330, validation loss: 0.1803
2024-05-22 22:54:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch52_loss0.1802765317261219.pypots
2024-05-22 22:54:52 [INFO]: Epoch 053 - training loss: 0.1741, validation loss: 0.1626
2024-05-22 22:54:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch53_loss0.16259998083114624.pypots
2024-05-22 22:54:54 [INFO]: Epoch 054 - training loss: 0.1332, validation loss: 0.1461
2024-05-22 22:54:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch54_loss0.14609861373901367.pypots
2024-05-22 22:54:56 [INFO]: Epoch 055 - training loss: 0.1565, validation loss: 0.1403
2024-05-22 22:54:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch55_loss0.14034578949213028.pypots
2024-05-22 22:54:58 [INFO]: Epoch 056 - training loss: 0.1308, validation loss: 0.1392
2024-05-22 22:54:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch56_loss0.13917012512683868.pypots
2024-05-22 22:55:00 [INFO]: Epoch 057 - training loss: 0.1340, validation loss: 0.1375
2024-05-22 22:55:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch57_loss0.13749823719263077.pypots
2024-05-22 22:55:03 [INFO]: Epoch 058 - training loss: 0.1362, validation loss: 0.1375
2024-05-22 22:55:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch58_loss0.13751910254359245.pypots
2024-05-22 22:55:05 [INFO]: Epoch 059 - training loss: 0.1620, validation loss: 0.1363
2024-05-22 22:55:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch59_loss0.13630641251802444.pypots
2024-05-22 22:55:07 [INFO]: Epoch 060 - training loss: 0.1306, validation loss: 0.1381
2024-05-22 22:55:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch60_loss0.13809499889612198.pypots
2024-05-22 22:55:09 [INFO]: Epoch 061 - training loss: 0.1374, validation loss: 0.1343
2024-05-22 22:55:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch61_loss0.13427194580435753.pypots
2024-05-22 22:55:11 [INFO]: Epoch 062 - training loss: 0.1704, validation loss: 0.1386
2024-05-22 22:55:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch62_loss0.13860276713967323.pypots
2024-05-22 22:55:13 [INFO]: Epoch 063 - training loss: 0.1702, validation loss: 0.1501
2024-05-22 22:55:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch63_loss0.1500736139714718.pypots
2024-05-22 22:55:15 [INFO]: Epoch 064 - training loss: 0.1679, validation loss: 0.1480
2024-05-22 22:55:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch64_loss0.14804399386048317.pypots
2024-05-22 22:55:17 [INFO]: Epoch 065 - training loss: 0.1655, validation loss: 0.1480
2024-05-22 22:55:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch65_loss0.14800084754824638.pypots
2024-05-22 22:55:19 [INFO]: Epoch 066 - training loss: 0.1742, validation loss: 0.1388
2024-05-22 22:55:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch66_loss0.13880227133631706.pypots
2024-05-22 22:55:21 [INFO]: Epoch 067 - training loss: 0.1474, validation loss: 0.1418
2024-05-22 22:55:21 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch67_loss0.14178237691521645.pypots
2024-05-22 22:55:23 [INFO]: Epoch 068 - training loss: 0.1461, validation loss: 0.1371
2024-05-22 22:55:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch68_loss0.13707122206687927.pypots
2024-05-22 22:55:25 [INFO]: Epoch 069 - training loss: 0.1583, validation loss: 0.1354
2024-05-22 22:55:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch69_loss0.13540633767843246.pypots
2024-05-22 22:55:27 [INFO]: Epoch 070 - training loss: 0.1378, validation loss: 0.1308
2024-05-22 22:55:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch70_loss0.13082150556147099.pypots
2024-05-22 22:55:29 [INFO]: Epoch 071 - training loss: 0.1504, validation loss: 0.1298
2024-05-22 22:55:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch71_loss0.12983737513422966.pypots
2024-05-22 22:55:31 [INFO]: Epoch 072 - training loss: 0.1245, validation loss: 0.1276
2024-05-22 22:55:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch72_loss0.12758042477071285.pypots
2024-05-22 22:55:33 [INFO]: Epoch 073 - training loss: 0.1796, validation loss: 0.1375
2024-05-22 22:55:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch73_loss0.13747036829590797.pypots
2024-05-22 22:55:35 [INFO]: Epoch 074 - training loss: 0.1666, validation loss: 0.1424
2024-05-22 22:55:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch74_loss0.14236316829919815.pypots
2024-05-22 22:55:37 [INFO]: Epoch 075 - training loss: 0.1969, validation loss: 0.1531
2024-05-22 22:55:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch75_loss0.1530768759548664.pypots
2024-05-22 22:55:39 [INFO]: Epoch 076 - training loss: 0.1252, validation loss: 0.1442
2024-05-22 22:55:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch76_loss0.144187543541193.pypots
2024-05-22 22:55:41 [INFO]: Epoch 077 - training loss: 0.1403, validation loss: 0.1332
2024-05-22 22:55:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch77_loss0.13320879265666008.pypots
2024-05-22 22:55:43 [INFO]: Epoch 078 - training loss: 0.1378, validation loss: 0.1307
2024-05-22 22:55:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch78_loss0.13073724508285522.pypots
2024-05-22 22:55:45 [INFO]: Epoch 079 - training loss: 0.1695, validation loss: 0.1435
2024-05-22 22:55:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch79_loss0.1435127891600132.pypots
2024-05-22 22:55:47 [INFO]: Epoch 080 - training loss: 0.1501, validation loss: 0.1420
2024-05-22 22:55:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch80_loss0.14203042536973953.pypots
2024-05-22 22:55:49 [INFO]: Epoch 081 - training loss: 0.1443, validation loss: 0.1322
2024-05-22 22:55:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch81_loss0.13218384236097336.pypots
2024-05-22 22:55:51 [INFO]: Epoch 082 - training loss: 0.1898, validation loss: 0.1375
2024-05-22 22:55:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI_epoch82_loss0.13748225569725037.pypots
2024-05-22 22:55:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:55:51 [INFO]: Finished training. The best model is from epoch#72.
2024-05-22 22:55:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_ettm1/20240522_T225305/CSDI.pypots
2024-05-22 22:56:07 [INFO]: CSDI on ETTm1: MAE=0.1440, MSE=0.0520
2024-05-22 22:56:07 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-22 22:56:07 [INFO]: Using the given device: cuda:0
2024-05-22 22:56:07 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240522_T225607
2024-05-22 22:56:07 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240522_T225607/tensorboard
2024-05-22 22:56:07 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-22 22:56:07 [INFO]: Epoch 001 - training loss: 24165.7028, validation loss: 0.9761
2024-05-22 22:56:07 [INFO]: Epoch 002 - training loss: 22060.1688, validation loss: 0.9668
2024-05-22 22:56:07 [INFO]: Epoch 003 - training loss: 20030.6201, validation loss: 0.9617
2024-05-22 22:56:07 [INFO]: Epoch 004 - training loss: 17794.9090, validation loss: 0.9478
2024-05-22 22:56:07 [INFO]: Epoch 005 - training loss: 16034.7385, validation loss: 0.9109
2024-05-22 22:56:08 [INFO]: Epoch 006 - training loss: 14431.5668, validation loss: 0.8593
2024-05-22 22:56:08 [INFO]: Epoch 007 - training loss: 13147.8130, validation loss: 0.7850
2024-05-22 22:56:08 [INFO]: Epoch 008 - training loss: 12266.2274, validation loss: 0.7389
2024-05-22 22:56:08 [INFO]: Epoch 009 - training loss: 11626.0415, validation loss: 0.6517
2024-05-22 22:56:08 [INFO]: Epoch 010 - training loss: 11135.3344, validation loss: 0.5754
2024-05-22 22:56:08 [INFO]: Epoch 011 - training loss: 10874.3328, validation loss: 0.5039
2024-05-22 22:56:08 [INFO]: Epoch 012 - training loss: 10616.4109, validation loss: 0.4706
2024-05-22 22:56:08 [INFO]: Epoch 013 - training loss: 10307.3746, validation loss: 0.4551
2024-05-22 22:56:08 [INFO]: Epoch 014 - training loss: 10177.0986, validation loss: 0.4387
2024-05-22 22:56:09 [INFO]: Epoch 015 - training loss: 10083.7868, validation loss: 0.4199
2024-05-22 22:56:09 [INFO]: Epoch 016 - training loss: 10011.0411, validation loss: 0.3860
2024-05-22 22:56:09 [INFO]: Epoch 017 - training loss: 9912.3601, validation loss: 0.3723
2024-05-22 22:56:09 [INFO]: Epoch 018 - training loss: 9819.2206, validation loss: 0.3495
2024-05-22 22:56:09 [INFO]: Epoch 019 - training loss: 9798.3434, validation loss: 0.3273
2024-05-22 22:56:09 [INFO]: Epoch 020 - training loss: 9744.0247, validation loss: 0.3174
2024-05-22 22:56:09 [INFO]: Epoch 021 - training loss: 9685.6539, validation loss: 0.3089
2024-05-22 22:56:09 [INFO]: Epoch 022 - training loss: 9649.6277, validation loss: 0.3058
2024-05-22 22:56:09 [INFO]: Epoch 023 - training loss: 9608.0108, validation loss: 0.3044
2024-05-22 22:56:10 [INFO]: Epoch 024 - training loss: 9580.6263, validation loss: 0.3021
2024-05-22 22:56:10 [INFO]: Epoch 025 - training loss: 9572.8525, validation loss: 0.3007
2024-05-22 22:56:10 [INFO]: Epoch 026 - training loss: 9552.5786, validation loss: 0.2982
2024-05-22 22:56:10 [INFO]: Epoch 027 - training loss: 9518.2399, validation loss: 0.2953
2024-05-22 22:56:10 [INFO]: Epoch 028 - training loss: 9515.3598, validation loss: 0.2874
2024-05-22 22:56:10 [INFO]: Epoch 029 - training loss: 9505.3792, validation loss: 0.2854
2024-05-22 22:56:10 [INFO]: Epoch 030 - training loss: 9527.2546, validation loss: 0.2802
2024-05-22 22:56:10 [INFO]: Epoch 031 - training loss: 9467.6345, validation loss: 0.2715
2024-05-22 22:56:10 [INFO]: Epoch 032 - training loss: 9454.9930, validation loss: 0.2626
2024-05-22 22:56:11 [INFO]: Epoch 033 - training loss: 9444.1245, validation loss: 0.2618
2024-05-22 22:56:11 [INFO]: Epoch 034 - training loss: 9438.3762, validation loss: 0.2554
2024-05-22 22:56:11 [INFO]: Epoch 035 - training loss: 9434.2057, validation loss: 0.2513
2024-05-22 22:56:11 [INFO]: Epoch 036 - training loss: 9416.2817, validation loss: 0.2502
2024-05-22 22:56:11 [INFO]: Epoch 037 - training loss: 9418.1609, validation loss: 0.2453
2024-05-22 22:56:11 [INFO]: Epoch 038 - training loss: 9404.1062, validation loss: 0.2409
2024-05-22 22:56:11 [INFO]: Epoch 039 - training loss: 9405.0480, validation loss: 0.2350
2024-05-22 22:56:11 [INFO]: Epoch 040 - training loss: 9390.6010, validation loss: 0.2293
2024-05-22 22:56:11 [INFO]: Epoch 041 - training loss: 9395.4973, validation loss: 0.2256
2024-05-22 22:56:12 [INFO]: Epoch 042 - training loss: 9393.2028, validation loss: 0.2194
2024-05-22 22:56:12 [INFO]: Epoch 043 - training loss: 9389.2398, validation loss: 0.2143
2024-05-22 22:56:12 [INFO]: Epoch 044 - training loss: 9372.8387, validation loss: 0.2101
2024-05-22 22:56:12 [INFO]: Epoch 045 - training loss: 9368.8177, validation loss: 0.2052
2024-05-22 22:56:12 [INFO]: Epoch 046 - training loss: 9386.2516, validation loss: 0.2001
2024-05-22 22:56:12 [INFO]: Epoch 047 - training loss: 9366.3917, validation loss: 0.1928
2024-05-22 22:56:12 [INFO]: Epoch 048 - training loss: 9361.2001, validation loss: 0.1893
2024-05-22 22:56:12 [INFO]: Epoch 049 - training loss: 9352.1757, validation loss: 0.1834
2024-05-22 22:56:12 [INFO]: Epoch 050 - training loss: 9352.0707, validation loss: 0.1802
2024-05-22 22:56:13 [INFO]: Epoch 051 - training loss: 9347.0538, validation loss: 0.1762
2024-05-22 22:56:13 [INFO]: Epoch 052 - training loss: 9344.4713, validation loss: 0.1720
2024-05-22 22:56:13 [INFO]: Epoch 053 - training loss: 9346.8153, validation loss: 0.1669
2024-05-22 22:56:13 [INFO]: Epoch 054 - training loss: 9341.3258, validation loss: 0.1632
2024-05-22 22:56:13 [INFO]: Epoch 055 - training loss: 9341.7106, validation loss: 0.1623
2024-05-22 22:56:13 [INFO]: Epoch 056 - training loss: 9342.6646, validation loss: 0.1594
2024-05-22 22:56:13 [INFO]: Epoch 057 - training loss: 9338.0311, validation loss: 0.1536
2024-05-22 22:56:13 [INFO]: Epoch 058 - training loss: 9334.4724, validation loss: 0.1531
2024-05-22 22:56:13 [INFO]: Epoch 059 - training loss: 9334.4453, validation loss: 0.1493
2024-05-22 22:56:14 [INFO]: Epoch 060 - training loss: 9329.2023, validation loss: 0.1476
2024-05-22 22:56:14 [INFO]: Epoch 061 - training loss: 9326.1161, validation loss: 0.1446
2024-05-22 22:56:14 [INFO]: Epoch 062 - training loss: 9325.1925, validation loss: 0.1446
2024-05-22 22:56:14 [INFO]: Epoch 063 - training loss: 9325.8446, validation loss: 0.1406
2024-05-22 22:56:14 [INFO]: Epoch 064 - training loss: 9324.6816, validation loss: 0.1410
2024-05-22 22:56:14 [INFO]: Epoch 065 - training loss: 9321.6509, validation loss: 0.1382
2024-05-22 22:56:14 [INFO]: Epoch 066 - training loss: 9318.3431, validation loss: 0.1368
2024-05-22 22:56:14 [INFO]: Epoch 067 - training loss: 9321.0071, validation loss: 0.1343
2024-05-22 22:56:14 [INFO]: Epoch 068 - training loss: 9317.9527, validation loss: 0.1329
2024-05-22 22:56:15 [INFO]: Epoch 069 - training loss: 9315.5751, validation loss: 0.1320
2024-05-22 22:56:15 [INFO]: Epoch 070 - training loss: 9313.2522, validation loss: 0.1308
2024-05-22 22:56:15 [INFO]: Epoch 071 - training loss: 9315.2243, validation loss: 0.1302
2024-05-22 22:56:15 [INFO]: Epoch 072 - training loss: 9315.9417, validation loss: 0.1278
2024-05-22 22:56:15 [INFO]: Epoch 073 - training loss: 9311.7825, validation loss: 0.1259
2024-05-22 22:56:15 [INFO]: Epoch 074 - training loss: 9315.1428, validation loss: 0.1286
2024-05-22 22:56:15 [INFO]: Epoch 075 - training loss: 9311.0020, validation loss: 0.1258
2024-05-22 22:56:15 [INFO]: Epoch 076 - training loss: 9309.4783, validation loss: 0.1229
2024-05-22 22:56:15 [INFO]: Epoch 077 - training loss: 9309.4074, validation loss: 0.1223
2024-05-22 22:56:16 [INFO]: Epoch 078 - training loss: 9308.1335, validation loss: 0.1224
2024-05-22 22:56:16 [INFO]: Epoch 079 - training loss: 9307.4254, validation loss: 0.1201
2024-05-22 22:56:16 [INFO]: Epoch 080 - training loss: 9308.7204, validation loss: 0.1198
2024-05-22 22:56:16 [INFO]: Epoch 081 - training loss: 9304.0739, validation loss: 0.1196
2024-05-22 22:56:16 [INFO]: Epoch 082 - training loss: 9307.9348, validation loss: 0.1184
2024-05-22 22:56:16 [INFO]: Epoch 083 - training loss: 9304.4139, validation loss: 0.1187
2024-05-22 22:56:16 [INFO]: Epoch 084 - training loss: 9302.5004, validation loss: 0.1156
2024-05-22 22:56:16 [INFO]: Epoch 085 - training loss: 9303.6577, validation loss: 0.1143
2024-05-22 22:56:16 [INFO]: Epoch 086 - training loss: 9300.0246, validation loss: 0.1168
2024-05-22 22:56:17 [INFO]: Epoch 087 - training loss: 9299.2197, validation loss: 0.1149
2024-05-22 22:56:17 [INFO]: Epoch 088 - training loss: 9301.4213, validation loss: 0.1129
2024-05-22 22:56:17 [INFO]: Epoch 089 - training loss: 9299.0828, validation loss: 0.1138
2024-05-22 22:56:17 [INFO]: Epoch 090 - training loss: 9299.1688, validation loss: 0.1115
2024-05-22 22:56:17 [INFO]: Epoch 091 - training loss: 9302.9160, validation loss: 0.1118
2024-05-22 22:56:17 [INFO]: Epoch 092 - training loss: 9295.5179, validation loss: 0.1111
2024-05-22 22:56:17 [INFO]: Epoch 093 - training loss: 9297.8890, validation loss: 0.1098
2024-05-22 22:56:18 [INFO]: Epoch 094 - training loss: 9295.6474, validation loss: 0.1096
2024-05-22 22:56:18 [INFO]: Epoch 095 - training loss: 9311.0123, validation loss: 0.1071
2024-05-22 22:56:18 [INFO]: Epoch 096 - training loss: 9294.8189, validation loss: 0.1081
2024-05-22 22:56:18 [INFO]: Epoch 097 - training loss: 9296.8234, validation loss: 0.1075
2024-05-22 22:56:18 [INFO]: Epoch 098 - training loss: 9294.3148, validation loss: 0.1075
2024-05-22 22:56:18 [INFO]: Epoch 099 - training loss: 9293.3101, validation loss: 0.1059
2024-05-22 22:56:18 [INFO]: Epoch 100 - training loss: 9294.3314, validation loss: 0.1052
2024-05-22 22:56:18 [INFO]: Epoch 101 - training loss: 9298.4400, validation loss: 0.1040
2024-05-22 22:56:18 [INFO]: Epoch 102 - training loss: 9294.4188, validation loss: 0.1048
2024-05-22 22:56:19 [INFO]: Epoch 103 - training loss: 9291.7590, validation loss: 0.1030
2024-05-22 22:56:19 [INFO]: Epoch 104 - training loss: 9292.9036, validation loss: 0.1023
2024-05-22 22:56:19 [INFO]: Epoch 105 - training loss: 9292.3777, validation loss: 0.1043
2024-05-22 22:56:19 [INFO]: Epoch 106 - training loss: 9289.9863, validation loss: 0.1020
2024-05-22 22:56:19 [INFO]: Epoch 107 - training loss: 9290.2305, validation loss: 0.1021
2024-05-22 22:56:19 [INFO]: Epoch 108 - training loss: 9288.2341, validation loss: 0.1025
2024-05-22 22:56:19 [INFO]: Epoch 109 - training loss: 9288.2208, validation loss: 0.1011
2024-05-22 22:56:19 [INFO]: Epoch 110 - training loss: 9291.5005, validation loss: 0.1009
2024-05-22 22:56:19 [INFO]: Epoch 111 - training loss: 9288.4444, validation loss: 0.1021
2024-05-22 22:56:20 [INFO]: Epoch 112 - training loss: 9289.1554, validation loss: 0.0993
2024-05-22 22:56:20 [INFO]: Epoch 113 - training loss: 9290.4606, validation loss: 0.0983
2024-05-22 22:56:20 [INFO]: Epoch 114 - training loss: 9289.1005, validation loss: 0.0981
2024-05-22 22:56:20 [INFO]: Epoch 115 - training loss: 9288.2802, validation loss: 0.0980
2024-05-22 22:56:20 [INFO]: Epoch 116 - training loss: 9286.5052, validation loss: 0.0966
2024-05-22 22:56:20 [INFO]: Epoch 117 - training loss: 9285.8090, validation loss: 0.0967
2024-05-22 22:56:20 [INFO]: Epoch 118 - training loss: 9286.0322, validation loss: 0.0966
2024-05-22 22:56:20 [INFO]: Epoch 119 - training loss: 9287.5234, validation loss: 0.0954
2024-05-22 22:56:20 [INFO]: Epoch 120 - training loss: 9285.8035, validation loss: 0.0956
2024-05-22 22:56:21 [INFO]: Epoch 121 - training loss: 9284.8538, validation loss: 0.0959
2024-05-22 22:56:21 [INFO]: Epoch 122 - training loss: 9284.7435, validation loss: 0.0961
2024-05-22 22:56:21 [INFO]: Epoch 123 - training loss: 9285.4418, validation loss: 0.0942
2024-05-22 22:56:21 [INFO]: Epoch 124 - training loss: 9285.6154, validation loss: 0.0959
2024-05-22 22:56:21 [INFO]: Epoch 125 - training loss: 9285.2105, validation loss: 0.0918
2024-05-22 22:56:21 [INFO]: Epoch 126 - training loss: 9283.7009, validation loss: 0.0932
2024-05-22 22:56:21 [INFO]: Epoch 127 - training loss: 9285.4550, validation loss: 0.0930
2024-05-22 22:56:21 [INFO]: Epoch 128 - training loss: 9284.3831, validation loss: 0.0929
2024-05-22 22:56:21 [INFO]: Epoch 129 - training loss: 9283.8406, validation loss: 0.0919
2024-05-22 22:56:22 [INFO]: Epoch 130 - training loss: 9282.5067, validation loss: 0.0912
2024-05-22 22:56:22 [INFO]: Epoch 131 - training loss: 9282.6693, validation loss: 0.0917
2024-05-22 22:56:22 [INFO]: Epoch 132 - training loss: 9282.4154, validation loss: 0.0914
2024-05-22 22:56:22 [INFO]: Epoch 133 - training loss: 9282.2048, validation loss: 0.0908
2024-05-22 22:56:22 [INFO]: Epoch 134 - training loss: 9283.5335, validation loss: 0.0893
2024-05-22 22:56:22 [INFO]: Epoch 135 - training loss: 9281.4207, validation loss: 0.0896
2024-05-22 22:56:22 [INFO]: Epoch 136 - training loss: 9283.1373, validation loss: 0.0898
2024-05-22 22:56:22 [INFO]: Epoch 137 - training loss: 9281.3596, validation loss: 0.0920
2024-05-22 22:56:22 [INFO]: Epoch 138 - training loss: 9281.0313, validation loss: 0.0895
2024-05-22 22:56:23 [INFO]: Epoch 139 - training loss: 9281.7232, validation loss: 0.0889
2024-05-22 22:56:23 [INFO]: Epoch 140 - training loss: 9280.8517, validation loss: 0.0874
2024-05-22 22:56:23 [INFO]: Epoch 141 - training loss: 9281.0617, validation loss: 0.0876
2024-05-22 22:56:23 [INFO]: Epoch 142 - training loss: 9280.7953, validation loss: 0.0864
2024-05-22 22:56:23 [INFO]: Epoch 143 - training loss: 9280.1938, validation loss: 0.0870
2024-05-22 22:56:23 [INFO]: Epoch 144 - training loss: 9281.6788, validation loss: 0.0876
2024-05-22 22:56:23 [INFO]: Epoch 145 - training loss: 9280.2042, validation loss: 0.0856
2024-05-22 22:56:23 [INFO]: Epoch 146 - training loss: 9279.4082, validation loss: 0.0860
2024-05-22 22:56:23 [INFO]: Epoch 147 - training loss: 9280.6065, validation loss: 0.0859
2024-05-22 22:56:24 [INFO]: Epoch 148 - training loss: 9280.6315, validation loss: 0.0864
2024-05-22 22:56:24 [INFO]: Epoch 149 - training loss: 9277.4875, validation loss: 0.0863
2024-05-22 22:56:24 [INFO]: Epoch 150 - training loss: 9278.2310, validation loss: 0.0869
2024-05-22 22:56:24 [INFO]: Epoch 151 - training loss: 9280.4779, validation loss: 0.0856
2024-05-22 22:56:24 [INFO]: Epoch 152 - training loss: 9278.2899, validation loss: 0.0847
2024-05-22 22:56:24 [INFO]: Epoch 153 - training loss: 9280.6284, validation loss: 0.0842
2024-05-22 22:56:24 [INFO]: Epoch 154 - training loss: 9278.3276, validation loss: 0.0840
2024-05-22 22:56:24 [INFO]: Epoch 155 - training loss: 9281.3598, validation loss: 0.0853
2024-05-22 22:56:24 [INFO]: Epoch 156 - training loss: 9279.3574, validation loss: 0.0865
2024-05-22 22:56:25 [INFO]: Epoch 157 - training loss: 9278.8391, validation loss: 0.0824
2024-05-22 22:56:25 [INFO]: Epoch 158 - training loss: 9277.8433, validation loss: 0.0832
2024-05-22 22:56:25 [INFO]: Epoch 159 - training loss: 9277.5617, validation loss: 0.0840
2024-05-22 22:56:25 [INFO]: Epoch 160 - training loss: 9277.1679, validation loss: 0.0847
2024-05-22 22:56:25 [INFO]: Epoch 161 - training loss: 9276.8486, validation loss: 0.0831
2024-05-22 22:56:25 [INFO]: Epoch 162 - training loss: 9277.7715, validation loss: 0.0818
2024-05-22 22:56:25 [INFO]: Epoch 163 - training loss: 9277.3364, validation loss: 0.0825
2024-05-22 22:56:25 [INFO]: Epoch 164 - training loss: 9277.2535, validation loss: 0.0813
2024-05-22 22:56:25 [INFO]: Epoch 165 - training loss: 9276.9470, validation loss: 0.0825
2024-05-22 22:56:26 [INFO]: Epoch 166 - training loss: 9278.6770, validation loss: 0.0821
2024-05-22 22:56:26 [INFO]: Epoch 167 - training loss: 9276.6569, validation loss: 0.0814
2024-05-22 22:56:26 [INFO]: Epoch 168 - training loss: 9277.9136, validation loss: 0.0816
2024-05-22 22:56:26 [INFO]: Epoch 169 - training loss: 9276.0193, validation loss: 0.0820
2024-05-22 22:56:26 [INFO]: Epoch 170 - training loss: 9277.5814, validation loss: 0.0792
2024-05-22 22:56:26 [INFO]: Epoch 171 - training loss: 9275.9515, validation loss: 0.0797
2024-05-22 22:56:26 [INFO]: Epoch 172 - training loss: 9277.9435, validation loss: 0.0795
2024-05-22 22:56:26 [INFO]: Epoch 173 - training loss: 9277.2128, validation loss: 0.0782
2024-05-22 22:56:26 [INFO]: Epoch 174 - training loss: 9274.8795, validation loss: 0.0813
2024-05-22 22:56:27 [INFO]: Epoch 175 - training loss: 9276.4326, validation loss: 0.0798
2024-05-22 22:56:27 [INFO]: Epoch 176 - training loss: 9276.9484, validation loss: 0.0785
2024-05-22 22:56:27 [INFO]: Epoch 177 - training loss: 9275.3740, validation loss: 0.0816
2024-05-22 22:56:27 [INFO]: Epoch 178 - training loss: 9276.0178, validation loss: 0.0786
2024-05-22 22:56:27 [INFO]: Epoch 179 - training loss: 9277.0029, validation loss: 0.0778
2024-05-22 22:56:27 [INFO]: Epoch 180 - training loss: 9274.3518, validation loss: 0.0773
2024-05-22 22:56:27 [INFO]: Epoch 181 - training loss: 9274.7223, validation loss: 0.0789
2024-05-22 22:56:27 [INFO]: Epoch 182 - training loss: 9275.2945, validation loss: 0.0794
2024-05-22 22:56:27 [INFO]: Epoch 183 - training loss: 9274.0346, validation loss: 0.0786
2024-05-22 22:56:28 [INFO]: Epoch 184 - training loss: 9275.0236, validation loss: 0.0792
2024-05-22 22:56:28 [INFO]: Epoch 185 - training loss: 9273.6587, validation loss: 0.0790
2024-05-22 22:56:28 [INFO]: Epoch 186 - training loss: 9274.2961, validation loss: 0.0790
2024-05-22 22:56:28 [INFO]: Epoch 187 - training loss: 9274.6113, validation loss: 0.0785
2024-05-22 22:56:28 [INFO]: Epoch 188 - training loss: 9274.6098, validation loss: 0.0784
2024-05-22 22:56:28 [INFO]: Epoch 189 - training loss: 9275.7269, validation loss: 0.0790
2024-05-22 22:56:28 [INFO]: Epoch 190 - training loss: 9274.7830, validation loss: 0.0792
2024-05-22 22:56:28 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 22:56:28 [INFO]: Finished training. The best model is from epoch#180.
2024-05-22 22:56:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_ettm1/20240522_T225607/GPVAE.pypots
2024-05-22 22:56:28 [INFO]: GP-VAE on ETTm1: MAE=0.2665, MSE=0.1494
2024-05-22 22:56:28 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-22 22:56:28 [INFO]: Using the given device: cuda:0
2024-05-22 22:56:28 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240522_T225628
2024-05-22 22:56:28 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_ettm1/20240522_T225628/tensorboard
2024-05-22 22:56:28 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-22 22:56:36 [INFO]: Epoch 001 - generator training loss: 0.4704, discriminator training loss: 0.4295, validation loss: 0.2956
2024-05-22 22:56:44 [INFO]: Epoch 002 - generator training loss: -0.0169, discriminator training loss: 0.3244, validation loss: 0.0913
2024-05-22 22:56:51 [INFO]: Epoch 003 - generator training loss: -0.1288, discriminator training loss: 0.3096, validation loss: 0.0597
2024-05-22 22:56:58 [INFO]: Epoch 004 - generator training loss: -0.1457, discriminator training loss: 0.3012, validation loss: 0.0481
2024-05-22 22:57:05 [INFO]: Epoch 005 - generator training loss: -0.1325, discriminator training loss: 0.2820, validation loss: 0.0430
2024-05-22 22:57:13 [INFO]: Epoch 006 - generator training loss: -0.1139, discriminator training loss: 0.2550, validation loss: 0.0377
2024-05-22 22:57:20 [INFO]: Epoch 007 - generator training loss: -0.0872, discriminator training loss: 0.2184, validation loss: 0.0359
2024-05-22 22:57:27 [INFO]: Epoch 008 - generator training loss: -0.0676, discriminator training loss: 0.1859, validation loss: 0.0345
2024-05-22 22:57:34 [INFO]: Epoch 009 - generator training loss: -0.0508, discriminator training loss: 0.1602, validation loss: 0.0347
2024-05-22 22:57:42 [INFO]: Epoch 010 - generator training loss: -0.0441, discriminator training loss: 0.1448, validation loss: 0.0335
2024-05-22 22:57:49 [INFO]: Epoch 011 - generator training loss: -0.0372, discriminator training loss: 0.1345, validation loss: 0.0334
2024-05-22 22:57:56 [INFO]: Epoch 012 - generator training loss: -0.0367, discriminator training loss: 0.1281, validation loss: 0.0324
2024-05-22 22:58:03 [INFO]: Epoch 013 - generator training loss: -0.0343, discriminator training loss: 0.1250, validation loss: 0.0318
2024-05-22 22:58:11 [INFO]: Epoch 014 - generator training loss: -0.0320, discriminator training loss: 0.1233, validation loss: 0.0314
2024-05-22 22:58:18 [INFO]: Epoch 015 - generator training loss: -0.0349, discriminator training loss: 0.1213, validation loss: 0.0309
2024-05-22 22:58:25 [INFO]: Epoch 016 - generator training loss: -0.0331, discriminator training loss: 0.1213, validation loss: 0.0308
2024-05-22 22:58:32 [INFO]: Epoch 017 - generator training loss: -0.0323, discriminator training loss: 0.1184, validation loss: 0.0311
2024-05-22 22:58:39 [INFO]: Epoch 018 - generator training loss: -0.0313, discriminator training loss: 0.1161, validation loss: 0.0313
2024-05-22 22:58:46 [INFO]: Epoch 019 - generator training loss: -0.0340, discriminator training loss: 0.1173, validation loss: 0.0307
2024-05-22 22:58:53 [INFO]: Epoch 020 - generator training loss: -0.0331, discriminator training loss: 0.1169, validation loss: 0.0295
2024-05-22 22:59:01 [INFO]: Epoch 021 - generator training loss: -0.0346, discriminator training loss: 0.1151, validation loss: 0.0290
2024-05-22 22:59:08 [INFO]: Epoch 022 - generator training loss: -0.0333, discriminator training loss: 0.1144, validation loss: 0.0283
2024-05-22 22:59:15 [INFO]: Epoch 023 - generator training loss: -0.0330, discriminator training loss: 0.1143, validation loss: 0.0287
2024-05-22 22:59:22 [INFO]: Epoch 024 - generator training loss: -0.0363, discriminator training loss: 0.1115, validation loss: 0.0277
2024-05-22 22:59:29 [INFO]: Epoch 025 - generator training loss: -0.0391, discriminator training loss: 0.1137, validation loss: 0.0288
2024-05-22 22:59:36 [INFO]: Epoch 026 - generator training loss: -0.0310, discriminator training loss: 0.1132, validation loss: 0.0275
2024-05-22 22:59:44 [INFO]: Epoch 027 - generator training loss: -0.0364, discriminator training loss: 0.1139, validation loss: 0.0272
2024-05-22 22:59:51 [INFO]: Epoch 028 - generator training loss: -0.0335, discriminator training loss: 0.1127, validation loss: 0.0296
2024-05-22 22:59:58 [INFO]: Epoch 029 - generator training loss: -0.0392, discriminator training loss: 0.1128, validation loss: 0.0265
2024-05-22 23:00:05 [INFO]: Epoch 030 - generator training loss: -0.0399, discriminator training loss: 0.1135, validation loss: 0.0261
2024-05-22 23:00:12 [INFO]: Epoch 031 - generator training loss: -0.0425, discriminator training loss: 0.1132, validation loss: 0.0258
2024-05-22 23:00:20 [INFO]: Epoch 032 - generator training loss: -0.0380, discriminator training loss: 0.1107, validation loss: 0.0256
2024-05-22 23:00:27 [INFO]: Epoch 033 - generator training loss: -0.0401, discriminator training loss: 0.1113, validation loss: 0.0261
2024-05-22 23:00:34 [INFO]: Epoch 034 - generator training loss: -0.0396, discriminator training loss: 0.1141, validation loss: 0.0253
2024-05-22 23:00:41 [INFO]: Epoch 035 - generator training loss: -0.0398, discriminator training loss: 0.1119, validation loss: 0.0258
2024-05-22 23:00:48 [INFO]: Epoch 036 - generator training loss: -0.0409, discriminator training loss: 0.1131, validation loss: 0.0260
2024-05-22 23:00:55 [INFO]: Epoch 037 - generator training loss: -0.0385, discriminator training loss: 0.1113, validation loss: 0.0261
2024-05-22 23:01:03 [INFO]: Epoch 038 - generator training loss: -0.0405, discriminator training loss: 0.1097, validation loss: 0.0253
2024-05-22 23:01:10 [INFO]: Epoch 039 - generator training loss: -0.0418, discriminator training loss: 0.1095, validation loss: 0.0250
2024-05-22 23:01:17 [INFO]: Epoch 040 - generator training loss: -0.0431, discriminator training loss: 0.1080, validation loss: 0.0246
2024-05-22 23:01:24 [INFO]: Epoch 041 - generator training loss: -0.0393, discriminator training loss: 0.1104, validation loss: 0.0253
2024-05-22 23:01:31 [INFO]: Epoch 042 - generator training loss: -0.0424, discriminator training loss: 0.1097, validation loss: 0.0243
2024-05-22 23:01:38 [INFO]: Epoch 043 - generator training loss: -0.0434, discriminator training loss: 0.1112, validation loss: 0.0240
2024-05-22 23:01:46 [INFO]: Epoch 044 - generator training loss: -0.0428, discriminator training loss: 0.1102, validation loss: 0.0237
2024-05-22 23:01:53 [INFO]: Epoch 045 - generator training loss: -0.0433, discriminator training loss: 0.1099, validation loss: 0.0249
2024-05-22 23:02:00 [INFO]: Epoch 046 - generator training loss: -0.0378, discriminator training loss: 0.1097, validation loss: 0.0238
2024-05-22 23:02:07 [INFO]: Epoch 047 - generator training loss: -0.0422, discriminator training loss: 0.1098, validation loss: 0.0239
2024-05-22 23:02:14 [INFO]: Epoch 048 - generator training loss: -0.0442, discriminator training loss: 0.1093, validation loss: 0.0239
2024-05-22 23:02:21 [INFO]: Epoch 049 - generator training loss: -0.0407, discriminator training loss: 0.1106, validation loss: 0.0254
2024-05-22 23:02:29 [INFO]: Epoch 050 - generator training loss: -0.0436, discriminator training loss: 0.1082, validation loss: 0.0237
2024-05-22 23:02:36 [INFO]: Epoch 051 - generator training loss: -0.0420, discriminator training loss: 0.1090, validation loss: 0.0245
2024-05-22 23:02:43 [INFO]: Epoch 052 - generator training loss: -0.0428, discriminator training loss: 0.1076, validation loss: 0.0237
2024-05-22 23:02:50 [INFO]: Epoch 053 - generator training loss: -0.0442, discriminator training loss: 0.1105, validation loss: 0.0238
2024-05-22 23:02:57 [INFO]: Epoch 054 - generator training loss: -0.0428, discriminator training loss: 0.1086, validation loss: 0.0232
2024-05-22 23:03:05 [INFO]: Epoch 055 - generator training loss: -0.0419, discriminator training loss: 0.1075, validation loss: 0.0239
2024-05-22 23:03:12 [INFO]: Epoch 056 - generator training loss: -0.0456, discriminator training loss: 0.1086, validation loss: 0.0234
2024-05-22 23:03:19 [INFO]: Epoch 057 - generator training loss: -0.0430, discriminator training loss: 0.1078, validation loss: 0.0231
2024-05-22 23:03:26 [INFO]: Epoch 058 - generator training loss: -0.0422, discriminator training loss: 0.1084, validation loss: 0.0235
2024-05-22 23:03:33 [INFO]: Epoch 059 - generator training loss: -0.0434, discriminator training loss: 0.1070, validation loss: 0.0243
2024-05-22 23:03:40 [INFO]: Epoch 060 - generator training loss: -0.0425, discriminator training loss: 0.1094, validation loss: 0.0236
2024-05-22 23:03:48 [INFO]: Epoch 061 - generator training loss: -0.0422, discriminator training loss: 0.1105, validation loss: 0.0236
2024-05-22 23:03:55 [INFO]: Epoch 062 - generator training loss: -0.0449, discriminator training loss: 0.1089, validation loss: 0.0231
2024-05-22 23:04:02 [INFO]: Epoch 063 - generator training loss: -0.0418, discriminator training loss: 0.1090, validation loss: 0.0226
2024-05-22 23:04:09 [INFO]: Epoch 064 - generator training loss: -0.0425, discriminator training loss: 0.1075, validation loss: 0.0222
2024-05-22 23:04:16 [INFO]: Epoch 065 - generator training loss: -0.0440, discriminator training loss: 0.1052, validation loss: 0.0232
2024-05-22 23:04:23 [INFO]: Epoch 066 - generator training loss: -0.0445, discriminator training loss: 0.1076, validation loss: 0.0226
2024-05-22 23:04:30 [INFO]: Epoch 067 - generator training loss: -0.0453, discriminator training loss: 0.1065, validation loss: 0.0222
2024-05-22 23:04:38 [INFO]: Epoch 068 - generator training loss: -0.0446, discriminator training loss: 0.1060, validation loss: 0.0215
2024-05-22 23:04:45 [INFO]: Epoch 069 - generator training loss: -0.0467, discriminator training loss: 0.1067, validation loss: 0.0219
2024-05-22 23:04:52 [INFO]: Epoch 070 - generator training loss: -0.0436, discriminator training loss: 0.1080, validation loss: 0.0221
2024-05-22 23:04:59 [INFO]: Epoch 071 - generator training loss: -0.0450, discriminator training loss: 0.1051, validation loss: 0.0239
2024-05-22 23:05:06 [INFO]: Epoch 072 - generator training loss: -0.0452, discriminator training loss: 0.1100, validation loss: 0.0220
2024-05-22 23:05:13 [INFO]: Epoch 073 - generator training loss: -0.0436, discriminator training loss: 0.1091, validation loss: 0.0232
2024-05-22 23:05:21 [INFO]: Epoch 074 - generator training loss: -0.0461, discriminator training loss: 0.1090, validation loss: 0.0209
2024-05-22 23:05:28 [INFO]: Epoch 075 - generator training loss: -0.0441, discriminator training loss: 0.1075, validation loss: 0.0212
2024-05-22 23:05:35 [INFO]: Epoch 076 - generator training loss: -0.0457, discriminator training loss: 0.1047, validation loss: 0.0213
2024-05-22 23:05:42 [INFO]: Epoch 077 - generator training loss: -0.0484, discriminator training loss: 0.1080, validation loss: 0.0208
2024-05-22 23:05:50 [INFO]: Epoch 078 - generator training loss: -0.0484, discriminator training loss: 0.1091, validation loss: 0.0207
2024-05-22 23:05:57 [INFO]: Epoch 079 - generator training loss: -0.0461, discriminator training loss: 0.1075, validation loss: 0.0205
2024-05-22 23:06:04 [INFO]: Epoch 080 - generator training loss: -0.0460, discriminator training loss: 0.1079, validation loss: 0.0214
2024-05-22 23:06:11 [INFO]: Epoch 081 - generator training loss: -0.0468, discriminator training loss: 0.1067, validation loss: 0.0211
2024-05-22 23:06:18 [INFO]: Epoch 082 - generator training loss: -0.0503, discriminator training loss: 0.1071, validation loss: 0.0208
2024-05-22 23:06:25 [INFO]: Epoch 083 - generator training loss: -0.0472, discriminator training loss: 0.1062, validation loss: 0.0198
2024-05-22 23:06:33 [INFO]: Epoch 084 - generator training loss: -0.0462, discriminator training loss: 0.1067, validation loss: 0.0206
2024-05-22 23:06:40 [INFO]: Epoch 085 - generator training loss: -0.0459, discriminator training loss: 0.1085, validation loss: 0.0207
2024-05-22 23:06:47 [INFO]: Epoch 086 - generator training loss: -0.0469, discriminator training loss: 0.1060, validation loss: 0.0254
2024-05-22 23:06:54 [INFO]: Epoch 087 - generator training loss: -0.0454, discriminator training loss: 0.1077, validation loss: 0.0192
2024-05-22 23:07:01 [INFO]: Epoch 088 - generator training loss: -0.0463, discriminator training loss: 0.1059, validation loss: 0.0215
2024-05-22 23:07:08 [INFO]: Epoch 089 - generator training loss: -0.0465, discriminator training loss: 0.1058, validation loss: 0.0192
2024-05-22 23:07:15 [INFO]: Epoch 090 - generator training loss: -0.0457, discriminator training loss: 0.1057, validation loss: 0.0196
2024-05-22 23:07:23 [INFO]: Epoch 091 - generator training loss: -0.0487, discriminator training loss: 0.1054, validation loss: 0.0194
2024-05-22 23:07:30 [INFO]: Epoch 092 - generator training loss: -0.0497, discriminator training loss: 0.1064, validation loss: 0.0192
2024-05-22 23:07:37 [INFO]: Epoch 093 - generator training loss: -0.0457, discriminator training loss: 0.1058, validation loss: 0.0199
2024-05-22 23:07:44 [INFO]: Epoch 094 - generator training loss: -0.0497, discriminator training loss: 0.1072, validation loss: 0.0197
2024-05-22 23:07:52 [INFO]: Epoch 095 - generator training loss: -0.0467, discriminator training loss: 0.1064, validation loss: 0.0196
2024-05-22 23:07:59 [INFO]: Epoch 096 - generator training loss: -0.0472, discriminator training loss: 0.1089, validation loss: 0.0190
2024-05-22 23:08:06 [INFO]: Epoch 097 - generator training loss: -0.0487, discriminator training loss: 0.1064, validation loss: 0.0196
2024-05-22 23:08:13 [INFO]: Epoch 098 - generator training loss: -0.0447, discriminator training loss: 0.1062, validation loss: 0.0179
2024-05-22 23:08:21 [INFO]: Epoch 099 - generator training loss: -0.0459, discriminator training loss: 0.1050, validation loss: 0.0197
2024-05-22 23:08:28 [INFO]: Epoch 100 - generator training loss: -0.0479, discriminator training loss: 0.1054, validation loss: 0.0201
2024-05-22 23:08:35 [INFO]: Epoch 101 - generator training loss: -0.0508, discriminator training loss: 0.1060, validation loss: 0.0188
2024-05-22 23:08:42 [INFO]: Epoch 102 - generator training loss: -0.0473, discriminator training loss: 0.1059, validation loss: 0.0187
2024-05-22 23:08:49 [INFO]: Epoch 103 - generator training loss: -0.0516, discriminator training loss: 0.1056, validation loss: 0.0184
2024-05-22 23:08:56 [INFO]: Epoch 104 - generator training loss: -0.0485, discriminator training loss: 0.1055, validation loss: 0.0186
2024-05-22 23:09:04 [INFO]: Epoch 105 - generator training loss: -0.0507, discriminator training loss: 0.1056, validation loss: 0.0192
2024-05-22 23:09:11 [INFO]: Epoch 106 - generator training loss: -0.0456, discriminator training loss: 0.1052, validation loss: 0.0201
2024-05-22 23:09:18 [INFO]: Epoch 107 - generator training loss: -0.0480, discriminator training loss: 0.1032, validation loss: 0.0198
2024-05-22 23:09:25 [INFO]: Epoch 108 - generator training loss: -0.0473, discriminator training loss: 0.1054, validation loss: 0.0190
2024-05-22 23:09:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 23:09:25 [INFO]: Finished training. The best model is from epoch#98.
2024-05-22 23:09:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_ettm1/20240522_T225628/USGAN.pypots
2024-05-22 23:09:25 [INFO]: US-GAN on ETTm1: MAE=0.1485, MSE=0.0609
2024-05-22 23:09:25 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-22 23:09:25 [INFO]: Using the given device: cuda:0
2024-05-22 23:09:25 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240522_T230925
2024-05-22 23:09:25 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_ettm1/20240522_T230925/tensorboard
2024-05-22 23:09:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-22 23:09:31 [INFO]: Epoch 001 - training loss: 1.3257, validation loss: 0.3106
2024-05-22 23:09:36 [INFO]: Epoch 002 - training loss: 0.9091, validation loss: 0.1042
2024-05-22 23:09:41 [INFO]: Epoch 003 - training loss: 0.7144, validation loss: 0.0592
2024-05-22 23:09:45 [INFO]: Epoch 004 - training loss: 0.6300, validation loss: 0.0448
2024-05-22 23:09:50 [INFO]: Epoch 005 - training loss: 0.5870, validation loss: 0.0444
2024-05-22 23:09:55 [INFO]: Epoch 006 - training loss: 0.5895, validation loss: 0.0377
2024-05-22 23:10:00 [INFO]: Epoch 007 - training loss: 0.5466, validation loss: 0.0340
2024-05-22 23:10:04 [INFO]: Epoch 008 - training loss: 0.5106, validation loss: 0.0321
2024-05-22 23:10:09 [INFO]: Epoch 009 - training loss: 0.4958, validation loss: 0.0302
2024-05-22 23:10:14 [INFO]: Epoch 010 - training loss: 0.4816, validation loss: 0.0328
2024-05-22 23:10:18 [INFO]: Epoch 011 - training loss: 0.4704, validation loss: 0.0287
2024-05-22 23:10:23 [INFO]: Epoch 012 - training loss: 0.4453, validation loss: 0.0272
2024-05-22 23:10:28 [INFO]: Epoch 013 - training loss: 0.4334, validation loss: 0.0254
2024-05-22 23:10:33 [INFO]: Epoch 014 - training loss: 0.4271, validation loss: 0.0248
2024-05-22 23:10:37 [INFO]: Epoch 015 - training loss: 0.4131, validation loss: 0.0246
2024-05-22 23:10:42 [INFO]: Epoch 016 - training loss: 0.4081, validation loss: 0.0241
2024-05-22 23:10:47 [INFO]: Epoch 017 - training loss: 0.4029, validation loss: 0.0234
2024-05-22 23:10:51 [INFO]: Epoch 018 - training loss: 0.3963, validation loss: 0.0234
2024-05-22 23:10:56 [INFO]: Epoch 019 - training loss: 0.4183, validation loss: 0.0233
2024-05-22 23:11:01 [INFO]: Epoch 020 - training loss: 0.3991, validation loss: 0.0229
2024-05-22 23:11:05 [INFO]: Epoch 021 - training loss: 0.3872, validation loss: 0.0224
2024-05-22 23:11:10 [INFO]: Epoch 022 - training loss: 0.3900, validation loss: 0.0221
2024-05-22 23:11:15 [INFO]: Epoch 023 - training loss: 0.3865, validation loss: 0.0222
2024-05-22 23:11:19 [INFO]: Epoch 024 - training loss: 0.3844, validation loss: 0.0224
2024-05-22 23:11:24 [INFO]: Epoch 025 - training loss: 0.3839, validation loss: 0.0222
2024-05-22 23:11:29 [INFO]: Epoch 026 - training loss: 0.3872, validation loss: 0.0219
2024-05-22 23:11:34 [INFO]: Epoch 027 - training loss: 0.3834, validation loss: 0.0222
2024-05-22 23:11:38 [INFO]: Epoch 028 - training loss: 0.3878, validation loss: 0.0223
2024-05-22 23:11:43 [INFO]: Epoch 029 - training loss: 0.3842, validation loss: 0.0223
2024-05-22 23:11:48 [INFO]: Epoch 030 - training loss: 0.3827, validation loss: 0.0224
2024-05-22 23:11:52 [INFO]: Epoch 031 - training loss: 0.3786, validation loss: 0.0219
2024-05-22 23:11:57 [INFO]: Epoch 032 - training loss: 0.3851, validation loss: 0.0220
2024-05-22 23:12:02 [INFO]: Epoch 033 - training loss: 0.3875, validation loss: 0.0224
2024-05-22 23:12:07 [INFO]: Epoch 034 - training loss: 0.3943, validation loss: 0.0231
2024-05-22 23:12:11 [INFO]: Epoch 035 - training loss: 0.3872, validation loss: 0.0232
2024-05-22 23:12:16 [INFO]: Epoch 036 - training loss: 0.3857, validation loss: 0.0227
2024-05-22 23:12:21 [INFO]: Epoch 037 - training loss: 0.3793, validation loss: 0.0221
2024-05-22 23:12:26 [INFO]: Epoch 038 - training loss: 0.3766, validation loss: 0.0221
2024-05-22 23:12:31 [INFO]: Epoch 039 - training loss: 0.3778, validation loss: 0.0219
2024-05-22 23:12:36 [INFO]: Epoch 040 - training loss: 0.3731, validation loss: 0.0222
2024-05-22 23:12:41 [INFO]: Epoch 041 - training loss: 0.3758, validation loss: 0.0218
2024-05-22 23:12:46 [INFO]: Epoch 042 - training loss: 0.3788, validation loss: 0.0218
2024-05-22 23:12:51 [INFO]: Epoch 043 - training loss: 0.3750, validation loss: 0.0219
2024-05-22 23:12:56 [INFO]: Epoch 044 - training loss: 0.3852, validation loss: 0.0222
2024-05-22 23:13:01 [INFO]: Epoch 045 - training loss: 0.3763, validation loss: 0.0221
2024-05-22 23:13:06 [INFO]: Epoch 046 - training loss: 0.3797, validation loss: 0.0219
2024-05-22 23:13:11 [INFO]: Epoch 047 - training loss: 0.3730, validation loss: 0.0223
2024-05-22 23:13:16 [INFO]: Epoch 048 - training loss: 0.3819, validation loss: 0.0223
2024-05-22 23:13:21 [INFO]: Epoch 049 - training loss: 0.3726, validation loss: 0.0223
2024-05-22 23:13:26 [INFO]: Epoch 050 - training loss: 0.3754, validation loss: 0.0222
2024-05-22 23:13:31 [INFO]: Epoch 051 - training loss: 0.3733, validation loss: 0.0221
2024-05-22 23:13:36 [INFO]: Epoch 052 - training loss: 0.3742, validation loss: 0.0220
2024-05-22 23:13:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 23:13:36 [INFO]: Finished training. The best model is from epoch#42.
2024-05-22 23:13:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_ettm1/20240522_T230925/BRITS.pypots
2024-05-22 23:13:37 [INFO]: BRITS on ETTm1: MAE=0.1257, MSE=0.0481
2024-05-22 23:13:37 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-22 23:13:37 [INFO]: Using the given device: cuda:0
2024-05-22 23:13:37 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337
2024-05-22 23:13:37 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/tensorboard
2024-05-22 23:13:37 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-22 23:13:38 [INFO]: Epoch 001 - training loss: 1.4179, validation loss: 1.2840
2024-05-22 23:13:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch1_loss1.284007340669632.pypots
2024-05-22 23:13:38 [INFO]: Epoch 002 - training loss: 1.0463, validation loss: 1.1234
2024-05-22 23:13:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch2_loss1.1233887672424316.pypots
2024-05-22 23:13:38 [INFO]: Epoch 003 - training loss: 0.9731, validation loss: 1.0468
2024-05-22 23:13:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch3_loss1.0467899441719055.pypots
2024-05-22 23:13:39 [INFO]: Epoch 004 - training loss: 0.9556, validation loss: 1.0225
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch4_loss1.022502064704895.pypots
2024-05-22 23:13:39 [INFO]: Epoch 005 - training loss: 0.9273, validation loss: 1.0097
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch5_loss1.0097305476665497.pypots
2024-05-22 23:13:39 [INFO]: Epoch 006 - training loss: 0.9253, validation loss: 1.0025
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch6_loss1.0025113224983215.pypots
2024-05-22 23:13:39 [INFO]: Epoch 007 - training loss: 0.9168, validation loss: 0.9947
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch7_loss0.99474036693573.pypots
2024-05-22 23:13:39 [INFO]: Epoch 008 - training loss: 0.9165, validation loss: 0.9872
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch8_loss0.987173780798912.pypots
2024-05-22 23:13:39 [INFO]: Epoch 009 - training loss: 0.9191, validation loss: 0.9833
2024-05-22 23:13:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch9_loss0.9833420068025589.pypots
2024-05-22 23:13:40 [INFO]: Epoch 010 - training loss: 0.9169, validation loss: 0.9818
2024-05-22 23:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch10_loss0.9817728251218796.pypots
2024-05-22 23:13:40 [INFO]: Epoch 011 - training loss: 0.8858, validation loss: 0.9788
2024-05-22 23:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch11_loss0.9788422286510468.pypots
2024-05-22 23:13:40 [INFO]: Epoch 012 - training loss: 0.9076, validation loss: 0.9754
2024-05-22 23:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch12_loss0.9754353761672974.pypots
2024-05-22 23:13:40 [INFO]: Epoch 013 - training loss: 0.8828, validation loss: 0.9767
2024-05-22 23:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch13_loss0.9766877591609955.pypots
2024-05-22 23:13:40 [INFO]: Epoch 014 - training loss: 0.8617, validation loss: 0.9798
2024-05-22 23:13:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch14_loss0.9797550141811371.pypots
2024-05-22 23:13:41 [INFO]: Epoch 015 - training loss: 0.9036, validation loss: 0.9802
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch15_loss0.9801576733589172.pypots
2024-05-22 23:13:41 [INFO]: Epoch 016 - training loss: 0.8694, validation loss: 0.9749
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch16_loss0.9748901873826981.pypots
2024-05-22 23:13:41 [INFO]: Epoch 017 - training loss: 0.8405, validation loss: 0.9768
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch17_loss0.9767963141202927.pypots
2024-05-22 23:13:41 [INFO]: Epoch 018 - training loss: 0.8660, validation loss: 0.9703
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch18_loss0.9702805131673813.pypots
2024-05-22 23:13:41 [INFO]: Epoch 019 - training loss: 0.8557, validation loss: 0.9698
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch19_loss0.9698388874530792.pypots
2024-05-22 23:13:41 [INFO]: Epoch 020 - training loss: 0.8395, validation loss: 0.9644
2024-05-22 23:13:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch20_loss0.9644308239221573.pypots
2024-05-22 23:13:42 [INFO]: Epoch 021 - training loss: 0.8496, validation loss: 0.9622
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch21_loss0.9621898680925369.pypots
2024-05-22 23:13:42 [INFO]: Epoch 022 - training loss: 0.8586, validation loss: 0.9615
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch22_loss0.9615455567836761.pypots
2024-05-22 23:13:42 [INFO]: Epoch 023 - training loss: 0.8531, validation loss: 0.9587
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch23_loss0.9587068408727646.pypots
2024-05-22 23:13:42 [INFO]: Epoch 024 - training loss: 0.8328, validation loss: 0.9575
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch24_loss0.9574999362230301.pypots
2024-05-22 23:13:42 [INFO]: Epoch 025 - training loss: 0.8057, validation loss: 0.9542
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch25_loss0.95421302318573.pypots
2024-05-22 23:13:42 [INFO]: Epoch 026 - training loss: 0.8207, validation loss: 0.9519
2024-05-22 23:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch26_loss0.9518921077251434.pypots
2024-05-22 23:13:43 [INFO]: Epoch 027 - training loss: 0.8610, validation loss: 0.9502
2024-05-22 23:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch27_loss0.9502056688070297.pypots
2024-05-22 23:13:43 [INFO]: Epoch 028 - training loss: 0.8140, validation loss: 0.9426
2024-05-22 23:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch28_loss0.9425836503505707.pypots
2024-05-22 23:13:43 [INFO]: Epoch 029 - training loss: 0.8496, validation loss: 0.9409
2024-05-22 23:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch29_loss0.9408751577138901.pypots
2024-05-22 23:13:43 [INFO]: Epoch 030 - training loss: 0.8289, validation loss: 0.9381
2024-05-22 23:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch30_loss0.9380675405263901.pypots
2024-05-22 23:13:43 [INFO]: Epoch 031 - training loss: 0.8245, validation loss: 0.9291
2024-05-22 23:13:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch31_loss0.9290923029184341.pypots
2024-05-22 23:13:44 [INFO]: Epoch 032 - training loss: 0.8142, validation loss: 0.9282
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch32_loss0.9281617552042007.pypots
2024-05-22 23:13:44 [INFO]: Epoch 033 - training loss: 0.8175, validation loss: 0.9219
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch33_loss0.9219090789556503.pypots
2024-05-22 23:13:44 [INFO]: Epoch 034 - training loss: 0.8181, validation loss: 0.9177
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch34_loss0.9176622182130814.pypots
2024-05-22 23:13:44 [INFO]: Epoch 035 - training loss: 0.8104, validation loss: 0.9188
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch35_loss0.9187827706336975.pypots
2024-05-22 23:13:44 [INFO]: Epoch 036 - training loss: 0.8257, validation loss: 0.9157
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch36_loss0.9156961143016815.pypots
2024-05-22 23:13:44 [INFO]: Epoch 037 - training loss: 0.8032, validation loss: 0.9118
2024-05-22 23:13:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch37_loss0.911762610077858.pypots
2024-05-22 23:13:45 [INFO]: Epoch 038 - training loss: 0.7877, validation loss: 0.9080
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch38_loss0.9079566150903702.pypots
2024-05-22 23:13:45 [INFO]: Epoch 039 - training loss: 0.8204, validation loss: 0.9043
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch39_loss0.9043377637863159.pypots
2024-05-22 23:13:45 [INFO]: Epoch 040 - training loss: 0.7983, validation loss: 0.9042
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch40_loss0.9042376428842545.pypots
2024-05-22 23:13:45 [INFO]: Epoch 041 - training loss: 0.8079, validation loss: 0.9012
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch41_loss0.9012492001056671.pypots
2024-05-22 23:13:45 [INFO]: Epoch 042 - training loss: 0.7914, validation loss: 0.8986
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch42_loss0.8986028283834457.pypots
2024-05-22 23:13:45 [INFO]: Epoch 043 - training loss: 0.8012, validation loss: 0.8962
2024-05-22 23:13:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch43_loss0.8962091654539108.pypots
2024-05-22 23:13:46 [INFO]: Epoch 044 - training loss: 0.7870, validation loss: 0.8944
2024-05-22 23:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch44_loss0.8943520933389664.pypots
2024-05-22 23:13:46 [INFO]: Epoch 045 - training loss: 0.8089, validation loss: 0.8912
2024-05-22 23:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch45_loss0.8912488222122192.pypots
2024-05-22 23:13:46 [INFO]: Epoch 046 - training loss: 0.8019, validation loss: 0.8896
2024-05-22 23:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch46_loss0.8895940184593201.pypots
2024-05-22 23:13:46 [INFO]: Epoch 047 - training loss: 0.7967, validation loss: 0.8869
2024-05-22 23:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch47_loss0.8868636786937714.pypots
2024-05-22 23:13:46 [INFO]: Epoch 048 - training loss: 0.8021, validation loss: 0.8870
2024-05-22 23:13:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch48_loss0.8870282024145126.pypots
2024-05-22 23:13:47 [INFO]: Epoch 049 - training loss: 0.7957, validation loss: 0.8848
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch49_loss0.8848384767770767.pypots
2024-05-22 23:13:47 [INFO]: Epoch 050 - training loss: 0.7715, validation loss: 0.8827
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch50_loss0.8826617449522018.pypots
2024-05-22 23:13:47 [INFO]: Epoch 051 - training loss: 0.8002, validation loss: 0.8818
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch51_loss0.881807953119278.pypots
2024-05-22 23:13:47 [INFO]: Epoch 052 - training loss: 0.7905, validation loss: 0.8803
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch52_loss0.8802649825811386.pypots
2024-05-22 23:13:47 [INFO]: Epoch 053 - training loss: 0.7826, validation loss: 0.8767
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch53_loss0.8767128139734268.pypots
2024-05-22 23:13:47 [INFO]: Epoch 054 - training loss: 0.7981, validation loss: 0.8763
2024-05-22 23:13:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch54_loss0.8762973099946976.pypots
2024-05-22 23:13:48 [INFO]: Epoch 055 - training loss: 0.7884, validation loss: 0.8755
2024-05-22 23:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch55_loss0.8754799515008926.pypots
2024-05-22 23:13:48 [INFO]: Epoch 056 - training loss: 0.7944, validation loss: 0.8739
2024-05-22 23:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch56_loss0.8739151805639267.pypots
2024-05-22 23:13:48 [INFO]: Epoch 057 - training loss: 0.7904, validation loss: 0.8718
2024-05-22 23:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch57_loss0.8717848360538483.pypots
2024-05-22 23:13:48 [INFO]: Epoch 058 - training loss: 0.7691, validation loss: 0.8715
2024-05-22 23:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch58_loss0.8715260773897171.pypots
2024-05-22 23:13:48 [INFO]: Epoch 059 - training loss: 0.7890, validation loss: 0.8705
2024-05-22 23:13:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch59_loss0.8705393821001053.pypots
2024-05-22 23:13:49 [INFO]: Epoch 060 - training loss: 0.7890, validation loss: 0.8708
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch60_loss0.8707723766565323.pypots
2024-05-22 23:13:49 [INFO]: Epoch 061 - training loss: 0.7980, validation loss: 0.8692
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch61_loss0.8691603243350983.pypots
2024-05-22 23:13:49 [INFO]: Epoch 062 - training loss: 0.7868, validation loss: 0.8671
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch62_loss0.8670941740274429.pypots
2024-05-22 23:13:49 [INFO]: Epoch 063 - training loss: 0.8236, validation loss: 0.8655
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch63_loss0.8654950708150864.pypots
2024-05-22 23:13:49 [INFO]: Epoch 064 - training loss: 0.7828, validation loss: 0.8647
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch64_loss0.8647087514400482.pypots
2024-05-22 23:13:49 [INFO]: Epoch 065 - training loss: 0.7641, validation loss: 0.8641
2024-05-22 23:13:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch65_loss0.8641017377376556.pypots
2024-05-22 23:13:50 [INFO]: Epoch 066 - training loss: 0.7838, validation loss: 0.8611
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch66_loss0.861114114522934.pypots
2024-05-22 23:13:50 [INFO]: Epoch 067 - training loss: 0.7874, validation loss: 0.8623
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch67_loss0.8622896522283554.pypots
2024-05-22 23:13:50 [INFO]: Epoch 068 - training loss: 0.7911, validation loss: 0.8595
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch68_loss0.8595210015773773.pypots
2024-05-22 23:13:50 [INFO]: Epoch 069 - training loss: 0.7984, validation loss: 0.8601
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch69_loss0.860125333070755.pypots
2024-05-22 23:13:50 [INFO]: Epoch 070 - training loss: 0.7861, validation loss: 0.8586
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch70_loss0.8586220443248749.pypots
2024-05-22 23:13:50 [INFO]: Epoch 071 - training loss: 0.7818, validation loss: 0.8577
2024-05-22 23:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch71_loss0.8577452600002289.pypots
2024-05-22 23:13:51 [INFO]: Epoch 072 - training loss: 0.7676, validation loss: 0.8572
2024-05-22 23:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch72_loss0.8572245836257935.pypots
2024-05-22 23:13:51 [INFO]: Epoch 073 - training loss: 0.7605, validation loss: 0.8561
2024-05-22 23:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch73_loss0.8561282306909561.pypots
2024-05-22 23:13:51 [INFO]: Epoch 074 - training loss: 0.8083, validation loss: 0.8564
2024-05-22 23:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch74_loss0.8564256131649017.pypots
2024-05-22 23:13:51 [INFO]: Epoch 075 - training loss: 0.7782, validation loss: 0.8559
2024-05-22 23:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch75_loss0.8558979630470276.pypots
2024-05-22 23:13:51 [INFO]: Epoch 076 - training loss: 0.7950, validation loss: 0.8552
2024-05-22 23:13:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch76_loss0.855193167924881.pypots
2024-05-22 23:13:52 [INFO]: Epoch 077 - training loss: 0.7837, validation loss: 0.8538
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch77_loss0.8537887185811996.pypots
2024-05-22 23:13:52 [INFO]: Epoch 078 - training loss: 0.7871, validation loss: 0.8559
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch78_loss0.8558980822563171.pypots
2024-05-22 23:13:52 [INFO]: Epoch 079 - training loss: 0.7804, validation loss: 0.8539
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch79_loss0.8538865000009537.pypots
2024-05-22 23:13:52 [INFO]: Epoch 080 - training loss: 0.7583, validation loss: 0.8537
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch80_loss0.853713184595108.pypots
2024-05-22 23:13:52 [INFO]: Epoch 081 - training loss: 0.7670, validation loss: 0.8520
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch81_loss0.852013424038887.pypots
2024-05-22 23:13:52 [INFO]: Epoch 082 - training loss: 0.7851, validation loss: 0.8545
2024-05-22 23:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch82_loss0.8545387983322144.pypots
2024-05-22 23:13:53 [INFO]: Epoch 083 - training loss: 0.7802, validation loss: 0.8519
2024-05-22 23:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch83_loss0.8518577218055725.pypots
2024-05-22 23:13:53 [INFO]: Epoch 084 - training loss: 0.7652, validation loss: 0.8521
2024-05-22 23:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch84_loss0.8520870506763458.pypots
2024-05-22 23:13:53 [INFO]: Epoch 085 - training loss: 0.7714, validation loss: 0.8509
2024-05-22 23:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch85_loss0.8509083837270737.pypots
2024-05-22 23:13:53 [INFO]: Epoch 086 - training loss: 0.7770, validation loss: 0.8535
2024-05-22 23:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch86_loss0.8535412400960922.pypots
2024-05-22 23:13:53 [INFO]: Epoch 087 - training loss: 0.7865, validation loss: 0.8494
2024-05-22 23:13:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch87_loss0.8493827134370804.pypots
2024-05-22 23:13:54 [INFO]: Epoch 088 - training loss: 0.7657, validation loss: 0.8496
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch88_loss0.8495924770832062.pypots
2024-05-22 23:13:54 [INFO]: Epoch 089 - training loss: 0.7574, validation loss: 0.8505
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch89_loss0.8505326360464096.pypots
2024-05-22 23:13:54 [INFO]: Epoch 090 - training loss: 0.7686, validation loss: 0.8502
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch90_loss0.8502495884895325.pypots
2024-05-22 23:13:54 [INFO]: Epoch 091 - training loss: 0.7834, validation loss: 0.8462
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch91_loss0.8462184071540833.pypots
2024-05-22 23:13:54 [INFO]: Epoch 092 - training loss: 0.7813, validation loss: 0.8467
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch92_loss0.846722349524498.pypots
2024-05-22 23:13:54 [INFO]: Epoch 093 - training loss: 0.7687, validation loss: 0.8508
2024-05-22 23:13:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch93_loss0.8507884293794632.pypots
2024-05-22 23:13:55 [INFO]: Epoch 094 - training loss: 0.7740, validation loss: 0.8518
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch94_loss0.8518443703651428.pypots
2024-05-22 23:13:55 [INFO]: Epoch 095 - training loss: 0.7846, validation loss: 0.8463
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch95_loss0.8462994694709778.pypots
2024-05-22 23:13:55 [INFO]: Epoch 096 - training loss: 0.7859, validation loss: 0.8476
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch96_loss0.847580075263977.pypots
2024-05-22 23:13:55 [INFO]: Epoch 097 - training loss: 0.7726, validation loss: 0.8479
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch97_loss0.8478723764419556.pypots
2024-05-22 23:13:55 [INFO]: Epoch 098 - training loss: 0.7807, validation loss: 0.8456
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch98_loss0.8455523103475571.pypots
2024-05-22 23:13:55 [INFO]: Epoch 099 - training loss: 0.7464, validation loss: 0.8443
2024-05-22 23:13:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch99_loss0.8443426340818405.pypots
2024-05-22 23:13:56 [INFO]: Epoch 100 - training loss: 0.7843, validation loss: 0.8460
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch100_loss0.8460368812084198.pypots
2024-05-22 23:13:56 [INFO]: Epoch 101 - training loss: 0.7677, validation loss: 0.8427
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch101_loss0.8427098095417023.pypots
2024-05-22 23:13:56 [INFO]: Epoch 102 - training loss: 0.7604, validation loss: 0.8442
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch102_loss0.844166561961174.pypots
2024-05-22 23:13:56 [INFO]: Epoch 103 - training loss: 0.7763, validation loss: 0.8439
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch103_loss0.8438733369112015.pypots
2024-05-22 23:13:56 [INFO]: Epoch 104 - training loss: 0.7669, validation loss: 0.8447
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch104_loss0.8447057604789734.pypots
2024-05-22 23:13:56 [INFO]: Epoch 105 - training loss: 0.7730, validation loss: 0.8438
2024-05-22 23:13:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch105_loss0.843837171792984.pypots
2024-05-22 23:13:57 [INFO]: Epoch 106 - training loss: 0.7545, validation loss: 0.8432
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch106_loss0.8431541621685028.pypots
2024-05-22 23:13:57 [INFO]: Epoch 107 - training loss: 0.7564, validation loss: 0.8438
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch107_loss0.8437631577253342.pypots
2024-05-22 23:13:57 [INFO]: Epoch 108 - training loss: 0.7659, validation loss: 0.8402
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch108_loss0.8401968777179718.pypots
2024-05-22 23:13:57 [INFO]: Epoch 109 - training loss: 0.7503, validation loss: 0.8404
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch109_loss0.840361937880516.pypots
2024-05-22 23:13:57 [INFO]: Epoch 110 - training loss: 0.7872, validation loss: 0.8405
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch110_loss0.8405350893735886.pypots
2024-05-22 23:13:57 [INFO]: Epoch 111 - training loss: 0.7709, validation loss: 0.8353
2024-05-22 23:13:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch111_loss0.8353278785943985.pypots
2024-05-22 23:13:58 [INFO]: Epoch 112 - training loss: 0.7709, validation loss: 0.8402
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch112_loss0.8401530236005783.pypots
2024-05-22 23:13:58 [INFO]: Epoch 113 - training loss: 0.7713, validation loss: 0.8381
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch113_loss0.8381323218345642.pypots
2024-05-22 23:13:58 [INFO]: Epoch 114 - training loss: 0.7726, validation loss: 0.8372
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch114_loss0.8371920883655548.pypots
2024-05-22 23:13:58 [INFO]: Epoch 115 - training loss: 0.7689, validation loss: 0.8369
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch115_loss0.8368710279464722.pypots
2024-05-22 23:13:58 [INFO]: Epoch 116 - training loss: 0.7890, validation loss: 0.8379
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch116_loss0.8378946632146835.pypots
2024-05-22 23:13:58 [INFO]: Epoch 117 - training loss: 0.7528, validation loss: 0.8356
2024-05-22 23:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch117_loss0.8356215357780457.pypots
2024-05-22 23:13:59 [INFO]: Epoch 118 - training loss: 0.7768, validation loss: 0.8347
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch118_loss0.8346993178129196.pypots
2024-05-22 23:13:59 [INFO]: Epoch 119 - training loss: 0.7749, validation loss: 0.8352
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch119_loss0.835195779800415.pypots
2024-05-22 23:13:59 [INFO]: Epoch 120 - training loss: 0.7702, validation loss: 0.8340
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch120_loss0.8339686691761017.pypots
2024-05-22 23:13:59 [INFO]: Epoch 121 - training loss: 0.7759, validation loss: 0.8356
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch121_loss0.8355601727962494.pypots
2024-05-22 23:13:59 [INFO]: Epoch 122 - training loss: 0.7695, validation loss: 0.8348
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch122_loss0.8348130881786346.pypots
2024-05-22 23:13:59 [INFO]: Epoch 123 - training loss: 0.7657, validation loss: 0.8331
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch123_loss0.8331247419118881.pypots
2024-05-22 23:13:59 [INFO]: Epoch 124 - training loss: 0.7685, validation loss: 0.8340
2024-05-22 23:13:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch124_loss0.8340011984109879.pypots
2024-05-22 23:14:00 [INFO]: Epoch 125 - training loss: 0.7657, validation loss: 0.8322
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch125_loss0.8321713805198669.pypots
2024-05-22 23:14:00 [INFO]: Epoch 126 - training loss: 0.7679, validation loss: 0.8332
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch126_loss0.8332402855157852.pypots
2024-05-22 23:14:00 [INFO]: Epoch 127 - training loss: 0.7554, validation loss: 0.8321
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch127_loss0.8320899456739426.pypots
2024-05-22 23:14:00 [INFO]: Epoch 128 - training loss: 0.7827, validation loss: 0.8344
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch128_loss0.8343663960695267.pypots
2024-05-22 23:14:00 [INFO]: Epoch 129 - training loss: 0.8020, validation loss: 0.8321
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch129_loss0.8320834040641785.pypots
2024-05-22 23:14:00 [INFO]: Epoch 130 - training loss: 0.7944, validation loss: 0.8262
2024-05-22 23:14:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch130_loss0.8262280076742172.pypots
2024-05-22 23:14:01 [INFO]: Epoch 131 - training loss: 0.7442, validation loss: 0.8296
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch131_loss0.8296317011117935.pypots
2024-05-22 23:14:01 [INFO]: Epoch 132 - training loss: 0.7675, validation loss: 0.8285
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch132_loss0.8285436928272247.pypots
2024-05-22 23:14:01 [INFO]: Epoch 133 - training loss: 0.7971, validation loss: 0.8298
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch133_loss0.8297717869281769.pypots
2024-05-22 23:14:01 [INFO]: Epoch 134 - training loss: 0.7735, validation loss: 0.8252
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch134_loss0.825247049331665.pypots
2024-05-22 23:14:01 [INFO]: Epoch 135 - training loss: 0.7534, validation loss: 0.8269
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch135_loss0.8269088566303253.pypots
2024-05-22 23:14:01 [INFO]: Epoch 136 - training loss: 0.7711, validation loss: 0.8297
2024-05-22 23:14:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch136_loss0.8297082632780075.pypots
2024-05-22 23:14:02 [INFO]: Epoch 137 - training loss: 0.7568, validation loss: 0.8247
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch137_loss0.8246815204620361.pypots
2024-05-22 23:14:02 [INFO]: Epoch 138 - training loss: 0.7460, validation loss: 0.8244
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch138_loss0.8244195431470871.pypots
2024-05-22 23:14:02 [INFO]: Epoch 139 - training loss: 0.7534, validation loss: 0.8233
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch139_loss0.823263019323349.pypots
2024-05-22 23:14:02 [INFO]: Epoch 140 - training loss: 0.7571, validation loss: 0.8258
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch140_loss0.82583287358284.pypots
2024-05-22 23:14:02 [INFO]: Epoch 141 - training loss: 0.7536, validation loss: 0.8239
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch141_loss0.8238687217235565.pypots
2024-05-22 23:14:02 [INFO]: Epoch 142 - training loss: 0.7602, validation loss: 0.8237
2024-05-22 23:14:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch142_loss0.8237474262714386.pypots
2024-05-22 23:14:03 [INFO]: Epoch 143 - training loss: 0.7609, validation loss: 0.8226
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch143_loss0.8226082623004913.pypots
2024-05-22 23:14:03 [INFO]: Epoch 144 - training loss: 0.7645, validation loss: 0.8241
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch144_loss0.8241006731987.pypots
2024-05-22 23:14:03 [INFO]: Epoch 145 - training loss: 0.7704, validation loss: 0.8194
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch145_loss0.8193930089473724.pypots
2024-05-22 23:14:03 [INFO]: Epoch 146 - training loss: 0.7572, validation loss: 0.8196
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch146_loss0.8195575475692749.pypots
2024-05-22 23:14:03 [INFO]: Epoch 147 - training loss: 0.7616, validation loss: 0.8185
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch147_loss0.8184749931097031.pypots
2024-05-22 23:14:03 [INFO]: Epoch 148 - training loss: 0.7645, validation loss: 0.8182
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch148_loss0.8182217329740524.pypots
2024-05-22 23:14:03 [INFO]: Epoch 149 - training loss: 0.7796, validation loss: 0.8195
2024-05-22 23:14:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch149_loss0.819527193903923.pypots
2024-05-22 23:14:04 [INFO]: Epoch 150 - training loss: 0.7824, validation loss: 0.8216
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch150_loss0.8215804249048233.pypots
2024-05-22 23:14:04 [INFO]: Epoch 151 - training loss: 0.7643, validation loss: 0.8187
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch151_loss0.8187171965837479.pypots
2024-05-22 23:14:04 [INFO]: Epoch 152 - training loss: 0.7734, validation loss: 0.8174
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch152_loss0.8174300789833069.pypots
2024-05-22 23:14:04 [INFO]: Epoch 153 - training loss: 0.7576, validation loss: 0.8163
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch153_loss0.8162603676319122.pypots
2024-05-22 23:14:04 [INFO]: Epoch 154 - training loss: 0.7436, validation loss: 0.8177
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch154_loss0.8177487254142761.pypots
2024-05-22 23:14:04 [INFO]: Epoch 155 - training loss: 0.7465, validation loss: 0.8156
2024-05-22 23:14:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch155_loss0.8155718892812729.pypots
2024-05-22 23:14:05 [INFO]: Epoch 156 - training loss: 0.7596, validation loss: 0.8160
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch156_loss0.8159719407558441.pypots
2024-05-22 23:14:05 [INFO]: Epoch 157 - training loss: 0.7628, validation loss: 0.8146
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch157_loss0.81463623046875.pypots
2024-05-22 23:14:05 [INFO]: Epoch 158 - training loss: 0.7614, validation loss: 0.8159
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch158_loss0.8158945888280869.pypots
2024-05-22 23:14:05 [INFO]: Epoch 159 - training loss: 0.7695, validation loss: 0.8139
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch159_loss0.8139061778783798.pypots
2024-05-22 23:14:05 [INFO]: Epoch 160 - training loss: 0.7707, validation loss: 0.8133
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch160_loss0.8132675141096115.pypots
2024-05-22 23:14:05 [INFO]: Epoch 161 - training loss: 0.7632, validation loss: 0.8127
2024-05-22 23:14:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch161_loss0.812695100903511.pypots
2024-05-22 23:14:06 [INFO]: Epoch 162 - training loss: 0.7870, validation loss: 0.8146
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch162_loss0.8146194368600845.pypots
2024-05-22 23:14:06 [INFO]: Epoch 163 - training loss: 0.7574, validation loss: 0.8116
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch163_loss0.8116143643856049.pypots
2024-05-22 23:14:06 [INFO]: Epoch 164 - training loss: 0.7573, validation loss: 0.8108
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch164_loss0.8107592910528183.pypots
2024-05-22 23:14:06 [INFO]: Epoch 165 - training loss: 0.7626, validation loss: 0.8117
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch165_loss0.811692863702774.pypots
2024-05-22 23:14:06 [INFO]: Epoch 166 - training loss: 0.7586, validation loss: 0.8101
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch166_loss0.8100531250238419.pypots
2024-05-22 23:14:06 [INFO]: Epoch 167 - training loss: 0.7489, validation loss: 0.8119
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch167_loss0.8119038939476013.pypots
2024-05-22 23:14:06 [INFO]: Epoch 168 - training loss: 0.7480, validation loss: 0.8075
2024-05-22 23:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch168_loss0.8075300604104996.pypots
2024-05-22 23:14:07 [INFO]: Epoch 169 - training loss: 0.7419, validation loss: 0.8112
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch169_loss0.8111934512853622.pypots
2024-05-22 23:14:07 [INFO]: Epoch 170 - training loss: 0.7706, validation loss: 0.8136
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch170_loss0.8136115372180939.pypots
2024-05-22 23:14:07 [INFO]: Epoch 171 - training loss: 0.7636, validation loss: 0.8076
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch171_loss0.807632103562355.pypots
2024-05-22 23:14:07 [INFO]: Epoch 172 - training loss: 0.7622, validation loss: 0.8114
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch172_loss0.8113729059696198.pypots
2024-05-22 23:14:07 [INFO]: Epoch 173 - training loss: 0.7674, validation loss: 0.8085
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch173_loss0.808480516076088.pypots
2024-05-22 23:14:07 [INFO]: Epoch 174 - training loss: 0.7714, validation loss: 0.8069
2024-05-22 23:14:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch174_loss0.806869626045227.pypots
2024-05-22 23:14:08 [INFO]: Epoch 175 - training loss: 0.7651, validation loss: 0.8094
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch175_loss0.8093803077936172.pypots
2024-05-22 23:14:08 [INFO]: Epoch 176 - training loss: 0.7362, validation loss: 0.8070
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch176_loss0.8069772273302078.pypots
2024-05-22 23:14:08 [INFO]: Epoch 177 - training loss: 0.7679, validation loss: 0.8101
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch177_loss0.8101125657558441.pypots
2024-05-22 23:14:08 [INFO]: Epoch 178 - training loss: 0.7660, validation loss: 0.8064
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch178_loss0.8064277768135071.pypots
2024-05-22 23:14:08 [INFO]: Epoch 179 - training loss: 0.7747, validation loss: 0.8068
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch179_loss0.8067652136087418.pypots
2024-05-22 23:14:08 [INFO]: Epoch 180 - training loss: 0.7536, validation loss: 0.8052
2024-05-22 23:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch180_loss0.8051995635032654.pypots
2024-05-22 23:14:09 [INFO]: Epoch 181 - training loss: 0.7465, validation loss: 0.8046
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch181_loss0.8045953810214996.pypots
2024-05-22 23:14:09 [INFO]: Epoch 182 - training loss: 0.7444, validation loss: 0.8073
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch182_loss0.8073045164346695.pypots
2024-05-22 23:14:09 [INFO]: Epoch 183 - training loss: 0.7715, validation loss: 0.8079
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch183_loss0.8079267144203186.pypots
2024-05-22 23:14:09 [INFO]: Epoch 184 - training loss: 0.7750, validation loss: 0.8044
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch184_loss0.8044399917125702.pypots
2024-05-22 23:14:09 [INFO]: Epoch 185 - training loss: 0.7538, validation loss: 0.8037
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch185_loss0.8037116825580597.pypots
2024-05-22 23:14:09 [INFO]: Epoch 186 - training loss: 0.7653, validation loss: 0.8037
2024-05-22 23:14:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch186_loss0.8037072867155075.pypots
2024-05-22 23:14:10 [INFO]: Epoch 187 - training loss: 0.7915, validation loss: 0.8045
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch187_loss0.8044985234737396.pypots
2024-05-22 23:14:10 [INFO]: Epoch 188 - training loss: 0.7383, validation loss: 0.8033
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch188_loss0.8033089935779572.pypots
2024-05-22 23:14:10 [INFO]: Epoch 189 - training loss: 0.7674, validation loss: 0.8047
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch189_loss0.804735079407692.pypots
2024-05-22 23:14:10 [INFO]: Epoch 190 - training loss: 0.7579, validation loss: 0.8023
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch190_loss0.8022534996271133.pypots
2024-05-22 23:14:10 [INFO]: Epoch 191 - training loss: 0.7539, validation loss: 0.8011
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch191_loss0.801132932305336.pypots
2024-05-22 23:14:10 [INFO]: Epoch 192 - training loss: 0.7686, validation loss: 0.8002
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch192_loss0.8001678287982941.pypots
2024-05-22 23:14:10 [INFO]: Epoch 193 - training loss: 0.7577, validation loss: 0.8044
2024-05-22 23:14:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch193_loss0.8043954223394394.pypots
2024-05-22 23:14:11 [INFO]: Epoch 194 - training loss: 0.7472, validation loss: 0.7992
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch194_loss0.7991849780082703.pypots
2024-05-22 23:14:11 [INFO]: Epoch 195 - training loss: 0.7825, validation loss: 0.8015
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch195_loss0.8015430271625519.pypots
2024-05-22 23:14:11 [INFO]: Epoch 196 - training loss: 0.7758, validation loss: 0.7976
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch196_loss0.7976155132055283.pypots
2024-05-22 23:14:11 [INFO]: Epoch 197 - training loss: 0.7712, validation loss: 0.8011
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch197_loss0.801095649600029.pypots
2024-05-22 23:14:11 [INFO]: Epoch 198 - training loss: 0.7744, validation loss: 0.8008
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch198_loss0.8007574528455734.pypots
2024-05-22 23:14:11 [INFO]: Epoch 199 - training loss: 0.7523, validation loss: 0.7971
2024-05-22 23:14:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch199_loss0.7970690578222275.pypots
2024-05-22 23:14:12 [INFO]: Epoch 200 - training loss: 0.7748, validation loss: 0.8014
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch200_loss0.8013832569122314.pypots
2024-05-22 23:14:12 [INFO]: Epoch 201 - training loss: 0.7751, validation loss: 0.7983
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch201_loss0.7983274161815643.pypots
2024-05-22 23:14:12 [INFO]: Epoch 202 - training loss: 0.7393, validation loss: 0.7981
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch202_loss0.7980989664793015.pypots
2024-05-22 23:14:12 [INFO]: Epoch 203 - training loss: 0.7672, validation loss: 0.8013
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch203_loss0.8012968897819519.pypots
2024-05-22 23:14:12 [INFO]: Epoch 204 - training loss: 0.7612, validation loss: 0.8005
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch204_loss0.8004772812128067.pypots
2024-05-22 23:14:12 [INFO]: Epoch 205 - training loss: 0.7633, validation loss: 0.8002
2024-05-22 23:14:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch205_loss0.8002468943595886.pypots
2024-05-22 23:14:13 [INFO]: Epoch 206 - training loss: 0.7897, validation loss: 0.7985
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch206_loss0.7984516024589539.pypots
2024-05-22 23:14:13 [INFO]: Epoch 207 - training loss: 0.7346, validation loss: 0.7981
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch207_loss0.798138216137886.pypots
2024-05-22 23:14:13 [INFO]: Epoch 208 - training loss: 0.7591, validation loss: 0.8011
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch208_loss0.8010895699262619.pypots
2024-05-22 23:14:13 [INFO]: Epoch 209 - training loss: 0.7719, validation loss: 0.7970
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch209_loss0.7970322072505951.pypots
2024-05-22 23:14:13 [INFO]: Epoch 210 - training loss: 0.7573, validation loss: 0.7964
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch210_loss0.7964356988668442.pypots
2024-05-22 23:14:13 [INFO]: Epoch 211 - training loss: 0.7655, validation loss: 0.7970
2024-05-22 23:14:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch211_loss0.7970382422208786.pypots
2024-05-22 23:14:14 [INFO]: Epoch 212 - training loss: 0.7570, validation loss: 0.7982
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch212_loss0.7981760948896408.pypots
2024-05-22 23:14:14 [INFO]: Epoch 213 - training loss: 0.7616, validation loss: 0.7956
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch213_loss0.795596107840538.pypots
2024-05-22 23:14:14 [INFO]: Epoch 214 - training loss: 0.7529, validation loss: 0.7957
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch214_loss0.7956672310829163.pypots
2024-05-22 23:14:14 [INFO]: Epoch 215 - training loss: 0.7685, validation loss: 0.7970
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch215_loss0.7969546765089035.pypots
2024-05-22 23:14:14 [INFO]: Epoch 216 - training loss: 0.7436, validation loss: 0.7978
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch216_loss0.7978353947401047.pypots
2024-05-22 23:14:14 [INFO]: Epoch 217 - training loss: 0.7911, validation loss: 0.7959
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch217_loss0.7958610206842422.pypots
2024-05-22 23:14:14 [INFO]: Epoch 218 - training loss: 0.7598, validation loss: 0.7954
2024-05-22 23:14:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch218_loss0.7953936010599136.pypots
2024-05-22 23:14:15 [INFO]: Epoch 219 - training loss: 0.7375, validation loss: 0.8008
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch219_loss0.8007640838623047.pypots
2024-05-22 23:14:15 [INFO]: Epoch 220 - training loss: 0.7695, validation loss: 0.7989
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch220_loss0.798928439617157.pypots
2024-05-22 23:14:15 [INFO]: Epoch 221 - training loss: 0.7418, validation loss: 0.7946
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch221_loss0.7946330606937408.pypots
2024-05-22 23:14:15 [INFO]: Epoch 222 - training loss: 0.7379, validation loss: 0.7982
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch222_loss0.7981570363044739.pypots
2024-05-22 23:14:15 [INFO]: Epoch 223 - training loss: 0.7566, validation loss: 0.7944
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch223_loss0.7943501323461533.pypots
2024-05-22 23:14:15 [INFO]: Epoch 224 - training loss: 0.7578, validation loss: 0.7951
2024-05-22 23:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch224_loss0.7951212227344513.pypots
2024-05-22 23:14:16 [INFO]: Epoch 225 - training loss: 0.7537, validation loss: 0.7946
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch225_loss0.7945610880851746.pypots
2024-05-22 23:14:16 [INFO]: Epoch 226 - training loss: 0.7668, validation loss: 0.7944
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch226_loss0.7943796664476395.pypots
2024-05-22 23:14:16 [INFO]: Epoch 227 - training loss: 0.7629, validation loss: 0.7957
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch227_loss0.7956566363573074.pypots
2024-05-22 23:14:16 [INFO]: Epoch 228 - training loss: 0.7753, validation loss: 0.7943
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch228_loss0.7943233698606491.pypots
2024-05-22 23:14:16 [INFO]: Epoch 229 - training loss: 0.7556, validation loss: 0.7943
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch229_loss0.7943192273378372.pypots
2024-05-22 23:14:16 [INFO]: Epoch 230 - training loss: 0.7637, validation loss: 0.7932
2024-05-22 23:14:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch230_loss0.7931834608316422.pypots
2024-05-22 23:14:17 [INFO]: Epoch 231 - training loss: 0.7544, validation loss: 0.7935
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch231_loss0.7934915125370026.pypots
2024-05-22 23:14:17 [INFO]: Epoch 232 - training loss: 0.7995, validation loss: 0.7930
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch232_loss0.7930411696434021.pypots
2024-05-22 23:14:17 [INFO]: Epoch 233 - training loss: 0.7859, validation loss: 0.7953
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch233_loss0.7952779680490494.pypots
2024-05-22 23:14:17 [INFO]: Epoch 234 - training loss: 0.7637, validation loss: 0.7968
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch234_loss0.7967504560947418.pypots
2024-05-22 23:14:17 [INFO]: Epoch 235 - training loss: 0.7504, validation loss: 0.7946
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch235_loss0.7945571839809418.pypots
2024-05-22 23:14:17 [INFO]: Epoch 236 - training loss: 0.7509, validation loss: 0.7953
2024-05-22 23:14:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch236_loss0.7953417599201202.pypots
2024-05-22 23:14:18 [INFO]: Epoch 237 - training loss: 0.7538, validation loss: 0.7915
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch237_loss0.7915234565734863.pypots
2024-05-22 23:14:18 [INFO]: Epoch 238 - training loss: 0.7505, validation loss: 0.7951
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch238_loss0.7950513064861298.pypots
2024-05-22 23:14:18 [INFO]: Epoch 239 - training loss: 0.7464, validation loss: 0.7969
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch239_loss0.7969062030315399.pypots
2024-05-22 23:14:18 [INFO]: Epoch 240 - training loss: 0.7601, validation loss: 0.7983
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch240_loss0.7982820123434067.pypots
2024-05-22 23:14:18 [INFO]: Epoch 241 - training loss: 0.7654, validation loss: 0.7951
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch241_loss0.7950639575719833.pypots
2024-05-22 23:14:18 [INFO]: Epoch 242 - training loss: 0.7408, validation loss: 0.7941
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch242_loss0.7941111177206039.pypots
2024-05-22 23:14:18 [INFO]: Epoch 243 - training loss: 0.7617, validation loss: 0.7932
2024-05-22 23:14:18 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch243_loss0.7931539118289948.pypots
2024-05-22 23:14:19 [INFO]: Epoch 244 - training loss: 0.7339, validation loss: 0.7946
2024-05-22 23:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch244_loss0.7945915907621384.pypots
2024-05-22 23:14:19 [INFO]: Epoch 245 - training loss: 0.7610, validation loss: 0.7970
2024-05-22 23:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch245_loss0.7969513982534409.pypots
2024-05-22 23:14:19 [INFO]: Epoch 246 - training loss: 0.7515, validation loss: 0.7974
2024-05-22 23:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch246_loss0.7974056601524353.pypots
2024-05-22 23:14:19 [INFO]: Epoch 247 - training loss: 0.7615, validation loss: 0.7930
2024-05-22 23:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN_epoch247_loss0.79298035800457.pypots
2024-05-22 23:14:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-22 23:14:19 [INFO]: Finished training. The best model is from epoch#237.
2024-05-22 23:14:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_ettm1/20240522_T231337/MRNN.pypots
2024-05-22 23:14:19 [INFO]: MRNN on ETTm1: MAE=0.5846, MSE=0.9802
2024-05-22 23:14:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-22 23:14:19 [INFO]: Using the given device: cpu
2024-05-22 23:14:19 [INFO]: LOCF on ETTm1: MAE=0.1350, MSE=0.0722
2024-05-22 23:14:19 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-22 23:14:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-22 23:14:19 [INFO]: Median on ETTm1: MAE=0.6566, MSE=0.8245
2024-05-22 23:14:19 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-22 23:14:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-22 23:14:19 [INFO]: Mean on ETTm1: MAE=0.6631, MSE=0.8091
2024-05-22 23:14:19 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-22 23:14:19 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-22 23:14:19 [INFO]: 
SAITS on data_overlay_premask/ettm1: MAE=0.164±0.014922403588322794, MSE=0.054±0.011636233941102029
Transformer on data_overlay_premask/ettm1: MAE=0.136±0.0034556908290971247, MSE=0.039±0.001802299001694248
TimesNet on data_overlay_premask/ettm1: MAE=0.109±0.0011176134276524702, MSE=0.026±0.0006174744549040315
CSDI on data_overlay_premask/ettm1: MAE=0.145±0.02244174821627457, MSE=0.062±0.03860612444260186
GPVAE on data_overlay_premask/ettm1: MAE=0.279±0.009293175793895256, MSE=0.163±0.009009663233105416
USGAN on data_overlay_premask/ettm1: MAE=0.148±0.007367245352815918, MSE=0.057±0.006289700010428623
BRITS on data_overlay_premask/ettm1: MAE=0.130±0.005549036438383844, MSE=0.050±0.005144126525419363
MRNN on data_overlay_premask/ettm1: MAE=0.590±0.021302998710630596, MSE=0.993±0.030073619906879494
LOCF on data_overlay_premask/ettm1: MAE=0.135±0.0, MSE=0.072±0.0
Median on data_overlay_premask/ettm1: MAE=0.657±0.0, MSE=0.825±0.0
Mean on data_overlay_premask/ettm1: MAE=0.663±0.0, MSE=0.809±0.0