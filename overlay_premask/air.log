2024-05-23 17:25:38 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-23 17:25:38 [INFO]: Using the given device: cuda:0
2024-05-23 17:25:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240523_T172539
2024-05-23 17:25:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/SAITS_air_quality/20240523_T172539/tensorboard
2024-05-23 17:25:39 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 17:25:40 [INFO]: Epoch 001 - training loss: 1.0416, validation loss: 0.4821
2024-05-23 17:25:41 [INFO]: Epoch 002 - training loss: 0.7501, validation loss: 0.3603
2024-05-23 17:25:41 [INFO]: Epoch 003 - training loss: 0.6440, validation loss: 0.2882
2024-05-23 17:25:42 [INFO]: Epoch 004 - training loss: 0.5660, validation loss: 0.2473
2024-05-23 17:25:42 [INFO]: Epoch 005 - training loss: 0.5136, validation loss: 0.2252
2024-05-23 17:25:43 [INFO]: Epoch 006 - training loss: 0.4734, validation loss: 0.2136
2024-05-23 17:25:44 [INFO]: Epoch 007 - training loss: 0.4485, validation loss: 0.2050
2024-05-23 17:25:44 [INFO]: Epoch 008 - training loss: 0.4288, validation loss: 0.1974
2024-05-23 17:25:45 [INFO]: Epoch 009 - training loss: 0.4148, validation loss: 0.1907
2024-05-23 17:25:45 [INFO]: Epoch 010 - training loss: 0.4031, validation loss: 0.1875
2024-05-23 17:25:46 [INFO]: Epoch 011 - training loss: 0.3930, validation loss: 0.1836
2024-05-23 17:25:47 [INFO]: Epoch 012 - training loss: 0.3846, validation loss: 0.1801
2024-05-23 17:25:47 [INFO]: Epoch 013 - training loss: 0.3775, validation loss: 0.1777
2024-05-23 17:25:48 [INFO]: Epoch 014 - training loss: 0.3702, validation loss: 0.1742
2024-05-23 17:25:48 [INFO]: Epoch 015 - training loss: 0.3648, validation loss: 0.1703
2024-05-23 17:25:49 [INFO]: Epoch 016 - training loss: 0.3594, validation loss: 0.1685
2024-05-23 17:25:49 [INFO]: Epoch 017 - training loss: 0.3538, validation loss: 0.1656
2024-05-23 17:25:50 [INFO]: Epoch 018 - training loss: 0.3487, validation loss: 0.1655
2024-05-23 17:25:51 [INFO]: Epoch 019 - training loss: 0.3448, validation loss: 0.1604
2024-05-23 17:25:51 [INFO]: Epoch 020 - training loss: 0.3403, validation loss: 0.1595
2024-05-23 17:25:52 [INFO]: Epoch 021 - training loss: 0.3360, validation loss: 0.1567
2024-05-23 17:25:52 [INFO]: Epoch 022 - training loss: 0.3326, validation loss: 0.1565
2024-05-23 17:25:53 [INFO]: Epoch 023 - training loss: 0.3296, validation loss: 0.1527
2024-05-23 17:25:53 [INFO]: Epoch 024 - training loss: 0.3256, validation loss: 0.1517
2024-05-23 17:25:54 [INFO]: Epoch 025 - training loss: 0.3245, validation loss: 0.1508
2024-05-23 17:25:55 [INFO]: Epoch 026 - training loss: 0.3199, validation loss: 0.1487
2024-05-23 17:25:55 [INFO]: Epoch 027 - training loss: 0.3173, validation loss: 0.1488
2024-05-23 17:25:56 [INFO]: Epoch 028 - training loss: 0.3151, validation loss: 0.1474
2024-05-23 17:25:56 [INFO]: Epoch 029 - training loss: 0.3118, validation loss: 0.1455
2024-05-23 17:25:57 [INFO]: Epoch 030 - training loss: 0.3093, validation loss: 0.1444
2024-05-23 17:25:57 [INFO]: Epoch 031 - training loss: 0.3067, validation loss: 0.1429
2024-05-23 17:25:58 [INFO]: Epoch 032 - training loss: 0.3057, validation loss: 0.1421
2024-05-23 17:25:59 [INFO]: Epoch 033 - training loss: 0.3040, validation loss: 0.1403
2024-05-23 17:25:59 [INFO]: Epoch 034 - training loss: 0.3015, validation loss: 0.1403
2024-05-23 17:26:00 [INFO]: Epoch 035 - training loss: 0.2985, validation loss: 0.1382
2024-05-23 17:26:00 [INFO]: Epoch 036 - training loss: 0.2959, validation loss: 0.1377
2024-05-23 17:26:01 [INFO]: Epoch 037 - training loss: 0.2952, validation loss: 0.1367
2024-05-23 17:26:02 [INFO]: Epoch 038 - training loss: 0.2941, validation loss: 0.1354
2024-05-23 17:26:02 [INFO]: Epoch 039 - training loss: 0.2914, validation loss: 0.1355
2024-05-23 17:26:03 [INFO]: Epoch 040 - training loss: 0.2884, validation loss: 0.1346
2024-05-23 17:26:03 [INFO]: Epoch 041 - training loss: 0.2877, validation loss: 0.1329
2024-05-23 17:26:04 [INFO]: Epoch 042 - training loss: 0.2846, validation loss: 0.1323
2024-05-23 17:26:04 [INFO]: Epoch 043 - training loss: 0.2839, validation loss: 0.1312
2024-05-23 17:26:05 [INFO]: Epoch 044 - training loss: 0.2825, validation loss: 0.1314
2024-05-23 17:26:06 [INFO]: Epoch 045 - training loss: 0.2810, validation loss: 0.1300
2024-05-23 17:26:06 [INFO]: Epoch 046 - training loss: 0.2797, validation loss: 0.1294
2024-05-23 17:26:07 [INFO]: Epoch 047 - training loss: 0.2762, validation loss: 0.1281
2024-05-23 17:26:07 [INFO]: Epoch 048 - training loss: 0.2746, validation loss: 0.1271
2024-05-23 17:26:08 [INFO]: Epoch 049 - training loss: 0.2741, validation loss: 0.1266
2024-05-23 17:26:09 [INFO]: Epoch 050 - training loss: 0.2725, validation loss: 0.1252
2024-05-23 17:26:09 [INFO]: Epoch 051 - training loss: 0.2707, validation loss: 0.1264
2024-05-23 17:26:10 [INFO]: Epoch 052 - training loss: 0.2698, validation loss: 0.1251
2024-05-23 17:26:10 [INFO]: Epoch 053 - training loss: 0.2671, validation loss: 0.1237
2024-05-23 17:26:11 [INFO]: Epoch 054 - training loss: 0.2661, validation loss: 0.1233
2024-05-23 17:26:12 [INFO]: Epoch 055 - training loss: 0.2654, validation loss: 0.1230
2024-05-23 17:26:12 [INFO]: Epoch 056 - training loss: 0.2634, validation loss: 0.1229
2024-05-23 17:26:13 [INFO]: Epoch 057 - training loss: 0.2628, validation loss: 0.1217
2024-05-23 17:26:13 [INFO]: Epoch 058 - training loss: 0.2605, validation loss: 0.1205
2024-05-23 17:26:14 [INFO]: Epoch 059 - training loss: 0.2589, validation loss: 0.1214
2024-05-23 17:26:14 [INFO]: Epoch 060 - training loss: 0.2570, validation loss: 0.1194
2024-05-23 17:26:15 [INFO]: Epoch 061 - training loss: 0.2551, validation loss: 0.1197
2024-05-23 17:26:16 [INFO]: Epoch 062 - training loss: 0.2546, validation loss: 0.1192
2024-05-23 17:26:16 [INFO]: Epoch 063 - training loss: 0.2530, validation loss: 0.1188
2024-05-23 17:26:17 [INFO]: Epoch 064 - training loss: 0.2515, validation loss: 0.1171
2024-05-23 17:26:17 [INFO]: Epoch 065 - training loss: 0.2501, validation loss: 0.1179
2024-05-23 17:26:18 [INFO]: Epoch 066 - training loss: 0.2489, validation loss: 0.1168
2024-05-23 17:26:19 [INFO]: Epoch 067 - training loss: 0.2474, validation loss: 0.1167
2024-05-23 17:26:19 [INFO]: Epoch 068 - training loss: 0.2468, validation loss: 0.1159
2024-05-23 17:26:20 [INFO]: Epoch 069 - training loss: 0.2448, validation loss: 0.1155
2024-05-23 17:26:20 [INFO]: Epoch 070 - training loss: 0.2447, validation loss: 0.1159
2024-05-23 17:26:21 [INFO]: Epoch 071 - training loss: 0.2452, validation loss: 0.1158
2024-05-23 17:26:22 [INFO]: Epoch 072 - training loss: 0.2433, validation loss: 0.1153
2024-05-23 17:26:22 [INFO]: Epoch 073 - training loss: 0.2420, validation loss: 0.1140
2024-05-23 17:26:23 [INFO]: Epoch 074 - training loss: 0.2401, validation loss: 0.1139
2024-05-23 17:26:23 [INFO]: Epoch 075 - training loss: 0.2395, validation loss: 0.1145
2024-05-23 17:26:24 [INFO]: Epoch 076 - training loss: 0.2382, validation loss: 0.1143
2024-05-23 17:26:24 [INFO]: Epoch 077 - training loss: 0.2366, validation loss: 0.1130
2024-05-23 17:26:25 [INFO]: Epoch 078 - training loss: 0.2364, validation loss: 0.1131
2024-05-23 17:26:26 [INFO]: Epoch 079 - training loss: 0.2346, validation loss: 0.1141
2024-05-23 17:26:26 [INFO]: Epoch 080 - training loss: 0.2345, validation loss: 0.1126
2024-05-23 17:26:27 [INFO]: Epoch 081 - training loss: 0.2337, validation loss: 0.1132
2024-05-23 17:26:28 [INFO]: Epoch 082 - training loss: 0.2324, validation loss: 0.1124
2024-05-23 17:26:28 [INFO]: Epoch 083 - training loss: 0.2309, validation loss: 0.1137
2024-05-23 17:26:29 [INFO]: Epoch 084 - training loss: 0.2311, validation loss: 0.1115
2024-05-23 17:26:29 [INFO]: Epoch 085 - training loss: 0.2309, validation loss: 0.1114
2024-05-23 17:26:30 [INFO]: Epoch 086 - training loss: 0.2301, validation loss: 0.1115
2024-05-23 17:26:30 [INFO]: Epoch 087 - training loss: 0.2290, validation loss: 0.1127
2024-05-23 17:26:31 [INFO]: Epoch 088 - training loss: 0.2296, validation loss: 0.1121
2024-05-23 17:26:32 [INFO]: Epoch 089 - training loss: 0.2270, validation loss: 0.1110
2024-05-23 17:26:32 [INFO]: Epoch 090 - training loss: 0.2257, validation loss: 0.1108
2024-05-23 17:26:33 [INFO]: Epoch 091 - training loss: 0.2264, validation loss: 0.1103
2024-05-23 17:26:33 [INFO]: Epoch 092 - training loss: 0.2242, validation loss: 0.1092
2024-05-23 17:26:34 [INFO]: Epoch 093 - training loss: 0.2241, validation loss: 0.1090
2024-05-23 17:26:35 [INFO]: Epoch 094 - training loss: 0.2227, validation loss: 0.1093
2024-05-23 17:26:35 [INFO]: Epoch 095 - training loss: 0.2218, validation loss: 0.1082
2024-05-23 17:26:36 [INFO]: Epoch 096 - training loss: 0.2222, validation loss: 0.1084
2024-05-23 17:26:36 [INFO]: Epoch 097 - training loss: 0.2216, validation loss: 0.1087
2024-05-23 17:26:37 [INFO]: Epoch 098 - training loss: 0.2214, validation loss: 0.1090
2024-05-23 17:26:38 [INFO]: Epoch 099 - training loss: 0.2197, validation loss: 0.1082
2024-05-23 17:26:38 [INFO]: Epoch 100 - training loss: 0.2191, validation loss: 0.1077
2024-05-23 17:26:39 [INFO]: Epoch 101 - training loss: 0.2188, validation loss: 0.1077
2024-05-23 17:26:39 [INFO]: Epoch 102 - training loss: 0.2182, validation loss: 0.1071
2024-05-23 17:26:40 [INFO]: Epoch 103 - training loss: 0.2174, validation loss: 0.1072
2024-05-23 17:26:40 [INFO]: Epoch 104 - training loss: 0.2172, validation loss: 0.1076
2024-05-23 17:26:41 [INFO]: Epoch 105 - training loss: 0.2156, validation loss: 0.1076
2024-05-23 17:26:42 [INFO]: Epoch 106 - training loss: 0.2149, validation loss: 0.1068
2024-05-23 17:26:42 [INFO]: Epoch 107 - training loss: 0.2141, validation loss: 0.1062
2024-05-23 17:26:43 [INFO]: Epoch 108 - training loss: 0.2145, validation loss: 0.1069
2024-05-23 17:26:43 [INFO]: Epoch 109 - training loss: 0.2142, validation loss: 0.1082
2024-05-23 17:26:44 [INFO]: Epoch 110 - training loss: 0.2137, validation loss: 0.1067
2024-05-23 17:26:45 [INFO]: Epoch 111 - training loss: 0.2133, validation loss: 0.1067
2024-05-23 17:26:45 [INFO]: Epoch 112 - training loss: 0.2119, validation loss: 0.1056
2024-05-23 17:26:46 [INFO]: Epoch 113 - training loss: 0.2106, validation loss: 0.1053
2024-05-23 17:26:46 [INFO]: Epoch 114 - training loss: 0.2101, validation loss: 0.1056
2024-05-23 17:26:47 [INFO]: Epoch 115 - training loss: 0.2099, validation loss: 0.1053
2024-05-23 17:26:47 [INFO]: Epoch 116 - training loss: 0.2092, validation loss: 0.1046
2024-05-23 17:26:48 [INFO]: Epoch 117 - training loss: 0.2096, validation loss: 0.1049
2024-05-23 17:26:49 [INFO]: Epoch 118 - training loss: 0.2085, validation loss: 0.1042
2024-05-23 17:26:49 [INFO]: Epoch 119 - training loss: 0.2095, validation loss: 0.1060
2024-05-23 17:26:50 [INFO]: Epoch 120 - training loss: 0.2080, validation loss: 0.1048
2024-05-23 17:26:50 [INFO]: Epoch 121 - training loss: 0.2067, validation loss: 0.1043
2024-05-23 17:26:51 [INFO]: Epoch 122 - training loss: 0.2052, validation loss: 0.1044
2024-05-23 17:26:52 [INFO]: Epoch 123 - training loss: 0.2051, validation loss: 0.1047
2024-05-23 17:26:52 [INFO]: Epoch 124 - training loss: 0.2049, validation loss: 0.1043
2024-05-23 17:26:53 [INFO]: Epoch 125 - training loss: 0.2053, validation loss: 0.1040
2024-05-23 17:26:53 [INFO]: Epoch 126 - training loss: 0.2047, validation loss: 0.1045
2024-05-23 17:26:54 [INFO]: Epoch 127 - training loss: 0.2058, validation loss: 0.1040
2024-05-23 17:26:54 [INFO]: Epoch 128 - training loss: 0.2031, validation loss: 0.1042
2024-05-23 17:26:55 [INFO]: Epoch 129 - training loss: 0.2030, validation loss: 0.1036
2024-05-23 17:26:56 [INFO]: Epoch 130 - training loss: 0.2028, validation loss: 0.1026
2024-05-23 17:26:56 [INFO]: Epoch 131 - training loss: 0.2037, validation loss: 0.1023
2024-05-23 17:26:57 [INFO]: Epoch 132 - training loss: 0.2019, validation loss: 0.1030
2024-05-23 17:26:57 [INFO]: Epoch 133 - training loss: 0.2004, validation loss: 0.1025
2024-05-23 17:26:58 [INFO]: Epoch 134 - training loss: 0.2009, validation loss: 0.1025
2024-05-23 17:26:59 [INFO]: Epoch 135 - training loss: 0.2015, validation loss: 0.1032
2024-05-23 17:26:59 [INFO]: Epoch 136 - training loss: 0.1997, validation loss: 0.1018
2024-05-23 17:27:00 [INFO]: Epoch 137 - training loss: 0.1985, validation loss: 0.1016
2024-05-23 17:27:01 [INFO]: Epoch 138 - training loss: 0.1981, validation loss: 0.1023
2024-05-23 17:27:01 [INFO]: Epoch 139 - training loss: 0.1983, validation loss: 0.1012
2024-05-23 17:27:02 [INFO]: Epoch 140 - training loss: 0.1977, validation loss: 0.1016
2024-05-23 17:27:02 [INFO]: Epoch 141 - training loss: 0.1969, validation loss: 0.1009
2024-05-23 17:27:03 [INFO]: Epoch 142 - training loss: 0.1976, validation loss: 0.1004
2024-05-23 17:27:03 [INFO]: Epoch 143 - training loss: 0.1969, validation loss: 0.1011
2024-05-23 17:27:04 [INFO]: Epoch 144 - training loss: 0.1959, validation loss: 0.1013
2024-05-23 17:27:05 [INFO]: Epoch 145 - training loss: 0.1948, validation loss: 0.1003
2024-05-23 17:27:05 [INFO]: Epoch 146 - training loss: 0.1956, validation loss: 0.1006
2024-05-23 17:27:06 [INFO]: Epoch 147 - training loss: 0.1948, validation loss: 0.0996
2024-05-23 17:27:06 [INFO]: Epoch 148 - training loss: 0.1943, validation loss: 0.0993
2024-05-23 17:27:07 [INFO]: Epoch 149 - training loss: 0.1935, validation loss: 0.0996
2024-05-23 17:27:08 [INFO]: Epoch 150 - training loss: 0.1930, validation loss: 0.1000
2024-05-23 17:27:08 [INFO]: Epoch 151 - training loss: 0.1933, validation loss: 0.0992
2024-05-23 17:27:09 [INFO]: Epoch 152 - training loss: 0.1936, validation loss: 0.0998
2024-05-23 17:27:09 [INFO]: Epoch 153 - training loss: 0.1924, validation loss: 0.1001
2024-05-23 17:27:10 [INFO]: Epoch 154 - training loss: 0.1928, validation loss: 0.0988
2024-05-23 17:27:10 [INFO]: Epoch 155 - training loss: 0.1926, validation loss: 0.0992
2024-05-23 17:27:11 [INFO]: Epoch 156 - training loss: 0.1915, validation loss: 0.0990
2024-05-23 17:27:12 [INFO]: Epoch 157 - training loss: 0.1907, validation loss: 0.0987
2024-05-23 17:27:12 [INFO]: Epoch 158 - training loss: 0.1903, validation loss: 0.0990
2024-05-23 17:27:13 [INFO]: Epoch 159 - training loss: 0.1895, validation loss: 0.0981
2024-05-23 17:27:13 [INFO]: Epoch 160 - training loss: 0.1897, validation loss: 0.0986
2024-05-23 17:27:14 [INFO]: Epoch 161 - training loss: 0.1896, validation loss: 0.0984
2024-05-23 17:27:14 [INFO]: Epoch 162 - training loss: 0.1903, validation loss: 0.0986
2024-05-23 17:27:15 [INFO]: Epoch 163 - training loss: 0.1891, validation loss: 0.0984
2024-05-23 17:27:16 [INFO]: Epoch 164 - training loss: 0.1886, validation loss: 0.0979
2024-05-23 17:27:16 [INFO]: Epoch 165 - training loss: 0.1876, validation loss: 0.0978
2024-05-23 17:27:17 [INFO]: Epoch 166 - training loss: 0.1873, validation loss: 0.0977
2024-05-23 17:27:17 [INFO]: Epoch 167 - training loss: 0.1873, validation loss: 0.0980
2024-05-23 17:27:18 [INFO]: Epoch 168 - training loss: 0.1867, validation loss: 0.0983
2024-05-23 17:27:18 [INFO]: Epoch 169 - training loss: 0.1869, validation loss: 0.0976
2024-05-23 17:27:19 [INFO]: Epoch 170 - training loss: 0.1852, validation loss: 0.0977
2024-05-23 17:27:20 [INFO]: Epoch 171 - training loss: 0.1845, validation loss: 0.0978
2024-05-23 17:27:20 [INFO]: Epoch 172 - training loss: 0.1847, validation loss: 0.0980
2024-05-23 17:27:21 [INFO]: Epoch 173 - training loss: 0.1845, validation loss: 0.0978
2024-05-23 17:27:21 [INFO]: Epoch 174 - training loss: 0.1837, validation loss: 0.0968
2024-05-23 17:27:22 [INFO]: Epoch 175 - training loss: 0.1837, validation loss: 0.0983
2024-05-23 17:27:22 [INFO]: Epoch 176 - training loss: 0.1826, validation loss: 0.0977
2024-05-23 17:27:23 [INFO]: Epoch 177 - training loss: 0.1827, validation loss: 0.0974
2024-05-23 17:27:24 [INFO]: Epoch 178 - training loss: 0.1829, validation loss: 0.0964
2024-05-23 17:27:24 [INFO]: Epoch 179 - training loss: 0.1827, validation loss: 0.0968
2024-05-23 17:27:25 [INFO]: Epoch 180 - training loss: 0.1847, validation loss: 0.0984
2024-05-23 17:27:25 [INFO]: Epoch 181 - training loss: 0.1829, validation loss: 0.0963
2024-05-23 17:27:26 [INFO]: Epoch 182 - training loss: 0.1832, validation loss: 0.0972
2024-05-23 17:27:27 [INFO]: Epoch 183 - training loss: 0.1819, validation loss: 0.0979
2024-05-23 17:27:27 [INFO]: Epoch 184 - training loss: 0.1815, validation loss: 0.0976
2024-05-23 17:27:28 [INFO]: Epoch 185 - training loss: 0.1807, validation loss: 0.0965
2024-05-23 17:27:28 [INFO]: Epoch 186 - training loss: 0.1794, validation loss: 0.0965
2024-05-23 17:27:29 [INFO]: Epoch 187 - training loss: 0.1795, validation loss: 0.0972
2024-05-23 17:27:29 [INFO]: Epoch 188 - training loss: 0.1789, validation loss: 0.0963
2024-05-23 17:27:30 [INFO]: Epoch 189 - training loss: 0.1789, validation loss: 0.0963
2024-05-23 17:27:31 [INFO]: Epoch 190 - training loss: 0.1786, validation loss: 0.0968
2024-05-23 17:27:31 [INFO]: Epoch 191 - training loss: 0.1780, validation loss: 0.0962
2024-05-23 17:27:32 [INFO]: Epoch 192 - training loss: 0.1782, validation loss: 0.0962
2024-05-23 17:27:32 [INFO]: Epoch 193 - training loss: 0.1779, validation loss: 0.0955
2024-05-23 17:27:33 [INFO]: Epoch 194 - training loss: 0.1791, validation loss: 0.0966
2024-05-23 17:27:33 [INFO]: Epoch 195 - training loss: 0.1782, validation loss: 0.0962
2024-05-23 17:27:34 [INFO]: Epoch 196 - training loss: 0.1768, validation loss: 0.0965
2024-05-23 17:27:35 [INFO]: Epoch 197 - training loss: 0.1759, validation loss: 0.0959
2024-05-23 17:27:35 [INFO]: Epoch 198 - training loss: 0.1778, validation loss: 0.0964
2024-05-23 17:27:36 [INFO]: Epoch 199 - training loss: 0.1764, validation loss: 0.0958
2024-05-23 17:27:36 [INFO]: Epoch 200 - training loss: 0.1757, validation loss: 0.0957
2024-05-23 17:27:37 [INFO]: Epoch 201 - training loss: 0.1761, validation loss: 0.0964
2024-05-23 17:27:37 [INFO]: Epoch 202 - training loss: 0.1752, validation loss: 0.0966
2024-05-23 17:27:38 [INFO]: Epoch 203 - training loss: 0.1745, validation loss: 0.0973
2024-05-23 17:27:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:27:38 [INFO]: Finished training. The best model is from epoch#193.
2024-05-23 17:27:38 [INFO]: Saved the model to overlay_premask_saved_results/round_0/SAITS_air_quality/20240523_T172539/SAITS.pypots
2024-05-23 17:27:38 [INFO]: SAITS on Air-Quality: MAE=0.1539, MSE=0.1713
2024-05-23 17:27:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-23 17:27:38 [INFO]: Using the given device: cuda:0
2024-05-23 17:27:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240523_T172738
2024-05-23 17:27:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/Transformer_air_quality/20240523_T172738/tensorboard
2024-05-23 17:27:38 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 17:27:39 [INFO]: Epoch 001 - training loss: 0.8888, validation loss: 0.4309
2024-05-23 17:27:39 [INFO]: Epoch 002 - training loss: 0.5546, validation loss: 0.3064
2024-05-23 17:27:39 [INFO]: Epoch 003 - training loss: 0.4645, validation loss: 0.2550
2024-05-23 17:27:39 [INFO]: Epoch 004 - training loss: 0.4174, validation loss: 0.2357
2024-05-23 17:27:40 [INFO]: Epoch 005 - training loss: 0.3890, validation loss: 0.2177
2024-05-23 17:27:40 [INFO]: Epoch 006 - training loss: 0.3696, validation loss: 0.2090
2024-05-23 17:27:40 [INFO]: Epoch 007 - training loss: 0.3514, validation loss: 0.2011
2024-05-23 17:27:40 [INFO]: Epoch 008 - training loss: 0.3406, validation loss: 0.1974
2024-05-23 17:27:40 [INFO]: Epoch 009 - training loss: 0.3351, validation loss: 0.1908
2024-05-23 17:27:41 [INFO]: Epoch 010 - training loss: 0.3239, validation loss: 0.1826
2024-05-23 17:27:41 [INFO]: Epoch 011 - training loss: 0.3188, validation loss: 0.1801
2024-05-23 17:27:41 [INFO]: Epoch 012 - training loss: 0.3090, validation loss: 0.1755
2024-05-23 17:27:41 [INFO]: Epoch 013 - training loss: 0.3045, validation loss: 0.1727
2024-05-23 17:27:42 [INFO]: Epoch 014 - training loss: 0.3005, validation loss: 0.1711
2024-05-23 17:27:42 [INFO]: Epoch 015 - training loss: 0.2958, validation loss: 0.1673
2024-05-23 17:27:42 [INFO]: Epoch 016 - training loss: 0.2937, validation loss: 0.1655
2024-05-23 17:27:42 [INFO]: Epoch 017 - training loss: 0.2877, validation loss: 0.1671
2024-05-23 17:27:43 [INFO]: Epoch 018 - training loss: 0.2856, validation loss: 0.1630
2024-05-23 17:27:43 [INFO]: Epoch 019 - training loss: 0.2803, validation loss: 0.1587
2024-05-23 17:27:43 [INFO]: Epoch 020 - training loss: 0.2791, validation loss: 0.1556
2024-05-23 17:27:43 [INFO]: Epoch 021 - training loss: 0.2750, validation loss: 0.1571
2024-05-23 17:27:44 [INFO]: Epoch 022 - training loss: 0.2718, validation loss: 0.1567
2024-05-23 17:27:44 [INFO]: Epoch 023 - training loss: 0.2699, validation loss: 0.1557
2024-05-23 17:27:44 [INFO]: Epoch 024 - training loss: 0.2703, validation loss: 0.1580
2024-05-23 17:27:44 [INFO]: Epoch 025 - training loss: 0.2705, validation loss: 0.1517
2024-05-23 17:27:44 [INFO]: Epoch 026 - training loss: 0.2644, validation loss: 0.1514
2024-05-23 17:27:45 [INFO]: Epoch 027 - training loss: 0.2598, validation loss: 0.1518
2024-05-23 17:27:45 [INFO]: Epoch 028 - training loss: 0.2612, validation loss: 0.1522
2024-05-23 17:27:45 [INFO]: Epoch 029 - training loss: 0.2597, validation loss: 0.1500
2024-05-23 17:27:45 [INFO]: Epoch 030 - training loss: 0.2534, validation loss: 0.1474
2024-05-23 17:27:46 [INFO]: Epoch 031 - training loss: 0.2520, validation loss: 0.1490
2024-05-23 17:27:46 [INFO]: Epoch 032 - training loss: 0.2505, validation loss: 0.1472
2024-05-23 17:27:46 [INFO]: Epoch 033 - training loss: 0.2517, validation loss: 0.1472
2024-05-23 17:27:46 [INFO]: Epoch 034 - training loss: 0.2496, validation loss: 0.1479
2024-05-23 17:27:47 [INFO]: Epoch 035 - training loss: 0.2455, validation loss: 0.1440
2024-05-23 17:27:47 [INFO]: Epoch 036 - training loss: 0.2436, validation loss: 0.1443
2024-05-23 17:27:47 [INFO]: Epoch 037 - training loss: 0.2422, validation loss: 0.1460
2024-05-23 17:27:47 [INFO]: Epoch 038 - training loss: 0.2419, validation loss: 0.1435
2024-05-23 17:27:47 [INFO]: Epoch 039 - training loss: 0.2390, validation loss: 0.1434
2024-05-23 17:27:48 [INFO]: Epoch 040 - training loss: 0.2378, validation loss: 0.1418
2024-05-23 17:27:48 [INFO]: Epoch 041 - training loss: 0.2360, validation loss: 0.1418
2024-05-23 17:27:48 [INFO]: Epoch 042 - training loss: 0.2352, validation loss: 0.1414
2024-05-23 17:27:48 [INFO]: Epoch 043 - training loss: 0.2352, validation loss: 0.1405
2024-05-23 17:27:49 [INFO]: Epoch 044 - training loss: 0.2330, validation loss: 0.1419
2024-05-23 17:27:49 [INFO]: Epoch 045 - training loss: 0.2312, validation loss: 0.1384
2024-05-23 17:27:49 [INFO]: Epoch 046 - training loss: 0.2308, validation loss: 0.1426
2024-05-23 17:27:49 [INFO]: Epoch 047 - training loss: 0.2288, validation loss: 0.1401
2024-05-23 17:27:50 [INFO]: Epoch 048 - training loss: 0.2267, validation loss: 0.1391
2024-05-23 17:27:50 [INFO]: Epoch 049 - training loss: 0.2254, validation loss: 0.1385
2024-05-23 17:27:50 [INFO]: Epoch 050 - training loss: 0.2249, validation loss: 0.1373
2024-05-23 17:27:50 [INFO]: Epoch 051 - training loss: 0.2232, validation loss: 0.1376
2024-05-23 17:27:50 [INFO]: Epoch 052 - training loss: 0.2232, validation loss: 0.1376
2024-05-23 17:27:51 [INFO]: Epoch 053 - training loss: 0.2213, validation loss: 0.1357
2024-05-23 17:27:51 [INFO]: Epoch 054 - training loss: 0.2192, validation loss: 0.1364
2024-05-23 17:27:51 [INFO]: Epoch 055 - training loss: 0.2187, validation loss: 0.1359
2024-05-23 17:27:51 [INFO]: Epoch 056 - training loss: 0.2172, validation loss: 0.1344
2024-05-23 17:27:52 [INFO]: Epoch 057 - training loss: 0.2165, validation loss: 0.1361
2024-05-23 17:27:52 [INFO]: Epoch 058 - training loss: 0.2163, validation loss: 0.1338
2024-05-23 17:27:52 [INFO]: Epoch 059 - training loss: 0.2150, validation loss: 0.1368
2024-05-23 17:27:52 [INFO]: Epoch 060 - training loss: 0.2136, validation loss: 0.1346
2024-05-23 17:27:53 [INFO]: Epoch 061 - training loss: 0.2136, validation loss: 0.1332
2024-05-23 17:27:53 [INFO]: Epoch 062 - training loss: 0.2125, validation loss: 0.1338
2024-05-23 17:27:53 [INFO]: Epoch 063 - training loss: 0.2100, validation loss: 0.1318
2024-05-23 17:27:53 [INFO]: Epoch 064 - training loss: 0.2085, validation loss: 0.1326
2024-05-23 17:27:53 [INFO]: Epoch 065 - training loss: 0.2112, validation loss: 0.1337
2024-05-23 17:27:54 [INFO]: Epoch 066 - training loss: 0.2081, validation loss: 0.1321
2024-05-23 17:27:54 [INFO]: Epoch 067 - training loss: 0.2065, validation loss: 0.1311
2024-05-23 17:27:54 [INFO]: Epoch 068 - training loss: 0.2043, validation loss: 0.1292
2024-05-23 17:27:54 [INFO]: Epoch 069 - training loss: 0.2023, validation loss: 0.1305
2024-05-23 17:27:55 [INFO]: Epoch 070 - training loss: 0.2035, validation loss: 0.1285
2024-05-23 17:27:55 [INFO]: Epoch 071 - training loss: 0.2044, validation loss: 0.1295
2024-05-23 17:27:55 [INFO]: Epoch 072 - training loss: 0.2023, validation loss: 0.1287
2024-05-23 17:27:55 [INFO]: Epoch 073 - training loss: 0.2018, validation loss: 0.1292
2024-05-23 17:27:56 [INFO]: Epoch 074 - training loss: 0.1993, validation loss: 0.1288
2024-05-23 17:27:56 [INFO]: Epoch 075 - training loss: 0.1988, validation loss: 0.1272
2024-05-23 17:27:56 [INFO]: Epoch 076 - training loss: 0.1978, validation loss: 0.1278
2024-05-23 17:27:56 [INFO]: Epoch 077 - training loss: 0.1974, validation loss: 0.1264
2024-05-23 17:27:56 [INFO]: Epoch 078 - training loss: 0.1967, validation loss: 0.1272
2024-05-23 17:27:57 [INFO]: Epoch 079 - training loss: 0.1963, validation loss: 0.1289
2024-05-23 17:27:57 [INFO]: Epoch 080 - training loss: 0.1954, validation loss: 0.1283
2024-05-23 17:27:57 [INFO]: Epoch 081 - training loss: 0.1934, validation loss: 0.1260
2024-05-23 17:27:57 [INFO]: Epoch 082 - training loss: 0.1940, validation loss: 0.1251
2024-05-23 17:27:58 [INFO]: Epoch 083 - training loss: 0.1942, validation loss: 0.1250
2024-05-23 17:27:58 [INFO]: Epoch 084 - training loss: 0.1940, validation loss: 0.1268
2024-05-23 17:27:58 [INFO]: Epoch 085 - training loss: 0.1910, validation loss: 0.1256
2024-05-23 17:27:58 [INFO]: Epoch 086 - training loss: 0.1913, validation loss: 0.1266
2024-05-23 17:27:59 [INFO]: Epoch 087 - training loss: 0.1886, validation loss: 0.1241
2024-05-23 17:27:59 [INFO]: Epoch 088 - training loss: 0.1911, validation loss: 0.1240
2024-05-23 17:27:59 [INFO]: Epoch 089 - training loss: 0.1916, validation loss: 0.1238
2024-05-23 17:27:59 [INFO]: Epoch 090 - training loss: 0.1878, validation loss: 0.1276
2024-05-23 17:28:00 [INFO]: Epoch 091 - training loss: 0.1880, validation loss: 0.1250
2024-05-23 17:28:00 [INFO]: Epoch 092 - training loss: 0.1861, validation loss: 0.1235
2024-05-23 17:28:00 [INFO]: Epoch 093 - training loss: 0.1854, validation loss: 0.1245
2024-05-23 17:28:00 [INFO]: Epoch 094 - training loss: 0.1834, validation loss: 0.1256
2024-05-23 17:28:00 [INFO]: Epoch 095 - training loss: 0.1848, validation loss: 0.1226
2024-05-23 17:28:01 [INFO]: Epoch 096 - training loss: 0.1851, validation loss: 0.1244
2024-05-23 17:28:01 [INFO]: Epoch 097 - training loss: 0.1845, validation loss: 0.1222
2024-05-23 17:28:01 [INFO]: Epoch 098 - training loss: 0.1847, validation loss: 0.1222
2024-05-23 17:28:01 [INFO]: Epoch 099 - training loss: 0.1803, validation loss: 0.1242
2024-05-23 17:28:02 [INFO]: Epoch 100 - training loss: 0.1793, validation loss: 0.1232
2024-05-23 17:28:02 [INFO]: Epoch 101 - training loss: 0.1795, validation loss: 0.1228
2024-05-23 17:28:02 [INFO]: Epoch 102 - training loss: 0.1761, validation loss: 0.1233
2024-05-23 17:28:02 [INFO]: Epoch 103 - training loss: 0.1774, validation loss: 0.1218
2024-05-23 17:28:03 [INFO]: Epoch 104 - training loss: 0.1771, validation loss: 0.1233
2024-05-23 17:28:03 [INFO]: Epoch 105 - training loss: 0.1776, validation loss: 0.1228
2024-05-23 17:28:03 [INFO]: Epoch 106 - training loss: 0.1779, validation loss: 0.1208
2024-05-23 17:28:03 [INFO]: Epoch 107 - training loss: 0.1768, validation loss: 0.1214
2024-05-23 17:28:03 [INFO]: Epoch 108 - training loss: 0.1750, validation loss: 0.1207
2024-05-23 17:28:04 [INFO]: Epoch 109 - training loss: 0.1761, validation loss: 0.1216
2024-05-23 17:28:04 [INFO]: Epoch 110 - training loss: 0.1733, validation loss: 0.1211
2024-05-23 17:28:04 [INFO]: Epoch 111 - training loss: 0.1731, validation loss: 0.1204
2024-05-23 17:28:04 [INFO]: Epoch 112 - training loss: 0.1721, validation loss: 0.1206
2024-05-23 17:28:05 [INFO]: Epoch 113 - training loss: 0.1716, validation loss: 0.1214
2024-05-23 17:28:05 [INFO]: Epoch 114 - training loss: 0.1709, validation loss: 0.1222
2024-05-23 17:28:05 [INFO]: Epoch 115 - training loss: 0.1700, validation loss: 0.1206
2024-05-23 17:28:05 [INFO]: Epoch 116 - training loss: 0.1692, validation loss: 0.1198
2024-05-23 17:28:06 [INFO]: Epoch 117 - training loss: 0.1667, validation loss: 0.1217
2024-05-23 17:28:06 [INFO]: Epoch 118 - training loss: 0.1673, validation loss: 0.1195
2024-05-23 17:28:06 [INFO]: Epoch 119 - training loss: 0.1678, validation loss: 0.1205
2024-05-23 17:28:06 [INFO]: Epoch 120 - training loss: 0.1672, validation loss: 0.1204
2024-05-23 17:28:06 [INFO]: Epoch 121 - training loss: 0.1672, validation loss: 0.1192
2024-05-23 17:28:07 [INFO]: Epoch 122 - training loss: 0.1708, validation loss: 0.1210
2024-05-23 17:28:07 [INFO]: Epoch 123 - training loss: 0.1671, validation loss: 0.1193
2024-05-23 17:28:07 [INFO]: Epoch 124 - training loss: 0.1644, validation loss: 0.1195
2024-05-23 17:28:07 [INFO]: Epoch 125 - training loss: 0.1651, validation loss: 0.1193
2024-05-23 17:28:08 [INFO]: Epoch 126 - training loss: 0.1668, validation loss: 0.1205
2024-05-23 17:28:08 [INFO]: Epoch 127 - training loss: 0.1646, validation loss: 0.1193
2024-05-23 17:28:08 [INFO]: Epoch 128 - training loss: 0.1627, validation loss: 0.1204
2024-05-23 17:28:08 [INFO]: Epoch 129 - training loss: 0.1618, validation loss: 0.1199
2024-05-23 17:28:09 [INFO]: Epoch 130 - training loss: 0.1616, validation loss: 0.1181
2024-05-23 17:28:09 [INFO]: Epoch 131 - training loss: 0.1636, validation loss: 0.1177
2024-05-23 17:28:09 [INFO]: Epoch 132 - training loss: 0.1619, validation loss: 0.1205
2024-05-23 17:28:09 [INFO]: Epoch 133 - training loss: 0.1611, validation loss: 0.1194
2024-05-23 17:28:09 [INFO]: Epoch 134 - training loss: 0.1609, validation loss: 0.1193
2024-05-23 17:28:10 [INFO]: Epoch 135 - training loss: 0.1587, validation loss: 0.1179
2024-05-23 17:28:10 [INFO]: Epoch 136 - training loss: 0.1600, validation loss: 0.1185
2024-05-23 17:28:10 [INFO]: Epoch 137 - training loss: 0.1581, validation loss: 0.1189
2024-05-23 17:28:10 [INFO]: Epoch 138 - training loss: 0.1559, validation loss: 0.1178
2024-05-23 17:28:11 [INFO]: Epoch 139 - training loss: 0.1559, validation loss: 0.1182
2024-05-23 17:28:11 [INFO]: Epoch 140 - training loss: 0.1573, validation loss: 0.1192
2024-05-23 17:28:11 [INFO]: Epoch 141 - training loss: 0.1564, validation loss: 0.1197
2024-05-23 17:28:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:28:11 [INFO]: Finished training. The best model is from epoch#131.
2024-05-23 17:28:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/Transformer_air_quality/20240523_T172738/Transformer.pypots
2024-05-23 17:28:11 [INFO]: Transformer on Air-Quality: MAE=0.1730, MSE=0.2047
2024-05-23 17:28:11 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-23 17:28:11 [INFO]: Using the given device: cuda:0
2024-05-23 17:28:11 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172811
2024-05-23 17:28:11 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172811/tensorboard
2024-05-23 17:28:12 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 17:28:12 [INFO]: Epoch 001 - training loss: 0.2707, validation loss: 0.2494
2024-05-23 17:28:13 [INFO]: Epoch 002 - training loss: 0.2150, validation loss: 0.2069
2024-05-23 17:28:13 [INFO]: Epoch 003 - training loss: 0.1842, validation loss: 0.1905
2024-05-23 17:28:14 [INFO]: Epoch 004 - training loss: 0.1606, validation loss: 0.1807
2024-05-23 17:28:14 [INFO]: Epoch 005 - training loss: 0.1483, validation loss: 0.1718
2024-05-23 17:28:14 [INFO]: Epoch 006 - training loss: 0.1411, validation loss: 0.1651
2024-05-23 17:28:15 [INFO]: Epoch 007 - training loss: 0.1384, validation loss: 0.1661
2024-05-23 17:28:15 [INFO]: Epoch 008 - training loss: 0.1316, validation loss: 0.1619
2024-05-23 17:28:16 [INFO]: Epoch 009 - training loss: 0.1177, validation loss: 0.1566
2024-05-23 17:28:16 [INFO]: Epoch 010 - training loss: 0.1117, validation loss: 0.1524
2024-05-23 17:28:17 [INFO]: Epoch 011 - training loss: 0.1067, validation loss: 0.1500
2024-05-23 17:28:17 [INFO]: Epoch 012 - training loss: 0.1040, validation loss: 0.1499
2024-05-23 17:28:17 [INFO]: Epoch 013 - training loss: 0.0985, validation loss: 0.1466
2024-05-23 17:28:18 [INFO]: Epoch 014 - training loss: 0.0961, validation loss: 0.1473
2024-05-23 17:28:18 [INFO]: Epoch 015 - training loss: 0.0982, validation loss: 0.1463
2024-05-23 17:28:19 [INFO]: Epoch 016 - training loss: 0.0970, validation loss: 0.1433
2024-05-23 17:28:19 [INFO]: Epoch 017 - training loss: 0.0957, validation loss: 0.1409
2024-05-23 17:28:20 [INFO]: Epoch 018 - training loss: 0.0983, validation loss: 0.1450
2024-05-23 17:28:20 [INFO]: Epoch 019 - training loss: 0.0978, validation loss: 0.1432
2024-05-23 17:28:20 [INFO]: Epoch 020 - training loss: 0.0931, validation loss: 0.1436
2024-05-23 17:28:21 [INFO]: Epoch 021 - training loss: 0.0840, validation loss: 0.1408
2024-05-23 17:28:21 [INFO]: Epoch 022 - training loss: 0.0817, validation loss: 0.1390
2024-05-23 17:28:22 [INFO]: Epoch 023 - training loss: 0.0788, validation loss: 0.1413
2024-05-23 17:28:22 [INFO]: Epoch 024 - training loss: 0.0900, validation loss: 0.1416
2024-05-23 17:28:23 [INFO]: Epoch 025 - training loss: 0.0871, validation loss: 0.1457
2024-05-23 17:28:23 [INFO]: Epoch 026 - training loss: 0.0958, validation loss: 0.1426
2024-05-23 17:28:23 [INFO]: Epoch 027 - training loss: 0.0861, validation loss: 0.1361
2024-05-23 17:28:24 [INFO]: Epoch 028 - training loss: 0.0737, validation loss: 0.1353
2024-05-23 17:28:24 [INFO]: Epoch 029 - training loss: 0.0715, validation loss: 0.1360
2024-05-23 17:28:25 [INFO]: Epoch 030 - training loss: 0.0714, validation loss: 0.1370
2024-05-23 17:28:25 [INFO]: Epoch 031 - training loss: 0.0698, validation loss: 0.1346
2024-05-23 17:28:25 [INFO]: Epoch 032 - training loss: 0.0678, validation loss: 0.1350
2024-05-23 17:28:26 [INFO]: Epoch 033 - training loss: 0.0665, validation loss: 0.1370
2024-05-23 17:28:26 [INFO]: Epoch 034 - training loss: 0.0680, validation loss: 0.1367
2024-05-23 17:28:27 [INFO]: Epoch 035 - training loss: 0.0693, validation loss: 0.1370
2024-05-23 17:28:27 [INFO]: Epoch 036 - training loss: 0.0655, validation loss: 0.1360
2024-05-23 17:28:28 [INFO]: Epoch 037 - training loss: 0.0651, validation loss: 0.1369
2024-05-23 17:28:28 [INFO]: Epoch 038 - training loss: 0.0651, validation loss: 0.1345
2024-05-23 17:28:28 [INFO]: Epoch 039 - training loss: 0.0642, validation loss: 0.1384
2024-05-23 17:28:29 [INFO]: Epoch 040 - training loss: 0.0633, validation loss: 0.1381
2024-05-23 17:28:29 [INFO]: Epoch 041 - training loss: 0.0694, validation loss: 0.1384
2024-05-23 17:28:30 [INFO]: Epoch 042 - training loss: 0.0682, validation loss: 0.1437
2024-05-23 17:28:30 [INFO]: Epoch 043 - training loss: 0.0701, validation loss: 0.1399
2024-05-23 17:28:31 [INFO]: Epoch 044 - training loss: 0.0662, validation loss: 0.1339
2024-05-23 17:28:31 [INFO]: Epoch 045 - training loss: 0.0909, validation loss: 0.1529
2024-05-23 17:28:31 [INFO]: Epoch 046 - training loss: 0.0858, validation loss: 0.1403
2024-05-23 17:28:32 [INFO]: Epoch 047 - training loss: 0.0656, validation loss: 0.1420
2024-05-23 17:28:32 [INFO]: Epoch 048 - training loss: 0.0646, validation loss: 0.1383
2024-05-23 17:28:33 [INFO]: Epoch 049 - training loss: 0.0672, validation loss: 0.1348
2024-05-23 17:28:33 [INFO]: Epoch 050 - training loss: 0.0587, validation loss: 0.1376
2024-05-23 17:28:34 [INFO]: Epoch 051 - training loss: 0.0560, validation loss: 0.1354
2024-05-23 17:28:34 [INFO]: Epoch 052 - training loss: 0.0548, validation loss: 0.1356
2024-05-23 17:28:34 [INFO]: Epoch 053 - training loss: 0.0530, validation loss: 0.1352
2024-05-23 17:28:35 [INFO]: Epoch 054 - training loss: 0.0520, validation loss: 0.1371
2024-05-23 17:28:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:28:35 [INFO]: Finished training. The best model is from epoch#44.
2024-05-23 17:28:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/TimesNet_air_quality/20240523_T172811/TimesNet.pypots
2024-05-23 17:28:35 [INFO]: TimesNet on Air-Quality: MAE=0.1659, MSE=0.2435
2024-05-23 17:28:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-23 17:28:35 [INFO]: Using the given device: cuda:0
2024-05-23 17:28:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835
2024-05-23 17:28:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/tensorboard
2024-05-23 17:28:35 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 17:28:52 [INFO]: Epoch 001 - training loss: 0.5330, validation loss: 0.3365
2024-05-23 17:28:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch1_loss0.3364980310201645.pypots
2024-05-23 17:29:08 [INFO]: Epoch 002 - training loss: 0.2736, validation loss: 0.2677
2024-05-23 17:29:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch2_loss0.26770029515028.pypots
2024-05-23 17:29:24 [INFO]: Epoch 003 - training loss: 0.2601, validation loss: 0.2517
2024-05-23 17:29:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch3_loss0.25169895589351654.pypots
2024-05-23 17:29:41 [INFO]: Epoch 004 - training loss: 0.2516, validation loss: 0.2436
2024-05-23 17:29:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch4_loss0.24364725649356841.pypots
2024-05-23 17:29:57 [INFO]: Epoch 005 - training loss: 0.2488, validation loss: 0.2324
2024-05-23 17:29:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch5_loss0.23238591104745865.pypots
2024-05-23 17:30:13 [INFO]: Epoch 006 - training loss: 0.2023, validation loss: 0.2234
2024-05-23 17:30:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch6_loss0.2234176442027092.pypots
2024-05-23 17:30:30 [INFO]: Epoch 007 - training loss: 0.2060, validation loss: 0.2058
2024-05-23 17:30:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch7_loss0.20581483989953994.pypots
2024-05-23 17:30:46 [INFO]: Epoch 008 - training loss: 0.1923, validation loss: 0.1967
2024-05-23 17:30:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch8_loss0.19668394178152085.pypots
2024-05-23 17:31:02 [INFO]: Epoch 009 - training loss: 0.1932, validation loss: 0.1780
2024-05-23 17:31:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch9_loss0.17804246991872788.pypots
2024-05-23 17:31:19 [INFO]: Epoch 010 - training loss: 0.1726, validation loss: 0.1779
2024-05-23 17:31:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch10_loss0.17789153307676314.pypots
2024-05-23 17:31:35 [INFO]: Epoch 011 - training loss: 0.1566, validation loss: 0.1675
2024-05-23 17:31:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch11_loss0.16748259514570235.pypots
2024-05-23 17:31:52 [INFO]: Epoch 012 - training loss: 0.1827, validation loss: 0.1817
2024-05-23 17:31:52 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch12_loss0.1817317321896553.pypots
2024-05-23 17:32:08 [INFO]: Epoch 013 - training loss: 0.1748, validation loss: 0.1614
2024-05-23 17:32:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch13_loss0.16140285432338713.pypots
2024-05-23 17:32:24 [INFO]: Epoch 014 - training loss: 0.1684, validation loss: 0.1516
2024-05-23 17:32:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch14_loss0.15158354640007018.pypots
2024-05-23 17:32:41 [INFO]: Epoch 015 - training loss: 0.1628, validation loss: 0.1580
2024-05-23 17:32:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch15_loss0.15802329778671265.pypots
2024-05-23 17:32:57 [INFO]: Epoch 016 - training loss: 0.1600, validation loss: 0.1457
2024-05-23 17:32:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch16_loss0.14565998315811157.pypots
2024-05-23 17:33:13 [INFO]: Epoch 017 - training loss: 0.1721, validation loss: 0.1475
2024-05-23 17:33:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch17_loss0.14749330282211304.pypots
2024-05-23 17:33:30 [INFO]: Epoch 018 - training loss: 0.1551, validation loss: 0.1470
2024-05-23 17:33:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch18_loss0.14698460549116135.pypots
2024-05-23 17:33:46 [INFO]: Epoch 019 - training loss: 0.1508, validation loss: 0.1465
2024-05-23 17:33:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch19_loss0.14654986709356307.pypots
2024-05-23 17:34:02 [INFO]: Epoch 020 - training loss: 0.1388, validation loss: 0.1391
2024-05-23 17:34:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch20_loss0.1390571802854538.pypots
2024-05-23 17:34:19 [INFO]: Epoch 021 - training loss: 0.1415, validation loss: 0.1422
2024-05-23 17:34:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch21_loss0.1422343596816063.pypots
2024-05-23 17:34:35 [INFO]: Epoch 022 - training loss: 0.1551, validation loss: 0.1358
2024-05-23 17:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch22_loss0.1358259528875351.pypots
2024-05-23 17:34:51 [INFO]: Epoch 023 - training loss: 0.1413, validation loss: 0.1368
2024-05-23 17:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch23_loss0.13680864945054055.pypots
2024-05-23 17:35:08 [INFO]: Epoch 024 - training loss: 0.1387, validation loss: 0.1369
2024-05-23 17:35:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch24_loss0.13692391961812972.pypots
2024-05-23 17:35:24 [INFO]: Epoch 025 - training loss: 0.1456, validation loss: 0.1375
2024-05-23 17:35:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch25_loss0.13745694532990455.pypots
2024-05-23 17:35:41 [INFO]: Epoch 026 - training loss: 0.1374, validation loss: 0.1348
2024-05-23 17:35:41 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch26_loss0.13481452465057372.pypots
2024-05-23 17:35:57 [INFO]: Epoch 027 - training loss: 0.1535, validation loss: 0.1344
2024-05-23 17:35:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch27_loss0.13444151133298873.pypots
2024-05-23 17:36:13 [INFO]: Epoch 028 - training loss: 0.1478, validation loss: 0.1328
2024-05-23 17:36:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch28_loss0.1327863059937954.pypots
2024-05-23 17:36:30 [INFO]: Epoch 029 - training loss: 0.1221, validation loss: 0.1337
2024-05-23 17:36:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch29_loss0.1337001696228981.pypots
2024-05-23 17:36:46 [INFO]: Epoch 030 - training loss: 0.1295, validation loss: 0.1552
2024-05-23 17:36:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch30_loss0.15520767271518707.pypots
2024-05-23 17:37:02 [INFO]: Epoch 031 - training loss: 0.1523, validation loss: 0.1341
2024-05-23 17:37:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch31_loss0.13406686633825302.pypots
2024-05-23 17:37:19 [INFO]: Epoch 032 - training loss: 0.1384, validation loss: 0.1281
2024-05-23 17:37:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch32_loss0.12814192995429038.pypots
2024-05-23 17:37:35 [INFO]: Epoch 033 - training loss: 0.1220, validation loss: 0.1279
2024-05-23 17:37:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch33_loss0.1278993546962738.pypots
2024-05-23 17:37:51 [INFO]: Epoch 034 - training loss: 0.1369, validation loss: 0.1274
2024-05-23 17:37:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch34_loss0.1274426408112049.pypots
2024-05-23 17:38:08 [INFO]: Epoch 035 - training loss: 0.1265, validation loss: 0.1279
2024-05-23 17:38:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch35_loss0.12792245671153069.pypots
2024-05-23 17:38:24 [INFO]: Epoch 036 - training loss: 0.1248, validation loss: 0.1293
2024-05-23 17:38:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch36_loss0.12928266674280167.pypots
2024-05-23 17:38:40 [INFO]: Epoch 037 - training loss: 0.1291, validation loss: 0.1248
2024-05-23 17:38:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch37_loss0.12478638589382171.pypots
2024-05-23 17:38:57 [INFO]: Epoch 038 - training loss: 0.1388, validation loss: 0.1273
2024-05-23 17:38:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch38_loss0.12726433724164962.pypots
2024-05-23 17:39:13 [INFO]: Epoch 039 - training loss: 0.1308, validation loss: 0.1269
2024-05-23 17:39:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch39_loss0.12686344236135483.pypots
2024-05-23 17:39:29 [INFO]: Epoch 040 - training loss: 0.1224, validation loss: 0.1245
2024-05-23 17:39:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch40_loss0.12452712878584862.pypots
2024-05-23 17:39:46 [INFO]: Epoch 041 - training loss: 0.1252, validation loss: 0.1304
2024-05-23 17:39:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch41_loss0.1303917482495308.pypots
2024-05-23 17:40:02 [INFO]: Epoch 042 - training loss: 0.1199, validation loss: 0.1223
2024-05-23 17:40:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch42_loss0.12225352823734284.pypots
2024-05-23 17:40:18 [INFO]: Epoch 043 - training loss: 0.1333, validation loss: 0.1234
2024-05-23 17:40:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch43_loss0.12341883406043053.pypots
2024-05-23 17:40:35 [INFO]: Epoch 044 - training loss: 0.1267, validation loss: 0.1221
2024-05-23 17:40:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch44_loss0.12212031334638596.pypots
2024-05-23 17:40:51 [INFO]: Epoch 045 - training loss: 0.1265, validation loss: 0.1223
2024-05-23 17:40:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch45_loss0.12230786085128784.pypots
2024-05-23 17:41:08 [INFO]: Epoch 046 - training loss: 0.1275, validation loss: 0.1198
2024-05-23 17:41:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch46_loss0.1197759360074997.pypots
2024-05-23 17:41:24 [INFO]: Epoch 047 - training loss: 0.1204, validation loss: 0.1174
2024-05-23 17:41:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch47_loss0.11736215874552727.pypots
2024-05-23 17:41:40 [INFO]: Epoch 048 - training loss: 0.1242, validation loss: 0.1245
2024-05-23 17:41:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch48_loss0.1244814582169056.pypots
2024-05-23 17:41:57 [INFO]: Epoch 049 - training loss: 0.1229, validation loss: 0.1206
2024-05-23 17:41:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch49_loss0.12062378823757172.pypots
2024-05-23 17:42:13 [INFO]: Epoch 050 - training loss: 0.1129, validation loss: 0.1223
2024-05-23 17:42:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch50_loss0.1222555547952652.pypots
2024-05-23 17:42:29 [INFO]: Epoch 051 - training loss: 0.1144, validation loss: 0.1196
2024-05-23 17:42:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch51_loss0.11964558959007263.pypots
2024-05-23 17:42:46 [INFO]: Epoch 052 - training loss: 0.1175, validation loss: 0.1166
2024-05-23 17:42:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch52_loss0.11663790792226791.pypots
2024-05-23 17:43:02 [INFO]: Epoch 053 - training loss: 0.1213, validation loss: 0.1183
2024-05-23 17:43:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch53_loss0.11834210455417633.pypots
2024-05-23 17:43:18 [INFO]: Epoch 054 - training loss: 0.1310, validation loss: 0.1155
2024-05-23 17:43:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch54_loss0.11545251384377479.pypots
2024-05-23 17:43:35 [INFO]: Epoch 055 - training loss: 0.1114, validation loss: 0.1165
2024-05-23 17:43:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch55_loss0.11650073900818825.pypots
2024-05-23 17:43:51 [INFO]: Epoch 056 - training loss: 0.1148, validation loss: 0.1167
2024-05-23 17:43:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch56_loss0.11673078984022141.pypots
2024-05-23 17:44:07 [INFO]: Epoch 057 - training loss: 0.1023, validation loss: 0.1174
2024-05-23 17:44:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch57_loss0.1173544131219387.pypots
2024-05-23 17:44:24 [INFO]: Epoch 058 - training loss: 0.1237, validation loss: 0.1187
2024-05-23 17:44:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch58_loss0.11868097931146622.pypots
2024-05-23 17:44:40 [INFO]: Epoch 059 - training loss: 0.1270, validation loss: 0.1192
2024-05-23 17:44:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch59_loss0.11920483633875847.pypots
2024-05-23 17:44:56 [INFO]: Epoch 060 - training loss: 0.1142, validation loss: 0.1172
2024-05-23 17:44:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch60_loss0.11719184219837189.pypots
2024-05-23 17:45:13 [INFO]: Epoch 061 - training loss: 0.1143, validation loss: 0.1139
2024-05-23 17:45:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch61_loss0.11389904767274857.pypots
2024-05-23 17:45:29 [INFO]: Epoch 062 - training loss: 0.1146, validation loss: 0.1198
2024-05-23 17:45:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch62_loss0.11975626051425933.pypots
2024-05-23 17:45:46 [INFO]: Epoch 063 - training loss: 0.1103, validation loss: 0.1164
2024-05-23 17:45:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch63_loss0.1163708284497261.pypots
2024-05-23 17:46:02 [INFO]: Epoch 064 - training loss: 0.0991, validation loss: 0.1122
2024-05-23 17:46:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch64_loss0.11221913993358612.pypots
2024-05-23 17:46:18 [INFO]: Epoch 065 - training loss: 0.1164, validation loss: 0.1170
2024-05-23 17:46:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch65_loss0.11696699485182763.pypots
2024-05-23 17:46:35 [INFO]: Epoch 066 - training loss: 0.0953, validation loss: 0.1114
2024-05-23 17:46:35 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch66_loss0.11135243996977806.pypots
2024-05-23 17:46:51 [INFO]: Epoch 067 - training loss: 0.1216, validation loss: 0.1142
2024-05-23 17:46:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch67_loss0.11423061639070511.pypots
2024-05-23 17:47:07 [INFO]: Epoch 068 - training loss: 0.1078, validation loss: 0.1172
2024-05-23 17:47:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch68_loss0.11721478179097175.pypots
2024-05-23 17:47:24 [INFO]: Epoch 069 - training loss: 0.1118, validation loss: 0.1119
2024-05-23 17:47:24 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch69_loss0.11192571297287941.pypots
2024-05-23 17:47:40 [INFO]: Epoch 070 - training loss: 0.1124, validation loss: 0.1123
2024-05-23 17:47:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch70_loss0.1122944861650467.pypots
2024-05-23 17:47:56 [INFO]: Epoch 071 - training loss: 0.1258, validation loss: 0.1120
2024-05-23 17:47:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch71_loss0.11195936575531959.pypots
2024-05-23 17:48:13 [INFO]: Epoch 072 - training loss: 0.1164, validation loss: 0.1124
2024-05-23 17:48:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch72_loss0.11237439066171646.pypots
2024-05-23 17:48:29 [INFO]: Epoch 073 - training loss: 0.1050, validation loss: 0.1150
2024-05-23 17:48:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch73_loss0.1149645872414112.pypots
2024-05-23 17:48:45 [INFO]: Epoch 074 - training loss: 0.1114, validation loss: 0.1116
2024-05-23 17:48:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch74_loss0.11162575334310532.pypots
2024-05-23 17:49:02 [INFO]: Epoch 075 - training loss: 0.1086, validation loss: 0.1098
2024-05-23 17:49:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch75_loss0.10984376966953277.pypots
2024-05-23 17:49:18 [INFO]: Epoch 076 - training loss: 0.1190, validation loss: 0.1105
2024-05-23 17:49:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch76_loss0.11046801656484603.pypots
2024-05-23 17:49:34 [INFO]: Epoch 077 - training loss: 0.1107, validation loss: 0.1136
2024-05-23 17:49:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch77_loss0.11361107230186462.pypots
2024-05-23 17:49:51 [INFO]: Epoch 078 - training loss: 0.1084, validation loss: 0.1104
2024-05-23 17:49:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch78_loss0.11037118136882781.pypots
2024-05-23 17:50:07 [INFO]: Epoch 079 - training loss: 0.1132, validation loss: 0.1106
2024-05-23 17:50:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch79_loss0.11061081066727638.pypots
2024-05-23 17:50:23 [INFO]: Epoch 080 - training loss: 0.1099, validation loss: 0.1122
2024-05-23 17:50:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch80_loss0.11217440962791443.pypots
2024-05-23 17:50:40 [INFO]: Epoch 081 - training loss: 0.1019, validation loss: 0.1088
2024-05-23 17:50:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch81_loss0.10884058028459549.pypots
2024-05-23 17:50:56 [INFO]: Epoch 082 - training loss: 0.1141, validation loss: 0.1067
2024-05-23 17:50:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch82_loss0.10670398622751236.pypots
2024-05-23 17:51:12 [INFO]: Epoch 083 - training loss: 0.1154, validation loss: 0.1101
2024-05-23 17:51:12 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch83_loss0.110117719322443.pypots
2024-05-23 17:51:29 [INFO]: Epoch 084 - training loss: 0.1027, validation loss: 0.1158
2024-05-23 17:51:29 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch84_loss0.11576659828424454.pypots
2024-05-23 17:51:45 [INFO]: Epoch 085 - training loss: 0.1093, validation loss: 0.1100
2024-05-23 17:51:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch85_loss0.10998954698443413.pypots
2024-05-23 17:52:02 [INFO]: Epoch 086 - training loss: 0.0985, validation loss: 0.1098
2024-05-23 17:52:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch86_loss0.10982073694467545.pypots
2024-05-23 17:52:18 [INFO]: Epoch 087 - training loss: 0.1050, validation loss: 0.1088
2024-05-23 17:52:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch87_loss0.10876991301774978.pypots
2024-05-23 17:52:34 [INFO]: Epoch 088 - training loss: 0.1113, validation loss: 0.1092
2024-05-23 17:52:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch88_loss0.10923348963260651.pypots
2024-05-23 17:52:51 [INFO]: Epoch 089 - training loss: 0.1092, validation loss: 0.1070
2024-05-23 17:52:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch89_loss0.10704397186636924.pypots
2024-05-23 17:53:07 [INFO]: Epoch 090 - training loss: 0.1101, validation loss: 0.1071
2024-05-23 17:53:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch90_loss0.10709467306733131.pypots
2024-05-23 17:53:23 [INFO]: Epoch 091 - training loss: 0.1160, validation loss: 0.1094
2024-05-23 17:53:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch91_loss0.10942024141550064.pypots
2024-05-23 17:53:40 [INFO]: Epoch 092 - training loss: 0.1050, validation loss: 0.1102
2024-05-23 17:53:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI_epoch92_loss0.11021750569343566.pypots
2024-05-23 17:53:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:53:40 [INFO]: Finished training. The best model is from epoch#82.
2024-05-23 17:53:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/CSDI_air_quality/20240523_T172835/CSDI.pypots
2024-05-23 17:55:58 [INFO]: CSDI on Air-Quality: MAE=0.1084, MSE=0.2242
2024-05-23 17:55:58 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-23 17:55:58 [INFO]: Using the given device: cuda:0
2024-05-23 17:55:58 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175558
2024-05-23 17:55:58 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175558/tensorboard
2024-05-23 17:55:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 17:55:58 [INFO]: Epoch 001 - training loss: 64260.6046, validation loss: 0.6189
2024-05-23 17:55:58 [INFO]: Epoch 002 - training loss: 41849.4932, validation loss: 0.5509
2024-05-23 17:55:59 [INFO]: Epoch 003 - training loss: 41504.1574, validation loss: 0.4834
2024-05-23 17:55:59 [INFO]: Epoch 004 - training loss: 41394.8038, validation loss: 0.4563
2024-05-23 17:55:59 [INFO]: Epoch 005 - training loss: 41285.0094, validation loss: 0.4182
2024-05-23 17:55:59 [INFO]: Epoch 006 - training loss: 41218.4206, validation loss: 0.3856
2024-05-23 17:56:00 [INFO]: Epoch 007 - training loss: 41207.9533, validation loss: 0.3929
2024-05-23 17:56:00 [INFO]: Epoch 008 - training loss: 41162.2852, validation loss: 0.3500
2024-05-23 17:56:00 [INFO]: Epoch 009 - training loss: 41122.5388, validation loss: 0.3212
2024-05-23 17:56:00 [INFO]: Epoch 010 - training loss: 41102.3030, validation loss: 0.3253
2024-05-23 17:56:00 [INFO]: Epoch 011 - training loss: 41106.6340, validation loss: 0.3108
2024-05-23 17:56:01 [INFO]: Epoch 012 - training loss: 41047.4753, validation loss: 0.3134
2024-05-23 17:56:01 [INFO]: Epoch 013 - training loss: 41037.0579, validation loss: 0.2948
2024-05-23 17:56:01 [INFO]: Epoch 014 - training loss: 41034.4076, validation loss: 0.2933
2024-05-23 17:56:01 [INFO]: Epoch 015 - training loss: 41011.4209, validation loss: 0.2766
2024-05-23 17:56:02 [INFO]: Epoch 016 - training loss: 40996.2023, validation loss: 0.2746
2024-05-23 17:56:02 [INFO]: Epoch 017 - training loss: 40982.5056, validation loss: 0.2647
2024-05-23 17:56:02 [INFO]: Epoch 018 - training loss: 40987.2242, validation loss: 0.2873
2024-05-23 17:56:02 [INFO]: Epoch 019 - training loss: 40979.5360, validation loss: 0.2875
2024-05-23 17:56:03 [INFO]: Epoch 020 - training loss: 40998.1557, validation loss: 0.2738
2024-05-23 17:56:03 [INFO]: Epoch 021 - training loss: 40962.8565, validation loss: 0.2754
2024-05-23 17:56:03 [INFO]: Epoch 022 - training loss: 40965.9162, validation loss: 0.2540
2024-05-23 17:56:03 [INFO]: Epoch 023 - training loss: 40944.1427, validation loss: 0.2536
2024-05-23 17:56:04 [INFO]: Epoch 024 - training loss: 40942.7701, validation loss: 0.2461
2024-05-23 17:56:04 [INFO]: Epoch 025 - training loss: 40944.2872, validation loss: 0.2500
2024-05-23 17:56:04 [INFO]: Epoch 026 - training loss: 40984.1684, validation loss: 0.2631
2024-05-23 17:56:04 [INFO]: Epoch 027 - training loss: 40989.9903, validation loss: 0.2586
2024-05-23 17:56:05 [INFO]: Epoch 028 - training loss: 40934.1678, validation loss: 0.2444
2024-05-23 17:56:05 [INFO]: Epoch 029 - training loss: 40934.0166, validation loss: 0.2451
2024-05-23 17:56:05 [INFO]: Epoch 030 - training loss: 40921.0729, validation loss: 0.2426
2024-05-23 17:56:05 [INFO]: Epoch 031 - training loss: 40941.5887, validation loss: 0.2701
2024-05-23 17:56:05 [INFO]: Epoch 032 - training loss: 40925.7458, validation loss: 0.2328
2024-05-23 17:56:06 [INFO]: Epoch 033 - training loss: 40913.5177, validation loss: 0.2256
2024-05-23 17:56:06 [INFO]: Epoch 034 - training loss: 40896.3666, validation loss: 0.2278
2024-05-23 17:56:06 [INFO]: Epoch 035 - training loss: 40892.5767, validation loss: 0.2259
2024-05-23 17:56:06 [INFO]: Epoch 036 - training loss: 40892.9527, validation loss: 0.2228
2024-05-23 17:56:07 [INFO]: Epoch 037 - training loss: 40892.8805, validation loss: 0.2244
2024-05-23 17:56:07 [INFO]: Epoch 038 - training loss: 40887.3456, validation loss: 0.2236
2024-05-23 17:56:07 [INFO]: Epoch 039 - training loss: 40883.6717, validation loss: 0.2203
2024-05-23 17:56:07 [INFO]: Epoch 040 - training loss: 40886.6632, validation loss: 0.2281
2024-05-23 17:56:08 [INFO]: Epoch 041 - training loss: 40885.8621, validation loss: 0.2241
2024-05-23 17:56:08 [INFO]: Epoch 042 - training loss: 40880.3422, validation loss: 0.2156
2024-05-23 17:56:08 [INFO]: Epoch 043 - training loss: 40890.0132, validation loss: 0.2582
2024-05-23 17:56:08 [INFO]: Epoch 044 - training loss: 41033.4489, validation loss: 0.2594
2024-05-23 17:56:09 [INFO]: Epoch 045 - training loss: 40979.7234, validation loss: 0.2436
2024-05-23 17:56:09 [INFO]: Epoch 046 - training loss: 40932.5010, validation loss: 0.2248
2024-05-23 17:56:09 [INFO]: Epoch 047 - training loss: 40921.4181, validation loss: 0.2253
2024-05-23 17:56:09 [INFO]: Epoch 048 - training loss: 40916.8166, validation loss: 0.2231
2024-05-23 17:56:09 [INFO]: Epoch 049 - training loss: 40915.8222, validation loss: 0.2258
2024-05-23 17:56:10 [INFO]: Epoch 050 - training loss: 40902.8853, validation loss: 0.2180
2024-05-23 17:56:10 [INFO]: Epoch 051 - training loss: 40890.8869, validation loss: 0.2214
2024-05-23 17:56:10 [INFO]: Epoch 052 - training loss: 40895.5250, validation loss: 0.2107
2024-05-23 17:56:10 [INFO]: Epoch 053 - training loss: 40898.7904, validation loss: 0.2169
2024-05-23 17:56:11 [INFO]: Epoch 054 - training loss: 40898.0845, validation loss: 0.2155
2024-05-23 17:56:11 [INFO]: Epoch 055 - training loss: 40880.6943, validation loss: 0.2163
2024-05-23 17:56:11 [INFO]: Epoch 056 - training loss: 40867.2627, validation loss: 0.2056
2024-05-23 17:56:11 [INFO]: Epoch 057 - training loss: 40861.8555, validation loss: 0.2078
2024-05-23 17:56:12 [INFO]: Epoch 058 - training loss: 40856.4753, validation loss: 0.2039
2024-05-23 17:56:12 [INFO]: Epoch 059 - training loss: 40854.4012, validation loss: 0.2086
2024-05-23 17:56:12 [INFO]: Epoch 060 - training loss: 40852.6383, validation loss: 0.2022
2024-05-23 17:56:12 [INFO]: Epoch 061 - training loss: 40851.6149, validation loss: 0.2018
2024-05-23 17:56:13 [INFO]: Epoch 062 - training loss: 40853.5622, validation loss: 0.2003
2024-05-23 17:56:13 [INFO]: Epoch 063 - training loss: 40850.3588, validation loss: 0.1975
2024-05-23 17:56:13 [INFO]: Epoch 064 - training loss: 40873.1207, validation loss: 0.2120
2024-05-23 17:56:13 [INFO]: Epoch 065 - training loss: 40871.1040, validation loss: 0.2056
2024-05-23 17:56:13 [INFO]: Epoch 066 - training loss: 40852.4932, validation loss: 0.2011
2024-05-23 17:56:14 [INFO]: Epoch 067 - training loss: 40845.4266, validation loss: 0.2005
2024-05-23 17:56:14 [INFO]: Epoch 068 - training loss: 40843.6730, validation loss: 0.2044
2024-05-23 17:56:14 [INFO]: Epoch 069 - training loss: 40840.9184, validation loss: 0.1984
2024-05-23 17:56:14 [INFO]: Epoch 070 - training loss: 40852.8753, validation loss: 0.2121
2024-05-23 17:56:15 [INFO]: Epoch 071 - training loss: 40893.9981, validation loss: 0.2142
2024-05-23 17:56:15 [INFO]: Epoch 072 - training loss: 40891.7290, validation loss: 0.2061
2024-05-23 17:56:15 [INFO]: Epoch 073 - training loss: 40862.8938, validation loss: 0.2087
2024-05-23 17:56:15 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 17:56:15 [INFO]: Finished training. The best model is from epoch#63.
2024-05-23 17:56:15 [INFO]: Saved the model to overlay_premask_saved_results/round_0/GPVAE_air_quality/20240523_T175558/GPVAE.pypots
2024-05-23 17:56:15 [INFO]: GP-VAE on Air-Quality: MAE=0.2810, MSE=0.3010
2024-05-23 17:56:15 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-23 17:56:15 [INFO]: Using the given device: cuda:0
2024-05-23 17:56:15 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240523_T175615
2024-05-23 17:56:15 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/USGAN_air_quality/20240523_T175615/tensorboard
2024-05-23 17:56:15 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 17:56:19 [INFO]: Epoch 001 - generator training loss: 0.4635, discriminator training loss: 0.4552, validation loss: 0.4871
2024-05-23 17:56:22 [INFO]: Epoch 002 - generator training loss: 0.0951, discriminator training loss: 0.3623, validation loss: 0.3693
2024-05-23 17:56:26 [INFO]: Epoch 003 - generator training loss: 0.0362, discriminator training loss: 0.3573, validation loss: 0.3010
2024-05-23 17:56:29 [INFO]: Epoch 004 - generator training loss: -0.0026, discriminator training loss: 0.3551, validation loss: 0.2621
2024-05-23 17:56:32 [INFO]: Epoch 005 - generator training loss: -0.0245, discriminator training loss: 0.3533, validation loss: 0.2382
2024-05-23 17:56:36 [INFO]: Epoch 006 - generator training loss: -0.0423, discriminator training loss: 0.3512, validation loss: 0.2205
2024-05-23 17:56:39 [INFO]: Epoch 007 - generator training loss: -0.0547, discriminator training loss: 0.3491, validation loss: 0.2078
2024-05-23 17:56:42 [INFO]: Epoch 008 - generator training loss: -0.0640, discriminator training loss: 0.3469, validation loss: 0.1976
2024-05-23 17:56:46 [INFO]: Epoch 009 - generator training loss: -0.0703, discriminator training loss: 0.3443, validation loss: 0.1895
2024-05-23 17:56:49 [INFO]: Epoch 010 - generator training loss: -0.0775, discriminator training loss: 0.3418, validation loss: 0.1818
2024-05-23 17:56:52 [INFO]: Epoch 011 - generator training loss: -0.0766, discriminator training loss: 0.3392, validation loss: 0.1764
2024-05-23 17:56:55 [INFO]: Epoch 012 - generator training loss: -0.0853, discriminator training loss: 0.3363, validation loss: 0.1729
2024-05-23 17:56:59 [INFO]: Epoch 013 - generator training loss: -0.0871, discriminator training loss: 0.3330, validation loss: 0.1677
2024-05-23 17:57:02 [INFO]: Epoch 014 - generator training loss: -0.0882, discriminator training loss: 0.3298, validation loss: 0.1637
2024-05-23 17:57:05 [INFO]: Epoch 015 - generator training loss: -0.0898, discriminator training loss: 0.3265, validation loss: 0.1606
2024-05-23 17:57:09 [INFO]: Epoch 016 - generator training loss: -0.0906, discriminator training loss: 0.3227, validation loss: 0.1568
2024-05-23 17:57:12 [INFO]: Epoch 017 - generator training loss: -0.0908, discriminator training loss: 0.3192, validation loss: 0.1547
2024-05-23 17:57:15 [INFO]: Epoch 018 - generator training loss: -0.0904, discriminator training loss: 0.3154, validation loss: 0.1518
2024-05-23 17:57:18 [INFO]: Epoch 019 - generator training loss: -0.0866, discriminator training loss: 0.3114, validation loss: 0.1493
2024-05-23 17:57:22 [INFO]: Epoch 020 - generator training loss: -0.0881, discriminator training loss: 0.3076, validation loss: 0.1473
2024-05-23 17:57:25 [INFO]: Epoch 021 - generator training loss: -0.0881, discriminator training loss: 0.3036, validation loss: 0.1443
2024-05-23 17:57:28 [INFO]: Epoch 022 - generator training loss: -0.0880, discriminator training loss: 0.2995, validation loss: 0.1423
2024-05-23 17:57:32 [INFO]: Epoch 023 - generator training loss: -0.0865, discriminator training loss: 0.2954, validation loss: 0.1396
2024-05-23 17:57:35 [INFO]: Epoch 024 - generator training loss: -0.0859, discriminator training loss: 0.2914, validation loss: 0.1375
2024-05-23 17:57:38 [INFO]: Epoch 025 - generator training loss: -0.0856, discriminator training loss: 0.2875, validation loss: 0.1356
2024-05-23 17:57:42 [INFO]: Epoch 026 - generator training loss: -0.0839, discriminator training loss: 0.2834, validation loss: 0.1342
2024-05-23 17:57:45 [INFO]: Epoch 027 - generator training loss: -0.0832, discriminator training loss: 0.2799, validation loss: 0.1322
2024-05-23 17:57:48 [INFO]: Epoch 028 - generator training loss: -0.0819, discriminator training loss: 0.2764, validation loss: 0.1313
2024-05-23 17:57:51 [INFO]: Epoch 029 - generator training loss: -0.0802, discriminator training loss: 0.2728, validation loss: 0.1300
2024-05-23 17:57:55 [INFO]: Epoch 030 - generator training loss: -0.0784, discriminator training loss: 0.2694, validation loss: 0.1271
2024-05-23 17:57:58 [INFO]: Epoch 031 - generator training loss: -0.0792, discriminator training loss: 0.2662, validation loss: 0.1259
2024-05-23 17:58:01 [INFO]: Epoch 032 - generator training loss: -0.0779, discriminator training loss: 0.2631, validation loss: 0.1240
2024-05-23 17:58:05 [INFO]: Epoch 033 - generator training loss: -0.0775, discriminator training loss: 0.2598, validation loss: 0.1230
2024-05-23 17:58:08 [INFO]: Epoch 034 - generator training loss: -0.0761, discriminator training loss: 0.2572, validation loss: 0.1220
2024-05-23 17:58:11 [INFO]: Epoch 035 - generator training loss: -0.0761, discriminator training loss: 0.2542, validation loss: 0.1210
2024-05-23 17:58:15 [INFO]: Epoch 036 - generator training loss: -0.0753, discriminator training loss: 0.2522, validation loss: 0.1196
2024-05-23 17:58:18 [INFO]: Epoch 037 - generator training loss: -0.0732, discriminator training loss: 0.2495, validation loss: 0.1179
2024-05-23 17:58:21 [INFO]: Epoch 038 - generator training loss: -0.0730, discriminator training loss: 0.2470, validation loss: 0.1171
2024-05-23 17:58:24 [INFO]: Epoch 039 - generator training loss: -0.0720, discriminator training loss: 0.2449, validation loss: 0.1159
2024-05-23 17:58:28 [INFO]: Epoch 040 - generator training loss: -0.0723, discriminator training loss: 0.2429, validation loss: 0.1152
2024-05-23 17:58:31 [INFO]: Epoch 041 - generator training loss: -0.0713, discriminator training loss: 0.2411, validation loss: 0.1147
2024-05-23 17:58:34 [INFO]: Epoch 042 - generator training loss: -0.0713, discriminator training loss: 0.2390, validation loss: 0.1132
2024-05-23 17:58:38 [INFO]: Epoch 043 - generator training loss: -0.0710, discriminator training loss: 0.2374, validation loss: 0.1122
2024-05-23 17:58:41 [INFO]: Epoch 044 - generator training loss: -0.0682, discriminator training loss: 0.2360, validation loss: 0.1113
2024-05-23 17:58:44 [INFO]: Epoch 045 - generator training loss: -0.0707, discriminator training loss: 0.2339, validation loss: 0.1109
2024-05-23 17:58:47 [INFO]: Epoch 046 - generator training loss: -0.0685, discriminator training loss: 0.2328, validation loss: 0.1102
2024-05-23 17:58:51 [INFO]: Epoch 047 - generator training loss: -0.0688, discriminator training loss: 0.2316, validation loss: 0.1095
2024-05-23 17:58:54 [INFO]: Epoch 048 - generator training loss: -0.0699, discriminator training loss: 0.2301, validation loss: 0.1083
2024-05-23 17:58:57 [INFO]: Epoch 049 - generator training loss: -0.0690, discriminator training loss: 0.2286, validation loss: 0.1078
2024-05-23 17:59:01 [INFO]: Epoch 050 - generator training loss: -0.0679, discriminator training loss: 0.2279, validation loss: 0.1075
2024-05-23 17:59:04 [INFO]: Epoch 051 - generator training loss: -0.0678, discriminator training loss: 0.2266, validation loss: 0.1070
2024-05-23 17:59:07 [INFO]: Epoch 052 - generator training loss: -0.0692, discriminator training loss: 0.2249, validation loss: 0.1059
2024-05-23 17:59:10 [INFO]: Epoch 053 - generator training loss: -0.0692, discriminator training loss: 0.2243, validation loss: 0.1054
2024-05-23 17:59:14 [INFO]: Epoch 054 - generator training loss: -0.0681, discriminator training loss: 0.2235, validation loss: 0.1055
2024-05-23 17:59:17 [INFO]: Epoch 055 - generator training loss: -0.0680, discriminator training loss: 0.2224, validation loss: 0.1051
2024-05-23 17:59:20 [INFO]: Epoch 056 - generator training loss: -0.0692, discriminator training loss: 0.2216, validation loss: 0.1039
2024-05-23 17:59:24 [INFO]: Epoch 057 - generator training loss: -0.0684, discriminator training loss: 0.2208, validation loss: 0.1037
2024-05-23 17:59:27 [INFO]: Epoch 058 - generator training loss: -0.0682, discriminator training loss: 0.2202, validation loss: 0.1031
2024-05-23 17:59:30 [INFO]: Epoch 059 - generator training loss: -0.0671, discriminator training loss: 0.2191, validation loss: 0.1025
2024-05-23 17:59:33 [INFO]: Epoch 060 - generator training loss: -0.0696, discriminator training loss: 0.2184, validation loss: 0.1018
2024-05-23 17:59:37 [INFO]: Epoch 061 - generator training loss: -0.0689, discriminator training loss: 0.2180, validation loss: 0.1018
2024-05-23 17:59:40 [INFO]: Epoch 062 - generator training loss: -0.0697, discriminator training loss: 0.2172, validation loss: 0.1018
2024-05-23 17:59:43 [INFO]: Epoch 063 - generator training loss: -0.0693, discriminator training loss: 0.2170, validation loss: 0.1012
2024-05-23 17:59:47 [INFO]: Epoch 064 - generator training loss: -0.0694, discriminator training loss: 0.2160, validation loss: 0.1005
2024-05-23 17:59:50 [INFO]: Epoch 065 - generator training loss: -0.0698, discriminator training loss: 0.2157, validation loss: 0.1007
2024-05-23 17:59:53 [INFO]: Epoch 066 - generator training loss: -0.0699, discriminator training loss: 0.2154, validation loss: 0.1000
2024-05-23 17:59:56 [INFO]: Epoch 067 - generator training loss: -0.0700, discriminator training loss: 0.2142, validation loss: 0.1005
2024-05-23 18:00:00 [INFO]: Epoch 068 - generator training loss: -0.0679, discriminator training loss: 0.2142, validation loss: 0.1001
2024-05-23 18:00:03 [INFO]: Epoch 069 - generator training loss: -0.0689, discriminator training loss: 0.2139, validation loss: 0.0996
2024-05-23 18:00:06 [INFO]: Epoch 070 - generator training loss: -0.0698, discriminator training loss: 0.2134, validation loss: 0.0991
2024-05-23 18:00:10 [INFO]: Epoch 071 - generator training loss: -0.0694, discriminator training loss: 0.2126, validation loss: 0.0993
2024-05-23 18:00:13 [INFO]: Epoch 072 - generator training loss: -0.0715, discriminator training loss: 0.2128, validation loss: 0.0986
2024-05-23 18:00:16 [INFO]: Epoch 073 - generator training loss: -0.0709, discriminator training loss: 0.2126, validation loss: 0.0985
2024-05-23 18:00:20 [INFO]: Epoch 074 - generator training loss: -0.0713, discriminator training loss: 0.2120, validation loss: 0.0990
2024-05-23 18:00:23 [INFO]: Epoch 075 - generator training loss: -0.0708, discriminator training loss: 0.2121, validation loss: 0.0981
2024-05-23 18:00:26 [INFO]: Epoch 076 - generator training loss: -0.0714, discriminator training loss: 0.2112, validation loss: 0.0984
2024-05-23 18:00:29 [INFO]: Epoch 077 - generator training loss: -0.0716, discriminator training loss: 0.2108, validation loss: 0.0975
2024-05-23 18:00:33 [INFO]: Epoch 078 - generator training loss: -0.0715, discriminator training loss: 0.2109, validation loss: 0.0966
2024-05-23 18:00:36 [INFO]: Epoch 079 - generator training loss: -0.0722, discriminator training loss: 0.2103, validation loss: 0.0977
2024-05-23 18:00:39 [INFO]: Epoch 080 - generator training loss: -0.0724, discriminator training loss: 0.2102, validation loss: 0.0971
2024-05-23 18:00:43 [INFO]: Epoch 081 - generator training loss: -0.0726, discriminator training loss: 0.2098, validation loss: 0.0966
2024-05-23 18:00:46 [INFO]: Epoch 082 - generator training loss: -0.0727, discriminator training loss: 0.2095, validation loss: 0.0962
2024-05-23 18:00:49 [INFO]: Epoch 083 - generator training loss: -0.0736, discriminator training loss: 0.2097, validation loss: 0.0960
2024-05-23 18:00:52 [INFO]: Epoch 084 - generator training loss: -0.0727, discriminator training loss: 0.2090, validation loss: 0.0968
2024-05-23 18:00:56 [INFO]: Epoch 085 - generator training loss: -0.0720, discriminator training loss: 0.2086, validation loss: 0.0959
2024-05-23 18:00:59 [INFO]: Epoch 086 - generator training loss: -0.0733, discriminator training loss: 0.2087, validation loss: 0.0956
2024-05-23 18:01:02 [INFO]: Epoch 087 - generator training loss: -0.0743, discriminator training loss: 0.2083, validation loss: 0.0955
2024-05-23 18:01:06 [INFO]: Epoch 088 - generator training loss: -0.0747, discriminator training loss: 0.2084, validation loss: 0.0955
2024-05-23 18:01:09 [INFO]: Epoch 089 - generator training loss: -0.0752, discriminator training loss: 0.2079, validation loss: 0.0947
2024-05-23 18:01:12 [INFO]: Epoch 090 - generator training loss: -0.0749, discriminator training loss: 0.2079, validation loss: 0.0950
2024-05-23 18:01:16 [INFO]: Epoch 091 - generator training loss: -0.0746, discriminator training loss: 0.2072, validation loss: 0.0954
2024-05-23 18:01:19 [INFO]: Epoch 092 - generator training loss: -0.0750, discriminator training loss: 0.2076, validation loss: 0.0949
2024-05-23 18:01:22 [INFO]: Epoch 093 - generator training loss: -0.0763, discriminator training loss: 0.2072, validation loss: 0.0948
2024-05-23 18:01:25 [INFO]: Epoch 094 - generator training loss: -0.0748, discriminator training loss: 0.2072, validation loss: 0.0953
2024-05-23 18:01:29 [INFO]: Epoch 095 - generator training loss: -0.0749, discriminator training loss: 0.2069, validation loss: 0.0945
2024-05-23 18:01:32 [INFO]: Epoch 096 - generator training loss: -0.0759, discriminator training loss: 0.2069, validation loss: 0.0952
2024-05-23 18:01:35 [INFO]: Epoch 097 - generator training loss: -0.0747, discriminator training loss: 0.2070, validation loss: 0.0946
2024-05-23 18:01:39 [INFO]: Epoch 098 - generator training loss: -0.0766, discriminator training loss: 0.2064, validation loss: 0.0946
2024-05-23 18:01:42 [INFO]: Epoch 099 - generator training loss: -0.0759, discriminator training loss: 0.2063, validation loss: 0.0949
2024-05-23 18:01:45 [INFO]: Epoch 100 - generator training loss: -0.0758, discriminator training loss: 0.2060, validation loss: 0.0952
2024-05-23 18:01:48 [INFO]: Epoch 101 - generator training loss: -0.0760, discriminator training loss: 0.2061, validation loss: 0.0946
2024-05-23 18:01:52 [INFO]: Epoch 102 - generator training loss: -0.0761, discriminator training loss: 0.2060, validation loss: 0.0945
2024-05-23 18:01:55 [INFO]: Epoch 103 - generator training loss: -0.0771, discriminator training loss: 0.2058, validation loss: 0.0942
2024-05-23 18:01:58 [INFO]: Epoch 104 - generator training loss: -0.0773, discriminator training loss: 0.2057, validation loss: 0.0939
2024-05-23 18:02:02 [INFO]: Epoch 105 - generator training loss: -0.0775, discriminator training loss: 0.2050, validation loss: 0.0945
2024-05-23 18:02:05 [INFO]: Epoch 106 - generator training loss: -0.0771, discriminator training loss: 0.2049, validation loss: 0.0941
2024-05-23 18:02:08 [INFO]: Epoch 107 - generator training loss: -0.0776, discriminator training loss: 0.2051, validation loss: 0.0941
2024-05-23 18:02:12 [INFO]: Epoch 108 - generator training loss: -0.0772, discriminator training loss: 0.2051, validation loss: 0.0934
2024-05-23 18:02:15 [INFO]: Epoch 109 - generator training loss: -0.0787, discriminator training loss: 0.2048, validation loss: 0.0940
2024-05-23 18:02:18 [INFO]: Epoch 110 - generator training loss: -0.0787, discriminator training loss: 0.2047, validation loss: 0.0946
2024-05-23 18:02:22 [INFO]: Epoch 111 - generator training loss: -0.0791, discriminator training loss: 0.2050, validation loss: 0.0936
2024-05-23 18:02:25 [INFO]: Epoch 112 - generator training loss: -0.0786, discriminator training loss: 0.2050, validation loss: 0.0942
2024-05-23 18:02:28 [INFO]: Epoch 113 - generator training loss: -0.0794, discriminator training loss: 0.2045, validation loss: 0.0949
2024-05-23 18:02:31 [INFO]: Epoch 114 - generator training loss: -0.0788, discriminator training loss: 0.2046, validation loss: 0.0944
2024-05-23 18:02:35 [INFO]: Epoch 115 - generator training loss: -0.0795, discriminator training loss: 0.2046, validation loss: 0.0940
2024-05-23 18:02:38 [INFO]: Epoch 116 - generator training loss: -0.0784, discriminator training loss: 0.2048, validation loss: 0.0941
2024-05-23 18:02:41 [INFO]: Epoch 117 - generator training loss: -0.0794, discriminator training loss: 0.2047, validation loss: 0.0937
2024-05-23 18:02:45 [INFO]: Epoch 118 - generator training loss: -0.0802, discriminator training loss: 0.2037, validation loss: 0.0930
2024-05-23 18:02:48 [INFO]: Epoch 119 - generator training loss: -0.0802, discriminator training loss: 0.2036, validation loss: 0.0941
2024-05-23 18:02:51 [INFO]: Epoch 120 - generator training loss: -0.0798, discriminator training loss: 0.2037, validation loss: 0.0941
2024-05-23 18:02:54 [INFO]: Epoch 121 - generator training loss: -0.0791, discriminator training loss: 0.2040, validation loss: 0.0937
2024-05-23 18:02:58 [INFO]: Epoch 122 - generator training loss: -0.0794, discriminator training loss: 0.2032, validation loss: 0.0944
2024-05-23 18:03:01 [INFO]: Epoch 123 - generator training loss: -0.0795, discriminator training loss: 0.2034, validation loss: 0.0944
2024-05-23 18:03:04 [INFO]: Epoch 124 - generator training loss: -0.0797, discriminator training loss: 0.2031, validation loss: 0.0939
2024-05-23 18:03:08 [INFO]: Epoch 125 - generator training loss: -0.0808, discriminator training loss: 0.2035, validation loss: 0.0934
2024-05-23 18:03:11 [INFO]: Epoch 126 - generator training loss: -0.0804, discriminator training loss: 0.2034, validation loss: 0.0931
2024-05-23 18:03:14 [INFO]: Epoch 127 - generator training loss: -0.0805, discriminator training loss: 0.2033, validation loss: 0.0934
2024-05-23 18:03:18 [INFO]: Epoch 128 - generator training loss: -0.0802, discriminator training loss: 0.2032, validation loss: 0.0930
2024-05-23 18:03:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:03:18 [INFO]: Finished training. The best model is from epoch#118.
2024-05-23 18:03:18 [INFO]: Saved the model to overlay_premask_saved_results/round_0/USGAN_air_quality/20240523_T175615/USGAN.pypots
2024-05-23 18:03:18 [INFO]: US-GAN on Air-Quality: MAE=0.1540, MSE=0.1503
2024-05-23 18:03:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-23 18:03:18 [INFO]: Using the given device: cuda:0
2024-05-23 18:03:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240523_T180318
2024-05-23 18:03:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/BRITS_air_quality/20240523_T180318/tensorboard
2024-05-23 18:03:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 18:03:21 [INFO]: Epoch 001 - training loss: 1.4113, validation loss: 0.9200
2024-05-23 18:03:23 [INFO]: Epoch 002 - training loss: 1.1497, validation loss: 0.6767
2024-05-23 18:03:25 [INFO]: Epoch 003 - training loss: 0.9555, validation loss: 0.5685
2024-05-23 18:03:27 [INFO]: Epoch 004 - training loss: 0.8446, validation loss: 0.4979
2024-05-23 18:03:30 [INFO]: Epoch 005 - training loss: 0.7695, validation loss: 0.4523
2024-05-23 18:03:32 [INFO]: Epoch 006 - training loss: 0.7141, validation loss: 0.4146
2024-05-23 18:03:34 [INFO]: Epoch 007 - training loss: 0.6688, validation loss: 0.3835
2024-05-23 18:03:36 [INFO]: Epoch 008 - training loss: 0.6339, validation loss: 0.3576
2024-05-23 18:03:39 [INFO]: Epoch 009 - training loss: 0.6083, validation loss: 0.3383
2024-05-23 18:03:41 [INFO]: Epoch 010 - training loss: 0.5863, validation loss: 0.3214
2024-05-23 18:03:43 [INFO]: Epoch 011 - training loss: 0.5702, validation loss: 0.3070
2024-05-23 18:03:45 [INFO]: Epoch 012 - training loss: 0.5560, validation loss: 0.2960
2024-05-23 18:03:47 [INFO]: Epoch 013 - training loss: 0.5426, validation loss: 0.2858
2024-05-23 18:03:50 [INFO]: Epoch 014 - training loss: 0.5300, validation loss: 0.2765
2024-05-23 18:03:52 [INFO]: Epoch 015 - training loss: 0.5190, validation loss: 0.2687
2024-05-23 18:03:54 [INFO]: Epoch 016 - training loss: 0.5102, validation loss: 0.2622
2024-05-23 18:03:56 [INFO]: Epoch 017 - training loss: 0.5011, validation loss: 0.2555
2024-05-23 18:03:58 [INFO]: Epoch 018 - training loss: 0.4927, validation loss: 0.2501
2024-05-23 18:04:01 [INFO]: Epoch 019 - training loss: 0.4854, validation loss: 0.2449
2024-05-23 18:04:03 [INFO]: Epoch 020 - training loss: 0.4771, validation loss: 0.2400
2024-05-23 18:04:05 [INFO]: Epoch 021 - training loss: 0.4696, validation loss: 0.2349
2024-05-23 18:04:07 [INFO]: Epoch 022 - training loss: 0.4632, validation loss: 0.2308
2024-05-23 18:04:09 [INFO]: Epoch 023 - training loss: 0.4567, validation loss: 0.2266
2024-05-23 18:04:12 [INFO]: Epoch 024 - training loss: 0.4514, validation loss: 0.2230
2024-05-23 18:04:14 [INFO]: Epoch 025 - training loss: 0.4433, validation loss: 0.2188
2024-05-23 18:04:16 [INFO]: Epoch 026 - training loss: 0.4381, validation loss: 0.2156
2024-05-23 18:04:18 [INFO]: Epoch 027 - training loss: 0.4339, validation loss: 0.2121
2024-05-23 18:04:21 [INFO]: Epoch 028 - training loss: 0.4285, validation loss: 0.2089
2024-05-23 18:04:23 [INFO]: Epoch 029 - training loss: 0.4233, validation loss: 0.2061
2024-05-23 18:04:25 [INFO]: Epoch 030 - training loss: 0.4179, validation loss: 0.2025
2024-05-23 18:04:27 [INFO]: Epoch 031 - training loss: 0.4132, validation loss: 0.1996
2024-05-23 18:04:29 [INFO]: Epoch 032 - training loss: 0.4095, validation loss: 0.1967
2024-05-23 18:04:32 [INFO]: Epoch 033 - training loss: 0.4052, validation loss: 0.1940
2024-05-23 18:04:34 [INFO]: Epoch 034 - training loss: 0.4018, validation loss: 0.1916
2024-05-23 18:04:36 [INFO]: Epoch 035 - training loss: 0.3983, validation loss: 0.1886
2024-05-23 18:04:38 [INFO]: Epoch 036 - training loss: 0.3940, validation loss: 0.1860
2024-05-23 18:04:41 [INFO]: Epoch 037 - training loss: 0.3903, validation loss: 0.1837
2024-05-23 18:04:43 [INFO]: Epoch 038 - training loss: 0.3865, validation loss: 0.1812
2024-05-23 18:04:45 [INFO]: Epoch 039 - training loss: 0.3826, validation loss: 0.1787
2024-05-23 18:04:47 [INFO]: Epoch 040 - training loss: 0.3792, validation loss: 0.1765
2024-05-23 18:04:49 [INFO]: Epoch 041 - training loss: 0.3762, validation loss: 0.1743
2024-05-23 18:04:52 [INFO]: Epoch 042 - training loss: 0.3732, validation loss: 0.1724
2024-05-23 18:04:54 [INFO]: Epoch 043 - training loss: 0.3701, validation loss: 0.1705
2024-05-23 18:04:56 [INFO]: Epoch 044 - training loss: 0.3677, validation loss: 0.1682
2024-05-23 18:04:58 [INFO]: Epoch 045 - training loss: 0.3649, validation loss: 0.1665
2024-05-23 18:05:00 [INFO]: Epoch 046 - training loss: 0.3629, validation loss: 0.1647
2024-05-23 18:05:03 [INFO]: Epoch 047 - training loss: 0.3602, validation loss: 0.1628
2024-05-23 18:05:05 [INFO]: Epoch 048 - training loss: 0.3574, validation loss: 0.1612
2024-05-23 18:05:07 [INFO]: Epoch 049 - training loss: 0.3552, validation loss: 0.1598
2024-05-23 18:05:09 [INFO]: Epoch 050 - training loss: 0.3526, validation loss: 0.1582
2024-05-23 18:05:11 [INFO]: Epoch 051 - training loss: 0.3505, validation loss: 0.1570
2024-05-23 18:05:14 [INFO]: Epoch 052 - training loss: 0.3486, validation loss: 0.1553
2024-05-23 18:05:16 [INFO]: Epoch 053 - training loss: 0.3458, validation loss: 0.1542
2024-05-23 18:05:18 [INFO]: Epoch 054 - training loss: 0.3442, validation loss: 0.1528
2024-05-23 18:05:20 [INFO]: Epoch 055 - training loss: 0.3424, validation loss: 0.1518
2024-05-23 18:05:23 [INFO]: Epoch 056 - training loss: 0.3402, validation loss: 0.1504
2024-05-23 18:05:25 [INFO]: Epoch 057 - training loss: 0.3391, validation loss: 0.1494
2024-05-23 18:05:27 [INFO]: Epoch 058 - training loss: 0.3366, validation loss: 0.1485
2024-05-23 18:05:29 [INFO]: Epoch 059 - training loss: 0.3354, validation loss: 0.1474
2024-05-23 18:05:31 [INFO]: Epoch 060 - training loss: 0.3329, validation loss: 0.1467
2024-05-23 18:05:34 [INFO]: Epoch 061 - training loss: 0.3330, validation loss: 0.1458
2024-05-23 18:05:36 [INFO]: Epoch 062 - training loss: 0.3298, validation loss: 0.1449
2024-05-23 18:05:38 [INFO]: Epoch 063 - training loss: 0.3287, validation loss: 0.1440
2024-05-23 18:05:40 [INFO]: Epoch 064 - training loss: 0.3281, validation loss: 0.1432
2024-05-23 18:05:42 [INFO]: Epoch 065 - training loss: 0.3258, validation loss: 0.1424
2024-05-23 18:05:45 [INFO]: Epoch 066 - training loss: 0.3247, validation loss: 0.1419
2024-05-23 18:05:47 [INFO]: Epoch 067 - training loss: 0.3232, validation loss: 0.1410
2024-05-23 18:05:49 [INFO]: Epoch 068 - training loss: 0.3212, validation loss: 0.1404
2024-05-23 18:05:51 [INFO]: Epoch 069 - training loss: 0.3208, validation loss: 0.1397
2024-05-23 18:05:53 [INFO]: Epoch 070 - training loss: 0.3197, validation loss: 0.1392
2024-05-23 18:05:56 [INFO]: Epoch 071 - training loss: 0.3188, validation loss: 0.1385
2024-05-23 18:05:58 [INFO]: Epoch 072 - training loss: 0.3170, validation loss: 0.1379
2024-05-23 18:06:00 [INFO]: Epoch 073 - training loss: 0.3160, validation loss: 0.1374
2024-05-23 18:06:02 [INFO]: Epoch 074 - training loss: 0.3155, validation loss: 0.1368
2024-05-23 18:06:05 [INFO]: Epoch 075 - training loss: 0.3153, validation loss: 0.1364
2024-05-23 18:06:07 [INFO]: Epoch 076 - training loss: 0.3127, validation loss: 0.1360
2024-05-23 18:06:09 [INFO]: Epoch 077 - training loss: 0.3113, validation loss: 0.1352
2024-05-23 18:06:11 [INFO]: Epoch 078 - training loss: 0.3108, validation loss: 0.1349
2024-05-23 18:06:13 [INFO]: Epoch 079 - training loss: 0.3099, validation loss: 0.1344
2024-05-23 18:06:16 [INFO]: Epoch 080 - training loss: 0.3086, validation loss: 0.1339
2024-05-23 18:06:18 [INFO]: Epoch 081 - training loss: 0.3076, validation loss: 0.1333
2024-05-23 18:06:20 [INFO]: Epoch 082 - training loss: 0.3070, validation loss: 0.1330
2024-05-23 18:06:22 [INFO]: Epoch 083 - training loss: 0.3065, validation loss: 0.1325
2024-05-23 18:06:24 [INFO]: Epoch 084 - training loss: 0.3057, validation loss: 0.1321
2024-05-23 18:06:27 [INFO]: Epoch 085 - training loss: 0.3047, validation loss: 0.1318
2024-05-23 18:06:29 [INFO]: Epoch 086 - training loss: 0.3039, validation loss: 0.1312
2024-05-23 18:06:31 [INFO]: Epoch 087 - training loss: 0.3034, validation loss: 0.1310
2024-05-23 18:06:33 [INFO]: Epoch 088 - training loss: 0.3016, validation loss: 0.1305
2024-05-23 18:06:36 [INFO]: Epoch 089 - training loss: 0.3012, validation loss: 0.1301
2024-05-23 18:06:38 [INFO]: Epoch 090 - training loss: 0.3014, validation loss: 0.1298
2024-05-23 18:06:40 [INFO]: Epoch 091 - training loss: 0.2996, validation loss: 0.1294
2024-05-23 18:06:42 [INFO]: Epoch 092 - training loss: 0.2983, validation loss: 0.1288
2024-05-23 18:06:44 [INFO]: Epoch 093 - training loss: 0.2978, validation loss: 0.1287
2024-05-23 18:06:47 [INFO]: Epoch 094 - training loss: 0.2972, validation loss: 0.1283
2024-05-23 18:06:49 [INFO]: Epoch 095 - training loss: 0.2967, validation loss: 0.1279
2024-05-23 18:06:51 [INFO]: Epoch 096 - training loss: 0.2958, validation loss: 0.1274
2024-05-23 18:06:53 [INFO]: Epoch 097 - training loss: 0.2956, validation loss: 0.1271
2024-05-23 18:06:55 [INFO]: Epoch 098 - training loss: 0.2950, validation loss: 0.1268
2024-05-23 18:06:58 [INFO]: Epoch 099 - training loss: 0.2950, validation loss: 0.1265
2024-05-23 18:07:00 [INFO]: Epoch 100 - training loss: 0.2936, validation loss: 0.1261
2024-05-23 18:07:02 [INFO]: Epoch 101 - training loss: 0.2925, validation loss: 0.1257
2024-05-23 18:07:04 [INFO]: Epoch 102 - training loss: 0.2919, validation loss: 0.1255
2024-05-23 18:07:06 [INFO]: Epoch 103 - training loss: 0.2916, validation loss: 0.1250
2024-05-23 18:07:09 [INFO]: Epoch 104 - training loss: 0.2907, validation loss: 0.1249
2024-05-23 18:07:11 [INFO]: Epoch 105 - training loss: 0.2905, validation loss: 0.1245
2024-05-23 18:07:13 [INFO]: Epoch 106 - training loss: 0.2901, validation loss: 0.1241
2024-05-23 18:07:15 [INFO]: Epoch 107 - training loss: 0.2890, validation loss: 0.1239
2024-05-23 18:07:17 [INFO]: Epoch 108 - training loss: 0.2888, validation loss: 0.1236
2024-05-23 18:07:20 [INFO]: Epoch 109 - training loss: 0.2883, validation loss: 0.1232
2024-05-23 18:07:22 [INFO]: Epoch 110 - training loss: 0.2874, validation loss: 0.1229
2024-05-23 18:07:24 [INFO]: Epoch 111 - training loss: 0.2870, validation loss: 0.1225
2024-05-23 18:07:26 [INFO]: Epoch 112 - training loss: 0.2862, validation loss: 0.1224
2024-05-23 18:07:28 [INFO]: Epoch 113 - training loss: 0.2856, validation loss: 0.1220
2024-05-23 18:07:31 [INFO]: Epoch 114 - training loss: 0.2848, validation loss: 0.1217
2024-05-23 18:07:33 [INFO]: Epoch 115 - training loss: 0.2847, validation loss: 0.1212
2024-05-23 18:07:35 [INFO]: Epoch 116 - training loss: 0.2855, validation loss: 0.1209
2024-05-23 18:07:37 [INFO]: Epoch 117 - training loss: 0.2841, validation loss: 0.1208
2024-05-23 18:07:40 [INFO]: Epoch 118 - training loss: 0.2834, validation loss: 0.1205
2024-05-23 18:07:42 [INFO]: Epoch 119 - training loss: 0.2828, validation loss: 0.1202
2024-05-23 18:07:44 [INFO]: Epoch 120 - training loss: 0.2821, validation loss: 0.1199
2024-05-23 18:07:46 [INFO]: Epoch 121 - training loss: 0.2816, validation loss: 0.1195
2024-05-23 18:07:48 [INFO]: Epoch 122 - training loss: 0.2819, validation loss: 0.1192
2024-05-23 18:07:51 [INFO]: Epoch 123 - training loss: 0.2817, validation loss: 0.1189
2024-05-23 18:07:53 [INFO]: Epoch 124 - training loss: 0.2805, validation loss: 0.1186
2024-05-23 18:07:55 [INFO]: Epoch 125 - training loss: 0.2800, validation loss: 0.1184
2024-05-23 18:07:57 [INFO]: Epoch 126 - training loss: 0.2796, validation loss: 0.1180
2024-05-23 18:08:00 [INFO]: Epoch 127 - training loss: 0.2791, validation loss: 0.1177
2024-05-23 18:08:02 [INFO]: Epoch 128 - training loss: 0.2786, validation loss: 0.1174
2024-05-23 18:08:04 [INFO]: Epoch 129 - training loss: 0.2779, validation loss: 0.1171
2024-05-23 18:08:06 [INFO]: Epoch 130 - training loss: 0.2781, validation loss: 0.1169
2024-05-23 18:08:08 [INFO]: Epoch 131 - training loss: 0.2775, validation loss: 0.1166
2024-05-23 18:08:11 [INFO]: Epoch 132 - training loss: 0.2772, validation loss: 0.1163
2024-05-23 18:08:13 [INFO]: Epoch 133 - training loss: 0.2763, validation loss: 0.1159
2024-05-23 18:08:15 [INFO]: Epoch 134 - training loss: 0.2762, validation loss: 0.1158
2024-05-23 18:08:17 [INFO]: Epoch 135 - training loss: 0.2755, validation loss: 0.1156
2024-05-23 18:08:19 [INFO]: Epoch 136 - training loss: 0.2749, validation loss: 0.1152
2024-05-23 18:08:22 [INFO]: Epoch 137 - training loss: 0.2748, validation loss: 0.1149
2024-05-23 18:08:24 [INFO]: Epoch 138 - training loss: 0.2745, validation loss: 0.1147
2024-05-23 18:08:26 [INFO]: Epoch 139 - training loss: 0.2742, validation loss: 0.1144
2024-05-23 18:08:28 [INFO]: Epoch 140 - training loss: 0.2740, validation loss: 0.1143
2024-05-23 18:08:30 [INFO]: Epoch 141 - training loss: 0.2736, validation loss: 0.1139
2024-05-23 18:08:33 [INFO]: Epoch 142 - training loss: 0.2735, validation loss: 0.1135
2024-05-23 18:08:35 [INFO]: Epoch 143 - training loss: 0.2725, validation loss: 0.1133
2024-05-23 18:08:37 [INFO]: Epoch 144 - training loss: 0.2722, validation loss: 0.1132
2024-05-23 18:08:39 [INFO]: Epoch 145 - training loss: 0.2717, validation loss: 0.1129
2024-05-23 18:08:41 [INFO]: Epoch 146 - training loss: 0.2715, validation loss: 0.1128
2024-05-23 18:08:44 [INFO]: Epoch 147 - training loss: 0.2708, validation loss: 0.1126
2024-05-23 18:08:46 [INFO]: Epoch 148 - training loss: 0.2707, validation loss: 0.1122
2024-05-23 18:08:48 [INFO]: Epoch 149 - training loss: 0.2702, validation loss: 0.1121
2024-05-23 18:08:50 [INFO]: Epoch 150 - training loss: 0.2701, validation loss: 0.1116
2024-05-23 18:08:52 [INFO]: Epoch 151 - training loss: 0.2697, validation loss: 0.1114
2024-05-23 18:08:55 [INFO]: Epoch 152 - training loss: 0.2694, validation loss: 0.1113
2024-05-23 18:08:57 [INFO]: Epoch 153 - training loss: 0.2688, validation loss: 0.1110
2024-05-23 18:08:59 [INFO]: Epoch 154 - training loss: 0.2690, validation loss: 0.1108
2024-05-23 18:09:01 [INFO]: Epoch 155 - training loss: 0.2683, validation loss: 0.1106
2024-05-23 18:09:04 [INFO]: Epoch 156 - training loss: 0.2683, validation loss: 0.1103
2024-05-23 18:09:06 [INFO]: Epoch 157 - training loss: 0.2678, validation loss: 0.1101
2024-05-23 18:09:08 [INFO]: Epoch 158 - training loss: 0.2673, validation loss: 0.1098
2024-05-23 18:09:10 [INFO]: Epoch 159 - training loss: 0.2671, validation loss: 0.1095
2024-05-23 18:09:12 [INFO]: Epoch 160 - training loss: 0.2664, validation loss: 0.1095
2024-05-23 18:09:15 [INFO]: Epoch 161 - training loss: 0.2670, validation loss: 0.1092
2024-05-23 18:09:17 [INFO]: Epoch 162 - training loss: 0.2661, validation loss: 0.1090
2024-05-23 18:09:19 [INFO]: Epoch 163 - training loss: 0.2662, validation loss: 0.1088
2024-05-23 18:09:21 [INFO]: Epoch 164 - training loss: 0.2660, validation loss: 0.1087
2024-05-23 18:09:24 [INFO]: Epoch 165 - training loss: 0.2656, validation loss: 0.1087
2024-05-23 18:09:26 [INFO]: Epoch 166 - training loss: 0.2657, validation loss: 0.1081
2024-05-23 18:09:28 [INFO]: Epoch 167 - training loss: 0.2654, validation loss: 0.1080
2024-05-23 18:09:30 [INFO]: Epoch 168 - training loss: 0.2645, validation loss: 0.1078
2024-05-23 18:09:32 [INFO]: Epoch 169 - training loss: 0.2645, validation loss: 0.1076
2024-05-23 18:09:35 [INFO]: Epoch 170 - training loss: 0.2640, validation loss: 0.1075
2024-05-23 18:09:37 [INFO]: Epoch 171 - training loss: 0.2641, validation loss: 0.1073
2024-05-23 18:09:39 [INFO]: Epoch 172 - training loss: 0.2635, validation loss: 0.1070
2024-05-23 18:09:41 [INFO]: Epoch 173 - training loss: 0.2635, validation loss: 0.1068
2024-05-23 18:09:43 [INFO]: Epoch 174 - training loss: 0.2627, validation loss: 0.1068
2024-05-23 18:09:46 [INFO]: Epoch 175 - training loss: 0.2626, validation loss: 0.1065
2024-05-23 18:09:48 [INFO]: Epoch 176 - training loss: 0.2618, validation loss: 0.1063
2024-05-23 18:09:50 [INFO]: Epoch 177 - training loss: 0.2622, validation loss: 0.1061
2024-05-23 18:09:52 [INFO]: Epoch 178 - training loss: 0.2618, validation loss: 0.1059
2024-05-23 18:09:54 [INFO]: Epoch 179 - training loss: 0.2615, validation loss: 0.1058
2024-05-23 18:09:57 [INFO]: Epoch 180 - training loss: 0.2612, validation loss: 0.1055
2024-05-23 18:09:59 [INFO]: Epoch 181 - training loss: 0.2614, validation loss: 0.1054
2024-05-23 18:10:01 [INFO]: Epoch 182 - training loss: 0.2607, validation loss: 0.1052
2024-05-23 18:10:03 [INFO]: Epoch 183 - training loss: 0.2607, validation loss: 0.1051
2024-05-23 18:10:05 [INFO]: Epoch 184 - training loss: 0.2604, validation loss: 0.1051
2024-05-23 18:10:08 [INFO]: Epoch 185 - training loss: 0.2600, validation loss: 0.1048
2024-05-23 18:10:10 [INFO]: Epoch 186 - training loss: 0.2594, validation loss: 0.1047
2024-05-23 18:10:12 [INFO]: Epoch 187 - training loss: 0.2594, validation loss: 0.1043
2024-05-23 18:10:14 [INFO]: Epoch 188 - training loss: 0.2590, validation loss: 0.1042
2024-05-23 18:10:16 [INFO]: Epoch 189 - training loss: 0.2590, validation loss: 0.1039
2024-05-23 18:10:19 [INFO]: Epoch 190 - training loss: 0.2591, validation loss: 0.1038
2024-05-23 18:10:21 [INFO]: Epoch 191 - training loss: 0.2587, validation loss: 0.1037
2024-05-23 18:10:23 [INFO]: Epoch 192 - training loss: 0.2583, validation loss: 0.1036
2024-05-23 18:10:25 [INFO]: Epoch 193 - training loss: 0.2582, validation loss: 0.1033
2024-05-23 18:10:28 [INFO]: Epoch 194 - training loss: 0.2579, validation loss: 0.1033
2024-05-23 18:10:30 [INFO]: Epoch 195 - training loss: 0.2577, validation loss: 0.1032
2024-05-23 18:10:32 [INFO]: Epoch 196 - training loss: 0.2581, validation loss: 0.1032
2024-05-23 18:10:34 [INFO]: Epoch 197 - training loss: 0.2573, validation loss: 0.1029
2024-05-23 18:10:36 [INFO]: Epoch 198 - training loss: 0.2569, validation loss: 0.1025
2024-05-23 18:10:39 [INFO]: Epoch 199 - training loss: 0.2570, validation loss: 0.1028
2024-05-23 18:10:41 [INFO]: Epoch 200 - training loss: 0.2564, validation loss: 0.1026
2024-05-23 18:10:43 [INFO]: Epoch 201 - training loss: 0.2565, validation loss: 0.1023
2024-05-23 18:10:45 [INFO]: Epoch 202 - training loss: 0.2568, validation loss: 0.1024
2024-05-23 18:10:48 [INFO]: Epoch 203 - training loss: 0.2562, validation loss: 0.1021
2024-05-23 18:10:50 [INFO]: Epoch 204 - training loss: 0.2560, validation loss: 0.1020
2024-05-23 18:10:52 [INFO]: Epoch 205 - training loss: 0.2554, validation loss: 0.1018
2024-05-23 18:10:54 [INFO]: Epoch 206 - training loss: 0.2557, validation loss: 0.1017
2024-05-23 18:10:57 [INFO]: Epoch 207 - training loss: 0.2553, validation loss: 0.1015
2024-05-23 18:10:59 [INFO]: Epoch 208 - training loss: 0.2549, validation loss: 0.1013
2024-05-23 18:11:01 [INFO]: Epoch 209 - training loss: 0.2543, validation loss: 0.1013
2024-05-23 18:11:03 [INFO]: Epoch 210 - training loss: 0.2542, validation loss: 0.1012
2024-05-23 18:11:05 [INFO]: Epoch 211 - training loss: 0.2545, validation loss: 0.1011
2024-05-23 18:11:08 [INFO]: Epoch 212 - training loss: 0.2540, validation loss: 0.1011
2024-05-23 18:11:10 [INFO]: Epoch 213 - training loss: 0.2538, validation loss: 0.1008
2024-05-23 18:11:12 [INFO]: Epoch 214 - training loss: 0.2534, validation loss: 0.1008
2024-05-23 18:11:14 [INFO]: Epoch 215 - training loss: 0.2536, validation loss: 0.1006
2024-05-23 18:11:16 [INFO]: Epoch 216 - training loss: 0.2534, validation loss: 0.1006
2024-05-23 18:11:19 [INFO]: Epoch 217 - training loss: 0.2530, validation loss: 0.1006
2024-05-23 18:11:21 [INFO]: Epoch 218 - training loss: 0.2526, validation loss: 0.1005
2024-05-23 18:11:23 [INFO]: Epoch 219 - training loss: 0.2526, validation loss: 0.1003
2024-05-23 18:11:25 [INFO]: Epoch 220 - training loss: 0.2525, validation loss: 0.1002
2024-05-23 18:11:28 [INFO]: Epoch 221 - training loss: 0.2520, validation loss: 0.1001
2024-05-23 18:11:30 [INFO]: Epoch 222 - training loss: 0.2525, validation loss: 0.1001
2024-05-23 18:11:32 [INFO]: Epoch 223 - training loss: 0.2517, validation loss: 0.0999
2024-05-23 18:11:34 [INFO]: Epoch 224 - training loss: 0.2517, validation loss: 0.0997
2024-05-23 18:11:36 [INFO]: Epoch 225 - training loss: 0.2514, validation loss: 0.0997
2024-05-23 18:11:39 [INFO]: Epoch 226 - training loss: 0.2516, validation loss: 0.0997
2024-05-23 18:11:41 [INFO]: Epoch 227 - training loss: 0.2514, validation loss: 0.0995
2024-05-23 18:11:43 [INFO]: Epoch 228 - training loss: 0.2509, validation loss: 0.0992
2024-05-23 18:11:45 [INFO]: Epoch 229 - training loss: 0.2512, validation loss: 0.0992
2024-05-23 18:11:48 [INFO]: Epoch 230 - training loss: 0.2508, validation loss: 0.0993
2024-05-23 18:11:50 [INFO]: Epoch 231 - training loss: 0.2503, validation loss: 0.0991
2024-05-23 18:11:52 [INFO]: Epoch 232 - training loss: 0.2506, validation loss: 0.0990
2024-05-23 18:11:54 [INFO]: Epoch 233 - training loss: 0.2504, validation loss: 0.0988
2024-05-23 18:11:56 [INFO]: Epoch 234 - training loss: 0.2500, validation loss: 0.0988
2024-05-23 18:11:59 [INFO]: Epoch 235 - training loss: 0.2501, validation loss: 0.0988
2024-05-23 18:12:01 [INFO]: Epoch 236 - training loss: 0.2494, validation loss: 0.0988
2024-05-23 18:12:03 [INFO]: Epoch 237 - training loss: 0.2501, validation loss: 0.0986
2024-05-23 18:12:05 [INFO]: Epoch 238 - training loss: 0.2494, validation loss: 0.0986
2024-05-23 18:12:07 [INFO]: Epoch 239 - training loss: 0.2492, validation loss: 0.0987
2024-05-23 18:12:10 [INFO]: Epoch 240 - training loss: 0.2491, validation loss: 0.0985
2024-05-23 18:12:12 [INFO]: Epoch 241 - training loss: 0.2491, validation loss: 0.0983
2024-05-23 18:12:14 [INFO]: Epoch 242 - training loss: 0.2487, validation loss: 0.0983
2024-05-23 18:12:16 [INFO]: Epoch 243 - training loss: 0.2489, validation loss: 0.0981
2024-05-23 18:12:19 [INFO]: Epoch 244 - training loss: 0.2479, validation loss: 0.0981
2024-05-23 18:12:21 [INFO]: Epoch 245 - training loss: 0.2480, validation loss: 0.0980
2024-05-23 18:12:23 [INFO]: Epoch 246 - training loss: 0.2479, validation loss: 0.0981
2024-05-23 18:12:25 [INFO]: Epoch 247 - training loss: 0.2480, validation loss: 0.0980
2024-05-23 18:12:27 [INFO]: Epoch 248 - training loss: 0.2489, validation loss: 0.0978
2024-05-23 18:12:30 [INFO]: Epoch 249 - training loss: 0.2476, validation loss: 0.0979
2024-05-23 18:12:32 [INFO]: Epoch 250 - training loss: 0.2468, validation loss: 0.0976
2024-05-23 18:12:34 [INFO]: Epoch 251 - training loss: 0.2470, validation loss: 0.0977
2024-05-23 18:12:36 [INFO]: Epoch 252 - training loss: 0.2471, validation loss: 0.0977
2024-05-23 18:12:39 [INFO]: Epoch 253 - training loss: 0.2472, validation loss: 0.0975
2024-05-23 18:12:41 [INFO]: Epoch 254 - training loss: 0.2465, validation loss: 0.0974
2024-05-23 18:12:43 [INFO]: Epoch 255 - training loss: 0.2469, validation loss: 0.0973
2024-05-23 18:12:45 [INFO]: Epoch 256 - training loss: 0.2465, validation loss: 0.0974
2024-05-23 18:12:47 [INFO]: Epoch 257 - training loss: 0.2463, validation loss: 0.0975
2024-05-23 18:12:50 [INFO]: Epoch 258 - training loss: 0.2466, validation loss: 0.0972
2024-05-23 18:12:52 [INFO]: Epoch 259 - training loss: 0.2465, validation loss: 0.0972
2024-05-23 18:12:54 [INFO]: Epoch 260 - training loss: 0.2455, validation loss: 0.0971
2024-05-23 18:12:56 [INFO]: Epoch 261 - training loss: 0.2457, validation loss: 0.0971
2024-05-23 18:12:59 [INFO]: Epoch 262 - training loss: 0.2463, validation loss: 0.0971
2024-05-23 18:13:01 [INFO]: Epoch 263 - training loss: 0.2451, validation loss: 0.0972
2024-05-23 18:13:03 [INFO]: Epoch 264 - training loss: 0.2451, validation loss: 0.0969
2024-05-23 18:13:05 [INFO]: Epoch 265 - training loss: 0.2454, validation loss: 0.0968
2024-05-23 18:13:07 [INFO]: Epoch 266 - training loss: 0.2446, validation loss: 0.0970
2024-05-23 18:13:10 [INFO]: Epoch 267 - training loss: 0.2447, validation loss: 0.0966
2024-05-23 18:13:12 [INFO]: Epoch 268 - training loss: 0.2444, validation loss: 0.0967
2024-05-23 18:13:14 [INFO]: Epoch 269 - training loss: 0.2444, validation loss: 0.0965
2024-05-23 18:13:16 [INFO]: Epoch 270 - training loss: 0.2442, validation loss: 0.0967
2024-05-23 18:13:18 [INFO]: Epoch 271 - training loss: 0.2439, validation loss: 0.0965
2024-05-23 18:13:21 [INFO]: Epoch 272 - training loss: 0.2440, validation loss: 0.0966
2024-05-23 18:13:23 [INFO]: Epoch 273 - training loss: 0.2440, validation loss: 0.0965
2024-05-23 18:13:25 [INFO]: Epoch 274 - training loss: 0.2440, validation loss: 0.0964
2024-05-23 18:13:27 [INFO]: Epoch 275 - training loss: 0.2439, validation loss: 0.0965
2024-05-23 18:13:29 [INFO]: Epoch 276 - training loss: 0.2436, validation loss: 0.0964
2024-05-23 18:13:32 [INFO]: Epoch 277 - training loss: 0.2430, validation loss: 0.0964
2024-05-23 18:13:34 [INFO]: Epoch 278 - training loss: 0.2438, validation loss: 0.0962
2024-05-23 18:13:36 [INFO]: Epoch 279 - training loss: 0.2431, validation loss: 0.0962
2024-05-23 18:13:38 [INFO]: Epoch 280 - training loss: 0.2436, validation loss: 0.0961
2024-05-23 18:13:41 [INFO]: Epoch 281 - training loss: 0.2435, validation loss: 0.0959
2024-05-23 18:13:43 [INFO]: Epoch 282 - training loss: 0.2426, validation loss: 0.0961
2024-05-23 18:13:45 [INFO]: Epoch 283 - training loss: 0.2422, validation loss: 0.0960
2024-05-23 18:13:47 [INFO]: Epoch 284 - training loss: 0.2430, validation loss: 0.0960
2024-05-23 18:13:49 [INFO]: Epoch 285 - training loss: 0.2428, validation loss: 0.0959
2024-05-23 18:13:52 [INFO]: Epoch 286 - training loss: 0.2421, validation loss: 0.0961
2024-05-23 18:13:54 [INFO]: Epoch 287 - training loss: 0.2425, validation loss: 0.0957
2024-05-23 18:13:56 [INFO]: Epoch 288 - training loss: 0.2422, validation loss: 0.0959
2024-05-23 18:13:58 [INFO]: Epoch 289 - training loss: 0.2425, validation loss: 0.0958
2024-05-23 18:14:00 [INFO]: Epoch 290 - training loss: 0.2421, validation loss: 0.0958
2024-05-23 18:14:03 [INFO]: Epoch 291 - training loss: 0.2420, validation loss: 0.0957
2024-05-23 18:14:05 [INFO]: Epoch 292 - training loss: 0.2418, validation loss: 0.0956
2024-05-23 18:14:07 [INFO]: Epoch 293 - training loss: 0.2414, validation loss: 0.0958
2024-05-23 18:14:10 [INFO]: Epoch 294 - training loss: 0.2418, validation loss: 0.0958
2024-05-23 18:14:12 [INFO]: Epoch 295 - training loss: 0.2416, validation loss: 0.0957
2024-05-23 18:14:14 [INFO]: Epoch 296 - training loss: 0.2413, validation loss: 0.0958
2024-05-23 18:14:16 [INFO]: Epoch 297 - training loss: 0.2412, validation loss: 0.0956
2024-05-23 18:14:19 [INFO]: Epoch 298 - training loss: 0.2411, validation loss: 0.0955
2024-05-23 18:14:21 [INFO]: Epoch 299 - training loss: 0.2408, validation loss: 0.0955
2024-05-23 18:14:23 [INFO]: Epoch 300 - training loss: 0.2405, validation loss: 0.0952
2024-05-23 18:14:23 [INFO]: Finished training. The best model is from epoch#300.
2024-05-23 18:14:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/BRITS_air_quality/20240523_T180318/BRITS.pypots
2024-05-23 18:14:24 [INFO]: BRITS on Air-Quality: MAE=0.1436, MSE=0.1634
2024-05-23 18:14:24 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-23 18:14:24 [INFO]: Using the given device: cuda:0
2024-05-23 18:14:24 [INFO]: Model files will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424
2024-05-23 18:14:24 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/tensorboard
2024-05-23 18:14:24 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 18:14:28 [INFO]: Epoch 001 - training loss: 1.4085, validation loss: 0.7854
2024-05-23 18:14:28 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch1_loss0.7854073226451874.pypots
2024-05-23 18:14:31 [INFO]: Epoch 002 - training loss: 1.0305, validation loss: 0.7222
2024-05-23 18:14:31 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch2_loss0.7221502631902694.pypots
2024-05-23 18:14:34 [INFO]: Epoch 003 - training loss: 0.9551, validation loss: 0.7003
2024-05-23 18:14:34 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch3_loss0.7002660542726517.pypots
2024-05-23 18:14:37 [INFO]: Epoch 004 - training loss: 0.9345, validation loss: 0.6872
2024-05-23 18:14:37 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch4_loss0.68715860247612.pypots
2024-05-23 18:14:40 [INFO]: Epoch 005 - training loss: 0.9205, validation loss: 0.6773
2024-05-23 18:14:40 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch5_loss0.6772872060537338.pypots
2024-05-23 18:14:43 [INFO]: Epoch 006 - training loss: 0.9193, validation loss: 0.6699
2024-05-23 18:14:43 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch6_loss0.6698992371559143.pypots
2024-05-23 18:14:46 [INFO]: Epoch 007 - training loss: 0.9101, validation loss: 0.6640
2024-05-23 18:14:46 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch7_loss0.6640428066253662.pypots
2024-05-23 18:14:49 [INFO]: Epoch 008 - training loss: 0.8970, validation loss: 0.6612
2024-05-23 18:14:49 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch8_loss0.661203783750534.pypots
2024-05-23 18:14:53 [INFO]: Epoch 009 - training loss: 0.8918, validation loss: 0.6565
2024-05-23 18:14:53 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch9_loss0.6565057128667832.pypots
2024-05-23 18:14:56 [INFO]: Epoch 010 - training loss: 0.8867, validation loss: 0.6535
2024-05-23 18:14:56 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch10_loss0.6534684807062149.pypots
2024-05-23 18:14:59 [INFO]: Epoch 011 - training loss: 0.8752, validation loss: 0.6528
2024-05-23 18:14:59 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch11_loss0.6528248816728592.pypots
2024-05-23 18:15:02 [INFO]: Epoch 012 - training loss: 0.8683, validation loss: 0.6499
2024-05-23 18:15:02 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch12_loss0.6499373435974121.pypots
2024-05-23 18:15:05 [INFO]: Epoch 013 - training loss: 0.8789, validation loss: 0.6490
2024-05-23 18:15:05 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch13_loss0.6489595979452133.pypots
2024-05-23 18:15:08 [INFO]: Epoch 014 - training loss: 0.8597, validation loss: 0.6477
2024-05-23 18:15:08 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch14_loss0.6476583361625672.pypots
2024-05-23 18:15:11 [INFO]: Epoch 015 - training loss: 0.8625, validation loss: 0.6469
2024-05-23 18:15:11 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch15_loss0.6469430387020111.pypots
2024-05-23 18:15:14 [INFO]: Epoch 016 - training loss: 0.8668, validation loss: 0.6480
2024-05-23 18:15:14 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch16_loss0.6479532092809677.pypots
2024-05-23 18:15:17 [INFO]: Epoch 017 - training loss: 0.8527, validation loss: 0.6456
2024-05-23 18:15:17 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch17_loss0.6456238001585006.pypots
2024-05-23 18:15:20 [INFO]: Epoch 018 - training loss: 0.8545, validation loss: 0.6452
2024-05-23 18:15:20 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch18_loss0.6451750665903091.pypots
2024-05-23 18:15:23 [INFO]: Epoch 019 - training loss: 0.8509, validation loss: 0.6457
2024-05-23 18:15:23 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch19_loss0.6457192450761795.pypots
2024-05-23 18:15:27 [INFO]: Epoch 020 - training loss: 0.8411, validation loss: 0.6444
2024-05-23 18:15:27 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch20_loss0.6444079399108886.pypots
2024-05-23 18:15:30 [INFO]: Epoch 021 - training loss: 0.8508, validation loss: 0.6438
2024-05-23 18:15:30 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch21_loss0.64376959502697.pypots
2024-05-23 18:15:33 [INFO]: Epoch 022 - training loss: 0.8407, validation loss: 0.6442
2024-05-23 18:15:33 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch22_loss0.644161731004715.pypots
2024-05-23 18:15:36 [INFO]: Epoch 023 - training loss: 0.8820, validation loss: 0.6435
2024-05-23 18:15:36 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch23_loss0.6435054004192352.pypots
2024-05-23 18:15:39 [INFO]: Epoch 024 - training loss: 0.8367, validation loss: 0.6430
2024-05-23 18:15:39 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch24_loss0.6430495083332062.pypots
2024-05-23 18:15:42 [INFO]: Epoch 025 - training loss: 0.8449, validation loss: 0.6445
2024-05-23 18:15:42 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch25_loss0.6444885432720184.pypots
2024-05-23 18:15:45 [INFO]: Epoch 026 - training loss: 0.8371, validation loss: 0.6424
2024-05-23 18:15:45 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch26_loss0.6424193322658539.pypots
2024-05-23 18:15:48 [INFO]: Epoch 027 - training loss: 0.8565, validation loss: 0.6430
2024-05-23 18:15:48 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch27_loss0.6430107533931733.pypots
2024-05-23 18:15:51 [INFO]: Epoch 028 - training loss: 0.8519, validation loss: 0.6414
2024-05-23 18:15:51 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch28_loss0.6413945555686951.pypots
2024-05-23 18:15:54 [INFO]: Epoch 029 - training loss: 0.8382, validation loss: 0.6428
2024-05-23 18:15:54 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch29_loss0.6428392380475998.pypots
2024-05-23 18:15:57 [INFO]: Epoch 030 - training loss: 0.8246, validation loss: 0.6424
2024-05-23 18:15:57 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch30_loss0.6424107760190964.pypots
2024-05-23 18:16:00 [INFO]: Epoch 031 - training loss: 0.8312, validation loss: 0.6428
2024-05-23 18:16:00 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch31_loss0.6427895903587342.pypots
2024-05-23 18:16:03 [INFO]: Epoch 032 - training loss: 0.8183, validation loss: 0.6428
2024-05-23 18:16:03 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch32_loss0.6428316771984101.pypots
2024-05-23 18:16:07 [INFO]: Epoch 033 - training loss: 0.8204, validation loss: 0.6445
2024-05-23 18:16:07 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch33_loss0.6444505304098129.pypots
2024-05-23 18:16:10 [INFO]: Epoch 034 - training loss: 0.8257, validation loss: 0.6446
2024-05-23 18:16:10 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch34_loss0.6445881366729737.pypots
2024-05-23 18:16:13 [INFO]: Epoch 035 - training loss: 0.8211, validation loss: 0.6440
2024-05-23 18:16:13 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch35_loss0.6439847201108932.pypots
2024-05-23 18:16:16 [INFO]: Epoch 036 - training loss: 0.8105, validation loss: 0.6446
2024-05-23 18:16:16 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch36_loss0.6445658385753632.pypots
2024-05-23 18:16:19 [INFO]: Epoch 037 - training loss: 0.8255, validation loss: 0.6442
2024-05-23 18:16:19 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch37_loss0.6441526889801026.pypots
2024-05-23 18:16:22 [INFO]: Epoch 038 - training loss: 0.8365, validation loss: 0.6451
2024-05-23 18:16:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN_epoch38_loss0.6451027393341064.pypots
2024-05-23 18:16:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:16:22 [INFO]: Finished training. The best model is from epoch#28.
2024-05-23 18:16:22 [INFO]: Saved the model to overlay_premask_saved_results/round_0/MRNN_air_quality/20240523_T181424/MRNN.pypots
2024-05-23 18:16:23 [INFO]: MRNN on Air-Quality: MAE=0.5224, MSE=0.6929
2024-05-23 18:16:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-23 18:16:23 [INFO]: Using the given device: cpu
2024-05-23 18:16:23 [INFO]: LOCF on Air-Quality: MAE=0.2090, MSE=0.3758
2024-05-23 18:16:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-23 18:16:23 [INFO]: Median on Air-Quality: MAE=0.6658, MSE=1.0901
2024-05-23 18:16:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-23 18:16:23 [INFO]: Mean on Air-Quality: MAE=0.6970, MSE=1.0309
2024-05-23 18:16:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-23 18:16:23 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-23 18:16:23 [INFO]: Using the given device: cuda:0
2024-05-23 18:16:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240523_T181623
2024-05-23 18:16:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/SAITS_air_quality/20240523_T181623/tensorboard
2024-05-23 18:16:23 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 18:16:24 [INFO]: Epoch 001 - training loss: 1.0375, validation loss: 0.4779
2024-05-23 18:16:24 [INFO]: Epoch 002 - training loss: 0.7375, validation loss: 0.3643
2024-05-23 18:16:25 [INFO]: Epoch 003 - training loss: 0.6291, validation loss: 0.2927
2024-05-23 18:16:26 [INFO]: Epoch 004 - training loss: 0.5567, validation loss: 0.2550
2024-05-23 18:16:26 [INFO]: Epoch 005 - training loss: 0.5062, validation loss: 0.2311
2024-05-23 18:16:27 [INFO]: Epoch 006 - training loss: 0.4722, validation loss: 0.2153
2024-05-23 18:16:27 [INFO]: Epoch 007 - training loss: 0.4483, validation loss: 0.2061
2024-05-23 18:16:28 [INFO]: Epoch 008 - training loss: 0.4307, validation loss: 0.2003
2024-05-23 18:16:29 [INFO]: Epoch 009 - training loss: 0.4166, validation loss: 0.1944
2024-05-23 18:16:29 [INFO]: Epoch 010 - training loss: 0.4045, validation loss: 0.1884
2024-05-23 18:16:30 [INFO]: Epoch 011 - training loss: 0.3939, validation loss: 0.1837
2024-05-23 18:16:30 [INFO]: Epoch 012 - training loss: 0.3854, validation loss: 0.1792
2024-05-23 18:16:31 [INFO]: Epoch 013 - training loss: 0.3774, validation loss: 0.1787
2024-05-23 18:16:32 [INFO]: Epoch 014 - training loss: 0.3714, validation loss: 0.1734
2024-05-23 18:16:32 [INFO]: Epoch 015 - training loss: 0.3645, validation loss: 0.1716
2024-05-23 18:16:33 [INFO]: Epoch 016 - training loss: 0.3596, validation loss: 0.1684
2024-05-23 18:16:33 [INFO]: Epoch 017 - training loss: 0.3534, validation loss: 0.1655
2024-05-23 18:16:34 [INFO]: Epoch 018 - training loss: 0.3487, validation loss: 0.1620
2024-05-23 18:16:34 [INFO]: Epoch 019 - training loss: 0.3448, validation loss: 0.1611
2024-05-23 18:16:35 [INFO]: Epoch 020 - training loss: 0.3408, validation loss: 0.1578
2024-05-23 18:16:36 [INFO]: Epoch 021 - training loss: 0.3367, validation loss: 0.1563
2024-05-23 18:16:36 [INFO]: Epoch 022 - training loss: 0.3344, validation loss: 0.1550
2024-05-23 18:16:37 [INFO]: Epoch 023 - training loss: 0.3290, validation loss: 0.1520
2024-05-23 18:16:37 [INFO]: Epoch 024 - training loss: 0.3254, validation loss: 0.1513
2024-05-23 18:16:38 [INFO]: Epoch 025 - training loss: 0.3219, validation loss: 0.1489
2024-05-23 18:16:39 [INFO]: Epoch 026 - training loss: 0.3202, validation loss: 0.1476
2024-05-23 18:16:39 [INFO]: Epoch 027 - training loss: 0.3165, validation loss: 0.1466
2024-05-23 18:16:40 [INFO]: Epoch 028 - training loss: 0.3145, validation loss: 0.1437
2024-05-23 18:16:40 [INFO]: Epoch 029 - training loss: 0.3113, validation loss: 0.1439
2024-05-23 18:16:41 [INFO]: Epoch 030 - training loss: 0.3090, validation loss: 0.1411
2024-05-23 18:16:42 [INFO]: Epoch 031 - training loss: 0.3067, validation loss: 0.1407
2024-05-23 18:16:42 [INFO]: Epoch 032 - training loss: 0.3037, validation loss: 0.1396
2024-05-23 18:16:43 [INFO]: Epoch 033 - training loss: 0.3011, validation loss: 0.1380
2024-05-23 18:16:43 [INFO]: Epoch 034 - training loss: 0.2989, validation loss: 0.1369
2024-05-23 18:16:44 [INFO]: Epoch 035 - training loss: 0.2972, validation loss: 0.1353
2024-05-23 18:16:44 [INFO]: Epoch 036 - training loss: 0.2965, validation loss: 0.1339
2024-05-23 18:16:45 [INFO]: Epoch 037 - training loss: 0.2926, validation loss: 0.1333
2024-05-23 18:16:46 [INFO]: Epoch 038 - training loss: 0.2915, validation loss: 0.1322
2024-05-23 18:16:46 [INFO]: Epoch 039 - training loss: 0.2893, validation loss: 0.1318
2024-05-23 18:16:47 [INFO]: Epoch 040 - training loss: 0.2872, validation loss: 0.1311
2024-05-23 18:16:47 [INFO]: Epoch 041 - training loss: 0.2847, validation loss: 0.1305
2024-05-23 18:16:48 [INFO]: Epoch 042 - training loss: 0.2830, validation loss: 0.1291
2024-05-23 18:16:49 [INFO]: Epoch 043 - training loss: 0.2811, validation loss: 0.1283
2024-05-23 18:16:49 [INFO]: Epoch 044 - training loss: 0.2801, validation loss: 0.1276
2024-05-23 18:16:50 [INFO]: Epoch 045 - training loss: 0.2777, validation loss: 0.1273
2024-05-23 18:16:50 [INFO]: Epoch 046 - training loss: 0.2769, validation loss: 0.1261
2024-05-23 18:16:51 [INFO]: Epoch 047 - training loss: 0.2756, validation loss: 0.1262
2024-05-23 18:16:52 [INFO]: Epoch 048 - training loss: 0.2732, validation loss: 0.1255
2024-05-23 18:16:52 [INFO]: Epoch 049 - training loss: 0.2720, validation loss: 0.1243
2024-05-23 18:16:53 [INFO]: Epoch 050 - training loss: 0.2695, validation loss: 0.1239
2024-05-23 18:16:53 [INFO]: Epoch 051 - training loss: 0.2682, validation loss: 0.1224
2024-05-23 18:16:54 [INFO]: Epoch 052 - training loss: 0.2671, validation loss: 0.1228
2024-05-23 18:16:54 [INFO]: Epoch 053 - training loss: 0.2652, validation loss: 0.1219
2024-05-23 18:16:55 [INFO]: Epoch 054 - training loss: 0.2647, validation loss: 0.1224
2024-05-23 18:16:56 [INFO]: Epoch 055 - training loss: 0.2618, validation loss: 0.1214
2024-05-23 18:16:56 [INFO]: Epoch 056 - training loss: 0.2611, validation loss: 0.1221
2024-05-23 18:16:57 [INFO]: Epoch 057 - training loss: 0.2598, validation loss: 0.1210
2024-05-23 18:16:57 [INFO]: Epoch 058 - training loss: 0.2588, validation loss: 0.1202
2024-05-23 18:16:58 [INFO]: Epoch 059 - training loss: 0.2564, validation loss: 0.1213
2024-05-23 18:16:59 [INFO]: Epoch 060 - training loss: 0.2578, validation loss: 0.1191
2024-05-23 18:16:59 [INFO]: Epoch 061 - training loss: 0.2557, validation loss: 0.1188
2024-05-23 18:17:00 [INFO]: Epoch 062 - training loss: 0.2547, validation loss: 0.1181
2024-05-23 18:17:00 [INFO]: Epoch 063 - training loss: 0.2534, validation loss: 0.1179
2024-05-23 18:17:01 [INFO]: Epoch 064 - training loss: 0.2506, validation loss: 0.1181
2024-05-23 18:17:02 [INFO]: Epoch 065 - training loss: 0.2496, validation loss: 0.1190
2024-05-23 18:17:02 [INFO]: Epoch 066 - training loss: 0.2488, validation loss: 0.1167
2024-05-23 18:17:03 [INFO]: Epoch 067 - training loss: 0.2467, validation loss: 0.1162
2024-05-23 18:17:03 [INFO]: Epoch 068 - training loss: 0.2462, validation loss: 0.1161
2024-05-23 18:17:04 [INFO]: Epoch 069 - training loss: 0.2447, validation loss: 0.1176
2024-05-23 18:17:04 [INFO]: Epoch 070 - training loss: 0.2439, validation loss: 0.1151
2024-05-23 18:17:05 [INFO]: Epoch 071 - training loss: 0.2430, validation loss: 0.1159
2024-05-23 18:17:06 [INFO]: Epoch 072 - training loss: 0.2426, validation loss: 0.1155
2024-05-23 18:17:06 [INFO]: Epoch 073 - training loss: 0.2413, validation loss: 0.1162
2024-05-23 18:17:07 [INFO]: Epoch 074 - training loss: 0.2400, validation loss: 0.1156
2024-05-23 18:17:07 [INFO]: Epoch 075 - training loss: 0.2380, validation loss: 0.1140
2024-05-23 18:17:08 [INFO]: Epoch 076 - training loss: 0.2368, validation loss: 0.1138
2024-05-23 18:17:09 [INFO]: Epoch 077 - training loss: 0.2362, validation loss: 0.1135
2024-05-23 18:17:09 [INFO]: Epoch 078 - training loss: 0.2363, validation loss: 0.1132
2024-05-23 18:17:10 [INFO]: Epoch 079 - training loss: 0.2351, validation loss: 0.1135
2024-05-23 18:17:10 [INFO]: Epoch 080 - training loss: 0.2348, validation loss: 0.1130
2024-05-23 18:17:11 [INFO]: Epoch 081 - training loss: 0.2342, validation loss: 0.1127
2024-05-23 18:17:12 [INFO]: Epoch 082 - training loss: 0.2321, validation loss: 0.1124
2024-05-23 18:17:12 [INFO]: Epoch 083 - training loss: 0.2325, validation loss: 0.1124
2024-05-23 18:17:13 [INFO]: Epoch 084 - training loss: 0.2316, validation loss: 0.1120
2024-05-23 18:17:13 [INFO]: Epoch 085 - training loss: 0.2291, validation loss: 0.1121
2024-05-23 18:17:14 [INFO]: Epoch 086 - training loss: 0.2287, validation loss: 0.1112
2024-05-23 18:17:14 [INFO]: Epoch 087 - training loss: 0.2279, validation loss: 0.1104
2024-05-23 18:17:15 [INFO]: Epoch 088 - training loss: 0.2275, validation loss: 0.1109
2024-05-23 18:17:16 [INFO]: Epoch 089 - training loss: 0.2273, validation loss: 0.1103
2024-05-23 18:17:16 [INFO]: Epoch 090 - training loss: 0.2263, validation loss: 0.1096
2024-05-23 18:17:17 [INFO]: Epoch 091 - training loss: 0.2253, validation loss: 0.1107
2024-05-23 18:17:17 [INFO]: Epoch 092 - training loss: 0.2264, validation loss: 0.1105
2024-05-23 18:17:18 [INFO]: Epoch 093 - training loss: 0.2255, validation loss: 0.1106
2024-05-23 18:17:19 [INFO]: Epoch 094 - training loss: 0.2235, validation loss: 0.1100
2024-05-23 18:17:19 [INFO]: Epoch 095 - training loss: 0.2227, validation loss: 0.1086
2024-05-23 18:17:20 [INFO]: Epoch 096 - training loss: 0.2216, validation loss: 0.1086
2024-05-23 18:17:20 [INFO]: Epoch 097 - training loss: 0.2209, validation loss: 0.1088
2024-05-23 18:17:21 [INFO]: Epoch 098 - training loss: 0.2212, validation loss: 0.1087
2024-05-23 18:17:22 [INFO]: Epoch 099 - training loss: 0.2208, validation loss: 0.1094
2024-05-23 18:17:22 [INFO]: Epoch 100 - training loss: 0.2201, validation loss: 0.1081
2024-05-23 18:17:23 [INFO]: Epoch 101 - training loss: 0.2202, validation loss: 0.1074
2024-05-23 18:17:23 [INFO]: Epoch 102 - training loss: 0.2191, validation loss: 0.1090
2024-05-23 18:17:24 [INFO]: Epoch 103 - training loss: 0.2188, validation loss: 0.1102
2024-05-23 18:17:24 [INFO]: Epoch 104 - training loss: 0.2175, validation loss: 0.1070
2024-05-23 18:17:25 [INFO]: Epoch 105 - training loss: 0.2159, validation loss: 0.1072
2024-05-23 18:17:26 [INFO]: Epoch 106 - training loss: 0.2151, validation loss: 0.1077
2024-05-23 18:17:26 [INFO]: Epoch 107 - training loss: 0.2154, validation loss: 0.1076
2024-05-23 18:17:27 [INFO]: Epoch 108 - training loss: 0.2145, validation loss: 0.1080
2024-05-23 18:17:27 [INFO]: Epoch 109 - training loss: 0.2138, validation loss: 0.1063
2024-05-23 18:17:28 [INFO]: Epoch 110 - training loss: 0.2130, validation loss: 0.1065
2024-05-23 18:17:29 [INFO]: Epoch 111 - training loss: 0.2122, validation loss: 0.1059
2024-05-23 18:17:29 [INFO]: Epoch 112 - training loss: 0.2114, validation loss: 0.1063
2024-05-23 18:17:30 [INFO]: Epoch 113 - training loss: 0.2111, validation loss: 0.1057
2024-05-23 18:17:30 [INFO]: Epoch 114 - training loss: 0.2105, validation loss: 0.1064
2024-05-23 18:17:31 [INFO]: Epoch 115 - training loss: 0.2101, validation loss: 0.1067
2024-05-23 18:17:32 [INFO]: Epoch 116 - training loss: 0.2104, validation loss: 0.1057
2024-05-23 18:17:32 [INFO]: Epoch 117 - training loss: 0.2097, validation loss: 0.1058
2024-05-23 18:17:33 [INFO]: Epoch 118 - training loss: 0.2083, validation loss: 0.1053
2024-05-23 18:17:33 [INFO]: Epoch 119 - training loss: 0.2080, validation loss: 0.1051
2024-05-23 18:17:34 [INFO]: Epoch 120 - training loss: 0.2078, validation loss: 0.1062
2024-05-23 18:17:34 [INFO]: Epoch 121 - training loss: 0.2102, validation loss: 0.1071
2024-05-23 18:17:35 [INFO]: Epoch 122 - training loss: 0.2079, validation loss: 0.1049
2024-05-23 18:17:36 [INFO]: Epoch 123 - training loss: 0.2059, validation loss: 0.1030
2024-05-23 18:17:36 [INFO]: Epoch 124 - training loss: 0.2053, validation loss: 0.1048
2024-05-23 18:17:37 [INFO]: Epoch 125 - training loss: 0.2053, validation loss: 0.1049
2024-05-23 18:17:37 [INFO]: Epoch 126 - training loss: 0.2038, validation loss: 0.1038
2024-05-23 18:17:38 [INFO]: Epoch 127 - training loss: 0.2038, validation loss: 0.1042
2024-05-23 18:17:39 [INFO]: Epoch 128 - training loss: 0.2031, validation loss: 0.1031
2024-05-23 18:17:39 [INFO]: Epoch 129 - training loss: 0.2026, validation loss: 0.1031
2024-05-23 18:17:40 [INFO]: Epoch 130 - training loss: 0.2026, validation loss: 0.1039
2024-05-23 18:17:40 [INFO]: Epoch 131 - training loss: 0.2030, validation loss: 0.1031
2024-05-23 18:17:41 [INFO]: Epoch 132 - training loss: 0.2020, validation loss: 0.1034
2024-05-23 18:17:42 [INFO]: Epoch 133 - training loss: 0.2018, validation loss: 0.1027
2024-05-23 18:17:42 [INFO]: Epoch 134 - training loss: 0.2005, validation loss: 0.1034
2024-05-23 18:17:43 [INFO]: Epoch 135 - training loss: 0.2004, validation loss: 0.1049
2024-05-23 18:17:43 [INFO]: Epoch 136 - training loss: 0.2012, validation loss: 0.1023
2024-05-23 18:17:44 [INFO]: Epoch 137 - training loss: 0.2009, validation loss: 0.1026
2024-05-23 18:17:45 [INFO]: Epoch 138 - training loss: 0.1980, validation loss: 0.1026
2024-05-23 18:17:45 [INFO]: Epoch 139 - training loss: 0.1976, validation loss: 0.1024
2024-05-23 18:17:46 [INFO]: Epoch 140 - training loss: 0.1986, validation loss: 0.1032
2024-05-23 18:17:46 [INFO]: Epoch 141 - training loss: 0.1998, validation loss: 0.1030
2024-05-23 18:17:47 [INFO]: Epoch 142 - training loss: 0.1980, validation loss: 0.1020
2024-05-23 18:17:47 [INFO]: Epoch 143 - training loss: 0.1980, validation loss: 0.1021
2024-05-23 18:17:48 [INFO]: Epoch 144 - training loss: 0.1967, validation loss: 0.1015
2024-05-23 18:17:49 [INFO]: Epoch 145 - training loss: 0.1950, validation loss: 0.1019
2024-05-23 18:17:49 [INFO]: Epoch 146 - training loss: 0.1955, validation loss: 0.1032
2024-05-23 18:17:50 [INFO]: Epoch 147 - training loss: 0.1950, validation loss: 0.1012
2024-05-23 18:17:50 [INFO]: Epoch 148 - training loss: 0.1948, validation loss: 0.1015
2024-05-23 18:17:51 [INFO]: Epoch 149 - training loss: 0.1949, validation loss: 0.1009
2024-05-23 18:17:52 [INFO]: Epoch 150 - training loss: 0.1933, validation loss: 0.1011
2024-05-23 18:17:52 [INFO]: Epoch 151 - training loss: 0.1927, validation loss: 0.1013
2024-05-23 18:17:53 [INFO]: Epoch 152 - training loss: 0.1925, validation loss: 0.1013
2024-05-23 18:17:53 [INFO]: Epoch 153 - training loss: 0.1940, validation loss: 0.1016
2024-05-23 18:17:54 [INFO]: Epoch 154 - training loss: 0.1917, validation loss: 0.1016
2024-05-23 18:17:55 [INFO]: Epoch 155 - training loss: 0.1915, validation loss: 0.1018
2024-05-23 18:17:55 [INFO]: Epoch 156 - training loss: 0.1915, validation loss: 0.1033
2024-05-23 18:17:56 [INFO]: Epoch 157 - training loss: 0.1914, validation loss: 0.1004
2024-05-23 18:17:56 [INFO]: Epoch 158 - training loss: 0.1905, validation loss: 0.1006
2024-05-23 18:17:57 [INFO]: Epoch 159 - training loss: 0.1903, validation loss: 0.1017
2024-05-23 18:17:58 [INFO]: Epoch 160 - training loss: 0.1899, validation loss: 0.1009
2024-05-23 18:17:58 [INFO]: Epoch 161 - training loss: 0.1885, validation loss: 0.1007
2024-05-23 18:17:59 [INFO]: Epoch 162 - training loss: 0.1884, validation loss: 0.1004
2024-05-23 18:17:59 [INFO]: Epoch 163 - training loss: 0.1883, validation loss: 0.1000
2024-05-23 18:18:00 [INFO]: Epoch 164 - training loss: 0.1886, validation loss: 0.0995
2024-05-23 18:18:00 [INFO]: Epoch 165 - training loss: 0.1874, validation loss: 0.1007
2024-05-23 18:18:01 [INFO]: Epoch 166 - training loss: 0.1876, validation loss: 0.1007
2024-05-23 18:18:02 [INFO]: Epoch 167 - training loss: 0.1867, validation loss: 0.1015
2024-05-23 18:18:02 [INFO]: Epoch 168 - training loss: 0.1865, validation loss: 0.0989
2024-05-23 18:18:03 [INFO]: Epoch 169 - training loss: 0.1864, validation loss: 0.1000
2024-05-23 18:18:03 [INFO]: Epoch 170 - training loss: 0.1863, validation loss: 0.0993
2024-05-23 18:18:04 [INFO]: Epoch 171 - training loss: 0.1857, validation loss: 0.0998
2024-05-23 18:18:05 [INFO]: Epoch 172 - training loss: 0.1852, validation loss: 0.1011
2024-05-23 18:18:05 [INFO]: Epoch 173 - training loss: 0.1844, validation loss: 0.0994
2024-05-23 18:18:06 [INFO]: Epoch 174 - training loss: 0.1843, validation loss: 0.0999
2024-05-23 18:18:06 [INFO]: Epoch 175 - training loss: 0.1849, validation loss: 0.0990
2024-05-23 18:18:07 [INFO]: Epoch 176 - training loss: 0.1838, validation loss: 0.0991
2024-05-23 18:18:08 [INFO]: Epoch 177 - training loss: 0.1837, validation loss: 0.0999
2024-05-23 18:18:08 [INFO]: Epoch 178 - training loss: 0.1834, validation loss: 0.0997
2024-05-23 18:18:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:18:08 [INFO]: Finished training. The best model is from epoch#168.
2024-05-23 18:18:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/SAITS_air_quality/20240523_T181623/SAITS.pypots
2024-05-23 18:18:08 [INFO]: SAITS on Air-Quality: MAE=0.1555, MSE=0.1735
2024-05-23 18:18:08 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-23 18:18:08 [INFO]: Using the given device: cuda:0
2024-05-23 18:18:08 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240523_T181808
2024-05-23 18:18:08 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/Transformer_air_quality/20240523_T181808/tensorboard
2024-05-23 18:18:08 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 18:18:09 [INFO]: Epoch 001 - training loss: 0.8962, validation loss: 0.4329
2024-05-23 18:18:09 [INFO]: Epoch 002 - training loss: 0.5550, validation loss: 0.3077
2024-05-23 18:18:09 [INFO]: Epoch 003 - training loss: 0.4663, validation loss: 0.2630
2024-05-23 18:18:09 [INFO]: Epoch 004 - training loss: 0.4200, validation loss: 0.2336
2024-05-23 18:18:10 [INFO]: Epoch 005 - training loss: 0.3899, validation loss: 0.2203
2024-05-23 18:18:10 [INFO]: Epoch 006 - training loss: 0.3699, validation loss: 0.2122
2024-05-23 18:18:10 [INFO]: Epoch 007 - training loss: 0.3552, validation loss: 0.2051
2024-05-23 18:18:10 [INFO]: Epoch 008 - training loss: 0.3437, validation loss: 0.1984
2024-05-23 18:18:11 [INFO]: Epoch 009 - training loss: 0.3335, validation loss: 0.1935
2024-05-23 18:18:11 [INFO]: Epoch 010 - training loss: 0.3244, validation loss: 0.1893
2024-05-23 18:18:11 [INFO]: Epoch 011 - training loss: 0.3221, validation loss: 0.1843
2024-05-23 18:18:11 [INFO]: Epoch 012 - training loss: 0.3133, validation loss: 0.1811
2024-05-23 18:18:12 [INFO]: Epoch 013 - training loss: 0.3059, validation loss: 0.1787
2024-05-23 18:18:12 [INFO]: Epoch 014 - training loss: 0.3024, validation loss: 0.1749
2024-05-23 18:18:12 [INFO]: Epoch 015 - training loss: 0.2976, validation loss: 0.1716
2024-05-23 18:18:12 [INFO]: Epoch 016 - training loss: 0.2927, validation loss: 0.1705
2024-05-23 18:18:13 [INFO]: Epoch 017 - training loss: 0.2901, validation loss: 0.1692
2024-05-23 18:18:13 [INFO]: Epoch 018 - training loss: 0.2878, validation loss: 0.1653
2024-05-23 18:18:13 [INFO]: Epoch 019 - training loss: 0.2835, validation loss: 0.1630
2024-05-23 18:18:13 [INFO]: Epoch 020 - training loss: 0.2786, validation loss: 0.1601
2024-05-23 18:18:13 [INFO]: Epoch 021 - training loss: 0.2776, validation loss: 0.1592
2024-05-23 18:18:14 [INFO]: Epoch 022 - training loss: 0.2757, validation loss: 0.1563
2024-05-23 18:18:14 [INFO]: Epoch 023 - training loss: 0.2742, validation loss: 0.1576
2024-05-23 18:18:14 [INFO]: Epoch 024 - training loss: 0.2697, validation loss: 0.1545
2024-05-23 18:18:14 [INFO]: Epoch 025 - training loss: 0.2650, validation loss: 0.1554
2024-05-23 18:18:15 [INFO]: Epoch 026 - training loss: 0.2645, validation loss: 0.1521
2024-05-23 18:18:15 [INFO]: Epoch 027 - training loss: 0.2612, validation loss: 0.1528
2024-05-23 18:18:15 [INFO]: Epoch 028 - training loss: 0.2615, validation loss: 0.1516
2024-05-23 18:18:15 [INFO]: Epoch 029 - training loss: 0.2579, validation loss: 0.1503
2024-05-23 18:18:16 [INFO]: Epoch 030 - training loss: 0.2542, validation loss: 0.1481
2024-05-23 18:18:16 [INFO]: Epoch 031 - training loss: 0.2526, validation loss: 0.1496
2024-05-23 18:18:16 [INFO]: Epoch 032 - training loss: 0.2543, validation loss: 0.1485
2024-05-23 18:18:16 [INFO]: Epoch 033 - training loss: 0.2501, validation loss: 0.1460
2024-05-23 18:18:17 [INFO]: Epoch 034 - training loss: 0.2489, validation loss: 0.1452
2024-05-23 18:18:17 [INFO]: Epoch 035 - training loss: 0.2457, validation loss: 0.1446
2024-05-23 18:18:17 [INFO]: Epoch 036 - training loss: 0.2452, validation loss: 0.1458
2024-05-23 18:18:17 [INFO]: Epoch 037 - training loss: 0.2440, validation loss: 0.1441
2024-05-23 18:18:18 [INFO]: Epoch 038 - training loss: 0.2403, validation loss: 0.1441
2024-05-23 18:18:18 [INFO]: Epoch 039 - training loss: 0.2401, validation loss: 0.1421
2024-05-23 18:18:18 [INFO]: Epoch 040 - training loss: 0.2406, validation loss: 0.1429
2024-05-23 18:18:18 [INFO]: Epoch 041 - training loss: 0.2368, validation loss: 0.1417
2024-05-23 18:18:18 [INFO]: Epoch 042 - training loss: 0.2342, validation loss: 0.1406
2024-05-23 18:18:19 [INFO]: Epoch 043 - training loss: 0.2380, validation loss: 0.1396
2024-05-23 18:18:19 [INFO]: Epoch 044 - training loss: 0.2406, validation loss: 0.1430
2024-05-23 18:18:19 [INFO]: Epoch 045 - training loss: 0.2319, validation loss: 0.1402
2024-05-23 18:18:19 [INFO]: Epoch 046 - training loss: 0.2305, validation loss: 0.1384
2024-05-23 18:18:20 [INFO]: Epoch 047 - training loss: 0.2270, validation loss: 0.1400
2024-05-23 18:18:20 [INFO]: Epoch 048 - training loss: 0.2253, validation loss: 0.1375
2024-05-23 18:18:20 [INFO]: Epoch 049 - training loss: 0.2252, validation loss: 0.1373
2024-05-23 18:18:20 [INFO]: Epoch 050 - training loss: 0.2236, validation loss: 0.1361
2024-05-23 18:18:21 [INFO]: Epoch 051 - training loss: 0.2230, validation loss: 0.1377
2024-05-23 18:18:21 [INFO]: Epoch 052 - training loss: 0.2224, validation loss: 0.1367
2024-05-23 18:18:21 [INFO]: Epoch 053 - training loss: 0.2218, validation loss: 0.1369
2024-05-23 18:18:21 [INFO]: Epoch 054 - training loss: 0.2252, validation loss: 0.1366
2024-05-23 18:18:22 [INFO]: Epoch 055 - training loss: 0.2231, validation loss: 0.1369
2024-05-23 18:18:22 [INFO]: Epoch 056 - training loss: 0.2175, validation loss: 0.1342
2024-05-23 18:18:22 [INFO]: Epoch 057 - training loss: 0.2157, validation loss: 0.1347
2024-05-23 18:18:22 [INFO]: Epoch 058 - training loss: 0.2146, validation loss: 0.1326
2024-05-23 18:18:23 [INFO]: Epoch 059 - training loss: 0.2137, validation loss: 0.1332
2024-05-23 18:18:23 [INFO]: Epoch 060 - training loss: 0.2124, validation loss: 0.1328
2024-05-23 18:18:23 [INFO]: Epoch 061 - training loss: 0.2111, validation loss: 0.1337
2024-05-23 18:18:23 [INFO]: Epoch 062 - training loss: 0.2109, validation loss: 0.1340
2024-05-23 18:18:23 [INFO]: Epoch 063 - training loss: 0.2109, validation loss: 0.1321
2024-05-23 18:18:24 [INFO]: Epoch 064 - training loss: 0.2092, validation loss: 0.1317
2024-05-23 18:18:24 [INFO]: Epoch 065 - training loss: 0.2072, validation loss: 0.1320
2024-05-23 18:18:24 [INFO]: Epoch 066 - training loss: 0.2078, validation loss: 0.1317
2024-05-23 18:18:24 [INFO]: Epoch 067 - training loss: 0.2064, validation loss: 0.1321
2024-05-23 18:18:25 [INFO]: Epoch 068 - training loss: 0.2046, validation loss: 0.1318
2024-05-23 18:18:25 [INFO]: Epoch 069 - training loss: 0.2031, validation loss: 0.1288
2024-05-23 18:18:25 [INFO]: Epoch 070 - training loss: 0.2025, validation loss: 0.1291
2024-05-23 18:18:25 [INFO]: Epoch 071 - training loss: 0.2034, validation loss: 0.1284
2024-05-23 18:18:26 [INFO]: Epoch 072 - training loss: 0.2029, validation loss: 0.1308
2024-05-23 18:18:26 [INFO]: Epoch 073 - training loss: 0.2063, validation loss: 0.1280
2024-05-23 18:18:26 [INFO]: Epoch 074 - training loss: 0.2028, validation loss: 0.1297
2024-05-23 18:18:26 [INFO]: Epoch 075 - training loss: 0.2014, validation loss: 0.1316
2024-05-23 18:18:27 [INFO]: Epoch 076 - training loss: 0.2002, validation loss: 0.1288
2024-05-23 18:18:27 [INFO]: Epoch 077 - training loss: 0.1990, validation loss: 0.1291
2024-05-23 18:18:27 [INFO]: Epoch 078 - training loss: 0.1949, validation loss: 0.1267
2024-05-23 18:18:27 [INFO]: Epoch 079 - training loss: 0.1935, validation loss: 0.1272
2024-05-23 18:18:28 [INFO]: Epoch 080 - training loss: 0.1928, validation loss: 0.1279
2024-05-23 18:18:28 [INFO]: Epoch 081 - training loss: 0.1918, validation loss: 0.1276
2024-05-23 18:18:28 [INFO]: Epoch 082 - training loss: 0.1938, validation loss: 0.1280
2024-05-23 18:18:28 [INFO]: Epoch 083 - training loss: 0.1976, validation loss: 0.1297
2024-05-23 18:18:29 [INFO]: Epoch 084 - training loss: 0.1950, validation loss: 0.1278
2024-05-23 18:18:29 [INFO]: Epoch 085 - training loss: 0.1905, validation loss: 0.1266
2024-05-23 18:18:29 [INFO]: Epoch 086 - training loss: 0.1879, validation loss: 0.1264
2024-05-23 18:18:29 [INFO]: Epoch 087 - training loss: 0.1886, validation loss: 0.1263
2024-05-23 18:18:29 [INFO]: Epoch 088 - training loss: 0.1867, validation loss: 0.1270
2024-05-23 18:18:30 [INFO]: Epoch 089 - training loss: 0.1867, validation loss: 0.1246
2024-05-23 18:18:30 [INFO]: Epoch 090 - training loss: 0.1860, validation loss: 0.1254
2024-05-23 18:18:30 [INFO]: Epoch 091 - training loss: 0.1860, validation loss: 0.1247
2024-05-23 18:18:30 [INFO]: Epoch 092 - training loss: 0.1868, validation loss: 0.1253
2024-05-23 18:18:31 [INFO]: Epoch 093 - training loss: 0.1864, validation loss: 0.1262
2024-05-23 18:18:31 [INFO]: Epoch 094 - training loss: 0.1827, validation loss: 0.1241
2024-05-23 18:18:31 [INFO]: Epoch 095 - training loss: 0.1816, validation loss: 0.1242
2024-05-23 18:18:31 [INFO]: Epoch 096 - training loss: 0.1815, validation loss: 0.1228
2024-05-23 18:18:32 [INFO]: Epoch 097 - training loss: 0.1817, validation loss: 0.1225
2024-05-23 18:18:32 [INFO]: Epoch 098 - training loss: 0.1826, validation loss: 0.1232
2024-05-23 18:18:32 [INFO]: Epoch 099 - training loss: 0.1822, validation loss: 0.1241
2024-05-23 18:18:32 [INFO]: Epoch 100 - training loss: 0.1801, validation loss: 0.1247
2024-05-23 18:18:33 [INFO]: Epoch 101 - training loss: 0.1830, validation loss: 0.1221
2024-05-23 18:18:33 [INFO]: Epoch 102 - training loss: 0.1802, validation loss: 0.1221
2024-05-23 18:18:33 [INFO]: Epoch 103 - training loss: 0.1782, validation loss: 0.1228
2024-05-23 18:18:33 [INFO]: Epoch 104 - training loss: 0.1753, validation loss: 0.1216
2024-05-23 18:18:33 [INFO]: Epoch 105 - training loss: 0.1739, validation loss: 0.1223
2024-05-23 18:18:34 [INFO]: Epoch 106 - training loss: 0.1738, validation loss: 0.1215
2024-05-23 18:18:34 [INFO]: Epoch 107 - training loss: 0.1740, validation loss: 0.1226
2024-05-23 18:18:34 [INFO]: Epoch 108 - training loss: 0.1753, validation loss: 0.1223
2024-05-23 18:18:34 [INFO]: Epoch 109 - training loss: 0.1750, validation loss: 0.1217
2024-05-23 18:18:35 [INFO]: Epoch 110 - training loss: 0.1753, validation loss: 0.1251
2024-05-23 18:18:35 [INFO]: Epoch 111 - training loss: 0.1741, validation loss: 0.1227
2024-05-23 18:18:35 [INFO]: Epoch 112 - training loss: 0.1761, validation loss: 0.1221
2024-05-23 18:18:35 [INFO]: Epoch 113 - training loss: 0.1782, validation loss: 0.1239
2024-05-23 18:18:36 [INFO]: Epoch 114 - training loss: 0.1752, validation loss: 0.1216
2024-05-23 18:18:36 [INFO]: Epoch 115 - training loss: 0.1719, validation loss: 0.1212
2024-05-23 18:18:36 [INFO]: Epoch 116 - training loss: 0.1691, validation loss: 0.1205
2024-05-23 18:18:36 [INFO]: Epoch 117 - training loss: 0.1674, validation loss: 0.1212
2024-05-23 18:18:37 [INFO]: Epoch 118 - training loss: 0.1661, validation loss: 0.1221
2024-05-23 18:18:37 [INFO]: Epoch 119 - training loss: 0.1673, validation loss: 0.1198
2024-05-23 18:18:37 [INFO]: Epoch 120 - training loss: 0.1666, validation loss: 0.1191
2024-05-23 18:18:37 [INFO]: Epoch 121 - training loss: 0.1651, validation loss: 0.1199
2024-05-23 18:18:38 [INFO]: Epoch 122 - training loss: 0.1665, validation loss: 0.1197
2024-05-23 18:18:38 [INFO]: Epoch 123 - training loss: 0.1649, validation loss: 0.1210
2024-05-23 18:18:38 [INFO]: Epoch 124 - training loss: 0.1670, validation loss: 0.1198
2024-05-23 18:18:38 [INFO]: Epoch 125 - training loss: 0.1638, validation loss: 0.1197
2024-05-23 18:18:38 [INFO]: Epoch 126 - training loss: 0.1635, validation loss: 0.1197
2024-05-23 18:18:39 [INFO]: Epoch 127 - training loss: 0.1627, validation loss: 0.1195
2024-05-23 18:18:39 [INFO]: Epoch 128 - training loss: 0.1626, validation loss: 0.1177
2024-05-23 18:18:39 [INFO]: Epoch 129 - training loss: 0.1644, validation loss: 0.1186
2024-05-23 18:18:39 [INFO]: Epoch 130 - training loss: 0.1642, validation loss: 0.1215
2024-05-23 18:18:40 [INFO]: Epoch 131 - training loss: 0.1651, validation loss: 0.1200
2024-05-23 18:18:40 [INFO]: Epoch 132 - training loss: 0.1615, validation loss: 0.1207
2024-05-23 18:18:40 [INFO]: Epoch 133 - training loss: 0.1597, validation loss: 0.1198
2024-05-23 18:18:40 [INFO]: Epoch 134 - training loss: 0.1604, validation loss: 0.1191
2024-05-23 18:18:41 [INFO]: Epoch 135 - training loss: 0.1588, validation loss: 0.1191
2024-05-23 18:18:41 [INFO]: Epoch 136 - training loss: 0.1580, validation loss: 0.1173
2024-05-23 18:18:41 [INFO]: Epoch 137 - training loss: 0.1571, validation loss: 0.1197
2024-05-23 18:18:41 [INFO]: Epoch 138 - training loss: 0.1564, validation loss: 0.1194
2024-05-23 18:18:42 [INFO]: Epoch 139 - training loss: 0.1559, validation loss: 0.1204
2024-05-23 18:18:42 [INFO]: Epoch 140 - training loss: 0.1563, validation loss: 0.1183
2024-05-23 18:18:42 [INFO]: Epoch 141 - training loss: 0.1549, validation loss: 0.1189
2024-05-23 18:18:42 [INFO]: Epoch 142 - training loss: 0.1548, validation loss: 0.1212
2024-05-23 18:18:43 [INFO]: Epoch 143 - training loss: 0.1542, validation loss: 0.1207
2024-05-23 18:18:43 [INFO]: Epoch 144 - training loss: 0.1548, validation loss: 0.1176
2024-05-23 18:18:43 [INFO]: Epoch 145 - training loss: 0.1537, validation loss: 0.1183
2024-05-23 18:18:43 [INFO]: Epoch 146 - training loss: 0.1542, validation loss: 0.1178
2024-05-23 18:18:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:18:43 [INFO]: Finished training. The best model is from epoch#136.
2024-05-23 18:18:43 [INFO]: Saved the model to overlay_premask_saved_results/round_1/Transformer_air_quality/20240523_T181808/Transformer.pypots
2024-05-23 18:18:43 [INFO]: Transformer on Air-Quality: MAE=0.1705, MSE=0.2024
2024-05-23 18:18:43 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-23 18:18:43 [INFO]: Using the given device: cuda:0
2024-05-23 18:18:43 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181843
2024-05-23 18:18:43 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181843/tensorboard
2024-05-23 18:18:44 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 18:18:44 [INFO]: Epoch 001 - training loss: 0.2829, validation loss: 0.2410
2024-05-23 18:18:45 [INFO]: Epoch 002 - training loss: 0.2241, validation loss: 0.2151
2024-05-23 18:18:45 [INFO]: Epoch 003 - training loss: 0.1853, validation loss: 0.1951
2024-05-23 18:18:46 [INFO]: Epoch 004 - training loss: 0.1566, validation loss: 0.1795
2024-05-23 18:18:46 [INFO]: Epoch 005 - training loss: 0.1486, validation loss: 0.1720
2024-05-23 18:18:46 [INFO]: Epoch 006 - training loss: 0.1367, validation loss: 0.1630
2024-05-23 18:18:47 [INFO]: Epoch 007 - training loss: 0.1245, validation loss: 0.1608
2024-05-23 18:18:47 [INFO]: Epoch 008 - training loss: 0.1251, validation loss: 0.1569
2024-05-23 18:18:48 [INFO]: Epoch 009 - training loss: 0.1231, validation loss: 0.1627
2024-05-23 18:18:48 [INFO]: Epoch 010 - training loss: 0.1148, validation loss: 0.1585
2024-05-23 18:18:49 [INFO]: Epoch 011 - training loss: 0.1169, validation loss: 0.1592
2024-05-23 18:18:49 [INFO]: Epoch 012 - training loss: 0.1083, validation loss: 0.1547
2024-05-23 18:18:50 [INFO]: Epoch 013 - training loss: 0.1037, validation loss: 0.1472
2024-05-23 18:18:50 [INFO]: Epoch 014 - training loss: 0.1070, validation loss: 0.1485
2024-05-23 18:18:50 [INFO]: Epoch 015 - training loss: 0.0967, validation loss: 0.1441
2024-05-23 18:18:51 [INFO]: Epoch 016 - training loss: 0.0921, validation loss: 0.1455
2024-05-23 18:18:51 [INFO]: Epoch 017 - training loss: 0.0929, validation loss: 0.1444
2024-05-23 18:18:52 [INFO]: Epoch 018 - training loss: 0.0864, validation loss: 0.1429
2024-05-23 18:18:52 [INFO]: Epoch 019 - training loss: 0.0850, validation loss: 0.1428
2024-05-23 18:18:53 [INFO]: Epoch 020 - training loss: 0.0848, validation loss: 0.1406
2024-05-23 18:18:53 [INFO]: Epoch 021 - training loss: 0.0880, validation loss: 0.1463
2024-05-23 18:18:54 [INFO]: Epoch 022 - training loss: 0.0841, validation loss: 0.1379
2024-05-23 18:18:54 [INFO]: Epoch 023 - training loss: 0.0807, validation loss: 0.1362
2024-05-23 18:18:54 [INFO]: Epoch 024 - training loss: 0.0778, validation loss: 0.1382
2024-05-23 18:18:55 [INFO]: Epoch 025 - training loss: 0.0764, validation loss: 0.1371
2024-05-23 18:18:55 [INFO]: Epoch 026 - training loss: 0.0776, validation loss: 0.1375
2024-05-23 18:18:56 [INFO]: Epoch 027 - training loss: 0.0785, validation loss: 0.1453
2024-05-23 18:18:56 [INFO]: Epoch 028 - training loss: 0.0733, validation loss: 0.1386
2024-05-23 18:18:57 [INFO]: Epoch 029 - training loss: 0.0798, validation loss: 0.1388
2024-05-23 18:18:57 [INFO]: Epoch 030 - training loss: 0.0740, validation loss: 0.1369
2024-05-23 18:18:57 [INFO]: Epoch 031 - training loss: 0.0738, validation loss: 0.1359
2024-05-23 18:18:58 [INFO]: Epoch 032 - training loss: 0.0714, validation loss: 0.1357
2024-05-23 18:18:58 [INFO]: Epoch 033 - training loss: 0.0791, validation loss: 0.1422
2024-05-23 18:18:59 [INFO]: Epoch 034 - training loss: 0.0740, validation loss: 0.1393
2024-05-23 18:18:59 [INFO]: Epoch 035 - training loss: 0.0716, validation loss: 0.1391
2024-05-23 18:19:00 [INFO]: Epoch 036 - training loss: 0.0781, validation loss: 0.1423
2024-05-23 18:19:00 [INFO]: Epoch 037 - training loss: 0.0677, validation loss: 0.1350
2024-05-23 18:19:01 [INFO]: Epoch 038 - training loss: 0.0625, validation loss: 0.1314
2024-05-23 18:19:01 [INFO]: Epoch 039 - training loss: 0.0605, validation loss: 0.1328
2024-05-23 18:19:01 [INFO]: Epoch 040 - training loss: 0.0617, validation loss: 0.1360
2024-05-23 18:19:02 [INFO]: Epoch 041 - training loss: 0.0605, validation loss: 0.1348
2024-05-23 18:19:02 [INFO]: Epoch 042 - training loss: 0.0588, validation loss: 0.1327
2024-05-23 18:19:03 [INFO]: Epoch 043 - training loss: 0.0580, validation loss: 0.1318
2024-05-23 18:19:03 [INFO]: Epoch 044 - training loss: 0.0574, validation loss: 0.1326
2024-05-23 18:19:04 [INFO]: Epoch 045 - training loss: 0.0598, validation loss: 0.1325
2024-05-23 18:19:04 [INFO]: Epoch 046 - training loss: 0.0577, validation loss: 0.1351
2024-05-23 18:19:05 [INFO]: Epoch 047 - training loss: 0.0555, validation loss: 0.1303
2024-05-23 18:19:05 [INFO]: Epoch 048 - training loss: 0.0541, validation loss: 0.1318
2024-05-23 18:19:05 [INFO]: Epoch 049 - training loss: 0.0541, validation loss: 0.1332
2024-05-23 18:19:06 [INFO]: Epoch 050 - training loss: 0.0563, validation loss: 0.1336
2024-05-23 18:19:06 [INFO]: Epoch 051 - training loss: 0.0549, validation loss: 0.1321
2024-05-23 18:19:07 [INFO]: Epoch 052 - training loss: 0.0535, validation loss: 0.1380
2024-05-23 18:19:07 [INFO]: Epoch 053 - training loss: 0.0538, validation loss: 0.1328
2024-05-23 18:19:08 [INFO]: Epoch 054 - training loss: 0.0501, validation loss: 0.1312
2024-05-23 18:19:08 [INFO]: Epoch 055 - training loss: 0.0481, validation loss: 0.1306
2024-05-23 18:19:09 [INFO]: Epoch 056 - training loss: 0.0477, validation loss: 0.1295
2024-05-23 18:19:09 [INFO]: Epoch 057 - training loss: 0.0477, validation loss: 0.1308
2024-05-23 18:19:09 [INFO]: Epoch 058 - training loss: 0.0484, validation loss: 0.1313
2024-05-23 18:19:10 [INFO]: Epoch 059 - training loss: 0.0487, validation loss: 0.1319
2024-05-23 18:19:10 [INFO]: Epoch 060 - training loss: 0.0485, validation loss: 0.1327
2024-05-23 18:19:11 [INFO]: Epoch 061 - training loss: 0.0473, validation loss: 0.1305
2024-05-23 18:19:11 [INFO]: Epoch 062 - training loss: 0.0476, validation loss: 0.1331
2024-05-23 18:19:12 [INFO]: Epoch 063 - training loss: 0.0464, validation loss: 0.1308
2024-05-23 18:19:12 [INFO]: Epoch 064 - training loss: 0.0452, validation loss: 0.1305
2024-05-23 18:19:12 [INFO]: Epoch 065 - training loss: 0.0474, validation loss: 0.1284
2024-05-23 18:19:13 [INFO]: Epoch 066 - training loss: 0.0435, validation loss: 0.1320
2024-05-23 18:19:13 [INFO]: Epoch 067 - training loss: 0.0424, validation loss: 0.1302
2024-05-23 18:19:14 [INFO]: Epoch 068 - training loss: 0.0418, validation loss: 0.1305
2024-05-23 18:19:14 [INFO]: Epoch 069 - training loss: 0.0410, validation loss: 0.1294
2024-05-23 18:19:15 [INFO]: Epoch 070 - training loss: 0.0411, validation loss: 0.1300
2024-05-23 18:19:15 [INFO]: Epoch 071 - training loss: 0.0421, validation loss: 0.1314
2024-05-23 18:19:16 [INFO]: Epoch 072 - training loss: 0.0452, validation loss: 0.1297
2024-05-23 18:19:16 [INFO]: Epoch 073 - training loss: 0.0630, validation loss: 0.1369
2024-05-23 18:19:16 [INFO]: Epoch 074 - training loss: 0.0486, validation loss: 0.1333
2024-05-23 18:19:17 [INFO]: Epoch 075 - training loss: 0.0454, validation loss: 0.1285
2024-05-23 18:19:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:19:17 [INFO]: Finished training. The best model is from epoch#65.
2024-05-23 18:19:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/TimesNet_air_quality/20240523_T181843/TimesNet.pypots
2024-05-23 18:19:17 [INFO]: TimesNet on Air-Quality: MAE=0.1650, MSE=0.2448
2024-05-23 18:19:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-23 18:19:17 [INFO]: Using the given device: cuda:0
2024-05-23 18:19:17 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917
2024-05-23 18:19:17 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/tensorboard
2024-05-23 18:19:17 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 18:19:34 [INFO]: Epoch 001 - training loss: 0.4931, validation loss: 0.3195
2024-05-23 18:19:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch1_loss0.31947349905967715.pypots
2024-05-23 18:19:50 [INFO]: Epoch 002 - training loss: 0.2926, validation loss: 0.2597
2024-05-23 18:19:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch2_loss0.25972874760627745.pypots
2024-05-23 18:20:06 [INFO]: Epoch 003 - training loss: 0.2464, validation loss: 0.2321
2024-05-23 18:20:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch3_loss0.23206972032785417.pypots
2024-05-23 18:20:23 [INFO]: Epoch 004 - training loss: 0.2340, validation loss: 0.2068
2024-05-23 18:20:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch4_loss0.20683013051748275.pypots
2024-05-23 18:20:39 [INFO]: Epoch 005 - training loss: 0.2121, validation loss: 0.1777
2024-05-23 18:20:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch5_loss0.17769996225833892.pypots
2024-05-23 18:20:56 [INFO]: Epoch 006 - training loss: 0.1787, validation loss: 0.1664
2024-05-23 18:20:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch6_loss0.16641522198915482.pypots
2024-05-23 18:21:12 [INFO]: Epoch 007 - training loss: 0.1637, validation loss: 0.1581
2024-05-23 18:21:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch7_loss0.1581251472234726.pypots
2024-05-23 18:21:28 [INFO]: Epoch 008 - training loss: 0.1690, validation loss: 0.1552
2024-05-23 18:21:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch8_loss0.15516945123672485.pypots
2024-05-23 18:21:45 [INFO]: Epoch 009 - training loss: 0.1631, validation loss: 0.1527
2024-05-23 18:21:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch9_loss0.1526666685938835.pypots
2024-05-23 18:22:01 [INFO]: Epoch 010 - training loss: 0.1820, validation loss: 0.1447
2024-05-23 18:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch10_loss0.1447009950876236.pypots
2024-05-23 18:22:18 [INFO]: Epoch 011 - training loss: 0.1583, validation loss: 0.1460
2024-05-23 18:22:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch11_loss0.1459765002131462.pypots
2024-05-23 18:22:34 [INFO]: Epoch 012 - training loss: 0.1501, validation loss: 0.1423
2024-05-23 18:22:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch12_loss0.1423399716615677.pypots
2024-05-23 18:22:50 [INFO]: Epoch 013 - training loss: 0.1459, validation loss: 0.1484
2024-05-23 18:22:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch13_loss0.1484253630042076.pypots
2024-05-23 18:23:07 [INFO]: Epoch 014 - training loss: 0.1572, validation loss: 0.1504
2024-05-23 18:23:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch14_loss0.15040940195322036.pypots
2024-05-23 18:23:23 [INFO]: Epoch 015 - training loss: 0.1512, validation loss: 0.1406
2024-05-23 18:23:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch15_loss0.14056685715913772.pypots
2024-05-23 18:23:39 [INFO]: Epoch 016 - training loss: 0.1779, validation loss: 0.1401
2024-05-23 18:23:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch16_loss0.1401321731507778.pypots
2024-05-23 18:23:56 [INFO]: Epoch 017 - training loss: 0.1473, validation loss: 0.1350
2024-05-23 18:23:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch17_loss0.13500758707523347.pypots
2024-05-23 18:24:12 [INFO]: Epoch 018 - training loss: 0.1349, validation loss: 0.1357
2024-05-23 18:24:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch18_loss0.1357123427093029.pypots
2024-05-23 18:24:28 [INFO]: Epoch 019 - training loss: 0.1360, validation loss: 0.1338
2024-05-23 18:24:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch19_loss0.13377622067928313.pypots
2024-05-23 18:24:45 [INFO]: Epoch 020 - training loss: 0.1313, validation loss: 0.1296
2024-05-23 18:24:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch20_loss0.12955880537629128.pypots
2024-05-23 18:25:01 [INFO]: Epoch 021 - training loss: 0.1337, validation loss: 0.1288
2024-05-23 18:25:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch21_loss0.12876555621623992.pypots
2024-05-23 18:25:17 [INFO]: Epoch 022 - training loss: 0.1402, validation loss: 0.1322
2024-05-23 18:25:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch22_loss0.1322052836418152.pypots
2024-05-23 18:25:34 [INFO]: Epoch 023 - training loss: 0.1264, validation loss: 0.1291
2024-05-23 18:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch23_loss0.12907007858157157.pypots
2024-05-23 18:25:50 [INFO]: Epoch 024 - training loss: 0.1265, validation loss: 0.1291
2024-05-23 18:25:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch24_loss0.12912248820066452.pypots
2024-05-23 18:26:07 [INFO]: Epoch 025 - training loss: 0.1331, validation loss: 0.1298
2024-05-23 18:26:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch25_loss0.1298207849264145.pypots
2024-05-23 18:26:23 [INFO]: Epoch 026 - training loss: 0.1453, validation loss: 0.1292
2024-05-23 18:26:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch26_loss0.12924745455384254.pypots
2024-05-23 18:26:39 [INFO]: Epoch 027 - training loss: 0.1230, validation loss: 0.1368
2024-05-23 18:26:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch27_loss0.13677191436290742.pypots
2024-05-23 18:26:56 [INFO]: Epoch 028 - training loss: 0.1202, validation loss: 0.1241
2024-05-23 18:26:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch28_loss0.12407086044549942.pypots
2024-05-23 18:27:12 [INFO]: Epoch 029 - training loss: 0.1171, validation loss: 0.1266
2024-05-23 18:27:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch29_loss0.1266243726015091.pypots
2024-05-23 18:27:28 [INFO]: Epoch 030 - training loss: 0.1192, validation loss: 0.1250
2024-05-23 18:27:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch30_loss0.12502828910946845.pypots
2024-05-23 18:27:45 [INFO]: Epoch 031 - training loss: 0.1161, validation loss: 0.1226
2024-05-23 18:27:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch31_loss0.12256720066070556.pypots
2024-05-23 18:28:01 [INFO]: Epoch 032 - training loss: 0.1241, validation loss: 0.1227
2024-05-23 18:28:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch32_loss0.12266757115721702.pypots
2024-05-23 18:28:18 [INFO]: Epoch 033 - training loss: 0.1369, validation loss: 0.1221
2024-05-23 18:28:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch33_loss0.12205176651477814.pypots
2024-05-23 18:28:34 [INFO]: Epoch 034 - training loss: 0.1234, validation loss: 0.1256
2024-05-23 18:28:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch34_loss0.12563636749982834.pypots
2024-05-23 18:28:50 [INFO]: Epoch 035 - training loss: 0.1231, validation loss: 0.1215
2024-05-23 18:28:50 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch35_loss0.12152794748544693.pypots
2024-05-23 18:29:07 [INFO]: Epoch 036 - training loss: 0.1187, validation loss: 0.1203
2024-05-23 18:29:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch36_loss0.12027906253933907.pypots
2024-05-23 18:29:23 [INFO]: Epoch 037 - training loss: 0.1250, validation loss: 0.1153
2024-05-23 18:29:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch37_loss0.11530042365193367.pypots
2024-05-23 18:29:40 [INFO]: Epoch 038 - training loss: 0.1181, validation loss: 0.1169
2024-05-23 18:29:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch38_loss0.11687061116099358.pypots
2024-05-23 18:29:56 [INFO]: Epoch 039 - training loss: 0.1279, validation loss: 0.1193
2024-05-23 18:29:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch39_loss0.11933728754520416.pypots
2024-05-23 18:30:12 [INFO]: Epoch 040 - training loss: 0.1171, validation loss: 0.1175
2024-05-23 18:30:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch40_loss0.11753173395991326.pypots
2024-05-23 18:30:29 [INFO]: Epoch 041 - training loss: 0.1332, validation loss: 0.1154
2024-05-23 18:30:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch41_loss0.11544159352779389.pypots
2024-05-23 18:30:45 [INFO]: Epoch 042 - training loss: 0.1037, validation loss: 0.1188
2024-05-23 18:30:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch42_loss0.11875083744525909.pypots
2024-05-23 18:31:02 [INFO]: Epoch 043 - training loss: 0.1106, validation loss: 0.1161
2024-05-23 18:31:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch43_loss0.11613787785172462.pypots
2024-05-23 18:31:18 [INFO]: Epoch 044 - training loss: 0.1202, validation loss: 0.1163
2024-05-23 18:31:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch44_loss0.11633046492934226.pypots
2024-05-23 18:31:34 [INFO]: Epoch 045 - training loss: 0.1102, validation loss: 0.1183
2024-05-23 18:31:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch45_loss0.11833971589803696.pypots
2024-05-23 18:31:51 [INFO]: Epoch 046 - training loss: 0.1243, validation loss: 0.1134
2024-05-23 18:31:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch46_loss0.11338056847453118.pypots
2024-05-23 18:32:07 [INFO]: Epoch 047 - training loss: 0.1230, validation loss: 0.1138
2024-05-23 18:32:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch47_loss0.1137553557753563.pypots
2024-05-23 18:32:24 [INFO]: Epoch 048 - training loss: 0.1179, validation loss: 0.1112
2024-05-23 18:32:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch48_loss0.1112348847091198.pypots
2024-05-23 18:32:40 [INFO]: Epoch 049 - training loss: 0.1286, validation loss: 0.1137
2024-05-23 18:32:40 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch49_loss0.11370940208435058.pypots
2024-05-23 18:32:56 [INFO]: Epoch 050 - training loss: 0.1106, validation loss: 0.1120
2024-05-23 18:32:56 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch50_loss0.11204080432653427.pypots
2024-05-23 18:33:13 [INFO]: Epoch 051 - training loss: 0.1076, validation loss: 0.1123
2024-05-23 18:33:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch51_loss0.11229115277528763.pypots
2024-05-23 18:33:29 [INFO]: Epoch 052 - training loss: 0.1210, validation loss: 0.1133
2024-05-23 18:33:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch52_loss0.11328935250639915.pypots
2024-05-23 18:33:46 [INFO]: Epoch 053 - training loss: 0.1177, validation loss: 0.1131
2024-05-23 18:33:46 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch53_loss0.1131289042532444.pypots
2024-05-23 18:34:02 [INFO]: Epoch 054 - training loss: 0.1041, validation loss: 0.1120
2024-05-23 18:34:02 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch54_loss0.11197352409362793.pypots
2024-05-23 18:34:18 [INFO]: Epoch 055 - training loss: 0.1176, validation loss: 0.1182
2024-05-23 18:34:18 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch55_loss0.1182261697947979.pypots
2024-05-23 18:34:35 [INFO]: Epoch 056 - training loss: 0.1093, validation loss: 0.1124
2024-05-23 18:34:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch56_loss0.11241507083177567.pypots
2024-05-23 18:34:51 [INFO]: Epoch 057 - training loss: 0.1217, validation loss: 0.1147
2024-05-23 18:34:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch57_loss0.11470919921994209.pypots
2024-05-23 18:35:08 [INFO]: Epoch 058 - training loss: 0.1064, validation loss: 0.1124
2024-05-23 18:35:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI_epoch58_loss0.11238438785076141.pypots
2024-05-23 18:35:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:35:08 [INFO]: Finished training. The best model is from epoch#48.
2024-05-23 18:35:08 [INFO]: Saved the model to overlay_premask_saved_results/round_1/CSDI_air_quality/20240523_T181917/CSDI.pypots
2024-05-23 18:37:26 [INFO]: CSDI on Air-Quality: MAE=0.1165, MSE=0.2294
2024-05-23 18:37:26 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-23 18:37:26 [INFO]: Using the given device: cuda:0
2024-05-23 18:37:26 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240523_T183726
2024-05-23 18:37:26 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240523_T183726/tensorboard
2024-05-23 18:37:26 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 18:37:26 [INFO]: Epoch 001 - training loss: 64655.2698, validation loss: 0.6317
2024-05-23 18:37:27 [INFO]: Epoch 002 - training loss: 41821.9534, validation loss: 0.5420
2024-05-23 18:37:27 [INFO]: Epoch 003 - training loss: 41511.3634, validation loss: 0.5281
2024-05-23 18:37:27 [INFO]: Epoch 004 - training loss: 41382.8666, validation loss: 0.4395
2024-05-23 18:37:27 [INFO]: Epoch 005 - training loss: 41269.1008, validation loss: 0.4076
2024-05-23 18:37:28 [INFO]: Epoch 006 - training loss: 41214.0113, validation loss: 0.4236
2024-05-23 18:37:28 [INFO]: Epoch 007 - training loss: 41207.0299, validation loss: 0.4102
2024-05-23 18:37:28 [INFO]: Epoch 008 - training loss: 41186.7788, validation loss: 0.3495
2024-05-23 18:37:28 [INFO]: Epoch 009 - training loss: 41121.2189, validation loss: 0.3175
2024-05-23 18:37:29 [INFO]: Epoch 010 - training loss: 41075.5179, validation loss: 0.3273
2024-05-23 18:37:29 [INFO]: Epoch 011 - training loss: 41135.6889, validation loss: 0.3177
2024-05-23 18:37:29 [INFO]: Epoch 012 - training loss: 41056.6152, validation loss: 0.2971
2024-05-23 18:37:30 [INFO]: Epoch 013 - training loss: 41027.9258, validation loss: 0.2959
2024-05-23 18:37:30 [INFO]: Epoch 014 - training loss: 41013.8232, validation loss: 0.2905
2024-05-23 18:37:30 [INFO]: Epoch 015 - training loss: 41014.4508, validation loss: 0.2826
2024-05-23 18:37:30 [INFO]: Epoch 016 - training loss: 40994.9521, validation loss: 0.2740
2024-05-23 18:37:31 [INFO]: Epoch 017 - training loss: 40985.1593, validation loss: 0.2828
2024-05-23 18:37:31 [INFO]: Epoch 018 - training loss: 40985.1888, validation loss: 0.2866
2024-05-23 18:37:31 [INFO]: Epoch 019 - training loss: 40981.4902, validation loss: 0.2658
2024-05-23 18:37:31 [INFO]: Epoch 020 - training loss: 40968.8883, validation loss: 0.2764
2024-05-23 18:37:32 [INFO]: Epoch 021 - training loss: 40985.5872, validation loss: 0.2801
2024-05-23 18:37:32 [INFO]: Epoch 022 - training loss: 40963.5188, validation loss: 0.2534
2024-05-23 18:37:32 [INFO]: Epoch 023 - training loss: 40938.9722, validation loss: 0.2505
2024-05-23 18:37:32 [INFO]: Epoch 024 - training loss: 40934.8578, validation loss: 0.2548
2024-05-23 18:37:33 [INFO]: Epoch 025 - training loss: 40934.9243, validation loss: 0.2529
2024-05-23 18:37:33 [INFO]: Epoch 026 - training loss: 40942.8260, validation loss: 0.2463
2024-05-23 18:37:33 [INFO]: Epoch 027 - training loss: 40935.8351, validation loss: 0.2437
2024-05-23 18:37:34 [INFO]: Epoch 028 - training loss: 40946.3899, validation loss: 0.2527
2024-05-23 18:37:34 [INFO]: Epoch 029 - training loss: 40922.8860, validation loss: 0.2391
2024-05-23 18:37:34 [INFO]: Epoch 030 - training loss: 40919.7352, validation loss: 0.2386
2024-05-23 18:37:34 [INFO]: Epoch 031 - training loss: 40922.5326, validation loss: 0.2702
2024-05-23 18:37:35 [INFO]: Epoch 032 - training loss: 40926.8944, validation loss: 0.2430
2024-05-23 18:37:35 [INFO]: Epoch 033 - training loss: 40920.9418, validation loss: 0.2367
2024-05-23 18:37:35 [INFO]: Epoch 034 - training loss: 40917.6573, validation loss: 0.2488
2024-05-23 18:37:35 [INFO]: Epoch 035 - training loss: 40911.8368, validation loss: 0.2336
2024-05-23 18:37:36 [INFO]: Epoch 036 - training loss: 40894.2629, validation loss: 0.2258
2024-05-23 18:37:36 [INFO]: Epoch 037 - training loss: 40888.0991, validation loss: 0.2258
2024-05-23 18:37:36 [INFO]: Epoch 038 - training loss: 40891.3584, validation loss: 0.2269
2024-05-23 18:37:36 [INFO]: Epoch 039 - training loss: 40882.4980, validation loss: 0.2205
2024-05-23 18:37:37 [INFO]: Epoch 040 - training loss: 40886.0289, validation loss: 0.2237
2024-05-23 18:37:37 [INFO]: Epoch 041 - training loss: 40883.7365, validation loss: 0.2211
2024-05-23 18:37:37 [INFO]: Epoch 042 - training loss: 40875.2237, validation loss: 0.2198
2024-05-23 18:37:38 [INFO]: Epoch 043 - training loss: 40874.6946, validation loss: 0.2181
2024-05-23 18:37:38 [INFO]: Epoch 044 - training loss: 40875.9946, validation loss: 0.2169
2024-05-23 18:37:38 [INFO]: Epoch 045 - training loss: 40884.0700, validation loss: 0.2267
2024-05-23 18:37:38 [INFO]: Epoch 046 - training loss: 40870.8879, validation loss: 0.2234
2024-05-23 18:37:39 [INFO]: Epoch 047 - training loss: 40879.7883, validation loss: 0.2255
2024-05-23 18:37:39 [INFO]: Epoch 048 - training loss: 40874.9569, validation loss: 0.2120
2024-05-23 18:37:39 [INFO]: Epoch 049 - training loss: 40862.1505, validation loss: 0.2103
2024-05-23 18:37:39 [INFO]: Epoch 050 - training loss: 40872.7536, validation loss: 0.2192
2024-05-23 18:37:40 [INFO]: Epoch 051 - training loss: 40874.6110, validation loss: 0.2226
2024-05-23 18:37:40 [INFO]: Epoch 052 - training loss: 40891.7526, validation loss: 0.2248
2024-05-23 18:37:40 [INFO]: Epoch 053 - training loss: 40879.0062, validation loss: 0.2209
2024-05-23 18:37:40 [INFO]: Epoch 054 - training loss: 40872.7588, validation loss: 0.2146
2024-05-23 18:37:41 [INFO]: Epoch 055 - training loss: 40869.9253, validation loss: 0.2292
2024-05-23 18:37:41 [INFO]: Epoch 056 - training loss: 40868.8288, validation loss: 0.2232
2024-05-23 18:37:41 [INFO]: Epoch 057 - training loss: 40886.5938, validation loss: 0.2073
2024-05-23 18:37:42 [INFO]: Epoch 058 - training loss: 40856.1092, validation loss: 0.2100
2024-05-23 18:37:42 [INFO]: Epoch 059 - training loss: 40848.7629, validation loss: 0.2023
2024-05-23 18:37:42 [INFO]: Epoch 060 - training loss: 40848.1969, validation loss: 0.2011
2024-05-23 18:37:42 [INFO]: Epoch 061 - training loss: 40842.2499, validation loss: 0.2092
2024-05-23 18:37:43 [INFO]: Epoch 062 - training loss: 40860.5848, validation loss: 0.2136
2024-05-23 18:37:43 [INFO]: Epoch 063 - training loss: 40884.4369, validation loss: 0.2440
2024-05-23 18:37:43 [INFO]: Epoch 064 - training loss: 40890.5152, validation loss: 0.2143
2024-05-23 18:37:43 [INFO]: Epoch 065 - training loss: 40854.9541, validation loss: 0.2052
2024-05-23 18:37:44 [INFO]: Epoch 066 - training loss: 40845.5360, validation loss: 0.2101
2024-05-23 18:37:44 [INFO]: Epoch 067 - training loss: 40856.5394, validation loss: 0.2024
2024-05-23 18:37:44 [INFO]: Epoch 068 - training loss: 40844.9514, validation loss: 0.2036
2024-05-23 18:37:44 [INFO]: Epoch 069 - training loss: 40849.8138, validation loss: 0.2092
2024-05-23 18:37:45 [INFO]: Epoch 070 - training loss: 40845.1698, validation loss: 0.1968
2024-05-23 18:37:45 [INFO]: Epoch 071 - training loss: 40837.0201, validation loss: 0.2021
2024-05-23 18:37:45 [INFO]: Epoch 072 - training loss: 40853.8691, validation loss: 0.2031
2024-05-23 18:37:46 [INFO]: Epoch 073 - training loss: 40845.0168, validation loss: 0.1999
2024-05-23 18:37:46 [INFO]: Epoch 074 - training loss: 40838.8670, validation loss: 0.2035
2024-05-23 18:37:46 [INFO]: Epoch 075 - training loss: 40831.7151, validation loss: 0.2025
2024-05-23 18:37:46 [INFO]: Epoch 076 - training loss: 40831.0880, validation loss: 0.1963
2024-05-23 18:37:47 [INFO]: Epoch 077 - training loss: 40835.6625, validation loss: 0.1951
2024-05-23 18:37:47 [INFO]: Epoch 078 - training loss: 40838.3834, validation loss: 0.1992
2024-05-23 18:37:47 [INFO]: Epoch 079 - training loss: 40860.0386, validation loss: 0.2092
2024-05-23 18:37:47 [INFO]: Epoch 080 - training loss: 40878.8202, validation loss: 0.2180
2024-05-23 18:37:48 [INFO]: Epoch 081 - training loss: 40878.5813, validation loss: 0.2052
2024-05-23 18:37:48 [INFO]: Epoch 082 - training loss: 40844.6615, validation loss: 0.1978
2024-05-23 18:37:48 [INFO]: Epoch 083 - training loss: 40827.2383, validation loss: 0.2004
2024-05-23 18:37:48 [INFO]: Epoch 084 - training loss: 40829.4280, validation loss: 0.1950
2024-05-23 18:37:49 [INFO]: Epoch 085 - training loss: 40832.3113, validation loss: 0.1996
2024-05-23 18:37:49 [INFO]: Epoch 086 - training loss: 40826.0703, validation loss: 0.1934
2024-05-23 18:37:49 [INFO]: Epoch 087 - training loss: 40822.4290, validation loss: 0.2081
2024-05-23 18:37:50 [INFO]: Epoch 088 - training loss: 40851.4588, validation loss: 0.2024
2024-05-23 18:37:50 [INFO]: Epoch 089 - training loss: 40846.6913, validation loss: 0.2059
2024-05-23 18:37:50 [INFO]: Epoch 090 - training loss: 40836.6791, validation loss: 0.1957
2024-05-23 18:37:50 [INFO]: Epoch 091 - training loss: 40818.0123, validation loss: 0.1911
2024-05-23 18:37:51 [INFO]: Epoch 092 - training loss: 40820.7156, validation loss: 0.1889
2024-05-23 18:37:51 [INFO]: Epoch 093 - training loss: 40824.4100, validation loss: 0.1967
2024-05-23 18:37:51 [INFO]: Epoch 094 - training loss: 40841.9345, validation loss: 0.1990
2024-05-23 18:37:51 [INFO]: Epoch 095 - training loss: 40831.8082, validation loss: 0.1958
2024-05-23 18:37:52 [INFO]: Epoch 096 - training loss: 40813.7082, validation loss: 0.1883
2024-05-23 18:37:52 [INFO]: Epoch 097 - training loss: 40808.0977, validation loss: 0.1890
2024-05-23 18:37:52 [INFO]: Epoch 098 - training loss: 40807.8971, validation loss: 0.1996
2024-05-23 18:37:52 [INFO]: Epoch 099 - training loss: 40823.7024, validation loss: 0.2081
2024-05-23 18:37:53 [INFO]: Epoch 100 - training loss: 40872.0104, validation loss: 0.2020
2024-05-23 18:37:53 [INFO]: Epoch 101 - training loss: 40838.4699, validation loss: 0.2079
2024-05-23 18:37:53 [INFO]: Epoch 102 - training loss: 40821.6264, validation loss: 0.1915
2024-05-23 18:37:54 [INFO]: Epoch 103 - training loss: 40828.1330, validation loss: 0.1953
2024-05-23 18:37:54 [INFO]: Epoch 104 - training loss: 40826.0655, validation loss: 0.2003
2024-05-23 18:37:54 [INFO]: Epoch 105 - training loss: 40813.3202, validation loss: 0.1899
2024-05-23 18:37:54 [INFO]: Epoch 106 - training loss: 40808.3898, validation loss: 0.1944
2024-05-23 18:37:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:37:54 [INFO]: Finished training. The best model is from epoch#96.
2024-05-23 18:37:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/GPVAE_air_quality/20240523_T183726/GPVAE.pypots
2024-05-23 18:37:54 [INFO]: GP-VAE on Air-Quality: MAE=0.2622, MSE=0.2828
2024-05-23 18:37:54 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-23 18:37:54 [INFO]: Using the given device: cuda:0
2024-05-23 18:37:54 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240523_T183754
2024-05-23 18:37:54 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/USGAN_air_quality/20240523_T183754/tensorboard
2024-05-23 18:37:54 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 18:37:58 [INFO]: Epoch 001 - generator training loss: 0.4422, discriminator training loss: 0.4564, validation loss: 0.4889
2024-05-23 18:38:02 [INFO]: Epoch 002 - generator training loss: 0.0910, discriminator training loss: 0.3617, validation loss: 0.3621
2024-05-23 18:38:05 [INFO]: Epoch 003 - generator training loss: 0.0220, discriminator training loss: 0.3575, validation loss: 0.2928
2024-05-23 18:38:09 [INFO]: Epoch 004 - generator training loss: -0.0155, discriminator training loss: 0.3554, validation loss: 0.2538
2024-05-23 18:38:12 [INFO]: Epoch 005 - generator training loss: -0.0404, discriminator training loss: 0.3539, validation loss: 0.2304
2024-05-23 18:38:16 [INFO]: Epoch 006 - generator training loss: -0.0547, discriminator training loss: 0.3520, validation loss: 0.2124
2024-05-23 18:38:19 [INFO]: Epoch 007 - generator training loss: -0.0670, discriminator training loss: 0.3499, validation loss: 0.2004
2024-05-23 18:38:23 [INFO]: Epoch 008 - generator training loss: -0.0762, discriminator training loss: 0.3480, validation loss: 0.1909
2024-05-23 18:38:26 [INFO]: Epoch 009 - generator training loss: -0.0829, discriminator training loss: 0.3456, validation loss: 0.1827
2024-05-23 18:38:30 [INFO]: Epoch 010 - generator training loss: -0.0835, discriminator training loss: 0.3434, validation loss: 0.1766
2024-05-23 18:38:33 [INFO]: Epoch 011 - generator training loss: -0.0921, discriminator training loss: 0.3405, validation loss: 0.1701
2024-05-23 18:38:37 [INFO]: Epoch 012 - generator training loss: -0.0946, discriminator training loss: 0.3380, validation loss: 0.1653
2024-05-23 18:38:40 [INFO]: Epoch 013 - generator training loss: -0.0978, discriminator training loss: 0.3348, validation loss: 0.1614
2024-05-23 18:38:44 [INFO]: Epoch 014 - generator training loss: -0.0998, discriminator training loss: 0.3315, validation loss: 0.1566
2024-05-23 18:38:47 [INFO]: Epoch 015 - generator training loss: -0.1004, discriminator training loss: 0.3281, validation loss: 0.1529
2024-05-23 18:38:51 [INFO]: Epoch 016 - generator training loss: -0.1014, discriminator training loss: 0.3248, validation loss: 0.1501
2024-05-23 18:38:54 [INFO]: Epoch 017 - generator training loss: -0.1014, discriminator training loss: 0.3210, validation loss: 0.1467
2024-05-23 18:38:58 [INFO]: Epoch 018 - generator training loss: -0.1014, discriminator training loss: 0.3171, validation loss: 0.1439
2024-05-23 18:39:01 [INFO]: Epoch 019 - generator training loss: -0.1007, discriminator training loss: 0.3132, validation loss: 0.1413
2024-05-23 18:39:05 [INFO]: Epoch 020 - generator training loss: -0.1014, discriminator training loss: 0.3094, validation loss: 0.1388
2024-05-23 18:39:08 [INFO]: Epoch 021 - generator training loss: -0.1009, discriminator training loss: 0.3051, validation loss: 0.1369
2024-05-23 18:39:12 [INFO]: Epoch 022 - generator training loss: -0.0985, discriminator training loss: 0.3011, validation loss: 0.1349
2024-05-23 18:39:15 [INFO]: Epoch 023 - generator training loss: -0.0980, discriminator training loss: 0.2969, validation loss: 0.1331
2024-05-23 18:39:18 [INFO]: Epoch 024 - generator training loss: -0.0968, discriminator training loss: 0.2926, validation loss: 0.1309
2024-05-23 18:39:22 [INFO]: Epoch 025 - generator training loss: -0.0949, discriminator training loss: 0.2887, validation loss: 0.1290
2024-05-23 18:39:25 [INFO]: Epoch 026 - generator training loss: -0.0940, discriminator training loss: 0.2848, validation loss: 0.1277
2024-05-23 18:39:28 [INFO]: Epoch 027 - generator training loss: -0.0925, discriminator training loss: 0.2812, validation loss: 0.1257
2024-05-23 18:39:31 [INFO]: Epoch 028 - generator training loss: -0.0909, discriminator training loss: 0.2775, validation loss: 0.1245
2024-05-23 18:39:35 [INFO]: Epoch 029 - generator training loss: -0.0892, discriminator training loss: 0.2741, validation loss: 0.1231
2024-05-23 18:39:39 [INFO]: Epoch 030 - generator training loss: -0.0878, discriminator training loss: 0.2704, validation loss: 0.1217
2024-05-23 18:39:42 [INFO]: Epoch 031 - generator training loss: -0.0866, discriminator training loss: 0.2673, validation loss: 0.1204
2024-05-23 18:39:45 [INFO]: Epoch 032 - generator training loss: -0.0852, discriminator training loss: 0.2641, validation loss: 0.1193
2024-05-23 18:39:49 [INFO]: Epoch 033 - generator training loss: -0.0839, discriminator training loss: 0.2612, validation loss: 0.1178
2024-05-23 18:39:52 [INFO]: Epoch 034 - generator training loss: -0.0834, discriminator training loss: 0.2584, validation loss: 0.1165
2024-05-23 18:39:55 [INFO]: Epoch 035 - generator training loss: -0.0822, discriminator training loss: 0.2554, validation loss: 0.1158
2024-05-23 18:39:59 [INFO]: Epoch 036 - generator training loss: -0.0807, discriminator training loss: 0.2531, validation loss: 0.1144
2024-05-23 18:40:02 [INFO]: Epoch 037 - generator training loss: -0.0798, discriminator training loss: 0.2507, validation loss: 0.1132
2024-05-23 18:40:05 [INFO]: Epoch 038 - generator training loss: -0.0802, discriminator training loss: 0.2482, validation loss: 0.1128
2024-05-23 18:40:09 [INFO]: Epoch 039 - generator training loss: -0.0798, discriminator training loss: 0.2462, validation loss: 0.1114
2024-05-23 18:40:12 [INFO]: Epoch 040 - generator training loss: -0.0797, discriminator training loss: 0.2441, validation loss: 0.1112
2024-05-23 18:40:15 [INFO]: Epoch 041 - generator training loss: -0.0785, discriminator training loss: 0.2422, validation loss: 0.1099
2024-05-23 18:40:19 [INFO]: Epoch 042 - generator training loss: -0.0776, discriminator training loss: 0.2403, validation loss: 0.1091
2024-05-23 18:40:22 [INFO]: Epoch 043 - generator training loss: -0.0772, discriminator training loss: 0.2388, validation loss: 0.1083
2024-05-23 18:40:25 [INFO]: Epoch 044 - generator training loss: -0.0766, discriminator training loss: 0.2371, validation loss: 0.1074
2024-05-23 18:40:28 [INFO]: Epoch 045 - generator training loss: -0.0758, discriminator training loss: 0.2354, validation loss: 0.1067
2024-05-23 18:40:32 [INFO]: Epoch 046 - generator training loss: -0.0753, discriminator training loss: 0.2337, validation loss: 0.1058
2024-05-23 18:40:35 [INFO]: Epoch 047 - generator training loss: -0.0751, discriminator training loss: 0.2323, validation loss: 0.1049
2024-05-23 18:40:38 [INFO]: Epoch 048 - generator training loss: -0.0757, discriminator training loss: 0.2311, validation loss: 0.1048
2024-05-23 18:40:42 [INFO]: Epoch 049 - generator training loss: -0.0752, discriminator training loss: 0.2303, validation loss: 0.1036
2024-05-23 18:40:45 [INFO]: Epoch 050 - generator training loss: -0.0749, discriminator training loss: 0.2290, validation loss: 0.1035
2024-05-23 18:40:48 [INFO]: Epoch 051 - generator training loss: -0.0747, discriminator training loss: 0.2276, validation loss: 0.1027
2024-05-23 18:40:52 [INFO]: Epoch 052 - generator training loss: -0.0748, discriminator training loss: 0.2265, validation loss: 0.1026
2024-05-23 18:40:55 [INFO]: Epoch 053 - generator training loss: -0.0752, discriminator training loss: 0.2255, validation loss: 0.1023
2024-05-23 18:40:58 [INFO]: Epoch 054 - generator training loss: -0.0735, discriminator training loss: 0.2245, validation loss: 0.1014
2024-05-23 18:41:01 [INFO]: Epoch 055 - generator training loss: -0.0751, discriminator training loss: 0.2239, validation loss: 0.1008
2024-05-23 18:41:05 [INFO]: Epoch 056 - generator training loss: -0.0749, discriminator training loss: 0.2227, validation loss: 0.1007
2024-05-23 18:41:08 [INFO]: Epoch 057 - generator training loss: -0.0748, discriminator training loss: 0.2219, validation loss: 0.1002
2024-05-23 18:41:11 [INFO]: Epoch 058 - generator training loss: -0.0749, discriminator training loss: 0.2210, validation loss: 0.0994
2024-05-23 18:41:14 [INFO]: Epoch 059 - generator training loss: -0.0744, discriminator training loss: 0.2203, validation loss: 0.0994
2024-05-23 18:41:18 [INFO]: Epoch 060 - generator training loss: -0.0753, discriminator training loss: 0.2199, validation loss: 0.0983
2024-05-23 18:41:21 [INFO]: Epoch 061 - generator training loss: -0.0745, discriminator training loss: 0.2191, validation loss: 0.0981
2024-05-23 18:41:24 [INFO]: Epoch 062 - generator training loss: -0.0742, discriminator training loss: 0.2182, validation loss: 0.0981
2024-05-23 18:41:28 [INFO]: Epoch 063 - generator training loss: -0.0755, discriminator training loss: 0.2176, validation loss: 0.0971
2024-05-23 18:41:31 [INFO]: Epoch 064 - generator training loss: -0.0756, discriminator training loss: 0.2169, validation loss: 0.0974
2024-05-23 18:41:35 [INFO]: Epoch 065 - generator training loss: -0.0760, discriminator training loss: 0.2162, validation loss: 0.0969
2024-05-23 18:41:38 [INFO]: Epoch 066 - generator training loss: -0.0756, discriminator training loss: 0.2162, validation loss: 0.0962
2024-05-23 18:41:41 [INFO]: Epoch 067 - generator training loss: -0.0757, discriminator training loss: 0.2157, validation loss: 0.0957
2024-05-23 18:41:44 [INFO]: Epoch 068 - generator training loss: -0.0759, discriminator training loss: 0.2149, validation loss: 0.0951
2024-05-23 18:41:48 [INFO]: Epoch 069 - generator training loss: -0.0766, discriminator training loss: 0.2145, validation loss: 0.0956
2024-05-23 18:41:51 [INFO]: Epoch 070 - generator training loss: -0.0750, discriminator training loss: 0.2139, validation loss: 0.0954
2024-05-23 18:41:54 [INFO]: Epoch 071 - generator training loss: -0.0765, discriminator training loss: 0.2135, validation loss: 0.0948
2024-05-23 18:41:58 [INFO]: Epoch 072 - generator training loss: -0.0766, discriminator training loss: 0.2130, validation loss: 0.0943
2024-05-23 18:42:01 [INFO]: Epoch 073 - generator training loss: -0.0767, discriminator training loss: 0.2128, validation loss: 0.0937
2024-05-23 18:42:04 [INFO]: Epoch 074 - generator training loss: -0.0760, discriminator training loss: 0.2123, validation loss: 0.0938
2024-05-23 18:42:08 [INFO]: Epoch 075 - generator training loss: -0.0766, discriminator training loss: 0.2118, validation loss: 0.0930
2024-05-23 18:42:11 [INFO]: Epoch 076 - generator training loss: -0.0772, discriminator training loss: 0.2116, validation loss: 0.0934
2024-05-23 18:42:14 [INFO]: Epoch 077 - generator training loss: -0.0770, discriminator training loss: 0.2114, validation loss: 0.0933
2024-05-23 18:42:18 [INFO]: Epoch 078 - generator training loss: -0.0778, discriminator training loss: 0.2113, validation loss: 0.0921
2024-05-23 18:42:21 [INFO]: Epoch 079 - generator training loss: -0.0778, discriminator training loss: 0.2111, validation loss: 0.0920
2024-05-23 18:42:24 [INFO]: Epoch 080 - generator training loss: -0.0775, discriminator training loss: 0.2106, validation loss: 0.0913
2024-05-23 18:42:28 [INFO]: Epoch 081 - generator training loss: -0.0772, discriminator training loss: 0.2102, validation loss: 0.0916
2024-05-23 18:42:31 [INFO]: Epoch 082 - generator training loss: -0.0768, discriminator training loss: 0.2102, validation loss: 0.0913
2024-05-23 18:42:35 [INFO]: Epoch 083 - generator training loss: -0.0784, discriminator training loss: 0.2096, validation loss: 0.0912
2024-05-23 18:42:38 [INFO]: Epoch 084 - generator training loss: -0.0789, discriminator training loss: 0.2095, validation loss: 0.0910
2024-05-23 18:42:41 [INFO]: Epoch 085 - generator training loss: -0.0780, discriminator training loss: 0.2089, validation loss: 0.0907
2024-05-23 18:42:44 [INFO]: Epoch 086 - generator training loss: -0.0779, discriminator training loss: 0.2088, validation loss: 0.0914
2024-05-23 18:42:48 [INFO]: Epoch 087 - generator training loss: -0.0781, discriminator training loss: 0.2084, validation loss: 0.0907
2024-05-23 18:42:51 [INFO]: Epoch 088 - generator training loss: -0.0789, discriminator training loss: 0.2082, validation loss: 0.0904
2024-05-23 18:42:54 [INFO]: Epoch 089 - generator training loss: -0.0796, discriminator training loss: 0.2081, validation loss: 0.0900
2024-05-23 18:42:57 [INFO]: Epoch 090 - generator training loss: -0.0795, discriminator training loss: 0.2076, validation loss: 0.0896
2024-05-23 18:43:01 [INFO]: Epoch 091 - generator training loss: -0.0799, discriminator training loss: 0.2079, validation loss: 0.0899
2024-05-23 18:43:04 [INFO]: Epoch 092 - generator training loss: -0.0796, discriminator training loss: 0.2076, validation loss: 0.0897
2024-05-23 18:43:07 [INFO]: Epoch 093 - generator training loss: -0.0792, discriminator training loss: 0.2069, validation loss: 0.0896
2024-05-23 18:43:11 [INFO]: Epoch 094 - generator training loss: -0.0792, discriminator training loss: 0.2069, validation loss: 0.0899
2024-05-23 18:43:14 [INFO]: Epoch 095 - generator training loss: -0.0797, discriminator training loss: 0.2068, validation loss: 0.0899
2024-05-23 18:43:17 [INFO]: Epoch 096 - generator training loss: -0.0801, discriminator training loss: 0.2067, validation loss: 0.0893
2024-05-23 18:43:21 [INFO]: Epoch 097 - generator training loss: -0.0810, discriminator training loss: 0.2068, validation loss: 0.0893
2024-05-23 18:43:24 [INFO]: Epoch 098 - generator training loss: -0.0809, discriminator training loss: 0.2071, validation loss: 0.0892
2024-05-23 18:43:27 [INFO]: Epoch 099 - generator training loss: -0.0813, discriminator training loss: 0.2063, validation loss: 0.0887
2024-05-23 18:43:30 [INFO]: Epoch 100 - generator training loss: -0.0816, discriminator training loss: 0.2061, validation loss: 0.0890
2024-05-23 18:43:34 [INFO]: Epoch 101 - generator training loss: -0.0809, discriminator training loss: 0.2063, validation loss: 0.0894
2024-05-23 18:43:37 [INFO]: Epoch 102 - generator training loss: -0.0808, discriminator training loss: 0.2057, validation loss: 0.0887
2024-05-23 18:43:40 [INFO]: Epoch 103 - generator training loss: -0.0807, discriminator training loss: 0.2060, validation loss: 0.0895
2024-05-23 18:43:43 [INFO]: Epoch 104 - generator training loss: -0.0812, discriminator training loss: 0.2052, validation loss: 0.0888
2024-05-23 18:43:47 [INFO]: Epoch 105 - generator training loss: -0.0818, discriminator training loss: 0.2057, validation loss: 0.0891
2024-05-23 18:43:50 [INFO]: Epoch 106 - generator training loss: -0.0819, discriminator training loss: 0.2050, validation loss: 0.0888
2024-05-23 18:43:54 [INFO]: Epoch 107 - generator training loss: -0.0827, discriminator training loss: 0.2058, validation loss: 0.0891
2024-05-23 18:43:57 [INFO]: Epoch 108 - generator training loss: -0.0824, discriminator training loss: 0.2049, validation loss: 0.0887
2024-05-23 18:44:00 [INFO]: Epoch 109 - generator training loss: -0.0828, discriminator training loss: 0.2050, validation loss: 0.0886
2024-05-23 18:44:04 [INFO]: Epoch 110 - generator training loss: -0.0828, discriminator training loss: 0.2046, validation loss: 0.0887
2024-05-23 18:44:07 [INFO]: Epoch 111 - generator training loss: -0.0826, discriminator training loss: 0.2045, validation loss: 0.0890
2024-05-23 18:44:10 [INFO]: Epoch 112 - generator training loss: -0.0823, discriminator training loss: 0.2051, validation loss: 0.0898
2024-05-23 18:44:14 [INFO]: Epoch 113 - generator training loss: -0.0827, discriminator training loss: 0.2049, validation loss: 0.0885
2024-05-23 18:44:17 [INFO]: Epoch 114 - generator training loss: -0.0824, discriminator training loss: 0.2042, validation loss: 0.0880
2024-05-23 18:44:21 [INFO]: Epoch 115 - generator training loss: -0.0826, discriminator training loss: 0.2039, validation loss: 0.0884
2024-05-23 18:44:24 [INFO]: Epoch 116 - generator training loss: -0.0836, discriminator training loss: 0.2043, validation loss: 0.0881
2024-05-23 18:44:28 [INFO]: Epoch 117 - generator training loss: -0.0842, discriminator training loss: 0.2037, validation loss: 0.0883
2024-05-23 18:44:32 [INFO]: Epoch 118 - generator training loss: -0.0834, discriminator training loss: 0.2035, validation loss: 0.0884
2024-05-23 18:44:35 [INFO]: Epoch 119 - generator training loss: -0.0836, discriminator training loss: 0.2034, validation loss: 0.0888
2024-05-23 18:44:39 [INFO]: Epoch 120 - generator training loss: -0.0839, discriminator training loss: 0.2038, validation loss: 0.0888
2024-05-23 18:44:42 [INFO]: Epoch 121 - generator training loss: -0.0834, discriminator training loss: 0.2034, validation loss: 0.0885
2024-05-23 18:44:46 [INFO]: Epoch 122 - generator training loss: -0.0838, discriminator training loss: 0.2042, validation loss: 0.0888
2024-05-23 18:44:49 [INFO]: Epoch 123 - generator training loss: -0.0848, discriminator training loss: 0.2034, validation loss: 0.0890
2024-05-23 18:44:53 [INFO]: Epoch 124 - generator training loss: -0.0844, discriminator training loss: 0.2033, validation loss: 0.0881
2024-05-23 18:44:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:44:53 [INFO]: Finished training. The best model is from epoch#114.
2024-05-23 18:44:53 [INFO]: Saved the model to overlay_premask_saved_results/round_1/USGAN_air_quality/20240523_T183754/USGAN.pypots
2024-05-23 18:44:53 [INFO]: US-GAN on Air-Quality: MAE=0.1518, MSE=0.1501
2024-05-23 18:44:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-23 18:44:53 [INFO]: Using the given device: cuda:0
2024-05-23 18:44:53 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240523_T184453
2024-05-23 18:44:53 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/BRITS_air_quality/20240523_T184453/tensorboard
2024-05-23 18:44:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 18:44:56 [INFO]: Epoch 001 - training loss: 1.4110, validation loss: 0.9235
2024-05-23 18:44:59 [INFO]: Epoch 002 - training loss: 1.1428, validation loss: 0.6696
2024-05-23 18:45:01 [INFO]: Epoch 003 - training loss: 0.9472, validation loss: 0.5568
2024-05-23 18:45:03 [INFO]: Epoch 004 - training loss: 0.8357, validation loss: 0.4871
2024-05-23 18:45:06 [INFO]: Epoch 005 - training loss: 0.7654, validation loss: 0.4432
2024-05-23 18:45:08 [INFO]: Epoch 006 - training loss: 0.7099, validation loss: 0.4060
2024-05-23 18:45:11 [INFO]: Epoch 007 - training loss: 0.6679, validation loss: 0.3779
2024-05-23 18:45:13 [INFO]: Epoch 008 - training loss: 0.6356, validation loss: 0.3545
2024-05-23 18:45:15 [INFO]: Epoch 009 - training loss: 0.6091, validation loss: 0.3367
2024-05-23 18:45:18 [INFO]: Epoch 010 - training loss: 0.5894, validation loss: 0.3212
2024-05-23 18:45:20 [INFO]: Epoch 011 - training loss: 0.5710, validation loss: 0.3082
2024-05-23 18:45:23 [INFO]: Epoch 012 - training loss: 0.5569, validation loss: 0.2968
2024-05-23 18:45:25 [INFO]: Epoch 013 - training loss: 0.5437, validation loss: 0.2869
2024-05-23 18:45:27 [INFO]: Epoch 014 - training loss: 0.5341, validation loss: 0.2780
2024-05-23 18:45:30 [INFO]: Epoch 015 - training loss: 0.5225, validation loss: 0.2703
2024-05-23 18:45:32 [INFO]: Epoch 016 - training loss: 0.5133, validation loss: 0.2630
2024-05-23 18:45:35 [INFO]: Epoch 017 - training loss: 0.5028, validation loss: 0.2570
2024-05-23 18:45:37 [INFO]: Epoch 018 - training loss: 0.4952, validation loss: 0.2511
2024-05-23 18:45:39 [INFO]: Epoch 019 - training loss: 0.4864, validation loss: 0.2455
2024-05-23 18:45:42 [INFO]: Epoch 020 - training loss: 0.4793, validation loss: 0.2401
2024-05-23 18:45:44 [INFO]: Epoch 021 - training loss: 0.4736, validation loss: 0.2361
2024-05-23 18:45:46 [INFO]: Epoch 022 - training loss: 0.4667, validation loss: 0.2311
2024-05-23 18:45:49 [INFO]: Epoch 023 - training loss: 0.4595, validation loss: 0.2275
2024-05-23 18:45:51 [INFO]: Epoch 024 - training loss: 0.4530, validation loss: 0.2234
2024-05-23 18:45:53 [INFO]: Epoch 025 - training loss: 0.4471, validation loss: 0.2193
2024-05-23 18:45:55 [INFO]: Epoch 026 - training loss: 0.4420, validation loss: 0.2159
2024-05-23 18:45:58 [INFO]: Epoch 027 - training loss: 0.4356, validation loss: 0.2125
2024-05-23 18:46:00 [INFO]: Epoch 028 - training loss: 0.4311, validation loss: 0.2089
2024-05-23 18:46:02 [INFO]: Epoch 029 - training loss: 0.4257, validation loss: 0.2055
2024-05-23 18:46:04 [INFO]: Epoch 030 - training loss: 0.4204, validation loss: 0.2024
2024-05-23 18:46:06 [INFO]: Epoch 031 - training loss: 0.4160, validation loss: 0.1992
2024-05-23 18:46:09 [INFO]: Epoch 032 - training loss: 0.4120, validation loss: 0.1960
2024-05-23 18:46:11 [INFO]: Epoch 033 - training loss: 0.4071, validation loss: 0.1934
2024-05-23 18:46:13 [INFO]: Epoch 034 - training loss: 0.4041, validation loss: 0.1906
2024-05-23 18:46:16 [INFO]: Epoch 035 - training loss: 0.4004, validation loss: 0.1877
2024-05-23 18:46:18 [INFO]: Epoch 036 - training loss: 0.3956, validation loss: 0.1847
2024-05-23 18:46:20 [INFO]: Epoch 037 - training loss: 0.3915, validation loss: 0.1822
2024-05-23 18:46:22 [INFO]: Epoch 038 - training loss: 0.3893, validation loss: 0.1798
2024-05-23 18:46:25 [INFO]: Epoch 039 - training loss: 0.3842, validation loss: 0.1770
2024-05-23 18:46:27 [INFO]: Epoch 040 - training loss: 0.3812, validation loss: 0.1751
2024-05-23 18:46:29 [INFO]: Epoch 041 - training loss: 0.3787, validation loss: 0.1725
2024-05-23 18:46:31 [INFO]: Epoch 042 - training loss: 0.3743, validation loss: 0.1704
2024-05-23 18:46:34 [INFO]: Epoch 043 - training loss: 0.3723, validation loss: 0.1684
2024-05-23 18:46:36 [INFO]: Epoch 044 - training loss: 0.3695, validation loss: 0.1664
2024-05-23 18:46:38 [INFO]: Epoch 045 - training loss: 0.3660, validation loss: 0.1646
2024-05-23 18:46:40 [INFO]: Epoch 046 - training loss: 0.3637, validation loss: 0.1627
2024-05-23 18:46:42 [INFO]: Epoch 047 - training loss: 0.3611, validation loss: 0.1610
2024-05-23 18:46:45 [INFO]: Epoch 048 - training loss: 0.3579, validation loss: 0.1597
2024-05-23 18:46:47 [INFO]: Epoch 049 - training loss: 0.3558, validation loss: 0.1580
2024-05-23 18:46:49 [INFO]: Epoch 050 - training loss: 0.3540, validation loss: 0.1564
2024-05-23 18:46:52 [INFO]: Epoch 051 - training loss: 0.3510, validation loss: 0.1552
2024-05-23 18:46:54 [INFO]: Epoch 052 - training loss: 0.3488, validation loss: 0.1536
2024-05-23 18:46:56 [INFO]: Epoch 053 - training loss: 0.3463, validation loss: 0.1525
2024-05-23 18:46:58 [INFO]: Epoch 054 - training loss: 0.3445, validation loss: 0.1515
2024-05-23 18:47:01 [INFO]: Epoch 055 - training loss: 0.3425, validation loss: 0.1503
2024-05-23 18:47:03 [INFO]: Epoch 056 - training loss: 0.3406, validation loss: 0.1492
2024-05-23 18:47:05 [INFO]: Epoch 057 - training loss: 0.3394, validation loss: 0.1482
2024-05-23 18:47:07 [INFO]: Epoch 058 - training loss: 0.3371, validation loss: 0.1473
2024-05-23 18:47:10 [INFO]: Epoch 059 - training loss: 0.3352, validation loss: 0.1463
2024-05-23 18:47:12 [INFO]: Epoch 060 - training loss: 0.3330, validation loss: 0.1451
2024-05-23 18:47:14 [INFO]: Epoch 061 - training loss: 0.3321, validation loss: 0.1447
2024-05-23 18:47:16 [INFO]: Epoch 062 - training loss: 0.3301, validation loss: 0.1438
2024-05-23 18:47:19 [INFO]: Epoch 063 - training loss: 0.3286, validation loss: 0.1428
2024-05-23 18:47:21 [INFO]: Epoch 064 - training loss: 0.3276, validation loss: 0.1422
2024-05-23 18:47:23 [INFO]: Epoch 065 - training loss: 0.3260, validation loss: 0.1413
2024-05-23 18:47:26 [INFO]: Epoch 066 - training loss: 0.3249, validation loss: 0.1407
2024-05-23 18:47:28 [INFO]: Epoch 067 - training loss: 0.3245, validation loss: 0.1399
2024-05-23 18:47:30 [INFO]: Epoch 068 - training loss: 0.3226, validation loss: 0.1393
2024-05-23 18:47:32 [INFO]: Epoch 069 - training loss: 0.3208, validation loss: 0.1387
2024-05-23 18:47:35 [INFO]: Epoch 070 - training loss: 0.3200, validation loss: 0.1381
2024-05-23 18:47:37 [INFO]: Epoch 071 - training loss: 0.3179, validation loss: 0.1373
2024-05-23 18:47:39 [INFO]: Epoch 072 - training loss: 0.3170, validation loss: 0.1368
2024-05-23 18:47:41 [INFO]: Epoch 073 - training loss: 0.3161, validation loss: 0.1363
2024-05-23 18:47:44 [INFO]: Epoch 074 - training loss: 0.3145, validation loss: 0.1357
2024-05-23 18:47:46 [INFO]: Epoch 075 - training loss: 0.3139, validation loss: 0.1352
2024-05-23 18:47:48 [INFO]: Epoch 076 - training loss: 0.3121, validation loss: 0.1347
2024-05-23 18:47:50 [INFO]: Epoch 077 - training loss: 0.3118, validation loss: 0.1341
2024-05-23 18:47:52 [INFO]: Epoch 078 - training loss: 0.3101, validation loss: 0.1335
2024-05-23 18:47:55 [INFO]: Epoch 079 - training loss: 0.3090, validation loss: 0.1330
2024-05-23 18:47:57 [INFO]: Epoch 080 - training loss: 0.3089, validation loss: 0.1328
2024-05-23 18:47:59 [INFO]: Epoch 081 - training loss: 0.3075, validation loss: 0.1323
2024-05-23 18:48:01 [INFO]: Epoch 082 - training loss: 0.3067, validation loss: 0.1317
2024-05-23 18:48:04 [INFO]: Epoch 083 - training loss: 0.3060, validation loss: 0.1315
2024-05-23 18:48:06 [INFO]: Epoch 084 - training loss: 0.3051, validation loss: 0.1309
2024-05-23 18:48:08 [INFO]: Epoch 085 - training loss: 0.3043, validation loss: 0.1305
2024-05-23 18:48:10 [INFO]: Epoch 086 - training loss: 0.3032, validation loss: 0.1299
2024-05-23 18:48:13 [INFO]: Epoch 087 - training loss: 0.3024, validation loss: 0.1295
2024-05-23 18:48:15 [INFO]: Epoch 088 - training loss: 0.3018, validation loss: 0.1292
2024-05-23 18:48:17 [INFO]: Epoch 089 - training loss: 0.3002, validation loss: 0.1288
2024-05-23 18:48:19 [INFO]: Epoch 090 - training loss: 0.3001, validation loss: 0.1284
2024-05-23 18:48:22 [INFO]: Epoch 091 - training loss: 0.2997, validation loss: 0.1279
2024-05-23 18:48:24 [INFO]: Epoch 092 - training loss: 0.2988, validation loss: 0.1275
2024-05-23 18:48:26 [INFO]: Epoch 093 - training loss: 0.2978, validation loss: 0.1270
2024-05-23 18:48:28 [INFO]: Epoch 094 - training loss: 0.2966, validation loss: 0.1269
2024-05-23 18:48:31 [INFO]: Epoch 095 - training loss: 0.2964, validation loss: 0.1265
2024-05-23 18:48:33 [INFO]: Epoch 096 - training loss: 0.2962, validation loss: 0.1260
2024-05-23 18:48:35 [INFO]: Epoch 097 - training loss: 0.2963, validation loss: 0.1257
2024-05-23 18:48:37 [INFO]: Epoch 098 - training loss: 0.2946, validation loss: 0.1253
2024-05-23 18:48:39 [INFO]: Epoch 099 - training loss: 0.2933, validation loss: 0.1249
2024-05-23 18:48:42 [INFO]: Epoch 100 - training loss: 0.2934, validation loss: 0.1244
2024-05-23 18:48:44 [INFO]: Epoch 101 - training loss: 0.2935, validation loss: 0.1243
2024-05-23 18:48:46 [INFO]: Epoch 102 - training loss: 0.2920, validation loss: 0.1239
2024-05-23 18:48:49 [INFO]: Epoch 103 - training loss: 0.2917, validation loss: 0.1235
2024-05-23 18:48:51 [INFO]: Epoch 104 - training loss: 0.2907, validation loss: 0.1233
2024-05-23 18:48:53 [INFO]: Epoch 105 - training loss: 0.2900, validation loss: 0.1228
2024-05-23 18:48:55 [INFO]: Epoch 106 - training loss: 0.2898, validation loss: 0.1226
2024-05-23 18:48:58 [INFO]: Epoch 107 - training loss: 0.2890, validation loss: 0.1222
2024-05-23 18:49:00 [INFO]: Epoch 108 - training loss: 0.2890, validation loss: 0.1221
2024-05-23 18:49:02 [INFO]: Epoch 109 - training loss: 0.2877, validation loss: 0.1216
2024-05-23 18:49:04 [INFO]: Epoch 110 - training loss: 0.2875, validation loss: 0.1211
2024-05-23 18:49:07 [INFO]: Epoch 111 - training loss: 0.2867, validation loss: 0.1210
2024-05-23 18:49:09 [INFO]: Epoch 112 - training loss: 0.2862, validation loss: 0.1205
2024-05-23 18:49:11 [INFO]: Epoch 113 - training loss: 0.2853, validation loss: 0.1202
2024-05-23 18:49:13 [INFO]: Epoch 114 - training loss: 0.2848, validation loss: 0.1201
2024-05-23 18:49:16 [INFO]: Epoch 115 - training loss: 0.2852, validation loss: 0.1197
2024-05-23 18:49:18 [INFO]: Epoch 116 - training loss: 0.2835, validation loss: 0.1197
2024-05-23 18:49:20 [INFO]: Epoch 117 - training loss: 0.2835, validation loss: 0.1190
2024-05-23 18:49:23 [INFO]: Epoch 118 - training loss: 0.2829, validation loss: 0.1187
2024-05-23 18:49:25 [INFO]: Epoch 119 - training loss: 0.2824, validation loss: 0.1184
2024-05-23 18:49:27 [INFO]: Epoch 120 - training loss: 0.2821, validation loss: 0.1181
2024-05-23 18:49:29 [INFO]: Epoch 121 - training loss: 0.2810, validation loss: 0.1181
2024-05-23 18:49:32 [INFO]: Epoch 122 - training loss: 0.2810, validation loss: 0.1176
2024-05-23 18:49:34 [INFO]: Epoch 123 - training loss: 0.2811, validation loss: 0.1173
2024-05-23 18:49:36 [INFO]: Epoch 124 - training loss: 0.2799, validation loss: 0.1170
2024-05-23 18:49:38 [INFO]: Epoch 125 - training loss: 0.2799, validation loss: 0.1168
2024-05-23 18:49:41 [INFO]: Epoch 126 - training loss: 0.2792, validation loss: 0.1164
2024-05-23 18:49:43 [INFO]: Epoch 127 - training loss: 0.2792, validation loss: 0.1161
2024-05-23 18:49:45 [INFO]: Epoch 128 - training loss: 0.2782, validation loss: 0.1159
2024-05-23 18:49:47 [INFO]: Epoch 129 - training loss: 0.2779, validation loss: 0.1157
2024-05-23 18:49:50 [INFO]: Epoch 130 - training loss: 0.2775, validation loss: 0.1153
2024-05-23 18:49:52 [INFO]: Epoch 131 - training loss: 0.2768, validation loss: 0.1150
2024-05-23 18:49:54 [INFO]: Epoch 132 - training loss: 0.2773, validation loss: 0.1146
2024-05-23 18:49:57 [INFO]: Epoch 133 - training loss: 0.2763, validation loss: 0.1143
2024-05-23 18:49:59 [INFO]: Epoch 134 - training loss: 0.2759, validation loss: 0.1142
2024-05-23 18:50:01 [INFO]: Epoch 135 - training loss: 0.2753, validation loss: 0.1139
2024-05-23 18:50:03 [INFO]: Epoch 136 - training loss: 0.2745, validation loss: 0.1138
2024-05-23 18:50:06 [INFO]: Epoch 137 - training loss: 0.2744, validation loss: 0.1133
2024-05-23 18:50:08 [INFO]: Epoch 138 - training loss: 0.2743, validation loss: 0.1131
2024-05-23 18:50:10 [INFO]: Epoch 139 - training loss: 0.2737, validation loss: 0.1129
2024-05-23 18:50:13 [INFO]: Epoch 140 - training loss: 0.2734, validation loss: 0.1126
2024-05-23 18:50:15 [INFO]: Epoch 141 - training loss: 0.2730, validation loss: 0.1123
2024-05-23 18:50:17 [INFO]: Epoch 142 - training loss: 0.2729, validation loss: 0.1121
2024-05-23 18:50:19 [INFO]: Epoch 143 - training loss: 0.2719, validation loss: 0.1119
2024-05-23 18:50:22 [INFO]: Epoch 144 - training loss: 0.2715, validation loss: 0.1115
2024-05-23 18:50:24 [INFO]: Epoch 145 - training loss: 0.2714, validation loss: 0.1114
2024-05-23 18:50:26 [INFO]: Epoch 146 - training loss: 0.2712, validation loss: 0.1112
2024-05-23 18:50:29 [INFO]: Epoch 147 - training loss: 0.2710, validation loss: 0.1109
2024-05-23 18:50:31 [INFO]: Epoch 148 - training loss: 0.2699, validation loss: 0.1107
2024-05-23 18:50:33 [INFO]: Epoch 149 - training loss: 0.2700, validation loss: 0.1103
2024-05-23 18:50:35 [INFO]: Epoch 150 - training loss: 0.2697, validation loss: 0.1101
2024-05-23 18:50:38 [INFO]: Epoch 151 - training loss: 0.2693, validation loss: 0.1100
2024-05-23 18:50:40 [INFO]: Epoch 152 - training loss: 0.2691, validation loss: 0.1098
2024-05-23 18:50:42 [INFO]: Epoch 153 - training loss: 0.2691, validation loss: 0.1095
2024-05-23 18:50:44 [INFO]: Epoch 154 - training loss: 0.2683, validation loss: 0.1094
2024-05-23 18:50:47 [INFO]: Epoch 155 - training loss: 0.2680, validation loss: 0.1092
2024-05-23 18:50:49 [INFO]: Epoch 156 - training loss: 0.2676, validation loss: 0.1088
2024-05-23 18:50:51 [INFO]: Epoch 157 - training loss: 0.2676, validation loss: 0.1088
2024-05-23 18:50:54 [INFO]: Epoch 158 - training loss: 0.2671, validation loss: 0.1085
2024-05-23 18:50:56 [INFO]: Epoch 159 - training loss: 0.2667, validation loss: 0.1082
2024-05-23 18:50:58 [INFO]: Epoch 160 - training loss: 0.2664, validation loss: 0.1080
2024-05-23 18:51:00 [INFO]: Epoch 161 - training loss: 0.2661, validation loss: 0.1079
2024-05-23 18:51:03 [INFO]: Epoch 162 - training loss: 0.2663, validation loss: 0.1078
2024-05-23 18:51:05 [INFO]: Epoch 163 - training loss: 0.2657, validation loss: 0.1075
2024-05-23 18:51:07 [INFO]: Epoch 164 - training loss: 0.2656, validation loss: 0.1074
2024-05-23 18:51:09 [INFO]: Epoch 165 - training loss: 0.2649, validation loss: 0.1072
2024-05-23 18:51:12 [INFO]: Epoch 166 - training loss: 0.2648, validation loss: 0.1069
2024-05-23 18:51:14 [INFO]: Epoch 167 - training loss: 0.2643, validation loss: 0.1068
2024-05-23 18:51:16 [INFO]: Epoch 168 - training loss: 0.2642, validation loss: 0.1069
2024-05-23 18:51:18 [INFO]: Epoch 169 - training loss: 0.2637, validation loss: 0.1064
2024-05-23 18:51:21 [INFO]: Epoch 170 - training loss: 0.2634, validation loss: 0.1061
2024-05-23 18:51:23 [INFO]: Epoch 171 - training loss: 0.2633, validation loss: 0.1059
2024-05-23 18:51:25 [INFO]: Epoch 172 - training loss: 0.2635, validation loss: 0.1057
2024-05-23 18:51:28 [INFO]: Epoch 173 - training loss: 0.2631, validation loss: 0.1056
2024-05-23 18:51:30 [INFO]: Epoch 174 - training loss: 0.2629, validation loss: 0.1055
2024-05-23 18:51:32 [INFO]: Epoch 175 - training loss: 0.2624, validation loss: 0.1053
2024-05-23 18:51:34 [INFO]: Epoch 176 - training loss: 0.2616, validation loss: 0.1053
2024-05-23 18:51:37 [INFO]: Epoch 177 - training loss: 0.2615, validation loss: 0.1050
2024-05-23 18:51:39 [INFO]: Epoch 178 - training loss: 0.2614, validation loss: 0.1048
2024-05-23 18:51:41 [INFO]: Epoch 179 - training loss: 0.2614, validation loss: 0.1047
2024-05-23 18:51:43 [INFO]: Epoch 180 - training loss: 0.2610, validation loss: 0.1045
2024-05-23 18:51:46 [INFO]: Epoch 181 - training loss: 0.2603, validation loss: 0.1045
2024-05-23 18:51:48 [INFO]: Epoch 182 - training loss: 0.2602, validation loss: 0.1042
2024-05-23 18:51:50 [INFO]: Epoch 183 - training loss: 0.2598, validation loss: 0.1040
2024-05-23 18:51:52 [INFO]: Epoch 184 - training loss: 0.2601, validation loss: 0.1038
2024-05-23 18:51:55 [INFO]: Epoch 185 - training loss: 0.2594, validation loss: 0.1037
2024-05-23 18:51:57 [INFO]: Epoch 186 - training loss: 0.2597, validation loss: 0.1036
2024-05-23 18:51:59 [INFO]: Epoch 187 - training loss: 0.2594, validation loss: 0.1035
2024-05-23 18:52:02 [INFO]: Epoch 188 - training loss: 0.2592, validation loss: 0.1034
2024-05-23 18:52:04 [INFO]: Epoch 189 - training loss: 0.2588, validation loss: 0.1031
2024-05-23 18:52:06 [INFO]: Epoch 190 - training loss: 0.2586, validation loss: 0.1027
2024-05-23 18:52:08 [INFO]: Epoch 191 - training loss: 0.2582, validation loss: 0.1028
2024-05-23 18:52:11 [INFO]: Epoch 192 - training loss: 0.2587, validation loss: 0.1026
2024-05-23 18:52:13 [INFO]: Epoch 193 - training loss: 0.2577, validation loss: 0.1024
2024-05-23 18:52:15 [INFO]: Epoch 194 - training loss: 0.2575, validation loss: 0.1024
2024-05-23 18:52:18 [INFO]: Epoch 195 - training loss: 0.2573, validation loss: 0.1023
2024-05-23 18:52:20 [INFO]: Epoch 196 - training loss: 0.2569, validation loss: 0.1022
2024-05-23 18:52:22 [INFO]: Epoch 197 - training loss: 0.2572, validation loss: 0.1022
2024-05-23 18:52:24 [INFO]: Epoch 198 - training loss: 0.2567, validation loss: 0.1019
2024-05-23 18:52:27 [INFO]: Epoch 199 - training loss: 0.2567, validation loss: 0.1016
2024-05-23 18:52:29 [INFO]: Epoch 200 - training loss: 0.2560, validation loss: 0.1018
2024-05-23 18:52:31 [INFO]: Epoch 201 - training loss: 0.2565, validation loss: 0.1016
2024-05-23 18:52:33 [INFO]: Epoch 202 - training loss: 0.2557, validation loss: 0.1014
2024-05-23 18:52:36 [INFO]: Epoch 203 - training loss: 0.2560, validation loss: 0.1015
2024-05-23 18:52:38 [INFO]: Epoch 204 - training loss: 0.2551, validation loss: 0.1012
2024-05-23 18:52:40 [INFO]: Epoch 205 - training loss: 0.2548, validation loss: 0.1012
2024-05-23 18:52:42 [INFO]: Epoch 206 - training loss: 0.2553, validation loss: 0.1010
2024-05-23 18:52:45 [INFO]: Epoch 207 - training loss: 0.2550, validation loss: 0.1008
2024-05-23 18:52:47 [INFO]: Epoch 208 - training loss: 0.2547, validation loss: 0.1006
2024-05-23 18:52:49 [INFO]: Epoch 209 - training loss: 0.2545, validation loss: 0.1006
2024-05-23 18:52:51 [INFO]: Epoch 210 - training loss: 0.2537, validation loss: 0.1005
2024-05-23 18:52:54 [INFO]: Epoch 211 - training loss: 0.2539, validation loss: 0.1003
2024-05-23 18:52:56 [INFO]: Epoch 212 - training loss: 0.2541, validation loss: 0.1003
2024-05-23 18:52:58 [INFO]: Epoch 213 - training loss: 0.2537, validation loss: 0.1001
2024-05-23 18:53:01 [INFO]: Epoch 214 - training loss: 0.2535, validation loss: 0.1001
2024-05-23 18:53:03 [INFO]: Epoch 215 - training loss: 0.2529, validation loss: 0.1000
2024-05-23 18:53:05 [INFO]: Epoch 216 - training loss: 0.2529, validation loss: 0.0998
2024-05-23 18:53:07 [INFO]: Epoch 217 - training loss: 0.2526, validation loss: 0.0997
2024-05-23 18:53:10 [INFO]: Epoch 218 - training loss: 0.2527, validation loss: 0.0996
2024-05-23 18:53:12 [INFO]: Epoch 219 - training loss: 0.2527, validation loss: 0.0995
2024-05-23 18:53:14 [INFO]: Epoch 220 - training loss: 0.2524, validation loss: 0.0992
2024-05-23 18:53:16 [INFO]: Epoch 221 - training loss: 0.2522, validation loss: 0.0993
2024-05-23 18:53:19 [INFO]: Epoch 222 - training loss: 0.2518, validation loss: 0.0990
2024-05-23 18:53:21 [INFO]: Epoch 223 - training loss: 0.2519, validation loss: 0.0990
2024-05-23 18:53:23 [INFO]: Epoch 224 - training loss: 0.2516, validation loss: 0.0989
2024-05-23 18:53:25 [INFO]: Epoch 225 - training loss: 0.2511, validation loss: 0.0989
2024-05-23 18:53:28 [INFO]: Epoch 226 - training loss: 0.2515, validation loss: 0.0987
2024-05-23 18:53:30 [INFO]: Epoch 227 - training loss: 0.2510, validation loss: 0.0987
2024-05-23 18:53:32 [INFO]: Epoch 228 - training loss: 0.2509, validation loss: 0.0986
2024-05-23 18:53:35 [INFO]: Epoch 229 - training loss: 0.2506, validation loss: 0.0987
2024-05-23 18:53:37 [INFO]: Epoch 230 - training loss: 0.2504, validation loss: 0.0984
2024-05-23 18:53:39 [INFO]: Epoch 231 - training loss: 0.2506, validation loss: 0.0983
2024-05-23 18:53:41 [INFO]: Epoch 232 - training loss: 0.2505, validation loss: 0.0981
2024-05-23 18:53:44 [INFO]: Epoch 233 - training loss: 0.2498, validation loss: 0.0980
2024-05-23 18:53:46 [INFO]: Epoch 234 - training loss: 0.2497, validation loss: 0.0981
2024-05-23 18:53:48 [INFO]: Epoch 235 - training loss: 0.2497, validation loss: 0.0980
2024-05-23 18:53:50 [INFO]: Epoch 236 - training loss: 0.2493, validation loss: 0.0978
2024-05-23 18:53:53 [INFO]: Epoch 237 - training loss: 0.2494, validation loss: 0.0978
2024-05-23 18:53:55 [INFO]: Epoch 238 - training loss: 0.2491, validation loss: 0.0979
2024-05-23 18:53:57 [INFO]: Epoch 239 - training loss: 0.2491, validation loss: 0.0975
2024-05-23 18:54:00 [INFO]: Epoch 240 - training loss: 0.2494, validation loss: 0.0976
2024-05-23 18:54:02 [INFO]: Epoch 241 - training loss: 0.2484, validation loss: 0.0973
2024-05-23 18:54:04 [INFO]: Epoch 242 - training loss: 0.2484, validation loss: 0.0974
2024-05-23 18:54:06 [INFO]: Epoch 243 - training loss: 0.2479, validation loss: 0.0971
2024-05-23 18:54:09 [INFO]: Epoch 244 - training loss: 0.2485, validation loss: 0.0971
2024-05-23 18:54:11 [INFO]: Epoch 245 - training loss: 0.2479, validation loss: 0.0975
2024-05-23 18:54:13 [INFO]: Epoch 246 - training loss: 0.2480, validation loss: 0.0970
2024-05-23 18:54:15 [INFO]: Epoch 247 - training loss: 0.2479, validation loss: 0.0971
2024-05-23 18:54:18 [INFO]: Epoch 248 - training loss: 0.2479, validation loss: 0.0970
2024-05-23 18:54:20 [INFO]: Epoch 249 - training loss: 0.2474, validation loss: 0.0969
2024-05-23 18:54:22 [INFO]: Epoch 250 - training loss: 0.2469, validation loss: 0.0968
2024-05-23 18:54:24 [INFO]: Epoch 251 - training loss: 0.2471, validation loss: 0.0967
2024-05-23 18:54:27 [INFO]: Epoch 252 - training loss: 0.2467, validation loss: 0.0966
2024-05-23 18:54:29 [INFO]: Epoch 253 - training loss: 0.2466, validation loss: 0.0966
2024-05-23 18:54:31 [INFO]: Epoch 254 - training loss: 0.2464, validation loss: 0.0966
2024-05-23 18:54:33 [INFO]: Epoch 255 - training loss: 0.2461, validation loss: 0.0964
2024-05-23 18:54:36 [INFO]: Epoch 256 - training loss: 0.2464, validation loss: 0.0964
2024-05-23 18:54:38 [INFO]: Epoch 257 - training loss: 0.2462, validation loss: 0.0964
2024-05-23 18:54:41 [INFO]: Epoch 258 - training loss: 0.2461, validation loss: 0.0963
2024-05-23 18:54:43 [INFO]: Epoch 259 - training loss: 0.2461, validation loss: 0.0963
2024-05-23 18:54:45 [INFO]: Epoch 260 - training loss: 0.2459, validation loss: 0.0961
2024-05-23 18:54:48 [INFO]: Epoch 261 - training loss: 0.2455, validation loss: 0.0960
2024-05-23 18:54:50 [INFO]: Epoch 262 - training loss: 0.2453, validation loss: 0.0963
2024-05-23 18:54:52 [INFO]: Epoch 263 - training loss: 0.2454, validation loss: 0.0960
2024-05-23 18:54:55 [INFO]: Epoch 264 - training loss: 0.2452, validation loss: 0.0959
2024-05-23 18:54:57 [INFO]: Epoch 265 - training loss: 0.2453, validation loss: 0.0957
2024-05-23 18:54:59 [INFO]: Epoch 266 - training loss: 0.2447, validation loss: 0.0959
2024-05-23 18:55:01 [INFO]: Epoch 267 - training loss: 0.2448, validation loss: 0.0957
2024-05-23 18:55:04 [INFO]: Epoch 268 - training loss: 0.2446, validation loss: 0.0956
2024-05-23 18:55:06 [INFO]: Epoch 269 - training loss: 0.2447, validation loss: 0.0958
2024-05-23 18:55:08 [INFO]: Epoch 270 - training loss: 0.2443, validation loss: 0.0955
2024-05-23 18:55:10 [INFO]: Epoch 271 - training loss: 0.2444, validation loss: 0.0957
2024-05-23 18:55:13 [INFO]: Epoch 272 - training loss: 0.2442, validation loss: 0.0955
2024-05-23 18:55:15 [INFO]: Epoch 273 - training loss: 0.2438, validation loss: 0.0955
2024-05-23 18:55:17 [INFO]: Epoch 274 - training loss: 0.2439, validation loss: 0.0955
2024-05-23 18:55:20 [INFO]: Epoch 275 - training loss: 0.2436, validation loss: 0.0953
2024-05-23 18:55:22 [INFO]: Epoch 276 - training loss: 0.2440, validation loss: 0.0955
2024-05-23 18:55:24 [INFO]: Epoch 277 - training loss: 0.2440, validation loss: 0.0953
2024-05-23 18:55:26 [INFO]: Epoch 278 - training loss: 0.2430, validation loss: 0.0953
2024-05-23 18:55:29 [INFO]: Epoch 279 - training loss: 0.2433, validation loss: 0.0951
2024-05-23 18:55:31 [INFO]: Epoch 280 - training loss: 0.2428, validation loss: 0.0951
2024-05-23 18:55:33 [INFO]: Epoch 281 - training loss: 0.2434, validation loss: 0.0951
2024-05-23 18:55:36 [INFO]: Epoch 282 - training loss: 0.2430, validation loss: 0.0949
2024-05-23 18:55:38 [INFO]: Epoch 283 - training loss: 0.2429, validation loss: 0.0950
2024-05-23 18:55:40 [INFO]: Epoch 284 - training loss: 0.2423, validation loss: 0.0949
2024-05-23 18:55:42 [INFO]: Epoch 285 - training loss: 0.2425, validation loss: 0.0948
2024-05-23 18:55:45 [INFO]: Epoch 286 - training loss: 0.2420, validation loss: 0.0951
2024-05-23 18:55:47 [INFO]: Epoch 287 - training loss: 0.2421, validation loss: 0.0949
2024-05-23 18:55:49 [INFO]: Epoch 288 - training loss: 0.2422, validation loss: 0.0948
2024-05-23 18:55:51 [INFO]: Epoch 289 - training loss: 0.2416, validation loss: 0.0948
2024-05-23 18:55:54 [INFO]: Epoch 290 - training loss: 0.2424, validation loss: 0.0947
2024-05-23 18:55:56 [INFO]: Epoch 291 - training loss: 0.2418, validation loss: 0.0946
2024-05-23 18:55:58 [INFO]: Epoch 292 - training loss: 0.2419, validation loss: 0.0946
2024-05-23 18:56:01 [INFO]: Epoch 293 - training loss: 0.2416, validation loss: 0.0946
2024-05-23 18:56:03 [INFO]: Epoch 294 - training loss: 0.2411, validation loss: 0.0946
2024-05-23 18:56:05 [INFO]: Epoch 295 - training loss: 0.2410, validation loss: 0.0944
2024-05-23 18:56:07 [INFO]: Epoch 296 - training loss: 0.2414, validation loss: 0.0946
2024-05-23 18:56:10 [INFO]: Epoch 297 - training loss: 0.2409, validation loss: 0.0945
2024-05-23 18:56:12 [INFO]: Epoch 298 - training loss: 0.2408, validation loss: 0.0945
2024-05-23 18:56:14 [INFO]: Epoch 299 - training loss: 0.2412, validation loss: 0.0944
2024-05-23 18:56:16 [INFO]: Epoch 300 - training loss: 0.2408, validation loss: 0.0946
2024-05-23 18:56:16 [INFO]: Finished training. The best model is from epoch#299.
2024-05-23 18:56:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/BRITS_air_quality/20240523_T184453/BRITS.pypots
2024-05-23 18:56:17 [INFO]: BRITS on Air-Quality: MAE=0.1437, MSE=0.1587
2024-05-23 18:56:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-23 18:56:17 [INFO]: Using the given device: cuda:0
2024-05-23 18:56:17 [INFO]: Model files will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617
2024-05-23 18:56:17 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/tensorboard
2024-05-23 18:56:17 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 18:56:21 [INFO]: Epoch 001 - training loss: 1.4084, validation loss: 0.7780
2024-05-23 18:56:21 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch1_loss0.7780011624097825.pypots
2024-05-23 18:56:24 [INFO]: Epoch 002 - training loss: 1.0311, validation loss: 0.7182
2024-05-23 18:56:24 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch2_loss0.7182046473026276.pypots
2024-05-23 18:56:27 [INFO]: Epoch 003 - training loss: 0.9601, validation loss: 0.6983
2024-05-23 18:56:27 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch3_loss0.6983171910047531.pypots
2024-05-23 18:56:30 [INFO]: Epoch 004 - training loss: 0.9283, validation loss: 0.6852
2024-05-23 18:56:30 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch4_loss0.6851752877235413.pypots
2024-05-23 18:56:33 [INFO]: Epoch 005 - training loss: 0.9263, validation loss: 0.6759
2024-05-23 18:56:33 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch5_loss0.6758553892374038.pypots
2024-05-23 18:56:36 [INFO]: Epoch 006 - training loss: 0.9169, validation loss: 0.6688
2024-05-23 18:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch6_loss0.6688150495290757.pypots
2024-05-23 18:56:39 [INFO]: Epoch 007 - training loss: 0.9060, validation loss: 0.6631
2024-05-23 18:56:39 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch7_loss0.6631228119134903.pypots
2024-05-23 18:56:42 [INFO]: Epoch 008 - training loss: 0.8874, validation loss: 0.6589
2024-05-23 18:56:42 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch8_loss0.6589432060718536.pypots
2024-05-23 18:56:45 [INFO]: Epoch 009 - training loss: 0.8850, validation loss: 0.6562
2024-05-23 18:56:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch9_loss0.6562001913785934.pypots
2024-05-23 18:56:49 [INFO]: Epoch 010 - training loss: 0.8800, validation loss: 0.6535
2024-05-23 18:56:49 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch10_loss0.6534981340169906.pypots
2024-05-23 18:56:52 [INFO]: Epoch 011 - training loss: 0.8939, validation loss: 0.6516
2024-05-23 18:56:52 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch11_loss0.6516099900007248.pypots
2024-05-23 18:56:55 [INFO]: Epoch 012 - training loss: 0.8865, validation loss: 0.6508
2024-05-23 18:56:55 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch12_loss0.6507969200611115.pypots
2024-05-23 18:56:58 [INFO]: Epoch 013 - training loss: 0.8760, validation loss: 0.6499
2024-05-23 18:56:58 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch13_loss0.6499001920223236.pypots
2024-05-23 18:57:01 [INFO]: Epoch 014 - training loss: 0.8667, validation loss: 0.6472
2024-05-23 18:57:01 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch14_loss0.6471619248390198.pypots
2024-05-23 18:57:04 [INFO]: Epoch 015 - training loss: 0.8510, validation loss: 0.6483
2024-05-23 18:57:04 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch15_loss0.6482792049646378.pypots
2024-05-23 18:57:07 [INFO]: Epoch 016 - training loss: 0.8591, validation loss: 0.6468
2024-05-23 18:57:07 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch16_loss0.6467575848102569.pypots
2024-05-23 18:57:10 [INFO]: Epoch 017 - training loss: 0.8535, validation loss: 0.6465
2024-05-23 18:57:10 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch17_loss0.6464907407760621.pypots
2024-05-23 18:57:13 [INFO]: Epoch 018 - training loss: 0.8437, validation loss: 0.6451
2024-05-23 18:57:13 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch18_loss0.6451319873332977.pypots
2024-05-23 18:57:17 [INFO]: Epoch 019 - training loss: 0.8585, validation loss: 0.6465
2024-05-23 18:57:17 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch19_loss0.6464971244335175.pypots
2024-05-23 18:57:20 [INFO]: Epoch 020 - training loss: 0.8618, validation loss: 0.6427
2024-05-23 18:57:20 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch20_loss0.6427476167678833.pypots
2024-05-23 18:57:23 [INFO]: Epoch 021 - training loss: 0.8603, validation loss: 0.6430
2024-05-23 18:57:23 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch21_loss0.643015468120575.pypots
2024-05-23 18:57:26 [INFO]: Epoch 022 - training loss: 0.8388, validation loss: 0.6430
2024-05-23 18:57:26 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch22_loss0.6430307745933532.pypots
2024-05-23 18:57:29 [INFO]: Epoch 023 - training loss: 0.8482, validation loss: 0.6438
2024-05-23 18:57:29 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch23_loss0.6437682002782822.pypots
2024-05-23 18:57:32 [INFO]: Epoch 024 - training loss: 0.8414, validation loss: 0.6473
2024-05-23 18:57:32 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch24_loss0.6472937196493149.pypots
2024-05-23 18:57:35 [INFO]: Epoch 025 - training loss: 0.8532, validation loss: 0.6456
2024-05-23 18:57:35 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch25_loss0.6455599665641785.pypots
2024-05-23 18:57:38 [INFO]: Epoch 026 - training loss: 0.8476, validation loss: 0.6422
2024-05-23 18:57:38 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch26_loss0.6421959966421127.pypots
2024-05-23 18:57:41 [INFO]: Epoch 027 - training loss: 0.8346, validation loss: 0.6441
2024-05-23 18:57:41 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch27_loss0.6441023588180542.pypots
2024-05-23 18:57:45 [INFO]: Epoch 028 - training loss: 0.8236, validation loss: 0.6443
2024-05-23 18:57:45 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch28_loss0.6442600369453431.pypots
2024-05-23 18:57:48 [INFO]: Epoch 029 - training loss: 0.8118, validation loss: 0.6446
2024-05-23 18:57:48 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch29_loss0.6446310639381408.pypots
2024-05-23 18:57:51 [INFO]: Epoch 030 - training loss: 0.8137, validation loss: 0.6443
2024-05-23 18:57:51 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch30_loss0.6443364948034287.pypots
2024-05-23 18:57:54 [INFO]: Epoch 031 - training loss: 0.8230, validation loss: 0.6443
2024-05-23 18:57:54 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch31_loss0.6443261921405792.pypots
2024-05-23 18:57:57 [INFO]: Epoch 032 - training loss: 0.8212, validation loss: 0.6436
2024-05-23 18:57:57 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch32_loss0.6435671150684357.pypots
2024-05-23 18:58:00 [INFO]: Epoch 033 - training loss: 0.8158, validation loss: 0.6446
2024-05-23 18:58:00 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch33_loss0.6446406215429306.pypots
2024-05-23 18:58:03 [INFO]: Epoch 034 - training loss: 0.8082, validation loss: 0.6440
2024-05-23 18:58:03 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch34_loss0.6440379649400712.pypots
2024-05-23 18:58:06 [INFO]: Epoch 035 - training loss: 0.8375, validation loss: 0.6415
2024-05-23 18:58:06 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch35_loss0.6414642214775086.pypots
2024-05-23 18:58:09 [INFO]: Epoch 036 - training loss: 0.8445, validation loss: 0.6465
2024-05-23 18:58:09 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch36_loss0.646451273560524.pypots
2024-05-23 18:58:12 [INFO]: Epoch 037 - training loss: 0.8110, validation loss: 0.6462
2024-05-23 18:58:12 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch37_loss0.6461787253618241.pypots
2024-05-23 18:58:16 [INFO]: Epoch 038 - training loss: 0.8066, validation loss: 0.6456
2024-05-23 18:58:16 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch38_loss0.6456449449062347.pypots
2024-05-23 18:58:19 [INFO]: Epoch 039 - training loss: 0.8200, validation loss: 0.6453
2024-05-23 18:58:19 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch39_loss0.6452604502439498.pypots
2024-05-23 18:58:22 [INFO]: Epoch 040 - training loss: 0.8289, validation loss: 0.6451
2024-05-23 18:58:22 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch40_loss0.6450672566890716.pypots
2024-05-23 18:58:25 [INFO]: Epoch 041 - training loss: 0.8094, validation loss: 0.6469
2024-05-23 18:58:25 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch41_loss0.646916851401329.pypots
2024-05-23 18:58:28 [INFO]: Epoch 042 - training loss: 0.7958, validation loss: 0.6483
2024-05-23 18:58:28 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch42_loss0.6483389019966126.pypots
2024-05-23 18:58:31 [INFO]: Epoch 043 - training loss: 0.7962, validation loss: 0.6450
2024-05-23 18:58:31 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch43_loss0.6449790060520172.pypots
2024-05-23 18:58:34 [INFO]: Epoch 044 - training loss: 0.7929, validation loss: 0.6501
2024-05-23 18:58:34 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch44_loss0.6501062750816345.pypots
2024-05-23 18:58:37 [INFO]: Epoch 045 - training loss: 0.7890, validation loss: 0.6468
2024-05-23 18:58:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN_epoch45_loss0.6467854678630829.pypots
2024-05-23 18:58:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 18:58:37 [INFO]: Finished training. The best model is from epoch#35.
2024-05-23 18:58:37 [INFO]: Saved the model to overlay_premask_saved_results/round_1/MRNN_air_quality/20240523_T185617/MRNN.pypots
2024-05-23 18:58:38 [INFO]: MRNN on Air-Quality: MAE=0.5220, MSE=0.6936
2024-05-23 18:58:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-23 18:58:38 [INFO]: Using the given device: cpu
2024-05-23 18:58:38 [INFO]: LOCF on Air-Quality: MAE=0.2090, MSE=0.3758
2024-05-23 18:58:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-23 18:58:38 [INFO]: Median on Air-Quality: MAE=0.6658, MSE=1.0901
2024-05-23 18:58:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-23 18:58:38 [INFO]: Mean on Air-Quality: MAE=0.6970, MSE=1.0309
2024-05-23 18:58:38 [INFO]: Successfully saved to overlay_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-23 18:58:38 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-23 18:58:38 [INFO]: Using the given device: cuda:0
2024-05-23 18:58:38 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240523_T185838
2024-05-23 18:58:38 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/SAITS_air_quality/20240523_T185838/tensorboard
2024-05-23 18:58:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 18:58:39 [INFO]: Epoch 001 - training loss: 1.0421, validation loss: 0.4900
2024-05-23 18:58:39 [INFO]: Epoch 002 - training loss: 0.7489, validation loss: 0.3570
2024-05-23 18:58:40 [INFO]: Epoch 003 - training loss: 0.6431, validation loss: 0.2860
2024-05-23 18:58:40 [INFO]: Epoch 004 - training loss: 0.5666, validation loss: 0.2503
2024-05-23 18:58:41 [INFO]: Epoch 005 - training loss: 0.5122, validation loss: 0.2298
2024-05-23 18:58:42 [INFO]: Epoch 006 - training loss: 0.4762, validation loss: 0.2154
2024-05-23 18:58:42 [INFO]: Epoch 007 - training loss: 0.4493, validation loss: 0.2042
2024-05-23 18:58:43 [INFO]: Epoch 008 - training loss: 0.4301, validation loss: 0.1977
2024-05-23 18:58:43 [INFO]: Epoch 009 - training loss: 0.4162, validation loss: 0.1913
2024-05-23 18:58:44 [INFO]: Epoch 010 - training loss: 0.4039, validation loss: 0.1881
2024-05-23 18:58:45 [INFO]: Epoch 011 - training loss: 0.3964, validation loss: 0.1842
2024-05-23 18:58:45 [INFO]: Epoch 012 - training loss: 0.3863, validation loss: 0.1784
2024-05-23 18:58:46 [INFO]: Epoch 013 - training loss: 0.3776, validation loss: 0.1746
2024-05-23 18:58:46 [INFO]: Epoch 014 - training loss: 0.3696, validation loss: 0.1730
2024-05-23 18:58:47 [INFO]: Epoch 015 - training loss: 0.3640, validation loss: 0.1697
2024-05-23 18:58:47 [INFO]: Epoch 016 - training loss: 0.3594, validation loss: 0.1682
2024-05-23 18:58:48 [INFO]: Epoch 017 - training loss: 0.3533, validation loss: 0.1645
2024-05-23 18:58:49 [INFO]: Epoch 018 - training loss: 0.3492, validation loss: 0.1641
2024-05-23 18:58:49 [INFO]: Epoch 019 - training loss: 0.3442, validation loss: 0.1603
2024-05-23 18:58:50 [INFO]: Epoch 020 - training loss: 0.3395, validation loss: 0.1591
2024-05-23 18:58:50 [INFO]: Epoch 021 - training loss: 0.3350, validation loss: 0.1567
2024-05-23 18:58:51 [INFO]: Epoch 022 - training loss: 0.3319, validation loss: 0.1562
2024-05-23 18:58:52 [INFO]: Epoch 023 - training loss: 0.3278, validation loss: 0.1530
2024-05-23 18:58:52 [INFO]: Epoch 024 - training loss: 0.3249, validation loss: 0.1522
2024-05-23 18:58:53 [INFO]: Epoch 025 - training loss: 0.3221, validation loss: 0.1515
2024-05-23 18:58:53 [INFO]: Epoch 026 - training loss: 0.3200, validation loss: 0.1495
2024-05-23 18:58:54 [INFO]: Epoch 027 - training loss: 0.3161, validation loss: 0.1499
2024-05-23 18:58:54 [INFO]: Epoch 028 - training loss: 0.3131, validation loss: 0.1479
2024-05-23 18:58:55 [INFO]: Epoch 029 - training loss: 0.3104, validation loss: 0.1473
2024-05-23 18:58:56 [INFO]: Epoch 030 - training loss: 0.3086, validation loss: 0.1454
2024-05-23 18:58:56 [INFO]: Epoch 031 - training loss: 0.3049, validation loss: 0.1437
2024-05-23 18:58:57 [INFO]: Epoch 032 - training loss: 0.3042, validation loss: 0.1437
2024-05-23 18:58:57 [INFO]: Epoch 033 - training loss: 0.3014, validation loss: 0.1413
2024-05-23 18:58:58 [INFO]: Epoch 034 - training loss: 0.2993, validation loss: 0.1410
2024-05-23 18:58:59 [INFO]: Epoch 035 - training loss: 0.2965, validation loss: 0.1392
2024-05-23 18:58:59 [INFO]: Epoch 036 - training loss: 0.2942, validation loss: 0.1382
2024-05-23 18:59:00 [INFO]: Epoch 037 - training loss: 0.2931, validation loss: 0.1365
2024-05-23 18:59:00 [INFO]: Epoch 038 - training loss: 0.2912, validation loss: 0.1366
2024-05-23 18:59:01 [INFO]: Epoch 039 - training loss: 0.2888, validation loss: 0.1350
2024-05-23 18:59:01 [INFO]: Epoch 040 - training loss: 0.2864, validation loss: 0.1346
2024-05-23 18:59:02 [INFO]: Epoch 041 - training loss: 0.2861, validation loss: 0.1335
2024-05-23 18:59:03 [INFO]: Epoch 042 - training loss: 0.2829, validation loss: 0.1326
2024-05-23 18:59:03 [INFO]: Epoch 043 - training loss: 0.2817, validation loss: 0.1303
2024-05-23 18:59:04 [INFO]: Epoch 044 - training loss: 0.2799, validation loss: 0.1311
2024-05-23 18:59:04 [INFO]: Epoch 045 - training loss: 0.2783, validation loss: 0.1304
2024-05-23 18:59:05 [INFO]: Epoch 046 - training loss: 0.2750, validation loss: 0.1294
2024-05-23 18:59:06 [INFO]: Epoch 047 - training loss: 0.2759, validation loss: 0.1275
2024-05-23 18:59:06 [INFO]: Epoch 048 - training loss: 0.2748, validation loss: 0.1273
2024-05-23 18:59:07 [INFO]: Epoch 049 - training loss: 0.2724, validation loss: 0.1269
2024-05-23 18:59:07 [INFO]: Epoch 050 - training loss: 0.2701, validation loss: 0.1253
2024-05-23 18:59:08 [INFO]: Epoch 051 - training loss: 0.2685, validation loss: 0.1260
2024-05-23 18:59:08 [INFO]: Epoch 052 - training loss: 0.2661, validation loss: 0.1249
2024-05-23 18:59:09 [INFO]: Epoch 053 - training loss: 0.2644, validation loss: 0.1233
2024-05-23 18:59:10 [INFO]: Epoch 054 - training loss: 0.2643, validation loss: 0.1239
2024-05-23 18:59:10 [INFO]: Epoch 055 - training loss: 0.2620, validation loss: 0.1218
2024-05-23 18:59:11 [INFO]: Epoch 056 - training loss: 0.2600, validation loss: 0.1220
2024-05-23 18:59:11 [INFO]: Epoch 057 - training loss: 0.2596, validation loss: 0.1221
2024-05-23 18:59:12 [INFO]: Epoch 058 - training loss: 0.2571, validation loss: 0.1204
2024-05-23 18:59:13 [INFO]: Epoch 059 - training loss: 0.2566, validation loss: 0.1196
2024-05-23 18:59:13 [INFO]: Epoch 060 - training loss: 0.2555, validation loss: 0.1192
2024-05-23 18:59:14 [INFO]: Epoch 061 - training loss: 0.2539, validation loss: 0.1188
2024-05-23 18:59:14 [INFO]: Epoch 062 - training loss: 0.2520, validation loss: 0.1182
2024-05-23 18:59:15 [INFO]: Epoch 063 - training loss: 0.2511, validation loss: 0.1172
2024-05-23 18:59:15 [INFO]: Epoch 064 - training loss: 0.2488, validation loss: 0.1176
2024-05-23 18:59:16 [INFO]: Epoch 065 - training loss: 0.2473, validation loss: 0.1174
2024-05-23 18:59:17 [INFO]: Epoch 066 - training loss: 0.2476, validation loss: 0.1166
2024-05-23 18:59:17 [INFO]: Epoch 067 - training loss: 0.2461, validation loss: 0.1159
2024-05-23 18:59:18 [INFO]: Epoch 068 - training loss: 0.2451, validation loss: 0.1153
2024-05-23 18:59:18 [INFO]: Epoch 069 - training loss: 0.2430, validation loss: 0.1175
2024-05-23 18:59:19 [INFO]: Epoch 070 - training loss: 0.2432, validation loss: 0.1151
2024-05-23 18:59:19 [INFO]: Epoch 071 - training loss: 0.2420, validation loss: 0.1148
2024-05-23 18:59:20 [INFO]: Epoch 072 - training loss: 0.2415, validation loss: 0.1150
2024-05-23 18:59:21 [INFO]: Epoch 073 - training loss: 0.2397, validation loss: 0.1148
2024-05-23 18:59:21 [INFO]: Epoch 074 - training loss: 0.2388, validation loss: 0.1134
2024-05-23 18:59:22 [INFO]: Epoch 075 - training loss: 0.2374, validation loss: 0.1128
2024-05-23 18:59:22 [INFO]: Epoch 076 - training loss: 0.2351, validation loss: 0.1122
2024-05-23 18:59:23 [INFO]: Epoch 077 - training loss: 0.2356, validation loss: 0.1130
2024-05-23 18:59:24 [INFO]: Epoch 078 - training loss: 0.2342, validation loss: 0.1132
2024-05-23 18:59:24 [INFO]: Epoch 079 - training loss: 0.2338, validation loss: 0.1127
2024-05-23 18:59:25 [INFO]: Epoch 080 - training loss: 0.2321, validation loss: 0.1122
2024-05-23 18:59:25 [INFO]: Epoch 081 - training loss: 0.2310, validation loss: 0.1112
2024-05-23 18:59:26 [INFO]: Epoch 082 - training loss: 0.2317, validation loss: 0.1114
2024-05-23 18:59:26 [INFO]: Epoch 083 - training loss: 0.2304, validation loss: 0.1110
2024-05-23 18:59:27 [INFO]: Epoch 084 - training loss: 0.2295, validation loss: 0.1118
2024-05-23 18:59:28 [INFO]: Epoch 085 - training loss: 0.2290, validation loss: 0.1109
2024-05-23 18:59:28 [INFO]: Epoch 086 - training loss: 0.2285, validation loss: 0.1114
2024-05-23 18:59:29 [INFO]: Epoch 087 - training loss: 0.2277, validation loss: 0.1109
2024-05-23 18:59:29 [INFO]: Epoch 088 - training loss: 0.2265, validation loss: 0.1104
2024-05-23 18:59:30 [INFO]: Epoch 089 - training loss: 0.2255, validation loss: 0.1103
2024-05-23 18:59:31 [INFO]: Epoch 090 - training loss: 0.2243, validation loss: 0.1092
2024-05-23 18:59:31 [INFO]: Epoch 091 - training loss: 0.2249, validation loss: 0.1090
2024-05-23 18:59:32 [INFO]: Epoch 092 - training loss: 0.2235, validation loss: 0.1085
2024-05-23 18:59:32 [INFO]: Epoch 093 - training loss: 0.2224, validation loss: 0.1091
2024-05-23 18:59:33 [INFO]: Epoch 094 - training loss: 0.2219, validation loss: 0.1089
2024-05-23 18:59:33 [INFO]: Epoch 095 - training loss: 0.2228, validation loss: 0.1081
2024-05-23 18:59:34 [INFO]: Epoch 096 - training loss: 0.2211, validation loss: 0.1083
2024-05-23 18:59:35 [INFO]: Epoch 097 - training loss: 0.2218, validation loss: 0.1083
2024-05-23 18:59:35 [INFO]: Epoch 098 - training loss: 0.2202, validation loss: 0.1078
2024-05-23 18:59:36 [INFO]: Epoch 099 - training loss: 0.2191, validation loss: 0.1074
2024-05-23 18:59:36 [INFO]: Epoch 100 - training loss: 0.2189, validation loss: 0.1074
2024-05-23 18:59:37 [INFO]: Epoch 101 - training loss: 0.2173, validation loss: 0.1065
2024-05-23 18:59:38 [INFO]: Epoch 102 - training loss: 0.2161, validation loss: 0.1063
2024-05-23 18:59:38 [INFO]: Epoch 103 - training loss: 0.2151, validation loss: 0.1060
2024-05-23 18:59:39 [INFO]: Epoch 104 - training loss: 0.2147, validation loss: 0.1064
2024-05-23 18:59:39 [INFO]: Epoch 105 - training loss: 0.2146, validation loss: 0.1068
2024-05-23 18:59:40 [INFO]: Epoch 106 - training loss: 0.2139, validation loss: 0.1057
2024-05-23 18:59:40 [INFO]: Epoch 107 - training loss: 0.2128, validation loss: 0.1050
2024-05-23 18:59:41 [INFO]: Epoch 108 - training loss: 0.2122, validation loss: 0.1053
2024-05-23 18:59:42 [INFO]: Epoch 109 - training loss: 0.2124, validation loss: 0.1066
2024-05-23 18:59:42 [INFO]: Epoch 110 - training loss: 0.2128, validation loss: 0.1070
2024-05-23 18:59:43 [INFO]: Epoch 111 - training loss: 0.2117, validation loss: 0.1052
2024-05-23 18:59:43 [INFO]: Epoch 112 - training loss: 0.2112, validation loss: 0.1048
2024-05-23 18:59:44 [INFO]: Epoch 113 - training loss: 0.2102, validation loss: 0.1046
2024-05-23 18:59:44 [INFO]: Epoch 114 - training loss: 0.2090, validation loss: 0.1048
2024-05-23 18:59:45 [INFO]: Epoch 115 - training loss: 0.2087, validation loss: 0.1045
2024-05-23 18:59:46 [INFO]: Epoch 116 - training loss: 0.2087, validation loss: 0.1048
2024-05-23 18:59:46 [INFO]: Epoch 117 - training loss: 0.2082, validation loss: 0.1049
2024-05-23 18:59:47 [INFO]: Epoch 118 - training loss: 0.2083, validation loss: 0.1045
2024-05-23 18:59:47 [INFO]: Epoch 119 - training loss: 0.2079, validation loss: 0.1042
2024-05-23 18:59:48 [INFO]: Epoch 120 - training loss: 0.2066, validation loss: 0.1039
2024-05-23 18:59:49 [INFO]: Epoch 121 - training loss: 0.2065, validation loss: 0.1036
2024-05-23 18:59:49 [INFO]: Epoch 122 - training loss: 0.2058, validation loss: 0.1031
2024-05-23 18:59:50 [INFO]: Epoch 123 - training loss: 0.2057, validation loss: 0.1040
2024-05-23 18:59:50 [INFO]: Epoch 124 - training loss: 0.2045, validation loss: 0.1024
2024-05-23 18:59:51 [INFO]: Epoch 125 - training loss: 0.2031, validation loss: 0.1026
2024-05-23 18:59:51 [INFO]: Epoch 126 - training loss: 0.2029, validation loss: 0.1026
2024-05-23 18:59:52 [INFO]: Epoch 127 - training loss: 0.2029, validation loss: 0.1032
2024-05-23 18:59:53 [INFO]: Epoch 128 - training loss: 0.2023, validation loss: 0.1026
2024-05-23 18:59:53 [INFO]: Epoch 129 - training loss: 0.2017, validation loss: 0.1038
2024-05-23 18:59:54 [INFO]: Epoch 130 - training loss: 0.2019, validation loss: 0.1022
2024-05-23 18:59:54 [INFO]: Epoch 131 - training loss: 0.2020, validation loss: 0.1020
2024-05-23 18:59:55 [INFO]: Epoch 132 - training loss: 0.2015, validation loss: 0.1021
2024-05-23 18:59:56 [INFO]: Epoch 133 - training loss: 0.2006, validation loss: 0.1028
2024-05-23 18:59:56 [INFO]: Epoch 134 - training loss: 0.1999, validation loss: 0.1028
2024-05-23 18:59:57 [INFO]: Epoch 135 - training loss: 0.1986, validation loss: 0.1021
2024-05-23 18:59:57 [INFO]: Epoch 136 - training loss: 0.1975, validation loss: 0.1008
2024-05-23 18:59:58 [INFO]: Epoch 137 - training loss: 0.1981, validation loss: 0.1015
2024-05-23 18:59:58 [INFO]: Epoch 138 - training loss: 0.1981, validation loss: 0.1000
2024-05-23 18:59:59 [INFO]: Epoch 139 - training loss: 0.1980, validation loss: 0.1018
2024-05-23 19:00:00 [INFO]: Epoch 140 - training loss: 0.1979, validation loss: 0.1016
2024-05-23 19:00:00 [INFO]: Epoch 141 - training loss: 0.1982, validation loss: 0.1014
2024-05-23 19:00:01 [INFO]: Epoch 142 - training loss: 0.1967, validation loss: 0.1005
2024-05-23 19:00:01 [INFO]: Epoch 143 - training loss: 0.1954, validation loss: 0.1006
2024-05-23 19:00:02 [INFO]: Epoch 144 - training loss: 0.1950, validation loss: 0.1009
2024-05-23 19:00:03 [INFO]: Epoch 145 - training loss: 0.1957, validation loss: 0.1022
2024-05-23 19:00:03 [INFO]: Epoch 146 - training loss: 0.1962, validation loss: 0.1008
2024-05-23 19:00:04 [INFO]: Epoch 147 - training loss: 0.1951, validation loss: 0.1011
2024-05-23 19:00:04 [INFO]: Epoch 148 - training loss: 0.1935, validation loss: 0.1002
2024-05-23 19:00:04 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:00:04 [INFO]: Finished training. The best model is from epoch#138.
2024-05-23 19:00:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/SAITS_air_quality/20240523_T185838/SAITS.pypots
2024-05-23 19:00:04 [INFO]: SAITS on Air-Quality: MAE=0.1569, MSE=0.1759
2024-05-23 19:00:04 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-23 19:00:04 [INFO]: Using the given device: cuda:0
2024-05-23 19:00:05 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240523_T190004
2024-05-23 19:00:05 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/Transformer_air_quality/20240523_T190004/tensorboard
2024-05-23 19:00:05 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 19:00:05 [INFO]: Epoch 001 - training loss: 0.8940, validation loss: 0.4266
2024-05-23 19:00:05 [INFO]: Epoch 002 - training loss: 0.5619, validation loss: 0.3041
2024-05-23 19:00:05 [INFO]: Epoch 003 - training loss: 0.4676, validation loss: 0.2567
2024-05-23 19:00:06 [INFO]: Epoch 004 - training loss: 0.4197, validation loss: 0.2351
2024-05-23 19:00:06 [INFO]: Epoch 005 - training loss: 0.3920, validation loss: 0.2198
2024-05-23 19:00:06 [INFO]: Epoch 006 - training loss: 0.3698, validation loss: 0.2112
2024-05-23 19:00:06 [INFO]: Epoch 007 - training loss: 0.3554, validation loss: 0.2004
2024-05-23 19:00:06 [INFO]: Epoch 008 - training loss: 0.3440, validation loss: 0.1955
2024-05-23 19:00:07 [INFO]: Epoch 009 - training loss: 0.3328, validation loss: 0.1917
2024-05-23 19:00:07 [INFO]: Epoch 010 - training loss: 0.3261, validation loss: 0.1854
2024-05-23 19:00:07 [INFO]: Epoch 011 - training loss: 0.3175, validation loss: 0.1814
2024-05-23 19:00:07 [INFO]: Epoch 012 - training loss: 0.3105, validation loss: 0.1781
2024-05-23 19:00:08 [INFO]: Epoch 013 - training loss: 0.3065, validation loss: 0.1751
2024-05-23 19:00:08 [INFO]: Epoch 014 - training loss: 0.3006, validation loss: 0.1706
2024-05-23 19:00:08 [INFO]: Epoch 015 - training loss: 0.2961, validation loss: 0.1694
2024-05-23 19:00:08 [INFO]: Epoch 016 - training loss: 0.2913, validation loss: 0.1653
2024-05-23 19:00:09 [INFO]: Epoch 017 - training loss: 0.2906, validation loss: 0.1652
2024-05-23 19:00:09 [INFO]: Epoch 018 - training loss: 0.2864, validation loss: 0.1621
2024-05-23 19:00:09 [INFO]: Epoch 019 - training loss: 0.2851, validation loss: 0.1576
2024-05-23 19:00:10 [INFO]: Epoch 020 - training loss: 0.2794, validation loss: 0.1582
2024-05-23 19:00:10 [INFO]: Epoch 021 - training loss: 0.2746, validation loss: 0.1568
2024-05-23 19:00:10 [INFO]: Epoch 022 - training loss: 0.2722, validation loss: 0.1554
2024-05-23 19:00:10 [INFO]: Epoch 023 - training loss: 0.2713, validation loss: 0.1543
2024-05-23 19:00:10 [INFO]: Epoch 024 - training loss: 0.2678, validation loss: 0.1518
2024-05-23 19:00:11 [INFO]: Epoch 025 - training loss: 0.2641, validation loss: 0.1533
2024-05-23 19:00:11 [INFO]: Epoch 026 - training loss: 0.2630, validation loss: 0.1525
2024-05-23 19:00:11 [INFO]: Epoch 027 - training loss: 0.2606, validation loss: 0.1508
2024-05-23 19:00:11 [INFO]: Epoch 028 - training loss: 0.2618, validation loss: 0.1511
2024-05-23 19:00:12 [INFO]: Epoch 029 - training loss: 0.2578, validation loss: 0.1493
2024-05-23 19:00:12 [INFO]: Epoch 030 - training loss: 0.2553, validation loss: 0.1504
2024-05-23 19:00:12 [INFO]: Epoch 031 - training loss: 0.2524, validation loss: 0.1467
2024-05-23 19:00:12 [INFO]: Epoch 032 - training loss: 0.2501, validation loss: 0.1453
2024-05-23 19:00:13 [INFO]: Epoch 033 - training loss: 0.2498, validation loss: 0.1468
2024-05-23 19:00:13 [INFO]: Epoch 034 - training loss: 0.2477, validation loss: 0.1463
2024-05-23 19:00:13 [INFO]: Epoch 035 - training loss: 0.2460, validation loss: 0.1460
2024-05-23 19:00:13 [INFO]: Epoch 036 - training loss: 0.2438, validation loss: 0.1449
2024-05-23 19:00:14 [INFO]: Epoch 037 - training loss: 0.2425, validation loss: 0.1424
2024-05-23 19:00:14 [INFO]: Epoch 038 - training loss: 0.2405, validation loss: 0.1436
2024-05-23 19:00:14 [INFO]: Epoch 039 - training loss: 0.2377, validation loss: 0.1413
2024-05-23 19:00:14 [INFO]: Epoch 040 - training loss: 0.2381, validation loss: 0.1421
2024-05-23 19:00:14 [INFO]: Epoch 041 - training loss: 0.2376, validation loss: 0.1396
2024-05-23 19:00:15 [INFO]: Epoch 042 - training loss: 0.2338, validation loss: 0.1396
2024-05-23 19:00:15 [INFO]: Epoch 043 - training loss: 0.2354, validation loss: 0.1399
2024-05-23 19:00:15 [INFO]: Epoch 044 - training loss: 0.2365, validation loss: 0.1416
2024-05-23 19:00:15 [INFO]: Epoch 045 - training loss: 0.2322, validation loss: 0.1388
2024-05-23 19:00:16 [INFO]: Epoch 046 - training loss: 0.2303, validation loss: 0.1389
2024-05-23 19:00:16 [INFO]: Epoch 047 - training loss: 0.2294, validation loss: 0.1403
2024-05-23 19:00:16 [INFO]: Epoch 048 - training loss: 0.2264, validation loss: 0.1400
2024-05-23 19:00:16 [INFO]: Epoch 049 - training loss: 0.2243, validation loss: 0.1373
2024-05-23 19:00:17 [INFO]: Epoch 050 - training loss: 0.2246, validation loss: 0.1391
2024-05-23 19:00:17 [INFO]: Epoch 051 - training loss: 0.2243, validation loss: 0.1378
2024-05-23 19:00:17 [INFO]: Epoch 052 - training loss: 0.2212, validation loss: 0.1357
2024-05-23 19:00:17 [INFO]: Epoch 053 - training loss: 0.2198, validation loss: 0.1356
2024-05-23 19:00:18 [INFO]: Epoch 054 - training loss: 0.2186, validation loss: 0.1353
2024-05-23 19:00:18 [INFO]: Epoch 055 - training loss: 0.2189, validation loss: 0.1373
2024-05-23 19:00:18 [INFO]: Epoch 056 - training loss: 0.2176, validation loss: 0.1355
2024-05-23 19:00:18 [INFO]: Epoch 057 - training loss: 0.2178, validation loss: 0.1345
2024-05-23 19:00:18 [INFO]: Epoch 058 - training loss: 0.2178, validation loss: 0.1340
2024-05-23 19:00:19 [INFO]: Epoch 059 - training loss: 0.2148, validation loss: 0.1341
2024-05-23 19:00:19 [INFO]: Epoch 060 - training loss: 0.2155, validation loss: 0.1347
2024-05-23 19:00:19 [INFO]: Epoch 061 - training loss: 0.2137, validation loss: 0.1358
2024-05-23 19:00:19 [INFO]: Epoch 062 - training loss: 0.2124, validation loss: 0.1320
2024-05-23 19:00:20 [INFO]: Epoch 063 - training loss: 0.2092, validation loss: 0.1347
2024-05-23 19:00:20 [INFO]: Epoch 064 - training loss: 0.2089, validation loss: 0.1318
2024-05-23 19:00:20 [INFO]: Epoch 065 - training loss: 0.2091, validation loss: 0.1330
2024-05-23 19:00:20 [INFO]: Epoch 066 - training loss: 0.2070, validation loss: 0.1294
2024-05-23 19:00:21 [INFO]: Epoch 067 - training loss: 0.2074, validation loss: 0.1329
2024-05-23 19:00:21 [INFO]: Epoch 068 - training loss: 0.2061, validation loss: 0.1314
2024-05-23 19:00:21 [INFO]: Epoch 069 - training loss: 0.2074, validation loss: 0.1298
2024-05-23 19:00:21 [INFO]: Epoch 070 - training loss: 0.2055, validation loss: 0.1310
2024-05-23 19:00:22 [INFO]: Epoch 071 - training loss: 0.2038, validation loss: 0.1298
2024-05-23 19:00:22 [INFO]: Epoch 072 - training loss: 0.2030, validation loss: 0.1297
2024-05-23 19:00:22 [INFO]: Epoch 073 - training loss: 0.2018, validation loss: 0.1287
2024-05-23 19:00:22 [INFO]: Epoch 074 - training loss: 0.2006, validation loss: 0.1274
2024-05-23 19:00:22 [INFO]: Epoch 075 - training loss: 0.1994, validation loss: 0.1279
2024-05-23 19:00:23 [INFO]: Epoch 076 - training loss: 0.1992, validation loss: 0.1295
2024-05-23 19:00:23 [INFO]: Epoch 077 - training loss: 0.2006, validation loss: 0.1287
2024-05-23 19:00:23 [INFO]: Epoch 078 - training loss: 0.1999, validation loss: 0.1307
2024-05-23 19:00:23 [INFO]: Epoch 079 - training loss: 0.1991, validation loss: 0.1296
2024-05-23 19:00:24 [INFO]: Epoch 080 - training loss: 0.1964, validation loss: 0.1274
2024-05-23 19:00:24 [INFO]: Epoch 081 - training loss: 0.1927, validation loss: 0.1275
2024-05-23 19:00:24 [INFO]: Epoch 082 - training loss: 0.1911, validation loss: 0.1262
2024-05-23 19:00:24 [INFO]: Epoch 083 - training loss: 0.1898, validation loss: 0.1266
2024-05-23 19:00:25 [INFO]: Epoch 084 - training loss: 0.1904, validation loss: 0.1250
2024-05-23 19:00:25 [INFO]: Epoch 085 - training loss: 0.1896, validation loss: 0.1254
2024-05-23 19:00:25 [INFO]: Epoch 086 - training loss: 0.1929, validation loss: 0.1265
2024-05-23 19:00:25 [INFO]: Epoch 087 - training loss: 0.1928, validation loss: 0.1245
2024-05-23 19:00:26 [INFO]: Epoch 088 - training loss: 0.1905, validation loss: 0.1257
2024-05-23 19:00:26 [INFO]: Epoch 089 - training loss: 0.1894, validation loss: 0.1234
2024-05-23 19:00:26 [INFO]: Epoch 090 - training loss: 0.1894, validation loss: 0.1243
2024-05-23 19:00:26 [INFO]: Epoch 091 - training loss: 0.1864, validation loss: 0.1252
2024-05-23 19:00:27 [INFO]: Epoch 092 - training loss: 0.1869, validation loss: 0.1234
2024-05-23 19:00:27 [INFO]: Epoch 093 - training loss: 0.1855, validation loss: 0.1253
2024-05-23 19:00:27 [INFO]: Epoch 094 - training loss: 0.1830, validation loss: 0.1245
2024-05-23 19:00:27 [INFO]: Epoch 095 - training loss: 0.1828, validation loss: 0.1223
2024-05-23 19:00:27 [INFO]: Epoch 096 - training loss: 0.1833, validation loss: 0.1234
2024-05-23 19:00:28 [INFO]: Epoch 097 - training loss: 0.1813, validation loss: 0.1229
2024-05-23 19:00:28 [INFO]: Epoch 098 - training loss: 0.1817, validation loss: 0.1228
2024-05-23 19:00:28 [INFO]: Epoch 099 - training loss: 0.1824, validation loss: 0.1225
2024-05-23 19:00:28 [INFO]: Epoch 100 - training loss: 0.1858, validation loss: 0.1203
2024-05-23 19:00:29 [INFO]: Epoch 101 - training loss: 0.1813, validation loss: 0.1225
2024-05-23 19:00:29 [INFO]: Epoch 102 - training loss: 0.1789, validation loss: 0.1229
2024-05-23 19:00:29 [INFO]: Epoch 103 - training loss: 0.1766, validation loss: 0.1216
2024-05-23 19:00:29 [INFO]: Epoch 104 - training loss: 0.1769, validation loss: 0.1231
2024-05-23 19:00:30 [INFO]: Epoch 105 - training loss: 0.1778, validation loss: 0.1225
2024-05-23 19:00:30 [INFO]: Epoch 106 - training loss: 0.1786, validation loss: 0.1204
2024-05-23 19:00:30 [INFO]: Epoch 107 - training loss: 0.1758, validation loss: 0.1213
2024-05-23 19:00:30 [INFO]: Epoch 108 - training loss: 0.1751, validation loss: 0.1203
2024-05-23 19:00:31 [INFO]: Epoch 109 - training loss: 0.1752, validation loss: 0.1225
2024-05-23 19:00:31 [INFO]: Epoch 110 - training loss: 0.1734, validation loss: 0.1204
2024-05-23 19:00:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:00:31 [INFO]: Finished training. The best model is from epoch#100.
2024-05-23 19:00:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/Transformer_air_quality/20240523_T190004/Transformer.pypots
2024-05-23 19:00:31 [INFO]: Transformer on Air-Quality: MAE=0.1742, MSE=0.2093
2024-05-23 19:00:31 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-23 19:00:31 [INFO]: Using the given device: cuda:0
2024-05-23 19:00:31 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240523_T190031
2024-05-23 19:00:31 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240523_T190031/tensorboard
2024-05-23 19:00:31 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 19:00:32 [INFO]: Epoch 001 - training loss: 0.2838, validation loss: 0.2452
2024-05-23 19:00:32 [INFO]: Epoch 002 - training loss: 0.2290, validation loss: 0.2173
2024-05-23 19:00:33 [INFO]: Epoch 003 - training loss: 0.1918, validation loss: 0.1902
2024-05-23 19:00:33 [INFO]: Epoch 004 - training loss: 0.1576, validation loss: 0.1816
2024-05-23 19:00:33 [INFO]: Epoch 005 - training loss: 0.1441, validation loss: 0.1698
2024-05-23 19:00:34 [INFO]: Epoch 006 - training loss: 0.1351, validation loss: 0.1654
2024-05-23 19:00:34 [INFO]: Epoch 007 - training loss: 0.1310, validation loss: 0.1655
2024-05-23 19:00:35 [INFO]: Epoch 008 - training loss: 0.1294, validation loss: 0.1634
2024-05-23 19:00:35 [INFO]: Epoch 009 - training loss: 0.1234, validation loss: 0.1596
2024-05-23 19:00:36 [INFO]: Epoch 010 - training loss: 0.1144, validation loss: 0.1545
2024-05-23 19:00:36 [INFO]: Epoch 011 - training loss: 0.1074, validation loss: 0.1514
2024-05-23 19:00:36 [INFO]: Epoch 012 - training loss: 0.1060, validation loss: 0.1510
2024-05-23 19:00:37 [INFO]: Epoch 013 - training loss: 0.1005, validation loss: 0.1494
2024-05-23 19:00:37 [INFO]: Epoch 014 - training loss: 0.0988, validation loss: 0.1480
2024-05-23 19:00:38 [INFO]: Epoch 015 - training loss: 0.0988, validation loss: 0.1445
2024-05-23 19:00:38 [INFO]: Epoch 016 - training loss: 0.0958, validation loss: 0.1470
2024-05-23 19:00:39 [INFO]: Epoch 017 - training loss: 0.0957, validation loss: 0.1425
2024-05-23 19:00:39 [INFO]: Epoch 018 - training loss: 0.0914, validation loss: 0.1540
2024-05-23 19:00:39 [INFO]: Epoch 019 - training loss: 0.0904, validation loss: 0.1433
2024-05-23 19:00:40 [INFO]: Epoch 020 - training loss: 0.0966, validation loss: 0.1468
2024-05-23 19:00:40 [INFO]: Epoch 021 - training loss: 0.0905, validation loss: 0.1478
2024-05-23 19:00:41 [INFO]: Epoch 022 - training loss: 0.0946, validation loss: 0.1401
2024-05-23 19:00:41 [INFO]: Epoch 023 - training loss: 0.0855, validation loss: 0.1469
2024-05-23 19:00:42 [INFO]: Epoch 024 - training loss: 0.0836, validation loss: 0.1389
2024-05-23 19:00:42 [INFO]: Epoch 025 - training loss: 0.0772, validation loss: 0.1415
2024-05-23 19:00:43 [INFO]: Epoch 026 - training loss: 0.0757, validation loss: 0.1370
2024-05-23 19:00:43 [INFO]: Epoch 027 - training loss: 0.0744, validation loss: 0.1380
2024-05-23 19:00:43 [INFO]: Epoch 028 - training loss: 0.0727, validation loss: 0.1412
2024-05-23 19:00:44 [INFO]: Epoch 029 - training loss: 0.0717, validation loss: 0.1397
2024-05-23 19:00:44 [INFO]: Epoch 030 - training loss: 0.0702, validation loss: 0.1371
2024-05-23 19:00:45 [INFO]: Epoch 031 - training loss: 0.0710, validation loss: 0.1477
2024-05-23 19:00:45 [INFO]: Epoch 032 - training loss: 0.0698, validation loss: 0.1393
2024-05-23 19:00:46 [INFO]: Epoch 033 - training loss: 0.0669, validation loss: 0.1370
2024-05-23 19:00:46 [INFO]: Epoch 034 - training loss: 0.0660, validation loss: 0.1368
2024-05-23 19:00:46 [INFO]: Epoch 035 - training loss: 0.0661, validation loss: 0.1359
2024-05-23 19:00:47 [INFO]: Epoch 036 - training loss: 0.0653, validation loss: 0.1411
2024-05-23 19:00:47 [INFO]: Epoch 037 - training loss: 0.0653, validation loss: 0.1498
2024-05-23 19:00:48 [INFO]: Epoch 038 - training loss: 0.0786, validation loss: 0.1367
2024-05-23 19:00:48 [INFO]: Epoch 039 - training loss: 0.0886, validation loss: 0.1641
2024-05-23 19:00:49 [INFO]: Epoch 040 - training loss: 0.0939, validation loss: 0.1387
2024-05-23 19:00:49 [INFO]: Epoch 041 - training loss: 0.0685, validation loss: 0.1338
2024-05-23 19:00:49 [INFO]: Epoch 042 - training loss: 0.0655, validation loss: 0.1347
2024-05-23 19:00:50 [INFO]: Epoch 043 - training loss: 0.0638, validation loss: 0.1369
2024-05-23 19:00:50 [INFO]: Epoch 044 - training loss: 0.0605, validation loss: 0.1342
2024-05-23 19:00:51 [INFO]: Epoch 045 - training loss: 0.0579, validation loss: 0.1323
2024-05-23 19:00:51 [INFO]: Epoch 046 - training loss: 0.0560, validation loss: 0.1335
2024-05-23 19:00:52 [INFO]: Epoch 047 - training loss: 0.0548, validation loss: 0.1341
2024-05-23 19:00:52 [INFO]: Epoch 048 - training loss: 0.0545, validation loss: 0.1320
2024-05-23 19:00:53 [INFO]: Epoch 049 - training loss: 0.0544, validation loss: 0.1356
2024-05-23 19:00:53 [INFO]: Epoch 050 - training loss: 0.0549, validation loss: 0.1349
2024-05-23 19:00:53 [INFO]: Epoch 051 - training loss: 0.0584, validation loss: 0.1331
2024-05-23 19:00:54 [INFO]: Epoch 052 - training loss: 0.0541, validation loss: 0.1329
2024-05-23 19:00:54 [INFO]: Epoch 053 - training loss: 0.0516, validation loss: 0.1324
2024-05-23 19:00:55 [INFO]: Epoch 054 - training loss: 0.0503, validation loss: 0.1326
2024-05-23 19:00:55 [INFO]: Epoch 055 - training loss: 0.0515, validation loss: 0.1384
2024-05-23 19:00:56 [INFO]: Epoch 056 - training loss: 0.0515, validation loss: 0.1320
2024-05-23 19:00:56 [INFO]: Epoch 057 - training loss: 0.0513, validation loss: 0.1357
2024-05-23 19:00:56 [INFO]: Epoch 058 - training loss: 0.0503, validation loss: 0.1310
2024-05-23 19:00:57 [INFO]: Epoch 059 - training loss: 0.0482, validation loss: 0.1341
2024-05-23 19:00:57 [INFO]: Epoch 060 - training loss: 0.0488, validation loss: 0.1321
2024-05-23 19:00:58 [INFO]: Epoch 061 - training loss: 0.0472, validation loss: 0.1325
2024-05-23 19:00:58 [INFO]: Epoch 062 - training loss: 0.0460, validation loss: 0.1323
2024-05-23 19:00:59 [INFO]: Epoch 063 - training loss: 0.0454, validation loss: 0.1348
2024-05-23 19:00:59 [INFO]: Epoch 064 - training loss: 0.0467, validation loss: 0.1361
2024-05-23 19:00:59 [INFO]: Epoch 065 - training loss: 0.0476, validation loss: 0.1340
2024-05-23 19:01:00 [INFO]: Epoch 066 - training loss: 0.0452, validation loss: 0.1338
2024-05-23 19:01:00 [INFO]: Epoch 067 - training loss: 0.0484, validation loss: 0.1332
2024-05-23 19:01:01 [INFO]: Epoch 068 - training loss: 0.0464, validation loss: 0.1351
2024-05-23 19:01:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:01:01 [INFO]: Finished training. The best model is from epoch#58.
2024-05-23 19:01:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/TimesNet_air_quality/20240523_T190031/TimesNet.pypots
2024-05-23 19:01:01 [INFO]: TimesNet on Air-Quality: MAE=0.1652, MSE=0.2475
2024-05-23 19:01:01 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-23 19:01:01 [INFO]: Using the given device: cuda:0
2024-05-23 19:01:01 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101
2024-05-23 19:01:01 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/tensorboard
2024-05-23 19:01:01 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 19:01:17 [INFO]: Epoch 001 - training loss: 0.5177, validation loss: 0.3519
2024-05-23 19:01:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch1_loss0.3519317388534546.pypots
2024-05-23 19:01:34 [INFO]: Epoch 002 - training loss: 0.2879, validation loss: 0.2657
2024-05-23 19:01:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch2_loss0.2657017260789871.pypots
2024-05-23 19:01:50 [INFO]: Epoch 003 - training loss: 0.2558, validation loss: 0.2489
2024-05-23 19:01:50 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch3_loss0.24890055060386657.pypots
2024-05-23 19:02:07 [INFO]: Epoch 004 - training loss: 0.2335, validation loss: 0.2176
2024-05-23 19:02:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch4_loss0.21756182461977006.pypots
2024-05-23 19:02:23 [INFO]: Epoch 005 - training loss: 0.2197, validation loss: 0.1978
2024-05-23 19:02:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch5_loss0.19776354730129242.pypots
2024-05-23 19:02:40 [INFO]: Epoch 006 - training loss: 0.1980, validation loss: 0.1830
2024-05-23 19:02:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch6_loss0.18297564834356309.pypots
2024-05-23 19:02:56 [INFO]: Epoch 007 - training loss: 0.1829, validation loss: 0.1767
2024-05-23 19:02:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch7_loss0.17667271494865416.pypots
2024-05-23 19:03:12 [INFO]: Epoch 008 - training loss: 0.1686, validation loss: 0.1647
2024-05-23 19:03:12 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch8_loss0.16465432345867156.pypots
2024-05-23 19:03:29 [INFO]: Epoch 009 - training loss: 0.1681, validation loss: 0.1580
2024-05-23 19:03:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch9_loss0.15801078230142593.pypots
2024-05-23 19:03:45 [INFO]: Epoch 010 - training loss: 0.1632, validation loss: 0.1547
2024-05-23 19:03:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch10_loss0.15471913367509843.pypots
2024-05-23 19:04:02 [INFO]: Epoch 011 - training loss: 0.1623, validation loss: 0.1554
2024-05-23 19:04:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch11_loss0.155448254942894.pypots
2024-05-23 19:04:18 [INFO]: Epoch 012 - training loss: 0.1497, validation loss: 0.1551
2024-05-23 19:04:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch12_loss0.15514524430036544.pypots
2024-05-23 19:04:34 [INFO]: Epoch 013 - training loss: 0.1578, validation loss: 0.1510
2024-05-23 19:04:34 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch13_loss0.1510140046477318.pypots
2024-05-23 19:04:51 [INFO]: Epoch 014 - training loss: 0.1541, validation loss: 0.1436
2024-05-23 19:04:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch14_loss0.1435850128531456.pypots
2024-05-23 19:05:07 [INFO]: Epoch 015 - training loss: 0.1573, validation loss: 0.1443
2024-05-23 19:05:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch15_loss0.14431033432483673.pypots
2024-05-23 19:05:24 [INFO]: Epoch 016 - training loss: 0.1586, validation loss: 0.1450
2024-05-23 19:05:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch16_loss0.14497551918029786.pypots
2024-05-23 19:05:40 [INFO]: Epoch 017 - training loss: 0.1521, validation loss: 0.1428
2024-05-23 19:05:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch17_loss0.1427553653717041.pypots
2024-05-23 19:05:56 [INFO]: Epoch 018 - training loss: 0.1544, validation loss: 0.1415
2024-05-23 19:05:56 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch18_loss0.1414502516388893.pypots
2024-05-23 19:06:13 [INFO]: Epoch 019 - training loss: 0.1435, validation loss: 0.1367
2024-05-23 19:06:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch19_loss0.13673861101269721.pypots
2024-05-23 19:06:29 [INFO]: Epoch 020 - training loss: 0.1360, validation loss: 0.1358
2024-05-23 19:06:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch20_loss0.1357829675078392.pypots
2024-05-23 19:06:46 [INFO]: Epoch 021 - training loss: 0.1427, validation loss: 0.1382
2024-05-23 19:06:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch21_loss0.13824212104082106.pypots
2024-05-23 19:07:02 [INFO]: Epoch 022 - training loss: 0.1313, validation loss: 0.1445
2024-05-23 19:07:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch22_loss0.14445898979902266.pypots
2024-05-23 19:07:18 [INFO]: Epoch 023 - training loss: 0.1378, validation loss: 0.1335
2024-05-23 19:07:18 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch23_loss0.13353442326188086.pypots
2024-05-23 19:07:35 [INFO]: Epoch 024 - training loss: 0.1424, validation loss: 0.1320
2024-05-23 19:07:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch24_loss0.13197000697255135.pypots
2024-05-23 19:07:51 [INFO]: Epoch 025 - training loss: 0.1355, validation loss: 0.1342
2024-05-23 19:07:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch25_loss0.13423424288630487.pypots
2024-05-23 19:08:08 [INFO]: Epoch 026 - training loss: 0.1318, validation loss: 0.1301
2024-05-23 19:08:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch26_loss0.1300825893878937.pypots
2024-05-23 19:08:24 [INFO]: Epoch 027 - training loss: 0.1223, validation loss: 0.1301
2024-05-23 19:08:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch27_loss0.13010013923048974.pypots
2024-05-23 19:08:40 [INFO]: Epoch 028 - training loss: 0.1410, validation loss: 0.1290
2024-05-23 19:08:40 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch28_loss0.12900599613785743.pypots
2024-05-23 19:08:57 [INFO]: Epoch 029 - training loss: 0.1322, validation loss: 0.1316
2024-05-23 19:08:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch29_loss0.13162586763501166.pypots
2024-05-23 19:09:13 [INFO]: Epoch 030 - training loss: 0.1252, validation loss: 0.1322
2024-05-23 19:09:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch30_loss0.13218895941972733.pypots
2024-05-23 19:09:30 [INFO]: Epoch 031 - training loss: 0.1227, validation loss: 0.1275
2024-05-23 19:09:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch31_loss0.1274663545191288.pypots
2024-05-23 19:09:46 [INFO]: Epoch 032 - training loss: 0.1291, validation loss: 0.1285
2024-05-23 19:09:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch32_loss0.12847834452986717.pypots
2024-05-23 19:10:02 [INFO]: Epoch 033 - training loss: 0.1129, validation loss: 0.1265
2024-05-23 19:10:02 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch33_loss0.12646741271018982.pypots
2024-05-23 19:10:19 [INFO]: Epoch 034 - training loss: 0.1185, validation loss: 0.1266
2024-05-23 19:10:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch34_loss0.12662639915943147.pypots
2024-05-23 19:10:35 [INFO]: Epoch 035 - training loss: 0.1176, validation loss: 0.1270
2024-05-23 19:10:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch35_loss0.1270069494843483.pypots
2024-05-23 19:10:52 [INFO]: Epoch 036 - training loss: 0.1214, validation loss: 0.1268
2024-05-23 19:10:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch36_loss0.12678027376532555.pypots
2024-05-23 19:11:08 [INFO]: Epoch 037 - training loss: 0.1332, validation loss: 0.1268
2024-05-23 19:11:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch37_loss0.12678451389074324.pypots
2024-05-23 19:11:24 [INFO]: Epoch 038 - training loss: 0.1210, validation loss: 0.1245
2024-05-23 19:11:24 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch38_loss0.12446440979838372.pypots
2024-05-23 19:11:41 [INFO]: Epoch 039 - training loss: 0.1348, validation loss: 0.1219
2024-05-23 19:11:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch39_loss0.12185526341199875.pypots
2024-05-23 19:11:57 [INFO]: Epoch 040 - training loss: 0.1094, validation loss: 0.1236
2024-05-23 19:11:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch40_loss0.12356158718466759.pypots
2024-05-23 19:12:14 [INFO]: Epoch 041 - training loss: 0.1235, validation loss: 0.1236
2024-05-23 19:12:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch41_loss0.1235777534544468.pypots
2024-05-23 19:12:30 [INFO]: Epoch 042 - training loss: 0.1182, validation loss: 0.1208
2024-05-23 19:12:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch42_loss0.12077758014202118.pypots
2024-05-23 19:12:46 [INFO]: Epoch 043 - training loss: 0.1261, validation loss: 0.1202
2024-05-23 19:12:46 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch43_loss0.12023926302790641.pypots
2024-05-23 19:13:03 [INFO]: Epoch 044 - training loss: 0.1148, validation loss: 0.1242
2024-05-23 19:13:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch44_loss0.12423259317874909.pypots
2024-05-23 19:13:19 [INFO]: Epoch 045 - training loss: 0.1245, validation loss: 0.1257
2024-05-23 19:13:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch45_loss0.1257364921271801.pypots
2024-05-23 19:13:35 [INFO]: Epoch 046 - training loss: 0.1282, validation loss: 0.1221
2024-05-23 19:13:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch46_loss0.12213060855865479.pypots
2024-05-23 19:13:52 [INFO]: Epoch 047 - training loss: 0.1145, validation loss: 0.1199
2024-05-23 19:13:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch47_loss0.11991614550352096.pypots
2024-05-23 19:14:08 [INFO]: Epoch 048 - training loss: 0.1148, validation loss: 0.1182
2024-05-23 19:14:08 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch48_loss0.11815130859613418.pypots
2024-05-23 19:14:25 [INFO]: Epoch 049 - training loss: 0.1039, validation loss: 0.1163
2024-05-23 19:14:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch49_loss0.11626649647951126.pypots
2024-05-23 19:14:41 [INFO]: Epoch 050 - training loss: 0.1272, validation loss: 0.1192
2024-05-23 19:14:41 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch50_loss0.11916375681757926.pypots
2024-05-23 19:14:57 [INFO]: Epoch 051 - training loss: 0.1062, validation loss: 0.1166
2024-05-23 19:14:57 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch51_loss0.11662840321660042.pypots
2024-05-23 19:15:14 [INFO]: Epoch 052 - training loss: 0.1171, validation loss: 0.1156
2024-05-23 19:15:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch52_loss0.11564147174358368.pypots
2024-05-23 19:15:30 [INFO]: Epoch 053 - training loss: 0.1287, validation loss: 0.1189
2024-05-23 19:15:30 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch53_loss0.11894968077540398.pypots
2024-05-23 19:15:47 [INFO]: Epoch 054 - training loss: 0.1228, validation loss: 0.1172
2024-05-23 19:15:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch54_loss0.1172082781791687.pypots
2024-05-23 19:16:03 [INFO]: Epoch 055 - training loss: 0.1164, validation loss: 0.1162
2024-05-23 19:16:03 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch55_loss0.11615600064396858.pypots
2024-05-23 19:16:19 [INFO]: Epoch 056 - training loss: 0.1062, validation loss: 0.1206
2024-05-23 19:16:19 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch56_loss0.1205558329820633.pypots
2024-05-23 19:16:36 [INFO]: Epoch 057 - training loss: 0.1209, validation loss: 0.1215
2024-05-23 19:16:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch57_loss0.12153158783912658.pypots
2024-05-23 19:16:52 [INFO]: Epoch 058 - training loss: 0.1099, validation loss: 0.1141
2024-05-23 19:16:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch58_loss0.11412524655461312.pypots
2024-05-23 19:17:09 [INFO]: Epoch 059 - training loss: 0.1170, validation loss: 0.1145
2024-05-23 19:17:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch59_loss0.11453297659754753.pypots
2024-05-23 19:17:25 [INFO]: Epoch 060 - training loss: 0.0967, validation loss: 0.1142
2024-05-23 19:17:25 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch60_loss0.11422288045287132.pypots
2024-05-23 19:17:42 [INFO]: Epoch 061 - training loss: 0.1121, validation loss: 0.1153
2024-05-23 19:17:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch61_loss0.11525109559297561.pypots
2024-05-23 19:17:58 [INFO]: Epoch 062 - training loss: 0.1088, validation loss: 0.1152
2024-05-23 19:17:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch62_loss0.11515047922730445.pypots
2024-05-23 19:18:15 [INFO]: Epoch 063 - training loss: 0.1170, validation loss: 0.1138
2024-05-23 19:18:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch63_loss0.11376681029796601.pypots
2024-05-23 19:18:31 [INFO]: Epoch 064 - training loss: 0.1108, validation loss: 0.1134
2024-05-23 19:18:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch64_loss0.1134270615875721.pypots
2024-05-23 19:18:47 [INFO]: Epoch 065 - training loss: 0.1203, validation loss: 0.1148
2024-05-23 19:18:47 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch65_loss0.11481222063302994.pypots
2024-05-23 19:19:04 [INFO]: Epoch 066 - training loss: 0.1082, validation loss: 0.1123
2024-05-23 19:19:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch66_loss0.11228266060352325.pypots
2024-05-23 19:19:20 [INFO]: Epoch 067 - training loss: 0.1143, validation loss: 0.1150
2024-05-23 19:19:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch67_loss0.11503674313426018.pypots
2024-05-23 19:19:36 [INFO]: Epoch 068 - training loss: 0.1104, validation loss: 0.1157
2024-05-23 19:19:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch68_loss0.1157301738858223.pypots
2024-05-23 19:19:53 [INFO]: Epoch 069 - training loss: 0.0984, validation loss: 0.1127
2024-05-23 19:19:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch69_loss0.11272071376442909.pypots
2024-05-23 19:20:09 [INFO]: Epoch 070 - training loss: 0.1174, validation loss: 0.1103
2024-05-23 19:20:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch70_loss0.11030859127640724.pypots
2024-05-23 19:20:26 [INFO]: Epoch 071 - training loss: 0.1113, validation loss: 0.1121
2024-05-23 19:20:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch71_loss0.11209959089756012.pypots
2024-05-23 19:20:42 [INFO]: Epoch 072 - training loss: 0.1154, validation loss: 0.1150
2024-05-23 19:20:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch72_loss0.11495155990123748.pypots
2024-05-23 19:20:58 [INFO]: Epoch 073 - training loss: 0.0992, validation loss: 0.1105
2024-05-23 19:20:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch73_loss0.11053083539009094.pypots
2024-05-23 19:21:15 [INFO]: Epoch 074 - training loss: 0.1154, validation loss: 0.1135
2024-05-23 19:21:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch74_loss0.1135186217725277.pypots
2024-05-23 19:21:31 [INFO]: Epoch 075 - training loss: 0.1029, validation loss: 0.1088
2024-05-23 19:21:31 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch75_loss0.10884668901562691.pypots
2024-05-23 19:21:48 [INFO]: Epoch 076 - training loss: 0.1030, validation loss: 0.1086
2024-05-23 19:21:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch76_loss0.10860450044274331.pypots
2024-05-23 19:22:04 [INFO]: Epoch 077 - training loss: 0.1060, validation loss: 0.1113
2024-05-23 19:22:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch77_loss0.11130732521414757.pypots
2024-05-23 19:22:20 [INFO]: Epoch 078 - training loss: 0.1232, validation loss: 0.1124
2024-05-23 19:22:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch78_loss0.11237389296293258.pypots
2024-05-23 19:22:37 [INFO]: Epoch 079 - training loss: 0.1139, validation loss: 0.1108
2024-05-23 19:22:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch79_loss0.1108333446085453.pypots
2024-05-23 19:22:53 [INFO]: Epoch 080 - training loss: 0.1065, validation loss: 0.1123
2024-05-23 19:22:53 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch80_loss0.11231288686394691.pypots
2024-05-23 19:23:09 [INFO]: Epoch 081 - training loss: 0.1056, validation loss: 0.1093
2024-05-23 19:23:09 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch81_loss0.1093346543610096.pypots
2024-05-23 19:23:26 [INFO]: Epoch 082 - training loss: 0.1156, validation loss: 0.1072
2024-05-23 19:23:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch82_loss0.10722329318523408.pypots
2024-05-23 19:23:42 [INFO]: Epoch 083 - training loss: 0.1100, validation loss: 0.1075
2024-05-23 19:23:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch83_loss0.10747116208076476.pypots
2024-05-23 19:23:59 [INFO]: Epoch 084 - training loss: 0.1142, validation loss: 0.1112
2024-05-23 19:23:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch84_loss0.11115865930914878.pypots
2024-05-23 19:24:15 [INFO]: Epoch 085 - training loss: 0.1004, validation loss: 0.1100
2024-05-23 19:24:15 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch85_loss0.11003370881080628.pypots
2024-05-23 19:24:32 [INFO]: Epoch 086 - training loss: 0.1110, validation loss: 0.1089
2024-05-23 19:24:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch86_loss0.10890481248497963.pypots
2024-05-23 19:24:48 [INFO]: Epoch 087 - training loss: 0.0987, validation loss: 0.1075
2024-05-23 19:24:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch87_loss0.10751813873648644.pypots
2024-05-23 19:25:04 [INFO]: Epoch 088 - training loss: 0.1052, validation loss: 0.1067
2024-05-23 19:25:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch88_loss0.10673697143793107.pypots
2024-05-23 19:25:21 [INFO]: Epoch 089 - training loss: 0.0959, validation loss: 0.1063
2024-05-23 19:25:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch89_loss0.10628532022237777.pypots
2024-05-23 19:25:37 [INFO]: Epoch 090 - training loss: 0.1074, validation loss: 0.1108
2024-05-23 19:25:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch90_loss0.11078397408127785.pypots
2024-05-23 19:25:54 [INFO]: Epoch 091 - training loss: 0.1080, validation loss: 0.1065
2024-05-23 19:25:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch91_loss0.10652113109827041.pypots
2024-05-23 19:26:10 [INFO]: Epoch 092 - training loss: 0.1035, validation loss: 0.1069
2024-05-23 19:26:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch92_loss0.10686318874359131.pypots
2024-05-23 19:26:26 [INFO]: Epoch 093 - training loss: 0.1057, validation loss: 0.1057
2024-05-23 19:26:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch93_loss0.10571396350860596.pypots
2024-05-23 19:26:43 [INFO]: Epoch 094 - training loss: 0.1003, validation loss: 0.1050
2024-05-23 19:26:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch94_loss0.10499578863382339.pypots
2024-05-23 19:26:59 [INFO]: Epoch 095 - training loss: 0.1113, validation loss: 0.1044
2024-05-23 19:26:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch95_loss0.10436709597706795.pypots
2024-05-23 19:27:16 [INFO]: Epoch 096 - training loss: 0.0955, validation loss: 0.1049
2024-05-23 19:27:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch96_loss0.10489768162369728.pypots
2024-05-23 19:27:32 [INFO]: Epoch 097 - training loss: 0.1150, validation loss: 0.1040
2024-05-23 19:27:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch97_loss0.10401220917701721.pypots
2024-05-23 19:27:48 [INFO]: Epoch 098 - training loss: 0.1004, validation loss: 0.1048
2024-05-23 19:27:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch98_loss0.10480773597955703.pypots
2024-05-23 19:28:05 [INFO]: Epoch 099 - training loss: 0.1061, validation loss: 0.1071
2024-05-23 19:28:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch99_loss0.10709266886115074.pypots
2024-05-23 19:28:21 [INFO]: Epoch 100 - training loss: 0.1052, validation loss: 0.1051
2024-05-23 19:28:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch100_loss0.10509098917245865.pypots
2024-05-23 19:28:37 [INFO]: Epoch 101 - training loss: 0.1009, validation loss: 0.1033
2024-05-23 19:28:37 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch101_loss0.10329514369368553.pypots
2024-05-23 19:28:54 [INFO]: Epoch 102 - training loss: 0.0986, validation loss: 0.1041
2024-05-23 19:28:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch102_loss0.10412710458040238.pypots
2024-05-23 19:29:10 [INFO]: Epoch 103 - training loss: 0.0971, validation loss: 0.1035
2024-05-23 19:29:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch103_loss0.10351806953549385.pypots
2024-05-23 19:29:27 [INFO]: Epoch 104 - training loss: 0.1018, validation loss: 0.1142
2024-05-23 19:29:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch104_loss0.11416818648576736.pypots
2024-05-23 19:29:43 [INFO]: Epoch 105 - training loss: 0.1162, validation loss: 0.1043
2024-05-23 19:29:43 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch105_loss0.10428045094013214.pypots
2024-05-23 19:29:59 [INFO]: Epoch 106 - training loss: 0.0971, validation loss: 0.1031
2024-05-23 19:29:59 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch106_loss0.10306204631924629.pypots
2024-05-23 19:30:16 [INFO]: Epoch 107 - training loss: 0.1002, validation loss: 0.1006
2024-05-23 19:30:16 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch107_loss0.10057356879115105.pypots
2024-05-23 19:30:32 [INFO]: Epoch 108 - training loss: 0.1057, validation loss: 0.1060
2024-05-23 19:30:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch108_loss0.10598579272627831.pypots
2024-05-23 19:30:49 [INFO]: Epoch 109 - training loss: 0.1044, validation loss: 0.1025
2024-05-23 19:30:49 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch109_loss0.1024872601032257.pypots
2024-05-23 19:31:05 [INFO]: Epoch 110 - training loss: 0.1066, validation loss: 0.1024
2024-05-23 19:31:05 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch110_loss0.1024187833070755.pypots
2024-05-23 19:31:21 [INFO]: Epoch 111 - training loss: 0.1085, validation loss: 0.1036
2024-05-23 19:31:21 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch111_loss0.10358834937214852.pypots
2024-05-23 19:31:38 [INFO]: Epoch 112 - training loss: 0.1014, validation loss: 0.1047
2024-05-23 19:31:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch112_loss0.10472406223416328.pypots
2024-05-23 19:31:54 [INFO]: Epoch 113 - training loss: 0.1046, validation loss: 0.1011
2024-05-23 19:31:54 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch113_loss0.10112901702523232.pypots
2024-05-23 19:32:11 [INFO]: Epoch 114 - training loss: 0.1003, validation loss: 0.1051
2024-05-23 19:32:11 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch114_loss0.10505029633641243.pypots
2024-05-23 19:32:27 [INFO]: Epoch 115 - training loss: 0.0936, validation loss: 0.1024
2024-05-23 19:32:27 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch115_loss0.10237690657377244.pypots
2024-05-23 19:32:43 [INFO]: Epoch 116 - training loss: 0.0976, validation loss: 0.1006
2024-05-23 19:32:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch116_loss0.10060319900512696.pypots
2024-05-23 19:33:00 [INFO]: Epoch 117 - training loss: 0.1032, validation loss: 0.1031
2024-05-23 19:33:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI_epoch117_loss0.10310425907373429.pypots
2024-05-23 19:33:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:33:00 [INFO]: Finished training. The best model is from epoch#107.
2024-05-23 19:33:00 [INFO]: Saved the model to overlay_premask_saved_results/round_2/CSDI_air_quality/20240523_T190101/CSDI.pypots
2024-05-23 19:35:18 [INFO]: CSDI on Air-Quality: MAE=0.1071, MSE=0.2213
2024-05-23 19:35:18 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-23 19:35:18 [INFO]: Using the given device: cuda:0
2024-05-23 19:35:18 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240523_T193518
2024-05-23 19:35:18 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240523_T193518/tensorboard
2024-05-23 19:35:18 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 19:35:19 [INFO]: Epoch 001 - training loss: 64281.8270, validation loss: 0.6246
2024-05-23 19:35:19 [INFO]: Epoch 002 - training loss: 41814.6946, validation loss: 0.5218
2024-05-23 19:35:19 [INFO]: Epoch 003 - training loss: 41503.7041, validation loss: 0.4717
2024-05-23 19:35:19 [INFO]: Epoch 004 - training loss: 41361.7979, validation loss: 0.4535
2024-05-23 19:35:20 [INFO]: Epoch 005 - training loss: 41273.6354, validation loss: 0.4065
2024-05-23 19:35:20 [INFO]: Epoch 006 - training loss: 41263.6095, validation loss: 0.3872
2024-05-23 19:35:20 [INFO]: Epoch 007 - training loss: 41180.0684, validation loss: 0.3468
2024-05-23 19:35:20 [INFO]: Epoch 008 - training loss: 41141.4457, validation loss: 0.3419
2024-05-23 19:35:21 [INFO]: Epoch 009 - training loss: 41106.0421, validation loss: 0.3290
2024-05-23 19:35:21 [INFO]: Epoch 010 - training loss: 41078.3725, validation loss: 0.2997
2024-05-23 19:35:21 [INFO]: Epoch 011 - training loss: 41047.8922, validation loss: 0.2970
2024-05-23 19:35:21 [INFO]: Epoch 012 - training loss: 41031.0712, validation loss: 0.2837
2024-05-23 19:35:21 [INFO]: Epoch 013 - training loss: 41018.2160, validation loss: 0.2971
2024-05-23 19:35:22 [INFO]: Epoch 014 - training loss: 41014.3235, validation loss: 0.2934
2024-05-23 19:35:22 [INFO]: Epoch 015 - training loss: 41023.4563, validation loss: 0.3323
2024-05-23 19:35:22 [INFO]: Epoch 016 - training loss: 41005.2698, validation loss: 0.2735
2024-05-23 19:35:22 [INFO]: Epoch 017 - training loss: 40976.1360, validation loss: 0.2595
2024-05-23 19:35:23 [INFO]: Epoch 018 - training loss: 40969.4049, validation loss: 0.2619
2024-05-23 19:35:23 [INFO]: Epoch 019 - training loss: 40963.4447, validation loss: 0.2735
2024-05-23 19:35:23 [INFO]: Epoch 020 - training loss: 40966.5699, validation loss: 0.2543
2024-05-23 19:35:23 [INFO]: Epoch 021 - training loss: 40945.1908, validation loss: 0.2553
2024-05-23 19:35:24 [INFO]: Epoch 022 - training loss: 40938.4638, validation loss: 0.2573
2024-05-23 19:35:24 [INFO]: Epoch 023 - training loss: 40933.9032, validation loss: 0.2470
2024-05-23 19:35:24 [INFO]: Epoch 024 - training loss: 40944.7260, validation loss: 0.2560
2024-05-23 19:35:24 [INFO]: Epoch 025 - training loss: 40966.8870, validation loss: 0.2571
2024-05-23 19:35:25 [INFO]: Epoch 026 - training loss: 40936.3750, validation loss: 0.2409
2024-05-23 19:35:25 [INFO]: Epoch 027 - training loss: 40927.2041, validation loss: 0.2542
2024-05-23 19:35:25 [INFO]: Epoch 028 - training loss: 40942.6253, validation loss: 0.2554
2024-05-23 19:35:25 [INFO]: Epoch 029 - training loss: 40943.5519, validation loss: 0.3522
2024-05-23 19:35:26 [INFO]: Epoch 030 - training loss: 41139.9595, validation loss: 0.2750
2024-05-23 19:35:26 [INFO]: Epoch 031 - training loss: 40998.3540, validation loss: 0.2804
2024-05-23 19:35:26 [INFO]: Epoch 032 - training loss: 40968.0302, validation loss: 0.2408
2024-05-23 19:35:26 [INFO]: Epoch 033 - training loss: 40921.7274, validation loss: 0.2302
2024-05-23 19:35:27 [INFO]: Epoch 034 - training loss: 40902.0036, validation loss: 0.2287
2024-05-23 19:35:27 [INFO]: Epoch 035 - training loss: 40893.7650, validation loss: 0.2235
2024-05-23 19:35:27 [INFO]: Epoch 036 - training loss: 40891.3056, validation loss: 0.2227
2024-05-23 19:35:27 [INFO]: Epoch 037 - training loss: 40885.8116, validation loss: 0.2196
2024-05-23 19:35:28 [INFO]: Epoch 038 - training loss: 40880.2513, validation loss: 0.2173
2024-05-23 19:35:28 [INFO]: Epoch 039 - training loss: 40880.6972, validation loss: 0.2185
2024-05-23 19:35:28 [INFO]: Epoch 040 - training loss: 40878.3859, validation loss: 0.2216
2024-05-23 19:35:28 [INFO]: Epoch 041 - training loss: 40876.9747, validation loss: 0.2255
2024-05-23 19:35:29 [INFO]: Epoch 042 - training loss: 40890.0318, validation loss: 0.2210
2024-05-23 19:35:29 [INFO]: Epoch 043 - training loss: 40875.0448, validation loss: 0.2203
2024-05-23 19:35:29 [INFO]: Epoch 044 - training loss: 40875.3453, validation loss: 0.2172
2024-05-23 19:35:29 [INFO]: Epoch 045 - training loss: 40871.6529, validation loss: 0.2121
2024-05-23 19:35:30 [INFO]: Epoch 046 - training loss: 40869.0683, validation loss: 0.2134
2024-05-23 19:35:30 [INFO]: Epoch 047 - training loss: 40865.5650, validation loss: 0.2212
2024-05-23 19:35:30 [INFO]: Epoch 048 - training loss: 40868.7166, validation loss: 0.2199
2024-05-23 19:35:30 [INFO]: Epoch 049 - training loss: 40870.1451, validation loss: 0.2122
2024-05-23 19:35:31 [INFO]: Epoch 050 - training loss: 40862.0354, validation loss: 0.2112
2024-05-23 19:35:31 [INFO]: Epoch 051 - training loss: 40862.0279, validation loss: 0.2069
2024-05-23 19:35:31 [INFO]: Epoch 052 - training loss: 40859.7707, validation loss: 0.2110
2024-05-23 19:35:31 [INFO]: Epoch 053 - training loss: 40860.9641, validation loss: 0.2135
2024-05-23 19:35:32 [INFO]: Epoch 054 - training loss: 40857.7969, validation loss: 0.2159
2024-05-23 19:35:32 [INFO]: Epoch 055 - training loss: 40868.0095, validation loss: 0.2098
2024-05-23 19:35:32 [INFO]: Epoch 056 - training loss: 40855.6652, validation loss: 0.2217
2024-05-23 19:35:32 [INFO]: Epoch 057 - training loss: 40907.6709, validation loss: 0.2334
2024-05-23 19:35:32 [INFO]: Epoch 058 - training loss: 40916.8725, validation loss: 0.2207
2024-05-23 19:35:33 [INFO]: Epoch 059 - training loss: 40886.1124, validation loss: 0.2311
2024-05-23 19:35:33 [INFO]: Epoch 060 - training loss: 40886.3222, validation loss: 0.2099
2024-05-23 19:35:33 [INFO]: Epoch 061 - training loss: 40944.7477, validation loss: 0.2264
2024-05-23 19:35:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:35:33 [INFO]: Finished training. The best model is from epoch#51.
2024-05-23 19:35:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/GPVAE_air_quality/20240523_T193518/GPVAE.pypots
2024-05-23 19:35:33 [INFO]: GP-VAE on Air-Quality: MAE=0.2951, MSE=0.3510
2024-05-23 19:35:33 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-23 19:35:33 [INFO]: Using the given device: cuda:0
2024-05-23 19:35:33 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240523_T193533
2024-05-23 19:35:33 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/USGAN_air_quality/20240523_T193533/tensorboard
2024-05-23 19:35:33 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 19:35:37 [INFO]: Epoch 001 - generator training loss: 0.4399, discriminator training loss: 0.4536, validation loss: 0.4826
2024-05-23 19:35:41 [INFO]: Epoch 002 - generator training loss: 0.0871, discriminator training loss: 0.3622, validation loss: 0.3551
2024-05-23 19:35:44 [INFO]: Epoch 003 - generator training loss: 0.0265, discriminator training loss: 0.3576, validation loss: 0.2862
2024-05-23 19:35:47 [INFO]: Epoch 004 - generator training loss: -0.0131, discriminator training loss: 0.3555, validation loss: 0.2506
2024-05-23 19:35:51 [INFO]: Epoch 005 - generator training loss: -0.0356, discriminator training loss: 0.3538, validation loss: 0.2263
2024-05-23 19:35:54 [INFO]: Epoch 006 - generator training loss: -0.0509, discriminator training loss: 0.3518, validation loss: 0.2105
2024-05-23 19:35:57 [INFO]: Epoch 007 - generator training loss: -0.0633, discriminator training loss: 0.3500, validation loss: 0.1975
2024-05-23 19:36:01 [INFO]: Epoch 008 - generator training loss: -0.0723, discriminator training loss: 0.3476, validation loss: 0.1875
2024-05-23 19:36:04 [INFO]: Epoch 009 - generator training loss: -0.0808, discriminator training loss: 0.3451, validation loss: 0.1804
2024-05-23 19:36:07 [INFO]: Epoch 010 - generator training loss: -0.0866, discriminator training loss: 0.3427, validation loss: 0.1735
2024-05-23 19:36:11 [INFO]: Epoch 011 - generator training loss: -0.0911, discriminator training loss: 0.3401, validation loss: 0.1671
2024-05-23 19:36:14 [INFO]: Epoch 012 - generator training loss: -0.0953, discriminator training loss: 0.3373, validation loss: 0.1619
2024-05-23 19:36:17 [INFO]: Epoch 013 - generator training loss: -0.0975, discriminator training loss: 0.3343, validation loss: 0.1572
2024-05-23 19:36:21 [INFO]: Epoch 014 - generator training loss: -0.0997, discriminator training loss: 0.3308, validation loss: 0.1534
2024-05-23 19:36:24 [INFO]: Epoch 015 - generator training loss: -0.1008, discriminator training loss: 0.3273, validation loss: 0.1491
2024-05-23 19:36:28 [INFO]: Epoch 016 - generator training loss: -0.1017, discriminator training loss: 0.3238, validation loss: 0.1465
2024-05-23 19:36:31 [INFO]: Epoch 017 - generator training loss: -0.1006, discriminator training loss: 0.3200, validation loss: 0.1440
2024-05-23 19:36:34 [INFO]: Epoch 018 - generator training loss: -0.1011, discriminator training loss: 0.3162, validation loss: 0.1413
2024-05-23 19:36:38 [INFO]: Epoch 019 - generator training loss: -0.1000, discriminator training loss: 0.3123, validation loss: 0.1386
2024-05-23 19:36:41 [INFO]: Epoch 020 - generator training loss: -0.1005, discriminator training loss: 0.3077, validation loss: 0.1361
2024-05-23 19:36:44 [INFO]: Epoch 021 - generator training loss: -0.0983, discriminator training loss: 0.3035, validation loss: 0.1346
2024-05-23 19:36:48 [INFO]: Epoch 022 - generator training loss: -0.0971, discriminator training loss: 0.2995, validation loss: 0.1323
2024-05-23 19:36:51 [INFO]: Epoch 023 - generator training loss: -0.0955, discriminator training loss: 0.2950, validation loss: 0.1301
2024-05-23 19:36:54 [INFO]: Epoch 024 - generator training loss: -0.0941, discriminator training loss: 0.2910, validation loss: 0.1281
2024-05-23 19:36:58 [INFO]: Epoch 025 - generator training loss: -0.0928, discriminator training loss: 0.2869, validation loss: 0.1263
2024-05-23 19:37:01 [INFO]: Epoch 026 - generator training loss: -0.0923, discriminator training loss: 0.2832, validation loss: 0.1248
2024-05-23 19:37:05 [INFO]: Epoch 027 - generator training loss: -0.0905, discriminator training loss: 0.2790, validation loss: 0.1229
2024-05-23 19:37:08 [INFO]: Epoch 028 - generator training loss: -0.0890, discriminator training loss: 0.2754, validation loss: 0.1214
2024-05-23 19:37:11 [INFO]: Epoch 029 - generator training loss: -0.0858, discriminator training loss: 0.2721, validation loss: 0.1201
2024-05-23 19:37:15 [INFO]: Epoch 030 - generator training loss: -0.0869, discriminator training loss: 0.2690, validation loss: 0.1184
2024-05-23 19:37:18 [INFO]: Epoch 031 - generator training loss: -0.0857, discriminator training loss: 0.2658, validation loss: 0.1175
2024-05-23 19:37:21 [INFO]: Epoch 032 - generator training loss: -0.0834, discriminator training loss: 0.2626, validation loss: 0.1162
2024-05-23 19:37:25 [INFO]: Epoch 033 - generator training loss: -0.0834, discriminator training loss: 0.2597, validation loss: 0.1148
2024-05-23 19:37:28 [INFO]: Epoch 034 - generator training loss: -0.0824, discriminator training loss: 0.2568, validation loss: 0.1142
2024-05-23 19:37:31 [INFO]: Epoch 035 - generator training loss: -0.0808, discriminator training loss: 0.2546, validation loss: 0.1125
2024-05-23 19:37:35 [INFO]: Epoch 036 - generator training loss: -0.0807, discriminator training loss: 0.2520, validation loss: 0.1122
2024-05-23 19:37:38 [INFO]: Epoch 037 - generator training loss: -0.0794, discriminator training loss: 0.2495, validation loss: 0.1115
2024-05-23 19:37:41 [INFO]: Epoch 038 - generator training loss: -0.0789, discriminator training loss: 0.2476, validation loss: 0.1103
2024-05-23 19:37:45 [INFO]: Epoch 039 - generator training loss: -0.0784, discriminator training loss: 0.2458, validation loss: 0.1088
2024-05-23 19:37:48 [INFO]: Epoch 040 - generator training loss: -0.0771, discriminator training loss: 0.2437, validation loss: 0.1084
2024-05-23 19:37:51 [INFO]: Epoch 041 - generator training loss: -0.0782, discriminator training loss: 0.2419, validation loss: 0.1074
2024-05-23 19:37:55 [INFO]: Epoch 042 - generator training loss: -0.0778, discriminator training loss: 0.2401, validation loss: 0.1061
2024-05-23 19:37:58 [INFO]: Epoch 043 - generator training loss: -0.0773, discriminator training loss: 0.2383, validation loss: 0.1054
2024-05-23 19:38:01 [INFO]: Epoch 044 - generator training loss: -0.0768, discriminator training loss: 0.2369, validation loss: 0.1049
2024-05-23 19:38:05 [INFO]: Epoch 045 - generator training loss: -0.0760, discriminator training loss: 0.2351, validation loss: 0.1040
2024-05-23 19:38:08 [INFO]: Epoch 046 - generator training loss: -0.0759, discriminator training loss: 0.2340, validation loss: 0.1034
2024-05-23 19:38:11 [INFO]: Epoch 047 - generator training loss: -0.0757, discriminator training loss: 0.2326, validation loss: 0.1031
2024-05-23 19:38:15 [INFO]: Epoch 048 - generator training loss: -0.0756, discriminator training loss: 0.2317, validation loss: 0.1024
2024-05-23 19:38:18 [INFO]: Epoch 049 - generator training loss: -0.0751, discriminator training loss: 0.2298, validation loss: 0.1020
2024-05-23 19:38:22 [INFO]: Epoch 050 - generator training loss: -0.0758, discriminator training loss: 0.2289, validation loss: 0.1010
2024-05-23 19:38:25 [INFO]: Epoch 051 - generator training loss: -0.0744, discriminator training loss: 0.2283, validation loss: 0.1004
2024-05-23 19:38:28 [INFO]: Epoch 052 - generator training loss: -0.0753, discriminator training loss: 0.2269, validation loss: 0.1001
2024-05-23 19:38:32 [INFO]: Epoch 053 - generator training loss: -0.0754, discriminator training loss: 0.2258, validation loss: 0.0993
2024-05-23 19:38:35 [INFO]: Epoch 054 - generator training loss: -0.0754, discriminator training loss: 0.2252, validation loss: 0.0987
2024-05-23 19:38:38 [INFO]: Epoch 055 - generator training loss: -0.0745, discriminator training loss: 0.2242, validation loss: 0.0983
2024-05-23 19:38:42 [INFO]: Epoch 056 - generator training loss: -0.0750, discriminator training loss: 0.2234, validation loss: 0.0983
2024-05-23 19:38:45 [INFO]: Epoch 057 - generator training loss: -0.0738, discriminator training loss: 0.2223, validation loss: 0.0976
2024-05-23 19:38:48 [INFO]: Epoch 058 - generator training loss: -0.0759, discriminator training loss: 0.2216, validation loss: 0.0969
2024-05-23 19:38:52 [INFO]: Epoch 059 - generator training loss: -0.0750, discriminator training loss: 0.2212, validation loss: 0.0971
2024-05-23 19:38:55 [INFO]: Epoch 060 - generator training loss: -0.0752, discriminator training loss: 0.2206, validation loss: 0.0965
2024-05-23 19:38:58 [INFO]: Epoch 061 - generator training loss: -0.0752, discriminator training loss: 0.2196, validation loss: 0.0967
2024-05-23 19:39:02 [INFO]: Epoch 062 - generator training loss: -0.0766, discriminator training loss: 0.2194, validation loss: 0.0956
2024-05-23 19:39:05 [INFO]: Epoch 063 - generator training loss: -0.0756, discriminator training loss: 0.2184, validation loss: 0.0948
2024-05-23 19:39:08 [INFO]: Epoch 064 - generator training loss: -0.0755, discriminator training loss: 0.2179, validation loss: 0.0950
2024-05-23 19:39:12 [INFO]: Epoch 065 - generator training loss: -0.0757, discriminator training loss: 0.2175, validation loss: 0.0945
2024-05-23 19:39:15 [INFO]: Epoch 066 - generator training loss: -0.0757, discriminator training loss: 0.2170, validation loss: 0.0941
2024-05-23 19:39:18 [INFO]: Epoch 067 - generator training loss: -0.0760, discriminator training loss: 0.2162, validation loss: 0.0938
2024-05-23 19:39:22 [INFO]: Epoch 068 - generator training loss: -0.0764, discriminator training loss: 0.2156, validation loss: 0.0934
2024-05-23 19:39:25 [INFO]: Epoch 069 - generator training loss: -0.0762, discriminator training loss: 0.2156, validation loss: 0.0932
2024-05-23 19:39:29 [INFO]: Epoch 070 - generator training loss: -0.0766, discriminator training loss: 0.2150, validation loss: 0.0929
2024-05-23 19:39:32 [INFO]: Epoch 071 - generator training loss: -0.0758, discriminator training loss: 0.2143, validation loss: 0.0929
2024-05-23 19:39:36 [INFO]: Epoch 072 - generator training loss: -0.0767, discriminator training loss: 0.2142, validation loss: 0.0930
2024-05-23 19:39:40 [INFO]: Epoch 073 - generator training loss: -0.0762, discriminator training loss: 0.2141, validation loss: 0.0919
2024-05-23 19:39:43 [INFO]: Epoch 074 - generator training loss: -0.0771, discriminator training loss: 0.2129, validation loss: 0.0919
2024-05-23 19:39:47 [INFO]: Epoch 075 - generator training loss: -0.0772, discriminator training loss: 0.2129, validation loss: 0.0921
2024-05-23 19:39:50 [INFO]: Epoch 076 - generator training loss: -0.0774, discriminator training loss: 0.2124, validation loss: 0.0916
2024-05-23 19:39:54 [INFO]: Epoch 077 - generator training loss: -0.0778, discriminator training loss: 0.2123, validation loss: 0.0913
2024-05-23 19:39:57 [INFO]: Epoch 078 - generator training loss: -0.0774, discriminator training loss: 0.2116, validation loss: 0.0908
2024-05-23 19:40:01 [INFO]: Epoch 079 - generator training loss: -0.0774, discriminator training loss: 0.2117, validation loss: 0.0907
2024-05-23 19:40:04 [INFO]: Epoch 080 - generator training loss: -0.0775, discriminator training loss: 0.2114, validation loss: 0.0910
2024-05-23 19:40:08 [INFO]: Epoch 081 - generator training loss: -0.0766, discriminator training loss: 0.2107, validation loss: 0.0908
2024-05-23 19:40:12 [INFO]: Epoch 082 - generator training loss: -0.0769, discriminator training loss: 0.2108, validation loss: 0.0905
2024-05-23 19:40:15 [INFO]: Epoch 083 - generator training loss: -0.0781, discriminator training loss: 0.2103, validation loss: 0.0902
2024-05-23 19:40:19 [INFO]: Epoch 084 - generator training loss: -0.0783, discriminator training loss: 0.2103, validation loss: 0.0903
2024-05-23 19:40:22 [INFO]: Epoch 085 - generator training loss: -0.0780, discriminator training loss: 0.2097, validation loss: 0.0898
2024-05-23 19:40:26 [INFO]: Epoch 086 - generator training loss: -0.0774, discriminator training loss: 0.2098, validation loss: 0.0902
2024-05-23 19:40:29 [INFO]: Epoch 087 - generator training loss: -0.0784, discriminator training loss: 0.2095, validation loss: 0.0897
2024-05-23 19:40:33 [INFO]: Epoch 088 - generator training loss: -0.0777, discriminator training loss: 0.2090, validation loss: 0.0900
2024-05-23 19:40:36 [INFO]: Epoch 089 - generator training loss: -0.0785, discriminator training loss: 0.2093, validation loss: 0.0895
2024-05-23 19:40:40 [INFO]: Epoch 090 - generator training loss: -0.0784, discriminator training loss: 0.2086, validation loss: 0.0894
2024-05-23 19:40:43 [INFO]: Epoch 091 - generator training loss: -0.0793, discriminator training loss: 0.2080, validation loss: 0.0892
2024-05-23 19:40:47 [INFO]: Epoch 092 - generator training loss: -0.0794, discriminator training loss: 0.2084, validation loss: 0.0886
2024-05-23 19:40:51 [INFO]: Epoch 093 - generator training loss: -0.0789, discriminator training loss: 0.2077, validation loss: 0.0894
2024-05-23 19:40:54 [INFO]: Epoch 094 - generator training loss: -0.0791, discriminator training loss: 0.2075, validation loss: 0.0890
2024-05-23 19:40:58 [INFO]: Epoch 095 - generator training loss: -0.0800, discriminator training loss: 0.2077, validation loss: 0.0896
2024-05-23 19:41:01 [INFO]: Epoch 096 - generator training loss: -0.0800, discriminator training loss: 0.2074, validation loss: 0.0899
2024-05-23 19:41:05 [INFO]: Epoch 097 - generator training loss: -0.0806, discriminator training loss: 0.2075, validation loss: 0.0893
2024-05-23 19:41:08 [INFO]: Epoch 098 - generator training loss: -0.0813, discriminator training loss: 0.2070, validation loss: 0.0891
2024-05-23 19:41:12 [INFO]: Epoch 099 - generator training loss: -0.0812, discriminator training loss: 0.2070, validation loss: 0.0890
2024-05-23 19:41:15 [INFO]: Epoch 100 - generator training loss: -0.0816, discriminator training loss: 0.2065, validation loss: 0.0894
2024-05-23 19:41:19 [INFO]: Epoch 101 - generator training loss: -0.0812, discriminator training loss: 0.2069, validation loss: 0.0893
2024-05-23 19:41:22 [INFO]: Epoch 102 - generator training loss: -0.0814, discriminator training loss: 0.2064, validation loss: 0.0893
2024-05-23 19:41:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:41:22 [INFO]: Finished training. The best model is from epoch#92.
2024-05-23 19:41:22 [INFO]: Saved the model to overlay_premask_saved_results/round_2/USGAN_air_quality/20240523_T193533/USGAN.pypots
2024-05-23 19:41:23 [INFO]: US-GAN on Air-Quality: MAE=0.1544, MSE=0.1481
2024-05-23 19:41:23 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-23 19:41:23 [INFO]: Using the given device: cuda:0
2024-05-23 19:41:23 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240523_T194123
2024-05-23 19:41:23 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/BRITS_air_quality/20240523_T194123/tensorboard
2024-05-23 19:41:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 19:41:26 [INFO]: Epoch 001 - training loss: 1.4077, validation loss: 0.9081
2024-05-23 19:41:28 [INFO]: Epoch 002 - training loss: 1.1417, validation loss: 0.6559
2024-05-23 19:41:31 [INFO]: Epoch 003 - training loss: 0.9460, validation loss: 0.5474
2024-05-23 19:41:33 [INFO]: Epoch 004 - training loss: 0.8410, validation loss: 0.4821
2024-05-23 19:41:35 [INFO]: Epoch 005 - training loss: 0.7659, validation loss: 0.4362
2024-05-23 19:41:38 [INFO]: Epoch 006 - training loss: 0.7135, validation loss: 0.4012
2024-05-23 19:41:40 [INFO]: Epoch 007 - training loss: 0.6683, validation loss: 0.3720
2024-05-23 19:41:43 [INFO]: Epoch 008 - training loss: 0.6362, validation loss: 0.3484
2024-05-23 19:41:45 [INFO]: Epoch 009 - training loss: 0.6090, validation loss: 0.3303
2024-05-23 19:41:47 [INFO]: Epoch 010 - training loss: 0.5878, validation loss: 0.3145
2024-05-23 19:41:49 [INFO]: Epoch 011 - training loss: 0.5694, validation loss: 0.3017
2024-05-23 19:41:52 [INFO]: Epoch 012 - training loss: 0.5541, validation loss: 0.2903
2024-05-23 19:41:54 [INFO]: Epoch 013 - training loss: 0.5423, validation loss: 0.2807
2024-05-23 19:41:56 [INFO]: Epoch 014 - training loss: 0.5306, validation loss: 0.2715
2024-05-23 19:41:58 [INFO]: Epoch 015 - training loss: 0.5199, validation loss: 0.2642
2024-05-23 19:42:01 [INFO]: Epoch 016 - training loss: 0.5091, validation loss: 0.2573
2024-05-23 19:42:03 [INFO]: Epoch 017 - training loss: 0.5010, validation loss: 0.2513
2024-05-23 19:42:05 [INFO]: Epoch 018 - training loss: 0.4927, validation loss: 0.2454
2024-05-23 19:42:07 [INFO]: Epoch 019 - training loss: 0.4850, validation loss: 0.2402
2024-05-23 19:42:10 [INFO]: Epoch 020 - training loss: 0.4762, validation loss: 0.2352
2024-05-23 19:42:12 [INFO]: Epoch 021 - training loss: 0.4708, validation loss: 0.2309
2024-05-23 19:42:14 [INFO]: Epoch 022 - training loss: 0.4627, validation loss: 0.2265
2024-05-23 19:42:16 [INFO]: Epoch 023 - training loss: 0.4573, validation loss: 0.2227
2024-05-23 19:42:19 [INFO]: Epoch 024 - training loss: 0.4501, validation loss: 0.2187
2024-05-23 19:42:21 [INFO]: Epoch 025 - training loss: 0.4448, validation loss: 0.2152
2024-05-23 19:42:23 [INFO]: Epoch 026 - training loss: 0.4389, validation loss: 0.2116
2024-05-23 19:42:25 [INFO]: Epoch 027 - training loss: 0.4335, validation loss: 0.2080
2024-05-23 19:42:28 [INFO]: Epoch 028 - training loss: 0.4290, validation loss: 0.2048
2024-05-23 19:42:30 [INFO]: Epoch 029 - training loss: 0.4226, validation loss: 0.2022
2024-05-23 19:42:32 [INFO]: Epoch 030 - training loss: 0.4188, validation loss: 0.1989
2024-05-23 19:42:34 [INFO]: Epoch 031 - training loss: 0.4160, validation loss: 0.1961
2024-05-23 19:42:37 [INFO]: Epoch 032 - training loss: 0.4097, validation loss: 0.1930
2024-05-23 19:42:39 [INFO]: Epoch 033 - training loss: 0.4064, validation loss: 0.1907
2024-05-23 19:42:41 [INFO]: Epoch 034 - training loss: 0.4018, validation loss: 0.1878
2024-05-23 19:42:43 [INFO]: Epoch 035 - training loss: 0.3974, validation loss: 0.1855
2024-05-23 19:42:46 [INFO]: Epoch 036 - training loss: 0.3935, validation loss: 0.1832
2024-05-23 19:42:48 [INFO]: Epoch 037 - training loss: 0.3902, validation loss: 0.1811
2024-05-23 19:42:50 [INFO]: Epoch 038 - training loss: 0.3875, validation loss: 0.1785
2024-05-23 19:42:52 [INFO]: Epoch 039 - training loss: 0.3828, validation loss: 0.1761
2024-05-23 19:42:55 [INFO]: Epoch 040 - training loss: 0.3800, validation loss: 0.1745
2024-05-23 19:42:57 [INFO]: Epoch 041 - training loss: 0.3782, validation loss: 0.1723
2024-05-23 19:42:59 [INFO]: Epoch 042 - training loss: 0.3737, validation loss: 0.1701
2024-05-23 19:43:02 [INFO]: Epoch 043 - training loss: 0.3717, validation loss: 0.1681
2024-05-23 19:43:04 [INFO]: Epoch 044 - training loss: 0.3683, validation loss: 0.1661
2024-05-23 19:43:06 [INFO]: Epoch 045 - training loss: 0.3650, validation loss: 0.1647
2024-05-23 19:43:08 [INFO]: Epoch 046 - training loss: 0.3625, validation loss: 0.1627
2024-05-23 19:43:11 [INFO]: Epoch 047 - training loss: 0.3606, validation loss: 0.1610
2024-05-23 19:43:13 [INFO]: Epoch 048 - training loss: 0.3586, validation loss: 0.1599
2024-05-23 19:43:15 [INFO]: Epoch 049 - training loss: 0.3553, validation loss: 0.1582
2024-05-23 19:43:17 [INFO]: Epoch 050 - training loss: 0.3520, validation loss: 0.1567
2024-05-23 19:43:20 [INFO]: Epoch 051 - training loss: 0.3506, validation loss: 0.1552
2024-05-23 19:43:22 [INFO]: Epoch 052 - training loss: 0.3483, validation loss: 0.1543
2024-05-23 19:43:24 [INFO]: Epoch 053 - training loss: 0.3467, validation loss: 0.1529
2024-05-23 19:43:26 [INFO]: Epoch 054 - training loss: 0.3445, validation loss: 0.1518
2024-05-23 19:43:29 [INFO]: Epoch 055 - training loss: 0.3425, validation loss: 0.1508
2024-05-23 19:43:31 [INFO]: Epoch 056 - training loss: 0.3407, validation loss: 0.1499
2024-05-23 19:43:33 [INFO]: Epoch 057 - training loss: 0.3385, validation loss: 0.1486
2024-05-23 19:43:35 [INFO]: Epoch 058 - training loss: 0.3363, validation loss: 0.1478
2024-05-23 19:43:38 [INFO]: Epoch 059 - training loss: 0.3353, validation loss: 0.1470
2024-05-23 19:43:40 [INFO]: Epoch 060 - training loss: 0.3331, validation loss: 0.1463
2024-05-23 19:43:42 [INFO]: Epoch 061 - training loss: 0.3320, validation loss: 0.1451
2024-05-23 19:43:45 [INFO]: Epoch 062 - training loss: 0.3302, validation loss: 0.1445
2024-05-23 19:43:47 [INFO]: Epoch 063 - training loss: 0.3290, validation loss: 0.1438
2024-05-23 19:43:49 [INFO]: Epoch 064 - training loss: 0.3274, validation loss: 0.1428
2024-05-23 19:43:51 [INFO]: Epoch 065 - training loss: 0.3257, validation loss: 0.1421
2024-05-23 19:43:54 [INFO]: Epoch 066 - training loss: 0.3246, validation loss: 0.1412
2024-05-23 19:43:56 [INFO]: Epoch 067 - training loss: 0.3233, validation loss: 0.1407
2024-05-23 19:43:58 [INFO]: Epoch 068 - training loss: 0.3219, validation loss: 0.1402
2024-05-23 19:44:00 [INFO]: Epoch 069 - training loss: 0.3214, validation loss: 0.1394
2024-05-23 19:44:03 [INFO]: Epoch 070 - training loss: 0.3199, validation loss: 0.1390
2024-05-23 19:44:05 [INFO]: Epoch 071 - training loss: 0.3182, validation loss: 0.1381
2024-05-23 19:44:07 [INFO]: Epoch 072 - training loss: 0.3171, validation loss: 0.1376
2024-05-23 19:44:09 [INFO]: Epoch 073 - training loss: 0.3152, validation loss: 0.1373
2024-05-23 19:44:12 [INFO]: Epoch 074 - training loss: 0.3147, validation loss: 0.1365
2024-05-23 19:44:14 [INFO]: Epoch 075 - training loss: 0.3139, validation loss: 0.1362
2024-05-23 19:44:16 [INFO]: Epoch 076 - training loss: 0.3126, validation loss: 0.1357
2024-05-23 19:44:18 [INFO]: Epoch 077 - training loss: 0.3115, validation loss: 0.1348
2024-05-23 19:44:21 [INFO]: Epoch 078 - training loss: 0.3104, validation loss: 0.1346
2024-05-23 19:44:23 [INFO]: Epoch 079 - training loss: 0.3106, validation loss: 0.1342
2024-05-23 19:44:25 [INFO]: Epoch 080 - training loss: 0.3084, validation loss: 0.1335
2024-05-23 19:44:27 [INFO]: Epoch 081 - training loss: 0.3082, validation loss: 0.1333
2024-05-23 19:44:30 [INFO]: Epoch 082 - training loss: 0.3072, validation loss: 0.1327
2024-05-23 19:44:32 [INFO]: Epoch 083 - training loss: 0.3066, validation loss: 0.1322
2024-05-23 19:44:34 [INFO]: Epoch 084 - training loss: 0.3059, validation loss: 0.1318
2024-05-23 19:44:36 [INFO]: Epoch 085 - training loss: 0.3041, validation loss: 0.1314
2024-05-23 19:44:39 [INFO]: Epoch 086 - training loss: 0.3031, validation loss: 0.1308
2024-05-23 19:44:41 [INFO]: Epoch 087 - training loss: 0.3022, validation loss: 0.1305
2024-05-23 19:44:43 [INFO]: Epoch 088 - training loss: 0.3021, validation loss: 0.1301
2024-05-23 19:44:46 [INFO]: Epoch 089 - training loss: 0.3014, validation loss: 0.1297
2024-05-23 19:44:48 [INFO]: Epoch 090 - training loss: 0.3002, validation loss: 0.1294
2024-05-23 19:44:50 [INFO]: Epoch 091 - training loss: 0.2996, validation loss: 0.1287
2024-05-23 19:44:52 [INFO]: Epoch 092 - training loss: 0.2990, validation loss: 0.1285
2024-05-23 19:44:55 [INFO]: Epoch 093 - training loss: 0.2986, validation loss: 0.1283
2024-05-23 19:44:57 [INFO]: Epoch 094 - training loss: 0.2973, validation loss: 0.1279
2024-05-23 19:44:59 [INFO]: Epoch 095 - training loss: 0.2967, validation loss: 0.1275
2024-05-23 19:45:01 [INFO]: Epoch 096 - training loss: 0.2961, validation loss: 0.1271
2024-05-23 19:45:04 [INFO]: Epoch 097 - training loss: 0.2951, validation loss: 0.1268
2024-05-23 19:45:06 [INFO]: Epoch 098 - training loss: 0.2950, validation loss: 0.1265
2024-05-23 19:45:08 [INFO]: Epoch 099 - training loss: 0.2937, validation loss: 0.1262
2024-05-23 19:45:10 [INFO]: Epoch 100 - training loss: 0.2938, validation loss: 0.1256
2024-05-23 19:45:13 [INFO]: Epoch 101 - training loss: 0.2930, validation loss: 0.1255
2024-05-23 19:45:15 [INFO]: Epoch 102 - training loss: 0.2921, validation loss: 0.1248
2024-05-23 19:45:17 [INFO]: Epoch 103 - training loss: 0.2910, validation loss: 0.1249
2024-05-23 19:45:19 [INFO]: Epoch 104 - training loss: 0.2910, validation loss: 0.1243
2024-05-23 19:45:22 [INFO]: Epoch 105 - training loss: 0.2904, validation loss: 0.1241
2024-05-23 19:45:24 [INFO]: Epoch 106 - training loss: 0.2893, validation loss: 0.1236
2024-05-23 19:45:26 [INFO]: Epoch 107 - training loss: 0.2898, validation loss: 0.1235
2024-05-23 19:45:28 [INFO]: Epoch 108 - training loss: 0.2892, validation loss: 0.1231
2024-05-23 19:45:31 [INFO]: Epoch 109 - training loss: 0.2880, validation loss: 0.1228
2024-05-23 19:45:33 [INFO]: Epoch 110 - training loss: 0.2878, validation loss: 0.1223
2024-05-23 19:45:35 [INFO]: Epoch 111 - training loss: 0.2869, validation loss: 0.1221
2024-05-23 19:45:37 [INFO]: Epoch 112 - training loss: 0.2864, validation loss: 0.1218
2024-05-23 19:45:40 [INFO]: Epoch 113 - training loss: 0.2858, validation loss: 0.1215
2024-05-23 19:45:42 [INFO]: Epoch 114 - training loss: 0.2850, validation loss: 0.1215
2024-05-23 19:45:44 [INFO]: Epoch 115 - training loss: 0.2844, validation loss: 0.1210
2024-05-23 19:45:46 [INFO]: Epoch 116 - training loss: 0.2841, validation loss: 0.1205
2024-05-23 19:45:49 [INFO]: Epoch 117 - training loss: 0.2839, validation loss: 0.1203
2024-05-23 19:45:51 [INFO]: Epoch 118 - training loss: 0.2833, validation loss: 0.1202
2024-05-23 19:45:53 [INFO]: Epoch 119 - training loss: 0.2827, validation loss: 0.1197
2024-05-23 19:45:55 [INFO]: Epoch 120 - training loss: 0.2830, validation loss: 0.1195
2024-05-23 19:45:58 [INFO]: Epoch 121 - training loss: 0.2821, validation loss: 0.1194
2024-05-23 19:46:00 [INFO]: Epoch 122 - training loss: 0.2811, validation loss: 0.1190
2024-05-23 19:46:02 [INFO]: Epoch 123 - training loss: 0.2809, validation loss: 0.1187
2024-05-23 19:46:04 [INFO]: Epoch 124 - training loss: 0.2806, validation loss: 0.1184
2024-05-23 19:46:07 [INFO]: Epoch 125 - training loss: 0.2800, validation loss: 0.1183
2024-05-23 19:46:09 [INFO]: Epoch 126 - training loss: 0.2799, validation loss: 0.1179
2024-05-23 19:46:11 [INFO]: Epoch 127 - training loss: 0.2789, validation loss: 0.1175
2024-05-23 19:46:13 [INFO]: Epoch 128 - training loss: 0.2786, validation loss: 0.1173
2024-05-23 19:46:16 [INFO]: Epoch 129 - training loss: 0.2783, validation loss: 0.1169
2024-05-23 19:46:18 [INFO]: Epoch 130 - training loss: 0.2775, validation loss: 0.1168
2024-05-23 19:46:20 [INFO]: Epoch 131 - training loss: 0.2774, validation loss: 0.1166
2024-05-23 19:46:23 [INFO]: Epoch 132 - training loss: 0.2774, validation loss: 0.1162
2024-05-23 19:46:25 [INFO]: Epoch 133 - training loss: 0.2764, validation loss: 0.1159
2024-05-23 19:46:27 [INFO]: Epoch 134 - training loss: 0.2761, validation loss: 0.1157
2024-05-23 19:46:29 [INFO]: Epoch 135 - training loss: 0.2758, validation loss: 0.1155
2024-05-23 19:46:32 [INFO]: Epoch 136 - training loss: 0.2753, validation loss: 0.1151
2024-05-23 19:46:34 [INFO]: Epoch 137 - training loss: 0.2749, validation loss: 0.1150
2024-05-23 19:46:36 [INFO]: Epoch 138 - training loss: 0.2747, validation loss: 0.1146
2024-05-23 19:46:38 [INFO]: Epoch 139 - training loss: 0.2745, validation loss: 0.1143
2024-05-23 19:46:41 [INFO]: Epoch 140 - training loss: 0.2737, validation loss: 0.1141
2024-05-23 19:46:43 [INFO]: Epoch 141 - training loss: 0.2734, validation loss: 0.1140
2024-05-23 19:46:45 [INFO]: Epoch 142 - training loss: 0.2729, validation loss: 0.1138
2024-05-23 19:46:47 [INFO]: Epoch 143 - training loss: 0.2734, validation loss: 0.1135
2024-05-23 19:46:50 [INFO]: Epoch 144 - training loss: 0.2722, validation loss: 0.1134
2024-05-23 19:46:52 [INFO]: Epoch 145 - training loss: 0.2716, validation loss: 0.1130
2024-05-23 19:46:54 [INFO]: Epoch 146 - training loss: 0.2718, validation loss: 0.1130
2024-05-23 19:46:56 [INFO]: Epoch 147 - training loss: 0.2712, validation loss: 0.1126
2024-05-23 19:46:59 [INFO]: Epoch 148 - training loss: 0.2709, validation loss: 0.1124
2024-05-23 19:47:01 [INFO]: Epoch 149 - training loss: 0.2702, validation loss: 0.1121
2024-05-23 19:47:03 [INFO]: Epoch 150 - training loss: 0.2707, validation loss: 0.1120
2024-05-23 19:47:05 [INFO]: Epoch 151 - training loss: 0.2697, validation loss: 0.1117
2024-05-23 19:47:08 [INFO]: Epoch 152 - training loss: 0.2694, validation loss: 0.1117
2024-05-23 19:47:10 [INFO]: Epoch 153 - training loss: 0.2694, validation loss: 0.1112
2024-05-23 19:47:12 [INFO]: Epoch 154 - training loss: 0.2686, validation loss: 0.1111
2024-05-23 19:47:14 [INFO]: Epoch 155 - training loss: 0.2686, validation loss: 0.1111
2024-05-23 19:47:17 [INFO]: Epoch 156 - training loss: 0.2685, validation loss: 0.1105
2024-05-23 19:47:19 [INFO]: Epoch 157 - training loss: 0.2676, validation loss: 0.1104
2024-05-23 19:47:21 [INFO]: Epoch 158 - training loss: 0.2678, validation loss: 0.1102
2024-05-23 19:47:23 [INFO]: Epoch 159 - training loss: 0.2670, validation loss: 0.1100
2024-05-23 19:47:26 [INFO]: Epoch 160 - training loss: 0.2670, validation loss: 0.1098
2024-05-23 19:47:28 [INFO]: Epoch 161 - training loss: 0.2678, validation loss: 0.1096
2024-05-23 19:47:30 [INFO]: Epoch 162 - training loss: 0.2664, validation loss: 0.1096
2024-05-23 19:47:32 [INFO]: Epoch 163 - training loss: 0.2663, validation loss: 0.1093
2024-05-23 19:47:35 [INFO]: Epoch 164 - training loss: 0.2655, validation loss: 0.1091
2024-05-23 19:47:37 [INFO]: Epoch 165 - training loss: 0.2654, validation loss: 0.1090
2024-05-23 19:47:39 [INFO]: Epoch 166 - training loss: 0.2653, validation loss: 0.1089
2024-05-23 19:47:41 [INFO]: Epoch 167 - training loss: 0.2651, validation loss: 0.1086
2024-05-23 19:47:44 [INFO]: Epoch 168 - training loss: 0.2646, validation loss: 0.1085
2024-05-23 19:47:46 [INFO]: Epoch 169 - training loss: 0.2641, validation loss: 0.1081
2024-05-23 19:47:48 [INFO]: Epoch 170 - training loss: 0.2643, validation loss: 0.1082
2024-05-23 19:47:50 [INFO]: Epoch 171 - training loss: 0.2639, validation loss: 0.1080
2024-05-23 19:47:53 [INFO]: Epoch 172 - training loss: 0.2639, validation loss: 0.1077
2024-05-23 19:47:55 [INFO]: Epoch 173 - training loss: 0.2639, validation loss: 0.1073
2024-05-23 19:47:57 [INFO]: Epoch 174 - training loss: 0.2628, validation loss: 0.1074
2024-05-23 19:47:59 [INFO]: Epoch 175 - training loss: 0.2630, validation loss: 0.1073
2024-05-23 19:48:02 [INFO]: Epoch 176 - training loss: 0.2624, validation loss: 0.1071
2024-05-23 19:48:04 [INFO]: Epoch 177 - training loss: 0.2619, validation loss: 0.1069
2024-05-23 19:48:06 [INFO]: Epoch 178 - training loss: 0.2617, validation loss: 0.1069
2024-05-23 19:48:09 [INFO]: Epoch 179 - training loss: 0.2613, validation loss: 0.1068
2024-05-23 19:48:11 [INFO]: Epoch 180 - training loss: 0.2612, validation loss: 0.1066
2024-05-23 19:48:13 [INFO]: Epoch 181 - training loss: 0.2618, validation loss: 0.1064
2024-05-23 19:48:15 [INFO]: Epoch 182 - training loss: 0.2614, validation loss: 0.1063
2024-05-23 19:48:18 [INFO]: Epoch 183 - training loss: 0.2611, validation loss: 0.1060
2024-05-23 19:48:20 [INFO]: Epoch 184 - training loss: 0.2609, validation loss: 0.1058
2024-05-23 19:48:22 [INFO]: Epoch 185 - training loss: 0.2604, validation loss: 0.1057
2024-05-23 19:48:24 [INFO]: Epoch 186 - training loss: 0.2600, validation loss: 0.1057
2024-05-23 19:48:27 [INFO]: Epoch 187 - training loss: 0.2600, validation loss: 0.1057
2024-05-23 19:48:29 [INFO]: Epoch 188 - training loss: 0.2593, validation loss: 0.1054
2024-05-23 19:48:31 [INFO]: Epoch 189 - training loss: 0.2588, validation loss: 0.1052
2024-05-23 19:48:33 [INFO]: Epoch 190 - training loss: 0.2592, validation loss: 0.1049
2024-05-23 19:48:36 [INFO]: Epoch 191 - training loss: 0.2593, validation loss: 0.1048
2024-05-23 19:48:38 [INFO]: Epoch 192 - training loss: 0.2584, validation loss: 0.1047
2024-05-23 19:48:40 [INFO]: Epoch 193 - training loss: 0.2581, validation loss: 0.1047
2024-05-23 19:48:42 [INFO]: Epoch 194 - training loss: 0.2582, validation loss: 0.1044
2024-05-23 19:48:45 [INFO]: Epoch 195 - training loss: 0.2584, validation loss: 0.1044
2024-05-23 19:48:47 [INFO]: Epoch 196 - training loss: 0.2578, validation loss: 0.1041
2024-05-23 19:48:49 [INFO]: Epoch 197 - training loss: 0.2578, validation loss: 0.1041
2024-05-23 19:48:51 [INFO]: Epoch 198 - training loss: 0.2573, validation loss: 0.1041
2024-05-23 19:48:54 [INFO]: Epoch 199 - training loss: 0.2569, validation loss: 0.1039
2024-05-23 19:48:56 [INFO]: Epoch 200 - training loss: 0.2571, validation loss: 0.1038
2024-05-23 19:48:58 [INFO]: Epoch 201 - training loss: 0.2564, validation loss: 0.1037
2024-05-23 19:49:00 [INFO]: Epoch 202 - training loss: 0.2562, validation loss: 0.1036
2024-05-23 19:49:03 [INFO]: Epoch 203 - training loss: 0.2555, validation loss: 0.1035
2024-05-23 19:49:05 [INFO]: Epoch 204 - training loss: 0.2562, validation loss: 0.1033
2024-05-23 19:49:07 [INFO]: Epoch 205 - training loss: 0.2558, validation loss: 0.1031
2024-05-23 19:49:09 [INFO]: Epoch 206 - training loss: 0.2553, validation loss: 0.1030
2024-05-23 19:49:12 [INFO]: Epoch 207 - training loss: 0.2555, validation loss: 0.1031
2024-05-23 19:49:14 [INFO]: Epoch 208 - training loss: 0.2551, validation loss: 0.1028
2024-05-23 19:49:16 [INFO]: Epoch 209 - training loss: 0.2548, validation loss: 0.1028
2024-05-23 19:49:18 [INFO]: Epoch 210 - training loss: 0.2550, validation loss: 0.1029
2024-05-23 19:49:21 [INFO]: Epoch 211 - training loss: 0.2544, validation loss: 0.1026
2024-05-23 19:49:23 [INFO]: Epoch 212 - training loss: 0.2543, validation loss: 0.1023
2024-05-23 19:49:25 [INFO]: Epoch 213 - training loss: 0.2537, validation loss: 0.1022
2024-05-23 19:49:27 [INFO]: Epoch 214 - training loss: 0.2540, validation loss: 0.1021
2024-05-23 19:49:30 [INFO]: Epoch 215 - training loss: 0.2537, validation loss: 0.1020
2024-05-23 19:49:32 [INFO]: Epoch 216 - training loss: 0.2537, validation loss: 0.1019
2024-05-23 19:49:34 [INFO]: Epoch 217 - training loss: 0.2529, validation loss: 0.1021
2024-05-23 19:49:36 [INFO]: Epoch 218 - training loss: 0.2535, validation loss: 0.1015
2024-05-23 19:49:39 [INFO]: Epoch 219 - training loss: 0.2529, validation loss: 0.1016
2024-05-23 19:49:41 [INFO]: Epoch 220 - training loss: 0.2532, validation loss: 0.1017
2024-05-23 19:49:43 [INFO]: Epoch 221 - training loss: 0.2528, validation loss: 0.1016
2024-05-23 19:49:45 [INFO]: Epoch 222 - training loss: 0.2527, validation loss: 0.1015
2024-05-23 19:49:48 [INFO]: Epoch 223 - training loss: 0.2530, validation loss: 0.1014
2024-05-23 19:49:50 [INFO]: Epoch 224 - training loss: 0.2518, validation loss: 0.1014
2024-05-23 19:49:53 [INFO]: Epoch 225 - training loss: 0.2517, validation loss: 0.1012
2024-05-23 19:49:55 [INFO]: Epoch 226 - training loss: 0.2518, validation loss: 0.1011
2024-05-23 19:49:58 [INFO]: Epoch 227 - training loss: 0.2513, validation loss: 0.1011
2024-05-23 19:50:00 [INFO]: Epoch 228 - training loss: 0.2510, validation loss: 0.1008
2024-05-23 19:50:03 [INFO]: Epoch 229 - training loss: 0.2514, validation loss: 0.1008
2024-05-23 19:50:05 [INFO]: Epoch 230 - training loss: 0.2507, validation loss: 0.1008
2024-05-23 19:50:07 [INFO]: Epoch 231 - training loss: 0.2504, validation loss: 0.1007
2024-05-23 19:50:10 [INFO]: Epoch 232 - training loss: 0.2504, validation loss: 0.1005
2024-05-23 19:50:12 [INFO]: Epoch 233 - training loss: 0.2505, validation loss: 0.1004
2024-05-23 19:50:14 [INFO]: Epoch 234 - training loss: 0.2503, validation loss: 0.1003
2024-05-23 19:50:17 [INFO]: Epoch 235 - training loss: 0.2496, validation loss: 0.1006
2024-05-23 19:50:19 [INFO]: Epoch 236 - training loss: 0.2498, validation loss: 0.1000
2024-05-23 19:50:21 [INFO]: Epoch 237 - training loss: 0.2500, validation loss: 0.1001
2024-05-23 19:50:23 [INFO]: Epoch 238 - training loss: 0.2491, validation loss: 0.1001
2024-05-23 19:50:26 [INFO]: Epoch 239 - training loss: 0.2492, validation loss: 0.1000
2024-05-23 19:50:28 [INFO]: Epoch 240 - training loss: 0.2499, validation loss: 0.0999
2024-05-23 19:50:30 [INFO]: Epoch 241 - training loss: 0.2489, validation loss: 0.0998
2024-05-23 19:50:32 [INFO]: Epoch 242 - training loss: 0.2490, validation loss: 0.0999
2024-05-23 19:50:35 [INFO]: Epoch 243 - training loss: 0.2490, validation loss: 0.0996
2024-05-23 19:50:37 [INFO]: Epoch 244 - training loss: 0.2483, validation loss: 0.0997
2024-05-23 19:50:39 [INFO]: Epoch 245 - training loss: 0.2486, validation loss: 0.0996
2024-05-23 19:50:42 [INFO]: Epoch 246 - training loss: 0.2481, validation loss: 0.0995
2024-05-23 19:50:44 [INFO]: Epoch 247 - training loss: 0.2477, validation loss: 0.0993
2024-05-23 19:50:46 [INFO]: Epoch 248 - training loss: 0.2485, validation loss: 0.0996
2024-05-23 19:50:48 [INFO]: Epoch 249 - training loss: 0.2475, validation loss: 0.0994
2024-05-23 19:50:51 [INFO]: Epoch 250 - training loss: 0.2476, validation loss: 0.0993
2024-05-23 19:50:53 [INFO]: Epoch 251 - training loss: 0.2471, validation loss: 0.0992
2024-05-23 19:50:55 [INFO]: Epoch 252 - training loss: 0.2476, validation loss: 0.0992
2024-05-23 19:50:57 [INFO]: Epoch 253 - training loss: 0.2475, validation loss: 0.0991
2024-05-23 19:51:00 [INFO]: Epoch 254 - training loss: 0.2469, validation loss: 0.0990
2024-05-23 19:51:02 [INFO]: Epoch 255 - training loss: 0.2471, validation loss: 0.0990
2024-05-23 19:51:04 [INFO]: Epoch 256 - training loss: 0.2472, validation loss: 0.0988
2024-05-23 19:51:07 [INFO]: Epoch 257 - training loss: 0.2458, validation loss: 0.0987
2024-05-23 19:51:09 [INFO]: Epoch 258 - training loss: 0.2462, validation loss: 0.0987
2024-05-23 19:51:11 [INFO]: Epoch 259 - training loss: 0.2460, validation loss: 0.0988
2024-05-23 19:51:13 [INFO]: Epoch 260 - training loss: 0.2470, validation loss: 0.0987
2024-05-23 19:51:16 [INFO]: Epoch 261 - training loss: 0.2460, validation loss: 0.0986
2024-05-23 19:51:18 [INFO]: Epoch 262 - training loss: 0.2460, validation loss: 0.0986
2024-05-23 19:51:20 [INFO]: Epoch 263 - training loss: 0.2455, validation loss: 0.0985
2024-05-23 19:51:22 [INFO]: Epoch 264 - training loss: 0.2455, validation loss: 0.0983
2024-05-23 19:51:25 [INFO]: Epoch 265 - training loss: 0.2459, validation loss: 0.0982
2024-05-23 19:51:27 [INFO]: Epoch 266 - training loss: 0.2453, validation loss: 0.0983
2024-05-23 19:51:29 [INFO]: Epoch 267 - training loss: 0.2453, validation loss: 0.0984
2024-05-23 19:51:32 [INFO]: Epoch 268 - training loss: 0.2448, validation loss: 0.0983
2024-05-23 19:51:34 [INFO]: Epoch 269 - training loss: 0.2445, validation loss: 0.0981
2024-05-23 19:51:36 [INFO]: Epoch 270 - training loss: 0.2448, validation loss: 0.0983
2024-05-23 19:51:38 [INFO]: Epoch 271 - training loss: 0.2446, validation loss: 0.0980
2024-05-23 19:51:41 [INFO]: Epoch 272 - training loss: 0.2442, validation loss: 0.0980
2024-05-23 19:51:43 [INFO]: Epoch 273 - training loss: 0.2448, validation loss: 0.0979
2024-05-23 19:51:45 [INFO]: Epoch 274 - training loss: 0.2441, validation loss: 0.0978
2024-05-23 19:51:48 [INFO]: Epoch 275 - training loss: 0.2438, validation loss: 0.0979
2024-05-23 19:51:50 [INFO]: Epoch 276 - training loss: 0.2438, validation loss: 0.0977
2024-05-23 19:51:52 [INFO]: Epoch 277 - training loss: 0.2439, validation loss: 0.0976
2024-05-23 19:51:54 [INFO]: Epoch 278 - training loss: 0.2434, validation loss: 0.0977
2024-05-23 19:51:57 [INFO]: Epoch 279 - training loss: 0.2435, validation loss: 0.0977
2024-05-23 19:51:59 [INFO]: Epoch 280 - training loss: 0.2432, validation loss: 0.0977
2024-05-23 19:52:01 [INFO]: Epoch 281 - training loss: 0.2430, validation loss: 0.0976
2024-05-23 19:52:03 [INFO]: Epoch 282 - training loss: 0.2428, validation loss: 0.0976
2024-05-23 19:52:06 [INFO]: Epoch 283 - training loss: 0.2430, validation loss: 0.0975
2024-05-23 19:52:08 [INFO]: Epoch 284 - training loss: 0.2429, validation loss: 0.0974
2024-05-23 19:52:10 [INFO]: Epoch 285 - training loss: 0.2427, validation loss: 0.0974
2024-05-23 19:52:13 [INFO]: Epoch 286 - training loss: 0.2428, validation loss: 0.0977
2024-05-23 19:52:15 [INFO]: Epoch 287 - training loss: 0.2427, validation loss: 0.0973
2024-05-23 19:52:17 [INFO]: Epoch 288 - training loss: 0.2422, validation loss: 0.0974
2024-05-23 19:52:19 [INFO]: Epoch 289 - training loss: 0.2418, validation loss: 0.0973
2024-05-23 19:52:22 [INFO]: Epoch 290 - training loss: 0.2420, validation loss: 0.0972
2024-05-23 19:52:24 [INFO]: Epoch 291 - training loss: 0.2419, validation loss: 0.0973
2024-05-23 19:52:26 [INFO]: Epoch 292 - training loss: 0.2416, validation loss: 0.0975
2024-05-23 19:52:28 [INFO]: Epoch 293 - training loss: 0.2418, validation loss: 0.0973
2024-05-23 19:52:31 [INFO]: Epoch 294 - training loss: 0.2413, validation loss: 0.0973
2024-05-23 19:52:33 [INFO]: Epoch 295 - training loss: 0.2422, validation loss: 0.0971
2024-05-23 19:52:35 [INFO]: Epoch 296 - training loss: 0.2412, validation loss: 0.0971
2024-05-23 19:52:38 [INFO]: Epoch 297 - training loss: 0.2409, validation loss: 0.0969
2024-05-23 19:52:40 [INFO]: Epoch 298 - training loss: 0.2415, validation loss: 0.0971
2024-05-23 19:52:42 [INFO]: Epoch 299 - training loss: 0.2410, validation loss: 0.0969
2024-05-23 19:52:44 [INFO]: Epoch 300 - training loss: 0.2410, validation loss: 0.0968
2024-05-23 19:52:44 [INFO]: Finished training. The best model is from epoch#300.
2024-05-23 19:52:44 [INFO]: Saved the model to overlay_premask_saved_results/round_2/BRITS_air_quality/20240523_T194123/BRITS.pypots
2024-05-23 19:52:45 [INFO]: BRITS on Air-Quality: MAE=0.1441, MSE=0.1654
2024-05-23 19:52:45 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-23 19:52:45 [INFO]: Using the given device: cuda:0
2024-05-23 19:52:45 [INFO]: Model files will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245
2024-05-23 19:52:45 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/tensorboard
2024-05-23 19:52:45 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 19:52:48 [INFO]: Epoch 001 - training loss: 1.3789, validation loss: 0.7784
2024-05-23 19:52:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch1_loss0.7784264057874679.pypots
2024-05-23 19:52:52 [INFO]: Epoch 002 - training loss: 1.0315, validation loss: 0.7176
2024-05-23 19:52:52 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch2_loss0.7175766855478287.pypots
2024-05-23 19:52:55 [INFO]: Epoch 003 - training loss: 0.9515, validation loss: 0.6975
2024-05-23 19:52:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch3_loss0.6975435823202133.pypots
2024-05-23 19:52:58 [INFO]: Epoch 004 - training loss: 0.9392, validation loss: 0.6847
2024-05-23 19:52:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch4_loss0.6846569240093231.pypots
2024-05-23 19:53:01 [INFO]: Epoch 005 - training loss: 0.9326, validation loss: 0.6757
2024-05-23 19:53:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch5_loss0.6756813764572144.pypots
2024-05-23 19:53:04 [INFO]: Epoch 006 - training loss: 0.9140, validation loss: 0.6686
2024-05-23 19:53:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch6_loss0.6685724973678588.pypots
2024-05-23 19:53:07 [INFO]: Epoch 007 - training loss: 0.8916, validation loss: 0.6642
2024-05-23 19:53:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch7_loss0.664211568236351.pypots
2024-05-23 19:53:10 [INFO]: Epoch 008 - training loss: 0.8987, validation loss: 0.6587
2024-05-23 19:53:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch8_loss0.6586925446987152.pypots
2024-05-23 19:53:14 [INFO]: Epoch 009 - training loss: 0.8940, validation loss: 0.6556
2024-05-23 19:53:14 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch9_loss0.6555623412132263.pypots
2024-05-23 19:53:17 [INFO]: Epoch 010 - training loss: 0.8702, validation loss: 0.6541
2024-05-23 19:53:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch10_loss0.6541490644216538.pypots
2024-05-23 19:53:20 [INFO]: Epoch 011 - training loss: 0.8744, validation loss: 0.6509
2024-05-23 19:53:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch11_loss0.6508606106042862.pypots
2024-05-23 19:53:23 [INFO]: Epoch 012 - training loss: 0.8688, validation loss: 0.6494
2024-05-23 19:53:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch12_loss0.6494024276733399.pypots
2024-05-23 19:53:26 [INFO]: Epoch 013 - training loss: 0.8699, validation loss: 0.6488
2024-05-23 19:53:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch13_loss0.6488088071346283.pypots
2024-05-23 19:53:29 [INFO]: Epoch 014 - training loss: 0.8567, validation loss: 0.6488
2024-05-23 19:53:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch14_loss0.6487679243087768.pypots
2024-05-23 19:53:33 [INFO]: Epoch 015 - training loss: 0.8625, validation loss: 0.6469
2024-05-23 19:53:33 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch15_loss0.6469072222709655.pypots
2024-05-23 19:53:36 [INFO]: Epoch 016 - training loss: 0.8547, validation loss: 0.6467
2024-05-23 19:53:36 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch16_loss0.6467228025197983.pypots
2024-05-23 19:53:39 [INFO]: Epoch 017 - training loss: 0.8762, validation loss: 0.6456
2024-05-23 19:53:39 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch17_loss0.6455948799848557.pypots
2024-05-23 19:53:42 [INFO]: Epoch 018 - training loss: 0.8518, validation loss: 0.6467
2024-05-23 19:53:42 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch18_loss0.6467270463705063.pypots
2024-05-23 19:53:45 [INFO]: Epoch 019 - training loss: 0.8626, validation loss: 0.6444
2024-05-23 19:53:45 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch19_loss0.6443576008081436.pypots
2024-05-23 19:53:48 [INFO]: Epoch 020 - training loss: 0.8572, validation loss: 0.6448
2024-05-23 19:53:48 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch20_loss0.6447895675897598.pypots
2024-05-23 19:53:51 [INFO]: Epoch 021 - training loss: 0.8391, validation loss: 0.6452
2024-05-23 19:53:51 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch21_loss0.6451605409383774.pypots
2024-05-23 19:53:55 [INFO]: Epoch 022 - training loss: 0.8567, validation loss: 0.6457
2024-05-23 19:53:55 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch22_loss0.645666292309761.pypots
2024-05-23 19:53:58 [INFO]: Epoch 023 - training loss: 0.8468, validation loss: 0.6445
2024-05-23 19:53:58 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch23_loss0.6444683194160461.pypots
2024-05-23 19:54:01 [INFO]: Epoch 024 - training loss: 0.8290, validation loss: 0.6446
2024-05-23 19:54:01 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch24_loss0.6445744544267654.pypots
2024-05-23 19:54:04 [INFO]: Epoch 025 - training loss: 0.8312, validation loss: 0.6442
2024-05-23 19:54:04 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch25_loss0.6441950559616089.pypots
2024-05-23 19:54:07 [INFO]: Epoch 026 - training loss: 0.8271, validation loss: 0.6435
2024-05-23 19:54:07 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch26_loss0.6434842824935914.pypots
2024-05-23 19:54:10 [INFO]: Epoch 027 - training loss: 0.8253, validation loss: 0.6445
2024-05-23 19:54:10 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch27_loss0.6445117831230164.pypots
2024-05-23 19:54:13 [INFO]: Epoch 028 - training loss: 0.8127, validation loss: 0.6446
2024-05-23 19:54:13 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch28_loss0.6446491956710816.pypots
2024-05-23 19:54:17 [INFO]: Epoch 029 - training loss: 0.8154, validation loss: 0.6462
2024-05-23 19:54:17 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch29_loss0.6462457865476608.pypots
2024-05-23 19:54:20 [INFO]: Epoch 030 - training loss: 0.8241, validation loss: 0.6457
2024-05-23 19:54:20 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch30_loss0.6457255780696869.pypots
2024-05-23 19:54:23 [INFO]: Epoch 031 - training loss: 0.8086, validation loss: 0.6466
2024-05-23 19:54:23 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch31_loss0.6465500503778457.pypots
2024-05-23 19:54:26 [INFO]: Epoch 032 - training loss: 0.8500, validation loss: 0.6466
2024-05-23 19:54:26 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch32_loss0.6466262131929398.pypots
2024-05-23 19:54:29 [INFO]: Epoch 033 - training loss: 0.8141, validation loss: 0.6470
2024-05-23 19:54:29 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch33_loss0.6469952493906022.pypots
2024-05-23 19:54:32 [INFO]: Epoch 034 - training loss: 0.8039, validation loss: 0.6443
2024-05-23 19:54:32 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch34_loss0.6442791730165481.pypots
2024-05-23 19:54:35 [INFO]: Epoch 035 - training loss: 0.7988, validation loss: 0.6481
2024-05-23 19:54:35 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch35_loss0.6481108248233796.pypots
2024-05-23 19:54:38 [INFO]: Epoch 036 - training loss: 0.8010, validation loss: 0.6445
2024-05-23 19:54:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN_epoch36_loss0.6445002555847168.pypots
2024-05-23 19:54:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:54:38 [INFO]: Finished training. The best model is from epoch#26.
2024-05-23 19:54:38 [INFO]: Saved the model to overlay_premask_saved_results/round_2/MRNN_air_quality/20240523_T195245/MRNN.pypots
2024-05-23 19:54:39 [INFO]: MRNN on Air-Quality: MAE=0.5202, MSE=0.6909
2024-05-23 19:54:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-23 19:54:39 [INFO]: Using the given device: cpu
2024-05-23 19:54:39 [INFO]: LOCF on Air-Quality: MAE=0.2090, MSE=0.3758
2024-05-23 19:54:39 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-23 19:54:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-23 19:54:39 [INFO]: Median on Air-Quality: MAE=0.6658, MSE=1.0901
2024-05-23 19:54:39 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-23 19:54:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-23 19:54:39 [INFO]: Mean on Air-Quality: MAE=0.6970, MSE=1.0309
2024-05-23 19:54:39 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-23 19:54:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-23 19:54:39 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-23 19:54:39 [INFO]: Using the given device: cuda:0
2024-05-23 19:54:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240523_T195439
2024-05-23 19:54:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/SAITS_air_quality/20240523_T195439/tensorboard
2024-05-23 19:54:39 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 19:54:40 [INFO]: Epoch 001 - training loss: 1.0447, validation loss: 0.4949
2024-05-23 19:54:40 [INFO]: Epoch 002 - training loss: 0.7561, validation loss: 0.3698
2024-05-23 19:54:41 [INFO]: Epoch 003 - training loss: 0.6471, validation loss: 0.2997
2024-05-23 19:54:42 [INFO]: Epoch 004 - training loss: 0.5711, validation loss: 0.2550
2024-05-23 19:54:42 [INFO]: Epoch 005 - training loss: 0.5163, validation loss: 0.2349
2024-05-23 19:54:43 [INFO]: Epoch 006 - training loss: 0.4790, validation loss: 0.2197
2024-05-23 19:54:43 [INFO]: Epoch 007 - training loss: 0.4508, validation loss: 0.2063
2024-05-23 19:54:44 [INFO]: Epoch 008 - training loss: 0.4328, validation loss: 0.2002
2024-05-23 19:54:44 [INFO]: Epoch 009 - training loss: 0.4196, validation loss: 0.1944
2024-05-23 19:54:45 [INFO]: Epoch 010 - training loss: 0.4052, validation loss: 0.1881
2024-05-23 19:54:46 [INFO]: Epoch 011 - training loss: 0.3948, validation loss: 0.1828
2024-05-23 19:54:46 [INFO]: Epoch 012 - training loss: 0.3861, validation loss: 0.1799
2024-05-23 19:54:47 [INFO]: Epoch 013 - training loss: 0.3787, validation loss: 0.1754
2024-05-23 19:54:47 [INFO]: Epoch 014 - training loss: 0.3699, validation loss: 0.1720
2024-05-23 19:54:48 [INFO]: Epoch 015 - training loss: 0.3647, validation loss: 0.1693
2024-05-23 19:54:49 [INFO]: Epoch 016 - training loss: 0.3581, validation loss: 0.1684
2024-05-23 19:54:49 [INFO]: Epoch 017 - training loss: 0.3524, validation loss: 0.1651
2024-05-23 19:54:50 [INFO]: Epoch 018 - training loss: 0.3466, validation loss: 0.1626
2024-05-23 19:54:50 [INFO]: Epoch 019 - training loss: 0.3425, validation loss: 0.1600
2024-05-23 19:54:51 [INFO]: Epoch 020 - training loss: 0.3394, validation loss: 0.1593
2024-05-23 19:54:52 [INFO]: Epoch 021 - training loss: 0.3354, validation loss: 0.1572
2024-05-23 19:54:52 [INFO]: Epoch 022 - training loss: 0.3303, validation loss: 0.1551
2024-05-23 19:54:53 [INFO]: Epoch 023 - training loss: 0.3285, validation loss: 0.1530
2024-05-23 19:54:53 [INFO]: Epoch 024 - training loss: 0.3267, validation loss: 0.1510
2024-05-23 19:54:54 [INFO]: Epoch 025 - training loss: 0.3221, validation loss: 0.1519
2024-05-23 19:54:54 [INFO]: Epoch 026 - training loss: 0.3178, validation loss: 0.1476
2024-05-23 19:54:55 [INFO]: Epoch 027 - training loss: 0.3148, validation loss: 0.1473
2024-05-23 19:54:56 [INFO]: Epoch 028 - training loss: 0.3126, validation loss: 0.1473
2024-05-23 19:54:56 [INFO]: Epoch 029 - training loss: 0.3091, validation loss: 0.1436
2024-05-23 19:54:57 [INFO]: Epoch 030 - training loss: 0.3075, validation loss: 0.1433
2024-05-23 19:54:57 [INFO]: Epoch 031 - training loss: 0.3053, validation loss: 0.1410
2024-05-23 19:54:58 [INFO]: Epoch 032 - training loss: 0.3032, validation loss: 0.1418
2024-05-23 19:54:59 [INFO]: Epoch 033 - training loss: 0.3011, validation loss: 0.1404
2024-05-23 19:54:59 [INFO]: Epoch 034 - training loss: 0.3003, validation loss: 0.1389
2024-05-23 19:55:00 [INFO]: Epoch 035 - training loss: 0.2977, validation loss: 0.1382
2024-05-23 19:55:00 [INFO]: Epoch 036 - training loss: 0.2941, validation loss: 0.1377
2024-05-23 19:55:01 [INFO]: Epoch 037 - training loss: 0.2921, validation loss: 0.1359
2024-05-23 19:55:01 [INFO]: Epoch 038 - training loss: 0.2905, validation loss: 0.1352
2024-05-23 19:55:02 [INFO]: Epoch 039 - training loss: 0.2890, validation loss: 0.1340
2024-05-23 19:55:03 [INFO]: Epoch 040 - training loss: 0.2874, validation loss: 0.1336
2024-05-23 19:55:03 [INFO]: Epoch 041 - training loss: 0.2851, validation loss: 0.1327
2024-05-23 19:55:04 [INFO]: Epoch 042 - training loss: 0.2842, validation loss: 0.1312
2024-05-23 19:55:04 [INFO]: Epoch 043 - training loss: 0.2825, validation loss: 0.1313
2024-05-23 19:55:05 [INFO]: Epoch 044 - training loss: 0.2833, validation loss: 0.1309
2024-05-23 19:55:06 [INFO]: Epoch 045 - training loss: 0.2809, validation loss: 0.1301
2024-05-23 19:55:06 [INFO]: Epoch 046 - training loss: 0.2775, validation loss: 0.1291
2024-05-23 19:55:07 [INFO]: Epoch 047 - training loss: 0.2761, validation loss: 0.1280
2024-05-23 19:55:07 [INFO]: Epoch 048 - training loss: 0.2758, validation loss: 0.1279
2024-05-23 19:55:08 [INFO]: Epoch 049 - training loss: 0.2744, validation loss: 0.1268
2024-05-23 19:55:09 [INFO]: Epoch 050 - training loss: 0.2706, validation loss: 0.1252
2024-05-23 19:55:09 [INFO]: Epoch 051 - training loss: 0.2692, validation loss: 0.1254
2024-05-23 19:55:10 [INFO]: Epoch 052 - training loss: 0.2676, validation loss: 0.1239
2024-05-23 19:55:10 [INFO]: Epoch 053 - training loss: 0.2664, validation loss: 0.1242
2024-05-23 19:55:11 [INFO]: Epoch 054 - training loss: 0.2660, validation loss: 0.1233
2024-05-23 19:55:11 [INFO]: Epoch 055 - training loss: 0.2641, validation loss: 0.1235
2024-05-23 19:55:12 [INFO]: Epoch 056 - training loss: 0.2632, validation loss: 0.1228
2024-05-23 19:55:13 [INFO]: Epoch 057 - training loss: 0.2616, validation loss: 0.1219
2024-05-23 19:55:13 [INFO]: Epoch 058 - training loss: 0.2596, validation loss: 0.1223
2024-05-23 19:55:14 [INFO]: Epoch 059 - training loss: 0.2581, validation loss: 0.1214
2024-05-23 19:55:14 [INFO]: Epoch 060 - training loss: 0.2565, validation loss: 0.1219
2024-05-23 19:55:15 [INFO]: Epoch 061 - training loss: 0.2555, validation loss: 0.1201
2024-05-23 19:55:16 [INFO]: Epoch 062 - training loss: 0.2538, validation loss: 0.1204
2024-05-23 19:55:16 [INFO]: Epoch 063 - training loss: 0.2533, validation loss: 0.1201
2024-05-23 19:55:17 [INFO]: Epoch 064 - training loss: 0.2527, validation loss: 0.1185
2024-05-23 19:55:17 [INFO]: Epoch 065 - training loss: 0.2505, validation loss: 0.1184
2024-05-23 19:55:18 [INFO]: Epoch 066 - training loss: 0.2496, validation loss: 0.1184
2024-05-23 19:55:19 [INFO]: Epoch 067 - training loss: 0.2494, validation loss: 0.1176
2024-05-23 19:55:19 [INFO]: Epoch 068 - training loss: 0.2487, validation loss: 0.1165
2024-05-23 19:55:20 [INFO]: Epoch 069 - training loss: 0.2462, validation loss: 0.1170
2024-05-23 19:55:20 [INFO]: Epoch 070 - training loss: 0.2461, validation loss: 0.1175
2024-05-23 19:55:21 [INFO]: Epoch 071 - training loss: 0.2456, validation loss: 0.1170
2024-05-23 19:55:21 [INFO]: Epoch 072 - training loss: 0.2423, validation loss: 0.1159
2024-05-23 19:55:22 [INFO]: Epoch 073 - training loss: 0.2421, validation loss: 0.1173
2024-05-23 19:55:23 [INFO]: Epoch 074 - training loss: 0.2417, validation loss: 0.1169
2024-05-23 19:55:23 [INFO]: Epoch 075 - training loss: 0.2390, validation loss: 0.1142
2024-05-23 19:55:24 [INFO]: Epoch 076 - training loss: 0.2382, validation loss: 0.1151
2024-05-23 19:55:24 [INFO]: Epoch 077 - training loss: 0.2373, validation loss: 0.1152
2024-05-23 19:55:25 [INFO]: Epoch 078 - training loss: 0.2366, validation loss: 0.1142
2024-05-23 19:55:26 [INFO]: Epoch 079 - training loss: 0.2358, validation loss: 0.1143
2024-05-23 19:55:26 [INFO]: Epoch 080 - training loss: 0.2353, validation loss: 0.1141
2024-05-23 19:55:27 [INFO]: Epoch 081 - training loss: 0.2342, validation loss: 0.1144
2024-05-23 19:55:27 [INFO]: Epoch 082 - training loss: 0.2328, validation loss: 0.1134
2024-05-23 19:55:28 [INFO]: Epoch 083 - training loss: 0.2318, validation loss: 0.1137
2024-05-23 19:55:28 [INFO]: Epoch 084 - training loss: 0.2319, validation loss: 0.1132
2024-05-23 19:55:29 [INFO]: Epoch 085 - training loss: 0.2302, validation loss: 0.1133
2024-05-23 19:55:30 [INFO]: Epoch 086 - training loss: 0.2290, validation loss: 0.1117
2024-05-23 19:55:30 [INFO]: Epoch 087 - training loss: 0.2287, validation loss: 0.1118
2024-05-23 19:55:31 [INFO]: Epoch 088 - training loss: 0.2276, validation loss: 0.1115
2024-05-23 19:55:31 [INFO]: Epoch 089 - training loss: 0.2271, validation loss: 0.1112
2024-05-23 19:55:32 [INFO]: Epoch 090 - training loss: 0.2266, validation loss: 0.1118
2024-05-23 19:55:33 [INFO]: Epoch 091 - training loss: 0.2275, validation loss: 0.1114
2024-05-23 19:55:33 [INFO]: Epoch 092 - training loss: 0.2250, validation loss: 0.1113
2024-05-23 19:55:34 [INFO]: Epoch 093 - training loss: 0.2245, validation loss: 0.1101
2024-05-23 19:55:34 [INFO]: Epoch 094 - training loss: 0.2236, validation loss: 0.1104
2024-05-23 19:55:35 [INFO]: Epoch 095 - training loss: 0.2227, validation loss: 0.1110
2024-05-23 19:55:35 [INFO]: Epoch 096 - training loss: 0.2219, validation loss: 0.1102
2024-05-23 19:55:36 [INFO]: Epoch 097 - training loss: 0.2215, validation loss: 0.1093
2024-05-23 19:55:37 [INFO]: Epoch 098 - training loss: 0.2201, validation loss: 0.1102
2024-05-23 19:55:37 [INFO]: Epoch 099 - training loss: 0.2198, validation loss: 0.1088
2024-05-23 19:55:38 [INFO]: Epoch 100 - training loss: 0.2196, validation loss: 0.1083
2024-05-23 19:55:38 [INFO]: Epoch 101 - training loss: 0.2198, validation loss: 0.1089
2024-05-23 19:55:39 [INFO]: Epoch 102 - training loss: 0.2192, validation loss: 0.1085
2024-05-23 19:55:40 [INFO]: Epoch 103 - training loss: 0.2169, validation loss: 0.1085
2024-05-23 19:55:40 [INFO]: Epoch 104 - training loss: 0.2167, validation loss: 0.1079
2024-05-23 19:55:41 [INFO]: Epoch 105 - training loss: 0.2171, validation loss: 0.1072
2024-05-23 19:55:41 [INFO]: Epoch 106 - training loss: 0.2162, validation loss: 0.1081
2024-05-23 19:55:42 [INFO]: Epoch 107 - training loss: 0.2151, validation loss: 0.1082
2024-05-23 19:55:43 [INFO]: Epoch 108 - training loss: 0.2145, validation loss: 0.1072
2024-05-23 19:55:43 [INFO]: Epoch 109 - training loss: 0.2136, validation loss: 0.1076
2024-05-23 19:55:44 [INFO]: Epoch 110 - training loss: 0.2135, validation loss: 0.1063
2024-05-23 19:55:44 [INFO]: Epoch 111 - training loss: 0.2125, validation loss: 0.1066
2024-05-23 19:55:45 [INFO]: Epoch 112 - training loss: 0.2114, validation loss: 0.1061
2024-05-23 19:55:45 [INFO]: Epoch 113 - training loss: 0.2107, validation loss: 0.1055
2024-05-23 19:55:46 [INFO]: Epoch 114 - training loss: 0.2113, validation loss: 0.1064
2024-05-23 19:55:47 [INFO]: Epoch 115 - training loss: 0.2095, validation loss: 0.1071
2024-05-23 19:55:47 [INFO]: Epoch 116 - training loss: 0.2096, validation loss: 0.1059
2024-05-23 19:55:48 [INFO]: Epoch 117 - training loss: 0.2092, validation loss: 0.1068
2024-05-23 19:55:48 [INFO]: Epoch 118 - training loss: 0.2107, validation loss: 0.1065
2024-05-23 19:55:49 [INFO]: Epoch 119 - training loss: 0.2089, validation loss: 0.1043
2024-05-23 19:55:50 [INFO]: Epoch 120 - training loss: 0.2093, validation loss: 0.1067
2024-05-23 19:55:50 [INFO]: Epoch 121 - training loss: 0.2085, validation loss: 0.1039
2024-05-23 19:55:51 [INFO]: Epoch 122 - training loss: 0.2065, validation loss: 0.1045
2024-05-23 19:55:51 [INFO]: Epoch 123 - training loss: 0.2072, validation loss: 0.1055
2024-05-23 19:55:52 [INFO]: Epoch 124 - training loss: 0.2070, validation loss: 0.1044
2024-05-23 19:55:52 [INFO]: Epoch 125 - training loss: 0.2064, validation loss: 0.1037
2024-05-23 19:55:53 [INFO]: Epoch 126 - training loss: 0.2044, validation loss: 0.1051
2024-05-23 19:55:54 [INFO]: Epoch 127 - training loss: 0.2039, validation loss: 0.1039
2024-05-23 19:55:54 [INFO]: Epoch 128 - training loss: 0.2034, validation loss: 0.1046
2024-05-23 19:55:55 [INFO]: Epoch 129 - training loss: 0.2029, validation loss: 0.1035
2024-05-23 19:55:55 [INFO]: Epoch 130 - training loss: 0.2025, validation loss: 0.1026
2024-05-23 19:55:56 [INFO]: Epoch 131 - training loss: 0.2019, validation loss: 0.1034
2024-05-23 19:55:57 [INFO]: Epoch 132 - training loss: 0.2014, validation loss: 0.1029
2024-05-23 19:55:57 [INFO]: Epoch 133 - training loss: 0.2013, validation loss: 0.1016
2024-05-23 19:55:58 [INFO]: Epoch 134 - training loss: 0.1998, validation loss: 0.1028
2024-05-23 19:55:58 [INFO]: Epoch 135 - training loss: 0.1993, validation loss: 0.1032
2024-05-23 19:55:59 [INFO]: Epoch 136 - training loss: 0.1989, validation loss: 0.1017
2024-05-23 19:56:00 [INFO]: Epoch 137 - training loss: 0.1989, validation loss: 0.1017
2024-05-23 19:56:00 [INFO]: Epoch 138 - training loss: 0.1985, validation loss: 0.1022
2024-05-23 19:56:01 [INFO]: Epoch 139 - training loss: 0.1977, validation loss: 0.1022
2024-05-23 19:56:01 [INFO]: Epoch 140 - training loss: 0.1983, validation loss: 0.1031
2024-05-23 19:56:02 [INFO]: Epoch 141 - training loss: 0.1978, validation loss: 0.1020
2024-05-23 19:56:02 [INFO]: Epoch 142 - training loss: 0.1964, validation loss: 0.1023
2024-05-23 19:56:03 [INFO]: Epoch 143 - training loss: 0.1955, validation loss: 0.1027
2024-05-23 19:56:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:56:03 [INFO]: Finished training. The best model is from epoch#133.
2024-05-23 19:56:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/SAITS_air_quality/20240523_T195439/SAITS.pypots
2024-05-23 19:56:03 [INFO]: SAITS on Air-Quality: MAE=0.1555, MSE=0.1799
2024-05-23 19:56:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-23 19:56:03 [INFO]: Using the given device: cuda:0
2024-05-23 19:56:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240523_T195603
2024-05-23 19:56:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/Transformer_air_quality/20240523_T195603/tensorboard
2024-05-23 19:56:03 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 19:56:04 [INFO]: Epoch 001 - training loss: 0.8925, validation loss: 0.4248
2024-05-23 19:56:04 [INFO]: Epoch 002 - training loss: 0.5563, validation loss: 0.3096
2024-05-23 19:56:04 [INFO]: Epoch 003 - training loss: 0.4659, validation loss: 0.2559
2024-05-23 19:56:04 [INFO]: Epoch 004 - training loss: 0.4192, validation loss: 0.2350
2024-05-23 19:56:05 [INFO]: Epoch 005 - training loss: 0.3903, validation loss: 0.2209
2024-05-23 19:56:05 [INFO]: Epoch 006 - training loss: 0.3712, validation loss: 0.2118
2024-05-23 19:56:05 [INFO]: Epoch 007 - training loss: 0.3569, validation loss: 0.2036
2024-05-23 19:56:05 [INFO]: Epoch 008 - training loss: 0.3445, validation loss: 0.1971
2024-05-23 19:56:05 [INFO]: Epoch 009 - training loss: 0.3321, validation loss: 0.1898
2024-05-23 19:56:06 [INFO]: Epoch 010 - training loss: 0.3257, validation loss: 0.1866
2024-05-23 19:56:06 [INFO]: Epoch 011 - training loss: 0.3207, validation loss: 0.1820
2024-05-23 19:56:06 [INFO]: Epoch 012 - training loss: 0.3142, validation loss: 0.1779
2024-05-23 19:56:06 [INFO]: Epoch 013 - training loss: 0.3090, validation loss: 0.1754
2024-05-23 19:56:07 [INFO]: Epoch 014 - training loss: 0.3030, validation loss: 0.1729
2024-05-23 19:56:07 [INFO]: Epoch 015 - training loss: 0.2965, validation loss: 0.1687
2024-05-23 19:56:07 [INFO]: Epoch 016 - training loss: 0.2932, validation loss: 0.1673
2024-05-23 19:56:07 [INFO]: Epoch 017 - training loss: 0.2907, validation loss: 0.1644
2024-05-23 19:56:08 [INFO]: Epoch 018 - training loss: 0.2871, validation loss: 0.1631
2024-05-23 19:56:08 [INFO]: Epoch 019 - training loss: 0.2829, validation loss: 0.1608
2024-05-23 19:56:08 [INFO]: Epoch 020 - training loss: 0.2814, validation loss: 0.1593
2024-05-23 19:56:08 [INFO]: Epoch 021 - training loss: 0.2788, validation loss: 0.1587
2024-05-23 19:56:09 [INFO]: Epoch 022 - training loss: 0.2747, validation loss: 0.1578
2024-05-23 19:56:09 [INFO]: Epoch 023 - training loss: 0.2728, validation loss: 0.1566
2024-05-23 19:56:09 [INFO]: Epoch 024 - training loss: 0.2705, validation loss: 0.1572
2024-05-23 19:56:09 [INFO]: Epoch 025 - training loss: 0.2688, validation loss: 0.1552
2024-05-23 19:56:10 [INFO]: Epoch 026 - training loss: 0.2647, validation loss: 0.1525
2024-05-23 19:56:10 [INFO]: Epoch 027 - training loss: 0.2607, validation loss: 0.1531
2024-05-23 19:56:10 [INFO]: Epoch 028 - training loss: 0.2588, validation loss: 0.1503
2024-05-23 19:56:10 [INFO]: Epoch 029 - training loss: 0.2587, validation loss: 0.1499
2024-05-23 19:56:10 [INFO]: Epoch 030 - training loss: 0.2548, validation loss: 0.1503
2024-05-23 19:56:11 [INFO]: Epoch 031 - training loss: 0.2533, validation loss: 0.1492
2024-05-23 19:56:11 [INFO]: Epoch 032 - training loss: 0.2514, validation loss: 0.1470
2024-05-23 19:56:11 [INFO]: Epoch 033 - training loss: 0.2526, validation loss: 0.1480
2024-05-23 19:56:11 [INFO]: Epoch 034 - training loss: 0.2485, validation loss: 0.1476
2024-05-23 19:56:12 [INFO]: Epoch 035 - training loss: 0.2460, validation loss: 0.1473
2024-05-23 19:56:12 [INFO]: Epoch 036 - training loss: 0.2437, validation loss: 0.1465
2024-05-23 19:56:12 [INFO]: Epoch 037 - training loss: 0.2425, validation loss: 0.1452
2024-05-23 19:56:12 [INFO]: Epoch 038 - training loss: 0.2435, validation loss: 0.1462
2024-05-23 19:56:13 [INFO]: Epoch 039 - training loss: 0.2411, validation loss: 0.1445
2024-05-23 19:56:13 [INFO]: Epoch 040 - training loss: 0.2381, validation loss: 0.1426
2024-05-23 19:56:13 [INFO]: Epoch 041 - training loss: 0.2388, validation loss: 0.1414
2024-05-23 19:56:13 [INFO]: Epoch 042 - training loss: 0.2354, validation loss: 0.1403
2024-05-23 19:56:13 [INFO]: Epoch 043 - training loss: 0.2327, validation loss: 0.1430
2024-05-23 19:56:14 [INFO]: Epoch 044 - training loss: 0.2324, validation loss: 0.1412
2024-05-23 19:56:14 [INFO]: Epoch 045 - training loss: 0.2313, validation loss: 0.1395
2024-05-23 19:56:14 [INFO]: Epoch 046 - training loss: 0.2333, validation loss: 0.1410
2024-05-23 19:56:14 [INFO]: Epoch 047 - training loss: 0.2313, validation loss: 0.1429
2024-05-23 19:56:15 [INFO]: Epoch 048 - training loss: 0.2305, validation loss: 0.1382
2024-05-23 19:56:15 [INFO]: Epoch 049 - training loss: 0.2309, validation loss: 0.1397
2024-05-23 19:56:15 [INFO]: Epoch 050 - training loss: 0.2283, validation loss: 0.1378
2024-05-23 19:56:15 [INFO]: Epoch 051 - training loss: 0.2240, validation loss: 0.1382
2024-05-23 19:56:16 [INFO]: Epoch 052 - training loss: 0.2217, validation loss: 0.1387
2024-05-23 19:56:16 [INFO]: Epoch 053 - training loss: 0.2206, validation loss: 0.1374
2024-05-23 19:56:16 [INFO]: Epoch 054 - training loss: 0.2182, validation loss: 0.1367
2024-05-23 19:56:16 [INFO]: Epoch 055 - training loss: 0.2184, validation loss: 0.1372
2024-05-23 19:56:17 [INFO]: Epoch 056 - training loss: 0.2167, validation loss: 0.1368
2024-05-23 19:56:17 [INFO]: Epoch 057 - training loss: 0.2169, validation loss: 0.1375
2024-05-23 19:56:17 [INFO]: Epoch 058 - training loss: 0.2154, validation loss: 0.1350
2024-05-23 19:56:17 [INFO]: Epoch 059 - training loss: 0.2128, validation loss: 0.1352
2024-05-23 19:56:17 [INFO]: Epoch 060 - training loss: 0.2147, validation loss: 0.1353
2024-05-23 19:56:18 [INFO]: Epoch 061 - training loss: 0.2133, validation loss: 0.1375
2024-05-23 19:56:18 [INFO]: Epoch 062 - training loss: 0.2121, validation loss: 0.1344
2024-05-23 19:56:18 [INFO]: Epoch 063 - training loss: 0.2115, validation loss: 0.1328
2024-05-23 19:56:18 [INFO]: Epoch 064 - training loss: 0.2111, validation loss: 0.1338
2024-05-23 19:56:19 [INFO]: Epoch 065 - training loss: 0.2103, validation loss: 0.1327
2024-05-23 19:56:19 [INFO]: Epoch 066 - training loss: 0.2084, validation loss: 0.1348
2024-05-23 19:56:19 [INFO]: Epoch 067 - training loss: 0.2063, validation loss: 0.1335
2024-05-23 19:56:19 [INFO]: Epoch 068 - training loss: 0.2053, validation loss: 0.1326
2024-05-23 19:56:20 [INFO]: Epoch 069 - training loss: 0.2052, validation loss: 0.1340
2024-05-23 19:56:20 [INFO]: Epoch 070 - training loss: 0.2062, validation loss: 0.1315
2024-05-23 19:56:20 [INFO]: Epoch 071 - training loss: 0.2033, validation loss: 0.1320
2024-05-23 19:56:20 [INFO]: Epoch 072 - training loss: 0.2116, validation loss: 0.1318
2024-05-23 19:56:21 [INFO]: Epoch 073 - training loss: 0.2118, validation loss: 0.1310
2024-05-23 19:56:21 [INFO]: Epoch 074 - training loss: 0.2017, validation loss: 0.1297
2024-05-23 19:56:21 [INFO]: Epoch 075 - training loss: 0.2012, validation loss: 0.1308
2024-05-23 19:56:21 [INFO]: Epoch 076 - training loss: 0.1996, validation loss: 0.1295
2024-05-23 19:56:21 [INFO]: Epoch 077 - training loss: 0.1982, validation loss: 0.1292
2024-05-23 19:56:22 [INFO]: Epoch 078 - training loss: 0.1982, validation loss: 0.1287
2024-05-23 19:56:22 [INFO]: Epoch 079 - training loss: 0.1980, validation loss: 0.1317
2024-05-23 19:56:22 [INFO]: Epoch 080 - training loss: 0.1973, validation loss: 0.1293
2024-05-23 19:56:22 [INFO]: Epoch 081 - training loss: 0.1939, validation loss: 0.1284
2024-05-23 19:56:23 [INFO]: Epoch 082 - training loss: 0.1918, validation loss: 0.1287
2024-05-23 19:56:23 [INFO]: Epoch 083 - training loss: 0.1917, validation loss: 0.1279
2024-05-23 19:56:23 [INFO]: Epoch 084 - training loss: 0.1905, validation loss: 0.1284
2024-05-23 19:56:23 [INFO]: Epoch 085 - training loss: 0.1908, validation loss: 0.1293
2024-05-23 19:56:24 [INFO]: Epoch 086 - training loss: 0.1934, validation loss: 0.1270
2024-05-23 19:56:24 [INFO]: Epoch 087 - training loss: 0.1901, validation loss: 0.1275
2024-05-23 19:56:24 [INFO]: Epoch 088 - training loss: 0.1907, validation loss: 0.1266
2024-05-23 19:56:24 [INFO]: Epoch 089 - training loss: 0.1901, validation loss: 0.1273
2024-05-23 19:56:25 [INFO]: Epoch 090 - training loss: 0.1880, validation loss: 0.1256
2024-05-23 19:56:25 [INFO]: Epoch 091 - training loss: 0.1865, validation loss: 0.1279
2024-05-23 19:56:25 [INFO]: Epoch 092 - training loss: 0.1859, validation loss: 0.1273
2024-05-23 19:56:25 [INFO]: Epoch 093 - training loss: 0.1843, validation loss: 0.1256
2024-05-23 19:56:25 [INFO]: Epoch 094 - training loss: 0.1835, validation loss: 0.1267
2024-05-23 19:56:26 [INFO]: Epoch 095 - training loss: 0.1854, validation loss: 0.1268
2024-05-23 19:56:26 [INFO]: Epoch 096 - training loss: 0.1833, validation loss: 0.1271
2024-05-23 19:56:26 [INFO]: Epoch 097 - training loss: 0.1826, validation loss: 0.1267
2024-05-23 19:56:26 [INFO]: Epoch 098 - training loss: 0.1814, validation loss: 0.1240
2024-05-23 19:56:27 [INFO]: Epoch 099 - training loss: 0.1803, validation loss: 0.1250
2024-05-23 19:56:27 [INFO]: Epoch 100 - training loss: 0.1794, validation loss: 0.1263
2024-05-23 19:56:27 [INFO]: Epoch 101 - training loss: 0.1810, validation loss: 0.1277
2024-05-23 19:56:27 [INFO]: Epoch 102 - training loss: 0.1804, validation loss: 0.1246
2024-05-23 19:56:28 [INFO]: Epoch 103 - training loss: 0.1801, validation loss: 0.1239
2024-05-23 19:56:28 [INFO]: Epoch 104 - training loss: 0.1791, validation loss: 0.1243
2024-05-23 19:56:28 [INFO]: Epoch 105 - training loss: 0.1786, validation loss: 0.1240
2024-05-23 19:56:28 [INFO]: Epoch 106 - training loss: 0.1763, validation loss: 0.1245
2024-05-23 19:56:29 [INFO]: Epoch 107 - training loss: 0.1855, validation loss: 0.1326
2024-05-23 19:56:29 [INFO]: Epoch 108 - training loss: 0.1827, validation loss: 0.1221
2024-05-23 19:56:29 [INFO]: Epoch 109 - training loss: 0.1770, validation loss: 0.1232
2024-05-23 19:56:29 [INFO]: Epoch 110 - training loss: 0.1733, validation loss: 0.1226
2024-05-23 19:56:29 [INFO]: Epoch 111 - training loss: 0.1724, validation loss: 0.1249
2024-05-23 19:56:30 [INFO]: Epoch 112 - training loss: 0.1714, validation loss: 0.1223
2024-05-23 19:56:30 [INFO]: Epoch 113 - training loss: 0.1701, validation loss: 0.1223
2024-05-23 19:56:30 [INFO]: Epoch 114 - training loss: 0.1699, validation loss: 0.1229
2024-05-23 19:56:30 [INFO]: Epoch 115 - training loss: 0.1716, validation loss: 0.1245
2024-05-23 19:56:31 [INFO]: Epoch 116 - training loss: 0.1733, validation loss: 0.1215
2024-05-23 19:56:31 [INFO]: Epoch 117 - training loss: 0.1749, validation loss: 0.1247
2024-05-23 19:56:31 [INFO]: Epoch 118 - training loss: 0.1695, validation loss: 0.1223
2024-05-23 19:56:31 [INFO]: Epoch 119 - training loss: 0.1672, validation loss: 0.1234
2024-05-23 19:56:32 [INFO]: Epoch 120 - training loss: 0.1671, validation loss: 0.1223
2024-05-23 19:56:32 [INFO]: Epoch 121 - training loss: 0.1682, validation loss: 0.1204
2024-05-23 19:56:32 [INFO]: Epoch 122 - training loss: 0.1657, validation loss: 0.1214
2024-05-23 19:56:32 [INFO]: Epoch 123 - training loss: 0.1661, validation loss: 0.1203
2024-05-23 19:56:33 [INFO]: Epoch 124 - training loss: 0.1676, validation loss: 0.1228
2024-05-23 19:56:33 [INFO]: Epoch 125 - training loss: 0.1671, validation loss: 0.1215
2024-05-23 19:56:33 [INFO]: Epoch 126 - training loss: 0.1680, validation loss: 0.1211
2024-05-23 19:56:33 [INFO]: Epoch 127 - training loss: 0.1640, validation loss: 0.1210
2024-05-23 19:56:33 [INFO]: Epoch 128 - training loss: 0.1632, validation loss: 0.1234
2024-05-23 19:56:34 [INFO]: Epoch 129 - training loss: 0.1626, validation loss: 0.1212
2024-05-23 19:56:34 [INFO]: Epoch 130 - training loss: 0.1610, validation loss: 0.1195
2024-05-23 19:56:34 [INFO]: Epoch 131 - training loss: 0.1602, validation loss: 0.1207
2024-05-23 19:56:34 [INFO]: Epoch 132 - training loss: 0.1594, validation loss: 0.1191
2024-05-23 19:56:35 [INFO]: Epoch 133 - training loss: 0.1607, validation loss: 0.1209
2024-05-23 19:56:35 [INFO]: Epoch 134 - training loss: 0.1596, validation loss: 0.1216
2024-05-23 19:56:35 [INFO]: Epoch 135 - training loss: 0.1619, validation loss: 0.1184
2024-05-23 19:56:35 [INFO]: Epoch 136 - training loss: 0.1592, validation loss: 0.1210
2024-05-23 19:56:36 [INFO]: Epoch 137 - training loss: 0.1579, validation loss: 0.1195
2024-05-23 19:56:36 [INFO]: Epoch 138 - training loss: 0.1581, validation loss: 0.1196
2024-05-23 19:56:36 [INFO]: Epoch 139 - training loss: 0.1574, validation loss: 0.1192
2024-05-23 19:56:36 [INFO]: Epoch 140 - training loss: 0.1571, validation loss: 0.1221
2024-05-23 19:56:36 [INFO]: Epoch 141 - training loss: 0.1566, validation loss: 0.1184
2024-05-23 19:56:37 [INFO]: Epoch 142 - training loss: 0.1576, validation loss: 0.1203
2024-05-23 19:56:37 [INFO]: Epoch 143 - training loss: 0.1567, validation loss: 0.1186
2024-05-23 19:56:37 [INFO]: Epoch 144 - training loss: 0.1569, validation loss: 0.1177
2024-05-23 19:56:37 [INFO]: Epoch 145 - training loss: 0.1573, validation loss: 0.1196
2024-05-23 19:56:38 [INFO]: Epoch 146 - training loss: 0.1552, validation loss: 0.1208
2024-05-23 19:56:38 [INFO]: Epoch 147 - training loss: 0.1545, validation loss: 0.1194
2024-05-23 19:56:38 [INFO]: Epoch 148 - training loss: 0.1531, validation loss: 0.1178
2024-05-23 19:56:38 [INFO]: Epoch 149 - training loss: 0.1522, validation loss: 0.1189
2024-05-23 19:56:39 [INFO]: Epoch 150 - training loss: 0.1508, validation loss: 0.1191
2024-05-23 19:56:39 [INFO]: Epoch 151 - training loss: 0.1503, validation loss: 0.1195
2024-05-23 19:56:39 [INFO]: Epoch 152 - training loss: 0.1528, validation loss: 0.1192
2024-05-23 19:56:39 [INFO]: Epoch 153 - training loss: 0.1534, validation loss: 0.1177
2024-05-23 19:56:40 [INFO]: Epoch 154 - training loss: 0.1510, validation loss: 0.1177
2024-05-23 19:56:40 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:56:40 [INFO]: Finished training. The best model is from epoch#144.
2024-05-23 19:56:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/Transformer_air_quality/20240523_T195603/Transformer.pypots
2024-05-23 19:56:40 [INFO]: Transformer on Air-Quality: MAE=0.1719, MSE=0.2014
2024-05-23 19:56:40 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-23 19:56:40 [INFO]: Using the given device: cuda:0
2024-05-23 19:56:40 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240523_T195640
2024-05-23 19:56:40 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240523_T195640/tensorboard
2024-05-23 19:56:40 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 19:56:40 [INFO]: Epoch 001 - training loss: 0.2644, validation loss: 0.2333
2024-05-23 19:56:41 [INFO]: Epoch 002 - training loss: 0.2130, validation loss: 0.2113
2024-05-23 19:56:41 [INFO]: Epoch 003 - training loss: 0.1813, validation loss: 0.1908
2024-05-23 19:56:42 [INFO]: Epoch 004 - training loss: 0.1564, validation loss: 0.1809
2024-05-23 19:56:42 [INFO]: Epoch 005 - training loss: 0.1403, validation loss: 0.1709
2024-05-23 19:56:43 [INFO]: Epoch 006 - training loss: 0.1361, validation loss: 0.1648
2024-05-23 19:56:43 [INFO]: Epoch 007 - training loss: 0.1400, validation loss: 0.1603
2024-05-23 19:56:43 [INFO]: Epoch 008 - training loss: 0.1199, validation loss: 0.1582
2024-05-23 19:56:44 [INFO]: Epoch 009 - training loss: 0.1210, validation loss: 0.1598
2024-05-23 19:56:44 [INFO]: Epoch 010 - training loss: 0.1117, validation loss: 0.1570
2024-05-23 19:56:45 [INFO]: Epoch 011 - training loss: 0.1067, validation loss: 0.1542
2024-05-23 19:56:45 [INFO]: Epoch 012 - training loss: 0.1055, validation loss: 0.1491
2024-05-23 19:56:46 [INFO]: Epoch 013 - training loss: 0.1037, validation loss: 0.1485
2024-05-23 19:56:46 [INFO]: Epoch 014 - training loss: 0.1016, validation loss: 0.1451
2024-05-23 19:56:47 [INFO]: Epoch 015 - training loss: 0.0985, validation loss: 0.1472
2024-05-23 19:56:47 [INFO]: Epoch 016 - training loss: 0.0915, validation loss: 0.1431
2024-05-23 19:56:47 [INFO]: Epoch 017 - training loss: 0.0862, validation loss: 0.1437
2024-05-23 19:56:48 [INFO]: Epoch 018 - training loss: 0.0835, validation loss: 0.1456
2024-05-23 19:56:48 [INFO]: Epoch 019 - training loss: 0.0821, validation loss: 0.1447
2024-05-23 19:56:49 [INFO]: Epoch 020 - training loss: 0.0879, validation loss: 0.1447
2024-05-23 19:56:49 [INFO]: Epoch 021 - training loss: 0.0871, validation loss: 0.1432
2024-05-23 19:56:50 [INFO]: Epoch 022 - training loss: 0.0802, validation loss: 0.1407
2024-05-23 19:56:50 [INFO]: Epoch 023 - training loss: 0.0820, validation loss: 0.1556
2024-05-23 19:56:50 [INFO]: Epoch 024 - training loss: 0.0823, validation loss: 0.1418
2024-05-23 19:56:51 [INFO]: Epoch 025 - training loss: 0.0775, validation loss: 0.1412
2024-05-23 19:56:51 [INFO]: Epoch 026 - training loss: 0.0786, validation loss: 0.1385
2024-05-23 19:56:52 [INFO]: Epoch 027 - training loss: 0.0784, validation loss: 0.1413
2024-05-23 19:56:52 [INFO]: Epoch 028 - training loss: 0.0728, validation loss: 0.1422
2024-05-23 19:56:53 [INFO]: Epoch 029 - training loss: 0.0712, validation loss: 0.1375
2024-05-23 19:56:53 [INFO]: Epoch 030 - training loss: 0.0694, validation loss: 0.1372
2024-05-23 19:56:53 [INFO]: Epoch 031 - training loss: 0.0651, validation loss: 0.1372
2024-05-23 19:56:54 [INFO]: Epoch 032 - training loss: 0.0685, validation loss: 0.1390
2024-05-23 19:56:54 [INFO]: Epoch 033 - training loss: 0.0708, validation loss: 0.1400
2024-05-23 19:56:55 [INFO]: Epoch 034 - training loss: 0.0734, validation loss: 0.1353
2024-05-23 19:56:55 [INFO]: Epoch 035 - training loss: 0.0717, validation loss: 0.1347
2024-05-23 19:56:56 [INFO]: Epoch 036 - training loss: 0.0675, validation loss: 0.1371
2024-05-23 19:56:56 [INFO]: Epoch 037 - training loss: 0.0635, validation loss: 0.1359
2024-05-23 19:56:57 [INFO]: Epoch 038 - training loss: 0.0632, validation loss: 0.1431
2024-05-23 19:56:57 [INFO]: Epoch 039 - training loss: 0.0695, validation loss: 0.1435
2024-05-23 19:56:57 [INFO]: Epoch 040 - training loss: 0.0616, validation loss: 0.1390
2024-05-23 19:56:58 [INFO]: Epoch 041 - training loss: 0.0696, validation loss: 0.1361
2024-05-23 19:56:58 [INFO]: Epoch 042 - training loss: 0.0567, validation loss: 0.1363
2024-05-23 19:56:59 [INFO]: Epoch 043 - training loss: 0.0558, validation loss: 0.1348
2024-05-23 19:56:59 [INFO]: Epoch 044 - training loss: 0.0570, validation loss: 0.1378
2024-05-23 19:57:00 [INFO]: Epoch 045 - training loss: 0.0586, validation loss: 0.1406
2024-05-23 19:57:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 19:57:00 [INFO]: Finished training. The best model is from epoch#35.
2024-05-23 19:57:00 [INFO]: Saved the model to overlay_premask_saved_results/round_3/TimesNet_air_quality/20240523_T195640/TimesNet.pypots
2024-05-23 19:57:00 [INFO]: TimesNet on Air-Quality: MAE=0.1697, MSE=0.2470
2024-05-23 19:57:00 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-23 19:57:00 [INFO]: Using the given device: cuda:0
2024-05-23 19:57:00 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700
2024-05-23 19:57:00 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/tensorboard
2024-05-23 19:57:00 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 19:57:16 [INFO]: Epoch 001 - training loss: 0.5185, validation loss: 0.3491
2024-05-23 19:57:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch1_loss0.34909125566482546.pypots
2024-05-23 19:57:33 [INFO]: Epoch 002 - training loss: 0.3078, validation loss: 0.2834
2024-05-23 19:57:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch2_loss0.28339086174964906.pypots
2024-05-23 19:57:49 [INFO]: Epoch 003 - training loss: 0.2636, validation loss: 0.2609
2024-05-23 19:57:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch3_loss0.26088550090789797.pypots
2024-05-23 19:58:06 [INFO]: Epoch 004 - training loss: 0.2568, validation loss: 0.2418
2024-05-23 19:58:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch4_loss0.24184477031230928.pypots
2024-05-23 19:58:22 [INFO]: Epoch 005 - training loss: 0.2316, validation loss: 0.2354
2024-05-23 19:58:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch5_loss0.23538953214883804.pypots
2024-05-23 19:58:38 [INFO]: Epoch 006 - training loss: 0.2281, validation loss: 0.2121
2024-05-23 19:58:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch6_loss0.21211028844118118.pypots
2024-05-23 19:58:55 [INFO]: Epoch 007 - training loss: 0.2037, validation loss: 0.2038
2024-05-23 19:58:55 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch7_loss0.20383692681789398.pypots
2024-05-23 19:59:11 [INFO]: Epoch 008 - training loss: 0.1952, validation loss: 0.1858
2024-05-23 19:59:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch8_loss0.18583750277757644.pypots
2024-05-23 19:59:28 [INFO]: Epoch 009 - training loss: 0.1961, validation loss: 0.1745
2024-05-23 19:59:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch9_loss0.17448272854089736.pypots
2024-05-23 19:59:44 [INFO]: Epoch 010 - training loss: 0.1716, validation loss: 0.1667
2024-05-23 19:59:44 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch10_loss0.16674024164676665.pypots
2024-05-23 20:00:01 [INFO]: Epoch 011 - training loss: 0.1735, validation loss: 0.1587
2024-05-23 20:00:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch11_loss0.15869031548500062.pypots
2024-05-23 20:00:17 [INFO]: Epoch 012 - training loss: 0.1696, validation loss: 0.1588
2024-05-23 20:00:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch12_loss0.15879440158605576.pypots
2024-05-23 20:00:33 [INFO]: Epoch 013 - training loss: 0.1516, validation loss: 0.1521
2024-05-23 20:00:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch13_loss0.1520500510931015.pypots
2024-05-23 20:00:50 [INFO]: Epoch 014 - training loss: 0.1514, validation loss: 0.1478
2024-05-23 20:00:50 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch14_loss0.14780734926462175.pypots
2024-05-23 20:01:06 [INFO]: Epoch 015 - training loss: 0.1560, validation loss: 0.1460
2024-05-23 20:01:06 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch15_loss0.1459611564874649.pypots
2024-05-23 20:01:23 [INFO]: Epoch 016 - training loss: 0.1523, validation loss: 0.1462
2024-05-23 20:01:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch16_loss0.1462429091334343.pypots
2024-05-23 20:01:39 [INFO]: Epoch 017 - training loss: 0.1557, validation loss: 0.1429
2024-05-23 20:01:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch17_loss0.14286163747310637.pypots
2024-05-23 20:01:56 [INFO]: Epoch 018 - training loss: 0.1566, validation loss: 0.1428
2024-05-23 20:01:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch18_loss0.14275425374507905.pypots
2024-05-23 20:02:12 [INFO]: Epoch 019 - training loss: 0.1436, validation loss: 0.1375
2024-05-23 20:02:12 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch19_loss0.13748345673084258.pypots
2024-05-23 20:02:28 [INFO]: Epoch 020 - training loss: 0.1437, validation loss: 0.1386
2024-05-23 20:02:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch20_loss0.13863973021507264.pypots
2024-05-23 20:02:45 [INFO]: Epoch 021 - training loss: 0.1489, validation loss: 0.1368
2024-05-23 20:02:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch21_loss0.1367930918931961.pypots
2024-05-23 20:03:01 [INFO]: Epoch 022 - training loss: 0.1484, validation loss: 0.1378
2024-05-23 20:03:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch22_loss0.13778936937451364.pypots
2024-05-23 20:03:18 [INFO]: Epoch 023 - training loss: 0.1645, validation loss: 0.1330
2024-05-23 20:03:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch23_loss0.13304806724190713.pypots
2024-05-23 20:03:34 [INFO]: Epoch 024 - training loss: 0.1391, validation loss: 0.1334
2024-05-23 20:03:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch24_loss0.1333770141005516.pypots
2024-05-23 20:03:50 [INFO]: Epoch 025 - training loss: 0.1517, validation loss: 0.1311
2024-05-23 20:03:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch25_loss0.13112545982003213.pypots
2024-05-23 20:04:07 [INFO]: Epoch 026 - training loss: 0.1422, validation loss: 0.1318
2024-05-23 20:04:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch26_loss0.13182109072804452.pypots
2024-05-23 20:04:23 [INFO]: Epoch 027 - training loss: 0.1435, validation loss: 0.1301
2024-05-23 20:04:23 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch27_loss0.1301243409514427.pypots
2024-05-23 20:04:40 [INFO]: Epoch 028 - training loss: 0.1306, validation loss: 0.1295
2024-05-23 20:04:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch28_loss0.1294753558933735.pypots
2024-05-23 20:04:56 [INFO]: Epoch 029 - training loss: 0.1305, validation loss: 0.1308
2024-05-23 20:04:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch29_loss0.13079976439476013.pypots
2024-05-23 20:05:13 [INFO]: Epoch 030 - training loss: 0.1232, validation loss: 0.1281
2024-05-23 20:05:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch30_loss0.1280755005776882.pypots
2024-05-23 20:05:29 [INFO]: Epoch 031 - training loss: 0.1248, validation loss: 0.1290
2024-05-23 20:05:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch31_loss0.12901503965258598.pypots
2024-05-23 20:05:45 [INFO]: Epoch 032 - training loss: 0.1281, validation loss: 0.1247
2024-05-23 20:05:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch32_loss0.12471833899617195.pypots
2024-05-23 20:06:02 [INFO]: Epoch 033 - training loss: 0.1313, validation loss: 0.1325
2024-05-23 20:06:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch33_loss0.13253081291913987.pypots
2024-05-23 20:06:18 [INFO]: Epoch 034 - training loss: 0.1187, validation loss: 0.1263
2024-05-23 20:06:18 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch34_loss0.12633820548653601.pypots
2024-05-23 20:06:35 [INFO]: Epoch 035 - training loss: 0.1231, validation loss: 0.1241
2024-05-23 20:06:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch35_loss0.12411930561065673.pypots
2024-05-23 20:06:51 [INFO]: Epoch 036 - training loss: 0.1231, validation loss: 0.1282
2024-05-23 20:06:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch36_loss0.12823728621006011.pypots
2024-05-23 20:07:08 [INFO]: Epoch 037 - training loss: 0.1315, validation loss: 0.1242
2024-05-23 20:07:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch37_loss0.12419919967651367.pypots
2024-05-23 20:07:24 [INFO]: Epoch 038 - training loss: 0.1259, validation loss: 0.1291
2024-05-23 20:07:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch38_loss0.12908439412713052.pypots
2024-05-23 20:07:40 [INFO]: Epoch 039 - training loss: 0.1318, validation loss: 0.1233
2024-05-23 20:07:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch39_loss0.12327383682131768.pypots
2024-05-23 20:07:57 [INFO]: Epoch 040 - training loss: 0.1275, validation loss: 0.1230
2024-05-23 20:07:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch40_loss0.123025793582201.pypots
2024-05-23 20:08:13 [INFO]: Epoch 041 - training loss: 0.1252, validation loss: 0.1255
2024-05-23 20:08:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch41_loss0.1254749983549118.pypots
2024-05-23 20:08:30 [INFO]: Epoch 042 - training loss: 0.1285, validation loss: 0.1190
2024-05-23 20:08:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch42_loss0.11898880377411843.pypots
2024-05-23 20:08:46 [INFO]: Epoch 043 - training loss: 0.1344, validation loss: 0.1217
2024-05-23 20:08:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch43_loss0.12174907475709915.pypots
2024-05-23 20:09:02 [INFO]: Epoch 044 - training loss: 0.1187, validation loss: 0.1229
2024-05-23 20:09:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch44_loss0.122916591912508.pypots
2024-05-23 20:09:19 [INFO]: Epoch 045 - training loss: 0.1321, validation loss: 0.1208
2024-05-23 20:09:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch45_loss0.1208417497575283.pypots
2024-05-23 20:09:35 [INFO]: Epoch 046 - training loss: 0.1229, validation loss: 0.1233
2024-05-23 20:09:35 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch46_loss0.12330960184335708.pypots
2024-05-23 20:09:52 [INFO]: Epoch 047 - training loss: 0.1117, validation loss: 0.1206
2024-05-23 20:09:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch47_loss0.12059641033411025.pypots
2024-05-23 20:10:08 [INFO]: Epoch 048 - training loss: 0.1166, validation loss: 0.1181
2024-05-23 20:10:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch48_loss0.11805759146809577.pypots
2024-05-23 20:10:24 [INFO]: Epoch 049 - training loss: 0.1098, validation loss: 0.1181
2024-05-23 20:10:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch49_loss0.11807115525007247.pypots
2024-05-23 20:10:41 [INFO]: Epoch 050 - training loss: 0.1240, validation loss: 0.1202
2024-05-23 20:10:41 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch50_loss0.12020161300897599.pypots
2024-05-23 20:10:57 [INFO]: Epoch 051 - training loss: 0.1327, validation loss: 0.1257
2024-05-23 20:10:57 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch51_loss0.1256701059639454.pypots
2024-05-23 20:11:14 [INFO]: Epoch 052 - training loss: 0.1192, validation loss: 0.1193
2024-05-23 20:11:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch52_loss0.1192552924156189.pypots
2024-05-23 20:11:30 [INFO]: Epoch 053 - training loss: 0.1197, validation loss: 0.1157
2024-05-23 20:11:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch53_loss0.11568667441606521.pypots
2024-05-23 20:11:47 [INFO]: Epoch 054 - training loss: 0.1192, validation loss: 0.1143
2024-05-23 20:11:47 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch54_loss0.11433873400092125.pypots
2024-05-23 20:12:03 [INFO]: Epoch 055 - training loss: 0.1234, validation loss: 0.1142
2024-05-23 20:12:03 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch55_loss0.11415991187095642.pypots
2024-05-23 20:12:20 [INFO]: Epoch 056 - training loss: 0.0994, validation loss: 0.1141
2024-05-23 20:12:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch56_loss0.11411652565002442.pypots
2024-05-23 20:12:36 [INFO]: Epoch 057 - training loss: 0.1103, validation loss: 0.1140
2024-05-23 20:12:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch57_loss0.11402838006615638.pypots
2024-05-23 20:12:52 [INFO]: Epoch 058 - training loss: 0.1029, validation loss: 0.1147
2024-05-23 20:12:52 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch58_loss0.11467470526695252.pypots
2024-05-23 20:13:09 [INFO]: Epoch 059 - training loss: 0.1078, validation loss: 0.1202
2024-05-23 20:13:09 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch59_loss0.12019737884402275.pypots
2024-05-23 20:13:25 [INFO]: Epoch 060 - training loss: 0.1280, validation loss: 0.1163
2024-05-23 20:13:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch60_loss0.11630399897694588.pypots
2024-05-23 20:13:42 [INFO]: Epoch 061 - training loss: 0.1005, validation loss: 0.1132
2024-05-23 20:13:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch61_loss0.11315879672765732.pypots
2024-05-23 20:13:58 [INFO]: Epoch 062 - training loss: 0.1119, validation loss: 0.1175
2024-05-23 20:13:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch62_loss0.11748061254620552.pypots
2024-05-23 20:14:15 [INFO]: Epoch 063 - training loss: 0.1227, validation loss: 0.1131
2024-05-23 20:14:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch63_loss0.11309807300567627.pypots
2024-05-23 20:14:31 [INFO]: Epoch 064 - training loss: 0.1219, validation loss: 0.1132
2024-05-23 20:14:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch64_loss0.11323467493057252.pypots
2024-05-23 20:14:48 [INFO]: Epoch 065 - training loss: 0.1086, validation loss: 0.1139
2024-05-23 20:14:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch65_loss0.11388252973556519.pypots
2024-05-23 20:15:04 [INFO]: Epoch 066 - training loss: 0.1116, validation loss: 0.1121
2024-05-23 20:15:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch66_loss0.11214703544974328.pypots
2024-05-23 20:15:20 [INFO]: Epoch 067 - training loss: 0.1156, validation loss: 0.1110
2024-05-23 20:15:20 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch67_loss0.1109885610640049.pypots
2024-05-23 20:15:37 [INFO]: Epoch 068 - training loss: 0.1069, validation loss: 0.1118
2024-05-23 20:15:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch68_loss0.11183210760354996.pypots
2024-05-23 20:15:53 [INFO]: Epoch 069 - training loss: 0.1098, validation loss: 0.1121
2024-05-23 20:15:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch69_loss0.1120895653963089.pypots
2024-05-23 20:16:10 [INFO]: Epoch 070 - training loss: 0.1182, validation loss: 0.1094
2024-05-23 20:16:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch70_loss0.10939503163099289.pypots
2024-05-23 20:16:26 [INFO]: Epoch 071 - training loss: 0.1061, validation loss: 0.1100
2024-05-23 20:16:26 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch71_loss0.10997518822550774.pypots
2024-05-23 20:16:43 [INFO]: Epoch 072 - training loss: 0.1251, validation loss: 0.1123
2024-05-23 20:16:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch72_loss0.11226365640759468.pypots
2024-05-23 20:16:59 [INFO]: Epoch 073 - training loss: 0.1140, validation loss: 0.1115
2024-05-23 20:16:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch73_loss0.11151138618588448.pypots
2024-05-23 20:17:16 [INFO]: Epoch 074 - training loss: 0.1130, validation loss: 0.1123
2024-05-23 20:17:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch74_loss0.11232237964868545.pypots
2024-05-23 20:17:32 [INFO]: Epoch 075 - training loss: 0.1021, validation loss: 0.1102
2024-05-23 20:17:32 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch75_loss0.11023218557238579.pypots
2024-05-23 20:17:48 [INFO]: Epoch 076 - training loss: 0.1038, validation loss: 0.1098
2024-05-23 20:17:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch76_loss0.10983357802033425.pypots
2024-05-23 20:18:05 [INFO]: Epoch 077 - training loss: 0.1091, validation loss: 0.1116
2024-05-23 20:18:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch77_loss0.11163645759224891.pypots
2024-05-23 20:18:21 [INFO]: Epoch 078 - training loss: 0.1205, validation loss: 0.1107
2024-05-23 20:18:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch78_loss0.11073827967047692.pypots
2024-05-23 20:18:38 [INFO]: Epoch 079 - training loss: 0.1086, validation loss: 0.1104
2024-05-23 20:18:38 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch79_loss0.11039969250559807.pypots
2024-05-23 20:18:54 [INFO]: Epoch 080 - training loss: 0.1208, validation loss: 0.1134
2024-05-23 20:18:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI_epoch80_loss0.11341137662529946.pypots
2024-05-23 20:18:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:18:54 [INFO]: Finished training. The best model is from epoch#70.
2024-05-23 20:18:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/CSDI_air_quality/20240523_T195700/CSDI.pypots
2024-05-23 20:21:12 [INFO]: CSDI on Air-Quality: MAE=0.1194, MSE=0.2602
2024-05-23 20:21:13 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-23 20:21:13 [INFO]: Using the given device: cuda:0
2024-05-23 20:21:13 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240523_T202113
2024-05-23 20:21:13 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240523_T202113/tensorboard
2024-05-23 20:21:13 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 20:21:13 [INFO]: Epoch 001 - training loss: 63138.0780, validation loss: 0.6191
2024-05-23 20:21:13 [INFO]: Epoch 002 - training loss: 41832.2280, validation loss: 0.5461
2024-05-23 20:21:13 [INFO]: Epoch 003 - training loss: 41513.5647, validation loss: 0.5122
2024-05-23 20:21:13 [INFO]: Epoch 004 - training loss: 41393.5302, validation loss: 0.5207
2024-05-23 20:21:14 [INFO]: Epoch 005 - training loss: 41340.9514, validation loss: 0.4216
2024-05-23 20:21:14 [INFO]: Epoch 006 - training loss: 41223.2677, validation loss: 0.3941
2024-05-23 20:21:14 [INFO]: Epoch 007 - training loss: 41178.8505, validation loss: 0.3589
2024-05-23 20:21:14 [INFO]: Epoch 008 - training loss: 41144.7972, validation loss: 0.3496
2024-05-23 20:21:15 [INFO]: Epoch 009 - training loss: 41104.6460, validation loss: 0.3212
2024-05-23 20:21:15 [INFO]: Epoch 010 - training loss: 41075.9719, validation loss: 0.2995
2024-05-23 20:21:15 [INFO]: Epoch 011 - training loss: 41048.7467, validation loss: 0.2934
2024-05-23 20:21:15 [INFO]: Epoch 012 - training loss: 41055.8715, validation loss: 0.2869
2024-05-23 20:21:16 [INFO]: Epoch 013 - training loss: 41093.9342, validation loss: 0.4062
2024-05-23 20:21:16 [INFO]: Epoch 014 - training loss: 41120.1869, validation loss: 0.3300
2024-05-23 20:21:16 [INFO]: Epoch 015 - training loss: 41035.1743, validation loss: 0.2944
2024-05-23 20:21:16 [INFO]: Epoch 016 - training loss: 40996.6169, validation loss: 0.2677
2024-05-23 20:21:17 [INFO]: Epoch 017 - training loss: 40981.2733, validation loss: 0.2608
2024-05-23 20:21:17 [INFO]: Epoch 018 - training loss: 40969.7403, validation loss: 0.2618
2024-05-23 20:21:17 [INFO]: Epoch 019 - training loss: 40959.7849, validation loss: 0.2582
2024-05-23 20:21:17 [INFO]: Epoch 020 - training loss: 40950.9964, validation loss: 0.2587
2024-05-23 20:21:18 [INFO]: Epoch 021 - training loss: 40955.1175, validation loss: 0.2819
2024-05-23 20:21:18 [INFO]: Epoch 022 - training loss: 40969.9741, validation loss: 0.2554
2024-05-23 20:21:18 [INFO]: Epoch 023 - training loss: 40945.4559, validation loss: 0.2608
2024-05-23 20:21:18 [INFO]: Epoch 024 - training loss: 40947.7041, validation loss: 0.2538
2024-05-23 20:21:19 [INFO]: Epoch 025 - training loss: 41004.7953, validation loss: 0.2629
2024-05-23 20:21:19 [INFO]: Epoch 026 - training loss: 41010.2671, validation loss: 0.2944
2024-05-23 20:21:19 [INFO]: Epoch 027 - training loss: 41007.7044, validation loss: 0.2619
2024-05-23 20:21:19 [INFO]: Epoch 028 - training loss: 40947.5440, validation loss: 0.2376
2024-05-23 20:21:20 [INFO]: Epoch 029 - training loss: 40920.3575, validation loss: 0.2356
2024-05-23 20:21:20 [INFO]: Epoch 030 - training loss: 40910.7406, validation loss: 0.2346
2024-05-23 20:21:20 [INFO]: Epoch 031 - training loss: 40931.2594, validation loss: 0.3615
2024-05-23 20:21:20 [INFO]: Epoch 032 - training loss: 40962.7962, validation loss: 0.2403
2024-05-23 20:21:20 [INFO]: Epoch 033 - training loss: 40911.9164, validation loss: 0.2367
2024-05-23 20:21:21 [INFO]: Epoch 034 - training loss: 40900.1790, validation loss: 0.2252
2024-05-23 20:21:21 [INFO]: Epoch 035 - training loss: 40889.4601, validation loss: 0.2211
2024-05-23 20:21:21 [INFO]: Epoch 036 - training loss: 40889.0318, validation loss: 0.2261
2024-05-23 20:21:21 [INFO]: Epoch 037 - training loss: 40888.0809, validation loss: 0.2204
2024-05-23 20:21:22 [INFO]: Epoch 038 - training loss: 40881.7093, validation loss: 0.2288
2024-05-23 20:21:22 [INFO]: Epoch 039 - training loss: 40888.9213, validation loss: 0.2202
2024-05-23 20:21:22 [INFO]: Epoch 040 - training loss: 40882.0012, validation loss: 0.2173
2024-05-23 20:21:22 [INFO]: Epoch 041 - training loss: 40889.3313, validation loss: 0.2283
2024-05-23 20:21:23 [INFO]: Epoch 042 - training loss: 40880.0968, validation loss: 0.2208
2024-05-23 20:21:23 [INFO]: Epoch 043 - training loss: 40878.5710, validation loss: 0.2171
2024-05-23 20:21:23 [INFO]: Epoch 044 - training loss: 40889.4708, validation loss: 0.2231
2024-05-23 20:21:23 [INFO]: Epoch 045 - training loss: 40887.1152, validation loss: 0.2300
2024-05-23 20:21:24 [INFO]: Epoch 046 - training loss: 40903.3019, validation loss: 0.2390
2024-05-23 20:21:24 [INFO]: Epoch 047 - training loss: 40928.4780, validation loss: 0.2232
2024-05-23 20:21:24 [INFO]: Epoch 048 - training loss: 40910.5056, validation loss: 0.2367
2024-05-23 20:21:24 [INFO]: Epoch 049 - training loss: 40946.4129, validation loss: 0.2246
2024-05-23 20:21:25 [INFO]: Epoch 050 - training loss: 40912.7215, validation loss: 0.2139
2024-05-23 20:21:25 [INFO]: Epoch 051 - training loss: 40893.9420, validation loss: 0.2093
2024-05-23 20:21:25 [INFO]: Epoch 052 - training loss: 40878.8643, validation loss: 0.2116
2024-05-23 20:21:25 [INFO]: Epoch 053 - training loss: 40883.1662, validation loss: 0.2065
2024-05-23 20:21:26 [INFO]: Epoch 054 - training loss: 40878.4288, validation loss: 0.2071
2024-05-23 20:21:26 [INFO]: Epoch 055 - training loss: 40871.4475, validation loss: 0.2091
2024-05-23 20:21:26 [INFO]: Epoch 056 - training loss: 40861.8953, validation loss: 0.2049
2024-05-23 20:21:26 [INFO]: Epoch 057 - training loss: 40857.9958, validation loss: 0.2072
2024-05-23 20:21:26 [INFO]: Epoch 058 - training loss: 40861.7951, validation loss: 0.2025
2024-05-23 20:21:27 [INFO]: Epoch 059 - training loss: 40854.2279, validation loss: 0.2047
2024-05-23 20:21:27 [INFO]: Epoch 060 - training loss: 40854.1866, validation loss: 0.2029
2024-05-23 20:21:27 [INFO]: Epoch 061 - training loss: 40857.6667, validation loss: 0.2136
2024-05-23 20:21:27 [INFO]: Epoch 062 - training loss: 40855.9193, validation loss: 0.2040
2024-05-23 20:21:28 [INFO]: Epoch 063 - training loss: 40860.4327, validation loss: 0.2125
2024-05-23 20:21:28 [INFO]: Epoch 064 - training loss: 40909.8406, validation loss: 0.2228
2024-05-23 20:21:28 [INFO]: Epoch 065 - training loss: 40928.0748, validation loss: 0.2204
2024-05-23 20:21:28 [INFO]: Epoch 066 - training loss: 40906.1451, validation loss: 0.2049
2024-05-23 20:21:29 [INFO]: Epoch 067 - training loss: 40870.9321, validation loss: 0.2096
2024-05-23 20:21:29 [INFO]: Epoch 068 - training loss: 40858.5722, validation loss: 0.2050
2024-05-23 20:21:29 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:21:29 [INFO]: Finished training. The best model is from epoch#58.
2024-05-23 20:21:29 [INFO]: Saved the model to overlay_premask_saved_results/round_3/GPVAE_air_quality/20240523_T202113/GPVAE.pypots
2024-05-23 20:21:29 [INFO]: GP-VAE on Air-Quality: MAE=0.2717, MSE=0.2975
2024-05-23 20:21:29 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-23 20:21:29 [INFO]: Using the given device: cuda:0
2024-05-23 20:21:29 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240523_T202129
2024-05-23 20:21:29 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/USGAN_air_quality/20240523_T202129/tensorboard
2024-05-23 20:21:29 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 20:21:33 [INFO]: Epoch 001 - generator training loss: 0.4486, discriminator training loss: 0.4512, validation loss: 0.4868
2024-05-23 20:21:36 [INFO]: Epoch 002 - generator training loss: 0.0870, discriminator training loss: 0.3616, validation loss: 0.3593
2024-05-23 20:21:40 [INFO]: Epoch 003 - generator training loss: 0.0236, discriminator training loss: 0.3574, validation loss: 0.2929
2024-05-23 20:21:43 [INFO]: Epoch 004 - generator training loss: -0.0148, discriminator training loss: 0.3552, validation loss: 0.2565
2024-05-23 20:21:46 [INFO]: Epoch 005 - generator training loss: -0.0357, discriminator training loss: 0.3535, validation loss: 0.2293
2024-05-23 20:21:50 [INFO]: Epoch 006 - generator training loss: -0.0528, discriminator training loss: 0.3516, validation loss: 0.2123
2024-05-23 20:21:53 [INFO]: Epoch 007 - generator training loss: -0.0656, discriminator training loss: 0.3496, validation loss: 0.1985
2024-05-23 20:21:56 [INFO]: Epoch 008 - generator training loss: -0.0735, discriminator training loss: 0.3471, validation loss: 0.1886
2024-05-23 20:22:00 [INFO]: Epoch 009 - generator training loss: -0.0801, discriminator training loss: 0.3447, validation loss: 0.1806
2024-05-23 20:22:03 [INFO]: Epoch 010 - generator training loss: -0.0863, discriminator training loss: 0.3424, validation loss: 0.1740
2024-05-23 20:22:06 [INFO]: Epoch 011 - generator training loss: -0.0913, discriminator training loss: 0.3397, validation loss: 0.1673
2024-05-23 20:22:10 [INFO]: Epoch 012 - generator training loss: -0.0891, discriminator training loss: 0.3368, validation loss: 0.1630
2024-05-23 20:22:13 [INFO]: Epoch 013 - generator training loss: -0.0958, discriminator training loss: 0.3338, validation loss: 0.1588
2024-05-23 20:22:16 [INFO]: Epoch 014 - generator training loss: -0.0965, discriminator training loss: 0.3306, validation loss: 0.1546
2024-05-23 20:22:20 [INFO]: Epoch 015 - generator training loss: -0.0997, discriminator training loss: 0.3275, validation loss: 0.1510
2024-05-23 20:22:23 [INFO]: Epoch 016 - generator training loss: -0.0985, discriminator training loss: 0.3240, validation loss: 0.1476
2024-05-23 20:22:26 [INFO]: Epoch 017 - generator training loss: -0.1002, discriminator training loss: 0.3206, validation loss: 0.1448
2024-05-23 20:22:30 [INFO]: Epoch 018 - generator training loss: -0.0990, discriminator training loss: 0.3170, validation loss: 0.1417
2024-05-23 20:22:33 [INFO]: Epoch 019 - generator training loss: -0.0995, discriminator training loss: 0.3132, validation loss: 0.1388
2024-05-23 20:22:36 [INFO]: Epoch 020 - generator training loss: -0.0996, discriminator training loss: 0.3094, validation loss: 0.1355
2024-05-23 20:22:40 [INFO]: Epoch 021 - generator training loss: -0.0983, discriminator training loss: 0.3054, validation loss: 0.1331
2024-05-23 20:22:43 [INFO]: Epoch 022 - generator training loss: -0.0974, discriminator training loss: 0.3012, validation loss: 0.1306
2024-05-23 20:22:46 [INFO]: Epoch 023 - generator training loss: -0.0977, discriminator training loss: 0.2976, validation loss: 0.1287
2024-05-23 20:22:50 [INFO]: Epoch 024 - generator training loss: -0.0972, discriminator training loss: 0.2939, validation loss: 0.1269
2024-05-23 20:22:53 [INFO]: Epoch 025 - generator training loss: -0.0929, discriminator training loss: 0.2901, validation loss: 0.1253
2024-05-23 20:22:56 [INFO]: Epoch 026 - generator training loss: -0.0941, discriminator training loss: 0.2860, validation loss: 0.1236
2024-05-23 20:23:00 [INFO]: Epoch 027 - generator training loss: -0.0930, discriminator training loss: 0.2825, validation loss: 0.1225
2024-05-23 20:23:03 [INFO]: Epoch 028 - generator training loss: -0.0916, discriminator training loss: 0.2792, validation loss: 0.1208
2024-05-23 20:23:06 [INFO]: Epoch 029 - generator training loss: -0.0911, discriminator training loss: 0.2755, validation loss: 0.1186
2024-05-23 20:23:10 [INFO]: Epoch 030 - generator training loss: -0.0883, discriminator training loss: 0.2724, validation loss: 0.1179
2024-05-23 20:23:13 [INFO]: Epoch 031 - generator training loss: -0.0890, discriminator training loss: 0.2693, validation loss: 0.1168
2024-05-23 20:23:16 [INFO]: Epoch 032 - generator training loss: -0.0874, discriminator training loss: 0.2661, validation loss: 0.1160
2024-05-23 20:23:20 [INFO]: Epoch 033 - generator training loss: -0.0859, discriminator training loss: 0.2631, validation loss: 0.1142
2024-05-23 20:23:23 [INFO]: Epoch 034 - generator training loss: -0.0846, discriminator training loss: 0.2602, validation loss: 0.1126
2024-05-23 20:23:26 [INFO]: Epoch 035 - generator training loss: -0.0841, discriminator training loss: 0.2576, validation loss: 0.1119
2024-05-23 20:23:30 [INFO]: Epoch 036 - generator training loss: -0.0837, discriminator training loss: 0.2550, validation loss: 0.1108
2024-05-23 20:23:33 [INFO]: Epoch 037 - generator training loss: -0.0829, discriminator training loss: 0.2530, validation loss: 0.1095
2024-05-23 20:23:37 [INFO]: Epoch 038 - generator training loss: -0.0818, discriminator training loss: 0.2507, validation loss: 0.1086
2024-05-23 20:23:40 [INFO]: Epoch 039 - generator training loss: -0.0812, discriminator training loss: 0.2483, validation loss: 0.1080
2024-05-23 20:23:43 [INFO]: Epoch 040 - generator training loss: -0.0810, discriminator training loss: 0.2462, validation loss: 0.1073
2024-05-23 20:23:47 [INFO]: Epoch 041 - generator training loss: -0.0816, discriminator training loss: 0.2445, validation loss: 0.1058
2024-05-23 20:23:50 [INFO]: Epoch 042 - generator training loss: -0.0795, discriminator training loss: 0.2430, validation loss: 0.1055
2024-05-23 20:23:53 [INFO]: Epoch 043 - generator training loss: -0.0780, discriminator training loss: 0.2409, validation loss: 0.1043
2024-05-23 20:23:57 [INFO]: Epoch 044 - generator training loss: -0.0795, discriminator training loss: 0.2393, validation loss: 0.1034
2024-05-23 20:24:00 [INFO]: Epoch 045 - generator training loss: -0.0791, discriminator training loss: 0.2374, validation loss: 0.1026
2024-05-23 20:24:03 [INFO]: Epoch 046 - generator training loss: -0.0777, discriminator training loss: 0.2365, validation loss: 0.1023
2024-05-23 20:24:07 [INFO]: Epoch 047 - generator training loss: -0.0787, discriminator training loss: 0.2347, validation loss: 0.1015
2024-05-23 20:24:10 [INFO]: Epoch 048 - generator training loss: -0.0779, discriminator training loss: 0.2337, validation loss: 0.1006
2024-05-23 20:24:13 [INFO]: Epoch 049 - generator training loss: -0.0778, discriminator training loss: 0.2326, validation loss: 0.1005
2024-05-23 20:24:17 [INFO]: Epoch 050 - generator training loss: -0.0781, discriminator training loss: 0.2310, validation loss: 0.0992
2024-05-23 20:24:20 [INFO]: Epoch 051 - generator training loss: -0.0778, discriminator training loss: 0.2300, validation loss: 0.0991
2024-05-23 20:24:23 [INFO]: Epoch 052 - generator training loss: -0.0767, discriminator training loss: 0.2288, validation loss: 0.0979
2024-05-23 20:24:27 [INFO]: Epoch 053 - generator training loss: -0.0777, discriminator training loss: 0.2280, validation loss: 0.0982
2024-05-23 20:24:30 [INFO]: Epoch 054 - generator training loss: -0.0773, discriminator training loss: 0.2270, validation loss: 0.0976
2024-05-23 20:24:34 [INFO]: Epoch 055 - generator training loss: -0.0777, discriminator training loss: 0.2259, validation loss: 0.0971
2024-05-23 20:24:37 [INFO]: Epoch 056 - generator training loss: -0.0771, discriminator training loss: 0.2250, validation loss: 0.0963
2024-05-23 20:24:40 [INFO]: Epoch 057 - generator training loss: -0.0770, discriminator training loss: 0.2240, validation loss: 0.0956
2024-05-23 20:24:44 [INFO]: Epoch 058 - generator training loss: -0.0770, discriminator training loss: 0.2231, validation loss: 0.0954
2024-05-23 20:24:47 [INFO]: Epoch 059 - generator training loss: -0.0777, discriminator training loss: 0.2224, validation loss: 0.0951
2024-05-23 20:24:50 [INFO]: Epoch 060 - generator training loss: -0.0750, discriminator training loss: 0.2217, validation loss: 0.0948
2024-05-23 20:24:54 [INFO]: Epoch 061 - generator training loss: -0.0769, discriminator training loss: 0.2211, validation loss: 0.0942
2024-05-23 20:24:57 [INFO]: Epoch 062 - generator training loss: -0.0770, discriminator training loss: 0.2202, validation loss: 0.0941
2024-05-23 20:25:00 [INFO]: Epoch 063 - generator training loss: -0.0771, discriminator training loss: 0.2198, validation loss: 0.0942
2024-05-23 20:25:04 [INFO]: Epoch 064 - generator training loss: -0.0766, discriminator training loss: 0.2190, validation loss: 0.0934
2024-05-23 20:25:07 [INFO]: Epoch 065 - generator training loss: -0.0766, discriminator training loss: 0.2185, validation loss: 0.0932
2024-05-23 20:25:10 [INFO]: Epoch 066 - generator training loss: -0.0766, discriminator training loss: 0.2177, validation loss: 0.0927
2024-05-23 20:25:14 [INFO]: Epoch 067 - generator training loss: -0.0760, discriminator training loss: 0.2174, validation loss: 0.0928
2024-05-23 20:25:17 [INFO]: Epoch 068 - generator training loss: -0.0773, discriminator training loss: 0.2169, validation loss: 0.0918
2024-05-23 20:25:20 [INFO]: Epoch 069 - generator training loss: -0.0759, discriminator training loss: 0.2157, validation loss: 0.0918
2024-05-23 20:25:24 [INFO]: Epoch 070 - generator training loss: -0.0776, discriminator training loss: 0.2158, validation loss: 0.0916
2024-05-23 20:25:27 [INFO]: Epoch 071 - generator training loss: -0.0785, discriminator training loss: 0.2152, validation loss: 0.0917
2024-05-23 20:25:30 [INFO]: Epoch 072 - generator training loss: -0.0770, discriminator training loss: 0.2145, validation loss: 0.0907
2024-05-23 20:25:34 [INFO]: Epoch 073 - generator training loss: -0.0775, discriminator training loss: 0.2144, validation loss: 0.0911
2024-05-23 20:25:37 [INFO]: Epoch 074 - generator training loss: -0.0781, discriminator training loss: 0.2137, validation loss: 0.0910
2024-05-23 20:25:40 [INFO]: Epoch 075 - generator training loss: -0.0780, discriminator training loss: 0.2136, validation loss: 0.0913
2024-05-23 20:25:44 [INFO]: Epoch 076 - generator training loss: -0.0782, discriminator training loss: 0.2132, validation loss: 0.0905
2024-05-23 20:25:47 [INFO]: Epoch 077 - generator training loss: -0.0774, discriminator training loss: 0.2130, validation loss: 0.0912
2024-05-23 20:25:50 [INFO]: Epoch 078 - generator training loss: -0.0771, discriminator training loss: 0.2125, validation loss: 0.0906
2024-05-23 20:25:54 [INFO]: Epoch 079 - generator training loss: -0.0779, discriminator training loss: 0.2122, validation loss: 0.0903
2024-05-23 20:25:57 [INFO]: Epoch 080 - generator training loss: -0.0785, discriminator training loss: 0.2120, validation loss: 0.0896
2024-05-23 20:26:00 [INFO]: Epoch 081 - generator training loss: -0.0772, discriminator training loss: 0.2117, validation loss: 0.0891
2024-05-23 20:26:04 [INFO]: Epoch 082 - generator training loss: -0.0785, discriminator training loss: 0.2112, validation loss: 0.0892
2024-05-23 20:26:07 [INFO]: Epoch 083 - generator training loss: -0.0785, discriminator training loss: 0.2110, validation loss: 0.0899
2024-05-23 20:26:11 [INFO]: Epoch 084 - generator training loss: -0.0792, discriminator training loss: 0.2107, validation loss: 0.0892
2024-05-23 20:26:14 [INFO]: Epoch 085 - generator training loss: -0.0793, discriminator training loss: 0.2105, validation loss: 0.0891
2024-05-23 20:26:17 [INFO]: Epoch 086 - generator training loss: -0.0783, discriminator training loss: 0.2102, validation loss: 0.0893
2024-05-23 20:26:21 [INFO]: Epoch 087 - generator training loss: -0.0789, discriminator training loss: 0.2102, validation loss: 0.0883
2024-05-23 20:26:24 [INFO]: Epoch 088 - generator training loss: -0.0784, discriminator training loss: 0.2098, validation loss: 0.0886
2024-05-23 20:26:27 [INFO]: Epoch 089 - generator training loss: -0.0784, discriminator training loss: 0.2095, validation loss: 0.0881
2024-05-23 20:26:31 [INFO]: Epoch 090 - generator training loss: -0.0800, discriminator training loss: 0.2097, validation loss: 0.0886
2024-05-23 20:26:34 [INFO]: Epoch 091 - generator training loss: -0.0799, discriminator training loss: 0.2090, validation loss: 0.0885
2024-05-23 20:26:37 [INFO]: Epoch 092 - generator training loss: -0.0801, discriminator training loss: 0.2086, validation loss: 0.0885
2024-05-23 20:26:41 [INFO]: Epoch 093 - generator training loss: -0.0821, discriminator training loss: 0.2083, validation loss: 0.0880
2024-05-23 20:26:44 [INFO]: Epoch 094 - generator training loss: -0.0805, discriminator training loss: 0.2087, validation loss: 0.0885
2024-05-23 20:26:47 [INFO]: Epoch 095 - generator training loss: -0.0808, discriminator training loss: 0.2082, validation loss: 0.0882
2024-05-23 20:26:51 [INFO]: Epoch 096 - generator training loss: -0.0806, discriminator training loss: 0.2082, validation loss: 0.0882
2024-05-23 20:26:54 [INFO]: Epoch 097 - generator training loss: -0.0804, discriminator training loss: 0.2076, validation loss: 0.0896
2024-05-23 20:26:57 [INFO]: Epoch 098 - generator training loss: -0.0806, discriminator training loss: 0.2080, validation loss: 0.0879
2024-05-23 20:27:01 [INFO]: Epoch 099 - generator training loss: -0.0813, discriminator training loss: 0.2076, validation loss: 0.0895
2024-05-23 20:27:04 [INFO]: Epoch 100 - generator training loss: -0.0803, discriminator training loss: 0.2076, validation loss: 0.0889
2024-05-23 20:27:07 [INFO]: Epoch 101 - generator training loss: -0.0814, discriminator training loss: 0.2075, validation loss: 0.0876
2024-05-23 20:27:11 [INFO]: Epoch 102 - generator training loss: -0.0830, discriminator training loss: 0.2071, validation loss: 0.0884
2024-05-23 20:27:14 [INFO]: Epoch 103 - generator training loss: -0.0816, discriminator training loss: 0.2066, validation loss: 0.0902
2024-05-23 20:27:17 [INFO]: Epoch 104 - generator training loss: -0.0808, discriminator training loss: 0.2070, validation loss: 0.0874
2024-05-23 20:27:21 [INFO]: Epoch 105 - generator training loss: -0.0808, discriminator training loss: 0.2058, validation loss: 0.0895
2024-05-23 20:27:24 [INFO]: Epoch 106 - generator training loss: -0.0790, discriminator training loss: 0.2068, validation loss: 0.0879
2024-05-23 20:27:27 [INFO]: Epoch 107 - generator training loss: -0.0805, discriminator training loss: 0.2065, validation loss: 0.0866
2024-05-23 20:27:31 [INFO]: Epoch 108 - generator training loss: -0.0815, discriminator training loss: 0.2064, validation loss: 0.0874
2024-05-23 20:27:34 [INFO]: Epoch 109 - generator training loss: -0.0819, discriminator training loss: 0.2063, validation loss: 0.0879
2024-05-23 20:27:37 [INFO]: Epoch 110 - generator training loss: -0.0817, discriminator training loss: 0.2054, validation loss: 0.0876
2024-05-23 20:27:41 [INFO]: Epoch 111 - generator training loss: -0.0821, discriminator training loss: 0.2055, validation loss: 0.0870
2024-05-23 20:27:44 [INFO]: Epoch 112 - generator training loss: -0.0828, discriminator training loss: 0.2057, validation loss: 0.0871
2024-05-23 20:27:47 [INFO]: Epoch 113 - generator training loss: -0.0840, discriminator training loss: 0.2058, validation loss: 0.0867
2024-05-23 20:27:51 [INFO]: Epoch 114 - generator training loss: -0.0834, discriminator training loss: 0.2051, validation loss: 0.0877
2024-05-23 20:27:54 [INFO]: Epoch 115 - generator training loss: -0.0837, discriminator training loss: 0.2045, validation loss: 0.0873
2024-05-23 20:27:58 [INFO]: Epoch 116 - generator training loss: -0.0831, discriminator training loss: 0.2049, validation loss: 0.0865
2024-05-23 20:28:01 [INFO]: Epoch 117 - generator training loss: -0.0843, discriminator training loss: 0.2047, validation loss: 0.0872
2024-05-23 20:28:04 [INFO]: Epoch 118 - generator training loss: -0.0837, discriminator training loss: 0.2045, validation loss: 0.0875
2024-05-23 20:28:08 [INFO]: Epoch 119 - generator training loss: -0.0842, discriminator training loss: 0.2045, validation loss: 0.0872
2024-05-23 20:28:11 [INFO]: Epoch 120 - generator training loss: -0.0834, discriminator training loss: 0.2044, validation loss: 0.0868
2024-05-23 20:28:14 [INFO]: Epoch 121 - generator training loss: -0.0842, discriminator training loss: 0.2048, validation loss: 0.0875
2024-05-23 20:28:18 [INFO]: Epoch 122 - generator training loss: -0.0851, discriminator training loss: 0.2041, validation loss: 0.0873
2024-05-23 20:28:21 [INFO]: Epoch 123 - generator training loss: -0.0845, discriminator training loss: 0.2040, validation loss: 0.0863
2024-05-23 20:28:24 [INFO]: Epoch 124 - generator training loss: -0.0845, discriminator training loss: 0.2035, validation loss: 0.0870
2024-05-23 20:28:28 [INFO]: Epoch 125 - generator training loss: -0.0839, discriminator training loss: 0.2040, validation loss: 0.0875
2024-05-23 20:28:31 [INFO]: Epoch 126 - generator training loss: -0.0840, discriminator training loss: 0.2039, validation loss: 0.0866
2024-05-23 20:28:34 [INFO]: Epoch 127 - generator training loss: -0.0846, discriminator training loss: 0.2036, validation loss: 0.0871
2024-05-23 20:28:38 [INFO]: Epoch 128 - generator training loss: -0.0849, discriminator training loss: 0.2036, validation loss: 0.0880
2024-05-23 20:28:41 [INFO]: Epoch 129 - generator training loss: -0.0840, discriminator training loss: 0.2039, validation loss: 0.0866
2024-05-23 20:28:44 [INFO]: Epoch 130 - generator training loss: -0.0850, discriminator training loss: 0.2034, validation loss: 0.0872
2024-05-23 20:28:48 [INFO]: Epoch 131 - generator training loss: -0.0836, discriminator training loss: 0.2027, validation loss: 0.0879
2024-05-23 20:28:51 [INFO]: Epoch 132 - generator training loss: -0.0849, discriminator training loss: 0.2033, validation loss: 0.0865
2024-05-23 20:28:54 [INFO]: Epoch 133 - generator training loss: -0.0849, discriminator training loss: 0.2031, validation loss: 0.0865
2024-05-23 20:28:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:28:54 [INFO]: Finished training. The best model is from epoch#123.
2024-05-23 20:28:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/USGAN_air_quality/20240523_T202129/USGAN.pypots
2024-05-23 20:28:55 [INFO]: US-GAN on Air-Quality: MAE=0.1512, MSE=0.1496
2024-05-23 20:28:55 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-23 20:28:55 [INFO]: Using the given device: cuda:0
2024-05-23 20:28:55 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240523_T202855
2024-05-23 20:28:55 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/BRITS_air_quality/20240523_T202855/tensorboard
2024-05-23 20:28:55 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 20:28:58 [INFO]: Epoch 001 - training loss: 1.4094, validation loss: 0.9006
2024-05-23 20:29:00 [INFO]: Epoch 002 - training loss: 1.1389, validation loss: 0.6500
2024-05-23 20:29:02 [INFO]: Epoch 003 - training loss: 0.9487, validation loss: 0.5454
2024-05-23 20:29:04 [INFO]: Epoch 004 - training loss: 0.8395, validation loss: 0.4827
2024-05-23 20:29:07 [INFO]: Epoch 005 - training loss: 0.7667, validation loss: 0.4407
2024-05-23 20:29:09 [INFO]: Epoch 006 - training loss: 0.7114, validation loss: 0.4048
2024-05-23 20:29:11 [INFO]: Epoch 007 - training loss: 0.6682, validation loss: 0.3787
2024-05-23 20:29:13 [INFO]: Epoch 008 - training loss: 0.6353, validation loss: 0.3558
2024-05-23 20:29:16 [INFO]: Epoch 009 - training loss: 0.6086, validation loss: 0.3364
2024-05-23 20:29:18 [INFO]: Epoch 010 - training loss: 0.5891, validation loss: 0.3213
2024-05-23 20:29:20 [INFO]: Epoch 011 - training loss: 0.5714, validation loss: 0.3068
2024-05-23 20:29:22 [INFO]: Epoch 012 - training loss: 0.5554, validation loss: 0.2963
2024-05-23 20:29:25 [INFO]: Epoch 013 - training loss: 0.5412, validation loss: 0.2857
2024-05-23 20:29:27 [INFO]: Epoch 014 - training loss: 0.5312, validation loss: 0.2773
2024-05-23 20:29:29 [INFO]: Epoch 015 - training loss: 0.5194, validation loss: 0.2696
2024-05-23 20:29:31 [INFO]: Epoch 016 - training loss: 0.5103, validation loss: 0.2623
2024-05-23 20:29:34 [INFO]: Epoch 017 - training loss: 0.5008, validation loss: 0.2561
2024-05-23 20:29:36 [INFO]: Epoch 018 - training loss: 0.4916, validation loss: 0.2501
2024-05-23 20:29:38 [INFO]: Epoch 019 - training loss: 0.4845, validation loss: 0.2453
2024-05-23 20:29:40 [INFO]: Epoch 020 - training loss: 0.4785, validation loss: 0.2407
2024-05-23 20:29:43 [INFO]: Epoch 021 - training loss: 0.4692, validation loss: 0.2356
2024-05-23 20:29:45 [INFO]: Epoch 022 - training loss: 0.4619, validation loss: 0.2313
2024-05-23 20:29:47 [INFO]: Epoch 023 - training loss: 0.4571, validation loss: 0.2273
2024-05-23 20:29:49 [INFO]: Epoch 024 - training loss: 0.4498, validation loss: 0.2232
2024-05-23 20:29:52 [INFO]: Epoch 025 - training loss: 0.4442, validation loss: 0.2200
2024-05-23 20:29:54 [INFO]: Epoch 026 - training loss: 0.4386, validation loss: 0.2162
2024-05-23 20:29:56 [INFO]: Epoch 027 - training loss: 0.4331, validation loss: 0.2134
2024-05-23 20:29:58 [INFO]: Epoch 028 - training loss: 0.4285, validation loss: 0.2096
2024-05-23 20:30:01 [INFO]: Epoch 029 - training loss: 0.4242, validation loss: 0.2066
2024-05-23 20:30:03 [INFO]: Epoch 030 - training loss: 0.4188, validation loss: 0.2037
2024-05-23 20:30:05 [INFO]: Epoch 031 - training loss: 0.4139, validation loss: 0.2003
2024-05-23 20:30:08 [INFO]: Epoch 032 - training loss: 0.4096, validation loss: 0.1977
2024-05-23 20:30:10 [INFO]: Epoch 033 - training loss: 0.4063, validation loss: 0.1949
2024-05-23 20:30:12 [INFO]: Epoch 034 - training loss: 0.4028, validation loss: 0.1921
2024-05-23 20:30:14 [INFO]: Epoch 035 - training loss: 0.3978, validation loss: 0.1894
2024-05-23 20:30:16 [INFO]: Epoch 036 - training loss: 0.3941, validation loss: 0.1870
2024-05-23 20:30:19 [INFO]: Epoch 037 - training loss: 0.3903, validation loss: 0.1844
2024-05-23 20:30:21 [INFO]: Epoch 038 - training loss: 0.3867, validation loss: 0.1819
2024-05-23 20:30:23 [INFO]: Epoch 039 - training loss: 0.3835, validation loss: 0.1792
2024-05-23 20:30:26 [INFO]: Epoch 040 - training loss: 0.3802, validation loss: 0.1770
2024-05-23 20:30:28 [INFO]: Epoch 041 - training loss: 0.3788, validation loss: 0.1754
2024-05-23 20:30:30 [INFO]: Epoch 042 - training loss: 0.3741, validation loss: 0.1727
2024-05-23 20:30:32 [INFO]: Epoch 043 - training loss: 0.3714, validation loss: 0.1704
2024-05-23 20:30:35 [INFO]: Epoch 044 - training loss: 0.3683, validation loss: 0.1688
2024-05-23 20:30:37 [INFO]: Epoch 045 - training loss: 0.3661, validation loss: 0.1666
2024-05-23 20:30:39 [INFO]: Epoch 046 - training loss: 0.3627, validation loss: 0.1649
2024-05-23 20:30:41 [INFO]: Epoch 047 - training loss: 0.3606, validation loss: 0.1632
2024-05-23 20:30:44 [INFO]: Epoch 048 - training loss: 0.3584, validation loss: 0.1615
2024-05-23 20:30:46 [INFO]: Epoch 049 - training loss: 0.3562, validation loss: 0.1601
2024-05-23 20:30:48 [INFO]: Epoch 050 - training loss: 0.3529, validation loss: 0.1582
2024-05-23 20:30:50 [INFO]: Epoch 051 - training loss: 0.3511, validation loss: 0.1571
2024-05-23 20:30:53 [INFO]: Epoch 052 - training loss: 0.3484, validation loss: 0.1555
2024-05-23 20:30:55 [INFO]: Epoch 053 - training loss: 0.3470, validation loss: 0.1541
2024-05-23 20:30:57 [INFO]: Epoch 054 - training loss: 0.3446, validation loss: 0.1531
2024-05-23 20:30:59 [INFO]: Epoch 055 - training loss: 0.3438, validation loss: 0.1522
2024-05-23 20:31:02 [INFO]: Epoch 056 - training loss: 0.3402, validation loss: 0.1508
2024-05-23 20:31:04 [INFO]: Epoch 057 - training loss: 0.3396, validation loss: 0.1498
2024-05-23 20:31:06 [INFO]: Epoch 058 - training loss: 0.3367, validation loss: 0.1488
2024-05-23 20:31:08 [INFO]: Epoch 059 - training loss: 0.3354, validation loss: 0.1481
2024-05-23 20:31:11 [INFO]: Epoch 060 - training loss: 0.3337, validation loss: 0.1468
2024-05-23 20:31:13 [INFO]: Epoch 061 - training loss: 0.3319, validation loss: 0.1461
2024-05-23 20:31:15 [INFO]: Epoch 062 - training loss: 0.3303, validation loss: 0.1451
2024-05-23 20:31:17 [INFO]: Epoch 063 - training loss: 0.3287, validation loss: 0.1443
2024-05-23 20:31:20 [INFO]: Epoch 064 - training loss: 0.3274, validation loss: 0.1436
2024-05-23 20:31:22 [INFO]: Epoch 065 - training loss: 0.3259, validation loss: 0.1428
2024-05-23 20:31:24 [INFO]: Epoch 066 - training loss: 0.3248, validation loss: 0.1422
2024-05-23 20:31:26 [INFO]: Epoch 067 - training loss: 0.3231, validation loss: 0.1414
2024-05-23 20:31:29 [INFO]: Epoch 068 - training loss: 0.3213, validation loss: 0.1407
2024-05-23 20:31:31 [INFO]: Epoch 069 - training loss: 0.3206, validation loss: 0.1400
2024-05-23 20:31:33 [INFO]: Epoch 070 - training loss: 0.3196, validation loss: 0.1394
2024-05-23 20:31:35 [INFO]: Epoch 071 - training loss: 0.3180, validation loss: 0.1390
2024-05-23 20:31:38 [INFO]: Epoch 072 - training loss: 0.3173, validation loss: 0.1383
2024-05-23 20:31:40 [INFO]: Epoch 073 - training loss: 0.3161, validation loss: 0.1377
2024-05-23 20:31:42 [INFO]: Epoch 074 - training loss: 0.3149, validation loss: 0.1370
2024-05-23 20:31:44 [INFO]: Epoch 075 - training loss: 0.3135, validation loss: 0.1365
2024-05-23 20:31:47 [INFO]: Epoch 076 - training loss: 0.3129, validation loss: 0.1360
2024-05-23 20:31:49 [INFO]: Epoch 077 - training loss: 0.3114, validation loss: 0.1355
2024-05-23 20:31:51 [INFO]: Epoch 078 - training loss: 0.3105, validation loss: 0.1350
2024-05-23 20:31:53 [INFO]: Epoch 079 - training loss: 0.3098, validation loss: 0.1344
2024-05-23 20:31:56 [INFO]: Epoch 080 - training loss: 0.3086, validation loss: 0.1339
2024-05-23 20:31:58 [INFO]: Epoch 081 - training loss: 0.3073, validation loss: 0.1334
2024-05-23 20:32:00 [INFO]: Epoch 082 - training loss: 0.3062, validation loss: 0.1329
2024-05-23 20:32:02 [INFO]: Epoch 083 - training loss: 0.3060, validation loss: 0.1324
2024-05-23 20:32:05 [INFO]: Epoch 084 - training loss: 0.3048, validation loss: 0.1319
2024-05-23 20:32:07 [INFO]: Epoch 085 - training loss: 0.3037, validation loss: 0.1316
2024-05-23 20:32:09 [INFO]: Epoch 086 - training loss: 0.3034, validation loss: 0.1312
2024-05-23 20:32:11 [INFO]: Epoch 087 - training loss: 0.3023, validation loss: 0.1309
2024-05-23 20:32:14 [INFO]: Epoch 088 - training loss: 0.3019, validation loss: 0.1304
2024-05-23 20:32:16 [INFO]: Epoch 089 - training loss: 0.3010, validation loss: 0.1299
2024-05-23 20:32:18 [INFO]: Epoch 090 - training loss: 0.3002, validation loss: 0.1296
2024-05-23 20:32:20 [INFO]: Epoch 091 - training loss: 0.2996, validation loss: 0.1290
2024-05-23 20:32:23 [INFO]: Epoch 092 - training loss: 0.2988, validation loss: 0.1286
2024-05-23 20:32:25 [INFO]: Epoch 093 - training loss: 0.2983, validation loss: 0.1283
2024-05-23 20:32:27 [INFO]: Epoch 094 - training loss: 0.2971, validation loss: 0.1279
2024-05-23 20:32:29 [INFO]: Epoch 095 - training loss: 0.2964, validation loss: 0.1276
2024-05-23 20:32:32 [INFO]: Epoch 096 - training loss: 0.2961, validation loss: 0.1271
2024-05-23 20:32:34 [INFO]: Epoch 097 - training loss: 0.2957, validation loss: 0.1269
2024-05-23 20:32:36 [INFO]: Epoch 098 - training loss: 0.2951, validation loss: 0.1265
2024-05-23 20:32:38 [INFO]: Epoch 099 - training loss: 0.2940, validation loss: 0.1261
2024-05-23 20:32:41 [INFO]: Epoch 100 - training loss: 0.2936, validation loss: 0.1259
2024-05-23 20:32:43 [INFO]: Epoch 101 - training loss: 0.2926, validation loss: 0.1255
2024-05-23 20:32:45 [INFO]: Epoch 102 - training loss: 0.2914, validation loss: 0.1250
2024-05-23 20:32:47 [INFO]: Epoch 103 - training loss: 0.2912, validation loss: 0.1249
2024-05-23 20:32:50 [INFO]: Epoch 104 - training loss: 0.2915, validation loss: 0.1244
2024-05-23 20:32:52 [INFO]: Epoch 105 - training loss: 0.2901, validation loss: 0.1240
2024-05-23 20:32:54 [INFO]: Epoch 106 - training loss: 0.2895, validation loss: 0.1235
2024-05-23 20:32:56 [INFO]: Epoch 107 - training loss: 0.2891, validation loss: 0.1235
2024-05-23 20:32:59 [INFO]: Epoch 108 - training loss: 0.2884, validation loss: 0.1229
2024-05-23 20:33:01 [INFO]: Epoch 109 - training loss: 0.2880, validation loss: 0.1225
2024-05-23 20:33:03 [INFO]: Epoch 110 - training loss: 0.2889, validation loss: 0.1222
2024-05-23 20:33:05 [INFO]: Epoch 111 - training loss: 0.2870, validation loss: 0.1221
2024-05-23 20:33:08 [INFO]: Epoch 112 - training loss: 0.2867, validation loss: 0.1219
2024-05-23 20:33:10 [INFO]: Epoch 113 - training loss: 0.2859, validation loss: 0.1216
2024-05-23 20:33:12 [INFO]: Epoch 114 - training loss: 0.2848, validation loss: 0.1211
2024-05-23 20:33:14 [INFO]: Epoch 115 - training loss: 0.2851, validation loss: 0.1206
2024-05-23 20:33:17 [INFO]: Epoch 116 - training loss: 0.2842, validation loss: 0.1205
2024-05-23 20:33:19 [INFO]: Epoch 117 - training loss: 0.2841, validation loss: 0.1200
2024-05-23 20:33:21 [INFO]: Epoch 118 - training loss: 0.2832, validation loss: 0.1197
2024-05-23 20:33:23 [INFO]: Epoch 119 - training loss: 0.2826, validation loss: 0.1196
2024-05-23 20:33:26 [INFO]: Epoch 120 - training loss: 0.2819, validation loss: 0.1193
2024-05-23 20:33:28 [INFO]: Epoch 121 - training loss: 0.2816, validation loss: 0.1189
2024-05-23 20:33:30 [INFO]: Epoch 122 - training loss: 0.2814, validation loss: 0.1186
2024-05-23 20:33:32 [INFO]: Epoch 123 - training loss: 0.2807, validation loss: 0.1183
2024-05-23 20:33:35 [INFO]: Epoch 124 - training loss: 0.2801, validation loss: 0.1180
2024-05-23 20:33:37 [INFO]: Epoch 125 - training loss: 0.2792, validation loss: 0.1177
2024-05-23 20:33:39 [INFO]: Epoch 126 - training loss: 0.2789, validation loss: 0.1176
2024-05-23 20:33:41 [INFO]: Epoch 127 - training loss: 0.2793, validation loss: 0.1171
2024-05-23 20:33:44 [INFO]: Epoch 128 - training loss: 0.2797, validation loss: 0.1167
2024-05-23 20:33:46 [INFO]: Epoch 129 - training loss: 0.2785, validation loss: 0.1167
2024-05-23 20:33:48 [INFO]: Epoch 130 - training loss: 0.2775, validation loss: 0.1162
2024-05-23 20:33:50 [INFO]: Epoch 131 - training loss: 0.2774, validation loss: 0.1160
2024-05-23 20:33:53 [INFO]: Epoch 132 - training loss: 0.2773, validation loss: 0.1157
2024-05-23 20:33:55 [INFO]: Epoch 133 - training loss: 0.2758, validation loss: 0.1155
2024-05-23 20:33:57 [INFO]: Epoch 134 - training loss: 0.2758, validation loss: 0.1152
2024-05-23 20:34:00 [INFO]: Epoch 135 - training loss: 0.2762, validation loss: 0.1148
2024-05-23 20:34:02 [INFO]: Epoch 136 - training loss: 0.2758, validation loss: 0.1146
2024-05-23 20:34:04 [INFO]: Epoch 137 - training loss: 0.2746, validation loss: 0.1143
2024-05-23 20:34:06 [INFO]: Epoch 138 - training loss: 0.2747, validation loss: 0.1142
2024-05-23 20:34:08 [INFO]: Epoch 139 - training loss: 0.2742, validation loss: 0.1138
2024-05-23 20:34:11 [INFO]: Epoch 140 - training loss: 0.2737, validation loss: 0.1136
2024-05-23 20:34:13 [INFO]: Epoch 141 - training loss: 0.2734, validation loss: 0.1134
2024-05-23 20:34:15 [INFO]: Epoch 142 - training loss: 0.2732, validation loss: 0.1131
2024-05-23 20:34:18 [INFO]: Epoch 143 - training loss: 0.2725, validation loss: 0.1129
2024-05-23 20:34:20 [INFO]: Epoch 144 - training loss: 0.2722, validation loss: 0.1127
2024-05-23 20:34:22 [INFO]: Epoch 145 - training loss: 0.2717, validation loss: 0.1124
2024-05-23 20:34:24 [INFO]: Epoch 146 - training loss: 0.2712, validation loss: 0.1121
2024-05-23 20:34:27 [INFO]: Epoch 147 - training loss: 0.2706, validation loss: 0.1119
2024-05-23 20:34:29 [INFO]: Epoch 148 - training loss: 0.2703, validation loss: 0.1118
2024-05-23 20:34:31 [INFO]: Epoch 149 - training loss: 0.2705, validation loss: 0.1114
2024-05-23 20:34:33 [INFO]: Epoch 150 - training loss: 0.2700, validation loss: 0.1112
2024-05-23 20:34:36 [INFO]: Epoch 151 - training loss: 0.2691, validation loss: 0.1109
2024-05-23 20:34:38 [INFO]: Epoch 152 - training loss: 0.2692, validation loss: 0.1108
2024-05-23 20:34:40 [INFO]: Epoch 153 - training loss: 0.2687, validation loss: 0.1105
2024-05-23 20:34:42 [INFO]: Epoch 154 - training loss: 0.2690, validation loss: 0.1103
2024-05-23 20:34:45 [INFO]: Epoch 155 - training loss: 0.2681, validation loss: 0.1101
2024-05-23 20:34:47 [INFO]: Epoch 156 - training loss: 0.2687, validation loss: 0.1100
2024-05-23 20:34:49 [INFO]: Epoch 157 - training loss: 0.2680, validation loss: 0.1097
2024-05-23 20:34:51 [INFO]: Epoch 158 - training loss: 0.2674, validation loss: 0.1093
2024-05-23 20:34:54 [INFO]: Epoch 159 - training loss: 0.2671, validation loss: 0.1092
2024-05-23 20:34:56 [INFO]: Epoch 160 - training loss: 0.2669, validation loss: 0.1089
2024-05-23 20:34:58 [INFO]: Epoch 161 - training loss: 0.2670, validation loss: 0.1089
2024-05-23 20:35:00 [INFO]: Epoch 162 - training loss: 0.2660, validation loss: 0.1086
2024-05-23 20:35:03 [INFO]: Epoch 163 - training loss: 0.2658, validation loss: 0.1084
2024-05-23 20:35:05 [INFO]: Epoch 164 - training loss: 0.2654, validation loss: 0.1081
2024-05-23 20:35:07 [INFO]: Epoch 165 - training loss: 0.2653, validation loss: 0.1081
2024-05-23 20:35:09 [INFO]: Epoch 166 - training loss: 0.2650, validation loss: 0.1078
2024-05-23 20:35:12 [INFO]: Epoch 167 - training loss: 0.2647, validation loss: 0.1077
2024-05-23 20:35:14 [INFO]: Epoch 168 - training loss: 0.2642, validation loss: 0.1075
2024-05-23 20:35:16 [INFO]: Epoch 169 - training loss: 0.2646, validation loss: 0.1071
2024-05-23 20:35:18 [INFO]: Epoch 170 - training loss: 0.2639, validation loss: 0.1070
2024-05-23 20:35:21 [INFO]: Epoch 171 - training loss: 0.2634, validation loss: 0.1067
2024-05-23 20:35:23 [INFO]: Epoch 172 - training loss: 0.2634, validation loss: 0.1066
2024-05-23 20:35:25 [INFO]: Epoch 173 - training loss: 0.2630, validation loss: 0.1064
2024-05-23 20:35:27 [INFO]: Epoch 174 - training loss: 0.2629, validation loss: 0.1061
2024-05-23 20:35:30 [INFO]: Epoch 175 - training loss: 0.2626, validation loss: 0.1062
2024-05-23 20:35:32 [INFO]: Epoch 176 - training loss: 0.2628, validation loss: 0.1059
2024-05-23 20:35:34 [INFO]: Epoch 177 - training loss: 0.2624, validation loss: 0.1059
2024-05-23 20:35:36 [INFO]: Epoch 178 - training loss: 0.2615, validation loss: 0.1056
2024-05-23 20:35:39 [INFO]: Epoch 179 - training loss: 0.2613, validation loss: 0.1056
2024-05-23 20:35:41 [INFO]: Epoch 180 - training loss: 0.2611, validation loss: 0.1052
2024-05-23 20:35:43 [INFO]: Epoch 181 - training loss: 0.2612, validation loss: 0.1050
2024-05-23 20:35:45 [INFO]: Epoch 182 - training loss: 0.2606, validation loss: 0.1050
2024-05-23 20:35:48 [INFO]: Epoch 183 - training loss: 0.2608, validation loss: 0.1047
2024-05-23 20:35:50 [INFO]: Epoch 184 - training loss: 0.2602, validation loss: 0.1048
2024-05-23 20:35:52 [INFO]: Epoch 185 - training loss: 0.2602, validation loss: 0.1046
2024-05-23 20:35:54 [INFO]: Epoch 186 - training loss: 0.2602, validation loss: 0.1042
2024-05-23 20:35:57 [INFO]: Epoch 187 - training loss: 0.2594, validation loss: 0.1041
2024-05-23 20:35:59 [INFO]: Epoch 188 - training loss: 0.2591, validation loss: 0.1040
2024-05-23 20:36:01 [INFO]: Epoch 189 - training loss: 0.2589, validation loss: 0.1038
2024-05-23 20:36:03 [INFO]: Epoch 190 - training loss: 0.2594, validation loss: 0.1036
2024-05-23 20:36:06 [INFO]: Epoch 191 - training loss: 0.2587, validation loss: 0.1035
2024-05-23 20:36:08 [INFO]: Epoch 192 - training loss: 0.2584, validation loss: 0.1034
2024-05-23 20:36:10 [INFO]: Epoch 193 - training loss: 0.2582, validation loss: 0.1032
2024-05-23 20:36:13 [INFO]: Epoch 194 - training loss: 0.2578, validation loss: 0.1031
2024-05-23 20:36:15 [INFO]: Epoch 195 - training loss: 0.2575, validation loss: 0.1030
2024-05-23 20:36:17 [INFO]: Epoch 196 - training loss: 0.2574, validation loss: 0.1028
2024-05-23 20:36:19 [INFO]: Epoch 197 - training loss: 0.2573, validation loss: 0.1028
2024-05-23 20:36:22 [INFO]: Epoch 198 - training loss: 0.2568, validation loss: 0.1025
2024-05-23 20:36:24 [INFO]: Epoch 199 - training loss: 0.2565, validation loss: 0.1025
2024-05-23 20:36:26 [INFO]: Epoch 200 - training loss: 0.2563, validation loss: 0.1023
2024-05-23 20:36:28 [INFO]: Epoch 201 - training loss: 0.2561, validation loss: 0.1021
2024-05-23 20:36:31 [INFO]: Epoch 202 - training loss: 0.2558, validation loss: 0.1022
2024-05-23 20:36:33 [INFO]: Epoch 203 - training loss: 0.2556, validation loss: 0.1020
2024-05-23 20:36:35 [INFO]: Epoch 204 - training loss: 0.2554, validation loss: 0.1019
2024-05-23 20:36:37 [INFO]: Epoch 205 - training loss: 0.2557, validation loss: 0.1017
2024-05-23 20:36:40 [INFO]: Epoch 206 - training loss: 0.2555, validation loss: 0.1015
2024-05-23 20:36:42 [INFO]: Epoch 207 - training loss: 0.2551, validation loss: 0.1015
2024-05-23 20:36:44 [INFO]: Epoch 208 - training loss: 0.2549, validation loss: 0.1013
2024-05-23 20:36:46 [INFO]: Epoch 209 - training loss: 0.2546, validation loss: 0.1012
2024-05-23 20:36:49 [INFO]: Epoch 210 - training loss: 0.2548, validation loss: 0.1009
2024-05-23 20:36:51 [INFO]: Epoch 211 - training loss: 0.2543, validation loss: 0.1009
2024-05-23 20:36:53 [INFO]: Epoch 212 - training loss: 0.2543, validation loss: 0.1008
2024-05-23 20:36:55 [INFO]: Epoch 213 - training loss: 0.2541, validation loss: 0.1007
2024-05-23 20:36:58 [INFO]: Epoch 214 - training loss: 0.2536, validation loss: 0.1007
2024-05-23 20:37:00 [INFO]: Epoch 215 - training loss: 0.2536, validation loss: 0.1004
2024-05-23 20:37:02 [INFO]: Epoch 216 - training loss: 0.2535, validation loss: 0.1004
2024-05-23 20:37:04 [INFO]: Epoch 217 - training loss: 0.2534, validation loss: 0.1002
2024-05-23 20:37:07 [INFO]: Epoch 218 - training loss: 0.2525, validation loss: 0.1000
2024-05-23 20:37:09 [INFO]: Epoch 219 - training loss: 0.2525, validation loss: 0.1003
2024-05-23 20:37:11 [INFO]: Epoch 220 - training loss: 0.2529, validation loss: 0.0999
2024-05-23 20:37:13 [INFO]: Epoch 221 - training loss: 0.2522, validation loss: 0.0999
2024-05-23 20:37:16 [INFO]: Epoch 222 - training loss: 0.2522, validation loss: 0.0998
2024-05-23 20:37:18 [INFO]: Epoch 223 - training loss: 0.2520, validation loss: 0.0996
2024-05-23 20:37:20 [INFO]: Epoch 224 - training loss: 0.2523, validation loss: 0.0993
2024-05-23 20:37:22 [INFO]: Epoch 225 - training loss: 0.2517, validation loss: 0.0995
2024-05-23 20:37:25 [INFO]: Epoch 226 - training loss: 0.2513, validation loss: 0.0991
2024-05-23 20:37:27 [INFO]: Epoch 227 - training loss: 0.2511, validation loss: 0.0992
2024-05-23 20:37:29 [INFO]: Epoch 228 - training loss: 0.2510, validation loss: 0.0993
2024-05-23 20:37:31 [INFO]: Epoch 229 - training loss: 0.2504, validation loss: 0.0990
2024-05-23 20:37:34 [INFO]: Epoch 230 - training loss: 0.2505, validation loss: 0.0991
2024-05-23 20:37:36 [INFO]: Epoch 231 - training loss: 0.2503, validation loss: 0.0989
2024-05-23 20:37:38 [INFO]: Epoch 232 - training loss: 0.2501, validation loss: 0.0987
2024-05-23 20:37:40 [INFO]: Epoch 233 - training loss: 0.2506, validation loss: 0.0987
2024-05-23 20:37:43 [INFO]: Epoch 234 - training loss: 0.2498, validation loss: 0.0986
2024-05-23 20:37:45 [INFO]: Epoch 235 - training loss: 0.2501, validation loss: 0.0986
2024-05-23 20:37:47 [INFO]: Epoch 236 - training loss: 0.2499, validation loss: 0.0984
2024-05-23 20:37:49 [INFO]: Epoch 237 - training loss: 0.2495, validation loss: 0.0981
2024-05-23 20:37:52 [INFO]: Epoch 238 - training loss: 0.2493, validation loss: 0.0984
2024-05-23 20:37:54 [INFO]: Epoch 239 - training loss: 0.2496, validation loss: 0.0982
2024-05-23 20:37:56 [INFO]: Epoch 240 - training loss: 0.2488, validation loss: 0.0981
2024-05-23 20:37:58 [INFO]: Epoch 241 - training loss: 0.2489, validation loss: 0.0980
2024-05-23 20:38:01 [INFO]: Epoch 242 - training loss: 0.2488, validation loss: 0.0979
2024-05-23 20:38:03 [INFO]: Epoch 243 - training loss: 0.2491, validation loss: 0.0979
2024-05-23 20:38:05 [INFO]: Epoch 244 - training loss: 0.2480, validation loss: 0.0979
2024-05-23 20:38:07 [INFO]: Epoch 245 - training loss: 0.2484, validation loss: 0.0977
2024-05-23 20:38:10 [INFO]: Epoch 246 - training loss: 0.2481, validation loss: 0.0977
2024-05-23 20:38:12 [INFO]: Epoch 247 - training loss: 0.2476, validation loss: 0.0976
2024-05-23 20:38:14 [INFO]: Epoch 248 - training loss: 0.2476, validation loss: 0.0976
2024-05-23 20:38:16 [INFO]: Epoch 249 - training loss: 0.2474, validation loss: 0.0974
2024-05-23 20:38:19 [INFO]: Epoch 250 - training loss: 0.2475, validation loss: 0.0973
2024-05-23 20:38:21 [INFO]: Epoch 251 - training loss: 0.2478, validation loss: 0.0973
2024-05-23 20:38:23 [INFO]: Epoch 252 - training loss: 0.2473, validation loss: 0.0973
2024-05-23 20:38:25 [INFO]: Epoch 253 - training loss: 0.2465, validation loss: 0.0973
2024-05-23 20:38:28 [INFO]: Epoch 254 - training loss: 0.2471, validation loss: 0.0972
2024-05-23 20:38:30 [INFO]: Epoch 255 - training loss: 0.2466, validation loss: 0.0969
2024-05-23 20:38:32 [INFO]: Epoch 256 - training loss: 0.2471, validation loss: 0.0969
2024-05-23 20:38:34 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0968
2024-05-23 20:38:37 [INFO]: Epoch 258 - training loss: 0.2462, validation loss: 0.0969
2024-05-23 20:38:39 [INFO]: Epoch 259 - training loss: 0.2460, validation loss: 0.0968
2024-05-23 20:38:41 [INFO]: Epoch 260 - training loss: 0.2460, validation loss: 0.0968
2024-05-23 20:38:43 [INFO]: Epoch 261 - training loss: 0.2459, validation loss: 0.0967
2024-05-23 20:38:46 [INFO]: Epoch 262 - training loss: 0.2456, validation loss: 0.0966
2024-05-23 20:38:48 [INFO]: Epoch 263 - training loss: 0.2457, validation loss: 0.0966
2024-05-23 20:38:50 [INFO]: Epoch 264 - training loss: 0.2454, validation loss: 0.0962
2024-05-23 20:38:52 [INFO]: Epoch 265 - training loss: 0.2453, validation loss: 0.0965
2024-05-23 20:38:55 [INFO]: Epoch 266 - training loss: 0.2448, validation loss: 0.0964
2024-05-23 20:38:57 [INFO]: Epoch 267 - training loss: 0.2455, validation loss: 0.0963
2024-05-23 20:38:59 [INFO]: Epoch 268 - training loss: 0.2445, validation loss: 0.0962
2024-05-23 20:39:01 [INFO]: Epoch 269 - training loss: 0.2449, validation loss: 0.0961
2024-05-23 20:39:04 [INFO]: Epoch 270 - training loss: 0.2442, validation loss: 0.0962
2024-05-23 20:39:06 [INFO]: Epoch 271 - training loss: 0.2446, validation loss: 0.0961
2024-05-23 20:39:08 [INFO]: Epoch 272 - training loss: 0.2443, validation loss: 0.0962
2024-05-23 20:39:10 [INFO]: Epoch 273 - training loss: 0.2440, validation loss: 0.0961
2024-05-23 20:39:13 [INFO]: Epoch 274 - training loss: 0.2439, validation loss: 0.0960
2024-05-23 20:39:15 [INFO]: Epoch 275 - training loss: 0.2438, validation loss: 0.0960
2024-05-23 20:39:17 [INFO]: Epoch 276 - training loss: 0.2433, validation loss: 0.0958
2024-05-23 20:39:20 [INFO]: Epoch 277 - training loss: 0.2435, validation loss: 0.0957
2024-05-23 20:39:22 [INFO]: Epoch 278 - training loss: 0.2431, validation loss: 0.0958
2024-05-23 20:39:24 [INFO]: Epoch 279 - training loss: 0.2429, validation loss: 0.0961
2024-05-23 20:39:26 [INFO]: Epoch 280 - training loss: 0.2430, validation loss: 0.0958
2024-05-23 20:39:28 [INFO]: Epoch 281 - training loss: 0.2431, validation loss: 0.0957
2024-05-23 20:39:31 [INFO]: Epoch 282 - training loss: 0.2427, validation loss: 0.0956
2024-05-23 20:39:33 [INFO]: Epoch 283 - training loss: 0.2434, validation loss: 0.0955
2024-05-23 20:39:35 [INFO]: Epoch 284 - training loss: 0.2426, validation loss: 0.0955
2024-05-23 20:39:37 [INFO]: Epoch 285 - training loss: 0.2423, validation loss: 0.0953
2024-05-23 20:39:40 [INFO]: Epoch 286 - training loss: 0.2424, validation loss: 0.0954
2024-05-23 20:39:42 [INFO]: Epoch 287 - training loss: 0.2422, validation loss: 0.0954
2024-05-23 20:39:44 [INFO]: Epoch 288 - training loss: 0.2422, validation loss: 0.0954
2024-05-23 20:39:46 [INFO]: Epoch 289 - training loss: 0.2419, validation loss: 0.0953
2024-05-23 20:39:49 [INFO]: Epoch 290 - training loss: 0.2418, validation loss: 0.0954
2024-05-23 20:39:51 [INFO]: Epoch 291 - training loss: 0.2420, validation loss: 0.0952
2024-05-23 20:39:53 [INFO]: Epoch 292 - training loss: 0.2418, validation loss: 0.0953
2024-05-23 20:39:56 [INFO]: Epoch 293 - training loss: 0.2413, validation loss: 0.0952
2024-05-23 20:39:58 [INFO]: Epoch 294 - training loss: 0.2413, validation loss: 0.0952
2024-05-23 20:40:00 [INFO]: Epoch 295 - training loss: 0.2417, validation loss: 0.0951
2024-05-23 20:40:02 [INFO]: Epoch 296 - training loss: 0.2415, validation loss: 0.0952
2024-05-23 20:40:05 [INFO]: Epoch 297 - training loss: 0.2413, validation loss: 0.0953
2024-05-23 20:40:07 [INFO]: Epoch 298 - training loss: 0.2407, validation loss: 0.0949
2024-05-23 20:40:09 [INFO]: Epoch 299 - training loss: 0.2408, validation loss: 0.0951
2024-05-23 20:40:11 [INFO]: Epoch 300 - training loss: 0.2408, validation loss: 0.0950
2024-05-23 20:40:11 [INFO]: Finished training. The best model is from epoch#298.
2024-05-23 20:40:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/BRITS_air_quality/20240523_T202855/BRITS.pypots
2024-05-23 20:40:12 [INFO]: BRITS on Air-Quality: MAE=0.1435, MSE=0.1645
2024-05-23 20:40:12 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-23 20:40:12 [INFO]: Using the given device: cuda:0
2024-05-23 20:40:12 [INFO]: Model files will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012
2024-05-23 20:40:12 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/tensorboard
2024-05-23 20:40:12 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 20:40:15 [INFO]: Epoch 001 - training loss: 1.4243, validation loss: 0.7844
2024-05-23 20:40:15 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch1_loss0.784442064166069.pypots
2024-05-23 20:40:19 [INFO]: Epoch 002 - training loss: 1.0442, validation loss: 0.7297
2024-05-23 20:40:19 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch2_loss0.7296506434679031.pypots
2024-05-23 20:40:22 [INFO]: Epoch 003 - training loss: 0.9668, validation loss: 0.6997
2024-05-23 20:40:22 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch3_loss0.6996659725904465.pypots
2024-05-23 20:40:25 [INFO]: Epoch 004 - training loss: 0.9333, validation loss: 0.6855
2024-05-23 20:40:25 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch4_loss0.6855376899242401.pypots
2024-05-23 20:40:28 [INFO]: Epoch 005 - training loss: 0.9348, validation loss: 0.6769
2024-05-23 20:40:28 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch5_loss0.6768584281206131.pypots
2024-05-23 20:40:31 [INFO]: Epoch 006 - training loss: 0.9037, validation loss: 0.6697
2024-05-23 20:40:31 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch6_loss0.6696916729211807.pypots
2024-05-23 20:40:34 [INFO]: Epoch 007 - training loss: 0.9003, validation loss: 0.6646
2024-05-23 20:40:34 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch7_loss0.6646160989999771.pypots
2024-05-23 20:40:37 [INFO]: Epoch 008 - training loss: 0.9018, validation loss: 0.6607
2024-05-23 20:40:37 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch8_loss0.6607407778501511.pypots
2024-05-23 20:40:40 [INFO]: Epoch 009 - training loss: 0.9030, validation loss: 0.6572
2024-05-23 20:40:40 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch9_loss0.6571748942136765.pypots
2024-05-23 20:40:43 [INFO]: Epoch 010 - training loss: 0.8985, validation loss: 0.6547
2024-05-23 20:40:43 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch10_loss0.654715821146965.pypots
2024-05-23 20:40:46 [INFO]: Epoch 011 - training loss: 0.8912, validation loss: 0.6527
2024-05-23 20:40:46 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch11_loss0.6526634931564331.pypots
2024-05-23 20:40:49 [INFO]: Epoch 012 - training loss: 0.8617, validation loss: 0.6502
2024-05-23 20:40:49 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch12_loss0.650208443403244.pypots
2024-05-23 20:40:53 [INFO]: Epoch 013 - training loss: 0.8716, validation loss: 0.6505
2024-05-23 20:40:53 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch13_loss0.6505185902118683.pypots
2024-05-23 20:40:56 [INFO]: Epoch 014 - training loss: 0.8908, validation loss: 0.6483
2024-05-23 20:40:56 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch14_loss0.6482929497957229.pypots
2024-05-23 20:40:59 [INFO]: Epoch 015 - training loss: 0.8718, validation loss: 0.6471
2024-05-23 20:40:59 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch15_loss0.6471210211515427.pypots
2024-05-23 20:41:02 [INFO]: Epoch 016 - training loss: 0.8759, validation loss: 0.6454
2024-05-23 20:41:02 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch16_loss0.6453600347042083.pypots
2024-05-23 20:41:05 [INFO]: Epoch 017 - training loss: 0.8654, validation loss: 0.6454
2024-05-23 20:41:05 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch17_loss0.645429190993309.pypots
2024-05-23 20:41:08 [INFO]: Epoch 018 - training loss: 0.8693, validation loss: 0.6452
2024-05-23 20:41:08 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch18_loss0.6452136039733887.pypots
2024-05-23 20:41:11 [INFO]: Epoch 019 - training loss: 0.8571, validation loss: 0.6477
2024-05-23 20:41:11 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch19_loss0.6477370828390121.pypots
2024-05-23 20:41:14 [INFO]: Epoch 020 - training loss: 0.8469, validation loss: 0.6454
2024-05-23 20:41:14 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch20_loss0.6454364627599716.pypots
2024-05-23 20:41:17 [INFO]: Epoch 021 - training loss: 0.8347, validation loss: 0.6452
2024-05-23 20:41:17 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch21_loss0.6452067613601684.pypots
2024-05-23 20:41:21 [INFO]: Epoch 022 - training loss: 0.8379, validation loss: 0.6450
2024-05-23 20:41:21 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch22_loss0.6450415253639221.pypots
2024-05-23 20:41:24 [INFO]: Epoch 023 - training loss: 0.8369, validation loss: 0.6469
2024-05-23 20:41:24 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch23_loss0.6468671023845672.pypots
2024-05-23 20:41:27 [INFO]: Epoch 024 - training loss: 0.8480, validation loss: 0.6438
2024-05-23 20:41:27 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch24_loss0.6438247084617614.pypots
2024-05-23 20:41:30 [INFO]: Epoch 025 - training loss: 0.8437, validation loss: 0.6439
2024-05-23 20:41:30 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch25_loss0.6438730746507645.pypots
2024-05-23 20:41:33 [INFO]: Epoch 026 - training loss: 0.8213, validation loss: 0.6443
2024-05-23 20:41:33 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch26_loss0.6443350970745086.pypots
2024-05-23 20:41:36 [INFO]: Epoch 027 - training loss: 0.8308, validation loss: 0.6436
2024-05-23 20:41:36 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch27_loss0.6435648769140243.pypots
2024-05-23 20:41:39 [INFO]: Epoch 028 - training loss: 0.8249, validation loss: 0.6435
2024-05-23 20:41:39 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch28_loss0.643457904458046.pypots
2024-05-23 20:41:42 [INFO]: Epoch 029 - training loss: 0.8212, validation loss: 0.6459
2024-05-23 20:41:42 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch29_loss0.6458548963069916.pypots
2024-05-23 20:41:45 [INFO]: Epoch 030 - training loss: 0.8113, validation loss: 0.6427
2024-05-23 20:41:45 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch30_loss0.642682883143425.pypots
2024-05-23 20:41:48 [INFO]: Epoch 031 - training loss: 0.8147, validation loss: 0.6444
2024-05-23 20:41:48 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch31_loss0.6443819165229797.pypots
2024-05-23 20:41:51 [INFO]: Epoch 032 - training loss: 0.8221, validation loss: 0.6445
2024-05-23 20:41:51 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch32_loss0.6444803088903427.pypots
2024-05-23 20:41:54 [INFO]: Epoch 033 - training loss: 0.8127, validation loss: 0.6477
2024-05-23 20:41:54 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch33_loss0.6477350413799285.pypots
2024-05-23 20:41:58 [INFO]: Epoch 034 - training loss: 0.8332, validation loss: 0.6494
2024-05-23 20:41:58 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch34_loss0.649436017870903.pypots
2024-05-23 20:42:01 [INFO]: Epoch 035 - training loss: 0.8206, validation loss: 0.6466
2024-05-23 20:42:01 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch35_loss0.6465816706418991.pypots
2024-05-23 20:42:04 [INFO]: Epoch 036 - training loss: 0.8200, validation loss: 0.6456
2024-05-23 20:42:04 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch36_loss0.6455867946147918.pypots
2024-05-23 20:42:07 [INFO]: Epoch 037 - training loss: 0.8358, validation loss: 0.6489
2024-05-23 20:42:07 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch37_loss0.6488712161779404.pypots
2024-05-23 20:42:10 [INFO]: Epoch 038 - training loss: 0.8222, validation loss: 0.6436
2024-05-23 20:42:10 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch38_loss0.6436269819736481.pypots
2024-05-23 20:42:13 [INFO]: Epoch 039 - training loss: 0.7986, validation loss: 0.6459
2024-05-23 20:42:13 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch39_loss0.6458679854869842.pypots
2024-05-23 20:42:16 [INFO]: Epoch 040 - training loss: 0.7915, validation loss: 0.6484
2024-05-23 20:42:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN_epoch40_loss0.6484175652265549.pypots
2024-05-23 20:42:16 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:42:16 [INFO]: Finished training. The best model is from epoch#30.
2024-05-23 20:42:16 [INFO]: Saved the model to overlay_premask_saved_results/round_3/MRNN_air_quality/20240523_T204012/MRNN.pypots
2024-05-23 20:42:17 [INFO]: MRNN on Air-Quality: MAE=0.5226, MSE=0.6943
2024-05-23 20:42:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-23 20:42:17 [INFO]: Using the given device: cpu
2024-05-23 20:42:17 [INFO]: LOCF on Air-Quality: MAE=0.2090, MSE=0.3758
2024-05-23 20:42:17 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-23 20:42:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-23 20:42:17 [INFO]: Median on Air-Quality: MAE=0.6658, MSE=1.0901
2024-05-23 20:42:17 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-23 20:42:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-23 20:42:17 [INFO]: Mean on Air-Quality: MAE=0.6970, MSE=1.0309
2024-05-23 20:42:17 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-23 20:42:17 [INFO]: Successfully saved to overlay_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-23 20:42:17 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-23 20:42:17 [INFO]: Using the given device: cuda:0
2024-05-23 20:42:17 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240523_T204217
2024-05-23 20:42:17 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/SAITS_air_quality/20240523_T204217/tensorboard
2024-05-23 20:42:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-23 20:42:17 [INFO]: Epoch 001 - training loss: 1.0430, validation loss: 0.4729
2024-05-23 20:42:18 [INFO]: Epoch 002 - training loss: 0.7416, validation loss: 0.3583
2024-05-23 20:42:19 [INFO]: Epoch 003 - training loss: 0.6339, validation loss: 0.2864
2024-05-23 20:42:19 [INFO]: Epoch 004 - training loss: 0.5611, validation loss: 0.2486
2024-05-23 20:42:20 [INFO]: Epoch 005 - training loss: 0.5075, validation loss: 0.2260
2024-05-23 20:42:20 [INFO]: Epoch 006 - training loss: 0.4705, validation loss: 0.2141
2024-05-23 20:42:21 [INFO]: Epoch 007 - training loss: 0.4471, validation loss: 0.2047
2024-05-23 20:42:22 [INFO]: Epoch 008 - training loss: 0.4283, validation loss: 0.1976
2024-05-23 20:42:22 [INFO]: Epoch 009 - training loss: 0.4138, validation loss: 0.1925
2024-05-23 20:42:23 [INFO]: Epoch 010 - training loss: 0.4014, validation loss: 0.1864
2024-05-23 20:42:23 [INFO]: Epoch 011 - training loss: 0.3937, validation loss: 0.1824
2024-05-23 20:42:24 [INFO]: Epoch 012 - training loss: 0.3853, validation loss: 0.1788
2024-05-23 20:42:24 [INFO]: Epoch 013 - training loss: 0.3750, validation loss: 0.1760
2024-05-23 20:42:25 [INFO]: Epoch 014 - training loss: 0.3666, validation loss: 0.1726
2024-05-23 20:42:26 [INFO]: Epoch 015 - training loss: 0.3637, validation loss: 0.1696
2024-05-23 20:42:26 [INFO]: Epoch 016 - training loss: 0.3566, validation loss: 0.1653
2024-05-23 20:42:27 [INFO]: Epoch 017 - training loss: 0.3527, validation loss: 0.1651
2024-05-23 20:42:27 [INFO]: Epoch 018 - training loss: 0.3461, validation loss: 0.1616
2024-05-23 20:42:28 [INFO]: Epoch 019 - training loss: 0.3423, validation loss: 0.1599
2024-05-23 20:42:28 [INFO]: Epoch 020 - training loss: 0.3390, validation loss: 0.1585
2024-05-23 20:42:29 [INFO]: Epoch 021 - training loss: 0.3336, validation loss: 0.1562
2024-05-23 20:42:30 [INFO]: Epoch 022 - training loss: 0.3314, validation loss: 0.1541
2024-05-23 20:42:30 [INFO]: Epoch 023 - training loss: 0.3264, validation loss: 0.1525
2024-05-23 20:42:31 [INFO]: Epoch 024 - training loss: 0.3236, validation loss: 0.1515
2024-05-23 20:42:31 [INFO]: Epoch 025 - training loss: 0.3214, validation loss: 0.1503
2024-05-23 20:42:32 [INFO]: Epoch 026 - training loss: 0.3187, validation loss: 0.1483
2024-05-23 20:42:33 [INFO]: Epoch 027 - training loss: 0.3150, validation loss: 0.1465
2024-05-23 20:42:33 [INFO]: Epoch 028 - training loss: 0.3121, validation loss: 0.1456
2024-05-23 20:42:34 [INFO]: Epoch 029 - training loss: 0.3118, validation loss: 0.1455
2024-05-23 20:42:34 [INFO]: Epoch 030 - training loss: 0.3084, validation loss: 0.1433
2024-05-23 20:42:35 [INFO]: Epoch 031 - training loss: 0.3075, validation loss: 0.1421
2024-05-23 20:42:35 [INFO]: Epoch 032 - training loss: 0.3038, validation loss: 0.1407
2024-05-23 20:42:36 [INFO]: Epoch 033 - training loss: 0.3009, validation loss: 0.1402
2024-05-23 20:42:37 [INFO]: Epoch 034 - training loss: 0.2989, validation loss: 0.1377
2024-05-23 20:42:37 [INFO]: Epoch 035 - training loss: 0.2967, validation loss: 0.1368
2024-05-23 20:42:38 [INFO]: Epoch 036 - training loss: 0.2945, validation loss: 0.1367
2024-05-23 20:42:38 [INFO]: Epoch 037 - training loss: 0.2932, validation loss: 0.1360
2024-05-23 20:42:39 [INFO]: Epoch 038 - training loss: 0.2913, validation loss: 0.1349
2024-05-23 20:42:39 [INFO]: Epoch 039 - training loss: 0.2898, validation loss: 0.1344
2024-05-23 20:42:40 [INFO]: Epoch 040 - training loss: 0.2879, validation loss: 0.1317
2024-05-23 20:42:41 [INFO]: Epoch 041 - training loss: 0.2863, validation loss: 0.1314
2024-05-23 20:42:41 [INFO]: Epoch 042 - training loss: 0.2842, validation loss: 0.1315
2024-05-23 20:42:42 [INFO]: Epoch 043 - training loss: 0.2821, validation loss: 0.1304
2024-05-23 20:42:42 [INFO]: Epoch 044 - training loss: 0.2810, validation loss: 0.1307
2024-05-23 20:42:43 [INFO]: Epoch 045 - training loss: 0.2796, validation loss: 0.1281
2024-05-23 20:42:44 [INFO]: Epoch 046 - training loss: 0.2773, validation loss: 0.1279
2024-05-23 20:42:44 [INFO]: Epoch 047 - training loss: 0.2755, validation loss: 0.1287
2024-05-23 20:42:45 [INFO]: Epoch 048 - training loss: 0.2752, validation loss: 0.1269
2024-05-23 20:42:45 [INFO]: Epoch 049 - training loss: 0.2730, validation loss: 0.1267
2024-05-23 20:42:46 [INFO]: Epoch 050 - training loss: 0.2711, validation loss: 0.1247
2024-05-23 20:42:46 [INFO]: Epoch 051 - training loss: 0.2701, validation loss: 0.1261
2024-05-23 20:42:47 [INFO]: Epoch 052 - training loss: 0.2710, validation loss: 0.1250
2024-05-23 20:42:48 [INFO]: Epoch 053 - training loss: 0.2677, validation loss: 0.1239
2024-05-23 20:42:48 [INFO]: Epoch 054 - training loss: 0.2659, validation loss: 0.1233
2024-05-23 20:42:49 [INFO]: Epoch 055 - training loss: 0.2646, validation loss: 0.1241
2024-05-23 20:42:49 [INFO]: Epoch 056 - training loss: 0.2637, validation loss: 0.1229
2024-05-23 20:42:50 [INFO]: Epoch 057 - training loss: 0.2609, validation loss: 0.1213
2024-05-23 20:42:50 [INFO]: Epoch 058 - training loss: 0.2599, validation loss: 0.1216
2024-05-23 20:42:51 [INFO]: Epoch 059 - training loss: 0.2599, validation loss: 0.1211
2024-05-23 20:42:52 [INFO]: Epoch 060 - training loss: 0.2577, validation loss: 0.1204
2024-05-23 20:42:52 [INFO]: Epoch 061 - training loss: 0.2559, validation loss: 0.1194
2024-05-23 20:42:53 [INFO]: Epoch 062 - training loss: 0.2560, validation loss: 0.1215
2024-05-23 20:42:53 [INFO]: Epoch 063 - training loss: 0.2553, validation loss: 0.1188
2024-05-23 20:42:54 [INFO]: Epoch 064 - training loss: 0.2515, validation loss: 0.1188
2024-05-23 20:42:55 [INFO]: Epoch 065 - training loss: 0.2502, validation loss: 0.1189
2024-05-23 20:42:55 [INFO]: Epoch 066 - training loss: 0.2497, validation loss: 0.1185
2024-05-23 20:42:56 [INFO]: Epoch 067 - training loss: 0.2486, validation loss: 0.1183
2024-05-23 20:42:56 [INFO]: Epoch 068 - training loss: 0.2473, validation loss: 0.1164
2024-05-23 20:42:57 [INFO]: Epoch 069 - training loss: 0.2470, validation loss: 0.1161
2024-05-23 20:42:57 [INFO]: Epoch 070 - training loss: 0.2449, validation loss: 0.1159
2024-05-23 20:42:58 [INFO]: Epoch 071 - training loss: 0.2441, validation loss: 0.1162
2024-05-23 20:42:59 [INFO]: Epoch 072 - training loss: 0.2437, validation loss: 0.1165
2024-05-23 20:42:59 [INFO]: Epoch 073 - training loss: 0.2420, validation loss: 0.1166
2024-05-23 20:43:00 [INFO]: Epoch 074 - training loss: 0.2405, validation loss: 0.1154
2024-05-23 20:43:00 [INFO]: Epoch 075 - training loss: 0.2397, validation loss: 0.1142
2024-05-23 20:43:01 [INFO]: Epoch 076 - training loss: 0.2386, validation loss: 0.1150
2024-05-23 20:43:01 [INFO]: Epoch 077 - training loss: 0.2377, validation loss: 0.1141
2024-05-23 20:43:02 [INFO]: Epoch 078 - training loss: 0.2376, validation loss: 0.1135
2024-05-23 20:43:03 [INFO]: Epoch 079 - training loss: 0.2364, validation loss: 0.1134
2024-05-23 20:43:03 [INFO]: Epoch 080 - training loss: 0.2353, validation loss: 0.1130
2024-05-23 20:43:04 [INFO]: Epoch 081 - training loss: 0.2336, validation loss: 0.1134
2024-05-23 20:43:04 [INFO]: Epoch 082 - training loss: 0.2333, validation loss: 0.1133
2024-05-23 20:43:05 [INFO]: Epoch 083 - training loss: 0.2328, validation loss: 0.1124
2024-05-23 20:43:06 [INFO]: Epoch 084 - training loss: 0.2306, validation loss: 0.1121
2024-05-23 20:43:06 [INFO]: Epoch 085 - training loss: 0.2316, validation loss: 0.1121
2024-05-23 20:43:07 [INFO]: Epoch 086 - training loss: 0.2301, validation loss: 0.1115
2024-05-23 20:43:07 [INFO]: Epoch 087 - training loss: 0.2293, validation loss: 0.1113
2024-05-23 20:43:08 [INFO]: Epoch 088 - training loss: 0.2284, validation loss: 0.1123
2024-05-23 20:43:08 [INFO]: Epoch 089 - training loss: 0.2279, validation loss: 0.1107
2024-05-23 20:43:09 [INFO]: Epoch 090 - training loss: 0.2275, validation loss: 0.1110
2024-05-23 20:43:10 [INFO]: Epoch 091 - training loss: 0.2270, validation loss: 0.1108
2024-05-23 20:43:10 [INFO]: Epoch 092 - training loss: 0.2268, validation loss: 0.1125
2024-05-23 20:43:11 [INFO]: Epoch 093 - training loss: 0.2254, validation loss: 0.1109
2024-05-23 20:43:11 [INFO]: Epoch 094 - training loss: 0.2249, validation loss: 0.1110
2024-05-23 20:43:12 [INFO]: Epoch 095 - training loss: 0.2245, validation loss: 0.1099
2024-05-23 20:43:12 [INFO]: Epoch 096 - training loss: 0.2230, validation loss: 0.1102
2024-05-23 20:43:13 [INFO]: Epoch 097 - training loss: 0.2236, validation loss: 0.1093
2024-05-23 20:43:14 [INFO]: Epoch 098 - training loss: 0.2219, validation loss: 0.1092
2024-05-23 20:43:14 [INFO]: Epoch 099 - training loss: 0.2221, validation loss: 0.1090
2024-05-23 20:43:15 [INFO]: Epoch 100 - training loss: 0.2207, validation loss: 0.1090
2024-05-23 20:43:15 [INFO]: Epoch 101 - training loss: 0.2202, validation loss: 0.1092
2024-05-23 20:43:16 [INFO]: Epoch 102 - training loss: 0.2191, validation loss: 0.1098
2024-05-23 20:43:16 [INFO]: Epoch 103 - training loss: 0.2183, validation loss: 0.1087
2024-05-23 20:43:17 [INFO]: Epoch 104 - training loss: 0.2180, validation loss: 0.1091
2024-05-23 20:43:18 [INFO]: Epoch 105 - training loss: 0.2173, validation loss: 0.1078
2024-05-23 20:43:18 [INFO]: Epoch 106 - training loss: 0.2172, validation loss: 0.1080
2024-05-23 20:43:19 [INFO]: Epoch 107 - training loss: 0.2160, validation loss: 0.1092
2024-05-23 20:43:19 [INFO]: Epoch 108 - training loss: 0.2159, validation loss: 0.1071
2024-05-23 20:43:20 [INFO]: Epoch 109 - training loss: 0.2154, validation loss: 0.1073
2024-05-23 20:43:21 [INFO]: Epoch 110 - training loss: 0.2145, validation loss: 0.1067
2024-05-23 20:43:21 [INFO]: Epoch 111 - training loss: 0.2133, validation loss: 0.1068
2024-05-23 20:43:22 [INFO]: Epoch 112 - training loss: 0.2123, validation loss: 0.1070
2024-05-23 20:43:22 [INFO]: Epoch 113 - training loss: 0.2131, validation loss: 0.1071
2024-05-23 20:43:23 [INFO]: Epoch 114 - training loss: 0.2122, validation loss: 0.1069
2024-05-23 20:43:23 [INFO]: Epoch 115 - training loss: 0.2119, validation loss: 0.1062
2024-05-23 20:43:24 [INFO]: Epoch 116 - training loss: 0.2130, validation loss: 0.1078
2024-05-23 20:43:25 [INFO]: Epoch 117 - training loss: 0.2114, validation loss: 0.1057
2024-05-23 20:43:25 [INFO]: Epoch 118 - training loss: 0.2098, validation loss: 0.1058
2024-05-23 20:43:26 [INFO]: Epoch 119 - training loss: 0.2078, validation loss: 0.1065
2024-05-23 20:43:26 [INFO]: Epoch 120 - training loss: 0.2083, validation loss: 0.1058
2024-05-23 20:43:27 [INFO]: Epoch 121 - training loss: 0.2073, validation loss: 0.1055
2024-05-23 20:43:27 [INFO]: Epoch 122 - training loss: 0.2094, validation loss: 0.1050
2024-05-23 20:43:28 [INFO]: Epoch 123 - training loss: 0.2080, validation loss: 0.1053
2024-05-23 20:43:29 [INFO]: Epoch 124 - training loss: 0.2071, validation loss: 0.1052
2024-05-23 20:43:29 [INFO]: Epoch 125 - training loss: 0.2069, validation loss: 0.1054
2024-05-23 20:43:30 [INFO]: Epoch 126 - training loss: 0.2055, validation loss: 0.1046
2024-05-23 20:43:30 [INFO]: Epoch 127 - training loss: 0.2048, validation loss: 0.1047
2024-05-23 20:43:31 [INFO]: Epoch 128 - training loss: 0.2045, validation loss: 0.1043
2024-05-23 20:43:32 [INFO]: Epoch 129 - training loss: 0.2046, validation loss: 0.1041
2024-05-23 20:43:32 [INFO]: Epoch 130 - training loss: 0.2039, validation loss: 0.1036
2024-05-23 20:43:33 [INFO]: Epoch 131 - training loss: 0.2038, validation loss: 0.1042
2024-05-23 20:43:33 [INFO]: Epoch 132 - training loss: 0.2040, validation loss: 0.1030
2024-05-23 20:43:34 [INFO]: Epoch 133 - training loss: 0.2027, validation loss: 0.1040
2024-05-23 20:43:34 [INFO]: Epoch 134 - training loss: 0.2017, validation loss: 0.1030
2024-05-23 20:43:35 [INFO]: Epoch 135 - training loss: 0.2009, validation loss: 0.1036
2024-05-23 20:43:36 [INFO]: Epoch 136 - training loss: 0.2005, validation loss: 0.1034
2024-05-23 20:43:36 [INFO]: Epoch 137 - training loss: 0.2005, validation loss: 0.1033
2024-05-23 20:43:37 [INFO]: Epoch 138 - training loss: 0.2006, validation loss: 0.1024
2024-05-23 20:43:37 [INFO]: Epoch 139 - training loss: 0.1995, validation loss: 0.1022
2024-05-23 20:43:38 [INFO]: Epoch 140 - training loss: 0.1985, validation loss: 0.1030
2024-05-23 20:43:38 [INFO]: Epoch 141 - training loss: 0.1985, validation loss: 0.1025
2024-05-23 20:43:39 [INFO]: Epoch 142 - training loss: 0.1994, validation loss: 0.1028
2024-05-23 20:43:40 [INFO]: Epoch 143 - training loss: 0.1977, validation loss: 0.1025
2024-05-23 20:43:40 [INFO]: Epoch 144 - training loss: 0.1970, validation loss: 0.1020
2024-05-23 20:43:41 [INFO]: Epoch 145 - training loss: 0.1962, validation loss: 0.1023
2024-05-23 20:43:41 [INFO]: Epoch 146 - training loss: 0.1958, validation loss: 0.1014
2024-05-23 20:43:42 [INFO]: Epoch 147 - training loss: 0.1960, validation loss: 0.1010
2024-05-23 20:43:43 [INFO]: Epoch 148 - training loss: 0.1964, validation loss: 0.1014
2024-05-23 20:43:43 [INFO]: Epoch 149 - training loss: 0.1955, validation loss: 0.1013
2024-05-23 20:43:44 [INFO]: Epoch 150 - training loss: 0.1953, validation loss: 0.1013
2024-05-23 20:43:44 [INFO]: Epoch 151 - training loss: 0.1940, validation loss: 0.1010
2024-05-23 20:43:45 [INFO]: Epoch 152 - training loss: 0.1940, validation loss: 0.1014
2024-05-23 20:43:45 [INFO]: Epoch 153 - training loss: 0.1936, validation loss: 0.1005
2024-05-23 20:43:46 [INFO]: Epoch 154 - training loss: 0.1961, validation loss: 0.1039
2024-05-23 20:43:47 [INFO]: Epoch 155 - training loss: 0.1969, validation loss: 0.1028
2024-05-23 20:43:47 [INFO]: Epoch 156 - training loss: 0.1960, validation loss: 0.1011
2024-05-23 20:43:48 [INFO]: Epoch 157 - training loss: 0.1934, validation loss: 0.1009
2024-05-23 20:43:48 [INFO]: Epoch 158 - training loss: 0.1929, validation loss: 0.1021
2024-05-23 20:43:49 [INFO]: Epoch 159 - training loss: 0.1919, validation loss: 0.1006
2024-05-23 20:43:49 [INFO]: Epoch 160 - training loss: 0.1909, validation loss: 0.1013
2024-05-23 20:43:50 [INFO]: Epoch 161 - training loss: 0.1905, validation loss: 0.1004
2024-05-23 20:43:51 [INFO]: Epoch 162 - training loss: 0.1901, validation loss: 0.1008
2024-05-23 20:43:51 [INFO]: Epoch 163 - training loss: 0.1908, validation loss: 0.1001
2024-05-23 20:43:52 [INFO]: Epoch 164 - training loss: 0.1894, validation loss: 0.1015
2024-05-23 20:43:52 [INFO]: Epoch 165 - training loss: 0.1889, validation loss: 0.1011
2024-05-23 20:43:53 [INFO]: Epoch 166 - training loss: 0.1894, validation loss: 0.1009
2024-05-23 20:43:54 [INFO]: Epoch 167 - training loss: 0.1909, validation loss: 0.1008
2024-05-23 20:43:54 [INFO]: Epoch 168 - training loss: 0.1885, validation loss: 0.0997
2024-05-23 20:43:55 [INFO]: Epoch 169 - training loss: 0.1873, validation loss: 0.1006
2024-05-23 20:43:55 [INFO]: Epoch 170 - training loss: 0.1873, validation loss: 0.1007
2024-05-23 20:43:56 [INFO]: Epoch 171 - training loss: 0.1864, validation loss: 0.0990
2024-05-23 20:43:56 [INFO]: Epoch 172 - training loss: 0.1879, validation loss: 0.0996
2024-05-23 20:43:57 [INFO]: Epoch 173 - training loss: 0.1881, validation loss: 0.0997
2024-05-23 20:43:58 [INFO]: Epoch 174 - training loss: 0.1866, validation loss: 0.0996
2024-05-23 20:43:58 [INFO]: Epoch 175 - training loss: 0.1859, validation loss: 0.0995
2024-05-23 20:43:59 [INFO]: Epoch 176 - training loss: 0.1851, validation loss: 0.0992
2024-05-23 20:43:59 [INFO]: Epoch 177 - training loss: 0.1847, validation loss: 0.0987
2024-05-23 20:44:00 [INFO]: Epoch 178 - training loss: 0.1842, validation loss: 0.0985
2024-05-23 20:44:00 [INFO]: Epoch 179 - training loss: 0.1852, validation loss: 0.0993
2024-05-23 20:44:01 [INFO]: Epoch 180 - training loss: 0.1843, validation loss: 0.0988
2024-05-23 20:44:02 [INFO]: Epoch 181 - training loss: 0.1837, validation loss: 0.0989
2024-05-23 20:44:02 [INFO]: Epoch 182 - training loss: 0.1829, validation loss: 0.0991
2024-05-23 20:44:03 [INFO]: Epoch 183 - training loss: 0.1825, validation loss: 0.0989
2024-05-23 20:44:03 [INFO]: Epoch 184 - training loss: 0.1828, validation loss: 0.0980
2024-05-23 20:44:04 [INFO]: Epoch 185 - training loss: 0.1820, validation loss: 0.0986
2024-05-23 20:44:05 [INFO]: Epoch 186 - training loss: 0.1824, validation loss: 0.0993
2024-05-23 20:44:05 [INFO]: Epoch 187 - training loss: 0.1844, validation loss: 0.0989
2024-05-23 20:44:06 [INFO]: Epoch 188 - training loss: 0.1825, validation loss: 0.0982
2024-05-23 20:44:06 [INFO]: Epoch 189 - training loss: 0.1821, validation loss: 0.0986
2024-05-23 20:44:07 [INFO]: Epoch 190 - training loss: 0.1821, validation loss: 0.0984
2024-05-23 20:44:08 [INFO]: Epoch 191 - training loss: 0.1804, validation loss: 0.0988
2024-05-23 20:44:08 [INFO]: Epoch 192 - training loss: 0.1799, validation loss: 0.0994
2024-05-23 20:44:09 [INFO]: Epoch 193 - training loss: 0.1800, validation loss: 0.0990
2024-05-23 20:44:09 [INFO]: Epoch 194 - training loss: 0.1791, validation loss: 0.0980
2024-05-23 20:44:10 [INFO]: Epoch 195 - training loss: 0.1786, validation loss: 0.0988
2024-05-23 20:44:11 [INFO]: Epoch 196 - training loss: 0.1784, validation loss: 0.0983
2024-05-23 20:44:11 [INFO]: Epoch 197 - training loss: 0.1783, validation loss: 0.0987
2024-05-23 20:44:12 [INFO]: Epoch 198 - training loss: 0.1782, validation loss: 0.0978
2024-05-23 20:44:12 [INFO]: Epoch 199 - training loss: 0.1783, validation loss: 0.0996
2024-05-23 20:44:13 [INFO]: Epoch 200 - training loss: 0.1778, validation loss: 0.0978
2024-05-23 20:44:14 [INFO]: Epoch 201 - training loss: 0.1780, validation loss: 0.0994
2024-05-23 20:44:14 [INFO]: Epoch 202 - training loss: 0.1777, validation loss: 0.0984
2024-05-23 20:44:15 [INFO]: Epoch 203 - training loss: 0.1777, validation loss: 0.0978
2024-05-23 20:44:15 [INFO]: Epoch 204 - training loss: 0.1775, validation loss: 0.0980
2024-05-23 20:44:16 [INFO]: Epoch 205 - training loss: 0.1764, validation loss: 0.0982
2024-05-23 20:44:17 [INFO]: Epoch 206 - training loss: 0.1763, validation loss: 0.0985
2024-05-23 20:44:17 [INFO]: Epoch 207 - training loss: 0.1757, validation loss: 0.0984
2024-05-23 20:44:18 [INFO]: Epoch 208 - training loss: 0.1752, validation loss: 0.0969
2024-05-23 20:44:18 [INFO]: Epoch 209 - training loss: 0.1752, validation loss: 0.0975
2024-05-23 20:44:19 [INFO]: Epoch 210 - training loss: 0.1743, validation loss: 0.0965
2024-05-23 20:44:20 [INFO]: Epoch 211 - training loss: 0.1743, validation loss: 0.0971
2024-05-23 20:44:20 [INFO]: Epoch 212 - training loss: 0.1734, validation loss: 0.0989
2024-05-23 20:44:21 [INFO]: Epoch 213 - training loss: 0.1736, validation loss: 0.0985
2024-05-23 20:44:21 [INFO]: Epoch 214 - training loss: 0.1739, validation loss: 0.0978
2024-05-23 20:44:22 [INFO]: Epoch 215 - training loss: 0.1737, validation loss: 0.0983
2024-05-23 20:44:23 [INFO]: Epoch 216 - training loss: 0.1743, validation loss: 0.0983
2024-05-23 20:44:23 [INFO]: Epoch 217 - training loss: 0.1752, validation loss: 0.0987
2024-05-23 20:44:24 [INFO]: Epoch 218 - training loss: 0.1760, validation loss: 0.0979
2024-05-23 20:44:24 [INFO]: Epoch 219 - training loss: 0.1733, validation loss: 0.0979
2024-05-23 20:44:25 [INFO]: Epoch 220 - training loss: 0.1722, validation loss: 0.0974
2024-05-23 20:44:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:44:25 [INFO]: Finished training. The best model is from epoch#210.
2024-05-23 20:44:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/SAITS_air_quality/20240523_T204217/SAITS.pypots
2024-05-23 20:44:25 [INFO]: SAITS on Air-Quality: MAE=0.1528, MSE=0.1783
2024-05-23 20:44:25 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-23 20:44:25 [INFO]: Using the given device: cuda:0
2024-05-23 20:44:25 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240523_T204425
2024-05-23 20:44:25 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/Transformer_air_quality/20240523_T204425/tensorboard
2024-05-23 20:44:25 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-23 20:44:26 [INFO]: Epoch 001 - training loss: 0.9016, validation loss: 0.4282
2024-05-23 20:44:26 [INFO]: Epoch 002 - training loss: 0.5541, validation loss: 0.3059
2024-05-23 20:44:26 [INFO]: Epoch 003 - training loss: 0.4615, validation loss: 0.2553
2024-05-23 20:44:26 [INFO]: Epoch 004 - training loss: 0.4183, validation loss: 0.2347
2024-05-23 20:44:27 [INFO]: Epoch 005 - training loss: 0.3885, validation loss: 0.2191
2024-05-23 20:44:27 [INFO]: Epoch 006 - training loss: 0.3699, validation loss: 0.2105
2024-05-23 20:44:27 [INFO]: Epoch 007 - training loss: 0.3539, validation loss: 0.2022
2024-05-23 20:44:27 [INFO]: Epoch 008 - training loss: 0.3431, validation loss: 0.1936
2024-05-23 20:44:28 [INFO]: Epoch 009 - training loss: 0.3320, validation loss: 0.1912
2024-05-23 20:44:28 [INFO]: Epoch 010 - training loss: 0.3246, validation loss: 0.1878
2024-05-23 20:44:28 [INFO]: Epoch 011 - training loss: 0.3177, validation loss: 0.1825
2024-05-23 20:44:28 [INFO]: Epoch 012 - training loss: 0.3128, validation loss: 0.1784
2024-05-23 20:44:29 [INFO]: Epoch 013 - training loss: 0.3062, validation loss: 0.1749
2024-05-23 20:44:29 [INFO]: Epoch 014 - training loss: 0.3016, validation loss: 0.1703
2024-05-23 20:44:29 [INFO]: Epoch 015 - training loss: 0.2968, validation loss: 0.1677
2024-05-23 20:44:29 [INFO]: Epoch 016 - training loss: 0.2921, validation loss: 0.1649
2024-05-23 20:44:30 [INFO]: Epoch 017 - training loss: 0.2886, validation loss: 0.1665
2024-05-23 20:44:30 [INFO]: Epoch 018 - training loss: 0.2866, validation loss: 0.1612
2024-05-23 20:44:30 [INFO]: Epoch 019 - training loss: 0.2819, validation loss: 0.1610
2024-05-23 20:44:30 [INFO]: Epoch 020 - training loss: 0.2771, validation loss: 0.1585
2024-05-23 20:44:30 [INFO]: Epoch 021 - training loss: 0.2759, validation loss: 0.1585
2024-05-23 20:44:31 [INFO]: Epoch 022 - training loss: 0.2715, validation loss: 0.1565
2024-05-23 20:44:31 [INFO]: Epoch 023 - training loss: 0.2697, validation loss: 0.1535
2024-05-23 20:44:31 [INFO]: Epoch 024 - training loss: 0.2678, validation loss: 0.1540
2024-05-23 20:44:31 [INFO]: Epoch 025 - training loss: 0.2646, validation loss: 0.1537
2024-05-23 20:44:32 [INFO]: Epoch 026 - training loss: 0.2616, validation loss: 0.1527
2024-05-23 20:44:32 [INFO]: Epoch 027 - training loss: 0.2597, validation loss: 0.1515
2024-05-23 20:44:32 [INFO]: Epoch 028 - training loss: 0.2569, validation loss: 0.1504
2024-05-23 20:44:32 [INFO]: Epoch 029 - training loss: 0.2559, validation loss: 0.1508
2024-05-23 20:44:33 [INFO]: Epoch 030 - training loss: 0.2551, validation loss: 0.1470
2024-05-23 20:44:33 [INFO]: Epoch 031 - training loss: 0.2526, validation loss: 0.1483
2024-05-23 20:44:33 [INFO]: Epoch 032 - training loss: 0.2508, validation loss: 0.1483
2024-05-23 20:44:33 [INFO]: Epoch 033 - training loss: 0.2499, validation loss: 0.1450
2024-05-23 20:44:34 [INFO]: Epoch 034 - training loss: 0.2512, validation loss: 0.1470
2024-05-23 20:44:34 [INFO]: Epoch 035 - training loss: 0.2519, validation loss: 0.1459
2024-05-23 20:44:34 [INFO]: Epoch 036 - training loss: 0.2446, validation loss: 0.1445
2024-05-23 20:44:34 [INFO]: Epoch 037 - training loss: 0.2412, validation loss: 0.1435
2024-05-23 20:44:34 [INFO]: Epoch 038 - training loss: 0.2411, validation loss: 0.1433
2024-05-23 20:44:35 [INFO]: Epoch 039 - training loss: 0.2419, validation loss: 0.1434
2024-05-23 20:44:35 [INFO]: Epoch 040 - training loss: 0.2367, validation loss: 0.1414
2024-05-23 20:44:35 [INFO]: Epoch 041 - training loss: 0.2349, validation loss: 0.1418
2024-05-23 20:44:35 [INFO]: Epoch 042 - training loss: 0.2355, validation loss: 0.1432
2024-05-23 20:44:36 [INFO]: Epoch 043 - training loss: 0.2349, validation loss: 0.1453
2024-05-23 20:44:36 [INFO]: Epoch 044 - training loss: 0.2335, validation loss: 0.1392
2024-05-23 20:44:36 [INFO]: Epoch 045 - training loss: 0.2312, validation loss: 0.1402
2024-05-23 20:44:36 [INFO]: Epoch 046 - training loss: 0.2281, validation loss: 0.1380
2024-05-23 20:44:37 [INFO]: Epoch 047 - training loss: 0.2273, validation loss: 0.1395
2024-05-23 20:44:37 [INFO]: Epoch 048 - training loss: 0.2264, validation loss: 0.1379
2024-05-23 20:44:37 [INFO]: Epoch 049 - training loss: 0.2243, validation loss: 0.1372
2024-05-23 20:44:37 [INFO]: Epoch 050 - training loss: 0.2240, validation loss: 0.1368
2024-05-23 20:44:37 [INFO]: Epoch 051 - training loss: 0.2221, validation loss: 0.1359
2024-05-23 20:44:38 [INFO]: Epoch 052 - training loss: 0.2244, validation loss: 0.1389
2024-05-23 20:44:38 [INFO]: Epoch 053 - training loss: 0.2240, validation loss: 0.1343
2024-05-23 20:44:38 [INFO]: Epoch 054 - training loss: 0.2210, validation loss: 0.1369
2024-05-23 20:44:38 [INFO]: Epoch 055 - training loss: 0.2168, validation loss: 0.1359
2024-05-23 20:44:39 [INFO]: Epoch 056 - training loss: 0.2156, validation loss: 0.1346
2024-05-23 20:44:39 [INFO]: Epoch 057 - training loss: 0.2179, validation loss: 0.1354
2024-05-23 20:44:39 [INFO]: Epoch 058 - training loss: 0.2154, validation loss: 0.1336
2024-05-23 20:44:39 [INFO]: Epoch 059 - training loss: 0.2152, validation loss: 0.1325
2024-05-23 20:44:40 [INFO]: Epoch 060 - training loss: 0.2125, validation loss: 0.1327
2024-05-23 20:44:40 [INFO]: Epoch 061 - training loss: 0.2167, validation loss: 0.1350
2024-05-23 20:44:40 [INFO]: Epoch 062 - training loss: 0.2181, validation loss: 0.1318
2024-05-23 20:44:40 [INFO]: Epoch 063 - training loss: 0.2109, validation loss: 0.1331
2024-05-23 20:44:41 [INFO]: Epoch 064 - training loss: 0.2079, validation loss: 0.1319
2024-05-23 20:44:41 [INFO]: Epoch 065 - training loss: 0.2071, validation loss: 0.1319
2024-05-23 20:44:41 [INFO]: Epoch 066 - training loss: 0.2064, validation loss: 0.1323
2024-05-23 20:44:41 [INFO]: Epoch 067 - training loss: 0.2050, validation loss: 0.1329
2024-05-23 20:44:41 [INFO]: Epoch 068 - training loss: 0.2067, validation loss: 0.1296
2024-05-23 20:44:42 [INFO]: Epoch 069 - training loss: 0.2047, validation loss: 0.1312
2024-05-23 20:44:42 [INFO]: Epoch 070 - training loss: 0.2031, validation loss: 0.1296
2024-05-23 20:44:42 [INFO]: Epoch 071 - training loss: 0.2026, validation loss: 0.1298
2024-05-23 20:44:42 [INFO]: Epoch 072 - training loss: 0.2045, validation loss: 0.1304
2024-05-23 20:44:43 [INFO]: Epoch 073 - training loss: 0.2030, validation loss: 0.1290
2024-05-23 20:44:43 [INFO]: Epoch 074 - training loss: 0.1998, validation loss: 0.1299
2024-05-23 20:44:43 [INFO]: Epoch 075 - training loss: 0.1986, validation loss: 0.1279
2024-05-23 20:44:43 [INFO]: Epoch 076 - training loss: 0.1964, validation loss: 0.1294
2024-05-23 20:44:44 [INFO]: Epoch 077 - training loss: 0.1971, validation loss: 0.1304
2024-05-23 20:44:44 [INFO]: Epoch 078 - training loss: 0.1979, validation loss: 0.1281
2024-05-23 20:44:44 [INFO]: Epoch 079 - training loss: 0.1950, validation loss: 0.1274
2024-05-23 20:44:44 [INFO]: Epoch 080 - training loss: 0.1938, validation loss: 0.1275
2024-05-23 20:44:44 [INFO]: Epoch 081 - training loss: 0.1927, validation loss: 0.1266
2024-05-23 20:44:45 [INFO]: Epoch 082 - training loss: 0.1945, validation loss: 0.1271
2024-05-23 20:44:45 [INFO]: Epoch 083 - training loss: 0.1933, validation loss: 0.1270
2024-05-23 20:44:45 [INFO]: Epoch 084 - training loss: 0.1918, validation loss: 0.1256
2024-05-23 20:44:45 [INFO]: Epoch 085 - training loss: 0.1921, validation loss: 0.1245
2024-05-23 20:44:46 [INFO]: Epoch 086 - training loss: 0.1901, validation loss: 0.1248
2024-05-23 20:44:46 [INFO]: Epoch 087 - training loss: 0.1893, validation loss: 0.1247
2024-05-23 20:44:46 [INFO]: Epoch 088 - training loss: 0.1872, validation loss: 0.1246
2024-05-23 20:44:46 [INFO]: Epoch 089 - training loss: 0.1868, validation loss: 0.1237
2024-05-23 20:44:47 [INFO]: Epoch 090 - training loss: 0.1857, validation loss: 0.1246
2024-05-23 20:44:47 [INFO]: Epoch 091 - training loss: 0.1854, validation loss: 0.1243
2024-05-23 20:44:47 [INFO]: Epoch 092 - training loss: 0.1874, validation loss: 0.1246
2024-05-23 20:44:47 [INFO]: Epoch 093 - training loss: 0.1934, validation loss: 0.1232
2024-05-23 20:44:48 [INFO]: Epoch 094 - training loss: 0.1912, validation loss: 0.1238
2024-05-23 20:44:48 [INFO]: Epoch 095 - training loss: 0.1870, validation loss: 0.1241
2024-05-23 20:44:48 [INFO]: Epoch 096 - training loss: 0.1887, validation loss: 0.1255
2024-05-23 20:44:48 [INFO]: Epoch 097 - training loss: 0.1845, validation loss: 0.1236
2024-05-23 20:44:48 [INFO]: Epoch 098 - training loss: 0.1826, validation loss: 0.1220
2024-05-23 20:44:49 [INFO]: Epoch 099 - training loss: 0.1818, validation loss: 0.1224
2024-05-23 20:44:49 [INFO]: Epoch 100 - training loss: 0.1795, validation loss: 0.1233
2024-05-23 20:44:49 [INFO]: Epoch 101 - training loss: 0.1799, validation loss: 0.1222
2024-05-23 20:44:49 [INFO]: Epoch 102 - training loss: 0.1780, validation loss: 0.1220
2024-05-23 20:44:50 [INFO]: Epoch 103 - training loss: 0.1777, validation loss: 0.1219
2024-05-23 20:44:50 [INFO]: Epoch 104 - training loss: 0.1764, validation loss: 0.1209
2024-05-23 20:44:50 [INFO]: Epoch 105 - training loss: 0.1767, validation loss: 0.1223
2024-05-23 20:44:50 [INFO]: Epoch 106 - training loss: 0.1766, validation loss: 0.1215
2024-05-23 20:44:51 [INFO]: Epoch 107 - training loss: 0.1738, validation loss: 0.1212
2024-05-23 20:44:51 [INFO]: Epoch 108 - training loss: 0.1731, validation loss: 0.1215
2024-05-23 20:44:51 [INFO]: Epoch 109 - training loss: 0.1718, validation loss: 0.1206
2024-05-23 20:44:51 [INFO]: Epoch 110 - training loss: 0.1713, validation loss: 0.1209
2024-05-23 20:44:51 [INFO]: Epoch 111 - training loss: 0.1724, validation loss: 0.1204
2024-05-23 20:44:52 [INFO]: Epoch 112 - training loss: 0.1738, validation loss: 0.1228
2024-05-23 20:44:52 [INFO]: Epoch 113 - training loss: 0.1714, validation loss: 0.1199
2024-05-23 20:44:52 [INFO]: Epoch 114 - training loss: 0.1706, validation loss: 0.1191
2024-05-23 20:44:52 [INFO]: Epoch 115 - training loss: 0.1687, validation loss: 0.1193
2024-05-23 20:44:53 [INFO]: Epoch 116 - training loss: 0.1680, validation loss: 0.1183
2024-05-23 20:44:53 [INFO]: Epoch 117 - training loss: 0.1682, validation loss: 0.1183
2024-05-23 20:44:53 [INFO]: Epoch 118 - training loss: 0.1668, validation loss: 0.1192
2024-05-23 20:44:53 [INFO]: Epoch 119 - training loss: 0.1674, validation loss: 0.1202
2024-05-23 20:44:54 [INFO]: Epoch 120 - training loss: 0.1663, validation loss: 0.1191
2024-05-23 20:44:54 [INFO]: Epoch 121 - training loss: 0.1681, validation loss: 0.1205
2024-05-23 20:44:54 [INFO]: Epoch 122 - training loss: 0.1681, validation loss: 0.1191
2024-05-23 20:44:54 [INFO]: Epoch 123 - training loss: 0.1679, validation loss: 0.1183
2024-05-23 20:44:55 [INFO]: Epoch 124 - training loss: 0.1669, validation loss: 0.1181
2024-05-23 20:44:55 [INFO]: Epoch 125 - training loss: 0.1641, validation loss: 0.1187
2024-05-23 20:44:55 [INFO]: Epoch 126 - training loss: 0.1648, validation loss: 0.1181
2024-05-23 20:44:55 [INFO]: Epoch 127 - training loss: 0.1699, validation loss: 0.1198
2024-05-23 20:44:55 [INFO]: Epoch 128 - training loss: 0.1693, validation loss: 0.1185
2024-05-23 20:44:56 [INFO]: Epoch 129 - training loss: 0.1668, validation loss: 0.1191
2024-05-23 20:44:56 [INFO]: Epoch 130 - training loss: 0.1642, validation loss: 0.1172
2024-05-23 20:44:56 [INFO]: Epoch 131 - training loss: 0.1652, validation loss: 0.1199
2024-05-23 20:44:56 [INFO]: Epoch 132 - training loss: 0.1641, validation loss: 0.1199
2024-05-23 20:44:57 [INFO]: Epoch 133 - training loss: 0.1617, validation loss: 0.1168
2024-05-23 20:44:57 [INFO]: Epoch 134 - training loss: 0.1599, validation loss: 0.1180
2024-05-23 20:44:57 [INFO]: Epoch 135 - training loss: 0.1592, validation loss: 0.1187
2024-05-23 20:44:57 [INFO]: Epoch 136 - training loss: 0.1586, validation loss: 0.1174
2024-05-23 20:44:58 [INFO]: Epoch 137 - training loss: 0.1593, validation loss: 0.1181
2024-05-23 20:44:58 [INFO]: Epoch 138 - training loss: 0.1574, validation loss: 0.1179
2024-05-23 20:44:58 [INFO]: Epoch 139 - training loss: 0.1548, validation loss: 0.1175
2024-05-23 20:44:58 [INFO]: Epoch 140 - training loss: 0.1564, validation loss: 0.1170
2024-05-23 20:44:59 [INFO]: Epoch 141 - training loss: 0.1570, validation loss: 0.1176
2024-05-23 20:44:59 [INFO]: Epoch 142 - training loss: 0.1560, validation loss: 0.1177
2024-05-23 20:44:59 [INFO]: Epoch 143 - training loss: 0.1537, validation loss: 0.1166
2024-05-23 20:44:59 [INFO]: Epoch 144 - training loss: 0.1540, validation loss: 0.1194
2024-05-23 20:44:59 [INFO]: Epoch 145 - training loss: 0.1536, validation loss: 0.1168
2024-05-23 20:45:00 [INFO]: Epoch 146 - training loss: 0.1538, validation loss: 0.1179
2024-05-23 20:45:00 [INFO]: Epoch 147 - training loss: 0.1522, validation loss: 0.1159
2024-05-23 20:45:00 [INFO]: Epoch 148 - training loss: 0.1577, validation loss: 0.1171
2024-05-23 20:45:00 [INFO]: Epoch 149 - training loss: 0.1557, validation loss: 0.1164
2024-05-23 20:45:01 [INFO]: Epoch 150 - training loss: 0.1540, validation loss: 0.1150
2024-05-23 20:45:01 [INFO]: Epoch 151 - training loss: 0.1535, validation loss: 0.1168
2024-05-23 20:45:01 [INFO]: Epoch 152 - training loss: 0.1532, validation loss: 0.1164
2024-05-23 20:45:01 [INFO]: Epoch 153 - training loss: 0.1517, validation loss: 0.1157
2024-05-23 20:45:02 [INFO]: Epoch 154 - training loss: 0.1509, validation loss: 0.1164
2024-05-23 20:45:02 [INFO]: Epoch 155 - training loss: 0.1527, validation loss: 0.1170
2024-05-23 20:45:02 [INFO]: Epoch 156 - training loss: 0.1510, validation loss: 0.1197
2024-05-23 20:45:02 [INFO]: Epoch 157 - training loss: 0.1506, validation loss: 0.1158
2024-05-23 20:45:02 [INFO]: Epoch 158 - training loss: 0.1490, validation loss: 0.1162
2024-05-23 20:45:03 [INFO]: Epoch 159 - training loss: 0.1496, validation loss: 0.1166
2024-05-23 20:45:03 [INFO]: Epoch 160 - training loss: 0.1496, validation loss: 0.1158
2024-05-23 20:45:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:45:03 [INFO]: Finished training. The best model is from epoch#150.
2024-05-23 20:45:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/Transformer_air_quality/20240523_T204425/Transformer.pypots
2024-05-23 20:45:03 [INFO]: Transformer on Air-Quality: MAE=0.1723, MSE=0.2032
2024-05-23 20:45:03 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-23 20:45:03 [INFO]: Using the given device: cuda:0
2024-05-23 20:45:03 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240523_T204503
2024-05-23 20:45:03 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240523_T204503/tensorboard
2024-05-23 20:45:03 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-23 20:45:04 [INFO]: Epoch 001 - training loss: 0.2819, validation loss: 0.2563
2024-05-23 20:45:04 [INFO]: Epoch 002 - training loss: 0.2299, validation loss: 0.2106
2024-05-23 20:45:05 [INFO]: Epoch 003 - training loss: 0.1783, validation loss: 0.1929
2024-05-23 20:45:05 [INFO]: Epoch 004 - training loss: 0.1614, validation loss: 0.1816
2024-05-23 20:45:06 [INFO]: Epoch 005 - training loss: 0.1508, validation loss: 0.1774
2024-05-23 20:45:06 [INFO]: Epoch 006 - training loss: 0.1423, validation loss: 0.1714
2024-05-23 20:45:06 [INFO]: Epoch 007 - training loss: 0.1463, validation loss: 0.1653
2024-05-23 20:45:07 [INFO]: Epoch 008 - training loss: 0.1310, validation loss: 0.1585
2024-05-23 20:45:07 [INFO]: Epoch 009 - training loss: 0.1207, validation loss: 0.1605
2024-05-23 20:45:08 [INFO]: Epoch 010 - training loss: 0.1175, validation loss: 0.1551
2024-05-23 20:45:08 [INFO]: Epoch 011 - training loss: 0.1072, validation loss: 0.1544
2024-05-23 20:45:09 [INFO]: Epoch 012 - training loss: 0.1050, validation loss: 0.1516
2024-05-23 20:45:09 [INFO]: Epoch 013 - training loss: 0.1079, validation loss: 0.1518
2024-05-23 20:45:09 [INFO]: Epoch 014 - training loss: 0.1021, validation loss: 0.1447
2024-05-23 20:45:10 [INFO]: Epoch 015 - training loss: 0.0959, validation loss: 0.1430
2024-05-23 20:45:10 [INFO]: Epoch 016 - training loss: 0.0931, validation loss: 0.1474
2024-05-23 20:45:11 [INFO]: Epoch 017 - training loss: 0.0906, validation loss: 0.1425
2024-05-23 20:45:11 [INFO]: Epoch 018 - training loss: 0.0949, validation loss: 0.1437
2024-05-23 20:45:12 [INFO]: Epoch 019 - training loss: 0.0870, validation loss: 0.1464
2024-05-23 20:45:12 [INFO]: Epoch 020 - training loss: 0.0881, validation loss: 0.1400
2024-05-23 20:45:12 [INFO]: Epoch 021 - training loss: 0.0847, validation loss: 0.1389
2024-05-23 20:45:13 [INFO]: Epoch 022 - training loss: 0.0871, validation loss: 0.1419
2024-05-23 20:45:13 [INFO]: Epoch 023 - training loss: 0.0953, validation loss: 0.1444
2024-05-23 20:45:14 [INFO]: Epoch 024 - training loss: 0.0861, validation loss: 0.1427
2024-05-23 20:45:14 [INFO]: Epoch 025 - training loss: 0.0849, validation loss: 0.1376
2024-05-23 20:45:15 [INFO]: Epoch 026 - training loss: 0.0779, validation loss: 0.1377
2024-05-23 20:45:15 [INFO]: Epoch 027 - training loss: 0.0807, validation loss: 0.1366
2024-05-23 20:45:15 [INFO]: Epoch 028 - training loss: 0.0734, validation loss: 0.1358
2024-05-23 20:45:16 [INFO]: Epoch 029 - training loss: 0.0754, validation loss: 0.1385
2024-05-23 20:45:16 [INFO]: Epoch 030 - training loss: 0.0773, validation loss: 0.1395
2024-05-23 20:45:17 [INFO]: Epoch 031 - training loss: 0.0788, validation loss: 0.1355
2024-05-23 20:45:17 [INFO]: Epoch 032 - training loss: 0.0714, validation loss: 0.1322
2024-05-23 20:45:18 [INFO]: Epoch 033 - training loss: 0.0661, validation loss: 0.1343
2024-05-23 20:45:18 [INFO]: Epoch 034 - training loss: 0.0648, validation loss: 0.1327
2024-05-23 20:45:19 [INFO]: Epoch 035 - training loss: 0.0666, validation loss: 0.1330
2024-05-23 20:45:19 [INFO]: Epoch 036 - training loss: 0.0693, validation loss: 0.1330
2024-05-23 20:45:19 [INFO]: Epoch 037 - training loss: 0.0622, validation loss: 0.1337
2024-05-23 20:45:20 [INFO]: Epoch 038 - training loss: 0.0605, validation loss: 0.1330
2024-05-23 20:45:20 [INFO]: Epoch 039 - training loss: 0.0596, validation loss: 0.1327
2024-05-23 20:45:21 [INFO]: Epoch 040 - training loss: 0.0610, validation loss: 0.1355
2024-05-23 20:45:21 [INFO]: Epoch 041 - training loss: 0.0609, validation loss: 0.1326
2024-05-23 20:45:22 [INFO]: Epoch 042 - training loss: 0.0613, validation loss: 0.1333
2024-05-23 20:45:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 20:45:22 [INFO]: Finished training. The best model is from epoch#32.
2024-05-23 20:45:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/TimesNet_air_quality/20240523_T204503/TimesNet.pypots
2024-05-23 20:45:22 [INFO]: TimesNet on Air-Quality: MAE=0.1682, MSE=0.2581
2024-05-23 20:45:22 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-23 20:45:22 [INFO]: Using the given device: cuda:0
2024-05-23 20:45:22 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522
2024-05-23 20:45:22 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/tensorboard
2024-05-23 20:45:22 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-23 20:45:38 [INFO]: Epoch 001 - training loss: 0.5017, validation loss: 0.3306
2024-05-23 20:45:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch1_loss0.3306445240974426.pypots
2024-05-23 20:45:55 [INFO]: Epoch 002 - training loss: 0.2983, validation loss: 0.2613
2024-05-23 20:45:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch2_loss0.261341954767704.pypots
2024-05-23 20:46:11 [INFO]: Epoch 003 - training loss: 0.2294, validation loss: 0.2192
2024-05-23 20:46:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch3_loss0.21915835589170457.pypots
2024-05-23 20:46:27 [INFO]: Epoch 004 - training loss: 0.2077, validation loss: 0.1919
2024-05-23 20:46:27 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch4_loss0.19190458059310914.pypots
2024-05-23 20:46:44 [INFO]: Epoch 005 - training loss: 0.2150, validation loss: 0.1760
2024-05-23 20:46:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch5_loss0.1759625107049942.pypots
2024-05-23 20:47:00 [INFO]: Epoch 006 - training loss: 0.1703, validation loss: 0.1639
2024-05-23 20:47:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch6_loss0.16390398293733596.pypots
2024-05-23 20:47:16 [INFO]: Epoch 007 - training loss: 0.1722, validation loss: 0.1552
2024-05-23 20:47:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch7_loss0.1551535427570343.pypots
2024-05-23 20:47:33 [INFO]: Epoch 008 - training loss: 0.1693, validation loss: 0.1517
2024-05-23 20:47:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch8_loss0.15173584818840027.pypots
2024-05-23 20:47:49 [INFO]: Epoch 009 - training loss: 0.1469, validation loss: 0.1486
2024-05-23 20:47:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch9_loss0.14863890409469604.pypots
2024-05-23 20:48:06 [INFO]: Epoch 010 - training loss: 0.1551, validation loss: 0.1511
2024-05-23 20:48:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch10_loss0.15109268128871917.pypots
2024-05-23 20:48:22 [INFO]: Epoch 011 - training loss: 0.1507, validation loss: 0.1478
2024-05-23 20:48:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch11_loss0.1478239670395851.pypots
2024-05-23 20:48:39 [INFO]: Epoch 012 - training loss: 0.1581, validation loss: 0.1469
2024-05-23 20:48:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch12_loss0.1468728482723236.pypots
2024-05-23 20:48:55 [INFO]: Epoch 013 - training loss: 0.1515, validation loss: 0.1408
2024-05-23 20:48:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch13_loss0.1408083200454712.pypots
2024-05-23 20:49:11 [INFO]: Epoch 014 - training loss: 0.1624, validation loss: 0.1418
2024-05-23 20:49:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch14_loss0.14176276624202727.pypots
2024-05-23 20:49:28 [INFO]: Epoch 015 - training loss: 0.1482, validation loss: 0.1404
2024-05-23 20:49:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch15_loss0.14040553271770478.pypots
2024-05-23 20:49:44 [INFO]: Epoch 016 - training loss: 0.1540, validation loss: 0.1404
2024-05-23 20:49:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch16_loss0.14044086784124374.pypots
2024-05-23 20:50:01 [INFO]: Epoch 017 - training loss: 0.1460, validation loss: 0.1363
2024-05-23 20:50:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch17_loss0.13628460541367532.pypots
2024-05-23 20:50:17 [INFO]: Epoch 018 - training loss: 0.1296, validation loss: 0.1343
2024-05-23 20:50:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch18_loss0.134278105199337.pypots
2024-05-23 20:50:34 [INFO]: Epoch 019 - training loss: 0.1336, validation loss: 0.1369
2024-05-23 20:50:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch19_loss0.13685679137706758.pypots
2024-05-23 20:50:50 [INFO]: Epoch 020 - training loss: 0.1330, validation loss: 0.1366
2024-05-23 20:50:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch20_loss0.13655224516987802.pypots
2024-05-23 20:51:07 [INFO]: Epoch 021 - training loss: 0.1399, validation loss: 0.1323
2024-05-23 20:51:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch21_loss0.1322983555495739.pypots
2024-05-23 20:51:23 [INFO]: Epoch 022 - training loss: 0.1356, validation loss: 0.1324
2024-05-23 20:51:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch22_loss0.1324198804795742.pypots
2024-05-23 20:51:40 [INFO]: Epoch 023 - training loss: 0.1282, validation loss: 0.1297
2024-05-23 20:51:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch23_loss0.12965485975146293.pypots
2024-05-23 20:51:56 [INFO]: Epoch 024 - training loss: 0.1319, validation loss: 0.1319
2024-05-23 20:51:56 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch24_loss0.1319039762020111.pypots
2024-05-23 20:52:13 [INFO]: Epoch 025 - training loss: 0.1280, validation loss: 0.1274
2024-05-23 20:52:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch25_loss0.12744853049516677.pypots
2024-05-23 20:52:29 [INFO]: Epoch 026 - training loss: 0.1456, validation loss: 0.1300
2024-05-23 20:52:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch26_loss0.12998991832137108.pypots
2024-05-23 20:52:46 [INFO]: Epoch 027 - training loss: 0.1395, validation loss: 0.1298
2024-05-23 20:52:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch27_loss0.12983768284320832.pypots
2024-05-23 20:53:02 [INFO]: Epoch 028 - training loss: 0.1323, validation loss: 0.1281
2024-05-23 20:53:02 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch28_loss0.12811191529035568.pypots
2024-05-23 20:53:19 [INFO]: Epoch 029 - training loss: 0.1306, validation loss: 0.1251
2024-05-23 20:53:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch29_loss0.12506860569119455.pypots
2024-05-23 20:53:35 [INFO]: Epoch 030 - training loss: 0.1255, validation loss: 0.1268
2024-05-23 20:53:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch30_loss0.1267928883433342.pypots
2024-05-23 20:53:51 [INFO]: Epoch 031 - training loss: 0.1228, validation loss: 0.1253
2024-05-23 20:53:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch31_loss0.125263824313879.pypots
2024-05-23 20:54:08 [INFO]: Epoch 032 - training loss: 0.1254, validation loss: 0.1291
2024-05-23 20:54:08 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch32_loss0.129146771132946.pypots
2024-05-23 20:54:24 [INFO]: Epoch 033 - training loss: 0.1223, validation loss: 0.1241
2024-05-23 20:54:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch33_loss0.1241182491183281.pypots
2024-05-23 20:54:41 [INFO]: Epoch 034 - training loss: 0.1296, validation loss: 0.1250
2024-05-23 20:54:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch34_loss0.12504944428801537.pypots
2024-05-23 20:54:57 [INFO]: Epoch 035 - training loss: 0.1332, validation loss: 0.1275
2024-05-23 20:54:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch35_loss0.1275088407099247.pypots
2024-05-23 20:55:14 [INFO]: Epoch 036 - training loss: 0.1122, validation loss: 0.1283
2024-05-23 20:55:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch36_loss0.1283401407301426.pypots
2024-05-23 20:55:30 [INFO]: Epoch 037 - training loss: 0.1204, validation loss: 0.1225
2024-05-23 20:55:30 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch37_loss0.12250293940305709.pypots
2024-05-23 20:55:47 [INFO]: Epoch 038 - training loss: 0.1262, validation loss: 0.1283
2024-05-23 20:55:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch38_loss0.12831107378005982.pypots
2024-05-23 20:56:03 [INFO]: Epoch 039 - training loss: 0.1197, validation loss: 0.1209
2024-05-23 20:56:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch39_loss0.12085981369018554.pypots
2024-05-23 20:56:20 [INFO]: Epoch 040 - training loss: 0.1303, validation loss: 0.1213
2024-05-23 20:56:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch40_loss0.1213419958949089.pypots
2024-05-23 20:56:36 [INFO]: Epoch 041 - training loss: 0.1313, validation loss: 0.1214
2024-05-23 20:56:36 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch41_loss0.1214080885052681.pypots
2024-05-23 20:56:53 [INFO]: Epoch 042 - training loss: 0.1275, validation loss: 0.1216
2024-05-23 20:56:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch42_loss0.1216350793838501.pypots
2024-05-23 20:57:09 [INFO]: Epoch 043 - training loss: 0.1208, validation loss: 0.1181
2024-05-23 20:57:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch43_loss0.1180870346724987.pypots
2024-05-23 20:57:26 [INFO]: Epoch 044 - training loss: 0.1180, validation loss: 0.1187
2024-05-23 20:57:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch44_loss0.11871288567781449.pypots
2024-05-23 20:57:42 [INFO]: Epoch 045 - training loss: 0.1273, validation loss: 0.1186
2024-05-23 20:57:42 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch45_loss0.11861979737877845.pypots
2024-05-23 20:57:59 [INFO]: Epoch 046 - training loss: 0.1173, validation loss: 0.1206
2024-05-23 20:57:59 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch46_loss0.12058058530092239.pypots
2024-05-23 20:58:15 [INFO]: Epoch 047 - training loss: 0.1183, validation loss: 0.1207
2024-05-23 20:58:15 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch47_loss0.12074970602989196.pypots
2024-05-23 20:58:32 [INFO]: Epoch 048 - training loss: 0.1201, validation loss: 0.1172
2024-05-23 20:58:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch48_loss0.11715859919786453.pypots
2024-05-23 20:58:48 [INFO]: Epoch 049 - training loss: 0.1025, validation loss: 0.1176
2024-05-23 20:58:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch49_loss0.11756732836365699.pypots
2024-05-23 20:59:05 [INFO]: Epoch 050 - training loss: 0.1133, validation loss: 0.1202
2024-05-23 20:59:05 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch50_loss0.12019922062754632.pypots
2024-05-23 20:59:21 [INFO]: Epoch 051 - training loss: 0.1041, validation loss: 0.1177
2024-05-23 20:59:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch51_loss0.11766510531306267.pypots
2024-05-23 20:59:38 [INFO]: Epoch 052 - training loss: 0.1100, validation loss: 0.1146
2024-05-23 20:59:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch52_loss0.1145770750939846.pypots
2024-05-23 20:59:55 [INFO]: Epoch 053 - training loss: 0.1107, validation loss: 0.1167
2024-05-23 20:59:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch53_loss0.11670249328017235.pypots
2024-05-23 21:00:11 [INFO]: Epoch 054 - training loss: 0.1206, validation loss: 0.1144
2024-05-23 21:00:11 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch54_loss0.11442627683281899.pypots
2024-05-23 21:00:28 [INFO]: Epoch 055 - training loss: 0.1168, validation loss: 0.1162
2024-05-23 21:00:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch55_loss0.11617501452565193.pypots
2024-05-23 21:00:44 [INFO]: Epoch 056 - training loss: 0.1220, validation loss: 0.1152
2024-05-23 21:00:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch56_loss0.11520977169275284.pypots
2024-05-23 21:01:01 [INFO]: Epoch 057 - training loss: 0.0986, validation loss: 0.1147
2024-05-23 21:01:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch57_loss0.11466238349676132.pypots
2024-05-23 21:01:17 [INFO]: Epoch 058 - training loss: 0.1100, validation loss: 0.1142
2024-05-23 21:01:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch58_loss0.11416304856538773.pypots
2024-05-23 21:01:33 [INFO]: Epoch 059 - training loss: 0.1142, validation loss: 0.1169
2024-05-23 21:01:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch59_loss0.11690907180309296.pypots
2024-05-23 21:01:50 [INFO]: Epoch 060 - training loss: 0.1072, validation loss: 0.1151
2024-05-23 21:01:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch60_loss0.11507394164800644.pypots
2024-05-23 21:02:06 [INFO]: Epoch 061 - training loss: 0.1057, validation loss: 0.1142
2024-05-23 21:02:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch61_loss0.1141794502735138.pypots
2024-05-23 21:02:23 [INFO]: Epoch 062 - training loss: 0.1154, validation loss: 0.1139
2024-05-23 21:02:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch62_loss0.11393272280693054.pypots
2024-05-23 21:02:39 [INFO]: Epoch 063 - training loss: 0.1208, validation loss: 0.1184
2024-05-23 21:02:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch63_loss0.11837716400623322.pypots
2024-05-23 21:02:55 [INFO]: Epoch 064 - training loss: 0.1064, validation loss: 0.1163
2024-05-23 21:02:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch64_loss0.11629819348454476.pypots
2024-05-23 21:03:12 [INFO]: Epoch 065 - training loss: 0.1149, validation loss: 0.1184
2024-05-23 21:03:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch65_loss0.11836375817656516.pypots
2024-05-23 21:03:28 [INFO]: Epoch 066 - training loss: 0.1149, validation loss: 0.1149
2024-05-23 21:03:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch66_loss0.11488409116864204.pypots
2024-05-23 21:03:44 [INFO]: Epoch 067 - training loss: 0.0985, validation loss: 0.1149
2024-05-23 21:03:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch67_loss0.11489196717739106.pypots
2024-05-23 21:04:01 [INFO]: Epoch 068 - training loss: 0.1102, validation loss: 0.1137
2024-05-23 21:04:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch68_loss0.11367611810564995.pypots
2024-05-23 21:04:17 [INFO]: Epoch 069 - training loss: 0.1091, validation loss: 0.1177
2024-05-23 21:04:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch69_loss0.11773879453539848.pypots
2024-05-23 21:04:33 [INFO]: Epoch 070 - training loss: 0.1156, validation loss: 0.1147
2024-05-23 21:04:33 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch70_loss0.11471721380949021.pypots
2024-05-23 21:04:50 [INFO]: Epoch 071 - training loss: 0.1130, validation loss: 0.1146
2024-05-23 21:04:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch71_loss0.1145895317196846.pypots
2024-05-23 21:05:06 [INFO]: Epoch 072 - training loss: 0.1011, validation loss: 0.1141
2024-05-23 21:05:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch72_loss0.11405322104692459.pypots
2024-05-23 21:05:23 [INFO]: Epoch 073 - training loss: 0.1095, validation loss: 0.1119
2024-05-23 21:05:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch73_loss0.11188833266496659.pypots
2024-05-23 21:05:39 [INFO]: Epoch 074 - training loss: 0.1130, validation loss: 0.1143
2024-05-23 21:05:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch74_loss0.11431506499648095.pypots
2024-05-23 21:05:55 [INFO]: Epoch 075 - training loss: 0.0949, validation loss: 0.1114
2024-05-23 21:05:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch75_loss0.11139685884118081.pypots
2024-05-23 21:06:12 [INFO]: Epoch 076 - training loss: 0.1033, validation loss: 0.1151
2024-05-23 21:06:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch76_loss0.11506441906094551.pypots
2024-05-23 21:06:28 [INFO]: Epoch 077 - training loss: 0.1210, validation loss: 0.1121
2024-05-23 21:06:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch77_loss0.11214232444763184.pypots
2024-05-23 21:06:44 [INFO]: Epoch 078 - training loss: 0.0982, validation loss: 0.1177
2024-05-23 21:06:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch78_loss0.11769145429134369.pypots
2024-05-23 21:07:01 [INFO]: Epoch 079 - training loss: 0.1063, validation loss: 0.1098
2024-05-23 21:07:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch79_loss0.10976643785834313.pypots
2024-05-23 21:07:17 [INFO]: Epoch 080 - training loss: 0.1077, validation loss: 0.1111
2024-05-23 21:07:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch80_loss0.11109301894903183.pypots
2024-05-23 21:07:34 [INFO]: Epoch 081 - training loss: 0.1171, validation loss: 0.1104
2024-05-23 21:07:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch81_loss0.1104251854121685.pypots
2024-05-23 21:07:50 [INFO]: Epoch 082 - training loss: 0.1048, validation loss: 0.1105
2024-05-23 21:07:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch82_loss0.1104743868112564.pypots
2024-05-23 21:08:06 [INFO]: Epoch 083 - training loss: 0.1032, validation loss: 0.1119
2024-05-23 21:08:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch83_loss0.11191884204745292.pypots
2024-05-23 21:08:23 [INFO]: Epoch 084 - training loss: 0.1130, validation loss: 0.1105
2024-05-23 21:08:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch84_loss0.11047785431146621.pypots
2024-05-23 21:08:39 [INFO]: Epoch 085 - training loss: 0.1144, validation loss: 0.1164
2024-05-23 21:08:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch85_loss0.11635559052228928.pypots
2024-05-23 21:08:55 [INFO]: Epoch 086 - training loss: 0.1098, validation loss: 0.1081
2024-05-23 21:08:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch86_loss0.10811744630336761.pypots
2024-05-23 21:09:12 [INFO]: Epoch 087 - training loss: 0.1012, validation loss: 0.1089
2024-05-23 21:09:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch87_loss0.1089339517056942.pypots
2024-05-23 21:09:28 [INFO]: Epoch 088 - training loss: 0.1058, validation loss: 0.1087
2024-05-23 21:09:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch88_loss0.10870273187756538.pypots
2024-05-23 21:09:45 [INFO]: Epoch 089 - training loss: 0.1062, validation loss: 0.1101
2024-05-23 21:09:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch89_loss0.11013367027044296.pypots
2024-05-23 21:10:01 [INFO]: Epoch 090 - training loss: 0.1003, validation loss: 0.1114
2024-05-23 21:10:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch90_loss0.11140193715691567.pypots
2024-05-23 21:10:17 [INFO]: Epoch 091 - training loss: 0.1025, validation loss: 0.1114
2024-05-23 21:10:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch91_loss0.11142095178365707.pypots
2024-05-23 21:10:34 [INFO]: Epoch 092 - training loss: 0.0992, validation loss: 0.1082
2024-05-23 21:10:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch92_loss0.10821623355150223.pypots
2024-05-23 21:10:50 [INFO]: Epoch 093 - training loss: 0.1020, validation loss: 0.1079
2024-05-23 21:10:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch93_loss0.1079453781247139.pypots
2024-05-23 21:11:06 [INFO]: Epoch 094 - training loss: 0.0967, validation loss: 0.1095
2024-05-23 21:11:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch94_loss0.10948176011443138.pypots
2024-05-23 21:11:23 [INFO]: Epoch 095 - training loss: 0.1130, validation loss: 0.1085
2024-05-23 21:11:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch95_loss0.10849926695227623.pypots
2024-05-23 21:11:39 [INFO]: Epoch 096 - training loss: 0.0914, validation loss: 0.1064
2024-05-23 21:11:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch96_loss0.10640389919281006.pypots
2024-05-23 21:11:55 [INFO]: Epoch 097 - training loss: 0.1158, validation loss: 0.1085
2024-05-23 21:11:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch97_loss0.1084846667945385.pypots
2024-05-23 21:12:12 [INFO]: Epoch 098 - training loss: 0.1071, validation loss: 0.1070
2024-05-23 21:12:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch98_loss0.10704984292387962.pypots
2024-05-23 21:12:28 [INFO]: Epoch 099 - training loss: 0.1163, validation loss: 0.1114
2024-05-23 21:12:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch99_loss0.11135558485984802.pypots
2024-05-23 21:12:44 [INFO]: Epoch 100 - training loss: 0.1103, validation loss: 0.1069
2024-05-23 21:12:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch100_loss0.10692897140979767.pypots
2024-05-23 21:13:01 [INFO]: Epoch 101 - training loss: 0.1114, validation loss: 0.1078
2024-05-23 21:13:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch101_loss0.10779511332511901.pypots
2024-05-23 21:13:17 [INFO]: Epoch 102 - training loss: 0.0919, validation loss: 0.1062
2024-05-23 21:13:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch102_loss0.10624274685978889.pypots
2024-05-23 21:13:34 [INFO]: Epoch 103 - training loss: 0.0940, validation loss: 0.1063
2024-05-23 21:13:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch103_loss0.10633327141404152.pypots
2024-05-23 21:13:50 [INFO]: Epoch 104 - training loss: 0.0962, validation loss: 0.1064
2024-05-23 21:13:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch104_loss0.10637695565819741.pypots
2024-05-23 21:14:06 [INFO]: Epoch 105 - training loss: 0.1007, validation loss: 0.1061
2024-05-23 21:14:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch105_loss0.10609943866729736.pypots
2024-05-23 21:14:23 [INFO]: Epoch 106 - training loss: 0.0987, validation loss: 0.1060
2024-05-23 21:14:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch106_loss0.10602998808026314.pypots
2024-05-23 21:14:39 [INFO]: Epoch 107 - training loss: 0.1003, validation loss: 0.1059
2024-05-23 21:14:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch107_loss0.10586432814598083.pypots
2024-05-23 21:14:55 [INFO]: Epoch 108 - training loss: 0.0988, validation loss: 0.1052
2024-05-23 21:14:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch108_loss0.10515331700444222.pypots
2024-05-23 21:15:12 [INFO]: Epoch 109 - training loss: 0.0953, validation loss: 0.1050
2024-05-23 21:15:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch109_loss0.10501087233424186.pypots
2024-05-23 21:15:28 [INFO]: Epoch 110 - training loss: 0.0934, validation loss: 0.1062
2024-05-23 21:15:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch110_loss0.10624914318323135.pypots
2024-05-23 21:15:44 [INFO]: Epoch 111 - training loss: 0.0979, validation loss: 0.1029
2024-05-23 21:15:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch111_loss0.10291145890951156.pypots
2024-05-23 21:16:01 [INFO]: Epoch 112 - training loss: 0.1081, validation loss: 0.1032
2024-05-23 21:16:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch112_loss0.1031987264752388.pypots
2024-05-23 21:16:17 [INFO]: Epoch 113 - training loss: 0.1059, validation loss: 0.1046
2024-05-23 21:16:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch113_loss0.10462321117520332.pypots
2024-05-23 21:16:34 [INFO]: Epoch 114 - training loss: 0.0914, validation loss: 0.1055
2024-05-23 21:16:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch114_loss0.10552404075860977.pypots
2024-05-23 21:16:50 [INFO]: Epoch 115 - training loss: 0.1020, validation loss: 0.1051
2024-05-23 21:16:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch115_loss0.10512009784579276.pypots
2024-05-23 21:17:06 [INFO]: Epoch 116 - training loss: 0.1028, validation loss: 0.1064
2024-05-23 21:17:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch116_loss0.10639059618115425.pypots
2024-05-23 21:17:23 [INFO]: Epoch 117 - training loss: 0.1036, validation loss: 0.1045
2024-05-23 21:17:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch117_loss0.10453397706151009.pypots
2024-05-23 21:17:39 [INFO]: Epoch 118 - training loss: 0.1146, validation loss: 0.1027
2024-05-23 21:17:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch118_loss0.10270922854542733.pypots
2024-05-23 21:17:55 [INFO]: Epoch 119 - training loss: 0.1058, validation loss: 0.1069
2024-05-23 21:17:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch119_loss0.10687368586659432.pypots
2024-05-23 21:18:12 [INFO]: Epoch 120 - training loss: 0.1044, validation loss: 0.1025
2024-05-23 21:18:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch120_loss0.10249376818537712.pypots
2024-05-23 21:18:28 [INFO]: Epoch 121 - training loss: 0.1024, validation loss: 0.1025
2024-05-23 21:18:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch121_loss0.10254608243703842.pypots
2024-05-23 21:18:44 [INFO]: Epoch 122 - training loss: 0.0965, validation loss: 0.1021
2024-05-23 21:18:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch122_loss0.10206024274230004.pypots
2024-05-23 21:19:01 [INFO]: Epoch 123 - training loss: 0.1042, validation loss: 0.1044
2024-05-23 21:19:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch123_loss0.10440633222460746.pypots
2024-05-23 21:19:17 [INFO]: Epoch 124 - training loss: 0.0978, validation loss: 0.1041
2024-05-23 21:19:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch124_loss0.10408645793795586.pypots
2024-05-23 21:19:34 [INFO]: Epoch 125 - training loss: 0.1025, validation loss: 0.1027
2024-05-23 21:19:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch125_loss0.10266588553786278.pypots
2024-05-23 21:19:50 [INFO]: Epoch 126 - training loss: 0.0881, validation loss: 0.1030
2024-05-23 21:19:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch126_loss0.10302429720759392.pypots
2024-05-23 21:20:06 [INFO]: Epoch 127 - training loss: 0.1003, validation loss: 0.1028
2024-05-23 21:20:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch127_loss0.10282799825072289.pypots
2024-05-23 21:20:23 [INFO]: Epoch 128 - training loss: 0.1040, validation loss: 0.1048
2024-05-23 21:20:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch128_loss0.10482016056776047.pypots
2024-05-23 21:20:39 [INFO]: Epoch 129 - training loss: 0.1071, validation loss: 0.1047
2024-05-23 21:20:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch129_loss0.10467304214835167.pypots
2024-05-23 21:20:55 [INFO]: Epoch 130 - training loss: 0.1042, validation loss: 0.1013
2024-05-23 21:20:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch130_loss0.10130343437194825.pypots
2024-05-23 21:21:12 [INFO]: Epoch 131 - training loss: 0.1127, validation loss: 0.1057
2024-05-23 21:21:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch131_loss0.10571935772895813.pypots
2024-05-23 21:21:28 [INFO]: Epoch 132 - training loss: 0.1063, validation loss: 0.1049
2024-05-23 21:21:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch132_loss0.10494396612048149.pypots
2024-05-23 21:21:44 [INFO]: Epoch 133 - training loss: 0.0966, validation loss: 0.1028
2024-05-23 21:21:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch133_loss0.10284695997834206.pypots
2024-05-23 21:22:01 [INFO]: Epoch 134 - training loss: 0.0889, validation loss: 0.1027
2024-05-23 21:22:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch134_loss0.10266372635960579.pypots
2024-05-23 21:22:17 [INFO]: Epoch 135 - training loss: 0.1047, validation loss: 0.1059
2024-05-23 21:22:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch135_loss0.10585861802101135.pypots
2024-05-23 21:22:33 [INFO]: Epoch 136 - training loss: 0.0906, validation loss: 0.1019
2024-05-23 21:22:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch136_loss0.10194988176226616.pypots
2024-05-23 21:22:50 [INFO]: Epoch 137 - training loss: 0.1059, validation loss: 0.1053
2024-05-23 21:22:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch137_loss0.10528625026345254.pypots
2024-05-23 21:23:06 [INFO]: Epoch 138 - training loss: 0.0982, validation loss: 0.1041
2024-05-23 21:23:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch138_loss0.10414956584572792.pypots
2024-05-23 21:23:23 [INFO]: Epoch 139 - training loss: 0.0995, validation loss: 0.1009
2024-05-23 21:23:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch139_loss0.10091894567012787.pypots
2024-05-23 21:23:39 [INFO]: Epoch 140 - training loss: 0.0932, validation loss: 0.1016
2024-05-23 21:23:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch140_loss0.10164924561977387.pypots
2024-05-23 21:23:55 [INFO]: Epoch 141 - training loss: 0.1003, validation loss: 0.1016
2024-05-23 21:23:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch141_loss0.10160024240612983.pypots
2024-05-23 21:24:12 [INFO]: Epoch 142 - training loss: 0.1048, validation loss: 0.1021
2024-05-23 21:24:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch142_loss0.10210376232862473.pypots
2024-05-23 21:24:28 [INFO]: Epoch 143 - training loss: 0.1006, validation loss: 0.1028
2024-05-23 21:24:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch143_loss0.10281458720564843.pypots
2024-05-23 21:24:44 [INFO]: Epoch 144 - training loss: 0.1009, validation loss: 0.1028
2024-05-23 21:24:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch144_loss0.10284081101417542.pypots
2024-05-23 21:25:01 [INFO]: Epoch 145 - training loss: 0.1081, validation loss: 0.1004
2024-05-23 21:25:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch145_loss0.10040538758039474.pypots
2024-05-23 21:25:17 [INFO]: Epoch 146 - training loss: 0.0929, validation loss: 0.1014
2024-05-23 21:25:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch146_loss0.10141459256410598.pypots
2024-05-23 21:25:33 [INFO]: Epoch 147 - training loss: 0.1076, validation loss: 0.0989
2024-05-23 21:25:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch147_loss0.09891837984323501.pypots
2024-05-23 21:25:50 [INFO]: Epoch 148 - training loss: 0.0840, validation loss: 0.1009
2024-05-23 21:25:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch148_loss0.10093703866004944.pypots
2024-05-23 21:26:06 [INFO]: Epoch 149 - training loss: 0.0955, validation loss: 0.1005
2024-05-23 21:26:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch149_loss0.10053140372037887.pypots
2024-05-23 21:26:23 [INFO]: Epoch 150 - training loss: 0.0981, validation loss: 0.1019
2024-05-23 21:26:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch150_loss0.10187980830669403.pypots
2024-05-23 21:26:39 [INFO]: Epoch 151 - training loss: 0.1023, validation loss: 0.0998
2024-05-23 21:26:39 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch151_loss0.09977055341005325.pypots
2024-05-23 21:26:55 [INFO]: Epoch 152 - training loss: 0.0913, validation loss: 0.1003
2024-05-23 21:26:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch152_loss0.10033841654658318.pypots
2024-05-23 21:27:12 [INFO]: Epoch 153 - training loss: 0.1010, validation loss: 0.1015
2024-05-23 21:27:12 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch153_loss0.10145904943346977.pypots
2024-05-23 21:27:28 [INFO]: Epoch 154 - training loss: 0.1003, validation loss: 0.0998
2024-05-23 21:27:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch154_loss0.09980183690786362.pypots
2024-05-23 21:27:44 [INFO]: Epoch 155 - training loss: 0.0956, validation loss: 0.0994
2024-05-23 21:27:44 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch155_loss0.09935064613819122.pypots
2024-05-23 21:28:01 [INFO]: Epoch 156 - training loss: 0.0887, validation loss: 0.1003
2024-05-23 21:28:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch156_loss0.10031331703066826.pypots
2024-05-23 21:28:17 [INFO]: Epoch 157 - training loss: 0.1029, validation loss: 0.0996
2024-05-23 21:28:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI_epoch157_loss0.09959521517157555.pypots
2024-05-23 21:28:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:28:17 [INFO]: Finished training. The best model is from epoch#147.
2024-05-23 21:28:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/CSDI_air_quality/20240523_T204522/CSDI.pypots
2024-05-23 21:30:35 [INFO]: CSDI on Air-Quality: MAE=0.1060, MSE=0.2624
2024-05-23 21:30:35 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-23 21:30:35 [INFO]: Using the given device: cuda:0
2024-05-23 21:30:35 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240523_T213035
2024-05-23 21:30:35 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240523_T213035/tensorboard
2024-05-23 21:30:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-23 21:30:36 [INFO]: Epoch 001 - training loss: 64712.5046, validation loss: 0.6131
2024-05-23 21:30:36 [INFO]: Epoch 002 - training loss: 41858.4909, validation loss: 0.5581
2024-05-23 21:30:36 [INFO]: Epoch 003 - training loss: 41506.5135, validation loss: 0.5184
2024-05-23 21:30:36 [INFO]: Epoch 004 - training loss: 41397.6622, validation loss: 0.4439
2024-05-23 21:30:37 [INFO]: Epoch 005 - training loss: 41298.8449, validation loss: 0.4374
2024-05-23 21:30:37 [INFO]: Epoch 006 - training loss: 41243.4203, validation loss: 0.4309
2024-05-23 21:30:37 [INFO]: Epoch 007 - training loss: 41211.5541, validation loss: 0.4695
2024-05-23 21:30:37 [INFO]: Epoch 008 - training loss: 41190.8403, validation loss: 0.3390
2024-05-23 21:30:38 [INFO]: Epoch 009 - training loss: 41141.1723, validation loss: 0.3326
2024-05-23 21:30:38 [INFO]: Epoch 010 - training loss: 41110.7212, validation loss: 0.3201
2024-05-23 21:30:38 [INFO]: Epoch 011 - training loss: 41078.1613, validation loss: 0.3003
2024-05-23 21:30:38 [INFO]: Epoch 012 - training loss: 41042.4612, validation loss: 0.3251
2024-05-23 21:30:39 [INFO]: Epoch 013 - training loss: 41053.0527, validation loss: 0.3081
2024-05-23 21:30:39 [INFO]: Epoch 014 - training loss: 41049.3479, validation loss: 0.3006
2024-05-23 21:30:39 [INFO]: Epoch 015 - training loss: 41021.9755, validation loss: 0.2834
2024-05-23 21:30:39 [INFO]: Epoch 016 - training loss: 41000.1820, validation loss: 0.3002
2024-05-23 21:30:40 [INFO]: Epoch 017 - training loss: 41116.4356, validation loss: 0.3124
2024-05-23 21:30:40 [INFO]: Epoch 018 - training loss: 41033.5707, validation loss: 0.2751
2024-05-23 21:30:40 [INFO]: Epoch 019 - training loss: 40993.1515, validation loss: 0.2717
2024-05-23 21:30:40 [INFO]: Epoch 020 - training loss: 40965.2691, validation loss: 0.2588
2024-05-23 21:30:41 [INFO]: Epoch 021 - training loss: 40958.6685, validation loss: 0.2552
2024-05-23 21:30:41 [INFO]: Epoch 022 - training loss: 40959.0859, validation loss: 0.2631
2024-05-23 21:30:41 [INFO]: Epoch 023 - training loss: 40958.1609, validation loss: 0.2492
2024-05-23 21:30:41 [INFO]: Epoch 024 - training loss: 40940.6871, validation loss: 0.2477
2024-05-23 21:30:42 [INFO]: Epoch 025 - training loss: 40931.0703, validation loss: 0.2430
2024-05-23 21:30:42 [INFO]: Epoch 026 - training loss: 40924.0940, validation loss: 0.2395
2024-05-23 21:30:42 [INFO]: Epoch 027 - training loss: 40920.2959, validation loss: 0.2420
2024-05-23 21:30:42 [INFO]: Epoch 028 - training loss: 40930.5663, validation loss: 0.2394
2024-05-23 21:30:43 [INFO]: Epoch 029 - training loss: 40939.2319, validation loss: 0.2461
2024-05-23 21:30:43 [INFO]: Epoch 030 - training loss: 40925.1457, validation loss: 0.2670
2024-05-23 21:30:43 [INFO]: Epoch 031 - training loss: 40934.1062, validation loss: 0.2520
2024-05-23 21:30:43 [INFO]: Epoch 032 - training loss: 40950.7415, validation loss: 0.2459
2024-05-23 21:30:43 [INFO]: Epoch 033 - training loss: 40923.9476, validation loss: 0.2407
2024-05-23 21:30:44 [INFO]: Epoch 034 - training loss: 40918.5739, validation loss: 0.2441
2024-05-23 21:30:44 [INFO]: Epoch 035 - training loss: 40952.1328, validation loss: 0.2288
2024-05-23 21:30:44 [INFO]: Epoch 036 - training loss: 40909.6069, validation loss: 0.2261
2024-05-23 21:30:44 [INFO]: Epoch 037 - training loss: 40895.1777, validation loss: 0.2219
2024-05-23 21:30:45 [INFO]: Epoch 038 - training loss: 40891.1331, validation loss: 0.2230
2024-05-23 21:30:45 [INFO]: Epoch 039 - training loss: 40895.6672, validation loss: 0.2255
2024-05-23 21:30:45 [INFO]: Epoch 040 - training loss: 40884.5242, validation loss: 0.2249
2024-05-23 21:30:45 [INFO]: Epoch 041 - training loss: 40892.6549, validation loss: 0.2215
2024-05-23 21:30:46 [INFO]: Epoch 042 - training loss: 40884.1581, validation loss: 0.2132
2024-05-23 21:30:46 [INFO]: Epoch 043 - training loss: 40876.3122, validation loss: 0.2217
2024-05-23 21:30:46 [INFO]: Epoch 044 - training loss: 40877.4634, validation loss: 0.2213
2024-05-23 21:30:46 [INFO]: Epoch 045 - training loss: 40884.8762, validation loss: 0.2137
2024-05-23 21:30:47 [INFO]: Epoch 046 - training loss: 40872.8709, validation loss: 0.2131
2024-05-23 21:30:47 [INFO]: Epoch 047 - training loss: 40870.6801, validation loss: 0.2126
2024-05-23 21:30:47 [INFO]: Epoch 048 - training loss: 40868.2792, validation loss: 0.2090
2024-05-23 21:30:47 [INFO]: Epoch 049 - training loss: 40866.5072, validation loss: 0.2116
2024-05-23 21:30:48 [INFO]: Epoch 050 - training loss: 40865.7448, validation loss: 0.2123
2024-05-23 21:30:48 [INFO]: Epoch 051 - training loss: 40864.2555, validation loss: 0.2126
2024-05-23 21:30:48 [INFO]: Epoch 052 - training loss: 40873.0524, validation loss: 0.2267
2024-05-23 21:30:48 [INFO]: Epoch 053 - training loss: 40891.3472, validation loss: 0.2188
2024-05-23 21:30:49 [INFO]: Epoch 054 - training loss: 40870.9534, validation loss: 0.2104
2024-05-23 21:30:49 [INFO]: Epoch 055 - training loss: 40905.3274, validation loss: 0.2195
2024-05-23 21:30:49 [INFO]: Epoch 056 - training loss: 40990.5178, validation loss: 0.2365
2024-05-23 21:30:49 [INFO]: Epoch 057 - training loss: 40901.5091, validation loss: 0.2186
2024-05-23 21:30:50 [INFO]: Epoch 058 - training loss: 40874.2953, validation loss: 0.2123
2024-05-23 21:30:50 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:30:50 [INFO]: Finished training. The best model is from epoch#48.
2024-05-23 21:30:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/GPVAE_air_quality/20240523_T213035/GPVAE.pypots
2024-05-23 21:30:50 [INFO]: GP-VAE on Air-Quality: MAE=0.2759, MSE=0.3225
2024-05-23 21:30:50 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-23 21:30:50 [INFO]: Using the given device: cuda:0
2024-05-23 21:30:50 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240523_T213050
2024-05-23 21:30:50 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/USGAN_air_quality/20240523_T213050/tensorboard
2024-05-23 21:30:50 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-23 21:30:53 [INFO]: Epoch 001 - generator training loss: 0.4719, discriminator training loss: 0.4531, validation loss: 0.4964
2024-05-23 21:30:57 [INFO]: Epoch 002 - generator training loss: 0.0945, discriminator training loss: 0.3621, validation loss: 0.3750
2024-05-23 21:31:00 [INFO]: Epoch 003 - generator training loss: 0.0354, discriminator training loss: 0.3575, validation loss: 0.3048
2024-05-23 21:31:04 [INFO]: Epoch 004 - generator training loss: -0.0093, discriminator training loss: 0.3556, validation loss: 0.2633
2024-05-23 21:31:07 [INFO]: Epoch 005 - generator training loss: -0.0325, discriminator training loss: 0.3537, validation loss: 0.2358
2024-05-23 21:31:10 [INFO]: Epoch 006 - generator training loss: -0.0499, discriminator training loss: 0.3518, validation loss: 0.2186
2024-05-23 21:31:13 [INFO]: Epoch 007 - generator training loss: -0.0625, discriminator training loss: 0.3499, validation loss: 0.2048
2024-05-23 21:31:17 [INFO]: Epoch 008 - generator training loss: -0.0689, discriminator training loss: 0.3478, validation loss: 0.1949
2024-05-23 21:31:20 [INFO]: Epoch 009 - generator training loss: -0.0776, discriminator training loss: 0.3452, validation loss: 0.1872
2024-05-23 21:31:23 [INFO]: Epoch 010 - generator training loss: -0.0835, discriminator training loss: 0.3431, validation loss: 0.1792
2024-05-23 21:31:27 [INFO]: Epoch 011 - generator training loss: -0.0858, discriminator training loss: 0.3407, validation loss: 0.1751
2024-05-23 21:31:30 [INFO]: Epoch 012 - generator training loss: -0.0908, discriminator training loss: 0.3379, validation loss: 0.1688
2024-05-23 21:31:33 [INFO]: Epoch 013 - generator training loss: -0.0926, discriminator training loss: 0.3349, validation loss: 0.1648
2024-05-23 21:31:37 [INFO]: Epoch 014 - generator training loss: -0.0941, discriminator training loss: 0.3318, validation loss: 0.1613
2024-05-23 21:31:40 [INFO]: Epoch 015 - generator training loss: -0.0960, discriminator training loss: 0.3283, validation loss: 0.1569
2024-05-23 21:31:43 [INFO]: Epoch 016 - generator training loss: -0.0972, discriminator training loss: 0.3248, validation loss: 0.1534
2024-05-23 21:31:47 [INFO]: Epoch 017 - generator training loss: -0.0968, discriminator training loss: 0.3211, validation loss: 0.1503
2024-05-23 21:31:50 [INFO]: Epoch 018 - generator training loss: -0.0973, discriminator training loss: 0.3169, validation loss: 0.1476
2024-05-23 21:31:53 [INFO]: Epoch 019 - generator training loss: -0.0978, discriminator training loss: 0.3131, validation loss: 0.1452
2024-05-23 21:31:57 [INFO]: Epoch 020 - generator training loss: -0.0968, discriminator training loss: 0.3089, validation loss: 0.1423
2024-05-23 21:32:00 [INFO]: Epoch 021 - generator training loss: -0.0965, discriminator training loss: 0.3048, validation loss: 0.1398
2024-05-23 21:32:03 [INFO]: Epoch 022 - generator training loss: -0.0944, discriminator training loss: 0.3006, validation loss: 0.1381
2024-05-23 21:32:07 [INFO]: Epoch 023 - generator training loss: -0.0922, discriminator training loss: 0.2963, validation loss: 0.1360
2024-05-23 21:32:10 [INFO]: Epoch 024 - generator training loss: -0.0921, discriminator training loss: 0.2922, validation loss: 0.1337
2024-05-23 21:32:13 [INFO]: Epoch 025 - generator training loss: -0.0902, discriminator training loss: 0.2883, validation loss: 0.1321
2024-05-23 21:32:17 [INFO]: Epoch 026 - generator training loss: -0.0899, discriminator training loss: 0.2845, validation loss: 0.1302
2024-05-23 21:32:20 [INFO]: Epoch 027 - generator training loss: -0.0887, discriminator training loss: 0.2804, validation loss: 0.1282
2024-05-23 21:32:24 [INFO]: Epoch 028 - generator training loss: -0.0879, discriminator training loss: 0.2767, validation loss: 0.1268
2024-05-23 21:32:27 [INFO]: Epoch 029 - generator training loss: -0.0853, discriminator training loss: 0.2731, validation loss: 0.1253
2024-05-23 21:32:31 [INFO]: Epoch 030 - generator training loss: -0.0823, discriminator training loss: 0.2697, validation loss: 0.1236
2024-05-23 21:32:34 [INFO]: Epoch 031 - generator training loss: -0.0832, discriminator training loss: 0.2664, validation loss: 0.1226
2024-05-23 21:32:38 [INFO]: Epoch 032 - generator training loss: -0.0820, discriminator training loss: 0.2633, validation loss: 0.1214
2024-05-23 21:32:42 [INFO]: Epoch 033 - generator training loss: -0.0815, discriminator training loss: 0.2602, validation loss: 0.1200
2024-05-23 21:32:45 [INFO]: Epoch 034 - generator training loss: -0.0797, discriminator training loss: 0.2576, validation loss: 0.1186
2024-05-23 21:32:49 [INFO]: Epoch 035 - generator training loss: -0.0775, discriminator training loss: 0.2541, validation loss: 0.1179
2024-05-23 21:32:52 [INFO]: Epoch 036 - generator training loss: -0.0771, discriminator training loss: 0.2519, validation loss: 0.1168
2024-05-23 21:32:56 [INFO]: Epoch 037 - generator training loss: -0.0769, discriminator training loss: 0.2498, validation loss: 0.1156
2024-05-23 21:33:00 [INFO]: Epoch 038 - generator training loss: -0.0763, discriminator training loss: 0.2472, validation loss: 0.1138
2024-05-23 21:33:03 [INFO]: Epoch 039 - generator training loss: -0.0758, discriminator training loss: 0.2451, validation loss: 0.1135
2024-05-23 21:33:07 [INFO]: Epoch 040 - generator training loss: -0.0737, discriminator training loss: 0.2430, validation loss: 0.1119
2024-05-23 21:33:10 [INFO]: Epoch 041 - generator training loss: -0.0750, discriminator training loss: 0.2410, validation loss: 0.1112
2024-05-23 21:33:14 [INFO]: Epoch 042 - generator training loss: -0.0742, discriminator training loss: 0.2389, validation loss: 0.1104
2024-05-23 21:33:17 [INFO]: Epoch 043 - generator training loss: -0.0740, discriminator training loss: 0.2377, validation loss: 0.1089
2024-05-23 21:33:21 [INFO]: Epoch 044 - generator training loss: -0.0738, discriminator training loss: 0.2358, validation loss: 0.1086
2024-05-23 21:33:24 [INFO]: Epoch 045 - generator training loss: -0.0725, discriminator training loss: 0.2342, validation loss: 0.1076
2024-05-23 21:33:28 [INFO]: Epoch 046 - generator training loss: -0.0729, discriminator training loss: 0.2326, validation loss: 0.1064
2024-05-23 21:33:31 [INFO]: Epoch 047 - generator training loss: -0.0726, discriminator training loss: 0.2314, validation loss: 0.1060
2024-05-23 21:33:34 [INFO]: Epoch 048 - generator training loss: -0.0727, discriminator training loss: 0.2300, validation loss: 0.1045
2024-05-23 21:33:38 [INFO]: Epoch 049 - generator training loss: -0.0710, discriminator training loss: 0.2290, validation loss: 0.1042
2024-05-23 21:33:41 [INFO]: Epoch 050 - generator training loss: -0.0725, discriminator training loss: 0.2284, validation loss: 0.1038
2024-05-23 21:33:44 [INFO]: Epoch 051 - generator training loss: -0.0726, discriminator training loss: 0.2267, validation loss: 0.1024
2024-05-23 21:33:48 [INFO]: Epoch 052 - generator training loss: -0.0725, discriminator training loss: 0.2257, validation loss: 0.1018
2024-05-23 21:33:51 [INFO]: Epoch 053 - generator training loss: -0.0726, discriminator training loss: 0.2247, validation loss: 0.1008
2024-05-23 21:33:54 [INFO]: Epoch 054 - generator training loss: -0.0723, discriminator training loss: 0.2236, validation loss: 0.1011
2024-05-23 21:33:58 [INFO]: Epoch 055 - generator training loss: -0.0729, discriminator training loss: 0.2228, validation loss: 0.1000
2024-05-23 21:34:01 [INFO]: Epoch 056 - generator training loss: -0.0711, discriminator training loss: 0.2223, validation loss: 0.0996
2024-05-23 21:34:04 [INFO]: Epoch 057 - generator training loss: -0.0731, discriminator training loss: 0.2211, validation loss: 0.0995
2024-05-23 21:34:08 [INFO]: Epoch 058 - generator training loss: -0.0723, discriminator training loss: 0.2206, validation loss: 0.0986
2024-05-23 21:34:11 [INFO]: Epoch 059 - generator training loss: -0.0731, discriminator training loss: 0.2199, validation loss: 0.0976
2024-05-23 21:34:14 [INFO]: Epoch 060 - generator training loss: -0.0723, discriminator training loss: 0.2188, validation loss: 0.0972
2024-05-23 21:34:18 [INFO]: Epoch 061 - generator training loss: -0.0730, discriminator training loss: 0.2186, validation loss: 0.0972
2024-05-23 21:34:21 [INFO]: Epoch 062 - generator training loss: -0.0719, discriminator training loss: 0.2182, validation loss: 0.0966
2024-05-23 21:34:24 [INFO]: Epoch 063 - generator training loss: -0.0738, discriminator training loss: 0.2176, validation loss: 0.0962
2024-05-23 21:34:28 [INFO]: Epoch 064 - generator training loss: -0.0741, discriminator training loss: 0.2168, validation loss: 0.0955
2024-05-23 21:34:31 [INFO]: Epoch 065 - generator training loss: -0.0735, discriminator training loss: 0.2159, validation loss: 0.0951
2024-05-23 21:34:35 [INFO]: Epoch 066 - generator training loss: -0.0735, discriminator training loss: 0.2157, validation loss: 0.0947
2024-05-23 21:34:38 [INFO]: Epoch 067 - generator training loss: -0.0739, discriminator training loss: 0.2150, validation loss: 0.0943
2024-05-23 21:34:41 [INFO]: Epoch 068 - generator training loss: -0.0746, discriminator training loss: 0.2151, validation loss: 0.0945
2024-05-23 21:34:45 [INFO]: Epoch 069 - generator training loss: -0.0743, discriminator training loss: 0.2149, validation loss: 0.0936
2024-05-23 21:34:48 [INFO]: Epoch 070 - generator training loss: -0.0749, discriminator training loss: 0.2139, validation loss: 0.0929
2024-05-23 21:34:51 [INFO]: Epoch 071 - generator training loss: -0.0744, discriminator training loss: 0.2137, validation loss: 0.0935
2024-05-23 21:34:55 [INFO]: Epoch 072 - generator training loss: -0.0739, discriminator training loss: 0.2128, validation loss: 0.0927
2024-05-23 21:34:58 [INFO]: Epoch 073 - generator training loss: -0.0749, discriminator training loss: 0.2131, validation loss: 0.0928
2024-05-23 21:35:01 [INFO]: Epoch 074 - generator training loss: -0.0740, discriminator training loss: 0.2122, validation loss: 0.0921
2024-05-23 21:35:05 [INFO]: Epoch 075 - generator training loss: -0.0748, discriminator training loss: 0.2119, validation loss: 0.0918
2024-05-23 21:35:08 [INFO]: Epoch 076 - generator training loss: -0.0758, discriminator training loss: 0.2115, validation loss: 0.0916
2024-05-23 21:35:11 [INFO]: Epoch 077 - generator training loss: -0.0755, discriminator training loss: 0.2115, validation loss: 0.0910
2024-05-23 21:35:15 [INFO]: Epoch 078 - generator training loss: -0.0753, discriminator training loss: 0.2110, validation loss: 0.0908
2024-05-23 21:35:18 [INFO]: Epoch 079 - generator training loss: -0.0764, discriminator training loss: 0.2111, validation loss: 0.0908
2024-05-23 21:35:21 [INFO]: Epoch 080 - generator training loss: -0.0757, discriminator training loss: 0.2103, validation loss: 0.0909
2024-05-23 21:35:25 [INFO]: Epoch 081 - generator training loss: -0.0760, discriminator training loss: 0.2106, validation loss: 0.0905
2024-05-23 21:35:28 [INFO]: Epoch 082 - generator training loss: -0.0761, discriminator training loss: 0.2103, validation loss: 0.0904
2024-05-23 21:35:31 [INFO]: Epoch 083 - generator training loss: -0.0767, discriminator training loss: 0.2098, validation loss: 0.0905
2024-05-23 21:35:35 [INFO]: Epoch 084 - generator training loss: -0.0765, discriminator training loss: 0.2095, validation loss: 0.0903
2024-05-23 21:35:38 [INFO]: Epoch 085 - generator training loss: -0.0768, discriminator training loss: 0.2091, validation loss: 0.0902
2024-05-23 21:35:41 [INFO]: Epoch 086 - generator training loss: -0.0770, discriminator training loss: 0.2091, validation loss: 0.0899
2024-05-23 21:35:45 [INFO]: Epoch 087 - generator training loss: -0.0773, discriminator training loss: 0.2088, validation loss: 0.0893
2024-05-23 21:35:48 [INFO]: Epoch 088 - generator training loss: -0.0780, discriminator training loss: 0.2087, validation loss: 0.0895
2024-05-23 21:35:51 [INFO]: Epoch 089 - generator training loss: -0.0774, discriminator training loss: 0.2084, validation loss: 0.0895
2024-05-23 21:35:55 [INFO]: Epoch 090 - generator training loss: -0.0779, discriminator training loss: 0.2083, validation loss: 0.0890
2024-05-23 21:35:58 [INFO]: Epoch 091 - generator training loss: -0.0781, discriminator training loss: 0.2080, validation loss: 0.0890
2024-05-23 21:36:02 [INFO]: Epoch 092 - generator training loss: -0.0775, discriminator training loss: 0.2078, validation loss: 0.0888
2024-05-23 21:36:05 [INFO]: Epoch 093 - generator training loss: -0.0783, discriminator training loss: 0.2073, validation loss: 0.0886
2024-05-23 21:36:08 [INFO]: Epoch 094 - generator training loss: -0.0784, discriminator training loss: 0.2074, validation loss: 0.0883
2024-05-23 21:36:12 [INFO]: Epoch 095 - generator training loss: -0.0779, discriminator training loss: 0.2069, validation loss: 0.0893
2024-05-23 21:36:15 [INFO]: Epoch 096 - generator training loss: -0.0786, discriminator training loss: 0.2066, validation loss: 0.0881
2024-05-23 21:36:18 [INFO]: Epoch 097 - generator training loss: -0.0791, discriminator training loss: 0.2071, validation loss: 0.0888
2024-05-23 21:36:22 [INFO]: Epoch 098 - generator training loss: -0.0789, discriminator training loss: 0.2060, validation loss: 0.0880
2024-05-23 21:36:25 [INFO]: Epoch 099 - generator training loss: -0.0802, discriminator training loss: 0.2065, validation loss: 0.0885
2024-05-23 21:36:29 [INFO]: Epoch 100 - generator training loss: -0.0793, discriminator training loss: 0.2063, validation loss: 0.0879
2024-05-23 21:36:32 [INFO]: Epoch 101 - generator training loss: -0.0788, discriminator training loss: 0.2063, validation loss: 0.0881
2024-05-23 21:36:35 [INFO]: Epoch 102 - generator training loss: -0.0795, discriminator training loss: 0.2063, validation loss: 0.0882
2024-05-23 21:36:39 [INFO]: Epoch 103 - generator training loss: -0.0796, discriminator training loss: 0.2057, validation loss: 0.0877
2024-05-23 21:36:42 [INFO]: Epoch 104 - generator training loss: -0.0801, discriminator training loss: 0.2053, validation loss: 0.0877
2024-05-23 21:36:45 [INFO]: Epoch 105 - generator training loss: -0.0801, discriminator training loss: 0.2057, validation loss: 0.0876
2024-05-23 21:36:49 [INFO]: Epoch 106 - generator training loss: -0.0803, discriminator training loss: 0.2056, validation loss: 0.0879
2024-05-23 21:36:52 [INFO]: Epoch 107 - generator training loss: -0.0806, discriminator training loss: 0.2053, validation loss: 0.0875
2024-05-23 21:36:56 [INFO]: Epoch 108 - generator training loss: -0.0812, discriminator training loss: 0.2054, validation loss: 0.0875
2024-05-23 21:36:59 [INFO]: Epoch 109 - generator training loss: -0.0788, discriminator training loss: 0.2049, validation loss: 0.0891
2024-05-23 21:37:02 [INFO]: Epoch 110 - generator training loss: -0.0791, discriminator training loss: 0.2048, validation loss: 0.0878
2024-05-23 21:37:06 [INFO]: Epoch 111 - generator training loss: -0.0810, discriminator training loss: 0.2046, validation loss: 0.0870
2024-05-23 21:37:09 [INFO]: Epoch 112 - generator training loss: -0.0820, discriminator training loss: 0.2048, validation loss: 0.0872
2024-05-23 21:37:12 [INFO]: Epoch 113 - generator training loss: -0.0818, discriminator training loss: 0.2042, validation loss: 0.0871
2024-05-23 21:37:16 [INFO]: Epoch 114 - generator training loss: -0.0817, discriminator training loss: 0.2046, validation loss: 0.0872
2024-05-23 21:37:19 [INFO]: Epoch 115 - generator training loss: -0.0815, discriminator training loss: 0.2042, validation loss: 0.0869
2024-05-23 21:37:23 [INFO]: Epoch 116 - generator training loss: -0.0815, discriminator training loss: 0.2044, validation loss: 0.0865
2024-05-23 21:37:26 [INFO]: Epoch 117 - generator training loss: -0.0823, discriminator training loss: 0.2040, validation loss: 0.0868
2024-05-23 21:37:29 [INFO]: Epoch 118 - generator training loss: -0.0834, discriminator training loss: 0.2041, validation loss: 0.0864
2024-05-23 21:37:33 [INFO]: Epoch 119 - generator training loss: -0.0827, discriminator training loss: 0.2038, validation loss: 0.0864
2024-05-23 21:37:36 [INFO]: Epoch 120 - generator training loss: -0.0834, discriminator training loss: 0.2038, validation loss: 0.0865
2024-05-23 21:37:39 [INFO]: Epoch 121 - generator training loss: -0.0835, discriminator training loss: 0.2038, validation loss: 0.0861
2024-05-23 21:37:43 [INFO]: Epoch 122 - generator training loss: -0.0840, discriminator training loss: 0.2037, validation loss: 0.0862
2024-05-23 21:37:46 [INFO]: Epoch 123 - generator training loss: -0.0828, discriminator training loss: 0.2033, validation loss: 0.0870
2024-05-23 21:37:50 [INFO]: Epoch 124 - generator training loss: -0.0826, discriminator training loss: 0.2035, validation loss: 0.0862
2024-05-23 21:37:53 [INFO]: Epoch 125 - generator training loss: -0.0835, discriminator training loss: 0.2032, validation loss: 0.0863
2024-05-23 21:37:56 [INFO]: Epoch 126 - generator training loss: -0.0831, discriminator training loss: 0.2036, validation loss: 0.0873
2024-05-23 21:38:00 [INFO]: Epoch 127 - generator training loss: -0.0833, discriminator training loss: 0.2029, validation loss: 0.0863
2024-05-23 21:38:03 [INFO]: Epoch 128 - generator training loss: -0.0833, discriminator training loss: 0.2031, validation loss: 0.0864
2024-05-23 21:38:07 [INFO]: Epoch 129 - generator training loss: -0.0843, discriminator training loss: 0.2028, validation loss: 0.0862
2024-05-23 21:38:10 [INFO]: Epoch 130 - generator training loss: -0.0842, discriminator training loss: 0.2027, validation loss: 0.0863
2024-05-23 21:38:13 [INFO]: Epoch 131 - generator training loss: -0.0842, discriminator training loss: 0.2024, validation loss: 0.0862
2024-05-23 21:38:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:38:13 [INFO]: Finished training. The best model is from epoch#121.
2024-05-23 21:38:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/USGAN_air_quality/20240523_T213050/USGAN.pypots
2024-05-23 21:38:14 [INFO]: US-GAN on Air-Quality: MAE=0.1516, MSE=0.1537
2024-05-23 21:38:14 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-23 21:38:14 [INFO]: Using the given device: cuda:0
2024-05-23 21:38:14 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240523_T213814
2024-05-23 21:38:14 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/BRITS_air_quality/20240523_T213814/tensorboard
2024-05-23 21:38:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-23 21:38:17 [INFO]: Epoch 001 - training loss: 1.4133, validation loss: 0.9115
2024-05-23 21:38:19 [INFO]: Epoch 002 - training loss: 1.1468, validation loss: 0.6690
2024-05-23 21:38:21 [INFO]: Epoch 003 - training loss: 0.9546, validation loss: 0.5640
2024-05-23 21:38:23 [INFO]: Epoch 004 - training loss: 0.8434, validation loss: 0.4952
2024-05-23 21:38:26 [INFO]: Epoch 005 - training loss: 0.7691, validation loss: 0.4492
2024-05-23 21:38:28 [INFO]: Epoch 006 - training loss: 0.7132, validation loss: 0.4123
2024-05-23 21:38:30 [INFO]: Epoch 007 - training loss: 0.6715, validation loss: 0.3821
2024-05-23 21:38:33 [INFO]: Epoch 008 - training loss: 0.6373, validation loss: 0.3580
2024-05-23 21:38:35 [INFO]: Epoch 009 - training loss: 0.6116, validation loss: 0.3381
2024-05-23 21:38:37 [INFO]: Epoch 010 - training loss: 0.5898, validation loss: 0.3223
2024-05-23 21:38:40 [INFO]: Epoch 011 - training loss: 0.5722, validation loss: 0.3092
2024-05-23 21:38:42 [INFO]: Epoch 012 - training loss: 0.5599, validation loss: 0.2970
2024-05-23 21:38:45 [INFO]: Epoch 013 - training loss: 0.5450, validation loss: 0.2870
2024-05-23 21:38:47 [INFO]: Epoch 014 - training loss: 0.5323, validation loss: 0.2779
2024-05-23 21:38:49 [INFO]: Epoch 015 - training loss: 0.5230, validation loss: 0.2708
2024-05-23 21:38:52 [INFO]: Epoch 016 - training loss: 0.5121, validation loss: 0.2627
2024-05-23 21:38:54 [INFO]: Epoch 017 - training loss: 0.5031, validation loss: 0.2560
2024-05-23 21:38:57 [INFO]: Epoch 018 - training loss: 0.4945, validation loss: 0.2504
2024-05-23 21:38:59 [INFO]: Epoch 019 - training loss: 0.4877, validation loss: 0.2445
2024-05-23 21:39:01 [INFO]: Epoch 020 - training loss: 0.4800, validation loss: 0.2393
2024-05-23 21:39:04 [INFO]: Epoch 021 - training loss: 0.4722, validation loss: 0.2346
2024-05-23 21:39:06 [INFO]: Epoch 022 - training loss: 0.4649, validation loss: 0.2306
2024-05-23 21:39:09 [INFO]: Epoch 023 - training loss: 0.4590, validation loss: 0.2264
2024-05-23 21:39:11 [INFO]: Epoch 024 - training loss: 0.4525, validation loss: 0.2223
2024-05-23 21:39:13 [INFO]: Epoch 025 - training loss: 0.4469, validation loss: 0.2185
2024-05-23 21:39:16 [INFO]: Epoch 026 - training loss: 0.4426, validation loss: 0.2149
2024-05-23 21:39:18 [INFO]: Epoch 027 - training loss: 0.4362, validation loss: 0.2104
2024-05-23 21:39:21 [INFO]: Epoch 028 - training loss: 0.4301, validation loss: 0.2074
2024-05-23 21:39:23 [INFO]: Epoch 029 - training loss: 0.4263, validation loss: 0.2037
2024-05-23 21:39:25 [INFO]: Epoch 030 - training loss: 0.4200, validation loss: 0.2005
2024-05-23 21:39:28 [INFO]: Epoch 031 - training loss: 0.4161, validation loss: 0.1977
2024-05-23 21:39:30 [INFO]: Epoch 032 - training loss: 0.4125, validation loss: 0.1946
2024-05-23 21:39:33 [INFO]: Epoch 033 - training loss: 0.4069, validation loss: 0.1915
2024-05-23 21:39:35 [INFO]: Epoch 034 - training loss: 0.4040, validation loss: 0.1888
2024-05-23 21:39:37 [INFO]: Epoch 035 - training loss: 0.3995, validation loss: 0.1863
2024-05-23 21:39:40 [INFO]: Epoch 036 - training loss: 0.3955, validation loss: 0.1839
2024-05-23 21:39:42 [INFO]: Epoch 037 - training loss: 0.3915, validation loss: 0.1813
2024-05-23 21:39:44 [INFO]: Epoch 038 - training loss: 0.3884, validation loss: 0.1788
2024-05-23 21:39:47 [INFO]: Epoch 039 - training loss: 0.3856, validation loss: 0.1766
2024-05-23 21:39:49 [INFO]: Epoch 040 - training loss: 0.3808, validation loss: 0.1743
2024-05-23 21:39:52 [INFO]: Epoch 041 - training loss: 0.3777, validation loss: 0.1723
2024-05-23 21:39:54 [INFO]: Epoch 042 - training loss: 0.3755, validation loss: 0.1704
2024-05-23 21:39:56 [INFO]: Epoch 043 - training loss: 0.3722, validation loss: 0.1687
2024-05-23 21:39:59 [INFO]: Epoch 044 - training loss: 0.3694, validation loss: 0.1666
2024-05-23 21:40:01 [INFO]: Epoch 045 - training loss: 0.3678, validation loss: 0.1648
2024-05-23 21:40:04 [INFO]: Epoch 046 - training loss: 0.3636, validation loss: 0.1632
2024-05-23 21:40:06 [INFO]: Epoch 047 - training loss: 0.3611, validation loss: 0.1619
2024-05-23 21:40:08 [INFO]: Epoch 048 - training loss: 0.3585, validation loss: 0.1603
2024-05-23 21:40:11 [INFO]: Epoch 049 - training loss: 0.3566, validation loss: 0.1588
2024-05-23 21:40:13 [INFO]: Epoch 050 - training loss: 0.3535, validation loss: 0.1574
2024-05-23 21:40:16 [INFO]: Epoch 051 - training loss: 0.3519, validation loss: 0.1561
2024-05-23 21:40:18 [INFO]: Epoch 052 - training loss: 0.3499, validation loss: 0.1549
2024-05-23 21:40:20 [INFO]: Epoch 053 - training loss: 0.3470, validation loss: 0.1535
2024-05-23 21:40:23 [INFO]: Epoch 054 - training loss: 0.3453, validation loss: 0.1525
2024-05-23 21:40:25 [INFO]: Epoch 055 - training loss: 0.3437, validation loss: 0.1512
2024-05-23 21:40:28 [INFO]: Epoch 056 - training loss: 0.3412, validation loss: 0.1502
2024-05-23 21:40:30 [INFO]: Epoch 057 - training loss: 0.3399, validation loss: 0.1495
2024-05-23 21:40:32 [INFO]: Epoch 058 - training loss: 0.3381, validation loss: 0.1484
2024-05-23 21:40:35 [INFO]: Epoch 059 - training loss: 0.3366, validation loss: 0.1474
2024-05-23 21:40:37 [INFO]: Epoch 060 - training loss: 0.3346, validation loss: 0.1465
2024-05-23 21:40:40 [INFO]: Epoch 061 - training loss: 0.3329, validation loss: 0.1456
2024-05-23 21:40:42 [INFO]: Epoch 062 - training loss: 0.3305, validation loss: 0.1447
2024-05-23 21:40:44 [INFO]: Epoch 063 - training loss: 0.3299, validation loss: 0.1440
2024-05-23 21:40:47 [INFO]: Epoch 064 - training loss: 0.3282, validation loss: 0.1432
2024-05-23 21:40:49 [INFO]: Epoch 065 - training loss: 0.3265, validation loss: 0.1425
2024-05-23 21:40:51 [INFO]: Epoch 066 - training loss: 0.3255, validation loss: 0.1417
2024-05-23 21:40:53 [INFO]: Epoch 067 - training loss: 0.3243, validation loss: 0.1409
2024-05-23 21:40:56 [INFO]: Epoch 068 - training loss: 0.3221, validation loss: 0.1405
2024-05-23 21:40:58 [INFO]: Epoch 069 - training loss: 0.3209, validation loss: 0.1396
2024-05-23 21:41:00 [INFO]: Epoch 070 - training loss: 0.3203, validation loss: 0.1391
2024-05-23 21:41:02 [INFO]: Epoch 071 - training loss: 0.3182, validation loss: 0.1384
2024-05-23 21:41:05 [INFO]: Epoch 072 - training loss: 0.3169, validation loss: 0.1378
2024-05-23 21:41:07 [INFO]: Epoch 073 - training loss: 0.3167, validation loss: 0.1372
2024-05-23 21:41:09 [INFO]: Epoch 074 - training loss: 0.3149, validation loss: 0.1365
2024-05-23 21:41:11 [INFO]: Epoch 075 - training loss: 0.3138, validation loss: 0.1361
2024-05-23 21:41:14 [INFO]: Epoch 076 - training loss: 0.3124, validation loss: 0.1355
2024-05-23 21:41:16 [INFO]: Epoch 077 - training loss: 0.3125, validation loss: 0.1349
2024-05-23 21:41:18 [INFO]: Epoch 078 - training loss: 0.3106, validation loss: 0.1344
2024-05-23 21:41:20 [INFO]: Epoch 079 - training loss: 0.3108, validation loss: 0.1338
2024-05-23 21:41:23 [INFO]: Epoch 080 - training loss: 0.3094, validation loss: 0.1334
2024-05-23 21:41:25 [INFO]: Epoch 081 - training loss: 0.3087, validation loss: 0.1330
2024-05-23 21:41:27 [INFO]: Epoch 082 - training loss: 0.3072, validation loss: 0.1325
2024-05-23 21:41:29 [INFO]: Epoch 083 - training loss: 0.3060, validation loss: 0.1318
2024-05-23 21:41:32 [INFO]: Epoch 084 - training loss: 0.3062, validation loss: 0.1313
2024-05-23 21:41:34 [INFO]: Epoch 085 - training loss: 0.3047, validation loss: 0.1309
2024-05-23 21:41:36 [INFO]: Epoch 086 - training loss: 0.3034, validation loss: 0.1302
2024-05-23 21:41:39 [INFO]: Epoch 087 - training loss: 0.3027, validation loss: 0.1299
2024-05-23 21:41:41 [INFO]: Epoch 088 - training loss: 0.3022, validation loss: 0.1294
2024-05-23 21:41:43 [INFO]: Epoch 089 - training loss: 0.3011, validation loss: 0.1290
2024-05-23 21:41:45 [INFO]: Epoch 090 - training loss: 0.3005, validation loss: 0.1285
2024-05-23 21:41:47 [INFO]: Epoch 091 - training loss: 0.3002, validation loss: 0.1282
2024-05-23 21:41:50 [INFO]: Epoch 092 - training loss: 0.2986, validation loss: 0.1277
2024-05-23 21:41:52 [INFO]: Epoch 093 - training loss: 0.2984, validation loss: 0.1271
2024-05-23 21:41:54 [INFO]: Epoch 094 - training loss: 0.2976, validation loss: 0.1268
2024-05-23 21:41:57 [INFO]: Epoch 095 - training loss: 0.2972, validation loss: 0.1264
2024-05-23 21:41:59 [INFO]: Epoch 096 - training loss: 0.2958, validation loss: 0.1260
2024-05-23 21:42:01 [INFO]: Epoch 097 - training loss: 0.2956, validation loss: 0.1258
2024-05-23 21:42:03 [INFO]: Epoch 098 - training loss: 0.2942, validation loss: 0.1252
2024-05-23 21:42:06 [INFO]: Epoch 099 - training loss: 0.2943, validation loss: 0.1249
2024-05-23 21:42:08 [INFO]: Epoch 100 - training loss: 0.2937, validation loss: 0.1245
2024-05-23 21:42:10 [INFO]: Epoch 101 - training loss: 0.2925, validation loss: 0.1240
2024-05-23 21:42:12 [INFO]: Epoch 102 - training loss: 0.2919, validation loss: 0.1238
2024-05-23 21:42:15 [INFO]: Epoch 103 - training loss: 0.2913, validation loss: 0.1234
2024-05-23 21:42:17 [INFO]: Epoch 104 - training loss: 0.2909, validation loss: 0.1231
2024-05-23 21:42:19 [INFO]: Epoch 105 - training loss: 0.2909, validation loss: 0.1225
2024-05-23 21:42:21 [INFO]: Epoch 106 - training loss: 0.2896, validation loss: 0.1222
2024-05-23 21:42:24 [INFO]: Epoch 107 - training loss: 0.2894, validation loss: 0.1220
2024-05-23 21:42:26 [INFO]: Epoch 108 - training loss: 0.2893, validation loss: 0.1215
2024-05-23 21:42:28 [INFO]: Epoch 109 - training loss: 0.2876, validation loss: 0.1213
2024-05-23 21:42:30 [INFO]: Epoch 110 - training loss: 0.2872, validation loss: 0.1209
2024-05-23 21:42:33 [INFO]: Epoch 111 - training loss: 0.2874, validation loss: 0.1204
2024-05-23 21:42:35 [INFO]: Epoch 112 - training loss: 0.2860, validation loss: 0.1202
2024-05-23 21:42:37 [INFO]: Epoch 113 - training loss: 0.2857, validation loss: 0.1198
2024-05-23 21:42:39 [INFO]: Epoch 114 - training loss: 0.2856, validation loss: 0.1194
2024-05-23 21:42:42 [INFO]: Epoch 115 - training loss: 0.2858, validation loss: 0.1192
2024-05-23 21:42:44 [INFO]: Epoch 116 - training loss: 0.2840, validation loss: 0.1192
2024-05-23 21:42:46 [INFO]: Epoch 117 - training loss: 0.2838, validation loss: 0.1187
2024-05-23 21:42:48 [INFO]: Epoch 118 - training loss: 0.2834, validation loss: 0.1183
2024-05-23 21:42:51 [INFO]: Epoch 119 - training loss: 0.2825, validation loss: 0.1181
2024-05-23 21:42:53 [INFO]: Epoch 120 - training loss: 0.2823, validation loss: 0.1178
2024-05-23 21:42:55 [INFO]: Epoch 121 - training loss: 0.2816, validation loss: 0.1174
2024-05-23 21:42:57 [INFO]: Epoch 122 - training loss: 0.2806, validation loss: 0.1172
2024-05-23 21:43:00 [INFO]: Epoch 123 - training loss: 0.2809, validation loss: 0.1170
2024-05-23 21:43:02 [INFO]: Epoch 124 - training loss: 0.2805, validation loss: 0.1166
2024-05-23 21:43:04 [INFO]: Epoch 125 - training loss: 0.2798, validation loss: 0.1162
2024-05-23 21:43:06 [INFO]: Epoch 126 - training loss: 0.2796, validation loss: 0.1162
2024-05-23 21:43:09 [INFO]: Epoch 127 - training loss: 0.2788, validation loss: 0.1157
2024-05-23 21:43:11 [INFO]: Epoch 128 - training loss: 0.2784, validation loss: 0.1154
2024-05-23 21:43:13 [INFO]: Epoch 129 - training loss: 0.2783, validation loss: 0.1152
2024-05-23 21:43:15 [INFO]: Epoch 130 - training loss: 0.2772, validation loss: 0.1148
2024-05-23 21:43:18 [INFO]: Epoch 131 - training loss: 0.2768, validation loss: 0.1147
2024-05-23 21:43:20 [INFO]: Epoch 132 - training loss: 0.2771, validation loss: 0.1145
2024-05-23 21:43:22 [INFO]: Epoch 133 - training loss: 0.2766, validation loss: 0.1142
2024-05-23 21:43:24 [INFO]: Epoch 134 - training loss: 0.2755, validation loss: 0.1140
2024-05-23 21:43:27 [INFO]: Epoch 135 - training loss: 0.2750, validation loss: 0.1135
2024-05-23 21:43:29 [INFO]: Epoch 136 - training loss: 0.2756, validation loss: 0.1135
2024-05-23 21:43:31 [INFO]: Epoch 137 - training loss: 0.2744, validation loss: 0.1131
2024-05-23 21:43:33 [INFO]: Epoch 138 - training loss: 0.2744, validation loss: 0.1129
2024-05-23 21:43:36 [INFO]: Epoch 139 - training loss: 0.2736, validation loss: 0.1127
2024-05-23 21:43:38 [INFO]: Epoch 140 - training loss: 0.2743, validation loss: 0.1123
2024-05-23 21:43:40 [INFO]: Epoch 141 - training loss: 0.2743, validation loss: 0.1121
2024-05-23 21:43:42 [INFO]: Epoch 142 - training loss: 0.2724, validation loss: 0.1120
2024-05-23 21:43:45 [INFO]: Epoch 143 - training loss: 0.2726, validation loss: 0.1117
2024-05-23 21:43:47 [INFO]: Epoch 144 - training loss: 0.2721, validation loss: 0.1113
2024-05-23 21:43:49 [INFO]: Epoch 145 - training loss: 0.2715, validation loss: 0.1113
2024-05-23 21:43:51 [INFO]: Epoch 146 - training loss: 0.2712, validation loss: 0.1110
2024-05-23 21:43:54 [INFO]: Epoch 147 - training loss: 0.2711, validation loss: 0.1107
2024-05-23 21:43:56 [INFO]: Epoch 148 - training loss: 0.2711, validation loss: 0.1104
2024-05-23 21:43:58 [INFO]: Epoch 149 - training loss: 0.2707, validation loss: 0.1104
2024-05-23 21:44:00 [INFO]: Epoch 150 - training loss: 0.2699, validation loss: 0.1101
2024-05-23 21:44:03 [INFO]: Epoch 151 - training loss: 0.2695, validation loss: 0.1096
2024-05-23 21:44:05 [INFO]: Epoch 152 - training loss: 0.2694, validation loss: 0.1097
2024-05-23 21:44:07 [INFO]: Epoch 153 - training loss: 0.2686, validation loss: 0.1095
2024-05-23 21:44:09 [INFO]: Epoch 154 - training loss: 0.2686, validation loss: 0.1094
2024-05-23 21:44:12 [INFO]: Epoch 155 - training loss: 0.2687, validation loss: 0.1090
2024-05-23 21:44:14 [INFO]: Epoch 156 - training loss: 0.2679, validation loss: 0.1088
2024-05-23 21:44:16 [INFO]: Epoch 157 - training loss: 0.2676, validation loss: 0.1086
2024-05-23 21:44:18 [INFO]: Epoch 158 - training loss: 0.2676, validation loss: 0.1083
2024-05-23 21:44:21 [INFO]: Epoch 159 - training loss: 0.2669, validation loss: 0.1082
2024-05-23 21:44:23 [INFO]: Epoch 160 - training loss: 0.2665, validation loss: 0.1078
2024-05-23 21:44:25 [INFO]: Epoch 161 - training loss: 0.2665, validation loss: 0.1077
2024-05-23 21:44:28 [INFO]: Epoch 162 - training loss: 0.2655, validation loss: 0.1076
2024-05-23 21:44:30 [INFO]: Epoch 163 - training loss: 0.2662, validation loss: 0.1074
2024-05-23 21:44:32 [INFO]: Epoch 164 - training loss: 0.2658, validation loss: 0.1070
2024-05-23 21:44:34 [INFO]: Epoch 165 - training loss: 0.2651, validation loss: 0.1070
2024-05-23 21:44:37 [INFO]: Epoch 166 - training loss: 0.2653, validation loss: 0.1069
2024-05-23 21:44:39 [INFO]: Epoch 167 - training loss: 0.2650, validation loss: 0.1065
2024-05-23 21:44:41 [INFO]: Epoch 168 - training loss: 0.2643, validation loss: 0.1064
2024-05-23 21:44:43 [INFO]: Epoch 169 - training loss: 0.2640, validation loss: 0.1064
2024-05-23 21:44:46 [INFO]: Epoch 170 - training loss: 0.2643, validation loss: 0.1060
2024-05-23 21:44:48 [INFO]: Epoch 171 - training loss: 0.2645, validation loss: 0.1058
2024-05-23 21:44:50 [INFO]: Epoch 172 - training loss: 0.2631, validation loss: 0.1058
2024-05-23 21:44:52 [INFO]: Epoch 173 - training loss: 0.2634, validation loss: 0.1055
2024-05-23 21:44:55 [INFO]: Epoch 174 - training loss: 0.2629, validation loss: 0.1054
2024-05-23 21:44:57 [INFO]: Epoch 175 - training loss: 0.2631, validation loss: 0.1053
2024-05-23 21:44:59 [INFO]: Epoch 176 - training loss: 0.2618, validation loss: 0.1049
2024-05-23 21:45:01 [INFO]: Epoch 177 - training loss: 0.2625, validation loss: 0.1049
2024-05-23 21:45:04 [INFO]: Epoch 178 - training loss: 0.2619, validation loss: 0.1048
2024-05-23 21:45:06 [INFO]: Epoch 179 - training loss: 0.2612, validation loss: 0.1045
2024-05-23 21:45:08 [INFO]: Epoch 180 - training loss: 0.2614, validation loss: 0.1044
2024-05-23 21:45:10 [INFO]: Epoch 181 - training loss: 0.2608, validation loss: 0.1042
2024-05-23 21:45:13 [INFO]: Epoch 182 - training loss: 0.2609, validation loss: 0.1041
2024-05-23 21:45:15 [INFO]: Epoch 183 - training loss: 0.2608, validation loss: 0.1041
2024-05-23 21:45:17 [INFO]: Epoch 184 - training loss: 0.2603, validation loss: 0.1037
2024-05-23 21:45:19 [INFO]: Epoch 185 - training loss: 0.2603, validation loss: 0.1036
2024-05-23 21:45:22 [INFO]: Epoch 186 - training loss: 0.2594, validation loss: 0.1033
2024-05-23 21:45:24 [INFO]: Epoch 187 - training loss: 0.2594, validation loss: 0.1032
2024-05-23 21:45:26 [INFO]: Epoch 188 - training loss: 0.2592, validation loss: 0.1030
2024-05-23 21:45:28 [INFO]: Epoch 189 - training loss: 0.2594, validation loss: 0.1030
2024-05-23 21:45:31 [INFO]: Epoch 190 - training loss: 0.2587, validation loss: 0.1029
2024-05-23 21:45:33 [INFO]: Epoch 191 - training loss: 0.2583, validation loss: 0.1028
2024-05-23 21:45:35 [INFO]: Epoch 192 - training loss: 0.2585, validation loss: 0.1025
2024-05-23 21:45:37 [INFO]: Epoch 193 - training loss: 0.2578, validation loss: 0.1024
2024-05-23 21:45:40 [INFO]: Epoch 194 - training loss: 0.2577, validation loss: 0.1024
2024-05-23 21:45:42 [INFO]: Epoch 195 - training loss: 0.2579, validation loss: 0.1022
2024-05-23 21:45:44 [INFO]: Epoch 196 - training loss: 0.2575, validation loss: 0.1021
2024-05-23 21:45:47 [INFO]: Epoch 197 - training loss: 0.2570, validation loss: 0.1019
2024-05-23 21:45:49 [INFO]: Epoch 198 - training loss: 0.2566, validation loss: 0.1016
2024-05-23 21:45:51 [INFO]: Epoch 199 - training loss: 0.2575, validation loss: 0.1017
2024-05-23 21:45:53 [INFO]: Epoch 200 - training loss: 0.2569, validation loss: 0.1014
2024-05-23 21:45:56 [INFO]: Epoch 201 - training loss: 0.2569, validation loss: 0.1015
2024-05-23 21:45:58 [INFO]: Epoch 202 - training loss: 0.2558, validation loss: 0.1013
2024-05-23 21:46:00 [INFO]: Epoch 203 - training loss: 0.2562, validation loss: 0.1011
2024-05-23 21:46:02 [INFO]: Epoch 204 - training loss: 0.2556, validation loss: 0.1010
2024-05-23 21:46:05 [INFO]: Epoch 205 - training loss: 0.2556, validation loss: 0.1007
2024-05-23 21:46:07 [INFO]: Epoch 206 - training loss: 0.2557, validation loss: 0.1009
2024-05-23 21:46:09 [INFO]: Epoch 207 - training loss: 0.2550, validation loss: 0.1007
2024-05-23 21:46:11 [INFO]: Epoch 208 - training loss: 0.2553, validation loss: 0.1005
2024-05-23 21:46:14 [INFO]: Epoch 209 - training loss: 0.2547, validation loss: 0.1004
2024-05-23 21:46:16 [INFO]: Epoch 210 - training loss: 0.2543, validation loss: 0.1003
2024-05-23 21:46:18 [INFO]: Epoch 211 - training loss: 0.2544, validation loss: 0.1002
2024-05-23 21:46:20 [INFO]: Epoch 212 - training loss: 0.2542, validation loss: 0.1001
2024-05-23 21:46:23 [INFO]: Epoch 213 - training loss: 0.2540, validation loss: 0.0999
2024-05-23 21:46:25 [INFO]: Epoch 214 - training loss: 0.2538, validation loss: 0.0998
2024-05-23 21:46:27 [INFO]: Epoch 215 - training loss: 0.2537, validation loss: 0.0996
2024-05-23 21:46:29 [INFO]: Epoch 216 - training loss: 0.2535, validation loss: 0.0996
2024-05-23 21:46:32 [INFO]: Epoch 217 - training loss: 0.2529, validation loss: 0.0996
2024-05-23 21:46:34 [INFO]: Epoch 218 - training loss: 0.2532, validation loss: 0.0992
2024-05-23 21:46:36 [INFO]: Epoch 219 - training loss: 0.2528, validation loss: 0.0993
2024-05-23 21:46:38 [INFO]: Epoch 220 - training loss: 0.2526, validation loss: 0.0991
2024-05-23 21:46:41 [INFO]: Epoch 221 - training loss: 0.2525, validation loss: 0.0991
2024-05-23 21:46:43 [INFO]: Epoch 222 - training loss: 0.2525, validation loss: 0.0991
2024-05-23 21:46:45 [INFO]: Epoch 223 - training loss: 0.2523, validation loss: 0.0990
2024-05-23 21:46:47 [INFO]: Epoch 224 - training loss: 0.2519, validation loss: 0.0988
2024-05-23 21:46:50 [INFO]: Epoch 225 - training loss: 0.2517, validation loss: 0.0987
2024-05-23 21:46:52 [INFO]: Epoch 226 - training loss: 0.2514, validation loss: 0.0985
2024-05-23 21:46:54 [INFO]: Epoch 227 - training loss: 0.2510, validation loss: 0.0986
2024-05-23 21:46:56 [INFO]: Epoch 228 - training loss: 0.2509, validation loss: 0.0983
2024-05-23 21:46:59 [INFO]: Epoch 229 - training loss: 0.2512, validation loss: 0.0983
2024-05-23 21:47:01 [INFO]: Epoch 230 - training loss: 0.2507, validation loss: 0.0983
2024-05-23 21:47:03 [INFO]: Epoch 231 - training loss: 0.2510, validation loss: 0.0980
2024-05-23 21:47:05 [INFO]: Epoch 232 - training loss: 0.2510, validation loss: 0.0982
2024-05-23 21:47:08 [INFO]: Epoch 233 - training loss: 0.2500, validation loss: 0.0979
2024-05-23 21:47:10 [INFO]: Epoch 234 - training loss: 0.2499, validation loss: 0.0979
2024-05-23 21:47:12 [INFO]: Epoch 235 - training loss: 0.2503, validation loss: 0.0978
2024-05-23 21:47:14 [INFO]: Epoch 236 - training loss: 0.2496, validation loss: 0.0978
2024-05-23 21:47:17 [INFO]: Epoch 237 - training loss: 0.2497, validation loss: 0.0978
2024-05-23 21:47:19 [INFO]: Epoch 238 - training loss: 0.2497, validation loss: 0.0978
2024-05-23 21:47:21 [INFO]: Epoch 239 - training loss: 0.2491, validation loss: 0.0977
2024-05-23 21:47:23 [INFO]: Epoch 240 - training loss: 0.2486, validation loss: 0.0976
2024-05-23 21:47:26 [INFO]: Epoch 241 - training loss: 0.2488, validation loss: 0.0974
2024-05-23 21:47:28 [INFO]: Epoch 242 - training loss: 0.2491, validation loss: 0.0973
2024-05-23 21:47:30 [INFO]: Epoch 243 - training loss: 0.2484, validation loss: 0.0972
2024-05-23 21:47:32 [INFO]: Epoch 244 - training loss: 0.2486, validation loss: 0.0972
2024-05-23 21:47:35 [INFO]: Epoch 245 - training loss: 0.2485, validation loss: 0.0971
2024-05-23 21:47:37 [INFO]: Epoch 246 - training loss: 0.2483, validation loss: 0.0970
2024-05-23 21:47:39 [INFO]: Epoch 247 - training loss: 0.2485, validation loss: 0.0968
2024-05-23 21:47:41 [INFO]: Epoch 248 - training loss: 0.2475, validation loss: 0.0968
2024-05-23 21:47:44 [INFO]: Epoch 249 - training loss: 0.2475, validation loss: 0.0969
2024-05-23 21:47:46 [INFO]: Epoch 250 - training loss: 0.2468, validation loss: 0.0967
2024-05-23 21:47:48 [INFO]: Epoch 251 - training loss: 0.2470, validation loss: 0.0968
2024-05-23 21:47:50 [INFO]: Epoch 252 - training loss: 0.2472, validation loss: 0.0968
2024-05-23 21:47:53 [INFO]: Epoch 253 - training loss: 0.2470, validation loss: 0.0965
2024-05-23 21:47:55 [INFO]: Epoch 254 - training loss: 0.2475, validation loss: 0.0966
2024-05-23 21:47:57 [INFO]: Epoch 255 - training loss: 0.2465, validation loss: 0.0964
2024-05-23 21:47:59 [INFO]: Epoch 256 - training loss: 0.2468, validation loss: 0.0964
2024-05-23 21:48:02 [INFO]: Epoch 257 - training loss: 0.2465, validation loss: 0.0964
2024-05-23 21:48:04 [INFO]: Epoch 258 - training loss: 0.2465, validation loss: 0.0962
2024-05-23 21:48:06 [INFO]: Epoch 259 - training loss: 0.2460, validation loss: 0.0962
2024-05-23 21:48:08 [INFO]: Epoch 260 - training loss: 0.2461, validation loss: 0.0960
2024-05-23 21:48:11 [INFO]: Epoch 261 - training loss: 0.2466, validation loss: 0.0961
2024-05-23 21:48:13 [INFO]: Epoch 262 - training loss: 0.2459, validation loss: 0.0960
2024-05-23 21:48:15 [INFO]: Epoch 263 - training loss: 0.2458, validation loss: 0.0959
2024-05-23 21:48:17 [INFO]: Epoch 264 - training loss: 0.2461, validation loss: 0.0959
2024-05-23 21:48:20 [INFO]: Epoch 265 - training loss: 0.2451, validation loss: 0.0958
2024-05-23 21:48:22 [INFO]: Epoch 266 - training loss: 0.2449, validation loss: 0.0959
2024-05-23 21:48:24 [INFO]: Epoch 267 - training loss: 0.2450, validation loss: 0.0957
2024-05-23 21:48:26 [INFO]: Epoch 268 - training loss: 0.2451, validation loss: 0.0958
2024-05-23 21:48:29 [INFO]: Epoch 269 - training loss: 0.2451, validation loss: 0.0957
2024-05-23 21:48:31 [INFO]: Epoch 270 - training loss: 0.2439, validation loss: 0.0955
2024-05-23 21:48:33 [INFO]: Epoch 271 - training loss: 0.2445, validation loss: 0.0955
2024-05-23 21:48:35 [INFO]: Epoch 272 - training loss: 0.2438, validation loss: 0.0954
2024-05-23 21:48:38 [INFO]: Epoch 273 - training loss: 0.2446, validation loss: 0.0955
2024-05-23 21:48:40 [INFO]: Epoch 274 - training loss: 0.2439, validation loss: 0.0955
2024-05-23 21:48:42 [INFO]: Epoch 275 - training loss: 0.2439, validation loss: 0.0955
2024-05-23 21:48:44 [INFO]: Epoch 276 - training loss: 0.2436, validation loss: 0.0953
2024-05-23 21:48:47 [INFO]: Epoch 277 - training loss: 0.2438, validation loss: 0.0953
2024-05-23 21:48:49 [INFO]: Epoch 278 - training loss: 0.2437, validation loss: 0.0952
2024-05-23 21:48:51 [INFO]: Epoch 279 - training loss: 0.2434, validation loss: 0.0953
2024-05-23 21:48:53 [INFO]: Epoch 280 - training loss: 0.2435, validation loss: 0.0952
2024-05-23 21:48:56 [INFO]: Epoch 281 - training loss: 0.2437, validation loss: 0.0952
2024-05-23 21:48:58 [INFO]: Epoch 282 - training loss: 0.2425, validation loss: 0.0950
2024-05-23 21:49:00 [INFO]: Epoch 283 - training loss: 0.2426, validation loss: 0.0950
2024-05-23 21:49:03 [INFO]: Epoch 284 - training loss: 0.2428, validation loss: 0.0951
2024-05-23 21:49:05 [INFO]: Epoch 285 - training loss: 0.2425, validation loss: 0.0948
2024-05-23 21:49:07 [INFO]: Epoch 286 - training loss: 0.2424, validation loss: 0.0950
2024-05-23 21:49:09 [INFO]: Epoch 287 - training loss: 0.2421, validation loss: 0.0949
2024-05-23 21:49:11 [INFO]: Epoch 288 - training loss: 0.2419, validation loss: 0.0948
2024-05-23 21:49:14 [INFO]: Epoch 289 - training loss: 0.2418, validation loss: 0.0949
2024-05-23 21:49:16 [INFO]: Epoch 290 - training loss: 0.2423, validation loss: 0.0947
2024-05-23 21:49:18 [INFO]: Epoch 291 - training loss: 0.2419, validation loss: 0.0947
2024-05-23 21:49:20 [INFO]: Epoch 292 - training loss: 0.2417, validation loss: 0.0948
2024-05-23 21:49:23 [INFO]: Epoch 293 - training loss: 0.2417, validation loss: 0.0948
2024-05-23 21:49:25 [INFO]: Epoch 294 - training loss: 0.2414, validation loss: 0.0947
2024-05-23 21:49:27 [INFO]: Epoch 295 - training loss: 0.2422, validation loss: 0.0946
2024-05-23 21:49:29 [INFO]: Epoch 296 - training loss: 0.2414, validation loss: 0.0946
2024-05-23 21:49:32 [INFO]: Epoch 297 - training loss: 0.2412, validation loss: 0.0945
2024-05-23 21:49:34 [INFO]: Epoch 298 - training loss: 0.2413, validation loss: 0.0945
2024-05-23 21:49:36 [INFO]: Epoch 299 - training loss: 0.2412, validation loss: 0.0943
2024-05-23 21:49:38 [INFO]: Epoch 300 - training loss: 0.2415, validation loss: 0.0945
2024-05-23 21:49:38 [INFO]: Finished training. The best model is from epoch#299.
2024-05-23 21:49:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/BRITS_air_quality/20240523_T213814/BRITS.pypots
2024-05-23 21:49:39 [INFO]: BRITS on Air-Quality: MAE=0.1442, MSE=0.1613
2024-05-23 21:49:39 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-23 21:49:39 [INFO]: Using the given device: cuda:0
2024-05-23 21:49:39 [INFO]: Model files will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939
2024-05-23 21:49:39 [INFO]: Tensorboard file will be saved to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/tensorboard
2024-05-23 21:49:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-23 21:49:43 [INFO]: Epoch 001 - training loss: 1.3321, validation loss: 0.7790
2024-05-23 21:49:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch1_loss0.7789829015731812.pypots
2024-05-23 21:49:46 [INFO]: Epoch 002 - training loss: 1.0212, validation loss: 0.7154
2024-05-23 21:49:46 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch2_loss0.7153853416442871.pypots
2024-05-23 21:49:49 [INFO]: Epoch 003 - training loss: 0.9618, validation loss: 0.6977
2024-05-23 21:49:49 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch3_loss0.697740325331688.pypots
2024-05-23 21:49:52 [INFO]: Epoch 004 - training loss: 0.9305, validation loss: 0.6841
2024-05-23 21:49:52 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch4_loss0.6841153681278229.pypots
2024-05-23 21:49:55 [INFO]: Epoch 005 - training loss: 0.9177, validation loss: 0.6753
2024-05-23 21:49:55 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch5_loss0.6752696722745896.pypots
2024-05-23 21:49:58 [INFO]: Epoch 006 - training loss: 0.9077, validation loss: 0.6692
2024-05-23 21:49:58 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch6_loss0.6692265480756759.pypots
2024-05-23 21:50:01 [INFO]: Epoch 007 - training loss: 0.9046, validation loss: 0.6642
2024-05-23 21:50:01 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch7_loss0.6641876190900803.pypots
2024-05-23 21:50:04 [INFO]: Epoch 008 - training loss: 0.9258, validation loss: 0.6588
2024-05-23 21:50:04 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch8_loss0.6588083058595657.pypots
2024-05-23 21:50:07 [INFO]: Epoch 009 - training loss: 0.8950, validation loss: 0.6557
2024-05-23 21:50:07 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch9_loss0.6556910574436188.pypots
2024-05-23 21:50:10 [INFO]: Epoch 010 - training loss: 0.8961, validation loss: 0.6544
2024-05-23 21:50:10 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch10_loss0.6544366031885147.pypots
2024-05-23 21:50:14 [INFO]: Epoch 011 - training loss: 0.8710, validation loss: 0.6518
2024-05-23 21:50:14 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch11_loss0.6517863720655441.pypots
2024-05-23 21:50:17 [INFO]: Epoch 012 - training loss: 0.8799, validation loss: 0.6506
2024-05-23 21:50:17 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch12_loss0.6505899131298065.pypots
2024-05-23 21:50:20 [INFO]: Epoch 013 - training loss: 0.8620, validation loss: 0.6491
2024-05-23 21:50:20 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch13_loss0.6490994721651078.pypots
2024-05-23 21:50:23 [INFO]: Epoch 014 - training loss: 0.8733, validation loss: 0.6485
2024-05-23 21:50:23 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch14_loss0.6484828650951385.pypots
2024-05-23 21:50:26 [INFO]: Epoch 015 - training loss: 0.8703, validation loss: 0.6479
2024-05-23 21:50:26 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch15_loss0.6479177206754685.pypots
2024-05-23 21:50:29 [INFO]: Epoch 016 - training loss: 0.8567, validation loss: 0.6471
2024-05-23 21:50:29 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch16_loss0.6470629423856735.pypots
2024-05-23 21:50:32 [INFO]: Epoch 017 - training loss: 0.8681, validation loss: 0.6473
2024-05-23 21:50:32 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch17_loss0.647254541516304.pypots
2024-05-23 21:50:35 [INFO]: Epoch 018 - training loss: 0.8656, validation loss: 0.6468
2024-05-23 21:50:35 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch18_loss0.6468346178531647.pypots
2024-05-23 21:50:38 [INFO]: Epoch 019 - training loss: 0.8626, validation loss: 0.6458
2024-05-23 21:50:38 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch19_loss0.6457847863435745.pypots
2024-05-23 21:50:41 [INFO]: Epoch 020 - training loss: 0.8386, validation loss: 0.6452
2024-05-23 21:50:41 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch20_loss0.6452071100473404.pypots
2024-05-23 21:50:45 [INFO]: Epoch 021 - training loss: 0.8425, validation loss: 0.6449
2024-05-23 21:50:45 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch21_loss0.6449048012495041.pypots
2024-05-23 21:50:48 [INFO]: Epoch 022 - training loss: 0.8421, validation loss: 0.6444
2024-05-23 21:50:48 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch22_loss0.6443922996520997.pypots
2024-05-23 21:50:51 [INFO]: Epoch 023 - training loss: 0.8354, validation loss: 0.6440
2024-05-23 21:50:51 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch23_loss0.6439903467893601.pypots
2024-05-23 21:50:54 [INFO]: Epoch 024 - training loss: 0.8355, validation loss: 0.6449
2024-05-23 21:50:54 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch24_loss0.6449085146188736.pypots
2024-05-23 21:50:57 [INFO]: Epoch 025 - training loss: 0.8474, validation loss: 0.6448
2024-05-23 21:50:57 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch25_loss0.6447808742523193.pypots
2024-05-23 21:51:00 [INFO]: Epoch 026 - training loss: 0.8547, validation loss: 0.6439
2024-05-23 21:51:00 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch26_loss0.643883228302002.pypots
2024-05-23 21:51:03 [INFO]: Epoch 027 - training loss: 0.8222, validation loss: 0.6448
2024-05-23 21:51:03 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch27_loss0.6448140442371368.pypots
2024-05-23 21:51:06 [INFO]: Epoch 028 - training loss: 0.8232, validation loss: 0.6439
2024-05-23 21:51:06 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch28_loss0.643886512517929.pypots
2024-05-23 21:51:09 [INFO]: Epoch 029 - training loss: 0.8317, validation loss: 0.6454
2024-05-23 21:51:09 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch29_loss0.6453525245189666.pypots
2024-05-23 21:51:13 [INFO]: Epoch 030 - training loss: 0.8227, validation loss: 0.6436
2024-05-23 21:51:13 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch30_loss0.6435988336801529.pypots
2024-05-23 21:51:16 [INFO]: Epoch 031 - training loss: 0.8243, validation loss: 0.6438
2024-05-23 21:51:16 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch31_loss0.6437624096870422.pypots
2024-05-23 21:51:19 [INFO]: Epoch 032 - training loss: 0.8394, validation loss: 0.6439
2024-05-23 21:51:19 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch32_loss0.6438608765602112.pypots
2024-05-23 21:51:22 [INFO]: Epoch 033 - training loss: 0.8384, validation loss: 0.6433
2024-05-23 21:51:22 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch33_loss0.6433107286691666.pypots
2024-05-23 21:51:25 [INFO]: Epoch 034 - training loss: 0.8267, validation loss: 0.6451
2024-05-23 21:51:25 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch34_loss0.6451099872589111.pypots
2024-05-23 21:51:28 [INFO]: Epoch 035 - training loss: 0.8464, validation loss: 0.6467
2024-05-23 21:51:28 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch35_loss0.6466778218746185.pypots
2024-05-23 21:51:31 [INFO]: Epoch 036 - training loss: 0.8067, validation loss: 0.6454
2024-05-23 21:51:31 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch36_loss0.6454498499631882.pypots
2024-05-23 21:51:34 [INFO]: Epoch 037 - training loss: 0.8075, validation loss: 0.6455
2024-05-23 21:51:34 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch37_loss0.6454894274473191.pypots
2024-05-23 21:51:37 [INFO]: Epoch 038 - training loss: 0.7998, validation loss: 0.6459
2024-05-23 21:51:37 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch38_loss0.6459304302930832.pypots
2024-05-23 21:51:40 [INFO]: Epoch 039 - training loss: 0.7988, validation loss: 0.6462
2024-05-23 21:51:40 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch39_loss0.6462003797292709.pypots
2024-05-23 21:51:43 [INFO]: Epoch 040 - training loss: 0.8012, validation loss: 0.6467
2024-05-23 21:51:43 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch40_loss0.6467375308275223.pypots
2024-05-23 21:51:47 [INFO]: Epoch 041 - training loss: 0.8085, validation loss: 0.6472
2024-05-23 21:51:47 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch41_loss0.6472043544054031.pypots
2024-05-23 21:51:50 [INFO]: Epoch 042 - training loss: 0.8079, validation loss: 0.6489
2024-05-23 21:51:50 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch42_loss0.6488988280296326.pypots
2024-05-23 21:51:53 [INFO]: Epoch 043 - training loss: 0.8096, validation loss: 0.6485
2024-05-23 21:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN_epoch43_loss0.6484976440668107.pypots
2024-05-23 21:51:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-23 21:51:53 [INFO]: Finished training. The best model is from epoch#33.
2024-05-23 21:51:53 [INFO]: Saved the model to overlay_premask_saved_results/round_4/MRNN_air_quality/20240523_T214939/MRNN.pypots
2024-05-23 21:51:53 [INFO]: MRNN on Air-Quality: MAE=0.5236, MSE=0.6950
2024-05-23 21:51:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-23 21:51:53 [INFO]: Using the given device: cpu
2024-05-23 21:51:53 [INFO]: LOCF on Air-Quality: MAE=0.2090, MSE=0.3758
2024-05-23 21:51:53 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-23 21:51:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-23 21:51:53 [INFO]: Median on Air-Quality: MAE=0.6658, MSE=1.0901
2024-05-23 21:51:53 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-23 21:51:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-23 21:51:53 [INFO]: Mean on Air-Quality: MAE=0.6970, MSE=1.0309
2024-05-23 21:51:53 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-23 21:51:53 [INFO]: Successfully saved to overlay_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-23 21:51:53 [INFO]: 
SAITS on data_overlay_premask/air_quality: MAE=0.155±0.0014248052892019292, MSE=0.176±0.0031026559144622917
Transformer on data_overlay_premask/air_quality: MAE=0.172±0.001221899479636671, MSE=0.204±0.0027724992409950276
TimesNet on data_overlay_premask/air_quality: MAE=0.167±0.001859185942485782, MSE=0.248±0.005186932927990082
CSDI on data_overlay_premask/air_quality: MAE=0.111±0.0054208716035633224, MSE=0.240±0.017991615267960913
GPVAE on data_overlay_premask/air_quality: MAE=0.277±0.01090915715775488, MSE=0.311±0.023681964522851207
USGAN on data_overlay_premask/air_quality: MAE=0.153±0.0013255537456026763, MSE=0.150±0.0018229854109045075
BRITS on data_overlay_premask/air_quality: MAE=0.144±0.0002719919744263242, MSE=0.163±0.002411192894114117
MRNN on data_overlay_premask/air_quality: MAE=0.522±0.0011212381530046943, MSE=0.693±0.0014183732854039365
LOCF on data_overlay_premask/air_quality: MAE=0.209±2.7755575615628914e-17, MSE=0.376±0.0
Median on data_overlay_premask/air_quality: MAE=0.666±0.0, MSE=1.090±0.0
Mean on data_overlay_premask/air_quality: MAE=0.697±0.0, MSE=1.031±0.0
