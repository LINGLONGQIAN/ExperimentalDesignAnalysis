2024-05-25 02:52:46 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-25 02:52:46 [INFO]: Using the given device: cuda:0
2024-05-25 02:52:46 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240525_T025246
2024-05-25 02:52:46 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240525_T025246/tensorboard
2024-05-25 02:52:47 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 02:52:51 [INFO]: Epoch 001 - training loss: 1.0566, validation loss: 0.5431
2024-05-25 02:52:52 [INFO]: Epoch 002 - training loss: 0.7605, validation loss: 0.4228
2024-05-25 02:52:52 [INFO]: Epoch 003 - training loss: 0.6542, validation loss: 0.3467
2024-05-25 02:52:53 [INFO]: Epoch 004 - training loss: 0.5773, validation loss: 0.3005
2024-05-25 02:52:54 [INFO]: Epoch 005 - training loss: 0.5218, validation loss: 0.2748
2024-05-25 02:52:54 [INFO]: Epoch 006 - training loss: 0.4825, validation loss: 0.2619
2024-05-25 02:52:55 [INFO]: Epoch 007 - training loss: 0.4565, validation loss: 0.2504
2024-05-25 02:52:55 [INFO]: Epoch 008 - training loss: 0.4370, validation loss: 0.2460
2024-05-25 02:52:56 [INFO]: Epoch 009 - training loss: 0.4222, validation loss: 0.2403
2024-05-25 02:52:57 [INFO]: Epoch 010 - training loss: 0.4109, validation loss: 0.2340
2024-05-25 02:52:57 [INFO]: Epoch 011 - training loss: 0.4005, validation loss: 0.2319
2024-05-25 02:52:58 [INFO]: Epoch 012 - training loss: 0.3926, validation loss: 0.2280
2024-05-25 02:52:58 [INFO]: Epoch 013 - training loss: 0.3847, validation loss: 0.2248
2024-05-25 02:52:59 [INFO]: Epoch 014 - training loss: 0.3780, validation loss: 0.2223
2024-05-25 02:53:00 [INFO]: Epoch 015 - training loss: 0.3733, validation loss: 0.2183
2024-05-25 02:53:00 [INFO]: Epoch 016 - training loss: 0.3676, validation loss: 0.2165
2024-05-25 02:53:01 [INFO]: Epoch 017 - training loss: 0.3614, validation loss: 0.2141
2024-05-25 02:53:01 [INFO]: Epoch 018 - training loss: 0.3574, validation loss: 0.2122
2024-05-25 02:53:02 [INFO]: Epoch 019 - training loss: 0.3556, validation loss: 0.2108
2024-05-25 02:53:03 [INFO]: Epoch 020 - training loss: 0.3494, validation loss: 0.2063
2024-05-25 02:53:03 [INFO]: Epoch 021 - training loss: 0.3447, validation loss: 0.2041
2024-05-25 02:53:04 [INFO]: Epoch 022 - training loss: 0.3407, validation loss: 0.2041
2024-05-25 02:53:04 [INFO]: Epoch 023 - training loss: 0.3379, validation loss: 0.2014
2024-05-25 02:53:05 [INFO]: Epoch 024 - training loss: 0.3343, validation loss: 0.1998
2024-05-25 02:53:05 [INFO]: Epoch 025 - training loss: 0.3327, validation loss: 0.1987
2024-05-25 02:53:06 [INFO]: Epoch 026 - training loss: 0.3287, validation loss: 0.1976
2024-05-25 02:53:07 [INFO]: Epoch 027 - training loss: 0.3261, validation loss: 0.1957
2024-05-25 02:53:07 [INFO]: Epoch 028 - training loss: 0.3236, validation loss: 0.1948
2024-05-25 02:53:08 [INFO]: Epoch 029 - training loss: 0.3214, validation loss: 0.1924
2024-05-25 02:53:08 [INFO]: Epoch 030 - training loss: 0.3185, validation loss: 0.1912
2024-05-25 02:53:09 [INFO]: Epoch 031 - training loss: 0.3162, validation loss: 0.1898
2024-05-25 02:53:10 [INFO]: Epoch 032 - training loss: 0.3141, validation loss: 0.1885
2024-05-25 02:53:10 [INFO]: Epoch 033 - training loss: 0.3132, validation loss: 0.1878
2024-05-25 02:53:11 [INFO]: Epoch 034 - training loss: 0.3099, validation loss: 0.1858
2024-05-25 02:53:11 [INFO]: Epoch 035 - training loss: 0.3087, validation loss: 0.1849
2024-05-25 02:53:12 [INFO]: Epoch 036 - training loss: 0.3062, validation loss: 0.1839
2024-05-25 02:53:13 [INFO]: Epoch 037 - training loss: 0.3048, validation loss: 0.1820
2024-05-25 02:53:13 [INFO]: Epoch 038 - training loss: 0.3040, validation loss: 0.1815
2024-05-25 02:53:14 [INFO]: Epoch 039 - training loss: 0.3012, validation loss: 0.1817
2024-05-25 02:53:14 [INFO]: Epoch 040 - training loss: 0.2994, validation loss: 0.1809
2024-05-25 02:53:15 [INFO]: Epoch 041 - training loss: 0.2968, validation loss: 0.1773
2024-05-25 02:53:16 [INFO]: Epoch 042 - training loss: 0.2949, validation loss: 0.1779
2024-05-25 02:53:16 [INFO]: Epoch 043 - training loss: 0.2945, validation loss: 0.1779
2024-05-25 02:53:17 [INFO]: Epoch 044 - training loss: 0.2919, validation loss: 0.1753
2024-05-25 02:53:17 [INFO]: Epoch 045 - training loss: 0.2898, validation loss: 0.1751
2024-05-25 02:53:18 [INFO]: Epoch 046 - training loss: 0.2881, validation loss: 0.1736
2024-05-25 02:53:19 [INFO]: Epoch 047 - training loss: 0.2865, validation loss: 0.1739
2024-05-25 02:53:19 [INFO]: Epoch 048 - training loss: 0.2859, validation loss: 0.1722
2024-05-25 02:53:20 [INFO]: Epoch 049 - training loss: 0.2840, validation loss: 0.1720
2024-05-25 02:53:20 [INFO]: Epoch 050 - training loss: 0.2818, validation loss: 0.1706
2024-05-25 02:53:21 [INFO]: Epoch 051 - training loss: 0.2803, validation loss: 0.1696
2024-05-25 02:53:22 [INFO]: Epoch 052 - training loss: 0.2797, validation loss: 0.1680
2024-05-25 02:53:22 [INFO]: Epoch 053 - training loss: 0.2781, validation loss: 0.1687
2024-05-25 02:53:23 [INFO]: Epoch 054 - training loss: 0.2765, validation loss: 0.1682
2024-05-25 02:53:23 [INFO]: Epoch 055 - training loss: 0.2760, validation loss: 0.1666
2024-05-25 02:53:24 [INFO]: Epoch 056 - training loss: 0.2740, validation loss: 0.1653
2024-05-25 02:53:25 [INFO]: Epoch 057 - training loss: 0.2736, validation loss: 0.1659
2024-05-25 02:53:25 [INFO]: Epoch 058 - training loss: 0.2711, validation loss: 0.1639
2024-05-25 02:53:26 [INFO]: Epoch 059 - training loss: 0.2706, validation loss: 0.1635
2024-05-25 02:53:26 [INFO]: Epoch 060 - training loss: 0.2681, validation loss: 0.1630
2024-05-25 02:53:27 [INFO]: Epoch 061 - training loss: 0.2659, validation loss: 0.1624
2024-05-25 02:53:28 [INFO]: Epoch 062 - training loss: 0.2660, validation loss: 0.1628
2024-05-25 02:53:28 [INFO]: Epoch 063 - training loss: 0.2635, validation loss: 0.1610
2024-05-25 02:53:29 [INFO]: Epoch 064 - training loss: 0.2625, validation loss: 0.1600
2024-05-25 02:53:29 [INFO]: Epoch 065 - training loss: 0.2612, validation loss: 0.1594
2024-05-25 02:53:30 [INFO]: Epoch 066 - training loss: 0.2606, validation loss: 0.1586
2024-05-25 02:53:31 [INFO]: Epoch 067 - training loss: 0.2590, validation loss: 0.1586
2024-05-25 02:53:31 [INFO]: Epoch 068 - training loss: 0.2589, validation loss: 0.1583
2024-05-25 02:53:32 [INFO]: Epoch 069 - training loss: 0.2572, validation loss: 0.1575
2024-05-25 02:53:32 [INFO]: Epoch 070 - training loss: 0.2556, validation loss: 0.1564
2024-05-25 02:53:33 [INFO]: Epoch 071 - training loss: 0.2548, validation loss: 0.1569
2024-05-25 02:53:34 [INFO]: Epoch 072 - training loss: 0.2540, validation loss: 0.1573
2024-05-25 02:53:34 [INFO]: Epoch 073 - training loss: 0.2536, validation loss: 0.1563
2024-05-25 02:53:35 [INFO]: Epoch 074 - training loss: 0.2525, validation loss: 0.1553
2024-05-25 02:53:35 [INFO]: Epoch 075 - training loss: 0.2510, validation loss: 0.1549
2024-05-25 02:53:36 [INFO]: Epoch 076 - training loss: 0.2495, validation loss: 0.1553
2024-05-25 02:53:37 [INFO]: Epoch 077 - training loss: 0.2491, validation loss: 0.1550
2024-05-25 02:53:37 [INFO]: Epoch 078 - training loss: 0.2483, validation loss: 0.1540
2024-05-25 02:53:38 [INFO]: Epoch 079 - training loss: 0.2463, validation loss: 0.1540
2024-05-25 02:53:38 [INFO]: Epoch 080 - training loss: 0.2458, validation loss: 0.1533
2024-05-25 02:53:39 [INFO]: Epoch 081 - training loss: 0.2453, validation loss: 0.1531
2024-05-25 02:53:40 [INFO]: Epoch 082 - training loss: 0.2440, validation loss: 0.1531
2024-05-25 02:53:40 [INFO]: Epoch 083 - training loss: 0.2430, validation loss: 0.1528
2024-05-25 02:53:41 [INFO]: Epoch 084 - training loss: 0.2425, validation loss: 0.1537
2024-05-25 02:53:41 [INFO]: Epoch 085 - training loss: 0.2420, validation loss: 0.1516
2024-05-25 02:53:42 [INFO]: Epoch 086 - training loss: 0.2409, validation loss: 0.1518
2024-05-25 02:53:43 [INFO]: Epoch 087 - training loss: 0.2408, validation loss: 0.1517
2024-05-25 02:53:43 [INFO]: Epoch 088 - training loss: 0.2407, validation loss: 0.1517
2024-05-25 02:53:44 [INFO]: Epoch 089 - training loss: 0.2385, validation loss: 0.1513
2024-05-25 02:53:44 [INFO]: Epoch 090 - training loss: 0.2385, validation loss: 0.1510
2024-05-25 02:53:45 [INFO]: Epoch 091 - training loss: 0.2376, validation loss: 0.1501
2024-05-25 02:53:46 [INFO]: Epoch 092 - training loss: 0.2358, validation loss: 0.1498
2024-05-25 02:53:46 [INFO]: Epoch 093 - training loss: 0.2352, validation loss: 0.1493
2024-05-25 02:53:47 [INFO]: Epoch 094 - training loss: 0.2345, validation loss: 0.1491
2024-05-25 02:53:47 [INFO]: Epoch 095 - training loss: 0.2346, validation loss: 0.1492
2024-05-25 02:53:48 [INFO]: Epoch 096 - training loss: 0.2341, validation loss: 0.1496
2024-05-25 02:53:49 [INFO]: Epoch 097 - training loss: 0.2341, validation loss: 0.1483
2024-05-25 02:53:49 [INFO]: Epoch 098 - training loss: 0.2338, validation loss: 0.1492
2024-05-25 02:53:50 [INFO]: Epoch 099 - training loss: 0.2325, validation loss: 0.1489
2024-05-25 02:53:50 [INFO]: Epoch 100 - training loss: 0.2314, validation loss: 0.1478
2024-05-25 02:53:51 [INFO]: Epoch 101 - training loss: 0.2316, validation loss: 0.1483
2024-05-25 02:53:52 [INFO]: Epoch 102 - training loss: 0.2302, validation loss: 0.1478
2024-05-25 02:53:52 [INFO]: Epoch 103 - training loss: 0.2293, validation loss: 0.1471
2024-05-25 02:53:53 [INFO]: Epoch 104 - training loss: 0.2283, validation loss: 0.1465
2024-05-25 02:53:53 [INFO]: Epoch 105 - training loss: 0.2282, validation loss: 0.1468
2024-05-25 02:53:54 [INFO]: Epoch 106 - training loss: 0.2270, validation loss: 0.1467
2024-05-25 02:53:55 [INFO]: Epoch 107 - training loss: 0.2260, validation loss: 0.1464
2024-05-25 02:53:55 [INFO]: Epoch 108 - training loss: 0.2263, validation loss: 0.1474
2024-05-25 02:53:56 [INFO]: Epoch 109 - training loss: 0.2260, validation loss: 0.1469
2024-05-25 02:53:56 [INFO]: Epoch 110 - training loss: 0.2247, validation loss: 0.1461
2024-05-25 02:53:57 [INFO]: Epoch 111 - training loss: 0.2244, validation loss: 0.1456
2024-05-25 02:53:58 [INFO]: Epoch 112 - training loss: 0.2233, validation loss: 0.1464
2024-05-25 02:53:58 [INFO]: Epoch 113 - training loss: 0.2219, validation loss: 0.1447
2024-05-25 02:53:59 [INFO]: Epoch 114 - training loss: 0.2225, validation loss: 0.1450
2024-05-25 02:53:59 [INFO]: Epoch 115 - training loss: 0.2217, validation loss: 0.1450
2024-05-25 02:54:00 [INFO]: Epoch 116 - training loss: 0.2213, validation loss: 0.1446
2024-05-25 02:54:01 [INFO]: Epoch 117 - training loss: 0.2207, validation loss: 0.1446
2024-05-25 02:54:01 [INFO]: Epoch 118 - training loss: 0.2206, validation loss: 0.1457
2024-05-25 02:54:02 [INFO]: Epoch 119 - training loss: 0.2227, validation loss: 0.1445
2024-05-25 02:54:02 [INFO]: Epoch 120 - training loss: 0.2207, validation loss: 0.1437
2024-05-25 02:54:03 [INFO]: Epoch 121 - training loss: 0.2190, validation loss: 0.1440
2024-05-25 02:54:04 [INFO]: Epoch 122 - training loss: 0.2178, validation loss: 0.1433
2024-05-25 02:54:04 [INFO]: Epoch 123 - training loss: 0.2173, validation loss: 0.1434
2024-05-25 02:54:05 [INFO]: Epoch 124 - training loss: 0.2162, validation loss: 0.1427
2024-05-25 02:54:05 [INFO]: Epoch 125 - training loss: 0.2163, validation loss: 0.1435
2024-05-25 02:54:06 [INFO]: Epoch 126 - training loss: 0.2175, validation loss: 0.1431
2024-05-25 02:54:07 [INFO]: Epoch 127 - training loss: 0.2171, validation loss: 0.1430
2024-05-25 02:54:07 [INFO]: Epoch 128 - training loss: 0.2152, validation loss: 0.1421
2024-05-25 02:54:08 [INFO]: Epoch 129 - training loss: 0.2165, validation loss: 0.1426
2024-05-25 02:54:08 [INFO]: Epoch 130 - training loss: 0.2150, validation loss: 0.1420
2024-05-25 02:54:09 [INFO]: Epoch 131 - training loss: 0.2140, validation loss: 0.1430
2024-05-25 02:54:10 [INFO]: Epoch 132 - training loss: 0.2163, validation loss: 0.1423
2024-05-25 02:54:10 [INFO]: Epoch 133 - training loss: 0.2147, validation loss: 0.1426
2024-05-25 02:54:11 [INFO]: Epoch 134 - training loss: 0.2130, validation loss: 0.1423
2024-05-25 02:54:11 [INFO]: Epoch 135 - training loss: 0.2117, validation loss: 0.1429
2024-05-25 02:54:12 [INFO]: Epoch 136 - training loss: 0.2116, validation loss: 0.1419
2024-05-25 02:54:12 [INFO]: Epoch 137 - training loss: 0.2105, validation loss: 0.1416
2024-05-25 02:54:13 [INFO]: Epoch 138 - training loss: 0.2095, validation loss: 0.1409
2024-05-25 02:54:14 [INFO]: Epoch 139 - training loss: 0.2096, validation loss: 0.1415
2024-05-25 02:54:14 [INFO]: Epoch 140 - training loss: 0.2095, validation loss: 0.1409
2024-05-25 02:54:15 [INFO]: Epoch 141 - training loss: 0.2088, validation loss: 0.1411
2024-05-25 02:54:15 [INFO]: Epoch 142 - training loss: 0.2097, validation loss: 0.1405
2024-05-25 02:54:16 [INFO]: Epoch 143 - training loss: 0.2077, validation loss: 0.1407
2024-05-25 02:54:17 [INFO]: Epoch 144 - training loss: 0.2074, validation loss: 0.1409
2024-05-25 02:54:17 [INFO]: Epoch 145 - training loss: 0.2068, validation loss: 0.1397
2024-05-25 02:54:18 [INFO]: Epoch 146 - training loss: 0.2063, validation loss: 0.1395
2024-05-25 02:54:18 [INFO]: Epoch 147 - training loss: 0.2062, validation loss: 0.1398
2024-05-25 02:54:19 [INFO]: Epoch 148 - training loss: 0.2056, validation loss: 0.1396
2024-05-25 02:54:20 [INFO]: Epoch 149 - training loss: 0.2062, validation loss: 0.1400
2024-05-25 02:54:20 [INFO]: Epoch 150 - training loss: 0.2055, validation loss: 0.1403
2024-05-25 02:54:21 [INFO]: Epoch 151 - training loss: 0.2045, validation loss: 0.1400
2024-05-25 02:54:21 [INFO]: Epoch 152 - training loss: 0.2036, validation loss: 0.1407
2024-05-25 02:54:22 [INFO]: Epoch 153 - training loss: 0.2037, validation loss: 0.1393
2024-05-25 02:54:23 [INFO]: Epoch 154 - training loss: 0.2041, validation loss: 0.1389
2024-05-25 02:54:23 [INFO]: Epoch 155 - training loss: 0.2035, validation loss: 0.1389
2024-05-25 02:54:24 [INFO]: Epoch 156 - training loss: 0.2023, validation loss: 0.1385
2024-05-25 02:54:24 [INFO]: Epoch 157 - training loss: 0.2015, validation loss: 0.1394
2024-05-25 02:54:25 [INFO]: Epoch 158 - training loss: 0.2015, validation loss: 0.1387
2024-05-25 02:54:26 [INFO]: Epoch 159 - training loss: 0.2006, validation loss: 0.1382
2024-05-25 02:54:26 [INFO]: Epoch 160 - training loss: 0.2008, validation loss: 0.1393
2024-05-25 02:54:27 [INFO]: Epoch 161 - training loss: 0.2014, validation loss: 0.1387
2024-05-25 02:54:27 [INFO]: Epoch 162 - training loss: 0.2031, validation loss: 0.1396
2024-05-25 02:54:28 [INFO]: Epoch 163 - training loss: 0.2009, validation loss: 0.1380
2024-05-25 02:54:29 [INFO]: Epoch 164 - training loss: 0.2008, validation loss: 0.1385
2024-05-25 02:54:29 [INFO]: Epoch 165 - training loss: 0.2004, validation loss: 0.1383
2024-05-25 02:54:30 [INFO]: Epoch 166 - training loss: 0.1993, validation loss: 0.1383
2024-05-25 02:54:30 [INFO]: Epoch 167 - training loss: 0.2008, validation loss: 0.1385
2024-05-25 02:54:31 [INFO]: Epoch 168 - training loss: 0.2000, validation loss: 0.1396
2024-05-25 02:54:32 [INFO]: Epoch 169 - training loss: 0.1991, validation loss: 0.1375
2024-05-25 02:54:32 [INFO]: Epoch 170 - training loss: 0.1965, validation loss: 0.1376
2024-05-25 02:54:33 [INFO]: Epoch 171 - training loss: 0.1965, validation loss: 0.1378
2024-05-25 02:54:33 [INFO]: Epoch 172 - training loss: 0.1959, validation loss: 0.1379
2024-05-25 02:54:34 [INFO]: Epoch 173 - training loss: 0.1955, validation loss: 0.1372
2024-05-25 02:54:35 [INFO]: Epoch 174 - training loss: 0.1954, validation loss: 0.1370
2024-05-25 02:54:35 [INFO]: Epoch 175 - training loss: 0.1952, validation loss: 0.1373
2024-05-25 02:54:36 [INFO]: Epoch 176 - training loss: 0.1955, validation loss: 0.1377
2024-05-25 02:54:36 [INFO]: Epoch 177 - training loss: 0.1947, validation loss: 0.1369
2024-05-25 02:54:37 [INFO]: Epoch 178 - training loss: 0.1961, validation loss: 0.1372
2024-05-25 02:54:38 [INFO]: Epoch 179 - training loss: 0.1939, validation loss: 0.1369
2024-05-25 02:54:38 [INFO]: Epoch 180 - training loss: 0.1933, validation loss: 0.1386
2024-05-25 02:54:39 [INFO]: Epoch 181 - training loss: 0.1937, validation loss: 0.1373
2024-05-25 02:54:39 [INFO]: Epoch 182 - training loss: 0.1931, validation loss: 0.1368
2024-05-25 02:54:40 [INFO]: Epoch 183 - training loss: 0.1939, validation loss: 0.1378
2024-05-25 02:54:41 [INFO]: Epoch 184 - training loss: 0.1920, validation loss: 0.1381
2024-05-25 02:54:41 [INFO]: Epoch 185 - training loss: 0.1916, validation loss: 0.1368
2024-05-25 02:54:42 [INFO]: Epoch 186 - training loss: 0.1926, validation loss: 0.1360
2024-05-25 02:54:42 [INFO]: Epoch 187 - training loss: 0.1920, validation loss: 0.1362
2024-05-25 02:54:43 [INFO]: Epoch 188 - training loss: 0.1906, validation loss: 0.1377
2024-05-25 02:54:44 [INFO]: Epoch 189 - training loss: 0.1911, validation loss: 0.1368
2024-05-25 02:54:44 [INFO]: Epoch 190 - training loss: 0.1911, validation loss: 0.1371
2024-05-25 02:54:45 [INFO]: Epoch 191 - training loss: 0.1895, validation loss: 0.1366
2024-05-25 02:54:45 [INFO]: Epoch 192 - training loss: 0.1896, validation loss: 0.1366
2024-05-25 02:54:46 [INFO]: Epoch 193 - training loss: 0.1893, validation loss: 0.1375
2024-05-25 02:54:47 [INFO]: Epoch 194 - training loss: 0.1900, validation loss: 0.1366
2024-05-25 02:54:47 [INFO]: Epoch 195 - training loss: 0.1892, validation loss: 0.1379
2024-05-25 02:54:48 [INFO]: Epoch 196 - training loss: 0.1879, validation loss: 0.1370
2024-05-25 02:54:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:54:48 [INFO]: Finished training. The best model is from epoch#186.
2024-05-25 02:54:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_air_quality/20240525_T025246/SAITS.pypots
2024-05-25 02:54:48 [INFO]: SAITS on Air-Quality: MAE=0.1575, MSE=0.1431
2024-05-25 02:54:48 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_air_quality/imputation.pkl
2024-05-25 02:54:48 [INFO]: Using the given device: cuda:0
2024-05-25 02:54:48 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240525_T025448
2024-05-25 02:54:48 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240525_T025448/tensorboard
2024-05-25 02:54:48 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 02:54:48 [INFO]: Epoch 001 - training loss: 0.9144, validation loss: 0.5015
2024-05-25 02:54:49 [INFO]: Epoch 002 - training loss: 0.5803, validation loss: 0.3735
2024-05-25 02:54:49 [INFO]: Epoch 003 - training loss: 0.4902, validation loss: 0.3197
2024-05-25 02:54:49 [INFO]: Epoch 004 - training loss: 0.4411, validation loss: 0.2862
2024-05-25 02:54:49 [INFO]: Epoch 005 - training loss: 0.4094, validation loss: 0.2720
2024-05-25 02:54:50 [INFO]: Epoch 006 - training loss: 0.3883, validation loss: 0.2613
2024-05-25 02:54:50 [INFO]: Epoch 007 - training loss: 0.3767, validation loss: 0.2506
2024-05-25 02:54:50 [INFO]: Epoch 008 - training loss: 0.3629, validation loss: 0.2470
2024-05-25 02:54:50 [INFO]: Epoch 009 - training loss: 0.3485, validation loss: 0.2401
2024-05-25 02:54:51 [INFO]: Epoch 010 - training loss: 0.3415, validation loss: 0.2355
2024-05-25 02:54:51 [INFO]: Epoch 011 - training loss: 0.3355, validation loss: 0.2312
2024-05-25 02:54:51 [INFO]: Epoch 012 - training loss: 0.3319, validation loss: 0.2283
2024-05-25 02:54:51 [INFO]: Epoch 013 - training loss: 0.3240, validation loss: 0.2233
2024-05-25 02:54:52 [INFO]: Epoch 014 - training loss: 0.3195, validation loss: 0.2187
2024-05-25 02:54:52 [INFO]: Epoch 015 - training loss: 0.3142, validation loss: 0.2177
2024-05-25 02:54:52 [INFO]: Epoch 016 - training loss: 0.3118, validation loss: 0.2151
2024-05-25 02:54:52 [INFO]: Epoch 017 - training loss: 0.3105, validation loss: 0.2089
2024-05-25 02:54:53 [INFO]: Epoch 018 - training loss: 0.3050, validation loss: 0.2079
2024-05-25 02:54:53 [INFO]: Epoch 019 - training loss: 0.3028, validation loss: 0.2037
2024-05-25 02:54:53 [INFO]: Epoch 020 - training loss: 0.2974, validation loss: 0.2017
2024-05-25 02:54:53 [INFO]: Epoch 021 - training loss: 0.2955, validation loss: 0.2024
2024-05-25 02:54:54 [INFO]: Epoch 022 - training loss: 0.2925, validation loss: 0.2007
2024-05-25 02:54:54 [INFO]: Epoch 023 - training loss: 0.2885, validation loss: 0.1988
2024-05-25 02:54:54 [INFO]: Epoch 024 - training loss: 0.2869, validation loss: 0.2014
2024-05-25 02:54:54 [INFO]: Epoch 025 - training loss: 0.2830, validation loss: 0.1970
2024-05-25 02:54:55 [INFO]: Epoch 026 - training loss: 0.2813, validation loss: 0.1950
2024-05-25 02:54:55 [INFO]: Epoch 027 - training loss: 0.2806, validation loss: 0.1942
2024-05-25 02:54:55 [INFO]: Epoch 028 - training loss: 0.2782, validation loss: 0.1933
2024-05-25 02:54:55 [INFO]: Epoch 029 - training loss: 0.2779, validation loss: 0.1926
2024-05-25 02:54:56 [INFO]: Epoch 030 - training loss: 0.2745, validation loss: 0.1934
2024-05-25 02:54:56 [INFO]: Epoch 031 - training loss: 0.2732, validation loss: 0.1906
2024-05-25 02:54:56 [INFO]: Epoch 032 - training loss: 0.2750, validation loss: 0.1925
2024-05-25 02:54:56 [INFO]: Epoch 033 - training loss: 0.2707, validation loss: 0.1899
2024-05-25 02:54:57 [INFO]: Epoch 034 - training loss: 0.2658, validation loss: 0.1889
2024-05-25 02:54:57 [INFO]: Epoch 035 - training loss: 0.2668, validation loss: 0.1888
2024-05-25 02:54:57 [INFO]: Epoch 036 - training loss: 0.2640, validation loss: 0.1862
2024-05-25 02:54:57 [INFO]: Epoch 037 - training loss: 0.2659, validation loss: 0.1864
2024-05-25 02:54:57 [INFO]: Epoch 038 - training loss: 0.2614, validation loss: 0.1846
2024-05-25 02:54:58 [INFO]: Epoch 039 - training loss: 0.2587, validation loss: 0.1850
2024-05-25 02:54:58 [INFO]: Epoch 040 - training loss: 0.2571, validation loss: 0.1859
2024-05-25 02:54:58 [INFO]: Epoch 041 - training loss: 0.2559, validation loss: 0.1855
2024-05-25 02:54:58 [INFO]: Epoch 042 - training loss: 0.2537, validation loss: 0.1837
2024-05-25 02:54:59 [INFO]: Epoch 043 - training loss: 0.2524, validation loss: 0.1842
2024-05-25 02:54:59 [INFO]: Epoch 044 - training loss: 0.2534, validation loss: 0.1825
2024-05-25 02:54:59 [INFO]: Epoch 045 - training loss: 0.2556, validation loss: 0.1830
2024-05-25 02:54:59 [INFO]: Epoch 046 - training loss: 0.2505, validation loss: 0.1834
2024-05-25 02:55:00 [INFO]: Epoch 047 - training loss: 0.2482, validation loss: 0.1818
2024-05-25 02:55:00 [INFO]: Epoch 048 - training loss: 0.2456, validation loss: 0.1820
2024-05-25 02:55:00 [INFO]: Epoch 049 - training loss: 0.2445, validation loss: 0.1814
2024-05-25 02:55:00 [INFO]: Epoch 050 - training loss: 0.2438, validation loss: 0.1830
2024-05-25 02:55:01 [INFO]: Epoch 051 - training loss: 0.2468, validation loss: 0.1809
2024-05-25 02:55:01 [INFO]: Epoch 052 - training loss: 0.2427, validation loss: 0.1822
2024-05-25 02:55:01 [INFO]: Epoch 053 - training loss: 0.2435, validation loss: 0.1795
2024-05-25 02:55:01 [INFO]: Epoch 054 - training loss: 0.2416, validation loss: 0.1809
2024-05-25 02:55:02 [INFO]: Epoch 055 - training loss: 0.2383, validation loss: 0.1792
2024-05-25 02:55:02 [INFO]: Epoch 056 - training loss: 0.2401, validation loss: 0.1788
2024-05-25 02:55:02 [INFO]: Epoch 057 - training loss: 0.2391, validation loss: 0.1796
2024-05-25 02:55:02 [INFO]: Epoch 058 - training loss: 0.2357, validation loss: 0.1793
2024-05-25 02:55:03 [INFO]: Epoch 059 - training loss: 0.2338, validation loss: 0.1792
2024-05-25 02:55:03 [INFO]: Epoch 060 - training loss: 0.2347, validation loss: 0.1786
2024-05-25 02:55:03 [INFO]: Epoch 061 - training loss: 0.2317, validation loss: 0.1781
2024-05-25 02:55:03 [INFO]: Epoch 062 - training loss: 0.2312, validation loss: 0.1774
2024-05-25 02:55:04 [INFO]: Epoch 063 - training loss: 0.2297, validation loss: 0.1771
2024-05-25 02:55:04 [INFO]: Epoch 064 - training loss: 0.2297, validation loss: 0.1771
2024-05-25 02:55:04 [INFO]: Epoch 065 - training loss: 0.2276, validation loss: 0.1776
2024-05-25 02:55:04 [INFO]: Epoch 066 - training loss: 0.2288, validation loss: 0.1794
2024-05-25 02:55:05 [INFO]: Epoch 067 - training loss: 0.2285, validation loss: 0.1780
2024-05-25 02:55:05 [INFO]: Epoch 068 - training loss: 0.2277, validation loss: 0.1766
2024-05-25 02:55:05 [INFO]: Epoch 069 - training loss: 0.2290, validation loss: 0.1763
2024-05-25 02:55:05 [INFO]: Epoch 070 - training loss: 0.2228, validation loss: 0.1753
2024-05-25 02:55:06 [INFO]: Epoch 071 - training loss: 0.2195, validation loss: 0.1763
2024-05-25 02:55:06 [INFO]: Epoch 072 - training loss: 0.2201, validation loss: 0.1758
2024-05-25 02:55:06 [INFO]: Epoch 073 - training loss: 0.2199, validation loss: 0.1761
2024-05-25 02:55:06 [INFO]: Epoch 074 - training loss: 0.2190, validation loss: 0.1743
2024-05-25 02:55:07 [INFO]: Epoch 075 - training loss: 0.2161, validation loss: 0.1732
2024-05-25 02:55:07 [INFO]: Epoch 076 - training loss: 0.2152, validation loss: 0.1759
2024-05-25 02:55:07 [INFO]: Epoch 077 - training loss: 0.2158, validation loss: 0.1747
2024-05-25 02:55:07 [INFO]: Epoch 078 - training loss: 0.2149, validation loss: 0.1733
2024-05-25 02:55:08 [INFO]: Epoch 079 - training loss: 0.2139, validation loss: 0.1739
2024-05-25 02:55:08 [INFO]: Epoch 080 - training loss: 0.2171, validation loss: 0.1749
2024-05-25 02:55:08 [INFO]: Epoch 081 - training loss: 0.2130, validation loss: 0.1729
2024-05-25 02:55:08 [INFO]: Epoch 082 - training loss: 0.2128, validation loss: 0.1717
2024-05-25 02:55:09 [INFO]: Epoch 083 - training loss: 0.2139, validation loss: 0.1743
2024-05-25 02:55:09 [INFO]: Epoch 084 - training loss: 0.2110, validation loss: 0.1718
2024-05-25 02:55:09 [INFO]: Epoch 085 - training loss: 0.2102, validation loss: 0.1715
2024-05-25 02:55:09 [INFO]: Epoch 086 - training loss: 0.2100, validation loss: 0.1739
2024-05-25 02:55:10 [INFO]: Epoch 087 - training loss: 0.2076, validation loss: 0.1721
2024-05-25 02:55:10 [INFO]: Epoch 088 - training loss: 0.2068, validation loss: 0.1715
2024-05-25 02:55:10 [INFO]: Epoch 089 - training loss: 0.2056, validation loss: 0.1723
2024-05-25 02:55:10 [INFO]: Epoch 090 - training loss: 0.2057, validation loss: 0.1714
2024-05-25 02:55:11 [INFO]: Epoch 091 - training loss: 0.2057, validation loss: 0.1732
2024-05-25 02:55:11 [INFO]: Epoch 092 - training loss: 0.2036, validation loss: 0.1713
2024-05-25 02:55:11 [INFO]: Epoch 093 - training loss: 0.2035, validation loss: 0.1714
2024-05-25 02:55:11 [INFO]: Epoch 094 - training loss: 0.2028, validation loss: 0.1703
2024-05-25 02:55:12 [INFO]: Epoch 095 - training loss: 0.2023, validation loss: 0.1723
2024-05-25 02:55:12 [INFO]: Epoch 096 - training loss: 0.2022, validation loss: 0.1714
2024-05-25 02:55:12 [INFO]: Epoch 097 - training loss: 0.2014, validation loss: 0.1720
2024-05-25 02:55:12 [INFO]: Epoch 098 - training loss: 0.2006, validation loss: 0.1706
2024-05-25 02:55:13 [INFO]: Epoch 099 - training loss: 0.1983, validation loss: 0.1704
2024-05-25 02:55:13 [INFO]: Epoch 100 - training loss: 0.1981, validation loss: 0.1697
2024-05-25 02:55:13 [INFO]: Epoch 101 - training loss: 0.1971, validation loss: 0.1715
2024-05-25 02:55:13 [INFO]: Epoch 102 - training loss: 0.1959, validation loss: 0.1691
2024-05-25 02:55:14 [INFO]: Epoch 103 - training loss: 0.1962, validation loss: 0.1687
2024-05-25 02:55:14 [INFO]: Epoch 104 - training loss: 0.1951, validation loss: 0.1684
2024-05-25 02:55:14 [INFO]: Epoch 105 - training loss: 0.2002, validation loss: 0.1704
2024-05-25 02:55:14 [INFO]: Epoch 106 - training loss: 0.1993, validation loss: 0.1690
2024-05-25 02:55:15 [INFO]: Epoch 107 - training loss: 0.1961, validation loss: 0.1685
2024-05-25 02:55:15 [INFO]: Epoch 108 - training loss: 0.1939, validation loss: 0.1681
2024-05-25 02:55:15 [INFO]: Epoch 109 - training loss: 0.1961, validation loss: 0.1687
2024-05-25 02:55:15 [INFO]: Epoch 110 - training loss: 0.1917, validation loss: 0.1681
2024-05-25 02:55:16 [INFO]: Epoch 111 - training loss: 0.1890, validation loss: 0.1680
2024-05-25 02:55:16 [INFO]: Epoch 112 - training loss: 0.1900, validation loss: 0.1689
2024-05-25 02:55:16 [INFO]: Epoch 113 - training loss: 0.1895, validation loss: 0.1679
2024-05-25 02:55:16 [INFO]: Epoch 114 - training loss: 0.1902, validation loss: 0.1688
2024-05-25 02:55:17 [INFO]: Epoch 115 - training loss: 0.1895, validation loss: 0.1670
2024-05-25 02:55:17 [INFO]: Epoch 116 - training loss: 0.1885, validation loss: 0.1677
2024-05-25 02:55:17 [INFO]: Epoch 117 - training loss: 0.1865, validation loss: 0.1665
2024-05-25 02:55:17 [INFO]: Epoch 118 - training loss: 0.1899, validation loss: 0.1694
2024-05-25 02:55:18 [INFO]: Epoch 119 - training loss: 0.1869, validation loss: 0.1685
2024-05-25 02:55:18 [INFO]: Epoch 120 - training loss: 0.1850, validation loss: 0.1671
2024-05-25 02:55:18 [INFO]: Epoch 121 - training loss: 0.1843, validation loss: 0.1675
2024-05-25 02:55:18 [INFO]: Epoch 122 - training loss: 0.1845, validation loss: 0.1670
2024-05-25 02:55:19 [INFO]: Epoch 123 - training loss: 0.1865, validation loss: 0.1673
2024-05-25 02:55:19 [INFO]: Epoch 124 - training loss: 0.1848, validation loss: 0.1676
2024-05-25 02:55:19 [INFO]: Epoch 125 - training loss: 0.1854, validation loss: 0.1687
2024-05-25 02:55:19 [INFO]: Epoch 126 - training loss: 0.1873, validation loss: 0.1660
2024-05-25 02:55:20 [INFO]: Epoch 127 - training loss: 0.1818, validation loss: 0.1655
2024-05-25 02:55:20 [INFO]: Epoch 128 - training loss: 0.1807, validation loss: 0.1668
2024-05-25 02:55:20 [INFO]: Epoch 129 - training loss: 0.1811, validation loss: 0.1682
2024-05-25 02:55:20 [INFO]: Epoch 130 - training loss: 0.1790, validation loss: 0.1667
2024-05-25 02:55:21 [INFO]: Epoch 131 - training loss: 0.1778, validation loss: 0.1675
2024-05-25 02:55:21 [INFO]: Epoch 132 - training loss: 0.1779, validation loss: 0.1668
2024-05-25 02:55:21 [INFO]: Epoch 133 - training loss: 0.1780, validation loss: 0.1659
2024-05-25 02:55:21 [INFO]: Epoch 134 - training loss: 0.1757, validation loss: 0.1663
2024-05-25 02:55:22 [INFO]: Epoch 135 - training loss: 0.1762, validation loss: 0.1664
2024-05-25 02:55:22 [INFO]: Epoch 136 - training loss: 0.1751, validation loss: 0.1663
2024-05-25 02:55:22 [INFO]: Epoch 137 - training loss: 0.1750, validation loss: 0.1663
2024-05-25 02:55:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:55:22 [INFO]: Finished training. The best model is from epoch#127.
2024-05-25 02:55:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_air_quality/20240525_T025448/Transformer.pypots
2024-05-25 02:55:22 [INFO]: Transformer on Air-Quality: MAE=0.1804, MSE=0.1684
2024-05-25 02:55:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_air_quality/imputation.pkl
2024-05-25 02:55:22 [INFO]: Using the given device: cuda:0
2024-05-25 02:55:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240525_T025522
2024-05-25 02:55:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240525_T025522/tensorboard
2024-05-25 02:55:23 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 02:55:24 [INFO]: Epoch 001 - training loss: 0.3009, validation loss: 0.2867
2024-05-25 02:55:24 [INFO]: Epoch 002 - training loss: 0.2059, validation loss: 0.2597
2024-05-25 02:55:24 [INFO]: Epoch 003 - training loss: 0.1848, validation loss: 0.2307
2024-05-25 02:55:25 [INFO]: Epoch 004 - training loss: 0.1593, validation loss: 0.2151
2024-05-25 02:55:25 [INFO]: Epoch 005 - training loss: 0.1547, validation loss: 0.2078
2024-05-25 02:55:26 [INFO]: Epoch 006 - training loss: 0.1400, validation loss: 0.2008
2024-05-25 02:55:26 [INFO]: Epoch 007 - training loss: 0.1304, validation loss: 0.1980
2024-05-25 02:55:27 [INFO]: Epoch 008 - training loss: 0.1269, validation loss: 0.1963
2024-05-25 02:55:27 [INFO]: Epoch 009 - training loss: 0.1232, validation loss: 0.1961
2024-05-25 02:55:28 [INFO]: Epoch 010 - training loss: 0.1213, validation loss: 0.1992
2024-05-25 02:55:28 [INFO]: Epoch 011 - training loss: 0.1288, validation loss: 0.2063
2024-05-25 02:55:29 [INFO]: Epoch 012 - training loss: 0.1217, validation loss: 0.1953
2024-05-25 02:55:29 [INFO]: Epoch 013 - training loss: 0.1113, validation loss: 0.1940
2024-05-25 02:55:29 [INFO]: Epoch 014 - training loss: 0.1072, validation loss: 0.1905
2024-05-25 02:55:30 [INFO]: Epoch 015 - training loss: 0.1054, validation loss: 0.1922
2024-05-25 02:55:30 [INFO]: Epoch 016 - training loss: 0.1019, validation loss: 0.1908
2024-05-25 02:55:31 [INFO]: Epoch 017 - training loss: 0.1044, validation loss: 0.1932
2024-05-25 02:55:31 [INFO]: Epoch 018 - training loss: 0.1039, validation loss: 0.1870
2024-05-25 02:55:32 [INFO]: Epoch 019 - training loss: 0.0989, validation loss: 0.1850
2024-05-25 02:55:32 [INFO]: Epoch 020 - training loss: 0.0937, validation loss: 0.1933
2024-05-25 02:55:33 [INFO]: Epoch 021 - training loss: 0.0904, validation loss: 0.1939
2024-05-25 02:55:33 [INFO]: Epoch 022 - training loss: 0.0890, validation loss: 0.1885
2024-05-25 02:55:34 [INFO]: Epoch 023 - training loss: 0.0870, validation loss: 0.1930
2024-05-25 02:55:34 [INFO]: Epoch 024 - training loss: 0.0893, validation loss: 0.1953
2024-05-25 02:55:34 [INFO]: Epoch 025 - training loss: 0.0879, validation loss: 0.1930
2024-05-25 02:55:35 [INFO]: Epoch 026 - training loss: 0.0863, validation loss: 0.1881
2024-05-25 02:55:35 [INFO]: Epoch 027 - training loss: 0.0860, validation loss: 0.1945
2024-05-25 02:55:36 [INFO]: Epoch 028 - training loss: 0.0824, validation loss: 0.1877
2024-05-25 02:55:36 [INFO]: Epoch 029 - training loss: 0.0822, validation loss: 0.1955
2024-05-25 02:55:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 02:55:36 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 02:55:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_air_quality/20240525_T025522/TimesNet.pypots
2024-05-25 02:55:37 [INFO]: TimesNet on Air-Quality: MAE=0.1701, MSE=0.2234
2024-05-25 02:55:37 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_air_quality/imputation.pkl
2024-05-25 02:55:37 [INFO]: Using the given device: cuda:0
2024-05-25 02:55:37 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537
2024-05-25 02:55:37 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/tensorboard
2024-05-25 02:55:37 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 02:55:53 [INFO]: Epoch 001 - training loss: 0.5153, validation loss: 0.3375
2024-05-25 02:55:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch1_loss0.3374761939048767.pypots
2024-05-25 02:56:10 [INFO]: Epoch 002 - training loss: 0.2868, validation loss: 0.2666
2024-05-25 02:56:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch2_loss0.2666491150856018.pypots
2024-05-25 02:56:27 [INFO]: Epoch 003 - training loss: 0.2307, validation loss: 0.2178
2024-05-25 02:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch3_loss0.2178083047270775.pypots
2024-05-25 02:56:43 [INFO]: Epoch 004 - training loss: 0.2217, validation loss: 0.1946
2024-05-25 02:56:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch4_loss0.1946061670780182.pypots
2024-05-25 02:57:00 [INFO]: Epoch 005 - training loss: 0.1894, validation loss: 0.1774
2024-05-25 02:57:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch5_loss0.177401340007782.pypots
2024-05-25 02:57:17 [INFO]: Epoch 006 - training loss: 0.1649, validation loss: 0.1611
2024-05-25 02:57:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch6_loss0.1611279994249344.pypots
2024-05-25 02:57:34 [INFO]: Epoch 007 - training loss: 0.1639, validation loss: 0.1576
2024-05-25 02:57:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch7_loss0.1576343521475792.pypots
2024-05-25 02:57:50 [INFO]: Epoch 008 - training loss: 0.1574, validation loss: 0.1551
2024-05-25 02:57:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch8_loss0.1550632819533348.pypots
2024-05-25 02:58:07 [INFO]: Epoch 009 - training loss: 0.1623, validation loss: 0.1514
2024-05-25 02:58:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch9_loss0.15139947682619095.pypots
2024-05-25 02:58:24 [INFO]: Epoch 010 - training loss: 0.1427, validation loss: 0.1466
2024-05-25 02:58:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch10_loss0.1465935379266739.pypots
2024-05-25 02:58:40 [INFO]: Epoch 011 - training loss: 0.1444, validation loss: 0.1503
2024-05-25 02:58:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch11_loss0.15032880157232284.pypots
2024-05-25 02:58:57 [INFO]: Epoch 012 - training loss: 0.1652, validation loss: 0.1455
2024-05-25 02:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch12_loss0.14550159722566605.pypots
2024-05-25 02:59:14 [INFO]: Epoch 013 - training loss: 0.1503, validation loss: 0.1384
2024-05-25 02:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch13_loss0.13844781294465064.pypots
2024-05-25 02:59:30 [INFO]: Epoch 014 - training loss: 0.1501, validation loss: 0.1411
2024-05-25 02:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch14_loss0.1411492720246315.pypots
2024-05-25 02:59:47 [INFO]: Epoch 015 - training loss: 0.1505, validation loss: 0.1401
2024-05-25 02:59:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch15_loss0.14011164158582687.pypots
2024-05-25 03:00:04 [INFO]: Epoch 016 - training loss: 0.1538, validation loss: 0.1395
2024-05-25 03:00:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch16_loss0.13954374566674232.pypots
2024-05-25 03:00:20 [INFO]: Epoch 017 - training loss: 0.1596, validation loss: 0.1408
2024-05-25 03:00:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch17_loss0.1407869689166546.pypots
2024-05-25 03:00:37 [INFO]: Epoch 018 - training loss: 0.1407, validation loss: 0.1358
2024-05-25 03:00:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch18_loss0.13580470457673072.pypots
2024-05-25 03:00:54 [INFO]: Epoch 019 - training loss: 0.1419, validation loss: 0.1342
2024-05-25 03:00:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch19_loss0.13420171588659285.pypots
2024-05-25 03:01:10 [INFO]: Epoch 020 - training loss: 0.1230, validation loss: 0.1326
2024-05-25 03:01:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch20_loss0.1325939528644085.pypots
2024-05-25 03:01:27 [INFO]: Epoch 021 - training loss: 0.1317, validation loss: 0.1341
2024-05-25 03:01:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch21_loss0.13414497151970864.pypots
2024-05-25 03:01:44 [INFO]: Epoch 022 - training loss: 0.1340, validation loss: 0.1302
2024-05-25 03:01:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch22_loss0.13016027212142944.pypots
2024-05-25 03:02:00 [INFO]: Epoch 023 - training loss: 0.1356, validation loss: 0.1346
2024-05-25 03:02:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch23_loss0.13464838191866874.pypots
2024-05-25 03:02:17 [INFO]: Epoch 024 - training loss: 0.1316, validation loss: 0.1339
2024-05-25 03:02:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch24_loss0.13390145003795623.pypots
2024-05-25 03:02:34 [INFO]: Epoch 025 - training loss: 0.1296, validation loss: 0.1292
2024-05-25 03:02:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch25_loss0.12915042638778687.pypots
2024-05-25 03:02:50 [INFO]: Epoch 026 - training loss: 0.1223, validation loss: 0.1301
2024-05-25 03:02:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch26_loss0.13011833950877189.pypots
2024-05-25 03:03:07 [INFO]: Epoch 027 - training loss: 0.1382, validation loss: 0.1325
2024-05-25 03:03:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch27_loss0.13249085769057273.pypots
2024-05-25 03:03:24 [INFO]: Epoch 028 - training loss: 0.1372, validation loss: 0.1301
2024-05-25 03:03:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch28_loss0.13009654656052588.pypots
2024-05-25 03:03:40 [INFO]: Epoch 029 - training loss: 0.1202, validation loss: 0.1270
2024-05-25 03:03:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch29_loss0.1269919365644455.pypots
2024-05-25 03:03:57 [INFO]: Epoch 030 - training loss: 0.1198, validation loss: 0.1258
2024-05-25 03:03:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch30_loss0.12583769783377646.pypots
2024-05-25 03:04:14 [INFO]: Epoch 031 - training loss: 0.1258, validation loss: 0.1308
2024-05-25 03:04:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch31_loss0.13083162531256676.pypots
2024-05-25 03:04:30 [INFO]: Epoch 032 - training loss: 0.1242, validation loss: 0.1262
2024-05-25 03:04:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch32_loss0.12621392533183098.pypots
2024-05-25 03:04:47 [INFO]: Epoch 033 - training loss: 0.1223, validation loss: 0.1240
2024-05-25 03:04:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch33_loss0.12401003390550613.pypots
2024-05-25 03:05:04 [INFO]: Epoch 034 - training loss: 0.1221, validation loss: 0.1252
2024-05-25 03:05:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch34_loss0.1252044804394245.pypots
2024-05-25 03:05:20 [INFO]: Epoch 035 - training loss: 0.1191, validation loss: 0.1241
2024-05-25 03:05:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch35_loss0.12405629903078079.pypots
2024-05-25 03:05:37 [INFO]: Epoch 036 - training loss: 0.1175, validation loss: 0.1233
2024-05-25 03:05:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch36_loss0.12329752072691917.pypots
2024-05-25 03:05:54 [INFO]: Epoch 037 - training loss: 0.1189, validation loss: 0.1200
2024-05-25 03:05:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch37_loss0.12001845538616181.pypots
2024-05-25 03:06:11 [INFO]: Epoch 038 - training loss: 0.1319, validation loss: 0.1205
2024-05-25 03:06:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch38_loss0.12049789130687713.pypots
2024-05-25 03:06:27 [INFO]: Epoch 039 - training loss: 0.1187, validation loss: 0.1221
2024-05-25 03:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch39_loss0.1221073605120182.pypots
2024-05-25 03:06:44 [INFO]: Epoch 040 - training loss: 0.1211, validation loss: 0.1213
2024-05-25 03:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch40_loss0.12131380513310433.pypots
2024-05-25 03:07:01 [INFO]: Epoch 041 - training loss: 0.1220, validation loss: 0.1217
2024-05-25 03:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch41_loss0.12167943716049194.pypots
2024-05-25 03:07:17 [INFO]: Epoch 042 - training loss: 0.1135, validation loss: 0.1199
2024-05-25 03:07:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch42_loss0.11993121579289437.pypots
2024-05-25 03:07:34 [INFO]: Epoch 043 - training loss: 0.1144, validation loss: 0.1163
2024-05-25 03:07:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch43_loss0.1162992499768734.pypots
2024-05-25 03:07:51 [INFO]: Epoch 044 - training loss: 0.1175, validation loss: 0.1177
2024-05-25 03:07:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch44_loss0.11768768578767777.pypots
2024-05-25 03:08:07 [INFO]: Epoch 045 - training loss: 0.1167, validation loss: 0.1165
2024-05-25 03:08:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch45_loss0.1164712741971016.pypots
2024-05-25 03:08:24 [INFO]: Epoch 046 - training loss: 0.1260, validation loss: 0.1183
2024-05-25 03:08:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch46_loss0.1183385744690895.pypots
2024-05-25 03:08:41 [INFO]: Epoch 047 - training loss: 0.1084, validation loss: 0.1190
2024-05-25 03:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch47_loss0.11903646737337112.pypots
2024-05-25 03:08:57 [INFO]: Epoch 048 - training loss: 0.1140, validation loss: 0.1186
2024-05-25 03:08:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch48_loss0.11862557232379914.pypots
2024-05-25 03:09:14 [INFO]: Epoch 049 - training loss: 0.1155, validation loss: 0.1214
2024-05-25 03:09:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch49_loss0.1214340902864933.pypots
2024-05-25 03:09:31 [INFO]: Epoch 050 - training loss: 0.1131, validation loss: 0.1183
2024-05-25 03:09:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch50_loss0.1182635858654976.pypots
2024-05-25 03:09:47 [INFO]: Epoch 051 - training loss: 0.1114, validation loss: 0.1137
2024-05-25 03:09:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch51_loss0.11372086107730865.pypots
2024-05-25 03:10:04 [INFO]: Epoch 052 - training loss: 0.0998, validation loss: 0.1121
2024-05-25 03:10:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch52_loss0.1120791494846344.pypots
2024-05-25 03:10:21 [INFO]: Epoch 053 - training loss: 0.1165, validation loss: 0.1137
2024-05-25 03:10:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch53_loss0.11371947154402733.pypots
2024-05-25 03:10:37 [INFO]: Epoch 054 - training loss: 0.1229, validation loss: 0.1154
2024-05-25 03:10:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch54_loss0.11542469114065171.pypots
2024-05-25 03:10:54 [INFO]: Epoch 055 - training loss: 0.1156, validation loss: 0.1168
2024-05-25 03:10:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch55_loss0.11680854484438896.pypots
2024-05-25 03:11:11 [INFO]: Epoch 056 - training loss: 0.1022, validation loss: 0.1140
2024-05-25 03:11:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch56_loss0.11395501643419266.pypots
2024-05-25 03:11:27 [INFO]: Epoch 057 - training loss: 0.0964, validation loss: 0.1159
2024-05-25 03:11:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch57_loss0.11585948318243026.pypots
2024-05-25 03:11:44 [INFO]: Epoch 058 - training loss: 0.1199, validation loss: 0.1136
2024-05-25 03:11:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch58_loss0.11355793699622155.pypots
2024-05-25 03:12:01 [INFO]: Epoch 059 - training loss: 0.1132, validation loss: 0.1107
2024-05-25 03:12:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch59_loss0.11069479808211327.pypots
2024-05-25 03:12:17 [INFO]: Epoch 060 - training loss: 0.1110, validation loss: 0.1107
2024-05-25 03:12:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch60_loss0.1106549248099327.pypots
2024-05-25 03:12:34 [INFO]: Epoch 061 - training loss: 0.0975, validation loss: 0.1125
2024-05-25 03:12:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch61_loss0.11245859265327454.pypots
2024-05-25 03:12:51 [INFO]: Epoch 062 - training loss: 0.1062, validation loss: 0.1095
2024-05-25 03:12:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch62_loss0.10945382788777351.pypots
2024-05-25 03:13:07 [INFO]: Epoch 063 - training loss: 0.1058, validation loss: 0.1107
2024-05-25 03:13:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch63_loss0.11068373769521714.pypots
2024-05-25 03:13:24 [INFO]: Epoch 064 - training loss: 0.0885, validation loss: 0.1096
2024-05-25 03:13:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch64_loss0.10963412299752236.pypots
2024-05-25 03:13:41 [INFO]: Epoch 065 - training loss: 0.1084, validation loss: 0.1105
2024-05-25 03:13:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch65_loss0.11053325980901718.pypots
2024-05-25 03:13:57 [INFO]: Epoch 066 - training loss: 0.0944, validation loss: 0.1104
2024-05-25 03:13:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch66_loss0.11040510982275009.pypots
2024-05-25 03:14:14 [INFO]: Epoch 067 - training loss: 0.1109, validation loss: 0.1205
2024-05-25 03:14:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch67_loss0.12050004452466964.pypots
2024-05-25 03:14:31 [INFO]: Epoch 068 - training loss: 0.1088, validation loss: 0.1111
2024-05-25 03:14:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch68_loss0.111060930788517.pypots
2024-05-25 03:14:47 [INFO]: Epoch 069 - training loss: 0.1038, validation loss: 0.1085
2024-05-25 03:14:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch69_loss0.10850931704044342.pypots
2024-05-25 03:15:04 [INFO]: Epoch 070 - training loss: 0.0996, validation loss: 0.1085
2024-05-25 03:15:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch70_loss0.1085452564060688.pypots
2024-05-25 03:15:21 [INFO]: Epoch 071 - training loss: 0.1078, validation loss: 0.1082
2024-05-25 03:15:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch71_loss0.10817829743027688.pypots
2024-05-25 03:15:37 [INFO]: Epoch 072 - training loss: 0.1083, validation loss: 0.1083
2024-05-25 03:15:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch72_loss0.10833464711904525.pypots
2024-05-25 03:15:54 [INFO]: Epoch 073 - training loss: 0.1054, validation loss: 0.1069
2024-05-25 03:15:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch73_loss0.1068920873105526.pypots
2024-05-25 03:16:11 [INFO]: Epoch 074 - training loss: 0.1044, validation loss: 0.1078
2024-05-25 03:16:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch74_loss0.10778266191482544.pypots
2024-05-25 03:16:28 [INFO]: Epoch 075 - training loss: 0.1015, validation loss: 0.1106
2024-05-25 03:16:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch75_loss0.11056244596838952.pypots
2024-05-25 03:16:44 [INFO]: Epoch 076 - training loss: 0.1207, validation loss: 0.1073
2024-05-25 03:16:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch76_loss0.10734280422329903.pypots
2024-05-25 03:17:01 [INFO]: Epoch 077 - training loss: 0.0984, validation loss: 0.1069
2024-05-25 03:17:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch77_loss0.10686217620968819.pypots
2024-05-25 03:17:18 [INFO]: Epoch 078 - training loss: 0.0938, validation loss: 0.1088
2024-05-25 03:17:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch78_loss0.10881264507770538.pypots
2024-05-25 03:17:34 [INFO]: Epoch 079 - training loss: 0.1038, validation loss: 0.1082
2024-05-25 03:17:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch79_loss0.10821637958288192.pypots
2024-05-25 03:17:51 [INFO]: Epoch 080 - training loss: 0.1120, validation loss: 0.1095
2024-05-25 03:17:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch80_loss0.10952840596437455.pypots
2024-05-25 03:18:08 [INFO]: Epoch 081 - training loss: 0.1005, validation loss: 0.1033
2024-05-25 03:18:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch81_loss0.10328802689909936.pypots
2024-05-25 03:18:24 [INFO]: Epoch 082 - training loss: 0.0988, validation loss: 0.1051
2024-05-25 03:18:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch82_loss0.10511407479643822.pypots
2024-05-25 03:18:41 [INFO]: Epoch 083 - training loss: 0.1131, validation loss: 0.1077
2024-05-25 03:18:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch83_loss0.10774130895733833.pypots
2024-05-25 03:18:58 [INFO]: Epoch 084 - training loss: 0.0993, validation loss: 0.1053
2024-05-25 03:18:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch84_loss0.1052989274263382.pypots
2024-05-25 03:19:14 [INFO]: Epoch 085 - training loss: 0.0988, validation loss: 0.1064
2024-05-25 03:19:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch85_loss0.10644176378846168.pypots
2024-05-25 03:19:31 [INFO]: Epoch 086 - training loss: 0.0971, validation loss: 0.1031
2024-05-25 03:19:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch86_loss0.10305372029542922.pypots
2024-05-25 03:19:48 [INFO]: Epoch 087 - training loss: 0.0947, validation loss: 0.1037
2024-05-25 03:19:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch87_loss0.10370828732848167.pypots
2024-05-25 03:20:04 [INFO]: Epoch 088 - training loss: 0.1038, validation loss: 0.1063
2024-05-25 03:20:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch88_loss0.10628835186362266.pypots
2024-05-25 03:20:21 [INFO]: Epoch 089 - training loss: 0.1039, validation loss: 0.1032
2024-05-25 03:20:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch89_loss0.10315184369683265.pypots
2024-05-25 03:20:38 [INFO]: Epoch 090 - training loss: 0.1051, validation loss: 0.1074
2024-05-25 03:20:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch90_loss0.10742929503321648.pypots
2024-05-25 03:20:54 [INFO]: Epoch 091 - training loss: 0.1081, validation loss: 0.1046
2024-05-25 03:20:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch91_loss0.10459613427519798.pypots
2024-05-25 03:21:11 [INFO]: Epoch 092 - training loss: 0.1012, validation loss: 0.1053
2024-05-25 03:21:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch92_loss0.10534102842211723.pypots
2024-05-25 03:21:28 [INFO]: Epoch 093 - training loss: 0.0933, validation loss: 0.1044
2024-05-25 03:21:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch93_loss0.104387915879488.pypots
2024-05-25 03:21:44 [INFO]: Epoch 094 - training loss: 0.0951, validation loss: 0.1069
2024-05-25 03:21:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch94_loss0.10687652379274368.pypots
2024-05-25 03:22:01 [INFO]: Epoch 095 - training loss: 0.1167, validation loss: 0.1038
2024-05-25 03:22:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch95_loss0.10380765497684478.pypots
2024-05-25 03:22:18 [INFO]: Epoch 096 - training loss: 0.0927, validation loss: 0.1034
2024-05-25 03:22:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI_epoch96_loss0.10343838408589363.pypots
2024-05-25 03:22:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:22:18 [INFO]: Finished training. The best model is from epoch#86.
2024-05-25 03:22:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_air_quality/20240525_T025537/CSDI.pypots
2024-05-25 03:24:38 [INFO]: CSDI on Air-Quality: MAE=0.1069, MSE=0.1613
2024-05-25 03:24:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_air_quality/imputation.pkl
2024-05-25 03:24:38 [INFO]: Using the given device: cuda:0
2024-05-25 03:24:38 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240525_T032438
2024-05-25 03:24:38 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240525_T032438/tensorboard
2024-05-25 03:24:38 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 03:24:39 [INFO]: Epoch 001 - training loss: 64863.9802, validation loss: 0.6756
2024-05-25 03:24:39 [INFO]: Epoch 002 - training loss: 41567.3678, validation loss: 0.5941
2024-05-25 03:24:39 [INFO]: Epoch 003 - training loss: 41214.6759, validation loss: 0.5543
2024-05-25 03:24:40 [INFO]: Epoch 004 - training loss: 41072.0172, validation loss: 0.5018
2024-05-25 03:24:40 [INFO]: Epoch 005 - training loss: 40984.9783, validation loss: 0.4686
2024-05-25 03:24:40 [INFO]: Epoch 006 - training loss: 40911.1481, validation loss: 0.4331
2024-05-25 03:24:41 [INFO]: Epoch 007 - training loss: 40853.6076, validation loss: 0.4075
2024-05-25 03:24:41 [INFO]: Epoch 008 - training loss: 40820.7935, validation loss: 0.3870
2024-05-25 03:24:41 [INFO]: Epoch 009 - training loss: 40799.8961, validation loss: 0.3695
2024-05-25 03:24:41 [INFO]: Epoch 010 - training loss: 40824.7419, validation loss: 0.3944
2024-05-25 03:24:42 [INFO]: Epoch 011 - training loss: 40783.6285, validation loss: 0.3648
2024-05-25 03:24:42 [INFO]: Epoch 012 - training loss: 40741.2545, validation loss: 0.3402
2024-05-25 03:24:42 [INFO]: Epoch 013 - training loss: 40717.5558, validation loss: 0.3280
2024-05-25 03:24:43 [INFO]: Epoch 014 - training loss: 40724.7854, validation loss: 0.3245
2024-05-25 03:24:43 [INFO]: Epoch 015 - training loss: 40704.7711, validation loss: 0.3136
2024-05-25 03:24:43 [INFO]: Epoch 016 - training loss: 40708.2925, validation loss: 0.3200
2024-05-25 03:24:44 [INFO]: Epoch 017 - training loss: 40678.2436, validation loss: 0.3294
2024-05-25 03:24:44 [INFO]: Epoch 018 - training loss: 40671.5343, validation loss: 0.3014
2024-05-25 03:24:44 [INFO]: Epoch 019 - training loss: 40656.1959, validation loss: 0.3147
2024-05-25 03:24:45 [INFO]: Epoch 020 - training loss: 40651.8112, validation loss: 0.2964
2024-05-25 03:24:45 [INFO]: Epoch 021 - training loss: 40651.7659, validation loss: 0.2945
2024-05-25 03:24:45 [INFO]: Epoch 022 - training loss: 40638.9897, validation loss: 0.2908
2024-05-25 03:24:46 [INFO]: Epoch 023 - training loss: 40628.2428, validation loss: 0.2884
2024-05-25 03:24:46 [INFO]: Epoch 024 - training loss: 40622.6811, validation loss: 0.2770
2024-05-25 03:24:46 [INFO]: Epoch 025 - training loss: 40621.0317, validation loss: 0.2825
2024-05-25 03:24:47 [INFO]: Epoch 026 - training loss: 40618.7976, validation loss: 0.2989
2024-05-25 03:24:47 [INFO]: Epoch 027 - training loss: 40611.5014, validation loss: 0.2713
2024-05-25 03:24:47 [INFO]: Epoch 028 - training loss: 40653.0380, validation loss: 0.3040
2024-05-25 03:24:47 [INFO]: Epoch 029 - training loss: 40721.8848, validation loss: 0.3150
2024-05-25 03:24:48 [INFO]: Epoch 030 - training loss: 40629.3968, validation loss: 0.2808
2024-05-25 03:24:48 [INFO]: Epoch 031 - training loss: 40621.7724, validation loss: 0.2804
2024-05-25 03:24:48 [INFO]: Epoch 032 - training loss: 40611.0707, validation loss: 0.2748
2024-05-25 03:24:49 [INFO]: Epoch 033 - training loss: 40605.6830, validation loss: 0.2725
2024-05-25 03:24:49 [INFO]: Epoch 034 - training loss: 40592.8945, validation loss: 0.2839
2024-05-25 03:24:49 [INFO]: Epoch 035 - training loss: 40598.0593, validation loss: 0.2629
2024-05-25 03:24:50 [INFO]: Epoch 036 - training loss: 40582.3151, validation loss: 0.2652
2024-05-25 03:24:50 [INFO]: Epoch 037 - training loss: 40592.4395, validation loss: 0.2663
2024-05-25 03:24:50 [INFO]: Epoch 038 - training loss: 40592.0911, validation loss: 0.2708
2024-05-25 03:24:51 [INFO]: Epoch 039 - training loss: 40575.5522, validation loss: 0.2550
2024-05-25 03:24:51 [INFO]: Epoch 040 - training loss: 40573.0352, validation loss: 0.2542
2024-05-25 03:24:51 [INFO]: Epoch 041 - training loss: 40575.1060, validation loss: 0.2956
2024-05-25 03:24:51 [INFO]: Epoch 042 - training loss: 40575.4527, validation loss: 0.2520
2024-05-25 03:24:52 [INFO]: Epoch 043 - training loss: 40579.3177, validation loss: 0.2721
2024-05-25 03:24:52 [INFO]: Epoch 044 - training loss: 40566.5492, validation loss: 0.2445
2024-05-25 03:24:52 [INFO]: Epoch 045 - training loss: 40559.5901, validation loss: 0.2522
2024-05-25 03:24:53 [INFO]: Epoch 046 - training loss: 40560.1085, validation loss: 0.2459
2024-05-25 03:24:53 [INFO]: Epoch 047 - training loss: 40557.8261, validation loss: 0.2444
2024-05-25 03:24:53 [INFO]: Epoch 048 - training loss: 40558.1927, validation loss: 0.2459
2024-05-25 03:24:54 [INFO]: Epoch 049 - training loss: 40555.7124, validation loss: 0.2493
2024-05-25 03:24:54 [INFO]: Epoch 050 - training loss: 40560.9417, validation loss: 0.2651
2024-05-25 03:24:54 [INFO]: Epoch 051 - training loss: 40603.8678, validation loss: 0.2895
2024-05-25 03:24:55 [INFO]: Epoch 052 - training loss: 40631.7245, validation loss: 0.2745
2024-05-25 03:24:55 [INFO]: Epoch 053 - training loss: 40597.5272, validation loss: 0.2597
2024-05-25 03:24:55 [INFO]: Epoch 054 - training loss: 40575.8542, validation loss: 0.2713
2024-05-25 03:24:56 [INFO]: Epoch 055 - training loss: 40565.1398, validation loss: 0.2482
2024-05-25 03:24:56 [INFO]: Epoch 056 - training loss: 40555.9099, validation loss: 0.2468
2024-05-25 03:24:56 [INFO]: Epoch 057 - training loss: 40557.5719, validation loss: 0.2922
2024-05-25 03:24:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:24:56 [INFO]: Finished training. The best model is from epoch#47.
2024-05-25 03:24:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_air_quality/20240525_T032438/GPVAE.pypots
2024-05-25 03:24:56 [INFO]: GP-VAE on Air-Quality: MAE=0.3153, MSE=0.2957
2024-05-25 03:24:56 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_air_quality/imputation.pkl
2024-05-25 03:24:56 [INFO]: Using the given device: cuda:0
2024-05-25 03:24:56 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240525_T032456
2024-05-25 03:24:56 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240525_T032456/tensorboard
2024-05-25 03:24:56 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 03:25:01 [INFO]: Epoch 001 - generator training loss: 0.3685, discriminator training loss: 0.5678, validation loss: 0.5454
2024-05-25 03:25:05 [INFO]: Epoch 002 - generator training loss: 0.0444, discriminator training loss: 0.5239, validation loss: 0.4206
2024-05-25 03:25:10 [INFO]: Epoch 003 - generator training loss: -0.0272, discriminator training loss: 0.5185, validation loss: 0.3480
2024-05-25 03:25:14 [INFO]: Epoch 004 - generator training loss: -0.0687, discriminator training loss: 0.5140, validation loss: 0.3045
2024-05-25 03:25:18 [INFO]: Epoch 005 - generator training loss: -0.0923, discriminator training loss: 0.5091, validation loss: 0.2750
2024-05-25 03:25:22 [INFO]: Epoch 006 - generator training loss: -0.1070, discriminator training loss: 0.5037, validation loss: 0.2550
2024-05-25 03:25:26 [INFO]: Epoch 007 - generator training loss: -0.1174, discriminator training loss: 0.4975, validation loss: 0.2391
2024-05-25 03:25:30 [INFO]: Epoch 008 - generator training loss: -0.1244, discriminator training loss: 0.4898, validation loss: 0.2273
2024-05-25 03:25:34 [INFO]: Epoch 009 - generator training loss: -0.1247, discriminator training loss: 0.4810, validation loss: 0.2179
2024-05-25 03:25:38 [INFO]: Epoch 010 - generator training loss: -0.1273, discriminator training loss: 0.4716, validation loss: 0.2110
2024-05-25 03:25:42 [INFO]: Epoch 011 - generator training loss: -0.1284, discriminator training loss: 0.4614, validation loss: 0.2041
2024-05-25 03:25:46 [INFO]: Epoch 012 - generator training loss: -0.1254, discriminator training loss: 0.4509, validation loss: 0.1985
2024-05-25 03:25:50 [INFO]: Epoch 013 - generator training loss: -0.1252, discriminator training loss: 0.4404, validation loss: 0.1939
2024-05-25 03:25:55 [INFO]: Epoch 014 - generator training loss: -0.1220, discriminator training loss: 0.4298, validation loss: 0.1899
2024-05-25 03:25:59 [INFO]: Epoch 015 - generator training loss: -0.1179, discriminator training loss: 0.4199, validation loss: 0.1850
2024-05-25 03:26:03 [INFO]: Epoch 016 - generator training loss: -0.1156, discriminator training loss: 0.4105, validation loss: 0.1812
2024-05-25 03:26:07 [INFO]: Epoch 017 - generator training loss: -0.1134, discriminator training loss: 0.4015, validation loss: 0.1776
2024-05-25 03:26:11 [INFO]: Epoch 018 - generator training loss: -0.1104, discriminator training loss: 0.3931, validation loss: 0.1746
2024-05-25 03:26:15 [INFO]: Epoch 019 - generator training loss: -0.1082, discriminator training loss: 0.3858, validation loss: 0.1722
2024-05-25 03:26:19 [INFO]: Epoch 020 - generator training loss: -0.1050, discriminator training loss: 0.3787, validation loss: 0.1697
2024-05-25 03:26:23 [INFO]: Epoch 021 - generator training loss: -0.1029, discriminator training loss: 0.3724, validation loss: 0.1674
2024-05-25 03:26:27 [INFO]: Epoch 022 - generator training loss: -0.1025, discriminator training loss: 0.3664, validation loss: 0.1653
2024-05-25 03:26:31 [INFO]: Epoch 023 - generator training loss: -0.1017, discriminator training loss: 0.3617, validation loss: 0.1633
2024-05-25 03:26:36 [INFO]: Epoch 024 - generator training loss: -0.0988, discriminator training loss: 0.3568, validation loss: 0.1612
2024-05-25 03:26:40 [INFO]: Epoch 025 - generator training loss: -0.0984, discriminator training loss: 0.3525, validation loss: 0.1598
2024-05-25 03:26:44 [INFO]: Epoch 026 - generator training loss: -0.0970, discriminator training loss: 0.3488, validation loss: 0.1585
2024-05-25 03:26:48 [INFO]: Epoch 027 - generator training loss: -0.0941, discriminator training loss: 0.3448, validation loss: 0.1562
2024-05-25 03:26:52 [INFO]: Epoch 028 - generator training loss: -0.0963, discriminator training loss: 0.3413, validation loss: 0.1552
2024-05-25 03:26:56 [INFO]: Epoch 029 - generator training loss: -0.0979, discriminator training loss: 0.3386, validation loss: 0.1528
2024-05-25 03:27:00 [INFO]: Epoch 030 - generator training loss: -0.0977, discriminator training loss: 0.3360, validation loss: 0.1513
2024-05-25 03:27:04 [INFO]: Epoch 031 - generator training loss: -0.0949, discriminator training loss: 0.3327, validation loss: 0.1495
2024-05-25 03:27:08 [INFO]: Epoch 032 - generator training loss: -0.0971, discriminator training loss: 0.3312, validation loss: 0.1483
2024-05-25 03:27:12 [INFO]: Epoch 033 - generator training loss: -0.0968, discriminator training loss: 0.3287, validation loss: 0.1469
2024-05-25 03:27:16 [INFO]: Epoch 034 - generator training loss: -0.0979, discriminator training loss: 0.3267, validation loss: 0.1457
2024-05-25 03:27:21 [INFO]: Epoch 035 - generator training loss: -0.0979, discriminator training loss: 0.3254, validation loss: 0.1446
2024-05-25 03:27:25 [INFO]: Epoch 036 - generator training loss: -0.0964, discriminator training loss: 0.3241, validation loss: 0.1438
2024-05-25 03:27:29 [INFO]: Epoch 037 - generator training loss: -0.0978, discriminator training loss: 0.3220, validation loss: 0.1428
2024-05-25 03:27:33 [INFO]: Epoch 038 - generator training loss: -0.0968, discriminator training loss: 0.3207, validation loss: 0.1421
2024-05-25 03:27:37 [INFO]: Epoch 039 - generator training loss: -0.0981, discriminator training loss: 0.3193, validation loss: 0.1406
2024-05-25 03:27:41 [INFO]: Epoch 040 - generator training loss: -0.0994, discriminator training loss: 0.3191, validation loss: 0.1404
2024-05-25 03:27:45 [INFO]: Epoch 041 - generator training loss: -0.0983, discriminator training loss: 0.3178, validation loss: 0.1396
2024-05-25 03:27:49 [INFO]: Epoch 042 - generator training loss: -0.0991, discriminator training loss: 0.3166, validation loss: 0.1390
2024-05-25 03:27:53 [INFO]: Epoch 043 - generator training loss: -0.0994, discriminator training loss: 0.3157, validation loss: 0.1376
2024-05-25 03:27:57 [INFO]: Epoch 044 - generator training loss: -0.1003, discriminator training loss: 0.3150, validation loss: 0.1371
2024-05-25 03:28:02 [INFO]: Epoch 045 - generator training loss: -0.1009, discriminator training loss: 0.3145, validation loss: 0.1361
2024-05-25 03:28:06 [INFO]: Epoch 046 - generator training loss: -0.0980, discriminator training loss: 0.3133, validation loss: 0.1353
2024-05-25 03:28:10 [INFO]: Epoch 047 - generator training loss: -0.1003, discriminator training loss: 0.3125, validation loss: 0.1346
2024-05-25 03:28:14 [INFO]: Epoch 048 - generator training loss: -0.1015, discriminator training loss: 0.3120, validation loss: 0.1339
2024-05-25 03:28:18 [INFO]: Epoch 049 - generator training loss: -0.1017, discriminator training loss: 0.3119, validation loss: 0.1341
2024-05-25 03:28:22 [INFO]: Epoch 050 - generator training loss: -0.1014, discriminator training loss: 0.3115, validation loss: 0.1326
2024-05-25 03:28:26 [INFO]: Epoch 051 - generator training loss: -0.1031, discriminator training loss: 0.3105, validation loss: 0.1326
2024-05-25 03:28:30 [INFO]: Epoch 052 - generator training loss: -0.1034, discriminator training loss: 0.3105, validation loss: 0.1313
2024-05-25 03:28:34 [INFO]: Epoch 053 - generator training loss: -0.1045, discriminator training loss: 0.3098, validation loss: 0.1319
2024-05-25 03:28:39 [INFO]: Epoch 054 - generator training loss: -0.1035, discriminator training loss: 0.3095, validation loss: 0.1303
2024-05-25 03:28:43 [INFO]: Epoch 055 - generator training loss: -0.1048, discriminator training loss: 0.3089, validation loss: 0.1312
2024-05-25 03:28:47 [INFO]: Epoch 056 - generator training loss: -0.1049, discriminator training loss: 0.3083, validation loss: 0.1296
2024-05-25 03:28:51 [INFO]: Epoch 057 - generator training loss: -0.1049, discriminator training loss: 0.3082, validation loss: 0.1295
2024-05-25 03:28:55 [INFO]: Epoch 058 - generator training loss: -0.1059, discriminator training loss: 0.3083, validation loss: 0.1289
2024-05-25 03:28:59 [INFO]: Epoch 059 - generator training loss: -0.1061, discriminator training loss: 0.3086, validation loss: 0.1295
2024-05-25 03:29:03 [INFO]: Epoch 060 - generator training loss: -0.1053, discriminator training loss: 0.3080, validation loss: 0.1282
2024-05-25 03:29:07 [INFO]: Epoch 061 - generator training loss: -0.1071, discriminator training loss: 0.3072, validation loss: 0.1279
2024-05-25 03:29:11 [INFO]: Epoch 062 - generator training loss: -0.1084, discriminator training loss: 0.3072, validation loss: 0.1274
2024-05-25 03:29:15 [INFO]: Epoch 063 - generator training loss: -0.1079, discriminator training loss: 0.3070, validation loss: 0.1265
2024-05-25 03:29:19 [INFO]: Epoch 064 - generator training loss: -0.1093, discriminator training loss: 0.3064, validation loss: 0.1272
2024-05-25 03:29:24 [INFO]: Epoch 065 - generator training loss: -0.1084, discriminator training loss: 0.3058, validation loss: 0.1261
2024-05-25 03:29:28 [INFO]: Epoch 066 - generator training loss: -0.1098, discriminator training loss: 0.3055, validation loss: 0.1265
2024-05-25 03:29:32 [INFO]: Epoch 067 - generator training loss: -0.1088, discriminator training loss: 0.3055, validation loss: 0.1266
2024-05-25 03:29:36 [INFO]: Epoch 068 - generator training loss: -0.1098, discriminator training loss: 0.3060, validation loss: 0.1252
2024-05-25 03:29:40 [INFO]: Epoch 069 - generator training loss: -0.1108, discriminator training loss: 0.3053, validation loss: 0.1257
2024-05-25 03:29:44 [INFO]: Epoch 070 - generator training loss: -0.1095, discriminator training loss: 0.3051, validation loss: 0.1254
2024-05-25 03:29:48 [INFO]: Epoch 071 - generator training loss: -0.1111, discriminator training loss: 0.3048, validation loss: 0.1246
2024-05-25 03:29:52 [INFO]: Epoch 072 - generator training loss: -0.1110, discriminator training loss: 0.3051, validation loss: 0.1251
2024-05-25 03:29:56 [INFO]: Epoch 073 - generator training loss: -0.1123, discriminator training loss: 0.3048, validation loss: 0.1237
2024-05-25 03:30:00 [INFO]: Epoch 074 - generator training loss: -0.1112, discriminator training loss: 0.3043, validation loss: 0.1245
2024-05-25 03:30:05 [INFO]: Epoch 075 - generator training loss: -0.1128, discriminator training loss: 0.3048, validation loss: 0.1239
2024-05-25 03:30:09 [INFO]: Epoch 076 - generator training loss: -0.1132, discriminator training loss: 0.3043, validation loss: 0.1240
2024-05-25 03:30:13 [INFO]: Epoch 077 - generator training loss: -0.1133, discriminator training loss: 0.3039, validation loss: 0.1234
2024-05-25 03:30:17 [INFO]: Epoch 078 - generator training loss: -0.1143, discriminator training loss: 0.3036, validation loss: 0.1242
2024-05-25 03:30:21 [INFO]: Epoch 079 - generator training loss: -0.1130, discriminator training loss: 0.3036, validation loss: 0.1236
2024-05-25 03:30:25 [INFO]: Epoch 080 - generator training loss: -0.1137, discriminator training loss: 0.3035, validation loss: 0.1231
2024-05-25 03:30:29 [INFO]: Epoch 081 - generator training loss: -0.1144, discriminator training loss: 0.3035, validation loss: 0.1236
2024-05-25 03:30:33 [INFO]: Epoch 082 - generator training loss: -0.1146, discriminator training loss: 0.3034, validation loss: 0.1228
2024-05-25 03:30:37 [INFO]: Epoch 083 - generator training loss: -0.1156, discriminator training loss: 0.3028, validation loss: 0.1232
2024-05-25 03:30:42 [INFO]: Epoch 084 - generator training loss: -0.1150, discriminator training loss: 0.3025, validation loss: 0.1231
2024-05-25 03:30:46 [INFO]: Epoch 085 - generator training loss: -0.1159, discriminator training loss: 0.3032, validation loss: 0.1226
2024-05-25 03:30:50 [INFO]: Epoch 086 - generator training loss: -0.1160, discriminator training loss: 0.3029, validation loss: 0.1219
2024-05-25 03:30:54 [INFO]: Epoch 087 - generator training loss: -0.1159, discriminator training loss: 0.3028, validation loss: 0.1222
2024-05-25 03:30:58 [INFO]: Epoch 088 - generator training loss: -0.1170, discriminator training loss: 0.3025, validation loss: 0.1228
2024-05-25 03:31:02 [INFO]: Epoch 089 - generator training loss: -0.1167, discriminator training loss: 0.3024, validation loss: 0.1225
2024-05-25 03:31:06 [INFO]: Epoch 090 - generator training loss: -0.1168, discriminator training loss: 0.3022, validation loss: 0.1212
2024-05-25 03:31:10 [INFO]: Epoch 091 - generator training loss: -0.1181, discriminator training loss: 0.3018, validation loss: 0.1228
2024-05-25 03:31:14 [INFO]: Epoch 092 - generator training loss: -0.1179, discriminator training loss: 0.3021, validation loss: 0.1221
2024-05-25 03:31:18 [INFO]: Epoch 093 - generator training loss: -0.1171, discriminator training loss: 0.3019, validation loss: 0.1210
2024-05-25 03:31:22 [INFO]: Epoch 094 - generator training loss: -0.1181, discriminator training loss: 0.3014, validation loss: 0.1209
2024-05-25 03:31:27 [INFO]: Epoch 095 - generator training loss: -0.1170, discriminator training loss: 0.3017, validation loss: 0.1226
2024-05-25 03:31:31 [INFO]: Epoch 096 - generator training loss: -0.1182, discriminator training loss: 0.3016, validation loss: 0.1216
2024-05-25 03:31:35 [INFO]: Epoch 097 - generator training loss: -0.1173, discriminator training loss: 0.3017, validation loss: 0.1218
2024-05-25 03:31:39 [INFO]: Epoch 098 - generator training loss: -0.1187, discriminator training loss: 0.3013, validation loss: 0.1221
2024-05-25 03:31:43 [INFO]: Epoch 099 - generator training loss: -0.1190, discriminator training loss: 0.3008, validation loss: 0.1215
2024-05-25 03:31:47 [INFO]: Epoch 100 - generator training loss: -0.1194, discriminator training loss: 0.3015, validation loss: 0.1209
2024-05-25 03:31:51 [INFO]: Epoch 101 - generator training loss: -0.1195, discriminator training loss: 0.3004, validation loss: 0.1220
2024-05-25 03:31:55 [INFO]: Epoch 102 - generator training loss: -0.1193, discriminator training loss: 0.3006, validation loss: 0.1213
2024-05-25 03:31:59 [INFO]: Epoch 103 - generator training loss: -0.1198, discriminator training loss: 0.3003, validation loss: 0.1226
2024-05-25 03:32:03 [INFO]: Epoch 104 - generator training loss: -0.1186, discriminator training loss: 0.3003, validation loss: 0.1205
2024-05-25 03:32:08 [INFO]: Epoch 105 - generator training loss: -0.1201, discriminator training loss: 0.3006, validation loss: 0.1210
2024-05-25 03:32:12 [INFO]: Epoch 106 - generator training loss: -0.1210, discriminator training loss: 0.3007, validation loss: 0.1214
2024-05-25 03:32:16 [INFO]: Epoch 107 - generator training loss: -0.1201, discriminator training loss: 0.3007, validation loss: 0.1203
2024-05-25 03:32:20 [INFO]: Epoch 108 - generator training loss: -0.1215, discriminator training loss: 0.3004, validation loss: 0.1214
2024-05-25 03:32:24 [INFO]: Epoch 109 - generator training loss: -0.1218, discriminator training loss: 0.3005, validation loss: 0.1212
2024-05-25 03:32:28 [INFO]: Epoch 110 - generator training loss: -0.1210, discriminator training loss: 0.2998, validation loss: 0.1207
2024-05-25 03:32:32 [INFO]: Epoch 111 - generator training loss: -0.1219, discriminator training loss: 0.2995, validation loss: 0.1215
2024-05-25 03:32:36 [INFO]: Epoch 112 - generator training loss: -0.1217, discriminator training loss: 0.3000, validation loss: 0.1203
2024-05-25 03:32:40 [INFO]: Epoch 113 - generator training loss: -0.1220, discriminator training loss: 0.2996, validation loss: 0.1212
2024-05-25 03:32:44 [INFO]: Epoch 114 - generator training loss: -0.1218, discriminator training loss: 0.2994, validation loss: 0.1207
2024-05-25 03:32:48 [INFO]: Epoch 115 - generator training loss: -0.1221, discriminator training loss: 0.2997, validation loss: 0.1208
2024-05-25 03:32:53 [INFO]: Epoch 116 - generator training loss: -0.1228, discriminator training loss: 0.2994, validation loss: 0.1210
2024-05-25 03:32:57 [INFO]: Epoch 117 - generator training loss: -0.1222, discriminator training loss: 0.2990, validation loss: 0.1212
2024-05-25 03:33:01 [INFO]: Epoch 118 - generator training loss: -0.1233, discriminator training loss: 0.2989, validation loss: 0.1215
2024-05-25 03:33:05 [INFO]: Epoch 119 - generator training loss: -0.1226, discriminator training loss: 0.2989, validation loss: 0.1213
2024-05-25 03:33:09 [INFO]: Epoch 120 - generator training loss: -0.1235, discriminator training loss: 0.2985, validation loss: 0.1207
2024-05-25 03:33:13 [INFO]: Epoch 121 - generator training loss: -0.1232, discriminator training loss: 0.2986, validation loss: 0.1210
2024-05-25 03:33:17 [INFO]: Epoch 122 - generator training loss: -0.1236, discriminator training loss: 0.2988, validation loss: 0.1213
2024-05-25 03:33:17 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:33:17 [INFO]: Finished training. The best model is from epoch#112.
2024-05-25 03:33:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_air_quality/20240525_T032456/USGAN.pypots
2024-05-25 03:33:18 [INFO]: US-GAN on Air-Quality: MAE=0.1640, MSE=0.1366
2024-05-25 03:33:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_air_quality/imputation.pkl
2024-05-25 03:33:18 [INFO]: Using the given device: cuda:0
2024-05-25 03:33:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240525_T033318
2024-05-25 03:33:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240525_T033318/tensorboard
2024-05-25 03:33:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 03:33:22 [INFO]: Epoch 001 - training loss: 1.4174, validation loss: 0.9857
2024-05-25 03:33:24 [INFO]: Epoch 002 - training loss: 1.1643, validation loss: 0.7345
2024-05-25 03:33:27 [INFO]: Epoch 003 - training loss: 0.9632, validation loss: 0.6167
2024-05-25 03:33:30 [INFO]: Epoch 004 - training loss: 0.8511, validation loss: 0.5474
2024-05-25 03:33:33 [INFO]: Epoch 005 - training loss: 0.7778, validation loss: 0.5015
2024-05-25 03:33:36 [INFO]: Epoch 006 - training loss: 0.7230, validation loss: 0.4664
2024-05-25 03:33:38 [INFO]: Epoch 007 - training loss: 0.6779, validation loss: 0.4373
2024-05-25 03:33:41 [INFO]: Epoch 008 - training loss: 0.6438, validation loss: 0.4143
2024-05-25 03:33:44 [INFO]: Epoch 009 - training loss: 0.6189, validation loss: 0.3957
2024-05-25 03:33:47 [INFO]: Epoch 010 - training loss: 0.5960, validation loss: 0.3782
2024-05-25 03:33:50 [INFO]: Epoch 011 - training loss: 0.5794, validation loss: 0.3641
2024-05-25 03:33:52 [INFO]: Epoch 012 - training loss: 0.5656, validation loss: 0.3527
2024-05-25 03:33:55 [INFO]: Epoch 013 - training loss: 0.5516, validation loss: 0.3414
2024-05-25 03:33:58 [INFO]: Epoch 014 - training loss: 0.5416, validation loss: 0.3324
2024-05-25 03:34:01 [INFO]: Epoch 015 - training loss: 0.5301, validation loss: 0.3242
2024-05-25 03:34:04 [INFO]: Epoch 016 - training loss: 0.5206, validation loss: 0.3155
2024-05-25 03:34:06 [INFO]: Epoch 017 - training loss: 0.5112, validation loss: 0.3091
2024-05-25 03:34:09 [INFO]: Epoch 018 - training loss: 0.5031, validation loss: 0.3024
2024-05-25 03:34:12 [INFO]: Epoch 019 - training loss: 0.4946, validation loss: 0.2969
2024-05-25 03:34:15 [INFO]: Epoch 020 - training loss: 0.4873, validation loss: 0.2907
2024-05-25 03:34:18 [INFO]: Epoch 021 - training loss: 0.4798, validation loss: 0.2863
2024-05-25 03:34:20 [INFO]: Epoch 022 - training loss: 0.4734, validation loss: 0.2811
2024-05-25 03:34:23 [INFO]: Epoch 023 - training loss: 0.4672, validation loss: 0.2769
2024-05-25 03:34:26 [INFO]: Epoch 024 - training loss: 0.4609, validation loss: 0.2723
2024-05-25 03:34:29 [INFO]: Epoch 025 - training loss: 0.4546, validation loss: 0.2686
2024-05-25 03:34:31 [INFO]: Epoch 026 - training loss: 0.4498, validation loss: 0.2647
2024-05-25 03:34:34 [INFO]: Epoch 027 - training loss: 0.4442, validation loss: 0.2609
2024-05-25 03:34:37 [INFO]: Epoch 028 - training loss: 0.4377, validation loss: 0.2579
2024-05-25 03:34:40 [INFO]: Epoch 029 - training loss: 0.4330, validation loss: 0.2540
2024-05-25 03:34:43 [INFO]: Epoch 030 - training loss: 0.4290, validation loss: 0.2507
2024-05-25 03:34:46 [INFO]: Epoch 031 - training loss: 0.4243, validation loss: 0.2477
2024-05-25 03:34:48 [INFO]: Epoch 032 - training loss: 0.4192, validation loss: 0.2446
2024-05-25 03:34:51 [INFO]: Epoch 033 - training loss: 0.4154, validation loss: 0.2410
2024-05-25 03:34:54 [INFO]: Epoch 034 - training loss: 0.4117, validation loss: 0.2383
2024-05-25 03:34:57 [INFO]: Epoch 035 - training loss: 0.4076, validation loss: 0.2357
2024-05-25 03:35:00 [INFO]: Epoch 036 - training loss: 0.4041, validation loss: 0.2330
2024-05-25 03:35:02 [INFO]: Epoch 037 - training loss: 0.4005, validation loss: 0.2307
2024-05-25 03:35:05 [INFO]: Epoch 038 - training loss: 0.3973, validation loss: 0.2279
2024-05-25 03:35:08 [INFO]: Epoch 039 - training loss: 0.3938, validation loss: 0.2256
2024-05-25 03:35:11 [INFO]: Epoch 040 - training loss: 0.3907, validation loss: 0.2233
2024-05-25 03:35:14 [INFO]: Epoch 041 - training loss: 0.3879, validation loss: 0.2207
2024-05-25 03:35:16 [INFO]: Epoch 042 - training loss: 0.3836, validation loss: 0.2187
2024-05-25 03:35:19 [INFO]: Epoch 043 - training loss: 0.3819, validation loss: 0.2164
2024-05-25 03:35:22 [INFO]: Epoch 044 - training loss: 0.3786, validation loss: 0.2140
2024-05-25 03:35:25 [INFO]: Epoch 045 - training loss: 0.3761, validation loss: 0.2127
2024-05-25 03:35:28 [INFO]: Epoch 046 - training loss: 0.3732, validation loss: 0.2106
2024-05-25 03:35:30 [INFO]: Epoch 047 - training loss: 0.3709, validation loss: 0.2084
2024-05-25 03:35:33 [INFO]: Epoch 048 - training loss: 0.3694, validation loss: 0.2066
2024-05-25 03:35:36 [INFO]: Epoch 049 - training loss: 0.3668, validation loss: 0.2050
2024-05-25 03:35:39 [INFO]: Epoch 050 - training loss: 0.3643, validation loss: 0.2030
2024-05-25 03:35:42 [INFO]: Epoch 051 - training loss: 0.3621, validation loss: 0.2016
2024-05-25 03:35:44 [INFO]: Epoch 052 - training loss: 0.3594, validation loss: 0.1997
2024-05-25 03:35:47 [INFO]: Epoch 053 - training loss: 0.3575, validation loss: 0.1981
2024-05-25 03:35:50 [INFO]: Epoch 054 - training loss: 0.3561, validation loss: 0.1968
2024-05-25 03:35:53 [INFO]: Epoch 055 - training loss: 0.3539, validation loss: 0.1955
2024-05-25 03:35:56 [INFO]: Epoch 056 - training loss: 0.3521, validation loss: 0.1940
2024-05-25 03:35:58 [INFO]: Epoch 057 - training loss: 0.3502, validation loss: 0.1924
2024-05-25 03:36:01 [INFO]: Epoch 058 - training loss: 0.3482, validation loss: 0.1912
2024-05-25 03:36:04 [INFO]: Epoch 059 - training loss: 0.3471, validation loss: 0.1900
2024-05-25 03:36:07 [INFO]: Epoch 060 - training loss: 0.3451, validation loss: 0.1887
2024-05-25 03:36:10 [INFO]: Epoch 061 - training loss: 0.3433, validation loss: 0.1875
2024-05-25 03:36:12 [INFO]: Epoch 062 - training loss: 0.3420, validation loss: 0.1867
2024-05-25 03:36:15 [INFO]: Epoch 063 - training loss: 0.3399, validation loss: 0.1852
2024-05-25 03:36:18 [INFO]: Epoch 064 - training loss: 0.3384, validation loss: 0.1844
2024-05-25 03:36:21 [INFO]: Epoch 065 - training loss: 0.3371, validation loss: 0.1835
2024-05-25 03:36:24 [INFO]: Epoch 066 - training loss: 0.3360, validation loss: 0.1824
2024-05-25 03:36:26 [INFO]: Epoch 067 - training loss: 0.3354, validation loss: 0.1816
2024-05-25 03:36:29 [INFO]: Epoch 068 - training loss: 0.3330, validation loss: 0.1806
2024-05-25 03:36:32 [INFO]: Epoch 069 - training loss: 0.3336, validation loss: 0.1796
2024-05-25 03:36:35 [INFO]: Epoch 070 - training loss: 0.3308, validation loss: 0.1787
2024-05-25 03:36:38 [INFO]: Epoch 071 - training loss: 0.3294, validation loss: 0.1778
2024-05-25 03:36:40 [INFO]: Epoch 072 - training loss: 0.3289, validation loss: 0.1772
2024-05-25 03:36:43 [INFO]: Epoch 073 - training loss: 0.3274, validation loss: 0.1761
2024-05-25 03:36:46 [INFO]: Epoch 074 - training loss: 0.3270, validation loss: 0.1755
2024-05-25 03:36:49 [INFO]: Epoch 075 - training loss: 0.3252, validation loss: 0.1746
2024-05-25 03:36:52 [INFO]: Epoch 076 - training loss: 0.3241, validation loss: 0.1743
2024-05-25 03:36:54 [INFO]: Epoch 077 - training loss: 0.3228, validation loss: 0.1732
2024-05-25 03:36:57 [INFO]: Epoch 078 - training loss: 0.3225, validation loss: 0.1725
2024-05-25 03:37:00 [INFO]: Epoch 079 - training loss: 0.3212, validation loss: 0.1721
2024-05-25 03:37:03 [INFO]: Epoch 080 - training loss: 0.3201, validation loss: 0.1712
2024-05-25 03:37:06 [INFO]: Epoch 081 - training loss: 0.3199, validation loss: 0.1708
2024-05-25 03:37:08 [INFO]: Epoch 082 - training loss: 0.3187, validation loss: 0.1702
2024-05-25 03:37:11 [INFO]: Epoch 083 - training loss: 0.3172, validation loss: 0.1694
2024-05-25 03:37:14 [INFO]: Epoch 084 - training loss: 0.3170, validation loss: 0.1687
2024-05-25 03:37:17 [INFO]: Epoch 085 - training loss: 0.3158, validation loss: 0.1684
2024-05-25 03:37:20 [INFO]: Epoch 086 - training loss: 0.3152, validation loss: 0.1674
2024-05-25 03:37:22 [INFO]: Epoch 087 - training loss: 0.3142, validation loss: 0.1672
2024-05-25 03:37:25 [INFO]: Epoch 088 - training loss: 0.3139, validation loss: 0.1666
2024-05-25 03:37:28 [INFO]: Epoch 089 - training loss: 0.3121, validation loss: 0.1660
2024-05-25 03:37:31 [INFO]: Epoch 090 - training loss: 0.3119, validation loss: 0.1654
2024-05-25 03:37:34 [INFO]: Epoch 091 - training loss: 0.3113, validation loss: 0.1650
2024-05-25 03:37:36 [INFO]: Epoch 092 - training loss: 0.3108, validation loss: 0.1644
2024-05-25 03:37:39 [INFO]: Epoch 093 - training loss: 0.3095, validation loss: 0.1642
2024-05-25 03:37:42 [INFO]: Epoch 094 - training loss: 0.3090, validation loss: 0.1637
2024-05-25 03:37:45 [INFO]: Epoch 095 - training loss: 0.3083, validation loss: 0.1631
2024-05-25 03:37:48 [INFO]: Epoch 096 - training loss: 0.3077, validation loss: 0.1626
2024-05-25 03:37:50 [INFO]: Epoch 097 - training loss: 0.3066, validation loss: 0.1622
2024-05-25 03:37:53 [INFO]: Epoch 098 - training loss: 0.3068, validation loss: 0.1619
2024-05-25 03:37:56 [INFO]: Epoch 099 - training loss: 0.3064, validation loss: 0.1613
2024-05-25 03:37:59 [INFO]: Epoch 100 - training loss: 0.3046, validation loss: 0.1607
2024-05-25 03:38:02 [INFO]: Epoch 101 - training loss: 0.3043, validation loss: 0.1605
2024-05-25 03:38:04 [INFO]: Epoch 102 - training loss: 0.3038, validation loss: 0.1600
2024-05-25 03:38:07 [INFO]: Epoch 103 - training loss: 0.3029, validation loss: 0.1595
2024-05-25 03:38:10 [INFO]: Epoch 104 - training loss: 0.3027, validation loss: 0.1594
2024-05-25 03:38:13 [INFO]: Epoch 105 - training loss: 0.3018, validation loss: 0.1589
2024-05-25 03:38:16 [INFO]: Epoch 106 - training loss: 0.3020, validation loss: 0.1584
2024-05-25 03:38:18 [INFO]: Epoch 107 - training loss: 0.3003, validation loss: 0.1579
2024-05-25 03:38:21 [INFO]: Epoch 108 - training loss: 0.3002, validation loss: 0.1577
2024-05-25 03:38:24 [INFO]: Epoch 109 - training loss: 0.2999, validation loss: 0.1573
2024-05-25 03:38:27 [INFO]: Epoch 110 - training loss: 0.2988, validation loss: 0.1570
2024-05-25 03:38:30 [INFO]: Epoch 111 - training loss: 0.2992, validation loss: 0.1565
2024-05-25 03:38:32 [INFO]: Epoch 112 - training loss: 0.2982, validation loss: 0.1561
2024-05-25 03:38:35 [INFO]: Epoch 113 - training loss: 0.2974, validation loss: 0.1558
2024-05-25 03:38:38 [INFO]: Epoch 114 - training loss: 0.2973, validation loss: 0.1554
2024-05-25 03:38:41 [INFO]: Epoch 115 - training loss: 0.2971, validation loss: 0.1552
2024-05-25 03:38:44 [INFO]: Epoch 116 - training loss: 0.2959, validation loss: 0.1547
2024-05-25 03:38:46 [INFO]: Epoch 117 - training loss: 0.2954, validation loss: 0.1544
2024-05-25 03:38:49 [INFO]: Epoch 118 - training loss: 0.2947, validation loss: 0.1540
2024-05-25 03:38:52 [INFO]: Epoch 119 - training loss: 0.2940, validation loss: 0.1538
2024-05-25 03:38:55 [INFO]: Epoch 120 - training loss: 0.2934, validation loss: 0.1534
2024-05-25 03:38:58 [INFO]: Epoch 121 - training loss: 0.2931, validation loss: 0.1532
2024-05-25 03:39:01 [INFO]: Epoch 122 - training loss: 0.2929, validation loss: 0.1527
2024-05-25 03:39:03 [INFO]: Epoch 123 - training loss: 0.2929, validation loss: 0.1526
2024-05-25 03:39:06 [INFO]: Epoch 124 - training loss: 0.2923, validation loss: 0.1523
2024-05-25 03:39:09 [INFO]: Epoch 125 - training loss: 0.2922, validation loss: 0.1519
2024-05-25 03:39:12 [INFO]: Epoch 126 - training loss: 0.2915, validation loss: 0.1514
2024-05-25 03:39:15 [INFO]: Epoch 127 - training loss: 0.2903, validation loss: 0.1512
2024-05-25 03:39:17 [INFO]: Epoch 128 - training loss: 0.2905, validation loss: 0.1510
2024-05-25 03:39:20 [INFO]: Epoch 129 - training loss: 0.2897, validation loss: 0.1506
2024-05-25 03:39:23 [INFO]: Epoch 130 - training loss: 0.2898, validation loss: 0.1502
2024-05-25 03:39:26 [INFO]: Epoch 131 - training loss: 0.2888, validation loss: 0.1502
2024-05-25 03:39:29 [INFO]: Epoch 132 - training loss: 0.2892, validation loss: 0.1496
2024-05-25 03:39:31 [INFO]: Epoch 133 - training loss: 0.2887, validation loss: 0.1492
2024-05-25 03:39:34 [INFO]: Epoch 134 - training loss: 0.2875, validation loss: 0.1489
2024-05-25 03:39:37 [INFO]: Epoch 135 - training loss: 0.2871, validation loss: 0.1488
2024-05-25 03:39:40 [INFO]: Epoch 136 - training loss: 0.2869, validation loss: 0.1488
2024-05-25 03:39:43 [INFO]: Epoch 137 - training loss: 0.2867, validation loss: 0.1482
2024-05-25 03:39:45 [INFO]: Epoch 138 - training loss: 0.2861, validation loss: 0.1479
2024-05-25 03:39:48 [INFO]: Epoch 139 - training loss: 0.2861, validation loss: 0.1478
2024-05-25 03:39:51 [INFO]: Epoch 140 - training loss: 0.2854, validation loss: 0.1475
2024-05-25 03:39:54 [INFO]: Epoch 141 - training loss: 0.2850, validation loss: 0.1474
2024-05-25 03:39:57 [INFO]: Epoch 142 - training loss: 0.2848, validation loss: 0.1470
2024-05-25 03:39:59 [INFO]: Epoch 143 - training loss: 0.2850, validation loss: 0.1467
2024-05-25 03:40:02 [INFO]: Epoch 144 - training loss: 0.2837, validation loss: 0.1464
2024-05-25 03:40:05 [INFO]: Epoch 145 - training loss: 0.2838, validation loss: 0.1462
2024-05-25 03:40:08 [INFO]: Epoch 146 - training loss: 0.2832, validation loss: 0.1458
2024-05-25 03:40:11 [INFO]: Epoch 147 - training loss: 0.2827, validation loss: 0.1458
2024-05-25 03:40:13 [INFO]: Epoch 148 - training loss: 0.2824, validation loss: 0.1455
2024-05-25 03:40:16 [INFO]: Epoch 149 - training loss: 0.2820, validation loss: 0.1452
2024-05-25 03:40:19 [INFO]: Epoch 150 - training loss: 0.2817, validation loss: 0.1450
2024-05-25 03:40:22 [INFO]: Epoch 151 - training loss: 0.2817, validation loss: 0.1449
2024-05-25 03:40:24 [INFO]: Epoch 152 - training loss: 0.2809, validation loss: 0.1448
2024-05-25 03:40:27 [INFO]: Epoch 153 - training loss: 0.2808, validation loss: 0.1443
2024-05-25 03:40:30 [INFO]: Epoch 154 - training loss: 0.2802, validation loss: 0.1441
2024-05-25 03:40:33 [INFO]: Epoch 155 - training loss: 0.2805, validation loss: 0.1438
2024-05-25 03:40:36 [INFO]: Epoch 156 - training loss: 0.2794, validation loss: 0.1438
2024-05-25 03:40:38 [INFO]: Epoch 157 - training loss: 0.2792, validation loss: 0.1434
2024-05-25 03:40:41 [INFO]: Epoch 158 - training loss: 0.2790, validation loss: 0.1436
2024-05-25 03:40:44 [INFO]: Epoch 159 - training loss: 0.2789, validation loss: 0.1433
2024-05-25 03:40:47 [INFO]: Epoch 160 - training loss: 0.2791, validation loss: 0.1430
2024-05-25 03:40:50 [INFO]: Epoch 161 - training loss: 0.2786, validation loss: 0.1426
2024-05-25 03:40:52 [INFO]: Epoch 162 - training loss: 0.2782, validation loss: 0.1426
2024-05-25 03:40:55 [INFO]: Epoch 163 - training loss: 0.2779, validation loss: 0.1423
2024-05-25 03:40:58 [INFO]: Epoch 164 - training loss: 0.2770, validation loss: 0.1420
2024-05-25 03:41:01 [INFO]: Epoch 165 - training loss: 0.2773, validation loss: 0.1419
2024-05-25 03:41:04 [INFO]: Epoch 166 - training loss: 0.2772, validation loss: 0.1417
2024-05-25 03:41:07 [INFO]: Epoch 167 - training loss: 0.2771, validation loss: 0.1417
2024-05-25 03:41:09 [INFO]: Epoch 168 - training loss: 0.2763, validation loss: 0.1415
2024-05-25 03:41:12 [INFO]: Epoch 169 - training loss: 0.2763, validation loss: 0.1412
2024-05-25 03:41:15 [INFO]: Epoch 170 - training loss: 0.2756, validation loss: 0.1410
2024-05-25 03:41:18 [INFO]: Epoch 171 - training loss: 0.2752, validation loss: 0.1407
2024-05-25 03:41:21 [INFO]: Epoch 172 - training loss: 0.2759, validation loss: 0.1405
2024-05-25 03:41:23 [INFO]: Epoch 173 - training loss: 0.2754, validation loss: 0.1404
2024-05-25 03:41:26 [INFO]: Epoch 174 - training loss: 0.2747, validation loss: 0.1403
2024-05-25 03:41:29 [INFO]: Epoch 175 - training loss: 0.2745, validation loss: 0.1403
2024-05-25 03:41:32 [INFO]: Epoch 176 - training loss: 0.2742, validation loss: 0.1399
2024-05-25 03:41:35 [INFO]: Epoch 177 - training loss: 0.2737, validation loss: 0.1397
2024-05-25 03:41:37 [INFO]: Epoch 178 - training loss: 0.2733, validation loss: 0.1396
2024-05-25 03:41:40 [INFO]: Epoch 179 - training loss: 0.2735, validation loss: 0.1396
2024-05-25 03:41:43 [INFO]: Epoch 180 - training loss: 0.2742, validation loss: 0.1395
2024-05-25 03:41:46 [INFO]: Epoch 181 - training loss: 0.2727, validation loss: 0.1391
2024-05-25 03:41:49 [INFO]: Epoch 182 - training loss: 0.2728, validation loss: 0.1388
2024-05-25 03:41:51 [INFO]: Epoch 183 - training loss: 0.2725, validation loss: 0.1387
2024-05-25 03:41:54 [INFO]: Epoch 184 - training loss: 0.2723, validation loss: 0.1386
2024-05-25 03:41:57 [INFO]: Epoch 185 - training loss: 0.2718, validation loss: 0.1385
2024-05-25 03:42:00 [INFO]: Epoch 186 - training loss: 0.2715, validation loss: 0.1384
2024-05-25 03:42:03 [INFO]: Epoch 187 - training loss: 0.2714, validation loss: 0.1384
2024-05-25 03:42:05 [INFO]: Epoch 188 - training loss: 0.2709, validation loss: 0.1381
2024-05-25 03:42:08 [INFO]: Epoch 189 - training loss: 0.2706, validation loss: 0.1380
2024-05-25 03:42:11 [INFO]: Epoch 190 - training loss: 0.2715, validation loss: 0.1378
2024-05-25 03:42:14 [INFO]: Epoch 191 - training loss: 0.2705, validation loss: 0.1376
2024-05-25 03:42:17 [INFO]: Epoch 192 - training loss: 0.2701, validation loss: 0.1373
2024-05-25 03:42:19 [INFO]: Epoch 193 - training loss: 0.2698, validation loss: 0.1375
2024-05-25 03:42:22 [INFO]: Epoch 194 - training loss: 0.2694, validation loss: 0.1373
2024-05-25 03:42:25 [INFO]: Epoch 195 - training loss: 0.2693, validation loss: 0.1372
2024-05-25 03:42:28 [INFO]: Epoch 196 - training loss: 0.2696, validation loss: 0.1370
2024-05-25 03:42:31 [INFO]: Epoch 197 - training loss: 0.2690, validation loss: 0.1370
2024-05-25 03:42:33 [INFO]: Epoch 198 - training loss: 0.2686, validation loss: 0.1369
2024-05-25 03:42:36 [INFO]: Epoch 199 - training loss: 0.2688, validation loss: 0.1366
2024-05-25 03:42:39 [INFO]: Epoch 200 - training loss: 0.2687, validation loss: 0.1365
2024-05-25 03:42:42 [INFO]: Epoch 201 - training loss: 0.2682, validation loss: 0.1364
2024-05-25 03:42:45 [INFO]: Epoch 202 - training loss: 0.2683, validation loss: 0.1363
2024-05-25 03:42:47 [INFO]: Epoch 203 - training loss: 0.2670, validation loss: 0.1360
2024-05-25 03:42:50 [INFO]: Epoch 204 - training loss: 0.2674, validation loss: 0.1361
2024-05-25 03:42:53 [INFO]: Epoch 205 - training loss: 0.2677, validation loss: 0.1357
2024-05-25 03:42:56 [INFO]: Epoch 206 - training loss: 0.2680, validation loss: 0.1357
2024-05-25 03:42:59 [INFO]: Epoch 207 - training loss: 0.2666, validation loss: 0.1357
2024-05-25 03:43:01 [INFO]: Epoch 208 - training loss: 0.2667, validation loss: 0.1354
2024-05-25 03:43:04 [INFO]: Epoch 209 - training loss: 0.2663, validation loss: 0.1353
2024-05-25 03:43:07 [INFO]: Epoch 210 - training loss: 0.2657, validation loss: 0.1351
2024-05-25 03:43:10 [INFO]: Epoch 211 - training loss: 0.2665, validation loss: 0.1351
2024-05-25 03:43:13 [INFO]: Epoch 212 - training loss: 0.2668, validation loss: 0.1348
2024-05-25 03:43:15 [INFO]: Epoch 213 - training loss: 0.2663, validation loss: 0.1347
2024-05-25 03:43:18 [INFO]: Epoch 214 - training loss: 0.2653, validation loss: 0.1347
2024-05-25 03:43:21 [INFO]: Epoch 215 - training loss: 0.2653, validation loss: 0.1348
2024-05-25 03:43:24 [INFO]: Epoch 216 - training loss: 0.2649, validation loss: 0.1344
2024-05-25 03:43:27 [INFO]: Epoch 217 - training loss: 0.2648, validation loss: 0.1342
2024-05-25 03:43:29 [INFO]: Epoch 218 - training loss: 0.2643, validation loss: 0.1342
2024-05-25 03:43:32 [INFO]: Epoch 219 - training loss: 0.2650, validation loss: 0.1343
2024-05-25 03:43:35 [INFO]: Epoch 220 - training loss: 0.2642, validation loss: 0.1340
2024-05-25 03:43:38 [INFO]: Epoch 221 - training loss: 0.2640, validation loss: 0.1338
2024-05-25 03:43:41 [INFO]: Epoch 222 - training loss: 0.2641, validation loss: 0.1339
2024-05-25 03:43:43 [INFO]: Epoch 223 - training loss: 0.2641, validation loss: 0.1337
2024-05-25 03:43:46 [INFO]: Epoch 224 - training loss: 0.2638, validation loss: 0.1337
2024-05-25 03:43:49 [INFO]: Epoch 225 - training loss: 0.2629, validation loss: 0.1336
2024-05-25 03:43:52 [INFO]: Epoch 226 - training loss: 0.2631, validation loss: 0.1336
2024-05-25 03:43:55 [INFO]: Epoch 227 - training loss: 0.2631, validation loss: 0.1335
2024-05-25 03:43:58 [INFO]: Epoch 228 - training loss: 0.2627, validation loss: 0.1332
2024-05-25 03:44:00 [INFO]: Epoch 229 - training loss: 0.2626, validation loss: 0.1331
2024-05-25 03:44:03 [INFO]: Epoch 230 - training loss: 0.2631, validation loss: 0.1332
2024-05-25 03:44:06 [INFO]: Epoch 231 - training loss: 0.2625, validation loss: 0.1332
2024-05-25 03:44:09 [INFO]: Epoch 232 - training loss: 0.2625, validation loss: 0.1329
2024-05-25 03:44:12 [INFO]: Epoch 233 - training loss: 0.2624, validation loss: 0.1329
2024-05-25 03:44:14 [INFO]: Epoch 234 - training loss: 0.2621, validation loss: 0.1327
2024-05-25 03:44:17 [INFO]: Epoch 235 - training loss: 0.2620, validation loss: 0.1324
2024-05-25 03:44:20 [INFO]: Epoch 236 - training loss: 0.2617, validation loss: 0.1324
2024-05-25 03:44:23 [INFO]: Epoch 237 - training loss: 0.2612, validation loss: 0.1323
2024-05-25 03:44:26 [INFO]: Epoch 238 - training loss: 0.2610, validation loss: 0.1325
2024-05-25 03:44:28 [INFO]: Epoch 239 - training loss: 0.2610, validation loss: 0.1323
2024-05-25 03:44:31 [INFO]: Epoch 240 - training loss: 0.2609, validation loss: 0.1325
2024-05-25 03:44:34 [INFO]: Epoch 241 - training loss: 0.2611, validation loss: 0.1321
2024-05-25 03:44:37 [INFO]: Epoch 242 - training loss: 0.2605, validation loss: 0.1321
2024-05-25 03:44:40 [INFO]: Epoch 243 - training loss: 0.2600, validation loss: 0.1320
2024-05-25 03:44:42 [INFO]: Epoch 244 - training loss: 0.2598, validation loss: 0.1321
2024-05-25 03:44:45 [INFO]: Epoch 245 - training loss: 0.2597, validation loss: 0.1318
2024-05-25 03:44:48 [INFO]: Epoch 246 - training loss: 0.2603, validation loss: 0.1316
2024-05-25 03:44:51 [INFO]: Epoch 247 - training loss: 0.2600, validation loss: 0.1315
2024-05-25 03:44:54 [INFO]: Epoch 248 - training loss: 0.2592, validation loss: 0.1315
2024-05-25 03:44:56 [INFO]: Epoch 249 - training loss: 0.2590, validation loss: 0.1314
2024-05-25 03:44:59 [INFO]: Epoch 250 - training loss: 0.2587, validation loss: 0.1314
2024-05-25 03:45:02 [INFO]: Epoch 251 - training loss: 0.2586, validation loss: 0.1313
2024-05-25 03:45:05 [INFO]: Epoch 252 - training loss: 0.2588, validation loss: 0.1313
2024-05-25 03:45:08 [INFO]: Epoch 253 - training loss: 0.2582, validation loss: 0.1313
2024-05-25 03:45:11 [INFO]: Epoch 254 - training loss: 0.2583, validation loss: 0.1311
2024-05-25 03:45:13 [INFO]: Epoch 255 - training loss: 0.2585, validation loss: 0.1311
2024-05-25 03:45:16 [INFO]: Epoch 256 - training loss: 0.2581, validation loss: 0.1310
2024-05-25 03:45:19 [INFO]: Epoch 257 - training loss: 0.2582, validation loss: 0.1312
2024-05-25 03:45:22 [INFO]: Epoch 258 - training loss: 0.2580, validation loss: 0.1310
2024-05-25 03:45:24 [INFO]: Epoch 259 - training loss: 0.2575, validation loss: 0.1309
2024-05-25 03:45:27 [INFO]: Epoch 260 - training loss: 0.2573, validation loss: 0.1309
2024-05-25 03:45:30 [INFO]: Epoch 261 - training loss: 0.2574, validation loss: 0.1309
2024-05-25 03:45:33 [INFO]: Epoch 262 - training loss: 0.2568, validation loss: 0.1306
2024-05-25 03:45:36 [INFO]: Epoch 263 - training loss: 0.2574, validation loss: 0.1306
2024-05-25 03:45:38 [INFO]: Epoch 264 - training loss: 0.2568, validation loss: 0.1304
2024-05-25 03:45:41 [INFO]: Epoch 265 - training loss: 0.2563, validation loss: 0.1302
2024-05-25 03:45:44 [INFO]: Epoch 266 - training loss: 0.2566, validation loss: 0.1303
2024-05-25 03:45:47 [INFO]: Epoch 267 - training loss: 0.2577, validation loss: 0.1304
2024-05-25 03:45:50 [INFO]: Epoch 268 - training loss: 0.2565, validation loss: 0.1303
2024-05-25 03:45:52 [INFO]: Epoch 269 - training loss: 0.2566, validation loss: 0.1302
2024-05-25 03:45:55 [INFO]: Epoch 270 - training loss: 0.2556, validation loss: 0.1299
2024-05-25 03:45:58 [INFO]: Epoch 271 - training loss: 0.2555, validation loss: 0.1301
2024-05-25 03:46:01 [INFO]: Epoch 272 - training loss: 0.2555, validation loss: 0.1300
2024-05-25 03:46:04 [INFO]: Epoch 273 - training loss: 0.2557, validation loss: 0.1302
2024-05-25 03:46:06 [INFO]: Epoch 274 - training loss: 0.2556, validation loss: 0.1299
2024-05-25 03:46:09 [INFO]: Epoch 275 - training loss: 0.2557, validation loss: 0.1299
2024-05-25 03:46:12 [INFO]: Epoch 276 - training loss: 0.2546, validation loss: 0.1298
2024-05-25 03:46:15 [INFO]: Epoch 277 - training loss: 0.2544, validation loss: 0.1298
2024-05-25 03:46:18 [INFO]: Epoch 278 - training loss: 0.2547, validation loss: 0.1297
2024-05-25 03:46:20 [INFO]: Epoch 279 - training loss: 0.2547, validation loss: 0.1297
2024-05-25 03:46:23 [INFO]: Epoch 280 - training loss: 0.2543, validation loss: 0.1297
2024-05-25 03:46:26 [INFO]: Epoch 281 - training loss: 0.2543, validation loss: 0.1295
2024-05-25 03:46:29 [INFO]: Epoch 282 - training loss: 0.2538, validation loss: 0.1295
2024-05-25 03:46:32 [INFO]: Epoch 283 - training loss: 0.2539, validation loss: 0.1295
2024-05-25 03:46:34 [INFO]: Epoch 284 - training loss: 0.2537, validation loss: 0.1294
2024-05-25 03:46:37 [INFO]: Epoch 285 - training loss: 0.2540, validation loss: 0.1293
2024-05-25 03:46:40 [INFO]: Epoch 286 - training loss: 0.2535, validation loss: 0.1294
2024-05-25 03:46:43 [INFO]: Epoch 287 - training loss: 0.2539, validation loss: 0.1291
2024-05-25 03:46:46 [INFO]: Epoch 288 - training loss: 0.2530, validation loss: 0.1294
2024-05-25 03:46:48 [INFO]: Epoch 289 - training loss: 0.2529, validation loss: 0.1291
2024-05-25 03:46:51 [INFO]: Epoch 290 - training loss: 0.2532, validation loss: 0.1292
2024-05-25 03:46:54 [INFO]: Epoch 291 - training loss: 0.2534, validation loss: 0.1291
2024-05-25 03:46:57 [INFO]: Epoch 292 - training loss: 0.2532, validation loss: 0.1290
2024-05-25 03:47:00 [INFO]: Epoch 293 - training loss: 0.2530, validation loss: 0.1290
2024-05-25 03:47:02 [INFO]: Epoch 294 - training loss: 0.2531, validation loss: 0.1290
2024-05-25 03:47:05 [INFO]: Epoch 295 - training loss: 0.2529, validation loss: 0.1289
2024-05-25 03:47:08 [INFO]: Epoch 296 - training loss: 0.2524, validation loss: 0.1289
2024-05-25 03:47:11 [INFO]: Epoch 297 - training loss: 0.2523, validation loss: 0.1291
2024-05-25 03:47:14 [INFO]: Epoch 298 - training loss: 0.2521, validation loss: 0.1286
2024-05-25 03:47:17 [INFO]: Epoch 299 - training loss: 0.2525, validation loss: 0.1288
2024-05-25 03:47:19 [INFO]: Epoch 300 - training loss: 0.2522, validation loss: 0.1289
2024-05-25 03:47:19 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 03:47:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_air_quality/20240525_T033318/BRITS.pypots
2024-05-25 03:47:20 [INFO]: BRITS on Air-Quality: MAE=0.1515, MSE=0.1330
2024-05-25 03:47:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_air_quality/imputation.pkl
2024-05-25 03:47:20 [INFO]: Using the given device: cuda:0
2024-05-25 03:47:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720
2024-05-25 03:47:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/tensorboard
2024-05-25 03:47:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 03:47:25 [INFO]: Epoch 001 - training loss: 1.4415, validation loss: 0.8275
2024-05-25 03:47:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch1_loss0.827542731165886.pypots
2024-05-25 03:47:29 [INFO]: Epoch 002 - training loss: 1.0108, validation loss: 0.7695
2024-05-25 03:47:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch2_loss0.7694576948881149.pypots
2024-05-25 03:47:33 [INFO]: Epoch 003 - training loss: 0.9281, validation loss: 0.7485
2024-05-25 03:47:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch3_loss0.7485362887382507.pypots
2024-05-25 03:47:36 [INFO]: Epoch 004 - training loss: 0.9035, validation loss: 0.7358
2024-05-25 03:47:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch4_loss0.735791701078415.pypots
2024-05-25 03:47:40 [INFO]: Epoch 005 - training loss: 0.8821, validation loss: 0.7269
2024-05-25 03:47:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch5_loss0.7269446045160294.pypots
2024-05-25 03:47:44 [INFO]: Epoch 006 - training loss: 0.8723, validation loss: 0.7210
2024-05-25 03:47:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch6_loss0.7209900259971619.pypots
2024-05-25 03:47:48 [INFO]: Epoch 007 - training loss: 0.8765, validation loss: 0.7164
2024-05-25 03:47:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch7_loss0.7164265185594558.pypots
2024-05-25 03:47:52 [INFO]: Epoch 008 - training loss: 0.8522, validation loss: 0.7124
2024-05-25 03:47:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch8_loss0.7124241054058075.pypots
2024-05-25 03:47:56 [INFO]: Epoch 009 - training loss: 0.8402, validation loss: 0.7098
2024-05-25 03:47:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch9_loss0.7098427474498749.pypots
2024-05-25 03:48:00 [INFO]: Epoch 010 - training loss: 0.8462, validation loss: 0.7065
2024-05-25 03:48:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch10_loss0.7065438389778137.pypots
2024-05-25 03:48:04 [INFO]: Epoch 011 - training loss: 0.8710, validation loss: 0.7039
2024-05-25 03:48:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch11_loss0.7038572311401368.pypots
2024-05-25 03:48:07 [INFO]: Epoch 012 - training loss: 0.8571, validation loss: 0.7046
2024-05-25 03:48:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch12_loss0.7046267330646515.pypots
2024-05-25 03:48:11 [INFO]: Epoch 013 - training loss: 0.8444, validation loss: 0.7038
2024-05-25 03:48:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch13_loss0.7037867933511734.pypots
2024-05-25 03:48:15 [INFO]: Epoch 014 - training loss: 0.8270, validation loss: 0.7023
2024-05-25 03:48:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch14_loss0.7022584557533265.pypots
2024-05-25 03:48:19 [INFO]: Epoch 015 - training loss: 0.8203, validation loss: 0.7010
2024-05-25 03:48:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch15_loss0.7009537398815155.pypots
2024-05-25 03:48:23 [INFO]: Epoch 016 - training loss: 0.8157, validation loss: 0.7012
2024-05-25 03:48:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch16_loss0.7011921405792236.pypots
2024-05-25 03:48:27 [INFO]: Epoch 017 - training loss: 0.8195, validation loss: 0.7019
2024-05-25 03:48:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch17_loss0.7018532007932663.pypots
2024-05-25 03:48:31 [INFO]: Epoch 018 - training loss: 0.8121, validation loss: 0.7009
2024-05-25 03:48:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch18_loss0.7008727133274079.pypots
2024-05-25 03:48:35 [INFO]: Epoch 019 - training loss: 0.8072, validation loss: 0.7006
2024-05-25 03:48:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch19_loss0.7005655258893967.pypots
2024-05-25 03:48:39 [INFO]: Epoch 020 - training loss: 0.8088, validation loss: 0.7017
2024-05-25 03:48:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch20_loss0.7016613990068435.pypots
2024-05-25 03:48:42 [INFO]: Epoch 021 - training loss: 0.8191, validation loss: 0.7010
2024-05-25 03:48:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch21_loss0.7010375916957855.pypots
2024-05-25 03:48:46 [INFO]: Epoch 022 - training loss: 0.8203, validation loss: 0.6995
2024-05-25 03:48:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch22_loss0.6994503408670425.pypots
2024-05-25 03:48:50 [INFO]: Epoch 023 - training loss: 0.8003, validation loss: 0.6989
2024-05-25 03:48:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch23_loss0.6988605171442032.pypots
2024-05-25 03:48:54 [INFO]: Epoch 024 - training loss: 0.8155, validation loss: 0.7021
2024-05-25 03:48:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch24_loss0.7021335393190384.pypots
2024-05-25 03:48:58 [INFO]: Epoch 025 - training loss: 0.8128, validation loss: 0.6997
2024-05-25 03:48:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch25_loss0.6996582299470901.pypots
2024-05-25 03:49:02 [INFO]: Epoch 026 - training loss: 0.7987, validation loss: 0.6979
2024-05-25 03:49:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch26_loss0.6978963345289231.pypots
2024-05-25 03:49:06 [INFO]: Epoch 027 - training loss: 0.8079, validation loss: 0.6996
2024-05-25 03:49:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch27_loss0.699553233385086.pypots
2024-05-25 03:49:10 [INFO]: Epoch 028 - training loss: 0.7941, validation loss: 0.7000
2024-05-25 03:49:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch28_loss0.6999674707651138.pypots
2024-05-25 03:49:14 [INFO]: Epoch 029 - training loss: 0.7855, validation loss: 0.7015
2024-05-25 03:49:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch29_loss0.7014684855937958.pypots
2024-05-25 03:49:17 [INFO]: Epoch 030 - training loss: 0.7938, validation loss: 0.7052
2024-05-25 03:49:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch30_loss0.7051833063364029.pypots
2024-05-25 03:49:21 [INFO]: Epoch 031 - training loss: 0.7910, validation loss: 0.7002
2024-05-25 03:49:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch31_loss0.7002238690853119.pypots
2024-05-25 03:49:25 [INFO]: Epoch 032 - training loss: 0.7854, validation loss: 0.6996
2024-05-25 03:49:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch32_loss0.6995720714330673.pypots
2024-05-25 03:49:29 [INFO]: Epoch 033 - training loss: 0.7977, validation loss: 0.7022
2024-05-25 03:49:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch33_loss0.7021684557199478.pypots
2024-05-25 03:49:33 [INFO]: Epoch 034 - training loss: 0.7787, validation loss: 0.7023
2024-05-25 03:49:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch34_loss0.7022874385118485.pypots
2024-05-25 03:49:37 [INFO]: Epoch 035 - training loss: 0.7865, validation loss: 0.6992
2024-05-25 03:49:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch35_loss0.6991996884346008.pypots
2024-05-25 03:49:41 [INFO]: Epoch 036 - training loss: 0.7652, validation loss: 0.7027
2024-05-25 03:49:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN_epoch36_loss0.7027095943689347.pypots
2024-05-25 03:49:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:49:41 [INFO]: Finished training. The best model is from epoch#26.
2024-05-25 03:49:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_air_quality/20240525_T034720/MRNN.pypots
2024-05-25 03:49:41 [INFO]: MRNN on Air-Quality: MAE=0.5210, MSE=0.6347
2024-05-25 03:49:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_air_quality/imputation.pkl
2024-05-25 03:49:41 [INFO]: Using the given device: cpu
2024-05-25 03:49:41 [INFO]: LOCF on Air-Quality: MAE=0.2194, MSE=0.3465
2024-05-25 03:49:41 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_air_quality".
2024-05-25 03:49:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_air_quality/imputation.pkl
2024-05-25 03:49:41 [INFO]: Median on Air-Quality: MAE=0.6629, MSE=1.0282
2024-05-25 03:49:41 [INFO]: Successfully created the given path "saved_results/round_0/Median_air_quality".
2024-05-25 03:49:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_air_quality/imputation.pkl
2024-05-25 03:49:42 [INFO]: Mean on Air-Quality: MAE=0.6945, MSE=0.9678
2024-05-25 03:49:42 [INFO]: Successfully created the given path "saved_results/round_0/Mean_air_quality".
2024-05-25 03:49:42 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_air_quality/imputation.pkl
2024-05-25 03:49:42 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-25 03:49:42 [INFO]: Using the given device: cuda:0
2024-05-25 03:49:42 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240525_T034942
2024-05-25 03:49:42 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240525_T034942/tensorboard
2024-05-25 03:49:42 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 03:49:42 [INFO]: Epoch 001 - training loss: 1.0507, validation loss: 0.5477
2024-05-25 03:49:43 [INFO]: Epoch 002 - training loss: 0.7481, validation loss: 0.4297
2024-05-25 03:49:44 [INFO]: Epoch 003 - training loss: 0.6389, validation loss: 0.3499
2024-05-25 03:49:44 [INFO]: Epoch 004 - training loss: 0.5656, validation loss: 0.3086
2024-05-25 03:49:45 [INFO]: Epoch 005 - training loss: 0.5160, validation loss: 0.2803
2024-05-25 03:49:45 [INFO]: Epoch 006 - training loss: 0.4811, validation loss: 0.2652
2024-05-25 03:49:46 [INFO]: Epoch 007 - training loss: 0.4562, validation loss: 0.2552
2024-05-25 03:49:47 [INFO]: Epoch 008 - training loss: 0.4377, validation loss: 0.2480
2024-05-25 03:49:47 [INFO]: Epoch 009 - training loss: 0.4232, validation loss: 0.2414
2024-05-25 03:49:48 [INFO]: Epoch 010 - training loss: 0.4124, validation loss: 0.2359
2024-05-25 03:49:49 [INFO]: Epoch 011 - training loss: 0.4021, validation loss: 0.2319
2024-05-25 03:49:49 [INFO]: Epoch 012 - training loss: 0.3939, validation loss: 0.2273
2024-05-25 03:49:50 [INFO]: Epoch 013 - training loss: 0.3854, validation loss: 0.2253
2024-05-25 03:49:50 [INFO]: Epoch 014 - training loss: 0.3791, validation loss: 0.2220
2024-05-25 03:49:51 [INFO]: Epoch 015 - training loss: 0.3721, validation loss: 0.2183
2024-05-25 03:49:52 [INFO]: Epoch 016 - training loss: 0.3683, validation loss: 0.2162
2024-05-25 03:49:52 [INFO]: Epoch 017 - training loss: 0.3617, validation loss: 0.2129
2024-05-25 03:49:53 [INFO]: Epoch 018 - training loss: 0.3565, validation loss: 0.2111
2024-05-25 03:49:53 [INFO]: Epoch 019 - training loss: 0.3517, validation loss: 0.2079
2024-05-25 03:49:54 [INFO]: Epoch 020 - training loss: 0.3483, validation loss: 0.2064
2024-05-25 03:49:55 [INFO]: Epoch 021 - training loss: 0.3437, validation loss: 0.2049
2024-05-25 03:49:55 [INFO]: Epoch 022 - training loss: 0.3408, validation loss: 0.2032
2024-05-25 03:49:56 [INFO]: Epoch 023 - training loss: 0.3373, validation loss: 0.2012
2024-05-25 03:49:56 [INFO]: Epoch 024 - training loss: 0.3340, validation loss: 0.2005
2024-05-25 03:49:57 [INFO]: Epoch 025 - training loss: 0.3300, validation loss: 0.1974
2024-05-25 03:49:58 [INFO]: Epoch 026 - training loss: 0.3294, validation loss: 0.1967
2024-05-25 03:49:58 [INFO]: Epoch 027 - training loss: 0.3264, validation loss: 0.1952
2024-05-25 03:49:59 [INFO]: Epoch 028 - training loss: 0.3236, validation loss: 0.1937
2024-05-25 03:49:59 [INFO]: Epoch 029 - training loss: 0.3203, validation loss: 0.1928
2024-05-25 03:50:00 [INFO]: Epoch 030 - training loss: 0.3180, validation loss: 0.1906
2024-05-25 03:50:01 [INFO]: Epoch 031 - training loss: 0.3154, validation loss: 0.1893
2024-05-25 03:50:01 [INFO]: Epoch 032 - training loss: 0.3139, validation loss: 0.1885
2024-05-25 03:50:02 [INFO]: Epoch 033 - training loss: 0.3121, validation loss: 0.1870
2024-05-25 03:50:02 [INFO]: Epoch 034 - training loss: 0.3086, validation loss: 0.1854
2024-05-25 03:50:03 [INFO]: Epoch 035 - training loss: 0.3059, validation loss: 0.1834
2024-05-25 03:50:04 [INFO]: Epoch 036 - training loss: 0.3055, validation loss: 0.1827
2024-05-25 03:50:04 [INFO]: Epoch 037 - training loss: 0.3021, validation loss: 0.1818
2024-05-25 03:50:05 [INFO]: Epoch 038 - training loss: 0.3006, validation loss: 0.1803
2024-05-25 03:50:05 [INFO]: Epoch 039 - training loss: 0.2974, validation loss: 0.1797
2024-05-25 03:50:06 [INFO]: Epoch 040 - training loss: 0.2967, validation loss: 0.1785
2024-05-25 03:50:07 [INFO]: Epoch 041 - training loss: 0.2945, validation loss: 0.1767
2024-05-25 03:50:07 [INFO]: Epoch 042 - training loss: 0.2927, validation loss: 0.1769
2024-05-25 03:50:08 [INFO]: Epoch 043 - training loss: 0.2915, validation loss: 0.1751
2024-05-25 03:50:08 [INFO]: Epoch 044 - training loss: 0.2906, validation loss: 0.1746
2024-05-25 03:50:09 [INFO]: Epoch 045 - training loss: 0.2890, validation loss: 0.1741
2024-05-25 03:50:10 [INFO]: Epoch 046 - training loss: 0.2867, validation loss: 0.1734
2024-05-25 03:50:10 [INFO]: Epoch 047 - training loss: 0.2856, validation loss: 0.1727
2024-05-25 03:50:11 [INFO]: Epoch 048 - training loss: 0.2829, validation loss: 0.1708
2024-05-25 03:50:11 [INFO]: Epoch 049 - training loss: 0.2817, validation loss: 0.1713
2024-05-25 03:50:12 [INFO]: Epoch 050 - training loss: 0.2799, validation loss: 0.1698
2024-05-25 03:50:13 [INFO]: Epoch 051 - training loss: 0.2786, validation loss: 0.1694
2024-05-25 03:50:13 [INFO]: Epoch 052 - training loss: 0.2774, validation loss: 0.1682
2024-05-25 03:50:14 [INFO]: Epoch 053 - training loss: 0.2766, validation loss: 0.1679
2024-05-25 03:50:14 [INFO]: Epoch 054 - training loss: 0.2751, validation loss: 0.1683
2024-05-25 03:50:15 [INFO]: Epoch 055 - training loss: 0.2718, validation loss: 0.1663
2024-05-25 03:50:16 [INFO]: Epoch 056 - training loss: 0.2713, validation loss: 0.1662
2024-05-25 03:50:16 [INFO]: Epoch 057 - training loss: 0.2691, validation loss: 0.1649
2024-05-25 03:50:17 [INFO]: Epoch 058 - training loss: 0.2687, validation loss: 0.1657
2024-05-25 03:50:17 [INFO]: Epoch 059 - training loss: 0.2681, validation loss: 0.1646
2024-05-25 03:50:18 [INFO]: Epoch 060 - training loss: 0.2666, validation loss: 0.1635
2024-05-25 03:50:19 [INFO]: Epoch 061 - training loss: 0.2658, validation loss: 0.1638
2024-05-25 03:50:19 [INFO]: Epoch 062 - training loss: 0.2648, validation loss: 0.1630
2024-05-25 03:50:20 [INFO]: Epoch 063 - training loss: 0.2640, validation loss: 0.1629
2024-05-25 03:50:20 [INFO]: Epoch 064 - training loss: 0.2612, validation loss: 0.1623
2024-05-25 03:50:21 [INFO]: Epoch 065 - training loss: 0.2596, validation loss: 0.1624
2024-05-25 03:50:22 [INFO]: Epoch 066 - training loss: 0.2590, validation loss: 0.1612
2024-05-25 03:50:22 [INFO]: Epoch 067 - training loss: 0.2584, validation loss: 0.1609
2024-05-25 03:50:23 [INFO]: Epoch 068 - training loss: 0.2572, validation loss: 0.1608
2024-05-25 03:50:23 [INFO]: Epoch 069 - training loss: 0.2556, validation loss: 0.1600
2024-05-25 03:50:24 [INFO]: Epoch 070 - training loss: 0.2542, validation loss: 0.1603
2024-05-25 03:50:25 [INFO]: Epoch 071 - training loss: 0.2545, validation loss: 0.1596
2024-05-25 03:50:25 [INFO]: Epoch 072 - training loss: 0.2532, validation loss: 0.1588
2024-05-25 03:50:26 [INFO]: Epoch 073 - training loss: 0.2523, validation loss: 0.1592
2024-05-25 03:50:26 [INFO]: Epoch 074 - training loss: 0.2504, validation loss: 0.1594
2024-05-25 03:50:27 [INFO]: Epoch 075 - training loss: 0.2499, validation loss: 0.1575
2024-05-25 03:50:28 [INFO]: Epoch 076 - training loss: 0.2483, validation loss: 0.1575
2024-05-25 03:50:28 [INFO]: Epoch 077 - training loss: 0.2471, validation loss: 0.1564
2024-05-25 03:50:29 [INFO]: Epoch 078 - training loss: 0.2464, validation loss: 0.1565
2024-05-25 03:50:29 [INFO]: Epoch 079 - training loss: 0.2459, validation loss: 0.1567
2024-05-25 03:50:30 [INFO]: Epoch 080 - training loss: 0.2451, validation loss: 0.1566
2024-05-25 03:50:31 [INFO]: Epoch 081 - training loss: 0.2439, validation loss: 0.1554
2024-05-25 03:50:31 [INFO]: Epoch 082 - training loss: 0.2433, validation loss: 0.1550
2024-05-25 03:50:32 [INFO]: Epoch 083 - training loss: 0.2425, validation loss: 0.1547
2024-05-25 03:50:32 [INFO]: Epoch 084 - training loss: 0.2432, validation loss: 0.1564
2024-05-25 03:50:33 [INFO]: Epoch 085 - training loss: 0.2433, validation loss: 0.1542
2024-05-25 03:50:34 [INFO]: Epoch 086 - training loss: 0.2438, validation loss: 0.1542
2024-05-25 03:50:34 [INFO]: Epoch 087 - training loss: 0.2412, validation loss: 0.1543
2024-05-25 03:50:35 [INFO]: Epoch 088 - training loss: 0.2394, validation loss: 0.1538
2024-05-25 03:50:35 [INFO]: Epoch 089 - training loss: 0.2385, validation loss: 0.1528
2024-05-25 03:50:36 [INFO]: Epoch 090 - training loss: 0.2380, validation loss: 0.1529
2024-05-25 03:50:37 [INFO]: Epoch 091 - training loss: 0.2373, validation loss: 0.1535
2024-05-25 03:50:37 [INFO]: Epoch 092 - training loss: 0.2402, validation loss: 0.1529
2024-05-25 03:50:38 [INFO]: Epoch 093 - training loss: 0.2366, validation loss: 0.1537
2024-05-25 03:50:38 [INFO]: Epoch 094 - training loss: 0.2356, validation loss: 0.1536
2024-05-25 03:50:39 [INFO]: Epoch 095 - training loss: 0.2340, validation loss: 0.1527
2024-05-25 03:50:40 [INFO]: Epoch 096 - training loss: 0.2336, validation loss: 0.1516
2024-05-25 03:50:40 [INFO]: Epoch 097 - training loss: 0.2329, validation loss: 0.1515
2024-05-25 03:50:41 [INFO]: Epoch 098 - training loss: 0.2334, validation loss: 0.1517
2024-05-25 03:50:41 [INFO]: Epoch 099 - training loss: 0.2321, validation loss: 0.1510
2024-05-25 03:50:42 [INFO]: Epoch 100 - training loss: 0.2310, validation loss: 0.1514
2024-05-25 03:50:43 [INFO]: Epoch 101 - training loss: 0.2311, validation loss: 0.1501
2024-05-25 03:50:43 [INFO]: Epoch 102 - training loss: 0.2307, validation loss: 0.1506
2024-05-25 03:50:44 [INFO]: Epoch 103 - training loss: 0.2298, validation loss: 0.1504
2024-05-25 03:50:44 [INFO]: Epoch 104 - training loss: 0.2284, validation loss: 0.1494
2024-05-25 03:50:45 [INFO]: Epoch 105 - training loss: 0.2273, validation loss: 0.1493
2024-05-25 03:50:46 [INFO]: Epoch 106 - training loss: 0.2269, validation loss: 0.1491
2024-05-25 03:50:46 [INFO]: Epoch 107 - training loss: 0.2265, validation loss: 0.1485
2024-05-25 03:50:47 [INFO]: Epoch 108 - training loss: 0.2258, validation loss: 0.1494
2024-05-25 03:50:47 [INFO]: Epoch 109 - training loss: 0.2257, validation loss: 0.1491
2024-05-25 03:50:48 [INFO]: Epoch 110 - training loss: 0.2261, validation loss: 0.1475
2024-05-25 03:50:49 [INFO]: Epoch 111 - training loss: 0.2265, validation loss: 0.1482
2024-05-25 03:50:49 [INFO]: Epoch 112 - training loss: 0.2254, validation loss: 0.1487
2024-05-25 03:50:50 [INFO]: Epoch 113 - training loss: 0.2240, validation loss: 0.1486
2024-05-25 03:50:50 [INFO]: Epoch 114 - training loss: 0.2230, validation loss: 0.1481
2024-05-25 03:50:51 [INFO]: Epoch 115 - training loss: 0.2219, validation loss: 0.1473
2024-05-25 03:50:52 [INFO]: Epoch 116 - training loss: 0.2226, validation loss: 0.1468
2024-05-25 03:50:52 [INFO]: Epoch 117 - training loss: 0.2212, validation loss: 0.1467
2024-05-25 03:50:53 [INFO]: Epoch 118 - training loss: 0.2214, validation loss: 0.1460
2024-05-25 03:50:53 [INFO]: Epoch 119 - training loss: 0.2206, validation loss: 0.1477
2024-05-25 03:50:54 [INFO]: Epoch 120 - training loss: 0.2200, validation loss: 0.1467
2024-05-25 03:50:55 [INFO]: Epoch 121 - training loss: 0.2192, validation loss: 0.1468
2024-05-25 03:50:55 [INFO]: Epoch 122 - training loss: 0.2182, validation loss: 0.1450
2024-05-25 03:50:56 [INFO]: Epoch 123 - training loss: 0.2168, validation loss: 0.1446
2024-05-25 03:50:56 [INFO]: Epoch 124 - training loss: 0.2176, validation loss: 0.1442
2024-05-25 03:50:57 [INFO]: Epoch 125 - training loss: 0.2165, validation loss: 0.1448
2024-05-25 03:50:58 [INFO]: Epoch 126 - training loss: 0.2157, validation loss: 0.1443
2024-05-25 03:50:58 [INFO]: Epoch 127 - training loss: 0.2151, validation loss: 0.1460
2024-05-25 03:50:59 [INFO]: Epoch 128 - training loss: 0.2148, validation loss: 0.1454
2024-05-25 03:50:59 [INFO]: Epoch 129 - training loss: 0.2146, validation loss: 0.1441
2024-05-25 03:51:00 [INFO]: Epoch 130 - training loss: 0.2140, validation loss: 0.1452
2024-05-25 03:51:01 [INFO]: Epoch 131 - training loss: 0.2142, validation loss: 0.1448
2024-05-25 03:51:01 [INFO]: Epoch 132 - training loss: 0.2134, validation loss: 0.1446
2024-05-25 03:51:02 [INFO]: Epoch 133 - training loss: 0.2135, validation loss: 0.1440
2024-05-25 03:51:02 [INFO]: Epoch 134 - training loss: 0.2114, validation loss: 0.1435
2024-05-25 03:51:03 [INFO]: Epoch 135 - training loss: 0.2113, validation loss: 0.1453
2024-05-25 03:51:04 [INFO]: Epoch 136 - training loss: 0.2116, validation loss: 0.1431
2024-05-25 03:51:04 [INFO]: Epoch 137 - training loss: 0.2118, validation loss: 0.1439
2024-05-25 03:51:05 [INFO]: Epoch 138 - training loss: 0.2121, validation loss: 0.1433
2024-05-25 03:51:05 [INFO]: Epoch 139 - training loss: 0.2102, validation loss: 0.1431
2024-05-25 03:51:06 [INFO]: Epoch 140 - training loss: 0.2096, validation loss: 0.1429
2024-05-25 03:51:07 [INFO]: Epoch 141 - training loss: 0.2089, validation loss: 0.1435
2024-05-25 03:51:07 [INFO]: Epoch 142 - training loss: 0.2080, validation loss: 0.1426
2024-05-25 03:51:08 [INFO]: Epoch 143 - training loss: 0.2076, validation loss: 0.1428
2024-05-25 03:51:09 [INFO]: Epoch 144 - training loss: 0.2100, validation loss: 0.1440
2024-05-25 03:51:09 [INFO]: Epoch 145 - training loss: 0.2087, validation loss: 0.1420
2024-05-25 03:51:10 [INFO]: Epoch 146 - training loss: 0.2070, validation loss: 0.1422
2024-05-25 03:51:10 [INFO]: Epoch 147 - training loss: 0.2055, validation loss: 0.1413
2024-05-25 03:51:11 [INFO]: Epoch 148 - training loss: 0.2062, validation loss: 0.1433
2024-05-25 03:51:12 [INFO]: Epoch 149 - training loss: 0.2067, validation loss: 0.1423
2024-05-25 03:51:12 [INFO]: Epoch 150 - training loss: 0.2061, validation loss: 0.1416
2024-05-25 03:51:13 [INFO]: Epoch 151 - training loss: 0.2051, validation loss: 0.1409
2024-05-25 03:51:13 [INFO]: Epoch 152 - training loss: 0.2047, validation loss: 0.1413
2024-05-25 03:51:14 [INFO]: Epoch 153 - training loss: 0.2054, validation loss: 0.1425
2024-05-25 03:51:15 [INFO]: Epoch 154 - training loss: 0.2036, validation loss: 0.1409
2024-05-25 03:51:15 [INFO]: Epoch 155 - training loss: 0.2023, validation loss: 0.1409
2024-05-25 03:51:16 [INFO]: Epoch 156 - training loss: 0.2023, validation loss: 0.1406
2024-05-25 03:51:16 [INFO]: Epoch 157 - training loss: 0.2016, validation loss: 0.1415
2024-05-25 03:51:17 [INFO]: Epoch 158 - training loss: 0.2015, validation loss: 0.1413
2024-05-25 03:51:18 [INFO]: Epoch 159 - training loss: 0.2012, validation loss: 0.1406
2024-05-25 03:51:18 [INFO]: Epoch 160 - training loss: 0.2003, validation loss: 0.1402
2024-05-25 03:51:19 [INFO]: Epoch 161 - training loss: 0.1996, validation loss: 0.1396
2024-05-25 03:51:19 [INFO]: Epoch 162 - training loss: 0.1999, validation loss: 0.1407
2024-05-25 03:51:20 [INFO]: Epoch 163 - training loss: 0.1992, validation loss: 0.1405
2024-05-25 03:51:21 [INFO]: Epoch 164 - training loss: 0.1986, validation loss: 0.1393
2024-05-25 03:51:21 [INFO]: Epoch 165 - training loss: 0.1983, validation loss: 0.1393
2024-05-25 03:51:22 [INFO]: Epoch 166 - training loss: 0.2001, validation loss: 0.1403
2024-05-25 03:51:22 [INFO]: Epoch 167 - training loss: 0.2033, validation loss: 0.1414
2024-05-25 03:51:23 [INFO]: Epoch 168 - training loss: 0.2025, validation loss: 0.1399
2024-05-25 03:51:24 [INFO]: Epoch 169 - training loss: 0.2006, validation loss: 0.1437
2024-05-25 03:51:24 [INFO]: Epoch 170 - training loss: 0.2015, validation loss: 0.1402
2024-05-25 03:51:25 [INFO]: Epoch 171 - training loss: 0.1979, validation loss: 0.1391
2024-05-25 03:51:25 [INFO]: Epoch 172 - training loss: 0.1970, validation loss: 0.1391
2024-05-25 03:51:26 [INFO]: Epoch 173 - training loss: 0.1967, validation loss: 0.1386
2024-05-25 03:51:27 [INFO]: Epoch 174 - training loss: 0.1958, validation loss: 0.1391
2024-05-25 03:51:27 [INFO]: Epoch 175 - training loss: 0.1958, validation loss: 0.1392
2024-05-25 03:51:28 [INFO]: Epoch 176 - training loss: 0.1949, validation loss: 0.1388
2024-05-25 03:51:28 [INFO]: Epoch 177 - training loss: 0.1946, validation loss: 0.1394
2024-05-25 03:51:29 [INFO]: Epoch 178 - training loss: 0.1948, validation loss: 0.1391
2024-05-25 03:51:30 [INFO]: Epoch 179 - training loss: 0.1932, validation loss: 0.1388
2024-05-25 03:51:30 [INFO]: Epoch 180 - training loss: 0.1932, validation loss: 0.1377
2024-05-25 03:51:31 [INFO]: Epoch 181 - training loss: 0.1926, validation loss: 0.1386
2024-05-25 03:51:31 [INFO]: Epoch 182 - training loss: 0.1926, validation loss: 0.1381
2024-05-25 03:51:32 [INFO]: Epoch 183 - training loss: 0.1927, validation loss: 0.1385
2024-05-25 03:51:33 [INFO]: Epoch 184 - training loss: 0.1912, validation loss: 0.1378
2024-05-25 03:51:33 [INFO]: Epoch 185 - training loss: 0.1920, validation loss: 0.1383
2024-05-25 03:51:34 [INFO]: Epoch 186 - training loss: 0.1921, validation loss: 0.1386
2024-05-25 03:51:34 [INFO]: Epoch 187 - training loss: 0.1912, validation loss: 0.1388
2024-05-25 03:51:35 [INFO]: Epoch 188 - training loss: 0.1906, validation loss: 0.1387
2024-05-25 03:51:36 [INFO]: Epoch 189 - training loss: 0.1900, validation loss: 0.1386
2024-05-25 03:51:36 [INFO]: Epoch 190 - training loss: 0.1895, validation loss: 0.1372
2024-05-25 03:51:37 [INFO]: Epoch 191 - training loss: 0.1895, validation loss: 0.1376
2024-05-25 03:51:37 [INFO]: Epoch 192 - training loss: 0.1900, validation loss: 0.1390
2024-05-25 03:51:38 [INFO]: Epoch 193 - training loss: 0.1889, validation loss: 0.1380
2024-05-25 03:51:39 [INFO]: Epoch 194 - training loss: 0.1889, validation loss: 0.1379
2024-05-25 03:51:39 [INFO]: Epoch 195 - training loss: 0.1887, validation loss: 0.1370
2024-05-25 03:51:40 [INFO]: Epoch 196 - training loss: 0.1888, validation loss: 0.1377
2024-05-25 03:51:40 [INFO]: Epoch 197 - training loss: 0.1885, validation loss: 0.1379
2024-05-25 03:51:41 [INFO]: Epoch 198 - training loss: 0.1900, validation loss: 0.1380
2024-05-25 03:51:42 [INFO]: Epoch 199 - training loss: 0.1885, validation loss: 0.1372
2024-05-25 03:51:42 [INFO]: Epoch 200 - training loss: 0.1874, validation loss: 0.1368
2024-05-25 03:51:43 [INFO]: Epoch 201 - training loss: 0.1873, validation loss: 0.1365
2024-05-25 03:51:43 [INFO]: Epoch 202 - training loss: 0.1859, validation loss: 0.1367
2024-05-25 03:51:44 [INFO]: Epoch 203 - training loss: 0.1854, validation loss: 0.1380
2024-05-25 03:51:45 [INFO]: Epoch 204 - training loss: 0.1880, validation loss: 0.1372
2024-05-25 03:51:45 [INFO]: Epoch 205 - training loss: 0.1865, validation loss: 0.1379
2024-05-25 03:51:46 [INFO]: Epoch 206 - training loss: 0.1855, validation loss: 0.1372
2024-05-25 03:51:46 [INFO]: Epoch 207 - training loss: 0.1845, validation loss: 0.1368
2024-05-25 03:51:47 [INFO]: Epoch 208 - training loss: 0.1846, validation loss: 0.1379
2024-05-25 03:51:48 [INFO]: Epoch 209 - training loss: 0.1839, validation loss: 0.1363
2024-05-25 03:51:48 [INFO]: Epoch 210 - training loss: 0.1837, validation loss: 0.1364
2024-05-25 03:51:49 [INFO]: Epoch 211 - training loss: 0.1834, validation loss: 0.1377
2024-05-25 03:51:49 [INFO]: Epoch 212 - training loss: 0.1831, validation loss: 0.1373
2024-05-25 03:51:50 [INFO]: Epoch 213 - training loss: 0.1828, validation loss: 0.1367
2024-05-25 03:51:51 [INFO]: Epoch 214 - training loss: 0.1831, validation loss: 0.1388
2024-05-25 03:51:51 [INFO]: Epoch 215 - training loss: 0.1833, validation loss: 0.1373
2024-05-25 03:51:52 [INFO]: Epoch 216 - training loss: 0.1838, validation loss: 0.1384
2024-05-25 03:51:52 [INFO]: Epoch 217 - training loss: 0.1824, validation loss: 0.1370
2024-05-25 03:51:53 [INFO]: Epoch 218 - training loss: 0.1825, validation loss: 0.1369
2024-05-25 03:51:54 [INFO]: Epoch 219 - training loss: 0.1820, validation loss: 0.1370
2024-05-25 03:51:54 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:51:54 [INFO]: Finished training. The best model is from epoch#209.
2024-05-25 03:51:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_air_quality/20240525_T034942/SAITS.pypots
2024-05-25 03:51:54 [INFO]: SAITS on Air-Quality: MAE=0.1583, MSE=0.1395
2024-05-25 03:51:54 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_air_quality/imputation.pkl
2024-05-25 03:51:54 [INFO]: Using the given device: cuda:0
2024-05-25 03:51:54 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240525_T035154
2024-05-25 03:51:54 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240525_T035154/tensorboard
2024-05-25 03:51:54 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 03:51:54 [INFO]: Epoch 001 - training loss: 0.9177, validation loss: 0.4862
2024-05-25 03:51:54 [INFO]: Epoch 002 - training loss: 0.5759, validation loss: 0.3683
2024-05-25 03:51:55 [INFO]: Epoch 003 - training loss: 0.4867, validation loss: 0.3154
2024-05-25 03:51:55 [INFO]: Epoch 004 - training loss: 0.4363, validation loss: 0.2858
2024-05-25 03:51:55 [INFO]: Epoch 005 - training loss: 0.4095, validation loss: 0.2726
2024-05-25 03:51:55 [INFO]: Epoch 006 - training loss: 0.3895, validation loss: 0.2622
2024-05-25 03:51:56 [INFO]: Epoch 007 - training loss: 0.3731, validation loss: 0.2542
2024-05-25 03:51:56 [INFO]: Epoch 008 - training loss: 0.3660, validation loss: 0.2475
2024-05-25 03:51:56 [INFO]: Epoch 009 - training loss: 0.3534, validation loss: 0.2425
2024-05-25 03:51:56 [INFO]: Epoch 010 - training loss: 0.3480, validation loss: 0.2398
2024-05-25 03:51:57 [INFO]: Epoch 011 - training loss: 0.3404, validation loss: 0.2346
2024-05-25 03:51:57 [INFO]: Epoch 012 - training loss: 0.3322, validation loss: 0.2298
2024-05-25 03:51:57 [INFO]: Epoch 013 - training loss: 0.3278, validation loss: 0.2263
2024-05-25 03:51:57 [INFO]: Epoch 014 - training loss: 0.3243, validation loss: 0.2235
2024-05-25 03:51:58 [INFO]: Epoch 015 - training loss: 0.3191, validation loss: 0.2191
2024-05-25 03:51:58 [INFO]: Epoch 016 - training loss: 0.3147, validation loss: 0.2188
2024-05-25 03:51:58 [INFO]: Epoch 017 - training loss: 0.3116, validation loss: 0.2173
2024-05-25 03:51:58 [INFO]: Epoch 018 - training loss: 0.3065, validation loss: 0.2118
2024-05-25 03:51:59 [INFO]: Epoch 019 - training loss: 0.3033, validation loss: 0.2106
2024-05-25 03:51:59 [INFO]: Epoch 020 - training loss: 0.2973, validation loss: 0.2073
2024-05-25 03:51:59 [INFO]: Epoch 021 - training loss: 0.2956, validation loss: 0.2049
2024-05-25 03:51:59 [INFO]: Epoch 022 - training loss: 0.2940, validation loss: 0.2045
2024-05-25 03:52:00 [INFO]: Epoch 023 - training loss: 0.2916, validation loss: 0.2007
2024-05-25 03:52:00 [INFO]: Epoch 024 - training loss: 0.2924, validation loss: 0.2002
2024-05-25 03:52:00 [INFO]: Epoch 025 - training loss: 0.2885, validation loss: 0.1975
2024-05-25 03:52:00 [INFO]: Epoch 026 - training loss: 0.2840, validation loss: 0.1972
2024-05-25 03:52:01 [INFO]: Epoch 027 - training loss: 0.2809, validation loss: 0.1946
2024-05-25 03:52:01 [INFO]: Epoch 028 - training loss: 0.2811, validation loss: 0.1935
2024-05-25 03:52:01 [INFO]: Epoch 029 - training loss: 0.2784, validation loss: 0.1957
2024-05-25 03:52:01 [INFO]: Epoch 030 - training loss: 0.2772, validation loss: 0.1947
2024-05-25 03:52:02 [INFO]: Epoch 031 - training loss: 0.2740, validation loss: 0.1912
2024-05-25 03:52:02 [INFO]: Epoch 032 - training loss: 0.2716, validation loss: 0.1905
2024-05-25 03:52:02 [INFO]: Epoch 033 - training loss: 0.2692, validation loss: 0.1904
2024-05-25 03:52:02 [INFO]: Epoch 034 - training loss: 0.2672, validation loss: 0.1897
2024-05-25 03:52:03 [INFO]: Epoch 035 - training loss: 0.2650, validation loss: 0.1888
2024-05-25 03:52:03 [INFO]: Epoch 036 - training loss: 0.2646, validation loss: 0.1885
2024-05-25 03:52:03 [INFO]: Epoch 037 - training loss: 0.2614, validation loss: 0.1862
2024-05-25 03:52:03 [INFO]: Epoch 038 - training loss: 0.2616, validation loss: 0.1859
2024-05-25 03:52:04 [INFO]: Epoch 039 - training loss: 0.2614, validation loss: 0.1860
2024-05-25 03:52:04 [INFO]: Epoch 040 - training loss: 0.2626, validation loss: 0.1887
2024-05-25 03:52:04 [INFO]: Epoch 041 - training loss: 0.2599, validation loss: 0.1860
2024-05-25 03:52:04 [INFO]: Epoch 042 - training loss: 0.2606, validation loss: 0.1851
2024-05-25 03:52:05 [INFO]: Epoch 043 - training loss: 0.2550, validation loss: 0.1869
2024-05-25 03:52:05 [INFO]: Epoch 044 - training loss: 0.2514, validation loss: 0.1851
2024-05-25 03:52:05 [INFO]: Epoch 045 - training loss: 0.2501, validation loss: 0.1832
2024-05-25 03:52:05 [INFO]: Epoch 046 - training loss: 0.2512, validation loss: 0.1851
2024-05-25 03:52:06 [INFO]: Epoch 047 - training loss: 0.2505, validation loss: 0.1844
2024-05-25 03:52:06 [INFO]: Epoch 048 - training loss: 0.2498, validation loss: 0.1825
2024-05-25 03:52:06 [INFO]: Epoch 049 - training loss: 0.2469, validation loss: 0.1818
2024-05-25 03:52:06 [INFO]: Epoch 050 - training loss: 0.2456, validation loss: 0.1806
2024-05-25 03:52:07 [INFO]: Epoch 051 - training loss: 0.2447, validation loss: 0.1845
2024-05-25 03:52:07 [INFO]: Epoch 052 - training loss: 0.2435, validation loss: 0.1816
2024-05-25 03:52:07 [INFO]: Epoch 053 - training loss: 0.2405, validation loss: 0.1801
2024-05-25 03:52:07 [INFO]: Epoch 054 - training loss: 0.2390, validation loss: 0.1790
2024-05-25 03:52:08 [INFO]: Epoch 055 - training loss: 0.2381, validation loss: 0.1824
2024-05-25 03:52:08 [INFO]: Epoch 056 - training loss: 0.2364, validation loss: 0.1807
2024-05-25 03:52:08 [INFO]: Epoch 057 - training loss: 0.2362, validation loss: 0.1812
2024-05-25 03:52:08 [INFO]: Epoch 058 - training loss: 0.2388, validation loss: 0.1806
2024-05-25 03:52:09 [INFO]: Epoch 059 - training loss: 0.2333, validation loss: 0.1789
2024-05-25 03:52:09 [INFO]: Epoch 060 - training loss: 0.2338, validation loss: 0.1785
2024-05-25 03:52:09 [INFO]: Epoch 061 - training loss: 0.2325, validation loss: 0.1792
2024-05-25 03:52:09 [INFO]: Epoch 062 - training loss: 0.2302, validation loss: 0.1769
2024-05-25 03:52:10 [INFO]: Epoch 063 - training loss: 0.2303, validation loss: 0.1766
2024-05-25 03:52:10 [INFO]: Epoch 064 - training loss: 0.2292, validation loss: 0.1756
2024-05-25 03:52:10 [INFO]: Epoch 065 - training loss: 0.2269, validation loss: 0.1776
2024-05-25 03:52:10 [INFO]: Epoch 066 - training loss: 0.2269, validation loss: 0.1784
2024-05-25 03:52:11 [INFO]: Epoch 067 - training loss: 0.2265, validation loss: 0.1763
2024-05-25 03:52:11 [INFO]: Epoch 068 - training loss: 0.2246, validation loss: 0.1768
2024-05-25 03:52:11 [INFO]: Epoch 069 - training loss: 0.2238, validation loss: 0.1764
2024-05-25 03:52:11 [INFO]: Epoch 070 - training loss: 0.2259, validation loss: 0.1771
2024-05-25 03:52:12 [INFO]: Epoch 071 - training loss: 0.2281, validation loss: 0.1766
2024-05-25 03:52:12 [INFO]: Epoch 072 - training loss: 0.2263, validation loss: 0.1750
2024-05-25 03:52:12 [INFO]: Epoch 073 - training loss: 0.2243, validation loss: 0.1749
2024-05-25 03:52:12 [INFO]: Epoch 074 - training loss: 0.2243, validation loss: 0.1772
2024-05-25 03:52:13 [INFO]: Epoch 075 - training loss: 0.2224, validation loss: 0.1773
2024-05-25 03:52:13 [INFO]: Epoch 076 - training loss: 0.2196, validation loss: 0.1746
2024-05-25 03:52:13 [INFO]: Epoch 077 - training loss: 0.2176, validation loss: 0.1747
2024-05-25 03:52:13 [INFO]: Epoch 078 - training loss: 0.2162, validation loss: 0.1736
2024-05-25 03:52:14 [INFO]: Epoch 079 - training loss: 0.2176, validation loss: 0.1741
2024-05-25 03:52:14 [INFO]: Epoch 080 - training loss: 0.2188, validation loss: 0.1736
2024-05-25 03:52:14 [INFO]: Epoch 081 - training loss: 0.2185, validation loss: 0.1758
2024-05-25 03:52:15 [INFO]: Epoch 082 - training loss: 0.2151, validation loss: 0.1733
2024-05-25 03:52:15 [INFO]: Epoch 083 - training loss: 0.2135, validation loss: 0.1719
2024-05-25 03:52:15 [INFO]: Epoch 084 - training loss: 0.2102, validation loss: 0.1745
2024-05-25 03:52:15 [INFO]: Epoch 085 - training loss: 0.2090, validation loss: 0.1732
2024-05-25 03:52:16 [INFO]: Epoch 086 - training loss: 0.2082, validation loss: 0.1733
2024-05-25 03:52:16 [INFO]: Epoch 087 - training loss: 0.2077, validation loss: 0.1722
2024-05-25 03:52:16 [INFO]: Epoch 088 - training loss: 0.2061, validation loss: 0.1737
2024-05-25 03:52:16 [INFO]: Epoch 089 - training loss: 0.2075, validation loss: 0.1725
2024-05-25 03:52:17 [INFO]: Epoch 090 - training loss: 0.2105, validation loss: 0.1728
2024-05-25 03:52:17 [INFO]: Epoch 091 - training loss: 0.2079, validation loss: 0.1713
2024-05-25 03:52:17 [INFO]: Epoch 092 - training loss: 0.2035, validation loss: 0.1725
2024-05-25 03:52:17 [INFO]: Epoch 093 - training loss: 0.2044, validation loss: 0.1748
2024-05-25 03:52:18 [INFO]: Epoch 094 - training loss: 0.2054, validation loss: 0.1717
2024-05-25 03:52:18 [INFO]: Epoch 095 - training loss: 0.2038, validation loss: 0.1719
2024-05-25 03:52:18 [INFO]: Epoch 096 - training loss: 0.2091, validation loss: 0.1693
2024-05-25 03:52:18 [INFO]: Epoch 097 - training loss: 0.2071, validation loss: 0.1711
2024-05-25 03:52:19 [INFO]: Epoch 098 - training loss: 0.2034, validation loss: 0.1700
2024-05-25 03:52:19 [INFO]: Epoch 099 - training loss: 0.1993, validation loss: 0.1689
2024-05-25 03:52:19 [INFO]: Epoch 100 - training loss: 0.1971, validation loss: 0.1702
2024-05-25 03:52:19 [INFO]: Epoch 101 - training loss: 0.1964, validation loss: 0.1710
2024-05-25 03:52:20 [INFO]: Epoch 102 - training loss: 0.1948, validation loss: 0.1691
2024-05-25 03:52:20 [INFO]: Epoch 103 - training loss: 0.1941, validation loss: 0.1681
2024-05-25 03:52:20 [INFO]: Epoch 104 - training loss: 0.1983, validation loss: 0.1688
2024-05-25 03:52:20 [INFO]: Epoch 105 - training loss: 0.1977, validation loss: 0.1701
2024-05-25 03:52:21 [INFO]: Epoch 106 - training loss: 0.1951, validation loss: 0.1697
2024-05-25 03:52:21 [INFO]: Epoch 107 - training loss: 0.1945, validation loss: 0.1708
2024-05-25 03:52:21 [INFO]: Epoch 108 - training loss: 0.1963, validation loss: 0.1692
2024-05-25 03:52:21 [INFO]: Epoch 109 - training loss: 0.1954, validation loss: 0.1684
2024-05-25 03:52:22 [INFO]: Epoch 110 - training loss: 0.1925, validation loss: 0.1685
2024-05-25 03:52:22 [INFO]: Epoch 111 - training loss: 0.1897, validation loss: 0.1670
2024-05-25 03:52:22 [INFO]: Epoch 112 - training loss: 0.1899, validation loss: 0.1695
2024-05-25 03:52:22 [INFO]: Epoch 113 - training loss: 0.1904, validation loss: 0.1692
2024-05-25 03:52:23 [INFO]: Epoch 114 - training loss: 0.1896, validation loss: 0.1682
2024-05-25 03:52:23 [INFO]: Epoch 115 - training loss: 0.1914, validation loss: 0.1687
2024-05-25 03:52:23 [INFO]: Epoch 116 - training loss: 0.1893, validation loss: 0.1682
2024-05-25 03:52:23 [INFO]: Epoch 117 - training loss: 0.1899, validation loss: 0.1679
2024-05-25 03:52:24 [INFO]: Epoch 118 - training loss: 0.1881, validation loss: 0.1690
2024-05-25 03:52:24 [INFO]: Epoch 119 - training loss: 0.1883, validation loss: 0.1680
2024-05-25 03:52:24 [INFO]: Epoch 120 - training loss: 0.1866, validation loss: 0.1673
2024-05-25 03:52:24 [INFO]: Epoch 121 - training loss: 0.1860, validation loss: 0.1674
2024-05-25 03:52:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:52:24 [INFO]: Finished training. The best model is from epoch#111.
2024-05-25 03:52:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_air_quality/20240525_T035154/Transformer.pypots
2024-05-25 03:52:24 [INFO]: Transformer on Air-Quality: MAE=0.1823, MSE=0.1712
2024-05-25 03:52:24 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_air_quality/imputation.pkl
2024-05-25 03:52:24 [INFO]: Using the given device: cuda:0
2024-05-25 03:52:24 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240525_T035224
2024-05-25 03:52:24 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240525_T035224/tensorboard
2024-05-25 03:52:25 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 03:52:25 [INFO]: Epoch 001 - training loss: 0.3087, validation loss: 0.2775
2024-05-25 03:52:26 [INFO]: Epoch 002 - training loss: 0.2093, validation loss: 0.2470
2024-05-25 03:52:26 [INFO]: Epoch 003 - training loss: 0.1783, validation loss: 0.2341
2024-05-25 03:52:27 [INFO]: Epoch 004 - training loss: 0.1664, validation loss: 0.2167
2024-05-25 03:52:27 [INFO]: Epoch 005 - training loss: 0.1616, validation loss: 0.2086
2024-05-25 03:52:28 [INFO]: Epoch 006 - training loss: 0.1499, validation loss: 0.2036
2024-05-25 03:52:28 [INFO]: Epoch 007 - training loss: 0.1373, validation loss: 0.2004
2024-05-25 03:52:29 [INFO]: Epoch 008 - training loss: 0.1289, validation loss: 0.1960
2024-05-25 03:52:29 [INFO]: Epoch 009 - training loss: 0.1220, validation loss: 0.1962
2024-05-25 03:52:29 [INFO]: Epoch 010 - training loss: 0.1180, validation loss: 0.1941
2024-05-25 03:52:30 [INFO]: Epoch 011 - training loss: 0.1163, validation loss: 0.2097
2024-05-25 03:52:30 [INFO]: Epoch 012 - training loss: 0.1193, validation loss: 0.2041
2024-05-25 03:52:31 [INFO]: Epoch 013 - training loss: 0.1234, validation loss: 0.1921
2024-05-25 03:52:31 [INFO]: Epoch 014 - training loss: 0.1108, validation loss: 0.1854
2024-05-25 03:52:32 [INFO]: Epoch 015 - training loss: 0.1029, validation loss: 0.1906
2024-05-25 03:52:32 [INFO]: Epoch 016 - training loss: 0.1042, validation loss: 0.1905
2024-05-25 03:52:33 [INFO]: Epoch 017 - training loss: 0.0975, validation loss: 0.2007
2024-05-25 03:52:33 [INFO]: Epoch 018 - training loss: 0.0962, validation loss: 0.1938
2024-05-25 03:52:34 [INFO]: Epoch 019 - training loss: 0.0966, validation loss: 0.1918
2024-05-25 03:52:34 [INFO]: Epoch 020 - training loss: 0.1009, validation loss: 0.1975
2024-05-25 03:52:34 [INFO]: Epoch 021 - training loss: 0.0957, validation loss: 0.1970
2024-05-25 03:52:35 [INFO]: Epoch 022 - training loss: 0.0952, validation loss: 0.1933
2024-05-25 03:52:35 [INFO]: Epoch 023 - training loss: 0.0948, validation loss: 0.1933
2024-05-25 03:52:36 [INFO]: Epoch 024 - training loss: 0.0940, validation loss: 0.1941
2024-05-25 03:52:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 03:52:36 [INFO]: Finished training. The best model is from epoch#14.
2024-05-25 03:52:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_air_quality/20240525_T035224/TimesNet.pypots
2024-05-25 03:52:36 [INFO]: TimesNet on Air-Quality: MAE=0.1741, MSE=0.2114
2024-05-25 03:52:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_air_quality/imputation.pkl
2024-05-25 03:52:36 [INFO]: Using the given device: cuda:0
2024-05-25 03:52:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236
2024-05-25 03:52:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/tensorboard
2024-05-25 03:52:36 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 03:52:53 [INFO]: Epoch 001 - training loss: 0.4909, validation loss: 0.3128
2024-05-25 03:52:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch1_loss0.3127602279186249.pypots
2024-05-25 03:53:10 [INFO]: Epoch 002 - training loss: 0.2892, validation loss: 0.2467
2024-05-25 03:53:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch2_loss0.24665433317422866.pypots
2024-05-25 03:53:26 [INFO]: Epoch 003 - training loss: 0.2268, validation loss: 0.2099
2024-05-25 03:53:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch3_loss0.20994002521038055.pypots
2024-05-25 03:53:43 [INFO]: Epoch 004 - training loss: 0.2058, validation loss: 0.1816
2024-05-25 03:53:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch4_loss0.18162945061922073.pypots
2024-05-25 03:54:00 [INFO]: Epoch 005 - training loss: 0.1983, validation loss: 0.1696
2024-05-25 03:54:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch5_loss0.16964617520570754.pypots
2024-05-25 03:54:16 [INFO]: Epoch 006 - training loss: 0.1713, validation loss: 0.1617
2024-05-25 03:54:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch6_loss0.16174301207065583.pypots
2024-05-25 03:54:33 [INFO]: Epoch 007 - training loss: 0.1626, validation loss: 0.1635
2024-05-25 03:54:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch7_loss0.16351705491542817.pypots
2024-05-25 03:54:50 [INFO]: Epoch 008 - training loss: 0.1795, validation loss: 0.1585
2024-05-25 03:54:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch8_loss0.15846795439720154.pypots
2024-05-25 03:55:06 [INFO]: Epoch 009 - training loss: 0.1485, validation loss: 0.1499
2024-05-25 03:55:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch9_loss0.14987466484308243.pypots
2024-05-25 03:55:23 [INFO]: Epoch 010 - training loss: 0.1754, validation loss: 0.1482
2024-05-25 03:55:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch10_loss0.14815061390399933.pypots
2024-05-25 03:55:40 [INFO]: Epoch 011 - training loss: 0.1633, validation loss: 0.1455
2024-05-25 03:55:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch11_loss0.14553904980421067.pypots
2024-05-25 03:55:56 [INFO]: Epoch 012 - training loss: 0.1586, validation loss: 0.1428
2024-05-25 03:55:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch12_loss0.1427663892507553.pypots
2024-05-25 03:56:13 [INFO]: Epoch 013 - training loss: 0.1373, validation loss: 0.1413
2024-05-25 03:56:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch13_loss0.14129640087485312.pypots
2024-05-25 03:56:30 [INFO]: Epoch 014 - training loss: 0.1546, validation loss: 0.1416
2024-05-25 03:56:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch14_loss0.14162770062685012.pypots
2024-05-25 03:56:46 [INFO]: Epoch 015 - training loss: 0.1572, validation loss: 0.1423
2024-05-25 03:56:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch15_loss0.1423051968216896.pypots
2024-05-25 03:57:03 [INFO]: Epoch 016 - training loss: 0.1692, validation loss: 0.1384
2024-05-25 03:57:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch16_loss0.1384260207414627.pypots
2024-05-25 03:57:20 [INFO]: Epoch 017 - training loss: 0.1592, validation loss: 0.1367
2024-05-25 03:57:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch17_loss0.13669246435165405.pypots
2024-05-25 03:57:36 [INFO]: Epoch 018 - training loss: 0.1238, validation loss: 0.1349
2024-05-25 03:57:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch18_loss0.13486750423908234.pypots
2024-05-25 03:57:53 [INFO]: Epoch 019 - training loss: 0.1460, validation loss: 0.1348
2024-05-25 03:57:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch19_loss0.1348087675869465.pypots
2024-05-25 03:58:10 [INFO]: Epoch 020 - training loss: 0.1411, validation loss: 0.1355
2024-05-25 03:58:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch20_loss0.13545570895075798.pypots
2024-05-25 03:58:26 [INFO]: Epoch 021 - training loss: 0.1332, validation loss: 0.1333
2024-05-25 03:58:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch21_loss0.13334094732999802.pypots
2024-05-25 03:58:43 [INFO]: Epoch 022 - training loss: 0.1372, validation loss: 0.1343
2024-05-25 03:58:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch22_loss0.13426999747753143.pypots
2024-05-25 03:59:00 [INFO]: Epoch 023 - training loss: 0.1303, validation loss: 0.1298
2024-05-25 03:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch23_loss0.12979619577527046.pypots
2024-05-25 03:59:16 [INFO]: Epoch 024 - training loss: 0.1319, validation loss: 0.1473
2024-05-25 03:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch24_loss0.14732528924942018.pypots
2024-05-25 03:59:33 [INFO]: Epoch 025 - training loss: 0.1387, validation loss: 0.1341
2024-05-25 03:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch25_loss0.1341009832918644.pypots
2024-05-25 03:59:50 [INFO]: Epoch 026 - training loss: 0.1351, validation loss: 0.1320
2024-05-25 03:59:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch26_loss0.1319616913795471.pypots
2024-05-25 04:00:06 [INFO]: Epoch 027 - training loss: 0.1277, validation loss: 0.1281
2024-05-25 04:00:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch27_loss0.12810660079121589.pypots
2024-05-25 04:00:23 [INFO]: Epoch 028 - training loss: 0.1241, validation loss: 0.1289
2024-05-25 04:00:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch28_loss0.1288764774799347.pypots
2024-05-25 04:00:40 [INFO]: Epoch 029 - training loss: 0.1296, validation loss: 0.1292
2024-05-25 04:00:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch29_loss0.12917688935995103.pypots
2024-05-25 04:00:57 [INFO]: Epoch 030 - training loss: 0.1191, validation loss: 0.1276
2024-05-25 04:00:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch30_loss0.12760347947478295.pypots
2024-05-25 04:01:13 [INFO]: Epoch 031 - training loss: 0.1160, validation loss: 0.1269
2024-05-25 04:01:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch31_loss0.12691297382116318.pypots
2024-05-25 04:01:30 [INFO]: Epoch 032 - training loss: 0.1232, validation loss: 0.1289
2024-05-25 04:01:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch32_loss0.1289094604551792.pypots
2024-05-25 04:01:47 [INFO]: Epoch 033 - training loss: 0.1371, validation loss: 0.1258
2024-05-25 04:01:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch33_loss0.12579607963562012.pypots
2024-05-25 04:02:03 [INFO]: Epoch 034 - training loss: 0.1241, validation loss: 0.1253
2024-05-25 04:02:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch34_loss0.1252752996981144.pypots
2024-05-25 04:02:20 [INFO]: Epoch 035 - training loss: 0.1188, validation loss: 0.1246
2024-05-25 04:02:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch35_loss0.12456595152616501.pypots
2024-05-25 04:02:37 [INFO]: Epoch 036 - training loss: 0.1252, validation loss: 0.1245
2024-05-25 04:02:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch36_loss0.12452006489038467.pypots
2024-05-25 04:02:53 [INFO]: Epoch 037 - training loss: 0.1273, validation loss: 0.1236
2024-05-25 04:02:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch37_loss0.12355353608727455.pypots
2024-05-25 04:03:10 [INFO]: Epoch 038 - training loss: 0.1177, validation loss: 0.1209
2024-05-25 04:03:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch38_loss0.1208730846643448.pypots
2024-05-25 04:03:27 [INFO]: Epoch 039 - training loss: 0.1201, validation loss: 0.1220
2024-05-25 04:03:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch39_loss0.12202833145856858.pypots
2024-05-25 04:03:43 [INFO]: Epoch 040 - training loss: 0.1159, validation loss: 0.1189
2024-05-25 04:03:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch40_loss0.11890294775366783.pypots
2024-05-25 04:04:00 [INFO]: Epoch 041 - training loss: 0.1337, validation loss: 0.1194
2024-05-25 04:04:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch41_loss0.11942196637392044.pypots
2024-05-25 04:04:17 [INFO]: Epoch 042 - training loss: 0.1092, validation loss: 0.1172
2024-05-25 04:04:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch42_loss0.11715956330299378.pypots
2024-05-25 04:04:33 [INFO]: Epoch 043 - training loss: 0.1047, validation loss: 0.1171
2024-05-25 04:04:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch43_loss0.11706725507974625.pypots
2024-05-25 04:04:50 [INFO]: Epoch 044 - training loss: 0.1119, validation loss: 0.1168
2024-05-25 04:04:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch44_loss0.11680538803339005.pypots
2024-05-25 04:05:07 [INFO]: Epoch 045 - training loss: 0.1132, validation loss: 0.1157
2024-05-25 04:05:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch45_loss0.11574320271611213.pypots
2024-05-25 04:05:23 [INFO]: Epoch 046 - training loss: 0.1204, validation loss: 0.1151
2024-05-25 04:05:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch46_loss0.11511723771691322.pypots
2024-05-25 04:05:40 [INFO]: Epoch 047 - training loss: 0.1258, validation loss: 0.1146
2024-05-25 04:05:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch47_loss0.11455662995576858.pypots
2024-05-25 04:05:57 [INFO]: Epoch 048 - training loss: 0.1149, validation loss: 0.1142
2024-05-25 04:05:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch48_loss0.11421300023794174.pypots
2024-05-25 04:06:13 [INFO]: Epoch 049 - training loss: 0.1322, validation loss: 0.1138
2024-05-25 04:06:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch49_loss0.11381570026278495.pypots
2024-05-25 04:06:30 [INFO]: Epoch 050 - training loss: 0.1100, validation loss: 0.1173
2024-05-25 04:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch50_loss0.1173041932284832.pypots
2024-05-25 04:06:47 [INFO]: Epoch 051 - training loss: 0.1163, validation loss: 0.1119
2024-05-25 04:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch51_loss0.11194339171051979.pypots
2024-05-25 04:07:03 [INFO]: Epoch 052 - training loss: 0.1140, validation loss: 0.1127
2024-05-25 04:07:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch52_loss0.11270855367183685.pypots
2024-05-25 04:07:20 [INFO]: Epoch 053 - training loss: 0.1141, validation loss: 0.1115
2024-05-25 04:07:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch53_loss0.11154733151197434.pypots
2024-05-25 04:07:37 [INFO]: Epoch 054 - training loss: 0.1107, validation loss: 0.1109
2024-05-25 04:07:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch54_loss0.11094513311982154.pypots
2024-05-25 04:07:53 [INFO]: Epoch 055 - training loss: 0.1121, validation loss: 0.1113
2024-05-25 04:07:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch55_loss0.11131257712841033.pypots
2024-05-25 04:08:10 [INFO]: Epoch 056 - training loss: 0.1067, validation loss: 0.1125
2024-05-25 04:08:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch56_loss0.11253068447113038.pypots
2024-05-25 04:08:27 [INFO]: Epoch 057 - training loss: 0.1155, validation loss: 0.1106
2024-05-25 04:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch57_loss0.11064694300293923.pypots
2024-05-25 04:08:44 [INFO]: Epoch 058 - training loss: 0.1014, validation loss: 0.1090
2024-05-25 04:08:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch58_loss0.10901507884263992.pypots
2024-05-25 04:09:00 [INFO]: Epoch 059 - training loss: 0.1063, validation loss: 0.1151
2024-05-25 04:09:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch59_loss0.11513662412762642.pypots
2024-05-25 04:09:17 [INFO]: Epoch 060 - training loss: 0.1131, validation loss: 0.1100
2024-05-25 04:09:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch60_loss0.10999395549297333.pypots
2024-05-25 04:09:34 [INFO]: Epoch 061 - training loss: 0.1138, validation loss: 0.1075
2024-05-25 04:09:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch61_loss0.10753366276621819.pypots
2024-05-25 04:09:50 [INFO]: Epoch 062 - training loss: 0.1117, validation loss: 0.1090
2024-05-25 04:09:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch62_loss0.10899196416139603.pypots
2024-05-25 04:10:07 [INFO]: Epoch 063 - training loss: 0.1056, validation loss: 0.1109
2024-05-25 04:10:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch63_loss0.1108773484826088.pypots
2024-05-25 04:10:24 [INFO]: Epoch 064 - training loss: 0.0990, validation loss: 0.1098
2024-05-25 04:10:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch64_loss0.10978342965245247.pypots
2024-05-25 04:10:40 [INFO]: Epoch 065 - training loss: 0.1077, validation loss: 0.1066
2024-05-25 04:10:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch65_loss0.10662236288189889.pypots
2024-05-25 04:10:57 [INFO]: Epoch 066 - training loss: 0.1098, validation loss: 0.1074
2024-05-25 04:10:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch66_loss0.10735148712992668.pypots
2024-05-25 04:11:14 [INFO]: Epoch 067 - training loss: 0.1151, validation loss: 0.1130
2024-05-25 04:11:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch67_loss0.1130299486219883.pypots
2024-05-25 04:11:30 [INFO]: Epoch 068 - training loss: 0.0967, validation loss: 0.1075
2024-05-25 04:11:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch68_loss0.10754576623439789.pypots
2024-05-25 04:11:47 [INFO]: Epoch 069 - training loss: 0.1067, validation loss: 0.1075
2024-05-25 04:11:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch69_loss0.10746326446533203.pypots
2024-05-25 04:12:04 [INFO]: Epoch 070 - training loss: 0.1053, validation loss: 0.1052
2024-05-25 04:12:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch70_loss0.10517521128058434.pypots
2024-05-25 04:12:20 [INFO]: Epoch 071 - training loss: 0.1067, validation loss: 0.1060
2024-05-25 04:12:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch71_loss0.10597787126898765.pypots
2024-05-25 04:12:37 [INFO]: Epoch 072 - training loss: 0.0981, validation loss: 0.1071
2024-05-25 04:12:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch72_loss0.107105952501297.pypots
2024-05-25 04:12:54 [INFO]: Epoch 073 - training loss: 0.1161, validation loss: 0.1112
2024-05-25 04:12:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch73_loss0.1111601434648037.pypots
2024-05-25 04:13:10 [INFO]: Epoch 074 - training loss: 0.1068, validation loss: 0.1119
2024-05-25 04:13:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch74_loss0.11186431348323822.pypots
2024-05-25 04:13:27 [INFO]: Epoch 075 - training loss: 0.1029, validation loss: 0.1068
2024-05-25 04:13:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch75_loss0.10675690993666649.pypots
2024-05-25 04:13:44 [INFO]: Epoch 076 - training loss: 0.1039, validation loss: 0.1052
2024-05-25 04:13:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch76_loss0.10518757477402688.pypots
2024-05-25 04:14:00 [INFO]: Epoch 077 - training loss: 0.1084, validation loss: 0.1062
2024-05-25 04:14:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch77_loss0.1062244400382042.pypots
2024-05-25 04:14:17 [INFO]: Epoch 078 - training loss: 0.1195, validation loss: 0.1051
2024-05-25 04:14:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch78_loss0.10505137965083122.pypots
2024-05-25 04:14:34 [INFO]: Epoch 079 - training loss: 0.1028, validation loss: 0.1042
2024-05-25 04:14:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch79_loss0.10419059023261071.pypots
2024-05-25 04:14:50 [INFO]: Epoch 080 - training loss: 0.1079, validation loss: 0.1057
2024-05-25 04:14:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch80_loss0.10571234673261642.pypots
2024-05-25 04:15:07 [INFO]: Epoch 081 - training loss: 0.0889, validation loss: 0.1063
2024-05-25 04:15:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch81_loss0.10633105263113976.pypots
2024-05-25 04:15:24 [INFO]: Epoch 082 - training loss: 0.0981, validation loss: 0.1048
2024-05-25 04:15:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch82_loss0.10480783358216286.pypots
2024-05-25 04:15:40 [INFO]: Epoch 083 - training loss: 0.1029, validation loss: 0.1042
2024-05-25 04:15:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch83_loss0.10422199293971061.pypots
2024-05-25 04:15:57 [INFO]: Epoch 084 - training loss: 0.0987, validation loss: 0.1057
2024-05-25 04:15:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch84_loss0.10565026178956032.pypots
2024-05-25 04:16:14 [INFO]: Epoch 085 - training loss: 0.1151, validation loss: 0.1085
2024-05-25 04:16:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch85_loss0.10850912556052209.pypots
2024-05-25 04:16:30 [INFO]: Epoch 086 - training loss: 0.1082, validation loss: 0.1056
2024-05-25 04:16:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch86_loss0.10560848191380501.pypots
2024-05-25 04:16:47 [INFO]: Epoch 087 - training loss: 0.1073, validation loss: 0.1033
2024-05-25 04:16:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch87_loss0.1033481553196907.pypots
2024-05-25 04:17:04 [INFO]: Epoch 088 - training loss: 0.1038, validation loss: 0.1044
2024-05-25 04:17:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch88_loss0.10437292009592056.pypots
2024-05-25 04:17:20 [INFO]: Epoch 089 - training loss: 0.1041, validation loss: 0.1030
2024-05-25 04:17:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch89_loss0.10302848741412163.pypots
2024-05-25 04:17:37 [INFO]: Epoch 090 - training loss: 0.1098, validation loss: 0.1052
2024-05-25 04:17:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch90_loss0.10523006319999695.pypots
2024-05-25 04:17:54 [INFO]: Epoch 091 - training loss: 0.1034, validation loss: 0.1043
2024-05-25 04:17:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch91_loss0.10432901531457901.pypots
2024-05-25 04:18:11 [INFO]: Epoch 092 - training loss: 0.0973, validation loss: 0.1054
2024-05-25 04:18:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch92_loss0.1054002545773983.pypots
2024-05-25 04:18:27 [INFO]: Epoch 093 - training loss: 0.0941, validation loss: 0.1035
2024-05-25 04:18:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch93_loss0.10348435044288636.pypots
2024-05-25 04:18:44 [INFO]: Epoch 094 - training loss: 0.0932, validation loss: 0.1060
2024-05-25 04:18:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch94_loss0.10598950684070588.pypots
2024-05-25 04:19:01 [INFO]: Epoch 095 - training loss: 0.1022, validation loss: 0.1034
2024-05-25 04:19:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch95_loss0.10343703180551529.pypots
2024-05-25 04:19:17 [INFO]: Epoch 096 - training loss: 0.1043, validation loss: 0.1043
2024-05-25 04:19:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch96_loss0.104331836104393.pypots
2024-05-25 04:19:34 [INFO]: Epoch 097 - training loss: 0.0915, validation loss: 0.1016
2024-05-25 04:19:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch97_loss0.101556695997715.pypots
2024-05-25 04:19:51 [INFO]: Epoch 098 - training loss: 0.0988, validation loss: 0.1026
2024-05-25 04:19:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch98_loss0.10262696593999862.pypots
2024-05-25 04:20:07 [INFO]: Epoch 099 - training loss: 0.1030, validation loss: 0.1035
2024-05-25 04:20:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch99_loss0.10351579934358597.pypots
2024-05-25 04:20:24 [INFO]: Epoch 100 - training loss: 0.0911, validation loss: 0.1033
2024-05-25 04:20:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch100_loss0.10327075868844986.pypots
2024-05-25 04:20:41 [INFO]: Epoch 101 - training loss: 0.0998, validation loss: 0.1022
2024-05-25 04:20:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch101_loss0.10220943316817284.pypots
2024-05-25 04:20:57 [INFO]: Epoch 102 - training loss: 0.1042, validation loss: 0.1028
2024-05-25 04:20:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch102_loss0.10280195623636246.pypots
2024-05-25 04:21:14 [INFO]: Epoch 103 - training loss: 0.0944, validation loss: 0.1046
2024-05-25 04:21:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch103_loss0.10460200607776642.pypots
2024-05-25 04:21:31 [INFO]: Epoch 104 - training loss: 0.0944, validation loss: 0.1039
2024-05-25 04:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch104_loss0.1039087601006031.pypots
2024-05-25 04:21:47 [INFO]: Epoch 105 - training loss: 0.1020, validation loss: 0.1055
2024-05-25 04:21:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch105_loss0.10550250634551048.pypots
2024-05-25 04:22:04 [INFO]: Epoch 106 - training loss: 0.1061, validation loss: 0.1027
2024-05-25 04:22:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch106_loss0.10270754843950272.pypots
2024-05-25 04:22:21 [INFO]: Epoch 107 - training loss: 0.0991, validation loss: 0.1041
2024-05-25 04:22:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI_epoch107_loss0.10414104387164116.pypots
2024-05-25 04:22:21 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:22:21 [INFO]: Finished training. The best model is from epoch#97.
2024-05-25 04:22:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_air_quality/20240525_T035236/CSDI.pypots
2024-05-25 04:24:41 [INFO]: CSDI on Air-Quality: MAE=0.1033, MSE=0.1280
2024-05-25 04:24:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_air_quality/imputation.pkl
2024-05-25 04:24:41 [INFO]: Using the given device: cuda:0
2024-05-25 04:24:41 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240525_T042441
2024-05-25 04:24:41 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240525_T042441/tensorboard
2024-05-25 04:24:41 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 04:24:41 [INFO]: Epoch 001 - training loss: 64965.1832, validation loss: 0.6539
2024-05-25 04:24:42 [INFO]: Epoch 002 - training loss: 41566.5709, validation loss: 0.6312
2024-05-25 04:24:42 [INFO]: Epoch 003 - training loss: 41215.3854, validation loss: 0.5617
2024-05-25 04:24:42 [INFO]: Epoch 004 - training loss: 41099.2538, validation loss: 0.5430
2024-05-25 04:24:43 [INFO]: Epoch 005 - training loss: 40989.3524, validation loss: 0.4737
2024-05-25 04:24:43 [INFO]: Epoch 006 - training loss: 40923.3653, validation loss: 0.4550
2024-05-25 04:24:43 [INFO]: Epoch 007 - training loss: 40868.7441, validation loss: 0.4718
2024-05-25 04:24:44 [INFO]: Epoch 008 - training loss: 40852.8469, validation loss: 0.4228
2024-05-25 04:24:44 [INFO]: Epoch 009 - training loss: 40813.3792, validation loss: 0.3919
2024-05-25 04:24:44 [INFO]: Epoch 010 - training loss: 40784.9886, validation loss: 0.3623
2024-05-25 04:24:45 [INFO]: Epoch 011 - training loss: 40771.4818, validation loss: 0.3748
2024-05-25 04:24:45 [INFO]: Epoch 012 - training loss: 40757.5650, validation loss: 0.3393
2024-05-25 04:24:45 [INFO]: Epoch 013 - training loss: 40725.8741, validation loss: 0.3588
2024-05-25 04:24:46 [INFO]: Epoch 014 - training loss: 40731.7616, validation loss: 0.3475
2024-05-25 04:24:46 [INFO]: Epoch 015 - training loss: 40710.6357, validation loss: 0.3298
2024-05-25 04:24:46 [INFO]: Epoch 016 - training loss: 40687.6499, validation loss: 0.3177
2024-05-25 04:24:47 [INFO]: Epoch 017 - training loss: 40683.5877, validation loss: 0.3171
2024-05-25 04:24:47 [INFO]: Epoch 018 - training loss: 40677.0386, validation loss: 0.3198
2024-05-25 04:24:47 [INFO]: Epoch 019 - training loss: 40697.0606, validation loss: 0.3161
2024-05-25 04:24:48 [INFO]: Epoch 020 - training loss: 40656.0890, validation loss: 0.3154
2024-05-25 04:24:48 [INFO]: Epoch 021 - training loss: 40659.7645, validation loss: 0.3181
2024-05-25 04:24:48 [INFO]: Epoch 022 - training loss: 40654.8424, validation loss: 0.3038
2024-05-25 04:24:48 [INFO]: Epoch 023 - training loss: 40651.7093, validation loss: 0.3010
2024-05-25 04:24:49 [INFO]: Epoch 024 - training loss: 40649.4608, validation loss: 0.3022
2024-05-25 04:24:49 [INFO]: Epoch 025 - training loss: 40634.7027, validation loss: 0.2840
2024-05-25 04:24:49 [INFO]: Epoch 026 - training loss: 40636.0666, validation loss: 0.2893
2024-05-25 04:24:50 [INFO]: Epoch 027 - training loss: 40646.0684, validation loss: 0.3234
2024-05-25 04:24:50 [INFO]: Epoch 028 - training loss: 40634.8417, validation loss: 0.2916
2024-05-25 04:24:50 [INFO]: Epoch 029 - training loss: 40611.3190, validation loss: 0.2801
2024-05-25 04:24:51 [INFO]: Epoch 030 - training loss: 40604.9928, validation loss: 0.2732
2024-05-25 04:24:51 [INFO]: Epoch 031 - training loss: 40599.0924, validation loss: 0.2722
2024-05-25 04:24:51 [INFO]: Epoch 032 - training loss: 40602.6359, validation loss: 0.2708
2024-05-25 04:24:52 [INFO]: Epoch 033 - training loss: 40592.4567, validation loss: 0.2682
2024-05-25 04:24:52 [INFO]: Epoch 034 - training loss: 40599.6694, validation loss: 0.2726
2024-05-25 04:24:52 [INFO]: Epoch 035 - training loss: 40595.7137, validation loss: 0.2648
2024-05-25 04:24:53 [INFO]: Epoch 036 - training loss: 40587.2082, validation loss: 0.2744
2024-05-25 04:24:53 [INFO]: Epoch 037 - training loss: 40611.1843, validation loss: 0.3211
2024-05-25 04:24:53 [INFO]: Epoch 038 - training loss: 40639.9120, validation loss: 0.3032
2024-05-25 04:24:54 [INFO]: Epoch 039 - training loss: 40603.4096, validation loss: 0.2756
2024-05-25 04:24:54 [INFO]: Epoch 040 - training loss: 40585.9732, validation loss: 0.2627
2024-05-25 04:24:54 [INFO]: Epoch 041 - training loss: 40574.9744, validation loss: 0.2577
2024-05-25 04:24:55 [INFO]: Epoch 042 - training loss: 40574.3507, validation loss: 0.2639
2024-05-25 04:24:55 [INFO]: Epoch 043 - training loss: 40570.0401, validation loss: 0.2532
2024-05-25 04:24:55 [INFO]: Epoch 044 - training loss: 40570.8785, validation loss: 0.2653
2024-05-25 04:24:56 [INFO]: Epoch 045 - training loss: 40564.7344, validation loss: 0.2564
2024-05-25 04:24:56 [INFO]: Epoch 046 - training loss: 40581.5632, validation loss: 0.2664
2024-05-25 04:24:56 [INFO]: Epoch 047 - training loss: 40609.1340, validation loss: 0.3048
2024-05-25 04:24:57 [INFO]: Epoch 048 - training loss: 40636.9376, validation loss: 0.2693
2024-05-25 04:24:57 [INFO]: Epoch 049 - training loss: 40605.8003, validation loss: 0.2755
2024-05-25 04:24:57 [INFO]: Epoch 050 - training loss: 40611.5020, validation loss: 0.2969
2024-05-25 04:24:58 [INFO]: Epoch 051 - training loss: 40610.8492, validation loss: 0.2675
2024-05-25 04:24:58 [INFO]: Epoch 052 - training loss: 40575.2729, validation loss: 0.2613
2024-05-25 04:24:58 [INFO]: Epoch 053 - training loss: 40572.7752, validation loss: 0.2541
2024-05-25 04:24:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:24:58 [INFO]: Finished training. The best model is from epoch#43.
2024-05-25 04:24:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_air_quality/20240525_T042441/GPVAE.pypots
2024-05-25 04:24:58 [INFO]: GP-VAE on Air-Quality: MAE=0.2838, MSE=0.2680
2024-05-25 04:24:58 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_air_quality/imputation.pkl
2024-05-25 04:24:58 [INFO]: Using the given device: cuda:0
2024-05-25 04:24:58 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240525_T042458
2024-05-25 04:24:58 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240525_T042458/tensorboard
2024-05-25 04:24:58 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 04:25:03 [INFO]: Epoch 001 - generator training loss: 0.3586, discriminator training loss: 0.5671, validation loss: 0.5588
2024-05-25 04:25:07 [INFO]: Epoch 002 - generator training loss: 0.0396, discriminator training loss: 0.5237, validation loss: 0.4223
2024-05-25 04:25:12 [INFO]: Epoch 003 - generator training loss: -0.0299, discriminator training loss: 0.5186, validation loss: 0.3538
2024-05-25 04:25:16 [INFO]: Epoch 004 - generator training loss: -0.0699, discriminator training loss: 0.5144, validation loss: 0.3096
2024-05-25 04:25:20 [INFO]: Epoch 005 - generator training loss: -0.0922, discriminator training loss: 0.5099, validation loss: 0.2805
2024-05-25 04:25:24 [INFO]: Epoch 006 - generator training loss: -0.1100, discriminator training loss: 0.5045, validation loss: 0.2581
2024-05-25 04:25:28 [INFO]: Epoch 007 - generator training loss: -0.1213, discriminator training loss: 0.4984, validation loss: 0.2428
2024-05-25 04:25:32 [INFO]: Epoch 008 - generator training loss: -0.1284, discriminator training loss: 0.4910, validation loss: 0.2304
2024-05-25 04:25:36 [INFO]: Epoch 009 - generator training loss: -0.1318, discriminator training loss: 0.4823, validation loss: 0.2216
2024-05-25 04:25:40 [INFO]: Epoch 010 - generator training loss: -0.1281, discriminator training loss: 0.4728, validation loss: 0.2140
2024-05-25 04:25:44 [INFO]: Epoch 011 - generator training loss: -0.1312, discriminator training loss: 0.4627, validation loss: 0.2074
2024-05-25 04:25:49 [INFO]: Epoch 012 - generator training loss: -0.1300, discriminator training loss: 0.4520, validation loss: 0.2020
2024-05-25 04:25:53 [INFO]: Epoch 013 - generator training loss: -0.1273, discriminator training loss: 0.4416, validation loss: 0.1969
2024-05-25 04:25:57 [INFO]: Epoch 014 - generator training loss: -0.1237, discriminator training loss: 0.4312, validation loss: 0.1929
2024-05-25 04:26:01 [INFO]: Epoch 015 - generator training loss: -0.1211, discriminator training loss: 0.4213, validation loss: 0.1898
2024-05-25 04:26:05 [INFO]: Epoch 016 - generator training loss: -0.1179, discriminator training loss: 0.4122, validation loss: 0.1867
2024-05-25 04:26:09 [INFO]: Epoch 017 - generator training loss: -0.1155, discriminator training loss: 0.4032, validation loss: 0.1838
2024-05-25 04:26:13 [INFO]: Epoch 018 - generator training loss: -0.1121, discriminator training loss: 0.3949, validation loss: 0.1806
2024-05-25 04:26:17 [INFO]: Epoch 019 - generator training loss: -0.1103, discriminator training loss: 0.3876, validation loss: 0.1779
2024-05-25 04:26:22 [INFO]: Epoch 020 - generator training loss: -0.1078, discriminator training loss: 0.3806, validation loss: 0.1755
2024-05-25 04:26:26 [INFO]: Epoch 021 - generator training loss: -0.1063, discriminator training loss: 0.3741, validation loss: 0.1731
2024-05-25 04:26:30 [INFO]: Epoch 022 - generator training loss: -0.1054, discriminator training loss: 0.3686, validation loss: 0.1703
2024-05-25 04:26:34 [INFO]: Epoch 023 - generator training loss: -0.1035, discriminator training loss: 0.3635, validation loss: 0.1684
2024-05-25 04:26:38 [INFO]: Epoch 024 - generator training loss: -0.1027, discriminator training loss: 0.3584, validation loss: 0.1666
2024-05-25 04:26:42 [INFO]: Epoch 025 - generator training loss: -0.1007, discriminator training loss: 0.3541, validation loss: 0.1648
2024-05-25 04:26:46 [INFO]: Epoch 026 - generator training loss: -0.1016, discriminator training loss: 0.3506, validation loss: 0.1634
2024-05-25 04:26:50 [INFO]: Epoch 027 - generator training loss: -0.0997, discriminator training loss: 0.3462, validation loss: 0.1620
2024-05-25 04:26:55 [INFO]: Epoch 028 - generator training loss: -0.1005, discriminator training loss: 0.3433, validation loss: 0.1607
2024-05-25 04:26:59 [INFO]: Epoch 029 - generator training loss: -0.1006, discriminator training loss: 0.3402, validation loss: 0.1593
2024-05-25 04:27:03 [INFO]: Epoch 030 - generator training loss: -0.0998, discriminator training loss: 0.3374, validation loss: 0.1579
2024-05-25 04:27:07 [INFO]: Epoch 031 - generator training loss: -0.0996, discriminator training loss: 0.3348, validation loss: 0.1562
2024-05-25 04:27:11 [INFO]: Epoch 032 - generator training loss: -0.0994, discriminator training loss: 0.3328, validation loss: 0.1552
2024-05-25 04:27:15 [INFO]: Epoch 033 - generator training loss: -0.0995, discriminator training loss: 0.3308, validation loss: 0.1541
2024-05-25 04:27:19 [INFO]: Epoch 034 - generator training loss: -0.0996, discriminator training loss: 0.3288, validation loss: 0.1529
2024-05-25 04:27:23 [INFO]: Epoch 035 - generator training loss: -0.0997, discriminator training loss: 0.3269, validation loss: 0.1520
2024-05-25 04:27:28 [INFO]: Epoch 036 - generator training loss: -0.0992, discriminator training loss: 0.3254, validation loss: 0.1506
2024-05-25 04:27:32 [INFO]: Epoch 037 - generator training loss: -0.0985, discriminator training loss: 0.3239, validation loss: 0.1504
2024-05-25 04:27:36 [INFO]: Epoch 038 - generator training loss: -0.1001, discriminator training loss: 0.3230, validation loss: 0.1489
2024-05-25 04:27:40 [INFO]: Epoch 039 - generator training loss: -0.0999, discriminator training loss: 0.3219, validation loss: 0.1477
2024-05-25 04:27:44 [INFO]: Epoch 040 - generator training loss: -0.0999, discriminator training loss: 0.3204, validation loss: 0.1471
2024-05-25 04:27:48 [INFO]: Epoch 041 - generator training loss: -0.1002, discriminator training loss: 0.3194, validation loss: 0.1458
2024-05-25 04:27:52 [INFO]: Epoch 042 - generator training loss: -0.1017, discriminator training loss: 0.3186, validation loss: 0.1451
2024-05-25 04:27:56 [INFO]: Epoch 043 - generator training loss: -0.1013, discriminator training loss: 0.3176, validation loss: 0.1446
2024-05-25 04:28:00 [INFO]: Epoch 044 - generator training loss: -0.1021, discriminator training loss: 0.3167, validation loss: 0.1432
2024-05-25 04:28:05 [INFO]: Epoch 045 - generator training loss: -0.1027, discriminator training loss: 0.3160, validation loss: 0.1430
2024-05-25 04:28:09 [INFO]: Epoch 046 - generator training loss: -0.1028, discriminator training loss: 0.3148, validation loss: 0.1417
2024-05-25 04:28:13 [INFO]: Epoch 047 - generator training loss: -0.1023, discriminator training loss: 0.3144, validation loss: 0.1415
2024-05-25 04:28:17 [INFO]: Epoch 048 - generator training loss: -0.1040, discriminator training loss: 0.3140, validation loss: 0.1406
2024-05-25 04:28:21 [INFO]: Epoch 049 - generator training loss: -0.1039, discriminator training loss: 0.3133, validation loss: 0.1390
2024-05-25 04:28:25 [INFO]: Epoch 050 - generator training loss: -0.1045, discriminator training loss: 0.3122, validation loss: 0.1399
2024-05-25 04:28:29 [INFO]: Epoch 051 - generator training loss: -0.1053, discriminator training loss: 0.3124, validation loss: 0.1378
2024-05-25 04:28:34 [INFO]: Epoch 052 - generator training loss: -0.1050, discriminator training loss: 0.3122, validation loss: 0.1383
2024-05-25 04:28:38 [INFO]: Epoch 053 - generator training loss: -0.1053, discriminator training loss: 0.3116, validation loss: 0.1369
2024-05-25 04:28:42 [INFO]: Epoch 054 - generator training loss: -0.1062, discriminator training loss: 0.3114, validation loss: 0.1363
2024-05-25 04:28:46 [INFO]: Epoch 055 - generator training loss: -0.1065, discriminator training loss: 0.3108, validation loss: 0.1364
2024-05-25 04:28:50 [INFO]: Epoch 056 - generator training loss: -0.1063, discriminator training loss: 0.3104, validation loss: 0.1356
2024-05-25 04:28:54 [INFO]: Epoch 057 - generator training loss: -0.1075, discriminator training loss: 0.3097, validation loss: 0.1351
2024-05-25 04:28:58 [INFO]: Epoch 058 - generator training loss: -0.1086, discriminator training loss: 0.3097, validation loss: 0.1345
2024-05-25 04:29:02 [INFO]: Epoch 059 - generator training loss: -0.1076, discriminator training loss: 0.3093, validation loss: 0.1347
2024-05-25 04:29:06 [INFO]: Epoch 060 - generator training loss: -0.1097, discriminator training loss: 0.3086, validation loss: 0.1332
2024-05-25 04:29:11 [INFO]: Epoch 061 - generator training loss: -0.1099, discriminator training loss: 0.3087, validation loss: 0.1333
2024-05-25 04:29:15 [INFO]: Epoch 062 - generator training loss: -0.1087, discriminator training loss: 0.3081, validation loss: 0.1334
2024-05-25 04:29:19 [INFO]: Epoch 063 - generator training loss: -0.1094, discriminator training loss: 0.3077, validation loss: 0.1324
2024-05-25 04:29:23 [INFO]: Epoch 064 - generator training loss: -0.1103, discriminator training loss: 0.3076, validation loss: 0.1321
2024-05-25 04:29:27 [INFO]: Epoch 065 - generator training loss: -0.1102, discriminator training loss: 0.3070, validation loss: 0.1317
2024-05-25 04:29:31 [INFO]: Epoch 066 - generator training loss: -0.1109, discriminator training loss: 0.3072, validation loss: 0.1316
2024-05-25 04:29:35 [INFO]: Epoch 067 - generator training loss: -0.1103, discriminator training loss: 0.3073, validation loss: 0.1315
2024-05-25 04:29:39 [INFO]: Epoch 068 - generator training loss: -0.1117, discriminator training loss: 0.3066, validation loss: 0.1298
2024-05-25 04:29:44 [INFO]: Epoch 069 - generator training loss: -0.1125, discriminator training loss: 0.3065, validation loss: 0.1307
2024-05-25 04:29:48 [INFO]: Epoch 070 - generator training loss: -0.1124, discriminator training loss: 0.3061, validation loss: 0.1305
2024-05-25 04:29:52 [INFO]: Epoch 071 - generator training loss: -0.1130, discriminator training loss: 0.3063, validation loss: 0.1300
2024-05-25 04:29:56 [INFO]: Epoch 072 - generator training loss: -0.1132, discriminator training loss: 0.3059, validation loss: 0.1298
2024-05-25 04:30:00 [INFO]: Epoch 073 - generator training loss: -0.1133, discriminator training loss: 0.3057, validation loss: 0.1294
2024-05-25 04:30:04 [INFO]: Epoch 074 - generator training loss: -0.1136, discriminator training loss: 0.3055, validation loss: 0.1291
2024-05-25 04:30:08 [INFO]: Epoch 075 - generator training loss: -0.1136, discriminator training loss: 0.3051, validation loss: 0.1292
2024-05-25 04:30:12 [INFO]: Epoch 076 - generator training loss: -0.1143, discriminator training loss: 0.3052, validation loss: 0.1279
2024-05-25 04:30:16 [INFO]: Epoch 077 - generator training loss: -0.1152, discriminator training loss: 0.3045, validation loss: 0.1285
2024-05-25 04:30:21 [INFO]: Epoch 078 - generator training loss: -0.1158, discriminator training loss: 0.3048, validation loss: 0.1277
2024-05-25 04:30:25 [INFO]: Epoch 079 - generator training loss: -0.1154, discriminator training loss: 0.3044, validation loss: 0.1280
2024-05-25 04:30:29 [INFO]: Epoch 080 - generator training loss: -0.1164, discriminator training loss: 0.3042, validation loss: 0.1282
2024-05-25 04:30:33 [INFO]: Epoch 081 - generator training loss: -0.1164, discriminator training loss: 0.3045, validation loss: 0.1278
2024-05-25 04:30:37 [INFO]: Epoch 082 - generator training loss: -0.1156, discriminator training loss: 0.3036, validation loss: 0.1275
2024-05-25 04:30:41 [INFO]: Epoch 083 - generator training loss: -0.1169, discriminator training loss: 0.3039, validation loss: 0.1274
2024-05-25 04:30:45 [INFO]: Epoch 084 - generator training loss: -0.1171, discriminator training loss: 0.3035, validation loss: 0.1267
2024-05-25 04:30:50 [INFO]: Epoch 085 - generator training loss: -0.1172, discriminator training loss: 0.3037, validation loss: 0.1267
2024-05-25 04:30:54 [INFO]: Epoch 086 - generator training loss: -0.1169, discriminator training loss: 0.3028, validation loss: 0.1274
2024-05-25 04:30:58 [INFO]: Epoch 087 - generator training loss: -0.1183, discriminator training loss: 0.3031, validation loss: 0.1270
2024-05-25 04:31:02 [INFO]: Epoch 088 - generator training loss: -0.1176, discriminator training loss: 0.3030, validation loss: 0.1263
2024-05-25 04:31:06 [INFO]: Epoch 089 - generator training loss: -0.1177, discriminator training loss: 0.3024, validation loss: 0.1270
2024-05-25 04:31:10 [INFO]: Epoch 090 - generator training loss: -0.1187, discriminator training loss: 0.3027, validation loss: 0.1269
2024-05-25 04:31:14 [INFO]: Epoch 091 - generator training loss: -0.1185, discriminator training loss: 0.3023, validation loss: 0.1275
2024-05-25 04:31:18 [INFO]: Epoch 092 - generator training loss: -0.1189, discriminator training loss: 0.3023, validation loss: 0.1261
2024-05-25 04:31:22 [INFO]: Epoch 093 - generator training loss: -0.1184, discriminator training loss: 0.3023, validation loss: 0.1268
2024-05-25 04:31:27 [INFO]: Epoch 094 - generator training loss: -0.1190, discriminator training loss: 0.3019, validation loss: 0.1256
2024-05-25 04:31:31 [INFO]: Epoch 095 - generator training loss: -0.1197, discriminator training loss: 0.3025, validation loss: 0.1260
2024-05-25 04:31:35 [INFO]: Epoch 096 - generator training loss: -0.1191, discriminator training loss: 0.3021, validation loss: 0.1265
2024-05-25 04:31:39 [INFO]: Epoch 097 - generator training loss: -0.1205, discriminator training loss: 0.3015, validation loss: 0.1263
2024-05-25 04:31:43 [INFO]: Epoch 098 - generator training loss: -0.1205, discriminator training loss: 0.3015, validation loss: 0.1252
2024-05-25 04:31:47 [INFO]: Epoch 099 - generator training loss: -0.1197, discriminator training loss: 0.3011, validation loss: 0.1259
2024-05-25 04:31:51 [INFO]: Epoch 100 - generator training loss: -0.1193, discriminator training loss: 0.3010, validation loss: 0.1257
2024-05-25 04:31:55 [INFO]: Epoch 101 - generator training loss: -0.1203, discriminator training loss: 0.3019, validation loss: 0.1256
2024-05-25 04:32:00 [INFO]: Epoch 102 - generator training loss: -0.1205, discriminator training loss: 0.3008, validation loss: 0.1254
2024-05-25 04:32:04 [INFO]: Epoch 103 - generator training loss: -0.1206, discriminator training loss: 0.3011, validation loss: 0.1261
2024-05-25 04:32:08 [INFO]: Epoch 104 - generator training loss: -0.1209, discriminator training loss: 0.3008, validation loss: 0.1253
2024-05-25 04:32:12 [INFO]: Epoch 105 - generator training loss: -0.1214, discriminator training loss: 0.3013, validation loss: 0.1250
2024-05-25 04:32:16 [INFO]: Epoch 106 - generator training loss: -0.1218, discriminator training loss: 0.3005, validation loss: 0.1252
2024-05-25 04:32:20 [INFO]: Epoch 107 - generator training loss: -0.1212, discriminator training loss: 0.3011, validation loss: 0.1258
2024-05-25 04:32:24 [INFO]: Epoch 108 - generator training loss: -0.1210, discriminator training loss: 0.3000, validation loss: 0.1250
2024-05-25 04:32:28 [INFO]: Epoch 109 - generator training loss: -0.1213, discriminator training loss: 0.3006, validation loss: 0.1251
2024-05-25 04:32:33 [INFO]: Epoch 110 - generator training loss: -0.1224, discriminator training loss: 0.3004, validation loss: 0.1248
2024-05-25 04:32:37 [INFO]: Epoch 111 - generator training loss: -0.1228, discriminator training loss: 0.3003, validation loss: 0.1245
2024-05-25 04:32:41 [INFO]: Epoch 112 - generator training loss: -0.1222, discriminator training loss: 0.2992, validation loss: 0.1244
2024-05-25 04:32:45 [INFO]: Epoch 113 - generator training loss: -0.1226, discriminator training loss: 0.2996, validation loss: 0.1252
2024-05-25 04:32:49 [INFO]: Epoch 114 - generator training loss: -0.1224, discriminator training loss: 0.2996, validation loss: 0.1249
2024-05-25 04:32:53 [INFO]: Epoch 115 - generator training loss: -0.1221, discriminator training loss: 0.2996, validation loss: 0.1245
2024-05-25 04:32:57 [INFO]: Epoch 116 - generator training loss: -0.1232, discriminator training loss: 0.2996, validation loss: 0.1245
2024-05-25 04:33:01 [INFO]: Epoch 117 - generator training loss: -0.1239, discriminator training loss: 0.2992, validation loss: 0.1242
2024-05-25 04:33:06 [INFO]: Epoch 118 - generator training loss: -0.1235, discriminator training loss: 0.2996, validation loss: 0.1251
2024-05-25 04:33:10 [INFO]: Epoch 119 - generator training loss: -0.1239, discriminator training loss: 0.2990, validation loss: 0.1244
2024-05-25 04:33:14 [INFO]: Epoch 120 - generator training loss: -0.1236, discriminator training loss: 0.2991, validation loss: 0.1250
2024-05-25 04:33:18 [INFO]: Epoch 121 - generator training loss: -0.1242, discriminator training loss: 0.2987, validation loss: 0.1246
2024-05-25 04:33:22 [INFO]: Epoch 122 - generator training loss: -0.1245, discriminator training loss: 0.2985, validation loss: 0.1245
2024-05-25 04:33:26 [INFO]: Epoch 123 - generator training loss: -0.1240, discriminator training loss: 0.2988, validation loss: 0.1253
2024-05-25 04:33:30 [INFO]: Epoch 124 - generator training loss: -0.1240, discriminator training loss: 0.2984, validation loss: 0.1239
2024-05-25 04:33:34 [INFO]: Epoch 125 - generator training loss: -0.1248, discriminator training loss: 0.2989, validation loss: 0.1244
2024-05-25 04:33:38 [INFO]: Epoch 126 - generator training loss: -0.1248, discriminator training loss: 0.2989, validation loss: 0.1242
2024-05-25 04:33:43 [INFO]: Epoch 127 - generator training loss: -0.1245, discriminator training loss: 0.2982, validation loss: 0.1242
2024-05-25 04:33:47 [INFO]: Epoch 128 - generator training loss: -0.1242, discriminator training loss: 0.2983, validation loss: 0.1236
2024-05-25 04:33:51 [INFO]: Epoch 129 - generator training loss: -0.1248, discriminator training loss: 0.2983, validation loss: 0.1237
2024-05-25 04:33:55 [INFO]: Epoch 130 - generator training loss: -0.1248, discriminator training loss: 0.2983, validation loss: 0.1239
2024-05-25 04:33:59 [INFO]: Epoch 131 - generator training loss: -0.1263, discriminator training loss: 0.2982, validation loss: 0.1232
2024-05-25 04:34:03 [INFO]: Epoch 132 - generator training loss: -0.1253, discriminator training loss: 0.2980, validation loss: 0.1242
2024-05-25 04:34:07 [INFO]: Epoch 133 - generator training loss: -0.1252, discriminator training loss: 0.2978, validation loss: 0.1242
2024-05-25 04:34:12 [INFO]: Epoch 134 - generator training loss: -0.1261, discriminator training loss: 0.2972, validation loss: 0.1239
2024-05-25 04:34:16 [INFO]: Epoch 135 - generator training loss: -0.1260, discriminator training loss: 0.2970, validation loss: 0.1232
2024-05-25 04:34:20 [INFO]: Epoch 136 - generator training loss: -0.1259, discriminator training loss: 0.2970, validation loss: 0.1245
2024-05-25 04:34:24 [INFO]: Epoch 137 - generator training loss: -0.1260, discriminator training loss: 0.2968, validation loss: 0.1242
2024-05-25 04:34:28 [INFO]: Epoch 138 - generator training loss: -0.1269, discriminator training loss: 0.2968, validation loss: 0.1237
2024-05-25 04:34:32 [INFO]: Epoch 139 - generator training loss: -0.1269, discriminator training loss: 0.2969, validation loss: 0.1231
2024-05-25 04:34:36 [INFO]: Epoch 140 - generator training loss: -0.1267, discriminator training loss: 0.2969, validation loss: 0.1241
2024-05-25 04:34:40 [INFO]: Epoch 141 - generator training loss: -0.1271, discriminator training loss: 0.2971, validation loss: 0.1236
2024-05-25 04:34:44 [INFO]: Epoch 142 - generator training loss: -0.1276, discriminator training loss: 0.2967, validation loss: 0.1236
2024-05-25 04:34:49 [INFO]: Epoch 143 - generator training loss: -0.1265, discriminator training loss: 0.2965, validation loss: 0.1234
2024-05-25 04:34:53 [INFO]: Epoch 144 - generator training loss: -0.1268, discriminator training loss: 0.2968, validation loss: 0.1234
2024-05-25 04:34:57 [INFO]: Epoch 145 - generator training loss: -0.1271, discriminator training loss: 0.2968, validation loss: 0.1236
2024-05-25 04:35:01 [INFO]: Epoch 146 - generator training loss: -0.1276, discriminator training loss: 0.2960, validation loss: 0.1236
2024-05-25 04:35:05 [INFO]: Epoch 147 - generator training loss: -0.1264, discriminator training loss: 0.2963, validation loss: 0.1247
2024-05-25 04:35:09 [INFO]: Epoch 148 - generator training loss: -0.1274, discriminator training loss: 0.2964, validation loss: 0.1238
2024-05-25 04:35:13 [INFO]: Epoch 149 - generator training loss: -0.1261, discriminator training loss: 0.2966, validation loss: 0.1241
2024-05-25 04:35:13 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:35:13 [INFO]: Finished training. The best model is from epoch#139.
2024-05-25 04:35:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_air_quality/20240525_T042458/USGAN.pypots
2024-05-25 04:35:14 [INFO]: US-GAN on Air-Quality: MAE=0.1635, MSE=0.1297
2024-05-25 04:35:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_air_quality/imputation.pkl
2024-05-25 04:35:14 [INFO]: Using the given device: cuda:0
2024-05-25 04:35:14 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240525_T043514
2024-05-25 04:35:14 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240525_T043514/tensorboard
2024-05-25 04:35:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 04:35:18 [INFO]: Epoch 001 - training loss: 1.3942, validation loss: 0.9668
2024-05-25 04:35:20 [INFO]: Epoch 002 - training loss: 1.1421, validation loss: 0.7256
2024-05-25 04:35:23 [INFO]: Epoch 003 - training loss: 0.9482, validation loss: 0.6124
2024-05-25 04:35:26 [INFO]: Epoch 004 - training loss: 0.8409, validation loss: 0.5449
2024-05-25 04:35:29 [INFO]: Epoch 005 - training loss: 0.7696, validation loss: 0.5000
2024-05-25 04:35:32 [INFO]: Epoch 006 - training loss: 0.7178, validation loss: 0.4647
2024-05-25 04:35:35 [INFO]: Epoch 007 - training loss: 0.6768, validation loss: 0.4340
2024-05-25 04:35:37 [INFO]: Epoch 008 - training loss: 0.6422, validation loss: 0.4104
2024-05-25 04:35:40 [INFO]: Epoch 009 - training loss: 0.6177, validation loss: 0.3898
2024-05-25 04:35:43 [INFO]: Epoch 010 - training loss: 0.5974, validation loss: 0.3735
2024-05-25 04:35:46 [INFO]: Epoch 011 - training loss: 0.5787, validation loss: 0.3588
2024-05-25 04:35:49 [INFO]: Epoch 012 - training loss: 0.5647, validation loss: 0.3474
2024-05-25 04:35:51 [INFO]: Epoch 013 - training loss: 0.5511, validation loss: 0.3361
2024-05-25 04:35:54 [INFO]: Epoch 014 - training loss: 0.5395, validation loss: 0.3269
2024-05-25 04:35:57 [INFO]: Epoch 015 - training loss: 0.5315, validation loss: 0.3191
2024-05-25 04:36:00 [INFO]: Epoch 016 - training loss: 0.5205, validation loss: 0.3107
2024-05-25 04:36:03 [INFO]: Epoch 017 - training loss: 0.5102, validation loss: 0.3043
2024-05-25 04:36:05 [INFO]: Epoch 018 - training loss: 0.5028, validation loss: 0.2974
2024-05-25 04:36:08 [INFO]: Epoch 019 - training loss: 0.4938, validation loss: 0.2919
2024-05-25 04:36:11 [INFO]: Epoch 020 - training loss: 0.4856, validation loss: 0.2864
2024-05-25 04:36:14 [INFO]: Epoch 021 - training loss: 0.4800, validation loss: 0.2815
2024-05-25 04:36:17 [INFO]: Epoch 022 - training loss: 0.4723, validation loss: 0.2770
2024-05-25 04:36:20 [INFO]: Epoch 023 - training loss: 0.4660, validation loss: 0.2729
2024-05-25 04:36:22 [INFO]: Epoch 024 - training loss: 0.4594, validation loss: 0.2689
2024-05-25 04:36:25 [INFO]: Epoch 025 - training loss: 0.4529, validation loss: 0.2651
2024-05-25 04:36:28 [INFO]: Epoch 026 - training loss: 0.4470, validation loss: 0.2608
2024-05-25 04:36:31 [INFO]: Epoch 027 - training loss: 0.4419, validation loss: 0.2580
2024-05-25 04:36:34 [INFO]: Epoch 028 - training loss: 0.4376, validation loss: 0.2548
2024-05-25 04:36:36 [INFO]: Epoch 029 - training loss: 0.4321, validation loss: 0.2517
2024-05-25 04:36:39 [INFO]: Epoch 030 - training loss: 0.4279, validation loss: 0.2486
2024-05-25 04:36:42 [INFO]: Epoch 031 - training loss: 0.4239, validation loss: 0.2455
2024-05-25 04:36:45 [INFO]: Epoch 032 - training loss: 0.4182, validation loss: 0.2429
2024-05-25 04:36:48 [INFO]: Epoch 033 - training loss: 0.4149, validation loss: 0.2395
2024-05-25 04:36:50 [INFO]: Epoch 034 - training loss: 0.4099, validation loss: 0.2369
2024-05-25 04:36:53 [INFO]: Epoch 035 - training loss: 0.4068, validation loss: 0.2347
2024-05-25 04:36:56 [INFO]: Epoch 036 - training loss: 0.4040, validation loss: 0.2323
2024-05-25 04:36:59 [INFO]: Epoch 037 - training loss: 0.3987, validation loss: 0.2293
2024-05-25 04:37:02 [INFO]: Epoch 038 - training loss: 0.3953, validation loss: 0.2273
2024-05-25 04:37:04 [INFO]: Epoch 039 - training loss: 0.3924, validation loss: 0.2245
2024-05-25 04:37:07 [INFO]: Epoch 040 - training loss: 0.3891, validation loss: 0.2225
2024-05-25 04:37:10 [INFO]: Epoch 041 - training loss: 0.3859, validation loss: 0.2203
2024-05-25 04:37:13 [INFO]: Epoch 042 - training loss: 0.3827, validation loss: 0.2184
2024-05-25 04:37:16 [INFO]: Epoch 043 - training loss: 0.3803, validation loss: 0.2164
2024-05-25 04:37:19 [INFO]: Epoch 044 - training loss: 0.3776, validation loss: 0.2145
2024-05-25 04:37:21 [INFO]: Epoch 045 - training loss: 0.3753, validation loss: 0.2125
2024-05-25 04:37:24 [INFO]: Epoch 046 - training loss: 0.3721, validation loss: 0.2110
2024-05-25 04:37:27 [INFO]: Epoch 047 - training loss: 0.3694, validation loss: 0.2090
2024-05-25 04:37:30 [INFO]: Epoch 048 - training loss: 0.3675, validation loss: 0.2069
2024-05-25 04:37:33 [INFO]: Epoch 049 - training loss: 0.3654, validation loss: 0.2052
2024-05-25 04:37:36 [INFO]: Epoch 050 - training loss: 0.3627, validation loss: 0.2039
2024-05-25 04:37:38 [INFO]: Epoch 051 - training loss: 0.3607, validation loss: 0.2020
2024-05-25 04:37:41 [INFO]: Epoch 052 - training loss: 0.3589, validation loss: 0.2003
2024-05-25 04:37:44 [INFO]: Epoch 053 - training loss: 0.3567, validation loss: 0.1987
2024-05-25 04:37:47 [INFO]: Epoch 054 - training loss: 0.3550, validation loss: 0.1971
2024-05-25 04:37:50 [INFO]: Epoch 055 - training loss: 0.3536, validation loss: 0.1961
2024-05-25 04:37:52 [INFO]: Epoch 056 - training loss: 0.3505, validation loss: 0.1942
2024-05-25 04:37:55 [INFO]: Epoch 057 - training loss: 0.3489, validation loss: 0.1930
2024-05-25 04:37:58 [INFO]: Epoch 058 - training loss: 0.3475, validation loss: 0.1920
2024-05-25 04:38:01 [INFO]: Epoch 059 - training loss: 0.3453, validation loss: 0.1905
2024-05-25 04:38:04 [INFO]: Epoch 060 - training loss: 0.3440, validation loss: 0.1892
2024-05-25 04:38:06 [INFO]: Epoch 061 - training loss: 0.3430, validation loss: 0.1882
2024-05-25 04:38:09 [INFO]: Epoch 062 - training loss: 0.3413, validation loss: 0.1869
2024-05-25 04:38:12 [INFO]: Epoch 063 - training loss: 0.3394, validation loss: 0.1860
2024-05-25 04:38:15 [INFO]: Epoch 064 - training loss: 0.3380, validation loss: 0.1850
2024-05-25 04:38:18 [INFO]: Epoch 065 - training loss: 0.3364, validation loss: 0.1836
2024-05-25 04:38:21 [INFO]: Epoch 066 - training loss: 0.3348, validation loss: 0.1826
2024-05-25 04:38:23 [INFO]: Epoch 067 - training loss: 0.3338, validation loss: 0.1816
2024-05-25 04:38:26 [INFO]: Epoch 068 - training loss: 0.3325, validation loss: 0.1805
2024-05-25 04:38:29 [INFO]: Epoch 069 - training loss: 0.3311, validation loss: 0.1796
2024-05-25 04:38:32 [INFO]: Epoch 070 - training loss: 0.3307, validation loss: 0.1788
2024-05-25 04:38:35 [INFO]: Epoch 071 - training loss: 0.3289, validation loss: 0.1774
2024-05-25 04:38:37 [INFO]: Epoch 072 - training loss: 0.3277, validation loss: 0.1768
2024-05-25 04:38:40 [INFO]: Epoch 073 - training loss: 0.3263, validation loss: 0.1760
2024-05-25 04:38:43 [INFO]: Epoch 074 - training loss: 0.3252, validation loss: 0.1752
2024-05-25 04:38:46 [INFO]: Epoch 075 - training loss: 0.3242, validation loss: 0.1748
2024-05-25 04:38:49 [INFO]: Epoch 076 - training loss: 0.3241, validation loss: 0.1737
2024-05-25 04:38:51 [INFO]: Epoch 077 - training loss: 0.3223, validation loss: 0.1732
2024-05-25 04:38:54 [INFO]: Epoch 078 - training loss: 0.3214, validation loss: 0.1724
2024-05-25 04:38:57 [INFO]: Epoch 079 - training loss: 0.3205, validation loss: 0.1716
2024-05-25 04:39:00 [INFO]: Epoch 080 - training loss: 0.3194, validation loss: 0.1707
2024-05-25 04:39:03 [INFO]: Epoch 081 - training loss: 0.3184, validation loss: 0.1700
2024-05-25 04:39:05 [INFO]: Epoch 082 - training loss: 0.3176, validation loss: 0.1696
2024-05-25 04:39:08 [INFO]: Epoch 083 - training loss: 0.3164, validation loss: 0.1690
2024-05-25 04:39:11 [INFO]: Epoch 084 - training loss: 0.3158, validation loss: 0.1684
2024-05-25 04:39:14 [INFO]: Epoch 085 - training loss: 0.3154, validation loss: 0.1676
2024-05-25 04:39:17 [INFO]: Epoch 086 - training loss: 0.3144, validation loss: 0.1672
2024-05-25 04:39:20 [INFO]: Epoch 087 - training loss: 0.3145, validation loss: 0.1666
2024-05-25 04:39:22 [INFO]: Epoch 088 - training loss: 0.3123, validation loss: 0.1657
2024-05-25 04:39:25 [INFO]: Epoch 089 - training loss: 0.3117, validation loss: 0.1651
2024-05-25 04:39:28 [INFO]: Epoch 090 - training loss: 0.3113, validation loss: 0.1647
2024-05-25 04:39:31 [INFO]: Epoch 091 - training loss: 0.3108, validation loss: 0.1642
2024-05-25 04:39:34 [INFO]: Epoch 092 - training loss: 0.3093, validation loss: 0.1638
2024-05-25 04:39:36 [INFO]: Epoch 093 - training loss: 0.3093, validation loss: 0.1634
2024-05-25 04:39:39 [INFO]: Epoch 094 - training loss: 0.3084, validation loss: 0.1629
2024-05-25 04:39:42 [INFO]: Epoch 095 - training loss: 0.3074, validation loss: 0.1626
2024-05-25 04:39:45 [INFO]: Epoch 096 - training loss: 0.3073, validation loss: 0.1621
2024-05-25 04:39:48 [INFO]: Epoch 097 - training loss: 0.3065, validation loss: 0.1615
2024-05-25 04:39:51 [INFO]: Epoch 098 - training loss: 0.3061, validation loss: 0.1610
2024-05-25 04:39:53 [INFO]: Epoch 099 - training loss: 0.3056, validation loss: 0.1606
2024-05-25 04:39:56 [INFO]: Epoch 100 - training loss: 0.3049, validation loss: 0.1602
2024-05-25 04:39:59 [INFO]: Epoch 101 - training loss: 0.3034, validation loss: 0.1598
2024-05-25 04:40:02 [INFO]: Epoch 102 - training loss: 0.3032, validation loss: 0.1594
2024-05-25 04:40:05 [INFO]: Epoch 103 - training loss: 0.3033, validation loss: 0.1591
2024-05-25 04:40:07 [INFO]: Epoch 104 - training loss: 0.3019, validation loss: 0.1586
2024-05-25 04:40:10 [INFO]: Epoch 105 - training loss: 0.3013, validation loss: 0.1583
2024-05-25 04:40:13 [INFO]: Epoch 106 - training loss: 0.3007, validation loss: 0.1580
2024-05-25 04:40:16 [INFO]: Epoch 107 - training loss: 0.3000, validation loss: 0.1573
2024-05-25 04:40:19 [INFO]: Epoch 108 - training loss: 0.3001, validation loss: 0.1571
2024-05-25 04:40:21 [INFO]: Epoch 109 - training loss: 0.2994, validation loss: 0.1568
2024-05-25 04:40:24 [INFO]: Epoch 110 - training loss: 0.2993, validation loss: 0.1564
2024-05-25 04:40:27 [INFO]: Epoch 111 - training loss: 0.2984, validation loss: 0.1559
2024-05-25 04:40:30 [INFO]: Epoch 112 - training loss: 0.2981, validation loss: 0.1558
2024-05-25 04:40:33 [INFO]: Epoch 113 - training loss: 0.2972, validation loss: 0.1553
2024-05-25 04:40:36 [INFO]: Epoch 114 - training loss: 0.2969, validation loss: 0.1549
2024-05-25 04:40:38 [INFO]: Epoch 115 - training loss: 0.2957, validation loss: 0.1545
2024-05-25 04:40:41 [INFO]: Epoch 116 - training loss: 0.2952, validation loss: 0.1542
2024-05-25 04:40:44 [INFO]: Epoch 117 - training loss: 0.2946, validation loss: 0.1539
2024-05-25 04:40:47 [INFO]: Epoch 118 - training loss: 0.2946, validation loss: 0.1537
2024-05-25 04:40:50 [INFO]: Epoch 119 - training loss: 0.2938, validation loss: 0.1534
2024-05-25 04:40:52 [INFO]: Epoch 120 - training loss: 0.2940, validation loss: 0.1530
2024-05-25 04:40:55 [INFO]: Epoch 121 - training loss: 0.2931, validation loss: 0.1527
2024-05-25 04:40:58 [INFO]: Epoch 122 - training loss: 0.2925, validation loss: 0.1525
2024-05-25 04:41:01 [INFO]: Epoch 123 - training loss: 0.2927, validation loss: 0.1519
2024-05-25 04:41:04 [INFO]: Epoch 124 - training loss: 0.2915, validation loss: 0.1518
2024-05-25 04:41:06 [INFO]: Epoch 125 - training loss: 0.2913, validation loss: 0.1514
2024-05-25 04:41:09 [INFO]: Epoch 126 - training loss: 0.2913, validation loss: 0.1513
2024-05-25 04:41:12 [INFO]: Epoch 127 - training loss: 0.2906, validation loss: 0.1509
2024-05-25 04:41:15 [INFO]: Epoch 128 - training loss: 0.2904, validation loss: 0.1505
2024-05-25 04:41:18 [INFO]: Epoch 129 - training loss: 0.2892, validation loss: 0.1505
2024-05-25 04:41:20 [INFO]: Epoch 130 - training loss: 0.2889, validation loss: 0.1500
2024-05-25 04:41:23 [INFO]: Epoch 131 - training loss: 0.2889, validation loss: 0.1498
2024-05-25 04:41:26 [INFO]: Epoch 132 - training loss: 0.2884, validation loss: 0.1495
2024-05-25 04:41:29 [INFO]: Epoch 133 - training loss: 0.2877, validation loss: 0.1492
2024-05-25 04:41:32 [INFO]: Epoch 134 - training loss: 0.2872, validation loss: 0.1489
2024-05-25 04:41:35 [INFO]: Epoch 135 - training loss: 0.2871, validation loss: 0.1486
2024-05-25 04:41:37 [INFO]: Epoch 136 - training loss: 0.2874, validation loss: 0.1483
2024-05-25 04:41:40 [INFO]: Epoch 137 - training loss: 0.2867, validation loss: 0.1483
2024-05-25 04:41:43 [INFO]: Epoch 138 - training loss: 0.2860, validation loss: 0.1477
2024-05-25 04:41:46 [INFO]: Epoch 139 - training loss: 0.2859, validation loss: 0.1477
2024-05-25 04:41:49 [INFO]: Epoch 140 - training loss: 0.2852, validation loss: 0.1474
2024-05-25 04:41:52 [INFO]: Epoch 141 - training loss: 0.2847, validation loss: 0.1471
2024-05-25 04:41:54 [INFO]: Epoch 142 - training loss: 0.2847, validation loss: 0.1469
2024-05-25 04:41:57 [INFO]: Epoch 143 - training loss: 0.2844, validation loss: 0.1466
2024-05-25 04:42:00 [INFO]: Epoch 144 - training loss: 0.2837, validation loss: 0.1463
2024-05-25 04:42:03 [INFO]: Epoch 145 - training loss: 0.2831, validation loss: 0.1461
2024-05-25 04:42:06 [INFO]: Epoch 146 - training loss: 0.2826, validation loss: 0.1459
2024-05-25 04:42:08 [INFO]: Epoch 147 - training loss: 0.2830, validation loss: 0.1457
2024-05-25 04:42:11 [INFO]: Epoch 148 - training loss: 0.2824, validation loss: 0.1455
2024-05-25 04:42:14 [INFO]: Epoch 149 - training loss: 0.2825, validation loss: 0.1456
2024-05-25 04:42:17 [INFO]: Epoch 150 - training loss: 0.2818, validation loss: 0.1448
2024-05-25 04:42:20 [INFO]: Epoch 151 - training loss: 0.2815, validation loss: 0.1450
2024-05-25 04:42:22 [INFO]: Epoch 152 - training loss: 0.2808, validation loss: 0.1446
2024-05-25 04:42:25 [INFO]: Epoch 153 - training loss: 0.2807, validation loss: 0.1444
2024-05-25 04:42:28 [INFO]: Epoch 154 - training loss: 0.2797, validation loss: 0.1441
2024-05-25 04:42:31 [INFO]: Epoch 155 - training loss: 0.2802, validation loss: 0.1438
2024-05-25 04:42:34 [INFO]: Epoch 156 - training loss: 0.2794, validation loss: 0.1435
2024-05-25 04:42:36 [INFO]: Epoch 157 - training loss: 0.2797, validation loss: 0.1435
2024-05-25 04:42:39 [INFO]: Epoch 158 - training loss: 0.2790, validation loss: 0.1432
2024-05-25 04:42:42 [INFO]: Epoch 159 - training loss: 0.2787, validation loss: 0.1432
2024-05-25 04:42:45 [INFO]: Epoch 160 - training loss: 0.2784, validation loss: 0.1429
2024-05-25 04:42:48 [INFO]: Epoch 161 - training loss: 0.2776, validation loss: 0.1428
2024-05-25 04:42:51 [INFO]: Epoch 162 - training loss: 0.2785, validation loss: 0.1426
2024-05-25 04:42:53 [INFO]: Epoch 163 - training loss: 0.2776, validation loss: 0.1424
2024-05-25 04:42:56 [INFO]: Epoch 164 - training loss: 0.2774, validation loss: 0.1421
2024-05-25 04:42:59 [INFO]: Epoch 165 - training loss: 0.2769, validation loss: 0.1420
2024-05-25 04:43:02 [INFO]: Epoch 166 - training loss: 0.2779, validation loss: 0.1418
2024-05-25 04:43:05 [INFO]: Epoch 167 - training loss: 0.2769, validation loss: 0.1417
2024-05-25 04:43:07 [INFO]: Epoch 168 - training loss: 0.2764, validation loss: 0.1415
2024-05-25 04:43:10 [INFO]: Epoch 169 - training loss: 0.2753, validation loss: 0.1413
2024-05-25 04:43:13 [INFO]: Epoch 170 - training loss: 0.2759, validation loss: 0.1411
2024-05-25 04:43:16 [INFO]: Epoch 171 - training loss: 0.2751, validation loss: 0.1409
2024-05-25 04:43:19 [INFO]: Epoch 172 - training loss: 0.2750, validation loss: 0.1407
2024-05-25 04:43:21 [INFO]: Epoch 173 - training loss: 0.2754, validation loss: 0.1406
2024-05-25 04:43:24 [INFO]: Epoch 174 - training loss: 0.2742, validation loss: 0.1408
2024-05-25 04:43:27 [INFO]: Epoch 175 - training loss: 0.2744, validation loss: 0.1404
2024-05-25 04:43:30 [INFO]: Epoch 176 - training loss: 0.2734, validation loss: 0.1401
2024-05-25 04:43:33 [INFO]: Epoch 177 - training loss: 0.2742, validation loss: 0.1401
2024-05-25 04:43:36 [INFO]: Epoch 178 - training loss: 0.2734, validation loss: 0.1397
2024-05-25 04:43:38 [INFO]: Epoch 179 - training loss: 0.2730, validation loss: 0.1398
2024-05-25 04:43:41 [INFO]: Epoch 180 - training loss: 0.2733, validation loss: 0.1395
2024-05-25 04:43:44 [INFO]: Epoch 181 - training loss: 0.2726, validation loss: 0.1392
2024-05-25 04:43:47 [INFO]: Epoch 182 - training loss: 0.2722, validation loss: 0.1391
2024-05-25 04:43:50 [INFO]: Epoch 183 - training loss: 0.2721, validation loss: 0.1391
2024-05-25 04:43:53 [INFO]: Epoch 184 - training loss: 0.2717, validation loss: 0.1389
2024-05-25 04:43:55 [INFO]: Epoch 185 - training loss: 0.2717, validation loss: 0.1389
2024-05-25 04:43:58 [INFO]: Epoch 186 - training loss: 0.2716, validation loss: 0.1387
2024-05-25 04:44:01 [INFO]: Epoch 187 - training loss: 0.2712, validation loss: 0.1383
2024-05-25 04:44:04 [INFO]: Epoch 188 - training loss: 0.2711, validation loss: 0.1382
2024-05-25 04:44:07 [INFO]: Epoch 189 - training loss: 0.2708, validation loss: 0.1381
2024-05-25 04:44:10 [INFO]: Epoch 190 - training loss: 0.2698, validation loss: 0.1381
2024-05-25 04:44:12 [INFO]: Epoch 191 - training loss: 0.2704, validation loss: 0.1377
2024-05-25 04:44:15 [INFO]: Epoch 192 - training loss: 0.2701, validation loss: 0.1378
2024-05-25 04:44:18 [INFO]: Epoch 193 - training loss: 0.2698, validation loss: 0.1375
2024-05-25 04:44:21 [INFO]: Epoch 194 - training loss: 0.2696, validation loss: 0.1377
2024-05-25 04:44:24 [INFO]: Epoch 195 - training loss: 0.2695, validation loss: 0.1373
2024-05-25 04:44:26 [INFO]: Epoch 196 - training loss: 0.2691, validation loss: 0.1373
2024-05-25 04:44:29 [INFO]: Epoch 197 - training loss: 0.2686, validation loss: 0.1371
2024-05-25 04:44:32 [INFO]: Epoch 198 - training loss: 0.2688, validation loss: 0.1370
2024-05-25 04:44:35 [INFO]: Epoch 199 - training loss: 0.2687, validation loss: 0.1369
2024-05-25 04:44:38 [INFO]: Epoch 200 - training loss: 0.2681, validation loss: 0.1366
2024-05-25 04:44:40 [INFO]: Epoch 201 - training loss: 0.2680, validation loss: 0.1365
2024-05-25 04:44:43 [INFO]: Epoch 202 - training loss: 0.2690, validation loss: 0.1364
2024-05-25 04:44:46 [INFO]: Epoch 203 - training loss: 0.2676, validation loss: 0.1362
2024-05-25 04:44:49 [INFO]: Epoch 204 - training loss: 0.2674, validation loss: 0.1363
2024-05-25 04:44:52 [INFO]: Epoch 205 - training loss: 0.2673, validation loss: 0.1361
2024-05-25 04:44:55 [INFO]: Epoch 206 - training loss: 0.2671, validation loss: 0.1359
2024-05-25 04:44:57 [INFO]: Epoch 207 - training loss: 0.2665, validation loss: 0.1358
2024-05-25 04:45:00 [INFO]: Epoch 208 - training loss: 0.2660, validation loss: 0.1358
2024-05-25 04:45:03 [INFO]: Epoch 209 - training loss: 0.2666, validation loss: 0.1356
2024-05-25 04:45:06 [INFO]: Epoch 210 - training loss: 0.2667, validation loss: 0.1355
2024-05-25 04:45:09 [INFO]: Epoch 211 - training loss: 0.2661, validation loss: 0.1353
2024-05-25 04:45:11 [INFO]: Epoch 212 - training loss: 0.2656, validation loss: 0.1353
2024-05-25 04:45:14 [INFO]: Epoch 213 - training loss: 0.2652, validation loss: 0.1352
2024-05-25 04:45:17 [INFO]: Epoch 214 - training loss: 0.2656, validation loss: 0.1351
2024-05-25 04:45:20 [INFO]: Epoch 215 - training loss: 0.2653, validation loss: 0.1350
2024-05-25 04:45:23 [INFO]: Epoch 216 - training loss: 0.2652, validation loss: 0.1347
2024-05-25 04:45:25 [INFO]: Epoch 217 - training loss: 0.2648, validation loss: 0.1348
2024-05-25 04:45:28 [INFO]: Epoch 218 - training loss: 0.2646, validation loss: 0.1346
2024-05-25 04:45:31 [INFO]: Epoch 219 - training loss: 0.2642, validation loss: 0.1347
2024-05-25 04:45:34 [INFO]: Epoch 220 - training loss: 0.2641, validation loss: 0.1343
2024-05-25 04:45:37 [INFO]: Epoch 221 - training loss: 0.2635, validation loss: 0.1343
2024-05-25 04:45:40 [INFO]: Epoch 222 - training loss: 0.2639, validation loss: 0.1343
2024-05-25 04:45:42 [INFO]: Epoch 223 - training loss: 0.2634, validation loss: 0.1343
2024-05-25 04:45:45 [INFO]: Epoch 224 - training loss: 0.2633, validation loss: 0.1341
2024-05-25 04:45:48 [INFO]: Epoch 225 - training loss: 0.2638, validation loss: 0.1338
2024-05-25 04:45:51 [INFO]: Epoch 226 - training loss: 0.2630, validation loss: 0.1337
2024-05-25 04:45:54 [INFO]: Epoch 227 - training loss: 0.2631, validation loss: 0.1336
2024-05-25 04:45:56 [INFO]: Epoch 228 - training loss: 0.2628, validation loss: 0.1335
2024-05-25 04:45:59 [INFO]: Epoch 229 - training loss: 0.2626, validation loss: 0.1336
2024-05-25 04:46:02 [INFO]: Epoch 230 - training loss: 0.2627, validation loss: 0.1336
2024-05-25 04:46:05 [INFO]: Epoch 231 - training loss: 0.2618, validation loss: 0.1332
2024-05-25 04:46:08 [INFO]: Epoch 232 - training loss: 0.2620, validation loss: 0.1333
2024-05-25 04:46:11 [INFO]: Epoch 233 - training loss: 0.2614, validation loss: 0.1331
2024-05-25 04:46:13 [INFO]: Epoch 234 - training loss: 0.2615, validation loss: 0.1331
2024-05-25 04:46:16 [INFO]: Epoch 235 - training loss: 0.2610, validation loss: 0.1331
2024-05-25 04:46:19 [INFO]: Epoch 236 - training loss: 0.2609, validation loss: 0.1329
2024-05-25 04:46:22 [INFO]: Epoch 237 - training loss: 0.2610, validation loss: 0.1331
2024-05-25 04:46:25 [INFO]: Epoch 238 - training loss: 0.2607, validation loss: 0.1328
2024-05-25 04:46:27 [INFO]: Epoch 239 - training loss: 0.2608, validation loss: 0.1328
2024-05-25 04:46:30 [INFO]: Epoch 240 - training loss: 0.2609, validation loss: 0.1326
2024-05-25 04:46:33 [INFO]: Epoch 241 - training loss: 0.2601, validation loss: 0.1324
2024-05-25 04:46:36 [INFO]: Epoch 242 - training loss: 0.2599, validation loss: 0.1325
2024-05-25 04:46:39 [INFO]: Epoch 243 - training loss: 0.2602, validation loss: 0.1324
2024-05-25 04:46:41 [INFO]: Epoch 244 - training loss: 0.2595, validation loss: 0.1321
2024-05-25 04:46:44 [INFO]: Epoch 245 - training loss: 0.2594, validation loss: 0.1324
2024-05-25 04:46:47 [INFO]: Epoch 246 - training loss: 0.2596, validation loss: 0.1323
2024-05-25 04:46:50 [INFO]: Epoch 247 - training loss: 0.2594, validation loss: 0.1321
2024-05-25 04:46:53 [INFO]: Epoch 248 - training loss: 0.2591, validation loss: 0.1320
2024-05-25 04:46:56 [INFO]: Epoch 249 - training loss: 0.2595, validation loss: 0.1319
2024-05-25 04:46:58 [INFO]: Epoch 250 - training loss: 0.2585, validation loss: 0.1320
2024-05-25 04:47:01 [INFO]: Epoch 251 - training loss: 0.2583, validation loss: 0.1318
2024-05-25 04:47:04 [INFO]: Epoch 252 - training loss: 0.2583, validation loss: 0.1318
2024-05-25 04:47:07 [INFO]: Epoch 253 - training loss: 0.2582, validation loss: 0.1316
2024-05-25 04:47:10 [INFO]: Epoch 254 - training loss: 0.2582, validation loss: 0.1315
2024-05-25 04:47:12 [INFO]: Epoch 255 - training loss: 0.2580, validation loss: 0.1315
2024-05-25 04:47:15 [INFO]: Epoch 256 - training loss: 0.2586, validation loss: 0.1314
2024-05-25 04:47:18 [INFO]: Epoch 257 - training loss: 0.2577, validation loss: 0.1315
2024-05-25 04:47:21 [INFO]: Epoch 258 - training loss: 0.2580, validation loss: 0.1314
2024-05-25 04:47:24 [INFO]: Epoch 259 - training loss: 0.2574, validation loss: 0.1316
2024-05-25 04:47:26 [INFO]: Epoch 260 - training loss: 0.2576, validation loss: 0.1311
2024-05-25 04:47:29 [INFO]: Epoch 261 - training loss: 0.2568, validation loss: 0.1313
2024-05-25 04:47:32 [INFO]: Epoch 262 - training loss: 0.2567, validation loss: 0.1311
2024-05-25 04:47:35 [INFO]: Epoch 263 - training loss: 0.2570, validation loss: 0.1311
2024-05-25 04:47:38 [INFO]: Epoch 264 - training loss: 0.2567, validation loss: 0.1308
2024-05-25 04:47:40 [INFO]: Epoch 265 - training loss: 0.2563, validation loss: 0.1308
2024-05-25 04:47:43 [INFO]: Epoch 266 - training loss: 0.2570, validation loss: 0.1309
2024-05-25 04:47:46 [INFO]: Epoch 267 - training loss: 0.2561, validation loss: 0.1308
2024-05-25 04:47:49 [INFO]: Epoch 268 - training loss: 0.2558, validation loss: 0.1306
2024-05-25 04:47:52 [INFO]: Epoch 269 - training loss: 0.2558, validation loss: 0.1307
2024-05-25 04:47:55 [INFO]: Epoch 270 - training loss: 0.2558, validation loss: 0.1307
2024-05-25 04:47:57 [INFO]: Epoch 271 - training loss: 0.2561, validation loss: 0.1307
2024-05-25 04:48:00 [INFO]: Epoch 272 - training loss: 0.2560, validation loss: 0.1304
2024-05-25 04:48:03 [INFO]: Epoch 273 - training loss: 0.2551, validation loss: 0.1304
2024-05-25 04:48:06 [INFO]: Epoch 274 - training loss: 0.2553, validation loss: 0.1303
2024-05-25 04:48:09 [INFO]: Epoch 275 - training loss: 0.2550, validation loss: 0.1303
2024-05-25 04:48:12 [INFO]: Epoch 276 - training loss: 0.2548, validation loss: 0.1304
2024-05-25 04:48:14 [INFO]: Epoch 277 - training loss: 0.2551, validation loss: 0.1303
2024-05-25 04:48:17 [INFO]: Epoch 278 - training loss: 0.2547, validation loss: 0.1301
2024-05-25 04:48:20 [INFO]: Epoch 279 - training loss: 0.2549, validation loss: 0.1300
2024-05-25 04:48:23 [INFO]: Epoch 280 - training loss: 0.2545, validation loss: 0.1301
2024-05-25 04:48:26 [INFO]: Epoch 281 - training loss: 0.2541, validation loss: 0.1299
2024-05-25 04:48:28 [INFO]: Epoch 282 - training loss: 0.2543, validation loss: 0.1300
2024-05-25 04:48:31 [INFO]: Epoch 283 - training loss: 0.2536, validation loss: 0.1300
2024-05-25 04:48:34 [INFO]: Epoch 284 - training loss: 0.2544, validation loss: 0.1299
2024-05-25 04:48:37 [INFO]: Epoch 285 - training loss: 0.2540, validation loss: 0.1298
2024-05-25 04:48:40 [INFO]: Epoch 286 - training loss: 0.2534, validation loss: 0.1297
2024-05-25 04:48:42 [INFO]: Epoch 287 - training loss: 0.2529, validation loss: 0.1297
2024-05-25 04:48:45 [INFO]: Epoch 288 - training loss: 0.2533, validation loss: 0.1298
2024-05-25 04:48:48 [INFO]: Epoch 289 - training loss: 0.2535, validation loss: 0.1296
2024-05-25 04:48:51 [INFO]: Epoch 290 - training loss: 0.2536, validation loss: 0.1295
2024-05-25 04:48:54 [INFO]: Epoch 291 - training loss: 0.2529, validation loss: 0.1295
2024-05-25 04:48:56 [INFO]: Epoch 292 - training loss: 0.2525, validation loss: 0.1295
2024-05-25 04:48:59 [INFO]: Epoch 293 - training loss: 0.2536, validation loss: 0.1293
2024-05-25 04:49:02 [INFO]: Epoch 294 - training loss: 0.2530, validation loss: 0.1295
2024-05-25 04:49:05 [INFO]: Epoch 295 - training loss: 0.2521, validation loss: 0.1294
2024-05-25 04:49:08 [INFO]: Epoch 296 - training loss: 0.2520, validation loss: 0.1295
2024-05-25 04:49:11 [INFO]: Epoch 297 - training loss: 0.2523, validation loss: 0.1292
2024-05-25 04:49:13 [INFO]: Epoch 298 - training loss: 0.2521, validation loss: 0.1292
2024-05-25 04:49:16 [INFO]: Epoch 299 - training loss: 0.2519, validation loss: 0.1294
2024-05-25 04:49:19 [INFO]: Epoch 300 - training loss: 0.2515, validation loss: 0.1292
2024-05-25 04:49:19 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 04:49:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_air_quality/20240525_T043514/BRITS.pypots
2024-05-25 04:49:20 [INFO]: BRITS on Air-Quality: MAE=0.1512, MSE=0.1326
2024-05-25 04:49:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_air_quality/imputation.pkl
2024-05-25 04:49:20 [INFO]: Using the given device: cuda:0
2024-05-25 04:49:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920
2024-05-25 04:49:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/tensorboard
2024-05-25 04:49:20 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 04:49:24 [INFO]: Epoch 001 - training loss: 1.3609, validation loss: 0.8329
2024-05-25 04:49:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch1_loss0.8328823328018189.pypots
2024-05-25 04:49:28 [INFO]: Epoch 002 - training loss: 0.9812, validation loss: 0.7755
2024-05-25 04:49:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch2_loss0.7754798412322998.pypots
2024-05-25 04:49:32 [INFO]: Epoch 003 - training loss: 0.9206, validation loss: 0.7505
2024-05-25 04:49:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch3_loss0.7504570484161377.pypots
2024-05-25 04:49:36 [INFO]: Epoch 004 - training loss: 0.8909, validation loss: 0.7370
2024-05-25 04:49:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch4_loss0.7369576811790466.pypots
2024-05-25 04:49:40 [INFO]: Epoch 005 - training loss: 0.8739, validation loss: 0.7275
2024-05-25 04:49:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch5_loss0.7274981319904328.pypots
2024-05-25 04:49:44 [INFO]: Epoch 006 - training loss: 0.8805, validation loss: 0.7209
2024-05-25 04:49:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch6_loss0.7209005296230316.pypots
2024-05-25 04:49:48 [INFO]: Epoch 007 - training loss: 0.8593, validation loss: 0.7160
2024-05-25 04:49:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch7_loss0.7159882634878159.pypots
2024-05-25 04:49:52 [INFO]: Epoch 008 - training loss: 0.8508, validation loss: 0.7116
2024-05-25 04:49:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch8_loss0.7115567564964295.pypots
2024-05-25 04:49:56 [INFO]: Epoch 009 - training loss: 0.8602, validation loss: 0.7085
2024-05-25 04:49:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch9_loss0.7084526896476746.pypots
2024-05-25 04:50:00 [INFO]: Epoch 010 - training loss: 0.8409, validation loss: 0.7061
2024-05-25 04:50:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch10_loss0.7060790538787842.pypots
2024-05-25 04:50:04 [INFO]: Epoch 011 - training loss: 0.8341, validation loss: 0.7049
2024-05-25 04:50:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch11_loss0.7048690259456635.pypots
2024-05-25 04:50:07 [INFO]: Epoch 012 - training loss: 0.8412, validation loss: 0.7045
2024-05-25 04:50:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch12_loss0.7044622302055359.pypots
2024-05-25 04:50:11 [INFO]: Epoch 013 - training loss: 0.8401, validation loss: 0.7039
2024-05-25 04:50:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch13_loss0.7038738071918488.pypots
2024-05-25 04:50:15 [INFO]: Epoch 014 - training loss: 0.8237, validation loss: 0.7000
2024-05-25 04:50:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch14_loss0.7000250399112702.pypots
2024-05-25 04:50:19 [INFO]: Epoch 015 - training loss: 0.8237, validation loss: 0.7008
2024-05-25 04:50:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch15_loss0.7007959842681885.pypots
2024-05-25 04:50:23 [INFO]: Epoch 016 - training loss: 0.8193, validation loss: 0.7018
2024-05-25 04:50:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch16_loss0.7018086075782776.pypots
2024-05-25 04:50:27 [INFO]: Epoch 017 - training loss: 0.8042, validation loss: 0.6994
2024-05-25 04:50:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch17_loss0.6994162380695343.pypots
2024-05-25 04:50:31 [INFO]: Epoch 018 - training loss: 0.8074, validation loss: 0.6984
2024-05-25 04:50:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch18_loss0.6984425902366638.pypots
2024-05-25 04:50:35 [INFO]: Epoch 019 - training loss: 0.8073, validation loss: 0.6974
2024-05-25 04:50:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch19_loss0.6974424600601197.pypots
2024-05-25 04:50:39 [INFO]: Epoch 020 - training loss: 0.8118, validation loss: 0.6977
2024-05-25 04:50:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch20_loss0.6977285116910934.pypots
2024-05-25 04:50:42 [INFO]: Epoch 021 - training loss: 0.7958, validation loss: 0.6985
2024-05-25 04:50:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch21_loss0.6985051780939102.pypots
2024-05-25 04:50:46 [INFO]: Epoch 022 - training loss: 0.8129, validation loss: 0.6976
2024-05-25 04:50:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch22_loss0.697597599029541.pypots
2024-05-25 04:50:50 [INFO]: Epoch 023 - training loss: 0.8014, validation loss: 0.6994
2024-05-25 04:50:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch23_loss0.6994255542755127.pypots
2024-05-25 04:50:54 [INFO]: Epoch 024 - training loss: 0.7954, validation loss: 0.6980
2024-05-25 04:50:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch24_loss0.698026779294014.pypots
2024-05-25 04:50:58 [INFO]: Epoch 025 - training loss: 0.7941, validation loss: 0.6982
2024-05-25 04:50:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch25_loss0.6981938123703003.pypots
2024-05-25 04:51:02 [INFO]: Epoch 026 - training loss: 0.7785, validation loss: 0.6983
2024-05-25 04:51:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch26_loss0.6982792824506759.pypots
2024-05-25 04:51:06 [INFO]: Epoch 027 - training loss: 0.7857, validation loss: 0.6990
2024-05-25 04:51:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch27_loss0.6990286916494369.pypots
2024-05-25 04:51:10 [INFO]: Epoch 028 - training loss: 0.7878, validation loss: 0.6988
2024-05-25 04:51:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch28_loss0.6988210141658783.pypots
2024-05-25 04:51:14 [INFO]: Epoch 029 - training loss: 0.7823, validation loss: 0.7005
2024-05-25 04:51:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN_epoch29_loss0.7004866182804108.pypots
2024-05-25 04:51:14 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:51:14 [INFO]: Finished training. The best model is from epoch#19.
2024-05-25 04:51:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_air_quality/20240525_T044920/MRNN.pypots
2024-05-25 04:51:14 [INFO]: MRNN on Air-Quality: MAE=0.5216, MSE=0.6340
2024-05-25 04:51:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_air_quality/imputation.pkl
2024-05-25 04:51:14 [INFO]: Using the given device: cpu
2024-05-25 04:51:14 [INFO]: LOCF on Air-Quality: MAE=0.2194, MSE=0.3465
2024-05-25 04:51:14 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_air_quality".
2024-05-25 04:51:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_air_quality/imputation.pkl
2024-05-25 04:51:14 [INFO]: Median on Air-Quality: MAE=0.6629, MSE=1.0282
2024-05-25 04:51:14 [INFO]: Successfully created the given path "saved_results/round_1/Median_air_quality".
2024-05-25 04:51:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_air_quality/imputation.pkl
2024-05-25 04:51:14 [INFO]: Mean on Air-Quality: MAE=0.6945, MSE=0.9678
2024-05-25 04:51:14 [INFO]: Successfully created the given path "saved_results/round_1/Mean_air_quality".
2024-05-25 04:51:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_air_quality/imputation.pkl
2024-05-25 04:51:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-25 04:51:15 [INFO]: Using the given device: cuda:0
2024-05-25 04:51:15 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240525_T045115
2024-05-25 04:51:15 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240525_T045115/tensorboard
2024-05-25 04:51:15 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 04:51:16 [INFO]: Epoch 001 - training loss: 1.0559, validation loss: 0.5547
2024-05-25 04:51:16 [INFO]: Epoch 002 - training loss: 0.7569, validation loss: 0.4215
2024-05-25 04:51:17 [INFO]: Epoch 003 - training loss: 0.6521, validation loss: 0.3466
2024-05-25 04:51:18 [INFO]: Epoch 004 - training loss: 0.5766, validation loss: 0.3035
2024-05-25 04:51:18 [INFO]: Epoch 005 - training loss: 0.5234, validation loss: 0.2826
2024-05-25 04:51:19 [INFO]: Epoch 006 - training loss: 0.4868, validation loss: 0.2657
2024-05-25 04:51:19 [INFO]: Epoch 007 - training loss: 0.4594, validation loss: 0.2551
2024-05-25 04:51:20 [INFO]: Epoch 008 - training loss: 0.4409, validation loss: 0.2460
2024-05-25 04:51:21 [INFO]: Epoch 009 - training loss: 0.4255, validation loss: 0.2397
2024-05-25 04:51:21 [INFO]: Epoch 010 - training loss: 0.4150, validation loss: 0.2350
2024-05-25 04:51:22 [INFO]: Epoch 011 - training loss: 0.4061, validation loss: 0.2317
2024-05-25 04:51:22 [INFO]: Epoch 012 - training loss: 0.3953, validation loss: 0.2276
2024-05-25 04:51:23 [INFO]: Epoch 013 - training loss: 0.3879, validation loss: 0.2238
2024-05-25 04:51:24 [INFO]: Epoch 014 - training loss: 0.3812, validation loss: 0.2210
2024-05-25 04:51:24 [INFO]: Epoch 015 - training loss: 0.3736, validation loss: 0.2185
2024-05-25 04:51:25 [INFO]: Epoch 016 - training loss: 0.3692, validation loss: 0.2163
2024-05-25 04:51:25 [INFO]: Epoch 017 - training loss: 0.3627, validation loss: 0.2130
2024-05-25 04:51:26 [INFO]: Epoch 018 - training loss: 0.3581, validation loss: 0.2117
2024-05-25 04:51:27 [INFO]: Epoch 019 - training loss: 0.3541, validation loss: 0.2104
2024-05-25 04:51:27 [INFO]: Epoch 020 - training loss: 0.3507, validation loss: 0.2073
2024-05-25 04:51:28 [INFO]: Epoch 021 - training loss: 0.3460, validation loss: 0.2073
2024-05-25 04:51:28 [INFO]: Epoch 022 - training loss: 0.3430, validation loss: 0.2039
2024-05-25 04:51:29 [INFO]: Epoch 023 - training loss: 0.3383, validation loss: 0.2028
2024-05-25 04:51:30 [INFO]: Epoch 024 - training loss: 0.3357, validation loss: 0.2013
2024-05-25 04:51:30 [INFO]: Epoch 025 - training loss: 0.3334, validation loss: 0.1998
2024-05-25 04:51:31 [INFO]: Epoch 026 - training loss: 0.3306, validation loss: 0.1993
2024-05-25 04:51:31 [INFO]: Epoch 027 - training loss: 0.3271, validation loss: 0.1973
2024-05-25 04:51:32 [INFO]: Epoch 028 - training loss: 0.3234, validation loss: 0.1971
2024-05-25 04:51:33 [INFO]: Epoch 029 - training loss: 0.3214, validation loss: 0.1953
2024-05-25 04:51:33 [INFO]: Epoch 030 - training loss: 0.3194, validation loss: 0.1935
2024-05-25 04:51:34 [INFO]: Epoch 031 - training loss: 0.3160, validation loss: 0.1927
2024-05-25 04:51:34 [INFO]: Epoch 032 - training loss: 0.3147, validation loss: 0.1910
2024-05-25 04:51:35 [INFO]: Epoch 033 - training loss: 0.3120, validation loss: 0.1889
2024-05-25 04:51:36 [INFO]: Epoch 034 - training loss: 0.3111, validation loss: 0.1901
2024-05-25 04:51:36 [INFO]: Epoch 035 - training loss: 0.3093, validation loss: 0.1874
2024-05-25 04:51:37 [INFO]: Epoch 036 - training loss: 0.3060, validation loss: 0.1858
2024-05-25 04:51:37 [INFO]: Epoch 037 - training loss: 0.3050, validation loss: 0.1850
2024-05-25 04:51:38 [INFO]: Epoch 038 - training loss: 0.3039, validation loss: 0.1845
2024-05-25 04:51:39 [INFO]: Epoch 039 - training loss: 0.3003, validation loss: 0.1823
2024-05-25 04:51:39 [INFO]: Epoch 040 - training loss: 0.2977, validation loss: 0.1822
2024-05-25 04:51:40 [INFO]: Epoch 041 - training loss: 0.2965, validation loss: 0.1811
2024-05-25 04:51:40 [INFO]: Epoch 042 - training loss: 0.2948, validation loss: 0.1806
2024-05-25 04:51:41 [INFO]: Epoch 043 - training loss: 0.2936, validation loss: 0.1792
2024-05-25 04:51:42 [INFO]: Epoch 044 - training loss: 0.2914, validation loss: 0.1788
2024-05-25 04:51:42 [INFO]: Epoch 045 - training loss: 0.2897, validation loss: 0.1778
2024-05-25 04:51:43 [INFO]: Epoch 046 - training loss: 0.2878, validation loss: 0.1772
2024-05-25 04:51:43 [INFO]: Epoch 047 - training loss: 0.2877, validation loss: 0.1755
2024-05-25 04:51:44 [INFO]: Epoch 048 - training loss: 0.2856, validation loss: 0.1744
2024-05-25 04:51:45 [INFO]: Epoch 049 - training loss: 0.2843, validation loss: 0.1744
2024-05-25 04:51:45 [INFO]: Epoch 050 - training loss: 0.2822, validation loss: 0.1727
2024-05-25 04:51:46 [INFO]: Epoch 051 - training loss: 0.2811, validation loss: 0.1729
2024-05-25 04:51:46 [INFO]: Epoch 052 - training loss: 0.2785, validation loss: 0.1715
2024-05-25 04:51:47 [INFO]: Epoch 053 - training loss: 0.2765, validation loss: 0.1718
2024-05-25 04:51:48 [INFO]: Epoch 054 - training loss: 0.2767, validation loss: 0.1702
2024-05-25 04:51:48 [INFO]: Epoch 055 - training loss: 0.2752, validation loss: 0.1695
2024-05-25 04:51:49 [INFO]: Epoch 056 - training loss: 0.2729, validation loss: 0.1682
2024-05-25 04:51:49 [INFO]: Epoch 057 - training loss: 0.2726, validation loss: 0.1684
2024-05-25 04:51:50 [INFO]: Epoch 058 - training loss: 0.2707, validation loss: 0.1676
2024-05-25 04:51:51 [INFO]: Epoch 059 - training loss: 0.2692, validation loss: 0.1659
2024-05-25 04:51:51 [INFO]: Epoch 060 - training loss: 0.2681, validation loss: 0.1662
2024-05-25 04:51:52 [INFO]: Epoch 061 - training loss: 0.2656, validation loss: 0.1647
2024-05-25 04:51:52 [INFO]: Epoch 062 - training loss: 0.2645, validation loss: 0.1650
2024-05-25 04:51:53 [INFO]: Epoch 063 - training loss: 0.2636, validation loss: 0.1637
2024-05-25 04:51:54 [INFO]: Epoch 064 - training loss: 0.2618, validation loss: 0.1623
2024-05-25 04:51:54 [INFO]: Epoch 065 - training loss: 0.2614, validation loss: 0.1627
2024-05-25 04:51:55 [INFO]: Epoch 066 - training loss: 0.2597, validation loss: 0.1623
2024-05-25 04:51:55 [INFO]: Epoch 067 - training loss: 0.2593, validation loss: 0.1615
2024-05-25 04:51:56 [INFO]: Epoch 068 - training loss: 0.2577, validation loss: 0.1617
2024-05-25 04:51:57 [INFO]: Epoch 069 - training loss: 0.2564, validation loss: 0.1617
2024-05-25 04:51:57 [INFO]: Epoch 070 - training loss: 0.2546, validation loss: 0.1595
2024-05-25 04:51:58 [INFO]: Epoch 071 - training loss: 0.2539, validation loss: 0.1590
2024-05-25 04:51:58 [INFO]: Epoch 072 - training loss: 0.2536, validation loss: 0.1589
2024-05-25 04:51:59 [INFO]: Epoch 073 - training loss: 0.2521, validation loss: 0.1589
2024-05-25 04:52:00 [INFO]: Epoch 074 - training loss: 0.2525, validation loss: 0.1579
2024-05-25 04:52:00 [INFO]: Epoch 075 - training loss: 0.2505, validation loss: 0.1576
2024-05-25 04:52:01 [INFO]: Epoch 076 - training loss: 0.2483, validation loss: 0.1592
2024-05-25 04:52:02 [INFO]: Epoch 077 - training loss: 0.2502, validation loss: 0.1574
2024-05-25 04:52:02 [INFO]: Epoch 078 - training loss: 0.2479, validation loss: 0.1581
2024-05-25 04:52:03 [INFO]: Epoch 079 - training loss: 0.2469, validation loss: 0.1566
2024-05-25 04:52:03 [INFO]: Epoch 080 - training loss: 0.2468, validation loss: 0.1570
2024-05-25 04:52:04 [INFO]: Epoch 081 - training loss: 0.2449, validation loss: 0.1554
2024-05-25 04:52:05 [INFO]: Epoch 082 - training loss: 0.2448, validation loss: 0.1554
2024-05-25 04:52:05 [INFO]: Epoch 083 - training loss: 0.2441, validation loss: 0.1554
2024-05-25 04:52:06 [INFO]: Epoch 084 - training loss: 0.2430, validation loss: 0.1552
2024-05-25 04:52:06 [INFO]: Epoch 085 - training loss: 0.2419, validation loss: 0.1550
2024-05-25 04:52:07 [INFO]: Epoch 086 - training loss: 0.2415, validation loss: 0.1549
2024-05-25 04:52:08 [INFO]: Epoch 087 - training loss: 0.2414, validation loss: 0.1549
2024-05-25 04:52:08 [INFO]: Epoch 088 - training loss: 0.2402, validation loss: 0.1536
2024-05-25 04:52:09 [INFO]: Epoch 089 - training loss: 0.2393, validation loss: 0.1530
2024-05-25 04:52:09 [INFO]: Epoch 090 - training loss: 0.2379, validation loss: 0.1524
2024-05-25 04:52:10 [INFO]: Epoch 091 - training loss: 0.2374, validation loss: 0.1535
2024-05-25 04:52:11 [INFO]: Epoch 092 - training loss: 0.2365, validation loss: 0.1519
2024-05-25 04:52:11 [INFO]: Epoch 093 - training loss: 0.2356, validation loss: 0.1540
2024-05-25 04:52:12 [INFO]: Epoch 094 - training loss: 0.2360, validation loss: 0.1511
2024-05-25 04:52:12 [INFO]: Epoch 095 - training loss: 0.2368, validation loss: 0.1521
2024-05-25 04:52:13 [INFO]: Epoch 096 - training loss: 0.2348, validation loss: 0.1512
2024-05-25 04:52:14 [INFO]: Epoch 097 - training loss: 0.2341, validation loss: 0.1514
2024-05-25 04:52:14 [INFO]: Epoch 098 - training loss: 0.2329, validation loss: 0.1513
2024-05-25 04:52:15 [INFO]: Epoch 099 - training loss: 0.2327, validation loss: 0.1512
2024-05-25 04:52:15 [INFO]: Epoch 100 - training loss: 0.2321, validation loss: 0.1503
2024-05-25 04:52:16 [INFO]: Epoch 101 - training loss: 0.2307, validation loss: 0.1502
2024-05-25 04:52:17 [INFO]: Epoch 102 - training loss: 0.2306, validation loss: 0.1498
2024-05-25 04:52:17 [INFO]: Epoch 103 - training loss: 0.2296, validation loss: 0.1498
2024-05-25 04:52:18 [INFO]: Epoch 104 - training loss: 0.2295, validation loss: 0.1500
2024-05-25 04:52:18 [INFO]: Epoch 105 - training loss: 0.2285, validation loss: 0.1507
2024-05-25 04:52:19 [INFO]: Epoch 106 - training loss: 0.2267, validation loss: 0.1488
2024-05-25 04:52:20 [INFO]: Epoch 107 - training loss: 0.2266, validation loss: 0.1488
2024-05-25 04:52:20 [INFO]: Epoch 108 - training loss: 0.2256, validation loss: 0.1494
2024-05-25 04:52:21 [INFO]: Epoch 109 - training loss: 0.2260, validation loss: 0.1496
2024-05-25 04:52:21 [INFO]: Epoch 110 - training loss: 0.2262, validation loss: 0.1492
2024-05-25 04:52:22 [INFO]: Epoch 111 - training loss: 0.2248, validation loss: 0.1488
2024-05-25 04:52:23 [INFO]: Epoch 112 - training loss: 0.2246, validation loss: 0.1482
2024-05-25 04:52:23 [INFO]: Epoch 113 - training loss: 0.2235, validation loss: 0.1481
2024-05-25 04:52:24 [INFO]: Epoch 114 - training loss: 0.2224, validation loss: 0.1481
2024-05-25 04:52:24 [INFO]: Epoch 115 - training loss: 0.2222, validation loss: 0.1485
2024-05-25 04:52:25 [INFO]: Epoch 116 - training loss: 0.2220, validation loss: 0.1476
2024-05-25 04:52:26 [INFO]: Epoch 117 - training loss: 0.2228, validation loss: 0.1500
2024-05-25 04:52:26 [INFO]: Epoch 118 - training loss: 0.2222, validation loss: 0.1472
2024-05-25 04:52:27 [INFO]: Epoch 119 - training loss: 0.2216, validation loss: 0.1469
2024-05-25 04:52:27 [INFO]: Epoch 120 - training loss: 0.2204, validation loss: 0.1467
2024-05-25 04:52:28 [INFO]: Epoch 121 - training loss: 0.2199, validation loss: 0.1483
2024-05-25 04:52:29 [INFO]: Epoch 122 - training loss: 0.2198, validation loss: 0.1459
2024-05-25 04:52:29 [INFO]: Epoch 123 - training loss: 0.2183, validation loss: 0.1471
2024-05-25 04:52:30 [INFO]: Epoch 124 - training loss: 0.2176, validation loss: 0.1459
2024-05-25 04:52:30 [INFO]: Epoch 125 - training loss: 0.2172, validation loss: 0.1468
2024-05-25 04:52:31 [INFO]: Epoch 126 - training loss: 0.2164, validation loss: 0.1455
2024-05-25 04:52:32 [INFO]: Epoch 127 - training loss: 0.2163, validation loss: 0.1462
2024-05-25 04:52:32 [INFO]: Epoch 128 - training loss: 0.2158, validation loss: 0.1458
2024-05-25 04:52:33 [INFO]: Epoch 129 - training loss: 0.2153, validation loss: 0.1465
2024-05-25 04:52:33 [INFO]: Epoch 130 - training loss: 0.2158, validation loss: 0.1460
2024-05-25 04:52:34 [INFO]: Epoch 131 - training loss: 0.2175, validation loss: 0.1460
2024-05-25 04:52:35 [INFO]: Epoch 132 - training loss: 0.2161, validation loss: 0.1442
2024-05-25 04:52:35 [INFO]: Epoch 133 - training loss: 0.2136, validation loss: 0.1440
2024-05-25 04:52:36 [INFO]: Epoch 134 - training loss: 0.2136, validation loss: 0.1443
2024-05-25 04:52:36 [INFO]: Epoch 135 - training loss: 0.2129, validation loss: 0.1436
2024-05-25 04:52:37 [INFO]: Epoch 136 - training loss: 0.2117, validation loss: 0.1438
2024-05-25 04:52:38 [INFO]: Epoch 137 - training loss: 0.2124, validation loss: 0.1433
2024-05-25 04:52:38 [INFO]: Epoch 138 - training loss: 0.2109, validation loss: 0.1439
2024-05-25 04:52:39 [INFO]: Epoch 139 - training loss: 0.2111, validation loss: 0.1423
2024-05-25 04:52:39 [INFO]: Epoch 140 - training loss: 0.2116, validation loss: 0.1438
2024-05-25 04:52:40 [INFO]: Epoch 141 - training loss: 0.2123, validation loss: 0.1430
2024-05-25 04:52:41 [INFO]: Epoch 142 - training loss: 0.2113, validation loss: 0.1426
2024-05-25 04:52:41 [INFO]: Epoch 143 - training loss: 0.2092, validation loss: 0.1425
2024-05-25 04:52:42 [INFO]: Epoch 144 - training loss: 0.2086, validation loss: 0.1439
2024-05-25 04:52:42 [INFO]: Epoch 145 - training loss: 0.2106, validation loss: 0.1438
2024-05-25 04:52:43 [INFO]: Epoch 146 - training loss: 0.2107, validation loss: 0.1437
2024-05-25 04:52:44 [INFO]: Epoch 147 - training loss: 0.2083, validation loss: 0.1420
2024-05-25 04:52:44 [INFO]: Epoch 148 - training loss: 0.2078, validation loss: 0.1427
2024-05-25 04:52:45 [INFO]: Epoch 149 - training loss: 0.2065, validation loss: 0.1423
2024-05-25 04:52:45 [INFO]: Epoch 150 - training loss: 0.2059, validation loss: 0.1451
2024-05-25 04:52:46 [INFO]: Epoch 151 - training loss: 0.2070, validation loss: 0.1427
2024-05-25 04:52:47 [INFO]: Epoch 152 - training loss: 0.2049, validation loss: 0.1423
2024-05-25 04:52:47 [INFO]: Epoch 153 - training loss: 0.2044, validation loss: 0.1418
2024-05-25 04:52:48 [INFO]: Epoch 154 - training loss: 0.2039, validation loss: 0.1417
2024-05-25 04:52:48 [INFO]: Epoch 155 - training loss: 0.2029, validation loss: 0.1408
2024-05-25 04:52:49 [INFO]: Epoch 156 - training loss: 0.2027, validation loss: 0.1410
2024-05-25 04:52:50 [INFO]: Epoch 157 - training loss: 0.2037, validation loss: 0.1404
2024-05-25 04:52:50 [INFO]: Epoch 158 - training loss: 0.2023, validation loss: 0.1422
2024-05-25 04:52:51 [INFO]: Epoch 159 - training loss: 0.2018, validation loss: 0.1414
2024-05-25 04:52:51 [INFO]: Epoch 160 - training loss: 0.2023, validation loss: 0.1413
2024-05-25 04:52:52 [INFO]: Epoch 161 - training loss: 0.2012, validation loss: 0.1412
2024-05-25 04:52:53 [INFO]: Epoch 162 - training loss: 0.2002, validation loss: 0.1411
2024-05-25 04:52:53 [INFO]: Epoch 163 - training loss: 0.2016, validation loss: 0.1415
2024-05-25 04:52:54 [INFO]: Epoch 164 - training loss: 0.2026, validation loss: 0.1405
2024-05-25 04:52:54 [INFO]: Epoch 165 - training loss: 0.2010, validation loss: 0.1414
2024-05-25 04:52:55 [INFO]: Epoch 166 - training loss: 0.2004, validation loss: 0.1402
2024-05-25 04:52:56 [INFO]: Epoch 167 - training loss: 0.2001, validation loss: 0.1401
2024-05-25 04:52:56 [INFO]: Epoch 168 - training loss: 0.1982, validation loss: 0.1393
2024-05-25 04:52:57 [INFO]: Epoch 169 - training loss: 0.1976, validation loss: 0.1403
2024-05-25 04:52:57 [INFO]: Epoch 170 - training loss: 0.1973, validation loss: 0.1404
2024-05-25 04:52:58 [INFO]: Epoch 171 - training loss: 0.1984, validation loss: 0.1413
2024-05-25 04:52:59 [INFO]: Epoch 172 - training loss: 0.1969, validation loss: 0.1397
2024-05-25 04:52:59 [INFO]: Epoch 173 - training loss: 0.1980, validation loss: 0.1411
2024-05-25 04:53:00 [INFO]: Epoch 174 - training loss: 0.1970, validation loss: 0.1392
2024-05-25 04:53:00 [INFO]: Epoch 175 - training loss: 0.1958, validation loss: 0.1402
2024-05-25 04:53:01 [INFO]: Epoch 176 - training loss: 0.1957, validation loss: 0.1392
2024-05-25 04:53:02 [INFO]: Epoch 177 - training loss: 0.1952, validation loss: 0.1384
2024-05-25 04:53:02 [INFO]: Epoch 178 - training loss: 0.1944, validation loss: 0.1383
2024-05-25 04:53:03 [INFO]: Epoch 179 - training loss: 0.1942, validation loss: 0.1391
2024-05-25 04:53:03 [INFO]: Epoch 180 - training loss: 0.1938, validation loss: 0.1385
2024-05-25 04:53:04 [INFO]: Epoch 181 - training loss: 0.1928, validation loss: 0.1397
2024-05-25 04:53:05 [INFO]: Epoch 182 - training loss: 0.1944, validation loss: 0.1397
2024-05-25 04:53:05 [INFO]: Epoch 183 - training loss: 0.1944, validation loss: 0.1405
2024-05-25 04:53:06 [INFO]: Epoch 184 - training loss: 0.1965, validation loss: 0.1411
2024-05-25 04:53:07 [INFO]: Epoch 185 - training loss: 0.1964, validation loss: 0.1394
2024-05-25 04:53:07 [INFO]: Epoch 186 - training loss: 0.1944, validation loss: 0.1394
2024-05-25 04:53:08 [INFO]: Epoch 187 - training loss: 0.1929, validation loss: 0.1381
2024-05-25 04:53:08 [INFO]: Epoch 188 - training loss: 0.1911, validation loss: 0.1392
2024-05-25 04:53:09 [INFO]: Epoch 189 - training loss: 0.1910, validation loss: 0.1389
2024-05-25 04:53:10 [INFO]: Epoch 190 - training loss: 0.1907, validation loss: 0.1383
2024-05-25 04:53:10 [INFO]: Epoch 191 - training loss: 0.1901, validation loss: 0.1380
2024-05-25 04:53:11 [INFO]: Epoch 192 - training loss: 0.1900, validation loss: 0.1381
2024-05-25 04:53:11 [INFO]: Epoch 193 - training loss: 0.1902, validation loss: 0.1385
2024-05-25 04:53:12 [INFO]: Epoch 194 - training loss: 0.1907, validation loss: 0.1381
2024-05-25 04:53:13 [INFO]: Epoch 195 - training loss: 0.1890, validation loss: 0.1387
2024-05-25 04:53:13 [INFO]: Epoch 196 - training loss: 0.1881, validation loss: 0.1372
2024-05-25 04:53:14 [INFO]: Epoch 197 - training loss: 0.1891, validation loss: 0.1382
2024-05-25 04:53:14 [INFO]: Epoch 198 - training loss: 0.1886, validation loss: 0.1381
2024-05-25 04:53:15 [INFO]: Epoch 199 - training loss: 0.1879, validation loss: 0.1390
2024-05-25 04:53:16 [INFO]: Epoch 200 - training loss: 0.1881, validation loss: 0.1376
2024-05-25 04:53:16 [INFO]: Epoch 201 - training loss: 0.1875, validation loss: 0.1379
2024-05-25 04:53:17 [INFO]: Epoch 202 - training loss: 0.1874, validation loss: 0.1387
2024-05-25 04:53:17 [INFO]: Epoch 203 - training loss: 0.1864, validation loss: 0.1374
2024-05-25 04:53:18 [INFO]: Epoch 204 - training loss: 0.1858, validation loss: 0.1380
2024-05-25 04:53:19 [INFO]: Epoch 205 - training loss: 0.1852, validation loss: 0.1375
2024-05-25 04:53:19 [INFO]: Epoch 206 - training loss: 0.1856, validation loss: 0.1381
2024-05-25 04:53:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:53:19 [INFO]: Finished training. The best model is from epoch#196.
2024-05-25 04:53:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_air_quality/20240525_T045115/SAITS.pypots
2024-05-25 04:53:19 [INFO]: SAITS on Air-Quality: MAE=0.1571, MSE=0.1444
2024-05-25 04:53:19 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_air_quality/imputation.pkl
2024-05-25 04:53:19 [INFO]: Using the given device: cuda:0
2024-05-25 04:53:19 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240525_T045319
2024-05-25 04:53:19 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240525_T045319/tensorboard
2024-05-25 04:53:19 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 04:53:20 [INFO]: Epoch 001 - training loss: 0.9129, validation loss: 0.5015
2024-05-25 04:53:20 [INFO]: Epoch 002 - training loss: 0.5812, validation loss: 0.3892
2024-05-25 04:53:20 [INFO]: Epoch 003 - training loss: 0.4893, validation loss: 0.3202
2024-05-25 04:53:20 [INFO]: Epoch 004 - training loss: 0.4395, validation loss: 0.2876
2024-05-25 04:53:21 [INFO]: Epoch 005 - training loss: 0.4114, validation loss: 0.2727
2024-05-25 04:53:21 [INFO]: Epoch 006 - training loss: 0.3915, validation loss: 0.2598
2024-05-25 04:53:21 [INFO]: Epoch 007 - training loss: 0.3762, validation loss: 0.2546
2024-05-25 04:53:21 [INFO]: Epoch 008 - training loss: 0.3620, validation loss: 0.2505
2024-05-25 04:53:22 [INFO]: Epoch 009 - training loss: 0.3540, validation loss: 0.2437
2024-05-25 04:53:22 [INFO]: Epoch 010 - training loss: 0.3465, validation loss: 0.2401
2024-05-25 04:53:22 [INFO]: Epoch 011 - training loss: 0.3390, validation loss: 0.2358
2024-05-25 04:53:22 [INFO]: Epoch 012 - training loss: 0.3337, validation loss: 0.2318
2024-05-25 04:53:23 [INFO]: Epoch 013 - training loss: 0.3287, validation loss: 0.2282
2024-05-25 04:53:23 [INFO]: Epoch 014 - training loss: 0.3238, validation loss: 0.2258
2024-05-25 04:53:23 [INFO]: Epoch 015 - training loss: 0.3240, validation loss: 0.2213
2024-05-25 04:53:23 [INFO]: Epoch 016 - training loss: 0.3164, validation loss: 0.2172
2024-05-25 04:53:24 [INFO]: Epoch 017 - training loss: 0.3108, validation loss: 0.2146
2024-05-25 04:53:24 [INFO]: Epoch 018 - training loss: 0.3045, validation loss: 0.2108
2024-05-25 04:53:24 [INFO]: Epoch 019 - training loss: 0.3058, validation loss: 0.2110
2024-05-25 04:53:24 [INFO]: Epoch 020 - training loss: 0.3000, validation loss: 0.2067
2024-05-25 04:53:25 [INFO]: Epoch 021 - training loss: 0.2974, validation loss: 0.2051
2024-05-25 04:53:25 [INFO]: Epoch 022 - training loss: 0.2925, validation loss: 0.2028
2024-05-25 04:53:25 [INFO]: Epoch 023 - training loss: 0.2905, validation loss: 0.2017
2024-05-25 04:53:25 [INFO]: Epoch 024 - training loss: 0.2875, validation loss: 0.1991
2024-05-25 04:53:26 [INFO]: Epoch 025 - training loss: 0.2842, validation loss: 0.1998
2024-05-25 04:53:26 [INFO]: Epoch 026 - training loss: 0.2839, validation loss: 0.1961
2024-05-25 04:53:26 [INFO]: Epoch 027 - training loss: 0.2818, validation loss: 0.1959
2024-05-25 04:53:26 [INFO]: Epoch 028 - training loss: 0.2781, validation loss: 0.1948
2024-05-25 04:53:27 [INFO]: Epoch 029 - training loss: 0.2790, validation loss: 0.1951
2024-05-25 04:53:27 [INFO]: Epoch 030 - training loss: 0.2804, validation loss: 0.1927
2024-05-25 04:53:27 [INFO]: Epoch 031 - training loss: 0.2741, validation loss: 0.1942
2024-05-25 04:53:27 [INFO]: Epoch 032 - training loss: 0.2734, validation loss: 0.1905
2024-05-25 04:53:28 [INFO]: Epoch 033 - training loss: 0.2701, validation loss: 0.1897
2024-05-25 04:53:28 [INFO]: Epoch 034 - training loss: 0.2688, validation loss: 0.1897
2024-05-25 04:53:28 [INFO]: Epoch 035 - training loss: 0.2673, validation loss: 0.1888
2024-05-25 04:53:28 [INFO]: Epoch 036 - training loss: 0.2651, validation loss: 0.1887
2024-05-25 04:53:29 [INFO]: Epoch 037 - training loss: 0.2640, validation loss: 0.1886
2024-05-25 04:53:29 [INFO]: Epoch 038 - training loss: 0.2603, validation loss: 0.1878
2024-05-25 04:53:29 [INFO]: Epoch 039 - training loss: 0.2577, validation loss: 0.1884
2024-05-25 04:53:29 [INFO]: Epoch 040 - training loss: 0.2562, validation loss: 0.1858
2024-05-25 04:53:30 [INFO]: Epoch 041 - training loss: 0.2603, validation loss: 0.1860
2024-05-25 04:53:30 [INFO]: Epoch 042 - training loss: 0.2573, validation loss: 0.1835
2024-05-25 04:53:30 [INFO]: Epoch 043 - training loss: 0.2537, validation loss: 0.1862
2024-05-25 04:53:30 [INFO]: Epoch 044 - training loss: 0.2525, validation loss: 0.1844
2024-05-25 04:53:31 [INFO]: Epoch 045 - training loss: 0.2506, validation loss: 0.1840
2024-05-25 04:53:31 [INFO]: Epoch 046 - training loss: 0.2513, validation loss: 0.1832
2024-05-25 04:53:31 [INFO]: Epoch 047 - training loss: 0.2477, validation loss: 0.1844
2024-05-25 04:53:31 [INFO]: Epoch 048 - training loss: 0.2505, validation loss: 0.1839
2024-05-25 04:53:32 [INFO]: Epoch 049 - training loss: 0.2478, validation loss: 0.1826
2024-05-25 04:53:32 [INFO]: Epoch 050 - training loss: 0.2479, validation loss: 0.1830
2024-05-25 04:53:32 [INFO]: Epoch 051 - training loss: 0.2447, validation loss: 0.1809
2024-05-25 04:53:32 [INFO]: Epoch 052 - training loss: 0.2419, validation loss: 0.1810
2024-05-25 04:53:33 [INFO]: Epoch 053 - training loss: 0.2411, validation loss: 0.1813
2024-05-25 04:53:33 [INFO]: Epoch 054 - training loss: 0.2379, validation loss: 0.1807
2024-05-25 04:53:33 [INFO]: Epoch 055 - training loss: 0.2384, validation loss: 0.1795
2024-05-25 04:53:33 [INFO]: Epoch 056 - training loss: 0.2366, validation loss: 0.1819
2024-05-25 04:53:34 [INFO]: Epoch 057 - training loss: 0.2351, validation loss: 0.1814
2024-05-25 04:53:34 [INFO]: Epoch 058 - training loss: 0.2340, validation loss: 0.1812
2024-05-25 04:53:34 [INFO]: Epoch 059 - training loss: 0.2349, validation loss: 0.1795
2024-05-25 04:53:34 [INFO]: Epoch 060 - training loss: 0.2318, validation loss: 0.1785
2024-05-25 04:53:35 [INFO]: Epoch 061 - training loss: 0.2321, validation loss: 0.1802
2024-05-25 04:53:35 [INFO]: Epoch 062 - training loss: 0.2299, validation loss: 0.1791
2024-05-25 04:53:35 [INFO]: Epoch 063 - training loss: 0.2284, validation loss: 0.1795
2024-05-25 04:53:36 [INFO]: Epoch 064 - training loss: 0.2305, validation loss: 0.1801
2024-05-25 04:53:36 [INFO]: Epoch 065 - training loss: 0.2300, validation loss: 0.1772
2024-05-25 04:53:36 [INFO]: Epoch 066 - training loss: 0.2331, validation loss: 0.1777
2024-05-25 04:53:36 [INFO]: Epoch 067 - training loss: 0.2375, validation loss: 0.1803
2024-05-25 04:53:37 [INFO]: Epoch 068 - training loss: 0.2296, validation loss: 0.1771
2024-05-25 04:53:37 [INFO]: Epoch 069 - training loss: 0.2221, validation loss: 0.1775
2024-05-25 04:53:37 [INFO]: Epoch 070 - training loss: 0.2213, validation loss: 0.1764
2024-05-25 04:53:37 [INFO]: Epoch 071 - training loss: 0.2202, validation loss: 0.1766
2024-05-25 04:53:38 [INFO]: Epoch 072 - training loss: 0.2204, validation loss: 0.1778
2024-05-25 04:53:38 [INFO]: Epoch 073 - training loss: 0.2192, validation loss: 0.1742
2024-05-25 04:53:38 [INFO]: Epoch 074 - training loss: 0.2168, validation loss: 0.1742
2024-05-25 04:53:38 [INFO]: Epoch 075 - training loss: 0.2182, validation loss: 0.1748
2024-05-25 04:53:39 [INFO]: Epoch 076 - training loss: 0.2187, validation loss: 0.1755
2024-05-25 04:53:39 [INFO]: Epoch 077 - training loss: 0.2180, validation loss: 0.1736
2024-05-25 04:53:39 [INFO]: Epoch 078 - training loss: 0.2145, validation loss: 0.1741
2024-05-25 04:53:39 [INFO]: Epoch 079 - training loss: 0.2139, validation loss: 0.1752
2024-05-25 04:53:40 [INFO]: Epoch 080 - training loss: 0.2186, validation loss: 0.1745
2024-05-25 04:53:40 [INFO]: Epoch 081 - training loss: 0.2224, validation loss: 0.1758
2024-05-25 04:53:40 [INFO]: Epoch 082 - training loss: 0.2172, validation loss: 0.1741
2024-05-25 04:53:40 [INFO]: Epoch 083 - training loss: 0.2147, validation loss: 0.1735
2024-05-25 04:53:41 [INFO]: Epoch 084 - training loss: 0.2119, validation loss: 0.1731
2024-05-25 04:53:41 [INFO]: Epoch 085 - training loss: 0.2097, validation loss: 0.1726
2024-05-25 04:53:41 [INFO]: Epoch 086 - training loss: 0.2067, validation loss: 0.1735
2024-05-25 04:53:41 [INFO]: Epoch 087 - training loss: 0.2065, validation loss: 0.1725
2024-05-25 04:53:42 [INFO]: Epoch 088 - training loss: 0.2066, validation loss: 0.1729
2024-05-25 04:53:42 [INFO]: Epoch 089 - training loss: 0.2078, validation loss: 0.1717
2024-05-25 04:53:42 [INFO]: Epoch 090 - training loss: 0.2039, validation loss: 0.1725
2024-05-25 04:53:42 [INFO]: Epoch 091 - training loss: 0.2047, validation loss: 0.1728
2024-05-25 04:53:43 [INFO]: Epoch 092 - training loss: 0.2037, validation loss: 0.1715
2024-05-25 04:53:43 [INFO]: Epoch 093 - training loss: 0.2020, validation loss: 0.1702
2024-05-25 04:53:43 [INFO]: Epoch 094 - training loss: 0.2026, validation loss: 0.1706
2024-05-25 04:53:43 [INFO]: Epoch 095 - training loss: 0.2010, validation loss: 0.1715
2024-05-25 04:53:44 [INFO]: Epoch 096 - training loss: 0.2002, validation loss: 0.1711
2024-05-25 04:53:44 [INFO]: Epoch 097 - training loss: 0.1993, validation loss: 0.1697
2024-05-25 04:53:44 [INFO]: Epoch 098 - training loss: 0.1979, validation loss: 0.1712
2024-05-25 04:53:44 [INFO]: Epoch 099 - training loss: 0.1962, validation loss: 0.1692
2024-05-25 04:53:45 [INFO]: Epoch 100 - training loss: 0.2002, validation loss: 0.1709
2024-05-25 04:53:45 [INFO]: Epoch 101 - training loss: 0.2026, validation loss: 0.1705
2024-05-25 04:53:45 [INFO]: Epoch 102 - training loss: 0.1972, validation loss: 0.1710
2024-05-25 04:53:45 [INFO]: Epoch 103 - training loss: 0.2000, validation loss: 0.1705
2024-05-25 04:53:46 [INFO]: Epoch 104 - training loss: 0.1970, validation loss: 0.1690
2024-05-25 04:53:46 [INFO]: Epoch 105 - training loss: 0.1967, validation loss: 0.1720
2024-05-25 04:53:46 [INFO]: Epoch 106 - training loss: 0.1995, validation loss: 0.1686
2024-05-25 04:53:46 [INFO]: Epoch 107 - training loss: 0.1947, validation loss: 0.1700
2024-05-25 04:53:47 [INFO]: Epoch 108 - training loss: 0.1947, validation loss: 0.1695
2024-05-25 04:53:47 [INFO]: Epoch 109 - training loss: 0.1914, validation loss: 0.1688
2024-05-25 04:53:47 [INFO]: Epoch 110 - training loss: 0.1914, validation loss: 0.1726
2024-05-25 04:53:47 [INFO]: Epoch 111 - training loss: 0.1937, validation loss: 0.1676
2024-05-25 04:53:48 [INFO]: Epoch 112 - training loss: 0.1971, validation loss: 0.1736
2024-05-25 04:53:48 [INFO]: Epoch 113 - training loss: 0.1928, validation loss: 0.1686
2024-05-25 04:53:48 [INFO]: Epoch 114 - training loss: 0.1886, validation loss: 0.1694
2024-05-25 04:53:48 [INFO]: Epoch 115 - training loss: 0.1885, validation loss: 0.1659
2024-05-25 04:53:49 [INFO]: Epoch 116 - training loss: 0.1872, validation loss: 0.1689
2024-05-25 04:53:49 [INFO]: Epoch 117 - training loss: 0.1884, validation loss: 0.1686
2024-05-25 04:53:49 [INFO]: Epoch 118 - training loss: 0.1859, validation loss: 0.1674
2024-05-25 04:53:49 [INFO]: Epoch 119 - training loss: 0.1846, validation loss: 0.1669
2024-05-25 04:53:50 [INFO]: Epoch 120 - training loss: 0.1837, validation loss: 0.1680
2024-05-25 04:53:50 [INFO]: Epoch 121 - training loss: 0.1826, validation loss: 0.1683
2024-05-25 04:53:50 [INFO]: Epoch 122 - training loss: 0.1829, validation loss: 0.1681
2024-05-25 04:53:50 [INFO]: Epoch 123 - training loss: 0.1837, validation loss: 0.1668
2024-05-25 04:53:51 [INFO]: Epoch 124 - training loss: 0.1844, validation loss: 0.1650
2024-05-25 04:53:51 [INFO]: Epoch 125 - training loss: 0.1858, validation loss: 0.1689
2024-05-25 04:53:51 [INFO]: Epoch 126 - training loss: 0.1838, validation loss: 0.1673
2024-05-25 04:53:51 [INFO]: Epoch 127 - training loss: 0.1808, validation loss: 0.1672
2024-05-25 04:53:52 [INFO]: Epoch 128 - training loss: 0.1802, validation loss: 0.1662
2024-05-25 04:53:52 [INFO]: Epoch 129 - training loss: 0.1831, validation loss: 0.1655
2024-05-25 04:53:52 [INFO]: Epoch 130 - training loss: 0.1832, validation loss: 0.1687
2024-05-25 04:53:52 [INFO]: Epoch 131 - training loss: 0.1817, validation loss: 0.1657
2024-05-25 04:53:53 [INFO]: Epoch 132 - training loss: 0.1780, validation loss: 0.1652
2024-05-25 04:53:53 [INFO]: Epoch 133 - training loss: 0.1794, validation loss: 0.1663
2024-05-25 04:53:53 [INFO]: Epoch 134 - training loss: 0.1823, validation loss: 0.1687
2024-05-25 04:53:53 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:53:53 [INFO]: Finished training. The best model is from epoch#124.
2024-05-25 04:53:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_air_quality/20240525_T045319/Transformer.pypots
2024-05-25 04:53:53 [INFO]: Transformer on Air-Quality: MAE=0.1846, MSE=0.1724
2024-05-25 04:53:53 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_air_quality/imputation.pkl
2024-05-25 04:53:53 [INFO]: Using the given device: cuda:0
2024-05-25 04:53:53 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240525_T045353
2024-05-25 04:53:53 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240525_T045353/tensorboard
2024-05-25 04:53:54 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 04:53:54 [INFO]: Epoch 001 - training loss: 0.2814, validation loss: 0.2670
2024-05-25 04:53:55 [INFO]: Epoch 002 - training loss: 0.2086, validation loss: 0.2506
2024-05-25 04:53:55 [INFO]: Epoch 003 - training loss: 0.1857, validation loss: 0.2279
2024-05-25 04:53:55 [INFO]: Epoch 004 - training loss: 0.1606, validation loss: 0.2127
2024-05-25 04:53:56 [INFO]: Epoch 005 - training loss: 0.1453, validation loss: 0.2042
2024-05-25 04:53:56 [INFO]: Epoch 006 - training loss: 0.1359, validation loss: 0.2027
2024-05-25 04:53:57 [INFO]: Epoch 007 - training loss: 0.1405, validation loss: 0.2021
2024-05-25 04:53:57 [INFO]: Epoch 008 - training loss: 0.1407, validation loss: 0.1961
2024-05-25 04:53:58 [INFO]: Epoch 009 - training loss: 0.1282, validation loss: 0.1981
2024-05-25 04:53:58 [INFO]: Epoch 010 - training loss: 0.1211, validation loss: 0.1919
2024-05-25 04:53:59 [INFO]: Epoch 011 - training loss: 0.1206, validation loss: 0.1896
2024-05-25 04:53:59 [INFO]: Epoch 012 - training loss: 0.1140, validation loss: 0.1889
2024-05-25 04:54:00 [INFO]: Epoch 013 - training loss: 0.1129, validation loss: 0.2146
2024-05-25 04:54:00 [INFO]: Epoch 014 - training loss: 0.1133, validation loss: 0.1845
2024-05-25 04:54:00 [INFO]: Epoch 015 - training loss: 0.1086, validation loss: 0.1844
2024-05-25 04:54:01 [INFO]: Epoch 016 - training loss: 0.1012, validation loss: 0.1879
2024-05-25 04:54:01 [INFO]: Epoch 017 - training loss: 0.0976, validation loss: 0.1869
2024-05-25 04:54:02 [INFO]: Epoch 018 - training loss: 0.0971, validation loss: 0.1891
2024-05-25 04:54:02 [INFO]: Epoch 019 - training loss: 0.0926, validation loss: 0.1921
2024-05-25 04:54:03 [INFO]: Epoch 020 - training loss: 0.0899, validation loss: 0.1868
2024-05-25 04:54:03 [INFO]: Epoch 021 - training loss: 0.0884, validation loss: 0.1948
2024-05-25 04:54:04 [INFO]: Epoch 022 - training loss: 0.0873, validation loss: 0.1893
2024-05-25 04:54:04 [INFO]: Epoch 023 - training loss: 0.0877, validation loss: 0.1949
2024-05-25 04:54:05 [INFO]: Epoch 024 - training loss: 0.0872, validation loss: 0.1921
2024-05-25 04:54:05 [INFO]: Epoch 025 - training loss: 0.0918, validation loss: 0.1922
2024-05-25 04:54:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 04:54:05 [INFO]: Finished training. The best model is from epoch#15.
2024-05-25 04:54:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_air_quality/20240525_T045353/TimesNet.pypots
2024-05-25 04:54:05 [INFO]: TimesNet on Air-Quality: MAE=0.1732, MSE=0.2175
2024-05-25 04:54:05 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_air_quality/imputation.pkl
2024-05-25 04:54:05 [INFO]: Using the given device: cuda:0
2024-05-25 04:54:05 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405
2024-05-25 04:54:05 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/tensorboard
2024-05-25 04:54:05 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 04:54:22 [INFO]: Epoch 001 - training loss: 0.4962, validation loss: 0.3740
2024-05-25 04:54:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch1_loss0.37402051985263823.pypots
2024-05-25 04:54:39 [INFO]: Epoch 002 - training loss: 0.3095, validation loss: 0.2787
2024-05-25 04:54:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch2_loss0.2787397265434265.pypots
2024-05-25 04:54:55 [INFO]: Epoch 003 - training loss: 0.2616, validation loss: 0.2349
2024-05-25 04:54:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch3_loss0.23489891439676286.pypots
2024-05-25 04:55:12 [INFO]: Epoch 004 - training loss: 0.2322, validation loss: 0.2130
2024-05-25 04:55:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch4_loss0.21296179592609404.pypots
2024-05-25 04:55:29 [INFO]: Epoch 005 - training loss: 0.2124, validation loss: 0.2021
2024-05-25 04:55:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch5_loss0.2020635649561882.pypots
2024-05-25 04:55:45 [INFO]: Epoch 006 - training loss: 0.1872, validation loss: 0.1730
2024-05-25 04:55:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch6_loss0.172961588203907.pypots
2024-05-25 04:56:02 [INFO]: Epoch 007 - training loss: 0.1768, validation loss: 0.1676
2024-05-25 04:56:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch7_loss0.1675666481256485.pypots
2024-05-25 04:56:19 [INFO]: Epoch 008 - training loss: 0.1675, validation loss: 0.1634
2024-05-25 04:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch8_loss0.16336604207754135.pypots
2024-05-25 04:56:35 [INFO]: Epoch 009 - training loss: 0.1669, validation loss: 0.1544
2024-05-25 04:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch9_loss0.15439844876527786.pypots
2024-05-25 04:56:52 [INFO]: Epoch 010 - training loss: 0.1586, validation loss: 0.1514
2024-05-25 04:56:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch10_loss0.15139818340539932.pypots
2024-05-25 04:57:09 [INFO]: Epoch 011 - training loss: 0.1545, validation loss: 0.1494
2024-05-25 04:57:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch11_loss0.14938988238573075.pypots
2024-05-25 04:57:25 [INFO]: Epoch 012 - training loss: 0.1496, validation loss: 0.1494
2024-05-25 04:57:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch12_loss0.1494329407811165.pypots
2024-05-25 04:57:42 [INFO]: Epoch 013 - training loss: 0.1675, validation loss: 0.1463
2024-05-25 04:57:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch13_loss0.14626744836568834.pypots
2024-05-25 04:57:59 [INFO]: Epoch 014 - training loss: 0.1485, validation loss: 0.1428
2024-05-25 04:57:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch14_loss0.14278883635997772.pypots
2024-05-25 04:58:15 [INFO]: Epoch 015 - training loss: 0.1507, validation loss: 0.1394
2024-05-25 04:58:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch15_loss0.13936199694871904.pypots
2024-05-25 04:58:32 [INFO]: Epoch 016 - training loss: 0.1537, validation loss: 0.1432
2024-05-25 04:58:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch16_loss0.1432349279522896.pypots
2024-05-25 04:58:49 [INFO]: Epoch 017 - training loss: 0.1548, validation loss: 0.1392
2024-05-25 04:58:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch17_loss0.13919344171881676.pypots
2024-05-25 04:59:05 [INFO]: Epoch 018 - training loss: 0.1484, validation loss: 0.1438
2024-05-25 04:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch18_loss0.14378467351198196.pypots
2024-05-25 04:59:22 [INFO]: Epoch 019 - training loss: 0.1353, validation loss: 0.1380
2024-05-25 04:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch19_loss0.1379796639084816.pypots
2024-05-25 04:59:39 [INFO]: Epoch 020 - training loss: 0.1477, validation loss: 0.1341
2024-05-25 04:59:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch20_loss0.1340617500245571.pypots
2024-05-25 04:59:56 [INFO]: Epoch 021 - training loss: 0.1397, validation loss: 0.1334
2024-05-25 04:59:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch21_loss0.13336070924997329.pypots
2024-05-25 05:00:12 [INFO]: Epoch 022 - training loss: 0.1234, validation loss: 0.1317
2024-05-25 05:00:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch22_loss0.1317367322742939.pypots
2024-05-25 05:00:29 [INFO]: Epoch 023 - training loss: 0.1358, validation loss: 0.1315
2024-05-25 05:00:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch23_loss0.13154739513993263.pypots
2024-05-25 05:00:46 [INFO]: Epoch 024 - training loss: 0.1364, validation loss: 0.1316
2024-05-25 05:00:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch24_loss0.13159383535385133.pypots
2024-05-25 05:01:02 [INFO]: Epoch 025 - training loss: 0.1419, validation loss: 0.1354
2024-05-25 05:01:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch25_loss0.13540151119232177.pypots
2024-05-25 05:01:19 [INFO]: Epoch 026 - training loss: 0.1280, validation loss: 0.1294
2024-05-25 05:01:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch26_loss0.12937839701771736.pypots
2024-05-25 05:01:36 [INFO]: Epoch 027 - training loss: 0.1233, validation loss: 0.1366
2024-05-25 05:01:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch27_loss0.13658776506781578.pypots
2024-05-25 05:01:52 [INFO]: Epoch 028 - training loss: 0.1418, validation loss: 0.1294
2024-05-25 05:01:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch28_loss0.12936698272824287.pypots
2024-05-25 05:02:09 [INFO]: Epoch 029 - training loss: 0.1296, validation loss: 0.1335
2024-05-25 05:02:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch29_loss0.1334884613752365.pypots
2024-05-25 05:02:26 [INFO]: Epoch 030 - training loss: 0.1325, validation loss: 0.1270
2024-05-25 05:02:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch30_loss0.12704007253050803.pypots
2024-05-25 05:02:42 [INFO]: Epoch 031 - training loss: 0.1174, validation loss: 0.1290
2024-05-25 05:02:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch31_loss0.1289506658911705.pypots
2024-05-25 05:02:59 [INFO]: Epoch 032 - training loss: 0.1237, validation loss: 0.1252
2024-05-25 05:02:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch32_loss0.12523804157972335.pypots
2024-05-25 05:03:16 [INFO]: Epoch 033 - training loss: 0.1101, validation loss: 0.1266
2024-05-25 05:03:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch33_loss0.12655680477619172.pypots
2024-05-25 05:03:32 [INFO]: Epoch 034 - training loss: 0.1191, validation loss: 0.1246
2024-05-25 05:03:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch34_loss0.12459087669849396.pypots
2024-05-25 05:03:49 [INFO]: Epoch 035 - training loss: 0.1190, validation loss: 0.1253
2024-05-25 05:03:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch35_loss0.12532153353095055.pypots
2024-05-25 05:04:06 [INFO]: Epoch 036 - training loss: 0.1220, validation loss: 0.1312
2024-05-25 05:04:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch36_loss0.13120626732707025.pypots
2024-05-25 05:04:22 [INFO]: Epoch 037 - training loss: 0.1207, validation loss: 0.1222
2024-05-25 05:04:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch37_loss0.12224508449435234.pypots
2024-05-25 05:04:39 [INFO]: Epoch 038 - training loss: 0.1145, validation loss: 0.1221
2024-05-25 05:04:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch38_loss0.12206186205148697.pypots
2024-05-25 05:04:56 [INFO]: Epoch 039 - training loss: 0.1273, validation loss: 0.1201
2024-05-25 05:04:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch39_loss0.12008559107780456.pypots
2024-05-25 05:05:12 [INFO]: Epoch 040 - training loss: 0.1165, validation loss: 0.1192
2024-05-25 05:05:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch40_loss0.11921996474266053.pypots
2024-05-25 05:05:29 [INFO]: Epoch 041 - training loss: 0.1015, validation loss: 0.1168
2024-05-25 05:05:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch41_loss0.116781085729599.pypots
2024-05-25 05:05:46 [INFO]: Epoch 042 - training loss: 0.1203, validation loss: 0.1164
2024-05-25 05:05:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch42_loss0.11644229739904403.pypots
2024-05-25 05:06:02 [INFO]: Epoch 043 - training loss: 0.1192, validation loss: 0.1163
2024-05-25 05:06:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch43_loss0.11632338687777519.pypots
2024-05-25 05:06:19 [INFO]: Epoch 044 - training loss: 0.1182, validation loss: 0.1163
2024-05-25 05:06:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch44_loss0.11627188771963119.pypots
2024-05-25 05:06:36 [INFO]: Epoch 045 - training loss: 0.1161, validation loss: 0.1175
2024-05-25 05:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch45_loss0.11750707253813744.pypots
2024-05-25 05:06:52 [INFO]: Epoch 046 - training loss: 0.1228, validation loss: 0.1157
2024-05-25 05:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch46_loss0.11566723510622978.pypots
2024-05-25 05:07:09 [INFO]: Epoch 047 - training loss: 0.1081, validation loss: 0.1121
2024-05-25 05:07:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch47_loss0.11212230771780014.pypots
2024-05-25 05:07:26 [INFO]: Epoch 048 - training loss: 0.1080, validation loss: 0.1137
2024-05-25 05:07:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch48_loss0.1136543944478035.pypots
2024-05-25 05:07:42 [INFO]: Epoch 049 - training loss: 0.1130, validation loss: 0.1180
2024-05-25 05:07:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch49_loss0.11798763796687126.pypots
2024-05-25 05:07:59 [INFO]: Epoch 050 - training loss: 0.1246, validation loss: 0.1180
2024-05-25 05:07:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch50_loss0.11804268434643746.pypots
2024-05-25 05:08:16 [INFO]: Epoch 051 - training loss: 0.0976, validation loss: 0.1104
2024-05-25 05:08:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch51_loss0.11035795509815216.pypots
2024-05-25 05:08:32 [INFO]: Epoch 052 - training loss: 0.1223, validation loss: 0.1147
2024-05-25 05:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch52_loss0.11473127901554107.pypots
2024-05-25 05:08:49 [INFO]: Epoch 053 - training loss: 0.1189, validation loss: 0.1111
2024-05-25 05:08:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch53_loss0.11110708490014076.pypots
2024-05-25 05:09:06 [INFO]: Epoch 054 - training loss: 0.1171, validation loss: 0.1119
2024-05-25 05:09:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch54_loss0.11193654611706734.pypots
2024-05-25 05:09:22 [INFO]: Epoch 055 - training loss: 0.1121, validation loss: 0.1100
2024-05-25 05:09:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch55_loss0.10998475402593613.pypots
2024-05-25 05:09:39 [INFO]: Epoch 056 - training loss: 0.1034, validation loss: 0.1113
2024-05-25 05:09:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch56_loss0.1113443098962307.pypots
2024-05-25 05:09:56 [INFO]: Epoch 057 - training loss: 0.1109, validation loss: 0.1126
2024-05-25 05:09:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch57_loss0.11259917989373207.pypots
2024-05-25 05:10:12 [INFO]: Epoch 058 - training loss: 0.1104, validation loss: 0.1168
2024-05-25 05:10:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch58_loss0.11676533594727516.pypots
2024-05-25 05:10:29 [INFO]: Epoch 059 - training loss: 0.1017, validation loss: 0.1102
2024-05-25 05:10:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch59_loss0.11015402600169182.pypots
2024-05-25 05:10:46 [INFO]: Epoch 060 - training loss: 0.1044, validation loss: 0.1126
2024-05-25 05:10:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch60_loss0.11258777305483818.pypots
2024-05-25 05:11:03 [INFO]: Epoch 061 - training loss: 0.1082, validation loss: 0.1085
2024-05-25 05:11:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch61_loss0.10847502946853638.pypots
2024-05-25 05:11:19 [INFO]: Epoch 062 - training loss: 0.1064, validation loss: 0.1073
2024-05-25 05:11:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch62_loss0.10729648098349572.pypots
2024-05-25 05:11:36 [INFO]: Epoch 063 - training loss: 0.1064, validation loss: 0.1088
2024-05-25 05:11:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch63_loss0.10876461565494537.pypots
2024-05-25 05:11:53 [INFO]: Epoch 064 - training loss: 0.1151, validation loss: 0.1063
2024-05-25 05:11:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch64_loss0.106285610049963.pypots
2024-05-25 05:12:09 [INFO]: Epoch 065 - training loss: 0.1099, validation loss: 0.1112
2024-05-25 05:12:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch65_loss0.11121716648340225.pypots
2024-05-25 05:12:26 [INFO]: Epoch 066 - training loss: 0.1153, validation loss: 0.1073
2024-05-25 05:12:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch66_loss0.10726511105895042.pypots
2024-05-25 05:12:43 [INFO]: Epoch 067 - training loss: 0.1050, validation loss: 0.1101
2024-05-25 05:12:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch67_loss0.1100516065955162.pypots
2024-05-25 05:12:59 [INFO]: Epoch 068 - training loss: 0.1013, validation loss: 0.1115
2024-05-25 05:12:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch68_loss0.11149231269955635.pypots
2024-05-25 05:13:16 [INFO]: Epoch 069 - training loss: 0.1071, validation loss: 0.1096
2024-05-25 05:13:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch69_loss0.10957148000597954.pypots
2024-05-25 05:13:33 [INFO]: Epoch 070 - training loss: 0.1023, validation loss: 0.1058
2024-05-25 05:13:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch70_loss0.1057776466012001.pypots
2024-05-25 05:13:49 [INFO]: Epoch 071 - training loss: 0.1168, validation loss: 0.1071
2024-05-25 05:13:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch71_loss0.10710943192243576.pypots
2024-05-25 05:14:06 [INFO]: Epoch 072 - training loss: 0.1063, validation loss: 0.1062
2024-05-25 05:14:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch72_loss0.10619213283061982.pypots
2024-05-25 05:14:23 [INFO]: Epoch 073 - training loss: 0.0942, validation loss: 0.1071
2024-05-25 05:14:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch73_loss0.10714536532759666.pypots
2024-05-25 05:14:39 [INFO]: Epoch 074 - training loss: 0.1107, validation loss: 0.1052
2024-05-25 05:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch74_loss0.10518601685762405.pypots
2024-05-25 05:14:56 [INFO]: Epoch 075 - training loss: 0.0995, validation loss: 0.1068
2024-05-25 05:14:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch75_loss0.10680124685168266.pypots
2024-05-25 05:15:13 [INFO]: Epoch 076 - training loss: 0.0950, validation loss: 0.1057
2024-05-25 05:15:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch76_loss0.10569710060954093.pypots
2024-05-25 05:15:29 [INFO]: Epoch 077 - training loss: 0.1160, validation loss: 0.1070
2024-05-25 05:15:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch77_loss0.1069753773510456.pypots
2024-05-25 05:15:46 [INFO]: Epoch 078 - training loss: 0.1179, validation loss: 0.1081
2024-05-25 05:15:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch78_loss0.1080965019762516.pypots
2024-05-25 05:16:03 [INFO]: Epoch 079 - training loss: 0.0982, validation loss: 0.1046
2024-05-25 05:16:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch79_loss0.1046372227370739.pypots
2024-05-25 05:16:19 [INFO]: Epoch 080 - training loss: 0.1006, validation loss: 0.1055
2024-05-25 05:16:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch80_loss0.10548237711191177.pypots
2024-05-25 05:16:36 [INFO]: Epoch 081 - training loss: 0.1088, validation loss: 0.1065
2024-05-25 05:16:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch81_loss0.10645237639546394.pypots
2024-05-25 05:16:53 [INFO]: Epoch 082 - training loss: 0.1030, validation loss: 0.1053
2024-05-25 05:16:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch82_loss0.10527951642870903.pypots
2024-05-25 05:17:09 [INFO]: Epoch 083 - training loss: 0.1138, validation loss: 0.1083
2024-05-25 05:17:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch83_loss0.10828222334384918.pypots
2024-05-25 05:17:26 [INFO]: Epoch 084 - training loss: 0.1100, validation loss: 0.1048
2024-05-25 05:17:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch84_loss0.10476763397455216.pypots
2024-05-25 05:17:43 [INFO]: Epoch 085 - training loss: 0.0964, validation loss: 0.1034
2024-05-25 05:17:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch85_loss0.10341146886348725.pypots
2024-05-25 05:17:59 [INFO]: Epoch 086 - training loss: 0.1062, validation loss: 0.1052
2024-05-25 05:17:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch86_loss0.10516482964158058.pypots
2024-05-25 05:18:16 [INFO]: Epoch 087 - training loss: 0.1009, validation loss: 0.1035
2024-05-25 05:18:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch87_loss0.10345410481095314.pypots
2024-05-25 05:18:33 [INFO]: Epoch 088 - training loss: 0.1064, validation loss: 0.1069
2024-05-25 05:18:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch88_loss0.1069416031241417.pypots
2024-05-25 05:18:49 [INFO]: Epoch 089 - training loss: 0.0972, validation loss: 0.1043
2024-05-25 05:18:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch89_loss0.10427309647202491.pypots
2024-05-25 05:19:06 [INFO]: Epoch 090 - training loss: 0.1106, validation loss: 0.1043
2024-05-25 05:19:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch90_loss0.10426708906888962.pypots
2024-05-25 05:19:23 [INFO]: Epoch 091 - training loss: 0.1007, validation loss: 0.1060
2024-05-25 05:19:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch91_loss0.10604333505034447.pypots
2024-05-25 05:19:39 [INFO]: Epoch 092 - training loss: 0.0989, validation loss: 0.1030
2024-05-25 05:19:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch92_loss0.10297116041183471.pypots
2024-05-25 05:19:56 [INFO]: Epoch 093 - training loss: 0.1075, validation loss: 0.1042
2024-05-25 05:19:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch93_loss0.10420914441347122.pypots
2024-05-25 05:20:13 [INFO]: Epoch 094 - training loss: 0.0982, validation loss: 0.1041
2024-05-25 05:20:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch94_loss0.10409963652491569.pypots
2024-05-25 05:20:30 [INFO]: Epoch 095 - training loss: 0.1063, validation loss: 0.1034
2024-05-25 05:20:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch95_loss0.10337387025356293.pypots
2024-05-25 05:20:46 [INFO]: Epoch 096 - training loss: 0.1001, validation loss: 0.1044
2024-05-25 05:20:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch96_loss0.10437624230980873.pypots
2024-05-25 05:21:03 [INFO]: Epoch 097 - training loss: 0.1041, validation loss: 0.1036
2024-05-25 05:21:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch97_loss0.10355373695492745.pypots
2024-05-25 05:21:20 [INFO]: Epoch 098 - training loss: 0.1037, validation loss: 0.1028
2024-05-25 05:21:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch98_loss0.10277932807803154.pypots
2024-05-25 05:21:36 [INFO]: Epoch 099 - training loss: 0.1046, validation loss: 0.1037
2024-05-25 05:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch99_loss0.10368416160345077.pypots
2024-05-25 05:21:53 [INFO]: Epoch 100 - training loss: 0.0984, validation loss: 0.1026
2024-05-25 05:21:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch100_loss0.10258519351482391.pypots
2024-05-25 05:22:10 [INFO]: Epoch 101 - training loss: 0.0999, validation loss: 0.1034
2024-05-25 05:22:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch101_loss0.10338757038116456.pypots
2024-05-25 05:22:26 [INFO]: Epoch 102 - training loss: 0.0959, validation loss: 0.1011
2024-05-25 05:22:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch102_loss0.10114874541759492.pypots
2024-05-25 05:22:43 [INFO]: Epoch 103 - training loss: 0.0918, validation loss: 0.1021
2024-05-25 05:22:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch103_loss0.10206882432103156.pypots
2024-05-25 05:23:00 [INFO]: Epoch 104 - training loss: 0.1072, validation loss: 0.1026
2024-05-25 05:23:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch104_loss0.102642210572958.pypots
2024-05-25 05:23:16 [INFO]: Epoch 105 - training loss: 0.1089, validation loss: 0.1033
2024-05-25 05:23:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch105_loss0.1032738856971264.pypots
2024-05-25 05:23:33 [INFO]: Epoch 106 - training loss: 0.0955, validation loss: 0.1020
2024-05-25 05:23:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch106_loss0.10195865333080292.pypots
2024-05-25 05:23:50 [INFO]: Epoch 107 - training loss: 0.0933, validation loss: 0.1014
2024-05-25 05:23:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch107_loss0.10142923295497894.pypots
2024-05-25 05:24:06 [INFO]: Epoch 108 - training loss: 0.1023, validation loss: 0.1023
2024-05-25 05:24:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch108_loss0.10226801112294197.pypots
2024-05-25 05:24:23 [INFO]: Epoch 109 - training loss: 0.1005, validation loss: 0.1007
2024-05-25 05:24:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch109_loss0.10066442936658859.pypots
2024-05-25 05:24:40 [INFO]: Epoch 110 - training loss: 0.1052, validation loss: 0.1026
2024-05-25 05:24:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch110_loss0.10261770263314247.pypots
2024-05-25 05:24:56 [INFO]: Epoch 111 - training loss: 0.1025, validation loss: 0.1025
2024-05-25 05:24:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch111_loss0.1025274470448494.pypots
2024-05-25 05:25:13 [INFO]: Epoch 112 - training loss: 0.0983, validation loss: 0.1008
2024-05-25 05:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch112_loss0.10082048550248146.pypots
2024-05-25 05:25:30 [INFO]: Epoch 113 - training loss: 0.1048, validation loss: 0.1008
2024-05-25 05:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch113_loss0.10084121450781822.pypots
2024-05-25 05:25:46 [INFO]: Epoch 114 - training loss: 0.1017, validation loss: 0.1025
2024-05-25 05:25:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch114_loss0.10247894003987312.pypots
2024-05-25 05:26:03 [INFO]: Epoch 115 - training loss: 0.0972, validation loss: 0.1007
2024-05-25 05:26:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch115_loss0.10065472945570945.pypots
2024-05-25 05:26:20 [INFO]: Epoch 116 - training loss: 0.1040, validation loss: 0.0993
2024-05-25 05:26:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch116_loss0.09931074976921081.pypots
2024-05-25 05:26:36 [INFO]: Epoch 117 - training loss: 0.0900, validation loss: 0.1013
2024-05-25 05:26:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch117_loss0.10128877758979797.pypots
2024-05-25 05:26:53 [INFO]: Epoch 118 - training loss: 0.0961, validation loss: 0.0999
2024-05-25 05:26:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch118_loss0.09988216385245323.pypots
2024-05-25 05:27:10 [INFO]: Epoch 119 - training loss: 0.1013, validation loss: 0.1014
2024-05-25 05:27:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch119_loss0.1014290951192379.pypots
2024-05-25 05:27:26 [INFO]: Epoch 120 - training loss: 0.0942, validation loss: 0.1007
2024-05-25 05:27:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch120_loss0.10071923211216927.pypots
2024-05-25 05:27:43 [INFO]: Epoch 121 - training loss: 0.1044, validation loss: 0.0991
2024-05-25 05:27:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch121_loss0.09905670657753944.pypots
2024-05-25 05:28:00 [INFO]: Epoch 122 - training loss: 0.0887, validation loss: 0.0995
2024-05-25 05:28:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch122_loss0.09952916502952576.pypots
2024-05-25 05:28:16 [INFO]: Epoch 123 - training loss: 0.0890, validation loss: 0.0990
2024-05-25 05:28:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch123_loss0.098961141705513.pypots
2024-05-25 05:28:33 [INFO]: Epoch 124 - training loss: 0.1092, validation loss: 0.1037
2024-05-25 05:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch124_loss0.1037399373948574.pypots
2024-05-25 05:28:50 [INFO]: Epoch 125 - training loss: 0.0984, validation loss: 0.1011
2024-05-25 05:28:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch125_loss0.10109938457608222.pypots
2024-05-25 05:29:06 [INFO]: Epoch 126 - training loss: 0.0966, validation loss: 0.0983
2024-05-25 05:29:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch126_loss0.0982543759047985.pypots
2024-05-25 05:29:23 [INFO]: Epoch 127 - training loss: 0.0998, validation loss: 0.0991
2024-05-25 05:29:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch127_loss0.09910069480538368.pypots
2024-05-25 05:29:40 [INFO]: Epoch 128 - training loss: 0.1004, validation loss: 0.1002
2024-05-25 05:29:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch128_loss0.10019440725445747.pypots
2024-05-25 05:29:56 [INFO]: Epoch 129 - training loss: 0.1073, validation loss: 0.0994
2024-05-25 05:29:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch129_loss0.09942666068673134.pypots
2024-05-25 05:30:13 [INFO]: Epoch 130 - training loss: 0.0973, validation loss: 0.0997
2024-05-25 05:30:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch130_loss0.099729373306036.pypots
2024-05-25 05:30:30 [INFO]: Epoch 131 - training loss: 0.0998, validation loss: 0.1009
2024-05-25 05:30:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch131_loss0.10094027668237686.pypots
2024-05-25 05:30:46 [INFO]: Epoch 132 - training loss: 0.0887, validation loss: 0.1013
2024-05-25 05:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch132_loss0.10130450427532196.pypots
2024-05-25 05:31:03 [INFO]: Epoch 133 - training loss: 0.1162, validation loss: 0.1023
2024-05-25 05:31:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch133_loss0.10229596123099327.pypots
2024-05-25 05:31:20 [INFO]: Epoch 134 - training loss: 0.1007, validation loss: 0.0982
2024-05-25 05:31:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch134_loss0.09824354276061058.pypots
2024-05-25 05:31:37 [INFO]: Epoch 135 - training loss: 0.1020, validation loss: 0.0990
2024-05-25 05:31:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch135_loss0.09903022050857543.pypots
2024-05-25 05:31:53 [INFO]: Epoch 136 - training loss: 0.0915, validation loss: 0.0987
2024-05-25 05:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch136_loss0.09871508702635765.pypots
2024-05-25 05:32:10 [INFO]: Epoch 137 - training loss: 0.0947, validation loss: 0.0999
2024-05-25 05:32:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch137_loss0.09990062192082405.pypots
2024-05-25 05:32:27 [INFO]: Epoch 138 - training loss: 0.0983, validation loss: 0.0983
2024-05-25 05:32:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch138_loss0.09828613102436065.pypots
2024-05-25 05:32:43 [INFO]: Epoch 139 - training loss: 0.0967, validation loss: 0.0990
2024-05-25 05:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch139_loss0.09898235276341438.pypots
2024-05-25 05:33:00 [INFO]: Epoch 140 - training loss: 0.0973, validation loss: 0.0976
2024-05-25 05:33:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch140_loss0.09761807322502136.pypots
2024-05-25 05:33:17 [INFO]: Epoch 141 - training loss: 0.0901, validation loss: 0.0997
2024-05-25 05:33:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch141_loss0.09965410307049752.pypots
2024-05-25 05:33:33 [INFO]: Epoch 142 - training loss: 0.1021, validation loss: 0.1002
2024-05-25 05:33:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch142_loss0.10017563328146935.pypots
2024-05-25 05:33:50 [INFO]: Epoch 143 - training loss: 0.0975, validation loss: 0.1003
2024-05-25 05:33:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch143_loss0.1003020390868187.pypots
2024-05-25 05:34:07 [INFO]: Epoch 144 - training loss: 0.0802, validation loss: 0.0988
2024-05-25 05:34:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch144_loss0.09880317747592926.pypots
2024-05-25 05:34:23 [INFO]: Epoch 145 - training loss: 0.0960, validation loss: 0.0984
2024-05-25 05:34:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch145_loss0.09844138398766518.pypots
2024-05-25 05:34:40 [INFO]: Epoch 146 - training loss: 0.0958, validation loss: 0.0993
2024-05-25 05:34:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch146_loss0.09933482334017754.pypots
2024-05-25 05:34:57 [INFO]: Epoch 147 - training loss: 0.1027, validation loss: 0.1025
2024-05-25 05:34:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch147_loss0.10253992602229119.pypots
2024-05-25 05:35:13 [INFO]: Epoch 148 - training loss: 0.0990, validation loss: 0.0996
2024-05-25 05:35:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch148_loss0.09958556741476059.pypots
2024-05-25 05:35:30 [INFO]: Epoch 149 - training loss: 0.0951, validation loss: 0.0984
2024-05-25 05:35:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch149_loss0.0983906053006649.pypots
2024-05-25 05:35:47 [INFO]: Epoch 150 - training loss: 0.1063, validation loss: 0.0989
2024-05-25 05:35:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI_epoch150_loss0.09885638356208801.pypots
2024-05-25 05:35:47 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:35:47 [INFO]: Finished training. The best model is from epoch#140.
2024-05-25 05:35:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_air_quality/20240525_T045405/CSDI.pypots
2024-05-25 05:38:07 [INFO]: CSDI on Air-Quality: MAE=0.1019, MSE=0.1403
2024-05-25 05:38:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_air_quality/imputation.pkl
2024-05-25 05:38:07 [INFO]: Using the given device: cuda:0
2024-05-25 05:38:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T053807
2024-05-25 05:38:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T053807/tensorboard
2024-05-25 05:38:07 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 05:38:07 [INFO]: Epoch 001 - training loss: 65396.8594, validation loss: 0.7082
2024-05-25 05:38:08 [INFO]: Epoch 002 - training loss: 41609.4536, validation loss: 0.5909
2024-05-25 05:38:08 [INFO]: Epoch 003 - training loss: 41212.6332, validation loss: 0.5996
2024-05-25 05:38:08 [INFO]: Epoch 004 - training loss: 41076.0347, validation loss: 0.5384
2024-05-25 05:38:09 [INFO]: Epoch 005 - training loss: 40984.3617, validation loss: 0.4919
2024-05-25 05:38:09 [INFO]: Epoch 006 - training loss: 40929.0638, validation loss: 0.4552
2024-05-25 05:38:09 [INFO]: Epoch 007 - training loss: 40862.2154, validation loss: 0.4329
2024-05-25 05:38:10 [INFO]: Epoch 008 - training loss: 40819.9078, validation loss: 0.4040
2024-05-25 05:38:10 [INFO]: Epoch 009 - training loss: 40801.2953, validation loss: 0.3641
2024-05-25 05:38:10 [INFO]: Epoch 010 - training loss: 40764.9245, validation loss: 0.3636
2024-05-25 05:38:11 [INFO]: Epoch 011 - training loss: 40736.4300, validation loss: 0.3462
2024-05-25 05:38:11 [INFO]: Epoch 012 - training loss: 40726.8701, validation loss: 0.3361
2024-05-25 05:38:11 [INFO]: Epoch 013 - training loss: 40709.2843, validation loss: 0.3282
2024-05-25 05:38:11 [INFO]: Epoch 014 - training loss: 40695.3728, validation loss: 0.3195
2024-05-25 05:38:12 [INFO]: Epoch 015 - training loss: 40714.3011, validation loss: 0.4378
2024-05-25 05:38:12 [INFO]: Epoch 016 - training loss: 40765.9113, validation loss: 0.3383
2024-05-25 05:38:12 [INFO]: Epoch 017 - training loss: 40696.0804, validation loss: 0.3228
2024-05-25 05:38:13 [INFO]: Epoch 018 - training loss: 40664.6098, validation loss: 0.3049
2024-05-25 05:38:13 [INFO]: Epoch 019 - training loss: 40649.2373, validation loss: 0.3021
2024-05-25 05:38:13 [INFO]: Epoch 020 - training loss: 40641.7007, validation loss: 0.2883
2024-05-25 05:38:14 [INFO]: Epoch 021 - training loss: 40629.3576, validation loss: 0.2974
2024-05-25 05:38:14 [INFO]: Epoch 022 - training loss: 40631.8602, validation loss: 0.2911
2024-05-25 05:38:14 [INFO]: Epoch 023 - training loss: 40630.6943, validation loss: 0.2992
2024-05-25 05:38:15 [INFO]: Epoch 024 - training loss: 40697.7488, validation loss: 0.3166
2024-05-25 05:38:15 [INFO]: Epoch 025 - training loss: 40651.7263, validation loss: 0.3156
2024-05-25 05:38:15 [INFO]: Epoch 026 - training loss: 40667.4444, validation loss: 0.3143
2024-05-25 05:38:16 [INFO]: Epoch 027 - training loss: 40637.5713, validation loss: 0.2820
2024-05-25 05:38:16 [INFO]: Epoch 028 - training loss: 40621.0120, validation loss: 0.2887
2024-05-25 05:38:16 [INFO]: Epoch 029 - training loss: 40613.3733, validation loss: 0.2731
2024-05-25 05:38:17 [INFO]: Epoch 030 - training loss: 40601.4774, validation loss: 0.2754
2024-05-25 05:38:17 [INFO]: Epoch 031 - training loss: 40597.6981, validation loss: 0.2796
2024-05-25 05:38:17 [INFO]: Epoch 032 - training loss: 40595.2391, validation loss: 0.2628
2024-05-25 05:38:18 [INFO]: Epoch 033 - training loss: 40582.9563, validation loss: 0.2665
2024-05-25 05:38:18 [INFO]: Epoch 034 - training loss: 40590.5645, validation loss: 0.2747
2024-05-25 05:38:18 [INFO]: Epoch 035 - training loss: 40583.9544, validation loss: 0.2639
2024-05-25 05:38:19 [INFO]: Epoch 036 - training loss: 40576.4087, validation loss: 0.2622
2024-05-25 05:38:19 [INFO]: Epoch 037 - training loss: 40588.8462, validation loss: 0.2702
2024-05-25 05:38:19 [INFO]: Epoch 038 - training loss: 40578.8812, validation loss: 0.2578
2024-05-25 05:38:20 [INFO]: Epoch 039 - training loss: 40569.8218, validation loss: 0.2750
2024-05-25 05:38:20 [INFO]: Epoch 040 - training loss: 40602.1042, validation loss: 0.2874
2024-05-25 05:38:20 [INFO]: Epoch 041 - training loss: 40599.5822, validation loss: 0.3160
2024-05-25 05:38:20 [INFO]: Epoch 042 - training loss: 40653.3207, validation loss: 0.2812
2024-05-25 05:38:21 [INFO]: Epoch 043 - training loss: 40618.8492, validation loss: 0.2778
2024-05-25 05:38:21 [INFO]: Epoch 044 - training loss: 40612.3284, validation loss: 0.2637
2024-05-25 05:38:21 [INFO]: Epoch 045 - training loss: 40579.4689, validation loss: 0.2542
2024-05-25 05:38:22 [INFO]: Epoch 046 - training loss: 40569.5369, validation loss: 0.2489
2024-05-25 05:38:22 [INFO]: Epoch 047 - training loss: 40563.8038, validation loss: 0.2483
2024-05-25 05:38:22 [INFO]: Epoch 048 - training loss: 40568.1794, validation loss: 0.2516
2024-05-25 05:38:23 [INFO]: Epoch 049 - training loss: 40566.2912, validation loss: 0.2525
2024-05-25 05:38:23 [INFO]: Epoch 050 - training loss: 40565.6337, validation loss: 0.2479
2024-05-25 05:38:23 [INFO]: Epoch 051 - training loss: 40555.1412, validation loss: 0.2501
2024-05-25 05:38:24 [INFO]: Epoch 052 - training loss: 40548.3844, validation loss: 0.2492
2024-05-25 05:38:24 [INFO]: Epoch 053 - training loss: 40549.4181, validation loss: 0.2454
2024-05-25 05:38:24 [INFO]: Epoch 054 - training loss: 40559.2733, validation loss: 0.2456
2024-05-25 05:38:25 [INFO]: Epoch 055 - training loss: 40559.6413, validation loss: 0.2552
2024-05-25 05:38:25 [INFO]: Epoch 056 - training loss: 40634.0231, validation loss: 0.2773
2024-05-25 05:38:25 [INFO]: Epoch 057 - training loss: 40612.3691, validation loss: 0.2680
2024-05-25 05:38:26 [INFO]: Epoch 058 - training loss: 40587.8403, validation loss: 0.2509
2024-05-25 05:38:26 [INFO]: Epoch 059 - training loss: 40561.2203, validation loss: 0.2448
2024-05-25 05:38:26 [INFO]: Epoch 060 - training loss: 40549.5626, validation loss: 0.2387
2024-05-25 05:38:27 [INFO]: Epoch 061 - training loss: 40548.7909, validation loss: 0.2372
2024-05-25 05:38:27 [INFO]: Epoch 062 - training loss: 40541.3345, validation loss: 0.2446
2024-05-25 05:38:27 [INFO]: Epoch 063 - training loss: 40569.0370, validation loss: 0.2455
2024-05-25 05:38:28 [INFO]: Epoch 064 - training loss: 40545.3546, validation loss: 0.2439
2024-05-25 05:38:28 [INFO]: Epoch 065 - training loss: 40541.5097, validation loss: 0.2415
2024-05-25 05:38:28 [INFO]: Epoch 066 - training loss: 40539.3008, validation loss: 0.2361
2024-05-25 05:38:28 [INFO]: Epoch 067 - training loss: 40537.0496, validation loss: 0.2347
2024-05-25 05:38:29 [INFO]: Epoch 068 - training loss: 40536.7049, validation loss: 0.2355
2024-05-25 05:38:29 [INFO]: Epoch 069 - training loss: 40534.8618, validation loss: 0.2327
2024-05-25 05:38:29 [INFO]: Epoch 070 - training loss: 40536.6098, validation loss: 0.2322
2024-05-25 05:38:30 [INFO]: Epoch 071 - training loss: 40530.7724, validation loss: 0.2387
2024-05-25 05:38:30 [INFO]: Epoch 072 - training loss: 40532.7125, validation loss: 0.2406
2024-05-25 05:38:30 [INFO]: Epoch 073 - training loss: 40539.9492, validation loss: 0.2415
2024-05-25 05:38:31 [INFO]: Epoch 074 - training loss: 40543.7124, validation loss: 0.2672
2024-05-25 05:38:31 [INFO]: Epoch 075 - training loss: 40560.0995, validation loss: 0.2512
2024-05-25 05:38:31 [INFO]: Epoch 076 - training loss: 40534.4064, validation loss: 0.2434
2024-05-25 05:38:32 [INFO]: Epoch 077 - training loss: 40555.5292, validation loss: 0.2420
2024-05-25 05:38:32 [INFO]: Epoch 078 - training loss: 40538.7306, validation loss: 0.2385
2024-05-25 05:38:32 [INFO]: Epoch 079 - training loss: 40530.4815, validation loss: 0.2420
2024-05-25 05:38:33 [INFO]: Epoch 080 - training loss: 40539.4922, validation loss: 0.2372
2024-05-25 05:38:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:38:33 [INFO]: Finished training. The best model is from epoch#70.
2024-05-25 05:38:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_air_quality/20240525_T053807/GPVAE.pypots
2024-05-25 05:38:33 [INFO]: GP-VAE on Air-Quality: MAE=0.2821, MSE=0.2533
2024-05-25 05:38:33 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_air_quality/imputation.pkl
2024-05-25 05:38:33 [INFO]: Using the given device: cuda:0
2024-05-25 05:38:33 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T053833
2024-05-25 05:38:33 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T053833/tensorboard
2024-05-25 05:38:33 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 05:38:38 [INFO]: Epoch 001 - generator training loss: 0.3649, discriminator training loss: 0.5670, validation loss: 0.5494
2024-05-25 05:38:42 [INFO]: Epoch 002 - generator training loss: 0.0355, discriminator training loss: 0.5240, validation loss: 0.4145
2024-05-25 05:38:46 [INFO]: Epoch 003 - generator training loss: -0.0364, discriminator training loss: 0.5187, validation loss: 0.3472
2024-05-25 05:38:50 [INFO]: Epoch 004 - generator training loss: -0.0753, discriminator training loss: 0.5148, validation loss: 0.3062
2024-05-25 05:38:54 [INFO]: Epoch 005 - generator training loss: -0.0978, discriminator training loss: 0.5107, validation loss: 0.2781
2024-05-25 05:38:58 [INFO]: Epoch 006 - generator training loss: -0.1134, discriminator training loss: 0.5052, validation loss: 0.2597
2024-05-25 05:39:02 [INFO]: Epoch 007 - generator training loss: -0.1170, discriminator training loss: 0.4989, validation loss: 0.2452
2024-05-25 05:39:07 [INFO]: Epoch 008 - generator training loss: -0.1299, discriminator training loss: 0.4922, validation loss: 0.2333
2024-05-25 05:39:11 [INFO]: Epoch 009 - generator training loss: -0.1323, discriminator training loss: 0.4836, validation loss: 0.2240
2024-05-25 05:39:15 [INFO]: Epoch 010 - generator training loss: -0.1351, discriminator training loss: 0.4746, validation loss: 0.2168
2024-05-25 05:39:19 [INFO]: Epoch 011 - generator training loss: -0.1335, discriminator training loss: 0.4645, validation loss: 0.2101
2024-05-25 05:39:23 [INFO]: Epoch 012 - generator training loss: -0.1310, discriminator training loss: 0.4539, validation loss: 0.2046
2024-05-25 05:39:27 [INFO]: Epoch 013 - generator training loss: -0.1286, discriminator training loss: 0.4430, validation loss: 0.1993
2024-05-25 05:39:31 [INFO]: Epoch 014 - generator training loss: -0.1243, discriminator training loss: 0.4324, validation loss: 0.1951
2024-05-25 05:39:35 [INFO]: Epoch 015 - generator training loss: -0.1218, discriminator training loss: 0.4222, validation loss: 0.1911
2024-05-25 05:39:39 [INFO]: Epoch 016 - generator training loss: -0.1174, discriminator training loss: 0.4124, validation loss: 0.1881
2024-05-25 05:39:44 [INFO]: Epoch 017 - generator training loss: -0.1149, discriminator training loss: 0.4031, validation loss: 0.1845
2024-05-25 05:39:48 [INFO]: Epoch 018 - generator training loss: -0.1105, discriminator training loss: 0.3946, validation loss: 0.1819
2024-05-25 05:39:52 [INFO]: Epoch 019 - generator training loss: -0.1094, discriminator training loss: 0.3865, validation loss: 0.1793
2024-05-25 05:39:56 [INFO]: Epoch 020 - generator training loss: -0.1070, discriminator training loss: 0.3792, validation loss: 0.1765
2024-05-25 05:40:00 [INFO]: Epoch 021 - generator training loss: -0.1002, discriminator training loss: 0.3726, validation loss: 0.1743
2024-05-25 05:40:04 [INFO]: Epoch 022 - generator training loss: -0.1022, discriminator training loss: 0.3665, validation loss: 0.1718
2024-05-25 05:40:08 [INFO]: Epoch 023 - generator training loss: -0.1003, discriminator training loss: 0.3603, validation loss: 0.1694
2024-05-25 05:40:12 [INFO]: Epoch 024 - generator training loss: -0.0993, discriminator training loss: 0.3559, validation loss: 0.1672
2024-05-25 05:40:17 [INFO]: Epoch 025 - generator training loss: -0.1001, discriminator training loss: 0.3508, validation loss: 0.1659
2024-05-25 05:40:21 [INFO]: Epoch 026 - generator training loss: -0.0979, discriminator training loss: 0.3468, validation loss: 0.1639
2024-05-25 05:40:25 [INFO]: Epoch 027 - generator training loss: -0.0979, discriminator training loss: 0.3437, validation loss: 0.1619
2024-05-25 05:40:29 [INFO]: Epoch 028 - generator training loss: -0.0963, discriminator training loss: 0.3393, validation loss: 0.1603
2024-05-25 05:40:33 [INFO]: Epoch 029 - generator training loss: -0.0966, discriminator training loss: 0.3366, validation loss: 0.1589
2024-05-25 05:40:37 [INFO]: Epoch 030 - generator training loss: -0.0970, discriminator training loss: 0.3340, validation loss: 0.1574
2024-05-25 05:40:41 [INFO]: Epoch 031 - generator training loss: -0.0971, discriminator training loss: 0.3313, validation loss: 0.1554
2024-05-25 05:40:45 [INFO]: Epoch 032 - generator training loss: -0.0964, discriminator training loss: 0.3290, validation loss: 0.1535
2024-05-25 05:40:49 [INFO]: Epoch 033 - generator training loss: -0.0971, discriminator training loss: 0.3269, validation loss: 0.1531
2024-05-25 05:40:53 [INFO]: Epoch 034 - generator training loss: -0.0952, discriminator training loss: 0.3253, validation loss: 0.1512
2024-05-25 05:40:58 [INFO]: Epoch 035 - generator training loss: -0.0978, discriminator training loss: 0.3231, validation loss: 0.1506
2024-05-25 05:41:02 [INFO]: Epoch 036 - generator training loss: -0.0975, discriminator training loss: 0.3221, validation loss: 0.1490
2024-05-25 05:41:06 [INFO]: Epoch 037 - generator training loss: -0.0978, discriminator training loss: 0.3206, validation loss: 0.1480
2024-05-25 05:41:10 [INFO]: Epoch 038 - generator training loss: -0.0981, discriminator training loss: 0.3188, validation loss: 0.1468
2024-05-25 05:41:14 [INFO]: Epoch 039 - generator training loss: -0.0978, discriminator training loss: 0.3181, validation loss: 0.1456
2024-05-25 05:41:18 [INFO]: Epoch 040 - generator training loss: -0.0988, discriminator training loss: 0.3174, validation loss: 0.1448
2024-05-25 05:41:22 [INFO]: Epoch 041 - generator training loss: -0.0997, discriminator training loss: 0.3162, validation loss: 0.1448
2024-05-25 05:41:26 [INFO]: Epoch 042 - generator training loss: -0.0998, discriminator training loss: 0.3153, validation loss: 0.1431
2024-05-25 05:41:31 [INFO]: Epoch 043 - generator training loss: -0.1005, discriminator training loss: 0.3148, validation loss: 0.1418
2024-05-25 05:41:35 [INFO]: Epoch 044 - generator training loss: -0.0997, discriminator training loss: 0.3139, validation loss: 0.1410
2024-05-25 05:41:39 [INFO]: Epoch 045 - generator training loss: -0.1013, discriminator training loss: 0.3132, validation loss: 0.1409
2024-05-25 05:41:43 [INFO]: Epoch 046 - generator training loss: -0.0997, discriminator training loss: 0.3126, validation loss: 0.1390
2024-05-25 05:41:47 [INFO]: Epoch 047 - generator training loss: -0.1021, discriminator training loss: 0.3123, validation loss: 0.1391
2024-05-25 05:41:51 [INFO]: Epoch 048 - generator training loss: -0.1015, discriminator training loss: 0.3112, validation loss: 0.1378
2024-05-25 05:41:55 [INFO]: Epoch 049 - generator training loss: -0.1028, discriminator training loss: 0.3109, validation loss: 0.1380
2024-05-25 05:41:59 [INFO]: Epoch 050 - generator training loss: -0.1021, discriminator training loss: 0.3100, validation loss: 0.1366
2024-05-25 05:42:03 [INFO]: Epoch 051 - generator training loss: -0.1023, discriminator training loss: 0.3100, validation loss: 0.1361
2024-05-25 05:42:08 [INFO]: Epoch 052 - generator training loss: -0.1040, discriminator training loss: 0.3096, validation loss: 0.1352
2024-05-25 05:42:12 [INFO]: Epoch 053 - generator training loss: -0.1048, discriminator training loss: 0.3094, validation loss: 0.1344
2024-05-25 05:42:16 [INFO]: Epoch 054 - generator training loss: -0.1042, discriminator training loss: 0.3085, validation loss: 0.1331
2024-05-25 05:42:20 [INFO]: Epoch 055 - generator training loss: -0.1048, discriminator training loss: 0.3084, validation loss: 0.1327
2024-05-25 05:42:24 [INFO]: Epoch 056 - generator training loss: -0.1066, discriminator training loss: 0.3079, validation loss: 0.1320
2024-05-25 05:42:28 [INFO]: Epoch 057 - generator training loss: -0.1072, discriminator training loss: 0.3079, validation loss: 0.1308
2024-05-25 05:42:32 [INFO]: Epoch 058 - generator training loss: -0.1074, discriminator training loss: 0.3076, validation loss: 0.1306
2024-05-25 05:42:36 [INFO]: Epoch 059 - generator training loss: -0.1080, discriminator training loss: 0.3071, validation loss: 0.1304
2024-05-25 05:42:41 [INFO]: Epoch 060 - generator training loss: -0.1086, discriminator training loss: 0.3073, validation loss: 0.1288
2024-05-25 05:42:45 [INFO]: Epoch 061 - generator training loss: -0.1087, discriminator training loss: 0.3068, validation loss: 0.1295
2024-05-25 05:42:49 [INFO]: Epoch 062 - generator training loss: -0.1092, discriminator training loss: 0.3062, validation loss: 0.1289
2024-05-25 05:42:53 [INFO]: Epoch 063 - generator training loss: -0.1086, discriminator training loss: 0.3064, validation loss: 0.1283
2024-05-25 05:42:57 [INFO]: Epoch 064 - generator training loss: -0.1104, discriminator training loss: 0.3063, validation loss: 0.1284
2024-05-25 05:43:01 [INFO]: Epoch 065 - generator training loss: -0.1103, discriminator training loss: 0.3060, validation loss: 0.1278
2024-05-25 05:43:05 [INFO]: Epoch 066 - generator training loss: -0.1110, discriminator training loss: 0.3057, validation loss: 0.1272
2024-05-25 05:43:09 [INFO]: Epoch 067 - generator training loss: -0.1116, discriminator training loss: 0.3051, validation loss: 0.1272
2024-05-25 05:43:13 [INFO]: Epoch 068 - generator training loss: -0.1118, discriminator training loss: 0.3050, validation loss: 0.1261
2024-05-25 05:43:18 [INFO]: Epoch 069 - generator training loss: -0.1119, discriminator training loss: 0.3042, validation loss: 0.1262
2024-05-25 05:43:22 [INFO]: Epoch 070 - generator training loss: -0.1117, discriminator training loss: 0.3048, validation loss: 0.1262
2024-05-25 05:43:26 [INFO]: Epoch 071 - generator training loss: -0.1119, discriminator training loss: 0.3045, validation loss: 0.1247
2024-05-25 05:43:30 [INFO]: Epoch 072 - generator training loss: -0.1121, discriminator training loss: 0.3047, validation loss: 0.1251
2024-05-25 05:43:34 [INFO]: Epoch 073 - generator training loss: -0.1133, discriminator training loss: 0.3044, validation loss: 0.1255
2024-05-25 05:43:38 [INFO]: Epoch 074 - generator training loss: -0.1129, discriminator training loss: 0.3045, validation loss: 0.1247
2024-05-25 05:43:42 [INFO]: Epoch 075 - generator training loss: -0.1136, discriminator training loss: 0.3039, validation loss: 0.1247
2024-05-25 05:43:47 [INFO]: Epoch 076 - generator training loss: -0.1140, discriminator training loss: 0.3037, validation loss: 0.1246
2024-05-25 05:43:51 [INFO]: Epoch 077 - generator training loss: -0.1150, discriminator training loss: 0.3037, validation loss: 0.1243
2024-05-25 05:43:55 [INFO]: Epoch 078 - generator training loss: -0.1150, discriminator training loss: 0.3034, validation loss: 0.1242
2024-05-25 05:43:59 [INFO]: Epoch 079 - generator training loss: -0.1151, discriminator training loss: 0.3031, validation loss: 0.1237
2024-05-25 05:44:03 [INFO]: Epoch 080 - generator training loss: -0.1147, discriminator training loss: 0.3030, validation loss: 0.1233
2024-05-25 05:44:07 [INFO]: Epoch 081 - generator training loss: -0.1165, discriminator training loss: 0.3028, validation loss: 0.1232
2024-05-25 05:44:11 [INFO]: Epoch 082 - generator training loss: -0.1164, discriminator training loss: 0.3028, validation loss: 0.1243
2024-05-25 05:44:16 [INFO]: Epoch 083 - generator training loss: -0.1155, discriminator training loss: 0.3024, validation loss: 0.1232
2024-05-25 05:44:20 [INFO]: Epoch 084 - generator training loss: -0.1172, discriminator training loss: 0.3024, validation loss: 0.1227
2024-05-25 05:44:24 [INFO]: Epoch 085 - generator training loss: -0.1165, discriminator training loss: 0.3027, validation loss: 0.1230
2024-05-25 05:44:28 [INFO]: Epoch 086 - generator training loss: -0.1165, discriminator training loss: 0.3020, validation loss: 0.1232
2024-05-25 05:44:32 [INFO]: Epoch 087 - generator training loss: -0.1171, discriminator training loss: 0.3018, validation loss: 0.1226
2024-05-25 05:44:36 [INFO]: Epoch 088 - generator training loss: -0.1180, discriminator training loss: 0.3023, validation loss: 0.1224
2024-05-25 05:44:40 [INFO]: Epoch 089 - generator training loss: -0.1169, discriminator training loss: 0.3021, validation loss: 0.1225
2024-05-25 05:44:44 [INFO]: Epoch 090 - generator training loss: -0.1182, discriminator training loss: 0.3016, validation loss: 0.1215
2024-05-25 05:44:48 [INFO]: Epoch 091 - generator training loss: -0.1172, discriminator training loss: 0.3022, validation loss: 0.1227
2024-05-25 05:44:53 [INFO]: Epoch 092 - generator training loss: -0.1185, discriminator training loss: 0.3013, validation loss: 0.1223
2024-05-25 05:44:57 [INFO]: Epoch 093 - generator training loss: -0.1194, discriminator training loss: 0.3014, validation loss: 0.1219
2024-05-25 05:45:01 [INFO]: Epoch 094 - generator training loss: -0.1194, discriminator training loss: 0.3020, validation loss: 0.1220
2024-05-25 05:45:05 [INFO]: Epoch 095 - generator training loss: -0.1192, discriminator training loss: 0.3011, validation loss: 0.1213
2024-05-25 05:45:09 [INFO]: Epoch 096 - generator training loss: -0.1199, discriminator training loss: 0.3017, validation loss: 0.1211
2024-05-25 05:45:13 [INFO]: Epoch 097 - generator training loss: -0.1187, discriminator training loss: 0.3011, validation loss: 0.1212
2024-05-25 05:45:17 [INFO]: Epoch 098 - generator training loss: -0.1199, discriminator training loss: 0.3010, validation loss: 0.1207
2024-05-25 05:45:21 [INFO]: Epoch 099 - generator training loss: -0.1195, discriminator training loss: 0.3008, validation loss: 0.1221
2024-05-25 05:45:26 [INFO]: Epoch 100 - generator training loss: -0.1202, discriminator training loss: 0.3005, validation loss: 0.1204
2024-05-25 05:45:30 [INFO]: Epoch 101 - generator training loss: -0.1192, discriminator training loss: 0.3008, validation loss: 0.1211
2024-05-25 05:45:34 [INFO]: Epoch 102 - generator training loss: -0.1213, discriminator training loss: 0.3003, validation loss: 0.1205
2024-05-25 05:45:38 [INFO]: Epoch 103 - generator training loss: -0.1197, discriminator training loss: 0.3003, validation loss: 0.1210
2024-05-25 05:45:42 [INFO]: Epoch 104 - generator training loss: -0.1208, discriminator training loss: 0.3001, validation loss: 0.1207
2024-05-25 05:45:46 [INFO]: Epoch 105 - generator training loss: -0.1219, discriminator training loss: 0.3005, validation loss: 0.1208
2024-05-25 05:45:50 [INFO]: Epoch 106 - generator training loss: -0.1211, discriminator training loss: 0.3002, validation loss: 0.1206
2024-05-25 05:45:54 [INFO]: Epoch 107 - generator training loss: -0.1215, discriminator training loss: 0.2999, validation loss: 0.1209
2024-05-25 05:45:59 [INFO]: Epoch 108 - generator training loss: -0.1220, discriminator training loss: 0.2995, validation loss: 0.1205
2024-05-25 05:46:03 [INFO]: Epoch 109 - generator training loss: -0.1229, discriminator training loss: 0.2995, validation loss: 0.1212
2024-05-25 05:46:07 [INFO]: Epoch 110 - generator training loss: -0.1221, discriminator training loss: 0.3001, validation loss: 0.1202
2024-05-25 05:46:11 [INFO]: Epoch 111 - generator training loss: -0.1227, discriminator training loss: 0.2995, validation loss: 0.1202
2024-05-25 05:46:15 [INFO]: Epoch 112 - generator training loss: -0.1231, discriminator training loss: 0.2993, validation loss: 0.1210
2024-05-25 05:46:19 [INFO]: Epoch 113 - generator training loss: -0.1241, discriminator training loss: 0.2995, validation loss: 0.1205
2024-05-25 05:46:23 [INFO]: Epoch 114 - generator training loss: -0.1226, discriminator training loss: 0.2995, validation loss: 0.1207
2024-05-25 05:46:27 [INFO]: Epoch 115 - generator training loss: -0.1237, discriminator training loss: 0.2995, validation loss: 0.1199
2024-05-25 05:46:31 [INFO]: Epoch 116 - generator training loss: -0.1229, discriminator training loss: 0.2987, validation loss: 0.1202
2024-05-25 05:46:36 [INFO]: Epoch 117 - generator training loss: -0.1236, discriminator training loss: 0.2990, validation loss: 0.1204
2024-05-25 05:46:40 [INFO]: Epoch 118 - generator training loss: -0.1235, discriminator training loss: 0.2982, validation loss: 0.1205
2024-05-25 05:46:44 [INFO]: Epoch 119 - generator training loss: -0.1244, discriminator training loss: 0.2985, validation loss: 0.1200
2024-05-25 05:46:48 [INFO]: Epoch 120 - generator training loss: -0.1242, discriminator training loss: 0.2984, validation loss: 0.1189
2024-05-25 05:46:52 [INFO]: Epoch 121 - generator training loss: -0.1250, discriminator training loss: 0.2985, validation loss: 0.1208
2024-05-25 05:46:56 [INFO]: Epoch 122 - generator training loss: -0.1245, discriminator training loss: 0.2989, validation loss: 0.1197
2024-05-25 05:47:00 [INFO]: Epoch 123 - generator training loss: -0.1240, discriminator training loss: 0.2991, validation loss: 0.1204
2024-05-25 05:47:04 [INFO]: Epoch 124 - generator training loss: -0.1246, discriminator training loss: 0.2989, validation loss: 0.1199
2024-05-25 05:47:09 [INFO]: Epoch 125 - generator training loss: -0.1248, discriminator training loss: 0.2987, validation loss: 0.1203
2024-05-25 05:47:13 [INFO]: Epoch 126 - generator training loss: -0.1258, discriminator training loss: 0.2988, validation loss: 0.1187
2024-05-25 05:47:17 [INFO]: Epoch 127 - generator training loss: -0.1263, discriminator training loss: 0.2978, validation loss: 0.1198
2024-05-25 05:47:21 [INFO]: Epoch 128 - generator training loss: -0.1252, discriminator training loss: 0.2984, validation loss: 0.1187
2024-05-25 05:47:25 [INFO]: Epoch 129 - generator training loss: -0.1264, discriminator training loss: 0.2985, validation loss: 0.1198
2024-05-25 05:47:29 [INFO]: Epoch 130 - generator training loss: -0.1270, discriminator training loss: 0.2978, validation loss: 0.1194
2024-05-25 05:47:33 [INFO]: Epoch 131 - generator training loss: -0.1255, discriminator training loss: 0.2980, validation loss: 0.1188
2024-05-25 05:47:37 [INFO]: Epoch 132 - generator training loss: -0.1263, discriminator training loss: 0.2982, validation loss: 0.1194
2024-05-25 05:47:41 [INFO]: Epoch 133 - generator training loss: -0.1271, discriminator training loss: 0.2978, validation loss: 0.1194
2024-05-25 05:47:46 [INFO]: Epoch 134 - generator training loss: -0.1267, discriminator training loss: 0.2980, validation loss: 0.1195
2024-05-25 05:47:50 [INFO]: Epoch 135 - generator training loss: -0.1280, discriminator training loss: 0.2977, validation loss: 0.1189
2024-05-25 05:47:54 [INFO]: Epoch 136 - generator training loss: -0.1275, discriminator training loss: 0.2972, validation loss: 0.1190
2024-05-25 05:47:58 [INFO]: Epoch 137 - generator training loss: -0.1272, discriminator training loss: 0.2976, validation loss: 0.1190
2024-05-25 05:48:02 [INFO]: Epoch 138 - generator training loss: -0.1278, discriminator training loss: 0.2968, validation loss: 0.1195
2024-05-25 05:48:02 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 05:48:02 [INFO]: Finished training. The best model is from epoch#128.
2024-05-25 05:48:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_air_quality/20240525_T053833/USGAN.pypots
2024-05-25 05:48:03 [INFO]: US-GAN on Air-Quality: MAE=0.1631, MSE=0.1276
2024-05-25 05:48:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_air_quality/imputation.pkl
2024-05-25 05:48:03 [INFO]: Using the given device: cuda:0
2024-05-25 05:48:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T054803
2024-05-25 05:48:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T054803/tensorboard
2024-05-25 05:48:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 05:48:07 [INFO]: Epoch 001 - training loss: 1.4157, validation loss: 0.9776
2024-05-25 05:48:09 [INFO]: Epoch 002 - training loss: 1.1584, validation loss: 0.7262
2024-05-25 05:48:12 [INFO]: Epoch 003 - training loss: 0.9621, validation loss: 0.6162
2024-05-25 05:48:15 [INFO]: Epoch 004 - training loss: 0.8530, validation loss: 0.5466
2024-05-25 05:48:18 [INFO]: Epoch 005 - training loss: 0.7790, validation loss: 0.5029
2024-05-25 05:48:21 [INFO]: Epoch 006 - training loss: 0.7255, validation loss: 0.4670
2024-05-25 05:48:23 [INFO]: Epoch 007 - training loss: 0.6831, validation loss: 0.4364
2024-05-25 05:48:26 [INFO]: Epoch 008 - training loss: 0.6471, validation loss: 0.4137
2024-05-25 05:48:29 [INFO]: Epoch 009 - training loss: 0.6234, validation loss: 0.3942
2024-05-25 05:48:32 [INFO]: Epoch 010 - training loss: 0.6020, validation loss: 0.3764
2024-05-25 05:48:35 [INFO]: Epoch 011 - training loss: 0.5842, validation loss: 0.3626
2024-05-25 05:48:37 [INFO]: Epoch 012 - training loss: 0.5688, validation loss: 0.3503
2024-05-25 05:48:40 [INFO]: Epoch 013 - training loss: 0.5566, validation loss: 0.3400
2024-05-25 05:48:43 [INFO]: Epoch 014 - training loss: 0.5432, validation loss: 0.3312
2024-05-25 05:48:46 [INFO]: Epoch 015 - training loss: 0.5342, validation loss: 0.3220
2024-05-25 05:48:49 [INFO]: Epoch 016 - training loss: 0.5244, validation loss: 0.3146
2024-05-25 05:48:51 [INFO]: Epoch 017 - training loss: 0.5138, validation loss: 0.3075
2024-05-25 05:48:54 [INFO]: Epoch 018 - training loss: 0.5063, validation loss: 0.3014
2024-05-25 05:48:57 [INFO]: Epoch 019 - training loss: 0.4982, validation loss: 0.2957
2024-05-25 05:49:00 [INFO]: Epoch 020 - training loss: 0.4910, validation loss: 0.2901
2024-05-25 05:49:03 [INFO]: Epoch 021 - training loss: 0.4829, validation loss: 0.2856
2024-05-25 05:49:05 [INFO]: Epoch 022 - training loss: 0.4765, validation loss: 0.2808
2024-05-25 05:49:08 [INFO]: Epoch 023 - training loss: 0.4701, validation loss: 0.2767
2024-05-25 05:49:11 [INFO]: Epoch 024 - training loss: 0.4634, validation loss: 0.2726
2024-05-25 05:49:14 [INFO]: Epoch 025 - training loss: 0.4583, validation loss: 0.2685
2024-05-25 05:49:17 [INFO]: Epoch 026 - training loss: 0.4528, validation loss: 0.2645
2024-05-25 05:49:19 [INFO]: Epoch 027 - training loss: 0.4468, validation loss: 0.2608
2024-05-25 05:49:22 [INFO]: Epoch 028 - training loss: 0.4421, validation loss: 0.2576
2024-05-25 05:49:25 [INFO]: Epoch 029 - training loss: 0.4363, validation loss: 0.2545
2024-05-25 05:49:28 [INFO]: Epoch 030 - training loss: 0.4319, validation loss: 0.2513
2024-05-25 05:49:31 [INFO]: Epoch 031 - training loss: 0.4268, validation loss: 0.2481
2024-05-25 05:49:34 [INFO]: Epoch 032 - training loss: 0.4221, validation loss: 0.2451
2024-05-25 05:49:36 [INFO]: Epoch 033 - training loss: 0.4183, validation loss: 0.2420
2024-05-25 05:49:39 [INFO]: Epoch 034 - training loss: 0.4141, validation loss: 0.2396
2024-05-25 05:49:42 [INFO]: Epoch 035 - training loss: 0.4103, validation loss: 0.2371
2024-05-25 05:49:45 [INFO]: Epoch 036 - training loss: 0.4068, validation loss: 0.2346
2024-05-25 05:49:48 [INFO]: Epoch 037 - training loss: 0.4023, validation loss: 0.2322
2024-05-25 05:49:50 [INFO]: Epoch 038 - training loss: 0.3998, validation loss: 0.2297
2024-05-25 05:49:53 [INFO]: Epoch 039 - training loss: 0.3955, validation loss: 0.2272
2024-05-25 05:49:56 [INFO]: Epoch 040 - training loss: 0.3921, validation loss: 0.2250
2024-05-25 05:49:59 [INFO]: Epoch 041 - training loss: 0.3896, validation loss: 0.2224
2024-05-25 05:50:02 [INFO]: Epoch 042 - training loss: 0.3862, validation loss: 0.2204
2024-05-25 05:50:05 [INFO]: Epoch 043 - training loss: 0.3830, validation loss: 0.2184
2024-05-25 05:50:07 [INFO]: Epoch 044 - training loss: 0.3807, validation loss: 0.2164
2024-05-25 05:50:10 [INFO]: Epoch 045 - training loss: 0.3773, validation loss: 0.2144
2024-05-25 05:50:13 [INFO]: Epoch 046 - training loss: 0.3745, validation loss: 0.2127
2024-05-25 05:50:16 [INFO]: Epoch 047 - training loss: 0.3724, validation loss: 0.2109
2024-05-25 05:50:19 [INFO]: Epoch 048 - training loss: 0.3699, validation loss: 0.2091
2024-05-25 05:50:21 [INFO]: Epoch 049 - training loss: 0.3677, validation loss: 0.2071
2024-05-25 05:50:24 [INFO]: Epoch 050 - training loss: 0.3646, validation loss: 0.2056
2024-05-25 05:50:27 [INFO]: Epoch 051 - training loss: 0.3624, validation loss: 0.2039
2024-05-25 05:50:30 [INFO]: Epoch 052 - training loss: 0.3613, validation loss: 0.2027
2024-05-25 05:50:33 [INFO]: Epoch 053 - training loss: 0.3576, validation loss: 0.2007
2024-05-25 05:50:35 [INFO]: Epoch 054 - training loss: 0.3564, validation loss: 0.1997
2024-05-25 05:50:38 [INFO]: Epoch 055 - training loss: 0.3551, validation loss: 0.1976
2024-05-25 05:50:41 [INFO]: Epoch 056 - training loss: 0.3527, validation loss: 0.1961
2024-05-25 05:50:44 [INFO]: Epoch 057 - training loss: 0.3507, validation loss: 0.1947
2024-05-25 05:50:47 [INFO]: Epoch 058 - training loss: 0.3489, validation loss: 0.1936
2024-05-25 05:50:49 [INFO]: Epoch 059 - training loss: 0.3468, validation loss: 0.1923
2024-05-25 05:50:52 [INFO]: Epoch 060 - training loss: 0.3456, validation loss: 0.1912
2024-05-25 05:50:55 [INFO]: Epoch 061 - training loss: 0.3431, validation loss: 0.1901
2024-05-25 05:50:58 [INFO]: Epoch 062 - training loss: 0.3421, validation loss: 0.1889
2024-05-25 05:51:01 [INFO]: Epoch 063 - training loss: 0.3421, validation loss: 0.1877
2024-05-25 05:51:04 [INFO]: Epoch 064 - training loss: 0.3392, validation loss: 0.1866
2024-05-25 05:51:06 [INFO]: Epoch 065 - training loss: 0.3376, validation loss: 0.1854
2024-05-25 05:51:09 [INFO]: Epoch 066 - training loss: 0.3365, validation loss: 0.1845
2024-05-25 05:51:12 [INFO]: Epoch 067 - training loss: 0.3345, validation loss: 0.1830
2024-05-25 05:51:15 [INFO]: Epoch 068 - training loss: 0.3343, validation loss: 0.1823
2024-05-25 05:51:18 [INFO]: Epoch 069 - training loss: 0.3323, validation loss: 0.1815
2024-05-25 05:51:20 [INFO]: Epoch 070 - training loss: 0.3309, validation loss: 0.1804
2024-05-25 05:51:23 [INFO]: Epoch 071 - training loss: 0.3300, validation loss: 0.1797
2024-05-25 05:51:26 [INFO]: Epoch 072 - training loss: 0.3289, validation loss: 0.1787
2024-05-25 05:51:29 [INFO]: Epoch 073 - training loss: 0.3274, validation loss: 0.1780
2024-05-25 05:51:32 [INFO]: Epoch 074 - training loss: 0.3275, validation loss: 0.1771
2024-05-25 05:51:34 [INFO]: Epoch 075 - training loss: 0.3257, validation loss: 0.1760
2024-05-25 05:51:37 [INFO]: Epoch 076 - training loss: 0.3253, validation loss: 0.1756
2024-05-25 05:51:40 [INFO]: Epoch 077 - training loss: 0.3238, validation loss: 0.1746
2024-05-25 05:51:43 [INFO]: Epoch 078 - training loss: 0.3224, validation loss: 0.1737
2024-05-25 05:51:46 [INFO]: Epoch 079 - training loss: 0.3215, validation loss: 0.1732
2024-05-25 05:51:48 [INFO]: Epoch 080 - training loss: 0.3206, validation loss: 0.1724
2024-05-25 05:51:51 [INFO]: Epoch 081 - training loss: 0.3194, validation loss: 0.1719
2024-05-25 05:51:54 [INFO]: Epoch 082 - training loss: 0.3190, validation loss: 0.1715
2024-05-25 05:51:57 [INFO]: Epoch 083 - training loss: 0.3184, validation loss: 0.1707
2024-05-25 05:52:00 [INFO]: Epoch 084 - training loss: 0.3169, validation loss: 0.1700
2024-05-25 05:52:03 [INFO]: Epoch 085 - training loss: 0.3159, validation loss: 0.1694
2024-05-25 05:52:05 [INFO]: Epoch 086 - training loss: 0.3149, validation loss: 0.1686
2024-05-25 05:52:08 [INFO]: Epoch 087 - training loss: 0.3140, validation loss: 0.1682
2024-05-25 05:52:11 [INFO]: Epoch 088 - training loss: 0.3134, validation loss: 0.1675
2024-05-25 05:52:14 [INFO]: Epoch 089 - training loss: 0.3130, validation loss: 0.1670
2024-05-25 05:52:17 [INFO]: Epoch 090 - training loss: 0.3120, validation loss: 0.1666
2024-05-25 05:52:19 [INFO]: Epoch 091 - training loss: 0.3118, validation loss: 0.1659
2024-05-25 05:52:22 [INFO]: Epoch 092 - training loss: 0.3109, validation loss: 0.1654
2024-05-25 05:52:25 [INFO]: Epoch 093 - training loss: 0.3097, validation loss: 0.1649
2024-05-25 05:52:28 [INFO]: Epoch 094 - training loss: 0.3093, validation loss: 0.1642
2024-05-25 05:52:31 [INFO]: Epoch 095 - training loss: 0.3086, validation loss: 0.1636
2024-05-25 05:52:33 [INFO]: Epoch 096 - training loss: 0.3083, validation loss: 0.1635
2024-05-25 05:52:36 [INFO]: Epoch 097 - training loss: 0.3070, validation loss: 0.1629
2024-05-25 05:52:39 [INFO]: Epoch 098 - training loss: 0.3063, validation loss: 0.1625
2024-05-25 05:52:42 [INFO]: Epoch 099 - training loss: 0.3054, validation loss: 0.1620
2024-05-25 05:52:45 [INFO]: Epoch 100 - training loss: 0.3055, validation loss: 0.1614
2024-05-25 05:52:48 [INFO]: Epoch 101 - training loss: 0.3052, validation loss: 0.1610
2024-05-25 05:52:50 [INFO]: Epoch 102 - training loss: 0.3036, validation loss: 0.1603
2024-05-25 05:52:53 [INFO]: Epoch 103 - training loss: 0.3035, validation loss: 0.1601
2024-05-25 05:52:56 [INFO]: Epoch 104 - training loss: 0.3031, validation loss: 0.1596
2024-05-25 05:52:59 [INFO]: Epoch 105 - training loss: 0.3020, validation loss: 0.1592
2024-05-25 05:53:02 [INFO]: Epoch 106 - training loss: 0.3015, validation loss: 0.1588
2024-05-25 05:53:04 [INFO]: Epoch 107 - training loss: 0.3007, validation loss: 0.1585
2024-05-25 05:53:07 [INFO]: Epoch 108 - training loss: 0.3009, validation loss: 0.1580
2024-05-25 05:53:10 [INFO]: Epoch 109 - training loss: 0.2992, validation loss: 0.1578
2024-05-25 05:53:13 [INFO]: Epoch 110 - training loss: 0.2994, validation loss: 0.1572
2024-05-25 05:53:16 [INFO]: Epoch 111 - training loss: 0.2991, validation loss: 0.1570
2024-05-25 05:53:18 [INFO]: Epoch 112 - training loss: 0.2988, validation loss: 0.1563
2024-05-25 05:53:21 [INFO]: Epoch 113 - training loss: 0.2971, validation loss: 0.1560
2024-05-25 05:53:24 [INFO]: Epoch 114 - training loss: 0.2984, validation loss: 0.1558
2024-05-25 05:53:27 [INFO]: Epoch 115 - training loss: 0.2971, validation loss: 0.1552
2024-05-25 05:53:30 [INFO]: Epoch 116 - training loss: 0.2965, validation loss: 0.1551
2024-05-25 05:53:32 [INFO]: Epoch 117 - training loss: 0.2958, validation loss: 0.1548
2024-05-25 05:53:35 [INFO]: Epoch 118 - training loss: 0.2957, validation loss: 0.1544
2024-05-25 05:53:38 [INFO]: Epoch 119 - training loss: 0.2947, validation loss: 0.1540
2024-05-25 05:53:41 [INFO]: Epoch 120 - training loss: 0.2936, validation loss: 0.1534
2024-05-25 05:53:44 [INFO]: Epoch 121 - training loss: 0.2938, validation loss: 0.1533
2024-05-25 05:53:47 [INFO]: Epoch 122 - training loss: 0.2931, validation loss: 0.1531
2024-05-25 05:53:49 [INFO]: Epoch 123 - training loss: 0.2933, validation loss: 0.1528
2024-05-25 05:53:52 [INFO]: Epoch 124 - training loss: 0.2919, validation loss: 0.1523
2024-05-25 05:53:55 [INFO]: Epoch 125 - training loss: 0.2922, validation loss: 0.1521
2024-05-25 05:53:58 [INFO]: Epoch 126 - training loss: 0.2915, validation loss: 0.1519
2024-05-25 05:54:01 [INFO]: Epoch 127 - training loss: 0.2909, validation loss: 0.1516
2024-05-25 05:54:03 [INFO]: Epoch 128 - training loss: 0.2906, validation loss: 0.1513
2024-05-25 05:54:06 [INFO]: Epoch 129 - training loss: 0.2897, validation loss: 0.1508
2024-05-25 05:54:09 [INFO]: Epoch 130 - training loss: 0.2898, validation loss: 0.1506
2024-05-25 05:54:12 [INFO]: Epoch 131 - training loss: 0.2891, validation loss: 0.1503
2024-05-25 05:54:15 [INFO]: Epoch 132 - training loss: 0.2891, validation loss: 0.1499
2024-05-25 05:54:18 [INFO]: Epoch 133 - training loss: 0.2886, validation loss: 0.1499
2024-05-25 05:54:20 [INFO]: Epoch 134 - training loss: 0.2877, validation loss: 0.1495
2024-05-25 05:54:23 [INFO]: Epoch 135 - training loss: 0.2882, validation loss: 0.1492
2024-05-25 05:54:26 [INFO]: Epoch 136 - training loss: 0.2872, validation loss: 0.1490
2024-05-25 05:54:29 [INFO]: Epoch 137 - training loss: 0.2876, validation loss: 0.1487
2024-05-25 05:54:32 [INFO]: Epoch 138 - training loss: 0.2861, validation loss: 0.1484
2024-05-25 05:54:34 [INFO]: Epoch 139 - training loss: 0.2861, validation loss: 0.1482
2024-05-25 05:54:37 [INFO]: Epoch 140 - training loss: 0.2857, validation loss: 0.1477
2024-05-25 05:54:40 [INFO]: Epoch 141 - training loss: 0.2857, validation loss: 0.1476
2024-05-25 05:54:43 [INFO]: Epoch 142 - training loss: 0.2849, validation loss: 0.1471
2024-05-25 05:54:46 [INFO]: Epoch 143 - training loss: 0.2843, validation loss: 0.1470
2024-05-25 05:54:48 [INFO]: Epoch 144 - training loss: 0.2848, validation loss: 0.1468
2024-05-25 05:54:51 [INFO]: Epoch 145 - training loss: 0.2840, validation loss: 0.1467
2024-05-25 05:54:54 [INFO]: Epoch 146 - training loss: 0.2833, validation loss: 0.1463
2024-05-25 05:54:57 [INFO]: Epoch 147 - training loss: 0.2834, validation loss: 0.1459
2024-05-25 05:55:00 [INFO]: Epoch 148 - training loss: 0.2825, validation loss: 0.1458
2024-05-25 05:55:02 [INFO]: Epoch 149 - training loss: 0.2830, validation loss: 0.1457
2024-05-25 05:55:05 [INFO]: Epoch 150 - training loss: 0.2824, validation loss: 0.1453
2024-05-25 05:55:08 [INFO]: Epoch 151 - training loss: 0.2813, validation loss: 0.1451
2024-05-25 05:55:11 [INFO]: Epoch 152 - training loss: 0.2815, validation loss: 0.1448
2024-05-25 05:55:14 [INFO]: Epoch 153 - training loss: 0.2811, validation loss: 0.1446
2024-05-25 05:55:16 [INFO]: Epoch 154 - training loss: 0.2813, validation loss: 0.1446
2024-05-25 05:55:19 [INFO]: Epoch 155 - training loss: 0.2805, validation loss: 0.1441
2024-05-25 05:55:22 [INFO]: Epoch 156 - training loss: 0.2796, validation loss: 0.1439
2024-05-25 05:55:25 [INFO]: Epoch 157 - training loss: 0.2805, validation loss: 0.1437
2024-05-25 05:55:28 [INFO]: Epoch 158 - training loss: 0.2805, validation loss: 0.1436
2024-05-25 05:55:31 [INFO]: Epoch 159 - training loss: 0.2793, validation loss: 0.1431
2024-05-25 05:55:33 [INFO]: Epoch 160 - training loss: 0.2791, validation loss: 0.1428
2024-05-25 05:55:36 [INFO]: Epoch 161 - training loss: 0.2791, validation loss: 0.1428
2024-05-25 05:55:39 [INFO]: Epoch 162 - training loss: 0.2778, validation loss: 0.1426
2024-05-25 05:55:42 [INFO]: Epoch 163 - training loss: 0.2777, validation loss: 0.1423
2024-05-25 05:55:45 [INFO]: Epoch 164 - training loss: 0.2784, validation loss: 0.1422
2024-05-25 05:55:47 [INFO]: Epoch 165 - training loss: 0.2771, validation loss: 0.1419
2024-05-25 05:55:50 [INFO]: Epoch 166 - training loss: 0.2769, validation loss: 0.1419
2024-05-25 05:55:53 [INFO]: Epoch 167 - training loss: 0.2770, validation loss: 0.1416
2024-05-25 05:55:56 [INFO]: Epoch 168 - training loss: 0.2765, validation loss: 0.1414
2024-05-25 05:55:59 [INFO]: Epoch 169 - training loss: 0.2764, validation loss: 0.1414
2024-05-25 05:56:01 [INFO]: Epoch 170 - training loss: 0.2765, validation loss: 0.1411
2024-05-25 05:56:04 [INFO]: Epoch 171 - training loss: 0.2755, validation loss: 0.1411
2024-05-25 05:56:07 [INFO]: Epoch 172 - training loss: 0.2755, validation loss: 0.1406
2024-05-25 05:56:10 [INFO]: Epoch 173 - training loss: 0.2750, validation loss: 0.1404
2024-05-25 05:56:13 [INFO]: Epoch 174 - training loss: 0.2742, validation loss: 0.1402
2024-05-25 05:56:16 [INFO]: Epoch 175 - training loss: 0.2747, validation loss: 0.1402
2024-05-25 05:56:18 [INFO]: Epoch 176 - training loss: 0.2742, validation loss: 0.1400
2024-05-25 05:56:21 [INFO]: Epoch 177 - training loss: 0.2740, validation loss: 0.1399
2024-05-25 05:56:24 [INFO]: Epoch 178 - training loss: 0.2746, validation loss: 0.1396
2024-05-25 05:56:27 [INFO]: Epoch 179 - training loss: 0.2735, validation loss: 0.1395
2024-05-25 05:56:30 [INFO]: Epoch 180 - training loss: 0.2734, validation loss: 0.1392
2024-05-25 05:56:32 [INFO]: Epoch 181 - training loss: 0.2729, validation loss: 0.1391
2024-05-25 05:56:35 [INFO]: Epoch 182 - training loss: 0.2724, validation loss: 0.1388
2024-05-25 05:56:38 [INFO]: Epoch 183 - training loss: 0.2734, validation loss: 0.1388
2024-05-25 05:56:41 [INFO]: Epoch 184 - training loss: 0.2722, validation loss: 0.1387
2024-05-25 05:56:44 [INFO]: Epoch 185 - training loss: 0.2721, validation loss: 0.1383
2024-05-25 05:56:46 [INFO]: Epoch 186 - training loss: 0.2716, validation loss: 0.1384
2024-05-25 05:56:49 [INFO]: Epoch 187 - training loss: 0.2708, validation loss: 0.1381
2024-05-25 05:56:52 [INFO]: Epoch 188 - training loss: 0.2709, validation loss: 0.1382
2024-05-25 05:56:55 [INFO]: Epoch 189 - training loss: 0.2708, validation loss: 0.1380
2024-05-25 05:56:58 [INFO]: Epoch 190 - training loss: 0.2705, validation loss: 0.1376
2024-05-25 05:57:00 [INFO]: Epoch 191 - training loss: 0.2706, validation loss: 0.1377
2024-05-25 05:57:03 [INFO]: Epoch 192 - training loss: 0.2704, validation loss: 0.1372
2024-05-25 05:57:06 [INFO]: Epoch 193 - training loss: 0.2699, validation loss: 0.1374
2024-05-25 05:57:09 [INFO]: Epoch 194 - training loss: 0.2697, validation loss: 0.1371
2024-05-25 05:57:12 [INFO]: Epoch 195 - training loss: 0.2694, validation loss: 0.1371
2024-05-25 05:57:15 [INFO]: Epoch 196 - training loss: 0.2693, validation loss: 0.1369
2024-05-25 05:57:17 [INFO]: Epoch 197 - training loss: 0.2692, validation loss: 0.1369
2024-05-25 05:57:20 [INFO]: Epoch 198 - training loss: 0.2685, validation loss: 0.1365
2024-05-25 05:57:23 [INFO]: Epoch 199 - training loss: 0.2686, validation loss: 0.1364
2024-05-25 05:57:26 [INFO]: Epoch 200 - training loss: 0.2686, validation loss: 0.1360
2024-05-25 05:57:29 [INFO]: Epoch 201 - training loss: 0.2678, validation loss: 0.1362
2024-05-25 05:57:31 [INFO]: Epoch 202 - training loss: 0.2681, validation loss: 0.1363
2024-05-25 05:57:34 [INFO]: Epoch 203 - training loss: 0.2685, validation loss: 0.1360
2024-05-25 05:57:37 [INFO]: Epoch 204 - training loss: 0.2671, validation loss: 0.1358
2024-05-25 05:57:40 [INFO]: Epoch 205 - training loss: 0.2672, validation loss: 0.1355
2024-05-25 05:57:43 [INFO]: Epoch 206 - training loss: 0.2673, validation loss: 0.1356
2024-05-25 05:57:45 [INFO]: Epoch 207 - training loss: 0.2670, validation loss: 0.1354
2024-05-25 05:57:48 [INFO]: Epoch 208 - training loss: 0.2667, validation loss: 0.1352
2024-05-25 05:57:51 [INFO]: Epoch 209 - training loss: 0.2660, validation loss: 0.1351
2024-05-25 05:57:54 [INFO]: Epoch 210 - training loss: 0.2663, validation loss: 0.1349
2024-05-25 05:57:57 [INFO]: Epoch 211 - training loss: 0.2656, validation loss: 0.1350
2024-05-25 05:57:59 [INFO]: Epoch 212 - training loss: 0.2651, validation loss: 0.1351
2024-05-25 05:58:02 [INFO]: Epoch 213 - training loss: 0.2655, validation loss: 0.1346
2024-05-25 05:58:05 [INFO]: Epoch 214 - training loss: 0.2654, validation loss: 0.1346
2024-05-25 05:58:08 [INFO]: Epoch 215 - training loss: 0.2659, validation loss: 0.1345
2024-05-25 05:58:11 [INFO]: Epoch 216 - training loss: 0.2646, validation loss: 0.1344
2024-05-25 05:58:13 [INFO]: Epoch 217 - training loss: 0.2656, validation loss: 0.1343
2024-05-25 05:58:16 [INFO]: Epoch 218 - training loss: 0.2649, validation loss: 0.1342
2024-05-25 05:58:19 [INFO]: Epoch 219 - training loss: 0.2650, validation loss: 0.1340
2024-05-25 05:58:22 [INFO]: Epoch 220 - training loss: 0.2645, validation loss: 0.1339
2024-05-25 05:58:25 [INFO]: Epoch 221 - training loss: 0.2640, validation loss: 0.1339
2024-05-25 05:58:28 [INFO]: Epoch 222 - training loss: 0.2633, validation loss: 0.1337
2024-05-25 05:58:30 [INFO]: Epoch 223 - training loss: 0.2642, validation loss: 0.1336
2024-05-25 05:58:33 [INFO]: Epoch 224 - training loss: 0.2632, validation loss: 0.1334
2024-05-25 05:58:36 [INFO]: Epoch 225 - training loss: 0.2635, validation loss: 0.1335
2024-05-25 05:58:39 [INFO]: Epoch 226 - training loss: 0.2631, validation loss: 0.1330
2024-05-25 05:58:42 [INFO]: Epoch 227 - training loss: 0.2627, validation loss: 0.1331
2024-05-25 05:58:44 [INFO]: Epoch 228 - training loss: 0.2623, validation loss: 0.1332
2024-05-25 05:58:47 [INFO]: Epoch 229 - training loss: 0.2627, validation loss: 0.1330
2024-05-25 05:58:50 [INFO]: Epoch 230 - training loss: 0.2626, validation loss: 0.1330
2024-05-25 05:58:53 [INFO]: Epoch 231 - training loss: 0.2621, validation loss: 0.1326
2024-05-25 05:58:56 [INFO]: Epoch 232 - training loss: 0.2616, validation loss: 0.1327
2024-05-25 05:58:59 [INFO]: Epoch 233 - training loss: 0.2619, validation loss: 0.1326
2024-05-25 05:59:01 [INFO]: Epoch 234 - training loss: 0.2617, validation loss: 0.1325
2024-05-25 05:59:04 [INFO]: Epoch 235 - training loss: 0.2613, validation loss: 0.1323
2024-05-25 05:59:07 [INFO]: Epoch 236 - training loss: 0.2616, validation loss: 0.1322
2024-05-25 05:59:10 [INFO]: Epoch 237 - training loss: 0.2611, validation loss: 0.1322
2024-05-25 05:59:13 [INFO]: Epoch 238 - training loss: 0.2613, validation loss: 0.1321
2024-05-25 05:59:15 [INFO]: Epoch 239 - training loss: 0.2607, validation loss: 0.1321
2024-05-25 05:59:18 [INFO]: Epoch 240 - training loss: 0.2606, validation loss: 0.1321
2024-05-25 05:59:21 [INFO]: Epoch 241 - training loss: 0.2607, validation loss: 0.1318
2024-05-25 05:59:24 [INFO]: Epoch 242 - training loss: 0.2606, validation loss: 0.1316
2024-05-25 05:59:27 [INFO]: Epoch 243 - training loss: 0.2602, validation loss: 0.1316
2024-05-25 05:59:29 [INFO]: Epoch 244 - training loss: 0.2597, validation loss: 0.1316
2024-05-25 05:59:32 [INFO]: Epoch 245 - training loss: 0.2601, validation loss: 0.1316
2024-05-25 05:59:35 [INFO]: Epoch 246 - training loss: 0.2599, validation loss: 0.1313
2024-05-25 05:59:38 [INFO]: Epoch 247 - training loss: 0.2603, validation loss: 0.1315
2024-05-25 05:59:41 [INFO]: Epoch 248 - training loss: 0.2597, validation loss: 0.1312
2024-05-25 05:59:43 [INFO]: Epoch 249 - training loss: 0.2589, validation loss: 0.1312
2024-05-25 05:59:46 [INFO]: Epoch 250 - training loss: 0.2588, validation loss: 0.1310
2024-05-25 05:59:49 [INFO]: Epoch 251 - training loss: 0.2591, validation loss: 0.1309
2024-05-25 05:59:52 [INFO]: Epoch 252 - training loss: 0.2581, validation loss: 0.1310
2024-05-25 05:59:55 [INFO]: Epoch 253 - training loss: 0.2581, validation loss: 0.1310
2024-05-25 05:59:57 [INFO]: Epoch 254 - training loss: 0.2587, validation loss: 0.1309
2024-05-25 06:00:00 [INFO]: Epoch 255 - training loss: 0.2584, validation loss: 0.1307
2024-05-25 06:00:03 [INFO]: Epoch 256 - training loss: 0.2579, validation loss: 0.1305
2024-05-25 06:00:06 [INFO]: Epoch 257 - training loss: 0.2582, validation loss: 0.1307
2024-05-25 06:00:09 [INFO]: Epoch 258 - training loss: 0.2571, validation loss: 0.1305
2024-05-25 06:00:11 [INFO]: Epoch 259 - training loss: 0.2577, validation loss: 0.1305
2024-05-25 06:00:14 [INFO]: Epoch 260 - training loss: 0.2577, validation loss: 0.1305
2024-05-25 06:00:17 [INFO]: Epoch 261 - training loss: 0.2574, validation loss: 0.1304
2024-05-25 06:00:20 [INFO]: Epoch 262 - training loss: 0.2574, validation loss: 0.1303
2024-05-25 06:00:23 [INFO]: Epoch 263 - training loss: 0.2566, validation loss: 0.1300
2024-05-25 06:00:26 [INFO]: Epoch 264 - training loss: 0.2570, validation loss: 0.1302
2024-05-25 06:00:28 [INFO]: Epoch 265 - training loss: 0.2566, validation loss: 0.1301
2024-05-25 06:00:31 [INFO]: Epoch 266 - training loss: 0.2565, validation loss: 0.1300
2024-05-25 06:00:34 [INFO]: Epoch 267 - training loss: 0.2565, validation loss: 0.1299
2024-05-25 06:00:37 [INFO]: Epoch 268 - training loss: 0.2562, validation loss: 0.1299
2024-05-25 06:00:40 [INFO]: Epoch 269 - training loss: 0.2561, validation loss: 0.1298
2024-05-25 06:00:42 [INFO]: Epoch 270 - training loss: 0.2559, validation loss: 0.1296
2024-05-25 06:00:45 [INFO]: Epoch 271 - training loss: 0.2557, validation loss: 0.1295
2024-05-25 06:00:48 [INFO]: Epoch 272 - training loss: 0.2553, validation loss: 0.1297
2024-05-25 06:00:51 [INFO]: Epoch 273 - training loss: 0.2555, validation loss: 0.1296
2024-05-25 06:00:54 [INFO]: Epoch 274 - training loss: 0.2562, validation loss: 0.1295
2024-05-25 06:00:57 [INFO]: Epoch 275 - training loss: 0.2559, validation loss: 0.1294
2024-05-25 06:00:59 [INFO]: Epoch 276 - training loss: 0.2549, validation loss: 0.1295
2024-05-25 06:01:02 [INFO]: Epoch 277 - training loss: 0.2554, validation loss: 0.1296
2024-05-25 06:01:05 [INFO]: Epoch 278 - training loss: 0.2552, validation loss: 0.1293
2024-05-25 06:01:08 [INFO]: Epoch 279 - training loss: 0.2542, validation loss: 0.1292
2024-05-25 06:01:11 [INFO]: Epoch 280 - training loss: 0.2547, validation loss: 0.1293
2024-05-25 06:01:13 [INFO]: Epoch 281 - training loss: 0.2543, validation loss: 0.1292
2024-05-25 06:01:16 [INFO]: Epoch 282 - training loss: 0.2543, validation loss: 0.1291
2024-05-25 06:01:19 [INFO]: Epoch 283 - training loss: 0.2544, validation loss: 0.1291
2024-05-25 06:01:22 [INFO]: Epoch 284 - training loss: 0.2541, validation loss: 0.1290
2024-05-25 06:01:25 [INFO]: Epoch 285 - training loss: 0.2536, validation loss: 0.1291
2024-05-25 06:01:27 [INFO]: Epoch 286 - training loss: 0.2539, validation loss: 0.1289
2024-05-25 06:01:30 [INFO]: Epoch 287 - training loss: 0.2536, validation loss: 0.1290
2024-05-25 06:01:33 [INFO]: Epoch 288 - training loss: 0.2539, validation loss: 0.1290
2024-05-25 06:01:36 [INFO]: Epoch 289 - training loss: 0.2533, validation loss: 0.1286
2024-05-25 06:01:39 [INFO]: Epoch 290 - training loss: 0.2531, validation loss: 0.1287
2024-05-25 06:01:41 [INFO]: Epoch 291 - training loss: 0.2526, validation loss: 0.1286
2024-05-25 06:01:44 [INFO]: Epoch 292 - training loss: 0.2529, validation loss: 0.1287
2024-05-25 06:01:47 [INFO]: Epoch 293 - training loss: 0.2525, validation loss: 0.1285
2024-05-25 06:01:50 [INFO]: Epoch 294 - training loss: 0.2531, validation loss: 0.1287
2024-05-25 06:01:53 [INFO]: Epoch 295 - training loss: 0.2528, validation loss: 0.1284
2024-05-25 06:01:55 [INFO]: Epoch 296 - training loss: 0.2524, validation loss: 0.1285
2024-05-25 06:01:58 [INFO]: Epoch 297 - training loss: 0.2525, validation loss: 0.1284
2024-05-25 06:02:01 [INFO]: Epoch 298 - training loss: 0.2524, validation loss: 0.1284
2024-05-25 06:02:04 [INFO]: Epoch 299 - training loss: 0.2521, validation loss: 0.1286
2024-05-25 06:02:07 [INFO]: Epoch 300 - training loss: 0.2520, validation loss: 0.1282
2024-05-25 06:02:07 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 06:02:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_air_quality/20240525_T054803/BRITS.pypots
2024-05-25 06:02:07 [INFO]: BRITS on Air-Quality: MAE=0.1513, MSE=0.1326
2024-05-25 06:02:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_air_quality/imputation.pkl
2024-05-25 06:02:07 [INFO]: Using the given device: cuda:0
2024-05-25 06:02:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207
2024-05-25 06:02:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/tensorboard
2024-05-25 06:02:07 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:02:12 [INFO]: Epoch 001 - training loss: 1.4481, validation loss: 0.8447
2024-05-25 06:02:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch1_loss0.8446504712104798.pypots
2024-05-25 06:02:16 [INFO]: Epoch 002 - training loss: 1.0060, validation loss: 0.7819
2024-05-25 06:02:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch2_loss0.7818535923957824.pypots
2024-05-25 06:02:20 [INFO]: Epoch 003 - training loss: 0.9304, validation loss: 0.7560
2024-05-25 06:02:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch3_loss0.7560342729091645.pypots
2024-05-25 06:02:24 [INFO]: Epoch 004 - training loss: 0.8974, validation loss: 0.7402
2024-05-25 06:02:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch4_loss0.7402087718248367.pypots
2024-05-25 06:02:28 [INFO]: Epoch 005 - training loss: 0.9099, validation loss: 0.7316
2024-05-25 06:02:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch5_loss0.7315505683422089.pypots
2024-05-25 06:02:32 [INFO]: Epoch 006 - training loss: 0.8983, validation loss: 0.7243
2024-05-25 06:02:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch6_loss0.724330672621727.pypots
2024-05-25 06:02:36 [INFO]: Epoch 007 - training loss: 0.8958, validation loss: 0.7190
2024-05-25 06:02:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch7_loss0.718966743350029.pypots
2024-05-25 06:02:39 [INFO]: Epoch 008 - training loss: 0.8619, validation loss: 0.7145
2024-05-25 06:02:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch8_loss0.7145127415657043.pypots
2024-05-25 06:02:43 [INFO]: Epoch 009 - training loss: 0.8449, validation loss: 0.7113
2024-05-25 06:02:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch9_loss0.7112704455852509.pypots
2024-05-25 06:02:47 [INFO]: Epoch 010 - training loss: 0.8521, validation loss: 0.7081
2024-05-25 06:02:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch10_loss0.7081427365541458.pypots
2024-05-25 06:02:51 [INFO]: Epoch 011 - training loss: 0.8550, validation loss: 0.7065
2024-05-25 06:02:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch11_loss0.7065008580684662.pypots
2024-05-25 06:02:55 [INFO]: Epoch 012 - training loss: 0.8494, validation loss: 0.7058
2024-05-25 06:02:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch12_loss0.7058046460151672.pypots
2024-05-25 06:02:59 [INFO]: Epoch 013 - training loss: 0.8432, validation loss: 0.7045
2024-05-25 06:02:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch13_loss0.7045115441083908.pypots
2024-05-25 06:03:03 [INFO]: Epoch 014 - training loss: 0.8328, validation loss: 0.7028
2024-05-25 06:03:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch14_loss0.7028106480836869.pypots
2024-05-25 06:03:07 [INFO]: Epoch 015 - training loss: 0.8360, validation loss: 0.7036
2024-05-25 06:03:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch15_loss0.7035513788461685.pypots
2024-05-25 06:03:11 [INFO]: Epoch 016 - training loss: 0.8245, validation loss: 0.7014
2024-05-25 06:03:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch16_loss0.7014264464378357.pypots
2024-05-25 06:03:14 [INFO]: Epoch 017 - training loss: 0.8431, validation loss: 0.7007
2024-05-25 06:03:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch17_loss0.7006584793329239.pypots
2024-05-25 06:03:18 [INFO]: Epoch 018 - training loss: 0.8575, validation loss: 0.7004
2024-05-25 06:03:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch18_loss0.7003644526004791.pypots
2024-05-25 06:03:22 [INFO]: Epoch 019 - training loss: 0.8235, validation loss: 0.7005
2024-05-25 06:03:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch19_loss0.7005381941795349.pypots
2024-05-25 06:03:26 [INFO]: Epoch 020 - training loss: 0.8126, validation loss: 0.7009
2024-05-25 06:03:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch20_loss0.7008536100387573.pypots
2024-05-25 06:03:30 [INFO]: Epoch 021 - training loss: 0.8075, validation loss: 0.7001
2024-05-25 06:03:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch21_loss0.7001218259334564.pypots
2024-05-25 06:03:34 [INFO]: Epoch 022 - training loss: 0.8119, validation loss: 0.6999
2024-05-25 06:03:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch22_loss0.6999455362558364.pypots
2024-05-25 06:03:38 [INFO]: Epoch 023 - training loss: 0.8178, validation loss: 0.7001
2024-05-25 06:03:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch23_loss0.7000783234834671.pypots
2024-05-25 06:03:42 [INFO]: Epoch 024 - training loss: 0.8053, validation loss: 0.6989
2024-05-25 06:03:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch24_loss0.6989480257034302.pypots
2024-05-25 06:03:46 [INFO]: Epoch 025 - training loss: 0.8053, validation loss: 0.7006
2024-05-25 06:03:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch25_loss0.7006141602993011.pypots
2024-05-25 06:03:50 [INFO]: Epoch 026 - training loss: 0.8091, validation loss: 0.6989
2024-05-25 06:03:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch26_loss0.698928689956665.pypots
2024-05-25 06:03:53 [INFO]: Epoch 027 - training loss: 0.8260, validation loss: 0.7018
2024-05-25 06:03:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch27_loss0.7018280684947967.pypots
2024-05-25 06:03:57 [INFO]: Epoch 028 - training loss: 0.8092, validation loss: 0.7002
2024-05-25 06:03:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch28_loss0.7002437621355057.pypots
2024-05-25 06:04:01 [INFO]: Epoch 029 - training loss: 0.7937, validation loss: 0.6997
2024-05-25 06:04:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch29_loss0.699687460064888.pypots
2024-05-25 06:04:05 [INFO]: Epoch 030 - training loss: 0.8109, validation loss: 0.7005
2024-05-25 06:04:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch30_loss0.7004744946956635.pypots
2024-05-25 06:04:09 [INFO]: Epoch 031 - training loss: 0.7963, validation loss: 0.7065
2024-05-25 06:04:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch31_loss0.706490296125412.pypots
2024-05-25 06:04:13 [INFO]: Epoch 032 - training loss: 0.7974, validation loss: 0.7025
2024-05-25 06:04:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch32_loss0.7024635970592499.pypots
2024-05-25 06:04:17 [INFO]: Epoch 033 - training loss: 0.8055, validation loss: 0.6984
2024-05-25 06:04:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch33_loss0.6984201937913894.pypots
2024-05-25 06:04:21 [INFO]: Epoch 034 - training loss: 0.7884, validation loss: 0.7033
2024-05-25 06:04:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch34_loss0.7033083617687226.pypots
2024-05-25 06:04:25 [INFO]: Epoch 035 - training loss: 0.7983, validation loss: 0.7016
2024-05-25 06:04:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch35_loss0.7015509575605392.pypots
2024-05-25 06:04:29 [INFO]: Epoch 036 - training loss: 0.7793, validation loss: 0.7013
2024-05-25 06:04:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch36_loss0.701322740316391.pypots
2024-05-25 06:04:32 [INFO]: Epoch 037 - training loss: 0.7901, validation loss: 0.7001
2024-05-25 06:04:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch37_loss0.700100114941597.pypots
2024-05-25 06:04:36 [INFO]: Epoch 038 - training loss: 0.7777, validation loss: 0.7054
2024-05-25 06:04:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch38_loss0.705372542142868.pypots
2024-05-25 06:04:40 [INFO]: Epoch 039 - training loss: 0.7681, validation loss: 0.7060
2024-05-25 06:04:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch39_loss0.7060480535030365.pypots
2024-05-25 06:04:44 [INFO]: Epoch 040 - training loss: 0.7791, validation loss: 0.7032
2024-05-25 06:04:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch40_loss0.7031695395708084.pypots
2024-05-25 06:04:48 [INFO]: Epoch 041 - training loss: 0.7739, validation loss: 0.7062
2024-05-25 06:04:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch41_loss0.7061799049377442.pypots
2024-05-25 06:04:52 [INFO]: Epoch 042 - training loss: 0.7952, validation loss: 0.7058
2024-05-25 06:04:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch42_loss0.7058270007371903.pypots
2024-05-25 06:04:56 [INFO]: Epoch 043 - training loss: 0.7874, validation loss: 0.7051
2024-05-25 06:04:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN_epoch43_loss0.7050572276115418.pypots
2024-05-25 06:04:56 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:04:56 [INFO]: Finished training. The best model is from epoch#33.
2024-05-25 06:04:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_air_quality/20240525_T060207/MRNN.pypots
2024-05-25 06:04:57 [INFO]: MRNN on Air-Quality: MAE=0.5217, MSE=0.6355
2024-05-25 06:04:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_air_quality/imputation.pkl
2024-05-25 06:04:57 [INFO]: Using the given device: cpu
2024-05-25 06:04:57 [INFO]: LOCF on Air-Quality: MAE=0.2194, MSE=0.3465
2024-05-25 06:04:57 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_air_quality".
2024-05-25 06:04:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_air_quality/imputation.pkl
2024-05-25 06:04:57 [INFO]: Median on Air-Quality: MAE=0.6629, MSE=1.0282
2024-05-25 06:04:57 [INFO]: Successfully created the given path "saved_results/round_2/Median_air_quality".
2024-05-25 06:04:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_air_quality/imputation.pkl
2024-05-25 06:04:57 [INFO]: Mean on Air-Quality: MAE=0.6945, MSE=0.9678
2024-05-25 06:04:57 [INFO]: Successfully created the given path "saved_results/round_2/Mean_air_quality".
2024-05-25 06:04:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_air_quality/imputation.pkl
2024-05-25 06:04:57 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-25 06:04:57 [INFO]: Using the given device: cuda:0
2024-05-25 06:04:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T060457
2024-05-25 06:04:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T060457/tensorboard
2024-05-25 06:04:57 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 06:04:57 [INFO]: Epoch 001 - training loss: 1.0567, validation loss: 0.5558
2024-05-25 06:04:58 [INFO]: Epoch 002 - training loss: 0.7652, validation loss: 0.4319
2024-05-25 06:04:59 [INFO]: Epoch 003 - training loss: 0.6567, validation loss: 0.3571
2024-05-25 06:04:59 [INFO]: Epoch 004 - training loss: 0.5817, validation loss: 0.3099
2024-05-25 06:05:00 [INFO]: Epoch 005 - training loss: 0.5263, validation loss: 0.2850
2024-05-25 06:05:01 [INFO]: Epoch 006 - training loss: 0.4874, validation loss: 0.2680
2024-05-25 06:05:01 [INFO]: Epoch 007 - training loss: 0.4590, validation loss: 0.2556
2024-05-25 06:05:02 [INFO]: Epoch 008 - training loss: 0.4397, validation loss: 0.2479
2024-05-25 06:05:02 [INFO]: Epoch 009 - training loss: 0.4260, validation loss: 0.2424
2024-05-25 06:05:03 [INFO]: Epoch 010 - training loss: 0.4141, validation loss: 0.2362
2024-05-25 06:05:04 [INFO]: Epoch 011 - training loss: 0.4049, validation loss: 0.2325
2024-05-25 06:05:04 [INFO]: Epoch 012 - training loss: 0.3950, validation loss: 0.2281
2024-05-25 06:05:05 [INFO]: Epoch 013 - training loss: 0.3871, validation loss: 0.2245
2024-05-25 06:05:05 [INFO]: Epoch 014 - training loss: 0.3808, validation loss: 0.2210
2024-05-25 06:05:06 [INFO]: Epoch 015 - training loss: 0.3733, validation loss: 0.2180
2024-05-25 06:05:07 [INFO]: Epoch 016 - training loss: 0.3672, validation loss: 0.2157
2024-05-25 06:05:07 [INFO]: Epoch 017 - training loss: 0.3614, validation loss: 0.2131
2024-05-25 06:05:08 [INFO]: Epoch 018 - training loss: 0.3561, validation loss: 0.2105
2024-05-25 06:05:08 [INFO]: Epoch 019 - training loss: 0.3511, validation loss: 0.2093
2024-05-25 06:05:09 [INFO]: Epoch 020 - training loss: 0.3484, validation loss: 0.2075
2024-05-25 06:05:10 [INFO]: Epoch 021 - training loss: 0.3454, validation loss: 0.2058
2024-05-25 06:05:10 [INFO]: Epoch 022 - training loss: 0.3402, validation loss: 0.2027
2024-05-25 06:05:11 [INFO]: Epoch 023 - training loss: 0.3367, validation loss: 0.2009
2024-05-25 06:05:11 [INFO]: Epoch 024 - training loss: 0.3358, validation loss: 0.1998
2024-05-25 06:05:12 [INFO]: Epoch 025 - training loss: 0.3323, validation loss: 0.1987
2024-05-25 06:05:13 [INFO]: Epoch 026 - training loss: 0.3285, validation loss: 0.1965
2024-05-25 06:05:13 [INFO]: Epoch 027 - training loss: 0.3249, validation loss: 0.1946
2024-05-25 06:05:14 [INFO]: Epoch 028 - training loss: 0.3222, validation loss: 0.1945
2024-05-25 06:05:14 [INFO]: Epoch 029 - training loss: 0.3200, validation loss: 0.1911
2024-05-25 06:05:15 [INFO]: Epoch 030 - training loss: 0.3185, validation loss: 0.1909
2024-05-25 06:05:16 [INFO]: Epoch 031 - training loss: 0.3166, validation loss: 0.1887
2024-05-25 06:05:16 [INFO]: Epoch 032 - training loss: 0.3130, validation loss: 0.1886
2024-05-25 06:05:17 [INFO]: Epoch 033 - training loss: 0.3115, validation loss: 0.1872
2024-05-25 06:05:17 [INFO]: Epoch 034 - training loss: 0.3101, validation loss: 0.1854
2024-05-25 06:05:18 [INFO]: Epoch 035 - training loss: 0.3086, validation loss: 0.1843
2024-05-25 06:05:19 [INFO]: Epoch 036 - training loss: 0.3057, validation loss: 0.1831
2024-05-25 06:05:19 [INFO]: Epoch 037 - training loss: 0.3031, validation loss: 0.1815
2024-05-25 06:05:20 [INFO]: Epoch 038 - training loss: 0.3007, validation loss: 0.1798
2024-05-25 06:05:20 [INFO]: Epoch 039 - training loss: 0.3000, validation loss: 0.1791
2024-05-25 06:05:21 [INFO]: Epoch 040 - training loss: 0.2988, validation loss: 0.1786
2024-05-25 06:05:22 [INFO]: Epoch 041 - training loss: 0.2961, validation loss: 0.1763
2024-05-25 06:05:22 [INFO]: Epoch 042 - training loss: 0.2942, validation loss: 0.1750
2024-05-25 06:05:23 [INFO]: Epoch 043 - training loss: 0.2923, validation loss: 0.1741
2024-05-25 06:05:23 [INFO]: Epoch 044 - training loss: 0.2924, validation loss: 0.1732
2024-05-25 06:05:24 [INFO]: Epoch 045 - training loss: 0.2902, validation loss: 0.1727
2024-05-25 06:05:25 [INFO]: Epoch 046 - training loss: 0.2886, validation loss: 0.1711
2024-05-25 06:05:25 [INFO]: Epoch 047 - training loss: 0.2866, validation loss: 0.1705
2024-05-25 06:05:26 [INFO]: Epoch 048 - training loss: 0.2851, validation loss: 0.1692
2024-05-25 06:05:27 [INFO]: Epoch 049 - training loss: 0.2842, validation loss: 0.1688
2024-05-25 06:05:27 [INFO]: Epoch 050 - training loss: 0.2819, validation loss: 0.1676
2024-05-25 06:05:28 [INFO]: Epoch 051 - training loss: 0.2813, validation loss: 0.1666
2024-05-25 06:05:28 [INFO]: Epoch 052 - training loss: 0.2793, validation loss: 0.1647
2024-05-25 06:05:29 [INFO]: Epoch 053 - training loss: 0.2773, validation loss: 0.1646
2024-05-25 06:05:30 [INFO]: Epoch 054 - training loss: 0.2760, validation loss: 0.1641
2024-05-25 06:05:30 [INFO]: Epoch 055 - training loss: 0.2753, validation loss: 0.1638
2024-05-25 06:05:31 [INFO]: Epoch 056 - training loss: 0.2743, validation loss: 0.1643
2024-05-25 06:05:31 [INFO]: Epoch 057 - training loss: 0.2735, validation loss: 0.1621
2024-05-25 06:05:32 [INFO]: Epoch 058 - training loss: 0.2732, validation loss: 0.1619
2024-05-25 06:05:33 [INFO]: Epoch 059 - training loss: 0.2696, validation loss: 0.1620
2024-05-25 06:05:33 [INFO]: Epoch 060 - training loss: 0.2672, validation loss: 0.1614
2024-05-25 06:05:34 [INFO]: Epoch 061 - training loss: 0.2665, validation loss: 0.1604
2024-05-25 06:05:35 [INFO]: Epoch 062 - training loss: 0.2653, validation loss: 0.1610
2024-05-25 06:05:35 [INFO]: Epoch 063 - training loss: 0.2642, validation loss: 0.1593
2024-05-25 06:05:36 [INFO]: Epoch 064 - training loss: 0.2634, validation loss: 0.1587
2024-05-25 06:05:36 [INFO]: Epoch 065 - training loss: 0.2626, validation loss: 0.1591
2024-05-25 06:05:37 [INFO]: Epoch 066 - training loss: 0.2616, validation loss: 0.1593
2024-05-25 06:05:38 [INFO]: Epoch 067 - training loss: 0.2596, validation loss: 0.1577
2024-05-25 06:05:38 [INFO]: Epoch 068 - training loss: 0.2597, validation loss: 0.1576
2024-05-25 06:05:39 [INFO]: Epoch 069 - training loss: 0.2582, validation loss: 0.1571
2024-05-25 06:05:39 [INFO]: Epoch 070 - training loss: 0.2593, validation loss: 0.1585
2024-05-25 06:05:40 [INFO]: Epoch 071 - training loss: 0.2576, validation loss: 0.1570
2024-05-25 06:05:41 [INFO]: Epoch 072 - training loss: 0.2547, validation loss: 0.1564
2024-05-25 06:05:41 [INFO]: Epoch 073 - training loss: 0.2544, validation loss: 0.1572
2024-05-25 06:05:42 [INFO]: Epoch 074 - training loss: 0.2552, validation loss: 0.1567
2024-05-25 06:05:42 [INFO]: Epoch 075 - training loss: 0.2510, validation loss: 0.1554
2024-05-25 06:05:43 [INFO]: Epoch 076 - training loss: 0.2499, validation loss: 0.1541
2024-05-25 06:05:44 [INFO]: Epoch 077 - training loss: 0.2492, validation loss: 0.1549
2024-05-25 06:05:44 [INFO]: Epoch 078 - training loss: 0.2493, validation loss: 0.1543
2024-05-25 06:05:45 [INFO]: Epoch 079 - training loss: 0.2477, validation loss: 0.1537
2024-05-25 06:05:45 [INFO]: Epoch 080 - training loss: 0.2468, validation loss: 0.1541
2024-05-25 06:05:46 [INFO]: Epoch 081 - training loss: 0.2467, validation loss: 0.1533
2024-05-25 06:05:47 [INFO]: Epoch 082 - training loss: 0.2447, validation loss: 0.1532
2024-05-25 06:05:47 [INFO]: Epoch 083 - training loss: 0.2442, validation loss: 0.1524
2024-05-25 06:05:48 [INFO]: Epoch 084 - training loss: 0.2436, validation loss: 0.1528
2024-05-25 06:05:48 [INFO]: Epoch 085 - training loss: 0.2420, validation loss: 0.1518
2024-05-25 06:05:49 [INFO]: Epoch 086 - training loss: 0.2408, validation loss: 0.1520
2024-05-25 06:05:50 [INFO]: Epoch 087 - training loss: 0.2415, validation loss: 0.1518
2024-05-25 06:05:50 [INFO]: Epoch 088 - training loss: 0.2398, validation loss: 0.1520
2024-05-25 06:05:51 [INFO]: Epoch 089 - training loss: 0.2391, validation loss: 0.1500
2024-05-25 06:05:51 [INFO]: Epoch 090 - training loss: 0.2379, validation loss: 0.1516
2024-05-25 06:05:52 [INFO]: Epoch 091 - training loss: 0.2390, validation loss: 0.1515
2024-05-25 06:05:53 [INFO]: Epoch 092 - training loss: 0.2368, validation loss: 0.1516
2024-05-25 06:05:53 [INFO]: Epoch 093 - training loss: 0.2370, validation loss: 0.1503
2024-05-25 06:05:54 [INFO]: Epoch 094 - training loss: 0.2370, validation loss: 0.1509
2024-05-25 06:05:54 [INFO]: Epoch 095 - training loss: 0.2366, validation loss: 0.1506
2024-05-25 06:05:55 [INFO]: Epoch 096 - training loss: 0.2353, validation loss: 0.1496
2024-05-25 06:05:56 [INFO]: Epoch 097 - training loss: 0.2347, validation loss: 0.1493
2024-05-25 06:05:56 [INFO]: Epoch 098 - training loss: 0.2334, validation loss: 0.1489
2024-05-25 06:05:57 [INFO]: Epoch 099 - training loss: 0.2323, validation loss: 0.1488
2024-05-25 06:05:58 [INFO]: Epoch 100 - training loss: 0.2323, validation loss: 0.1484
2024-05-25 06:05:58 [INFO]: Epoch 101 - training loss: 0.2331, validation loss: 0.1490
2024-05-25 06:05:59 [INFO]: Epoch 102 - training loss: 0.2314, validation loss: 0.1481
2024-05-25 06:05:59 [INFO]: Epoch 103 - training loss: 0.2297, validation loss: 0.1481
2024-05-25 06:06:00 [INFO]: Epoch 104 - training loss: 0.2291, validation loss: 0.1470
2024-05-25 06:06:01 [INFO]: Epoch 105 - training loss: 0.2303, validation loss: 0.1478
2024-05-25 06:06:01 [INFO]: Epoch 106 - training loss: 0.2298, validation loss: 0.1468
2024-05-25 06:06:02 [INFO]: Epoch 107 - training loss: 0.2286, validation loss: 0.1476
2024-05-25 06:06:02 [INFO]: Epoch 108 - training loss: 0.2272, validation loss: 0.1477
2024-05-25 06:06:03 [INFO]: Epoch 109 - training loss: 0.2267, validation loss: 0.1479
2024-05-25 06:06:04 [INFO]: Epoch 110 - training loss: 0.2285, validation loss: 0.1461
2024-05-25 06:06:04 [INFO]: Epoch 111 - training loss: 0.2276, validation loss: 0.1468
2024-05-25 06:06:05 [INFO]: Epoch 112 - training loss: 0.2244, validation loss: 0.1455
2024-05-25 06:06:05 [INFO]: Epoch 113 - training loss: 0.2242, validation loss: 0.1456
2024-05-25 06:06:06 [INFO]: Epoch 114 - training loss: 0.2241, validation loss: 0.1451
2024-05-25 06:06:07 [INFO]: Epoch 115 - training loss: 0.2228, validation loss: 0.1456
2024-05-25 06:06:07 [INFO]: Epoch 116 - training loss: 0.2216, validation loss: 0.1451
2024-05-25 06:06:08 [INFO]: Epoch 117 - training loss: 0.2212, validation loss: 0.1453
2024-05-25 06:06:08 [INFO]: Epoch 118 - training loss: 0.2236, validation loss: 0.1457
2024-05-25 06:06:09 [INFO]: Epoch 119 - training loss: 0.2199, validation loss: 0.1440
2024-05-25 06:06:10 [INFO]: Epoch 120 - training loss: 0.2197, validation loss: 0.1442
2024-05-25 06:06:10 [INFO]: Epoch 121 - training loss: 0.2199, validation loss: 0.1442
2024-05-25 06:06:11 [INFO]: Epoch 122 - training loss: 0.2191, validation loss: 0.1440
2024-05-25 06:06:11 [INFO]: Epoch 123 - training loss: 0.2182, validation loss: 0.1444
2024-05-25 06:06:12 [INFO]: Epoch 124 - training loss: 0.2183, validation loss: 0.1433
2024-05-25 06:06:13 [INFO]: Epoch 125 - training loss: 0.2166, validation loss: 0.1429
2024-05-25 06:06:13 [INFO]: Epoch 126 - training loss: 0.2165, validation loss: 0.1445
2024-05-25 06:06:14 [INFO]: Epoch 127 - training loss: 0.2171, validation loss: 0.1433
2024-05-25 06:06:14 [INFO]: Epoch 128 - training loss: 0.2168, validation loss: 0.1440
2024-05-25 06:06:15 [INFO]: Epoch 129 - training loss: 0.2159, validation loss: 0.1431
2024-05-25 06:06:16 [INFO]: Epoch 130 - training loss: 0.2157, validation loss: 0.1437
2024-05-25 06:06:16 [INFO]: Epoch 131 - training loss: 0.2139, validation loss: 0.1425
2024-05-25 06:06:17 [INFO]: Epoch 132 - training loss: 0.2133, validation loss: 0.1431
2024-05-25 06:06:17 [INFO]: Epoch 133 - training loss: 0.2165, validation loss: 0.1433
2024-05-25 06:06:18 [INFO]: Epoch 134 - training loss: 0.2150, validation loss: 0.1434
2024-05-25 06:06:19 [INFO]: Epoch 135 - training loss: 0.2133, validation loss: 0.1433
2024-05-25 06:06:19 [INFO]: Epoch 136 - training loss: 0.2119, validation loss: 0.1424
2024-05-25 06:06:20 [INFO]: Epoch 137 - training loss: 0.2111, validation loss: 0.1420
2024-05-25 06:06:20 [INFO]: Epoch 138 - training loss: 0.2106, validation loss: 0.1426
2024-05-25 06:06:21 [INFO]: Epoch 139 - training loss: 0.2102, validation loss: 0.1429
2024-05-25 06:06:22 [INFO]: Epoch 140 - training loss: 0.2103, validation loss: 0.1429
2024-05-25 06:06:22 [INFO]: Epoch 141 - training loss: 0.2100, validation loss: 0.1421
2024-05-25 06:06:23 [INFO]: Epoch 142 - training loss: 0.2086, validation loss: 0.1421
2024-05-25 06:06:24 [INFO]: Epoch 143 - training loss: 0.2084, validation loss: 0.1422
2024-05-25 06:06:24 [INFO]: Epoch 144 - training loss: 0.2092, validation loss: 0.1397
2024-05-25 06:06:25 [INFO]: Epoch 145 - training loss: 0.2091, validation loss: 0.1407
2024-05-25 06:06:25 [INFO]: Epoch 146 - training loss: 0.2080, validation loss: 0.1407
2024-05-25 06:06:26 [INFO]: Epoch 147 - training loss: 0.2078, validation loss: 0.1409
2024-05-25 06:06:27 [INFO]: Epoch 148 - training loss: 0.2077, validation loss: 0.1410
2024-05-25 06:06:27 [INFO]: Epoch 149 - training loss: 0.2075, validation loss: 0.1413
2024-05-25 06:06:28 [INFO]: Epoch 150 - training loss: 0.2068, validation loss: 0.1405
2024-05-25 06:06:28 [INFO]: Epoch 151 - training loss: 0.2053, validation loss: 0.1410
2024-05-25 06:06:29 [INFO]: Epoch 152 - training loss: 0.2061, validation loss: 0.1421
2024-05-25 06:06:30 [INFO]: Epoch 153 - training loss: 0.2061, validation loss: 0.1405
2024-05-25 06:06:30 [INFO]: Epoch 154 - training loss: 0.2059, validation loss: 0.1414
2024-05-25 06:06:30 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:06:30 [INFO]: Finished training. The best model is from epoch#144.
2024-05-25 06:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_air_quality/20240525_T060457/SAITS.pypots
2024-05-25 06:06:30 [INFO]: SAITS on Air-Quality: MAE=0.1626, MSE=0.1465
2024-05-25 06:06:30 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_air_quality/imputation.pkl
2024-05-25 06:06:30 [INFO]: Using the given device: cuda:0
2024-05-25 06:06:30 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T060630
2024-05-25 06:06:30 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T060630/tensorboard
2024-05-25 06:06:30 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 06:06:31 [INFO]: Epoch 001 - training loss: 0.9072, validation loss: 0.5010
2024-05-25 06:06:31 [INFO]: Epoch 002 - training loss: 0.5755, validation loss: 0.3830
2024-05-25 06:06:31 [INFO]: Epoch 003 - training loss: 0.4884, validation loss: 0.3222
2024-05-25 06:06:31 [INFO]: Epoch 004 - training loss: 0.4408, validation loss: 0.2868
2024-05-25 06:06:32 [INFO]: Epoch 005 - training loss: 0.4095, validation loss: 0.2707
2024-05-25 06:06:32 [INFO]: Epoch 006 - training loss: 0.3913, validation loss: 0.2606
2024-05-25 06:06:32 [INFO]: Epoch 007 - training loss: 0.3753, validation loss: 0.2544
2024-05-25 06:06:32 [INFO]: Epoch 008 - training loss: 0.3642, validation loss: 0.2507
2024-05-25 06:06:33 [INFO]: Epoch 009 - training loss: 0.3556, validation loss: 0.2420
2024-05-25 06:06:33 [INFO]: Epoch 010 - training loss: 0.3461, validation loss: 0.2382
2024-05-25 06:06:33 [INFO]: Epoch 011 - training loss: 0.3382, validation loss: 0.2329
2024-05-25 06:06:33 [INFO]: Epoch 012 - training loss: 0.3314, validation loss: 0.2301
2024-05-25 06:06:34 [INFO]: Epoch 013 - training loss: 0.3290, validation loss: 0.2261
2024-05-25 06:06:34 [INFO]: Epoch 014 - training loss: 0.3227, validation loss: 0.2240
2024-05-25 06:06:34 [INFO]: Epoch 015 - training loss: 0.3187, validation loss: 0.2207
2024-05-25 06:06:35 [INFO]: Epoch 016 - training loss: 0.3139, validation loss: 0.2169
2024-05-25 06:06:35 [INFO]: Epoch 017 - training loss: 0.3112, validation loss: 0.2170
2024-05-25 06:06:35 [INFO]: Epoch 018 - training loss: 0.3055, validation loss: 0.2110
2024-05-25 06:06:35 [INFO]: Epoch 019 - training loss: 0.3008, validation loss: 0.2104
2024-05-25 06:06:36 [INFO]: Epoch 020 - training loss: 0.2991, validation loss: 0.2075
2024-05-25 06:06:36 [INFO]: Epoch 021 - training loss: 0.2965, validation loss: 0.2052
2024-05-25 06:06:36 [INFO]: Epoch 022 - training loss: 0.2960, validation loss: 0.2018
2024-05-25 06:06:36 [INFO]: Epoch 023 - training loss: 0.2904, validation loss: 0.2020
2024-05-25 06:06:37 [INFO]: Epoch 024 - training loss: 0.2880, validation loss: 0.1991
2024-05-25 06:06:37 [INFO]: Epoch 025 - training loss: 0.2838, validation loss: 0.1984
2024-05-25 06:06:37 [INFO]: Epoch 026 - training loss: 0.2870, validation loss: 0.1973
2024-05-25 06:06:37 [INFO]: Epoch 027 - training loss: 0.2844, validation loss: 0.1951
2024-05-25 06:06:38 [INFO]: Epoch 028 - training loss: 0.2836, validation loss: 0.1958
2024-05-25 06:06:38 [INFO]: Epoch 029 - training loss: 0.2784, validation loss: 0.1938
2024-05-25 06:06:38 [INFO]: Epoch 030 - training loss: 0.2772, validation loss: 0.1974
2024-05-25 06:06:38 [INFO]: Epoch 031 - training loss: 0.2751, validation loss: 0.1945
2024-05-25 06:06:39 [INFO]: Epoch 032 - training loss: 0.2715, validation loss: 0.1932
2024-05-25 06:06:39 [INFO]: Epoch 033 - training loss: 0.2699, validation loss: 0.1919
2024-05-25 06:06:39 [INFO]: Epoch 034 - training loss: 0.2669, validation loss: 0.1904
2024-05-25 06:06:39 [INFO]: Epoch 035 - training loss: 0.2669, validation loss: 0.1891
2024-05-25 06:06:40 [INFO]: Epoch 036 - training loss: 0.2632, validation loss: 0.1888
2024-05-25 06:06:40 [INFO]: Epoch 037 - training loss: 0.2644, validation loss: 0.1862
2024-05-25 06:06:40 [INFO]: Epoch 038 - training loss: 0.2636, validation loss: 0.1894
2024-05-25 06:06:40 [INFO]: Epoch 039 - training loss: 0.2635, validation loss: 0.1873
2024-05-25 06:06:41 [INFO]: Epoch 040 - training loss: 0.2594, validation loss: 0.1877
2024-05-25 06:06:41 [INFO]: Epoch 041 - training loss: 0.2570, validation loss: 0.1867
2024-05-25 06:06:41 [INFO]: Epoch 042 - training loss: 0.2545, validation loss: 0.1870
2024-05-25 06:06:41 [INFO]: Epoch 043 - training loss: 0.2528, validation loss: 0.1849
2024-05-25 06:06:42 [INFO]: Epoch 044 - training loss: 0.2517, validation loss: 0.1841
2024-05-25 06:06:42 [INFO]: Epoch 045 - training loss: 0.2505, validation loss: 0.1860
2024-05-25 06:06:42 [INFO]: Epoch 046 - training loss: 0.2503, validation loss: 0.1836
2024-05-25 06:06:42 [INFO]: Epoch 047 - training loss: 0.2486, validation loss: 0.1850
2024-05-25 06:06:43 [INFO]: Epoch 048 - training loss: 0.2469, validation loss: 0.1847
2024-05-25 06:06:43 [INFO]: Epoch 049 - training loss: 0.2460, validation loss: 0.1846
2024-05-25 06:06:43 [INFO]: Epoch 050 - training loss: 0.2440, validation loss: 0.1819
2024-05-25 06:06:43 [INFO]: Epoch 051 - training loss: 0.2423, validation loss: 0.1799
2024-05-25 06:06:44 [INFO]: Epoch 052 - training loss: 0.2454, validation loss: 0.1808
2024-05-25 06:06:44 [INFO]: Epoch 053 - training loss: 0.2426, validation loss: 0.1833
2024-05-25 06:06:44 [INFO]: Epoch 054 - training loss: 0.2425, validation loss: 0.1820
2024-05-25 06:06:44 [INFO]: Epoch 055 - training loss: 0.2419, validation loss: 0.1802
2024-05-25 06:06:45 [INFO]: Epoch 056 - training loss: 0.2375, validation loss: 0.1800
2024-05-25 06:06:45 [INFO]: Epoch 057 - training loss: 0.2356, validation loss: 0.1798
2024-05-25 06:06:45 [INFO]: Epoch 058 - training loss: 0.2384, validation loss: 0.1841
2024-05-25 06:06:45 [INFO]: Epoch 059 - training loss: 0.2387, validation loss: 0.1790
2024-05-25 06:06:46 [INFO]: Epoch 060 - training loss: 0.2350, validation loss: 0.1793
2024-05-25 06:06:46 [INFO]: Epoch 061 - training loss: 0.2377, validation loss: 0.1772
2024-05-25 06:06:46 [INFO]: Epoch 062 - training loss: 0.2390, validation loss: 0.1784
2024-05-25 06:06:46 [INFO]: Epoch 063 - training loss: 0.2327, validation loss: 0.1785
2024-05-25 06:06:47 [INFO]: Epoch 064 - training loss: 0.2308, validation loss: 0.1771
2024-05-25 06:06:47 [INFO]: Epoch 065 - training loss: 0.2282, validation loss: 0.1777
2024-05-25 06:06:47 [INFO]: Epoch 066 - training loss: 0.2274, validation loss: 0.1763
2024-05-25 06:06:47 [INFO]: Epoch 067 - training loss: 0.2285, validation loss: 0.1756
2024-05-25 06:06:48 [INFO]: Epoch 068 - training loss: 0.2288, validation loss: 0.1810
2024-05-25 06:06:48 [INFO]: Epoch 069 - training loss: 0.2261, validation loss: 0.1761
2024-05-25 06:06:48 [INFO]: Epoch 070 - training loss: 0.2251, validation loss: 0.1762
2024-05-25 06:06:48 [INFO]: Epoch 071 - training loss: 0.2213, validation loss: 0.1763
2024-05-25 06:06:49 [INFO]: Epoch 072 - training loss: 0.2194, validation loss: 0.1753
2024-05-25 06:06:49 [INFO]: Epoch 073 - training loss: 0.2183, validation loss: 0.1732
2024-05-25 06:06:49 [INFO]: Epoch 074 - training loss: 0.2177, validation loss: 0.1757
2024-05-25 06:06:49 [INFO]: Epoch 075 - training loss: 0.2186, validation loss: 0.1746
2024-05-25 06:06:50 [INFO]: Epoch 076 - training loss: 0.2167, validation loss: 0.1748
2024-05-25 06:06:50 [INFO]: Epoch 077 - training loss: 0.2214, validation loss: 0.1745
2024-05-25 06:06:50 [INFO]: Epoch 078 - training loss: 0.2229, validation loss: 0.1731
2024-05-25 06:06:50 [INFO]: Epoch 079 - training loss: 0.2188, validation loss: 0.1750
2024-05-25 06:06:51 [INFO]: Epoch 080 - training loss: 0.2125, validation loss: 0.1752
2024-05-25 06:06:51 [INFO]: Epoch 081 - training loss: 0.2122, validation loss: 0.1728
2024-05-25 06:06:51 [INFO]: Epoch 082 - training loss: 0.2123, validation loss: 0.1716
2024-05-25 06:06:51 [INFO]: Epoch 083 - training loss: 0.2108, validation loss: 0.1730
2024-05-25 06:06:52 [INFO]: Epoch 084 - training loss: 0.2154, validation loss: 0.1732
2024-05-25 06:06:52 [INFO]: Epoch 085 - training loss: 0.2114, validation loss: 0.1736
2024-05-25 06:06:52 [INFO]: Epoch 086 - training loss: 0.2094, validation loss: 0.1718
2024-05-25 06:06:52 [INFO]: Epoch 087 - training loss: 0.2076, validation loss: 0.1720
2024-05-25 06:06:53 [INFO]: Epoch 088 - training loss: 0.2084, validation loss: 0.1731
2024-05-25 06:06:53 [INFO]: Epoch 089 - training loss: 0.2050, validation loss: 0.1711
2024-05-25 06:06:53 [INFO]: Epoch 090 - training loss: 0.2049, validation loss: 0.1735
2024-05-25 06:06:53 [INFO]: Epoch 091 - training loss: 0.2058, validation loss: 0.1737
2024-05-25 06:06:54 [INFO]: Epoch 092 - training loss: 0.2083, validation loss: 0.1744
2024-05-25 06:06:54 [INFO]: Epoch 093 - training loss: 0.2067, validation loss: 0.1704
2024-05-25 06:06:54 [INFO]: Epoch 094 - training loss: 0.2046, validation loss: 0.1705
2024-05-25 06:06:54 [INFO]: Epoch 095 - training loss: 0.2023, validation loss: 0.1710
2024-05-25 06:06:55 [INFO]: Epoch 096 - training loss: 0.2087, validation loss: 0.1726
2024-05-25 06:06:55 [INFO]: Epoch 097 - training loss: 0.2058, validation loss: 0.1710
2024-05-25 06:06:55 [INFO]: Epoch 098 - training loss: 0.2003, validation loss: 0.1708
2024-05-25 06:06:55 [INFO]: Epoch 099 - training loss: 0.1985, validation loss: 0.1721
2024-05-25 06:06:56 [INFO]: Epoch 100 - training loss: 0.2003, validation loss: 0.1718
2024-05-25 06:06:56 [INFO]: Epoch 101 - training loss: 0.1980, validation loss: 0.1699
2024-05-25 06:06:56 [INFO]: Epoch 102 - training loss: 0.1971, validation loss: 0.1720
2024-05-25 06:06:56 [INFO]: Epoch 103 - training loss: 0.2001, validation loss: 0.1689
2024-05-25 06:06:57 [INFO]: Epoch 104 - training loss: 0.2001, validation loss: 0.1706
2024-05-25 06:06:57 [INFO]: Epoch 105 - training loss: 0.2016, validation loss: 0.1695
2024-05-25 06:06:57 [INFO]: Epoch 106 - training loss: 0.1975, validation loss: 0.1701
2024-05-25 06:06:57 [INFO]: Epoch 107 - training loss: 0.1933, validation loss: 0.1700
2024-05-25 06:06:58 [INFO]: Epoch 108 - training loss: 0.1922, validation loss: 0.1683
2024-05-25 06:06:58 [INFO]: Epoch 109 - training loss: 0.1917, validation loss: 0.1688
2024-05-25 06:06:58 [INFO]: Epoch 110 - training loss: 0.1926, validation loss: 0.1701
2024-05-25 06:06:58 [INFO]: Epoch 111 - training loss: 0.1914, validation loss: 0.1688
2024-05-25 06:06:59 [INFO]: Epoch 112 - training loss: 0.1901, validation loss: 0.1675
2024-05-25 06:06:59 [INFO]: Epoch 113 - training loss: 0.1915, validation loss: 0.1714
2024-05-25 06:06:59 [INFO]: Epoch 114 - training loss: 0.1895, validation loss: 0.1692
2024-05-25 06:06:59 [INFO]: Epoch 115 - training loss: 0.1886, validation loss: 0.1686
2024-05-25 06:07:00 [INFO]: Epoch 116 - training loss: 0.1876, validation loss: 0.1680
2024-05-25 06:07:00 [INFO]: Epoch 117 - training loss: 0.1883, validation loss: 0.1698
2024-05-25 06:07:00 [INFO]: Epoch 118 - training loss: 0.1879, validation loss: 0.1705
2024-05-25 06:07:00 [INFO]: Epoch 119 - training loss: 0.1862, validation loss: 0.1677
2024-05-25 06:07:01 [INFO]: Epoch 120 - training loss: 0.1874, validation loss: 0.1676
2024-05-25 06:07:01 [INFO]: Epoch 121 - training loss: 0.1854, validation loss: 0.1725
2024-05-25 06:07:01 [INFO]: Epoch 122 - training loss: 0.1882, validation loss: 0.1702
2024-05-25 06:07:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:07:01 [INFO]: Finished training. The best model is from epoch#112.
2024-05-25 06:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_air_quality/20240525_T060630/Transformer.pypots
2024-05-25 06:07:01 [INFO]: Transformer on Air-Quality: MAE=0.1849, MSE=0.1729
2024-05-25 06:07:01 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_air_quality/imputation.pkl
2024-05-25 06:07:01 [INFO]: Using the given device: cuda:0
2024-05-25 06:07:01 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T060701
2024-05-25 06:07:01 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T060701/tensorboard
2024-05-25 06:07:02 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 06:07:02 [INFO]: Epoch 001 - training loss: 0.2936, validation loss: 0.2824
2024-05-25 06:07:03 [INFO]: Epoch 002 - training loss: 0.2102, validation loss: 0.2637
2024-05-25 06:07:03 [INFO]: Epoch 003 - training loss: 0.1902, validation loss: 0.2366
2024-05-25 06:07:03 [INFO]: Epoch 004 - training loss: 0.1747, validation loss: 0.2220
2024-05-25 06:07:04 [INFO]: Epoch 005 - training loss: 0.1497, validation loss: 0.2113
2024-05-25 06:07:04 [INFO]: Epoch 006 - training loss: 0.1403, validation loss: 0.2141
2024-05-25 06:07:05 [INFO]: Epoch 007 - training loss: 0.1421, validation loss: 0.2102
2024-05-25 06:07:05 [INFO]: Epoch 008 - training loss: 0.1289, validation loss: 0.2055
2024-05-25 06:07:06 [INFO]: Epoch 009 - training loss: 0.1232, validation loss: 0.2061
2024-05-25 06:07:06 [INFO]: Epoch 010 - training loss: 0.1175, validation loss: 0.1999
2024-05-25 06:07:07 [INFO]: Epoch 011 - training loss: 0.1172, validation loss: 0.2146
2024-05-25 06:07:07 [INFO]: Epoch 012 - training loss: 0.1141, validation loss: 0.2044
2024-05-25 06:07:08 [INFO]: Epoch 013 - training loss: 0.1102, validation loss: 0.2147
2024-05-25 06:07:08 [INFO]: Epoch 014 - training loss: 0.1068, validation loss: 0.2108
2024-05-25 06:07:08 [INFO]: Epoch 015 - training loss: 0.1041, validation loss: 0.2131
2024-05-25 06:07:09 [INFO]: Epoch 016 - training loss: 0.1028, validation loss: 0.2134
2024-05-25 06:07:09 [INFO]: Epoch 017 - training loss: 0.0968, validation loss: 0.2217
2024-05-25 06:07:10 [INFO]: Epoch 018 - training loss: 0.0947, validation loss: 0.2034
2024-05-25 06:07:10 [INFO]: Epoch 019 - training loss: 0.0970, validation loss: 0.2128
2024-05-25 06:07:11 [INFO]: Epoch 020 - training loss: 0.0949, validation loss: 0.2091
2024-05-25 06:07:11 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:07:11 [INFO]: Finished training. The best model is from epoch#10.
2024-05-25 06:07:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_air_quality/20240525_T060701/TimesNet.pypots
2024-05-25 06:07:11 [INFO]: TimesNet on Air-Quality: MAE=0.1759, MSE=0.2185
2024-05-25 06:07:11 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_air_quality/imputation.pkl
2024-05-25 06:07:11 [INFO]: Using the given device: cuda:0
2024-05-25 06:07:11 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711
2024-05-25 06:07:11 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/tensorboard
2024-05-25 06:07:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 06:07:28 [INFO]: Epoch 001 - training loss: 0.5153, validation loss: 0.3500
2024-05-25 06:07:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch1_loss0.3500034749507904.pypots
2024-05-25 06:07:44 [INFO]: Epoch 002 - training loss: 0.3135, validation loss: 0.2780
2024-05-25 06:07:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch2_loss0.2779832392930984.pypots
2024-05-25 06:08:01 [INFO]: Epoch 003 - training loss: 0.2667, validation loss: 0.2490
2024-05-25 06:08:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch3_loss0.24896033853292465.pypots
2024-05-25 06:08:18 [INFO]: Epoch 004 - training loss: 0.2341, validation loss: 0.2262
2024-05-25 06:08:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch4_loss0.22616889774799348.pypots
2024-05-25 06:08:34 [INFO]: Epoch 005 - training loss: 0.2102, validation loss: 0.1929
2024-05-25 06:08:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch5_loss0.19288263469934464.pypots
2024-05-25 06:08:51 [INFO]: Epoch 006 - training loss: 0.1824, validation loss: 0.1759
2024-05-25 06:08:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch6_loss0.17592485547065734.pypots
2024-05-25 06:09:08 [INFO]: Epoch 007 - training loss: 0.1817, validation loss: 0.1709
2024-05-25 06:09:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch7_loss0.1708754703402519.pypots
2024-05-25 06:09:24 [INFO]: Epoch 008 - training loss: 0.1774, validation loss: 0.1604
2024-05-25 06:09:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch8_loss0.16043330878019332.pypots
2024-05-25 06:09:41 [INFO]: Epoch 009 - training loss: 0.1538, validation loss: 0.1563
2024-05-25 06:09:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch9_loss0.1563340410590172.pypots
2024-05-25 06:09:58 [INFO]: Epoch 010 - training loss: 0.1618, validation loss: 0.1517
2024-05-25 06:09:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch10_loss0.15169320851564408.pypots
2024-05-25 06:10:15 [INFO]: Epoch 011 - training loss: 0.1589, validation loss: 0.1497
2024-05-25 06:10:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch11_loss0.14968036115169525.pypots
2024-05-25 06:10:31 [INFO]: Epoch 012 - training loss: 0.1557, validation loss: 0.1462
2024-05-25 06:10:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch12_loss0.1461981400847435.pypots
2024-05-25 06:10:48 [INFO]: Epoch 013 - training loss: 0.1413, validation loss: 0.1430
2024-05-25 06:10:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch13_loss0.1430458776652813.pypots
2024-05-25 06:11:05 [INFO]: Epoch 014 - training loss: 0.1501, validation loss: 0.1443
2024-05-25 06:11:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch14_loss0.1442789062857628.pypots
2024-05-25 06:11:21 [INFO]: Epoch 015 - training loss: 0.1389, validation loss: 0.1394
2024-05-25 06:11:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch15_loss0.1394015930593014.pypots
2024-05-25 06:11:38 [INFO]: Epoch 016 - training loss: 0.1575, validation loss: 0.1418
2024-05-25 06:11:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch16_loss0.14183923453092576.pypots
2024-05-25 06:11:55 [INFO]: Epoch 017 - training loss: 0.1497, validation loss: 0.1365
2024-05-25 06:11:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch17_loss0.13650104403495789.pypots
2024-05-25 06:12:11 [INFO]: Epoch 018 - training loss: 0.1450, validation loss: 0.1335
2024-05-25 06:12:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch18_loss0.13346014693379402.pypots
2024-05-25 06:12:28 [INFO]: Epoch 019 - training loss: 0.1367, validation loss: 0.1339
2024-05-25 06:12:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch19_loss0.13388667479157448.pypots
2024-05-25 06:12:45 [INFO]: Epoch 020 - training loss: 0.1389, validation loss: 0.1350
2024-05-25 06:12:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch20_loss0.1349744364619255.pypots
2024-05-25 06:13:01 [INFO]: Epoch 021 - training loss: 0.1298, validation loss: 0.1310
2024-05-25 06:13:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch21_loss0.13097616136074067.pypots
2024-05-25 06:13:18 [INFO]: Epoch 022 - training loss: 0.1422, validation loss: 0.1320
2024-05-25 06:13:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch22_loss0.13202810138463975.pypots
2024-05-25 06:13:35 [INFO]: Epoch 023 - training loss: 0.1510, validation loss: 0.1309
2024-05-25 06:13:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch23_loss0.1309150531888008.pypots
2024-05-25 06:13:51 [INFO]: Epoch 024 - training loss: 0.1349, validation loss: 0.1306
2024-05-25 06:13:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch24_loss0.1306346498429775.pypots
2024-05-25 06:14:08 [INFO]: Epoch 025 - training loss: 0.1321, validation loss: 0.1377
2024-05-25 06:14:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch25_loss0.13773089721798898.pypots
2024-05-25 06:14:25 [INFO]: Epoch 026 - training loss: 0.1441, validation loss: 0.1287
2024-05-25 06:14:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch26_loss0.12870064973831177.pypots
2024-05-25 06:14:41 [INFO]: Epoch 027 - training loss: 0.1332, validation loss: 0.1258
2024-05-25 06:14:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch27_loss0.1258046269416809.pypots
2024-05-25 06:14:58 [INFO]: Epoch 028 - training loss: 0.1319, validation loss: 0.1269
2024-05-25 06:14:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch28_loss0.12694628089666365.pypots
2024-05-25 06:15:15 [INFO]: Epoch 029 - training loss: 0.1187, validation loss: 0.1252
2024-05-25 06:15:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch29_loss0.1252150982618332.pypots
2024-05-25 06:15:31 [INFO]: Epoch 030 - training loss: 0.1162, validation loss: 0.1263
2024-05-25 06:15:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch30_loss0.12627825364470482.pypots
2024-05-25 06:15:48 [INFO]: Epoch 031 - training loss: 0.1148, validation loss: 0.1261
2024-05-25 06:15:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch31_loss0.12610290497541427.pypots
2024-05-25 06:16:05 [INFO]: Epoch 032 - training loss: 0.1232, validation loss: 0.1235
2024-05-25 06:16:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch32_loss0.12353889420628547.pypots
2024-05-25 06:16:21 [INFO]: Epoch 033 - training loss: 0.1195, validation loss: 0.1264
2024-05-25 06:16:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch33_loss0.1263780638575554.pypots
2024-05-25 06:16:38 [INFO]: Epoch 034 - training loss: 0.1278, validation loss: 0.1242
2024-05-25 06:16:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch34_loss0.12422621995210648.pypots
2024-05-25 06:16:55 [INFO]: Epoch 035 - training loss: 0.1074, validation loss: 0.1203
2024-05-25 06:16:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch35_loss0.12025160416960716.pypots
2024-05-25 06:17:11 [INFO]: Epoch 036 - training loss: 0.1179, validation loss: 0.1238
2024-05-25 06:17:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch36_loss0.1238006241619587.pypots
2024-05-25 06:17:28 [INFO]: Epoch 037 - training loss: 0.1219, validation loss: 0.1244
2024-05-25 06:17:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch37_loss0.12442195191979408.pypots
2024-05-25 06:17:45 [INFO]: Epoch 038 - training loss: 0.1170, validation loss: 0.1226
2024-05-25 06:17:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch38_loss0.12258583158254624.pypots
2024-05-25 06:18:02 [INFO]: Epoch 039 - training loss: 0.1184, validation loss: 0.1194
2024-05-25 06:18:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch39_loss0.11937263682484626.pypots
2024-05-25 06:18:18 [INFO]: Epoch 040 - training loss: 0.1267, validation loss: 0.1207
2024-05-25 06:18:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch40_loss0.12068840712308884.pypots
2024-05-25 06:18:35 [INFO]: Epoch 041 - training loss: 0.1190, validation loss: 0.1279
2024-05-25 06:18:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch41_loss0.1278758242726326.pypots
2024-05-25 06:18:52 [INFO]: Epoch 042 - training loss: 0.1349, validation loss: 0.1306
2024-05-25 06:18:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch42_loss0.13058025911450385.pypots
2024-05-25 06:19:08 [INFO]: Epoch 043 - training loss: 0.1305, validation loss: 0.1181
2024-05-25 06:19:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch43_loss0.11809323355555534.pypots
2024-05-25 06:19:25 [INFO]: Epoch 044 - training loss: 0.1114, validation loss: 0.1155
2024-05-25 06:19:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch44_loss0.11548279002308845.pypots
2024-05-25 06:19:42 [INFO]: Epoch 045 - training loss: 0.1242, validation loss: 0.1144
2024-05-25 06:19:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch45_loss0.11438107267022132.pypots
2024-05-25 06:19:58 [INFO]: Epoch 046 - training loss: 0.1131, validation loss: 0.1144
2024-05-25 06:19:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch46_loss0.11442857906222344.pypots
2024-05-25 06:20:15 [INFO]: Epoch 047 - training loss: 0.0985, validation loss: 0.1168
2024-05-25 06:20:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch47_loss0.11680348590016365.pypots
2024-05-25 06:20:32 [INFO]: Epoch 048 - training loss: 0.1084, validation loss: 0.1139
2024-05-25 06:20:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch48_loss0.11385810747742653.pypots
2024-05-25 06:20:48 [INFO]: Epoch 049 - training loss: 0.1081, validation loss: 0.1164
2024-05-25 06:20:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch49_loss0.11636902540922164.pypots
2024-05-25 06:21:05 [INFO]: Epoch 050 - training loss: 0.1050, validation loss: 0.1131
2024-05-25 06:21:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch50_loss0.11309827044606209.pypots
2024-05-25 06:21:22 [INFO]: Epoch 051 - training loss: 0.1204, validation loss: 0.1161
2024-05-25 06:21:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch51_loss0.1161147452890873.pypots
2024-05-25 06:21:38 [INFO]: Epoch 052 - training loss: 0.1175, validation loss: 0.1173
2024-05-25 06:21:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch52_loss0.11730313077569007.pypots
2024-05-25 06:21:55 [INFO]: Epoch 053 - training loss: 0.1111, validation loss: 0.1129
2024-05-25 06:21:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch53_loss0.11294922158122063.pypots
2024-05-25 06:22:12 [INFO]: Epoch 054 - training loss: 0.1160, validation loss: 0.1107
2024-05-25 06:22:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch54_loss0.11073916703462601.pypots
2024-05-25 06:22:29 [INFO]: Epoch 055 - training loss: 0.1230, validation loss: 0.1126
2024-05-25 06:22:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch55_loss0.112577885389328.pypots
2024-05-25 06:22:45 [INFO]: Epoch 056 - training loss: 0.1028, validation loss: 0.1183
2024-05-25 06:22:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch56_loss0.11832799315452576.pypots
2024-05-25 06:23:02 [INFO]: Epoch 057 - training loss: 0.0988, validation loss: 0.1102
2024-05-25 06:23:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch57_loss0.110230652987957.pypots
2024-05-25 06:23:19 [INFO]: Epoch 058 - training loss: 0.0986, validation loss: 0.1118
2024-05-25 06:23:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch58_loss0.11184811666607856.pypots
2024-05-25 06:23:35 [INFO]: Epoch 059 - training loss: 0.1124, validation loss: 0.1111
2024-05-25 06:23:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch59_loss0.11107433587312698.pypots
2024-05-25 06:23:52 [INFO]: Epoch 060 - training loss: 0.1087, validation loss: 0.1087
2024-05-25 06:23:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch60_loss0.10868229418992996.pypots
2024-05-25 06:24:09 [INFO]: Epoch 061 - training loss: 0.1054, validation loss: 0.1112
2024-05-25 06:24:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch61_loss0.11123223230242729.pypots
2024-05-25 06:24:25 [INFO]: Epoch 062 - training loss: 0.1009, validation loss: 0.1094
2024-05-25 06:24:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch62_loss0.10937496945261956.pypots
2024-05-25 06:24:42 [INFO]: Epoch 063 - training loss: 0.1184, validation loss: 0.1094
2024-05-25 06:24:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch63_loss0.1093622624874115.pypots
2024-05-25 06:24:59 [INFO]: Epoch 064 - training loss: 0.1127, validation loss: 0.1075
2024-05-25 06:24:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch64_loss0.10753642320632935.pypots
2024-05-25 06:25:15 [INFO]: Epoch 065 - training loss: 0.1103, validation loss: 0.1103
2024-05-25 06:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch65_loss0.11034377217292786.pypots
2024-05-25 06:25:32 [INFO]: Epoch 066 - training loss: 0.1004, validation loss: 0.1105
2024-05-25 06:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch66_loss0.11050669178366661.pypots
2024-05-25 06:25:49 [INFO]: Epoch 067 - training loss: 0.1015, validation loss: 0.1108
2024-05-25 06:25:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch67_loss0.11082197874784469.pypots
2024-05-25 06:26:05 [INFO]: Epoch 068 - training loss: 0.1039, validation loss: 0.1067
2024-05-25 06:26:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch68_loss0.10665521398186684.pypots
2024-05-25 06:26:22 [INFO]: Epoch 069 - training loss: 0.1082, validation loss: 0.1062
2024-05-25 06:26:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch69_loss0.1061747945845127.pypots
2024-05-25 06:26:39 [INFO]: Epoch 070 - training loss: 0.1061, validation loss: 0.1071
2024-05-25 06:26:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch70_loss0.10711212158203125.pypots
2024-05-25 06:26:55 [INFO]: Epoch 071 - training loss: 0.1084, validation loss: 0.1111
2024-05-25 06:26:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch71_loss0.1110802374780178.pypots
2024-05-25 06:27:12 [INFO]: Epoch 072 - training loss: 0.1087, validation loss: 0.1081
2024-05-25 06:27:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch72_loss0.10806068554520606.pypots
2024-05-25 06:27:29 [INFO]: Epoch 073 - training loss: 0.1176, validation loss: 0.1102
2024-05-25 06:27:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch73_loss0.11022337898612022.pypots
2024-05-25 06:27:45 [INFO]: Epoch 074 - training loss: 0.1076, validation loss: 0.1094
2024-05-25 06:27:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch74_loss0.10940521880984307.pypots
2024-05-25 06:28:02 [INFO]: Epoch 075 - training loss: 0.1035, validation loss: 0.1109
2024-05-25 06:28:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch75_loss0.11094490587711334.pypots
2024-05-25 06:28:19 [INFO]: Epoch 076 - training loss: 0.0977, validation loss: 0.1095
2024-05-25 06:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch76_loss0.10953762382268906.pypots
2024-05-25 06:28:35 [INFO]: Epoch 077 - training loss: 0.0985, validation loss: 0.1043
2024-05-25 06:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch77_loss0.10430753976106644.pypots
2024-05-25 06:28:52 [INFO]: Epoch 078 - training loss: 0.1074, validation loss: 0.1044
2024-05-25 06:28:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch78_loss0.10440070480108261.pypots
2024-05-25 06:29:09 [INFO]: Epoch 079 - training loss: 0.1100, validation loss: 0.1071
2024-05-25 06:29:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch79_loss0.10714994817972183.pypots
2024-05-25 06:29:26 [INFO]: Epoch 080 - training loss: 0.1034, validation loss: 0.1071
2024-05-25 06:29:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch80_loss0.10707235038280487.pypots
2024-05-25 06:29:42 [INFO]: Epoch 081 - training loss: 0.1215, validation loss: 0.1066
2024-05-25 06:29:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch81_loss0.10656444728374481.pypots
2024-05-25 06:29:59 [INFO]: Epoch 082 - training loss: 0.0940, validation loss: 0.1069
2024-05-25 06:29:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch82_loss0.10690452381968499.pypots
2024-05-25 06:30:16 [INFO]: Epoch 083 - training loss: 0.1115, validation loss: 0.1074
2024-05-25 06:30:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch83_loss0.1073724240064621.pypots
2024-05-25 06:30:32 [INFO]: Epoch 084 - training loss: 0.1136, validation loss: 0.1058
2024-05-25 06:30:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch84_loss0.10580811873078347.pypots
2024-05-25 06:30:49 [INFO]: Epoch 085 - training loss: 0.0971, validation loss: 0.1083
2024-05-25 06:30:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch85_loss0.10825567096471786.pypots
2024-05-25 06:31:06 [INFO]: Epoch 086 - training loss: 0.1156, validation loss: 0.1089
2024-05-25 06:31:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch86_loss0.10889490395784378.pypots
2024-05-25 06:31:22 [INFO]: Epoch 087 - training loss: 0.1089, validation loss: 0.1066
2024-05-25 06:31:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI_epoch87_loss0.10659851133823395.pypots
2024-05-25 06:31:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:31:22 [INFO]: Finished training. The best model is from epoch#77.
2024-05-25 06:31:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_air_quality/20240525_T060711/CSDI.pypots
2024-05-25 06:33:43 [INFO]: CSDI on Air-Quality: MAE=0.1089, MSE=0.1644
2024-05-25 06:33:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_air_quality/imputation.pkl
2024-05-25 06:33:43 [INFO]: Using the given device: cuda:0
2024-05-25 06:33:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T063343
2024-05-25 06:33:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T063343/tensorboard
2024-05-25 06:33:43 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 06:33:43 [INFO]: Epoch 001 - training loss: 64818.8477, validation loss: 0.6809
2024-05-25 06:33:44 [INFO]: Epoch 002 - training loss: 41586.0346, validation loss: 0.6013
2024-05-25 06:33:44 [INFO]: Epoch 003 - training loss: 41203.4148, validation loss: 0.5432
2024-05-25 06:33:44 [INFO]: Epoch 004 - training loss: 41097.9447, validation loss: 0.5511
2024-05-25 06:33:45 [INFO]: Epoch 005 - training loss: 41011.3352, validation loss: 0.4818
2024-05-25 06:33:45 [INFO]: Epoch 006 - training loss: 40914.4329, validation loss: 0.4583
2024-05-25 06:33:45 [INFO]: Epoch 007 - training loss: 40878.0913, validation loss: 0.4355
2024-05-25 06:33:46 [INFO]: Epoch 008 - training loss: 40827.6487, validation loss: 0.3952
2024-05-25 06:33:46 [INFO]: Epoch 009 - training loss: 40821.5650, validation loss: 0.3968
2024-05-25 06:33:46 [INFO]: Epoch 010 - training loss: 40786.6808, validation loss: 0.3557
2024-05-25 06:33:47 [INFO]: Epoch 011 - training loss: 40774.3832, validation loss: 0.3881
2024-05-25 06:33:47 [INFO]: Epoch 012 - training loss: 40740.4518, validation loss: 0.3475
2024-05-25 06:33:47 [INFO]: Epoch 013 - training loss: 40729.0463, validation loss: 0.3278
2024-05-25 06:33:48 [INFO]: Epoch 014 - training loss: 40706.6913, validation loss: 0.3327
2024-05-25 06:33:48 [INFO]: Epoch 015 - training loss: 40710.3002, validation loss: 0.3205
2024-05-25 06:33:48 [INFO]: Epoch 016 - training loss: 40690.2512, validation loss: 0.3365
2024-05-25 06:33:49 [INFO]: Epoch 017 - training loss: 40691.2532, validation loss: 0.3249
2024-05-25 06:33:49 [INFO]: Epoch 018 - training loss: 40666.6027, validation loss: 0.3041
2024-05-25 06:33:49 [INFO]: Epoch 019 - training loss: 40654.0230, validation loss: 0.2964
2024-05-25 06:33:50 [INFO]: Epoch 020 - training loss: 40645.2227, validation loss: 0.2978
2024-05-25 06:33:50 [INFO]: Epoch 021 - training loss: 40650.6798, validation loss: 0.3037
2024-05-25 06:33:50 [INFO]: Epoch 022 - training loss: 40653.0697, validation loss: 0.2973
2024-05-25 06:33:51 [INFO]: Epoch 023 - training loss: 40629.8014, validation loss: 0.2994
2024-05-25 06:33:51 [INFO]: Epoch 024 - training loss: 40631.8821, validation loss: 0.3077
2024-05-25 06:33:51 [INFO]: Epoch 025 - training loss: 40626.5294, validation loss: 0.2956
2024-05-25 06:33:52 [INFO]: Epoch 026 - training loss: 40625.0288, validation loss: 0.2995
2024-05-25 06:33:52 [INFO]: Epoch 027 - training loss: 40677.6659, validation loss: 0.2924
2024-05-25 06:33:52 [INFO]: Epoch 028 - training loss: 40621.3383, validation loss: 0.2878
2024-05-25 06:33:53 [INFO]: Epoch 029 - training loss: 40639.5638, validation loss: 0.3027
2024-05-25 06:33:53 [INFO]: Epoch 030 - training loss: 40621.6739, validation loss: 0.2775
2024-05-25 06:33:53 [INFO]: Epoch 031 - training loss: 40605.2441, validation loss: 0.2725
2024-05-25 06:33:54 [INFO]: Epoch 032 - training loss: 40601.9220, validation loss: 0.2733
2024-05-25 06:33:54 [INFO]: Epoch 033 - training loss: 40591.1076, validation loss: 0.2629
2024-05-25 06:33:54 [INFO]: Epoch 034 - training loss: 40601.9498, validation loss: 0.3239
2024-05-25 06:33:55 [INFO]: Epoch 035 - training loss: 40594.6963, validation loss: 0.2672
2024-05-25 06:33:55 [INFO]: Epoch 036 - training loss: 40585.3397, validation loss: 0.2698
2024-05-25 06:33:55 [INFO]: Epoch 037 - training loss: 40581.9214, validation loss: 0.2582
2024-05-25 06:33:56 [INFO]: Epoch 038 - training loss: 40593.4065, validation loss: 0.2829
2024-05-25 06:33:56 [INFO]: Epoch 039 - training loss: 40588.1756, validation loss: 0.2579
2024-05-25 06:33:56 [INFO]: Epoch 040 - training loss: 40590.8736, validation loss: 0.2848
2024-05-25 06:33:57 [INFO]: Epoch 041 - training loss: 40592.6195, validation loss: 0.2639
2024-05-25 06:33:57 [INFO]: Epoch 042 - training loss: 40592.2859, validation loss: 0.2594
2024-05-25 06:33:57 [INFO]: Epoch 043 - training loss: 40583.2909, validation loss: 0.2610
2024-05-25 06:33:58 [INFO]: Epoch 044 - training loss: 40568.5026, validation loss: 0.2635
2024-05-25 06:33:58 [INFO]: Epoch 045 - training loss: 40565.2740, validation loss: 0.2550
2024-05-25 06:33:58 [INFO]: Epoch 046 - training loss: 40558.7811, validation loss: 0.2571
2024-05-25 06:33:59 [INFO]: Epoch 047 - training loss: 40555.9502, validation loss: 0.2532
2024-05-25 06:33:59 [INFO]: Epoch 048 - training loss: 40558.9780, validation loss: 0.2550
2024-05-25 06:33:59 [INFO]: Epoch 049 - training loss: 40561.9003, validation loss: 0.2505
2024-05-25 06:34:00 [INFO]: Epoch 050 - training loss: 40573.7650, validation loss: 0.2566
2024-05-25 06:34:00 [INFO]: Epoch 051 - training loss: 40634.8644, validation loss: 0.2856
2024-05-25 06:34:00 [INFO]: Epoch 052 - training loss: 40619.4683, validation loss: 0.2689
2024-05-25 06:34:01 [INFO]: Epoch 053 - training loss: 40591.5486, validation loss: 0.2730
2024-05-25 06:34:01 [INFO]: Epoch 054 - training loss: 40578.9637, validation loss: 0.2540
2024-05-25 06:34:01 [INFO]: Epoch 055 - training loss: 40561.6435, validation loss: 0.2566
2024-05-25 06:34:02 [INFO]: Epoch 056 - training loss: 40565.8657, validation loss: 0.2539
2024-05-25 06:34:02 [INFO]: Epoch 057 - training loss: 40562.5380, validation loss: 0.2550
2024-05-25 06:34:02 [INFO]: Epoch 058 - training loss: 40557.1209, validation loss: 0.2537
2024-05-25 06:34:03 [INFO]: Epoch 059 - training loss: 40559.5171, validation loss: 0.2519
2024-05-25 06:34:03 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:34:03 [INFO]: Finished training. The best model is from epoch#49.
2024-05-25 06:34:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_air_quality/20240525_T063343/GPVAE.pypots
2024-05-25 06:34:03 [INFO]: GP-VAE on Air-Quality: MAE=0.2819, MSE=0.2657
2024-05-25 06:34:03 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_air_quality/imputation.pkl
2024-05-25 06:34:03 [INFO]: Using the given device: cuda:0
2024-05-25 06:34:03 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T063403
2024-05-25 06:34:03 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T063403/tensorboard
2024-05-25 06:34:03 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 06:34:08 [INFO]: Epoch 001 - generator training loss: 0.3550, discriminator training loss: 0.5686, validation loss: 0.5516
2024-05-25 06:34:12 [INFO]: Epoch 002 - generator training loss: 0.0386, discriminator training loss: 0.5239, validation loss: 0.4171
2024-05-25 06:34:16 [INFO]: Epoch 003 - generator training loss: -0.0323, discriminator training loss: 0.5186, validation loss: 0.3514
2024-05-25 06:34:20 [INFO]: Epoch 004 - generator training loss: -0.0698, discriminator training loss: 0.5144, validation loss: 0.3077
2024-05-25 06:34:24 [INFO]: Epoch 005 - generator training loss: -0.0957, discriminator training loss: 0.5098, validation loss: 0.2792
2024-05-25 06:34:28 [INFO]: Epoch 006 - generator training loss: -0.1091, discriminator training loss: 0.5042, validation loss: 0.2596
2024-05-25 06:34:32 [INFO]: Epoch 007 - generator training loss: -0.1171, discriminator training loss: 0.4978, validation loss: 0.2440
2024-05-25 06:34:37 [INFO]: Epoch 008 - generator training loss: -0.1243, discriminator training loss: 0.4900, validation loss: 0.2326
2024-05-25 06:34:41 [INFO]: Epoch 009 - generator training loss: -0.1278, discriminator training loss: 0.4815, validation loss: 0.2232
2024-05-25 06:34:45 [INFO]: Epoch 010 - generator training loss: -0.1291, discriminator training loss: 0.4720, validation loss: 0.2153
2024-05-25 06:34:49 [INFO]: Epoch 011 - generator training loss: -0.1287, discriminator training loss: 0.4622, validation loss: 0.2088
2024-05-25 06:34:53 [INFO]: Epoch 012 - generator training loss: -0.1272, discriminator training loss: 0.4515, validation loss: 0.2036
2024-05-25 06:34:57 [INFO]: Epoch 013 - generator training loss: -0.1241, discriminator training loss: 0.4409, validation loss: 0.1988
2024-05-25 06:35:01 [INFO]: Epoch 014 - generator training loss: -0.1209, discriminator training loss: 0.4306, validation loss: 0.1945
2024-05-25 06:35:05 [INFO]: Epoch 015 - generator training loss: -0.1176, discriminator training loss: 0.4205, validation loss: 0.1904
2024-05-25 06:35:10 [INFO]: Epoch 016 - generator training loss: -0.1144, discriminator training loss: 0.4105, validation loss: 0.1869
2024-05-25 06:35:14 [INFO]: Epoch 017 - generator training loss: -0.1119, discriminator training loss: 0.4016, validation loss: 0.1828
2024-05-25 06:35:18 [INFO]: Epoch 018 - generator training loss: -0.1092, discriminator training loss: 0.3932, validation loss: 0.1804
2024-05-25 06:35:22 [INFO]: Epoch 019 - generator training loss: -0.1058, discriminator training loss: 0.3851, validation loss: 0.1773
2024-05-25 06:35:26 [INFO]: Epoch 020 - generator training loss: -0.1050, discriminator training loss: 0.3783, validation loss: 0.1743
2024-05-25 06:35:30 [INFO]: Epoch 021 - generator training loss: -0.1035, discriminator training loss: 0.3716, validation loss: 0.1719
2024-05-25 06:35:34 [INFO]: Epoch 022 - generator training loss: -0.1012, discriminator training loss: 0.3658, validation loss: 0.1700
2024-05-25 06:35:38 [INFO]: Epoch 023 - generator training loss: -0.1001, discriminator training loss: 0.3600, validation loss: 0.1674
2024-05-25 06:35:42 [INFO]: Epoch 024 - generator training loss: -0.0998, discriminator training loss: 0.3555, validation loss: 0.1657
2024-05-25 06:35:46 [INFO]: Epoch 025 - generator training loss: -0.0986, discriminator training loss: 0.3509, validation loss: 0.1635
2024-05-25 06:35:51 [INFO]: Epoch 026 - generator training loss: -0.0975, discriminator training loss: 0.3472, validation loss: 0.1620
2024-05-25 06:35:55 [INFO]: Epoch 027 - generator training loss: -0.0966, discriminator training loss: 0.3433, validation loss: 0.1605
2024-05-25 06:35:59 [INFO]: Epoch 028 - generator training loss: -0.0958, discriminator training loss: 0.3400, validation loss: 0.1587
2024-05-25 06:36:03 [INFO]: Epoch 029 - generator training loss: -0.0953, discriminator training loss: 0.3373, validation loss: 0.1568
2024-05-25 06:36:07 [INFO]: Epoch 030 - generator training loss: -0.0961, discriminator training loss: 0.3343, validation loss: 0.1557
2024-05-25 06:36:11 [INFO]: Epoch 031 - generator training loss: -0.0958, discriminator training loss: 0.3320, validation loss: 0.1545
2024-05-25 06:36:15 [INFO]: Epoch 032 - generator training loss: -0.0951, discriminator training loss: 0.3301, validation loss: 0.1534
2024-05-25 06:36:19 [INFO]: Epoch 033 - generator training loss: -0.0958, discriminator training loss: 0.3278, validation loss: 0.1518
2024-05-25 06:36:24 [INFO]: Epoch 034 - generator training loss: -0.0945, discriminator training loss: 0.3261, validation loss: 0.1503
2024-05-25 06:36:28 [INFO]: Epoch 035 - generator training loss: -0.0957, discriminator training loss: 0.3240, validation loss: 0.1493
2024-05-25 06:36:32 [INFO]: Epoch 036 - generator training loss: -0.0939, discriminator training loss: 0.3224, validation loss: 0.1485
2024-05-25 06:36:36 [INFO]: Epoch 037 - generator training loss: -0.0963, discriminator training loss: 0.3215, validation loss: 0.1470
2024-05-25 06:36:40 [INFO]: Epoch 038 - generator training loss: -0.0958, discriminator training loss: 0.3204, validation loss: 0.1460
2024-05-25 06:36:44 [INFO]: Epoch 039 - generator training loss: -0.0967, discriminator training loss: 0.3189, validation loss: 0.1455
2024-05-25 06:36:48 [INFO]: Epoch 040 - generator training loss: -0.0969, discriminator training loss: 0.3180, validation loss: 0.1438
2024-05-25 06:36:52 [INFO]: Epoch 041 - generator training loss: -0.0955, discriminator training loss: 0.3167, validation loss: 0.1434
2024-05-25 06:36:56 [INFO]: Epoch 042 - generator training loss: -0.0980, discriminator training loss: 0.3160, validation loss: 0.1422
2024-05-25 06:37:00 [INFO]: Epoch 043 - generator training loss: -0.0984, discriminator training loss: 0.3154, validation loss: 0.1418
2024-05-25 06:37:05 [INFO]: Epoch 044 - generator training loss: -0.0991, discriminator training loss: 0.3145, validation loss: 0.1411
2024-05-25 06:37:09 [INFO]: Epoch 045 - generator training loss: -0.0991, discriminator training loss: 0.3138, validation loss: 0.1401
2024-05-25 06:37:13 [INFO]: Epoch 046 - generator training loss: -0.0997, discriminator training loss: 0.3130, validation loss: 0.1397
2024-05-25 06:37:17 [INFO]: Epoch 047 - generator training loss: -0.0996, discriminator training loss: 0.3127, validation loss: 0.1383
2024-05-25 06:37:21 [INFO]: Epoch 048 - generator training loss: -0.0997, discriminator training loss: 0.3122, validation loss: 0.1379
2024-05-25 06:37:25 [INFO]: Epoch 049 - generator training loss: -0.0999, discriminator training loss: 0.3113, validation loss: 0.1368
2024-05-25 06:37:29 [INFO]: Epoch 050 - generator training loss: -0.1019, discriminator training loss: 0.3111, validation loss: 0.1365
2024-05-25 06:37:33 [INFO]: Epoch 051 - generator training loss: -0.1012, discriminator training loss: 0.3108, validation loss: 0.1363
2024-05-25 06:37:38 [INFO]: Epoch 052 - generator training loss: -0.1025, discriminator training loss: 0.3100, validation loss: 0.1350
2024-05-25 06:37:42 [INFO]: Epoch 053 - generator training loss: -0.1034, discriminator training loss: 0.3100, validation loss: 0.1347
2024-05-25 06:37:46 [INFO]: Epoch 054 - generator training loss: -0.1038, discriminator training loss: 0.3092, validation loss: 0.1348
2024-05-25 06:37:50 [INFO]: Epoch 055 - generator training loss: -0.1031, discriminator training loss: 0.3092, validation loss: 0.1338
2024-05-25 06:37:54 [INFO]: Epoch 056 - generator training loss: -0.1033, discriminator training loss: 0.3090, validation loss: 0.1333
2024-05-25 06:37:58 [INFO]: Epoch 057 - generator training loss: -0.1046, discriminator training loss: 0.3086, validation loss: 0.1327
2024-05-25 06:38:02 [INFO]: Epoch 058 - generator training loss: -0.1043, discriminator training loss: 0.3078, validation loss: 0.1321
2024-05-25 06:38:06 [INFO]: Epoch 059 - generator training loss: -0.1046, discriminator training loss: 0.3079, validation loss: 0.1313
2024-05-25 06:38:10 [INFO]: Epoch 060 - generator training loss: -0.1051, discriminator training loss: 0.3077, validation loss: 0.1318
2024-05-25 06:38:15 [INFO]: Epoch 061 - generator training loss: -0.1062, discriminator training loss: 0.3076, validation loss: 0.1310
2024-05-25 06:38:19 [INFO]: Epoch 062 - generator training loss: -0.1066, discriminator training loss: 0.3072, validation loss: 0.1302
2024-05-25 06:38:23 [INFO]: Epoch 063 - generator training loss: -0.1072, discriminator training loss: 0.3072, validation loss: 0.1303
2024-05-25 06:38:27 [INFO]: Epoch 064 - generator training loss: -0.1071, discriminator training loss: 0.3064, validation loss: 0.1299
2024-05-25 06:38:31 [INFO]: Epoch 065 - generator training loss: -0.1082, discriminator training loss: 0.3064, validation loss: 0.1292
2024-05-25 06:38:35 [INFO]: Epoch 066 - generator training loss: -0.1083, discriminator training loss: 0.3065, validation loss: 0.1293
2024-05-25 06:38:39 [INFO]: Epoch 067 - generator training loss: -0.1084, discriminator training loss: 0.3058, validation loss: 0.1287
2024-05-25 06:38:43 [INFO]: Epoch 068 - generator training loss: -0.1083, discriminator training loss: 0.3056, validation loss: 0.1285
2024-05-25 06:38:47 [INFO]: Epoch 069 - generator training loss: -0.1086, discriminator training loss: 0.3052, validation loss: 0.1280
2024-05-25 06:38:52 [INFO]: Epoch 070 - generator training loss: -0.1104, discriminator training loss: 0.3048, validation loss: 0.1278
2024-05-25 06:38:56 [INFO]: Epoch 071 - generator training loss: -0.1109, discriminator training loss: 0.3051, validation loss: 0.1282
2024-05-25 06:39:00 [INFO]: Epoch 072 - generator training loss: -0.1111, discriminator training loss: 0.3050, validation loss: 0.1271
2024-05-25 06:39:04 [INFO]: Epoch 073 - generator training loss: -0.1117, discriminator training loss: 0.3054, validation loss: 0.1274
2024-05-25 06:39:08 [INFO]: Epoch 074 - generator training loss: -0.1120, discriminator training loss: 0.3050, validation loss: 0.1272
2024-05-25 06:39:12 [INFO]: Epoch 075 - generator training loss: -0.1112, discriminator training loss: 0.3043, validation loss: 0.1271
2024-05-25 06:39:16 [INFO]: Epoch 076 - generator training loss: -0.1115, discriminator training loss: 0.3044, validation loss: 0.1261
2024-05-25 06:39:20 [INFO]: Epoch 077 - generator training loss: -0.1112, discriminator training loss: 0.3038, validation loss: 0.1269
2024-05-25 06:39:25 [INFO]: Epoch 078 - generator training loss: -0.1122, discriminator training loss: 0.3042, validation loss: 0.1264
2024-05-25 06:39:29 [INFO]: Epoch 079 - generator training loss: -0.1127, discriminator training loss: 0.3039, validation loss: 0.1245
2024-05-25 06:39:33 [INFO]: Epoch 080 - generator training loss: -0.1129, discriminator training loss: 0.3038, validation loss: 0.1255
2024-05-25 06:39:37 [INFO]: Epoch 081 - generator training loss: -0.1129, discriminator training loss: 0.3029, validation loss: 0.1257
2024-05-25 06:39:41 [INFO]: Epoch 082 - generator training loss: -0.1128, discriminator training loss: 0.3029, validation loss: 0.1248
2024-05-25 06:39:45 [INFO]: Epoch 083 - generator training loss: -0.1145, discriminator training loss: 0.3041, validation loss: 0.1259
2024-05-25 06:39:49 [INFO]: Epoch 084 - generator training loss: -0.1127, discriminator training loss: 0.3034, validation loss: 0.1247
2024-05-25 06:39:53 [INFO]: Epoch 085 - generator training loss: -0.1148, discriminator training loss: 0.3030, validation loss: 0.1250
2024-05-25 06:39:57 [INFO]: Epoch 086 - generator training loss: -0.1150, discriminator training loss: 0.3034, validation loss: 0.1245
2024-05-25 06:40:02 [INFO]: Epoch 087 - generator training loss: -0.1142, discriminator training loss: 0.3024, validation loss: 0.1250
2024-05-25 06:40:06 [INFO]: Epoch 088 - generator training loss: -0.1149, discriminator training loss: 0.3020, validation loss: 0.1245
2024-05-25 06:40:10 [INFO]: Epoch 089 - generator training loss: -0.1154, discriminator training loss: 0.3025, validation loss: 0.1248
2024-05-25 06:40:14 [INFO]: Epoch 090 - generator training loss: -0.1152, discriminator training loss: 0.3023, validation loss: 0.1244
2024-05-25 06:40:18 [INFO]: Epoch 091 - generator training loss: -0.1163, discriminator training loss: 0.3024, validation loss: 0.1245
2024-05-25 06:40:22 [INFO]: Epoch 092 - generator training loss: -0.1159, discriminator training loss: 0.3019, validation loss: 0.1246
2024-05-25 06:40:26 [INFO]: Epoch 093 - generator training loss: -0.1159, discriminator training loss: 0.3018, validation loss: 0.1245
2024-05-25 06:40:30 [INFO]: Epoch 094 - generator training loss: -0.1171, discriminator training loss: 0.3017, validation loss: 0.1247
2024-05-25 06:40:34 [INFO]: Epoch 095 - generator training loss: -0.1167, discriminator training loss: 0.3016, validation loss: 0.1231
2024-05-25 06:40:38 [INFO]: Epoch 096 - generator training loss: -0.1179, discriminator training loss: 0.3010, validation loss: 0.1237
2024-05-25 06:40:43 [INFO]: Epoch 097 - generator training loss: -0.1165, discriminator training loss: 0.3018, validation loss: 0.1239
2024-05-25 06:40:47 [INFO]: Epoch 098 - generator training loss: -0.1166, discriminator training loss: 0.3009, validation loss: 0.1233
2024-05-25 06:40:51 [INFO]: Epoch 099 - generator training loss: -0.1183, discriminator training loss: 0.3011, validation loss: 0.1229
2024-05-25 06:40:55 [INFO]: Epoch 100 - generator training loss: -0.1179, discriminator training loss: 0.3009, validation loss: 0.1223
2024-05-25 06:40:59 [INFO]: Epoch 101 - generator training loss: -0.1182, discriminator training loss: 0.3010, validation loss: 0.1236
2024-05-25 06:41:03 [INFO]: Epoch 102 - generator training loss: -0.1190, discriminator training loss: 0.3010, validation loss: 0.1237
2024-05-25 06:41:07 [INFO]: Epoch 103 - generator training loss: -0.1178, discriminator training loss: 0.3012, validation loss: 0.1226
2024-05-25 06:41:11 [INFO]: Epoch 104 - generator training loss: -0.1185, discriminator training loss: 0.3006, validation loss: 0.1232
2024-05-25 06:41:16 [INFO]: Epoch 105 - generator training loss: -0.1195, discriminator training loss: 0.3003, validation loss: 0.1230
2024-05-25 06:41:20 [INFO]: Epoch 106 - generator training loss: -0.1196, discriminator training loss: 0.3006, validation loss: 0.1217
2024-05-25 06:41:24 [INFO]: Epoch 107 - generator training loss: -0.1192, discriminator training loss: 0.3004, validation loss: 0.1236
2024-05-25 06:41:28 [INFO]: Epoch 108 - generator training loss: -0.1197, discriminator training loss: 0.3005, validation loss: 0.1229
2024-05-25 06:41:32 [INFO]: Epoch 109 - generator training loss: -0.1195, discriminator training loss: 0.3007, validation loss: 0.1231
2024-05-25 06:41:36 [INFO]: Epoch 110 - generator training loss: -0.1200, discriminator training loss: 0.3001, validation loss: 0.1223
2024-05-25 06:41:40 [INFO]: Epoch 111 - generator training loss: -0.1209, discriminator training loss: 0.2997, validation loss: 0.1231
2024-05-25 06:41:44 [INFO]: Epoch 112 - generator training loss: -0.1205, discriminator training loss: 0.2994, validation loss: 0.1225
2024-05-25 06:41:49 [INFO]: Epoch 113 - generator training loss: -0.1205, discriminator training loss: 0.2998, validation loss: 0.1227
2024-05-25 06:41:53 [INFO]: Epoch 114 - generator training loss: -0.1211, discriminator training loss: 0.2991, validation loss: 0.1218
2024-05-25 06:41:57 [INFO]: Epoch 115 - generator training loss: -0.1216, discriminator training loss: 0.2996, validation loss: 0.1232
2024-05-25 06:42:01 [INFO]: Epoch 116 - generator training loss: -0.1205, discriminator training loss: 0.2995, validation loss: 0.1226
2024-05-25 06:42:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:42:01 [INFO]: Finished training. The best model is from epoch#106.
2024-05-25 06:42:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_air_quality/20240525_T063403/USGAN.pypots
2024-05-25 06:42:02 [INFO]: US-GAN on Air-Quality: MAE=0.1646, MSE=0.1306
2024-05-25 06:42:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_air_quality/imputation.pkl
2024-05-25 06:42:02 [INFO]: Using the given device: cuda:0
2024-05-25 06:42:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T064202
2024-05-25 06:42:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T064202/tensorboard
2024-05-25 06:42:02 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 06:42:05 [INFO]: Epoch 001 - training loss: 1.4193, validation loss: 0.9795
2024-05-25 06:42:08 [INFO]: Epoch 002 - training loss: 1.1618, validation loss: 0.7299
2024-05-25 06:42:11 [INFO]: Epoch 003 - training loss: 0.9613, validation loss: 0.6182
2024-05-25 06:42:14 [INFO]: Epoch 004 - training loss: 0.8505, validation loss: 0.5488
2024-05-25 06:42:16 [INFO]: Epoch 005 - training loss: 0.7792, validation loss: 0.5040
2024-05-25 06:42:19 [INFO]: Epoch 006 - training loss: 0.7236, validation loss: 0.4676
2024-05-25 06:42:22 [INFO]: Epoch 007 - training loss: 0.6816, validation loss: 0.4367
2024-05-25 06:42:25 [INFO]: Epoch 008 - training loss: 0.6494, validation loss: 0.4119
2024-05-25 06:42:28 [INFO]: Epoch 009 - training loss: 0.6212, validation loss: 0.3918
2024-05-25 06:42:30 [INFO]: Epoch 010 - training loss: 0.5994, validation loss: 0.3743
2024-05-25 06:42:33 [INFO]: Epoch 011 - training loss: 0.5815, validation loss: 0.3597
2024-05-25 06:42:36 [INFO]: Epoch 012 - training loss: 0.5677, validation loss: 0.3482
2024-05-25 06:42:39 [INFO]: Epoch 013 - training loss: 0.5549, validation loss: 0.3365
2024-05-25 06:42:42 [INFO]: Epoch 014 - training loss: 0.5417, validation loss: 0.3269
2024-05-25 06:42:44 [INFO]: Epoch 015 - training loss: 0.5335, validation loss: 0.3184
2024-05-25 06:42:47 [INFO]: Epoch 016 - training loss: 0.5210, validation loss: 0.3116
2024-05-25 06:42:50 [INFO]: Epoch 017 - training loss: 0.5131, validation loss: 0.3046
2024-05-25 06:42:53 [INFO]: Epoch 018 - training loss: 0.5035, validation loss: 0.2978
2024-05-25 06:42:56 [INFO]: Epoch 019 - training loss: 0.4959, validation loss: 0.2922
2024-05-25 06:42:59 [INFO]: Epoch 020 - training loss: 0.4878, validation loss: 0.2858
2024-05-25 06:43:01 [INFO]: Epoch 021 - training loss: 0.4810, validation loss: 0.2816
2024-05-25 06:43:04 [INFO]: Epoch 022 - training loss: 0.4740, validation loss: 0.2765
2024-05-25 06:43:07 [INFO]: Epoch 023 - training loss: 0.4690, validation loss: 0.2724
2024-05-25 06:43:10 [INFO]: Epoch 024 - training loss: 0.4612, validation loss: 0.2677
2024-05-25 06:43:13 [INFO]: Epoch 025 - training loss: 0.4561, validation loss: 0.2636
2024-05-25 06:43:15 [INFO]: Epoch 026 - training loss: 0.4505, validation loss: 0.2598
2024-05-25 06:43:18 [INFO]: Epoch 027 - training loss: 0.4441, validation loss: 0.2563
2024-05-25 06:43:21 [INFO]: Epoch 028 - training loss: 0.4397, validation loss: 0.2529
2024-05-25 06:43:24 [INFO]: Epoch 029 - training loss: 0.4349, validation loss: 0.2492
2024-05-25 06:43:27 [INFO]: Epoch 030 - training loss: 0.4286, validation loss: 0.2460
2024-05-25 06:43:29 [INFO]: Epoch 031 - training loss: 0.4245, validation loss: 0.2433
2024-05-25 06:43:32 [INFO]: Epoch 032 - training loss: 0.4215, validation loss: 0.2401
2024-05-25 06:43:35 [INFO]: Epoch 033 - training loss: 0.4156, validation loss: 0.2370
2024-05-25 06:43:38 [INFO]: Epoch 034 - training loss: 0.4122, validation loss: 0.2347
2024-05-25 06:43:41 [INFO]: Epoch 035 - training loss: 0.4078, validation loss: 0.2316
2024-05-25 06:43:44 [INFO]: Epoch 036 - training loss: 0.4056, validation loss: 0.2290
2024-05-25 06:43:46 [INFO]: Epoch 037 - training loss: 0.4005, validation loss: 0.2266
2024-05-25 06:43:49 [INFO]: Epoch 038 - training loss: 0.3982, validation loss: 0.2241
2024-05-25 06:43:52 [INFO]: Epoch 039 - training loss: 0.3939, validation loss: 0.2216
2024-05-25 06:43:55 [INFO]: Epoch 040 - training loss: 0.3909, validation loss: 0.2190
2024-05-25 06:43:58 [INFO]: Epoch 041 - training loss: 0.3878, validation loss: 0.2170
2024-05-25 06:44:01 [INFO]: Epoch 042 - training loss: 0.3846, validation loss: 0.2148
2024-05-25 06:44:03 [INFO]: Epoch 043 - training loss: 0.3822, validation loss: 0.2125
2024-05-25 06:44:06 [INFO]: Epoch 044 - training loss: 0.3794, validation loss: 0.2108
2024-05-25 06:44:09 [INFO]: Epoch 045 - training loss: 0.3767, validation loss: 0.2087
2024-05-25 06:44:12 [INFO]: Epoch 046 - training loss: 0.3735, validation loss: 0.2071
2024-05-25 06:44:15 [INFO]: Epoch 047 - training loss: 0.3714, validation loss: 0.2053
2024-05-25 06:44:17 [INFO]: Epoch 048 - training loss: 0.3685, validation loss: 0.2036
2024-05-25 06:44:20 [INFO]: Epoch 049 - training loss: 0.3665, validation loss: 0.2020
2024-05-25 06:44:23 [INFO]: Epoch 050 - training loss: 0.3646, validation loss: 0.2001
2024-05-25 06:44:26 [INFO]: Epoch 051 - training loss: 0.3620, validation loss: 0.1985
2024-05-25 06:44:29 [INFO]: Epoch 052 - training loss: 0.3600, validation loss: 0.1969
2024-05-25 06:44:31 [INFO]: Epoch 053 - training loss: 0.3572, validation loss: 0.1959
2024-05-25 06:44:34 [INFO]: Epoch 054 - training loss: 0.3550, validation loss: 0.1943
2024-05-25 06:44:37 [INFO]: Epoch 055 - training loss: 0.3537, validation loss: 0.1928
2024-05-25 06:44:40 [INFO]: Epoch 056 - training loss: 0.3519, validation loss: 0.1917
2024-05-25 06:44:43 [INFO]: Epoch 057 - training loss: 0.3504, validation loss: 0.1905
2024-05-25 06:44:45 [INFO]: Epoch 058 - training loss: 0.3497, validation loss: 0.1894
2024-05-25 06:44:48 [INFO]: Epoch 059 - training loss: 0.3464, validation loss: 0.1883
2024-05-25 06:44:51 [INFO]: Epoch 060 - training loss: 0.3450, validation loss: 0.1871
2024-05-25 06:44:54 [INFO]: Epoch 061 - training loss: 0.3439, validation loss: 0.1859
2024-05-25 06:44:57 [INFO]: Epoch 062 - training loss: 0.3417, validation loss: 0.1850
2024-05-25 06:45:00 [INFO]: Epoch 063 - training loss: 0.3400, validation loss: 0.1842
2024-05-25 06:45:02 [INFO]: Epoch 064 - training loss: 0.3394, validation loss: 0.1829
2024-05-25 06:45:05 [INFO]: Epoch 065 - training loss: 0.3373, validation loss: 0.1821
2024-05-25 06:45:08 [INFO]: Epoch 066 - training loss: 0.3365, validation loss: 0.1812
2024-05-25 06:45:11 [INFO]: Epoch 067 - training loss: 0.3345, validation loss: 0.1803
2024-05-25 06:45:14 [INFO]: Epoch 068 - training loss: 0.3324, validation loss: 0.1794
2024-05-25 06:45:16 [INFO]: Epoch 069 - training loss: 0.3319, validation loss: 0.1786
2024-05-25 06:45:19 [INFO]: Epoch 070 - training loss: 0.3307, validation loss: 0.1777
2024-05-25 06:45:22 [INFO]: Epoch 071 - training loss: 0.3298, validation loss: 0.1770
2024-05-25 06:45:25 [INFO]: Epoch 072 - training loss: 0.3283, validation loss: 0.1761
2024-05-25 06:45:28 [INFO]: Epoch 073 - training loss: 0.3273, validation loss: 0.1753
2024-05-25 06:45:30 [INFO]: Epoch 074 - training loss: 0.3258, validation loss: 0.1748
2024-05-25 06:45:33 [INFO]: Epoch 075 - training loss: 0.3249, validation loss: 0.1741
2024-05-25 06:45:36 [INFO]: Epoch 076 - training loss: 0.3233, validation loss: 0.1733
2024-05-25 06:45:39 [INFO]: Epoch 077 - training loss: 0.3230, validation loss: 0.1727
2024-05-25 06:45:42 [INFO]: Epoch 078 - training loss: 0.3218, validation loss: 0.1721
2024-05-25 06:45:45 [INFO]: Epoch 079 - training loss: 0.3211, validation loss: 0.1712
2024-05-25 06:45:47 [INFO]: Epoch 080 - training loss: 0.3199, validation loss: 0.1708
2024-05-25 06:45:50 [INFO]: Epoch 081 - training loss: 0.3193, validation loss: 0.1701
2024-05-25 06:45:53 [INFO]: Epoch 082 - training loss: 0.3189, validation loss: 0.1693
2024-05-25 06:45:56 [INFO]: Epoch 083 - training loss: 0.3180, validation loss: 0.1690
2024-05-25 06:45:59 [INFO]: Epoch 084 - training loss: 0.3166, validation loss: 0.1684
2024-05-25 06:46:01 [INFO]: Epoch 085 - training loss: 0.3150, validation loss: 0.1675
2024-05-25 06:46:04 [INFO]: Epoch 086 - training loss: 0.3147, validation loss: 0.1669
2024-05-25 06:46:07 [INFO]: Epoch 087 - training loss: 0.3138, validation loss: 0.1665
2024-05-25 06:46:10 [INFO]: Epoch 088 - training loss: 0.3135, validation loss: 0.1661
2024-05-25 06:46:13 [INFO]: Epoch 089 - training loss: 0.3128, validation loss: 0.1656
2024-05-25 06:46:16 [INFO]: Epoch 090 - training loss: 0.3121, validation loss: 0.1649
2024-05-25 06:46:18 [INFO]: Epoch 091 - training loss: 0.3110, validation loss: 0.1643
2024-05-25 06:46:21 [INFO]: Epoch 092 - training loss: 0.3100, validation loss: 0.1641
2024-05-25 06:46:24 [INFO]: Epoch 093 - training loss: 0.3093, validation loss: 0.1635
2024-05-25 06:46:27 [INFO]: Epoch 094 - training loss: 0.3086, validation loss: 0.1629
2024-05-25 06:46:30 [INFO]: Epoch 095 - training loss: 0.3079, validation loss: 0.1626
2024-05-25 06:46:32 [INFO]: Epoch 096 - training loss: 0.3075, validation loss: 0.1620
2024-05-25 06:46:35 [INFO]: Epoch 097 - training loss: 0.3067, validation loss: 0.1617
2024-05-25 06:46:38 [INFO]: Epoch 098 - training loss: 0.3063, validation loss: 0.1613
2024-05-25 06:46:41 [INFO]: Epoch 099 - training loss: 0.3051, validation loss: 0.1609
2024-05-25 06:46:44 [INFO]: Epoch 100 - training loss: 0.3053, validation loss: 0.1604
2024-05-25 06:46:46 [INFO]: Epoch 101 - training loss: 0.3042, validation loss: 0.1599
2024-05-25 06:46:49 [INFO]: Epoch 102 - training loss: 0.3031, validation loss: 0.1592
2024-05-25 06:46:52 [INFO]: Epoch 103 - training loss: 0.3031, validation loss: 0.1591
2024-05-25 06:46:55 [INFO]: Epoch 104 - training loss: 0.3025, validation loss: 0.1586
2024-05-25 06:46:58 [INFO]: Epoch 105 - training loss: 0.3019, validation loss: 0.1581
2024-05-25 06:47:00 [INFO]: Epoch 106 - training loss: 0.3014, validation loss: 0.1579
2024-05-25 06:47:03 [INFO]: Epoch 107 - training loss: 0.3011, validation loss: 0.1576
2024-05-25 06:47:06 [INFO]: Epoch 108 - training loss: 0.3003, validation loss: 0.1570
2024-05-25 06:47:09 [INFO]: Epoch 109 - training loss: 0.2997, validation loss: 0.1568
2024-05-25 06:47:12 [INFO]: Epoch 110 - training loss: 0.2990, validation loss: 0.1565
2024-05-25 06:47:15 [INFO]: Epoch 111 - training loss: 0.2980, validation loss: 0.1560
2024-05-25 06:47:17 [INFO]: Epoch 112 - training loss: 0.2978, validation loss: 0.1557
2024-05-25 06:47:20 [INFO]: Epoch 113 - training loss: 0.2970, validation loss: 0.1555
2024-05-25 06:47:23 [INFO]: Epoch 114 - training loss: 0.2969, validation loss: 0.1548
2024-05-25 06:47:26 [INFO]: Epoch 115 - training loss: 0.2965, validation loss: 0.1546
2024-05-25 06:47:29 [INFO]: Epoch 116 - training loss: 0.2959, validation loss: 0.1543
2024-05-25 06:47:31 [INFO]: Epoch 117 - training loss: 0.2952, validation loss: 0.1537
2024-05-25 06:47:34 [INFO]: Epoch 118 - training loss: 0.2949, validation loss: 0.1537
2024-05-25 06:47:37 [INFO]: Epoch 119 - training loss: 0.2943, validation loss: 0.1532
2024-05-25 06:47:40 [INFO]: Epoch 120 - training loss: 0.2937, validation loss: 0.1529
2024-05-25 06:47:43 [INFO]: Epoch 121 - training loss: 0.2933, validation loss: 0.1526
2024-05-25 06:47:46 [INFO]: Epoch 122 - training loss: 0.2934, validation loss: 0.1523
2024-05-25 06:47:48 [INFO]: Epoch 123 - training loss: 0.2922, validation loss: 0.1521
2024-05-25 06:47:51 [INFO]: Epoch 124 - training loss: 0.2925, validation loss: 0.1518
2024-05-25 06:47:54 [INFO]: Epoch 125 - training loss: 0.2915, validation loss: 0.1511
2024-05-25 06:47:57 [INFO]: Epoch 126 - training loss: 0.2911, validation loss: 0.1509
2024-05-25 06:48:00 [INFO]: Epoch 127 - training loss: 0.2904, validation loss: 0.1506
2024-05-25 06:48:02 [INFO]: Epoch 128 - training loss: 0.2904, validation loss: 0.1504
2024-05-25 06:48:05 [INFO]: Epoch 129 - training loss: 0.2899, validation loss: 0.1500
2024-05-25 06:48:08 [INFO]: Epoch 130 - training loss: 0.2888, validation loss: 0.1500
2024-05-25 06:48:11 [INFO]: Epoch 131 - training loss: 0.2888, validation loss: 0.1495
2024-05-25 06:48:14 [INFO]: Epoch 132 - training loss: 0.2896, validation loss: 0.1494
2024-05-25 06:48:16 [INFO]: Epoch 133 - training loss: 0.2879, validation loss: 0.1488
2024-05-25 06:48:19 [INFO]: Epoch 134 - training loss: 0.2880, validation loss: 0.1487
2024-05-25 06:48:22 [INFO]: Epoch 135 - training loss: 0.2874, validation loss: 0.1484
2024-05-25 06:48:25 [INFO]: Epoch 136 - training loss: 0.2871, validation loss: 0.1482
2024-05-25 06:48:28 [INFO]: Epoch 137 - training loss: 0.2867, validation loss: 0.1480
2024-05-25 06:48:31 [INFO]: Epoch 138 - training loss: 0.2863, validation loss: 0.1477
2024-05-25 06:48:33 [INFO]: Epoch 139 - training loss: 0.2868, validation loss: 0.1475
2024-05-25 06:48:36 [INFO]: Epoch 140 - training loss: 0.2865, validation loss: 0.1472
2024-05-25 06:48:39 [INFO]: Epoch 141 - training loss: 0.2848, validation loss: 0.1470
2024-05-25 06:48:42 [INFO]: Epoch 142 - training loss: 0.2849, validation loss: 0.1466
2024-05-25 06:48:45 [INFO]: Epoch 143 - training loss: 0.2843, validation loss: 0.1463
2024-05-25 06:48:47 [INFO]: Epoch 144 - training loss: 0.2843, validation loss: 0.1461
2024-05-25 06:48:50 [INFO]: Epoch 145 - training loss: 0.2841, validation loss: 0.1461
2024-05-25 06:48:53 [INFO]: Epoch 146 - training loss: 0.2838, validation loss: 0.1456
2024-05-25 06:48:56 [INFO]: Epoch 147 - training loss: 0.2827, validation loss: 0.1455
2024-05-25 06:48:59 [INFO]: Epoch 148 - training loss: 0.2823, validation loss: 0.1451
2024-05-25 06:49:01 [INFO]: Epoch 149 - training loss: 0.2829, validation loss: 0.1450
2024-05-25 06:49:04 [INFO]: Epoch 150 - training loss: 0.2816, validation loss: 0.1450
2024-05-25 06:49:07 [INFO]: Epoch 151 - training loss: 0.2817, validation loss: 0.1445
2024-05-25 06:49:10 [INFO]: Epoch 152 - training loss: 0.2812, validation loss: 0.1443
2024-05-25 06:49:13 [INFO]: Epoch 153 - training loss: 0.2817, validation loss: 0.1442
2024-05-25 06:49:15 [INFO]: Epoch 154 - training loss: 0.2806, validation loss: 0.1438
2024-05-25 06:49:18 [INFO]: Epoch 155 - training loss: 0.2804, validation loss: 0.1437
2024-05-25 06:49:21 [INFO]: Epoch 156 - training loss: 0.2794, validation loss: 0.1433
2024-05-25 06:49:24 [INFO]: Epoch 157 - training loss: 0.2805, validation loss: 0.1432
2024-05-25 06:49:27 [INFO]: Epoch 158 - training loss: 0.2797, validation loss: 0.1429
2024-05-25 06:49:29 [INFO]: Epoch 159 - training loss: 0.2787, validation loss: 0.1428
2024-05-25 06:49:32 [INFO]: Epoch 160 - training loss: 0.2783, validation loss: 0.1425
2024-05-25 06:49:35 [INFO]: Epoch 161 - training loss: 0.2789, validation loss: 0.1423
2024-05-25 06:49:38 [INFO]: Epoch 162 - training loss: 0.2777, validation loss: 0.1422
2024-05-25 06:49:41 [INFO]: Epoch 163 - training loss: 0.2780, validation loss: 0.1420
2024-05-25 06:49:44 [INFO]: Epoch 164 - training loss: 0.2775, validation loss: 0.1419
2024-05-25 06:49:46 [INFO]: Epoch 165 - training loss: 0.2775, validation loss: 0.1417
2024-05-25 06:49:49 [INFO]: Epoch 166 - training loss: 0.2769, validation loss: 0.1414
2024-05-25 06:49:52 [INFO]: Epoch 167 - training loss: 0.2768, validation loss: 0.1412
2024-05-25 06:49:55 [INFO]: Epoch 168 - training loss: 0.2761, validation loss: 0.1412
2024-05-25 06:49:58 [INFO]: Epoch 169 - training loss: 0.2757, validation loss: 0.1410
2024-05-25 06:50:01 [INFO]: Epoch 170 - training loss: 0.2760, validation loss: 0.1406
2024-05-25 06:50:03 [INFO]: Epoch 171 - training loss: 0.2754, validation loss: 0.1405
2024-05-25 06:50:06 [INFO]: Epoch 172 - training loss: 0.2752, validation loss: 0.1402
2024-05-25 06:50:09 [INFO]: Epoch 173 - training loss: 0.2753, validation loss: 0.1404
2024-05-25 06:50:12 [INFO]: Epoch 174 - training loss: 0.2752, validation loss: 0.1403
2024-05-25 06:50:15 [INFO]: Epoch 175 - training loss: 0.2749, validation loss: 0.1397
2024-05-25 06:50:17 [INFO]: Epoch 176 - training loss: 0.2743, validation loss: 0.1398
2024-05-25 06:50:20 [INFO]: Epoch 177 - training loss: 0.2740, validation loss: 0.1395
2024-05-25 06:50:23 [INFO]: Epoch 178 - training loss: 0.2736, validation loss: 0.1392
2024-05-25 06:50:26 [INFO]: Epoch 179 - training loss: 0.2731, validation loss: 0.1393
2024-05-25 06:50:29 [INFO]: Epoch 180 - training loss: 0.2736, validation loss: 0.1392
2024-05-25 06:50:31 [INFO]: Epoch 181 - training loss: 0.2727, validation loss: 0.1389
2024-05-25 06:50:34 [INFO]: Epoch 182 - training loss: 0.2727, validation loss: 0.1388
2024-05-25 06:50:37 [INFO]: Epoch 183 - training loss: 0.2724, validation loss: 0.1386
2024-05-25 06:50:40 [INFO]: Epoch 184 - training loss: 0.2720, validation loss: 0.1385
2024-05-25 06:50:43 [INFO]: Epoch 185 - training loss: 0.2721, validation loss: 0.1382
2024-05-25 06:50:45 [INFO]: Epoch 186 - training loss: 0.2724, validation loss: 0.1382
2024-05-25 06:50:48 [INFO]: Epoch 187 - training loss: 0.2713, validation loss: 0.1380
2024-05-25 06:50:51 [INFO]: Epoch 188 - training loss: 0.2711, validation loss: 0.1379
2024-05-25 06:50:54 [INFO]: Epoch 189 - training loss: 0.2709, validation loss: 0.1378
2024-05-25 06:50:57 [INFO]: Epoch 190 - training loss: 0.2715, validation loss: 0.1377
2024-05-25 06:51:00 [INFO]: Epoch 191 - training loss: 0.2701, validation loss: 0.1374
2024-05-25 06:51:02 [INFO]: Epoch 192 - training loss: 0.2697, validation loss: 0.1372
2024-05-25 06:51:05 [INFO]: Epoch 193 - training loss: 0.2701, validation loss: 0.1371
2024-05-25 06:51:08 [INFO]: Epoch 194 - training loss: 0.2707, validation loss: 0.1372
2024-05-25 06:51:11 [INFO]: Epoch 195 - training loss: 0.2697, validation loss: 0.1368
2024-05-25 06:51:14 [INFO]: Epoch 196 - training loss: 0.2693, validation loss: 0.1368
2024-05-25 06:51:16 [INFO]: Epoch 197 - training loss: 0.2688, validation loss: 0.1366
2024-05-25 06:51:19 [INFO]: Epoch 198 - training loss: 0.2691, validation loss: 0.1365
2024-05-25 06:51:22 [INFO]: Epoch 199 - training loss: 0.2688, validation loss: 0.1363
2024-05-25 06:51:25 [INFO]: Epoch 200 - training loss: 0.2685, validation loss: 0.1363
2024-05-25 06:51:28 [INFO]: Epoch 201 - training loss: 0.2680, validation loss: 0.1363
2024-05-25 06:51:30 [INFO]: Epoch 202 - training loss: 0.2680, validation loss: 0.1361
2024-05-25 06:51:33 [INFO]: Epoch 203 - training loss: 0.2675, validation loss: 0.1358
2024-05-25 06:51:36 [INFO]: Epoch 204 - training loss: 0.2672, validation loss: 0.1357
2024-05-25 06:51:39 [INFO]: Epoch 205 - training loss: 0.2675, validation loss: 0.1356
2024-05-25 06:51:42 [INFO]: Epoch 206 - training loss: 0.2673, validation loss: 0.1355
2024-05-25 06:51:44 [INFO]: Epoch 207 - training loss: 0.2667, validation loss: 0.1355
2024-05-25 06:51:47 [INFO]: Epoch 208 - training loss: 0.2669, validation loss: 0.1354
2024-05-25 06:51:50 [INFO]: Epoch 209 - training loss: 0.2663, validation loss: 0.1353
2024-05-25 06:51:53 [INFO]: Epoch 210 - training loss: 0.2661, validation loss: 0.1352
2024-05-25 06:51:56 [INFO]: Epoch 211 - training loss: 0.2663, validation loss: 0.1349
2024-05-25 06:51:59 [INFO]: Epoch 212 - training loss: 0.2658, validation loss: 0.1347
2024-05-25 06:52:01 [INFO]: Epoch 213 - training loss: 0.2656, validation loss: 0.1348
2024-05-25 06:52:04 [INFO]: Epoch 214 - training loss: 0.2656, validation loss: 0.1349
2024-05-25 06:52:07 [INFO]: Epoch 215 - training loss: 0.2656, validation loss: 0.1346
2024-05-25 06:52:10 [INFO]: Epoch 216 - training loss: 0.2649, validation loss: 0.1345
2024-05-25 06:52:13 [INFO]: Epoch 217 - training loss: 0.2650, validation loss: 0.1342
2024-05-25 06:52:16 [INFO]: Epoch 218 - training loss: 0.2647, validation loss: 0.1343
2024-05-25 06:52:18 [INFO]: Epoch 219 - training loss: 0.2641, validation loss: 0.1341
2024-05-25 06:52:21 [INFO]: Epoch 220 - training loss: 0.2641, validation loss: 0.1338
2024-05-25 06:52:24 [INFO]: Epoch 221 - training loss: 0.2639, validation loss: 0.1338
2024-05-25 06:52:27 [INFO]: Epoch 222 - training loss: 0.2639, validation loss: 0.1339
2024-05-25 06:52:30 [INFO]: Epoch 223 - training loss: 0.2640, validation loss: 0.1335
2024-05-25 06:52:32 [INFO]: Epoch 224 - training loss: 0.2631, validation loss: 0.1335
2024-05-25 06:52:35 [INFO]: Epoch 225 - training loss: 0.2634, validation loss: 0.1335
2024-05-25 06:52:38 [INFO]: Epoch 226 - training loss: 0.2632, validation loss: 0.1334
2024-05-25 06:52:41 [INFO]: Epoch 227 - training loss: 0.2632, validation loss: 0.1333
2024-05-25 06:52:44 [INFO]: Epoch 228 - training loss: 0.2628, validation loss: 0.1331
2024-05-25 06:52:46 [INFO]: Epoch 229 - training loss: 0.2622, validation loss: 0.1330
2024-05-25 06:52:49 [INFO]: Epoch 230 - training loss: 0.2624, validation loss: 0.1330
2024-05-25 06:52:52 [INFO]: Epoch 231 - training loss: 0.2619, validation loss: 0.1329
2024-05-25 06:52:55 [INFO]: Epoch 232 - training loss: 0.2622, validation loss: 0.1328
2024-05-25 06:52:58 [INFO]: Epoch 233 - training loss: 0.2618, validation loss: 0.1326
2024-05-25 06:53:00 [INFO]: Epoch 234 - training loss: 0.2615, validation loss: 0.1324
2024-05-25 06:53:03 [INFO]: Epoch 235 - training loss: 0.2611, validation loss: 0.1325
2024-05-25 06:53:06 [INFO]: Epoch 236 - training loss: 0.2619, validation loss: 0.1325
2024-05-25 06:53:09 [INFO]: Epoch 237 - training loss: 0.2614, validation loss: 0.1324
2024-05-25 06:53:12 [INFO]: Epoch 238 - training loss: 0.2610, validation loss: 0.1322
2024-05-25 06:53:15 [INFO]: Epoch 239 - training loss: 0.2606, validation loss: 0.1320
2024-05-25 06:53:17 [INFO]: Epoch 240 - training loss: 0.2607, validation loss: 0.1321
2024-05-25 06:53:20 [INFO]: Epoch 241 - training loss: 0.2606, validation loss: 0.1321
2024-05-25 06:53:23 [INFO]: Epoch 242 - training loss: 0.2600, validation loss: 0.1319
2024-05-25 06:53:26 [INFO]: Epoch 243 - training loss: 0.2603, validation loss: 0.1318
2024-05-25 06:53:29 [INFO]: Epoch 244 - training loss: 0.2599, validation loss: 0.1316
2024-05-25 06:53:31 [INFO]: Epoch 245 - training loss: 0.2596, validation loss: 0.1318
2024-05-25 06:53:34 [INFO]: Epoch 246 - training loss: 0.2597, validation loss: 0.1315
2024-05-25 06:53:37 [INFO]: Epoch 247 - training loss: 0.2601, validation loss: 0.1317
2024-05-25 06:53:40 [INFO]: Epoch 248 - training loss: 0.2594, validation loss: 0.1314
2024-05-25 06:53:43 [INFO]: Epoch 249 - training loss: 0.2594, validation loss: 0.1314
2024-05-25 06:53:45 [INFO]: Epoch 250 - training loss: 0.2591, validation loss: 0.1313
2024-05-25 06:53:48 [INFO]: Epoch 251 - training loss: 0.2591, validation loss: 0.1310
2024-05-25 06:53:51 [INFO]: Epoch 252 - training loss: 0.2588, validation loss: 0.1311
2024-05-25 06:53:54 [INFO]: Epoch 253 - training loss: 0.2587, validation loss: 0.1309
2024-05-25 06:53:57 [INFO]: Epoch 254 - training loss: 0.2585, validation loss: 0.1310
2024-05-25 06:54:00 [INFO]: Epoch 255 - training loss: 0.2583, validation loss: 0.1310
2024-05-25 06:54:02 [INFO]: Epoch 256 - training loss: 0.2581, validation loss: 0.1308
2024-05-25 06:54:05 [INFO]: Epoch 257 - training loss: 0.2578, validation loss: 0.1307
2024-05-25 06:54:08 [INFO]: Epoch 258 - training loss: 0.2574, validation loss: 0.1306
2024-05-25 06:54:11 [INFO]: Epoch 259 - training loss: 0.2576, validation loss: 0.1305
2024-05-25 06:54:14 [INFO]: Epoch 260 - training loss: 0.2575, validation loss: 0.1306
2024-05-25 06:54:16 [INFO]: Epoch 261 - training loss: 0.2568, validation loss: 0.1305
2024-05-25 06:54:19 [INFO]: Epoch 262 - training loss: 0.2571, validation loss: 0.1302
2024-05-25 06:54:22 [INFO]: Epoch 263 - training loss: 0.2571, validation loss: 0.1302
2024-05-25 06:54:25 [INFO]: Epoch 264 - training loss: 0.2568, validation loss: 0.1303
2024-05-25 06:54:28 [INFO]: Epoch 265 - training loss: 0.2568, validation loss: 0.1302
2024-05-25 06:54:31 [INFO]: Epoch 266 - training loss: 0.2564, validation loss: 0.1302
2024-05-25 06:54:33 [INFO]: Epoch 267 - training loss: 0.2562, validation loss: 0.1300
2024-05-25 06:54:36 [INFO]: Epoch 268 - training loss: 0.2561, validation loss: 0.1300
2024-05-25 06:54:39 [INFO]: Epoch 269 - training loss: 0.2558, validation loss: 0.1301
2024-05-25 06:54:42 [INFO]: Epoch 270 - training loss: 0.2557, validation loss: 0.1302
2024-05-25 06:54:45 [INFO]: Epoch 271 - training loss: 0.2558, validation loss: 0.1301
2024-05-25 06:54:47 [INFO]: Epoch 272 - training loss: 0.2558, validation loss: 0.1297
2024-05-25 06:54:50 [INFO]: Epoch 273 - training loss: 0.2553, validation loss: 0.1298
2024-05-25 06:54:53 [INFO]: Epoch 274 - training loss: 0.2554, validation loss: 0.1296
2024-05-25 06:54:56 [INFO]: Epoch 275 - training loss: 0.2552, validation loss: 0.1296
2024-05-25 06:54:59 [INFO]: Epoch 276 - training loss: 0.2547, validation loss: 0.1295
2024-05-25 06:55:01 [INFO]: Epoch 277 - training loss: 0.2549, validation loss: 0.1298
2024-05-25 06:55:04 [INFO]: Epoch 278 - training loss: 0.2544, validation loss: 0.1296
2024-05-25 06:55:07 [INFO]: Epoch 279 - training loss: 0.2545, validation loss: 0.1295
2024-05-25 06:55:10 [INFO]: Epoch 280 - training loss: 0.2547, validation loss: 0.1293
2024-05-25 06:55:13 [INFO]: Epoch 281 - training loss: 0.2539, validation loss: 0.1295
2024-05-25 06:55:15 [INFO]: Epoch 282 - training loss: 0.2541, validation loss: 0.1291
2024-05-25 06:55:18 [INFO]: Epoch 283 - training loss: 0.2543, validation loss: 0.1294
2024-05-25 06:55:21 [INFO]: Epoch 284 - training loss: 0.2539, validation loss: 0.1292
2024-05-25 06:55:24 [INFO]: Epoch 285 - training loss: 0.2538, validation loss: 0.1293
2024-05-25 06:55:27 [INFO]: Epoch 286 - training loss: 0.2545, validation loss: 0.1289
2024-05-25 06:55:30 [INFO]: Epoch 287 - training loss: 0.2538, validation loss: 0.1291
2024-05-25 06:55:32 [INFO]: Epoch 288 - training loss: 0.2537, validation loss: 0.1290
2024-05-25 06:55:35 [INFO]: Epoch 289 - training loss: 0.2536, validation loss: 0.1290
2024-05-25 06:55:38 [INFO]: Epoch 290 - training loss: 0.2530, validation loss: 0.1289
2024-05-25 06:55:41 [INFO]: Epoch 291 - training loss: 0.2535, validation loss: 0.1288
2024-05-25 06:55:44 [INFO]: Epoch 292 - training loss: 0.2530, validation loss: 0.1290
2024-05-25 06:55:46 [INFO]: Epoch 293 - training loss: 0.2528, validation loss: 0.1288
2024-05-25 06:55:49 [INFO]: Epoch 294 - training loss: 0.2535, validation loss: 0.1288
2024-05-25 06:55:52 [INFO]: Epoch 295 - training loss: 0.2526, validation loss: 0.1287
2024-05-25 06:55:55 [INFO]: Epoch 296 - training loss: 0.2521, validation loss: 0.1287
2024-05-25 06:55:58 [INFO]: Epoch 297 - training loss: 0.2522, validation loss: 0.1285
2024-05-25 06:56:00 [INFO]: Epoch 298 - training loss: 0.2524, validation loss: 0.1287
2024-05-25 06:56:03 [INFO]: Epoch 299 - training loss: 0.2522, validation loss: 0.1285
2024-05-25 06:56:06 [INFO]: Epoch 300 - training loss: 0.2517, validation loss: 0.1284
2024-05-25 06:56:06 [INFO]: Finished training. The best model is from epoch#300.
2024-05-25 06:56:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_air_quality/20240525_T064202/BRITS.pypots
2024-05-25 06:56:07 [INFO]: BRITS on Air-Quality: MAE=0.1510, MSE=0.1305
2024-05-25 06:56:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_air_quality/imputation.pkl
2024-05-25 06:56:07 [INFO]: Using the given device: cuda:0
2024-05-25 06:56:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607
2024-05-25 06:56:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/tensorboard
2024-05-25 06:56:07 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 06:56:12 [INFO]: Epoch 001 - training loss: 1.4506, validation loss: 0.8312
2024-05-25 06:56:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch1_loss0.8311938226222992.pypots
2024-05-25 06:56:15 [INFO]: Epoch 002 - training loss: 1.0194, validation loss: 0.7749
2024-05-25 06:56:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch2_loss0.774879914522171.pypots
2024-05-25 06:56:19 [INFO]: Epoch 003 - training loss: 0.9345, validation loss: 0.7493
2024-05-25 06:56:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch3_loss0.7492737501859665.pypots
2024-05-25 06:56:23 [INFO]: Epoch 004 - training loss: 0.9040, validation loss: 0.7369
2024-05-25 06:56:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch4_loss0.7368652790784835.pypots
2024-05-25 06:56:27 [INFO]: Epoch 005 - training loss: 0.9031, validation loss: 0.7289
2024-05-25 06:56:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch5_loss0.7289370059967041.pypots
2024-05-25 06:56:31 [INFO]: Epoch 006 - training loss: 0.8930, validation loss: 0.7220
2024-05-25 06:56:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch6_loss0.7219668835401535.pypots
2024-05-25 06:56:35 [INFO]: Epoch 007 - training loss: 0.8832, validation loss: 0.7175
2024-05-25 06:56:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch7_loss0.7175244420766831.pypots
2024-05-25 06:56:39 [INFO]: Epoch 008 - training loss: 0.8573, validation loss: 0.7135
2024-05-25 06:56:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch8_loss0.7134771466255188.pypots
2024-05-25 06:56:43 [INFO]: Epoch 009 - training loss: 0.8627, validation loss: 0.7116
2024-05-25 06:56:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch9_loss0.7116023659706116.pypots
2024-05-25 06:56:47 [INFO]: Epoch 010 - training loss: 0.8859, validation loss: 0.7083
2024-05-25 06:56:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch10_loss0.7083493739366531.pypots
2024-05-25 06:56:51 [INFO]: Epoch 011 - training loss: 0.8883, validation loss: 0.7052
2024-05-25 06:56:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch11_loss0.7051953762769699.pypots
2024-05-25 06:56:54 [INFO]: Epoch 012 - training loss: 0.8537, validation loss: 0.7045
2024-05-25 06:56:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch12_loss0.7044562697410583.pypots
2024-05-25 06:56:58 [INFO]: Epoch 013 - training loss: 0.8478, validation loss: 0.7044
2024-05-25 06:56:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch13_loss0.7044052392244339.pypots
2024-05-25 06:57:02 [INFO]: Epoch 014 - training loss: 0.8464, validation loss: 0.7016
2024-05-25 06:57:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch14_loss0.7016252398490905.pypots
2024-05-25 06:57:06 [INFO]: Epoch 015 - training loss: 0.8393, validation loss: 0.7008
2024-05-25 06:57:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch15_loss0.7007727593183517.pypots
2024-05-25 06:57:10 [INFO]: Epoch 016 - training loss: 0.8288, validation loss: 0.7006
2024-05-25 06:57:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch16_loss0.7005648612976074.pypots
2024-05-25 06:57:14 [INFO]: Epoch 017 - training loss: 0.8379, validation loss: 0.6995
2024-05-25 06:57:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch17_loss0.699464637041092.pypots
2024-05-25 06:57:18 [INFO]: Epoch 018 - training loss: 0.8416, validation loss: 0.7004
2024-05-25 06:57:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch18_loss0.7004399478435517.pypots
2024-05-25 06:57:22 [INFO]: Epoch 019 - training loss: 0.8481, validation loss: 0.7022
2024-05-25 06:57:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch19_loss0.7022147297859191.pypots
2024-05-25 06:57:26 [INFO]: Epoch 020 - training loss: 0.8349, validation loss: 0.6997
2024-05-25 06:57:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch20_loss0.6996943354606628.pypots
2024-05-25 06:57:29 [INFO]: Epoch 021 - training loss: 0.8168, validation loss: 0.7000
2024-05-25 06:57:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch21_loss0.7000165045261383.pypots
2024-05-25 06:57:33 [INFO]: Epoch 022 - training loss: 0.8155, validation loss: 0.6966
2024-05-25 06:57:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch22_loss0.6966093957424164.pypots
2024-05-25 06:57:37 [INFO]: Epoch 023 - training loss: 0.8374, validation loss: 0.6982
2024-05-25 06:57:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch23_loss0.6982109099626541.pypots
2024-05-25 06:57:41 [INFO]: Epoch 024 - training loss: 0.8383, validation loss: 0.6976
2024-05-25 06:57:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch24_loss0.69756198823452.pypots
2024-05-25 06:57:45 [INFO]: Epoch 025 - training loss: 0.8424, validation loss: 0.6986
2024-05-25 06:57:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch25_loss0.6986148297786713.pypots
2024-05-25 06:57:49 [INFO]: Epoch 026 - training loss: 0.8351, validation loss: 0.6982
2024-05-25 06:57:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch26_loss0.698222216963768.pypots
2024-05-25 06:57:53 [INFO]: Epoch 027 - training loss: 0.8158, validation loss: 0.7006
2024-05-25 06:57:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch27_loss0.7006058782339096.pypots
2024-05-25 06:57:57 [INFO]: Epoch 028 - training loss: 0.8106, validation loss: 0.6975
2024-05-25 06:57:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch28_loss0.6975459575653076.pypots
2024-05-25 06:58:01 [INFO]: Epoch 029 - training loss: 0.8026, validation loss: 0.6998
2024-05-25 06:58:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch29_loss0.6998039662837983.pypots
2024-05-25 06:58:05 [INFO]: Epoch 030 - training loss: 0.8063, validation loss: 0.6992
2024-05-25 06:58:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch30_loss0.6992364525794983.pypots
2024-05-25 06:58:08 [INFO]: Epoch 031 - training loss: 0.8052, validation loss: 0.7010
2024-05-25 06:58:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch31_loss0.7010067939758301.pypots
2024-05-25 06:58:12 [INFO]: Epoch 032 - training loss: 0.8118, validation loss: 0.6986
2024-05-25 06:58:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN_epoch32_loss0.6986299067735672.pypots
2024-05-25 06:58:12 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:58:12 [INFO]: Finished training. The best model is from epoch#22.
2024-05-25 06:58:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_air_quality/20240525_T065607/MRNN.pypots
2024-05-25 06:58:13 [INFO]: MRNN on Air-Quality: MAE=0.5190, MSE=0.6316
2024-05-25 06:58:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_air_quality/imputation.pkl
2024-05-25 06:58:13 [INFO]: Using the given device: cpu
2024-05-25 06:58:13 [INFO]: LOCF on Air-Quality: MAE=0.2194, MSE=0.3465
2024-05-25 06:58:13 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_air_quality".
2024-05-25 06:58:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_air_quality/imputation.pkl
2024-05-25 06:58:13 [INFO]: Median on Air-Quality: MAE=0.6629, MSE=1.0282
2024-05-25 06:58:13 [INFO]: Successfully created the given path "saved_results/round_3/Median_air_quality".
2024-05-25 06:58:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_air_quality/imputation.pkl
2024-05-25 06:58:13 [INFO]: Mean on Air-Quality: MAE=0.6945, MSE=0.9678
2024-05-25 06:58:13 [INFO]: Successfully created the given path "saved_results/round_3/Mean_air_quality".
2024-05-25 06:58:13 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_air_quality/imputation.pkl
2024-05-25 06:58:13 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-25 06:58:13 [INFO]: Using the given device: cuda:0
2024-05-25 06:58:13 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T065813
2024-05-25 06:58:13 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T065813/tensorboard
2024-05-25 06:58:13 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 43,630,224
2024-05-25 06:58:14 [INFO]: Epoch 001 - training loss: 1.0594, validation loss: 0.5368
2024-05-25 06:58:15 [INFO]: Epoch 002 - training loss: 0.7547, validation loss: 0.4217
2024-05-25 06:58:15 [INFO]: Epoch 003 - training loss: 0.6485, validation loss: 0.3404
2024-05-25 06:58:16 [INFO]: Epoch 004 - training loss: 0.5734, validation loss: 0.3005
2024-05-25 06:58:16 [INFO]: Epoch 005 - training loss: 0.5188, validation loss: 0.2766
2024-05-25 06:58:17 [INFO]: Epoch 006 - training loss: 0.4802, validation loss: 0.2639
2024-05-25 06:58:18 [INFO]: Epoch 007 - training loss: 0.4550, validation loss: 0.2536
2024-05-25 06:58:18 [INFO]: Epoch 008 - training loss: 0.4369, validation loss: 0.2459
2024-05-25 06:58:19 [INFO]: Epoch 009 - training loss: 0.4223, validation loss: 0.2412
2024-05-25 06:58:19 [INFO]: Epoch 010 - training loss: 0.4104, validation loss: 0.2351
2024-05-25 06:58:20 [INFO]: Epoch 011 - training loss: 0.4024, validation loss: 0.2296
2024-05-25 06:58:21 [INFO]: Epoch 012 - training loss: 0.3955, validation loss: 0.2279
2024-05-25 06:58:21 [INFO]: Epoch 013 - training loss: 0.3839, validation loss: 0.2247
2024-05-25 06:58:22 [INFO]: Epoch 014 - training loss: 0.3784, validation loss: 0.2209
2024-05-25 06:58:22 [INFO]: Epoch 015 - training loss: 0.3758, validation loss: 0.2176
2024-05-25 06:58:23 [INFO]: Epoch 016 - training loss: 0.3661, validation loss: 0.2148
2024-05-25 06:58:24 [INFO]: Epoch 017 - training loss: 0.3638, validation loss: 0.2133
2024-05-25 06:58:24 [INFO]: Epoch 018 - training loss: 0.3569, validation loss: 0.2102
2024-05-25 06:58:25 [INFO]: Epoch 019 - training loss: 0.3525, validation loss: 0.2090
2024-05-25 06:58:25 [INFO]: Epoch 020 - training loss: 0.3492, validation loss: 0.2078
2024-05-25 06:58:26 [INFO]: Epoch 021 - training loss: 0.3453, validation loss: 0.2048
2024-05-25 06:58:27 [INFO]: Epoch 022 - training loss: 0.3437, validation loss: 0.2032
2024-05-25 06:58:27 [INFO]: Epoch 023 - training loss: 0.3380, validation loss: 0.2009
2024-05-25 06:58:28 [INFO]: Epoch 024 - training loss: 0.3347, validation loss: 0.2007
2024-05-25 06:58:29 [INFO]: Epoch 025 - training loss: 0.3325, validation loss: 0.1977
2024-05-25 06:58:29 [INFO]: Epoch 026 - training loss: 0.3297, validation loss: 0.1960
2024-05-25 06:58:30 [INFO]: Epoch 027 - training loss: 0.3261, validation loss: 0.1944
2024-05-25 06:58:30 [INFO]: Epoch 028 - training loss: 0.3240, validation loss: 0.1946
2024-05-25 06:58:31 [INFO]: Epoch 029 - training loss: 0.3226, validation loss: 0.1933
2024-05-25 06:58:32 [INFO]: Epoch 030 - training loss: 0.3188, validation loss: 0.1927
2024-05-25 06:58:32 [INFO]: Epoch 031 - training loss: 0.3169, validation loss: 0.1890
2024-05-25 06:58:33 [INFO]: Epoch 032 - training loss: 0.3138, validation loss: 0.1882
2024-05-25 06:58:33 [INFO]: Epoch 033 - training loss: 0.3119, validation loss: 0.1877
2024-05-25 06:58:34 [INFO]: Epoch 034 - training loss: 0.3116, validation loss: 0.1863
2024-05-25 06:58:35 [INFO]: Epoch 035 - training loss: 0.3076, validation loss: 0.1851
2024-05-25 06:58:35 [INFO]: Epoch 036 - training loss: 0.3052, validation loss: 0.1836
2024-05-25 06:58:36 [INFO]: Epoch 037 - training loss: 0.3033, validation loss: 0.1820
2024-05-25 06:58:36 [INFO]: Epoch 038 - training loss: 0.3017, validation loss: 0.1816
2024-05-25 06:58:37 [INFO]: Epoch 039 - training loss: 0.3010, validation loss: 0.1808
2024-05-25 06:58:38 [INFO]: Epoch 040 - training loss: 0.3024, validation loss: 0.1786
2024-05-25 06:58:38 [INFO]: Epoch 041 - training loss: 0.2970, validation loss: 0.1774
2024-05-25 06:58:39 [INFO]: Epoch 042 - training loss: 0.2948, validation loss: 0.1764
2024-05-25 06:58:39 [INFO]: Epoch 043 - training loss: 0.2925, validation loss: 0.1761
2024-05-25 06:58:40 [INFO]: Epoch 044 - training loss: 0.2924, validation loss: 0.1748
2024-05-25 06:58:41 [INFO]: Epoch 045 - training loss: 0.2903, validation loss: 0.1733
2024-05-25 06:58:41 [INFO]: Epoch 046 - training loss: 0.2885, validation loss: 0.1724
2024-05-25 06:58:42 [INFO]: Epoch 047 - training loss: 0.2871, validation loss: 0.1724
2024-05-25 06:58:42 [INFO]: Epoch 048 - training loss: 0.2858, validation loss: 0.1720
2024-05-25 06:58:43 [INFO]: Epoch 049 - training loss: 0.2851, validation loss: 0.1703
2024-05-25 06:58:44 [INFO]: Epoch 050 - training loss: 0.2826, validation loss: 0.1692
2024-05-25 06:58:44 [INFO]: Epoch 051 - training loss: 0.2816, validation loss: 0.1684
2024-05-25 06:58:45 [INFO]: Epoch 052 - training loss: 0.2814, validation loss: 0.1682
2024-05-25 06:58:45 [INFO]: Epoch 053 - training loss: 0.2780, validation loss: 0.1670
2024-05-25 06:58:46 [INFO]: Epoch 054 - training loss: 0.2771, validation loss: 0.1663
2024-05-25 06:58:47 [INFO]: Epoch 055 - training loss: 0.2760, validation loss: 0.1675
2024-05-25 06:58:47 [INFO]: Epoch 056 - training loss: 0.2741, validation loss: 0.1657
2024-05-25 06:58:48 [INFO]: Epoch 057 - training loss: 0.2724, validation loss: 0.1659
2024-05-25 06:58:48 [INFO]: Epoch 058 - training loss: 0.2708, validation loss: 0.1640
2024-05-25 06:58:49 [INFO]: Epoch 059 - training loss: 0.2700, validation loss: 0.1641
2024-05-25 06:58:50 [INFO]: Epoch 060 - training loss: 0.2683, validation loss: 0.1635
2024-05-25 06:58:50 [INFO]: Epoch 061 - training loss: 0.2679, validation loss: 0.1620
2024-05-25 06:58:51 [INFO]: Epoch 062 - training loss: 0.2671, validation loss: 0.1624
2024-05-25 06:58:51 [INFO]: Epoch 063 - training loss: 0.2660, validation loss: 0.1615
2024-05-25 06:58:52 [INFO]: Epoch 064 - training loss: 0.2659, validation loss: 0.1611
2024-05-25 06:58:53 [INFO]: Epoch 065 - training loss: 0.2634, validation loss: 0.1602
2024-05-25 06:58:53 [INFO]: Epoch 066 - training loss: 0.2633, validation loss: 0.1594
2024-05-25 06:58:54 [INFO]: Epoch 067 - training loss: 0.2615, validation loss: 0.1604
2024-05-25 06:58:54 [INFO]: Epoch 068 - training loss: 0.2595, validation loss: 0.1581
2024-05-25 06:58:55 [INFO]: Epoch 069 - training loss: 0.2583, validation loss: 0.1586
2024-05-25 06:58:56 [INFO]: Epoch 070 - training loss: 0.2581, validation loss: 0.1595
2024-05-25 06:58:56 [INFO]: Epoch 071 - training loss: 0.2566, validation loss: 0.1585
2024-05-25 06:58:57 [INFO]: Epoch 072 - training loss: 0.2556, validation loss: 0.1573
2024-05-25 06:58:57 [INFO]: Epoch 073 - training loss: 0.2538, validation loss: 0.1567
2024-05-25 06:58:58 [INFO]: Epoch 074 - training loss: 0.2527, validation loss: 0.1565
2024-05-25 06:58:59 [INFO]: Epoch 075 - training loss: 0.2523, validation loss: 0.1553
2024-05-25 06:58:59 [INFO]: Epoch 076 - training loss: 0.2514, validation loss: 0.1558
2024-05-25 06:59:00 [INFO]: Epoch 077 - training loss: 0.2511, validation loss: 0.1552
2024-05-25 06:59:00 [INFO]: Epoch 078 - training loss: 0.2494, validation loss: 0.1548
2024-05-25 06:59:01 [INFO]: Epoch 079 - training loss: 0.2500, validation loss: 0.1538
2024-05-25 06:59:02 [INFO]: Epoch 080 - training loss: 0.2478, validation loss: 0.1540
2024-05-25 06:59:02 [INFO]: Epoch 081 - training loss: 0.2462, validation loss: 0.1549
2024-05-25 06:59:03 [INFO]: Epoch 082 - training loss: 0.2464, validation loss: 0.1544
2024-05-25 06:59:03 [INFO]: Epoch 083 - training loss: 0.2462, validation loss: 0.1549
2024-05-25 06:59:04 [INFO]: Epoch 084 - training loss: 0.2449, validation loss: 0.1539
2024-05-25 06:59:05 [INFO]: Epoch 085 - training loss: 0.2447, validation loss: 0.1522
2024-05-25 06:59:05 [INFO]: Epoch 086 - training loss: 0.2430, validation loss: 0.1519
2024-05-25 06:59:06 [INFO]: Epoch 087 - training loss: 0.2424, validation loss: 0.1518
2024-05-25 06:59:06 [INFO]: Epoch 088 - training loss: 0.2415, validation loss: 0.1522
2024-05-25 06:59:07 [INFO]: Epoch 089 - training loss: 0.2406, validation loss: 0.1511
2024-05-25 06:59:08 [INFO]: Epoch 090 - training loss: 0.2401, validation loss: 0.1511
2024-05-25 06:59:08 [INFO]: Epoch 091 - training loss: 0.2405, validation loss: 0.1527
2024-05-25 06:59:09 [INFO]: Epoch 092 - training loss: 0.2403, validation loss: 0.1501
2024-05-25 06:59:09 [INFO]: Epoch 093 - training loss: 0.2379, validation loss: 0.1503
2024-05-25 06:59:10 [INFO]: Epoch 094 - training loss: 0.2372, validation loss: 0.1504
2024-05-25 06:59:11 [INFO]: Epoch 095 - training loss: 0.2367, validation loss: 0.1510
2024-05-25 06:59:11 [INFO]: Epoch 096 - training loss: 0.2360, validation loss: 0.1505
2024-05-25 06:59:12 [INFO]: Epoch 097 - training loss: 0.2370, validation loss: 0.1498
2024-05-25 06:59:12 [INFO]: Epoch 098 - training loss: 0.2354, validation loss: 0.1493
2024-05-25 06:59:13 [INFO]: Epoch 099 - training loss: 0.2353, validation loss: 0.1494
2024-05-25 06:59:14 [INFO]: Epoch 100 - training loss: 0.2341, validation loss: 0.1488
2024-05-25 06:59:14 [INFO]: Epoch 101 - training loss: 0.2332, validation loss: 0.1490
2024-05-25 06:59:15 [INFO]: Epoch 102 - training loss: 0.2321, validation loss: 0.1490
2024-05-25 06:59:15 [INFO]: Epoch 103 - training loss: 0.2315, validation loss: 0.1477
2024-05-25 06:59:16 [INFO]: Epoch 104 - training loss: 0.2311, validation loss: 0.1485
2024-05-25 06:59:17 [INFO]: Epoch 105 - training loss: 0.2307, validation loss: 0.1476
2024-05-25 06:59:17 [INFO]: Epoch 106 - training loss: 0.2301, validation loss: 0.1487
2024-05-25 06:59:18 [INFO]: Epoch 107 - training loss: 0.2288, validation loss: 0.1477
2024-05-25 06:59:18 [INFO]: Epoch 108 - training loss: 0.2283, validation loss: 0.1472
2024-05-25 06:59:19 [INFO]: Epoch 109 - training loss: 0.2276, validation loss: 0.1462
2024-05-25 06:59:20 [INFO]: Epoch 110 - training loss: 0.2282, validation loss: 0.1460
2024-05-25 06:59:20 [INFO]: Epoch 111 - training loss: 0.2271, validation loss: 0.1467
2024-05-25 06:59:21 [INFO]: Epoch 112 - training loss: 0.2260, validation loss: 0.1459
2024-05-25 06:59:21 [INFO]: Epoch 113 - training loss: 0.2263, validation loss: 0.1462
2024-05-25 06:59:22 [INFO]: Epoch 114 - training loss: 0.2266, validation loss: 0.1458
2024-05-25 06:59:23 [INFO]: Epoch 115 - training loss: 0.2262, validation loss: 0.1454
2024-05-25 06:59:23 [INFO]: Epoch 116 - training loss: 0.2251, validation loss: 0.1470
2024-05-25 06:59:24 [INFO]: Epoch 117 - training loss: 0.2247, validation loss: 0.1446
2024-05-25 06:59:24 [INFO]: Epoch 118 - training loss: 0.2224, validation loss: 0.1452
2024-05-25 06:59:25 [INFO]: Epoch 119 - training loss: 0.2217, validation loss: 0.1451
2024-05-25 06:59:26 [INFO]: Epoch 120 - training loss: 0.2213, validation loss: 0.1456
2024-05-25 06:59:26 [INFO]: Epoch 121 - training loss: 0.2207, validation loss: 0.1455
2024-05-25 06:59:27 [INFO]: Epoch 122 - training loss: 0.2202, validation loss: 0.1439
2024-05-25 06:59:27 [INFO]: Epoch 123 - training loss: 0.2198, validation loss: 0.1448
2024-05-25 06:59:28 [INFO]: Epoch 124 - training loss: 0.2200, validation loss: 0.1445
2024-05-25 06:59:29 [INFO]: Epoch 125 - training loss: 0.2194, validation loss: 0.1440
2024-05-25 06:59:29 [INFO]: Epoch 126 - training loss: 0.2188, validation loss: 0.1435
2024-05-25 06:59:30 [INFO]: Epoch 127 - training loss: 0.2180, validation loss: 0.1439
2024-05-25 06:59:30 [INFO]: Epoch 128 - training loss: 0.2173, validation loss: 0.1432
2024-05-25 06:59:31 [INFO]: Epoch 129 - training loss: 0.2163, validation loss: 0.1433
2024-05-25 06:59:32 [INFO]: Epoch 130 - training loss: 0.2176, validation loss: 0.1438
2024-05-25 06:59:32 [INFO]: Epoch 131 - training loss: 0.2166, validation loss: 0.1436
2024-05-25 06:59:33 [INFO]: Epoch 132 - training loss: 0.2161, validation loss: 0.1428
2024-05-25 06:59:33 [INFO]: Epoch 133 - training loss: 0.2152, validation loss: 0.1430
2024-05-25 06:59:34 [INFO]: Epoch 134 - training loss: 0.2171, validation loss: 0.1434
2024-05-25 06:59:35 [INFO]: Epoch 135 - training loss: 0.2159, validation loss: 0.1431
2024-05-25 06:59:35 [INFO]: Epoch 136 - training loss: 0.2146, validation loss: 0.1424
2024-05-25 06:59:36 [INFO]: Epoch 137 - training loss: 0.2145, validation loss: 0.1430
2024-05-25 06:59:36 [INFO]: Epoch 138 - training loss: 0.2135, validation loss: 0.1433
2024-05-25 06:59:37 [INFO]: Epoch 139 - training loss: 0.2123, validation loss: 0.1423
2024-05-25 06:59:38 [INFO]: Epoch 140 - training loss: 0.2117, validation loss: 0.1426
2024-05-25 06:59:38 [INFO]: Epoch 141 - training loss: 0.2120, validation loss: 0.1428
2024-05-25 06:59:39 [INFO]: Epoch 142 - training loss: 0.2116, validation loss: 0.1428
2024-05-25 06:59:40 [INFO]: Epoch 143 - training loss: 0.2105, validation loss: 0.1428
2024-05-25 06:59:40 [INFO]: Epoch 144 - training loss: 0.2107, validation loss: 0.1420
2024-05-25 06:59:41 [INFO]: Epoch 145 - training loss: 0.2101, validation loss: 0.1427
2024-05-25 06:59:41 [INFO]: Epoch 146 - training loss: 0.2092, validation loss: 0.1410
2024-05-25 06:59:42 [INFO]: Epoch 147 - training loss: 0.2092, validation loss: 0.1406
2024-05-25 06:59:43 [INFO]: Epoch 148 - training loss: 0.2102, validation loss: 0.1404
2024-05-25 06:59:43 [INFO]: Epoch 149 - training loss: 0.2088, validation loss: 0.1420
2024-05-25 06:59:44 [INFO]: Epoch 150 - training loss: 0.2080, validation loss: 0.1413
2024-05-25 06:59:44 [INFO]: Epoch 151 - training loss: 0.2082, validation loss: 0.1406
2024-05-25 06:59:45 [INFO]: Epoch 152 - training loss: 0.2100, validation loss: 0.1422
2024-05-25 06:59:46 [INFO]: Epoch 153 - training loss: 0.2077, validation loss: 0.1407
2024-05-25 06:59:46 [INFO]: Epoch 154 - training loss: 0.2080, validation loss: 0.1418
2024-05-25 06:59:47 [INFO]: Epoch 155 - training loss: 0.2085, validation loss: 0.1436
2024-05-25 06:59:47 [INFO]: Epoch 156 - training loss: 0.2089, validation loss: 0.1421
2024-05-25 06:59:48 [INFO]: Epoch 157 - training loss: 0.2057, validation loss: 0.1412
2024-05-25 06:59:49 [INFO]: Epoch 158 - training loss: 0.2048, validation loss: 0.1418
2024-05-25 06:59:49 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 06:59:49 [INFO]: Finished training. The best model is from epoch#148.
2024-05-25 06:59:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_air_quality/20240525_T065813/SAITS.pypots
2024-05-25 06:59:49 [INFO]: SAITS on Air-Quality: MAE=0.1625, MSE=0.1478
2024-05-25 06:59:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_air_quality/imputation.pkl
2024-05-25 06:59:49 [INFO]: Using the given device: cuda:0
2024-05-25 06:59:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T065949
2024-05-25 06:59:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T065949/tensorboard
2024-05-25 06:59:49 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 13,001,860
2024-05-25 06:59:49 [INFO]: Epoch 001 - training loss: 0.9079, validation loss: 0.4971
2024-05-25 06:59:49 [INFO]: Epoch 002 - training loss: 0.5743, validation loss: 0.3750
2024-05-25 06:59:50 [INFO]: Epoch 003 - training loss: 0.4865, validation loss: 0.3168
2024-05-25 06:59:50 [INFO]: Epoch 004 - training loss: 0.4359, validation loss: 0.2897
2024-05-25 06:59:50 [INFO]: Epoch 005 - training loss: 0.4096, validation loss: 0.2711
2024-05-25 06:59:50 [INFO]: Epoch 006 - training loss: 0.3903, validation loss: 0.2606
2024-05-25 06:59:51 [INFO]: Epoch 007 - training loss: 0.3784, validation loss: 0.2550
2024-05-25 06:59:51 [INFO]: Epoch 008 - training loss: 0.3636, validation loss: 0.2500
2024-05-25 06:59:51 [INFO]: Epoch 009 - training loss: 0.3530, validation loss: 0.2413
2024-05-25 06:59:51 [INFO]: Epoch 010 - training loss: 0.3431, validation loss: 0.2362
2024-05-25 06:59:52 [INFO]: Epoch 011 - training loss: 0.3360, validation loss: 0.2341
2024-05-25 06:59:52 [INFO]: Epoch 012 - training loss: 0.3314, validation loss: 0.2281
2024-05-25 06:59:52 [INFO]: Epoch 013 - training loss: 0.3298, validation loss: 0.2252
2024-05-25 06:59:52 [INFO]: Epoch 014 - training loss: 0.3239, validation loss: 0.2215
2024-05-25 06:59:53 [INFO]: Epoch 015 - training loss: 0.3171, validation loss: 0.2163
2024-05-25 06:59:53 [INFO]: Epoch 016 - training loss: 0.3131, validation loss: 0.2167
2024-05-25 06:59:53 [INFO]: Epoch 017 - training loss: 0.3100, validation loss: 0.2122
2024-05-25 06:59:53 [INFO]: Epoch 018 - training loss: 0.3059, validation loss: 0.2087
2024-05-25 06:59:54 [INFO]: Epoch 019 - training loss: 0.3007, validation loss: 0.2083
2024-05-25 06:59:54 [INFO]: Epoch 020 - training loss: 0.3035, validation loss: 0.2052
2024-05-25 06:59:54 [INFO]: Epoch 021 - training loss: 0.2976, validation loss: 0.2039
2024-05-25 06:59:54 [INFO]: Epoch 022 - training loss: 0.2937, validation loss: 0.2031
2024-05-25 06:59:55 [INFO]: Epoch 023 - training loss: 0.2910, validation loss: 0.1996
2024-05-25 06:59:55 [INFO]: Epoch 024 - training loss: 0.2893, validation loss: 0.2014
2024-05-25 06:59:55 [INFO]: Epoch 025 - training loss: 0.2853, validation loss: 0.1966
2024-05-25 06:59:55 [INFO]: Epoch 026 - training loss: 0.2824, validation loss: 0.1974
2024-05-25 06:59:56 [INFO]: Epoch 027 - training loss: 0.2814, validation loss: 0.1962
2024-05-25 06:59:56 [INFO]: Epoch 028 - training loss: 0.2800, validation loss: 0.1942
2024-05-25 06:59:56 [INFO]: Epoch 029 - training loss: 0.2773, validation loss: 0.1939
2024-05-25 06:59:56 [INFO]: Epoch 030 - training loss: 0.2765, validation loss: 0.1919
2024-05-25 06:59:57 [INFO]: Epoch 031 - training loss: 0.2728, validation loss: 0.1934
2024-05-25 06:59:57 [INFO]: Epoch 032 - training loss: 0.2725, validation loss: 0.1929
2024-05-25 06:59:57 [INFO]: Epoch 033 - training loss: 0.2696, validation loss: 0.1897
2024-05-25 06:59:57 [INFO]: Epoch 034 - training loss: 0.2678, validation loss: 0.1924
2024-05-25 06:59:58 [INFO]: Epoch 035 - training loss: 0.2670, validation loss: 0.1915
2024-05-25 06:59:58 [INFO]: Epoch 036 - training loss: 0.2635, validation loss: 0.1893
2024-05-25 06:59:58 [INFO]: Epoch 037 - training loss: 0.2645, validation loss: 0.1877
2024-05-25 06:59:58 [INFO]: Epoch 038 - training loss: 0.2627, validation loss: 0.1900
2024-05-25 06:59:59 [INFO]: Epoch 039 - training loss: 0.2600, validation loss: 0.1882
2024-05-25 06:59:59 [INFO]: Epoch 040 - training loss: 0.2593, validation loss: 0.1894
2024-05-25 06:59:59 [INFO]: Epoch 041 - training loss: 0.2598, validation loss: 0.1871
2024-05-25 06:59:59 [INFO]: Epoch 042 - training loss: 0.2542, validation loss: 0.1878
2024-05-25 07:00:00 [INFO]: Epoch 043 - training loss: 0.2521, validation loss: 0.1841
2024-05-25 07:00:00 [INFO]: Epoch 044 - training loss: 0.2516, validation loss: 0.1857
2024-05-25 07:00:00 [INFO]: Epoch 045 - training loss: 0.2512, validation loss: 0.1840
2024-05-25 07:00:00 [INFO]: Epoch 046 - training loss: 0.2487, validation loss: 0.1870
2024-05-25 07:00:01 [INFO]: Epoch 047 - training loss: 0.2496, validation loss: 0.1867
2024-05-25 07:00:01 [INFO]: Epoch 048 - training loss: 0.2522, validation loss: 0.1841
2024-05-25 07:00:01 [INFO]: Epoch 049 - training loss: 0.2460, validation loss: 0.1826
2024-05-25 07:00:01 [INFO]: Epoch 050 - training loss: 0.2436, validation loss: 0.1838
2024-05-25 07:00:02 [INFO]: Epoch 051 - training loss: 0.2443, validation loss: 0.1837
2024-05-25 07:00:02 [INFO]: Epoch 052 - training loss: 0.2450, validation loss: 0.1838
2024-05-25 07:00:02 [INFO]: Epoch 053 - training loss: 0.2447, validation loss: 0.1810
2024-05-25 07:00:02 [INFO]: Epoch 054 - training loss: 0.2410, validation loss: 0.1823
2024-05-25 07:00:03 [INFO]: Epoch 055 - training loss: 0.2393, validation loss: 0.1806
2024-05-25 07:00:03 [INFO]: Epoch 056 - training loss: 0.2371, validation loss: 0.1802
2024-05-25 07:00:03 [INFO]: Epoch 057 - training loss: 0.2375, validation loss: 0.1808
2024-05-25 07:00:03 [INFO]: Epoch 058 - training loss: 0.2372, validation loss: 0.1795
2024-05-25 07:00:04 [INFO]: Epoch 059 - training loss: 0.2354, validation loss: 0.1788
2024-05-25 07:00:04 [INFO]: Epoch 060 - training loss: 0.2342, validation loss: 0.1815
2024-05-25 07:00:04 [INFO]: Epoch 061 - training loss: 0.2335, validation loss: 0.1833
2024-05-25 07:00:04 [INFO]: Epoch 062 - training loss: 0.2323, validation loss: 0.1809
2024-05-25 07:00:05 [INFO]: Epoch 063 - training loss: 0.2308, validation loss: 0.1810
2024-05-25 07:00:05 [INFO]: Epoch 064 - training loss: 0.2304, validation loss: 0.1797
2024-05-25 07:00:05 [INFO]: Epoch 065 - training loss: 0.2284, validation loss: 0.1784
2024-05-25 07:00:05 [INFO]: Epoch 066 - training loss: 0.2262, validation loss: 0.1761
2024-05-25 07:00:06 [INFO]: Epoch 067 - training loss: 0.2282, validation loss: 0.1772
2024-05-25 07:00:06 [INFO]: Epoch 068 - training loss: 0.2276, validation loss: 0.1767
2024-05-25 07:00:06 [INFO]: Epoch 069 - training loss: 0.2243, validation loss: 0.1771
2024-05-25 07:00:06 [INFO]: Epoch 070 - training loss: 0.2225, validation loss: 0.1754
2024-05-25 07:00:07 [INFO]: Epoch 071 - training loss: 0.2208, validation loss: 0.1760
2024-05-25 07:00:07 [INFO]: Epoch 072 - training loss: 0.2221, validation loss: 0.1755
2024-05-25 07:00:07 [INFO]: Epoch 073 - training loss: 0.2234, validation loss: 0.1791
2024-05-25 07:00:07 [INFO]: Epoch 074 - training loss: 0.2237, validation loss: 0.1763
2024-05-25 07:00:08 [INFO]: Epoch 075 - training loss: 0.2204, validation loss: 0.1772
2024-05-25 07:00:08 [INFO]: Epoch 076 - training loss: 0.2191, validation loss: 0.1759
2024-05-25 07:00:08 [INFO]: Epoch 077 - training loss: 0.2179, validation loss: 0.1748
2024-05-25 07:00:08 [INFO]: Epoch 078 - training loss: 0.2165, validation loss: 0.1734
2024-05-25 07:00:09 [INFO]: Epoch 079 - training loss: 0.2157, validation loss: 0.1754
2024-05-25 07:00:09 [INFO]: Epoch 080 - training loss: 0.2149, validation loss: 0.1753
2024-05-25 07:00:09 [INFO]: Epoch 081 - training loss: 0.2127, validation loss: 0.1735
2024-05-25 07:00:09 [INFO]: Epoch 082 - training loss: 0.2110, validation loss: 0.1779
2024-05-25 07:00:10 [INFO]: Epoch 083 - training loss: 0.2120, validation loss: 0.1719
2024-05-25 07:00:10 [INFO]: Epoch 084 - training loss: 0.2104, validation loss: 0.1724
2024-05-25 07:00:10 [INFO]: Epoch 085 - training loss: 0.2138, validation loss: 0.1740
2024-05-25 07:00:10 [INFO]: Epoch 086 - training loss: 0.2122, validation loss: 0.1734
2024-05-25 07:00:11 [INFO]: Epoch 087 - training loss: 0.2106, validation loss: 0.1751
2024-05-25 07:00:11 [INFO]: Epoch 088 - training loss: 0.2101, validation loss: 0.1745
2024-05-25 07:00:11 [INFO]: Epoch 089 - training loss: 0.2071, validation loss: 0.1729
2024-05-25 07:00:11 [INFO]: Epoch 090 - training loss: 0.2067, validation loss: 0.1732
2024-05-25 07:00:12 [INFO]: Epoch 091 - training loss: 0.2054, validation loss: 0.1718
2024-05-25 07:00:12 [INFO]: Epoch 092 - training loss: 0.2047, validation loss: 0.1730
2024-05-25 07:00:12 [INFO]: Epoch 093 - training loss: 0.2062, validation loss: 0.1719
2024-05-25 07:00:12 [INFO]: Epoch 094 - training loss: 0.2026, validation loss: 0.1717
2024-05-25 07:00:13 [INFO]: Epoch 095 - training loss: 0.2024, validation loss: 0.1717
2024-05-25 07:00:13 [INFO]: Epoch 096 - training loss: 0.2028, validation loss: 0.1709
2024-05-25 07:00:13 [INFO]: Epoch 097 - training loss: 0.2024, validation loss: 0.1701
2024-05-25 07:00:13 [INFO]: Epoch 098 - training loss: 0.2035, validation loss: 0.1711
2024-05-25 07:00:14 [INFO]: Epoch 099 - training loss: 0.2049, validation loss: 0.1716
2024-05-25 07:00:14 [INFO]: Epoch 100 - training loss: 0.2022, validation loss: 0.1697
2024-05-25 07:00:14 [INFO]: Epoch 101 - training loss: 0.2017, validation loss: 0.1711
2024-05-25 07:00:14 [INFO]: Epoch 102 - training loss: 0.1996, validation loss: 0.1709
2024-05-25 07:00:15 [INFO]: Epoch 103 - training loss: 0.1965, validation loss: 0.1694
2024-05-25 07:00:15 [INFO]: Epoch 104 - training loss: 0.1955, validation loss: 0.1701
2024-05-25 07:00:15 [INFO]: Epoch 105 - training loss: 0.1945, validation loss: 0.1717
2024-05-25 07:00:15 [INFO]: Epoch 106 - training loss: 0.1939, validation loss: 0.1691
2024-05-25 07:00:16 [INFO]: Epoch 107 - training loss: 0.1929, validation loss: 0.1692
2024-05-25 07:00:16 [INFO]: Epoch 108 - training loss: 0.1922, validation loss: 0.1705
2024-05-25 07:00:16 [INFO]: Epoch 109 - training loss: 0.1923, validation loss: 0.1694
2024-05-25 07:00:16 [INFO]: Epoch 110 - training loss: 0.1920, validation loss: 0.1700
2024-05-25 07:00:17 [INFO]: Epoch 111 - training loss: 0.1920, validation loss: 0.1684
2024-05-25 07:00:17 [INFO]: Epoch 112 - training loss: 0.1972, validation loss: 0.1697
2024-05-25 07:00:17 [INFO]: Epoch 113 - training loss: 0.1951, validation loss: 0.1696
2024-05-25 07:00:17 [INFO]: Epoch 114 - training loss: 0.1931, validation loss: 0.1689
2024-05-25 07:00:18 [INFO]: Epoch 115 - training loss: 0.1932, validation loss: 0.1692
2024-05-25 07:00:18 [INFO]: Epoch 116 - training loss: 0.1907, validation loss: 0.1704
2024-05-25 07:00:18 [INFO]: Epoch 117 - training loss: 0.1883, validation loss: 0.1679
2024-05-25 07:00:18 [INFO]: Epoch 118 - training loss: 0.1861, validation loss: 0.1693
2024-05-25 07:00:19 [INFO]: Epoch 119 - training loss: 0.1875, validation loss: 0.1684
2024-05-25 07:00:19 [INFO]: Epoch 120 - training loss: 0.1869, validation loss: 0.1682
2024-05-25 07:00:19 [INFO]: Epoch 121 - training loss: 0.1846, validation loss: 0.1678
2024-05-25 07:00:19 [INFO]: Epoch 122 - training loss: 0.1832, validation loss: 0.1702
2024-05-25 07:00:20 [INFO]: Epoch 123 - training loss: 0.1861, validation loss: 0.1685
2024-05-25 07:00:20 [INFO]: Epoch 124 - training loss: 0.1861, validation loss: 0.1689
2024-05-25 07:00:20 [INFO]: Epoch 125 - training loss: 0.1854, validation loss: 0.1675
2024-05-25 07:00:20 [INFO]: Epoch 126 - training loss: 0.1833, validation loss: 0.1698
2024-05-25 07:00:21 [INFO]: Epoch 127 - training loss: 0.1829, validation loss: 0.1665
2024-05-25 07:00:21 [INFO]: Epoch 128 - training loss: 0.1867, validation loss: 0.1675
2024-05-25 07:00:21 [INFO]: Epoch 129 - training loss: 0.1847, validation loss: 0.1671
2024-05-25 07:00:21 [INFO]: Epoch 130 - training loss: 0.1814, validation loss: 0.1668
2024-05-25 07:00:22 [INFO]: Epoch 131 - training loss: 0.1806, validation loss: 0.1671
2024-05-25 07:00:22 [INFO]: Epoch 132 - training loss: 0.1804, validation loss: 0.1679
2024-05-25 07:00:22 [INFO]: Epoch 133 - training loss: 0.1805, validation loss: 0.1665
2024-05-25 07:00:23 [INFO]: Epoch 134 - training loss: 0.1803, validation loss: 0.1664
2024-05-25 07:00:23 [INFO]: Epoch 135 - training loss: 0.1783, validation loss: 0.1681
2024-05-25 07:00:23 [INFO]: Epoch 136 - training loss: 0.1765, validation loss: 0.1665
2024-05-25 07:00:23 [INFO]: Epoch 137 - training loss: 0.1753, validation loss: 0.1658
2024-05-25 07:00:24 [INFO]: Epoch 138 - training loss: 0.1748, validation loss: 0.1655
2024-05-25 07:00:24 [INFO]: Epoch 139 - training loss: 0.1762, validation loss: 0.1657
2024-05-25 07:00:24 [INFO]: Epoch 140 - training loss: 0.1823, validation loss: 0.1654
2024-05-25 07:00:24 [INFO]: Epoch 141 - training loss: 0.1795, validation loss: 0.1665
2024-05-25 07:00:25 [INFO]: Epoch 142 - training loss: 0.1765, validation loss: 0.1651
2024-05-25 07:00:25 [INFO]: Epoch 143 - training loss: 0.1761, validation loss: 0.1660
2024-05-25 07:00:25 [INFO]: Epoch 144 - training loss: 0.1761, validation loss: 0.1646
2024-05-25 07:00:25 [INFO]: Epoch 145 - training loss: 0.1734, validation loss: 0.1659
2024-05-25 07:00:26 [INFO]: Epoch 146 - training loss: 0.1716, validation loss: 0.1653
2024-05-25 07:00:26 [INFO]: Epoch 147 - training loss: 0.1717, validation loss: 0.1652
2024-05-25 07:00:26 [INFO]: Epoch 148 - training loss: 0.1749, validation loss: 0.1673
2024-05-25 07:00:26 [INFO]: Epoch 149 - training loss: 0.1732, validation loss: 0.1660
2024-05-25 07:00:27 [INFO]: Epoch 150 - training loss: 0.1704, validation loss: 0.1653
2024-05-25 07:00:27 [INFO]: Epoch 151 - training loss: 0.1711, validation loss: 0.1646
2024-05-25 07:00:27 [INFO]: Epoch 152 - training loss: 0.1688, validation loss: 0.1655
2024-05-25 07:00:27 [INFO]: Epoch 153 - training loss: 0.1709, validation loss: 0.1655
2024-05-25 07:00:28 [INFO]: Epoch 154 - training loss: 0.1704, validation loss: 0.1649
2024-05-25 07:00:28 [INFO]: Epoch 155 - training loss: 0.1695, validation loss: 0.1650
2024-05-25 07:00:28 [INFO]: Epoch 156 - training loss: 0.1679, validation loss: 0.1641
2024-05-25 07:00:28 [INFO]: Epoch 157 - training loss: 0.1676, validation loss: 0.1654
2024-05-25 07:00:29 [INFO]: Epoch 158 - training loss: 0.1700, validation loss: 0.1681
2024-05-25 07:00:29 [INFO]: Epoch 159 - training loss: 0.1707, validation loss: 0.1640
2024-05-25 07:00:29 [INFO]: Epoch 160 - training loss: 0.1674, validation loss: 0.1648
2024-05-25 07:00:29 [INFO]: Epoch 161 - training loss: 0.1675, validation loss: 0.1643
2024-05-25 07:00:30 [INFO]: Epoch 162 - training loss: 0.1660, validation loss: 0.1643
2024-05-25 07:00:30 [INFO]: Epoch 163 - training loss: 0.1678, validation loss: 0.1656
2024-05-25 07:00:30 [INFO]: Epoch 164 - training loss: 0.1643, validation loss: 0.1639
2024-05-25 07:00:30 [INFO]: Epoch 165 - training loss: 0.1632, validation loss: 0.1630
2024-05-25 07:00:31 [INFO]: Epoch 166 - training loss: 0.1657, validation loss: 0.1645
2024-05-25 07:00:31 [INFO]: Epoch 167 - training loss: 0.1654, validation loss: 0.1648
2024-05-25 07:00:31 [INFO]: Epoch 168 - training loss: 0.1644, validation loss: 0.1656
2024-05-25 07:00:31 [INFO]: Epoch 169 - training loss: 0.1619, validation loss: 0.1650
2024-05-25 07:00:32 [INFO]: Epoch 170 - training loss: 0.1620, validation loss: 0.1643
2024-05-25 07:00:32 [INFO]: Epoch 171 - training loss: 0.1624, validation loss: 0.1639
2024-05-25 07:00:32 [INFO]: Epoch 172 - training loss: 0.1615, validation loss: 0.1648
2024-05-25 07:00:32 [INFO]: Epoch 173 - training loss: 0.1603, validation loss: 0.1652
2024-05-25 07:00:33 [INFO]: Epoch 174 - training loss: 0.1613, validation loss: 0.1641
2024-05-25 07:00:33 [INFO]: Epoch 175 - training loss: 0.1598, validation loss: 0.1641
2024-05-25 07:00:33 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:00:33 [INFO]: Finished training. The best model is from epoch#165.
2024-05-25 07:00:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_air_quality/20240525_T065949/Transformer.pypots
2024-05-25 07:00:33 [INFO]: Transformer on Air-Quality: MAE=0.1797, MSE=0.1661
2024-05-25 07:00:33 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_air_quality/imputation.pkl
2024-05-25 07:00:33 [INFO]: Using the given device: cuda:0
2024-05-25 07:00:33 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T070033
2024-05-25 07:00:33 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T070033/tensorboard
2024-05-25 07:00:33 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 44,316,804
2024-05-25 07:00:34 [INFO]: Epoch 001 - training loss: 0.2975, validation loss: 0.2891
2024-05-25 07:00:34 [INFO]: Epoch 002 - training loss: 0.2159, validation loss: 0.2482
2024-05-25 07:00:35 [INFO]: Epoch 003 - training loss: 0.1835, validation loss: 0.2243
2024-05-25 07:00:35 [INFO]: Epoch 004 - training loss: 0.1598, validation loss: 0.2159
2024-05-25 07:00:36 [INFO]: Epoch 005 - training loss: 0.1573, validation loss: 0.2218
2024-05-25 07:00:36 [INFO]: Epoch 006 - training loss: 0.1493, validation loss: 0.2053
2024-05-25 07:00:37 [INFO]: Epoch 007 - training loss: 0.1550, validation loss: 0.2040
2024-05-25 07:00:37 [INFO]: Epoch 008 - training loss: 0.1410, validation loss: 0.2024
2024-05-25 07:00:37 [INFO]: Epoch 009 - training loss: 0.1255, validation loss: 0.1964
2024-05-25 07:00:38 [INFO]: Epoch 010 - training loss: 0.1196, validation loss: 0.1940
2024-05-25 07:00:38 [INFO]: Epoch 011 - training loss: 0.1127, validation loss: 0.1992
2024-05-25 07:00:39 [INFO]: Epoch 012 - training loss: 0.1097, validation loss: 0.1986
2024-05-25 07:00:39 [INFO]: Epoch 013 - training loss: 0.1097, validation loss: 0.1962
2024-05-25 07:00:40 [INFO]: Epoch 014 - training loss: 0.1082, validation loss: 0.1931
2024-05-25 07:00:40 [INFO]: Epoch 015 - training loss: 0.1044, validation loss: 0.1963
2024-05-25 07:00:41 [INFO]: Epoch 016 - training loss: 0.1017, validation loss: 0.1960
2024-05-25 07:00:41 [INFO]: Epoch 017 - training loss: 0.0977, validation loss: 0.2100
2024-05-25 07:00:42 [INFO]: Epoch 018 - training loss: 0.0956, validation loss: 0.1938
2024-05-25 07:00:42 [INFO]: Epoch 019 - training loss: 0.0961, validation loss: 0.1989
2024-05-25 07:00:42 [INFO]: Epoch 020 - training loss: 0.0940, validation loss: 0.2055
2024-05-25 07:00:43 [INFO]: Epoch 021 - training loss: 0.0916, validation loss: 0.2030
2024-05-25 07:00:43 [INFO]: Epoch 022 - training loss: 0.0889, validation loss: 0.2034
2024-05-25 07:00:44 [INFO]: Epoch 023 - training loss: 0.0883, validation loss: 0.2102
2024-05-25 07:00:44 [INFO]: Epoch 024 - training loss: 0.0875, validation loss: 0.2058
2024-05-25 07:00:44 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:00:44 [INFO]: Finished training. The best model is from epoch#14.
2024-05-25 07:00:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_air_quality/20240525_T070033/TimesNet.pypots
2024-05-25 07:00:45 [INFO]: TimesNet on Air-Quality: MAE=0.1726, MSE=0.2173
2024-05-25 07:00:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_air_quality/imputation.pkl
2024-05-25 07:00:45 [INFO]: Using the given device: cuda:0
2024-05-25 07:00:45 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045
2024-05-25 07:00:45 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/tensorboard
2024-05-25 07:00:45 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 290,049
2024-05-25 07:01:01 [INFO]: Epoch 001 - training loss: 0.4927, validation loss: 0.3282
2024-05-25 07:01:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch1_loss0.3281588852405548.pypots
2024-05-25 07:01:18 [INFO]: Epoch 002 - training loss: 0.2964, validation loss: 0.2589
2024-05-25 07:01:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch2_loss0.258877632021904.pypots
2024-05-25 07:01:35 [INFO]: Epoch 003 - training loss: 0.2547, validation loss: 0.2248
2024-05-25 07:01:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch3_loss0.2247504025697708.pypots
2024-05-25 07:01:51 [INFO]: Epoch 004 - training loss: 0.2055, validation loss: 0.1971
2024-05-25 07:01:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch4_loss0.1971183866262436.pypots
2024-05-25 07:02:08 [INFO]: Epoch 005 - training loss: 0.2005, validation loss: 0.2010
2024-05-25 07:02:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch5_loss0.20102064311504364.pypots
2024-05-25 07:02:25 [INFO]: Epoch 006 - training loss: 0.1900, validation loss: 0.1640
2024-05-25 07:02:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch6_loss0.16403553932905196.pypots
2024-05-25 07:02:41 [INFO]: Epoch 007 - training loss: 0.1692, validation loss: 0.1612
2024-05-25 07:02:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch7_loss0.16118284016847612.pypots
2024-05-25 07:02:58 [INFO]: Epoch 008 - training loss: 0.1648, validation loss: 0.1598
2024-05-25 07:02:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch8_loss0.1598047435283661.pypots
2024-05-25 07:03:15 [INFO]: Epoch 009 - training loss: 0.1565, validation loss: 0.1519
2024-05-25 07:03:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch9_loss0.15194927304983138.pypots
2024-05-25 07:03:31 [INFO]: Epoch 010 - training loss: 0.1519, validation loss: 0.1493
2024-05-25 07:03:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch10_loss0.14928330034017562.pypots
2024-05-25 07:03:48 [INFO]: Epoch 011 - training loss: 0.1548, validation loss: 0.1447
2024-05-25 07:03:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch11_loss0.1447155296802521.pypots
2024-05-25 07:04:05 [INFO]: Epoch 012 - training loss: 0.1400, validation loss: 0.1414
2024-05-25 07:04:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch12_loss0.14142110496759414.pypots
2024-05-25 07:04:21 [INFO]: Epoch 013 - training loss: 0.1503, validation loss: 0.1416
2024-05-25 07:04:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch13_loss0.14164985492825508.pypots
2024-05-25 07:04:38 [INFO]: Epoch 014 - training loss: 0.1687, validation loss: 0.1490
2024-05-25 07:04:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch14_loss0.14903160482645034.pypots
2024-05-25 07:04:55 [INFO]: Epoch 015 - training loss: 0.1553, validation loss: 0.1392
2024-05-25 07:04:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch15_loss0.1391712687909603.pypots
2024-05-25 07:05:11 [INFO]: Epoch 016 - training loss: 0.1423, validation loss: 0.1359
2024-05-25 07:05:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch16_loss0.13591307923197746.pypots
2024-05-25 07:05:28 [INFO]: Epoch 017 - training loss: 0.1444, validation loss: 0.1369
2024-05-25 07:05:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch17_loss0.13691140785813333.pypots
2024-05-25 07:05:45 [INFO]: Epoch 018 - training loss: 0.1468, validation loss: 0.1335
2024-05-25 07:05:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch18_loss0.13349579647183418.pypots
2024-05-25 07:06:01 [INFO]: Epoch 019 - training loss: 0.1301, validation loss: 0.1357
2024-05-25 07:06:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch19_loss0.13569153994321823.pypots
2024-05-25 07:06:18 [INFO]: Epoch 020 - training loss: 0.1221, validation loss: 0.1316
2024-05-25 07:06:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch20_loss0.13163041472434997.pypots
2024-05-25 07:06:35 [INFO]: Epoch 021 - training loss: 0.1361, validation loss: 0.1358
2024-05-25 07:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch21_loss0.13577525764703752.pypots
2024-05-25 07:06:52 [INFO]: Epoch 022 - training loss: 0.1384, validation loss: 0.1285
2024-05-25 07:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch22_loss0.128499061614275.pypots
2024-05-25 07:07:08 [INFO]: Epoch 023 - training loss: 0.1218, validation loss: 0.1334
2024-05-25 07:07:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch23_loss0.13337003514170648.pypots
2024-05-25 07:07:25 [INFO]: Epoch 024 - training loss: 0.1249, validation loss: 0.1306
2024-05-25 07:07:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch24_loss0.13062190786004066.pypots
2024-05-25 07:07:42 [INFO]: Epoch 025 - training loss: 0.1357, validation loss: 0.1285
2024-05-25 07:07:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch25_loss0.12848564013838767.pypots
2024-05-25 07:07:58 [INFO]: Epoch 026 - training loss: 0.1266, validation loss: 0.1277
2024-05-25 07:07:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch26_loss0.12767383083701134.pypots
2024-05-25 07:08:15 [INFO]: Epoch 027 - training loss: 0.1449, validation loss: 0.1290
2024-05-25 07:08:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch27_loss0.12902092188596725.pypots
2024-05-25 07:08:32 [INFO]: Epoch 028 - training loss: 0.1204, validation loss: 0.1291
2024-05-25 07:08:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch28_loss0.12906668782234193.pypots
2024-05-25 07:08:48 [INFO]: Epoch 029 - training loss: 0.1345, validation loss: 0.1358
2024-05-25 07:08:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch29_loss0.13581346198916436.pypots
2024-05-25 07:09:05 [INFO]: Epoch 030 - training loss: 0.1187, validation loss: 0.1258
2024-05-25 07:09:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch30_loss0.1258364237844944.pypots
2024-05-25 07:09:22 [INFO]: Epoch 031 - training loss: 0.1227, validation loss: 0.1241
2024-05-25 07:09:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch31_loss0.12406841591000557.pypots
2024-05-25 07:09:38 [INFO]: Epoch 032 - training loss: 0.1253, validation loss: 0.1249
2024-05-25 07:09:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch32_loss0.12490248084068298.pypots
2024-05-25 07:09:55 [INFO]: Epoch 033 - training loss: 0.1110, validation loss: 0.1221
2024-05-25 07:09:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch33_loss0.12207688614726067.pypots
2024-05-25 07:10:12 [INFO]: Epoch 034 - training loss: 0.1247, validation loss: 0.1261
2024-05-25 07:10:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch34_loss0.1260859675705433.pypots
2024-05-25 07:10:28 [INFO]: Epoch 035 - training loss: 0.1295, validation loss: 0.1227
2024-05-25 07:10:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch35_loss0.12272242829203606.pypots
2024-05-25 07:10:45 [INFO]: Epoch 036 - training loss: 0.1150, validation loss: 0.1217
2024-05-25 07:10:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch36_loss0.12167543917894363.pypots
2024-05-25 07:11:02 [INFO]: Epoch 037 - training loss: 0.1067, validation loss: 0.1217
2024-05-25 07:11:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch37_loss0.12169632315635681.pypots
2024-05-25 07:11:18 [INFO]: Epoch 038 - training loss: 0.1217, validation loss: 0.1214
2024-05-25 07:11:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch38_loss0.12139454931020736.pypots
2024-05-25 07:11:35 [INFO]: Epoch 039 - training loss: 0.1255, validation loss: 0.1208
2024-05-25 07:11:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch39_loss0.120840273052454.pypots
2024-05-25 07:11:52 [INFO]: Epoch 040 - training loss: 0.1190, validation loss: 0.1192
2024-05-25 07:11:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch40_loss0.11922515258193016.pypots
2024-05-25 07:12:08 [INFO]: Epoch 041 - training loss: 0.1338, validation loss: 0.1178
2024-05-25 07:12:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch41_loss0.11780963391065598.pypots
2024-05-25 07:12:25 [INFO]: Epoch 042 - training loss: 0.1198, validation loss: 0.1173
2024-05-25 07:12:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch42_loss0.11730839014053344.pypots
2024-05-25 07:12:42 [INFO]: Epoch 043 - training loss: 0.1315, validation loss: 0.1179
2024-05-25 07:12:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch43_loss0.11786066591739655.pypots
2024-05-25 07:12:58 [INFO]: Epoch 044 - training loss: 0.1039, validation loss: 0.1173
2024-05-25 07:12:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch44_loss0.11733885183930397.pypots
2024-05-25 07:13:15 [INFO]: Epoch 045 - training loss: 0.1114, validation loss: 0.1149
2024-05-25 07:13:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch45_loss0.11486145332455636.pypots
2024-05-25 07:13:32 [INFO]: Epoch 046 - training loss: 0.1151, validation loss: 0.1138
2024-05-25 07:13:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch46_loss0.11375872492790222.pypots
2024-05-25 07:13:49 [INFO]: Epoch 047 - training loss: 0.1145, validation loss: 0.1142
2024-05-25 07:13:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch47_loss0.11421026960015297.pypots
2024-05-25 07:14:05 [INFO]: Epoch 048 - training loss: 0.1137, validation loss: 0.1166
2024-05-25 07:14:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch48_loss0.11663493290543556.pypots
2024-05-25 07:14:22 [INFO]: Epoch 049 - training loss: 0.0995, validation loss: 0.1140
2024-05-25 07:14:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch49_loss0.11402420699596405.pypots
2024-05-25 07:14:39 [INFO]: Epoch 050 - training loss: 0.1024, validation loss: 0.1129
2024-05-25 07:14:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch50_loss0.11285716146230698.pypots
2024-05-25 07:14:55 [INFO]: Epoch 051 - training loss: 0.1018, validation loss: 0.1118
2024-05-25 07:14:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch51_loss0.11177705526351929.pypots
2024-05-25 07:15:12 [INFO]: Epoch 052 - training loss: 0.0963, validation loss: 0.1116
2024-05-25 07:15:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch52_loss0.11161060705780983.pypots
2024-05-25 07:15:29 [INFO]: Epoch 053 - training loss: 0.1102, validation loss: 0.1124
2024-05-25 07:15:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch53_loss0.11242986470460892.pypots
2024-05-25 07:15:45 [INFO]: Epoch 054 - training loss: 0.1158, validation loss: 0.1134
2024-05-25 07:15:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch54_loss0.11340607553720475.pypots
2024-05-25 07:16:02 [INFO]: Epoch 055 - training loss: 0.1087, validation loss: 0.1114
2024-05-25 07:16:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch55_loss0.11138973087072372.pypots
2024-05-25 07:16:19 [INFO]: Epoch 056 - training loss: 0.1260, validation loss: 0.1113
2024-05-25 07:16:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch56_loss0.11131134629249573.pypots
2024-05-25 07:16:35 [INFO]: Epoch 057 - training loss: 0.1001, validation loss: 0.1130
2024-05-25 07:16:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch57_loss0.11298774033784867.pypots
2024-05-25 07:16:52 [INFO]: Epoch 058 - training loss: 0.1036, validation loss: 0.1112
2024-05-25 07:16:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch58_loss0.1112236462533474.pypots
2024-05-25 07:17:09 [INFO]: Epoch 059 - training loss: 0.1110, validation loss: 0.1111
2024-05-25 07:17:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch59_loss0.11106559857726098.pypots
2024-05-25 07:17:25 [INFO]: Epoch 060 - training loss: 0.1036, validation loss: 0.1109
2024-05-25 07:17:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch60_loss0.11085577160120011.pypots
2024-05-25 07:17:42 [INFO]: Epoch 061 - training loss: 0.1029, validation loss: 0.1113
2024-05-25 07:17:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch61_loss0.11127176210284233.pypots
2024-05-25 07:17:59 [INFO]: Epoch 062 - training loss: 0.1007, validation loss: 0.1113
2024-05-25 07:17:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch62_loss0.11134492456912995.pypots
2024-05-25 07:18:15 [INFO]: Epoch 063 - training loss: 0.1192, validation loss: 0.1130
2024-05-25 07:18:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch63_loss0.1129913091659546.pypots
2024-05-25 07:18:32 [INFO]: Epoch 064 - training loss: 0.1157, validation loss: 0.1108
2024-05-25 07:18:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch64_loss0.11075282543897629.pypots
2024-05-25 07:18:49 [INFO]: Epoch 065 - training loss: 0.1032, validation loss: 0.1109
2024-05-25 07:18:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch65_loss0.11090220659971237.pypots
2024-05-25 07:19:05 [INFO]: Epoch 066 - training loss: 0.1106, validation loss: 0.1125
2024-05-25 07:19:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch66_loss0.11249940618872642.pypots
2024-05-25 07:19:22 [INFO]: Epoch 067 - training loss: 0.1008, validation loss: 0.1097
2024-05-25 07:19:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch67_loss0.10968148559331894.pypots
2024-05-25 07:19:39 [INFO]: Epoch 068 - training loss: 0.1051, validation loss: 0.1104
2024-05-25 07:19:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch68_loss0.11035931780934334.pypots
2024-05-25 07:19:55 [INFO]: Epoch 069 - training loss: 0.1026, validation loss: 0.1102
2024-05-25 07:19:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch69_loss0.11016024276614189.pypots
2024-05-25 07:20:12 [INFO]: Epoch 070 - training loss: 0.1040, validation loss: 0.1093
2024-05-25 07:20:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch70_loss0.10925830155611038.pypots
2024-05-25 07:20:29 [INFO]: Epoch 071 - training loss: 0.1105, validation loss: 0.1102
2024-05-25 07:20:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch71_loss0.11015287339687348.pypots
2024-05-25 07:20:46 [INFO]: Epoch 072 - training loss: 0.1005, validation loss: 0.1120
2024-05-25 07:20:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch72_loss0.1119829386472702.pypots
2024-05-25 07:21:02 [INFO]: Epoch 073 - training loss: 0.0994, validation loss: 0.1113
2024-05-25 07:21:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch73_loss0.11127590388059616.pypots
2024-05-25 07:21:19 [INFO]: Epoch 074 - training loss: 0.1058, validation loss: 0.1088
2024-05-25 07:21:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch74_loss0.10876208618283272.pypots
2024-05-25 07:21:36 [INFO]: Epoch 075 - training loss: 0.1003, validation loss: 0.1093
2024-05-25 07:21:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch75_loss0.10926257446408272.pypots
2024-05-25 07:21:52 [INFO]: Epoch 076 - training loss: 0.1020, validation loss: 0.1103
2024-05-25 07:21:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch76_loss0.1102798454463482.pypots
2024-05-25 07:22:09 [INFO]: Epoch 077 - training loss: 0.1126, validation loss: 0.1104
2024-05-25 07:22:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch77_loss0.11041195839643478.pypots
2024-05-25 07:22:26 [INFO]: Epoch 078 - training loss: 0.1074, validation loss: 0.1097
2024-05-25 07:22:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch78_loss0.10965437218546867.pypots
2024-05-25 07:22:42 [INFO]: Epoch 079 - training loss: 0.0982, validation loss: 0.1072
2024-05-25 07:22:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch79_loss0.1072410561144352.pypots
2024-05-25 07:22:59 [INFO]: Epoch 080 - training loss: 0.1004, validation loss: 0.1063
2024-05-25 07:22:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch80_loss0.1062527097761631.pypots
2024-05-25 07:23:16 [INFO]: Epoch 081 - training loss: 0.1149, validation loss: 0.1085
2024-05-25 07:23:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch81_loss0.10849800035357475.pypots
2024-05-25 07:23:32 [INFO]: Epoch 082 - training loss: 0.0995, validation loss: 0.1071
2024-05-25 07:23:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch82_loss0.10709503516554833.pypots
2024-05-25 07:23:49 [INFO]: Epoch 083 - training loss: 0.1042, validation loss: 0.1073
2024-05-25 07:23:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch83_loss0.10733048692345619.pypots
2024-05-25 07:24:06 [INFO]: Epoch 084 - training loss: 0.0996, validation loss: 0.1069
2024-05-25 07:24:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch84_loss0.10686828047037125.pypots
2024-05-25 07:24:22 [INFO]: Epoch 085 - training loss: 0.1096, validation loss: 0.1064
2024-05-25 07:24:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch85_loss0.10641449987888336.pypots
2024-05-25 07:24:39 [INFO]: Epoch 086 - training loss: 0.1110, validation loss: 0.1072
2024-05-25 07:24:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch86_loss0.10722601041197777.pypots
2024-05-25 07:24:56 [INFO]: Epoch 087 - training loss: 0.0971, validation loss: 0.1083
2024-05-25 07:24:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch87_loss0.10831624418497085.pypots
2024-05-25 07:25:12 [INFO]: Epoch 088 - training loss: 0.0934, validation loss: 0.1068
2024-05-25 07:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch88_loss0.10682359486818313.pypots
2024-05-25 07:25:29 [INFO]: Epoch 089 - training loss: 0.1106, validation loss: 0.1063
2024-05-25 07:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch89_loss0.10630468428134918.pypots
2024-05-25 07:25:46 [INFO]: Epoch 090 - training loss: 0.1073, validation loss: 0.1065
2024-05-25 07:25:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI_epoch90_loss0.10654889419674873.pypots
2024-05-25 07:25:46 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:25:46 [INFO]: Finished training. The best model is from epoch#80.
2024-05-25 07:25:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_air_quality/20240525_T070045/CSDI.pypots
2024-05-25 07:28:06 [INFO]: CSDI on Air-Quality: MAE=0.1111, MSE=0.1339
2024-05-25 07:28:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_air_quality/imputation.pkl
2024-05-25 07:28:06 [INFO]: Using the given device: cuda:0
2024-05-25 07:28:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T072806
2024-05-25 07:28:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T072806/tensorboard
2024-05-25 07:28:06 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 2,486,800
2024-05-25 07:28:07 [INFO]: Epoch 001 - training loss: 65714.5301, validation loss: 0.6662
2024-05-25 07:28:07 [INFO]: Epoch 002 - training loss: 41569.5632, validation loss: 0.6049
2024-05-25 07:28:07 [INFO]: Epoch 003 - training loss: 41203.5152, validation loss: 0.5825
2024-05-25 07:28:08 [INFO]: Epoch 004 - training loss: 41064.3505, validation loss: 0.5283
2024-05-25 07:28:08 [INFO]: Epoch 005 - training loss: 40990.2718, validation loss: 0.4729
2024-05-25 07:28:08 [INFO]: Epoch 006 - training loss: 40897.0595, validation loss: 0.4317
2024-05-25 07:28:09 [INFO]: Epoch 007 - training loss: 40843.7008, validation loss: 0.4096
2024-05-25 07:28:09 [INFO]: Epoch 008 - training loss: 40831.1264, validation loss: 0.4091
2024-05-25 07:28:09 [INFO]: Epoch 009 - training loss: 40806.3607, validation loss: 0.3654
2024-05-25 07:28:10 [INFO]: Epoch 010 - training loss: 40772.3037, validation loss: 0.3584
2024-05-25 07:28:10 [INFO]: Epoch 011 - training loss: 40737.2674, validation loss: 0.3388
2024-05-25 07:28:10 [INFO]: Epoch 012 - training loss: 40721.2060, validation loss: 0.3505
2024-05-25 07:28:11 [INFO]: Epoch 013 - training loss: 40717.8578, validation loss: 0.3386
2024-05-25 07:28:11 [INFO]: Epoch 014 - training loss: 40701.3613, validation loss: 0.3286
2024-05-25 07:28:11 [INFO]: Epoch 015 - training loss: 40695.3313, validation loss: 0.3462
2024-05-25 07:28:12 [INFO]: Epoch 016 - training loss: 40683.1821, validation loss: 0.3223
2024-05-25 07:28:12 [INFO]: Epoch 017 - training loss: 40674.3731, validation loss: 0.3164
2024-05-25 07:28:12 [INFO]: Epoch 018 - training loss: 40682.2759, validation loss: 0.3186
2024-05-25 07:28:13 [INFO]: Epoch 019 - training loss: 40669.6220, validation loss: 0.3056
2024-05-25 07:28:13 [INFO]: Epoch 020 - training loss: 40660.2707, validation loss: 0.3015
2024-05-25 07:28:13 [INFO]: Epoch 021 - training loss: 40644.5315, validation loss: 0.3098
2024-05-25 07:28:14 [INFO]: Epoch 022 - training loss: 40639.2325, validation loss: 0.2988
2024-05-25 07:28:14 [INFO]: Epoch 023 - training loss: 40634.2383, validation loss: 0.2997
2024-05-25 07:28:14 [INFO]: Epoch 024 - training loss: 40636.5226, validation loss: 0.3359
2024-05-25 07:28:15 [INFO]: Epoch 025 - training loss: 40766.4757, validation loss: 0.3249
2024-05-25 07:28:15 [INFO]: Epoch 026 - training loss: 40694.1628, validation loss: 0.3119
2024-05-25 07:28:15 [INFO]: Epoch 027 - training loss: 40663.6249, validation loss: 0.2943
2024-05-25 07:28:16 [INFO]: Epoch 028 - training loss: 40646.2038, validation loss: 0.2952
2024-05-25 07:28:16 [INFO]: Epoch 029 - training loss: 40642.6113, validation loss: 0.2940
2024-05-25 07:28:16 [INFO]: Epoch 030 - training loss: 40627.6950, validation loss: 0.2779
2024-05-25 07:28:17 [INFO]: Epoch 031 - training loss: 40608.1166, validation loss: 0.2753
2024-05-25 07:28:17 [INFO]: Epoch 032 - training loss: 40607.9094, validation loss: 0.2684
2024-05-25 07:28:17 [INFO]: Epoch 033 - training loss: 40593.1037, validation loss: 0.2697
2024-05-25 07:28:18 [INFO]: Epoch 034 - training loss: 40599.2387, validation loss: 0.2682
2024-05-25 07:28:18 [INFO]: Epoch 035 - training loss: 40602.6367, validation loss: 0.2840
2024-05-25 07:28:18 [INFO]: Epoch 036 - training loss: 40592.9692, validation loss: 0.2599
2024-05-25 07:28:19 [INFO]: Epoch 037 - training loss: 40586.9580, validation loss: 0.2731
2024-05-25 07:28:19 [INFO]: Epoch 038 - training loss: 40579.6850, validation loss: 0.2680
2024-05-25 07:28:19 [INFO]: Epoch 039 - training loss: 40578.8393, validation loss: 0.2777
2024-05-25 07:28:20 [INFO]: Epoch 040 - training loss: 40576.2969, validation loss: 0.2600
2024-05-25 07:28:20 [INFO]: Epoch 041 - training loss: 40571.1545, validation loss: 0.2591
2024-05-25 07:28:20 [INFO]: Epoch 042 - training loss: 40574.6512, validation loss: 0.2531
2024-05-25 07:28:21 [INFO]: Epoch 043 - training loss: 40561.0747, validation loss: 0.2547
2024-05-25 07:28:21 [INFO]: Epoch 044 - training loss: 40570.0295, validation loss: 0.2618
2024-05-25 07:28:21 [INFO]: Epoch 045 - training loss: 40569.3792, validation loss: 0.3001
2024-05-25 07:28:22 [INFO]: Epoch 046 - training loss: 40624.8388, validation loss: 0.3139
2024-05-25 07:28:22 [INFO]: Epoch 047 - training loss: 40639.9622, validation loss: 0.2602
2024-05-25 07:28:22 [INFO]: Epoch 048 - training loss: 40569.1256, validation loss: 0.2525
2024-05-25 07:28:23 [INFO]: Epoch 049 - training loss: 40560.8922, validation loss: 0.2460
2024-05-25 07:28:23 [INFO]: Epoch 050 - training loss: 40559.0428, validation loss: 0.2467
2024-05-25 07:28:23 [INFO]: Epoch 051 - training loss: 40556.9408, validation loss: 0.2529
2024-05-25 07:28:24 [INFO]: Epoch 052 - training loss: 40559.6279, validation loss: 0.2595
2024-05-25 07:28:24 [INFO]: Epoch 053 - training loss: 40573.5130, validation loss: 0.2617
2024-05-25 07:28:24 [INFO]: Epoch 054 - training loss: 40622.0809, validation loss: 0.2841
2024-05-25 07:28:25 [INFO]: Epoch 055 - training loss: 40612.3481, validation loss: 0.2879
2024-05-25 07:28:25 [INFO]: Epoch 056 - training loss: 40580.8539, validation loss: 0.2531
2024-05-25 07:28:25 [INFO]: Epoch 057 - training loss: 40590.1431, validation loss: 0.2697
2024-05-25 07:28:26 [INFO]: Epoch 058 - training loss: 40581.3319, validation loss: 0.2489
2024-05-25 07:28:26 [INFO]: Epoch 059 - training loss: 40549.5414, validation loss: 0.2419
2024-05-25 07:28:26 [INFO]: Epoch 060 - training loss: 40546.8641, validation loss: 0.2413
2024-05-25 07:28:27 [INFO]: Epoch 061 - training loss: 40549.3827, validation loss: 0.2383
2024-05-25 07:28:27 [INFO]: Epoch 062 - training loss: 40551.9983, validation loss: 0.2399
2024-05-25 07:28:27 [INFO]: Epoch 063 - training loss: 40546.1985, validation loss: 0.2364
2024-05-25 07:28:27 [INFO]: Epoch 064 - training loss: 40540.7734, validation loss: 0.2387
2024-05-25 07:28:28 [INFO]: Epoch 065 - training loss: 40541.7255, validation loss: 0.2403
2024-05-25 07:28:28 [INFO]: Epoch 066 - training loss: 40543.7669, validation loss: 0.2402
2024-05-25 07:28:28 [INFO]: Epoch 067 - training loss: 40542.8109, validation loss: 0.2360
2024-05-25 07:28:29 [INFO]: Epoch 068 - training loss: 40546.1412, validation loss: 0.2600
2024-05-25 07:28:29 [INFO]: Epoch 069 - training loss: 40548.4589, validation loss: 0.2400
2024-05-25 07:28:29 [INFO]: Epoch 070 - training loss: 40565.3814, validation loss: 0.2394
2024-05-25 07:28:30 [INFO]: Epoch 071 - training loss: 40542.5265, validation loss: 0.2368
2024-05-25 07:28:30 [INFO]: Epoch 072 - training loss: 40537.7439, validation loss: 0.2325
2024-05-25 07:28:30 [INFO]: Epoch 073 - training loss: 40534.9368, validation loss: 0.2331
2024-05-25 07:28:31 [INFO]: Epoch 074 - training loss: 40533.3517, validation loss: 0.2322
2024-05-25 07:28:31 [INFO]: Epoch 075 - training loss: 40528.0315, validation loss: 0.2308
2024-05-25 07:28:31 [INFO]: Epoch 076 - training loss: 40524.2616, validation loss: 0.2279
2024-05-25 07:28:32 [INFO]: Epoch 077 - training loss: 40527.5534, validation loss: 0.2330
2024-05-25 07:28:32 [INFO]: Epoch 078 - training loss: 40535.7018, validation loss: 0.2384
2024-05-25 07:28:32 [INFO]: Epoch 079 - training loss: 40534.9705, validation loss: 0.2407
2024-05-25 07:28:33 [INFO]: Epoch 080 - training loss: 40527.8738, validation loss: 0.2340
2024-05-25 07:28:33 [INFO]: Epoch 081 - training loss: 40524.4962, validation loss: 0.2313
2024-05-25 07:28:33 [INFO]: Epoch 082 - training loss: 40523.4252, validation loss: 0.2314
2024-05-25 07:28:34 [INFO]: Epoch 083 - training loss: 40521.5198, validation loss: 0.2328
2024-05-25 07:28:34 [INFO]: Epoch 084 - training loss: 40548.6557, validation loss: 0.2442
2024-05-25 07:28:34 [INFO]: Epoch 085 - training loss: 40553.5706, validation loss: 0.2355
2024-05-25 07:28:35 [INFO]: Epoch 086 - training loss: 40544.1319, validation loss: 0.2321
2024-05-25 07:28:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:28:35 [INFO]: Finished training. The best model is from epoch#76.
2024-05-25 07:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_air_quality/20240525_T072806/GPVAE.pypots
2024-05-25 07:28:35 [INFO]: GP-VAE on Air-Quality: MAE=0.2722, MSE=0.2457
2024-05-25 07:28:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_air_quality/imputation.pkl
2024-05-25 07:28:35 [INFO]: Using the given device: cuda:0
2024-05-25 07:28:35 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T072835
2024-05-25 07:28:35 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T072835/tensorboard
2024-05-25 07:28:35 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 948,260
2024-05-25 07:28:40 [INFO]: Epoch 001 - generator training loss: 0.3707, discriminator training loss: 0.5683, validation loss: 0.5492
2024-05-25 07:28:44 [INFO]: Epoch 002 - generator training loss: 0.0424, discriminator training loss: 0.5240, validation loss: 0.4216
2024-05-25 07:28:48 [INFO]: Epoch 003 - generator training loss: -0.0154, discriminator training loss: 0.5184, validation loss: 0.3555
2024-05-25 07:28:52 [INFO]: Epoch 004 - generator training loss: -0.0658, discriminator training loss: 0.5139, validation loss: 0.3124
2024-05-25 07:28:56 [INFO]: Epoch 005 - generator training loss: -0.0887, discriminator training loss: 0.5091, validation loss: 0.2846
2024-05-25 07:29:00 [INFO]: Epoch 006 - generator training loss: -0.1026, discriminator training loss: 0.5035, validation loss: 0.2633
2024-05-25 07:29:04 [INFO]: Epoch 007 - generator training loss: -0.1122, discriminator training loss: 0.4967, validation loss: 0.2493
2024-05-25 07:29:09 [INFO]: Epoch 008 - generator training loss: -0.1162, discriminator training loss: 0.4888, validation loss: 0.2377
2024-05-25 07:29:13 [INFO]: Epoch 009 - generator training loss: -0.1236, discriminator training loss: 0.4800, validation loss: 0.2274
2024-05-25 07:29:17 [INFO]: Epoch 010 - generator training loss: -0.1211, discriminator training loss: 0.4704, validation loss: 0.2197
2024-05-25 07:29:21 [INFO]: Epoch 011 - generator training loss: -0.1235, discriminator training loss: 0.4602, validation loss: 0.2129
2024-05-25 07:29:25 [INFO]: Epoch 012 - generator training loss: -0.1170, discriminator training loss: 0.4495, validation loss: 0.2074
2024-05-25 07:29:29 [INFO]: Epoch 013 - generator training loss: -0.1171, discriminator training loss: 0.4390, validation loss: 0.2015
2024-05-25 07:29:33 [INFO]: Epoch 014 - generator training loss: -0.1169, discriminator training loss: 0.4288, validation loss: 0.1972
2024-05-25 07:29:37 [INFO]: Epoch 015 - generator training loss: -0.1141, discriminator training loss: 0.4189, validation loss: 0.1939
2024-05-25 07:29:41 [INFO]: Epoch 016 - generator training loss: -0.1100, discriminator training loss: 0.4095, validation loss: 0.1904
2024-05-25 07:29:46 [INFO]: Epoch 017 - generator training loss: -0.1082, discriminator training loss: 0.4009, validation loss: 0.1864
2024-05-25 07:29:50 [INFO]: Epoch 018 - generator training loss: -0.1048, discriminator training loss: 0.3927, validation loss: 0.1834
2024-05-25 07:29:54 [INFO]: Epoch 019 - generator training loss: -0.1024, discriminator training loss: 0.3850, validation loss: 0.1805
2024-05-25 07:29:58 [INFO]: Epoch 020 - generator training loss: -0.1019, discriminator training loss: 0.3776, validation loss: 0.1777
2024-05-25 07:30:02 [INFO]: Epoch 021 - generator training loss: -0.0977, discriminator training loss: 0.3711, validation loss: 0.1746
2024-05-25 07:30:06 [INFO]: Epoch 022 - generator training loss: -0.0977, discriminator training loss: 0.3647, validation loss: 0.1721
2024-05-25 07:30:10 [INFO]: Epoch 023 - generator training loss: -0.0955, discriminator training loss: 0.3592, validation loss: 0.1700
2024-05-25 07:30:14 [INFO]: Epoch 024 - generator training loss: -0.0943, discriminator training loss: 0.3540, validation loss: 0.1687
2024-05-25 07:30:18 [INFO]: Epoch 025 - generator training loss: -0.0930, discriminator training loss: 0.3495, validation loss: 0.1666
2024-05-25 07:30:23 [INFO]: Epoch 026 - generator training loss: -0.0929, discriminator training loss: 0.3453, validation loss: 0.1645
2024-05-25 07:30:27 [INFO]: Epoch 027 - generator training loss: -0.0906, discriminator training loss: 0.3414, validation loss: 0.1629
2024-05-25 07:30:31 [INFO]: Epoch 028 - generator training loss: -0.0909, discriminator training loss: 0.3379, validation loss: 0.1611
2024-05-25 07:30:35 [INFO]: Epoch 029 - generator training loss: -0.0899, discriminator training loss: 0.3350, validation loss: 0.1592
2024-05-25 07:30:39 [INFO]: Epoch 030 - generator training loss: -0.0898, discriminator training loss: 0.3324, validation loss: 0.1583
2024-05-25 07:30:43 [INFO]: Epoch 031 - generator training loss: -0.0904, discriminator training loss: 0.3303, validation loss: 0.1571
2024-05-25 07:30:47 [INFO]: Epoch 032 - generator training loss: -0.0898, discriminator training loss: 0.3273, validation loss: 0.1556
2024-05-25 07:30:51 [INFO]: Epoch 033 - generator training loss: -0.0899, discriminator training loss: 0.3253, validation loss: 0.1540
2024-05-25 07:30:56 [INFO]: Epoch 034 - generator training loss: -0.0910, discriminator training loss: 0.3233, validation loss: 0.1527
2024-05-25 07:31:00 [INFO]: Epoch 035 - generator training loss: -0.0910, discriminator training loss: 0.3221, validation loss: 0.1518
2024-05-25 07:31:04 [INFO]: Epoch 036 - generator training loss: -0.0909, discriminator training loss: 0.3205, validation loss: 0.1505
2024-05-25 07:31:08 [INFO]: Epoch 037 - generator training loss: -0.0908, discriminator training loss: 0.3193, validation loss: 0.1492
2024-05-25 07:31:12 [INFO]: Epoch 038 - generator training loss: -0.0916, discriminator training loss: 0.3182, validation loss: 0.1488
2024-05-25 07:31:16 [INFO]: Epoch 039 - generator training loss: -0.0916, discriminator training loss: 0.3166, validation loss: 0.1475
2024-05-25 07:31:20 [INFO]: Epoch 040 - generator training loss: -0.0921, discriminator training loss: 0.3153, validation loss: 0.1464
2024-05-25 07:31:24 [INFO]: Epoch 041 - generator training loss: -0.0936, discriminator training loss: 0.3148, validation loss: 0.1455
2024-05-25 07:31:28 [INFO]: Epoch 042 - generator training loss: -0.0955, discriminator training loss: 0.3138, validation loss: 0.1444
2024-05-25 07:31:33 [INFO]: Epoch 043 - generator training loss: -0.0955, discriminator training loss: 0.3137, validation loss: 0.1434
2024-05-25 07:31:37 [INFO]: Epoch 044 - generator training loss: -0.0955, discriminator training loss: 0.3121, validation loss: 0.1436
2024-05-25 07:31:41 [INFO]: Epoch 045 - generator training loss: -0.0962, discriminator training loss: 0.3117, validation loss: 0.1415
2024-05-25 07:31:45 [INFO]: Epoch 046 - generator training loss: -0.0978, discriminator training loss: 0.3110, validation loss: 0.1409
2024-05-25 07:31:49 [INFO]: Epoch 047 - generator training loss: -0.0979, discriminator training loss: 0.3102, validation loss: 0.1402
2024-05-25 07:31:53 [INFO]: Epoch 048 - generator training loss: -0.0980, discriminator training loss: 0.3103, validation loss: 0.1393
2024-05-25 07:31:57 [INFO]: Epoch 049 - generator training loss: -0.0999, discriminator training loss: 0.3096, validation loss: 0.1382
2024-05-25 07:32:01 [INFO]: Epoch 050 - generator training loss: -0.1009, discriminator training loss: 0.3086, validation loss: 0.1369
2024-05-25 07:32:06 [INFO]: Epoch 051 - generator training loss: -0.1023, discriminator training loss: 0.3090, validation loss: 0.1362
2024-05-25 07:32:10 [INFO]: Epoch 052 - generator training loss: -0.1027, discriminator training loss: 0.3087, validation loss: 0.1358
2024-05-25 07:32:14 [INFO]: Epoch 053 - generator training loss: -0.1037, discriminator training loss: 0.3077, validation loss: 0.1350
2024-05-25 07:32:18 [INFO]: Epoch 054 - generator training loss: -0.1044, discriminator training loss: 0.3078, validation loss: 0.1340
2024-05-25 07:32:22 [INFO]: Epoch 055 - generator training loss: -0.1031, discriminator training loss: 0.3073, validation loss: 0.1340
2024-05-25 07:32:26 [INFO]: Epoch 056 - generator training loss: -0.1040, discriminator training loss: 0.3068, validation loss: 0.1334
2024-05-25 07:32:30 [INFO]: Epoch 057 - generator training loss: -0.1057, discriminator training loss: 0.3068, validation loss: 0.1327
2024-05-25 07:32:34 [INFO]: Epoch 058 - generator training loss: -0.1066, discriminator training loss: 0.3063, validation loss: 0.1324
2024-05-25 07:32:38 [INFO]: Epoch 059 - generator training loss: -0.1061, discriminator training loss: 0.3061, validation loss: 0.1317
2024-05-25 07:32:43 [INFO]: Epoch 060 - generator training loss: -0.1058, discriminator training loss: 0.3061, validation loss: 0.1314
2024-05-25 07:32:47 [INFO]: Epoch 061 - generator training loss: -0.1066, discriminator training loss: 0.3053, validation loss: 0.1309
2024-05-25 07:32:51 [INFO]: Epoch 062 - generator training loss: -0.1069, discriminator training loss: 0.3057, validation loss: 0.1303
2024-05-25 07:32:55 [INFO]: Epoch 063 - generator training loss: -0.1083, discriminator training loss: 0.3049, validation loss: 0.1303
2024-05-25 07:32:59 [INFO]: Epoch 064 - generator training loss: -0.1081, discriminator training loss: 0.3048, validation loss: 0.1298
2024-05-25 07:33:03 [INFO]: Epoch 065 - generator training loss: -0.1067, discriminator training loss: 0.3045, validation loss: 0.1300
2024-05-25 07:33:07 [INFO]: Epoch 066 - generator training loss: -0.1088, discriminator training loss: 0.3042, validation loss: 0.1299
2024-05-25 07:33:11 [INFO]: Epoch 067 - generator training loss: -0.1097, discriminator training loss: 0.3045, validation loss: 0.1291
2024-05-25 07:33:16 [INFO]: Epoch 068 - generator training loss: -0.1105, discriminator training loss: 0.3044, validation loss: 0.1285
2024-05-25 07:33:20 [INFO]: Epoch 069 - generator training loss: -0.1094, discriminator training loss: 0.3040, validation loss: 0.1281
2024-05-25 07:33:24 [INFO]: Epoch 070 - generator training loss: -0.1114, discriminator training loss: 0.3040, validation loss: 0.1282
2024-05-25 07:33:28 [INFO]: Epoch 071 - generator training loss: -0.1105, discriminator training loss: 0.3035, validation loss: 0.1282
2024-05-25 07:33:32 [INFO]: Epoch 072 - generator training loss: -0.1111, discriminator training loss: 0.3037, validation loss: 0.1277
2024-05-25 07:33:36 [INFO]: Epoch 073 - generator training loss: -0.1123, discriminator training loss: 0.3034, validation loss: 0.1280
2024-05-25 07:33:40 [INFO]: Epoch 074 - generator training loss: -0.1126, discriminator training loss: 0.3027, validation loss: 0.1272
2024-05-25 07:33:44 [INFO]: Epoch 075 - generator training loss: -0.1122, discriminator training loss: 0.3032, validation loss: 0.1271
2024-05-25 07:33:48 [INFO]: Epoch 076 - generator training loss: -0.1125, discriminator training loss: 0.3034, validation loss: 0.1267
2024-05-25 07:33:53 [INFO]: Epoch 077 - generator training loss: -0.1127, discriminator training loss: 0.3029, validation loss: 0.1268
2024-05-25 07:33:57 [INFO]: Epoch 078 - generator training loss: -0.1127, discriminator training loss: 0.3023, validation loss: 0.1268
2024-05-25 07:34:01 [INFO]: Epoch 079 - generator training loss: -0.1135, discriminator training loss: 0.3030, validation loss: 0.1260
2024-05-25 07:34:05 [INFO]: Epoch 080 - generator training loss: -0.1135, discriminator training loss: 0.3025, validation loss: 0.1262
2024-05-25 07:34:09 [INFO]: Epoch 081 - generator training loss: -0.1144, discriminator training loss: 0.3022, validation loss: 0.1260
2024-05-25 07:34:13 [INFO]: Epoch 082 - generator training loss: -0.1147, discriminator training loss: 0.3024, validation loss: 0.1259
2024-05-25 07:34:17 [INFO]: Epoch 083 - generator training loss: -0.1156, discriminator training loss: 0.3016, validation loss: 0.1262
2024-05-25 07:34:21 [INFO]: Epoch 084 - generator training loss: -0.1138, discriminator training loss: 0.3018, validation loss: 0.1256
2024-05-25 07:34:25 [INFO]: Epoch 085 - generator training loss: -0.1155, discriminator training loss: 0.3020, validation loss: 0.1250
2024-05-25 07:34:30 [INFO]: Epoch 086 - generator training loss: -0.1164, discriminator training loss: 0.3022, validation loss: 0.1254
2024-05-25 07:34:34 [INFO]: Epoch 087 - generator training loss: -0.1160, discriminator training loss: 0.3016, validation loss: 0.1251
2024-05-25 07:34:38 [INFO]: Epoch 088 - generator training loss: -0.1169, discriminator training loss: 0.3010, validation loss: 0.1248
2024-05-25 07:34:42 [INFO]: Epoch 089 - generator training loss: -0.1156, discriminator training loss: 0.3010, validation loss: 0.1255
2024-05-25 07:34:46 [INFO]: Epoch 090 - generator training loss: -0.1170, discriminator training loss: 0.3012, validation loss: 0.1242
2024-05-25 07:34:50 [INFO]: Epoch 091 - generator training loss: -0.1170, discriminator training loss: 0.3004, validation loss: 0.1247
2024-05-25 07:34:54 [INFO]: Epoch 092 - generator training loss: -0.1168, discriminator training loss: 0.3008, validation loss: 0.1243
2024-05-25 07:34:58 [INFO]: Epoch 093 - generator training loss: -0.1170, discriminator training loss: 0.3009, validation loss: 0.1251
2024-05-25 07:35:02 [INFO]: Epoch 094 - generator training loss: -0.1183, discriminator training loss: 0.2998, validation loss: 0.1246
2024-05-25 07:35:07 [INFO]: Epoch 095 - generator training loss: -0.1177, discriminator training loss: 0.3005, validation loss: 0.1241
2024-05-25 07:35:11 [INFO]: Epoch 096 - generator training loss: -0.1187, discriminator training loss: 0.3007, validation loss: 0.1244
2024-05-25 07:35:15 [INFO]: Epoch 097 - generator training loss: -0.1195, discriminator training loss: 0.3007, validation loss: 0.1244
2024-05-25 07:35:19 [INFO]: Epoch 098 - generator training loss: -0.1191, discriminator training loss: 0.3004, validation loss: 0.1241
2024-05-25 07:35:23 [INFO]: Epoch 099 - generator training loss: -0.1179, discriminator training loss: 0.3004, validation loss: 0.1241
2024-05-25 07:35:27 [INFO]: Epoch 100 - generator training loss: -0.1192, discriminator training loss: 0.2994, validation loss: 0.1238
2024-05-25 07:35:31 [INFO]: Epoch 101 - generator training loss: -0.1187, discriminator training loss: 0.2998, validation loss: 0.1240
2024-05-25 07:35:35 [INFO]: Epoch 102 - generator training loss: -0.1205, discriminator training loss: 0.2999, validation loss: 0.1240
2024-05-25 07:35:40 [INFO]: Epoch 103 - generator training loss: -0.1194, discriminator training loss: 0.2996, validation loss: 0.1236
2024-05-25 07:35:44 [INFO]: Epoch 104 - generator training loss: -0.1208, discriminator training loss: 0.3001, validation loss: 0.1233
2024-05-25 07:35:48 [INFO]: Epoch 105 - generator training loss: -0.1205, discriminator training loss: 0.2998, validation loss: 0.1234
2024-05-25 07:35:52 [INFO]: Epoch 106 - generator training loss: -0.1200, discriminator training loss: 0.2995, validation loss: 0.1238
2024-05-25 07:35:56 [INFO]: Epoch 107 - generator training loss: -0.1215, discriminator training loss: 0.2993, validation loss: 0.1226
2024-05-25 07:36:00 [INFO]: Epoch 108 - generator training loss: -0.1211, discriminator training loss: 0.2994, validation loss: 0.1235
2024-05-25 07:36:04 [INFO]: Epoch 109 - generator training loss: -0.1201, discriminator training loss: 0.2989, validation loss: 0.1232
2024-05-25 07:36:08 [INFO]: Epoch 110 - generator training loss: -0.1207, discriminator training loss: 0.2990, validation loss: 0.1233
2024-05-25 07:36:12 [INFO]: Epoch 111 - generator training loss: -0.1209, discriminator training loss: 0.2990, validation loss: 0.1235
2024-05-25 07:36:17 [INFO]: Epoch 112 - generator training loss: -0.1219, discriminator training loss: 0.2993, validation loss: 0.1236
2024-05-25 07:36:21 [INFO]: Epoch 113 - generator training loss: -0.1218, discriminator training loss: 0.2993, validation loss: 0.1233
2024-05-25 07:36:25 [INFO]: Epoch 114 - generator training loss: -0.1203, discriminator training loss: 0.2987, validation loss: 0.1241
2024-05-25 07:36:29 [INFO]: Epoch 115 - generator training loss: -0.1214, discriminator training loss: 0.2990, validation loss: 0.1238
2024-05-25 07:36:33 [INFO]: Epoch 116 - generator training loss: -0.1217, discriminator training loss: 0.2984, validation loss: 0.1232
2024-05-25 07:36:37 [INFO]: Epoch 117 - generator training loss: -0.1225, discriminator training loss: 0.2981, validation loss: 0.1235
2024-05-25 07:36:37 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:36:37 [INFO]: Finished training. The best model is from epoch#107.
2024-05-25 07:36:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_air_quality/20240525_T072835/USGAN.pypots
2024-05-25 07:36:38 [INFO]: US-GAN on Air-Quality: MAE=0.1635, MSE=0.1269
2024-05-25 07:36:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_air_quality/imputation.pkl
2024-05-25 07:36:38 [INFO]: Using the given device: cuda:0
2024-05-25 07:36:38 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T073638
2024-05-25 07:36:38 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T073638/tensorboard
2024-05-25 07:36:38 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 1,345,184
2024-05-25 07:36:42 [INFO]: Epoch 001 - training loss: 1.4419, validation loss: 0.9903
2024-05-25 07:36:44 [INFO]: Epoch 002 - training loss: 1.1834, validation loss: 0.7349
2024-05-25 07:36:47 [INFO]: Epoch 003 - training loss: 0.9803, validation loss: 0.6243
2024-05-25 07:36:50 [INFO]: Epoch 004 - training loss: 0.8637, validation loss: 0.5506
2024-05-25 07:36:53 [INFO]: Epoch 005 - training loss: 0.7856, validation loss: 0.5033
2024-05-25 07:36:56 [INFO]: Epoch 006 - training loss: 0.7290, validation loss: 0.4661
2024-05-25 07:36:58 [INFO]: Epoch 007 - training loss: 0.6855, validation loss: 0.4363
2024-05-25 07:37:01 [INFO]: Epoch 008 - training loss: 0.6524, validation loss: 0.4134
2024-05-25 07:37:04 [INFO]: Epoch 009 - training loss: 0.6254, validation loss: 0.3934
2024-05-25 07:37:07 [INFO]: Epoch 010 - training loss: 0.6043, validation loss: 0.3766
2024-05-25 07:37:10 [INFO]: Epoch 011 - training loss: 0.5874, validation loss: 0.3635
2024-05-25 07:37:13 [INFO]: Epoch 012 - training loss: 0.5718, validation loss: 0.3513
2024-05-25 07:37:15 [INFO]: Epoch 013 - training loss: 0.5593, validation loss: 0.3407
2024-05-25 07:37:18 [INFO]: Epoch 014 - training loss: 0.5467, validation loss: 0.3306
2024-05-25 07:37:21 [INFO]: Epoch 015 - training loss: 0.5370, validation loss: 0.3231
2024-05-25 07:37:24 [INFO]: Epoch 016 - training loss: 0.5272, validation loss: 0.3151
2024-05-25 07:37:27 [INFO]: Epoch 017 - training loss: 0.5169, validation loss: 0.3075
2024-05-25 07:37:29 [INFO]: Epoch 018 - training loss: 0.5088, validation loss: 0.3008
2024-05-25 07:37:32 [INFO]: Epoch 019 - training loss: 0.5004, validation loss: 0.2948
2024-05-25 07:37:35 [INFO]: Epoch 020 - training loss: 0.4926, validation loss: 0.2898
2024-05-25 07:37:38 [INFO]: Epoch 021 - training loss: 0.4851, validation loss: 0.2844
2024-05-25 07:37:41 [INFO]: Epoch 022 - training loss: 0.4782, validation loss: 0.2800
2024-05-25 07:37:43 [INFO]: Epoch 023 - training loss: 0.4716, validation loss: 0.2754
2024-05-25 07:37:46 [INFO]: Epoch 024 - training loss: 0.4656, validation loss: 0.2713
2024-05-25 07:37:49 [INFO]: Epoch 025 - training loss: 0.4597, validation loss: 0.2672
2024-05-25 07:37:52 [INFO]: Epoch 026 - training loss: 0.4537, validation loss: 0.2632
2024-05-25 07:37:55 [INFO]: Epoch 027 - training loss: 0.4485, validation loss: 0.2595
2024-05-25 07:37:58 [INFO]: Epoch 028 - training loss: 0.4424, validation loss: 0.2558
2024-05-25 07:38:00 [INFO]: Epoch 029 - training loss: 0.4375, validation loss: 0.2527
2024-05-25 07:38:03 [INFO]: Epoch 030 - training loss: 0.4332, validation loss: 0.2496
2024-05-25 07:38:06 [INFO]: Epoch 031 - training loss: 0.4286, validation loss: 0.2462
2024-05-25 07:38:09 [INFO]: Epoch 032 - training loss: 0.4234, validation loss: 0.2433
2024-05-25 07:38:12 [INFO]: Epoch 033 - training loss: 0.4199, validation loss: 0.2406
2024-05-25 07:38:15 [INFO]: Epoch 034 - training loss: 0.4151, validation loss: 0.2374
2024-05-25 07:38:17 [INFO]: Epoch 035 - training loss: 0.4111, validation loss: 0.2352
2024-05-25 07:38:20 [INFO]: Epoch 036 - training loss: 0.4075, validation loss: 0.2323
2024-05-25 07:38:23 [INFO]: Epoch 037 - training loss: 0.4036, validation loss: 0.2298
2024-05-25 07:38:26 [INFO]: Epoch 038 - training loss: 0.4009, validation loss: 0.2274
2024-05-25 07:38:29 [INFO]: Epoch 039 - training loss: 0.3968, validation loss: 0.2248
2024-05-25 07:38:31 [INFO]: Epoch 040 - training loss: 0.3942, validation loss: 0.2227
2024-05-25 07:38:34 [INFO]: Epoch 041 - training loss: 0.3898, validation loss: 0.2203
2024-05-25 07:38:37 [INFO]: Epoch 042 - training loss: 0.3869, validation loss: 0.2180
2024-05-25 07:38:40 [INFO]: Epoch 043 - training loss: 0.3839, validation loss: 0.2162
2024-05-25 07:38:43 [INFO]: Epoch 044 - training loss: 0.3815, validation loss: 0.2139
2024-05-25 07:38:45 [INFO]: Epoch 045 - training loss: 0.3783, validation loss: 0.2117
2024-05-25 07:38:48 [INFO]: Epoch 046 - training loss: 0.3758, validation loss: 0.2096
2024-05-25 07:38:51 [INFO]: Epoch 047 - training loss: 0.3740, validation loss: 0.2085
2024-05-25 07:38:54 [INFO]: Epoch 048 - training loss: 0.3705, validation loss: 0.2062
2024-05-25 07:38:57 [INFO]: Epoch 049 - training loss: 0.3679, validation loss: 0.2045
2024-05-25 07:39:00 [INFO]: Epoch 050 - training loss: 0.3658, validation loss: 0.2030
2024-05-25 07:39:02 [INFO]: Epoch 051 - training loss: 0.3640, validation loss: 0.2016
2024-05-25 07:39:05 [INFO]: Epoch 052 - training loss: 0.3613, validation loss: 0.2000
2024-05-25 07:39:08 [INFO]: Epoch 053 - training loss: 0.3591, validation loss: 0.1987
2024-05-25 07:39:11 [INFO]: Epoch 054 - training loss: 0.3566, validation loss: 0.1971
2024-05-25 07:39:14 [INFO]: Epoch 055 - training loss: 0.3550, validation loss: 0.1958
2024-05-25 07:39:16 [INFO]: Epoch 056 - training loss: 0.3529, validation loss: 0.1947
2024-05-25 07:39:19 [INFO]: Epoch 057 - training loss: 0.3516, validation loss: 0.1933
2024-05-25 07:39:22 [INFO]: Epoch 058 - training loss: 0.3489, validation loss: 0.1918
2024-05-25 07:39:25 [INFO]: Epoch 059 - training loss: 0.3470, validation loss: 0.1908
2024-05-25 07:39:28 [INFO]: Epoch 060 - training loss: 0.3456, validation loss: 0.1898
2024-05-25 07:39:31 [INFO]: Epoch 061 - training loss: 0.3441, validation loss: 0.1887
2024-05-25 07:39:33 [INFO]: Epoch 062 - training loss: 0.3427, validation loss: 0.1877
2024-05-25 07:39:36 [INFO]: Epoch 063 - training loss: 0.3404, validation loss: 0.1864
2024-05-25 07:39:39 [INFO]: Epoch 064 - training loss: 0.3394, validation loss: 0.1855
2024-05-25 07:39:42 [INFO]: Epoch 065 - training loss: 0.3384, validation loss: 0.1848
2024-05-25 07:39:45 [INFO]: Epoch 066 - training loss: 0.3360, validation loss: 0.1836
2024-05-25 07:39:47 [INFO]: Epoch 067 - training loss: 0.3353, validation loss: 0.1826
2024-05-25 07:39:50 [INFO]: Epoch 068 - training loss: 0.3335, validation loss: 0.1820
2024-05-25 07:39:53 [INFO]: Epoch 069 - training loss: 0.3326, validation loss: 0.1812
2024-05-25 07:39:56 [INFO]: Epoch 070 - training loss: 0.3309, validation loss: 0.1803
2024-05-25 07:39:59 [INFO]: Epoch 071 - training loss: 0.3295, validation loss: 0.1793
2024-05-25 07:40:01 [INFO]: Epoch 072 - training loss: 0.3286, validation loss: 0.1785
2024-05-25 07:40:04 [INFO]: Epoch 073 - training loss: 0.3284, validation loss: 0.1776
2024-05-25 07:40:07 [INFO]: Epoch 074 - training loss: 0.3263, validation loss: 0.1769
2024-05-25 07:40:10 [INFO]: Epoch 075 - training loss: 0.3251, validation loss: 0.1763
2024-05-25 07:40:13 [INFO]: Epoch 076 - training loss: 0.3242, validation loss: 0.1755
2024-05-25 07:40:16 [INFO]: Epoch 077 - training loss: 0.3230, validation loss: 0.1749
2024-05-25 07:40:18 [INFO]: Epoch 078 - training loss: 0.3216, validation loss: 0.1743
2024-05-25 07:40:21 [INFO]: Epoch 079 - training loss: 0.3208, validation loss: 0.1734
2024-05-25 07:40:24 [INFO]: Epoch 080 - training loss: 0.3196, validation loss: 0.1728
2024-05-25 07:40:27 [INFO]: Epoch 081 - training loss: 0.3192, validation loss: 0.1722
2024-05-25 07:40:30 [INFO]: Epoch 082 - training loss: 0.3183, validation loss: 0.1714
2024-05-25 07:40:33 [INFO]: Epoch 083 - training loss: 0.3177, validation loss: 0.1709
2024-05-25 07:40:35 [INFO]: Epoch 084 - training loss: 0.3167, validation loss: 0.1704
2024-05-25 07:40:38 [INFO]: Epoch 085 - training loss: 0.3166, validation loss: 0.1698
2024-05-25 07:40:41 [INFO]: Epoch 086 - training loss: 0.3158, validation loss: 0.1691
2024-05-25 07:40:44 [INFO]: Epoch 087 - training loss: 0.3140, validation loss: 0.1686
2024-05-25 07:40:47 [INFO]: Epoch 088 - training loss: 0.3128, validation loss: 0.1680
2024-05-25 07:40:49 [INFO]: Epoch 089 - training loss: 0.3124, validation loss: 0.1674
2024-05-25 07:40:52 [INFO]: Epoch 090 - training loss: 0.3117, validation loss: 0.1671
2024-05-25 07:40:55 [INFO]: Epoch 091 - training loss: 0.3108, validation loss: 0.1665
2024-05-25 07:40:58 [INFO]: Epoch 092 - training loss: 0.3104, validation loss: 0.1659
2024-05-25 07:41:01 [INFO]: Epoch 093 - training loss: 0.3090, validation loss: 0.1655
2024-05-25 07:41:03 [INFO]: Epoch 094 - training loss: 0.3084, validation loss: 0.1650
2024-05-25 07:41:06 [INFO]: Epoch 095 - training loss: 0.3080, validation loss: 0.1644
2024-05-25 07:41:09 [INFO]: Epoch 096 - training loss: 0.3078, validation loss: 0.1639
2024-05-25 07:41:12 [INFO]: Epoch 097 - training loss: 0.3067, validation loss: 0.1635
2024-05-25 07:41:15 [INFO]: Epoch 098 - training loss: 0.3057, validation loss: 0.1632
2024-05-25 07:41:18 [INFO]: Epoch 099 - training loss: 0.3050, validation loss: 0.1627
2024-05-25 07:41:20 [INFO]: Epoch 100 - training loss: 0.3047, validation loss: 0.1625
2024-05-25 07:41:23 [INFO]: Epoch 101 - training loss: 0.3037, validation loss: 0.1618
2024-05-25 07:41:26 [INFO]: Epoch 102 - training loss: 0.3030, validation loss: 0.1614
2024-05-25 07:41:29 [INFO]: Epoch 103 - training loss: 0.3028, validation loss: 0.1612
2024-05-25 07:41:32 [INFO]: Epoch 104 - training loss: 0.3019, validation loss: 0.1607
2024-05-25 07:41:34 [INFO]: Epoch 105 - training loss: 0.3016, validation loss: 0.1604
2024-05-25 07:41:37 [INFO]: Epoch 106 - training loss: 0.3007, validation loss: 0.1600
2024-05-25 07:41:40 [INFO]: Epoch 107 - training loss: 0.3007, validation loss: 0.1593
2024-05-25 07:41:43 [INFO]: Epoch 108 - training loss: 0.2997, validation loss: 0.1591
2024-05-25 07:41:46 [INFO]: Epoch 109 - training loss: 0.2993, validation loss: 0.1588
2024-05-25 07:41:49 [INFO]: Epoch 110 - training loss: 0.2992, validation loss: 0.1584
2024-05-25 07:41:51 [INFO]: Epoch 111 - training loss: 0.2983, validation loss: 0.1581
2024-05-25 07:41:54 [INFO]: Epoch 112 - training loss: 0.2978, validation loss: 0.1575
2024-05-25 07:41:57 [INFO]: Epoch 113 - training loss: 0.2967, validation loss: 0.1574
2024-05-25 07:42:00 [INFO]: Epoch 114 - training loss: 0.2974, validation loss: 0.1569
2024-05-25 07:42:03 [INFO]: Epoch 115 - training loss: 0.2957, validation loss: 0.1568
2024-05-25 07:42:05 [INFO]: Epoch 116 - training loss: 0.2962, validation loss: 0.1562
2024-05-25 07:42:08 [INFO]: Epoch 117 - training loss: 0.2953, validation loss: 0.1559
2024-05-25 07:42:11 [INFO]: Epoch 118 - training loss: 0.2950, validation loss: 0.1555
2024-05-25 07:42:14 [INFO]: Epoch 119 - training loss: 0.2945, validation loss: 0.1554
2024-05-25 07:42:17 [INFO]: Epoch 120 - training loss: 0.2933, validation loss: 0.1549
2024-05-25 07:42:20 [INFO]: Epoch 121 - training loss: 0.2934, validation loss: 0.1547
2024-05-25 07:42:22 [INFO]: Epoch 122 - training loss: 0.2927, validation loss: 0.1542
2024-05-25 07:42:25 [INFO]: Epoch 123 - training loss: 0.2932, validation loss: 0.1540
2024-05-25 07:42:28 [INFO]: Epoch 124 - training loss: 0.2921, validation loss: 0.1537
2024-05-25 07:42:31 [INFO]: Epoch 125 - training loss: 0.2922, validation loss: 0.1532
2024-05-25 07:42:34 [INFO]: Epoch 126 - training loss: 0.2914, validation loss: 0.1532
2024-05-25 07:42:36 [INFO]: Epoch 127 - training loss: 0.2912, validation loss: 0.1531
2024-05-25 07:42:39 [INFO]: Epoch 128 - training loss: 0.2898, validation loss: 0.1525
2024-05-25 07:42:42 [INFO]: Epoch 129 - training loss: 0.2897, validation loss: 0.1521
2024-05-25 07:42:45 [INFO]: Epoch 130 - training loss: 0.2896, validation loss: 0.1520
2024-05-25 07:42:48 [INFO]: Epoch 131 - training loss: 0.2889, validation loss: 0.1517
2024-05-25 07:42:51 [INFO]: Epoch 132 - training loss: 0.2882, validation loss: 0.1512
2024-05-25 07:42:53 [INFO]: Epoch 133 - training loss: 0.2885, validation loss: 0.1511
2024-05-25 07:42:56 [INFO]: Epoch 134 - training loss: 0.2876, validation loss: 0.1509
2024-05-25 07:42:59 [INFO]: Epoch 135 - training loss: 0.2876, validation loss: 0.1504
2024-05-25 07:43:02 [INFO]: Epoch 136 - training loss: 0.2864, validation loss: 0.1503
2024-05-25 07:43:05 [INFO]: Epoch 137 - training loss: 0.2871, validation loss: 0.1500
2024-05-25 07:43:07 [INFO]: Epoch 138 - training loss: 0.2861, validation loss: 0.1499
2024-05-25 07:43:10 [INFO]: Epoch 139 - training loss: 0.2851, validation loss: 0.1495
2024-05-25 07:43:13 [INFO]: Epoch 140 - training loss: 0.2854, validation loss: 0.1493
2024-05-25 07:43:16 [INFO]: Epoch 141 - training loss: 0.2846, validation loss: 0.1491
2024-05-25 07:43:19 [INFO]: Epoch 142 - training loss: 0.2843, validation loss: 0.1487
2024-05-25 07:43:21 [INFO]: Epoch 143 - training loss: 0.2843, validation loss: 0.1487
2024-05-25 07:43:24 [INFO]: Epoch 144 - training loss: 0.2843, validation loss: 0.1480
2024-05-25 07:43:27 [INFO]: Epoch 145 - training loss: 0.2837, validation loss: 0.1480
2024-05-25 07:43:30 [INFO]: Epoch 146 - training loss: 0.2832, validation loss: 0.1478
2024-05-25 07:43:33 [INFO]: Epoch 147 - training loss: 0.2832, validation loss: 0.1474
2024-05-25 07:43:36 [INFO]: Epoch 148 - training loss: 0.2822, validation loss: 0.1474
2024-05-25 07:43:38 [INFO]: Epoch 149 - training loss: 0.2818, validation loss: 0.1473
2024-05-25 07:43:41 [INFO]: Epoch 150 - training loss: 0.2821, validation loss: 0.1469
2024-05-25 07:43:44 [INFO]: Epoch 151 - training loss: 0.2812, validation loss: 0.1466
2024-05-25 07:43:47 [INFO]: Epoch 152 - training loss: 0.2815, validation loss: 0.1464
2024-05-25 07:43:50 [INFO]: Epoch 153 - training loss: 0.2808, validation loss: 0.1461
2024-05-25 07:43:52 [INFO]: Epoch 154 - training loss: 0.2803, validation loss: 0.1459
2024-05-25 07:43:55 [INFO]: Epoch 155 - training loss: 0.2813, validation loss: 0.1458
2024-05-25 07:43:58 [INFO]: Epoch 156 - training loss: 0.2798, validation loss: 0.1455
2024-05-25 07:44:01 [INFO]: Epoch 157 - training loss: 0.2798, validation loss: 0.1454
2024-05-25 07:44:04 [INFO]: Epoch 158 - training loss: 0.2792, validation loss: 0.1449
2024-05-25 07:44:07 [INFO]: Epoch 159 - training loss: 0.2787, validation loss: 0.1448
2024-05-25 07:44:09 [INFO]: Epoch 160 - training loss: 0.2794, validation loss: 0.1446
2024-05-25 07:44:12 [INFO]: Epoch 161 - training loss: 0.2785, validation loss: 0.1445
2024-05-25 07:44:15 [INFO]: Epoch 162 - training loss: 0.2783, validation loss: 0.1441
2024-05-25 07:44:18 [INFO]: Epoch 163 - training loss: 0.2776, validation loss: 0.1441
2024-05-25 07:44:21 [INFO]: Epoch 164 - training loss: 0.2777, validation loss: 0.1439
2024-05-25 07:44:24 [INFO]: Epoch 165 - training loss: 0.2777, validation loss: 0.1436
2024-05-25 07:44:26 [INFO]: Epoch 166 - training loss: 0.2770, validation loss: 0.1437
2024-05-25 07:44:29 [INFO]: Epoch 167 - training loss: 0.2765, validation loss: 0.1435
2024-05-25 07:44:32 [INFO]: Epoch 168 - training loss: 0.2761, validation loss: 0.1431
2024-05-25 07:44:35 [INFO]: Epoch 169 - training loss: 0.2761, validation loss: 0.1429
2024-05-25 07:44:38 [INFO]: Epoch 170 - training loss: 0.2755, validation loss: 0.1425
2024-05-25 07:44:40 [INFO]: Epoch 171 - training loss: 0.2753, validation loss: 0.1424
2024-05-25 07:44:43 [INFO]: Epoch 172 - training loss: 0.2750, validation loss: 0.1423
2024-05-25 07:44:46 [INFO]: Epoch 173 - training loss: 0.2747, validation loss: 0.1421
2024-05-25 07:44:49 [INFO]: Epoch 174 - training loss: 0.2748, validation loss: 0.1419
2024-05-25 07:44:52 [INFO]: Epoch 175 - training loss: 0.2738, validation loss: 0.1420
2024-05-25 07:44:55 [INFO]: Epoch 176 - training loss: 0.2738, validation loss: 0.1416
2024-05-25 07:44:57 [INFO]: Epoch 177 - training loss: 0.2738, validation loss: 0.1414
2024-05-25 07:45:00 [INFO]: Epoch 178 - training loss: 0.2733, validation loss: 0.1413
2024-05-25 07:45:03 [INFO]: Epoch 179 - training loss: 0.2733, validation loss: 0.1412
2024-05-25 07:45:06 [INFO]: Epoch 180 - training loss: 0.2728, validation loss: 0.1410
2024-05-25 07:45:09 [INFO]: Epoch 181 - training loss: 0.2733, validation loss: 0.1408
2024-05-25 07:45:11 [INFO]: Epoch 182 - training loss: 0.2729, validation loss: 0.1407
2024-05-25 07:45:14 [INFO]: Epoch 183 - training loss: 0.2718, validation loss: 0.1405
2024-05-25 07:45:17 [INFO]: Epoch 184 - training loss: 0.2721, validation loss: 0.1402
2024-05-25 07:45:20 [INFO]: Epoch 185 - training loss: 0.2721, validation loss: 0.1402
2024-05-25 07:45:23 [INFO]: Epoch 186 - training loss: 0.2717, validation loss: 0.1400
2024-05-25 07:45:26 [INFO]: Epoch 187 - training loss: 0.2711, validation loss: 0.1400
2024-05-25 07:45:28 [INFO]: Epoch 188 - training loss: 0.2706, validation loss: 0.1396
2024-05-25 07:45:31 [INFO]: Epoch 189 - training loss: 0.2709, validation loss: 0.1397
2024-05-25 07:45:34 [INFO]: Epoch 190 - training loss: 0.2710, validation loss: 0.1395
2024-05-25 07:45:37 [INFO]: Epoch 191 - training loss: 0.2703, validation loss: 0.1395
2024-05-25 07:45:40 [INFO]: Epoch 192 - training loss: 0.2693, validation loss: 0.1392
2024-05-25 07:45:42 [INFO]: Epoch 193 - training loss: 0.2698, validation loss: 0.1390
2024-05-25 07:45:45 [INFO]: Epoch 194 - training loss: 0.2699, validation loss: 0.1388
2024-05-25 07:45:48 [INFO]: Epoch 195 - training loss: 0.2691, validation loss: 0.1389
2024-05-25 07:45:51 [INFO]: Epoch 196 - training loss: 0.2684, validation loss: 0.1385
2024-05-25 07:45:54 [INFO]: Epoch 197 - training loss: 0.2691, validation loss: 0.1384
2024-05-25 07:45:56 [INFO]: Epoch 198 - training loss: 0.2683, validation loss: 0.1383
2024-05-25 07:45:59 [INFO]: Epoch 199 - training loss: 0.2686, validation loss: 0.1382
2024-05-25 07:46:02 [INFO]: Epoch 200 - training loss: 0.2682, validation loss: 0.1379
2024-05-25 07:46:05 [INFO]: Epoch 201 - training loss: 0.2685, validation loss: 0.1378
2024-05-25 07:46:08 [INFO]: Epoch 202 - training loss: 0.2682, validation loss: 0.1377
2024-05-25 07:46:11 [INFO]: Epoch 203 - training loss: 0.2677, validation loss: 0.1374
2024-05-25 07:46:13 [INFO]: Epoch 204 - training loss: 0.2679, validation loss: 0.1375
2024-05-25 07:46:16 [INFO]: Epoch 205 - training loss: 0.2669, validation loss: 0.1374
2024-05-25 07:46:19 [INFO]: Epoch 206 - training loss: 0.2673, validation loss: 0.1374
2024-05-25 07:46:22 [INFO]: Epoch 207 - training loss: 0.2660, validation loss: 0.1372
2024-05-25 07:46:25 [INFO]: Epoch 208 - training loss: 0.2665, validation loss: 0.1368
2024-05-25 07:46:28 [INFO]: Epoch 209 - training loss: 0.2661, validation loss: 0.1369
2024-05-25 07:46:30 [INFO]: Epoch 210 - training loss: 0.2659, validation loss: 0.1366
2024-05-25 07:46:33 [INFO]: Epoch 211 - training loss: 0.2658, validation loss: 0.1367
2024-05-25 07:46:36 [INFO]: Epoch 212 - training loss: 0.2656, validation loss: 0.1362
2024-05-25 07:46:39 [INFO]: Epoch 213 - training loss: 0.2657, validation loss: 0.1362
2024-05-25 07:46:42 [INFO]: Epoch 214 - training loss: 0.2651, validation loss: 0.1361
2024-05-25 07:46:44 [INFO]: Epoch 215 - training loss: 0.2650, validation loss: 0.1362
2024-05-25 07:46:47 [INFO]: Epoch 216 - training loss: 0.2649, validation loss: 0.1359
2024-05-25 07:46:50 [INFO]: Epoch 217 - training loss: 0.2648, validation loss: 0.1358
2024-05-25 07:46:53 [INFO]: Epoch 218 - training loss: 0.2646, validation loss: 0.1359
2024-05-25 07:46:56 [INFO]: Epoch 219 - training loss: 0.2646, validation loss: 0.1355
2024-05-25 07:46:58 [INFO]: Epoch 220 - training loss: 0.2641, validation loss: 0.1354
2024-05-25 07:47:01 [INFO]: Epoch 221 - training loss: 0.2645, validation loss: 0.1356
2024-05-25 07:47:04 [INFO]: Epoch 222 - training loss: 0.2635, validation loss: 0.1352
2024-05-25 07:47:07 [INFO]: Epoch 223 - training loss: 0.2637, validation loss: 0.1353
2024-05-25 07:47:10 [INFO]: Epoch 224 - training loss: 0.2632, validation loss: 0.1352
2024-05-25 07:47:13 [INFO]: Epoch 225 - training loss: 0.2636, validation loss: 0.1348
2024-05-25 07:47:15 [INFO]: Epoch 226 - training loss: 0.2632, validation loss: 0.1352
2024-05-25 07:47:18 [INFO]: Epoch 227 - training loss: 0.2624, validation loss: 0.1349
2024-05-25 07:47:21 [INFO]: Epoch 228 - training loss: 0.2626, validation loss: 0.1346
2024-05-25 07:47:24 [INFO]: Epoch 229 - training loss: 0.2624, validation loss: 0.1346
2024-05-25 07:47:27 [INFO]: Epoch 230 - training loss: 0.2621, validation loss: 0.1346
2024-05-25 07:47:29 [INFO]: Epoch 231 - training loss: 0.2620, validation loss: 0.1346
2024-05-25 07:47:32 [INFO]: Epoch 232 - training loss: 0.2624, validation loss: 0.1344
2024-05-25 07:47:35 [INFO]: Epoch 233 - training loss: 0.2615, validation loss: 0.1341
2024-05-25 07:47:38 [INFO]: Epoch 234 - training loss: 0.2614, validation loss: 0.1342
2024-05-25 07:47:41 [INFO]: Epoch 235 - training loss: 0.2613, validation loss: 0.1342
2024-05-25 07:47:44 [INFO]: Epoch 236 - training loss: 0.2612, validation loss: 0.1340
2024-05-25 07:47:46 [INFO]: Epoch 237 - training loss: 0.2610, validation loss: 0.1340
2024-05-25 07:47:49 [INFO]: Epoch 238 - training loss: 0.2609, validation loss: 0.1338
2024-05-25 07:47:52 [INFO]: Epoch 239 - training loss: 0.2606, validation loss: 0.1336
2024-05-25 07:47:55 [INFO]: Epoch 240 - training loss: 0.2611, validation loss: 0.1337
2024-05-25 07:47:58 [INFO]: Epoch 241 - training loss: 0.2602, validation loss: 0.1333
2024-05-25 07:48:00 [INFO]: Epoch 242 - training loss: 0.2601, validation loss: 0.1333
2024-05-25 07:48:03 [INFO]: Epoch 243 - training loss: 0.2596, validation loss: 0.1334
2024-05-25 07:48:06 [INFO]: Epoch 244 - training loss: 0.2599, validation loss: 0.1332
2024-05-25 07:48:09 [INFO]: Epoch 245 - training loss: 0.2596, validation loss: 0.1331
2024-05-25 07:48:12 [INFO]: Epoch 246 - training loss: 0.2592, validation loss: 0.1331
2024-05-25 07:48:14 [INFO]: Epoch 247 - training loss: 0.2593, validation loss: 0.1330
2024-05-25 07:48:17 [INFO]: Epoch 248 - training loss: 0.2587, validation loss: 0.1328
2024-05-25 07:48:20 [INFO]: Epoch 249 - training loss: 0.2590, validation loss: 0.1329
2024-05-25 07:48:23 [INFO]: Epoch 250 - training loss: 0.2589, validation loss: 0.1329
2024-05-25 07:48:26 [INFO]: Epoch 251 - training loss: 0.2584, validation loss: 0.1328
2024-05-25 07:48:29 [INFO]: Epoch 252 - training loss: 0.2584, validation loss: 0.1328
2024-05-25 07:48:31 [INFO]: Epoch 253 - training loss: 0.2586, validation loss: 0.1326
2024-05-25 07:48:34 [INFO]: Epoch 254 - training loss: 0.2582, validation loss: 0.1324
2024-05-25 07:48:37 [INFO]: Epoch 255 - training loss: 0.2581, validation loss: 0.1325
2024-05-25 07:48:40 [INFO]: Epoch 256 - training loss: 0.2579, validation loss: 0.1323
2024-05-25 07:48:43 [INFO]: Epoch 257 - training loss: 0.2579, validation loss: 0.1322
2024-05-25 07:48:46 [INFO]: Epoch 258 - training loss: 0.2576, validation loss: 0.1322
2024-05-25 07:48:48 [INFO]: Epoch 259 - training loss: 0.2574, validation loss: 0.1320
2024-05-25 07:48:51 [INFO]: Epoch 260 - training loss: 0.2572, validation loss: 0.1320
2024-05-25 07:48:54 [INFO]: Epoch 261 - training loss: 0.2579, validation loss: 0.1319
2024-05-25 07:48:57 [INFO]: Epoch 262 - training loss: 0.2573, validation loss: 0.1318
2024-05-25 07:49:00 [INFO]: Epoch 263 - training loss: 0.2568, validation loss: 0.1318
2024-05-25 07:49:02 [INFO]: Epoch 264 - training loss: 0.2564, validation loss: 0.1316
2024-05-25 07:49:05 [INFO]: Epoch 265 - training loss: 0.2563, validation loss: 0.1317
2024-05-25 07:49:08 [INFO]: Epoch 266 - training loss: 0.2557, validation loss: 0.1316
2024-05-25 07:49:11 [INFO]: Epoch 267 - training loss: 0.2561, validation loss: 0.1314
2024-05-25 07:49:14 [INFO]: Epoch 268 - training loss: 0.2558, validation loss: 0.1317
2024-05-25 07:49:17 [INFO]: Epoch 269 - training loss: 0.2555, validation loss: 0.1313
2024-05-25 07:49:19 [INFO]: Epoch 270 - training loss: 0.2553, validation loss: 0.1314
2024-05-25 07:49:22 [INFO]: Epoch 271 - training loss: 0.2555, validation loss: 0.1312
2024-05-25 07:49:25 [INFO]: Epoch 272 - training loss: 0.2555, validation loss: 0.1311
2024-05-25 07:49:28 [INFO]: Epoch 273 - training loss: 0.2562, validation loss: 0.1312
2024-05-25 07:49:31 [INFO]: Epoch 274 - training loss: 0.2554, validation loss: 0.1310
2024-05-25 07:49:33 [INFO]: Epoch 275 - training loss: 0.2550, validation loss: 0.1312
2024-05-25 07:49:36 [INFO]: Epoch 276 - training loss: 0.2548, validation loss: 0.1309
2024-05-25 07:49:39 [INFO]: Epoch 277 - training loss: 0.2543, validation loss: 0.1310
2024-05-25 07:49:42 [INFO]: Epoch 278 - training loss: 0.2541, validation loss: 0.1312
2024-05-25 07:49:45 [INFO]: Epoch 279 - training loss: 0.2541, validation loss: 0.1309
2024-05-25 07:49:47 [INFO]: Epoch 280 - training loss: 0.2539, validation loss: 0.1309
2024-05-25 07:49:50 [INFO]: Epoch 281 - training loss: 0.2544, validation loss: 0.1306
2024-05-25 07:49:53 [INFO]: Epoch 282 - training loss: 0.2541, validation loss: 0.1306
2024-05-25 07:49:56 [INFO]: Epoch 283 - training loss: 0.2539, validation loss: 0.1305
2024-05-25 07:49:59 [INFO]: Epoch 284 - training loss: 0.2536, validation loss: 0.1306
2024-05-25 07:50:02 [INFO]: Epoch 285 - training loss: 0.2534, validation loss: 0.1303
2024-05-25 07:50:04 [INFO]: Epoch 286 - training loss: 0.2537, validation loss: 0.1301
2024-05-25 07:50:07 [INFO]: Epoch 287 - training loss: 0.2534, validation loss: 0.1305
2024-05-25 07:50:10 [INFO]: Epoch 288 - training loss: 0.2534, validation loss: 0.1306
2024-05-25 07:50:13 [INFO]: Epoch 289 - training loss: 0.2535, validation loss: 0.1304
2024-05-25 07:50:16 [INFO]: Epoch 290 - training loss: 0.2526, validation loss: 0.1303
2024-05-25 07:50:18 [INFO]: Epoch 291 - training loss: 0.2528, validation loss: 0.1302
2024-05-25 07:50:21 [INFO]: Epoch 292 - training loss: 0.2532, validation loss: 0.1302
2024-05-25 07:50:24 [INFO]: Epoch 293 - training loss: 0.2526, validation loss: 0.1305
2024-05-25 07:50:27 [INFO]: Epoch 294 - training loss: 0.2529, validation loss: 0.1301
2024-05-25 07:50:30 [INFO]: Epoch 295 - training loss: 0.2525, validation loss: 0.1300
2024-05-25 07:50:33 [INFO]: Epoch 296 - training loss: 0.2519, validation loss: 0.1302
2024-05-25 07:50:35 [INFO]: Epoch 297 - training loss: 0.2525, validation loss: 0.1302
2024-05-25 07:50:38 [INFO]: Epoch 298 - training loss: 0.2528, validation loss: 0.1299
2024-05-25 07:50:41 [INFO]: Epoch 299 - training loss: 0.2522, validation loss: 0.1300
2024-05-25 07:50:44 [INFO]: Epoch 300 - training loss: 0.2518, validation loss: 0.1300
2024-05-25 07:50:44 [INFO]: Finished training. The best model is from epoch#298.
2024-05-25 07:50:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_air_quality/20240525_T073638/BRITS.pypots
2024-05-25 07:50:45 [INFO]: BRITS on Air-Quality: MAE=0.1510, MSE=0.1337
2024-05-25 07:50:45 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_air_quality/imputation.pkl
2024-05-25 07:50:45 [INFO]: Using the given device: cuda:0
2024-05-25 07:50:45 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045
2024-05-25 07:50:45 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/tensorboard
2024-05-25 07:50:45 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 72,009
2024-05-25 07:50:49 [INFO]: Epoch 001 - training loss: 1.3864, validation loss: 0.8408
2024-05-25 07:50:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch1_loss0.8407767474651336.pypots
2024-05-25 07:50:53 [INFO]: Epoch 002 - training loss: 1.0114, validation loss: 0.7806
2024-05-25 07:50:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch2_loss0.7806115567684173.pypots
2024-05-25 07:50:57 [INFO]: Epoch 003 - training loss: 0.9398, validation loss: 0.7562
2024-05-25 07:50:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch3_loss0.7561726212501526.pypots
2024-05-25 07:51:01 [INFO]: Epoch 004 - training loss: 0.9086, validation loss: 0.7387
2024-05-25 07:51:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch4_loss0.7386736154556275.pypots
2024-05-25 07:51:05 [INFO]: Epoch 005 - training loss: 0.8882, validation loss: 0.7302
2024-05-25 07:51:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch5_loss0.7302366077899933.pypots
2024-05-25 07:51:09 [INFO]: Epoch 006 - training loss: 0.8840, validation loss: 0.7222
2024-05-25 07:51:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch6_loss0.7222084373235702.pypots
2024-05-25 07:51:13 [INFO]: Epoch 007 - training loss: 0.8682, validation loss: 0.7174
2024-05-25 07:51:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch7_loss0.7174466162919998.pypots
2024-05-25 07:51:17 [INFO]: Epoch 008 - training loss: 0.8751, validation loss: 0.7123
2024-05-25 07:51:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch8_loss0.7122994154691696.pypots
2024-05-25 07:51:20 [INFO]: Epoch 009 - training loss: 0.8824, validation loss: 0.7104
2024-05-25 07:51:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch9_loss0.7104009926319123.pypots
2024-05-25 07:51:24 [INFO]: Epoch 010 - training loss: 0.8585, validation loss: 0.7074
2024-05-25 07:51:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch10_loss0.7074050396680832.pypots
2024-05-25 07:51:28 [INFO]: Epoch 011 - training loss: 0.8404, validation loss: 0.7053
2024-05-25 07:51:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch11_loss0.7053197741508483.pypots
2024-05-25 07:51:32 [INFO]: Epoch 012 - training loss: 0.8551, validation loss: 0.7056
2024-05-25 07:51:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch12_loss0.7055888622999191.pypots
2024-05-25 07:51:36 [INFO]: Epoch 013 - training loss: 0.8288, validation loss: 0.7039
2024-05-25 07:51:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch13_loss0.7038973897695542.pypots
2024-05-25 07:51:40 [INFO]: Epoch 014 - training loss: 0.8297, validation loss: 0.7019
2024-05-25 07:51:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch14_loss0.7019165813922882.pypots
2024-05-25 07:51:44 [INFO]: Epoch 015 - training loss: 0.8190, validation loss: 0.7008
2024-05-25 07:51:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch15_loss0.7007855504751206.pypots
2024-05-25 07:51:48 [INFO]: Epoch 016 - training loss: 0.8220, validation loss: 0.7002
2024-05-25 07:51:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch16_loss0.7001781195402146.pypots
2024-05-25 07:51:52 [INFO]: Epoch 017 - training loss: 0.8266, validation loss: 0.6993
2024-05-25 07:51:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch17_loss0.6993396937847137.pypots
2024-05-25 07:51:56 [INFO]: Epoch 018 - training loss: 0.8230, validation loss: 0.6976
2024-05-25 07:51:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch18_loss0.6975721687078476.pypots
2024-05-25 07:51:59 [INFO]: Epoch 019 - training loss: 0.8293, validation loss: 0.7020
2024-05-25 07:51:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch19_loss0.7019558191299439.pypots
2024-05-25 07:52:03 [INFO]: Epoch 020 - training loss: 0.8249, validation loss: 0.6998
2024-05-25 07:52:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch20_loss0.6998362898826599.pypots
2024-05-25 07:52:07 [INFO]: Epoch 021 - training loss: 0.8237, validation loss: 0.6992
2024-05-25 07:52:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch21_loss0.6992274701595307.pypots
2024-05-25 07:52:11 [INFO]: Epoch 022 - training loss: 0.8166, validation loss: 0.7001
2024-05-25 07:52:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch22_loss0.7001216411590576.pypots
2024-05-25 07:52:15 [INFO]: Epoch 023 - training loss: 0.8125, validation loss: 0.6985
2024-05-25 07:52:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch23_loss0.698485466837883.pypots
2024-05-25 07:52:19 [INFO]: Epoch 024 - training loss: 0.8151, validation loss: 0.6993
2024-05-25 07:52:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch24_loss0.6993258744478226.pypots
2024-05-25 07:52:23 [INFO]: Epoch 025 - training loss: 0.7947, validation loss: 0.6990
2024-05-25 07:52:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch25_loss0.6989926129579545.pypots
2024-05-25 07:52:27 [INFO]: Epoch 026 - training loss: 0.7971, validation loss: 0.7020
2024-05-25 07:52:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch26_loss0.7019978195428849.pypots
2024-05-25 07:52:31 [INFO]: Epoch 027 - training loss: 0.7915, validation loss: 0.6990
2024-05-25 07:52:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch27_loss0.698952454328537.pypots
2024-05-25 07:52:35 [INFO]: Epoch 028 - training loss: 0.8038, validation loss: 0.7001
2024-05-25 07:52:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN_epoch28_loss0.7001311987638473.pypots
2024-05-25 07:52:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-25 07:52:35 [INFO]: Finished training. The best model is from epoch#18.
2024-05-25 07:52:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_air_quality/20240525_T075045/MRNN.pypots
2024-05-25 07:52:35 [INFO]: MRNN on Air-Quality: MAE=0.5214, MSE=0.6332
2024-05-25 07:52:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_air_quality/imputation.pkl
2024-05-25 07:52:35 [INFO]: Using the given device: cpu
2024-05-25 07:52:35 [INFO]: LOCF on Air-Quality: MAE=0.2194, MSE=0.3465
2024-05-25 07:52:35 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_air_quality".
2024-05-25 07:52:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_air_quality/imputation.pkl
2024-05-25 07:52:35 [INFO]: Median on Air-Quality: MAE=0.6629, MSE=1.0282
2024-05-25 07:52:35 [INFO]: Successfully created the given path "saved_results/round_4/Median_air_quality".
2024-05-25 07:52:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_air_quality/imputation.pkl
2024-05-25 07:52:35 [INFO]: Mean on Air-Quality: MAE=0.6945, MSE=0.9678
2024-05-25 07:52:35 [INFO]: Successfully created the given path "saved_results/round_4/Mean_air_quality".
2024-05-25 07:52:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_air_quality/imputation.pkl
2024-05-25 07:52:35 [INFO]: 
SAITS on data/air_quality: MAE=0.160±0.0024276557853240796, MSE=0.144±0.002873405548938391
Transformer on data/air_quality: MAE=0.182±0.0021135964839808855, MSE=0.170±0.002581896031886578
TimesNet on data/air_quality: MAE=0.173±0.0019018658539113897, MSE=0.218±0.003828260536291331
CSDI on data/air_quality: MAE=0.106±0.0034283417130531253, MSE=0.146±0.0146505488656474
GPVAE on data/air_quality: MAE=0.287±0.014679048756152583, MSE=0.266±0.017106471859881067
USGAN on data/air_quality: MAE=0.164±0.0005315797047890452, MSE=0.130±0.0034306110084282903
BRITS on data/air_quality: MAE=0.151±0.000184927923484864, MSE=0.132±0.0010562031589755453
MRNN on data/air_quality: MAE=0.521±0.0009779917543185465, MSE=0.634±0.0013551672103586409
LOCF on data/air_quality: MAE=0.219±0.0, MSE=0.347±0.0
Median on data/air_quality: MAE=0.663±0.0, MSE=1.028±0.0
Mean on data/air_quality: MAE=0.694±0.0, MSE=0.968±0.0