2024-05-24 19:28:58 [INFO]: Have set the random seed as 2023 for numpy and pytorch.
2024-05-24 19:28:58 [INFO]: Using the given device: cuda:0
2024-05-24 19:28:58 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T192858
2024-05-24 19:28:58 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T192858/tensorboard
2024-05-24 19:28:58 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 19:29:09 [INFO]: Epoch 001 - training loss: 1.2042, validation loss: 0.2814
2024-05-24 19:29:09 [INFO]: Epoch 002 - training loss: 0.9328, validation loss: 0.1474
2024-05-24 19:29:10 [INFO]: Epoch 003 - training loss: 0.7868, validation loss: 0.1077
2024-05-24 19:29:10 [INFO]: Epoch 004 - training loss: 0.7301, validation loss: 0.1055
2024-05-24 19:29:10 [INFO]: Epoch 005 - training loss: 0.7001, validation loss: 0.0801
2024-05-24 19:29:11 [INFO]: Epoch 006 - training loss: 0.6872, validation loss: 0.0793
2024-05-24 19:29:11 [INFO]: Epoch 007 - training loss: 0.6537, validation loss: 0.0707
2024-05-24 19:29:12 [INFO]: Epoch 008 - training loss: 0.6304, validation loss: 0.0832
2024-05-24 19:29:12 [INFO]: Epoch 009 - training loss: 0.6305, validation loss: 0.0631
2024-05-24 19:29:13 [INFO]: Epoch 010 - training loss: 0.6174, validation loss: 0.0740
2024-05-24 19:29:13 [INFO]: Epoch 011 - training loss: 0.5963, validation loss: 0.0732
2024-05-24 19:29:14 [INFO]: Epoch 012 - training loss: 0.5750, validation loss: 0.0619
2024-05-24 19:29:14 [INFO]: Epoch 013 - training loss: 0.5730, validation loss: 0.0511
2024-05-24 19:29:15 [INFO]: Epoch 014 - training loss: 0.5693, validation loss: 0.0475
2024-05-24 19:29:15 [INFO]: Epoch 015 - training loss: 0.5596, validation loss: 0.0535
2024-05-24 19:29:16 [INFO]: Epoch 016 - training loss: 0.5591, validation loss: 0.0519
2024-05-24 19:29:16 [INFO]: Epoch 017 - training loss: 0.5715, validation loss: 0.0526
2024-05-24 19:29:17 [INFO]: Epoch 018 - training loss: 0.5376, validation loss: 0.0486
2024-05-24 19:29:17 [INFO]: Epoch 019 - training loss: 0.5594, validation loss: 0.0489
2024-05-24 19:29:18 [INFO]: Epoch 020 - training loss: 0.5363, validation loss: 0.0520
2024-05-24 19:29:18 [INFO]: Epoch 021 - training loss: 0.5301, validation loss: 0.0463
2024-05-24 19:29:19 [INFO]: Epoch 022 - training loss: 0.5243, validation loss: 0.0501
2024-05-24 19:29:19 [INFO]: Epoch 023 - training loss: 0.5075, validation loss: 0.0591
2024-05-24 19:29:20 [INFO]: Epoch 024 - training loss: 0.5129, validation loss: 0.0649
2024-05-24 19:29:20 [INFO]: Epoch 025 - training loss: 0.5072, validation loss: 0.0459
2024-05-24 19:29:21 [INFO]: Epoch 026 - training loss: 0.5131, validation loss: 0.0410
2024-05-24 19:29:21 [INFO]: Epoch 027 - training loss: 0.5016, validation loss: 0.0419
2024-05-24 19:29:21 [INFO]: Epoch 028 - training loss: 0.4904, validation loss: 0.0418
2024-05-24 19:29:22 [INFO]: Epoch 029 - training loss: 0.4808, validation loss: 0.0371
2024-05-24 19:29:22 [INFO]: Epoch 030 - training loss: 0.4903, validation loss: 0.0512
2024-05-24 19:29:23 [INFO]: Epoch 031 - training loss: 0.5072, validation loss: 0.0367
2024-05-24 19:29:23 [INFO]: Epoch 032 - training loss: 0.4901, validation loss: 0.0392
2024-05-24 19:29:24 [INFO]: Epoch 033 - training loss: 0.4727, validation loss: 0.0431
2024-05-24 19:29:24 [INFO]: Epoch 034 - training loss: 0.4707, validation loss: 0.0451
2024-05-24 19:29:25 [INFO]: Epoch 035 - training loss: 0.4691, validation loss: 0.0437
2024-05-24 19:29:25 [INFO]: Epoch 036 - training loss: 0.4552, validation loss: 0.0451
2024-05-24 19:29:26 [INFO]: Epoch 037 - training loss: 0.4503, validation loss: 0.0408
2024-05-24 19:29:26 [INFO]: Epoch 038 - training loss: 0.4464, validation loss: 0.0373
2024-05-24 19:29:27 [INFO]: Epoch 039 - training loss: 0.4358, validation loss: 0.0348
2024-05-24 19:29:27 [INFO]: Epoch 040 - training loss: 0.4335, validation loss: 0.0405
2024-05-24 19:29:28 [INFO]: Epoch 041 - training loss: 0.4312, validation loss: 0.0388
2024-05-24 19:29:28 [INFO]: Epoch 042 - training loss: 0.4096, validation loss: 0.0396
2024-05-24 19:29:29 [INFO]: Epoch 043 - training loss: 0.4076, validation loss: 0.0641
2024-05-24 19:29:29 [INFO]: Epoch 044 - training loss: 0.4229, validation loss: 0.0615
2024-05-24 19:29:30 [INFO]: Epoch 045 - training loss: 0.4221, validation loss: 0.0585
2024-05-24 19:29:30 [INFO]: Epoch 046 - training loss: 0.4101, validation loss: 0.0548
2024-05-24 19:29:31 [INFO]: Epoch 047 - training loss: 0.4050, validation loss: 0.0444
2024-05-24 19:29:31 [INFO]: Epoch 048 - training loss: 0.3843, validation loss: 0.0468
2024-05-24 19:29:31 [INFO]: Epoch 049 - training loss: 0.3706, validation loss: 0.0409
2024-05-24 19:29:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:29:31 [INFO]: Finished training. The best model is from epoch#39.
2024-05-24 19:29:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/SAITS_ettm1/20240524_T192858/SAITS.pypots
2024-05-24 19:29:32 [INFO]: SAITS on ETTm1: MAE=0.1567, MSE=0.0501
2024-05-24 19:29:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/SAITS_ettm1/imputation.pkl
2024-05-24 19:29:32 [INFO]: Using the given device: cuda:0
2024-05-24 19:29:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T192932
2024-05-24 19:29:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T192932/tensorboard
2024-05-24 19:29:32 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 19:29:32 [INFO]: Epoch 001 - training loss: 1.1843, validation loss: 0.3368
2024-05-24 19:29:32 [INFO]: Epoch 002 - training loss: 0.7129, validation loss: 0.1919
2024-05-24 19:29:32 [INFO]: Epoch 003 - training loss: 0.5683, validation loss: 0.1413
2024-05-24 19:29:32 [INFO]: Epoch 004 - training loss: 0.5193, validation loss: 0.1164
2024-05-24 19:29:33 [INFO]: Epoch 005 - training loss: 0.4817, validation loss: 0.1052
2024-05-24 19:29:33 [INFO]: Epoch 006 - training loss: 0.4575, validation loss: 0.0828
2024-05-24 19:29:33 [INFO]: Epoch 007 - training loss: 0.4282, validation loss: 0.0787
2024-05-24 19:29:33 [INFO]: Epoch 008 - training loss: 0.4118, validation loss: 0.0694
2024-05-24 19:29:33 [INFO]: Epoch 009 - training loss: 0.3962, validation loss: 0.0672
2024-05-24 19:29:34 [INFO]: Epoch 010 - training loss: 0.3873, validation loss: 0.0623
2024-05-24 19:29:34 [INFO]: Epoch 011 - training loss: 0.3764, validation loss: 0.0654
2024-05-24 19:29:34 [INFO]: Epoch 012 - training loss: 0.3667, validation loss: 0.0695
2024-05-24 19:29:34 [INFO]: Epoch 013 - training loss: 0.3658, validation loss: 0.0553
2024-05-24 19:29:34 [INFO]: Epoch 014 - training loss: 0.3465, validation loss: 0.0514
2024-05-24 19:29:35 [INFO]: Epoch 015 - training loss: 0.3448, validation loss: 0.0500
2024-05-24 19:29:35 [INFO]: Epoch 016 - training loss: 0.3427, validation loss: 0.0495
2024-05-24 19:29:35 [INFO]: Epoch 017 - training loss: 0.3308, validation loss: 0.0524
2024-05-24 19:29:35 [INFO]: Epoch 018 - training loss: 0.3256, validation loss: 0.0478
2024-05-24 19:29:35 [INFO]: Epoch 019 - training loss: 0.3182, validation loss: 0.0426
2024-05-24 19:29:35 [INFO]: Epoch 020 - training loss: 0.3081, validation loss: 0.0430
2024-05-24 19:29:36 [INFO]: Epoch 021 - training loss: 0.3051, validation loss: 0.0404
2024-05-24 19:29:36 [INFO]: Epoch 022 - training loss: 0.3019, validation loss: 0.0456
2024-05-24 19:29:36 [INFO]: Epoch 023 - training loss: 0.3041, validation loss: 0.0438
2024-05-24 19:29:36 [INFO]: Epoch 024 - training loss: 0.3004, validation loss: 0.0418
2024-05-24 19:29:36 [INFO]: Epoch 025 - training loss: 0.2970, validation loss: 0.0439
2024-05-24 19:29:37 [INFO]: Epoch 026 - training loss: 0.2918, validation loss: 0.0393
2024-05-24 19:29:37 [INFO]: Epoch 027 - training loss: 0.2800, validation loss: 0.0382
2024-05-24 19:29:37 [INFO]: Epoch 028 - training loss: 0.2808, validation loss: 0.0371
2024-05-24 19:29:37 [INFO]: Epoch 029 - training loss: 0.2800, validation loss: 0.0371
2024-05-24 19:29:37 [INFO]: Epoch 030 - training loss: 0.2765, validation loss: 0.0414
2024-05-24 19:29:38 [INFO]: Epoch 031 - training loss: 0.2740, validation loss: 0.0349
2024-05-24 19:29:38 [INFO]: Epoch 032 - training loss: 0.2647, validation loss: 0.0361
2024-05-24 19:29:38 [INFO]: Epoch 033 - training loss: 0.2669, validation loss: 0.0343
2024-05-24 19:29:38 [INFO]: Epoch 034 - training loss: 0.2597, validation loss: 0.0340
2024-05-24 19:29:38 [INFO]: Epoch 035 - training loss: 0.2608, validation loss: 0.0328
2024-05-24 19:29:38 [INFO]: Epoch 036 - training loss: 0.2599, validation loss: 0.0347
2024-05-24 19:29:39 [INFO]: Epoch 037 - training loss: 0.2531, validation loss: 0.0354
2024-05-24 19:29:39 [INFO]: Epoch 038 - training loss: 0.2550, validation loss: 0.0314
2024-05-24 19:29:39 [INFO]: Epoch 039 - training loss: 0.2477, validation loss: 0.0332
2024-05-24 19:29:39 [INFO]: Epoch 040 - training loss: 0.2438, validation loss: 0.0340
2024-05-24 19:29:39 [INFO]: Epoch 041 - training loss: 0.2416, validation loss: 0.0349
2024-05-24 19:29:40 [INFO]: Epoch 042 - training loss: 0.2436, validation loss: 0.0341
2024-05-24 19:29:40 [INFO]: Epoch 043 - training loss: 0.2425, validation loss: 0.0352
2024-05-24 19:29:40 [INFO]: Epoch 044 - training loss: 0.2388, validation loss: 0.0310
2024-05-24 19:29:40 [INFO]: Epoch 045 - training loss: 0.2341, validation loss: 0.0329
2024-05-24 19:29:40 [INFO]: Epoch 046 - training loss: 0.2345, validation loss: 0.0312
2024-05-24 19:29:41 [INFO]: Epoch 047 - training loss: 0.2330, validation loss: 0.0341
2024-05-24 19:29:41 [INFO]: Epoch 048 - training loss: 0.2330, validation loss: 0.0341
2024-05-24 19:29:41 [INFO]: Epoch 049 - training loss: 0.2263, validation loss: 0.0324
2024-05-24 19:29:41 [INFO]: Epoch 050 - training loss: 0.2333, validation loss: 0.0297
2024-05-24 19:29:41 [INFO]: Epoch 051 - training loss: 0.2246, validation loss: 0.0288
2024-05-24 19:29:41 [INFO]: Epoch 052 - training loss: 0.2205, validation loss: 0.0316
2024-05-24 19:29:42 [INFO]: Epoch 053 - training loss: 0.2224, validation loss: 0.0294
2024-05-24 19:29:42 [INFO]: Epoch 054 - training loss: 0.2198, validation loss: 0.0289
2024-05-24 19:29:42 [INFO]: Epoch 055 - training loss: 0.2178, validation loss: 0.0299
2024-05-24 19:29:42 [INFO]: Epoch 056 - training loss: 0.2171, validation loss: 0.0284
2024-05-24 19:29:42 [INFO]: Epoch 057 - training loss: 0.2151, validation loss: 0.0293
2024-05-24 19:29:43 [INFO]: Epoch 058 - training loss: 0.2147, validation loss: 0.0284
2024-05-24 19:29:43 [INFO]: Epoch 059 - training loss: 0.2148, validation loss: 0.0289
2024-05-24 19:29:43 [INFO]: Epoch 060 - training loss: 0.2122, validation loss: 0.0311
2024-05-24 19:29:43 [INFO]: Epoch 061 - training loss: 0.2178, validation loss: 0.0301
2024-05-24 19:29:43 [INFO]: Epoch 062 - training loss: 0.2115, validation loss: 0.0311
2024-05-24 19:29:44 [INFO]: Epoch 063 - training loss: 0.2181, validation loss: 0.0288
2024-05-24 19:29:44 [INFO]: Epoch 064 - training loss: 0.2079, validation loss: 0.0317
2024-05-24 19:29:44 [INFO]: Epoch 065 - training loss: 0.2187, validation loss: 0.0292
2024-05-24 19:29:44 [INFO]: Epoch 066 - training loss: 0.2105, validation loss: 0.0283
2024-05-24 19:29:44 [INFO]: Epoch 067 - training loss: 0.2095, validation loss: 0.0307
2024-05-24 19:29:45 [INFO]: Epoch 068 - training loss: 0.2111, validation loss: 0.0294
2024-05-24 19:29:45 [INFO]: Epoch 069 - training loss: 0.2080, validation loss: 0.0287
2024-05-24 19:29:45 [INFO]: Epoch 070 - training loss: 0.2035, validation loss: 0.0282
2024-05-24 19:29:45 [INFO]: Epoch 071 - training loss: 0.2033, validation loss: 0.0259
2024-05-24 19:29:45 [INFO]: Epoch 072 - training loss: 0.2022, validation loss: 0.0272
2024-05-24 19:29:45 [INFO]: Epoch 073 - training loss: 0.1996, validation loss: 0.0272
2024-05-24 19:29:46 [INFO]: Epoch 074 - training loss: 0.2006, validation loss: 0.0258
2024-05-24 19:29:46 [INFO]: Epoch 075 - training loss: 0.1981, validation loss: 0.0256
2024-05-24 19:29:46 [INFO]: Epoch 076 - training loss: 0.1955, validation loss: 0.0276
2024-05-24 19:29:46 [INFO]: Epoch 077 - training loss: 0.1983, validation loss: 0.0299
2024-05-24 19:29:46 [INFO]: Epoch 078 - training loss: 0.1966, validation loss: 0.0273
2024-05-24 19:29:47 [INFO]: Epoch 079 - training loss: 0.1930, validation loss: 0.0299
2024-05-24 19:29:47 [INFO]: Epoch 080 - training loss: 0.1974, validation loss: 0.0302
2024-05-24 19:29:47 [INFO]: Epoch 081 - training loss: 0.2006, validation loss: 0.0273
2024-05-24 19:29:47 [INFO]: Epoch 082 - training loss: 0.1987, validation loss: 0.0255
2024-05-24 19:29:47 [INFO]: Epoch 083 - training loss: 0.1942, validation loss: 0.0274
2024-05-24 19:29:48 [INFO]: Epoch 084 - training loss: 0.1906, validation loss: 0.0276
2024-05-24 19:29:48 [INFO]: Epoch 085 - training loss: 0.1923, validation loss: 0.0306
2024-05-24 19:29:48 [INFO]: Epoch 086 - training loss: 0.1973, validation loss: 0.0284
2024-05-24 19:29:48 [INFO]: Epoch 087 - training loss: 0.1965, validation loss: 0.0252
2024-05-24 19:29:48 [INFO]: Epoch 088 - training loss: 0.1892, validation loss: 0.0259
2024-05-24 19:29:48 [INFO]: Epoch 089 - training loss: 0.1911, validation loss: 0.0252
2024-05-24 19:29:49 [INFO]: Epoch 090 - training loss: 0.1897, validation loss: 0.0259
2024-05-24 19:29:49 [INFO]: Epoch 091 - training loss: 0.1872, validation loss: 0.0245
2024-05-24 19:29:49 [INFO]: Epoch 092 - training loss: 0.1821, validation loss: 0.0262
2024-05-24 19:29:49 [INFO]: Epoch 093 - training loss: 0.1867, validation loss: 0.0245
2024-05-24 19:29:49 [INFO]: Epoch 094 - training loss: 0.1844, validation loss: 0.0251
2024-05-24 19:29:50 [INFO]: Epoch 095 - training loss: 0.1854, validation loss: 0.0250
2024-05-24 19:29:50 [INFO]: Epoch 096 - training loss: 0.1834, validation loss: 0.0255
2024-05-24 19:29:50 [INFO]: Epoch 097 - training loss: 0.1864, validation loss: 0.0278
2024-05-24 19:29:50 [INFO]: Epoch 098 - training loss: 0.1892, validation loss: 0.0272
2024-05-24 19:29:50 [INFO]: Epoch 099 - training loss: 0.1953, validation loss: 0.0241
2024-05-24 19:29:51 [INFO]: Epoch 100 - training loss: 0.1846, validation loss: 0.0270
2024-05-24 19:29:51 [INFO]: Epoch 101 - training loss: 0.1857, validation loss: 0.0250
2024-05-24 19:29:51 [INFO]: Epoch 102 - training loss: 0.1828, validation loss: 0.0274
2024-05-24 19:29:51 [INFO]: Epoch 103 - training loss: 0.1895, validation loss: 0.0253
2024-05-24 19:29:51 [INFO]: Epoch 104 - training loss: 0.1848, validation loss: 0.0255
2024-05-24 19:29:51 [INFO]: Epoch 105 - training loss: 0.1890, validation loss: 0.0268
2024-05-24 19:29:52 [INFO]: Epoch 106 - training loss: 0.1910, validation loss: 0.0246
2024-05-24 19:29:52 [INFO]: Epoch 107 - training loss: 0.1852, validation loss: 0.0257
2024-05-24 19:29:52 [INFO]: Epoch 108 - training loss: 0.1803, validation loss: 0.0259
2024-05-24 19:29:52 [INFO]: Epoch 109 - training loss: 0.1783, validation loss: 0.0273
2024-05-24 19:29:52 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:29:52 [INFO]: Finished training. The best model is from epoch#99.
2024-05-24 19:29:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/Transformer_ettm1/20240524_T192932/Transformer.pypots
2024-05-24 19:29:52 [INFO]: Transformer on ETTm1: MAE=0.1467, MSE=0.0405
2024-05-24 19:29:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Transformer_ettm1/imputation.pkl
2024-05-24 19:29:52 [INFO]: Using the given device: cuda:0
2024-05-24 19:29:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T192952
2024-05-24 19:29:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T192952/tensorboard
2024-05-24 19:29:52 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 19:29:59 [INFO]: Epoch 001 - training loss: 0.1516, validation loss: 0.0513
2024-05-24 19:30:00 [INFO]: Epoch 002 - training loss: 0.0673, validation loss: 0.0412
2024-05-24 19:30:00 [INFO]: Epoch 003 - training loss: 0.0560, validation loss: 0.0344
2024-05-24 19:30:00 [INFO]: Epoch 004 - training loss: 0.0461, validation loss: 0.0328
2024-05-24 19:30:00 [INFO]: Epoch 005 - training loss: 0.0439, validation loss: 0.0330
2024-05-24 19:30:00 [INFO]: Epoch 006 - training loss: 0.0438, validation loss: 0.0329
2024-05-24 19:30:01 [INFO]: Epoch 007 - training loss: 0.0443, validation loss: 0.0318
2024-05-24 19:30:01 [INFO]: Epoch 008 - training loss: 0.0425, validation loss: 0.0307
2024-05-24 19:30:01 [INFO]: Epoch 009 - training loss: 0.0386, validation loss: 0.0290
2024-05-24 19:30:01 [INFO]: Epoch 010 - training loss: 0.0376, validation loss: 0.0295
2024-05-24 19:30:01 [INFO]: Epoch 011 - training loss: 0.0389, validation loss: 0.0311
2024-05-24 19:30:01 [INFO]: Epoch 012 - training loss: 0.0379, validation loss: 0.0294
2024-05-24 19:30:02 [INFO]: Epoch 013 - training loss: 0.0358, validation loss: 0.0282
2024-05-24 19:30:02 [INFO]: Epoch 014 - training loss: 0.0388, validation loss: 0.0306
2024-05-24 19:30:02 [INFO]: Epoch 015 - training loss: 0.0426, validation loss: 0.0287
2024-05-24 19:30:02 [INFO]: Epoch 016 - training loss: 0.0371, validation loss: 0.0286
2024-05-24 19:30:02 [INFO]: Epoch 017 - training loss: 0.0347, validation loss: 0.0273
2024-05-24 19:30:03 [INFO]: Epoch 018 - training loss: 0.0352, validation loss: 0.0277
2024-05-24 19:30:03 [INFO]: Epoch 019 - training loss: 0.0355, validation loss: 0.0272
2024-05-24 19:30:03 [INFO]: Epoch 020 - training loss: 0.0335, validation loss: 0.0271
2024-05-24 19:30:03 [INFO]: Epoch 021 - training loss: 0.0313, validation loss: 0.0275
2024-05-24 19:30:03 [INFO]: Epoch 022 - training loss: 0.0335, validation loss: 0.0278
2024-05-24 19:30:03 [INFO]: Epoch 023 - training loss: 0.0343, validation loss: 0.0272
2024-05-24 19:30:04 [INFO]: Epoch 024 - training loss: 0.0308, validation loss: 0.0273
2024-05-24 19:30:04 [INFO]: Epoch 025 - training loss: 0.0321, validation loss: 0.0271
2024-05-24 19:30:04 [INFO]: Epoch 026 - training loss: 0.0330, validation loss: 0.0269
2024-05-24 19:30:04 [INFO]: Epoch 027 - training loss: 0.0345, validation loss: 0.0272
2024-05-24 19:30:04 [INFO]: Epoch 028 - training loss: 0.0299, validation loss: 0.0267
2024-05-24 19:30:04 [INFO]: Epoch 029 - training loss: 0.0300, validation loss: 0.0261
2024-05-24 19:30:05 [INFO]: Epoch 030 - training loss: 0.0306, validation loss: 0.0275
2024-05-24 19:30:05 [INFO]: Epoch 031 - training loss: 0.0324, validation loss: 0.0274
2024-05-24 19:30:05 [INFO]: Epoch 032 - training loss: 0.0301, validation loss: 0.0263
2024-05-24 19:30:05 [INFO]: Epoch 033 - training loss: 0.0299, validation loss: 0.0266
2024-05-24 19:30:05 [INFO]: Epoch 034 - training loss: 0.0288, validation loss: 0.0259
2024-05-24 19:30:06 [INFO]: Epoch 035 - training loss: 0.0281, validation loss: 0.0261
2024-05-24 19:30:06 [INFO]: Epoch 036 - training loss: 0.0276, validation loss: 0.0255
2024-05-24 19:30:06 [INFO]: Epoch 037 - training loss: 0.0256, validation loss: 0.0256
2024-05-24 19:30:06 [INFO]: Epoch 038 - training loss: 0.0265, validation loss: 0.0260
2024-05-24 19:30:06 [INFO]: Epoch 039 - training loss: 0.0271, validation loss: 0.0256
2024-05-24 19:30:06 [INFO]: Epoch 040 - training loss: 0.0250, validation loss: 0.0260
2024-05-24 19:30:07 [INFO]: Epoch 041 - training loss: 0.0250, validation loss: 0.0257
2024-05-24 19:30:07 [INFO]: Epoch 042 - training loss: 0.0259, validation loss: 0.0258
2024-05-24 19:30:07 [INFO]: Epoch 043 - training loss: 0.0280, validation loss: 0.0290
2024-05-24 19:30:07 [INFO]: Epoch 044 - training loss: 0.0329, validation loss: 0.0281
2024-05-24 19:30:07 [INFO]: Epoch 045 - training loss: 0.0265, validation loss: 0.0263
2024-05-24 19:30:08 [INFO]: Epoch 046 - training loss: 0.0249, validation loss: 0.0254
2024-05-24 19:30:08 [INFO]: Epoch 047 - training loss: 0.0237, validation loss: 0.0258
2024-05-24 19:30:08 [INFO]: Epoch 048 - training loss: 0.0246, validation loss: 0.0258
2024-05-24 19:30:08 [INFO]: Epoch 049 - training loss: 0.0231, validation loss: 0.0261
2024-05-24 19:30:08 [INFO]: Epoch 050 - training loss: 0.0248, validation loss: 0.0258
2024-05-24 19:30:08 [INFO]: Epoch 051 - training loss: 0.0227, validation loss: 0.0253
2024-05-24 19:30:09 [INFO]: Epoch 052 - training loss: 0.0221, validation loss: 0.0252
2024-05-24 19:30:09 [INFO]: Epoch 053 - training loss: 0.0216, validation loss: 0.0260
2024-05-24 19:30:09 [INFO]: Epoch 054 - training loss: 0.0212, validation loss: 0.0262
2024-05-24 19:30:09 [INFO]: Epoch 055 - training loss: 0.0208, validation loss: 0.0259
2024-05-24 19:30:09 [INFO]: Epoch 056 - training loss: 0.0207, validation loss: 0.0256
2024-05-24 19:30:10 [INFO]: Epoch 057 - training loss: 0.0202, validation loss: 0.0262
2024-05-24 19:30:10 [INFO]: Epoch 058 - training loss: 0.0215, validation loss: 0.0276
2024-05-24 19:30:10 [INFO]: Epoch 059 - training loss: 0.0233, validation loss: 0.0267
2024-05-24 19:30:10 [INFO]: Epoch 060 - training loss: 0.0207, validation loss: 0.0260
2024-05-24 19:30:10 [INFO]: Epoch 061 - training loss: 0.0191, validation loss: 0.0257
2024-05-24 19:30:10 [INFO]: Epoch 062 - training loss: 0.0189, validation loss: 0.0261
2024-05-24 19:30:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:30:10 [INFO]: Finished training. The best model is from epoch#52.
2024-05-24 19:30:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/TimesNet_ettm1/20240524_T192952/TimesNet.pypots
2024-05-24 19:30:11 [INFO]: TimesNet on ETTm1: MAE=0.1152, MSE=0.0288
2024-05-24 19:30:11 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/TimesNet_ettm1/imputation.pkl
2024-05-24 19:30:11 [INFO]: Using the given device: cuda:0
2024-05-24 19:30:11 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011
2024-05-24 19:30:11 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/tensorboard
2024-05-24 19:30:11 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 19:30:14 [INFO]: Epoch 001 - training loss: 0.6776, validation loss: 0.4055
2024-05-24 19:30:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch1_loss0.40546006709337234.pypots
2024-05-24 19:30:16 [INFO]: Epoch 002 - training loss: 0.3754, validation loss: 0.3751
2024-05-24 19:30:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch2_loss0.375070720911026.pypots
2024-05-24 19:30:18 [INFO]: Epoch 003 - training loss: 0.3725, validation loss: 0.3251
2024-05-24 19:30:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch3_loss0.3250787928700447.pypots
2024-05-24 19:30:20 [INFO]: Epoch 004 - training loss: 0.2991, validation loss: 0.2904
2024-05-24 19:30:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch4_loss0.29040171205997467.pypots
2024-05-24 19:30:22 [INFO]: Epoch 005 - training loss: 0.2953, validation loss: 0.2737
2024-05-24 19:30:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch5_loss0.27370529621839523.pypots
2024-05-24 19:30:24 [INFO]: Epoch 006 - training loss: 0.2460, validation loss: 0.2637
2024-05-24 19:30:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch6_loss0.2637128606438637.pypots
2024-05-24 19:30:26 [INFO]: Epoch 007 - training loss: 0.2485, validation loss: 0.2548
2024-05-24 19:30:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch7_loss0.25481776520609856.pypots
2024-05-24 19:30:28 [INFO]: Epoch 008 - training loss: 0.2418, validation loss: 0.2457
2024-05-24 19:30:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch8_loss0.24565069004893303.pypots
2024-05-24 19:30:30 [INFO]: Epoch 009 - training loss: 0.2559, validation loss: 0.2612
2024-05-24 19:30:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch9_loss0.26116374135017395.pypots
2024-05-24 19:30:32 [INFO]: Epoch 010 - training loss: 0.2704, validation loss: 0.2369
2024-05-24 19:30:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch10_loss0.23692309111356735.pypots
2024-05-24 19:30:34 [INFO]: Epoch 011 - training loss: 0.2333, validation loss: 0.2264
2024-05-24 19:30:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch11_loss0.22644726932048798.pypots
2024-05-24 19:30:36 [INFO]: Epoch 012 - training loss: 0.2487, validation loss: 0.2223
2024-05-24 19:30:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch12_loss0.22234714031219482.pypots
2024-05-24 19:30:38 [INFO]: Epoch 013 - training loss: 0.2201, validation loss: 0.2117
2024-05-24 19:30:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch13_loss0.21167878061532974.pypots
2024-05-24 19:30:40 [INFO]: Epoch 014 - training loss: 0.2239, validation loss: 0.2127
2024-05-24 19:30:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch14_loss0.21266422048211098.pypots
2024-05-24 19:30:42 [INFO]: Epoch 015 - training loss: 0.2264, validation loss: 0.2095
2024-05-24 19:30:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch15_loss0.2095480039715767.pypots
2024-05-24 19:30:44 [INFO]: Epoch 016 - training loss: 0.2305, validation loss: 0.2092
2024-05-24 19:30:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch16_loss0.20921869203448296.pypots
2024-05-24 19:30:46 [INFO]: Epoch 017 - training loss: 0.2507, validation loss: 0.1985
2024-05-24 19:30:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch17_loss0.19851497933268547.pypots
2024-05-24 19:30:48 [INFO]: Epoch 018 - training loss: 0.2779, validation loss: 0.2306
2024-05-24 19:30:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch18_loss0.23056909069418907.pypots
2024-05-24 19:30:50 [INFO]: Epoch 019 - training loss: 0.2302, validation loss: 0.2182
2024-05-24 19:30:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch19_loss0.2182018682360649.pypots
2024-05-24 19:30:52 [INFO]: Epoch 020 - training loss: 0.2003, validation loss: 0.1915
2024-05-24 19:30:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch20_loss0.19146009534597397.pypots
2024-05-24 19:30:54 [INFO]: Epoch 021 - training loss: 0.1945, validation loss: 0.1825
2024-05-24 19:30:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch21_loss0.18249526992440224.pypots
2024-05-24 19:30:56 [INFO]: Epoch 022 - training loss: 0.1860, validation loss: 0.1751
2024-05-24 19:30:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch22_loss0.1750769279897213.pypots
2024-05-24 19:30:58 [INFO]: Epoch 023 - training loss: 0.2116, validation loss: 0.1866
2024-05-24 19:30:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch23_loss0.18662646785378456.pypots
2024-05-24 19:31:00 [INFO]: Epoch 024 - training loss: 0.2271, validation loss: 0.1891
2024-05-24 19:31:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch24_loss0.18908511474728584.pypots
2024-05-24 19:31:02 [INFO]: Epoch 025 - training loss: 0.2720, validation loss: 0.1770
2024-05-24 19:31:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch25_loss0.1770045980811119.pypots
2024-05-24 19:31:04 [INFO]: Epoch 026 - training loss: 0.1724, validation loss: 0.1655
2024-05-24 19:31:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch26_loss0.165545292198658.pypots
2024-05-24 19:31:06 [INFO]: Epoch 027 - training loss: 0.1766, validation loss: 0.1620
2024-05-24 19:31:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch27_loss0.1620321311056614.pypots
2024-05-24 19:31:08 [INFO]: Epoch 028 - training loss: 0.1573, validation loss: 0.1572
2024-05-24 19:31:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch28_loss0.157227274030447.pypots
2024-05-24 19:31:10 [INFO]: Epoch 029 - training loss: 0.1672, validation loss: 0.1539
2024-05-24 19:31:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch29_loss0.15387045964598656.pypots
2024-05-24 19:31:12 [INFO]: Epoch 030 - training loss: 0.1778, validation loss: 0.1534
2024-05-24 19:31:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch30_loss0.15343184769153595.pypots
2024-05-24 19:31:14 [INFO]: Epoch 031 - training loss: 0.1672, validation loss: 0.1653
2024-05-24 19:31:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch31_loss0.1652578003704548.pypots
2024-05-24 19:31:17 [INFO]: Epoch 032 - training loss: 0.1819, validation loss: 0.1597
2024-05-24 19:31:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch32_loss0.15970095619559288.pypots
2024-05-24 19:31:19 [INFO]: Epoch 033 - training loss: 0.1407, validation loss: 0.1505
2024-05-24 19:31:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch33_loss0.15054098144173622.pypots
2024-05-24 19:31:21 [INFO]: Epoch 034 - training loss: 0.1533, validation loss: 0.1477
2024-05-24 19:31:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch34_loss0.14767781645059586.pypots
2024-05-24 19:31:23 [INFO]: Epoch 035 - training loss: 0.1686, validation loss: 0.1491
2024-05-24 19:31:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch35_loss0.14906591922044754.pypots
2024-05-24 19:31:25 [INFO]: Epoch 036 - training loss: 0.1592, validation loss: 0.1441
2024-05-24 19:31:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch36_loss0.14406315982341766.pypots
2024-05-24 19:31:27 [INFO]: Epoch 037 - training loss: 0.1711, validation loss: 0.1608
2024-05-24 19:31:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch37_loss0.16080091148614883.pypots
2024-05-24 19:31:29 [INFO]: Epoch 038 - training loss: 0.1712, validation loss: 0.1530
2024-05-24 19:31:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch38_loss0.15297244116663933.pypots
2024-05-24 19:31:31 [INFO]: Epoch 039 - training loss: 0.1546, validation loss: 0.1427
2024-05-24 19:31:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch39_loss0.1427140198647976.pypots
2024-05-24 19:31:33 [INFO]: Epoch 040 - training loss: 0.1587, validation loss: 0.1385
2024-05-24 19:31:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch40_loss0.13845695927739143.pypots
2024-05-24 19:31:35 [INFO]: Epoch 041 - training loss: 0.1520, validation loss: 0.1434
2024-05-24 19:31:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch41_loss0.14337913691997528.pypots
2024-05-24 19:31:37 [INFO]: Epoch 042 - training loss: 0.1499, validation loss: 0.1524
2024-05-24 19:31:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch42_loss0.15238406509160995.pypots
2024-05-24 19:31:39 [INFO]: Epoch 043 - training loss: 0.1518, validation loss: 0.1396
2024-05-24 19:31:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch43_loss0.13956869393587112.pypots
2024-05-24 19:31:41 [INFO]: Epoch 044 - training loss: 0.1380, validation loss: 0.1391
2024-05-24 19:31:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch44_loss0.13909706473350525.pypots
2024-05-24 19:31:43 [INFO]: Epoch 045 - training loss: 0.1865, validation loss: 0.1390
2024-05-24 19:31:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch45_loss0.13897213339805603.pypots
2024-05-24 19:31:45 [INFO]: Epoch 046 - training loss: 0.1539, validation loss: 0.1506
2024-05-24 19:31:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch46_loss0.150625579059124.pypots
2024-05-24 19:31:47 [INFO]: Epoch 047 - training loss: 0.1539, validation loss: 0.1462
2024-05-24 19:31:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch47_loss0.14621050283312798.pypots
2024-05-24 19:31:49 [INFO]: Epoch 048 - training loss: 0.1345, validation loss: 0.1424
2024-05-24 19:31:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch48_loss0.14243299886584282.pypots
2024-05-24 19:31:51 [INFO]: Epoch 049 - training loss: 0.1276, validation loss: 0.1379
2024-05-24 19:31:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch49_loss0.13788913935422897.pypots
2024-05-24 19:31:53 [INFO]: Epoch 050 - training loss: 0.1324, validation loss: 0.1363
2024-05-24 19:31:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch50_loss0.13628583028912544.pypots
2024-05-24 19:31:55 [INFO]: Epoch 051 - training loss: 0.1582, validation loss: 0.1327
2024-05-24 19:31:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch51_loss0.13272282108664513.pypots
2024-05-24 19:31:57 [INFO]: Epoch 052 - training loss: 0.1462, validation loss: 0.1325
2024-05-24 19:31:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch52_loss0.13249364867806435.pypots
2024-05-24 19:31:59 [INFO]: Epoch 053 - training loss: 0.1403, validation loss: 0.1341
2024-05-24 19:31:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch53_loss0.13411381840705872.pypots
2024-05-24 19:32:01 [INFO]: Epoch 054 - training loss: 0.1587, validation loss: 0.1486
2024-05-24 19:32:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch54_loss0.1485789343714714.pypots
2024-05-24 19:32:03 [INFO]: Epoch 055 - training loss: 0.1508, validation loss: 0.1474
2024-05-24 19:32:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch55_loss0.14738861471414566.pypots
2024-05-24 19:32:06 [INFO]: Epoch 056 - training loss: 0.1432, validation loss: 0.1387
2024-05-24 19:32:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch56_loss0.13874737173318863.pypots
2024-05-24 19:32:08 [INFO]: Epoch 057 - training loss: 0.1553, validation loss: 0.1304
2024-05-24 19:32:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch57_loss0.1303760316222906.pypots
2024-05-24 19:32:10 [INFO]: Epoch 058 - training loss: 0.1484, validation loss: 0.1289
2024-05-24 19:32:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch58_loss0.12889214977622032.pypots
2024-05-24 19:32:12 [INFO]: Epoch 059 - training loss: 0.1447, validation loss: 0.1281
2024-05-24 19:32:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch59_loss0.12809851579368114.pypots
2024-05-24 19:32:14 [INFO]: Epoch 060 - training loss: 0.1208, validation loss: 0.1271
2024-05-24 19:32:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch60_loss0.1271264422684908.pypots
2024-05-24 19:32:16 [INFO]: Epoch 061 - training loss: 0.1481, validation loss: 0.1278
2024-05-24 19:32:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch61_loss0.1278306096792221.pypots
2024-05-24 19:32:18 [INFO]: Epoch 062 - training loss: 0.1419, validation loss: 0.1266
2024-05-24 19:32:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch62_loss0.1265628281980753.pypots
2024-05-24 19:32:20 [INFO]: Epoch 063 - training loss: 0.1440, validation loss: 0.1277
2024-05-24 19:32:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch63_loss0.12766997329890728.pypots
2024-05-24 19:32:22 [INFO]: Epoch 064 - training loss: 0.1321, validation loss: 0.1301
2024-05-24 19:32:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch64_loss0.13011720590293407.pypots
2024-05-24 19:32:24 [INFO]: Epoch 065 - training loss: 0.1259, validation loss: 0.1254
2024-05-24 19:32:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch65_loss0.1254196409136057.pypots
2024-05-24 19:32:26 [INFO]: Epoch 066 - training loss: 0.1324, validation loss: 0.1259
2024-05-24 19:32:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch66_loss0.12591392546892166.pypots
2024-05-24 19:32:28 [INFO]: Epoch 067 - training loss: 0.1359, validation loss: 0.1303
2024-05-24 19:32:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch67_loss0.130317110568285.pypots
2024-05-24 19:32:30 [INFO]: Epoch 068 - training loss: 0.1195, validation loss: 0.1274
2024-05-24 19:32:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch68_loss0.12743121199309826.pypots
2024-05-24 19:32:32 [INFO]: Epoch 069 - training loss: 0.1694, validation loss: 0.1286
2024-05-24 19:32:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch69_loss0.1286169681698084.pypots
2024-05-24 19:32:34 [INFO]: Epoch 070 - training loss: 0.1311, validation loss: 0.1372
2024-05-24 19:32:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch70_loss0.13718331605196.pypots
2024-05-24 19:32:36 [INFO]: Epoch 071 - training loss: 0.1295, validation loss: 0.1297
2024-05-24 19:32:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch71_loss0.12966731004416943.pypots
2024-05-24 19:32:38 [INFO]: Epoch 072 - training loss: 0.1614, validation loss: 0.1541
2024-05-24 19:32:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch72_loss0.154117614030838.pypots
2024-05-24 19:32:40 [INFO]: Epoch 073 - training loss: 0.1639, validation loss: 0.1598
2024-05-24 19:32:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch73_loss0.15975098311901093.pypots
2024-05-24 19:32:43 [INFO]: Epoch 074 - training loss: 0.1393, validation loss: 0.1514
2024-05-24 19:32:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch74_loss0.1513901986181736.pypots
2024-05-24 19:32:45 [INFO]: Epoch 075 - training loss: 0.1423, validation loss: 0.1348
2024-05-24 19:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI_epoch75_loss0.1348443329334259.pypots
2024-05-24 19:32:45 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:32:45 [INFO]: Finished training. The best model is from epoch#65.
2024-05-24 19:32:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/CSDI_ettm1/20240524_T193011/CSDI.pypots
2024-05-24 19:33:00 [INFO]: CSDI on ETTm1: MAE=0.1325, MSE=0.0488
2024-05-24 19:33:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/CSDI_ettm1/imputation.pkl
2024-05-24 19:33:00 [INFO]: Using the given device: cuda:0
2024-05-24 19:33:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T193300
2024-05-24 19:33:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T193300/tensorboard
2024-05-24 19:33:00 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 19:33:02 [INFO]: Epoch 001 - training loss: 23961.3182, validation loss: 1.0039
2024-05-24 19:33:02 [INFO]: Epoch 002 - training loss: 22159.0964, validation loss: 0.9954
2024-05-24 19:33:02 [INFO]: Epoch 003 - training loss: 20194.3459, validation loss: 0.9811
2024-05-24 19:33:02 [INFO]: Epoch 004 - training loss: 18518.3428, validation loss: 0.9686
2024-05-24 19:33:03 [INFO]: Epoch 005 - training loss: 16598.0700, validation loss: 0.9357
2024-05-24 19:33:03 [INFO]: Epoch 006 - training loss: 14831.2218, validation loss: 0.8593
2024-05-24 19:33:03 [INFO]: Epoch 007 - training loss: 13397.7763, validation loss: 0.7313
2024-05-24 19:33:03 [INFO]: Epoch 008 - training loss: 12487.8142, validation loss: 0.6167
2024-05-24 19:33:03 [INFO]: Epoch 009 - training loss: 11893.2642, validation loss: 0.5731
2024-05-24 19:33:03 [INFO]: Epoch 010 - training loss: 11215.7726, validation loss: 0.5384
2024-05-24 19:33:03 [INFO]: Epoch 011 - training loss: 10893.0199, validation loss: 0.4954
2024-05-24 19:33:03 [INFO]: Epoch 012 - training loss: 10568.1835, validation loss: 0.4871
2024-05-24 19:33:04 [INFO]: Epoch 013 - training loss: 10400.7539, validation loss: 0.4794
2024-05-24 19:33:04 [INFO]: Epoch 014 - training loss: 10209.2012, validation loss: 0.4544
2024-05-24 19:33:04 [INFO]: Epoch 015 - training loss: 10055.6490, validation loss: 0.4406
2024-05-24 19:33:04 [INFO]: Epoch 016 - training loss: 9953.4747, validation loss: 0.4304
2024-05-24 19:33:04 [INFO]: Epoch 017 - training loss: 9892.8993, validation loss: 0.4123
2024-05-24 19:33:04 [INFO]: Epoch 018 - training loss: 9844.3820, validation loss: 0.4013
2024-05-24 19:33:04 [INFO]: Epoch 019 - training loss: 9750.0691, validation loss: 0.3813
2024-05-24 19:33:04 [INFO]: Epoch 020 - training loss: 9700.7193, validation loss: 0.3639
2024-05-24 19:33:04 [INFO]: Epoch 021 - training loss: 9699.8475, validation loss: 0.3538
2024-05-24 19:33:05 [INFO]: Epoch 022 - training loss: 9649.5854, validation loss: 0.3452
2024-05-24 19:33:05 [INFO]: Epoch 023 - training loss: 9604.4556, validation loss: 0.3434
2024-05-24 19:33:05 [INFO]: Epoch 024 - training loss: 9592.7650, validation loss: 0.3381
2024-05-24 19:33:05 [INFO]: Epoch 025 - training loss: 9532.0794, validation loss: 0.3371
2024-05-24 19:33:05 [INFO]: Epoch 026 - training loss: 9509.1438, validation loss: 0.3389
2024-05-24 19:33:05 [INFO]: Epoch 027 - training loss: 9533.2271, validation loss: 0.3237
2024-05-24 19:33:05 [INFO]: Epoch 028 - training loss: 9483.9200, validation loss: 0.3281
2024-05-24 19:33:05 [INFO]: Epoch 029 - training loss: 9451.9570, validation loss: 0.3206
2024-05-24 19:33:06 [INFO]: Epoch 030 - training loss: 9460.4282, validation loss: 0.3192
2024-05-24 19:33:06 [INFO]: Epoch 031 - training loss: 9424.0565, validation loss: 0.3210
2024-05-24 19:33:06 [INFO]: Epoch 032 - training loss: 9421.8085, validation loss: 0.3244
2024-05-24 19:33:06 [INFO]: Epoch 033 - training loss: 9408.3268, validation loss: 0.3217
2024-05-24 19:33:06 [INFO]: Epoch 034 - training loss: 9400.1066, validation loss: 0.3198
2024-05-24 19:33:06 [INFO]: Epoch 035 - training loss: 9383.6417, validation loss: 0.3174
2024-05-24 19:33:06 [INFO]: Epoch 036 - training loss: 9382.4525, validation loss: 0.3064
2024-05-24 19:33:06 [INFO]: Epoch 037 - training loss: 9401.5385, validation loss: 0.2984
2024-05-24 19:33:06 [INFO]: Epoch 038 - training loss: 9360.3345, validation loss: 0.3091
2024-05-24 19:33:07 [INFO]: Epoch 039 - training loss: 9366.6448, validation loss: 0.3011
2024-05-24 19:33:07 [INFO]: Epoch 040 - training loss: 9357.9588, validation loss: 0.2993
2024-05-24 19:33:07 [INFO]: Epoch 041 - training loss: 9346.4797, validation loss: 0.2926
2024-05-24 19:33:07 [INFO]: Epoch 042 - training loss: 9340.8091, validation loss: 0.2899
2024-05-24 19:33:07 [INFO]: Epoch 043 - training loss: 9336.0439, validation loss: 0.2918
2024-05-24 19:33:07 [INFO]: Epoch 044 - training loss: 9331.3885, validation loss: 0.2844
2024-05-24 19:33:07 [INFO]: Epoch 045 - training loss: 9330.7518, validation loss: 0.2821
2024-05-24 19:33:07 [INFO]: Epoch 046 - training loss: 9318.7071, validation loss: 0.2743
2024-05-24 19:33:08 [INFO]: Epoch 047 - training loss: 9320.3102, validation loss: 0.2742
2024-05-24 19:33:08 [INFO]: Epoch 048 - training loss: 9308.9323, validation loss: 0.2684
2024-05-24 19:33:08 [INFO]: Epoch 049 - training loss: 9306.1194, validation loss: 0.2579
2024-05-24 19:33:08 [INFO]: Epoch 050 - training loss: 9308.2879, validation loss: 0.2557
2024-05-24 19:33:08 [INFO]: Epoch 051 - training loss: 9301.1428, validation loss: 0.2478
2024-05-24 19:33:08 [INFO]: Epoch 052 - training loss: 9297.4779, validation loss: 0.2424
2024-05-24 19:33:08 [INFO]: Epoch 053 - training loss: 9295.2133, validation loss: 0.2315
2024-05-24 19:33:08 [INFO]: Epoch 054 - training loss: 9295.3538, validation loss: 0.2272
2024-05-24 19:33:08 [INFO]: Epoch 055 - training loss: 9290.9634, validation loss: 0.2224
2024-05-24 19:33:09 [INFO]: Epoch 056 - training loss: 9286.4517, validation loss: 0.2185
2024-05-24 19:33:09 [INFO]: Epoch 057 - training loss: 9286.0723, validation loss: 0.2101
2024-05-24 19:33:09 [INFO]: Epoch 058 - training loss: 9280.4321, validation loss: 0.2078
2024-05-24 19:33:09 [INFO]: Epoch 059 - training loss: 9299.7139, validation loss: 0.2019
2024-05-24 19:33:09 [INFO]: Epoch 060 - training loss: 9277.2064, validation loss: 0.1985
2024-05-24 19:33:09 [INFO]: Epoch 061 - training loss: 9273.7112, validation loss: 0.1936
2024-05-24 19:33:09 [INFO]: Epoch 062 - training loss: 9271.2958, validation loss: 0.1912
2024-05-24 19:33:09 [INFO]: Epoch 063 - training loss: 9271.9573, validation loss: 0.1860
2024-05-24 19:33:10 [INFO]: Epoch 064 - training loss: 9268.0066, validation loss: 0.1791
2024-05-24 19:33:10 [INFO]: Epoch 065 - training loss: 9268.5760, validation loss: 0.1778
2024-05-24 19:33:10 [INFO]: Epoch 066 - training loss: 9263.8654, validation loss: 0.1730
2024-05-24 19:33:10 [INFO]: Epoch 067 - training loss: 9263.0982, validation loss: 0.1690
2024-05-24 19:33:10 [INFO]: Epoch 068 - training loss: 9265.1747, validation loss: 0.1663
2024-05-24 19:33:10 [INFO]: Epoch 069 - training loss: 9261.7219, validation loss: 0.1641
2024-05-24 19:33:10 [INFO]: Epoch 070 - training loss: 9259.7394, validation loss: 0.1624
2024-05-24 19:33:10 [INFO]: Epoch 071 - training loss: 9263.1996, validation loss: 0.1588
2024-05-24 19:33:10 [INFO]: Epoch 072 - training loss: 9257.3160, validation loss: 0.1553
2024-05-24 19:33:11 [INFO]: Epoch 073 - training loss: 9254.4135, validation loss: 0.1529
2024-05-24 19:33:11 [INFO]: Epoch 074 - training loss: 9262.6515, validation loss: 0.1503
2024-05-24 19:33:11 [INFO]: Epoch 075 - training loss: 9258.2279, validation loss: 0.1502
2024-05-24 19:33:11 [INFO]: Epoch 076 - training loss: 9252.0189, validation loss: 0.1465
2024-05-24 19:33:11 [INFO]: Epoch 077 - training loss: 9249.3426, validation loss: 0.1446
2024-05-24 19:33:11 [INFO]: Epoch 078 - training loss: 9250.3099, validation loss: 0.1436
2024-05-24 19:33:11 [INFO]: Epoch 079 - training loss: 9246.4148, validation loss: 0.1423
2024-05-24 19:33:11 [INFO]: Epoch 080 - training loss: 9248.9229, validation loss: 0.1411
2024-05-24 19:33:11 [INFO]: Epoch 081 - training loss: 9245.0750, validation loss: 0.1404
2024-05-24 19:33:12 [INFO]: Epoch 082 - training loss: 9244.9470, validation loss: 0.1382
2024-05-24 19:33:12 [INFO]: Epoch 083 - training loss: 9244.2463, validation loss: 0.1363
2024-05-24 19:33:12 [INFO]: Epoch 084 - training loss: 9243.7346, validation loss: 0.1345
2024-05-24 19:33:12 [INFO]: Epoch 085 - training loss: 9245.0447, validation loss: 0.1333
2024-05-24 19:33:12 [INFO]: Epoch 086 - training loss: 9243.0317, validation loss: 0.1319
2024-05-24 19:33:12 [INFO]: Epoch 087 - training loss: 9244.0062, validation loss: 0.1304
2024-05-24 19:33:12 [INFO]: Epoch 088 - training loss: 9240.8354, validation loss: 0.1308
2024-05-24 19:33:12 [INFO]: Epoch 089 - training loss: 9239.1241, validation loss: 0.1299
2024-05-24 19:33:12 [INFO]: Epoch 090 - training loss: 9240.3246, validation loss: 0.1295
2024-05-24 19:33:13 [INFO]: Epoch 091 - training loss: 9240.1843, validation loss: 0.1285
2024-05-24 19:33:13 [INFO]: Epoch 092 - training loss: 9238.4041, validation loss: 0.1274
2024-05-24 19:33:13 [INFO]: Epoch 093 - training loss: 9237.2568, validation loss: 0.1263
2024-05-24 19:33:13 [INFO]: Epoch 094 - training loss: 9238.2992, validation loss: 0.1257
2024-05-24 19:33:13 [INFO]: Epoch 095 - training loss: 9237.5815, validation loss: 0.1248
2024-05-24 19:33:13 [INFO]: Epoch 096 - training loss: 9237.7661, validation loss: 0.1244
2024-05-24 19:33:13 [INFO]: Epoch 097 - training loss: 9235.5624, validation loss: 0.1231
2024-05-24 19:33:13 [INFO]: Epoch 098 - training loss: 9240.5898, validation loss: 0.1222
2024-05-24 19:33:14 [INFO]: Epoch 099 - training loss: 9232.2419, validation loss: 0.1209
2024-05-24 19:33:14 [INFO]: Epoch 100 - training loss: 9242.6625, validation loss: 0.1212
2024-05-24 19:33:14 [INFO]: Epoch 101 - training loss: 9231.9851, validation loss: 0.1204
2024-05-24 19:33:14 [INFO]: Epoch 102 - training loss: 9231.7289, validation loss: 0.1196
2024-05-24 19:33:14 [INFO]: Epoch 103 - training loss: 9229.7530, validation loss: 0.1193
2024-05-24 19:33:14 [INFO]: Epoch 104 - training loss: 9232.2405, validation loss: 0.1172
2024-05-24 19:33:14 [INFO]: Epoch 105 - training loss: 9229.6758, validation loss: 0.1179
2024-05-24 19:33:14 [INFO]: Epoch 106 - training loss: 9229.3291, validation loss: 0.1166
2024-05-24 19:33:15 [INFO]: Epoch 107 - training loss: 9228.1937, validation loss: 0.1180
2024-05-24 19:33:15 [INFO]: Epoch 108 - training loss: 9230.0079, validation loss: 0.1152
2024-05-24 19:33:15 [INFO]: Epoch 109 - training loss: 9228.7913, validation loss: 0.1158
2024-05-24 19:33:15 [INFO]: Epoch 110 - training loss: 9229.8300, validation loss: 0.1146
2024-05-24 19:33:15 [INFO]: Epoch 111 - training loss: 9229.6254, validation loss: 0.1145
2024-05-24 19:33:15 [INFO]: Epoch 112 - training loss: 9227.3077, validation loss: 0.1123
2024-05-24 19:33:15 [INFO]: Epoch 113 - training loss: 9227.5651, validation loss: 0.1127
2024-05-24 19:33:15 [INFO]: Epoch 114 - training loss: 9225.9165, validation loss: 0.1127
2024-05-24 19:33:15 [INFO]: Epoch 115 - training loss: 9226.0480, validation loss: 0.1113
2024-05-24 19:33:16 [INFO]: Epoch 116 - training loss: 9227.0673, validation loss: 0.1107
2024-05-24 19:33:16 [INFO]: Epoch 117 - training loss: 9226.1505, validation loss: 0.1101
2024-05-24 19:33:16 [INFO]: Epoch 118 - training loss: 9227.1740, validation loss: 0.1080
2024-05-24 19:33:16 [INFO]: Epoch 119 - training loss: 9226.1326, validation loss: 0.1103
2024-05-24 19:33:16 [INFO]: Epoch 120 - training loss: 9223.6229, validation loss: 0.1085
2024-05-24 19:33:16 [INFO]: Epoch 121 - training loss: 9223.1371, validation loss: 0.1076
2024-05-24 19:33:16 [INFO]: Epoch 122 - training loss: 9225.3430, validation loss: 0.1075
2024-05-24 19:33:16 [INFO]: Epoch 123 - training loss: 9221.7499, validation loss: 0.1076
2024-05-24 19:33:16 [INFO]: Epoch 124 - training loss: 9225.0719, validation loss: 0.1080
2024-05-24 19:33:17 [INFO]: Epoch 125 - training loss: 9222.6686, validation loss: 0.1047
2024-05-24 19:33:17 [INFO]: Epoch 126 - training loss: 9223.6154, validation loss: 0.1056
2024-05-24 19:33:17 [INFO]: Epoch 127 - training loss: 9225.1367, validation loss: 0.1035
2024-05-24 19:33:17 [INFO]: Epoch 128 - training loss: 9222.3185, validation loss: 0.1056
2024-05-24 19:33:17 [INFO]: Epoch 129 - training loss: 9222.5354, validation loss: 0.1054
2024-05-24 19:33:17 [INFO]: Epoch 130 - training loss: 9222.8521, validation loss: 0.1017
2024-05-24 19:33:17 [INFO]: Epoch 131 - training loss: 9220.8431, validation loss: 0.1034
2024-05-24 19:33:17 [INFO]: Epoch 132 - training loss: 9220.6032, validation loss: 0.1032
2024-05-24 19:33:18 [INFO]: Epoch 133 - training loss: 9222.3636, validation loss: 0.1018
2024-05-24 19:33:18 [INFO]: Epoch 134 - training loss: 9221.7198, validation loss: 0.1016
2024-05-24 19:33:18 [INFO]: Epoch 135 - training loss: 9221.5908, validation loss: 0.1034
2024-05-24 19:33:18 [INFO]: Epoch 136 - training loss: 9220.3087, validation loss: 0.1001
2024-05-24 19:33:18 [INFO]: Epoch 137 - training loss: 9219.2131, validation loss: 0.1009
2024-05-24 19:33:18 [INFO]: Epoch 138 - training loss: 9222.8912, validation loss: 0.0996
2024-05-24 19:33:18 [INFO]: Epoch 139 - training loss: 9220.1747, validation loss: 0.0996
2024-05-24 19:33:18 [INFO]: Epoch 140 - training loss: 9221.0783, validation loss: 0.1002
2024-05-24 19:33:19 [INFO]: Epoch 141 - training loss: 9218.8792, validation loss: 0.0980
2024-05-24 19:33:19 [INFO]: Epoch 142 - training loss: 9220.0981, validation loss: 0.0990
2024-05-24 19:33:19 [INFO]: Epoch 143 - training loss: 9219.0546, validation loss: 0.0972
2024-05-24 19:33:19 [INFO]: Epoch 144 - training loss: 9217.7087, validation loss: 0.0968
2024-05-24 19:33:19 [INFO]: Epoch 145 - training loss: 9218.6320, validation loss: 0.0978
2024-05-24 19:33:19 [INFO]: Epoch 146 - training loss: 9218.2874, validation loss: 0.0962
2024-05-24 19:33:19 [INFO]: Epoch 147 - training loss: 9219.0109, validation loss: 0.0965
2024-05-24 19:33:19 [INFO]: Epoch 148 - training loss: 9216.2764, validation loss: 0.0962
2024-05-24 19:33:19 [INFO]: Epoch 149 - training loss: 9219.7602, validation loss: 0.0966
2024-05-24 19:33:20 [INFO]: Epoch 150 - training loss: 9217.2387, validation loss: 0.0969
2024-05-24 19:33:20 [INFO]: Epoch 151 - training loss: 9219.5516, validation loss: 0.0943
2024-05-24 19:33:20 [INFO]: Epoch 152 - training loss: 9217.7385, validation loss: 0.0948
2024-05-24 19:33:20 [INFO]: Epoch 153 - training loss: 9217.1335, validation loss: 0.0935
2024-05-24 19:33:20 [INFO]: Epoch 154 - training loss: 9215.7695, validation loss: 0.0956
2024-05-24 19:33:20 [INFO]: Epoch 155 - training loss: 9216.7737, validation loss: 0.0937
2024-05-24 19:33:20 [INFO]: Epoch 156 - training loss: 9217.1569, validation loss: 0.0944
2024-05-24 19:33:20 [INFO]: Epoch 157 - training loss: 9219.3220, validation loss: 0.0931
2024-05-24 19:33:21 [INFO]: Epoch 158 - training loss: 9217.4582, validation loss: 0.0943
2024-05-24 19:33:21 [INFO]: Epoch 159 - training loss: 9215.6716, validation loss: 0.0924
2024-05-24 19:33:21 [INFO]: Epoch 160 - training loss: 9216.7820, validation loss: 0.0927
2024-05-24 19:33:21 [INFO]: Epoch 161 - training loss: 9215.6732, validation loss: 0.0927
2024-05-24 19:33:21 [INFO]: Epoch 162 - training loss: 9214.4050, validation loss: 0.0923
2024-05-24 19:33:21 [INFO]: Epoch 163 - training loss: 9215.4685, validation loss: 0.0917
2024-05-24 19:33:21 [INFO]: Epoch 164 - training loss: 9214.3055, validation loss: 0.0909
2024-05-24 19:33:21 [INFO]: Epoch 165 - training loss: 9213.9113, validation loss: 0.0901
2024-05-24 19:33:22 [INFO]: Epoch 166 - training loss: 9214.3948, validation loss: 0.0909
2024-05-24 19:33:22 [INFO]: Epoch 167 - training loss: 9214.0683, validation loss: 0.0905
2024-05-24 19:33:22 [INFO]: Epoch 168 - training loss: 9214.6301, validation loss: 0.0902
2024-05-24 19:33:22 [INFO]: Epoch 169 - training loss: 9216.4171, validation loss: 0.0905
2024-05-24 19:33:22 [INFO]: Epoch 170 - training loss: 9214.1290, validation loss: 0.0903
2024-05-24 19:33:22 [INFO]: Epoch 171 - training loss: 9216.4490, validation loss: 0.0895
2024-05-24 19:33:22 [INFO]: Epoch 172 - training loss: 9212.9487, validation loss: 0.0895
2024-05-24 19:33:22 [INFO]: Epoch 173 - training loss: 9212.8834, validation loss: 0.0904
2024-05-24 19:33:23 [INFO]: Epoch 174 - training loss: 9213.1190, validation loss: 0.0880
2024-05-24 19:33:23 [INFO]: Epoch 175 - training loss: 9215.4720, validation loss: 0.0887
2024-05-24 19:33:23 [INFO]: Epoch 176 - training loss: 9215.3502, validation loss: 0.0897
2024-05-24 19:33:23 [INFO]: Epoch 177 - training loss: 9213.2930, validation loss: 0.0897
2024-05-24 19:33:23 [INFO]: Epoch 178 - training loss: 9213.9062, validation loss: 0.0894
2024-05-24 19:33:23 [INFO]: Epoch 179 - training loss: 9214.0995, validation loss: 0.0883
2024-05-24 19:33:23 [INFO]: Epoch 180 - training loss: 9213.6954, validation loss: 0.0895
2024-05-24 19:33:23 [INFO]: Epoch 181 - training loss: 9212.1030, validation loss: 0.0884
2024-05-24 19:33:23 [INFO]: Epoch 182 - training loss: 9214.6803, validation loss: 0.0882
2024-05-24 19:33:24 [INFO]: Epoch 183 - training loss: 9212.0058, validation loss: 0.0846
2024-05-24 19:33:24 [INFO]: Epoch 184 - training loss: 9211.0299, validation loss: 0.0877
2024-05-24 19:33:24 [INFO]: Epoch 185 - training loss: 9213.7341, validation loss: 0.0853
2024-05-24 19:33:24 [INFO]: Epoch 186 - training loss: 9210.6946, validation loss: 0.0851
2024-05-24 19:33:24 [INFO]: Epoch 187 - training loss: 9210.7924, validation loss: 0.0873
2024-05-24 19:33:24 [INFO]: Epoch 188 - training loss: 9211.4193, validation loss: 0.0857
2024-05-24 19:33:24 [INFO]: Epoch 189 - training loss: 9211.1193, validation loss: 0.0853
2024-05-24 19:33:24 [INFO]: Epoch 190 - training loss: 9211.0833, validation loss: 0.0845
2024-05-24 19:33:25 [INFO]: Epoch 191 - training loss: 9211.0795, validation loss: 0.0869
2024-05-24 19:33:25 [INFO]: Epoch 192 - training loss: 9211.8353, validation loss: 0.0860
2024-05-24 19:33:25 [INFO]: Epoch 193 - training loss: 9211.0844, validation loss: 0.0872
2024-05-24 19:33:25 [INFO]: Epoch 194 - training loss: 9210.2514, validation loss: 0.0851
2024-05-24 19:33:25 [INFO]: Epoch 195 - training loss: 9211.0419, validation loss: 0.0849
2024-05-24 19:33:25 [INFO]: Epoch 196 - training loss: 9210.5468, validation loss: 0.0845
2024-05-24 19:33:25 [INFO]: Epoch 197 - training loss: 9210.7874, validation loss: 0.0838
2024-05-24 19:33:25 [INFO]: Epoch 198 - training loss: 9211.3804, validation loss: 0.0847
2024-05-24 19:33:26 [INFO]: Epoch 199 - training loss: 9210.0491, validation loss: 0.0841
2024-05-24 19:33:26 [INFO]: Epoch 200 - training loss: 9211.2607, validation loss: 0.0824
2024-05-24 19:33:26 [INFO]: Epoch 201 - training loss: 9209.8494, validation loss: 0.0836
2024-05-24 19:33:26 [INFO]: Epoch 202 - training loss: 9210.2372, validation loss: 0.0839
2024-05-24 19:33:26 [INFO]: Epoch 203 - training loss: 9209.9156, validation loss: 0.0834
2024-05-24 19:33:26 [INFO]: Epoch 204 - training loss: 9209.9372, validation loss: 0.0840
2024-05-24 19:33:26 [INFO]: Epoch 205 - training loss: 9209.5359, validation loss: 0.0847
2024-05-24 19:33:26 [INFO]: Epoch 206 - training loss: 9211.1383, validation loss: 0.0829
2024-05-24 19:33:27 [INFO]: Epoch 207 - training loss: 9209.7745, validation loss: 0.0843
2024-05-24 19:33:27 [INFO]: Epoch 208 - training loss: 9211.6188, validation loss: 0.0830
2024-05-24 19:33:27 [INFO]: Epoch 209 - training loss: 9212.0745, validation loss: 0.0830
2024-05-24 19:33:27 [INFO]: Epoch 210 - training loss: 9209.5892, validation loss: 0.0816
2024-05-24 19:33:27 [INFO]: Epoch 211 - training loss: 9210.3915, validation loss: 0.0830
2024-05-24 19:33:27 [INFO]: Epoch 212 - training loss: 9209.9377, validation loss: 0.0847
2024-05-24 19:33:27 [INFO]: Epoch 213 - training loss: 9209.9861, validation loss: 0.0808
2024-05-24 19:33:27 [INFO]: Epoch 214 - training loss: 9209.8943, validation loss: 0.0840
2024-05-24 19:33:27 [INFO]: Epoch 215 - training loss: 9208.4524, validation loss: 0.0871
2024-05-24 19:33:27 [INFO]: Epoch 216 - training loss: 9211.0374, validation loss: 0.0831
2024-05-24 19:33:28 [INFO]: Epoch 217 - training loss: 9209.5047, validation loss: 0.0828
2024-05-24 19:33:28 [INFO]: Epoch 218 - training loss: 9211.2859, validation loss: 0.0830
2024-05-24 19:33:28 [INFO]: Epoch 219 - training loss: 9210.7042, validation loss: 0.0827
2024-05-24 19:33:28 [INFO]: Epoch 220 - training loss: 9208.8726, validation loss: 0.0849
2024-05-24 19:33:28 [INFO]: Epoch 221 - training loss: 9209.7740, validation loss: 0.0806
2024-05-24 19:33:28 [INFO]: Epoch 222 - training loss: 9209.0142, validation loss: 0.0823
2024-05-24 19:33:28 [INFO]: Epoch 223 - training loss: 9209.7332, validation loss: 0.0836
2024-05-24 19:33:28 [INFO]: Epoch 224 - training loss: 9209.0585, validation loss: 0.0825
2024-05-24 19:33:29 [INFO]: Epoch 225 - training loss: 9209.7332, validation loss: 0.0815
2024-05-24 19:33:29 [INFO]: Epoch 226 - training loss: 9208.4349, validation loss: 0.0829
2024-05-24 19:33:29 [INFO]: Epoch 227 - training loss: 9207.6486, validation loss: 0.0804
2024-05-24 19:33:29 [INFO]: Epoch 228 - training loss: 9208.6793, validation loss: 0.0803
2024-05-24 19:33:29 [INFO]: Epoch 229 - training loss: 9209.2331, validation loss: 0.0805
2024-05-24 19:33:29 [INFO]: Epoch 230 - training loss: 9208.7547, validation loss: 0.0807
2024-05-24 19:33:29 [INFO]: Epoch 231 - training loss: 9208.5358, validation loss: 0.0807
2024-05-24 19:33:29 [INFO]: Epoch 232 - training loss: 9209.2939, validation loss: 0.0825
2024-05-24 19:33:29 [INFO]: Epoch 233 - training loss: 9207.6014, validation loss: 0.0787
2024-05-24 19:33:30 [INFO]: Epoch 234 - training loss: 9209.8667, validation loss: 0.0796
2024-05-24 19:33:30 [INFO]: Epoch 235 - training loss: 9209.8121, validation loss: 0.0788
2024-05-24 19:33:30 [INFO]: Epoch 236 - training loss: 9207.8259, validation loss: 0.0802
2024-05-24 19:33:30 [INFO]: Epoch 237 - training loss: 9207.1249, validation loss: 0.0834
2024-05-24 19:33:30 [INFO]: Epoch 238 - training loss: 9207.5938, validation loss: 0.0789
2024-05-24 19:33:30 [INFO]: Epoch 239 - training loss: 9207.9081, validation loss: 0.0790
2024-05-24 19:33:30 [INFO]: Epoch 240 - training loss: 9208.6055, validation loss: 0.0802
2024-05-24 19:33:30 [INFO]: Epoch 241 - training loss: 9209.4459, validation loss: 0.0818
2024-05-24 19:33:30 [INFO]: Epoch 242 - training loss: 9207.8751, validation loss: 0.0798
2024-05-24 19:33:31 [INFO]: Epoch 243 - training loss: 9208.6583, validation loss: 0.0797
2024-05-24 19:33:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:33:31 [INFO]: Finished training. The best model is from epoch#233.
2024-05-24 19:33:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/GPVAE_ettm1/20240524_T193300/GPVAE.pypots
2024-05-24 19:33:31 [INFO]: GP-VAE on ETTm1: MAE=0.2960, MSE=0.1970
2024-05-24 19:33:31 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/GPVAE_ettm1/imputation.pkl
2024-05-24 19:33:31 [INFO]: Using the given device: cuda:0
2024-05-24 19:33:31 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T193331
2024-05-24 19:33:31 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T193331/tensorboard
2024-05-24 19:33:31 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 19:33:40 [INFO]: Epoch 001 - generator training loss: 0.5942, discriminator training loss: 0.5369, validation loss: 0.3238
2024-05-24 19:33:47 [INFO]: Epoch 002 - generator training loss: -0.0105, discriminator training loss: 0.4704, validation loss: 0.1709
2024-05-24 19:33:54 [INFO]: Epoch 003 - generator training loss: -0.1265, discriminator training loss: 0.4269, validation loss: 0.0974
2024-05-24 19:34:01 [INFO]: Epoch 004 - generator training loss: -0.1261, discriminator training loss: 0.3600, validation loss: 0.0707
2024-05-24 19:34:08 [INFO]: Epoch 005 - generator training loss: -0.0865, discriminator training loss: 0.2826, validation loss: 0.0582
2024-05-24 19:34:15 [INFO]: Epoch 006 - generator training loss: -0.0689, discriminator training loss: 0.2259, validation loss: 0.0505
2024-05-24 19:34:22 [INFO]: Epoch 007 - generator training loss: -0.0576, discriminator training loss: 0.1962, validation loss: 0.0450
2024-05-24 19:34:29 [INFO]: Epoch 008 - generator training loss: -0.0534, discriminator training loss: 0.1850, validation loss: 0.0424
2024-05-24 19:34:36 [INFO]: Epoch 009 - generator training loss: -0.0510, discriminator training loss: 0.1773, validation loss: 0.0401
2024-05-24 19:34:43 [INFO]: Epoch 010 - generator training loss: -0.0538, discriminator training loss: 0.1767, validation loss: 0.0383
2024-05-24 19:34:50 [INFO]: Epoch 011 - generator training loss: -0.0582, discriminator training loss: 0.1768, validation loss: 0.0371
2024-05-24 19:34:57 [INFO]: Epoch 012 - generator training loss: -0.0574, discriminator training loss: 0.1754, validation loss: 0.0364
2024-05-24 19:35:04 [INFO]: Epoch 013 - generator training loss: -0.0582, discriminator training loss: 0.1707, validation loss: 0.0357
2024-05-24 19:35:11 [INFO]: Epoch 014 - generator training loss: -0.0606, discriminator training loss: 0.1741, validation loss: 0.0344
2024-05-24 19:35:18 [INFO]: Epoch 015 - generator training loss: -0.0559, discriminator training loss: 0.1727, validation loss: 0.0340
2024-05-24 19:35:25 [INFO]: Epoch 016 - generator training loss: -0.0596, discriminator training loss: 0.1723, validation loss: 0.0328
2024-05-24 19:35:32 [INFO]: Epoch 017 - generator training loss: -0.0611, discriminator training loss: 0.1716, validation loss: 0.0323
2024-05-24 19:35:39 [INFO]: Epoch 018 - generator training loss: -0.0602, discriminator training loss: 0.1723, validation loss: 0.0322
2024-05-24 19:35:46 [INFO]: Epoch 019 - generator training loss: -0.0602, discriminator training loss: 0.1741, validation loss: 0.0312
2024-05-24 19:35:53 [INFO]: Epoch 020 - generator training loss: -0.0636, discriminator training loss: 0.1717, validation loss: 0.0311
2024-05-24 19:36:00 [INFO]: Epoch 021 - generator training loss: -0.0597, discriminator training loss: 0.1701, validation loss: 0.0315
2024-05-24 19:36:07 [INFO]: Epoch 022 - generator training loss: -0.0595, discriminator training loss: 0.1701, validation loss: 0.0304
2024-05-24 19:36:14 [INFO]: Epoch 023 - generator training loss: -0.0625, discriminator training loss: 0.1693, validation loss: 0.0314
2024-05-24 19:36:21 [INFO]: Epoch 024 - generator training loss: -0.0632, discriminator training loss: 0.1715, validation loss: 0.0290
2024-05-24 19:36:28 [INFO]: Epoch 025 - generator training loss: -0.0612, discriminator training loss: 0.1691, validation loss: 0.0302
2024-05-24 19:36:35 [INFO]: Epoch 026 - generator training loss: -0.0654, discriminator training loss: 0.1669, validation loss: 0.0288
2024-05-24 19:36:42 [INFO]: Epoch 027 - generator training loss: -0.0619, discriminator training loss: 0.1683, validation loss: 0.0286
2024-05-24 19:36:49 [INFO]: Epoch 028 - generator training loss: -0.0647, discriminator training loss: 0.1684, validation loss: 0.0287
2024-05-24 19:36:56 [INFO]: Epoch 029 - generator training loss: -0.0635, discriminator training loss: 0.1687, validation loss: 0.0279
2024-05-24 19:37:03 [INFO]: Epoch 030 - generator training loss: -0.0680, discriminator training loss: 0.1697, validation loss: 0.0278
2024-05-24 19:37:09 [INFO]: Epoch 031 - generator training loss: -0.0642, discriminator training loss: 0.1665, validation loss: 0.0273
2024-05-24 19:37:17 [INFO]: Epoch 032 - generator training loss: -0.0675, discriminator training loss: 0.1678, validation loss: 0.0270
2024-05-24 19:37:23 [INFO]: Epoch 033 - generator training loss: -0.0657, discriminator training loss: 0.1673, validation loss: 0.0270
2024-05-24 19:37:30 [INFO]: Epoch 034 - generator training loss: -0.0650, discriminator training loss: 0.1696, validation loss: 0.0270
2024-05-24 19:37:37 [INFO]: Epoch 035 - generator training loss: -0.0674, discriminator training loss: 0.1663, validation loss: 0.0271
2024-05-24 19:37:44 [INFO]: Epoch 036 - generator training loss: -0.0685, discriminator training loss: 0.1667, validation loss: 0.0273
2024-05-24 19:37:51 [INFO]: Epoch 037 - generator training loss: -0.0681, discriminator training loss: 0.1680, validation loss: 0.0276
2024-05-24 19:37:58 [INFO]: Epoch 038 - generator training loss: -0.0682, discriminator training loss: 0.1672, validation loss: 0.0263
2024-05-24 19:38:05 [INFO]: Epoch 039 - generator training loss: -0.0656, discriminator training loss: 0.1666, validation loss: 0.0269
2024-05-24 19:38:12 [INFO]: Epoch 040 - generator training loss: -0.0673, discriminator training loss: 0.1677, validation loss: 0.0259
2024-05-24 19:38:19 [INFO]: Epoch 041 - generator training loss: -0.0621, discriminator training loss: 0.1688, validation loss: 0.0269
2024-05-24 19:38:26 [INFO]: Epoch 042 - generator training loss: -0.0656, discriminator training loss: 0.1687, validation loss: 0.0261
2024-05-24 19:38:33 [INFO]: Epoch 043 - generator training loss: -0.0684, discriminator training loss: 0.1673, validation loss: 0.0257
2024-05-24 19:38:40 [INFO]: Epoch 044 - generator training loss: -0.0677, discriminator training loss: 0.1673, validation loss: 0.0256
2024-05-24 19:38:47 [INFO]: Epoch 045 - generator training loss: -0.0689, discriminator training loss: 0.1660, validation loss: 0.0257
2024-05-24 19:38:55 [INFO]: Epoch 046 - generator training loss: -0.0678, discriminator training loss: 0.1659, validation loss: 0.0259
2024-05-24 19:39:02 [INFO]: Epoch 047 - generator training loss: -0.0684, discriminator training loss: 0.1653, validation loss: 0.0252
2024-05-24 19:39:08 [INFO]: Epoch 048 - generator training loss: -0.0709, discriminator training loss: 0.1647, validation loss: 0.0254
2024-05-24 19:39:15 [INFO]: Epoch 049 - generator training loss: -0.0701, discriminator training loss: 0.1641, validation loss: 0.0251
2024-05-24 19:39:22 [INFO]: Epoch 050 - generator training loss: -0.0675, discriminator training loss: 0.1668, validation loss: 0.0251
2024-05-24 19:39:29 [INFO]: Epoch 051 - generator training loss: -0.0700, discriminator training loss: 0.1668, validation loss: 0.0251
2024-05-24 19:39:36 [INFO]: Epoch 052 - generator training loss: -0.0708, discriminator training loss: 0.1646, validation loss: 0.0253
2024-05-24 19:39:43 [INFO]: Epoch 053 - generator training loss: -0.0708, discriminator training loss: 0.1669, validation loss: 0.0247
2024-05-24 19:39:50 [INFO]: Epoch 054 - generator training loss: -0.0693, discriminator training loss: 0.1660, validation loss: 0.0246
2024-05-24 19:39:57 [INFO]: Epoch 055 - generator training loss: -0.0699, discriminator training loss: 0.1655, validation loss: 0.0249
2024-05-24 19:40:04 [INFO]: Epoch 056 - generator training loss: -0.0688, discriminator training loss: 0.1639, validation loss: 0.0250
2024-05-24 19:40:11 [INFO]: Epoch 057 - generator training loss: -0.0702, discriminator training loss: 0.1651, validation loss: 0.0245
2024-05-24 19:40:18 [INFO]: Epoch 058 - generator training loss: -0.0728, discriminator training loss: 0.1636, validation loss: 0.0244
2024-05-24 19:40:25 [INFO]: Epoch 059 - generator training loss: -0.0727, discriminator training loss: 0.1644, validation loss: 0.0245
2024-05-24 19:40:32 [INFO]: Epoch 060 - generator training loss: -0.0698, discriminator training loss: 0.1657, validation loss: 0.0246
2024-05-24 19:40:39 [INFO]: Epoch 061 - generator training loss: -0.0701, discriminator training loss: 0.1641, validation loss: 0.0243
2024-05-24 19:40:46 [INFO]: Epoch 062 - generator training loss: -0.0711, discriminator training loss: 0.1652, validation loss: 0.0242
2024-05-24 19:40:53 [INFO]: Epoch 063 - generator training loss: -0.0701, discriminator training loss: 0.1639, validation loss: 0.0248
2024-05-24 19:41:00 [INFO]: Epoch 064 - generator training loss: -0.0677, discriminator training loss: 0.1634, validation loss: 0.0242
2024-05-24 19:41:07 [INFO]: Epoch 065 - generator training loss: -0.0730, discriminator training loss: 0.1645, validation loss: 0.0245
2024-05-24 19:41:14 [INFO]: Epoch 066 - generator training loss: -0.0706, discriminator training loss: 0.1632, validation loss: 0.0237
2024-05-24 19:41:21 [INFO]: Epoch 067 - generator training loss: -0.0730, discriminator training loss: 0.1636, validation loss: 0.0240
2024-05-24 19:41:28 [INFO]: Epoch 068 - generator training loss: -0.0721, discriminator training loss: 0.1622, validation loss: 0.0240
2024-05-24 19:41:35 [INFO]: Epoch 069 - generator training loss: -0.0725, discriminator training loss: 0.1637, validation loss: 0.0241
2024-05-24 19:41:42 [INFO]: Epoch 070 - generator training loss: -0.0715, discriminator training loss: 0.1644, validation loss: 0.0245
2024-05-24 19:41:49 [INFO]: Epoch 071 - generator training loss: -0.0701, discriminator training loss: 0.1639, validation loss: 0.0250
2024-05-24 19:41:56 [INFO]: Epoch 072 - generator training loss: -0.0707, discriminator training loss: 0.1663, validation loss: 0.0243
2024-05-24 19:42:03 [INFO]: Epoch 073 - generator training loss: -0.0696, discriminator training loss: 0.1626, validation loss: 0.0245
2024-05-24 19:42:10 [INFO]: Epoch 074 - generator training loss: -0.0710, discriminator training loss: 0.1643, validation loss: 0.0248
2024-05-24 19:42:17 [INFO]: Epoch 075 - generator training loss: -0.0698, discriminator training loss: 0.1644, validation loss: 0.0239
2024-05-24 19:42:24 [INFO]: Epoch 076 - generator training loss: -0.0722, discriminator training loss: 0.1632, validation loss: 0.0241
2024-05-24 19:42:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:42:24 [INFO]: Finished training. The best model is from epoch#66.
2024-05-24 19:42:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/USGAN_ettm1/20240524_T193331/USGAN.pypots
2024-05-24 19:42:25 [INFO]: US-GAN on ETTm1: MAE=0.1582, MSE=0.0669
2024-05-24 19:42:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/USGAN_ettm1/imputation.pkl
2024-05-24 19:42:25 [INFO]: Using the given device: cuda:0
2024-05-24 19:42:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T194225
2024-05-24 19:42:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T194225/tensorboard
2024-05-24 19:42:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 19:42:30 [INFO]: Epoch 001 - training loss: 1.2931, validation loss: 0.2842
2024-05-24 19:42:35 [INFO]: Epoch 002 - training loss: 0.8494, validation loss: 0.1038
2024-05-24 19:42:40 [INFO]: Epoch 003 - training loss: 0.6630, validation loss: 0.0541
2024-05-24 19:42:44 [INFO]: Epoch 004 - training loss: 0.5996, validation loss: 0.0475
2024-05-24 19:42:49 [INFO]: Epoch 005 - training loss: 0.5612, validation loss: 0.0425
2024-05-24 19:42:53 [INFO]: Epoch 006 - training loss: 0.5235, validation loss: 0.0394
2024-05-24 19:42:58 [INFO]: Epoch 007 - training loss: 0.4995, validation loss: 0.0333
2024-05-24 19:43:03 [INFO]: Epoch 008 - training loss: 0.4762, validation loss: 0.0319
2024-05-24 19:43:07 [INFO]: Epoch 009 - training loss: 0.4537, validation loss: 0.0314
2024-05-24 19:43:12 [INFO]: Epoch 010 - training loss: 0.4436, validation loss: 0.0285
2024-05-24 19:43:16 [INFO]: Epoch 011 - training loss: 0.4320, validation loss: 0.0285
2024-05-24 19:43:21 [INFO]: Epoch 012 - training loss: 0.4223, validation loss: 0.0278
2024-05-24 19:43:26 [INFO]: Epoch 013 - training loss: 0.4212, validation loss: 0.0271
2024-05-24 19:43:30 [INFO]: Epoch 014 - training loss: 0.4082, validation loss: 0.0269
2024-05-24 19:43:35 [INFO]: Epoch 015 - training loss: 0.4146, validation loss: 0.0263
2024-05-24 19:43:39 [INFO]: Epoch 016 - training loss: 0.4189, validation loss: 0.0275
2024-05-24 19:43:44 [INFO]: Epoch 017 - training loss: 0.4205, validation loss: 0.0272
2024-05-24 19:43:48 [INFO]: Epoch 018 - training loss: 0.4020, validation loss: 0.0265
2024-05-24 19:43:53 [INFO]: Epoch 019 - training loss: 0.4059, validation loss: 0.0259
2024-05-24 19:43:58 [INFO]: Epoch 020 - training loss: 0.4001, validation loss: 0.0256
2024-05-24 19:44:02 [INFO]: Epoch 021 - training loss: 0.4001, validation loss: 0.0259
2024-05-24 19:44:07 [INFO]: Epoch 022 - training loss: 0.4046, validation loss: 0.0262
2024-05-24 19:44:12 [INFO]: Epoch 023 - training loss: 0.4089, validation loss: 0.0268
2024-05-24 19:44:16 [INFO]: Epoch 024 - training loss: 0.4111, validation loss: 0.0262
2024-05-24 19:44:21 [INFO]: Epoch 025 - training loss: 0.3987, validation loss: 0.0252
2024-05-24 19:44:25 [INFO]: Epoch 026 - training loss: 0.4036, validation loss: 0.0257
2024-05-24 19:44:30 [INFO]: Epoch 027 - training loss: 0.4031, validation loss: 0.0253
2024-05-24 19:44:35 [INFO]: Epoch 028 - training loss: 0.4139, validation loss: 0.0256
2024-05-24 19:44:39 [INFO]: Epoch 029 - training loss: 0.4026, validation loss: 0.0256
2024-05-24 19:44:44 [INFO]: Epoch 030 - training loss: 0.3948, validation loss: 0.0254
2024-05-24 19:44:48 [INFO]: Epoch 031 - training loss: 0.3964, validation loss: 0.0252
2024-05-24 19:44:53 [INFO]: Epoch 032 - training loss: 0.3972, validation loss: 0.0253
2024-05-24 19:44:57 [INFO]: Epoch 033 - training loss: 0.3962, validation loss: 0.0259
2024-05-24 19:45:02 [INFO]: Epoch 034 - training loss: 0.3944, validation loss: 0.0258
2024-05-24 19:45:06 [INFO]: Epoch 035 - training loss: 0.4037, validation loss: 0.0249
2024-05-24 19:45:11 [INFO]: Epoch 036 - training loss: 0.3922, validation loss: 0.0252
2024-05-24 19:45:16 [INFO]: Epoch 037 - training loss: 0.3929, validation loss: 0.0253
2024-05-24 19:45:20 [INFO]: Epoch 038 - training loss: 0.4023, validation loss: 0.0262
2024-05-24 19:45:25 [INFO]: Epoch 039 - training loss: 0.4020, validation loss: 0.0272
2024-05-24 19:45:29 [INFO]: Epoch 040 - training loss: 0.3960, validation loss: 0.0256
2024-05-24 19:45:34 [INFO]: Epoch 041 - training loss: 0.4077, validation loss: 0.0249
2024-05-24 19:45:39 [INFO]: Epoch 042 - training loss: 0.4016, validation loss: 0.0268
2024-05-24 19:45:43 [INFO]: Epoch 043 - training loss: 0.3925, validation loss: 0.0260
2024-05-24 19:45:48 [INFO]: Epoch 044 - training loss: 0.3944, validation loss: 0.0255
2024-05-24 19:45:52 [INFO]: Epoch 045 - training loss: 0.3864, validation loss: 0.0248
2024-05-24 19:45:57 [INFO]: Epoch 046 - training loss: 0.3909, validation loss: 0.0254
2024-05-24 19:46:02 [INFO]: Epoch 047 - training loss: 0.3878, validation loss: 0.0250
2024-05-24 19:46:06 [INFO]: Epoch 048 - training loss: 0.3980, validation loss: 0.0250
2024-05-24 19:46:11 [INFO]: Epoch 049 - training loss: 0.3895, validation loss: 0.0252
2024-05-24 19:46:15 [INFO]: Epoch 050 - training loss: 0.3950, validation loss: 0.0251
2024-05-24 19:46:20 [INFO]: Epoch 051 - training loss: 0.3924, validation loss: 0.0254
2024-05-24 19:46:25 [INFO]: Epoch 052 - training loss: 0.3916, validation loss: 0.0256
2024-05-24 19:46:29 [INFO]: Epoch 053 - training loss: 0.3913, validation loss: 0.0253
2024-05-24 19:46:34 [INFO]: Epoch 054 - training loss: 0.3900, validation loss: 0.0252
2024-05-24 19:46:38 [INFO]: Epoch 055 - training loss: 0.3986, validation loss: 0.0264
2024-05-24 19:46:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:46:38 [INFO]: Finished training. The best model is from epoch#45.
2024-05-24 19:46:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/BRITS_ettm1/20240524_T194225/BRITS.pypots
2024-05-24 19:46:39 [INFO]: BRITS on ETTm1: MAE=0.1358, MSE=0.0548
2024-05-24 19:46:39 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/BRITS_ettm1/imputation.pkl
2024-05-24 19:46:39 [INFO]: Using the given device: cuda:0
2024-05-24 19:46:39 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639
2024-05-24 19:46:39 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/tensorboard
2024-05-24 19:46:39 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 19:46:40 [INFO]: Epoch 001 - training loss: 1.3271, validation loss: 1.2075
2024-05-24 19:46:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch1_loss1.2074615359306335.pypots
2024-05-24 19:46:41 [INFO]: Epoch 002 - training loss: 0.9666, validation loss: 1.0968
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch2_loss1.0967910289764404.pypots
2024-05-24 19:46:41 [INFO]: Epoch 003 - training loss: 0.9160, validation loss: 1.0544
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch3_loss1.0544404089450836.pypots
2024-05-24 19:46:41 [INFO]: Epoch 004 - training loss: 0.8775, validation loss: 1.0433
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch4_loss1.0433012396097183.pypots
2024-05-24 19:46:41 [INFO]: Epoch 005 - training loss: 0.8674, validation loss: 1.0363
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch5_loss1.036347046494484.pypots
2024-05-24 19:46:41 [INFO]: Epoch 006 - training loss: 0.8684, validation loss: 1.0289
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch6_loss1.0289292484521866.pypots
2024-05-24 19:46:41 [INFO]: Epoch 007 - training loss: 0.8563, validation loss: 1.0289
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch7_loss1.0289310216903687.pypots
2024-05-24 19:46:41 [INFO]: Epoch 008 - training loss: 0.8663, validation loss: 1.0296
2024-05-24 19:46:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch8_loss1.0295555144548416.pypots
2024-05-24 19:46:42 [INFO]: Epoch 009 - training loss: 0.8649, validation loss: 1.0241
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch9_loss1.0240655541419983.pypots
2024-05-24 19:46:42 [INFO]: Epoch 010 - training loss: 0.8585, validation loss: 1.0269
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch10_loss1.02693872153759.pypots
2024-05-24 19:46:42 [INFO]: Epoch 011 - training loss: 0.8780, validation loss: 1.0264
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch11_loss1.0264189392328262.pypots
2024-05-24 19:46:42 [INFO]: Epoch 012 - training loss: 0.8312, validation loss: 1.0251
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch12_loss1.025133267045021.pypots
2024-05-24 19:46:42 [INFO]: Epoch 013 - training loss: 0.8296, validation loss: 1.0216
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch13_loss1.0216209292411804.pypots
2024-05-24 19:46:42 [INFO]: Epoch 014 - training loss: 0.8226, validation loss: 1.0223
2024-05-24 19:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch14_loss1.0222855061292648.pypots
2024-05-24 19:46:43 [INFO]: Epoch 015 - training loss: 0.8239, validation loss: 1.0186
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch15_loss1.0186288207769394.pypots
2024-05-24 19:46:43 [INFO]: Epoch 016 - training loss: 0.8127, validation loss: 1.0167
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch16_loss1.0167238414287567.pypots
2024-05-24 19:46:43 [INFO]: Epoch 017 - training loss: 0.8171, validation loss: 1.0164
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch17_loss1.016374945640564.pypots
2024-05-24 19:46:43 [INFO]: Epoch 018 - training loss: 0.8243, validation loss: 1.0097
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch18_loss1.009687528014183.pypots
2024-05-24 19:46:43 [INFO]: Epoch 019 - training loss: 0.7894, validation loss: 1.0099
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch19_loss1.0098652839660645.pypots
2024-05-24 19:46:43 [INFO]: Epoch 020 - training loss: 0.7972, validation loss: 1.0115
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch20_loss1.0115278959274292.pypots
2024-05-24 19:46:43 [INFO]: Epoch 021 - training loss: 0.8018, validation loss: 1.0086
2024-05-24 19:46:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch21_loss1.0086135417222977.pypots
2024-05-24 19:46:44 [INFO]: Epoch 022 - training loss: 0.7988, validation loss: 1.0046
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch22_loss1.0046011060476303.pypots
2024-05-24 19:46:44 [INFO]: Epoch 023 - training loss: 0.7858, validation loss: 0.9997
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch23_loss0.999730721116066.pypots
2024-05-24 19:46:44 [INFO]: Epoch 024 - training loss: 0.7941, validation loss: 0.9980
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch24_loss0.9979808330535889.pypots
2024-05-24 19:46:44 [INFO]: Epoch 025 - training loss: 0.7861, validation loss: 0.9953
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch25_loss0.9953297972679138.pypots
2024-05-24 19:46:44 [INFO]: Epoch 026 - training loss: 0.7756, validation loss: 0.9891
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch26_loss0.9891102313995361.pypots
2024-05-24 19:46:44 [INFO]: Epoch 027 - training loss: 0.8202, validation loss: 0.9878
2024-05-24 19:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch27_loss0.9877660721540451.pypots
2024-05-24 19:46:45 [INFO]: Epoch 028 - training loss: 0.7775, validation loss: 0.9870
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch28_loss0.9870229065418243.pypots
2024-05-24 19:46:45 [INFO]: Epoch 029 - training loss: 0.7847, validation loss: 0.9810
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch29_loss0.9809795022010803.pypots
2024-05-24 19:46:45 [INFO]: Epoch 030 - training loss: 0.7804, validation loss: 0.9787
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch30_loss0.978703111410141.pypots
2024-05-24 19:46:45 [INFO]: Epoch 031 - training loss: 0.7835, validation loss: 0.9759
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch31_loss0.9758902043104172.pypots
2024-05-24 19:46:45 [INFO]: Epoch 032 - training loss: 0.7492, validation loss: 0.9736
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch32_loss0.9735697209835052.pypots
2024-05-24 19:46:45 [INFO]: Epoch 033 - training loss: 0.7595, validation loss: 0.9705
2024-05-24 19:46:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch33_loss0.9704802185297012.pypots
2024-05-24 19:46:46 [INFO]: Epoch 034 - training loss: 0.7505, validation loss: 0.9683
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch34_loss0.9683431535959244.pypots
2024-05-24 19:46:46 [INFO]: Epoch 035 - training loss: 0.7722, validation loss: 0.9661
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch35_loss0.9660584479570389.pypots
2024-05-24 19:46:46 [INFO]: Epoch 036 - training loss: 0.7610, validation loss: 0.9609
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch36_loss0.9609420597553253.pypots
2024-05-24 19:46:46 [INFO]: Epoch 037 - training loss: 0.7646, validation loss: 0.9616
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch37_loss0.9615810960531235.pypots
2024-05-24 19:46:46 [INFO]: Epoch 038 - training loss: 0.7788, validation loss: 0.9579
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch38_loss0.9578681588172913.pypots
2024-05-24 19:46:46 [INFO]: Epoch 039 - training loss: 0.7747, validation loss: 0.9551
2024-05-24 19:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch39_loss0.9551054239273071.pypots
2024-05-24 19:46:47 [INFO]: Epoch 040 - training loss: 0.7670, validation loss: 0.9535
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch40_loss0.9535144865512848.pypots
2024-05-24 19:46:47 [INFO]: Epoch 041 - training loss: 0.7297, validation loss: 0.9470
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch41_loss0.9469875991344452.pypots
2024-05-24 19:46:47 [INFO]: Epoch 042 - training loss: 0.7497, validation loss: 0.9471
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch42_loss0.947057694196701.pypots
2024-05-24 19:46:47 [INFO]: Epoch 043 - training loss: 0.7581, validation loss: 0.9442
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch43_loss0.9441830068826675.pypots
2024-05-24 19:46:47 [INFO]: Epoch 044 - training loss: 0.7629, validation loss: 0.9394
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch44_loss0.9394484460353851.pypots
2024-05-24 19:46:47 [INFO]: Epoch 045 - training loss: 0.7958, validation loss: 0.9408
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch45_loss0.9408278167247772.pypots
2024-05-24 19:46:47 [INFO]: Epoch 046 - training loss: 0.7546, validation loss: 0.9350
2024-05-24 19:46:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch46_loss0.9350451976060867.pypots
2024-05-24 19:46:48 [INFO]: Epoch 047 - training loss: 0.7575, validation loss: 0.9356
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch47_loss0.9356104880571365.pypots
2024-05-24 19:46:48 [INFO]: Epoch 048 - training loss: 0.7311, validation loss: 0.9316
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch48_loss0.9315570294857025.pypots
2024-05-24 19:46:48 [INFO]: Epoch 049 - training loss: 0.7349, validation loss: 0.9294
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch49_loss0.9294154793024063.pypots
2024-05-24 19:46:48 [INFO]: Epoch 050 - training loss: 0.7613, validation loss: 0.9299
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch50_loss0.9298730492591858.pypots
2024-05-24 19:46:48 [INFO]: Epoch 051 - training loss: 0.7440, validation loss: 0.9256
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch51_loss0.9256217628717422.pypots
2024-05-24 19:46:48 [INFO]: Epoch 052 - training loss: 0.7373, validation loss: 0.9244
2024-05-24 19:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch52_loss0.9243619441986084.pypots
2024-05-24 19:46:49 [INFO]: Epoch 053 - training loss: 0.7382, validation loss: 0.9225
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch53_loss0.9225164949893951.pypots
2024-05-24 19:46:49 [INFO]: Epoch 054 - training loss: 0.7556, validation loss: 0.9220
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch54_loss0.9220242202281952.pypots
2024-05-24 19:46:49 [INFO]: Epoch 055 - training loss: 0.7532, validation loss: 0.9217
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch55_loss0.9216693192720413.pypots
2024-05-24 19:46:49 [INFO]: Epoch 056 - training loss: 0.7511, validation loss: 0.9232
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch56_loss0.9231612980365753.pypots
2024-05-24 19:46:49 [INFO]: Epoch 057 - training loss: 0.7677, validation loss: 0.9193
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch57_loss0.9192659854888916.pypots
2024-05-24 19:46:49 [INFO]: Epoch 058 - training loss: 0.7408, validation loss: 0.9167
2024-05-24 19:46:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch58_loss0.9166822135448456.pypots
2024-05-24 19:46:50 [INFO]: Epoch 059 - training loss: 0.7459, validation loss: 0.9187
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch59_loss0.9186797589063644.pypots
2024-05-24 19:46:50 [INFO]: Epoch 060 - training loss: 0.7398, validation loss: 0.9163
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch60_loss0.9163108766078949.pypots
2024-05-24 19:46:50 [INFO]: Epoch 061 - training loss: 0.7292, validation loss: 0.9133
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch61_loss0.9133074432611465.pypots
2024-05-24 19:46:50 [INFO]: Epoch 062 - training loss: 0.7218, validation loss: 0.9122
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch62_loss0.9121809899806976.pypots
2024-05-24 19:46:50 [INFO]: Epoch 063 - training loss: 0.7292, validation loss: 0.9120
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch63_loss0.9120312333106995.pypots
2024-05-24 19:46:50 [INFO]: Epoch 064 - training loss: 0.7244, validation loss: 0.9092
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch64_loss0.9091567099094391.pypots
2024-05-24 19:46:50 [INFO]: Epoch 065 - training loss: 0.7491, validation loss: 0.9108
2024-05-24 19:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch65_loss0.9107990860939026.pypots
2024-05-24 19:46:51 [INFO]: Epoch 066 - training loss: 0.7758, validation loss: 0.9070
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch66_loss0.9070066809654236.pypots
2024-05-24 19:46:51 [INFO]: Epoch 067 - training loss: 0.7813, validation loss: 0.9095
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch67_loss0.9094682186841965.pypots
2024-05-24 19:46:51 [INFO]: Epoch 068 - training loss: 0.7565, validation loss: 0.9084
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch68_loss0.9083532989025116.pypots
2024-05-24 19:46:51 [INFO]: Epoch 069 - training loss: 0.7414, validation loss: 0.9067
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch69_loss0.9067005515098572.pypots
2024-05-24 19:46:51 [INFO]: Epoch 070 - training loss: 0.7396, validation loss: 0.9042
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch70_loss0.904180034995079.pypots
2024-05-24 19:46:51 [INFO]: Epoch 071 - training loss: 0.7397, validation loss: 0.9016
2024-05-24 19:46:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch71_loss0.9016344249248505.pypots
2024-05-24 19:46:52 [INFO]: Epoch 072 - training loss: 0.7187, validation loss: 0.9037
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch72_loss0.9036637097597122.pypots
2024-05-24 19:46:52 [INFO]: Epoch 073 - training loss: 0.7182, validation loss: 0.9020
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch73_loss0.9020487666130066.pypots
2024-05-24 19:46:52 [INFO]: Epoch 074 - training loss: 0.7294, validation loss: 0.9046
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch74_loss0.9046216756105423.pypots
2024-05-24 19:46:52 [INFO]: Epoch 075 - training loss: 0.7378, validation loss: 0.8973
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch75_loss0.8973319232463837.pypots
2024-05-24 19:46:52 [INFO]: Epoch 076 - training loss: 0.7360, validation loss: 0.8949
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch76_loss0.8948641419410706.pypots
2024-05-24 19:46:52 [INFO]: Epoch 077 - training loss: 0.7202, validation loss: 0.8938
2024-05-24 19:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch77_loss0.893785297870636.pypots
2024-05-24 19:46:53 [INFO]: Epoch 078 - training loss: 0.7109, validation loss: 0.8932
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch78_loss0.8931612968444824.pypots
2024-05-24 19:46:53 [INFO]: Epoch 079 - training loss: 0.7154, validation loss: 0.8942
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch79_loss0.8942225724458694.pypots
2024-05-24 19:46:53 [INFO]: Epoch 080 - training loss: 0.7121, validation loss: 0.8913
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch80_loss0.8912677764892578.pypots
2024-05-24 19:46:53 [INFO]: Epoch 081 - training loss: 0.7279, validation loss: 0.8936
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch81_loss0.8936433345079422.pypots
2024-05-24 19:46:53 [INFO]: Epoch 082 - training loss: 0.7181, validation loss: 0.8927
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch82_loss0.8927409499883652.pypots
2024-05-24 19:46:53 [INFO]: Epoch 083 - training loss: 0.7333, validation loss: 0.8909
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch83_loss0.8909488022327423.pypots
2024-05-24 19:46:53 [INFO]: Epoch 084 - training loss: 0.7622, validation loss: 0.8896
2024-05-24 19:46:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch84_loss0.8896257430315018.pypots
2024-05-24 19:46:54 [INFO]: Epoch 085 - training loss: 0.7525, validation loss: 0.8898
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch85_loss0.8898348212242126.pypots
2024-05-24 19:46:54 [INFO]: Epoch 086 - training loss: 0.7301, validation loss: 0.8907
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch86_loss0.8906603455543518.pypots
2024-05-24 19:46:54 [INFO]: Epoch 087 - training loss: 0.7500, validation loss: 0.8863
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch87_loss0.8862536400556564.pypots
2024-05-24 19:46:54 [INFO]: Epoch 088 - training loss: 0.7315, validation loss: 0.8853
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch88_loss0.8852748572826385.pypots
2024-05-24 19:46:54 [INFO]: Epoch 089 - training loss: 0.7454, validation loss: 0.8898
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch89_loss0.8897770196199417.pypots
2024-05-24 19:46:54 [INFO]: Epoch 090 - training loss: 0.7128, validation loss: 0.8818
2024-05-24 19:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch90_loss0.8817861378192902.pypots
2024-05-24 19:46:55 [INFO]: Epoch 091 - training loss: 0.7196, validation loss: 0.8870
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch91_loss0.886981338262558.pypots
2024-05-24 19:46:55 [INFO]: Epoch 092 - training loss: 0.7219, validation loss: 0.8832
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch92_loss0.8831710964441299.pypots
2024-05-24 19:46:55 [INFO]: Epoch 093 - training loss: 0.7112, validation loss: 0.8847
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch93_loss0.8847377151250839.pypots
2024-05-24 19:46:55 [INFO]: Epoch 094 - training loss: 0.7113, validation loss: 0.8835
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch94_loss0.8834796100854874.pypots
2024-05-24 19:46:55 [INFO]: Epoch 095 - training loss: 0.7219, validation loss: 0.8813
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch95_loss0.8813457489013672.pypots
2024-05-24 19:46:55 [INFO]: Epoch 096 - training loss: 0.7461, validation loss: 0.8806
2024-05-24 19:46:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch96_loss0.8805833160877228.pypots
2024-05-24 19:46:56 [INFO]: Epoch 097 - training loss: 0.7334, validation loss: 0.8781
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch97_loss0.8781342208385468.pypots
2024-05-24 19:46:56 [INFO]: Epoch 098 - training loss: 0.7320, validation loss: 0.8783
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch98_loss0.8782766908407211.pypots
2024-05-24 19:46:56 [INFO]: Epoch 099 - training loss: 0.7172, validation loss: 0.8797
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch99_loss0.8796719014644623.pypots
2024-05-24 19:46:56 [INFO]: Epoch 100 - training loss: 0.7258, validation loss: 0.8794
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch100_loss0.879408672451973.pypots
2024-05-24 19:46:56 [INFO]: Epoch 101 - training loss: 0.7326, validation loss: 0.8776
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch101_loss0.877645805478096.pypots
2024-05-24 19:46:56 [INFO]: Epoch 102 - training loss: 0.7243, validation loss: 0.8777
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch102_loss0.8776775747537613.pypots
2024-05-24 19:46:56 [INFO]: Epoch 103 - training loss: 0.7423, validation loss: 0.8797
2024-05-24 19:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch103_loss0.8797354400157928.pypots
2024-05-24 19:46:57 [INFO]: Epoch 104 - training loss: 0.7427, validation loss: 0.8734
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch104_loss0.873422235250473.pypots
2024-05-24 19:46:57 [INFO]: Epoch 105 - training loss: 0.7008, validation loss: 0.8768
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch105_loss0.8767973482608795.pypots
2024-05-24 19:46:57 [INFO]: Epoch 106 - training loss: 0.7199, validation loss: 0.8743
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch106_loss0.8743101060390472.pypots
2024-05-24 19:46:57 [INFO]: Epoch 107 - training loss: 0.7262, validation loss: 0.8730
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch107_loss0.873042568564415.pypots
2024-05-24 19:46:57 [INFO]: Epoch 108 - training loss: 0.7279, validation loss: 0.8739
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch108_loss0.8739138245582581.pypots
2024-05-24 19:46:57 [INFO]: Epoch 109 - training loss: 0.7430, validation loss: 0.8735
2024-05-24 19:46:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch109_loss0.873527929186821.pypots
2024-05-24 19:46:58 [INFO]: Epoch 110 - training loss: 0.7210, validation loss: 0.8685
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch110_loss0.8685461580753326.pypots
2024-05-24 19:46:58 [INFO]: Epoch 111 - training loss: 0.7295, validation loss: 0.8729
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch111_loss0.8728809058666229.pypots
2024-05-24 19:46:58 [INFO]: Epoch 112 - training loss: 0.7585, validation loss: 0.8711
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch112_loss0.871052548289299.pypots
2024-05-24 19:46:58 [INFO]: Epoch 113 - training loss: 0.7150, validation loss: 0.8717
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch113_loss0.8717037290334702.pypots
2024-05-24 19:46:58 [INFO]: Epoch 114 - training loss: 0.7358, validation loss: 0.8695
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch114_loss0.8695164173841476.pypots
2024-05-24 19:46:58 [INFO]: Epoch 115 - training loss: 0.7334, validation loss: 0.8720
2024-05-24 19:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch115_loss0.8720161467790604.pypots
2024-05-24 19:46:59 [INFO]: Epoch 116 - training loss: 0.7236, validation loss: 0.8725
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch116_loss0.8725017160177231.pypots
2024-05-24 19:46:59 [INFO]: Epoch 117 - training loss: 0.7140, validation loss: 0.8696
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch117_loss0.8695836663246155.pypots
2024-05-24 19:46:59 [INFO]: Epoch 118 - training loss: 0.7303, validation loss: 0.8692
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch118_loss0.8692431598901749.pypots
2024-05-24 19:46:59 [INFO]: Epoch 119 - training loss: 0.7343, validation loss: 0.8681
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch119_loss0.868117943406105.pypots
2024-05-24 19:46:59 [INFO]: Epoch 120 - training loss: 0.7198, validation loss: 0.8581
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch120_loss0.8581080287694931.pypots
2024-05-24 19:46:59 [INFO]: Epoch 121 - training loss: 0.7304, validation loss: 0.8648
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch121_loss0.8647972196340561.pypots
2024-05-24 19:46:59 [INFO]: Epoch 122 - training loss: 0.7285, validation loss: 0.8652
2024-05-24 19:46:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch122_loss0.865155354142189.pypots
2024-05-24 19:47:00 [INFO]: Epoch 123 - training loss: 0.7188, validation loss: 0.8642
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch123_loss0.8641742914915085.pypots
2024-05-24 19:47:00 [INFO]: Epoch 124 - training loss: 0.7240, validation loss: 0.8654
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch124_loss0.8654483556747437.pypots
2024-05-24 19:47:00 [INFO]: Epoch 125 - training loss: 0.7130, validation loss: 0.8651
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch125_loss0.8651432394981384.pypots
2024-05-24 19:47:00 [INFO]: Epoch 126 - training loss: 0.7062, validation loss: 0.8635
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch126_loss0.863483652472496.pypots
2024-05-24 19:47:00 [INFO]: Epoch 127 - training loss: 0.7280, validation loss: 0.8623
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch127_loss0.8623252511024475.pypots
2024-05-24 19:47:00 [INFO]: Epoch 128 - training loss: 0.7110, validation loss: 0.8643
2024-05-24 19:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch128_loss0.8643106371164322.pypots
2024-05-24 19:47:01 [INFO]: Epoch 129 - training loss: 0.7142, validation loss: 0.8582
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch129_loss0.8582230508327484.pypots
2024-05-24 19:47:01 [INFO]: Epoch 130 - training loss: 0.7085, validation loss: 0.8564
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch130_loss0.8563766330480576.pypots
2024-05-24 19:47:01 [INFO]: Epoch 131 - training loss: 0.7223, validation loss: 0.8564
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch131_loss0.8564132004976273.pypots
2024-05-24 19:47:01 [INFO]: Epoch 132 - training loss: 0.7104, validation loss: 0.8566
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch132_loss0.8565957695245743.pypots
2024-05-24 19:47:01 [INFO]: Epoch 133 - training loss: 0.7185, validation loss: 0.8546
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch133_loss0.8546122610569.pypots
2024-05-24 19:47:01 [INFO]: Epoch 134 - training loss: 0.7505, validation loss: 0.8529
2024-05-24 19:47:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch134_loss0.852852925658226.pypots
2024-05-24 19:47:02 [INFO]: Epoch 135 - training loss: 0.7298, validation loss: 0.8551
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch135_loss0.855055034160614.pypots
2024-05-24 19:47:02 [INFO]: Epoch 136 - training loss: 0.7034, validation loss: 0.8534
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch136_loss0.8534062206745148.pypots
2024-05-24 19:47:02 [INFO]: Epoch 137 - training loss: 0.7269, validation loss: 0.8581
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch137_loss0.8580665439367294.pypots
2024-05-24 19:47:02 [INFO]: Epoch 138 - training loss: 0.7163, validation loss: 0.8563
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch138_loss0.8562616407871246.pypots
2024-05-24 19:47:02 [INFO]: Epoch 139 - training loss: 0.7061, validation loss: 0.8552
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch139_loss0.8552418649196625.pypots
2024-05-24 19:47:02 [INFO]: Epoch 140 - training loss: 0.7171, validation loss: 0.8534
2024-05-24 19:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch140_loss0.8534029424190521.pypots
2024-05-24 19:47:03 [INFO]: Epoch 141 - training loss: 0.7101, validation loss: 0.8540
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch141_loss0.8539656698703766.pypots
2024-05-24 19:47:03 [INFO]: Epoch 142 - training loss: 0.7245, validation loss: 0.8522
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch142_loss0.8521994203329086.pypots
2024-05-24 19:47:03 [INFO]: Epoch 143 - training loss: 0.7166, validation loss: 0.8491
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch143_loss0.8490853756666183.pypots
2024-05-24 19:47:03 [INFO]: Epoch 144 - training loss: 0.7249, validation loss: 0.8483
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch144_loss0.8482934385538101.pypots
2024-05-24 19:47:03 [INFO]: Epoch 145 - training loss: 0.7330, validation loss: 0.8572
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch145_loss0.8571589589118958.pypots
2024-05-24 19:47:03 [INFO]: Epoch 146 - training loss: 0.7041, validation loss: 0.8469
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch146_loss0.8469169586896896.pypots
2024-05-24 19:47:03 [INFO]: Epoch 147 - training loss: 0.7186, validation loss: 0.8531
2024-05-24 19:47:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch147_loss0.8531053364276886.pypots
2024-05-24 19:47:04 [INFO]: Epoch 148 - training loss: 0.7267, validation loss: 0.8497
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch148_loss0.8496670126914978.pypots
2024-05-24 19:47:04 [INFO]: Epoch 149 - training loss: 0.7264, validation loss: 0.8428
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch149_loss0.842840775847435.pypots
2024-05-24 19:47:04 [INFO]: Epoch 150 - training loss: 0.7668, validation loss: 0.8432
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch150_loss0.8431519865989685.pypots
2024-05-24 19:47:04 [INFO]: Epoch 151 - training loss: 0.7196, validation loss: 0.8448
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch151_loss0.8448039442300797.pypots
2024-05-24 19:47:04 [INFO]: Epoch 152 - training loss: 0.7732, validation loss: 0.8521
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch152_loss0.8521142452955246.pypots
2024-05-24 19:47:04 [INFO]: Epoch 153 - training loss: 0.7276, validation loss: 0.8458
2024-05-24 19:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch153_loss0.8457993566989899.pypots
2024-05-24 19:47:05 [INFO]: Epoch 154 - training loss: 0.7617, validation loss: 0.8477
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch154_loss0.8476503938436508.pypots
2024-05-24 19:47:05 [INFO]: Epoch 155 - training loss: 0.7180, validation loss: 0.8449
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch155_loss0.8449351936578751.pypots
2024-05-24 19:47:05 [INFO]: Epoch 156 - training loss: 0.7234, validation loss: 0.8471
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch156_loss0.8470878601074219.pypots
2024-05-24 19:47:05 [INFO]: Epoch 157 - training loss: 0.7166, validation loss: 0.8436
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch157_loss0.8436277061700821.pypots
2024-05-24 19:47:05 [INFO]: Epoch 158 - training loss: 0.7163, validation loss: 0.8413
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch158_loss0.8412998467683792.pypots
2024-05-24 19:47:05 [INFO]: Epoch 159 - training loss: 0.7359, validation loss: 0.8423
2024-05-24 19:47:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch159_loss0.8423478156328201.pypots
2024-05-24 19:47:06 [INFO]: Epoch 160 - training loss: 0.7396, validation loss: 0.8423
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch160_loss0.8423299938440323.pypots
2024-05-24 19:47:06 [INFO]: Epoch 161 - training loss: 0.7140, validation loss: 0.8418
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch161_loss0.8418307304382324.pypots
2024-05-24 19:47:06 [INFO]: Epoch 162 - training loss: 0.7151, validation loss: 0.8410
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch162_loss0.8410169035196304.pypots
2024-05-24 19:47:06 [INFO]: Epoch 163 - training loss: 0.7138, validation loss: 0.8386
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch163_loss0.8386466056108475.pypots
2024-05-24 19:47:06 [INFO]: Epoch 164 - training loss: 0.7028, validation loss: 0.8407
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch164_loss0.8406820595264435.pypots
2024-05-24 19:47:06 [INFO]: Epoch 165 - training loss: 0.7392, validation loss: 0.8399
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch165_loss0.8398634493350983.pypots
2024-05-24 19:47:06 [INFO]: Epoch 166 - training loss: 0.7324, validation loss: 0.8391
2024-05-24 19:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch166_loss0.8391432613134384.pypots
2024-05-24 19:47:07 [INFO]: Epoch 167 - training loss: 0.7013, validation loss: 0.8377
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch167_loss0.837711751461029.pypots
2024-05-24 19:47:07 [INFO]: Epoch 168 - training loss: 0.7196, validation loss: 0.8365
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch168_loss0.8364652842283249.pypots
2024-05-24 19:47:07 [INFO]: Epoch 169 - training loss: 0.7172, validation loss: 0.8375
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch169_loss0.8375482559204102.pypots
2024-05-24 19:47:07 [INFO]: Epoch 170 - training loss: 0.7253, validation loss: 0.8392
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch170_loss0.8391545712947845.pypots
2024-05-24 19:47:07 [INFO]: Epoch 171 - training loss: 0.7054, validation loss: 0.8389
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch171_loss0.8388729095458984.pypots
2024-05-24 19:47:07 [INFO]: Epoch 172 - training loss: 0.7245, validation loss: 0.8396
2024-05-24 19:47:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch172_loss0.8396082371473312.pypots
2024-05-24 19:47:08 [INFO]: Epoch 173 - training loss: 0.7093, validation loss: 0.8349
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch173_loss0.8348634988069534.pypots
2024-05-24 19:47:08 [INFO]: Epoch 174 - training loss: 0.7188, validation loss: 0.8355
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch174_loss0.8354514092206955.pypots
2024-05-24 19:47:08 [INFO]: Epoch 175 - training loss: 0.7329, validation loss: 0.8384
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch175_loss0.8384133577346802.pypots
2024-05-24 19:47:08 [INFO]: Epoch 176 - training loss: 0.7144, validation loss: 0.8393
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch176_loss0.8393067419528961.pypots
2024-05-24 19:47:08 [INFO]: Epoch 177 - training loss: 0.7485, validation loss: 0.8350
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch177_loss0.835029125213623.pypots
2024-05-24 19:47:08 [INFO]: Epoch 178 - training loss: 0.7286, validation loss: 0.8315
2024-05-24 19:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch178_loss0.8315179198980331.pypots
2024-05-24 19:47:09 [INFO]: Epoch 179 - training loss: 0.7324, validation loss: 0.8289
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch179_loss0.8288814276456833.pypots
2024-05-24 19:47:09 [INFO]: Epoch 180 - training loss: 0.7054, validation loss: 0.8315
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch180_loss0.8315317928791046.pypots
2024-05-24 19:47:09 [INFO]: Epoch 181 - training loss: 0.6972, validation loss: 0.8354
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch181_loss0.8353891372680664.pypots
2024-05-24 19:47:09 [INFO]: Epoch 182 - training loss: 0.7304, validation loss: 0.8348
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch182_loss0.834841176867485.pypots
2024-05-24 19:47:09 [INFO]: Epoch 183 - training loss: 0.7152, validation loss: 0.8343
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch183_loss0.8343007117509842.pypots
2024-05-24 19:47:09 [INFO]: Epoch 184 - training loss: 0.7021, validation loss: 0.8330
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch184_loss0.832957535982132.pypots
2024-05-24 19:47:09 [INFO]: Epoch 185 - training loss: 0.7160, validation loss: 0.8321
2024-05-24 19:47:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch185_loss0.8321002274751663.pypots
2024-05-24 19:47:10 [INFO]: Epoch 186 - training loss: 0.6939, validation loss: 0.8295
2024-05-24 19:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch186_loss0.8295072019100189.pypots
2024-05-24 19:47:10 [INFO]: Epoch 187 - training loss: 0.7272, validation loss: 0.8324
2024-05-24 19:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch187_loss0.8323872238397598.pypots
2024-05-24 19:47:10 [INFO]: Epoch 188 - training loss: 0.7308, validation loss: 0.8310
2024-05-24 19:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch188_loss0.831039309501648.pypots
2024-05-24 19:47:10 [INFO]: Epoch 189 - training loss: 0.7063, validation loss: 0.8353
2024-05-24 19:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN_epoch189_loss0.8353479504585266.pypots
2024-05-24 19:47:10 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:47:10 [INFO]: Finished training. The best model is from epoch#179.
2024-05-24 19:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_0/MRNN_ettm1/20240524_T194639/MRNN.pypots
2024-05-24 19:47:10 [INFO]: MRNN on ETTm1: MAE=0.5992, MSE=0.9959
2024-05-24 19:47:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/MRNN_ettm1/imputation.pkl
2024-05-24 19:47:10 [INFO]: Using the given device: cpu
2024-05-24 19:47:10 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-24 19:47:10 [INFO]: Successfully created the given path "saved_results/round_0/LOCF_ettm1".
2024-05-24 19:47:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/LOCF_ettm1/imputation.pkl
2024-05-24 19:47:10 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-24 19:47:10 [INFO]: Successfully created the given path "saved_results/round_0/Median_ettm1".
2024-05-24 19:47:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Median_ettm1/imputation.pkl
2024-05-24 19:47:10 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-24 19:47:10 [INFO]: Successfully created the given path "saved_results/round_0/Mean_ettm1".
2024-05-24 19:47:10 [INFO]: Successfully saved to augmentation_premask_saved_results/round_0/Mean_ettm1/imputation.pkl
2024-05-24 19:47:10 [INFO]: Have set the random seed as 2024 for numpy and pytorch.
2024-05-24 19:47:10 [INFO]: Using the given device: cuda:0
2024-05-24 19:47:10 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T194710
2024-05-24 19:47:10 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T194710/tensorboard
2024-05-24 19:47:11 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 19:47:11 [INFO]: Epoch 001 - training loss: 1.1269, validation loss: 0.2893
2024-05-24 19:47:12 [INFO]: Epoch 002 - training loss: 0.8359, validation loss: 0.1538
2024-05-24 19:47:12 [INFO]: Epoch 003 - training loss: 0.7518, validation loss: 0.1188
2024-05-24 19:47:12 [INFO]: Epoch 004 - training loss: 0.6890, validation loss: 0.0945
2024-05-24 19:47:13 [INFO]: Epoch 005 - training loss: 0.6413, validation loss: 0.0757
2024-05-24 19:47:13 [INFO]: Epoch 006 - training loss: 0.6016, validation loss: 0.0717
2024-05-24 19:47:14 [INFO]: Epoch 007 - training loss: 0.5823, validation loss: 0.0784
2024-05-24 19:47:14 [INFO]: Epoch 008 - training loss: 0.5709, validation loss: 0.0674
2024-05-24 19:47:15 [INFO]: Epoch 009 - training loss: 0.5790, validation loss: 0.0692
2024-05-24 19:47:15 [INFO]: Epoch 010 - training loss: 0.5477, validation loss: 0.0583
2024-05-24 19:47:16 [INFO]: Epoch 011 - training loss: 0.5204, validation loss: 0.0533
2024-05-24 19:47:16 [INFO]: Epoch 012 - training loss: 0.5250, validation loss: 0.0519
2024-05-24 19:47:17 [INFO]: Epoch 013 - training loss: 0.4919, validation loss: 0.0590
2024-05-24 19:47:17 [INFO]: Epoch 014 - training loss: 0.4833, validation loss: 0.0481
2024-05-24 19:47:18 [INFO]: Epoch 015 - training loss: 0.4855, validation loss: 0.0712
2024-05-24 19:47:18 [INFO]: Epoch 016 - training loss: 0.4670, validation loss: 0.0653
2024-05-24 19:47:19 [INFO]: Epoch 017 - training loss: 0.4521, validation loss: 0.0556
2024-05-24 19:47:19 [INFO]: Epoch 018 - training loss: 0.4450, validation loss: 0.0591
2024-05-24 19:47:20 [INFO]: Epoch 019 - training loss: 0.4436, validation loss: 0.0493
2024-05-24 19:47:20 [INFO]: Epoch 020 - training loss: 0.4319, validation loss: 0.0417
2024-05-24 19:47:21 [INFO]: Epoch 021 - training loss: 0.4161, validation loss: 0.0549
2024-05-24 19:47:21 [INFO]: Epoch 022 - training loss: 0.4077, validation loss: 0.0491
2024-05-24 19:47:22 [INFO]: Epoch 023 - training loss: 0.3995, validation loss: 0.0492
2024-05-24 19:47:22 [INFO]: Epoch 024 - training loss: 0.3913, validation loss: 0.0401
2024-05-24 19:47:23 [INFO]: Epoch 025 - training loss: 0.3899, validation loss: 0.0395
2024-05-24 19:47:23 [INFO]: Epoch 026 - training loss: 0.3909, validation loss: 0.1278
2024-05-24 19:47:24 [INFO]: Epoch 027 - training loss: 0.4178, validation loss: 0.0629
2024-05-24 19:47:24 [INFO]: Epoch 028 - training loss: 0.3770, validation loss: 0.0599
2024-05-24 19:47:25 [INFO]: Epoch 029 - training loss: 0.3649, validation loss: 0.0469
2024-05-24 19:47:25 [INFO]: Epoch 030 - training loss: 0.3642, validation loss: 0.0416
2024-05-24 19:47:25 [INFO]: Epoch 031 - training loss: 0.3538, validation loss: 0.0423
2024-05-24 19:47:26 [INFO]: Epoch 032 - training loss: 0.3562, validation loss: 0.0414
2024-05-24 19:47:26 [INFO]: Epoch 033 - training loss: 0.3502, validation loss: 0.0441
2024-05-24 19:47:27 [INFO]: Epoch 034 - training loss: 0.3463, validation loss: 0.0390
2024-05-24 19:47:27 [INFO]: Epoch 035 - training loss: 0.3395, validation loss: 0.0369
2024-05-24 19:47:28 [INFO]: Epoch 036 - training loss: 0.3308, validation loss: 0.0414
2024-05-24 19:47:28 [INFO]: Epoch 037 - training loss: 0.3288, validation loss: 0.0400
2024-05-24 19:47:29 [INFO]: Epoch 038 - training loss: 0.3320, validation loss: 0.0408
2024-05-24 19:47:29 [INFO]: Epoch 039 - training loss: 0.3190, validation loss: 0.0354
2024-05-24 19:47:30 [INFO]: Epoch 040 - training loss: 0.3218, validation loss: 0.0370
2024-05-24 19:47:30 [INFO]: Epoch 041 - training loss: 0.3151, validation loss: 0.0466
2024-05-24 19:47:31 [INFO]: Epoch 042 - training loss: 0.3170, validation loss: 0.0422
2024-05-24 19:47:31 [INFO]: Epoch 043 - training loss: 0.3149, validation loss: 0.0432
2024-05-24 19:47:32 [INFO]: Epoch 044 - training loss: 0.3179, validation loss: 0.0339
2024-05-24 19:47:32 [INFO]: Epoch 045 - training loss: 0.3041, validation loss: 0.0362
2024-05-24 19:47:33 [INFO]: Epoch 046 - training loss: 0.3052, validation loss: 0.0467
2024-05-24 19:47:33 [INFO]: Epoch 047 - training loss: 0.2965, validation loss: 0.0423
2024-05-24 19:47:34 [INFO]: Epoch 048 - training loss: 0.2950, validation loss: 0.0339
2024-05-24 19:47:34 [INFO]: Epoch 049 - training loss: 0.2925, validation loss: 0.0395
2024-05-24 19:47:35 [INFO]: Epoch 050 - training loss: 0.2870, validation loss: 0.0345
2024-05-24 19:47:35 [INFO]: Epoch 051 - training loss: 0.2949, validation loss: 0.0376
2024-05-24 19:47:36 [INFO]: Epoch 052 - training loss: 0.2838, validation loss: 0.0417
2024-05-24 19:47:36 [INFO]: Epoch 053 - training loss: 0.2886, validation loss: 0.0391
2024-05-24 19:47:37 [INFO]: Epoch 054 - training loss: 0.2826, validation loss: 0.0322
2024-05-24 19:47:37 [INFO]: Epoch 055 - training loss: 0.2792, validation loss: 0.0521
2024-05-24 19:47:38 [INFO]: Epoch 056 - training loss: 0.2904, validation loss: 0.0634
2024-05-24 19:47:38 [INFO]: Epoch 057 - training loss: 0.3102, validation loss: 0.0392
2024-05-24 19:47:38 [INFO]: Epoch 058 - training loss: 0.2939, validation loss: 0.0390
2024-05-24 19:47:39 [INFO]: Epoch 059 - training loss: 0.2914, validation loss: 0.0384
2024-05-24 19:47:39 [INFO]: Epoch 060 - training loss: 0.2778, validation loss: 0.0369
2024-05-24 19:47:40 [INFO]: Epoch 061 - training loss: 0.2807, validation loss: 0.0349
2024-05-24 19:47:40 [INFO]: Epoch 062 - training loss: 0.2933, validation loss: 0.0448
2024-05-24 19:47:41 [INFO]: Epoch 063 - training loss: 0.2806, validation loss: 0.0446
2024-05-24 19:47:41 [INFO]: Epoch 064 - training loss: 0.2721, validation loss: 0.0365
2024-05-24 19:47:41 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:47:41 [INFO]: Finished training. The best model is from epoch#54.
2024-05-24 19:47:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/SAITS_ettm1/20240524_T194710/SAITS.pypots
2024-05-24 19:47:41 [INFO]: SAITS on ETTm1: MAE=0.1517, MSE=0.0468
2024-05-24 19:47:41 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/SAITS_ettm1/imputation.pkl
2024-05-24 19:47:41 [INFO]: Using the given device: cuda:0
2024-05-24 19:47:41 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T194741
2024-05-24 19:47:41 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T194741/tensorboard
2024-05-24 19:47:42 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 19:47:42 [INFO]: Epoch 001 - training loss: 1.2489, validation loss: 0.4213
2024-05-24 19:47:42 [INFO]: Epoch 002 - training loss: 0.7401, validation loss: 0.2105
2024-05-24 19:47:42 [INFO]: Epoch 003 - training loss: 0.5927, validation loss: 0.1439
2024-05-24 19:47:42 [INFO]: Epoch 004 - training loss: 0.5269, validation loss: 0.1233
2024-05-24 19:47:42 [INFO]: Epoch 005 - training loss: 0.4822, validation loss: 0.1018
2024-05-24 19:47:43 [INFO]: Epoch 006 - training loss: 0.4565, validation loss: 0.0870
2024-05-24 19:47:43 [INFO]: Epoch 007 - training loss: 0.4347, validation loss: 0.0765
2024-05-24 19:47:43 [INFO]: Epoch 008 - training loss: 0.4159, validation loss: 0.0736
2024-05-24 19:47:43 [INFO]: Epoch 009 - training loss: 0.4036, validation loss: 0.0668
2024-05-24 19:47:43 [INFO]: Epoch 010 - training loss: 0.3867, validation loss: 0.0632
2024-05-24 19:47:44 [INFO]: Epoch 011 - training loss: 0.3737, validation loss: 0.0599
2024-05-24 19:47:44 [INFO]: Epoch 012 - training loss: 0.3695, validation loss: 0.0542
2024-05-24 19:47:44 [INFO]: Epoch 013 - training loss: 0.3546, validation loss: 0.0571
2024-05-24 19:47:44 [INFO]: Epoch 014 - training loss: 0.3481, validation loss: 0.0557
2024-05-24 19:47:44 [INFO]: Epoch 015 - training loss: 0.3447, validation loss: 0.0559
2024-05-24 19:47:45 [INFO]: Epoch 016 - training loss: 0.3371, validation loss: 0.0465
2024-05-24 19:47:45 [INFO]: Epoch 017 - training loss: 0.3245, validation loss: 0.0467
2024-05-24 19:47:45 [INFO]: Epoch 018 - training loss: 0.3224, validation loss: 0.0474
2024-05-24 19:47:45 [INFO]: Epoch 019 - training loss: 0.3128, validation loss: 0.0469
2024-05-24 19:47:45 [INFO]: Epoch 020 - training loss: 0.3201, validation loss: 0.0457
2024-05-24 19:47:46 [INFO]: Epoch 021 - training loss: 0.3125, validation loss: 0.0456
2024-05-24 19:47:46 [INFO]: Epoch 022 - training loss: 0.3025, validation loss: 0.0427
2024-05-24 19:47:46 [INFO]: Epoch 023 - training loss: 0.3032, validation loss: 0.0417
2024-05-24 19:47:46 [INFO]: Epoch 024 - training loss: 0.2962, validation loss: 0.0445
2024-05-24 19:47:46 [INFO]: Epoch 025 - training loss: 0.2967, validation loss: 0.0412
2024-05-24 19:47:46 [INFO]: Epoch 026 - training loss: 0.2895, validation loss: 0.0386
2024-05-24 19:47:47 [INFO]: Epoch 027 - training loss: 0.2904, validation loss: 0.0423
2024-05-24 19:47:47 [INFO]: Epoch 028 - training loss: 0.2865, validation loss: 0.0439
2024-05-24 19:47:47 [INFO]: Epoch 029 - training loss: 0.2955, validation loss: 0.0381
2024-05-24 19:47:47 [INFO]: Epoch 030 - training loss: 0.2777, validation loss: 0.0378
2024-05-24 19:47:47 [INFO]: Epoch 031 - training loss: 0.2727, validation loss: 0.0375
2024-05-24 19:47:48 [INFO]: Epoch 032 - training loss: 0.2630, validation loss: 0.0377
2024-05-24 19:47:48 [INFO]: Epoch 033 - training loss: 0.2655, validation loss: 0.0346
2024-05-24 19:47:48 [INFO]: Epoch 034 - training loss: 0.2589, validation loss: 0.0342
2024-05-24 19:47:48 [INFO]: Epoch 035 - training loss: 0.2578, validation loss: 0.0357
2024-05-24 19:47:48 [INFO]: Epoch 036 - training loss: 0.2578, validation loss: 0.0338
2024-05-24 19:47:49 [INFO]: Epoch 037 - training loss: 0.2527, validation loss: 0.0305
2024-05-24 19:47:49 [INFO]: Epoch 038 - training loss: 0.2463, validation loss: 0.0315
2024-05-24 19:47:49 [INFO]: Epoch 039 - training loss: 0.2509, validation loss: 0.0363
2024-05-24 19:47:49 [INFO]: Epoch 040 - training loss: 0.2502, validation loss: 0.0323
2024-05-24 19:47:49 [INFO]: Epoch 041 - training loss: 0.2444, validation loss: 0.0364
2024-05-24 19:47:49 [INFO]: Epoch 042 - training loss: 0.2446, validation loss: 0.0320
2024-05-24 19:47:50 [INFO]: Epoch 043 - training loss: 0.2356, validation loss: 0.0321
2024-05-24 19:47:50 [INFO]: Epoch 044 - training loss: 0.2374, validation loss: 0.0308
2024-05-24 19:47:50 [INFO]: Epoch 045 - training loss: 0.2376, validation loss: 0.0323
2024-05-24 19:47:50 [INFO]: Epoch 046 - training loss: 0.2414, validation loss: 0.0332
2024-05-24 19:47:50 [INFO]: Epoch 047 - training loss: 0.2361, validation loss: 0.0295
2024-05-24 19:47:51 [INFO]: Epoch 048 - training loss: 0.2312, validation loss: 0.0342
2024-05-24 19:47:51 [INFO]: Epoch 049 - training loss: 0.2324, validation loss: 0.0374
2024-05-24 19:47:51 [INFO]: Epoch 050 - training loss: 0.2311, validation loss: 0.0300
2024-05-24 19:47:51 [INFO]: Epoch 051 - training loss: 0.2263, validation loss: 0.0282
2024-05-24 19:47:51 [INFO]: Epoch 052 - training loss: 0.2236, validation loss: 0.0286
2024-05-24 19:47:52 [INFO]: Epoch 053 - training loss: 0.2277, validation loss: 0.0286
2024-05-24 19:47:52 [INFO]: Epoch 054 - training loss: 0.2205, validation loss: 0.0274
2024-05-24 19:47:52 [INFO]: Epoch 055 - training loss: 0.2187, validation loss: 0.0296
2024-05-24 19:47:52 [INFO]: Epoch 056 - training loss: 0.2256, validation loss: 0.0290
2024-05-24 19:47:52 [INFO]: Epoch 057 - training loss: 0.2145, validation loss: 0.0307
2024-05-24 19:47:53 [INFO]: Epoch 058 - training loss: 0.2219, validation loss: 0.0287
2024-05-24 19:47:53 [INFO]: Epoch 059 - training loss: 0.2160, validation loss: 0.0302
2024-05-24 19:47:53 [INFO]: Epoch 060 - training loss: 0.2140, validation loss: 0.0258
2024-05-24 19:47:53 [INFO]: Epoch 061 - training loss: 0.2093, validation loss: 0.0274
2024-05-24 19:47:53 [INFO]: Epoch 062 - training loss: 0.2099, validation loss: 0.0263
2024-05-24 19:47:53 [INFO]: Epoch 063 - training loss: 0.2109, validation loss: 0.0257
2024-05-24 19:47:54 [INFO]: Epoch 064 - training loss: 0.2074, validation loss: 0.0255
2024-05-24 19:47:54 [INFO]: Epoch 065 - training loss: 0.2037, validation loss: 0.0274
2024-05-24 19:47:54 [INFO]: Epoch 066 - training loss: 0.2053, validation loss: 0.0282
2024-05-24 19:47:54 [INFO]: Epoch 067 - training loss: 0.2092, validation loss: 0.0269
2024-05-24 19:47:54 [INFO]: Epoch 068 - training loss: 0.2069, validation loss: 0.0257
2024-05-24 19:47:55 [INFO]: Epoch 069 - training loss: 0.2006, validation loss: 0.0275
2024-05-24 19:47:55 [INFO]: Epoch 070 - training loss: 0.2106, validation loss: 0.0258
2024-05-24 19:47:55 [INFO]: Epoch 071 - training loss: 0.2077, validation loss: 0.0254
2024-05-24 19:47:55 [INFO]: Epoch 072 - training loss: 0.2062, validation loss: 0.0250
2024-05-24 19:47:55 [INFO]: Epoch 073 - training loss: 0.1989, validation loss: 0.0249
2024-05-24 19:47:56 [INFO]: Epoch 074 - training loss: 0.1979, validation loss: 0.0258
2024-05-24 19:47:56 [INFO]: Epoch 075 - training loss: 0.1999, validation loss: 0.0261
2024-05-24 19:47:56 [INFO]: Epoch 076 - training loss: 0.1965, validation loss: 0.0263
2024-05-24 19:47:56 [INFO]: Epoch 077 - training loss: 0.1965, validation loss: 0.0259
2024-05-24 19:47:56 [INFO]: Epoch 078 - training loss: 0.1983, validation loss: 0.0291
2024-05-24 19:47:56 [INFO]: Epoch 079 - training loss: 0.2034, validation loss: 0.0255
2024-05-24 19:47:57 [INFO]: Epoch 080 - training loss: 0.1990, validation loss: 0.0243
2024-05-24 19:47:57 [INFO]: Epoch 081 - training loss: 0.1929, validation loss: 0.0255
2024-05-24 19:47:57 [INFO]: Epoch 082 - training loss: 0.1935, validation loss: 0.0252
2024-05-24 19:47:57 [INFO]: Epoch 083 - training loss: 0.1897, validation loss: 0.0242
2024-05-24 19:47:57 [INFO]: Epoch 084 - training loss: 0.1920, validation loss: 0.0256
2024-05-24 19:47:58 [INFO]: Epoch 085 - training loss: 0.1903, validation loss: 0.0240
2024-05-24 19:47:58 [INFO]: Epoch 086 - training loss: 0.1901, validation loss: 0.0256
2024-05-24 19:47:58 [INFO]: Epoch 087 - training loss: 0.1939, validation loss: 0.0267
2024-05-24 19:47:58 [INFO]: Epoch 088 - training loss: 0.1924, validation loss: 0.0254
2024-05-24 19:47:58 [INFO]: Epoch 089 - training loss: 0.1944, validation loss: 0.0248
2024-05-24 19:47:59 [INFO]: Epoch 090 - training loss: 0.1932, validation loss: 0.0281
2024-05-24 19:47:59 [INFO]: Epoch 091 - training loss: 0.2077, validation loss: 0.0290
2024-05-24 19:47:59 [INFO]: Epoch 092 - training loss: 0.1975, validation loss: 0.0249
2024-05-24 19:47:59 [INFO]: Epoch 093 - training loss: 0.1874, validation loss: 0.0241
2024-05-24 19:47:59 [INFO]: Epoch 094 - training loss: 0.1888, validation loss: 0.0258
2024-05-24 19:48:00 [INFO]: Epoch 095 - training loss: 0.1883, validation loss: 0.0266
2024-05-24 19:48:00 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:48:00 [INFO]: Finished training. The best model is from epoch#85.
2024-05-24 19:48:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/Transformer_ettm1/20240524_T194741/Transformer.pypots
2024-05-24 19:48:00 [INFO]: Transformer on ETTm1: MAE=0.1322, MSE=0.0349
2024-05-24 19:48:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Transformer_ettm1/imputation.pkl
2024-05-24 19:48:00 [INFO]: Using the given device: cuda:0
2024-05-24 19:48:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T194800
2024-05-24 19:48:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T194800/tensorboard
2024-05-24 19:48:00 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 19:48:00 [INFO]: Epoch 001 - training loss: 0.1691, validation loss: 0.0600
2024-05-24 19:48:00 [INFO]: Epoch 002 - training loss: 0.0755, validation loss: 0.0432
2024-05-24 19:48:00 [INFO]: Epoch 003 - training loss: 0.0573, validation loss: 0.0369
2024-05-24 19:48:00 [INFO]: Epoch 004 - training loss: 0.0485, validation loss: 0.0342
2024-05-24 19:48:01 [INFO]: Epoch 005 - training loss: 0.0442, validation loss: 0.0313
2024-05-24 19:48:01 [INFO]: Epoch 006 - training loss: 0.0397, validation loss: 0.0298
2024-05-24 19:48:01 [INFO]: Epoch 007 - training loss: 0.0392, validation loss: 0.0289
2024-05-24 19:48:01 [INFO]: Epoch 008 - training loss: 0.0396, validation loss: 0.0291
2024-05-24 19:48:01 [INFO]: Epoch 009 - training loss: 0.0381, validation loss: 0.0301
2024-05-24 19:48:02 [INFO]: Epoch 010 - training loss: 0.0382, validation loss: 0.0285
2024-05-24 19:48:02 [INFO]: Epoch 011 - training loss: 0.0380, validation loss: 0.0279
2024-05-24 19:48:02 [INFO]: Epoch 012 - training loss: 0.0371, validation loss: 0.0285
2024-05-24 19:48:02 [INFO]: Epoch 013 - training loss: 0.0408, validation loss: 0.0302
2024-05-24 19:48:02 [INFO]: Epoch 014 - training loss: 0.0406, validation loss: 0.0291
2024-05-24 19:48:02 [INFO]: Epoch 015 - training loss: 0.0386, validation loss: 0.0293
2024-05-24 19:48:03 [INFO]: Epoch 016 - training loss: 0.0375, validation loss: 0.0297
2024-05-24 19:48:03 [INFO]: Epoch 017 - training loss: 0.0372, validation loss: 0.0284
2024-05-24 19:48:03 [INFO]: Epoch 018 - training loss: 0.0365, validation loss: 0.0285
2024-05-24 19:48:03 [INFO]: Epoch 019 - training loss: 0.0364, validation loss: 0.0281
2024-05-24 19:48:03 [INFO]: Epoch 020 - training loss: 0.0343, validation loss: 0.0272
2024-05-24 19:48:04 [INFO]: Epoch 021 - training loss: 0.0313, validation loss: 0.0273
2024-05-24 19:48:04 [INFO]: Epoch 022 - training loss: 0.0331, validation loss: 0.0275
2024-05-24 19:48:04 [INFO]: Epoch 023 - training loss: 0.0335, validation loss: 0.0272
2024-05-24 19:48:04 [INFO]: Epoch 024 - training loss: 0.0334, validation loss: 0.0261
2024-05-24 19:48:04 [INFO]: Epoch 025 - training loss: 0.0317, validation loss: 0.0272
2024-05-24 19:48:04 [INFO]: Epoch 026 - training loss: 0.0331, validation loss: 0.0277
2024-05-24 19:48:05 [INFO]: Epoch 027 - training loss: 0.0312, validation loss: 0.0267
2024-05-24 19:48:05 [INFO]: Epoch 028 - training loss: 0.0298, validation loss: 0.0266
2024-05-24 19:48:05 [INFO]: Epoch 029 - training loss: 0.0293, validation loss: 0.0257
2024-05-24 19:48:05 [INFO]: Epoch 030 - training loss: 0.0287, validation loss: 0.0263
2024-05-24 19:48:05 [INFO]: Epoch 031 - training loss: 0.0305, validation loss: 0.0258
2024-05-24 19:48:06 [INFO]: Epoch 032 - training loss: 0.0290, validation loss: 0.0270
2024-05-24 19:48:06 [INFO]: Epoch 033 - training loss: 0.0322, validation loss: 0.0270
2024-05-24 19:48:06 [INFO]: Epoch 034 - training loss: 0.0315, validation loss: 0.0266
2024-05-24 19:48:06 [INFO]: Epoch 035 - training loss: 0.0275, validation loss: 0.0256
2024-05-24 19:48:06 [INFO]: Epoch 036 - training loss: 0.0283, validation loss: 0.0261
2024-05-24 19:48:06 [INFO]: Epoch 037 - training loss: 0.0275, validation loss: 0.0260
2024-05-24 19:48:07 [INFO]: Epoch 038 - training loss: 0.0266, validation loss: 0.0260
2024-05-24 19:48:07 [INFO]: Epoch 039 - training loss: 0.0256, validation loss: 0.0252
2024-05-24 19:48:07 [INFO]: Epoch 040 - training loss: 0.0251, validation loss: 0.0262
2024-05-24 19:48:07 [INFO]: Epoch 041 - training loss: 0.0254, validation loss: 0.0259
2024-05-24 19:48:07 [INFO]: Epoch 042 - training loss: 0.0246, validation loss: 0.0257
2024-05-24 19:48:07 [INFO]: Epoch 043 - training loss: 0.0245, validation loss: 0.0259
2024-05-24 19:48:08 [INFO]: Epoch 044 - training loss: 0.0243, validation loss: 0.0253
2024-05-24 19:48:08 [INFO]: Epoch 045 - training loss: 0.0234, validation loss: 0.0259
2024-05-24 19:48:08 [INFO]: Epoch 046 - training loss: 0.0230, validation loss: 0.0259
2024-05-24 19:48:08 [INFO]: Epoch 047 - training loss: 0.0230, validation loss: 0.0255
2024-05-24 19:48:08 [INFO]: Epoch 048 - training loss: 0.0225, validation loss: 0.0252
2024-05-24 19:48:09 [INFO]: Epoch 049 - training loss: 0.0225, validation loss: 0.0264
2024-05-24 19:48:09 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:48:09 [INFO]: Finished training. The best model is from epoch#39.
2024-05-24 19:48:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/TimesNet_ettm1/20240524_T194800/TimesNet.pypots
2024-05-24 19:48:09 [INFO]: TimesNet on ETTm1: MAE=0.1153, MSE=0.0287
2024-05-24 19:48:09 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/TimesNet_ettm1/imputation.pkl
2024-05-24 19:48:09 [INFO]: Using the given device: cuda:0
2024-05-24 19:48:09 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809
2024-05-24 19:48:09 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/tensorboard
2024-05-24 19:48:09 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 19:48:11 [INFO]: Epoch 001 - training loss: 0.6914, validation loss: 0.4268
2024-05-24 19:48:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch1_loss0.42680495232343674.pypots
2024-05-24 19:48:13 [INFO]: Epoch 002 - training loss: 0.4163, validation loss: 0.3814
2024-05-24 19:48:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch2_loss0.3814081400632858.pypots
2024-05-24 19:48:15 [INFO]: Epoch 003 - training loss: 0.3059, validation loss: 0.3035
2024-05-24 19:48:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch3_loss0.30348775535821915.pypots
2024-05-24 19:48:17 [INFO]: Epoch 004 - training loss: 0.3620, validation loss: 0.2909
2024-05-24 19:48:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch4_loss0.29091840237379074.pypots
2024-05-24 19:48:19 [INFO]: Epoch 005 - training loss: 0.2883, validation loss: 0.2635
2024-05-24 19:48:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch5_loss0.2634993940591812.pypots
2024-05-24 19:48:21 [INFO]: Epoch 006 - training loss: 0.2789, validation loss: 0.2591
2024-05-24 19:48:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch6_loss0.25906042009592056.pypots
2024-05-24 19:48:23 [INFO]: Epoch 007 - training loss: 0.2719, validation loss: 0.2485
2024-05-24 19:48:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch7_loss0.2485123910009861.pypots
2024-05-24 19:48:25 [INFO]: Epoch 008 - training loss: 0.3037, validation loss: 0.2469
2024-05-24 19:48:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch8_loss0.24686040356755257.pypots
2024-05-24 19:48:27 [INFO]: Epoch 009 - training loss: 0.2219, validation loss: 0.2362
2024-05-24 19:48:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch9_loss0.23620371893048286.pypots
2024-05-24 19:48:29 [INFO]: Epoch 010 - training loss: 0.2550, validation loss: 0.2416
2024-05-24 19:48:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch10_loss0.24156324565410614.pypots
2024-05-24 19:48:31 [INFO]: Epoch 011 - training loss: 0.2241, validation loss: 0.2349
2024-05-24 19:48:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch11_loss0.23489096760749817.pypots
2024-05-24 19:48:33 [INFO]: Epoch 012 - training loss: 0.2256, validation loss: 0.2312
2024-05-24 19:48:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch12_loss0.231176245957613.pypots
2024-05-24 19:48:35 [INFO]: Epoch 013 - training loss: 0.2845, validation loss: 0.2182
2024-05-24 19:48:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch13_loss0.2181617207825184.pypots
2024-05-24 19:48:37 [INFO]: Epoch 014 - training loss: 0.2003, validation loss: 0.2037
2024-05-24 19:48:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch14_loss0.20370401442050934.pypots
2024-05-24 19:48:39 [INFO]: Epoch 015 - training loss: 0.1760, validation loss: 0.1921
2024-05-24 19:48:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch15_loss0.19206934049725533.pypots
2024-05-24 19:48:41 [INFO]: Epoch 016 - training loss: 0.1809, validation loss: 0.1812
2024-05-24 19:48:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch16_loss0.18120690435171127.pypots
2024-05-24 19:48:43 [INFO]: Epoch 017 - training loss: 0.1889, validation loss: 0.1793
2024-05-24 19:48:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch17_loss0.1792532540857792.pypots
2024-05-24 19:48:45 [INFO]: Epoch 018 - training loss: 0.1720, validation loss: 0.1764
2024-05-24 19:48:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch18_loss0.17636948823928833.pypots
2024-05-24 19:48:47 [INFO]: Epoch 019 - training loss: 0.1797, validation loss: 0.1686
2024-05-24 19:48:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch19_loss0.16859396919608116.pypots
2024-05-24 19:48:49 [INFO]: Epoch 020 - training loss: 0.1592, validation loss: 0.1685
2024-05-24 19:48:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch20_loss0.16851980239152908.pypots
2024-05-24 19:48:51 [INFO]: Epoch 021 - training loss: 0.1466, validation loss: 0.1593
2024-05-24 19:48:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch21_loss0.15926403552293777.pypots
2024-05-24 19:48:53 [INFO]: Epoch 022 - training loss: 0.2137, validation loss: 0.1598
2024-05-24 19:48:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch22_loss0.15979959070682526.pypots
2024-05-24 19:48:55 [INFO]: Epoch 023 - training loss: 0.1651, validation loss: 0.1592
2024-05-24 19:48:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch23_loss0.15918104350566864.pypots
2024-05-24 19:48:57 [INFO]: Epoch 024 - training loss: 0.1642, validation loss: 0.1534
2024-05-24 19:48:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch24_loss0.1534033715724945.pypots
2024-05-24 19:48:59 [INFO]: Epoch 025 - training loss: 0.1647, validation loss: 0.1672
2024-05-24 19:48:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch25_loss0.16724565625190735.pypots
2024-05-24 19:49:01 [INFO]: Epoch 026 - training loss: 0.1838, validation loss: 0.1535
2024-05-24 19:49:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch26_loss0.15345105156302452.pypots
2024-05-24 19:49:03 [INFO]: Epoch 027 - training loss: 0.1854, validation loss: 0.1574
2024-05-24 19:49:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch27_loss0.15741650760173798.pypots
2024-05-24 19:49:05 [INFO]: Epoch 028 - training loss: 0.1496, validation loss: 0.1532
2024-05-24 19:49:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch28_loss0.1532215252518654.pypots
2024-05-24 19:49:07 [INFO]: Epoch 029 - training loss: 0.1742, validation loss: 0.1676
2024-05-24 19:49:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch29_loss0.16759157925844193.pypots
2024-05-24 19:49:09 [INFO]: Epoch 030 - training loss: 0.1817, validation loss: 0.1703
2024-05-24 19:49:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch30_loss0.17033186927437782.pypots
2024-05-24 19:49:11 [INFO]: Epoch 031 - training loss: 0.2249, validation loss: 0.1649
2024-05-24 19:49:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch31_loss0.1648949384689331.pypots
2024-05-24 19:49:13 [INFO]: Epoch 032 - training loss: 0.1572, validation loss: 0.1523
2024-05-24 19:49:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch32_loss0.15226122364401817.pypots
2024-05-24 19:49:15 [INFO]: Epoch 033 - training loss: 0.1370, validation loss: 0.1487
2024-05-24 19:49:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch33_loss0.14868395030498505.pypots
2024-05-24 19:49:18 [INFO]: Epoch 034 - training loss: 0.1685, validation loss: 0.1397
2024-05-24 19:49:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch34_loss0.13965155184268951.pypots
2024-05-24 19:49:20 [INFO]: Epoch 035 - training loss: 0.1476, validation loss: 0.1397
2024-05-24 19:49:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch35_loss0.13972295075654984.pypots
2024-05-24 19:49:22 [INFO]: Epoch 036 - training loss: 0.1825, validation loss: 0.1636
2024-05-24 19:49:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch36_loss0.1636338010430336.pypots
2024-05-24 19:49:24 [INFO]: Epoch 037 - training loss: 0.1851, validation loss: 0.1539
2024-05-24 19:49:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch37_loss0.15388582274317741.pypots
2024-05-24 19:49:26 [INFO]: Epoch 038 - training loss: 0.1578, validation loss: 0.1413
2024-05-24 19:49:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch38_loss0.1412862204015255.pypots
2024-05-24 19:49:28 [INFO]: Epoch 039 - training loss: 0.1307, validation loss: 0.1438
2024-05-24 19:49:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch39_loss0.14383593574166298.pypots
2024-05-24 19:49:30 [INFO]: Epoch 040 - training loss: 0.1407, validation loss: 0.1373
2024-05-24 19:49:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch40_loss0.13732433691620827.pypots
2024-05-24 19:49:32 [INFO]: Epoch 041 - training loss: 0.1481, validation loss: 0.1374
2024-05-24 19:49:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch41_loss0.13738282769918442.pypots
2024-05-24 19:49:34 [INFO]: Epoch 042 - training loss: 0.1601, validation loss: 0.1413
2024-05-24 19:49:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch42_loss0.1412908397614956.pypots
2024-05-24 19:49:36 [INFO]: Epoch 043 - training loss: 0.1395, validation loss: 0.1351
2024-05-24 19:49:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch43_loss0.1350582093000412.pypots
2024-05-24 19:49:38 [INFO]: Epoch 044 - training loss: 0.1396, validation loss: 0.1332
2024-05-24 19:49:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch44_loss0.13319305330514908.pypots
2024-05-24 19:49:40 [INFO]: Epoch 045 - training loss: 0.1451, validation loss: 0.1312
2024-05-24 19:49:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch45_loss0.13124743103981018.pypots
2024-05-24 19:49:42 [INFO]: Epoch 046 - training loss: 0.1289, validation loss: 0.1325
2024-05-24 19:49:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch46_loss0.13253806717693806.pypots
2024-05-24 19:49:44 [INFO]: Epoch 047 - training loss: 0.1405, validation loss: 0.1284
2024-05-24 19:49:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch47_loss0.1283546481281519.pypots
2024-05-24 19:49:46 [INFO]: Epoch 048 - training loss: 0.1920, validation loss: 0.1454
2024-05-24 19:49:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch48_loss0.14538399502635002.pypots
2024-05-24 19:49:48 [INFO]: Epoch 049 - training loss: 0.1447, validation loss: 0.1395
2024-05-24 19:49:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch49_loss0.1394745409488678.pypots
2024-05-24 19:49:50 [INFO]: Epoch 050 - training loss: 0.1288, validation loss: 0.1333
2024-05-24 19:49:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch50_loss0.133348498493433.pypots
2024-05-24 19:49:52 [INFO]: Epoch 051 - training loss: 0.1357, validation loss: 0.1307
2024-05-24 19:49:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch51_loss0.13068684004247189.pypots
2024-05-24 19:49:54 [INFO]: Epoch 052 - training loss: 0.1204, validation loss: 0.1304
2024-05-24 19:49:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch52_loss0.13040482252836227.pypots
2024-05-24 19:49:56 [INFO]: Epoch 053 - training loss: 0.1435, validation loss: 0.1288
2024-05-24 19:49:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch53_loss0.12884854711592197.pypots
2024-05-24 19:49:58 [INFO]: Epoch 054 - training loss: 0.1288, validation loss: 0.1280
2024-05-24 19:49:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch54_loss0.12796523608267307.pypots
2024-05-24 19:50:00 [INFO]: Epoch 055 - training loss: 0.1212, validation loss: 0.1258
2024-05-24 19:50:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch55_loss0.12582617066800594.pypots
2024-05-24 19:50:02 [INFO]: Epoch 056 - training loss: 0.1612, validation loss: 0.1333
2024-05-24 19:50:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch56_loss0.13332239538431168.pypots
2024-05-24 19:50:04 [INFO]: Epoch 057 - training loss: 0.1609, validation loss: 0.1428
2024-05-24 19:50:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch57_loss0.1428408920764923.pypots
2024-05-24 19:50:06 [INFO]: Epoch 058 - training loss: 0.1925, validation loss: 0.1419
2024-05-24 19:50:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch58_loss0.14191478118300438.pypots
2024-05-24 19:50:08 [INFO]: Epoch 059 - training loss: 0.1589, validation loss: 0.1470
2024-05-24 19:50:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch59_loss0.14702988415956497.pypots
2024-05-24 19:50:10 [INFO]: Epoch 060 - training loss: 0.1493, validation loss: 0.1398
2024-05-24 19:50:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch60_loss0.13982364162802696.pypots
2024-05-24 19:50:12 [INFO]: Epoch 061 - training loss: 0.1815, validation loss: 0.1469
2024-05-24 19:50:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch61_loss0.14689397811889648.pypots
2024-05-24 19:50:14 [INFO]: Epoch 062 - training loss: 0.1782, validation loss: 0.1529
2024-05-24 19:50:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch62_loss0.15287809073925018.pypots
2024-05-24 19:50:16 [INFO]: Epoch 063 - training loss: 0.1738, validation loss: 0.1398
2024-05-24 19:50:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch63_loss0.13984421640634537.pypots
2024-05-24 19:50:18 [INFO]: Epoch 064 - training loss: 0.1403, validation loss: 0.1318
2024-05-24 19:50:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch64_loss0.13176477514207363.pypots
2024-05-24 19:50:20 [INFO]: Epoch 065 - training loss: 0.1315, validation loss: 0.1276
2024-05-24 19:50:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI_epoch65_loss0.12762054800987244.pypots
2024-05-24 19:50:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:50:20 [INFO]: Finished training. The best model is from epoch#55.
2024-05-24 19:50:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/CSDI_ettm1/20240524_T194809/CSDI.pypots
2024-05-24 19:50:36 [INFO]: CSDI on ETTm1: MAE=0.1219, MSE=0.0393
2024-05-24 19:50:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/CSDI_ettm1/imputation.pkl
2024-05-24 19:50:36 [INFO]: Using the given device: cuda:0
2024-05-24 19:50:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T195036
2024-05-24 19:50:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T195036/tensorboard
2024-05-24 19:50:36 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 19:50:36 [INFO]: Epoch 001 - training loss: 24104.7078, validation loss: 0.9798
2024-05-24 19:50:36 [INFO]: Epoch 002 - training loss: 22287.5569, validation loss: 0.9760
2024-05-24 19:50:36 [INFO]: Epoch 003 - training loss: 20340.6139, validation loss: 0.9742
2024-05-24 19:50:36 [INFO]: Epoch 004 - training loss: 18573.7833, validation loss: 0.9625
2024-05-24 19:50:37 [INFO]: Epoch 005 - training loss: 16661.2181, validation loss: 0.9458
2024-05-24 19:50:37 [INFO]: Epoch 006 - training loss: 14792.9103, validation loss: 0.9101
2024-05-24 19:50:37 [INFO]: Epoch 007 - training loss: 13545.0322, validation loss: 0.8348
2024-05-24 19:50:37 [INFO]: Epoch 008 - training loss: 12317.4918, validation loss: 0.7430
2024-05-24 19:50:37 [INFO]: Epoch 009 - training loss: 11681.2448, validation loss: 0.6867
2024-05-24 19:50:37 [INFO]: Epoch 010 - training loss: 11208.1706, validation loss: 0.6188
2024-05-24 19:50:37 [INFO]: Epoch 011 - training loss: 10847.2429, validation loss: 0.5578
2024-05-24 19:50:37 [INFO]: Epoch 012 - training loss: 10631.0358, validation loss: 0.5119
2024-05-24 19:50:37 [INFO]: Epoch 013 - training loss: 10387.0604, validation loss: 0.4968
2024-05-24 19:50:38 [INFO]: Epoch 014 - training loss: 10192.5634, validation loss: 0.4749
2024-05-24 19:50:38 [INFO]: Epoch 015 - training loss: 10043.9898, validation loss: 0.4555
2024-05-24 19:50:38 [INFO]: Epoch 016 - training loss: 9933.6791, validation loss: 0.4367
2024-05-24 19:50:38 [INFO]: Epoch 017 - training loss: 9941.9180, validation loss: 0.4158
2024-05-24 19:50:38 [INFO]: Epoch 018 - training loss: 9792.7144, validation loss: 0.3947
2024-05-24 19:50:38 [INFO]: Epoch 019 - training loss: 9815.5981, validation loss: 0.3763
2024-05-24 19:50:38 [INFO]: Epoch 020 - training loss: 9767.9070, validation loss: 0.3574
2024-05-24 19:50:38 [INFO]: Epoch 021 - training loss: 9648.0177, validation loss: 0.3408
2024-05-24 19:50:38 [INFO]: Epoch 022 - training loss: 9649.0858, validation loss: 0.3287
2024-05-24 19:50:38 [INFO]: Epoch 023 - training loss: 9595.7335, validation loss: 0.3153
2024-05-24 19:50:39 [INFO]: Epoch 024 - training loss: 9539.9391, validation loss: 0.3077
2024-05-24 19:50:39 [INFO]: Epoch 025 - training loss: 9511.6859, validation loss: 0.2956
2024-05-24 19:50:39 [INFO]: Epoch 026 - training loss: 9528.3865, validation loss: 0.2892
2024-05-24 19:50:39 [INFO]: Epoch 027 - training loss: 9473.0655, validation loss: 0.2810
2024-05-24 19:50:39 [INFO]: Epoch 028 - training loss: 9472.4048, validation loss: 0.2758
2024-05-24 19:50:39 [INFO]: Epoch 029 - training loss: 9440.0735, validation loss: 0.2676
2024-05-24 19:50:39 [INFO]: Epoch 030 - training loss: 9422.3990, validation loss: 0.2635
2024-05-24 19:50:39 [INFO]: Epoch 031 - training loss: 9413.1356, validation loss: 0.2574
2024-05-24 19:50:39 [INFO]: Epoch 032 - training loss: 9411.9552, validation loss: 0.2555
2024-05-24 19:50:40 [INFO]: Epoch 033 - training loss: 9392.2634, validation loss: 0.2461
2024-05-24 19:50:40 [INFO]: Epoch 034 - training loss: 9388.1133, validation loss: 0.2425
2024-05-24 19:50:40 [INFO]: Epoch 035 - training loss: 9373.5961, validation loss: 0.2377
2024-05-24 19:50:40 [INFO]: Epoch 036 - training loss: 9377.0693, validation loss: 0.2359
2024-05-24 19:50:40 [INFO]: Epoch 037 - training loss: 9358.4666, validation loss: 0.2254
2024-05-24 19:50:40 [INFO]: Epoch 038 - training loss: 9358.0027, validation loss: 0.2225
2024-05-24 19:50:40 [INFO]: Epoch 039 - training loss: 9344.6204, validation loss: 0.2205
2024-05-24 19:50:40 [INFO]: Epoch 040 - training loss: 9335.7601, validation loss: 0.2163
2024-05-24 19:50:40 [INFO]: Epoch 041 - training loss: 9333.5809, validation loss: 0.2144
2024-05-24 19:50:41 [INFO]: Epoch 042 - training loss: 9327.7008, validation loss: 0.2088
2024-05-24 19:50:41 [INFO]: Epoch 043 - training loss: 9322.7701, validation loss: 0.2073
2024-05-24 19:50:41 [INFO]: Epoch 044 - training loss: 9319.4057, validation loss: 0.2035
2024-05-24 19:50:41 [INFO]: Epoch 045 - training loss: 9319.1562, validation loss: 0.2011
2024-05-24 19:50:41 [INFO]: Epoch 046 - training loss: 9310.7244, validation loss: 0.2000
2024-05-24 19:50:41 [INFO]: Epoch 047 - training loss: 9310.0557, validation loss: 0.1979
2024-05-24 19:50:41 [INFO]: Epoch 048 - training loss: 9300.6974, validation loss: 0.1956
2024-05-24 19:50:41 [INFO]: Epoch 049 - training loss: 9296.9143, validation loss: 0.1919
2024-05-24 19:50:41 [INFO]: Epoch 050 - training loss: 9296.3935, validation loss: 0.1894
2024-05-24 19:50:42 [INFO]: Epoch 051 - training loss: 9296.6749, validation loss: 0.1860
2024-05-24 19:50:42 [INFO]: Epoch 052 - training loss: 9290.2277, validation loss: 0.1799
2024-05-24 19:50:42 [INFO]: Epoch 053 - training loss: 9288.0504, validation loss: 0.1812
2024-05-24 19:50:42 [INFO]: Epoch 054 - training loss: 9285.4509, validation loss: 0.1767
2024-05-24 19:50:42 [INFO]: Epoch 055 - training loss: 9290.3453, validation loss: 0.1738
2024-05-24 19:50:42 [INFO]: Epoch 056 - training loss: 9288.4543, validation loss: 0.1722
2024-05-24 19:50:42 [INFO]: Epoch 057 - training loss: 9282.9949, validation loss: 0.1686
2024-05-24 19:50:42 [INFO]: Epoch 058 - training loss: 9278.7709, validation loss: 0.1692
2024-05-24 19:50:42 [INFO]: Epoch 059 - training loss: 9276.7786, validation loss: 0.1681
2024-05-24 19:50:43 [INFO]: Epoch 060 - training loss: 9272.9301, validation loss: 0.1655
2024-05-24 19:50:43 [INFO]: Epoch 061 - training loss: 9271.5328, validation loss: 0.1636
2024-05-24 19:50:43 [INFO]: Epoch 062 - training loss: 9271.7706, validation loss: 0.1621
2024-05-24 19:50:43 [INFO]: Epoch 063 - training loss: 9277.2586, validation loss: 0.1603
2024-05-24 19:50:43 [INFO]: Epoch 064 - training loss: 9264.7515, validation loss: 0.1621
2024-05-24 19:50:43 [INFO]: Epoch 065 - training loss: 9264.1226, validation loss: 0.1637
2024-05-24 19:50:43 [INFO]: Epoch 066 - training loss: 9261.3951, validation loss: 0.1576
2024-05-24 19:50:43 [INFO]: Epoch 067 - training loss: 9258.9800, validation loss: 0.1554
2024-05-24 19:50:43 [INFO]: Epoch 068 - training loss: 9259.5327, validation loss: 0.1565
2024-05-24 19:50:44 [INFO]: Epoch 069 - training loss: 9262.8208, validation loss: 0.1558
2024-05-24 19:50:44 [INFO]: Epoch 070 - training loss: 9257.1534, validation loss: 0.1559
2024-05-24 19:50:44 [INFO]: Epoch 071 - training loss: 9258.5428, validation loss: 0.1534
2024-05-24 19:50:44 [INFO]: Epoch 072 - training loss: 9257.6472, validation loss: 0.1525
2024-05-24 19:50:44 [INFO]: Epoch 073 - training loss: 9254.9317, validation loss: 0.1523
2024-05-24 19:50:44 [INFO]: Epoch 074 - training loss: 9251.6766, validation loss: 0.1469
2024-05-24 19:50:44 [INFO]: Epoch 075 - training loss: 9261.3291, validation loss: 0.1480
2024-05-24 19:50:44 [INFO]: Epoch 076 - training loss: 9255.2356, validation loss: 0.1472
2024-05-24 19:50:44 [INFO]: Epoch 077 - training loss: 9250.1450, validation loss: 0.1457
2024-05-24 19:50:45 [INFO]: Epoch 078 - training loss: 9249.2274, validation loss: 0.1479
2024-05-24 19:50:45 [INFO]: Epoch 079 - training loss: 9246.8177, validation loss: 0.1467
2024-05-24 19:50:45 [INFO]: Epoch 080 - training loss: 9248.4188, validation loss: 0.1445
2024-05-24 19:50:45 [INFO]: Epoch 081 - training loss: 9245.5439, validation loss: 0.1446
2024-05-24 19:50:45 [INFO]: Epoch 082 - training loss: 9246.4877, validation loss: 0.1436
2024-05-24 19:50:45 [INFO]: Epoch 083 - training loss: 9246.5298, validation loss: 0.1424
2024-05-24 19:50:45 [INFO]: Epoch 084 - training loss: 9243.9919, validation loss: 0.1414
2024-05-24 19:50:45 [INFO]: Epoch 085 - training loss: 9244.8846, validation loss: 0.1421
2024-05-24 19:50:45 [INFO]: Epoch 086 - training loss: 9242.9487, validation loss: 0.1423
2024-05-24 19:50:46 [INFO]: Epoch 087 - training loss: 9243.3268, validation loss: 0.1403
2024-05-24 19:50:46 [INFO]: Epoch 088 - training loss: 9242.6747, validation loss: 0.1390
2024-05-24 19:50:46 [INFO]: Epoch 089 - training loss: 9241.6755, validation loss: 0.1391
2024-05-24 19:50:46 [INFO]: Epoch 090 - training loss: 9240.7911, validation loss: 0.1385
2024-05-24 19:50:46 [INFO]: Epoch 091 - training loss: 9238.7559, validation loss: 0.1380
2024-05-24 19:50:46 [INFO]: Epoch 092 - training loss: 9236.2224, validation loss: 0.1372
2024-05-24 19:50:46 [INFO]: Epoch 093 - training loss: 9238.5180, validation loss: 0.1365
2024-05-24 19:50:46 [INFO]: Epoch 094 - training loss: 9240.9005, validation loss: 0.1354
2024-05-24 19:50:46 [INFO]: Epoch 095 - training loss: 9235.5156, validation loss: 0.1342
2024-05-24 19:50:47 [INFO]: Epoch 096 - training loss: 9236.5424, validation loss: 0.1347
2024-05-24 19:50:47 [INFO]: Epoch 097 - training loss: 9236.9513, validation loss: 0.1332
2024-05-24 19:50:47 [INFO]: Epoch 098 - training loss: 9242.3832, validation loss: 0.1334
2024-05-24 19:50:47 [INFO]: Epoch 099 - training loss: 9234.3473, validation loss: 0.1311
2024-05-24 19:50:47 [INFO]: Epoch 100 - training loss: 9232.7880, validation loss: 0.1315
2024-05-24 19:50:47 [INFO]: Epoch 101 - training loss: 9233.8910, validation loss: 0.1307
2024-05-24 19:50:47 [INFO]: Epoch 102 - training loss: 9232.4034, validation loss: 0.1295
2024-05-24 19:50:47 [INFO]: Epoch 103 - training loss: 9232.4819, validation loss: 0.1305
2024-05-24 19:50:47 [INFO]: Epoch 104 - training loss: 9231.8609, validation loss: 0.1302
2024-05-24 19:50:47 [INFO]: Epoch 105 - training loss: 9230.0589, validation loss: 0.1286
2024-05-24 19:50:48 [INFO]: Epoch 106 - training loss: 9231.5112, validation loss: 0.1271
2024-05-24 19:50:48 [INFO]: Epoch 107 - training loss: 9230.5501, validation loss: 0.1279
2024-05-24 19:50:48 [INFO]: Epoch 108 - training loss: 9228.5497, validation loss: 0.1261
2024-05-24 19:50:48 [INFO]: Epoch 109 - training loss: 9230.0326, validation loss: 0.1259
2024-05-24 19:50:48 [INFO]: Epoch 110 - training loss: 9227.7626, validation loss: 0.1247
2024-05-24 19:50:48 [INFO]: Epoch 111 - training loss: 9229.4243, validation loss: 0.1258
2024-05-24 19:50:48 [INFO]: Epoch 112 - training loss: 9227.8209, validation loss: 0.1269
2024-05-24 19:50:48 [INFO]: Epoch 113 - training loss: 9227.3070, validation loss: 0.1240
2024-05-24 19:50:48 [INFO]: Epoch 114 - training loss: 9226.9506, validation loss: 0.1221
2024-05-24 19:50:49 [INFO]: Epoch 115 - training loss: 9228.3554, validation loss: 0.1248
2024-05-24 19:50:49 [INFO]: Epoch 116 - training loss: 9227.0234, validation loss: 0.1228
2024-05-24 19:50:49 [INFO]: Epoch 117 - training loss: 9227.6929, validation loss: 0.1218
2024-05-24 19:50:49 [INFO]: Epoch 118 - training loss: 9225.6856, validation loss: 0.1206
2024-05-24 19:50:49 [INFO]: Epoch 119 - training loss: 9226.7941, validation loss: 0.1210
2024-05-24 19:50:49 [INFO]: Epoch 120 - training loss: 9228.4947, validation loss: 0.1199
2024-05-24 19:50:49 [INFO]: Epoch 121 - training loss: 9225.4823, validation loss: 0.1179
2024-05-24 19:50:49 [INFO]: Epoch 122 - training loss: 9224.7252, validation loss: 0.1187
2024-05-24 19:50:49 [INFO]: Epoch 123 - training loss: 9223.9742, validation loss: 0.1196
2024-05-24 19:50:50 [INFO]: Epoch 124 - training loss: 9224.0821, validation loss: 0.1178
2024-05-24 19:50:50 [INFO]: Epoch 125 - training loss: 9223.6537, validation loss: 0.1155
2024-05-24 19:50:50 [INFO]: Epoch 126 - training loss: 9224.7668, validation loss: 0.1161
2024-05-24 19:50:50 [INFO]: Epoch 127 - training loss: 9221.5672, validation loss: 0.1161
2024-05-24 19:50:50 [INFO]: Epoch 128 - training loss: 9223.2285, validation loss: 0.1147
2024-05-24 19:50:50 [INFO]: Epoch 129 - training loss: 9221.6120, validation loss: 0.1154
2024-05-24 19:50:50 [INFO]: Epoch 130 - training loss: 9221.1015, validation loss: 0.1147
2024-05-24 19:50:50 [INFO]: Epoch 131 - training loss: 9225.1172, validation loss: 0.1138
2024-05-24 19:50:50 [INFO]: Epoch 132 - training loss: 9220.0996, validation loss: 0.1161
2024-05-24 19:50:51 [INFO]: Epoch 133 - training loss: 9221.9245, validation loss: 0.1138
2024-05-24 19:50:51 [INFO]: Epoch 134 - training loss: 9220.5812, validation loss: 0.1121
2024-05-24 19:50:51 [INFO]: Epoch 135 - training loss: 9222.0432, validation loss: 0.1109
2024-05-24 19:50:51 [INFO]: Epoch 136 - training loss: 9221.6326, validation loss: 0.1127
2024-05-24 19:50:51 [INFO]: Epoch 137 - training loss: 9220.3951, validation loss: 0.1140
2024-05-24 19:50:51 [INFO]: Epoch 138 - training loss: 9219.4852, validation loss: 0.1115
2024-05-24 19:50:51 [INFO]: Epoch 139 - training loss: 9218.6912, validation loss: 0.1101
2024-05-24 19:50:51 [INFO]: Epoch 140 - training loss: 9221.5660, validation loss: 0.1107
2024-05-24 19:50:51 [INFO]: Epoch 141 - training loss: 9223.3068, validation loss: 0.1105
2024-05-24 19:50:52 [INFO]: Epoch 142 - training loss: 9218.7180, validation loss: 0.1086
2024-05-24 19:50:52 [INFO]: Epoch 143 - training loss: 9218.8129, validation loss: 0.1100
2024-05-24 19:50:52 [INFO]: Epoch 144 - training loss: 9219.6604, validation loss: 0.1099
2024-05-24 19:50:52 [INFO]: Epoch 145 - training loss: 9219.6193, validation loss: 0.1086
2024-05-24 19:50:52 [INFO]: Epoch 146 - training loss: 9217.1263, validation loss: 0.1067
2024-05-24 19:50:52 [INFO]: Epoch 147 - training loss: 9218.0349, validation loss: 0.1084
2024-05-24 19:50:52 [INFO]: Epoch 148 - training loss: 9217.3938, validation loss: 0.1082
2024-05-24 19:50:52 [INFO]: Epoch 149 - training loss: 9217.7461, validation loss: 0.1072
2024-05-24 19:50:52 [INFO]: Epoch 150 - training loss: 9218.0621, validation loss: 0.1063
2024-05-24 19:50:53 [INFO]: Epoch 151 - training loss: 9217.3629, validation loss: 0.1055
2024-05-24 19:50:53 [INFO]: Epoch 152 - training loss: 9217.9087, validation loss: 0.1043
2024-05-24 19:50:53 [INFO]: Epoch 153 - training loss: 9216.5404, validation loss: 0.1077
2024-05-24 19:50:53 [INFO]: Epoch 154 - training loss: 9219.8464, validation loss: 0.1043
2024-05-24 19:50:53 [INFO]: Epoch 155 - training loss: 9216.6246, validation loss: 0.1050
2024-05-24 19:50:53 [INFO]: Epoch 156 - training loss: 9217.7294, validation loss: 0.1030
2024-05-24 19:50:53 [INFO]: Epoch 157 - training loss: 9218.2162, validation loss: 0.1062
2024-05-24 19:50:53 [INFO]: Epoch 158 - training loss: 9218.5792, validation loss: 0.1018
2024-05-24 19:50:53 [INFO]: Epoch 159 - training loss: 9218.8307, validation loss: 0.1049
2024-05-24 19:50:54 [INFO]: Epoch 160 - training loss: 9217.7576, validation loss: 0.1024
2024-05-24 19:50:54 [INFO]: Epoch 161 - training loss: 9213.8828, validation loss: 0.1026
2024-05-24 19:50:54 [INFO]: Epoch 162 - training loss: 9215.9434, validation loss: 0.0997
2024-05-24 19:50:54 [INFO]: Epoch 163 - training loss: 9214.3909, validation loss: 0.1017
2024-05-24 19:50:54 [INFO]: Epoch 164 - training loss: 9229.4733, validation loss: 0.1020
2024-05-24 19:50:54 [INFO]: Epoch 165 - training loss: 9213.6882, validation loss: 0.0999
2024-05-24 19:50:54 [INFO]: Epoch 166 - training loss: 9214.5540, validation loss: 0.1013
2024-05-24 19:50:54 [INFO]: Epoch 167 - training loss: 9214.3790, validation loss: 0.1021
2024-05-24 19:50:54 [INFO]: Epoch 168 - training loss: 9213.7059, validation loss: 0.1002
2024-05-24 19:50:55 [INFO]: Epoch 169 - training loss: 9213.2983, validation loss: 0.1017
2024-05-24 19:50:55 [INFO]: Epoch 170 - training loss: 9213.0173, validation loss: 0.1005
2024-05-24 19:50:55 [INFO]: Epoch 171 - training loss: 9215.3496, validation loss: 0.1002
2024-05-24 19:50:55 [INFO]: Epoch 172 - training loss: 9216.0406, validation loss: 0.1016
2024-05-24 19:50:55 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 19:50:55 [INFO]: Finished training. The best model is from epoch#162.
2024-05-24 19:50:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/GPVAE_ettm1/20240524_T195036/GPVAE.pypots
2024-05-24 19:50:55 [INFO]: GP-VAE on ETTm1: MAE=0.3467, MSE=0.2333
2024-05-24 19:50:55 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/GPVAE_ettm1/imputation.pkl
2024-05-24 19:50:55 [INFO]: Using the given device: cuda:0
2024-05-24 19:50:55 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T195055
2024-05-24 19:50:55 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T195055/tensorboard
2024-05-24 19:50:55 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 19:51:03 [INFO]: Epoch 001 - generator training loss: 0.4006, discriminator training loss: 0.5278, validation loss: 0.3077
2024-05-24 19:51:10 [INFO]: Epoch 002 - generator training loss: -0.0893, discriminator training loss: 0.4669, validation loss: 0.1049
2024-05-24 19:51:17 [INFO]: Epoch 003 - generator training loss: -0.1619, discriminator training loss: 0.4216, validation loss: 0.0763
2024-05-24 19:51:24 [INFO]: Epoch 004 - generator training loss: -0.1398, discriminator training loss: 0.3541, validation loss: 0.0564
2024-05-24 19:51:31 [INFO]: Epoch 005 - generator training loss: -0.0982, discriminator training loss: 0.2773, validation loss: 0.0490
2024-05-24 19:51:38 [INFO]: Epoch 006 - generator training loss: -0.0656, discriminator training loss: 0.2204, validation loss: 0.0458
2024-05-24 19:51:45 [INFO]: Epoch 007 - generator training loss: -0.0570, discriminator training loss: 0.1944, validation loss: 0.0423
2024-05-24 19:51:52 [INFO]: Epoch 008 - generator training loss: -0.0549, discriminator training loss: 0.1831, validation loss: 0.0396
2024-05-24 19:52:00 [INFO]: Epoch 009 - generator training loss: -0.0543, discriminator training loss: 0.1772, validation loss: 0.0390
2024-05-24 19:52:07 [INFO]: Epoch 010 - generator training loss: -0.0585, discriminator training loss: 0.1789, validation loss: 0.0373
2024-05-24 19:52:14 [INFO]: Epoch 011 - generator training loss: -0.0542, discriminator training loss: 0.1748, validation loss: 0.0360
2024-05-24 19:52:20 [INFO]: Epoch 012 - generator training loss: -0.0552, discriminator training loss: 0.1708, validation loss: 0.0369
2024-05-24 19:52:27 [INFO]: Epoch 013 - generator training loss: -0.0556, discriminator training loss: 0.1706, validation loss: 0.0397
2024-05-24 19:52:34 [INFO]: Epoch 014 - generator training loss: -0.0526, discriminator training loss: 0.1723, validation loss: 0.0398
2024-05-24 19:52:41 [INFO]: Epoch 015 - generator training loss: -0.0572, discriminator training loss: 0.1720, validation loss: 0.0353
2024-05-24 19:52:48 [INFO]: Epoch 016 - generator training loss: -0.0558, discriminator training loss: 0.1717, validation loss: 0.0343
2024-05-24 19:52:55 [INFO]: Epoch 017 - generator training loss: -0.0562, discriminator training loss: 0.1687, validation loss: 0.0345
2024-05-24 19:53:03 [INFO]: Epoch 018 - generator training loss: -0.0594, discriminator training loss: 0.1684, validation loss: 0.0335
2024-05-24 19:53:09 [INFO]: Epoch 019 - generator training loss: -0.0613, discriminator training loss: 0.1669, validation loss: 0.0332
2024-05-24 19:53:17 [INFO]: Epoch 020 - generator training loss: -0.0608, discriminator training loss: 0.1697, validation loss: 0.0336
2024-05-24 19:53:23 [INFO]: Epoch 021 - generator training loss: -0.0618, discriminator training loss: 0.1683, validation loss: 0.0324
2024-05-24 19:53:31 [INFO]: Epoch 022 - generator training loss: -0.0657, discriminator training loss: 0.1712, validation loss: 0.0320
2024-05-24 19:53:38 [INFO]: Epoch 023 - generator training loss: -0.0587, discriminator training loss: 0.1703, validation loss: 0.0318
2024-05-24 19:53:45 [INFO]: Epoch 024 - generator training loss: -0.0617, discriminator training loss: 0.1691, validation loss: 0.0322
2024-05-24 19:53:52 [INFO]: Epoch 025 - generator training loss: -0.0618, discriminator training loss: 0.1683, validation loss: 0.0318
2024-05-24 19:53:59 [INFO]: Epoch 026 - generator training loss: -0.0644, discriminator training loss: 0.1693, validation loss: 0.0311
2024-05-24 19:54:06 [INFO]: Epoch 027 - generator training loss: -0.0617, discriminator training loss: 0.1699, validation loss: 0.0311
2024-05-24 19:54:13 [INFO]: Epoch 028 - generator training loss: -0.0622, discriminator training loss: 0.1699, validation loss: 0.0309
2024-05-24 19:54:20 [INFO]: Epoch 029 - generator training loss: -0.0620, discriminator training loss: 0.1660, validation loss: 0.0321
2024-05-24 19:54:27 [INFO]: Epoch 030 - generator training loss: -0.0575, discriminator training loss: 0.1680, validation loss: 0.0346
2024-05-24 19:54:34 [INFO]: Epoch 031 - generator training loss: -0.0590, discriminator training loss: 0.1694, validation loss: 0.0359
2024-05-24 19:54:41 [INFO]: Epoch 032 - generator training loss: -0.0622, discriminator training loss: 0.1686, validation loss: 0.0315
2024-05-24 19:54:48 [INFO]: Epoch 033 - generator training loss: -0.0626, discriminator training loss: 0.1699, validation loss: 0.0305
2024-05-24 19:54:55 [INFO]: Epoch 034 - generator training loss: -0.0657, discriminator training loss: 0.1687, validation loss: 0.0301
2024-05-24 19:55:02 [INFO]: Epoch 035 - generator training loss: -0.0612, discriminator training loss: 0.1676, validation loss: 0.0299
2024-05-24 19:55:09 [INFO]: Epoch 036 - generator training loss: -0.0651, discriminator training loss: 0.1676, validation loss: 0.0306
2024-05-24 19:55:16 [INFO]: Epoch 037 - generator training loss: -0.0629, discriminator training loss: 0.1649, validation loss: 0.0294
2024-05-24 19:55:23 [INFO]: Epoch 038 - generator training loss: -0.0662, discriminator training loss: 0.1668, validation loss: 0.0297
2024-05-24 19:55:30 [INFO]: Epoch 039 - generator training loss: -0.0639, discriminator training loss: 0.1681, validation loss: 0.0294
2024-05-24 19:55:37 [INFO]: Epoch 040 - generator training loss: -0.0650, discriminator training loss: 0.1662, validation loss: 0.0300
2024-05-24 19:55:44 [INFO]: Epoch 041 - generator training loss: -0.0666, discriminator training loss: 0.1673, validation loss: 0.0293
2024-05-24 19:55:51 [INFO]: Epoch 042 - generator training loss: -0.0648, discriminator training loss: 0.1671, validation loss: 0.0292
2024-05-24 19:55:58 [INFO]: Epoch 043 - generator training loss: -0.0672, discriminator training loss: 0.1674, validation loss: 0.0295
2024-05-24 19:56:05 [INFO]: Epoch 044 - generator training loss: -0.0658, discriminator training loss: 0.1665, validation loss: 0.0292
2024-05-24 19:56:12 [INFO]: Epoch 045 - generator training loss: -0.0681, discriminator training loss: 0.1671, validation loss: 0.0297
2024-05-24 19:56:19 [INFO]: Epoch 046 - generator training loss: -0.0680, discriminator training loss: 0.1659, validation loss: 0.0292
2024-05-24 19:56:26 [INFO]: Epoch 047 - generator training loss: -0.0676, discriminator training loss: 0.1666, validation loss: 0.0301
2024-05-24 19:56:33 [INFO]: Epoch 048 - generator training loss: -0.0639, discriminator training loss: 0.1640, validation loss: 0.0289
2024-05-24 19:56:40 [INFO]: Epoch 049 - generator training loss: -0.0687, discriminator training loss: 0.1685, validation loss: 0.0294
2024-05-24 19:56:47 [INFO]: Epoch 050 - generator training loss: -0.0630, discriminator training loss: 0.1680, validation loss: 0.0290
2024-05-24 19:56:54 [INFO]: Epoch 051 - generator training loss: -0.0702, discriminator training loss: 0.1673, validation loss: 0.0292
2024-05-24 19:57:01 [INFO]: Epoch 052 - generator training loss: -0.0684, discriminator training loss: 0.1668, validation loss: 0.0286
2024-05-24 19:57:08 [INFO]: Epoch 053 - generator training loss: -0.0710, discriminator training loss: 0.1665, validation loss: 0.0288
2024-05-24 19:57:15 [INFO]: Epoch 054 - generator training loss: -0.0678, discriminator training loss: 0.1647, validation loss: 0.0287
2024-05-24 19:57:22 [INFO]: Epoch 055 - generator training loss: -0.0660, discriminator training loss: 0.1648, validation loss: 0.0280
2024-05-24 19:57:29 [INFO]: Epoch 056 - generator training loss: -0.0668, discriminator training loss: 0.1660, validation loss: 0.0278
2024-05-24 19:57:36 [INFO]: Epoch 057 - generator training loss: -0.0686, discriminator training loss: 0.1664, validation loss: 0.0287
2024-05-24 19:57:43 [INFO]: Epoch 058 - generator training loss: -0.0666, discriminator training loss: 0.1656, validation loss: 0.0278
2024-05-24 19:57:50 [INFO]: Epoch 059 - generator training loss: -0.0690, discriminator training loss: 0.1669, validation loss: 0.0289
2024-05-24 19:57:57 [INFO]: Epoch 060 - generator training loss: -0.0711, discriminator training loss: 0.1650, validation loss: 0.0273
2024-05-24 19:58:04 [INFO]: Epoch 061 - generator training loss: -0.0708, discriminator training loss: 0.1659, validation loss: 0.0266
2024-05-24 19:58:11 [INFO]: Epoch 062 - generator training loss: -0.0704, discriminator training loss: 0.1646, validation loss: 0.0277
2024-05-24 19:58:18 [INFO]: Epoch 063 - generator training loss: -0.0700, discriminator training loss: 0.1649, validation loss: 0.0264
2024-05-24 19:58:25 [INFO]: Epoch 064 - generator training loss: -0.0726, discriminator training loss: 0.1630, validation loss: 0.0265
2024-05-24 19:58:32 [INFO]: Epoch 065 - generator training loss: -0.0728, discriminator training loss: 0.1647, validation loss: 0.0268
2024-05-24 19:58:39 [INFO]: Epoch 066 - generator training loss: -0.0719, discriminator training loss: 0.1649, validation loss: 0.0266
2024-05-24 19:58:46 [INFO]: Epoch 067 - generator training loss: -0.0699, discriminator training loss: 0.1643, validation loss: 0.0257
2024-05-24 19:58:53 [INFO]: Epoch 068 - generator training loss: -0.0752, discriminator training loss: 0.1643, validation loss: 0.0255
2024-05-24 19:59:00 [INFO]: Epoch 069 - generator training loss: -0.0722, discriminator training loss: 0.1646, validation loss: 0.0254
2024-05-24 19:59:07 [INFO]: Epoch 070 - generator training loss: -0.0712, discriminator training loss: 0.1638, validation loss: 0.0250
2024-05-24 19:59:14 [INFO]: Epoch 071 - generator training loss: -0.0748, discriminator training loss: 0.1651, validation loss: 0.0245
2024-05-24 19:59:21 [INFO]: Epoch 072 - generator training loss: -0.0734, discriminator training loss: 0.1646, validation loss: 0.0238
2024-05-24 19:59:28 [INFO]: Epoch 073 - generator training loss: -0.0755, discriminator training loss: 0.1637, validation loss: 0.0247
2024-05-24 19:59:35 [INFO]: Epoch 074 - generator training loss: -0.0720, discriminator training loss: 0.1660, validation loss: 0.0243
2024-05-24 19:59:42 [INFO]: Epoch 075 - generator training loss: -0.0706, discriminator training loss: 0.1616, validation loss: 0.0257
2024-05-24 19:59:49 [INFO]: Epoch 076 - generator training loss: -0.0729, discriminator training loss: 0.1635, validation loss: 0.0237
2024-05-24 19:59:56 [INFO]: Epoch 077 - generator training loss: -0.0772, discriminator training loss: 0.1636, validation loss: 0.0241
2024-05-24 20:00:03 [INFO]: Epoch 078 - generator training loss: -0.0740, discriminator training loss: 0.1626, validation loss: 0.0240
2024-05-24 20:00:10 [INFO]: Epoch 079 - generator training loss: -0.0728, discriminator training loss: 0.1644, validation loss: 0.0259
2024-05-24 20:00:17 [INFO]: Epoch 080 - generator training loss: -0.0719, discriminator training loss: 0.1642, validation loss: 0.0239
2024-05-24 20:00:24 [INFO]: Epoch 081 - generator training loss: -0.0734, discriminator training loss: 0.1638, validation loss: 0.0234
2024-05-24 20:00:31 [INFO]: Epoch 082 - generator training loss: -0.0705, discriminator training loss: 0.1618, validation loss: 0.0282
2024-05-24 20:00:38 [INFO]: Epoch 083 - generator training loss: -0.0743, discriminator training loss: 0.1612, validation loss: 0.0238
2024-05-24 20:00:45 [INFO]: Epoch 084 - generator training loss: -0.0742, discriminator training loss: 0.1632, validation loss: 0.0238
2024-05-24 20:00:52 [INFO]: Epoch 085 - generator training loss: -0.0742, discriminator training loss: 0.1613, validation loss: 0.0239
2024-05-24 20:00:59 [INFO]: Epoch 086 - generator training loss: -0.0732, discriminator training loss: 0.1628, validation loss: 0.0237
2024-05-24 20:01:06 [INFO]: Epoch 087 - generator training loss: -0.0722, discriminator training loss: 0.1609, validation loss: 0.0236
2024-05-24 20:01:13 [INFO]: Epoch 088 - generator training loss: -0.0758, discriminator training loss: 0.1621, validation loss: 0.0234
2024-05-24 20:01:20 [INFO]: Epoch 089 - generator training loss: -0.0718, discriminator training loss: 0.1633, validation loss: 0.0242
2024-05-24 20:01:27 [INFO]: Epoch 090 - generator training loss: -0.0758, discriminator training loss: 0.1608, validation loss: 0.0230
2024-05-24 20:01:34 [INFO]: Epoch 091 - generator training loss: -0.0730, discriminator training loss: 0.1627, validation loss: 0.0235
2024-05-24 20:01:41 [INFO]: Epoch 092 - generator training loss: -0.0756, discriminator training loss: 0.1632, validation loss: 0.0229
2024-05-24 20:01:48 [INFO]: Epoch 093 - generator training loss: -0.0735, discriminator training loss: 0.1608, validation loss: 0.0250
2024-05-24 20:01:56 [INFO]: Epoch 094 - generator training loss: -0.0743, discriminator training loss: 0.1624, validation loss: 0.0231
2024-05-24 20:02:03 [INFO]: Epoch 095 - generator training loss: -0.0749, discriminator training loss: 0.1620, validation loss: 0.0235
2024-05-24 20:02:09 [INFO]: Epoch 096 - generator training loss: -0.0735, discriminator training loss: 0.1613, validation loss: 0.0242
2024-05-24 20:02:16 [INFO]: Epoch 097 - generator training loss: -0.0723, discriminator training loss: 0.1597, validation loss: 0.0232
2024-05-24 20:02:23 [INFO]: Epoch 098 - generator training loss: -0.0739, discriminator training loss: 0.1628, validation loss: 0.0230
2024-05-24 20:02:30 [INFO]: Epoch 099 - generator training loss: -0.0713, discriminator training loss: 0.1601, validation loss: 0.0240
2024-05-24 20:02:37 [INFO]: Epoch 100 - generator training loss: -0.0762, discriminator training loss: 0.1609, validation loss: 0.0233
2024-05-24 20:02:44 [INFO]: Epoch 101 - generator training loss: -0.0730, discriminator training loss: 0.1620, validation loss: 0.0232
2024-05-24 20:02:51 [INFO]: Epoch 102 - generator training loss: -0.0735, discriminator training loss: 0.1615, validation loss: 0.0231
2024-05-24 20:02:51 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:02:51 [INFO]: Finished training. The best model is from epoch#92.
2024-05-24 20:02:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/USGAN_ettm1/20240524_T195055/USGAN.pypots
2024-05-24 20:02:52 [INFO]: US-GAN on ETTm1: MAE=0.1670, MSE=0.0724
2024-05-24 20:02:52 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/USGAN_ettm1/imputation.pkl
2024-05-24 20:02:52 [INFO]: Using the given device: cuda:0
2024-05-24 20:02:52 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T200252
2024-05-24 20:02:52 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T200252/tensorboard
2024-05-24 20:02:52 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 20:02:58 [INFO]: Epoch 001 - training loss: 1.3478, validation loss: 0.3689
2024-05-24 20:03:02 [INFO]: Epoch 002 - training loss: 0.9539, validation loss: 0.1243
2024-05-24 20:03:07 [INFO]: Epoch 003 - training loss: 0.7381, validation loss: 0.0696
2024-05-24 20:03:11 [INFO]: Epoch 004 - training loss: 0.6851, validation loss: 0.0519
2024-05-24 20:03:16 [INFO]: Epoch 005 - training loss: 0.6199, validation loss: 0.0459
2024-05-24 20:03:21 [INFO]: Epoch 006 - training loss: 0.5729, validation loss: 0.0403
2024-05-24 20:03:25 [INFO]: Epoch 007 - training loss: 0.5861, validation loss: 0.0418
2024-05-24 20:03:30 [INFO]: Epoch 008 - training loss: 0.5390, validation loss: 0.0365
2024-05-24 20:03:34 [INFO]: Epoch 009 - training loss: 0.5096, validation loss: 0.0369
2024-05-24 20:03:39 [INFO]: Epoch 010 - training loss: 0.4952, validation loss: 0.0327
2024-05-24 20:03:44 [INFO]: Epoch 011 - training loss: 0.4876, validation loss: 0.0357
2024-05-24 20:03:48 [INFO]: Epoch 012 - training loss: 0.4754, validation loss: 0.0308
2024-05-24 20:03:53 [INFO]: Epoch 013 - training loss: 0.4733, validation loss: 0.0304
2024-05-24 20:03:58 [INFO]: Epoch 014 - training loss: 0.4522, validation loss: 0.0295
2024-05-24 20:04:02 [INFO]: Epoch 015 - training loss: 0.4503, validation loss: 0.0294
2024-05-24 20:04:07 [INFO]: Epoch 016 - training loss: 0.4351, validation loss: 0.0285
2024-05-24 20:04:11 [INFO]: Epoch 017 - training loss: 0.4325, validation loss: 0.0285
2024-05-24 20:04:16 [INFO]: Epoch 018 - training loss: 0.4224, validation loss: 0.0279
2024-05-24 20:04:21 [INFO]: Epoch 019 - training loss: 0.4108, validation loss: 0.0277
2024-05-24 20:04:25 [INFO]: Epoch 020 - training loss: 0.4379, validation loss: 0.0275
2024-05-24 20:04:30 [INFO]: Epoch 021 - training loss: 0.4246, validation loss: 0.0281
2024-05-24 20:04:34 [INFO]: Epoch 022 - training loss: 0.4101, validation loss: 0.0258
2024-05-24 20:04:39 [INFO]: Epoch 023 - training loss: 0.4120, validation loss: 0.0265
2024-05-24 20:04:43 [INFO]: Epoch 024 - training loss: 0.4137, validation loss: 0.0264
2024-05-24 20:04:48 [INFO]: Epoch 025 - training loss: 0.4119, validation loss: 0.0257
2024-05-24 20:04:53 [INFO]: Epoch 026 - training loss: 0.4068, validation loss: 0.0265
2024-05-24 20:04:57 [INFO]: Epoch 027 - training loss: 0.3990, validation loss: 0.0257
2024-05-24 20:05:02 [INFO]: Epoch 028 - training loss: 0.4031, validation loss: 0.0252
2024-05-24 20:05:07 [INFO]: Epoch 029 - training loss: 0.4124, validation loss: 0.0257
2024-05-24 20:05:11 [INFO]: Epoch 030 - training loss: 0.4018, validation loss: 0.0260
2024-05-24 20:05:16 [INFO]: Epoch 031 - training loss: 0.4211, validation loss: 0.0258
2024-05-24 20:05:20 [INFO]: Epoch 032 - training loss: 0.4102, validation loss: 0.0259
2024-05-24 20:05:25 [INFO]: Epoch 033 - training loss: 0.4085, validation loss: 0.0259
2024-05-24 20:05:29 [INFO]: Epoch 034 - training loss: 0.3984, validation loss: 0.0253
2024-05-24 20:05:34 [INFO]: Epoch 035 - training loss: 0.4022, validation loss: 0.0256
2024-05-24 20:05:39 [INFO]: Epoch 036 - training loss: 0.4000, validation loss: 0.0249
2024-05-24 20:05:43 [INFO]: Epoch 037 - training loss: 0.3947, validation loss: 0.0250
2024-05-24 20:05:48 [INFO]: Epoch 038 - training loss: 0.3978, validation loss: 0.0258
2024-05-24 20:05:53 [INFO]: Epoch 039 - training loss: 0.3947, validation loss: 0.0254
2024-05-24 20:05:57 [INFO]: Epoch 040 - training loss: 0.3952, validation loss: 0.0251
2024-05-24 20:06:02 [INFO]: Epoch 041 - training loss: 0.4051, validation loss: 0.0257
2024-05-24 20:06:06 [INFO]: Epoch 042 - training loss: 0.3994, validation loss: 0.0258
2024-05-24 20:06:11 [INFO]: Epoch 043 - training loss: 0.4063, validation loss: 0.0259
2024-05-24 20:06:16 [INFO]: Epoch 044 - training loss: 0.3960, validation loss: 0.0267
2024-05-24 20:06:20 [INFO]: Epoch 045 - training loss: 0.3928, validation loss: 0.0255
2024-05-24 20:06:25 [INFO]: Epoch 046 - training loss: 0.4027, validation loss: 0.0252
2024-05-24 20:06:25 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:06:25 [INFO]: Finished training. The best model is from epoch#36.
2024-05-24 20:06:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/BRITS_ettm1/20240524_T200252/BRITS.pypots
2024-05-24 20:06:26 [INFO]: BRITS on ETTm1: MAE=0.1435, MSE=0.0622
2024-05-24 20:06:26 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/BRITS_ettm1/imputation.pkl
2024-05-24 20:06:26 [INFO]: Using the given device: cuda:0
2024-05-24 20:06:26 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626
2024-05-24 20:06:26 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/tensorboard
2024-05-24 20:06:26 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 20:06:27 [INFO]: Epoch 001 - training loss: 1.3894, validation loss: 1.3613
2024-05-24 20:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch1_loss1.3613024950027466.pypots
2024-05-24 20:06:27 [INFO]: Epoch 002 - training loss: 1.0002, validation loss: 1.2205
2024-05-24 20:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch2_loss1.2205145806074142.pypots
2024-05-24 20:06:27 [INFO]: Epoch 003 - training loss: 0.9202, validation loss: 1.1218
2024-05-24 20:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch3_loss1.1218158155679703.pypots
2024-05-24 20:06:27 [INFO]: Epoch 004 - training loss: 0.8868, validation loss: 1.0714
2024-05-24 20:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch4_loss1.0714037120342255.pypots
2024-05-24 20:06:27 [INFO]: Epoch 005 - training loss: 0.8842, validation loss: 1.0529
2024-05-24 20:06:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch5_loss1.0529112368822098.pypots
2024-05-24 20:06:28 [INFO]: Epoch 006 - training loss: 0.8728, validation loss: 1.0381
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch6_loss1.0381163358688354.pypots
2024-05-24 20:06:28 [INFO]: Epoch 007 - training loss: 0.8626, validation loss: 1.0346
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch7_loss1.0345667451620102.pypots
2024-05-24 20:06:28 [INFO]: Epoch 008 - training loss: 0.8445, validation loss: 1.0272
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch8_loss1.027247205376625.pypots
2024-05-24 20:06:28 [INFO]: Epoch 009 - training loss: 0.8309, validation loss: 1.0219
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch9_loss1.0219282656908035.pypots
2024-05-24 20:06:28 [INFO]: Epoch 010 - training loss: 0.8394, validation loss: 1.0168
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch10_loss1.0168295800685883.pypots
2024-05-24 20:06:28 [INFO]: Epoch 011 - training loss: 0.8545, validation loss: 1.0128
2024-05-24 20:06:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch11_loss1.012762412428856.pypots
2024-05-24 20:06:29 [INFO]: Epoch 012 - training loss: 0.8490, validation loss: 1.0113
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch12_loss1.0113375037908554.pypots
2024-05-24 20:06:29 [INFO]: Epoch 013 - training loss: 0.8051, validation loss: 1.0100
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch13_loss1.0100087821483612.pypots
2024-05-24 20:06:29 [INFO]: Epoch 014 - training loss: 0.8238, validation loss: 1.0056
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch14_loss1.0055814981460571.pypots
2024-05-24 20:06:29 [INFO]: Epoch 015 - training loss: 0.8253, validation loss: 1.0070
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch15_loss1.0070218592882156.pypots
2024-05-24 20:06:29 [INFO]: Epoch 016 - training loss: 0.8137, validation loss: 1.0026
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch16_loss1.0025579929351807.pypots
2024-05-24 20:06:29 [INFO]: Epoch 017 - training loss: 0.8157, validation loss: 0.9966
2024-05-24 20:06:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch17_loss0.996558889746666.pypots
2024-05-24 20:06:30 [INFO]: Epoch 018 - training loss: 0.7967, validation loss: 0.9963
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch18_loss0.9962840527296066.pypots
2024-05-24 20:06:30 [INFO]: Epoch 019 - training loss: 0.7835, validation loss: 0.9931
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch19_loss0.9931259006261826.pypots
2024-05-24 20:06:30 [INFO]: Epoch 020 - training loss: 0.7884, validation loss: 0.9864
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch20_loss0.9863711446523666.pypots
2024-05-24 20:06:30 [INFO]: Epoch 021 - training loss: 0.7850, validation loss: 0.9833
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch21_loss0.9832926243543625.pypots
2024-05-24 20:06:30 [INFO]: Epoch 022 - training loss: 0.7579, validation loss: 0.9830
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch22_loss0.9830348193645477.pypots
2024-05-24 20:06:30 [INFO]: Epoch 023 - training loss: 0.7620, validation loss: 0.9775
2024-05-24 20:06:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch23_loss0.9775426089763641.pypots
2024-05-24 20:06:31 [INFO]: Epoch 024 - training loss: 0.7716, validation loss: 0.9741
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch24_loss0.9740675836801529.pypots
2024-05-24 20:06:31 [INFO]: Epoch 025 - training loss: 0.7877, validation loss: 0.9730
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch25_loss0.9730396121740341.pypots
2024-05-24 20:06:31 [INFO]: Epoch 026 - training loss: 0.7584, validation loss: 0.9667
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch26_loss0.9666531831026077.pypots
2024-05-24 20:06:31 [INFO]: Epoch 027 - training loss: 0.7683, validation loss: 0.9699
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch27_loss0.9698968380689621.pypots
2024-05-24 20:06:31 [INFO]: Epoch 028 - training loss: 0.7915, validation loss: 0.9659
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch28_loss0.9658652693033218.pypots
2024-05-24 20:06:31 [INFO]: Epoch 029 - training loss: 0.7847, validation loss: 0.9634
2024-05-24 20:06:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch29_loss0.9633674621582031.pypots
2024-05-24 20:06:32 [INFO]: Epoch 030 - training loss: 0.7499, validation loss: 0.9603
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch30_loss0.9602843523025513.pypots
2024-05-24 20:06:32 [INFO]: Epoch 031 - training loss: 0.7550, validation loss: 0.9606
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch31_loss0.96055106818676.pypots
2024-05-24 20:06:32 [INFO]: Epoch 032 - training loss: 0.7429, validation loss: 0.9571
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch32_loss0.957052618265152.pypots
2024-05-24 20:06:32 [INFO]: Epoch 033 - training loss: 0.7723, validation loss: 0.9505
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch33_loss0.9504939019680023.pypots
2024-05-24 20:06:32 [INFO]: Epoch 034 - training loss: 0.7642, validation loss: 0.9504
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch34_loss0.9503774791955948.pypots
2024-05-24 20:06:32 [INFO]: Epoch 035 - training loss: 0.7422, validation loss: 0.9473
2024-05-24 20:06:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch35_loss0.9473416358232498.pypots
2024-05-24 20:06:33 [INFO]: Epoch 036 - training loss: 0.7479, validation loss: 0.9445
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch36_loss0.9445030689239502.pypots
2024-05-24 20:06:33 [INFO]: Epoch 037 - training loss: 0.7664, validation loss: 0.9441
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch37_loss0.9441379755735397.pypots
2024-05-24 20:06:33 [INFO]: Epoch 038 - training loss: 0.7363, validation loss: 0.9411
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch38_loss0.9410923421382904.pypots
2024-05-24 20:06:33 [INFO]: Epoch 039 - training loss: 0.7434, validation loss: 0.9364
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch39_loss0.9363663494586945.pypots
2024-05-24 20:06:33 [INFO]: Epoch 040 - training loss: 0.7737, validation loss: 0.9373
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch40_loss0.9372813701629639.pypots
2024-05-24 20:06:33 [INFO]: Epoch 041 - training loss: 0.7489, validation loss: 0.9340
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch41_loss0.9340233951807022.pypots
2024-05-24 20:06:33 [INFO]: Epoch 042 - training loss: 0.7594, validation loss: 0.9349
2024-05-24 20:06:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch42_loss0.9349351227283478.pypots
2024-05-24 20:06:34 [INFO]: Epoch 043 - training loss: 0.7308, validation loss: 0.9291
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch43_loss0.9290722459554672.pypots
2024-05-24 20:06:34 [INFO]: Epoch 044 - training loss: 0.7644, validation loss: 0.9299
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch44_loss0.9298504143953323.pypots
2024-05-24 20:06:34 [INFO]: Epoch 045 - training loss: 0.7461, validation loss: 0.9261
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch45_loss0.9260983169078827.pypots
2024-05-24 20:06:34 [INFO]: Epoch 046 - training loss: 0.7235, validation loss: 0.9244
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch46_loss0.9244145750999451.pypots
2024-05-24 20:06:34 [INFO]: Epoch 047 - training loss: 0.7474, validation loss: 0.9237
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch47_loss0.9237070381641388.pypots
2024-05-24 20:06:34 [INFO]: Epoch 048 - training loss: 0.7280, validation loss: 0.9273
2024-05-24 20:06:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch48_loss0.9273416846990585.pypots
2024-05-24 20:06:35 [INFO]: Epoch 049 - training loss: 0.7783, validation loss: 0.9251
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch49_loss0.9250856637954712.pypots
2024-05-24 20:06:35 [INFO]: Epoch 050 - training loss: 0.7662, validation loss: 0.9243
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch50_loss0.9242685437202454.pypots
2024-05-24 20:06:35 [INFO]: Epoch 051 - training loss: 0.7530, validation loss: 0.9228
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch51_loss0.9227872341871262.pypots
2024-05-24 20:06:35 [INFO]: Epoch 052 - training loss: 0.7483, validation loss: 0.9190
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch52_loss0.9190444797277451.pypots
2024-05-24 20:06:35 [INFO]: Epoch 053 - training loss: 0.7419, validation loss: 0.9216
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch53_loss0.9216194152832031.pypots
2024-05-24 20:06:35 [INFO]: Epoch 054 - training loss: 0.7266, validation loss: 0.9197
2024-05-24 20:06:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch54_loss0.9197136014699936.pypots
2024-05-24 20:06:36 [INFO]: Epoch 055 - training loss: 0.7376, validation loss: 0.9191
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch55_loss0.9191073328256607.pypots
2024-05-24 20:06:36 [INFO]: Epoch 056 - training loss: 0.7231, validation loss: 0.9179
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch56_loss0.9179204851388931.pypots
2024-05-24 20:06:36 [INFO]: Epoch 057 - training loss: 0.7375, validation loss: 0.9165
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch57_loss0.9164643585681915.pypots
2024-05-24 20:06:36 [INFO]: Epoch 058 - training loss: 0.7378, validation loss: 0.9183
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch58_loss0.9182562232017517.pypots
2024-05-24 20:06:36 [INFO]: Epoch 059 - training loss: 0.7480, validation loss: 0.9151
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch59_loss0.9151031970977783.pypots
2024-05-24 20:06:36 [INFO]: Epoch 060 - training loss: 0.7322, validation loss: 0.9140
2024-05-24 20:06:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch60_loss0.9139929860830307.pypots
2024-05-24 20:06:37 [INFO]: Epoch 061 - training loss: 0.7417, validation loss: 0.9145
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch61_loss0.9144700318574905.pypots
2024-05-24 20:06:37 [INFO]: Epoch 062 - training loss: 0.7252, validation loss: 0.9161
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch62_loss0.9161311686038971.pypots
2024-05-24 20:06:37 [INFO]: Epoch 063 - training loss: 0.7399, validation loss: 0.9139
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch63_loss0.9139164835214615.pypots
2024-05-24 20:06:37 [INFO]: Epoch 064 - training loss: 0.7455, validation loss: 0.9145
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch64_loss0.9144640862941742.pypots
2024-05-24 20:06:37 [INFO]: Epoch 065 - training loss: 0.7283, validation loss: 0.9129
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch65_loss0.9128658771514893.pypots
2024-05-24 20:06:37 [INFO]: Epoch 066 - training loss: 0.7279, validation loss: 0.9107
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch66_loss0.9106687158346176.pypots
2024-05-24 20:06:37 [INFO]: Epoch 067 - training loss: 0.7241, validation loss: 0.9153
2024-05-24 20:06:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch67_loss0.9153499901294708.pypots
2024-05-24 20:06:38 [INFO]: Epoch 068 - training loss: 0.7418, validation loss: 0.9123
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch68_loss0.9123341888189316.pypots
2024-05-24 20:06:38 [INFO]: Epoch 069 - training loss: 0.7167, validation loss: 0.9096
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch69_loss0.9096393138170242.pypots
2024-05-24 20:06:38 [INFO]: Epoch 070 - training loss: 0.7311, validation loss: 0.9090
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch70_loss0.9090129435062408.pypots
2024-05-24 20:06:38 [INFO]: Epoch 071 - training loss: 0.7243, validation loss: 0.9095
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch71_loss0.909530371427536.pypots
2024-05-24 20:06:38 [INFO]: Epoch 072 - training loss: 0.7575, validation loss: 0.9096
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch72_loss0.9096244871616364.pypots
2024-05-24 20:06:38 [INFO]: Epoch 073 - training loss: 0.7327, validation loss: 0.9110
2024-05-24 20:06:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch73_loss0.9109815657138824.pypots
2024-05-24 20:06:39 [INFO]: Epoch 074 - training loss: 0.7251, validation loss: 0.9096
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch74_loss0.9095872640609741.pypots
2024-05-24 20:06:39 [INFO]: Epoch 075 - training loss: 0.7319, validation loss: 0.9096
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch75_loss0.9095877259969711.pypots
2024-05-24 20:06:39 [INFO]: Epoch 076 - training loss: 0.7193, validation loss: 0.9084
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch76_loss0.908350259065628.pypots
2024-05-24 20:06:39 [INFO]: Epoch 077 - training loss: 0.7188, validation loss: 0.9098
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch77_loss0.9098479598760605.pypots
2024-05-24 20:06:39 [INFO]: Epoch 078 - training loss: 0.7171, validation loss: 0.9097
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch78_loss0.9097470343112946.pypots
2024-05-24 20:06:39 [INFO]: Epoch 079 - training loss: 0.7282, validation loss: 0.9084
2024-05-24 20:06:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch79_loss0.9083952754735947.pypots
2024-05-24 20:06:40 [INFO]: Epoch 080 - training loss: 0.7374, validation loss: 0.9081
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch80_loss0.9080531895160675.pypots
2024-05-24 20:06:40 [INFO]: Epoch 081 - training loss: 0.7271, validation loss: 0.9059
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch81_loss0.9059447050094604.pypots
2024-05-24 20:06:40 [INFO]: Epoch 082 - training loss: 0.7315, validation loss: 0.9074
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch82_loss0.907395213842392.pypots
2024-05-24 20:06:40 [INFO]: Epoch 083 - training loss: 0.7163, validation loss: 0.9030
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch83_loss0.9030200839042664.pypots
2024-05-24 20:06:40 [INFO]: Epoch 084 - training loss: 0.7383, validation loss: 0.9054
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch84_loss0.9053609520196915.pypots
2024-05-24 20:06:40 [INFO]: Epoch 085 - training loss: 0.7516, validation loss: 0.9053
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch85_loss0.9052621722221375.pypots
2024-05-24 20:06:40 [INFO]: Epoch 086 - training loss: 0.7386, validation loss: 0.9040
2024-05-24 20:06:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch86_loss0.9040015488862991.pypots
2024-05-24 20:06:41 [INFO]: Epoch 087 - training loss: 0.7241, validation loss: 0.9043
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch87_loss0.9043146371841431.pypots
2024-05-24 20:06:41 [INFO]: Epoch 088 - training loss: 0.7400, validation loss: 0.9001
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch88_loss0.9000543504953384.pypots
2024-05-24 20:06:41 [INFO]: Epoch 089 - training loss: 0.7320, validation loss: 0.9037
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch89_loss0.9037270694971085.pypots
2024-05-24 20:06:41 [INFO]: Epoch 090 - training loss: 0.7484, validation loss: 0.9026
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch90_loss0.9025559723377228.pypots
2024-05-24 20:06:41 [INFO]: Epoch 091 - training loss: 0.7261, validation loss: 0.9001
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch91_loss0.900085061788559.pypots
2024-05-24 20:06:41 [INFO]: Epoch 092 - training loss: 0.7317, validation loss: 0.9012
2024-05-24 20:06:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch92_loss0.9011786133050919.pypots
2024-05-24 20:06:42 [INFO]: Epoch 093 - training loss: 0.7217, validation loss: 0.9000
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch93_loss0.8999972939491272.pypots
2024-05-24 20:06:42 [INFO]: Epoch 094 - training loss: 0.7312, validation loss: 0.8996
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch94_loss0.8996175527572632.pypots
2024-05-24 20:06:42 [INFO]: Epoch 095 - training loss: 0.7033, validation loss: 0.8994
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch95_loss0.8993532061576843.pypots
2024-05-24 20:06:42 [INFO]: Epoch 096 - training loss: 0.7422, validation loss: 0.9031
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch96_loss0.9030783921480179.pypots
2024-05-24 20:06:42 [INFO]: Epoch 097 - training loss: 0.7412, validation loss: 0.8984
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch97_loss0.8984162211418152.pypots
2024-05-24 20:06:42 [INFO]: Epoch 098 - training loss: 0.7269, validation loss: 0.8999
2024-05-24 20:06:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch98_loss0.8998661637306213.pypots
2024-05-24 20:06:43 [INFO]: Epoch 099 - training loss: 0.7540, validation loss: 0.8987
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch99_loss0.8987304419279099.pypots
2024-05-24 20:06:43 [INFO]: Epoch 100 - training loss: 0.7319, validation loss: 0.8978
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch100_loss0.8977783769369125.pypots
2024-05-24 20:06:43 [INFO]: Epoch 101 - training loss: 0.7162, validation loss: 0.8973
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch101_loss0.8973088711500168.pypots
2024-05-24 20:06:43 [INFO]: Epoch 102 - training loss: 0.7371, validation loss: 0.8966
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch102_loss0.8966245353221893.pypots
2024-05-24 20:06:43 [INFO]: Epoch 103 - training loss: 0.7227, validation loss: 0.8931
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch103_loss0.8931389898061752.pypots
2024-05-24 20:06:43 [INFO]: Epoch 104 - training loss: 0.7116, validation loss: 0.8901
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch104_loss0.8901268243789673.pypots
2024-05-24 20:06:43 [INFO]: Epoch 105 - training loss: 0.7282, validation loss: 0.8908
2024-05-24 20:06:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch105_loss0.8908238857984543.pypots
2024-05-24 20:06:44 [INFO]: Epoch 106 - training loss: 0.7182, validation loss: 0.8894
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch106_loss0.8894384503364563.pypots
2024-05-24 20:06:44 [INFO]: Epoch 107 - training loss: 0.7042, validation loss: 0.8859
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch107_loss0.8858779668807983.pypots
2024-05-24 20:06:44 [INFO]: Epoch 108 - training loss: 0.7441, validation loss: 0.8844
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch108_loss0.8843887597322464.pypots
2024-05-24 20:06:44 [INFO]: Epoch 109 - training loss: 0.7057, validation loss: 0.8876
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch109_loss0.8875633180141449.pypots
2024-05-24 20:06:44 [INFO]: Epoch 110 - training loss: 0.7190, validation loss: 0.8863
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch110_loss0.8863156586885452.pypots
2024-05-24 20:06:44 [INFO]: Epoch 111 - training loss: 0.7778, validation loss: 0.8877
2024-05-24 20:06:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch111_loss0.8876713216304779.pypots
2024-05-24 20:06:45 [INFO]: Epoch 112 - training loss: 0.7390, validation loss: 0.8824
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch112_loss0.8824438154697418.pypots
2024-05-24 20:06:45 [INFO]: Epoch 113 - training loss: 0.7422, validation loss: 0.8854
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch113_loss0.8854434788227081.pypots
2024-05-24 20:06:45 [INFO]: Epoch 114 - training loss: 0.7357, validation loss: 0.8867
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch114_loss0.8866758346557617.pypots
2024-05-24 20:06:45 [INFO]: Epoch 115 - training loss: 0.7187, validation loss: 0.8824
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch115_loss0.8824324011802673.pypots
2024-05-24 20:06:45 [INFO]: Epoch 116 - training loss: 0.7645, validation loss: 0.8805
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch116_loss0.8804881274700165.pypots
2024-05-24 20:06:45 [INFO]: Epoch 117 - training loss: 0.7308, validation loss: 0.8789
2024-05-24 20:06:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch117_loss0.8789019584655762.pypots
2024-05-24 20:06:46 [INFO]: Epoch 118 - training loss: 0.7225, validation loss: 0.8801
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch118_loss0.8800585865974426.pypots
2024-05-24 20:06:46 [INFO]: Epoch 119 - training loss: 0.7355, validation loss: 0.8836
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch119_loss0.8836352229118347.pypots
2024-05-24 20:06:46 [INFO]: Epoch 120 - training loss: 0.7198, validation loss: 0.8787
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch120_loss0.8786775171756744.pypots
2024-05-24 20:06:46 [INFO]: Epoch 121 - training loss: 0.7234, validation loss: 0.8829
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch121_loss0.8828594237565994.pypots
2024-05-24 20:06:46 [INFO]: Epoch 122 - training loss: 0.7290, validation loss: 0.8780
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch122_loss0.877994030714035.pypots
2024-05-24 20:06:46 [INFO]: Epoch 123 - training loss: 0.7737, validation loss: 0.8741
2024-05-24 20:06:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch123_loss0.8741351962089539.pypots
2024-05-24 20:06:47 [INFO]: Epoch 124 - training loss: 0.7787, validation loss: 0.8757
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch124_loss0.8757326453924179.pypots
2024-05-24 20:06:47 [INFO]: Epoch 125 - training loss: 0.7404, validation loss: 0.8917
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch125_loss0.8917381018400192.pypots
2024-05-24 20:06:47 [INFO]: Epoch 126 - training loss: 0.7262, validation loss: 0.8809
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch126_loss0.8809412270784378.pypots
2024-05-24 20:06:47 [INFO]: Epoch 127 - training loss: 0.7295, validation loss: 0.8825
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch127_loss0.882522240281105.pypots
2024-05-24 20:06:47 [INFO]: Epoch 128 - training loss: 0.7176, validation loss: 0.8753
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch128_loss0.8752829432487488.pypots
2024-05-24 20:06:47 [INFO]: Epoch 129 - training loss: 0.7333, validation loss: 0.8734
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch129_loss0.8734297752380371.pypots
2024-05-24 20:06:47 [INFO]: Epoch 130 - training loss: 0.7075, validation loss: 0.8769
2024-05-24 20:06:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch130_loss0.8768588006496429.pypots
2024-05-24 20:06:48 [INFO]: Epoch 131 - training loss: 0.7168, validation loss: 0.8656
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch131_loss0.8656206130981445.pypots
2024-05-24 20:06:48 [INFO]: Epoch 132 - training loss: 0.7392, validation loss: 0.8715
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch132_loss0.8714763224124908.pypots
2024-05-24 20:06:48 [INFO]: Epoch 133 - training loss: 0.7105, validation loss: 0.8680
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch133_loss0.867994949221611.pypots
2024-05-24 20:06:48 [INFO]: Epoch 134 - training loss: 0.7252, validation loss: 0.8727
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch134_loss0.8726651966571808.pypots
2024-05-24 20:06:48 [INFO]: Epoch 135 - training loss: 0.7375, validation loss: 0.8691
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch135_loss0.8690696954727173.pypots
2024-05-24 20:06:48 [INFO]: Epoch 136 - training loss: 0.7264, validation loss: 0.8640
2024-05-24 20:06:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch136_loss0.8639621883630753.pypots
2024-05-24 20:06:49 [INFO]: Epoch 137 - training loss: 0.7051, validation loss: 0.8642
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch137_loss0.8641980588436127.pypots
2024-05-24 20:06:49 [INFO]: Epoch 138 - training loss: 0.7244, validation loss: 0.8666
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch138_loss0.8666220903396606.pypots
2024-05-24 20:06:49 [INFO]: Epoch 139 - training loss: 0.7083, validation loss: 0.8615
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch139_loss0.8614531755447388.pypots
2024-05-24 20:06:49 [INFO]: Epoch 140 - training loss: 0.7137, validation loss: 0.8631
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch140_loss0.8630985915660858.pypots
2024-05-24 20:06:49 [INFO]: Epoch 141 - training loss: 0.7144, validation loss: 0.8607
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch141_loss0.8606870025396347.pypots
2024-05-24 20:06:49 [INFO]: Epoch 142 - training loss: 0.7142, validation loss: 0.8597
2024-05-24 20:06:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch142_loss0.8597048670053482.pypots
2024-05-24 20:06:50 [INFO]: Epoch 143 - training loss: 0.7186, validation loss: 0.8595
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch143_loss0.8594570904970169.pypots
2024-05-24 20:06:50 [INFO]: Epoch 144 - training loss: 0.7070, validation loss: 0.8616
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch144_loss0.8615895807743073.pypots
2024-05-24 20:06:50 [INFO]: Epoch 145 - training loss: 0.7138, validation loss: 0.8611
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch145_loss0.8611132204532623.pypots
2024-05-24 20:06:50 [INFO]: Epoch 146 - training loss: 0.7208, validation loss: 0.8570
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch146_loss0.8569869548082352.pypots
2024-05-24 20:06:50 [INFO]: Epoch 147 - training loss: 0.7347, validation loss: 0.8535
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch147_loss0.8535096645355225.pypots
2024-05-24 20:06:50 [INFO]: Epoch 148 - training loss: 0.7235, validation loss: 0.8555
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch148_loss0.8555345088243484.pypots
2024-05-24 20:06:50 [INFO]: Epoch 149 - training loss: 0.7186, validation loss: 0.8581
2024-05-24 20:06:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch149_loss0.8581284582614899.pypots
2024-05-24 20:06:51 [INFO]: Epoch 150 - training loss: 0.7273, validation loss: 0.8549
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch150_loss0.8548789322376251.pypots
2024-05-24 20:06:51 [INFO]: Epoch 151 - training loss: 0.7220, validation loss: 0.8526
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch151_loss0.852624773979187.pypots
2024-05-24 20:06:51 [INFO]: Epoch 152 - training loss: 0.7139, validation loss: 0.8523
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch152_loss0.8523417264223099.pypots
2024-05-24 20:06:51 [INFO]: Epoch 153 - training loss: 0.7327, validation loss: 0.8505
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch153_loss0.8505096137523651.pypots
2024-05-24 20:06:51 [INFO]: Epoch 154 - training loss: 0.7138, validation loss: 0.8534
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch154_loss0.8534247428178787.pypots
2024-05-24 20:06:51 [INFO]: Epoch 155 - training loss: 0.7458, validation loss: 0.8545
2024-05-24 20:06:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch155_loss0.8545181453227997.pypots
2024-05-24 20:06:52 [INFO]: Epoch 156 - training loss: 0.7168, validation loss: 0.8466
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch156_loss0.846600279211998.pypots
2024-05-24 20:06:52 [INFO]: Epoch 157 - training loss: 0.7280, validation loss: 0.8466
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch157_loss0.8465881794691086.pypots
2024-05-24 20:06:52 [INFO]: Epoch 158 - training loss: 0.7171, validation loss: 0.8468
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch158_loss0.8468137979507446.pypots
2024-05-24 20:06:52 [INFO]: Epoch 159 - training loss: 0.7166, validation loss: 0.8518
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch159_loss0.8518414199352264.pypots
2024-05-24 20:06:52 [INFO]: Epoch 160 - training loss: 0.7314, validation loss: 0.8522
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch160_loss0.852186918258667.pypots
2024-05-24 20:06:52 [INFO]: Epoch 161 - training loss: 0.7094, validation loss: 0.8450
2024-05-24 20:06:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch161_loss0.844965860247612.pypots
2024-05-24 20:06:53 [INFO]: Epoch 162 - training loss: 0.7150, validation loss: 0.8471
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch162_loss0.8471357673406601.pypots
2024-05-24 20:06:53 [INFO]: Epoch 163 - training loss: 0.7244, validation loss: 0.8457
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch163_loss0.8457445204257965.pypots
2024-05-24 20:06:53 [INFO]: Epoch 164 - training loss: 0.7201, validation loss: 0.8421
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch164_loss0.8420966863632202.pypots
2024-05-24 20:06:53 [INFO]: Epoch 165 - training loss: 0.7004, validation loss: 0.8483
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch165_loss0.8482894152402878.pypots
2024-05-24 20:06:53 [INFO]: Epoch 166 - training loss: 0.7137, validation loss: 0.8439
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch166_loss0.8439426124095917.pypots
2024-05-24 20:06:53 [INFO]: Epoch 167 - training loss: 0.7334, validation loss: 0.8463
2024-05-24 20:06:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch167_loss0.846307098865509.pypots
2024-05-24 20:06:54 [INFO]: Epoch 168 - training loss: 0.7293, validation loss: 0.8417
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch168_loss0.8416605591773987.pypots
2024-05-24 20:06:54 [INFO]: Epoch 169 - training loss: 0.7332, validation loss: 0.8427
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch169_loss0.8427081257104874.pypots
2024-05-24 20:06:54 [INFO]: Epoch 170 - training loss: 0.7250, validation loss: 0.8407
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch170_loss0.8407411426305771.pypots
2024-05-24 20:06:54 [INFO]: Epoch 171 - training loss: 0.7299, validation loss: 0.8396
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch171_loss0.8395633697509766.pypots
2024-05-24 20:06:54 [INFO]: Epoch 172 - training loss: 0.7123, validation loss: 0.8431
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch172_loss0.8430789113044739.pypots
2024-05-24 20:06:54 [INFO]: Epoch 173 - training loss: 0.7018, validation loss: 0.8421
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch173_loss0.8421454280614853.pypots
2024-05-24 20:06:54 [INFO]: Epoch 174 - training loss: 0.7171, validation loss: 0.8415
2024-05-24 20:06:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch174_loss0.8414507210254669.pypots
2024-05-24 20:06:55 [INFO]: Epoch 175 - training loss: 0.6968, validation loss: 0.8438
2024-05-24 20:06:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch175_loss0.8438332229852676.pypots
2024-05-24 20:06:55 [INFO]: Epoch 176 - training loss: 0.7201, validation loss: 0.8376
2024-05-24 20:06:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch176_loss0.8376264572143555.pypots
2024-05-24 20:06:55 [INFO]: Epoch 177 - training loss: 0.7094, validation loss: 0.8374
2024-05-24 20:06:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch177_loss0.8373812139034271.pypots
2024-05-24 20:06:55 [INFO]: Epoch 178 - training loss: 0.7127, validation loss: 0.8396
2024-05-24 20:06:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch178_loss0.8395727127790451.pypots
2024-05-24 20:06:55 [INFO]: Epoch 179 - training loss: 0.7090, validation loss: 0.8371
2024-05-24 20:06:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch179_loss0.8370713293552399.pypots
2024-05-24 20:06:56 [INFO]: Epoch 180 - training loss: 0.6985, validation loss: 0.8364
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch180_loss0.8364077061414719.pypots
2024-05-24 20:06:56 [INFO]: Epoch 181 - training loss: 0.7122, validation loss: 0.8338
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch181_loss0.833790972828865.pypots
2024-05-24 20:06:56 [INFO]: Epoch 182 - training loss: 0.7186, validation loss: 0.8398
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch182_loss0.8398408442735672.pypots
2024-05-24 20:06:56 [INFO]: Epoch 183 - training loss: 0.7193, validation loss: 0.8364
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch183_loss0.8364272713661194.pypots
2024-05-24 20:06:56 [INFO]: Epoch 184 - training loss: 0.7110, validation loss: 0.8351
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch184_loss0.8350920081138611.pypots
2024-05-24 20:06:56 [INFO]: Epoch 185 - training loss: 0.7234, validation loss: 0.8319
2024-05-24 20:06:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch185_loss0.8319373726844788.pypots
2024-05-24 20:06:57 [INFO]: Epoch 186 - training loss: 0.6935, validation loss: 0.8346
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch186_loss0.834603801369667.pypots
2024-05-24 20:06:57 [INFO]: Epoch 187 - training loss: 0.7169, validation loss: 0.8336
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch187_loss0.833576574921608.pypots
2024-05-24 20:06:57 [INFO]: Epoch 188 - training loss: 0.7271, validation loss: 0.8339
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch188_loss0.8339453339576721.pypots
2024-05-24 20:06:57 [INFO]: Epoch 189 - training loss: 0.7094, validation loss: 0.8309
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch189_loss0.8309219926595688.pypots
2024-05-24 20:06:57 [INFO]: Epoch 190 - training loss: 0.7296, validation loss: 0.8316
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch190_loss0.8316024541854858.pypots
2024-05-24 20:06:57 [INFO]: Epoch 191 - training loss: 0.7251, validation loss: 0.8309
2024-05-24 20:06:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch191_loss0.8309470117092133.pypots
2024-05-24 20:06:58 [INFO]: Epoch 192 - training loss: 0.7150, validation loss: 0.8354
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch192_loss0.835418701171875.pypots
2024-05-24 20:06:58 [INFO]: Epoch 193 - training loss: 0.7006, validation loss: 0.8347
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch193_loss0.8346944749355316.pypots
2024-05-24 20:06:58 [INFO]: Epoch 194 - training loss: 0.6943, validation loss: 0.8311
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch194_loss0.8310910165309906.pypots
2024-05-24 20:06:58 [INFO]: Epoch 195 - training loss: 0.7318, validation loss: 0.8342
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch195_loss0.834166094660759.pypots
2024-05-24 20:06:58 [INFO]: Epoch 196 - training loss: 0.7103, validation loss: 0.8329
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch196_loss0.8328989893198013.pypots
2024-05-24 20:06:58 [INFO]: Epoch 197 - training loss: 0.7154, validation loss: 0.8323
2024-05-24 20:06:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch197_loss0.8323456346988678.pypots
2024-05-24 20:06:59 [INFO]: Epoch 198 - training loss: 0.7201, validation loss: 0.8303
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch198_loss0.8303028792142868.pypots
2024-05-24 20:06:59 [INFO]: Epoch 199 - training loss: 0.7176, validation loss: 0.8304
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch199_loss0.8304177075624466.pypots
2024-05-24 20:06:59 [INFO]: Epoch 200 - training loss: 0.7155, validation loss: 0.8280
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch200_loss0.8279592543840408.pypots
2024-05-24 20:06:59 [INFO]: Epoch 201 - training loss: 0.7180, validation loss: 0.8296
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch201_loss0.8296202421188354.pypots
2024-05-24 20:06:59 [INFO]: Epoch 202 - training loss: 0.7220, validation loss: 0.8264
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch202_loss0.8263827413320541.pypots
2024-05-24 20:06:59 [INFO]: Epoch 203 - training loss: 0.7243, validation loss: 0.8287
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch203_loss0.8286935836076736.pypots
2024-05-24 20:06:59 [INFO]: Epoch 204 - training loss: 0.7244, validation loss: 0.8303
2024-05-24 20:06:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch204_loss0.8302639424800873.pypots
2024-05-24 20:07:00 [INFO]: Epoch 205 - training loss: 0.7090, validation loss: 0.8277
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch205_loss0.8277090340852737.pypots
2024-05-24 20:07:00 [INFO]: Epoch 206 - training loss: 0.7096, validation loss: 0.8240
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch206_loss0.8240455389022827.pypots
2024-05-24 20:07:00 [INFO]: Epoch 207 - training loss: 0.7152, validation loss: 0.8278
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch207_loss0.8277634978294373.pypots
2024-05-24 20:07:00 [INFO]: Epoch 208 - training loss: 0.7274, validation loss: 0.8279
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch208_loss0.8279039412736893.pypots
2024-05-24 20:07:00 [INFO]: Epoch 209 - training loss: 0.7263, validation loss: 0.8287
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch209_loss0.828683614730835.pypots
2024-05-24 20:07:00 [INFO]: Epoch 210 - training loss: 0.7350, validation loss: 0.8268
2024-05-24 20:07:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch210_loss0.8267652094364166.pypots
2024-05-24 20:07:01 [INFO]: Epoch 211 - training loss: 0.7103, validation loss: 0.8268
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch211_loss0.8268430531024933.pypots
2024-05-24 20:07:01 [INFO]: Epoch 212 - training loss: 0.7024, validation loss: 0.8270
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch212_loss0.8269920200109482.pypots
2024-05-24 20:07:01 [INFO]: Epoch 213 - training loss: 0.6942, validation loss: 0.8252
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch213_loss0.8252299726009369.pypots
2024-05-24 20:07:01 [INFO]: Epoch 214 - training loss: 0.7444, validation loss: 0.8300
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch214_loss0.8300279527902603.pypots
2024-05-24 20:07:01 [INFO]: Epoch 215 - training loss: 0.7307, validation loss: 0.8250
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch215_loss0.825041651725769.pypots
2024-05-24 20:07:01 [INFO]: Epoch 216 - training loss: 0.7404, validation loss: 0.8266
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN_epoch216_loss0.826630249619484.pypots
2024-05-24 20:07:01 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:07:01 [INFO]: Finished training. The best model is from epoch#206.
2024-05-24 20:07:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_1/MRNN_ettm1/20240524_T200626/MRNN.pypots
2024-05-24 20:07:02 [INFO]: MRNN on ETTm1: MAE=0.5800, MSE=0.9732
2024-05-24 20:07:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/MRNN_ettm1/imputation.pkl
2024-05-24 20:07:02 [INFO]: Using the given device: cpu
2024-05-24 20:07:02 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-24 20:07:02 [INFO]: Successfully created the given path "saved_results/round_1/LOCF_ettm1".
2024-05-24 20:07:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/LOCF_ettm1/imputation.pkl
2024-05-24 20:07:02 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-24 20:07:02 [INFO]: Successfully created the given path "saved_results/round_1/Median_ettm1".
2024-05-24 20:07:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Median_ettm1/imputation.pkl
2024-05-24 20:07:02 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-24 20:07:02 [INFO]: Successfully created the given path "saved_results/round_1/Mean_ettm1".
2024-05-24 20:07:02 [INFO]: Successfully saved to augmentation_premask_saved_results/round_1/Mean_ettm1/imputation.pkl
2024-05-24 20:07:02 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2024-05-24 20:07:02 [INFO]: Using the given device: cuda:0
2024-05-24 20:07:02 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T200702
2024-05-24 20:07:02 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T200702/tensorboard
2024-05-24 20:07:02 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 20:07:02 [INFO]: Epoch 001 - training loss: 1.1662, validation loss: 0.2925
2024-05-24 20:07:03 [INFO]: Epoch 002 - training loss: 0.8440, validation loss: 0.1564
2024-05-24 20:07:03 [INFO]: Epoch 003 - training loss: 0.7223, validation loss: 0.1321
2024-05-24 20:07:04 [INFO]: Epoch 004 - training loss: 0.6546, validation loss: 0.1156
2024-05-24 20:07:04 [INFO]: Epoch 005 - training loss: 0.6275, validation loss: 0.0825
2024-05-24 20:07:05 [INFO]: Epoch 006 - training loss: 0.5769, validation loss: 0.0716
2024-05-24 20:07:05 [INFO]: Epoch 007 - training loss: 0.5511, validation loss: 0.0674
2024-05-24 20:07:06 [INFO]: Epoch 008 - training loss: 0.5308, validation loss: 0.0657
2024-05-24 20:07:06 [INFO]: Epoch 009 - training loss: 0.5260, validation loss: 0.0669
2024-05-24 20:07:07 [INFO]: Epoch 010 - training loss: 0.5218, validation loss: 0.0564
2024-05-24 20:07:07 [INFO]: Epoch 011 - training loss: 0.4891, validation loss: 0.0596
2024-05-24 20:07:08 [INFO]: Epoch 012 - training loss: 0.4916, validation loss: 0.0575
2024-05-24 20:07:08 [INFO]: Epoch 013 - training loss: 0.4852, validation loss: 0.0513
2024-05-24 20:07:08 [INFO]: Epoch 014 - training loss: 0.4649, validation loss: 0.0538
2024-05-24 20:07:09 [INFO]: Epoch 015 - training loss: 0.4773, validation loss: 0.0510
2024-05-24 20:07:09 [INFO]: Epoch 016 - training loss: 0.4445, validation loss: 0.0526
2024-05-24 20:07:10 [INFO]: Epoch 017 - training loss: 0.4792, validation loss: 0.0437
2024-05-24 20:07:10 [INFO]: Epoch 018 - training loss: 0.4435, validation loss: 0.0630
2024-05-24 20:07:11 [INFO]: Epoch 019 - training loss: 0.4328, validation loss: 0.0486
2024-05-24 20:07:11 [INFO]: Epoch 020 - training loss: 0.4106, validation loss: 0.0460
2024-05-24 20:07:12 [INFO]: Epoch 021 - training loss: 0.4353, validation loss: 0.0453
2024-05-24 20:07:12 [INFO]: Epoch 022 - training loss: 0.4100, validation loss: 0.0433
2024-05-24 20:07:13 [INFO]: Epoch 023 - training loss: 0.3984, validation loss: 0.0471
2024-05-24 20:07:13 [INFO]: Epoch 024 - training loss: 0.3998, validation loss: 0.0520
2024-05-24 20:07:14 [INFO]: Epoch 025 - training loss: 0.3942, validation loss: 0.0402
2024-05-24 20:07:14 [INFO]: Epoch 026 - training loss: 0.3930, validation loss: 0.0489
2024-05-24 20:07:15 [INFO]: Epoch 027 - training loss: 0.3852, validation loss: 0.0446
2024-05-24 20:07:15 [INFO]: Epoch 028 - training loss: 0.3762, validation loss: 0.0495
2024-05-24 20:07:16 [INFO]: Epoch 029 - training loss: 0.3915, validation loss: 0.0452
2024-05-24 20:07:16 [INFO]: Epoch 030 - training loss: 0.3827, validation loss: 0.0470
2024-05-24 20:07:17 [INFO]: Epoch 031 - training loss: 0.3837, validation loss: 0.0415
2024-05-24 20:07:17 [INFO]: Epoch 032 - training loss: 0.3647, validation loss: 0.0350
2024-05-24 20:07:18 [INFO]: Epoch 033 - training loss: 0.3540, validation loss: 0.0348
2024-05-24 20:07:18 [INFO]: Epoch 034 - training loss: 0.3507, validation loss: 0.0448
2024-05-24 20:07:19 [INFO]: Epoch 035 - training loss: 0.3502, validation loss: 0.0363
2024-05-24 20:07:19 [INFO]: Epoch 036 - training loss: 0.3562, validation loss: 0.0345
2024-05-24 20:07:20 [INFO]: Epoch 037 - training loss: 0.3618, validation loss: 0.0457
2024-05-24 20:07:20 [INFO]: Epoch 038 - training loss: 0.3506, validation loss: 0.0378
2024-05-24 20:07:21 [INFO]: Epoch 039 - training loss: 0.3657, validation loss: 0.0350
2024-05-24 20:07:21 [INFO]: Epoch 040 - training loss: 0.3372, validation loss: 0.0490
2024-05-24 20:07:21 [INFO]: Epoch 041 - training loss: 0.3283, validation loss: 0.0404
2024-05-24 20:07:22 [INFO]: Epoch 042 - training loss: 0.3225, validation loss: 0.0343
2024-05-24 20:07:22 [INFO]: Epoch 043 - training loss: 0.3278, validation loss: 0.0337
2024-05-24 20:07:23 [INFO]: Epoch 044 - training loss: 0.3206, validation loss: 0.0346
2024-05-24 20:07:23 [INFO]: Epoch 045 - training loss: 0.3230, validation loss: 0.1276
2024-05-24 20:07:24 [INFO]: Epoch 046 - training loss: 0.3606, validation loss: 0.0461
2024-05-24 20:07:24 [INFO]: Epoch 047 - training loss: 0.3312, validation loss: 0.0462
2024-05-24 20:07:25 [INFO]: Epoch 048 - training loss: 0.3192, validation loss: 0.0366
2024-05-24 20:07:25 [INFO]: Epoch 049 - training loss: 0.3243, validation loss: 0.0339
2024-05-24 20:07:26 [INFO]: Epoch 050 - training loss: 0.3042, validation loss: 0.0385
2024-05-24 20:07:26 [INFO]: Epoch 051 - training loss: 0.3073, validation loss: 0.0382
2024-05-24 20:07:27 [INFO]: Epoch 052 - training loss: 0.3023, validation loss: 0.0364
2024-05-24 20:07:27 [INFO]: Epoch 053 - training loss: 0.2984, validation loss: 0.0321
2024-05-24 20:07:28 [INFO]: Epoch 054 - training loss: 0.3079, validation loss: 0.0377
2024-05-24 20:07:28 [INFO]: Epoch 055 - training loss: 0.3074, validation loss: 0.0492
2024-05-24 20:07:29 [INFO]: Epoch 056 - training loss: 0.3064, validation loss: 0.0486
2024-05-24 20:07:29 [INFO]: Epoch 057 - training loss: 0.3038, validation loss: 0.0362
2024-05-24 20:07:30 [INFO]: Epoch 058 - training loss: 0.2978, validation loss: 0.0399
2024-05-24 20:07:30 [INFO]: Epoch 059 - training loss: 0.2951, validation loss: 0.0370
2024-05-24 20:07:31 [INFO]: Epoch 060 - training loss: 0.2952, validation loss: 0.0336
2024-05-24 20:07:31 [INFO]: Epoch 061 - training loss: 0.2888, validation loss: 0.0311
2024-05-24 20:07:32 [INFO]: Epoch 062 - training loss: 0.2849, validation loss: 0.0347
2024-05-24 20:07:32 [INFO]: Epoch 063 - training loss: 0.2841, validation loss: 0.0378
2024-05-24 20:07:33 [INFO]: Epoch 064 - training loss: 0.2988, validation loss: 0.0387
2024-05-24 20:07:33 [INFO]: Epoch 065 - training loss: 0.2876, validation loss: 0.0322
2024-05-24 20:07:34 [INFO]: Epoch 066 - training loss: 0.2825, validation loss: 0.0355
2024-05-24 20:07:34 [INFO]: Epoch 067 - training loss: 0.2910, validation loss: 0.0340
2024-05-24 20:07:34 [INFO]: Epoch 068 - training loss: 0.2768, validation loss: 0.0365
2024-05-24 20:07:35 [INFO]: Epoch 069 - training loss: 0.2812, validation loss: 0.0331
2024-05-24 20:07:35 [INFO]: Epoch 070 - training loss: 0.2774, validation loss: 0.0332
2024-05-24 20:07:36 [INFO]: Epoch 071 - training loss: 0.2789, validation loss: 0.0343
2024-05-24 20:07:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:07:36 [INFO]: Finished training. The best model is from epoch#61.
2024-05-24 20:07:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/SAITS_ettm1/20240524_T200702/SAITS.pypots
2024-05-24 20:07:36 [INFO]: SAITS on ETTm1: MAE=0.1576, MSE=0.0572
2024-05-24 20:07:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/SAITS_ettm1/imputation.pkl
2024-05-24 20:07:36 [INFO]: Using the given device: cuda:0
2024-05-24 20:07:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T200736
2024-05-24 20:07:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T200736/tensorboard
2024-05-24 20:07:36 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 20:07:36 [INFO]: Epoch 001 - training loss: 1.2200, validation loss: 0.3616
2024-05-24 20:07:36 [INFO]: Epoch 002 - training loss: 0.7275, validation loss: 0.1973
2024-05-24 20:07:37 [INFO]: Epoch 003 - training loss: 0.5834, validation loss: 0.1450
2024-05-24 20:07:37 [INFO]: Epoch 004 - training loss: 0.5481, validation loss: 0.1142
2024-05-24 20:07:37 [INFO]: Epoch 005 - training loss: 0.4926, validation loss: 0.1021
2024-05-24 20:07:37 [INFO]: Epoch 006 - training loss: 0.4559, validation loss: 0.0917
2024-05-24 20:07:37 [INFO]: Epoch 007 - training loss: 0.4385, validation loss: 0.0812
2024-05-24 20:07:38 [INFO]: Epoch 008 - training loss: 0.4190, validation loss: 0.0736
2024-05-24 20:07:38 [INFO]: Epoch 009 - training loss: 0.4053, validation loss: 0.0693
2024-05-24 20:07:38 [INFO]: Epoch 010 - training loss: 0.3896, validation loss: 0.0649
2024-05-24 20:07:38 [INFO]: Epoch 011 - training loss: 0.3757, validation loss: 0.0614
2024-05-24 20:07:38 [INFO]: Epoch 012 - training loss: 0.3678, validation loss: 0.0595
2024-05-24 20:07:39 [INFO]: Epoch 013 - training loss: 0.3619, validation loss: 0.0553
2024-05-24 20:07:39 [INFO]: Epoch 014 - training loss: 0.3481, validation loss: 0.0507
2024-05-24 20:07:39 [INFO]: Epoch 015 - training loss: 0.3431, validation loss: 0.0519
2024-05-24 20:07:39 [INFO]: Epoch 016 - training loss: 0.3349, validation loss: 0.0475
2024-05-24 20:07:39 [INFO]: Epoch 017 - training loss: 0.3258, validation loss: 0.0471
2024-05-24 20:07:39 [INFO]: Epoch 018 - training loss: 0.3217, validation loss: 0.0475
2024-05-24 20:07:40 [INFO]: Epoch 019 - training loss: 0.3197, validation loss: 0.0504
2024-05-24 20:07:40 [INFO]: Epoch 020 - training loss: 0.3257, validation loss: 0.0461
2024-05-24 20:07:40 [INFO]: Epoch 021 - training loss: 0.3153, validation loss: 0.0433
2024-05-24 20:07:40 [INFO]: Epoch 022 - training loss: 0.3094, validation loss: 0.0428
2024-05-24 20:07:40 [INFO]: Epoch 023 - training loss: 0.3058, validation loss: 0.0443
2024-05-24 20:07:41 [INFO]: Epoch 024 - training loss: 0.3009, validation loss: 0.0431
2024-05-24 20:07:41 [INFO]: Epoch 025 - training loss: 0.2957, validation loss: 0.0498
2024-05-24 20:07:41 [INFO]: Epoch 026 - training loss: 0.3039, validation loss: 0.0406
2024-05-24 20:07:41 [INFO]: Epoch 027 - training loss: 0.2916, validation loss: 0.0396
2024-05-24 20:07:41 [INFO]: Epoch 028 - training loss: 0.2861, validation loss: 0.0394
2024-05-24 20:07:42 [INFO]: Epoch 029 - training loss: 0.2800, validation loss: 0.0371
2024-05-24 20:07:42 [INFO]: Epoch 030 - training loss: 0.2743, validation loss: 0.0379
2024-05-24 20:07:42 [INFO]: Epoch 031 - training loss: 0.2748, validation loss: 0.0421
2024-05-24 20:07:42 [INFO]: Epoch 032 - training loss: 0.2806, validation loss: 0.0353
2024-05-24 20:07:42 [INFO]: Epoch 033 - training loss: 0.2658, validation loss: 0.0373
2024-05-24 20:07:43 [INFO]: Epoch 034 - training loss: 0.2662, validation loss: 0.0355
2024-05-24 20:07:43 [INFO]: Epoch 035 - training loss: 0.2670, validation loss: 0.0408
2024-05-24 20:07:43 [INFO]: Epoch 036 - training loss: 0.2686, validation loss: 0.0371
2024-05-24 20:07:43 [INFO]: Epoch 037 - training loss: 0.2594, validation loss: 0.0346
2024-05-24 20:07:43 [INFO]: Epoch 038 - training loss: 0.2516, validation loss: 0.0346
2024-05-24 20:07:44 [INFO]: Epoch 039 - training loss: 0.2546, validation loss: 0.0334
2024-05-24 20:07:44 [INFO]: Epoch 040 - training loss: 0.2515, validation loss: 0.0327
2024-05-24 20:07:44 [INFO]: Epoch 041 - training loss: 0.2441, validation loss: 0.0340
2024-05-24 20:07:44 [INFO]: Epoch 042 - training loss: 0.2443, validation loss: 0.0311
2024-05-24 20:07:44 [INFO]: Epoch 043 - training loss: 0.2415, validation loss: 0.0329
2024-05-24 20:07:44 [INFO]: Epoch 044 - training loss: 0.2397, validation loss: 0.0308
2024-05-24 20:07:45 [INFO]: Epoch 045 - training loss: 0.2359, validation loss: 0.0316
2024-05-24 20:07:45 [INFO]: Epoch 046 - training loss: 0.2356, validation loss: 0.0323
2024-05-24 20:07:45 [INFO]: Epoch 047 - training loss: 0.2333, validation loss: 0.0328
2024-05-24 20:07:45 [INFO]: Epoch 048 - training loss: 0.2345, validation loss: 0.0315
2024-05-24 20:07:45 [INFO]: Epoch 049 - training loss: 0.2311, validation loss: 0.0290
2024-05-24 20:07:46 [INFO]: Epoch 050 - training loss: 0.2301, validation loss: 0.0300
2024-05-24 20:07:46 [INFO]: Epoch 051 - training loss: 0.2251, validation loss: 0.0293
2024-05-24 20:07:46 [INFO]: Epoch 052 - training loss: 0.2253, validation loss: 0.0328
2024-05-24 20:07:46 [INFO]: Epoch 053 - training loss: 0.2311, validation loss: 0.0301
2024-05-24 20:07:46 [INFO]: Epoch 054 - training loss: 0.2276, validation loss: 0.0321
2024-05-24 20:07:47 [INFO]: Epoch 055 - training loss: 0.2205, validation loss: 0.0330
2024-05-24 20:07:47 [INFO]: Epoch 056 - training loss: 0.2217, validation loss: 0.0285
2024-05-24 20:07:47 [INFO]: Epoch 057 - training loss: 0.2172, validation loss: 0.0295
2024-05-24 20:07:47 [INFO]: Epoch 058 - training loss: 0.2152, validation loss: 0.0321
2024-05-24 20:07:47 [INFO]: Epoch 059 - training loss: 0.2187, validation loss: 0.0289
2024-05-24 20:07:48 [INFO]: Epoch 060 - training loss: 0.2137, validation loss: 0.0277
2024-05-24 20:07:48 [INFO]: Epoch 061 - training loss: 0.2163, validation loss: 0.0298
2024-05-24 20:07:48 [INFO]: Epoch 062 - training loss: 0.2169, validation loss: 0.0276
2024-05-24 20:07:48 [INFO]: Epoch 063 - training loss: 0.2098, validation loss: 0.0279
2024-05-24 20:07:48 [INFO]: Epoch 064 - training loss: 0.2125, validation loss: 0.0280
2024-05-24 20:07:48 [INFO]: Epoch 065 - training loss: 0.2093, validation loss: 0.0279
2024-05-24 20:07:49 [INFO]: Epoch 066 - training loss: 0.2074, validation loss: 0.0276
2024-05-24 20:07:49 [INFO]: Epoch 067 - training loss: 0.2019, validation loss: 0.0274
2024-05-24 20:07:49 [INFO]: Epoch 068 - training loss: 0.2041, validation loss: 0.0264
2024-05-24 20:07:49 [INFO]: Epoch 069 - training loss: 0.2008, validation loss: 0.0261
2024-05-24 20:07:49 [INFO]: Epoch 070 - training loss: 0.2027, validation loss: 0.0280
2024-05-24 20:07:50 [INFO]: Epoch 071 - training loss: 0.2096, validation loss: 0.0266
2024-05-24 20:07:50 [INFO]: Epoch 072 - training loss: 0.2072, validation loss: 0.0263
2024-05-24 20:07:50 [INFO]: Epoch 073 - training loss: 0.1999, validation loss: 0.0259
2024-05-24 20:07:50 [INFO]: Epoch 074 - training loss: 0.1981, validation loss: 0.0267
2024-05-24 20:07:50 [INFO]: Epoch 075 - training loss: 0.2007, validation loss: 0.0264
2024-05-24 20:07:51 [INFO]: Epoch 076 - training loss: 0.1979, validation loss: 0.0255
2024-05-24 20:07:51 [INFO]: Epoch 077 - training loss: 0.1932, validation loss: 0.0255
2024-05-24 20:07:51 [INFO]: Epoch 078 - training loss: 0.1959, validation loss: 0.0260
2024-05-24 20:07:51 [INFO]: Epoch 079 - training loss: 0.1973, validation loss: 0.0260
2024-05-24 20:07:51 [INFO]: Epoch 080 - training loss: 0.1957, validation loss: 0.0295
2024-05-24 20:07:52 [INFO]: Epoch 081 - training loss: 0.2003, validation loss: 0.0264
2024-05-24 20:07:52 [INFO]: Epoch 082 - training loss: 0.1954, validation loss: 0.0278
2024-05-24 20:07:52 [INFO]: Epoch 083 - training loss: 0.1982, validation loss: 0.0290
2024-05-24 20:07:52 [INFO]: Epoch 084 - training loss: 0.2029, validation loss: 0.0253
2024-05-24 20:07:52 [INFO]: Epoch 085 - training loss: 0.1945, validation loss: 0.0261
2024-05-24 20:07:52 [INFO]: Epoch 086 - training loss: 0.1939, validation loss: 0.0275
2024-05-24 20:07:53 [INFO]: Epoch 087 - training loss: 0.1975, validation loss: 0.0258
2024-05-24 20:07:53 [INFO]: Epoch 088 - training loss: 0.1915, validation loss: 0.0263
2024-05-24 20:07:53 [INFO]: Epoch 089 - training loss: 0.1918, validation loss: 0.0252
2024-05-24 20:07:53 [INFO]: Epoch 090 - training loss: 0.1885, validation loss: 0.0270
2024-05-24 20:07:53 [INFO]: Epoch 091 - training loss: 0.1921, validation loss: 0.0260
2024-05-24 20:07:54 [INFO]: Epoch 092 - training loss: 0.1952, validation loss: 0.0268
2024-05-24 20:07:54 [INFO]: Epoch 093 - training loss: 0.1888, validation loss: 0.0261
2024-05-24 20:07:54 [INFO]: Epoch 094 - training loss: 0.1915, validation loss: 0.0273
2024-05-24 20:07:54 [INFO]: Epoch 095 - training loss: 0.1964, validation loss: 0.0261
2024-05-24 20:07:54 [INFO]: Epoch 096 - training loss: 0.1899, validation loss: 0.0252
2024-05-24 20:07:55 [INFO]: Epoch 097 - training loss: 0.1882, validation loss: 0.0275
2024-05-24 20:07:55 [INFO]: Epoch 098 - training loss: 0.1969, validation loss: 0.0245
2024-05-24 20:07:55 [INFO]: Epoch 099 - training loss: 0.1910, validation loss: 0.0266
2024-05-24 20:07:55 [INFO]: Epoch 100 - training loss: 0.1899, validation loss: 0.0252
2024-05-24 20:07:55 [INFO]: Epoch 101 - training loss: 0.1897, validation loss: 0.0276
2024-05-24 20:07:55 [INFO]: Epoch 102 - training loss: 0.1865, validation loss: 0.0261
2024-05-24 20:07:56 [INFO]: Epoch 103 - training loss: 0.1838, validation loss: 0.0241
2024-05-24 20:07:56 [INFO]: Epoch 104 - training loss: 0.1831, validation loss: 0.0254
2024-05-24 20:07:56 [INFO]: Epoch 105 - training loss: 0.1825, validation loss: 0.0252
2024-05-24 20:07:56 [INFO]: Epoch 106 - training loss: 0.1868, validation loss: 0.0250
2024-05-24 20:07:56 [INFO]: Epoch 107 - training loss: 0.1831, validation loss: 0.0245
2024-05-24 20:07:57 [INFO]: Epoch 108 - training loss: 0.1825, validation loss: 0.0263
2024-05-24 20:07:57 [INFO]: Epoch 109 - training loss: 0.1804, validation loss: 0.0259
2024-05-24 20:07:57 [INFO]: Epoch 110 - training loss: 0.1882, validation loss: 0.0297
2024-05-24 20:07:57 [INFO]: Epoch 111 - training loss: 0.1890, validation loss: 0.0286
2024-05-24 20:07:57 [INFO]: Epoch 112 - training loss: 0.1840, validation loss: 0.0258
2024-05-24 20:07:58 [INFO]: Epoch 113 - training loss: 0.1880, validation loss: 0.0266
2024-05-24 20:07:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:07:58 [INFO]: Finished training. The best model is from epoch#103.
2024-05-24 20:07:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/Transformer_ettm1/20240524_T200736/Transformer.pypots
2024-05-24 20:07:58 [INFO]: Transformer on ETTm1: MAE=0.1494, MSE=0.0430
2024-05-24 20:07:58 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Transformer_ettm1/imputation.pkl
2024-05-24 20:07:58 [INFO]: Using the given device: cuda:0
2024-05-24 20:07:58 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T200758
2024-05-24 20:07:58 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T200758/tensorboard
2024-05-24 20:07:58 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 20:07:58 [INFO]: Epoch 001 - training loss: 0.1353, validation loss: 0.0567
2024-05-24 20:07:58 [INFO]: Epoch 002 - training loss: 0.0628, validation loss: 0.0401
2024-05-24 20:07:58 [INFO]: Epoch 003 - training loss: 0.0518, validation loss: 0.0334
2024-05-24 20:07:59 [INFO]: Epoch 004 - training loss: 0.0442, validation loss: 0.0333
2024-05-24 20:07:59 [INFO]: Epoch 005 - training loss: 0.0427, validation loss: 0.0312
2024-05-24 20:07:59 [INFO]: Epoch 006 - training loss: 0.0425, validation loss: 0.0302
2024-05-24 20:07:59 [INFO]: Epoch 007 - training loss: 0.0424, validation loss: 0.0324
2024-05-24 20:07:59 [INFO]: Epoch 008 - training loss: 0.0419, validation loss: 0.0298
2024-05-24 20:07:59 [INFO]: Epoch 009 - training loss: 0.0383, validation loss: 0.0301
2024-05-24 20:08:00 [INFO]: Epoch 010 - training loss: 0.0364, validation loss: 0.0290
2024-05-24 20:08:00 [INFO]: Epoch 011 - training loss: 0.0368, validation loss: 0.0284
2024-05-24 20:08:00 [INFO]: Epoch 012 - training loss: 0.0378, validation loss: 0.0285
2024-05-24 20:08:00 [INFO]: Epoch 013 - training loss: 0.0352, validation loss: 0.0285
2024-05-24 20:08:00 [INFO]: Epoch 014 - training loss: 0.0379, validation loss: 0.0289
2024-05-24 20:08:00 [INFO]: Epoch 015 - training loss: 0.0391, validation loss: 0.0321
2024-05-24 20:08:01 [INFO]: Epoch 016 - training loss: 0.0486, validation loss: 0.0316
2024-05-24 20:08:01 [INFO]: Epoch 017 - training loss: 0.0377, validation loss: 0.0293
2024-05-24 20:08:01 [INFO]: Epoch 018 - training loss: 0.0342, validation loss: 0.0276
2024-05-24 20:08:01 [INFO]: Epoch 019 - training loss: 0.0348, validation loss: 0.0279
2024-05-24 20:08:01 [INFO]: Epoch 020 - training loss: 0.0343, validation loss: 0.0282
2024-05-24 20:08:02 [INFO]: Epoch 021 - training loss: 0.0329, validation loss: 0.0280
2024-05-24 20:08:02 [INFO]: Epoch 022 - training loss: 0.0325, validation loss: 0.0270
2024-05-24 20:08:02 [INFO]: Epoch 023 - training loss: 0.0321, validation loss: 0.0283
2024-05-24 20:08:02 [INFO]: Epoch 024 - training loss: 0.0345, validation loss: 0.0279
2024-05-24 20:08:02 [INFO]: Epoch 025 - training loss: 0.0333, validation loss: 0.0282
2024-05-24 20:08:03 [INFO]: Epoch 026 - training loss: 0.0348, validation loss: 0.0345
2024-05-24 20:08:03 [INFO]: Epoch 027 - training loss: 0.0384, validation loss: 0.0279
2024-05-24 20:08:03 [INFO]: Epoch 028 - training loss: 0.0331, validation loss: 0.0271
2024-05-24 20:08:03 [INFO]: Epoch 029 - training loss: 0.0333, validation loss: 0.0284
2024-05-24 20:08:03 [INFO]: Epoch 030 - training loss: 0.0312, validation loss: 0.0266
2024-05-24 20:08:04 [INFO]: Epoch 031 - training loss: 0.0292, validation loss: 0.0264
2024-05-24 20:08:04 [INFO]: Epoch 032 - training loss: 0.0309, validation loss: 0.0265
2024-05-24 20:08:04 [INFO]: Epoch 033 - training loss: 0.0320, validation loss: 0.0270
2024-05-24 20:08:04 [INFO]: Epoch 034 - training loss: 0.0322, validation loss: 0.0278
2024-05-24 20:08:04 [INFO]: Epoch 035 - training loss: 0.0305, validation loss: 0.0262
2024-05-24 20:08:04 [INFO]: Epoch 036 - training loss: 0.0288, validation loss: 0.0267
2024-05-24 20:08:05 [INFO]: Epoch 037 - training loss: 0.0269, validation loss: 0.0256
2024-05-24 20:08:05 [INFO]: Epoch 038 - training loss: 0.0269, validation loss: 0.0251
2024-05-24 20:08:05 [INFO]: Epoch 039 - training loss: 0.0259, validation loss: 0.0255
2024-05-24 20:08:05 [INFO]: Epoch 040 - training loss: 0.0264, validation loss: 0.0260
2024-05-24 20:08:05 [INFO]: Epoch 041 - training loss: 0.0268, validation loss: 0.0270
2024-05-24 20:08:05 [INFO]: Epoch 042 - training loss: 0.0260, validation loss: 0.0264
2024-05-24 20:08:06 [INFO]: Epoch 043 - training loss: 0.0253, validation loss: 0.0260
2024-05-24 20:08:06 [INFO]: Epoch 044 - training loss: 0.0246, validation loss: 0.0264
2024-05-24 20:08:06 [INFO]: Epoch 045 - training loss: 0.0243, validation loss: 0.0267
2024-05-24 20:08:06 [INFO]: Epoch 046 - training loss: 0.0277, validation loss: 0.0267
2024-05-24 20:08:06 [INFO]: Epoch 047 - training loss: 0.0252, validation loss: 0.0261
2024-05-24 20:08:07 [INFO]: Epoch 048 - training loss: 0.0245, validation loss: 0.0255
2024-05-24 20:08:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:08:07 [INFO]: Finished training. The best model is from epoch#38.
2024-05-24 20:08:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/TimesNet_ettm1/20240524_T200758/TimesNet.pypots
2024-05-24 20:08:07 [INFO]: TimesNet on ETTm1: MAE=0.1145, MSE=0.0284
2024-05-24 20:08:07 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/TimesNet_ettm1/imputation.pkl
2024-05-24 20:08:07 [INFO]: Using the given device: cuda:0
2024-05-24 20:08:07 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807
2024-05-24 20:08:07 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/tensorboard
2024-05-24 20:08:07 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 20:08:09 [INFO]: Epoch 001 - training loss: 0.7032, validation loss: 0.4456
2024-05-24 20:08:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch1_loss0.44558100402355194.pypots
2024-05-24 20:08:11 [INFO]: Epoch 002 - training loss: 0.4774, validation loss: 0.3748
2024-05-24 20:08:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch2_loss0.37481842190027237.pypots
2024-05-24 20:08:13 [INFO]: Epoch 003 - training loss: 0.3509, validation loss: 0.3544
2024-05-24 20:08:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch3_loss0.3544166162610054.pypots
2024-05-24 20:08:15 [INFO]: Epoch 004 - training loss: 0.3188, validation loss: 0.3053
2024-05-24 20:08:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch4_loss0.3052787482738495.pypots
2024-05-24 20:08:17 [INFO]: Epoch 005 - training loss: 0.3445, validation loss: 0.2871
2024-05-24 20:08:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch5_loss0.2870739996433258.pypots
2024-05-24 20:08:19 [INFO]: Epoch 006 - training loss: 0.2983, validation loss: 0.2814
2024-05-24 20:08:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch6_loss0.2813502177596092.pypots
2024-05-24 20:08:21 [INFO]: Epoch 007 - training loss: 0.2540, validation loss: 0.2603
2024-05-24 20:08:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch7_loss0.2603481858968735.pypots
2024-05-24 20:08:23 [INFO]: Epoch 008 - training loss: 0.2694, validation loss: 0.2616
2024-05-24 20:08:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch8_loss0.2616279795765877.pypots
2024-05-24 20:08:25 [INFO]: Epoch 009 - training loss: 0.2712, validation loss: 0.2540
2024-05-24 20:08:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch9_loss0.25395966321229935.pypots
2024-05-24 20:08:27 [INFO]: Epoch 010 - training loss: 0.2503, validation loss: 0.2468
2024-05-24 20:08:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch10_loss0.2467736192047596.pypots
2024-05-24 20:08:29 [INFO]: Epoch 011 - training loss: 0.2350, validation loss: 0.2349
2024-05-24 20:08:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch11_loss0.23492289707064629.pypots
2024-05-24 20:08:31 [INFO]: Epoch 012 - training loss: 0.2400, validation loss: 0.2321
2024-05-24 20:08:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch12_loss0.23213369026780128.pypots
2024-05-24 20:08:33 [INFO]: Epoch 013 - training loss: 0.2258, validation loss: 0.2275
2024-05-24 20:08:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch13_loss0.227523572742939.pypots
2024-05-24 20:08:35 [INFO]: Epoch 014 - training loss: 0.2711, validation loss: 0.2321
2024-05-24 20:08:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch14_loss0.2320907674729824.pypots
2024-05-24 20:08:37 [INFO]: Epoch 015 - training loss: 0.2165, validation loss: 0.2281
2024-05-24 20:08:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch15_loss0.22813992574810982.pypots
2024-05-24 20:08:39 [INFO]: Epoch 016 - training loss: 0.2090, validation loss: 0.2150
2024-05-24 20:08:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch16_loss0.21502233669161797.pypots
2024-05-24 20:08:41 [INFO]: Epoch 017 - training loss: 0.2283, validation loss: 0.2121
2024-05-24 20:08:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch17_loss0.21211491897702217.pypots
2024-05-24 20:08:43 [INFO]: Epoch 018 - training loss: 0.1869, validation loss: 0.2027
2024-05-24 20:08:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch18_loss0.20270906388759613.pypots
2024-05-24 20:08:45 [INFO]: Epoch 019 - training loss: 0.2108, validation loss: 0.1889
2024-05-24 20:08:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch19_loss0.18886195123195648.pypots
2024-05-24 20:08:47 [INFO]: Epoch 020 - training loss: 0.1834, validation loss: 0.1963
2024-05-24 20:08:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch20_loss0.19626041129231453.pypots
2024-05-24 20:08:49 [INFO]: Epoch 021 - training loss: 0.2142, validation loss: 0.1938
2024-05-24 20:08:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch21_loss0.19379600882530212.pypots
2024-05-24 20:08:51 [INFO]: Epoch 022 - training loss: 0.2143, validation loss: 0.1970
2024-05-24 20:08:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch22_loss0.1970011442899704.pypots
2024-05-24 20:08:53 [INFO]: Epoch 023 - training loss: 0.2092, validation loss: 0.1796
2024-05-24 20:08:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch23_loss0.1795884184539318.pypots
2024-05-24 20:08:55 [INFO]: Epoch 024 - training loss: 0.2160, validation loss: 0.1962
2024-05-24 20:08:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch24_loss0.19616783410310745.pypots
2024-05-24 20:08:57 [INFO]: Epoch 025 - training loss: 0.1956, validation loss: 0.1896
2024-05-24 20:08:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch25_loss0.18955503404140472.pypots
2024-05-24 20:08:59 [INFO]: Epoch 026 - training loss: 0.1854, validation loss: 0.1759
2024-05-24 20:08:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch26_loss0.17592719569802284.pypots
2024-05-24 20:09:01 [INFO]: Epoch 027 - training loss: 0.1599, validation loss: 0.1747
2024-05-24 20:09:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch27_loss0.17465022206306458.pypots
2024-05-24 20:09:03 [INFO]: Epoch 028 - training loss: 0.1579, validation loss: 0.1665
2024-05-24 20:09:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch28_loss0.16649146378040314.pypots
2024-05-24 20:09:05 [INFO]: Epoch 029 - training loss: 0.1684, validation loss: 0.1651
2024-05-24 20:09:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch29_loss0.1651480495929718.pypots
2024-05-24 20:09:07 [INFO]: Epoch 030 - training loss: 0.1975, validation loss: 0.1641
2024-05-24 20:09:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch30_loss0.16410451754927635.pypots
2024-05-24 20:09:09 [INFO]: Epoch 031 - training loss: 0.1766, validation loss: 0.1563
2024-05-24 20:09:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch31_loss0.15633787959814072.pypots
2024-05-24 20:09:11 [INFO]: Epoch 032 - training loss: 0.1611, validation loss: 0.1540
2024-05-24 20:09:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch32_loss0.15396535396575928.pypots
2024-05-24 20:09:13 [INFO]: Epoch 033 - training loss: 0.1845, validation loss: 0.1555
2024-05-24 20:09:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch33_loss0.1555338278412819.pypots
2024-05-24 20:09:15 [INFO]: Epoch 034 - training loss: 0.1470, validation loss: 0.1502
2024-05-24 20:09:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch34_loss0.15023783966898918.pypots
2024-05-24 20:09:18 [INFO]: Epoch 035 - training loss: 0.2167, validation loss: 0.1470
2024-05-24 20:09:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch35_loss0.14695509150624275.pypots
2024-05-24 20:09:20 [INFO]: Epoch 036 - training loss: 0.1521, validation loss: 0.1447
2024-05-24 20:09:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch36_loss0.14472070336341858.pypots
2024-05-24 20:09:22 [INFO]: Epoch 037 - training loss: 0.1596, validation loss: 0.1705
2024-05-24 20:09:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch37_loss0.17053816467523575.pypots
2024-05-24 20:09:24 [INFO]: Epoch 038 - training loss: 0.1689, validation loss: 0.1586
2024-05-24 20:09:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch38_loss0.15859027206897736.pypots
2024-05-24 20:09:26 [INFO]: Epoch 039 - training loss: 0.1711, validation loss: 0.1498
2024-05-24 20:09:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch39_loss0.14979824051260948.pypots
2024-05-24 20:09:28 [INFO]: Epoch 040 - training loss: 0.1503, validation loss: 0.1536
2024-05-24 20:09:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch40_loss0.15362877398729324.pypots
2024-05-24 20:09:30 [INFO]: Epoch 041 - training loss: 0.1611, validation loss: 0.1439
2024-05-24 20:09:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch41_loss0.14389119297266006.pypots
2024-05-24 20:09:32 [INFO]: Epoch 042 - training loss: 0.1942, validation loss: 0.1445
2024-05-24 20:09:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch42_loss0.14454203099012375.pypots
2024-05-24 20:09:34 [INFO]: Epoch 043 - training loss: 0.1333, validation loss: 0.1472
2024-05-24 20:09:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch43_loss0.14720452204346657.pypots
2024-05-24 20:09:36 [INFO]: Epoch 044 - training loss: 0.1431, validation loss: 0.1462
2024-05-24 20:09:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch44_loss0.14622770622372627.pypots
2024-05-24 20:09:38 [INFO]: Epoch 045 - training loss: 0.1836, validation loss: 0.1419
2024-05-24 20:09:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch45_loss0.14187230914831161.pypots
2024-05-24 20:09:40 [INFO]: Epoch 046 - training loss: 0.1549, validation loss: 0.1836
2024-05-24 20:09:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch46_loss0.18355530127882957.pypots
2024-05-24 20:09:42 [INFO]: Epoch 047 - training loss: 0.1832, validation loss: 0.1618
2024-05-24 20:09:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch47_loss0.16177032515406609.pypots
2024-05-24 20:09:44 [INFO]: Epoch 048 - training loss: 0.1577, validation loss: 0.1557
2024-05-24 20:09:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch48_loss0.15565402805805206.pypots
2024-05-24 20:09:46 [INFO]: Epoch 049 - training loss: 0.2002, validation loss: 0.1554
2024-05-24 20:09:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch49_loss0.1553651988506317.pypots
2024-05-24 20:09:48 [INFO]: Epoch 050 - training loss: 0.1736, validation loss: 0.1684
2024-05-24 20:09:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch50_loss0.16836027428507805.pypots
2024-05-24 20:09:50 [INFO]: Epoch 051 - training loss: 0.1606, validation loss: 0.1455
2024-05-24 20:09:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch51_loss0.14547879621386528.pypots
2024-05-24 20:09:52 [INFO]: Epoch 052 - training loss: 0.1392, validation loss: 0.1460
2024-05-24 20:09:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch52_loss0.14603357762098312.pypots
2024-05-24 20:09:54 [INFO]: Epoch 053 - training loss: 0.1658, validation loss: 0.1420
2024-05-24 20:09:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch53_loss0.14201010391116142.pypots
2024-05-24 20:09:56 [INFO]: Epoch 054 - training loss: 0.1685, validation loss: 0.1547
2024-05-24 20:09:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch54_loss0.15467709675431252.pypots
2024-05-24 20:09:58 [INFO]: Epoch 055 - training loss: 0.1682, validation loss: 0.1503
2024-05-24 20:09:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI_epoch55_loss0.15029415488243103.pypots
2024-05-24 20:09:58 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:09:58 [INFO]: Finished training. The best model is from epoch#45.
2024-05-24 20:09:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/CSDI_ettm1/20240524_T200807/CSDI.pypots
2024-05-24 20:10:14 [INFO]: CSDI on ETTm1: MAE=0.1564, MSE=0.0573
2024-05-24 20:10:14 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/CSDI_ettm1/imputation.pkl
2024-05-24 20:10:14 [INFO]: Using the given device: cuda:0
2024-05-24 20:10:14 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T201014
2024-05-24 20:10:14 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T201014/tensorboard
2024-05-24 20:10:14 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 20:10:14 [INFO]: Epoch 001 - training loss: 23783.0465, validation loss: 0.9650
2024-05-24 20:10:14 [INFO]: Epoch 002 - training loss: 21849.7721, validation loss: 0.9686
2024-05-24 20:10:14 [INFO]: Epoch 003 - training loss: 19825.0906, validation loss: 0.9622
2024-05-24 20:10:14 [INFO]: Epoch 004 - training loss: 17984.9076, validation loss: 0.9419
2024-05-24 20:10:14 [INFO]: Epoch 005 - training loss: 16161.3669, validation loss: 0.9123
2024-05-24 20:10:14 [INFO]: Epoch 006 - training loss: 14409.2569, validation loss: 0.8483
2024-05-24 20:10:14 [INFO]: Epoch 007 - training loss: 13144.0184, validation loss: 0.7490
2024-05-24 20:10:15 [INFO]: Epoch 008 - training loss: 12110.4063, validation loss: 0.6372
2024-05-24 20:10:15 [INFO]: Epoch 009 - training loss: 11528.5474, validation loss: 0.5548
2024-05-24 20:10:15 [INFO]: Epoch 010 - training loss: 11061.4077, validation loss: 0.5144
2024-05-24 20:10:15 [INFO]: Epoch 011 - training loss: 10771.6878, validation loss: 0.5069
2024-05-24 20:10:15 [INFO]: Epoch 012 - training loss: 10405.8199, validation loss: 0.5036
2024-05-24 20:10:15 [INFO]: Epoch 013 - training loss: 10234.1740, validation loss: 0.4970
2024-05-24 20:10:15 [INFO]: Epoch 014 - training loss: 10106.5220, validation loss: 0.4891
2024-05-24 20:10:15 [INFO]: Epoch 015 - training loss: 10024.8545, validation loss: 0.4831
2024-05-24 20:10:15 [INFO]: Epoch 016 - training loss: 9935.0989, validation loss: 0.4782
2024-05-24 20:10:16 [INFO]: Epoch 017 - training loss: 9869.0013, validation loss: 0.4679
2024-05-24 20:10:16 [INFO]: Epoch 018 - training loss: 9761.7720, validation loss: 0.4543
2024-05-24 20:10:16 [INFO]: Epoch 019 - training loss: 9704.3901, validation loss: 0.4517
2024-05-24 20:10:16 [INFO]: Epoch 020 - training loss: 9704.9694, validation loss: 0.4371
2024-05-24 20:10:16 [INFO]: Epoch 021 - training loss: 9629.1910, validation loss: 0.4188
2024-05-24 20:10:16 [INFO]: Epoch 022 - training loss: 9595.9383, validation loss: 0.4065
2024-05-24 20:10:16 [INFO]: Epoch 023 - training loss: 9566.1626, validation loss: 0.3908
2024-05-24 20:10:16 [INFO]: Epoch 024 - training loss: 9569.0141, validation loss: 0.3677
2024-05-24 20:10:16 [INFO]: Epoch 025 - training loss: 9521.5874, validation loss: 0.3457
2024-05-24 20:10:16 [INFO]: Epoch 026 - training loss: 9559.2741, validation loss: 0.3218
2024-05-24 20:10:17 [INFO]: Epoch 027 - training loss: 9477.5015, validation loss: 0.3145
2024-05-24 20:10:17 [INFO]: Epoch 028 - training loss: 9468.3271, validation loss: 0.2942
2024-05-24 20:10:17 [INFO]: Epoch 029 - training loss: 9510.9501, validation loss: 0.2803
2024-05-24 20:10:17 [INFO]: Epoch 030 - training loss: 9440.9753, validation loss: 0.2659
2024-05-24 20:10:17 [INFO]: Epoch 031 - training loss: 9408.1202, validation loss: 0.2572
2024-05-24 20:10:17 [INFO]: Epoch 032 - training loss: 9397.5140, validation loss: 0.2476
2024-05-24 20:10:17 [INFO]: Epoch 033 - training loss: 9388.1138, validation loss: 0.2450
2024-05-24 20:10:17 [INFO]: Epoch 034 - training loss: 9384.0510, validation loss: 0.2431
2024-05-24 20:10:17 [INFO]: Epoch 035 - training loss: 9385.4630, validation loss: 0.2362
2024-05-24 20:10:18 [INFO]: Epoch 036 - training loss: 9360.4948, validation loss: 0.2306
2024-05-24 20:10:18 [INFO]: Epoch 037 - training loss: 9354.7975, validation loss: 0.2290
2024-05-24 20:10:18 [INFO]: Epoch 038 - training loss: 9353.2701, validation loss: 0.2222
2024-05-24 20:10:18 [INFO]: Epoch 039 - training loss: 9343.5825, validation loss: 0.2207
2024-05-24 20:10:18 [INFO]: Epoch 040 - training loss: 9335.6577, validation loss: 0.2157
2024-05-24 20:10:18 [INFO]: Epoch 041 - training loss: 9346.0941, validation loss: 0.2095
2024-05-24 20:10:18 [INFO]: Epoch 042 - training loss: 9327.9239, validation loss: 0.2067
2024-05-24 20:10:18 [INFO]: Epoch 043 - training loss: 9322.8952, validation loss: 0.2059
2024-05-24 20:10:18 [INFO]: Epoch 044 - training loss: 9319.7709, validation loss: 0.2060
2024-05-24 20:10:19 [INFO]: Epoch 045 - training loss: 9311.7991, validation loss: 0.2003
2024-05-24 20:10:19 [INFO]: Epoch 046 - training loss: 9319.5602, validation loss: 0.1983
2024-05-24 20:10:19 [INFO]: Epoch 047 - training loss: 9305.2294, validation loss: 0.1939
2024-05-24 20:10:19 [INFO]: Epoch 048 - training loss: 9302.1392, validation loss: 0.1926
2024-05-24 20:10:19 [INFO]: Epoch 049 - training loss: 9297.5093, validation loss: 0.1885
2024-05-24 20:10:19 [INFO]: Epoch 050 - training loss: 9299.7329, validation loss: 0.1883
2024-05-24 20:10:19 [INFO]: Epoch 051 - training loss: 9296.1151, validation loss: 0.1844
2024-05-24 20:10:19 [INFO]: Epoch 052 - training loss: 9302.3060, validation loss: 0.1826
2024-05-24 20:10:19 [INFO]: Epoch 053 - training loss: 9286.3338, validation loss: 0.1759
2024-05-24 20:10:20 [INFO]: Epoch 054 - training loss: 9285.1446, validation loss: 0.1748
2024-05-24 20:10:20 [INFO]: Epoch 055 - training loss: 9282.3440, validation loss: 0.1720
2024-05-24 20:10:20 [INFO]: Epoch 056 - training loss: 9281.0486, validation loss: 0.1693
2024-05-24 20:10:20 [INFO]: Epoch 057 - training loss: 9280.8513, validation loss: 0.1674
2024-05-24 20:10:20 [INFO]: Epoch 058 - training loss: 9280.3390, validation loss: 0.1664
2024-05-24 20:10:20 [INFO]: Epoch 059 - training loss: 9276.6221, validation loss: 0.1609
2024-05-24 20:10:20 [INFO]: Epoch 060 - training loss: 9280.7764, validation loss: 0.1588
2024-05-24 20:10:20 [INFO]: Epoch 061 - training loss: 9273.3582, validation loss: 0.1582
2024-05-24 20:10:20 [INFO]: Epoch 062 - training loss: 9266.0909, validation loss: 0.1540
2024-05-24 20:10:20 [INFO]: Epoch 063 - training loss: 9264.4824, validation loss: 0.1556
2024-05-24 20:10:21 [INFO]: Epoch 064 - training loss: 9263.8227, validation loss: 0.1529
2024-05-24 20:10:21 [INFO]: Epoch 065 - training loss: 9262.6186, validation loss: 0.1508
2024-05-24 20:10:21 [INFO]: Epoch 066 - training loss: 9260.1954, validation loss: 0.1497
2024-05-24 20:10:21 [INFO]: Epoch 067 - training loss: 9276.4951, validation loss: 0.1502
2024-05-24 20:10:21 [INFO]: Epoch 068 - training loss: 9259.8200, validation loss: 0.1458
2024-05-24 20:10:21 [INFO]: Epoch 069 - training loss: 9261.3589, validation loss: 0.1471
2024-05-24 20:10:21 [INFO]: Epoch 070 - training loss: 9264.3533, validation loss: 0.1443
2024-05-24 20:10:21 [INFO]: Epoch 071 - training loss: 9260.2354, validation loss: 0.1451
2024-05-24 20:10:21 [INFO]: Epoch 072 - training loss: 9253.0699, validation loss: 0.1424
2024-05-24 20:10:22 [INFO]: Epoch 073 - training loss: 9250.4125, validation loss: 0.1416
2024-05-24 20:10:22 [INFO]: Epoch 074 - training loss: 9249.4012, validation loss: 0.1417
2024-05-24 20:10:22 [INFO]: Epoch 075 - training loss: 9248.1702, validation loss: 0.1424
2024-05-24 20:10:22 [INFO]: Epoch 076 - training loss: 9247.3724, validation loss: 0.1401
2024-05-24 20:10:22 [INFO]: Epoch 077 - training loss: 9248.5381, validation loss: 0.1401
2024-05-24 20:10:22 [INFO]: Epoch 078 - training loss: 9247.6772, validation loss: 0.1403
2024-05-24 20:10:22 [INFO]: Epoch 079 - training loss: 9246.7842, validation loss: 0.1370
2024-05-24 20:10:22 [INFO]: Epoch 080 - training loss: 9243.5239, validation loss: 0.1368
2024-05-24 20:10:22 [INFO]: Epoch 081 - training loss: 9244.4761, validation loss: 0.1378
2024-05-24 20:10:23 [INFO]: Epoch 082 - training loss: 9244.9641, validation loss: 0.1365
2024-05-24 20:10:23 [INFO]: Epoch 083 - training loss: 9241.7603, validation loss: 0.1355
2024-05-24 20:10:23 [INFO]: Epoch 084 - training loss: 9243.7550, validation loss: 0.1366
2024-05-24 20:10:23 [INFO]: Epoch 085 - training loss: 9242.1525, validation loss: 0.1337
2024-05-24 20:10:23 [INFO]: Epoch 086 - training loss: 9238.6849, validation loss: 0.1361
2024-05-24 20:10:23 [INFO]: Epoch 087 - training loss: 9239.4681, validation loss: 0.1330
2024-05-24 20:10:23 [INFO]: Epoch 088 - training loss: 9238.7065, validation loss: 0.1323
2024-05-24 20:10:23 [INFO]: Epoch 089 - training loss: 9238.9530, validation loss: 0.1322
2024-05-24 20:10:23 [INFO]: Epoch 090 - training loss: 9237.1869, validation loss: 0.1318
2024-05-24 20:10:24 [INFO]: Epoch 091 - training loss: 9238.0344, validation loss: 0.1321
2024-05-24 20:10:24 [INFO]: Epoch 092 - training loss: 9235.3147, validation loss: 0.1292
2024-05-24 20:10:24 [INFO]: Epoch 093 - training loss: 9238.0426, validation loss: 0.1311
2024-05-24 20:10:24 [INFO]: Epoch 094 - training loss: 9237.4160, validation loss: 0.1297
2024-05-24 20:10:24 [INFO]: Epoch 095 - training loss: 9241.6865, validation loss: 0.1275
2024-05-24 20:10:24 [INFO]: Epoch 096 - training loss: 9234.3959, validation loss: 0.1280
2024-05-24 20:10:24 [INFO]: Epoch 097 - training loss: 9240.8248, validation loss: 0.1275
2024-05-24 20:10:24 [INFO]: Epoch 098 - training loss: 9234.0684, validation loss: 0.1262
2024-05-24 20:10:24 [INFO]: Epoch 099 - training loss: 9235.1416, validation loss: 0.1271
2024-05-24 20:10:24 [INFO]: Epoch 100 - training loss: 9234.7318, validation loss: 0.1246
2024-05-24 20:10:25 [INFO]: Epoch 101 - training loss: 9231.4752, validation loss: 0.1246
2024-05-24 20:10:25 [INFO]: Epoch 102 - training loss: 9230.7791, validation loss: 0.1255
2024-05-24 20:10:25 [INFO]: Epoch 103 - training loss: 9235.6273, validation loss: 0.1265
2024-05-24 20:10:25 [INFO]: Epoch 104 - training loss: 9228.4091, validation loss: 0.1237
2024-05-24 20:10:25 [INFO]: Epoch 105 - training loss: 9229.6239, validation loss: 0.1239
2024-05-24 20:10:25 [INFO]: Epoch 106 - training loss: 9228.8235, validation loss: 0.1222
2024-05-24 20:10:25 [INFO]: Epoch 107 - training loss: 9229.4983, validation loss: 0.1226
2024-05-24 20:10:25 [INFO]: Epoch 108 - training loss: 9227.1250, validation loss: 0.1212
2024-05-24 20:10:25 [INFO]: Epoch 109 - training loss: 9230.8009, validation loss: 0.1204
2024-05-24 20:10:26 [INFO]: Epoch 110 - training loss: 9228.6267, validation loss: 0.1217
2024-05-24 20:10:26 [INFO]: Epoch 111 - training loss: 9226.9504, validation loss: 0.1229
2024-05-24 20:10:26 [INFO]: Epoch 112 - training loss: 9228.3796, validation loss: 0.1215
2024-05-24 20:10:26 [INFO]: Epoch 113 - training loss: 9226.8082, validation loss: 0.1209
2024-05-24 20:10:26 [INFO]: Epoch 114 - training loss: 9226.5667, validation loss: 0.1183
2024-05-24 20:10:26 [INFO]: Epoch 115 - training loss: 9226.6246, validation loss: 0.1179
2024-05-24 20:10:26 [INFO]: Epoch 116 - training loss: 9225.1979, validation loss: 0.1181
2024-05-24 20:10:26 [INFO]: Epoch 117 - training loss: 9226.7694, validation loss: 0.1183
2024-05-24 20:10:26 [INFO]: Epoch 118 - training loss: 9223.6241, validation loss: 0.1182
2024-05-24 20:10:27 [INFO]: Epoch 119 - training loss: 9225.9366, validation loss: 0.1153
2024-05-24 20:10:27 [INFO]: Epoch 120 - training loss: 9225.3966, validation loss: 0.1168
2024-05-24 20:10:27 [INFO]: Epoch 121 - training loss: 9223.3483, validation loss: 0.1157
2024-05-24 20:10:27 [INFO]: Epoch 122 - training loss: 9225.5774, validation loss: 0.1135
2024-05-24 20:10:27 [INFO]: Epoch 123 - training loss: 9224.2496, validation loss: 0.1175
2024-05-24 20:10:27 [INFO]: Epoch 124 - training loss: 9223.5488, validation loss: 0.1148
2024-05-24 20:10:27 [INFO]: Epoch 125 - training loss: 9223.7353, validation loss: 0.1139
2024-05-24 20:10:27 [INFO]: Epoch 126 - training loss: 9226.3392, validation loss: 0.1143
2024-05-24 20:10:27 [INFO]: Epoch 127 - training loss: 9221.3045, validation loss: 0.1133
2024-05-24 20:10:28 [INFO]: Epoch 128 - training loss: 9221.6810, validation loss: 0.1130
2024-05-24 20:10:28 [INFO]: Epoch 129 - training loss: 9223.6995, validation loss: 0.1135
2024-05-24 20:10:28 [INFO]: Epoch 130 - training loss: 9220.5963, validation loss: 0.1103
2024-05-24 20:10:28 [INFO]: Epoch 131 - training loss: 9221.5328, validation loss: 0.1106
2024-05-24 20:10:28 [INFO]: Epoch 132 - training loss: 9222.3295, validation loss: 0.1092
2024-05-24 20:10:28 [INFO]: Epoch 133 - training loss: 9221.2081, validation loss: 0.1101
2024-05-24 20:10:28 [INFO]: Epoch 134 - training loss: 9222.8777, validation loss: 0.1110
2024-05-24 20:10:28 [INFO]: Epoch 135 - training loss: 9220.9532, validation loss: 0.1092
2024-05-24 20:10:28 [INFO]: Epoch 136 - training loss: 9220.4623, validation loss: 0.1090
2024-05-24 20:10:28 [INFO]: Epoch 137 - training loss: 9220.3436, validation loss: 0.1093
2024-05-24 20:10:29 [INFO]: Epoch 138 - training loss: 9219.6663, validation loss: 0.1090
2024-05-24 20:10:29 [INFO]: Epoch 139 - training loss: 9218.8464, validation loss: 0.1062
2024-05-24 20:10:29 [INFO]: Epoch 140 - training loss: 9220.6278, validation loss: 0.1096
2024-05-24 20:10:29 [INFO]: Epoch 141 - training loss: 9220.0082, validation loss: 0.1076
2024-05-24 20:10:29 [INFO]: Epoch 142 - training loss: 9219.3067, validation loss: 0.1090
2024-05-24 20:10:29 [INFO]: Epoch 143 - training loss: 9219.5159, validation loss: 0.1065
2024-05-24 20:10:29 [INFO]: Epoch 144 - training loss: 9220.3083, validation loss: 0.1073
2024-05-24 20:10:29 [INFO]: Epoch 145 - training loss: 9218.5024, validation loss: 0.1051
2024-05-24 20:10:29 [INFO]: Epoch 146 - training loss: 9217.7968, validation loss: 0.1075
2024-05-24 20:10:30 [INFO]: Epoch 147 - training loss: 9217.0035, validation loss: 0.1053
2024-05-24 20:10:30 [INFO]: Epoch 148 - training loss: 9216.3527, validation loss: 0.1054
2024-05-24 20:10:30 [INFO]: Epoch 149 - training loss: 9217.3563, validation loss: 0.1045
2024-05-24 20:10:30 [INFO]: Epoch 150 - training loss: 9216.8863, validation loss: 0.1047
2024-05-24 20:10:30 [INFO]: Epoch 151 - training loss: 9217.3333, validation loss: 0.1041
2024-05-24 20:10:30 [INFO]: Epoch 152 - training loss: 9217.5822, validation loss: 0.1031
2024-05-24 20:10:30 [INFO]: Epoch 153 - training loss: 9217.0807, validation loss: 0.1042
2024-05-24 20:10:30 [INFO]: Epoch 154 - training loss: 9215.0457, validation loss: 0.1035
2024-05-24 20:10:30 [INFO]: Epoch 155 - training loss: 9215.3240, validation loss: 0.1033
2024-05-24 20:10:31 [INFO]: Epoch 156 - training loss: 9215.3557, validation loss: 0.1034
2024-05-24 20:10:31 [INFO]: Epoch 157 - training loss: 9215.8496, validation loss: 0.1024
2024-05-24 20:10:31 [INFO]: Epoch 158 - training loss: 9215.5491, validation loss: 0.1009
2024-05-24 20:10:31 [INFO]: Epoch 159 - training loss: 9215.5042, validation loss: 0.1023
2024-05-24 20:10:31 [INFO]: Epoch 160 - training loss: 9216.6782, validation loss: 0.1022
2024-05-24 20:10:31 [INFO]: Epoch 161 - training loss: 9215.1053, validation loss: 0.1016
2024-05-24 20:10:31 [INFO]: Epoch 162 - training loss: 9216.9410, validation loss: 0.0999
2024-05-24 20:10:31 [INFO]: Epoch 163 - training loss: 9216.4415, validation loss: 0.1003
2024-05-24 20:10:31 [INFO]: Epoch 164 - training loss: 9216.4737, validation loss: 0.1007
2024-05-24 20:10:32 [INFO]: Epoch 165 - training loss: 9215.3714, validation loss: 0.0979
2024-05-24 20:10:32 [INFO]: Epoch 166 - training loss: 9214.4098, validation loss: 0.0993
2024-05-24 20:10:32 [INFO]: Epoch 167 - training loss: 9214.1572, validation loss: 0.1003
2024-05-24 20:10:32 [INFO]: Epoch 168 - training loss: 9214.4081, validation loss: 0.1007
2024-05-24 20:10:32 [INFO]: Epoch 169 - training loss: 9215.3591, validation loss: 0.0979
2024-05-24 20:10:32 [INFO]: Epoch 170 - training loss: 9218.4172, validation loss: 0.1008
2024-05-24 20:10:32 [INFO]: Epoch 171 - training loss: 9215.8336, validation loss: 0.1013
2024-05-24 20:10:32 [INFO]: Epoch 172 - training loss: 9213.1722, validation loss: 0.0989
2024-05-24 20:10:32 [INFO]: Epoch 173 - training loss: 9213.5963, validation loss: 0.0976
2024-05-24 20:10:32 [INFO]: Epoch 174 - training loss: 9213.8411, validation loss: 0.0974
2024-05-24 20:10:33 [INFO]: Epoch 175 - training loss: 9215.0538, validation loss: 0.0983
2024-05-24 20:10:33 [INFO]: Epoch 176 - training loss: 9212.7413, validation loss: 0.0975
2024-05-24 20:10:33 [INFO]: Epoch 177 - training loss: 9211.7117, validation loss: 0.0965
2024-05-24 20:10:33 [INFO]: Epoch 178 - training loss: 9213.8582, validation loss: 0.0974
2024-05-24 20:10:33 [INFO]: Epoch 179 - training loss: 9212.6373, validation loss: 0.0971
2024-05-24 20:10:33 [INFO]: Epoch 180 - training loss: 9212.2513, validation loss: 0.0971
2024-05-24 20:10:33 [INFO]: Epoch 181 - training loss: 9214.0735, validation loss: 0.0981
2024-05-24 20:10:33 [INFO]: Epoch 182 - training loss: 9212.5182, validation loss: 0.0952
2024-05-24 20:10:33 [INFO]: Epoch 183 - training loss: 9212.5417, validation loss: 0.0968
2024-05-24 20:10:34 [INFO]: Epoch 184 - training loss: 9212.5613, validation loss: 0.0983
2024-05-24 20:10:34 [INFO]: Epoch 185 - training loss: 9212.1280, validation loss: 0.0965
2024-05-24 20:10:34 [INFO]: Epoch 186 - training loss: 9211.3792, validation loss: 0.0959
2024-05-24 20:10:34 [INFO]: Epoch 187 - training loss: 9212.7360, validation loss: 0.0973
2024-05-24 20:10:34 [INFO]: Epoch 188 - training loss: 9212.0937, validation loss: 0.0952
2024-05-24 20:10:34 [INFO]: Epoch 189 - training loss: 9212.0124, validation loss: 0.0953
2024-05-24 20:10:34 [INFO]: Epoch 190 - training loss: 9212.2571, validation loss: 0.0955
2024-05-24 20:10:34 [INFO]: Epoch 191 - training loss: 9221.9443, validation loss: 0.0944
2024-05-24 20:10:34 [INFO]: Epoch 192 - training loss: 9213.7787, validation loss: 0.0951
2024-05-24 20:10:35 [INFO]: Epoch 193 - training loss: 9210.2996, validation loss: 0.0972
2024-05-24 20:10:35 [INFO]: Epoch 194 - training loss: 9213.3278, validation loss: 0.0937
2024-05-24 20:10:35 [INFO]: Epoch 195 - training loss: 9211.7745, validation loss: 0.0958
2024-05-24 20:10:35 [INFO]: Epoch 196 - training loss: 9211.3610, validation loss: 0.0936
2024-05-24 20:10:35 [INFO]: Epoch 197 - training loss: 9210.1050, validation loss: 0.0928
2024-05-24 20:10:35 [INFO]: Epoch 198 - training loss: 9210.8654, validation loss: 0.0939
2024-05-24 20:10:35 [INFO]: Epoch 199 - training loss: 9211.2414, validation loss: 0.0935
2024-05-24 20:10:35 [INFO]: Epoch 200 - training loss: 9211.1004, validation loss: 0.0948
2024-05-24 20:10:35 [INFO]: Epoch 201 - training loss: 9209.4420, validation loss: 0.0923
2024-05-24 20:10:36 [INFO]: Epoch 202 - training loss: 9208.8152, validation loss: 0.0941
2024-05-24 20:10:36 [INFO]: Epoch 203 - training loss: 9210.7779, validation loss: 0.0936
2024-05-24 20:10:36 [INFO]: Epoch 204 - training loss: 9212.7772, validation loss: 0.0919
2024-05-24 20:10:36 [INFO]: Epoch 205 - training loss: 9211.6315, validation loss: 0.0931
2024-05-24 20:10:36 [INFO]: Epoch 206 - training loss: 9211.0978, validation loss: 0.0922
2024-05-24 20:10:36 [INFO]: Epoch 207 - training loss: 9209.7286, validation loss: 0.0925
2024-05-24 20:10:36 [INFO]: Epoch 208 - training loss: 9210.8972, validation loss: 0.0923
2024-05-24 20:10:36 [INFO]: Epoch 209 - training loss: 9209.3156, validation loss: 0.0926
2024-05-24 20:10:36 [INFO]: Epoch 210 - training loss: 9210.4650, validation loss: 0.0934
2024-05-24 20:10:36 [INFO]: Epoch 211 - training loss: 9208.8131, validation loss: 0.0926
2024-05-24 20:10:37 [INFO]: Epoch 212 - training loss: 9209.0792, validation loss: 0.0912
2024-05-24 20:10:37 [INFO]: Epoch 213 - training loss: 9211.3480, validation loss: 0.0898
2024-05-24 20:10:37 [INFO]: Epoch 214 - training loss: 9208.5941, validation loss: 0.0901
2024-05-24 20:10:37 [INFO]: Epoch 215 - training loss: 9210.0208, validation loss: 0.0918
2024-05-24 20:10:37 [INFO]: Epoch 216 - training loss: 9209.8809, validation loss: 0.0911
2024-05-24 20:10:37 [INFO]: Epoch 217 - training loss: 9211.4384, validation loss: 0.0914
2024-05-24 20:10:37 [INFO]: Epoch 218 - training loss: 9208.8516, validation loss: 0.0916
2024-05-24 20:10:37 [INFO]: Epoch 219 - training loss: 9209.7569, validation loss: 0.0907
2024-05-24 20:10:37 [INFO]: Epoch 220 - training loss: 9208.6125, validation loss: 0.0927
2024-05-24 20:10:38 [INFO]: Epoch 221 - training loss: 9210.7806, validation loss: 0.0923
2024-05-24 20:10:38 [INFO]: Epoch 222 - training loss: 9208.2272, validation loss: 0.0899
2024-05-24 20:10:38 [INFO]: Epoch 223 - training loss: 9209.5390, validation loss: 0.0922
2024-05-24 20:10:38 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:10:38 [INFO]: Finished training. The best model is from epoch#213.
2024-05-24 20:10:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/GPVAE_ettm1/20240524_T201014/GPVAE.pypots
2024-05-24 20:10:38 [INFO]: GP-VAE on ETTm1: MAE=0.2875, MSE=0.1797
2024-05-24 20:10:38 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/GPVAE_ettm1/imputation.pkl
2024-05-24 20:10:38 [INFO]: Using the given device: cuda:0
2024-05-24 20:10:38 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T201038
2024-05-24 20:10:38 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T201038/tensorboard
2024-05-24 20:10:38 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 20:10:46 [INFO]: Epoch 001 - generator training loss: 0.4413, discriminator training loss: 0.5398, validation loss: 0.3744
2024-05-24 20:10:53 [INFO]: Epoch 002 - generator training loss: -0.0398, discriminator training loss: 0.4743, validation loss: 0.1511
2024-05-24 20:11:00 [INFO]: Epoch 003 - generator training loss: -0.1454, discriminator training loss: 0.4350, validation loss: 0.0780
2024-05-24 20:11:07 [INFO]: Epoch 004 - generator training loss: -0.1474, discriminator training loss: 0.3726, validation loss: 0.0562
2024-05-24 20:11:14 [INFO]: Epoch 005 - generator training loss: -0.1089, discriminator training loss: 0.2948, validation loss: 0.0472
2024-05-24 20:11:21 [INFO]: Epoch 006 - generator training loss: -0.0782, discriminator training loss: 0.2339, validation loss: 0.0420
2024-05-24 20:11:28 [INFO]: Epoch 007 - generator training loss: -0.0634, discriminator training loss: 0.2001, validation loss: 0.0389
2024-05-24 20:11:35 [INFO]: Epoch 008 - generator training loss: -0.0507, discriminator training loss: 0.1869, validation loss: 0.0396
2024-05-24 20:11:42 [INFO]: Epoch 009 - generator training loss: -0.0553, discriminator training loss: 0.1841, validation loss: 0.0371
2024-05-24 20:11:49 [INFO]: Epoch 010 - generator training loss: -0.0568, discriminator training loss: 0.1778, validation loss: 0.0361
2024-05-24 20:11:56 [INFO]: Epoch 011 - generator training loss: -0.0558, discriminator training loss: 0.1753, validation loss: 0.0361
2024-05-24 20:12:03 [INFO]: Epoch 012 - generator training loss: -0.0564, discriminator training loss: 0.1757, validation loss: 0.0351
2024-05-24 20:12:10 [INFO]: Epoch 013 - generator training loss: -0.0563, discriminator training loss: 0.1707, validation loss: 0.0344
2024-05-24 20:12:17 [INFO]: Epoch 014 - generator training loss: -0.0590, discriminator training loss: 0.1733, validation loss: 0.0344
2024-05-24 20:12:24 [INFO]: Epoch 015 - generator training loss: -0.0598, discriminator training loss: 0.1756, validation loss: 0.0346
2024-05-24 20:12:31 [INFO]: Epoch 016 - generator training loss: -0.0580, discriminator training loss: 0.1707, validation loss: 0.0334
2024-05-24 20:12:38 [INFO]: Epoch 017 - generator training loss: -0.0629, discriminator training loss: 0.1736, validation loss: 0.0339
2024-05-24 20:12:45 [INFO]: Epoch 018 - generator training loss: -0.0596, discriminator training loss: 0.1712, validation loss: 0.0332
2024-05-24 20:12:52 [INFO]: Epoch 019 - generator training loss: -0.0598, discriminator training loss: 0.1716, validation loss: 0.0326
2024-05-24 20:12:59 [INFO]: Epoch 020 - generator training loss: -0.0602, discriminator training loss: 0.1724, validation loss: 0.0318
2024-05-24 20:13:06 [INFO]: Epoch 021 - generator training loss: -0.0602, discriminator training loss: 0.1699, validation loss: 0.0333
2024-05-24 20:13:13 [INFO]: Epoch 022 - generator training loss: -0.0573, discriminator training loss: 0.1698, validation loss: 0.0328
2024-05-24 20:13:20 [INFO]: Epoch 023 - generator training loss: -0.0604, discriminator training loss: 0.1691, validation loss: 0.0325
2024-05-24 20:13:27 [INFO]: Epoch 024 - generator training loss: -0.0590, discriminator training loss: 0.1693, validation loss: 0.0325
2024-05-24 20:13:34 [INFO]: Epoch 025 - generator training loss: -0.0607, discriminator training loss: 0.1695, validation loss: 0.0315
2024-05-24 20:13:41 [INFO]: Epoch 026 - generator training loss: -0.0629, discriminator training loss: 0.1716, validation loss: 0.0313
2024-05-24 20:13:48 [INFO]: Epoch 027 - generator training loss: -0.0609, discriminator training loss: 0.1670, validation loss: 0.0333
2024-05-24 20:13:56 [INFO]: Epoch 028 - generator training loss: -0.0603, discriminator training loss: 0.1703, validation loss: 0.0315
2024-05-24 20:14:03 [INFO]: Epoch 029 - generator training loss: -0.0601, discriminator training loss: 0.1697, validation loss: 0.0322
2024-05-24 20:14:10 [INFO]: Epoch 030 - generator training loss: -0.0587, discriminator training loss: 0.1690, validation loss: 0.0316
2024-05-24 20:14:17 [INFO]: Epoch 031 - generator training loss: -0.0637, discriminator training loss: 0.1697, validation loss: 0.0319
2024-05-24 20:14:24 [INFO]: Epoch 032 - generator training loss: -0.0618, discriminator training loss: 0.1664, validation loss: 0.0302
2024-05-24 20:14:31 [INFO]: Epoch 033 - generator training loss: -0.0634, discriminator training loss: 0.1673, validation loss: 0.0303
2024-05-24 20:14:37 [INFO]: Epoch 034 - generator training loss: -0.0617, discriminator training loss: 0.1692, validation loss: 0.0303
2024-05-24 20:14:45 [INFO]: Epoch 035 - generator training loss: -0.0628, discriminator training loss: 0.1674, validation loss: 0.0288
2024-05-24 20:14:52 [INFO]: Epoch 036 - generator training loss: -0.0654, discriminator training loss: 0.1666, validation loss: 0.0296
2024-05-24 20:14:58 [INFO]: Epoch 037 - generator training loss: -0.0666, discriminator training loss: 0.1661, validation loss: 0.0282
2024-05-24 20:15:06 [INFO]: Epoch 038 - generator training loss: -0.0636, discriminator training loss: 0.1691, validation loss: 0.0295
2024-05-24 20:15:12 [INFO]: Epoch 039 - generator training loss: -0.0635, discriminator training loss: 0.1697, validation loss: 0.0289
2024-05-24 20:15:19 [INFO]: Epoch 040 - generator training loss: -0.0616, discriminator training loss: 0.1691, validation loss: 0.0291
2024-05-24 20:15:27 [INFO]: Epoch 041 - generator training loss: -0.0617, discriminator training loss: 0.1665, validation loss: 0.0283
2024-05-24 20:15:34 [INFO]: Epoch 042 - generator training loss: -0.0662, discriminator training loss: 0.1659, validation loss: 0.0281
2024-05-24 20:15:41 [INFO]: Epoch 043 - generator training loss: -0.0670, discriminator training loss: 0.1683, validation loss: 0.0282
2024-05-24 20:15:48 [INFO]: Epoch 044 - generator training loss: -0.0658, discriminator training loss: 0.1681, validation loss: 0.0278
2024-05-24 20:15:55 [INFO]: Epoch 045 - generator training loss: -0.0627, discriminator training loss: 0.1658, validation loss: 0.0276
2024-05-24 20:16:02 [INFO]: Epoch 046 - generator training loss: -0.0666, discriminator training loss: 0.1663, validation loss: 0.0275
2024-05-24 20:16:09 [INFO]: Epoch 047 - generator training loss: -0.0653, discriminator training loss: 0.1656, validation loss: 0.0273
2024-05-24 20:16:16 [INFO]: Epoch 048 - generator training loss: -0.0651, discriminator training loss: 0.1661, validation loss: 0.0270
2024-05-24 20:16:23 [INFO]: Epoch 049 - generator training loss: -0.0646, discriminator training loss: 0.1639, validation loss: 0.0262
2024-05-24 20:16:30 [INFO]: Epoch 050 - generator training loss: -0.0667, discriminator training loss: 0.1639, validation loss: 0.0265
2024-05-24 20:16:37 [INFO]: Epoch 051 - generator training loss: -0.0669, discriminator training loss: 0.1673, validation loss: 0.0259
2024-05-24 20:16:44 [INFO]: Epoch 052 - generator training loss: -0.0671, discriminator training loss: 0.1640, validation loss: 0.0256
2024-05-24 20:16:51 [INFO]: Epoch 053 - generator training loss: -0.0658, discriminator training loss: 0.1635, validation loss: 0.0266
2024-05-24 20:16:58 [INFO]: Epoch 054 - generator training loss: -0.0686, discriminator training loss: 0.1648, validation loss: 0.0253
2024-05-24 20:17:05 [INFO]: Epoch 055 - generator training loss: -0.0675, discriminator training loss: 0.1650, validation loss: 0.0259
2024-05-24 20:17:12 [INFO]: Epoch 056 - generator training loss: -0.0707, discriminator training loss: 0.1652, validation loss: 0.0251
2024-05-24 20:17:19 [INFO]: Epoch 057 - generator training loss: -0.0675, discriminator training loss: 0.1666, validation loss: 0.0265
2024-05-24 20:17:26 [INFO]: Epoch 058 - generator training loss: -0.0687, discriminator training loss: 0.1630, validation loss: 0.0256
2024-05-24 20:17:33 [INFO]: Epoch 059 - generator training loss: -0.0673, discriminator training loss: 0.1660, validation loss: 0.0250
2024-05-24 20:17:40 [INFO]: Epoch 060 - generator training loss: -0.0651, discriminator training loss: 0.1653, validation loss: 0.0258
2024-05-24 20:17:47 [INFO]: Epoch 061 - generator training loss: -0.0677, discriminator training loss: 0.1650, validation loss: 0.0247
2024-05-24 20:17:54 [INFO]: Epoch 062 - generator training loss: -0.0671, discriminator training loss: 0.1649, validation loss: 0.0246
2024-05-24 20:18:01 [INFO]: Epoch 063 - generator training loss: -0.0680, discriminator training loss: 0.1645, validation loss: 0.0255
2024-05-24 20:18:08 [INFO]: Epoch 064 - generator training loss: -0.0687, discriminator training loss: 0.1633, validation loss: 0.0254
2024-05-24 20:18:15 [INFO]: Epoch 065 - generator training loss: -0.0690, discriminator training loss: 0.1643, validation loss: 0.0247
2024-05-24 20:18:22 [INFO]: Epoch 066 - generator training loss: -0.0693, discriminator training loss: 0.1655, validation loss: 0.0247
2024-05-24 20:18:29 [INFO]: Epoch 067 - generator training loss: -0.0691, discriminator training loss: 0.1636, validation loss: 0.0244
2024-05-24 20:18:36 [INFO]: Epoch 068 - generator training loss: -0.0678, discriminator training loss: 0.1655, validation loss: 0.0251
2024-05-24 20:18:43 [INFO]: Epoch 069 - generator training loss: -0.0690, discriminator training loss: 0.1635, validation loss: 0.0245
2024-05-24 20:18:50 [INFO]: Epoch 070 - generator training loss: -0.0679, discriminator training loss: 0.1632, validation loss: 0.0245
2024-05-24 20:18:57 [INFO]: Epoch 071 - generator training loss: -0.0724, discriminator training loss: 0.1652, validation loss: 0.0250
2024-05-24 20:19:04 [INFO]: Epoch 072 - generator training loss: -0.0688, discriminator training loss: 0.1620, validation loss: 0.0242
2024-05-24 20:19:11 [INFO]: Epoch 073 - generator training loss: -0.0666, discriminator training loss: 0.1652, validation loss: 0.0248
2024-05-24 20:19:18 [INFO]: Epoch 074 - generator training loss: -0.0685, discriminator training loss: 0.1646, validation loss: 0.0238
2024-05-24 20:19:25 [INFO]: Epoch 075 - generator training loss: -0.0706, discriminator training loss: 0.1639, validation loss: 0.0249
2024-05-24 20:19:32 [INFO]: Epoch 076 - generator training loss: -0.0678, discriminator training loss: 0.1630, validation loss: 0.0246
2024-05-24 20:19:39 [INFO]: Epoch 077 - generator training loss: -0.0683, discriminator training loss: 0.1623, validation loss: 0.0241
2024-05-24 20:19:46 [INFO]: Epoch 078 - generator training loss: -0.0701, discriminator training loss: 0.1633, validation loss: 0.0250
2024-05-24 20:19:53 [INFO]: Epoch 079 - generator training loss: -0.0689, discriminator training loss: 0.1630, validation loss: 0.0250
2024-05-24 20:20:00 [INFO]: Epoch 080 - generator training loss: -0.0691, discriminator training loss: 0.1633, validation loss: 0.0250
2024-05-24 20:20:07 [INFO]: Epoch 081 - generator training loss: -0.0701, discriminator training loss: 0.1641, validation loss: 0.0244
2024-05-24 20:20:14 [INFO]: Epoch 082 - generator training loss: -0.0711, discriminator training loss: 0.1617, validation loss: 0.0249
2024-05-24 20:20:21 [INFO]: Epoch 083 - generator training loss: -0.0704, discriminator training loss: 0.1647, validation loss: 0.0236
2024-05-24 20:20:28 [INFO]: Epoch 084 - generator training loss: -0.0713, discriminator training loss: 0.1626, validation loss: 0.0246
2024-05-24 20:20:35 [INFO]: Epoch 085 - generator training loss: -0.0724, discriminator training loss: 0.1608, validation loss: 0.0242
2024-05-24 20:20:42 [INFO]: Epoch 086 - generator training loss: -0.0707, discriminator training loss: 0.1623, validation loss: 0.0244
2024-05-24 20:20:49 [INFO]: Epoch 087 - generator training loss: -0.0707, discriminator training loss: 0.1622, validation loss: 0.0239
2024-05-24 20:20:56 [INFO]: Epoch 088 - generator training loss: -0.0709, discriminator training loss: 0.1631, validation loss: 0.0241
2024-05-24 20:21:03 [INFO]: Epoch 089 - generator training loss: -0.0692, discriminator training loss: 0.1613, validation loss: 0.0242
2024-05-24 20:21:10 [INFO]: Epoch 090 - generator training loss: -0.0710, discriminator training loss: 0.1618, validation loss: 0.0247
2024-05-24 20:21:17 [INFO]: Epoch 091 - generator training loss: -0.0698, discriminator training loss: 0.1637, validation loss: 0.0237
2024-05-24 20:21:24 [INFO]: Epoch 092 - generator training loss: -0.0701, discriminator training loss: 0.1616, validation loss: 0.0239
2024-05-24 20:21:31 [INFO]: Epoch 093 - generator training loss: -0.0755, discriminator training loss: 0.1618, validation loss: 0.0244
2024-05-24 20:21:31 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:21:31 [INFO]: Finished training. The best model is from epoch#83.
2024-05-24 20:21:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/USGAN_ettm1/20240524_T201038/USGAN.pypots
2024-05-24 20:21:32 [INFO]: US-GAN on ETTm1: MAE=0.1461, MSE=0.0563
2024-05-24 20:21:32 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/USGAN_ettm1/imputation.pkl
2024-05-24 20:21:32 [INFO]: Using the given device: cuda:0
2024-05-24 20:21:32 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T202132
2024-05-24 20:21:32 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T202132/tensorboard
2024-05-24 20:21:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 20:21:38 [INFO]: Epoch 001 - training loss: 1.3389, validation loss: 0.3681
2024-05-24 20:21:42 [INFO]: Epoch 002 - training loss: 0.9381, validation loss: 0.1210
2024-05-24 20:21:47 [INFO]: Epoch 003 - training loss: 0.7299, validation loss: 0.0609
2024-05-24 20:21:51 [INFO]: Epoch 004 - training loss: 0.6465, validation loss: 0.0518
2024-05-24 20:21:56 [INFO]: Epoch 005 - training loss: 0.5959, validation loss: 0.0411
2024-05-24 20:22:01 [INFO]: Epoch 006 - training loss: 0.5655, validation loss: 0.0397
2024-05-24 20:22:05 [INFO]: Epoch 007 - training loss: 0.5391, validation loss: 0.0367
2024-05-24 20:22:10 [INFO]: Epoch 008 - training loss: 0.5013, validation loss: 0.0338
2024-05-24 20:22:14 [INFO]: Epoch 009 - training loss: 0.4880, validation loss: 0.0329
2024-05-24 20:22:19 [INFO]: Epoch 010 - training loss: 0.4796, validation loss: 0.0312
2024-05-24 20:22:24 [INFO]: Epoch 011 - training loss: 0.4539, validation loss: 0.0312
2024-05-24 20:22:28 [INFO]: Epoch 012 - training loss: 0.4360, validation loss: 0.0292
2024-05-24 20:22:33 [INFO]: Epoch 013 - training loss: 0.4291, validation loss: 0.0287
2024-05-24 20:22:37 [INFO]: Epoch 014 - training loss: 0.4268, validation loss: 0.0271
2024-05-24 20:22:42 [INFO]: Epoch 015 - training loss: 0.4154, validation loss: 0.0271
2024-05-24 20:22:47 [INFO]: Epoch 016 - training loss: 0.4137, validation loss: 0.0271
2024-05-24 20:22:51 [INFO]: Epoch 017 - training loss: 0.4110, validation loss: 0.0267
2024-05-24 20:22:56 [INFO]: Epoch 018 - training loss: 0.4087, validation loss: 0.0276
2024-05-24 20:23:01 [INFO]: Epoch 019 - training loss: 0.4054, validation loss: 0.0258
2024-05-24 20:23:05 [INFO]: Epoch 020 - training loss: 0.4043, validation loss: 0.0255
2024-05-24 20:23:10 [INFO]: Epoch 021 - training loss: 0.4020, validation loss: 0.0257
2024-05-24 20:23:14 [INFO]: Epoch 022 - training loss: 0.4060, validation loss: 0.0255
2024-05-24 20:23:19 [INFO]: Epoch 023 - training loss: 0.4104, validation loss: 0.0258
2024-05-24 20:23:24 [INFO]: Epoch 024 - training loss: 0.4052, validation loss: 0.0273
2024-05-24 20:23:28 [INFO]: Epoch 025 - training loss: 0.4292, validation loss: 0.0268
2024-05-24 20:23:33 [INFO]: Epoch 026 - training loss: 0.4145, validation loss: 0.0269
2024-05-24 20:23:37 [INFO]: Epoch 027 - training loss: 0.3975, validation loss: 0.0269
2024-05-24 20:23:42 [INFO]: Epoch 028 - training loss: 0.4034, validation loss: 0.0262
2024-05-24 20:23:47 [INFO]: Epoch 029 - training loss: 0.4007, validation loss: 0.0251
2024-05-24 20:23:51 [INFO]: Epoch 030 - training loss: 0.3991, validation loss: 0.0252
2024-05-24 20:23:56 [INFO]: Epoch 031 - training loss: 0.3973, validation loss: 0.0259
2024-05-24 20:24:01 [INFO]: Epoch 032 - training loss: 0.4019, validation loss: 0.0250
2024-05-24 20:24:05 [INFO]: Epoch 033 - training loss: 0.4062, validation loss: 0.0258
2024-05-24 20:24:10 [INFO]: Epoch 034 - training loss: 0.3970, validation loss: 0.0253
2024-05-24 20:24:14 [INFO]: Epoch 035 - training loss: 0.3925, validation loss: 0.0253
2024-05-24 20:24:19 [INFO]: Epoch 036 - training loss: 0.3928, validation loss: 0.0250
2024-05-24 20:24:23 [INFO]: Epoch 037 - training loss: 0.3917, validation loss: 0.0257
2024-05-24 20:24:28 [INFO]: Epoch 038 - training loss: 0.3921, validation loss: 0.0256
2024-05-24 20:24:33 [INFO]: Epoch 039 - training loss: 0.3993, validation loss: 0.0259
2024-05-24 20:24:37 [INFO]: Epoch 040 - training loss: 0.3980, validation loss: 0.0251
2024-05-24 20:24:42 [INFO]: Epoch 041 - training loss: 0.3928, validation loss: 0.0255
2024-05-24 20:24:46 [INFO]: Epoch 042 - training loss: 0.3960, validation loss: 0.0259
2024-05-24 20:24:51 [INFO]: Epoch 043 - training loss: 0.3979, validation loss: 0.0293
2024-05-24 20:24:56 [INFO]: Epoch 044 - training loss: 0.3985, validation loss: 0.0256
2024-05-24 20:25:00 [INFO]: Epoch 045 - training loss: 0.4053, validation loss: 0.0253
2024-05-24 20:25:05 [INFO]: Epoch 046 - training loss: 0.4015, validation loss: 0.0257
2024-05-24 20:25:05 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:25:05 [INFO]: Finished training. The best model is from epoch#36.
2024-05-24 20:25:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/BRITS_ettm1/20240524_T202132/BRITS.pypots
2024-05-24 20:25:06 [INFO]: BRITS on ETTm1: MAE=0.1390, MSE=0.0570
2024-05-24 20:25:06 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/BRITS_ettm1/imputation.pkl
2024-05-24 20:25:06 [INFO]: Using the given device: cuda:0
2024-05-24 20:25:06 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506
2024-05-24 20:25:06 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/tensorboard
2024-05-24 20:25:06 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 20:25:07 [INFO]: Epoch 001 - training loss: 1.3162, validation loss: 1.3566
2024-05-24 20:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch1_loss1.3565888106822968.pypots
2024-05-24 20:25:07 [INFO]: Epoch 002 - training loss: 0.9898, validation loss: 1.2250
2024-05-24 20:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch2_loss1.2250482141971588.pypots
2024-05-24 20:25:07 [INFO]: Epoch 003 - training loss: 0.9231, validation loss: 1.1336
2024-05-24 20:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch3_loss1.1335854828357697.pypots
2024-05-24 20:25:07 [INFO]: Epoch 004 - training loss: 0.8963, validation loss: 1.0855
2024-05-24 20:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch4_loss1.0855206549167633.pypots
2024-05-24 20:25:07 [INFO]: Epoch 005 - training loss: 0.8732, validation loss: 1.0602
2024-05-24 20:25:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch5_loss1.06020849943161.pypots
2024-05-24 20:25:08 [INFO]: Epoch 006 - training loss: 0.9069, validation loss: 1.0501
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch6_loss1.0501087754964828.pypots
2024-05-24 20:25:08 [INFO]: Epoch 007 - training loss: 0.8669, validation loss: 1.0394
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch7_loss1.039375513792038.pypots
2024-05-24 20:25:08 [INFO]: Epoch 008 - training loss: 0.8557, validation loss: 1.0360
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch8_loss1.0359933376312256.pypots
2024-05-24 20:25:08 [INFO]: Epoch 009 - training loss: 0.8344, validation loss: 1.0307
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch9_loss1.0306954085826874.pypots
2024-05-24 20:25:08 [INFO]: Epoch 010 - training loss: 0.8266, validation loss: 1.0235
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch10_loss1.0234608501195908.pypots
2024-05-24 20:25:08 [INFO]: Epoch 011 - training loss: 0.8462, validation loss: 1.0176
2024-05-24 20:25:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch11_loss1.0175990164279938.pypots
2024-05-24 20:25:09 [INFO]: Epoch 012 - training loss: 0.8396, validation loss: 1.0163
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch12_loss1.0162810534238815.pypots
2024-05-24 20:25:09 [INFO]: Epoch 013 - training loss: 0.8125, validation loss: 1.0095
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch13_loss1.0094559490680695.pypots
2024-05-24 20:25:09 [INFO]: Epoch 014 - training loss: 0.8083, validation loss: 1.0065
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch14_loss1.0064617693424225.pypots
2024-05-24 20:25:09 [INFO]: Epoch 015 - training loss: 0.7924, validation loss: 1.0057
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch15_loss1.0056852102279663.pypots
2024-05-24 20:25:09 [INFO]: Epoch 016 - training loss: 0.7927, validation loss: 1.0006
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch16_loss1.000649943947792.pypots
2024-05-24 20:25:09 [INFO]: Epoch 017 - training loss: 0.7840, validation loss: 0.9949
2024-05-24 20:25:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch17_loss0.9949043393135071.pypots
2024-05-24 20:25:10 [INFO]: Epoch 018 - training loss: 0.7930, validation loss: 0.9898
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch18_loss0.9897571206092834.pypots
2024-05-24 20:25:10 [INFO]: Epoch 019 - training loss: 0.7983, validation loss: 0.9882
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch19_loss0.988161027431488.pypots
2024-05-24 20:25:10 [INFO]: Epoch 020 - training loss: 0.7848, validation loss: 0.9810
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch20_loss0.9809845834970474.pypots
2024-05-24 20:25:10 [INFO]: Epoch 021 - training loss: 0.7778, validation loss: 0.9767
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch21_loss0.9766523241996765.pypots
2024-05-24 20:25:10 [INFO]: Epoch 022 - training loss: 0.7931, validation loss: 0.9708
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch22_loss0.9707958400249481.pypots
2024-05-24 20:25:10 [INFO]: Epoch 023 - training loss: 0.7804, validation loss: 0.9660
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch23_loss0.9659683704376221.pypots
2024-05-24 20:25:10 [INFO]: Epoch 024 - training loss: 0.7888, validation loss: 0.9602
2024-05-24 20:25:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch24_loss0.9601528346538544.pypots
2024-05-24 20:25:11 [INFO]: Epoch 025 - training loss: 0.7819, validation loss: 0.9589
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch25_loss0.9588592201471329.pypots
2024-05-24 20:25:11 [INFO]: Epoch 026 - training loss: 0.7490, validation loss: 0.9535
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch26_loss0.9535053372383118.pypots
2024-05-24 20:25:11 [INFO]: Epoch 027 - training loss: 0.7754, validation loss: 0.9484
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch27_loss0.948384702205658.pypots
2024-05-24 20:25:11 [INFO]: Epoch 028 - training loss: 0.7778, validation loss: 0.9436
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch28_loss0.9435620754957199.pypots
2024-05-24 20:25:11 [INFO]: Epoch 029 - training loss: 0.7522, validation loss: 0.9387
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch29_loss0.938738688826561.pypots
2024-05-24 20:25:11 [INFO]: Epoch 030 - training loss: 0.7667, validation loss: 0.9387
2024-05-24 20:25:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch30_loss0.9386877566576004.pypots
2024-05-24 20:25:12 [INFO]: Epoch 031 - training loss: 0.7522, validation loss: 0.9366
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch31_loss0.9365625083446503.pypots
2024-05-24 20:25:12 [INFO]: Epoch 032 - training loss: 0.7501, validation loss: 0.9337
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch32_loss0.9337495714426041.pypots
2024-05-24 20:25:12 [INFO]: Epoch 033 - training loss: 0.7402, validation loss: 0.9314
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch33_loss0.9314402192831039.pypots
2024-05-24 20:25:12 [INFO]: Epoch 034 - training loss: 0.7619, validation loss: 0.9266
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch34_loss0.9265727549791336.pypots
2024-05-24 20:25:12 [INFO]: Epoch 035 - training loss: 0.7513, validation loss: 0.9235
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch35_loss0.9235136210918427.pypots
2024-05-24 20:25:12 [INFO]: Epoch 036 - training loss: 0.7579, validation loss: 0.9256
2024-05-24 20:25:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch36_loss0.9255812019109726.pypots
2024-05-24 20:25:13 [INFO]: Epoch 037 - training loss: 0.7311, validation loss: 0.9215
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch37_loss0.9214720129966736.pypots
2024-05-24 20:25:13 [INFO]: Epoch 038 - training loss: 0.7425, validation loss: 0.9187
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch38_loss0.91870978474617.pypots
2024-05-24 20:25:13 [INFO]: Epoch 039 - training loss: 0.7424, validation loss: 0.9183
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch39_loss0.9183028340339661.pypots
2024-05-24 20:25:13 [INFO]: Epoch 040 - training loss: 0.7397, validation loss: 0.9164
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch40_loss0.9164065718650818.pypots
2024-05-24 20:25:13 [INFO]: Epoch 041 - training loss: 0.7569, validation loss: 0.9145
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch41_loss0.914494201540947.pypots
2024-05-24 20:25:13 [INFO]: Epoch 042 - training loss: 0.7440, validation loss: 0.9144
2024-05-24 20:25:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch42_loss0.9143669009208679.pypots
2024-05-24 20:25:14 [INFO]: Epoch 043 - training loss: 0.7419, validation loss: 0.9114
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch43_loss0.9114294052124023.pypots
2024-05-24 20:25:14 [INFO]: Epoch 044 - training loss: 0.7423, validation loss: 0.9096
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch44_loss0.9096481800079346.pypots
2024-05-24 20:25:14 [INFO]: Epoch 045 - training loss: 0.7924, validation loss: 0.9106
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch45_loss0.9105789363384247.pypots
2024-05-24 20:25:14 [INFO]: Epoch 046 - training loss: 0.7631, validation loss: 0.9125
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch46_loss0.9124718308448792.pypots
2024-05-24 20:25:14 [INFO]: Epoch 047 - training loss: 0.7285, validation loss: 0.9097
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch47_loss0.9096918851137161.pypots
2024-05-24 20:25:14 [INFO]: Epoch 048 - training loss: 0.7529, validation loss: 0.9071
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch48_loss0.9070943742990494.pypots
2024-05-24 20:25:14 [INFO]: Epoch 049 - training loss: 0.7535, validation loss: 0.9062
2024-05-24 20:25:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch49_loss0.9062205404043198.pypots
2024-05-24 20:25:15 [INFO]: Epoch 050 - training loss: 0.7353, validation loss: 0.9031
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch50_loss0.9031481444835663.pypots
2024-05-24 20:25:15 [INFO]: Epoch 051 - training loss: 0.7263, validation loss: 0.9048
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch51_loss0.9047978073358536.pypots
2024-05-24 20:25:15 [INFO]: Epoch 052 - training loss: 0.7560, validation loss: 0.9025
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch52_loss0.9025368094444275.pypots
2024-05-24 20:25:15 [INFO]: Epoch 053 - training loss: 0.7407, validation loss: 0.9027
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch53_loss0.9027463793754578.pypots
2024-05-24 20:25:15 [INFO]: Epoch 054 - training loss: 0.7412, validation loss: 0.9004
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch54_loss0.9003558456897736.pypots
2024-05-24 20:25:15 [INFO]: Epoch 055 - training loss: 0.7313, validation loss: 0.9023
2024-05-24 20:25:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch55_loss0.9022643566131592.pypots
2024-05-24 20:25:16 [INFO]: Epoch 056 - training loss: 0.7346, validation loss: 0.9038
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch56_loss0.9037677943706512.pypots
2024-05-24 20:25:16 [INFO]: Epoch 057 - training loss: 0.7389, validation loss: 0.9003
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch57_loss0.9002749919891357.pypots
2024-05-24 20:25:16 [INFO]: Epoch 058 - training loss: 0.7563, validation loss: 0.9020
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch58_loss0.9019552767276764.pypots
2024-05-24 20:25:16 [INFO]: Epoch 059 - training loss: 0.7257, validation loss: 0.8936
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch59_loss0.8935946375131607.pypots
2024-05-24 20:25:16 [INFO]: Epoch 060 - training loss: 0.7225, validation loss: 0.8985
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch60_loss0.8984874337911606.pypots
2024-05-24 20:25:16 [INFO]: Epoch 061 - training loss: 0.7308, validation loss: 0.8983
2024-05-24 20:25:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch61_loss0.8983045667409897.pypots
2024-05-24 20:25:17 [INFO]: Epoch 062 - training loss: 0.7119, validation loss: 0.8985
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch62_loss0.8985012322664261.pypots
2024-05-24 20:25:17 [INFO]: Epoch 063 - training loss: 0.7929, validation loss: 0.8977
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch63_loss0.8976956009864807.pypots
2024-05-24 20:25:17 [INFO]: Epoch 064 - training loss: 0.7326, validation loss: 0.8934
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch64_loss0.893375352025032.pypots
2024-05-24 20:25:17 [INFO]: Epoch 065 - training loss: 0.7250, validation loss: 0.8955
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch65_loss0.8954991102218628.pypots
2024-05-24 20:25:17 [INFO]: Epoch 066 - training loss: 0.7297, validation loss: 0.8895
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch66_loss0.8895308822393417.pypots
2024-05-24 20:25:17 [INFO]: Epoch 067 - training loss: 0.7284, validation loss: 0.8914
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch67_loss0.8914105445146561.pypots
2024-05-24 20:25:17 [INFO]: Epoch 068 - training loss: 0.7327, validation loss: 0.8892
2024-05-24 20:25:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch68_loss0.8892060816287994.pypots
2024-05-24 20:25:18 [INFO]: Epoch 069 - training loss: 0.7485, validation loss: 0.8898
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch69_loss0.8898080885410309.pypots
2024-05-24 20:25:18 [INFO]: Epoch 070 - training loss: 0.7462, validation loss: 0.8874
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch70_loss0.8874065428972244.pypots
2024-05-24 20:25:18 [INFO]: Epoch 071 - training loss: 0.7134, validation loss: 0.8871
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch71_loss0.8871151655912399.pypots
2024-05-24 20:25:18 [INFO]: Epoch 072 - training loss: 0.7176, validation loss: 0.8890
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch72_loss0.8890224695205688.pypots
2024-05-24 20:25:18 [INFO]: Epoch 073 - training loss: 0.7435, validation loss: 0.8911
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch73_loss0.8911343812942505.pypots
2024-05-24 20:25:18 [INFO]: Epoch 074 - training loss: 0.7192, validation loss: 0.8834
2024-05-24 20:25:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch74_loss0.8833513557910919.pypots
2024-05-24 20:25:19 [INFO]: Epoch 075 - training loss: 0.7258, validation loss: 0.8855
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch75_loss0.885490894317627.pypots
2024-05-24 20:25:19 [INFO]: Epoch 076 - training loss: 0.7291, validation loss: 0.8857
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch76_loss0.8856936544179916.pypots
2024-05-24 20:25:19 [INFO]: Epoch 077 - training loss: 0.7374, validation loss: 0.8832
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch77_loss0.8832036107778549.pypots
2024-05-24 20:25:19 [INFO]: Epoch 078 - training loss: 0.7373, validation loss: 0.8809
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch78_loss0.880923792719841.pypots
2024-05-24 20:25:19 [INFO]: Epoch 079 - training loss: 0.7404, validation loss: 0.8826
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch79_loss0.8826064467430115.pypots
2024-05-24 20:25:19 [INFO]: Epoch 080 - training loss: 0.7386, validation loss: 0.8821
2024-05-24 20:25:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch80_loss0.8821218013763428.pypots
2024-05-24 20:25:20 [INFO]: Epoch 081 - training loss: 0.7430, validation loss: 0.8819
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch81_loss0.8818776458501816.pypots
2024-05-24 20:25:20 [INFO]: Epoch 082 - training loss: 0.7253, validation loss: 0.8805
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch82_loss0.880508080124855.pypots
2024-05-24 20:25:20 [INFO]: Epoch 083 - training loss: 0.7741, validation loss: 0.8793
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch83_loss0.8793091177940369.pypots
2024-05-24 20:25:20 [INFO]: Epoch 084 - training loss: 0.7407, validation loss: 0.8743
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch84_loss0.8742950856685638.pypots
2024-05-24 20:25:20 [INFO]: Epoch 085 - training loss: 0.7296, validation loss: 0.8796
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch85_loss0.8795837610960007.pypots
2024-05-24 20:25:20 [INFO]: Epoch 086 - training loss: 0.7243, validation loss: 0.8769
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch86_loss0.8769058436155319.pypots
2024-05-24 20:25:20 [INFO]: Epoch 087 - training loss: 0.7184, validation loss: 0.8761
2024-05-24 20:25:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch87_loss0.8761177062988281.pypots
2024-05-24 20:25:21 [INFO]: Epoch 088 - training loss: 0.7273, validation loss: 0.8737
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch88_loss0.8737069368362427.pypots
2024-05-24 20:25:21 [INFO]: Epoch 089 - training loss: 0.7302, validation loss: 0.8734
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch89_loss0.8733906000852585.pypots
2024-05-24 20:25:21 [INFO]: Epoch 090 - training loss: 0.7347, validation loss: 0.8743
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch90_loss0.8742667436599731.pypots
2024-05-24 20:25:21 [INFO]: Epoch 091 - training loss: 0.7546, validation loss: 0.8749
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch91_loss0.8749492466449738.pypots
2024-05-24 20:25:21 [INFO]: Epoch 092 - training loss: 0.7750, validation loss: 0.8706
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch92_loss0.8705783039331436.pypots
2024-05-24 20:25:21 [INFO]: Epoch 093 - training loss: 0.7600, validation loss: 0.8729
2024-05-24 20:25:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch93_loss0.8729298263788223.pypots
2024-05-24 20:25:22 [INFO]: Epoch 094 - training loss: 0.7294, validation loss: 0.8704
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch94_loss0.8703892976045609.pypots
2024-05-24 20:25:22 [INFO]: Epoch 095 - training loss: 0.7286, validation loss: 0.8661
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch95_loss0.8660591244697571.pypots
2024-05-24 20:25:22 [INFO]: Epoch 096 - training loss: 0.7194, validation loss: 0.8710
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch96_loss0.8710226267576218.pypots
2024-05-24 20:25:22 [INFO]: Epoch 097 - training loss: 0.7394, validation loss: 0.8680
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch97_loss0.8679622262716293.pypots
2024-05-24 20:25:22 [INFO]: Epoch 098 - training loss: 0.7382, validation loss: 0.8676
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch98_loss0.867571696639061.pypots
2024-05-24 20:25:22 [INFO]: Epoch 099 - training loss: 0.7388, validation loss: 0.8645
2024-05-24 20:25:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch99_loss0.8645129799842834.pypots
2024-05-24 20:25:23 [INFO]: Epoch 100 - training loss: 0.7252, validation loss: 0.8663
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch100_loss0.8662990033626556.pypots
2024-05-24 20:25:23 [INFO]: Epoch 101 - training loss: 0.7102, validation loss: 0.8658
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch101_loss0.865812748670578.pypots
2024-05-24 20:25:23 [INFO]: Epoch 102 - training loss: 0.7168, validation loss: 0.8634
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch102_loss0.8633562624454498.pypots
2024-05-24 20:25:23 [INFO]: Epoch 103 - training loss: 0.7463, validation loss: 0.8669
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch103_loss0.8668610751628876.pypots
2024-05-24 20:25:23 [INFO]: Epoch 104 - training loss: 0.7180, validation loss: 0.8589
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch104_loss0.8589333295822144.pypots
2024-05-24 20:25:23 [INFO]: Epoch 105 - training loss: 0.7249, validation loss: 0.8641
2024-05-24 20:25:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch105_loss0.8641413748264313.pypots
2024-05-24 20:25:24 [INFO]: Epoch 106 - training loss: 0.7244, validation loss: 0.8633
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch106_loss0.86325803399086.pypots
2024-05-24 20:25:24 [INFO]: Epoch 107 - training loss: 0.7226, validation loss: 0.8599
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch107_loss0.8599367439746857.pypots
2024-05-24 20:25:24 [INFO]: Epoch 108 - training loss: 0.7103, validation loss: 0.8630
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch108_loss0.8629869520664215.pypots
2024-05-24 20:25:24 [INFO]: Epoch 109 - training loss: 0.7180, validation loss: 0.8622
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch109_loss0.8622482120990753.pypots
2024-05-24 20:25:24 [INFO]: Epoch 110 - training loss: 0.7300, validation loss: 0.8594
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch110_loss0.859439954161644.pypots
2024-05-24 20:25:24 [INFO]: Epoch 111 - training loss: 0.7226, validation loss: 0.8601
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch111_loss0.8600733131170273.pypots
2024-05-24 20:25:24 [INFO]: Epoch 112 - training loss: 0.7227, validation loss: 0.8560
2024-05-24 20:25:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch112_loss0.8559657335281372.pypots
2024-05-24 20:25:25 [INFO]: Epoch 113 - training loss: 0.7141, validation loss: 0.8534
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch113_loss0.8533895313739777.pypots
2024-05-24 20:25:25 [INFO]: Epoch 114 - training loss: 0.7575, validation loss: 0.8571
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch114_loss0.857064813375473.pypots
2024-05-24 20:25:25 [INFO]: Epoch 115 - training loss: 0.7081, validation loss: 0.8550
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch115_loss0.8550136238336563.pypots
2024-05-24 20:25:25 [INFO]: Epoch 116 - training loss: 0.7321, validation loss: 0.8538
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch116_loss0.8538396954536438.pypots
2024-05-24 20:25:25 [INFO]: Epoch 117 - training loss: 0.7140, validation loss: 0.8564
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch117_loss0.8563950061798096.pypots
2024-05-24 20:25:25 [INFO]: Epoch 118 - training loss: 0.7007, validation loss: 0.8512
2024-05-24 20:25:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch118_loss0.851193979382515.pypots
2024-05-24 20:25:26 [INFO]: Epoch 119 - training loss: 0.7024, validation loss: 0.8542
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch119_loss0.8542430698871613.pypots
2024-05-24 20:25:26 [INFO]: Epoch 120 - training loss: 0.7169, validation loss: 0.8540
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch120_loss0.8540137559175491.pypots
2024-05-24 20:25:26 [INFO]: Epoch 121 - training loss: 0.7329, validation loss: 0.8546
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch121_loss0.8546316176652908.pypots
2024-05-24 20:25:26 [INFO]: Epoch 122 - training loss: 0.7271, validation loss: 0.8494
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch122_loss0.8493792414665222.pypots
2024-05-24 20:25:26 [INFO]: Epoch 123 - training loss: 0.7172, validation loss: 0.8535
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch123_loss0.8534520119428635.pypots
2024-05-24 20:25:26 [INFO]: Epoch 124 - training loss: 0.7212, validation loss: 0.8491
2024-05-24 20:25:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch124_loss0.8491267263889313.pypots
2024-05-24 20:25:27 [INFO]: Epoch 125 - training loss: 0.7222, validation loss: 0.8463
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch125_loss0.8463460057973862.pypots
2024-05-24 20:25:27 [INFO]: Epoch 126 - training loss: 0.7295, validation loss: 0.8481
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch126_loss0.848131075501442.pypots
2024-05-24 20:25:27 [INFO]: Epoch 127 - training loss: 0.7151, validation loss: 0.8468
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch127_loss0.8468025177717209.pypots
2024-05-24 20:25:27 [INFO]: Epoch 128 - training loss: 0.6990, validation loss: 0.8473
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch128_loss0.8473055064678192.pypots
2024-05-24 20:25:27 [INFO]: Epoch 129 - training loss: 0.7023, validation loss: 0.8456
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch129_loss0.8455891013145447.pypots
2024-05-24 20:25:27 [INFO]: Epoch 130 - training loss: 0.7054, validation loss: 0.8430
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch130_loss0.8430184572935104.pypots
2024-05-24 20:25:27 [INFO]: Epoch 131 - training loss: 0.7285, validation loss: 0.8428
2024-05-24 20:25:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch131_loss0.8427512347698212.pypots
2024-05-24 20:25:28 [INFO]: Epoch 132 - training loss: 0.7049, validation loss: 0.8429
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch132_loss0.8428972363471985.pypots
2024-05-24 20:25:28 [INFO]: Epoch 133 - training loss: 0.7236, validation loss: 0.8416
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch133_loss0.8415596932172775.pypots
2024-05-24 20:25:28 [INFO]: Epoch 134 - training loss: 0.7062, validation loss: 0.8392
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch134_loss0.8392205685377121.pypots
2024-05-24 20:25:28 [INFO]: Epoch 135 - training loss: 0.7205, validation loss: 0.8427
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch135_loss0.8427298218011856.pypots
2024-05-24 20:25:28 [INFO]: Epoch 136 - training loss: 0.7245, validation loss: 0.8414
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch136_loss0.8413798213005066.pypots
2024-05-24 20:25:28 [INFO]: Epoch 137 - training loss: 0.7102, validation loss: 0.8427
2024-05-24 20:25:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch137_loss0.8426519930362701.pypots
2024-05-24 20:25:29 [INFO]: Epoch 138 - training loss: 0.7085, validation loss: 0.8384
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch138_loss0.8384315073490143.pypots
2024-05-24 20:25:29 [INFO]: Epoch 139 - training loss: 0.7063, validation loss: 0.8419
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch139_loss0.8418947160243988.pypots
2024-05-24 20:25:29 [INFO]: Epoch 140 - training loss: 0.7312, validation loss: 0.8418
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch140_loss0.8417616933584213.pypots
2024-05-24 20:25:29 [INFO]: Epoch 141 - training loss: 0.7408, validation loss: 0.8411
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch141_loss0.8411428928375244.pypots
2024-05-24 20:25:29 [INFO]: Epoch 142 - training loss: 0.7161, validation loss: 0.8382
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch142_loss0.8382468968629837.pypots
2024-05-24 20:25:29 [INFO]: Epoch 143 - training loss: 0.7398, validation loss: 0.8372
2024-05-24 20:25:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch143_loss0.8372271209955215.pypots
2024-05-24 20:25:30 [INFO]: Epoch 144 - training loss: 0.7111, validation loss: 0.8361
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch144_loss0.8361444920301437.pypots
2024-05-24 20:25:30 [INFO]: Epoch 145 - training loss: 0.7185, validation loss: 0.8366
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch145_loss0.836642786860466.pypots
2024-05-24 20:25:30 [INFO]: Epoch 146 - training loss: 0.7191, validation loss: 0.8384
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch146_loss0.8384452313184738.pypots
2024-05-24 20:25:30 [INFO]: Epoch 147 - training loss: 0.7161, validation loss: 0.8355
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch147_loss0.8355169296264648.pypots
2024-05-24 20:25:30 [INFO]: Epoch 148 - training loss: 0.6981, validation loss: 0.8340
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch148_loss0.8339651674032211.pypots
2024-05-24 20:25:30 [INFO]: Epoch 149 - training loss: 0.7052, validation loss: 0.8338
2024-05-24 20:25:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch149_loss0.8337826877832413.pypots
2024-05-24 20:25:31 [INFO]: Epoch 150 - training loss: 0.7162, validation loss: 0.8372
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch150_loss0.8371994644403458.pypots
2024-05-24 20:25:31 [INFO]: Epoch 151 - training loss: 0.7252, validation loss: 0.8309
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch151_loss0.8308779001235962.pypots
2024-05-24 20:25:31 [INFO]: Epoch 152 - training loss: 0.7105, validation loss: 0.8353
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch152_loss0.8352837264537811.pypots
2024-05-24 20:25:31 [INFO]: Epoch 153 - training loss: 0.7259, validation loss: 0.8327
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch153_loss0.8326925486326218.pypots
2024-05-24 20:25:31 [INFO]: Epoch 154 - training loss: 0.7251, validation loss: 0.8291
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch154_loss0.8290871679782867.pypots
2024-05-24 20:25:31 [INFO]: Epoch 155 - training loss: 0.7141, validation loss: 0.8304
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch155_loss0.8303541243076324.pypots
2024-05-24 20:25:31 [INFO]: Epoch 156 - training loss: 0.7144, validation loss: 0.8300
2024-05-24 20:25:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch156_loss0.8299868106842041.pypots
2024-05-24 20:25:32 [INFO]: Epoch 157 - training loss: 0.7243, validation loss: 0.8279
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch157_loss0.827934592962265.pypots
2024-05-24 20:25:32 [INFO]: Epoch 158 - training loss: 0.7405, validation loss: 0.8284
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch158_loss0.8283734321594238.pypots
2024-05-24 20:25:32 [INFO]: Epoch 159 - training loss: 0.7170, validation loss: 0.8288
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch159_loss0.8287793099880219.pypots
2024-05-24 20:25:32 [INFO]: Epoch 160 - training loss: 0.7326, validation loss: 0.8290
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch160_loss0.8290146589279175.pypots
2024-05-24 20:25:32 [INFO]: Epoch 161 - training loss: 0.7331, validation loss: 0.8265
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch161_loss0.8265257030725479.pypots
2024-05-24 20:25:32 [INFO]: Epoch 162 - training loss: 0.7298, validation loss: 0.8248
2024-05-24 20:25:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch162_loss0.8247893154621124.pypots
2024-05-24 20:25:33 [INFO]: Epoch 163 - training loss: 0.7187, validation loss: 0.8269
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch163_loss0.8268801867961884.pypots
2024-05-24 20:25:33 [INFO]: Epoch 164 - training loss: 0.7243, validation loss: 0.8286
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch164_loss0.8285718709230423.pypots
2024-05-24 20:25:33 [INFO]: Epoch 165 - training loss: 0.7244, validation loss: 0.8269
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch165_loss0.8269023299217224.pypots
2024-05-24 20:25:33 [INFO]: Epoch 166 - training loss: 0.7258, validation loss: 0.8250
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch166_loss0.8249790966510773.pypots
2024-05-24 20:25:33 [INFO]: Epoch 167 - training loss: 0.7152, validation loss: 0.8256
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch167_loss0.825648695230484.pypots
2024-05-24 20:25:33 [INFO]: Epoch 168 - training loss: 0.7315, validation loss: 0.8263
2024-05-24 20:25:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch168_loss0.8263020068407059.pypots
2024-05-24 20:25:34 [INFO]: Epoch 169 - training loss: 0.7231, validation loss: 0.8263
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch169_loss0.8262738883495331.pypots
2024-05-24 20:25:34 [INFO]: Epoch 170 - training loss: 0.7242, validation loss: 0.8243
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch170_loss0.8243355005979538.pypots
2024-05-24 20:25:34 [INFO]: Epoch 171 - training loss: 0.7149, validation loss: 0.8240
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch171_loss0.8239917457103729.pypots
2024-05-24 20:25:34 [INFO]: Epoch 172 - training loss: 0.7248, validation loss: 0.8264
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch172_loss0.8264467120170593.pypots
2024-05-24 20:25:34 [INFO]: Epoch 173 - training loss: 0.7070, validation loss: 0.8229
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch173_loss0.8229336738586426.pypots
2024-05-24 20:25:34 [INFO]: Epoch 174 - training loss: 0.7249, validation loss: 0.8229
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch174_loss0.8229291886091232.pypots
2024-05-24 20:25:34 [INFO]: Epoch 175 - training loss: 0.7335, validation loss: 0.8237
2024-05-24 20:25:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch175_loss0.8237236738204956.pypots
2024-05-24 20:25:35 [INFO]: Epoch 176 - training loss: 0.6909, validation loss: 0.8223
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch176_loss0.8222546130418777.pypots
2024-05-24 20:25:35 [INFO]: Epoch 177 - training loss: 0.7137, validation loss: 0.8201
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch177_loss0.8201006203889847.pypots
2024-05-24 20:25:35 [INFO]: Epoch 178 - training loss: 0.6986, validation loss: 0.8231
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch178_loss0.8231354504823685.pypots
2024-05-24 20:25:35 [INFO]: Epoch 179 - training loss: 0.7307, validation loss: 0.8256
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch179_loss0.8256300985813141.pypots
2024-05-24 20:25:35 [INFO]: Epoch 180 - training loss: 0.7261, validation loss: 0.8210
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch180_loss0.8210232257843018.pypots
2024-05-24 20:25:35 [INFO]: Epoch 181 - training loss: 0.7195, validation loss: 0.8198
2024-05-24 20:25:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch181_loss0.8198264837265015.pypots
2024-05-24 20:25:36 [INFO]: Epoch 182 - training loss: 0.7176, validation loss: 0.8227
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch182_loss0.8227141201496124.pypots
2024-05-24 20:25:36 [INFO]: Epoch 183 - training loss: 0.7183, validation loss: 0.8204
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch183_loss0.8203868418931961.pypots
2024-05-24 20:25:36 [INFO]: Epoch 184 - training loss: 0.7142, validation loss: 0.8238
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch184_loss0.8238043636083603.pypots
2024-05-24 20:25:36 [INFO]: Epoch 185 - training loss: 0.7135, validation loss: 0.8217
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch185_loss0.8216766715049744.pypots
2024-05-24 20:25:36 [INFO]: Epoch 186 - training loss: 0.7444, validation loss: 0.8213
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch186_loss0.821253091096878.pypots
2024-05-24 20:25:36 [INFO]: Epoch 187 - training loss: 0.7111, validation loss: 0.8198
2024-05-24 20:25:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch187_loss0.8197629302740097.pypots
2024-05-24 20:25:37 [INFO]: Epoch 188 - training loss: 0.7143, validation loss: 0.8216
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch188_loss0.8216189444065094.pypots
2024-05-24 20:25:37 [INFO]: Epoch 189 - training loss: 0.7245, validation loss: 0.8185
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch189_loss0.8185158520936966.pypots
2024-05-24 20:25:37 [INFO]: Epoch 190 - training loss: 0.7189, validation loss: 0.8219
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch190_loss0.8218584805727005.pypots
2024-05-24 20:25:37 [INFO]: Epoch 191 - training loss: 0.7274, validation loss: 0.8184
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch191_loss0.8184095025062561.pypots
2024-05-24 20:25:37 [INFO]: Epoch 192 - training loss: 0.7013, validation loss: 0.8193
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch192_loss0.8193265944719315.pypots
2024-05-24 20:25:37 [INFO]: Epoch 193 - training loss: 0.7265, validation loss: 0.8187
2024-05-24 20:25:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch193_loss0.8187423646450043.pypots
2024-05-24 20:25:38 [INFO]: Epoch 194 - training loss: 0.7362, validation loss: 0.8190
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch194_loss0.8189992755651474.pypots
2024-05-24 20:25:38 [INFO]: Epoch 195 - training loss: 0.7149, validation loss: 0.8178
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch195_loss0.8178378194570541.pypots
2024-05-24 20:25:38 [INFO]: Epoch 196 - training loss: 0.7160, validation loss: 0.8172
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch196_loss0.8172154277563095.pypots
2024-05-24 20:25:38 [INFO]: Epoch 197 - training loss: 0.7038, validation loss: 0.8167
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch197_loss0.8167362809181213.pypots
2024-05-24 20:25:38 [INFO]: Epoch 198 - training loss: 0.7131, validation loss: 0.8189
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch198_loss0.8189479410648346.pypots
2024-05-24 20:25:38 [INFO]: Epoch 199 - training loss: 0.7102, validation loss: 0.8194
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch199_loss0.8193876147270203.pypots
2024-05-24 20:25:38 [INFO]: Epoch 200 - training loss: 0.7179, validation loss: 0.8182
2024-05-24 20:25:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch200_loss0.8182172179222107.pypots
2024-05-24 20:25:39 [INFO]: Epoch 201 - training loss: 0.7289, validation loss: 0.8165
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch201_loss0.8165108561515808.pypots
2024-05-24 20:25:39 [INFO]: Epoch 202 - training loss: 0.7002, validation loss: 0.8161
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch202_loss0.8160949200391769.pypots
2024-05-24 20:25:39 [INFO]: Epoch 203 - training loss: 0.7174, validation loss: 0.8214
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch203_loss0.821448802947998.pypots
2024-05-24 20:25:39 [INFO]: Epoch 204 - training loss: 0.7530, validation loss: 0.8159
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch204_loss0.8159108310937881.pypots
2024-05-24 20:25:39 [INFO]: Epoch 205 - training loss: 0.7231, validation loss: 0.8164
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch205_loss0.8164400458335876.pypots
2024-05-24 20:25:39 [INFO]: Epoch 206 - training loss: 0.7210, validation loss: 0.8157
2024-05-24 20:25:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch206_loss0.8156903237104416.pypots
2024-05-24 20:25:40 [INFO]: Epoch 207 - training loss: 0.7162, validation loss: 0.8163
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch207_loss0.8163148164749146.pypots
2024-05-24 20:25:40 [INFO]: Epoch 208 - training loss: 0.7166, validation loss: 0.8152
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch208_loss0.815175399184227.pypots
2024-05-24 20:25:40 [INFO]: Epoch 209 - training loss: 0.7195, validation loss: 0.8160
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch209_loss0.8160062581300735.pypots
2024-05-24 20:25:40 [INFO]: Epoch 210 - training loss: 0.7019, validation loss: 0.8157
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch210_loss0.8157438635826111.pypots
2024-05-24 20:25:40 [INFO]: Epoch 211 - training loss: 0.7184, validation loss: 0.8153
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch211_loss0.8152754157781601.pypots
2024-05-24 20:25:40 [INFO]: Epoch 212 - training loss: 0.7208, validation loss: 0.8160
2024-05-24 20:25:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch212_loss0.8159885555505753.pypots
2024-05-24 20:25:41 [INFO]: Epoch 213 - training loss: 0.7213, validation loss: 0.8157
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch213_loss0.815710186958313.pypots
2024-05-24 20:25:41 [INFO]: Epoch 214 - training loss: 0.7269, validation loss: 0.8152
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch214_loss0.8152204900979996.pypots
2024-05-24 20:25:41 [INFO]: Epoch 215 - training loss: 0.7057, validation loss: 0.8146
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch215_loss0.8145889788866043.pypots
2024-05-24 20:25:41 [INFO]: Epoch 216 - training loss: 0.7078, validation loss: 0.8125
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch216_loss0.8125451058149338.pypots
2024-05-24 20:25:41 [INFO]: Epoch 217 - training loss: 0.7163, validation loss: 0.8134
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch217_loss0.8133622258901596.pypots
2024-05-24 20:25:41 [INFO]: Epoch 218 - training loss: 0.7158, validation loss: 0.8138
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch218_loss0.8137996345758438.pypots
2024-05-24 20:25:41 [INFO]: Epoch 219 - training loss: 0.7275, validation loss: 0.8136
2024-05-24 20:25:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch219_loss0.8135933578014374.pypots
2024-05-24 20:25:42 [INFO]: Epoch 220 - training loss: 0.7162, validation loss: 0.8141
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch220_loss0.8140707314014435.pypots
2024-05-24 20:25:42 [INFO]: Epoch 221 - training loss: 0.7115, validation loss: 0.8151
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch221_loss0.8150553107261658.pypots
2024-05-24 20:25:42 [INFO]: Epoch 222 - training loss: 0.7002, validation loss: 0.8150
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch222_loss0.8150248527526855.pypots
2024-05-24 20:25:42 [INFO]: Epoch 223 - training loss: 0.7055, validation loss: 0.8129
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch223_loss0.8128754198551178.pypots
2024-05-24 20:25:42 [INFO]: Epoch 224 - training loss: 0.7084, validation loss: 0.8149
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch224_loss0.8149370104074478.pypots
2024-05-24 20:25:42 [INFO]: Epoch 225 - training loss: 0.7096, validation loss: 0.8130
2024-05-24 20:25:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch225_loss0.813036248087883.pypots
2024-05-24 20:25:43 [INFO]: Epoch 226 - training loss: 0.7070, validation loss: 0.8130
2024-05-24 20:25:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN_epoch226_loss0.8129736483097076.pypots
2024-05-24 20:25:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:25:43 [INFO]: Finished training. The best model is from epoch#216.
2024-05-24 20:25:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_2/MRNN_ettm1/20240524_T202506/MRNN.pypots
2024-05-24 20:25:43 [INFO]: MRNN on ETTm1: MAE=0.5758, MSE=0.9624
2024-05-24 20:25:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/MRNN_ettm1/imputation.pkl
2024-05-24 20:25:43 [INFO]: Using the given device: cpu
2024-05-24 20:25:43 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-24 20:25:43 [INFO]: Successfully created the given path "saved_results/round_2/LOCF_ettm1".
2024-05-24 20:25:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/LOCF_ettm1/imputation.pkl
2024-05-24 20:25:43 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-24 20:25:43 [INFO]: Successfully created the given path "saved_results/round_2/Median_ettm1".
2024-05-24 20:25:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Median_ettm1/imputation.pkl
2024-05-24 20:25:43 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-24 20:25:43 [INFO]: Successfully created the given path "saved_results/round_2/Mean_ettm1".
2024-05-24 20:25:43 [INFO]: Successfully saved to augmentation_premask_saved_results/round_2/Mean_ettm1/imputation.pkl
2024-05-24 20:25:43 [INFO]: Have set the random seed as 2026 for numpy and pytorch.
2024-05-24 20:25:43 [INFO]: Using the given device: cuda:0
2024-05-24 20:25:43 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T202543
2024-05-24 20:25:43 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T202543/tensorboard
2024-05-24 20:25:43 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 20:25:43 [INFO]: Epoch 001 - training loss: 1.1893, validation loss: 0.2981
2024-05-24 20:25:44 [INFO]: Epoch 002 - training loss: 0.8507, validation loss: 0.1896
2024-05-24 20:25:44 [INFO]: Epoch 003 - training loss: 0.7631, validation loss: 0.1174
2024-05-24 20:25:45 [INFO]: Epoch 004 - training loss: 0.6956, validation loss: 0.1112
2024-05-24 20:25:45 [INFO]: Epoch 005 - training loss: 0.6642, validation loss: 0.0922
2024-05-24 20:25:46 [INFO]: Epoch 006 - training loss: 0.6359, validation loss: 0.1017
2024-05-24 20:25:46 [INFO]: Epoch 007 - training loss: 0.6206, validation loss: 0.1064
2024-05-24 20:25:47 [INFO]: Epoch 008 - training loss: 0.6111, validation loss: 0.0681
2024-05-24 20:25:47 [INFO]: Epoch 009 - training loss: 0.5940, validation loss: 0.0700
2024-05-24 20:25:48 [INFO]: Epoch 010 - training loss: 0.5833, validation loss: 0.0639
2024-05-24 20:25:48 [INFO]: Epoch 011 - training loss: 0.5773, validation loss: 0.0617
2024-05-24 20:25:49 [INFO]: Epoch 012 - training loss: 0.5678, validation loss: 0.0554
2024-05-24 20:25:49 [INFO]: Epoch 013 - training loss: 0.5499, validation loss: 0.0508
2024-05-24 20:25:50 [INFO]: Epoch 014 - training loss: 0.5508, validation loss: 0.0552
2024-05-24 20:25:50 [INFO]: Epoch 015 - training loss: 0.5360, validation loss: 0.0687
2024-05-24 20:25:51 [INFO]: Epoch 016 - training loss: 0.5516, validation loss: 0.0551
2024-05-24 20:25:51 [INFO]: Epoch 017 - training loss: 0.5275, validation loss: 0.0458
2024-05-24 20:25:52 [INFO]: Epoch 018 - training loss: 0.5283, validation loss: 0.0570
2024-05-24 20:25:52 [INFO]: Epoch 019 - training loss: 0.5310, validation loss: 0.0458
2024-05-24 20:25:53 [INFO]: Epoch 020 - training loss: 0.5192, validation loss: 0.0533
2024-05-24 20:25:53 [INFO]: Epoch 021 - training loss: 0.4998, validation loss: 0.0456
2024-05-24 20:25:54 [INFO]: Epoch 022 - training loss: 0.4978, validation loss: 0.0402
2024-05-24 20:25:54 [INFO]: Epoch 023 - training loss: 0.4855, validation loss: 0.0438
2024-05-24 20:25:55 [INFO]: Epoch 024 - training loss: 0.4889, validation loss: 0.0724
2024-05-24 20:25:55 [INFO]: Epoch 025 - training loss: 0.5003, validation loss: 0.0555
2024-05-24 20:25:55 [INFO]: Epoch 026 - training loss: 0.4805, validation loss: 0.0436
2024-05-24 20:25:56 [INFO]: Epoch 027 - training loss: 0.4880, validation loss: 0.0432
2024-05-24 20:25:56 [INFO]: Epoch 028 - training loss: 0.4821, validation loss: 0.0648
2024-05-24 20:25:57 [INFO]: Epoch 029 - training loss: 0.4783, validation loss: 0.0444
2024-05-24 20:25:57 [INFO]: Epoch 030 - training loss: 0.4723, validation loss: 0.0418
2024-05-24 20:25:58 [INFO]: Epoch 031 - training loss: 0.4679, validation loss: 0.0505
2024-05-24 20:25:58 [INFO]: Epoch 032 - training loss: 0.4580, validation loss: 0.0397
2024-05-24 20:25:59 [INFO]: Epoch 033 - training loss: 0.4638, validation loss: 0.0442
2024-05-24 20:25:59 [INFO]: Epoch 034 - training loss: 0.4700, validation loss: 0.0418
2024-05-24 20:26:00 [INFO]: Epoch 035 - training loss: 0.4752, validation loss: 0.0471
2024-05-24 20:26:00 [INFO]: Epoch 036 - training loss: 0.4735, validation loss: 0.0471
2024-05-24 20:26:01 [INFO]: Epoch 037 - training loss: 0.4657, validation loss: 0.0351
2024-05-24 20:26:01 [INFO]: Epoch 038 - training loss: 0.4443, validation loss: 0.0404
2024-05-24 20:26:02 [INFO]: Epoch 039 - training loss: 0.4340, validation loss: 0.0454
2024-05-24 20:26:02 [INFO]: Epoch 040 - training loss: 0.4459, validation loss: 0.0398
2024-05-24 20:26:03 [INFO]: Epoch 041 - training loss: 0.4475, validation loss: 0.0340
2024-05-24 20:26:03 [INFO]: Epoch 042 - training loss: 0.4362, validation loss: 0.0400
2024-05-24 20:26:04 [INFO]: Epoch 043 - training loss: 0.4319, validation loss: 0.0479
2024-05-24 20:26:04 [INFO]: Epoch 044 - training loss: 0.4380, validation loss: 0.0406
2024-05-24 20:26:05 [INFO]: Epoch 045 - training loss: 0.4329, validation loss: 0.0362
2024-05-24 20:26:05 [INFO]: Epoch 046 - training loss: 0.4277, validation loss: 0.0359
2024-05-24 20:26:06 [INFO]: Epoch 047 - training loss: 0.4186, validation loss: 0.0418
2024-05-24 20:26:06 [INFO]: Epoch 048 - training loss: 0.4476, validation loss: 0.0453
2024-05-24 20:26:07 [INFO]: Epoch 049 - training loss: 0.4247, validation loss: 0.0490
2024-05-24 20:26:07 [INFO]: Epoch 050 - training loss: 0.4214, validation loss: 0.0352
2024-05-24 20:26:07 [INFO]: Epoch 051 - training loss: 0.4119, validation loss: 0.0351
2024-05-24 20:26:07 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:26:07 [INFO]: Finished training. The best model is from epoch#41.
2024-05-24 20:26:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/SAITS_ettm1/20240524_T202543/SAITS.pypots
2024-05-24 20:26:08 [INFO]: SAITS on ETTm1: MAE=0.1581, MSE=0.0467
2024-05-24 20:26:08 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/SAITS_ettm1/imputation.pkl
2024-05-24 20:26:08 [INFO]: Using the given device: cuda:0
2024-05-24 20:26:08 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T202608
2024-05-24 20:26:08 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T202608/tensorboard
2024-05-24 20:26:08 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 20:26:08 [INFO]: Epoch 001 - training loss: 1.2692, validation loss: 0.3975
2024-05-24 20:26:08 [INFO]: Epoch 002 - training loss: 0.7270, validation loss: 0.1896
2024-05-24 20:26:08 [INFO]: Epoch 003 - training loss: 0.5997, validation loss: 0.1498
2024-05-24 20:26:08 [INFO]: Epoch 004 - training loss: 0.5314, validation loss: 0.1243
2024-05-24 20:26:09 [INFO]: Epoch 005 - training loss: 0.4859, validation loss: 0.1024
2024-05-24 20:26:09 [INFO]: Epoch 006 - training loss: 0.4588, validation loss: 0.0898
2024-05-24 20:26:09 [INFO]: Epoch 007 - training loss: 0.4428, validation loss: 0.0798
2024-05-24 20:26:09 [INFO]: Epoch 008 - training loss: 0.4182, validation loss: 0.0728
2024-05-24 20:26:09 [INFO]: Epoch 009 - training loss: 0.4037, validation loss: 0.0652
2024-05-24 20:26:10 [INFO]: Epoch 010 - training loss: 0.3908, validation loss: 0.0630
2024-05-24 20:26:10 [INFO]: Epoch 011 - training loss: 0.3754, validation loss: 0.0621
2024-05-24 20:26:10 [INFO]: Epoch 012 - training loss: 0.3652, validation loss: 0.0570
2024-05-24 20:26:10 [INFO]: Epoch 013 - training loss: 0.3556, validation loss: 0.0544
2024-05-24 20:26:10 [INFO]: Epoch 014 - training loss: 0.3435, validation loss: 0.0510
2024-05-24 20:26:10 [INFO]: Epoch 015 - training loss: 0.3365, validation loss: 0.0495
2024-05-24 20:26:11 [INFO]: Epoch 016 - training loss: 0.3370, validation loss: 0.0566
2024-05-24 20:26:11 [INFO]: Epoch 017 - training loss: 0.3316, validation loss: 0.0485
2024-05-24 20:26:11 [INFO]: Epoch 018 - training loss: 0.3224, validation loss: 0.0479
2024-05-24 20:26:11 [INFO]: Epoch 019 - training loss: 0.3180, validation loss: 0.0447
2024-05-24 20:26:11 [INFO]: Epoch 020 - training loss: 0.3089, validation loss: 0.0426
2024-05-24 20:26:12 [INFO]: Epoch 021 - training loss: 0.3128, validation loss: 0.0443
2024-05-24 20:26:12 [INFO]: Epoch 022 - training loss: 0.3110, validation loss: 0.0475
2024-05-24 20:26:12 [INFO]: Epoch 023 - training loss: 0.3096, validation loss: 0.0456
2024-05-24 20:26:12 [INFO]: Epoch 024 - training loss: 0.2998, validation loss: 0.0383
2024-05-24 20:26:12 [INFO]: Epoch 025 - training loss: 0.2924, validation loss: 0.0405
2024-05-24 20:26:13 [INFO]: Epoch 026 - training loss: 0.3001, validation loss: 0.0407
2024-05-24 20:26:13 [INFO]: Epoch 027 - training loss: 0.2862, validation loss: 0.0459
2024-05-24 20:26:13 [INFO]: Epoch 028 - training loss: 0.2849, validation loss: 0.0372
2024-05-24 20:26:13 [INFO]: Epoch 029 - training loss: 0.2708, validation loss: 0.0374
2024-05-24 20:26:13 [INFO]: Epoch 030 - training loss: 0.2733, validation loss: 0.0365
2024-05-24 20:26:14 [INFO]: Epoch 031 - training loss: 0.2715, validation loss: 0.0387
2024-05-24 20:26:14 [INFO]: Epoch 032 - training loss: 0.2667, validation loss: 0.0395
2024-05-24 20:26:14 [INFO]: Epoch 033 - training loss: 0.2687, validation loss: 0.0395
2024-05-24 20:26:14 [INFO]: Epoch 034 - training loss: 0.2645, validation loss: 0.0370
2024-05-24 20:26:14 [INFO]: Epoch 035 - training loss: 0.2539, validation loss: 0.0329
2024-05-24 20:26:14 [INFO]: Epoch 036 - training loss: 0.2531, validation loss: 0.0330
2024-05-24 20:26:15 [INFO]: Epoch 037 - training loss: 0.2498, validation loss: 0.0346
2024-05-24 20:26:15 [INFO]: Epoch 038 - training loss: 0.2467, validation loss: 0.0338
2024-05-24 20:26:15 [INFO]: Epoch 039 - training loss: 0.2495, validation loss: 0.0333
2024-05-24 20:26:15 [INFO]: Epoch 040 - training loss: 0.2450, validation loss: 0.0357
2024-05-24 20:26:15 [INFO]: Epoch 041 - training loss: 0.2418, validation loss: 0.0342
2024-05-24 20:26:16 [INFO]: Epoch 042 - training loss: 0.2430, validation loss: 0.0304
2024-05-24 20:26:16 [INFO]: Epoch 043 - training loss: 0.2366, validation loss: 0.0357
2024-05-24 20:26:16 [INFO]: Epoch 044 - training loss: 0.2493, validation loss: 0.0324
2024-05-24 20:26:16 [INFO]: Epoch 045 - training loss: 0.2436, validation loss: 0.0387
2024-05-24 20:26:16 [INFO]: Epoch 046 - training loss: 0.2548, validation loss: 0.0319
2024-05-24 20:26:17 [INFO]: Epoch 047 - training loss: 0.2411, validation loss: 0.0311
2024-05-24 20:26:17 [INFO]: Epoch 048 - training loss: 0.2323, validation loss: 0.0350
2024-05-24 20:26:17 [INFO]: Epoch 049 - training loss: 0.2327, validation loss: 0.0316
2024-05-24 20:26:17 [INFO]: Epoch 050 - training loss: 0.2291, validation loss: 0.0310
2024-05-24 20:26:17 [INFO]: Epoch 051 - training loss: 0.2232, validation loss: 0.0315
2024-05-24 20:26:18 [INFO]: Epoch 052 - training loss: 0.2238, validation loss: 0.0312
2024-05-24 20:26:18 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:26:18 [INFO]: Finished training. The best model is from epoch#42.
2024-05-24 20:26:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/Transformer_ettm1/20240524_T202608/Transformer.pypots
2024-05-24 20:26:18 [INFO]: Transformer on ETTm1: MAE=0.1466, MSE=0.0427
2024-05-24 20:26:18 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Transformer_ettm1/imputation.pkl
2024-05-24 20:26:18 [INFO]: Using the given device: cuda:0
2024-05-24 20:26:18 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T202618
2024-05-24 20:26:18 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T202618/tensorboard
2024-05-24 20:26:18 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 20:26:18 [INFO]: Epoch 001 - training loss: 0.1743, validation loss: 0.0592
2024-05-24 20:26:18 [INFO]: Epoch 002 - training loss: 0.0748, validation loss: 0.0439
2024-05-24 20:26:18 [INFO]: Epoch 003 - training loss: 0.0507, validation loss: 0.0348
2024-05-24 20:26:19 [INFO]: Epoch 004 - training loss: 0.0463, validation loss: 0.0321
2024-05-24 20:26:19 [INFO]: Epoch 005 - training loss: 0.0432, validation loss: 0.0326
2024-05-24 20:26:19 [INFO]: Epoch 006 - training loss: 0.0429, validation loss: 0.0304
2024-05-24 20:26:19 [INFO]: Epoch 007 - training loss: 0.0426, validation loss: 0.0312
2024-05-24 20:26:19 [INFO]: Epoch 008 - training loss: 0.0429, validation loss: 0.0307
2024-05-24 20:26:19 [INFO]: Epoch 009 - training loss: 0.0392, validation loss: 0.0303
2024-05-24 20:26:20 [INFO]: Epoch 010 - training loss: 0.0403, validation loss: 0.0304
2024-05-24 20:26:20 [INFO]: Epoch 011 - training loss: 0.0392, validation loss: 0.0287
2024-05-24 20:26:20 [INFO]: Epoch 012 - training loss: 0.0380, validation loss: 0.0287
2024-05-24 20:26:20 [INFO]: Epoch 013 - training loss: 0.0373, validation loss: 0.0282
2024-05-24 20:26:20 [INFO]: Epoch 014 - training loss: 0.0376, validation loss: 0.0298
2024-05-24 20:26:20 [INFO]: Epoch 015 - training loss: 0.0360, validation loss: 0.0278
2024-05-24 20:26:21 [INFO]: Epoch 016 - training loss: 0.0354, validation loss: 0.0275
2024-05-24 20:26:21 [INFO]: Epoch 017 - training loss: 0.0353, validation loss: 0.0276
2024-05-24 20:26:21 [INFO]: Epoch 018 - training loss: 0.0343, validation loss: 0.0283
2024-05-24 20:26:21 [INFO]: Epoch 019 - training loss: 0.0345, validation loss: 0.0286
2024-05-24 20:26:21 [INFO]: Epoch 020 - training loss: 0.0379, validation loss: 0.0281
2024-05-24 20:26:22 [INFO]: Epoch 021 - training loss: 0.0338, validation loss: 0.0275
2024-05-24 20:26:22 [INFO]: Epoch 022 - training loss: 0.0332, validation loss: 0.0272
2024-05-24 20:26:22 [INFO]: Epoch 023 - training loss: 0.0328, validation loss: 0.0275
2024-05-24 20:26:22 [INFO]: Epoch 024 - training loss: 0.0321, validation loss: 0.0269
2024-05-24 20:26:22 [INFO]: Epoch 025 - training loss: 0.0297, validation loss: 0.0266
2024-05-24 20:26:22 [INFO]: Epoch 026 - training loss: 0.0302, validation loss: 0.0262
2024-05-24 20:26:23 [INFO]: Epoch 027 - training loss: 0.0301, validation loss: 0.0270
2024-05-24 20:26:23 [INFO]: Epoch 028 - training loss: 0.0293, validation loss: 0.0261
2024-05-24 20:26:23 [INFO]: Epoch 029 - training loss: 0.0294, validation loss: 0.0261
2024-05-24 20:26:23 [INFO]: Epoch 030 - training loss: 0.0287, validation loss: 0.0260
2024-05-24 20:26:23 [INFO]: Epoch 031 - training loss: 0.0280, validation loss: 0.0264
2024-05-24 20:26:24 [INFO]: Epoch 032 - training loss: 0.0283, validation loss: 0.0299
2024-05-24 20:26:24 [INFO]: Epoch 033 - training loss: 0.0317, validation loss: 0.0277
2024-05-24 20:26:24 [INFO]: Epoch 034 - training loss: 0.0294, validation loss: 0.0265
2024-05-24 20:26:24 [INFO]: Epoch 035 - training loss: 0.0272, validation loss: 0.0258
2024-05-24 20:26:24 [INFO]: Epoch 036 - training loss: 0.0278, validation loss: 0.0258
2024-05-24 20:26:24 [INFO]: Epoch 037 - training loss: 0.0259, validation loss: 0.0263
2024-05-24 20:26:25 [INFO]: Epoch 038 - training loss: 0.0271, validation loss: 0.0257
2024-05-24 20:26:25 [INFO]: Epoch 039 - training loss: 0.0263, validation loss: 0.0263
2024-05-24 20:26:25 [INFO]: Epoch 040 - training loss: 0.0268, validation loss: 0.0255
2024-05-24 20:26:25 [INFO]: Epoch 041 - training loss: 0.0236, validation loss: 0.0256
2024-05-24 20:26:25 [INFO]: Epoch 042 - training loss: 0.0245, validation loss: 0.0259
2024-05-24 20:26:25 [INFO]: Epoch 043 - training loss: 0.0254, validation loss: 0.0259
2024-05-24 20:26:26 [INFO]: Epoch 044 - training loss: 0.0231, validation loss: 0.0254
2024-05-24 20:26:26 [INFO]: Epoch 045 - training loss: 0.0232, validation loss: 0.0265
2024-05-24 20:26:26 [INFO]: Epoch 046 - training loss: 0.0243, validation loss: 0.0258
2024-05-24 20:26:26 [INFO]: Epoch 047 - training loss: 0.0240, validation loss: 0.0255
2024-05-24 20:26:26 [INFO]: Epoch 048 - training loss: 0.0226, validation loss: 0.0256
2024-05-24 20:26:27 [INFO]: Epoch 049 - training loss: 0.0239, validation loss: 0.0264
2024-05-24 20:26:27 [INFO]: Epoch 050 - training loss: 0.0232, validation loss: 0.0259
2024-05-24 20:26:27 [INFO]: Epoch 051 - training loss: 0.0225, validation loss: 0.0259
2024-05-24 20:26:27 [INFO]: Epoch 052 - training loss: 0.0230, validation loss: 0.0263
2024-05-24 20:26:27 [INFO]: Epoch 053 - training loss: 0.0203, validation loss: 0.0257
2024-05-24 20:26:27 [INFO]: Epoch 054 - training loss: 0.0204, validation loss: 0.0257
2024-05-24 20:26:27 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:26:27 [INFO]: Finished training. The best model is from epoch#44.
2024-05-24 20:26:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/TimesNet_ettm1/20240524_T202618/TimesNet.pypots
2024-05-24 20:26:28 [INFO]: TimesNet on ETTm1: MAE=0.1146, MSE=0.0283
2024-05-24 20:26:28 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/TimesNet_ettm1/imputation.pkl
2024-05-24 20:26:28 [INFO]: Using the given device: cuda:0
2024-05-24 20:26:28 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628
2024-05-24 20:26:28 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/tensorboard
2024-05-24 20:26:28 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 20:26:30 [INFO]: Epoch 001 - training loss: 0.7086, validation loss: 0.4767
2024-05-24 20:26:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch1_loss0.4766743555665016.pypots
2024-05-24 20:26:32 [INFO]: Epoch 002 - training loss: 0.4110, validation loss: 0.3738
2024-05-24 20:26:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch2_loss0.3738444149494171.pypots
2024-05-24 20:26:34 [INFO]: Epoch 003 - training loss: 0.3460, validation loss: 0.3211
2024-05-24 20:26:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch3_loss0.3210715427994728.pypots
2024-05-24 20:26:36 [INFO]: Epoch 004 - training loss: 0.3574, validation loss: 0.2973
2024-05-24 20:26:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch4_loss0.2972799763083458.pypots
2024-05-24 20:26:38 [INFO]: Epoch 005 - training loss: 0.2748, validation loss: 0.2831
2024-05-24 20:26:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch5_loss0.28311687707901.pypots
2024-05-24 20:26:40 [INFO]: Epoch 006 - training loss: 0.2978, validation loss: 0.2688
2024-05-24 20:26:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch6_loss0.2687901630997658.pypots
2024-05-24 20:26:42 [INFO]: Epoch 007 - training loss: 0.2866, validation loss: 0.2635
2024-05-24 20:26:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch7_loss0.2635265663266182.pypots
2024-05-24 20:26:44 [INFO]: Epoch 008 - training loss: 0.2606, validation loss: 0.2483
2024-05-24 20:26:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch8_loss0.24832206219434738.pypots
2024-05-24 20:26:46 [INFO]: Epoch 009 - training loss: 0.2809, validation loss: 0.2480
2024-05-24 20:26:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch9_loss0.24802923575043678.pypots
2024-05-24 20:26:48 [INFO]: Epoch 010 - training loss: 0.2735, validation loss: 0.2438
2024-05-24 20:26:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch10_loss0.243837159126997.pypots
2024-05-24 20:26:50 [INFO]: Epoch 011 - training loss: 0.2705, validation loss: 0.2454
2024-05-24 20:26:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch11_loss0.24540980532765388.pypots
2024-05-24 20:26:52 [INFO]: Epoch 012 - training loss: 0.2462, validation loss: 0.2323
2024-05-24 20:26:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch12_loss0.23230920359492302.pypots
2024-05-24 20:26:54 [INFO]: Epoch 013 - training loss: 0.1987, validation loss: 0.2170
2024-05-24 20:26:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch13_loss0.21700505912303925.pypots
2024-05-24 20:26:56 [INFO]: Epoch 014 - training loss: 0.2115, validation loss: 0.2050
2024-05-24 20:26:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch14_loss0.2050054706633091.pypots
2024-05-24 20:26:58 [INFO]: Epoch 015 - training loss: 0.1935, validation loss: 0.1957
2024-05-24 20:26:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch15_loss0.19569649547338486.pypots
2024-05-24 20:27:00 [INFO]: Epoch 016 - training loss: 0.2098, validation loss: 0.1929
2024-05-24 20:27:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch16_loss0.192915178835392.pypots
2024-05-24 20:27:02 [INFO]: Epoch 017 - training loss: 0.1856, validation loss: 0.1873
2024-05-24 20:27:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch17_loss0.18729086965322495.pypots
2024-05-24 20:27:04 [INFO]: Epoch 018 - training loss: 0.1885, validation loss: 0.1843
2024-05-24 20:27:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch18_loss0.18425174430012703.pypots
2024-05-24 20:27:06 [INFO]: Epoch 019 - training loss: 0.2412, validation loss: 0.1913
2024-05-24 20:27:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch19_loss0.1912897825241089.pypots
2024-05-24 20:27:08 [INFO]: Epoch 020 - training loss: 0.2138, validation loss: 0.1859
2024-05-24 20:27:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch20_loss0.1858733929693699.pypots
2024-05-24 20:27:10 [INFO]: Epoch 021 - training loss: 0.2011, validation loss: 0.1764
2024-05-24 20:27:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch21_loss0.17643581330776215.pypots
2024-05-24 20:27:12 [INFO]: Epoch 022 - training loss: 0.1979, validation loss: 0.1847
2024-05-24 20:27:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch22_loss0.18467358499765396.pypots
2024-05-24 20:27:14 [INFO]: Epoch 023 - training loss: 0.1580, validation loss: 0.1773
2024-05-24 20:27:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch23_loss0.17732982710003853.pypots
2024-05-24 20:27:16 [INFO]: Epoch 024 - training loss: 0.1809, validation loss: 0.1818
2024-05-24 20:27:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch24_loss0.18177569657564163.pypots
2024-05-24 20:27:18 [INFO]: Epoch 025 - training loss: 0.1851, validation loss: 0.1876
2024-05-24 20:27:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch25_loss0.18764886632561684.pypots
2024-05-24 20:27:20 [INFO]: Epoch 026 - training loss: 0.1818, validation loss: 0.1694
2024-05-24 20:27:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch26_loss0.16939545422792435.pypots
2024-05-24 20:27:22 [INFO]: Epoch 027 - training loss: 0.2406, validation loss: 0.1717
2024-05-24 20:27:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch27_loss0.1716914065182209.pypots
2024-05-24 20:27:24 [INFO]: Epoch 028 - training loss: 0.2049, validation loss: 0.1765
2024-05-24 20:27:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch28_loss0.17646995559334755.pypots
2024-05-24 20:27:26 [INFO]: Epoch 029 - training loss: 0.2789, validation loss: 0.1730
2024-05-24 20:27:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch29_loss0.17297427728772163.pypots
2024-05-24 20:27:28 [INFO]: Epoch 030 - training loss: 0.1627, validation loss: 0.1711
2024-05-24 20:27:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch30_loss0.1711292564868927.pypots
2024-05-24 20:27:30 [INFO]: Epoch 031 - training loss: 0.1369, validation loss: 0.1605
2024-05-24 20:27:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch31_loss0.1605033315718174.pypots
2024-05-24 20:27:32 [INFO]: Epoch 032 - training loss: 0.1574, validation loss: 0.1571
2024-05-24 20:27:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch32_loss0.15712033957242966.pypots
2024-05-24 20:27:34 [INFO]: Epoch 033 - training loss: 0.1557, validation loss: 0.1591
2024-05-24 20:27:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch33_loss0.15909318998456.pypots
2024-05-24 20:27:36 [INFO]: Epoch 034 - training loss: 0.1581, validation loss: 0.1495
2024-05-24 20:27:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch34_loss0.14946335181593895.pypots
2024-05-24 20:27:38 [INFO]: Epoch 035 - training loss: 0.1388, validation loss: 0.1523
2024-05-24 20:27:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch35_loss0.1522500142455101.pypots
2024-05-24 20:27:40 [INFO]: Epoch 036 - training loss: 0.1476, validation loss: 0.1487
2024-05-24 20:27:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch36_loss0.14870351180434227.pypots
2024-05-24 20:27:43 [INFO]: Epoch 037 - training loss: 0.1624, validation loss: 0.1480
2024-05-24 20:27:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch37_loss0.14795498177409172.pypots
2024-05-24 20:27:45 [INFO]: Epoch 038 - training loss: 0.1745, validation loss: 0.1648
2024-05-24 20:27:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch38_loss0.16477632522583008.pypots
2024-05-24 20:27:47 [INFO]: Epoch 039 - training loss: 0.2066, validation loss: 0.1568
2024-05-24 20:27:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch39_loss0.15678225830197334.pypots
2024-05-24 20:27:49 [INFO]: Epoch 040 - training loss: 0.1678, validation loss: 0.1452
2024-05-24 20:27:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch40_loss0.14524009451270103.pypots
2024-05-24 20:27:51 [INFO]: Epoch 041 - training loss: 0.1591, validation loss: 0.1537
2024-05-24 20:27:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch41_loss0.1537381112575531.pypots
2024-05-24 20:27:53 [INFO]: Epoch 042 - training loss: 0.2049, validation loss: 0.1594
2024-05-24 20:27:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch42_loss0.1594199277460575.pypots
2024-05-24 20:27:55 [INFO]: Epoch 043 - training loss: 0.1727, validation loss: 0.1587
2024-05-24 20:27:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch43_loss0.15870755538344383.pypots
2024-05-24 20:27:57 [INFO]: Epoch 044 - training loss: 0.1582, validation loss: 0.1476
2024-05-24 20:27:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch44_loss0.14763983339071274.pypots
2024-05-24 20:27:59 [INFO]: Epoch 045 - training loss: 0.1528, validation loss: 0.1505
2024-05-24 20:27:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch45_loss0.15047888085246086.pypots
2024-05-24 20:28:01 [INFO]: Epoch 046 - training loss: 0.2374, validation loss: 0.1499
2024-05-24 20:28:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch46_loss0.14994143694639206.pypots
2024-05-24 20:28:03 [INFO]: Epoch 047 - training loss: 0.1295, validation loss: 0.1410
2024-05-24 20:28:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch47_loss0.1409626603126526.pypots
2024-05-24 20:28:05 [INFO]: Epoch 048 - training loss: 0.1649, validation loss: 0.1386
2024-05-24 20:28:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch48_loss0.13861406221985817.pypots
2024-05-24 20:28:07 [INFO]: Epoch 049 - training loss: 0.1176, validation loss: 0.1371
2024-05-24 20:28:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch49_loss0.13714756816625595.pypots
2024-05-24 20:28:09 [INFO]: Epoch 050 - training loss: 0.1444, validation loss: 0.1349
2024-05-24 20:28:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch50_loss0.1349433735013008.pypots
2024-05-24 20:28:11 [INFO]: Epoch 051 - training loss: 0.1391, validation loss: 0.1450
2024-05-24 20:28:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch51_loss0.14495255425572395.pypots
2024-05-24 20:28:13 [INFO]: Epoch 052 - training loss: 0.1424, validation loss: 0.1450
2024-05-24 20:28:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch52_loss0.14499353989958763.pypots
2024-05-24 20:28:15 [INFO]: Epoch 053 - training loss: 0.1352, validation loss: 0.1403
2024-05-24 20:28:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch53_loss0.14027521014213562.pypots
2024-05-24 20:28:17 [INFO]: Epoch 054 - training loss: 0.1531, validation loss: 0.1349
2024-05-24 20:28:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch54_loss0.13491300866007805.pypots
2024-05-24 20:28:19 [INFO]: Epoch 055 - training loss: 0.1675, validation loss: 0.1407
2024-05-24 20:28:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch55_loss0.14070914685726166.pypots
2024-05-24 20:28:21 [INFO]: Epoch 056 - training loss: 0.1614, validation loss: 0.1512
2024-05-24 20:28:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch56_loss0.15119460970163345.pypots
2024-05-24 20:28:23 [INFO]: Epoch 057 - training loss: 0.1623, validation loss: 0.1391
2024-05-24 20:28:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch57_loss0.13907146453857422.pypots
2024-05-24 20:28:25 [INFO]: Epoch 058 - training loss: 0.1514, validation loss: 0.1385
2024-05-24 20:28:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch58_loss0.13852518796920776.pypots
2024-05-24 20:28:27 [INFO]: Epoch 059 - training loss: 0.1605, validation loss: 0.1423
2024-05-24 20:28:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch59_loss0.14234230294823647.pypots
2024-05-24 20:28:29 [INFO]: Epoch 060 - training loss: 0.1787, validation loss: 0.1504
2024-05-24 20:28:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch60_loss0.15037071332335472.pypots
2024-05-24 20:28:31 [INFO]: Epoch 061 - training loss: 0.1422, validation loss: 0.1386
2024-05-24 20:28:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch61_loss0.1386193372309208.pypots
2024-05-24 20:28:33 [INFO]: Epoch 062 - training loss: 0.1369, validation loss: 0.1386
2024-05-24 20:28:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch62_loss0.13856111839413643.pypots
2024-05-24 20:28:35 [INFO]: Epoch 063 - training loss: 0.1716, validation loss: 0.1338
2024-05-24 20:28:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch63_loss0.1338271088898182.pypots
2024-05-24 20:28:37 [INFO]: Epoch 064 - training loss: 0.1540, validation loss: 0.1414
2024-05-24 20:28:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch64_loss0.14137093350291252.pypots
2024-05-24 20:28:39 [INFO]: Epoch 065 - training loss: 0.1799, validation loss: 0.1343
2024-05-24 20:28:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch65_loss0.13425366953015327.pypots
2024-05-24 20:28:41 [INFO]: Epoch 066 - training loss: 0.1334, validation loss: 0.1373
2024-05-24 20:28:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch66_loss0.13731299713253975.pypots
2024-05-24 20:28:43 [INFO]: Epoch 067 - training loss: 0.1597, validation loss: 0.1340
2024-05-24 20:28:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch67_loss0.13400317169725895.pypots
2024-05-24 20:28:45 [INFO]: Epoch 068 - training loss: 0.1463, validation loss: 0.1322
2024-05-24 20:28:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch68_loss0.1321792546659708.pypots
2024-05-24 20:28:47 [INFO]: Epoch 069 - training loss: 0.1454, validation loss: 0.1291
2024-05-24 20:28:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch69_loss0.12905937433242798.pypots
2024-05-24 20:28:49 [INFO]: Epoch 070 - training loss: 0.2054, validation loss: 0.1481
2024-05-24 20:28:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch70_loss0.14809896424412727.pypots
2024-05-24 20:28:51 [INFO]: Epoch 071 - training loss: 0.1845, validation loss: 0.1611
2024-05-24 20:28:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch71_loss0.1611098013818264.pypots
2024-05-24 20:28:53 [INFO]: Epoch 072 - training loss: 0.1449, validation loss: 0.1433
2024-05-24 20:28:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch72_loss0.14330872893333435.pypots
2024-05-24 20:28:55 [INFO]: Epoch 073 - training loss: 0.1346, validation loss: 0.1374
2024-05-24 20:28:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch73_loss0.13743414729833603.pypots
2024-05-24 20:28:57 [INFO]: Epoch 074 - training loss: 0.1579, validation loss: 0.1289
2024-05-24 20:28:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch74_loss0.12893225252628326.pypots
2024-05-24 20:28:59 [INFO]: Epoch 075 - training loss: 0.1302, validation loss: 0.1274
2024-05-24 20:28:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch75_loss0.1273739580065012.pypots
2024-05-24 20:29:01 [INFO]: Epoch 076 - training loss: 0.1716, validation loss: 0.1767
2024-05-24 20:29:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch76_loss0.17668670043349266.pypots
2024-05-24 20:29:03 [INFO]: Epoch 077 - training loss: 0.2012, validation loss: 0.1636
2024-05-24 20:29:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch77_loss0.16357474401593208.pypots
2024-05-24 20:29:06 [INFO]: Epoch 078 - training loss: 0.1320, validation loss: 0.1438
2024-05-24 20:29:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch78_loss0.14382954686880112.pypots
2024-05-24 20:29:08 [INFO]: Epoch 079 - training loss: 0.1403, validation loss: 0.1385
2024-05-24 20:29:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch79_loss0.13850780948996544.pypots
2024-05-24 20:29:10 [INFO]: Epoch 080 - training loss: 0.1447, validation loss: 0.1375
2024-05-24 20:29:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch80_loss0.13747770711779594.pypots
2024-05-24 20:29:12 [INFO]: Epoch 081 - training loss: 0.1397, validation loss: 0.1340
2024-05-24 20:29:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch81_loss0.1340070255100727.pypots
2024-05-24 20:29:14 [INFO]: Epoch 082 - training loss: 0.1806, validation loss: 0.1382
2024-05-24 20:29:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch82_loss0.13819989562034607.pypots
2024-05-24 20:29:16 [INFO]: Epoch 083 - training loss: 0.1262, validation loss: 0.1365
2024-05-24 20:29:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch83_loss0.1365201734006405.pypots
2024-05-24 20:29:18 [INFO]: Epoch 084 - training loss: 0.1729, validation loss: 0.1342
2024-05-24 20:29:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch84_loss0.13417372480034828.pypots
2024-05-24 20:29:20 [INFO]: Epoch 085 - training loss: 0.1441, validation loss: 0.1457
2024-05-24 20:29:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI_epoch85_loss0.14565566182136536.pypots
2024-05-24 20:29:20 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:29:20 [INFO]: Finished training. The best model is from epoch#75.
2024-05-24 20:29:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/CSDI_ettm1/20240524_T202628/CSDI.pypots
2024-05-24 20:29:35 [INFO]: CSDI on ETTm1: MAE=0.1393, MSE=0.0450
2024-05-24 20:29:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/CSDI_ettm1/imputation.pkl
2024-05-24 20:29:35 [INFO]: Using the given device: cuda:0
2024-05-24 20:29:35 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T202935
2024-05-24 20:29:35 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T202935/tensorboard
2024-05-24 20:29:35 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 20:29:35 [INFO]: Epoch 001 - training loss: 23782.4762, validation loss: 0.9635
2024-05-24 20:29:36 [INFO]: Epoch 002 - training loss: 21868.7725, validation loss: 0.9670
2024-05-24 20:29:36 [INFO]: Epoch 003 - training loss: 20065.9514, validation loss: 0.9596
2024-05-24 20:29:36 [INFO]: Epoch 004 - training loss: 18159.7637, validation loss: 0.9414
2024-05-24 20:29:36 [INFO]: Epoch 005 - training loss: 16245.1472, validation loss: 0.8902
2024-05-24 20:29:36 [INFO]: Epoch 006 - training loss: 14653.1502, validation loss: 0.7927
2024-05-24 20:29:36 [INFO]: Epoch 007 - training loss: 13159.3300, validation loss: 0.6930
2024-05-24 20:29:36 [INFO]: Epoch 008 - training loss: 12461.7033, validation loss: 0.6181
2024-05-24 20:29:36 [INFO]: Epoch 009 - training loss: 11764.2186, validation loss: 0.5769
2024-05-24 20:29:36 [INFO]: Epoch 010 - training loss: 11200.7178, validation loss: 0.5390
2024-05-24 20:29:37 [INFO]: Epoch 011 - training loss: 10755.5832, validation loss: 0.5206
2024-05-24 20:29:37 [INFO]: Epoch 012 - training loss: 10466.8162, validation loss: 0.5055
2024-05-24 20:29:37 [INFO]: Epoch 013 - training loss: 10329.4230, validation loss: 0.4931
2024-05-24 20:29:37 [INFO]: Epoch 014 - training loss: 10182.5847, validation loss: 0.4815
2024-05-24 20:29:37 [INFO]: Epoch 015 - training loss: 10023.3691, validation loss: 0.4706
2024-05-24 20:29:37 [INFO]: Epoch 016 - training loss: 9978.9957, validation loss: 0.4518
2024-05-24 20:29:37 [INFO]: Epoch 017 - training loss: 9891.5103, validation loss: 0.4273
2024-05-24 20:29:37 [INFO]: Epoch 018 - training loss: 9778.6967, validation loss: 0.4028
2024-05-24 20:29:37 [INFO]: Epoch 019 - training loss: 9734.4403, validation loss: 0.3852
2024-05-24 20:29:38 [INFO]: Epoch 020 - training loss: 9702.0795, validation loss: 0.3593
2024-05-24 20:29:38 [INFO]: Epoch 021 - training loss: 9638.1346, validation loss: 0.3383
2024-05-24 20:29:38 [INFO]: Epoch 022 - training loss: 9594.3644, validation loss: 0.3134
2024-05-24 20:29:38 [INFO]: Epoch 023 - training loss: 9575.9562, validation loss: 0.3071
2024-05-24 20:29:38 [INFO]: Epoch 024 - training loss: 9536.5915, validation loss: 0.2988
2024-05-24 20:29:38 [INFO]: Epoch 025 - training loss: 9536.7306, validation loss: 0.2928
2024-05-24 20:29:38 [INFO]: Epoch 026 - training loss: 9514.8346, validation loss: 0.2941
2024-05-24 20:29:38 [INFO]: Epoch 027 - training loss: 9488.3801, validation loss: 0.2809
2024-05-24 20:29:38 [INFO]: Epoch 028 - training loss: 9463.9065, validation loss: 0.2818
2024-05-24 20:29:39 [INFO]: Epoch 029 - training loss: 9439.5540, validation loss: 0.2735
2024-05-24 20:29:39 [INFO]: Epoch 030 - training loss: 9434.7039, validation loss: 0.2642
2024-05-24 20:29:39 [INFO]: Epoch 031 - training loss: 9409.1512, validation loss: 0.2526
2024-05-24 20:29:39 [INFO]: Epoch 032 - training loss: 9395.6369, validation loss: 0.2426
2024-05-24 20:29:39 [INFO]: Epoch 033 - training loss: 9399.1823, validation loss: 0.2380
2024-05-24 20:29:39 [INFO]: Epoch 034 - training loss: 9377.6967, validation loss: 0.2341
2024-05-24 20:29:39 [INFO]: Epoch 035 - training loss: 9362.0471, validation loss: 0.2264
2024-05-24 20:29:39 [INFO]: Epoch 036 - training loss: 9354.9269, validation loss: 0.2176
2024-05-24 20:29:39 [INFO]: Epoch 037 - training loss: 9363.1230, validation loss: 0.2172
2024-05-24 20:29:40 [INFO]: Epoch 038 - training loss: 9338.2708, validation loss: 0.2075
2024-05-24 20:29:40 [INFO]: Epoch 039 - training loss: 9336.5732, validation loss: 0.2035
2024-05-24 20:29:40 [INFO]: Epoch 040 - training loss: 9332.6124, validation loss: 0.1968
2024-05-24 20:29:40 [INFO]: Epoch 041 - training loss: 9331.2923, validation loss: 0.1909
2024-05-24 20:29:40 [INFO]: Epoch 042 - training loss: 9317.1727, validation loss: 0.1864
2024-05-24 20:29:40 [INFO]: Epoch 043 - training loss: 9320.7653, validation loss: 0.1790
2024-05-24 20:29:40 [INFO]: Epoch 044 - training loss: 9308.0352, validation loss: 0.1766
2024-05-24 20:29:40 [INFO]: Epoch 045 - training loss: 9305.2197, validation loss: 0.1740
2024-05-24 20:29:40 [INFO]: Epoch 046 - training loss: 9319.9303, validation loss: 0.1652
2024-05-24 20:29:40 [INFO]: Epoch 047 - training loss: 9298.1530, validation loss: 0.1657
2024-05-24 20:29:41 [INFO]: Epoch 048 - training loss: 9293.5529, validation loss: 0.1622
2024-05-24 20:29:41 [INFO]: Epoch 049 - training loss: 9290.4120, validation loss: 0.1604
2024-05-24 20:29:41 [INFO]: Epoch 050 - training loss: 9289.0670, validation loss: 0.1557
2024-05-24 20:29:41 [INFO]: Epoch 051 - training loss: 9284.5250, validation loss: 0.1549
2024-05-24 20:29:41 [INFO]: Epoch 052 - training loss: 9280.1981, validation loss: 0.1521
2024-05-24 20:29:41 [INFO]: Epoch 053 - training loss: 9278.7539, validation loss: 0.1506
2024-05-24 20:29:41 [INFO]: Epoch 054 - training loss: 9276.8959, validation loss: 0.1504
2024-05-24 20:29:41 [INFO]: Epoch 055 - training loss: 9276.2454, validation loss: 0.1474
2024-05-24 20:29:41 [INFO]: Epoch 056 - training loss: 9273.2942, validation loss: 0.1476
2024-05-24 20:29:42 [INFO]: Epoch 057 - training loss: 9270.2045, validation loss: 0.1414
2024-05-24 20:29:42 [INFO]: Epoch 058 - training loss: 9266.7632, validation loss: 0.1413
2024-05-24 20:29:42 [INFO]: Epoch 059 - training loss: 9265.9233, validation loss: 0.1399
2024-05-24 20:29:42 [INFO]: Epoch 060 - training loss: 9265.0546, validation loss: 0.1396
2024-05-24 20:29:42 [INFO]: Epoch 061 - training loss: 9265.2898, validation loss: 0.1385
2024-05-24 20:29:42 [INFO]: Epoch 062 - training loss: 9268.1133, validation loss: 0.1373
2024-05-24 20:29:42 [INFO]: Epoch 063 - training loss: 9261.1234, validation loss: 0.1366
2024-05-24 20:29:42 [INFO]: Epoch 064 - training loss: 9257.2822, validation loss: 0.1353
2024-05-24 20:29:42 [INFO]: Epoch 065 - training loss: 9256.2561, validation loss: 0.1347
2024-05-24 20:29:43 [INFO]: Epoch 066 - training loss: 9255.2167, validation loss: 0.1341
2024-05-24 20:29:43 [INFO]: Epoch 067 - training loss: 9256.8785, validation loss: 0.1333
2024-05-24 20:29:43 [INFO]: Epoch 068 - training loss: 9251.3144, validation loss: 0.1338
2024-05-24 20:29:43 [INFO]: Epoch 069 - training loss: 9254.1026, validation loss: 0.1316
2024-05-24 20:29:43 [INFO]: Epoch 070 - training loss: 9249.3078, validation loss: 0.1300
2024-05-24 20:29:43 [INFO]: Epoch 071 - training loss: 9251.0349, validation loss: 0.1296
2024-05-24 20:29:43 [INFO]: Epoch 072 - training loss: 9248.6114, validation loss: 0.1281
2024-05-24 20:29:43 [INFO]: Epoch 073 - training loss: 9249.6187, validation loss: 0.1283
2024-05-24 20:29:43 [INFO]: Epoch 074 - training loss: 9246.3982, validation loss: 0.1282
2024-05-24 20:29:44 [INFO]: Epoch 075 - training loss: 9244.4367, validation loss: 0.1271
2024-05-24 20:29:44 [INFO]: Epoch 076 - training loss: 9246.1827, validation loss: 0.1243
2024-05-24 20:29:44 [INFO]: Epoch 077 - training loss: 9247.0566, validation loss: 0.1270
2024-05-24 20:29:44 [INFO]: Epoch 078 - training loss: 9243.1174, validation loss: 0.1242
2024-05-24 20:29:44 [INFO]: Epoch 079 - training loss: 9247.0143, validation loss: 0.1236
2024-05-24 20:29:44 [INFO]: Epoch 080 - training loss: 9243.0783, validation loss: 0.1230
2024-05-24 20:29:44 [INFO]: Epoch 081 - training loss: 9239.8143, validation loss: 0.1221
2024-05-24 20:29:44 [INFO]: Epoch 082 - training loss: 9239.9066, validation loss: 0.1236
2024-05-24 20:29:44 [INFO]: Epoch 083 - training loss: 9241.5153, validation loss: 0.1213
2024-05-24 20:29:44 [INFO]: Epoch 084 - training loss: 9240.1485, validation loss: 0.1220
2024-05-24 20:29:45 [INFO]: Epoch 085 - training loss: 9237.9406, validation loss: 0.1210
2024-05-24 20:29:45 [INFO]: Epoch 086 - training loss: 9237.8746, validation loss: 0.1194
2024-05-24 20:29:45 [INFO]: Epoch 087 - training loss: 9235.1305, validation loss: 0.1191
2024-05-24 20:29:45 [INFO]: Epoch 088 - training loss: 9236.8931, validation loss: 0.1188
2024-05-24 20:29:45 [INFO]: Epoch 089 - training loss: 9237.5610, validation loss: 0.1184
2024-05-24 20:29:45 [INFO]: Epoch 090 - training loss: 9234.5543, validation loss: 0.1167
2024-05-24 20:29:45 [INFO]: Epoch 091 - training loss: 9235.9344, validation loss: 0.1176
2024-05-24 20:29:45 [INFO]: Epoch 092 - training loss: 9234.0201, validation loss: 0.1165
2024-05-24 20:29:45 [INFO]: Epoch 093 - training loss: 9232.2328, validation loss: 0.1151
2024-05-24 20:29:46 [INFO]: Epoch 094 - training loss: 9232.8420, validation loss: 0.1162
2024-05-24 20:29:46 [INFO]: Epoch 095 - training loss: 9232.8186, validation loss: 0.1170
2024-05-24 20:29:46 [INFO]: Epoch 096 - training loss: 9231.2408, validation loss: 0.1130
2024-05-24 20:29:46 [INFO]: Epoch 097 - training loss: 9230.0859, validation loss: 0.1139
2024-05-24 20:29:46 [INFO]: Epoch 098 - training loss: 9230.9873, validation loss: 0.1134
2024-05-24 20:29:46 [INFO]: Epoch 099 - training loss: 9232.9332, validation loss: 0.1131
2024-05-24 20:29:46 [INFO]: Epoch 100 - training loss: 9230.8154, validation loss: 0.1127
2024-05-24 20:29:46 [INFO]: Epoch 101 - training loss: 9229.6926, validation loss: 0.1147
2024-05-24 20:29:46 [INFO]: Epoch 102 - training loss: 9228.5309, validation loss: 0.1107
2024-05-24 20:29:47 [INFO]: Epoch 103 - training loss: 9228.7705, validation loss: 0.1136
2024-05-24 20:29:47 [INFO]: Epoch 104 - training loss: 9226.9935, validation loss: 0.1098
2024-05-24 20:29:47 [INFO]: Epoch 105 - training loss: 9225.6900, validation loss: 0.1128
2024-05-24 20:29:47 [INFO]: Epoch 106 - training loss: 9229.6132, validation loss: 0.1091
2024-05-24 20:29:47 [INFO]: Epoch 107 - training loss: 9227.7454, validation loss: 0.1109
2024-05-24 20:29:47 [INFO]: Epoch 108 - training loss: 9225.7410, validation loss: 0.1079
2024-05-24 20:29:47 [INFO]: Epoch 109 - training loss: 9224.2204, validation loss: 0.1108
2024-05-24 20:29:47 [INFO]: Epoch 110 - training loss: 9225.8611, validation loss: 0.1088
2024-05-24 20:29:47 [INFO]: Epoch 111 - training loss: 9224.7643, validation loss: 0.1073
2024-05-24 20:29:48 [INFO]: Epoch 112 - training loss: 9226.7211, validation loss: 0.1069
2024-05-24 20:29:48 [INFO]: Epoch 113 - training loss: 9223.1911, validation loss: 0.1076
2024-05-24 20:29:48 [INFO]: Epoch 114 - training loss: 9223.2947, validation loss: 0.1060
2024-05-24 20:29:48 [INFO]: Epoch 115 - training loss: 9223.9038, validation loss: 0.1076
2024-05-24 20:29:48 [INFO]: Epoch 116 - training loss: 9225.2280, validation loss: 0.1047
2024-05-24 20:29:48 [INFO]: Epoch 117 - training loss: 9223.5203, validation loss: 0.1053
2024-05-24 20:29:48 [INFO]: Epoch 118 - training loss: 9223.5815, validation loss: 0.1038
2024-05-24 20:29:48 [INFO]: Epoch 119 - training loss: 9224.3481, validation loss: 0.1054
2024-05-24 20:29:48 [INFO]: Epoch 120 - training loss: 9224.0492, validation loss: 0.1039
2024-05-24 20:29:48 [INFO]: Epoch 121 - training loss: 9223.1362, validation loss: 0.1034
2024-05-24 20:29:49 [INFO]: Epoch 122 - training loss: 9224.1457, validation loss: 0.1030
2024-05-24 20:29:49 [INFO]: Epoch 123 - training loss: 9222.1470, validation loss: 0.1043
2024-05-24 20:29:49 [INFO]: Epoch 124 - training loss: 9223.4632, validation loss: 0.1025
2024-05-24 20:29:49 [INFO]: Epoch 125 - training loss: 9219.8783, validation loss: 0.1014
2024-05-24 20:29:49 [INFO]: Epoch 126 - training loss: 9221.1508, validation loss: 0.1025
2024-05-24 20:29:49 [INFO]: Epoch 127 - training loss: 9218.9480, validation loss: 0.1014
2024-05-24 20:29:49 [INFO]: Epoch 128 - training loss: 9220.6520, validation loss: 0.1023
2024-05-24 20:29:49 [INFO]: Epoch 129 - training loss: 9220.1602, validation loss: 0.1010
2024-05-24 20:29:49 [INFO]: Epoch 130 - training loss: 9219.0097, validation loss: 0.1015
2024-05-24 20:29:50 [INFO]: Epoch 131 - training loss: 9219.9850, validation loss: 0.0981
2024-05-24 20:29:50 [INFO]: Epoch 132 - training loss: 9219.7159, validation loss: 0.1008
2024-05-24 20:29:50 [INFO]: Epoch 133 - training loss: 9220.2722, validation loss: 0.0997
2024-05-24 20:29:50 [INFO]: Epoch 134 - training loss: 9221.1895, validation loss: 0.1012
2024-05-24 20:29:50 [INFO]: Epoch 135 - training loss: 9220.8064, validation loss: 0.0996
2024-05-24 20:29:50 [INFO]: Epoch 136 - training loss: 9219.3511, validation loss: 0.1000
2024-05-24 20:29:50 [INFO]: Epoch 137 - training loss: 9218.5234, validation loss: 0.0973
2024-05-24 20:29:50 [INFO]: Epoch 138 - training loss: 9218.7004, validation loss: 0.0992
2024-05-24 20:29:50 [INFO]: Epoch 139 - training loss: 9218.0983, validation loss: 0.0987
2024-05-24 20:29:51 [INFO]: Epoch 140 - training loss: 9219.3736, validation loss: 0.0960
2024-05-24 20:29:51 [INFO]: Epoch 141 - training loss: 9220.0748, validation loss: 0.0979
2024-05-24 20:29:51 [INFO]: Epoch 142 - training loss: 9218.4310, validation loss: 0.0975
2024-05-24 20:29:51 [INFO]: Epoch 143 - training loss: 9215.6522, validation loss: 0.0978
2024-05-24 20:29:51 [INFO]: Epoch 144 - training loss: 9217.4457, validation loss: 0.0975
2024-05-24 20:29:51 [INFO]: Epoch 145 - training loss: 9216.9911, validation loss: 0.0953
2024-05-24 20:29:51 [INFO]: Epoch 146 - training loss: 9215.0060, validation loss: 0.0982
2024-05-24 20:29:51 [INFO]: Epoch 147 - training loss: 9216.4794, validation loss: 0.0973
2024-05-24 20:29:51 [INFO]: Epoch 148 - training loss: 9215.6464, validation loss: 0.0972
2024-05-24 20:29:52 [INFO]: Epoch 149 - training loss: 9217.1967, validation loss: 0.0948
2024-05-24 20:29:52 [INFO]: Epoch 150 - training loss: 9215.8432, validation loss: 0.0961
2024-05-24 20:29:52 [INFO]: Epoch 151 - training loss: 9217.1829, validation loss: 0.0940
2024-05-24 20:29:52 [INFO]: Epoch 152 - training loss: 9214.8645, validation loss: 0.0942
2024-05-24 20:29:52 [INFO]: Epoch 153 - training loss: 9215.7267, validation loss: 0.0940
2024-05-24 20:29:52 [INFO]: Epoch 154 - training loss: 9215.6482, validation loss: 0.0944
2024-05-24 20:29:52 [INFO]: Epoch 155 - training loss: 9216.9447, validation loss: 0.0948
2024-05-24 20:29:52 [INFO]: Epoch 156 - training loss: 9215.6460, validation loss: 0.0913
2024-05-24 20:29:52 [INFO]: Epoch 157 - training loss: 9216.6210, validation loss: 0.0928
2024-05-24 20:29:52 [INFO]: Epoch 158 - training loss: 9213.9169, validation loss: 0.0929
2024-05-24 20:29:53 [INFO]: Epoch 159 - training loss: 9213.9825, validation loss: 0.0919
2024-05-24 20:29:53 [INFO]: Epoch 160 - training loss: 9215.0382, validation loss: 0.0924
2024-05-24 20:29:53 [INFO]: Epoch 161 - training loss: 9215.6519, validation loss: 0.0936
2024-05-24 20:29:53 [INFO]: Epoch 162 - training loss: 9212.9377, validation loss: 0.0913
2024-05-24 20:29:53 [INFO]: Epoch 163 - training loss: 9214.3069, validation loss: 0.0925
2024-05-24 20:29:53 [INFO]: Epoch 164 - training loss: 9214.7433, validation loss: 0.0909
2024-05-24 20:29:53 [INFO]: Epoch 165 - training loss: 9213.1143, validation loss: 0.0935
2024-05-24 20:29:53 [INFO]: Epoch 166 - training loss: 9213.5037, validation loss: 0.0911
2024-05-24 20:29:53 [INFO]: Epoch 167 - training loss: 9212.0786, validation loss: 0.0924
2024-05-24 20:29:54 [INFO]: Epoch 168 - training loss: 9212.5905, validation loss: 0.0910
2024-05-24 20:29:54 [INFO]: Epoch 169 - training loss: 9212.4677, validation loss: 0.0907
2024-05-24 20:29:54 [INFO]: Epoch 170 - training loss: 9212.6913, validation loss: 0.0908
2024-05-24 20:29:54 [INFO]: Epoch 171 - training loss: 9216.9381, validation loss: 0.0921
2024-05-24 20:29:54 [INFO]: Epoch 172 - training loss: 9213.1326, validation loss: 0.0900
2024-05-24 20:29:54 [INFO]: Epoch 173 - training loss: 9214.0794, validation loss: 0.0892
2024-05-24 20:29:54 [INFO]: Epoch 174 - training loss: 9212.8365, validation loss: 0.0905
2024-05-24 20:29:54 [INFO]: Epoch 175 - training loss: 9212.7902, validation loss: 0.0898
2024-05-24 20:29:54 [INFO]: Epoch 176 - training loss: 9213.5134, validation loss: 0.0898
2024-05-24 20:29:55 [INFO]: Epoch 177 - training loss: 9214.1352, validation loss: 0.0927
2024-05-24 20:29:55 [INFO]: Epoch 178 - training loss: 9215.8625, validation loss: 0.0891
2024-05-24 20:29:55 [INFO]: Epoch 179 - training loss: 9214.4780, validation loss: 0.0910
2024-05-24 20:29:55 [INFO]: Epoch 180 - training loss: 9213.8565, validation loss: 0.0906
2024-05-24 20:29:55 [INFO]: Epoch 181 - training loss: 9213.4954, validation loss: 0.0893
2024-05-24 20:29:55 [INFO]: Epoch 182 - training loss: 9213.1484, validation loss: 0.0893
2024-05-24 20:29:55 [INFO]: Epoch 183 - training loss: 9211.1840, validation loss: 0.0889
2024-05-24 20:29:55 [INFO]: Epoch 184 - training loss: 9213.7772, validation loss: 0.0895
2024-05-24 20:29:55 [INFO]: Epoch 185 - training loss: 9211.8251, validation loss: 0.0888
2024-05-24 20:29:56 [INFO]: Epoch 186 - training loss: 9212.3348, validation loss: 0.0885
2024-05-24 20:29:56 [INFO]: Epoch 187 - training loss: 9210.8691, validation loss: 0.0872
2024-05-24 20:29:56 [INFO]: Epoch 188 - training loss: 9211.2212, validation loss: 0.0888
2024-05-24 20:29:56 [INFO]: Epoch 189 - training loss: 9211.0505, validation loss: 0.0879
2024-05-24 20:29:56 [INFO]: Epoch 190 - training loss: 9211.5908, validation loss: 0.0889
2024-05-24 20:29:56 [INFO]: Epoch 191 - training loss: 9213.9270, validation loss: 0.0875
2024-05-24 20:29:56 [INFO]: Epoch 192 - training loss: 9210.9499, validation loss: 0.0888
2024-05-24 20:29:56 [INFO]: Epoch 193 - training loss: 9210.7650, validation loss: 0.0888
2024-05-24 20:29:56 [INFO]: Epoch 194 - training loss: 9209.8633, validation loss: 0.0871
2024-05-24 20:29:57 [INFO]: Epoch 195 - training loss: 9213.0918, validation loss: 0.0867
2024-05-24 20:29:57 [INFO]: Epoch 196 - training loss: 9211.8051, validation loss: 0.0880
2024-05-24 20:29:57 [INFO]: Epoch 197 - training loss: 9211.0592, validation loss: 0.0878
2024-05-24 20:29:57 [INFO]: Epoch 198 - training loss: 9212.7480, validation loss: 0.0861
2024-05-24 20:29:57 [INFO]: Epoch 199 - training loss: 9210.4994, validation loss: 0.0885
2024-05-24 20:29:57 [INFO]: Epoch 200 - training loss: 9210.4448, validation loss: 0.0876
2024-05-24 20:29:57 [INFO]: Epoch 201 - training loss: 9208.9480, validation loss: 0.0869
2024-05-24 20:29:57 [INFO]: Epoch 202 - training loss: 9210.5448, validation loss: 0.0879
2024-05-24 20:29:58 [INFO]: Epoch 203 - training loss: 9210.7560, validation loss: 0.0862
2024-05-24 20:29:58 [INFO]: Epoch 204 - training loss: 9209.8729, validation loss: 0.0859
2024-05-24 20:29:58 [INFO]: Epoch 205 - training loss: 9209.1439, validation loss: 0.0850
2024-05-24 20:29:58 [INFO]: Epoch 206 - training loss: 9209.4563, validation loss: 0.0861
2024-05-24 20:29:58 [INFO]: Epoch 207 - training loss: 9209.4681, validation loss: 0.0848
2024-05-24 20:29:58 [INFO]: Epoch 208 - training loss: 9210.9982, validation loss: 0.0845
2024-05-24 20:29:58 [INFO]: Epoch 209 - training loss: 9210.0406, validation loss: 0.0837
2024-05-24 20:29:58 [INFO]: Epoch 210 - training loss: 9209.4716, validation loss: 0.0852
2024-05-24 20:29:58 [INFO]: Epoch 211 - training loss: 9208.9810, validation loss: 0.0862
2024-05-24 20:29:58 [INFO]: Epoch 212 - training loss: 9210.3139, validation loss: 0.0866
2024-05-24 20:29:59 [INFO]: Epoch 213 - training loss: 9209.5248, validation loss: 0.0874
2024-05-24 20:29:59 [INFO]: Epoch 214 - training loss: 9210.1191, validation loss: 0.0862
2024-05-24 20:29:59 [INFO]: Epoch 215 - training loss: 9208.5118, validation loss: 0.0871
2024-05-24 20:29:59 [INFO]: Epoch 216 - training loss: 9209.6561, validation loss: 0.0845
2024-05-24 20:29:59 [INFO]: Epoch 217 - training loss: 9209.8506, validation loss: 0.0851
2024-05-24 20:29:59 [INFO]: Epoch 218 - training loss: 9209.6944, validation loss: 0.0859
2024-05-24 20:29:59 [INFO]: Epoch 219 - training loss: 9209.6320, validation loss: 0.0848
2024-05-24 20:29:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:29:59 [INFO]: Finished training. The best model is from epoch#209.
2024-05-24 20:29:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/GPVAE_ettm1/20240524_T202935/GPVAE.pypots
2024-05-24 20:29:59 [INFO]: GP-VAE on ETTm1: MAE=0.2813, MSE=0.1708
2024-05-24 20:29:59 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/GPVAE_ettm1/imputation.pkl
2024-05-24 20:29:59 [INFO]: Using the given device: cuda:0
2024-05-24 20:29:59 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T202959
2024-05-24 20:29:59 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T202959/tensorboard
2024-05-24 20:29:59 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 20:30:07 [INFO]: Epoch 001 - generator training loss: 0.4767, discriminator training loss: 0.5439, validation loss: 0.3626
2024-05-24 20:30:14 [INFO]: Epoch 002 - generator training loss: -0.0410, discriminator training loss: 0.4765, validation loss: 0.1291
2024-05-24 20:30:21 [INFO]: Epoch 003 - generator training loss: -0.1543, discriminator training loss: 0.4350, validation loss: 0.0731
2024-05-24 20:30:28 [INFO]: Epoch 004 - generator training loss: -0.1459, discriminator training loss: 0.3702, validation loss: 0.0593
2024-05-24 20:30:35 [INFO]: Epoch 005 - generator training loss: -0.1062, discriminator training loss: 0.2944, validation loss: 0.0492
2024-05-24 20:30:42 [INFO]: Epoch 006 - generator training loss: -0.0794, discriminator training loss: 0.2381, validation loss: 0.0469
2024-05-24 20:30:49 [INFO]: Epoch 007 - generator training loss: -0.0568, discriminator training loss: 0.2017, validation loss: 0.0428
2024-05-24 20:30:56 [INFO]: Epoch 008 - generator training loss: -0.0548, discriminator training loss: 0.1895, validation loss: 0.0410
2024-05-24 20:31:03 [INFO]: Epoch 009 - generator training loss: -0.0537, discriminator training loss: 0.1834, validation loss: 0.0408
2024-05-24 20:31:10 [INFO]: Epoch 010 - generator training loss: -0.0535, discriminator training loss: 0.1775, validation loss: 0.0386
2024-05-24 20:31:17 [INFO]: Epoch 011 - generator training loss: -0.0570, discriminator training loss: 0.1767, validation loss: 0.0375
2024-05-24 20:31:24 [INFO]: Epoch 012 - generator training loss: -0.0556, discriminator training loss: 0.1740, validation loss: 0.0362
2024-05-24 20:31:31 [INFO]: Epoch 013 - generator training loss: -0.0532, discriminator training loss: 0.1739, validation loss: 0.0362
2024-05-24 20:31:38 [INFO]: Epoch 014 - generator training loss: -0.0574, discriminator training loss: 0.1735, validation loss: 0.0350
2024-05-24 20:31:45 [INFO]: Epoch 015 - generator training loss: -0.0548, discriminator training loss: 0.1734, validation loss: 0.0341
2024-05-24 20:31:52 [INFO]: Epoch 016 - generator training loss: -0.0543, discriminator training loss: 0.1742, validation loss: 0.0355
2024-05-24 20:31:59 [INFO]: Epoch 017 - generator training loss: -0.0588, discriminator training loss: 0.1714, validation loss: 0.0332
2024-05-24 20:32:06 [INFO]: Epoch 018 - generator training loss: -0.0575, discriminator training loss: 0.1723, validation loss: 0.0343
2024-05-24 20:32:14 [INFO]: Epoch 019 - generator training loss: -0.0558, discriminator training loss: 0.1687, validation loss: 0.0326
2024-05-24 20:32:20 [INFO]: Epoch 020 - generator training loss: -0.0611, discriminator training loss: 0.1703, validation loss: 0.0345
2024-05-24 20:32:27 [INFO]: Epoch 021 - generator training loss: -0.0527, discriminator training loss: 0.1699, validation loss: 0.0350
2024-05-24 20:32:34 [INFO]: Epoch 022 - generator training loss: -0.0593, discriminator training loss: 0.1710, validation loss: 0.0333
2024-05-24 20:32:41 [INFO]: Epoch 023 - generator training loss: -0.0531, discriminator training loss: 0.1689, validation loss: 0.0335
2024-05-24 20:32:48 [INFO]: Epoch 024 - generator training loss: -0.0591, discriminator training loss: 0.1707, validation loss: 0.0329
2024-05-24 20:32:55 [INFO]: Epoch 025 - generator training loss: -0.0595, discriminator training loss: 0.1700, validation loss: 0.0310
2024-05-24 20:33:02 [INFO]: Epoch 026 - generator training loss: -0.0609, discriminator training loss: 0.1686, validation loss: 0.0313
2024-05-24 20:33:09 [INFO]: Epoch 027 - generator training loss: -0.0600, discriminator training loss: 0.1684, validation loss: 0.0307
2024-05-24 20:33:16 [INFO]: Epoch 028 - generator training loss: -0.0610, discriminator training loss: 0.1705, validation loss: 0.0313
2024-05-24 20:33:23 [INFO]: Epoch 029 - generator training loss: -0.0628, discriminator training loss: 0.1691, validation loss: 0.0307
2024-05-24 20:33:30 [INFO]: Epoch 030 - generator training loss: -0.0630, discriminator training loss: 0.1680, validation loss: 0.0301
2024-05-24 20:33:37 [INFO]: Epoch 031 - generator training loss: -0.0601, discriminator training loss: 0.1697, validation loss: 0.0308
2024-05-24 20:33:44 [INFO]: Epoch 032 - generator training loss: -0.0591, discriminator training loss: 0.1695, validation loss: 0.0307
2024-05-24 20:33:51 [INFO]: Epoch 033 - generator training loss: -0.0586, discriminator training loss: 0.1671, validation loss: 0.0309
2024-05-24 20:33:58 [INFO]: Epoch 034 - generator training loss: -0.0604, discriminator training loss: 0.1667, validation loss: 0.0309
2024-05-24 20:34:05 [INFO]: Epoch 035 - generator training loss: -0.0631, discriminator training loss: 0.1682, validation loss: 0.0293
2024-05-24 20:34:12 [INFO]: Epoch 036 - generator training loss: -0.0605, discriminator training loss: 0.1676, validation loss: 0.0293
2024-05-24 20:34:19 [INFO]: Epoch 037 - generator training loss: -0.0607, discriminator training loss: 0.1666, validation loss: 0.0299
2024-05-24 20:34:26 [INFO]: Epoch 038 - generator training loss: -0.0645, discriminator training loss: 0.1687, validation loss: 0.0313
2024-05-24 20:34:34 [INFO]: Epoch 039 - generator training loss: -0.0633, discriminator training loss: 0.1678, validation loss: 0.0298
2024-05-24 20:34:41 [INFO]: Epoch 040 - generator training loss: -0.0652, discriminator training loss: 0.1644, validation loss: 0.0300
2024-05-24 20:34:48 [INFO]: Epoch 041 - generator training loss: -0.0641, discriminator training loss: 0.1661, validation loss: 0.0291
2024-05-24 20:34:55 [INFO]: Epoch 042 - generator training loss: -0.0629, discriminator training loss: 0.1651, validation loss: 0.0296
2024-05-24 20:35:02 [INFO]: Epoch 043 - generator training loss: -0.0656, discriminator training loss: 0.1659, validation loss: 0.0287
2024-05-24 20:35:09 [INFO]: Epoch 044 - generator training loss: -0.0646, discriminator training loss: 0.1671, validation loss: 0.0293
2024-05-24 20:35:15 [INFO]: Epoch 045 - generator training loss: -0.0650, discriminator training loss: 0.1664, validation loss: 0.0297
2024-05-24 20:35:23 [INFO]: Epoch 046 - generator training loss: -0.0664, discriminator training loss: 0.1653, validation loss: 0.0290
2024-05-24 20:35:29 [INFO]: Epoch 047 - generator training loss: -0.0665, discriminator training loss: 0.1675, validation loss: 0.0287
2024-05-24 20:35:36 [INFO]: Epoch 048 - generator training loss: -0.0668, discriminator training loss: 0.1680, validation loss: 0.0295
2024-05-24 20:35:43 [INFO]: Epoch 049 - generator training loss: -0.0647, discriminator training loss: 0.1675, validation loss: 0.0291
2024-05-24 20:35:50 [INFO]: Epoch 050 - generator training loss: -0.0640, discriminator training loss: 0.1668, validation loss: 0.0288
2024-05-24 20:35:57 [INFO]: Epoch 051 - generator training loss: -0.0651, discriminator training loss: 0.1671, validation loss: 0.0286
2024-05-24 20:36:04 [INFO]: Epoch 052 - generator training loss: -0.0666, discriminator training loss: 0.1642, validation loss: 0.0287
2024-05-24 20:36:11 [INFO]: Epoch 053 - generator training loss: -0.0677, discriminator training loss: 0.1651, validation loss: 0.0280
2024-05-24 20:36:18 [INFO]: Epoch 054 - generator training loss: -0.0632, discriminator training loss: 0.1663, validation loss: 0.0275
2024-05-24 20:36:26 [INFO]: Epoch 055 - generator training loss: -0.0632, discriminator training loss: 0.1641, validation loss: 0.0286
2024-05-24 20:36:33 [INFO]: Epoch 056 - generator training loss: -0.0703, discriminator training loss: 0.1662, validation loss: 0.0278
2024-05-24 20:36:40 [INFO]: Epoch 057 - generator training loss: -0.0653, discriminator training loss: 0.1630, validation loss: 0.0281
2024-05-24 20:36:47 [INFO]: Epoch 058 - generator training loss: -0.0676, discriminator training loss: 0.1627, validation loss: 0.0281
2024-05-24 20:36:54 [INFO]: Epoch 059 - generator training loss: -0.0675, discriminator training loss: 0.1673, validation loss: 0.0272
2024-05-24 20:37:01 [INFO]: Epoch 060 - generator training loss: -0.0664, discriminator training loss: 0.1638, validation loss: 0.0284
2024-05-24 20:37:08 [INFO]: Epoch 061 - generator training loss: -0.0679, discriminator training loss: 0.1641, validation loss: 0.0269
2024-05-24 20:37:15 [INFO]: Epoch 062 - generator training loss: -0.0668, discriminator training loss: 0.1639, validation loss: 0.0278
2024-05-24 20:37:22 [INFO]: Epoch 063 - generator training loss: -0.0679, discriminator training loss: 0.1648, validation loss: 0.0273
2024-05-24 20:37:29 [INFO]: Epoch 064 - generator training loss: -0.0647, discriminator training loss: 0.1623, validation loss: 0.0281
2024-05-24 20:37:36 [INFO]: Epoch 065 - generator training loss: -0.0673, discriminator training loss: 0.1644, validation loss: 0.0267
2024-05-24 20:37:43 [INFO]: Epoch 066 - generator training loss: -0.0654, discriminator training loss: 0.1639, validation loss: 0.0294
2024-05-24 20:37:50 [INFO]: Epoch 067 - generator training loss: -0.0685, discriminator training loss: 0.1654, validation loss: 0.0271
2024-05-24 20:37:57 [INFO]: Epoch 068 - generator training loss: -0.0662, discriminator training loss: 0.1623, validation loss: 0.0285
2024-05-24 20:38:04 [INFO]: Epoch 069 - generator training loss: -0.0709, discriminator training loss: 0.1612, validation loss: 0.0309
2024-05-24 20:38:11 [INFO]: Epoch 070 - generator training loss: -0.0638, discriminator training loss: 0.1621, validation loss: 0.0277
2024-05-24 20:38:18 [INFO]: Epoch 071 - generator training loss: -0.0653, discriminator training loss: 0.1647, validation loss: 0.0269
2024-05-24 20:38:25 [INFO]: Epoch 072 - generator training loss: -0.0686, discriminator training loss: 0.1619, validation loss: 0.0267
2024-05-24 20:38:32 [INFO]: Epoch 073 - generator training loss: -0.0651, discriminator training loss: 0.1630, validation loss: 0.0268
2024-05-24 20:38:39 [INFO]: Epoch 074 - generator training loss: -0.0660, discriminator training loss: 0.1621, validation loss: 0.0267
2024-05-24 20:38:46 [INFO]: Epoch 075 - generator training loss: -0.0704, discriminator training loss: 0.1630, validation loss: 0.0276
2024-05-24 20:38:53 [INFO]: Epoch 076 - generator training loss: -0.0668, discriminator training loss: 0.1663, validation loss: 0.0308
2024-05-24 20:39:00 [INFO]: Epoch 077 - generator training loss: -0.0625, discriminator training loss: 0.1617, validation loss: 0.0277
2024-05-24 20:39:07 [INFO]: Epoch 078 - generator training loss: -0.0678, discriminator training loss: 0.1617, validation loss: 0.0287
2024-05-24 20:39:14 [INFO]: Epoch 079 - generator training loss: -0.0631, discriminator training loss: 0.1652, validation loss: 0.0291
2024-05-24 20:39:21 [INFO]: Epoch 080 - generator training loss: -0.0616, discriminator training loss: 0.1634, validation loss: 0.0270
2024-05-24 20:39:28 [INFO]: Epoch 081 - generator training loss: -0.0676, discriminator training loss: 0.1614, validation loss: 0.0269
2024-05-24 20:39:35 [INFO]: Epoch 082 - generator training loss: -0.0656, discriminator training loss: 0.1614, validation loss: 0.0273
2024-05-24 20:39:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:39:35 [INFO]: Finished training. The best model is from epoch#72.
2024-05-24 20:39:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/USGAN_ettm1/20240524_T202959/USGAN.pypots
2024-05-24 20:39:36 [INFO]: US-GAN on ETTm1: MAE=0.1580, MSE=0.0633
2024-05-24 20:39:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/USGAN_ettm1/imputation.pkl
2024-05-24 20:39:36 [INFO]: Using the given device: cuda:0
2024-05-24 20:39:36 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T203936
2024-05-24 20:39:36 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T203936/tensorboard
2024-05-24 20:39:36 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 20:39:41 [INFO]: Epoch 001 - training loss: 1.3319, validation loss: 0.3460
2024-05-24 20:39:46 [INFO]: Epoch 002 - training loss: 0.9252, validation loss: 0.0946
2024-05-24 20:39:51 [INFO]: Epoch 003 - training loss: 0.7421, validation loss: 0.0587
2024-05-24 20:39:55 [INFO]: Epoch 004 - training loss: 0.6635, validation loss: 0.0478
2024-05-24 20:40:00 [INFO]: Epoch 005 - training loss: 0.6281, validation loss: 0.0425
2024-05-24 20:40:04 [INFO]: Epoch 006 - training loss: 0.5808, validation loss: 0.0383
2024-05-24 20:40:09 [INFO]: Epoch 007 - training loss: 0.5520, validation loss: 0.0368
2024-05-24 20:40:14 [INFO]: Epoch 008 - training loss: 0.5234, validation loss: 0.0362
2024-05-24 20:40:18 [INFO]: Epoch 009 - training loss: 0.5082, validation loss: 0.0339
2024-05-24 20:40:23 [INFO]: Epoch 010 - training loss: 0.4866, validation loss: 0.0352
2024-05-24 20:40:27 [INFO]: Epoch 011 - training loss: 0.4710, validation loss: 0.0308
2024-05-24 20:40:32 [INFO]: Epoch 012 - training loss: 0.4483, validation loss: 0.0296
2024-05-24 20:40:36 [INFO]: Epoch 013 - training loss: 0.4363, validation loss: 0.0282
2024-05-24 20:40:41 [INFO]: Epoch 014 - training loss: 0.4267, validation loss: 0.0276
2024-05-24 20:40:46 [INFO]: Epoch 015 - training loss: 0.4253, validation loss: 0.0263
2024-05-24 20:40:50 [INFO]: Epoch 016 - training loss: 0.4244, validation loss: 0.0264
2024-05-24 20:40:55 [INFO]: Epoch 017 - training loss: 0.4152, validation loss: 0.0263
2024-05-24 20:41:00 [INFO]: Epoch 018 - training loss: 0.4125, validation loss: 0.0260
2024-05-24 20:41:04 [INFO]: Epoch 019 - training loss: 0.4107, validation loss: 0.0269
2024-05-24 20:41:09 [INFO]: Epoch 020 - training loss: 0.4071, validation loss: 0.0260
2024-05-24 20:41:13 [INFO]: Epoch 021 - training loss: 0.4098, validation loss: 0.0258
2024-05-24 20:41:18 [INFO]: Epoch 022 - training loss: 0.4051, validation loss: 0.0264
2024-05-24 20:41:23 [INFO]: Epoch 023 - training loss: 0.4040, validation loss: 0.0257
2024-05-24 20:41:27 [INFO]: Epoch 024 - training loss: 0.4040, validation loss: 0.0259
2024-05-24 20:41:32 [INFO]: Epoch 025 - training loss: 0.4018, validation loss: 0.0273
2024-05-24 20:41:36 [INFO]: Epoch 026 - training loss: 0.4099, validation loss: 0.0255
2024-05-24 20:41:41 [INFO]: Epoch 027 - training loss: 0.4051, validation loss: 0.0262
2024-05-24 20:41:46 [INFO]: Epoch 028 - training loss: 0.3982, validation loss: 0.0257
2024-05-24 20:41:50 [INFO]: Epoch 029 - training loss: 0.3938, validation loss: 0.0248
2024-05-24 20:41:55 [INFO]: Epoch 030 - training loss: 0.3955, validation loss: 0.0255
2024-05-24 20:42:00 [INFO]: Epoch 031 - training loss: 0.3955, validation loss: 0.0249
2024-05-24 20:42:04 [INFO]: Epoch 032 - training loss: 0.4026, validation loss: 0.0256
2024-05-24 20:42:09 [INFO]: Epoch 033 - training loss: 0.3991, validation loss: 0.0251
2024-05-24 20:42:13 [INFO]: Epoch 034 - training loss: 0.3987, validation loss: 0.0243
2024-05-24 20:42:18 [INFO]: Epoch 035 - training loss: 0.3925, validation loss: 0.0253
2024-05-24 20:42:23 [INFO]: Epoch 036 - training loss: 0.4014, validation loss: 0.0259
2024-05-24 20:42:27 [INFO]: Epoch 037 - training loss: 0.3922, validation loss: 0.0258
2024-05-24 20:42:32 [INFO]: Epoch 038 - training loss: 0.3954, validation loss: 0.0264
2024-05-24 20:42:36 [INFO]: Epoch 039 - training loss: 0.3905, validation loss: 0.0251
2024-05-24 20:42:41 [INFO]: Epoch 040 - training loss: 0.3966, validation loss: 0.0253
2024-05-24 20:42:46 [INFO]: Epoch 041 - training loss: 0.3896, validation loss: 0.0255
2024-05-24 20:42:50 [INFO]: Epoch 042 - training loss: 0.3946, validation loss: 0.0253
2024-05-24 20:42:55 [INFO]: Epoch 043 - training loss: 0.3867, validation loss: 0.0257
2024-05-24 20:42:59 [INFO]: Epoch 044 - training loss: 0.3893, validation loss: 0.0266
2024-05-24 20:42:59 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:42:59 [INFO]: Finished training. The best model is from epoch#34.
2024-05-24 20:42:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/BRITS_ettm1/20240524_T203936/BRITS.pypots
2024-05-24 20:43:00 [INFO]: BRITS on ETTm1: MAE=0.1494, MSE=0.0638
2024-05-24 20:43:00 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/BRITS_ettm1/imputation.pkl
2024-05-24 20:43:00 [INFO]: Using the given device: cuda:0
2024-05-24 20:43:00 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300
2024-05-24 20:43:00 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/tensorboard
2024-05-24 20:43:00 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 20:43:01 [INFO]: Epoch 001 - training loss: 1.3554, validation loss: 1.3494
2024-05-24 20:43:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch1_loss1.349394530057907.pypots
2024-05-24 20:43:01 [INFO]: Epoch 002 - training loss: 0.9986, validation loss: 1.1956
2024-05-24 20:43:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch2_loss1.1956254988908768.pypots
2024-05-24 20:43:02 [INFO]: Epoch 003 - training loss: 0.9611, validation loss: 1.1099
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch3_loss1.1099129915237427.pypots
2024-05-24 20:43:02 [INFO]: Epoch 004 - training loss: 0.8967, validation loss: 1.0664
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch4_loss1.0664017498493195.pypots
2024-05-24 20:43:02 [INFO]: Epoch 005 - training loss: 0.8797, validation loss: 1.0520
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch5_loss1.0519780963659286.pypots
2024-05-24 20:43:02 [INFO]: Epoch 006 - training loss: 0.8713, validation loss: 1.0386
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch6_loss1.0385627299547195.pypots
2024-05-24 20:43:02 [INFO]: Epoch 007 - training loss: 0.8543, validation loss: 1.0304
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch7_loss1.030436784029007.pypots
2024-05-24 20:43:02 [INFO]: Epoch 008 - training loss: 0.8699, validation loss: 1.0261
2024-05-24 20:43:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch8_loss1.026135876774788.pypots
2024-05-24 20:43:03 [INFO]: Epoch 009 - training loss: 0.8690, validation loss: 1.0274
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch9_loss1.0274169147014618.pypots
2024-05-24 20:43:03 [INFO]: Epoch 010 - training loss: 0.8701, validation loss: 1.0251
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch10_loss1.025115266442299.pypots
2024-05-24 20:43:03 [INFO]: Epoch 011 - training loss: 0.8469, validation loss: 1.0243
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch11_loss1.0243214666843414.pypots
2024-05-24 20:43:03 [INFO]: Epoch 012 - training loss: 0.8343, validation loss: 1.0233
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch12_loss1.0232978463172913.pypots
2024-05-24 20:43:03 [INFO]: Epoch 013 - training loss: 0.8337, validation loss: 1.0191
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch13_loss1.0191463977098465.pypots
2024-05-24 20:43:03 [INFO]: Epoch 014 - training loss: 0.8601, validation loss: 1.0178
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch14_loss1.0178145468235016.pypots
2024-05-24 20:43:03 [INFO]: Epoch 015 - training loss: 0.8082, validation loss: 1.0175
2024-05-24 20:43:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch15_loss1.0175205171108246.pypots
2024-05-24 20:43:04 [INFO]: Epoch 016 - training loss: 0.8103, validation loss: 1.0141
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch16_loss1.014147236943245.pypots
2024-05-24 20:43:04 [INFO]: Epoch 017 - training loss: 0.8207, validation loss: 1.0117
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch17_loss1.0116803497076035.pypots
2024-05-24 20:43:04 [INFO]: Epoch 018 - training loss: 0.7952, validation loss: 1.0117
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch18_loss1.0116573423147202.pypots
2024-05-24 20:43:04 [INFO]: Epoch 019 - training loss: 0.8032, validation loss: 1.0110
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch19_loss1.0110064595937729.pypots
2024-05-24 20:43:04 [INFO]: Epoch 020 - training loss: 0.8131, validation loss: 1.0132
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch20_loss1.0132185965776443.pypots
2024-05-24 20:43:04 [INFO]: Epoch 021 - training loss: 0.7957, validation loss: 1.0114
2024-05-24 20:43:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch21_loss1.0113999396562576.pypots
2024-05-24 20:43:05 [INFO]: Epoch 022 - training loss: 0.8224, validation loss: 1.0056
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch22_loss1.005551129579544.pypots
2024-05-24 20:43:05 [INFO]: Epoch 023 - training loss: 0.8235, validation loss: 1.0081
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch23_loss1.008097842335701.pypots
2024-05-24 20:43:05 [INFO]: Epoch 024 - training loss: 0.7900, validation loss: 1.0044
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch24_loss1.0043828338384628.pypots
2024-05-24 20:43:05 [INFO]: Epoch 025 - training loss: 0.7996, validation loss: 1.0057
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch25_loss1.0057177543640137.pypots
2024-05-24 20:43:05 [INFO]: Epoch 026 - training loss: 0.8044, validation loss: 1.0021
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch26_loss1.0021368712186813.pypots
2024-05-24 20:43:05 [INFO]: Epoch 027 - training loss: 0.7642, validation loss: 1.0002
2024-05-24 20:43:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch27_loss1.0002489984035492.pypots
2024-05-24 20:43:06 [INFO]: Epoch 028 - training loss: 0.7671, validation loss: 0.9982
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch28_loss0.9982360005378723.pypots
2024-05-24 20:43:06 [INFO]: Epoch 029 - training loss: 0.7554, validation loss: 0.9955
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch29_loss0.9954865425825119.pypots
2024-05-24 20:43:06 [INFO]: Epoch 030 - training loss: 0.7719, validation loss: 0.9923
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch30_loss0.99233278632164.pypots
2024-05-24 20:43:06 [INFO]: Epoch 031 - training loss: 0.7730, validation loss: 0.9915
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch31_loss0.9915348440408707.pypots
2024-05-24 20:43:06 [INFO]: Epoch 032 - training loss: 0.7859, validation loss: 0.9865
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch32_loss0.9864788800477982.pypots
2024-05-24 20:43:06 [INFO]: Epoch 033 - training loss: 0.7711, validation loss: 0.9847
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch33_loss0.9846726506948471.pypots
2024-05-24 20:43:06 [INFO]: Epoch 034 - training loss: 0.7904, validation loss: 0.9780
2024-05-24 20:43:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch34_loss0.9779709577560425.pypots
2024-05-24 20:43:07 [INFO]: Epoch 035 - training loss: 0.7684, validation loss: 0.9786
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch35_loss0.9785580784082413.pypots
2024-05-24 20:43:07 [INFO]: Epoch 036 - training loss: 0.7703, validation loss: 0.9732
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch36_loss0.9731954485177994.pypots
2024-05-24 20:43:07 [INFO]: Epoch 037 - training loss: 0.7488, validation loss: 0.9729
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch37_loss0.9729293137788773.pypots
2024-05-24 20:43:07 [INFO]: Epoch 038 - training loss: 0.7457, validation loss: 0.9674
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch38_loss0.9674143642187119.pypots
2024-05-24 20:43:07 [INFO]: Epoch 039 - training loss: 0.7668, validation loss: 0.9641
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch39_loss0.9640880525112152.pypots
2024-05-24 20:43:07 [INFO]: Epoch 040 - training loss: 0.7832, validation loss: 0.9646
2024-05-24 20:43:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch40_loss0.9645896404981613.pypots
2024-05-24 20:43:08 [INFO]: Epoch 041 - training loss: 0.7674, validation loss: 0.9609
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch41_loss0.9609074890613556.pypots
2024-05-24 20:43:08 [INFO]: Epoch 042 - training loss: 0.7481, validation loss: 0.9574
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch42_loss0.9573546350002289.pypots
2024-05-24 20:43:08 [INFO]: Epoch 043 - training loss: 0.7623, validation loss: 0.9561
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch43_loss0.9561063349246979.pypots
2024-05-24 20:43:08 [INFO]: Epoch 044 - training loss: 0.7515, validation loss: 0.9550
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch44_loss0.9549641013145447.pypots
2024-05-24 20:43:08 [INFO]: Epoch 045 - training loss: 0.7295, validation loss: 0.9508
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch45_loss0.9507620632648468.pypots
2024-05-24 20:43:08 [INFO]: Epoch 046 - training loss: 0.7865, validation loss: 0.9469
2024-05-24 20:43:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch46_loss0.9468674957752228.pypots
2024-05-24 20:43:09 [INFO]: Epoch 047 - training loss: 0.7572, validation loss: 0.9458
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch47_loss0.9458185881376266.pypots
2024-05-24 20:43:09 [INFO]: Epoch 048 - training loss: 0.7984, validation loss: 0.9417
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch48_loss0.9417081624269485.pypots
2024-05-24 20:43:09 [INFO]: Epoch 049 - training loss: 0.7593, validation loss: 0.9367
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch49_loss0.9367421120405197.pypots
2024-05-24 20:43:09 [INFO]: Epoch 050 - training loss: 0.7433, validation loss: 0.9401
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch50_loss0.9400780946016312.pypots
2024-05-24 20:43:09 [INFO]: Epoch 051 - training loss: 0.7328, validation loss: 0.9391
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch51_loss0.9391094595193863.pypots
2024-05-24 20:43:09 [INFO]: Epoch 052 - training loss: 0.7427, validation loss: 0.9384
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch52_loss0.9384266883134842.pypots
2024-05-24 20:43:09 [INFO]: Epoch 053 - training loss: 0.7310, validation loss: 0.9384
2024-05-24 20:43:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch53_loss0.9383656084537506.pypots
2024-05-24 20:43:10 [INFO]: Epoch 054 - training loss: 0.7377, validation loss: 0.9365
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch54_loss0.9364641755819321.pypots
2024-05-24 20:43:10 [INFO]: Epoch 055 - training loss: 0.7405, validation loss: 0.9350
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch55_loss0.9350491911172867.pypots
2024-05-24 20:43:10 [INFO]: Epoch 056 - training loss: 0.7571, validation loss: 0.9343
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch56_loss0.9342506378889084.pypots
2024-05-24 20:43:10 [INFO]: Epoch 057 - training loss: 0.7433, validation loss: 0.9312
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch57_loss0.931223601102829.pypots
2024-05-24 20:43:10 [INFO]: Epoch 058 - training loss: 0.7391, validation loss: 0.9294
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch58_loss0.9294320940971375.pypots
2024-05-24 20:43:10 [INFO]: Epoch 059 - training loss: 0.7559, validation loss: 0.9271
2024-05-24 20:43:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch59_loss0.9271282255649567.pypots
2024-05-24 20:43:11 [INFO]: Epoch 060 - training loss: 0.7324, validation loss: 0.9234
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch60_loss0.9233805537223816.pypots
2024-05-24 20:43:11 [INFO]: Epoch 061 - training loss: 0.7393, validation loss: 0.9209
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch61_loss0.9209395349025726.pypots
2024-05-24 20:43:11 [INFO]: Epoch 062 - training loss: 0.7506, validation loss: 0.9227
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch62_loss0.9226999580860138.pypots
2024-05-24 20:43:11 [INFO]: Epoch 063 - training loss: 0.7501, validation loss: 0.9158
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch63_loss0.9157979786396027.pypots
2024-05-24 20:43:11 [INFO]: Epoch 064 - training loss: 0.7476, validation loss: 0.9225
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch64_loss0.9225254505872726.pypots
2024-05-24 20:43:11 [INFO]: Epoch 065 - training loss: 0.7564, validation loss: 0.9187
2024-05-24 20:43:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch65_loss0.918656587600708.pypots
2024-05-24 20:43:12 [INFO]: Epoch 066 - training loss: 0.7624, validation loss: 0.9154
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch66_loss0.9153723269701004.pypots
2024-05-24 20:43:12 [INFO]: Epoch 067 - training loss: 0.7268, validation loss: 0.9169
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch67_loss0.916860431432724.pypots
2024-05-24 20:43:12 [INFO]: Epoch 068 - training loss: 0.7416, validation loss: 0.9193
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch68_loss0.9192693382501602.pypots
2024-05-24 20:43:12 [INFO]: Epoch 069 - training loss: 0.7628, validation loss: 0.9190
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch69_loss0.918962225317955.pypots
2024-05-24 20:43:12 [INFO]: Epoch 070 - training loss: 0.7522, validation loss: 0.9170
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch70_loss0.9169543832540512.pypots
2024-05-24 20:43:12 [INFO]: Epoch 071 - training loss: 0.7375, validation loss: 0.9182
2024-05-24 20:43:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch71_loss0.9181957542896271.pypots
2024-05-24 20:43:13 [INFO]: Epoch 072 - training loss: 0.7420, validation loss: 0.9171
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch72_loss0.9171341955661774.pypots
2024-05-24 20:43:13 [INFO]: Epoch 073 - training loss: 0.7511, validation loss: 0.9139
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch73_loss0.9138762503862381.pypots
2024-05-24 20:43:13 [INFO]: Epoch 074 - training loss: 0.7419, validation loss: 0.9129
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch74_loss0.9129044562578201.pypots
2024-05-24 20:43:13 [INFO]: Epoch 075 - training loss: 0.7334, validation loss: 0.9130
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch75_loss0.9130286574363708.pypots
2024-05-24 20:43:13 [INFO]: Epoch 076 - training loss: 0.7480, validation loss: 0.9147
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch76_loss0.9147470742464066.pypots
2024-05-24 20:43:13 [INFO]: Epoch 077 - training loss: 0.7637, validation loss: 0.9124
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch77_loss0.9124324321746826.pypots
2024-05-24 20:43:13 [INFO]: Epoch 078 - training loss: 0.7919, validation loss: 0.9139
2024-05-24 20:43:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch78_loss0.9138707518577576.pypots
2024-05-24 20:43:14 [INFO]: Epoch 079 - training loss: 0.7320, validation loss: 0.9078
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch79_loss0.9077959209680557.pypots
2024-05-24 20:43:14 [INFO]: Epoch 080 - training loss: 0.7369, validation loss: 0.9166
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch80_loss0.9165680259466171.pypots
2024-05-24 20:43:14 [INFO]: Epoch 081 - training loss: 0.7364, validation loss: 0.9075
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch81_loss0.907476156949997.pypots
2024-05-24 20:43:14 [INFO]: Epoch 082 - training loss: 0.7379, validation loss: 0.9109
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch82_loss0.9108905643224716.pypots
2024-05-24 20:43:14 [INFO]: Epoch 083 - training loss: 0.7401, validation loss: 0.9075
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch83_loss0.9075492322444916.pypots
2024-05-24 20:43:14 [INFO]: Epoch 084 - training loss: 0.7267, validation loss: 0.9093
2024-05-24 20:43:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch84_loss0.909345954656601.pypots
2024-05-24 20:43:15 [INFO]: Epoch 085 - training loss: 0.7434, validation loss: 0.9125
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch85_loss0.9125047028064728.pypots
2024-05-24 20:43:15 [INFO]: Epoch 086 - training loss: 0.7211, validation loss: 0.9077
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch86_loss0.9076661020517349.pypots
2024-05-24 20:43:15 [INFO]: Epoch 087 - training loss: 0.7362, validation loss: 0.9117
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch87_loss0.9117068350315094.pypots
2024-05-24 20:43:15 [INFO]: Epoch 088 - training loss: 0.7394, validation loss: 0.9088
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch88_loss0.9087620079517365.pypots
2024-05-24 20:43:15 [INFO]: Epoch 089 - training loss: 0.7271, validation loss: 0.9071
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch89_loss0.9071240574121475.pypots
2024-05-24 20:43:15 [INFO]: Epoch 090 - training loss: 0.7246, validation loss: 0.9083
2024-05-24 20:43:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch90_loss0.9082546532154083.pypots
2024-05-24 20:43:16 [INFO]: Epoch 091 - training loss: 0.7174, validation loss: 0.9090
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch91_loss0.9090341925621033.pypots
2024-05-24 20:43:16 [INFO]: Epoch 092 - training loss: 0.7250, validation loss: 0.9039
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch92_loss0.9039346873760223.pypots
2024-05-24 20:43:16 [INFO]: Epoch 093 - training loss: 0.7572, validation loss: 0.9048
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch93_loss0.9048023223876953.pypots
2024-05-24 20:43:16 [INFO]: Epoch 094 - training loss: 0.7181, validation loss: 0.9045
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch94_loss0.9044606238603592.pypots
2024-05-24 20:43:16 [INFO]: Epoch 095 - training loss: 0.7230, validation loss: 0.9059
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch95_loss0.9059264361858368.pypots
2024-05-24 20:43:16 [INFO]: Epoch 096 - training loss: 0.7568, validation loss: 0.9045
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch96_loss0.904505044221878.pypots
2024-05-24 20:43:16 [INFO]: Epoch 097 - training loss: 0.7221, validation loss: 0.9030
2024-05-24 20:43:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch97_loss0.9029724448919296.pypots
2024-05-24 20:43:17 [INFO]: Epoch 098 - training loss: 0.7272, validation loss: 0.9002
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch98_loss0.9002046138048172.pypots
2024-05-24 20:43:17 [INFO]: Epoch 099 - training loss: 0.7455, validation loss: 0.9006
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch99_loss0.9005682915449142.pypots
2024-05-24 20:43:17 [INFO]: Epoch 100 - training loss: 0.7217, validation loss: 0.8995
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch100_loss0.8995462357997894.pypots
2024-05-24 20:43:17 [INFO]: Epoch 101 - training loss: 0.7343, validation loss: 0.8972
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch101_loss0.8972260802984238.pypots
2024-05-24 20:43:17 [INFO]: Epoch 102 - training loss: 0.7264, validation loss: 0.9070
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch102_loss0.9069697856903076.pypots
2024-05-24 20:43:17 [INFO]: Epoch 103 - training loss: 0.7370, validation loss: 0.8944
2024-05-24 20:43:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch103_loss0.8944429308176041.pypots
2024-05-24 20:43:18 [INFO]: Epoch 104 - training loss: 0.7384, validation loss: 0.8979
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch104_loss0.8978623151779175.pypots
2024-05-24 20:43:18 [INFO]: Epoch 105 - training loss: 0.7298, validation loss: 0.8920
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch105_loss0.8919802606105804.pypots
2024-05-24 20:43:18 [INFO]: Epoch 106 - training loss: 0.7561, validation loss: 0.8891
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch106_loss0.8891095221042633.pypots
2024-05-24 20:43:18 [INFO]: Epoch 107 - training loss: 0.7466, validation loss: 0.8878
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch107_loss0.8878083676099777.pypots
2024-05-24 20:43:18 [INFO]: Epoch 108 - training loss: 0.7314, validation loss: 0.8909
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch108_loss0.8908849805593491.pypots
2024-05-24 20:43:18 [INFO]: Epoch 109 - training loss: 0.7235, validation loss: 0.8894
2024-05-24 20:43:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch109_loss0.8893709182739258.pypots
2024-05-24 20:43:19 [INFO]: Epoch 110 - training loss: 0.7193, validation loss: 0.8883
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch110_loss0.8883450627326965.pypots
2024-05-24 20:43:19 [INFO]: Epoch 111 - training loss: 0.7526, validation loss: 0.8863
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch111_loss0.8863498419523239.pypots
2024-05-24 20:43:19 [INFO]: Epoch 112 - training loss: 0.7312, validation loss: 0.8871
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch112_loss0.8870673030614853.pypots
2024-05-24 20:43:19 [INFO]: Epoch 113 - training loss: 0.7062, validation loss: 0.8851
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch113_loss0.8850614130496979.pypots
2024-05-24 20:43:19 [INFO]: Epoch 114 - training loss: 0.6987, validation loss: 0.8871
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch114_loss0.8871249258518219.pypots
2024-05-24 20:43:19 [INFO]: Epoch 115 - training loss: 0.7418, validation loss: 0.8932
2024-05-24 20:43:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch115_loss0.8932376950979233.pypots
2024-05-24 20:43:20 [INFO]: Epoch 116 - training loss: 0.7152, validation loss: 0.8858
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch116_loss0.8858303129673004.pypots
2024-05-24 20:43:20 [INFO]: Epoch 117 - training loss: 0.7220, validation loss: 0.8828
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch117_loss0.8828379660844803.pypots
2024-05-24 20:43:20 [INFO]: Epoch 118 - training loss: 0.7192, validation loss: 0.8849
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch118_loss0.884863406419754.pypots
2024-05-24 20:43:20 [INFO]: Epoch 119 - training loss: 0.7198, validation loss: 0.8803
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch119_loss0.8803286552429199.pypots
2024-05-24 20:43:20 [INFO]: Epoch 120 - training loss: 0.7271, validation loss: 0.8831
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch120_loss0.8831220716238022.pypots
2024-05-24 20:43:20 [INFO]: Epoch 121 - training loss: 0.7193, validation loss: 0.8814
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch121_loss0.8813739269971848.pypots
2024-05-24 20:43:20 [INFO]: Epoch 122 - training loss: 0.7182, validation loss: 0.8818
2024-05-24 20:43:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch122_loss0.8818239718675613.pypots
2024-05-24 20:43:21 [INFO]: Epoch 123 - training loss: 0.7119, validation loss: 0.8796
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch123_loss0.8796468377113342.pypots
2024-05-24 20:43:21 [INFO]: Epoch 124 - training loss: 0.7293, validation loss: 0.8808
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch124_loss0.8807642310857773.pypots
2024-05-24 20:43:21 [INFO]: Epoch 125 - training loss: 0.7232, validation loss: 0.8812
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch125_loss0.881155714392662.pypots
2024-05-24 20:43:21 [INFO]: Epoch 126 - training loss: 0.7204, validation loss: 0.8798
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch126_loss0.8797725439071655.pypots
2024-05-24 20:43:21 [INFO]: Epoch 127 - training loss: 0.7311, validation loss: 0.8757
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch127_loss0.8756605386734009.pypots
2024-05-24 20:43:21 [INFO]: Epoch 128 - training loss: 0.7117, validation loss: 0.8757
2024-05-24 20:43:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch128_loss0.8757186681032181.pypots
2024-05-24 20:43:22 [INFO]: Epoch 129 - training loss: 0.7451, validation loss: 0.8736
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch129_loss0.873555988073349.pypots
2024-05-24 20:43:22 [INFO]: Epoch 130 - training loss: 0.7105, validation loss: 0.8707
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch130_loss0.8706755936145782.pypots
2024-05-24 20:43:22 [INFO]: Epoch 131 - training loss: 0.7200, validation loss: 0.8730
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch131_loss0.8729759305715561.pypots
2024-05-24 20:43:22 [INFO]: Epoch 132 - training loss: 0.7162, validation loss: 0.8710
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch132_loss0.8709953427314758.pypots
2024-05-24 20:43:22 [INFO]: Epoch 133 - training loss: 0.7132, validation loss: 0.8685
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch133_loss0.8684950768947601.pypots
2024-05-24 20:43:22 [INFO]: Epoch 134 - training loss: 0.7261, validation loss: 0.8667
2024-05-24 20:43:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch134_loss0.8667264729738235.pypots
2024-05-24 20:43:23 [INFO]: Epoch 135 - training loss: 0.7286, validation loss: 0.8710
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch135_loss0.8709782510995865.pypots
2024-05-24 20:43:23 [INFO]: Epoch 136 - training loss: 0.7253, validation loss: 0.8675
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch136_loss0.8675281852483749.pypots
2024-05-24 20:43:23 [INFO]: Epoch 137 - training loss: 0.7233, validation loss: 0.8674
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch137_loss0.8673803508281708.pypots
2024-05-24 20:43:23 [INFO]: Epoch 138 - training loss: 0.7042, validation loss: 0.8645
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch138_loss0.8645312786102295.pypots
2024-05-24 20:43:23 [INFO]: Epoch 139 - training loss: 0.7399, validation loss: 0.8669
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch139_loss0.8668964356184006.pypots
2024-05-24 20:43:23 [INFO]: Epoch 140 - training loss: 0.7632, validation loss: 0.8618
2024-05-24 20:43:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch140_loss0.8617886155843735.pypots
2024-05-24 20:43:24 [INFO]: Epoch 141 - training loss: 0.7496, validation loss: 0.8655
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch141_loss0.8655344545841217.pypots
2024-05-24 20:43:24 [INFO]: Epoch 142 - training loss: 0.7233, validation loss: 0.8613
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch142_loss0.8613095730543137.pypots
2024-05-24 20:43:24 [INFO]: Epoch 143 - training loss: 0.7324, validation loss: 0.8628
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch143_loss0.8628145605325699.pypots
2024-05-24 20:43:24 [INFO]: Epoch 144 - training loss: 0.7184, validation loss: 0.8586
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch144_loss0.8585596829652786.pypots
2024-05-24 20:43:24 [INFO]: Epoch 145 - training loss: 0.7163, validation loss: 0.8591
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch145_loss0.8590763956308365.pypots
2024-05-24 20:43:24 [INFO]: Epoch 146 - training loss: 0.7431, validation loss: 0.8594
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch146_loss0.8593957871198654.pypots
2024-05-24 20:43:24 [INFO]: Epoch 147 - training loss: 0.7173, validation loss: 0.8597
2024-05-24 20:43:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch147_loss0.8596849888563156.pypots
2024-05-24 20:43:25 [INFO]: Epoch 148 - training loss: 0.7215, validation loss: 0.8558
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch148_loss0.8557585030794144.pypots
2024-05-24 20:43:25 [INFO]: Epoch 149 - training loss: 0.7266, validation loss: 0.8560
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch149_loss0.8560117483139038.pypots
2024-05-24 20:43:25 [INFO]: Epoch 150 - training loss: 0.7546, validation loss: 0.8566
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch150_loss0.8566495031118393.pypots
2024-05-24 20:43:25 [INFO]: Epoch 151 - training loss: 0.7327, validation loss: 0.8508
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch151_loss0.8508269190788269.pypots
2024-05-24 20:43:25 [INFO]: Epoch 152 - training loss: 0.7010, validation loss: 0.8542
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch152_loss0.8542461842298508.pypots
2024-05-24 20:43:25 [INFO]: Epoch 153 - training loss: 0.7244, validation loss: 0.8578
2024-05-24 20:43:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch153_loss0.857819139957428.pypots
2024-05-24 20:43:26 [INFO]: Epoch 154 - training loss: 0.7094, validation loss: 0.8528
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch154_loss0.8527755886316299.pypots
2024-05-24 20:43:26 [INFO]: Epoch 155 - training loss: 0.7277, validation loss: 0.8543
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch155_loss0.8542646765708923.pypots
2024-05-24 20:43:26 [INFO]: Epoch 156 - training loss: 0.7402, validation loss: 0.8487
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch156_loss0.8487097471952438.pypots
2024-05-24 20:43:26 [INFO]: Epoch 157 - training loss: 0.7323, validation loss: 0.8492
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch157_loss0.8492133021354675.pypots
2024-05-24 20:43:26 [INFO]: Epoch 158 - training loss: 0.7166, validation loss: 0.8472
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch158_loss0.8472016900777817.pypots
2024-05-24 20:43:26 [INFO]: Epoch 159 - training loss: 0.7114, validation loss: 0.8443
2024-05-24 20:43:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch159_loss0.844322994351387.pypots
2024-05-24 20:43:27 [INFO]: Epoch 160 - training loss: 0.7194, validation loss: 0.8460
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch160_loss0.845966711640358.pypots
2024-05-24 20:43:27 [INFO]: Epoch 161 - training loss: 0.7199, validation loss: 0.8479
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch161_loss0.8478625267744064.pypots
2024-05-24 20:43:27 [INFO]: Epoch 162 - training loss: 0.7289, validation loss: 0.8499
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch162_loss0.8498992770910263.pypots
2024-05-24 20:43:27 [INFO]: Epoch 163 - training loss: 0.7200, validation loss: 0.8438
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch163_loss0.8437958359718323.pypots
2024-05-24 20:43:27 [INFO]: Epoch 164 - training loss: 0.7297, validation loss: 0.8436
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch164_loss0.8436433523893356.pypots
2024-05-24 20:43:27 [INFO]: Epoch 165 - training loss: 0.7415, validation loss: 0.8442
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch165_loss0.8441940546035767.pypots
2024-05-24 20:43:27 [INFO]: Epoch 166 - training loss: 0.7186, validation loss: 0.8419
2024-05-24 20:43:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch166_loss0.8419422209262848.pypots
2024-05-24 20:43:28 [INFO]: Epoch 167 - training loss: 0.7157, validation loss: 0.8445
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch167_loss0.8445339649915695.pypots
2024-05-24 20:43:28 [INFO]: Epoch 168 - training loss: 0.7242, validation loss: 0.8449
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch168_loss0.8448966592550278.pypots
2024-05-24 20:43:28 [INFO]: Epoch 169 - training loss: 0.7448, validation loss: 0.8445
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch169_loss0.8445404917001724.pypots
2024-05-24 20:43:28 [INFO]: Epoch 170 - training loss: 0.7216, validation loss: 0.8398
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch170_loss0.8398487418889999.pypots
2024-05-24 20:43:28 [INFO]: Epoch 171 - training loss: 0.7292, validation loss: 0.8430
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch171_loss0.8429886251688004.pypots
2024-05-24 20:43:28 [INFO]: Epoch 172 - training loss: 0.7205, validation loss: 0.8432
2024-05-24 20:43:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch172_loss0.8431579023599625.pypots
2024-05-24 20:43:29 [INFO]: Epoch 173 - training loss: 0.7044, validation loss: 0.8413
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch173_loss0.8413238674402237.pypots
2024-05-24 20:43:29 [INFO]: Epoch 174 - training loss: 0.7168, validation loss: 0.8389
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch174_loss0.8388500511646271.pypots
2024-05-24 20:43:29 [INFO]: Epoch 175 - training loss: 0.7335, validation loss: 0.8388
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch175_loss0.8388348817825317.pypots
2024-05-24 20:43:29 [INFO]: Epoch 176 - training loss: 0.7257, validation loss: 0.8383
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch176_loss0.8383200764656067.pypots
2024-05-24 20:43:29 [INFO]: Epoch 177 - training loss: 0.7179, validation loss: 0.8353
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch177_loss0.8353421688079834.pypots
2024-05-24 20:43:29 [INFO]: Epoch 178 - training loss: 0.7184, validation loss: 0.8361
2024-05-24 20:43:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch178_loss0.8360506743192673.pypots
2024-05-24 20:43:30 [INFO]: Epoch 179 - training loss: 0.7200, validation loss: 0.8372
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch179_loss0.8372187167406082.pypots
2024-05-24 20:43:30 [INFO]: Epoch 180 - training loss: 0.7155, validation loss: 0.8368
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch180_loss0.8367862105369568.pypots
2024-05-24 20:43:30 [INFO]: Epoch 181 - training loss: 0.7032, validation loss: 0.8347
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch181_loss0.8346852660179138.pypots
2024-05-24 20:43:30 [INFO]: Epoch 182 - training loss: 0.7339, validation loss: 0.8387
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch182_loss0.8387174755334854.pypots
2024-05-24 20:43:30 [INFO]: Epoch 183 - training loss: 0.7163, validation loss: 0.8362
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch183_loss0.8361810892820358.pypots
2024-05-24 20:43:30 [INFO]: Epoch 184 - training loss: 0.7068, validation loss: 0.8355
2024-05-24 20:43:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch184_loss0.8354572802782059.pypots
2024-05-24 20:43:31 [INFO]: Epoch 185 - training loss: 0.7231, validation loss: 0.8355
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch185_loss0.8355052620172501.pypots
2024-05-24 20:43:31 [INFO]: Epoch 186 - training loss: 0.7249, validation loss: 0.8359
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch186_loss0.8358812630176544.pypots
2024-05-24 20:43:31 [INFO]: Epoch 187 - training loss: 0.7210, validation loss: 0.8331
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch187_loss0.8331097960472107.pypots
2024-05-24 20:43:31 [INFO]: Epoch 188 - training loss: 0.7027, validation loss: 0.8337
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch188_loss0.8336573839187622.pypots
2024-05-24 20:43:31 [INFO]: Epoch 189 - training loss: 0.7124, validation loss: 0.8326
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch189_loss0.8326020985841751.pypots
2024-05-24 20:43:31 [INFO]: Epoch 190 - training loss: 0.7158, validation loss: 0.8327
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch190_loss0.8326987326145172.pypots
2024-05-24 20:43:31 [INFO]: Epoch 191 - training loss: 0.7303, validation loss: 0.8296
2024-05-24 20:43:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch191_loss0.8295534402132034.pypots
2024-05-24 20:43:32 [INFO]: Epoch 192 - training loss: 0.7271, validation loss: 0.8304
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch192_loss0.8304305225610733.pypots
2024-05-24 20:43:32 [INFO]: Epoch 193 - training loss: 0.7099, validation loss: 0.8338
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch193_loss0.8337681591510773.pypots
2024-05-24 20:43:32 [INFO]: Epoch 194 - training loss: 0.7232, validation loss: 0.8320
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch194_loss0.8320299685001373.pypots
2024-05-24 20:43:32 [INFO]: Epoch 195 - training loss: 0.7291, validation loss: 0.8295
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch195_loss0.8295042365789413.pypots
2024-05-24 20:43:32 [INFO]: Epoch 196 - training loss: 0.7183, validation loss: 0.8291
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch196_loss0.8290815204381943.pypots
2024-05-24 20:43:32 [INFO]: Epoch 197 - training loss: 0.7174, validation loss: 0.8304
2024-05-24 20:43:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch197_loss0.8304412215948105.pypots
2024-05-24 20:43:33 [INFO]: Epoch 198 - training loss: 0.7205, validation loss: 0.8309
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch198_loss0.8309461027383804.pypots
2024-05-24 20:43:33 [INFO]: Epoch 199 - training loss: 0.6995, validation loss: 0.8279
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch199_loss0.8278900384902954.pypots
2024-05-24 20:43:33 [INFO]: Epoch 200 - training loss: 0.7606, validation loss: 0.8270
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch200_loss0.8270127177238464.pypots
2024-05-24 20:43:33 [INFO]: Epoch 201 - training loss: 0.7343, validation loss: 0.8247
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch201_loss0.8246786892414093.pypots
2024-05-24 20:43:33 [INFO]: Epoch 202 - training loss: 0.7051, validation loss: 0.8312
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch202_loss0.8312405347824097.pypots
2024-05-24 20:43:33 [INFO]: Epoch 203 - training loss: 0.7236, validation loss: 0.8321
2024-05-24 20:43:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch203_loss0.8320627957582474.pypots
2024-05-24 20:43:34 [INFO]: Epoch 204 - training loss: 0.7418, validation loss: 0.8287
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch204_loss0.8286560326814651.pypots
2024-05-24 20:43:34 [INFO]: Epoch 205 - training loss: 0.6916, validation loss: 0.8266
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch205_loss0.8266373127698898.pypots
2024-05-24 20:43:34 [INFO]: Epoch 206 - training loss: 0.7122, validation loss: 0.8263
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch206_loss0.8263051956892014.pypots
2024-05-24 20:43:34 [INFO]: Epoch 207 - training loss: 0.6986, validation loss: 0.8255
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch207_loss0.8254821002483368.pypots
2024-05-24 20:43:34 [INFO]: Epoch 208 - training loss: 0.7075, validation loss: 0.8282
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch208_loss0.8281642496585846.pypots
2024-05-24 20:43:34 [INFO]: Epoch 209 - training loss: 0.7105, validation loss: 0.8258
2024-05-24 20:43:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch209_loss0.8257568627595901.pypots
2024-05-24 20:43:35 [INFO]: Epoch 210 - training loss: 0.6993, validation loss: 0.8261
2024-05-24 20:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch210_loss0.8261349201202393.pypots
2024-05-24 20:43:35 [INFO]: Epoch 211 - training loss: 0.7126, validation loss: 0.8299
2024-05-24 20:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN_epoch211_loss0.8298991471529007.pypots
2024-05-24 20:43:35 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:43:35 [INFO]: Finished training. The best model is from epoch#201.
2024-05-24 20:43:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_3/MRNN_ettm1/20240524_T204300/MRNN.pypots
2024-05-24 20:43:35 [INFO]: MRNN on ETTm1: MAE=0.5946, MSE=1.0028
2024-05-24 20:43:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/MRNN_ettm1/imputation.pkl
2024-05-24 20:43:35 [INFO]: Using the given device: cpu
2024-05-24 20:43:35 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-24 20:43:35 [INFO]: Successfully created the given path "saved_results/round_3/LOCF_ettm1".
2024-05-24 20:43:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/LOCF_ettm1/imputation.pkl
2024-05-24 20:43:35 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-24 20:43:35 [INFO]: Successfully created the given path "saved_results/round_3/Median_ettm1".
2024-05-24 20:43:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Median_ettm1/imputation.pkl
2024-05-24 20:43:35 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-24 20:43:35 [INFO]: Successfully created the given path "saved_results/round_3/Mean_ettm1".
2024-05-24 20:43:35 [INFO]: Successfully saved to augmentation_premask_saved_results/round_3/Mean_ettm1/imputation.pkl
2024-05-24 20:43:35 [INFO]: Have set the random seed as 2027 for numpy and pytorch.
2024-05-24 20:43:35 [INFO]: Using the given device: cuda:0
2024-05-24 20:43:35 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T204335
2024-05-24 20:43:35 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T204335/tensorboard
2024-05-24 20:43:35 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 18,944,798
2024-05-24 20:43:36 [INFO]: Epoch 001 - training loss: 1.1623, validation loss: 0.2485
2024-05-24 20:43:36 [INFO]: Epoch 002 - training loss: 0.8793, validation loss: 0.1590
2024-05-24 20:43:36 [INFO]: Epoch 003 - training loss: 0.7981, validation loss: 0.1046
2024-05-24 20:43:37 [INFO]: Epoch 004 - training loss: 0.7433, validation loss: 0.1134
2024-05-24 20:43:37 [INFO]: Epoch 005 - training loss: 0.7337, validation loss: 0.0945
2024-05-24 20:43:38 [INFO]: Epoch 006 - training loss: 0.7095, validation loss: 0.0851
2024-05-24 20:43:38 [INFO]: Epoch 007 - training loss: 0.6704, validation loss: 0.0759
2024-05-24 20:43:39 [INFO]: Epoch 008 - training loss: 0.6548, validation loss: 0.0714
2024-05-24 20:43:39 [INFO]: Epoch 009 - training loss: 0.6295, validation loss: 0.0755
2024-05-24 20:43:40 [INFO]: Epoch 010 - training loss: 0.6116, validation loss: 0.0653
2024-05-24 20:43:40 [INFO]: Epoch 011 - training loss: 0.6146, validation loss: 0.0667
2024-05-24 20:43:41 [INFO]: Epoch 012 - training loss: 0.6046, validation loss: 0.0521
2024-05-24 20:43:41 [INFO]: Epoch 013 - training loss: 0.5988, validation loss: 0.0545
2024-05-24 20:43:42 [INFO]: Epoch 014 - training loss: 0.5872, validation loss: 0.0490
2024-05-24 20:43:42 [INFO]: Epoch 015 - training loss: 0.6071, validation loss: 0.0525
2024-05-24 20:43:43 [INFO]: Epoch 016 - training loss: 0.5714, validation loss: 0.0501
2024-05-24 20:43:43 [INFO]: Epoch 017 - training loss: 0.5765, validation loss: 0.0688
2024-05-24 20:43:44 [INFO]: Epoch 018 - training loss: 0.5888, validation loss: 0.0547
2024-05-24 20:43:44 [INFO]: Epoch 019 - training loss: 0.5529, validation loss: 0.0692
2024-05-24 20:43:45 [INFO]: Epoch 020 - training loss: 0.5478, validation loss: 0.0526
2024-05-24 20:43:45 [INFO]: Epoch 021 - training loss: 0.5453, validation loss: 0.0400
2024-05-24 20:43:46 [INFO]: Epoch 022 - training loss: 0.5415, validation loss: 0.0482
2024-05-24 20:43:46 [INFO]: Epoch 023 - training loss: 0.5429, validation loss: 0.0684
2024-05-24 20:43:47 [INFO]: Epoch 024 - training loss: 0.5452, validation loss: 0.0482
2024-05-24 20:43:47 [INFO]: Epoch 025 - training loss: 0.5313, validation loss: 0.0373
2024-05-24 20:43:48 [INFO]: Epoch 026 - training loss: 0.5182, validation loss: 0.0693
2024-05-24 20:43:48 [INFO]: Epoch 027 - training loss: 0.5218, validation loss: 0.0389
2024-05-24 20:43:49 [INFO]: Epoch 028 - training loss: 0.5357, validation loss: 0.0478
2024-05-24 20:43:49 [INFO]: Epoch 029 - training loss: 0.5183, validation loss: 0.0465
2024-05-24 20:43:49 [INFO]: Epoch 030 - training loss: 0.5069, validation loss: 0.0579
2024-05-24 20:43:50 [INFO]: Epoch 031 - training loss: 0.5067, validation loss: 0.0444
2024-05-24 20:43:50 [INFO]: Epoch 032 - training loss: 0.5040, validation loss: 0.0479
2024-05-24 20:43:51 [INFO]: Epoch 033 - training loss: 0.5091, validation loss: 0.0487
2024-05-24 20:43:51 [INFO]: Epoch 034 - training loss: 0.5141, validation loss: 0.0381
2024-05-24 20:43:52 [INFO]: Epoch 035 - training loss: 0.5038, validation loss: 0.0341
2024-05-24 20:43:52 [INFO]: Epoch 036 - training loss: 0.4936, validation loss: 0.0443
2024-05-24 20:43:53 [INFO]: Epoch 037 - training loss: 0.4846, validation loss: 0.0489
2024-05-24 20:43:53 [INFO]: Epoch 038 - training loss: 0.4833, validation loss: 0.0401
2024-05-24 20:43:54 [INFO]: Epoch 039 - training loss: 0.4980, validation loss: 0.0441
2024-05-24 20:43:54 [INFO]: Epoch 040 - training loss: 0.4870, validation loss: 0.0528
2024-05-24 20:43:55 [INFO]: Epoch 041 - training loss: 0.4943, validation loss: 0.0401
2024-05-24 20:43:55 [INFO]: Epoch 042 - training loss: 0.4803, validation loss: 0.0386
2024-05-24 20:43:56 [INFO]: Epoch 043 - training loss: 0.4742, validation loss: 0.0364
2024-05-24 20:43:56 [INFO]: Epoch 044 - training loss: 0.4721, validation loss: 0.0440
2024-05-24 20:43:57 [INFO]: Epoch 045 - training loss: 0.4727, validation loss: 0.0388
2024-05-24 20:43:57 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:43:57 [INFO]: Finished training. The best model is from epoch#35.
2024-05-24 20:43:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/SAITS_ettm1/20240524_T204335/SAITS.pypots
2024-05-24 20:43:57 [INFO]: SAITS on ETTm1: MAE=0.1557, MSE=0.0472
2024-05-24 20:43:57 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/SAITS_ettm1/imputation.pkl
2024-05-24 20:43:57 [INFO]: Using the given device: cuda:0
2024-05-24 20:43:57 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T204357
2024-05-24 20:43:57 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T204357/tensorboard
2024-05-24 20:43:57 [INFO]: Transformer initialized with the given hyperparameters, the number of trainable parameters: 7,369,735
2024-05-24 20:43:57 [INFO]: Epoch 001 - training loss: 1.1764, validation loss: 0.3943
2024-05-24 20:43:57 [INFO]: Epoch 002 - training loss: 0.7227, validation loss: 0.1928
2024-05-24 20:43:57 [INFO]: Epoch 003 - training loss: 0.5864, validation loss: 0.1399
2024-05-24 20:43:58 [INFO]: Epoch 004 - training loss: 0.5168, validation loss: 0.1105
2024-05-24 20:43:58 [INFO]: Epoch 005 - training loss: 0.4774, validation loss: 0.0939
2024-05-24 20:43:58 [INFO]: Epoch 006 - training loss: 0.4519, validation loss: 0.0809
2024-05-24 20:43:58 [INFO]: Epoch 007 - training loss: 0.4274, validation loss: 0.0723
2024-05-24 20:43:58 [INFO]: Epoch 008 - training loss: 0.4128, validation loss: 0.0655
2024-05-24 20:43:59 [INFO]: Epoch 009 - training loss: 0.3947, validation loss: 0.0641
2024-05-24 20:43:59 [INFO]: Epoch 010 - training loss: 0.3900, validation loss: 0.0646
2024-05-24 20:43:59 [INFO]: Epoch 011 - training loss: 0.3762, validation loss: 0.0624
2024-05-24 20:43:59 [INFO]: Epoch 012 - training loss: 0.3875, validation loss: 0.0599
2024-05-24 20:43:59 [INFO]: Epoch 013 - training loss: 0.3705, validation loss: 0.0536
2024-05-24 20:44:00 [INFO]: Epoch 014 - training loss: 0.3519, validation loss: 0.0507
2024-05-24 20:44:00 [INFO]: Epoch 015 - training loss: 0.3354, validation loss: 0.0483
2024-05-24 20:44:00 [INFO]: Epoch 016 - training loss: 0.3296, validation loss: 0.0486
2024-05-24 20:44:00 [INFO]: Epoch 017 - training loss: 0.3264, validation loss: 0.0453
2024-05-24 20:44:00 [INFO]: Epoch 018 - training loss: 0.3174, validation loss: 0.0458
2024-05-24 20:44:00 [INFO]: Epoch 019 - training loss: 0.3182, validation loss: 0.0430
2024-05-24 20:44:01 [INFO]: Epoch 020 - training loss: 0.3117, validation loss: 0.0449
2024-05-24 20:44:01 [INFO]: Epoch 021 - training loss: 0.3108, validation loss: 0.0440
2024-05-24 20:44:01 [INFO]: Epoch 022 - training loss: 0.3068, validation loss: 0.0413
2024-05-24 20:44:01 [INFO]: Epoch 023 - training loss: 0.2972, validation loss: 0.0457
2024-05-24 20:44:01 [INFO]: Epoch 024 - training loss: 0.2988, validation loss: 0.0410
2024-05-24 20:44:02 [INFO]: Epoch 025 - training loss: 0.2902, validation loss: 0.0417
2024-05-24 20:44:02 [INFO]: Epoch 026 - training loss: 0.2906, validation loss: 0.0426
2024-05-24 20:44:02 [INFO]: Epoch 027 - training loss: 0.2862, validation loss: 0.0381
2024-05-24 20:44:02 [INFO]: Epoch 028 - training loss: 0.2743, validation loss: 0.0371
2024-05-24 20:44:02 [INFO]: Epoch 029 - training loss: 0.2809, validation loss: 0.0375
2024-05-24 20:44:03 [INFO]: Epoch 030 - training loss: 0.2804, validation loss: 0.0396
2024-05-24 20:44:03 [INFO]: Epoch 031 - training loss: 0.2727, validation loss: 0.0364
2024-05-24 20:44:03 [INFO]: Epoch 032 - training loss: 0.2639, validation loss: 0.0364
2024-05-24 20:44:03 [INFO]: Epoch 033 - training loss: 0.2632, validation loss: 0.0352
2024-05-24 20:44:03 [INFO]: Epoch 034 - training loss: 0.2548, validation loss: 0.0352
2024-05-24 20:44:04 [INFO]: Epoch 035 - training loss: 0.2570, validation loss: 0.0378
2024-05-24 20:44:04 [INFO]: Epoch 036 - training loss: 0.2627, validation loss: 0.0337
2024-05-24 20:44:04 [INFO]: Epoch 037 - training loss: 0.2532, validation loss: 0.0353
2024-05-24 20:44:04 [INFO]: Epoch 038 - training loss: 0.2483, validation loss: 0.0357
2024-05-24 20:44:04 [INFO]: Epoch 039 - training loss: 0.2489, validation loss: 0.0367
2024-05-24 20:44:04 [INFO]: Epoch 040 - training loss: 0.2478, validation loss: 0.0369
2024-05-24 20:44:05 [INFO]: Epoch 041 - training loss: 0.2469, validation loss: 0.0344
2024-05-24 20:44:05 [INFO]: Epoch 042 - training loss: 0.2422, validation loss: 0.0331
2024-05-24 20:44:05 [INFO]: Epoch 043 - training loss: 0.2395, validation loss: 0.0306
2024-05-24 20:44:05 [INFO]: Epoch 044 - training loss: 0.2369, validation loss: 0.0303
2024-05-24 20:44:05 [INFO]: Epoch 045 - training loss: 0.2339, validation loss: 0.0322
2024-05-24 20:44:06 [INFO]: Epoch 046 - training loss: 0.2302, validation loss: 0.0329
2024-05-24 20:44:06 [INFO]: Epoch 047 - training loss: 0.2321, validation loss: 0.0286
2024-05-24 20:44:06 [INFO]: Epoch 048 - training loss: 0.2278, validation loss: 0.0331
2024-05-24 20:44:06 [INFO]: Epoch 049 - training loss: 0.2333, validation loss: 0.0326
2024-05-24 20:44:06 [INFO]: Epoch 050 - training loss: 0.2292, validation loss: 0.0319
2024-05-24 20:44:07 [INFO]: Epoch 051 - training loss: 0.2270, validation loss: 0.0291
2024-05-24 20:44:07 [INFO]: Epoch 052 - training loss: 0.2241, validation loss: 0.0294
2024-05-24 20:44:07 [INFO]: Epoch 053 - training loss: 0.2152, validation loss: 0.0287
2024-05-24 20:44:07 [INFO]: Epoch 054 - training loss: 0.2189, validation loss: 0.0305
2024-05-24 20:44:07 [INFO]: Epoch 055 - training loss: 0.2169, validation loss: 0.0297
2024-05-24 20:44:08 [INFO]: Epoch 056 - training loss: 0.2184, validation loss: 0.0296
2024-05-24 20:44:08 [INFO]: Epoch 057 - training loss: 0.2193, validation loss: 0.0315
2024-05-24 20:44:08 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:44:08 [INFO]: Finished training. The best model is from epoch#47.
2024-05-24 20:44:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/Transformer_ettm1/20240524_T204357/Transformer.pypots
2024-05-24 20:44:08 [INFO]: Transformer on ETTm1: MAE=0.1480, MSE=0.0450
2024-05-24 20:44:08 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Transformer_ettm1/imputation.pkl
2024-05-24 20:44:08 [INFO]: Using the given device: cuda:0
2024-05-24 20:44:08 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T204408
2024-05-24 20:44:08 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T204408/tensorboard
2024-05-24 20:44:08 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 21,634,183
2024-05-24 20:44:08 [INFO]: Epoch 001 - training loss: 0.1825, validation loss: 0.0601
2024-05-24 20:44:08 [INFO]: Epoch 002 - training loss: 0.0719, validation loss: 0.0416
2024-05-24 20:44:08 [INFO]: Epoch 003 - training loss: 0.0510, validation loss: 0.0348
2024-05-24 20:44:09 [INFO]: Epoch 004 - training loss: 0.0472, validation loss: 0.0321
2024-05-24 20:44:09 [INFO]: Epoch 005 - training loss: 0.0427, validation loss: 0.0315
2024-05-24 20:44:09 [INFO]: Epoch 006 - training loss: 0.0449, validation loss: 0.0319
2024-05-24 20:44:09 [INFO]: Epoch 007 - training loss: 0.0430, validation loss: 0.0301
2024-05-24 20:44:09 [INFO]: Epoch 008 - training loss: 0.0411, validation loss: 0.0297
2024-05-24 20:44:10 [INFO]: Epoch 009 - training loss: 0.0399, validation loss: 0.0296
2024-05-24 20:44:10 [INFO]: Epoch 010 - training loss: 0.0382, validation loss: 0.0292
2024-05-24 20:44:10 [INFO]: Epoch 011 - training loss: 0.0360, validation loss: 0.0284
2024-05-24 20:44:10 [INFO]: Epoch 012 - training loss: 0.0377, validation loss: 0.0277
2024-05-24 20:44:10 [INFO]: Epoch 013 - training loss: 0.0358, validation loss: 0.0280
2024-05-24 20:44:10 [INFO]: Epoch 014 - training loss: 0.0380, validation loss: 0.0304
2024-05-24 20:44:11 [INFO]: Epoch 015 - training loss: 0.0433, validation loss: 0.0305
2024-05-24 20:44:11 [INFO]: Epoch 016 - training loss: 0.0413, validation loss: 0.0282
2024-05-24 20:44:11 [INFO]: Epoch 017 - training loss: 0.0374, validation loss: 0.0288
2024-05-24 20:44:11 [INFO]: Epoch 018 - training loss: 0.0366, validation loss: 0.0284
2024-05-24 20:44:11 [INFO]: Epoch 019 - training loss: 0.0355, validation loss: 0.0285
2024-05-24 20:44:12 [INFO]: Epoch 020 - training loss: 0.0349, validation loss: 0.0283
2024-05-24 20:44:12 [INFO]: Epoch 021 - training loss: 0.0338, validation loss: 0.0275
2024-05-24 20:44:12 [INFO]: Epoch 022 - training loss: 0.0331, validation loss: 0.0277
2024-05-24 20:44:12 [INFO]: Epoch 023 - training loss: 0.0334, validation loss: 0.0278
2024-05-24 20:44:12 [INFO]: Epoch 024 - training loss: 0.0336, validation loss: 0.0292
2024-05-24 20:44:12 [INFO]: Epoch 025 - training loss: 0.0397, validation loss: 0.0302
2024-05-24 20:44:13 [INFO]: Epoch 026 - training loss: 0.0372, validation loss: 0.0275
2024-05-24 20:44:13 [INFO]: Epoch 027 - training loss: 0.0336, validation loss: 0.0287
2024-05-24 20:44:13 [INFO]: Epoch 028 - training loss: 0.0337, validation loss: 0.0268
2024-05-24 20:44:13 [INFO]: Epoch 029 - training loss: 0.0310, validation loss: 0.0263
2024-05-24 20:44:13 [INFO]: Epoch 030 - training loss: 0.0307, validation loss: 0.0262
2024-05-24 20:44:14 [INFO]: Epoch 031 - training loss: 0.0304, validation loss: 0.0262
2024-05-24 20:44:14 [INFO]: Epoch 032 - training loss: 0.0312, validation loss: 0.0273
2024-05-24 20:44:14 [INFO]: Epoch 033 - training loss: 0.0300, validation loss: 0.0261
2024-05-24 20:44:14 [INFO]: Epoch 034 - training loss: 0.0282, validation loss: 0.0261
2024-05-24 20:44:14 [INFO]: Epoch 035 - training loss: 0.0289, validation loss: 0.0266
2024-05-24 20:44:14 [INFO]: Epoch 036 - training loss: 0.0281, validation loss: 0.0257
2024-05-24 20:44:15 [INFO]: Epoch 037 - training loss: 0.0281, validation loss: 0.0265
2024-05-24 20:44:15 [INFO]: Epoch 038 - training loss: 0.0285, validation loss: 0.0260
2024-05-24 20:44:15 [INFO]: Epoch 039 - training loss: 0.0274, validation loss: 0.0257
2024-05-24 20:44:15 [INFO]: Epoch 040 - training loss: 0.0266, validation loss: 0.0273
2024-05-24 20:44:15 [INFO]: Epoch 041 - training loss: 0.0277, validation loss: 0.0265
2024-05-24 20:44:15 [INFO]: Epoch 042 - training loss: 0.0281, validation loss: 0.0256
2024-05-24 20:44:16 [INFO]: Epoch 043 - training loss: 0.0262, validation loss: 0.0257
2024-05-24 20:44:16 [INFO]: Epoch 044 - training loss: 0.0255, validation loss: 0.0261
2024-05-24 20:44:16 [INFO]: Epoch 045 - training loss: 0.0246, validation loss: 0.0267
2024-05-24 20:44:16 [INFO]: Epoch 046 - training loss: 0.0255, validation loss: 0.0287
2024-05-24 20:44:16 [INFO]: Epoch 047 - training loss: 0.0278, validation loss: 0.0270
2024-05-24 20:44:17 [INFO]: Epoch 048 - training loss: 0.0281, validation loss: 0.0261
2024-05-24 20:44:17 [INFO]: Epoch 049 - training loss: 0.0256, validation loss: 0.0260
2024-05-24 20:44:17 [INFO]: Epoch 050 - training loss: 0.0239, validation loss: 0.0263
2024-05-24 20:44:17 [INFO]: Epoch 051 - training loss: 0.0244, validation loss: 0.0268
2024-05-24 20:44:17 [INFO]: Epoch 052 - training loss: 0.0233, validation loss: 0.0255
2024-05-24 20:44:17 [INFO]: Epoch 053 - training loss: 0.0222, validation loss: 0.0260
2024-05-24 20:44:18 [INFO]: Epoch 054 - training loss: 0.0220, validation loss: 0.0260
2024-05-24 20:44:18 [INFO]: Epoch 055 - training loss: 0.0216, validation loss: 0.0260
2024-05-24 20:44:18 [INFO]: Epoch 056 - training loss: 0.0221, validation loss: 0.0262
2024-05-24 20:44:18 [INFO]: Epoch 057 - training loss: 0.0229, validation loss: 0.0265
2024-05-24 20:44:18 [INFO]: Epoch 058 - training loss: 0.0220, validation loss: 0.0261
2024-05-24 20:44:19 [INFO]: Epoch 059 - training loss: 0.0218, validation loss: 0.0266
2024-05-24 20:44:19 [INFO]: Epoch 060 - training loss: 0.0258, validation loss: 0.0265
2024-05-24 20:44:19 [INFO]: Epoch 061 - training loss: 0.0204, validation loss: 0.0262
2024-05-24 20:44:19 [INFO]: Epoch 062 - training loss: 0.0211, validation loss: 0.0258
2024-05-24 20:44:19 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:44:19 [INFO]: Finished training. The best model is from epoch#52.
2024-05-24 20:44:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/TimesNet_ettm1/20240524_T204408/TimesNet.pypots
2024-05-24 20:44:20 [INFO]: TimesNet on ETTm1: MAE=0.1155, MSE=0.0290
2024-05-24 20:44:20 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/TimesNet_ettm1/imputation.pkl
2024-05-24 20:44:20 [INFO]: Using the given device: cuda:0
2024-05-24 20:44:20 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420
2024-05-24 20:44:20 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/tensorboard
2024-05-24 20:44:20 [INFO]: CSDI initialized with the given hyperparameters, the number of trainable parameters: 448,993
2024-05-24 20:44:22 [INFO]: Epoch 001 - training loss: 0.6509, validation loss: 0.4611
2024-05-24 20:44:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch1_loss0.4610547497868538.pypots
2024-05-24 20:44:24 [INFO]: Epoch 002 - training loss: 0.4036, validation loss: 0.3561
2024-05-24 20:44:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch2_loss0.35612621903419495.pypots
2024-05-24 20:44:26 [INFO]: Epoch 003 - training loss: 0.3199, validation loss: 0.3236
2024-05-24 20:44:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch3_loss0.3235892057418823.pypots
2024-05-24 20:44:28 [INFO]: Epoch 004 - training loss: 0.3832, validation loss: 0.2821
2024-05-24 20:44:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch4_loss0.2821446806192398.pypots
2024-05-24 20:44:30 [INFO]: Epoch 005 - training loss: 0.3333, validation loss: 0.2845
2024-05-24 20:44:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch5_loss0.2844843864440918.pypots
2024-05-24 20:44:32 [INFO]: Epoch 006 - training loss: 0.2626, validation loss: 0.2716
2024-05-24 20:44:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch6_loss0.2715909704566002.pypots
2024-05-24 20:44:34 [INFO]: Epoch 007 - training loss: 0.2271, validation loss: 0.2626
2024-05-24 20:44:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch7_loss0.26258403807878494.pypots
2024-05-24 20:44:36 [INFO]: Epoch 008 - training loss: 0.2255, validation loss: 0.2532
2024-05-24 20:44:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch8_loss0.25317680463194847.pypots
2024-05-24 20:44:38 [INFO]: Epoch 009 - training loss: 0.2194, validation loss: 0.2383
2024-05-24 20:44:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch9_loss0.23830069601535797.pypots
2024-05-24 20:44:40 [INFO]: Epoch 010 - training loss: 0.2428, validation loss: 0.2303
2024-05-24 20:44:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch10_loss0.23032288998365402.pypots
2024-05-24 20:44:42 [INFO]: Epoch 011 - training loss: 0.2054, validation loss: 0.2257
2024-05-24 20:44:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch11_loss0.22571652382612228.pypots
2024-05-24 20:44:45 [INFO]: Epoch 012 - training loss: 0.2455, validation loss: 0.2212
2024-05-24 20:44:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch12_loss0.22120148688554764.pypots
2024-05-24 20:44:47 [INFO]: Epoch 013 - training loss: 0.2107, validation loss: 0.2401
2024-05-24 20:44:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch13_loss0.24005122110247612.pypots
2024-05-24 20:44:49 [INFO]: Epoch 014 - training loss: 0.2938, validation loss: 0.2169
2024-05-24 20:44:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch14_loss0.21690431982278824.pypots
2024-05-24 20:44:51 [INFO]: Epoch 015 - training loss: 0.2166, validation loss: 0.2140
2024-05-24 20:44:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch15_loss0.21402179077267647.pypots
2024-05-24 20:44:53 [INFO]: Epoch 016 - training loss: 0.1985, validation loss: 0.2026
2024-05-24 20:44:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch16_loss0.20257259532809258.pypots
2024-05-24 20:44:55 [INFO]: Epoch 017 - training loss: 0.1984, validation loss: 0.2013
2024-05-24 20:44:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch17_loss0.2013433463871479.pypots
2024-05-24 20:44:57 [INFO]: Epoch 018 - training loss: 0.1877, validation loss: 0.1925
2024-05-24 20:44:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch18_loss0.19245228916406631.pypots
2024-05-24 20:44:59 [INFO]: Epoch 019 - training loss: 0.1925, validation loss: 0.1809
2024-05-24 20:44:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch19_loss0.18093601241707802.pypots
2024-05-24 20:45:01 [INFO]: Epoch 020 - training loss: 0.1821, validation loss: 0.1821
2024-05-24 20:45:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch20_loss0.18212389200925827.pypots
2024-05-24 20:45:03 [INFO]: Epoch 021 - training loss: 0.1777, validation loss: 0.1746
2024-05-24 20:45:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch21_loss0.1745724454522133.pypots
2024-05-24 20:45:05 [INFO]: Epoch 022 - training loss: 0.1690, validation loss: 0.1727
2024-05-24 20:45:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch22_loss0.17269553989171982.pypots
2024-05-24 20:45:07 [INFO]: Epoch 023 - training loss: 0.1635, validation loss: 0.1675
2024-05-24 20:45:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch23_loss0.1675303466618061.pypots
2024-05-24 20:45:09 [INFO]: Epoch 024 - training loss: 0.1649, validation loss: 0.1665
2024-05-24 20:45:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch24_loss0.1664825901389122.pypots
2024-05-24 20:45:11 [INFO]: Epoch 025 - training loss: 0.2110, validation loss: 0.1671
2024-05-24 20:45:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch25_loss0.16707352921366692.pypots
2024-05-24 20:45:13 [INFO]: Epoch 026 - training loss: 0.1900, validation loss: 0.1637
2024-05-24 20:45:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch26_loss0.16371195018291473.pypots
2024-05-24 20:45:15 [INFO]: Epoch 027 - training loss: 0.1657, validation loss: 0.1592
2024-05-24 20:45:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch27_loss0.1592429205775261.pypots
2024-05-24 20:45:17 [INFO]: Epoch 028 - training loss: 0.1943, validation loss: 0.1647
2024-05-24 20:45:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch28_loss0.16470441222190857.pypots
2024-05-24 20:45:19 [INFO]: Epoch 029 - training loss: 0.2334, validation loss: 0.1728
2024-05-24 20:45:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch29_loss0.17279541119933128.pypots
2024-05-24 20:45:21 [INFO]: Epoch 030 - training loss: 0.1569, validation loss: 0.1657
2024-05-24 20:45:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch30_loss0.16567663848400116.pypots
2024-05-24 20:45:23 [INFO]: Epoch 031 - training loss: 0.1829, validation loss: 0.1543
2024-05-24 20:45:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch31_loss0.15434885770082474.pypots
2024-05-24 20:45:25 [INFO]: Epoch 032 - training loss: 0.1556, validation loss: 0.1508
2024-05-24 20:45:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch32_loss0.15084783732891083.pypots
2024-05-24 20:45:27 [INFO]: Epoch 033 - training loss: 0.1447, validation loss: 0.1486
2024-05-24 20:45:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch33_loss0.14858655259013176.pypots
2024-05-24 20:45:29 [INFO]: Epoch 034 - training loss: 0.1711, validation loss: 0.1724
2024-05-24 20:45:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch34_loss0.17238254472613335.pypots
2024-05-24 20:45:31 [INFO]: Epoch 035 - training loss: 0.1753, validation loss: 0.1587
2024-05-24 20:45:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch35_loss0.15872486680746078.pypots
2024-05-24 20:45:33 [INFO]: Epoch 036 - training loss: 0.1683, validation loss: 0.1472
2024-05-24 20:45:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch36_loss0.14718272909522057.pypots
2024-05-24 20:45:35 [INFO]: Epoch 037 - training loss: 0.2335, validation loss: 0.1492
2024-05-24 20:45:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch37_loss0.1491769477725029.pypots
2024-05-24 20:45:37 [INFO]: Epoch 038 - training loss: 0.2079, validation loss: 0.1586
2024-05-24 20:45:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch38_loss0.1586454100906849.pypots
2024-05-24 20:45:39 [INFO]: Epoch 039 - training loss: 0.1648, validation loss: 0.1701
2024-05-24 20:45:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch39_loss0.17009208351373672.pypots
2024-05-24 20:45:41 [INFO]: Epoch 040 - training loss: 0.2463, validation loss: 0.1529
2024-05-24 20:45:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch40_loss0.15291373431682587.pypots
2024-05-24 20:45:43 [INFO]: Epoch 041 - training loss: 0.1536, validation loss: 0.1448
2024-05-24 20:45:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch41_loss0.14482374489307404.pypots
2024-05-24 20:45:45 [INFO]: Epoch 042 - training loss: 0.1468, validation loss: 0.1402
2024-05-24 20:45:45 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch42_loss0.1401597335934639.pypots
2024-05-24 20:45:47 [INFO]: Epoch 043 - training loss: 0.1368, validation loss: 0.1359
2024-05-24 20:45:47 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch43_loss0.1358831450343132.pypots
2024-05-24 20:45:49 [INFO]: Epoch 044 - training loss: 0.1241, validation loss: 0.1370
2024-05-24 20:45:49 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch44_loss0.1370200552046299.pypots
2024-05-24 20:45:51 [INFO]: Epoch 045 - training loss: 0.2074, validation loss: 0.1641
2024-05-24 20:45:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch45_loss0.1641218103468418.pypots
2024-05-24 20:45:53 [INFO]: Epoch 046 - training loss: 0.1706, validation loss: 0.1550
2024-05-24 20:45:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch46_loss0.1549658291041851.pypots
2024-05-24 20:45:55 [INFO]: Epoch 047 - training loss: 0.1626, validation loss: 0.1491
2024-05-24 20:45:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch47_loss0.14911428466439247.pypots
2024-05-24 20:45:57 [INFO]: Epoch 048 - training loss: 0.1622, validation loss: 0.1436
2024-05-24 20:45:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch48_loss0.14355800300836563.pypots
2024-05-24 20:45:59 [INFO]: Epoch 049 - training loss: 0.1482, validation loss: 0.1388
2024-05-24 20:45:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch49_loss0.13883202895522118.pypots
2024-05-24 20:46:01 [INFO]: Epoch 050 - training loss: 0.1358, validation loss: 0.1319
2024-05-24 20:46:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch50_loss0.13191824033856392.pypots
2024-05-24 20:46:04 [INFO]: Epoch 051 - training loss: 0.1550, validation loss: 0.1318
2024-05-24 20:46:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch51_loss0.13182456977665424.pypots
2024-05-24 20:46:06 [INFO]: Epoch 052 - training loss: 0.1657, validation loss: 0.1356
2024-05-24 20:46:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch52_loss0.13557586818933487.pypots
2024-05-24 20:46:08 [INFO]: Epoch 053 - training loss: 0.1473, validation loss: 0.1430
2024-05-24 20:46:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch53_loss0.14300033822655678.pypots
2024-05-24 20:46:10 [INFO]: Epoch 054 - training loss: 0.1184, validation loss: 0.1326
2024-05-24 20:46:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch54_loss0.13263591192662716.pypots
2024-05-24 20:46:12 [INFO]: Epoch 055 - training loss: 0.1420, validation loss: 0.1308
2024-05-24 20:46:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch55_loss0.13080386631190777.pypots
2024-05-24 20:46:14 [INFO]: Epoch 056 - training loss: 0.1305, validation loss: 0.1375
2024-05-24 20:46:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch56_loss0.1375023052096367.pypots
2024-05-24 20:46:16 [INFO]: Epoch 057 - training loss: 0.1332, validation loss: 0.1350
2024-05-24 20:46:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch57_loss0.1349978819489479.pypots
2024-05-24 20:46:18 [INFO]: Epoch 058 - training loss: 0.1349, validation loss: 0.1307
2024-05-24 20:46:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch58_loss0.13069276697933674.pypots
2024-05-24 20:46:20 [INFO]: Epoch 059 - training loss: 0.1426, validation loss: 0.1321
2024-05-24 20:46:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch59_loss0.1320941150188446.pypots
2024-05-24 20:46:22 [INFO]: Epoch 060 - training loss: 0.1497, validation loss: 0.1323
2024-05-24 20:46:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch60_loss0.13233758509159088.pypots
2024-05-24 20:46:24 [INFO]: Epoch 061 - training loss: 0.1486, validation loss: 0.1449
2024-05-24 20:46:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch61_loss0.1448584944009781.pypots
2024-05-24 20:46:26 [INFO]: Epoch 062 - training loss: 0.1424, validation loss: 0.1334
2024-05-24 20:46:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch62_loss0.133390998467803.pypots
2024-05-24 20:46:28 [INFO]: Epoch 063 - training loss: 0.1735, validation loss: 0.1378
2024-05-24 20:46:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch63_loss0.13776666298508644.pypots
2024-05-24 20:46:30 [INFO]: Epoch 064 - training loss: 0.1685, validation loss: 0.1393
2024-05-24 20:46:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch64_loss0.13926174491643906.pypots
2024-05-24 20:46:32 [INFO]: Epoch 065 - training loss: 0.1562, validation loss: 0.1454
2024-05-24 20:46:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch65_loss0.14536035060882568.pypots
2024-05-24 20:46:34 [INFO]: Epoch 066 - training loss: 0.1399, validation loss: 0.1316
2024-05-24 20:46:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch66_loss0.13158089853823185.pypots
2024-05-24 20:46:36 [INFO]: Epoch 067 - training loss: 0.1295, validation loss: 0.1256
2024-05-24 20:46:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch67_loss0.1256021037697792.pypots
2024-05-24 20:46:38 [INFO]: Epoch 068 - training loss: 0.1470, validation loss: 0.1277
2024-05-24 20:46:38 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch68_loss0.12766851112246513.pypots
2024-05-24 20:46:40 [INFO]: Epoch 069 - training loss: 0.1587, validation loss: 0.1419
2024-05-24 20:46:40 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch69_loss0.14187415316700935.pypots
2024-05-24 20:46:42 [INFO]: Epoch 070 - training loss: 0.1380, validation loss: 0.1341
2024-05-24 20:46:42 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch70_loss0.134094700217247.pypots
2024-05-24 20:46:44 [INFO]: Epoch 071 - training loss: 0.1412, validation loss: 0.1267
2024-05-24 20:46:44 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch71_loss0.126682223752141.pypots
2024-05-24 20:46:46 [INFO]: Epoch 072 - training loss: 0.1384, validation loss: 0.1269
2024-05-24 20:46:46 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch72_loss0.12694403529167175.pypots
2024-05-24 20:46:48 [INFO]: Epoch 073 - training loss: 0.1491, validation loss: 0.1285
2024-05-24 20:46:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch73_loss0.1284549292176962.pypots
2024-05-24 20:46:50 [INFO]: Epoch 074 - training loss: 0.1272, validation loss: 0.1267
2024-05-24 20:46:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch74_loss0.1266655307263136.pypots
2024-05-24 20:46:52 [INFO]: Epoch 075 - training loss: 0.1492, validation loss: 0.1247
2024-05-24 20:46:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch75_loss0.12468112073838711.pypots
2024-05-24 20:46:54 [INFO]: Epoch 076 - training loss: 0.1029, validation loss: 0.1221
2024-05-24 20:46:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch76_loss0.12206379324197769.pypots
2024-05-24 20:46:56 [INFO]: Epoch 077 - training loss: 0.1228, validation loss: 0.1217
2024-05-24 20:46:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch77_loss0.1217018160969019.pypots
2024-05-24 20:46:58 [INFO]: Epoch 078 - training loss: 0.1215, validation loss: 0.1212
2024-05-24 20:46:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch78_loss0.12122590281069279.pypots
2024-05-24 20:47:00 [INFO]: Epoch 079 - training loss: 0.1011, validation loss: 0.1220
2024-05-24 20:47:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch79_loss0.12195082195103168.pypots
2024-05-24 20:47:02 [INFO]: Epoch 080 - training loss: 0.1342, validation loss: 0.1242
2024-05-24 20:47:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch80_loss0.12416350841522217.pypots
2024-05-24 20:47:04 [INFO]: Epoch 081 - training loss: 0.1292, validation loss: 0.1260
2024-05-24 20:47:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch81_loss0.1260450016707182.pypots
2024-05-24 20:47:06 [INFO]: Epoch 082 - training loss: 0.1492, validation loss: 0.1255
2024-05-24 20:47:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch82_loss0.12546337582170963.pypots
2024-05-24 20:47:08 [INFO]: Epoch 083 - training loss: 0.1260, validation loss: 0.1212
2024-05-24 20:47:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch83_loss0.12123776599764824.pypots
2024-05-24 20:47:10 [INFO]: Epoch 084 - training loss: 0.1266, validation loss: 0.1185
2024-05-24 20:47:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch84_loss0.11849402822554111.pypots
2024-05-24 20:47:12 [INFO]: Epoch 085 - training loss: 0.1388, validation loss: 0.1190
2024-05-24 20:47:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch85_loss0.1190019641071558.pypots
2024-05-24 20:47:14 [INFO]: Epoch 086 - training loss: 0.1328, validation loss: 0.1250
2024-05-24 20:47:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch86_loss0.12504776194691658.pypots
2024-05-24 20:47:16 [INFO]: Epoch 087 - training loss: 0.1307, validation loss: 0.1203
2024-05-24 20:47:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch87_loss0.12032621167600155.pypots
2024-05-24 20:47:18 [INFO]: Epoch 088 - training loss: 0.1219, validation loss: 0.1204
2024-05-24 20:47:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch88_loss0.12041078880429268.pypots
2024-05-24 20:47:20 [INFO]: Epoch 089 - training loss: 0.1267, validation loss: 0.1177
2024-05-24 20:47:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch89_loss0.11766182631254196.pypots
2024-05-24 20:47:22 [INFO]: Epoch 090 - training loss: 0.1145, validation loss: 0.1163
2024-05-24 20:47:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch90_loss0.11634938232600689.pypots
2024-05-24 20:47:24 [INFO]: Epoch 091 - training loss: 0.1172, validation loss: 0.1213
2024-05-24 20:47:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch91_loss0.12126539833843708.pypots
2024-05-24 20:47:27 [INFO]: Epoch 092 - training loss: 0.1366, validation loss: 0.1252
2024-05-24 20:47:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch92_loss0.12521464936435223.pypots
2024-05-24 20:47:29 [INFO]: Epoch 093 - training loss: 0.1816, validation loss: 0.1402
2024-05-24 20:47:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch93_loss0.14017005264759064.pypots
2024-05-24 20:47:31 [INFO]: Epoch 094 - training loss: 0.1801, validation loss: 0.1425
2024-05-24 20:47:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch94_loss0.14251799508929253.pypots
2024-05-24 20:47:33 [INFO]: Epoch 095 - training loss: 0.1611, validation loss: 0.1400
2024-05-24 20:47:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch95_loss0.13998128473758698.pypots
2024-05-24 20:47:35 [INFO]: Epoch 096 - training loss: 0.1512, validation loss: 0.1415
2024-05-24 20:47:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch96_loss0.14147035032510757.pypots
2024-05-24 20:47:37 [INFO]: Epoch 097 - training loss: 0.1304, validation loss: 0.1267
2024-05-24 20:47:37 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch97_loss0.1266525499522686.pypots
2024-05-24 20:47:39 [INFO]: Epoch 098 - training loss: 0.1847, validation loss: 0.1269
2024-05-24 20:47:39 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch98_loss0.1268672551959753.pypots
2024-05-24 20:47:41 [INFO]: Epoch 099 - training loss: 0.1416, validation loss: 0.1389
2024-05-24 20:47:41 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch99_loss0.13886656239628792.pypots
2024-05-24 20:47:43 [INFO]: Epoch 100 - training loss: 0.1274, validation loss: 0.1367
2024-05-24 20:47:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI_epoch100_loss0.13674956560134888.pypots
2024-05-24 20:47:43 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:47:43 [INFO]: Finished training. The best model is from epoch#90.
2024-05-24 20:47:43 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/CSDI_ettm1/20240524_T204420/CSDI.pypots
2024-05-24 20:47:58 [INFO]: CSDI on ETTm1: MAE=0.1116, MSE=0.0303
2024-05-24 20:47:58 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/CSDI_ettm1/imputation.pkl
2024-05-24 20:47:58 [INFO]: Using the given device: cuda:0
2024-05-24 20:47:58 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T204758
2024-05-24 20:47:58 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T204758/tensorboard
2024-05-24 20:47:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 472,604
2024-05-24 20:47:58 [INFO]: Epoch 001 - training loss: 23930.2415, validation loss: 0.9900
2024-05-24 20:47:59 [INFO]: Epoch 002 - training loss: 22077.1173, validation loss: 0.9900
2024-05-24 20:47:59 [INFO]: Epoch 003 - training loss: 20126.9998, validation loss: 0.9874
2024-05-24 20:47:59 [INFO]: Epoch 004 - training loss: 18126.5282, validation loss: 0.9735
2024-05-24 20:47:59 [INFO]: Epoch 005 - training loss: 16079.4411, validation loss: 0.9484
2024-05-24 20:47:59 [INFO]: Epoch 006 - training loss: 14528.3434, validation loss: 0.8831
2024-05-24 20:47:59 [INFO]: Epoch 007 - training loss: 13254.4936, validation loss: 0.7718
2024-05-24 20:47:59 [INFO]: Epoch 008 - training loss: 12113.6667, validation loss: 0.6611
2024-05-24 20:47:59 [INFO]: Epoch 009 - training loss: 11568.4040, validation loss: 0.5966
2024-05-24 20:47:59 [INFO]: Epoch 010 - training loss: 11115.3448, validation loss: 0.5360
2024-05-24 20:48:00 [INFO]: Epoch 011 - training loss: 10856.9139, validation loss: 0.4900
2024-05-24 20:48:00 [INFO]: Epoch 012 - training loss: 10728.0998, validation loss: 0.4577
2024-05-24 20:48:00 [INFO]: Epoch 013 - training loss: 10243.9811, validation loss: 0.4367
2024-05-24 20:48:00 [INFO]: Epoch 014 - training loss: 10110.2476, validation loss: 0.4201
2024-05-24 20:48:00 [INFO]: Epoch 015 - training loss: 9998.3551, validation loss: 0.3960
2024-05-24 20:48:00 [INFO]: Epoch 016 - training loss: 9933.2657, validation loss: 0.3751
2024-05-24 20:48:00 [INFO]: Epoch 017 - training loss: 9950.6398, validation loss: 0.3516
2024-05-24 20:48:00 [INFO]: Epoch 018 - training loss: 9758.2751, validation loss: 0.3381
2024-05-24 20:48:00 [INFO]: Epoch 019 - training loss: 9758.8519, validation loss: 0.3204
2024-05-24 20:48:01 [INFO]: Epoch 020 - training loss: 9660.3160, validation loss: 0.3081
2024-05-24 20:48:01 [INFO]: Epoch 021 - training loss: 9642.9479, validation loss: 0.2955
2024-05-24 20:48:01 [INFO]: Epoch 022 - training loss: 9658.8278, validation loss: 0.2850
2024-05-24 20:48:01 [INFO]: Epoch 023 - training loss: 9559.9380, validation loss: 0.2764
2024-05-24 20:48:01 [INFO]: Epoch 024 - training loss: 9577.7894, validation loss: 0.2695
2024-05-24 20:48:01 [INFO]: Epoch 025 - training loss: 9493.1607, validation loss: 0.2601
2024-05-24 20:48:01 [INFO]: Epoch 026 - training loss: 9479.2708, validation loss: 0.2554
2024-05-24 20:48:01 [INFO]: Epoch 027 - training loss: 9451.8485, validation loss: 0.2487
2024-05-24 20:48:01 [INFO]: Epoch 028 - training loss: 9463.2888, validation loss: 0.2476
2024-05-24 20:48:02 [INFO]: Epoch 029 - training loss: 9423.2125, validation loss: 0.2416
2024-05-24 20:48:02 [INFO]: Epoch 030 - training loss: 9415.9694, validation loss: 0.2382
2024-05-24 20:48:02 [INFO]: Epoch 031 - training loss: 9410.9062, validation loss: 0.2302
2024-05-24 20:48:02 [INFO]: Epoch 032 - training loss: 9389.9668, validation loss: 0.2256
2024-05-24 20:48:02 [INFO]: Epoch 033 - training loss: 9382.0193, validation loss: 0.2212
2024-05-24 20:48:02 [INFO]: Epoch 034 - training loss: 9403.5921, validation loss: 0.2141
2024-05-24 20:48:02 [INFO]: Epoch 035 - training loss: 9361.9012, validation loss: 0.2141
2024-05-24 20:48:02 [INFO]: Epoch 036 - training loss: 9367.9519, validation loss: 0.2100
2024-05-24 20:48:02 [INFO]: Epoch 037 - training loss: 9348.2262, validation loss: 0.2034
2024-05-24 20:48:02 [INFO]: Epoch 038 - training loss: 9346.9424, validation loss: 0.1996
2024-05-24 20:48:03 [INFO]: Epoch 039 - training loss: 9340.0250, validation loss: 0.1985
2024-05-24 20:48:03 [INFO]: Epoch 040 - training loss: 9330.7243, validation loss: 0.1937
2024-05-24 20:48:03 [INFO]: Epoch 041 - training loss: 9324.7123, validation loss: 0.1923
2024-05-24 20:48:03 [INFO]: Epoch 042 - training loss: 9323.3360, validation loss: 0.1886
2024-05-24 20:48:03 [INFO]: Epoch 043 - training loss: 9316.7123, validation loss: 0.1864
2024-05-24 20:48:03 [INFO]: Epoch 044 - training loss: 9326.0184, validation loss: 0.1829
2024-05-24 20:48:03 [INFO]: Epoch 045 - training loss: 9306.2713, validation loss: 0.1811
2024-05-24 20:48:03 [INFO]: Epoch 046 - training loss: 9304.3473, validation loss: 0.1812
2024-05-24 20:48:03 [INFO]: Epoch 047 - training loss: 9298.9548, validation loss: 0.1749
2024-05-24 20:48:04 [INFO]: Epoch 048 - training loss: 9295.2960, validation loss: 0.1730
2024-05-24 20:48:04 [INFO]: Epoch 049 - training loss: 9302.3154, validation loss: 0.1706
2024-05-24 20:48:04 [INFO]: Epoch 050 - training loss: 9289.5656, validation loss: 0.1701
2024-05-24 20:48:04 [INFO]: Epoch 051 - training loss: 9287.0915, validation loss: 0.1655
2024-05-24 20:48:04 [INFO]: Epoch 052 - training loss: 9289.3753, validation loss: 0.1634
2024-05-24 20:48:04 [INFO]: Epoch 053 - training loss: 9283.6390, validation loss: 0.1636
2024-05-24 20:48:04 [INFO]: Epoch 054 - training loss: 9283.5872, validation loss: 0.1623
2024-05-24 20:48:04 [INFO]: Epoch 055 - training loss: 9286.8554, validation loss: 0.1621
2024-05-24 20:48:04 [INFO]: Epoch 056 - training loss: 9280.5593, validation loss: 0.1585
2024-05-24 20:48:05 [INFO]: Epoch 057 - training loss: 9278.4421, validation loss: 0.1547
2024-05-24 20:48:05 [INFO]: Epoch 058 - training loss: 9273.1935, validation loss: 0.1547
2024-05-24 20:48:05 [INFO]: Epoch 059 - training loss: 9271.8085, validation loss: 0.1544
2024-05-24 20:48:05 [INFO]: Epoch 060 - training loss: 9270.1888, validation loss: 0.1510
2024-05-24 20:48:05 [INFO]: Epoch 061 - training loss: 9267.4011, validation loss: 0.1519
2024-05-24 20:48:05 [INFO]: Epoch 062 - training loss: 9263.0342, validation loss: 0.1480
2024-05-24 20:48:05 [INFO]: Epoch 063 - training loss: 9265.0330, validation loss: 0.1490
2024-05-24 20:48:05 [INFO]: Epoch 064 - training loss: 9265.0634, validation loss: 0.1472
2024-05-24 20:48:05 [INFO]: Epoch 065 - training loss: 9263.1703, validation loss: 0.1464
2024-05-24 20:48:06 [INFO]: Epoch 066 - training loss: 9258.0430, validation loss: 0.1454
2024-05-24 20:48:06 [INFO]: Epoch 067 - training loss: 9258.1417, validation loss: 0.1449
2024-05-24 20:48:06 [INFO]: Epoch 068 - training loss: 9257.1439, validation loss: 0.1443
2024-05-24 20:48:06 [INFO]: Epoch 069 - training loss: 9255.8428, validation loss: 0.1441
2024-05-24 20:48:06 [INFO]: Epoch 070 - training loss: 9251.9424, validation loss: 0.1425
2024-05-24 20:48:06 [INFO]: Epoch 071 - training loss: 9255.7196, validation loss: 0.1400
2024-05-24 20:48:06 [INFO]: Epoch 072 - training loss: 9252.1865, validation loss: 0.1428
2024-05-24 20:48:06 [INFO]: Epoch 073 - training loss: 9248.7525, validation loss: 0.1398
2024-05-24 20:48:06 [INFO]: Epoch 074 - training loss: 9250.3412, validation loss: 0.1392
2024-05-24 20:48:07 [INFO]: Epoch 075 - training loss: 9255.9800, validation loss: 0.1375
2024-05-24 20:48:07 [INFO]: Epoch 076 - training loss: 9247.0995, validation loss: 0.1373
2024-05-24 20:48:07 [INFO]: Epoch 077 - training loss: 9248.5676, validation loss: 0.1375
2024-05-24 20:48:07 [INFO]: Epoch 078 - training loss: 9247.1354, validation loss: 0.1373
2024-05-24 20:48:07 [INFO]: Epoch 079 - training loss: 9246.4572, validation loss: 0.1344
2024-05-24 20:48:07 [INFO]: Epoch 080 - training loss: 9241.7377, validation loss: 0.1354
2024-05-24 20:48:07 [INFO]: Epoch 081 - training loss: 9248.6042, validation loss: 0.1336
2024-05-24 20:48:07 [INFO]: Epoch 082 - training loss: 9245.2739, validation loss: 0.1338
2024-05-24 20:48:07 [INFO]: Epoch 083 - training loss: 9241.9954, validation loss: 0.1321
2024-05-24 20:48:07 [INFO]: Epoch 084 - training loss: 9244.2805, validation loss: 0.1317
2024-05-24 20:48:08 [INFO]: Epoch 085 - training loss: 9241.5151, validation loss: 0.1307
2024-05-24 20:48:08 [INFO]: Epoch 086 - training loss: 9240.7584, validation loss: 0.1300
2024-05-24 20:48:08 [INFO]: Epoch 087 - training loss: 9241.8687, validation loss: 0.1302
2024-05-24 20:48:08 [INFO]: Epoch 088 - training loss: 9243.7786, validation loss: 0.1290
2024-05-24 20:48:08 [INFO]: Epoch 089 - training loss: 9238.3891, validation loss: 0.1287
2024-05-24 20:48:08 [INFO]: Epoch 090 - training loss: 9238.6087, validation loss: 0.1272
2024-05-24 20:48:08 [INFO]: Epoch 091 - training loss: 9240.2817, validation loss: 0.1282
2024-05-24 20:48:08 [INFO]: Epoch 092 - training loss: 9234.7658, validation loss: 0.1266
2024-05-24 20:48:08 [INFO]: Epoch 093 - training loss: 9235.0337, validation loss: 0.1254
2024-05-24 20:48:09 [INFO]: Epoch 094 - training loss: 9234.8409, validation loss: 0.1266
2024-05-24 20:48:09 [INFO]: Epoch 095 - training loss: 9233.3992, validation loss: 0.1253
2024-05-24 20:48:09 [INFO]: Epoch 096 - training loss: 9234.1833, validation loss: 0.1238
2024-05-24 20:48:09 [INFO]: Epoch 097 - training loss: 9233.5479, validation loss: 0.1233
2024-05-24 20:48:09 [INFO]: Epoch 098 - training loss: 9233.0326, validation loss: 0.1232
2024-05-24 20:48:09 [INFO]: Epoch 099 - training loss: 9233.1422, validation loss: 0.1222
2024-05-24 20:48:09 [INFO]: Epoch 100 - training loss: 9232.0674, validation loss: 0.1231
2024-05-24 20:48:09 [INFO]: Epoch 101 - training loss: 9237.6478, validation loss: 0.1213
2024-05-24 20:48:09 [INFO]: Epoch 102 - training loss: 9230.8685, validation loss: 0.1222
2024-05-24 20:48:10 [INFO]: Epoch 103 - training loss: 9231.3108, validation loss: 0.1189
2024-05-24 20:48:10 [INFO]: Epoch 104 - training loss: 9230.1740, validation loss: 0.1222
2024-05-24 20:48:10 [INFO]: Epoch 105 - training loss: 9232.0396, validation loss: 0.1211
2024-05-24 20:48:10 [INFO]: Epoch 106 - training loss: 9229.7869, validation loss: 0.1186
2024-05-24 20:48:10 [INFO]: Epoch 107 - training loss: 9227.6272, validation loss: 0.1183
2024-05-24 20:48:10 [INFO]: Epoch 108 - training loss: 9227.0837, validation loss: 0.1174
2024-05-24 20:48:10 [INFO]: Epoch 109 - training loss: 9228.0104, validation loss: 0.1173
2024-05-24 20:48:10 [INFO]: Epoch 110 - training loss: 9229.0012, validation loss: 0.1165
2024-05-24 20:48:10 [INFO]: Epoch 111 - training loss: 9230.4744, validation loss: 0.1161
2024-05-24 20:48:11 [INFO]: Epoch 112 - training loss: 9228.9865, validation loss: 0.1153
2024-05-24 20:48:11 [INFO]: Epoch 113 - training loss: 9226.5336, validation loss: 0.1162
2024-05-24 20:48:11 [INFO]: Epoch 114 - training loss: 9229.2873, validation loss: 0.1161
2024-05-24 20:48:11 [INFO]: Epoch 115 - training loss: 9225.1438, validation loss: 0.1143
2024-05-24 20:48:11 [INFO]: Epoch 116 - training loss: 9226.9794, validation loss: 0.1130
2024-05-24 20:48:11 [INFO]: Epoch 117 - training loss: 9223.6664, validation loss: 0.1135
2024-05-24 20:48:11 [INFO]: Epoch 118 - training loss: 9224.2663, validation loss: 0.1139
2024-05-24 20:48:11 [INFO]: Epoch 119 - training loss: 9225.9066, validation loss: 0.1133
2024-05-24 20:48:11 [INFO]: Epoch 120 - training loss: 9225.5146, validation loss: 0.1115
2024-05-24 20:48:11 [INFO]: Epoch 121 - training loss: 9225.6755, validation loss: 0.1105
2024-05-24 20:48:12 [INFO]: Epoch 122 - training loss: 9225.3495, validation loss: 0.1122
2024-05-24 20:48:12 [INFO]: Epoch 123 - training loss: 9222.3670, validation loss: 0.1103
2024-05-24 20:48:12 [INFO]: Epoch 124 - training loss: 9221.5826, validation loss: 0.1105
2024-05-24 20:48:12 [INFO]: Epoch 125 - training loss: 9224.1148, validation loss: 0.1097
2024-05-24 20:48:12 [INFO]: Epoch 126 - training loss: 9223.8395, validation loss: 0.1108
2024-05-24 20:48:12 [INFO]: Epoch 127 - training loss: 9221.0016, validation loss: 0.1075
2024-05-24 20:48:12 [INFO]: Epoch 128 - training loss: 9220.4252, validation loss: 0.1086
2024-05-24 20:48:12 [INFO]: Epoch 129 - training loss: 9223.2326, validation loss: 0.1075
2024-05-24 20:48:12 [INFO]: Epoch 130 - training loss: 9221.2237, validation loss: 0.1077
2024-05-24 20:48:13 [INFO]: Epoch 131 - training loss: 9220.9834, validation loss: 0.1070
2024-05-24 20:48:13 [INFO]: Epoch 132 - training loss: 9220.9254, validation loss: 0.1068
2024-05-24 20:48:13 [INFO]: Epoch 133 - training loss: 9223.0448, validation loss: 0.1084
2024-05-24 20:48:13 [INFO]: Epoch 134 - training loss: 9220.4019, validation loss: 0.1055
2024-05-24 20:48:13 [INFO]: Epoch 135 - training loss: 9224.3246, validation loss: 0.1054
2024-05-24 20:48:13 [INFO]: Epoch 136 - training loss: 9221.1791, validation loss: 0.1046
2024-05-24 20:48:13 [INFO]: Epoch 137 - training loss: 9221.3889, validation loss: 0.1083
2024-05-24 20:48:13 [INFO]: Epoch 138 - training loss: 9222.3920, validation loss: 0.1028
2024-05-24 20:48:13 [INFO]: Epoch 139 - training loss: 9221.8240, validation loss: 0.1033
2024-05-24 20:48:14 [INFO]: Epoch 140 - training loss: 9220.5533, validation loss: 0.1029
2024-05-24 20:48:14 [INFO]: Epoch 141 - training loss: 9217.7380, validation loss: 0.1040
2024-05-24 20:48:14 [INFO]: Epoch 142 - training loss: 9217.7192, validation loss: 0.1013
2024-05-24 20:48:14 [INFO]: Epoch 143 - training loss: 9219.4281, validation loss: 0.1032
2024-05-24 20:48:14 [INFO]: Epoch 144 - training loss: 9220.4434, validation loss: 0.1023
2024-05-24 20:48:14 [INFO]: Epoch 145 - training loss: 9219.6551, validation loss: 0.1038
2024-05-24 20:48:14 [INFO]: Epoch 146 - training loss: 9218.3827, validation loss: 0.1026
2024-05-24 20:48:14 [INFO]: Epoch 147 - training loss: 9218.0729, validation loss: 0.0993
2024-05-24 20:48:14 [INFO]: Epoch 148 - training loss: 9220.6837, validation loss: 0.1011
2024-05-24 20:48:15 [INFO]: Epoch 149 - training loss: 9217.0503, validation loss: 0.1003
2024-05-24 20:48:15 [INFO]: Epoch 150 - training loss: 9217.1709, validation loss: 0.0995
2024-05-24 20:48:15 [INFO]: Epoch 151 - training loss: 9216.7329, validation loss: 0.1002
2024-05-24 20:48:15 [INFO]: Epoch 152 - training loss: 9216.7809, validation loss: 0.0996
2024-05-24 20:48:15 [INFO]: Epoch 153 - training loss: 9216.5955, validation loss: 0.1001
2024-05-24 20:48:15 [INFO]: Epoch 154 - training loss: 9216.6888, validation loss: 0.0980
2024-05-24 20:48:15 [INFO]: Epoch 155 - training loss: 9216.6682, validation loss: 0.0986
2024-05-24 20:48:15 [INFO]: Epoch 156 - training loss: 9229.4406, validation loss: 0.0962
2024-05-24 20:48:15 [INFO]: Epoch 157 - training loss: 9218.3335, validation loss: 0.0987
2024-05-24 20:48:16 [INFO]: Epoch 158 - training loss: 9215.5312, validation loss: 0.0989
2024-05-24 20:48:16 [INFO]: Epoch 159 - training loss: 9214.9297, validation loss: 0.0961
2024-05-24 20:48:16 [INFO]: Epoch 160 - training loss: 9213.8304, validation loss: 0.0964
2024-05-24 20:48:16 [INFO]: Epoch 161 - training loss: 9215.7982, validation loss: 0.0973
2024-05-24 20:48:16 [INFO]: Epoch 162 - training loss: 9217.8900, validation loss: 0.0964
2024-05-24 20:48:16 [INFO]: Epoch 163 - training loss: 9215.8862, validation loss: 0.0974
2024-05-24 20:48:16 [INFO]: Epoch 164 - training loss: 9217.3027, validation loss: 0.0979
2024-05-24 20:48:16 [INFO]: Epoch 165 - training loss: 9214.1447, validation loss: 0.0964
2024-05-24 20:48:16 [INFO]: Epoch 166 - training loss: 9215.4512, validation loss: 0.0954
2024-05-24 20:48:16 [INFO]: Epoch 167 - training loss: 9214.7952, validation loss: 0.0935
2024-05-24 20:48:17 [INFO]: Epoch 168 - training loss: 9213.9081, validation loss: 0.0937
2024-05-24 20:48:17 [INFO]: Epoch 169 - training loss: 9215.3535, validation loss: 0.0939
2024-05-24 20:48:17 [INFO]: Epoch 170 - training loss: 9214.1315, validation loss: 0.0947
2024-05-24 20:48:17 [INFO]: Epoch 171 - training loss: 9212.6238, validation loss: 0.0947
2024-05-24 20:48:17 [INFO]: Epoch 172 - training loss: 9214.1181, validation loss: 0.0940
2024-05-24 20:48:17 [INFO]: Epoch 173 - training loss: 9215.9494, validation loss: 0.0923
2024-05-24 20:48:17 [INFO]: Epoch 174 - training loss: 9212.7986, validation loss: 0.0944
2024-05-24 20:48:17 [INFO]: Epoch 175 - training loss: 9213.6205, validation loss: 0.0926
2024-05-24 20:48:17 [INFO]: Epoch 176 - training loss: 9213.7863, validation loss: 0.0917
2024-05-24 20:48:18 [INFO]: Epoch 177 - training loss: 9213.8568, validation loss: 0.0919
2024-05-24 20:48:18 [INFO]: Epoch 178 - training loss: 9215.1154, validation loss: 0.0918
2024-05-24 20:48:18 [INFO]: Epoch 179 - training loss: 9211.8702, validation loss: 0.0901
2024-05-24 20:48:18 [INFO]: Epoch 180 - training loss: 9213.3364, validation loss: 0.0932
2024-05-24 20:48:18 [INFO]: Epoch 181 - training loss: 9214.2406, validation loss: 0.0907
2024-05-24 20:48:18 [INFO]: Epoch 182 - training loss: 9213.1174, validation loss: 0.0902
2024-05-24 20:48:18 [INFO]: Epoch 183 - training loss: 9213.1901, validation loss: 0.0901
2024-05-24 20:48:18 [INFO]: Epoch 184 - training loss: 9212.7712, validation loss: 0.0921
2024-05-24 20:48:18 [INFO]: Epoch 185 - training loss: 9212.2628, validation loss: 0.0900
2024-05-24 20:48:19 [INFO]: Epoch 186 - training loss: 9212.7784, validation loss: 0.0914
2024-05-24 20:48:19 [INFO]: Epoch 187 - training loss: 9212.4709, validation loss: 0.0907
2024-05-24 20:48:19 [INFO]: Epoch 188 - training loss: 9213.2527, validation loss: 0.0907
2024-05-24 20:48:19 [INFO]: Epoch 189 - training loss: 9211.0284, validation loss: 0.0908
2024-05-24 20:48:19 [INFO]: Epoch 190 - training loss: 9212.1992, validation loss: 0.0906
2024-05-24 20:48:19 [INFO]: Epoch 191 - training loss: 9211.4355, validation loss: 0.0897
2024-05-24 20:48:19 [INFO]: Epoch 192 - training loss: 9211.1507, validation loss: 0.0910
2024-05-24 20:48:19 [INFO]: Epoch 193 - training loss: 9212.6832, validation loss: 0.0896
2024-05-24 20:48:19 [INFO]: Epoch 194 - training loss: 9213.0557, validation loss: 0.0902
2024-05-24 20:48:20 [INFO]: Epoch 195 - training loss: 9211.7960, validation loss: 0.0899
2024-05-24 20:48:20 [INFO]: Epoch 196 - training loss: 9211.8279, validation loss: 0.0901
2024-05-24 20:48:20 [INFO]: Epoch 197 - training loss: 9209.7015, validation loss: 0.0898
2024-05-24 20:48:20 [INFO]: Epoch 198 - training loss: 9212.9760, validation loss: 0.0879
2024-05-24 20:48:20 [INFO]: Epoch 199 - training loss: 9210.4846, validation loss: 0.0900
2024-05-24 20:48:20 [INFO]: Epoch 200 - training loss: 9211.2629, validation loss: 0.0886
2024-05-24 20:48:20 [INFO]: Epoch 201 - training loss: 9210.0117, validation loss: 0.0883
2024-05-24 20:48:20 [INFO]: Epoch 202 - training loss: 9211.7704, validation loss: 0.0874
2024-05-24 20:48:20 [INFO]: Epoch 203 - training loss: 9212.0273, validation loss: 0.0895
2024-05-24 20:48:20 [INFO]: Epoch 204 - training loss: 9212.1526, validation loss: 0.0891
2024-05-24 20:48:21 [INFO]: Epoch 205 - training loss: 9210.3617, validation loss: 0.0889
2024-05-24 20:48:21 [INFO]: Epoch 206 - training loss: 9210.9670, validation loss: 0.0870
2024-05-24 20:48:21 [INFO]: Epoch 207 - training loss: 9210.8056, validation loss: 0.0878
2024-05-24 20:48:21 [INFO]: Epoch 208 - training loss: 9210.5278, validation loss: 0.0886
2024-05-24 20:48:21 [INFO]: Epoch 209 - training loss: 9211.1927, validation loss: 0.0852
2024-05-24 20:48:21 [INFO]: Epoch 210 - training loss: 9209.0018, validation loss: 0.0875
2024-05-24 20:48:21 [INFO]: Epoch 211 - training loss: 9210.9789, validation loss: 0.0851
2024-05-24 20:48:21 [INFO]: Epoch 212 - training loss: 9210.3961, validation loss: 0.0848
2024-05-24 20:48:21 [INFO]: Epoch 213 - training loss: 9210.3300, validation loss: 0.0884
2024-05-24 20:48:22 [INFO]: Epoch 214 - training loss: 9210.4942, validation loss: 0.0863
2024-05-24 20:48:22 [INFO]: Epoch 215 - training loss: 9209.3857, validation loss: 0.0851
2024-05-24 20:48:22 [INFO]: Epoch 216 - training loss: 9211.4976, validation loss: 0.0871
2024-05-24 20:48:22 [INFO]: Epoch 217 - training loss: 9210.7131, validation loss: 0.0866
2024-05-24 20:48:22 [INFO]: Epoch 218 - training loss: 9211.5486, validation loss: 0.0849
2024-05-24 20:48:22 [INFO]: Epoch 219 - training loss: 9210.3664, validation loss: 0.0873
2024-05-24 20:48:22 [INFO]: Epoch 220 - training loss: 9209.7579, validation loss: 0.0854
2024-05-24 20:48:22 [INFO]: Epoch 221 - training loss: 9210.2739, validation loss: 0.0849
2024-05-24 20:48:22 [INFO]: Epoch 222 - training loss: 9210.6606, validation loss: 0.0856
2024-05-24 20:48:22 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:48:22 [INFO]: Finished training. The best model is from epoch#212.
2024-05-24 20:48:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/GPVAE_ettm1/20240524_T204758/GPVAE.pypots
2024-05-24 20:48:22 [INFO]: GP-VAE on ETTm1: MAE=0.3009, MSE=0.1952
2024-05-24 20:48:22 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/GPVAE_ettm1/imputation.pkl
2024-05-24 20:48:22 [INFO]: Using the given device: cuda:0
2024-05-24 20:48:22 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T204822
2024-05-24 20:48:22 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T204822/tensorboard
2024-05-24 20:48:22 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 74,951
2024-05-24 20:48:31 [INFO]: Epoch 001 - generator training loss: 0.4370, discriminator training loss: 0.5376, validation loss: 0.3521
2024-05-24 20:48:37 [INFO]: Epoch 002 - generator training loss: -0.0667, discriminator training loss: 0.4740, validation loss: 0.1105
2024-05-24 20:48:44 [INFO]: Epoch 003 - generator training loss: -0.1717, discriminator training loss: 0.4344, validation loss: 0.0697
2024-05-24 20:48:51 [INFO]: Epoch 004 - generator training loss: -0.1546, discriminator training loss: 0.3750, validation loss: 0.0527
2024-05-24 20:48:58 [INFO]: Epoch 005 - generator training loss: -0.1064, discriminator training loss: 0.2997, validation loss: 0.0465
2024-05-24 20:49:05 [INFO]: Epoch 006 - generator training loss: -0.0793, discriminator training loss: 0.2371, validation loss: 0.0429
2024-05-24 20:49:12 [INFO]: Epoch 007 - generator training loss: -0.0617, discriminator training loss: 0.2022, validation loss: 0.0393
2024-05-24 20:49:19 [INFO]: Epoch 008 - generator training loss: -0.0560, discriminator training loss: 0.1847, validation loss: 0.0373
2024-05-24 20:49:26 [INFO]: Epoch 009 - generator training loss: -0.0592, discriminator training loss: 0.1786, validation loss: 0.0375
2024-05-24 20:49:33 [INFO]: Epoch 010 - generator training loss: -0.0547, discriminator training loss: 0.1794, validation loss: 0.0351
2024-05-24 20:49:40 [INFO]: Epoch 011 - generator training loss: -0.0579, discriminator training loss: 0.1746, validation loss: 0.0483
2024-05-24 20:49:47 [INFO]: Epoch 012 - generator training loss: -0.0556, discriminator training loss: 0.1744, validation loss: 0.0456
2024-05-24 20:49:54 [INFO]: Epoch 013 - generator training loss: -0.0559, discriminator training loss: 0.1735, validation loss: 0.0371
2024-05-24 20:50:01 [INFO]: Epoch 014 - generator training loss: -0.0569, discriminator training loss: 0.1717, validation loss: 0.0348
2024-05-24 20:50:08 [INFO]: Epoch 015 - generator training loss: -0.0600, discriminator training loss: 0.1729, validation loss: 0.0338
2024-05-24 20:50:15 [INFO]: Epoch 016 - generator training loss: -0.0595, discriminator training loss: 0.1702, validation loss: 0.0326
2024-05-24 20:50:22 [INFO]: Epoch 017 - generator training loss: -0.0597, discriminator training loss: 0.1708, validation loss: 0.0319
2024-05-24 20:50:29 [INFO]: Epoch 018 - generator training loss: -0.0623, discriminator training loss: 0.1715, validation loss: 0.0329
2024-05-24 20:50:36 [INFO]: Epoch 019 - generator training loss: -0.0610, discriminator training loss: 0.1723, validation loss: 0.0324
2024-05-24 20:50:43 [INFO]: Epoch 020 - generator training loss: -0.0632, discriminator training loss: 0.1697, validation loss: 0.0313
2024-05-24 20:50:51 [INFO]: Epoch 021 - generator training loss: -0.0619, discriminator training loss: 0.1674, validation loss: 0.0312
2024-05-24 20:50:58 [INFO]: Epoch 022 - generator training loss: -0.0658, discriminator training loss: 0.1682, validation loss: 0.0309
2024-05-24 20:51:05 [INFO]: Epoch 023 - generator training loss: -0.0654, discriminator training loss: 0.1719, validation loss: 0.0306
2024-05-24 20:51:12 [INFO]: Epoch 024 - generator training loss: -0.0630, discriminator training loss: 0.1707, validation loss: 0.0305
2024-05-24 20:51:19 [INFO]: Epoch 025 - generator training loss: -0.0627, discriminator training loss: 0.1702, validation loss: 0.0302
2024-05-24 20:51:25 [INFO]: Epoch 026 - generator training loss: -0.0631, discriminator training loss: 0.1703, validation loss: 0.0303
2024-05-24 20:51:32 [INFO]: Epoch 027 - generator training loss: -0.0626, discriminator training loss: 0.1695, validation loss: 0.0304
2024-05-24 20:51:40 [INFO]: Epoch 028 - generator training loss: -0.0643, discriminator training loss: 0.1686, validation loss: 0.0296
2024-05-24 20:51:46 [INFO]: Epoch 029 - generator training loss: -0.0658, discriminator training loss: 0.1704, validation loss: 0.0298
2024-05-24 20:51:53 [INFO]: Epoch 030 - generator training loss: -0.0653, discriminator training loss: 0.1667, validation loss: 0.0295
2024-05-24 20:52:00 [INFO]: Epoch 031 - generator training loss: -0.0653, discriminator training loss: 0.1701, validation loss: 0.0293
2024-05-24 20:52:07 [INFO]: Epoch 032 - generator training loss: -0.0637, discriminator training loss: 0.1679, validation loss: 0.0365
2024-05-24 20:52:14 [INFO]: Epoch 033 - generator training loss: -0.0606, discriminator training loss: 0.1691, validation loss: 0.0373
2024-05-24 20:52:21 [INFO]: Epoch 034 - generator training loss: -0.0602, discriminator training loss: 0.1684, validation loss: 0.0332
2024-05-24 20:52:29 [INFO]: Epoch 035 - generator training loss: -0.0624, discriminator training loss: 0.1685, validation loss: 0.0299
2024-05-24 20:52:36 [INFO]: Epoch 036 - generator training loss: -0.0638, discriminator training loss: 0.1662, validation loss: 0.0297
2024-05-24 20:52:43 [INFO]: Epoch 037 - generator training loss: -0.0650, discriminator training loss: 0.1669, validation loss: 0.0290
2024-05-24 20:52:50 [INFO]: Epoch 038 - generator training loss: -0.0675, discriminator training loss: 0.1672, validation loss: 0.0284
2024-05-24 20:52:57 [INFO]: Epoch 039 - generator training loss: -0.0674, discriminator training loss: 0.1660, validation loss: 0.0288
2024-05-24 20:53:04 [INFO]: Epoch 040 - generator training loss: -0.0675, discriminator training loss: 0.1688, validation loss: 0.0295
2024-05-24 20:53:11 [INFO]: Epoch 041 - generator training loss: -0.0624, discriminator training loss: 0.1668, validation loss: 0.0293
2024-05-24 20:53:18 [INFO]: Epoch 042 - generator training loss: -0.0694, discriminator training loss: 0.1661, validation loss: 0.0281
2024-05-24 20:53:25 [INFO]: Epoch 043 - generator training loss: -0.0680, discriminator training loss: 0.1648, validation loss: 0.0288
2024-05-24 20:53:32 [INFO]: Epoch 044 - generator training loss: -0.0626, discriminator training loss: 0.1665, validation loss: 0.0290
2024-05-24 20:53:39 [INFO]: Epoch 045 - generator training loss: -0.0706, discriminator training loss: 0.1666, validation loss: 0.0283
2024-05-24 20:53:46 [INFO]: Epoch 046 - generator training loss: -0.0658, discriminator training loss: 0.1657, validation loss: 0.0281
2024-05-24 20:53:53 [INFO]: Epoch 047 - generator training loss: -0.0661, discriminator training loss: 0.1683, validation loss: 0.0277
2024-05-24 20:54:00 [INFO]: Epoch 048 - generator training loss: -0.0647, discriminator training loss: 0.1674, validation loss: 0.0275
2024-05-24 20:54:07 [INFO]: Epoch 049 - generator training loss: -0.0666, discriminator training loss: 0.1657, validation loss: 0.0283
2024-05-24 20:54:14 [INFO]: Epoch 050 - generator training loss: -0.0682, discriminator training loss: 0.1654, validation loss: 0.0273
2024-05-24 20:54:21 [INFO]: Epoch 051 - generator training loss: -0.0673, discriminator training loss: 0.1683, validation loss: 0.0282
2024-05-24 20:54:28 [INFO]: Epoch 052 - generator training loss: -0.0644, discriminator training loss: 0.1672, validation loss: 0.0278
2024-05-24 20:54:35 [INFO]: Epoch 053 - generator training loss: -0.0673, discriminator training loss: 0.1674, validation loss: 0.0277
2024-05-24 20:54:42 [INFO]: Epoch 054 - generator training loss: -0.0650, discriminator training loss: 0.1652, validation loss: 0.0276
2024-05-24 20:54:49 [INFO]: Epoch 055 - generator training loss: -0.0661, discriminator training loss: 0.1666, validation loss: 0.0275
2024-05-24 20:54:56 [INFO]: Epoch 056 - generator training loss: -0.0641, discriminator training loss: 0.1666, validation loss: 0.0274
2024-05-24 20:55:03 [INFO]: Epoch 057 - generator training loss: -0.0690, discriminator training loss: 0.1649, validation loss: 0.0277
2024-05-24 20:55:10 [INFO]: Epoch 058 - generator training loss: -0.0656, discriminator training loss: 0.1663, validation loss: 0.0277
2024-05-24 20:55:17 [INFO]: Epoch 059 - generator training loss: -0.0681, discriminator training loss: 0.1664, validation loss: 0.0275
2024-05-24 20:55:24 [INFO]: Epoch 060 - generator training loss: -0.0661, discriminator training loss: 0.1641, validation loss: 0.0277
2024-05-24 20:55:24 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:55:24 [INFO]: Finished training. The best model is from epoch#50.
2024-05-24 20:55:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/USGAN_ettm1/20240524_T204822/USGAN.pypots
2024-05-24 20:55:25 [INFO]: US-GAN on ETTm1: MAE=0.1641, MSE=0.0661
2024-05-24 20:55:25 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/USGAN_ettm1/imputation.pkl
2024-05-24 20:55:25 [INFO]: Using the given device: cuda:0
2024-05-24 20:55:25 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T205525
2024-05-24 20:55:25 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T205525/tensorboard
2024-05-24 20:55:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 43,328
2024-05-24 20:55:30 [INFO]: Epoch 001 - training loss: 1.3472, validation loss: 0.2983
2024-05-24 20:55:35 [INFO]: Epoch 002 - training loss: 0.9198, validation loss: 0.0942
2024-05-24 20:55:40 [INFO]: Epoch 003 - training loss: 0.7552, validation loss: 0.0607
2024-05-24 20:55:44 [INFO]: Epoch 004 - training loss: 0.6732, validation loss: 0.0450
2024-05-24 20:55:49 [INFO]: Epoch 005 - training loss: 0.6262, validation loss: 0.0418
2024-05-24 20:55:53 [INFO]: Epoch 006 - training loss: 0.5848, validation loss: 0.0411
2024-05-24 20:55:58 [INFO]: Epoch 007 - training loss: 0.5614, validation loss: 0.0378
2024-05-24 20:56:03 [INFO]: Epoch 008 - training loss: 0.5422, validation loss: 0.0360
2024-05-24 20:56:07 [INFO]: Epoch 009 - training loss: 0.5260, validation loss: 0.0329
2024-05-24 20:56:12 [INFO]: Epoch 010 - training loss: 0.4961, validation loss: 0.0332
2024-05-24 20:56:16 [INFO]: Epoch 011 - training loss: 0.4790, validation loss: 0.0325
2024-05-24 20:56:21 [INFO]: Epoch 012 - training loss: 0.4730, validation loss: 0.0324
2024-05-24 20:56:26 [INFO]: Epoch 013 - training loss: 0.4619, validation loss: 0.0314
2024-05-24 20:56:30 [INFO]: Epoch 014 - training loss: 0.4400, validation loss: 0.0299
2024-05-24 20:56:35 [INFO]: Epoch 015 - training loss: 0.4374, validation loss: 0.0294
2024-05-24 20:56:39 [INFO]: Epoch 016 - training loss: 0.4226, validation loss: 0.0282
2024-05-24 20:56:44 [INFO]: Epoch 017 - training loss: 0.4161, validation loss: 0.0281
2024-05-24 20:56:49 [INFO]: Epoch 018 - training loss: 0.4068, validation loss: 0.0263
2024-05-24 20:56:53 [INFO]: Epoch 019 - training loss: 0.4107, validation loss: 0.0267
2024-05-24 20:56:58 [INFO]: Epoch 020 - training loss: 0.4082, validation loss: 0.0262
2024-05-24 20:57:03 [INFO]: Epoch 021 - training loss: 0.4080, validation loss: 0.0262
2024-05-24 20:57:07 [INFO]: Epoch 022 - training loss: 0.4054, validation loss: 0.0270
2024-05-24 20:57:12 [INFO]: Epoch 023 - training loss: 0.4066, validation loss: 0.0263
2024-05-24 20:57:16 [INFO]: Epoch 024 - training loss: 0.4008, validation loss: 0.0257
2024-05-24 20:57:21 [INFO]: Epoch 025 - training loss: 0.4121, validation loss: 0.0255
2024-05-24 20:57:26 [INFO]: Epoch 026 - training loss: 0.4101, validation loss: 0.0261
2024-05-24 20:57:30 [INFO]: Epoch 027 - training loss: 0.3994, validation loss: 0.0261
2024-05-24 20:57:35 [INFO]: Epoch 028 - training loss: 0.3991, validation loss: 0.0259
2024-05-24 20:57:39 [INFO]: Epoch 029 - training loss: 0.3968, validation loss: 0.0254
2024-05-24 20:57:44 [INFO]: Epoch 030 - training loss: 0.3972, validation loss: 0.0254
2024-05-24 20:57:48 [INFO]: Epoch 031 - training loss: 0.4017, validation loss: 0.0251
2024-05-24 20:57:53 [INFO]: Epoch 032 - training loss: 0.4018, validation loss: 0.0255
2024-05-24 20:57:58 [INFO]: Epoch 033 - training loss: 0.4061, validation loss: 0.0255
2024-05-24 20:58:02 [INFO]: Epoch 034 - training loss: 0.3958, validation loss: 0.0249
2024-05-24 20:58:07 [INFO]: Epoch 035 - training loss: 0.3938, validation loss: 0.0255
2024-05-24 20:58:11 [INFO]: Epoch 036 - training loss: 0.4076, validation loss: 0.0258
2024-05-24 20:58:16 [INFO]: Epoch 037 - training loss: 0.4091, validation loss: 0.0255
2024-05-24 20:58:21 [INFO]: Epoch 038 - training loss: 0.3995, validation loss: 0.0254
2024-05-24 20:58:25 [INFO]: Epoch 039 - training loss: 0.3969, validation loss: 0.0256
2024-05-24 20:58:30 [INFO]: Epoch 040 - training loss: 0.3922, validation loss: 0.0253
2024-05-24 20:58:35 [INFO]: Epoch 041 - training loss: 0.4474, validation loss: 0.0276
2024-05-24 20:58:39 [INFO]: Epoch 042 - training loss: 0.4227, validation loss: 0.0281
2024-05-24 20:58:44 [INFO]: Epoch 043 - training loss: 0.4125, validation loss: 0.0267
2024-05-24 20:58:48 [INFO]: Epoch 044 - training loss: 0.3983, validation loss: 0.0279
2024-05-24 20:58:48 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:58:48 [INFO]: Finished training. The best model is from epoch#34.
2024-05-24 20:58:48 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/BRITS_ettm1/20240524_T205525/BRITS.pypots
2024-05-24 20:58:49 [INFO]: BRITS on ETTm1: MAE=0.1540, MSE=0.0705
2024-05-24 20:58:49 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/BRITS_ettm1/imputation.pkl
2024-05-24 20:58:49 [INFO]: Using the given device: cuda:0
2024-05-24 20:58:49 [INFO]: Model files will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849
2024-05-24 20:58:49 [INFO]: Tensorboard file will be saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/tensorboard
2024-05-24 20:58:49 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 102,611
2024-05-24 20:58:50 [INFO]: Epoch 001 - training loss: 1.3383, validation loss: 1.3017
2024-05-24 20:58:50 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch1_loss1.3016782104969025.pypots
2024-05-24 20:58:51 [INFO]: Epoch 002 - training loss: 1.0211, validation loss: 1.1562
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch2_loss1.1561521738767624.pypots
2024-05-24 20:58:51 [INFO]: Epoch 003 - training loss: 0.9264, validation loss: 1.0870
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch3_loss1.0870168805122375.pypots
2024-05-24 20:58:51 [INFO]: Epoch 004 - training loss: 0.9377, validation loss: 1.0511
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch4_loss1.0510737150907516.pypots
2024-05-24 20:58:51 [INFO]: Epoch 005 - training loss: 0.9101, validation loss: 1.0356
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch5_loss1.0356064587831497.pypots
2024-05-24 20:58:51 [INFO]: Epoch 006 - training loss: 0.8603, validation loss: 1.0289
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch6_loss1.0288509279489517.pypots
2024-05-24 20:58:51 [INFO]: Epoch 007 - training loss: 0.8730, validation loss: 1.0252
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch7_loss1.0252114236354828.pypots
2024-05-24 20:58:51 [INFO]: Epoch 008 - training loss: 0.8558, validation loss: 1.0200
2024-05-24 20:58:51 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch8_loss1.0199599862098694.pypots
2024-05-24 20:58:52 [INFO]: Epoch 009 - training loss: 0.8416, validation loss: 1.0222
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch9_loss1.0221974551677704.pypots
2024-05-24 20:58:52 [INFO]: Epoch 010 - training loss: 0.8742, validation loss: 1.0243
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch10_loss1.024262934923172.pypots
2024-05-24 20:58:52 [INFO]: Epoch 011 - training loss: 0.8525, validation loss: 1.0201
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch11_loss1.0201077163219452.pypots
2024-05-24 20:58:52 [INFO]: Epoch 012 - training loss: 0.8387, validation loss: 1.0196
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch12_loss1.0195677280426025.pypots
2024-05-24 20:58:52 [INFO]: Epoch 013 - training loss: 0.8468, validation loss: 1.0166
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch13_loss1.0165523141622543.pypots
2024-05-24 20:58:52 [INFO]: Epoch 014 - training loss: 0.8404, validation loss: 1.0169
2024-05-24 20:58:52 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch14_loss1.0168517082929611.pypots
2024-05-24 20:58:53 [INFO]: Epoch 015 - training loss: 0.8345, validation loss: 1.0157
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch15_loss1.015696719288826.pypots
2024-05-24 20:58:53 [INFO]: Epoch 016 - training loss: 0.8296, validation loss: 1.0127
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch16_loss1.0126552432775497.pypots
2024-05-24 20:58:53 [INFO]: Epoch 017 - training loss: 0.8097, validation loss: 1.0033
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch17_loss1.0032907724380493.pypots
2024-05-24 20:58:53 [INFO]: Epoch 018 - training loss: 0.8090, validation loss: 0.9989
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch18_loss0.9989310204982758.pypots
2024-05-24 20:58:53 [INFO]: Epoch 019 - training loss: 0.8189, validation loss: 1.0010
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch19_loss1.0010399222373962.pypots
2024-05-24 20:58:53 [INFO]: Epoch 020 - training loss: 0.7866, validation loss: 0.9977
2024-05-24 20:58:53 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch20_loss0.9976894557476044.pypots
2024-05-24 20:58:54 [INFO]: Epoch 021 - training loss: 0.8011, validation loss: 0.9942
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch21_loss0.99419766664505.pypots
2024-05-24 20:58:54 [INFO]: Epoch 022 - training loss: 0.7865, validation loss: 0.9935
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch22_loss0.99351866543293.pypots
2024-05-24 20:58:54 [INFO]: Epoch 023 - training loss: 0.7879, validation loss: 0.9853
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch23_loss0.9852601438760757.pypots
2024-05-24 20:58:54 [INFO]: Epoch 024 - training loss: 0.7825, validation loss: 0.9812
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch24_loss0.9812154322862625.pypots
2024-05-24 20:58:54 [INFO]: Epoch 025 - training loss: 0.7823, validation loss: 0.9839
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch25_loss0.9838926643133163.pypots
2024-05-24 20:58:54 [INFO]: Epoch 026 - training loss: 0.7831, validation loss: 0.9835
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch26_loss0.9834596365690231.pypots
2024-05-24 20:58:54 [INFO]: Epoch 027 - training loss: 0.7794, validation loss: 0.9820
2024-05-24 20:58:54 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch27_loss0.9820257127285004.pypots
2024-05-24 20:58:55 [INFO]: Epoch 028 - training loss: 0.7759, validation loss: 0.9825
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch28_loss0.9825295060873032.pypots
2024-05-24 20:58:55 [INFO]: Epoch 029 - training loss: 0.7724, validation loss: 0.9810
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch29_loss0.981028363108635.pypots
2024-05-24 20:58:55 [INFO]: Epoch 030 - training loss: 0.7695, validation loss: 0.9772
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch30_loss0.9772215485572815.pypots
2024-05-24 20:58:55 [INFO]: Epoch 031 - training loss: 0.7530, validation loss: 0.9771
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch31_loss0.977124035358429.pypots
2024-05-24 20:58:55 [INFO]: Epoch 032 - training loss: 0.7652, validation loss: 0.9746
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch32_loss0.9745571166276932.pypots
2024-05-24 20:58:55 [INFO]: Epoch 033 - training loss: 0.7629, validation loss: 0.9738
2024-05-24 20:58:55 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch33_loss0.9737761318683624.pypots
2024-05-24 20:58:56 [INFO]: Epoch 034 - training loss: 0.7547, validation loss: 0.9743
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch34_loss0.9742680937051773.pypots
2024-05-24 20:58:56 [INFO]: Epoch 035 - training loss: 0.7548, validation loss: 0.9712
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch35_loss0.9712024033069611.pypots
2024-05-24 20:58:56 [INFO]: Epoch 036 - training loss: 0.7645, validation loss: 0.9712
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch36_loss0.9712185859680176.pypots
2024-05-24 20:58:56 [INFO]: Epoch 037 - training loss: 0.7570, validation loss: 0.9661
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch37_loss0.9661167412996292.pypots
2024-05-24 20:58:56 [INFO]: Epoch 038 - training loss: 0.7544, validation loss: 0.9698
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch38_loss0.969836875796318.pypots
2024-05-24 20:58:56 [INFO]: Epoch 039 - training loss: 0.7484, validation loss: 0.9649
2024-05-24 20:58:56 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch39_loss0.9649423062801361.pypots
2024-05-24 20:58:57 [INFO]: Epoch 040 - training loss: 0.7624, validation loss: 0.9657
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch40_loss0.9657364338636398.pypots
2024-05-24 20:58:57 [INFO]: Epoch 041 - training loss: 0.7297, validation loss: 0.9656
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch41_loss0.9656398296356201.pypots
2024-05-24 20:58:57 [INFO]: Epoch 042 - training loss: 0.7488, validation loss: 0.9633
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch42_loss0.9633127748966217.pypots
2024-05-24 20:58:57 [INFO]: Epoch 043 - training loss: 0.7428, validation loss: 0.9650
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch43_loss0.9649603366851807.pypots
2024-05-24 20:58:57 [INFO]: Epoch 044 - training loss: 0.7428, validation loss: 0.9658
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch44_loss0.9658029675483704.pypots
2024-05-24 20:58:57 [INFO]: Epoch 045 - training loss: 0.7529, validation loss: 0.9642
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch45_loss0.9642049223184586.pypots
2024-05-24 20:58:57 [INFO]: Epoch 046 - training loss: 0.7382, validation loss: 0.9579
2024-05-24 20:58:57 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch46_loss0.9578712731599808.pypots
2024-05-24 20:58:58 [INFO]: Epoch 047 - training loss: 0.7574, validation loss: 0.9562
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch47_loss0.9562242329120636.pypots
2024-05-24 20:58:58 [INFO]: Epoch 048 - training loss: 0.7423, validation loss: 0.9564
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch48_loss0.9564081579446793.pypots
2024-05-24 20:58:58 [INFO]: Epoch 049 - training loss: 0.7521, validation loss: 0.9562
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch49_loss0.9561958163976669.pypots
2024-05-24 20:58:58 [INFO]: Epoch 050 - training loss: 0.7462, validation loss: 0.9524
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch50_loss0.952383428812027.pypots
2024-05-24 20:58:58 [INFO]: Epoch 051 - training loss: 0.7712, validation loss: 0.9528
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch51_loss0.9527876824140549.pypots
2024-05-24 20:58:58 [INFO]: Epoch 052 - training loss: 0.7587, validation loss: 0.9511
2024-05-24 20:58:58 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch52_loss0.9510879367589951.pypots
2024-05-24 20:58:59 [INFO]: Epoch 053 - training loss: 0.7386, validation loss: 0.9499
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch53_loss0.9499436020851135.pypots
2024-05-24 20:58:59 [INFO]: Epoch 054 - training loss: 0.7429, validation loss: 0.9484
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch54_loss0.9484219253063202.pypots
2024-05-24 20:58:59 [INFO]: Epoch 055 - training loss: 0.7435, validation loss: 0.9489
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch55_loss0.9489192217588425.pypots
2024-05-24 20:58:59 [INFO]: Epoch 056 - training loss: 0.7446, validation loss: 0.9454
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch56_loss0.9454090297222137.pypots
2024-05-24 20:58:59 [INFO]: Epoch 057 - training loss: 0.7235, validation loss: 0.9466
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch57_loss0.9465561658143997.pypots
2024-05-24 20:58:59 [INFO]: Epoch 058 - training loss: 0.7532, validation loss: 0.9463
2024-05-24 20:58:59 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch58_loss0.9462531805038452.pypots
2024-05-24 20:59:00 [INFO]: Epoch 059 - training loss: 0.7209, validation loss: 0.9474
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch59_loss0.9474022388458252.pypots
2024-05-24 20:59:00 [INFO]: Epoch 060 - training loss: 0.7160, validation loss: 0.9440
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch60_loss0.9439559727907181.pypots
2024-05-24 20:59:00 [INFO]: Epoch 061 - training loss: 0.7280, validation loss: 0.9459
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch61_loss0.9458604604005814.pypots
2024-05-24 20:59:00 [INFO]: Epoch 062 - training loss: 0.7472, validation loss: 0.9410
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch62_loss0.9409759938716888.pypots
2024-05-24 20:59:00 [INFO]: Epoch 063 - training loss: 0.7357, validation loss: 0.9397
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch63_loss0.9397120475769043.pypots
2024-05-24 20:59:00 [INFO]: Epoch 064 - training loss: 0.7213, validation loss: 0.9399
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch64_loss0.9399297535419464.pypots
2024-05-24 20:59:00 [INFO]: Epoch 065 - training loss: 0.7473, validation loss: 0.9377
2024-05-24 20:59:00 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch65_loss0.9376551508903503.pypots
2024-05-24 20:59:01 [INFO]: Epoch 066 - training loss: 0.7320, validation loss: 0.9345
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch66_loss0.9344981908798218.pypots
2024-05-24 20:59:01 [INFO]: Epoch 067 - training loss: 0.7624, validation loss: 0.9368
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch67_loss0.9367644786834717.pypots
2024-05-24 20:59:01 [INFO]: Epoch 068 - training loss: 0.7381, validation loss: 0.9336
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch68_loss0.933645635843277.pypots
2024-05-24 20:59:01 [INFO]: Epoch 069 - training loss: 0.7268, validation loss: 0.9299
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch69_loss0.9299467504024506.pypots
2024-05-24 20:59:01 [INFO]: Epoch 070 - training loss: 0.7443, validation loss: 0.9301
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch70_loss0.9300585687160492.pypots
2024-05-24 20:59:01 [INFO]: Epoch 071 - training loss: 0.7532, validation loss: 0.9366
2024-05-24 20:59:01 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch71_loss0.9365685433149338.pypots
2024-05-24 20:59:02 [INFO]: Epoch 072 - training loss: 0.7391, validation loss: 0.9317
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch72_loss0.9316898435354233.pypots
2024-05-24 20:59:02 [INFO]: Epoch 073 - training loss: 0.7493, validation loss: 0.9304
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch73_loss0.9303980469703674.pypots
2024-05-24 20:59:02 [INFO]: Epoch 074 - training loss: 0.7372, validation loss: 0.9270
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch74_loss0.9270212799310684.pypots
2024-05-24 20:59:02 [INFO]: Epoch 075 - training loss: 0.7559, validation loss: 0.9262
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch75_loss0.926236554980278.pypots
2024-05-24 20:59:02 [INFO]: Epoch 076 - training loss: 0.7235, validation loss: 0.9248
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch76_loss0.9247927814722061.pypots
2024-05-24 20:59:02 [INFO]: Epoch 077 - training loss: 0.7210, validation loss: 0.9245
2024-05-24 20:59:02 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch77_loss0.9244620501995087.pypots
2024-05-24 20:59:03 [INFO]: Epoch 078 - training loss: 0.7337, validation loss: 0.9223
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch78_loss0.9223426878452301.pypots
2024-05-24 20:59:03 [INFO]: Epoch 079 - training loss: 0.7544, validation loss: 0.9178
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch79_loss0.9178093373775482.pypots
2024-05-24 20:59:03 [INFO]: Epoch 080 - training loss: 0.7360, validation loss: 0.9196
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch80_loss0.9196455627679825.pypots
2024-05-24 20:59:03 [INFO]: Epoch 081 - training loss: 0.7435, validation loss: 0.9213
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch81_loss0.9213258475065231.pypots
2024-05-24 20:59:03 [INFO]: Epoch 082 - training loss: 0.7382, validation loss: 0.9174
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch82_loss0.9174168556928635.pypots
2024-05-24 20:59:03 [INFO]: Epoch 083 - training loss: 0.7589, validation loss: 0.9177
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch83_loss0.9177006632089615.pypots
2024-05-24 20:59:03 [INFO]: Epoch 084 - training loss: 0.7129, validation loss: 0.9171
2024-05-24 20:59:03 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch84_loss0.9171246290206909.pypots
2024-05-24 20:59:04 [INFO]: Epoch 085 - training loss: 0.7264, validation loss: 0.9184
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch85_loss0.9183778315782547.pypots
2024-05-24 20:59:04 [INFO]: Epoch 086 - training loss: 0.7415, validation loss: 0.9200
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch86_loss0.9200129210948944.pypots
2024-05-24 20:59:04 [INFO]: Epoch 087 - training loss: 0.7509, validation loss: 0.9194
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch87_loss0.9193940311670303.pypots
2024-05-24 20:59:04 [INFO]: Epoch 088 - training loss: 0.7453, validation loss: 0.9135
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch88_loss0.9134703427553177.pypots
2024-05-24 20:59:04 [INFO]: Epoch 089 - training loss: 0.7246, validation loss: 0.9165
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch89_loss0.9165158420801163.pypots
2024-05-24 20:59:04 [INFO]: Epoch 090 - training loss: 0.7366, validation loss: 0.9188
2024-05-24 20:59:04 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch90_loss0.9187879264354706.pypots
2024-05-24 20:59:05 [INFO]: Epoch 091 - training loss: 0.7488, validation loss: 0.9167
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch91_loss0.916717141866684.pypots
2024-05-24 20:59:05 [INFO]: Epoch 092 - training loss: 0.7137, validation loss: 0.9152
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch92_loss0.9152241051197052.pypots
2024-05-24 20:59:05 [INFO]: Epoch 093 - training loss: 0.7371, validation loss: 0.9101
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch93_loss0.9100511819124222.pypots
2024-05-24 20:59:05 [INFO]: Epoch 094 - training loss: 0.7471, validation loss: 0.9131
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch94_loss0.9131119251251221.pypots
2024-05-24 20:59:05 [INFO]: Epoch 095 - training loss: 0.7440, validation loss: 0.9158
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch95_loss0.9157790243625641.pypots
2024-05-24 20:59:05 [INFO]: Epoch 096 - training loss: 0.7216, validation loss: 0.9124
2024-05-24 20:59:05 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch96_loss0.9123931676149368.pypots
2024-05-24 20:59:06 [INFO]: Epoch 097 - training loss: 0.7112, validation loss: 0.9095
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch97_loss0.9095215648412704.pypots
2024-05-24 20:59:06 [INFO]: Epoch 098 - training loss: 0.7295, validation loss: 0.9117
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch98_loss0.9116539061069489.pypots
2024-05-24 20:59:06 [INFO]: Epoch 099 - training loss: 0.7199, validation loss: 0.9059
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch99_loss0.9059204161167145.pypots
2024-05-24 20:59:06 [INFO]: Epoch 100 - training loss: 0.7202, validation loss: 0.9106
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch100_loss0.9105730801820755.pypots
2024-05-24 20:59:06 [INFO]: Epoch 101 - training loss: 0.7272, validation loss: 0.9075
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch101_loss0.9075033664703369.pypots
2024-05-24 20:59:06 [INFO]: Epoch 102 - training loss: 0.7294, validation loss: 0.9058
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch102_loss0.9058421105146408.pypots
2024-05-24 20:59:06 [INFO]: Epoch 103 - training loss: 0.7359, validation loss: 0.9057
2024-05-24 20:59:06 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch103_loss0.9057113081216812.pypots
2024-05-24 20:59:07 [INFO]: Epoch 104 - training loss: 0.7290, validation loss: 0.9043
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch104_loss0.9042725116014481.pypots
2024-05-24 20:59:07 [INFO]: Epoch 105 - training loss: 0.7368, validation loss: 0.9062
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch105_loss0.9061647951602936.pypots
2024-05-24 20:59:07 [INFO]: Epoch 106 - training loss: 0.7440, validation loss: 0.9061
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch106_loss0.9061027020215988.pypots
2024-05-24 20:59:07 [INFO]: Epoch 107 - training loss: 0.7224, validation loss: 0.8992
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch107_loss0.8992114365100861.pypots
2024-05-24 20:59:07 [INFO]: Epoch 108 - training loss: 0.7385, validation loss: 0.9011
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch108_loss0.9011259824037552.pypots
2024-05-24 20:59:07 [INFO]: Epoch 109 - training loss: 0.7258, validation loss: 0.8988
2024-05-24 20:59:07 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch109_loss0.8987873494625092.pypots
2024-05-24 20:59:08 [INFO]: Epoch 110 - training loss: 0.7257, validation loss: 0.9003
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch110_loss0.9002505093812943.pypots
2024-05-24 20:59:08 [INFO]: Epoch 111 - training loss: 0.7420, validation loss: 0.8983
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch111_loss0.8983494788408279.pypots
2024-05-24 20:59:08 [INFO]: Epoch 112 - training loss: 0.7069, validation loss: 0.8945
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch112_loss0.8944510817527771.pypots
2024-05-24 20:59:08 [INFO]: Epoch 113 - training loss: 0.7307, validation loss: 0.8979
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch113_loss0.8979129195213318.pypots
2024-05-24 20:59:08 [INFO]: Epoch 114 - training loss: 0.7258, validation loss: 0.8980
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch114_loss0.8979511857032776.pypots
2024-05-24 20:59:08 [INFO]: Epoch 115 - training loss: 0.7181, validation loss: 0.8982
2024-05-24 20:59:08 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch115_loss0.8981588929891586.pypots
2024-05-24 20:59:09 [INFO]: Epoch 116 - training loss: 0.7224, validation loss: 0.8956
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch116_loss0.8956418335437775.pypots
2024-05-24 20:59:09 [INFO]: Epoch 117 - training loss: 0.7175, validation loss: 0.8924
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch117_loss0.8924416601657867.pypots
2024-05-24 20:59:09 [INFO]: Epoch 118 - training loss: 0.7191, validation loss: 0.8926
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch118_loss0.8925883769989014.pypots
2024-05-24 20:59:09 [INFO]: Epoch 119 - training loss: 0.7687, validation loss: 0.8922
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch119_loss0.8921752721071243.pypots
2024-05-24 20:59:09 [INFO]: Epoch 120 - training loss: 0.7092, validation loss: 0.8876
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch120_loss0.8875536769628525.pypots
2024-05-24 20:59:09 [INFO]: Epoch 121 - training loss: 0.7273, validation loss: 0.8928
2024-05-24 20:59:09 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch121_loss0.8928219527006149.pypots
2024-05-24 20:59:10 [INFO]: Epoch 122 - training loss: 0.7397, validation loss: 0.8902
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch122_loss0.8901925086975098.pypots
2024-05-24 20:59:10 [INFO]: Epoch 123 - training loss: 0.7395, validation loss: 0.8888
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch123_loss0.8887999653816223.pypots
2024-05-24 20:59:10 [INFO]: Epoch 124 - training loss: 0.7488, validation loss: 0.8924
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch124_loss0.8924315869808197.pypots
2024-05-24 20:59:10 [INFO]: Epoch 125 - training loss: 0.7260, validation loss: 0.8845
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch125_loss0.8844639360904694.pypots
2024-05-24 20:59:10 [INFO]: Epoch 126 - training loss: 0.7416, validation loss: 0.8834
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch126_loss0.8834386169910431.pypots
2024-05-24 20:59:10 [INFO]: Epoch 127 - training loss: 0.7070, validation loss: 0.8790
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch127_loss0.8789516389369965.pypots
2024-05-24 20:59:10 [INFO]: Epoch 128 - training loss: 0.7161, validation loss: 0.8831
2024-05-24 20:59:10 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch128_loss0.8831054270267487.pypots
2024-05-24 20:59:11 [INFO]: Epoch 129 - training loss: 0.7184, validation loss: 0.8808
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch129_loss0.880820706486702.pypots
2024-05-24 20:59:11 [INFO]: Epoch 130 - training loss: 0.7098, validation loss: 0.8801
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch130_loss0.8800563365221024.pypots
2024-05-24 20:59:11 [INFO]: Epoch 131 - training loss: 0.7088, validation loss: 0.8809
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch131_loss0.8808906525373459.pypots
2024-05-24 20:59:11 [INFO]: Epoch 132 - training loss: 0.7243, validation loss: 0.8791
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch132_loss0.8790958821773529.pypots
2024-05-24 20:59:11 [INFO]: Epoch 133 - training loss: 0.7081, validation loss: 0.8784
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch133_loss0.8783954381942749.pypots
2024-05-24 20:59:11 [INFO]: Epoch 134 - training loss: 0.7392, validation loss: 0.8815
2024-05-24 20:59:11 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch134_loss0.8814608603715897.pypots
2024-05-24 20:59:12 [INFO]: Epoch 135 - training loss: 0.7208, validation loss: 0.8772
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch135_loss0.8771589696407318.pypots
2024-05-24 20:59:12 [INFO]: Epoch 136 - training loss: 0.7331, validation loss: 0.8749
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch136_loss0.8749240934848785.pypots
2024-05-24 20:59:12 [INFO]: Epoch 137 - training loss: 0.7090, validation loss: 0.8758
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch137_loss0.8758155852556229.pypots
2024-05-24 20:59:12 [INFO]: Epoch 138 - training loss: 0.7165, validation loss: 0.8749
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch138_loss0.8749040961265564.pypots
2024-05-24 20:59:12 [INFO]: Epoch 139 - training loss: 0.7268, validation loss: 0.8725
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch139_loss0.8725487142801285.pypots
2024-05-24 20:59:12 [INFO]: Epoch 140 - training loss: 0.7253, validation loss: 0.8667
2024-05-24 20:59:12 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch140_loss0.8667430728673935.pypots
2024-05-24 20:59:13 [INFO]: Epoch 141 - training loss: 0.7306, validation loss: 0.8727
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch141_loss0.8726884424686432.pypots
2024-05-24 20:59:13 [INFO]: Epoch 142 - training loss: 0.7229, validation loss: 0.8700
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch142_loss0.8699550777673721.pypots
2024-05-24 20:59:13 [INFO]: Epoch 143 - training loss: 0.7121, validation loss: 0.8648
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch143_loss0.864778682589531.pypots
2024-05-24 20:59:13 [INFO]: Epoch 144 - training loss: 0.7235, validation loss: 0.8674
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch144_loss0.867374449968338.pypots
2024-05-24 20:59:13 [INFO]: Epoch 145 - training loss: 0.7186, validation loss: 0.8660
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch145_loss0.8659635633230209.pypots
2024-05-24 20:59:13 [INFO]: Epoch 146 - training loss: 0.7287, validation loss: 0.8655
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch146_loss0.865482360124588.pypots
2024-05-24 20:59:13 [INFO]: Epoch 147 - training loss: 0.7319, validation loss: 0.8672
2024-05-24 20:59:13 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch147_loss0.8672337532043457.pypots
2024-05-24 20:59:14 [INFO]: Epoch 148 - training loss: 0.7258, validation loss: 0.8647
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch148_loss0.8647323995828629.pypots
2024-05-24 20:59:14 [INFO]: Epoch 149 - training loss: 0.7355, validation loss: 0.8669
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch149_loss0.8669456243515015.pypots
2024-05-24 20:59:14 [INFO]: Epoch 150 - training loss: 0.7081, validation loss: 0.8644
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch150_loss0.8643527179956436.pypots
2024-05-24 20:59:14 [INFO]: Epoch 151 - training loss: 0.7618, validation loss: 0.8659
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch151_loss0.8658761531114578.pypots
2024-05-24 20:59:14 [INFO]: Epoch 152 - training loss: 0.6999, validation loss: 0.8616
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch152_loss0.8616048246622086.pypots
2024-05-24 20:59:14 [INFO]: Epoch 153 - training loss: 0.7125, validation loss: 0.8614
2024-05-24 20:59:14 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch153_loss0.8614134788513184.pypots
2024-05-24 20:59:15 [INFO]: Epoch 154 - training loss: 0.7258, validation loss: 0.8598
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch154_loss0.8598417788743973.pypots
2024-05-24 20:59:15 [INFO]: Epoch 155 - training loss: 0.7115, validation loss: 0.8591
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch155_loss0.859071210026741.pypots
2024-05-24 20:59:15 [INFO]: Epoch 156 - training loss: 0.7423, validation loss: 0.8588
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch156_loss0.8588247746229172.pypots
2024-05-24 20:59:15 [INFO]: Epoch 157 - training loss: 0.7272, validation loss: 0.8562
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch157_loss0.8562187701463699.pypots
2024-05-24 20:59:15 [INFO]: Epoch 158 - training loss: 0.7172, validation loss: 0.8546
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch158_loss0.8546383827924728.pypots
2024-05-24 20:59:15 [INFO]: Epoch 159 - training loss: 0.7265, validation loss: 0.8515
2024-05-24 20:59:15 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch159_loss0.851528212428093.pypots
2024-05-24 20:59:16 [INFO]: Epoch 160 - training loss: 0.7146, validation loss: 0.8502
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch160_loss0.8502331525087357.pypots
2024-05-24 20:59:16 [INFO]: Epoch 161 - training loss: 0.7164, validation loss: 0.8547
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch161_loss0.8547102808952332.pypots
2024-05-24 20:59:16 [INFO]: Epoch 162 - training loss: 0.7347, validation loss: 0.8540
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch162_loss0.8540053218603134.pypots
2024-05-24 20:59:16 [INFO]: Epoch 163 - training loss: 0.7159, validation loss: 0.8530
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch163_loss0.8529528379440308.pypots
2024-05-24 20:59:16 [INFO]: Epoch 164 - training loss: 0.7146, validation loss: 0.8533
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch164_loss0.8533058315515518.pypots
2024-05-24 20:59:16 [INFO]: Epoch 165 - training loss: 0.7306, validation loss: 0.8502
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch165_loss0.850184440612793.pypots
2024-05-24 20:59:16 [INFO]: Epoch 166 - training loss: 0.7168, validation loss: 0.8488
2024-05-24 20:59:16 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch166_loss0.8488131016492844.pypots
2024-05-24 20:59:17 [INFO]: Epoch 167 - training loss: 0.7223, validation loss: 0.8507
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch167_loss0.8507046848535538.pypots
2024-05-24 20:59:17 [INFO]: Epoch 168 - training loss: 0.7312, validation loss: 0.8481
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch168_loss0.8481238782405853.pypots
2024-05-24 20:59:17 [INFO]: Epoch 169 - training loss: 0.7020, validation loss: 0.8468
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch169_loss0.8467604219913483.pypots
2024-05-24 20:59:17 [INFO]: Epoch 170 - training loss: 0.7412, validation loss: 0.8516
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch170_loss0.851553425192833.pypots
2024-05-24 20:59:17 [INFO]: Epoch 171 - training loss: 0.7165, validation loss: 0.8459
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch171_loss0.8458989709615707.pypots
2024-05-24 20:59:17 [INFO]: Epoch 172 - training loss: 0.7041, validation loss: 0.8495
2024-05-24 20:59:17 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch172_loss0.8495444506406784.pypots
2024-05-24 20:59:18 [INFO]: Epoch 173 - training loss: 0.7550, validation loss: 0.8496
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch173_loss0.8496333956718445.pypots
2024-05-24 20:59:18 [INFO]: Epoch 174 - training loss: 0.7176, validation loss: 0.8444
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch174_loss0.8444005697965622.pypots
2024-05-24 20:59:18 [INFO]: Epoch 175 - training loss: 0.7449, validation loss: 0.8432
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch175_loss0.8432301133871078.pypots
2024-05-24 20:59:18 [INFO]: Epoch 176 - training loss: 0.7028, validation loss: 0.8421
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch176_loss0.8420605361461639.pypots
2024-05-24 20:59:18 [INFO]: Epoch 177 - training loss: 0.7182, validation loss: 0.8459
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch177_loss0.8459179401397705.pypots
2024-05-24 20:59:18 [INFO]: Epoch 178 - training loss: 0.7141, validation loss: 0.8421
2024-05-24 20:59:18 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch178_loss0.842118501663208.pypots
2024-05-24 20:59:19 [INFO]: Epoch 179 - training loss: 0.7015, validation loss: 0.8426
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch179_loss0.8425746411085129.pypots
2024-05-24 20:59:19 [INFO]: Epoch 180 - training loss: 0.7188, validation loss: 0.8435
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch180_loss0.8435030430555344.pypots
2024-05-24 20:59:19 [INFO]: Epoch 181 - training loss: 0.7248, validation loss: 0.8397
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch181_loss0.8396742343902588.pypots
2024-05-24 20:59:19 [INFO]: Epoch 182 - training loss: 0.7141, validation loss: 0.8409
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch182_loss0.840943232178688.pypots
2024-05-24 20:59:19 [INFO]: Epoch 183 - training loss: 0.7058, validation loss: 0.8399
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch183_loss0.8399175405502319.pypots
2024-05-24 20:59:19 [INFO]: Epoch 184 - training loss: 0.7147, validation loss: 0.8383
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch184_loss0.8383049070835114.pypots
2024-05-24 20:59:19 [INFO]: Epoch 185 - training loss: 0.7106, validation loss: 0.8419
2024-05-24 20:59:19 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch185_loss0.8418653011322021.pypots
2024-05-24 20:59:20 [INFO]: Epoch 186 - training loss: 0.7151, validation loss: 0.8376
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch186_loss0.8376207500696182.pypots
2024-05-24 20:59:20 [INFO]: Epoch 187 - training loss: 0.7069, validation loss: 0.8382
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch187_loss0.8381980359554291.pypots
2024-05-24 20:59:20 [INFO]: Epoch 188 - training loss: 0.7093, validation loss: 0.8368
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch188_loss0.8368406891822815.pypots
2024-05-24 20:59:20 [INFO]: Epoch 189 - training loss: 0.7275, validation loss: 0.8361
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch189_loss0.8360550403594971.pypots
2024-05-24 20:59:20 [INFO]: Epoch 190 - training loss: 0.7251, validation loss: 0.8355
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch190_loss0.8355468511581421.pypots
2024-05-24 20:59:20 [INFO]: Epoch 191 - training loss: 0.7369, validation loss: 0.8360
2024-05-24 20:59:20 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch191_loss0.8360409140586853.pypots
2024-05-24 20:59:21 [INFO]: Epoch 192 - training loss: 0.7329, validation loss: 0.8350
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch192_loss0.8350064307451248.pypots
2024-05-24 20:59:21 [INFO]: Epoch 193 - training loss: 0.7128, validation loss: 0.8375
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch193_loss0.8374820649623871.pypots
2024-05-24 20:59:21 [INFO]: Epoch 194 - training loss: 0.7172, validation loss: 0.8336
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch194_loss0.8335591107606888.pypots
2024-05-24 20:59:21 [INFO]: Epoch 195 - training loss: 0.7255, validation loss: 0.8322
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch195_loss0.8321765661239624.pypots
2024-05-24 20:59:21 [INFO]: Epoch 196 - training loss: 0.7089, validation loss: 0.8315
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch196_loss0.8315279334783554.pypots
2024-05-24 20:59:21 [INFO]: Epoch 197 - training loss: 0.7012, validation loss: 0.8309
2024-05-24 20:59:21 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch197_loss0.830851286649704.pypots
2024-05-24 20:59:22 [INFO]: Epoch 198 - training loss: 0.7288, validation loss: 0.8312
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch198_loss0.8312158137559891.pypots
2024-05-24 20:59:22 [INFO]: Epoch 199 - training loss: 0.7073, validation loss: 0.8325
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch199_loss0.8325020521879196.pypots
2024-05-24 20:59:22 [INFO]: Epoch 200 - training loss: 0.7284, validation loss: 0.8340
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch200_loss0.8339848071336746.pypots
2024-05-24 20:59:22 [INFO]: Epoch 201 - training loss: 0.7084, validation loss: 0.8333
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch201_loss0.8333121836185455.pypots
2024-05-24 20:59:22 [INFO]: Epoch 202 - training loss: 0.7109, validation loss: 0.8315
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch202_loss0.8314911872148514.pypots
2024-05-24 20:59:22 [INFO]: Epoch 203 - training loss: 0.7241, validation loss: 0.8315
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch203_loss0.8315248489379883.pypots
2024-05-24 20:59:22 [INFO]: Epoch 204 - training loss: 0.7278, validation loss: 0.8285
2024-05-24 20:59:22 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch204_loss0.8284733593463898.pypots
2024-05-24 20:59:23 [INFO]: Epoch 205 - training loss: 0.7140, validation loss: 0.8299
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch205_loss0.8299018442630768.pypots
2024-05-24 20:59:23 [INFO]: Epoch 206 - training loss: 0.7317, validation loss: 0.8289
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch206_loss0.8288798928260803.pypots
2024-05-24 20:59:23 [INFO]: Epoch 207 - training loss: 0.7065, validation loss: 0.8329
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch207_loss0.8329233825206757.pypots
2024-05-24 20:59:23 [INFO]: Epoch 208 - training loss: 0.7033, validation loss: 0.8298
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch208_loss0.829787477850914.pypots
2024-05-24 20:59:23 [INFO]: Epoch 209 - training loss: 0.7106, validation loss: 0.8312
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch209_loss0.8312427252531052.pypots
2024-05-24 20:59:23 [INFO]: Epoch 210 - training loss: 0.7049, validation loss: 0.8297
2024-05-24 20:59:23 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch210_loss0.8297201991081238.pypots
2024-05-24 20:59:24 [INFO]: Epoch 211 - training loss: 0.7123, validation loss: 0.8286
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch211_loss0.8286075294017792.pypots
2024-05-24 20:59:24 [INFO]: Epoch 212 - training loss: 0.7207, validation loss: 0.8247
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch212_loss0.8247146904468536.pypots
2024-05-24 20:59:24 [INFO]: Epoch 213 - training loss: 0.7264, validation loss: 0.8274
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch213_loss0.8274338990449905.pypots
2024-05-24 20:59:24 [INFO]: Epoch 214 - training loss: 0.7203, validation loss: 0.8287
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch214_loss0.828706219792366.pypots
2024-05-24 20:59:24 [INFO]: Epoch 215 - training loss: 0.7120, validation loss: 0.8256
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch215_loss0.8255516886711121.pypots
2024-05-24 20:59:24 [INFO]: Epoch 216 - training loss: 0.7079, validation loss: 0.8254
2024-05-24 20:59:24 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch216_loss0.8253905326128006.pypots
2024-05-24 20:59:25 [INFO]: Epoch 217 - training loss: 0.7320, validation loss: 0.8257
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch217_loss0.8256535232067108.pypots
2024-05-24 20:59:25 [INFO]: Epoch 218 - training loss: 0.7209, validation loss: 0.8242
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch218_loss0.8242269456386566.pypots
2024-05-24 20:59:25 [INFO]: Epoch 219 - training loss: 0.7230, validation loss: 0.8252
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch219_loss0.8252445161342621.pypots
2024-05-24 20:59:25 [INFO]: Epoch 220 - training loss: 0.7066, validation loss: 0.8250
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch220_loss0.8250399380922318.pypots
2024-05-24 20:59:25 [INFO]: Epoch 221 - training loss: 0.7113, validation loss: 0.8262
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch221_loss0.8261878341436386.pypots
2024-05-24 20:59:25 [INFO]: Epoch 222 - training loss: 0.7238, validation loss: 0.8257
2024-05-24 20:59:25 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch222_loss0.8257320076227188.pypots
2024-05-24 20:59:26 [INFO]: Epoch 223 - training loss: 0.7203, validation loss: 0.8244
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch223_loss0.8244160860776901.pypots
2024-05-24 20:59:26 [INFO]: Epoch 224 - training loss: 0.7146, validation loss: 0.8214
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch224_loss0.8213856518268585.pypots
2024-05-24 20:59:26 [INFO]: Epoch 225 - training loss: 0.7192, validation loss: 0.8229
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch225_loss0.8229384571313858.pypots
2024-05-24 20:59:26 [INFO]: Epoch 226 - training loss: 0.7165, validation loss: 0.8259
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch226_loss0.8259247839450836.pypots
2024-05-24 20:59:26 [INFO]: Epoch 227 - training loss: 0.7215, validation loss: 0.8237
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch227_loss0.8236516416072845.pypots
2024-05-24 20:59:26 [INFO]: Epoch 228 - training loss: 0.7241, validation loss: 0.8251
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch228_loss0.8250545561313629.pypots
2024-05-24 20:59:26 [INFO]: Epoch 229 - training loss: 0.7204, validation loss: 0.8236
2024-05-24 20:59:26 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch229_loss0.8236451596021652.pypots
2024-05-24 20:59:27 [INFO]: Epoch 230 - training loss: 0.7152, validation loss: 0.8228
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch230_loss0.8228452354669571.pypots
2024-05-24 20:59:27 [INFO]: Epoch 231 - training loss: 0.7270, validation loss: 0.8198
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch231_loss0.8197914659976959.pypots
2024-05-24 20:59:27 [INFO]: Epoch 232 - training loss: 0.7228, validation loss: 0.8191
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch232_loss0.8190902173519135.pypots
2024-05-24 20:59:27 [INFO]: Epoch 233 - training loss: 0.7240, validation loss: 0.8200
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch233_loss0.8200292587280273.pypots
2024-05-24 20:59:27 [INFO]: Epoch 234 - training loss: 0.7156, validation loss: 0.8190
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch234_loss0.818996474146843.pypots
2024-05-24 20:59:27 [INFO]: Epoch 235 - training loss: 0.7522, validation loss: 0.8197
2024-05-24 20:59:27 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch235_loss0.8196736425161362.pypots
2024-05-24 20:59:28 [INFO]: Epoch 236 - training loss: 0.7222, validation loss: 0.8177
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch236_loss0.8176687210798264.pypots
2024-05-24 20:59:28 [INFO]: Epoch 237 - training loss: 0.7302, validation loss: 0.8203
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch237_loss0.8203105628490448.pypots
2024-05-24 20:59:28 [INFO]: Epoch 238 - training loss: 0.7165, validation loss: 0.8192
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch238_loss0.8192237913608551.pypots
2024-05-24 20:59:28 [INFO]: Epoch 239 - training loss: 0.7062, validation loss: 0.8179
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch239_loss0.8178906440734863.pypots
2024-05-24 20:59:28 [INFO]: Epoch 240 - training loss: 0.7169, validation loss: 0.8167
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch240_loss0.8167286068201065.pypots
2024-05-24 20:59:28 [INFO]: Epoch 241 - training loss: 0.7266, validation loss: 0.8212
2024-05-24 20:59:28 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch241_loss0.8211939036846161.pypots
2024-05-24 20:59:29 [INFO]: Epoch 242 - training loss: 0.7366, validation loss: 0.8193
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch242_loss0.8193185180425644.pypots
2024-05-24 20:59:29 [INFO]: Epoch 243 - training loss: 0.7438, validation loss: 0.8196
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch243_loss0.8195832520723343.pypots
2024-05-24 20:59:29 [INFO]: Epoch 244 - training loss: 0.7090, validation loss: 0.8181
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch244_loss0.8181286156177521.pypots
2024-05-24 20:59:29 [INFO]: Epoch 245 - training loss: 0.7232, validation loss: 0.8209
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch245_loss0.8208977431058884.pypots
2024-05-24 20:59:29 [INFO]: Epoch 246 - training loss: 0.7398, validation loss: 0.8173
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch246_loss0.8173245638608932.pypots
2024-05-24 20:59:29 [INFO]: Epoch 247 - training loss: 0.7270, validation loss: 0.8164
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch247_loss0.8164353370666504.pypots
2024-05-24 20:59:29 [INFO]: Epoch 248 - training loss: 0.7402, validation loss: 0.8151
2024-05-24 20:59:29 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch248_loss0.8151344954967499.pypots
2024-05-24 20:59:30 [INFO]: Epoch 249 - training loss: 0.7091, validation loss: 0.8171
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch249_loss0.8171453922986984.pypots
2024-05-24 20:59:30 [INFO]: Epoch 250 - training loss: 0.7217, validation loss: 0.8165
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch250_loss0.8165208399295807.pypots
2024-05-24 20:59:30 [INFO]: Epoch 251 - training loss: 0.7210, validation loss: 0.8182
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch251_loss0.8181978166103363.pypots
2024-05-24 20:59:30 [INFO]: Epoch 252 - training loss: 0.6945, validation loss: 0.8168
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch252_loss0.8168477863073349.pypots
2024-05-24 20:59:30 [INFO]: Epoch 253 - training loss: 0.7180, validation loss: 0.8187
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch253_loss0.8186662942171097.pypots
2024-05-24 20:59:30 [INFO]: Epoch 254 - training loss: 0.7291, validation loss: 0.8175
2024-05-24 20:59:30 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch254_loss0.8174894005060196.pypots
2024-05-24 20:59:31 [INFO]: Epoch 255 - training loss: 0.7191, validation loss: 0.8191
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch255_loss0.8191104978322983.pypots
2024-05-24 20:59:31 [INFO]: Epoch 256 - training loss: 0.7358, validation loss: 0.8174
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch256_loss0.817350760102272.pypots
2024-05-24 20:59:31 [INFO]: Epoch 257 - training loss: 0.7295, validation loss: 0.8150
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch257_loss0.8149947673082352.pypots
2024-05-24 20:59:31 [INFO]: Epoch 258 - training loss: 0.7106, validation loss: 0.8188
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch258_loss0.8188263922929764.pypots
2024-05-24 20:59:31 [INFO]: Epoch 259 - training loss: 0.7234, validation loss: 0.8149
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch259_loss0.8148875087499619.pypots
2024-05-24 20:59:31 [INFO]: Epoch 260 - training loss: 0.7327, validation loss: 0.8184
2024-05-24 20:59:31 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch260_loss0.8183767050504684.pypots
2024-05-24 20:59:32 [INFO]: Epoch 261 - training loss: 0.7199, validation loss: 0.8161
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch261_loss0.8161264657974243.pypots
2024-05-24 20:59:32 [INFO]: Epoch 262 - training loss: 0.7104, validation loss: 0.8176
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch262_loss0.8176239132881165.pypots
2024-05-24 20:59:32 [INFO]: Epoch 263 - training loss: 0.6929, validation loss: 0.8145
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch263_loss0.8144655525684357.pypots
2024-05-24 20:59:32 [INFO]: Epoch 264 - training loss: 0.7540, validation loss: 0.8155
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch264_loss0.8154692202806473.pypots
2024-05-24 20:59:32 [INFO]: Epoch 265 - training loss: 0.7306, validation loss: 0.8146
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch265_loss0.81462062895298.pypots
2024-05-24 20:59:32 [INFO]: Epoch 266 - training loss: 0.7615, validation loss: 0.8158
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch266_loss0.815773218870163.pypots
2024-05-24 20:59:32 [INFO]: Epoch 267 - training loss: 0.7161, validation loss: 0.8142
2024-05-24 20:59:32 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch267_loss0.814200296998024.pypots
2024-05-24 20:59:33 [INFO]: Epoch 268 - training loss: 0.7019, validation loss: 0.8145
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch268_loss0.8144515752792358.pypots
2024-05-24 20:59:33 [INFO]: Epoch 269 - training loss: 0.7171, validation loss: 0.8144
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch269_loss0.8144004046916962.pypots
2024-05-24 20:59:33 [INFO]: Epoch 270 - training loss: 0.7154, validation loss: 0.8140
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch270_loss0.8139761090278625.pypots
2024-05-24 20:59:33 [INFO]: Epoch 271 - training loss: 0.7245, validation loss: 0.8150
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch271_loss0.8149703741073608.pypots
2024-05-24 20:59:33 [INFO]: Epoch 272 - training loss: 0.7162, validation loss: 0.8131
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch272_loss0.8130673766136169.pypots
2024-05-24 20:59:33 [INFO]: Epoch 273 - training loss: 0.7004, validation loss: 0.8164
2024-05-24 20:59:33 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch273_loss0.8163611739873886.pypots
2024-05-24 20:59:34 [INFO]: Epoch 274 - training loss: 0.7230, validation loss: 0.8172
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch274_loss0.817237064242363.pypots
2024-05-24 20:59:34 [INFO]: Epoch 275 - training loss: 0.7573, validation loss: 0.8131
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch275_loss0.8130886107683182.pypots
2024-05-24 20:59:34 [INFO]: Epoch 276 - training loss: 0.7094, validation loss: 0.8118
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch276_loss0.8117866516113281.pypots
2024-05-24 20:59:34 [INFO]: Epoch 277 - training loss: 0.7222, validation loss: 0.8154
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch277_loss0.8153820633888245.pypots
2024-05-24 20:59:34 [INFO]: Epoch 278 - training loss: 0.7111, validation loss: 0.8121
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch278_loss0.812100887298584.pypots
2024-05-24 20:59:34 [INFO]: Epoch 279 - training loss: 0.7193, validation loss: 0.8141
2024-05-24 20:59:34 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch279_loss0.8141438961029053.pypots
2024-05-24 20:59:35 [INFO]: Epoch 280 - training loss: 0.6947, validation loss: 0.8134
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch280_loss0.8134056478738785.pypots
2024-05-24 20:59:35 [INFO]: Epoch 281 - training loss: 0.7212, validation loss: 0.8163
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch281_loss0.8162811547517776.pypots
2024-05-24 20:59:35 [INFO]: Epoch 282 - training loss: 0.7040, validation loss: 0.8138
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch282_loss0.813781127333641.pypots
2024-05-24 20:59:35 [INFO]: Epoch 283 - training loss: 0.7104, validation loss: 0.8135
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch283_loss0.8134612590074539.pypots
2024-05-24 20:59:35 [INFO]: Epoch 284 - training loss: 0.7269, validation loss: 0.8128
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch284_loss0.8127866834402084.pypots
2024-05-24 20:59:35 [INFO]: Epoch 285 - training loss: 0.7084, validation loss: 0.8132
2024-05-24 20:59:35 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch285_loss0.8131662458181381.pypots
2024-05-24 20:59:35 [INFO]: Epoch 286 - training loss: 0.7254, validation loss: 0.8133
2024-05-24 20:59:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN_epoch286_loss0.8132567554712296.pypots
2024-05-24 20:59:36 [INFO]: Exceeded the training patience. Terminating the training procedure...
2024-05-24 20:59:36 [INFO]: Finished training. The best model is from epoch#276.
2024-05-24 20:59:36 [INFO]: Saved the model to augmentation_premask_saved_results/round_4/MRNN_ettm1/20240524_T205849/MRNN.pypots
2024-05-24 20:59:36 [INFO]: MRNN on ETTm1: MAE=0.5763, MSE=0.9773
2024-05-24 20:59:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/MRNN_ettm1/imputation.pkl
2024-05-24 20:59:36 [INFO]: Using the given device: cpu
2024-05-24 20:59:36 [INFO]: LOCF on ETTm1: MAE=0.1434, MSE=0.0826
2024-05-24 20:59:36 [INFO]: Successfully created the given path "saved_results/round_4/LOCF_ettm1".
2024-05-24 20:59:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/LOCF_ettm1/imputation.pkl
2024-05-24 20:59:36 [INFO]: Median on ETTm1: MAE=0.6527, MSE=0.8213
2024-05-24 20:59:36 [INFO]: Successfully created the given path "saved_results/round_4/Median_ettm1".
2024-05-24 20:59:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Median_ettm1/imputation.pkl
2024-05-24 20:59:36 [INFO]: Mean on ETTm1: MAE=0.6579, MSE=0.8008
2024-05-24 20:59:36 [INFO]: Successfully created the given path "saved_results/round_4/Mean_ettm1".
2024-05-24 20:59:36 [INFO]: Successfully saved to augmentation_premask_saved_results/round_4/Mean_ettm1/imputation.pkl
2024-05-24 20:59:36 [INFO]: 
SAITS on data/ettm1: MAE=0.156±0.002280205255906487, MSE=0.050±0.004002720856190509
Transformer on data/ettm1: MAE=0.145±0.00626797131286893, MSE=0.041±0.003474859822241333
TimesNet on data/ettm1: MAE=0.115±0.00040615840986943575, MSE=0.029±0.00024288176792806553
CSDI on data/ettm1: MAE=0.132±0.015265438659632164, MSE=0.044±0.009077638482472051
GPVAE on data/ettm1: MAE=0.302±0.023122529643041415, MSE=0.195±0.021407280716793195
USGAN on data/ettm1: MAE=0.159±0.007192073435250808, MSE=0.065±0.005248028696948788
BRITS on data/ettm1: MAE=0.144±0.006627435826808204, MSE=0.062±0.0054889549590993875
MRNN on data/ettm1: MAE=0.585±0.009792343552083247, MSE=0.982±0.014881744737451089
LOCF on data/ettm1: MAE=0.143±0.0, MSE=0.083±0.0
Median on data/ettm1: MAE=0.653±0.0, MSE=0.821±1.1102230246251565e-16
Mean on data/ettm1: MAE=0.658±0.0, MSE=0.801±0.0